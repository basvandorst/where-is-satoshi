@_author: peter__r
@_date: 2015-12-25 02:23:45
I agree; I think it is an exciting technology.  I believe the free-market will find the right balance for what type of transactions are best for LN and what types are best for the Blockchain.  
@_date: 2015-12-01 08:21:49
That's just the *limit* for the block size, not the block size itself.  The block size will be dynamic under BIP101.  
@_date: 2015-12-30 06:46:15
I'm sure our good friend has informed them all by now.  
@_date: 2015-12-30 01:44:23
I'm starting to think you're right.  It quite elegant actually.  
@_date: 2015-12-29 20:39:22
Hmm...you might be right!
(thus proving my point that I can be wrong :)
@_date: 2015-12-30 22:51:19
Yes, I can see it that way too.  I think I understand it as much as I can at the moment.  I'd need to dig deeper into the math to quantify the effects further.  
@_date: 2015-12-29 18:19:10
In reality, fees are dynamically balanced with the cost of production (like you suggested), as a result of the free-market forces.  In the figure caption, I was trying to explain the dynamics around why this balance occurs.   
@_date: 2015-12-28 21:00:39


Precisely.  
@_date: 2015-12-30 00:57:39


Yes!  Because it does induce a real cost--only the cost is not paid each block, but all at once every so often when a block is orphaned and the entire block reward is lost.  For example, if including 1 MB of transactions in my block increases my orphaning risk by 1%, then *most* of the time I'll make more money in fees by included that 1 MB of transactions.  However, every hundredth block or so, I'll lose the full 25 BTC block reward.  What we say is that the "expectation value" of the cost is 0.25 BTC per block--even though it will either cost me 0 BTC or 25 BTC.  See what I mean?
I wrote a [paper]( on this as well.  And gave a [talk]( on the same subject in Montreal.  


Doesn't matter, so long as any miner can increase his profit by either building a larger or smaller block.  There is always some block size that maximizes the expectation value of his profit.  This is exactly what I show in the paper I linked above.  
@_date: 2015-12-30 02:25:29
@_date: 2015-12-24 09:28:30


His point is that we *already* have a fee market; what small-block proponents want to do is increase prices.  Block space is a commodity and satisfies the laws of supply and demand:
@_date: 2015-12-30 15:41:22


That's not true though.  I'd like to invite you to join the discussion on this topic at bitco.in.  There is a great deal of wisdom that has accrued there on this and other topics, and other posters who would love to debate with you.  
@_date: 2015-12-17 16:51:55


Indeed.  On a related note, what's interesting is that transaction curve spikes *lag* the market cap spikes by several days.  The reason is that people make more transactions both when the price is rocketing and also when the price is crashing. 
@_date: 2015-12-30 22:06:49
Yes I agree.  But point is valid too: because these orphaned blocks are lost, the electricity that went into them is sort of lost too.  The result is that the "difficulty" is less than it would have been had the orphan risk been reduced using something like subchains.  
@_date: 2015-12-28 23:40:53
Giving choice to the user is the vision behind Bitcoin Unlimited (BU is a fork of Core that allows users to choose directly).  We would love to see you at our forum: 
@_date: 2015-12-17 16:58:25


Correct.  But like you said, we don't have reliable data on the number of participants.  Interestingly, using the "number of unique addressed used per day" produces a similar fit.  
@_date: 2015-12-29 18:08:21
It sounds like you've got it.  What Greg was arguing is that "on average" the funds lost to orphaning risk (and other non-PoW costs) would precisely balance the funds gained by transaction fees.  If this were true, it would mean that none of the fee revenue pays for the hashing cost.  
I've shown that this is not true.  (It sounds like you already understood that intuitively.)
@_date: 2015-12-29 20:11:27
I think that's an overstatement.  Greg just didn't think though several points related to the economics and game theory of Bitcoin. 
There is nothing "wrong" with being wrong.  There are numerous topics that I know very little about, and I also get things wrong on the topics that I do know a lot about too.  Everyone does.
@_date: 2015-12-17 22:19:21
@_date: 2015-12-24 15:00:14
And those who try are asked not to block the stream of transactions on the main chain in order to subsidize their project.  
@_date: 2015-12-17 16:38:31
They are plotted on the *same* set of axes.  The chart compares the market cap to the number of transactions *squared*--hence why it's referred to as the Metcalfe relationship.
@_date: 2015-12-29 17:55:50
He is saying that without a restrictive block size limit, that all of the fees "leak" out of the system, paying for things such as orphaned blocks and other costs.  That is, they don't count towards network security (see linked email).
What I have shown is that this is not the case.  With subchains, a significant part of the transactions fees is diverted to increasing the network hash power, rather than being "wasted" as orphaned blocks. 
I would love to hear thoughts on this.  He seems to be one of the only small-block proponents with a solid grasp on economics.  
@_date: 2015-12-30 01:25:48
OK, yes, I agree with this.  The total revenue is the same regardless of orphans.  
@_date: 2015-12-01 07:00:22
I like that too :)
@_date: 2015-12-29 20:38:54
In this paper, I showed that under very general conditions, fees will not trend to zero:
@_date: 2015-12-25 01:45:30
I think LN is a very interesting idea worthwhile of exploring.  My only problem with Blockstream is their idea that the stream of transactions on the main chain should be blocked to encourage the growth of off-chain solutions like LN.
I say let both compete freely and the market will decide.
@_date: 2015-12-07 21:29:13
Another great paper by Bitfury researchers!  Thank you for being an active contributor to public Bitcoin research!
@_date: 2015-12-22 18:43:17
@_date: 2015-12-06 05:10:23
Hahah so true!
@_date: 2015-12-20 04:23:45
Nice work, John!  It's great to see more people getting involved--especially on much-needed projects such as 'weak blocks' initiatives like this.    
@_date: 2015-12-24 16:07:16
If you increase the price of main-chain transactions, then you create increased demand for substitutes like Lightning Network transactions.  This is one of the reason Blockstream wants to keep a restrictive block size limit in the first place: to encourage the development of off-chain solutions.  
This is very basic economics.  
@_date: 2015-12-30 01:01:54
Did you look at the [subchains paper]( where this chart comes from?  I honestly can't even parse what you're trying to say.  
I've shown that transaction fees can contribute to PoW security even in the absence of a *restrictive* limit.  Agree or disagree?
@_date: 2015-12-27 02:57:29


[Bitcoin Unlimited]( allows users to set their own block size limits, but has defaults such that it won't fork with respect to consensus.  
Is Bitcoin Unlimited an altcoin?
@_date: 2015-12-31 21:19:52
This isn't from the Core team, but this is the type of visual explanation our team uses to try to convey the intuition behind technical proposals to the community:
If one can't explain it simply, then one probably doesn't understand it completely. 
@_date: 2015-06-23 16:09:03
Awesome work, TradeBlock!
@_date: 2015-12-28 14:06:00
I'm not sure how much you've been following, but there is still a block size limit with BU (and it may end up being more conservative than with BIP101).  Furthermore, Bitcoin Unlimited is complementary to other proposals (BU isn't really a "proposal" any way).  
There is no need for all miners and nodes to support the exact same settings regarding the max block size limit.  Node operators can safely increase their own block size limits today to proclaim "I accept bigger blocks TODAY!"  There are presently 60+ nodes (over 1% of the network) doing this now.   
@_date: 2015-12-17 18:39:33
I just download the data "live" from blockchain.info into Mathematica and make the plots.  Here is the code I use to get it:
     mcap= {AbsoluteTime[{ "Month", "Year", "Hour", "Minute", "Second"}}],  -&gt; True];
     txsqrd= {AbsoluteTime[{ "Month", "Year", "Hour", "Minute", "Second"}}],  -&gt; True];
@_date: 2015-12-30 02:09:44


I don't understand why you keep saying this when there are 80+ Bitcoin Unlimited nodes following different validation rules (i.e., a larger accepted block size) yet Bitcoin is still working.  
Do all the nodes have to follow the same validation rules or not?
@_date: 2015-12-26 20:24:42
I'm not sure subchains would hurt Lightning.  Can someone explain exactly *why* LN needs RBF?  
@_date: 2015-12-19 18:21:12
A group of miners with over 50% of the network hashing power can *always* cooperate to orphan valid blocks.  This seems to me as just another way of looking at the 51% attack.   
@_date: 2015-12-01 07:22:45


Block sizes have always been dynamic and based on supply and demand. There are no big-block proponents proposing to make blocks a constant size.  
@_date: 2015-12-28 21:26:01
Bitcoin Unlimited (BU) will follow consensus as defined by the longest proof-of-work chain composed of valid transactions, whether or not that chain contains blocks &gt; 1 MB.  
What is special about BU is that nodes can honestly proclaim that they "will accept bigger blocks TODAY!"  They don't need to wait for BIP101 or some other proposal to activate.  
@_date: 2015-12-20 14:29:18
This paper represents novel work related to privacy techniques for cryptocurrency, so it is entirely relevant. 
@_date: 2015-12-27 19:39:58
Because the block size limit applies to the size of the subchain itself (because this is what becomes the strong block).  If there was high demand for block space (i.e., lots of transactions waiting to be mined), miners would have to stop extending the subchain once they hit the limit (which means they wouldn't be able to processes as many transactions as the want to).  
@_date: 2015-12-29 00:16:00
With the release of Bitcoin Unlimited, it has now been *empirically* demonstrated that nodes can safely and *independently* increase their block size limits and still track consensus.  This was already [understood from a theoretical perspective]( by investigators outside of Core.   
There are presently 70+ nodes that TODAY will accept blocks larger than 1 MB.  They are proclaiming to the world "If you make a bigger block, I will accept it!"
@_date: 2015-12-24 18:00:22
They are a private for-profit company.  Do you think their goal is to lose money by developing LN?
Anyways, there is absolutely *nothing* wrong with trying to make a profit.  My only problem with Blockstream is their idea that the stream of transactions on the main chain should be blocked to encourage the growth of off-chain solutions like LN.  
I say let both compete freely and the market will decide.  
@_date: 2015-12-17 20:16:41
@_date: 2015-12-29 16:13:17
The first three sectors were identified in [this excellent paper]( by researchers Bonneau, Miller (Clark, Narayanan, Kroll and Felten.  
Here is some additional background info related to the chart:
@_date: 2015-12-29 17:39:19
I believe [these charts]( are significant because they reveal that transaction fees will directly contribute to the proof-of-work cost even in the absence of a block size limit.  This is important because investigators have previously argued that fees that result from orphaning risk do not contribute to network security.  For example, Maxwell [argued]( “the fact that verifying and transmitting transactions has a cost isn’t enough, because all the funds go to pay that cost and none to the POW ‘artificial’ cost.”  This was in fact one of the argument put forth by small-block proponents for the need of a *restrictive* block size limit in the first place.  
Here is a [link]( to the full paper from which the chart was excerpted (refer to Sections 4 and 5).  
CC: @_date: 2015-12-22 20:51:31


I agree; this paper explains how a fee market exists today and will in fact always exists because space within a block behaves like a normal economic commodity (it satisfies the laws of supply and demand)


Total fees will actually go *up* as blocks become larger.  Furthermore, by employing subchains (an application of weak blocks), a significant portion of fee revenue is directed to proof-of-work, thereby increasing security:
@_date: 2015-12-25 03:56:01


That's catchy.  I like it. 8)
@_date: 2015-12-23 19:11:06
I think what further research will show is that Bitcoin transactions will always be essentially free...if you are willing to wait long enough.  (That is, unless of course a block size limit is employed to subsidize off-chain networks such as lightning.)   
@_date: 2015-06-22 19:25:34
Yes, please. 
@_date: 2015-12-29 18:06:12
Miners are incentivized to cooperate to build subchains (see [Sections 3 and 4]( modelling miners as short-term profit-maximizing agents.  I.e., cooperation is a Nash equilibrium.  
If there is limited non-cooperation, the claim still holds.  Only if miners *never* or *rarely* cooperate, would the claim by invalidated.  However, complete non-cooperation requires the majority of the network to NOT be net econo-rational.  But the network being net econo-rational is probably a requirement for Bitcoin to be secure in the first place.  
@_date: 2015-12-26 22:32:42
Sure.  It was an email that I wrote in response to Pieter Wuille's email earlier this morning.  You can read it here:
The rest of the thread contains additional context.  
@_date: 2015-06-21 17:32:31
Thank you to Smooth, Adrian-X, Solex and Cypherdoc for their suggestions.  
This graphic is released under the Creative Commons Attribution 4.0 License.
EDIT: If the image is blurry on your system, try this link:
@_date: 2015-12-24 09:35:17
It makes perfect sense! 
The guiding principle for Bitcoin is that the evolution of the network is decided by the code people freely choose to run. Consensus is therefore an emergent property, objectively represented by the longest proof-of-work chain. This fact is an unassailable property of Bitcoin and cannot be changed by fiat.
The final sentence of the Bitcoin white paper states:
*"They [nodes/miners] vote with their CPU power, expressing their acceptance of valid blocks by working on extending them and rejecting invalid blocks by refusing to work on them. Any needed rules and incentives can be enforced with this consensus mechanism."*
It is this mechanism of "voting with their CPU power" that keeps Bitcoin permissionless and uncensorable. Were it possible to compel miners to run a specific application with a specific set of rules then it would be trivial for the owner of the codebase to, for example, invalidate transactions, modify the inflation schedule, block certain bitcoin addresses or IP ranges, limit the quantity of transactions in a block, or implement any other centralized policies.
In other words, Bitcoin only maintains its intrinsically valuable properties of being permissionless, uncensorable, trustless, and uninflatable, precisely because the software is not, and should not be, controlled by any single governance entity.
@_date: 2015-12-30 22:18:51
It is best to keep orphan risk low for several reasons, including the self-propagation advantage.
@_date: 2015-12-23 20:42:52
Similar in the sense that they're both application of weak blocks.  Different in that append-only subchains are simpler from the networking perspective, and also provide increased security for zero-confirm transactions.  
@_date: 2015-12-30 18:44:53
You took my quote out of context by removing the statement after the emdash.  Read the full post.  I am agreeing with you on Point 1 (except I'm avoiding any discussion on the extent to which this might help attackers).  
Furthermore, by reducing orphaning risk, subchains reduce the "self-propagation advantage" that you're worried about in Points 2 and 3.  (I disagree that higher orphaning risk *causes* centralization but I do agree it is a centralizing factor).  
@_date: 2015-12-24 03:43:56
Agreed.  I didn't mean to focus on just more miners, rather more decentralization in general because the wealth of Bitcoin would be spread across a larger number of stake holders.  That being said, I suspect we'll also see a continuation in miner decentralization (has done lots of work on this) as adoption grows too (but that is not the most important effect IMO).  
@_date: 2015-12-22 19:37:48
Also, my latest work on subchains shows that by deploying weak blocks a significant portion of the fee revenue can be directed to proof-of-work.  This point is particularly important because investigators have previously argued that fees that result from orphaning risk do not contribute to network security.  This was in fact one of the argument put forth by small-block proponents for the need of a block size limit in the first place.  
  [Fig. 4, p. 6]
@_date: 2015-12-17 17:33:12
$2700 / BTC.  
Fingers crossed :D
@_date: 2015-12-30 18:26:44
OK, I think this is starting to make sense to me.  I agree with you and I agree with (thanks for pushing me on this BTW!).
Orphaning has a *real* cost for an individual miner (he paid for hashing power that went towards a block that didn't count).  However, from the aggregate perspective, since *some miner* claims both the fees and the block reward, orphaning doesn't have a real cost to the network as a whole--but only in a certain sense!  
In another sense it still has a sort of cost because--like you said--the effect of a high orphan rate, *ceteris paribus*, is to reduce network difficulty (the question of whether *this* reduces security is a separate topic that I'll avoid for now).  So a technique like subchains increases network difficulty in comparison to not using it.   
So I've learned something new!  My question now is whether this sentence from the abstract of my [subchains paper]( is still correct:
*"The use of subchains also diverts fee revenue towards network hash power rather than dripping it out of the system to pay for orphaned blocks"*
cc: @_date: 2015-06-21 18:28:57
That comment applies to the "high growth" curve.  If we indeed follow such a trajectory, we would bump into the blocksize limit near 2020.  Since we can't exceed the limit without another hardfork, it is reasonable to infer that price (fees) would increase to balance the reduced supply (blockspace).  
@_date: 2015-12-17 22:03:36
I can make you an [ugly log-log scatter plot]( for free, but a pretty one will cost you ;)
@_date: 2015-12-30 22:04:10
I don't think it does.
@_date: 2015-06-22 19:22:51
Yes, I just noticed this too.  Perhaps when the specs for the BIP are more finalized, I'll update the chart.  Thanks for pointing this out.
@_date: 2015-06-21 18:41:37
The same place the "moderate," "limited," and "failure" growth curves come from ;)
@_date: 2015-12-17 17:04:37
This is just a chart showing two time series plotted on the same set of axes.  
The correlation coefficient is 96%, by the way.  
@_date: 2015-12-27 03:15:58


But right now there are 40+ nodes running Bitcoin Unlimited that will accept &gt; 1 MB blocks TODAY.  Clearly not everyone has decided on the same thing, however the system still appears to be working.  
@_date: 2015-12-30 19:13:02


Read Sections 3 to 5 of my [subchains paper](  This problem is now solved.  Subchains reduce total risk, but they don't reduce marginal risk.  We *can* have it both ways.  


Because there are other decentralizing factors that balance these out.  The extent to which mining centralizes depends on all factor--not just a single factor.  
@_date: 2015-06-22 03:00:15
Try this link:
@_date: 2015-12-26 07:33:49
I believe it should be complementary to most proposals, the one exception being replace-by-fee.  I don't think replace-by-fee would work very well if subchains were implemented because subchains would make it harder to double-spend unconfirmed transactions.  
@_date: 2015-12-30 01:08:56




Well, I did write an entire paper to address this point you brought up, which involved inventing a technique to solve it (subchains) :-) .  Speaking of that, I should add you to my list of references.  Sorry for missing that. 
I need to be careful with my wording here: I agree that it is *significantly* better if total orphan risk cost &lt;&lt; total fee revenue for many reasons.  However, I'm not convinced that if orphan risk cost ~= total fee revenue that that would necessarily be a deal breaker.  For example, presently orphan risk cost is actually slightly greater than total fee revenue (more money is lost to orphans that earned in fees). 
@_date: 2015-12-28 23:08:14
Keep pushing You're having an effect.  
@_date: 2015-12-29 06:08:06


BU is not really a block size limit proposal so there's really nothing to gain support for.  Instead, it is a tool to achieve an emergent consensus--or an economic consensus--rather than a block size limit determined by Core's central planners.  BU is designed to co-exist with other proposals and other implementations...or in fact even to *implement* those proposals.  BU does not preclude miners coordinating block size limit agreements with each other to obtain the security that you suggest they want--in fact the very task that you undertook with your "census on consensus" is exactly the type of out-of-band negotiations that BU proponents imagine should unfold when negotiating changes to the protocol.  
Miners can certainly use BU as a tool to set their limits to whatever they want once they are confident with their choice.  
Bitcoin Unlimited helps nodes and miners realize their own power: the block size limit is a figment of our collective imagination.  BU reduces *friction* to coming to this realization.  We can set our own limit to whatever we want and we don't need to wait for anyone else.  Most importantly, we don't need to wait for the permission of the Core Central Planning Authority.   
cc: @_date: 2015-12-17 16:53:44
The two curves aren't actually adjusted at all.  They are plotted on the exact same set of axes--but the number of transactions per day is squared.  It's just a lucky coincidence that "one day" is the time interval that makes the curve line up.    
@_date: 2015-06-22 13:25:20
There are four future growth scenarios plotted: high growth, moderate, limited and failure.  What's wrong with exploring how various future scenarios might look?
@_date: 2015-06-22 02:46:03
The resolution of the image file is 2600 x 5000 and this seems to have caused problems on a few people's systems.  I tested it on my iPhone and laptop before posting and it looked great.  
I'm curious if this link looks better on your mobile:
@_date: 2015-06-03 07:57:45
Here's a plot shared a few weeks ago that illustrates differently when we may bump into the 1MB limit:
It's perhaps easier to visualize the exponential trend line using a log axis because it becomes a straight line.
@_date: 2015-06-21 23:48:25
Can you suggest additional information that should be displayed in the graphic?  
@_date: 2015-12-27 03:06:54
Bigger blocks are near!
@_date: 2015-12-30 01:24:54


True.  It seems no one knows exactly what will happen when the block reward runs out. 
@_date: 2015-12-18 01:14:16
Interestingly, Robert Metcalfe made the famous quote predicting that the Internet would collapse under its own weight because he didn't think it could scale.  
Sounds familiar...
@_date: 2015-12-23 23:27:36


False.  Bigger blocks cause *decentralization* as bigger blocks correlate with more users, more awareness and more support for Bitcoin.  


True, *ceteris paribus*, but technological progress *reduces* the cost to run a node.  


The idea is to keep the limit constantly above the free-market equilibrium block size: Q* &lt; Q_max.




FUD.  Non-upgrading nodes will no longer see valid blocks as difficulty will be too high.  But the node operator will realize something went wrong anyways, so this really isn't a concern.   
@_date: 2015-12-17 07:45:52
Including additional transactions increases the probability that the miner's block is orphaned.  This results in a *real* cost for miners to produce block space.  In other words, block space behaves like a normal economic commodity.  
Here is a research paper on the topic:
And here is the corresponding talk:
@_date: 2015-12-17 19:23:21
The linear correlation coefficient is 0.96 for log N^2 vs log MC.
@_date: 2015-12-29 20:20:39


No.  This is a new chart that analyzes the fee market when [subchains]( are employed.  
The key result is that even if miners build blocks until the marginal fee revenue is equal to the marginal orphaning risk, the *total* fee revenue is necessarily much greater than the *total* orphaning risk.  In other words, the notion that
     value of orphan risk cost = mining industry fee revenue
does not apply.  
@_date: 2015-06-21 23:47:03
Oh man, I read it over so many times!  I see that I also missed the "B" on "30 TB."
Thanks for pointing it out!
@_date: 2015-12-29 01:59:34
Have you developed a crush on me?  It seems like you've been following me around lately.  By the way, I wrote something nice about your Ork Master Saruman for CoinDesk (see 
@_date: 2015-12-30 01:33:24
Hmm...now that's *really* messing with my mind.  Let me think on that...
@_date: 2015-12-30 15:39:39


I disagree.  It does mean something. It means that people can raise their block size limit TODAY for what they are willing to accept and still track consensus.  The can proclaim to the world "I will attempt to accept your bigger block TODAY and I'm not waiting for permission from the Core Central Planners."
In my opinion, that is **not** nothing.  It is a very significant shift in understanding.  
@_date: 2015-12-22 04:54:17
Thank you for the attention, I'd like to take this opportunity to share my recent paper to help scale Bitcoin:
@_date: 2015-12-30 02:26:38
Exactly.  
@_date: 2015-12-26 21:19:23
Work to promote [decentralization of development]( add multiple protocol implementations (e.g., by supporting [Bitcoin Unlimited]( and increase the transactional capacity of the network and improve 0-conf security (e.g., by integrating [subchains](
@_date: 2015-12-29 00:08:15


But there are presently [70+ Bitcoin Unlimited nodes]( that will accept blocks bigger than 1 MB TODAY.  How do you explain that?
@_date: 2015-12-30 02:46:05


That's the important preface to the statement that's been missing for oh-so long.  Glad to see it finally make an appearance.  
@_date: 2015-12-17 16:46:44
Thank you for conceding that indeed the two curves are plotted on the *same* set of axes.
@_date: 2015-12-17 17:09:52
Thanks for the compliment!


Personally, I'm fascinated by why the two curves were historically so correlated in the first place.  I can't really explain any of it (the correlation or the divergence).  
Here's hoping the market price curve catches up! :D 
@_date: 2015-12-23 20:49:30


Yes, precisely.  It doesn't necessarily need to be done as a "charity" either.  As long as the marginal hashing cost for a nonzero fraction of the network hash power is zero or negative, then there I believe I could show that there would always exists moments when the block space supply cost approaches zero (in which case, a miner might include a TX even for a 1 satoshi fee).  
I believe a nonzero fraction of the hash power would *always* hash because (a) they might do so automatically as part of a hot water heater, etc., or (b) they might be located near nuclear power plants (or similar) and be designed to absorb the excess capacity when demand for electricity is low (in such a case, the power plant may even pay *you* to deal with the extra electricity).  
@_date: 2015-12-27 11:20:29


Yes, I would say that is a pretty good ELI5 that you just gave.  I might add that by doing this "mini-conf," the network is also able to reduce orphaning risk, so that it can process more transactions per second (assuming the block size limit were raised in conjunction).  
Here is a visual explanation of how they work that you might like, in case you haven't seen this yet:
@_date: 2015-12-17 16:49:31
Yes, that is what the data shows.  It will be interesting to see if the two curves begin to correlate strongly with each other again (as they have in the past), or if the historical relationship has already broken down.  
@_date: 2015-12-17 18:37:05
Hopefully one day.  What I'd like to do is create a series of graphs plotting all the relevant variables against each other, and create a "table of correlations" and another table estimating the power-law relationships between the variables.
Too many interesting things to work on...
@_date: 2015-12-29 00:26:41
And then the block would be orphaned.  Approximately 1% of blocks get orphaned every day anyways; so it's the same risk but vastly less likely to happen.  
@_date: 2015-12-30 15:07:24


That is one of my points!  We've empirical shown that BU nodes behave exactly like Core nodes under present conditions.  It might seem obvious to you, but to new users and less technical users, this was not obvious due to Blockstream FUD that "all nodes must enforce exactly the same rules." 


That will be another data point. 
BU nodes will track consensus regardless of the block sizes that get produced.  If the consensus stays with Core, then BU nodes will follow that chain.  If the consensus is for larger blocks, then BU will track the large-block blockchain.  
We've proven this empirically on testnet.  Hopefully we'll get our chance to prove this empirically on Main net very soon :)
@_date: 2015-12-24 18:32:15


There is no conspiracy.  
1.  Blockstream is a for-profit private company in the business of developing off-chain payment solutions.  
2. Blockstream and its employees use their influence over Core to ensure that blocks remain small.
3. Blockstream's off-chain solutions would see increased demand if blocks remain small.
There is no conspiracy; just a conflict of interest.  
@_date: 2015-06-22 00:30:05
Thanks for the suggestion.  I'm slowly (read: it may never be compete) working on another chart with this type of information, as well as cost projections for running a full node in the future.  
I elected to keep this graphic focussed on visualizing Gavin's code change, and four possible "growth" scenarios: high, moderate, limited, and failure.  
@_date: 2014-03-24 05:38:18
Investors are continuously diversifying as the price grows.  They did this on the growth spurt to $30 in 2011, on the growth spurt to $266 in spring 2011 and on the growth spurt to $1242.  They will do this again if we rise to $3000, more so should we rise to $10,000, and so on.  There does not come a specific "point" where everyone "cashes out at once."  Every day certain individuals are divesting (reallocating their capital).  
Who do you think is selling coins right now?
@_date: 2014-05-03 16:32:07
I think this proposal is perfect:  one million square bits forming a single round coin represents the fusion of our analog and digital worlds.  The unicode character 0x0180 which produces the symbol ƀ may keep the people who wanted to switch to Ƀ happy, without actually changing from ฿.  
"Bits" is a simple, easy-to-say word that is already a colloquial term for money.  And the parallel between money and bits (bytes) is even somewhat accurate.  When viewed from far enough away and from a physics perspective, money is often earned by creating information or removing entropy, and both information and entropy can be measured in bits.
@_date: 2014-02-03 02:17:17
Liquidity swap!
@_date: 2014-03-02 23:29:59
Wow, I didn't realize that.  Thanks for the tip.  
@_date: 2014-03-29 02:56:33
What a nice surprise to see my chart posted.  Thanks for linking back to the original source!
@_date: 2014-03-29 08:19:36
That's a good point.  If the network is more useful, I expect it to be used more often.  I actually think that transactions per day (excluding popular addresses) is thus a better proxy for the "N" in Metcalfe's Law than if we actually knew the true user base.  
A user that uses bitcoin a lot probably adds more value than a user that uses it only a little.
@_date: 2014-03-29 20:47:29
What gigavps said, and also the data was averaged on a weekly basis, which flattens out the spikes and dips.  This graph was produced very casually in the context of an active discussion on Risto's thread at bitcointalk.org.  If I had known that it would receive this much attention, I would have made it more "self explanatory."  (I wasn't the one who posted it here, although I am glad tacotacoman1 did.)  
@_date: 2014-03-29 18:08:13
Absolutely.  I'll try to make this more clear when I update these charts in the future. 
@_date: 2015-12-26 07:49:38


Probably some miners would.  The system would still function fine, however.
 


There is no financial benefit for them *not* to transmit their Δ-blocks, and actually a small financial benefit *to* transmit them (they can influence the contents of the next block by transmitting).  Cooperating to build subchains is thus a stable Nash equilibrium (no miner has a profitable deviation by *not* participating [unless he's trying to double-spend]).  


Indeed you can, but your revenue in expectation will be lower if you don't cooperate, because you will face higher orphaning risk.  I tried to estimate the costs of invalidating a transaction verified in a subchain in [Section 8]( (see Table 1, p. 11).
@_date: 2015-12-30 03:16:46
I don't see why not.  has lots of interesting ideas on this topic, such as full nodes getting paid to serve blockchain data to SPV nodes.  It's not something I'm particularly interested in researching, however. 
@_date: 2014-03-29 08:14:05
The chart is not really about causation.  It simply shows that bitcoin's market cap has obeyed Metcalfe's Law over the last 4 years and over 1,000,000% growth in price.  
Does price drive adoption?  Or does adoption drive price?  Probably a bit of both, but that is not really the point of this chart. 
@_date: 2014-03-16 01:28:32
I think this is the Sybil Attack you're referring to, but I'm no expert here either. 
I don't understand how bitcoin network security grows with the number of nodes but I'd like to know.  The 10k number comes as a shock to me, but only because I had 100k in my head.  Is 10k too low or more than enough?
My limited understanding is that as long as information can flow freely across the network, dishonest nodes can't inflict damage.  An attack is only damaging if a single node can be completely isolated by a Sybil attack (completely surrounded by dishonest peers), or a group of attacking nodes can split the network (the only connections between Honest Node Group A and Honest Node Group B are through colluding attackers).   
EDIT: thinking about this now, I understand why Jeff Garzik wants to put the bitcoin node on the cubesat in space. 
@_date: 2014-01-15 00:45:54
This message verifies to 1B8jvhGnSpY3BeSJRrdT54K16bHY5cgMn, which is not the address on youtube or on SkateSoft's signature.  You probably just signed it from the wrong address in your wallet (there are probably several address) or perhaps you didn't cut and paste it exactly.  If there is even one extra space somewhere it won't work.  
I will still honor the deal if you get it to verify to 1JUL1GKM8kjpiiYNoZjrmxkVS5bHmMWjZ5.
EDIT: you can check what it verifies to using the "verify" tab on brainwallet.org
@_date: 2014-01-14 14:51:21
Thanks for getting back to me. Yes, someone received tips on Reddit and someone received tips to  These may or may not be the same person.
We know "SkateSoft" posted the YouTube video and that his "tipping" address listed on the YouTube link matches that in SkateSoft's signature in the BitcoinTalk post. You could very easily prove that you are this same person by signing a message using the private key to this address.
You can easily sign a message using the Blockchain.info webwallet or   For example, this proves that I control the private key to 18AmW8Leih6sw2aARCCPG6bK5Ktbzdttta:  I signed "This is Peter__R" (no quotes) and got:  
Using brainwallet.org, you can check that my signature verfies to the address that I claimed to control.  
SkateSoft could have also proved that he was indeed the student in the video had the bitcoin address shown in the video matched his tipping address (but it didn't).
I actually believe you are honest, I'm just pointing out that using the "digital signature" ideas in bitcoin, you could prove that you are honest and you won't get people like me questioning you.
@_date: 2014-03-02 23:00:42
The tale is a mixture of fact and speculation.
We know that MtGox was hacked in June 2011, but we don't know that any bitcoins were taken.  
We know that Mark controlled at least 424,242 BTC after the hack, but we don't know how many he should of controlled.  
We know the price dropped to $2 in 2011, but we don't know that this was due to the hackers re-selling the stolen coins.  
We know that Willy was real, but we don't know for a fact that it belonged to Mark (although we do know that it was buying when the web and API interface were down last fall).
We don't know that he used customer funds, but we do know that MtGox is now short on fiat in addition to being short on bitcoin.  
We do know that Mt Gox's code did not properly deal with transaction malleability, but we don't know that this was done intentionally for the purposes of obfuscation.
If this article is popular, perhaps I can add references to more clearly distinguish between fact and speculation.  I spent several hours writing and editing this today and I wanted to put it out there  :)  
@_date: 2014-01-23 06:58:19
I wrote to T-Mobile a few weeks ago, explaining how as a Canadian traveling back and forth to the US, I would top-up my T-mobile SIM card even for short day trips if I could do it in 10 seconds with a single bitcoin payment. 
I described how the hassle of logging into my account (after resetting my password that I forgot) and paying by Visa (which always seems to take 10 min) could be avoided with bitcoin. If I have a T-Mobile SIM card in my mobile device and my bitcoin payment is good, then they don't need to authenticate me since credit-card fraud is no longer a risk.  
I never heard back, but perhaps I helped pave the way for you!
@_date: 2014-01-14 06:59:43
DadFoundMyAccount: could you clear up a few things?
1.  Are you "SkateSoft" who posted the same video on bitcointalk:  
2.  If so, why haven't the tipped coins moved from the donation address of  to the paper wallets?
  
EDIT: I wanted to point out that you could remove a lot of doubt over this entire saga if:
A.  The QR code shown in the video matched the donation address on youtube and at bitcointalk.
B.  You signed a message with the private key to this address and posted it in the comments to this thread.  This would prove that you are indeed the person who created the video.  
C.  We could all see by checking blockchain.info that you did move the tips you received to those paper wallets (but so far the funds haven't moved).   
@_date: 2014-01-14 15:56:52
Awesome.  I'll check back and give you a 25mBTC tip for learning about bitcoin-signed messages once you verify that you control 1JUL1GKM8kjpiiYNoZjrmxkVS5bHmMWjZ5. 
@_date: 2014-03-31 21:13:03
Is my adjusted basis for this new 2 BTC coin now ($400 + $800) / 2 = $600 per BTC ?
@_date: 2014-09-07 17:10:02
Wow, I wake up and see the video I posted to bitcointalk.org late last night has already been viewed 434 times.  I love r/bitcoin!
The pitch is that this device would act as a "second signer" for a multisig address that's part of your wallet.  Your phone (or computer) would create (and display) the transaction, sign it with its private key, and then request that you "tap" your sigSafe tag to produce the second signature (which is signed internally within the sigSafe tag and then relayed over NFC back to the phone).  This solution provides low-cost/simple *hardware* security by allowing the tag to piggyback off of the phone's screen.  The user would keep a paper back-up of the sigSafe's "seed" in case the device is lost.
White paper: 
Project development thread: 
Credit to:
- Bitcointalk member "Bonam" who generated the gerber files to produce the PCBs (and I paid him "internationally" using bitcoin).  
- My colleague Noah for producing the flashy diagrams (who also become a bitcoin user through this process :)
- Tom from Klinch for the name "sigsafe."
- And Gerald (DeathAndTaxes) for reviewing the white paper and offering several helpful suggestions to improve the device security and useability.  
@_date: 2014-01-15 18:33:50
I am interested in seeing this technology move forward.  It looks like solanoid_ might be a Reddit throwaway.  Are you on BitcoinTalk?  Would you be willing to PM me your email address?
@_date: 2014-03-31 19:36:44
"There is no minimum threshold for reporting taxable gains. It doesn't matter if your gain is $0.50 or $500,000. Gain is gain, and if you are required to file an income tax return, you need to report all of your gains."
What if you didn't make a gain?  Say you realized a $0.50 loss.  Are you still required to report this fact, or only if you want to offset gains?
@_date: 2014-03-27 23:04:12
This is not true.  BitPay must issue a 1099 to any merchant that it processed more than $600 of payments for.  
The only time the merchant cares about the identity of the customer is for purchases that have AML laws attached to them such as buying a car.  If you buy a car using bitcoin or bankwire, the dealership will file a report.  In no case does BitPay need to know the identity of the merchant's customer.  
@_date: 2014-03-29 03:28:10
Thanks for the credit, tacotacoman1.
@_date: 2014-11-03 01:50:10
Come on Chris, get with the program :)
$5 @_date: 2014-04-01 00:32:58
LOL, it sounds trivial I know.  But this question came up in our discussion about the ZGL accounting technique at bitcointalk.org.  The ZGL technique arranges your transactions so that you realize capital gains in lump sums through coins swaps.  It then arranges your day-to-day spending such that each purchase results in exactly zero gain or loss.
Hypothetical Question: If I bought a gold coin from Person A for exactly $1300.00 and a gold coin from Person B for $1000.00, melted both coins down and forged a new gold coin, and then sold this coin for exactly $2300.00, what should I do?
@_date: 2014-02-06 20:26:34
Jason, I'll throw in 0.05 BTC (~$40) for the winner.  
I think if you could clarify how we should donate, and make the total amount donated more transparent, it would encourage more to work on the videos and others to contribute additional bitcoins.  
@_date: 2014-02-08 20:15:45
I agree: you need to make the names of the people and their relation to bitcoin clear.  Remember this is for a non-bitcoin audience too.
Well done!  (I like how you still kept the one shot of the phone being destroyed)
@_date: 2014-09-07 16:49:30
A generic NFC tag acts more like a "secure EEPROM."  You could read-out a private key from such a tag, but the tag could *not* parse and sign a bitcoin transaction.
Sigsafe is different because the private keys never leave the device.  It actually produces the digital signatures internally.  
@_date: 2014-01-18 16:58:37
It is a mathematical fact that *all* the wealth in the world is eventually transferred from the older generation to the younger generation.  
Inheritance is *not* the only way this wealth transfer takes place.  If the younger generation's perception of value shifts--away from legacy financial assets and towards promising things like bitcoin--wealth is actually *sucked out* of paper money, over-leveraged bond funds, and dinosaur banks as if by magic.
@_date: 2014-09-08 19:59:31
What I demonstrated in the video was one of the alpha-models.  The answer to most your questions is "it depends on what people want."  
1.  Users will certainly be able to load their own keys.  This is critical to being able to audit the deterministic signatures it produces (to avoid the Android "repeat k-value" problem).  
2.  I think it has to become open source.  I've never been involved in an open-source initiative, so I'm still questioning how to proceed.  I'd like to "open source" it at a point where the code is fairly stable albeit simple, and there's at least one wallet implementing Sigsafe connectivity.  
3.  Right now, there's a default pubkey that is always readable, and, depending on the settings, the pubkeys/addresses corresponding to user-loaded privkeys can optionally be read.  But again, this behaviour is easy to change to suit the application.  
4.  Right now there's no way to access the private key at all, except by taking the chip to a lab and having someone wire bond to strategic points on the micro's die.  I'm thinking it's probably best that there's no way to read out the keys once they're loaded into EEPROM.  
@_date: 2014-01-13 19:21:35
I'm really glad to see you guys get this service running, Eric.  
I just signed up, added my credit card as a "bill pay," payed $20 towards it, and just received a confirmation email.  So far so good.  If this gets properly credited to my Visa account, I will continue to use the Bylls service to help support bitcoin innovation.  
One criticism: when I scanned the QR code to pay, it only picked up the bitcoin address.  I had to manually enter the amount.  Since Bylls already *knows* the amount, they should encode this into the QR code the same way that BitPay or Coinbase does.  
Lastly, for those complaining about their fees: this is a small company and they likely don't have investors with deep-pockets financing this effort.  I'm sure their fees will go down once they get up and running.  And, besides, bitcoin goes up and down 10% in a day.  Is a couple bucks or 1% really that much of a problem at this early stage in bitcoin? 
@_date: 2014-01-15 19:16:47
Double-spending "with a higher fee" is not a risk.  Nodes won't propagate transactions they recognize as double-spends and miners won't add them to their memory pool *even if* they are sent with a higher fee.  
Coinbase, BitPay, and the Vancouver Bitcoin Co-op's Coinos system all work fine at brick-and-mortar stores using zero-confirm transactions.  
I wrote a post here about how difficult it actually is to double-spend:
@_date: 2014-09-07 18:39:03
You've quoted an excerpt from the white paper related to "proof-of-intent" bonds. This has nothing to do with the primary function of the device, but rather how a manufacturer could "earn trust".
Here's the idea: why should you trust that a hardware wallet is not going to leak your private key? Well, what if the manufacturer loaded his own private key (that unlocks, e.g., 1 BTC) onto each device sold. The device would be configured to produce bitcoin-signed message only with this private key, proving to the user that the manufacturer trusts his own device (at least enough to risk the value of the proof-of-intent bond).
@_date: 2014-09-07 17:49:44
Thanks mulpacha!
Regarding the lack of a display, my "pitch" is that the device would act as a second signer for a multisig address on your phone (or computer).  So you'd see the transaction before you tap your tag to produce the second signature.  I suppose your wallet app could "go rogue" [and there are some potential solutions here too], but, like you pointed out, it requires a more sophisticated attack since one of the keys are permanently offline.
For brevity, I kept the video as simple as possible.  But through the NFC APDU interface, users can load their own private keys, set passwords, require cryptographic authentication from the wallet app (check an ECDSA signature), lock the "spend address", set per "tap" or daily spend limits (this requires the optional battery), etc.  I discuss this in more detail in the white paper. 
The challenge though is coming up with a simple "pitch" for how this could very easily be integrated with the popular wallets.  What's the simplest but still useful realization of this technology?  
My answer is "a second signer" for a multisig wallet.  Integrating this into existing apps should not be too difficult:
- To initially create the multisig address, the app would request the user tap his tag to the phone and the app would read the pubkey (which it would then use together with one of its own keys to create a P2SH multisig address).
- To transfer funds from the multisig address, upon user acknowledgement the wallet app would sign the TX, and then pass the TX to the sigSafe to get the second signature.  The user "taps" his tag to sign.
There's *lots* of additional cool things you could do later to improve both useability and security, but I think it's nice to start out with something very simple. 
@_date: 2014-01-11 01:12:47
I just downloaded the Wheely app: you can allow it to use your current location to hail the taxi, and then you can watch your taxi make its way towards you.  Paying with bitcoin is just the icing on the cake.  
Please come to Vancouver soon!
@_date: 2014-03-29 07:44:24
The dips in the green and brown lines are not real.  Remember when blockchain.info went down due to the database bug?  Ever since then, their charts have had "holes" in them.  The charts are still correct, but the spikes are not real.  I expect the fit to look even better once I remake these graphs after Mr. Cary is able to repair his charting engine.  
BTW, Blockchain.info has been a fantastic service to the bitcoin community!  Thank you very much Nic!
@_date: 2014-01-18 17:24:59
Only the debt that we as a society recognize as legitimate.  
Real assets like semiconductor fabs, the technology behind Google, and the real-estate in New York *must* be transferred to the younger generation *some how*.  
But *perception-based* things like debt or the value of paper money vs bitcoin are pliable: they were never real in the sense that the home where you live is real.  
@_date: 2014-03-31 20:17:06
Say I move 1 BTC purchased at $400 and 1 BTC purchased at $800 to a new address using a single transaction (2 inputs, 1 output).  If I don't trade or sell this coin, I just store it in my wallet and look at it sometimes, was this a taxable event?
@_date: 2014-09-08 04:32:47
Power is an issue, as the microcontroller clock speed is limited by the amount of current it can pull from the NFC antenna.  After a lot of work, it's now taking ~1.5 seconds to perform an elliptic curve multiplication. I'm confident this can be reduced to under 0.5 second with more engineering, and perhaps much further.  
I haven't delved into the details of BIP32 yet, but this should give you an "order of magnitude" idea regarding the energy cost of elliptic curve multiplications.  Hashing is of course very fast.  
@_date: 2014-03-28 04:10:05
Bitcoin is a new technology.  It has no political ideology.    
It is people who project their fears and dreams onto bitcoin.  Some dream of getting rich, and some dream of a future utopian world.  Some fear losing money or respect, while others fear increased surveillance via blockchain monitoring.  
Bitcoin doesn't give a fuck.  
@_date: 2014-01-25 06:09:25
It wasn't showing TigerDirect for me until I reset Firefox and VPN'd into Seattle.  Now it comes up just as the OP showed.  
@_date: 2014-03-29 03:06:51
I do believe we are witnessing the economic realization of Metcalfe's Law, but I agree that we must eventually diverge from V~N^2 growth to something milder.  That could still be a few years away, however.    
If you assume bitcoin adoption is at 0.1% of its long-term saturation level, this model would predict a price in today's dollars of ~$500,000,000 / BTC at full adoption.  This seems a few orders of magnitude too high for even the most ardent bull!
@_date: 2014-01-20 18:45:12
You also have to convince the nodes (power users).  Last time I checked there were about 250,000 of them.  
Users will not voluntarily debase their currency.  
@_date: 2014-02-06 22:16:19
0.05 BTC sent.
@_date: 2014-04-05 21:23:36
I just signed up for the tip bot, so I thought I'd test it out:
EDIT: what do you know, it works!
@_date: 2014-04-16 21:23:39
How exactly do you ship, flobin?  I find that packages sent via regular "airmail" post wiz through customs (into Canada) without a problem.  But even small items shipped via UPS or Fedex require phone calls and seemingly-random brokerage charges.  
@_date: 2014-01-23 07:31:54
Probably this thread has now gone dead, but yes it did work.  I actually made my second Bylls payment a few days ago.  
@_date: 2014-09-07 19:48:13
It's immune to key-loggers (e.g., when used with your computer).
It's immune to wallet.dat stealers (since your important private keys are offline).
It's resistant to attacks on the sigsafe supply chain or poor random seed selection (since the other seed is generated by an independent party).    
It's resistant to man-in-the-middle attacks (see below).
Regarding signing rogue TXs, I avoided too many details in the video (it's described in the white paper), but the device will only sign transactions authorized by its "signing rules." For example, the device can set "per tap" spend limits (or daily spend limits with the optional battery), verify an ECDSA signature (to reduce the threat of a MITM attack), check a PIN, etc.
Consider this scenario: My tag is configured to only sign up to 1 BTC "per tap." In the (IMO very) unlikely event that my wallet app "goes rogue" and remains undetected through several "day-to-day" transactions (even though it *could* just steal the online funds) until the moment that I'm about to transfer from my sigsafe, then modifies the TX in an undetected way, authenticates successfully with the sigSafe, and then I sign the rogue TX by tapping, the damage is sill limited to the per-tap spend limit. The attack must occur in the brief moment when your tag is in contact with the NFC reader and would be very difficult to execute.
There's no perfect security and there's certainly benefits to having a screen, buttons, etc. But we should also weigh probability of loss versus the cost and complexity of the security solution. I think a device like this is simple to use, low cost, and reduces the attack surface significantly.
That being said, I'd still like to make a more expensive version with a screen and capacitive touch sensor :)
@_date: 2014-09-15 21:20:34
NFC coupled with the payment protocol (BIP70) is probably the natural solution for bitcoin payments at brick-and-mortar shops.  The communication channel is two-way and large amounts of data can be transferred between devices (unlike QR codes).  This means that mobile devices can directly respond to payment requests that conform to BIP70.  In addition to being more intuitive (e.g., tap to pay), this is also helpful because:
- Rather than pushing a payment to the network over its own internet connection, the user's mobile device can deliver the TX to the merchant's terminal directly over NFC.  By rejecting (not broadcasting) TXs crafted to take advantage of mempool-acceptance heterogeneity, the merchant can reduce the risk of zero-confirm fraud.  
- By inspecting the X.509 certificate attached to the payment request, the user's mobile devices will eventually be able to show "Pay 5,240 bits to Starbucks Coffee" rather than the more cryptic "Pay 0.00524 BTC to 16c5JFDLCHK3eukrLYFcwmZtvCujSDfRBo."
- Devices without an internet connection or a power supply could still pay using the same BIP70+OpenNFC protocol (imagine a NFC version of Trezor).  
*I should note that, AFAIK, the NFC on the Schildbach wallet simply uses URIs to encode the payment request, such that the device making the payment broadcasts the TX to the network rather than passing the signed TX back over NFC.  This is not a criticism, as it's a necessary first step, I'm just pointing out that a lot of work could be done to streamline and standardize bitcoin payments over NFC.  
@_date: 2014-02-04 23:28:34
Hah.  I made a similar DNA analogy earlier today:
@_date: 2014-09-07 19:45:54
It's immune to key-loggers (e.g., when used with your computer).
It's immune to wallet.dat stealers (since your important private keys are offline).
It's resistant to attacks on the sigsafe supply chain or poor random seed selection (since the other seed is generated by an independent party).    
It's resistant to man-in-the-middle attacks (see below).
Regarding signing rogue TXs, I avoided too many details in the video (it's described in the white paper), but the device will only sign transactions authorized by its "signing rules." For example, the device can set "per tap" spend limits (or daily spend limits with the optional battery), verify an ECDSA signature (to reduce the threat of a MITM attack), check a PIN, etc.
Consider this scenario: My tag is configured to only sign up to 1 BTC "per tap." In the (IMO very) unlikely event that my wallet app "goes rogue" and remains undetected through several "day-to-day" transactions (even though it *could* just steal the online funds) until the moment that I'm about to transfer from my sigsafe, then modifies the TX in an undetected way, authenticates successfully with the sigSafe, and then I sign the rogue TX by tapping, the damage is sill limited to the per-tap spend limit. The attack must occur in the brief moment when your tag is in contact with the NFC reader and would be very difficult to execute.
There's no perfect security and there's certainly benefits to having a screen, buttons, etc. But we should also weigh probability of loss versus the cost and complexity of the security solution. I think a device like this is simple to use, low cost, and reduces the attack surface significantly.
That being said, I'd still like to make a more expensive version with a screen and capacitive touch sensor :)
@_date: 2014-01-15 17:41:35
This is a thing of beauty--so simple but exactly what we need.  
We have several brick-and-mortar stores in Vancouver accepting bitcoin.   These stores normally use an iPad or Android tablet and BitPay or The Bitcoin Coop's Coinos payment system.  The problem is that it is still awkward to grab the iPad from behind the counter, open the payment app, and have the customer scan the QR code.  We need a *single purpose* device like this that can just sit there on the counter always ready.
When do you expect to have these units available for sale?  Are you looking for beta testers?
@_date: 2014-02-03 02:31:56
Why would Argentina make it difficult to *export* (bringing hard currency into the country which they desperately need)?
I would purchase a few cases of good quality Argentine wine, thereby supporting bitcoin while helping the currency crisis in Argentina.  But it looks like it would also be very difficult to import this to Canada (even if you could get it out of Argentina).
If trade were truly free at the person-to-person level, we could really make great things happen.  Free trade but only for the big companies and only for certain things, I suppose. 
@_date: 2014-03-31 21:52:09
But they've become fused into a single coin.  There is no way to tell them apart any longer.  The IRS made no reference to LIFO or FIFO in their guidance, just that one should use fair market value and a reasonable and consistent accounting method.
EDIT: This article mentions that you can choose LIFO, FIFO, weighted average, or lot identification, as long as you are consistent, although it is not directly about bitcoin.
@_date: 2014-05-26 07:16:46
Like Walkas said, the device uses deterministic k-values, as per RFC6979.  What happened with the Android faulty random number generator is not possible with deterministic k-values.  
@_date: 2014-05-26 07:11:31
Interesting to see my project posted here.  I was going to keep it in semi-stealth mode until the alpha model was ready, but here's a sneak peak!
I have the NFC portion running using dev boards, and the design and layout for the alpha version is largely complete.  Alpha models should be constructed within ~6 weeks.  I want to take this device quite slowly, because I have additional plans for it, so I don't expect it will be out of beta until late 2014 or early 2015, assuming there's a demand for such a device.  
To correct one point above, yes the manufacturer would write *one* of the private keys to the device, however the user can write his own private keys to the device as well (and is not required to use the one that came with it).  I feel the device needs to come with a single pre-generated key so that it works "out of the box" for people that wouldn't be comfortable loading their own keys.  I think I have a very secure method to generate this key that I will discuss as development of this device moves forward.
@_date: 2014-03-27 23:46:57
The 1099 is issued by the person *paying*.  BitPay to merchant, or you to the guy you hired to build your garage.  
@_date: 2015-05-21 17:25:18
Haha so cool!  It really works!  Would you mind doing something more entertaining, though? :)
Some comments about the service:
1. I found it somewhat annoying that I had to input a return address for my change.  I paid with my phone very quickly by scanning the QR code, but then I had to dig up a valid bitcoin address and paste it into the text box in order to watch the stream.  At the risk of upsetting the never-reuse-an-address crowd, would it be possible to default to sending the change back to the address it came from if no return address is entered (or doing something else, just make it less work to get the stream playing)?
2. The service didn't work at all for me on Safari for some reason (worked on Firefox though).  
@_date: 2014-09-08 17:16:46
If you take a look at the circuit board at 2:20 in the video, you'll see there's two large solder pads.  These are for attaching a very thin battery that would last for several years and help expedite ECDSA operations if an application required it.  
But I think the best approach is to further optimize the most computation-intensive ECDSA operations.  There's peer-reviewed papers that indicate I should be able to make another order of magnitude improvement.  Email me (see white paper or end of video) if you'd like to discuss further.  
@_date: 2014-03-29 03:15:21
Metcalfe's Law states that V is *proportional* to N^2.  It says that if you double the number of users (adoption level), the value of the network increases by a factor of four.  The fact that the slopes on a log chart match up over 4 decades of price growth is what is remarkable.   
Since the terms V and N^2 have different units, it is not possible to plot them on a common "labeled scale".   Note that changing the "scale" on a log chart only shifts the curve up or down.  It doesn't change it's slope.  
@_date: 2014-01-15 01:14:48
You got it!
As promised I sent 25mBTC to 1JUL1GKM8kjpiiYNoZjrmxkVS5bHmMWjZ5
24.91mTC here:
and 0.09 mBTC here:
(I miscalculated the fees the first time when withdrawing from a service that deducts the fee from the total)
@_date: 2014-03-29 07:38:42
The plot simply shows that the bitcoin market cap does appear to be obeying Metcalfe's Law.  The dark black line is the bitcoin market cap in dollars.  The other two lines represent two different estimates of the bitcoin network's "Metcalfe Value" (V~N^2 ).  
N is the number of users in the network, but since we can't directly measure N, I used two separate proxies for N: the number of transactions per day (excluding popular addresses) and the number of unique addresses used per day.  They both seemed to fit the Metcalfe model quite accurately.  
@_date: 2015-05-21 18:35:05
I can't stop thinking about the possibilities with this technology...imagine an "ultra reality show": some interesting guy or girl _commits_ to wearing a headcam+audio for 1 month and streaming _everything_ live.  Let's call them the protagonist.  Word eventually gets out and more and more people start tuning in to watch segments of the live video (perhaps the protagonist announces interesting events in advance).  Suddenly, everyone's talking about this crazy ultra-reality video experiment.  The person ends up making a killing, bitcoin gets some attention, and a new genre of video is born!
@_date: 2015-05-09 20:28:50
Credit to Solex for the 1MBCON Advisory System Status:
and DeathAndTaxes for digging up the GitHub commits that introduced the blocksize limits:
@_date: 2014-09-14 20:43:09
Trezor is an important step forward in secure bitcoin storage.  It is a completely custom device (circuit board, firmware, plastic enclosure) that represents a great deal of engineering development.  $119 is a very good price for this level of technology and innovation, given the lower volume levels that our small market supports.  And you're not just paying for the hardware, you're also paying for the trust and goodwill that Satoshi Labs has earned.  Would you really want to secure your bitcoins using some cheap knock-off?
As adoption grows and manufacturing can be scaled-up to higher volumes, then expect this tech to become cheaper and more sophisticated.  Instead of complaining, let's work together to make that happen.  
@_date: 2016-01-07 17:55:33


Thank you to the Core team for addressing this important point!  Indeed, the [evolution of the network is decided by the code people freely choose to run]( 
Paging does this mean we're now permitted to discuss the benefits of alternative implementations such as [BitcoinUnlimited](
@_date: 2016-01-08 23:16:11


Core is only one implementation of the Bitcoin protocol (albeit presently the most popular one).
@_date: 2015-08-15 21:58:26
Transparency of communication.  
@_date: 2015-08-25 03:00:54
Is it feasible for a miner (or a node) to simultaneously show support for BIP100 *and* BIP101?  The idea would be that whichever proposal is ratified first is the one that gets activated in the software.  
@_date: 2015-08-04 07:31:58
The paper estimates the cost that this bad actor would have to pay the miner to create such a spam block.  Refer to Section 9 and Fig. 8 in particular.
@_date: 2015-08-04 23:00:52
@_date: 2015-08-04 11:44:27
Great catch!  $10 sent:
@_date: 2015-08-04 12:12:37
Yes, a believe that is unquestionably a grammar error. $10 more sent:
@_date: 2015-08-16 15:48:26
I agree that miners will tend to act rationally to maximize their profits.  And a healthy fee market is, in fact, the expected outcome of rational miner behaviour, if block size is unconstrained by the protocol (and notwithstanding the assumptions stated explicitly in Section 10 of the linked paper).
@_date: 2015-08-05 21:07:18
Wow, thanks for the great tip!
@_date: 2015-08-16 15:41:38
Instead of viewing orphaned blocks as a negative, why not view them as a natural constraint against blocks that are too large?  This paper shows how the fact that orphaning is possible serves to create a healthy transaction fee market:
@_date: 2015-08-27 17:28:38
That makes sense.  To help make sense of that number, I just did a quick check and that seems less likely than the chance the network hash power could find a SHA256 collision with a probability of 0.01%:
   400x10^15 hash/sec * *t* = 0.0001*2^256
Solving for *t* yields
   *t* -&gt; 2.9 x 10^55 sec
     -&gt; 9.4 x 10^47 years
@_date: 2015-08-04 12:15:15
Thanks. I think I will rule this as "awkward" but not an error.
@_date: 2015-08-27 17:50:07


This is not true according to the original design of Bitcoin (although it is true for the specific implementation called Core).  There is no mention of a block size limit in the Bitcoin white paper.  The original design was such that (paraphrased):
- Nodes assemble valid transactions into a block and work to find a proof-of-work.
- Nodes express their acceptance of a new block by mining on top of it.
- The longest chain composed of valid transactions is "Bitcoin."  
Here's the description straight from the horse's mouth:
The longest chain composed of valid transactions *is* the correct one, according to the Satoshi white paper.  If BIP101 becomes the longest chain, it will be Bitcoin by definition.  By making it easier for nodes to "express their acceptance of a block" (e.g., for blocks larger than 1 MB via BIP101), we are making it easier for the network to come to consensus according to the original design of Bitcoin.
@_date: 2015-08-27 17:00:42
Nice work, oreganoofcorti!
Am I correct that your calculations prove that with 750 of the last 1000 blocks supporting BIP101, that the probability of BIP101 *not* becoming the longest chain (due to variance) is effectively zero?  
@_date: 2015-08-04 13:48:19
Do you then agree that "A Transaction Fee Market Exists Without a Block Size Limit"?
I've noticed you post links to the paper by Nicolas Houy (which is a useful paper, btw!) in the past in defence of a block size limit to enforce a fee market. My paper refutes the idea that a miner would "[include] all transactions whatever the fee attached."  It explains that his conclusion that either a minimum fee or a limited block size is required does not hold when one considers orphaning.
@_date: 2015-08-04 09:42:59
Thanks for the feedback.  I'm going to have to get a second opinion on whether this is an error or whether this is a stylistic decision.  
@_date: 2015-08-10 05:28:32
Right, he could do this.  And then he'd have a higher probability of having his block orphaned and losing the block reward.  This has a cost associated with it, which is described by Eq. (11) and illustrated in Fig. 8.   
@_date: 2015-08-10 05:06:20


I addressed this in Section 9 (Cost of a Spam Attack).  The results apply whether the attacker is the miner or not.
@_date: 2015-08-04 11:39:15
Haha I didn't know there was a difference between innumerate and enumerate!  $10 sent:
(I think saintoshi beat you with the typo on page 2).  
@_date: 2015-08-04 11:36:40
Awesome!  Good catch.  $10 sent:
@_date: 2015-08-05 22:27:05
The paper argues that block propagation is O(N) was N is the amount of information in the block.  Larger blocks contain (typically) more information and thus take longer to communicate to peers.  This applies whether the blocks are compressed or not (wav files are bigger than mp3 but two mp3 songs are of course bigger than 1 mp3 song).
 Does this not seem intuitive?
@_date: 2015-08-04 06:21:15
I’d like to share a research paper I’ve recently completed titled “A Transaction Fee Market Exists Without a Block Size Limit.”   In addition to presenting some useful charts such as the cost to produce large spam blocks, I think the paper convincingly demonstrates that due to the orphaning cost, a block size limit is not necessary to ensure a functioning fee market.  
The paper does not argue that a block size limit is unnecessary in general, and in fact brings up questions related to mining cartels and the size of the UTXO set.   
It can be downloaded in PDF format here:
Or viewed with a web-browser here:
**Abstract.**  This paper shows how a rational Bitcoin miner should select transactions from his node’s mempool, when creating a new block, in order to maximize his profit in the absence of a block size limit. To show this, the paper introduces the *block space supply curve* and the *mempool demand curve*.  The former describes the cost for a miner to supply block space by accounting for orphaning risk.  The latter represents the fees offered by the transactions in mempool, and is expressed versus the minimum block size required to claim a given portion of the fees.  The paper explains how the supply and demand curves from classical economics are related to the derivatives of these two curves, and proves that producing the quantity of block space indicated by their intersection point maximizes the miner’s profit.  The paper then shows that an unhealthy fee market—where miners are incentivized to produce arbitrarily large blocks—cannot exist since it requires communicating information at an arbitrarily fast rate.  The paper concludes by considering the conditions under which a rational miner would produce big, small or empty blocks, and by estimating the cost of a spam attack.  
[$10 BOUNTIES] Find an error in the PDF manuscript (excluding end notes), report it by responding to this comment along with your bitcoin address and receive $10!!  Your comment must be UNEDITED so that I can reasonably trust the time stamps.  Errors include spelling and grammar mistakes, typesetting issues, mis-numbered equations, typos, etc.  Suggestions are appreciated but do not qualify for a bounty.  I reserve final say regarding what does and does not qualify for a bounty.   (And yes I know my pi variable is sometimes in italics due to a bug in Word.)
UPDATE: I will be without Internet for several hours and will award further bounties when I return.  Thanks everyone for their feedback!! Moving forward now, I'm mostly interested in clear errors like missing or repeated words, clear spelling mistakes, wrong verb tense, etc, than I am with grammar nuance.
@_date: 2015-08-04 14:40:52
Yes, thank you for the detailed feedback! I've sent a $10 bounty your way for the error related to "maximum":
@_date: 2015-08-04 08:08:07
Thanks for the comment.  I'm going to rule this as a "stylistic decision" rather than an error.  I find always writing "his or her" disrupts from the flow of the prose.   
@_date: 2015-08-15 17:32:07
Congratulations Gavin and Mike on completing the patch to support larger block sizes. Although we all have ideological disagreements from time to time, two fundamental values of the Bitcoin community are freedom of choice and transparency of communication. Your work represents a big step in returning the power over Bitcoin's future back to the community where it belongs. 
@_date: 2015-08-29 19:32:25
Sorry.  I was referring to my paper making that assumption.  Your paper helps move beyond that assumption.  
@_date: 2015-08-27 23:14:59
I think we're in agreement.  
Like Harda mentioned, "any needed rules and incentives can be enforced with this consensus mechanism."  The consensus mechanism is the idea that miner's express their acceptance of a block by mining on top of it and that the longest (persistent) chain is the correct one.  If that becomes a chain that includes larger blocks and all the miners move there…well that's just Bitcoin's consensus mechanism playing out as designed!  
@_date: 2015-08-04 07:23:09
Hmm, that was actually intentional.  My grammar expert thinks I should have rephrased that sentence however, so I will pay out in good faith.  
@_date: 2015-08-26 19:17:21
And I wrote the paper from the sidelines while wearing my beer hat.
@_date: 2015-08-05 05:54:07
That's an interesting point.  I have been purposely making it a single word for several reasons: (1) it makes sense to think of it as one sort of "thing" and thus one word is appropriate, (2) using a single word seems to be the common usage now, and (3) it allows me to capitalize the b in "the Blockchain" when I'm specifically referring to Bitcoin's blockchain.  
@_date: 2015-08-29 23:47:08


This is not true.  Although a miner may begin mining on just the header while he works to receive/validate the full block, if--in the meantime--he fully receives and validates a small block, he will then orphan the larger block.  He does this because it is better to build upon a block that you are 100% sure is valid.
The results of the papers still apply. 
@_date: 2015-08-26 17:35:27
Adam is wrong that "fees will drop to basically zero" if the limit is increased from 1 MB to 8 MB.  In addition to empirical evidence that shows this is not the case (e.g., fees existed when the average block size was much smaller than today), this paper shows that a transaction fee market would exist even in the *absence of a block size limit*:
If the block size is not constrained by the protocol, then the fee per kilobyte is governed largely by the orphan cost.  The orphan cost is a function of the propagation impedance for block solutions.  Raising the block size limit does not affect the propagation impedance.  Fees per kilobyte would be largely unchanged; however, since more kilobytes of transactions could be included in a block, the *total* fees per block could grow higher.  
As the average block size grows, so would the total fees collected by miners, assuming the network propagation impedance remains constant.  
@_date: 2015-08-04 13:57:04
I agree!
@_date: 2015-08-05 05:55:23
Thanks for pointing this error out! Unfortunately, it doesn't qualify for a bounty because the OP read "Find an error in the PDF manuscript (excluding end notes)." The end notes weren't reviewed to the same level of detail as the main body, so I wanted to exclude bounties here.
@_date: 2015-08-05 13:13:38
Awesome work dpinna!  I was planning to look into the same thing when I board my train in a few hours...I'll let you know if I get the same results as you.
Two notes for posterity (not directed at you, just of general interest to readers):
1.  It was David Hudson who originally pointed out this objection (and did so politely and constructively).
2.  The original construction for Eq. (5) can still interpreted as valid (although perhaps less useful than with your modifications)--like you suggested, you'd associate a small propagation impedance between your own hash power and a larger impedance to the rest of the network.  I had actually tried to make this more formal in an unpublished Appendix B, but decided that topic was better suited for a follow-up paper.  However, I'm now thinking that perhaps David Hudson's adjustment to my formulation and your modification here is more useful.  (It's a lot simpler than what I was trying to do which was work with a huge matrix that referenced the propagation impedance between the i_th and the j_th segment of network hash power).  
@_date: 2015-08-04 09:41:25
Good catch!  $10 sent:
@_date: 2015-08-04 08:15:47
Thanks for the suggestion.  I had the same thought as well.  Perhaps I will re-structure the abstract in a future revision.  
@_date: 2015-08-27 23:45:44


Good. Then we both agree that the white paper did refer to the number of coins being limited.


Since the white paper mentioned that
*"Any needed rules and incentives can be enforced with this consensus mechanism"*
it allows for a lot of flexibility.  I'm not saying that "there can be no block size limit."  What I am saying is that the consensus mechanism that the white paper refers to is the idea that miner's express their acceptance of a block by mining on top of it and that the longest (persistent) chain is the correct one.  If that becomes a chain that includes larger blocks…well that's just Bitcoin's consensus mechanism playing out as designed!
@_date: 2015-08-27 23:21:24


Bitcoin white paper, page 4, paragraph 3:
*"Once a predetermined number of coins have entered circulation, the incentive can transition entirely to transaction fees and be completely inflation free"*
Satoshi *did* refer to the number of coins being limited.  
@_date: 2015-08-16 18:34:23
I agree.  I believe we're saying the same thing.  What block size will be accepted by the network is a calculation each mining node must make before it begins mining on top of a large block.  This is part of the feedback mechanism that enforces an *effective* block size limit even in the absence of a protocol-defined limit.
@_date: 2015-08-04 08:17:38
Good point!  
@_date: 2015-08-25 03:07:48
This is my understanding as well.  For miners that are indifferent to BIP101 vs BIP100, this might be a reasonable thing to do as it would expedite the consensus process. 
@_date: 2015-08-05 21:09:21
Yes, I agree.  I think Dave Hudson's objection is the most valid criticism of the work.  I suspect we can address this rigorously without affecting the main claims of the paper.  But I'm not there yet.  
@_date: 2015-08-15 17:30:01
Congratulations Gavin and Mike on completing the patch to support larger block sizes.  Although we all have ideological disagreements from time to time, two fundamental values of the Bitcoin community are freedom of choice and transparency of communication.  Your work represents a big step in returning the power over Bitcoin's future back to the community where it belongs. 
@_date: 2015-08-25 03:14:45
Only one of the proposals would get activated. However, prior to the activation date, I'm suggesting that indifferent miners could express their support of both.  Just an idea...
@_date: 2015-08-10 02:27:37
I think the analogy to the Fed's FOMC is fairly accurate.  Part of the ideology behind central banking is that a group of educated men can make better decisions for what is best for the economy (by choosing the interest rate that balances "inflation expectations" with "employment") than allowing the free market to solve the same problem.  
This is similar to the block size debate.  Part of the ideology behind limiting the block size is that a group of talented coders can make better decisions for what is best for Bitcoin, by choosing a limit that produces what they see as a better balance between "decentralization" and "blockchain access," than what would happen if the limit were slowly removed according to Gavin's BIP101 proposal.     
Isn't this what the debate really comes down to now?   The technical debate is over; It's ideology at this point.  Do we want a Bitcoin that has a dual mandate of balancing decentralization with blockchain access?  Or do we want a permissionless Bitcoin where blockspace is governed by the fee market?   
@_date: 2015-07-09 02:22:20
I agree.  I know Greg Maxwell and many others have suggested similar ideas in the past.  
Why can't this be added as part of the isStandard() test?  Scale the min relay fee by a variable that is &gt; 1 if the TX increases the UTXO set and &lt; 1 if otherwise.  
@_date: 2015-08-29 19:12:04
Correct me if I'm wrong but I believe:
1.  It builds on this paper [here]( which shows that a transaction fee market exists without a block size limit. 
2.  It addresses Dave Hudson's criticism of the paper linked above^1 that miner's "don't orphan their own blocks."  It does this by making the propagation impedance a function of the ratio of the miner's hash rate, *h*, to the total network hash rate, *H*.   
3.  It shows that although miner's with a large portion of the network hash rate have an advantage over small miners, this advantage *decreases* as the block reward drops or as total fees increases. 
This is important because it shows the second-order concern brought up by Dave Hudson regarding the health of the fee market (in the absence of a block size limit) actually gets reduced (a) if blocks become bigger and include more fees in total, and (b) as time progresses and the block reward becomes less important.  
 ^1 To make the math tractable, the paper above made the simplifying assumption that the chance a miner mined two blocks in a row was small enough to ignore. 
@_date: 2015-08-04 10:07:59
Thanks for pointing this out!  Unfortunately, it doesn't qualify for a bounty because the OP read "Find an error in the PDF manuscript (excluding end notes)."  The end notes weren't reviewed to the same level of detail as the main body, so I wanted to exclude bounties here.
@_date: 2015-08-13 04:53:02
This is correct.  The probability of orphaning a block is approximately equal to block's size multiplied by the network's propagation impedance.  If blocks become twice the size but the network becomes twice as efficient at propagating them, then the net effect on the orphan rate is nil.  
There's more on this here: 
@_date: 2015-08-04 14:14:07
Thank you for all of your comments and reading my paper in such detail!  I agree that the "maximum" issue was a grammar error and I've awarded you $10:
I appreciate the other comments but I believe they fall more in the category of style, and some words ("expectation value" and "versus") I am using in a technical sense.
@_date: 2015-07-04 22:49:21
I am the author of that post.  I wanted to say that although I'm excited by that result, it should be taken with a grain of salt.  It was derived from a simplified model that doesn't take into account all the messy details of the real world.  
@_date: 2015-08-13 03:10:57
Now it looks like your test post has been hidden too!  
@_date: 2015-07-02 21:33:51
I agree with some of what you just said and I agree that the adjective "very" in that quote is misleading (I included his quote to help discern a well-formed TX from a TX with poor network propagation, incorrect fees, or unconfirmed inputs).  
My words were:
"A well-formed transaction without any confirmation will be mined into a block with a probability P, which can be estimated empirically by payment providers based on network heuristics."
"Like they do now, vendors will continue to choose the level of security required for their use case (0-conf, 1-conf, etc), evaluating risk based on network heuristics."
@_date: 2015-07-02 16:47:57
He seems to make two points:
1.  Because transactions will more frequently become stuck as a result of fee pressure from the 1 MB limit, replace-by-fee (RBF) is necessary to unstick them. 
2.  Because zero-confirm transactions aren't completely secure, let's make them completely _insecure_ (e.g., by deploying full-RBF rather than first-seen-safe RBF or child-pays-parent).   
I don't understand this.  Why purposely make 0-conf less secure?  How about, instead, we keep this system that many people enjoy working?  Like they do now, vendors will continue to choose the level of security required for their use case (0-conf, 1-conf, etc), evaluating risk based on network heuristics.
@_date: 2015-07-01 22:47:04
This is ambitious, but what I would LOVE is to be able to pay for parking with Bitcoin.  I frequently run out of change for the meter, pay terminals with credit card readers are often broken, and I find the various parking apps for phones cumbersome and intrusive.  
Each stall could have a QR code with a price/hour to park listed.  You simply pay the address for however long you want and walk away.  If you decide you need more parking, you just send the same address a top-up payment.  There'd be an optional app that gives more information, but for travelers who don't want to download an app for each city, they just send the QR code a few bits as easily as dropping coins into a vending machine.  
Meter checkers would just use an app that scans the blockchain for the last payment to each stall, and issue tickets if payments were expired.  
*Better yet: make it a payment channel that you close when you return to your car and drive away.  Never run out of time again!
@_date: 2015-08-04 14:21:14
Thanks for going through the manuscript with a fine-toothed comb! I'm awarding you $10 for the grammar error in the Fig. 1 caption. The others I think are not clear errors and, for example, my use of "expectation value" is technical.
@_date: 2015-08-09 19:29:17
**Central banking**: the idea that a group of educated men can control the money supply better than the free market.  
**Central (core) deving**: the idea that a group of talented coders can control the block space supply better than the fee market:
@_date: 2015-07-01 05:01:40
If you look really close on the right side, about half way up, you can just make out the letters "Bount..."  I think it's a Bounty Select-A-Size paper towel :)
@_date: 2015-07-02 21:37:25


I don't disagree.  What I'm saying is that there's a certain risk to accepting a 0-conf payment.  This risk can be evaluated by merchants or payment processors.  If the risk is acceptable for a merchant's business model, then they should accept 0-confirm transactions.  If not, then they shouldn't.  
@_date: 2015-07-02 21:17:15




Quoting rocks from BCT:
"well-formed transactions (i.e. transactions where all inputs are already confirmed, include an appropriate fee, and which are accepted by all your P2P peers [meaning you did not receive any alternative broadcasts using the same inputs]) are very secure with today's P2P rules and easy to accept for nominal amounts."


If the merchant or payment provider estimates the probability that the payment will be mined into a block to be exactly zero, then obviously he should not accept it.  
@_date: 2015-07-05 00:15:22
Please don't attribute words to me that I didn't say.  Where did I state in my post that "we don't need a blocksize limit"?
For the record, I support Gavin's plan to double the limit every two years, after a jump to 8 MB.  
@_date: 2015-08-27 18:46:07


I agree.  And if we need to increase the block size limit, and if a BIP101 chain becomes longest, then that is an example of this consensus mechanism playing out.  
What exactly are you disagreeing with?
@_date: 2015-08-29 23:48:56


This is the point of contention that dpinna's paper tried to addressed.  claims to have shown that although miners with a large portion of the network hash rate have an advantage over small miners, this advantage decreases as the block reward drops or as total fees increase.
@_date: 2015-07-01 03:52:24
Yes, a fork to raise the limit.  Gavin is working on it.  
@_date: 2015-08-16 18:16:38
Right.  Furthermore, we should capitalize the word "Core" because that is the name given to one implementation of the Bitcoin protocol (albeit the most popular implementation at the moment).  Like Noosterdam has pointed out before, referring to it as "core" (lower case) could unintentionally imply that it is somehow the permanent core of Bitcoin.  
@_date: 2015-07-05 07:10:57
Good catch!  I'll correct it.  Thank you. 
@_date: 2015-08-05 05:56:24
Thanks! However, I'm going to rule this as a stylistic decision rather than an error.
@_date: 2015-07-02 21:02:15




Perhaps your _definition_ is the source of your cognitive dissonance.  
By _reality_, a well-formed transaction without any confirmation will be mined into a block with a probability _P_, which can be estimated empirically by payment providers based on network heuristics.    
Relying on your made-up definition to change how things _should_ be treated is, to use your own words, the "stupidest possible [thing] you could possibly devise."
@_date: 2015-08-15 22:22:57
@_date: 2015-07-05 00:57:02


Agreed.  It is a simplified model so that the effect can be easily isolated and understood.  It would be interesting to try to model a distribution of verification times, among other details.  In any case, I suspect the important result will be the same. 
@_date: 2015-07-05 00:25:26
Thanks for the thoughtful reply.  
The analysis only considers the upper-bound for blockchain growth / effective blocksize, given the stated assumptions.  Like you point out, miners are free to choose any value for S, and won't necessarily pick S'.  The point is that if they pick any other value, then the blockchain will grow *slower* than the upper limit.  
Jorge, seems like your slowly coming around to the good side ;)
@_date: 2015-07-05 01:40:29


This is the type of comment that makes me not want to post in this community.  This morning, based on Cypherdoc's use of the term "defensive blocks," I realized that, due to these empty blocks becoming more prevalent at larger blocksizes, that I could show with a simple analytical model that the network capacity would be bounded.  I spent the morning preparing that post and was excited to share it and get feedback from others.
Noosterdam must have thought it deserved more widespread coverage and posted it here to r/bitcoin.  
I then **immediately** came here and posted a warning, which, because the readers of Reddit are very sensible, was upvoted to the top comment.  I completely agree this is a simplified model.  I believe it is useful in its simplicity.
You know, I've been on your side in private conversations where people are questioning your motives.  But with a spiteful reply like this, I'm beginning to think u/raisethelimit was right:
@_date: 2015-07-01 06:30:35
Maybe they're just...sleeping?  :(
@_date: 2015-07-03 00:13:52


No one is claiming that.  "Secure" and "insecure" are not absolute adjectives.  Something can be more secure or less secure than something else, for example:
   0-conf (+ full-RBF)   &lt;   0-conf (as is)   &lt;  1-conf   &lt;   2-conf …
Where the symbol [ &lt; ] means "less secure than."  It is up to the recipient to choose the level of security required for the exchange, based on network heuristics like the current card companies do.
What is the benefit of purposely making 0-conf less secure?
@_date: 2015-07-09 17:01:26
100 milliwatts!  Look out!!  :D
@_date: 2015-07-04 23:55:19
I think we're trying to say the same thing.
@_date: 2015-07-04 22:52:53
The incident was not caused by SPV mining *for the few moments it takes to validate the latest block.*  It was caused by F2Pool (and AntPool) never getting around to actually validating the blocks.  
Attempting to mine empty SPV blocks during the time it takes to verify the previous block increases the miners revenue, as shown here: 
@_date: 2015-09-15 12:06:03
# Ledger: Call for Papers | 2015 September 15 #
 ledgerjournal.org 
**The journal *Ledger* invites authors to submit their original research for the inaugural issue of the very first peer-reviewed academic publication devoted solely to the field of cryptocurrencies and its related subtopics.** This nascent field of research is highly interdisciplinary, sitting at the intersection of computer science, cryptography, economics, engineering, finance, law, mathematics, and politics. Due to its novelty and wide-ranging nature, cryptocurrency studies have not sat comfortably in any traditional journal, and it is thus our aim to create the first purpose-built vehicle for the leading research in the field. We welcome papers of up to four thousand words detailing new ideas and perspectives on any relevant topic, including but not limited to the technical, social, economic, and philosophical developments and implications of Bitcoin, cryptocurrencies, public and decentralized ledgers, distributed consensus, and more. Interested authors should consult the [submissions and policies sections on the *Ledger* website]( for more details on our focus and scope, submission methods, transparent peer-review process, [author guidelines]( and open-access policy. The deadline for submissions for the inaugural issue is 31 December 2015, but we will consider submissions after that date for subsequent issues on an ongoing basis. We welcome inquiries by e-mail at ledger
*Ledger* is the first peer-reviewed journal devoted to the inherently interdisciplinary subject of cryptocurrencies, and is proud to be supported by its [distinguished editorial board]( It is published quarterly by the [University Library System, University of Pittsburgh]( as an open-access journal and does not charge author fees. *Ledger* timestamps all published articles in the Bitcoin blockchain, and encourages authors to digitally sign their manuscripts. For further information please visit [ledgerjournal.org](
@_date: 2015-09-11 14:38:21


Why not?  I think you're imagining changes to the consensus critical code when you express your concern--these types of changes will be *very* rare.  In fact, I'd expect all implementations to use essentially the same consensus library.  
Changes to other features--like p2p messages--can be done without the same level of rigor.  
@_date: 2015-09-12 20:27:22


I actually take that into account.  Even if you assume that the intra-pool propagation impedance is zero, it still doesn't affect the health of the fee market *unless only one pool exists* (in which case there is no one to lose an block race to).  
Here's the slide: 
@_date: 2015-09-13 04:28:53
No it doesn't.  The rules of TCP/IP obey the laws of physics, not the other way around.  According to the laws of physics, I've shown that the fee market exists provided (1) Bitcoin's inflation rate is nonzero, and (2) more than one miner or mining pool exists.  
Empirical orphan data for the network *right now* also backs my claims.  
@_date: 2015-04-30 22:07:14
PM sent.
@_date: 2015-04-30 16:21:56
(Off-topic indeed) Thanks for the interest. It's difficult to identify how a business based around inexpensive niche hardware like Sigsafe can be made profitable.  Anyways, we're applying for NRC-IRAP funding (Canada) and if that's awarded we'll do _something_.  I know there was interest for Sigsafe "as is" but I didn't want to market a product only "half-way-done" before nailing the UI and security. 
PM me at BCT if you'd like to discuss further. 
@_date: 2015-04-30 15:20:41
Quote taken from: 
Credit to Smooth from BCT for pointing it out.  
@_date: 2015-04-30 18:35:27
It is linear with area.  
@_date: 2015-09-11 14:00:42
What about consensus rule changes that kick in--like BIP101 does--only when it's clear that the majority of the hash power will support the change?  Seems like a good way to make changes! The other nodes then need to get inline or be left behind!
@_date: 2015-09-22 15:17:53
We've been thrilled with the community's reception to [*Ledger*](  In less than a week, we've had over one hundred and sixty individuals register as authors and readers, and we've already received five submissions. 
The purpose of this post is twofold:
1. To make the community aware of *Ledger*'s Author Guidelines. 
2. To solicit input from the community regarding these guidelines.
*Ledger* has a difficult job.  On the one hand, it is important that its published content be of a high scholarly quality for both the journal's sake and for the legitimacy of cryptocurrency as a new field of research.  On the other hand, we want to encourage submissions from a broad spectrum of disciplines and from knowledgeable individuals both in academia and industry, each of whom may have significantly different views on how an article should be written. 
The linked paper "How to Write and Format an Article for *Ledger*" is our first attempt at communicating the journal's expectations for articles.  It is formatted based on the stylistic requirements of the journal, and thus also serves as a useful example to which prospective authors can refer. 
To encourage people to read these guidelines, I am also offering $10 bounties for errors found. To qualify for a bounty, **you must NOT respond to this comment but rather to the comment by LEDGERTHROWAWAY1 in the cross-posted thread in the [REDACTED] subreddit**. (I tried to provide a link but it appears to get [REDACTED])
@_date: 2015-09-20 19:58:17
I've noticed the same "arguing from both sides" too.  For example, in regards to a fee market driven by orphaning costs, I've seen the same individual claim that (a) the orphan rate is too high to permit larger blocks, and (b) the orphan rate is too low to drive a fee market.  How can it simultaneously be too high and too low?  The reality is that orphaning acts as a natural constraint against large blocks.  If network connectivity improves, then it will become more cost-effective for miners to produce larger blocks; if not, the miners will continue building small blocks.  Either way, an equilibrium will be maintained (just like it's been maintained for the past 6 years).  
@_date: 2015-09-22 18:42:12
Email is best.  My email address is shown at the bottom of the linked PDF, or you can contact the journal directly.  
@_date: 2015-09-22 02:56:43
You actually bring up a good point.  Due to the fact that Bitcoin adoption is limited to the inhabitants of Earth, Bitcoin is O(1) scaling…just with a really big constant :D  
@_date: 2015-09-10 00:42:40
I think it was in the preface to "The Feynman Lectures on Physics" (that he prepared for a freshman audience) but I could be mistaken.  Haha I think I've read every word he's written...
@_date: 2015-09-11 13:55:34
Correct; the number of non-Core nodes is even less now. I'd like to see the Development pie chart looking more like the mining chart.
If a future superstar dev is reading, please do a fork of Core like XT did and you will (likely) have my support!!
@_date: 2015-09-16 16:46:24
I think schemes like this to implement coding gain (the "gamma" variable in my model) are what is necessary to reduce the network propagation impedance to make it more affordable for miners to produce larger blocks in the future.  
I am happy to continue this discussion at a leisurely pace in [this thread](  
@_date: 2015-04-02 18:47:39
Some notes:
* To spend from a 2-of-3 multisig address, the user must know the redemption script and at least 2 of the 3 private keys.
* The redemption script can be public (at the expense of showing the world the public keys associated with the multisig address), and in fact becomes public the moment that multisig address first spends an output.  
* If the redemption script is lost, in general it cannot be recovered with only 2 of the 3 private key.  However, if a payment from that multisig address had previously been made, there will be a permanent copy of the redemption script in the blockchain.  
@_date: 2015-04-30 19:01:55
More like 5400 times due to the 90.69% tight packing factor.  The bitcoin circle is the tiny orange dot.  There's possibly some error due to pixelation, but the circles were plotted to scale. 
@_date: 2015-09-11 14:17:04
OrganOfCorti showed that it was more likely for the network to find a SHA256 collision than for it to activate BIP101 *without* it also becoming the longest proof-of-work chain.  
@_date: 2015-09-08 19:49:00
I'm making a descriptive statement rather than a normative one: he *was* banned.  
I will also make a predictive statement: this thread will be removed.  
@_date: 2015-09-26 01:04:38


At the end, I made a reference to how production quotas in the past have been enforced (censorship at first, and attacks if necessary), and then gave evidence of this happening in Bitcoin.  So I sort of showed that it's not preposterous at all and is in fact exactly what's been happening.
My tone was quite calm and the slides themselves did most the talking at the end.  If you and the poster above you find this "abrasive," perhaps it is because it hurts you to hear the truth.  
@_date: 2015-09-14 02:21:09
So you agree that the idea that the Blockchain should only be a settlement layer and out of reach for the average user is non-technical?
@_date: 2015-04-27 20:13:35
That's because it's a Poisson process :) Similar to how the expectation time for the next block is always 10 min from _now_, GBTC trading is always two weeks away regardless of how long we've already been waiting. 
@_date: 2015-09-11 13:58:28
How do you think we come to consensus? Do the people follow the code or does the code follow the people?
@_date: 2015-04-30 21:29:45
M2 and GDP are two different things.
-  reports China's M2 as 127,530 billion CNY.  
- xe.com reports that 1 CNY = 0.161265 USD
- (127.530 x 10^12 CNY) x (0.161265 USD / CNY) = 20.566 trillion USD
-  reports US M2 money supply as 11.846 trillion USD
@_date: 2015-09-22 16:22:24
@_date: 2015-09-12 20:24:06
IBLTs (or other schemes to achieve coding gain for block propagation) decrease the network propagation impedance.  These are the kind of advances we need to make the production of large blocks economical.
More info: 
@_date: 2015-09-15 21:53:08
What do you think about the (proposed) look of the journal's published articles?  Like Richard mentioned, we had more design flexibility here.
@_date: 2015-09-08 20:00:13


This thread is now removed, BTW.
@_date: 2015-09-05 19:08:42
You're losing the ability to use your money locked in that payment channel for something else at the same time.  
@_date: 2015-09-16 15:29:01
There is now a thread to discuss questions like this in the new Bitcoin forum:
@_date: 2015-04-30 16:30:33
- The area of each gray disk (assuming the disks stack) represents the corresponding M2 money supply, converted to USD.  
- Bitcoin's disk is the very small orange one in the center. Its area represents Bitcoin's market cap in USD. 
- The figure was made in Mathematica.  I wrote a script to plot each circle with a radius proportional to the square root of the M2 money supply (so that the circle's area is linearly proportional to the money supply).  
Edit: added note from Noosterdam re stacking.
@_date: 2015-09-12 20:10:55
Some people are missing the point:
"We can only enforce the rules that most people agree with anyways."
The production quota is to the left of the free-market equilibrium.  This means the market *wants* an increase.  It requires *force* to keep the quota.  
On the other hand, the market doesn't *want* to change the coin supply.  So that rule gets enforced. (It's on the other side of Q* and so doesn't distort the free market).   
@_date: 2015-09-11 06:03:09
If there's one thing the block size limit has revealed, it's the dangerous level of centralization at the Bitcoin development level.  This image shows Bitcoin centralization in terms on nodes, miners and development:
With this level of centralization, it may be possible in the future for a group of coders to prevent important changes from being made in a timely fashion (e.g., should their interests no longer align with those of the larger Bitcoin community).
It's funny, because prior to the block size drama, I sort of took it for granted that "yeah, everyone just runs Core."  If we get a bigger block size AND move away from Core, that would be WIN-WIN.  
@_date: 2015-09-27 05:53:17
This sounds similar to Adam Back's Flexcap proposal.  
@_date: 2015-09-14 12:48:27
I thought his talk was excellent!  I like how he stressed the importance of community building over purely short-term profit making.
@_date: 2015-09-11 14:44:29


Read the white paper.  He never said that.  He said blocks were valid if all the transactions in them were valid and not already spent.  **In other words, he made no mention of a block size limit being part of the consensus rules.**
@_date: 2015-09-08 19:41:46
This is the cartoon that got a month-long ban for trolling.  I wonder if the mods will leave it up this time.  
@_date: 2015-09-11 14:23:53


I think the code quality would be better.  
Each team could take the best pieces of each other team's work.  Of course a very strong incentive would exist for all the implementations to remain fork-wise compatible with each other (sticking to consensus on the state of the Ledger is sort of the main point).  Since these competing implementations would fork from Core like XT did, the concerns regarding "bug-for-bug" compatibility are minor.  
@_date: 2015-09-11 14:06:27
I agree. They go side by side. Each feed off each other!
@_date: 2015-09-16 19:43:12
I don't think my talk made my opinion on the matter completely clear: a block size limit is OK IMO so long as it is (far) to the right of Q*.  This way, it doesn't affect the free market dynamics, and serves only as an anti-spam measure (as it has done historically).  
@_date: 2015-09-11 21:12:51
"(likely)" :p
@_date: 2015-09-23 00:42:01
You're supposed to claim bounties in the other thread. Nevertheless, the "comma" error was pointed out earlier (I can't link to the comment that claimed this bounty, however, or my comment disappears).  
Regarding Appendixes vs. Appendices, both are considered "correct."
@_date: 2015-09-09 22:35:28
I like how Gavin takes the time to explain technical topics like this in such an accessible way.  His blog posts from a few months ago where he methodically went through each objection to raising the block size limit were similarly well communicated.  
I am a believer in the idea popularized by the physicist Richard Feynman, that if you really understand something--regardless of how complex it is--that you will be able to explain it at the freshman level.
Gavin really understands Bitcoin and is also a great educator.  
@_date: 2015-09-11 14:32:38
There will always be *some* contention.  Satoshi said that miners express their acceptance of a block by mining on top of it.  He said the longest chain is the correct one.  In other words, we already have a way of determining consensus.  That's what Bitcoin is all about!
@_date: 2015-11-22 17:50:49
They *have* told me what happened.  I already know.  And yes my abstract has always been public.  
@_date: 2015-09-11 14:26:28
Do you think it is possible for a decentralized currency like Bitcoin to *enforce* rules that go against the will of the market?  How can the invisible hand of the market be fought?
Whether the decisions made by the (economic) majority are good or bad is irrelevant.  There is no way to stop the economic majority from getting its way.  
@_date: 2015-11-12 17:15:51


But it *does* work.  It's been working empirically since 2009 and we can understand one way in which it's guaranteed to continue to work by considering orphan costs as per my [fee market paper]( or my [talk in Montreal](  


Here, you're assuming that miners and nodes have no power to limit the size of blocks themselves; it's as though you're arguing that we need some "top-down policy action" to save us from ourselves.  
A decent analogy for why this won't happen is software: companies sell their premium software for more money even though the marginal cost of production is no different than for their lower-tier software. Sure, their competitors could start discounting their premium software to force a race to the bottom, but this doesn't happen because it would destroy the industry. 
In Bitcoin mining the "premium product" is "next-block service."  Miners are already purposely delaying lower-fee transactions to create a premium market for "next-block service," demonstrating that they have pricing power.  
Like always says: miners won't keep their foot on the pedal if they see a cliff approaching in the distance.


I find it strange that you view the block size limit as some "policy tool" that must be set in a top-down fashion in order to "keep Bitcoin decentralized."  Do you not believe it can naturally come about as an emergent phenomena by all the participants in the network making the decisions they think are best?  All we need to achieve this is free communication, education, and open discussion.
I think what your missing is that the only consensus that matters is that formed by the longest persistent chain. If the longest chain includes blocks larger than 1 MB, well that is just Bitcoin's consensus system doing what it's supposed to do. If--in the distant future--there was some important reason to maintain a small perpetual inflation rate, then the longest chain would probably include some small perpetual inflation. But these sorts of events are not to be feared--they are what allows Bitcoin to adapt to challenges as they arise. They would not result in bitcoins having no value as some fear, but are what prevents Bitcoin from losing its value in the face of obstacles.
This is what the Bitcoin experiment is all about! If we can't trust the market to make good decisions for the health of Bitcoin--and if we really do need people like Greg and Adam making those decisions for us--then Bitcoin has already failed.
@_date: 2015-09-14 01:35:32
What would be a non-technical issue in your opinion?
@_date: 2015-09-22 21:25:10
Yes!  One is presently being built (along with a MS Word template).
[So if anyone dislikes any styling decisions in the linked PDF, speak up now]
@_date: 2015-09-28 22:38:22
I would recommend [Bitcoin for the Befuddled](  It is co-authored by Prof. Chris Wilmer and, despite the simple sounding name, the book even covers technical topics such as elliptic curves and digital signatures (in a easy-to-understand way).  
Disclosure: I work with Chris on [Ledger](  
@_date: 2015-09-13 01:34:56
Until very recently, the production quota was to the right of Q*.  So the production quota was not affecting the free market equilibrium.  In other words, the natural limit was exactly where is was over all these years (less than 1 MB)!!
It is only recently that the anti-spam measure has started to act as a political measure instead, moving to the left of Q* and distorting the free market (causing a deadweight loss as illustrated during my talk).
@_date: 2015-11-30 23:55:27
@_date: 2015-11-22 22:48:39
There is a lot of great work that has gone into Core and there is no reason to abandon that work.  I mean "deprecate" in the sense that the other implementations would still all be compatible but that Blockstream's version of the protocol (Core) would no longer be the reference.  
@_date: 2015-11-22 19:04:38
The mods are now deleting and then undeleting some of my comments here, creating a mess.  To continue this discussion, I suggest a different subreddit or bitco.in.
@_date: 2015-11-22 19:34:29
I learned that my comments were being deleted/hidden after I received a PM from telling me that my response to Adam Back had just been deleted.  I then logged out of my Peter__R account and confirmed it myself.  Sure, it could have been your "spam filter": for example, does your spam filter "just happen" to remove comments with links to certain subreddits?  
After that point, all further comments in this thread that I made were being hidden/deleted. 


I think it is better to reveal the censorship in this subreddit than to try to hide it.
@_date: 2015-11-30 22:54:14
With Bitcoin Unlimited you *could* set your node's limit to 8 GB if you chose to and still track consensus as defined by the longest chain of valid transactions.
@_date: 2015-11-30 19:40:33
The problem is that some people think BIP101's conservative schedule is actually hyper-aggressive.  If demand grows fast, I don't see why we can't scale up **faster** than what is shown in the chart too.  People will be less worried once they see that 8 MB is a piece of cake.
@_date: 2015-11-22 18:56:57
It's political satire--quite effective at communicating the truth in a humorous way.  


The mods have already been deleting my comments here today, for example one comment was deleted in my debate [[here]( with and and then I posted another comment to point out that one was deleted, and then the deleted one reappeared and the second one was then deleted.  
@_date: 2015-11-15 23:00:18
In that case, one dies as investors and miners abandon it.  
@_date: 2015-09-22 18:03:27
Yes.  We will publish a peer-review transcript as a file that can be downloaded alongside the PDF article.  We modelled *Ledger*'s review process after the process used by the [EMBO journal](
You can read more about *Ledger's* transparent peer-review process [here](
@_date: 2015-11-04 02:01:58
Congratulations to for voicing this opinion and providing some much-needed leadership in scaling bitcoin!  
Incidentally, I was also very impressed to learn that you're not only a talented businessman but had the technical ability to create the first version of the Bitcoin node Coinbase now uses to serve 2.7 million people.  
@_date: 2015-11-28 18:35:17
 Thoughts On Opt-In Replace-by-Fee
When I read about Todd's "opt-in" replace-by-fee, my initial thought was that it was harmless because it was optional.  This morning, I think it will do damage to Bitcoin's reputation as a payment system.  Here's how...
Firstly, it's important to understand what the "opt-in" means.  The "opt-in" isn't on a node-by-node basis; it's on a transaction-by-transaction basis.  What this means is that if an attacker "opts-in" on a payment to a vendor, and later tries to double spend that payment, that *all the nodes and miners running Blockstream's implementation of the protocol will work to facilitate the double spend attack.*
So why will this cause problems?  There are several ways:
  Local Bitcoins
Core has just made it very easy for scammers to operate on Local Bitcoins: the scammer will simply trade bitcoins for cash and then double spend it a bit later.  The newbie buying the coins won't understand that "since this TX was flagged for double-spending, he should have waited for a confirmation."  Instead of double-spending being a low-probabiliy attack that required a knowledgable person to even attempt, Core is making it easy and reliable for your average run-of-the-mill scammer.
The idea that Bitcoin now has a payment type to make double-spending easier will not make sense to newbies.  In fact, it makes no sense to me!  We can unstick stuck transactions with child-pays-for-parent, after all.
 Merchants Running Custom Payment Systems
The same problem will happen at merchants running their own payment systems: many won't get around to upgrading to detect these transactions (they might not even realize they need to).  After they get scammed a few times, they will be more reluctant to accept Bitcoin at all.  Explaining to them that "well you should have noted that the transaction was double-spendable" would just seem ridiculous: "you're telling me that Bitcoin now facilitates double spending!?"
 Extra Work for Payment Processors
Payment processors like Bitpay will get around to making sure they can detect the double-spendable transactions.  However, this means they'll need to put engineers on the job and take them off of other projects.  In other words, Core has effectively forced these payment processors to spend more money to support a "feature" that there was no demand for anyways.
 Good News
There is a silver lining to this!  Once industry wraps their heads around how silly this "opt-in RBF" is, then I think we'll see more backlash.  Perhaps this will be the proverbial straw that broke Core's back, pushing people into XT, btcd, Unlimited and other clients that don't support any form of RBF.
 Did Core Add "Opt-in" Replace By Fee?
My hunch is that Blockstream already realized that this would cause damage to Bitcoin's reputation as a payment system, and that by selling it as "optional" they could allow the damage to occur without taking the blame ("it was the free market at work!").  When the problems I described above start to happen, it will give them more ammunition to say "We told you we need Lightning Network because Bitcoin isn't reliable as a payment network!"
@_date: 2015-11-10 03:00:10
Indeed they could.  But that would mean that the ~~Federal Reserve's Open Market Committee wouldn't be able to conduct policy to balance employment with inflation expectations~~ Core Dev's Block Size Planning Committee wouldn't be able to conduct policy to balance the cost of running a node with the price of transaction fees.  
Is it better to trust these decisions to the market or to a committee of experts?
@_date: 2015-11-30 20:20:35


BIP101 doesn't raise the block size; it raises the protocol-enforced *limit* for the block size.  In order to understand the block size limit debate, it is important that people understand the difference.
Furthermore, it is not physically-possible for the network to generate blocks bigger than what the network tech is capable of generating.  So block size is already *physically limited* by the network itself.
@_date: 2015-11-25 22:41:41
You are hugely respected in this community, your vision for Bitcoin's future aligns with the original goals of the project, and I am very much looking forward to your return to leading development (if that is what you choose).  
Please remember that you have LOTS of supporters.  We will rally around the cause; we just need a direction!  
@_date: 2015-11-12 17:49:24
The point is that there is no "variable" equal to 21,000,000.  The total coin supply is an emergent phenomenon: it is equal (approximately) to the sum of all the individual block rewards that have been accepted into the longest chain.  Right now we have consensus that the block reward is 25 BTC.  We also have strong consensus to reduce that to 12.5 BTC sometime next summer.  
What we don't have is a guarantee regarding what the inflation rate will be fifty years from now.  We have a *guide* left to us by Satoshi, but we also have a tool left to us by the same individual for how we come to consensus about rules and incentives: the longest proof-of-work chain!  Perhaps fifty years from now our grand-children will recognize a strong benefit for a small amount of perpetual inflation and will decide to cease any further halvings.  
@_date: 2015-11-30 16:40:44
I believe we're now linearly interpolating between the 8, 16, 32 MB, ... , 8 GB points.  So imagine a ramp with some wiggles rather than a staircase. 
@_date: 2015-11-22 17:02:28
You're still missing that fact that Bitcoin Unlimited *has* an effective block size limit.
I was in the process of putting together a nice presentation to explain how it works so that we could debate sensibly.  Before my SBHK presentation was axed, I was even asked if I'd be OK allowing Blockstream personnel to review my slides prior to presenting (which I agreed to).  I understand it's Blockstream's conference about how they should change their implementation of the protocol (Core), but come on: at least listen to and try to understand what the Bitcoin Unlimited proposal is all about before you criticize it about things you think are true but aren't.
@_date: 2015-11-23 17:04:08
It is fact that more than just Blockstream personnel contribute.  That doesn't change the new reality that it is still ultimately Blockstream's implementation of the protocol.  


We need alternative implementation to make it easier for people to vote with their feet regarding the evolution of the network--this is especially important to guard against the significant changes that Blockstream wants to make to Bitcoin nature.
@_date: 2015-11-22 18:09:28


Firstly, we were *not* permitted to submit full papers.  Only BIPs and 1-2 page abstracts.  
Secondly, I have *not* said that Blockstream blocked my paper.  Only that Blockstream personnel were concerned about the results I intended to present and that I was asked to allow Blockstream personnel to review my slides prior to presenting.  
I also have new information that Blockstream personnel attempted to have parts of my Montreal talk censored from the YouTube proceedings.  


@_date: 2015-11-26 02:32:49
Child pays for parent (CPFP) can be used by the sender too provided the sender's wallet returns at least some change back to himself (which is normal).  The sender just re-spends this change output back to himself with a sufficiently-high fee.
The only thing I can see that replace by fee (RBF) does that CPFP doesn't is RBF makes double-spending 0-conf TXs easier. But intentionally making 0-conf less secure seems pure crazy to me!
@_date: 2015-09-16 15:07:45


I can assure you that spherical cows in a vacuum would be neither simple nor pretty:
@_date: 2015-11-22 22:57:27
Yes, fair enough.  After reviewing your links, I agree that the word "deprecate" was not the best choice for what I was trying to communicate.  "Decentralizing Bitcoin Development" would have been better, as you suggested.  
@_date: 2015-11-22 23:13:33
Core is now Blockstream's implementation of the Bitcoin protocol.  This is why we need additional implementations.  
@_date: 2015-11-22 20:10:51
I have posted the email I received from the committee in the thread I linked above along with some of the reviewer comments.  There are certain comments communicated orally to me that I do not feel would be appropriate to make public.
@_date: 2015-11-22 20:36:04


This is why we need additional implementations.  For the record, I think Blockstream is doing lots of exciting things, and I look forward to see what happens with them.  My only problem is the conflict-of-interest with a for-profit company controlling the protocol run by most of the nodes.  I'd much rather see only 30% of so of nodes run Blockstream Core.  
@_date: 2015-11-22 18:28:09
Yes, the block size limit debate has taught us two important things that we'll fix moving forward:
1.  We cannot be dependent on a single centralized communication platform, because its [owner can be compromised]( 
2.  We cannot be dependent on only Blockstream's implementation of the protocol (Core), because they can [block the stream of transactions to divert flow to their off-chain solutions](  We need to get a greater percentage of nodes running other implementations.  
@_date: 2015-10-04 21:33:54


Two reasons:
1. It becomes easier for the community to exercise their voting power.  For example, if multiple protocol implementations was the accepted norm, then the significant fraction of the community that currently wants larger blocks could migrate to an implementation dedicated to making that happen (e.g., such as XT).  Right now--just because it's never been done before--people are hesitant to switch to XT.  They don't yet understand that Bitcoin is *not* Core; Core is just the name of the dominant implementation of the protocol at the present time.  My animated GIF shows how this could change over time. 
2.  It makes Bitcoin more resilient to accidental forks.  Core's self-fork in 2013 basically split the network in half.  With multiple implementations, it is likely that accidental forks would affect a significantly-smaller percentage of the network.  It would be clear (based on the longest chain) where consensus lay, and the forking implementation could be identified and corrected.  
There was a lot of discussion on both of these points in this thread from a few days ago:
@_date: 2015-11-28 18:18:52
The former.  RBF allows you to mark a transaction as "double spendable" and nodes and miners running Core will work to facilitate the double spend. 
@_date: 2015-11-22 17:36:32


Just because the name is "Bitcoin Unlimited" it doesn't mean block size is unlimited.  I've said this several times now.  Let's put this conversation on hold until we have a clear presentation as a starting point.   


The only reason I know it was initially accepted is because conference organizers (two of them) reached out to *me* for more information--and to ask that I not say certain things during my presentation--because Blockstream personnel were apparently concerned about the results I intended to present.  I've documented everything I knew on Wednesday here: 
@_date: 2015-11-30 22:56:40
Yes, I'd be happy to take a look. 
@_date: 2015-10-01 17:03:35
Agreed that libconsensus will make this easier.  
@_date: 2015-11-22 23:00:49
has contributed a great deal, development wise.  He has run one of the most popular threads in Bitcoin for over four years and several influential ideas have come out of it, helping to steer the evolution of our network.    
@_date: 2015-11-12 17:38:59


I don't recall proposing this.  What proposal are you referring to?  
@_date: 2015-10-01 17:06:45
I know you're being sarcastic, but--since some PoS proponents use this as an argument in favour of checkpoints--a checkpoint is strictly a point *after* the beginning of the program's execution.   
@_date: 2015-10-08 00:32:53


I agree that evidence suggesting that encountering the limit would stifle adoption would provide the strongest support for removal of the limit. 
The way I'm looking at it is that the "Bitcoin system" has a bunch of state variables that are all monotonic functions of the control variable called "adoption".  However, the state variables are also affected by “speculative noise.”  I don't think this model is necessarily unreasonable, as all of these variables show strong correlations with one another.  What I’m questioning, is if there is a limit that prevents *any one* of these state variables from growing, will this also affect the other variables and thus adoption from growing too?  To me it seems like the answer is almost certainly "yes," and the important question is instead how severe the effect will be. 
It's sort of like trying to get more current through a resistor in a circuit, but your power supply has a voltage limit.  Since V=IR, the cap on voltage directly affects the max current.  Well, unless you change your circuit… 
Any ideas? 
@_date: 2015-10-04 22:44:43
I agree that Bitcoin needs more developers. Fostering multiple implementations of the protocol is one method to help achieve that.  We discussed this at a Round Table discussion at Scaling Bitcoin.  More implementations creates more opportunities for new developers to get involved and allows them to choose a group that better aligns with the new developer's goals and ideology.  
@_date: 2015-10-21 03:39:30
Thank you!  
@_date: 2015-10-07 18:43:31


Historically, it has had 92% to do with the price.  Nevertheless, I agree that the cause of the increase in both time series is probably due to increased adoption.  
@_date: 2015-10-01 19:10:17


But it sounds like btcd's [fork rate]( with respect to Core is on the same order of magnitude as Core's self-fork rate (it's fork rate with respect to itself).  Since ensuring that the chance of a fork is identically 0% is impossible in practice, it sounds to me that btcd is already working pretty well.  
That being said, I do support the completion of libconsensus.  
@_date: 2015-10-18 03:52:51


The natural state is for supply to meet demand at a certain price and at a certain equilibrium block size.  If demand increases, then blocks get bigger and the price per TX goes up.  If the cost to produce block space decreases, then the price per TX falls and the average block size increases again.  There is no "economic limit"--there's just a continual market process of supply meeting demand.  


Are you viewing the block size limit as a policy tool that we should be using to balance "fees" with "decentralization"?
Unless we're viewing the block size limit as a policy tool, this question reads as a non-sequitor to me.  For the entire history of Bitcoin, the average block size has been set according to supply and demand in a free-market process unaffected by the block size limit (since it was much greater than the equilibrium block size Q*).  There is nothing to be "ready for"; Bitcoin should simply continue to operate with its original economic model: a block size limit serving as an emergency "anti-spam" measure and not as a policy tool to balance "fees" with "decentralization."  
@_date: 2015-10-02 03:50:00
I've noticed at least three pervasive contradictions repeated by many people:
1.A. Multiple protocol implementations are impractical because the probability of forking is too high.
1.B. (*contradiction*) It is not possible to estimate the probability of forking.  
2.A. Orphan rates are too high to safely permit larger block sizes. 
2.B. (*contradiction*) We cannot rely on orphan rates to drive a fee market in the absence of a block size limit (because orphan rates might be too low).  
3.A. Bitcoin can defend itself against developers who are no longer aligned with the interests of the community because the community can fork the protocol.
3.B. (*contradiction*) Attempts to fork the protocol are an attack on Bitcoin (even when supported by a significant portion of the community).  
@_date: 2015-10-06 15:57:55
Fair enough!
@_date: 2015-10-02 16:46:38
I completely agree.  
But are you saying that it would be misleading if I were to somehow divide each pie slice with faint dashed lines to represent the distribution of hash power in a pool or the distribution of political in a GitHub repo?  I would still keep the real pie slice a homogeneous color (because, like you said, it is ultimately controlled by a single entity).  
@_date: 2015-10-22 19:47:00


Sure, and this results in a healthy fee market.  Here is a graph that illustrates the effect you're talking about [[img]( the marginal cost increases exponentially with block size. 
is correct.
@_date: 2015-10-14 00:47:32


Still stone walling I see.  But now you're also throwing in some ad hominem for good measure, hey?
Anyways, the top hit for me is a wikipedia article. Try it yourself:
For the record, I'm not trying to cause trouble; I am trying to point out how this sub-reddit has become a complete parody of its former self.  
@_date: 2015-11-22 18:51:43


Firstly, we were not permitted to submit full papers. Only BIPs and 1-2 page abstracts.
Secondly, I have not said that Blockstream blocked my paper. Only that Blockstream personnel were concerned about the results I intended to present and that I was asked to allow Blockstream personnel to review my slides prior to presenting.
I also have new information that Blockstream personnel attempted to have parts of my Montreal talk censored from the YouTube proceedings.
I linked my abstract to an earlier comment but it was deleted by the moderators here.  This comment might also get deleted since I'm pointed out the censorship.  
@_date: 2015-10-07 17:10:35


Do you deny that the two quantities have historically been correlated?


Let's imagine that two years from now the price of a bitcoin is $10,000.  If you were to make a prediction, would you predict block sizes greater or small than today?


In what ways is the correlation dangerous?
@_date: 2015-10-07 22:37:31
Bitcoin XT nodes drops random TXs so that the network, as a whole, is less likely to drop any. This improves the security of 0-conf transactions.
@_date: 2015-11-14 02:31:16
If the nodes and miners rejected the block as invalid then it would not persist as the longest chain. If the nodes and miners accepted the block and continued to build on top of it then that block must be valid and that chain must be Bitcoin.
@_date: 2015-10-22 19:39:37


This has been the case for the entire history of Bitcoin (although the fee market is not that efficient yet).  The block size limit was greater than the free-market equilibrium block size and so is did not affect the free-market dynamics.  **For most of Bitcoin's history, the orphan rate has been on the order of 1%.**


There is no evidence to support this (orphan rates are normally around 1%).  Furthermore, the marginal cost of a byte of block space grows exponentially with the size of a block.  This means that if miners are seeing high orphaning rates due to large blocks, they have a significant incentive to improve network connectivity to improve their profit margins (and thus reduce their orphan rates).  
@_date: 2015-10-05 00:55:04
My interpretation of how Bitcoin comes to consensus is based on what Satoshi described in the white paper:
- Nodes accept the block only if all transactions in it are valid and not already spent.
- Nodes express their acceptance of the block by working on creating the next block in the chain, using the hash of the accepted block as the previous hash.
- Nodes always consider the longest chain to be the correct one and will keep working on extending it.
Protocol implementations that track the same blockchain are implementations of the SAME consensus (at least that's my view).  XT and Core are presently implementing the same consensus.  I suspect if BIP101 were activated that this would continue to be true (i.e., Core would capitulate and make changes in order to follow the longest chain).  
@_date: 2015-10-01 18:02:58
Thanks for the info!
So it sounds like btcd nodes probably make up a few percent of the total, rather than less than 1%.  Do you know if any significant mining operations use btcd?
I am very impressed with btcd's forking numbers.  Although the data is sparse, it sounds like btcd's forking rate is the same order of magnitude as Core's self-forking rate.  This would appear to make the "bug-for-bug" compatibility fear more of an academic concern rather than a practical concern.  
I completely agree with your sentiment that multiple implementations would reduce the impact of fork events that do occur.  
Lastly, does btcd have a position on the block size limit debate?
@_date: 2015-10-26 21:07:14




Sorry, I didn't mean to suggest my chart was "better than yours," only that it was better than the scribbled whiteboard version I showed you from a few days ago.  
The curves in my chart represent the integrals of your marginal curves.  Have you read my [fee market paper](  If you look at just Sections 4 - 6 I think it will be very clear how our charts are related.  


I don't know.  It's sort of unavoidable, isn't it?  A block size limit just bends up the supply curve at the limit so that the orphan risk cost is ~infinity for Q &gt; Qmax.  I think it might be a problem if the real orphan *rates*, were, for example 95%, but I don't think that would ever be the case. 


Hmm, ok I normally think in terms of the marginal curves thus the confusion.    


I don't know what will happen when the block reward goes away or even if it will go away.  My work assumes that the block reward is not insignificant.  I haven't thought enough about the case when R/T -&gt; 0 to really argue either way.  
@_date: 2015-10-07 14:20:28
This animation is a unique visualization of the historical relationship between the average block size and the price of a bitcoin.  Not only do the two quantities tend to grow larger together, the higher-frequency oscillations are often in phase too.  
The animation was created in Mathematica from empirical (real) data downloaded from blockchain.info.  I wrote a simple program to create a “true-to-scale” static image for an arbitrary month, looped through all the months of Bitcoin’s history, and then exported the resulting array of images as an animated GIF.  
The cited 92% correlation is the Pearson’s correlation coefficient between the logarithm of the two time series.  It is important to take the logarithm so that the correlation coefficient describes how the percent change in one quantity is related to the percent change in the other.  
P.S. The green rectangles are supposed to represent dollar bills :)
@_date: 2015-10-05 00:24:08


Agreed.  
I support a block size limit far above Q* (refer to [this video]( for background on the equilibrium block size Q*).  The block size limit should serve only as a safety mechanism.  I don't support a block size limit that attempts to force fees upwards. I prefer to allow the [fee market to determine the appropriate block size](  
To exercise my vote, I would run either an implementation supporting BIP101 activation or Bitcoin Unlimited.  
@_date: 2015-10-24 05:49:25
Yes it is exciting! I hope Bitcoin helps us to get back to smaller, more local communities, each with their own take on dealing with problems like crime and poverty.  Without the ability to debase the currency, it will be difficult for "big gov" to finance itself.
@_date: 2015-10-17 08:12:42


*Ledger* accepts submissions for cover art, if you are interested.
@_date: 2015-10-07 17:01:22


I believe we should increase the block size limit to make room for bigger blocks.  I also believe that allowing bitcoin to scale in this way will lead to higher prices.  So, yeah, I'm promoting what I believe to be true and showing facts that support this viewpoint. 


Increases in the average block size have historically corresponded with increases in the bitcoin price (92% correlation).  I agree that we can't know with certainty that this correlation will hold in the future.   
@_date: 2015-10-17 00:11:57
Exponential growth makes a straight line on a log curve like this. 
Since mid 2013, the growth curve is fairly straight (exponential growth at a constant growth rate).  If we account for the "hump" due to Satoshi Dice:
- 2012-04-24 SatoshiDice launches
- 2013-05-14 SatoshiDice web site closes to US players
we get a reasonably straight (exponential) fit back to mid 2012.
The growth during the growth spurt of 2011 was also exponential (but even faster than what we're seeing now).  
@_date: 2015-10-01 16:33:34
What are your thoughts on development?  Do you think it is good to have multiple forkwise-compatible implementations of the protocol, or best to only have a single implementation?
With multiple implementations, like-minded people would flock to the implementation that best matched their work style and goals.  I think a lot of the negativity and personal attacks could be avoided.  This would also open up room for new talented developers to get involved at the highest level.  Attracting 10x more developers to work on the Bitcoin protocol was the topic of a Round Table discussion at Scaling Bitcoin.  My impression was that most the people involved in that discussion thought this was a good idea, provided there was a friendly and practical way to break away from Core's dominance.
Hard-forking changes would be settled by the user base migrating to the implementation that proposed the best solution.  The other implementations would then concede defeat and make forkwise-compatible changes in order to retain their dwindling user bases.  
@_date: 2015-10-07 18:06:08


Correct.  I'm showing that there's been a historical relationship between price and block size (both are probably driven primarily by adoption).  
One reason I think we should increase the block size limit, is because not doing so would necessarily result in a change to bitcoin's growth dynamics (historically, the free-market equilibrium block size has been smaller than the limit).  The change to Bitcoin's dynamics may be less favourable to Bitcoin's continued growth.  
@_date: 2015-10-05 01:57:03
Perhaps I can be the official animated pie chart creator.  No one can create an animated pie chart without my consensus :)
@_date: 2015-10-14 23:18:13


Bitcoin has historically operated with a block size limit *greater* than the free-market equilibrium block size.  By *not* changing a single simple parameter (i.e., increasing the block size limit) we would be changing the dynamics of the economic model that Bitcoin has *successfully* operated under since its inception.  
Let me get this straight, Adam: are you suggesting that we *purposely change* the successful economic parameters of Bitcoin to remove transactions from the Blockchain in order to subsidize off-chain payment solutions?
So that readers can appreciate the extent of any conflicts of interest, is it also true that you are co-founder and CEO of Blockstream, a company in the business of developing and operating off-chain payment solutions?  
@_date: 2015-11-30 23:01:10
Done. 
@_date: 2015-10-07 15:03:49
The correct saying is that correlation does not necessarily imply causation.  A causal relationship may, of course, exist; it is just that one doesn't *necessarily* exist.  Anyways, this is all beside the point.  The visualization illustrates the correlation not the cause.
I suspect the correlation between average block size and the price of a bitcoin will continue to hold into the future after the block size limit is raised.  
@_date: 2015-10-04 20:49:21
This is a simple animated GIF that visualizes one possibility for how multiple protocol implementations might emerge over time. 
Decentralizing development and supporting multiple forkwise-compatible implementations of the protocol is a worthwhile goal that will simultaneously make Bitcoin more robust *and* more responsive to the will of the Bitcoin community. 
**EDIT: this post has now been censored and I have been banned from this sub-reddit.**
@_date: 2015-10-23 02:02:36
Please refer to the image in my response to your other comment:
@_date: 2015-10-07 15:34:20
"Bigger blocks = higher prices (92% correlation)" is true a statement.    
It doesn't mean that higher prices *cause* bigger blocks or that bigger blocks *cause* higher prices.  It just means that the two quantities have been highly correlated with each other.  A percentage increase in the average size of the block has equated with an increase in the price of a bitcoin with a strength of 92%.
(BTW: I actually *do* think that a higher block size *limit* would cause higher prices, but that is my opinion.)
@_date: 2015-10-07 21:48:22
I said "we can't know *with certainty* that this correlation will hold in the *future*."  This is true for all non stationary stochastic processes.
@_date: 2015-10-24 03:16:58
Jerry is awesome and a huge advocate for Bitcoin.  Coordinating this very impressive group of government organizations and private businesses was certainly a significant effort, and IMO will lead to innovation.  Wouldn't it be a positive if we could better catch real criminals such as the BitStamp or Gox thieves, but at the same time work towards better privacy for users and fungibility of coins? Initiatives to better educate law enforcement regarding blockchain technology could help achieve this.
We want Bitcoin to succeed, we want our privacy preserved, and we want the fungibility of our money supply unaffected.  Law enforcement wants to catch criminals.  I don't see these as irreconcilable differences. I do realize that mistakes are made and innocent people are targeted unfairly at times, but to then write off law enforcement completely is as closed-minded as the people who write off Bitcoin because a few unlucky individuals have their wallets hacked.  
Bitcoin is a honeybadher and will achieve *all* sorts of innovation and disruption. 
@_date: 2015-11-12 23:19:53


There's not much we can ever say for sure about the distant future.  Instead, we must make decisions based on the information we have and be ready to change our minds when the facts change.  


My paper is accepted by some people and not by others.  That's pretty usual for a research paper like that.  Only with time will it become obvious how useful the framework I presented in that paper is. 


My paper makes no attempt to predict what the equilibrium block size would be at some point in the future--only that it would exists.  Perhaps two decades from now it will cost $20/month to run a node; perhaps it will cost $2,000/month.  No one knows.  


I'm proposing that we keep Bitcoin as it has always been: with a block size limit acting as an anti-spam measure and greater than the free-market equilibrium block size.  I do *not* believe the block size limit should be used as a policy tool dictated as a top-down directive.    


Because it is true.  In fact, it's described in the white paper:
- Nodes accept the block only if all transactions in it are valid and not already spent.
- Nodes express their acceptance of the block by working on creating the next block in the chain, using the hash of the accepted block as the previous hash.
- Nodes always consider the longest chain to be the correct one and will keep working on extending it. 


I see no reason for the inflation schedule to change over our lifetimes, but it is certainly not immutable.  If research shows that the best way to pay for security in the year 2140 is with fees in addition to a small block subsidy, then that's what will happen.  
Bitcoin is ultimately a creature of the market, governed by the code people freely choose to run. Consensus is then an emergent property, objectively represented by the longest proof-of-work chain.  You can try to deny this fact all you want--you can continue to censor this sub-reddit and delete threads and comments that reveal its truth, but you cannot affect the reality of the situation.  
*"For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled."* – Richard Feynman
@_date: 2015-11-22 23:21:47
I don't disagree.  
@_date: 2015-10-22 19:27:14
The theoretical orphan rate is 1 - e^-τ/T , where τ is a measure of the propagation time.  Orphaning rates are presently approximately 1%, suggesting that τ ~ 6 seconds for the average orphaned block.  
What I am particularly interested to study is how empirical orphan rates depend on the size of the orphaned block.  This would lead to another indirect measurement of the network propagation impedance.  However, I know of no authoritative list of orphaned blocks  
@_date: 2015-10-07 18:30:16
If you look at this chart (it is TXs per day vs. market cap but the correlation is similar), you can see that there's even a correlation in the higher-frequency changes, such as during the bubble and collapse in 2011:
Indeed, the correlation has not held recently, but perhaps that is because the market is concerned about whether Bitcoin will be able to scale further.  
@_date: 2015-10-01 21:57:19


OK I'll make a new pie chart.  Would you be willing to estimate the distribution of political power in Core?  I'm not sure what numbers to use and I don't think GitHub commits are really an accurate measure of political power.
@_date: 2015-10-02 01:02:18
I think your logic applies to development as well as it applies to hashers in a pool.  Hashers can leave a pool if the pool is badly governed; developers can leave a repo if the repo is badly governed.  
I think we could use faint dashed lines to separate each slice of pie into "sub-slices" but I think each sub-slice should still be the same color as the real slice to which it belongs.  
@_date: 2015-10-31 00:00:01
Another interesting fact is that--except for the title--the word "bitcoin" does not appear in the white paper.  
(I think bitcoin is a great name, for the record.)
@_date: 2015-10-23 01:51:50


Agreed.  What you're talking about relates to the orphan rate's dependence on block size.  I'm just pointing out that since orphaning exists, propagation time empirically matters.  


Agreed.  


Which revenue?  Are you suggesting that *fee* revenue will equal the expected orphaning cost?  This was an idea popularized by [Gmax]( and used to argue that fees wouldn't contribute to security.  It is easy to show that this idea is false with a simple diagram [[img](  As long as block space satisfies the laws of supply and demand, the fee revenue will be greater than the expected orphaning costs in an efficient market (profits -&gt; 0).  


No, the orphaning risk cost depends on how big a miner chooses to make his block, the propagation impedance, and his communication latency. 
If, on the other hand, you mean that *network-wide* orphan rates would increase with an increase in demand (holding everything else constant), then I would agree.  


I would agree that the fee market is only weekly developed and inefficient, but it clearly exists.  For example, average fee revenue is linear with block size--as predicted by the fee market theory.  


Demand for any commodity can be considered infinite at a low enough unit price.  
@_date: 2015-10-01 18:38:11


But it appears that btcd is already doing this--and with a fork rate (albeit based on sparse data) of the same order of magnitude as Core's self-fork rate.  This suggests to me that *it is practical now* (because it's already being done) and will become increasingly practical with the completion of libconsensus.  
EDIT: BitcoinXT is also doing this (albeit with essentially Core's consensus code).  
@_date: 2015-10-17 00:05:11
That's a good point; in fact, a growth spurt like we saw in early 2011 would push us over 8 MB in about half a year.  
Since it's probably not practical to operate above 75% of the limit for the reasons Mike Hearn has pointed out several times, there is essentially no capacity left to accommodate another growth spurt like we saw in 2011, early 2013, or late 2013.  
@_date: 2015-10-15 21:41:17




Can you try to explain why you think the free-market equilibrium block size may have been greater than 1 MB for much of Bitcoin's history?  Your comment just now is the first I've heard against the theory that (up until perhaps recently) the block size limit has historically been greater than the free-market equilibrium block size.  




From my perspective, I don't really care whether the block size limit next year is 4 MB or 40 MB--so long as it is once again far to the right of the equilibrium block size Q* .  This is where I think we disagree: you seem to want to permit the block size limit to drift to the left of Q* so that it serves the political purpose of taking transactions off of the main chain (increased fee pressure) in order to subsidize off-chain solutions like Lightning Networks and side chains.  
I can only parse your statement "wait to see what Lightning can achieve for improved scalability" if I interpret is as a request to subsidize Lightning for a few years.  Why do we have to "wait and see" anything?  Instead, we should increase (or remove) the hard limit and allow Lightning and "Bitcoin Classic" to compete on an even playing field.




There is nothing *wrong* with having a conflict of interest, Adam.  Just be honest with that fact and allow people to come to their own conclusions.  The facts are that:
1. Blockstream is in the business of developing and operating off-chain payment solutions.
2. A restrictive block size limit increases demand for off-chain payment solutions.
3. Blockstream employees and contractors are vocal about ensuring the block size limit stays/becomes restrictive.  
How is me pointing this out "emotional and rude"?
Let me end by saying that I think lots of the things Blockstream is doing are really cool and I hope that some are successful.  My *only* problem is with Blockstream (in particular Core Devs who are involved with Blockstream) arguing against main-chain scaling due to the clear conflict of interest.  
@_date: 2015-10-01 19:23:43
I agree that the lack of statistical data and the low node count for btcd make the historical fork rate a less-than-ideal predictor of fork probability.  However, I can't think of a better way to estimate it.
My question to you then: what could an alternative implementation (i.e., one *not* built from libconsensus) do to convince you that the probability of forking was very small?  
@_date: 2015-10-02 17:15:55


Yes, since I have no idea how to objectively measure this, figuring out how to draw those dashed lines is certainly an obstacle!  
The reason I'm entertaining the idea is that suggested it in terms of development and Rocks suggested it in terms of mining pools.  If it can't be done, then it can't be done.  
@_date: 2015-10-01 19:35:20


I disagree.  I'm not sure how libconsensus will work exactly, but when I compile the same code with even different versions of the same compiler, it can result in differences in the HEX file (most my C/C++ experience is related to microcontrollers; the HEX file is the machine code for the program).  Furthermore, future processors could have unknown errata that result in slightly different behaviour in rare edge cases.  For example, a few years ago my team spent several weeks tracking down an issue where two different revisions of the same part-numbered microcontroller behaved differently when programmed with the same HEX file (due to what we later learned was an not-yet-known erratum for the chip).  
My point is that when you're dealing with the real world, you can never really predict the outcome of an event with 100% certainty.  Thinking that you can is dangerous.     
@_date: 2015-11-10 05:16:21


Correct, I use what I call the "small miner approximation" which assumes that each miner's hash rate, h, is small compared to the network hash rate, H.  This is of course not true in practice, as certain pools have h/H ~ 25% and thus have a theoretical advantage (all other variables held constant) due to the self-propagation effect.  That being said, a small miner can always join a pool in which case he will no longer be disadvantaged.    
One thing I don't know--and I'm not sure anyone does--is how large this theoretical advantage is.  I haven't been able rigorously work out the math and I am skeptical of the simulations I've seen referenced...


Depends what you mean by "healthy," but yeah 20 years in the future and maybe it will cost $10 / month to run a node, or maybe it will cost $5000 / month.  What I did show is that the idea that fees would coverage to "1 satoshi" was false.  
@_date: 2015-11-20 17:24:32
Good point.  If they controlled a greater portion of the hash power they could take increased advantage of the backlog due to the block size limit.
@_date: 2015-11-12 17:30:58
Bitcoin is ultimately a creature of the market, governed by the code people freely choose to run. Consensus is then an emergent property, objectively represented by the longest proof-of-work chain.
Both the block interval time or the block reward (inflation rate) could change if the market viewed that as being in Bitcoin's best interest.  I think *both* of these things will change eventually:
-  I think the block interval time will change a decade or two from now to something much smaller (~1 minute), as we build better communication infrastructure between nodes and miners to reduce orphaning (remember, 10 min was sort of a conservative guess to balance speed of confirmation with orphaning risk).  
- I think the block reward will decrease to 12.5 BTC in the summer of 2016.
@_date: 2015-11-22 19:44:03
That is the same link that I just shared with you.  No one claimed that it had anything to do with Greg; just that the timing was suspicious.  I received acknowledgement of my paper's informal acceptance by two people, not one, which is what led to the rumors.  And yes, I know *exactly* why my proposal was rejected.  I have now spoken with several people.    
@_date: 2015-10-14 00:19:10


Who is the third party that defines the terms for you? 
Are you trying to stonewall /s
@_date: 2015-10-14 00:22:20


I felt what was doing was trying to get clarification on what topics and posts will be censored and what type of comments people would be banned for.  By calling that "stirring up drama" in my opinion you are using *ad hominem* to make him appear unreasonable and the moderation here as reasonable, while in fact the opposite is true.  
@_date: 2015-10-14 00:28:39
But Google is a search engine so it links to multiple definitions.  
For the record, you've already broken the following rules:
* Stonewalling (refusing to clarify the definitions)
* Sidetracking (repeating the same non-answer over again)
@_date: 2015-10-04 20:57:40
They would all follow the longest proof-of-work chain composed of valid transactions.  
@_date: 2015-11-15 16:36:41
Are you saying that Bitcoin must be governed from the "top down"?  That allowing people to easily express their preference on things like block size limit or the client they run in order to achieve "bottom up" governance would not work?  
@_date: 2015-10-06 05:00:39
makes a good point.
The results on your hardware might be different than on my hardware.  For example, the bit width of "int" is compiler dependent.  It is normally set to the natural width of the processor the compiler is compiling for.  This is why it's advisable to use &lt;stdint.h&gt; to make the bit width's explicit (e.g., int32_t).
Furthermore, the [overflow behaviour]( of signed ints is not defined by, e.g., C99, and is again compiler dependent.  
Lastly, the above code is an abstraction of the actual machine code that gets executed on the processor.  This will certainly affect timing and, in rare edge cases, could trigger an unknown erratum for that version of the processor's silicon.  
In summary, the code posted above is not unambiguous for all possible inputs, compilers and hardware. 
@_date: 2015-10-12 05:27:56
You're not allowed to ask these types of questions.
@_date: 2015-10-01 21:48:50
organofcorti did some statistical work that explains why it would be unlikely for the protocol to fork with only 51%.  The reason is that if, for example, 510 of the last 1000 blocks were BIP101, there is actually a good chance it was a result of variance and that the real support level is less than 50%.  
Before activating a forking change, the network would want to see convincing evidence that the forked chain will become dominant.  Because measurements of consensus involve uncertainty, it will always required a supermajority of support. 
@_date: 2015-10-19 23:05:07


Do you have a link to when Greg argues this particular point? The link you provided is broken for me.  
@_date: 2015-11-03 22:50:11


Do you think it is better for the majority of nodes to run the same implementation, or for nodes to run multiple implementations?
@_date: 2015-11-26 19:36:29
I do.  But Bitcoin is dynamic; just because XT/BIP101 didn't immediately gain traction when released this summer doesn't mean that BIP101 won't gain traction later when the need becomes acute.  
@_date: 2015-11-22 16:18:40


This is not true with Bitcoin Unlimited.  The block size rule is moved from the consensus layer to the network layer.  Retaining a block size limit allows nodes and miners to still influence Blockchain growth by increasing the orphaning probability of large blocks; however, moving the limit outside of the consensus layer means that Bitcoin Unlimited nodes will always follow the longest chain composed of valid transactions (even if that chain contains blocks larger than a given node's individual block size limit).  
In other words, Bitcoin Unlimited is *more* robust to recovering from forks than Core.    
Here is some more information (draft form for now): 
@_date: 2015-10-17 01:29:44
The graph is color-coded in a linear scale to show % fullness.  
The graph was green for much of Bitcoin's history, meaning that blocks were &lt; 20% full.  Interestingly, our transition into the "orange and reds" (&gt; 40% full) has corresponded with an increase in the intensity of the block size limit debate.


@_date: 2015-10-14 00:24:32


Ad hominem.  Reported.
@_date: 2015-11-23 16:36:51
I think most people agree that Blockstream is doing exciting and useful research (e.g., Lightning Network, Confidential Transactions, etc.)  
The source of tension is that the majority of Bitcoin nodes run Blockstream's implementation of the protocol (Core).  Whether Blockstream is abusing its control of the protocol is irrelevant; the fact that they can is a conflict of interest and also the reason we need more implementations.  
@_date: 2015-10-01 15:21:11
In my opinion, it is important that we work towards multiple (forkwise-compatible) implementations of the protocol. The 90% node share that Core presently has is a danger to Bitcoin's future development.
@_date: 2015-10-07 15:22:09
Do you mean before the block size *limit* was a factor at all?
@_date: 2015-10-05 00:04:51


I think the IRC meetings are a great idea for lower-level code maintenance and non-controversial enhancements.  
For bigger-picture stuff, I'd like to see an academic and interdisciplinary communication channel that would allow bright minds in economics, computer science, anthropology, physics and law to contribute at the highest-level towards the evolution of Bitcoin.  
The scientific journal [*Nature* recently said]( that "Bitcoin officially came of age in academia with the launch of [*Ledger*]( the first journal dedicated to cryptocurrency research."  I hope this journal makes an impact towards Bitcoin leadership and governance too.  
  
@_date: 2015-10-01 19:48:34
Rocks [recently suggested]( that the pie charts also make mining appear more centralized than it really is for a similar reason: hashers can leave one mining pool if it misbehaves similar to how coders could leave one implementation if it misbehaves.  
I would propose that I indicate both with faint dashed lines, but keep the "sub-slices" of the pie the same color.  The problem though is that I don't know how to determine the distribution of hash power in a mining pool or the distribution of political power in a GitHub repo.   
@_date: 2015-10-26 23:50:09
Interesting.  Have you tried to work out the math for this?
@_date: 2015-10-17 00:30:54
Another good point.  The way I think about it is that moving "upwards" on the chart by 1 cm means the same percentage increase no matter where on the chart you start.  
For example, at the beginning of 2012, on my computer screen, there's about 2.5 cm between the block size limit and average block size.  To visualize what the block size limit *today* would need to be to be the same % greater, then just move up 2.5 cm from the point marked "today."  The equivalent block size limit would need to be about 50 MB.  
@_date: 2015-10-07 19:07:44
I wouldn't say I *assume* the market is worried about scaling, more like I *believe* the market is worried about scaling.  
I think the trend was initially broken after the bubble pop in 2014 for reasons unrelated to the block size limit.  However, I also believe the trend would have resumed if the block size limit were much higher than it is today.  But again, that is just my opinion.  
Anyways, it will be interesting to see what happens should BIP101 (or something similar) be activated.  I suspect the price will rally hard within a six-month window centered around this event.  
@_date: 2015-10-24 03:54:57
I believe a crime must be perpetrated against a victim.  Marijuana users and raw milk farmers are thus not criminals.  Snowden exposed unconstitutional behaviour of the NSA and other government organizations.  I totally agree that there are some messed up laws and messed up people influencing certain government agencies.  But there are messed up people everywhere, including within Bitcoin.  
More communication, education and transparency is a positive thing for both law enforcement and Bitcoin, in my opinion.
@_date: 2015-10-04 00:52:22
*Also* what happens when 21,000,001 people make it their personal goal to have at least 1 bitcoin?
@_date: 2015-10-02 16:48:28
Paging are you willing to make estimates on the distribution of individual influence (political power) in the Core team?  I want to follow-up with your suggestion.  
@_date: 2015-11-12 18:30:48


It is a research paper that analyzes the fee market in the absence of a protocol-enforced block size limit, assuming that miners will add TXs to their blocks if the added fee income is greater than the marginal orphaning risk cost. The purpose of the paper is to gain a better understanding of how this stuff works.  Just because I concluded that a fee market would exist without a block size limit, doesn't mean I'm advocating for its removal. 


The "unlimited" in Bitcoin Unlimited means unlimited freedom of choice regarding things like the block size limit.  I personally like the comfort of a block size limit.  I just think it should be much higher than 1 MB today and that further changes should be determined in an organic bottom-up approach (emergent phenomenon) rather than as a top-down decision (policy tool).  
That being said, I also support BIP101.    
@_date: 2015-10-04 21:51:48


In order for each implementation to follow the longest chain composed of valid transactions, implementations would all have the same consensus rules for what constitutes a valid transaction.  
Regarding isStandard() tests, they would likely have different rules here (e.g., different fee relay policies).  They would also have different rules for dropping transactions from mempool (lowest fee density vs random TXs) and they might support new ideas like 'weak blocks' in different ways (at least initially).  
Regarding transport-layer rules like the max block size, implementations could have different rules *to a limited extent*.  For example, nodes could run Bitcoin Unlimited (no block size limit) and still follow the longest chain.  However, nodes that enforced too small a block size limit would eventually be forked off the network if they refused to follow consensus and increase their limits.  
@_date: 2015-10-14 23:40:16
This is a simple animated GIF that visualizes one possibility for how multiple protocol implementations might emerge over time. 
Decentralizing development and supporting multiple forkwise-compatible implementations of the protocol is a worthwhile goal that will simultaneously make Bitcoin more robust *and* more responsive to the will of the market.  
*Background:  This post was previously censored and I was banned for 1 day under the rationale that I was vote brigading [charges which I deny].*
@_date: 2015-11-30 21:07:01
Then the free-market equilibrium block size would be less than the limit and no change would be required.
@_date: 2015-10-04 22:25:54


I have not personally written any code that is used by an implementation of the Bitcoin protocol, nor do I plan to in the near future. 
I believe there are many ways to contribute to Bitcoin and I agree that contributing code is one them.  I try to make contributions that best use my skill set and that I think are needed.   
@_date: 2015-10-07 21:37:57


It's the correlation coefficient.  It means that a percent increase in the block size has historically equated with an increase in the price with 92% correlation.  
For the record, do you stand by your claim that "block size has 100% nothing at all to do with the price."?
@_date: 2015-10-30 01:00:08
Yes, this is true.  Gmax suggested that etblocktemplate() is superlinear in the mempool size.  We analyzed this in the now-locked Gold Collapsing. Bitcoin UP thread this summer.  thought that miners were producing more empty blocks when the mempool was large and we were trying to understand why that might be the case (the reason is the time is takes getblocktemplate() to execute).   
@_date: 2015-10-07 18:41:06
This chart shows Bitcoin's market cap plotted alongside the square of the number of transactions per day (not including popular address as defined by blockchain.info).  
It is interesting, because we see that the correlation does not *only* exist over long time scale, but exists over shorter time scales too.  For example, the bubble and bust of 2011 resulted in a similar looking curve for the square of the number of transactions.  
Indeed, the relationship appears to have broken over the past year.  I believe the market is worried that Bitcoin will be unable to further scale.
@_date: 2015-10-26 22:51:11


I guess it depends what your definition of "orphan risk cost" is and what you mean by "significant".  My definition is that "orphan risk cost" obeys:
     fee revenue = extra security + orphaning risk cost + miners' profit
and "significant" means "significant enough that it affects the decisions made by miners."


No, not at all.  I'm just saying that I don't know how the Blockchain will be secured decades into the future.  There are a lot of possibilities and maybe the system is fine exactly how it is.  I think it will be our kids or grandkids figuring this out--assuming Bitcoin is still around, that is.  
@_date: 2015-10-06 05:55:52


Thank you for commenting!  
It's nothing that sophisticated, unfortunately.  The initial parameters represent the node distributions today, but the predications about the future are essentially arbitrary. 
My goal with this animated GIF was to get people to become more familiar with the idea that a deprecation of Core could indeed occur.  By drawing a visual parallel to the mining pool pie charts (that people already recognize as "good" if they include many slices) I hoped to impart a familiarity to the process, and in fact a desire in the community to see it evolve similarly to what was animated.  
@_date: 2015-10-15 23:59:38


Viewing things through the perspective of conflicts-of-interest allows one to assess biases.  It doesn't matter whether you claim to be acting upon your conflict of interest or not--the conflict of interest is *real* and could be affecting your bias.  
The fact is that Blockstream personally benefits from a restrictive block size limit, is arguing in favor of a restrictive limit (i.e., a limit the the left of Q*), and is using its influence within Core Dev to achieve a restrictive limit.  It doesn't matter that the reason you give for your position is "security" (as opposed to a subsidy towards off-chain solutions).  Humans are strange creatures--how would you know that you're not being affected by the conflict of interest?
Since you gave me unsolicited advice, I'll do the same for you: recluse yourself from the block size limit debate and suggest the others at Blockstream who share the conflict of interest do the same.  Make a public statement that says that "since Blockstream is in a position to benefit from a restrictive block size limit, Blockstream employees and contractors with influential positions within Core Dev (Adam, Greg, Pieter and Luke) will no longer debate "for" or "against" changes to the block size limit.  
Do that and Blockstream will have my support.  


I would like to apologize to you for making that statement, Adam.  I agree that I crossed the line by using that choice of words and the image on my last slide.   
@_date: 2015-10-04 21:37:45


Good point!  At Scaling Bitcoin, we had a Round Table discussion to brainstorm ways to get 10X the amount of developers working at the protocol level.  Multiple implementations would create opportunities to talented developers to make a bigger impact than trying to navigate the politics of contributing to Core.  
@_date: 2015-10-01 18:33:15
Can you explain exactly how you're proposing I should split Core between the different organizations developing it?  
@_date: 2015-10-06 06:15:16
Congrats!  I remember the first time I saw that picture very well!  
@_date: 2015-10-04 21:57:52


I think with multiple implementations it would actually be easier to make changes that had the support of a super majority.  One implementation would implement the solutions (e.g., using a technique like the 75% requirement for activation from BIP101), and nodes would migrate to this implementation.  In an effort to retain their dwindling node share, at a certain point the other implementations would capitulate and also make changes to ensure forkwise compatibility.
**In other words, consensus would be determined by the code we run.** 
@_date: 2015-10-05 01:44:45


I disagree.
@_date: 2015-10-07 15:18:52


In other words, you're saying that the block sizes have historically been correlated with the price of a bitcoin.  But there is no skewing: those are the actual facts.
@_date: 2015-10-07 17:57:40


I think the *causal* variable is probably adoption--i.e., the number of Bitcoin users (as you suggested).  More users leads to more transactions (bigger blocks) and leads to an increased demand to hold coins (higher prices).  Bitcoin as a "system" grows together (which is of course quite intuitive).
While it is true that we can't know with certainty that the price would no longer increase if the 1 MB limit were retained, it is also true that if growth were to continue it would occur with different [and potentially less favourable]  dynamics than in the past.  (We would be forcing a change to the dynamics of "Bitcoin as a system"--the same system that resulted in the correlations between variables such as block size and price that we see today).   


Roughly, yes, although I believe TXs have gotten slightly bigger on average with the popularization of multisig and coinjoin.  
BTW, the strongest correlation I've found is between Bitcoin's "market cap" and the "number of transactions per day not including popular addresses" [as defined by blockchain.info].  Last time I checked, the historical correlation was 97%.  What is really interesting is that the regression between to the two time series shows that Bitcoin's market cap is nearly proportional to the *square* of the number of transactions per day (although this correlation has not held over the last year or so).  I am very curious if the "squared" relationship is just dumb luck, or if it means something fundamental.  
@_date: 2015-10-01 15:42:58
Thanks for pointing out btcsuite!  I have three questions:
1. When I was building these charts, it looked like only about 0.3% of the nodes were actually running this implementation of the Bitcoin protocol.  Does that number sound accurate to you?
2. We are often reminded of the need for "bug-for-bug" compatibility.  In your opinion, is this feasible with an implementation like BTC suite (that was not derived as a fork from Core like XT was)?  
3. Has there every been an instance when the BTC nodes forked from the Core nodes due to a compatibility issue?  
@_date: 2015-10-02 02:33:52
In my opinion, the paper is written objectively and, if anything, I feel it gives more credit to dPOS than was deserved based on the arguments presented.  
You are correct that BitFury has a conflict of interest. However, this emphatically does *not* mean that the paper is not credible.  In fact, since BitFury is intimately involved in proof-of-work mining, they are uniquely positioned to provide important insight on the topic.  
If such a paper were to be submitted to [*Ledger*]( the author would disclose this conflict of interest after the conclusion section (e.g., "The author is a principle of a proof-of-work mining operation.").  The paper would then be reviewed no differently than if the paper had been submitted by someone who wasn't directly involved in mining.  
It is important that potential conflicts of interest be disclosed, but it is ultimately the content of the paper that we should be focussing on.    
@_date: 2015-10-05 00:34:43
I actually agree.  I'm hoping that continued deadlock in Core regarding the block size limit will be the impetus needed to decentralize development.  If we can deprecate Core (or significantly reduce its node share) then I think all the debate and drama over the past several months will have been worthwhile.  
@_date: 2015-10-26 04:01:45
Thanks for the graph!  I appreciate you arguing from the perspective of supply and demand, as this way we can speak the same language.  


I agree.  [Here]( is a better chart I recently made to illustrate this point.


He is wrong provided that block space obeys the law of demand (positive price elasticity of supply).  More on this [here](  


Thanks for this.  I agree "in spirit" although I disagree with your shading.  I think the orphaning cost is the area under the dark green curve, while the fee revenue is the area under the light green curve.  The area between the curves is the miner's surplus, which obeys the equation:
     Miner's surplus = Profit + Added security
I am fine with most of your assumptions except for   As far as I know, no one has even been able to rigorously show what happens to the fee market when the block reward goes away.  I am always working from the assumption that the block reward is *not* insignificant.  This will be the case for the next few decades, at least.  
@_date: 2015-10-07 18:38:18
Correct; I like to think of this as the "Metcalfe Value relationship."  I am very curious to know whether the "squared" relationship is just random luck, or whether it represents something fundamental.  
@_date: 2015-10-17 05:57:33


The colour scale is linear with block fullness. It was actually adapted from 1MBCON advisory system from BitcoinTalk that I thought was a completely reasonable color scheme:
@_date: 2015-10-02 02:54:09
Fair enough!
@_date: 2015-10-01 18:36:03
Thanks!  Did you noticed comment about the privacy defaults in btcd resulting in underestimates of btcd node count? 
@_date: 2013-12-04 16:12:52
I think this is half joke, half scam: look carefully at the picture people!  There are random faces floating in mid air.  And the same face is in three spots!
@_date: 2013-12-05 02:00:17
lol, indeed they are signs.  
I hope this bitcoin QR-sign thing goes viral--it's great publicity and illustrates the power of bitcoin to the masses.  But, still, something is not sitting right with me about this particular story, but I can't explain.  Maybe its the way some posters seem almost too eager to identify the bitcoin address in the sign.  The ESPN sign seemed a lot more "organic." 
@_date: 2013-12-25 05:23:25
This is a fantastic idea.  
Jeff Garzik has discussed his ideas for linking identities to bitcoin addresses (by choice, not by law).  One could simply link his physical shipping address to one of his bitcoin addresses, and post a signed-message to the block-chain to record this fact.  This way, no third-party needs to manage your shipping address at all--you are fully in control.  But any vendor can use it if you give them access. 
So, yeah, you'd see a TV advertisement with an "order now" QR code.  You simply scan the QR code with your phone, pay it from your "order now" address (the one linked to your shipping address), and then the package arrives at your door in a few days!
@_date: 2013-12-03 02:17:52
The textbooks of the future will describe Erik Voorhees as an eloquent and great proponent of the bitcoin movement.  I feel we are truly making history here.  
Well done Erik!