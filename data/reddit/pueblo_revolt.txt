@_author: pueblo_revolt
@_date: 2018-01-14 23:03:54
Not sure if you realize this, but what the animation shows is just when commits were merged into the master branch of the bitcoin/bitcoin repo on github. So you're watching changes on a central repository merged by the tiny group (four or five people afaik) with write access.
What the video shows (presumably, I haven't watched it as I find these visualisations boring) is that there was a lot of activity from a number of developers. But that doesn't tell you anything about decentralization one way or the other, all it tells you is that bitcoin core isn't a one man show
@_date: 2018-01-11 16:02:19
When that schedule was written, the plan was still to release segwit wallet in 0.15.1, so I don't think it's still valid. AFAIK the current plan is to release whenever segwit wallet is ready, so it'll probably be sooner than May
@_date: 2018-01-15 10:37:15


A lot of that stuff could probably be automated. The list of affiliations you would need to maintain by hand, but most of the raw data you can probably pull from git logs (except for review-by, which bitcoin doesn't seem to use). And once you have that, generating a few funky charts shouldn't be too hard. Might make a nice side project for someone willing to contribute, but unwilling to learn C :-)
@_date: 2018-01-10 18:25:24
but the counterparty that tries to steal your coins has the same fee estimation problem, so it kind of evens out :-)
@_date: 2018-01-04 17:23:17
Average is not really a good measurement, since a handful of high value transactions can skew it severely. The median value for the same period is around $4,800:
Edit: Yes, the median fee is $15, i.e. also smaller than the avg fee, but only 50% smaller, not 95%
@_date: 2018-01-15 07:50:19
Well yeah, that's how git works. Again, I'm not complaining about the dev process, I'm saying that some animated version of the bitcoin/bitcoin master commit timeline doesn't provide any useful insight into how decentralized it is. 
@_date: 2018-01-15 09:27:13
Let me put it this way: If you did the same video for Dash or Litecoin, it would probably look almost the same, since they backport everything Core does and then just add their branding. So if you go only by the video, Litecoin would probably look more decentralized because it has all the commits from Core plus whatever coblee is doing.
What would be more useful would be something like "Who wrote Linux" reports Jonathan Corbet does, i.e. Number of commits/reviews/merges by individual and affiliation, and so on (ort of what you did in your 0.15 presentation).
@_date: 2018-01-10 18:31:00
Well, implementing segwit lowers _your_ fees, no need to wait for the rest of the ecosystem to catch up. But yeah, players that don't pay transaction fees themselves (i.e. services where users pay the fees) don't really have an incentive to upgrade
@_date: 2019-07-20 15:30:32
An interesting scenario might be if there is some critical bug found in one of the main ln implementations which causes say 30% of ln nodes to go offline. Then, everyone will want to close their channels simultaneously, so you'd have tens of thousands of transactions flooding the mempool simultaneously. BTC itself will function normally I guess, but the question is if all this can be settled before htlc timeouts kick in, channel owners panic etc..
@_date: 2017-12-29 16:03:51
Not really. Somebody who does one transaction per day pays the fee for transaction data + signature data. A big player with a hundred transactions every ten minutes pays the fees for each transaction's transaction data and then the fee for one signature which covers all the 100 transactions. So the big player saves 99% of the signature data fees compared to the small player
@_date: 2017-12-19 15:43:35
yeah well at least you still get to participate in appreciations in BTC value (if any) at the price of some risk (that the exchange might go under). Certainly not ideal, but it's the option available right now.
@_date: 2017-12-14 22:31:21
Good to know! Haven't looked into bcoin and bitcrust so far, but I seem to remember that abc backports quite a few things from core, no?
@_date: 2017-12-19 13:52:41
well, you can use an altcoin just like you would use LN. Put some money in when you want to make transactions, when your're done, withdraw to BTC
@_date: 2018-09-28 17:01:00
They don't take 20% fees, they take 20% _of_ the fees. So for example if the fee is 1% of the transaction value, they take 20% of that, i.e. 0,2% of the transaction value. You make it sound as if they take 20% of the transaction value, which would be pretty crazy
@_date: 2017-12-14 22:14:33


But how different are they really? I mean AFAICT they are mostly forks of some version of core with some stuff backported and some added/removed functionality. If it were different implementations from the ground up (like the LN implementations e.g., which are also in different languages and different dependencies), it could be interesting. But to me they just seem too similar
@_date: 2018-09-29 22:25:40
Actually, something like 70% of kernel contributors are employees of various IT companies. 
@_date: 2017-12-29 13:36:45
I've read somewhere that it might creat some centralization pressure, because the more transactions you process, the more opportunities you get for aggregating signatures. Thus, big users will get lower transaction fees than small players
@_date: 2018-09-27 18:04:32
This change didn't directly cause the inflation bug. Another, seemingly unrelated change turned what was a crash bug into the inflation bug. Software development is hard :-)
@_date: 2017-12-22 11:19:16


It's not only the GUI, but also the wallet that is missing some stuff
@_date: 2018-09-30 07:06:54


Sure. The difference is that if Blockstream's venture capital runs out (or if IBM decides to shift strategy and focus something else), the devs will get reassigned or look for another job, which will cause the projects they were working on to suffer. In the case where the dev's compensation is directly linked to the success of their project, they can keep going as long as their software is deemed useful by the relevant target audience. A much more sustainable arrangement IMO.
@_date: 2018-09-01 09:18:03
Huge missed opportunity: "Rakuten Buys Everybody's Bitcoin" would have been a way funnier headline :-)
@_date: 2018-09-27 18:02:41
it's all in the git history
@_date: 2017-12-14 21:11:32


Larger in terms of kb or weight? Beause if it's only kb, it still would have a positive effect on congestion
@_date: 2018-09-29 10:56:04
Well, I still don't really see the harm. AFAIK it's merge-mining, so for the miners, this is extra income. And the extra income is derived from work rsk has been doing, i.e. building and maintaining a software that people find useful enough to spend money on. If rsk got nothing, then they would be working for the miners for free, no? 
EDIT: IOW, and more to your point: Security and competitiveness do not come from miners alone. The software also needs to be maintained and evolved. And that costs money
@_date: 2018-09-01 10:13:06
Nothing to do with keys: The name of the company they bought is "Everybody's Bitcoin". Hence:
Rakuten Buys Everybody's Bitcoin
@_date: 2018-09-30 09:31:41
All that sidechain stuff is centralized anyways in the sense that the devs need to get permission from the miners (i.e. they can choose to merge mine or not). If anything, that is something you could get upset about.
And no, I don't think centralization inside of one sidechain is a problem, just like it's not a problem that Firefox development is centralized around a company that makes money from it. If you don't like, just don't use it.
Anyhow, this conversation is becoming a bit tedious. If you think that taking a cut of the transaction fees is evil, then so be it. You're certainly entitled to your opinion.
@_date: 2017-12-14 21:17:32


I don't mean to sound snarky, but maybe you should have all gotten together and worked on a common roadmap, too. It might have made a bigger splash than six individual projects
@_date: 2018-09-28 19:46:56
yeah, but as a user, what difference does it make? You spend the gas anyways, and whether the miner keeps all of it or gives some of it to someone else doesn't really affect you
@_date: 2017-12-22 13:25:11
I would guess mostly (smaller) businesses may use it in their backend, so it might make a difference 
@_date: 2018-09-27 18:01:15
of course there is a way to test it. Read the full disclosure document. It says right there the Greg Maxwell has timestamped a testcase for it. The only reason it's not public yet is to not make it easier to copy n paste this into some exploit code
@_date: 2018-09-02 09:17:06
Point of Sale (just in case someone is legitimately confused about this :-))
@_date: 2017-12-27 19:37:43
It should be noted that you have to be online permanently for that to work. If someone manages to kill your Internet for long enough, they can still steal the funds in the channel afaik
@_date: 2017-12-20 20:55:31


Um... I'm gonna go with... insiders?
@_date: 2018-09-21 17:42:24
Just out of curiosity: The announcement specifically mentions that you timestamped "the hash of a test-case which demonstrates the inflation vulnerability". What purpose does that serve exactly? And why is it worth mentioning in the announcement?
@_date: 2017-12-28 09:57:23
Well, as long as you have a channel open, you need to monitor the network to make sure your counterparty doesn't publish a transaction that wasn't previously agreed to. Of course this monitoring will be automated, but it still has to happen.
@_date: 2018-09-29 14:42:28


Oh my. I do not want to hear your thoughts on the Linux kernel..
@_date: 2018-08-26 16:14:40
Nothing. From the PR description:


At some point in the future, this is supposed to replace bloom filters afaik (and maybe also txindex?)
@_date: 2018-08-03 20:03:52
Anyone else thinks that "bakkt" sounds like a stoner version of "rekt"?
@_date: 2018-05-01 08:37:30
I for one switched to radio-controlled watches and am really glad I don't have to wonder anymore which of my watches is actually showing the correct time. Hurray for centralization!
@_date: 2018-05-24 17:40:57
..unless the product is "store of value"
@_date: 2018-05-24 20:29:10
yes, but currently the median transaction fee is around 18 cents, and their minimum withdrawal is 0.1 btc (about $750), so by the time you get the free withdrawal, you have already paid $7.50 in offchain fees
@_date: 2018-05-24 20:24:57
It's 1% of your total revenue. So if you're the vendor, then for every 100 bucks you make, 1 goes to strike (it might be micropayments, but if you want to make a living from those, you'd have to generate a whole bunch of them).
@_date: 2018-05-03 08:06:43
I'm not sure why exactly, but this black and white with the jagged line somehow made me think of cows. Is there some milk/yogurth company that has a similar design?
Needless to say, I don't particularly like it. It looks less amateurish than the old version, but at the same time, it looks like it's trying really hard to sell you something. So not really much of an improvement, more like a different kind of (slightly) sucky
@_date: 2018-05-24 17:43:56
1% transaction fee seems kind of expensive
@_date: 2017-02-11 13:00:52
I think you may underestimate how easy it is to create controversy. Especially when it's about a complicated and dynamic system that most participants don't fully understand, and a lot of money is at stake. Just look at Global Warming for instance
@_date: 2017-02-11 19:07:35
My point was that you can create controversy about almost anything. Another example might be the whole "Smoking kills" saga that has been ongoing for at least 60 years now
@_date: 2017-02-08 13:52:07
So go ahead and kiss them! I mean seriously, if that is all that it takes to solve this impasse, it's a small price to pay.
Joking aside, some gesture of humility towards the miners may actually do the trick. I don't know a lot about China, but at least you always read that culturally, "saving face" seems to be an important concept over there. So if you could frame it such that it's not miners losing the scaling battle, but instead as miners graciously deciding to do everyone a favor and solving a problem, this might go a long way.
@_date: 2019-03-24 11:21:20
I've linked this from somewhere else in this thread already, but it applies here, too:
every change carries some risk, and for every change there will be someone who complains that it breaks their workflow (however misguided)
@_date: 2019-03-24 10:15:38


...and I bet when he read the replies he wished the mailing list had stayed down :-)
A lot of the protocol discussion seems to suffer from this phenomenon:
@_date: 2019-03-23 16:55:54
I guess most of them are still active somewhere in the wider ecosystem, only not directly in Core anymore
@_date: 2019-03-24 08:14:36


To me it seems like the default reaction to a PR a reviewer doesn't like is to simply pass it by. For example you could see this in BlueMatt's last PRs, where he was begging for reviews for weeks, but got practically no reaction. It seemed like the reviewers looked at it and said to themselves "he probably knows what he's doing, but I don't want to spend my time on this". So he was waiting and waiting for feedback that simply wouldn't come, which ofc is extremely frustrating.
Maybe there needs to be another category besides ACK/NACK that says "I looked at this PR but I don't feel like reviewing it" (let's call it MEH for the sake of argument). That way, the author would at least have an indication of whether or not there's still a chance of getting review (if the two or three experts in this particular area of the code all reply MEH, you can probably close/rework it) 
@_date: 2019-03-23 15:11:51
That doesn't make any sense to me: Pure style changes are forbidden by the contribution guidelines, tests are about the only things that have a chance of getting merged in a reasonable timeframe, refactorings are usually a prerequisite to new features (or otherwise the have extremely low priority), and the C++ intricacy PRs are almost all from one person (and usually get ignored over long periods of time).
IMO the problem is more that their attitude is as if they were writing the software for the space shuttle, only without the job security and unlimited budget a government agency has. Maybe this caution is necessary, maybe they're overdoing it. But at any rate, someone who just wants to make a difference by contributing to open source in their spare time will probably tell themselves that their time is better spent elsewhere after debating some minor change for months, rebasing it a dozen times, implementing and reverting conflicting suggestions and so on and so forth
@_date: 2019-03-23 15:47:53


Sure, makes sense. Only then don't complain that the UI looks like someone's university semester project from the late nineties and that new contributors run away screaming when they realize what kinds of hoops they have to jump through. 
Which incidentally might be a long-term security problem: The current maintainers will die off or move on eventually, so if they manage to scare away literally all newer constributors with their "perfect or nothing" approach, then the software will eventually become unmaintained
@_date: 2019-03-23 15:55:32
yeah, maybe. But there have been a number of departures in recent years: BlueMatt, cfields, Alex Morcos, Peter Todd, and probably more that I've missed. Not sure if the developer base is currently constant or shrinking, but at least I don't have the impression that it's growing
@_date: 2019-03-23 17:06:46
Yes, definitely. The "separate wallet/node/ui" patch series by ryanofsky was a nice preliminary step in this direction. Only it took almost two years (and probably a thousand rebases) to get it in, so I'm kind of afraid that he will burn out before this project gets anywhere 
@_date: 2019-03-24 12:50:12


TBH, that's a bit his fault, too, because he never writes a proper motivation (12802 is another good example of this). I remember seeing this PR before, and I was like, ok, so why is two better than one? Why not three or five or something? I mean from the linked morcos PR I kind of guess that maybe this is supposed to defend against some sort of slowloris attack, but why can't he just write it in his PR description? I guess it's probably obvious for someone who works on Core fulltime, but I always considered the motivation section of the PR description as being there to motivate people to review it (as in, if we do this, we get XX), and he really didn't do a good job at this
@_date: 2019-11-18 22:08:14
Considering that the utxo set has been growing by 500k every week for most of 2019, this really isn't all that much
@_date: 2018-10-12 19:16:11
Yeah well, we'll see how it all plays out. But at least on paper it seems to me that LN could actually become more capable in the long run
@_date: 2019-03-23 17:09:30
Yes, that's how jnewbery started out, and he seems to be about the only "newcomer" that the oldtimers seem to really respect (only my outsider's point of view, maybe I'm wrong). But I think I recently read that the test suite is pushing the limit of what is possible with Travis, so the question is how far it can still be extended
@_date: 2019-03-24 10:23:53


I think the reason some much stuff is done in software these days is because software is easy to change. Say for example someone could proove beyond any doubt that the train system would be much more efficient if the tracks were 10% further apart. That's nice to know, but doesn't help in practice, because it's just flat out impossible to rip out all the existing tracks, rebuild bridges, trains stations, trains, and so on and so forth.
In software otoh, if someone discovers that 32kb packages are more efficient than 16kb packages, you simply adapt the code, create a migration path, publish your new version, and in a year (or five) everyone will be on the new, more efficient system.
A software that cannot be changed loses the main reason to use software in the first place
@_date: 2017-08-12 11:35:59
I don't think blocksize is a big deal either, append-only databases are not sustainable in any case. In the long run, the size approaches infinity, the difference between 1mb, 2mb or 300k is just that it collapses a bit sooner or a bit later. So somebody really needs to find a way to discard old data. For example, I recently read on an old version of the scaling page in bitcoin wiki that at some point, they thought about removing transactions from old blocks once all the outputs were spent. What happend to that? It sounds like a great idea.
(in the meantime, LN might also be a good way to at least slow down blockchain growth)
@_date: 2017-08-19 14:44:43
tbh I kind of understand why they weren't invited. First of all, their position was already clear (no hardfork before the effects of segwit are evaluated, and if we can't have segwit, then we'll be fine anyways), and second of all, nothing good came of their participation in the previous Hong Kong agreement (other than a few research papers, the authors of which were called "well-meaning idiots" iirc)
@_date: 2017-08-21 17:26:16
Yeah, but in the end, the 21 million limit is still in place. So the next halvings will simply come sooner, i.e. in the (really) long run, inflation is still the same as in BTC
@_date: 2017-08-20 10:45:21


Actually, he talked about payment channels often. It's just that his design was insecure, so they had to come up with a new one before actually implementing it
@_date: 2017-08-14 18:19:43
especially that horrible music. Like a cheap knockoff of Hans Zimmer (who alreday sucks)
@_date: 2017-08-21 21:25:03


Right now, it's more like quintuple: 


Not the majority of _their_ users. And everyone else simply got a dividend on their BTC holdings, ranging from 6 - 24 %, depending on when you sold. I don't find that all that dramatic
@_date: 2017-08-09 20:49:45


That sentence really works both ways. I guess you don't see yourself as an enemy of permissionlessness either, but at the same time, you deny the s2x crowd the permission to make a change they want
@_date: 2017-08-14 18:14:34
Darth Ver actually has a nice ring to it :-)
@_date: 2017-08-21 17:33:29
I'm just saying, your post made it sound like BCH inflation would permanently be higher, but it isn't. In fact, right this second it's still lower than BTC, because they are still 750 blocks behind
@_date: 2017-08-20 21:23:47
Renaissance means "rebirth". Did crypto die and I missed it?
@_date: 2017-08-30 22:13:41
Even if, hashrate is continuously growing (new equipment coming online), and we _did_ have a difficulty drop at the last retargetting 
@_date: 2017-08-04 22:03:30
we're at 10 nanometers right now (if that's what you mean by nano scale), which is something like 20 silicon atoms, and yes, there's a number of alternative materials being mentioned from time to time, but afaik, they're all pretty much at the basic research stage still. I'm not saying performance won't improve anymore in the future, but it's naive to assume some line someone drew in a publication in the sixties will continue on the same trajectory forever (especially since it clearly hasn't done so in the last couple of years).
And not to rub it in, but it really is "officially" dead, as in the International Technology Roadmap for Semiconductors (which was based on it) is no longer updated since 2016, see 
@_date: 2017-08-08 18:34:45


So, are there any contingency plans for the possibility that core is the slower fork? 
@_date: 2017-08-30 21:47:08
That seems carefully worded, too :-)
for the complete picture, you should also add that the 8mins we're seeing now is (at least partially) caused by the same anomaly: Since it already began before the last retargetting, difficulty is now lower than it would have been without bch
@_date: 2017-08-01 19:35:18
yeah, I know. Was just trying to make a lame joke :-)
@_date: 2017-08-20 11:56:17
That would be really simple to implement, so I would guess if it were possible, it would already have been done
@_date: 2017-08-19 17:17:35
Dev team matters only in the long run: LTC for example managed to get by without any devs to speak of for the last four years or so
@_date: 2017-08-19 23:22:22
Yes, I think so, too. But it's a tough sell for miners, seeing how their livelihood will increasingly depend on fees
@_date: 2017-08-04 14:04:49
Yeah well, it's his job to say that. But look at the actual improvements they delivered over the last five years or so
@_date: 2017-08-20 11:55:06
I think if a way can be found to discard old data from the blockchain (which is more or less what you're saying, right?) then a lot of the scaling problems will go away. AFAIK utxo commitments are being worked on, although it's probably too early to tell whether they will really deliver all that is needed (and also when they'll be ready)
@_date: 2017-08-17 08:54:44
I think it might be relevant to looks at the interests of those arguing against it. Segwit enables/facilitates layer 2 solutions, which means (at least that's how most people see it) that you can do transactions off-chain and for lower fees. Miners currently earn their living mostly from the block reward, but that is guaranteed to go down to zero over time, and from transaction fees. So if there is an update that causes transaction fees to move to off-chain solutions, miners see this a a threat to their only longterm revenue stream. Whether or not it will really play out like this or not remains to be seen, but it's a risk to their business model, so many of them considered it prudent to at least stall segwit and push for on-chain scaling at the same time (I would guess in a bid to compete against off-chain solutions). 
And that's where many of those arguments came from. Which is not to say that it makes the arguments automatically invalid, but i think it helps to be aware of where they are coming from
@_date: 2017-08-19 20:16:15
If you think _you_ will get downvoted, wait till you see my answer :-)
What is wrong with it is that low fees &amp; fast transactions would mean more usage. But bitcoin (and all cryptos derived from it) has this horribly clunky design where you need to know the entire history of everything that happened to determine if the coins you have are even legit. Every transaction adds to this history, so every time anybody uses the system, it automatically becomes slower for everybody, forever.
Core devs usually say this in a more neutral and polite way (probably because they make a living working on this system), but that's basically what this is all about. There are those (including Satoshi) who believe this ever-growing baggage won't be a problem, because Moore's Law will make hardware speeds grow even faster than said backlog, but empirically, this hasn't been the case in the last couple of years (and it doesn't look very promising for the future either).
@_date: 2017-08-10 19:48:23
He who controls the bits controls the universe?
@_date: 2017-08-10 20:11:38
Hardware-wise I don't see how it could. It's a very small vertical market, so I doubt that any monopoly commission would bother with it. ofc it's theoretically possible that AMD or some other company with enough expertise and resources tries their luck at some point, but I think for now he's sitting pretty and would have to shoot himself in the foot pretty badly to endanger his position. BCH, BTC, S2X, no matter which one prevails in the end, Bitmain always wins (and they're manufacturing Scrypt ASICs, too, I read).
@_date: 2018-10-12 17:33:25
I would rather say Liquid is a stopgap which is useful while we're waiting for Lightning to mature. And it looks like that's going to take a while, based on the pace of development we've seen so far. Liquid is production-ready right now (or at least Blockstream claims it is), so why not use it for the next couple of years so that the LN people can develop their stuff in peace.
@_date: 2017-08-19 07:26:11
But they need to be able to do this for quite a while to repay their initial investment. Constantly switching back and forth will just make both networks unreliable and probably lower the price, so while mining the most profitable chain might work in the very short term, on longer time frames the cost/benefit calculation might look different
@_date: 2017-08-16 17:31:02
So how do I check my memepool for viruses? I tried running McAffee, but all it does is show an image of some old dude trying to give himself a blowjob
@_date: 2017-08-13 06:43:57
Pruning only deletes blocks from your machine older than a user-configured threshold. This idea was to make the blockchain itself shrink (which would also improve privacy, since old transactions would simply disappear from the system forever)
@_date: 2017-08-09 19:02:07
He said 16gb, so I'm guessing one of those terribly overpriced macbook pros
@_date: 2017-08-07 13:14:17
Yeah, that's true
@_date: 2017-08-07 18:42:45
it's not released yet (notice it's _Draft_ Release Notes)
@_date: 2017-08-09 18:59:24
So you think segwit locking in is a definitional failure of the Bitcoin value proposition? It only locked in because the aforementioned cluster of companies decided that it should
@_date: 2017-08-03 15:16:35


In fairness, that confusion was started by the segwit developers themselves. I distinctly remember reading about it in the first segwit concept post, which I unfortunately can't find anymore. But it's also in this video transcript (which is linked from 
@_date: 2017-08-20 10:38:01
@_date: 2017-08-10 19:51:52
it might just be a conspiracy theory, but he _is_ the only one manufacturing mining equipment in noticable quantities. So if he doesn't like you, you won't stay a miner for long
@_date: 2017-08-13 07:19:47
Good question. Like I said, I only saw this in an old version of the Scaling page in bitcoin wiki. It doesn't say how it's supposed to work, but apparently


@_date: 2017-08-17 21:29:39
Err, what? It sounds as if you think that the bitcoins somehow appear in the mining machines when a block is created. It works more or less like this: the machine finds a block and includes the coinbase transaction, which sends the block reward to an address of the miner's choosing. If the facility gets blown up before the block is sent to the network, it's as if the block had never been found (i.e. another will take its place), if the facility gets blown up after the block has propagated, the reward is already in the miner's address. And he will probably have multiple backups of the adress' private key in different geographic locations, so there's no way such an attack would make any sense
@_date: 2018-10-12 20:36:36
I don't think the points you list are completely accurate, but for the sake of argument, let's say that they are completely true right now. That still doesn't mean that it's impossible that in say five years from now, people will have come up with enough clever mitigations to make these concerns irrelevant in practice.
As for other shitcoins: Sure, why not. But they don't run on magic fairy dust either, but will have to put in the engineering effort and so on to make their stuff work. Proclaiming today that solution X will definitely fail and solution Y is superior in every way seems a bit premature to say the least
@_date: 2017-08-17 21:46:14
but the key can be backed up pretty easily and stored in different geographical locations. It's also short enough to print it out, engrave it into a piece of metal, or even memorize it
@_date: 2017-08-17 21:32:41
Bitcoins don't have a physical location. They exist (so to speak) in the blockchain, i.e. in all synchronized nodes. You can't destroy them unless you destroy every copy of the blockchain. You can, however, destroy the private key needed to access them. They will still exist on the blockchain (and in the utxo set), but nobody can move them anymore (unless the cryptography is broken ofc)
@_date: 2017-08-09 21:14:08
yeah, sure, but they don't want to make their own coin. They want to make a change to bitcoin. And that they cannot do
Not that I particularly want to defend s2x, but from their point of view, here's some guy that says "we're all in a permissionless system, which is great". Then they say, "cool, let's do X". Then he says, "if you do that, you're out"
@_date: 2017-08-04 22:42:25
Yeah, sure, progress won't stop all of a sudden. But the good thing about Moore's Law was that you could basically count on the fact that every two years or so, all existing programs would simply run twice as fast. Now, with all these alternative scaling methods, we need completely different architectures to take advantage of them (e.g. take a look at how long multicore processors already exist and how much software still can't effectively use that capacity)
@_date: 2017-08-07 13:05:00
Both only really occur for users that upgrade. The only diffrence is that in the softfork case, both upgraded and unupgraded are still on the same network
@_date: 2017-08-04 06:53:55
Moore's Law is already dead and gone:
@_date: 2017-08-21 20:27:02
Exactly. It's not a race, it's a marathon :-)
@_date: 2017-08-25 10:29:18
Problem is, you have to buy the miners from AntPool's parent company, so they win in any case
@_date: 2017-08-26 10:10:47
would be cool if he used the heat from a miner to pop the corn :-)
@_date: 2017-08-19 22:39:45
The citizens of York, Orleans and Hampshire agree and support you in your cause :-)
@_date: 2017-08-09 21:20:20
P.S.: I see that you changed my "s2x" to "s8x". Does that mean that you also write segwit4x for regular segwit? If not, you should, otherwise that Math doesn't work out :-)
@_date: 2017-08-19 07:29:17
So, does anyone have a list or something of wallets/services that will support/use segwit right away? Or do we have to wait for everyone to release new versions and such?
@_date: 2017-08-17 21:40:44
But the proper way to tell this conspiracy theory is ofc that the attack on North Korea will be to protect the dollar's role as the world reserve currency. The nukes are obviously just a red herring
@_date: 2017-08-01 17:49:52
The question is self-defeating: If we told you, it wouldn't be "effects that people aren't talking about" :-)
@_date: 2019-10-11 14:52:33
you can follow the progress here:
(PRs for implementations are usually linked there at some point)
@_date: 2019-10-10 22:01:31
There has been a steady stream of new releases and development efforts, but frankly nothing too exciting. More like really basic stuff, e.g. being able to make some sort of backup, not melting your machine when there are more than a handful of nodes, correctly handling all possible scenarios in the protocol and so on. In retrospect, I guess it's fair to say that the first releases were more like proofs of concept, and they have been working on turning this into actual production-ready code ever since.
Maybe amp (which at least seems to be on the horizon now) will give it a boost, but imho it probably won't be ready for the masses before we have something like eltoo (and that could take a while, since they still haven't figured out how to safely integrate it into the core Bitcoin protocol)
@_date: 2019-10-16 10:17:38


You think? Because intuitively, I would have thought that the failure rate would go up, since in regular payments, there's only one route that has to work, in AMP, there are potentially many routes involved, and if only one of them has a problem, the entire payment fails.
What amp gives you is a way to get around the per channel limit, and also a way to actually use your entire balance, i.e. you don't have to know the details of your channels to see if you can pay a particular invoice, only if your current balance is big enough. So for the user it's conceptually simpler (and more like a bank account/wallet as a mental model), but under the hood, there are more moving parts involved, so I'd think it would be more fragile
@_date: 2017-11-22 20:27:51
next year is in six weeks
@_date: 2017-11-16 18:19:01
If all the stakeholders in gold came together and decided that the global supply should really be doubled, it would still be impossible. Simply because you cannot change the laws of physics by referendum. The stakeholders in bitcoin could (in principle) make the same change very easily, it's literally just updating a few lines of code and deploying it.
And BTW: If a system of diverse actors can be changed by the actors negotiating and reaching an agreement on what should be changed and how, then the process of reaching that agreement is by any definition I know a political process. Any change made this way is hence a political change. So contrary to what you stated above, I would say that bitcoin can _only_ be changed through political processes. Saying it shouldn't be changed through politics is saying it shouldn't be changed at all. And if that's your position, then just state it outright.
@_date: 2017-11-15 21:23:24
Yes, bitcoin is like the weather in fact. Everybody has an opinion about it, but nobody can influence it... I don't suppose you understand how people could find this frustrating.
@_date: 2017-11-15 20:15:47
Wait, I thought childish insults and namecalling were the reddit's entire raison d'etre. Did I miss a memo or something? 
@_date: 2017-11-11 17:04:45
afaik yes, it's impossible to prevent mining empty blocks (simply because if you do prevent it, the miner can just fill them with garbage). otoh, empty blocks mean the miner doesn't get any transaction fees, so there's at least a minimal incentive not to do so (and as the subsidy decreases, the relative penalty gets bigger)
@_date: 2017-11-11 16:56:49
afaiu 0.15.2 has been more or less canceled. The segwit wallet release will be called 0.16 
@_date: 2017-11-08 09:32:46
There's also the fix for the problem that segwit change addresses were not recognized by the wallet, and some fixes related to wallet backups
@_date: 2017-11-12 20:30:22
This is all good and well, but if technological soundness and security are the key to success, how come Windows won the OS wars?
@_date: 2017-11-15 21:10:31
Don't get too excited. The test suite is still in the process of being built out, so they'll probably add a lot more tests (if you look at the overview, you can see the total number of tests increase between the runs). So they'll likely find more problematic scenarios. Also, just because implementations can talk to each other doesn't necessarily mean they are stable and secure and all that. 
A good way to gauge progress at least for lnd is  They said 0.4-beta will be first first release to support mainnet. So once those two milestones are achieved, we might be getting close to something useful
@_date: 2017-11-13 22:24:41
Won't happen. Greg Maxwell wrote some long angry rants about why he doesn't like doing roadmaps. You should be able to google them. I don't remember exactly, but it had something to do with not wanting to promise stuff they can't deliver, not giving the impression that development is centralized, and a lot of comparisons with Linux kernel development. Personally, I think it's silly, but what can you do. for better or worse, they are answerable to no one. So it's basically "it's done when it's done" and "if you don't want to wait, code it yourself"
@_date: 2017-11-11 16:55:15
the idea is just to make it harder to limit blocks to 1MB by accident (i.e. by having some forgotten old setting in the config), i.e. what F2pool seems to have been doing until a few days ago
@_date: 2017-11-17 19:25:53
I was re-using your gold example, which specifically said "gold atoms", not physical coins. Of course coins (a currency, i.e. a social/political construct, _not_ something found in nature) can be modified. Which is sort of my point: Physical coins can be modified, and so can virtual ones, because they're both made up by people. The mechanisms for doing so and they ways you can cheat them vary, but that's beside the point. 
What I'm trying to get across is that a comparison like the one you made earlier between gold atoms and bitcoin is as invalid as a comparison between magnetism and attractiveness 
@_date: 2017-11-09 18:25:50
Not really. You can fit only 1mb legacy transactions into a block, but (on average, based on current usage patterns) about 2mb of segwit transactions. So if everyone would be using it, not only would everyone get the 75% discount, but there would also be about twice the space available in the block 
@_date: 2017-11-16 08:02:12
Gold is a physical object found in nature basically since the beginning of time. Bitcoin is a software system running on a few computers for less than a decade. It is simply weirding me out how developers can start a cargo cult about their own project.
Edit: To put it another way: What irritates me is that the creators of bitcoin constantly seem to refer to it as though it was something found in nature, when it so so very clearly a man-made construct. Made by themselves, no less! I just don't get how anyone can reconcile these two positions
@_date: 2019-02-14 21:47:04
I gotta say, it is a pretty smart business idea: The people who (at least in their opinion) can benefit most from high fees on btc can now pay Veriblock to create a mass of transactions that not only raise fees, but at the same time make their own crypto more secure. Win-win achieved! 
Edit: Oh, and most of the fees generated this way will go to the miners in the end. Somebody really thought this through
@_date: 2017-11-11 16:58:40
there's nothing related to replay protection in this release, it's mostly p2p/dos protections
@_date: 2017-11-10 13:59:34
doesn't mean they won't seel it when they get it
@_date: 2019-12-02 22:29:32
The problem with that is that will get you overrun by botnets
@_date: 2017-11-23 12:01:48
isn't that what the assumevalid option does?
@_date: 2017-11-12 20:56:36
What I wonder is, why was it even worked on before segwit wallet support? It seems kind of backwards to add advanced segwit functionality before Core can even fully handle the basics. I mean, the s2x timeline was known well in advance, so if all the time invested in coding, reviewing and merging the bech32 stuff had been spent on segwit wallet support instead, you might have been able to squeeze it in before the p2p stuff became urgent, no? 
@_date: 2017-11-07 23:15:59
How (and since when) does "game of life / cell automat" qualify as AI? To me that sounds like some sort of virus at best (admittedly without researching it much futher).
And ignoring for a minute whether or not the claims have merit, I can't really figure out what "AI on blockchain" is supposed to be good for (except stringing together two buzzwords ofc :-)). Does anyone have some possible usa case for this? Because to me building an AI in some cryptocurrency's script language sounds about as useful as trying to write a word processor in brainfuck
@_date: 2019-12-02 22:27:00
actually, it's a Russian proverb:
@_date: 2019-12-05 16:40:29
They will probably be recovered once Quantum computing is sufficiently advanced. Encryption schemes don't last forever
@_date: 2019-12-05 18:16:49
10^256 seems a bit much (in fact, I'm pretty sure that's more than the number of atoms in the universe), are you sure about that number?
But anyways, coins that are lost today will still be lost in 20-25 years, meaning their former owners can't move them to something that's Quantum-safe. So they're basically just sitting there waiting to be taken (which is why some people say lost bitcoins are in fact like a bounty for developing Quantum computers)
@_date: 2017-11-13 07:43:33


u/pwuille seems to disagree:




@_date: 2019-04-11 20:18:16
the schnorr bip draft has been out since last July:
@_date: 2019-04-10 15:11:37
From what is publicly visible, the answer to your question is "not at all".
ppl are probably working on it in private repos/channels, though. The only publicly visible thing I know of is this:
But PRs in that repository seem to be moving only on geologic timescales, so I have no idea how long it could be before this gets merged. Once it is, it would need to be imported into bitcoin core, and then somebody can write a PR that actually makes use of it. And then, some timetable for activation needs to be proposed, discussed, implemented, rolled out and so on. If I had to guess I'd say end of next year is probably the earliest you could see any of this in production
@_date: 2018-03-28 15:36:38
[citation needed]
@_date: 2017-09-12 16:51:02
Bitcoin Core wallet doesn't support making segwit transactions yet (you can only do that on the command line with a function that is intended for debugging mostly)
@_date: 2017-09-10 18:02:15


I read that a lot, but is there actually a provision in the NYA that prohibits the signers from supporting other sha256 coins? AFAIK all it says is that they promise to signal Segwit on Bitcoin, which they did.
@_date: 2017-09-02 13:36:40
you can make those graphs yourself: Just select the coins you want to compare: 
@_date: 2017-09-05 18:08:31
I bet you're fun at parties :-)
@_date: 2017-10-12 15:56:44
It would be great if they could also remove the 1MB limit, none of the blocks they mine is full...
@_date: 2017-09-12 15:40:20
segwit support is going to be in 0.15.1, so I would guess more like six weeks
@_date: 2017-09-10 10:16:00
but if you convert them to btc, the vendor gets paid in btc, and a corresponding transaction is produced. So shapeshift et al. really don't solve anything 
@_date: 2018-02-09 19:17:09
Well, they obviously know what they're talking about :-)
@_date: 2017-10-16 16:44:55
no, not really. the biggest they ever go is 1000.04 MB according to coin.dance. But if you look at the block weight, they are never close to 4 million
@_date: 2017-09-10 10:13:43


As far as I understand it, what they have solved is the mining/transaction fees issue. As in, they don't need miners and thus you don't have to pay them. But their ledger still grows indefinitely just like bitcoin's (The difference is only that it's not in discrete block intervals, but continously, i.e. transaction by transaction)
@_date: 2017-09-12 16:49:08
I'm referring to the wallet part of Bitcoin Core specifically
@_date: 2017-10-05 21:18:22
if you want to use segwit change addresses with bitcoin core, there's a patch for this: 
@_date: 2017-09-08 10:04:24
but it's also about six months away (and that's not counting possible delays), by that time, bitmain may well have something comparable 
@_date: 2018-02-09 21:53:24
Well, if I _don't_ batch, let's say I have ten transactions, each of which has two outputs (recipient + change), so 20 in total. If I _do_ batch, I have one transaction with 11 outpus (10 recipients + change). So batching should cause the number of outputs to go down, no?
@_date: 2019-09-11 10:15:52


yeah, that's a bit the problem. Attention spans today are not what they used to be in the late 19th century. Also, if you're over 50, does it even make sense to read up on crypto? By the time it is sufficiently developed, you'll probably be so senile &amp; frail that the future of money is the least of your problems
@_date: 2017-09-12 13:15:32
... or at least Core
@_date: 2018-04-26 18:52:02
For starters, only one of them was created through a fork. If you had any bitcoin software running before the fork (or if you install an older version today for some reason), it would follow the btc chain. The bch chain has different consensus rules
@_date: 2018-04-23 10:12:38
Just out of curiosity: Who is that guy, and why does he dress like a vampire hunter from a Steampunk novel?
@_date: 2018-04-25 14:07:59
Why? If e.g. if 1BTC is mined to A, then sent to B, then to C, and then to D, it is really only necessary to know that the bitcoin went from A to D, forgetting about the intermediate steps B and C doesn't really change anything about the current state of the ledger
@_date: 2018-04-17 17:42:02
No, I'm just really really lazy :-)
Also, I wouldn't use a ledger in public anyways, so the proposed attack is really only theoretical for my use case
@_date: 2018-04-14 21:30:41
VERy funny
@_date: 2018-04-25 16:36:55
Question is: Did anyone ever try to implement this? I know there's some work on UTXO commitments, which would achieve something similar (but probably more efficient afaict), but I've never seen any work on "in-block pruning" (or however the correct term may be)
@_date: 2018-04-26 20:44:23
but they all still follow the same ruleset (consensus)
@_date: 2018-04-30 19:34:38
I only skimmed it, so this might not be exactly accurate, but maybe it points you in the right direction: The current mechanism tries to ensure honesty by threatening retribution for offenses. Something like: If you do X, I can retaliate with Y and take your money. So for each X they can do you need to prepare a Y and have it handy in case they try something. Because once they make it to the blockchain, it's game over.
The proposal goes something like: Each participant gets exactly the same (not yet broadcast) transaction to close the channel (and then newer ones when the balance changes). The trick is that this transaction contains a clause where (roughly speaking) its output can be redirected by a newer transaction from the same participants. So you don't have to watch the mempool for transactions that try to steal from you, you can simply wait until they make it into a block and then publish your newer transaction which takes its output (thus the attacker loses the fees and gains nothing).
 
Like I said, I only skimmed it (and I simplified a bit in the middle, it's actually two transactions I think), so maybe it's not all that accurate. Corrections welcome! 
@_date: 2018-04-17 14:01:05


I know they mean well, but this is another fine example of how the quest for security destroys usability. No more muscle memory to help you enter the pin, now you have to stare at the the display constantly, just so that some theoretical user can enter their pin in public without some theoretical eavesdropper breaking their code. It would be really nice if they made this optional
@_date: 2018-04-14 20:32:05
No idea, but I'm pretty sure somewhere there's a subreddit full of people pondering these questions. In r/bitcoin it's kind of off-topic though
@_date: 2018-04-30 10:16:01
Question is, why would I want to do that as an employer? Usually, the customers don't pay right at the very second my employee does the work, so I would have to front the money, negatively affecting my cash flow
@_date: 2017-05-12 21:58:32
Well, the thing is, if LN becomes ubiquituous in the sense that everyone has an open channel and you can do all your transactions through it, the perceived lock-in becomes a non-issue. The channel will be like a bank account then, your salary or whatever is credited to it and your shopping is debited. Doing a standard transaction would then be analoguous to withdrawing cash from your bank account, i.e. always possible, but not used in the majority of cases.
And the thing about prefunding is a lot less drastic then you make it out to be I think, if someone transfers funds via your node, the corresponding sum will normally only be blocked for a couple of seconds (the time between you sending the transaction to the next hop and the response it passes back to you from the final recipient), so you would only need one billion if this million users each want to transfer all their money in the same second. At least that's how I read it in the documentation 
@_date: 2018-04-14 15:22:44


Not really. The idea of nation-states (i.e. where a political entity was largely comprised of one ethnic group) became popular in the 19th century, and nationalism was a major factor in things like WW1. Before, there were mostly empires (political entities comprised of multiple nationalities), like the Ottoman empire, the British empire, or the Roman empire if you want to go back further. Not that those were exactly peaceful, but nation-states weren't really an improvement in that regard either 
@_date: 2017-07-06 21:30:04
Yeah, you could argue about semantics for sure (e.g. the exact definition of decentralized), but let's leave that to people who actually care about eth :-)
About illegal (in some jurisdictions) dapps: I guess they could go for a utility-like defence, i.e. "we only provide the platform and have no control over how ppl use it". Same as how a telecom can't be held responsible for someone using a phone for blackmail (or Twitter for spreading ISIS propaganda)
@_date: 2017-07-15 09:02:09




So, if you had to decide between living either in North Korea or in the US, you could go either way because you see the two as equivalent (ignoring the difference in wealth for the moment)? I'm not saying the the US is great, but not making any distinction because "they all suck" is probably the fastest way to turn every place into North Korea 
@_date: 2017-07-21 18:42:32
at least not deliberately :-)
@_date: 2017-07-08 13:53:48
The thing you have to realize is that witness data is prunable, so it doesn't need to be kept around forever by every node. And due to the way the weight calculation works, the unprunable part of a segwit block will almost always be smaller than 1MB (it can only be exactly 1mb if there is no witness data whatsoever).
So as crazy as it might sound, segwit is both an increase and a decrease in blocksize at the same time :-) (increase as far as bandwidth and validation is concerned, decrease as far as long-term storage is concerned)
@_date: 2017-07-05 19:55:23
I think by legacy limit he means that the part of transactions visible to old nodes cannot exceed 1MB (otherwise it wouldn't be a softfork, right?)
My understanding is that if segwit was active and you have a block containing no segwit transactions whatsoever, its weight would be 4000000 when its size is 1MB. If you have a block of only segwit transactions with a weight of 4000000, the part visible to old nodes (so more or less the transactions without signatures) still would be smaller or equal to 1MB (because it's multiplied by 4 in the weight calculation).
Since Schnorr only affects witness size (it can't be used for legacy transactions, right?), it only affects the part multiplied by 1 for the weight calculation, so it won't really make room for additional transactions (which necessarily include a *4 part), unless the signatures' combined weight in the block is over 3000000.
Or am I missing something?
@_date: 2017-07-08 12:22:27
well, it creates a certain inertia. The more ppl have invested in something, the more they will try to protect that investment and the more hesitant they will be to abandon it. 
@_date: 2017-07-10 21:54:02
it actually was discussed, see  for example. But I guess they never implemented any of their ideas
@_date: 2017-07-08 17:22:13
Come on, give the guy some credit. He did a lot of work on Linux SATA drivers back in the day, and Linus isn't exactly known for being tolerant about bad code quality.
@_date: 2017-07-14 20:56:50
Yeah, I did, and I'm not saying that I like the PRs, I was just pointing out that the OP was a bit overly sensational for my taste (and the followup is still different from the screenshot in that it at least leaves the other seeds in there instead of removing them)
@_date: 2017-07-07 23:03:13
Bitcoin doesn't have any physical properties, it's just a bunch of data that is completely useless if you lose power or internet access, so I don't really see how the comparison to gold applies. 
It's also not that established yet that it can rely on inertia to keep its top spot (I mean, face it, much of the "market cap" is lost coins or earlier adopters sitting on 100000% profit they can't hope to realize without crashing the market), so if another software were to implement the things bitcoin can't, I don't see why ppl would continue to use an (in this hypothetical scenario) outdated system.
@_date: 2017-07-15 08:46:33


I dont know how you define "recent", but this happened less than a month ago:
@_date: 2017-07-14 15:44:10
This is not by Garzik, but by someone named kleetus, and the PR was closed (i.e. not merged), so it's a bit flamebait. If you wanna get mad about something, at least use current followup PR: 
@_date: 2017-07-06 19:14:47
AFAIK, ethereum never really aimed to be a highly-decentralized, grassroot type of project (but I gotta admit, I don't really know much about eth). So why would anyone be upset that they are a corporate coin? Works as designed, I would say.
@_date: 2017-07-14 19:27:11
That happens a lot at a certain income level (and I think by now he's probably rich enough that a million more or less doesn't make a big difference): When the material needs are taken care of, ppl suddenly start worrying about their legacy, pick pet causes or spend their time with personal vendettas and the like. Just look at all the stupid stuff Silicon Valley bilionaires are pushing  
@_date: 2017-07-08 12:33:55
If you're sure about b), why not accept the 2mb increase? What's the difference between a half-empty 2mb block and a full 1mb block? (yes, the numbers are not correct, but you know what I mean)
a) is a great oppotunity to say "I told you so" when it really happens and might shut up overeager hardforkers for a long while, and c) is not something we really need to consider today. 
I'm not saying there definitely needs to be a HF right now, but your three points are kind of weak
@_date: 2017-07-02 18:25:57
I think what OP was trying to say is there's no direct monetary compensation for running a node. It only costs time and money (hosting, electricity, maintenance and so on). As the blockchain grows larger, it becomes more and more cumbersome to run a node, so the number of people doing it will probably go down. By running a node, you're basically doing everyone else in the ecosystem a favor since everyone benefits equally from decentralization, while you're stuck with the bill. From a financial point of view it is thus more efficient to let the altruists and the true believers do the work for you.
@_date: 2017-07-05 20:42:04
I thought about it some more and I think I figured it out now: My last calculation was wrong, right? i.e. if you have 3MB (== 3mil) witness data, you don't have 1MB left for the rest of transaction data, but in fact only 250KB (multiplied by 4 equals 1mil). And thus a block exactly 4MB big would have to consist only of witness data.
It's actually funny, because I think most people currently assume that segwit gives you 1MB for transaction data and then on top of that up to 3MB for witness data, when in fact the 1MB that an old node sees can only ever be reached if the size of extra witness data is zero. I'm surprised noone in rbtc has made a "segwit decreases blocksize" mem out of this :-)
You're right that technically there is only one limit, but not all data is weighed equally, so to get back to the Schnorr example: If Schnorr saves 400kb of space in the witness section, you will gain (for example) 100kb for legacy transactions (assuming the block is full), is that correct?
  
@_date: 2017-07-08 14:14:35
If you're on core 0.14, you don't validate older transactions anymore (see  headline "Assumevalid"), so old signatures are essentially dead weight. My guess would be that some future version will offer the possibility to either not save older witness data or skip its download altogether, and that there will be a new level of node in-between full node (all transaction history + all signatures) and pruned node (last X mb of transaction history). So you would have all the transaction history, but only as much signature data as needed to properly react to reorgs. No idea if it will really happen, but that's the way I figure.
@_date: 2017-07-10 20:38:13
Yes, he does, although it might be a bit dated by now. Ten years ago he was one of the bigger names there, and was actually the only Bitcoin developer I had heard of before Bitcoin becamse a thing (e.g. he was the maintainer for the SATA subsystem. It's kind of hard to google this old stuff, but he's listed here for example: 
@_date: 2019-05-24 21:11:13
so did I hear this right that his best guess is that this will be ready for production in two and a half years?
@_date: 2018-12-03 12:04:00


Oh? Security of what? Of everyone's balances I suppose. And how do those come to be? By transactions. Which are in blocks. And which will be the only incentive to produce blocks once the subsidy falls to negligible levels
@_date: 2018-12-03 22:47:09


Yeah, but the reduction is logarithmic. After the seventh halving (in 18 years or something), the reward is already below 1 btc. At the tenth halving, it's at 0.1. 


Yeah, that's the thing: Just because miners stop mining doesn't that the hardware will disappear immediately. On the contrary, when miners give up, you can probably buy it off them for very little and use it for things that wouldn't have been feasible economically before (like attacking). 


Yeah, but a block without a transaction wouldn't pay out the block reward, so why would anyone spend energy to create such a block?


and the paying out is recorded as the first transaction in the block: 
@_date: 2018-12-02 19:39:16
You're missing the point: If gold mining were to stop, gold owners wouldn't care (actually they would probably be happy, because their asset will not get dliuted by new supply any more). If Bitcoin mining stops, Bitcoins become more or less worthless, since you can't make transactions anymore
@_date: 2018-12-02 19:03:44


I'd say that's a function of its value (and the fact that it's a bearer instrument). In principle, you could put your gold whereever (bury it in your back yard f.x), and no harm would come to it. It's more paranoia and regulatory concerns that make storage expensive. And when I look at all the crypto custody solutions in development, I don't get the impression that they will be significantly lower-cost.  


Exactly. The two basically have nothing in common, other than that people consider them valuable. That's why I find these Gold 2.0 threads mostly silly :-)
@_date: 2018-12-02 22:04:47
No, what I'm trying to say is that gold mining is decoupled from the usefulness (and for the most part, the value) of gold. While Bitcoin cannot exist (at least in a useful form) without mining. 
Or to put it another way: "Mining" is a terrible name for the block production process, because it gives people a totally wrong idea of what its purpose is, and invites stupid comparisons (like the article linked in the OP)
@_date: 2019-05-10 18:16:21
it is blocked by  (see  I've read somewhere else that the actual implementation is pretty simple once everyone agrees on the format, but I'm too lazy to search for a link on that
@_date: 2017-06-26 07:02:27
I could be wrong, but the way I understand it, it only affects the signature portion of the transaction. In segwit, there are 3mb of space for signatures and 1mb for the rest. Schnorr won't affect the 1mb bottleneck, it only means that less of the 3mb is used. I'd call it an efficiency (and potentially privacy) improvement, but I'm not sure if it can actually do that much for scaling
@_date: 2018-12-04 18:50:19


Yeah, ok, I concede that maybe the definition of "empty block" is wrong :-)
@_date: 2017-06-14 12:38:29
Maybe that's part of the problem: If the only thing that Core as a collective can (more or less unanimously) do is to say no to an idea, then there'll be stagnation. IOW, I can understand that you (as an individual or as part of subset of Core developers) don't want to impose your vision of Bitcoin on others. But simply saying "it's not my/our place to decide" effectively becomes avoiding responsibility at some point. 
As for "Bitcoin is fine the way it is": Maybe, for now. But every time I read this statement, it reminds me of this line from La Haine:


@_date: 2018-12-03 17:52:46


I mean that the block reward is halved every four years. E.g. in ten years, it'll be less than 2 btc and it'll continue to go down until it's basically zero. So the only long-term source of income for miners is the transaction fees, which is why I found your statement that mining has nothing to do with transactions kind of amusing. And again, what are the miners securing if not transactions? (even if it is only the coinbase transaction that pays them the block reward)
@_date: 2017-06-15 07:54:14
I didn't mean janitorial as an insult, where I come from, its a term that deisgnates a certain type of development tasks. There is (or used to be) a Linux kernel janitors conference, and as far as I know, it is not a place where they send bad engineers as punishment :-)
So what you're saying is basically that you don't have to care about specific improvements because Bitcoin itself is some sort of historical inevitability? I gotta admire your optimism, but would refer you back to the La Haine quote above: Bitcoin is fine until it's not. And when it's not, it's by no means certain that it could make a comeback. There's plenty of other projects out there that are willing to get their hands dirty with politics &amp; marketing instead of letting their work speak for itself (which IMO is a noble, but very naive sentiment)
@_date: 2017-06-16 17:09:26
I'm just trying to see things from the miners' point of view: The block reward is guaranteed to continue to fall (rising exchange rates might compensate this for a while if they're calculating in fiat, but that won't go on forever), while so far, fee income has been rising thanks to the rising number of transactions. The number of transactions can't rise anymore since blocksize limit is reached (currently, this is canceled out because the fees per transaction are rising, but that can't go on forever either). Now segwit comes along and offers a one-time increase in capacity, but coupled with a discount, which (at least on the face of it) means that miners have to do more work to achieve a similar fee revenue. At the same time, segwit paves the way for the Lightning network, which means that miners won't participate in any potential future growth in transaction volume (I remember some devs even saying that with LN block space usage might go down to something like 300kb).
I'm not necessarily subscribing to that point of view, but I'm pretty sure this scenario came up in the miners' cost/benefit analysis for segwit. There are of course a lot of things that could be done to mitigate (for example, miners can become lightning nodes themselves), but still it's a risky change for them at best. So in retrospect I would say that either there should have been some specific incentive for them (not just the generic "a rising tide lifts all the boats"), or the change should have been made in a way that  is impossible for them to block.
Asicboost may or may not have been a factor in this (AFAIK it hasn't been conclusively proven yet, but correct me if I'm wrong), but I think the reasoning mentioned above is sufficient to explain their reluctance/resistance, especially since Core sent the message that they're ok with segwit falling through (for now)
@_date: 2017-06-16 08:07:30
I would argue that the biggest immediate threat to the stability of Bitcoin is the prospect of Bitmain and the UASFers battling it out on the live network come August 1st, which is a direct consequence of segwit's failure to activate. Of course, it's possible that it'll all blow over and nothing bad will happen, but I think this whole mess might have been avoided if Core just put a little more effort into convincing the ecosystem to adopt this change. 
From the game theory point of view, you could also say that the biggest flaw in segwit's design was its activation method: It threatens the miners' only longterm source of income and at the same time hands them a very easy way to block it. This wasn't caught in review, which is unfortunate, but can't be changed now. But once it became apparent, some mitigation should have been attempted instead of letting things just play out (which is what gave an opening to big blockers, uasfers, barrycoiners and the like)
@_date: 2018-12-02 17:29:13
Yeah, but the difference is that if Gold mining were to stop completely, the gold would still be usable. Bitcoin, not so much
@_date: 2017-06-25 14:28:14
just out of curiosity: Does anyone know if there's any logic to the BIP numbers? I mean, how does "Reduced activation threshold segwit masf" have the number 91 while segwit itself has 141 although it was published two years earlier (according to the chart at least)? I would have assumed numbers are assigned more or less in the order proposals are published (or accepted or whatever), but clearly, I'm missing something 
@_date: 2017-06-12 12:34:14


obligatory xkcd: 
@_date: 2018-12-03 12:05:28
I'm nt saying that mining will stop. I was using the hypothetical scenario to illustrate that mining is necessary for Bitcoin to be useful. As opposed to Gold, where mining only serves to dilute existing holdings
@_date: 2018-12-04 12:17:12


My point was more that the subsidy will become negligible, and that transaction fees will become the main motivation for creating blocks


which is technically a transaction, too (it's called the coinbase _transaction_ after all)
@_date: 2017-06-14 13:24:36
Yes, you're right, I was exaggerating a little bit there. And maybe I'm not getting the entire picture, but to me it seems like even segwit support was a bit lukewarm, at least at first. For example, I distinctly remember you and some other devs saying something along the lines of "I don't care if segwit activates", which to me as an outsider doesn't sound like a glowing endorsement, but more like "we've run out of reasons to reject it"
- Edit -
P.S.: Don't get me wrong, for janitorial tasks (fixing build issues, improving tests, refactoring, keeping dependencies up to date, improving performance and architecture and so on), the Core process works really well (and I suspect most of the thousands of things you mentioned fall under this category). I don't think even the craziest Core hater will complain about your work in that regard. But when it comes to "bigger picture" conceptual things, it's easy to get the impression that Core retreats into a comfy "I'm just an engineer" position where they confine themselves to listing reasons why idea xyz doesn't work. Individual devs might then work on some alternative solutions, but once they complete the technical steps (whitepapers, peer review, implementation, testing etc), they are thrown over the fence so to speak, and the wider community is told "this is what we came up with, you can take it or leave it". Core as a whole staying neutral on the proprosed change instead of actively recommending/promoting it is what I meant by Core being unable to say yes