@_author: bu-user
@_date: 2017-03-27 17:30:43


Why are we waiting for 95% of blocks mined by miners to activate Segwit then?
@_date: 2017-03-30 16:12:34
Or classic, or as you say, just recompile core with a higher limit. 
@_date: 2017-03-19 08:22:50
Emergent Consensus is exactly what Cryptocurrencies are designed for. 
@_date: 2017-03-24 12:02:18
It seems like we must be told what the current consensus is now, rather than allow consensus to emerge through mining in the way it was originally meant to happen. 
@_date: 2017-03-19 13:17:31
Can you explain how a current SPV wallet, such as breadwallet, will reject any &gt;1MB blocks if there is a majority BU fork?
SPV clients don't verify the blocksize. 
@_date: 2017-03-12 22:26:22
If 30% of miners decide that block is invalid, and 70% of miners decide it is valid, you will split the network.
After the first "invalid" block, the chain with the greatest hash rate (70% in this example) will quickly find another "invalid" block. The minority chain will reject it. And so forth. 
@_date: 2017-03-20 06:58:01
The problem is this - these 2nd layer solutions are years away. We need the ability to scale now in a safe and conservative way. 
There was an agreement last year in Hong Kong which said segwit would be released and the base blocksize would be increased to 2MB. Unfortunately this 2MB code was never written.
Segwit offers a tiny increase, BU's emergent consensus protocol allows miners to slowly and conservatively raise the blocksize over time as technology improves. Over time the networks ability to propagate larger blocks increases, improvements such as xtra thin blocks and compact blocks help with this. 
@_date: 2017-03-24 18:11:57
I think perhaps people should have read the white paper before investing, it's very clear that miners vote with their hash power. 
No where in the white paper does it say that we should vote on pull requests to one central code repository. 
@_date: 2017-03-15 22:02:35
They aren't, they are decentralising the control of one parameter, the blocksize. 
@_date: 2017-03-12 21:43:34
This is a hard fork though. Right now around 30% of blocks mined support Segwit. If this was introduced now, you would end up with two chains. 
A minority chain, with 30% of the hash power with Segwit activated, and a chain with 70% of the hash power behind it not running segwit. 
Are we saying hard forks are ok now?
@_date: 2017-03-09 16:21:12
I'm also confused that it's possible to identify bugs in code that doesn't yet exist, but we have now clarified that BU does not yet include any flex tx code. 
Please can you identify bugs within the current version of BU which need resolving. 
@_date: 2017-03-21 14:56:50
There is nothing to stop someone compiling a core node, but have it follow EC rules. In fact there is a project working on this now. Which will for all intents and purposes spoof a core node. 
@_date: 2017-03-28 16:29:08
Is that including jumbo frames?
@_date: 2017-03-20 16:52:05
Segwit and RBF, to give 2 examples, were not part of the original code base, so can't be considered as the standard code. 
The 1MB block limit was not part of the original code base. 
If you change the POW, that's not part of the original code base either. 
@_date: 2017-03-16 21:37:58


I think this very much depends on who has the majority hash rate at the time this proposal is activated. 
Lets say at the time, segwit only has 30% support from the miners. Segwit miners and nodes begin rejecting non-segwit blocks and start to follow their own chain of segwit supporting blocks.  
However, 70% of the hash rate is continuing to mine non-segwit blocks and so is able to generate a longer valid chain of blocks with the most proof of work. 
This means that non-segwit nodes will follow this chain, this includes core nodes which have not upgraded 
@_date: 2017-03-21 14:38:13
Does your spv wallet connect to any node on the bitcoin network or a list of nodes supplied by you? 
@_date: 2017-03-16 16:20:13
Can you explain why they would do that? 
@_date: 2017-03-13 18:43:45
If the past 2 years have demonstrated anything, it is that miners are *extremely* cautious when it comes to raising the blocksize. Miners will not produce a block larger than 1MB until the network is ready. 
Contrast that approach with [this]( one. That approach recommends the following (my bold):


That approach will mean that even if the Segwit supporting hash rate is in a minority at the flag day activation point, Segwit supporting miners will begin **rejecting** non-segwit blocks. 
That seems hostile to me. 
@_date: 2017-03-21 13:56:42
And if they talk to a BU node? 
They will see the new chain and then will reject the old one from that point onwards. 
See [here](




















@_date: 2017-03-21 06:46:23
Samurai wallet is an spv wallet. Like all spv wallets they don't verify block size. They look for the longest chain with the most proof of work. 
Should we fork to a larger blocksize with a majority of the hash rate, Samouri wallet users will follow this chain. 
@_date: 2017-03-09 17:06:01
This issue is mitigated with the recent parallel validation enhancement. See [here](
@_date: 2017-03-24 20:02:08
Please explain why they would propose to adjust this cap. 
I don't see any proposals to adjust the 21M coin limit. 
Also I don't see any mention that there should be a 1MB cap on the blocksize in the white paper either. What is mentioned in the white paper, what we all signed up for, was that miners should vote with their hash power in order for there to be decentralised trust-less consensus. 
Lets check again what it says:


valid blocks by working on extending them and rejecting invalid blocks by refusing to work on
them. **Any needed rules and incentives can be enforced with this consensus mechanism**.
It does not say anything about rules and incentives being enforced by voting on pull requests on a centralised code base.
 
@_date: 2017-03-26 18:08:14
Absolutely right, plus we have the name of the white paper: 


@_date: 2017-03-09 06:59:00
If you are against Bitmain partly funding Bitcoin Unlimited development. Are you against Blockstream employees being paid to work on Core development?
@_date: 2017-03-11 12:45:23


Can you explain why you think this is a good thing? 
It's only required to promote the use of segwit transactions. If all transactions were segwit transactions, then the only difference between them would be their size (bytes). So in effect, they would revert to being compared by their bytes.  
@_date: 2017-03-20 17:41:57
Actually, I think RBF was a huge change to the fundamental protocol as it broke zero confirmation transactions. 
How about the fact that the 1MB blocksize limit was not present in the original code base and added later?
@_date: 2017-03-14 18:52:59
Are we saying Core has never contained, or will ever contain any bugs in the future?
That's a rather high bar for any software project to set. 
@_date: 2017-03-09 16:27:53
Those relate to a bug which was fixed. Core had a bug before which caused a fork, so it's evens in that regard. 
The rest are concerns about larger blocks. Please point to lines of code within the current release which are buggy and require fixing. 
@_date: 2017-03-20 14:02:46
How would you stop miners from deciding what code to run? 
Unless you are trying to centralise decision making, I don't see how it is possible. There is always the risk someone won't agree with you. 
@_date: 2017-03-29 05:56:32
For many users, this will be the first time they have ever run a non core node. Perhaps this will plant the seed that it's ok to not run core. 
@_date: 2017-03-15 16:45:43
Can you explain why 90% is too high? I haven't said it would be 90% who compile from source, but I'm interested as to why you think that is an outlandish figure. 
@_date: 2017-03-13 05:40:06
Old clients will follow the longest chain with the most proof of work. 
Only new clients will reject non segwit blocks. If the segwit chain has the minority hash rate, old clients will follow the the non segwit chain. 
@_date: 2017-03-19 13:23:15
So if they connect to a BU node at any point, they will see this new BU chain with the most proof of work. After that they will reject the minority chain. 
See [here](




















@_date: 2017-03-09 19:57:36


What happens when 1% of the network is not happy with high fees, and they leave, and then the next 1%, and they leave? 
It's a balance. At the moment asics are expensive and are improving quickly so that it is hard to keep up. Eventually this rate of improvement will tail off, many people will be able to afford a reasonably powerful asic that won't be quickly outdated, with reasonable power consumption. We have seen this with every other tech, there is no reason this won't happen with asics. 


Bitcoin has and always will be an arms race, its the nature of the beast. If one group grows to big however they risk people losing confidence in the decentralised nature of the currency. This is yet another natural limiting factor. 


I absolutely agree with this, I really do. This is why we need to raise the blocksize. The people who really need Bitcoin, the people who don't have ready access to the banking system have been priced out. Now transaction fees are approaching $1, this is too high. I'm perfectly fine if people need to transact quickly they can choose to pay a higher fee, but allow some low paying transactions to be confirmed. 


Miners are an extremely important factor when it comes to consensus within Bitcoin, the single biggest factor. I accept full nodes also play an important part, but miners are the ones who are securing the network. No matter what pow you use, miners will be the ones who have invested the most resources into their equipment/hardware to run their operations. It has to be this way or else the network is susceptible to attack. 


Right now we, or at least up until very recently we had one main client. That is not a healthy situation. I would rather allow consensus to be formed using Nakamoto consensus, rather than by voting on pull requests submitted to a github repository controlled by a few select people. 
For Bitcoin to grow, we need to onboard more users. To onboard more users, we need more space to accommodate them.  Segwit is not enough, its too little, even if it was to activate today. 
 
@_date: 2017-03-29 05:53:24
The miners have invested heavily in equipment which secures the Bitcoin network, which in turn drives the price. 
@_date: 2017-03-20 17:39:46
Just because there are multiple versions of something, doesn't mean one is close to being released into production. 
@_date: 2017-03-19 13:35:01
If they connect to a node which is following the longest chain, with the most proof of work, they will see these &gt;1MB blocks.
This includes BU nodes, Bitcoin Classic nodes and Bitcoin XT nodes, for the time being. By the time we actually fork there may be more implementations. 
Once they see this chain, they will follow it.  
@_date: 2017-03-25 19:36:55
Looks like there might be some [issues]( with it though, if I understand this correctly:






@_date: 2017-03-20 07:01:44
Exactly, this is how Bitcoin was intended to work, through emergent consensus. There doesn't need to be any centrally planned signal rate, when the time is deemed right, a miner will mine a 1.1MB block. 
This may take a good while yet, not until everything looks to be ready will this happen. In fact when it does happen, I think people will wonder what the fuss was all about. 
@_date: 2017-03-20 07:54:59
Absolutely, this was always the intention. 
@_date: 2017-03-09 08:17:33
Your link says they are supplying funding to BU, it doesn't say they are the sole contributor. So I assume you do not have evidence. 
@_date: 2017-03-11 18:30:59


I doubt most people who use Bitcoin will have any idea they even have these addresses which contain unspendable outputs. Most users just let their wallet take care of everything. 
I don't see how having high fees helps to reduce bloat in this case. 
@_date: 2017-03-19 09:37:14


If that is the case, who is writing the code for consensus changes which have been adopted by core?
@_date: 2017-03-20 13:06:56
If you change the POW and the new set of miners decide to change the consensus rules, what happens then? Another POW change?
@_date: 2017-03-25 19:49:03


Nodes such as Breadwallet, SPV nodes which will follow the valid longest chain with the most proof of work. They don't verify the size of blocks. I believe the majority of users of Bitcoin use these wallets, representing a significant proportion of the "economic majority". 
@_date: 2017-03-11 18:06:46
That's not what I am arguing against here, I'm saying that blockweight is not a benefit, it's a requirement of segwit as a soft fork. You need to encourage people to switch over to segwit transactions and this is done by introducing the blockweight and the 75% discount. 
I agree that reducing UTXO should be encouraged. However there is a balance. As an extreme example you could have a negative fee for transactions, pay people to submit transactions which consolidate many inputs into a single output. You would probably need to have an unlimited blocksize to support this though, but it would reduce UTXO bloat, to some degree at least. No matter what you do, to support more users the UTXO size has to increase, to allow them to store a balance. 
The other problem we have is that due to high fees, 55% of bitcoin addresses have balances which are less than the fee required to spend them. That's not good for bloat; they will sit there forever. We need to reduce fees to allow these to be spent. 
I'm not in favour though of hard coded values, such as this 75% discount. I think the market, should be able to determine what should be incentivised. 
@_date: 2017-03-21 14:30:03
It's possible, but I think that is unlikely. You could easily spoof a core node if you wished to, and which point these wallets would happily connect to you and accept the new chain as valid. 
@_date: 2017-03-20 07:07:00
Core can just merge the emergent consensus protocol into their code. 
@_date: 2017-03-28 16:31:19
I think the users who are spending $0.50 to $1 for a transaction would disagree. 
@_date: 2017-03-14 10:20:14
What is the issue here? BU supporters support multiple implementations of Bitcoin. BU works closely with Bitcoin classic, Bitcoin XT and Core (although there have been difficulties with that).
Miners and users should be free to run any implementation they want. 
This simply relates to the internal management of BU, nothing more. 
@_date: 2017-03-09 08:37:24
I never said there was anything wrong with Blockstream funding Bitcoin core. I just asked you what your opinion was, since you have an issue with Bitmain funding BU. 
@_date: 2017-03-20 06:49:37
There is plenty of time yet. Even once we reach 75% or higher in support of BU rules, miners will wait until the BU supporting node count rises. This doesn't have to mean running a BU node, it might be a core node recompiled to support the emergent consensus protocol. 
It's not only miners who are running BU at the moment though, many regular folk and a few businesses are. 
@_date: 2017-03-26 07:10:11
How can they reject the first known to be invalid block?
That can only happen in retrospect, at that point a user could have already received funds on the new longer chain. 
You will also require SPV users to upgrade, something which we have been told makes a hard fork difficult to pull off. With a hard fork to increase the blocksize, SPV wallet users don't need to worry, they automatically switch to this chain. 
This is a good thing. 
@_date: 2017-03-09 18:26:54
In the last 24 hours, 34% of blocks did not signal for either Segwit or BU. 
As you need 95% for Segwit, you could just as easily say that the 34% of miners who are not signalling are blocking Segwit. 
For those interested, 33% signalled for BU and 22% signalled for Segwit. 
@_date: 2017-03-29 05:41:58
SPV clients/nodes don't verify the blocksize. I would argue they represent a significant proportion of the economic majority. 
@_date: 2017-03-20 16:12:29
Who decides what the "standard code" is, and what is the mechanism for making the decision?
@_date: 2017-03-09 15:04:37
Ok then as their code is opensource I assume you can point to their flexible txs implementation in the latest release, together with which lines contain bugs. 
@_date: 2017-03-13 12:57:19
How is this hostile? Miners are free to run the software they want and vote how they want. 
@_date: 2017-03-26 07:54:08


Automated how? Sounds like centralisation to me, relying on a central server to point you in the right direction? Bitcoin solved this problem of relying on a central authority by using trustless decentralised consensus. Just because you don't like what the consensus is, doesn't mean you have to throw away Nakamoto consensus. 


They have no need to worry, they will continue to follow Bitcoin, and they will be following the longest chain with the most proof of work; the most secure chain. 
@_date: 2017-03-09 18:10:48
Larger blocks take longer to relay. If a miner produces a block which takes longer to relay than another block found at around the same time, they run the risk of having their block orphaned. This hits them in their back pocket, by quite a significant amount at today's exchange rates. 
Miners need to balance block relay times, with block sizes. The bigger the block, the more transactions they can include within it. More transactions, more users, more fees. However, there is a natural limitation which is network propagation times. 
With this natural economic incentive in place, and traditional market forces, the network will naturally converge to the optimal blocksize that the network can support. 
We don't need to have this centrally controlled.
@_date: 2017-03-19 08:52:51
BU promotes alternative client implementations and have worked closely with Bitcoin XT, Bitcoin Classic and with Core.
How BU organise themselves internally is purely up to them to decide. They have developed a client, and miners are choosing to run it. 
@_date: 2017-03-09 07:30:25
We both know it takes time for users to update software. One of the reasons users have difficulties now is that they are running old software which does not calculate an appropriate fee when sending a transaction. 
Segwit is an effective increase to 2mb once all transactions are segwit transactions. This will take time. 
If the effective limit of 2mb ( 4mb including witness data) needs to be raised in the future, we will need to hard fork. There won't be a way around that. 2mb is in my opinion inadequate to support a current users and transaction levels. 
Segwit has not been tested on main net either; both present risks. But the reward of one implementation solves this problem forever as miners will determine the optimal blocksize based on what the network can safely support. They will not risk generating blocks which are too large, as they risk having their blocks orphaned. The economic incentive is there and in place, and acts as a natural limiting factor. 
@_date: 2017-03-11 19:33:32


OK, lets look at what you said:


I don't understand what you mean here. Are you saying we could reduce this further and aim for the vast majority of transactions to have 1 output?


So we agree then, it has been determined it is a requirement for segwit to be useful. 


Miners? Perhaps out of their coinbase fee? I did say it was an extreme example. But if that's what miners decided was important to them, that they wanted to reduce the size of the UTXO they were storing, it is conceivable they could offer to donate some of their fee to whoever is cleaning up the UTXO bloat. I'm not suggesting this is something that should happen. 


Lets say we started Bitcoin over again. To onboard users, the UTXO size has to grow. They have to have balance, for a balance, they need an address. Which is an unspent output. 


There is a breakdown of addresses [here]( 55% of addresses have a balance of less than 0.001 btc. So technically we might not be quite there yet, but we aren't far off it if fees keep rising as they have done, would you agree?


I was referring to determining transaction fees, and in my opinion, the blocksize as well. 
@_date: 2017-03-12 22:31:58
Can you explain what you think a hard fork is, in your opinion?
@_date: 2017-03-24 20:36:05
As it stands, SPV wallets do not verify the blocksize. A proposal has been made to allow them to do this, but its not been implemented and I would be surprised if any of them did, at least without making this limit configurable by the user.
If we forked tomorrow, SPV wallet users who represent a significant proportion of the so called "economic majority" would automatically switch to this chain. 
A number of exchanges have said that they to would follow the longest chain with the most proof of work, which any BU fork would be, as miners have said the will not fork until its clear there is significant support via signalling. 
The economic majority, the regular users of Bitcoin need more block space for their transactions, to reduce their cost. Without this people will go and look for alternatives and it seems that it has already begun to happen. 
The title of the white paper was:
**Bitcoin: A Peer-to-Peer Electronic Cash System**
We have moved well away from that. A $0.50 charge for a cash transaction?
@_date: 2017-03-09 06:54:31
Even if segwit activated today, it would take time for wallets and users to begin to fully utilise what is effectively a tiny increase.
A hard fork provides immediate benefits with the same transactions we use today, wallet providers and users are not required to change their behaviour. 
@_date: 2017-03-26 18:11:25
Just variance with regards to the hash rate drop. 
As it stands now, last 24 hours:
* Segwit: 31.8%
* BU: 34.4%
* 8MB: 4.6% 
@_date: 2017-03-11 19:36:55


In most cases wallets are generating this change, users aren't the ones gathering up transactions and deciding where to allocate change. Wallets do this automatically. 
@_date: 2017-03-11 15:06:44


Are you sure about this? That seems backwards to me. The more inputs there are, the larger the transaction will be. For example, you can estimate the size of a transaction using the following formulae:
    in*180 + out*34 + 10 (plus or minus 'in')
From [here](
You can see that the cost weight of the inputs is much higher than the outputs. 


Can you point me to either where in a BIP this is mentioned, or perhaps where in the code?
According to [BIP-0141]( transaction weight is described as follows:








































It mentions nothing about the number of inputs and outputs, just the transaction size. 
@_date: 2017-03-09 07:03:41


Where as:


@_date: 2017-03-24 22:40:36
From the white paper:


A team of developers have proposed a mechanism to upgrade to larger blocks, to reduce transaction costs. Separate development teams have adopted the same consensus mechanism. Miners have looked at the proposal, like the look of it and are now signalling support for it. 
@_date: 2017-03-09 14:47:17
Sorry to be pedantic but you have pointed to an issue with Bitcoin Classic code. Do you have an example of these bugs which are in the latest version of the BU client ?
@_date: 2017-03-19 13:08:38
It's worth noting that SPV clients will follow the longest chain with the most proof of work. They will follow any BU fork. 
@_date: 2017-03-29 05:39:30
The risk here is that any UASF nodes will fork themselves onto either a non existing chain (no blocks will signal for segwit and so they will reject all blocks), or onto a less secure minority chain. As it stands Segregated witness has minority support amongst the miners. 
@_date: 2017-03-09 14:06:25
Can you point me to this code and these bugs?
@_date: 2017-03-21 08:17:40
Yes, of course. I would expect it to become apparent which chain has "won" much quicker than 6 months though. I think we are talking a matter of days, if that. 
By the time we fork, everything will be ready I think the outcome will already be known. 
@_date: 2017-03-15 16:28:54
Whilst I don't believe all BU node operators do this, I expect a large number may do.
What is the issue with that? It's not hard, it's perfectly safe and secure. 
@_date: 2017-03-20 18:52:40
The miners will wait until there is significant support for a blocksize increase, probably around 75% of the hash rate. 
Once this is reached, they will likely signal their intention to fork and invite people to run BU compatible nodes. Once the node count increases to a reasonable level they will likely announce the blockheight at which they will modify their EB values so that blocks larger than 1MB will be accepted and relayed. It is likely a EB value of 2MB will be used. 
Once the network looks ready, we will likely see blocks of 1.1MB created and propagated. At this point the fork will have begun. 
@_date: 2017-03-19 17:37:00


How is this being measured?
@_date: 2017-03-09 07:35:44
Do you have any evidence that they are the sole contributor?
@_date: 2017-03-21 14:49:58
How do you verify a node added by a user is a core node?
@_date: 2017-03-21 14:47:29
Which explains why this is possible then. Rather than allowing your client to discover nodes on the network, you are hard coding them in. 
@_date: 2017-03-09 06:51:39
Many people and companies do in fact support it, but perhaps are afraid to come out and publicly support BU, for fear of a backlash. 
I get the impression the tide is turning however. 
@_date: 2017-03-11 17:28:48
The vast majority of transactions have 2 outputs. For these transactions when 100% of these are segwit transactions, what matters is their size. 
@_date: 2017-03-29 05:37:04
It should be noted that SPV clients do not verify the blocksize. Should Bitcoin upgrade and hard fork to a larger blocksize, SPV client users do not need to do anything. 
@_date: 2017-03-29 17:05:06
Yep, and I choose not to run it. I'm interested to see what is going to happen to nodes which do choose to run it. 
@_date: 2017-03-28 17:10:54
Can you explain how we can identify if a transaction is a "spam" transaction or a valid one?
@_date: 2017-03-25 19:39:35
I believe this is a typo, as far as I am aware this is referring to the issue on Tuesday. 
@_date: 2017-03-13 18:24:17
None of the above explains why BU is hostile to Bitcoin. 
You may not agree with their emergent consensus layer, or what they have chosen to prioritise, but people should understand that the number one reason for raising the blocksize limit is to allow Bitcoin to scale in the short term whilst second layer solutions are worked on. 
The three main goals are:
1. Reduce fees for users. 
2. Reduce confirmation times. 
3. Onboard more users. 
Where is the hostility there?


This is simply not true. They created an incident report for the recent bug - BUIR-2017-01-29. You can find this on google if required. A patch was quickly released.
@_date: 2017-03-11 16:40:56
I think you may be referring to [this]( 
Which is interesting, however the vast majority of transactions have 2 outputs, the target address plus a change address. I can see how it will incentivize reducing the number of outputs in some limited cases. 
@_date: 2017-03-10 06:13:42
The white paper does not mention anything about a blocksize limit. 
@_date: 2016-10-23 16:26:25
They signed an agreement which said they would support segwit in return for a blocksize increase to 2mb via a hard fork. 
Read about it [here](
How can you say they didn't want bigger blocks ?
@_date: 2017-07-13 18:34:35
Ones which rely on connecting to a number of random full nodes on the network. The more nodes you connect to, the more confident you can be that you are following the longest chain with the most proof of work (the valid Bitcoin chain). 
@_date: 2017-07-12 21:13:09
Only the headers are downloaded. See [here](


How else can a mobile wallet sync the full chain in a matter of minutes? It certainly doesn't do it by downloading full blocks. 
@_date: 2017-07-13 17:46:49
I know you didn't write it, but you expressed your belief that the statement was true. 
Lets go right back to the very beginning. From the white paper:






a copy of the block headers of the longest proof-of-work chain, which he can get by querying
network nodes until he's convinced he has the longest chain
This still holds. The longest chain, with the most proof of work is Bitcoin. If there are people out there who wish to try and attempt to follow a minority chain, then it is the responsibility of those people to ensure that they protect themselves against replay attacks. 
There is nothing stopping anyone right now from forking Bitcoin and creating their own minority chain. Should we ensure that we protect each and every one of those people from the possibility of a replay attack?
The very fact that SPV wallets follow the longest chain with the most proof of work in this way should be welcomed. The majority of end users do not have to worry about upgrading their clients if they wish to continue to use Bitcoin. Why would we want to reverse that situation?
@_date: 2017-07-12 21:10:31
Only when running Bitcoinj in fully the full verification mode, which requires downloading the full blocks. SPV clients do not do this by definition, only the headers are downloaded. 
This was the issue Luke attempted to solve with [bip-180](


@_date: 2017-07-15 08:29:35
Luke has posted to the segwit2x mailing list. See [here]( 
@_date: 2017-07-13 17:28:26


Can you explain why you believe this to be true?
@_date: 2017-07-13 18:42:51


Can you explain how this would happen? 


We are not discussing Bitcoin Unlimited. 
We are discussing a solution proposed by a group who represent:








@_date: 2017-07-13 15:33:34
I agree that the segwit aspect of Segwit2x is a huge unknown. We don't know what it's impact will be, how much it will actually be used, and what the long term implications for maintenance will be. 
In comparison the hard fork from 1mb to 2mb is a very minor change hardly anyone will notice when the time comes. 
@_date: 2017-07-12 16:56:57
SPV wallets will by default follow the longest chain with the most proof of work. They do not verify the blocksize.
This fork will have &gt;80% of the Bitcoin hash rate, and a similar proportion of the "economic majority". 
Given this, SPV wallets will follow this new chain immediately. 
If people want to follow a minority chain, then it is up those people to develop their own solutions to avoiding replay attacks. 
@_date: 2017-07-15 08:08:33
The mailing list is public. Just like the core one. See [here]( 
@_date: 2017-07-13 18:18:26
The minority chain, if it even exists, will have very little hash power and will quickly fall behind the main chain. Miners won't waste their time mining on a worthless chain.


That may be the case, but SPV wallets today still behave as the white paper describes. 
@_date: 2017-07-15 08:21:22
Looking forward to moving Bitcoin back towards it's original intention: **a peer to peer electronic cash system**. 
@_date: 2017-07-12 21:03:19


No, it is correct. It is possible to run bitcoinj as a fully verifying node. Please see [here]( 


I suspect the code you have linked to is part of this fully verifying component of the codebase. 
SPV clients are not able to verify the size of each block. 
@_date: 2017-07-15 08:44:44
I'm not aware that anyone has been banned from that mailing list. 
@_date: 2017-07-13 18:08:32


Are you sure about that? If you want to use that as a precedent, lets look back at what happened


So it was ETC who were forced in the early stages to implement replay protection. The onus was on them. 


At the time of the hard fork, at a very minimum there will be 80% of miners on board. What do you expect the other 20% will do? Do you believe they will risk mining on an alt coin with little value? It's very likely &gt;95% of miners will follow this hard fork to protect their investments. If a minority chain does survive, it will take much longer than 10 minutes on average to mine a block. It will quickly fall behind the Bitcoin chain. 


Only if they wish to follow a minority non Bitcoin alt coin. 
@_date: 2017-07-13 18:12:49
SPV wallets deem the longest chain with the most proof of work to be the valid chain. 
@_date: 2017-07-12 18:04:32


This is false. SPV clients connect to the longest chain with the most proof of work. They connect to multiple random nodes. As soon as they see the new longest valid chain, they will follow it. 
This was the whole reason why Luke tried to implement [Fraud proofs]( to ensure that SPV clients do not follow a chain which includes blocks over a certain size. 
@_date: 2017-07-13 07:28:00
Segwit2x just implements the Hong Kong agreement. There is no face saving excercise. Miners signed up to this over a year ago. It is finally being implemented. 
@_date: 2017-07-13 18:29:12
If end users wish to follow Bitcoin, then they have nothing to worry about. They will be able to send and receive balances no matter which chain is winning the race. Transactions will be valid on both. 
As is the case today when we have an orphaned chain. 
It only matters when you want to follow both chains. The onus is on users who wish to follow the minority non Bitcoin chain to protect themselves. 
Should we protect anyone who wishes to fork and create their own minority chain?
@_date: 2017-06-03 13:41:21


I don't buy the spam argument. If a transaction is willing to provide a fee, then who is anyone to judge whether a transaction is or is not spam. 
I've never heard the term "speculative spam" before either. What are these people speculating on? That they are able to send a Bitcoin transaction with a reasonable fee?
@_date: 2017-07-13 07:01:15
The most likely scenario is that segwit2x is the majority come the 1st of August. At which point all blocks will already be signalling for segwit. Therefore, all clients are compatible. Nothing will happen. 
@_date: 2017-07-12 18:21:37
Given that the segwit2x chain has 80% of the hash rate, and a similar proportion of the economic majority, then I would say its extremely likely that the segwit2x chain will be the longest chain almost immediately. 
If any of the remaining 20% of miners have not already switched, they will have a very strong incentive to switch at time time of the fork, as they will be mining on a minority chain with little economic support. This hits their profits, and means a loss on their investment. 
Lets say we end up with 95% of miners on segwit2x and 5% on 1MB BTC, the difficulty won't adjust for some time. This will mean it will take significantly longer than 10 minutes on average to find a block. Confirmation times for anyone remaining on this chain will increase dramatically. 
The only option for this chain will be for it to itself implement a hard fork, and move to a new proof of work. 
@_date: 2017-06-03 13:14:50
As I said, even with 100% immediate conversion, its still only ~800KB, at best. 
What then? Do we hard fork to increase the block weight? It's not like there are any second layer solutions available for imminent release. 
@_date: 2017-06-03 13:48:52
Fees are high, and Bitcoin's share of the Cryptocurrency market in terms of capitalisation is decreasing in the face of alternatives who are able to provide transactions at a lower cost with faster confirmation times.  
Progress has stalled for years, I would say it's urgent. 
@_date: 2017-06-03 13:37:01


What's stopping the Lightning network now then? Litecoin has Segwit. Lets try it. 
@_date: 2017-06-03 18:50:39
That's not true, as far as I am aware. Segwit signalling miners who are not enforcing BIP148 will still follow the longest chain with the most proof of work, no matter if the blocks have signalled for segwit or not. 
@_date: 2017-06-03 13:57:02


What is the relevant metric then? 


Can you back this up in a meaningful way, or is this just speculation on your part?
@_date: 2017-06-03 18:52:31
They might be signalling, but if they are not enforcing it come August the 1st they will just follow the regular chain which has the most proof of work. 
@_date: 2017-06-03 13:24:59
We've forked [before]( 


It was so successful and so painless that hardly anyone seems to know about it. I don't see what the issue is. 
@_date: 2017-06-03 13:43:25
That's neither neither here nor there, lets see Lightning up and running in a real world situation. This was the argument to activate Segwit on Litecoin. 
Lets see Lightning running. It ***is*** ready, right?
@_date: 2017-06-03 12:36:00


Tell me, which solutions are available?


None of the links you post mention anything out routing. How exactly is routing going to work in lightning world? Its still a problem yet to be solved. 
Payment channels are nothing new, which is all you have demonstrated is possible, see here for an alternative:
 
Lightning has routing issues plus no one has yet explained how users will ensure that there channels are closed in a timely manner without having to do any manual closure of them. Will you have to have your node running 24/7 to ensure that prior to a channel timing out that they automatically close it?
What happens if blocks are full? What if your transaction to close a channel is delayed ? There is a risk the other party can steal the remaining unused balance at this point.
Apart from the issues above we then have the problem of what stops a large central payment hub from developing which has channels open with everyone, huge amounts of funds available for pre-allocation, and can therefore offer the lowest fees. 
Plus, who wants to think about how much to pre-allocate into a channel? When you make a payment now, do you think, hmmm, will I be sending any more transactions to this entity within the next few days, weeks or months? If so, how much should I allocate into this new channel? The more you automate this decision, the more you move towards central hubs, with the fewest hops to setup a channel with the entity you want to transact with. 
Right now, Lightning is purely theoretical with many issues yet to be solved. Yet we know Bitcoin works well, and has done for years. 
@_date: 2017-06-03 14:01:32


I didn't think so. 
@_date: 2017-06-03 13:53:53
The incentive is a technical demonstration of its usefulness and viability as a second layer solution. I would have thought the Kudos of solving this problem would be enough to want to get it productionised onto a live real world Blockchain. 
The same argument was used to activate Segwit on Litecoin, despite it not having full blocks. Lets do the same with Lightning. Lets see it working. 
@_date: 2017-06-03 12:02:42


Segwit is far too little, too late. Even if it activated today, it would take years for everyone to shift over to segwit addresses. 
Best case scenario is that after years of people finally migrating over to Segwit addresses, it gives us an effective blocksize increase of ~800KB. Tiny. Taking us to 1.8MB. Take litecoin for example. How many segwit transactions are actually being used on litecoin, hardly any. After a huge push to get it activated. 
Whilst it solves a few other minor issues (albeit in a very complex way, evident by how long it took to be released), the most pressing one is capacity and reducing the fees users pay to send their transactions. Currently we are forcing users to spend more per transaction.  
The idea that Segwit somehow enables second layer solutions or sidechains is a fallacy, as we have been told time and time again that Segwit isn't a prerequisite. 
Perhaps if there were any second layer solutions waiting in the wings for use once Segwit activates, Segwit might have more support. There aren't however. 
We were told hard forks were dangerous, which was why we must scale with soft forks. Now we have this campaign for UASF, which will effectively lead to a hard fork. At that point we may as well just hard fork and increase capacity on chain, in a slow and safe conservative manner over time. 
The whole situation is deeply depressing. 
@_date: 2017-06-03 13:58:51
Fees would be lower though, do you accept that?
If you increase the supply of something, it's price will fall. So from a users point of view we will not be "exactly where we are now", as their transactions will be cheaper. 