@_author: kanzure
@_date: 2016-08-02 23:56:45
this is a bad idea because the attacker can do the same thing
@_date: 2016-08-05 23:39:48
Yeah it's fairly straight-forward to be friends with developers. The process is essentially "talk code for 20 hours straight, plus or minus other conversations, and done". This tends to be much less messy than other human socialization rituals.
@_date: 2016-08-18 02:44:43
yes but which source? :)
@_date: 2016-08-18 05:34:10
yes, it's bad opsec, but it's hard to convince anyone to revert his commit at this point.
@_date: 2016-08-18 16:28:05
edit your `~/.gnupg/gpg.conf` file and add these two lines:
    # try to avoid showing short ids to the user
    keyid-format 0xlong
Also, be sure to use the `--keyid-format long` parameter and `--with-fingerprint` when using gpg in the future:
    gpg --keyid-format long --with-fingerprint --list-keys kanzure
@_date: 2016-08-06 01:36:59
Well, there were originally some proposals for a hard-fork that does not modify anything important, as an industry-wide experiment. Additionally, a similar industry-wide experiment was proposed that does not require a hard-fork, something like changing the address type, which would be used for collecting data and "lessons learned" before designing a hard-fork. I think jl2012 had a recent "hard-fork wishlist" but all I can find is his segwit wish-list. There is always the old hard-fork wishlist from ages ago, but it's outdated and not ideal.
@_date: 2016-08-17 23:01:33
So far, none of the others I have pinged about this has any info as to its veracity or background. Unlike most contributions to bitcoin.org, this one was pushed to the master branch without a corresponding pull request (a mechanism used to solicit review and feedback from others). 
I suggest skepticism. We should be cautious of anyone skipping peer review processes, even for security incidents. Poor handling of these situations can lead to unintentional panic where panic of any kind is unhelpful to resolving issues. However, everyone should always be encouraged to check the signatures regardless of alerts, of course. Multiple signatures should always be checked, and not just Wladimir's signature. Use the [gitian signatures repository]( to get other signatures, and always verify public key and signature data through multiple independent channels.
Someone on  IRC suggested to write down [some steps for GPG verification of builds]( and a link to [the gitian build steps](
And if the concern is about someone targeting Chinese users in particular, then I would suggest a Chinese translation of the same instructions and checklists.
**Edit**: another interesting (although probably unrelated) observation is CVE-2016-6316 see  which says:




**Edit**: Also, don't use gpg short ids. Always verify fingerprints. There are gpg short id matching keys floating around for some Bitcoin developers - for example  check out the revoked key.
**Edit**: To emphasize, it is insecure for Cobra to give a specific key with a specific fingerprint on a server that he is warning might be compromised (perhaps the server itself or perhaps for other unrelated web reasons). His is a recommendation that should be improved. Instead, use multiple independent uncorrelated channels to look at sources of information to acquire keys, fingerprints, binaries/builds, and signatures. Keep in mind that it is not always easy to tell if two channels (like: internet connection at your house vs an internet connection at your friend's house down the street) are uncorrelated. Perhaps they are both targets to a neighborhood-wide attack? For example, there are many stories from Internet lore where a company purchased redundant internet service from multiple Internet Service Providers only to find that both providers were indeed using the same physical fiberoptic drop.... Go to key signing parties.
**Edit**: man-in-the-middle attacks are a real problem. We should try to encourage people to post security alerts rather than not post them, and that goes for myself as well. I hope that my comment has not discouraged future alerts by any means; it was wrong of me to focus on process concerns in the opening. Security incident response deserves focus on higher priority issues. Context: 
@_date: 2016-08-15 02:43:33
Hardly. I'll counter your Wei link with a way more awesome Wei link about cryptography: 
@_date: 2016-08-02 18:02:14


I hope to tweet (or something) to let others know ahead of publishing the big one. Maybe something like multiple hours notice or an entire day?
@_date: 2016-08-06 00:51:38
All paragraphs were constructed to be invariant across all possible speakers. We did this by sampling the words in the document, then splitting the sentences and analyzing Hamiltonian paths to evade stylometry.
More seriously, there's no general rule about paragraph composition in this doc. It's a good idea though, it's something I will work on for future typing. Also, this goes both ways. Just as a paragraph is not necessarily spoken by a single person, two pairwise paragraphs are not necessarily spoken by different people.
@_date: 2016-08-17 23:41:15
Unfortunately, man-in-the-middle attacks are capable of bypassing "a clear separation of duties". The domain name system is not decentralized. Also, when you're not busy sometime, check out how the certificate authority system works for SSL/TLS certs. ... and [certificate authority (CA) various security problems](
**Edit**: the thing to think about is, what happens when you type a URL into your browser and hit enter? What are all of the steps that occur between the time that you press enter and the time that you see information on your screen from the bitcoin.org website? How do you know it is from the bitcoin.org website? By what method was the information verified by your machine, if at all? Additional layers have to be looked at including TCP/IP, DNS, SSL, HTTPS, etc. And even after this, also consider questions such as: how did the information come to be on that website? How has the veracity of that information been determined, by what procedure and have you verified that procedure yourself? And which personal attack vectors, if any, are currently mitigated by the techniques you are personally employing? etc.
@_date: 2016-08-06 01:10:30
You're welcome. Someone [asked]( me on twitter what my typing method is. I joked that, [like CSW]( it's [18 forms of ninjutsu]( but I won't tell you [which ones]( Also, hokuto shinken.
@_date: 2016-08-08 15:05:45
transcript: 
@_date: 2016-08-15 05:19:31
Not interested by that line of argument, sorry. "Friendliness" is mostly fearmongering about "loss of control" when the truth was that they (Eliezer/Wei/et al.) did not have "control" in the first place.
@_date: 2016-08-18 16:52:44
Some backlinks:
* 
* 
* 
* 
@_date: 2016-08-18 19:35:49


Rumor I heard (unfortunately I don't remember the origin of where I saw this rumor, but I saw something yesterday I think?) was that some researcher had created a large number of gpg keys with matching short ids. This was briefly discussed in today's Bitcoin Core meeting in  Here is a ref:
I had heard about this yesterday from somewhere, but I have no idea why I had heard about this, or from where. This twitter link is new to me, in fact I haven't read this one yet. (got it from the IRC meeting)
**Edit**: 
**Edit**: i haven't checked if the evil32 data set is related to the revoked keys you are looking at. These two things we're discussing might be unrelated :).
@_date: 2016-08-18 01:19:57
Some recent discussion about mimblewimble:
* 
* 
* 
* 
* 
* 
@_date: 2016-08-17 23:36:29
In a man-in-the-middle attack, yes the adversary would want to replace any text related to the previous key with text related to another (adversarial) key that they control instead. It's important for everyone to verify through multiple independent uncorrelated channels.
@_date: 2016-08-06 01:22:47


Some have advocated for always preferring soft-forks, including for block size increases. I think you might be wrong about the lack of disagreement.
@_date: 2016-08-09 03:10:52
"Didn't destroy value" except all the losses from replay attacks and the other umpteen issues
@_date: 2016-08-06 00:49:23
You might recognize some of the developers, but I think you'll be pleasantly surprised to hear which of them are the Chinese miners.
@_date: 2016-08-08 15:31:03
Some backlinks:
* 
* 
* 
* 
* 
@_date: 2016-08-02 01:48:54


Well mostly it's a result of social awkwardness (it's weird to just type what other people are saying)..... but you're right, we probably don't need that. deleted.
@_date: 2016-04-11 14:30:21
For the far future scenario, the idea is that transaction fees will replace the block reward as the mining incentive. There are at least two ways to consider off-chain transaction processing.
One is that you could consider the blockchain to be a means of settling disputes, such that if any sequence of bitcoin transactions off-chain (such as [Lightning Network]( bitcoin transaction sequence) is under dispute, the transactions could be relayed to the bitcoin p2p network and undergo final settlement according to the transcript scripts. Under this scenario, the question you would have to ask is: would the rate of dispute be high enough to support the bitcoin network? Would there be enough dispute such that transactions are broadcast to the network every 10 minutes enough to support bitcoin mining? If you are an optimist, then you would think perhaps not-- maybe the whole network runs pretty well and only has one or two transactions once in a while that are disputed and need to be settled to the Bitcoin blockchain. Would mining equipment sit idle and wait for the transactions to be relayed over the network? And would this be sufficient incentive.
The second aspect to consider is that on-chain settlement has some distinct benefits like the increasingly-hard-to-reverse nature of a transaction buried under additional confirmations. Suppose, here, that there are no disputed transactions from the first scenario. Would there be any reason to relay transactions to the bitcoin network? The primary reason to relay transactions would be for long-term cold storage. Users that wish to store BTC while going offline would prefer to store BTC in the blockchain. Users that are planning on spending their BTC would also relay transactions to the p2p network. So far, developers working on Lightning Network have thought mostly about LN for small payments and small amounts of BTC because of the inherent security concerns of having a "hot wallet" (private keys loaded in memory, signing bitcoin transactions). Larger amounts of BTC should be in "cold storage" in the blockchain and should not be controlled by private keys loaded into memory to network-connected devices (such as LN or bitcoin nodes).
Re: mining efficiency and whether certain changes would be desirable, I recommend reading  and  and 
@_date: 2016-04-01 22:53:02


@_date: 2016-04-21 16:35:12
here's my transcript of the video, any errors my own etc etc- 
@_date: 2016-04-02 02:21:30


Another explanation is that the author lives in a different time zone ahead of yours.
@_date: 2016-04-02 02:23:35


Control flow path- 












Instead of revealing the whole program (which is costly with an increasing size of program under consideration), a merkleized abstract syntax tree could be used to commit to some (hashed) program and then only reveal some portion to be executed by the bitcoin blockchain whenever some future transaction references that output as input.
edit: Eh I'll also leave a link to 
and 
@_date: 2016-04-13 16:49:52


This is already the case for all Bitcoin on the blockchain. It's locked. You make a transaction. The transaction unlocks the BTC. Same thing with LN, you have to spend the BTC either through LN over payment channels or to another Bitcoin address. Already locked even without LN.
@_date: 2016-04-14 02:05:45


@_date: 2018-01-09 15:28:25
An overview of bip98, bip116 and bip117: 
Separately, for jl2012's bip114 (as seen in OP's link), there's:
@_date: 2018-01-31 19:00:35
transcript: 
@_date: 2018-01-31 20:04:15
I checked the transcript. It's pronounced Pieter Wuille.
@_date: 2018-01-09 15:21:44
And the actual implementation:
bip98 and bip116 
bip117 
@_date: 2017-12-28 20:46:14


The lightning payment channel open transaction must be confirmed first. The protocol can only work once that transaction is confirmed. So it's relying on the initial confirmed transaction, from which the other properties of the payment channel concept all derive.
I hope this can help clear up some possible confusion, it might warrant taking a second look at how payment channels work.
@_date: 2015-12-10 08:23:19
You're in a thread talking about the effects of bandwidth limitations on Bitcoin consensus and mining, even without dialup you can have a slow connection. You can't mine on headers you haven't downloaded.
@_date: 2015-12-07 17:17:49
IBLT has continued to progress, see [the Montreal presentation about IBLT]( and more recently [the Hong Kong presentation on IBLT]( There is also [gavinandresen's original IBLT proposal](
@_date: 2015-12-10 07:58:43
Your scenario was the following:


No amount of SPV mining would make you able to catch up with downloading. You have a "download defecit" due to low bandwidth. Your orphan rate is going to be higher, because you can't keep up with the PoW consensus, so other nodes will reject even your SPV blocks.
@_date: 2015-12-01 19:28:53
Bitcoin transaction receivers cannot opt-out of the negative consequences of treating zero-confirmation transactions like very-confirmed transactions, even in absence of (opt-in) replace-by-fee. Similarly, Bitcoin cannot eliminate the possibility of even "natural" replace-by-fee behavior occurring in the absence of replace-by-fee, because of how there cannot be mempool consensus and how there cannot be instant global confirmation consensus.
However, I don't see any way it would ever become possible to remove zero-confirmation transactions from Bitcoin, so you don't have to worry there. Payment channels offer an intriguing alternative to zero-confirmation transactions as long as you continue to watch the stream of transactions and confirmations, because those Bitcoin transactions are essentially tied together in a web of rules that work out better than vanilla zero-confirmation transactions (plus, there's at least one commitment transaction which does require confirmations anyway).
Payment channels can be seen as constraining the set of negative consequences of zero-confirmation transactions, by anchoring to a confirmed commitment transaction and through a few other methods. The upside is that some of these details can be achieved through consensus validation rules for confirmed transactions, even though two (or more) parties were exchanging unconfirmed transactions during the period of presumed honesty. Weird, right? (As a quick note, the way that this trick works, to my knowledge, is that the invalid transactions are technically valid and get into the blockchain history, but the previous agreement between the n parties still allows for another transaction to get into the blockchain history? I might be missing a few details here since I have not for a while reviewed the transaction sequence details. Maybe it's just something about watching for other zero-confirmation transactions that reveal the details you need to get something confirmed more quickly. Whatever.)
Your article mentions "risk" and tradeoffs for $x amount of value to a company. I get that, really. But your article conflates receiving a zero-confirmation transaction with receiving a very-confirmed transaction in the following sense: you don't receive BTC from a zero-confirmation transaction, that's not what Bitcoin does. It's impossible to do that. Yeah sure we casually talk about receiving by zero-conf, but until there is historical consensus in the blockchain on the ordering of transactions, it's not "received" in any meaningful way other than "hey I can try to mine this transaction myself, gee I hope someone doesn't mine a competing alternative transaction in the mean time". (Plus or minus all of the trust and business relationship setup you have with your customers. But this is outside of the Bitcoin protocol anyway, so feels OK to not mention it in my "any meaningful way other than".)
Also, re: the comparison to holding Bitcoin as a financial asset, it is very important to note that nobody should consider holding zero-confirmation BTC as an asset. That's.. almost exactly similarly as bad as someone else holding the keys.
Another element to consider is that Bitcoin is a push-only system, so zero-confirmation transactions can always be "sent" to any Bitcoin address. There's no way to "opt-out" of zero-conf and there's no way to eliminate zero-conf without deciding to never mine any future transactions.
Edit: also, I am not sure what zero-conf features you perceive as being lost? If anything, a world without replace-by-fee is more of a restriction over zero-conf abilities or something; difficult to tell what the concern is. We could all try to agree to not use replace-by-fee, but even then there could be a rogue mempool operator that is totally fine using a different set of rules and therefore mines different transactions.... or, alternatively, even if we all try to cooperate to the best of our abilities, we would still have faults in the network because mempool consensus is not guaranteed, so even despite our best intentions, you (even currently!) end up with "natural" replace-by-fee occurrencies. 
Also, regarding replace-by-fee, see 
@_date: 2015-12-21 13:22:29
@_date: 2015-12-18 14:52:55


this is vulnerable to sybil attacks


consensus rule choice should never be based on sybil-vulnerable mechanisms
@_date: 2015-12-02 02:55:14
see 


@_date: 2015-12-22 16:42:58


Pointing out invalidity is entirely constructive. I'll give you an example: I am pointing out that your claim that I am complaining merely about "credit" is false and invalid. This is useful because you can now go look at my post and [find that I wasn't talking only about credit]( Without pointing this out, I suspect you would not have noticed how constructive it is to know about dead-ends and invalid conclusions.


Bitcoin contributors should not have to wade through a bunch of broken invalid stuff; we should have a minimum level or minimum standard that we hold each other to, and we should generally strive to make excellent contributions. Thanks.


That's great. Admirable, even. But attribution isn't merely about "invention", it's about progress and contribution.  And it's a waste of our community's time to have to deal with noisy papers like this that exclude previous discussion and invalidity (which the author was directly privy to (see above link))... We need to have a minimum standard of excellence and progress and contribution, and it's okay to not jam our communication channels with every possible variation of every invalid idea ("weak blocks control block size" ?? the pastebin text argued why that wasn't true).
edit: has removed his post, which was originally:




edit: while preserving post I lost my update-text about attribution, so I have rewritten it, it's not the same but eh it's close enough.


@_date: 2015-12-11 16:40:51
Some of the ideas from NG have made their way into the popularization of "weak blocks" recently, like 
and  and 
@_date: 2015-12-20 17:33:08


Unfortunately "reputation" does not prevent someone from high-rate spouting of factual inaccuracies ; e.g. we have "reputable members" pumping out incoherent fallacious arguments on a regular basis. Operative question seems to be "reputable to whom?". I really don't care if high-reputation individuals misunderstand Bitcoin; their reputation is still not a good reason to flood our communication channels with low-quality nearly-off-topic contributions. Also, their posts's inclusion in the mailing list is often perceived as conferring further reputation and agreement from other developers that the email is topical or well-reasoned or whatever.... which is something that other Bitcoin developers are simply uninterested in associating themselves with.
I think a lot of the success you perceive on LKML is because everyone has calibrated against Linus and other monolithic kernel developers. When there is an inconsistency or a dispute, you resolve that by escalating up the chain to whatever fork maintainer. There is no maintainer for the Bitcoin consensus rules; just our mutual understanding and best knowledge about the topic. There's a maintainer (well, release manager) for the Bitcoin Core project, but that's definitely not the same role as a hypothetical maintainer for the Bitcoin consensus rules. For Bitcoin consensus rules, escalation instead requires an escalation of reasoning through all the known options. 
Reputation is a lousy way to judge correctness, and to the extent that we are capable of limiting others' conflation of reputation/correctness, yeah we should engage in limiting that.
"Just our mutual understanding and best knowledge" and best reasoning... and low-quality contributions, such as those with high fallacy count (no matter how high the reputation of the author), can trivially jam this development process up.


Ultimately your moderation originates at Linus and other fork maintainers. Linus doesn't sit there moderating LKML incoming emails, but he doesn't have to because misunderstandings by other contributors can simply be ignored or rejected at his own choice, which I would argue is not really decentralized. Bitcoin world doesn't have the Linus (Satoshi) option; instead we have to reason with each other...  except in situations regarding non-consensus-related changes, which can be decided by alternative implementation release managers or maintainers or whatever.
More specifically: moderation cannot be "implicitly decentralized" like that especially when reputation (for resolving escalations) is unavailable or inappropriate. 


"You will see a lot less backlash" unfortunately this does not seem to be true; the bitcoin-dev-moderation mailing list contains (nearly) all the rejected emails (rejected from bitcoin-dev moderation queue), and people seem to still be complaining at the same rate as they were before.
@_date: 2015-12-29 00:27:01


you are doing a bunch of copy-pasting [1]( [2](


and then [refuted]( i believe the follow-up from you was "your reasoning is not in a PDF file, and therefore peer review is impossible".
@_date: 2015-12-30 00:59:00


Transaction fees could perhaps pay cover for big block orphan risk, but why would that be interesting? There's something else that can more reliably eliminate that risk or cost. As you increase centralization pressures, and as hashrate centralization increases, the effects of other hashrate orphaning your block is reduced because you can instantly propagate the block to yourself (as a larger miner). Additional transaction fees might pay a miner towards the cost of the additional orphaning risk in the absence of the block size limit, sure/probably/why not. However, a miner's overall orphan risk can be eliminated by a miner if the miner were to increase bandwidth to other large chunks of hashrate (such as their own, due to BTC accumulated from centralization pressure induced advantages), or centralizing most of the network's total hashrate to the same pool, or centralizing most of the network's total hashrate to the same physical host. This has been observed to happen in the field, and does not require new tech development (already exists already happening). This trendly reduces the propagation delay (and that miner's orphan rate) to zero because the miner does not need to propagate to other parts of the network, which eliminates the orphaning risk associated costs that the additional transaction fees were "sure probably why not but why is it interesting" mitigating.
Absent a limit on the supply, a lower propagation impedance can be more profitable to that particular miner, which is yet another centralization pressure (like increasingly big blocks). Bitcoin does not claim to presently be totally absent centralization pressures (nor do the Bitcoin developers claim this either!), although Bitcoin does propose that an alternative to centralization seems to be feasible and that we should work towards that, even if there may be existing runaway consensus rule centralization side-effects absent the block size limit.... instead seems like a good reason for resource requirement minimization methods.
((Also: even if all of that was false, the marginal cost of including an additional transaction (and thus increasing/consuming more block size) is usually assumed to only be related to orphan risk and such. Unfortunately it's more accurate to say that in addition to those risk costs there is also the cost of incompatibility with the existing network bandwidth graph, which is a really difficult calculation to make seeing as how there's no decentralized way to verify node count, and even if there was then still further problems regarding economic verification or economic estimation of the economic relevance of the nodes that you would be cutting off by increasing resource requirements beyond their capacity. These resource capacity incompatibilities cause hard-fork splits occur, basically byzantine consensus failures, and this is generally incompatible with the idea of a currency and probably-completely-necessary currency-specific network effects.))
Proof-of-Work cannot provide security (security for a ledger history consensus) to Bitcoin under conditions of PoW hashrate consolidation or centralization... and this would hold true regardless of what the transaction fees are, and regardless of whether there is a "(un)healthy transaction fee market". The security is absent here because the purpose of PoW was deployed as a sybil-resistant method to avoid centralized authorization (and no amount of fees would fix PoW to be useful under centralization). PoW itself might have economies-of-scale effects, but that's not a good reason to remove the block size limit.
Specifically..... [you previously agreed that in Bitcoin there exists a method for a miner to transmit information to itself without propagating over a network (e.g. independent of block size) (on the current deployed Bitcoin network)]( As a consequence, an unhealthy fee market can exist. The "unhealthy fee market is impossible" conclusion required an assumption of the absence of centralization and absence of centralization pressures like those from increasingly big blocks. This seems like an unreasonable assumption for you to hold given your agreement to the contrary in the link :-) ([this]( one).  I also recently [pointed this out again to you]( as a reminder, and IIRC the only rebuttal I recall seeing in recent memory has been "peer review is only valid in the form of a follow-up PDF" (which is false).


At this time the Bitcoin security argument is something like "there is a floor on the cost of attacking the system". The problem is that centralization pressures eat away at this floor, even if the PoW difficulty number is increasing. You cannot reasonably say "for the network to be secure, it's probably a requirement that the network must not have an attacker." That's.... not how security works.
(((Something I didn't go over, but should briefly mention, is that you can include more transactions without increasing orphan risk anyway....  basically you as a miner include a commitment to some out-of-band transactions and only add them to the block once other participating miners are indicating that they have them. This is not my construction.)))
@_date: 2015-12-31 23:23:15


This is vulnerable to grinding, I think.
@_date: 2015-12-03 00:25:22


I think you have misunderstood the problem with orphaning and big block size. It's not that the big blocks get increasingly orphaned (because actually, they don't) as you increase the bandwidth and resources of larger miners.
Rather, orphaning is effected by block size because of bandwidth asymmetries on the network. You (as a smaller miner) can't mine on top of a block (or even headers) that you haven't seen or haven't downloaded.
But that big block can still exist out there even if you haven't seen or downloaded it, and others might be mining on it (even in spite of the bandwidth asymmetry). But meanwhile a smaller miner is mining on top of something else, which will get orphaned when it's discovered to be not the best chaintip - especially if other miners (a significant portion) have already been mining on the other non-smaller-miner chaintip. They can't upload/broadcast/publish faster than the mega-bandwidthers anyway.
So orphaning does not really allow smaller miners to stop larger miners from mining big blocks, especially to the extent that the smaller miner's bandwidth can't push out their blocks fast enough. Over time, their orphans mean that others are accumulating more BTC to buy/build more hashrate on the other side of the bandwidth asymmetries, thus the hashrate consolidation.... (but see my [other comment]( for the good news; as long as we keep an eye on orphan rate and even try to tune it downwards more, it's possible to keep everything working pretty well, I think.)
This is where people got interested in the "weak block" concept. However, in  I expressed some concerns that "weak block" just shifts the bandwidth requirements around from block publishing to weak block downloading, which while it could possibly make more even utilization of bandwidth, can't really magically increase local bandwidth heh. So weak block may be useful, but I doubt it minimizes orphan rate in a world with increasingly big blocks and increasingly big weak blocks. (The size of the weak block and the size of the block have to be related somehow, because otherwise the concept is pointless. e.g. by receiving all of the weak blocks, you have all the transactions that would have been included in the strong block. This is download/bandwidth again, see?)


I have thought about your statement for a while, and I think you are trying to say something like: "larger miners won't both buy mega-awesome bandwidth and also won't be sending over increasingly big blocks, because that would be essentially similar to selfish mining". Is that what you're going for here?
[larger miners would be on the winning side of the orphaning more often](
[orphaning expectation is smaller for larger better-bandwidthed better-connected miners](
[relay network doesn't help initial block upload](
[in weak block schemes, total bandwidth requirement is same but peak bandwidth requirement is reduced](
@_date: 2015-12-01 20:23:09


If you take mempool reliability as axiomatic, then shouldn't you find it weird that in practice we observe that different mempools have different contents? Not only should it seem weird to you (I think it should, but maybe you have a reason otherwise), it should also be clear it's axiom-violating, and axiom violations are hugely important intellectual events, similar to crashing two atoms into each other and getting out something totally unexpected, signaling that we need to go back and figure out a better model of physics that can explain our observations.
(Hopefully you'll agree with my edits to your comment. Sorry if I got your message wrong.)
@_date: 2015-12-29 00:19:39


The same way we explained that to you yesterday and the day before. Perhaps you should read [replies]( or are you going to again demand replies are only valid in the form of PDF files :-).
@_date: 2015-12-10 02:18:00
If you spend too much time downloading other stuff, no amount of "SPV mining" is going to make you come out ahead on the network especially as block size increases. You'll get left behind, because the rest of the network has more hashrate than you do. 
Check out the conversation over here- 
@_date: 2015-12-11 17:04:43


Your question is, "what does downloading have to do with block size"? Well, the only way to get a block from the network is to download it.
@_date: 2015-12-21 01:11:31


So you're saying that they are both making zero-conf a possibility, and also not making it a possibility? Make up your mind :-).
Zero-conf had undefined behavior prior to replace-by-fee, and it will continue to have undefined behavior after replace-by-fee.
@_date: 2015-06-19 16:41:12


The regular bitcoin protocol is sufficiently strangled on its own, and it's not because Blockstream exists (see [various conflict of interest details]( It's because there are engineering constraints to this project.
The worst case scenario isn't that "everyone starts using some sidelightning instead of processing trillions of transactions on the blockchain", the worst case scenario would be that _nobody_ is able to use bitcoin because either (1) in a hypothetical scenario perhaps a too large max block size [accidentally broke]( the network or , or (2) a [contentious hard-fork]( split the blockchain into N&gt;=2 different simultaneous catastrophes.
The worst case scenario was never "people continue to use bitcoin and everything's great, thanks to increasing the max block size". That's not even close to the definition of a worst case scenario. It's nearly a best case scenario, actually. And even in that nearly best case scenario, there will never be blockchain (or any other type of) capacity to support an unlimited quantity of transactions, which isn't a "market decision" it's an engineering detail. This would be true whether Blockstream existed or didn't.
The more alarming worst case scenario is [unilateral]( [threats]( of hard-forking like someone made ("I am using my position to campaign to companies (who are accustomed to assuming all systems are based on authority), to force a hard-fork") which can't possibly be safe, especially when they go straight to vulnerable companies... The max block size can be increased, although not if we also destroy the network before we have the chance.
@_date: 2015-06-19 21:03:58


No; just because you (or anyone else) "implement math" does not mean that the network is running that new software (implemented math). An example of this is that even while Satoshi was writing software for Bitcoin Core, others were still able to run their own software with modifications to Bitcoin Core without asking Satoshi or anyone else. So even if Satoshi made a change, he had no real way of forcing the network to change to the new change, except that people usually expect a central authority running a project but that's just a bug in human psychology.
Also, they don't determine what's implemented: they only determine what's implemented in the client that they are working on. They have no ability to determine that in another client someone else is incapable of implementing some other stuff.


Not even the mixed group of developers is in control of the software running the network. Everyone runs their own software. Sometimes that software is written by different "mixed groups of developers"; sometimes that software is written by a BDFL. But that doesn't mean that the ability to publish software is a form of governance. (Although, the ability to threaten various hard-forks is probably a form of governance, of some kind...)


Heh well the same is true for any self-proclaimed leaders or anyone else using the system; you can't use the bitcoin system to reach through the internet and physically stop others from hard-forking their local node or something...
[Bitcoin needs a "leader" like a fish needs a bicycle.](
@_date: 2015-12-12 23:06:29
It's possible to build a "private blockchain" that solves goals unrelated to what Bitcoin is doing. Some companies might have different problems they want to solve using a blockchain (no matter how technically inappropriate it may be).
But that's rather uninteresting; it's obvious that other problems can exist that Bitcoin doesn't solve. What's more interesting is to ask whether those private blockchains can be used to replace the utility of a public decentralized system like Bitcoin, namely the Bitcoin financial asset.
Bitcoin seeks to address the root problem with conventional currency: all the trust that's required to make it work-- Not that justified trust is a bad thing, but trust makes systems brittle, opaque, and costly to operate. Trust failures result in systemic collapses, trust curation creates inequality and monopoly lock-in, and naturally arising trust choke-points can be abused to deny access to due process. This is a tremendous amount of inefficiency. Through the use of cryptographic proof and decentralized networks Bitcoin seeks to minimize and replace the cost of that (increasingly unnecessary) trust.
@_date: 2015-12-21 01:39:24


"They're making it so that you can respend your coins" is something that zero-conf behavior does on its own. You are claiming that replace-by-fee itself is conferring this ability... but it's not true.


Nope; there is no such thing as probabilistic mempool consistency. Mempool is an inconsistency accumulator, at best.


Unfortunately that's not what "guarantee" means, in this context. Above links I provided clarify this point.
@_date: 2015-12-10 08:04:37
That's a good question.
Honestly, I would shop around to get some opinions from the other moderators. Next, I would shop around to some of the members of the mailing list.
If the consensus was "no" on that email, I would reject the email and ask the sender to instead direct the message to the bitcoin-discuss mailing list.
@_date: 2015-12-29 02:45:19


Sorry, I am not attracted to low-quality reasoning, but thanks for asking I guess? The number of times that you post wrong or broken stuff is not going to influence how wrong or broken the stuff is. That's not how reasoning works, dude.
@_date: 2015-12-28 16:56:20


"Supermajority" doesn't make indistinguishable the coins from the (multiple) chains resulting from a hard-fork. "Supermajority" is irrelevant.
@_date: 2015-12-11 17:36:44


Only the blocks, those with the most PoW-weight, that get distributed to at least 30% of the total network hashrate, are the blocks that matter the most for consensus. All the other blocks floating around on the network are going to get left behind in an upcoming "reorg" when the nodes learn about the better-PoW chain.
"Consensus" can actually be made instantaneously when the block was found by a miner with a big chunk of the total network hashrate. This is of course a failure mode for the network and should be avoided to the best of our ability.
I agree that reducing the data burst requirement is necessary and important.
Clients are still going to have to download transactions and blocks at some point, even if it's smoothed out over the new-interblock-notification downtime. I suggest maybe looking over this example: 
@_date: 2015-12-09 04:44:52


Doesn't torpedo the article, it torpedoes your own credibility and reputation. Minutes ago the police raided that dude's house "because taxes", if this was a no-knock US raid then he would be dead and his dog bleeding out, all because you were complicit with this ridiculous circus of misrepresentation.
In the past I have favored you, I think you have the potential to contribute and work towards a great transhumanist future, but you're not going to be able to do that by accumulating piles of circumstantial non-evidence to advance what's little left of your reputation.
@_date: 2015-12-18 04:23:45


Sounds anti-social to ignore "economic demand", right? I would actually submit that it is pro-social to ignore "economic demand". It is pro-social in the sense that it makes lower-value assumptions about participants' resources. Anti-social would be assuming resources too high. Mutual compatibility and the ability to verify and participate in the Bitcoin network, is basically the only meaningful definition of pro-social when it comes to Bitcoin..
@_date: 2015-12-31 21:32:05
IIRC, the reasoning is also that malleability doesn't matter in segwit, since the witness is segregated, it doesn't matter which authorization you have as long as you have at least some valid authorization.
@_date: 2015-12-27 03:48:13


Nobody ever said that high-bandwidth nodes can't achieve history consensus with themselves. However, getting a set of high-bandwidth nodes to achieve history consensus with themselves does not meet the Bitcoin design goals.
As resource requirements increase, there is an increasing inability for low-bandwidth Bitcoin computers to verify blocks, transactions and related data. Block contents are required otherwise nodes (indeed even miners) don't know whether to reject a (PoW-valid but otherwise) invalid block.
I suggest reading this subthread: 
The reason why it is important to not exclude the low-bandwidth portions of the existing Bitcoin network is because of the importance of compatibility, network effect and growth. Hard-forking a currency into multiple fragmented pieces is not a good way to ensure currency compatibility, nor adoption nor reliability.


Indeed, there are people (even users!) that don't understand Bitcoin. Some might even think a client that is self-hard-forking against itself is a good idea.... but they would be wrong. It should not be surprising to you that misunderstanding about Bitcoin exists. You have yourself been party to this on occasion, instead of resolving misunderstandings (whether your own or others!) you insisted on correspondence only in the form of PDF (just kidding- but yeah you were ridiculous..... you know what, nevermind, I am not kidding).
Re: "40".... this is ultimately an unverifiable claim, because there's no way to achieve consensus on number of nodes on a network. At this point I am pretty sure you have already been informed about sybil attacks..... so why talk about number of nodes, as if it is a verifiable value ? Collecting these details on the Bitcoin network is useful in some cases but you have to be super careful about what can be known about these details --- the numbers aren't meaningful in the way that most people assume they are.
edit: backlinks,
@_date: 2015-12-30 16:17:00


other than the one you linked to, there was a [segwit soft-fork wishlist]( but yea we have not been good at keeping track of hard-fork wishlist stuff...... we should probably get on top of this...........
@_date: 2015-12-09 01:24:30








































gwern's gonna get doxxed and left for dead
edit: also on HN- 
@_date: 2015-12-07 14:58:42
see also:
@_date: 2015-12-01 17:52:55
You mean the BIP number assignment guy? IIRC the process is "email him off-list" to get a number assigned. Plus, there are mailing list archives if he wants to look at email. So why would he need to be subscribed to the mailing list?
@_date: 2015-12-08 15:30:50
Well here's a place to start:
@_date: 2015-12-10 15:09:15
BTW rusty i blasted off an email a few minutes ago to you; turns out that the moderated emails are currently _not_ being correctly archived on your server.... this is a bug.
@_date: 2015-12-06 02:36:14
Here are some transcripts:
day 2:
@_date: 2015-12-11 17:19:49
Alright this thread doesn't seem to be working. Could you take a look at the example over in this other one? It might help iron out some details.
@_date: 2015-12-10 15:10:27


This doesn't seem to be a popular opinion; the other developers seem to want heavy-handed moderation that focuses very strongly on short-term bitcoin development, and is only slightly willing to accept long-term development stuff.
@_date: 2015-12-07 17:24:47
like this hard-fork version in elements: 
@_date: 2015-12-20 02:50:21


That's not really what the Bitcoin developers are aiming for by operating or participating in the Bitcoin development mailing list. While they appreciate the spread of a shared understanding of Bitcoin in the world, they are not tasking themselves with that mission. The purpose of the bitcoin-dev mailing list is to facilitate the discussion between Bitcoin developers primarily regarding the development of the Bitcoin Core reference implementation. So, no.
All participants are encouraged to make the best possible contributions to Bitcoin Core. This includes efforts like programming, documenting, reasoning. When those contributions don't meet standards and expectations and they appear in the mailing list moderation queue, yeah I am going to reject those emails. This is very similar to rejecting buggy proposals or insecure patches provided in pull requests.
The purpose of moderation is to increase the signal-to-noise ratio of the communication channel. Ultimately we should not allow noise to oversaturate our communication channels. Our communication channels should be reserved for high-quality contributions, and we should have a well-maintained signal-to-noise ratio. Persistent high-volume low-quality contributions are harmful to Bitcoin development. Also, we should not be afraid to reject non-Bitcoin stuff.
Moderation will almost always have a non-zero failure rate (false positives, false negatives, etc). However, the "failure rate" of non-moderation is even higher because it's always going to be cheaper to flood a communication channel with noisy junk than it is to flood a communication channel with high-signal content. It's always going to be that way. The Bitcoin developers and mailing list operators believe that maintaining a high signal-noise ratio is way more beneficial to Bitcoin development and is a better way to serve Bitcoin developers, compared to the alternative of non-moderation.
Fallacious reasoning should not be tolerated (fallacies are a proof of failure during independent verification), and I should point out that this should also hold for Satoshi's reasoning. (At the time that Satoshi posted his comments, nobody was really picking apart all of his reasoning, which is sort of unfortunate, because I think that people would have found a lot of inconsistency in what he was writing, as they do now. Inconsistency is generally not good and breaks reasoning.) So when you do find inconsistency, how do you know which goal is the correct one? What if someone picked the other side of the inconsistency? How do you know you picked correctly? Well in other contexts usually the answer is "ask the person who originally wrote down the inconsistency", which is not an option here (in the Satoshi example) obviously. But absent that option, how do you know anything in this world? This topic is usually called epistemology. I have found that developers tend to have a strong sense of epistemology, often because of their experience with debugging and writing software. This comes in handy when trying to figure out the origin of an error, or why you know something is broken, and can tend to involve lots of skepticism and fact checking.
Since "ask Satoshi to clarify the inconsistency" is an unavailable option (and, I would add that even if he did answer, fallacious reasoning should still not be tolerated), the alternative option is that you have to steelman both (all) sides of the inconsistency, and then evaluate which explanation is stronger and accounts for all of the available evidence, and also evaluate which explanation most strongly explains why the other explanations are weaker or wrong. In the Bitcoin whitepaper, that's the same method that Bitcoin uses for figuring out transaction ordering ("The only way to know is to see everything" (principle of independent verification))-- except in Bitcoin, for knowing about transactions, the method (for blocks/txns) is way simpler because you only have to verify the difficulty of the Proof-of-Work... and unfortunately it takes much more effort to construct (for engineering arguments) steelmanned alternatives, not to mention their independent verification also tends to require non-trivial effort and thus cost.... So forcing everyone to do this all the time is just not going to happen, coercion doesn't work like that anyway, and physical coercion is also not an option; people are going to say whatever they want, they aren't going to spend effort on explaining why alternative ideas might be better (I mean, most people don't do this, it's not often you see this, and they usually have little direct motivation to do this, etc.).
But.... moderation can certainly solve that problem by selecting for at least a minimum signal-to-noise ratio, based on our best understanding of Bitcoin and related efforts. Yeah sure there might be a failure rate when moderating in this style, and yeah maybe it makes sense to measure that actual failure rate, but I think that high &gt;1% failure rates of this moderation style can still buy a really really high signal-to-noise ratio that reserves the entirety of the communication channel for on-topic productive Bitcoin development. (Numbers sorta made up, I'll have to think about this in more detail.) I also think that alternative moderation methods (like "auto-approve everyone after their first email seems OK") have a dramatically higher failure rate and generate more on-list noise, compared to a method focused on signal-noise ratio discrimination.
I think that it might be OK to have an incubation area where low-quality contributions can be developed with the assistance of other contributors or something, but there's absolutely no reason to clog the main communication channels with that, especially if it's not about Bitcoin Core or Bitcoin Core goals.
One other minor thing: imagine a world where Bitcoin truth was only understood by 500 people. In this scenario, I dunno why there are only 500 people that know "Bitcoin truth" or whatever, but that's the scenario. I think that even in this scenario, it makes sense to not have the 500 people constantly trying to explain to millions of people, or trying to counter millions of arguments unrelated to Bitcoin or whatever... It makes sense for those 500 people to just work together on Bitcoin and challenge each other to make the best possible contributions; if other people join up and continue down that path, sure that's great, but those 500 should not postpone their work merely because of distracting realization of immensity of non-/mis-understanding in the world.... Btw I am not saying that there's "only 500" in our world, I am just illustrating that example world to make my preferences and actions hopefully easier for you to understand.


I don't think "rights" exist like that; I think it's a horribly flawed concept. Judging correctness or signal quality is something that I think everyone is already naturally doing on their own as a result of how the brain works, in its information processing capacities. But note that I don't make any claims as to how well-calibrated with reality that people happen to be :-). Having said that, I could explain some of my internal clockwork to you I guess? I aim and attempt to cultivate my own independent evaluation of any idea that I come across, and I also attempt to reject fallacious reasoning when recognized. I believe that others can do this as well, and I believe this process can be improved. My motivation is solely my own, although I can appreciate that others might have similar motivations and comprehensions. I hold myself to certain standards for reasoning which ultimately I hope my colleagues will hold me to as well, even when I happen to fail by these metrics.
@_date: 2015-12-01 19:34:59
Is there any loss of zero-confirmation functionality occurring? Zero-confirmation transactions still exist and they still get relayed around the network. Mempools will continue to not have consensus, regardless of the existence of a partially (or widely) deployed replace-by-fee.
@_date: 2015-06-19 03:04:09


Yes, probably. However, nobody has really been batting for this and nobody has written a BIP for this yet, or an implementation. Smaller max block sizes have been mentioned a few times, see  for some of those proposals.
@_date: 2015-06-24 12:47:48


Nobody has really been arguing for "no increase ever" (this is a strawman but not a very important strawman). Anyway, here are some proposals:
@_date: 2015-12-05 00:25:00


Depends on the type of commitment transactions required. With [multi-chain lightning]( the commitment transactions could originate on any number of sidechains. Still using BTC, still using zero-conf transactions, still using lightning.
Disputes between users can be resolved first by dumping to the sidechain and then exiting through a peg back to the Bitcoin blockchain. If a user simply wants to get a Bitcoin mainnet UTXO, the user could use the multi-chain functionality to end at an atomic-swap or some other technique to get mainnet BTC out at the end.
All of this could be done without 100 MB blocks on the bitcoin blockchain.
edit: 100 MB blocks may not be required due to timestop (see page 16 of [the lightning paper](
@_date: 2015-12-01 20:27:48


Well, you need more (or different) inputs to add more fee. You might not have an input that matches the exact amount of additional fee you want to add, and thus extra amount needs to go to a change address, which reduces privacy.
@_date: 2015-12-12 02:02:46


Can't download a block header if you are too busy downloading other stuff. Whether the block header is a certain size is irrelevant. At a certain point you cannot pack any more bits down the link.
If you are downloading _only_ block headers, then you will not be able to tell whether invalid transactions have been mined into the block. You can check for transaction inclusion by checking the merkle root, but that wont tell you whether the coins were double-spent inside that block, or even in previous blocks. In the Bitcoin whitepaper SPV section (section 8), a proposal was put forward to use fraud proofs so that SPV clients wouldn't be vulnerable to these attacks.
However, even fraud proofs can have considerable large size, and they require downloading the full data to confirm that fraud has actually occurred. This too requires downloading, and thus bandwidth. :-)
I think you are going to find that the bandwidth approach to scaling has too many limitations in the Bitcoin system. Thankfully, alternative solutions are known and quickly becoming ready/available/tested/deployed.
@_date: 2015-06-18 18:28:15
Good question. Someone's access should be immediately revoked under many situations, such as when they start blackmailing or something. Revocation can be less extreme, and at the same time there are trivial commits that nobody cares about bypassing the review process (although it could be argued that trivial commits should never bypass the review process, but I have no interest either way on that front I think).
@_date: 2015-06-19 17:24:41


There was never anyone that engineered the constraint that the system can't support 100 trillion transactions per second. This isn't a strawman, either. The part of my comment you were replying to was stating that system constraints aren't because of Blockstream; what number of transactions per second would convince you that Blockstream isn't the cause of system bottlenecks.....?




Well, nobody argues that a working blockchain with working transactions is a failure.


Right....... so if you assume that the network is working with 100 MB, it is hard to argue any other details. The problematic scenario is the one where 100 MB blocks cause the network to break in an unrecoverable way. Anyway, everyone agrees that the max block size will be increased, although so far people are still considering various [proposals](


Agreed, the 100 MB + working blockchain scenario was described as working and decentralized. But there's also a possible 100 MB + broken blockchain scenario, unfortunately.




Could you please describe how the market could bypass physical fact..? Why then hasn't the market been able to "decide" to make faster-than-light transactions? I am so confused.
@_date: 2015-12-26 22:02:27


Nope; the other Bitcoin Core developers will complain very loudly (and then proceed to fork and move somewhere else) even when all 5 are using demonstrably poor reasoning.
@_date: 2015-12-18 23:49:57
It's not even about being polite; he just got some details factually wrong (e.g. magical thinking regarding user-weight to decide engineering parameters), and since he's chief moderator the other moderators weren't really able to do anything to postpone his message or ask him to fix etc.. Oh well. Hopefully this will be fixed when bitcoin-dev mailing list moderation policy is examined in the near future.
@_date: 2015-12-18 03:40:22


"requirements" matter to participate in and compute network state details....
@_date: 2015-12-08 01:41:22
@_date: 2015-12-22 20:41:13


it is: 
@_date: 2015-12-10 17:34:21
Who wants a lighter approach to moderation? besides jgarzik?
@_date: 2015-12-22 16:10:37


This turns out to be false, see: 
which was about [an alarming amount of invalidity]( ...
Given [his known bias as managing editor]( I suspect that he is willing to overlook this invalidity while still claiming it's comprehensive and factual, since he through this method could at least accumulate [readers who confuse "academic document formatting" for "truth"](
btw this is like the [nth x-post]( of that [comment]( what gives? no updating?
@_date: 2015-12-30 17:46:05


Sorry, could you elaborate please? Thanks!
@_date: 2015-12-01 19:55:13
A "payment channel" is a sequence of bitcoin transactions, many of which are zero-confirmation. So you are essentially asking why you would want to use zero-conf bitcoin transactions. And you seemed to already agree that zero-conf worked for you. So you wouldn't be "switching" to anything except a different sequence of bitcoin transactions. When you find out that something doesn't fit your needs (even in the absence of replace-by-fee, "naturally occuring" replace-by-fee has been known to occur due to lack of mempool consensus), it's reasonable to "switch" to something that does, and since the alternative is a different sequence of bitcoin transactions.... seems OK, except for the current lack of widely-deployed payment channel tech.
@_date: 2015-12-10 07:54:07
for those trying to follow along, I replied over here,  and in  -- I need better moderation policy to be able to reject posts at my convenience; has already expressed incredulity about possible reject decision for that email, so it seems like policy is already uncertain enough. Hopefully we'll get this resolved soon. Sorry about the interruption of normal bitcoin-dev service.
@_date: 2015-12-19 15:56:04
I will definitely moderate "wrong stuff", heck yeah. Moderator policy is shifting more towards "yes we are going to moderate and prevent low-quality content from wasting everyone's time".
@_date: 2015-06-24 13:38:36


So your claim is that all of the proposals for off-chain trustless transactions are all flawed..? or fake? I don't know which thing you are trying to say.
@_date: 2015-12-02 04:47:30
re: testing for replace-by-fee, see 
@_date: 2015-12-07 17:39:54
Unfortunately, claiming ineptitude will confuse the situation because absence/presence of ineptitude wouldn't change the non-applicability of governance over the consensus protocol.
@_date: 2015-12-31 23:21:57


and as points out, that's probably going to be botnet operators from day 1.
@_date: 2015-06-21 13:55:13


There have been many: 
@_date: 2015-12-07 17:16:24
Segregated witness was released with the "elements alpha" sidechain. At the time, the soft-fork method was not known, so even if he had looked he wouldn't have seen the soft-fork approach and may have considered a hard-fork too burdensome. Could be ignorance, could be malice, or (more likely) could be that good ideas often get lost in the noise despite everyone's best efforts.
@_date: 2015-06-24 14:43:26






What does "directly accessing" really mean though? You can't just draw arbitrary lines in the sand and say that accessing the blockchain through any way other than the p2p protocol is invalid, because no matter how you receive the data you can still run the rules. This is the same no matter how big/small your wallet is, or whether you're an institution.
See also 


Anyway, it's wrong to characterize "irreversible trustless payments" as possible only through the current p2p transaction relay gossip network--- that's what I was replying to. Bitcoin transactions are a physical collection of bytes and they can be transmitted by any means. Also, it may be possible to have a single bitcoin transaction summarize the history of a million or a billion other bitcoin transactions (although this implementation is only forthcoming at the moment).
Also... I don't want to strawman you too much, but it also sounds like any transaction fees would be too high for your taste, because theoretically it's possible for a person to exist who has less than enough BTC to pay as a transaction fee. Even in the absence of transaction fees, I think you might find this still to be the case because of mental transaction costs (for example, there's a minimum cost to thinking about bitcoin or to making any decision whatsoever, ibid. Szabo).
@_date: 2015-06-24 13:27:33




Wrong; there's a way to increase the max block size with a soft-fork:  Thus, a hard-fork is unnecessary.
@_date: 2015-12-02 23:30:33


Orphan rate is about a miner's competitor's orphan rate, even in the local absence of validation such as in "SPV mining". Therefore, block propagation is still relevant. What goes wrong is when competitors (smaller miners) get squeezed out because they cannot quickly enough begin mining on top of the big blocks, thus having a competitor that is more profitably winning blocks over time, such that there is hashrate consolidation in the larger miner.
Additionally, you cannot mine on top of block headers you have not yet downloaded.
This is important because lower bandwidth small miners will usually be unable to propagate their blocks to the network fast enough for others to begin mining on the new block, but this is all marginal and it's where the orphan rate starts to get increased by big blocks.
Even a natural orphan rate not caused by malicious intent can unintentionally cause larger miners to win-out over smaller miners. Over time by buying/building more hashrate this can lead to smaller miners left with increasingly smaller proportions of the hashrate. Some of this is going to be due to bandwidth asymmetries across the network, leading to miner hashrate consolidation, especially if the orphan rate gets "really high".


re: "selfish mining", not sure why you're bringing it up-- selfish mining was about block withholding and attackers (e.g., that the requirements for attacking can in some cases be lower than what was previously expected), but here's a fun paper about that:
Back to orphan rate for a sec; the good news is that [since we know about the (natural, not-necessarily-maliciously-intended big block miner) impact of big blocks on orphan rates and larger miner hashrate consolidation]( we can "debunk" the problem by designing and using Bitcoin software in a way that takes this knowledge into account. For example, in the above IRC logs I talk about the many ways of non-bandwidth scaling solutions for Bitcoin.
@_date: 2015-12-05 02:30:54


It's a fair question.
To use lightning, one would have to lock up some amount of BTC for lightning-exclusive use, which I believe still requires a hot wallet. Storing BTC long-term in a hot wallet is not a good plan. I suspect that the majority of the use for the Bitcoin blockchain would become entering and exiting long-term cold storage.
The side-coins would be BTC because of the two-way peg mechanism.
In addition, sidechains could conceivably reward merge-miners with sidechain-BTC instead of sidechain-unique-asset. Merge-miners would transfer back to the Bitcoin blockchain any of their earnings from the peg-denominated BTC subsidy (or transaction fee loot) on the sidechain, unless they wanted to increase their reserves on the sidechain for some reason, of course.
I suspect that over time the trend will be that Bitcoin blockchain miners are going to be mostly mining transactions that are entering/exiting long-term cold storage.
I would be way more concerned about trying to spend dust long before I would become concerned about presence of non-zero transaction fees.
@_date: 2015-12-13 02:06:14
Well, if you allow for embryo implantation in multiple wombs:
@_date: 2015-06-19 17:31:11


Both ways might lead to collapse; solutions are not always easy. There might be collapse when blocks are too full (because nobody wants to use bitcoin anymore), and there might be collapse when blocks are too large for the network to process. oops (Although I'm optimistic that increasing the max block size can work.)
@_date: 2015-12-22 03:30:59


There is no voting. That's not how the system works. This is not a democracy where different groups submit votes to be counted.


You can't coerce developers into writing software they don't want to write. They want to write what they think Bitcoin is; you're free to pay others to do other stuff, but the developers have no obligation to you (or anyone else) to fund those other activities.


Well they can choose to not run anything at all; also, consensus is not really about voting, it's about building on and strengthening a consensus history. Bitcoin decentralized consensus is about the ledger, not about the development of Bitcoin Core. But alternative implementations can use whatever "voting" strategy they want I guess.
@_date: 2015-12-10 23:38:46
Right, the problem was re: "maintaining" a share. The expected payout amount is not determined by "maintaining a share", but rather it's determined by mining and hashrate etc.
@_date: 2015-12-09 21:22:23


Wasn't just Greenberg, [they were also relying on Gwern](
@_date: 2015-06-24 13:11:42


Although it may look like magic, software development isn't a matter of making wishes and having software materialize that works flawlessly. When you put software into the world, the most likely result for all possible software is that it fails. Almost all possible sequences of bytes for software are byte sequences that will completely fail to do anything. All we can do is use our knowledge about the world and make educated guesses, and write code in a defensive manner, to protect against as much failure as we can remember.
@_date: 2015-12-03 17:57:14


When the smaller miner is mining on the smaller fork, yeah he has technically "orphaned" the big block. But not in any relevant sense, because the wider bitcoin network will never choose the smaller miner's fork, since he can't broadcast it quickly enough to enough nodes/miners.
The smaller miner's fork "orphans" the big block only to the extent that the smaller miner wasn't able to download the big block data.
There is zero chance of being able to download more data than possible, zero is not a "very small chance". Zero is no chance whatsoever. Zero is sayonara to the network.


The above text shows how this is false and doesn't work. Also, consensus protocol design is not majoritarian.


We cannot pursue discovery of larger miner trustworthiness (mostly because we're entirely uninterested in asking the question and have no need to ask) in sacrifice consensus protocol mission integrity. And besides, I already know the answer: larger miners can definitely be coerced by law enforcement, government, regulatory capture. This destroys the independence of the bitcoin network and the extremely valuable independence of the bitcoin financial asset.
Orphaning is yet another way that smaller miners are an increasingly small influence on the network, in addition to the natural progression towards hashrate consolidation into increasingly larger miners. So this sort of change would exacerbate that problem. Perhaps there will be other solutions in the future to make sure that smaller miners don't become completely inconsequential, but that's for another comment....
So what do we do? The reason for anyone to propose increasing the block size limit was ultimately _scale_, which is a concept _not_ limited to bandwidth. There are many non-bandwidth scaling proposals, and all of them should be preferred over launching an experiment regarding increasingly-larger miner trust consolidation.


Yeah I guess you could make that assumption more reasonable if you had miners with identities and reputation and regulation. But absent that, "validationless mining" is not reasonable.


Agreed, except block sync and propagation cannot add bandwidth, only physical network upgrades can do that.
@_date: 2015-06-04 01:47:19
transcript: 
@_date: 2015-06-19 17:33:10


That might be unsafe for various reasons: 
However, it's of course safe to fork an open-source software repository and use a BDFL to run the repository; this is a separate topic from network consensus and hard-forks.
@_date: 2015-06-16 01:15:27


@_date: 2015-06-19 20:46:20


There are many [block size proposals]( and some of them even seem to be less controversial. Ideally our process for selecting which proposals we are each individually investigating would be better (in all the ways) than just optimizing for controversy. Other than that I agree with your other points.
@_date: 2015-12-30 16:12:54


even if the network can handle 2 MB blocks, it would be interesting to not do the upgrade, because you could get a lot of bitcoin benefit to low-end hardware and low-resource nodes by not immediately increasing capacity requirements. this gives time for tech advancement to accrue in bitcoin's favor, as sort of a buffer against all of the existing centralization pressures that we as developers haven't figured out how to fix yet......
@_date: 2015-06-19 17:50:38


Edit: also, being a "Lead Developer" is a very specific term with a very specific meaning. Look it up.
@_date: 2015-06-18 23:22:57


I could think of many reasons why they would be doing that. For example, even if you don't know what you're doing, it is easy to get companies to think that a centralized model makes sense for bitcoin development; companies usually expect this in almost every other form of commerce. So it makes sense, without implying anyone does or does not know what they are doing. This is much cheaper than asserting otherwise, even if the assertion would have been true...


Well, it's possible they have different customers of their own, I guess. I don't want to speculate about the range of possibilities there.
@_date: 2015-12-12 19:39:29


I think it's more likely that they will use zero-confirmation Bitcoin transactions, long before they go through the trouble of switching to another currency.
@_date: 2015-12-07 17:23:47


You could use lightning-style zero-conf bitcoin transactions to put some constraints around (otherwise undefined) zero-conf behavior. I elaborated on this concept in a recent comment [here]( Yesterday in Hong Kong, there was [a presentation on lightning regarding BIPs necessary to strength zero-conf transactions](
@_date: 2015-06-19 15:41:47
Similar discussion happened over here:
These were interesting:
@_date: 2015-12-30 01:08:08


"Differently"? The consensus rules seem to possibly (by accident) encourage fee revenue to get allocated increasingly "samely", e.g. a centralization pressure. PoW does not offer Bitcoin security in an increasingly centralized regime, see [near the end of my recent comment here]( in this thread.
@_date: 2015-06-18 18:46:00


That's true; however, there has been recent concerns that some developers are going behind the scenes to convince companies, miners, exchanges, etc., to adopt a hard-fork. Society is not yet accustomed to a decentralized system, so companies are far more likely to say "yep okay let's go with it" without thinking about whether the changes are likely to cause a catastrophic partial hard-fork. When you become more popular, you have to weigh your own popularity against what you say, so that you don't cause anyone to think that trusting you is a substitute for running rule validation or something. Neutrality has to be emphasized above all else, because otherwise you risk accidentally hard-forking the network into oblivion.
@_date: 2015-12-28 16:20:43
"supermajority" is irrelevant, not sure why you're bringing it up
@_date: 2015-12-21 13:18:27


shieeet, a guy can't sleep these days? Hah. Just woke up, WTF is this.
@_date: 2015-12-17 20:06:33
skeptical that gratitude was ever the goal. it's certainly nice to have, yeah.
@_date: 2015-12-17 20:05:05


You mean by votes on the blockchain? Bitcoin solves a consensus problem for transaction ordering -- which is not the same thing as block size result computation. Governance decisions are not solved by Proof-of-Work-enforced consensus. I think you are ascribing too much magic to the Bitcoin consensus protocol :-).
@_date: 2015-06-19 17:41:53




Heh, I mean that even without an "artificial hard limit" the system still can't do that, and that it's not Blockstream's fault that the system has bottlenecks and constraints, or that the laws of physics don't allow infinite transactions per sec, and yet the laws will just as easily allow a system to exist that can shoot itself in its foot in unrecoverable oops-we-crossed-some-random-system-threshold-we-were-only-vaguely-aware-of ways....


So could you clarify whether you think that is an agreeable result, whether you would call that bitcoin, and also could you clarify if you are asking me about my opinion on that scenario?


Well, this partly explains why I wrote those questions a moment ago; I am not sure if you are asking "how can 100 MB blocks not work if the blocks are full" or if you are asking "is it possible that 100 MB blocks can't be processed by the hardware on the network"..?


The blockchain can bypass it if the rules allowed this, but in the process can shoot itself in the foot, such as as unrecoverable software failure. Now, keep in mind that I am not saying that 2 MB blocks are going to cause unrecoverable blockchain failure. I am just stating the extreme failure scenario, in the same way that "1 MB blocks are full and nobody can use it and nobody can pay the high transaction fees" is another extreme failure scenario to keep in mind.
Also: there must be some max block size such that the system would be unable to function- such as, where the nodes are incapable of download the blocks before the next block is created. This is in part what has inspired some people to write simulations and run WAN emulations of larger max block size.
@_date: 2015-06-28 23:03:59


False! There's a concept in cryptography called an "aggregate signature" which does not require additional transactions, although it may require some extra bytes...


I am talking about cryptography, not institutions.
@_date: 2015-06-24 23:56:30


Is your argument that "only institutions will be capable of running software to aggregate transactions" because aggregation technology will not work for non-institutional users..? (And more importantly, how would anyone ever be capable of writing transaction aggregation software that only works for institutions? Like is your concern DRM...?).
@_date: 2015-12-01 19:00:24


Bitcoin transaction receivers cannot opt-out of the negative consequences of treating zero-confirmation transactions like very-confirmed transactions, even in absence of (opt-in) replace-by-fee.
@_date: 2015-12-23 00:44:54
@_date: 2015-12-03 14:23:25


There's no way to enforce this, plus I don't see how it's relevant to the comment you were replying to? You claim the problem is data burst requirement, but data burst is usually limited to total possible available bandwidth anyway. I think.
Additionally, there is no way for a smaller miner with lower bandwidth to guarantee that their own block is on "the critical path" especially if there's no bandwidth-critical-path available to them from their location in the network graph.
@_date: 2015-12-22 17:55:45


Yes, almost. I would change it to say "if and only if lots of bitcoin transaction fees are offered". You can't estimate the number of people using the transactions in big block scenarios nor small block scenarios; but yeah it's possible that more people would be using Bitcoin in the high-fee scenarios.
@_date: 2015-06-15 16:42:35


Good sentiment, although I suspect that even in the absence of a larger max block size, that they will take fees on payment channels, lightning bolts, sidechains, etc. Still, perhaps they presently think it is less likely that they will want to take fees from sidechain transactions than main chain transactions? Who knows.
@_date: 2015-12-02 15:16:09
How do you determine mempool "consistency" before a confirmation?
@_date: 2015-12-31 18:38:44
@_date: 2018-08-21 17:44:57
transcript: 
@_date: 2015-12-08 16:56:59
flexcap stuff: 
bip101 testnet propagation data: 
overview of BIPs necessary for zero-conf payment channels: 
jgarzik bips talk: 
fungibility and privacy (older video): 
@_date: 2015-06-19 15:51:47


Yeah, I can't think of any at the moment that have posted proposals on the mailing list for smaller max block size. I also know that there has definitely never (yet) been a BIP for smaller max block sizes...


Yes, that's true. Nobody seems to be interested in writing the alternative proposals for smaller block sizes, which is unfortunate. Here are some thoughts that might need to be incorporated into such proposals though:
(1) When reducing the max block size, should the max be reduced immediately, or gradually?
(2) Should reduction of the max block size be based on some adjustment algorithm, where the values of recent transaction fees are considered?
(3) Does it only go down, or does the adjustment algorithm allow it to go back to 1 MB to relieve pending transaction pressure?
(4) What's the absolute smallest max block size that the network could tolerate without imploding?
And now for my obligatory statement of neutrality: I really don't mind if the max block size is not reduced, but I think that it is interesting to speculate about.
@_date: 2015-06-24 12:54:33


So... are there any scalability limits that you think he _didn't_ cause? Which ones?
@_date: 2015-12-30 15:58:05
generalized soft-forks:
bip102 forced soft-fork:
auxiliary blocks and evil soft-forks or forced soft-forks:
soft-fork block size increase using extension blocks:
extension blocks were also discussed in this interview:
.... which includes something very similar to the idea of a soft-hard fork (something I was informed about on 2015-06-13 ..... not sure if I should mention this?)
some discussion from today re: origin of the term evil fork, evil soft-fork, forced soft-fork:
some much older discussion about extension blocks and sidechains:
some discussion about "generalized soft-forks" and extension blocks and evil soft-forks:
segwit soft-fork makes use of a similar idea:
discussion about evil forks and evil soft-forks and extension blocks:
note: this is an x-post from 
also x-posted here, 
@_date: 2015-12-12 19:48:11
Whether someone is an elitist doesn't change whether their ideas have merit (only the content of the idea decides merit). Also, I doubt he's an elitist anyway.
@_date: 2015-12-30 02:24:51


@_date: 2015-12-22 17:08:15


Anyone can keep making the same arguments over and over again in debate, no matter how many times they were refuted (Also: I don't really think of this as a debate.....). This is no excuse to slander anyone, but yeah it makes sense to remove them eventually. Old invalid arguments need to die eventually, and we can't waste all of our time on them.
@_date: 2015-06-19 17:14:57


1) he is talking about [contentious hard-forks]( not all possible hard-forks. Max block size can be increased without [controversial]( hard-forks.
2) adam3us [proposed extension blocks]( invalidating your argument that he will not propose anything?
@_date: 2015-12-31 14:58:29


well, we can certainly implement measures designed to prevent and limit this.....
@_date: 2015-12-27 13:24:13


except for all the proposals and implementations and evidence to the contrary.... To be fair, I think these could have been achieved without "debate" though.
@_date: 2015-12-28 14:20:54


Hard-forks don't work like that. Also, coinbase can choose during a hard-fork to pre-emptively convert their IOUs to whatever they want -- indeed this might even be advisable so that they don't end up with 2x or broken liabilities.
@_date: 2015-12-06 06:29:48
1) How much involvement with Bitcoin Core development do Chinese miners have? Has this been an intentional decision on their part? What goes into this decision? What might change these circumstances in the near future or distant future?
2) Are the Chinese miners planning to take advantage of the proposal to only send 1 kilobyte over the Great Firewall? I believe this was mentioned in an earlier presentation (the bip101 presentation?).
3) Are the Chinese miners reading the bitcoin-dev mailing list on a regular basis? Which emails have they found the most helpful?
4) Do the Chinese miners read Bitcoin Core pull requests? Do they do any code review?
5) What do the Chinese miners think about non-bandwidth methods of scaling bitcoin, such as payment channels, lightning, zero-confirmation transactions, etc.? Have they investigated these proposals?
6) At the last Scaling Bitcoin workshop in Montreal, there was a discussion regarding how to improve communication with the community in China. What have been the results of this and how to improve?
@_date: 2015-12-11 17:01:15
There's no way to guarantee seeing all the double-spends until they are recorded in blocks (and of course, a block that includes them are rejected). The above variant of replace-by-fee would not be enough to overcome this problem, and might even give merchants a false (misleading) sense of security. Misleading merchants is not a good Bitcoin adoption strategy. If merchants want to use zero-conf, then they should use the more restricted versions such as zero-conf used inside a Bitcoin payment channel, which add rules around the otherwise undefined "double-spending" behavior.
@_date: 2015-12-12 19:37:18


Bitcoin developers tend to disagree with this, so it would be helpful for you to explain why they think otherwise, followed by why you think their explanation is wrong.
@_date: 2015-06-09 03:18:59
slides: 
transcript: 
@_date: 2015-12-18 04:10:35


you want something like a censorship fraud proof? bitcoin doesn't have this at the moment.
@_date: 2015-12-11 16:45:55
Months ago the Bitcoin Core release manager did make a decision regarding bip101, although clearly it was not in favor of bip101.
I think that it is practical and reasonable to expect "endless discussion" of BIPs, because at least some BIPs are going to be busted or broken in some sort of fundamental way. So yeah, I guess you could argue that BIP discussion should move on to other BIPs and other proposals.
For the Bitcoin Core repository, the decision may not be to your liking, but it's still (irrefutably) a decision that they have collectively come to.
I think the outline from the Bitcoin Core developers has been around for a while, but was recently popularized at the Hong Kong workshop, so if I were you and interested in seeing (popularized, rather than nuanced) evidence of forward direction, then I would start there.
(Sorry for the late reply!)
@_date: 2015-12-18 14:57:43
i would also submit that an effective steelman would probably have to point out that blockchain hype is useful for these banks to overcome internal resistance to legacy database upgrades. by now many of the original internal bank architects are probably dead, so there are fewer people around that know how everything works, so to some extent people are willing to change but they are still conservative. hype gives them an out, the details be damned. now _that_ is a steelman.
@_date: 2015-12-03 14:13:30


Why would attackers be interested in eating...?




You cannot mine on top of block headers that you haven't downloaded. You were too busy downloading other stuff, other blocks, other transactions. "SPV mining" is when you mine on top of block headers without performing validation of the block contents, but you still need the block header to work from. That's one of the parameters required in the header of the block that you create.
@_date: 2015-12-03 20:52:35


Asking "why use LN when you could just use altcoins" is like asking "why use zero-conf transactions when you could just use altcoins".
LN basically adds restrictions around otherwise undefined behavior of zero-confirmation transactions, so asking "why use LN when you could just use altcoins" is like asking "why use zero-conf transactions when you could just use altcoins". Basically, the answer is that zero-conf bitcoin transactions on altcoin networks don't get into the bitcoin network, so they are essentially useless for people who want to transfer BTC around.


The fee market is for confirming transactions, not for sequences of (mutually agreed) zero-conf transactions that will never touch or see the fee market.


LN may require some additions to existing Bitcoin wallet software, but so what? Wallet users aren't going to see a convoluted mess, they will just see Bitcoin transactions flying around p2p style.
@_date: 2015-12-05 14:49:33
LN (and other payment channel solutions) do exist, and are increasingly existing. They are in development, and you're welcome to try out the prototypes or contribute effort towards their practical realization.
@_date: 2015-12-12 01:51:28
Your link does not seem topical (it's about segregated witness). Mars was used as an example for discussing engineering requirements.
@_date: 2015-06-18 18:05:10
"Revoking access" isn't the same thing as "just committing something". They are two separate types of actions.
@_date: 2018-05-21 18:01:57
Other SIGHASH_NOINPUT stuff:
@_date: 2018-05-14 15:53:23
@_date: 2014-10-20 14:20:58
Shameless plug, but what about  ? I would have to hear some more about your exact situation, but it sounds like a problem Royalty Chain solves. Basically the idea is to use Bitcoin to send instant royalty payments to multiple collaborators based on whatever they are proportionally owed. Ping me by email and I can arrange a demo, API access, etc.
@_date: 2015-05-31 15:00:39


That's one of the worst outcomes from all this; increasing the frequency of hardforks can be disastrous for the network, too, even if every hardfork has absolute consensus from everyone there is still the possibility that as you increase the number of hardforks towards infinity you increase the likelihood of crippling catastrophic bugs or takeover of the hardfork procedures and introduction of centralization pressures... Thankfully, nobody seems to be asking for a hardfork every 10 minutes... at least, not yet.
@_date: 2015-05-31 15:04:00


Yes, if those nodes were all operated by the same person or company, yeah that's centralized. Also it is possible for computers to spoof the presence of multiple computers on the same network, this is roughly the same as a Sybil attack.
@_date: 2015-05-31 18:47:39


Over time, such an entity could hardfork a bunch of the current rules out of bitcoin, to migrate it towards a more traditional payment system, while deprecating previous features (like Script). However, if the whole network was relying on a single mega-miner, that miner may not choose that route, of course. At the same time, such a company (if it is in the US) is subject to US law and regulations, and may be told by law enforcement that they must migrate the network to become less-bitcoin-like. This is all disaster scenario stuff, though.
@_date: 2017-02-25 20:11:56
except the signature is valid (and he doesn't have commit/push access anyway), nice try though :)
@_date: 2015-05-31 18:28:04


Unfortunately, the slope does not have to look slippery at all. Many changes can look harmless and look like there's a slope, but because of subtle side effects there can be consequences unrelated to whatever the feature was intended to do. For example, and I'm not saying this is the case, but it is possible that the current 5000 nodes on the network are all only capable of operating as 1 MB nodes. So even if we had developers all agreeing to hardfork in a year to another larger average block size, the network could still totally break by losing all but a handful of its nodes even if it seems like a reasonable change at first glance. This is just an example of how "frictionlessness slopes" aren't a good mental model for what we're dealing with here. I don't claim that all 5000 nodes are incapable of larger blocks, just that it is an easily plausible scenario that is worthy of illustration because it has all the best attributes- everyone thinks something is a good idea, then a subtle reason why it is broken appears later... Ideally the network should continue to operate even in the presence of our ignorance.


I don't think it's fair to characterize my last message as inciting drama, but I am willing to hear you out.
@_date: 2015-05-31 14:40:32


Unfortunately, almost all of the businesses have been uninterested in running bitcoin nodes on the network. Instead they use the services of third-party API providers, who operate a single node instead, which happens to be centralization pressure. I think it would be an interesting project for someone to go around and ask all the companies why they're not running bitcoin nodes. Adding more businesses would probably increase this trend, not reverse this trend. That said, yeah I want more business, but not like that.
@_date: 2015-05-31 14:50:57


You cannot just decide how decentralized it is.... it sort of does its own thing, based on what the software and rules allow. Once you make a mistake and it becomes centralized, it becomes almost impossible to undo that mistake and make things decentralized again. So yes, everyone is trying to be protective here.


You'll need to propose that somewhere other than a reddit comment; I suggest opening an issue on the github repository, or something. It is very unlikely for lots of developers (who are busy writing software) to be reading every reddit comment and find your suggestion there.
@_date: 2015-05-31 15:47:31


If they are not automatically incentivized now (by the system), why would they be incentivized later? There's no rules in the code that are doing this; so what's the argument? I'm at a loss to see what you're saying, you'll have to explain it more slowly perhaps.
@_date: 2015-05-31 15:21:25


What competitive reason is there to run separate nodes that will exist later but doesn't seem to exist now? Please, explain.
@_date: 2015-05-31 19:27:10


Well, consider the case where the bitcoin blockchain is voluntarily converted into a centralized system. At that point, there's really no difference between the bitcoin system and a banking system. Bitcoin addresses essentially get turned into account numbers, just like at the bank. Under these scenarios and others, many of the rules of bitcoin can be forked out of existence and rewritten-- you may wake up one day and bitcoin addresses no longer work without permission from the Central Mining Authority.
See commentary here:
(But again, I am just describing what things look like with extreme centralization, and pointing out that it may pose an obstacle to what you find interesting about bitcoin.)
@_date: 2015-05-31 15:05:45


I have a speculative question about this, Luke. I am simply curious. Do you think that "a series of lots of hardforks" is more or less dangerous than "making everyone accustomed to quickly joining a hardfork"? We should be careful and pick the one that is less likely to explode the system.
@_date: 2015-05-31 23:08:05


Because that would decrease the resource requirements for low-end nodes. That's an excellent idea, and I don't think it requires larger blocks.
@_date: 2015-05-31 15:15:51


I am not sure that altruism is a good reason to expect full nodes to join the network in greater numbers. I have also been disappointed by the sybil-attackable proposals to incentivize full node operation. I think that in the end what matters is that a number of unrelated people doing unrelated things must be using their own bitcoin nodes for their own purposes, so that they have stake in the "game" and so that they are cautious about the rules being changed out from under their nose..
@_date: 2015-05-31 16:59:16
Well, characterizing "lots of transactions" as the ship sinking is a little strange. I could arbitrarily create a billion transactions and sign them, and choose to not broadcast them to the bitcoin network. Does that mean that the ship is sinking? What if I told you I did that 30 days ago? The blockchain still seems to be operating somewhat normally to me, based on what metrics I can observe.....
@_date: 2015-05-31 14:46:00


From a physics perspective, it is faster to spread a smaller blockchain. Larger average blocks would make it slower to spread.
@_date: 2016-01-01 03:47:52


They don't need to run Bitcoin at all (not even Bitcoin Core), especially if they think it's in their best interest to hard-fork into a system with rules that mandate higher resource requirements. If they are okay with these sorts of increasing requirements then there's increasingly fewer reasons to bother with much of Bitcoin's architecture.
@_date: 2016-01-01 01:53:43
CPU power is nice but hashrate is not "1 cpu = 1 vote". I don't even know what a "vote" is. Satoshi didn't implement "votes" anyway. He implemented Proof-of-Work (PoW).
What Satoshi should have said is that hashrate is used to decide transaction ordering (and a few other details) in the Bitcoin consensus protocol. It does not decide "governance". It does not decide "Bitcoin consensus rules", it does not write new software rules. It does not "compute democracy". It doesn't count votes, it doesn't create elections, and it doesn't itself entirely prevent centralization, and it doesn't counteract all possible economies of scale.


.... except there were self-destructive (self-hard-forking) rules that were implemented, and hard-forks are by definition incompatible with consensus. It's a consensus fork, after all.
It should not be surprising that Bitcoin developers have learned stuff since Satoshi left.


PoW is for Bitcoin ledger history consensus. Dynamic multiparty membership PoW-based authorization, as a method, is not designed to determine correct values for consensus protocol parameters or new rules (except those constraining previous more permissive rules-- it wasn't designed to do this either, but it seems to be OK at it). Transaction ordering is sort of irrelevant, it doesn't matter what the order is as long as all the Bitcoin nodes can eventually come to agreement, which is what PoW is used for in Bitcoin. On the other hand, Bitcoin consensus protocol parameters values (like max block size) is not determined by PoW. In the case of the max block size limit, we already know that people can agree to make highly centralized systems, and we know that increasing resource requirements can bump nodes off of the Bitcoin network, and we know that most people have few resources so node cost has to be pretty low if they are to use Bitcoin without a trusted third-party involved (concerns about high transaction fees are pretty weird in this context because if the minimum resource requirements to run a node are high, there's no way to run or use Bitcoin, so the transaction fee wouldn't even matter, even if it was zero). Centralized systems have happened in the past and people will continue making and deploying and using them in the future, which is fine and okay, but we're Bitcoin users and Bitcoin developers.... we have better things to be doing with our time (see [capacity increases (FAQ)]( from Bitcoin Core developers), such as continuing to make the best electronic asset of all time.
@_date: 2016-01-07 20:20:53
Disagree. Here's some previous convincing commentary.


Also, the [2016-01-07 Bitcoin Core developer statement]( soft-fork comments are better understood in the context of the [Bitcoin Core capacity increases FAQ](
@_date: 2015-05-31 22:14:11


I don't think that's what others mean when they are talking about centralization. Nobody is upset that bitcoin-related service companies exist, rather there is a concern that the bitcoin network itself can become centralized in its structure and operation, in the sense of nodes on the connectivity graph, not in the sense of people enjoying the services of companies.
Centralization is not "the existence of companies". Centralization is "the bitcoin network loses its p2p network over time because fewer nodes continue to operate". Payment centralization can be sidestepped by just selling private keys.


Well at minimum you have to admit there must be at least some (real) circumstances where increasing the operational requirements of the blockchain and its network's nodes, you exhaust the supply of network node resources. As you exhaust network node resources, it does not "give the most decentralization". How could it?
@_date: 2016-01-13 23:42:20


Nodes don't necessarily know that the miners are agreeing to some additional constraining rules (such as a non-publicized soft-fork). The primary function of a node is the verifying enforcement of known rules, not unknown rules.
@_date: 2016-03-31 23:57:34
The article says that [the Motherboard article]( was based on "the cipher list was impossible", but the Motherboard article doesn't seem to say this at all. So why would these other authors spend so much time refuting "the cipher list was impossible" if it wasn't said? In fact, I seem to recall [gmaxwell explicitly said that defaults could have been overridden]( duh. Perhaps the authors of this "don't trust anyone" pdf should take their own advice and apply it to themselves the next time they write :-). Also, I can offer peer review to catch fundamental errors like this. Turning this into a gmaxwell smear belies the true intentions of the authors. Yawn... next!
@_date: 2016-01-01 13:54:34


This has nothing to do with "1 cpu = 1 vote".
@_date: 2015-05-31 15:06:52


The more we hardfork, the more likely it is that the hardforking process can be subverted, or that (despite our best intentions) accidental bugs get introduced into the network. Hardforks should in general be avoided as much as possible.
@_date: 2015-05-31 18:44:26
Decentralization is the most interesting and unique property of Bitcoin. Almost everything else that bitcoin does can be done billions of times more efficiently using centralized systems.






property of bitcoin. Everything else is rather trivial and could be
achieved millions of times more efficiently with conventional
technology. Our technical work should be informed by the technical
nature of the system we have constructed.


interested in Bitcoin.  Is Bitcoin more of a digital gold or is it more
of a competitor to Square?  Is Bitcoin something that should improve
personal and commercial autonomy from central banks?  From commercial
banks? Or from just the existing status-quo commercial banks?   What are
people's fundamental rights with Bitcoin?  Do participants have a
right to mine? How much control should third parties have over their
transactions?  How much security must be provided? Is there a deadline
for world domination or bust?  Is Bitcoin only for the developed world?
Must it be totally limited by the most impoverished parts of the world?
@_date: 2015-05-31 06:14:56


Hmm that's not entirely fair, is it? He and others have been spending a tremendous amount of time writing content everywhere- papers, articles, technical documentation, reddit, multiple IRC channels, the bitcoin-development mailing list, and github issues and pull requests and code review. So it would seem that there's both code being written, and lots of words being written. I would estimate he's written far more words and thoughts on this topic than Gavin at this point....
The bitcoin network should ideally not be one where the Bitcoin Core reference implementation developers have to personally defend the users from making terrible choices. Out of all the things that wont scale, having all the developers personally defend against all the media campaigns is like the most poorly scaling thing ever. Do we really want a system so fragile that if developers stop campaigning to work on software and writing source code, that the system falls apart? What happens if someone goes on vacation, or someone farts? gah. (What's even the point of writing source code if everyone ignores it? wtf) What's worse is that the media campaigns for BAD software decisions are only going to increase with time, not decrease. As bitcoin gets more popular, this sort of stuff is going to be happening more often and there's no way that personally refuting everything is going to scale....
The bitcoin network will continue to operate if the max block size limit is left unchanged. The dichotomy between off-chain transactions and on-chain transactions has been misrepresented multiple times by now. There are many ways of processing transactions that end up on chain, without requiring absurd huge fees. Ultimately though there must be some way to select which transactions- out of quadrillions per day- that must be inserted in the blockchain, and fees are a fairly accepted way of doing that. Without transaction fees, or any scarcity for this, it would be perfectly legitimate to complain that the network is not compatible with confirming someone's 1 quadrillion transactions per day (or pick any other insanely huge number that a centralized system would be capable of handling almost instantaneously).
As the number of transactions confirmed per second increases, the amount of decentralization drops to zero. When the amount of decentralization drops to zero, the US government steps in via law enforcement and asks miners to subvert (attack) the network to make things more "orderly". Well anyway, I am not claiming this is a direct consequence of the proposed hard fork, but I am simply mentioning one of the consequences of a possible long-term trend from these decisions.


Well I don't want money, I want bitcoin.
@_date: 2016-03-08 16:10:39
sorry for any inaccuracies that I have caused in the transcript. My abilities are limited because typing is hard, listening is hard, and doing both at the same time is even harder. By the way, the website is sourced from a git repository (  ) and I would be happy to take pull requests. In the past, I have to the transcripts added links to the corresponding youtube videos. Also, if you want, we could add text to the document saying "Sergio says this transcript is inaccurate (and he is probably right!), please watch the video instead". Feel free to email me about any of this, thanks &amp; nice meeting you in person at the event. :)
@_date: 2015-05-31 14:57:19


Man, I wish you were right, but Gavin has said on multiple occasions (at least privately) that he's okay with replacing proof-of-work with something more centralized or that he wouldn't mind if the bitcoin network eventually ends up being a ~five big google-scale nodes. This seems like a disagreement over a fundamental principle to me.
See the "ideological differences" section here: 
@_date: 2016-01-29 14:21:30


Nakamoto consensus does not decide on throughput, it decides on transaction ordering.
@_date: 2016-01-01 02:16:56


The Bitcoin idea was to avoid trusted third-parties, so I'm not sure why you are bringing up trusted third-party stuff? Yes, people can make those APIs, web wallets and other services, regardless of whether Bitcoin was intended to avoid payment processor centralization. Satoshi made lots of contradictory statements on this ("just use some big servers" and such from his emails or the forum, vs. his p2pfoundation ning post re: avoiding centralization), but really it's obvious what Bitcoin was designed to do and be-- the design and architecture is completely nonsense for the centralized scenario that Satoshi had imagined.


You are claiming it's unfalsifiable whether nodes have a resource cost?


Well, even if the total number of nodes has stayed absolutely the same, this does not seem like a good reason to increase the the max block size limit (yes, yes, I know that Bitcoin Core has already set forward plans to work on capacity increases). Instead of increasing the max block size limit, we can accrue benefits from upcoming hardware technology improvements (lots of people around here like Moore's/Nielsen's laws, for some reason (I don't put much stock in 'em)) to be realized that make it less costly to run full nodes under current Bitcoin protocol rules and conditions. Meanwhile there are various capacity increase improvements that Bitcoin Core is pursuing.
@_date: 2016-01-01 01:02:22


can you show me the opposite please? Like, something saying that larger blocks don't increase the resource requirements or resource costs.
@_date: 2015-05-31 15:08:27


@_date: 2015-05-31 15:12:51


Let me propose a hypothetical scenario to you. Imagine 1 billion bitcoin users. They all have transactions flying around that get reasonably confirmed, although they are not sure how because they never asked. At the same time, in this hypothetical scenario, there are still 1 megabyte blocks. This is something that is achievable with known and existing technologies. Yeah, I admit, if this was happening then I would not see a problem with 1 megabyte blocks. If there's a way to make the system work with smaller max block sizes, then we should take it. And if there's a way to make the system work with even smaller max block sizes (like 250 kilobytes or whatever), then we should take that as well.
@_date: 2016-01-11 21:29:37


Huh? Zero-conf transactions can be broadcast once your customer leaves.
@_date: 2016-01-21 16:37:14
Their section on "Bitcoin money supply change" is wrong; they are saying that "with majority miner agreement, a supply change is possible". That's not true at all..... that's a hard-fork.
@_date: 2016-01-27 21:54:32
a long time ago it was pointed out to miners that they should use a single date for any sort of hard-fork plans. But this is all silly since we already know how to do soft-forks for this. To the extent that they want to continue insisting on hard-forks, they should not bother with "hashrate signalling thresholds".
@_date: 2016-01-30 03:11:03
Nope, it doesn't repurpose PoW for voting, because the votes can be trivially censored by mining on another block. That's not what's going on....
@_date: 2017-03-31 17:15:33
_or_ they could refrain from spreading lies and bullshit; wizards have no obligation to help those who raise false accusations against wizards.
@_date: 2016-03-06 12:24:43
from yesterday, 
@_date: 2016-01-29 21:02:20
That transcript is _slightly_ wrong in a few places. Go to the source material to figure out what was really said. A more precise version would be good to have.
@_date: 2016-01-01 19:07:33


That's only true under some assumptions and other lemmas which were [refuted]( for other readers, there is a related comment I just made [here](
@_date: 2016-01-01 14:24:07
Proof-of-Work is not "trust free", see 
@_date: 2017-03-24 10:11:49
That is not how a reorg attack works. Intentional orphaning, yo.
@_date: 2016-01-29 18:46:32


That's not true; please read the whitepaper (  ) and then take a look at 


Soft-forks are a signalling mechanism between miners, and the results are supported by upgraded fully-validating nodes. Perhaps you could say it's majoritarian during initial activation in the presence of no fully-validating nodes, but you can't really measure that in the system after the activation period: you (as a miner) run the risk of blocks getting rejected by the p2p network if you mine soft-fork rule violations, regardless of whether you believed you had "populist consent". :)
PoW hashrate can't pick the rules of the system much, they can only signal version bits or support flags etc. PoW hashrate could try to /intimidate/ full-nodes into participating in a hard-fork, but intimidation does not seem like a reasonable network design and maintenance strategy, especially for a global financial system.
@_date: 2016-01-22 17:27:22


The only way to own BTC is to hold your own private keys and run a fully-validating node:
@_date: 2015-05-31 20:44:50


Eh, you're correct that the hashrate itself does not determine the rules. However, we were talking about a centralization scenario where there is only a handful of mega-miners that are colluding together. When they announce a hardfork, they could easily attack other chains with massive reorganizations and cause those chains to be useless. So this is sort of rule changing by coercion. You're right that this cannot happen with hashrate only.


I wasn't talking about a 51% attack, but you're still correct anyway. With unoperable other forks of the blockchain, users may be incentivized- through coercion- to participate on forks that they at the time might not completely agree with, but want their transactions to be processed anyway. Over time these decisions add up and suddenly you're submitting a scan of your passport to the Central Mining Authority.
I would like to re-emphasize that this was simply a discussion about what centralization can become.
See also 
@_date: 2015-05-31 20:59:45


Yep. However, they can attack other chains if they have a significant excess of mining power (hashrate) to render unusable the other chains with the other rules they disagree with.... This sort of coercion may tempt node operators to switch to the other rules, which itself could be a "slippery slope" of "just one more change wont hurt, right?" reasoning. Hopefully this gets balanced out by others who recognize that sticking to the original rules, and continuing to mine, has outsized advantages (like receiving the rewards that the other large miners would have received themselves) while others are off working on a possibly-going-to-fail attack ruleset.
@_date: 2015-05-31 16:47:13
Not everyone who disagrees is a moron; some of them have genuine concerns that motivate their positions. There's no central authority on Bitcoin and what Bitcoin "is" or "is not", so it is not surprising that some users want different directions compared to others.
@_date: 2016-01-15 01:24:01


Oh you mean like how all bitcoin transactions are reversible? After receiving any number of confirmations, there is a certain amount of Proof-of-Work that could be done, increasingly vanishingly unlikely within the means of anyone, to cause the transaction to be reverted. Indeed this is why the six confirmation timeline is one of the recommended minimums.
As for zero-conf transactions, the situation is even more nebulous because zero-conf transactions refers to zero _confirmations_, which is to say that the network has not come to agreement about the existence of that transaction.
Unfortunately there is no way to prevent a user from signing multiple transactions. Doubly unfortunate that there's no way to guarantee consensus among mempools across the network (plus it wouldn't make sense anyway, it would be "pre-consensus" consensus, but how can you be something while also being pre-that-something?)
The part he's leaving out is that a user can already always sign different transactions, even in the absence of replace-by-fee.
Here are some details about how zero-conf transactions work:
Here is why replace-by-fee does not remove zero-conf transactions from Bitcoin:
Here is a FAQ about replace-by-fee:
@_date: 2016-01-01 00:50:27




What do you consider research, here? A paper? a PDF file? A published paper in some journal? An email to bitcoin-dev? A reddit comment but based on experiments? .. what about a comment based on experience? Thanks.
Intriguingly, even if the Bitcoin Core developers introduced a block size hard-fork into their client (which is something they don't want to do with any of the current proposals, apparently), they would still not be capable of forcing the network go through with that hard-fork. Bitcoin adoption is voluntary, and thus it can only be voluntary to also adopt hard-forking current-Bitcoin-incompatible rules.
The argument behind "larger blocks lead to more centralization" is that there exist bandwidth asymmetries on the Bitcoin network between the p2p nodes, and there is a maximum limit to the data that can be transported over some of these links. By increasing the requirements beyond the limits of these connections, it is possible to bump those nodes off the network, reducing the number of nodes (people) that are able to participate in Bitcoin.
The argument against "larger blocks lead to more centralization" from Gavin was specifically "a larger maximum block size wont change how easy it is for users to use alternatives to running a full node, will continue to be easier to use a web wallet or a third-party API, and bigger blocks will not significantly contribute to the trend of declining counts of full nodes". Others have also added to Gavin's argument something like "by increasing the max block size, there is more space for more people even if transaction fees increase even if there are more transactions, so those people getting transactions into blocks might run more nodes even if the resource requirements are significantly higher than current requirements".
His argument that increasing the block size does not change "that equation for users" (his words from his blog post) is wrong because users that don't want to use a trusted third-party (e.g. they want to use Bitcoin actual), will have to use a trusted third-party if they do not have sufficient bandwidth to meet the new increased minimum resource requirements. That sounds like "changing the Bitcoin equation" to me. The existence of a third-party API service does not make "trust a third-party" suddenly viable for Bitcoin, even in the presence of larger blocks. If Bitcoin could work using a trusted third-party like that, there would be no reason to bother with decentralization or PoW or any of this other inefficient blockchain stuff. But for some reason we do Bitcoin like that :-).
Regarding "well there might be more people who use Bitcoin in the future, and some of those people might run full nodes".... there are people who are running Bitcoin nodes _now_ who would be incapable of doing so with larger blocks. Maybe we should sacrifice those people in the hopes of even greater adoption, though? How many people should we sacrifice? What minimum cost to pick? $1k minimum is OK but then why wouldn't $10k minimum be OK? As you increase the costs there are fewer and fewer who can afford to participate. This is the minimum participation cost, the minim resource requirements being pushed up. To participate you need to both be capable of affording the minimum participation costs as well as the transaction fees. If the transaction fees go up too much, you can't participate either. But if the minimum participation cost (before you even get to transaction fees) is too high, it doesn't matter what the transaction fee would have been.
(((To be fair, I would be willing to do one or two Bitcoin transactions per year if the transaction fees were too insanely high for me to afford. I would probably be willing to mortgage a house or something, just to afford a Bitcoin transaction fee, and I don't even like mortgages, but I definitely think that Bitcoin is valuable to me even with high transaction fees.)))
@_date: 2016-01-13 19:24:12
I would not characterize any of this as a debate.
Your youtube link shows that you're wrong- "achieved something not as strong as the thing I proved was impossible"... which is precisely what I just said in my last comment. Also, that's not the doc that I was requesting you to find.
Anyway it seems that you were not genuinely interested when you asked "how do you know". This goes back to your insistence on "faith". I think you'll find that over time the value of knowing is much higher than the value of not knowing.
But you aren't going to find that today.
@_date: 2016-01-08 03:01:37
He would have to say that he has been intending to do something, otherwise his statements have not been hypocritical.
@_date: 2017-03-26 02:19:21
pindar, i think there is broad support from bitcoin developers already that they would be interested in contributing to an ASIC in terms of design and programming (VHDL/verilog/microarchitecture).  many of the talented individuals in our community are also talented at ASICs, it's many of the same skills.  the mask runs would have to come from somewhere else.  the other problem is that the details of a mask run often influence the details of the verilog/VHDL that gets written. this would probably be the ideal topic for which to tap outside advice about.
there are also many open-source sha256 vhdl designs floating around, although i will not vouch for whether they are sufficiently optimized. and obv. they are not mining-ready designs.
@_date: 2016-01-13 04:40:19


To be fair, Greg was right, it doesn't solve the Byzantine generals' problem but rather (as Ian Grigg pointed out) a relaxed version with different properties.
Matt is also correct that there is no academically rigorous consensus proof for BGP.
As for "it clearly does work", Bitcoin developers are generally not satisfied with "it seems to be working", especially when they know about existing vulnerabilities that invalidate the statement.... We can do better, and we can be more nuanced and more specific.
Security is absolutely not backed by "faith", unless you really really hate the random oracle model :-).
@_date: 2016-01-29 18:24:36


Bitcoin is not a majoritarian protocol, the Bitcoin design is not decided by majorities, not decided by minorities, and not decided by miner-orities. Also, it's important to realize that "mass adoption" has occurred for non-majoritarian systems in the world before Bitcoin. He's essentially arguing in favor of a transformation into a majoritarian populist system. His argument is unnecessary because we already know how to more-safely upgrade the current system without hard-forks and without having blood feuds between different Bitcoiners.
Here's what gavinandresen says he is thinking about the future of Bitcoin:  


.... snip ....








... snip ...


Here's the thing; we already know what heavy regulation has done to the modern finance system, it's failed and it's broken, and we have a way to do finance even better. Jurisdictional arbitrage between datacenters ain't gonna stop cross-jurisdiction cooperation.
@_date: 2016-01-13 16:11:33


That's not how money works. You choose assets base on features you know are desirable. If you are wrong, nobody will ever accept your money, independent of your "trust".


Bitcoin security is purely a technical matter, no matter how much "faith" exists or does not exist. This is why the "more adoption == more nodes == more security" thesis has been rejected; it's based on faith, not security. We can continue achieving adoption doing just as we have been.
@_date: 2016-01-05 17:18:07


Interesting to note that existing "settlement systems", like TARGET2, are actually just payment processors. They are not architecturally any different from centralized ledger approach to payment processing. Outside of Bitcoin, settlement/payments distinction seems to be meaningless.
@_date: 2016-01-01 01:27:48
Depending on fee estimation software bugginess, miners could spam-create transactions with high fees if they are convinced that they will make additional fee revenue back even given losses due to other miners eating their fees.
Also, in a low subsidy environment (like far in the future), perhaps miners will prefer to mine on an orphan chain if there was a mined transaction with a really really high fee in recent history.
This was partly mentioned here  I think, although I seem to recall a better presentation somewhere I can't remember at the moment....
@_date: 2017-03-24 13:54:11
this seems to be about 
or 
@_date: 2016-01-01 02:55:45


I agree with you that this information is included in blocks, sure. Also, I would point out that miners can communicate with each other out-of-band about soft-fork activation.
















So yes PoW is being used to signal soft-fork rule activation, especially for the benefit of full nodes. However, PoW itself does not check whether a particular soft-fork is a good idea, or a consensus-compatible idea, or whether it is buggy or insecure or whether any particular implementation is a correct implementation. I am afraid that other readers might assume too much about what PoW is actually doing.
PoW also does not do any of the actual transaction ordering, contrary to what I said in my previous message. I have no idea why I said that. PoW proofs are used to decide which blocks to work from...


geeze we're not using versionbits yet?
@_date: 2016-01-01 14:04:18


He said CPUs can be spoofed, not (regular/reliable) hashrate. If you assume X hashrate is 1 CPU, then hashrate hardware improvements will eventually fool you into thinking there's (X * improvement) CPUs.
@_date: 2016-01-29 19:20:32
Segwit soft-fork still doesn't "decide" throughput, it's just a flag that miners use for activation thresholds, and then you count some flags on the previous blocks built through Nakamoto consensus.
@_date: 2016-01-30 04:48:09


Just because a bunch of people choose to use another system does not mean that you are dropping the network.
edit: Intimidation is not a feature of the protocol, nice try.
@_date: 2016-01-30 01:33:46


Full-nodes verify all transactions and all blocks. Nodes don't assume that miners are honest regarding the rules, no.....
Maybe it seems impressive to imagine a network with massive PoW and no tiny-resource fully-validating nodes. But why use PoW in this scenario? What does PoW tell you, as a node operator? It tells the operator almost nothing--- you must see all the blocks and all the transactions, that's why Satoshi said "the only way to know is to see everything".
There are some theoretical constructions on the horizon that might fix this eventually, such as SNARKs, which could provide for proofs that are sublinear in size of the blockchain, although at great computational expense. This for the moment isn't available yet in a meaningful way.
Also..... fully-verifying nodes are important for another additional reason, which is that larger miners are vulnerable to both law enforcement and less violent but still concerning regulatory/compulsory control. Without the presence of rule validation you are basically advocating for a huge security hole :).
You think they are just "auditing"? Heh. They are serving up the blockchain to peers that want to participate according to the Bitcoin protocol rules.
As you increase the resource requirements for operating a full-node, you are pushing some full-nodes off the network, and increasing the minimum costs for participating in Bitcoin (e.g. you gotta hold your private keys and also run a fully-validating node, so.......): [1]( [2]( [3](
Welcome to Bitcoin.
@_date: 2016-03-01 17:23:08
Your post advocates a:
* ( ) technical ( ) legislative ( ) market-based ( ) vigilante
approach to fighting spam. Your idea will not work. Here is why it won't work. (One or more of the following may apply to your particular idea, and it may have other flaws which used to vary from state to state before a bad federal law was passed.)
* ( ) Spammers can easily use it to harvest email addresses
* ( ) Mailing lists and other legitimate email uses would be affected
* ( ) No one will be able to find the guy or collect the money
* ( ) It is defenseless against brute force attacks
* ( ) It will stop spam for two weeks and then we'll be stuck with it
* ( ) Users of email will not put up with it
* ( ) Microsoft will not put up with it
* ( ) The police will not put up with it
* ( ) Requires too much cooperation from spammers
* ( ) Requires immediate total cooperation from everybody at once
* ( ) Many email users cannot afford to lose business or alienate potential employers
* ( ) Spammers don't care about invalid addresses in their lists
* ( ) Anyone could anonymously destroy anyone else's career or business
Specifically, your plan fails to account for
* ( ) Laws expressly prohibiting it
* ( ) Lack of centrally controlling authority for email
* ( ) Open relays in foreign countries
* ( ) Ease of searching tiny alphanumeric address space of all email addresses
* ( ) Asshats
* ( ) Jurisdictional problems
* ( ) Unpopularity of weird new taxes
* ( ) Public reluctance to accept weird new forms of money
* ( ) Huge existing software investment in SMTP
* ( ) Susceptibility of protocols other than SMTP to attack
* ( ) Willingness of users to install OS patches received by email
* ( ) Armies of worm riddled broadband-connected Windows boxes
* ( ) Eternal arms race involved in all filtering approaches
* ( ) Extreme profitability of spam
* ( ) Joe jobs and/or identity theft
* ( ) Technically illiterate politicians
* ( ) Extreme stupidity on the part of people who do business with spammers
* ( ) Dishonesty on the part of spammers themselves
* ( ) Bandwidth costs that are unaffected by client filtering
* ( ) Outlook
and the following philosophical objections may also apply:
* ( ) Ideas similar to yours are easy to come up with, yet none have ever
been shown practical
* ( ) Any scheme based on opt-out is unacceptable
* ( ) SMTP headers should not be the subject of legislation
* ( ) Blacklists suck
* ( ) Whitelists suck
* ( ) We should be able to talk about Viagra without being censored
* ( ) Countermeasures should not involve wire fraud or credit card fraud
* ( ) Countermeasures should not involve sabotage of public networks
* ( ) Countermeasures must work if phased in gradually
* ( ) Sending email should be free
* ( ) Why should we have to trust you and your servers?
* ( ) Incompatiblity with open source or open source licenses
* ( ) Feel-good measures do nothing to solve the problem
* ( ) Temporary/one-time email addresses are cumbersome
* ( ) I don't want the government reading my email
* ( ) Killing them that way is not slow and painful enough
Furthermore, this is what I think about you:
* ( ) Sorry dude, but I don't think it would work.
* ( ) This is a stupid idea, and you're a stupid person for suggesting it.
* ( ) Nice try, assh0le! I'm going to find out where you live and burn your
house down!
actually I happen to agree with you.
@_date: 2017-03-30 23:02:37
transcript: 
@_date: 2017-03-24 10:18:24
What, like orphaning non-segwit signalling blocks, or even rejecting non-signalling blocks, shaolinfry style? Number of differences- it's not an empty block DoS attack, for one....
@_date: 2016-01-13 18:48:20


How do you know anything? See  and 


Bitcoin's fundamental security assumptions are unrelated to honesty, like all the security assumptions required to believe that cryptography works, that one-way functions exist, that the random oracle model works, etc. These are not about honesty/faith of hashrate, and it's misleading for you to say so.
Btw most of the claims about "proving Bitcoin consensus is impossible" are referring to some document about the impossibility of Wikipedia decentralized consensus. I haven't been able to find this document. I also haven't seen gmaxwell refer to this as evidence for why instantaneous decentralized consensus is impossible; he's probably said that Bitcoin doesn't solve BGP, but this is not the same thing as saying he has proved solving relaxed forms of BGP are impossible. If you could find the doc that would be helpful, thanks.
@_date: 2016-01-13 18:53:15
paypal has been known to reverse payments up to 180 days after. withdrawals are not "finalized" until then. of course, even "finalized" transactions can be reverted by way of prosecution in the judicial system.
@_date: 2016-01-01 19:05:31


Under adversarial conditions, you cannot guarantee block sizes anyway. Adversaries will voluntarily use max block sizes. For the average case, I largely agree with you on this point.


That's not what his research shows. Rather, his research shows that if you assume block propagation improvements beyond a certain point are impossible, (and a few other assumptions), then an (un?)healthy fee market might exist. There already exists [known refutations]( of those assumptions and follow-on work ([elaborated](
@_date: 2016-01-31 01:57:31
This should indicate to you that voting is therefore inappropriate for non-majoritarian systems :). The PoW hashrate is about transaction ordering of valid transactions and mining on top of which blocks.
@_date: 2017-03-31 17:14:14


Ahahaha. No, you can't twist the truth. You accused me of censorship, dude. I have no obligation to help those who raise false accusations against me. Kindly get lost.
@_date: 2017-03-24 12:55:43
Different conclusions on soft-forks and hard-forks aren't a double standard.
@_date: 2016-01-01 05:01:57
Hold up a sec though, if a miner decides they no longer want to be a Bitcoin miner, it's perfectly fine for them to stop their Bitcoin mining activity.
@_date: 2016-01-01 03:01:20


I think there was an idea about paying nodes for data, for relaying, etc. However, wouldn't nodes simply seek out free sources of Bitcoin data instead? Not sure how the idea was supposed to work.
@_date: 2019-03-22 23:07:36
transcript: 
@_date: 2016-01-21 21:53:01
It should be clear by now that Bitcoin Core needs to improve its communication strategy. I doubt they are going to be capable of doing this on the extremely short timeline that Bitfury has proposed (by this weekend). No representation on behalf of Bitcoin Core is going to be there. What Bitfury could do is have a Core developer join their discussion who only speaks on his own behalf, but I honestly doubt that this is what Bitfury is looking for.
@_date: 2016-06-28 15:53:48


The lore around here is that there isn't any internal governance, and nor does anyone think internal governance would be safe.
Bitcoin Core itself does have a decision making process for trivial decisions, in particular for the wallet and GUI and things that do not impact the protocol itself, although most people are bored to tears to hear about the details of that particular decision making process.
Still, it's obvious that there are people who are working on the protocol, and it's obvious that there are distribution channels for builds that some users download without independently vetting the source code to determine whether the software is safe to run. Safety is a good metric to focus on, as well as backwards compatibility (which is impossible with a hard-fork by definition) with the existing deployed network and its users. If you're going to have a crowd of users that are uninterested in manually verifying safety properties, then compatibility maximization seems like a good personal metric to judge by.
I think that ascribing problems like "users are just going to blindly download whatever you recommend, so therefore you have unlimited control and power of the system" to Core developers is unreasonable, and I also suspect anyone who believes that would also have to believe that the concept of apolitical money (like Bitcoin) is impossible.


To do that, you would need a central authority to issue identity tokens (like many crypto schemes) or you need Proof-of-Work to limit the number of identities to only those who have lots of resources (which invariably becomes the "the set of people who are wealthy", unless you're okay with endless sybil attacks, which we are not okay with).


Coin voting? Because there are critical, fundamental flaws and vulnerabilities in all voting protocols, and the developers choose not to shoot everyone in the foot. Proponents in favor of voting are unlikely to mention the downsides. Also, keep in mind: who decides the choices on the ballot from which votes are cast? Arrow's theorem? Also, why should anyone expect voting to be a reasonable way to do system engineering?


There is no constitution, only the source code which the bitcoin.pdf whitepaper made poor effort to describe.


The source code answers that question. It's the implementation.


@_date: 2016-06-25 00:55:05
Somewhat the opposite point is made:


Although, to be fair, you can only coerce the community to use other protocols, you can't coerce the definitions to change. So there's that, at least.
@_date: 2016-06-24 20:42:55
"Voting" makes everyone feel good, sure. You still have someone deciding the ballot of options from which to select from. I think this is avoiding the underlying issues.
@_date: 2016-06-28 13:18:03
Many of the developers concluded that "governance" is a failure mode for Bitcoin protocol rules because 'governance' will make it even easier for law enforcement intervention and (external) political intervention in the system. This trivially violates the mission integrity of the system. Structurelessness also has similar problems. So far nobody has proposed something that seems to work better. There's definitely some interesting social problems here, and yeah it's hard to get newcomers up to speed on proposals because of how utterly bizarre and unusual newcomers find this (a)social system to be.


Unfortunately, social consensus seems to be incompatible with disagreement because people will simply name you an outcast and not part of the consensus ("because you don't (dis)agree"). Look at how it's happening in the ethereum subreddit, "if you disagree with us, then you're a toxic sociopath". If they had any less self-awareness, they might vanish out of existence. I would recommend discarding the concept of "social consensus" entirely, especially because of its problems like sybil attacks, censorship, etc. The implementation of consensus in the Bitcoin protocol is not about social consensus, but rather an algorithmic consensus using the Bitcoin protocol. Yes this uses admittedly poor and confusing word choices, and the confusion and conflation that folks have about this is to be expected I guess.
@_date: 2016-01-29 21:03:12
Gosh, and what do you think makes miners have to follow transaction validity rules? :)
@_date: 2016-01-11 21:24:48
This is not how zero-conf works:


Replace-by-fee cannot eliminate zero-conf transactions. Also, replace-by-fee requires zero-conf transactions.
see also 
AFAIK, petertodd's reddit account suspension is unrelated to his [recent description of how zero-conf works](
@_date: 2018-10-06 23:32:28
transcript from u/maaku7's scaling bitcoin presentation 
@_date: 2018-10-06 23:31:44
transcripts:  and 
@_date: 2016-06-06 22:11:08


@_date: 2017-08-22 11:13:51
You need replay protection even if you have supermajority, actually. Otherwise you are exposing users to potential [losses from replay attacks](
@_date: 2017-08-10 22:37:21
this is extortion, not compromise.
@_date: 2017-08-17 16:28:03
@_date: 2017-01-10 04:01:07
@_date: 2017-08-22 13:28:11
You said so right here:


Your solution to replay attacks is coin splitting (which can't work for the entire UTXO set due to bandwidth/capacity limitations btw).
@_date: 2017-08-22 13:36:44


If that is really their perspective then I think [they should be more upfront about that](


Do you really think so? I share some mild amount of hope and optimism, but I am unable to justify it.
@_date: 2016-01-01 04:59:23
I don't see merit to that, I don't see merit to assuming a governance model, and I am not going to implement that for you.
@_date: 2016-01-29 19:12:57


That's not what the "honest miners" stuff is about, it's about coming to consensus on transaction ordering. Thanks!
@_date: 2017-08-22 13:31:01
The following is a bit of an understatement:


It's a non-solution because the entire UTXO set can't get this done in time due to inherent capacity limitations. Opt-out replay protection is still an available solution, of course.
@_date: 2016-06-11 18:25:09
transcript, 
@_date: 2017-08-24 02:37:27
Actually, Blockstream does not have a patent on segwit.
@_date: 2016-06-28 18:00:49
Well, I appreciate your effort to design a social system that you feel would solve those existing problems. You should be encouraged to continue trying that. My personal evaluation of the one you proposed, the one with rotation and so on, is somewhat negative, although I would like to emphasize that this should not discourage you from continuing to try to design social structures in general outside of the context of this thread.......
Fairness and democracy might ultimately be completely unrelated to a well-functioning Bitcoin system. If the users have whim one way or the other, should their whim be imposed on the system, is it because of the sheer quantity of users swayed one way or the other?
An interesting note is that Bitcoin does not really /force/ anyone to continue using Bitcoin. Everyone is free to stop using bitcoin if it no longer solves their problems or has properties they like. When should fundamental properties of bitcoin be modified to satisfy user preference, if ever? And if the answer is "never", how to adequately communicate to users that they should feel OK with preferring to use another system? So far this has been difficult :).


I have no reason to believe that 'miners expressing themselves' is any more relevant than anyone else expressing themselves. It's irrelevant whether an idea is proposed by a miner or a non-miner. All ideas should be evaluated and rejected when they are found to be broken beyond ability to repair, regardless of who originated the idea.
Maybe as a group, humans aren't ready for that sort of level of involvement in a project, and maybe its nature is too difficult to communicate to everyone. There's a distinct possibility that this is the case...


Oh certainly, it's a huge problem.


It is hard to tell exactly how many have any coins at all. Some developers don't have any coins. Some of the earlier developers were involved in mining, we think. As you have noted, they aren't paid, so it's hard to assume that new or recent developers have any coins. We also can't really ask these unpaid volunteers to reveal information about their personal financial situation, because this could be used against them for blackmail, intimidation, political attack, etc.


As unusual as it sounds, the answer is that a newcomer just shows up and starts writing code, fixing bugs, talking on IRC and reviewing pull requests to the Bitcoin Core source code repository. That's how I personally got sucked into this.


Yes there is software rot. Not only is there a set of protocol rules, but those rules are deployed on thousands of nodes across the world, and all sorts of people depending on different features at certain levels of reliability even if they are not running nodes themselves. So even the rot has to be maintained in some cases, e.g. maintenance of old releases with bug patches and security patches.


It's an interesting immune system. I view some of this as an immune reaction. It's good to have a bunch of people critical about any proposed change, although ideally the criticism will be put to productive use such as making better proposals or better alternatives, rather than endless social media banter.
In future scenarios where bitcoin has hundreds of millions of users, I suspect many users will decide that they want to remove the 21 million coin limit. The politics of that situation will be even worse than "block size" was. People tend to assume that yelling loudly enough, assembling enough people together with them, is enough to force others to do as they wish. I think that even if everything continues to operate correctly, that the social politics will continue to get more strange than we have already seen. This is somewhat unfortunate but I don't currently know how to change any of it without violating lots of my principles and values and such.
@_date: 2017-08-20 12:07:00
I made a comment the other day about why replay protection should be added to segwit2x from the perspective of a segwit2x supporter-- but keep in mind that I am not a supporter of segwit2x.






@_date: 2017-08-09 21:06:23
He doesn't "deny the s8x crowd the permission to make the change they want". They literally want an incompatible change-- that is not the fault of They can freely make as many incompatible forks as they want.
@_date: 2017-08-21 07:26:08
Here is some elaboration as to why replay attacks must be fixed by adding opt-out replay protection to Segwit2x: 
@_date: 2017-08-22 12:24:10
Thankfully, Core isn't proposing a contentious hard-fork, so that's not applicable.
@_date: 2017-08-22 13:52:05
why opt-in coin splitting (an alternative to opt-out strong two-way replay protection) is a non-solution: 
@_date: 2017-08-22 13:41:55


See  or [here]( And on a similar note, the [minting acceleration problems in BCH]( are worth keeping an eyeball on.
@_date: 2017-08-22 20:01:24
Visa transfers "dollars" around. Bitcoin doesn't transfer dollars. Bitcoin itself doesn't replace Visa. Bitcoin is an entirely new type of financial asset that Visa cannot deploy other than as a trusted intermediary.
Bitcoin is not here to move away from centralized payment processors like Visa.... The design of bitcoin is just fundamentally unsuitable to the problem that Visa solves. To make bitcoin natively implement what Visa offers (real-time, reversible trusted, "zero fee" to the consumer, instant payments), in absence of payment channels and other similar tech, you'd need to radically centralize the bitcoin infrastructure.
Bitcoin has had transaction fees from day one. I think early on a lot of people were promoting bitcoin as if it had no transaction fees. I would be pretty upset too if I didn't verify whether bitcoin had no transaction fees in its protocol. So to some extent a lot of the questions around transaction fees make sense, bitcoin is difficult to understand and wrap heads around.
Having said all that, segwit does enable more transactions to get into blocks, and it's a capacity increase for the bitcoin system. It also helps developers implement new types of systems that require transaction trees (sequences of transactions) before anyone signs the initial root transactions. (This turns out to be helpful for developers implementing lighting network stuff, but segwit isn't actually necessary for lightning.) So bitcoin is definitely moving forward and I think your concerns about centralization from bitcoin development is somewhat overblown. Staying vigilant isn't so bad, of course.
I think an area of legitimate criticism that could be investigated (instead of scale) would be looking at dust UTXOs and how over time the fee rate might eventually never return to a value low enough to enable small face value UTXOs to be spent. There have been some proposals for how to sweep low value UTXOs but I believe the proposals have required a hard-fork. This is the sort of concern that I would expect people to have, but instead I observe lots of "give me zero transaction fees and ultra-scale or give me bitcoin's death" chest thumping (... not necessarily from you, I don't remember you).
In a scenario where bitcoin has 300 kilobyte blocks, I don't think users would be pushed out of bitcoin. In fact, I think more users will be able to use the bitcoin protocol in that situation because the resource requirements go down over time compared to the alternative's growth in resource requirements. The number of transactions that can get into a block would go down but this is not necessarily directly correlated to the number of users that are participant to those transactions. Having such a small block size could even encourage and incentivize novel solutions to be developed that would allow for more users to utilize the same number of bytes. This is the kind of pressure you want because it gives tremendous reward to whoever can figure out the actual solution within the rules of the bitcoin system.
Scaling a decentralized system to ultimate levels is going to look like: blocks replaced by a single merkle root hash of constant size, the total blockchain size grows at a constant rate independent of the quantity of transaction volume, etc. etc. Currently the problem with this approach is that it doesn't protect against double spending so that's why you don't see anyone proposing it.. but it's a good example of what type of solution would be meaningful to bitcoin's problem space.
There's probably a lot of value to be had from developing and deploying centralized systems. Probably not all of the value has been captured by existing products. I don't think bitcoin should be aiming to capture that value at the cost of the bitcoin base layer. In this sense, bitcoin isn't really here to save you from all the plausible centralized systems that can go get deployed and create value.
@_date: 2016-12-15 01:47:02
Er, I don't think it was always Phil. Besides, Phil is "pgp".
@_date: 2017-08-09 04:43:33


There have now been years of work on segwit, and so many other efforts.
@_date: 2016-11-15 14:40:52
@_date: 2017-08-31 13:26:14
where's the stream link?
@_date: 2017-08-28 16:11:12
transcript: 
@_date: 2017-08-22 12:03:08
Heh, you buried the lede and put it at the end of your post: you admit that replay attacks are a problem, and you believe that it's okay to be complicit in replay attacks. So basically you're complicit in replay attacks.
@_date: 2016-11-11 14:59:01
@_date: 2017-08-22 16:58:33
Taking a look at this comment thread again, I think I should have replied to your parent comment, not your comment. You weren't the one that made false claims like "Bitcoin Core strategy is to use proposal" or "doesn't really support his own proposal". So I am not sure why I had replied to you. From my interactions with I can say that he takes bitcoin's design as a very serious topic and that he has good reason to conclude that decentralized systems don't scale as well as centralized payment processors.
@_date: 2016-12-15 02:49:21
The transcript is probably completely made up anyway. Nobody can type that quickly and be 100% accurate.
@_date: 2016-12-04 15:21:44
Er, that has nothing to do with Core. What you've linked to is some programmers who plan to work on and publish a branch of source code (and maybe a proposal doc, I dunno).
@_date: 2018-10-10 01:02:03
Didn't type that one. You're welcome to make your own transcript.
@_date: 2016-12-04 13:07:51
It's wrong to say "Core is working on a hard-fork" (from the title). That's not how things work. Some Core contributors are working on their own branch, just like any other branch a Core contributor would work on.
@_date: 2017-08-22 12:43:18
They are, in fact, proposing a hard-fork. [They even call it a "hard fork"](
@_date: 2016-11-25 04:09:22
transcript: 
@_date: 2016-11-01 14:57:23
@_date: 2016-12-14 23:36:07
transcript: 
@_date: 2016-12-15 02:19:00
_This_ one was Phil.
@_date: 2016-12-14 23:36:29
transcript: 
@_date: 2019-08-02 15:36:45
Segwit was a soft-fork, not a hard-fork. @_date: 2016-11-03 00:34:50
@_date: 2018-06-16 03:03:22


@_date: 2016-11-19 18:17:44
Schnorr signatures:  and  and  and 
MAST:  and 
Lightning:  and 
Extension blocks:  and 
Transaction malleability:  and  and maybe 
More available upon request.
@_date: 2015-08-09 15:52:05


Do you think that arguments of authority are completely ineffective? That nobody is influenced? You may have missed his email where he was talking about his vision for "lobbying" and "ultimate authority": 
Also, regulators asking about Bitcoin governance and BDFLs are not asking about git commit logs... Some users might be influenced by claims of governance to change how their nodes come to consensus on the Bitcoin network. Even something like the BIP process is something that BDFLs are accustomed to managing.
@_date: 2015-08-19 01:05:55


Because all it takes to spot a major vulnerability is for a single person to speak up, and for others to listen and evaluate. That someone had more accurate knowledge is great because it can prevent us from shooting ourselves in the collective foot.
@_date: 2017-08-22 16:22:17
Actually, it would be unprofessional if he said something other than his actual belief. Things get confusing around here, but surely asking for to outright lie about his beliefs should not be considered "professional".
@_date: 2015-08-13 22:20:24


@_date: 2015-08-02 21:39:59


There's no way to identify the size of the user, you can't block non-large institutions. So that's already impossible.
@_date: 2015-08-17 13:35:03


Unfortunately it is very easy to spoof commits, unless it was a signed commit.
@_date: 2015-08-09 13:22:30
You should review bitcoin-dev for emails about governance models.
"Bitcoin needs a 'leader' like a fish needs a bicycle." 






Also, there has already been lots of evidence of why voting is bad besides all of the traditional problems of voting, like miner censorship of individual votes, votegrinding, votestaking, vote buying, sybil attacks, etc. Additionally, having a BDFL has the additional problem of probably needing a money transmitter license in every jurisdiction, so good luck with that I guess?
Here are some questions you should ask:
* What is Gavin's definition of governance? Does it only cover the maintenance of wallet software? Does it include blockchain network consensus?
* When Gavin is talking with companies, startups, or regulators, how does he explain to them how bitcoin development works?
* How is Gavin going to respond to pressure from regulators that want Bitcoin to have a governance model that they are more familiar with?
* What is trustlessness? What role does it play in Bitcoin and in what areas?
* Are there any forms of governance that Gavin would not be interested in?
* What differences are there between Gavin and Mike's opinions regarding governance, if any?
* Is Gavin willing to register for a money transmitter license in all the relevant jurisdictions if he was to become BDFL?
* Does Gavin have a "warrant canary" arranged?
* What are the steps of the current BIP process?
* Some argue that Bitcoin's current governance model is incomprehensible or broken. What possible kinds of evidence to the contrary would be sufficient to refute this?
* Has there ever been anything completely wrong merged into Bitcoin Core?
* When Satoshi said "1 cpu = 1 vote", what did that mean? Was it a true statement? How do you count individual CPUs?
* Not everyone is aware of this so it might be helpful for listeners: How does miner censorship of votes work?
* Is there any way to measure a "majority" of Bitcoin users? Why does Sybil get to decide?
* Branding might seem trivial, but in the event of a hard-fork into two separate networks, who gets to keep the Bitcoin name and brand? And what about all the current altcoins- why can't they claim to be Bitcoin too? Aren't they essentially copies anyway?
* What would be the value proposition of a centrally managed Bitcoin? At what point or threshold do you think the value proposition would evaporate? or is there no limit ..?
* Are you sponsored by ChunkHost or something? What's the deal with the namedrops.
* Are there any benefits to a Bitcoin network where none of the participants are swayed by arguments from authority?
.. there are more, but that's your job not mine :-).
@_date: 2015-08-09 15:47:06
Why does their affiliation matter? No matter what affiliation they have, all of their ideas and proposals should be evaluated the same way every single time. Even if the NSA shows up and wants to introduce some change, they too should be submitted to the same level of rigor as everyone else. No preferential treatment or mistreatment.
@_date: 2015-08-09 15:21:37


Ah but they aren't BDFLs, they are just maintainers of the Bitcoin Core software. They don't have any special authority on the network. They can't magically define or change the rules of the bitcoin network participants. Gavin is talking about defining the rules (governance), and that is why regulators would take interest.


Yeah, wallet or node developers probably don't. Also, as long as the BIP process continues to work the way it currently does, its participants probably don't have to get licensed or regulated by the US government..... Probably.


Consensus and protocol governance issues extend beyond the maintenance of wallets. Switching to another wallet implementation is one thing; hard-forking the network is another. Making changes to the protocol. Changes to how consensus is computed. There was something sent to the mailing list that was essentially "I have been talking with companies behind the scenes, and we're ready to go to hard-fork the network"-- this is not related to Core vs XT this is related to network rules. Changing the rules like that is essentially what regulators would love to control; they will say that if one person can change the rules then that one person has to obey the regulators' decisions about what rules to make and how Bitcoin operates.
@_date: 2015-08-19 00:41:54
Ah my mistake, it presently says "[removed]" and not "[deleted]". Try using incognito mode on some fancypants web browser? Btw, good posts lately.
@_date: 2015-08-18 01:55:12


Some of this is based on the concept that it would be nice and important to have a reason to run full nodes other than altruism; full nodes are software that receives and validates all transaction in the bitcoin blockchain. It's deceptively easy to avoid using your own fully-validating bitcoin node, and the implications are not widely understood. Including multiple merkle trees some with invalid transactions would be an interesting way to encourage users to fully validate transactions, although I suspect there's a chance that it may serve to encourage users to use third-party API services instead of their own fully-validating bitcoin nodes.... Hopefully this isn't true.
@_date: 2015-08-04 13:54:02


Why would I use a centralized service to merge transactions, when I can do similar merging in a trustless way?
@_date: 2015-08-13 19:03:48


Bitcoin is a push network, not a pull network. Your software doesn't decide to accept or reject a payment, but rather validates all transactions that it is exposed to. Also there's no voting... it's not implemented.
@_date: 2015-08-09 15:28:49


Ah but those already happened. Sidechain software was released. There's a few sidechains already running.
@_date: 2019-02-11 01:33:06
transcript: 
@_date: 2015-08-14 02:11:48


You could, in theory, compile bitcoin-core with the lightning network. But why would you want the bitcoin-core developers to maintain the lightning network in addition to bitcoin-core? Separation of concerns can be quite useful.


Well, not really. Multisig doesn't work that way. The other person can exert no control that you disagree with. The only failure mode is something like "you forgot to relay (or have someone else relay) your transactions to take your money back when your counterparty misbehaved", er as long as your lightning wallet implementation isn't busted I guess.


The lightning network concept is just a series of bitcoin transactions. That's all they are. Physically the messages that your lightning-compatible wallet makes are literally bitcoin transactions, just with some different opcodes instead of vanilla P2PKH.


You could say the same thing about full blocks of at any max block size. Unaffordably high fees are already the case for the vast majority of all people everywhere, who don't even have a single satoshi BTC or don't even have a single UTXO.
How would you plan to prioritize transactions when (1) there is a finite block size and (2) there are many more transactions that could reasonably fit into a block? Which transactions would you pick? How do you pick?
@_date: 2015-08-25 20:34:30


I think you could make a better argument by saying something like, "freelancers who want to charge-per-minute could be better served by hearing about the financial benefits of avoiding micromanagement in all forms".
@_date: 2015-08-22 12:45:06


There's a lot of security work that goes into bitcoin. Keeping the network secure with mining. Anti-dos mechanisms, to prevent denial of service attacks. Prevention of remote code execution vulnerabilities. Just because the software and protocol is open-source does not mean that it is immune to network failure or other vulnerabilities. Another type of vulnerability is something like "the network can easily become centralized"... and another one is "transactions can't currently be aggregated into bundles thus making it difficult to use bitcoin if transaction fees were sufficiently high". Scalability isn't just a matter of increasing the size of the landing strip for the deliverance of millions of users, scalability is how we keep the mission integrity of bitcoin while not breaking it as it spins completely out of control into the clutches of massive datacenters. If you've got research to share with the broader community on these topics, please consider going to  in Montreal Sept 12-13 2015.
@_date: 2015-08-19 00:00:51
You removed your post :-(


 


 


 


@_date: 2015-08-17 04:27:46


That particular key was never used to sign anything as far as anyone knows, so how would anyone know whether that was his key?
@_date: 2015-08-04 21:33:01
@_date: 2015-08-04 02:52:08


So what happens when non-banks start making "settlement transactions"? Is that bad too?
@_date: 2015-08-09 22:58:39


They should be looking very, very closely at everything.
@_date: 2015-08-21 19:53:02
Vinay Gupta has a tendency to show up in the correct place but 10 years too early. It's interesting that he mentions Kevin Carson, because Kevin was posting to p2pfoundation a bunch around the time that Satoshi Nakamoto was doing the same.
like 
and  or 
@_date: 2015-07-30 17:05:04




There are ways to increase the max block size without using a hard-fork. He's not lying, just informed.
@_date: 2015-07-24 14:10:50


Chargebacks are not double spending. To make a chargeback, you call Visa and tell them you want a chargeback. Their internal ledger then shows that chargeback, returning you the Visacreds. Next, you spend it on something else. Double spending would require the chargeback step to be _skipped_.
@_date: 2015-07-30 21:49:08


Could you describe that scenario? What does that mean? I think you would have to make it impossible for transactions to aggregate multiple interests somehow. How would that work...?
@_date: 2017-11-25 19:53:52
actually it was $5000 
@_date: 2015-08-17 14:39:17
Yep, they are doing that, see  -- although, I happen to disagree about the value of face-to-face, to each their own...
@_date: 2015-08-17 04:16:51


Agreed, but hopefully we can figure out a way to make the routing also private so that hubs can keep hush without revealing the entire structure of the whole network or all the peers. I dunno how to do that with onion routing..
@_date: 2015-07-09 03:31:04


Here are some opinions to the contrary:


There are unique properties to the way that the bitcoin network operates that make it incompatible with traditional (and all other) forms of governance or leadership... I think this is a hard concept to agree with, in the same way that others find it hard to agree that bitcoin is better than money.
@_date: 2015-07-09 03:33:25


It seems possible to me that face-to-face meetings would take a long time to die off, even if they were made completely worthless or significantly less valuable. Additionally, it seems like there's an observation effect where you only see the people that choose to go to those meetings, rather than the people who don't because they aren't there. Give it a few more years (or decades?) and education will shift more online; these trends take a while to change direction, although MOOCs have already been happening for a while now and growing.
@_date: 2015-07-30 17:08:18


Double spending is not stealing from the merchant, except in the sense that you are stealing from all BTC holders by a silent tax increasing the supply of BTC. So in that sense yes you are stealing from the merchant. However, since double spending is impossible in bitcoin, this is obviously not what you're talking about.
Chargebacks, on the other hand, do not involve an inflation of the supply of money- they aren't double spending. Chargebacks can very easily involve theft, especially if you don't return the goods or services or something, sure.
@_date: 2015-08-04 02:53:01


Fees don't identify the size of the user either. You can make a transaction paying a fee using any source of funds, whether your own or someone else. Child-pays is also a related scheme that will help.
@_date: 2015-07-10 00:16:45


True! But also, there's no Bitcoin committee.
@_date: 2015-07-26 20:26:25


You're talking about stealing from a merchant, not double spending which is where you create a copy of your money and spend it twice.
@_date: 2015-07-08 20:07:14
At the moment, all of the core devs communicate with each other at nearly all hours of the day on IRC, the bitcoin-dev mailing list, the bitcoin-core issue tracker, and sometimes bitcointalk.org as well. I suspect that putting them all in one place would actually decrease the amount of idea sharing. One example of this is that on IRC many developers can engage in multiple simultaneous and asynchronous conversations at their leisure. The reason why I am pointing this out is because I am selfish and read as much IRC logs as I can, plus there's also the "bus factor" or "key man risk" of putting everyone in the same room that makes me uncomfortable.
As for BIP 100 and BIP 101, I am not sure that bypassing the mailing list or other development norms for a  "debate summit" is wise. I suppose there's still that "lingering threat" that hasn't been resolved yet?
@_date: 2015-07-26 20:24:59


Yeah, but even a 99.5% handle-rate might not be enough. Once the majority of the network slips past some threshold, like "can only handle 5% variance", we might break the network in a way that is unrecoverable, even if everyone's node is capable of handling 4 MB blocks.
@_date: 2015-07-28 01:13:31


There's nothing that guarantees the value that is picked will not be "unacceptable"..
@_date: 2015-07-13 02:25:31


Doesn't matter. All ideas should be evaluated on the merits of the idea, even if the idea was submitted by the NSA or whoever.
@_date: 2015-07-31 22:56:56


"Scale quickly enough" won't stop legislation from being proposed.
@_date: 2017-04-04 09:10:50
Some older extension block links and references:
@_date: 2016-02-03 17:00:13
The code can't (and doesn't) measure a "majority of users". Thanks for asking!
@_date: 2016-02-22 18:53:13


Anyone can write a broken node implementation, indeed many have been arguing that your understanding of Bitcoin is flawed in a bunch of ways and therefore unsafe despite your insistence otherwise. Does your concept of safety include peer review by Bitcoin Core developers and outsiders? Upload it.
@_date: 2017-04-06 19:56:31
@_date: 2016-02-11 20:16:50
And his clarification _was_ pedantic, compared to the other good reasons he mentioned (like "imposing a huge analysis cost on anyone else using the software").
@_date: 2017-04-04 03:10:26
Also, if the commitment is required in all blocks, then it doesn't sound opt-in for miners, especially small miners who may not have the bandwidth necessary for whatever size extension blocks are flying around.
@_date: 2017-04-06 01:29:31


anti-asicboost has been known for a while, do you put the first authored date, or the latest edit date?
@_date: 2017-04-04 15:10:08
it's not in the mod queue waiting for my attention either
@_date: 2017-04-04 09:21:14
also some logs:






















































































... actually a bunch from this day, probably better to just read the logs themselves..




















@_date: 2017-04-06 02:53:56
ah, could be typo then, but yes anti-asicboost has been thought about for a while now
@_date: 2017-04-06 19:51:22
yeah a few friends of mine have electron microscopes, 
@_date: 2016-02-05 18:30:14


"I don't believe a second, compatible implementation of Bitcoin will ever be a good idea.  So much of the design depends on all nodes getting exactly identical results in lockstep that a second implementation would be a menace to the network."
@_date: 2017-04-06 18:32:01


@_date: 2016-02-28 22:30:45
Right, unfortunately there's nothing stopping you from writing a broken verification program. This technique only works for information that you are able to verify, such as a sudoku solution which can be verified.
@_date: 2016-02-03 20:24:38


Yep everyone should. I have spent a bunch of time reading the source code.


Link me to where this happens in the source code. There's no measurement of "majority of users", believe me.
@_date: 2017-04-26 18:02:47
here is a fun thing i have timestamped (viruses) 
@_date: 2015-07-13 01:49:54
Don't forget CIA.vc :-) /sarc
@_date: 2017-04-07 15:33:10
sha256 hashes of the firmware files that were timestamped:
    f2d0a897828e09e8fa41999789b0aff2f166b5adeb1ecfbc47dc09ce34d77ad8  Antminer-R4-all-201612020035-autofreq-user.tar.gz
    20989239427ddfb8a846dc75e51e4364415190c1e774f6c0c7910fc7dc45be88  Antminer-S9-all-201702272206-autofreq-user-Update2UBI-NF.tar.gz
    4bfe7a1b745a35a8b84f5af116a706ad5731def74fc7949599c142726d2856a3  Antminer-T9-all-201703270300-autofreq-user-UBI-NF.tar.gz
    e1125b928c421e6f459be152693147a5f490c3af71094b6afbc33afb1d0b6ef0  S5+__20150924-325M.tar.gz
    1a8257795bf86e80025db90d042eb72d5dfada506c43f488d6c3144d02fba980  S5+__20150929-375M.tar.gz
    eed8cc03941e340ca4cefe7a8241c1af469bc4f8b8f9e9d69d79c86eae95eb66  S7-20160511-525M-2fan-4320.tar.gz
    15a507eba50a86719c99ee40b36a323f9458930edff194d64750c222bbad4f48  S7-20160511-550M-2fan-4320.tar.gz
    4c8f504e8b32ad937f1a35620376426e2b477d737c651e7aef0891447a5547f8  S7-20160511-575M-2fan-4320.tar.gz
    001bc75fc47879570cd3a22c43740837b470c44cb4830d2592741818dca4ba6b  S7-20160511-600M-2fan-4320.tar.gz
    320abaa0bfca48499b4f19db4e46d6c45fcf269e9f1d0723ddcc37a24911551d  S7-20160511-625M-2fan-4320.tar.gz
    f297288f1408fac3378bc4ec434127b8b6e2d4a7810a04f6b21d4a48b8061a01  S7-20160511-650M-2fan-4320.tar.gz
    b3391979b34bcaa595c28780c288f5f2008694f90999f6b55904fc08de99a49f  S7-20160511-675M-2fan-4320.tar.gz
    8303f2901586e208aa2b1643579e42c8791b6efb2f017138edf2cfef7808614f  S7-20160511-700M-1fan-6000.tar.gz
    87e4a7aa7dff1ea88d756643d8741009926203315767edb7c5462ba6993de9b8  S7-20160511-700M-2fan-4320.tar.gz
    066fb6f5ea6a546b3c0b44b52412872a96665821575bbace9cf39423dad212be  S7-20160523-700M-1fan-6000.tar.gz
    dab8443b8dabf486d236e96f5fa0a366b8410a96a501063ad68f5798c9a3743d  S7-20160523-700M-2fan-4320.tar.gz
    0eb0c7564479da03538b12ed7b1e39fb99c2d4451adcc2ba239106d3435e6ad2  S7-2.7T_201605181458-600M-2fan-3700.tar.gz
    9fe73b60aa3a1f0f79cac2efca71a2b795beadbfc01735d74ab0ffbbe4f8f2e7  s9-20160715-550M.tar.gz
    e0a846edc61ef4088ba2be33674dd088aa125b203b6f6f7959f681806eef87c4  s9-20160715-600M.tar.gz
    6e33fe690440a0edde174b1a8959f277f183d17f0391bbeda1d8d5fb2316468e  s9-20160715-650M.tar.gz
    24f39cb708389ad20c684eb7e9a3002d41e5db3f8a6e14d58564a2cf637f0625  SD-S5+-20150804.tar.gz
    aecd34505b5b1ada9ba47e5a4c839202331f2703b2570926e0a7681afe3f23c9  BitmainMinerTool-bin.zip
    17e01755ab940184354da40d5659a33f3a05936f60e2822f794a0ff5f62ccd0f  BitmainMinerTool-setup.zip
    ab7aee6fb91e9d05b6c1520d65da4f48cfcb9ea17b602a39facd7164da748d1f  antMiner_openwrt20131212.bin
    ad16374576e2d349ebe823a3454796d7a4f07a7b402d079dd9079159d3953c8a  antMiner_openwrt20131226.bin
    3367d2cd28e7ba4fb5031b269193001ed041778be50432697889603131b76df9  antMiner_openwrt20140207.bin
@_date: 2017-04-06 18:33:28
unfortunately, covert asicboost is probably disabled (or missing?) in the public firmware
@_date: 2017-04-06 18:34:11


you are wrong and need better hobbies, 
@_date: 2015-07-26 13:54:16


Perhaps your strawmen find it very difficult to use computers. Lumping all of the opinions of Bitcoin Core developers into the same category is a recipe for misunderstandings. The number one problem that any Core developer has expressed is a problem related to a threshold that might be crossed by the network that once crossed the network cannot recover from, such as a block that is too large or consistently large blocks that might cripple the network and make it impossible to reboot.
@_date: 2016-12-04 15:20:23
Anyone can submit randomly titled submissions to reddit, it doesn't mean it's "official core" or whatever. There are some folks working on a branch that implements a hard-fork... it's not "Core" working on a branch.
@_date: 2017-04-08 00:36:50
oops, that's my super secret engineering channel
@_date: 2016-02-06 21:55:24
Yep here's some other papers I have been reading: 
@_date: 2017-04-06 18:31:10


bitmain's already-public firmware binaries?
@_date: 2017-04-04 09:12:47
They did run to the press, made various threats to some journalists, and then I timestamped those logs.
(I just woke up and I am going back to sleep. When I am actually not sleeping in the near future, I'll have to consider whether it is rational to post those logs and timestamps.)
@_date: 2017-04-07 15:25:40
Here are some timestamps of the bitmain firmware from the other day: 
Also timestamped the bmminer.git repository.
These are timestamped in the blockchain:  These timestamps prove that the firmware existed prior to the existence of the timestamp, anchored into the blockchain at a certain block.
@_date: 2017-04-04 16:59:00
Are you storing only stem cells, what about blood and sperm and my chutzpah?
@_date: 2016-02-05 18:33:49


And it's wrong. There's no way in the code to measure majorities of "miners and nodes".
@_date: 2015-07-27 15:32:40


That's true, but it's also useless. Theoretically there could be a massive server farm that makes a 200 terabyte block. Right now. The fact that they are able to handle it is meaningless; the rest of the network will be unable to do so. It would take too long to download, the network will encounter synchronization problems, etc. (Assume that the max block size value was increased to tolerate this, even.)


That's possible, yes.


The limit doesn't impose reality, reality imposes on the limit. If we select a limit too high, then the network might get into an unrecoverable state where we can't "reboot" bitcoin. When I used the word "variance" I meant a variance in the block-handling rate. Block handling isn't a matter of just bumping the size of the max block size limiter, but also things like probabilistic synchronization issues. Even if the limit allows a certain block size, the physical bitcoin network itself may be incompatible with that block size (not incompatible because the value of the limit prevents it from occurring, but incompatible for other technical reasons such as impossibility, speed-of-light, synchronization, so many other possible reasons).
@_date: 2019-01-14 16:28:37
Someone was kind enough to type a transcript of my talk, 
but really just read the BIP 
@_date: 2018-02-11 21:45:18
I appreciated the perspective offered by [Wei Dai on cryptography in the context of brain emulation and technological singularities](
I think it's a lack of creativity, failure of imagination, or a lack of deep knowledge on behalf of speculative fiction authors. I find myself bored by most speculative fiction. They have no sense for what already exists or what's about to exist, most likely because of the absurd amount of specialization required to even learn about certain scientific projects. It's worldbuilding, and you might as well just go build in the real world anyway, I guess.
@_date: 2018-02-13 18:44:07
I don't know whether donations to scihub will really help the situation. They should widely distribute their entire library to everyone, so that scihub isn't a single point of failure. It would be easy to get money for distributing the entire library. It's one of the most important piles of literature ever created. I've offered in the past, but my offers were refused. Maybe someone has ideas for how to make this more appealing to scihub...
@_date: 2017-09-02 06:52:34
transcript: 
@_date: 2018-02-14 15:39:27
Do you have a complete copy of libgen? Ask yourself why not. They have torrents, but do they have sufficient seeders. There's a serious lack of distribution of this data.
@_date: 2017-09-29 01:26:09
extended review over here, 
@_date: 2019-01-15 00:35:54
No, you're not the only one. I should have added diagrams. Definitely not my best presentation, has room for improvement. Thanks for watching.
@_date: 2017-09-09 15:49:59
bitcoin's security derives from its rules not just hashrate stuff
@_date: 2018-02-13 18:46:03
transcript: 
@_date: 2017-09-18 22:52:00
segwit2x needs to implement strong two-way replay protection if they want to have [any legitimacy regarding the quality of their work](
@_date: 2017-09-27 10:50:35


That's not how merit works around here. Merit is based on the quality and details of a proposal.
@_date: 2018-02-14 22:49:24
Just to take a specific example, many developers in this community wouldn't want bitcoin donation addresses sprayed around because they feel it is one such violation. Is it really a violation of personal integrity to tell others your donation address?
Some follow-up here: 
@_date: 2018-02-14 18:45:58
it seems like you do not feel comfortable with personal gain as a motivating factor if not also self-considered-undue personal gain unrelated to whatever the original motivation was. Gain and loss are both healthy and I think you should consider that maybe personal gain isn't so bad, and that ethical action is not incompatible with gain.
@_date: 2018-02-02 20:01:30
transcript: 
@_date: 2018-02-13 15:26:46
Further improvements on attack probability numbers can be found in this paper: 
@_date: 2018-02-11 03:23:41
bpase18 transcript: 
bpase17 transcript: 
@_date: 2018-02-18 14:19:37
transcript of a discreet log contracts talk (don't have the rest of the other 5 hours in that talk): 
@_date: 2018-07-12 19:12:43
transcript: 
@_date: 2017-10-05 15:57:07
@_date: 2017-09-02 14:49:37
actually i asked aubrey about that and it's the other way around, aubrey is copying EDIT: do your reading, kids! 
@_date: 2018-02-10 14:04:19
transcript: 
@_date: 2018-02-11 18:50:03
Are there any good works of speculative fiction on the impacts of immortality on finance in particular?
Brain uploading (as a method of achieving immortality) might work one day, but lots of folks overlook the high cost of running a human brain emulation. Eventually it might be possible to optimize human brain emulations to cut down on unnecessary computation. The finances of this are going to be really weird. In polite conversation, I have noticed an assumption that the computation is expected to be costless.
And then you get into weird problems like your own cognitive privacy not to mention wallet privacy...
@_date: 2018-07-14 13:02:36
@_date: 2015-09-23 20:22:28


Sad nope, because "weak blocks" and "near blocks" are still blocks that have finite size and need to be propagated as well.
Here's a short review of where these ideas have showed up before: 
@_date: 2015-09-09 12:59:03


@_date: 2015-09-22 01:16:58


Besides human (mental) transaction costs, there's also the issue of chargebacks which makes "go get $0.10" somewhat impractical for everyone.
@_date: 2015-09-23 20:16:58
Here are some other "weak blocks" and "near blocks" proposals or mentions:
more recently:
@_date: 2015-09-17 19:52:25
more detail: 
x-post (well, it was earlier than mine): 
Also these two showed up earlier today:
Unfortunate timing: 
@_date: 2015-09-08 16:50:20


Very subtle; actually I am backlogged because I want to do that lightning network discussion from letstalkbitcoin the other day. I'll flip a coin or something.
@_date: 2015-09-14 00:36:02


See these:
* 
* 
* 
* 
* 
* 
* 
@_date: 2015-09-24 16:04:59


Previously I speculated that there might be some benefit to selling mining equipment to avoid chargeback risk when getting BTC to lots of users. But a slight correction to this is that most users already have computing equipment, so they could be mining for their "stream of satoshi BTC" already without buying more equipment to do so. Additionally, chargeback risk can be handled with an enormous fraud team, or doing cash-only sales.
"Buying into bitcoin" takes more forms than just buying some BTC. When a developer starts learning about bitcoin, they are spending (and investing) their time and energy into the subject. It's true that there are many people that can dig through the mailing list, forums, subreddits and IRC channels, or sit down and read the source code and extrapolate all possibilities from there, but in many cases paying for a high-quality setup (including a pre-installed node with gitian backdoored and ready to go) can be very valuable. Unclear whether a pre-installed node happens to be a good paid resource for curious developers, although it's better than a third-party SaaS abstraction over bitcoin.
@_date: 2015-09-25 13:45:05


Dunno, start here:
Bram Cohen had some follow-up comments between 2015-09-18 and 2015-09-25 in the -wizards logs, but I don't remember which day.
@_date: 2015-09-04 23:29:59


The deployed network would look very different if that value was set to 0. That would be a complete redesign of network topology and utility of the network. So your point doesn't seem to hold... I suggest hating Szabo for other reasons, like how he hasn't finished his clay self-replicator machine design.
@_date: 2018-07-14 13:05:08
.. and transcripts for Building on Bitcoin are here: 
@_date: 2015-09-22 22:59:29
Simple answer is that $300 of BTC can be stolen by chargebacks and weird return policies. Mining's the way out of this problem.
@_date: 2015-09-04 23:27:59


False dichotomy. "Majority consensus" is not implemented in the bitcoin source code, but pull requests welcome I guess. Your other option doesn't make sense to me either, since both source code repositories have benevolent leaders. If "an Internet mob" could translate their wishes and desire into directly increasing the utility and value of Bitcoin, then this thing would have spiraled out of control a long time ago. Software doesn't (directly) convert wishes  into results.
@_date: 2018-07-14 14:07:39
Until then, how about this one: 
@_date: 2015-09-17 12:00:50
@_date: 2015-09-08 13:36:59
@_date: 2015-09-20 21:22:32
in particular there's also these:
@_date: 2015-09-08 18:06:09


Heh, I was aiming for humor when I said "Very subtle" but I missed.
@_date: 2015-09-13 15:44:55
more transcripts 
@_date: 2015-09-21 20:42:41


That seems unlikely; they could source far more liquidity just by including a markup in the price.
@_date: 2015-09-09 16:45:26






The explanation I was given was "roundtable discussions will not involve attribution"; perhaps the roundtable results session later. But ask someone else.
@_date: 2015-09-16 19:21:46


I am not sure if that is possible in all large-block scenarios, unless SPV or chain pruning or removing the larger blocks so that the other nodes can catch up..? Especially if any of the blocks (even the small ones) have non-proportional additional verification time.
@_date: 2016-10-09 20:25:30
Have you some transcripts for great win:
Fungibility 
joinmarket 
tumblebit 
mimblewimble 
Onion routing in lightning 
Flare 
Unlinkable outsourced channel monitoring 
lightning stuff 
segwit 
schnorr sigatures 
bip151 peer encryption 
coin selection 
covenants 
security and performance analysis 
collective signing 
fast difficulty adjustment algorithm 
jute and DAG braiding stuff 
client-side validation 
"breaking the chain" session 
day 1 group summaries 
day 2 group summaries 
@_date: 2015-09-12 18:05:58


The workshop organizers would like to not record attribution during those sessions, which video would negatively facilitate.
@_date: 2016-10-27 05:55:34
you were replying to it should be obvious i was referring to luke-jr's bip. the one you were asking for. it's not bip109.
edit: 
@_date: 2016-10-27 19:18:53
@_date: 2016-10-09 19:59:30
collective signing 
fast difficulty adjustment algorithm 
jute and DAG braiding stuff 
client-side validation 
"breaking the chain" session 
@_date: 2016-10-21 14:16:50


it was me


because you had asked:


there is literally a hyperlink to source code in there for your hard-fork. i really don't know how to help you; you are beyond help.
@_date: 2015-09-30 11:41:35
"Ray Kurzweil is a pessimist." - George Church, 
Also, some of you may be interested in  an IRC channel ( on irc.freenode.net) for engineering on projects such as open-source von Neumann probes (astrochickens) and projects such as synthetic biology for terraforming the nearby planets.
@_date: 2015-09-12 11:48:56
I'll be presenting today at  see livestream video on youtube 
@_date: 2016-10-21 01:53:39


you really need to read 
@_date: 2016-10-27 00:57:33
or they could read  (search for "luke-jr" to jump to a relevant section)
@_date: 2016-10-08 14:07:57
@_date: 2016-10-28 14:10:31


There is a timeline here -  - under the heading "Segwit timeline".
@_date: 2016-10-27 18:11:27


Use a merkle tree and only periodically commit the merkle root into the blockchain. So use  ... and aggregate multiple hashes into a single merkle root, then broadcast on a regular schedule all at once with a single bitcoin transaction and single output.
I pointed out the same thing to Jeremy earlier today - 
@_date: 2016-10-28 14:13:29
Here is an overview of recent work on Schnorr signatures and some of the problems that are getting looked at, 
@_date: 2015-11-19 23:36:35


I have never seen that specific question asked to him, so I think you might be wrong, but I'll reply anyway. I have seen people ask him about BIP101, but never about which conditions would be required for him to think BIP101 was a good idea. I would imagine that he would say something about internet backbone tech, like maybe widely deployable easily fabricated fiber optic cabling, kilometer-range infrared optical links with high bandwidth, stuff like that. And also his response would probably include something about either fraud proofs, SNARKs or some other techniques to reduce the validation impact required.
@_date: 2015-09-30 17:45:07
This seems new since we last talked on 2010-12-10, my question is have you talked with the Artlery team yet?
@_date: 2015-09-28 12:42:46


@_date: 2016-10-21 01:33:40
the implementation proposal was delivered a long time ago
@_date: 2016-10-08 10:38:03
Fungibility 
joinmarket 
tumblebit 
mimblewimble 
@_date: 2016-10-27 05:29:59


because everyone is incapable of reading; it's been in public for months and all i see is endless complaining about its nonexistence or something. wtf.
@_date: 2016-10-27 00:11:26
see also 
@_date: 2015-11-08 01:35:12


Eventually there might be someone that tries to use bitcoin, only to find that the software doesn't meet their goals. I think it's reasonable to expect some (confused?) users to be told that bitcoin doesn't really solve their problem. For example, some finance companies are finally learning about postgresql and mysql, which are both projects that bitcoin should never strive to replace.
I suspect that has already happened at least once; many people thought that bitcoin transactions were anonymous, and it's dangerous to tell them they have anonymity because they might be in jurisdictions where lack of anonymity may cause them physical harm to themselves (partly due to unfortunate ways of the world for now...).
As for metrics of success, the "more users = more transactions per second = gigablocks = supernodes = more price = more better" is a surprisingly easy narrative, so any alternative, whether (in)correct, will have to compete with that, at least in the heads of those who are not looking for correctness.....
@_date: 2015-09-21 21:57:09


Yeah exactly, but 21inc could do the same thing without using an ASIC miner. Instead they could take a percentage of the MSRP and buy bitcoin with the USD they earn from their device sales. When the device connects to the internet for the first time, the device could send a bitcoin address to 21inc for the "stream of BTC" to begin. This would obviate the need for a mining ASIC while still providing "initial liquidity" to the device user.
Perhaps the reason to include mining is so that "21inc can issue devices or users a credit line (with perhaps no fees for 21inc, compared to accessing other lines of credit) secured by their ability to charge arbitrary, limited amounts to device electricity bills." But you'd expect them to market this angle more directly...
Also; mining very small amounts of BTC can be useful for setting up Lightning Network payment channels which sometimes require initial liquidity. There are some ways to do this without having some initial UTXOs but nobody has fleshed out those proposals yet, so in the mean time using mined satoshi BTC dust could be an alternative... other than the blockchain bloat it would cause? Doesn't seem particularly compelling to me. Some of the pre-lightning proposals for payment channels involved escrow, so perhaps 21inc will transition to operating as a payment channel escrow service for their devices? Escrow also doesn't seem compelling at first glance.
Chargebacks make it impractical to run send-to-wallet-once-device-is-activated schemes. With chargebacks (or just normal return policies), you would be out of the money since the BTC user could just transfer the money somewhere else and return the machine or wallet to wherever it was purchased. Alternatively, users could eventually reverse engineer the machine and get the initial money setup to happen multiple times, which also loses money. Setting up a bunch of new BTC users is difficult because chargebacks make this basically impossible for everyone involved, which makes the traditional banking system, including credit cards, some forms of bank transfers, and paypal, all unusable for these purposes, which mining solves even for small amounts. Perhaps there's room for a device sold for cash-only that comes with a pre-loaded BTC wallet or uses a one-time-use handout password.
All-in-one bitcoin-ready computer makes sense from the perspective of a developer first getting introduced to bitcoin; no reason to spend 20-30 hours (thousands of dollars of a developer's time) on tracking down good sources of information, or wasting time scanning in the 8th passport to buy BTC on a random site, when he can just pay $400 for everything bitcoin ready to go. For small payments, this "SDK" tells the developer that there's a reasonable plan for onboarding lots of users and bypassing all of the deadly chargeback risk or the chargeback incompatibility chasm that traditional payment systems can't overcome.
dunno, their marketing doesn't really go in any particular direction...
@_date: 2016-10-20 21:34:48
@_date: 2016-10-10 22:59:57
Write very, very well. Be better at communication than Core developers aren't.
@_date: 2015-11-20 15:30:13
I am having trouble understanding you; could you please elaborate on why you have proposed transaction processing capacity is the only relevant comparison ("on par") of bitcoin to CHIPS? Why would the transaction rate determine whether the system's transactions qualify as settlement....? If that is not what you have proposed, then could you clarify your comment?
@_date: 2015-11-24 22:36:37
Some commentary starting near 14:07 - 
@_date: 2015-11-25 14:39:05


Channel closure aggregation could be used here, possibly using multisig techniques. Also, you could use UTXOs in sidechains as a final escape valve, especially if you don't feel like competing with the other transaction fees on the main chain. If you choose to do that, then the other party will simply be done with the channel and wont send back any BTC on the bitcoin side (only sending you BTC on the sidechain), thus effectively closing the channel. So there will always be a way to close the channel.
@_date: 2015-11-19 22:03:09
We can't have talking about proposals, that's absurd... Just kidding. I recently posted re: "What counts as progress?" over here, 
Would it be possible to have progress even if the solution is not the one you personally favor? this is a tough question, even for me.
@_date: 2015-11-19 19:05:38


The scenario that Mike proposed was "Coinbase grows so wildly and the bitcoin network has essentially zero activity". So you are asking me "what if instead of Coinbase it's the miners that grow while the network dies" ? Many people have raised that exact concern about superlarge miners, yeah.
@_date: 2015-11-19 16:26:29
Why are they concerned about "using bitcoin for all their interbank transactions" when bitcoin has never tried to sell itself for that purpose? The Bitcoin architecture is simply unrelated to that (all interbank? all..?).... A good strategy to start with would be to look at the properties of bitcoin and see why it's interesting and what problems bitcoin solves. They have gold and they post gold as collateral, so it's clear that they have problems that bitcoin solves. The growth and development of bitcoin as an asset class and cryptographic system is far more interesting and has far more potential than recovering tiny margins from upgrading old internal back-office ledgers. "Why bitcoin" details can be found here: 
Why are you surprised that Blockstream has a product that has higher transactions/sec than the Bitcoin blockchain? Bitcoin's architecture is clearly not designed to be the fastest transaction processor. You're okay with banks having different goals and requirements when it suits your own purposes, but when Blockstream identifies a problem that Bitcoin doesn't entirely solve, that's not okay? What's bizarre about your objection is that Liquid actually does use BTC in a somewhat secure way, whereas your "all interbank transactions" wouldn't.... (well, they could conceivably be backed by bitcoin bonds or something, but I haven't seen a proposal like that).
@_date: 2015-11-21 22:47:54
Too busy coding, perhaps weren't asked (or weren't paid?) to participate, maybe all the programmers didn't like the colors and said "nah".
@_date: 2015-11-19 21:32:11


That was debunked months ago, there's actually a lot of BIPs and other proposals: 
@_date: 2016-10-15 21:05:08
Initial block validation for a new node can outrun your ability to do validation. You can run beyond that point long before anything like sharding is close to working. Not sure if you missed this point; he didn't explicitly say it.
@_date: 2015-11-23 03:26:53
and 
@_date: 2015-11-08 21:22:33


There are many properties of bitcoin that programmers are still discovering. Some of this is academic research, too. Much of this is new territory.
Some were told that bitcoin transactions were "completely anonymous", and then we learned this wasn't true.
Maybe it's not anybody's fault.
@_date: 2015-09-10 23:22:53


That's not sufficient, because previous blocks also have to be verified. But you may be interested in some of the ideas from this one: 
(I'll be presenting a bunch of alternatives at  on Saturday.)
edit: other thread, 
@_date: 2015-11-08 17:56:42
Nah, even profitable products need to be replaced with products that require less operational overhead. It's easier to maintain just lightning network software, rather than "lightning network software AND this bizarre zeromq fedpeg implementation that keeps breaking".
@_date: 2015-11-07 23:11:39


This sort of strategy can be trivially defeated by setting up the sides as the extremes and the midpoint as the originally unreasonable item. See also zeno's paradox.
@_date: 2015-11-08 17:55:06
I think you're just going to have to live with Blockstream, or any other company, creating alternative payment processing rails that don't share properties with the bitcoin system. Centralized payment processors are way faster, period, that's just how the math works... But it's at the expense of the interesting properties of bitcoin, thus it's not bitcoin. Meanwhile, bitcoin can keep on bitcoining as it does.
@_date: 2015-11-09 16:52:11
I would say the difference here is that PayPal's system has fundamentally different goals, and is far more scalable and efficient in all theoretical and practical formulations. Comparing apples and oranges. Fundamentally different problems cannot always be addressed by the same underlying technology, even if both happen to use data structures or "software" under the hood.
@_date: 2016-10-06 16:24:38
I suspect that many people don't consider their source code to be write-once use-once. New deployments of contracts, even with minor alterations, are likely to happen. However, if it's the case that the folks in Ethereum land don't want Solidity source code to be reusable, then they should probably make that much more explicit and widely known........
@_date: 2015-11-19 19:29:00
I never claimed Coinbase would always be successful in Mike's scenario- perhaps they would fail to get the decentralization really going? Who knows. And perhaps miners too. That's why the rules of the network should be decided by reason, not by miner choice.
@_date: 2015-11-29 05:57:56


I can understand your desire to pander to anti-Blockstream sentiment as a way to signal in-group/out-group preferences, but you making that sort of BS comment hides whether you understand that zero-confirmation transactions are a property of Bitcoin itself (and that thus they are not BS-induced).
The reason why I mention this is because if you don't grasp that's a property of Bitcoin itself, then why are you bothering with spending your time on Bitcoin? At some point you might find that Bitcoin really doesn't do what you thought it did (again, can't tell if you're genuinely unaware that BS didn't cause Bitcoin to have a concept of unreliable zero-confirmation transactions). Imagine that you live in a world where all those pesky Bitcoin developers were right about how things work and why things are necessary; in this world, you would have the same goals and requirements as you do now... I suspect you, in this Totally Hypothetical Scenario, would find that your goals and requirements would be better met by spending your time and efforts on a non-Bitcoin system.
Again, reason why I mention all of this is because unclear from your text, plus there's no reason for Bitcoiners to mislead you about what Bitcoin is or isn't, misleading you (or others) is a good way to generate a huge amount of anger and animosity that I have no interest in cultivating from you or others. Bitcoin don't need that.
Be wary the sunk cost fallacies. Probably I am just reading too much into your BS text; but I can think of no good faith reason to use that.....
Also, child-pays-for-parent is a good idea that should happen. However, zero-confirmation transactions are still insecure regardless of the existence of child-pays-for-parent features.
@_date: 2015-11-20 16:16:56
Yep makes sense. My disagreement with you is the following: I doubt that anticipated demand must be "completely" supported. I suspect that bitcoin can partially support various demands and still be perfectly healthy.
I'll give you a random example. At the moment bitcoin has not satisfied the (enormous) demand for anonymous transactions, and yet bitcoin has continued to work and have value regardless.
I am skeptical that bitcoin should be expected to compete on transactions/sec with systems that don't have the same goals as bitcoin. Why compete for users that have problems that bitcoin doesn't solve ?
Bitcoin solves different, way more important and way more valuable problems. Bitcoin isn't CHIPS, and that's good.
@_date: 2015-11-19 18:03:22


What evidence would be sufficient to refute this belief of yours? Surely there is some sort of evidence that could possibly exist that would change your mind? What would it look like, or what would it have to do?
Maybe there's no downsides to non-fallible ideation, though; someone should try to get Karl Popper on the phone to discuss this amazing development.&lt;/tasteful-humor-element&gt;


"Half" of the lightning network source code seems to be protobufs, which is your ex-Google bread-and-butter, right? I'm teasing. But really, take a look at the source code and see how bitcoin transactions are used (I don't recommend relying on reddit comments to serialize correct implementation details about lightning network; reading source code seems way more efficient use of our time): 


Because bitcoin transactions ? No really, what's the concern here?


You mean instead of spending your time and efforts on bitcoin? That doesn't sound likely from my understanding of your goals, which is why I am asking.
(I lost my original comment and I am sad about this. Totally my fault and user-error.)
@_date: 2015-11-23 20:26:23
You could conceivably operate a sidechain that operates its own form of monetary policy. Sidechain monetary policy can only directly control the production of currency on the sidechain, and not the production of BTC on the main chain.
The benefit to a sidechain asset is that the central bank can elevate its own currency to become a "first-class citizen" and benefit from bitcoin transaction features, such as CLTV and other contracts. This sort of integration would be a very forward-looking step that would allow anyone in the world to write software that can handle that country's fiat money.
The difference is that you cannot do these feats without first using a decentralized scarce asset at the base layer.
@_date: 2015-11-07 10:34:23


Yes, except when you are talking about the security of the network then you have to look at worst-case not average-case or best-case.
@_date: 2015-11-09 20:18:16
some replies to those points are available here: 
@_date: 2015-09-09 12:56:15


yes, also IRC in  on freenode


@_date: 2015-11-09 11:28:44
Hey that's a great site, thank you. Yeah I agree that the developers never claimed anonymous money magic. People just make stuff up.
@_date: 2015-11-19 18:23:30
Rusty isn't the only one working on it. Mystery solved!
@_date: 2016-10-21 15:30:25
search "luke-jr" in the transcript
@_date: 2015-11-19 18:11:47


Yeah I think Rusty got slightly discouraged about onion routing implementation details? Not sure; but also- 
@_date: 2016-10-27 05:28:39


That's a big misunderstanding, then. FWIW code was written anyway, there's a branch floating around.
@_date: 2016-10-13 15:48:19
Whole of the bitcoin industrial ecosystem should be participating in defensive patent licensing and defensive patent pools. Every bitcoin startup should be participating. Eventually, it would be nice to fix the problems inherent to intellectual property law. In the mean time, defensive patent licensing, pledges and pools are the mechanisms we have available. These serve as additions to open-source licensing which are based on copyright law --- the additions are necessary because "patent law" in modern courts is generally more powerful than "copyright law". Even in the presence of an open-source license, software patents can find sneaky ways to interfere with the bitcoin ecosystem's licensing goals. Defensive patenting is so far the best strategy we know to collectively defend against this, other than eventually fixing the broader intellectual property legal landscape.
[EFF on why the patent system is broken]( (or [this one](
[Proposal for the reform of the patent system by reducing patents to a formality](
[Andrew Torrance has written about some studies on effects of patents on innovation](
@_date: 2015-11-09 16:47:32
re: treechunks, have you commented in public about either of these two?
@_date: 2015-11-05 23:04:55


more reasons 
@_date: 2015-11-12 03:06:35


Well, yes, although not for any particular BIP, because there's no particular BIP in existence yet... But yeah I would agree there seems to be rough consensus. I have heard no specific objections to the compact SPV proof approach, other than "well that's nice but where's the implementation" once or twice.
@_date: 2016-10-09 12:17:13
segwit 
schnorr sigatures 
bip151 peer encryption 
coin selection 
covenants 
security and performance analysis 
@_date: 2015-11-19 23:55:12
Oh interesting, he seemed to propose that for bip101 he would be interested in "an informational indicator of miner upgrade that is not a trigger". Thanks for the link.
@_date: 2015-11-07 23:19:51


Centralized schemes can be far faster than decentralized consensus systems like bitcoin. It shouldn't be really surprising that they can operate their product at much higher transaction rates than the bitcoin blockchain. Another example is the lack of mining; the participants on that network are simply uninterested in mining as a form of consensus. I suspect they used bitcoin-style sidechains because of their existing expertise in bitcoin software, and I am sure they don't actually want to become a shared database software company which explains why they chose to continue with bitcoin software for this product. But other than those reasons, a shared database strategy would have worked for the "Liquid" network's requirements. It's not unreasonable and it's not their fault that bitcoin doesn't solve all possible business problems, and it's unreasonable to claim that this is a problem that bitcoin should solve in the first place....
edit: On second thought, I suspect that "Liquid" will eventually be deprecated in favor of the lightning network, and most of this will be transitioned to complex sequences of bitcoin transactions using checksequenceverify and checklocktimeverify opcodes. I strongly doubt that Blockstream has a long-term incentive to maintain "Liquid" even if it's highly profitable; if they plan to run any lightning network nodes, then they will probably just migrate their exchange partners over to lightning stuff instead, since it would simplify their operational requirements.
@_date: 2015-10-29 14:26:02
Voting simulation visualizations and why voting and polls are broken: 
@_date: 2015-11-07 23:28:45


Oh, alright. Cool then.
@_date: 2017-05-14 01:14:35
@_date: 2015-11-26 23:31:33
Actually, there is at least one presentation on that subject (look more closely?).
@_date: 2015-11-19 18:19:43


Yeah if the 1 MB limit is kept, I think that it would make sense for the world to move on from that particular concern. They would realize that dumping a trillion transactions/sec into Bitcoin is infeasible, and this might give them spare cycles to look at the actual benefits of bitcoin.


bitcoin-ruby. So yeah they do work on bitcoin implementation details.


I think that Coinbase would either (1) realize the importance of the p2p network and contribute more towards making the p2p network a maintainable decentralized reality of some kind, or (2) face the consequences of nuking the network and try to transition into a Visa/PayPal operation.
@_date: 2016-10-15 21:27:13
Well, the concern was about growing the blockchain faster than the ability of new nodes to join the network. Even if there is lots of interest from new nodes, they wouldn't be able to join under circumstances where the physical validation work they must do is growing faster than their ability to complete that work. So when picking block sizes, the number has to be significantly low enough to make sure we can all still join the software network.
@_date: 2017-05-05 13:05:45
@_date: 2015-11-12 03:00:59


Yeah "not being able to achieve a direction" is a pretty weird way to phrase "look at all these BIPs and proposals that we've been analyzing, geeze that's, approximately, completely no progress whatsoever; I wonder if we can replace all of this inefficiency with rule by fiat".
From a distance, probably hard to tell what counts as development and progress because to nearly anyone who looks at a programmer, he's just sitting there typing on a keyboard pushing pixels around on a screen. When's the real work going to happen, huh?
This "perceived indirection" is possibly the result of not understanding how open-source software development works, how meritorious solutions are found shortly after proposal to be slightly less than meritorious and then replaced with what people expect to be actually meritorious... Work can be difficult, and that's OK.
I think a more apt question would be, "what to do about undercurrents in bitcoin community of urgency/desperation regarding not having achieved total adoption by yesterday? What to do about (ANGRY) users that get tricked into trying out bitcoin, only to become upset later when they learn that it's not on the same mission as Visa or PayPal?".
I strongly doubt that there are any benefits that could outweigh the drawbacks of a "Bitcoin dictator". Yeah, sure, a dictator can make quick decisions, but unfortunately a dictator can also be compelled (such as by government) to rig the system and inflate everything, even if the system was originally designed with a specific set of verification rules those too can be replaced with alternative rules when said dictator is coerced. Moving away from a meritorious approach is the final mistake, and is where the law (or threat?) of coercion begins to overcome law by reason.
@_date: 2015-11-08 19:27:01


Nah, because they can use "private routing" with lightning networks. Sidechains are more about extensibility than about scale, and lightning is more about scale than extensibility, so it makes sense for them to transition away from "Liquid" in the long run.
@_date: 2016-10-05 22:25:23
If you change the compiler, then you're going to get different compilations. Author is not talking about storing bytecode in a blockchain.
@_date: 2016-10-08 14:06:28
Onion routing in lightning 
Flare 
Unlinkable outsourced channel monitoring 
@_date: 2015-10-16 21:57:07
is there streaming video, or recorded video at all? need link
@_date: 2017-05-03 03:02:54
transcript: 
@_date: 2015-10-24 02:33:03


Open-source works through a few hacks involving copyright licensing.
@_date: 2015-10-28 16:14:59
Yeah, if Sergio wants to re-send that, I think it will get approved. I am not sure why he has a moderator bit at the moment anyway- probably because we forgot to unset that during his last email (or he hasn't sent an email since moderation started).
@_date: 2015-11-24 14:50:46
Here are some extra references:
sharding validation:  and 
proofchains: 
fraud proofs: 
snarks: page 43-48 of 
@_date: 2017-05-13 12:46:14
transcript: 
@_date: 2016-05-02 20:38:59
Yeah I didn't hear the question, it probably happened. Pindar is right in front of me at the moment, I would ask Pindar but he lost his voice earlier today.... Updates to the transcript can be submitted through github, 
@_date: 2015-11-19 19:22:04
poon, aj, tadge, rusty, thunder dude, towns
@_date: 2015-11-05 11:58:58


His argument was a proof-by-counterexample. Gavin's challenge was "here is a claim, can you think of any situation where it is wrong?" and Adam did think of a situation where it was wrong, by using the counterexample method. The counterexample method happened to use a big number, but so what?
@_date: 2015-11-27 18:57:25


So your current belief is that a git merge is related to a "command-and-control" over bitcoin consensus.... how? And how do you know whether you are conflating network consensus with technical consensus, or network consensus forks versus git repository forks?
Would you be doing any damage if you were wrong about Bitcoin having "governance" at the moment?
@_date: 2017-07-24 21:33:12


Start with 
@_date: 2017-07-24 22:08:41


it's real, physical bitcoin. &amp; no margin trading at launch for starters.
@_date: 2016-05-02 20:41:06
Verification is impossible without installing software to the laptop, even if it was recently purchased.
@_date: 2017-07-18 19:45:31
looks fine, got anything older that i can bookmark tho?
@_date: 2015-10-29 20:07:01
try the interactive version instead? 
@_date: 2015-10-14 18:28:29
Aggregated various problems with bitcoin-ng at 
Previous analysis and attacks were discussed here: 
Aggregation also referenced here: 
transcript from scalingbitcoin talk: 
@_date: 2017-07-03 23:08:30
Does this simulate the effect of negative fees re: channel fund imbalance/exhaustion?
@_date: 2017-07-16 02:21:27


We are not forcing anything-- anyone can freely hard-fork whenever they want. But which one gets called bitcoin? 
@_date: 2017-07-17 13:31:01
Has hoaxchain finished raising its seed round yet? I am wondering what terms are you offering to potential investors. Just to clarify, I mean a real seed round, you guys can sell humor better than The Onion.
@_date: 2016-05-13 01:11:56
Your post advocates a:
* ( ) technical ( ) legislative ( ) market-based ( ) vigilante
approach to fighting spam. Your idea will not work. Here is why it won't work. (One or more of the following may apply to your particular idea, and it may have other flaws which used to vary from state to state before a bad federal law was passed.)
* ( ) Spammers can easily use it to harvest email addresses
* ( ) Mailing lists and other legitimate email uses would be affected
* ( ) No one will be able to find the guy or collect the money
* ( ) It is defenseless against brute force attacks
* ( ) It will stop spam for two weeks and then we'll be stuck with it
* ( ) Users of email will not put up with it
* ( ) Microsoft will not put up with it
* ( ) The police will not put up with it
* ( ) Requires too much cooperation from spammers
* ( ) Requires immediate total cooperation from everybody at once
* ( ) Many email users cannot afford to lose business or alienate potential employers
* ( ) Spammers don't care about invalid addresses in their lists
* ( ) Anyone could anonymously destroy anyone else's career or business
Specifically, your plan fails to account for
* ( ) Laws expressly prohibiting it
* ( ) Lack of centrally controlling authority for email
* ( ) Open relays in foreign countries
* ( ) Ease of searching tiny alphanumeric address space of all email addresses
* ( ) Asshats
* ( ) Jurisdictional problems
* ( ) Unpopularity of weird new taxes
* ( ) Public reluctance to accept weird new forms of money
* ( ) Huge existing software investment in SMTP
* ( ) Susceptibility of protocols other than SMTP to attack
* ( ) Willingness of users to install OS patches received by email
* ( ) Armies of worm riddled broadband-connected Windows boxes
* ( ) Eternal arms race involved in all filtering approaches
* ( ) Extreme profitability of spam
* ( ) Joe jobs and/or identity theft
* ( ) Technically illiterate politicians
* ( ) Extreme stupidity on the part of people who do business with spammers
* ( ) Dishonesty on the part of spammers themselves
* ( ) Bandwidth costs that are unaffected by client filtering
* ( ) Outlook
and the following philosophical objections may also apply:
* ( ) Ideas similar to yours are easy to come up with, yet none have ever been shown practical
* ( ) Any scheme based on opt-out is unacceptable
* ( ) SMTP headers should not be the subject of legislation
* ( ) Blacklists suck
* ( ) Whitelists suck
* ( ) We should be able to talk about Viagra without being censored
* ( ) Countermeasures should not involve wire fraud or credit card fraud
* ( ) Countermeasures should not involve sabotage of public networks
* ( ) Countermeasures must work if phased in gradually
* ( ) Sending email should be free
* ( ) Why should we have to trust you and your servers?
* ( ) Incompatiblity with open source or open source licenses
* ( ) Feel-good measures do nothing to solve the problem
* ( ) Temporary/one-time email addresses are cumbersome
* ( ) I don't want the government reading my email
* ( ) Killing them that way is not slow and painful enough
Furthermore, this is what I think about you:
* ( ) Sorry dude, but I don't think it would work.
* ( ) This is a stupid idea, and you're a stupid person for suggesting it.
* ( ) Nice try, assh0le! I'm going to find out where you live and burn your house down!
@_date: 2017-07-24 00:57:39
also: 
@_date: 2017-07-16 02:13:28


A hard-fork splits the network(well, chain) regardless of whether core developers recommend/speak against it.
@_date: 2017-07-12 16:56:07
i don't think it's fair to map politics to bitcoin, especially such a reductive summary of the situation.
@_date: 2017-07-17 00:13:28
@_date: 2017-07-16 02:17:38


Sticking to core principles isn't going to burn down the system. At most this drama can somewhat delay the activation of segwit. But long-term, things are OK even without segwit for another year. Is that really what burning looks like?
@_date: 2017-07-19 13:35:06
@_date: 2017-07-24 20:27:37
Moon? A bunch of us at LedgerX are actually really big fans of SpaceX so we've had our eyes set on Mars for quite a while.
@_date: 2016-05-26 20:14:09
Also, a transcript from that meeting --  ( unformatted-  )
@_date: 2015-11-14 04:14:25
Older node implementations consider CLTV transactions to be non-standard, so those older nodes will not relay or mine CLTV transactions at all. Blocks mined by miners with CLTV transactions will be blocks that are compatible with older software not implementing CLTV rules, because this is a soft-fork and various forms of planning were involved for this.


@_date: 2015-11-24 19:46:17


Those concepts aren't as different as you might think. A decentralized P2P cash system is always going to tend to look less like highly-scalable centralized transaction processors, and always going to tend to look more like a settlement system. I suspect that if you looked at RTGS target2 under the hood, you would find that target2 is more like a payment system than a settlement system.
The lightning network proposal says it uses actual bitcoin transactions:  and  (The summary is slightly misleading; transactions aren't "conducted off blockchain" any more than regular bitcoin transactions are... This is confusing because "off blockchain" usually means "not using bitcoin transactions", which isn't true here.)
@_date: 2017-07-16 02:16:06


PoW change is only necessary in a few outcomes here, none of which seem likely. "Support" is one thing (like bumper stickers and block signaling)-- but if miners follow-through on their threats of empty block DoS attacks, that's when the PoW change proposals start to pick up lots of support.
@_date: 2017-07-16 23:22:39


perhaps you mean lightning labs (the inventors of lightning, although not payment channels)   ... Your "simplest explanation" isn't so simple when you consider all of the counter evidence against your "simple" explanation-- such as when Blockstream, an entirely different company by the way, says that they "have no plans to monetize blockstream lightning implementation".
ALSO: lightning network doesn't require segwit, 


and would you say the same thing about chaincode, MIT, etc., for hiring and paying bitcoin developers to work on bitcoin?


the bitcoin developers have proposed segwit and have other ideas in mind for how to increase overall capacity. your "ransom" looks an awful lot like "slow and steady progress".
@_date: 2017-07-19 14:36:44
here are some links to prior discussions about BU problems, from before that paper was published:
@_date: 2016-05-02 20:37:38
I typed the transcript. Someone made an error somewhere, and it wasn't me. Software had to be put on the computer to do the verification--- computers don't come unboxed with Craig's fake signature data, right? So somehow the data was put on there, and the other software was put on there too.
@_date: 2017-07-17 14:46:11
How do I know you have the real CSW working for you? Could you [sign a message]( by any chance?
@_date: 2017-07-11 02:11:08
currently links to 
@_date: 2017-07-18 12:32:10
previously the same reasoning was given, it seems like it's far past time for that piece of rbtc fud to die, github even fixed the bug too: 
@_date: 2017-07-12 17:46:29
That hasn't been my experience.
Who has burden of proof when one accuses the other of politics?
If you believe you are narrative building, then perhaps that's one way to answer it.
@_date: 2017-07-17 01:12:32


Well, within that particular scenario, I think multiple (non-public planned) PoW changes would solve that particular problem eventually. This is of course entirely separate from the question of whether it's feasible to actually go ahead and do multiple PoW changes. At some point no matter how well capitalized they are, they will not be able to afford to keep making new asics if they can never recover their investment costs.
@_date: 2017-07-16 22:28:04


segwit is not indecision


my node seems to be working fine, could you post the core dump if you're really getting a crash? thanks, it's important.
@_date: 2017-07-24 21:31:45
@_date: 2015-10-02 20:21:30


Miners don't have to lose out on lightning network fees, they can collect fees by running a lightning network node themselves. But fees aren't profits, and miner profitability is not yet greatly influenced by transaction fees. Also, because of the low security of hot wallets, not everyone is going to want to store BTC/UTXOs in lightning payment channels.
@_date: 2017-07-10 17:46:59


That's... not how it works.
@_date: 2017-07-16 23:08:11
number of transactions doesn't correspond to number of users
demo (infinite loop):
    while true; do createtx; done
@_date: 2016-07-24 04:12:12


Fits trivially. Capacity increases can be delivered using soft-forks. See  etc.
@_date: 2017-07-14 18:40:06
Unfortunately that has the same problem, the IRC server is a central target, easy to implement filtering and other interference. Also it was sort of rude (although entirely understandable) to do initial bootstrapping on Freenode-- it's not like Freenode wants botnets using their service after all :).
@_date: 2019-05-22 19:25:56
@_date: 2016-07-24 04:33:43


Great sounds like you've moved on (from wondering about how to increase capacity without a hard-fork) to wondering about parameters for a soft-fork capacity increase.
Theoretically, I think there's an upper limit where the number of transactions per person should probably not be above a certain number, like a trillion, because if it takes more than a trillion transactions per person to sort things out, then you have some rather severe financial problems for your civilization of commerce. So we know we need at most a trillion per person... It's a good start. (Actually I think it's probably less than a trillion per person. It's probably log of the population count or something...)
More realistically, we should base it on the data and testing submitted to the mailing list, academic conferences, IRC, and Scaling Bitcoin workshops. Everyone should be responsible for performing their own analysis of the system, running tests and performing calculations that attempt to reproduce the results or outcomes found by others, such as the initial block sync time problems.
@_date: 2017-06-18 19:33:28


Satoshi also mentioned in an email that nodes by default were not mining, you had to go enable the option:


@_date: 2017-06-17 17:33:17


Some comments along those lines: 
@_date: 2016-07-19 16:51:56
A small detail about patent law that readers might be unfamiliar with is that "patent law" unfortunately has the tendency to trump "copyright law" in courts. A patent is a much more powerful legal tool than copyright ownership. Open-source software licensing is itself somewhat of a hack on top of copyright law. Hardware is even more tricky, especially since you are not automatically granted "patent rights" whenever you make up some hardware in the same way that authors are granted immediate copyright by law upon creation of their authored works.
On a related note, here is an old proposal of mine for reforming the patent system: 
@_date: 2017-06-17 17:28:52


Full nodes validating all the transactions and running all the rules has been constantly suggested, supported and implemented by the technical community. In fact, some people are even sick of hearing as much.