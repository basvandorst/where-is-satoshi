@_author: bitcoincashthrowx2
@_date: 2018-01-15 21:57:00
I've never seen it being used in that context, IIRC. Can you point to an example?
ZKP are used to hide amounts in some cryptographic currencies, and will be used for Liquid (a blockstream product for exchanges I don't know much about) in a Bitcoin side chain.
@_date: 2018-01-13 11:58:24
I'll unravel it for you. These are not automatically my opinions, by the way. They might be, though.


Blockchains with PoW (Bitcoin) solves the Byzantine General's Problem. How it works forces future generations to store the whole blockchain.


Some humans know enough math to believe that growing at logarithmic rate (or beyond) will make it impossible to store the blockchain in the future.


If you believe we have logarithmic or faster growth for storage until Bitcoin becomes irrelevant, you can grow the blockchain like that, negating what he said above.


Bitcoin Core devs think about their design choices, and not just the code they are/would be commiting right now because of it. (This is a bit of an interpretation. I'd say they do care about Big O notation, but they include their design choices (such as the problem of probably having to increase the blocksize again in the future, even if it's not written in code). It might also mean that they care about the factor of their real world implementation before the Big O, something scientists often seem to ignore when designing algorithms.
I also think you could have reacted a bit nicer. This took probably way over one hour to write down for the OP, and he's genuinely trying to help this sub and Bitcoin in general by spreading his high level view of the choices Bitcoin made. That's just my opinion, though. A very hostile environment might create spicier replies ;)
@_date: 2018-01-11 15:32:00
You seem honest, so even if it sounds a bit weird, I invite you to read the (few) comments I wrote in the past weeks where I try to explain why bigger blocks centralize the system. I only write about this stuff with this throwaway account, so it's all on topic I hope.
To make it short: It's not really HDD costs, but block propagation issues and the time it takes a current CPU to verify a block (You know about empty blocks, so that should give you a good estimate how long it takes to verify transactions in a block not found by yourself. Miners lose out on many $$$ just because they couldn't verify faster, enabling them to add new tx to their own block they mine). 
HDD costs might still matter if we want this currency to be available to 3rd world countries. A small block size increase ever few years would allow everybody to do their own verification (no trust) on their smartphone (SPV always has the problem of the server being able to lie to you ("No, that transaction wasn't done")).
Something I haven't touched upon yet in my comments is the problem of getting real consensus (not just majority) for just ONE hard fork. Some might want 4MB, some 8MB, some 32MB, or even a steady increase based on usage. If just two of these ideas gather enough supporters, it'd split the network over just this one minor difference (instead of actual technical arguments). And to be honest, I might even be on the 'keep 1MB + SegWit' side if that 'war' broke out right now, even though fees are ridiculously high and damaging the reputation of Bitcoin right now. I want tests and hard evidence that the problems concerncing centralization with higher block sizes have been solved or don't matter because the software (compact blocks) and networks have become better in the past 2 years (since that one paper was done). Then, and if we don't split the network, I'm all for increasing block size as much as sensibly possible.
@_date: 2018-01-16 03:02:01
The actual question I was answering to was by Bjartleif, not you. Did you forget to switch accounts?
The following is what you wrote. Where is the question you are talking about? Am I missing something? I'm confused.


@_date: 2018-01-12 21:39:46
I explained in my post why they can even increase their satoshi / byte fee above what they originally paid for unbatched transactions. Higher fees make block inclusion much more likely. I'm sorry, but please read what I wrote. I even agreed to


My argument still stands even if that is true.
@_date: 2018-01-12 21:25:30
I think the main reason why they didn't implement a hard forking 4-8MB increase was missing consensus. Even something like 80% support isn't enough to safely roll out such an update. That's just a guess, though, and not a real technical argument.
We have a bit more than one megabyte sized blocks right now, and receiving a block + verification of it seems to take longer than 37 seconds if we look at real world blocks being found: 
 
 (A full 37 seconds between both blocks being found, but there's still no transactions in the second block because you can only add those after verifying the new block completely (or at least ruling out double spending for the transactions you want to add))
Let's assume verification takes 30 seconds. If we increase to 8MB, verification will take roughly 8 times as long (at least for that pool), so that's 4 minutes of not being able to add transactions. If we go to 16MB, that pool wouldn't even be able to verify blocks faster than they arrive.
If someone sees an error in that reasoning, please reply. I'll still answer your other questions, btw.
@_date: 2018-01-12 21:33:16
No. It does not negate the rest. Please read on from "Now to the real reason". Coinbase can speed up transactions for their customers through batching, even if somebody else fills up the blocks entirely, paying the same fee as Coinbase did originally.
@_date: 2018-01-15 21:57:52
I've never seen it being used in that context, IIRC. Can you point to an example?
ZKP are used to hide amounts in some cryptographic currencies, and will be used for Liquid (a blockstream product for exchanges I don't know much about) in a Bitcoin side chain.
@_date: 2018-01-11 15:51:47
I think so, yes. 
Skip this if you already know this: Currently, there's this fixed limit of 1.000.000 bytes for the block. SegWit uses a trick to allow for up to 3.000.000 additional bytes, but some part of transactions cannot use the trick, so the actual limit is somewhere around 2 megabytes with a non-artificially created block. Even if SegWit allowed for 10.000.000, actual blocks would not be larger than 2 megabytes.
The trick means that miners who don't know SegWit will only see the first 1.000.000 bytes, and all transactions will appear valid. This is why it is a soft fork. If we change the 1.000.000 bytes to something else, or introduce a rule that allows for even more variation, miners without a software update will not see the block as valid anymore, and reject it. 
So regardless of how much we want to increase it in the future, or by which rules, we actually have to release an update to all software validating blocks (all different open source bitcoin implementations, miners running their own code only they know, etc). But this introduces the problem that someone might also release an update, under a different name, increasing to a different size / with a different rule set, and people might like that one better. Software A with the new rules and Software B with the other new rules wouldn't be compatible, however, so essentially you'd have two blockchains who don't care about each other (like with BTC and BCH, because BCH changed the rules (hard fork), while BTC changed them in a way that's not noticeable/that doesn't cause validation to fail with the old software)
Hope that helped.
@_date: 2018-01-15 19:26:48


If we grow -block size- logarithmically, the total blockchain grows faster than linearly. We only have linear growth if the block size does not change at all. If there's an implicit block size increase whenever X happens, the block chain grows faster than linearly. 
Is it clear now, or am I still confusing?


Logarithmic growth = current block size + some logarithmic growth on top, no? Maybe I messed up trying to be clear and concise :/
Storage can't grow exponentially forever and there are hard limits (physics) to how large it can grow. But I agree that we've seen some good growth in that sector until now. 
The argument the OP was trying to make was that if you believe we will have enough growth, then his argument can be ignored.
@_date: 2018-01-15 19:17:43
The term "trustless" is used to express something very specific in Bitcoin and LN.
Here, you are using it to refer to the trust you have in the software or the security of your computer. Computers can always be hacked, so you always have to trust in the security of your devices when using them to store Bitcoin private keys.
What the term is meant to mean is that you do not have to trust the people you interact with via Bitcoin or Lightning Networks. If you send someone money, they can't 'steal' the rest or do other weird things (like lock up your mutual funds indefinitely). With Lightning, it also means that you do not have to trust the hops on the network to be honest participants. Even if they try to scam you, they can't. The system makes sure they only get paid fees if the money arrives at the other end, and they can't steal any money that moves through them.
How it does that is complicated. In real life, if you give someone money to give it to someone else, they can easily steal it. With Lightning and HTLCs, they never really get the money, but they get funds encumbered by a smart contract that only pays them in case they delivered the money. That's how it is trust less. 
If we are only talking about a single channel, trustless means that the other party can't cause you to lose the Bitcoin in your channel through non-cooperation. Before funding the channel, you create a transaction that returns your Bitcoin to you, so you can always get your Bitcoin back. Later on, that transaction becomes practically unspendable through another smart contract that makes your own Bitcoin spendable by the other party if you already agreed on a new transaction, because that involves you giving up a secret that makes the other party capable of stealing your Bitcoin in the channel should you release the old transaction.
@_date: 2018-01-11 17:39:43




That was not the problem I was trying to explain. Let's assume all miners have always been around, and they had enough time to verify the blockchain up until the newest block. Now a new block is created, and everybody who didn't find that block has to verify it. Verification of the block header is very quick: Is the hash correct? Yes. Was it difficult enough to find? Yes.
Now, miners create a new block building upon that recently found one. There is one problem, however: They also need to check all transactions for validity: Were their inputs used before? Are the signatures and public keys valid, i.e. were they sent by the true owner? Does something weird happen that's no allowed (like the miner paying itself 12.5 bitcoin + 10 bitcoin fees despite there only being 9 bitcoin fees in the transactions).
AFTER this (or a certain part of this) has happened, the miners who got the new block can start adding new transactions to their own unsolved block. Obviously it will change, but that doesn't matter, it's not like they lose anything. Finding a new block is just chance and chance increases when you have more hash power, not by having tried more often in the past.
The miner who originally found the new block, however, doesn't need to check the validity of his own block. He knows it is valid, he made it. So he can add transactions (and their fee) right away, and start looking for a valid block hash sooner than other people.
Now imagine if that transaction check only the other people have to do takes 10 minutes to do. Or 20. It's "only" about 20-40 seconds right now. At least you can guess so from looking at empty blocks on the blockchain, and the time they were found). You could only mine empty blocks as a miner then, as you'd mine an invalid block if you accidentally added an already used output again). Empty blocks means 0 fee reward.
Maybe (I'm not 100% on this) someone with a lot of hashing power could even abuse the inability of the rest of the network to check all transactions in time to cause them to mine on top of a block with an invalid transactions, causing loss of mining reward for them on top of loss of transaction fee reward. It would cost the attacker some money and wouldn't be a sure thing, though.
To sum it all up: This centralizes the system. The people with a lot of hashing power get an additional, meaningful edge, and thus more money for the same amount of work per hash. This advantage has always been present in the system, but by making blocks bigger, it becomes more pronounced, at least until latency and bandwidth and CPU speed increase similarly. Ideally, we'd like block propagation and verification to only take a few (milli)seconds. If most blocks are found around 10 minutes, the advantage of a big miner isn't too damaging to the fairness of the system, then.
I'll answer your other questions at a later time.
@_date: 2018-01-12 21:09:55
Batching might mean you won't get your transaction into the next block because you are waiting for additional people wanting to send their funds elsewhere, but nothing can guarantee that, anyway. On the other hand, batching actually allows Coinbase to speed up transactions in the following way:
First the obvious: If there's more space left in the block because of batching, more people can be paid in a single block. Let's assume this isn't the case because all space is used up by other transactions, still.
Now to the real reason: If you send out a normal transaction with one receiving and one change address, that's about 250 bytes in the 1.000.000 part of the block without SegWit. If they pay 1000 satoshi per byte, that means you will pay 250,000 satoshi total.
Let's assume we only batch two of those transactions. The input size remains the same (if they are smart about consolidation), only the output gets an additional one, which is &lt;40 Bytes (I'm too lazy to look it up. 20 bytes for the hash + a few more single byte opcodes should be less than 40 Bytes)
They paid 500,000 satoshi for the original two transactions (2 times 250 times 1000 = 500,000).
If they pay the same amount for the now batched, but single 290 Byte transaction, that transaction suddenly pays 1724 satoshi/byte instead of just 1000 satoshi per byte. Pretty big increase in certainty that it'll make it into the next block, especially if you don't want to overpay too much. 
You could even do CPFP much more easily and cheaper in case it wasn't enough (after 3 blocks or so), which is too expensive for single transactions. Just spend the change address with a really high fee. This is economically viable if you batch more than 2 transactions and try to stay close to a reasonable satoshi/byte ratio, leaving you with enough satoshi to pay for the Child-Pays-For-Partent-TX in case it didn't get through in the first few blocks.