@_author: lightsword
@_date: 2016-08-30 21:42:50
You can't mine bitcoin without a [bitcoin miner]( anymore.
@_date: 2016-08-30 22:17:35
What model of miner? You'll probably need to use [cgminer]( which supports most miners, it works fine on a mac.
@_date: 2016-04-10 18:20:46
2MB itself is likely fine, and SegWit is nearly 2MB, the issue with proposals like Classic is that many other aspects of them are dangerous such as activation parameters.
@_date: 2016-04-09 20:46:22


This is a naive assumption that turns out to be false in light of deployment complexity and attack vectors that are opened up by increased block size limits. The hard fork nature alone significantly complicates a safe deployment vs a soft fork like SegWit.
@_date: 2016-04-12 20:25:20


I find it ironic that you are accusing core of adding technical debt when you did exactly that with Classic's [sigop/sighash accounting]( You even made a [post]( arguing against using that very code before you found out that f2pool was mining blocks larger than 100k and decided to do it anyways to try and win their support.
Your own argument against the tech debt you decided to merge into Classic:


You argue that SegWit will fix the problem but decided to go ahead with your sigop/sighash accounting in Classic anyways.
@_date: 2016-04-12 18:32:59


Hashpower can not in any way force a hard fork as everyone has to opt-in, hashpower can generally force a soft fork(although economic power can choose a different PoW if miners were to do a soft fork they disagree with). Miners are only one segment of the bitcoin industry and they do not have the power to force a hard fork on users who do not want it.


Have any data on that, I don't think that's actually true and I would be interested to see exactly how you are measuring that, you can't just measure that by number of reddit posts? Regardless, majority is in no way consensus.


Most developers and miners disagree it would seem.


I think most people think it can scale, it's just a disagreement on how it can scale, I don't think exponential on-chain scaling is possible without undermining decentralization.
@_date: 2016-08-18 00:17:41


This IMO would be the biggest worry since some nation states likely have some level of control over the CA's. This may be hard to detect if it is done in a highly targeted way(where they only MITM a few high value targets).
@_date: 2016-04-10 02:17:18


You would think that is the case at first glance but it turns out that it's really not that simple at all, there are a lot of issues that have to be mitigated such as sigop/sighash scaling, as it turns out SegWit doesn't have those same issues.


There were a lot of problems with that code, many users and most core developers considered it extremely dangerous to the network by leaving many users vulnerable to attacks.
@_date: 2016-04-19 04:57:09


That's funny, I don't see an increased amount of traffic. 
@_date: 2018-01-04 11:40:18
Using a [heartbleed]( class of vulnerability along with a compromised payment provider the private keys could be leaked from the wallet process's memory. If BIP70 is not used then it would be more difficult to fully compromise the wallet keys since the wallet would not be communicating with the payment provider directly over a protocol with a large attack surface.
@_date: 2018-01-07 23:04:27
Sure, it's not a Bitpay only feature, I think the author put "Bitpay's" because they are the only major merchant to exclusively support BIP-70.
@_date: 2018-01-03 03:16:40


But this really should not be within the wallet itself, PKI and https has expensive maintenance costs and adds significant attack surface to the wallet.
@_date: 2018-01-03 03:20:19


The problem is that PKI/HTTPS dependencies introduce attack surface that puts all the funds in the wallet at risk, if there is a HTTPS vulnerability in a browser in many cases it will not affect the wallet directly(especially if used with an offline signing scheme) so only the funds being used for the payment are put at risk in that case.
@_date: 2018-01-03 03:14:33


This is dependent on how they are designed, in many cases this increases risk of funds losses.


My mailing list post advocates moving all the PKI/TLS parts into the browser itself which already has to have this infrastructure.


The user already has a browser to open the webpage so they should just be able to use that to get payment destination from the site ideally.


It's simply not feasible to support BIP70 directly for many signing schemes(such as offline signing or joinmarket). Hence my recommendation to have the browser extension translate BIP70 into BIP21 URI's/normal addresses. It should not be the responsibility for the wallet to handle a complex standard such as https, we already have browsers for that. Having the wallet also handle https introduces another point of failure.
@_date: 2018-01-07 22:50:50
BIP-70 is not consensus critical, it's just an optional way of handling invoices. BIP-21 is the current defacto way for paying merchant transactions, BIP-70 has compatibility issues with a lot wallets and [other problems](
@_date: 2016-04-04 06:02:20
This could be a scam and even if it's not you would be sending bitcoin through a wallet which you don't control the keys for which is a bad idea especially when using a random site whos owners aren't publicly known. The blockchain.info v1 method should not be used anyways, at least with [their v2 method]( you control the private keys since it uses BIP32.
@_date: 2018-01-03 14:00:35
I have't looked into Samourai in detail but wallets should not actually need to implement TLS at all since they can use the P2P network directly. Bitcoin P2P protocol is much simpler and easier to harden than TLS.
@_date: 2018-01-03 13:56:47
That's not the main issue here. The main issue is the attack surface introduced by the PKI/HTTPS dependencies.
@_date: 2018-01-03 03:22:46


The alternative is to remove HTTPS support from the wallet entirely, the wallet should simply not be responsible for handling HTTPS, that should be isolated to the browser.
@_date: 2015-12-01 00:40:40
There is also some more issues in cases where pools transmit blocks with unseen transactions(f2pool and 21 Inc appear to do this)
@_date: 2015-12-01 19:58:56


The solution is to first fix the problems around block propagation. The reason the miners aren't jumping on BIP101 is that they deal with propagation issues on a daily basis and know that the current situation is far from what it should be even at 1MB. Don't expect the miners to take you seriously when you have willfully ignored them.
@_date: 2015-12-01 06:10:47
Completely unrelated.
@_date: 2015-12-01 00:45:32


Hard to say IMO, in regards to mining 95% consensus has happened multiple times for things like BIP66 and BIP65 and there is no indication it can't happen again for a block size increase.
@_date: 2015-12-01 08:30:49


They are forced to download blocks however from everyone.


I don't think it is hyperbole, IMO it could completely destroy decentralization.
@_date: 2015-12-03 07:54:42
Difference is miners and core aren't the ones being willfully ignorant to block propagation issues. Miners and the Core devs are paying attention to each other and BIP101 while on the other hand Gavin/Mike have ignored the miners completely and aren't taking the security concerns from the Core developers seriously. Gavin/Hearn decided not to pay attention then were surprised when everyone else didn't blindly follow them.
@_date: 2015-12-01 01:38:36
Antpool triggered the fork not by actually mining the block but by sending out templates from a block someone else mined(which f2pool built off of since they didn't validate).
@_date: 2015-12-01 00:10:00


This implies that the BIP101 chain would be slower and have less hashing power than the 1MB chain.
@_date: 2015-12-01 02:01:54
BTCNugget mined the block that triggered it, Antpool had an unupgraded node that picked up that block which caused Antpool to send out templates for that block, f2pool then picked up those templates from Antpool. F2pool was then the first to mine a block on top of the BTCNugget block.
@_date: 2015-12-23 19:05:53
PSA this could be a scam,  looks really sketchy, there are even some https issues on it.
@_date: 2015-12-01 07:13:30
@_date: 2015-12-08 09:40:48
bitcoin-cli getblockchaininfo
@_date: 2015-12-01 01:29:11


That's a little different since it would be a soft-fork not a hard-fork.


This is really only true in regards to soft-forks.
@_date: 2015-12-11 04:43:48
The other subreddits have a far worse signal to noise ratio at this point than The fact of the matter is there are lots of sockpuppet accounts that are gaming the voting system so some moderation is necessary to keep the trolls from causing too much disruption.
@_date: 2015-12-08 08:46:43
v4 flags support for BIP65
@_date: 2015-12-01 00:33:04
For a pool that I've benchmarked as one of the slower pools in regards to sending out updated templates to miners on block changes I'm surprised you would be ok with BIP101 before fixing those issues.
@_date: 2015-12-30 01:32:56


This isn't really a long term solution, it carries risk of the block being invalid, in addition when fees become a significant percentage of the reward it won't be effective since miners can only use that technique for the block reward itself. It is also a one-direction optimization, meaning pools only pick up the block headers from pools they directly connect to, you can't push block headers to pools without them allowing it.
@_date: 2015-12-18 00:47:36


The miners are currently more or less fine with the direction development is going in Core, BIP100 was the miners answer to BIP101, it was their way of saying we are ok with raising the block size but not ok with BIP101, they have said it was a preference vote but they won't force a hard-fork without consensus. The miners would prefer to have a proposal that everyone can agree with, they don't want to be the ones leading a contentious hard-fork.
@_date: 2015-12-01 00:26:40
In regards to BIP101 we have "general agreement" that it is a bad idea then among experts.
@_date: 2015-12-01 08:04:19


Something that probably isn't clear is that we currently don't have reasonable block propagation speeds, so maybe a better question is how we are going to make those speeds acceptable and scale them up to larger blocks.


Accurately predicting the future is usually based off of past knowledge. We know that things like Moore's law are very limited in scope when it comes to the various bottlenecks we are dealing with in regards to block propagation and scaling so we can't assume we can't rely on that to scale. A lot of the recent propagation improvements we are seeing are well known low hanging fruit types of improvements that have been known about for a long time, we are running out of these. I don't think it is wise to risk Bitcoin's future on guesses about what will happen down the road.
@_date: 2015-12-07 23:50:58
For miners though they need to upgrade otherwise their blocks will get rejected at the 95% threshold.
@_date: 2015-12-02 20:09:19


Exchanges generally don't care about block propagation speeds so miners should not blindly follow them. Miners need to make their decisions based on a proper technical evaluation of the issues at hand. Exchanges have a conflict of interest since they want lower transactions fees.
@_date: 2015-12-01 07:41:54
Lets do some math here, say there are two regions, China and non-China separated by the GFW, for the sake of arguments lets say it takes blocks 20 seconds to cross the GFW while at the same time propagating internally within their region in 1 second. Now say there is 60PH of miners in China and 40PH outside of China. 
Now when the block is found outside of China 40% of the hashing power would be mining on top of it within 1 second. Now lets say 5 seconds late a pool in China finds a block, within 1 second 60% of the hashing power is mining on top of that block. This means that even though the non-China block was found first they have less miners mining on top of it and thus the Chinese block has a significantly higher chance of confirmation.
It your relative bandwidth to other miners that counts not your max bandwidth locally.
@_date: 2015-12-07 21:59:31
I think it will only hit enforcement within 24h, I think that site has activation and enforcement reversed.
@_date: 2015-12-01 05:54:39
Late I heard from f2pool is this. Antpool at the time was only connecting to f2pool. Not sure about BTCC


@_date: 2015-12-01 01:14:48


If BIP101 is a minority fork it takes far less than the majority of miners to attack it.
@_date: 2015-12-31 16:07:52
[This]( paper explains why ASIC resistance is bad for decentralization. Also CPU mining would allow botnets or supercomputers(such as the type government agency's like the NSA have) to mine bitcoin.
@_date: 2015-12-01 00:24:23


This is where there is an important distinction between a hard-fork and a soft-fork/policy change.
@_date: 2015-12-01 01:13:09
Problem is it starts going up significantly before then.
@_date: 2015-12-01 00:46:51


There however would still be a fork without that increase.
@_date: 2015-12-01 00:10:58
I didn't say everything they do is a good thing only that they certainly seem able to adapt.
@_date: 2015-12-01 05:23:19
AFAIK they don't mine on p2p headers as that is riskier, anyone can send an invalid block over the network and they would pick it up, at least by establishing stratum connections and only using those as the SPV header source it makes it so that only a pool they are directly connected to can feed them a bad block header.
@_date: 2015-12-02 06:40:53
I've found OpenVPN going through obfsproxy can also work.
@_date: 2015-12-02 18:08:16
Yeah, it's online but the GFW is still causing huge delays.
@_date: 2015-12-13 05:35:26
Yep, that's too low, probably off by a factor of 10.
@_date: 2015-12-01 01:32:57


Currently I don't think we are at the point where it would be safe to mine on alternate full node implementations(AFAIK all miners use core or patched versions of core), this may change once libbitcoinconsensus is usable in other implementations.
@_date: 2015-12-02 23:44:36


It's certainly not an easy problem to fix, IMO everyone needs to be less tied to a specific proposal like BIP101 and look for a compromise that there can be rough consensus on. I think BIP101/XT hopefully taught people that they can't just ignore a whole segment of the bitcoin industry like Gavin and Hearn did with the mining industry.
@_date: 2015-12-02 05:38:02
Enough miners have made very strong statements saying they will not adopt BIP101, I don't think this is likely. Without hashing power the BIP101 chain would be highly vulnerable to 51% attack. Hard forking without the miners is not a realistic option.
@_date: 2015-12-01 07:43:58


While maintaining reasonable block propagation speeds? I don't think so. We have enough problems with 1MB blocks


So you can predict the future?
@_date: 2015-12-01 00:43:42


The miners aren't some group isolated from the rest of the Bitcoin economy, some like BTCC are also an exchange.


Most don't think BIP101 is good for the price of the coin.


A fork without hashing power can be 51% attacked very easily. Forking without the miners isn't really practical IMO.
@_date: 2015-12-02 05:28:43


That does in no way make it better, in one sense that is actually worse since the increase happens faster.


Yes, there are many things that affect block propagation that have to be dealt with and are being dealt with, primarily by the core devs and miners(gavin/hearn have completely ignored the miners in this regard). Yes, we actually aren't just sitting on our feet as they would have you believe. 0.12 will include a large number of propagation related improvements and other mining related optimizations. It looks like we may get most of the low hanging fruit type of improvements in 0.12(improvements that have been known about for years), the problem is we are going to be running out of things that provide massive improvements in all likelihood fairly soon. The problem is we will likely not be able to get enough improvements to scale at the rate BIP101 increases unless some new sort of optimization method is discovered, I don't think we should be risking Bitcoin's future decentralization on something that doesn't yet exist.
@_date: 2015-12-14 08:41:00
There isn't one mempool or anything like that, there are nodes with many different mempool policies, so that doesn't sound possible.
@_date: 2015-12-01 00:12:12
Implementation is not really the hard part when it comes to raising the block size, the hard part is testing and gaining consensus.
@_date: 2015-12-14 15:21:34
Would potentially be tricky to get anything accurate on the lower fee end when those transactions generally fall off of nodes after a while. Maybe just show only what's over the 0.11.2 default min relay tx fee(granted a lot of pools raise this).
@_date: 2015-12-01 04:29:12


F2pool picked up the block from Antpool not the other way around.


F2pool says they got the bad block from Antpool and Antpool says they only source from f2pool this means the bad block was picked up by Antpool on the p2p network due to one of their nodes not enforcing BIP66.


Sequence of blocks being found doesn't matter, sequence of stratum job's is what does, Antpool just wasn't as lucky so f2pool found the blocks first.
@_date: 2015-12-01 03:14:25
Yes obviously BTCNugget failed to upgrade their software but f2pool wasn't using them as a SPV block source directly(their version of SPV mining uses stratum not the p2p network). F2pool was however using Antpool as a block source, since Antpool had not upgraded one of their nodes f2pool picked up that invalid block from Antpool and started mining on top of it, this continued for a few blocks since f2pool Antpool and BTCC all use each other as SPV block sources without full validation.
Here's the timeline:
BTCNugget Mines an invalid v2 block
The block is picked up by an unupgraded node on Antpool
Antpool starts building off of the v2 block from their unupgraded node
F2pool and BTCC using Antpool as an unvalidated block source start building off of the v2 block
F2pool finds a block built off of the invalid v2 block
More blocks are found by the Chinese pools that continue to build off of each others invalid blocks since none of the stratum servers are fully validating.
Eventually the Chinese pool admins shut down their SPV mining links temporarily and begin building on fully validated blocks only.
@_date: 2015-12-01 00:04:02


Here's how you should look at it:
larger blocks=slower propagation
slower propagation=centralization pressure
larger blocks=centralization pressure
The reason slower blocks=centralization pressure is because you don't have to propagate blocks to yourself that you mine, this gives larger miners an advantage.
BTW it's really not last mile datacenter connectivity that's the issue it's regional. Keep in mind that if the majority of the hashpower is in China it is no longer China with the bandwidth problem it is everyone else.
@_date: 2015-12-01 00:19:05
In the case of BIP101 blocks under 1MB are still valid so you can only veto &gt;1MB BIP101 blocks not regular &lt;1MB blocks.
@_date: 2015-12-01 03:59:59
Antpool forgot to upgrade one of their nodes(they were mining v3 blocks at the time though because all their other nodes were upgraded), that is why they failed to enforce and block the initial block download from BTCNuggets, all it takes is one unupgraded node to mess everything up the way they were operating at the time. From IRC logs here is what likely happened(wangchun is f2pool of course).






















Later on:




















@_date: 2015-12-01 00:36:29


It is Antpool f2pool and BTCC that do SPV mining without validation. Antpool actually was the one that forgot to upgrade one of their nodes which triggered the fork.
@_date: 2015-12-01 05:18:05
No, if they were upgraded they never would have picked up the v2 hash to begin with unless it came from f2pool since their nodes should have rejected it. Their SPV mining only skips validation for templates originating from other pools stratum servers not the p2p network.
@_date: 2015-12-01 02:57:41
Do you even know how their version of SPV mining works?
@_date: 2015-12-18 00:05:02
I don't think we can have an alternate client we can use in production until the consensus parts can be fully factored out from core for use in other projects. IMO handling edge cases can be ridiculously complex to find and handle properly and attempting a full re-implementation of bitcoin's consensus code would open up attack vectors if used on substantial portions of the network.
@_date: 2015-12-01 08:51:53
However they didn't start serving 7680Ã—4320 video's until they could actually handle them.
@_date: 2015-12-01 00:00:32
IPv6 isn't really bandwidth constrained though, large blocks are. There is such thing as reasonable testing. We had the technology to run IPv6 for years at scale(we just didn't have enough adoption), we don't have the technology to run 8GB blocks at scale currently.
@_date: 2015-12-02 18:18:10
No, we currently use relay network which is technically more bandwidth efficient. There are a lot of issues other than raw bandwidth however.
@_date: 2015-12-01 08:58:12


There are plenty of voluntary changes that could destroy the network if adopted by enough people.


I think it's just a matter of being careful in regards to protocol changes and don't agree with this.
@_date: 2015-12-01 04:34:21
F2pool did not use BTCNugget as a SPV block source directly so the block must have come from another pool f2pool was using as a SPV block source.
@_date: 2015-12-02 18:20:33


You still validate blocks coming from relay network it only reduces bandwidth. The SPV mining AFAIK predates relay network.


They use both relay and SPV, relay wasn't fast enough so they still use SPV.
@_date: 2015-12-01 00:38:08
Consensus is important for non-trivial consensus changing modifications not for trivial changes.
@_date: 2015-12-18 06:47:10
The miners aren't trying to take control over the project though, many have made statement saying they will not switch without consensus. Their tagging BIP100 was more of a vote against BIP101 than anything.
@_date: 2015-12-14 02:00:12
There's a GBT latency/mempool bloating issue in 0.11.2 with priority, I also ended up disabling it on my pool.
@_date: 2015-12-01 03:20:47
How do you think it went down, f2pool was not running any nonupgraded p2p nodes at the time of the fork. The fork happened because they were using nonvalidated stratum as a blocksource.
@_date: 2015-12-01 06:29:35
They use relay as well, SPV mining is just something they do to gain an advantage.
@_date: 2015-12-29 21:36:02
I don't see where you are factoring in the advantage to miners which have a large portion of the network hashrate. Remember at a network hashrate percentage the higher overall orphan rates benefit the pool instead of hurting the pool. We see this already at 1MB blocks with the Chinese pools, it's basically accidental selfish mining.
@_date: 2015-12-01 07:15:28
No, because China has more hashing power, if they find a block 5 seconds later that only manages to propagate to pools within China theirs still has a better chance of confirmation because more miners are hashing on that block.
@_date: 2015-12-02 06:39:04
Yeah, I was more talking about what could happen if BIP101 was modified to have a forced checkpoint to fork without 75% of the miners.
@_date: 2015-12-07 23:53:29
This is what it looks like in bitcoind:
    "id" : "bip65",
    "version" : 4,
    "enforce" : {
        "status" : false,
        "found" : 738,
        "required" : 750,
        "window" : 1000
    },
    "reject" : {
        "status" : false,
        "found" : 738,
        "required" : 950,
        "window" : 1000
    }
@_date: 2015-12-03 09:56:33
No, I mean simply not paying attention to well known facts within the mining community at all, he's not able to convince miners because they know things he doesn't in regards to propagation issues and he ends up making false assumptions in his arguments.


The primary network issues are cross region mainly to and from China, upgrading network connections there does not help much due to the GFW.
@_date: 2015-12-01 00:17:10
@_date: 2015-12-02 19:54:14


Yes, however hey use relay network in increase propagation of their blocks to other pools.


It was actually going on from a long time before that, from IRC logs:
















Wangchun was the one who invented the technique of mining on stratum headers:


















@_date: 2015-12-01 08:05:53
Yes, and they do mine the largest blocks possible already at 1MB which gives them an advantage. At the same time they don't want to destroy Bitcoin so they are not backing BIP101.
@_date: 2015-12-01 00:41:17
Yes, there is currently no code for BIP100, but that in and of itself isn't an issue.
@_date: 2015-12-01 00:22:30


Obviously there will always be some who won't agree but I'm talking about reasonable consensus where the vast majority of experts and people in the industry agree on something.
@_date: 2017-02-27 01:28:01
@_date: 2017-02-04 21:51:16


Once the UTXO is mined on the BTCU chain at a low fee it can't be mined on BTCU at a high fee. Lets assume that more transactions are being mined on BTCU than BTC, you broadcast a low fee transaction and simply wait for the transaction to be mined on BTCU then use RBF to send it with a high fee after being mined on BTCU so that the high fee transaction gets mined only the BTC chain and not the BTCU chain. At that point your UTXO's are different between the two chains.


Even if it is true in theory that the same transactions can be mined on both chains that doesn't mean they will be since miners will find blocks at different times.


Nope, you don't have to combine with mined coins at all, you just need to get a transaction mined on one chain but not the other then double spend the UTXO on the chain that it wasn't mined on.
@_date: 2016-03-14 07:35:35
The problem is when there is no diversity in settings for a particular host and they are all non-default settings it would suggest that they are all the same node.
@_date: 2016-03-14 06:22:45
The issue isn't the amount of nodes, it's that virtually all are running with a non-default setting.
@_date: 2017-02-27 00:37:27
Yes, as long as the wallet was created on version 0.13.0 or newer it should use BIP32.
@_date: 2017-02-25 02:46:34


Yeah, it's a pretty useless metric by itself since it varies by client.
@_date: 2016-01-01 12:52:10
Mainly the trolls attacking them for supposedly holding up progress even though they are doing the most work in regards to actually making bitcoin scaleable and transactions private.
@_date: 2016-03-14 20:26:25
This is similar to that but instead of changing the port number you just change the IP's to all redirect to the same node.
@_date: 2016-03-06 22:54:34


He's made this statement before the satoshi roundtable.
@_date: 2016-03-06 15:29:51
I've been seeing this statement a lot by Gavin:


I've yet to hear any pools saying anything actually like that though. I think it'd be reasonable to say that statement is fabricated unless some evidence to the contrary is presented. The idea that miners want 75% because of DDoS threats seems pretty absurd to me given that DDoS attacks are pretty common and major pools already have solid defenses in general.
@_date: 2016-03-13 04:04:00
Mining decentralization is probably more important than node decentralization and is a problem that really needs to be fixed.
@_date: 2017-02-03 19:35:03
Miners will mine wherever chain is most profitable(see ETH/ETC for an example of how hashrate follows exchange rate/difficulty), if BTC has more value than BTCU(Coins of the BU side of the fork) then miners would likely mine more on the BTC side(which would also have the side effect of wiping out BTCU's history).


Blocksize doesn't really matter in the profit calculation however, exchange rate, transaction fees and difficulty is what would determine which chain they mine on. If the BTC side of the chain has any significant value users could easily encourage miners to mine blocks on that side long enough for a difficulty drop simply by sending very high transaction fees in BTC(they could use UTXO's that were spent already on BTCU). Since BTCU would have very little if any transaction fee pressure there's a good chance miners would switch back to BTC.
One thing game theory aspect to this is that BTCU would likely further lose value if it were likely that BTC hashrate would end up overtaking it since BTC could wipe out BTCU's history while the opposite is not possible.
@_date: 2016-01-02 02:51:47


I don't think this is true for block validation though, there is the sigcache for transactions you already have but validating the block itself AFAIK is mostly single threaded as is CreateNewBlock for generating the template for mining. CPU core clock speed seems to be a major bottleneck to the point I've started having pool servers built with high clock speeds instead of strictly more cores. The actual mining pool stratum server software that builds on those templates can of course scale just fine with multiple cores and is highly multi-threaded.
@_date: 2016-03-02 09:45:16
That doesn't sound accurate, it also depends on what the goals of the spammer are, if they are trying to waste resources such as bandwidth, storage and CPU cycles then raising the blocksize to 2mb would actually reduce their costs.
@_date: 2016-03-14 05:54:21
The big giveaway here is that basically all of them don't have NODE_NETWORK which means they are pruned nodes, it's kind of funny that the node faker is too cheap to even route all those IP's to a full non-pruned node.
@_date: 2017-02-03 22:43:12


You must not have read this part "they could use UTXO's that were spent already on BTCU" which makes it not possible to mine those high fee transactions on BTCU.
@_date: 2016-03-06 06:31:48
I run pools with ~4% of the network hashpower and I don't think we can handle 2MB blocks in addition to SegWit yet without a significant orphan rate increase.
@_date: 2016-03-14 06:57:33
Notice that nearly all of the IP's are IPv6 and many appear to be on the exact same subnets, you can map an entire subnet to a single node and it will appear as many unique IP addresses to node trackers like bitnodes.
@_date: 2016-01-01 04:22:16
I wonder if all the attacks on BlockStream are due to their work on confidential transactions and other privacy initiatives that makes things harder for companies who's business model is tracking transactions
@_date: 2016-03-06 15:41:59
I think many of them just don't think that's going to make a difference.
@_date: 2017-03-16 03:30:09
[Looks like]( it's actually "BitcoinEC"
@_date: 2016-03-15 02:20:11
One of them in the post is 45.32.227.131:8333
@_date: 2016-01-02 20:55:33
Well I'm pretty sure blocksize generally affects utxo size so that would still be an issue.
@_date: 2017-03-07 15:48:51


Of course jl2012 also wrote a few different HF's such as [spoonnet]( and [forcenet](
@_date: 2017-03-07 16:06:55


It's a short term decrease long term increase.


Both luke-jr and jl2012 wrote multiple HF's.


Well there didn't seem to be community support for moving any of the proposals forward yet, jl2012's spoonnet fork seems to be pretty solid as an initial starting point for discussion/testing though. I wouldn't expect a HF to be merged without widespread support.
@_date: 2016-03-14 07:20:46
Each node on that host should be assigned a single IPv4 address and an IPv6 address range, you can count the IPv4 addresses to get an idea of how many actual nodes there are.
@_date: 2016-03-14 07:23:52
The host should provide both a single IPv4 address and an IPv6 address range for each actual VPS, to count the real nodes just exclude IPv6
@_date: 2016-01-13 14:26:40
Should be who funded it.
@_date: 2016-03-13 00:53:02
There's a really great quote in here:


@_date: 2016-01-02 14:21:23
I'm more worried about the single threaded aspects of the block validation part since computationally expensive parts of CNB can be more or less controlled by the miner making the template.
@_date: 2016-03-14 07:40:31
There are a few IPv4 addresses but most of the addresses appear to be IPv6 address routed to the same systems. Each VPS typically gets just one IPv4 address but an entire range of IPv6 addresses, this means that you can have many IPv6 addresses for a single host. Since IPv6 addresses will not be unique you need to count IPv4 addresses to get the real node count which will be far less than the count including IPv6 addresses.
@_date: 2016-01-13 14:30:44
Peter Todd's RBF forks are the same in that sense since they only change local policy and not consensus rules.
@_date: 2016-03-13 19:48:29
Generally your node will avoid peering with rented nodes by default because of built in Sybil attack mitigation measures in peer selection, I would recommend against making manual changes there.
@_date: 2016-06-23 23:02:22
What are the txid's?
@_date: 2017-01-30 18:11:21
What you see in practice is probably better described as validationless mining since they mine on data picked up over stratum, which doesn't allow for validation of even the header(it only allows for very minimal sanity checks).
@_date: 2017-01-30 18:09:37
It seems most pools now timeout if they can't validate the block within about 30 seconds, so at least there are mitigating factors to make this less likely.
@_date: 2017-01-21 01:10:56


I don't know of any that are, and there is virtually no difference between the hard fork and soft fork versions of segwit(only witness commitment location would be changed which is a trivial difference).
@_date: 2017-01-21 01:54:32


However the claim that SegWit is not a clean update isn't true, there's virtually no difference between the hard fork and soft fork versions and I've yet to really see any of those arguing against the soft fork version object specifically to the one difference. I find it strange people are actually arguing against backwards compatibility.
@_date: 2017-01-21 01:07:44


This isn't true, the situation is more complicated. Virtually all of the Chinese technical community supports SegWit.
@_date: 2017-01-15 19:46:06


[Share DOA and orphans]( are usually over 10%. Orphan blocks aren't as high as orphan shares however but difference in share orphan percentages between miners impacts relative earnings.


Does this protocol punish miners that submit stale shares? If not then they are being rewarded for shares that are unlikely to result in valid blocks and may not be appropriately incentivized to have good connectivity.
How often does this protocol require miners to switch to new work?
Where can I take a look at the proof of concept code?
@_date: 2017-01-21 02:11:02


Apparently that is when they are planning to update from Debian 7 to something more modern.
@_date: 2017-01-15 22:07:59


Well the connectivity among p2pool members sort of helps with that since p2pool has a [transaction caching system that effectively acts as a sort of internal relay network]( which makes good p2pool connectivity the same as good bitcoin network connectivity for the most part. If their connectivity to other p2pool miners isn't good they get punished by higher stale/orphan share rates.
Without being able to appropriately punish miners with bad connectivity it's very unlikely to be viable since centralized pools can immediately reject stale shares as soon as new templates are broadcast(which should take well under a second once the stratum server receives a new block).
I would say something like this isn't really needed in general, the main issue for decentralization can be solved much easier by simply decoupling transaction selection from variance reduction with the centralized pools(this could in theory even be done with something as simple as a stratum extension).
Did this ever get to the point of being able to be mined on by an actual miner?
@_date: 2017-01-30 15:19:42
Yes, using branches is pretty common for unfinished code.
@_date: 2017-01-29 23:37:21
Looks like they were [commenting out and replacing code]( without understanding what it's for.
@_date: 2017-08-24 16:04:00
Most wallets should have it enabled soon as they had the code written but not yet merged or not yet enabled since they were waiting on activation.
@_date: 2017-01-21 01:13:10
FYI that's not a post he actually made, it's some sort of [automated platform](
@_date: 2017-01-15 15:03:34
This seems to be completely impractical in addition to ignoring the orphan rate issue. Centralized pools have a massive advantage when it comes to orphan rates due to efficiencies in block relay by centralization in addition to other factors such as having faster and better connected infrastructure. The primary reason p2pool is impractical is due to higher orphan and stale share rates. Miners are unlikely to use a decentralized pool if there is a non-negligible expected earnings difference.
GBT as a protocol is impractical due to very high overhead(this overhead can be mostly eliminated with a redesign of the protocol), the concept of letting miners do their own transaction selection or having someone other than the pool they use for variance reduction do transaction selection should however be viable and far simpler than this overly complex smartpool idea.
@_date: 2016-06-17 06:44:45
I would guess because your question doesn't really make much sense based off of the way things work, transactions approach infinity as fee approaches 0 when graphed, transactions accepted will vary based on min relay fee which varies based on mempool size, effectively the number of transactions that make it to your node won't really change.
@_date: 2017-01-30 01:29:59
Fairly simple, but it really goes to show how poor the code review for BU is since that is something that should have easily been caught. There are likely many more unidentified bugs that would have easily been caught with proper code review.
@_date: 2017-01-30 08:02:03


Yeah, tweaking code that one doesn't understand usually doesn't end well for mission critical applications. When people bring up BU vulnerabilities a common response from them is rather than fix the issue they say it's supposed to be like that or just say they don't think it's likely to be exploited. A good example of that would be the xthinblock shortid collision attack vulnerability that was never patched. Many of these vulnerabilities don't really matter unless there is significant usage of the software.
@_date: 2017-08-24 11:13:26
I wouldn't worry about this yet, pool software based on eloipool [by default won't include the witness commitment unless there are actually segwit transactions in the block]( once there are more segwit transactions being created it should be a more reliable indicator.
@_date: 2016-06-18 18:17:45
Sounds like Rootstock is putting [security first]( unlike ethereum.
@_date: 2016-12-06 00:42:01
That also isn't decreasing. ~24% of hashpower have upgraded to segwit so far, the graph ramped quickly because all that had previously upgraded started signaling at once and the graph is using an average over many blocks.
@_date: 2016-11-18 06:17:36


Looks like the mutex code he's complaining about is inside of an [ DEBUG_LOCKORDER]( so it shouldn't even cause any issues unless you are specifically compile with that flag(which is only supposed to be used for debugging).
@_date: 2016-12-05 11:59:34
Wonder if I'll get banned for posting [this Coindesk article](
@_date: 2017-01-09 10:23:47


There is virtually no difference between doing a soft fork and hard fork version of SegWit, the only thing one would change is the location of the witness merkle root(which can always be changed later if a hard fork is done).


This proposal has had many [flaws]( [doesn't appear to fully fix malleability]( third party malleability) and introduces [needless complexity]( Flexible Transactions was developed by a developer(Thomas Zander) who has a [history of being toxic]( to open source projects and is unlikely to ever be used.
@_date: 2016-12-05 12:00:21
Probably talking about the [information in this article](
@_date: 2016-11-17 21:25:30
I don't see BU mentioned [there]( at all.
@_date: 2016-12-06 05:40:31
No, that's not how it works, there is no config setting to enable SegWit in 0.13.1 on an individual node basis. SegWit will be enabled for all 0.13.1 nodes once miners activate it using BIP9 version bits. Miners running 0.13.1 with SegWit compatible pool software should automatically signal for SegWit via BIP9 version bits.
@_date: 2016-12-05 12:23:42
There was [this](
@_date: 2016-11-10 13:08:49


This here is very vague and sounds a lot like advocating for people choosing their own individual consensus rules. Would be a good idea to clarify that changing consensus rules requires widespread agreement otherwise people will end up on different forks.
@_date: 2016-12-05 12:14:02
That's what I would assume, that's the excuse they used to ban him from @_date: 2016-12-05 15:42:35
Wonder if I will get banned for posting [publicly available mailing list posts that contain email addresses](
@_date: 2016-12-08 23:56:22
That hasn't been too big an issue, virtually all the Chinese miners seem to have pool developers that know enough English to work with English speaking developers directly.
@_date: 2016-12-06 00:37:16
It isn't decreasing, bitnodes, for example, shows 2007 out of 5292 are 0.13.1+ which is about 38% and isn't lower than its been before.
@_date: 2016-12-08 21:45:30


Looks like that was [just merged](
@_date: 2016-12-06 09:45:56


Yes, it would make sense that generating SegWit transactions in the wallet is disabled until activation for safety reasons. The consensus code is the important part though for nodes to fully understand SegWit which is activated via BIP9 and not via any config flag. Addresses that start with a 3 are of course P2SH which are not exclusive to SegWit usage.
@_date: 2016-12-14 23:26:41
There is a transcript [here](
@_date: 2019-02-12 09:33:18
I have no problem helping them fix the vulnerability...once they are compliant with the GPL licenses of the software they use in the firmware(some of which I've contributed to myself). Bitmain firmware is very buggy in general and it's important that users be able to fix the bugs Bitmain introduces.
@_date: 2019-02-12 23:18:35


@_date: 2015-08-04 13:55:07
Here's my current list of suspected shill accounts from this company let me know if you see any more, also upvote this post for visibility as they are using downvote bots:
@_date: 2015-08-25 15:52:27
Look at how many large pools are private, like Bitfury, 21 Inc etc, this has been going on for a while now.
@_date: 2015-08-26 18:57:31
I'm guessing you probably mean increase the minimum blocksize cap to 2MB, an actual minimum blocksize is a very bad idea.
@_date: 2015-08-04 13:14:43
Until someone posts some internal pictures and a firmware image that can be verified(I can help someone create this if they have a real unit) everyone should consider this a scam. Their price on the Antminer S5 is also too low to be legitimate IMO.
@_date: 2015-08-28 05:19:49
Going against the miners is far too risky, it would significantly lower the barrier to a 51% attack on the smaller fork.
@_date: 2015-08-28 03:57:02
The merchants will have to come to a compromise with the miners then, BIP101 can't activate without ~75% miner support.
@_date: 2015-08-28 15:37:08
One other thing at play is BIP101 killing any sort of fee market by making transactions too cheap.
@_date: 2015-08-26 19:17:52
They actually are literally tagging their coinbase sigs with "BIP100".
@_date: 2015-08-27 23:59:47
I had previously thought this might be the case but it wasn't clear until they actually started tagging /BIP100/
@_date: 2015-08-28 00:18:26
Thanks, added to OP.
@_date: 2015-08-28 05:33:13
I think even the possibility of a 51% attack is enough to prevent economic consensus that is out of line with the miners. Miners are also heavily involved with the Bitcoin economy in general and hold influence there as well.
@_date: 2015-08-25 07:36:36
This isn't actually true in a lot of cases, there are many pools that own most of the miners that hash for them.
@_date: 2015-08-26 17:51:25
Some of the Chinese pools didn't tag every block with 8MB back when they initially backed a 8MB increase, but unless they tag something else or say otherwise I think it's safe to assume they are still supporting BIP100.
@_date: 2015-08-04 13:24:40
Yeah, and the OP's account is 24 days old, going to say confirmed scam at this point. Nobody in the mining industry has ever heard of a "CloudThink NanoHash Chip". Mining ASIC's take many months of development and generally don't just come out of nowhere.
@_date: 2015-08-28 17:43:45
Because miners are often holders.
@_date: 2015-08-04 13:34:53
It doesn't actually exist, known scam 
@_date: 2019-02-12 12:28:20


I don't have a S15, I was able to discover the vulnerability by auditing the firmware update file on their support site.
@_date: 2015-08-04 12:54:48
The technical details(or rather lack of details) would potentially indicate this is a scam, I have requested further details from them but for now I would recommend against purchase.
@_date: 2015-08-28 16:32:42
That's why I think we will have to have a compromise of some sort, one that allows transaction volume to scale up but only as needed.
@_date: 2015-08-26 18:26:33
It's clearly not just the Chinese that have an issue with XT, Bitfury is not based in China.
@_date: 2015-08-26 18:34:19
Kind of surprising that China backed it first then isn't it?
@_date: 2019-02-12 23:04:06
Somehow the "don't" got auto-corrected out, fixed now.
@_date: 2015-08-30 03:23:11
So apparently miners aren't even human anymore.....nice shitpost you got here. There currently isn't a better mechanism than proof of work since other methods far too easy to fake.
@_date: 2016-02-11 20:05:30
I don't run BitmainWarranty myself though, I'm not the CEO.
@_date: 2016-02-11 19:22:07
BITMAINWarranty is run by Yoshi Goto as the letter states.
@_date: 2016-02-11 21:38:02
Other companies like Bitfury and BTCC also had multiple signatories.
@_date: 2017-04-10 05:35:10
People have been attempting to gain consensus round [that proposal]( but so far it hasn't gained much traction.
@_date: 2016-02-11 21:21:00
I signed under BitmainWarranty because Yoshi who runs BitmainWarranty also supported the letter.
@_date: 2016-02-13 01:02:04
I guess that's the only response they have after they let a large miner [steal]( from everyone else for what was likely months(I wonder if they are going to reimburse the miners that got stolen from). [This]( is how Eligius handled a similar situation.
@_date: 2016-02-11 21:54:11
~2-3% of the network
@_date: 2016-02-13 03:04:25
Yeah, that's what I thought, seems mostly pointless IMO.
@_date: 2017-04-01 10:06:42
Other [hard forks]( that are much better have been put forward, this seems unlikely to gain significant support from users/industry.
@_date: 2016-02-11 22:07:40
I can't really go into specifics there, some is in semi-private pools I operate while some is in public pools.
@_date: 2016-09-01 18:21:08
You normally would want to use a mining pool, you could use a lotto pool like [solo ckpool]( The chance of you finding a block is very low though and you won't have enough hashpower to really earn anything on a normal pool due to payout minimums.
@_date: 2016-09-09 10:28:48
What's the txid?
@_date: 2019-01-18 03:57:14
The [license]( for the libbitcoin library that you are using doesn't allow for closed source releases.
@_date: 2019-01-18 21:18:03
Seems there is an [inconsistency]( with libbitcoin's license.
@_date: 2019-01-18 03:20:44
I should note that many BIP70 implementations have unfixed security flaws and that there's a high chance that independent implementations will be implemented incorrectly. Without source code it can be tricky to determine if an implementation is vulnerable or not.
@_date: 2015-09-07 16:38:36


This is actually just an optimization issue with bitcoin core, the mempool just needs to be filtered beforehand so GBT/CNB don't have to work off of the entire mempool. There are lots of optimizations like this that need to be done.
@_date: 2015-09-22 00:06:35
AFAICT it's literally a miner hooked to a pi with some bitcoin related software, you could install the software on any pi and hook one of the many random USB miners to it for a quarter the price. In any case it wouldn't even mine much in the way of a useful amount of bitcoin.
@_date: 2015-09-07 06:30:17


When he failed to convince the miners he tried to bypass them by pushing BIP101 on the payment providers, it didn't exactly work out for him/BIP101. The strong opposition comes from the engineering side of the Bitcoin community which is aware of the issues larger blocks can cause.
@_date: 2015-09-03 04:06:47
It has everything to do with block size because validation and propagation is tied in very closely with block size. BTW not fully validating the chain currently does pay, but they have to trust the source of their SPV mining. 
@_date: 2015-09-07 06:46:35


The issue here is that miners can hack around the issue with trusted SPV mining networks(as is done in China) which is dangerous to the network, in reality propagation has not a whole lot to do with raw bandwidth and a lot more to do with software optimization, most miners don't have enough money to hire devs capable working on security sensitive software such as bitcoin core in any significant capacity. There has been very little work in regards to mining side development in core due to reducing sync times being a priority.
@_date: 2015-09-01 15:59:01
If there is a blocksize increase in the near future it will certainly not be BIP101, miners have weighed in with BIP100 as an alternative that is far safer to implement as it provides a mechanism to dynamically vote on the block size rather than trying to make predictions 20 years into the future like BIP101.
@_date: 2015-09-03 15:22:35


What I'm saying is that large pools can use each other as a reliable source of validation data, that's exactly how it's done with f2pool and Antpool with their SPV mining. 
From what I've heard the BIP66 validation issue was the result of Antpool leaving one of their nodes in a non-upgraded state(with f2pool building their block off of that node), their SPV mining scheme would have otherwise worked fine.
@_date: 2015-09-21 20:05:51


Lol, so it's basically a pi hooked to a more efficient Antminer U3 in terms of hashrate for $400. Wonder what type of idiots will buy this thing. Could easily buy a &gt;1TH miner for $400.
@_date: 2015-09-02 03:21:23


They do with BIP101 because of the voting mechanism.
@_date: 2015-09-21 21:52:25
I'm not sure what though that you couldn't just install yourself on regular pi.
@_date: 2015-09-21 19:54:38
Maybe I'm missing something but did they just announce a bitcoin miner without any specs listed at all in regards to hashing speed? I mean you could buy raspberrypi2 and an Antminer U3 for about $50.
@_date: 2015-09-06 05:43:59


Funny how that letter contains a lie about majority miner support for BIP101, any idea where that info came from?
@_date: 2015-09-01 18:22:45
That's not really accurate, that's just the narrative BIP101 backers are pushing. Among experts and a good amount of the more technically inclined Bitcoin community there is in fact very strong opposition to BIP101, most of this opposition has nothing to do with Blockstream.
@_date: 2015-09-02 01:24:47
Bitmain basically confirms they will not switch to XT here and want consensus in the Bitcoin industry. If consensus is reached on BIP100 it would appear Bitmain would back it, this potentially brings BIP100 support to over 80%.
@_date: 2015-09-02 23:08:18
Miners have to download block as well you realize, if a miner uploads a huge block that another can't download quickly it causes problems for that miner. That is the point of the caps it to prevent large miners from pushing out smaller ones. Because of this large blocks are dangerous to decentralization.
@_date: 2015-09-01 18:51:31
His power grab was more directed towards the payment processor side of the industry and the general public. Doing it from within the core dev community would have been too difficult since they would tear BIP101 apart on the technical side. IMO he failed to realize how strong the opposition was and thought he could railroad it through. He couldn't convince the miners so he tried to go around them, it didn't work out too well for him since they rejected very strongly before BIP101 could pick up too much momentum.
@_date: 2017-01-30 01:06:10
They removed code that reserved space for the generation transaction basically. Although looks like it was [this commit]( that triggered the issue in the end. Would appear they removed 2 safeties that could have prevented it.
@_date: 2015-09-03 16:12:56
I'm not arguing against any block size increase I'm arguing against BIP101 which massively increases the block size cap all the way up to 8GB without any sort of safety net.
@_date: 2015-09-22 00:51:02
Um, by default you can do just about anything from command line on a pi, I don't really see what's special about it.
@_date: 2015-09-03 18:17:05
I don't consider a soft maxblocksize to be something that can reasonably work well enough. I'm ok with BIP100 because it has 2 safety nets, the voting mechanism and a 32MB hard cap. I consider the future too hard to predict to commit to 8GB blocks right now.
@_date: 2015-09-22 01:13:20
[U3]( are more like $20 though so it would be even less.
@_date: 2015-09-03 21:35:45
That's why I mentioned a higher threshold than 80% for going above 32MB, one that would be unlikely to activate without consensus.
@_date: 2015-09-02 21:52:23
The issue was the doubling of cap every two years not the mechanism in which it doubled, being linear between the doublings in no way addresses the concerns of the miners. The issue is that rather than provide a way to scale up the cap as needed it attempt to predict the cap that is needed all the way out to 20 years from now which IMO is reckless and should have no place in a network like bitcoin.
@_date: 2015-09-03 20:37:40
They want a cap they can plan for easily. Its risk management basically.
@_date: 2015-09-07 16:35:35


Relay network only helps with one of the block propagation problems, there are still issues with GBT/CNB being slow especially with larger mempools.
@_date: 2015-09-11 19:58:05
Send an email to info they have refunded these mistakes in the past, may take a few days though since it's the weekend and they are probably busy with the S7 launch.
@_date: 2015-09-02 03:53:06
Miner's are a part of the Bitcoin ecosystem just like other users, they do not exist in complete isolation.
@_date: 2015-09-03 15:15:35
Not really interesting, its pretty obvious why there would be little controversy, most pools manually set this option and it does not change the consensus rules in any way.
@_date: 2015-09-03 21:33:50
I run a semi-private pool and operate mining farms, from conversations I've had people are generally wary of removing the cap completely.
@_date: 2015-09-22 03:00:46
Yep, IMO this is probably just a gimmick product to get more VC investment.
@_date: 2015-09-03 18:22:47
Miner's are likely to reject it without the cap. One possibility may to have a threshold at something very high such as 95%(same used for BIP66) that is needed to increase the blocksize beyond the 32MB cap.
@_date: 2015-09-02 03:20:20


You think miners aren't investors?
@_date: 2015-09-03 20:38:55
I would prefer a higher percentage for moving beyond so that we have an upper target to plan for in the near future.
@_date: 2015-09-21 21:19:34
I don't see anything all that special about their software. Seems like a standard command line mining interface to me.
@_date: 2015-09-07 06:40:11


It was never really about raw bandwidth or the cost of bandwidth, it's about regional propagation and software optimization(primarily in bitcoin core). Have you benched your block notify's over stratum in comparison to other pools? Bitcoin is a bit bursty so for pools you generally need high throughput but not a lot of overall transfer in comparison. There are major issues with GBT/CNB that slow down the block notifys that I've run into myself such especially when there is a larger mempool. I do farm/pool operations for about 1% of the bitcoin hashrate btw.
@_date: 2015-09-11 00:17:54
A default increase is a bad idea, any sort of arbitrary increases without majority miner support should be avoided as that indicates the miners may have problems handling larger blocks. There should also be a mechanism for miners to vote down the block size if they end up having problems with an increase.
@_date: 2016-10-13 00:04:28
There are a lot of things in the post that show a shockingly bad understanding of how Bitcoin works, one of the worst being:


It is ultimately up to the users to decide whether to increase the block size, miners have very little power here in reality.
There is also a big misunderstanding regarding Segwit:


Segregated Witness actually fixes many longstanding issues with transactions such as malleability, this effectively reduces technical debt. It should be noted that most bitcoin software and underlying libraries are ready or almost ready for SegWit already.
@_date: 2015-09-25 05:41:15
He should also be able to run BFGMiner in proxy mode right? Other option is a dedicated stratum server like [ckpool]( Did spondoolies not compile their cgminer with GBT support? Normally cgminer should support GBT.
@_date: 2015-09-21 19:50:09
They tagged their mined blocks with BIP100.
@_date: 2015-09-03 18:20:49


It only bit them because of a technical mistake(forgetting to upgrade a node), if done properly between trusted pools there theoretically shouldn't be an issue.
Really what I'm saying is we need more time before attempting something as drastic as BIP101 which is why I would prefer BIP100. I'm not saying issues can't be resolved, I'm saying that until they are we shouldn't jump the gun.
@_date: 2015-09-01 15:29:25
IMO you are campaigning for public support for BIP101 instead of support from experts and pool operators, there are serious technical issues with BIP101 and miners will not support you unless their concerns are addressed. The 60% of miners currently coinbase tagging BIP100 and statements rejecting BIP101 reflect my opinion.
This is less about governance and more about the technical issues with BIP101, the miners were quick to realize this and back an alternate proposal. You tried to screw them over by pushing this without their approval and without addressing their concerns. You should not be surprised at the backlash. Miners do not like your style of governance which completely ignores them.
You and Gavin have done very little work to improve the mining side of the ecosystem, if it wasn't for others such as gmaxwell we would have significantly higher orphan rates, it is only through hard work from a lot of people that we have been able to mostly handle 1MB blocks without too much of an issue but there is a lot of work to be done still in order to handle larger sizes.
You tried to completely bypass the miners and push support for BIP101 with the payment industry along with the general public, I suggest you do not try that again as it will not succeed, you may have tricked some into thinking their was wider industry support but not all of us are that stupid.
@_date: 2015-09-03 02:23:20
IMO my fear is already proven by the Chinese SPV mining, there are serious technical issues with larger blocks and to ignore them is dangerous. A large miner or group of miners with SPV mining links could push out smaller miners since they wouldn't even have to fully validate between each other, IMO this is already happening to some degree with the Chinese pools.
@_date: 2016-10-13 08:06:18


Clearly this post is not promoting running client software without consensus as there isn't even client software for it yet. Mimblewimble can likely be deployed as either a sidechain or extension block and depending on the details would be considered actual Bitcoin.
@_date: 2015-11-21 21:29:14


There is a UUID but it is very easy to clone with this command.


@_date: 2015-09-07 16:41:27
The issue with their SPV mining AFAIK was a non-upgraded node on antpool that f2pool SPV mined off of, it was a simple fix. AFAIK they only SPV mine between other chinese pools.
@_date: 2015-11-16 20:57:14
While BIP65 can be used to help with Scalability, it is a useful feature regardless of the block size, there is no downside to it. Since there are no significant objections to implementing it and since it is not a change that breaks existing consensus rules it can be implemented as a soft-fork. This is very different from a block size increase which can have many negative aspects that need to be taken into account in addition to the hardfork nature of it. There is no reason to hold off of general improvements like BIP65 while a block size increase is evaluated.
@_date: 2016-10-12 23:48:05


This is a pretty dangerous misunderstanding of how Bitcoin works, miners can't remove consensus rules without the consent of the users of Bitcoin.
@_date: 2015-11-30 13:21:58
The mining pools are going to block BIP101 activation if it comes down to a fight, f2pool(which has been very vocally against BIP101) for instance is essentially large enough by itself to block BIP101 activation.
@_date: 2015-09-01 17:10:14
IMO it wasn't urgent, it was a power grab by hearn/gavin. 
@_date: 2015-11-30 15:01:29


This isn't really safe in practice by itself, in addition only miners can vote in this way in practice since there is no such thing as proof of node.
@_date: 2015-11-16 19:22:30
BIP65 is useful regardless of block size and will be deployed before any block size increase now since BIP101 has failed to gain any significant support from miners.
@_date: 2015-11-15 19:06:28
[Blocktrail]( has a nice graph.
@_date: 2015-11-30 15:36:39
There isn't a whole lot which is one of many reasons that BIP101 is dangerous. In any case you should keep in mind that the BIP101 cap rapidly increases, it only starts at 8MB.
@_date: 2015-11-30 14:57:56
A large amount of hashing power is actually owned by the same entity's that runs the pools they hash in([Antpool]( [Bitfury]( [KNC]( [21 Inc]( [BW.com]( [BitclubNetwork]( [Telco 214]( are all pools where a substantial portion of their hashrate is known to be internally owned and operated), so if they were the ones doing the 51% attack it could be profitable.
@_date: 2015-11-30 14:47:31
[BIP101]( is a scaling proposal by a mostly inactive Bitcoin Core developer Gavin Andresen which was merged into Mike Hearn's fork of bitcoin core in attempt to [take control]( of Bitcoin's protocol development and bypass the current consensus system. It increases the block size cap to 8MB and then doubles it every two years all the way up to 8GB. The rate of this increase is considered by most experts to be far too fast for Bitcoin mining and transaction processing to remain decentralized. It is widely regarded by most technical experts familiar with the matter as reckless and harmful to bitcoin's future decentralization. It is also considered by many to make it easier to censor and regulate bitcoin transactions due to increased centralization pressure on miners, exchanges and other transaction processors, which is something Mike Hearn has advocated for in the past using a [redlist]( type system.
@_date: 2015-11-30 13:28:44


KncMiner is backing BIP100 not BIP101, they just weren't fact checking and hearn tricked them into signing a statement backing BIP101. Once they realized they had been tricked they started mining BIP100 tagged blocks and made a statement saying they prefer BIP100.
@_date: 2015-11-30 14:52:00


This doesn't work because miners can't choose the size of the blocks they want to download, they have to download every valid block or they risk having their own blocks orphaned.
@_date: 2015-11-30 15:12:16
I think the only major exchange that currently mines is BTCC and they are not in favor of BIP101.
@_date: 2015-11-30 14:36:20


This is not true, their are other scaling proposals that have been implemented, the difference is people aren't advocating switching to them without reasonable consensus.
@_date: 2015-11-13 23:09:30


I'm saying we have a lot of existing propagation issues that take time to profile and fix. I threw together a simple tool for monitoring stratum updates across pools and I've already used it to isolate some GBT latency sources.


I don't think that raising the block size or scheduling block size increases that go above current available technology is a good idea. IMO raising the block size cap is the simple part, fixing the underlying issues is the hard part. As is I see far too much centralization pressure from large blocks.


Yes, I've been following these tests and so far the data I have seen would indicate that mainnet can't handle even 8MB blocks let alone larger without massive propagation delays.


I've been doing all that I can to get better data and profile block propagation, everything I have so far indicates we are quite a ways away from being able to handle even 8MB blocks without a massive orphan rate increase. I was already able to use this data to tune my pool so that it is the fastest pool to send out block updates to miners compared with all other pools that don't SPV miner or mine empty blocks.
@_date: 2015-11-16 05:12:40
Yeah, firmware image as in a data dump of the memory card, not a photo.
@_date: 2015-11-21 21:55:38


I don't think this will be effective, it should be fairly trivial to modify their swirl implementation and turn it into a stratum proxy so that any sha256 miners can be used with it.
@_date: 2015-09-08 16:07:05
Are you planning to fix it? I'd be interested in seeing how long it takes between a submit block on one node and a gbt call returning on another one with 32MB or larger blocks.
@_date: 2015-11-30 13:26:10


The miners are not this stupid, they see orphans every day and know that larger blocks can have a serious effect on orphan rates(I've done a good deal of benchmarking in regards to this myself). A lot of them also value decentralization and know that BIP101 would seriously damage mining decentralization.
@_date: 2015-09-02 02:56:58
The experts are also users, they are the ones who run the pools and services, this is not the type of thing that should be pushed on the public without support from the technical side of the bitcoin community. BIP101 was pushed politically because it had too many technical issues to convince the experts, in this case I prefer having a [meritocracy](
@_date: 2015-11-30 15:30:52


BIP100 attempts to do this by allowing miners to dynamically vote on what block size cap they can handle.


BIP100 is basically a more practical version of this IMO since it coordinates the cap between miners.
@_date: 2015-11-30 15:39:08
Hint: There's a reason over 50% of mining pools are tagging BIP100 and BIP101 is at less than 1%. They aren't idiots.
@_date: 2015-11-30 15:17:17
Voting generally implies having an actual affect on something, simply running XT in and of itself doesn't really have an affect.
@_date: 2015-11-15 20:24:13
It already has, there is very little development activity in XT compared to Core. Although it is somewhat less of an issue since XT isn't really an independent client so much as a patchset on top of Core.
@_date: 2015-11-30 14:49:43
Regional connectivity is a far bigger issue than last mile actually, China is currently a really big problem in regards to this since they have the majority of the hashing power. When it comes to mining if the majority of the hashing power is in China it is not China with the bandwidth problem it is everyone else.
@_date: 2015-11-30 15:03:32
No, 75% is only hashpower consensus, it doesn't take into account the consensus of other major players. In addition BIP66 and BIP65 use 95% as the threshold not 75% which IMO is a much more reasonable threshold.
@_date: 2015-11-18 09:03:52
Don't ask too many questions about their chip or they will ban you :P.
@_date: 2015-11-15 20:30:29
There is already a [pull request]( so it will likely get merged soon.
@_date: 2015-11-30 15:09:18


That threshold is IMO far too low, although it is unlikely to get anywhere close to that due to strong statements in opposition to BIP101 from many major mining pool operators.


IMO decentralization and fungibility is the essence of Bitcoin, and BIP101 is extremely dangerous to decentralization. It would give way to centralized transaction confirmations.
@_date: 2015-11-30 15:24:14
Forking without the miners massively reduces the security of the fork since 51% attacks would be far easier to carry out.
@_date: 2015-11-30 17:22:01


That's kind of how consensus works. However I think we can get there, it just might not be overnight.
@_date: 2015-11-30 15:13:24


The issue has less to do with last mile connectivity and more to do with regional connectivity. Mining for instance is a very latency and bandwidth sensitive activity. One thing to keep in mind as well is that if the majority of the hashpower is in China, it is not China with the bandwidth problem it is everyone else.
@_date: 2015-11-30 15:20:27


I don't really see how.
@_date: 2016-05-03 01:35:00
Since Gavin was able to be convinced that Craig is Satoshi I think there's a very real risk that he might have given him access to the github repo. Since Gavin isn't supposed to be merging PR's to the Bitcoin Core repo I see no reason that he should have any elevated privileges anymore.
@_date: 2015-11-30 15:22:32
None, unless they have a secret farm somewhere they aren't telling anyone about.
@_date: 2015-11-19 22:57:36
How would you identify net hashrate percentage? I don't think this is really possible.
@_date: 2015-11-30 15:10:37
No, it is actually [750 out of 1000](
@_date: 2015-11-19 19:50:56
I just think this is the wrong way to encourage decentralization, one problem for instance is that smaller pools wouldn't mine enough blocks by themselves to get reasonable confirmation times for transactions locked to a single pool.
@_date: 2015-11-30 15:27:11
Yes, there are many such as developers and other bitcoin related services.
@_date: 2015-11-11 04:17:21


So basically have nobody doing full validation anymore? If you don't fully validate you have to trust all the pools you connect to. By the way the type of stratum based SPV mining that the Chinese pools use is closer to no validation than it is to even SPV levels of validation.


It is the size of the blocks that caused SPV mining in the first place however, small blocks can propagate across the GFW quite quickly however blocks closer to 1MB take significantly longer(often in the 5-10 second range). The stratum based SPV mining system was created by the f2pool pool admin because block propagation was too slow. SPV mining will be less relevant as the block subsidy goes down which would cause even more regional propagation issues.
@_date: 2015-11-30 16:53:33


Not saying I think that's a good idea.
@_date: 2015-11-30 14:09:43
I think it's a little early to predict what a home connection will be like with BIP101's 8GB blocks. Increasing the block size to levels that have not been tested is extremely dangerous to decentralization.
@_date: 2015-11-30 23:54:58
Not really, If I wanted to I could bring up a thousand XT nodes, doesn't mean each one counts as a vote.
@_date: 2015-11-19 19:33:42
IMO there is far too much risk of collusion with something like this, if exchanges or other payment processors collude they would be able to push out smaller miners. It is important that all miners have a chance to mine any valid transactions. In any case this can technically be accomplished by having the pools accept transactions directly not over the p2p network(this was actually done between mtgox and eligius for a very short period of time where eligius would mine mtgox transactions for free). If they don't broadcast the transaction they would be the only pool that could mine the transaction.
@_date: 2017-05-23 06:59:07
There are a lot of miners sitting on the fence and also a lot of pressure to move forward and activate segwit, especially with BIP148 gaining momentum. Since activating the existing segwit deployment is the only technically viable short term scaling solution it may very well happen. This proposal provides miners with a way to avoid BIP148 as well, we saw what happened with Litecoin already when it was clear the community was going to back BIP148(miners used the MASF to activate segwit), something similar could very well happen with Bitcoin.
@_date: 2017-05-23 22:37:22
Matt Corallo [thinks it is a reasonable proposal](
@_date: 2015-11-30 16:24:01


Odd you say that when f2pool is often the one taking risks trying new things.
@_date: 2017-05-24 03:55:33
There is code [here]( already.
@_date: 2016-05-03 01:51:33
Yeah, I'm saying if he was given commit access back he would be a risk.
@_date: 2017-05-23 02:56:45


I don't think so.


I was not there in person but I have talked with some who were.


I'm not sure, I made this proposal so that everyone is aware that there is a technically sound way to accomplish the first goal of "Activate Segregated Witness at an 80% threshold, signaling at bit 4" quickly and without full redeployment:


As mentioned in the draft BIP it can be lowered, 55% hashpower would even be enough to prevent a chain split although higher is still better.


I thought it was clear enough from the first sentence in the mailing list post.
@_date: 2017-05-23 06:50:27
I'm not sure, a September HF deadline is completely reckless regardless. Another explanation may be that they didn't realize they could do something like this to reduce the threshold without a full redeployment.
@_date: 2017-05-23 01:25:36
@_date: 2017-05-23 22:28:19
I don't think any sort of dirty HF is a good idea.
@_date: 2017-05-23 22:27:36


There is a [mandatory signalling period]( for BIP91.
@_date: 2015-11-30 16:01:20


True it doesn't actually do anything towards activation but it certainly gives you an idea where their support lies.


Neither of these are all that significant. There are other proposals with code and node counts by themselves don't matter(and are really easy to fake).
@_date: 2016-05-12 13:49:17
Timo is the one licensing the patent outside of China, Bitmain only has the patent within China. I don't think Bitmain intends to enforce the patent but Timo has indicated he does.
@_date: 2015-11-16 19:57:43
BIP65 doesn't really have an effect on the block size debate though, and it is fairly uncontroversial(there are no objections by miners AFAIK). There is also no serious objections to BIP65 from the bitcoin community in general.
@_date: 2017-05-25 14:05:13
I have a [PR open]( there as well.
@_date: 2017-05-22 22:55:44


The second signalling bit makes it safer by automating coordination.
@_date: 2016-05-03 01:36:21
According to Gavin Craig proved he was Satoshi to him already.
@_date: 2017-05-23 03:45:15
It's fairly safe for soft forks, especially if most of the economy has already updated and will enforce the rules. Hard forks even 95% hashpower can result in a chain split so there's a higher bar there.
@_date: 2017-05-23 22:46:22


I'm not sure what you're suggesting, it would not be safe to put an unfinished HF in a stable release.
@_date: 2016-05-03 01:38:42
Yes, it's an old comment but I think there's still a very real risk that he would give Craig control over the repo.
@_date: 2015-11-30 14:31:59


Actually there kind of is because the BIP101 chain would then be shorter than the normal chain. If BIP101 is modified to be a forced fork using a checkpoint or something like that and has a minority of the hashpower it would be much easier to 51% attack it.
@_date: 2016-05-02 20:30:38
Archived the google cache:
@_date: 2017-07-16 17:53:31
I have a minimal 0.14.2 BIP91 branch available [here]( that miners can use.
@_date: 2017-05-22 22:56:34
This decouples the second part so it can be done at a later date, it eliminates the need to try and rush a completely new deployment.
@_date: 2017-05-24 08:34:32


You can see from the tweet after that one he's clearly referring to a HF. BIP91 is still a convergent soft fork so you won't end up with 2 chains.
@_date: 2015-11-30 23:57:15
The bitcoin network is a consensus protocol itself and running software with an alternate consensus protocol can be risky.
@_date: 2017-05-22 23:01:42
Correct, but it's done in a way that's fully compatible with the existing deployment.
@_date: 2015-10-15 17:11:07
Looks like they already [fixed]( it, although the website usually takes a while to update. For some reason the coinbase sig string matching picked up "Slush" before the Antpool tag.
@_date: 2015-11-30 13:58:30
BIP101 by definition requires 75% hashrate majority.
@_date: 2015-11-30 16:09:47


I consider the hard limit a good thing, IMO it's basically a failsafe.


However it has the very real danger of quickly outpacing technological growth without a failsafe.
@_date: 2015-11-20 17:01:20
Bitcoin doesn't really provide a way to positively identify miners though. The way blockchain.info and other block explorers do it only works if the pool wants to be identified.
@_date: 2017-07-16 17:51:01
That's correct.
@_date: 2016-05-03 02:00:41
Yep, doesn't make sense, one way or the other Gavin's compromised though.
@_date: 2015-11-30 14:35:18


More than enough to block BIP101 activation have come out strongly against it so this would be unlikely.
@_date: 2017-05-23 04:38:52
80% is the threshold listed [here]( which is why I used it in the proposal. There wasn't too much in the way of technical details there so I figured I would make a proposal for how to accomplish the first part in a technically sound and backwards compatible way.
@_date: 2015-11-10 19:54:54
I think you are missing the way large blocks can hurt or help certain regions even when pools have no malicious intent, lets take China as an example, connectivity within China between pools is pretty decent and with SPV mining factored in the entire region gains a significant advantage over everyone else since they have the majority of the hashing power. This puts non-Chinese pools at a disadvantage due to the time it takes for block to cross the GFW. A lot of Chinese pools max out the 1MB block size already, these block propagate quickly to other Chinese pools but not to pools outside of China. Due to their SPV mining even large blocks from outside of China quickly propagate the other way around(this is pretty much only one way since most non-Chinese pools do not SPV mine).
To summarize, if the majority of the hashing power is in China it is not China that has a bandwidth problem it is everyone else.
@_date: 2017-05-23 17:13:38
Incentive models due to the minority chain reorg probability would reduce the likelihood of that significantly.
@_date: 2015-11-30 13:16:36


Miners will likely prevent any activation attempt since they would be the ones to lose money from BIP101(primarily from significantly higher orphan rates) while exchanges would benefit from lower transaction fees.
@_date: 2015-11-30 23:54:07


This isn't really true in the current state, the current system requires consensus for changes that modify the consensus protocol.
@_date: 2016-07-28 07:57:28
AFAIK only 3 do, Antpool, f2pool and BTCC's pool.
@_date: 2016-07-21 15:41:36
Yeah, most just use API's...some at least are backed by full nodes on VPS's or servers but still use a centralized management system from the ATM manufacturer. I've seen others use electrum wallets, I don't think any really have the resources to run a full node in general.
@_date: 2016-10-13 09:10:30
You basically add a consensus rule that both the mimblewimble extension and the original block must be validated, you can then move UTXO's between the original part of the block and the mimblewimble part(I may have messed up some of the details but this is my current understanding of one way it could be implemented).
@_date: 2016-07-24 11:45:33
That proposal is very dangerous as it effectively removes the limit and gives miners complete control over block size.
@_date: 2017-06-07 00:58:09
I have another [proposal]( that changes that.
@_date: 2018-12-07 07:06:22


This is a vulnerability in the wallet side not the merchant side.


This opens up new attack vectors most likely to be exploitable for things such as OTC transactions.


That would happen during this step:
`4. (Server) Verifies invoice exists and is still accepting payments, responds with payment request`
@_date: 2016-07-12 07:09:15
This so called "security researcher" gets a lot of facts wrong. First of all it is well known that Antminers should never be directly exposed to the internet as they are not hardened systems.


He states he is running an S5 here.


Yet then says they run OpenWRT. Only the S1 S3 and R1 run OpenWRT, the S5 and S7 however run a variant of Angstrom Linux.


Most farm operators don't ever change the default passwords and just firewall the miners off.


This is clearly intentional so that farm automation systems can automatically read cgminer stats from miners.


Guess he also hasn't realized that /etc/init.d/cgminer.sh is read only and any changes to it get erased when you reboot. These filepaths are what the Angstrom Linux based Antminers use not the OpenWRT ones.


Yes, they are obviously designed to run behind a firewall/NAT just as almost all networks they are used on are configured.


The S5 does not use LuCi as it does not run OpenWRT, its web interface is basically just a set of cgi scripts. These issues he mentions are generally all well known and are configured that way for the convenience of farm operators so that they can more easily control miners.
@_date: 2017-06-04 08:21:07
Why isn't there a segwit witness commitment OP_RETURN? You generation transaction also looks to have an invalid address version so any blocks mined will probably be rejected. Have you tested on testnet at all that you can actually mine valid segwit blocks? Edit: I've confirmed the stratum server is not capable of mining segwit blocks.
    {
        "txid": "89aac31510ccf6f7bc1463cd3ccee8f718bb66b9b3c337043358355446d5c299",
        "hash": "89aac31510ccf6f7bc1463cd3ccee8f718bb66b9b3c337043358355446d5c299",
        "version": 536870914,
        "locktime": 0,
        "vin": [
            {
                "coinbase": "03aa2a0703f4d516082000000b000000000d2f436f696e69756d536572762f",
                "sequence": 0
            }
        ],
        "vout": [
            {
                "value": 15.79315231,
                "n": 0,
                "scriptPubKey": {
                    "asm": "OP_DUP OP_HASH160 87502ed9634398262922403e43635392d004c6d4 OP_EQUALVERIFY OP_CHECKSIG",
                    "hex": "76a91487502ed9634398262922403e43635392d004c6d488ac",
                    "reqSigs": 1,
                    "type": "pubkeyhash",
                    "addresses": [
                        "1DLUH7NpWmTLM34Fz477wfLhWXVovKMMTu"
                    ]
                }
            }, 
            {
                "value": 0.00,
                "n": 1,
                "scriptPubKey": {
                    "asm": "OP_DUP OP_HASH160 81a74ec2ce0f8c0e9269b033d2f3548b2e633e30 OP_EQUALVERIFY OP_CHECKSIG",
                    "hex": "76a91481a74ec2ce0f8c0e9269b033d2f3548b2e633e3088ac",
                    "reqSigs": 1,
                    "type": "pubkeyhash",
                    "addresses": [
                        "1CpYbVCMreNjwBzGx2XSZ9gWJjTjsvv4i7"
                    ]
                }
            }
        ],
        "hex": "02000020010000000000000000000000000000000000000000000000000000000000000000ffffffff1f03aa2a0703f4d516082000000b000000000d2f436f696e69756d536572762f00000000021f70225e000000001976a91487502ed9634398262922403e43635392d004c6d488ac00000000000000001976a91481a74ec2ce0f8c0e9269b033d2f3548b2e633e3088ac00000000"
    }
@_date: 2018-12-07 05:43:45
The original has a security vulnerability in it, my change fixes that.
@_date: 2017-06-04 08:47:47
Don't buy hashpower if you can't control which pool it mines to.
@_date: 2017-06-07 01:30:48
This is BIP148 compatible, it potentially makes BIP148 safer though.
@_date: 2018-12-07 20:14:51


I think the real reason is quite obvious, it's not to solve customer issues it's to reduce customer support costs for BitPay.


I don't see any stats on what percentage of issued invoices successfully get paid, I only see the percentage of paid invoices with errors, I would expect the percentage of paid invoices vs total issued invoices to have significantly dropped due to BIP70 usability issues and lack of wallet support. We have a case of "Lies, damned lies, and statistics" here.
There are also unfixed security vulnerabilities in many BIP70 implementations, including BitPay's wallet implementations which I have reported, BIP70 has long been on a deprecation track due to serious technical design issues that impact security.
@_date: 2018-12-07 01:43:11
Here's one option for a decoder that can be run locally  You can also use curl as described [here](