@_author: adam3us
@_date: 2016-08-23 13:02:32
It is like the bank note forgery detectors in shops.  By the self-interested act of a subset of economic actors checking the payments they receive for forgery using full nodes, they help secure and deter attacks on SPV nodes.
However a full node that you do not use for transactions adds limited value - there are already plenty of nodes for transaction volume.  A zombie node which you do not depend on for value is also likely to be unsecured, not frequently updated etc.  Users would really want if there was a way to detect to get their information from economic full-nodes - ones where the operator has an aligned interest to secure and maintain the node.
So I would say a full node that you do use for your own transaction validation that is only online even 5% of the time is infinitely more valuable than an always on node that you do not personally rely on for transaction validation at all.  In particular one person or company running multiple not personally used nodes in cloud services is not useful to network security.  It may even be a net negative for security because users accidentally connect to them because there are many of them, rather than the more useful full nodes run by people who are checking their own transactions against them.
@_date: 2016-08-24 14:37:24
MAST (merkelized abstract syntax trees) also help make the type of contract used more ambiguous.  For example lets say normally a 2 of X multisig is used with optionally some alternative mechanism in case of disaster recovery.  With MAST used appropriately you would not be able to distinguish between single signer payment, 2 of 3, 2 of 2 nor the locktime params if any because the contract would be a schnorr pubkey hash (being the addition of the two keys) and would look like sig with &lt;pubkey&gt; OR [undisclosed] in normal usage.
@_date: 2016-04-06 11:00:58
Maybe 5.  Blockchain.info has thunder network also.
@_date: 2016-04-03 10:14:32
Not quite.  Creating change on average is about 4x cheaper than cleaning it up, that is where the discount comes from the level the playing field and make it cost the same, so we dont have bloat.
This is because spending includes signature/witness data which is much bigger than the P2SH used by most outputs for creating change.
@_date: 2016-04-02 17:38:47
the minimum requirements are that you have to reveal the whole program except the parts that can be shown the program will still return true even if they are omitted. so if the top leve of the program is OR(a,b,c) then I only need to show sub-script b and I can omit a and c. To omit parts I have to show their hashes so that the recipient can still confirm the script is as committed in the root merkle hash.


If you use the (sig(A) and sig(B)) or MAST(script) model you dont have to reveal the script at all unless one party goes offline permanently.
In the BIP Johnson Lau gives a few example usecase programs: 
@_date: 2016-04-02 18:14:36
The Bitcoin script model is if you can provide inputs that cause the script to return true, you can take the outputs.  
XOR(a,b) would not work so well because short-circuit execution doesnt work on XOR - if we proved a returns true then we still dont know if XOR returns true as we need to know if sub script b returns true also.
But script could be pretty arbitrarily extended by the segwit script extension mechanism, to add even a whole new script language.
@_date: 2016-04-22 22:26:07
Emin Sirer has a go at explaining this surprisingly widespread misconception also 
@_date: 2016-04-03 13:17:40
as u/nullc explained


the 1/4 is to remove the negative externality and is the ratio calculated empirically from the above data points and blockchain data to approximately balance things so using change is about the same cost as creating spurious new change.
@_date: 2016-04-14 20:04:11
True on the patent timing.  Unknown on the Satoshi selection - I'm not sure if he ever commented on it, maybe he didnt know about it - ECDSA is much more widely used. (ECDSA itself came after Schnorr and is a kind of copy of it but changed in a few ways, generally regarded as an NSA tweaked but more complex version of Schnorr, suspected to have been motivated by the US government avoiding buying the patent from Prof Schnorr).  Note Daniel Bernstein (DJB)'s EdDSA is in fact Schnorr despite the name.  Anyway the Schnorr patent has expired now.
@_date: 2016-04-14 19:29:08
30% of the transaction size saving comes from signing inputs on your own transactions, so no communicating with participants required there. 
41% (a bit more) comes from doing coinjoin also.
@_date: 2016-04-01 19:53:08
Would allow use of huge programs where only one path needs to be shown, the only limit is how much time it takes to merkle hash the parse tree (assuming only a small part must be revealed to demonstrate program returns true).  That might be useful in allowing some bigger and more interesting scripts.
Also it adds privacy only reveal what is needed.
Generally saves space for non-trivial programs, conserving on-chain space, improving scaling for those types of transactions.
@_date: 2016-04-03 09:49:42
see 
@_date: 2016-04-03 09:45:16
An SPV upgrade is an SPV upgrade, there will definitionally exist some bit string a miner could mine to convince a not-yet-upgraded client he received money that is fake.  However it is possible and I think 0.13? will introduce warnings that a client is interpreting according to an old protocol version. That could be made into a safe mode so you have to override it to proceed.
This is the way you should be using SPV upgrades - a miner based safety net for people who do not upgrade in a timely way, or while they upgrade.
It is good to re-examine things to see if they could be improved in a planned way but Satoshi invented SPV upgrades and it is the way all upgrades todate have worked.  Now is not the time to be exploring different upgrade mechanisms.
@_date: 2016-04-03 10:11:05


I see the source of this confusion: sidechain elements alpha had just implemented the hard-fork version of segwit back in june 2015.  It is not to enable sidechains it is rather that it was tested and proven first in side-chains as they allow more rapid experimentation and malleability was a known problem people have long been looking for robust fixes for!


Dont really understand that.  Segwit transactions are forwards and backwards compatible.


Well technically most people are using transactions via some library and most libraries by now have segwit support already see  
But yes they do have to upgrade a library and maybe generate a new style address to benefit.  But they can also upgrade the library and get scale by doing nothing further because people who do upgrade move the 60% of their transaction which is signature/witness data to the witness area, thereby creating free space in the 1MB block for people who have not yet upgraded.  They can upgrade to segwit transactions at their leisure though their transactions will cost a little more than people who did not upgrade.
The alternative of a hard-fork has been oversold in its simplicity it involves work arounds for n^2 hashing problem that segwit has robust solution for, and not yet conducted security and upgrade testing.  It will take much much longer to achieve a hard-fork.  This is why people were excited to discover they could soft-fork segwit, initially it also was planned as a hard-fork.
@_date: 2016-04-03 13:11:27
False.  See 
@_date: 2016-04-22 11:20:47
anyone up for a kickstarter including companies?
@_date: 2016-04-26 17:33:51
You are misunderstanding the balance in Bitcoin it is a p2p user currency, it is the users economic decisions that enforce bitcoin's properties via economically dependent full-nodes. Here's Emin Sirer's blog explainer 
@_date: 2018-01-25 17:25:49
schnorr can be used to aggregate unrelated signatures, see   "interactive ones are trivial to construct: take a multi-signature scheme and have every participant sign the concatenation of all messages." note the multi-signature is interactive, as shown in the blog post.
@_date: 2016-04-01 19:42:59
rather a bit more than that - sets up channels, exchanges transactions, and if you listen to the walk through of the test mode it exercises a number of other mechanisms also.
@_date: 2016-04-03 09:49:12
Yes it takes more bytes to spend a transaction than to split a transaction because input consumption includes signatures (witness data) and outputs typically contain only P2SH which is compact.  So the discount balances those input consumption bytes and output creation bytes so there is no longer a financial incentive to create dust.  To be sure if you run out of coins your wallet will use change, but until then it will keep splitting coins.  Say you have 100 1BTC lumps in your wallet for privacy, and you make 100 &lt; 1BTC payment your wallet will correctly minimise fees by splitting all 1BTC payments and creating 100 change coins.  That is bad for UTXO bloat.  With the incentive fix depending on what amounts you're paying the UTXO bloat will be much smaller.  A negative economic externality is saying someone else, or everyone is paying for your actions because you are not exposed to their cost.  That is what is happening today with change.
@_date: 2016-04-01 19:45:50
That should change soon with the merge a few days of CSV into bitcoin ready for soft-fork activation and the progress on segregated witness implementation on it's (expected) last testnet version segnet4.  Those are the two last things needed to run lightning live and proper.  (Actually you can run lightning without CSV it is just more efficient as transactions can recirculate indefinitely rather than needing to be refreshed on chain periodically).
@_date: 2016-04-03 12:57:41


Well part of the reason sidechains enable rapid experimentation is you can use a new chain without $7B value resting on it.  Secondly it is easier to ignore backwards compatibility - as it was a brand new empty chain it had nothing to be backwards compatible to.  So it wasnt even so much a hard-fork as a clean slate new chain if that makes sense.  The same sidechain has only Schnorr sigs - no support for ECDSA at all, just replace the thing and do it right with 20 20 hindsight is way easier than hard or soft fork!  Thirdly the discovery that you could soft-fork segwit was not made until much later in 2015, maybe sept or october by u/luke-jr so no one had noticed that possibility either.


Segwit was originally planned for mainnet as a hard-fork.  Soft-forkabiltiy discovered after all of this.


That's normal and how all soft-fork upgrades work.  That doesnt mean they should not upgrade!  People should upgrade and the more money involved the faster.  But they are protected during upgrade by miners.


I believe they are indicating they are working on it and aim to have segwit support integrated and tested before segwit itself activates.


I agree it is not as simple, but it has been made as simple as possible for them for free by other people.  Many businesses are also rightly complaining of operational issues from malleability.  We need segwit anyway for malleability fixes.  If we were to say there must be no further code changes ever, we'll have a really big problem improving Bitcoin scale or features.  I think people need to work together and be willing to upgrade code as a cost of fast paced innovation.  The backwards compatibility, security record and testing level is fantastic compared to any other rapid paced technology.  Not really a lot to complain about in my opinion.
@_date: 2016-04-14 19:29:32
that is where most of the saving comes from yes.
@_date: 2016-04-07 14:53:58




I made an allegory over the new years holiday period a year back (posted Jan 2015) to try give some intuition for why this might be. You might like it 
@_date: 2016-04-03 20:13:11
Johnson Lau gives some motivation and example programs in the BIP.
@_date: 2016-04-01 19:41:31
MAST = merkelised abstract syntax tree, which uses the idea that you can commit just the root hash of the merkletree committing to the syntax tree of a script.  Because with short-circuit boolean OR execution you do not need to execute past one true you can effectively reveal just the short-circuit path used to claim the coins.  The other conditions can be never revealed.  That improves privacy and reduces on-chain bandwidth usage for complex scripts.
It also allows the idiom of only even revealing the script-proper at all in event the two parties to a contract are no longer both around to execute it with (sig(A) and sig(B)) or MAST(script) where if both parties are online they can mutually agree to execute the transaction as dictated by a complex script, there is no point forcing blockchain execution because the execution is deterministic so both parties are certain how it will be interpreted.
@_date: 2016-04-10 16:52:09


Joseph Poon is saying summer 2016 I saw.
Everything needed for Lightning is in the upcoming release with CLTV (already in bitcoin 0.12) and CSV (in 0.12.1) and segwit (in 0.12.2 upcoming).  Lightning is currently being tested on segnet4, the last expected testnet version for segwit.
@_date: 2016-04-03 10:14:02
No this is incorrect the discount is to fix the negative externality.  Lightning does not need discount as it can already get 100s to 1000s of transactions for the price of one, it can happily pay 10x fees and still be a strong cost saving for micropayments transactions.
@_date: 2016-04-14 20:04:44
It is also easier to blind Schnorr signatures than ECDSA ones.  Also handy for privacy things like coinJoin.
@_date: 2016-04-10 15:42:05
Maybe also 1.5x-2x throughput from aggregated schnorr signatures which can be soft-forked as a segwit based script upgrade.  
that means transactions become 2/3 to 1/2 the size and we get 1.5x-2x throughput out of 2MB of effective blocksize.  Technically that is an improvement in scalability where other changes are more just an increase in scale.
@_date: 2018-01-23 19:50:31
BTC recirculates in the lightning network. exchanges join also to provide topups, and then when users buy more BTC they withdraw it by the pizza shop being paid to send the users own bitcoin back to them on the existing channel (and the shop cashes out to usd to buy more dough etc).
@_date: 2018-01-17 08:56:06
i think lightning is a bit more directed to keeping bitcoin also. the third party payment processors tend to wire you a USD payment end of day, so you dont even have to see bitcoin. a real bitcoin-bitcoin economy drives value better I think, where the merchant keeps some bitcoin.
@_date: 2016-04-10 15:48:15
there are some explainers and papers on above page but see also
@_date: 2016-04-14 20:38:01
Nothing but advantages.
@_date: 2018-01-17 08:49:53
the mugs are real btw 
but so far not offered for sale, they were just internal swag.
@_date: 2016-04-02 13:18:52
Simple: soft-fork a difficulty increase leading up to the halvening and then drop the difficulty increase immediately after.  Miners can do this all by themselves with no assistance from anyone because it is a soft-fork that only they care about.  u/petertodd could probably implement it for them for a weeks work including testing.
@_date: 2016-04-03 00:00:16
It is only an upgrade mechanism, and same upgrade mechanism used for all planned upgrades in bitcoin ever. You dont have to use segwit transactions, it is recommended you upgrade fullnodes quickly, but until you do miners will protect you same as with any other upgrade.
@_date: 2018-01-19 08:23:07
@_date: 2016-04-01 19:54:42
Maybe the down-vote bot is still operational.  Have a hard time seeing a legitimate reason to down-vote a politically neutral explanation of what MAST is and what interesting things you can use if for.
@_date: 2018-01-04 09:01:00
let's do it
@_date: 2016-04-02 23:54:34
The discount is to remove a negative economic externality that is causing wallets to manage change in ways that result in UTXO dust build up.  UTXO size is itself a scaling issue, so this is an important and useful change.  The discount ensures that it is approximately same cost to use change as to create new change.
@_date: 2016-04-02 00:25:44
there are more advanced nice-to-have questions being worked out but I dont see any blockers - I mean a few different implementations have various levels of it working in pre-alpha already.  probably we can improve on the idea to given time also.
@_date: 2016-04-03 12:58:39
I believe they are indicating they are working on it and aim to have segwit support integrated and tested before segwit itself activates.
Also I think from watching the update messages that it is probably out of date.
@_date: 2016-04-21 20:00:54
slides 
@_date: 2018-01-17 08:39:22
just buy more first before spending. buy a few extra even.
need a few retail exchanges to support LN topups. let us know if you're an exchange and interested to set it up.
@_date: 2018-01-17 08:40:31
notice it's be your own payment processor too - no arbitrary policy from bitcoin payment processor it's your store, you take direct payment.
@_date: 2018-01-19 08:14:15
CT/bulletproofs on bitcoin would be my vote :) more fungibility is important.
@_date: 2018-01-17 03:32:33
see also mega thread on lightning setup 
@_date: 2016-04-16 11:11:38
If we assume both chains support lightning (either by both being based on 0.12.2 release of bitcoin) or by having equivalent support, then so long as hashlock contracts are compatible, even if the chains were different format, I think fast crosschain Lightning based atomicswap should work.
@_date: 2018-01-20 19:58:26
some validity I would say. bitcoin also has a lot of imperfection in terms of fungibility that is why people are interested in Confidential Transactions/bullet proofs, Schnorr sigs, MAST, scriptless scripts, discrete log contracts etc.
but bear in mind this is lightning 1.0 spec. first deploy, then improve - there are a range of ideas to reduce these correlations, and somethings are limited by what Bitcoin itself can do. so once schnorr is available on bitcoin some things improve. if/when CT is available on bitcoin some more things improve. and the HTLC hash pre-image correlation is crypto fixable too I think, in a later version. in principle you could pay hops to fund and establish channels also to generalise the connectivity (though AFAIK that is not currently a feature).
there are other things that need to come also, like splice out (to pay a non-LN user from an LN channel) and splice in (to increase a channel balance with funds from a non-LN user) to increase backwards compatibility and make things more opt-in.
plus stability/security fixes at implementation level. 
@_date: 2016-04-21 21:31:39
types at 200wpm or something :) During scaling bitcoin in Montreal he had typed and uploaded speakers transcript before they sat down form their talk.
@_date: 2018-01-24 01:08:45
cool. I hope we can expect 50c bitcoin rap songs soon :)
@_date: 2018-01-24 15:59:58
I think people are a bit hesitant to do that, because it discounts and therefore encourages address reuse which is bad for privacy, fungibility and quantum resistance.
@_date: 2018-01-05 17:57:30
They could in my opinion. There is a funding page but it's a contact and ask not a donate to this address type of page: 
Maybe they could be asked to put up and manage a multisig wallet for direct donations.
@_date: 2018-01-23 23:45:55
He has debts of $32mil on assets of $25m, and $7m of the debts are a court finding against him.
I wonder if the BTC will get disputed as part of that and how that would play out.
@_date: 2018-01-24 16:01:03
they like new or first things typically, more than optimising existing things. it's because of the publication criteria.
@_date: 2018-01-23 13:11:56
Actually see  in a real-time mix net we argue that you would only need to control the entry and exit.  Also we argue you can control the route, by exhausting capacity, which tor like systems given you everything you need as a regular user.
For lightning version1 it also has the HTLC preimage which is correlated through the route.
That is fixable in a revised version using schnorr (decorrelated schnorr signature based HTLC).
You can also probe route capacity with lightning.
And another thing you can do to gain visibility as a well funded adversary is to provide a lot of cheap liquidity to the network.
Anyway despite the limitations it is clearly higher fungibility and privacy, plus being more scalable vs on-chain transactions, and there are multiple paths to better privacy and fungibility in later versions.
On-chain dependencies that would improve privacy and fungibility further are schnorr sigs, and maybe longer term, confidential transactions.
Users can help also by providing cheap low fee user liquidity to route payments with privacy.
@_date: 2018-01-27 12:46:29
never gets boring watching unfairly cheap and fast transactions zip around :)
@_date: 2019-07-29 22:00:02
that could be a good thing. retail on lightning increasingly, and traders on Liquid. IMO it is often the traders who pay the premiums and push fees up. note cold storage is best on main-chain, but at least the exchange to exchange arbitrage bitcoin transfers don't need to go on main chain with Liquid (and don't gain from doing so either, so no loss of assurance for moving from one custody exchange to another).
@_date: 2019-07-31 11:39:55
car needs to be one of these landrover defender for citadel era use  kind of vehicle that keeps trucking 50 years after manufacture. can get with EMP proof ignition options.
@_date: 2019-07-06 01:51:00
confidential torch request 
@_date: 2019-07-06 13:23:06
document on how to obtain L-BTC  see also 
@_date: 2019-07-29 16:41:03
check out the liquid user to user OTC swap tool  (linux, mac, windows binaries and source). trustless* atomic swap (*modulo issuer risk)
@_date: 2017-12-10 22:03:48
changetip used to work this way, and was used for among other things tipping on reddit.
@_date: 2017-12-28 00:12:28
Ok sorry I didn't read fully to see that. The idea is the first point to convey for others to understand, yes.
@_date: 2019-07-06 01:40:46
if you want to try Confidential Transactions :) green wallet now supports liquid L-BTC and liquid assets. thanks to hard work of  green wallet team over the last months. you can also look at L-BTC transactions on   (tho you can't see values etc)
there are telegram groups: Liquid Community  and  Green Community  &amp; developer / slack discussion on bitcoin core slack  / IRC  for people who want to compare notes, swap BTC for L-BTC 
see also the blockstream block-explorer liquid network view:  ofc most of it is encrypted due to Confidential Transactions.
@_date: 2017-12-11 19:50:11
skip that - go straight to bits. 1.7c/bit or $0.017/bit
@_date: 2017-12-27 22:35:18
cool. you can do more compact and multi-denomination ecash with brands' protocol  which works in RSA or Discrete Log (Including ECDL and Bitcoin's curve).  It's very similar to the pedersen commitment in confidential transactions.  Should be faster, smaller - having multiple denominations is nice also.
Using range proofs you could also have the server combine and split coins with value privacy I think.
Also should work with threshold of signers using the key tree sig like model.
@_date: 2017-12-26 01:53:24
The hodl urge is strong (even pre-bitcoin tendency) so I have trouble selling Bitcoin, never sold one, so I don't really have house money. It feels more like committed investment if you're not selling parts. Hodl to the hyperbitcoinization, when there will be nothing left to sell for :)
But I can see that it can be a reasonable strategy for some people to sell 5% after a 10x climb.  Your position wont be *that* different.
I do some dip buying with a USD allocation, which I sell back to USD and keep profits in BTC to hodl. And occasional fork shorting, fork dumping etc which I kept as BTC hodlings.
@_date: 2017-12-27 09:17:52
I find it's best to buy Bitcoin some months  in advance of giving it to people, so they are like 50-100% in the money. Then tell them the purchase cost, and that it's volatile but HODL like you did before giving it to them.
@_date: 2017-12-27 09:48:48
that dip buying is looking good now :)
@_date: 2015-12-15 09:17:54
one can have fungibility without anonymity and various social norms in between.  See 
@_date: 2015-12-07 05:31:00
The positive outcome is to increase the effective block-size to around 4MB in a soft-fork which can be more safely and rapidly deployed on the network than hard-fork proposals.
@_date: 2015-12-12 17:23:52


Same as other soft-forks, it accepts it but has a simplified understanding.  Basically a non-updated node accepts soft-fork changes because they look like OP_TRUE (anyone can spend) and that they are the lucky beneficiary of this.  In reality that are some parameters that old nodes are ignoring that specify the information that upgraded nodes and miners are enforcing.
After a bit most nodes upgrade anyway, soft-forks mostly help in having a more forgiving upgrade time-frame and roll-out plan.  For sure miners upgrade after triggering at 95% because the 5% who do not upgrade at that point risk losing money if they mine no longer valid blocks (eg spending OP_TRUE transactions that are not really OP_TRUEs but new version features).
@_date: 2015-12-15 12:24:27
I think if you organise things correctly as Roastbeef pointed out, you can put the fee cost on the defaulting node, not the user doing the reclaim.  Just need to ensure always more funds left in the channel owed to the node, than the cost of a reclaim transaction fee.
@_date: 2015-12-01 02:05:14
Watch and learn :)  There is some clever stuff that has been implemented and proposed.  Some of it is not public yet.
@_date: 2018-09-30 12:29:04
@_date: 2015-12-07 06:13:31
Yes, the way that would be done in two stages.  First the seg-witness soft-fork, and then later a hard-fork for block-size increase.  mentions this on his summary slide from the presentation 
@_date: 2015-12-07 06:14:19
Yup, really pulled a rabbit of the hat with that.
@_date: 2015-12-31 20:41:54
@_date: 2015-12-19 12:46:43
what was your proposal in summary?  (Or in detail - you could post it in a new thread even) and link here?
@_date: 2017-12-10 03:33:35
Yes is great. He was asking a question that came from online - twitter or irc? But it is a fair question.
There are multiple sites where you deposit bitcoin then reduce your bitcoin balance as you spend.
@_date: 2015-12-31 16:54:49
suggest reading the FAQ 
@_date: 2015-06-13 09:46:03
actually the level db bug was fixed by soft-fork not hard-fork.  we have never had a hard-fork (except in early alpha days apparently when Satoshi was hacking on stuff more free form and there were hardly any users and no exchanges nor listed price.)
@_date: 2015-12-31 00:41:16
a firm soft fork is not opt-in where an extension block is opt-in.
@_date: 2015-12-16 23:22:19
You can choose the fee at time of channel reclaim (funded by the defaulting parties channel-bound funds).
@_date: 2015-12-31 01:52:51
I consider extension-blocks somewhat complex also.  But maybe the complexity is being overestimated - some have even claimed extension-blocks are simpler than segregated-witness. Segregated-witness itself could be viewed as a kind of extension-block.  Hypothetically it is maybe a not too far fetched evolution from segregated-witness with witness data in extension-area towards extension-block with entire transactions in the extension area.
@_date: 2015-06-28 12:31:06


Bitcoin block-size is limited, inherently; its a fact of physics and the light-cone of information dispersion and latency, if nothing else.  But more immediate:
- ratio between block propagation delay and block interval, if it gets too low, orphan rates shoot up and things fail; some alt-coins have failed in this way, it's a real thing.
- we can improve that with IBLT that's why and are working on them.  And why implemented the relay network which most of the hashrate is using today.  Really we need an integrated version of that and analysis of it's decentralisation and DoS resistance properties before we assume it, but its great and practically useful today.
- note IBLT is not a free lunch, there is a weak homogenising force which could be argued is a weak force for censorship to follow the views of nodes you are connected with to avoid delay penalty.
- Bitcoin depends on decentralisation for it's properties.
- SPV security depends on a sufficient weight of the economic activity in the network being validated by full nodes.
- we can improve decentralisation, which is artificially centralised by improving pool protocols.  People are working on that.
- we can improve throughput within safety margins set by decentralisation improvements, bandwidth improvements and block transfer latency improvements (IBLT etc)
@_date: 2015-12-15 18:32:23
No.  (Not as far as I know).
@_date: 2015-12-07 01:47:25
normally the transactionID is the hash of the signature and the transaction.  With segregated witness, the transactionID is the hash of the transaction only (excludes the signatures).  As the signatures are the malleable part, that fixes malleability in a simple and robust way.
Because signatures are also a big part of the data consumed in a block, particularly with multi-sig use, which is increasing; he also is able to get an effective block-size increase as a soft-fork by not counting the signature data in the block-size for seg-witness enabled transactions.
@_date: 2015-12-06 22:29:21
Wide agreement that one of the new BIPs is the obvious next step.
Looking forward to BIP presentations which all happen today.
@_date: 2015-12-01 11:42:44
Censorship is bad.  


This is why I would say even moderation is not a great idea - it invites finding moderators kryptonite to convert moderation into censorship.  Even happened temporarily to the cypherpunks list - that is exactly what happened there (cypherpunks censorship event, which created much controversy at the time):
1. increasingly bad signal to noise ratio.
2. calls for moderation to remove spam some of which likely systematic attempt to disrupt list objectives. 
3. moderation added, but objective as anti-spam only.
4. moderators kryptonite found by someone (probably same people as systematic attackers in 2).  lookup the details, some clever triggering of legal conflict of interest for moderator, who felt legally bound to censor the post in question.
I think in Bitcoin we have a bit of Streisand effect mixed in so not exactly the same.  But as they say those who dont know history are doomed to repeat it.
@_date: 2015-12-31 18:14:51
draft BIP 
@_date: 2015-12-31 22:19:02


I think we need to get rid of off-chain transactions because they are insecure and/or forfeit self-custody, by replacing 3rd party custody models with self-custody and trustless custodian (2 of 2 plus timelock like greenAddress). This requires lots of on-chain scale because most of the bitcoin exchange transactions are off-chain and are collectively much higher volume than bitcoin on-chain transactions.  I view lightning as on-chain because they are cached cut-through Bitcoin transactions and may actually increase on-chain fees because they increase scale a lot (a lot more cheap transactions can result in cheaper fees and more fees).  But either way we need more on-chain scale because Lightning itself uses on-chain space.  Note sudden excess capacity can reduce total fees due to supply and demand - why pay more than minimum if some miner will take minimum or zero with an eye to driving future value, fee-estimation will automate that effect even, much fee pressure is from defaults in old non-fee-estimation aware clients and services that are overpaying  Side-chains are more about opt-in extensibility than scale.  Side-chain elements also uses pegged Bitcoin as a fee currency which creates new fee opportunities for miners once merge-mining is added (most miners seemed pretty enthusiastic about merge-mining side-chains to provide security services to bitcoin 2.0 stuff).  
Bitcoin *is* tokenised security fees and all financial transactions need security - the main innovation of Bitcoin comes from automating trust and security.
And yes the time-locked bitcoin (plus early adopter/miner or later investor status of many founders &amp; employees).  We setup incentive program to align new people with Bitcoin in case they had no bitcoin because we view the company interests as aligned and need a strong, secure and scalable Bitcoin.  We certainly put more development hours into improving Bitcoin core than any other company.
@_date: 2015-06-13 09:17:34
No all extended blocks are also 1Mb blocks, because an extended block hangs off a 1MB block, the 1MB block must always be there - even if it became less used, just with fewer transactions in it.
I am thinking people would value 1MB transactions more because they are more decentralisation secure so for long term storage etc and big transactions I think people would be willing to pay a higher transaction fee to get it into the 1MB block.
@_date: 2015-06-27 23:24:40


If you do that and rely on transactions in it, you will lose money.  If it's your money that's your prerogative.  Encouraging a bunch of other people to do it will cause them to lose money also, and is ethically questionable to my mind.  When they lose money, they may attack you legally, or even physically possibly.
Going and persuading a lot of people to do it is reckless.  It may lose everyone money if the entire ledger is corrupt.
It's not that anyone can coerce you into not doing it, it's just that its self-sabotaging and at scale actively dangerous for the entire network.  Bitcoin assumes via mutual assured destruction logic they people would not do it.
What do you think will happen if 30% of the economic interest is on 8MB blocks and 70% is on say 2MB blocks growing more slowly and neither side agrees that it should give in to coercion?  It's not going to be pretty.   That's playing chicken with $3b of other people's money.
I guess a return question for you is why would you, or anyone, want to vandalise and try to destroy Bitcoin, when they could collaborate and try to make it better?
@_date: 2015-12-12 17:45:20
I am not being specific, there are a few different ways to do a soft-fork, and one of the features of segregated witness is a simpler way to introduce more soft-forks.
@_date: 2015-12-07 03:41:52
Agreed.  But crucially it is *soft-forkable* which is simpler and safer to more immediately deploy.  See comments from the transcript: 


@_date: 2015-12-11 03:18:45
I dont think quantum computers are any kind of near-term threat as they first have to build them with a useful number of qubits and keep them stable and error rates down to actually be able to compute anything meaningful.  We dont know how many decades that will take or even if it's physically possible or if their are physics limitations that mean it will never happen.  Lots of open questions and decades away from being a threat to anything in the cryptography domain is my view.
Anyway even if they surprise on the upside, it is relatively straightforward to defend against with post quantum crypto algorithms which Bitcoin can adopt in plenty of time.
@_date: 2015-12-09 22:46:56
generally speaking a soft-fork will be rolled out faster than hard-fork for a number of reasons.  lower risk, less need for coordinated upgrade, many have been done before so there is confidence and practice in the process etc.
@_date: 2015-12-19 11:26:19
It's likely to be a bigger impact later.  Generally economic inputs should move gradually (either up or down) is Rusty's point.
@_date: 2015-12-01 14:01:56
Who's going?  I believe 150 or more which is probably the biggest part of the tech community (if it was like the Montreal workshop)  I am going to be there.
@_date: 2015-06-13 11:00:36
I can guarantee that yes I would feel the same way.  
I feel the risk to Bitcoins continued existence from the apparent media popularity of Gavin's contentious hard fork, and the decentralisation security risks from other proposals are really important to handle correctly or we risk Bitcoin ending up being not Bitcoin via centralisation mid-term, or worse diverged and broken ledger if the contentious hard-fork threat were to go live and end badly.
ps I'm not sure if its clear but with a pure business hat on it would probably be in my interests to stay out of this debate.  Consider also the soft-fork for side-chains in the future, which I think are in Bitcoins interests to support faster innovation.  You can guarantee people will throw up that I spoke up about the hard-fork to argue that they should argue against an OP-2WP soft-fork.
@_date: 2015-06-29 22:55:46
Well it's a question of scale right.  If those transactions couldn't possibly fit on a decentralised blockchain anyway, bitcoin miners would not have received those fees.
If each on-chain anchor transaction facilitates 1000s, or 10,000s of layer 2 transactions, the fee can afford to be higher.  How to do that and avoid individuals personally paying the high fee is a little more subtle but I think can be done to even out the cost.  Insurance for example is commonly used to make for rare but expensive unpredictable outcomes inexpensive and predictable.
@_date: 2015-12-31 21:37:29
Yes that is the way both segregated-witness and normalised tx-id fix malleability: they exclude the signature (witness) from the transaction-id hash calculation. I doubt it was a new idea even then, because and an army of other bitcoin wizards created a nearly comprehensive prior art database on bitcointalk, but I proposed something like this on bitcoin-wizards in 2013 along the lines of fixing malleability by "excluding or replacing with fixed data the mutable signature part". Segregated-witness does a lot more clever things also.
@_date: 2015-06-16 01:14:06
Indeed.  Well as likes to say "bitcoin is anti-fragile".
This is what anti-fragile looks like on the inside, people spot attacks, and figure out how to defend against them.  Presuming that this unilateral hard-fork fails, people will know more about the governance system and watch out for signs of such abuses of process in the future.  Right now, what I was actually trying to explain, is why those defences are there as people do not even seem to understand what makes the system secure, and while they say the price for security is eternal vigilance, people like company CTOs and CEOs and the public cant be vigilant if they dont know what to look for.
Most seem to say "great fork it, whats the problem".  I try to explain in full detail exactly what the problem is and people still say "great fork, whats the problem".  Puzzling.  Maybe more PR or sound bites are needed. 
No offence, and your comment is astute of the issue, but it's curious how very few people on reddit seem to have drawn any particular information from how ever many thousand words of detailed explanation.
@_date: 2015-06-28 10:52:47


Well I took the time to explain the technical reasons why it's true.  Your comment doesn't seem to seek to refute any of the rationale given.


Note we dont need more full nodes for scaling, a handful of full nodes (and we have 6000 or something) can satisfy all current SPV volume.  We need more *economically dependent* full nodes that make economic decisions based on what their own full node tells them.
You didnt cite what post you were referring to.  I have seen him before argue it would be nice if we could pay full nodes for service to SPV nodes.  That could be interesting - probably we need lightning to make that scale however.  (Otherwise to pay them creates more on chain traffic).  Anyway it doesnt seem like the current priority given other things to improve.  Better use of time to make lightning work for example to enable it.  We'd also have to figure out the perverse incentives, of which there maybe some.
@_date: 2015-06-28 10:36:05


It was Satoshi that put the limit there!  It was also said, I believe in the white paper that fees maybe can grow to replace subsidy over time to secure the network.


You do realise increasing the block-size in an uncontrolled way (eg removing any limit at all which you seem to be a fan of) reduces fee revenue which is the only direct source of "economic incentives that protect Bitcoin" other than subsidy.


I do support scaling now within safety margins.  If you want to scale beyond safety margins there is a way for you to do it: go do it yourself off-chain or in a side-chain.  Seriously go write some code, go get some investors - I'll even tell you how to do it!
@_date: 2015-12-07 05:13:42
added to top.
@_date: 2015-12-31 19:05:25


Segregated-Witness is the way bitcoin should have organised block-chain data in hindsight because it is a clean well designed robust solution to malleability.


No one is arguing against segregated-witness, it is almost universally viewed as a necessary and good idea.
A few people discussed alternative deployment sequences like introducing two forks a soft and a hard in some sequence to deploy segregated-witness.  Anyway Bitcoin Core is moving ahead with the single soft-fork method.
@_date: 2015-06-28 12:21:26


What makes you assume that?  If transactions become cheaper for example, maybe bitcoin tipping transactions go on chain.  Or more exchange transactions.


99% of transactions are already off-chain.  We want to get them on chain so that miners improve security as they are paid more fees, and the users benefit from the security advantages of not relying on custodians.  But on-chain security can also be achieved by lightning - each lightning transaction *is* a valid Bitcoin transaction, that is cached and can be posted to the chain to reclaim funds if a hub goes offline.
People want to scale Bitcoin so more transactions and users can benefit from on-chain security.  It is just that changing a parameter and refusing to contemplate algorithmic improvements is not a sustainable way to do it.
I think we need an FAQ, then we can just refer to Q/A numbers and progress faster.  Too much typing on the same repeated, and wrong assumption based arguments.
@_date: 2015-06-14 09:50:30
Bitcoin miners still collect fees on side-chains. one part of side-chains is enabling new types of transactions, so those aren't displacing bitcoin existing transactions. If you think about it off-chain transactions like those in coinbase, circle, exchanges etc are already 99% of bitcoin transactions collectively - are those causing the main chain to die?  Note they wouldnt fit on the chain because there are too many of them. Lightning is another example, the anchor transactions stay on the chain, but 1000s of transactions per anchor transaction happen off-chain, is that limiting bitcoin?
I think ultimately because bitcoin (and sidechains) are an O(n^2) network we will have off-chain transactions of some kind or other - see eg 


again side-chains just allow different types of transactions, validation of code to back-port to bitcoin, an upgrade mechanism for bitcoin if you like, and a place to try radical new improvements to bitcoin like Confidential Transactions or ZeroCash or ZK-SNARK contracts.
Side-chains are not a proprietary technology, they are open and under the same license and we expect as interest becomes real so there are more bitcoin developers, the same development model as bitcoin.
@_date: 2015-06-27 20:35:30
I am not sure where people are drawing these conclusions.
Read eg 




underway, and education)










@_date: 2015-06-13 09:35:23
No one is in the do-not-increase bitcoin scale side.  But there is a concept of decentralisation security, from which bitcoin achieves all the useful features people care about.  If we push it too far, we *will* lose those features and Bitcoin wont be Bitcoin anymore.  It will be federated paypal 2.0 run by a few large companies.  
See this explanation 
or a bit more hyperbolic for effect, but spelling out more the long term consequences
See eg 
@_date: 2015-06-27 20:02:56
Right, and this is why people who understand the risks say that it's better to collaborate and minimise controversy.  I did tell Gavin privately that even if he wanted to try a unilateral fork, which I think is hugely inadvisable, presuming he would want to succeed the best way for that to happen is for him and everyone to minimise controversy.  It is the controversy itself that makes things higher risk.
@_date: 2015-06-13 11:03:09
No. If you keep using existing client software, everything will work fine for you.  Send to any 1MB or 10MB users, receive from any 1MB and 10MB users.  The same is true for companies.  It can be organically upgraded by users and companies as they prefer.  You can stay on 1MB block indefinitely though you may longer term have higher fees to use the more secure 1MB transaction space.
@_date: 2015-12-31 08:29:16
there is.
@_date: 2015-06-13 10:34:22
Its not merge-mined, but somewhere in the merkle-tree of 1MB block transactions or its header there is a link to a 10MB block of transactions with the same rules and same code (plus small changes to account for the generalisation).
Pools and businesses would upgrade to 10MB block aware bitcoind I would expect.  So if you're pool mining its no different.
If you are running a full-node for your own security as a power-user and didnt have bandwidth for 10MB blocks, you could just opt to always use 1MB transactions.
It would also be possible for a tiny pool to validate 1MB transactions and connect to a bigger pool to delegate validation of 10MB transactions.
@_date: 2015-06-27 23:41:25
I love reddit.  
Dumb posts about changing parameters to silly numbers in ignorance of the tradeoffs involved: 100s of replies.  
Someone actually scaling Bitcoin (literally working on lightning and IBLT stuff): 1 reply.
@_date: 2015-06-28 14:49:14


It sounds attractive as an abstract objective, but...


The miners who want to reduce block-size will be economically locked out from participating.  Where is this back-pressure going to come from?
From users leaving the system and the price falling?
@_date: 2015-06-13 09:52:56
There is a default and sensible way to proceed - work to scale bitcoin by consensus.  Ie try to propose a design - like has done - or like I did with extension blocks and let people figure out when it can be deployed, what has to be fixed first, what we can do to improve decentralisation to make it safe without breaking decentralisation security.  
There is nothing to be gained by controversial hard-forks, that way lies disaster.  To even be proposing it is just damaging bitcoins credibility.  Everyone technical has known for years that a controversial hard-fork is the worst possible scenario.
@_date: 2015-06-23 17:41:38
wrote a crypto explainer document here 
@_date: 2015-06-30 22:27:14
Nice cartoon :)  LoL.  Very topically funny, seriously :)
However block-size is not a free variable - Bitcoin as a system is a balance of factors, interests &amp; incentives.
Change can be in stages, eg simple size increase fork now, fancier stuff later in another fork in a year or two.  Thats what I proposed here earlier today:
I dont have artistic skills, but there has to be a counter cartoon, maybe it's something like with the in flight aircraft analogy: a mob of those dogs outside the cockpit door with a crowbar and a USB stick trying to overpower the flight engineer who wants to know what's on it, and if the plane will crash as a result, because they want to upgrade the flight control system immediately with something they heard about on reddit.  The flight engineer gets hit over the head with the crowbar and his complaints about aircraft systems validation and testing go unheard.  The plane turns into a brick as the engines fail and nearly every one dies.  The surviving dog shrugs and says "huh, I really thought that would work! who knew you need to modify other parameters too!"
@_date: 2015-06-13 12:40:25
It would need a soft-fork rule like 75% or 90% or whatever threshold by hash-rate is aware of the extension block before turning on as with other soft-forks.  Being aware of is not the same as processing transactions in the extension block.  A miner could delegate validation for the 20MB block to a pool.  Or it could construct an empty 20MB block.  
But because its a soft-fork any miner that included an invalid 20MB block in their transaction would get over ruled by the network.
@_date: 2015-06-28 10:41:33
Well they seem to be in ignorance of just about everything relevant!
- falsely claim that people dont want to scale bitcoin
- falsely accuse people of saying "no" and not working on scaling (eg people as and who spent maybe 1000 man hours on scaling work over the last year or so)
- ignore the security properties of Bitcoin as irrelevant
- dont understand what O(n^2) means for costs per transaction
- or want everyone to run SPV and have no security (the system needs a good portion of the Bitcoin economy by BTC volume to be using economically reliant full nodes).
- aren't aware of layer 2 (with offchain netting) already running
- dont know what lightning is nor the security properties it retains from Bitcoin.
yes I have come to believe they are ignorant of the trade-offs, and yet think that if they shout louder physics will bend to their will!
@_date: 2015-12-31 17:27:41
good questions. probably better that seg wit testnet be running than go over that ground again, but someone should update the FAQ.
@_date: 2015-12-15 09:18:23
Yes, it is important.  +1 to OP.
@_date: 2015-06-28 10:14:28
In my view people on reddit might like to encourage the review process  rather than trying to amplify controversy.
Given that long list of proposals and that Gavin said he'd support some of the other proposals if accepted, we have the recipe for progress.
A flame war on reddit among people who dont understand how decentralisation is a key part of bitcoin doesnt really help.  (Not to imply present company doesnt understand that trade-off).
@_date: 2015-06-30 22:49:54
It's intentionally two stage.  Simple fork with smaller numbers more people will agree with now, and a second fork in a few years time when we know more about how some of the layer 2 stuff scales.  
We may not need a second fork if for example a side-chain / extension-block type of thing can easily and dynamically add more chains of any size in parallel and lightning can hang off them or the main chain.
Or maybe we do need a second fork, in some years time and then we can do it again as necessary.
@_date: 2015-12-10 03:34:54
So is correct, to elaborate, the size of data in the total/extended block (including also the segregated witness) depends on the amount of multi SIG use. said on the basis of current averages it would be about 1.75MB (a 75% TPS increase).
As more or larger multi sigs are used that would increase. The maximum is 4MB.
It would be easy for a miner trying to maximise the extended blocksize by making an artificially large multisig or input script, so it is necessary to have *a* limit for anti-DoS or avoidance of place some limit on worst case theoretical selfish mining zero-sum miner vs miner attacks.
Another way to look at it multisigs (which are good for security) become more encouraged as their use no longer reduces TPS.
@_date: 2015-06-13 09:49:47
thats for a soft-fork.  with a contetnious hard-fork people are intentionally not upgrading so the networks diverge.  some miners are on each, but the actual hashrate is irrelevant - if 60% of the hashrate went onto the controversial change, but 40% stayed and all the users stuck with the original 40% chain, the original will still win because the 60% miners are mining an alt-coin with no users.  However in the mean time if some businesses and users are confused or ill-advised and spend coins on both sides etc the ledgers will get confused and they *will* lose money.  This is not as simple as a hashrate majority as with a soft-fork because the blocks for each chain are incompatible and dont relate (once any divergence starts any block containing a double-spend from that chains perspective is rejected and ignored regardless of hashrate).
@_date: 2015-06-13 23:10:16


Well you can use the range proof to prove non-dust status alternatively.
@_date: 2015-06-13 16:56:22
There is some clever stuff in Lightning.  Users can maintain connections to a few different hubs.  If a hub gets more demand than it has capital for on one channel, it could drain another channel to pay a user to send money back (user incentivised by negative fees).  This can reduce capital requirements and increase time between the need for fresh anchor transactions.
@_date: 2015-06-12 12:14:28
Nice post, see also how we can improve algorithmic scaling via lightning cacheing layer so that offchain can gain almost all of bitcoins assurances and make them available to everyone over time:
@_date: 2015-06-13 10:35:05
Correct.  But with some slight security advantages over a side-chain as the bitcoin miners are aware of and enforcing the rules.  (In a side-chain only the side-chain merge-miners know the side-chain rules, and the bitcoin miners just trust the majority of the side-chain miners).
@_date: 2015-06-14 14:48:13
You care because if its O(n^2) total cost then the per user cost is O(n) ie its getting more expensive per user the more users there are.  As you agreed that users transactions (and utility value) do not scale as O(n^2) in the number of users (ie that Metcalfe's law does not fully apply due to small-worlds hypothesis in payment networks) that means on chain transactions may get more expensive over time, towards linearly with the number of users in the network.
@_date: 2015-12-06 09:31:40
210 people in person I heard.
@_date: 2015-06-30 20:44:16
Yup, it's meta-game theory.  Create a perception of risk and hence incentive to change.  Bitcoin ecosystem is remarkably resistant to change for an Internet technology wave.
@_date: 2015-12-01 14:39:49
I would hope and expect everyone will be practical and collaborate around the BIP that has clearest rough consensus.  We all want Bitcoin to succeed.  Not that anything is up to me, but I will work to bridge views and encourage collaboration around whichever BIP that is, *including* the one you mentioned and I hope you and others would do likewise.
@_date: 2015-06-21 11:27:20
I prefer Jeff Garzik's proposal to this.  I believe Gavin said he was ok with Jeff's proposal also.  Is there going to be some discussion of this on bitcoin-dev list for review?
@_date: 2015-12-15 22:04:58
Fees being insufficient is a problem for direct bitcoin transactions also.  That can be addressed in the same way, fee estimation and increasing fees via RBF or CPFP.
A defence for large hub load is a) dont send your reclaim transaction until later (the clock on reclaim doesnt start until you post it to the chain); b) time-stop (a new feature) where the elapsed time would not count towards reclaim expiry for any full blocks.
@_date: 2015-06-30 11:27:05
I think you are mistaking a security trade-off with side-chains with lightning.  Lightning can work directly for Bitcoin independently, as well as a cacheing layer for side-chains.
The recent progress on inclusion of BIP65 in Bitcoin moves that time-frame closer.
Note further about the economics of the Lightning + Bitcoin vs Bitcoin + large blocks:
Lightning can provide higher fees to Bitcoin miners with less centralisation, and much more scale than would be possible with Bitcoin alone.  So its cheaper for users, more scalable for users, more profitable for miners, essentially the same trust model as Bitcoin but with more security from decentralisation than promoting a high-side large block-size as a long term strategy because high volume of transactions can be supported with more decentralizable block-size parameters by Bitcoin incorporating Lightning like features as an integral cacheing layer.  Seems like win-win-win-win.
@_date: 2015-06-13 09:38:32


What makes you think some big miners wouldnt immediately (at no cost to them) fill blocks to 20MB with pay-to-self free transactions.  Then they can exclude other smaller miners who will become unprofitable due to higher orphan rate.  This is a soft-version of the selfish mining attack, which becomes profitable for a group of miners at &gt; 33% of hashrate.
You're asking for a block-size change that cedes control to miners.  They will do what is best for their profit margin (modulo not upsetting users off so much that they sell bitcoin as miners depend on bitcoin price) but anyway *not* best for you.
@_date: 2015-06-13 11:28:19
These are valid points I think.  Note that bitcoin has a lot of SPV in it on a day to day basis because of people who dont upgrade after existing soft-forks.  I expect a big % of the network has some SPV risk vs miners.  Not that that is a good thing...
But the answer is to upgrade software, and if you dont like the risk, restrict yourself to 1MB transactions, or run a 20MB full node, or rely on businesses who already would do that.
I do understand the tradeoff, but consider also that a 20MB block basically already pushes many people to SPV because they dont have the bandwidth.  if you figured you would be unaffected because you have the bandwidth you will be in the same position.  Upgrading to a 20MB aware full-node doesnt mean you have to use 20MB transactions (which are more prone to policy abuse being a bit more centralised in their validation).  You can opt to use 1MB transactions either.
Still I believe that is win-win over single-size 20MB blocks, that exposes *everyone* (without ever increasing bandwidth) to the risk you are correctly objecting to.
@_date: 2015-06-12 11:48:52
Actually its more complicated.  You can do a soft-fork decrease, its just policy.  And you can do a soft-fork increase up to the current hard-cap.  (For example many bitcoin miners are soft-capping by policy at 750kB, they can change that to 1MB by editing a constant).
And while its surprising you can actually increase beyond 1MB by soft-fork also, eg via extension blocks and a few other ways also. See   I think if you want to look at it simply an extension block approach is better in most regards than a hard-fork:
- users can opt-in (if you like 20MB blocks go ahead and use them)
- users who dont want them can stay on 1MB
- miners dont lose revenue (they pool mine extension blocks if they dont have bandwidth)
- its a soft-fork not a hard-fork so there is no divergence risk
- its opt-in so its not forcing someones view on someone else
- it allows multiple different blocksizes to be used in parallel for increasing scale/security tradeoffs, if needed a 100MB or a 1GB block could be created, so its future proofed.
- obviously the bigger the blocksize the higher the centralisation, but thats a user risk tradeoff they can take.
- its less centralising than people going offchain and using hosted wallets
- it doesnt force a one-size fits all compromise which gives neither security nor useful scale.
seems like a win-win-win?
@_date: 2015-06-13 20:29:32
The techcrunch article by  is 
And the lightning-dev mailing-list code release notes by Rusty Russell is 
github is 
@_date: 2015-06-29 23:06:58
I know you're joking but for people who dont get the joke: dont do that!
@_date: 2015-06-30 20:38:25
Yes.  It's not intended to be a long term solution - these schedules run out faster by design, to be superseded once we have a better handle on the technology.  It is intended to make time to work on better technology.  ie Lightning, extension-block / side-chain like things etc.  Those things alone may essentially obviate the need for a further increase if there are parallel larger chains that can scale and be spun up without touching the base chain.  
Point is we dont know for sure and cant expect to project that far into the future.  Maybe someone figures out some SNARK magic and the game changes again for the better.  Maybe someone figures out lightning v2 that makes a huge difference, or lightning on top of lightning... 10 years is a huge amount of time in Internet pace technology.  Or maybe we make a new growth schedule then if internet bandwidth has leapt and the capacity pushing the limits.
@_date: 2015-12-31 19:53:49
The issue is segregated witness is simpler than normalised transaction ids so it doesnt really make sense to do them both. So the solution is use segregated-witness transactions. Normalised tx-ids and segregated-witness is similar in a number of ways in the effective way they fix malleability, only normalised tx-ids do it with serialisation during hashing.
@_date: 2015-06-13 21:12:16
I think the people concerned about a crunch from full-blocks are being collaborative.  Eg take a look at the  segment  
I really hope we can take time to properly analyse the economic incentives and test any proposal.  Personally I think we should take some remedial action to beef up decentralisation also in parallel.  Some people are working on GBT voting delegation to reduce some artificial centralisation.  Maybe some PR and lobbying of bitcoin companies and users could get an improvement on use of full-nodes for economic activity also.


The hit is purely software complexity I think, because if people have bandwidth not allowing them to validate the full 1MB+20MB extension block, they will have a worse problem validating the 20MB single-sized block, because then they will be pure SPV and have no option to keep their own transactions in the 1MB transaction set only.


Right, well except I dont know if they're stupid, some of them are trying to be KISS.


It could be a useful live-test environment once they are running non-alpha.
@_date: 2015-12-07 06:11:17
You're probably running the wrong code base if you're looking for code momentum, BIPs, proposals, security resources etc a comparison of the githubs would show that.
@_date: 2015-06-29 00:17:48
But did not actually post a BIP until he'd spent a lot more hours lobbying companies and threatening everyone with a unilateral hard fork that wasted huge amounts of peoples time to try talk him out of and warn others about the dangers of.  We wouldn't be here arguing now if he hadn't done that, I think it is true to say.  
Now it transpires he did all that stuff without understanding basic things about lightning.  That's kind of a critical component of the scaling picture - so does that mean the 8MB-8GB ramp no longer makes sense, even to him in hindsight?
For sure I think everyone's interested to review the proposals, and Gavin also has one published now in bitcoin-core (rather than only in Bitcoin-XT).
@_date: 2015-12-30 16:30:37
There is a difference between the hard fork and soft fork version of a forced or evil fork, which are both possible. It enforces the tyranny of the majority hashrate, or as says it leaves the remaining recourse for the minority by hashrate to hard-fork away.
Splitting the currency base is not much recourse for anyone as it is a mutual loss.
In some ways these evil or forced hard and soft forks are more coercive than a hard-fork because with a hard-fork the vast super majority must agree, assuming conservative rational behaviour by the technical and business ecosystem.  However they can be more secure because people can not transact on the fork left behind it is at least a *secure* forced upgrade.  
I think many people do not appreciate the risk and coercion implied.  Bitcoin aims to be a p2p currency that is free from coercion.  Distributed systems thinking is new and counter-intuitive to many people.  There are some temporary systemic risks in that statement.
I prefer opt-in mechanisms where people can try different features in parallel.
I might have been the originator of the hard fork version.  Appears may have figured out the soft fork version. I proposed a backwards compatible generalised soft-fork extension-blocks which are related though less coercive because it by design co-exists and interoperates with non-upgraded clients.
@_date: 2015-06-13 12:30:45
My gut estimate from the complexity of what people have implemented is if people all agreed in the dev community, we could get it live faster than a hard-fork (with the kind of delays to allow upgrade we are forced to use to avoid mass money loss with consensus hard-forks) because it can be safely enabled instantly once implemented.
@_date: 2015-06-13 19:14:24
Well the 1MB block is just what we have, and cant get rid of directly without a hard-fork, and hard-forks are risk and take a long time due to the need to have *everyone* upgrade (or they lose money!)
So there's nothing magic about 1MB and I wouldnt mind if someone increased it or reduced it, so long as there is pretty good decentralisation so that a bunch of small businesses and power users can still validate it.
The user choice isnt about the magic number, its the preservation of bitcoin ethos of the interesting and very useful properties that bitcoin users get as a result of that.  For example permissionlessness, no trusted parties for clearing and security, self-determination (ecash/bearer holding of your own money), policy neutral (no blocking, freezing, seizing at core level) and even potentially the number of coins (fixed vs inflation) and the subsidy supply curve.  As you can see from the 2008 financial collapse when you give humans policy choices, they mean well but fail under-pressure and we get moral-hazard, quantitative easing, bail-outs etc.  We really dont want to repeat any of that stuff or we lose the differentiating features.
Sure if you werent particularly attached to those features (eg you just liked cheap fees or fast international settlement) then it may look like an odd choice.  But really if you dont care about those features the bitcoin architecture is *all wrong* and far more efficient architectures could be built via trusting others, right.
@_date: 2015-12-19 11:24:32
It's the same general mechanism as used in other soft-forks and SPV wallets cant tell the difference.
@_date: 2015-06-13 09:46:59
amen to that "CHICKEN IS A STUPID GAME TO PLAY WHY WOULD YOU WANT TO POSSIBLY WRECK A PERFECTLY GOOD CAR AND RISK YOUR LIFE?  Same thing goes for Bitcoin."
@_date: 2015-12-14 15:01:05
Here, here.
@_date: 2015-06-12 13:39:42
Lower risk of breaking consensus than a contentious hard-fork which literally risks directly diverging consensus.  Lots of bitcoin is complex.  There are many advanced types of QA, regression tests, network tests going on.  The extension block is basically another instance of bitcoin logic with the merkle root tacked into the main chains tree, so it may not be as scary as it sounds, though its definitely not as simple as changing a parameter, it's likely safer compared with the divergence risk that comes with a contentious hard-fork.
@_date: 2015-06-28 12:08:13
Well it's not a strawman exactly: Gavin proposed 8GB blocks (via automatic doubling from 8MB in a schedule).  Anyway my point is not  the example numbers, which I use only to illustrate that there is such a thing as a number which would clearly cause this kind of problem today.  The point is it is a decentralisation scale tradeoff, and one of the security assumptions is that a reasonable proportion of the economic weight of the network is quickly validated by full nodes operated by power users and business that rely on their full nodes validation.
@_date: 2015-12-19 14:05:05




could you explain that part?  it seems like you are suggesting constraining the segregated-witness feature to apply only to the first 1MB of a block rather than following the base-block size as it increases?  I didnt understand the rationale.  Maybe you are considering that will get 2x growth too fast for your intended growth profile for the first 2 years, if we one had growth going to 8mb and segregated witness effective ~2x blocksize increase on top?
@_date: 2015-06-13 11:13:43
His testing was inadequate and he massively downplayed the risks of a contentious hard-fork in presenting it to the media.  And then he made things more contentious than they needed to be by going to the media instead of writing a BIP, and threatening to fork the codebase.  
Not sure how you could work harder to ensure a contentious outcome.
@_date: 2015-06-13 21:47:52
Correct, that is the idea.
@_date: 2015-06-13 16:47:46
Well sort of.  In a restricted sense the 1MB node has validated it - it went into the 20MB extension-block single big transaction stayed there for a while (bouncing around unseen to the 1MB block) and then some coins came out of it, as a 1MB full-node you are directly validating that no more coins go in than come out of the extension-block.  (Similar logic to a side-chain security firewall argument).
In the case of an client that has only bandwidth to receive the 1MB block transactions,  in terms of receipt of 20MB transactions thats a higher security assurance than for a pure SPV node.  You're also not a tiny bandwidth node, you can understand 20MB transactions, your client can fetch some history around the transaction you're receiving, fetch inputs back until it came into the 20MB block, or until its quite buried.  (Thats a lowish price to pay vs receiving 1MB every 10minutes, as its for your own transactions that you value).  eg maybe you say as a 1MB full-node (that understands 20MB transactions but doesnt have bandwidth to receive them all) that you want 144 or 2016 history on transactions.
As 1MB blocks are a subset of a 20MB block, there is no way for them to invalidate your receipt of funds short of reorganising the block.
As long as the hash-rate majority agrees, over time it becomes infeasible to over-rule it.
There are also some things you can do to improve it, which have been proposed for bitcoin-core.  The UTXO commitments proposed by and fraud-proofs allow 20MB full nodes to compactly broadcast proofs of invalid data in 20MB blocks.  This also opens the door for sharded validation where potentially each 1MB block node also validates 100kB of the 20MB block, such that between all 1MB clients they validate the 20MB block many times over, and if any of them find a flaw they can broadcast the fraud-proof.  Fraud-proofs can come with bounties.
Anyway without getting into those bitcoin-core mid-term planned things, as is the extension-block is safer for people who have bandwidth for 1MB only and cant afford 20MB bandwidth than a single fixed size 20MB block because by that logic they would be forced to be SPV clients and there is no lower bandwidth 1MB fully validabtable sub-division.
Either you have the bandwidth or you dont.  If you dont you either have someone else you can trust who does have the bandwidth or you dont.  If you dont, that wont change because there is a single, fixed 20MB block, you'll just be pure SPV along with a not insignificant number of other people.
@_date: 2015-06-28 18:08:23


IBLT and fountain codes are interesting things for network compression.  I am imagining we could use the latency improvement 
for shorter block intervals.  Larger blocks are still the same issue as before for validating only (non-mining) full-nodes if the bandwidth gets too high.  These approaches reduce bandwidth by ~50% which is good, but the problem doesnt evaporate - eg we could double the blocksize and stay with the same decentralisation.
About creating a large block if there is no block limit, I think this will look to the network like a variant of the selfish mining attack.  If the block is filled with miner self-generated transactions it will have a slow propagation.  That means the miner (or group of well connected miners) will tend to win the hash race because they have the same kind of informational advantage as in the selfish-mining attack.  Note that attack can be effective from 25%-33% hashrate depending on assumptions.  They will probably degrade more towards 33% because they will rarely win the transfer race if their block is intentionally very different.  
Or they could actually flood the network with transactions before hand - there's no limit in this thought experiment - until some nodes cant keep up just with the transactions.
The kind of thing people are worried about in an unlimited block world is a centralised or well connected corner of the network colluding to win all blocks.
It can even be accidental.  Eg China has more users and hash-rate that the rest of the network combined.  So as the links coming out of China are lower bandwidth, they will tend to win all blocks, without any malicious intent.
People have run simulations on this Jonas Nick, others.  They may have tried IBLT also (it's a simulation so they don't have to implement it, just estimate it's effects).
@_date: 2015-06-13 11:20:27
Note we may easily be able to deploy extension-blocks faster than a hard-fork.  This is because its divergence-safe and so  (once implemented) you can safely deploy extension-blocks immediately, whereas a hard-fork has a long lead time (I think 1 year was proposed) to avoid people and businesses accidentally losing all their money by not being prompt to upgrade everything.
@_date: 2015-06-27 23:36:33
Why is it a conflict of interest?  Did you read the proposals on 
How are any of them in conflict - they're all trying to improve Bitcoin scalability via different mechanisms?
They're also all trying to scale bitcoin nowish.  Like end of year time-frame kind of thing.
@_date: 2015-06-13 12:27:08
Perversely that would actually be safer in terms of divergence fork-risk though less respect users interests.  (Again putting miners in charge).  Note hashrate is somewhat elastic, so people will stop underclocking for efficiency (revert to full overclock) and turn on non-electrically efficient decommissioned hardware and drive up hash-rental fees).  
The fact that it would be an overt attack, kind of sets the tone and is in the same space as a contentious hard-fork - it is a kind of policy attack via mutual assured destruction game theory.  The 51% attack other chain variant is a policy attack via miner attack hash-war.
I dont think this is (or even was designed to be) any way to improve bitcoin other than by consensus.  Otherwise we're just back to reinventing moral hazard in central banking.  Thats exactly what the call to extremis stuff is - "do what I want or dire things happen".
@_date: 2015-06-13 21:59:47
Emergency powers seems a heck of a lot like the moral hazard happening in central banking committees that led Satoshi to put that quantitative easing quote in the genesis block.  I think some kind of safety limit cap maybe prudent in case the variable control or economics are incorrect and fail.  32MB is an interesting number (the code limit currently).  I think flexcap model ( explained by I think its better than (he is planning based on feedback I think to include a soft-cap rate of change limited - like 2x per 3mo max) because it puts some economic back-pressure on miners, otherwise there is no real long-term limit - they'll max or min it to where they make the most profit, or to the switching-cost pain point of users and other bitcoin businesses. 
@_date: 2015-06-13 09:58:39
If we want to say we can never improve bitcoin beyond changing parameters, bitcoin is doomed now.
See for some technical discussion about scalability (scalability is more important than throughput in an O(n^2) network)
@_date: 2015-06-13 13:20:20
This is a new and good point actually.  I think there might be limits because there is a cost to trying to orphan if you are not in a clear  and organised majority cartel because others may not follow you and then it is you who has been orphaned.
Maybe we have to content ourselves with non-overtly hostile (protocol honest) miner model because I dont think even time-lock encryption would fix it. (The cartel could orphan blocks that do not tell them the vote, though that is even more overtly hostile).  
That is quite limiting however as just greedy miners can do it within protocol without really it being directly provable who did it.
@_date: 2015-06-16 00:52:41
Yes.  I am not opposed in principle to extension-blocks being one of the long term proposals with something like proposal with some fixes being a short term throughput increase, or another similar proposal.  I said that somewhere else but there's a lot of posts on here.  I do think to do it without a plan to work on decentralisation is dangerous as decentralisation is already low.  And the point of the exercise is to scale bitcoin so we should apply the lightning support fixes to bitcoin and a few hard-fork fixes that help scalability while we are kicking the can a few years.
@_date: 2015-06-14 09:27:37
no AFAIK he didnt talk to any of us, but  is a moderately famous sci-fi author AND a programmer so he can figure out tech stuff for himself better than most tech journal writers.
@_date: 2015-06-12 23:14:17


Yes you get the idea.


No actually extension blocks are more directly integrated.  Its like running a 10MB instance of bitcoin within itself, and attaching its merkle root into the 1MB instance.  The difference is side-chains are based on SPV are independent merge-mined chains, where the 2wp is used to move coins backwards and forwards (slowly with the 100 block delay for fraud proofs).
With extension blocks it can be as fast as you want it to be, as the 10MB block miners are fully aware of the details.
You can also do fractional validation and fraud-proofs using UTXO commitments, but thats more code.
@_date: 2015-06-28 23:26:14


I did!! :)  People were too busy supporting Gavin's mega-block proposal to listen!
Allow me to quote myself from 2 weeks ago:














you also wrote:


well it's incremental.  You know if say someone makes a wallet that integrates lightning and someone else doesn't I'm guessing the market will decide?  Lower fees, faster transactions, instant secure 0-confirm, support for micro-payment pay per KB level use.  Seems like a no-brainer to me if it works out as people imagine.
@_date: 2015-06-18 00:39:01
I explained how big O arives at O(n^2) -- total network bandwith consumed for n users here.
If you prefer to think about bandwidth per user then thats O( n ).
The  confusing thing about big O calculations is it omits multiplication factors and addition factors and lower order factors.  So O( k*n^2 ) = O( n^2 ) and O( n^2 + 100000000 n ) = O( n^2 )... (even if 10000000 n dominates for useful parameter ranges).  Its really a mathematical model for the complexity of the system as n tends to infinity.  There is no guarantee it tells you something useful about the behaviour at low values.  
But still its the standard model for talking about system scalability.
And also there are a lot of assumptions about the relationships - eg how may transactions do users send, and how that grows as more users are added (most people assume some kind of small world hypothesis not Metcalfe's law) and what is the relationship between number of users and full-nodes (I would expect full-nodes to grow - presumably power user density is a bit front loaded, but businesses should be running them).
@_date: 2015-06-16 01:19:37
I am taking it you did not read the section on Scaling plans as I describe the plan for how we maybe able to scale bitcoin a lot using lightning, and the tradeoffs of how to get there.




underway, and education)








Could you tell me what was wrong or unclear about the write up that caused you to make a statement like that?  Its a question because evidently I need to write something differently as people dont seem to understand still and its quite important that they do for their own safety and for the safety of bitcoin.
@_date: 2015-06-14 21:00:38


As far as I can see you are saying the same thing I am.  I said:
O(n^2) total bandwidth cost
and therefore O(n) cost per user (or if you prefer per node).
Big O notation is fuzzy because of the multiplicative constants.  It is all imprecise obviously but its just giving us a hint as to the rough effect with the crude input assumptions.
@_date: 2015-06-30 23:08:15
Because Bitcoin decentralisation is already too low and that risks making it insecure or to lose its censor resistant or fungibility.  It's a better security/scale model if layer 1 is secure so FOSS projects can build various competing layer 2 things on top of it that scale highly.  Lightning works on top of eg side-chains or extension blocks and other similar things.
@_date: 2015-06-13 09:59:57
Actually that was my mistake I used the wrong link at the top by accident.  The more technical description of how it works is here:
see also Tier Nolan's script level explanation of the same proposal 
@_date: 2015-06-27 20:22:08
The article is from oct 2014.  Where is he now though.  That kind of statement could be a useful voice in this debate.
@_date: 2015-06-28 23:11:23


You clearly have no idea what lightning is or what it does.  Hint lightning transactions *are* bitcoin transactions.
@_date: 2015-06-15 23:23:27
Well I dont agree with your conclusions but I can appreciate healthy scepticism about conflicts of interest, and its important people keep that mindset and examine things critically.
You should read the section on Governance again, its about preventing one person seizing control, or surreptitiously inserting a backdoor, we cant have that right or a industrial or foreign saboteur could break bitcoin, or steal huge amounts of money.
(search Governance)
@_date: 2015-06-13 10:08:36
proposal is on the gradual increase non-contentious proposal.  He should be thanked for doing something constructive and trying to work towards consensus.
@_date: 2015-06-12 13:34:46


I'm sure he understands that bitcoin wont scale without algorithmic improvements and a block-size parameter change is just a temporary measure until we can implement algorithmic improvements.  Other people are working on such things (CPU, memory and bandwidth/latency) scalability for the last year and more recently on lightning.


I think full blocks have a natural overflow opportunity with extension blocks - more extension blocks of different sizes can be deployed in parallel ahed.  So it wont be higher fees or go offchain it will be higher fees or switch some users to a bigger extension block.


Yes.  And it also doesnt deprive people who value the p2p nature of retaining a high level of decentralisation and the policy neutrality and permissionless features that are tied to that.
@_date: 2015-06-15 23:07:16
Yes I didnt say do it all at once what I said is this
(search for "Scalability plans")
















actively worked on RIGHT NOW, and in the case of algorithmic scaling and improve decentralisation have been worked on for months.


blocks are only 3x-4x below capacity such that we should look at it.




(and rest of that *Scalability plans* section)
@_date: 2015-06-28 23:00:52
Correct.  I expect many people would by default assume that a lightning transaction is some kind of trusty off-chain thing.  But it's not the case, every lightning transaction is a valid bitcoin transaction, that can be posted to the blockchain to reclaim funds if the hub goes offline.  It's a fairly integral write-coallescing write-cache network for bitcoin that people think should allow Bitcoin to scale massively.
@_date: 2015-06-12 13:13:01
I dont agree with the claimed usability problems.  Its a protocol level detail, its opt-in and backwards-and-forwards compatible and users dont look at protocol byte streams in hex anyway.
If this is such a big problem, people would be willing to adapt clients, which they can opt to do unilaterally and organically due to backwards and forwards compatibility.  If its not a problem, then we dont need blocksize increases and the extension block would not be actively used until such time as we did.
Bitcoin itself is complicated as is computer science, CPUs, routers networks etc. You cant cripple Bitcoin by saying we'll never do anything non-trivial.  If all we'e allowed to do is tweak parameters, Bitcoin is then already dead-end with any practical blocksize increase.  There are other complex things that we and others are working on, for example the lightning network.  Read what I wrote here about O(n^2) ontop of exponential growth vs O(n log n ) or O(log n).














Improving decentralisation is important because it creates safety margin within current network capacity that could allow us to by consensus and safely increase block-size.
@_date: 2015-06-12 19:53:56
because of limits in bandwidth. many consumer connections are asymmetric some have monthly bandwidth caps. people may turn it off even if its within their bandwidth limits if it degrades their voip, youtube, skype and counter-strike use.  Even 20MB pushes many people off they have said (yes they are super technical people who did the calculations, and no they were not in ridiculously poor bandwidth situations).
@_date: 2015-06-27 20:04:28
Exactly.  Thank you!  Up-vote what says.
@_date: 2015-12-07 05:30:04
I dont think anyone is proposing to not scale short-term.  I prefer seg-witness or next preference 2-4-8.
@_date: 2015-06-30 22:43:42
Actually I believe that is a miscommunication.  If you read the Chinese language discussion forums, where they are talking about block-size, they were more saying they did not want a big increase, but if that was going to happen despite their preferences to the contrary, they'd definitely not want more than 8MB.  (I can't read Chinese but I know someone who can who came away with that impression, and also know someone else who has been talking frequently with the Chinese miners).
That's why I put an example capped at 8MB in some years time with the flexcap (safest) model.
@_date: 2015-06-13 21:45:17
Its simpler and clearer to think of the bitcoins *moving* to the sidechain and then moving back later.  (The technical details are about how to do that: freeze 1BTC on the main chain so its dead in the water, cant be used; present that proof to the sidechain it gives you 1BTC on the sidechain; sometime later you want it back so you burn it on the sidechain, and present that proof to the main-chain and it unfreezes (reanimates) the main coin.)  So at all times there exactly 21mil cap in aggregate across bitcoin main and all sidechains.
It preserves the number of coins, they move, no new coins are mined, there is no separate mining schedule on the sidechain for bitcoin.
@_date: 2015-06-03 13:48:25
I wrote about this here in bitcointalk  .  Actually I reinvented the LWW approach based on AOS paper, and then found out that LWW already beat me to it :)
The scheme Greg came up - the Borromean signature - is an extension of the AOS compact ring signature going from a1 OR a2 OR... to (a1 OR a2) AND (a3 OR a4) etc for arbitrary sizes of OR and AND sets like that.  Off the top of my head I think that makes common uses like 30% ish smaller again for that use case.  But for a single a1 OR a2 OR ... the main optimisation from Borromean (ring of ORS connected by ring of ANDs) doesnt apply as there are 0 ANDs.
As said you only need LWW signatures for linkable ring sigs (what Monero / Bytecoin uses).  I dont think it helps that use case, but it helps other use cases.  Stay tuned :)
@_date: 2015-06-12 23:35:24
red-lists I believe it were posted by Mike Hearn (when he was in some policy position there) on a foundation only internal list and leaked by someone.  I think the idea is that you alert users so they know a transaction is red-listed but could override it. Of course businesses and many people would refuse to accept it because they'd know it would be hard to spend.  (Explicit fungibility breakdown).
black-lists would be somehow mandatory - they are just binary unspendable by consensus.
They are nearly the same thing but not quite.  Anyway both bad things in bitcoin functionality terms.  Breaking fungibility is also just generally bad for confidence and basic functionality of bitcoin - if you never know when a coin will retroactively become less fungible it affects confidence in a currency.
@_date: 2015-06-13 23:02:42
 also has some blog comments about Confidential Transactions 
btw while the range proof (which is part of the segregated witness feature  and so discardable) is largish (1-3kB range subject to some optimisations) it is interesting to observe that one of the reasons to have multiple UTXOs and use merge-avoidance (  ) is to hide balances.  With Confidential Transactions the overhead and UTXO space created for that is avoided, ie merge-avoidance becomes redundant and unnecessary.
The other reason for multiple UTXOs is to for fungibility in avoiding address-reuse.  Confidential Transactions dont directly do anything about fungibility, but may enable other interesting things that indirectly may.  Eg send 0-satoshis to other people, or buy 0-units of stock for 0-satoshis daily to prevent others knowing your stock trades.
Also the status of change vs spend is a little more ambiguous and fungibility improving because the value is not disclosed publicly.
Another interesting feature that CT internals can be used for is to re-use the range-proof for other things: eg prove the transaction is over some amount (eg that it is not dust) or that it is under some amount.
@_date: 2015-06-13 09:31:41
Sure.  There can be multiple extension blocks in parallel but a given extension block could be variable size with miner voting; much safer as we have the fall back that if it gets out of hand, people will switch to one that doesnt have it.
@_date: 2015-06-14 09:57:07
Clearly lightning should be as p2p as possible, and decentralised as possible.  I think the current protocol can be improved towards that.  It's also more decentralised than people assume, because of some crazy-smart things you can do (negative fees to rebalance channels, where each user has 2-6 channels eg that allows funds to recirculate longer without needing a new anchor transaction) but it does have some risk factors.  The hot-walllet risk is a bit of a centralising feature as is high-capitalisation.  Unfortunately not quite a free lunch but still the best bet we have right now for improving scale of bitcoin without pushing it towards centralisation death (becoming paypal2.0)
@_date: 2015-06-14 12:08:10


I can assure you this is not what is going on.  Everyone wants to scale bitcoin to make its properties available to as many people as possible.  However its not a free thing, there is a security/scale tradeoff.  The developers who work at or founded blockstream have been saying the same thing for nearly 4 years, long before blockstream existed, and you can go find them pointing out this security tradeoff all over bitcoin-talk, IRC and mailing-lists constantly year in year out.  Their opinion did not change, just now more people are looking at the scaling challenge and paying attention finally to the security/scale tradeoff.
There are a technical minority who I think, without inferring any malice, are just not that concerned about security.  To them its no problem to ramp up block sizes to 20MB, 200MB or 2GB, because to them full-nodes can run in data-centres, and later tier1 data-centres and later in a co-located banking centre with fiberchannel interconnects.  I think they think this is ok, and bitcoin will still be bitcoin.  I do not agree.
If we go ahead and do that (increasingly large blocks as a single parameter choice) bitcoin will not be bitcoin anymore faster than you expect.  That will not be fun because we will have killed bitcoin while trying to help adoption and scale.
Many people may not know this but paypal started off as plan as bearer ecash on palmpilots.  Look where it is now - the epitome of arbitrary policy abuse, seizures, freezes.  Further many of the other system properties will be lost once it is under central control - fees being market set, even the number of coins is up for policy debate at that point because its under central control.
I do understand that its frustrating that it is complicated to scale bitcoin, but all the people at blockstream have been working very hard on it (pre-blockstream, and with the independent developer hat on also, and blockstream itself as well).  See for example list of work that is in progress in various contexts:
Now I think maybe the only way to avoid a lose-lose compromise over block-size where bitcoin gets neither security nor useful scale, is algorithmic improvements, and *user choice* of parameters.  Hence why I proposed extension-blocks as a way to allow opt-in block-size increases.
@_date: 2015-06-14 12:14:58
Actually the upgrade mechanism idea was the 1-way peg.  But the possibility does remain with a 2-way peg (and is safer because you can abandon an unsuccessful upgrade with having coins trapped).  I was thinking of it as more of a longer-term thing because there some unknowns in how to navigate that.  But it would be beneficial to have a robust security isolated software upgrade mechanism for major vs minor feature and code refactoring work.
(May 2013) Posing requirements for 2-way peg  


(Oct 2013) proposing 1-way peg as an upgrade mechanism (because its kind of limited for experimentation or extensions as you cant reliably go back in some market-conditions) 
@_date: 2015-06-13 12:51:28
maybe start a new reddit post on lightning?  there was a code release today (drowned out by chanting of "hard fork bitcoin now!:)  
this topic may get lost in here, otherwise and perhaps there are people more interested in lightning (scale) than can kicking (throughput via parameter editing).
@_date: 2015-06-27 23:07:17
Saturating the internet isnt the first bottle-neck.  There are multiple: hitting performance limits of desktop CPUs, hitting memory IO limits, hitting RAM limits.  As I mentioned in my other post, people who you say are doing nothing have been working on these things, like 1000 man hours work over the last year.
Another limit is that there clearly exists a limit where Bitcoin is centralised to an extent that it doesnt make sense.  Bitcoin achieves many of it's useful properties from being reasonably decentralised.  Bitcoin decentralisation is already at a low point.  This is why I said we need also work on improve decentralisation.  There is work that can be done, there are simple pool protocol changes that can improve it by removing artificial centralisation that benefits no one, and is a historic pool protocol accident.  It wont make sense beyond a certain level of centralisation because the useful properties will be eroded, and at those centralised trust levels, there are cheaper protocols, like the ones banks use today.  I and others have been working on improving Bitcoin decentralisation in these ways.
If you're really really sure that it is 100% necessary and critical for bitcoin to scale to millions of micropayments per day, maybe you could go do a startup to compete with changetip.  Personally I think micropayments are quite interesting and might prove to be a new web content monetisation model that could be more effective than advertising.  When's the last time you clicked on a web advertisement?  That doesnt mean each second of each person in the worlds web viewing, you tube viewing and web clicks etc can be broadcast worldwide in an O(n^2) network.  Thats nonsensical.
It's just not plausible to anyone that we can keep broadcasting all transactions to some say 0.1% of users (being power users, businesses etc) if we get to global usage levels for stock markets, all cash, debit card, IoT traffic etc.  The bandwidth cost will exceed the payment value at some point along that path for micropayments.  While a given node doesnt pay it, it still cant work economically to cost more in bandwidth than a payment has value; indirectly we all pay for that cost.
Fortunately for Bitcoin enthusiasts, which presumably includes you as well as me, Bitcoin can scale much further and more efficiently with the addition of a native cacheing layer.  It preserves pretty much all of the properties of Bitcoin, and at a much better algorithmic complexity, so that we actually could do those per click, or per second micropayments on a global basis with everyone using it.
I'm not sure why you're arguing with me, I'm trying to do those things.  It probably takes a small increase to create a bit of time for the layer 2 to get implemented, which I already argued is a good idea.
Btw some of the people who have been working on Bitcoin are getting disheartened by uninformed demands for unilateral hard-forks and other divisive and clearly dangerous activities, to the point of musing if they even want to work on Bitcoin anymore.  So this kind of rampage of criticism is actively hurting it's own interests.  There really arent many people in the world right now with the knowledge and skills to do the scaling work to make Bitcoin reach the next level.
@_date: 2015-06-12 02:34:38


There are limits here because bitcoin scales with O(n^2).  Things like lightning help, but unless you expect bandwidth to grow n^2 with bitcoin adoption (which itself could be exponential again for a while), this is very clearly not going to work, right.
Therefore the more useful place to focus work is in increasing the algorithmic scaling (say O(n log n) or O( n ) or O( log n) that kind of direction).  And Lightning which acts as a write-cache for bitcoin is one direction that has a lot of promise because it can maybe cache 1000x or 10,000x transactions per on chain transaction or whatever the ratio works out to.
(Not picking on you here, just some comments copied over from twitter in longer form).
Note the meme that people are doing nothing about scaling or are obstructionist is blatantly false 1000s of man hours of work have gone into just that!:
- work was done on CPU, memory &amp; bandwidth utilisation scalability
- work was done to use the space in blocks more efficiently
- work was done to make modifying fees easier
and as you may have seen some people are working on Lightning and also on reducing mining centralisation via things like GBT (to delegate voting so they you dont have to cede your vote to a pool just to get variance reduction).
Improving decentralisation is important because it creates safety margin within current network capacity that could allow us to by consensus and safely increase block-size.
I said what I wanted to say about controversial hard-forks on twitter:




To elaborate this is extremely dangerous because if it succeeds it shows that if someone is reckless enough to take something controversial, partner up with a big company that's not particularly sensitive to user values (and there isnt a complete shortage of such companies) and then threaten the network that they'll trigger a network divergence where everyone loses, unless users capitulate to their demands, the message will be anyone can force anything by threats of dire things. Thats exactly like moral hazard in central banks overriding policy for expediency by calls to special circumstances as seen in 2008 and the quote in the genesis block. People seem to not learn! We should not be reinventing fiat currencies failings in Bitcoin. Sure a blocksize increase isnt as controversial as that, but that being the case, why go to such a dangerous nuclear option; its just plain bad for Bitcoin in every conceivable way.
I would like to see everyone focus on the engineering, and on improving bitcoin; scale it within safety margins, and abandon the contentious hard fork risk, which should never have been started.  Work collaboratively within the consensus process, don't fork the codebase and above all do not take the crazy risk of diverging the network.
@_date: 2015-06-13 11:22:14
Its not really related to side-chains if thats what you mean by alternative systems.  If there is doubt about the importance of security importance for bitcoin read this article 
Also for the record *everyone* in bitcoin development wants to scale bitcoin within safety margins.
See also 
@_date: 2015-06-30 23:30:36
Well I disagreed with and the pool that did deploy full/unsafe RBF undid it (F2pool) when Gavin spoke up.
So it's not that I agree with Peter's strategy there, but he fully understands what he's doing and that was his strategy I'm pretty sure.  It's also not ideal if people keep using a technology option that isnt that secure, and people seem more inclined to lobby miners than to fix their software, which is a really bad precedent.  Unfortunately the only robust fixes to secure fast 0-conf transactions are greenaddress which works now, but is a bit trusty/centralising or lightning which isnt implemented yet.
It's kind of a grey area but I favor making RBF opt-in so people who can work with 5% fraud rate or are face to face or physical shop dont lose the convenience until something better comes along.
They really ought to have a short-term contingency plan B though because the unconfirmed model is a bit weak and prone to slipping worse.
@_date: 2015-12-15 17:37:53
With lightning there is a channel with some funds on it in one or both directions, and you over-time how much of the funds are owned by each of the two parties changes as they pay each other.  A decent margin in each direction can be reserved to cover fees in the event of default (going offline, failure to progress transactions).  That can ensure that the defaulting party is the one that pays the fees.
The fees dont have to be decided at channel setup time.  You wont want to have a channel that is below the typical fee size as then you can get into not worth disputing scenarios if the defaulting party doesnt have enough funds that would be forfeited on default to cover the fee costs.
But that doesnt say anything about the transaction size zipping around inside lightning and recirculating as the channels change direction.  They can be as small as you like and uses as much bandwidth as you like subject to the bandwidth on the route between the payer and the recipient via lightning payment routing nodes.
@_date: 2015-06-29 00:00:48
Pretty fair paraphrase.  Except for 


I think it's reasonable to do a modest increase now.  (I mean as soon as people review and test proposals).  Because it's probably safer to do it more slowly than at the last minute.
@_date: 2015-06-13 12:34:28
Its not like people aren't working on scalability.  Yesterday first code drop of lightning pre-pre-alpha 
drowned out by the "hard-fork bitcoin now" chanting :)
@_date: 2015-06-13 20:43:49
You can think of lightning network as a (write-coalescing) write-cache layer for bitcoin where it actually preserves almost all of native bitcoin properties.  The key every party actually has a real bitcoin transaction that they could post to the network at any time to start a claim that will see them after a delay get what they are owed.  You really do need bitcoin though for the anchor and dispute claim transactions.
Rusty Russell has a 4 part blog post describing how lightning works 
Also see the orignal paper by Joseph Poon (and Thaddeus Dryja) 
@_date: 2015-06-23 16:38:53


Well now you've published your BIP, and there is discussion of the dozen or so proposals - maybe you could keep an eye on that discussion and return to working on IBLTs?  has done some stuff on it but is spending more focus on lightning.
@_date: 2015-06-28 15:09:48


Do you suppose miners interests are aligned with users?
Users want high scale and free fees.  Miners want to make a profit.
You've probably heard about the concept of the switching cost of a network.  It maybe quite rational for miners to try to discover the switching cost of users of the network, whether that's testing tolerance for centralisation or testing tolerance for small blocks and high fees.
Bitcoin's design tries to align users and full-nodes to verify and hold miner's honest.  If you cut those links the system will probably function worse, and maybe fail.  Dont forget that very little about the system is arbitrary - it is serving a function to keep the system incentives in balance, to keep the system secure, decentralised and policy neutral.
@_date: 2015-06-13 23:33:42
I agree we cant make wild assumptions - we can just so far see that miners incentives are different from users and businesses.  Miners *might* alternatively want smallest blocks that maximise switching-cost profit instead which would be a different problem if the switching cost were high (because people greatly value bitcoin vs alternatives like fiat, a subset of users could get price gouged and forced into insecure off-chain systems).
@_date: 2015-06-19 09:03:00
I assume as written here
that O(n^2) assumes full nodes are in some relationship with the number of users.  For bitcoins security model to work, for bitcoin to be secure and for that security to scale with its use and value and companies and users dependence on it, this would tend to be the case.
I suggested as an example full nodes might be c*u where c=0.1%.  Ie one in 1000 users of the system operate full nodes.  So that is O(n^2 ).  Of course there are assumptions and I explained my assumptions.  Simple matter to scroll through back-post to find it.  A reasonable person may disagree on constants and relationhips, but I do not think it reasonable to say eg full nodes is a constant and stays at 5000.  Bitcoin security depends on a good portion of economically active full-nodes that are auditing for their own benefit.
@_date: 2015-06-13 10:45:32
Note people at Blockstream are wearing two hats, a blockstream founder/employee hat, and an independent bitcoin dev hat  In our contract (that we helped write) it is stated that we are independent in matters relating to bitcoin-core work.  In the case of and even if Blockstream does something sucky they can quit and Blockstream is contractually obligated to pay them salary for a year while they work on bitcoin independently or with some group or foundation.
Everyone in bitcoin-core as far as I know is very clear that they want to scale bitcoin within safety margins.  The disconnect I feel among and Mike Hearn is that they are way more optimistic about the risks of decentralisation.  For people who dont see why decentralisation is a security requirement for bitcoin I recommend reading this 
There was a lot of work done in bitcoin development on scalability, 1000 man hours maybe, over the last year (CPU, memory, network/latency scalability work).
is proposing a consensus compromise.
It has problems but its better than a contentious hard-fork!
The main complaint I had from on extension-blocks was that it's not as simple.  KISS is a good principle.  But avoiding doing things that risk decentralisation security in the long term is maybe worth some engineering effort.  We cant progress bitcoin if we never make changes that amount to anything more than a parameter-change, if that were the artificial limit on what we are allowed to code, Bitcoin scalability is probably dead already due to O(n^2) scaling.  See eg 
It's maybe not either-or either. Another model in principle might be to kick the can a little to give some breathing room and then implement extension-blocks.
However even though they are more complex extension-blocks are safe against network-divergence, so unlike hard-forks which call for I think 1 years lead time has been said, extension-blocks could (once implemented) be safely deployed immediately.
@_date: 2015-12-31 19:28:12
and Pieter were before working on normalised tx-ids. Segregated-Witness ended up being slightly cleaner particularly for the soft-fork and backwards compatibility reasons. You can find discussion on the bitcoin-dev list and there was a draft.
@_date: 2015-06-13 21:50:25
There is also a feature described where the path of multi-hop transactions can be elided, by replacing the back and forth amongst a bunch of users with an updated transaction that coalesces them into a smaller/shorter set of transactions eliding a bunch of transactions that cancel out.  (Like netting).
@_date: 2015-12-07 01:34:28
transcript: 
@_date: 2015-06-28 23:54:44
Lighting is interesting because it offers the prospect of high scale with reasonable decentralisation.  Raising block-size as if it's a free-variable leads to neither high scale nor decentralisation.
It's not pure vaporware people are working on it:
@_date: 2015-12-01 01:54:18


I think the Bitstamp comment is taken out of context.  I dont think Bitstamp nor any other bitcoin company will unilaterally adopt a fork outside of consensus.  I suggest following the  and commenting on proposals.
Censorship is bad.  I am not keen on moderation either as from previous experience it can be a way that censorship becomes reality: just figure out the moderators kryptonite and you have a censor.  Even happened to the cypherpunks list.
Signal to noise can be terrible also on some internet forums.  The only real solution I have seen is to try yourself inject and focus on signal and avoid making the noise worse.  Look at 20 years of the late Hal Finney internet commentary for a positive role model and example.
People who are not focussed on courteous, constructive reasoned discourse are a typical populist justification for moderation to start with often a side-effect of defacto censorship following.
We dont really have opt-in moderation that on any of these forums - I mean like NoCeMs where there are multiple competing suppliers of opt-in moderation.  With NoCeMs people can opt-in or out of them.
One can also participate/subscribe in multiple forums?  has a different set of moderators so you at least get a weak form of opt-in moderation - use both!  There are also other forums.
@_date: 2015-06-27 20:43:17
As far as I can see I was and remain correct in the general complexity area of bitcoin scaling.  The article you link to has you agreeing even?
@_date: 2015-12-07 16:23:23
It requires code, but it is implemented,  It requires testing but some aspects of it have already been tested in sidechain elements alpha which has a similar seg-witness feature.
@_date: 2015-06-13 10:19:19
I think you read the game-theory correctly.
It is actually preferable if users choose, and the main way to do that is with a wide-spread consensus hard-fork such.
But compared to a controversial hard-fork which is different, almost anything is better than that because there's a real chance of destroying bitcoin with the network being diverged.  This is why its important for hard-fork discussions for people to be collaborative, constructive and not threaten contentious unilateral actions.
I do think an extension-block still preserves user choice quite well because no change is made without user permission, and different users can opt-in to different size extension-blocks, including NONE and staying on the 1MB chain.
And the fact that its soft-forkable shows that we are not forcing anything that miners cant already do.  They could go implement and deploy extension-blocks today.  And if no users liked it, that would be fine, it would just have no users, and no one would be put at risk of network-fork etc.
A hard-fork we the users have to reach consensus on and upgrade together voluntarily, *and that is a feature*.  (Absent unilateral threats where people may feel compelled to capitulate to avoid forking the network).
Extension-blocks also have the advantage of keeping even for the very long-term an increasingly decentralised base (1MB block gets network cheaper over time).  Without the ability for multiple block-size choices we are *forced* to make lose-lose compromises where we get neither optimal decentralisation security *nor* optimal scale.
@_date: 2015-06-12 12:03:09
I described to in private email that its obvious what to do to get closer to consensus: work collaboratively and post a BIP on bitcoin-dev and iterate from there.
You mention what is the hurdle for consensus.  Let me say this, currently this is what happened, tell me if this is not working as hard against finding consensus as humanly possible?
- Chief Scientist going to media (he did not post a BIP, nor discussion on list first)
- bypasses 4yr established process he used before
- threatens to imminently fork the codebase
- lobbies companies in private to adopt proposed code fork
- ignores or downplays divergence risk, which is dangerous beyond belief
So you say how do we make the decision making process work?  Yes please, people in bitcoin core have been trying for the last year!  The person you need to talk to about this is I believe that the fully understands the risk and is gambling that every one else chickens out.  However as I wrote below that is itself a very dangerous gamble (if that fails Bitcoin is dead basically) and sets a *really* bad precedent.








@_date: 2015-06-13 10:04:18
An extension-block is not a sidechain. Extension blocks were proposed some time ago first on   See other comments for more explanation of the difference between extension-blocks &amp; side-chains.
@_date: 2015-12-12 20:57:59
Well the soft-fork script upgrade feature is separate from whether segregated witness itself is introduced via soft-fork or not.
So I think the main advantage of soft-fork is it gives some size increase as a soft-fork, and can probably be done faster as it's a simpler upgrade process that we have more experience with.
It was known that you can soft-fork block-size increases via extension-blocks, however that is more complex.  It's more surprising that you can soft-fork segregated witness and get some size increase out of it, the segregated-witness soft-fork is a simpler and different mechanism.
@_date: 2015-06-13 11:33:42
I am sure you could combine things in various ways.  
I am not sure it would still be particularly important to change the base blocksize via hard-fork, once you had the option of soft-fork 10MB or 100MB or whatever you want multiple-parallel extension-blocks.  By comparison hard-forks are risky and slow and require coordinated software upgrade to avoid people losing money.
The pressure to hard-fork once extension-blocks were deployed I think would be close to zero.  People would have a future-proofed way to grow and make security/decentralisation trade-offs still secure in the knowledge there exists a very decentralised core (and increasingly decentralised as bandwidth improves).
But hypothetically you could hard-fork later (not sure why).  Or you could hard-fork a 2MB bump to give time to implement extension-blocks.  
However even that I am not sure makes sense because we may easily be able to deploy extension-blocks faster than a hard-fork. This is because its divergence-safe and so (once implemented) you can safely deploy extension-blocks immediately, whereas a hard-fork has a long lead time (I think 1 year was proposed) to avoid people and businesses accidentally losing all their money by not being prompt to upgrade everything.
@_date: 2015-06-28 23:52:54
Again I love reddit.  Posts bike-shedding block-size choice without understanding the security/decentralisation tradeoffs, game-theory etc.  What 10,000 by now?
Views on Joseph Poon talking about lightning - actually scaling blockchain: 70.
@_date: 2015-06-12 23:41:40
its still mind boggling complex but Rusty Russell (maybe on reddit but dont know handle) has a 4 part blog post explaining quite well.  
@_date: 2015-06-27 20:38:07
He was probably not aware of the 250kB soft-cap and the 750kB soft-cap which still exist in some miners in the network.  But people without facts usually speak louder.
@_date: 2015-06-13 10:10:07
Kind of.  The layer-1 money to layer-0 full-nodes looks like a big single transaction controlled by a script they dont much understand.  But they can accept money from it (thats how backwards compatibility works) and they can send money to it (thats how forwards compatibility works).
@_date: 2015-06-13 10:07:33
This is true.  However note also from the top, a soft-fork (once implemented) can safely be rolled out immediately.  A hard-fork even Gavin's version had a 1 year lead time to at least limit chances of people being unaware and accidentally just losing all their money by not upgrading.  
So that may mean a soft-fork extension block can provide scale faster also as well as safer (no network divergence risk), as well as being opt-in so that no one is forced to compromise over whats best for their use case, and also more secure because a high security/high decentralisation (small block) remains available.
@_date: 2015-06-13 12:44:16


because there is a phantom single large address in the 1MB space that looks to 1MB users like who they paid.  It is only 20MB users who will know whats going on inside that.


All 20MB nodes are also 1MB nodes.


No its a unified chain just in two tiers with possibility to delegate validation if you dont have bandwidth via pools.
@_date: 2015-12-31 00:45:03
OP links to new option A  which documents consensus to move forward on segregated-witness 2MB soft-fork and a roadmap stretching beyond.


beyond that - bitcoin core reached consensus and is working on the plan. maybe that wasnt clear enough as the link OP posted to was the actual statement of that! and yet he posed it as a question.
@_date: 2015-06-13 09:41:08
No see further up extension-blocks are different from sidechains.  They are a direct extension, not a separate chain.  They are directly understood and secured by bitcoin miners (sidechains rely on SPV security of sidechain merge-miners).
@_date: 2015-12-15 19:06:36
I mean is working full time on lightning at blockstream, and Joseph Poon and Tadge Dryja are collaborating on mailing list, github, IRC etc on lightning design.  And so are a few other companies.  Lightning implementation and protocol work is an interoperable FOSS project with multiple participants.
@_date: 2015-12-07 03:58:41
see also discussion on 
@_date: 2018-08-30 17:23:44
But you have to write the seed down either way, so really how much difference does it make? The only way I see it being easier is a larger screen or people doing inadvisable things with their seed, keeping online electronic copies.
Your device generating experience should be similar to trezor, ledger, coldcard which specifically avoid the risk of generating keys outside the device.
@_date: 2015-06-15 23:27:01




I'm curious why you found that convincing, it looks a lot like a strawman argument to me.
read the section on (search) Scalability Plans
Does that sound like people do not want to scale bitcoin?  Or that scalability work is not already ongoing within the existing code change governance process?
@_date: 2015-06-15 01:01:55
has a 4 part blog explaining 
basically the hub has to be well capitalised and have funds locked to all outgoing connections.  It sounds heavy but the channels are reversible unlike micropayment hub channels.  And there is some clever scheme where users can maintain connections to multiple hubs and if a hub runs out of capital it can pay users via negative fees to rebalance a different channel to recapitalise so that funds can move around longer before having to go back for a fresh anchor transaction.  The other innovation is the relative CTLV which means the channel can last indefinitely because the expiry clock doesnt start until the reclaim transaction hits the chain.
@_date: 2015-06-12 13:15:56
It is not sound engineering to expose the network to divergence risk.  That is madness.  Everyone technical is shocked and dismayed that Gavin particularly would go there, though Mike would be unsurprising as he's talked publicly about having a more data-center centric view of scalability (which I dont think is really compatible with bitcoin's p2p security model).
@_date: 2015-06-28 18:28:40
Certainly agoric computing is interesting in the generic anti-DoS property that it provides, eg that a DoS becomes a profit making opportunity.  However do note that data-center bandwidth in bulk is much cheaper than consumer bandwidth.  Consumers can rent VPS and hosts in data-centers too of course, but that does itself lead to some form of centralisation.  Eg if we have 1000 nodes in amazon EC2 run by various people we have much lower decentralisation than if we have 1000 nodes run from various power users and home/garage miners.
But yes agorics is interesting, and I think it should be explored once we have lightning to make that viable.
You may know that mojonation tried to do this (agoric p2p grid for storage and anonymous publishing) back in early 2000s.  Bram Cohen (bittorrent) and Zooko (tahoe LAFS) worked there and you can see elements of it in bittorrent's tit for tat accounting model.
Hmm this is far too constructive.  Shouldnt we be joining the 1TB blocks now rant? ;)
@_date: 2015-12-04 00:26:49


Actually that is quite innaccurate, I am assuming you are not reading the right forums, but eg BIP 103 and 102 have been implemented for months and similarly the BIPs being presented this weekend have implementations.
Anyway watch the live stream.
@_date: 2015-06-13 10:11:21
Tier Nolan wrote something up, which on the same proposal with a bit more script detail.  
@_date: 2015-06-28 23:58:27
None.  Well it'd be kind of nice if Gavin would publicly retract the Bitcoin-XT fork threat, that's not helpful - it's dangerous and controversy is the opposite of what you want for something already inherently as risky as a hard-fork.
Then I guess people should review the proposals, code the best one and deploy it.  QED :)  That's what people are trying to do on bitcoin-dev between being getting sucked into the block-size bike-shedding vortex.  There's a bunch of proposals:
@_date: 2015-06-12 20:07:39


Lets keep it simple by talking about 1MB main chain and 20MB (extension block).
So as a principle you often do not know how the recipient is storing his private key, what his script to redeem the coin is (because of P2SH addresses which hide the script until you spend).  You may know or not, but its not your business or problem, because after that its his coin.
As a 1MB user to send to an address you just send to it, you dont care whether its in the 1MB or 20MB chain.  So that allows the 1MB user to send to an 20MB user (even if the 1MB user is using software that doesnt know about 20MB extension blocks).
When an 20MB block payment is sent to another 20MB block address, the client knows about it and the transaction goes in the extension block, giving lower decentralisation assurance, probably lower fees.
When an 20MB block payment is sent to a 1MB user it is taken from the pool of extension coins that to 1MB non-upgraded users looks like it holds all coins and a 1MB transaction is made, but to 20MB aware clients, fullnodes and miners they know it has coins with separate ownership tracked in the 20MB merkle tree.
For mining miners either mine 1MB blocks only or they mine both 1MB+20MB blocks.  If miners are running their own full node and solo mining (quite rare) and they would like the extra fees from the 20MB transactions, they could pool mine the 20MB transactions and solo min the 1MB transactions.  In any case pools would likely upgrade for the extra transaction fees so non-power users wouldnt actually notice the difference.


20MB miners and 20MB full nodes are watching both, and will orphan blocks with invalid transactions in them.  They wont happen often because thats a way to lose 25BTC.  1MB miners can check with other nodes or a pull for an opinion or pool mine the 20MB to get extra fees even if they dont have the bandwidth for 20MB.
@_date: 2015-12-01 15:10:47
Good suggestion IMO.
@_date: 2015-12-19 13:27:33
What made the internet a runaway success was network-effect and permissionlessness so 1000s of startups and coders could find the killer apps - it is hard to outcompete that kind of leveraged self-reinforcing advantage.  It seems doubtful that the bank chain things will be open nor permissionless.
@_date: 2015-06-15 23:30:44
Not sure if that indicator is reliable.  is exactly right in his characterisation of the situation.
@_date: 2015-06-30 19:58:00
@_date: 2015-06-28 22:45:50
I had replied to that on the list before seeing someone copied this conversation here.
On 28 June 2015 at 23:05, Gavin Andresen &lt;gavinandresen at gmail.com&gt; wrote:














Its a source routed network, not a broadcast network.  Fees are
charged on channels so
DoS is just a way to pay people a multiple of bandwidth cost.
in terms of trustlessness Andrew Lapp explained it pretty well:




















Gavin wrote:


I gave it a go a couple of posts up.  I didnt realise people here
proposing mega-blocks were not paying attention to the whole lightning
concept and detail.
People said lots of things about how it's better to work on lightning,
to scale algorithmically, rather than increasing block-size to
dangerously centralising proportions.
Did you think we were Gish Galloping you?  We were completely serious.
The paper is on 
though it is not so clearly explained there, however Joseph is working
on improving the paper as I understand it.
Rusty wrote a high-level blog explainer: 
though I don't recall that he got into recirculation, negative fees
etc.  A good question
for the lightning-dev mailing list maybe.
There are a couple of recorded presentation videos / podcasts from Joseph Poon.
sf bitcoin dev presentation:
epicenter bitcoin:
There's a related paper from Christian Decker "Duplex Micropayment Channels"




We don't need to convince people, we just have to code it and
demonstrate it, which people are working on.
But Lightning does need a decentralised and secure Bitcoin network for
anchor and reclaim transactions, so take it easy with the mega-blocks
in the mean-time.




maybe you want to check in on
and help code it.
I expect we can get something running inside a year.  Which kind of
obviates the burning "need" for a schedule into the far future rising
to 8GB with unrealistic bandwidth growth assumptions that will surely
cause centralisation problems.
For block-size I think it would be better to have a 2-4 year or one
off size bump with policy limits and then re-evaluate after we've seen
what lightning can do.
I have been saying the same thing ad-nauseam for weeks.




Not nearly as big as if you tried to put the transactions it would
enable on the chain, that's for sure!  We dont know what that limit is
but people have been imagining 1,000 or 10,000 transactions per anchor
transaction.  If micro-payments get popular many more.
Basically users would park Bitcoins on a hub channel instead of the
blockchain.  The channel can stay up indefinitely, and the user has
assurances analogous to greenaddress time-lock mechanism
Flexcap maybe a better solution because that allows bursting
block-size when economically rational.
Note that the time-locks with lightning are assumed to be relative
CTLV eg using the mechanism as Mark Friedenbach described in a post
here, and as implemented in the elements sidechain, so there is not a
huge rush to reclaim funds.  They can be spread out in time.
If you want to scale Bitcoin - like really scale it - work on
lightning.  Lightning + a decentralised and secure Bitcoin, scales
further and is more trustless than Bitcoin forced into centralisation
via premature mega-blocks.
To my mind a shorter, more conservative block-size increase to give a
few years room is enough for now.  We'll be in a better position to
know what the right next step is after lightning is running.
Something to mention is you can elide transactions before reclaiming.
So long as the balancing transaction is correct, someone online can
swap it for you with an equal balance one with less hops of
intermediate payment flows.
It's pretty interesting what you can do already.  I'm fairly confident
we're not finished algorithmically optimising it either.  It's
surprising how much new territory there is just sitting there
@_date: 2015-06-28 23:49:46


OK, I take that back then.  You do know what a payment channel is.  Just the rest of your comments seemed at odds with that understanding:


Because that is *exactly* what we do to solve the scaling of the network.


You mistake the block-size issue for conflict of interest - it has nothing to do with interests.
I never said dont increase the block-size.  This is like the 5th time today I've quoted what I wrote 2 weeks ago:




underway, and education)










point 2 is me saying lets increase the block-size (conservatively) to make time for people to work on lightning and similar things.
@_date: 2015-06-12 10:00:27
Right.  But as if Satoshi couldnt or wouldnt be lurking and would need a status update.  You actually can go read the leaked Mike-&gt;Satoshi one-way emails, they're online somewhere.  (Came from Satoshi's GMX web mail account getting hacked).
@_date: 2015-06-28 12:16:03


Because global (and per node local) cost per transaction is increasing as the number of users grows.  Once the cost exceeds the transaction value it wont make sense.  It seems likely that the level of centralisation implied if the only scaling "work" is to increase block-sizes only, and algorithmic improvements rejected, will create policy neutrality breakdown/fungibility and security problems before that.


An economically dependent node is when where it's operator is only accepting transactions considered valid by his node.  For example a merchant, or a power user.
@_date: 2015-06-13 14:23:01
I think means that extension-blocks show that miners can unilaterally increase block-sizes via soft-fork rather than having the users decide via a hard fork which requires user-consensus.  Its a form of ceding control to miners where its in principle better to have users choose by consensus.
Another aspect of proposing extension-blocks is if people are going to fold to a contentious hard-fork that's far worse than having miners give users more choices.
There maybe an aspect of defacto centralisation if users dont care and use poor tradeoffs (eg if a cartel of centralised miners set up 1GB blocks with few who can validate at all or something).  Users using that would be a bad choice.  Almost to users using custody wallet services level of bad choice.
On the other side there are many positive things about extension-blocks: that miners can not change the size of the existing main block, so that remains with a good security/scale tradeoff to ensure bitcoins user ethos &amp; social contract properties are robustly enforced.
And also fixing the one-size fits-all lose-lose situation where the hard-fork approach by having a single fixed block-size we are always going to end up with neither robust decentralisation nor high scale.
Note we could even create smaller extension blocks (100kB, 10kB).
@_date: 2015-06-14 11:27:52


It depends on your assumptions, but dont forget that O notation ignores constants (even multiplicative ones so that O(n) == O(c*n)).  Lets call u users, and I have been saying its approximately an O(u^2) network, here's a rationale which gets there:
If we call n the number of nodes, and t the number of transactions, then clearly the total bandwidth cost is O(n*t).  Then we move onto the relationship between 1. users and nodes, and also 2. users and transactions.
1. The number of economically used full-nodes today is maybe 5000 (probably less) for say 5mil users.  So if we say thats a constant factor - 0.1% of users + hopefully all Bitcoin businesses run full nodes.  Assumption 1.  That says n grows with O(u).
2. We can say as you do also, that while Metcalfe's O(n^2) law about value of a communication network may not apply to bandwidth in a payment network, because of the small-worlds hypothesis, still some kind of super linear function applies, because there are multiple positive reinforcing feedback loops: as we get more users, more people economically interact, as the network becomes more valuable more developers and startups add more apps and types of transactions, etc.  So what ever you believe its sub-quadratic (not full metcalfe's probably) but still reasonably justifiable as a super-linear function f, so the number of transactions t = O(f(u)).  Assumption 2.
Putting it all together we can see that we have bandwidth = O(f(u)*u) which is more than O(u^2).  If reasonable people disagree with Assumptions 1 or 2 in either direction, we can say ok lets be conservative, cancel them out as an estimate and we are left with O(u^2) aka O(n^2) as a reasonable model of bandwidth costs as the number of users grow.
@_date: 2015-12-01 14:43:31
On the schedule there are a range of BIPs being presented.  
Good question about review committee, I am not sure who is on it, but I will ask someone from scaling bitcoin to comment.
I do not believe anyone is stalling FWIW, there was quite a bit of protocol analysis, review and coding/development work that went into the proposals.
@_date: 2015-06-13 09:20:56


So the money flows from user to hub, on alice to mtBox channel, and mtBox keeps it.  Then using its own money, the hub (mtBox) sends the same amount (but not the same coins) to the Tesco on the mtBox-Tesco channel.  The hub could chose to send your money also to Amazon, but it would lose money if it did so because that comes out of its own pocket on a separate mtBox-Amazon channel.
@_date: 2015-06-13 11:42:48
Oh yeah :) Sorry that maybe was not clear.  Its soft-forkable, so you can do it again and again in parallel with different blocksizes.
Lets say a 10MB block and later a 100MB block, and then another 10MB block for some reason (eg you could add some opt-in features in a same-sized extension block).
As long as you keep it generic and only the size changes I think you can add more extension blocks later without even updating clients.
@_date: 2015-06-13 12:22:35
In terms of paid fees it costs miners nothing.  Its not even detectable.  If miners can squeeze the fees up without detection that may even be a game-theory schelling point for them to just do that without direct collusion.
Yes there are some sanity limits from meta-incentive of the mutual interest in bitcoin - if miners overdo it users will quit bitcoin.  But this is what business do all the time - figure out the switching costs of users and push them to that line and not beyond.
I am not sure its very robust game-theory to assume the meta-incentive pressure on miners is particularly strong.  For example if users go else-where they abandon bitcoin.  Maybe they really like and value bitcoins properties and tolerate being fee gouged quite significantly as fiat is hugely inferior.  Or the more price sensitive users stay in bitcoin but go off-chain to amortise fess and so receive weaker assurances.
As a statement of intent I'm sure we'd all like for bitcoin users to receive reasonable fee pricing, enough to pay for a good security margin in mining (factoring in subsidy for now) and for bitcoin to scale really far so that all users who are interested can benefit from the useful properties of bitcoin as possible.
I do think algorithmic improvements like lightning are probably needed as we get into the higher scale, otherwise we either end up with a single super-computer or a very centralised cluster of dark-fiber connected boxes and a trust-me solution which is basically a bitcoin failure mode where it becomes the same as the status quo.
@_date: 2015-06-30 15:59:49


I am not aware of any sybil attack that could steal coins in Lightning.  Clearly you need the right address for the person you are paying, but that is the case inherently with Bitcoin, and lightning uses Bitcoin addresses (and a payment route via some number of hubs).  You do not have to trust a lightning hub to not steal your funds.
The reason fees increase for miners is that many more layer 2 transactions become possible per on-chain anchor/reclaim transaction so even though users are paying smaller fees, in total miners can receive higher fees.
I think also that trying to achieve that volume on-chain is impractical, or would happen far slower.  If we could get immediate headroom that would be more attractive also to those people who hold hope of microtransactions being a popular use case.  I do think there is quite some scope for this area: near instant, secure, any-to-any microtransactions could be interesting as a supplement or replacement for the ad-revenue model.  eg it can be the case that users are at a point where they'd sooner pay a tiny micropayment at a level below active decision based on browser metrics, to avoid the annoyance of advertisements they would essentially never click on.  You can see the trend in the fact that adblockplus now has started charging companies to let select advertisements bypass the blocking!
@_date: 2015-06-28 10:31:48
Changing throughput parameters is a security and decentralisation tradeoff. Bitcoin relies on decentralisation to provide it's useful properties.
If you disagree, you need to justify and explain why you think everyone of the core developers is wrong. If you have a clear and scientifically validatable argument, they will listen.
I can be working in your interests, without you understanding the tradeoffs.  No thanks required.
@_date: 2015-06-29 19:20:01
@_date: 2015-12-07 04:30:21


Code for seg-witness soft-fork: 
@_date: 2015-06-13 18:58:13
I think would say that there is a meta-incentive for miners not to do that in the sense that if users dont like it they may apply economic pressure by leaving the system and causing BTC price to fall, which miners are quite exposed to.  However its common in some areas of business for the businesses to figure out the switching cost of users, and ramp up fees (or in this case ramp up capacity = blocksize * fees) to just below that switching cost.  What we dont know is if that switching cost will still enable a power user to audit the chain.  If power users cant audit the chain, bitcoin can easily lose it's differentiating features - miners or pools are by then more centralised as a result of the same choices, and more susceptible to policy abuse.
This is why I prefer extension-blocks, even if we had to get there in two stages (via a kick the can but down the road but, hard-capped hard-fork).  At least then we have much stronger assurance that bitcoins user ethos properties will be robustly defended for the future for those who value them.  And users who are making cups of coffee payments dont need them as much, so the same user may use different trade-offs for different types of bitcoin storage (savings, vs retail vs micropayments).  Also even the threat that the affected users can react by moving to a more decentralised extension-block (or the base 1MB chain), may deter even trying the abuse.  The streisand-effect will render it useless anyway as users will have a way to evade the bad effects of it.
btw Another user pressure is the threat to have a user-led hard-fork leaving the miners with useless hard-ware by changing the hash-function, the so-called "big red button" option.  However as people have been discussing hard-forks are risky, so this may be a not-so-realistic threat or things would have to be *really* dire before people would seriously contemplate it such that it would likely not create much back-pressure on user-interest disregarding parameters.
The main selling point of extension-blocks is it is *much* more free market, as it lets users pick their own security/scale trade-offs and pay for the fees in them accordingly (more decentralised are going to cost slightly more).
I think there's a some amount of keynesian macro-economics assumptions in letting the miners vote for the block-size - the assumption that will create headroom and low fees.  In fact it may not achieve that even, because miners may prefer smaller-blocks to maximise fees due the switching cost being probably high.
Miners could obviously have a go at censoring extension-block creation, so there are miner good behaviour dynamics lurking everywhere.  (Like observation you mentioned earlier that miners could censor block-size votes the dont like).
@_date: 2015-06-28 10:28:56


That is not a coherent argument.  Changing througput parameters is a security and decentralisation tradeoff.  Bitcoin relies on decentralisation to provide it's useful properties.
If you disagree, you need to justify and explain why you think everyone of the core developers is wrong.  If you have a clear and scientifically validatable argument, they will listen.
@_date: 2015-06-27 20:39:12
As I recall I was talking about the risk to Bitcoin posed by a controversial unilateral hard-fork.
Pressure for what?
@_date: 2015-06-22 22:06:52
Actually, FWIW, what Bram said is true, Gavin did not much work on bitcoin-core since then.  Go check the github for yourself.  Probably busy with the bitcoin foundation issues, and also researching IBLTs (network compression for faster block transmission).
@_date: 2015-06-13 20:18:53


Well there is a proof of that (by existence) that it could be done with ZK-SNARKS.  So the real hunt as you indicate was can it be it be done, and done efficiently enough with conservative crypto.
Whats new here is that this math is making no new novel crypto assumptions (assumes only the same crypto building blocks as bitcoin), and is provably secure.
Actually the privacy can be configured to be unconditionally secure which is a kind of surprising and fun result.  Meaning no amount of compute time in the future will ever be able to tell what value your transaction is because even with ability to compute discrete log in the blink of an eye (in a hundred years time with a computer the size of a planet) all it can see is that all possible values are possible.  This is because there is a solution for V=xG+vH for all possible values of v.  Right now you cant solve them, though you can easily create hashes of that form.
Whether thats actually really the case depends on fine print like your pseudo-random number generator and other choices.  But it gives an indication that the value privacy is pretty good.
It relates to this 2013 bitcoin-talk post -  -  but with some awesome new optimisations, and even signature generalisations - the borromean signature  from @_date: 2015-06-17 07:46:17
Well said.   Thank you.  Here's similar assertion I made in one of my posts to bitcoin-dev:




@_date: 2015-06-30 23:05:41
Well I think it was more of a rejection but please no more than 8MB or you'll kick us (or yourselves in fact) off the network, eg:
@_date: 2015-06-27 20:06:06


Think you're misremembering a conversation there. I have said, as I think others have observed, that if Gavin pushed *Bitcoin-XT* against the advice of everyone else with a technical understanding, and it corrupted the Bitcoin ledger causing Bitcoin to fail, well yes everyone interested in Bitcoin, including yourself, would be upset.
@_date: 2015-12-19 12:51:31
Maybe an analogy would be early days of internet where companies were making intranets because they had not yet understood the network-effect and benefit of open networking.
@_date: 2015-06-13 21:16:09
The techcrunch article by  is 
And the lightning-dev mailing-list code release notes by is 
github is 
four part lightning explainer by lightning paper by Joseph Poon (and Thaddeus Dryja) 
@_date: 2015-06-13 16:53:15
Link works for me?
The post is:
Hi all,
        There are three major parts to the Lightning Network.  One is
generalized channels, the second is Hash Time Locked Contracts, and the
third is routing and network discovery.  I've hacked up some strawman
proposals for the first (and easiest) part:
        
This is currently Google protobufs proto file and an ugly grab bag of
cli utils which can generate them to sanity check.  It "works" on
testnet via two hacks:
1) We share the anchor sigs early to get around the
   sign-child-before-parent problem.
2) Instead of using OP_CHECKSEQUENCEVERIFY we use a OP_NOP.
What happens from here?
In the short term:
1) People who read the code feel slightly ill.
2) When they recover, we start discussing and merging improvements.
3) Move to the Blockstream Alpha sidechain where the above hacks are
   unnecessary[1][2]
In the longer term (getting vaguer as we go):
1) Implement channel anchor update.
2) Implement HTLCs.
3) Implement a real daemon.
4) Implement routing.
5) Collect CVEs, goto step 1.
[1] I hope to keep a  BITCOIN_TESTNET or something to allow
    testing on both, at least for the moment.
[2] The alpha sidechain has cut-down txids which is great for the
    anchor signature problem, but the solution for bitcoin will have
    to be something different as that change is not soft-forkable.
@_date: 2015-06-13 10:29:25
Exactly.  Extension-blocks also are able to offer slightly better security than side-chains because the bitcoin miners are aware of it, and validate transaction rules.  With side-chains there is more flexibility and a security firewall so that people can do radical rewrites of chain logic in the side-chain (eg vastly different things like Confidential Transactions (which we implemented in the alpha chain) or ZeroCash or SNARK smart-contacts or an Abstract VM script language etc); and this flexibility has a security cost of separating the validation for the chain - so only side-chain miners are aware of it, and bitcoin miners wouldnt know whether to reject a block that had an associated invalid side-chain block.
With extension-blocks its just another data-structure instance of the existing chain logic but with a bigger block-size parameter, its in-chain and miner and full-node validated.
@_date: 2018-08-31 11:03:35
Bear in mind no other recommended wallet on the market trezor, ledger, coldcard, bitbox2 does this. It will for sure hurt sales because technical reviewers will see it as a red flag and advise against buying what is otherwise a pretty cool looking alternative. @_date: 2015-06-13 22:08:28
Maybe.  Incremental is generally good.  I think the main pushback from bitcoin devs to increasing block-size is the weak state of decentralisation.  People have been working on it, but we should push to improve that in parallel to create security headroom.
@_date: 2015-06-13 11:08:18
What was saying is that scale to broadcast a single transaction is O(c*n) where c is a constant accounting for the gossip broadcast fanout and n is the number of nodes, and so that is written O(n) however n is the number of transactions.  If you account for transactions (n) and nodes (m) its O( n*m ).
If we look instead at the number of users and presume transactions are somewhat-linear in the number of users (because of Metcalfe's law, the weaker version assumed to hold in payment networks due to small-world hypothesis vs full version for communication networks) its probably more like O( n^2 ) where n is the number of users.  The number of nodes will probably increase and each user tends to send more payments, the more of his contacts and the more applications etc that are driven by higher scale, like tipping, exchange traffic, IoT, etc etc.
@_date: 2015-06-12 20:25:02
I am not sure about Tier Nolan's auxiliary header BIP, but coincidentally Tier also proposed extension blocks: 
I'm not actually sure if he is explaining the proposal, or reinvented the same idea.  When people start reinventing things sometimes it indicates its time :)
@_date: 2015-06-14 10:18:22
I dont think so.  Bitcoin main chain should remain the most secure and master chain by technical definition of what it can offer.
Offchain things are not chains sure, but they still defacto are competing with main chain transactions: probably 99% of transactions are off-chain in exchanges etc.  If bitcoin could scale to handle that load, thats forgone fees for bitcoin, being collected by exchanges.
Fees on side-chains go to miners, miners seem to be OK with that.  Side-chains are not a proprietary technology.  If side-chains were a proprietary technology and Blockstream were collecting fees from it then there would be a conflict of interest but neither of these things are true - we're just working to improve bitcoin and enable more types of transactions.
If you want to talk about fees leaking out to other networks - I think you want to complain about lightning.  However given that Bitcoin has O(n^2) scaling I dont think the tech community has many options other than to try to make algorithmic improvements like lightning as a (write-coalescing) write-cache layer.  Thats still basically part of bitcoin the same as the ram cache on your disk is part of your disk etc.  Btw lightning can only cache for transactions that are valid on the chain its cacheing for.
@_date: 2015-06-13 11:11:40
I think whole world bandwidth use is relevant and whether bitcoin would even be feasible with dark-fiber links or a single super-computer.  Never mind whether bitcoin could retain decentralisation security or real-time audit by full-nodes run by power-users.  Take a read of the lightning paper, they do some calculations with multi-hundred GB blocks to show what it would take to support various types of existing transactions.
@_date: 2015-12-07 02:48:42
Seems like a win-win.
@_date: 2015-06-13 14:04:24
is good at game-theory.  Sometimes he even uses it on others, I suspect.  Sometimes find myself wondering if some of his proposals have hidden messages or undisclosed strategic intent :)  Keeps the mind sharp at least to watch.
@_date: 2018-08-30 21:23:51
you can do recovery on device with the later firmware of trezor one also. just it is hard to do without error because of the small screen and two button procedure. trezor one can recover a 12 word seed also, it just wont generate 12.
@_date: 2015-06-13 23:57:35
So a sidechain (the one-way peg version) was first proposed as a way to upgrade the network to a major new version.  Still with the 2wp version it could possibly used in that way.
Say people work on a bitcoin 2.0 in parallel with 1.x and test it on a sidechain with live coins.  They do a major refactoring which would be too risky or basically impossible with a series of hard-forks on the main chain.  Once its stable, has held $1b happily for a long period of time, maybe it could become the new main chain.  (Or subsidy could be paid directly into it, and the old main chain continue just with empty blocks).
@_date: 2015-06-13 11:18:00
Thats well articulated, but I dont think its quite right.  Its better than a single 20MB hard-fork for security because if you dislike the centralisation risks of 1MB block transactions you dont have to use them.
A lot of bitcoin validation is done by pools and business run full-nodes.  Its not a big deal for them to upgrade to 20MB.
But you can still validate things on the 1MB block, and you can delegate validation to pools or cross-check if you want to check 20MB blocks.
You can also validate 20MB blocks even if you think its in-advisable and would keep your own coins on the 1MB block.
You can be a 1MB preferring user while still upgrading your software.
@_date: 2015-06-29 20:20:31
The hubs compete for fees, and are paid by the sender (or recipient).  Users also can be hubs.  There is competition so there would be multiple routes, going via different hubs.
Lightning depends on transaction malleability fixes.  The sidechain elements alpha network has both of the features needed for lightning implemented transaction malleability fixes and relative Check Lock Time Verify.  Those features could be back-ported to Bitcoin, relative CLTV more easily than malleability fixes.
@_date: 2018-08-30 16:53:40
OK glad to hear you can do it on the device.
Why is it convenient to do it on android? 
That just invites people to cut &amp; paste, take screen shots, email it to themselves, store it in dropbox / google docs or image on the phone and get hacked.
@_date: 2015-06-12 13:42:47
I'm sure people with 10s of millions of VC money to excite people about and scale bitcoin would help-themselves by adapting their software, as they are keen for more scale, they will want to plan ahead.  It wont be like they have to write the protocol, just apply a patch or update a library.
@_date: 2015-12-13 06:06:26


Yes versionBits itself is a soft-fork.


Well say we want to deploy soft-fork:
1 versionBits
2 segregated witness
3 RCLTV (aka CSV aka MATURITY)
what order should we use, I suspect the above is reasonable, because people are still working on lightning, and I think they are not blocked, so long as RCLTV comes online in good time they wouldnt have a problem.  Eg we can have a test net that has the feature early.  And there are some less efficient lightning configurations that do not need RCTLV.
I wouldnt mind segregated witness coming first personally if that gives the scale improvements a month or so earlier.  I think the advantage of versionBits first is that RCTLV and segregated witness could be soft-forked in parallel then.
@_date: 2015-06-07 20:08:27


correct answer one.  (until libbitcoinconsensus is done).
Otherwise what you get is not decentralisation but fork failure.  (Its generally very very hard to have bit-level identical consensus behaviour from different implementations, or (slightly worse) different languages).
I would give that one decentralisation score of -100.  (Do that and propose lots of miners or ecosystem players or full nodes use it and you risk blowing the system up by major fork).
@_date: 2015-12-14 15:28:58
I believe people think one way it could go could be (some example numbers, likely higher scale):
100 more transactions 10x cheaper fees, still results in 10x higher fees on chain.
so then you have a kind of insurance situation: there is a small chance you may have to pay 10x normal fee to reclaim a transaction prematurely.  That could be fixed via insurance.  It is possible to trustlessly and securely delegated some lightning actions to services, which could do insurance pricing making the price including reclaim cheap and predictable.
Another issue which you have not talked about is if the reclaim expires before you can get it into the block you could have a problem.  Potential solutions to that have included timestop (the time doesnt count towards expiry when blocks are full)
@_date: 2015-06-28 22:54:04


actually lightning was proposed by Joseph Poon.  Check out the presentations
sf bitcoin dev presentation:
epicenter bitcoin:
Christian Decker also proposed something similar duplex micropayment channels:
lightning is a FOSS project, a write cacheing layer for bitcoin.  If it works as people think it will, I'd assume it would become a bitcoin component.
You know blockstream is actually just trying to improve Bitcoin right?  The people in blockstream, who founded it, wrote their own employment contracts to try to guarantee independence on core work,  etc are core developers who've worked on bitcoin for years.


I have been saying this for weeks.  eg take a look at  


























I have been saying scale bitcoin incrementally for a few years so the dev community can see if lightning delivers what is expected.  Then after a couple of years we'll know better what to do next.
@_date: 2015-06-15 23:17:10


Thank you.  I can assure you you are right and that iI do not have a hidden agenda.


I dont think you can kick the can down the road repeatedly on an broadcast network, or you either hit the O(n^2) scaling wall or you centralise it to the point it doesnt make sense, wherever comes first.
But I do think I am pragmatic, just not dangerously so, is this pragmatic enough for you?
(search for "Scalability plans") 


work to improve decentralisation (specific technical work already underway, and education)
1. create a plan to increase block-size in a slow fashion to not cause system shocks (eg like Jeff is proposing or some better variant)
2. work on actual algorithmic scaling
3. In this way we can have throughput needed for scalability and security work to continue.








(and rest of that Scalability plans section)
Is that pragmatic enough?  I am thinking the post was too long and we're into TL;DR territory.
@_date: 2015-12-01 13:54:33
Yes.  Well reddit has karma points overlaid on it in some way to try to improve that.  However I believe there has been analysis to suggest that is also being gamed via various techniques.
@_date: 2015-12-12 15:41:56


A new soft-fork being considered is versionBits, that allows up to 30 different soft-forks to be deployed in parallel.  That could help get deployed OP_CSV, segregated witness and other features faster during 2016.
@_date: 2015-06-13 22:39:52


I agree.  The dynamic limit prevents uneconomic games via miner pay-to-self dummy transactions, because they have to pay quadratically in PoW to increase block-size.  But still maybe the demand outstrips decentralisation safety.  I think articulating that this is a problem that should be controlled somewhat will upset some people, but they maybe interested then to think about extension-blocks (or other things in that direction) for the mid-term.  And to focus on scalability rather than throughput eg lightning, segregated witness, sharded validation via UTXO commitments and fraud-proofs.
agrees also and he explained the additional idea on the same thread as write up there is  a bit dense but its the same as what used basically which is that you use the 25% percentile (half way between 0 and the median), and in version some hysteresis so it falls back if the size cap is not used.
@_date: 2015-06-13 09:42:42
Read the summary of properties at top of post.  It does not require rewriting all wallet software on day one.  It can be incrementally deployed by those who claim they need a bigger block.  It is backwards and forwards compatible.
@_date: 2015-06-28 10:57:49


I like merits, technical discourse that results in better algorithms or code that materially improves Bitcoin is useful.  Obviously if someone who evidently doenst understand tradeoffs gets up on a soapbox and makes a lot of noise about doing something inadvisable, you can surely expect people who disagree to have equal right to speak up and explain that this guy isn't understanding the technology tradeoffs?
As you've seen I'm very happy to hear any range of input.  Insults I can happily let slide - been through enough USENET flamewars before probably most of you guys were born :)
So bring it on - lets see some useful discussion.
@_date: 2015-06-27 19:59:28


Think you're misremembering a conversation there.  I have said, as I think others have observed, that if Gavin pushed Bitcoin-XT against the advice of everyone else with a technical understanding, and it corrupted the Bitcoin ledger causing Bitcoin to fail, well yes everyone interested in Bitcoin, including yourself, would be upset.
@_date: 2015-06-13 09:29:47
It is simpler, and he's working for consensus so that is good.
It does have the one-size fits all issue, so the long term trend is unpredictable.  He has no hard cap at-all so the sky is the limit.
From discussion he does agree it would be better to add a limit to the rate of growth miners can vote for (eg no more than 2x per 3months) to the proposal, so I think he's adding that.
The vote to increase the blocksize from miners requires something like 90% of miners.
However I do think there is a bit of a leap of faith that miners wont do whats best for miners.  eg maybe its best for miners to have small blocks so there is fierce fee competition for big institutional onchain BTC transactions they get lots of fees.  (Overlaid only with the within reason limit of miner meta-incentive that users will get frustrated and price fall which would also be bad for miners).  
Or another possibility would be for the miner hashrate majority to vote for centralising levels of blocksize.  This is why he has 90% as the voting threshold as this is a competitive thing, smaller miners would not go along with that so the 90% threshold wouldnt be reached.
There isnt really any direct user control involved.  When he says users influence he means only in the "big-red button" sense of users could hard-fork themselves and replace the hash function.  Given how disruptive and high risk of diverging fork that would be for users, its not really a very realistic threat.  The threat of selling bitcoin and using fiat where miners care about bitcoin price is the only real influence users have.  So there is an element of users being hostage to miner behaviour and hoping miners behave nice through weak shared interest in Bitcoin price.
@_date: 2015-06-14 00:02:58


Secondly side-chains as points out often are not directly a scaling mechanism.  Transactions still use the same amount of bandwidth on a side-chain as the main-chain after all.
The only argument for using a side-chain for scale is that maybe you could make one with weaker security/scale trade-off for users who didnt care about security very much for cup-of-coffee level transactions.
However thats better suited to lightning really.
@_date: 2018-08-30 21:16:40
Yes I would really recommend removing this smartphone generated seed option or making it very hard to find, and with warnings. After I saw the demo video with the seed generation on smartphone, I mentally wrote it off as security defective design. Now that I learn it can do device generation that question is answered but if that's not default, it's risky for new users.
@_date: 2015-06-29 20:29:05
So lightning fundamentally relies on and needs layer 1 anchor and reclaim transactions.  Some people may prefer layer 1 transactions also.  The transactions cant all fit on layer 1, so it is better to have higher fees on layer 1 and lower fees in the layer 2 lightning layer and support vastly more transactions in total.
@_date: 2015-06-28 11:02:35
When you rely on SPV, you're doing the calculus that someone else is checking what the miners are saying.  So if you're not checking, you run the risk that a miner or group of miners could fool you into accepting coins that dont exist.  But if a good portion of the economic weight of the network is checking, they will reject the fake coins you've been cheated with, and so you will realise.  Eg if you spend money to a merchant who is checking, then the merchant will reject your coins.  Now the game-theory is that if this type of attack will very quickly be noticed and coins rejected, then the miner wont much get away with it, so he's less incentivised to try.
If no one is checking, miners can do this as much as they want. Let say for example Bitcoin gets really centralised so its running 8GB blocks (as Gavin proposed), or higher and they only fit in a big datacenter.  Now if no one has the bandwidth to verify them, we're back to trusting the assertions of a group of central people.  This is how the banking system works today, and we know how that works out.
ps You're right that it's not "no security" but it relies on a weaker assumption, that miners remain decentralised enough and honest enough to orphan off attacks.  If there were significant cheating going on 1 or even 2 confirmations would become unreliable while the honest nodes orphan the dishonest ones.
@_date: 2014-04-09 23:54:24
very strange. this thread has better comment quality than slashdot or bitcointalk or twitter amongst crypto currency  geeks.  reddit trollbox? where did you go?
@_date: 2015-06-27 23:32:30
One argument that I saw make is we should use network improvements to improve Bitcoin, and that there are multiple things we could do with the gain: more layer 1 transactions per second, but also more decentralisation, or more privacy (which often comes at a space/privacy tradeoff).
I think maybe something conservative that lasts 2-4 years would be more likely to get consensus, and less likely to miss the mark in ways that may turn out to have undesired consequences (accidental centralisation of Neilsen's law doesnt work for all geographies equally; or insufficient security if exponential bandwidth gains outpace demand while reward is falling).  After 3 years then we'd have more experience with layer 2, have seen how predictions worked out, have some more inventions like lightning etc, maybe snarks or more crypto.  Snarks are completely game changing for scale if we can get them working with conservative assumptions.
Interested to look at and be informed by specific proposals.  There's a bunch on 
But that's my current thinking.
The other thing that may be different in that time frame is maybe a decentralisation safer variant of extension-blocks could be deployed which allows free choice of different tradeoffs.  Eg with side-chains which dont expose people who dont opt in to the extension centralisation risk.
@_date: 2015-06-12 20:09:54
You could.  but sidechains are not yet supported directly by bitcoin. only via functionaries (the model described in appendix A which relies on some threshold of nodes to protocol adapt a multisig for the mainchain to the miner selection on the sidechain.
If the timing were reversed, it would be interesting to do that.
Note there are security advantages of extension blocks, they are less SPV because they are more constrained in what they can do: the 20MB full node contains the code to understand them fully.
@_date: 2015-06-09 14:13:31
Only if there is wide-spread agreement and ideally if it is handled non-controversially would hard-forking be a feature.  A disorderly hard-fork where there are factions with different but strongly held opinions about being "right" operating different fullnodes and services, that could be extremely bad.  Ledger could get irreconcilably scrambled.  There is no "right" branch because thats a point of view, and hash-rate majority doesnt define it because full nodes that are not patched to recognise a hard fork wont recognise hard-forked mined blocks.
This is a feature in the sense that hypothetically if miners decided to do something that the majority of users did not like, the miners would have created an alt-coin with no users on it (and mining difficulty would adapt on bitcoin).  The miners being stuck with 25 forkcoins per block and mounting electricity bills and no market for forkcoins would either go out of business or get back onto the user preferred fork.
@_date: 2015-06-19 10:17:21
Exactly.  I said that multiple times in the thread.  Maybe you werent even arguing with me, just others who didnt notice I said O(n^2 ) system-wide = O(n) per node.  (In my model because I assume users and nodes are in a linear relationship like 0.1% of people run full nodes).
Full system resources do matter also.  If we gossip flood the internet with O(n^2 ) system resources and do not do layer2 with algorithmic improvements, a) if IoT sort of apps take off with agoric compute fabric for the planet, maybe it saturates the internet; b) that doesnt even make sense because at high values of n the efficiency is untenable in the sense that the likely centralisation would create a breakdown in ability for nodes to audit, and without independent audit bitcoins security model is broken.  It depends on your assumption about adoption growth vs bandwidth growth, and the thresholds of useful decentralisation.  It is clear right now decentralisation is at an all time low in several metrics.  (Eg number of miners/pools in control of 95% of hashrate) 
@_date: 2015-06-27 22:46:32
I wrote what I wanted to say explaining O(n^2) scaling here.
You mention Mike &amp; Gavin as if they said something refuting this.  What they said was that the network scales as O(t * m) where t is transactions and m is nodes.  That is not a useful way to express scaling, because it's completely obvious and doesnt inform us about scaling as the number of users grow.


What you are saying is untrue.  spent hundreds of hours working with on CPU &amp; memory scaling of Bitcoin over the last year.  Without that work block-sizes now being talked about would not have been computationally possible.  There is more to scaling software than changing constants, the complexity of algorithms involving CPU, memory, bandwidth, latency are all important  and necessary factors to address.  Focussing on one and ignoring the others tends to hit a different scaling limit.
is working on lightning.
I also worked on lightning.
I wrote how I think Bitcoin can best scale here:
I have read a few of comments however he seems to lately be more talking about general economic theories which I did not see had direct relevance to scaling nor protocol design.
I'm talking about code &amp; algorithm improvements.  That's work taking actual coders and people who understand the system limits and tradeoffs.
@_date: 2018-08-30 16:40:28
The hardware looks cool, but for security from a demo video I saw that you generate the mnemonic on the companion android app, and then send it over bluetooth to the device?  That's not generally a good idea, as malware on the android phone could steal the coins. Should generate the HD seed on the device and display seed on it's screen. Any reason you couldn't make software updates to do it that way?
@_date: 2014-04-11 17:54:37
I view pegged side-chains as the right thing to do, and was working on bitcoin ideas with 110% of my spare time, from before I had any involvement or idea of spinning up a company to do it. actually what got me started thinking about how to improve the rate of innovation in bitcoin core without introducing risk, was that I had thought up a number of other ideas like homomorphically encrypted values (another form of privacy), committed-transactions (to combat policy centralization risk), schnorr compact multi-sigs various other things and got enthusiastic about other peoples ideas that could be implemented to good effect but werent being implemented.  Then I realized why, they cant make those changes, its too risky because of $7b of market cap.  So then only things that tend to get implemented are low risk or strongly important.  I explained some of these ideas in  or search bitcointalk.org user adam3us you can see I went down the rabbit hole in a big way.  I was cryptographer &amp; security architect at ZKS and my burning interest was ecash &amp; privacy technology and any crypto that could make that more decentralized or stronger.  Take a search of cypherpunks for adam and ecash, b-money etc.
I partnered with Austin Hill because he has business experience (I am just another crypto-geek) and I've known him for 15years, trust him, and  know he cares about cypherpunk ideas like digital freedom of speech, association, privacy: strongly enforcing such rights through encryption.  He and his brother put up the seed money, and some of the A-round to fund zero-knowledge systems because he thought cryptography empowering individuals was the coolest thing on the planet.  Imagine his brain on bitcoin, he's on bitcoin-overload :)
ZKS implemented ToR before Tor existed.  Tor references our stuff in their white paper.  Former ZKS chief-scientist is chair of Tor foundation.  Bruce Schneier, John Gilmore and a bunch of internet freedom/cypherpunk/crypto people were on ZKS advisory board.


I agree, thats why I want to work on it.  I view the alt-silo and alt-share fragmentation as an existential threat, or certainly dragging down bitcoins potential. It not about people speculating on alts, as a principle that no different than penny stocks, the point is I think its actually negative for crypto-currency reaching its potential.
While it was me who proposed some of the things related to pegs, others were proposed by and seemingly also some were reinventions or related to things figured out.  Overlapping reinvention Happens a lot in bitcoin.  People also reinvented already things I proposed eg stealth address, though I also reinvented.  3 reinventions of the stealth idea :)
@_date: 2014-04-09 19:24:45
alts must die!
@_date: 2014-04-12 02:28:02
Peter Todd idea.  He wrote it up on bitcoin-dev list in the last month sometime.  I think it works for full-nodes only, but it was a little hard to follow what he meant, at least thats what others interpreted it be exploring.
@_date: 2015-12-02 04:57:51
No see jtoomim's presentation on the schedule
@_date: 2014-04-09 21:45:18
the point is crypto currency share trading extensions need a transactional currency for fees, and to make cross-trades more cost-efficient in some cases for liquidity in unusual pairs.  smart-contracts make more sense (are smarter) when the transactional currency is also self-issuing, as then there is no counter-party risk.
and for various feature coins its more convenient, and avoids the market craziness that comes with zero-sum alt speculation, if they are also denominated in bitcoin.
it helps also if all the feature coins and crypto currency chains are interoperable via a zero-trust / self-issue currency.  there is one neutral choice for that currency: bitcoin.
many internet things have been helped by network-effect -- their utility value grows with the square of the number of users, or claims like that.  if each new feature coin or innovation comes in its own silo, non-interoperable with a speculative alt it weakens network effect, and so we dont see bitcoin / blockchain tech reach its interesting potential.  also the scarcity race with alt-coins tends to dilute mind-share and pollute the market with lots of marketing/meme based "innovation" where the sole reason for existence is to enrich the "innovator".  its more interesting to see the actual innovation happen. zero-sum alt-games are just that, penny-stock gambling games and meme/marketing exercises.
@_date: 2015-06-13 12:08:26
No is correct.
In a soft-fork 51% defines network consensus.
In a contentious hard-fork different people are running different software by-intent and so do not count each others blocks.  The 20MB block is invalid by the consensus rules of the 1MB chain so they wont be counted by definition.  A 1MB block could be valid for the 20MB chain however that will destabilise nearly instantly, because after even a single double-spend that goes both ways, neither chain will ever consider valid and build on a block from the other chain ever again.  
@_date: 2014-04-10 19:07:47
no, soft-fork only
@_date: 2014-04-10 18:41:11
I thought ethereums latest PoW is tied to turing-script interpretation (might be interesting to add OP_SHA3 for several reasons though).
But I think the reverse arrangement makes more sense: make a downstream ethereum fork (once its released out of alpha) that replaces their current PoW with bitcoin via 2-way pegs.  Then you can use ethereum scripts on a side-chain with the interoperability benefit of a neutral currency.
The main criticism of ethereum (other than quibbles about security of generalized byte code, statefulness and complexity being the enemy of security) is the premine and new alt-coin scarcity race.  Pegging allows those objections to be removed.  
Well another criticism is the loss of security from starting a new PoW race.  That also is fixed (subject to incentive compatibility arguments of fee-only chains).
@_date: 2014-04-11 21:03:29


I am not sure why that makes sense. It seems more logical to me to build on network effect and use bitcoin as the unifying interop currency and deploy ethereum on a pegged side-chain.  And to use $7b market cap, deployed ecosystem of sw wallets, hardware wallets, merchant &amp; financial integration, $500m worth of ASIC security etc.  (ASIC-hard PoW are hard to design, most so far failed, noticed you changed your own design 3x so far, so you know first-hand).  You also reset $7b worth of digital scarcity which was produced at a cost of &lt; $1b, if you reset it, this time it'll cost closer to $7b of electricity, because it will be less of a surprise.  
You sure you're not on the token-ring vs open/standard/interop TCP/IP network-effect wins side of history here by proposing to attach to a new alt?
You have some interesting and elegant scripting machinery, but doing a reset on the digital scarcity doesnt seem like a good direction.  Also big-picture game theory (though maybe you can cash out the premine in time even with the vesting) hypothetically if the ether alt succeeded and overtook bitcoin, you'd probably destroy durable engineered scarcity.  Otherwise why would people be confident something else wouldnt come along and displace the ether alt.  Gold has been around as a physical scarcity money technology for 2400 years.  Bitcoin digital scarcity for 5.  Give it a bit of run-time eh?  If you or other alt-coiners destroy it before it starts, it maybe the end of digital scarcity period and then we're back to fiat and physical gold.


We (Bitcoiners) are similarly happy to see any kind of contract development tested inside pegged side-chains :)
Happier even because then we can all work together on network effect and stop fragmenting the ecosystem with selfish alt races.  I know your alt premine is cleverly toned down via continual inflation etc, but its still a premine.  And even if there were no premine its still an alt which is inherently ecosystem fragmentary.
@_date: 2014-04-12 01:51:31
I guess its the ease of forking and assimilating (as well as open experimentation) that makes side-chains fun.  You are right.  Alts will be assimilated.  It makes the concept that a new alt-race with a feature that is not outside the source easier to demolish: DRM doesnt work, and analogously your alt if its at all interesting or useful will be forked and assimilated by the bitcoin-borg collective into a side-chain.
Alt side-chain resistance is indeed futile :)
Next attempt: closed source.  That also definitionally cant work - a decentralized crypto currency has to be open source or its not under decentralized development and review/transparency.
Next attempt: open source but restrictive license.  Also cant work: if you are not allowed to change the code, then its again not under decentralized development.
Seems close to game over for alts.
I do think people would still play zero-sum alt-speculation games.  Just the meme about future potential would be reality adjusted.  The potential is failure or assimilation.  Ie ZERO.  But maybe that doesnt stop the zero-sum speculation I think most already know that.
@_date: 2014-04-13 14:20:40


I agree. This is one of the useful benefits of side-chains.  People can do different things on different side-chains, in parallel, competing with each other based on different conclusions about what is the right choice.  (Large blocks, zerocoin/zerocash, turing complete contract language, block frequency, ghost protocol, homomorphic encrypted values etc.)
@_date: 2014-04-14 00:34:21
the idea of the reverse peg is to validate a compact SPV proof.  ethereum if migrated or forked to a pegged side-chain would be tasked with producing that proof. The main chain doesnt have to understand any other side-chain internals.  Easiest would be to change the PoW otherwise as you said bitcoin for the reverse peg has to be able to verify the PoW.
btw it wasnt me who created these multiple reddit threads (nor their provocative "side-chains kill ethereum" subject line) that was some users.
I will say though in reply to the source of funding view, that there does seem to me to be something akin to internet-physics/DRM failure inherent in the view that one can extract rent or profit logically from a FOSS coin other than in a pump &amp; dump sense where there will be losers.  this is because if it is useful people can and will fork. viz aethereum (which was also nothing to do with me btw).
if that was the only problem I'd say fine lets see if people end up forking and using the fork without rent.  maybe it works maybe it doesnt, hard to predict as there are multiple factors. I mean skype worked by closing and obfuscating the source and providing a shiny UX to retain control. Except you cant usefully have a closed source crypto currency or its not decentralized software control.
the main problem I have with alts is a) its fragmentary, rather than building network-effect; b) i dont think you can fairly distribute coins now that bitcoin has proven to work (each new coin creates a pump &amp; dump rented VPS farm race like a few people we both know like to play with) - there were only two types of attempts to be fair I saw freicoin (80% to charity + demurrage) and things like auracoin (give coins to all citizens of a given country); c) I think it may destroy the concept of digital scarcity.
You said (in another post) that bitcoin distribution is unfair or arbitrary.  It is arbitrary but it was down to luck and early adopter status where no one knew it would work.  It is what it is, but its done, and it cant be repeated on the same terms, because everyone knows that it can bootstrap.  Anyone can buy them.  $350 or $400 isnt that pricey compared to the $1250 previous peak.  No miners are now getting significantly rich due to market competition.  (To be clear I am not an early miner, bought my first coins in mid 2013).
we might both want to lay off the analogies, I notice you also use them, it mostly too technical and unique for them to largely make sense.  network-effect, and interoperability are useful things, dont need analogies to make that point.
@_date: 2014-04-11 19:33:14


well. there is colorcoin which isnt an alt, but doesnt scale because its sharing bitcoins network capacity and also has no SPV support, and there is mastercoin and counterparty which are metacoins (spam bitcoin with watermarked transactions like colorcoin) and are alts because they have a floating value. and there is ethereum which is an alt. and now there is aethereum which is an ethereum fork without the premine. and protoshare which is a sort of marketing share meme related alt (an alt with a promise of ownership in a to be developed alt-share).  then there's freimarkets which can be used with an alt-coin or with a side-chain, I like freimarket best. forking ethereum onto a side-chain might be ok if the security risks end up being controllable. most of those are alts. the argument of why (pre side-chain) they almost had to use an alt because of scalability of sharing bitcoins network capacity and lack of SPV support for color tracking in bitcoin.


with namecoin which is merge mined, its only 85% merge-mined so its difficulty is lower.  consequently some namecoins are not valid bitcoins.  and some bitcoins are not validname coins (because 15% are not mining namecoin).  that illustrates that different intervals and difficulties can be mined.


it could be supported if desired, but would presumably require more understanding of the side-chain to actually verify the stake claims.  one nice thing about PoW side-chains is the main network doesnt have understand what they're doing, just that they produce a return proof in compatible format.
@_date: 2014-04-10 00:02:00
actually it gets more composable yet.  say you want to create a new side-chain that would like to use crypto assets from multiple different side-chains. you should be able to peg other crypto assets than bitcoins - eg issued assets, smart-contracts that allows you to create in-chain contracts involving non-natively understood contracts and constructs from other side-chains.
@_date: 2014-04-10 19:03:32
No the security firewall is quite categoric (modulo a bug in the critical code change to bitcoin main).  It was a reference to previously less clear thinking on the topic of how to secure them - I was saying, I was happy that had come up with a very simple and robust argument for why it is safe for bitcoin-main.
The only people with coins at risk to bugs in a given side-chain are those with coins in that side-chain.  Main bitcoins are immune from bugs in a side-chain.  And one side-chain is immune from bugs in other side-chains.
@_date: 2014-04-14 10:06:09
btw I dont mean to imply app-coins have the same problem, or that one cant fund development in interesting new ways.  I just think that to avoid the fundamental DRM-loses problem app-coins need to have value outside of the source.  You know like actual infrastructure, services that someone has invested capital in.
Or to be up-front and fairly state the unenforceable request, shareware style.  Obviously that has less wild-upside than pump &amp; dump, but then there are no losers because its a "support" fee like redhat, or a suggested fee, so it also doesnt have the ethical problems.  Lots of options, that dont involve losers if the fork happens, use imagination.
Btw some of these ethical problems are actually legal problems too.  People like to rail against the system, and it is slow-moving and clumsy, but some of these regulations exist for a reason, they are about consumer protection, and were created in reaction to previous abuses.  Incorporating offshore as a way to avoid regulations might might not be that wise.  People might like to look up what anti-CFC rules mean also.  Offshore is more wise than ignoring regulations while operating onshore or being a "DAC" (which is actually just operating under your own name without limited liability protection unless you are really very anonymous).  There is actually some history to this ecash business.  For example e-gold.  They were incorporated and operated from the caribbean, but the owners were living in the US.  A friend of mine contract operated &amp; developed via his own company systemics the ecash servers, and he lived in the caribbean.  He was called as a witness, but the owners faced fines,  and narrowly avoided jail time instead house arrest.  
e-gold had lawers, offshore incorporation and some AML/KYC features.  As far as I know the argument centered around them having slightly too weak features; couldnt say if the case had merit or not though they lost it.  Ian Grigg put all the docs online 
@_date: 2014-04-14 01:21:21
btw it wasnt me who created these multiple reddit threads (nor their provocative "side-chains kill ethereum" subject line) that was some users.
I will say though in reply to the source of funding view, that there does seem to me to be something akin to internet-physics/DRM failure inherent in the view that one can extract rent or profit logically from a FOSS coin other than in a pump &amp; dump sense where there will be losers. this is because if it is useful people can and will fork. viz aethereum (which was also nothing to do with me btw). I have concerns that pump &amp; dump with losers is unethical because its something like a pyramid, the last to dump lose.
other than the concern for pyramid losers, or if you take the view that this will not happen (confidence people wont fork for some reason or whatever justification), if that was the only problem I'd say fine lets see if people end up forking and using the fork without rent, its an experiment. maybe it works maybe it doesnt, hard to predict as there are multiple factors. I mean skype worked by closing and obfuscating the source and providing a shiny UX to retain control. Except you cant usefully have a closed source crypto currency or its not decentralized software control.
however the main things I want to say are I think alts are a bad idea because
a) its fragmentary, rather than building network-effect; 
b) i dont think you can fairly distribute coins now that bitcoin has proven to work (each new coin creates a pump &amp; dump rented VPS farm race like a few people we both know like to play with) - there were only two types of attempts to be fair I saw freicoin (80% to charity + demurrage) and things like auracoin (give coins to all citizens of a given country); you can see this view - its not just me being fussy - about for example mastercoin which people have viewed as scammy. ethereum is doing approximately the same thing. so alts end up being grossly unfair, and I presume that the hope to win from the pump are why there are &gt;200 of them. 
c) I think it may destroy the concept of digital scarcity.
You said (in another post) that bitcoin distribution is unfair or arbitrary. It is arbitrary but it was down to luck and early adopter status where no one knew it would work. It is what it is, but its done, and it cant be repeated on the same terms, because everyone knows that a cryptocoin can bootstrap. Anyone can buy them. $350 or $400 isnt that pricey compared to the $1250 previous peak. No miners are now getting significantly rich due to market competition. (To be clear I am not an early miner, bought my first coins in mid 2013).
so in summary I dont like the ethics of pyramids with losers, of course thats arguable, if you think for some reason DRM works or people wont fork; but I can deal with that by saying it and not participating economically in it. my big worry is c) that the concept of digital scarcity starts to look weak. how can we say its scarce if 100s of people keep making new scarcities. if everyone does that its NOT actually scarce in aggregate, or it certainly looks bewildering and noisy.  this is why I say bitcoin is somewhat arbitrary, but it is what it is: its unique because it came first (where the first few years of scarcity bootstrap was a surprise), and it is the only coin that could win, without damaging the concept of digital scarcity. (if newcoin overtakes bitcoin it leaves newcoin holders wondering if it will happen again.) as there is no physical value, that is a problem. they can all collapse to zero, and we're left with a sad story about digital tulips. I would not like to go down in history as the guy who destroyed digital scarcity, aka bitcoin, which in its first 5 years looks to be shaping up to be able to offer a lot of value to humanity over the next 20 years in reshaping finance, and all the amazing advantages that smart-contracts can bring.
we might both want to lay off the analogies, I notice you also use them, it's mostly too technical and unique for them to largely make sense. network-effect, and interoperability are useful things, dont need analogies to make that point.
@_date: 2014-04-10 15:57:08
The circumstantial evidence I alluded to above (its all 2nd hand info) is Artforz was also the guy who implemented the first GPU miner for bitcoin (so he would be well aware of performance tuning GPU code and its performance characteristics) and also was into FPGA mining and wrote his own bitcoin FPGA miner.  To some people that is smoking gun.  And if ArtForz were suspected, its secondly unclear if Charlie Lee was suspected also or an innocent dupe.  The rationale for Charlie copying Art Forz tenebrix code and rebranding it as "litecoin the silver to bitcoins gold;)" was to remove the premine.  Now why would ArtForz bother with a premine if he had a hidden 10x mining advantage?  Well its not clear cut, it was explained to me that the pre-mine was part of a built-in mixing pool fund to facilitate privacy, and not "owned" by Art.
Internet conspiracy theory?  Who knows.  Not a fantastic genesis rumor but no proof.  And most of the claimed properties failed (GPU harness, ASIC hardness, decentralization via ASIC hardness) and some of them are questionable (faster confirmation, yes but weaker confirmations as less work) and faster confirms create slight latency related centralization risk and slightly higher orphan rates, and propagation is slower as Scrypt verification CPU cost is way higher, again centralization risk.
Litecoin does some useful coopetition stuff under Warren Togami's lead (he's taken over litecoin dev for some time).
@_date: 2014-04-10 15:04:06
I think articulated the security limits above somewhere (quoting for convenience):




You are correct in saying that there is a the security limit caveat (and that the limits should be discussed!)   A few things to say about the security limits:
a) because bitcoin full-nodes have a relatively absolute security model (modulo access to &gt; 51% power for extended periods of time) people tend to have a threat model of demanding the most that can be demanded.  In practice as the SPV model demonstrates less security is still very good.
b) There are some things you could clearly do to improve that.  Already as proposed the buried side-chain burn proof plus maturity period means an attack has to be sustained for several days.  At that rate there is plenty of evidence and someone can bypass the DoS by phoning a mining pool or cloud hasher worstcase! Bitcoin for security though it is little discussed already depends on maintaining defense against selective DoS.  Bitcoin ecosystem components already (the competently run ones) have redundant connection types, and ToR low bandwidth checks for blocks (or should have).  Sustained DoS in this scenario is quite difficult.
c) I am not sure if it was mentioned in the writeup but there is the possibility for a second fee (equal to the transfer fee) used as a bounty to incentivize 3rd-parties to search for attacks on reverse pegging and claim the bounty during the maturity period.  They also can call a miner if a DoS is standing between them and their bounty.
These proofs are something like "proof of treachery" (a related previous bitcoin idea) that can be cashed by anyone for a bounty.  Easy money for running a full-node with no mining ASICs.
d) ZK SNARKS (an awesome bit of bleeding edge crypto-overload "bitcoin is the gateway drug to snarks" -  But SNARKS can do amazing crazy counter-intuitive things.  I believe you could use them to make a compact proof and commitment to the entire contents of the transaction flow on the side-chain, and produce a compact ZKP proof in ~300bytes, that can be efficiently verified by bitcoin-main as asserting that the entire ownership transfer history is correct within the side-chain, WITHOUT understanding the ownership transfer rules.  And while the crypto is bleeding edge, the security it adds is strictly addative - if it fails unexpectedly due to cryptanalysis, unlike with zerocash which also relies on SNARKS, in this use case we dont lose coins, we fall back to the existing security model.
e) the question has only just become strongly relevant.  Maybe someone eg can come up with something even cleverer without SNARKs.
@_date: 2014-04-09 20:57:22
Pegged mean not floating/market exchange rate: inspired by currency pegs, only this one is mathematically enforced, not policy or market price manipulation based on the deep pockets of a currency control board.
@_date: 2014-04-10 19:28:44
what about a side-chain with a fresh implementation for diversity.  if the main-chain melts down, people can freeze their bitcoin activity, force migrate all their coins.  Kind of complex area to explore but maybe something could be done.
Another bitcoin robustifying activity is to minimize and modularize the consensus critical code.  Some core devs are working on this as I understand it.
Another idea would be 3 independent implementations.  They each vote on what happens.  If less than 3/3 agree, the majority wins, and a big debug effort is undertaken to find out which is wrong.  Should help avoid the catastrophic bug meltdown scenario.
@_date: 2014-12-30 19:09:35
That rather depends on the peg script, the sidechain author writes using a new op_code for consuming a compact SPV-proof.  (Btw pegs are not that remote possibilities: the return peg nearly but not quite works with existing bitcoin script.. it might even be possible to contort it to already work with some chained bloaty transaction).
For example a peg script which stops the &gt;50% attack is if the person originating the return has to put up an equal bounty in main chain btc, that if their transfer fails they lose it.
@_date: 2014-04-09 19:43:03
you forgot the first fail:
~~GPU resistant~~
@_date: 2014-12-22 20:23:23
Would you say the same thing about email spam?  Curious rationale.
What you are proposing is blockchain spam to 10,000 full nodes and to the blockchain history that every full node has to download for ever.  
If you want to *do* something, write some code to do something, eg design &amp; implement a hard to censor p2p network, dont hack up some script to spam bitcoin and then declare victory.
@_date: 2014-12-22 10:00:10


that part of the article mis-summarised what was said, and a scan of bitcoin github would tell you that is incorrect (both on company time and in spare time).  the quote was quite clear though "Core development has been quite conservative and focused on security and stability 
@_date: 2014-04-09 23:49:46


Yes its like the film Inception (recursive dreams), even side-chains can have side-chains.




you could shard a side-chain if you have a use case (lots of instances of the same side-chain) however absent ZK-SNARKS or something else clever it seems that the scalability problem is somewhat tied to the miners ability to receive all the transactions (which is the same bandwidth if its sharded).
however there is a solution to even higher transaction throughput and very low latency: peg a side-chain to a private-chain.  I described it in another comment on this page.  search for private-chain.


very funny you should mention that.  Luke-Jr or maybe it was Maaku proposed the exact same thing in the context of 2-way pegs.  Peg side-chains with different block intervals growing outwards towards Mars.  Mars pegged bitcoins can be pegged if they are appropriately slowly pegged to earth coins.  Maybe someone can figure out how to account for the lower hashrate on the mars colony :)
@_date: 2014-04-12 02:15:57
y'know we didnt actually post this stuff on reddit.  someone else got excited and did it 3 or 4x in diff threads.  the interest in the idea is running on its own steam pushing us along bemused.  fun discussions tho.
it was actually a reference to "cypherpunks write code"
@_date: 2014-04-09 19:10:47
It should be possible to replicate ethereum fuctionality, or actually fork ethereum FOSS code itself, replace ether with real bitcoin (via the 2-way peg) and run it on a side-chain.  If a feature coin can run on a 2-way peg (and its secure &amp; useful) it will be forked and 2-way pegged.  
New law of crypto currency: if it can be 2-way pegged, the project does not need its own alt.  If it has its own alt anyway, it will be forked and replaced with bitcoin.  
This is not a new problem, but it highlights the natural limit on profitability and self-defeating nature of alt-shares that try to premine all or part the transactional currrency: any user past a moderately succesful level of use will fork and replace the premined transactional currency.  Replacing the currency with bitcoin is neutral and fair.  It is just not plausible to imagine a few early speculators owning the entire transactional currency for the world.  
Bitcoin itself is different, its &gt; 50% disbursed, electrically efficiently, and was a genuine ultra high risk speculation in the first few years when most of the disbursement happened.  People who mine bitcoin now are not getting rich.  Ownership is wide.  Anyone can choose any investment level.  There is a natural (decentralized) monopoly for durable engineered scarcity (bitcoin), advantages are strong for everyone to use it.  Its definitional: if another me-too scarcity displaced bitcoin, neither bitcoin nor the newcoin would be viewed as durable.  Starting new scarcity races for feature coins is self-defeating as a funding model with no other feature outside of the source, it can and will be forked if it gets use.  Starting new scarcity races is also grossly unfair, coins should have a reason for existence, and making the param-tweaker rich is not a reason.
@_date: 2014-04-11 21:11:32
indeed thats the $64m question, we're waiting to here about from team-ethereum :)
@_date: 2014-04-10 19:24:53
They are also largely zero-sum speculation with limited interest to provide actual utility.  Mostly harmless, though a waste of electricity, unless it get out of hand and people start huffing their own meme/sales pitches - then it gets serious, worst case it could destroy digital scarcity if a meme-currency over took bitcoin in market cap.  It might be a confidence affecting crazy-moment.  (Would have to be some kind of liquidity adjusted market cap many alts create a bazillion units as part of their param-tweak + meme package so that even at minimum price precision on cryptsy they can claim a high though completely shallow/thin untradeable market cap.)
@_date: 2014-11-17 19:23:56
Thats what cant be evil means: structure and plan to prevent future evil so an org cant turn evil or so it doesn't matter if an org turns evil, because you are forever protected (eg because the source and protocol are open, decentralised and trustless).
@_date: 2014-04-09 21:07:22
There are threads exploring this speculation on bitcoin talk.  From what I could tell while there was some circumstantial evidence there was no real proof.  Its rude to accuse, absent more concrete evidence, and Charlie Lee is a well known public face, and its a pretty scammy thing to be accused of.  Litecoin isnt really a fork, its just a code copy of tenebrix by some other people who actually designed the parameters.
So for now I think all we can say is that they claimed it was GPU resistant by design and (unless that was a scam false claim), they failed badly.
@_date: 2014-11-04 12:23:27
If you are interested in Proof of Stake you maybe interested in this paper.  by Andrew Poelsrta 
The author has a proof that proof of stake does not and cannot work, and is not secure.
@_date: 2014-04-09 19:49:33
More: you can freely move your bitcoins between side-chains.  Multiple side-chains can be created for different purposes by different people.  Even competing ones for the same reason.  And it doesnt matter because they all interoperate at the level of bitcoins, that can be moved between them.  So you get network effect rather than alt-coin coopetition / competition and alt-share / feature coin silos.
Innovation the internet way, bitcoin becomes the transactional currency TCP/IP of internet money; rather than each feature coin trying to selfishly invent its own alt-coin, param-tweaking and changing magic values to make incompatible coins that then float at wildly swinging zero-sum speculative market rates.  
And sadly most alts usually outright fail due to technical incompetence, lack of hashrate, or lack of software maintenance.  Even changing parameters is complex, maintaining a crypto currency with $Bs of value is not a job for a param-tweaker (can use compiler and dream big).  Crypto currency development is rocket science - it has very pointy edges, and complex consensus rules that are ignored at the alts peril.  Its also not a joke (Doges eh be sure to put your pension in that).
@_date: 2014-04-11 13:52:59
increasing the main bitcoin block-size leads to centralization due to need for data-center grade network bandwidth.  by using side-chains you can have a size-chain with an aggressively large block size, for micropayments.  if you do it right you can have large centralized block-size for micropayments **without** the policy centralization risks if the side-chain allows unilateral return (you can take your coin out without the need for cooperation from the centralized chain).  That even works up to the point of private-chains (chains with mining replaced by signature of a central server).  Obviously with a private-chain server you can scale further &amp; have lower latency, because there is no need for consensus.  You still have incentivized (via fraud-proof bounty) auditors that can prevent fraud during the maturity period of the unilateral return.
@_date: 2014-04-09 21:24:05
Each side-chain would have a security/value firewall to the main chain (and by implication between chains).  This works because suspended coins can only be reanimated (moved back) from the chain they were sent to.  The security firewall means some quite imaginative things remain safe for bitcoin, become possible, though not all are things rational users would want to put coins in.
Some things that could be put on a 2-way peg:
- zerocoin/zerocash (all anonymous chain, or zerocash fungibility with payment protocol identity &amp; business records).
- smart-contracts/issued assets (like color-coin but tagged rather than watermarked, and scalable to SPV clients, and with smart-contract extensions, eg like freimarkets)
- micropayments (big blocks, and maybe bitcoin could shrink its block to aid decentralization)
- bitcoin 2.0 beta (move over rest of coins at some point in the future).
- ethereum contracts (replacing ether with bitcoin as transactional currency and flushing the premine/alt)
- anything you could build with ethereum.  but without turing complete scripting risk to durability for long term storage - if you store in other side-chains.
- ripple-like IOUs (IOUs tracking can work on the side-chain, though they obviously must be blocked or Alice gives entire balance to Bob as an IOU and he cashes it out!)
- homomorphically encrypted values (still validatable but hides the values involved for financial privacy (your salary?) and commercial deal pricing confidentiality)
- freicoin (yes bitcoin+demurrage can work with artificial friction to return)
- fractional reserve bitcoin with additional mining reward (or worse... premine?) (not sure I want to put money in that one - side-chain run!)
- bitcoin denominated namecoin functionality
- random crazy, idea. only coins at risk are those put into it.
@_date: 2014-04-13 15:01:09


I will say it myself also and I have on bitcointalk also.  I have respect for Satoshi *because* I tried for 5 years to solve that problem and failed (deploy decentralized anonymous ecash using hashcash as the underlying digital scarcity).  
If you search cypherpunks archives for adam  from 1997 to 2005 you'll see long set of threads exploring inflation control, broadcast networks between Wei Dai, Hal Finney, anonymous posters, and myself.
Its not exactly like a dumped hashcash onto the programmer communities knowledge base and walked away, which most people seem to assume.  I was into anonymous ecash, distributed systems long before I invented hashcash and long afterwards.  
From the idealized ecash cryptographer mindset  Satoshi didnt quite reach it because bitcoin is not very fungible and you nearly but not quite need unlinkability for fungibility (what you actually need is irrevocability, though there are side-effect to having irrevocability without unlinkabilty however, as you see with coin validation/redlisting).  First thing that went through my mind when I saw bitcoin was great step but incomplete solution because of the bad privacy/fungibility properties (due to linkability side-effect of one-use addresses) and why didnt he use Sander &amp; Ta-Shma's 1999 "auditable anonymous electronic cash" crypto/ecash paper which would fix that to get a complete idealized system!  (zerocoin is an optimization of Sander &amp; Ta-Shma protocol).  But Sander/zerocoin are inefficient and only support one denomination. And zerocash fixes several of this limits, much closer but is still also not quite ideal/complete because its bleeding edge crypto, has a genesis trapdoor, moderately heavy CPU and a 1GB verification key; very close tho.
Satoshi was the guy who finally cracked inflation control for decentralized digital scarcity based cash.  There were others who tried, and even had moderately plausible but less elegant/direct designs (Wei Dai, Nick Szabo).  The bitcoin design is genius.
It seemed to be immediately obvious to *many* people after hashcash was released in 1997 that this was somehow a form of digital scarcity or digital gold, and then people immediately explored inflation control to avoid moore's law making it unstable.  I reckon 100,000 programmers knew about hashcash probably by 1999 a fair few of who also probably thought about the digital gold aspect also as it seemed immediately obvious to many people already in 1997 same day/next day it was released.
@_date: 2014-05-19 00:26:29
I do not think tree-chains are a competing technology to side-chains.  
Side-chains are a generic bitcoin extension mechanism.  One way to scale transactions on a side-chain is to change the block-size (which is less risky for policy centralization than the main chain block size increasing as you can opt to unilaterally return your coins).
Tree-chains are a scaling idea.  If the incentive and details work out, tree-chains might use a side-chain for deployment.
@_date: 2014-08-03 22:09:07
Presumably when you talk about SPV clients they are SPV+ ie they do not download all history (like a full node) but just bits of history relevant to the units being traded?  (Which could get pretty big, eg looking at bitcoins history if you exclude UTXO, but is clearly smaller than full history).
@_date: 2014-04-09 22:52:28
you can just move existing bitcoins between side-chains and the main bitcoin chain.  a bitcoin is a bitcoin whichever chain its on.  a litecoin side-chain is a bit tricker because its PoW is incompatible.
in principle a side-chain could be pegged from multiple coins (more easily if they have the same PoW). eg namecoins and bitcoins could be pegged to the same side-chain.
anyway part of the point of the side-chains is you dont need multiple crypto currencies.
@_date: 2014-04-11 17:22:44
the centralization is bandwidth &amp; latency, not storage, nor cost (hosted bandwidth is cheap).  retaining data is even optional right, verify &amp; integrity protect UTXO which is only 360MB.
scrypt size 80 to 40? that sounds like OP_RETURN size no?  unrelated to side-chains.
yes profit, but non-profit also: hybrid organization. obviously to anyone with sense, though not all biz people have such sense, even in bitcoin sadly, any bitcoin related core tech has to be open source, open spec, open protocol or it would and should be rejected.
@_date: 2014-04-12 02:13:34
Curious you would say that, ethereum has that exact problem, people will make a bitcoin fork.
I think its generic: alt scarcity races (and/or premines) attached to feature coins with no service value outside of the source, their profit-potential is limited by the maintenance cost.
@_date: 2014-04-11 14:00:59
agreed that people know about and were excited about color coins, smart-contracts built on them, extending smart-contracts etc.  the point is with side-chains you dont need alt-coins to do those things, you can do them with bitcoin itself.  you can have different block-times, on side-chains, and very low latency transactions on private-chains all based on bitcoin without alts. also things based on watermarking bitcoin like colorcoin, mastercoin, counterparty are not scalable, so the interest in them on closer analysis is aspirational only, not practical.
introducing a new hashing algorithm has been touted as a reason for existence by some alts, but its not a reason.  most of the attempts are flat-out worse for long term ASIC resistance (watch litecoin as the scrypt ASICs with more power advantage than SHA256 ASICs), worse centralization, poor or no maintenance, no actual transactions/utility value, and basically zero-sum pyramid gambling (pump &amp; dump first out wins, and zero-sum penny stock price manipulation games before the big dump). this is all not good for credibility, and maybe even long term existence of durable engineered scarcity.
@_date: 2014-04-12 18:45:26


there is no way we could nor should be able to make a change to bitcoin without approval, review and sign-off of core dev which is decentralized.
details not there yet but its shaped something like just a small bitcoin change adding a new OP_CODE or two which makes side-chains possible.  its neutral, reusable and allow anyone to make side-chains. whether thats zerocash project, bitcoin developers, our to be named co, darkwallet, ethereum, internet gambling chain, opentransactions, ripple. open competition and innovation to drive faster true innovation. (which simultaneously discredits fake innovation like param-tweak alts).


i'd be interested to hear your opinions on it.
yeah that is fiendishly clever. Its still an alt however, with a sort of soft-premine (disguised premine) by just giving them to everyene then buying them early for real money at low prices.
I still think alts are fragmentary and its better to build on network effect.
@_date: 2014-04-12 02:24:06


I dont think that is true.  You recall my trustless exchange idea (atomic swap usdcoin for bitcoins via an order matching exchange that doesnt hold the coins).  So side-chains are a way to implement bitcoin extensions.  a primary interesting one being native coloring, like freimarket, but attached to bitcoin as the transactional currency.  A btc-denominated freimarket side-chain could certainly atomically swap bitcoin for usdcoin.  (And even do order filling where orders are matched by different transactions, not sure if Mark &amp; Jorge wrote that in the paper yet, but they have a way to do that also).
I am not sure decentralized exchange is necessary as a first pass but that could be done via p2p same as others propose.
I think its better if even the USD are encoded as coins, even if the exchange self-issues them (because offline signing key issued coins are less vulnerable than a database).
You probably cant quite use the 2-way peg to get non-escrowed bitcoin in ethereum, due to the incompatible PoW.  (Maybe you could consider swapping that back to SHA256d for convenience, then this would also work).
@_date: 2014-04-11 14:04:44
if you have any ideas of how to make it more open, lets hear them.  open bitcoin interoperable side-chains allow anyone to create their own side-chain and increase bitcoins rate of innovation while building network effect.  not saying there do not exist other ideas.  lets have them.  side-chains are an open protocol, open development, open source project developed under the same terms as bitcoin.  add your brain to the party.
@_date: 2014-04-09 21:30:34
You can create side-chains without 2-way pegs, that hold nothing but issued assets.  The advantage of 2-way pegs is that then you can use actual bitcoins on the side-chain also.  The side-chain features might be higher TPS, fancier smart-contracts, zerocash anonymity, whatever.  If you want access to bitcoins then its nicer to peg than not, because then there is no escrow agent holding your bitcoins (like with ripple's gateways, or open transactions voting pools, mtgox etc).  OpenTransactions itself could possibly upgrade voting pools to 2-way pegs.  2-way pegs also work between a side-chain and a private-chain, which is how you really get low latency and high scale.  Still with all the zero-trust bitcoin features: public auditability, unfreezability/unseizability etc.  You can unilaterally move coins from private-chain to side-chain if it cheats, drops off the net etc.  A private-chain has no mining, just time-stamped signatures (time-stamp recorded in the block-chain via a time-stamp service merkle root).
@_date: 2014-04-11 14:07:35
good price too:) $350 dip last night, still only $400 today.
@_date: 2014-08-03 22:04:32
Like says surprised you did not mention freedom from a floating alt-coin that will likely create a self-sabotaging conflict of interest leading to a coin re-issuance fork like stellar just did to ripple, or collapse under pre-mined moral hazard at some point.  Big differentiator, clean model with no get-rich-quick model tacked on in an easily forkable way.
@_date: 2014-06-18 12:49:29
| No one has the (moral) right to claim to be the one true successor of bitcoin.
Agreed.  However extending bitcoin by adding a generic extension mechanism... that seems like not a claim to anything, just helping bitcoin  reach its fuller potential by pulling share/smart-contract, anonymity &amp; other interesting extensions (zerocash, or a coin based on snark scripts say) natively into bitcoin network.  Otherwise I think the downside is the floating new scarcity race alt-coin approach doesnt benefit as much from network effect, which is what got crypto-currencies to where they are, and where $8bn of vested interest is probably going to be pulling.
@_date: 2014-04-13 12:22:43
+10 what said.
@_date: 2014-12-13 13:06:52
I wouldnt say its exactly trustless, you're trusting the in-flight increment of funds whatever that is. (and there is a tiny bandwidth cost for the increment, and you cant go below the dust limit for the minimum up front increment).
Its more like trusted but in tiny offchain increments.
It also creates a pair of on-chain transactions per time-interval so whether its a net win depends on the usage pattern.  If there are 1million users registered in this who are relatively inactive they still create 2million on chain tx per week or whatever the interval is.  For that to be a win they must on average make more than 2million off-chain tx via the hub.
btw thanks Peter for writing it up.  I had kind of assumed there would be a way to do it without even incremental trust, so yeah the method is kind of simplistic.  Pure offline trust but incremental.
@_date: 2014-04-10 18:55:46
Scrypt failed its GPU/ASIC-hardness claims (other thread/page you were in).  But maybe you didnt know, scrypt is actually worse for ASICs than SHA-256, ie there is a bigger speed boost for ASIC-scrypt vs GPU-scrypt than ASIC-SHA256d vs GPU-SHA256d.  And there are a few companies about to ship Scrypt ASICs.  The centralization might get pretty interesting on litecoin RSN.  This is why there is a discussion about swapping scrypt for another hash on litecoin forum now.  Its a difficult discussion because obviously some people dont agree (view it as violation of social contract) and will refuse to migrate and then you get some kind of unworkable net-split or fork with double-spends on either side or such problems.  Warren Togami (lead developer) and Charlie Lee have come out against changing with arguments about confusion and social contract (read the litecoin forum thread for a better summary).
Maybe they could splinter it.. exodus to new PoW for litecoin2 by some flag day after which it floats or other variants.  I think its technically possible.
@_date: 2014-04-14 09:01:23
replying to vitalik main developer of ethereum script, and the "ethereum killer" part of your subject that elicited his reply.
@_date: 2014-10-25 01:32:11
other comments explained about it being possible to have both merge-mined and non-merge-mined side-chains, but about the cost question:
the extra cost to the miner is not hashrate, but primarily bandwidth to receive the other chain(s) to have the data to validate.  It depends on a chains parameters but if a chain were hypothetically to have a very large block size that could make it more difficult to receive the data to validate with ADSL/cable modem consumer connections.  basically data center bandwidth is far cheaper than consumer bandwidth.
Merge mining is optional (eg you dont have to merge mine namecoin, though apparently 85% of people by hashrate do).  But when mining is close to commodity pricing, every source of revenue counts.  namecoin gives an additional 0.5% revenue from the NMC even though it has few fees as there are few transactions.  So one argument is it could become economically non-optional if mining is for profit (vs for the social good, or largely free as a house heater in winter).
Currently most pooled miners are actually letting the pool chose the block so they arent taking the bandwidth cost of running a full node.  Even if they are running a full node they are not making use of that typically.  That is an unnecessary source of centralisation that can be improved.
But it also shows that one can mine for profit without validating if there are a decentralised and trustworthy set of people to delegate validation to for people with low bandwidth.  There may also be ways to statistically verify the blockchain by sampling by a number of low bandwidth peers where 100 of them they each validate 1/50th part.
So from that perspective no one is forced to do anything though there is an economic dimension to choice also.  For reasoning about it keep in mind 5 things:
1. voting (validation) and mining are separable tasks
2. mining requires hashing equipment
3. validation requires low-medium bandwidth
4. voting decentralisation is important for bitcoin to retain its policy neutrality properties.
5. mining decentralisation is also important.
@_date: 2014-04-10 19:31:40
But much PoW, ~~GPU-hard~~, ~~ASIC-hard~~.  I am guessing Primecoin as the jumping point for GPU alt-miners once the scrypt ASICs centralize and dominate litecoin network.  Prediction: ~~GPU-hard~~ (people maybe heard of SSL accelerators, hardware wins, its kind of like entropy rules.)
@_date: 2014-06-18 23:40:44
I think the point is if you added SNARKS to a side-chain the security model would offer the same assurances of bitcoin itself (modulo the merge mining rate).  
This is an observation therefore about bitcoin as is itself also: you can steal coins if you can overwhelm the network hashrate by a) double spend attack people (there are victims, you must hold the coins); b) you can rewrite history and retake coins you once held (not ones you never held), c) claim the coinbase transactions.  It depends how much excess power you have and what you think the network will do in reaction if this extreme situation happens.
The new 51% attack on side-chains is the take all the coins because main bitcoin is an SPV client of the sidechain and so will believe ownership asserts via hash majority.
| I can guarantee you Austin and co definitely haven't solved the 51% attack problem with sidechains."
If we're talking about the steal all the coins attack, and without resort to SNARKs (or other new crypto) are you willing to bet one cant do better than 51%? ;) 
@_date: 2014-11-19 12:19:31
Pieter Wuille explained that the OP_RETURN discussion long pre-dates blockstream: 
see also bitcoin-dev list discussion  and views of core developers and dev community and blockstream (comments are different from comments) and Wladimir has different views again - the views all vary as you can see there; probably a better forum for technical discussion.
Core changes are by design a community &amp; technical community consensus based on merit, but that takes time and must be defensive of bitcoin code churn and security and scalability.  There are some technical confusions extant relating to OP_RETURN so I think people should make sure to understand what can be implemented with out of band communication without use of blockchain resources before they assume its political or unfair influence of core developers, or other parties.  I think all the parties are expressing their genuine considered technical opinion.
btw In many ways people who have these debates about claimed political aspect should _love_ sidechains because once they are up, they can have free reign to take novel or divergent assumptions about design decisions which may not all be implementable by bitcoin core, either due to change risk, or novel design shifts/alternatives, or one-size fits all aspect of bitcoin where if there is conflict it cant really support multiple choices (eg blocksize, block interval, replace by fee or not etc some of the design choices may even end up being technically impossible to simultaneously support both of).
@_date: 2014-04-09 21:38:14
[who invented the two-way peg, when asked if he thought the core would be willing to code the enabling change (which itself carries risk that it is designed to avoid for all future changes) called it "the one change to rule them all".  (ie if you make this change, everyone with a pet feature can go do it on a side-chain rather than getting mad at the core devs for not being willing to risk $7B bitcoin value by adding some novel, though highly interesting feature).
@_date: 2014-08-04 14:49:36
I think the reddit title chosen by is a bit misleading as sidechains &amp; treechains are different technologies/ideas with different and largely orthogonal objectives.  The original linked article on greenaddress just describes the two without saying "vs".
It might be that for example it is convenient to test treechains ideas in a sidechain.
Treechains builds on an idea I proposed last year called committed transactions.  The base idea which so far (absent snarks) is full node only, is that miners only partly validate the transaction, and full nodes do the rest of the validation.  From there has been exploring the what-if of sharding the blockchain to allow people with weaker security requirements to have their tx mined with lower proof of work by nodes that receive a subset of tx.  Something like that, the details are a bit TBD I think.  So I think treechains objective is to allow non-pooled mining, and higher (low assurance) tx volume using sharding.
Side chains have a different objective: to provide a generic extension mechanism for bitcoin in a way that supports SPV nodes.
Side chains are described on this bitcoin-dev list post:  and written about in the OP greenaddress blog article also. 
I presume it is clear that bitcoins fundamental properties partly depend on its decentralised neutrality.  There are various things that could be done to improve the decentralisation of bitcoins current level of cloud &amp; pool mining centralisation.  I am and hope others too are committed to decentralisation, user control and network neutrality of bitcoin.  Scalability is also part of decentralisation.  If things are insufficiently scalable then "trust me" solutions end up being used by necessity, which does not use smart-contracts to their proper potential.  (And leads to things like mtgox collapse, and the other 50% of centralised BTC related infrastructure that got hacked, "hacked" or accidentally lost their coins).
@_date: 2014-12-22 18:28:01
or maybe tahoe-lafs.  abusing the blockchain as a way to send tweets is a not a good use of bandwidth.  or why not make your own p2p protocol that tunnels over common protocols to make it hard to censor.  eg like tor does.  the blockchain exists, and someone wrote it, that doesnt mean you should put your tweets on to it, its very expensive.  it would be cheaper to send it using a sat phone or something, block subsidy included.  that also cant be blocked easily.
@_date: 2017-02-27 13:02:12
I think Tone did not bad, it's like going on TV - it's hard to get a point across when interacting with a politician or hostile TV presenter live - Roger was talking over, interrupting, heckling while talking, and making emotional appeals which dont relate to technical reality, and also trying to slide some known incorrect claims past him.
@_date: 2017-02-17 11:24:35
looks like there is a patch in review for bitcoinj.  
@_date: 2017-02-13 16:04:39
felix weiss proposed a soft-fork way of adding confidential transactions to Bitcoin.  
@_date: 2017-02-23 09:49:24
actually if you read what u/jonny1000 has been explaining, a small minority of miners can mess with BU in a kind of worsened selfish-mining like attack, splitting the median size by hashrate repeatedly.
@_date: 2015-05-03 22:15:01
The core dev label is overloaded.  Some people interpret it to be someone who has commit access to bitcoin's github, and with that definition its like a handful of people.  A looser interpretation is someone who actively codes on the bitcoin project (presumably with feature level or important contributions to code review, which is a big part of bitcoin coding).  You can look at the stats on github or posted some summary stats a while back on reddit somewhere.  There are also people who are interested in bitcoin protocols which I guess is more like feature exploration and/or smart-contract programming.  does do interesting threat analysis, and protocol work as well as some bitcoin coding. 
@_date: 2017-02-10 08:08:11
they dont.
@_date: 2015-05-31 13:56:42
| I don't want a Bitcoin where developers do what there employer wants so the can keep there jobs.
I agree and those of us bitcoiners who founded blockstream not coincidentally want whats best for bitcoin interests and ethos, thats why we founded blockstream - to improve bitcoin.  Take a look at 
We tried to do a number of things to backup the "cant be evil" mantra.  That's why and have contract clauses allowing them to resign if they view blockstream is doing something they disapprove of in connection with bitcoins interests and ethos and have blockstream pay their salary for a year to work on bitcoin (independently or under some foundation as they prefer).
@_date: 2017-02-22 13:08:00
you could run an experiment: go say something contra on r/btc you will be attacked instantly. if your name is googleable they'll "google research" try to harass you. they harassed one devs father when they found him on a cancer support site. you tend to receive death threats. some swatting attempts were tried also (very dangerous in the US, people can die from such things).
dont forget you wont see the worst of it because their mods will delete them.
@_date: 2014-04-11 21:09:55
Yes. Its very clever. Still an alt which is inherently fragmentary to the ecosystem and prevents network effect.  But its fiendishly clever, best soft-premine concept I've seen yet, hardest to rip-apart with criticism.
@_date: 2017-02-22 14:15:31
no he didnt let on he was working for R3 for a while people figured. this would confirm.
@_date: 2017-02-09 05:37:57


And yet Johnson Lau proposed a big list of onchain scaling forks.  I dont think anyone seems to be aware of.  They are hard to read because they are highly technical but there are some very clever ideas and well thought out combination of hard-fork only fixes.  
@_date: 2017-02-22 14:14:17
that is not it at all. one can have a constructive discussion about trade-offs while being cognisant of facts without going full-negative. (maybe like not going full-retard -- lose ability to reason 
@_date: 2017-02-23 09:45:03
I do not think discussion of technical tradeoffs nor candidate protocol improvement ideas were ever intended to be considered off-topic.
The sidebar says "Promotion of client software which attempts to alter the Bitcoin protocol without overwhelming consensus is not permitted." Now I think that policy is kind inadvisable in obviously inviting use of the Streisand-effect as justification for inadvisable forks, but it is nevertheless clear.
u/LovelyDay you might do better to offer some actual technical discussion rather than intentionally moderator baiting and trying to claim the Streisand effect.  Assuming that your interest is to have a technical discussion rather than a trophy to show in r/btc.
Obviously discussion of how to improve bitcoin has to be on topic.
I think enough discussion has been had in other forums, and in here for that matter, for example by u/jonny1000 to know that BU has been thoroughly debunked in having a large number of technical flaws as the OP mentions.
@_date: 2017-02-05 16:47:50
It is probably time to change the capacity metric to be about transaction throughput not blocksize.  It's like CPU clock rate which hasnt gone up that fast in the last decade, even though CPUs are enormously more powerful and transistor counts are 100x, due to bigger faster caches, higher IPS, more cores, smaller features, higher density etc.  As it will be with more efficient usage of existing space (less wasteful transaction patterns), smaller transaction types (schnorr aggregation), support for trustless layer2 (lightning, or write-back cache), and improved latency handling (fibre, compact blocks, maybe weak blocks), better fungibility (mast, schnorr, other) as well as more on-chain capacity (segwit and things to follow).
Technically you can increase on-chain transaction throughput (and blocksize) with a softfork via extension-blocks, or safe-hard-fork (aka soft hardfork or evil fork... not very "soft" but can be considered a soft fork of sorts) or sidechain as has proposed.
@_date: 2017-02-09 04:22:48
I dont think there are in-principle disagreements - but there are technology and science limitations that preclude that being feasible or agreeable.  eg As you may have noticed Johnson Lau and Luke Dashjr posted a number of fork proposals on bitcoin-dev mailing list over the last months.  There are also empirical tests people will want to do on segwit and lightning and compact blocks and fibre post adoption to understand what the next bottleneck is.  Also some of the ideas are in progress research - hard to paint a definitive X will happen on day Z, when we dont yet know if X or Y is the best method, or if Y even works out ultimately.
@_date: 2017-02-08 10:27:22
And to single sig transactions - schnorr aggregation works across multiple inputs too.
@_date: 2015-05-07 06:32:55
Decentralisation is key to bitcoins value, user-centric ethos, and permissionless nature.  There are a range of blocksizes for which there will likely be good-enough decentralisation, but as a trend, as the blocksize increases, so does centralisation slightly.
If (non-pooled) mining, or pool decentralisation and fullnode-mode use fall below some threshold bitcoin ceases to make sense, so we must keep it in a good, decentralisation safe area of the parameter space.  The decentralisation safe maximum blocksize increases slowly inline with software, hardware and networks improvements.  
There are other factors affecting mining centralisation - for example pools getting large, ASIC manufacturer consolidation/bankruptcies, vertical integration, availability of home miners.  If mining was more decentralised we could perhaps tolerate a little higher blocksize than would otherwise safe, because while that would increase centralisation, it could then still be enough decentralisation (ie more than now, if a bunch of other centralising issues were improved)
Larger blocks also affect block transmission latency, and block interval is balanced with block latency to keep low orphan rates.  High orphan rates are bad for network progress, security and stability.  New approaches Gavin Greg and others are looking at (IBLT etc) may reduce block transmission latency, but arguably not without some other side-effects in homogeneity in blocks which is slightly counter to decentralisation itself.
In some ways of thinking bitcoin blocks are already 100x oversubscribed - probably &gt; 100x transactions than fit in a block are happening offchain - mainly inside bitcoin exchanges, and those coins are subject to custody risk as a result of their offline status.
Other approaches to increasing throughput exist, the micropayment hub related ones like payment channels, lightning and variants.  Bitcoin throughput relates to network/blocksize but also CPU, memory and disk efficiency to avoid bottlenecking on another dimension.  CPU efficiency of validation code (like libsecp256k1 by increasing compactness of transactions (eg schnorr multisig rather than ecdsa) and more tight memory &amp; disk usage (the mode that doesnt keep history).
Also deploying a change via hard-fork is not without risk; people may get left behind who dont upgrade fullnodes by the cutoff date, and SPV nodes that connect to old fullnodes and stale sites/services relying on those fullnodes are then at risk of low hashrate attack on the straggler miners still mining small blocks (they will ignore large blocks).
So I dont think anyone is saying there is anything fundamental about 1MB, but there is something very fundamental about bitcoin to keeping the parameters well within the decentralisation safe range.  We should look at it holistically and look to adapt that cautiously, eg by smaller increments and after more stress testing on representative hardware/networks modelling the existing network.  
There is also a question of whether the transactions in blocks are all useful, which modifies the question of how full the blocks really are.  Some fee pressure might be useful to determining that.  It seems clear that in the long run bitcoin security needs fee pressure, or large scale commercial altruism, or assurance contracts or something in order to pay for network security.  But its also true that subsidy will be here for some decades, and the value of subsidy depends on bitcoin price which would increase with bitcoin and transactional demand (so that 3.125 btc/block could be more than today in $ terms for example).
I think its more important to work on scalability at protocol level than throughput by upping the parameters for the longer term.
@_date: 2017-02-23 09:28:24
it might be enough to nearly collapse the fee market, so it could have a pretty big impact. it also allows more throughput, and makes spam attacks more expensive. it is a first step, with more incremental steps to follow like schnorr aggregated signatures, MAST, and helps lightning for a prospect of real scale.
@_date: 2017-02-04 00:41:54
Median transaction size is currently &lt; 250 bytes so it is &gt; 4000 tx/block (&gt; 6.7 tx/sec) with segwit at capacity it is &gt; 8000 tx/block (&gt;13.3 tx/sec), plus if the 30% adds up &gt; 10,400 tx/block (&gt; 17.3 tx/sec) and the 41% 11,200 tx/block (&gt;18.8 tx/sec).
@_date: 2014-12-20 16:22:02
those claims are unsubstantiated hyperbole.  if you read the authors own links they dont support what he is saying.
@_date: 2017-02-17 10:52:46
it depends on their wallet. most wallets are ready, so even if the user is not creating segwit addresses, they will be 0-confirm informed of transactions they receive from segwit users.
most smart-phone wallets are also (for better or worse) auto-upgrade. so we could expect that issue to be quite short lived for SPV users.
@_date: 2017-02-09 04:39:39


Segwit was that compromise and it is a literal 2MB fork.  The blocks it sends you can network capture and see are 2MB, not in parts/witness areas etc, but actually a bonafide 2MB block.  Many people from all views just misunderstood that and added to confusion.


If people cant exhibit self-interest we may have bigger problems.  Probably the people that are wiser and/or strongly invested may have more influence is another way this could resolve.
It is bear in mind easy to throw around ideas of could fork this way or that way or compromise this or that are easy to say, but each fork this implies probably 3-6mo of development, 3+ mo of testing, and depending on the fork 3-12mo of coordination.  So without any judgement on the method even, it's just pragmatically an automatic delay.
People who think they can rush things self-evidently lack the experience to manage bitcoin security.  That's not an insult but it's a very complicated area where some very smart people spent 5-6 years of their life learning every nuance of the system and how to avoid problems they learned the hard way earlier in bitcoins history.
@_date: 2017-02-23 09:48:04
Roger aside who probably believes things, it is curious to reflect on why someone would promote something that they know is broken. occam's razor may suggest they just dont know how to fix it, and want to hold onto the flawed sales pitch that it lets non-miners influence size. (In fact that claim does not work, and BU just removes the balance and cross-check that satoshi put into the protocol that full-nodes balance miners by enforcing consensus rules).
@_date: 2017-02-10 19:12:16
Many altcoins add innovations first developed in Bitcoin. I dont think it is sinister that Charlie Lee would advocate for adopting it in Litecoin.  If anything it is helpful in showing that segwit is a technologically sound advancement of scale and functionality.  And maybe it adds confidence as a live test to show that it works.
@_date: 2017-02-03 05:51:27
Signature aggregation does not require segwit.
@_date: 2017-02-09 08:25:43
the CSS is a good thing, it fixes brigade voting which r/btc is very vulnerable to.
@_date: 2017-02-11 03:06:20
It is always useful to have a plan "B".  Another one is libbitcoin by Amir Taaki, and another is btcd written in go.
@_date: 2017-02-09 04:55:18
It's just a needlessly abrasive email - sending this to Johnson who has been diligently working on numerous scaling fork proposals is just un-constructive and unprofessional and totally uncalled for.
@_date: 2017-02-22 11:53:22
so what does it say?
@_date: 2015-05-03 21:48:53
Because that is a waste of bandwidth, the blockchain is a transaction integrity broadcast channel.  If you want to send application messages you should send them out of band using payment protocol or extensions thereof.
@_date: 2017-02-23 09:50:51
I do not think a technical defence exists. This topic has been hashed out at length on at least four different forums.
Topic banning is a bad idea IMO, but you can not say that BU is not-broken because Streisand, that is a logical fallacy.
Go ahead and give it your best, or call for technical re-enforcements if you cant defend it yourself.
@_date: 2017-02-23 10:25:20
do you have any technical arguments refuting the OP specific claims?
@_date: 2015-05-10 19:17:32
To me at a high-level bit-gold &amp; b-money seem like rather similar and close to equally relevant?  bit-gold had a different proposed mechanism involving collectible markets (bundles of differently valued stamps having a similar bundle value) vs b-money's server voting to decide on supply increase &amp; cost.  Maybe bit-gold was slightly more specified but both left both details and system coherence questions unanswered I think (or someone would've tried to implement the time).
@_date: 2014-04-13 21:52:23
assurance bond? if people want the feature seems fairer rather than ongoing rent-seeking.  i think like said that rent-seeking tends to be forked as the switching cost is really low, just the cost of maintaining a downstream tiny patch.
@_date: 2017-02-22 13:28:24
I've heard such views before - that bitcoin supporters harass people.  I have to say while one "combatting FUD" could be another persons "troll" the level of pettiness, adhominem and vitriol I would say is self-evidently worse on r/btc.
What might get you into arguments is claiming things without being able to back them up with facts...  I think all could do with calming down and sticking to rational discussion about tradeoffs, no adhominems, no inflammatory sock attacks, no paid astro-turfers.
I can assure you no one that I know has anything to do with astroturfing nor paid negativity campaigns.
@_date: 2014-04-14 01:03:02


Maybe you can use fiat-shamir transform to spot-check those anti-spam SHA3s as used in coelho merkle-hash PoW which you adapted for Dagger.  (eg driven from the stack trace samples organized as a tree)
@_date: 2017-02-27 13:06:50
Tone is literally financially qualified, he worked on wall street and has a Master's degree in advanced finance.  That might be relevant as Roger often tries to claim financial expertise (self taught) relative to developers as a reason his views should carry weight.
@_date: 2017-02-09 04:59:08
There is a sort of asymmetry in decorum and reasonable behaviour standards which is mismatched between private abusive behaviour and public.
@_date: 2017-02-06 04:26:23
Minor correction:


segwit blocks include transaction and witness in place, interleaved; there isnt a separate witness data area.  There is a 2MB chunk of data - the new block version including segwit parts - that is sent over the network to other nodes.  Its format is a sequence of (transaction,witness) x 8000 or whatever.  If a segwit node encounters an old non-segwit node it will serialise a backwards compatible block which omits the witness parts and so is &lt;= 1MB.
@_date: 2017-02-23 11:51:20
FOSS is selfless work, not something for everyone - with something as heavily optimised as bitcoin has been over the years, there are not so many obvious win-win opportunities for further optimisation.  It's hard enough to even catchup with what has been considered and then to keep up with the pace of innovations is nearly a full time job for a CS uber-geek with a lot of specialised knowledge. If you're up to speed and keeping that way, you're smart and dedicated - and generating ideas that are rejected by peer review, not laughed at, but with citations for why it was considered is a milestone in itself, a stepping stone towards finding a new insight.
Not everyone is able to accept peer review with good grace, sometimes delivered with some historic basics education, many contributors have repeated the same FAQ a dozen times in as many weeks, for the most part are polite and helpful but sometimes can get frustrated by demanding FAQ explainer requests.  Maybe an idea is just not as clever as the proposer thought it was, or an OK idea but not worth the complexity, cost; and most likely was considered and discarded years ago, and if you go search around bitcointalk or IRC logs you can probably find the discussion thread even.
I wouldnt read too much into what the NegSocks say, they revel in or are paid to generate negativity.
@_date: 2015-05-29 13:25:09
Yes - firewall config was changed since the above - can you retry?
@_date: 2017-02-11 03:45:53
Last point I dont think it speeds up, probably slows down slightly - more work on cross compatibility testing?
But today I dont think it's too bad most of the compat testing is done by the alternatives.  And a number of the developers of those versions are protocol contributors themselves.  Alternative implementations of the same BIP help find bugs too.  So I think that's a netwin.  found interesting defects in bitcoin code in the early days with his haskell bitcoin.  Even BIP1 was written by Amir Taaki from libbitcoin.
Probably best for protocol speed up is more reviewers and participation in protocol discussion.  Today Luke Dashjr and Johnson Lau produced maybe 5 or 6 BIPs related to scaling that didnt yet get much protocol experienced review.
@_date: 2017-02-09 05:08:15
Yes dont listen to me, think for yourself!
@_date: 2017-02-22 18:40:53
like many technical people, he doesnt like to see falsifiable misinformation stand uncorrected. the participants repeat a lot of false information and to debunk is a sure fire way to attract their ire. c'est la vie on r/btc.
@_date: 2017-02-23 12:09:48
read this  and stop asking people to answer FAQs for you. see also BIP 1 and 2.
@_date: 2017-02-23 11:17:42
others will code and promote your idea, if the idea is good enough.
@_date: 2017-02-13 04:23:51
oops, I knew that too! fixed.
@_date: 2017-02-21 08:27:45
@_date: 2017-02-17 19:52:54
the sender sends to an address. if the address is a p2sh address, provided by the recipient, then the sender does not know and cannot tell if that address is a segwit or non-segwit addess.
this is because the spender will only reveal the script inside the p2sh address, at spending time.
@_date: 2017-02-22 11:07:40
man that's even better :) slightly slower maybe?
@_date: 2017-02-11 03:22:12
Also UTXO access latency degrades super-linearly in the number of entries.
@_date: 2017-02-09 05:20:08
BU has no consensus threshold.  It is activated when the node and miners call each other and decide to trigger something.  Or when bugs kick in and nodes are already misconfigured (as happened last week).
@_date: 2017-02-09 04:29:08
Thank you.  IMO we need to calm way down.  Bitcoin is disrupting the world we should be celebrating that and collaborating on incremental things we can agree on, not trying to make bitcoin fail due to inconsequential infighting.  One can make incremental progress on win-win stepwise things without even knowing the mid-term future, nor agreeing yet on what the next steps are.  Which is good because some of the science isn't even understood yet, bitcoin has a lot of bleeding edge tech convergence around crypto, game-theory, consensus algorithms and p2p trust/security models.
@_date: 2017-02-16 16:29:52
what do you think they dont like about the top-notch work of volunteers?
@_date: 2017-02-11 03:41:02
Well you just need a big majority of mining on a well security maintained version for security and everyone to run that majority with opt-in additional ones.  In a plan B situation one implementation may have had some huge political issue and the community wishes to avoid relying on it for some reason, so then the "everyone runs core + other to cross check" would change to "everyone runs &lt;planB&gt; + other to cross check".
@_date: 2017-02-09 05:03:34
It is opt-in to create segwit blocks for miners, even after activation; it is opt-in to create segwit transactions, it is tested, it fixes a lot of good things to fix, it enables a more efficient variant of lightning and importantly it will not create chain forking risk.
@_date: 2017-02-17 16:23:35
the recipient chooses the conditions under which he can respend. as sender you do not need to know, and indeed can not even tell whether the recipient is using segwit or not.
@_date: 2017-02-09 09:42:44
Unfortunately some of them are connected and harder to do individually.  Also adding too much optionality multiplies up the testing permutations otherwise it might have been interesting.  It's also more development work.  But BIP9 for versionBits which is now used, does allow modular upgrades.  I think people would like to see a solo module go live before doing parallel ones.
@_date: 2015-05-09 06:50:08
Satoshi I think cited b-money because I referred him to it see footnote 34 of   I think I was aware of bit-gold somewhat though it was discussed on a list I was not subscribed to, but b-money had come to mind when I read Satoshi's abstract.  Which is to say Satoshi was also not aware of b-money.
@_date: 2017-02-23 09:26:31
where? never heard of such.
@_date: 2017-02-09 01:52:09


That seems like the status quo.  Not constructive and not good for users experience and fees.  Probably doesnt much hurt hodlers and exchanges given their average transaction sizes.
@_date: 2017-02-09 06:57:37
By pure coincidence I was just predicting this could be a problem yesterday.  HF are tricky to handle.  SF are safer for non-controversial things.  SF with bug fixes and opt-in features and equal scale seems like a simple safe direction vs creating these kinds of needless risks.
@_date: 2017-02-21 23:48:36
trying to say something about lightning? ;)
@_date: 2017-02-09 05:25:05
It's probably a conspiracy too far.
@_date: 2017-02-13 16:08:31
as to the size issues one thing to note is that while they are bigger confidential transactions are more powerful, and may often replace multiple regular transactions.  eg where people are using multiple regular transactions for value privacy, as a number of people do.
I made a longer explanation of this and related topics at bitcoin scaling hong kong in Dec 2015 
@_date: 2017-02-08 22:26:41
I am sorry you got this kind of un-constructive nastygram.  To my mind u/jl_2012 is endlessly constructive and generating ideas, BIPs and specs and is working on hard-fork proposals towards finding consensus on future forks.  You can see the specs he has created on linuxfoundation bitcoin-dev  and  and  and  and more.
@_date: 2017-02-09 09:49:57
But say it were made modular at investment of say 3 months development and testing work so that segwit and other fixes/features were separate BIP 9 signal from the weighting allowing 2MB segwit.  And then say segwit activates without the scale improvements.  Wouldnt the stupidity of it just be boggling :|?  Then we'd be wondering about fees going up and it would be 3 months later.
@_date: 2014-04-09 23:16:10
the addresses would not be compatible most likely; but if you have a coin in your wallet on one side-chain, you can move it to another side-chain by a special kind of spend-to-yourself, by atomically swapping it with someone wanting to move the other way, or via a market-maker.
the spend-to-yourself is most likely to be reserved for liquidity payments because the other methods more space efficient where not needed.
@_date: 2017-02-10 17:39:57




That would be at least logical - however in the mean time there is nothing that anyone can do, because it would take 6months to have an alternative ready.  Luke DashJr and Johnson Lau have a number of safe fork and long term hard fork proposals with draft specs and implementations but none of them are production ready and tested upgrades.  Johnson has a couple of testnets.  So the people that are being punished are users via higher fees and companies who's service suffers if they pay the fees or becomes less attractive if the users pay the fees or cant grow users.
So it seems again illogical to not at least take the available scale while the next stage scale of schnorr aggregatable signatures to get to 2.75-3.3 MB equivalent of transactions (but in 2MB of storage and bandwidth) can be done and other things later.  I dont think miners would think BU is credible because any advice would tell them it has a wide range fo problems, and even if they were all fixed requires 6mo+ of coordination.
@_date: 2017-02-22 13:05:49
it's at least fairly equal opportunity - people on that forum will go "google research" and smear anyone who criticises group-think or questions censorship happening on the sub-reddit.
not that this forum doesnt have it's own censorship problems (topic banning.)
@_date: 2017-02-06 06:15:01
Lets just say Roger is a little prone to exaggeration for effect and leave it there.  I am also not a fan of topic moderation, but BashCo is a mod so I expect he knows.
Now Roger did get himself banned from all of reddit temporarily for doxxing someone, but that was something he did on his own subreddit and that reddit site admins did.
@_date: 2017-02-18 18:37:10
Would you consider making a 10 btc or 12.5 btc titanium coin at btcc mint? I think some people prefer the coin form factor to the blocks.
@_date: 2015-05-07 05:31:30
Well I think we can trust everyone to be mature enough to reason on the basis the neutral merit based technical arguments, but if you're pointing at blockstream as if its a conflict of interest, note that Gavin is an advisor to coinbase, not that I see any problem with that either.
I think people should focus on the technical arguments: there were quite a number of very detailed explanations and summaries of in some cases quite old analysis written up in the posts linked at the top.
I rather liked Bryan Bishop's simple argument: 


@_date: 2015-05-31 00:41:28
I do think bitcoin loses most of its user ethos features (open access, self-determination, permissionless innovation, policy neutrality) if it fails to be decentralised.  To me other than the 21million coin supply curve, these properties are part of the social contract, and users should reject changes that reduce the availability of those properties.  Ultimately users *are* in control with bitcoin.  If we get to a situation where bitcoin becomes centralised such that merchants, miners or ecosystem players end up in control, it will be a short-trip back to the central banking status quo - thats one way for bitcoin to cease to be bitcoin.  My view is these defining properties must be invariant, and to enforce that users must be vigilant and refuse to use software that violates them, as this is the mechanism for retaining your rights, and maintaining the social contract.  As developers we must not trade-away user ethos features, it would be a violation of the social contract.  
I realise its a hard problem, but to make the ethos features available to more people, developers also have to find ways to make bitcoin scale better, as without scale, defacto users end up offchain, and users of third party custodian based offchain transactions are often not benefitting from many of the security assurances bitcoin offers.  Its hard because some of those requirements are in conflict.  But we're not done yet.  Lightning is an interesting first step, that does change the scaling to much better than O(n^2).
I believe Gavin acknowledges the importance of decentralisation also eg listen to his answer when Peter Todd put the question to him of policy neutrality on the letstalkbitcoin show 
The problem is bitcoin scales somewhat poorly O(n^2) .  I think its important to focus on using the blockchain efficiently, and improving the scaling (eg with lightning network or other similar extensions).  
In the mean time I prefer approaches that are optional to use - allow people to opt-in so that those who want small transactions but dont care as much about decentralisation can get that without breaking the assurances arising from decentralisation for the users who really value them.  There are ways to do this, though they also are not simple, and have their own different risks.  (See about soft-fork opt-in block-size increase  )  A hard-fork that is not an obvious clear consensus is actually existentially dangerous for bitcoin, splitting the network in two with conflicting and rapidly diverging ledgers ends in disaster.  Clearly no one wants that to happen.  (I didnt read Gavin make *that* comment, comments like that should not be made).
There are lower risk (and simpler than the opt-in) approaches to increasing blocksize to get breathing room for better scalability.  I hesitate to suggest them because they are more miner enforced, and I think hard-forks are better as they require large scale user approval.  However that argument assumes people are circumspect and informed and understand the risks and implications.  A miner enforced modest blocksize increase is maybe a lesser evil than the risk of a non-consensus hard-fork that risks a splitting the network, if it really is the case that people dont understand the danger.
Certainly what said about cypherpunks views on the importance of decentralisation for the user ethos of bitcoin resonates well to me.
@_date: 2017-02-22 13:09:39
apologies probably you mean.
@_date: 2017-02-05 18:00:45
@_date: 2017-02-17 12:58:21
maybe something like that will happen in due course, but design, implementing, testing and network validating a hard-fork will take months leading to more delays. looking at segwit as an example that could be another year. makes more sense to move forward in parallel and bank the incremental scale we have now. in the mean time lightning can then be tried, as well as schnorr aggregated sigs and MAST etc for more onchain scale. for more elaboration and my take on what that sequence might look like watch  offset 1hr.
@_date: 2015-05-04 17:39:30
(comment on something Joey Krug says in the video ^^ that augur may use an ethereum sidechain) btw I dont think you can (directly) make an ethereum implementation of a bitcoin sidechain unless ethereum changes its proof of work to bitcoin's standardised hashcash one, otherwise it would be unable practically to provide usefully high hashrate compact DMMS proofs (in order to return coins to bitcoin).  Someone could probably (with some work - not looked at it) do the reverse as counterparty did - fork ethereum into a sidechain (so that it uses bitcoins PoW &amp; bitcoin currency).
@_date: 2017-02-17 16:46:44
more details about cleanstack: 
miners will not currently mine segwit transactions because of standardness policy and also CLEANSTACK was added in 0.11.0.
and all miners are running CLEANSTACK because they activated two softforks since then so are all mining on &gt; 0.11.2 because of BIP65 and actually 0.12.1 because BIP68/112/113 softfork was not backported to 0.11
@_date: 2015-05-08 05:49:23
Progress is bad, lower variance is equivalent to progress.  The reason you can see by looking at the extremes: say there was zero variance, then the fastest computer would always win.  Any reduced variance runs that problem, just to a less extreme level, eg say for some parameters someone with 10x as much hashrate as someone else, if they get 20x advantage thats bad as its an economy of scale and disadvantages the smaller miner, which is bad for decentralisation.  You can get very close to 0 variance for example by having a very large number of sub-PoWs eg 256 of them or whatever, that will make mining variance quite low.
@_date: 2017-02-19 05:46:46
maybe use the same design as 5 BTC but with 5 changed to 10? I think a different form factor helps aesthetics much. actually i would've been just as happy if the 5 BTC was the same dimensions as the 1 BTC &amp; 0.5 BTC.
@_date: 2017-02-20 18:05:30
it started as amadeus anagram with my name in it, with a 3 instead of e for 'leet writing. like wolfgang amadeus mozart.
@_date: 2017-02-09 09:46:18
You are correct.  Dont worry about the detractor he doesnt seem to get it.
@_date: 2017-02-23 12:16:50
some people want to centralise bitcoin. of course it is not popular to say that because it wont be bitcoin anymore, so they try to package the story in different wrapper stories.
@_date: 2017-02-09 05:04:30
Not sure, but yes he and many writing are wrong in their basic understanding.  Hard-forks are not fast.  Segwit can be online in 4 weeks+2.
@_date: 2017-02-15 01:35:40
yep hard to know. maybe a mixture as there is some independence and individuals can also have multiple even partly conflicting motivations.
given the coding and testing cycle to get something like segwit deployed, that a planned HF has never been done before that would seem to minimally delay scale and cause fees to unnecessarily rise for probably 6months absolute minimum (deploy not active).
@_date: 2017-02-09 05:27:24
@_date: 2017-02-23 12:07:49
i wrote what i wanted to say on this topic and i stand by it: 






@_date: 2017-02-09 05:17:15
Thats not what you would do.  Segwit if needed could be soft-forked out without any funds loss, and a replacement mechanism introduced.
@_date: 2017-02-09 05:38:11
@_date: 2017-02-22 11:08:08
h0dl on for dear life!
@_date: 2016-03-29 17:55:02
skip to offset 9m00s like this  to save yourself viewing time.
There does seem to be some attack the person not the facts going on in bitcoinland.
@_date: 2017-02-17 10:40:28
Segwit is backwards and forwards compatible.  The decision of what script to use to authorise onwards spending is made by the recipient.  The sender doesnt need to know, and in fact cant tell if the recipient is segwit using or not.
@_date: 2017-02-22 18:38:05


u/luke-jr implemented a BIP and code which was discussed with miners present at the jul 2016 miner / dev meeting in the bay area.  so actually, that was ahead of schedule by any definition.  and since then u/jl_2012 has made a number of further scale proposals.
everyone present at the hk roundtable had clear understanding that the developers present could only propose.  consensus has to startup somewhere.
other developers and ecosystem participants are invited to critique, improve or suggest alternative BIPs.
transcript 
BIP &amp; code 
@_date: 2017-02-09 05:21:54
Hashrate can be measured but is centralised which is why we're having this discussion in the first place.  hashrate alone can not introduce protocol changes because of the way Satoshi designed Bitcoin's checks-and-balances security model which basically puts protocol consensus rule enforcement in the hands of economic full nodes.
@_date: 2017-02-06 02:50:53


and he did that, months ago.  And has made several other proposals since.  Johnson Lau also made multiple fork proposals.
@_date: 2017-02-22 13:38:49
it's easy to feel relaxed about attacks on others. you should try being subject of the attacks for a while. he is not attacking rbtc, he is trying to combat FUD and misinformation to help bystanders who evidence shows sometimes otherwise believe it. of course you get attacked for doing that.
@_date: 2017-02-16 03:51:52
I am not sure. maybe someone like the taint tracing services that exchanges use would have analysis that could create that kind of information. in terms of breaking up values (not even mixing) i've heard of multiple people doing that, seems to occur to lots of people.
@_date: 2017-02-09 09:24:48
I believe this is likely true.
@_date: 2017-02-14 23:49:12
tl;dr for miners if you agree lightning has potential to add more scale and want more scale: activate segwit now?
@_date: 2017-02-18 18:33:38
speaking of bitcoin hero reminds me of this photoshop of marvel poster  
@_date: 2017-02-09 09:53:31
Hmm I bet psychology: people would actually signal for both BIPs.  The choice would make them happy and then they'd signal for both segwit and 2MB.  We'd still lose 3months or whatever development and testing were involved, and it might be difficult to find any developers willing to do something largely pointless - but it might work :)
@_date: 2017-02-09 04:26:53


I am kind of tired of being right around here.  I am 3 for 3 in the last few weeks.  BU, Zcash &amp; ETF in sequence.  Just today I am in private conversations about an ETF problem which I did not know was about to have this structural problem when I wrote the OP.
This stuff should be obvious to anyone who is paying attention and thinking for themselves.
@_date: 2017-02-09 04:34:00


except BU just forked by accident due to bugs right after I coincidentally pointed out it was inadequately tested and someone wrote an angry blog post claiming otherwise and insulting me for offering the peer review.  I mean I have thick skin so whatever, but you should pay attention to these things evolving.


It is controversial to many holders and some businesses that are concerned about severing the checks and balances between miners and centralisation security decisions.  Satoshi made these checks and balances as part of the security model of Bitcoin.  Changing them in a cavalier manner without really even understanding or acknowledging the huge tradeoff and loss of security is irresponsible.  Sorry, I would like to see a constructive way forward, but unlimited size set by miners is not the ideal way to get agreement.  There are a range of other things that have been proposed that are better.  Just act a bit more moderate and incremental we dont have to solve all future problems today because we dont have the technical answers for how to do some of those things.  And we have lots of incremental progress and also layer2 scale which is all happening this year.  Why create a controversy now?
@_date: 2017-02-09 05:13:26
Yes it is probably not helpful to say who, maybe they'll come back.  There also several current devs who are close to sick of this unprofessional conduct from both a few formerly prominent people and a few holders.  It only takes a few people who lose decorum to make an unpleasant environment.  People need to calm down, and try to prevail with logic and incremental progress.
@_date: 2017-02-09 05:02:22
Well I think users and companies should talk with each other and with miners.  In my opinion miners should look to activate the rules that the clear majority of users and businesses want, so long as it is safe, and opt-in and they can judge for themselves it is good for Bitcoin.
@_date: 2017-02-23 12:23:43
If anyone wants to take a go at refuting basic flaws pointed out prominently for all to see in bitcoin magazine some weeks ago feel free to present some technical arguments.
articles by u/aaronvanwirdum and cite some analysis by u/jonny1000 
@_date: 2017-02-03 06:36:30
It is simpler and easier to do security testing using the segwit soft-fork script version mechanism, than using normal op code soft-fork, but schnorr signatures and signature aggregation can be done either way.
@_date: 2016-03-03 00:27:52
What are you guys talking about? It's a what-if technical discussion because some miners asked the question if it was possible. There are also posts explaining how to do it with a soft-fork.
@_date: 2016-01-31 15:00:29
Olivier if that were the case, you would work within the BIP process and have participated in the scaling workshops to get consensus on an approach.  Then you would have forked and maintained a client optimised for some purpose (or just for coopetition).  You'd probably need some developers with some experience - they tend to be easier to attract when your coders are not running around saying they want to "fire core developers" nor rocking the market with drama of a rushed hard-fork that puts funds at risk.
I am very happy to chat offline about this and working towards collaboration.  But please - be accurate in your representations of what you are doing.  If that is your intent it is a noble one, but "classic"'s actions to date belie that claim.
@_date: 2016-01-18 11:26:42
Bitcoin was imagined as a solution to moral hazard, that works because it is by design hard for the majority to prevail over the minority. This is why hard-forks are by design hard. Trying to force a hard-fork by political means is dangerous to the very idea of Bitcoin.
@_date: 2017-02-22 13:23:51
We heard from an astro-turfing company that claims someone on r/btc is paying them to do that. Including the personal attacks on named individuals. Hoax? Real? Unclear. But the evidence kind of looks consistent at times.
@_date: 2017-02-13 12:35:12
You could use bitcoin this way eg extreme address reuse where each wallet has one address only. However that is quite bad for fungibility &amp; privacy. Checkpoints are in the process of being phased out as they are form of somewhat centralised control and replaced with blockheight hints (that still work with a deeper reorg just less efficiently).
One can obviously do things with lower overhead by reducing the security model. But you could do that unilaterally without weakening the existing security model. For example Jonas Schnelli made a patch for initial SPV mode that switches to fullnode after catchup has happened in the background. You can also turn on pruning to reduce local storage. And you can turn off relaying if you have low bandwidth.
@_date: 2016-01-09 21:41:00


thanks :)
@_date: 2017-02-09 09:56:02
some other FAQs 
@_date: 2017-02-21 20:45:31
courtesy of 
@_date: 2015-05-04 18:19:03
Real Soon Now :)  I believe has commented elsewhere on reddit that we have an test version running and plan to publish the source soon.  Note there is a difference between access to source, federated and 2wp.  (Joey Krug mentions federated model, which can be run without a 2wp mechanism available in bitcoin).  
A 2wp mechanism being standardised and implemented in bitcoin (or equivalent flexibility via scripting or op codes: bitcoin can almost, but probably not quite, do 2wp using existing scripting flexibility, so there are a range of bitcoin script extensions that could enable it) is something for the technical community to consider and will take more time.  We cant make presumptions about what the technical community will reach a conclusion on other than to comment that our founding team is part of that community and considers the flexibility to extend chains is useful, and a number of other people we've seen do also from the initial largely positive technical community response to discussion before the sidechain idea was not associated with a company, as well as after we co-founded blockstream.
Greg Maxwell (mentions the timeline and we go into more detail about the federated, 2wp and related next gen ideas in this epicenter podcast 
@_date: 2016-03-13 17:02:04
Well, from the paper and from my summary that this is just a summary of current state of network infrastructure, decentralisation and block relay protocols, all of which can and should improve if developers and companies proactively work to improve and deploy those things.  There are lots more things that can be done to improve Bitcoin, we're just warming up, it's just that there's a bit of negativity headwind for no apparent good fundamental reason (that I can detect).  The future has never looked brighter for bitcoin technologically than now.  I am not sure why people are so negative really - it is self-defeating behaviour.
@_date: 2016-03-13 17:35:57
Because transactions on average have multiple inputs, lets say a tx has 3 inputs all singleSig.  Schnorr multisSig can compress the signatures that into the space of a single sig vs 3 ECDSA sigs.
@_date: 2016-01-29 02:49:16
But those are two false narratives. Like literally false claims.
@_date: 2016-01-01 15:30:55


The problem Bitcoin faces is it is very complex and yet superficially simple (chess moves vs chess opening analysis).
So I was thinking it is better to focus on the effect than the code variable names. The important thing to understand is that capacity is increased in an on-chain way.  Arguing about data structures wont work as cryptographically linked data structures and the reason they are restructured to fix a design mistake wont be understandable unless they want a 2hr explainer on cryptographic dependencies which will make their head spin.
I started using effective block-size to counteract the confusion Jeff was creating by over-focus on MAX_BLOCK_SIZE.
Basically they should not need to know variable names or data structures to know that capacity is being increased by more data being sent per 10min interval: at a superficial level "effective block-size" is synonymous with the data sent per 10min interval that is voted on via hash commitments by miners.
A second factor you may have picked up on is it seems like some people actually politically want an effective block-size increase (not just a capacity increase even though the effect is the same) for indirect reasons - they've listen to other people say things about it and logic wont do it for them because they made a judgement that commenter seemed trustworthy.
All methods have adoption speed assumptions but that is a reason to articulate assumptions.
@_date: 2017-02-09 08:22:36
yes you can do that all day long.  but the other thing you can not do.  which is the source of the streisand effect lending credibility to bad ideas.  so that's a net lose IMO.
@_date: 2016-01-01 20:59:21
Someone asked me why did this thread get deleted.  I happened to have the tab still open with the undeleted information and with help from a more experienced redditor, I believe the explanation of what happened it was deleted by the creator of the thread who deleted his whole reddit account As to why someone would do that, unfortunately it is most likely a troll attack to orphan comments when the troll attempt back-fired and his attempted stirring of trouble didnt work as his arguments were mostly rejected as incorrect.
here is the OP text that he deleted:
~~                                                                                                                  ~~
I've been really perplexed by the Bitcoin Core developers' positions lately, specifically wrt to a fork (or hard-fork as they call it.) They seem in stark contrast to my understanding of the system. Today I think I finally understand the issue and would like to point it out in the hopes of alleviating the confusion of others.
Apparently, the Core developers are operating under a not-often-spoken assumption that Satoshi was in fact wrong (about several things but specifically) about the issue of whether or not CPU power was meant to govern the Bitcoin system.
I take quotes from the white paper to illustrate why I think that was his intention:




This makes sense to me. The point of the system is to eliminate the need for trust. The only trust required is that "honest nodes collectively control more CPU power than any cooperating group of attacker nodes." At least, that's always been my interpretation which I'm willing to concede is flawed if I can be convinced.
Now how I discovered the aforementioned assumption. 
These are IRC logs from  today:








The above parties (with the possible exception of "adlai") were signers of the capacity roadmap letter. Now it makes perfect sense to me. They think Satoshi was wrong about the system so we have a fundamental disagreement. That's why it looks as if we will never be able to reconcile our mutually exclusive positions on the matter.
Hope this helps others.
@_date: 2017-02-09 04:41:32
I dont think that's likely to fly, and a number of people said this to Luke.  You should thank Luke though for being 100% independent and thinking for himself and doing his own research.  I am supposing what could be more plausible is eg 500kB + segwit, growing over time - but I dont see the point given that it's more coding and segwit will grow based on adoption over time anyway.
@_date: 2016-03-30 23:39:53
quite cool.
@_date: 2017-02-22 14:25:32
so talk to people about activating segwit? so we can get lightning going and see some real scale?
@_date: 2016-01-09 13:54:03
Yes but the recipient has to know how much money the received.  They dont know how much your change nor starting balance was however.
Which output is change becomes more ambiguous, and it does make CoinJoin perfect.  You can also send 0 value transactions to random people.  So there is some funbility gain, but it doesnt directly change the analysability of the transaction graph.
@_date: 2016-01-29 01:21:59


The bitcoin developers first step scale proposal as part of the roadmap has been active on testnet since December. That someone could get visibility and even traction for a technically inferior, slower and more risky proposal at 11th hour after the solution was already running in testnet is a bit odd. I think it's more about control and demand for clearer communication. A suggestion: communication is a two-way concept - if you feel someone is not listening, it's human 101: call them up and talk with them. Most suspicions evaporate, and trust is gained simply by talking with people.
@_date: 2016-01-29 00:03:58


No, you're quite wrong.  Architecturally this happens all the time. Say flow-control of IP packets at the higher TCP level adding reliability that is missing at the lower level.  Similar for disk caches.  Lightning is a write cache for Bitcoin.
@_date: 2017-02-14 15:41:31
it was you that said 


scalability is about the big-O complexity of various resources as transaction rates increase. throughput is about decentralisation and security limits. segwit has better big-O communication complexity for SPV nodes, better computational complexity for transaction verification (O(n^2) hashing) etc there are multiple complexity wins.
@_date: 2016-03-13 16:57:23
It is because you can apply Schnorr multisig across multiple (singleSig or multiSig) inputs to a single transaction.  Using Schnorr across multiple inputs to single transactions gives around 30% transaction space savings.  If you coinJoin transactions you can get further up to around 50% space savings.  wrote about it in more detail here 
@_date: 2016-01-01 17:53:14


It is not as simple as you say because there are DoS issues covered in the FAQ.  Segregated-witness needs to happen anyway so the choice is between two releases and one.  One is simpler more secure and faster.


You know it says in the FAQ Segregated-Witness has been running it's hard-fork version since last june?  People talked about this idea since early 2013 if not before.  (I certainly recall talking about this direction of fix in 2013)


Feel free to suggest alternative ways of accounting.  I dont think it is a blocking nor deciding factor because it's transitionary. Maybe if you could elaborate why you think it's a problem it might help.
Did you look at the Validation Cost Metric work and understand that aspect?


"capacity increase" is also misleading because what people care about is transaction throughput.  I agree this is complex stuff so we should pick words carefully and be honest in trying to improve Bitcoin.


I know information was poorly organised but this is you have to admit kind of illogical.  MultiSig was added via soft-fork.  Malleability needs to be fixed to scale Bitcoin and also to enable all kinds of contracts and even simple greenAddress things that companies are struggling to secure now. You dont see people trying to create drama about that.  
It is normal for a network system to include backwards and forwards compatibility plans. Soft-forks have backwards and forwards compatibility advantages.
On the terminology side - maybe you are familiar with extension-blocks, firm soft-forks and firm hard-forks?  Which of those would you consider effective block size increase or not.  (Extension blocks introduce multiple blocks to allow competition between parameters and even script features).
@_date: 2017-02-08 09:28:20
Good post, thanks for writing your thoughts.


Yes and I think the ongoing work of Johnson Lau and Luke Dashjr on forks are comendable in planning for the longer term.  One of Johnson's forks in particular has a quite good list of hard-fork wish list items (things that can not be easily fixed or improved via soft-fork).  You can read about them on linux-foundation bitcoin-dev list.
@_date: 2017-02-10 16:53:53
Why would someone who is a miner want bigger blocks even though it leads to lower fee revenue?  Well probably because they are longer term invested in Bitcoin and hope that it allows more users, and longer term they get &gt; 50% fee per transaction for 2x transactions so that it becomes a little higher per block, or that Jevlon's paradox kicks in and more capacity leads to more demand and a higher price.
But then you could also say "The miners sure seem to want larger blocks" then why are some of them not yet signalling for bigger blocks via the fastest and safest way.  There is no other mechanism ready today that can realistically deliver bigger blocks inside of 6months without almost guaranteeing an ETC/ETH split which will be very bad for confidence and probably not something a long term invested miner would want.
@_date: 2016-01-01 00:22:06


That sounds way too disruptive, network software with interoperability requirements typically have backwards and forwards compatibility plans.  Soft-forks do that.
Also see the FAQ it talks about some of your other concerns. 
@_date: 2016-03-13 14:41:34
Bitfury has a paper with similar conclusions.  It's on their website somewhere.
@_date: 2017-02-10 20:07:42
Yes that looks like pure politics, and is not good for confidence in Bitcoin.  Miners should act calmly, with best technical advice and following the economic majority view point.  There is quite widespread support in favour of segwit in node software and in companies segwit upgrade readyness and public statements of support.
@_date: 2017-02-08 05:28:58
@_date: 2016-03-11 06:47:32


in the BIP.
@_date: 2016-01-02 00:35:00
Suggest you look at data you're misinformed.
@_date: 2016-01-29 02:26:20
see anti-censorship statement on that website: 
@_date: 2016-03-13 19:18:59


If you talk to any developers they will tell you that is nonsense, pure tin-foil-hat stuff.  There are lots of developers funded by a range of sources, and no one believes the "evil" astro-turf story.


I dont think anyone believes that either - that would be nuts - you are defacto relying daily on the code the 50 or more active developers are developing and maintaining and doing security incident response for.  If you dont trust their code, you need to sell and go invest in something else.
@_date: 2016-03-13 16:57:55
Yes indeed!  And it would be very nice if people would put a bit more focus on to improving decentralisation also.
@_date: 2016-03-13 13:26:57
Here's a position paper by the main academics who have been publishing on Bitcoin saying that 4MB is currently around the maximum for on-chain scaling 
To be clear I think there is still quite good headroom within that limit because seg-wit offers better scaling characteristics, and because with Schnorr multisig that seg-wit opens the door to we can get 30-50% smaller transactions to nearly double the number of transactions per MB.
And some of those limits come from block relay tech that can be significantly improved, creating more scaling headroom within the limits of existing network infrastructure.  Hopefully mid-term decentralisation can also be improved, and network infrastructure improved also.  Some improvements will work better with proactive collaboration from Bitcoin companies.
@_date: 2016-03-14 07:07:23
What use is a rented full node, that the owner of doesnt use to validate transactions against?  None.
For an explanation of how economic full nodes enforce consensus rules (and by implication rented fullnodes do nothing) See this blog post by Prof Emin Sirer 
@_date: 2017-02-22 09:12:38
u/CryptOrca same as  info about the video question^
@_date: 2017-03-02 02:02:33
@_date: 2016-01-01 09:34:05
OK, lets consider: there are 6000 full nodes in the system. Lets say 1000 of them are economically dependent. If we restrict ourselves to considering only fullnodes (and not SPV nodes) for a moment, now we can see that if a miner tries to violate the consensus rules (spend a coin without a valid signature, spend a coin that doesnt exist, mine more than 25 btc/block) then the full nodes consider the block invalid and ignore it.  This is true even if &gt; 50% of the network tried to change back to 50btc/block - because the other full nodes which include miners would ignore those blocks and build on top of valid blocks, and economically dependent fullnodes would likewise ignore them. 
QED it is quite obvious that fullnodes are setting the (validatable) consensus rules in this picture.
When you reintroduce SPV nodes, they are depending on this power balance for their security, and because transactions intermingle even if half of the economic activity is on SPV nodes, within a few transactions they land on a fullnode which rejects them if some miners were hacked and did not follow the consensus rules.
It's not that complicated when you think about it.
I wouldnt say your quote from Satoshi is wrong, it's just talking about consensus on transaction ordering.
To claim with religious zeal and non-constructive anger however that Satoshi was never wrong is misguided: you may not have been involved but the code had numerous critical bugs that were fixed (eg anyone can take anyones coins and crazy things in the very early days).  It seems puzzling to me that people assume the developers are doing nothing without say ever having lucked at github, the continued existence and operation of Bitcoin is due to developers if you ran the first version with todays load it would crash and the network stop.
Maybe an easier example would be transaction malleability: clearly segregated witness or normalised transaction ids are the right way to do things, in hindsight. Transaction malleability was a design mistake. 
But hindsight is 20:20 so that's not a disrespectful comment.
@_date: 2016-03-30 23:42:43
Hey dont over attack u/zooko, he's trying to be helpful.
@_date: 2017-03-04 19:58:49
the basic soft-fork upgrade is a soft-fork and would only be done if the economic majority indicated support for it.
the attack scenario you describe, but no one is assuming miners would be incentivised to do, being directly and indirectly bitcoin invested themselves, indeed is a hard-fork but one triggered intentionally by hypothetical hostile miners.
consider for a moment, miners if hostile, could hard-fork a previous soft-fork today if inclined: they could mine an invalid CSV and mine on top of it. would create mayhem and be a hard-fork as pure-SPV wallets and un-upgraded nodes got forked off the network.  bitcoin works for people who dont run full nodes or who havent yet upgraded their full node because miners are paid and trusted to keep up to date with protocol upgrades that economic nodes are enforcing.
also bear in mind that no one would propose to do a soft-fork whether miner activated or user activated without ample discussion with miners and the economic majority.
a question to you: if 25% of users and companies are actively ready to created segwit transactions and start using lightning, and 99% of businesses say they are ready to honour those users opt-in choice (by upgrading their fullnodes to segwit rule enforcing even though they may not be generated segwit transactions nor blocks themselves) then would you think it reasonable for miners support this permissionless request of users?
or would you advocate for the miners to become hostile and intentionally fork the network?
what do you think the mid-term outcome would be if miners did intentionally damage the network?
@_date: 2016-03-15 21:42:14
You could maybe get some idea as to why Gavin doesnt seem to value decentralisation much by listening to him talking about it on this podcast 
@_date: 2017-02-11 03:19:10
I think generally you want to like use both - like firewall your btcd node by bitcoind or whatever in both mining and wallet/service uses.  Otherwise you can get hit with small bit level differences - it is very difficult due to LangSec limitations to guarantee otherwise.
@_date: 2017-02-18 19:17:28
actually multibit *will* see segwit 0-confirms, because it is SPV, and will connect to and send bloom filter queries to 0.13.2 nodes which will tell it the transaction is pending.
(sorry before I was not connecting that multibit is an SPV wallet, should have know by the dependency on bitcoinj.  bitcoinj doesnt need SPV support in order to receive notifications of 0-conf, though it will be a slightly more thorough when it's segwit patch is reviewed &amp; merged).
@_date: 2016-01-01 18:33:41
It is irresponsible to make unfounded wild accusations.  It is dishonest, risks creating misplaced distrust if anyone takes you seriously, and it is unethical. You keep doing it. Please stop.
For example your own link is about regular DDoS extortion. In the past it has been reported that Bitcoin exchanges have been DDoSed to try to manipulate price.  There were even rumours that exchanges and miners or pools might be DDoSing each other for competitive profit. I have heard of miners and pools being worried about block withholding. Occam's razor can be a useful thing to consider before hitting send on conspiracies.
@_date: 2016-01-31 05:57:06
I dont think it's even about scale.  Some companies want control because they failed to communication with the developers, and built up unfounded siloed suspicions.  I think certainly contributed to it by interposing his negative views - imagine if as a company your trusted interface to developers is telling you they need to be fired, and you trust him so you believe him.
(If you want to hear Gavin say it see  excerpt at bottom from the podcast  )
Gavin has a lot to answer for in the current disaster IMO.  If this happened in my company it is Gavin that would be fired.
@_date: 2016-01-01 13:33:06
A non-mining node will reject invalid blocks and not relay them, unless it has been hacked or tampered with.


Well of course, I was only explaining how the system works!  Some of it is surprisingly complex and counter-intuitive and yet the basic rules look simple.  Maybe vaguely analogous to chess: the rules are ELI5able but to predict why some openings are weak gets remarkably complex.


To be clear this is Nakamoto consensus and what is implied by the bitcoin whitepaper.


That would not happen automatically. Humans would have to go change those nodes.  The ultimate arbiter is still fullnodes.  Say the SPV wallet you use is poorly designed, and it accepts without question the assertion of one random fullnode (which happens to be following an invalid chain).  Then you lose money because when you spend with a business or deposit in an exchange your coins you thought you received are invalid and rejected.  This would cause a rapid shift to wallets that have more defences against that issue.  Some wallets offer hybrids of a semi-trusted full node and SPV (eg some of the greenAddress wallets).  The new features in segregated-witness that support fraud-proofs help improve security of SPV wallets also. 
@_date: 2016-01-29 00:29:51
it is happening in parallel. Layer2 is possible and you cant stop it even if you wanted to, so relax and let the market decide.
@_date: 2016-01-31 07:34:40
There is also lightning which should come online pretty soon now (before IBLT &amp; weak-blocks say).
And a number of incremental things that can be soft-forked much faster into seg-wit with it's new extensibility.  Like schnorr multisigs that compact 2 of 2 or n of n multiSigs into the space of a single signature.  We should be able to estimate the throughput boost from that based on the multiSig ratios that go into the 1.75-2MB estimate.
There are other things also like elidable pubkeys so miners can choose to tradeoff validation cost (from loss of batch verifiability) for more compact space.  The elided public keys can be reconstructed with a small CPU cost.
Some other things are possible also.
People should just calm down and talk with developers.
All in there is a fantastic roadmap for scale and layer2 things coming online that really move the needle even for new high scale transaction use cases.  Not a time to be doing ugly bandaids that actually make scale worse mid-term and risk alienating the people with the expertise to make the scale happen.
@_date: 2016-01-29 00:05:50


You know - people can talk to people other than the software architect.  Often companies say employ tech sales people.
Maybe you like the roadmap better when explained by Andreas Antonopoulos: 
@_date: 2016-01-01 15:43:51
No argument from me, I get ethically offended when people deviate from meritocracy rules - if you cant arrive at the best conclusion via technical rationales it is a breach of trust to try to prevail by other means in my book.  That way lies replacing technical merit focussed on preservation of Bitcoins ethos and social contract which are sacrosanct, with the worst of politics and puts Bitcoins ethos at risk.
@_date: 2016-01-01 22:54:27
I think you are talking about miner meta-incentive. That's more BIP 100 than BIP 101.


That would be set a trend with no feedback loop that reduces Bitcoin security to centralised trust miners only.  If we want to trust miners only, it is certainly true that many things become simpler and can be optimised.  I dont think anyone thinks that would be a good idea on a security basis.


Miners signalling they are ready for activation is useful, but that is not setting consensus rules, that is signalling upgrade, similar to as used in soft-forks too only with a hard-fork it is even more important to know that the vast majority of full-nodes have upgraded than that miners have upgraded (though it is still useful to know that a reasonable majority of miners upgraded).
@_date: 2016-03-30 10:15:14
BIP9 versionBits is pretty cool and immediately applying to CSV and Segregated Witness itself.  (Eg hypothetically CSV and SW could activate in either order).  Up to 29 soft-fork features deployable in parallel.  Now we just need more developers to implement more!
@_date: 2016-03-16 08:34:06
Except it is a manufactured and false dichotomy bitcoin developers have a soft-fork block-size increase coming next month.
@_date: 2017-02-13 16:16:22
you can use it for sender balance privacy with lower adoption though. eg if you have X btc and you send someone 0.1btc in cleartext (or confidentially but then they turn around and spend it cleartext) then your X balance is still protected. I think this type of use is also one of the reasons people create multiple UTXOs for hodling they dont want 100btc in one output for value privacy, so they split it into 5btc, 10btc etc amounts.
@_date: 2017-02-22 17:07:19
  is fun on twitter 
@_date: 2017-02-22 13:22:36
r/btc's job in life is to inject negativity. someone has to give it a go to respond positively, unfortunately evidence shows otherwise bystanders believe misinformation.
also unfortunately streisand effect from topic banning in r/bitcoin is being used as a wedge issue to promote inadvisable network fork risk software in r/btc. roger's u/memorydealers site bitcoin-com even advertises to novice users to run BU as a default full node which is unethical IMO - it's fine for a protocol developer or power user to test it, but not to recommend to novice users - it could eat their coins if people are not paying attention and dont know the issues.
@_date: 2017-03-05 12:38:28
no.  i just personally prefer no moderation, or that moderation be dynamically opt-in. if something weird is going on then you can turn it off.  reddit has multiple problems however.  people can self-edit posts.  reddit admins themselves are unpredictable, and prone to being fooled by fake reports from a few abusive subreddit admins.  and so on.
I wouldnt seek to deprive someone from moderation if they seek it.  I can say I think it was misjudged and a bad idea though.
@_date: 2017-03-02 02:00:46
also apparently said on the same podcast not a core dev. but JD does have an econ/finance degree from Berkeley.
@_date: 2016-03-13 19:02:30
Yes mining is not doing so well.  Listen carefully to what says with data and graphs (he packs data in really fast have to hit pause to digest and parse what he's saying!)
Actually even full nodes are not doing so well in practice.  While some people have spun up lots of VSP nodes they are not economically useful.  The level of decentralisation of economically dependent nodes is weaker than it has been in the past, with a current trend to outsource fullnodes.  By economically dependent I mean a node that you run yourself (or have reason to trust the operator of) to validate your own transactions against.  That gives you far stronger security assurances than SPV clients.
@_date: 2016-01-31 04:53:35
It's a nice narrative, but much of your claims are exaggerated or false, but lets not dwell on that - clearly usage is creeping up.
You somehow seek to denigrate the bitcoin developers and yet it is they who have done all the work to scale bitcoin!  There are a range of performance and scale improvements in the 0.12 release which includes 80,000 lines of code change vs 0.11, include 30x improvement in a mining API that affects orphan rate, and ~7x performance improvement in sig validation.
And the roadmap includes a safe and fast way to increase scale via soft-fork, which fixes much needed transaction malleability that companies have been complaining about and adversely affected by , that was running in testnet before anyone ever heard of "classic".  There are over 30 wallets and libraries working on supporting seg-wit before release.  So tell me what is it that you think is achieved by a rushed and funds-loss risky hard-fork?
@_date: 2017-03-08 18:23:39
yes and that is default. [edit] see nullc comment  ^
@_date: 2017-03-04 21:03:01


that's mischaracterised. USAF was a proposal by u/shaolinfry. there arent really core proposals until there is consensus and this is so far just a BIP draft for discussion from one person.


the hypothetical hostile miners you are convinced exist, and are sufficiently non-incentivised that they would seek to damage bitcoin would be intentionally forking by declining to do the job they are paid to do in providing security to the network for the protocol version that economic nodes are tracking.
so in no way would be "core not allowing" but your hypothetical hostile miners intentionally creating a fork.


a miner activated soft-fork is less risky than a user activated soft-fork
and a user-activated soft-fork is less risky than a hard-fork.
but i put it to you that even activated by miners majority, if miners are becoming user-antagonistic to the point of not doing their job of providing security to the network for the protocol version that economic nodes are tracking, they can sabotage the network today by for example:
- mining invalid CSV transactions and blocks on top of that
- by signalling SW but not enforcing it (same outcome as you fear for UASF)
so ask your mining friends to start activating segwit and make it all moot.
also do you care to explaining a rationale for why miners or anyone would seek to deny access to an opt-in feature that is opt-in for users, and opt-in for miners (to create SW blocks or not).
@_date: 2016-01-18 18:09:49
I think it means in hindsight I may have received the first email Satoshi ever sent.  I didnt realise "Satoshi Nakamoto" was a psuedonym at the time.  I had suggested he might like to read Wei Dai's 1998 B-money system  which is a related concept to what he was describing.  (I didnt release copies of Satoshi's emails for netiquette reasons though I did confirm a few sequence things to Gwern).
@_date: 2016-03-01 08:14:01
actually it is 1.8x with current transaction multiSig ratio, and that has been increasing due to security benefits.  About people using it, I dont think anyone is expecting demand to jump from 700kB (or whatever current average is) to 1.8MB nor 2MB in a step function overnight - so adoption will presumably be smooth in either case.
Also note a subtle benefit is people who do upgrade to sending segwit transactions, free up space in the 1MB main block for people who do not and the non-sig to signature part ratio is 40:60 so for each 100kB of transactions that upgrade 60kB is saved in the main block and therefore available to people who have not upgraded (or additional transaction scale)
@_date: 2016-01-01 14:39:59


Incorrect.  Say 30% of the hashrate decided to revert to 50BTC/block at the next halvening rather than falling to 12.5BTC/block.  Result: the 30% forms an alt-coin with no users, and burns electricity with 50 invalid coins per block. Bitcoin hashrate drops a little, difficulty adjusts and Bitcoin is unaffected: the economic majority expressing it's desired consensus rules via their self-reliance on fullnodes to enforce consensus rules.
Granted if the hostile hashrate grows beyond 50% they could potentially DoS the consensus rules by using most of their hashrate to stop progress on the mainchain to blackmail them into accepting their 50BTC view.  But as you say that is sufficiently shocking that it is highly unlikely that a majority of miners would do it: miners are significantly long term committed to Bitcoin because of their large capital investment in ASICs - creating economic shocks that would harm Bitcoin price or confidence would be against their interests, also in the real world quite a few miners are altruistic and excited about Bitcoin as are users.


You may want to look up data for a reality check on what you think miners want.


You have a confused understanding of how Bitcoin security works.
@_date: 2016-03-13 18:23:40
I consider sidechains not a real algorithmic scaling solution because the limits with blockchains are about orphan rate and latency, bandwidth, block-relay protocols etc and if to mine profitably you have to mine two chains, that doesnt really improve much if it's 2x 1MB chains vs 1x 2MB chain - you still have to sync the data and validate it as a miner.
You might consider multiple chains as no longer one-size fits all so perhaps you could make a micropayments relatively centralised one, but it's still not a game-changing scaling solution IMO.
@_date: 2017-02-10 08:10:37
yes and it is both a scaling (lower overhead per transaction) and a throughput (more transactions per block) improvement.
@_date: 2017-02-09 06:08:03
I think you are right that the centralisation issues in mining are very under discussed, and underly the whole scaling discussion.  If bitcoin were very decentralised we could more easily afford to push up block size a bit without creating censorship or policy or geopolitical risks.
@_date: 2016-01-30 18:48:32
there is a hard-fork in the roadmap. just the soft-fork is done first because it is faster and safer.
honestly I would presume what everyone wants is scale earlier and safer. The rest is about control and trust only I suspect. The technical arguments are without merit.
@_date: 2017-02-09 05:05:39
No I do not agree with those parameters.  I prefer some of Johnson's BIPs.
@_date: 2016-01-28 23:58:29
Actually yes he did. Eg listen to this podcast 
pretty sure he's said the same thing on bitcointalk or other online.
@_date: 2016-01-01 14:57:22
So do you understand now why hard-forks are not a miner vote?
@_date: 2016-01-01 21:11:20
Hard-forks are not a miner vote, because economically dependent fullnodes enforce the consensus rules.
In fact the design could be changed so that miners could enforce consensus rules, however I think that could be a rather bad idea, though from what you said I suspect you do not understand what those design changes would be, but a straight-forward hard-fork cant do it.
@_date: 2017-02-22 15:22:29
very very little constructive discussion happening on r/btc if that were the only reason.
@_date: 2016-01-23 06:36:39
Are you interested to take a communication role?
@_date: 2016-01-01 14:42:37
Again read the FAQ there are timelines.
Notice our profile says you are an moderator.
@_date: 2016-01-29 15:14:50


actually I was vocal against full RBF and in support of opt-in RBF.  There is a big difference and you can read the FAQ here: 
@_date: 2017-03-05 16:14:39


maybe.  it is still the most work valid chain.  more users could run full-nodes.  more semi-trusted fullnode checking SPV hybrid wallets used (a number do today).  perhaps something could be done about reorg and double-spend attacks - R&amp;D question with no answer today.


probably helps some.  anyway as bitcoin is so awesome, we want scale so everyone who values those properties to be able to enjoy censor-resistant bearer internet money.  positive disruptive implications better met and sooner the more scale and reasonable fees to support a range of interesting uses.
@_date: 2017-03-04 19:03:36
this is my view of reddit, moderation, topic bans and censorship:






@_date: 2017-02-01 16:09:23
Relating to the BIP 66 activation, there was more than one post bip66 branches of invalid blocks: at least a 6 in depth, a 3 in depth, and a 2 in depth stretching out to up to 6mo after the activation. at least 12 total blocks, not necessarily all in the same chain.
@_date: 2016-01-09 08:20:43
In privacy tech eg Brands ecash  it is able to provide unconditional anonymity, which means even peering back from the far future with a dyson sphere powered planet sized computronium brain with the ability to do EC256 DL in seconds you will never be able to tell.
This property holds for the value ambiguity in CT as well.  The reason that surprising property holds is because the base structure is counter-intuitive but relatively easy to see, the value V is hidden by blinding factor x:
so for any given value v, there does exist a corresponding x that solves the equation, and because G is a generator of a group, that means any v value is equally plausible.  It is a similar property to xor with a one time pad.  So this is unconditional security vs the usual computational security (and for pragmatic reasons people may not care to hide their values 50 years in the future so may choose to opt into a computational security tradeoffs or to make a choice).
You can read about CT here 
or  video explainer skip to the section on CT.
There are different configurations and soundness vs security guarantees to play with, but I just wanted to clarify that.
@_date: 2016-01-29 00:07:18
to make bitcoin less fungible and less private.  and toomim ends up doing as asked (at least in effect) by reverting to 0.11.2
@_date: 2016-01-01 20:42:39
It does seem that thinking shifted a bit with some new ideas during the last 12months. Possibly bitcoin extensibility and upgrade mechanisms may evolve and improve in the future. 
One pattern could be a sequence of soft-forks followed by less frequent hard-forks to update formats.
Or maybe with planning one hard-fork followed by opt-in parallel extensions (extension blocks).
It is possible that we are missing some new insight even.  Recently jl2012  and joe2015  posted on the bitcoin-dev list some interesting things about firm soft-forks another upgrade mechanism. Another type of upgrade is firm hard-forks.
We have to figure out the ethos compatibility of extensibility and upgrade mechanisms.  I think the important thing is to preserve bitcoin's bearer cash property (bearer = security, unseizable, unfreezable, permisionlessness use, robust fungibility and 21M supply unadulterated from the social contract), add ways for people to extend and scale in different truly opt-in ways without splitting the coin base or bearer property.  This could be a very fun and productive time.
Hopefully we can make 2016 a year to recapture peoples constructive imagination to making Bitcoin more awesome.
@_date: 2014-04-10 15:40:03
You are credited in the bitcoin-dev write-up  which you maybe didnt see because you didnt clarify the bit where a question is asked as reference was quite ambiguous so it was posed as a reference with a question mark:
I could well believe it, there are many reinventions in bitcoin.  Your reddit write up seems clearer: 
from that it sounds like a variant between 1-way peg which I proposed last year and the 2-way peg proposed last dec.  I say that because you first use 1-way peg to exodus coins to what you call HubCoin, and then use bidirectional chain-aware pegging between HubCoin and side-chains.  (Which seems viable except that it requires the same kind of reasoning as my 1-way peg what-if for protocol upgrade which is somewhat of a who-jumps-first user herding/bootstrap problem to get everyone to agree - to people who dont agree you just burned your coins, and if they end up in the majority you lose).  Part of 2-way peg is no side-chain awareness by the main-chain  (the side-chain just adhering to some proof-format and electing to use SPV security + maturity periods) to minimize main-chain changes, and allow maximum flexibility in the side-chain logic.
From your 2013 bitcointalk thread post you also thought about SPV proofs so probably that is just a deployment model question.  2-way pegs propose to modify bitcoin-main to be the HubCoin to side-step the user bootstrap problem.  While not articulated I presume you might have thought of burying the side-chain transaction and quieting period with proof of treachery (a Jul 2012 idea from I think proof-of-burn or proof-of-sacrifice as a mechanism (which is the mechanism for 1-way peg) probably is older still.  Not sure of the attribution for that one.
@_date: 2016-03-01 01:25:17
This  is also a useful resource to see more real-time about transaction fee vs confirmation time.  unconfirmed transactions are fast, as some people noted there never was a guarantee of fast clearing due to luck and stress tests, whatever the block-size.
It would be useful to monitor confirmation time by wallet, and that would be a useful additional resource if that can be automated somehow even for smart-phone wallets.  There are different success rates and overpayment with different wallets due to wallet limitations.
There are some approaches to getting weaker confirmation sooner, with greenAddress, bitGo wallets and other related services, and with weak-blocks in the future.
Services that improve unconfirmed transaction security with the green address approach benefit from segregated witness because then you can accept re-spent but not yet cleared bitcoins without being vulnerable to malleability.
@_date: 2017-03-05 15:59:34
correct, could be done but it's ugly and pointless - malleability needs to be fixed and segwit already provided the canonical elegant and robust fix (plus a bunch of other needed fixes and features).
@_date: 2016-01-01 18:14:12
I guess the toomim with the conspiracy theories on hackernews was your brother.  I was referring in part to that set of comments re conspiracy theories.
@_date: 2016-03-31 21:28:07
Actually I believe bitgo and similar services like greenAddress and others do benefit from malleability fixes because they do instant transactions, they end up spending unconfirmed transactions that can otherwise be reneged on by double-spend.
@_date: 2017-03-05 12:49:03
apparently some peoples 'N' key is broken.


presumably the tech and clients still exist.
@_date: 2017-03-29 15:33:50


here's 67 pages of developers and miners talking, feel free to read it.  
@_date: 2016-01-01 13:42:39


I'll offer you a third option, Occam's razor suggests that you do not fully understand how Bitcoin works.  No offence, it is complicated; everyone is still learning even researchers.  The selfish mining attack was not realised for years.  New things are still being discovered.


Yes I can because you are incorrect, and if Satoshi were around I'm confident he would explain the same thing to you.
It is not a question of "allowing" it is a distributed system where users are in charge by the software they run.
Soft-forks are voted by miner consensus of longest chain.  Hard-forks are decided on by super-majority of users.
Consider the miners decide to award themselves 50BTC per block. They effectively create an alt-coin that users ignore, and give up.  There was a splinter group of miners that tried this in the last halvening.  It didnt work out for them.  This is why hard-forks are more complex than soft-forks.
There are actually other fork types that could be done via miner but this does not appear to be what you are talking about.
@_date: 2017-02-10 08:08:12
they dont.
@_date: 2017-03-04 18:30:08
I have some ideas.
@_date: 2017-03-01 10:55:57
cant read it - what does it say?
@_date: 2017-03-05 12:16:43
no i said it multiple times, on both subreddits and privately to theymos, it's just reddit has no permanence and scrolls off.
@_date: 2016-01-31 06:42:04
You may notice I signed the roadmap statement - should be a hint.  I see the roadmap as a safer faster way to roll out the first parts of 2-4...
And indeed no I do not speak for core - my influence is limited to coming up with ideas with merit that people would then adopt and use - which is the way it should be in a meritocracy.
@_date: 2017-03-04 19:07:13


not really. miners are paid to provide security for pure-spv wallets and people who have not yet upgraded their full nodes, and so they need to run recent software following rules that the economic majority is tracking.
they minimally need to upgrade their border nodes, which mostly they have to protect against accidental forks since the SPY mining fork.  they do not at all have to mine segwit blocks, those are optional even post activation.
@_date: 2017-03-05 12:39:29
systematic brigade and even bot downvoting is effectively a form of moderation or censorship if you prefer. whoever does it.
@_date: 2016-01-01 10:48:28
Say you personally are checking the block chain with a pen and paper. You check the longest chain.  But you also check consensus rules, one of which is that that there are maximum 25BTC mined per block.
(Yes you really could verify Bitcoin proof-of-work with a pen and paper:  see  ).
Lets say there are two miners with 50% of hashrate each: a good miner and a bad miner.
The good miner follows the rules and mines 25BTC per block.  The bad miner mines 50BTC per block. You as the fullnode, reject and ignore the blocks mined by the bad miner because you consider them invalid.  The good miner also ignores the invalid bad miner blocks and builds a chain of valid blocks.  Bitcoin is built not from the longest chain but the longest *valid* chain.
Who is setting the rules: generally speaking the fullnodes (you manually rejecting invalid blocks in the example) because you are the audience and consumer of the Bitcoin service.  A miner who mines invalid blocks will lose money.
Extrapolate to many users and businesses and their fullnodes - the *fullnodes collectively enforce the consensus rules*. Miners provide a tie breaker to order blocks. They also make assertions that SPV users rely on, but invalid assertions are less profitable - because the bitcoin fullnodes reject the coins mined in them - and so SPV users have assurance that economically rational miners would not do that.
Now about economic dependent fullnodes. If someone starts a fullnode in a VPS and no one is relying on it's fullnode verifications for economic activity, no one economically cares if it falls because no one listens to it. It is only validating rules not enforcing rules if no one makes economic decisions based on it's validation. Power users and businesses wont rely on validation claims by a fullnode they do not control or trust.  So the way things work is the *economically dependent full nodes collectively enforce the consensus rules*.
@_date: 2016-01-01 11:12:52
Probably more like one joule one vote. I also foresaw ASICs in 1997 while designing hashcash proof-of-work FWIW there were dozens of design decisions and discarded alternate designs. Hal Finney also helped simplify it.
@_date: 2017-03-10 20:51:38
that's not true, jonny is bitcoin invested, and very bullish about bitcoin fungibility and digital gold investment thesis.
@_date: 2017-03-05 15:14:49
generally good points.


note that while it undoubtedly helps, and banks using blockchain for other uses probably helps make bitcoin look less scary, the too big to censor or shutdown argument got schooled  by the indian politicians, removing 500 &amp; 1000 INR notes from validity with 4hrs notice in televised address and india's population is 1.25 billion people. $230bil value held in those notes $50Bil was never reclaimed, confiscated from one of the worlds poorest countries.  
that use prevents banning argument fails in the real-world was predicted. lots of historical examples too no doubt.
@_date: 2017-03-05 18:23:29
right fees go to those who put up capital. and the network will route over cheapest link, so that may not be very high fees. the point is to get more scale - that benefits everyone.
lightning is also interesting for fast cross-chain atomic swaps as the lightning write-back cache can work above multiple chains.
@_date: 2016-01-29 14:57:21
Yes Gavin, but there can be multiple alternative layer2s.  In fact there already are and have been for years - and most bitcoin transactions by volume are currently using them.
Layer2 methods can be and are being improved.
Also on-chain scale is happening and would happen faster if you would start helping instead of misfiring with contentious hard-fork support.
As you have a researcher title at MIT and funding from donors (some of who are probably not too happy with your current use of their funds) - why not get back to research and help with the IBLT/weak-blocks in the roadmap, I saw you were interested in and did some reading and analysis of IBLTs.
@_date: 2017-03-05 15:26:17




not sure about that. a government censor might prevent a programme being televised. you may still be able to get it off bit-torrent via Tor outside your country - was it censored? yes.
it is still effectively somewhat moderated and somewhat censored because a big portion of the people participating in the discussion will not see it because of inertia and laziness.  this is a soft and subtle form of censorship and is particularly pernicious because people can argue it's not really censorship and so is "a-ok". it's not ok in my view.
@_date: 2016-03-01 01:57:49
You got it :)  win-win-win. (performance, size/scale, fungibility/privacy).
@_date: 2016-01-01 22:06:30
most of them are overpaying by using fixed fees 
@_date: 2016-01-01 22:07:24
2MB is the same amount that miners have said is the maximum they can support until IBLT &amp; weak-blocks are implemented.  Keep up eh?  And read the FAQ!
@_date: 2016-01-23 06:36:09
They did collectively organise the scaling Bitcoin workshops.  I thought those were quite constructive and enjoyed by those who attended and centred the analysis around review and data.
In my view that is a good way to evolve something as important if not more important than something like a new NIST standard for SHA3.
Introducing politics into Bitcoin is a mistake, if that is the way people are seeing it.  We will all lose if people can not find it in themselves to be constructive, security conscious and respectful of others contributions.
@_date: 2016-01-01 22:56:21
It is not clear to me that Bitcoin Unlimited implements anything other than manual changing a constant which will insta-fork if anyone creates a &gt; 1MB block.
@_date: 2016-01-29 18:04:02


Bitcoin does not support multiple layer1s yet, but it is possible extension-blocks and side-chains - why not wait for that, or help build it.


because that is what there was consensus for.  You were part of the review process.  You told me you didnt much care whether it was a 2MB soft-fork or a 2MB hard-fork.  Could you explain in that circumstance why you are supporting classic - the controversy is bad for bitcoin price, investability and confidence and to no technical gain.


Because soft-forks are safer and faster.  I personally am interested to see a hard-fork scheduled for later activation.  We have to decide what goes into it, see my idea for a fast, safe future upgrade mechanism to hard-fork on wizards.  (Ie hard-fork a new upgrade mechanism that allows fast safe future size upgrades).


We should put Bitcoin's interests first.  A bit more selflessness all around.  I think everyone is interested in Bitcoin scaling.  Firing all the engineering talent to force a risky to funds loss bandaid and delay 
long needed malleability fixes that businesses have been demanding doesnt look smart from where I am sitting.
@_date: 2016-03-14 21:57:49
They could, they could pool-mine the sidechain and solo-mine the main chain for example.  That approach has limits though if too many people outsource chain validation to a very small group of validators.
We already have problems with such things in Bitcoin today due to large pools and SPV mining.  But that could be improved via config, improved decentralisation and improved pooling protocols.
@_date: 2016-03-01 02:07:07
Isnt that 60% reduction asymptotically, if average non-sig to sig data is 40:60 plus 1% seg-wit overhead taking to 41%?
Or is Greg calculating relative to assuming Schnorr is already deployed rather than vs current?
@_date: 2019-03-12 00:46:05
and server=1 in bitcoin.conf?
@_date: 2017-03-05 13:14:03
problem is I would think all or almost all of the hashrate on it is equipment owned by bitmain, or on some kind of revenue share with strings attached that they have to use bitmain pool (eg to calculate revenue).
@_date: 2016-01-29 00:01:33
Actually Gavin did say that. Eg listen to this podcast  pretty sure he's also said the same thing on bitcointalk or other online.
@_date: 2017-03-05 13:14:42
good comment.  but caveat that bitcoin is a user-currency, so it is absolutely users and h0dlers who's reasons for using and h0dling that are paramount, enter requirements.  i think what people who arent focussing on the complex protocol details and innovation should do is discuss requirements.  this is a common model for development in software-engineering.  
My take on requirements are that bitcoin must remain secure, bearer, permissionless, fungible, censorship-resistant, unfreezable, unseizable and so far that requires decentralisation.  It is important that bitcoin scale and fees support use cases that desire those properties.  It is a non-requirement that bitcoin be available to people who dont care about bearer for example, because they can use changeTip, an ETF etc.
for example a correctly formed requirement request might be "i like micropayments, and want bitcoin to displace the USD and be used by everyone, i think that micropayments and mass deployment is the killer app for bitcoin, and so I want to pivot bitcoin into datacenters so that it remains digital gold, but loses decentralisation and so loses differentiating properties: permissionless, fungible, censorship-resistant, unfreezable, unseizable."
That is what gavin, hearn and roger are saying as best I can tell.  Of course most people said, no thanks.
@_date: 2017-03-05 17:55:48
good point. the vote for segwit &amp; BU is censored. I suppose though false signalling is a bad idea, people could run core and show "support" for BU. in fact it is believed that most of the hash rate showing BU "support" is actually running core for safety reasons.
and I suppose it is not technically false signalling in the normal sense, as BU has no signal threshold, and no BIP 9 signal bit 
@_date: 2016-03-04 22:48:05
Actually it was proposed by a miner as a self-admitted implausible worst case.  I mean it's not going to happen for many reasons.  The question of how much by is more useful which is likely by a small %.
@_date: 2017-03-05 15:09:42
ok. can you afford $1000/mo conop? how about $10k/mo conop?
@_date: 2017-03-31 23:52:54
less bad, but still.
@_date: 2017-03-31 23:53:21
it will because it will delay scale by 12months, needlessly.
@_date: 2017-03-02 13:08:34
on ext-blocks u/jl_2012 has done some recent work 
p2p sidechain work is also progressing, and like lightning there are now more companies working on them.
@_date: 2016-03-13 18:47:22
Thats a lot of tech mumbo jumbo until proven otherwise and seems like a bubble well ahead of tech maturity even to not have yet more accidental hard-forks.
My thoughts are stop attacking each other and dont get suckered by astro-turfing negativity that has conflict of interest underlying it.  Let the technologists focus on code.  It doesnt really matter what the bubble price is if no one is using it as a currency nor store of value.
@_date: 2017-03-29 23:40:49
I actually had designed floating point difficulty adjustment in hashcash but took it out for the email anti-spam use-case in the interests of simpler verification for the anti-spam application because power of 2 difficulty was probably good enough, and that enables you to verify pow using sha1sum and bash script for example.
Bitcoin needs finer grain difficulty so it does that.
@_date: 2017-03-01 11:57:24
without lightning we might ask the question which transactions actually need inherently expensive (but currently subsidised via mining reward) censorship resistance, unseizability etc a cup of coffee is probably not in dire need of censorship resistance.  the interest in bitcoin's differentiating properties vs other payment mechanisms in the event of scarcity of limited transaction capacity tends to be indicated by inelastic demand as price rises.  blocks are still full with fees 10x higher.
it is unfortunate that there is a bad tradeoff between bitcoin's differentiating features and scale - meaning if scale is ramped up aggressively, bitcoin will become even more centralised than it already is, and lose it's differentiating features.
I am very interested to see lightning succeed because it can increase scale very well and retain bitcoin's differentiating features.
I think is right that it would be more useful to market bitcoin to people who are using it for it's differentiated reasons, not just a fun or cheaper way to buy a cup of coffee, because if people use bitcoin for wrong reasons, or no fundamental reason - they will switch in a heartbeat if something else is cheaper or more fun - and they wont argue in favour of differentiating features, they will argue for pivoting away from them, or against fungibility even, and towards discounted cups of coffee.
@_date: 2017-03-31 23:52:28
This exact proposal (lets compromise X+Y with X=2MB HF and Y being segwit) has been made half a dozen times over the last months, and I and others had to explain engineering realities, to many people individually and in groups, so lets recap that again
So, lets see.  That has to designed, reviewed, implemented, tested, re-network validated, the 100+ companies who already integrated and tested segwit have to go change that, and retest; not just them but every piece of software on the network needs upgrading.
This seems like a huge step backwards if we want scale inside of a  year.  After implementation, segwit took 6months of testing and it is a soft-fork.  This is a hard-fork and no planned hard-forks have been done before.  It took a long time for companies to upgrade to segwit, and some have not yet, but that's ok because it's a soft-fork.  This is a hard-fork, so they will all need to upgrade or chaos can happen.  There is no anti-replay and no wipe-out protection.  The author seems largely out of the loop on bitcoin R&amp;D on hard-fork work for the last few years hardfork such as BIPs, code and testnets by Dr Johnson Lau, and BIPs by Luke Dashjr.  
No hardfork wishlist items are included unlike the above work.
Research not captured yet there, was also done on weightings and cost validation metrics to think about how to combine by adding a HF (after segwit), and none of the necessary tradeoffs are considered in this X+Y "compromise".
That'll do for starters.  Even with the hypothetical if it were a genius new wizard grade idea, and everyone fell instantly in love with it, and figured we must do this asap, it would delay access to scale by around 12months, just due to engineering realities.
SegWit itself was and is a compromise, but a radically better one because it includes memory, CPU, storage, bandwidth complexity improvements to compensate.  Just activate segwit and scale starts to be available in weeks - it's all good to go.
How about a compromise: activate the existing compromise.  And work on next step scale next, if you are interested in fork research, join the R&amp;D effort with Johsnon, Luke and others.
@_date: 2017-03-04 18:59:54
i think just get off reddit. the random site-wide bans and abuse of fake reports to reddit admins and their inability to see through it is enough reason.
no offense to sub-reddit moderators on either channel but a moderation free forum would be a good thing to have.
@_date: 2016-01-01 13:46:48
incorrect. read the FAQ it provides an effective blocksize increase.
@_date: 2017-03-05 17:41:48


heh because bitcoin on-chain scales O(n^2) communication, if every transaction in the world was on-chain the internet would be 10,000% overloaded.
and because with giga-blocks only companies with lots of resources to run tier1 data center nodes would be actually validating the blockchain, and they are static, identified and servable with court-orders. so then bitcoin is pivoted to paypal2.0 IOU with no permissionlessness, no censor-resistance etc.


here's me saying censorship is bad, amongst dozens of similar complaints over years:


stating the risks about hard-forks: controversial hard-forks are likely to lead to a currency split. most people dont want that.


u/luke-jr made a hard-fork proposal with a lot of interesting wishlist features ahead of schedule as documented in the miner dev meeting in the bay area july 2016, see the transcript.  


such as? being helpful enough to answer questions on reddit?
@_date: 2017-03-04 19:40:14


you're missing a clever feature of recent soft-forks that segwit uses. non-upgraded nodes see that transaction as non-standard and wont relay not accept it.
the only way that is going to happen is if someone maliciously mines an invalid segwit block.
non segwit miners can certainly protect themselves and users with a segwit border node, or upgrade to a segwit node.  a segwit node doesnt create segwit transactions nor segwit blocks, it requires pool (or solo-mining) software to upgrade to do that.
most big miners have border nodes since the SPY mining fork in bip 66 to protect from accidental SPY mining caused invalid chain forks.  trivial to upgrade.
besides they're probably going to want to upgrade because recent version of the software are much faster at relaying, validating blocks and at creating block-proposals.  i think better coin selection also means more fees.
no one is saying (i hope) force anyone, but I think it's a very reasonable request that miners, who are afterall literally paid for the service of protecting users who havent upgraded or who are pure-SPV from such malicious blocks.
furthermore if there is good evidence that a majority of economic full nodes and ecosystem companies are ready to use it, miners can allow them to opt-into segwit without having to create segwit blocks themselves.
i fail to see why denying someone something they want that doesnt hurt you is constructive.  care to elaborate further on why you want to block other peoples access to opt-in features, that are also miner opt-in (can opt to create SW blocks or not)?
@_date: 2017-03-04 19:35:58
example of why moderation is bad. brings out the inner school-yard bully in some people. obviously not a threat, abuse of mod privileges.
@_date: 2017-03-04 23:48:33




but I stated as an assumptions that you selectively edited:


so I explicitly said that it is assumed that enough miners are expected to or confirming they will do their job (by upgrading border nodes) providing security to the network for the protocol version that economic nodes are tracking.
you keep reverting to some incorrect assumptions.


it seems you are not up to speed on the proxy war going on. maybe spend more time in wechat.


being asked to not delay an double opt-in feature is no imposition, when it is what the network is paying them to do. could as well say if they dont want to do their job, quit.


of something they need to upgrade and keep up to date anyway for a dozen reasons, in order to not split the network and in order to do the job they are paid to do. that is not very forced. it is a highly reasonable request.


clearly miner activated would be better.
clearly miners not delaying opt-in features for a reasonable portion of the community that wants it would be good.
question is what is any of us or the ecosystem going to do to fix this social or understanding problem.
@_date: 2017-03-29 14:11:40
yes i mean bitcoin directly uses the hashcash algorithm, adapted for more fine grained difficulty, fine grained difficulty is something which I had but stripped out of hashcash as used for anti-spam because I figured it was "good enough" and simpler to validate difficulty which was power of 2 only difficulty adjustment. (with that you can validate proof of work easily even from a sh script).
as far as that goes b-money, bit-gold and RPOW the three previous proposals and even implementation (RPOW) related to "no banking interface" boot-strappable mining-based ecash proposals out of cypherpunks Wei Dai, Nick Szabo and Hal Finney all used hashcash explicitly also (you can find citations on Szabo's blog, Finney's RPOW pages and list discussions etc)
now at the time I proposed hashcash I was not aware of the academic publication by dwork &amp; naor - I was trying from first principles to solve a problem - spam abuse via remailers to USENET, while preserving privacy, as concretely i was very interested in positive social disruption from cryptography, PGP, anonymous ecash protocols, OTR, pipenet/zks freedom network/cebolla/Tor (before tor) and was personally running a remailer for some time that was being abused by spam attack I believe in attempts to discredit and deter remailer availability by people who disliked privacy, maybe in similar ways that people are spamming bitcoin for unknown but possibly unfriendly to bitcoin ethos reasons.  the solution I found in hashcash, was arrived at by rejecting identity as the security principal on principle and instead focus on the core problem which is that email was cost-free and yet with negative economic externalities.  misguided abuse of identity as security principal for authorisation and service availability protection I still to this day consider a fallacy and recurring analytical mistake. you can see evidence of the mission creep in un-intended privacy invasive failure point in SPF providing non-repudiation - forced ISP level added, on the record, digital signatures on email for identity based anti-spam motivations. I also get concerned about initiatives to retrofit identity into blockchain consensus layer, I consider that a mistake also, in the same vein.
as far as applicability as ecash I recall mailing list discussions around the "this is kind of like digital gold" concept being commented on within days of publishing the beta reference implementation in 1997.  Ie it grabbed many people as an interesting possibility.  Fast forward through b-money and bit-gold (both published around the same time in 1998) and RPOW and to Bitcoin and there is a consistent connection with intended properties (bearer, un-censorable, fungible, no banking interface) achieved to various degrees.  eg RPOW had better fungibility/privacy guarantees but weaker survivability.  most of the cypherpunks and cryptography list archives from 1997 - 2002 era seem to have suffered bitrot so it's hard to find those early "this is kind of like digital gold" discussions.  I have tried nagging a few people who are the owners of the archive indexed/searchable sites to fix their bitrot.
quite some time later someone flagged the dwork and naor paper to me, and it's 3 proof of work proposals are not ideal for bitcoin use.  one what-if question post bitcoin, was could those proof of works be used in bitcoin, and it's hard due to missing properties around progress freedom, scalability (lack of constant sized proofs as difficulty scales) so I think the answer is a fairly clear quite difficult or inelegant/very large proofs and size relating to difficulty growing to sizes that with today's difficulty might be larger than blocks for the proof alone.  as far as that goes I consider hashcash a much better crypto design for the problem statement: harder guarantees, elegant/simple design, not stressing the hash function etc. one side-effect of the simple design, which took quite some work in whittllng down more complex alternative designs, is that somewhat frequently people describe the algorithm inline because it's fun to describe rather than citing.
for hashcash already the design simplicity/elegance, and robustness to cryptanalytic progress -- that tends to slide more in asymmetric cryptography with a long history of gradual algorithmic factoring/discrete log/elliptic curve/special case attack improvements -- contrasts with the the kind of designs used in Dwork &amp; Naor would be subject to. I had actually also considered asymmetric variants and rejected them in favour of the simpler symmetric only design. As far as even hash-function security assumptions hashcash, like HMAC, does not stress the hash function properties - ie it makes quite conservative and narrow assumptions about properties. so that for both HMAC and hashcash, even MD5 and also SHA1 would still work, whereas for generic use MD5 is broken, and SHA1 showing cracks.
i had conversed with the authors of client-puzzles and they also were not aware of hashcash when they published, and that idea relates.  there were a couple of other papers published after hashcash that looked at similar applications, sometimes maybe without citation - for context it's useful to understand at the time how widely known hashcash was amongst software engineers who were building internet applications.  there was a lot of since bit-rotted tech magazine and publications finding it interesting and at the time spam was a hot problem.  so in terms of who would have know about hashcash in relation to bitcoin design, i think the answer is almost everyone doing internet p2p, network programming, services etc. and many people generally. at the time it was common for me to be recognised "oh, you're the guy who did hashcash" from people I did not know at all at conferences. spam kind of faded as a hot topic from back then.
@_date: 2016-01-18 07:11:45
This is pretty funny. some light relief in a drama filled Bitcoin week. LOL.
@_date: 2017-03-05 15:16:41
good discussion points, and thanks for replying with technical comments. all to rare on reddit.


they explicitly do and this underlies bitcoin's security model suggest reading Prof Emin Sirer's explainer on this, which should be stickied IMO it is that common a misunderstanding 


no it doesnt because people dont orphan their own blocks and empirically today, 60% miners are already SPY mining.


and yet SPY mining continues.  You know that compact blocks is not adversarially secure?  Multiple miners take out of band transactions and fees for priority, those transactions often not being broadcast are not going to compress.  It is also trivial to induce slow validation.


see above Prof Sirer's explainer - SPV security depends on reasonable proportion of economic activity running full nodes, particularly including harder to censor and enforce external policy on anonymous power users vs business processors.


see ABcore. 


this problem persists because network compression alone is not adversarially secure viz 60% SPY mining.
@_date: 2017-03-05 21:01:11
see explainer about the cuckoo cache part from Jeremy Rubin 
@_date: 2017-02-17 14:01:30
no because of cleanstack rule. (handwavy version) it says that op_nul is valid and standard inside p2sh, but &lt;unknown params&gt; op_nul is valid but not-standard, the unexpected and not understood parameter on the stack (hence "cleanstack") is an indicator that the node is not understanding something about the payment and so should consider it non-standard.
@_date: 2017-03-04 18:32:10
true. some topics are also banned, from the side bar "Promotion of client software which attempts to alter the Bitcoin protocol without overwhelming consensus is not permitted."
we should have an unmoderated forum as an option.
@_date: 2017-03-25 14:40:49
I think in principle some of the work that was done for seg-wit helps make ext-blocks a bit easier than they would have been otherwise.
I think the bigger point is we shouldnt want to make bitcoin unvalidatable, and we should want to improve decentralisation.
@_date: 2017-03-09 14:27:13
antpool is not running BU.
@_date: 2016-01-01 14:49:35
I find "effective blocksize increase" pretty clear, and I was using that terminology before you started proposing "capacity increase". Blocks contain a range of data some via pointers.  The effective block-size = base block-size + witness data.
It is an effective blocksize increase that creates a capacity increase.  There are other things that create capacity increases: more compact transactions (like Schnorr multiSig), cut-through transactions like Lightning, payment channels etc.
I can assure you that at no time do I have any intent to be misleading.
The terminology is motivated by technical accuracy and understandability.
You seem remarkably paranoid and quick to jump to negative conclusions.  Jeeze.  Like the hackernews rant full of conspiracy theories.  Lay off the caffeine :)
@_date: 2019-03-12 11:34:19
did you run bitcoind or bitcoin-qt with --server (or server=1 in bitcoin.conf)?
if you have it installed in non standard location (if your .bitcoin folder is not in the normal place, beeing on an external drive) read these instructions 
@_date: 2017-03-05 16:02:26


that's an interesting comparison.
I am not a fan of over-priced transactions.  I would like to see bitcoin scale, and so transaction fees return to levels that do not price out may interesting use-cases.
@_date: 2016-01-02 12:39:15
I think you missed the starting point: the security of the network depends on the activity of economically dependent fullnodes: they enforce consensus rules in the network (with a bit of help from miners - the combination of them in a balance of game-theory).
@_date: 2017-02-09 05:45:39
It is not possible to implement a hard-fork ontop for two obvious reason that no one has tested this combination it is easy to construct plausible ideas on reddit, but it requires months of coding and testing.  Developer resources are scarce so there isnt spare capability to make multiple so people who dont really fully understand the tradeoffs and risks can haggle over which one post implementation and testing.
@_date: 2017-03-05 09:15:55
you read my mind. opt-in moderation for people who's "n" key is missing = nocems.
@_date: 2016-01-01 09:14:53
This is incorrect the main contributors to core are responsible for publication of hard fork BIPs 103, flexcap. The roadmap proposes a hard-fork. Were it not for discovery of ability to do better and soft-fork segregated-witness was proposed initially as a hard-fork.  And see the FAQ which goes over why a soft-fork is better than a hard-fork at this stage. 
@_date: 2016-01-10 12:26:23
I also did various other stunts like this 
And things I like as Confidential Transactions (formerly called Homomorphic Values) which was optimised and implemented by Greg Maxwell &amp; Pieter Wuille  and other fungibility ideas.
And in the past things like forward-anonymity (used by Tor now).
You have my word.
@_date: 2019-03-11 23:26:12
site with demo assets  explorer 
there is discussion on freenode IRC  or the open source elements project  that liquid is built with and compatible with has a FOSS discussion / user channel on bitcoin core community slack also:  channel. 
@_date: 2017-03-18 00:47:08
@_date: 2017-02-10 08:09:52
not sure you can read much into it, but one could observe that miners are likely getting higher fees per block in total with no increase, than they would with a 2MB+ segwit block.
@_date: 2017-02-09 05:01:06


Because a lot of companies say they are ready  and many users also, plus check out the node count which is not sybil they are fullnode upgrades.  Segwit may not be the perfect thing, but it's here, it's tested and we have to compromise somehow - it was a compromise to start with.
It maybe that there is an inherent bias - like negative news sells - people liking to argue on the interwebs.  Hopefully wiser cooler minds prevail.
@_date: 2017-03-05 16:36:02


blockstream is mostly about making blockchain trust and smart-contract tech available for other uses: shares, bonds, contract based instruments etc. as we base our tech on bitcoin source with elements sidechain and we contribute code and features back, and employ some people who straight-up work on improving bitcoin itself at protocol and code and testing level.
a few facts:
- every employee at blockstream is bitcoin invested (time-locked bitcoin + personal holdings)
- p2p side-chains are primarily about extending functionality not about scale. 
- lightning is an open protocol, and will route around high fees, and around censorship and improve fungibility.
- developers working on bitcoin at blockstream have contractual independence, todo what they think is right for bitcoin.
now what is your assumption that we would be doing that is in anyway against bitcoin's scalability and ethos?
I think blockstream has a great track record for supprting bitcoin, and I dont believe anyone in the technical community feels otherwise.  
so no, I think the best strategy for bitcoin is being taken in adding scale via lightning.  it is the fastest way to reach high scale without damaging nor disabling bitcoins differentiating properties of permissionlessness, censor-resistance, unfreezability, unseizability and fungibility.
@_date: 2016-03-13 18:52:39
Probably.  It can be hard to predict decades into the future as the tech is advancing quite quickly.  I like flex-cap best of the proposals because it introduces an economic feedback loop disincentivising flooding blocks with pay to self transactions.  
I also think we can improve the upgrade mechanism to be able to more safely and quickly do upgrades than with todays mechanisms so that we can react to improvements more easily.
@_date: 2017-02-10 08:30:52
segwit increases bitcoin blocksize.
@_date: 2017-03-04 20:13:14
ok this sounds a bit more reasonable.


well I would assume people are not going to activate UASF unless they are convinced by miner assurance or overwhelming majority are protected by fullnodes, that basically no one is at risk.


actually it's very similar, though arguably less risky than hard-forks which seemingly some people are mistakenly confident in the safety of.  I am glad that the thought experiment and analysis around UASF is helping people recognise risks.




OK we agree they should.  I think the reason people proposed UASF is many businesses are getting impatient that one or two miners are not signalling SW and seem inclined to stall, hurting scale, delaying lightning etc.  and yet with no rationale offered for why. a rationale people can work with, maybe a risk can be explained, or a potential issue fixed or an economics confusion explained - but "no because" is not a usable action for a business or users, and not good for bitcoin confidence.


this seems like a misunderstanding. the transactions are non-standard to pre-sw nodes intentionally to prevent this kind of issue.  they will not happen by accident. there is zero harm to be found by restricting to the SW-valid ones.
@_date: 2019-03-12 13:14:29
yes you're looking at blockchain data which is size minimised to provide transaction transfer, privacy etc. so it doesn't have info about what it is, what it's redeemable for (nothing unless you find the guy and he buys you a beer:) etc.
@_date: 2017-03-02 00:30:30
have you heard that segwit is a blocksize increase that can be active in 6weeks?  just needs activation.
@_date: 2016-01-20 06:09:04
Yes. Clearly there were many communication failures. On both sides even. Various people are working to try improve that now and in future. Admitting mistakes is a start.
Forum censorship is just bad.  And counter-productive - Streisand effect becomes the focus instead of improving Bitcoin.  I had to move conversations between forums to avoid censorship.
@_date: 2017-03-29 15:12:33
mining security tends to follow subsidy and fees by economic weight, eg viz ETC vs ETH both chains were mined like with economic arbitrage mostly neutral to philosophy, with hashrate tracking mining profitability.
@_date: 2017-03-29 17:38:35
No, there is auto switching software designed to do this for alt coins eg minergate.com Even if you value etc over eth or BTC over doge etc it can be econ rational to mine whatever is most profitable by the 5min interval and sell for BTC.
@_date: 2016-01-01 15:36:21
Would you please read the FAQ?  It is explained in quite some detail, if anything is unclear probably the FAQ authors will be happy to improve it.
@_date: 2019-03-21 00:45:30
Green has Tor support, plus for exploring tor/noscript explorer  But one current limitation with green is it does ask for an email (in order to send you the timelocked transactions for recovery).  We have implemented and plan to replace that with CSV recovery in the future (CSV timelocks are in the smart contract) which would remove the email dependency.  
@_date: 2017-03-04 19:01:15
@_date: 2017-03-08 09:14:40
many people have suggested similar ideas, here's a canonical explainer of why it is not as practical or simple as you are thinking:




It's certainly within bounds of technical possibility but ideally the time to have that kind of discussion would've been aug 2015 scaling conferences with 200 attendees, video streaming, and online participation via IRC or online and offline conversations in the 6months around that. segwith with approx 2MB initial size, which can grow afterwards via soft-fork with schnorr aggregated signatures etc, was the compromise that came out of those discussions. It would have been better to have what if 2MB HF + segwit back then, before 12-15mo work went into doing the widely community agreed compromise. Anyway that's past, lots of things could have been done better by many people.








And then there are also the ideas about flex-cap which are pretty interesting way for the fees to not collapse when block-sizes increase nor shoot up dramatically during surges, where miners can pay to dynamically surge block-size where it makes economic sense to do that. I think that's pretty interesting but needs even more R&amp;D.




@_date: 2019-03-09 12:26:56
for some reason super wealthy people, with land, who could buy anything, use them in the UK, even older ones which are kind of clunky and tractor level finish. they do last nearly forever. bodies are aluminium. chassis can be replaced, body panels service replaceable.
@_date: 2017-03-04 20:04:22
well you can say things in multiple forums. then the diversity of moderation policy means most things aggregate are not censored.
but yes we should create an unmoderated forum.
@_date: 2017-03-05 09:24:40


I agree with that.
I just think moderation should be opt-in.  Then for those who are opted-in to moderation they can opt-out again and look at the raw feed when things get linear and obviously things are getting deleted.
The modlog on r/btc is a good step.  But it's ugly to find the original post.  There is ceddit I guess but it seems a bit slow for some reason and I presume is read only.  I would prefer that the real base forum is uncensored, unmoderated and free-for-all.  One could combat spam with btc payment maybe.
@_date: 2017-03-15 14:34:20
to clarify the confidential transactions post was 2013  and I had a few optimisations that were in sketch form and not fully validated, though it clearly worked, what was unclear was that some of the optimisations conflicted and so not simultaneously usable.  Greg re-examined it and systematically went through that, and found a better optimisation path using two very interesting optimisations, the second even more interesting/innovative than the first, both clever.  First was to switch to a different base than base 2 (base 4) which is more size optimal, second was to generalise the hash-ring signature construct from an OR network to a collection of ORs connected with ANDs in a way that reused one of the challenge values across all ANDs called a borromean ring signature (a ring signature generalisation)   The base optimisation alone results in a 17% saving.  The base-4 change also was a 25% saving from 4 values per bit to 3 values, and then with the borromean ring to 2.5.  Use of the AOS hash-ring sig is also very space efficient as a start vs previous DL ring sigs.
@_date: 2016-01-01 21:06:49
See 
I think the poster deleted his account to censor the thread because his troll to create discord didnt work out.
@_date: 2016-01-23 06:38:18


I thought things were on a good track following the two scaling bitcoin conferences.
The current contentious bent to discussion from some directions seems kind of odd to me.  Not in the interests of Bitcoin.  unBitcoin like.
@_date: 2016-06-02 19:37:03
Explainer from video explainer:
@_date: 2016-01-31 19:25:34
that comes later if a block-size increase is hard-forked to take benefit of IBLT/weak-blocks work that comes after seg-wit soft-fork, then the effective block-size will be larger.
The net result is similar, just it starts faster and more safely via seg-wit soft-fork, vs starting at slower for safety 2MB hard-fork which was my previous outline proposal.
@_date: 2017-03-02 01:19:06


that's very bad for fungibility. and it's not a new idea. and schnorr aggregation provides more compression anyway.
@_date: 2016-01-29 07:41:29
send $5!
There you go fixed that for you :)
@_date: 2019-03-21 07:16:06
bitcoin moves are fast like a lambo with a sticky accelerator: the gains happen in a few days per year. being out of market, waiting for a better price, is a disproportionate risk. anyway that's what the HODL meme is saying and many people's experience too.
@_date: 2019-03-12 11:26:38
correct. the liquid/elements 4M weight will see a different balance because the range proofs are large relative to signatures, so the witness will be larger than 4x the body, and so unlike with bitcoin 4MW blocks will be seen at capacity (unless a lot of users disable the on-by-default confidential transactions features).
as block intervals are 1minute instead of 10minute, the larger transaction weight vs bitcoin yet same block weight, is likely offset so that transaction throughput should be similar.
the limit is a similar rationale to bitcoin - you want power users, traders and small businesses to be able to reasonably run fullnodes. the fullnodes are a bit heavier because the rangeproofs are like more than a dozen signatures in verification cost, and bigger, say bitcoin longer term converges with segwit adoption and more efficient block-weight use to around 2MB/10mins of data liquid would get to around 40MB/10mins so 20x more, and probably similar increase in CPU requirements. so liquid is more like desktop + high speed internet where bitcoin can keep embedded system and modest/baseline consumer bandwidth.
so for similar reasons you would not want to push up resources so it becomes impractical to sync, and keep-up.
@_date: 2017-03-04 19:47:07
i know my views on moderation are not the same as other peoples. i have seen in the past moderation degrade into censorship when some devious person finds the moderators kryptonite and next thing you know they're censoring things. even happened to the cypherpunks list someone introduced a moderated version. then someone found the moderators kryptonite, he talked to his lawyer friend, and next thing you know he deleted a post from both the moderated and even form the claimed unmoderated list. furore followed.  then the list was made decentralised like a mini-usenet with half a dozen nodes so it couldnt happen again. 
it also just annoys me in more heavily moderated forums (not these reddit forums but some mailing lists) for the moderator to say "enough of this topic" or "dont think it would be good to say this" and delete your conversation.
the cost of no moderation is to be willing to skim through bad signal to noise ratio, ignore the noise and focus on or try to generate signal.
moderation should at least be opt-in in my view.
@_date: 2017-03-05 20:29:58


not it was not. read the transcript, that was an entirely different HF proposal with a bunch of great wishlist features and alpha code too in a github.


that's not what it means and twitter comment field is short. it is explained here...  inflation control was the main problem with earlier designs, and one of satoshi's main innovations. anyway read it.
I think i plowed through all your contra arguments with ease. anything else? or are you converted to satoshi's way - ie p2p ecash that is permissionless and censor-resistant, via decentralisation.
@_date: 2017-03-05 18:48:47
probably closer to say somewhat moderated. nevertheless having your comments be removed from view for 99% of users is not cool.
@_date: 2016-06-02 19:37:59
and some info from elements project (sidechain where CT is implemented): 
@_date: 2017-03-13 12:31:48


Actually no.  Eg CSV was a soft-fork, in the event that a problem were found in it, future blocks involving CSV could be soft-forked out, to give time for a fixed CSV2 to be implemented, which could in turn be deployed via a 3rd soft-fork.  Soft-forks can add and remove features.
Reverting as in relaxing rules so that temporarily restricted rules were allowed again would create a hard-fork to people who did not install newer software beyond the version that was enforcing the soft-fork.
@_date: 2016-06-02 19:50:03
Confidential Transactions explainer paper by Adam Gibson including python sample code.  
@_date: 2016-06-07 10:12:55


I think you mean segwit is required for LN to function, and CSV (relative lock-time) enables time-unlimited channels (as said CSV &gt; CLTV).
@_date: 2019-03-09 09:14:29
Much better than a used lambo for the money ;)
@_date: 2016-06-07 21:50:21
I asked about this non-malleability fix workaround area, and he confirms that it can sort-of-function; however it has inconvenient limits.  Your anchor transaction can get malleated and so you need a CLTV timeout to reclaim the funds in case that happens, which then ties up your malleated funds up for a while until you can reclaim them.  Also has the undesirable side-effect of forcing your channels to be time-limited, where with CSV &amp; segwit you can have immortal channels.  (Or something like that, if I mangled it Rusty may now feel obliged to fix my explanation of the limits:).
@_date: 2016-06-08 14:44:57
You can watch activation progress here: 
95% activation threshold across.
@_date: 2016-06-02 19:46:30
People are working on it, believe I have the range proof down from 2.5kB to 2kB, maybe some more avenues to further compaction.
See also  at hong kong scaling dec 2015 where I argue that CT is not as far from practical for mainchain use as one might assume, because a CT transaction is more powerful and can in some uses replace multiple regular transactions.
eg say you're investing in bitcoin and you split your coins up into 0.1 btc, 1.0 btc amounts across multiple transactions even though they were all bought at once because you dont want to reveal how many BTC you're holding (or that you are paid as salary in BTC) when you spend.  With CT you could combine those into one payment saving many smaller transactions.
Say each CT transaction would on average replace 4 regular transactions, then practical deployment would be to compact CT enough that the transactions were only 4x size.
Another factor is that perhaps people would be willing to pay more for CT transactions for better privacy over bitcoin holdings.  This also illustrates that there is a third tradeoff in scaling (other than decentralisation vs scale) there is also privacy vs scale.
CT also works better with CoinJoin.
Also CT enables you to send 0 BTC to people to improve fungibility (and privacy).
@_date: 2019-03-11 23:21:22
@_date: 2019-03-11 23:42:18
Yes but it's quite small / fast to sync (so far).
@_date: 2018-10-11 16:23:36
what's the law (variant of betteridge's law) on the effect where when you read an article a journalist writes about something you're an expert in and you're aghast at how confused/inaccurate it is?  start to wonder about Nouriel when he says such under-informed and plain factually wrong stuff about Bitcoin with absolute confidence.  does he do the same with economics itself?  
@_date: 2017-03-04 18:33:25
that applies to r/bitcoin too. both moderated. so is bitcoin-com and bitco-in. some more so than others.
@_date: 2018-10-13 09:41:41
they also have other lines of more retail bitcoin related business, I think particularly in latin american countries.
@_date: 2018-10-11 08:25:53
there are multiple mis-attributions so it's significantly exaggerated. it also doesnt show other entities eg chain-code. also where does the data come from is it talking about IRC meetings? i'm not sure why it would be surprising that protocol capable developers would attend them. you'd be more worried if a company had no one participating.
@_date: 2019-03-06 19:48:59
github tracker  with feature request list and issues.
@_date: 2017-08-21 00:37:52
 and he's live. received a tx over satellite on an internet offline laptop.
@_date: 2018-10-10 18:27:54
2 or 3 blockexplorers coming.
@_date: 2017-01-21 23:27:30
I am not sure I see it. 
**What is a block?** It is a set of transactions.
 
**How is the block related to the Proof of work?** It is a commitment to the merkle tree containing the data in a header structure.
**What is it that didnt change?** A variable name in the code.
**Is this a rationale to argue against fixing the malleability design issue or stalling upgrade that brings about 2x capacity and paves the way for higher scale with lightning?** No.
@_date: 2018-10-11 10:32:52
other than speed, another bonus offsetting federated security model somewhat is that the Confidential Transactions features improve fungibility.
@_date: 2017-01-12 18:14:31
From the article:




Naturally we charge for that...
Think of blockstream as the cisco / redhat of blockchain infrastructure.  Clear enough?
@_date: 2016-01-01 21:41:02
seg-wit increases the effective block-size.
@_date: 2018-10-10 22:20:22
a side-chain is a related chain to a main-chain.
here the relation is that main-chain coins can be moved into the liquid side-chain, via two way peg.
people have also talked about other types of side-chains, eg one-way pegged side-chain (move coins in but not out again)
some more lose interpretation I have heard people claim namecoin is a side-chain of sorts, of bitcoin because it is merge mined.
alt-coins are not side-chains though because their chains are unrelated other than using Bitcoin ideas and/or code.
i guess forks are a new type of related chain like Bitcoin gold, etc.
@_date: 2018-10-11 09:01:44
u/andytoshi and others are working on it, for smaller CT &amp; CA.
@_date: 2018-10-11 11:03:28
but that's a false premise that's been debunked multiple times. lightning and liquid are scaling for bitcoin, but mostly they are different and better tradeoffs for specific use-cases. it's not engineeringwise that realistic to assume $1mil international transfers 0.1c microtips, $3 coffee, and censorship resistance needed use cases and high value long term cold storage all need the same tradeoffs. one or more of these use-cases will always be sub-optimal in a one-size fits all world view where everything goes on chain.
also blockstream the company holds bitcoin, and all employees are partly paid in locked in Bitcoin so stand to gain from bitcoin adoption which depends on scaling bitcoin.
plus blockstream is one of the three companies working on lightning which is far better for scaling some types of transactions than flood fill broadcast global permanent record. and lightning payments are faster, nearly instantly final, lower cost, and more private.
@_date: 2018-10-06 10:39:11
I'd assume the biggest challenge is whether there would be community support for trading off decentralisation.
But if there was consensus for that, wouldn't extension-blocks be simpler and more elegant?  
Yes old nodes can't see the data, but balance that against the inelegance of using the time-warp attack to accelerate block-rates plus other complexities to get it to work.
You can view segwit as a partial extension-block (with only signatures weight accounted for as extended data), where a general extension-block has the whole transaction included.  Extension blocks can also be backwards and forwards compatible with non-upgraded nodes.
I'm not sure sharding is generally an answer to validation cost, because either you validate the data or you do not (fully).
@_date: 2017-03-05 09:19:50


there are several limits: one is what does it cost to run a fullnode, so that users can have economic self-sovereignty and be on the bitcoin network proper rather than trusting other people.  maybe &gt; $100/month is too much?
exchanges bigger can probably afford a higher conop.
but the lower bottleneck is pushing the latency race for miners so that they centralise mining to SPY mining (60% are SPY mining today) and pushing latency race further I expect will be reacted to by running a single central pool.  At that point permissionlessness, censorship resistance, and funds freezing are likely lost - a single court order on a single legal entity and it's game over.
@_date: 2017-01-21 22:39:35
Well recycling UTXOs which segwit encourages is better for scaling.  So maybe you could say leaving unnecessary dust in the UTXO is like creating extra garbage that should have been recycled.
@_date: 2017-01-29 15:56:03
No but it segwit makes script extensions easier to test and deploy.
But you really want to compound big-O complexity improvements.
@_date: 2017-01-22 02:21:57
I think segwit is pretty close to what can be done easily with a soft-fork towards the effect you mentioned, but also see 
@_date: 2017-08-09 19:47:37
Here's some more text I wrote that explains and comes after that text, from email thread the "If a few companies, or even a cluster of companies, can effectively take control of bitcoin governance, and force a change - that is a definitional failure of Bitcoin's decentralised value proposition in itself" part came from.
















@_date: 2017-01-05 07:28:58
Progress on scale and features requires software upgrades.  Scale probably doesnt affect market fundamentals much because that appears mostly about hedging geopolitical currency issues.  But it would still be nice to have soonish!  There is some eventual risk of altcoins if protocol progress is long term stalled.  I dont believe adoption of innovations will stall and people need patience for the market to work these things out, but something to keep in mind.
It is completely non-controversial to work together on taking scale innovations, like making transactions 30-50% smaller so you can pack 3MB-4MB worth of transactions in a 2MB SegWit block.  I was talking about schnorr aggregation advantages in early 2013.  Similarly non-controversial to make hardware wallets radically cheaper and more efficient with signed values.  And to fix malleability so we can get to lightning deployed in wallets asap.
I talk about some of these scaling and protocol improvements here  (skip to 1h00 mark) at venue in Prague mid last year.
By most metrics Bitcoin pace of protocol innovation is at an all time high and we can have our digital gold and cups of coffee both.
@_date: 2017-08-14 13:36:19
much of the world doesn't have ID, but many do have smartphones.
@_date: 2017-01-06 11:13:18
Yes.  You get unilateral benefit by upgrading in terms of access to more scale at lower fee per transactions.  The stat has been that transactions are 66% signature (roughly) so if you get 75% lower weighting on the signature part you'd expect roughly half the cost.
What's more you adopting moves signatures out of the main block into the witness space, creating more scale and immediate benefit even for people who did not yet upgrade.
@_date: 2017-01-09 13:24:46
this blog by Emin Sirer may help explain the confusion about hashrate and protocol rule enforcement 
@_date: 2017-08-21 01:04:29
yes. it would do that too but the primary purpose is to work through outages of up to 24hrs. eg storm pushed dish out of alignment. solar eclipse blocked path :) etc
@_date: 2018-10-10 22:25:54
the consensus rules are that &gt; 2/3 of the functionaries sign transactions. technically 1/3 could block transactions.  the current network has 23 participants but 15 functionaries, so pegged BTC are held in an 11 of 15 multisig. technically that means 5 functionaries could block a transaction. however the software is not discretionary, it's unattended block processing based on taking the highest fee-rate transactions first.
@_date: 2017-01-06 14:53:58
nice :) good for you!
@_date: 2017-01-30 09:05:53
buggy implementation, defective protocol design, and buggy default configuration IMO all three.
@_date: 2016-06-07 10:34:38
Pools and miners do their own testing, fyi, which is a good thing though this obviously adds time.  Do recall that upgrades are risk points, and for example things went wrong and had to be corrected with miner coordination in several past upgrades over the last 4 years.
@_date: 2017-01-04 08:14:28
Read about Their's law...  "Bad money drives out good if they exchange for the same price."  ie Gresham's law is due to legal tender laws.  In a free market money situation good money drives out bad.  The section gives examples where this has happened, eg dollarisation of economies with unreliable currencies, even in the face of illegality of USD use.  Thus it will be for Bitcoin.  Already seeing evidence in the demand spreads in countries with hyperinflation, capital controls and anti-cash policies (Venezuela, India, Pakistan)...
@_date: 2018-10-11 08:18:16
yes it's very bitcoin-like. fees are paid in LBTC. block-construction is based on highest fee-rate. the difference is most of these transactions are likely to be trade related larger transfers, so they won't push up bitcoin mainnet fees.
possibly bigger could be later. it has the similar tradeoff to bitcoin, it is important for businesses and individual power users and traders to be able to practically validate the chain with their own fullnode.
@_date: 2017-08-15 23:24:00
right. actually it's even better the stream is authenticated by PoW so you could authenticate it via SMS of the 80 byte blockheaders once every 10 minutes.
@_date: 2018-10-10 18:44:52
we can make the transactions smaller with bullet-proofs which has some log-scaling benefits also. possibly bigger could be later. it has the similar tradeoff to bitcoin, it is important for businesses and individual power users and traders to be able to practically validate the chain with their own fullnode.
@_date: 2017-01-29 08:45:50
Mimble Wimble is a motivation to get a sidechain working asap :)
@_date: 2017-01-12 15:11:10
Encourage companies to contribute to  development  
I would encourage all companies to collaborate in making
Bitcoin more awesome, joining best practice and interoperability
efforts at application level, and contributing to the development
process, whether that be by bug reports, feature requests, community
event management, documentation, applications, making bitcoin easy to
use, hiring developers to work independently on bitcoin or funding
volunteer developers.
And users to volunteer  whether documentation, 
Translations, Testing code, testing releases, Improving UIs or contributing on  coding 
@_date: 2017-01-25 14:20:43


The early rubik's branded ones had removable centre panels covering a screw to adjust spring tension like the one in the film, I had one back in mid 80s.  Often the modern speed cubes have no removable cover.
@_date: 2019-03-11 23:57:08
liquid is mostly interesting for people who trade on exchanges, or do cross-exchange trading as it allows them to deposit funds faster from storage, and move funds across exchanges quickly. it also paves the way for trustless exchange. you can issue assets on liquid like the  demo
also interesting if you want a preview of how confidential transactions could work on Bitcoin with L-BTC.
fiat coins on liquid as those come online will make things interesting also for atomic trade, arbitrage / market-making and network liquidity.
@_date: 2018-10-10 17:24:58
The use case is for trading, if the alternative is single exchange custody federated is strictly better.
Also as liquid transactions use confidential transactions and confidential assets, improved fungibility in part offsets the federated limitation.
@_date: 2017-01-23 01:13:13
That'd do it. But I think most would agree it's an unnecessary imposition on someone who just wants to do a few transactions with an old wallet - that would be a forced upgrade.
@_date: 2017-01-17 09:48:17
How so? Do you envisage that Intel and AMD have remote control of all Intel and AMD chips?
@_date: 2017-01-29 08:51:49
You could split it eg fix malleability via soft-fork with no scale.  Curiously that might have passed with no controversy like CSV etc but why delay scale?
You could increase capacity via hard fork but it's more risky and so needs to be slower.  Either way people need to be in consensus before changes are made to Bitcoin.  The way to get towards consensus is to strive to improve understanding and state clearly concerns and technical tradeoffs.  Ie to get to consensus you have to want and try to do that by talking in a positive sense.
@_date: 2017-01-22 15:21:01
It is by design an opt-in fix **and that is a feature**. It could be made mandatory with soft or hard-fork, just wiser people realise that mandatory things are unfriendly. It is also easier not to, because you have to grandfather existing transactions otherwise you freeze lots of coins, which is obviously a non-starter. That wouldnt fit in with the security best practice to keep complexity as low as is reasonable without creating tech debt.
All clear now?
@_date: 2017-08-22 15:06:06
There is no contradiction. Security measures in logarithmic bits. At no place did I say (obviously) that Bitcoin should use integer log difficulty.
@_date: 2017-01-22 02:17:24
What are you talking about?  Doesnt make any sense.
@_date: 2017-01-08 22:55:47
SegWit is a blocksize increase to around 2MB.
@_date: 2017-01-22 16:13:48
@_date: 2018-10-12 01:06:29


the transaction processing rules are the same in terms of consensus, block construction and signing for liquid assets and LBTC. pegouts are managed by a pair of transactions reflecting the pegout on liquid and a payment out of a multisig on the main-chain. similar with peg-ins.


only if 1/3 of them modified their respective functionaries and colluded. consensus is round-robin so they would have to block all other rounds which would be noticed. because of use of Confidential Transactions fungibility and HD wallets it maybe difficult for specific exchanges transactions to be identified for blocking.


it would take &gt; 2/3 to take funds without approval, and it functionary modification. bear in mind the participants are identified businesses and the pegouts are signed.
@_date: 2017-01-22 03:28:34
the article by that was linked 
@_date: 2017-01-30 12:21:54
Correct.  Bullet dodged on this one.  It was 20mins until block mined, they had lots of time to build on top of it, it was "unlucky" that they did not.
[edit: 24mins until next block mined]
I expect people will try to work out what went wrong, it's possible that they did create a child of the invalid block and network connectivity or link bans from invalid block relaying meant that they have not yet been found and got orphaned without notice.
@_date: 2018-10-11 10:31:46
no inflation because there is a 1:1 ratio between BTC frozen in the peg transaction on Bitcoin and L-BTC being used on liquid.
@_date: 2017-01-22 00:05:13
Yes, but no one would have sent them because they would not have been safe, if not for miners enforcing segwit and understanding the signatures in the witness area.
@_date: 2017-01-10 09:49:25


You could also unban he was doing a good job of adding balance.  And whitelist etc.  Lots of people unable to speak on r/btc.  Two wrongs dont make a right of course, but as you're commenting on the topic ...
@_date: 2018-10-10 18:31:12
FOSS tools and examples coming.  A liquid asset is just a special transaction type, you pay the LBTC fee and create them.  Whether some exchanges will list your asset is a different topic. They can exist unlisted as demo/test assets.
@_date: 2018-10-10 17:52:42
23 participants, not all of who have announced yet.  15 of them are running blocksigners. 11 of 15 multisig in the current version. you can probably find them on a block explorer.
@_date: 2017-08-14 12:12:43
@_date: 2017-01-21 16:32:12
@_date: 2018-10-11 07:33:00
yes you can own and p2p spend L-BTC. wallets you will be able to use GreenAddress and an upcoming Liquid Wallet soon. BTC to L-BTC exchange by swapping with other users or deposit/withdrawing on exchange.
@_date: 2017-01-06 21:01:43
Note I am not saying what is preferred I am just observing what is for now.  Lots of things would be preferable, eg free fees, infinite scale, instant final settlement, cryptographic privacy &amp; fungibility, miner decentralisation.  Anyway incremental progress has the answers over time.  Things are going well.
@_date: 2017-08-09 09:36:12
@_date: 2017-01-29 09:26:01
I think people often dont internalise without trying it and finding out for themselves quite how much it is the case that consensus algorithms are fragile, similar to things like cryptographic signatures and encryption where if you change a few things around it can go from secure to broken unpredictably. Game theory is also fragile, counter-intuitive and unpredictable to the non-expert.  Even experts get bitten without peer-review.
Take selfish-mining as an example that took years to discover, and all attempts to "what if we do this to fix it" by some very clever people, all failed under peer review on bitcointalk in short time.
People can go find the threads it's instructive to look at the surprises in the attempted fixes.
Also I think just because there are some consensus rules, there are limits to the consensus systems functioning - if enough users do different and divergent things, send false signals, wrong signals, or change their code around - it's entirely possible, even likely, that the network will just fail in various inconvenient ways.
Mix in economic incentives - a financial incentive for people to adaptively and maliciously signal in search of some outcome - and it becomes complex.  We know people will adaptively do things to game the system, because they have been doing it all the time over the last years.  This is why bitcoin tries to minimise gameability and incentivise  behaviour that results in correct system operation.
@_date: 2017-08-22 13:57:34
You can have fractional powers of 2. Eg 78.1 now. You can still see by hand that it is 78.something and you can even estimate the something by approximating log base 16 of next digit.
@_date: 2017-08-14 13:14:34
yep. the beauty is the transaction can be small, so a wider range of tech can work.
@_date: 2017-08-10 01:04:28
so with some help from u/goatpig - thanks! - I got one of the recent armory versions to compile.
they have done several overhauls since the last ATI version, and changed the DB model, used a more complex threading model to eek performance, and it it is *really fast*.
like &lt; 10mins on a 4 core new i7 laptop with SSD and 16GB ram, never used more than 4GB vm/2GB physical.  (excluding already synced bitcoincore).
@_date: 2018-10-11 09:01:10
so think about it as liquid is a blockchain, though with &gt;2/3 threshold signing in place of mining. the risk depends on how the asset are held. if you hold them yourself with a hardware wallet (cold store) then your risk is similar to cold stored bitcoin for liquid assets, because you can run your own fullnode and the assets are native.
for LBTC the story is a bit different, however there are hardware modules with the keys, automated boxes stored in exchanges operations centres (typically same location they store their hot wallet, so it will be hard to get physical access). the keys are stored in the hardware module and do not leave it. there are also other protections, the hardware module will only peg-out to exchanges who can use a redundant liquid fullnode to verify it is correct.
because you can transfer faster deposit and then trade is more plausible. and potentially trade with multisig trades it can provide more direct user control and longer term reduce exchange hot-wallet risk.
@_date: 2017-08-23 20:23:14
I dont understand this argument. If they wanted to avoid a chain split they would try to be inclusive, open and make a proposal and not make enemies of bitcoin holders, users, and the ecosystem with an ultimatum.
@_date: 2017-08-14 13:46:39
Who says they dont own bitcoin too? (I know a number do).
Separately about why they invested - here's the "why I invested" comments from our seed round lead: 
@_date: 2017-08-10 10:20:31
I think my $10k server could've done it, but it's not here.
@_date: 2017-08-24 19:08:51
should be blockmaxweight=4000000 and delete the blockmaxsize line.
@_date: 2017-08-09 22:19:53
I think you have that reversed: BIPs are work by consensus - the part people object to is a few individuals thinking that it is OK for them to try to force changes on everyone else, even if there is clearly lack of consensus for their proposal.
@_date: 2017-08-15 16:28:38
you can buy bidirectional satellite data, expensive per MByte, not only about 1c / tx for average 250Byte bitcoin transactions.  Plus use lightning so your tx stays local once the channels are up and monitor via a villager local IT/tech guys satellite downlink fullnode.
@_date: 2017-08-21 00:35:10
@_date: 2017-01-06 14:07:26
Well if people dont want to upgrade, then they dont consider the fees high enough to optimise, evidently.
Also any upgrade requires software upgrades and collaboration from the ecosystem.  A HF requires very coordinated and long term planning and a planned HF has never been done in Bitcoin where as many SF have.
And demand wont go in a step function from 1 to 2MB with a 2MB soft-hardfork either, but that's still not a reason to not upgrade opt-in scale which ever method is used.
And finally segwit should be more gradual, with a simple HF other than the currency split risks, and upgrade failure risks, and economic incentives for miners to mine both sides, the excess capacity with a simple HF could easily drop fees to zero and present a shock to miners.  (talk about "economic change event":)
@_date: 2017-08-16 01:49:50
a 33km cable. well full coverage coming before end of year.
@_date: 2017-08-21 00:43:12
he really might be well placed to if his fiat is hyper-inflating, doesnt trust banks due to corruption and doesnt have ID to get a bank account.
@_date: 2017-01-07 08:31:36
Re "individual user unilaterally getting full benefits" to your point specifically you personally as the hypothetical single and only segwit user, you could send 3 transactions when other users could only send 2 (and outbid them on satoshi/byte by a tiny increment) with the 2 input 2 output case (higher ratio with some other io patterns).  Or you could just get 40% cheaper transactions. 
Lets run another unilateral adoption case, if you were payment processor doing say 1% of transaction volume and using Rusty's 372 bytes (which is above the median 226 bytes for a bitcoin transaction today) then you would be doing without segwit 27 transactions/block or 3870 transactions/day.  With the same cost and capacity use, by unilaterally adopting segwit your service could send 47 transactions/block or 6713 transactions/day a 73% transaction throughput improvement at 0 extra cost.
So yes unilaterally adopting segwit really does benefit you.
You can see why many payment services, hosted wallets, security providers, exchanges, and user wallets  are standing ready to use segwit.
@_date: 2017-01-30 15:57:23
the level of validation used to be worse than it is now. at least some of them now revert to their fullnode for next work queue block proposal after a few minutes, which would cause them to work to revert their old work. the bip66 fork was I think 12 empty blocks in a row so clearly they did not easily stop spv mining once started at that time.  however this timeout thing in some of them changed since then I think, presumably reactive to getting stuck in that mode with &gt; 50% hashrate. also the other hashrate couldnt catchup and interrupt them once they pulled ahead with any strong probability which it would if they were all mining valid stuff so you could see how this string of empty blocks could get triggered by mining one invalid block. I dont think we know enough about the behaviour of each relative hashrate spv minrs. Some of them are also not internally monolithic in config - multiple versions in different sets of hashrate and locations within one pool or solo miner.
@_date: 2017-01-21 23:34:15
No 3,000,000,000,000,000,000 H/sec 
= 3,000,000,000,000,000 KiloH/sec
= 3,000,000,000,000 MegaH/sec
= 3,000,000,000 GigaH/sec
= 3,000,000 TeraH/sec
= 3,000 PetaH/sec
= 3 ExaH/sec
@_date: 2017-08-24 19:24:18
no, they will not if it's not profitable.
@_date: 2017-08-05 09:09:35
Dude: withdraw cash, put it in a duffel bag, walk across town, deposit it in next bank.  I have done this for immediate bank-to-bank deposit I needed to happen by a 12midday property transaction ($$$) and it works and it's free.  Felt a little nervous with that amount of cash, but the retail bank will take you into a private office room to withdraw/deposit that kind of cash.
That's what Bitcoin can do, but at a distance!
@_date: 2018-10-10 19:05:06
right that's the exchange-level participants. users with liquid assets or LBTC would just pay network fees (like on bitcoin, but LBTC).
@_date: 2017-01-30 13:36:24
Yes it would be rejected without doubt or glitch by todays economic full nodes. It may present a danger to SPV (smartphone) clients of today though. Their model could do with improvement. Some wallets today have a better model which is a semi-trusted fullnode maintained by the wallet author, spot checked with p2p fullnodes. Some connect to a few p2p fullnodes and could be chance be surrounded by invalid block accepting nodes and provided information showing them transactions that may never be accepted on the main chain. In the chaos some may seek to defraud SPV users via multiple confirmation double-spends.
@_date: 2017-01-22 03:15:58
Not disagreeing, just that to be backwards compatible you need to express a cost that maxes out at 1MB in bytes. So you see with segwit there is the formula base+1/4 witness &lt; 1MB.  And with the Validation cost metric proposal I linked to, there is a more sophisticated metric that still maxes to 1MB but achieves closer to what you were describing.
The other problem is you dont want a multidimensional problem (eg a limit in outputs and a separate 1MB limit in bytes, because a wallet wont know what other transactions are in a miners mempool, in order to choose fees or help miners pack their transaction into block, it becomes more like blind tetris.  And for the miners sorting by validation cost metric is easy todo the knapsack problem is actually NP hard and so can even get computationally expensive as well as complex to implement reasonably efficient heuristic versions at a given size.
@_date: 2017-08-16 08:56:36
Yes there is some block retransmit via the satellite but only enough to recover temporary outage. You need sneakernet/snail to get the block history on blueray/dvd etc.
@_date: 2018-10-13 01:40:15
betteridges law 
@_date: 2017-08-15 16:58:37
more like and that's a problem, so we should work as a community to fix it. the satellite is infrastructure the community can build out wifi repeaters and configurations locally.
@_date: 2018-10-11 00:29:46
I tend to agree. But side-chains is an old word and some people have different opinions, that include very vague or indirectly related chains.
@_date: 2017-01-21 23:15:20
With 3 exahash = 3000 petahash = 3 million terahash = 3 billion gigahash, the current hashrate, if it were all 16nm equipment maybe 0.15J/GH then maybe 450MW and $500m worth of equipment.  Probably more on both because of mixed generation equipment.  Say electricity cost 3c-5c/kWh so maybe $120m-$200m/year electricity.  And $600m/year subsidy from bitcoin mining + fees at current $925/BTC, maybe fees are $50m/year +/- (at 0.8BTC/block) though that will probably fall once segwit and lightning are active, or at least more transactions and hence more utility value will be derived.
@_date: 2016-06-02 20:55:14
CT also improves fungibility because change vs payment is not disambiguated by amount eg 19.99 at spot price vs 13.237 any guesses which is change.
@_date: 2017-01-12 18:19:44


We feel quite good about being able to provide full time jobs and leeway or paid time at work to work on Bitcoin, and for being a good FOSS community player  in contributing back to code that we base our work on.
Some of the extensions and features tested on sidechains have informed or been used in Bitcoin, so some of the work blockstream have done on sidechains (that are extensions of Bitcoin, being based on the bitcoin code base), has fed back into Bitcoin.  Several soft-fork features were first used live on elements sidechain.  
I hope in due course a proposal is made for consideration to add confidential transactions to Bitcoin users (either direct or via a p2p sidechain).  It certainly seems like a feature that a lot of people in the ecosystem and community were very interested in.  Confidential Transcations was first conceived before blockstream, but it was the resources and commercial applicability that enabled us to improve the design and implement it.
Note none of the developers working at blockstream previously were working full time on bitcoin (neither as volunteers nor paid) because they had day jobs or other things (eg study) using up their time.
@_date: 2017-08-23 13:29:08
Right but Rusty is not saying anything in favor of closed door process.  He's trying to start open discussion towards consensus.
@_date: 2017-08-14 11:10:37
@_date: 2017-08-23 22:43:30
I would say no to all of those questions. So would old @_date: 2017-01-10 20:53:02
there are a few FAQs about this topic 
@_date: 2017-08-13 11:21:08
Or a business could try talking with the protocol developers, explain their use case, problem and see what advice they give on how the businesses own developers can solve their problem.
Sounds simple and pragmatic, but for the most part this does not happen.  The companies do not talk with protocol developers.
And FWIW there are many practical and simple things companies can do today to increase their scale, lower their fee costs etc. which they are not currently doing.
@_date: 2017-01-10 20:53:15
@_date: 2017-08-17 11:07:36
it's possible we could do both.. eg big dish higher bandwidth, small dish base bandwidth with appropriate error-correction and satellite magic.
@_date: 2017-01-03 15:33:44
It also probably helped it's owner not day trade it at much lower prices.
@_date: 2017-01-09 12:37:20
there's a FAQ that answers some confusions like that 
and flex trans has problems 
@_date: 2017-08-21 00:41:47
yes 24hr cyclic retransmit. may increase period after optimisation and tuning.
@_date: 2017-01-21 22:40:17
It is a blocksize increase.
If you add a second fuel tank to your car, but dont yet upgrade the fuel gauge, you still have bigger range and fuel capacity.
@_date: 2019-03-09 08:58:37
looks like a rugged work-horse self-reliant grade vehicle. nice choice.
@_date: 2017-08-17 09:25:45
24hours outage with current conservative 64kbits assumption on 46cm/18" dishes.  once we have some stats from people at the periphery of coverage zones there is opportunity to achieve more bandwidth if the signal is good in practice at the periphery. in main coverage zones it could do ~2x. with bigger dishes it can also do more still, however we want it to work stable with standard 46cm/18"  satellite TV dishes so that people can use 2nd hand ones etc and to keep costs low.
@_date: 2017-08-22 09:02:32
you can also verify them by hand with shasum on the command line which is installed on most systems, or by using a SHA1 library from code.
@_date: 2018-10-13 17:10:28
liquid is a p2p network operated by a federation of exchanges with threshold signing (11 of 15 multisig). the federation is not blockstream, it is a set of 15 exchanges, market makers etc distributed around the world. blockstream is also not able to force push software nor network participant updates.
obviously it is a tradeoff designed to be useful for traders, exchanges, market-makers/arbitrage so the alternative is lower velocity, slower deposit/withdrawal single custody exchange. we'll see what people find interesting to build with it and use it for, some may also find the confidential transactions and other features interesting and use the LBTC p2p, with choice of full-node, greenaddress liquid wallet (coming soon) and block explorer.  NBitcoin fullnode, library also is working on elements/liquid support.
the other feature is liquid assets, which are native to the chain and power user issuable.
@_date: 2017-01-29 08:48:34
I think it is miscommunication leading to mutual confusion of intent.  Everyone actually wants the same thing, bitcoin success, conservative security management and keep improving scale and decentralisation in balance.  Lightning is the big interesting deal in scale, so lets do it!
@_date: 2018-10-10 21:24:15
side-chains are not consensus dependent, otherwise it would be more correctly described as an extension-block, and the risk with that model is it could import consensus fork risk from the extension-blocks codebase or new features.  side-chains are by design loosely coupled.
@_date: 2017-08-18 01:43:11
Personally I think it has a number of problems and I would sooner people worked together in a collaborative way.
As people can see form the satellite and working with the other lightning companies we're doing our part to bring bitcoin to billions of people.  
We have to scale intelligently with scalable tech like lightning and other layer2 innovations as well as on chain via backwards compatible, well tested and reasonable integration time upgrades.
We already get 2x-2.5x with segwit once fully adopted and MAST, schnorr aggregation etc soft-forks coming next.  Adding 2x doesnt move the needle nearly as much as 1000x from lightning and the disruption of a non-backwards compatible change is IMO not worth it.  Definitely not worth creating another spinoff coin like BCH.
@_date: 2017-08-24 11:17:56
I think managed to hit most of the segwit fallacies in one continuous conspiracy story :) only missing are the hollow earth and lizard nazis? 
@_date: 2019-03-09 12:23:32
Seriously. People run these things for 50years. You can even self-replace the chassis. British gentry, farmers, out door people use them they last and last. You can also tow ridiculous things with them. Have seen people towing a trailer of hay on steep inclines. The military also uses variants with older less electronic engine controls to withstand EM pulse better and be easier to field service. Fuel efficiency is not great especially on older modela, but otherwise serious equipment :)
@_date: 2018-10-10 17:30:57
Liquid is a public network however. FOSS smart-phone wallet coming soon. You'll also be able to run a full-node and audit the network (though much of it is encrypted due to the confidential transactions and confidential assets.)
Note for native assets the federation signers can only select the transactions, once they are final, which happens after 2 (1min interval) blocks, they are not able to be undone - as it is not probabilistic, reorgs cant go deeper.  So a full-node can verify that.
@_date: 2017-01-21 23:38:20
Present company excluded, answer was somewhat general.  Questions about related things gets asked 100x/day.  Hence FAQs etc. 
@_date: 2017-08-15 23:22:58
transactions in near real time (even before confirmed) and then blocks (via network compression with fibre 
@_date: 2017-01-21 23:29:13
Every upgrade to date has used soft-forks.
@_date: 2017-01-08 23:47:27
FAQ should clarify 
@_date: 2017-08-07 21:42:31
segwit is a blocksize increase.  another few FAQs:  and 
@_date: 2017-08-24 19:10:11
they are overpaying. just set it to 1sat/byte dust limit. clears fine- their blocks are empty.
@_date: 2017-01-22 03:33:04
Bald assertion. Give us the code reference and your critique?
@_date: 2017-08-22 09:11:01
That's not what that's saying.  It's saying you can represent difficulty as a fractional or floating point power of 2.  Today it is 78.113 for example.
So it might be an useful and easy fact to remember and track that security is about 78.1 bits this adjustment period.  Security is usually expressed as bits of entropy (2^bits for brute force).  eg AES-128 for 128-bit security etc.
See also 
@_date: 2017-08-23 20:58:41
If his own colleagues and co-founder cant convince him...  Note bitgo did not sign the NYA agreement, just to offer technical assistance, because of the principled rejection from the other Bitgo guys, so it's kind of odd that Mike would be the front person for this.  They take the flak without even being solid supporters.
@_date: 2017-08-05 09:34:16
Bitcoin is also better for asset protection. Much harder to find ownership and create a fake excuse to seize your assets, with a tech savvy user and defensive config. Even if they got past the first hurdle of convincing themselves you have the Bitcoin, they have to go the hardway to compel you to hand it over. That gives you time to say no, and for legal defence against bullshit seizure: possession is 9/10th of the law. The other way around, with fiat, you can go whistle to haggle for your money back and they can drag their heels.
@_date: 2017-08-15 23:21:17
we plan to offer an open API for developers to send auxiliary data for mBTC/kByte via the satellite broadcast. then for onwards use / repeating via wifi hotspot/meshnet coverage that people build out from there.
@_date: 2017-08-22 14:26:39
Bits is logarithmic (whether floating point/fractional or integer) difficulty is a large number divided by 0xFFFF0000 (approx 32-bits). The norm in expressions about security level is in logarthimic form: bits.
@_date: 2017-08-15 16:26:21
yes there is periodic retransmit to cover moderate interruptions.
@_date: 2017-08-23 11:37:00
even which active experienced developers are there on the other "side".  I think it is unrepresentative and biased to sound as if that really exists even, if any consideration is given to safety, robustness and security.
@_date: 2017-01-06 12:38:52
I talked about it a bit here  (1h0 offset) at venue last year.  But the above is probably clear enough.
@_date: 2018-10-10 22:15:50
the functionaries do not have visibility into the confidentiality, they're like miners they just assemble blocks of transactions and sign them.
@_date: 2017-08-05 09:12:13
They lack an irony meter.
@_date: 2017-01-21 16:16:26
Suggest to read the FAQ 
@_date: 2017-08-18 00:50:18
that's a lot of data :) what I meant is we could send a longer retransmit period so it could withstand say 7days outage or...
there's also ongoing discussion of adding consensus enforced UTXO snapshots to bitcoin protocol which would likely help as you could optionally use a UTXO snapshot and then stream from there, and UTXO is much smaller than blockhistory most of which is shadowed by later transfers.
@_date: 2016-12-21 16:45:10
transcript by @_date: 2016-12-05 05:09:34
Yes is talking about a soft-hardfork there, which has also been called a firm-fork or evil-fork.  The BIP and have been working on is one of these kinds of forks.  I think this kind of fork is more hard than soft, in the sense that users basically have to upgrade (or fork away).
An extension-block is more soft-fork like because it is opt-in, and forwards and backwards compatible for users.
@_date: 2017-01-21 21:30:11
This is pretty good analogy also for the reason that segwit creates an incentive to defrag UTXOs so recycling UTXOs  results in less dust UTXOs (less garbage in the analogy) which makes bitcoin scale better, because UTXO scaling is non-linear.
This explainer by is pretty good 
@_date: 2018-10-10 18:27:32
(More specific details to follow) 1minute blocks, likely around the same throughput as Bitcoin mainchain -- around 10x more blockspace but around 10x bigger transactions due to a lot more Zero Knowledge Proofs with ECDL based ZKPs for confidential transactions and confidential assets.
More federation members will be able to join later.
@_date: 2018-06-13 18:26:44
the authors appear not to have heard of BTFD, ie people buy when they think the price is lower than what they see as potential or fundamental value. of course they buy via tether and wire transfer! how else would they buy? also tether loads up in batches this is a known factor in how they administer it for some exchanges. they published an audit report I highly doubt it is fractional. also people are less likely to take USD out of crypto exchanges because when they do sell, they know it is slow to move funds in and out, so they are likely to hold the fiat on the exchange to have the ability to buy bitcoin at short notice later.
@_date: 2016-12-03 22:14:33
Actually the concept originates from 2011 bitcoin wizards IRC discussions 3 years before bockstream existed.  We implemented a non-backwards compatible version of it in the elements sidechain, which because it was a new sidechain, it didnt need, because malleability is a problem that has to be fixed for many smart-contracting use cases.
@_date: 2016-11-19 15:22:30
Happens with salvage of sunken treasure of gold coins worth lots.
@_date: 2016-12-24 09:27:37
oops you are right.  one lakh crore / ten kharab / one thousand arab.
@_date: 2019-08-22 08:53:20
well to leave no trace on the phone. people may not know but green wallet is designed so that all info about the wallet is encrypted on the phone and wiped on removal, eg if you get the pin wrong three times it's gone.  server assisted pin lockout.  temp wallet is in ram only if you power off the phone it's gone and does not get written even in encrypted format after timeout.  you have to watch it because if your timeout is very low you'll have to retype the mnemonic.  it's like incognito mode for a secondary or only wallet.  it's not so easy to use because you have to enter the mnemonic (12 or 24 word seed).  anyway that's what it does.  it's been there for a long time as a feature but a bit obscure and confusing to find, this change makes it easier to find and clearer what it does.
@_date: 2016-12-08 19:38:35
That's not very soft.  This is a soft-fork opt-in way to do it: 
@_date: 2016-12-04 19:30:34
Yes you can increase size via soft-fork see  using extension blocks.
In some ways segwit itself is a simplified extension block, and does some of the work towards enabling extension-blockss.
Like segwit an ext-block is opt-in and forwards and backwards compatible.
Note it is not without downsides because it does increase block size and can be done via soft fork, where a hard fork requires more agreement from users, investors, exchanges etc.
@_date: 2019-08-09 13:31:49
it is a curious phenomena that BCH and BSV are (rightly) more scared of each other than blockstream. low hashrate fork chains are protected not by hashrate but by other miner's professionalism.
@_date: 2016-12-05 03:46:07
Depends on definition.  But they could be activated in a soft-fork like way, so in that sense yes.
@_date: 2019-08-03 09:45:19
Bitcoin itself is very new tech to most people and confusing so probably a surprising portion of hodlers don't fully understand halvenings. However there is probably a weighting at least for newer entrants that higher investments are correlated with more sophisticated economic modeling and understanding to make analogies to other money tech (gold, precious metals etc). you would hope.  But markets can stay irrational for a while as people learn.
Some portion of the market volatility comes from day traders playing with leveraged derivatives and alt speculation but that's just volatility and doesn't affect the long-term value thesis of Bitcoin.
@_date: 2016-12-31 06:33:34
Aka cypherpunks write code.  
@_date: 2019-10-15 23:39:23
yes see ABcore on android  (also by blockstream chief architect Lawrence Nahum you probably need a 400GB sd card though or an android phone with that much storage)
@_date: 2017-08-16 08:44:35
re upsell bitcoin / blockchain sat services 
@_date: 2019-08-21 23:30:16
sats logo credit to  
@_date: 2019-10-16 15:44:42
actually email is optional, but you need it for 90day recovery.
otherwise its 12mo recovery.
but yes the hw wallet is still 2of2 +timelock or 2of3 (and so has the email option for timelock pre-signed recovery transactions)
we are also switching to CSV soon which will remove the timelock emails altogether.
note the recovery emails are encrypted
@_date: 2019-10-16 01:27:12
true. 
to use ABcore on the phone as the SPV bitcoin node for blockstream green bitcoin wallet to use you need unpruned fullnode.
@_date: 2017-01-22 09:37:34
It is by design an opt-in fix.  You can upgrade if you want, or not.
@_date: 2019-08-21 23:42:31
@_date: 2016-12-24 07:58:16
one kharab or ten thousand crore or one hundred arab rupees!
@_date: 2019-10-16 01:40:50
use google auth on another device. don't enable email if you don't want to.
@_date: 2019-02-26 13:04:32
I do. Probably tweeted about it at the time, buying the hearn rage quit Dip ;)
@_date: 2015-08-18 01:00:52
@_date: 2015-08-17 06:28:26


That's not how that happened.  Gavin did some tests and proposed 20MB, someone pointed out a basic arithmetic error in his calculations, so it became 8MB after that correction.  


People asked for a proposal that would keep up with network improvements.  The number in BIP103 comes from cisco's figures for yearly bandwidth improvement.  Unless you want to weaken Bitcoin's security and create a centralisation problem... anyway he provided what people were asking for.  It's also not the only proposal.
As I said a few times I think flexcap is probably the best proposal because it scales for demand while being economic rational - miners pay for larger blocks but make a profit doing so by collecting higher fees.  That is good for miners too as large mostly empty blocks lead to zero fees.
But my other proposal is step to 2MB now, 4MB after 2 years, 8MB after 4 years to create space for lightning etc R &amp; D and after that re-evaluate what can best happen next.  20 years is way too far in the future for an exponential 40%, the future is uncertain and we'll know a lot more about lightning and sidechains and other scaling/extension mechanisms by then.  It may easily be that no other (size related) core changes are necessary for example, because scaling can happen via extensions.


There are a lot of proposals, multiple that are better than Gavin's BIP 101.  If you want to give credit, one could gracefully say Gavin helped create a focus on scaling.  I think it's discourteous in the extreme to say people didnt give an inch on scaling.  They did 99% of the work on scaling!  As has been explaining Bitcoin wouldnt even scale to 1MB on a CPU and memory basis if not for the work and did.  The work on libsecp256k1 was 1000+ of hours of algorithmic optimisation - the lib is now something like 6x faster than hand-coded openSSL assembler and validation actually uncovered bugs in openSSL.  That makes a lot of difference for making 2-4-8 MB blocks even sensible to run on a CPU basis for latency of verification (latency affects orphan rate which makes mining unprofitable).  Easy for someone like Gavin to come in at the end and make a fuss about a constant - it was the 1000+ hours of optimisation work that makes it even possible - and irony *not* lost on the people who did the actual work.  (Gavin has barely made contribs to Bitcoin in 1.5 years with bitcoin foundation funding crisis and IBLT work and public speaking - dont take my word for it check github.  Mike has 3 contribs total and one indirectly led to the leveldb fork bug that fixed.)
@_date: 2015-08-18 00:43:47
Whoever implemented noXT would not have done it if not for XT.  Why is it good for XT to be written to bypass review process and endanger Bitcion, but not good for noXT to be written to oppose that view.  You seem conflicted.
@_date: 2015-08-18 06:46:47
That is funny.  But I think presumably the Bitcoin-XT people would have to abandon the fork as too dangerous for Bitcoin.  Maybe.
Also they might be able to tell because none of the blocks created were over 1MB?  That would be indication that there is nothing to worry about?
@_date: 2015-08-24 21:06:50
SPV mining makes this advantage self-evident and shows that miners are willing to take short-cuts and this caused a network breaking fork 4th July BIP66 roll out by accident, only recovered by manual intervention.
Also mining is already quite centralised.
I think you should talk to and about your conclusions on simulations.  They think you are drawing the wrong conclusions.  The point is you want at practical level a level playing field between miners at say 1% and 10%.  Fair?
This kind of logic is not good for security reasons "miners aren't generally malicious" though as has been saying.  It's possible to argue security down through generally reasonable tradeoff arguments until the security of the system implodes.  There are trigger points.  And we are not far from them.  As I say security is already way to centralised from what Satoshi was imagining.
We're working on improving this.
But it says scalability changes we make should be pragmatic but also safe.  That's why I proposed 2MB now, 4MB in 2 years, 8MB after 4 years and then re-evaluate with better knowledge of how decentralisation has improved and how scalabillity has improved (both in Bitcoin and in lightning and extensibility frameworks).
You cant forcast weather 20 years ahead with any accuracy.
You dont want to have to rely on softforking backwards to fix later because people bake in network assumptions into their business model.
If you overshoot the network becomes insecure, and if you undershoot it becomes bottlenecked for scalability.
@_date: 2015-08-16 14:09:50
Most of the scaling work over the last year or so was done by and eg libsecp256k1 
I dont think this fork has any perf related features.
@_date: 2017-11-17 08:47:19
in physical coins this is called debasement - mixing cheap metals with gold. it has happened a number of times. not usually with holders approval but by governments.
In bitcoin you get free instant assay so this wont happen without your optin.
@_date: 2017-08-22 00:05:38
more than similar - bitcoin uses hashcash with a minor and obvious extension - to make difficulty adjustable in fractions.  I considered doing this at the time of designing hashcash but figured it was simpler for the application of anti-DoS stamps to use power of 2 as then the difficulty is human readable.
For bitcoin you need finer grained control
That doesnt make it a different algorithm.
@_date: 2019-02-25 20:48:29
I already have plans on how many more BTC I can buy. Even more at that price.
People forget what it was like to buy in the previous cycles.  No one could say for sure unless you were bullish to buy sub 200 after correction from 1200.  I bought some at 190. (And at some higher prices before and after).
What makes people think this cycle is different - the main difference is perspective of being in the middle of it rather than looking back with hindsight.
@_date: 2017-11-22 17:16:48
see elaboration: 
@_date: 2017-11-04 05:11:10
I would have posted here too but last time I got modded apparently it is against moderation policy to post trading offers. the link is 
plus you'd think the B2X and BCH buyers are over there, but no buyers in sight.
@_date: 2017-11-04 17:16:55
I wanted to, but Roger would not do the group buy.
@_date: 2017-11-17 08:47:44
and what's my agenda? a more valuable, and scalable bitcoin - by not approaching things in a simplistic and clumsy way or via politics. bitcoin and how to scale it is bleeding edge technology with security implications.
@_date: 2019-02-25 20:49:56
If you're always buying steady it's called dollar cost averaging.  If you buy more when prices fall it's BTFD.  I did say I was a permabull.
@_date: 2015-08-18 01:00:14
Bitcoin-XT is both a hard-fork for full nodes and a soft-fork for SPV nodes.  It gives SPV nodes no choice and lies to them about what blocks are valid by overriding their choice without them opting in.  Mike spoke out against soft-forks in his recent blog post, however XT is doing a soft-fork on XT.
I did not write noXT.  I did not release XT either which is what triggered someone to devise and write noXT.  I did predict that something like that would likely happen and warned Mike &amp; Gavin of that risk.  Sure enough here we are.  Software deployment "wars" have you know two parties.  Not everyone is cool and level headed and collaborative, or you know we wouldnt be here.
As I said none of this is collaborative and I'd really wish people would be collaborative and not engage in this whole thing.  But to be clear it was Mike &amp; Gavin that started it over everyone else's advice.
@_date: 2015-08-17 13:58:28
Yes this is an interesting topic.  Part of the problem is XT is not completely a hard-fork.  It *is* a hard-fork for full-nodes, but it is a soft-fork for SPV nodes - so it silently attacks and converts bitcoin's SPV clients into being exposed to XT network-split failure.  If it was purely opt-in (for SPV clients also) that would be fairer.
I think there was one proposal that would maybe prevent XT, which is to change Bitcoin full nodes to pretend to support XT but reject XT blocks.  Someone made a patch to do this over the last few days I saw.  Maybe there should be a campaign to run "noXT" nodes if we wanted to adopt the same level of maturity as Gavin &amp; Mike about protocol design &amp; review (ie start a fork war instead of working constructively).
That would work because then XT would trigger early, but be a small minority of hashrate and so it's users would lose money.
It's quite close in effect to what happened with the 4th July fork where miners were SPV mining (also indirectly lying about their supported version, which wasnt known).
Here again you would not be able to tell what percent were lying about supported version.
Maybe I should go run one and put my miners behind it.  Or a pool offer it?
There may be other ways to prevent XT network split risk, though what makes it challenging is that it silently soft-fork attacks Bitcoin SPV nodes and it is harder to defend against a soft-fork, because SPV clients validate very little data.
Maybe one could upgrade bitcoin SPV nodes to automatically recognise and ignore XT nodes, via some soft-fork support but that is a little slower because of the need for soft-fork upgrade vs just network hash rate upgrade (miner soft-fork vs node soft-fork).  Or someone suggested bitcoin nodes could refuse connections from XT.  (Or maybe teergrube them to increase their orphan rate).
None of this is especially constructive.  I am disappointed Gavin and Mike created this mess.
@_date: 2015-08-17 03:22:20
There's also plenty of scope for massive double-spending to occur leading to collapse or MtGox or price impact.  People should be looking at the 4th July fork for a preview of the kinds of things that can go wrong by accident.  Here there is even more risk as there is controversy.
@_date: 2015-08-17 05:44:47
I dont think you understand the risks of a consensus failure.  Giving a free choice to opt-in or out is perfect - eg sidechains or extension blocks.  But if this goes wrong it may lose your Bitcoins.  There is non-trivial risk of it actually going wrong as the 4th July fork would have absent manual intervention.
@_date: 2015-08-16 19:24:36
It's hard to say but from current climate I think there is a real danger of losing multiple people who have kept bitcoin secure, maintained and developed bitcoin over the last 4 years.  Reddit can be hyper negative so while people talk about anti-fragile and honey badger etc that is actually smart dedicated people.  Reddit lately has been alienating and discouraging Bitcoin core participation, if not by intent, nevertheless by effect. Try empathizing with developer who worked 12hrs/day through a weekend on Bitcoin security defects unsafe for public disclosure.  Not everyone takes a torrent of insults as encouragement to continue. 
People somewhat work on FOSS projects for the kudos, feeling of delivering value and appreciation of the users.  A sense of community, shared values and meritocracy rewarding good work by recognition can help a positive feedback loop.
If an informed technically sound decision that has widespread support is made no one will have a problem.  And some people are genuinely trying to progress the tech, see the range of BIPs and and flexcap proposal.  Bypassing review process for a security design question is divisive and may lose core contributors that bitcoin currently depends on.
Don't kill the honey badger.
@_date: 2015-08-16 16:39:37
Not on this thread I didnt !
The tweets clarify that it's possibly Satoshi, I think consistent with his views IMO, and not completely unauthenticated - it was from Satoshi's old vistomail address.
@_date: 2015-08-18 00:40:41
That's the point - bitcoin-XT without widespread consensus is risky.  Gavin and Mike were warned repeatedly that it is unsafe, that 75% is a dangerously weak parameter, and that people would probably find and some would be tempted to run counter-measures like noXT (not sure if that was thought of since then or was worked on before).
It might surprisingly to your assumption actually be better if Bitcoin-XT stops, and it's authors return to collaborative process so that we can have a sensible design process without this threat hanging over normal collaborative working.
@_date: 2015-08-17 13:11:08


Thats  not the correct sequence.  Gavin pulled released XT a few days.  The BIPs were released months ago.  Core devs have been working on memory and CPU scaling (1000s of hours of actual rocket science work, not constant changing) for &gt; 1 year.
Like I said if you want to give credit you can say Gavin helped focus effort on the scaling issue.


I think blockchains are inherently not great at instant clearing transactions.  high latency between blocks and high variance (10min average, 20min outlier is not infrequent or worse), and for confidence you need multiple confirmations.  Lightning gives instant final settlement in ways that a direct blockchain basically can not, no matter the parameters - it's due to mining convergence and orphan rates driven by propagation/validation latency vs block interval inherent to the hashcash poisson process.
See also timestop proposal to handle bursts for transactions with an expiry.  (Lightning reclaim transactions have an expiry, while relying on relative check lock time verify (RCLTV), once the clock is started they can expire if blocks are full eg because of a DoS and then you could lose money.  Timestop makes a new mode for RCTLV where time stops (does not increase in block intervals) for any blocks that are full).
You should read flexcap, that is actually doing something more interesting than tweaking parameters.  (Making it so that blocksize can auto-grow within economically rational limits plus a safety envelope, by paying for blocksize increases and still making a net profit by collecting excess fees that otherwise would not fit).  
See [2] flexcap propoal by Greg Maxwell see post by Mark Freidenbach
[3] growth limited proposal for flexcap by Greg Maxwell
@_date: 2015-08-18 00:42:16
What you are saying is factually inaccurate and not the sequence of events.  There were 4 BIPs and a dozen more proposals under active review, in most cases for several months before this fork was released.
@_date: 2019-02-04 06:08:02
myth, never happened.
@_date: 2015-08-16 19:41:32
Everyone has their limits of cheerfully accepting abuse while providing 1000 hrs/year of volunteer effort for the benefit of a community that reading reddit you would have to assume wants core devs to quit. You might be surprised. Speaking for myself I have to not read reddit for days at a time to avoid being discouraged. 
I am not sure why Mike &amp; Gavin, who I talked to both of at length would not want to do what is best for Bitcoin.  When there are multiple proposals most of which I consider better than BIP 101 why do something so divisive.  Even if BIP 101 was selected or a variant of it that is just better done within the technical review process.
I would be very sad if Mike and Gavin broke Bitcoin.  I might try to help fix it, but some types of failure are likely irreparable which is why I think they should return to acting collaboratively.
@_date: 2017-11-15 03:45:17
yeah it's very easy to see  ... has no bitcoin check-ins 
@_date: 2015-08-23 22:32:05
Oh noes return of the phantom deleting post attack.
ps I recommend always quote what you're replying to with &gt; like


@_date: 2015-08-17 05:43:00
Instigating discussion is fine.  I think bitcoin-XT has gone quite a bit beyond that and is actively soliciting miners to run it which then creates a ticking clock until the network forks or with significant risk actually breaks instead.  I am having trouble seeing any way in which that was constructive.  All the patch does is change a constant - he could create it as a patch to illustrate the BIP as others have done, without lobbying people to run it.
@_date: 2015-08-17 06:58:55
This is normal security defect procedure in any security application.  See security disclosure on bitcoin-dev for details of recent major one.  It was unsafe for public disclosure because until he fixed it, it could have been abused to steal people's Bitcoins.  Keeping people in the dark about 0-day security defects is for the protection of your Bitcoin.
@_date: 2015-08-18 06:41:24
You might find the notBitcoinXT project readme interesting 
Sounds more reasonable than it is, but it was perfectly predictable something like this would happen, multiple people warned them of sorts of things that might be expected and Gavin &amp; Mike went ahead with the fork anyway.
@_date: 2015-08-17 02:23:13


The other BIPs are at a similar stage of development as BIP 101 - we could as easily do any of the BIPs at this point.  And there would be a lot more time to do that if people were not having to spend cycles counteracting a divisive fork.
@_date: 2015-08-18 05:33:07


There is no normal bitcoin mechanism for hard forks, because there has never been a planned hard-fork.  You maybe thinking of soft-forks which are relatively different.
I guess the point is, Gavin &amp; Mike hope that people who disagree with XT, when faced with MAD as you put it, that they have to kowtow to the threat and change against their wishes.
NoXT turns that around and uses the same strategy against the people who proposed to force their view via MAD.
It's quite interesting the degree of animosity to the exact same strategy.
Neither strategy is advisable or sensible, and I have been on record for months trying to persuade Gavin &amp; Mike from doing it.  But there is some karma in the fact that whoever wrote noXT did it almost immediately after Bitcoin-XT release.


I think you're misunderstanding what's happening.  There are other BIPs, their authors are not rushing to bypass the review process and force their version on users, nor try to create publicity drives for adoption.  Why is BIP 101 special and it's fine if they do it, but no one else should?  Why is it suddenly objectionable if someone who disagrees uses XT's own tactics against it.
It's not BIP 101 that is objectionable, it's the abuse of MAD logic to promote it.  You dont want to use such logic in Bitcoin, it's too dangerous.  What should be done is to collaborate in the review of proposals and work together to deploy it through normal channels.
I do not think bitcoin XT has widespread support - it has the opposite, most of the technical community has been advising that it is a really bad idea to deploy it this way, and that other BIPs are safer or better in various ways.
@_date: 2017-11-22 15:50:03
Well I have skin in ordering these 
@_date: 2017-11-22 21:28:30
simulated vs running.
@_date: 2015-08-17 04:03:35
The proposed process is pretty reasonable.  Technical review of proposals.  See also  technical conference on the topic.
All far more constructive and likely to result in a safe, secure and scalable outcome than the really ill-advised step of starting fork wars.
@_date: 2017-11-15 07:49:01
Who do you speak for? Bitcoin is not a company, I has no spokes person just users, contributors etc.
@_date: 2017-11-22 15:02:02
it is not bitmain. and it is completely real 
@_date: 2015-08-24 18:50:01
OK you did ask:
Block creation is n log n, once utxo doesnt fit in ram there's a cliff; exponential utxo size (as BIP 101 doesnt have UTXO compacting incentive like flexcap) will imply log scaling.
I know you like to say fix things as they arise, but the people that are doing the actual hard work scaling and fixing bitcoin (libsecp256k1 and the huge security defect they fixed without your involvement) are saying the other BIPs are better and they need a few weeks to work on the flexcap params.
I am happy to have a conference call with you and eg the people who signed the 7 company support letter and have a balanced discussion.
Or to have that conversation in Montreal.
Should we do this?  Gavin, do you want to schedule it?
@_date: 2017-11-22 15:55:49
no. new miner unrelated to bitmain.
@_date: 2017-11-23 15:46:58
I think that's generally a good idea. see also drivechain.info lightning is also interesting because it can be shared across sidechains and provide fast relatively trustless transfer, and transparent conversion (subject to lightning p2p network liquidity)
@_date: 2015-08-18 06:39:31


Why would they call for a referendum when there was already a design process months underway with competing better proposals?


This is incorrect - as a user you have no vote, it is only miners that vote.  Secondly SPV nodes dont even get to chose - XT is a miner forced soft-fork changing the rules without consent of SPV users, which is most of the users.


I guess NoXT is probably something like a protest vote objecting for an unconstitutional referendum?


How do you know it will not be contentious.  I cant see myself or anyone else suddenly agreeing it's a good thing just because hashrate of some miners.
I think what you really mean (or certainly what Gavin means because he said it) is that people will to avoid risk of a fork failure be forced to adopt Bitcoin-XT, even if they strongly disagree.


No it's a really low bar.  Previous soft-forks used 95% as a trigger.  Even BIP66 which was completely uncontroversial accidentally forked because of the unexpected factor of SPV mining which wasnt realised.  It was saved by manual intervention.
Given that Bitcoin-XT is self-evidently controversial, the BIP66 issue should be a warning of the inadvisability.  Other than the noXT  patch other things could accidentally go wrong.
@_date: 2015-08-17 13:19:25
It was posted on bitcoin-dev by Pieter Wuille as I said.  You could have googled that: 


I think it's by evidence accurate to say that no one (who had any intention exploit it) knew as no one's money was stolen which would have been detectable.
There are a very small group of people in the know, I dont know exactly who knew, because my policy is not to be in the loop unless I am helping fix something - if you are not part of the small group of 2-3 fixing it, it is probably better not to know (Gavin and Mike are not part of that group BTW which may have relevance to maintenance and security of XT, if that group do resign).
There was talk of applying for a CVE number, not sure if that was done. 
@_date: 2017-11-28 10:14:03
I saw some other halong miners at another location maybe a week earlier.
@_date: 2015-08-16 19:28:10
@_date: 2015-08-12 18:43:54
Yes!  sidechains have no natively mined coins, the native coin is Bitcoin, that can be moved between main chain and Bitcoin.
Sidechains are like (Bitcoin centric) internetworking for blockchains.  More features, more independent and faster innovation, more interoperability.  I think sidechains are a good thing for Bitcoin utility, demand and value.
Sidechains are Bitcoin extensions that build on Bitcoin and Bitcoin's network effect.
@_date: 2015-08-23 22:19:40
the cache will only be warm if miners follow the the default protocol.  As you know selfish mining and other attacks do not follow the protocol, and are not defendable against using consensus compatibility.
Therefore while that is good for the normal case, it doesnt particularly help in the case where miners use more profitable strategies.
It is not a hypothetical that miners would use different strategies: the 4th july fork on BIP66, only fixed by manual intervention of devs, was because miners started "SPV" mining in search of lower latency validation (ie by disabling validation or trusting other people to validate).
So clearly they can easily induce at zero cost blocks to take longer to propagate: just fill them up with pay to self transactions which will not be in the utxo cache.  Miners (or groups of trusting miners like the majority doing SPV mining over the last few months, which seemingly are the majority) therefore can gain a different advantage by increasing the blocksize.
I'm puzzled why you would say transmission delay is of no import given that you yourself spent much time working on IBLT which is a relay-network like protocol.
I maybe missing something, or perhaps you are focussing on a different case, please elaborate if so.
@_date: 2015-08-07 13:18:49
There are some comments in the sidechains white-paper about interoperability, though they may not have been very fully explained.  I do think interoperability and an open non-proprietary technology base are key.  You could view 2wp sidechain transfer mechanism as an "internetworking" mechanism for blockchains, and bitcoin as a standardised/reference fee currency.
I'm not sure if it's clear but in principle you could peg to move other things between chains.  Eg you could move an issued asset, or a financial instrument implemented as a smart-contract in one sidechain using it's scripting language, and peg the instrument into another sidechain to move it there.  And then write a contract in the second sidechain using the transferred instrument or asset from the first chain as a building block as part of another smart-contract.  
The point is an open interoperability mechanism to allow instruments and contracts and assets to be moved between chains.  Obviously more work has to be done to get there but this is how I view the sidechain interop potential too.
I agree with the comments about Bitcoin being the main secure chain, with most mature code, most hashrate security, most value transacted, most accumulated expertise, biggest network effect, deployed base etc.  Dont fight the Bitcoin network effect :)
@_date: 2015-08-18 00:44:19
No incorrect.
@_date: 2015-08-15 06:43:43
used 17% because of this cisco broadband report  which gives that as the empirical last mile broadband speed growth over some years.
Nielsen's is more hand wavy I think - cisco is using real numbers looking backwards.
The other thing to keep in mind is end2end achievable throughput is more important than last mile bandwidth in isolation (not much use having 100mbps to the PoP if the bandwidth has massive contention and you can only get 10mbps end2end in reality (for example).  Also latency once we have network compression like IBLT, fountain codes, or relay network or something like it integrated with Bitcoin.  Already a big % of mining hashrate is using the relay network.
@_date: 2017-11-22 15:55:21
it's a real photo. the logo is photoshopped on.
@_date: 2015-08-23 22:28:41
Hi I think you are considering CPU and RAM on average case.  But miners do not have to follow average case if they are optimising for profit, or attackers if they are trying to DoS or disrupt.  There are worse case for CPU and RAM than average, eg as evidence even by accidental claiming of 1MB of "stress test" dust with much CPU to validate.  Relay network crashed from RAM exhaustion and had to be repaired to defend.
This is not hypothetical that miners would diverge from general case.  You cant keep Bitcoin secure by downplaying easy attacks.  You cant say miners wont try alternative strategies, because eg look at 4th July fork.  Miners are running custom code, changed not foreseen configurations eg SPV mining.
I know it's tempting to say be pragmatic and assume general case but Bitcoin does depend on all these complex and somewhat fragile game theory things that we are still learning about the attack limits on.
Yes meta-incentive remains, but if there are easily exploitable and fixable DoS amplifiers I'd sooner see effort put into fixing them.  Seeing PoW tested and found wanting leaves Bitcoin in the unknown so we should try to fix what we can incrementally so we at least have a best effort to not end up there by default.
Note some of the CPU and memory scaling characteristics are non-linear with block-size.
Hope that's constructive.
@_date: 2015-08-16 17:28:54
We dont know if it's Satoshi or not, but it is from an email address known to be previously used by him.  To me what it says is consistent with what I would think Satoshi's opinions would be here.  Anyway I like the comments and think they have merit regardless of whether Satoshi wrote them or not.
I am supposing the focus on whether Satoshi wrote this or not, is more because of Mike Hearn's fairly frequent use of Satoshi quotes in the XT writeup and other forum posts.
@_date: 2015-08-24 00:04:14
Hi I think it would be better to focus on what users, companies and miners want in terms of Bitcoin ethos properties.  I say that because it is not obvious how the network protocol and parameters interplay to assure security of the ethos properties.
I dont think we'll know what users, companies and miners think without a presentation of balanced information on this.  We (technical people) need to do this.  I dont think anyone has really tried.
This is all highly complex and even people designing BIPs are still learning new things about limits of and new defences for Bitcoin consensus.
If you believe in and value permissionless use of Bitcoin and policy neutrality I dont think what you're saying is actually good for your own interests or users interests or network security.  Many users wont understand at all, and many companies also.  Consensus is complicated.
Either way the safest and fastest way to upgrade the network is for everyone to work together.  The network might really have problems if a 75% activation deployment does not go smoothly.  There's no accurate way to understand what users want particularly if you focus on technical parameters far removed from what users actually care about.
@_date: 2015-08-16 16:45:03
Maybe, but why try to push the technical review process out of the technical merit based process?  Just creates unprofessional image and creates needless controversy.
  As I recall previously said he'd be equally happy with BIP 101.  Now we also have BIP 103.  There is also and flexcap.  Isn't this an attempt to bypass a technical merit based review process?  How does that help Bitcoin?  I think people should be constructive and work towards improving Bitcoin in a constructive and mutually respectful way.
@_date: 2015-08-17 01:55:49
Sorry I had BIP 100 (Jeff) and BIP 101 (Gavin) BIP numbers reversed.
@_date: 2017-11-16 01:23:08
maybe we can consider it a feature. if gold atoms were subject to political change arguments, it would be less valuable.
@_date: 2015-08-18 00:30:57
This is not a blockstream blog post or press release - we individually participate in Bitcoin the same as many people at other companies - like Jeff, Gavin, Mike (yes Gavin and Mike have options and/or are paid by companies too from what I heard).
I dont know if you noticed but I proposed the same growth rate as Gavin, but on a shorter time-frame: 2MB immediately, then 4MB after 2 years then 8MB after 4 years, then stop auto-growth and re-evaluate after we've seen results of lightning, sidechain etc R &amp; D.
It is the duration more than the growth rate, but I think that 40% is too high to run for a really long time; more comfortable with 4 years because 8MB as a maximum for auth-growth within 4 years is less likely to cause immediate problems.
@_date: 2015-08-16 15:53:48
Note Mike Hearn, while I presume he is a British national, lives in Zurich.
I think Gavin and Mike have received shares/options and consulting income from some Bitcoin companies.
But my main argument is XT as a fork disregards other probably better proposals, and is not constructive.
@_date: 2017-11-16 13:05:34
@_date: 2015-08-18 06:58:12
There are multiple better BIPs that have been proposed, if that was your question.  Gavin even said he supported BIP 100 if it would win the design process.
@_date: 2017-11-22 21:29:44
@_date: 2015-08-26 06:27:30


There are better designs that support bursting.
You're a miner right?  (toomim mining I recognise from bitcointalk) so I think it's fairly clear that for supply and demand reasons if blocks are currently &lt; 1/2 full average and about 1/2 of those transactions are &lt; $1, then if the blocksize is jumped to 8MB the network will be overcapacity by 16-32x.  Now if there is an excess of supply, price falls, ergo fees will drop to zero basically.  If you're a miner this is maybe not to your advantage.
Hosted wallet companies may want free fees.  I'm not sure if you do.
Gavin has said some keynsian subsidy things like he wants to subsidise fees by increasing the blocksize.
Maybe come to the  conference or watch the live-stream they're trying to setup and participate via IRC.
I think it should be uncontroversial that multiple BIPs be reviewed and tested, simulated, the best one selected and deployed.  That's what people are working on.
@_date: 2015-07-09 23:45:38
There's quite a lot of information in the lightning paper.
There's also another paper by Christian Decker on duplex micropayment channels.
Main point is people should *stop* panicking, people are working on bitcoin scaling.  People coming on reddit demanding massive blocks immediately, in some state of anger because they are severely confused and think it's an obvious and trivial change,  doesn't make sense, won't happen and would break bitcoin if they got their way.  This constant noise about stupidly large blocks is security protocol design by lynch mob.
@_date: 2015-08-18 06:44:08


I did propose two other solutions.  The extension block proposal (which is soft-fork and opt-in) I think most people agree that is clearly nicer as everyone has a choice, and there is no network split risk.  Only downside is software complexity.
I also proposed a simple compromise: 2MB immediately, then 4MB in 2 years, 8MB in 4 years and then re-evaluate what to do next based on experience with how well lightning, sidechains etc work in practice.  4 years is a really long time in Bitcoin, and I think racing off into the future with an 8GB block is inadvisably risky.  Very hard to predict 20 years into the future and likely wrong in one direction or other with deleterious effects.
@_date: 2015-08-18 00:46:23
If people get to vote for XT by running it, are others not allowed to vote against it by running noXT?
It was Gavin and Mike who decided to bypass the good faith effort to find the optimal solution and rush to lobby companies and miners to run software.  I would place the existence of XT and the fact that no doubt some people are running noXT on them squarely.  In fact I warned them personally that something like this would surely happen.
I didnt do any of it, I warned them to think ahead of peoples reactions and human factors.  They chose to ignore warnings and advice and the obvious happened.  I didnt have anything to do with noXT, I'm not running it either FWIW.
@_date: 2015-08-30 15:41:12


No they are significantly different.
@_date: 2015-07-09 21:31:09
Sigh.  So many alarmist and completely uninformed posts on reddit about block-size.
I guess does not know that lightning is a proposed integral p2p write cache layer for bitcoin where every transaction is a valid main chain transaction, just the incentives are setup that it is not necessary to post it to the main chain.
@_date: 2015-07-09 23:55:40
You appear to be.  Did you have a point?  I think a 2MB block will see us through.  blocks are 1/2 to 1/3 full (absent obvious spam) and of those 50% are &lt; $1 transactions.  2MB blocks would be 4-6x headroom.
@_date: 2017-11-06 00:28:07
moon clause?
@_date: 2015-07-10 04:01:51
There's a difference between a hard cap and miner policy.
@_date: 2015-08-17 02:34:28
Actually what happened is this.  I kind of saw the writing on the wall that MtGox was in trouble so I withdrew all coins quite a bit before the crash (from previous technical issues and withdraw issues).  Then I did some arbitrage between btc-e and bitstamp.  Then someone started professionally arbitraging that pair with investor's money, and the margin went out of it.  So then I did another type of arbitrage between bitstamp and mtgox, that doesnt require withdrawing the USD.  I put a smaller amount of bitcoins back into MtGox with the knowledge that this was risky.  I made 20% return, but then lost those coins.  So it was something I figured I could afford to lose, but I was disappointed how soon it was lost!
@_date: 2017-11-05 07:13:20
bitPico is the guy who time-wasted and did not buy B2X offer.
@_date: 2015-07-01 21:08:01
Maybe worth making this point to Joseph Poon, apparently he is writing a revised version of the paper.  For him to explain how smart-contracts work on top of lightning clearly in the paper would be useful.  I do not believe it was mentioned in the previous paper though I may have missed it.  
Sometimes you get this problem with advanced concepts - people think something subsidiary is obvious and dont mention it.  While in fact it's not necessarily obvious or being a key and interesting use-case should be documented really to make the case for the tech in it's white paper.
@_date: 2015-07-10 04:28:08
Centralisation is not a vague concern - Bitcoin doesnt make sense it if it's centralised.  One of bitcoin's main distinguishing features is it's policy neutrality.  Secondly we need a good portion of the economic interest of the network to run full nodes they rely on (if their node tells them the payment is OK, they accept it; otherwise not).  Increasing blocksize increases bandwidth, reduces economically dependent full nodes and hence security for SPV clients.  Some people seem to assume everyone can just use SPV with no security side effects.  This assumption is incorrect.
@_date: 2015-07-09 23:38:05




Have you looked at github lately?  While people on reddit have been trying to manufacture a sense of misplaced anger while being largely misinformed, and how bitcoin scaling works, people are coding on these things.
@_date: 2017-11-16 13:05:16
Well Bitcoin is a virtual object who's properties are maintained by all the users who track that software compatible version. I don't think it's that dissimilar because if you change the network it is automatically ignored by the users software so really the only way to make a non backwards compatible change is for a lot of  users to opt in.
@_date: 2015-08-17 02:10:42
Well how would that someone take over Satoshi's email on demand to make a post?
I think it would be better to express arguments based on technical merit not quotes.  But it does seem to appeal to some people.
@_date: 2017-11-22 15:01:39
 yes it is real as a heart-attack. I've seen them running in person.
@_date: 2015-07-09 23:34:36
If lightning allowed 1,000 or 10,000 tx per on chain transaction, it'll scale the same as a 1GB or 10GB block, which is infeasible right now.
Who said 1MB was going to last forever - we'll probably have say a 2MB limit by end of year.
@_date: 2017-11-04 15:23:50
He agreed to a trade with Charlie Lee, Tuur Demeester, Alex Morcos &amp; Ben Davenport of 1000 BTC.  But he went quiet and would not take the group buy offered by Trace Mayer for 25k BTC.
@_date: 2015-07-09 23:52:38
Well riddle me this, if lightning offered a 10,000 transaction scale advantage over bitcoin layer 1, would you concede that it will serve more people?
We cant change the blocksize to be 10,000 times larger (ram, CPU, disk IO etc will all fail as well as bandwidth saturation for nodes etc).
Wherein is it written that we could not increase from 1MB to 2MB when we hit 100mil users and that starts to be a problem in 5 years time or whatever?  When bandwidth available is higher, decentralisation issues are improved 
and reddit trolls jumping up and down about 8GB blocks have become bored and moved onto other things?
@_date: 2015-07-10 04:38:00
So as I understand it you have a comp sci PhD?  Or lecture in comp sci presuming you're the same J Stolfi?  How about helping out with some of these complex things?  Or have your students help out.  Saying whereas things are complex, doesnt help find solutions.  Yes Bitcoin is complex and scaling Bitcoin is complex.  What should we do?  Give up?  Change the block-size to unlimited now and watch what happens?
@_date: 2015-08-16 17:16:52
Yes, but none of that requires active advertisement, popularisation or solicitation of miners to run something that is under active public review between collaboratively competing alternatives.
I think it would be better for Bitcoin if people would act collaboratively with mutual respect to do what is best for Bitcoin and Bitcoin users.  If each technical alternative would run a premature popularisation and miner adoption campaign it would not help the review process to find the best approach.
@_date: 2015-07-01 00:15:15
Tried to elaborate with a related question here:
@_date: 2015-08-16 20:00:04
Thanks about loudest voices on reddit not being representative try to tell oneself that. It is not just reddit, some people have invaded bitcoin-dev list and swamping it with FAQ level policy arguments plus much vitriol. I kid you not that people who contribute to core (a lot) have unsubscribed.  And bitcoin media tend to amplify the negative, as news often does. Plus Mike and Gavin seem to have put more effort into promoting XT with media, blog, podcast and lobbying companies.  90% of people arguing for block-size increase it seems to me have no idea it's a security tradeoff.  Or are angry because they are confused that it is a simple obvious change.
@_date: 2015-07-09 21:31:42
Correct.  doesnt seem to know what he's talking about.
@_date: 2017-11-15 03:43:54
yeah I really do not speak for anyone other than myself.
@_date: 2015-07-10 14:34:28
No that is a disastrously bad idea (split Bitcoin in two).  About as much fun as a disorderly exit from the eurozone, something universally feared by economists.
The simple thing to do is create an 8MB sidechain - then you get what you want, in a way that is opt-in and people who think 2MB is a more sensible increase can try that.  There's no need to force a one-size fits all compromise on everyone that is neither optimally secure nor optimally scalable.
@_date: 2015-08-16 19:51:18
People are at their limits of tolerating the abuse torrent and in parallel policy attack from Gavin and Mike.  Prepare to be unpleasantly surprised.
I don't think it is an unreasonable ask to Gavin and Mike to work with the technical community with good grace.  Assuming you are right and refusing to consider alternatives or accept peer review is unscientific and neither of them are while smart people in their own right, the brains of bitcoin protocol analysis and design.if everyone else is saying another proposal is better what's wrong with working on that. Earlier Gavin said he would be equally happy with BIP 101 and now he's trying to bypass consideration of that.
@_date: 2017-11-25 08:11:36
I saw a different demo of several units a few weeks earlier. This looks like another demo 
@_date: 2015-07-10 04:39:59


Because while lightning tx are bitcoin tx, they do not have to be sent to the main Bitcoin chain except to reclaim funds in event of a permanent hub failure.  During the lifetime of a hub many transactions can be exchanged.  Rusty offered the analogy of thinking of hubs like ISPs in the size and expected number of them (1000s).  Maybe we can make it even more p2p with some additional ideas.
@_date: 2015-07-02 11:26:04
ELI5: Lightning makes bitcoin faster and better.
Lightning is a (coalescing) write cache layer for Bitcoin. it enables massive scalability, secure instant clearing transactions with lower fees.  It preserves decentralisation because lightning transactions use much less bandwidth as they are routed like the internet, point to point; not broadcast like Bitcoin layer-1.  It retains fees for miners, because eg 1000x as many transactions paying 1/100th size fees = 10x miner revenue for anchor transactions.  It doesn't remove the need for bigger blocks, but it gets much more efficient use of blocks for anchor transactions that support 1000s of layer-2 transactions.
And yet each Lightning transaction *is* a valid Bitcoin transaction, that can be reclaimed on the Bitcoin lockchain in event something goes wrong.
@_date: 2017-11-22 17:17:15
and I bought at $1200 etc I know r/btc memes.
@_date: 2017-11-22 16:02:18
not a scam, I have seen these in person. the photo is real, just the logo photoshopped onto it. see also tweet from Jan Capek.
@_date: 2015-07-10 02:26:01
Who said 5 years. I'd suggested double block size plus policy limits to have miners influence growth from 1-2mb within that. Like in the next 6mo. Forks hard or soft take a while to test and deploy.
@_date: 2015-07-10 02:13:41
No.  It's a tradeoff between security and scale.
@_date: 2015-07-10 02:18:47
It's easy to act aggressive and belligerent, but have you say looked at transaction scaling over the last few years?  Do you know about policy limits at 250kb and 750kb?  You realise I am saying lightning hugely increases the number of layer 2 transactions. 2mb with lightning would provide scale that's basically impossible unless you think 20gb blocks are "no problem"
@_date: 2015-07-01 19:06:37
Well so on the blockchain is a relative locktime transaction anchoring coins in the channel between user &amp; hub (or between hub and hub).  The user holds a transaction with the hub that allows the transaction to be updated with agreement of both the user and the hub (a multisig but with a time difference eg (user and hub) or (user and relative timelock).  Now each time the user sends or receives money the reclaim transaction is updated by being signed by the hub, and later by the user if he wants to start the reclaim process.  Now the reclaim transaction can include additional rules of the other user connected via hubs requests it.  eg a p2SH could be added to it or other bitcoin script rules.  
So while the channel doesn't enforce the script, the users can use the reclaim transaction to ask the blockchain to start arbitrating and enforce the script at any time.  So users can verify *would* the script be valid if posted to the blockchain (after the relative timelock) and if so the game theory is such that they should accept it (they will only lose if they do not because the wronged party can take it to the blockchain and claim).
So the blockchain becomes an automated dispute enforcement process, and as the disputes are of deterministic fully predictable scripts, there is no rational reason to need to use the reclaim transactions unless a hub goes offline for long enough that it doesnt look like it will return.
I am not sure if this is specifically explained anywhere, but this would work and I believe they are assuming it themselves.
@_date: 2015-07-01 06:03:08
Well we'll have experience of this one, and the user-base will be better informed, and more people will understand the game-theory, and hopefully we won't have someone at that time gumming up the process by proposing unilateral hard-forks.
@_date: 2015-07-09 23:51:10
Say a year.  +/- fudge-factor.  Please dont break bitcoin with stupid parameter proposals in the mean time.
@_date: 2015-08-17 02:24:56
How is working on scaling, working on BIPs to increase block-size and working on lightning restricting Bitcoins growth?
@_date: 2015-07-01 12:54:27
Suspect organised, maybe paid trolling at work.
@_date: 2015-07-10 04:35:57
The point is it's opt-in.  An 8mb sidechain will be more centralised than a 1MB main chain, and so less secure, more vulnerable to policy etc.  But if you like more small cheap payments you could use it.  I'd use it for like &lt; $10 transactions.  Why not - if it's just spending money.
Conversely if people insist on doing that to the main Bitcoin chain, Bitcoin itself is made more centralised, less secure and more vulnerable to policy failure.
@_date: 2015-07-10 03:53:23
Gavin's proposal is not conservative, it jumps to 8MB once deployed and then doubles it's way up to 8GB on an automatic schedule which is strongly centralising.
I'd say a conservative proposal is to increase the blocksize to 2MB now with policy limits, and adjust it again later with a more well analysed longer term solution.  Hopefully by then we have lightning running so we can see how that works out.
@_date: 2015-08-18 01:02:45
Curious how this got to -31 points.  That is an impressive negative score, I guess one should view that as a positive?  Is there anyone who down-voted who would care to explain?  Or is this more attack of shills, bots and mysteriously deleted posts?
@_date: 2015-08-17 13:47:31
Say flexcap?  It looks to be able to provide fee pressure and an auto-growing block that is limited to economically rational growth.  (That's important because economically non-rational growth means miner attack, or fees falling to zero and hurting miners).
Failing that I gave my thoughts - that maybe a plausible compromise because a big part of the objections to BIP 101 is that it imposes exponential growth at a high rate for 20 years which is too long.  I proposed some param variant of the same thing: 2MB immediate step, 4MB after 2 years, 8MB after 4 years to give time for lightning, sidechain etc R &amp; D to happen, and re-evaluate after that when we'll know more.  It may easily be we'd never need further rapid core block-size growth due to extension mechanisms or other R &amp; D wins.
The answer to complex questions is to *think harder* not to grandstand,  start a fork war, or coup.  Constructivity and inventiveness of vs night and day.  for Bitcoin chief scientist any day in my book.
@_date: 2015-08-29 11:40:49
People who work at blockstream made 4 proposals to scale bitcoin: bip 103, flexcap, extension blocks and a bip 102 like 2,4,8mb over 4 years proposal.  also did a lot of work in core on scaling, most recently speeding up DSA verification by 6-8x, before that headers first etc. developed the relay network that much of the hashrate is using to reduce orphans. Without this kind of work inceasing blocksize would bottleneck other things. Please keep up-to-date with actual core work and proposals on bitcoin-dev before casting incorrect aspersions.
@_date: 2015-07-09 20:55:05
might like to read some of the background information before getting angry about something he presumably knows virtually nothing about.  Blocksize is not a free variable, it's a security scale tradeoff.
@_date: 2017-11-28 10:12:33
they vest between 1 year cliff 5 year vest, first year on cliff and paid in 1/60th amounts after the cliff. (amounts locked in at start date)
@_date: 2015-08-16 17:24:53
Yes it could (to the extent they are known with confidence - bearing in mind fraud, false claims of theft, difficulty in proving a negative etc).
A problem however is probably a big portion of those coins have new owners who are innocent of the theft (this is what fungibility means - the current holder is defined as the owner - or confidence in coins is lost).  You might be interested to read about redlists that Mike Hearn proposed and blacklists and the effect that can have on fungibility.
(It may indicate some philosophical tendency from Mike to want to tradeoff fungibility for undoing thefts, but be warned that fungibility is really important for confidence in and acceptance of a currency).
Or if XT did issue you new coins then there will (eventually) be more than 21M BTC, and that acts as an involuntary tax on everyone else.
I also lost some coins in MtGox but I do not think this is a good idea.
@_date: 2015-07-01 15:08:25
Not a fundamentalist, but have a read of this 
@_date: 2015-07-10 14:21:41
Lets start with this: Bitcoin is not a micro-payments system.  You see to want to change it so that it is, in simplistic ways that weaken security, policy neutrality and risk breaking Bitcoin.
@_date: 2015-07-10 05:18:05
So you're aware that miners are in a complex game between each other and that their interests do not necessarily align with users.  Much of Bitcoin's logic and decentralisation and the need for economically dependent full nodes is to hold miners honest.
So let me ask you a different question, if the maximum block-size jumps to 8MB do you suppose the spammer might fill it?  Or a group of well connected miners might (at no cost to them) fill blocks with payments to themselves, to disadvantage other miners.  This would a form of selfish mining.
I'm trying to propose what's best for Bitcoin and explain to the "unlimited Blocks now" crowd that this is not a safe thing to do.
@_date: 2017-11-22 15:54:56
this is a batch0 as it says on the site. see specs there. I imagine batch0 S9 were also not as good as batch N. also watch out for at ASIC power vs at wall and PSU efficiency.
@_date: 2017-11-17 08:42:35
man why are people so focussed on freaking block-size. it's largely irrelevant. the point is transaction throughput and decentralisation so that bitcoin keeps it's differentiating properties.
all I did was pose a question on higher fungibility from CT offsetting the space &amp; validation cost.  a related question is I think there's a case that a CT transaction may displace multiple non-CT transactions, for example because some people split coins into parts for value privacy.
@_date: 2015-07-10 14:19:49
Something that is less secure, more centralised but opt-in is ok; something that enforces those same restrictions on bitcoin is not.
@_date: 2015-07-01 20:58:51
So conflict things eh.  It's not an unreasonable question, and while a bunch of things have been said they may not have been collected in one place.  I do not think there is a conflict here and I'll explain why:
a) everyone of the co-founders that left a job took a pay cut versus former employment.
b) every blockstream employee has been awarded Bitcoin bonds (time-locked bitcoin) in addition to company stock/options to align the companies interests with the success of Bitcoin.  Many people owned some Bitcoin from mining or having bought some before this also.
c) blockstream work on sidechains and our work collaborating on the lightning project are Bitcoin denominated, so the technical improvements, higher scale of transactions, faster settlement, improved security, privacy, fungibility research and new uses cases etc all benefits Bitcoin.
d) the above work is FOSS and open so others can use it.
e) so we aim to make a profit from providing technical services and integration and various other activities - seems like an honest living to me - we want to make a profit for our investors and for ourselves (we're share holders too).  But it's a virtuous thing by improving the Bitcoin ecosystem, making a profit by being experts in that, we then build and improve the system further by reinvesting the profits in further R&amp;D.
f) is on record saying publicly that he owns more $ value of Bitcoin than Blockstream stock.
g) and and others at the company work on Bitcoin core on their own time and part-time on company time by intent for Blockstream to contribute to improving core.  A few companies have done that, publicly or privately but IMO more should - having donations pay for core developers salaries apparently was difficult to secure for the Bitcoin Foundation.  Joi Ito at the MIT Digital Currency Initiative project thankfully secured funding for Wladimir, Cory &amp; Gavin.
g) sidechains and lightning also need larger blocks - sidechains for return peg transactions; lightning for bursting reclaim transactions when a big hub goes offline.  (though they can be safely delayed by people who can afford to wait with relative locktime).
h) speaking short-term to reach maximum safe scale within technology and security limits, blocks on main-chain are likely to get increased with or without lightning or side-chain related secondary chains.  It's just that with lightning we can get a really high scale and near instant settlement that is basically physically not possible directly on Bitcoin.  But there is no need to create excess capacity on a schedule for decades ahead as it risks guessing wrong and distorting the market, and weakening Bitcoin's security model via centralisation.  It's more logical to incrementally increase scale and see how the technology works out and then do it again armed with better information about technology and network advances in a couple of years.  I wrote about this here: 
h) the people who founded the company are basically a bunch of core devs, bitcoin committers and cypherpunks.  You know like the Austin &amp; myself were doing ToR things back in late 90s early 2000s with Zero Knowledge Systems another startup.  ToR white paper references some stuff to do with forward anonymity I invented while working on ToR precursor things at ZKS.  You can look up the contributions of and on Bitcoin, their to contributions to bitcoin-core before and since co-founding Blockstream have been large.
i) just about everyone at the company has years of FOSS experience and contributed algorithms, code to the public domain.  We have a long collective history of both unpaid as well as startup contributions to privacy and other technology for improving technology or being attracted to technology with positive social implications, shifting the balance of power towards the individual.
j) I dislike patents and intentionally did NOT patent hashcash back in 1997 which Bitcoin uses for mining.  Lucky for you eh?
k) if we had not formed Blockstream we would be working on the same stuff in our free time anyway or self-funded.  Pretty much everyone technical in the company has been working on Bitcoin for years almost all unpaid.
l) It would not be smart communications strategy for a company to get into this argument at all.  Most CTOs and CEOs and company affiliated people you may notice are not participating.  We are participating with our personal Bitcoin contributor hats on because we are concerned to see the best technology decisions made for Bitcoin and that is more important than getting flamed on reddit.
l) ... anyway you get the idea.  I really dont think we can nor should be construed as the bad guys here.  We're trying to improve Bitcoin and help it reach it's potential.  I have said I do not think there is a conflict here.  I believe it.  Our strategy is to produce the best technology and be experts in it.  Not to steer people to defective tech and certainly not hold-back advancement in Bitcoin, it's truly hard to make such claims of or many of the advancements lately to Bitcoin have come from them.  Holding back Bitcoins technology improvement would make no sense all the FOSS stuff we're building and contributing to builds on Bitcoin!  Bitcoin and our interests are quite well aligned.  That is why we felt it appropriate to reinforce that alignment by awarding employees time-locked Bitcoin as well as stock/options.
So when you see me or others saying things about block-size, its for good technically sound reason aimed with making Bitcoin the best it can be as soon as possible.  The fact that we are providing detailed technical rationales shows this is a technical discussion.  Anyone is invited to participate in the technical discussion and come up with better ideas or critique the analysis anyone puts forward.  That's the way FOSS works and the BIP review process etc.
@_date: 2019-04-17 04:46:45
popularity of the people promoting the coin - not market popularity of the coin itself. 
@_date: 2015-07-09 23:36:09


No.  Say we had sidechains now and someone made an 8MB sidechain, and some people who are interested in lots of low value transactions start using it.  They can go ahead and do that.  It doesnt have to be sharded?  You maybe thinking about pettycoin?
@_date: 2019-04-30 15:18:43
Used to at the time confidential transactions were worked on, he's an independent bitcoin protocol developer now.
@_date: 2015-07-08 21:10:27
It is normally expected that a sidechain BTC is a mainchain BTC because the ratio is a fixed 1:1 ratio.  But yes an inflationary sidechain could work - say the excess bitcoins go to mining reward for the sidechain for example.  Part of the side-chain definition would be a deterministic function that specifies how the ratio from sidechain fractionalBTC to mainchain BTC varies over time.
One example we mention in the sidechain white paper is it would be possible to implement freicoin-like demurrage on a side-chain.  You might need an exit or entrance fee otherwise people could use the side-chain functions without exposing themselves to much demurrage by swapping back to bitcoin for storage and transferring into the sidechain at the last minute.
@_date: 2015-08-17 13:49:10
Controversy - you'll know it when you see it?  Are you seeing the controversy on reddit, bitcoin-dev, etc - doesnt look non-controversial.  I dont know if it's obvious but a big part of what is controversial is bypassing the review process.  Why would Gavin not be happy to let the best proposal win?  He even said before he was happy to see Jeff's BIP 100 be deployed instead.  And yet he released Bitcoin XT anyway.
@_date: 2015-07-02 10:36:28
I think this and parallel things in the US are part of a coordinated attempt to deflect criticism from the illegal things GCHQ &amp; NSA were exposed doing by Snowden.
Two Senate hearings on whether US government should have a backdoor into crypto. Intel:  Judiciary: 
They know the answer is no, banning encryption is not appropriate in any kind of democratic country but hope create some noise as people fight it, avoids the massive glare of media spot light on them for illegal mass-surveillance actions.
Look at the timing of it.. 
0. huge amounts of knowingly illegal activity mass-surveillance by GCHQ / NSA
1. Snowden whistleblowing on the illegal activity
2. courts start handing down decisions that GCHQ / NSA activities were illegal
3. start a PR campaign and prod a few politicians to starting talking about banning encryption
4. resume/continue illegal spying and hope no one notices
@_date: 2019-04-17 04:33:57
I was talking about popularity of the proponents should not be a criteria IMO. One of the interesting Bitcoin and cryptocurrency properties is censorship-resistance and permissionless, so an unpopular minority must be able to use them - and in principle use a coin or tech optimised for their use case.
I think trade popularity would be partly covered by trade-volume and is relevant (an exchange is making an investment to do the listing and maintenance so wants to have some confidence of recouping that investment over time).
@_date: 2015-08-17 03:58:00
Yeah I dont think you looked at the 4th July fork.  That was non-controversial, and by accident it actually forked and people were only saved from losing money by rapid manual intervention.  It had a 95% activation hash rate.  Bitcoin-XT is controversial, and has a 75% activation.
You also seem to imagine that people who think Bitcoin-XT is dangerous and ill-advised will do nothing to defend Bitcoin against it.  This is partly where it gets dangerous.
People are talking about how to sabotage Bitcoin-XT - there is even a patch to do it that has been released.  Maybe some people are already running it, you wont be able to tell (by design).
None of this is collaborative, and it would be far better for Bitcoin if people worked in good faith on improving Bitcoin.  Reviewing and analysing BIPs is constructive.  Starting fork wars is a really bad idea.
@_date: 2015-07-01 00:13:14
Well for example if we look at  we see that 3 pools together can 51% the network and probably one pool or two other pools can selfish mine the network.  A bit centralised no?
The number of full nodes has dropped a lot also.  The number of economically dependent full nodes (ie people that run full nodes who use it for their business to decide whether they've been paid or not) is also dropping due to the rise of various outsourced SAS models.
It's not that I'm deciding I'm just pointing out things we should fix.  Also FWIW I and others are working on fixing them!
We'd just sooner people didnt get demanding changing parameters to unsafe areas before those things are fixed.
Also the CPU load of verifying blocks is quite heavy from block signing.  Already some miners are mining the header without waiting for the block-sig verification - thats bad because you can then get higher rate of 2-block orphans and cause people to lose money.
and did a bunch of work over the last year on optimising CPU load with an approx 6x faster than openSSL asm implementation of secp256k1 
otherwise increasing the blocksize would not even be computationally possible on many computers.
Scaling has to fix up a range of bottlenecks, it's not as simple as changing the headline parameter.  People also worked on memory scaling and rewrote the block sync protocol to catchup in hours instead of days when you join the network.  was working on IBLT to increase block syncing time.  built the relay network which is already used and does a version of that and the majority of the hashrate is now using it.  It's a form of network compression to reduce block transfer latency.
So I dont know people are approaching it scientifically and benchmarking the next bottleneck that gets hit as each one is fixed, is that a fair answer?
@_date: 2015-07-10 03:57:40
There are technical and security limits.  It maybe instructive to ask what you think Bitcoin is?  (Serious question: what is the primary benefit of bitcoin over paypal, ACH, debit cards in your view?)  In my view bitcoin is fundamentally not a micropayment network.  Expecting it to scale to world wide use while ramping up blocksize and refusing to consider algorithm improvements is a recipe to break bitcoin's security.  Then bitcoin will be neither a micropayment nor an policy neutral p2p payment network - it will be broken.  Again, changing the block-size is not a free variable - it is a security scale tradeoff.  By combining Bitcoin with an integrated write cacheing layer we maybe able to get both Bitcoin that still works, and micropayments.  But aggressively ramping up the block-size is just a bad idea.
@_date: 2017-04-05 09:04:22
the point of extension-blocks is like Sztorc's large block side-chain: that the ext-block is less secure. it would be natural for some people to prefer to anchor transactions in the main chain for security reasons. people have other reasons for wanting malleability fixes, high value smart-contracts to do with cold storage etc. so it is important that a malleability fix be available on the main chain.
There seems to be some mistaken view that ext-blocks is the new economic centre and the main chain doesnt need upgrading nor fixes. i strong disagree with that view.  the main chain is the economic centre of bitcoin, an extension-block is a place for cups of coffee that competes with lightning.
It's also poor planning if you're looking for success: be compatible with features that are running for activation, and will be so until November, and may get renewed if not activated by then.  It's also just socially not clever, that's just accidentally through clumsy social thinking going to needlessly irritate and annoy the hundreds of industry and dozens of developers who put work into segwit.
@_date: 2017-04-21 07:48:51
Greg linked to the BIP and code by Luke.  That was presented at the miner / dev meeting in july 2016, which was ahead of schedule suggested in the agreement.  You can read the BIP and transcript of the meeting for yourself google kanzure transcript miner meeting 2016.  
@_date: 2017-04-02 10:45:42


Why are you socks deleting posts?  Trying to disrupt comment and disproof of know false claims, much?  We can just quote your text, boring.
What you said is *false* and you know it.
See first link on  for BIP and code for Luke's BIP from July 2016 presented at the miner / dev meeting.  The transcript of that meeting is 
@_date: 2017-04-21 03:52:21


that is untrue. those present produced HF BIP and code, and Johnson Lau even had several testnets running some HF variants he proposed and coded.
@_date: 2017-04-05 08:58:30
what about reorgs? 
@_date: 2016-02-02 13:25:09
You couldn't make this stuff up :)  Oliver Stone film definitely needed.  Agent Bridges is way more criminal than Ulbricht ever was.  This story just keeps giving - the original court docs read like a Training Day script - rampage of criminality.  And even at the 11th hour Bridge's is still in full rampage mode -  3 offshore companies, stolen Bitcoins, foreign passport applications for his wife.  Really couldnt make this up.  I volunteer as Bitcoin advisor if they make this movie :)
@_date: 2017-04-30 06:56:34
ex Neo &amp; Bee Danny Brewster is still tweeting  btw
@_date: 2015-08-16 20:26:08
False. People who work for Blockstream have contractual independence to do what they think is right for Bitcoin.  Several devs affiliated with blockstream worked extensively on scaling and proposing different scaling BIPs.  It is Gavin and Mike that are trying to assert central control of a necessarily decentralised system.
@_date: 2015-07-02 10:58:01
"If it was just giving people another way to buy a cup of coffee, no one in our ecosystem would be working this hard"
Nice quote.
Maybe something to balance the "8MB of discounted micro-transactions now or death" telling.
@_date: 2016-02-25 05:57:57
see 
what matters is that people work together improving Bitcoin.  Those present intend to keep to their agreement to write BIPs &amp; code, and work with other devs on reaching consensus.
@_date: 2017-04-04 07:52:42
Hey u/josephpoon


and yet you were less open than the HK agreement, which didnt make closed proposal - just a commitment from the developers present to make an open proposal in the normal process, which they then did.
I'm sure JJ and yourself were trying to be helpful, but it's kind of difficult to get open collaboration and review in the design of things by starting out in this way.  Why not follow Dr Johsnon Lau's example here?  He made multiple proposals, all of them open and two with testnets.  Add to the research on  I know you know prior proposals like P2SH, CSV, SW etc had input from a lot of technical and business use case contributors.  Why not aim for that here?
This is actually a variant of how Gavin started this whole annoying drama moving consensus protocol design from the technical domain to the backroom discussion and then media blitz.  You did one thing differently: Gavin first tried to persuade people making drastic security tradeoffs was a good idea to pivot towards micropayments, and when no one agreed, then he (in secret) went down this path, and the rest is history: XT, classic, BU, EC, 2MB HF+SW, and now ext-blocks by surprise!  (What you did differently, as with 2MB HF+SW, is to skip the first part, so you couldnt technically say that tech community opinion was not that supportive - because you didnt talk about it with anyone nor make any public comments on related existing work.)  Why not comment or make suggested improvements to Johnson's proposal? 
@_date: 2017-04-23 17:41:50


They did get together in person for a multi-day technical design meeting on this topic (at their own expense).
They did propose a mechanism.  They even proposed many mechanisms, and code, and running testnets.
However even the miners didnt want a hard-fork in the july 2017 miner/dev two day meeting in the silicon valley/bay area, because in part it was recently after the DAO fork failure, and no one wanted to re-create that problem in Bitcoin.
You can read the transcript of that meeting online.  
Jihan particularly said in person that he would make sure Bitmain controlled hashrate would upgrade and signal to activate segwit once it was released (as a soft-fork).
Apparently he also told another developer in person the same thing, about signalling segwit in September.
What really happened is hard to say, but he did not do what he said he would do; and those present at the HK meeting did everything they said they would do.
Perhaps as you said some people could have been more persuasive or persistent in politely and constructively reminding people about spoonnet2 etc.  But given that even the miners seemed to lose interest in hard-forks and that it's difficult to imagine checking in untested code for future activation, and the testing involves deployment and network measurement of segwit, that is inherently future work.
Luke did propose another method which is interesting to make a future HF to relax many rules, and then a soft-fork to implement the details later within that envelope.  However he found it got overly complex and so risky itself and so suspended that work.
You are a member of the community, and so are miners, users, businesses any can feel free and should be encouraged to reopen discussions.  I suggest a constructive tone will tend to work best for anyone.
I think it's a technically useful discussion to talk about empirical network measurements and security conditions for a size increase hard-fork eg using spoonnet2.
@_date: 2015-07-13 05:33:07
You know Gavin called himself dictator and said that Mike told him he should be more dictator like, and Mike gives him the thumbs up for saying it.  It's more like a self-quote than anyone called Gavin a dictator.
(There's a you tube video online I think it's this one  )
@_date: 2016-02-14 22:26:59
I'd more think a non-contentious hard-fork or firm-fork will be the what we'll see.  I mean if people want success, and I have to assume they and their investors want success, the obvious thing to do is to try to minimise risk and controversiality.  Try to be inclusive, calm and technically justify and get open review of what you're proposing.  There's no reason the industry cant do a hard-fork in a reasonable time-frame and if there's wide-spread agreement the risk is further reduced.  Reasonable time frame could be inside that period.  Firm-fork maybe faster.
@_date: 2017-04-30 07:27:09
endless wrong assertions, even - the perfect bait and tar-pit for xkcd 386 reactive folks.
@_date: 2019-04-15 19:30:39
OP_HODL? future usage of miniscript  and output descriptors  may allow more interoperable custom setups
@_date: 2016-02-15 11:58:31
Probably would've been better with a core-dev on there.
@_date: 2016-02-07 09:48:10
The mission statement of at the bottom of his infographic is kind of neat:
I think u/nullc wrote a number of explainers eg  and


@_date: 2015-07-01 08:22:12
I know as I said I know Bitcoin people who can read Chinese and read that doc and the background Chinese language forums and together it colours the full story differently.
@_date: 2017-04-21 03:44:08


Luke's hard-fork wasnt a block size reduction.  You're mistakenly referring to an unrelated proposal made about 9months after the proposal from Luke-jr with BIP and code that Greg cited.
@_date: 2016-02-15 13:01:33
Hi Olivier
Do you think the companies who expressed their view here  should also have their views heard?  (60-70% of hashrate, bitfury, f2pool, part of bitmain group, bitfinex is largest USD exchange at 41% of market share, plus btc china and many others).
Many people understandably dont want to enter the public noise and politics but may have a more conservative view also, I have talked with a few of them who have this kind of view.
Are you sure your views are what the market wants?
Are you sure a rushed hard-fork is safe?
I know you're invested in Bitcoin -- but are you sure you are acting in your own economic interests?  Acting in the interests of success for Bitcoin?
The drama is itself not good for Bitcoin price, confidence and investatbility.
The bitcoin developers working on core produced 80,000 lines of code during this and the previous drama, and many new innovations and scale improvements.  Is it useful or helpful to create drama vs say participating in the open decentralised process and working on the next step things like IBLT/weak-blocks and next steps hard-fork like tech-debt write down, size hard-fork and/or flexcap.
ps are you going to Satoshi round-table in florida?












@_date: 2016-02-15 16:20:42
I was answering


with a link to an article I didnt write the above...
@_date: 2016-02-15 00:14:18
Lots of failure modes.  There are a lot of "only in Bitcoin" stories of weird stuff once you see the operational side of it.  The warning software warns all the time because of false positives, people already ignore it or dont look at it.
Much software is embedded - who is looking at it's warnings?
A number of services are semi-maintained, operator off doing something else (eg real estate development with early bitcoin money).
Losing money doesnt seem to motivate people, I guess they dont notice or care enough.  Eg 2PH mining pool mining invalid blocks for several months.
A number of services lose money ongoing due to various issues, design defects, or limitations and just reimburse users from revenue or capital.
Some services are running on old or unmaintained software.
Lots of old nodes on the network that are effectively SPV.
Lots of unmaintained non-economic nodes.
SPV lite clients can get accidentally or intentionally surrounded by weak chain nodes.
Probably a bunch more things if you go talk with someone who's worked on the 24 CVEs in Bitcoin's history and undisclosed near misses.
@_date: 2017-04-05 10:20:03
Yes actually I did know that - that your work on bcoin as one of the segwit implementations tracking the development and contributed to it.  
btw dont take questions adversarially, the analysis is about security for Bitcoin.
My point, which you did not answer, is that because what you have proposed (seemingly gratuitously/accidentally/implementation side-effect) as incompatible with segwit flushes the integration work that the people on this list did 
So it's a simple suggestion: make it compatible.  Or make a strong case for making it not compatible.
I think it's a slight misjudgement about human nature also, to avoid accidentally seeming dismissive of their work.  Particularly when they and 100s of people put a lot of work into it, and absent a few mining pools stand ready to activate.  Think about it from your own perspective, you even contributed to it.
There's no realistic way that a proposal as complex as ext-blocks is going to be in a seg-wit level tested state inside of 6mo-1year; probably realistically a year+.  So in the mean time there's no point making it incompatible.
Similarly I gave reasons why Bitcoin would need and have strong use cases for segwit (or other) malleability fixes on chain (not just in low security ext-block).  You didnt comment.  Do you agree?
The bigger concern, always for me as one of the people who proposed ext-block idea back in Jan 2015 (being a reinvention of Johnson Lau's 2013 aux block) is how will Bitcoin remain secure if power users cant validate blocks?  What happens if there is a reorg by consensus failure in the ext block? Even full node users are vulnerable then to reorgs based on data they are not able to validate.
It's maybe a bit like SPY mining, you can end up with invalid chains until people realise what the "right" chain is.
It also makes the barrier to entry for smaller miners harder in bandwidth.
And creates more latency hit with block transfer which creates orphan risk.  Yes there is now compared to 2 years ago when I proposed this for discussion, now compact blocks, falcon, fibre etc, but those protocols are not adversarially secure.  It is trivial for a miner to game the system to their advantage in amplifying a selfish mining attack.
@_date: 2017-04-04 08:50:41
So now what? Design by media blitz? World speaking tour for those doing the actual work. (Which detracts from their time to do work:)
ie I mean should forcenet1, forcenet2 and spoonnet1 also seek main stream media coverage? Is main stream media coverage the way to analyse deeply technical tradeoffs?  Poon's a smart guy.  He knows this game theory.  Curious for explanation.
@_date: 2015-07-10 04:00:45
You know if you want to help, there's a git hub for bitcoin and another one for lightning; and there are fundamental and very complex protocol questions to analyse.  That's what I'm doing.  Shouting people down on reddit without understanding the tradeoffs isnt actually helping.  It alarms people and the market who might mistake the people shouting as knowing what they're talking about.
@_date: 2016-02-08 22:12:58
Good post! Best way to combat signal to noise issues - generate signal :)
@_date: 2017-04-02 00:14:41
Look do you want scale fast or not? If so ask miners to activate SegWit, then we can see Lightning do it's thing. If not, sit tight, status quo works. I can assure you h0dlers dont care much other than embarrassment factor of anti-science brigading having any sway at all in Bitcoin progress.
Personally I think that's a shame because higher than necessary fees, price out great use cases that need the actual important and revolutionary properties of bitcoin.
@_date: 2017-04-29 01:32:24
Sure it's not an ideal outcome, but it's probably better than MtGox where no investors (except possibly a few insiders who had fore knowledge) got their money.  They probably said publicly what the percentage that opted to convert to stock vs wait for reimbursement.  At this point all of those who didnt convert to stock, got reimbursed some weeks back.
Anyway my main point is that situation has nothing to do with tether, as far as I can see.  Not sure if you were trying to say that or not, however the thread was about tether.
@_date: 2016-02-14 23:14:58
it prevents anyone on the old chain losing money because the old chain is prevented from transacting (there's a new consensus rule that the old chain blocks are merge mined and be empty of transactions).  It's a bit coercive but if there was wide-spread consensus, it's safe and so could be done more quickly without risk of loss on the old chain or chain splitting risk.
There's also a soft firm-fork which is sort of similar except no merge-mining and so the header format cant change.
Stephen Pair is also talking about it in this article 
@_date: 2017-04-22 16:35:53
Seems like FUD.
@_date: 2017-04-01 10:52:41
You're mixing quotes.  It's Feynman:
"For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled." - Richard P. Feynman
(in the post-mortem analysis of the human tragedy of the shuttle disaster).
@_date: 2017-04-29 00:57:39
[EDIT delete claim Roger is an investor in MtGox, had recently skimmed a transcript of Roger's "MtGox is fine" video before MtGox collapse  which either I or they misparsed as having "in" after he says he's an investor and is at MtGox world HQ; he was meaning I think listening to the original that he's an investor *in Bitcoin* and he's at MtGox world HQ, not that he's an investor in MtGox.  I think he said he maybe had some coins at MtGox at some point before or after the collapse I am not sure.]
Note ~~Roger is an investor in MtGox, so he had an incentive to stop a run on~~ MtGox ~~which it~~ turned out they did not have funds to repay.
It would be curious to know which insiders got their money out before it sank, while others were being assured that they were solvent.
@_date: 2017-04-02 21:09:45
I was replaying to my mind non-technically grounded arguments for pivoting to data center IOUs, and responses to pointing out that being a problem in eroding bitcoin's useful properties, the proponents saying that well perhaps if doing a pivot to IOUs results in the expected side-effects, perhaps the technical community could undo that or the community could re-decentralise bitcoin. 
@_date: 2017-04-30 07:34:00
 actually lots of work has been done and ongoing even several active test nets.
@_date: 2017-04-04 08:19:00
It's just disappointing that JJ and Poon would choose to participate in this end-run around FOSS and IETF protocol norms, which even was the exact problem created this drama &gt; 1.5 years ago.  They surely know that, and yet didnt see the connection that starting a proposal in this way just leads to drama and delays.  They could easily have followed Johnson's example, and he even had recently published a draft BIP that relates.
@_date: 2017-04-21 23:51:08
there is a link in the transcript to luke's code which is from mid 2016.
@_date: 2016-02-07 09:45:11
The mission statement of at the bottom of his infographic is kind of neat:
I think u/nullc wrote a number of explainers eg  and 
Or u/nullc:


@_date: 2017-04-22 06:23:12
that doc and the code was written in july 2016 and earlier.
@_date: 2017-04-01 22:28:11


false. look at the linked site, there are multiple bips, with code and two testnets. 
@_date: 2017-04-23 18:53:18


Reportedly at two further discussions in July and September.


My suggestion for a while now is follow the money, that this is really about a power and control tussle in mining cartel / monopoly space.  When things are not making technical sense (stream of excuses from various people, that dont add up) Occam's razor suggests they can actually make sense, when coupled with hidden information about real-politic.


they admitted publicly that they implemented asicboost, in their own blog post, still on Bitmain web page. 


It's not really wise to design protocols around politics.  Doubly so when you dont even know what the real-politic is.  How can you design around a pure speculation of why someone is delaying progress temporarily? 
I think what each person can do is do what they think is ethically right, and in the best interests of users and Bitcoin.




If anything it's a handicap.


we should not make square wheels in Bitcoin because someone has a monopoly interest to delay production of round wheels.


a hard fork has risks as the DAO showed, no one wanted that at the July meeting.  it is also a lot of work to retest changes for volunteers, many months of security critical work.  also 100s of companies have to redo their integration work for zero benefit.  seems implausible for practical reasons.


if a hard-fork were done, the right thing to do is increase the discount.
the technical need for the discount is explained here 
the idea to remove the discount is more reactive design to work around false excuses.


creates quite a bit of tech debt to do that.  bitcoin security model requires a level mining playing field, wouldnt it be better to deprecate?


probably I dont have the influence that you and others think I do.
I prefer that each persons influence be limited to their ability to generate good ideas and act in a calm, constructive fashion that respects other people.


It's not a policy limit, it's a technical and security limit.  You can no more assure secure Bitcoin with 1GB blocks than compromise on rocket design with square wings.
I do think that continuing to act in an ethical way, with users and Bitcoin interests first will prevail. 
I encourage anyone to do likewise and also to suggest proposals.  Without being political compromises, consensus starts with proposals, and I'd suggest looking at Johnson Lau's work for a good example.
$20B of other peoples money can find a way to achieve the scientific, secure and logical outcome.
@_date: 2015-07-10 05:03:57


You know Bitcoin had a fee market before at the 250kB and 750kB policy limits, and nothing failed.  I do think we should work on increasing the block-size, just incrementally and sensibly; not via jump to 8MB and then auto-doubling to 8GB.
@_date: 2017-04-30 01:38:54
kind of biased "civil discussion" talking points


this one is untrue, as a) many companies are standing waiting for activation; b) the new users who would join bitcoin will be using new wallets that make segwit transactions; c) people using lower weight segwit transactions make space for heavier legacy/non-segwit transactions.
@_date: 2017-04-29 00:54:50
Some large percentage of bitfinex customers* opted to convert their BFX tokens to bitfinex stock.  The rest of BFX token holders were reimbursed.  I cant see that has anything to do with tether.
* From the qualified US investors and international investors.
@_date: 2017-04-30 06:46:42
malta is one.  if the coins are demonstrably offshore, and the hodler has appropriate remittance tax status.
if you have a US passport things get more complicated, but for anyone else...
@_date: 2017-04-04 09:43:01
I dont think that's it. Even if this proposal were new and radically better, if we take segwit as an example, it took a bit over 12months from idea through design, coding, review, testing, mining pool &amp; good start on integration work by ecosystem to begin signalling. ext-blocks are more complex.  I dont think anyone wants to wait 12months+ for scale.  Ext-blocks are an existing proposal with it's own pros and cons.
@_date: 2017-04-04 08:53:01


actually it would lead to centralisation in almost exactly the same way as a large block - I was the guy who proposed it  (as a reinvention of related / similar idea to Johnson's 2013 proposal).
that is because if miners and fullnodes dont have the resources to keep up with the ext-block data stream and CPU costs, then they are effectively involuntarily downgraded to SPV.
@_date: 2016-02-15 15:46:59
 april 2014 I guess.
@_date: 2016-02-11 12:43:01
it is not about one side losing or winning, not us vs them - we're in bitcoin together, we should be disrupting the inefficiencies in the existing financial system and enabling new types of applications - letting open competition improve finance as the internet opened new innovation.
Take a look at Matt Corallo's suggested way forward to collaborate: 
no reason we cant collaborate, there are 3 things in the roadmap that people could work on in parallel and collaborate on: IBLTs/weak-blocks, flex-cap, hard-forks.
See also the proposals from Matt 
and also recent new types of faster / safer fork BIPs by Luke DashJr  and Johnson Lau  and 
@_date: 2017-04-01 12:32:18
Yes but you appear unaware of history here. Segwit soft-fork was discussed from Aug 2015 and has approx 1 year of community, ecosystem and tech discussion and review across multiple sacking workshops dozens of private meetings and asking people if they supported. It's worth noting that of the few people who are delaying segwit currently previously voiced support during this process.
@_date: 2017-04-05 23:06:48
the bip is a soft-fork
@_date: 2017-04-04 07:39:57
HK agreement also wasnt a proposal it was a commitment from some developments to work in the normal open collaborative way on a proposal, which they subsequently did
and later further work 
 and proposed later publicly (not with secret lobbying and fan-fare).
I can only assume that some people are not familiar with FOSS and open IETF protocol development.
For example Johnson Lau hasnt been working in secret on code, not trying to get buy in from businesses before technical review and contributions from others for spoonnet, he just published all of it on the bitcoin-dev mailing list.
I can presume that people are trying to be helpful and make new proposals that after review and improvements get even accepted - consensus has to start somewhere, with proposals! - but this backroom pre-agreement approach is 100% inverted to how things work in FOSS.  It distracts from progress, it will likely slow down or reduce likelihood of a proposal going anywhere.  It's more like microsoft machinations in standards space.
And i'm even someone who named the thing extension-blocks  I think in 2015 or so and described the trade-offs, it was a reinvention of Johnson's related 2013 prior proposal.
The trade-offs are maybe slightly less ban than a HF in some ways, but in other ways have worse security trade-offs than simple large block HF.  They are also more complex than seg-wit which as people saw took close to year to go from idea to design contribution cycle, reviewed, implemented and well tested status with good levels of ecosystem integration.  Even if this proposal were to ultimately get ecosystem approval - it will take a year and delay scale if segwit adoption were delayed as a result.  It make sense to me, as Johnson did, to put this kind of proposal in parallel.  Johnson in fact recently made a draft of the technical limits 
@_date: 2016-02-15 11:28:07


I mean *integrated* into some service and non-UI not interactive shell command line ie wrapped by a library or API in a hosted wallet, payment processor, mining pool etc. Not desktop software where a user or operator would see error message pop up on screen.
@_date: 2015-07-10 02:23:12
I'm assuming users would opt to upgrade to an integrated layer 2 that has instant secure 0 conf, 1,000 - 10,000 more scale and each tx *is* still a bitcoin tx so it has basically the same security properties, and lower fees for users and higher fees for miners if widely used, yes.  SGTM.
@_date: 2017-04-30 06:57:20
Hey no I am around, obviously :) long term h0dler.  decentralised bitcoin can outlive all.
@_date: 2017-04-30 06:42:12
 has some FAQs and explainers.
I dont think there's a lot of controversy amongst bitcoiners, it's just a few personalities operating pools, temporarily.  The list of companies supporting segwit and ready for activation is pretty long 
@_date: 2017-04-01 22:31:22
so activate segwit.
@_date: 2017-04-21 08:24:21
google and read bitcoin dev mailing list. also 
@_date: 2017-04-21 03:47:31


the developers present did that: they made something like 4 or 5 HF BIPs, Johnson Lau even made two or three testnets to test some of his BIPs.
words on reddit are 1000s of times cheaper than doing actual design and coding, dont forget.
@_date: 2016-02-02 18:50:48
Funny how the click bait flames attract lots of comments but informative and constructive posts linger with no upvotes and no comments.  I guess "negative news sells" :)
@_date: 2016-02-15 10:59:22
Not listened but did anything change since  ?
I hope Andreas asked some good questions...
@_date: 2017-04-30 06:45:02
software tends to scale incrementally, as each bottleneck is benchmarked and improved.  segwit is just one step out of dozens, including lightning and FIBRE, schnorr aggregation etc.
the excuses to delay segwit are running thin, with the activation of segwit on lightning, and it being likely that litecoin will see lightning active before Bitcoin.
@_date: 2017-04-01 22:30:44


Right.  And that is a feature.  People who like politics or want political money can use paypal, fiat.
@_date: 2016-02-02 13:26:36
Man those honey badger things are fearless and fierce eh?
@_date: 2017-04-30 06:55:00
Jed McCaleb was the mtGox founder and later co-owner, went on to do ripple and then stellar last I heard.
@_date: 2016-02-11 09:58:19


Does not read as an ultimatum to me, more like "work with to clarify".  Bear in mind if they had not given a time-frame a different narrative would be read eg that well how soon will we get clarity?  (Which would be another fair question).
It also something that people have been being work on see Matt Corallo's suggested way for all developers to collaborate on soft and then hard-fork  and 
and also recent new types of faster / safer fork BIPs by Luke DashJr  and Johnson Lau  and 
There is no reason we cant all work together as Matt suggested.  We should be drawing a line under past disagreements and working together to improve Bitcoin.
Ultimately we should be clear that Bitcoin is a p2p user currency and users views are most important - companies exist to provide services, features and use-cases that users value building on Bitcoin.  This is why people say there should be widespread consensus - Bitcoin security works as a decentralised collaboration between users, ecosystem companies like exchanges, wallets, and services helping users and miners providing security for the user and ecosystem economic full nodes, which then creates SPV security for smartphone wallets.
@_date: 2017-04-30 07:26:13
I doubt it.
btw it seemed like Silvio Micali said during his presentation at the Financial Crypto conference in Malta some weeks ago, that he had patented proof of stake.
@_date: 2016-02-11 21:33:42


Quite a bit: 
@_date: 2017-04-01 10:43:46
Right I think that is one of the confusions of new comers to the trade-off and design space: there is probably no path forward to be had if the rationale for delaying segwit so far, is not understood.
What reason would anyone concerned have to believe that those delaying may not in 12months time find new excuses to delay compromise v2 also.  Or they may just enable segwit after 6mo and flush that work, once their reason for delay has passed (eg if it is delay in manufacture of a big ASIC investment, perhaps, and the delivery is made 3months late).
My money is on the reason being a mining economic tussle about time to market of ASICs, in a consolidating and maturing market, with real-politic and business confidential information we are not party to.
In that context, it would make far more sense to talk frankly with the people involved to understand what they actually want and see if they can mediate between the mining cartel members to not hurt bitcoin users and bitcoin confidence and find a path forward via compromise or co-investment, stock-swap or something among the mining manufacturing and pools.  Of course less mining centralisation would be far better, but changing proof of work is too drastic and messy of a path, and simpler paths forward exist for the ecosystem and community to move forward, for example UASF is less bad than a 12mo delay with no understanding of real-politic rationale.
NB probably most of the proponents including Roger, of the various "hard-fork" proposals are themselves pawns and also not understanding the real-politic.  Well compounded by that some also do not seem to understand that user validation is necessary for Bitcoin to be secure - the pivot to datacenter IOU mindset, it'll be alright because economics, and if we break it maybe the tech community can repair it.
@_date: 2017-04-17 01:11:50
Money invested in a startup, is managed prudently to pay salaries, office rent, computers etc. the biggest cost of a software startup is engineers salaries.  Divide it by headcount and some years plus overhead to get an idea.  It seems like some people think startups are like a lottery ticket winnings for the founders and employees - that is not how it works - startups typically pay below established company salaries, in exchange for a stake in the upside of the company and manage their burn rate in order to optimise for success.
Blockstream was co-founded by developers who are strong believers in Bitcoin ethos and user rights:  
@_date: 2017-04-02 00:13:13
And it's not alone: schnorr aggregated signatures (27-41% smaller transactions), MAST (onchain also) and probably some other crypto size optimisations, plus lightning.  That's lots quite a bit to be going on with.
@_date: 2017-04-02 10:41:29
Come on digitsu, any evidence for any of the things you said?
@_date: 2017-04-01 22:23:37
That's not a bad idea.  A segwit malleability fix, without a blocksize increase, paradoxically, could activate sooner.
Unfortunately even that is not all that simple.
@_date: 2017-04-01 22:34:44
The keep most of their mined coins as investment, for the long term so it doesnt hurt them. The drama makes it harder for competing manufacturers to raise capital.  Happened before, one of the miners went bankrupt due to investors pulling out because of low / stagnant price.
@_date: 2017-04-01 10:48:13


Yes it is, and saying otherwise is revisionism.


no reddit suffered a partial outage due to overload. 
@_date: 2017-04-30 11:25:09
the two large votes are bitmain, it is believed. the vote used to be reversed. other large h0dlers didnt chose to remove their privacy to correct.
@_date: 2018-11-22 16:57:32
you'd be better off buying Vontobel's bitcoin ETN also SIX stock exchange listed 
this ETP has a bag of alts in it &gt; 50% diluted.
@_date: 2018-11-06 21:52:55
see also explorer for Bitcoin and Liquid including cross-links for peg-in and peg-out 
@_date: 2018-11-07 00:30:13
we are working on a version of  greenAddress wallet with support for liquid assets (and L-BTC). you'll be able to send those to other liquid users. but really you're better off using bitcoin or lightning, unless it's a trading wallet to hold liquid assets / L-BTC off-exchange.
@_date: 2018-11-07 13:50:29
there are frequent blocks (1mins) so they scroll off fast, and not yet many users, and wallet is cli so basically for power users programmers only. here's some confidential transactions (it's a test asset someone made)
@_date: 2018-11-06 21:56:34
liquid is for traders, storing L-BTC in a liquid wallet ready to deposit in a minute or so into any liquid supporting exchange is an alternative to storing BTC in exchange custody.
for cold storage and censorship resistant payments you want to use Bitcoin main chain.
for retail payments (fast, cheap) lightning is better.
it's a third option optimised for crypto traders... but it can be any amount small or large, not reserved for "institutions" nor "liquid members only", just sign up for an account.  there are some users using L-BTC in their own wallets from the rock trading.
@_date: 2018-03-24 17:32:05
cool. welcome to malta @_date: 2018-11-06 22:08:14
see also liquid fullnode and cli wallet release  (to participate in the p2p network that drives the liquid part of the explorer) 
@_date: 2018-11-07 13:52:52
blocks are 6x faster and same size, also has segwit but because the Confidential Transactions/Conflidential Asset proofs are part of the witness and bigger, probably in Liquid the witness may end up being the limit rather than the base. throughput maybe similar to BTC factoring in the bigger transactions.
@_date: 2018-11-11 17:13:12
Even then, other than the BTC-LBTC peg, that would be more of a DoS to the perspective of the fullnodes - people running liquid fullnode wallets would not see invalid blocks (that became invalid by functionaries trying to apply different rules). They might be able to resume the network from the last valid chain by reaching human consensus of new functionaries to sign blocks on it.
@_date: 2016-09-30 23:36:11
Consensus rule - other miners and fullnode users would consider blocks invalid if they didnt approve (by reference) the valid decrypted transactions from already mined blocks (after the time-lock delay).
So miners remaining choice is to block all transactions or try to change the protocol.  They cant unilaterally change consensus rules because consensus rules are enforced by economically dependent full-nodes.
@_date: 2018-11-15 00:39:07
in liquid there are both peg assets (liquid bitcoin L-BTC) and liquid issued assets.  issued assets are not peg related, and there you rely on the issuers claims - eg if it were a fiat coin, do they have the fiat in their bank account (think like tether, gemini, paxos fiat coins on liquid). or representing other kinds of ownership of stock, bonds, digital collectibles etc. so is correct.
@_date: 2018-11-07 13:58:45
Both correct and that is the way Liquid peg-outs work with hardware module enforcement that peg-out payments go to exchange member cold wallet.  
The way the rock trading (exchange) integrated L-BTC is they have an L-BTC wallet and pay L-BTC withdrawals from it so you can deposit BTC and then withdraw L-BTC (probably without waiting the full 102 BTC blocks pegin maturity). when you deposit L-BTC and ask to withdraw BTC, they pay you from their BTC wallet (and I presume rebalance BTC vs L-BTC as needed later).  I'm not sure how fast that is, depends how automated and may depend on amount (hot vs cold wallet on the pegout BTC payment).
@_date: 2018-11-21 12:10:42
it's maltese for palace. the palazzos in valleta are typically tall like over 3-5 stories as valletta is the capital, think like a stately home in the city so limited grounds but with roof space and maybe a court yard. they're typically multiple hundreds of years old, sometimes owned or formerly owned by nobility. here's one you can take a tour of  still owned by the de Piro family.
@_date: 2018-03-09 15:39:57
the miner includes an FPGA for calculating collisions locally.
@_date: 2018-11-06 22:01:33
some fiat coins will be multi-network (the value is not in the token that's an IOU so the issuer sometimes has APIs to swap them).
@_date: 2018-11-22 00:05:32










well a fall from 500k to 100k is no different pro-rata to the investor than a fall from 20k to ~4k or 1300 to 200 etc. but you'd have to think eventually as bitcoin gets closer to the top of it's adoption S-curve, liquidity is deeper that volatility would decline.  further along the Lindy effect may give more people a price target they have confidence in as a floor or fair value.
I also didnt give a time horizon "the years ahead" ie I'm thinking that maybe it +/- as a gold competitor based on private ownership of gold, market cap of gold etc unless more ambitious scenarios build on top of that eg reserve currency, new gold standard per Saifedean Ammous etc.  But I think looking at gold competitor is enough to think about for now.
@_date: 2019-01-21 20:29:46
@_date: 2019-01-16 19:57:23
There is a 3:1 turbo code on top of that, so we have optimised for resiliency at the end of the coverage zone in weather interference with 45cm dish.  The raw / best case bandwidth without Forward Error Correction (FEC) overhead is &gt; 3x higher than the payload bandwidth. There are two levels of error correction.
@_date: 2019-01-21 12:05:45
I am not sure this is true. Apparently due to an early implementation artefact it was not possible to mine without having active connections to other peers. And there were definitely other miners around, even though as a kind of hobby, novelty tech explorer/experimenter geek kind of thing. Some of them have spoke up to dispute claimed graph analysis claims of coins ownership from time to time. I know there are people who intentionally did not claim forks on batches of 50BTC blocks they solo mined for security/privacy/tax exposure. Even with a 10-20% premium.
@_date: 2019-01-21 12:02:20
I am not sure, I have heard that claim before, but presumably that california IP # was a Tor or VPN exit IP. Btw if I had such a log, I would wipe the file: it's best if Satoshi stays anon for a number of reasons.
@_date: 2016-09-27 10:15:20
The counters involved are effectively infinite for purposes of computations completing this side of the sun burning out.
@_date: 2019-01-16 23:03:13
Yes you can reuse the dish, even 45cm one should work, if you align it accurately but generally we recommend 60cm as it is easier to align (more forgiving). We used direct TV dishes for our office downlink. But check the LNB you may need a different one. Note In Asia Pacific coverage areas you need a 60cm dish. You need also other equipment but it is not expensive under $50 if you already have the dish. See guide 
@_date: 2018-03-24 22:44:59
you self host it. lightning charge and the Lapps are be-your-own-bank HODL the earned bitcoin, participate in the bitcoin economy tools, not payment gateway that wires you USD like previous gen bitcoin payment services.
@_date: 2018-03-24 20:53:33
speaking of LN tip bot  and 
@_date: 2018-11-06 22:06:03
@_date: 2019-01-16 21:07:57
You can learn more about Liquid in this video by  Jonas Nick, Applied Researcher at Blockstream:  
@_date: 2019-01-16 22:52:08
We can scale the bandwidth, there is some headroom today, we are sending the same data twice 24hr delayed to help recover from temporary power-cuts at the users side, and there is scope for data compression as u/nullc noted lower down.
What we hope to do is use revenue from paid API services and data users to reinvest and increase bandwidth.  Other than potential future higher scale Bitcoin needs, we can very usefully provide better Bitcoin service: for example periodic UTXO checkpoint, or fast full block sync (on a 24hr or 3day loop, that's quite a bit more expensive as it is 200GB uncompressed) but very useful to people.
@_date: 2019-01-17 08:40:44
The intelligence is in the teleport (ground station) which has a bitcoin node, a FIBRE handler, and software defined radio (SDR) to encode analog radio signal which is sent to the satellite, and then relayed down over the coverage areas it has antennae focussed on. The blocks are stored on the ground, the satellite is an analog relay.
@_date: 2019-01-16 19:26:48
Yes we hear questions from people, and during the first phase launch that has coverage areas: North &amp; South America, Europe and Africa  in Aug 2017, the LNB that it required sold out on Amazon.  We should be able to share some user stories in the near future.
The service has been continuously operational (except for a short interruption during a hurricane last year, which disrupted an uplink) since that launch in Aug 2017.  In the event the stream down time self-recovered because it has a 24hour data retransmit feature.
There are users using it in remote locations who have to transport pre-synced disks to a remote location to bootstrap.
@_date: 2019-01-17 00:37:30
Yes, and the guys in Japan did that 
@_date: 2019-01-27 11:50:42
Correct. But also note the confidential issue and confidential transactions are default on, but optional, and interoperate confidential and non-confidential.
@_date: 2019-01-16 22:37:26
I guess there is no way to look at the messages without a dish fullnode. Could be a side-project for someone with a dish to connect a webserver to the receive folder...
@_date: 2019-01-16 19:18:46
You could probably do it with the existing bitcoin  satellite a motor home / recreational vehicle today using an auto-steering dish of the type housed in a dome and gyro stabilized that people use on motor yachts.
To your question: maybe, we're exploring follow on services. like other tech it improves over time and what starts expensive and power user only becomes cheap and accessible to many, like with cell/mobile phones etc.
@_date: 2019-01-21 01:09:18
Question why was pay to TCPIP deprecated: 














@_date: 2019-01-16 19:49:01
It does have a retransmit window to cover service interruptions, power cuts or other outages on the client (or teleport uplink side, though that has more redundancy). However we have a relatively modest bandwidth allocation at present, less than a TV channel.
We are interested to grow usage of the service, and Bitcoin lightning micropayment driven use cases of satellite and scale the service as demand grows.
With enough data, we could indeed retransmit full block data though bear in mind that is a lot of data! 200GB history today. It would certainly be attractive to be able to provide fast fullsync on a reasonable frequency (once a day, or every few days in a loop).  Some data compression should be possible also. It is really a question of economics, so we're growing it incrementally as we get adoption to drive reinvestment.
@_date: 2019-01-15 00:42:21
See the text in the second image links it explains he had died suddenly while travelling, from complications of Crohn's disease.  I didn't know him but sounds like a good guy.
@_date: 2019-01-16 20:34:38
Yes, several of them have been talking about and posting equipment pictures on twitter.  One is in Latin America with mesh and LoRa.
I believe there are three or more Bitcoin embassies with Bitcoin Satellite dish connectivity or in progress / setup.
@_date: 2019-01-17 00:00:46


True enough. But also a new Bitcoin node with assumeValid does not validate signatures before that point. So a UTXO commit from before the assumeValid point maybe isn't so different, clearly you're not verifying as thoroughly that you are on the one true chain via proof of work headers and other validation that happens with transactions and blocks before assumeValid mark.
@_date: 2019-01-16 19:38:13
We considered it and may release more related products or kits in the future to simplify the business of setting up a bitcoin satellite fullnode.
@_date: 2019-01-16 19:59:00
u/bashco the bi-directional satellite services are tracked per user, so less private, only available to subscribers, will likely be metered, and may be expensive for bulk on-going data.
@_date: 2019-01-21 20:44:30
Atomic Trade diagram from  
@_date: 2019-01-21 10:48:53
I guess, or a VPN. Either that or Hal's system transiently saw Satoshi' IP address, which seems unlikely given that as far as we know Satoshi was CPU mining for quite some time (exposes IP address to p2p network of other nodes) and his OpSec was strong.
@_date: 2019-01-17 01:58:58
This is a general satellite topic, the satellites we lease bandwidth from are listed on  and are general use offering satellite TV and other industrial data applications. If someone attempting jamming and disrupted satellite TV, viewers would be annoyed The satellite operators would be upset with disruption and triangulate the source.
@_date: 2019-01-12 14:13:11
kind of. it's also just broadcasting less data - ie more users per bandwidth used, so that the network is not scaling at O(n^2) but at lower complexity, which is a bit Comp Sci techy. Not sure what a good analogy for that is.
@_date: 2019-01-21 00:52:23
I think some explorers convert it into an address by hashing the public key in it, but that is not really correct as this old Script template does not have an address type.
@_date: 2019-01-16 21:11:20
You mean like free low priority? As it is lightning paid and based on bids, you could pay an extremely low fee and probably get that effect, being sent in a time of low usage, when the send queue gets empty.
@_date: 2019-01-17 11:03:01
cypherpunks write code.
@_date: 2019-01-16 20:30:46
The Asia Pacific coverage is provided from a very recently launched satellite telstar 18V.  It's actual launch video for interest can be seen here 
Telstar 18 VANTAGE / Apstar-5C. Operated by Telesat, Telstar 18 VANTAGE will provide high-throughput communications coverage to China, Mongolia, Southeast Asia, and the Pacific Ocean region. The launch date was Monday, September 10, 2018 at 4:45 AM (UTC).
Shiny new satellites for the win!
But yes indeed, we are leasing less than one TV channels worth of bandwidth on this satellite along side TV providers, and other industrial data applications.
The signal and dish parameter engineering to get coverage with a huge 9m teleport dish (pictures of same model dish in OP) are interesting also.
@_date: 2019-01-17 11:11:06
See answers here  and 
Also it is infrastructure and enables more use cases, more adoption see if we succeed at contributing to adoption growth, we sell more infrastructure and services to companies and individuals. Also blockstream as a company holds Bitcoin.
@_date: 2019-01-16 20:42:50
We have an Bitcoin centric long term view point and focus on building infrastructure and you can see a range of products on  including GreenAddress Wallet, Liquid/Elements, C-Lightning/spark/charge, ICE/blockstream data feed and a range of applied R&amp;D work to keep product lines at the leading edge.  
We also released a year in review video that highlights some of the things we released in 2018 
We have a number of revenue generating products including ICE/blockstream crypto data feed, Liquid and other product development plans.  And as released today a new paid service API for satellite data!
@_date: 2017-09-29 20:50:53
I see what requirements you are interested in, and those are good - but logically and empirically the effect is the opposite.  fewer more centralised pools makes it easier to restrict transactions - clearly - today a government pressuring not very many people could create problems because of extreme centralisation problems.
past evidence shows that as latency grows from validation, transfer time, and short-cuts people take like spy mining, fibre and private transports just push centralisation higher.
@_date: 2019-01-19 14:41:15


Actually it dates back originally earlier to some discussions u/nullc explains here in this hackernews post:










@_date: 2019-01-22 03:15:25
@_date: 2019-01-16 22:00:46
People can look at the message queue and add and manage messages here:
looks like quite a lot of messages sent!
@_date: 2019-01-16 22:40:19
Yes there are several USD tokens coming to liquid. Some USD tokens are multi-network and these will be also. The advantage is you can move it quickly and reliably between exchanges so you get higher velocity trade and so more arbitrage or position trades possible without waiting for slow Fiat or BTC.
It is also more secure than storing funds on an individual exchange to hold them in your liquid wallet, because they are secured by 11/15 multisig with the functionaries being exchanges as described above. 
Another advantage is confidentiality people won't be able to see how much BTC or USD you're moving due to Confidential Transactions, and also won't be able to tell the difference between BTC and USD on the network due to Confidential Assets.
explains more on this in this video presentation 
@_date: 2019-01-16 21:28:39
Good feed back thanks.
Yes Liquid is running.  You can hear more detailed description of Liquid features and how it works by u/nicklerj here: 
@_date: 2019-01-16 22:20:45
@_date: 2019-01-16 20:13:24
We have heard from people are working on wifi repeaters, mesh networks and LoRa long haul in multiple locations around the world.  Part of the point of the Bitcoin satellite is to provide a back-bone piece of infrastructure to support lower cost last mile connectivity around the world so that more people can participate directly in the Bitcoin network.
@_date: 2019-01-16 23:06:50
Users may find various interesting uses for it that we have not thought of, the API is significantly to enable developers to experiment and build services. We made one example application  which is about GPG encrypted messages and the client to scan incoming messages over satellite for decryption.
We'll be interested to see what use cases and applications people build.
@_date: 2019-01-17 01:12:56
it should be good, if you have an expensive low bandwidth link to cross-check headers with. see 
@_date: 2019-01-16 22:31:29
Here's the team in Chile, looking to provide mesh and LoRa tech in Latin American.  
Actually they are looking to raise a bit of money  to pay developers, because they're working in their spare time and have day jobs - self-funded project.  
I met them in person and had several discussions at LaBitConf held in Chile last month, showed me their hardware and what they're doing.
@_date: 2019-01-16 20:13:58
In terms of payment we expect to use incremental per transaction or message fees to sustain and grow these kind of use cases, as with the API announced today. It is free using testnet coins for a short time while in testing.
The cost per message or transaction is often reasonable because while it costs a lot relative to average salary in some emerging markets, to have an internet connection fast enough to maintain a fullnode, the cost per transaction to send or receive a transaction becomes small because they are small typically 250bytes range, so that even at $10/MByte a single transaction could cost less than 1c.
@_date: 2018-03-31 09:31:52
the coins would be lost. it would create bitcoin deflation and transfer percentage ownership equally to other holders. but generally I think people need better solutions for this situation, which preserve privacy and bearer asset guarantees during normal use but offer a disaster recovery solution.
@_date: 2019-01-21 20:25:44
Some more context from the guy who submitted the patch to disable it  2011 in a Sep 2010 with Satoshi and others. Apparently wasn't used much by then either.
@_date: 2019-01-18 18:11:54
I have to say that sounds quite wasteful but I do not know how veriblock works or why they think it necessary to send so many phantom transactions, consuming bitcoin blockspace, just to anchor another chain's immutability.
@_date: 2019-01-08 12:31:40
the malleability fix in segwit is opt-in. lightning funding and reclaim transactions use segwit.
@_date: 2019-01-16 23:40:49
It's all possible, just a question of cost, satellites have a lot of bandwidth because they have many TV channels, and each HD TV channel is more than a megabit/sec, and we're using 312kbps.  We're getting a bit of interest to transmit other chains which could help cost share to expand the bandwidth leases.
It would be interesting to transmit liquid blockchain also.
Or Bitcoin related content - Bitcoin TV.
@_date: 2019-01-16 19:35:39
The receive only Bitcoin transaction and block data stream is free to receive and broadcast nearly globally with the recent launch of Asia Pacific satellite coverage. The idea of providing global bi-directional satellite Bitcoin payments is attractive and part of why we started on this project in 2016, with initial launch in Aug 2017. We are proceeding in stages as we build more infrastructure and technology.
In terms of payment we expect to use incremental per transaction or message fees to sustain and grow these kind of use cases, as with the API announced today.  It is free using testnet coins for a short time while in testing.
The cost per message or transaction is often reasonable because while it costs a lot relative to average salary in some emerging markets, to have an internet connection fast enough to maintain a fullnode, the cost per transaction to send or receive a transaction becomes small because they are small typically 250bytes range, so that even at $10/MByte a single transaction could cost less than 1c.
@_date: 2019-01-16 23:07:52
is Adam Back, blockstream.
@_date: 2019-01-17 00:27:20
Thank you for your positive comments.
Of course myself and people at blockstream are immersed in Bitcoin so we are bullish on the technology potential and adoption. My personal view is there is still lots of technical work to improve Bitcoin balanced with being very careful about security of changes. I think OP_RETURN is a useful feature, as it provides a way to send transaction extension data, allowing specialised wallets to build new features. Where it has historically been more controversial is where people have sent general application messages in it that are not part of the transaction completion and could as easily be sent via other channels.
@_date: 2019-01-21 00:28:23
@_date: 2016-09-24 08:46:18
A number of those implementations are collaborating to achieve enough format compatibility to interoperate.
@_date: 2019-01-16 22:53:55
We have had other requests, and you can use the data API paid via lightning micropayment for that purpose, or if you want to bulk buy longer term use for ongoing use, please contact us via email inquiries
@_date: 2019-01-16 20:04:53
Also Pavol Rusnok (CTO of Trezor) has an SMS gateway for sending Bitcoin transactions 
@_date: 2019-01-16 19:30:54
Lightning is a bit of an interactive protocol where the current iteration of the satellite service is uni-directional (receive only).  However you could certainly run a fullnode using hte satellite and run a lightning node using that fullnode, and use another more expensive per MB or slower internet connection such as GPRS or mesh networks to establish lightning connections and send and receive lightning transactions, and that is potentially a good use case for the satellite service.
@_date: 2019-01-16 20:09:05
Personally I certainly hope so, and this was my motivation for working with others on the applied crypto for Confidential Transactions, which I hope would some day become available in Bitcoin.  The second layer via lightning does offer additional privacy and fungibility due to recirculation of funds, and netted information not being settled to the main chain.
You can use CT today in the liquid sidechain which is a public blockchain you can run a fullnode for and transact on.  Transfer of BTC out requires an exchange account, for security reasons, but p2p trade and holding coins in wallets works on the sidechain.  Liquid is optimised for traders who trade on exchanges and OTC.
@_date: 2019-01-18 01:56:44
The fee market is a bit trigger happy it seems to me, because there are "bots" (various client's fee estimators) determined to reach predefined probability of first confirmation within N blocks, that can all act at once. Need more people low-balling fees, and representing their lack of priority on purpose. Many of the services and apps do not allow you to say "this is not urgent send it in the next day or two".
@_date: 2019-01-16 20:47:28
More details: 312.5kbps raw (without FEC overhead). 101.8kbps after FEC overhead.  10kbps allocated to data API currently.
@_date: 2019-01-02 14:49:48
correct re leased bandwidth. note re "control" it's another link, but users can and should cross check with slower independent links. potentially much slower. this cross-check security/control question is discussed more here: 
@_date: 2019-01-16 21:37:50
It's pretty easy, just download binaries for linux from here  and run liquidd. to check how far it's synced you would run liquidd --server and then run liquid-cli getblockcount and see if it's caught up with the liquid blockexplorer here: 
If you run into difficulty you can ask questions on  IRC or on bitcoincore slack in the  channel which is the same code basically as liquid. You can actually connect to liquid with elements fullnode if you change some defaults (ports, dns seeds) in the config file.
@_date: 2019-01-16 20:55:11
We did not launch satellites we are leasing a small part of the bandwidth available on 4 commercial satellites: GALAXY 18, EUTELSAT 113, TELSTAR 11N and TELSTAR 18V.
The last one TELSTAR 18V was launched very recently by spaceX, it's actual launch video for interest can be seen here  Telstar 18 VANTAGE / Apstar-5C. Operated by Telesat, Telstar 18 VANTAGE will provide high-throughput communications coverage to China, Mongolia, Southeast Asia, and the Pacific Ocean region. The launch date was Monday, September 10, 2018 at 4:45 AM (UTC).
The idea was developed by Chris Cook and u/nullc Greg Maxwell and dates back some years. Work began heavily in late 2016 with surprise product launch in Aug 2017 with this teaser video released without further explanation  the day before live service was revealed.
We also operate two teleports (uplink sites) including a 9m dish  to reach Telstar 18V.  The teleports have multiple dishes and can reach each others satellite for data connectivity.
@_date: 2019-01-17 09:20:36
I think it's a question of engineering resources to integrate and do high end security validation. We have shown Confidential Transactions works in production, and that supports monero equivalent types of usage. For example you can send 0-value payments to other people, and have them spend them, if you want to obscure who is moving money around to accumulate stock for a merger or buy out as one use case, on elements/liquid.
For now I think Bitcoin developers who work on crypto parts of the protocol are focussed on getting Schnorr signatures integrated.  For blockstream part we are also progressing CT for elements/liquid using Bullet Proofs, see  and active research continues on improving CT space efficiency.
@_date: 2019-01-16 23:52:30
Sounds cool! Also check out the mesh and LoRa tech project in Latin American. 
they are looking to raise donations  to pay developer time, because they're working in their spare time and have day jobs - self-funded project. 
I met them in person and had several discussions at LaBitConf held in Chile last month, showed me their hardware and what they're doing.
@_date: 2019-01-02 16:03:49
you can and should verify using other channels (slower/more expensive per MB links). you can even check via SMS. see 
@_date: 2019-01-17 21:01:55
I spoke to the tech guy a couple of times at conferences and I think they may have a paper online.  It seemed a bit complicated but they had technical arguments for how it combined bitcoin hashrate to achieve a secure effect.  IMO ideally they would use bitcoin more like a time-stamping service and not publish more than one transaction/op_return per block to be space efficient like opentimestamp or eternitywall's service.
@_date: 2019-01-21 20:18:43








Atomic trade coming to Japanese Exchanges, market makers and institutional traders via regulatory sandbox for regulator approved L-JPY "JPY Token", and Liquid sidechain atomic swaps. Alongside SETTLENET product and tools to enable atomic swaps, using confidential transactions, liquid fast settlement transactions and Atomic Transaction type supported in Liquid Network.
@_date: 2019-01-16 19:40:56
See answer to this related question 
We are working on follow on products and services, but prefer not to pre-announce, so watch this space.  We are interested in ideas and use cases, and for technical individuals and entrepreneurs in local communities globally to build local services to deploy Bitcoin connectivity, eg via mesh-networks, LoRa etc and there are several such projects under way.
@_date: 2019-01-16 22:48:50
We do have Europe and Africa coverage zones on TELSTAR 11N. Currently we are leasing bandwidth on 4 Geo-stationary satellites for close to global coverage: GALAXY 18 (North America), EUTELSAT 113 (South &amp; North America), TELSTAR 11N (Africa &amp; Europe), TELSTAR 18V (Asia Pacific combined area).  We have two teleports, and a configuration where teleport West can see East's satellite and fail over to it's data if the local internet fails. We do have redundant internet at the teleport also.
@_date: 2019-01-02 16:23:22
in some ways it helps, because you can cross-check your ISP via satellite or cross-check satellite (via slow/expensive internet) so kind of macro-level decentralization. but you're right people should not rely solely on the satellites nor blockstream. don't trust. verify!
@_date: 2017-09-17 11:25:06
started a new thread and expanded ^ 
@_date: 2019-01-16 23:54:42
Depends if StarLink opt to. It's a satellite to satellite laser data transmission routed mesh of many, many satellites and many up/down links - so they would be not naturally global broadcast designed, but seems plausible if they built software to do that if they had that use case in mind as an option.
@_date: 2019-01-17 00:23:12
We have some novel engineering on the satellite parameters, so the power is way higher than normal C-band, it should work with 60cm dish (depending on area). There are some folks doing a setup in Japan who post pictures of their setup.  and 
We are working on improvements and tuning also to increase reliability and reduce requirements.
@_date: 2019-01-17 13:18:29
The cost to open a lightning channel should be similar to a regular on-chain transaction, which if you are not in a rush has been about 1c lately for a 250byte range transaction. (1 sat/byte fee leve, the network minimum).  Eg see 
@_date: 2019-01-02 16:07:55
also many people have internet, just not very fast or too expensive to receive blocks over, but pretty cheap to send a 250byte transaction over.
@_date: 2018-02-01 06:26:51


@_date: 2017-09-19 14:53:54
Bitcoin is adapting pretty quickly. A lot has happened and continues to happen in the technical sphere.  the coin cap is not a problem at all, 2,100 trillion satoshis is a lot, plus it's not hard to add more precision under that if needed.
Bitcoin has so far kept ahead of security issues and has a security focus. Best bet for load is layer2.  Flat-blockists will eventually follow once everyone doing sub $1000 transactions is zipping around on Lightning starting soon and into next year.
It's not clear that centralisation pressures are static they ebb and flow.  Current fundamentals for example are seeing new ASIC manufacturing entrants like GMO.
@_date: 2017-09-28 02:18:48


miners follow the most profitable chain by the minute.  miners are part of the  ecosystem, but a small part.
segwit is a 2x increase.
@_date: 2018-11-14 02:52:29
just for context, that was false and entrapment by a corrupt and now imprisoned pair of FBI and DEA agents.
@_date: 2018-02-27 14:11:02
I thought he self-claims now to sold most of his BTC and bought BCH.
@_date: 2019-01-16 20:38:04
We have not heard any complaints from officialdom so far.  Users are enthusiastic, obviously.
@_date: 2018-03-25 12:16:15
raspberry pi like device would do it. plug in to wall socket and connect to wifi.
@_date: 2019-01-16 21:23:07
You can send transactions for free, just send them to the Bitcoin network and they get routed over a FIBRE point to the satellite teleports which are FIBRE connected and then transcoded, software-defined-radio (SDR) encoded and broadcast up and then down.  The payment is only for data messages that sit alongside the Bitcoin data stream and are not part of the Bitcoin block data.
@_date: 2019-01-17 11:02:46
Yes, if someone pays for the data.
@_date: 2019-01-02 16:13:57
you could just download headers from another source even, 10,000x less bandwidth than blocks. you could do that over SMS just about.
@_date: 2019-01-02 14:48:00
yes but they are not dedicated to Bitcoin they are multi-function, and the Bitcoin related bandwidth is leased by Blockstream from the satellite operating companies. there are four satellites and six coverage zones. the satellites are general use and provide satellite TV, industrial data and other applications.
@_date: 2019-01-21 20:46:59
Totan aka Tokyo Tanshi is one of the main large interbank settlement networks in Japan  
@_date: 2017-09-27 22:12:33
basically none of what you said is true? they are dissimilar.  i was somewhat involved in NYA - in trying to advise people. rushing a dangerous HF to prove safe makes no sense.
@_date: 2018-02-22 11:44:33
Yes bitcoin has had smart contracts from day 0, using a security constrained language.
@_date: 2019-01-10 01:25:40
btw Horizons Ventures also invested in Blockstream (lead investor of A-round). 
@_date: 2017-09-17 10:54:17
I hope that was only part of your holdings - news-flow is fairly unreliable in it's direction predictive power generally, and bitcoin news-flow is crazy unpredictable in it's arrival (not like quarterly financial statements, pre-announced product launches etc of stock market companies).
@_date: 2017-09-18 11:42:52
if someone has some user names for tech, spokespeople or management people from those companies, could be useful to tag them here.
@_date: 2019-01-21 00:28:43
@_date: 2017-09-15 08:50:25
the BC changes look like all upstream - ie imported from core based on author.
@_date: 2017-09-27 23:50:43
segwit blocks are limited to 4MB. technology improves over time. I hope that mid-term we are able to get past the contentious fork drama and do a technically useful fork that improves a lot of things like spoonnet.
@_date: 2017-09-16 20:52:56
I did hear a core dev hypothesize that to the contrary blocks have effectively been nearly instantly "full" for many years. There used to be soft-limits, local policy on mining pools   "Model demand as infinite". there are some graphs that do look like they corroborate this theory step functions as soft-limits were edited.
@_date: 2017-09-22 14:19:01
feature: does not come with a pointless ICO.
@_date: 2017-09-17 08:02:48
bitcoin had soft-limits in effect over a period of many years.
@_date: 2017-09-17 12:45:34
What is electrum's view on segwit2x - will they focus on Bitcoin or the spinoff?  Bitcoin hodlers want to know the focus is on Bitcoin...
ps congrats on segwit support, lets see the adoption numbers grow! 
@_date: 2019-01-16 21:01:45
The liquid sidechain blocks are not mined but signed by a federation of 15 functionaries: in liquid those are exchanges, market makers, prop trading companies. The functionary is a server with an embedded Hardware Module for key signing operations.  Because of the revised consensus algorithm reorgs beyond two blocks are not possible, so once there are two confirmations (2minutes) transactions are final.  It's security model is different from Bitcoins because you do trust that the functionaries do not collude nor the majority tamper with their Hardware Modules, so it is an improvement as compared with giving your funds to a single exchange.  But for long term storage and censorship resistance you will be best using the Bitcoin mainchain; Liquid is optimised for traders who use exchanges and OTC. But it does give early access to several novel and interesting features that have not to date made their way back into Bitcoin, though hopefully some of them do in the future.  Historically Elements had SegWit and CSV before Bitcoin, and may to get Schnorr signatures earlier also.
@_date: 2018-03-24 22:45:47
it's self-hosted: deploy away. you have to choose if you want to play safe and use testnet or be  and go mainnet.
@_date: 2019-01-12 15:22:19
It's so hard to explain big O complexity walls to people. Comp sci has such weird tradeoffs compared to what people are used to and their intuitions are based on in the physical world.
For example scanning a word list. Let's say early Bitcoin just did a linear scan of a list with  &lt; 1000 addresses in it. Then some people later say crap this scales O(n) that's terrible, let's change it to a sorted binary tree so we can scan it in O(log n) and some people who dont understand have a big fight that it's satoshis vision etc to have unscalable word searches, and people just need to buy $20k computers, or stop verifying and rely on third parties etc. It's not obvious to non techy people why that absolutely won't work. Scaling wall is basically a vertical brick wall past some point. Or put another way a smartphone using the O(log n) binary tree search can kick the butt of a $20k computer at list sizes in the billions. (Bitcoins history is 200Gig, some altcoins with "rich statefulness" and other unscalable design decisions has over 1TB and pulling away rapidly).
@_date: 2017-09-17 11:29:30
ps I have been buying China news for a while now, always seems more dramatic in it's interpretation, and have limited impact on price mid-term.  Each time it seems to have less effect.  That seems to be playing out with latest "china really bans bitcoin" rumors.  Even if they really do, Streisand effect upside, focus on Bitcoin's permissionless Internet money roots and differentiated payment and counter-cyclical hedge store-of-value proposition, the news serves as maybe a useful reminder of this.  And much of Chinese trade will probably continue outside China or via localbitcoins or other new outlets via varying payment methods also, and China's volume is much lower than it has been relative to global with more entrants from Japan, Korea, India etc and the wash-trade and volume reporting inflation being partly curbed in the recent / previous suspension of China bitcoin exchange service.  For perspective recall China blocks a number of things, including twitter.
@_date: 2017-09-18 08:44:55
Yes something like that. A sidechain is another chain sharing Bitcoin as the currency where bitcoins can flow in and out of sidechains to the mainchain. Think of it as internetworking for Bitcoin.
@_date: 2017-09-27 14:13:59
hope that clarifies the stark difference, and the mistakes that were made.
@_date: 2017-09-27 13:10:14
I believe one or two are a bit machiavellian so I am not sure what we can do with them - maybe boycott and replace their businesses.  But most are good faith bitcoin believers but got stuck in an expediency mind-frame that it was the only way to "rescue" bitcoin from segwit delay by Jihan at Bitmain.  Laughably Jihan promptly forked UAHF/Bcash on the eve of the "compromise" which was a laugh in your face move.  And yet they dont seem to be deterred from continuing.  I just think we need to reach out to them as customers and ask to talk with the CEOs on phone, in person whether you are an user, bitcoin investor, CEO, VC or someone concerned to retain Bitcoin's future meaningful value - we need to convince the majority good apples who got sucked into segwit2x on a good faith assumption that now is the time to get out.
@_date: 2017-09-27 20:16:02
segwit was the can kicking but properly designed. read this 
@_date: 2019-01-16 23:10:38
You have to be accurate at aligning / pointing exactly at the satellite with 45cm dish, but it does work. It's a bit easier with a 60cm dish if you were buying new.
@_date: 2017-10-29 18:07:43
oh yeah, I was mis-thinking... the hashlock is revealed, by the bitcoin transaction spend, if the B2X chain doesnt exist, that's unrelated.
@_date: 2017-09-28 08:33:57
indeed - wow how low can they go!
@_date: 2017-09-07 10:37:50
you're right that does seem illogical.
also most light wallets have auto-upgrade.
and some wallets are unsupported, which is more an argument for not using them as security issues will arise and go unfixed.
and lastly the claim that smart phone wallets would work without change with a hard-fork is just false for most modern wallets because they are hybrid architectures involving a semi-trusted server full-node verified via SPV.
there are also network reasons that even old style pure-spv wallets would not continue to work through a hard-fork.
@_date: 2017-10-29 15:55:09
are you buying BT2 futures?
@_date: 2017-09-27 20:04:01
just like - except this time there is no remaining china news to be had!
@_date: 2017-09-27 22:39:44
I think that sucks.  I had some ideas about making an actual decentralised and censorship resistant forum, but so much to do with Bitcoin.
Anyway it is pretty annoying that there is no unmoderated forum.  Everything is moderated, gamed, brigade voted.
I wrote some longer rants about this somewhere.  For now I guess we work with effect that there are lots of forums though with different moderation so a given opinion is basically impossible to censor or moderate in all of them.
@_date: 2019-01-21 00:33:09
@_date: 2017-09-12 15:23:56
right but the point is in the short term people get nervous about dips and sell, and then the price races off while they are out and never looks back and other such hazards.
either buy and hodl, or just keep buying dips in stages, or put a regular amount in periodically.
panic selling or day trading almost never work out, if they do it's because you got unreasonably lucky - day trading a slow exponential with high volatility and effectively random movement is a losing game.
@_date: 2017-09-12 12:50:11
IMO if you must day trade, dont sell more BTC than you can afford to lose. eg day trade 10% holdings or something. 
@_date: 2018-02-01 06:39:18
lol chartist parody.
@_date: 2018-11-14 01:43:34
is he still confused about how soft-forks work? Bitcoin fullnodes will not accept segwit tx without signatures. this is the same as p2sh and every other soft-fork.
@_date: 2017-09-19 13:16:46
yep. well on the plus side it is quite hard to prevent people from holding bitcoin, being as it's a quite permissionless and decentralised protocol.
@_date: 2018-03-31 08:53:10
defacto if you arrange for someone else to know where your key is in this scenario they now have your coins.
doing the paper work to make that is consistent with inheritance rules is a parallel construction.  intestacy would just mean like other property bitcoin would (if the keys were accessible and the rules followed) follow the same ownership transfer rules.
main thing is to make sure your keys don't get permanently lost.
@_date: 2017-09-06 06:38:23
@_date: 2018-02-14 14:25:20
You're looking at the wrong metric, you need to look at transaction outputs. And soon lightning payments.
@_date: 2017-10-30 10:59:56
Well think he owns shares in a number of companies and probably BTC went up faster than he spent or invested but yeah even 80k is still $500mil.  Plus some altcoins, domains/websites. His website costs him $500k/mo for a while now starting at lower prices so today's cost might be $100m has a big staff. (To moderate rbtc, troll on wechat, fly around and lobby, fake retweet service, up/down vote bots probably him also or friends and an astroturfing company retained also I hear from a few sources).  None of it cricket to most people. I do think Roger believes he's rescuing Bitcoin and Bitcoin needs gigablock so the ends justify the means to him. 
@_date: 2017-09-29 15:11:42
also many of them are members of blockchain alliance which exists to foster collaboration with law enforcement.  some have said they pre-emptively hand over all information to law enforcement.  it's difficult running an exchange.  but you dont want the company CEOs with control, and if they were not blind to the risks, they would not want it themselves.
@_date: 2017-09-17 18:24:21
for your enjoyment the original hodl post 
@_date: 2017-09-07 01:41:35
forget 5 sat/byte, try 10x cheaper: here's a 0.53 satoshis/byte (1 satoshi/virtual byte)  
@_date: 2017-09-17 14:55:04
People have different views of likely long term. Personally I'm holding for  the long term. Generally people say do not invest more than you can afford to lose. Also on top of that if you are not long term outlook you could part profit take to derisk eg if you got to 10x sell 5-10% and hold the rest so you still get the upside. Some people have said things like (long term) bitcoin is either zero or it's huge. That sounds high high risk so you may want to plan accordingly.  If Bitcoin becomes or  already is a big portion of your networth, so long as you don't bank your gains mentality - eg adjust spending habits - I think it can be ok to just keep on HODLing.  But people's financial position, responsibilities and economic environments and risk factors vary - if you over-invested or Bitcoin holdings are good but you'd be in dire shape if Bitcoin goes to zero and there's no safety net around you probably should derisk a bit, eg take some profit but keep upside you can afford.
@_date: 2018-03-19 17:53:16
it could get better 1/10th sat/B :) if Bitcoin gets to $100k/coin basically need that to stand still in dollar terms.
@_date: 2017-09-27 20:16:37
I support faster than light travel too - still we need scientists and physicists to build safe and secure things.
@_date: 2019-01-16 23:42:43
It's not our dish, it's a photo of the same model belonging to someone else so it's at their location not ours.
@_date: 2017-09-16 14:46:44
yes. it is better to have slower transaction clearing than lose money. fast difficulty adjustment presents other security issues around partitions. bear in mind that mining is a poisson process so that even 1hr block intervals are not that rare. for fast, final settlement something like lightning is needed anyway. it's a tradeoff but security is very important, and hodling is protected fine through a temporary slow down in exceptional circumstances until adjustment.
@_date: 2018-02-22 07:23:22
Correct 51 bits is enough in precision. And likely less eg 48-bits or 40-bits, as it would be on a practical basis unlikey and probably inadvisable to send all the bitcoins at once :) even 32bits at current prices ($10k+) that would be $430,000. But see point.
@_date: 2017-09-12 12:48:45
many buy more coins before spending. and keep the change in BTC. as Francis Pouliot said "dont sell more BTC than you can afford to lose"
@_date: 2017-09-19 15:16:58
agree. bitcoin is high risk and short-medium term volatile, do not invest more than you can afford to lose.
@_date: 2017-09-06 16:18:54
its like reddit people scribble on reviews.
the greenaddress &amp; greenbits wallet is a technical wallet for technical users, offers lots of advanced features and good security via hardware support (trezor, ledger) even on smartphone wallts using a microusb cable.
blockstream acquired greenaddress last year.
But the greenaddress wallet has been around for some time.
@_date: 2018-11-14 01:46:12
yes it's a typo, ofc :) perma-bull. I think u/mccormack555 is uploading a few typo fixes tomorrow.
@_date: 2017-09-12 15:20:52
greenbits 2.00 released today has segwith with fee control. (greenaddress had it before, greenbits is the new native version of greenaddress but is catching up on a few features yet).
normal 55c, economy 3.8c, custom 1000sat/kB is 0.9c.  custom it is! got to bid those fees down, too many people with over-estimated fees - estimator bots driving each other up.
@_date: 2017-09-28 00:44:25
yes. yes. and yes i have.
@_date: 2017-09-19 14:49:52
Competition is good and some of that may happen - but it often seems like yesterdays era folks cant adapt, there can be structural or inertia, special interests, and regulatory capture etc that hold them back even if they had intent.
@_date: 2017-09-12 09:47:46
Gif/meme was by 
@_date: 2017-09-27 20:15:15
right but you may lack context that segwit itself was that proposal, people agreed to it - every single reachable bitcoin company, including every NYA signing service company.  this proposal started in aug 2015, oct 2015 it was realised it could be done as a soft-fork. alpha code and proposal presented dec 2015 scaling HK meeting, tech review, companies agreed.  the idea to throw in a double increase at the 11th hour and go back on their previous agreement to move forward with segwit as is, was motivated solely by Jihan/bitmain delaying segwit.  That's not scientific.
There are specific design and code things in segwit that counter-balance the scale load.  That's how agreement on it was reached!
Scale isnt picking magic numbers and changing a parameter, it's about profiling, security tradeoffs and evaluation of centralisation effects.  Centralisation is already really messed up, and I would think the situation with China now probably makes that clear for everyone.
@_date: 2017-09-27 20:18:31
read these threads 
@_date: 2017-09-17 07:56:42
the internet has flow-control and quality-of-service. the real world is not a zero packet-drop, no-contention LAN. as with bitcoin fees - transactions can not be free. hashcash itself was invented because with zero cost people will flood just for giggles and to irritate others (on USENET via remailers, and email spam).
Realise that L2 both competes with and uses L1. So if most retail payments ( &lt;$1000) go on L2, there will be short term less demand on L1.  If L1 gets ridiculously cheap people might lose impetus to upgrade to L2 wallet, then if fees creep up they have incentive again.  This is a positive dynamic. Fees today are mostly high at times because of apathy and lazyiness on the part of services (paying 100x what is needed "because", not doing batching, not doing RBF, not doing segwit, and passing the infllated cost on to users) and some users not upgrading either, and the overpaying fees bidding each other up. Users need to indicate their economic preference for price, and priority or the fee bots have nothing to work with.
@_date: 2017-09-07 09:04:47
Should be able to get lower with batching  according to 
Also single sig is smaller &amp; cheaper than 2 of 2 sig 
@_date: 2017-10-05 15:07:53
HK didnt agree that. the participants agreed to do research and make a proposal for ecosystem and community evaluation to see if there would be consensus. they did that 
the segwit delay was Jihan.
@_date: 2017-09-17 12:19:52
Yep. My other view, which others may or may not agree with, is speculating on pyramid exit timing is a bit ethically grey, for each profit take by one person there are bag holders who lose as mid term they converge on zero sum. New users often mistakenly see allure of buying something with a low price or the idea of getting in early, or haven't yet learned enough to see through the hollow marketing of featureless alts, or app-coins where if the app was useful someone would just fork the coin. Here's an allegory for why alt-coins in general are fools digital gold 
@_date: 2017-09-28 08:16:29
You do realise that upgrades require *software upgrade* either way.  It's not like they have to do that much work.  Francis Pouliot had a consultant get his service switched over in a days work.
@_date: 2019-01-02 16:04:57
you can check the headers from another source and headers are &gt; 10,000 smaller than blocks. see 
@_date: 2017-09-17 15:36:45
sidechains can basically do anything, opt-in and opt-out again while being bitcoin denominated.  and soft-forks are quite powerful.  hard-forks to refactor formats periodically post soft-fork features as proposed by Johnson Lau seems reasonable to me also.
@_date: 2017-09-06 06:57:06
@_date: 2017-09-16 21:05:27
You need to look at periods where 250, 500 and 750kB soft limits were common. There are steps at those sizes (not everyone changed params simultaneously tho).
@_date: 2017-09-17 10:07:18
HODL. if you must day-trade do so with &lt; 10% IMO. HODL proceeds if any in bitcoin. if it goes against you HODL. aka dont sell more BTC than you can afford to lose!
@_date: 2017-10-29 10:24:12
it's a disguised way to pretend it's ok to have Bitmain attack hashrate as they have too much influence, to promote B2X as "real" bitcoin.
I will be shorting B2X hard, buying BTC dips and recommending everyone to not use coinbase until that changes or be very careful to not buy mislabelled fake Bitcoin.
@_date: 2017-09-19 15:29:30
With lightning it seems likely so. But let's start with a target of 100s and work from there - tech progress is incremental.
@_date: 2018-11-15 00:44:11
if anything segwit transactions have the opportunity to be more secure against birthday attack, because there is a 256 bit address hash variant designed for multisig p2wsh. (with p2sh it is a 160-bit hash which if the p2sh is of a multisig with two parties, a birthday attack could hypothetically be created with 80-bit work - which is a lot of work, but exponentially less than 160-bit work implied for single sig. 256-bit ensures that even that case has 128-bit security, which is as secure as 256-bit ecdsa, so then things are balanced.
@_date: 2017-10-26 11:43:05
it will be great - once the fork is done, and another BCH / BTG like spinoff coin created, we can get back to work.
Probably there will be dozens of spinoffs next year too.  I already hear about bitcoin silver.
@_date: 2017-10-01 00:51:30
I think he's trying check this: 
@_date: 2017-10-29 17:46:41
he doesnt have that any more. i believe he's down to around 80k. made too many investments.
@_date: 2017-10-01 19:30:17


It certainly does violate the non-aggression principle!
You're calling "minority chain" something with 10s of $billions economic value held by people who fundamentally disagree with tradeoffs you want to opt-into.  We do not want to opt-in to your tradeoffs and you are talking about coercive activities to force your view.
Why cant you be content to take a live and let live, non-aggression approach.  You just admitted that you do not have any idea which chain has more economic weight:


OK so you wont sell.  But I will sell B2X coins and so will 10s of $billions worth of user investments.  That in itself makes your chain weaker because it will have lower price - you cant express a market opinion without acting in the market!  The market price is driven predominantly by investors not by retail transactions at this point in Bitcoin's growth.
So given that you admit you dont know which chain will have higher value, but certainly it is without dispute that there are many early adopters and users on absolute principle against what you are proposing - then you should be content to act neutrally and let the market decide the relative value - indeed there is basically nothing you can do to prevent this.  You dont even seem to have an economic opinion as you seem content to hold both!
In that circumstances it is simple - original Bitcoin will continue unaffected, and you will create a new spinoff, a clone like bitcoin cash/bcash, but called segwit2x/bizcoin or whatever exchanges and users end up calling it.
You understood Bitcoin a lot less than people would assume if you think miners views decide the protocol.  The market decides the price, and hashrate follows the price.  Both chains will exist.
And therefore it makes sense for the ecosystem, users and the market that we proceed with proper replay protection in segwit2x because it will be split in any possible future anyway, but just at higher development cost.  It is not up to the original chain to add replay protection, because it is far simpler to add it to the new chain, for the simple reason that it does not exist yet, and people using it will definitionally need to upgrade.  To defensively change original Bitcoin to work around your stubbornness will cost 1000s of hours of developer work across the ecosystem, including at your own company - unless you want to forgo the BTC B2X trade and have shapelly take that business.  Then basically every service, exchange, hardware and software wallet has to adapt to avoid chaos and funds loss.  Not a good way to act as a member of the bitcoin ecosystem where your reputation affects business - I for sure would recommend no one use your service.
@_date: 2017-09-17 17:06:18
yeah that was a nice dip :)
@_date: 2017-09-17 10:12:21
because you dont know when the local peak is, just your long term thesis that bitcoin is digital gold and long term target is much higher.  selling all at what you guess is a local peak, can go against you - then you end up holding no bitcoin because you sold it all, and price doubles, never to return.  then you are no longer a bitcoin HODLer or you buy back at a higher price and have 5 instead of 10...
generally day trading a slow exponential random function with high volatility is high risk - statistically you will lose. if you want to guess news-flow do it with a small part like &lt; 10% so you still have 90%+ in long term HODLings if you guess wrong!  anyone who has day-traded regular stocks will tell you news-flow is hazardous, even when you get the news that you bet on, often enough the market already bet further than that so it falls instead of rises etc.  dont forget the market is also trying to predict the future.
and dont buy your speculative allocation in one shot put it in say 3 buckets in increasing size, and start with smallest and set limit orders larger downwards for bucket1.  if that all triggers then wait a bit, re-examine if you want to try the next bucket.  and don't be afraid of a profit take, a profit is a profit - but keep the proceeds in BTC and HODL them don't ramp up your speculation fund.
another strategy to get in, you could be buy a bit so you have a start and then setup a regular buy, just allocate something you can afford monthly and buy to dollar average.
as francis pouliot said "dont sell more bitcoin than you can afford to lose!"
@_date: 2017-10-30 09:32:16
speak for yourself, I work for the greater good of bitcoin, which also benefits me and blockstream because I and every blockstream employee and blockstream itself are bitcoin hodlers.
@_date: 2017-10-05 15:05:16
it's easy to deny parallels: HK discussion participants agreed to produce some research, and proposals for ecosystem &amp; community consideration. they did 
the delay on segwit was Jihan.
@_date: 2017-09-28 23:04:40
I think it's Andrew Quentson.  It's more agenda spun opinion than journalism.
@_date: 2018-02-04 08:41:48
@_date: 2017-09-17 13:48:45
It's easier to increase a soft-limit because it's not a fork, just a local config. Have to find the graph but the graph of blocksizes around soft-limit changes looked stepped. It depends on adaption time a bit but consider fees are free and blocks infinite what do you think would happen? I think the protocol would fail or suffer major problems. TCP has flow-control and quality-of-service and a broadcast base network for Bitcoin needs analogous. In the lab with no packet drops sure everything is peachy but in the real world with attackers, political spammers etc that's the reality. You could push block sizes way up but then that makes bitcoin. Data center only over time and rejects layer 1.5 protocols. Bitcoin is an odd space we have people arguing against innovation that fundamentally makes Bitcoin more scalable so they can brute force bandwidth complexity walls which are a predictable losing proposition. At the margins there are trade-offs but the computer science view point has been proven correct at every step! Bitcoin needs layer 1.5 it will short term reduce pressure on layer1, improve user experience with immediate confirmation and scale to levels not practical at layer1 while preserving bitcoins differentiating characteristics and reason to use it to begin with. 
@_date: 2017-09-06 05:38:10
@_date: 2017-09-30 14:26:28
Blockchain alliance has a website and segwit.party site has a list of companies and BCA affiliation.
@_date: 2017-09-16 14:48:19
it's maybe 2.2MB with todays workload. MAST and schnorr aggregation soft-forks will push it higher also.
@_date: 2017-09-29 19:32:28
The thing is they already did - there was a 2-4MB discussion in Aug 2015. That was improved to soft-fork when that was realised as possible in Oct 2015. Alpha code and presentation Dec 2015, then early 2016 all reachable companies, including each and every NYA participating service company agreed, then there was a miner dev meeting in jul 2016 Jihan agreed he would signal segwit, same in another discussion in September 2016. Then when signalling started Jihan started first a proxy war to delay segwit viabtc and other fronts, then users got annoyed and started talking about UASF then some companies got worried about miners making a fork with UAHF threat written by bitmain, so they met in private in a hotel  room and made a compromise to persuade Jihan to stop delaying as part of that they offered a *second* blocksize doubling on top by hard fork, and before segwit has even been fully adopted. Then Jihan did the UAHF anyway with Bcash, and persuaded exchanges to list it, pumped up the price and bought BCH coins, and is now seen at conferences promoting Bcash as "real Bitcoin" along with Roger ver, another NYA signer. 
Of the NYA participants present in their hotel meeting around half have already backed out, or never signed or promoting Bcash in place of NYA.
The problem is carefully tested software takes time, and people changing their minds, reneging on things they said, playing politics, making compromises that are not theirs to make..  they can do that much faster than software can be engineered.
@_date: 2017-10-15 14:36:23
Reddit is hard to search u/nullc commented on it somewhere over the last week+ 
@_date: 2017-10-04 09:03:07
there's no point - it will be banned anyway, because it is sending invalid blocks according to Bitcoin protocol.  this just *creates* problems for bizcoin2x and wastes bandwidth and leads to a sharper network churn as the B2X nodes get themselves banned in a flurry. u/jgarzik
@_date: 2017-10-29 15:51:32
yes u/nullc had an outline for atomic swap with a transaction constructed so as to be only valid on B2X chain.  However B2X code and replay ideas keep changing with 17 days left.  Which is dangerously rushed.
but atomic swap also wont work if B2X is never created.  the previous atomic swap was assuming no fork no trade. here there is a trade if no fork by 31 Dec 2017 - the sellers(s) keep the BTC paid.
@_date: 2017-09-17 08:02:03
No, the soft-limits are a preview of what happens when accessible capacity is reached.  Users don't care if the space is limited because of a security limit or a policy limit or the lack of best practice adoption of companies. The latter two they can shout at miners or switch service provider to encourage improvements respectively. The former they can shout at ecosystem companies to improve decentralisation best practices, which are *the primary* impediment to increasing base scale.
@_date: 2017-09-27 13:17:27
And yet for your claims about urgent scalability - the NYA core signers, (with the exception of bitgo who actually declined to sign), are somewhat laggards in technology adoption: dont yet have segwit, dont have transaction batching, have weak or bad fee estimation, pass fees onto users in some cases, and likely are not far advanced in lightning preparation.
there could well be a correlation with tech risk as custodians if the laggard aspect extends to advanced security management.
If this pattern is anything to go by they would also probably be least well placed to navigate a non-replay protected segwit2x fork.  Many have not yet adapted to the Bcash fork, and yet passively have so far declined to take their name off a messier, harder to manage non-replay protected contentious fork take2.
This is all typical arm-chair protocol expert thinking.  2x is not strategically useful 1000x is and the only way we get that is with lightning taking retail load. There maybe conflicts as some miners seem to argue for on-chain scaling only, so that they would directly get the fees and maybe fought segwit as a way to delay lightning.  That is actually economically confused.  Also some chinese miners did not like lightning because it improves fungibility.
@_date: 2017-09-30 23:27:37
I am just pointing out the folly of centralising things. skype was p2p, then got centralised and sold to microsoft, now microsoft snoops on URLs pasted in skype. (try it - setup a webserver, make a random hard to guess URL paste it in skype - you'll get a webhit from a microsoft server in redmond).  This is what happens when you centralise things.
There are other things wrong with 2x like no proper replay protection, rushed time-period, centralisation issues it creates, lack of testing, lack of review, no validation of scale claims, no testing of clients, lack of consensus, the process whereby a few CEOs get in a hotel room and decide to "change bitcoin" etc. there's lots not to like.
@_date: 2017-10-28 18:45:25
u/RustyReddit did that 
@_date: 2019-01-16 23:36:52
You don't like those utxo commitment ideas? eg Jonas Schnelli's patch to start in SPV and sync later, modified to start from most recent UTXO commitment in sort-of SPV mode and switch to fullnode once sync completed?
For sure it's a tradeoff so its not a real fullnode until fully verified and synced, but I think it's a quite bit better than a normal SPV-lite node if the commitment is buried by quite a bit of work.
@_date: 2017-09-18 08:42:43
Well more like bitcoin works and we don't need dozens of clones, anything useful can generically built on top.  The clones are mildly harmful because they dilute network effect, confuse users, reduce confidence. - slightly from people who haven't yet learned enough to see through the hollow marketing.  Anyway don't take my opinion - do the thought exercise yourself and think of anything that couldn't be done with Bitcoin as the fee currency.
@_date: 2017-09-17 12:05:19
see this alt-coin graph study 
@_date: 2018-02-01 06:36:41
A well designed system, that more effort went into, is often simple and elegant and people look at it and think duh "I could do that". they don't see the 1000s hours on inferior alternatives and, the failed attempts, the exchange of ideas, and building on insights from each new contributor, nor the 10,000 hours to gain an understanding of the field as table stakes. Bitcoin itself is accessible at various levels, which is a feature but also a contributor to the "hello i'm new to bitcoin and here to fix it" effect, but near full understanding of it's currently understood nuances (which is itself probably incomplete yet) are pretty rarefied.  I think Satoshi didnt understand the full game theory and interplay either, new things are being learned still as it is a new field.
I think if anything bitcoin teaches new respect for the sheer underestimation of dunning-kruger's effect. it's like hofstadter's law squared. Aside from the bluster of the few fake experts bouncing around vying for recognition.
@_date: 2017-09-28 00:44:01
no we are the honey badger. if we do not speak up then users can be misled.
@_date: 2017-09-16 14:33:31
 difficulty auto-adjusts . 
@_date: 2017-10-01 23:11:15
well for one because 12 guys who met in a hotel room now think they control the protocol evolution, and yet as I said are vulnerable to state influence.
but secondly because empirically we know that when orphan rates increase, or various attacks are done exploiting weaknesses related to selfish mining, miners pragmatically defend themselves, and those defences have almost all been centralising.  bigger pools, SPY mining, FIBRE and private links.
@_date: 2017-09-17 12:42:53
It's just my view but I think both clone coins and app-coins trend to zero-sum, no offence to promoters / devs some of them do actual innovation, but I'd sooner see that effort go into building an opt-in bitcoin sidechain and not confuse the market. I think that's where it's going to end anyway.
@_date: 2017-10-29 18:08:53
no. I will double down on Bitcoin by selling B2X coins, and buying the Bitcoin dip. same as always with drama: by the dip, hodl and repeat.
@_date: 2017-10-01 00:40:02
Trace was in Bitcoin quite some time before Roger, and Roger himself claims to have 100k BTC I hear.  I dont doubt Trace can cover 25k BTC and then some.  Besides there are others interested to join, it started as a group buy.
I suggested 25k BTC because I figured u/memorydealers might not be certain enough to go all in, it's a lot of money and people may want to hedge being wrong, from discussion with u/olivierjanss who seemed willing  to get this going that 25% in might be a good balance of conviction vs hedged. u/nullc
@_date: 2018-03-09 15:40:40
asicboost does not make miners faster, it makes them use 15-20% less power.
@_date: 2018-02-22 07:57:36
Generally ZKPs are either unconditionally private, leading to inflation (all possible values possible if discrete log is available to the attacker, and so privacy remains hidden even with complete discrete log break) or unconditionally secure via the argument that there exists only one value that can be hidden (and this will fails in the direction of leaking privacy).  For CT elgamal commitments can achieve the latter.  Bulletproofs have this same property because of the construction of bulletproofs with compression the unconditionally private property is not available.
See also switch commitments by Tim Ruffing which allow you to reactively switch from pedersen commitments to el gamal commitments thus saving space until such time that it may become necessary to use the larger elgamal commitments.
@_date: 2017-09-19 12:39:37
This is all a pretty optimistic exploration of what could happen, and I think all but the most crazy optimistic see fiat co-existing. Most people with managed investment portfolios are currency diversified, so maybe it's another diversification and (super optimistically) Bitcoin becomes the new world reserve currency displacing the dollar.
There are some crazy optimistic people who think fiat may become nearly obsolete, displaced by Bitcoin through a hyerbitcoinization event, and perhaps there are some precedents for a predominantly commodity money world from the centuries where gold was the global commodity money, but the Greece issue with economic policy vs a fixed external currency seems to create similar problems with Bitcoin also - what happens to local economic policy when currency cant devalue to deal with more or less effective policy, and differing raw material advantages or other factors.  One thing that can give is fiat remains (and Greece leaves the eurozone).
So maybe the s-curve tops out before that even in the optimistic case.
Or another thing that can give, a different potential outcome is government policy fades in relevance, with eroded influence of fiat and so economic policy control - my favourite outcome, the snow-crash scenario  local policies become over time-meaningless until this quote makes sense














Another bitcoin-relevant Neal Stephenson near sci-fi this one a short story is  which is available online in pdf form 
@_date: 2017-09-17 07:59:41
This is a bit of a fallacy, it's like that "restaurant is always full, their prices are high" and claiming it's going to go out of business. In startup terms it's a champagne problelm, or a "good problem to have". ie your demand is in excess of your capacity, so get to work adopting best practices, batching, segwit, RBF, fee priority choice, lightning, payment channels and increasing capacity.
At some limit we have to say we're comfortable with company A going out of business and company B eating their lunch because company B offers cheaper faster service by keeping up and reinvesting in technology and company A passively complaining to the ecosystem that they need empty blocks because they dont follow best practices.
@_date: 2017-09-27 20:11:45
for sure that is the case. there's a lot of ongoing scaling activity other than the huge performance improvements in 0.15 there is also as others said schnorr aggregated signatures, MAST, and a lot of hard-fork research - the features in spoonnet are pretty awesome. 
but also we do need companies to do their part in adopting existing scale technology.  Notably any of the NYA signers are lagging on adoption of segwit, lightning, proper fee estimation (bids fees up unnecessarily), batch processing etc.
@_date: 2017-10-15 13:02:58
Yea. Atomic swap. u/nullc talked about it. needs bitcoin 2x properties to not diverge too much between now and fork date.
@_date: 2017-10-12 18:13:38
It'll be fine just slow for a bit, but transactions are not real time anyway unless you're doing lightning or zero-confirms.  As things stand with the futures market Bitcoin would be 20% slower so 12mins instead of 10 average.  (Hashrate typically follows price quite quickly).
@_date: 2017-09-19 11:04:34
along the way $41,000/BTC would be about 1BTC/kilo of gold.
@_date: 2017-10-29 14:46:54
Damn it copied the typo from the tweet and subject uneditable. Anyway it's clear in the text: B2X coins not BCH.
@_date: 2017-10-29 21:11:37
how about we just use bitfinex contract and determination, and expiry date. simple enough?
@_date: 2017-09-29 20:52:37
i'm sure that can be arranged too. lets see if there is any interest.
@_date: 2017-09-18 15:38:50
Erik, miner stats dont mean anything, they have other things to worry about with China and they follow rapidly the economics.  As for users, go ask any users - they clearly do not support it.  Ask developers also near zero support.  Bitcoin is not going away.  So then you are left with another spinoff coin. What is the point?  Is the destruction of value, say price $1000 target if you go through with this vs $10k target if you make nice and act inclusive and collaborate with the ecosystem of users, developers, investors and other companies.  Even if you phrase it as a proposal instead of an edict it will help. Somehow I have been so far unable to persuade any of the NYA signers of basic human psychology 101 that no one likes edicts, a gun to their head.  Play nice it costs you nothing.
There will be a fork if you go ahead, because you will be creating one.  I will not upgrade my node and neither will any users or investors to speak of.  Take the breaking bitcoin conference I wonder what the networth in bitcoin of the audience is - probably plenty - so developers are economic actors also.
Also think about the cost-benefit analysis here - this economic destruction you're trying to bring about - what is the benefit?  2x capacity?  Is it worth it?  If it was 1000x it might be worth talking about but 2x is a blip a tiny constant - easily eaten by demand in months if there is a spike in demand from political events.  Far quicker than it took to setup the rushed fork.
So if you are concerned about scale - and you should be - would you please work with the ecosystem and technical experts to upgrade your stuff.  You're still not doing segwit, are you at least doing batching?  (Even batching can make up to a 5x reduction in block space use per transaction for services).
@_date: 2017-10-26 21:51:08
or a satellite network...
but mainly a centrally controlled medium security 2x spinoff coin pivoted towards retail payments at the cost of decentralisation, permissionlessness, and uncensorability is just intrinsically far less valuable.  And also quite silly because that kind of system can be built on top of Bitcoin (and will be accelerated once the delay crowd are off on their own retail chain).
that's why the futures market is at 0.10-0.15 and why no NYA participants will buy B2X coins, despite a huge public interest to sell them. they do not believe in their economic value themselves.
@_date: 2017-10-11 08:03:43
looks like him. one of the crypto companies contracted him to take photos before, plus bitcoiners raised BTC to compensate for paparazzi inconvenience. maybe he went to the event for one of those reasons.
@_date: 2017-10-30 02:00:06
sure. it's more complex the further out you go. i think bitfinex's covers the only really plausible outcomes during the time-frame reasonably.
@_date: 2017-09-27 13:02:52
why?  segwit2x has no technically defensible rationale - we should evolve bitcoin scientifically and with ecosystem and users agreement only, segwit2x has an unsafe rushed time-frame, lacks proper replay protection, and is not even asking for collaboration - I urged them to make it an open proposal and it seems that they do not wish to do so, and the users and investors will not stand for such a compromise such that even if someone kidnapped every last bitcoin developer, the users and investors would rise up and reject it with prejudice, as they should.  political compromise just encourages people to further political compromise and backroom deals which ends in Bitcoin losing it's differentiating features, guaranteed. 
pivoting to a few CEOs in a backroom change process is antithetical to the continued meaningful existence of bitcoin.  even if they have good intention, which some do, this is just the beginning of the end.  so I say no, and I encourage every last bitcoiner, investor to reach out to them, cancel accounts, contact CEOs and explain it to them so that they dont get stuck in an opinion bubble.
@_date: 2017-09-19 10:26:40
maybe 300 times rare by my calculation. 175,000 tonnes of gold, 31 grams per troy ounces = 5.6 billion troy oz of gold. current bitcoin mined 16.6 million = 300x.
gold is about $1300/oz so gold market cap is around $7.3 trillion, so Bitcoin today would have to be $440,000/coin. given gold mining 2500tonnes/year and bitcoin mining 657,000btc/year by the next halving in 1000 days for bitcoin to be cross total gold it would need $410,000/coin by then assuming &gt; $100k/BTC didn't trigger hyperbitcoinization and pressure on gold price.
@_date: 2017-10-25 19:51:52
I already had my dip buy order in at $5000 :)
@_date: 2017-09-17 12:29:51
My thought is he's quite wrong 90% or more of the innovation is in bitcoin. Large dev team, smartest hard core developers. Nearly all altcoins are wastelands of old copied code, or hot-mess of crash, fork, funds loss. And where there is innovation once it is safe &amp; mature Bitcoin will incorporate it and mid-term provide as opt-in via side-chains.
@_date: 2017-10-04 09:05:36
it's not a "indicate support" it's a protocol compatibility bit B2X is by design and intentionally *incompatible*. it's like starting BIZTP and demanding to send incompatible things on the SMTP port and then wondering why SMTP servers drop the connection after receiving malformed commands.
@_date: 2017-10-01 00:54:59
Trace's podcast is  - you can listen to some of his discussion.
@_date: 2017-09-16 14:16:49
it's a technical comment about some of bitcoin's current design that make it actually quite censor-resistant and why protocol experts argue against multi-gigabyte blocks.
@_date: 2015-04-20 16:12:18
While there are some synergies in properties (public audit, transparency), bitcoin doesnt directly make a great evoting system.  Evoting systems exist - have interesting and important formal properties - its probably safest to just use them!
If a blockchain needs voting for blockchain tracked share share-holder voting, it would still make sense to use the existing voting systems and commit a proof of the vote outcome to the blockchain in terms of bandwidth, efficiency, security, privacy, anti-censorship (of miner dis-favored votes).
@_date: 2019-09-04 00:57:42
sounds about right. 100MWh at 5c/kWh costs $5000 so for $10k bitcoin plus recovering hardware, hosting costs etc.
@_date: 2017-09-19 12:52:27
Bitcoin doesnt have to displace fiat to be geopolitically interesting. You can still rent physical dvds, go to libraries take out physical books, and buy print news papers and magazines. The internet still changed everything.
@_date: 2017-09-12 09:43:34
@_date: 2017-10-01 00:47:05
he was in bitcoin before Roger, promoting Bitcoin on financial news shows.
@_date: 2019-09-04 01:13:09
another way to visualize is about 3000 x 1.5kW miners (at 100W/TH/s aka 100J/TH) running for a day should find a Bitcoin. that uses 4.5MW which is quite a bit of power, the 4.5MW transformers are the size of small room. 3000 miners would be about $2m-$3m worth of equipment.
@_date: 2017-10-05 15:06:38
and yet the polls continue to show.
@_date: 2018-11-06 22:03:24
useful to traders.  it's hard to untangle, but it did seem like 2017 run up fees were in part driven by trading frenzy.  I generally try to low-ball fees but the temptation is there to pay high fees just to get the trades in and with trading the &gt;= 0.2% trading fee, 0.1% wire fee etc is much higher so people are not that price sensitive which can be disruptive for bitcoin payments.
@_date: 2018-11-06 22:09:06
@_date: 2017-10-15 00:21:33
No I want to swap B2x for BTC. I will give someone B2X (if the fork happens) and in exchange they will give me BTC
@_date: 2019-09-06 12:00:52
@_date: 2017-10-01 15:26:12
But that's posture and you know it.
Many of the polls run show 75:25 against B2X and I would expect a higher weighting against if it were $ weighted due to investors with an investment thesis around digital gold and censor resistant payments and permissionless use (all eroded by a few company CEOs controlling a spinoff coin).
I think it is fair to expect if you own something and something new is created that the new thing be opt-in, and not seek to damage holders of the original thing assuming there is a non-negligible interest to keep the original thing.  As there appears to be at least 75% interest then attacking Bitcoiners is unethical on your part.
ps even it were 25:75 the same would be the case. why can you not be content calling segwit2x what it is: bizcoin.  or just dont bother with the distraction and use bitcoin cash/bcash, that's a fairly descriptive and nice name and Jihan already created it for you and it has a bigger block than Segwit2x as a bonus.
Maybe you would like to join Roger in swapping your bitcoin for segwit2x coins 1:1?  To confirm your claimed posture that original Bitcoin support is marginal.  You might be interested to know that Trace Mayer disagrees and stands ready to take your coins off your hands along with many others.
@_date: 2017-10-27 00:34:27
like with classic, 2MB (actually 4-8MB) is just a start, some of them they wanted 100MB but thought it would cause more rejection, once it is underway you can be sure there will be no stopping before gigablocks within a few years. some are even talking about gigablock testing now. it is about roadmap intent, central control, and pivoting a decentralised, permissionless uncensorable system into a medium security, centralised IOU.
@_date: 2019-09-05 18:20:42
tagged  and asked :) 
@_date: 2017-10-29 18:13:45
B2X would be the chain promoted by NYA and a few retail payment companies.
Bitcoin would be the existing chain, regardless of price or hashrate, or attempts to create market confusion by misleading naming of B2X.
@_date: 2017-09-28 22:18:48
that is a pretty good summary there!
@_date: 2017-09-06 06:58:53
yes that is segwit - you can tell because the vsize is smaller than the size in smartbits explorer.
@_date: 2018-07-06 22:11:34
they should generally as it's a better signature scheme, though for basic uses ECDSA is good enough, so probably in non-bitcoin areas of use there may not be a rush to use schnorr.  Note a little known fact is that Bernstein's EdDSA is schnorr also (though over an edwards curve, the ed25519 curve).  It's not as convenient for bitcoin uses, and bitcoin's libsecp26k1 library is slightly faster than ed25519 now I think with all the optimisation that went into it.
@_date: 2017-09-28 00:43:11
segwit2x is not a solution because it results in two coins which creates more damage than benefit.  it also rejects concerns about centralisation, and more detailed technical issues.
point in fact I have worked on scaling solutions, and at blockstream we have multiple people working on lightning also.
@_date: 2018-07-06 13:09:53
or maybe not crypto currencies but blockchain tokenized regulated securities  I guess businessinsider will clarify the discrepancy with the swissinfo article 
@_date: 2018-07-06 11:34:25
@_date: 2019-09-07 22:22:24
has a web hosted minscript compiler  you can try out
@_date: 2017-10-01 21:29:12
Maybe if you or someone else thought about it you could make a physical analogy.
But think about it this way, I and apparently 75% of users on the main forums by polls are minding our own business using Bitcoin, waited impatiently for segwit to activate, which we finally have now, and segwit adoption growth is today up to 7% and growing and we are looking forward to even more scale with lightning real soon now.
Some guys got in a room with NYA and made some kind of pact, 1/2 of them changed their mind or never agreed and some splintered off to do bitcoin cash, but the vocal subset of the remaining 5 or 6 guys posture they can shut off Bitcoin and demand we switch to a new chain.  They say this is "ok" because we have the choice to use their coin instead.  But we dont like their coin, for one it by intent and design tries to put them in charge - and we're not sure if we trust them, or even if we did trust them (and one or two of them are pretty OK guys by bitcoin intent)  we think they're naive and will get pressured by law enforcement and governments because they are centralised, easily identifiable officers of companies.  Secondly it weakens security by creating a worse centralisation problem.  it has many other problems too myriad to go into right now, but suffice to say the vast majority of researchers and expert developers roundly criticise segwit2x/NYA as very badly conceived.
They can make their own spinoff, like bitcoin cash did, but by the non-aggression principle they should not seek to prevent the continued normal functioning of Bitcoin while making their spinoff.
@_date: 2017-10-14 22:16:08
also Belshe is censuring people who critique B2X philosophically but leaving the people heckling in support of B2X alone...
@_date: 2017-09-27 23:51:35
because these companies intend to confuse users as to which is bitcoin when selling it.  if they wanted to call it bizcoin - then go for it.
but also what is the point bcash already exists.  if they want relatively centralised medium security cheap transaction chain, then just use it!
one fork is less PR damage than two!
@_date: 2018-02-04 08:54:16
btw the saving is in the signature, not the public keys.  so if you have 3 of 3 signature aggregation you'll still have 3 pubkeys + 1 sig rather than 3 pub keys + 3 sigs. there is also key aggregation where the public key is aggregated off-chain between the co-signers, and in that case there is only one public key and one signature.
finally in the threshold multisig case, like 3 of 5 say, for efficiency you dont have to reveal all 5 pubkeys, you can put the 3 choose 5 combinations public key sums as the leafs of a merkle tree and reveal that.  this is u/pwuille's keytree signature idea 
there the overhead would be like committed 32-byte merkle root, and as C(8,3)=56 then you'd need 6 deep (2^6 = 64) and to reveal the summed public key, it's neighbour and 5 preimages above that, so in total 7 32-byte values.  At that level it is cheaper than sending 8 public keys. For smaller multisigs you'd just as well send the public keys.
@_date: 2018-11-21 23:53:25
pretty good explainer about how and why of blocksat and liquid/sidechains (and rootstock)
@_date: 2018-11-21 09:31:53
People have causality reversed: when people buy bitcoin they wire transfer money to exchanges. You don't see conspiracies "zomg it's a conspiracy users wired $100m to gemini, $200m to kraken, $300m to coinbase" because people can't see those wires!
Bitfinex just adds transparencey, and of course money wired in preceeds prices increases - price is driven by supply and demand, and more money wired into tether shows an increase in demand and reserve capital ready to buy.  People don't tend to leave USD on exchanges unless they want to buy or trade.  QED. 
@_date: 2019-09-07 22:20:37
the medium blockstream engineering blog article "Miniscript: Streamlined Bitcoin Scripting" 
@_date: 2015-09-06 05:38:55


Bruce I think you're forgetting something - someone else did request this as you know (not me).
Generally I'm with btcdrak on this as are I expect many many people who are too polite to say so.
I really do wish Gavin would not wrap his left-field technical views in the "Bitcoin Chief Scientist" flag.  That has to be intentional and discredits him and the foundation for balance.  I'm with btcdrak on this.
@_date: 2019-09-18 14:46:58
you can do p2p payments in green wallet if you want also with bitcoin, usd tether etc. it's just designed for traders in terms of optimisation.
for long-term secure storage you are better off doing on bitcoin mainchain though because liquid depends on 2/3rds of the exchanges to keep it secure and operate via block-signing hardware with HSMs.
for a trader that's fine because otherwise you'd have single exchange custody risk. but for users for p2p payment or if you want to try out confidential transactions download green for android or iOS and try it out.
@_date: 2017-10-01 17:10:48
But you advocate something asymmetric, try, if you can to imagine that you were to your surprise wrong and weighted economic support is the opposite of what you claim. You just admitted you have no reason to suppose it does not.
As a libertarian should you not abide by the non-aggression principle and not seek to damage other people's investments and preferences much as you would like them not to damage yours?
If by simple and small majority 45:55 in either direction if we suppose it was close, this is a symmetric situation and it is unethical for a service company to deprive one group of their preferences and value.
If you want to persuade people please try. But do not wade in and tell us original Bitcoin won't exist in mid November because you are wrong.
You declined to comment on the 1:1 BTC B2X swap. Are you ready to put your money where your claims are.
As for the polls I think you've seen them for example Luke's poll that uses coinbase KYC api or a number of Twitter polls run by people of opposing views.
PS it does not matter if it is 75:25 or 50:50 or 25:75 non-aggression applies and you are proposing to violate it.
@_date: 2018-07-07 11:07:00
actually schnorr has lower assumptions than DSA. (better proofs of equivalence to discrete log - in theory DSA could be broken without discrete log being broken, where there is a proof that schnorr is equivalent to discrete log). literally the only reason DSA even exists was to avoid use of Schnorr patent, DSA is just worse in every way across flexibility (blinding, batching, compact multisig) security (no proof of dlog equivalence, also stronger dependency on hash function properties), complexity (messier math with /k outside hence lower flexibility, it's less mathematically convenient to rearrange and combine)
@_date: 2017-09-16 20:56:36
Believe more like 2-2.2MB with current transaction types.
@_date: 2017-10-01 01:05:00
oh that's been going on for a while the contrast is pretty stark 
@_date: 2019-09-27 19:48:00
well past that for some. but the right level depends on your and family financial commitments and cash reserves, spending needs etc. plus risk appetite. don't rekt by doing more than you can afford given factors.
@_date: 2015-09-07 22:37:07


I think idea is that this deterrent would encourage miners to respect limits desired by users, ie that miners need a good Bitcoin price so they wouldnt push things too far towards their profit at Bitcoin users' expense or the price would fall as users sold Bitcoins.
That seems correct however I do agree with what you said that there is much friction there.  One way to look at it is miners could reduce block-size to discover the switching cost of users.  It's common practice in cell phone and other networks for competing providers to raise prices to optimise their profit.  The switching-cost being the point at which users jump ships to a different ISP or cell phone provider.  The switching-cost is the degree of inconvenience to the user (eg lose their address book, change their phone number, hassle of cancelling a contract, cell phone company makes it intentionally difficult to cancel etc).  In Bitcoin a risk might be the switching cost could be quite high because there is no alternative, if it's Bitcoin or USD/paypal.  We dont know what the optimal miner profit point is, could be good or bad for users.  What's the switching cost in a natural monopoly like a global currency.
What seems fairly sure is that this gives quite a bit of control and pricing discretion to miners, and that miners are not necessarily in direct alignment with users or eco-system companies.  On the plus side it's fairly simple.
There were some other variants that proposed a user-vote also, which seems perhaps more balanced.
@_date: 2015-09-08 15:49:10
Right.  Miners are very influential.  But they cant easily override consensus rules that the majority of economically dependent full-nodes insist on.  Now if miners became very aggressive they could do things like coordinated blackmail: censor all transactions until people did what they want - but that's pretty overt and bad for Bitcoin and therefore for their mining revenue, so they'd hopefully be hesitant to do that.  Users do have another reaction if things got there: change the hash function rendering miners ASICs valueless.  Both of those outcomes are extreme enough to seem unlikely to be used.
As says therefore it really is that consensus is set by the economically dependent full nodes.  I am not sure if agrees, maybe he does or maybe not, this suggests not but is somewhat old and also ambiguous.
It's a pretty big factor in deciding what is safe to change about the system.
@_date: 2017-10-14 22:15:07
offering B2X BTC 1:1 swap. 
@_date: 2015-09-07 23:04:05
invitation for moderated  v  tech discussion
I believe Trace Mayer will be in Montreal.
@_date: 2015-09-30 22:42:31
Yeah I wouldnt call myself a core-dev though.  Sometimes journalists guess.
@_date: 2017-09-15 08:50:25
the BC changes look like all upstream - ie imported from core based on author.
@_date: 2015-09-07 22:00:27


A number of things about Bitcoin should indeed be like the laws of physics.  The supply of coins.  The properties of being permissionless, policy neutral payments, security, no blocking/seizing/revoking.
The enforcement of those properties requires Bitcoin to be decentralised.
I am not sure you agree with all of those things (eg the red-lists proposal you made).
Also you tend to be not so concerned about decentralisation, or at least Gavin does not seem so concerned about decentralisation.
I think this is why you reach different conclusions to the other developers - a different assumption.
When smart people reach different conclusions it's usually because they have an unstated different assumption.  I think therefore it would be more productive to focus discussion on the input assumption.
Discussions based on different unstated input assumptions otherwise risk getting circular or non-technical in nature.
@_date: 2015-09-05 20:34:04


Side-chains are not primarily a scaling technology because miners have to receive and validate transactions even if the Bitcoin transactions are grouped into subnets (main and sidechains).
One advantage of sidechains is ability to more easily make invasive changes or hard-fork changes.  Confidential Transactions being one example.  Most of the side-chains alpha features could be back-ported to Bitcoin core however some would require more work to soft-fork.
Another potential with side-chains (or extension-blocks) is that we could have opt-in subnets of Bitcoin that make different security throughput tradeoffs.  In that way potentially bip101 like parameters could be used in one subnet and various values tested for markets that prefer different tradeoffs.
Side-chain and extension block security has a number of trade-offs and options, but is different to Bitcoin-core slightly.  For apples to apples comparison it should be noted that Bitcoin core adopting a prematurely large block-size would also have security implications.  People who are comfortable with accepting security risk to get a moderate throughput increase may like the side-chain tradeoff.  If cups of coffee range of payments adopt such a chain it's a step forward from all using a hosted wallet or whatever happens today.
The main thing people are really complaining about is the question of pushing the block-size to a poor security / throughput position with no opt-in choice for users who prefer Bitcoin's ethos features.
Centralisation of the development process would also be a related risk.
I do think if we changed Bitcoin block-size too high immediately it would create security and decentralisation problems.  I also think that has different views about the importance of economically dependent full-nodes being essential part of Bitcoin's security model in setting the consensus rules.  If I understand both and are more relaxed about an ever shrinking ratio of economically dependent full nodes, which to my mind risks building paypal 2.0.  From what says I think he thinks it is more important to increase throughput and create free transactions with excess capacity to drive adoption and use-cases than for Bitcoin to retain policy neutrality etc.  I dont think has given up on red-lists and adapting Bitcoin to hierarchical and policy influence.  
Feel free to contradict me if you think that's inaccurate, but I truly think this misunderstanding and optimism about the side-effects of centralisation is why and arrive at different proposals to everyone else.
When smart-people disagree there is usually an unstated different assumption.  I think this is the cause.
@_date: 2015-09-05 20:02:41


This is false. Bitcoin contributors and core who founded Blockstream have done many things to change, scale and improve Bitcoin before and after co-founding Blockstream.
Facts: versionbits, BIP 66, fixing the 4th july fork, the openssl security defect, work on RCLTV, libsecp256k1.  I mean please?  You could look in github and see what you are saying is just factually incorrect?


Would you care to enumerate who these long term participants of the ecosystem are who believe that anyone at Blockstream has "bizarre assumptions like the Bitcoin network being unchangeable".  
I understand there are differences of opinion about scaling Bitcoin - that you and Gavin are not so much concerned about security &amp; decentralisation, so you reach different conclusions, but please lets discuss accurately.  I suspect a face 2 face meeting is more likely to arrive at clarity of input assumptions and from there the best tradeoff to scale Bitcoin.
@_date: 2019-09-10 21:16:53
the hash output is effectively a random number. while it is one way, that is not important here, what is important is that it is hard to steer a hash output more cheaply than brute force to have a special form. the special form chosen since hashcash v1 (superceding v0) thanks to a 2002 suggestion from Hal Finney is to have lots of leading 0s in the hashoutput. think of it like throwing a bag of 256 coins on the ground lining them up and needing the first 75 to be tails. they land deterministically but you can  it unpredictably by changing a counter, so the only way to find 75 leading 0s is to try 2^75 times, which is a lot of times 60 billion trillion times (within 10minutes average).
@_date: 2015-09-05 20:42:27


Actually I think says that you did urge him to fund Lightning.


But that's a non-sequitur because no one has argued for freezing the Bitcoin blockchain (apparently OED now says that is a word!) and a big part of the interest in side-chains is to prove out and test features for back-porting to Bitcoin, and the people you are accusing of freezing Bitcoin did a big portion of the major feature and BIP work on Bitcoin core since co-founding Blockstream. 
@_date: 2015-04-23 00:22:31
Still unclear to me: if the wallet name is intended to be private, how is that privacy ensured by putting it in DNS (secured DNS or regular DNS - DNS security is about auth not encryption)?
You mention an name to address lookup, however addresses are not supposed to be reused.
You mention BIP32 (towards combatting address reuse), however end users with smart-phones arent running an introduction service, and many payments are non-recurring so BIP32 doesnt help there, and DNS cant readily be used as an introduction service because BIP32 needs the chaincode to be private, and to hand out a different chaincode to each recipient.
@_date: 2018-07-06 12:06:03
@_date: 2017-10-01 19:44:17
75% of polled users vote against B2X.
However you did not answer my comment that weighted by economic value, the percentage is far higher.  The GINI coefficient is not great - the conference attendees and early whales can more than counter the tiny bit of flow through pressure (on a relative level) from retail payments integration at bitpay for example - and they seem to have gone to Bitcoin Cash anyway!  Along with Jihan who started Bitcoin Cash and is propping up the market, selling miners only for Bcash etc.  How is he supporting NYA?  He's at conferences, along with your friend Roger, saying that "bitcoin cash = real bitcoin"!  You keep talking confidently and with aggressive bias but the basic facts are not supporting your story in reality.
@_date: 2017-10-01 23:07:44
I think even if 25:75 were the case it would be a violation of NAP to attempt to damage the normal operation of the original chain.  or if it were 10:90.  bitcoin users do not owe the people that want to opt-in to a new more centralised controlled bizcoin their agreement.
bticoin users who prefer the existing chain have a right to continue doing so.  and it is aggression to try to seek to deprive them of that right.
@_date: 2015-09-16 02:50:09
Not quite, the flexcap proposal is a soft-fork.  However the downside is it is somewhat complex 
@_date: 2015-09-18 14:55:02


Yes I was not commenting on flexcap, just replying to the claim that "All proposed solutions require a hardfork" by to say technically you could increase the block-size with a soft-fork too, eg with extension blocks or similar proposals (just that it is more complex for now).
@_date: 2015-09-07 22:10:46


So it seems you maybe do understand how Bitcoin transactions can be cached in Lightning.  It wasnt clear from what you said before.
My point is a Lightning transaction is a not-yet-published Bitcoin transaction.  Each LN transaction could be posted to the blockchain if there was an economic reason to.  There is typically not a reason to because you are guaranteed to receive your money without doing that.
Maybe it would be simpler to start with the micropayment channels that and worked on.  They work in a similar way except are uni-directional and not initially proposed to be routed via a hub.  (Though they also could be).
Do you consider them to be inferior to Bitcoin transactions too (if the usage pattern meets the use case)?
@_date: 2015-09-05 20:22:55


Bitcoin core and contributors who co-founded Blockstream also have done a lot of work in bitcoin-core.  I was more imagining Bruce Fenton was talking about that core work, though I did not hear anything other than what was posted publicly by the Bitcoin Foundation.
@_date: 2015-09-07 21:38:52
The swiss have a card game called Jass, which has a unique feature that you can invert the order of the cards.  Get a hand with no picture cards, no problem you just bid Unden-ufe (lowest card has highest value).
At times lately with all the down-voting I take it as I must've said something good to instantly get into double-negative votes :)
@_date: 2015-09-02 06:17:37
You realise a soft-fork like BIP 66 took 6months to activate.  I think we can afford a few weeks of discussion and then some testing.  No need race to discard better alternatives because "time".
@_date: 2015-09-02 06:31:25
Actually I did not say that, you calculated it but anyway you are ignoring also flexcap by and to try to make your claim.
Again I say your claim is factually incorrect.  I myself proposed a schedule running to 8MB within 4 years, which is the maximum the Chinese miners said they would feel safe for orphan rates given their network latency. 
@_date: 2015-09-08 20:30:08


I dont think miners can change the rules even with 75% hash power, though it is a grey area at the fringes of blackmail etc.
Consider miners tried to do something unpopular which constitutes a change to consensus rules: changing coin supply to 50BTC/block to reward themselves.  This detectable to full-nodes, they would automatically reject it, so what would happen if 75% of miners tried to force it is from the full-nodes perspective the hashrate would drop to 25%, and they would ignore the hashrate majority because it was invalid work to their code.


They could but that is a system level attack that impacts the value and security of Bitcoin.  Bitcoin price would fall if they grouped together and did that, and the value of their ASICs would also fall.
If the system is reasonable decentralised because of the selfish interest to profit it would be unlikely they could achieve private agreement to do an attack like this - miners could break ranks and mine honestly instead.


A full node could maybe warn that there were deep reorgs, but right by valid longest chain rule this would be within consensus rules.


For 51% attack you are right.


Right.  But I think the more central attack is changing consensus rules, and there the full-nodes do set the rules effectively.  (The 51% attack is a separate attack and if that were to happen the system is in big trouble such that basically miners have gone rogue and destroyed the system almost - time to change the hash function and remove them current batch.  Even that is a pretty extreme and risky move - changing the hash function - so it would not be done except in the most extreme circumstance of system failure I think).
@_date: 2017-10-12 18:16:08
I dont see any scenario where the Bitcoin chain does not continue, at all.
Hashrate follows price.  Futures showing that B2X is at 20% and falling by price.  So hashrate should be no problem.
Even in some outside scenario in either case there will be things that can be done either wait with slower transactions for a while, or adapt something.
If there is a shortage of transaction capacity also high fee urgent transactions will cause miners to mine blocks again.
@_date: 2015-09-02 06:15:09
Hi I thought the letter was relatively bland personally it does not propose or vote for a given proposal, it's just about saying lets be constructive here and work through the technical questions and get to a solution everyone can upgrade to via consensus.  The selected solution after testing might be BIP100 or a safer variant of it that achieves similar effects at lower risk, or with better balance between user votes and miner votes say.
We're far from done with BIPs nor analysis, testing on real networks, or measuring the UTXO scaling characteristics of larger blocks, thinking about DoS or other security risks.  So it's IMO unfortunate and premature that some in the media have reduced it to a BIP 100 vs 101 binary / populist or full node or miner "votes" or polling.  There are other proposals 102, 103, flexcap and simpler variants?  To get to a good outcome each of these should be considered and compared, and some testing.
@_date: 2019-09-08 00:49:56
there's also this video presentation by u/pwuille at SBC 2019  about miniscript
@_date: 2015-09-02 06:20:02
Do remember to quote posts you reply to with &gt; as


to prevent the recurring phantom deleted post attack.
@_date: 2015-09-05 19:28:43
@_date: 2015-09-27 19:50:03
Yes this is true, see the confidential transactions podcast, and explainer text from Greg   I proposed CT (called it homomorphic values) in 2013 on bitcoin talk   and optimised and generalised the crypto algorithms and implemented it in sidechains alpha.
It's already implemented so zero time :)  However thats in sidechains elements  with testnet coins, to soft-fork things into Bitcoin adds work, and there is a space tradeoff.
I would say absent a big part of the bitcoin development industry being massively distracted by the block-size debate we might have been closer to having more compact CT.  I certainly would have spent several months working on it.
Unfortunately as someone noted the original compact CT paper (by was broken by He's also been working on repairing it.
@_date: 2016-10-05 22:09:17
@_date: 2019-09-05 18:12:54
that is a good idea - ERB youtube channel is more general audience and has 14mil subscribers. Someone could ask 
@_date: 2015-09-30 19:53:03
So here's a proof that larger blocks reduce decentralisation: if one makes a 1GB block, very few miners can validate blocks for bandwidth, cost and CPU reasons, so there will be less miners constructing their own blocks, QED.  (That is the principle the rest is scale and balance).
@_date: 2019-09-07 22:00:02
see also previous thread from a few weeks ago discussing the miniscript compiler  @_date: 2015-09-06 05:19:34


Actually no, one side tried to bypass and replace the review process, spent most of the energy on web pages, blogs, media.  The other side wrote code and acted in good faith.


the answer is to act in good faith and work for a reasonable incremental compromise between the interests of users, miners and ecosystem companies.
@_date: 2015-09-07 20:30:32
 audio only, probably slightly better audio.
@_date: 2017-10-30 09:27:51
Yes that's exactly it re Trace group buy and Roger.  Could have been more but 25k would a bit over 25% of Roger's holdings so I thought if he believed it he could still take it and be hedged that he'd still  be a big holder if he was 180 degrees wrong.  Its 50k BTC looking to dump B2X across not too many people. There a wall of sell for B2X and it's committed to dump that's just a few people who pinged me. Each B2X supporter I talk with is a fence-sitter "not sure I will hold both" this is how you get rekt in the market. The sellers drive the price down then the fencer sitters panic sell.
@_date: 2015-09-26 23:10:58
I think there could be something to be said for a global permissionless micropayment system for internet protocols.  Fiat just doesnt work that well internationally and the permissions might cost more to setup than the life-time value of the transactions for tiny low value devices.
But agreed that cant work directly on blockchain due to scale - lightning network might be able to offer the needed scale, and with more "sovereign volition" (as you put it) than needed, but that's ok.
@_date: 2018-04-22 15:30:38
seems like
@_date: 2015-04-24 17:56:12
So what about Melanie Shapiro, PhD CEO of  bitcoin hardware wallet.  Some of the people on that coinfilter list arent even bitcoin related - like altcoin promoters!
@_date: 2015-09-04 04:32:07
Mining is a commodity economics situation, meaning profit tends to be low and go to the most efficient operator.  Say mining 25btc costs 24.75btc to a quite marginal operator.
Block transfer &amp; validation time affects orphan rates.  A 1% higher orphan rate could make this miner unprofitable, then they stop mining and leave it to people with lower power and equipment costs.  There are economies of scale so that people who get squeezed out tend to be small players.
You might like this paper by bitfury  that tries to estimate what percent would leave the network at various block-sizes.
@_date: 2018-07-06 11:36:16
I think this is pretty big. The swiss wealth management and private banking sector holds 1/3 of global offshore wealth. This is the first major reputable stock exchange to offer crypto trading. SIX also is the stock exchange that lists the Bitcoin ETN issued by vontobel private bank. Game on switzerland! The swiss market is accessible globally to professional investors and retail if they seek out assistance from brokers.
@_date: 2015-11-05 16:24:36


This really needs to go in a FAQ.  BIP 103 code is in the BIP text.  Yes thats the full code it is rather short as it is just a parameter change.  No it is not pseudo code, you replace that function in bitcoind and recompile.
@_date: 2015-09-29 04:14:29
Note it's not quite an apples to apples comparison because CT transactions provide more privacy per transaction.  Therefore to the extent people are doing things to aim for privacy, they may eg coalesce multiple non-CT tx into one CT tx.  There are some further optimisations possible with conservative CT, which would be my preference.  eg doing the exponent separately from the mantissa (which is possible and described in the bitcoin talk post) and reducing the range, and other math compression (possibly) and tracking the maximum range (no point providing more precision than is possible based on known input range maximums).  That last one may not be so important IMO as if CT is the default, then the range will soon become maximal.  And you want that for privacy anyway.  ps You can also prove things about ranges for application level in ZK: eg payment is over X or payment is under Y or in range X-Y.
@_date: 2015-09-10 11:06:37
I think what happened is timing.  Lightning &amp; sidechains/extension-blocks/other extension mechanism are a year or two out, and projections can, not implausibly, be claimed to show scale might be an issue before then (particularly given the added uncertainty because it takes 6mo to deploy out a soft-fork, presumably similar or more for a hard-fork).
That's why I think BIP102 or my similar 2-4-8MB over 4 years to create space for those innovations to play out and re-assess scaling after that.  Otherwise we risk creating long-term unnecessary centralisation risk.
I suspect a simple, short-term (2-4 year) plan is least controversial as it involves caps (2MB or 8MB) which are viewed as safe-enough by Miners, by Gavin's own tests etc.  Otherwise we take a long-term gamble into the unknown which stores future scaling or centralisation risk (we wont know what until we see how Lightning &amp; extensibility &amp; decentralisation initiatives fare).
I do think it is in everybody's best interests and for Bitcoin to remain decentralised, both in payment policy neutrality and in development decisions - anything else is a insufficiently considered risk, and raised controversial issues.  To succeed and reach consensus we need to to reduce controversial issues, not scrap over too-long term or too-fancy plans today.
How about it Reiterate offer to go on podcast moderated by  to discuss constructively and with answers not generalisations.
@_date: 2017-10-29 17:48:18
I did! I did a group buy with Trace Mayer and others, for privacy, but Roger wouldn't buy - went radio silent.
@_date: 2015-11-14 17:30:52
Identity for miners makes the side-effects of centralisation worse, it is a principle that bitcoin participation should be permissionless and so identification of miners is intentionally not required.
That does mean you can not strictly measure the level of mining decentralisation.  But think for a moment if they were all identified - it would also not solve the problem, because, as now, they could if inclined use multiple identities on the network.  (I say now because we do have information or measurable information such as hash-rate of pools and miners, self-reported or measurable against the IP address announcing the block, and by being miner of a wide range of pools and seeing which blocks announced correspond to which.)
@_date: 2015-09-07 20:08:00




if the payment layer is a hosted wallet like coinbase, circle etc then yes you are trusting them.
If the payment layer is like micropayment channels that worked on with or lightning by then no, those things are offering you direct ownership of coins like Bitcoin does.
@_date: 2015-11-22 04:43:44
Decentralising development is something everyone agrees with.  Peter R says illogical things though about how to decentralise it.  Like well everyone can run random competing consensus algorithms and see which win.  (Err, no, consensus algorithms dont work like that).  And then he assumes well hopefully someone will chicken out to avert disaster.  That's kind of like deciding which side of the road to drive on by playing a game of high speed chicken: it invites disaster.  
And I guess he's also now arguing that unlimited blocksizes will arrive at a market equilibrium block-size.  However that ignores the selfish mining attack, and what can happen there is a single pool creates blocks that none else can validate in time and the network becomes 100% centralised.  Peter R would probably argue it's ok, it's an equilibrium or that maybe they would have enough self-interest to not do that.  
Sure everyone understands all this stuff but it's not useful.  Bitcoin aims to provide more security than meta-incentive only.  I mean if we were to weaken the security target to meta-incentive only, for sure we could do a lot of things to simplify and scale.
@_date: 2015-11-22 02:41:33


Well if there is no mining then there is no cost to fraud and so security is lower, it's much closer to the status quo; also depending on what a private blockchain means, maybe they dont provide full node audit assurance to users either.  So yes mining does have value.
@_date: 2015-11-05 16:52:17
They do and I wouldnt want it any other way.  But on the flip side you have to act in good-faith, counter technical arguments with reason, and not engage in censorship.
If we both want success here, a bit of professionalism, politeness and assumption of good-faith is needed in all directions.
@_date: 2015-11-23 02:51:15
No intent to bamboozle you for sure - I thought you were questioning if it's possible - the top OP was mostly a "please feed me more information" so I was still in that mode of thinking.  No dispute that there is work to do, but I think the "it's possible" is fairly widely accepted.
edit: btw I wasnt sure what you meant about 60days.  The lightning paper was published in Feb (now 8months ago) if that is what you were referring to.
@_date: 2015-09-05 19:56:15
Actually I think you would see if you looked at a graph of github over time that wrote code in bitcoin-core over the entire period, except while on holiday and perhaps for a few weeks during a crunch to get finish sidechains-alpha.  and also did core work (code, and review).  has always done a lot of review work.


I dont think this is correct.  If one were inclined to spend cycles disproving your guess here one could look up the github accounts and see how much code they wrote before and after joining blockstream in bitcoin core.
I do think productivity on core and anything else in the industry has dropped off a cliff since technical discussion was moved outside of the technical forums.  Different people react differently to hostility and politics.  Some enjoy a fight and write dozens of blogposts, media appearances, spend most of their days talking to journalists and others unsubscribe from technical forums and stop reading &amp; contributing to github and stop participating.  Neither are good outcomes for Bitcoin.  Some of these people are basically irreplaceable and their absence puts Bitcoin at technical risk.  The people who were not writing Bitcoin core code (yourself and Gavin much lately) managed to stop most others writing code also!  (If you want to talk about cause and effect, and code statistics).
@_date: 2019-09-27 19:44:48
yes due to more segwit use. i think the biggest was 2.3MB
@_date: 2015-11-20 15:46:36


That is exactly what we are working on at blockstream - to extend Bitcoin in a scalable way to enable faster pace of innovation with sidechains.  (As well as scaling underlying Bitcoin directly and via lightning).  So I do not agree with your views on Bitcoin.  I find Richard Brown does a pretty balanced and very professional job of evaluating technologies and commenting on them.
I think Bitcoin's network effect and security ultimately will win out and demonstrate their value over private chains that lack public auditability, are not open to innovation.  People tend to use the observation that what unlocked the pace of innovation on the internet was the open permissionless nature.
I also think a major part of the value of Bitcoin is the automation of trust management.  I suspect that some of the banks are under-estimating the value of that, and have not yet considered the interoperability dimension.  Financial networks are very interconnected, people are building financial instruments from each others products and moving assets and instruments around.  If the only way to move an instrument is a legal contract, that kind of voids a fair bit of the point of blockchains.  I view sidechains as an interoperability and internetworking mechanism for extended Bitcoin.


I think you should read more and learn more about the tech before you jump to emphatic "that's impossible" conclusions.  That's like declaring what the internet cant do in 1985 or something.


Bitcoin can already do everything ethereum can do or will soon - rootstock.io for example.  Dont confuse the network with the smart-contracting language.  Sidechains allow interoperability and building instruments in different smart-contracting languages and moving them between chains and combining them.
I also dont agree with your characterisations about core development.  Core just has more resources, more skilled programmers than any competing system by an order of magnitude.  The rate of technology progress speaks for itself.  I would encourage you to be more professional in your online interactions.
@_date: 2015-11-08 15:59:48
aka "Cypherpunks write code" (unknown? maybe Timothy C May?)
@_date: 2015-11-22 19:37:47
Seems like in your own thread people from the review committee have answered you adequately?  AMiller owned up to prematurely suggesting your proposal might be accepted?
And corrected your incorrect claims that it had anything to do with Greg Maxwell.
All cleared up now?  Do you need someone else from the review committee to comment?  They said 40% of proposals were not accepted due to receiving too many high quality proposals.
@_date: 2015-11-09 11:55:55
I think there are multiple things: downvote brigades (eg wanting to suppress different views?), normal voting, and systematic abuse (bots for automated voting via multiple accounts, bought accounts with deleted history, stolen accounts, karma gaming via deleting posts).  Some of that stuff is bad-faith, some of it is just human nature side-effect of an imperfect voting system.  Voting is good in principle but in practice can see downvotes of quite well argued posts and upvotes of trollish comments depending on which point of view has more voters, even without bad-faith.  It might be better if voting was just turned off for r/Bitcoin for example.
@_date: 2015-11-22 19:08:17


It's quite puzzling and I am not sure who among the reviewers would be making such claims.   I have not seen your paper.
I dont see why anyone should be concerned about results, makes no sense to me.  If results are good, secure and practical then maybe Bitcoin can adopt them, if they are not practical then at least it informs the applied research and maybe someone can extend them to make them practical.  If someone breaks the results, we've still learned something.


As far as I understand the moderation policy does not discourage discussion of ways to improve Bitcoin.  Also there is the sticky topic where you can post anything related to "governance" and "controversial hard-forks" topic.


News to me.  You want to tell me who you think said this (offline if you prefer)?  Do you have any evidence?  These conspiratorial claims are getting increasingly outlandish so some actual evidence would be really nice to see.
@_date: 2015-11-05 12:44:03
To be clear, as that was probably ambiguous, I was saying it was ironic that the parent post got downvoted.  (I upvoted it)
@_date: 2015-11-05 12:54:54
I have at this point taken reward from negative clear insta bot votes: it means I wrote something insightful that the bot / brigaders were afraid others might see and be influenced by.  Insta -30, wow I managed to say something clear and useful.
@_date: 2015-11-19 20:23:44
I think you may be misunderstanding something about the relationship between lightning cache and Bitcoin.  Each lightning transaction *is* a bitcoin transaction, and it stands ready to be posted to the blockchain in event of dispute.  So lightning cant provide smart-contract features that are not in the Bitcoin, but it does provides all features that are expressible in Bitcoin script, and it is the same script language.
It is just a write cache for Bitcoin transactions, the smart-contracting features are unchanged.
@_date: 2015-11-04 19:56:52
It's a bit more than that, it's an extremely robust and simple argument.
@_date: 2015-11-11 17:34:51
I think the panelists and Andreas got through a pretty informative discussion.  There was some other discussion of tradeoffs in presentation  eg facts and figures and trends about new-client sync time, mining block relay &amp; validation latency (and orphan rates), SPV mining implications etc.
You may want to watch the live stream of the hong kong scaling bitcoin workshop coming up on dec 6-7th.  People are busy implementing, testing BIPs and I think the technical and business community will be happy, and as I said above I think a number of practical scaling and improvements will come out of that and the overall Bitcoin development process.
@_date: 2015-11-08 14:54:24
"Actual ownership" sounds like a clearer way to express Trace's "Financial Sovereignty" ie gold or *bearer* electronic cash like a bearer bond, or a wallet full of fiat currency, or a piece of gold.  But better because it's non physical.  Or digital-gold as Szabo says "bit-gold".
@_date: 2015-11-05 10:13:08
I dont think you are taking into account the selfish-mining attack.  Unlimited block-sizes can be used to exacerbate that.
@_date: 2015-11-08 13:31:39
Yes probably but it's still quite misleading and not what the question asked.
@_date: 2015-11-05 09:54:54


Agreed, but that is not where we are.  Many people and businesses who could and should run economically dependent full nodes for their own or their users security are not.


bitcoin security depends on miners being decentralised and economically dependent fullnodes being decentralised.  (Economically dependent full-nodes enforce consensus rules on miners and users).
If one factor is decentralisation weak, we have to protect the other one even more.  Or to explain it a different way:
A. we can ideally have high mining decentralisation and high economically dependent full node decentralisation.
But if we can get by with:
B. high mining decentralisation but weak full node decentralisation or
C. high full node decentralisation but weak mining decentralisation.
D. weak full node decentralisation AND weak mining decentralisation will I expect end in centralisation failure.
We are somewhere between c and d.  You seem to argue because mining decentralisation is weak we should abandon the only remaining check and balance: full node decentralisation.  That is the opposite of what we need.
The explanation of where we are can be found here:
@_date: 2015-11-07 21:51:38


There are a few flexcap proposals some of them are online already.  I think it's interesting particularly the bursting to deal with transaction demand and that miners can pay for that increase and make a profit.  (That also avoids people filling blocks with pay to self free transactions to game the system eg with selfish mining related attacks).
@_date: 2015-11-10 19:52:04
Clearly, but also they are not affected by validation nor transfer cost for their own blocks.  Due to selfish-mining that can create an incentive to do this.  I explained it here:
and here:
@_date: 2015-11-05 09:36:32
"delay verification mining" is not a good idea, it damages SPV security.
@_date: 2015-11-04 23:45:49


OK, let's talk about these counter-points:


For security you have to consider byzantine attackers.  Note miners can fill blocks at no cost.


Well that's a good question.  People have argued that ability to fill blocks at no cost would amplify the selfish mining attack   A related concept is that you are not at orphan risk when you mined the block - so bigger miners are at an advantage.  
@_date: 2015-11-22 04:06:28


I consider users involved if they are assets they own.  So then what you said was ambiguous.  So apparently you did mean a private but shared ledger, fair enough that is conventional terminology.  (And apparently you dont consider owners of assets are involved or need to have integrity assurance beyond "trust us".;)
If you are talking only about sharing ledgers between institutions that  can deliver some value to the institutions in cross-audit but is limiting in a number of ways as to what it can achieve.




You know blockchain is a word that came out of the Satoshi white paper so...
I think I'm pretty capable to think laterally about what can be achieved in a variety of models and how they interact.  (I know some people learned about consensus, public key crypto, merkle trees, proof of work etc from Bitcoin, but I am not one of them).
I think it is prudent to use blockchain compatible formats and tech so that PoW can be opted into later for additional security, for interoperability and so that integrity assurances are global and transitive rather than pairwise between trusted parties.  I do see a bit too much emphatic pronouncement about the future, and I dont think anyone fully understands the implications of secure tokenisation (which relies on mining) and smart-contracts yet.  So by all means start with a private shared ledger but I would not recommend locking yourself into an approach that is unable to interoperate with a blockchain world.
@_date: 2015-11-22 04:38:00
Yeah.  But only in a pathological failure sense!
@_date: 2015-11-08 10:33:23
I think Gavin was OK with 2-4-8 as a compromise fwiw.  Possible.  I think some suggested using BIP 103 exponential scaling at Cisco bandwidth numbers after year 4.
@_date: 2015-11-04 20:44:47


Bitcoin has an overhang of centralised control risk.  


When you are building security systems, you dont shrink the key size to 40-bits and then claim that no one would attack it, you design for security so it is robust against attack.  I think it's naive to imagine that no actor with power would ever attack Bitcoin.  If there was a bitcoin.com (like a company like napster) Bitcoin obituaries would have had one entry and it would have been permanent.  eg the silk road or something like that.


I have argued for accelerating velocity using lightning.  There is a fundamental tradeoff between decentralisation security and scale.  We should aim for a sensible balance, not an extreme - in either direction.  But we do have to understand the state of centralisation, be aware of the risks, and not fall into the trap of Schneier's Law  by being unfamiliar with security engineering.
@_date: 2015-11-08 13:29:06
Personally what ever it is, I think, and my advice to him is come back to Bitcoin and spend more time coding Bitcoin stuff.  Engaging in political activities, as seems his inclination, makes you another policy wonk or activist, which is good work and I strongly value the work they do and all, BUT there are other activists: working on Bitcoin as a talented coder magnifies your impact a thousandfold, and is infinitely more likely to result in making a positive social impact.  &lt;EOM&gt;
@_date: 2015-11-08 16:35:58
I think something like flexcap can take care of that.  See 
Also I think you may have missed the point of sidechains and lightning - they build on top of Bitcoin.  People have said things like a sidechain is like HTTP ontop of TCIP.  Not sure that is super analogous, but the point is it is compatible and allows extensions.  Lightning adds scale (integrated write-cache module).
Not sure if there's a good analogy, but maybe someone arguing we should have GB MTUs (size of an IP packet) to support video - not necessary, we can stream stuff in fragments vs we can do things on Lightning or side-chains.
@_date: 2015-11-22 17:25:39
Well do explain how you think an unlimited blocksize would be secure against centralisation and amplifying the selfish mining attack.  Presumably it could be explained in less words than your post.
Next you seem to divert into some areas which I'm not really so interested in.  I prefer to focus on constructive technical review and proposals.
If your paper was not accepted you have to take it up with the review panel - have they not commented on your public complaints or private inquiries?  I am not on the review panel.  
@_date: 2015-11-04 20:01:07
A number of devs consider it misleading to have a miner vote for a hard-fork.  It is more important what the users and ecosystem companies run, then miners will upgrade.  Miner vote is appropriate for soft-fork but not hard-fork.
@_date: 2015-11-22 22:03:23
soft-forks only, and the lightning paper says we do have an idea of how it is going to work.  also one of the soft-forks is in progress of deployment right now.  the remaining two CSV is implemented and coming next, and seg-witness to fix the malleability is also soft-forkable.
@_date: 2015-11-08 17:24:07


btw did you know that paypal started as bearer ecash on palmpilots.  Projects suffer change and degrade.  IMO we have to be careful and aware of history and design protocols and balance centralisation carefully to avoid the same fate for Bitcoin.
@_date: 2015-11-11 20:37:59
sidechain BIP time-frame comment was in Q&amp;A also some discussion of sidechains in talk at Dev Core 
@_date: 2015-11-22 17:26:39
Selfish-miners, hashrate.
@_date: 2015-11-08 10:45:13
I share your view about linear growth being quite interesting, i was musing if it would be better eg to make 2-4-8 linear at a straightline for example - that front loads growth, and if you look at the history of transaction volume growth it's a bit spiky but often linear for long stretches.  Also I was thinking to front-load so there is a jump because if there is a delay until activation you want to start growth now you could start growth accounting now so it takes effect there is some stored up pending growth.  2-4-8 to be clear would be growing like BIP103 does in 3month increments with linear between, not year 2, year 4 inflection points.
@_date: 2015-11-04 19:36:12
I am not sure what you are trying to say.  It *is* an implementation of the BIP.
@_date: 2015-11-22 23:58:56
I think that maybe fixable.
[edit] Also more simply, it's p2p and they consider negative fees to rebalance across addresses.  You yourself if you receive excess capital monthly, that you dont need until later in the month can participate as a node in providing liquidity.  You would get fees for that (akin to interest).  The interest rates would adapt to create the liquidity and as payments are fast, if velocity is high, reasonable interest could be paid while exposing users to small fees.
@_date: 2015-11-05 12:37:48


The tell tale I heard was that if you look at the karma it is high, and yet the account has zero history (all deleted).  If you dig up the history somewhere on archive.org or caches or whatever it will be random and unrelated to Bitcoin.
Obviously you can also see a lot of disposable / one use accounts, it is a trope even when people reply "Hello and welcome to reddit And there is the deleted post trick (where people post something inflammatory, wait for the negative responses and downvotes then delete the comment.  The best fix for this is to quote the text you are replying to (highlight and click reply, or quote with &gt;).  I believe people have said this is to do with gaming the karma accounting system form the downvotes.
btw I cant say for sure that any particular post yesterday was bot-voted, because well that's intentionally hard to prove.  A mixture of people who amuse themselves censoring others, people who dislike bitcoin and want to disrupt, and people that just enjoy arguing plus of course some people who do disagree, usually due to confusion or incomplete understanding or believing and repeating misrepresentations put out by people acting in bad-faith.  There are a few, maybe 5% or less of discussion which is intelligent and interesting commentary and that is what we should really be focussing on.  That is the discussion we want to have, and we could move forward faster if we could find a way to do that.  There should be a FAQ for the repeated questions and the misrepresentations and canards.
I am not sure what can be done about vote abuse.  Censorship is bad.  Lack of moderation is also close to unusable - results in an unusable forum due to the brigading, and bot attacks.  It is rather telling that (Roger Ver) also has moderation on bitcoin.com even though he is clearly anti-censorship.
I do think we could see something with Bitcoin where voting is based on changeTip level donations that are split between the poster and the forum to fund it.  At least that would add cost to the bot voting.
Another older concept is NoCeM's which are a distributed rating system.  It's a bit like voting except you are subscribing to one of multiple competing post rating feeds.  That way there is nothing to game because there isnt a centrally applied default rating, you spot check your rating feed periodically or people complain about it and you switch.  In this way ratings are kept competitive and matches peoples preferences.  You can also opt out of rating feeds and see the raw feed.  It is used for USENET which can be a lot worse than reddit in terms of signal to noise.
My tolerance for having discussions in bad signal to noise ratio forums was honed by trying to hold crypto protocol discussions on alt USENET forums misspent time from my student days.
Academics are researching what is going on in terms of the types of censorship and brigading tricks.  mentioned it on  for some reason site seems to have a bit of a rendering issue on chrome, firefox &amp; safari right now.  The only way I see to actually play the podcast is to click on the latest podcasts page. 
@_date: 2015-11-08 20:01:00
@_date: 2015-11-07 15:26:02
there are more bitcoin-core devs and they have maintained bitcoin diligently for years.  while some work for blockstream many do not, and they have not acted in conflict.
Gavin is an advisor to coinbase and Mike to A16Z an investor in coinbase.  This information is on the coinbase and a16z web page respectively.
Anyway this is getting silly, both sides put forward detailed technical rationales and there are a variety of BIP proposals with different tradeoffs.  They are being presented at scaling bitcoin in hong kong.  Lets collectively calm down and collaborate to select the best tradeoff.
Moderation, voting abuse and censorship are separate topics.
@_date: 2015-11-19 20:28:36
In the IETF model of rough consensus and running code, you get to write a BIP, an implementation and try in good faith to see which approach is the best next step on scaling Bitcoin.  Scaling is a process not a silver bullet situation - it's something that evolves over time, and there are several years of history of that process.
@_date: 2015-11-05 20:14:18


Your aspersion is rather vague.  Would you be able to name with proof a single underhanded tactic, or even specific suspicion?
@_date: 2015-11-21 20:47:56
@_date: 2015-11-04 18:03:07
No one has put up a website with downloadable executables, because people are still evaluating which BIP can achieve rough consensus to deploy.  But if you wanted to you could build it by applying the patch.
@_date: 2015-11-08 09:54:09
Well Mike was maintaining XT and started it before BIP101 or block-size discussions were not part of it.  It arose out of some extra informational feature APIs he wanted for lighthouse that did not get merged into bitcoind if I recall.  I think he kind of took offence that Bitcoin did not merge his feature, which is presumably why he says negative things about core.  Their justification was the feature was not secure - in a harmless way, so if it was just unverifiable information he could run it anywhere, even centrally with equal security or his own spin.  So that is what he did, made a spin: XT.  I discussed this with Mike and I do think it's a bit of a grey area - it depends whether you view bitcoin RPC as a generic app server that should be extended for various peoples projects, or whether Bitcoin should be kept focussed and such unsecurable informational APIs should be run centrally eg like blockchain.info does, or spun up on other p2p fabric if it's not security but p2p fabric you want.  If it's not securable anyway the argument can be it as good or better to get to from a central node you trust (like blockchain.info) vs a random node you connect to on the internet running over Tor that may lie to you.  Mike's counter argument is that he would then have to run a node and he wanted to make something p2p - ie he wanted to use Bitcoin's p2p fabric to deploy parts of his app.  And that maybe you could spot check multiple random nodes and hope on average some are honest.
On node software diversity, there already is some diversity: libbitcoin, btcd, bitcoind.  XT back then wasnt so much diversity as a spin or patchset - something with a couple of extra features.
I think everyone is generally agreeing that node diversity can be good.  There is a bit of caution about writing the consensus part from scratch particularly in different languages as it's really hard to get bit-level compatible and you can lose money fast if someone exploits the difference.  This is why there is a subproject in bitcoind to factor out libbitcoinconsensus so that it can be linked from other languages and have node diversity without risking consensus network forks.
I dont think it would make a lot of sense to maintain a hard-fork after a different hard-fork had taken effect.  Maintaining XT without BIP101 if that was the way it turned out - sure why not?


I dont think that's it.  I tried hard by asking questions etc to understand where the different views came from.  My understanding is here:  I think those quite different assumptions about what is the important differentiating feature of Bitcoin - ie what is Bitcoin's reason for existence even - are why Mike &amp; Gavin have a different direction of proposal to the rest of the technical community.
@_date: 2015-11-05 00:31:17




Right and then you've outsourced the security to a bargain VSP provider.  This is like the people promoting 100s of fullnodes run in amazon: it's not very useful for security.


Of course.


Well BitFury, which I assume you know is one of the larger miners, has said that large block-sizes could be problematic.  It's not always about bandwidth in the cloud, it's about bandwidth at the mine location, and in some places it's hard to buy bandwidth for money.  Yes you can do stuff in the cloud, but we that also weakens decentralisation and security.  




Yes they do.  But their security gain doesnt increase with block-size, and yet their costs do.


Well that's the idea to be pragmatic and end the debate.  We as a community have bigger fish to fry.  We're trying to innovate, and we've had enough of this.


"plan for success" means scale yes.  But scale is in a tradeoff with decentralisation security.  We have to do it in a balance or we get insecure but scaled, and then it suffers centralisation failure and Bitcoin loses it's main reason for existence - permissionlessness.  A centralised system is not permissionless.  Watch all the stuff from banks about "permissioned blockchains".  Why do you think that is?
@_date: 2017-05-09 16:22:20
Could some people who voted the target market as $500k (swiss bank minimum balance) comment?  i am curious of their rationale - is it a way to say Bitcoin as a gold competitor which I guess gold ETF's are often held as a hedge by HNWI's?  Would the same voters be anxious to see a Bitcoin ETF come online?
@_date: 2015-11-21 20:47:43
They are working on BIP specs and implementations.  And you?  Spreading FUD on reddit?  That'll help scale bitcoin for sure ;)
@_date: 2015-11-04 19:34:12
I get it: you want cheap vastly scalable transactions.  So do I.
But you have to understand that there is a decentralisation security scalability tradeoff.
Fortunately it seems like we can get much higher scale, low fee transactions by introducing a write-caching layer into Bitcoin, and people are working on that now (lightning).  It might take a bit of time, but do not panic.
That Bitcoin security depends on reasonable decentralisation of economically dependent full nodes is a perhaps subtle but I think well established fact about how Bitcoin security works.


People use Bitcoin for many different reasons, and there maybe some for who this is true.  However without the write cacheing layer you should understand that Bitcoin is inherently more costly and less scalable than central server systems like paypal or changeTip.  The cost is from the broadcast bandwidth, mining subsidy etc.


The point is what makes Bitcoin payments special vs centralised payment systems is the fact that is a permissionless open network.  Maybe we can keep cheap transactions if lightning works, but until then there is a cost to the decentralisation that we may not be able to magic away.
If people want cheapness more than they want decentralisation there are hybrid solutions: like changeTip - bitcoin denominated, but higher scale and adequate for low value transactions.
Anyway lets see how lightning works.  And lets scale in the short term so we dont have immediate problems via block-size increase as I suggested, eg 2-4-8 like proposal.
@_date: 2015-11-08 17:59:40
I believe so.
@_date: 2015-11-13 12:26:38
I guess that was short enough to transcribe, Nick Szabo:


@_date: 2015-11-04 22:55:49


There is no central control beyond that we hope through self-interest people have the common sense to run the same consensus code.  Libconsensus is different from the node code, run all the 3rd party home brew node code you want.  But be aware that security is hard, and consensus security harder; and Bitcoin is very caveat emptor.


I am advocating to increase the blocksize but for sensible time frames at a sensible pace.
But centralisation is quite bad in Bitcoin at present




Read 


The consensus code is better protected by libconsensus, than different implementations, or different consensus algorithms, but there can be multiple software packages that use libconsensus.
@_date: 2015-11-19 19:26:08
At what rate?  People are putting in a lot of effort.  They're not talking on reddit they are writing BIPs and implementations of them for hong kong.
@_date: 2015-11-10 16:52:56
Re "negative or unproductive" not so bad, he focusses on strategically useful bigger picture things.  Quite high on my top 10 impactful people mental list:   (podcast with Trace Mayer talking about contributions of an incomplete subset of people who made strong Bitcoin contributions).  At times you have to understand Peter's sense of humour.  It helps to see his facial expression as he's poking someone (smirking) as it sometimes doesnt translate.  Probably he's improving also 5 years is a long time.  
Also bitcoin is a meritocracy, and the age range is immense - some behaviour is learned by experience.  And some of us never learn either :) 
Tips for being functional in high noise environments and not contributing to signal loss dynamics: focus on the tech, ignore the barbs, forgive, work-with people, dont hold grudges, be a positive example, dont retaliate etc.  For example online mailing-list &amp; forum interactions of the late Hal Finney - never saw him once get angry in a decade of online discussions, including cypherpunks flame-fests and USENET etc polite and hyper focussed on the constructive and technical challenge.
(Present company excluded): some people need to develop thicker skins too probably, it's often surprising how the same person can be happy to dish it out but fragile on the receiving end.  I'm sure knows all about it from Linux kernel dev, apparently Linus Torvalds is notoriously acerbic.   
@_date: 2015-11-05 10:39:20
In this environment it actually is it seems.
Maybe we need a invert votes button, it would actually improve this subforum at times.
@_date: 2015-11-04 18:04:53




I did not mention BIP101.  Gavin said he had not heard a convincing argument that large blocks could create centralisation risk.  I provided a simple proof by counter-example: pick an immediate quite large block, and contemplate the impact, trivially large blocks do affect centralisation.  The remaining question is what is the best tradeoff between decentralisation security and scalability.  That is not to say that a larger block, even a 1GB block, would not be supportable in the future, it just disproves Gavin's claim.  It is important in protocol design to realise which claims are wrong, or you might design a protocol with a defective assumption.
@_date: 2015-11-04 20:15:19


That does not work for Satoshi consensus algorithm: the network can not reach consensus with multiple competing incompatible consensus algorithms vying for control.  That leads to elevated probability of failure.  This is why core is working on libconsensus so that you can safely have competing implementations but with one consensus rule.  This is why soft-forks have miner voting for upgrades.  And it is why hard-forks need to be coordinated so everyone upgrades to the same consensus rules.


Do let me know if the above is unclear.
@_date: 2015-11-05 17:16:19


neither google nor reddit search (which sucks) can seem to find this long reddit post.  Unfortunate I think it answers and provides references to some of the things you are (quite reasonably) asking about.
@_date: 2015-11-04 17:58:08


I was answering an a question Gavin posed in the text you snipped, viz:








I am working on one as discussed in the post you snipped:




I am.


Critiquing ideas is part of the scientific review process.  Proposals and blog posts musing about criteria are open for commentary - presumably that is why they are published, to solicit commentary.
Personally I am happy if someone disproves a claim I made, because then we both know more and can design a better protocol.


I open doors for discussion.  eg I persuaded Gavin to do this podcast:


I am and have been.
@_date: 2015-11-21 04:22:35
People in core are working on scaling Bitcoin.  Core also did all of the scaling to date (and it is several orders of magnitude scaling work over the years)  People are working on BIPs and implementations of them to scale core.  It's only a few weeks to scaling Bitcoin workshop, encourage yourself and others to watch the presentations, get on IRC and ask questions or attend.
@_date: 2015-11-07 18:52:24


Coincidentally 2-4-8, is really close to what you described except I had a higher growth rate (41% = sqrt(2) from doubling every 2 years) but for a shorter time period (4 years).  My logic was it's more buffer to have a faster growth rate and we can more safely push growth higher if the time-frame is constrained.  Also short-time frame because the future is really uncertain there's a lot happening right now and 4 years is an eternity in bitcoin if you think back 4 years.  We'll know a lot more about decentralisation of mining (and mining protocol fixes like GBT) and bandwidth growth, and validating node count, and transaction volumes, fees, price, new protocols for IBLT, lightning, maybe sidechains, maybe some new things not invented yet.  In 3-4 years we'll be in a better position to know what to do next.
Various developers are busying coding and writing BIPs and I will be excited to see which appears the best under review.  I view 2-4-8 as a kind of fallback something like BIP-102 but a bit longer-term/less one-shot - it's simple pragmatic and good enough to do quickly, as a backup to the better alternatives being delayed.  ie Hypothetically one could do BIP10x or one could do BIP-248 (it doesnt have a number so dont quote that) followed by BIP10x to give more time for something complicated to be tested and reviewed.
@_date: 2015-11-01 10:49:14
 hong kong, 6-7th dec.
@_date: 2015-11-07 19:09:09
Yes I saw.  I guess I mostly said what I wanted to say without getting into correcting / counters which have all been made before.
I did have a podcast with Gavin on the same kind of topic:
(and then supper with Gavin, Greg &amp; Trace at the previous scaling bitcoin workshop).
About AMA bitcoin.com Roger did ask and now it looks kind of booked up back to back for months, and the threading UI isnt yet fixed up - and there is reddit AMA also.  Anyway it maybe better to do an AMA after the scaling workshop and some progress when hopefully everyone is in a more forward-looking and positive mood :)  Maybe.  Not sure could be done nowish either on reddit AMA.
@_date: 2015-11-09 00:00:03
@_date: 2015-11-13 10:07:26
Requirements from a business perspective are good to know of course and we could do with more companies articulating what their thoughts are, so I am pleased Brian - often they seem to keep their thoughts private or talk to one or two people in private only.  In FOSS it's hard to, and perhaps even undesirable, to handle non-public feedback and requirements.
At Scaling Bitcoin 1 in Montreal, Charlie Lee (coinbase CTO) attended.  Maybe Brian would like to have coinbase co-sponsor the conference, along with the other 40 companies sponsoring, and perhaps also to present BIP-101 if Gavin is unable to come, or have Charlie do it if he agrees.  It's probably better to be involved in the technical conversation and BIP evaluation.
Personally I look forward to seeing the BIP proposals that are presented.  I would estimate it's going to roll until early 2016 just for safety reasons - it takes coordination and testing and time to activate soft-forks, and I am presuming something similar will be true for hard-forks.  I believe people have said if there is clear agreement, a hard-fork could happen faster, so that could be good for a basic scaling proposal.  We maybe faced with a choice of a basic proposal or a better long term proposal (that are both implemented and ready to go from a core tech perspective).  Hard to prejudge that without seeing what the better long term proposal offers specifically.
@_date: 2015-11-08 17:01:43
Yes Wences is *the man* - if you listen to his video talks, he grew up in Argentina and personally saw his family lose their entire net worth TWICE while he was growing up due to government currency collapses and mismanagement.  He understands much more first hand than many of us do why what Trace calls "Financial Sovereignty" can be important.  He also started and sold an ISP and a bank so he's knowledgeable about business.  
Interestingly Wences seems to focus quite a bit on providing services to economies with problems we do not see as starkly in western countries: capital controls, unofficial exchange rates, runaway inflation, rebooting financial collapses of government mismanagement, rebasement of money (adding 00s) etc.  In many ways you would think people in those countries have a strong need for Bitcoins properties of low and mathematically predictable supply inflation.
@_date: 2015-11-07 20:48:39


Agreed.  Also it is actively dangerous to centralised it.  People can be blackmailed, kidnapped, bribed, extorted, go insane, get drunk, get greedy, simulate a "hack" or a "bug" - $7b is a lot of money and it may grow way higher in the future.  No one thinking about it carefully would want to be in sole individual control of that software stack, even not for their own personal safety.  Even governments and central banks with trillions of dollars and billions of peoples financial stability at stake have difficulty avoiding moral hazard and political influence.  You actively want redundant cross-checks, review - it's decentralised by very specific and well-thought out intent.  I wrote about this before with Gavin &amp; Mike.  Not sure I ever got a clear answer on it.
Btw this  about how rough consensus works in IETF that someone posted parts of on the bitcoin-dev is quite interesting.
@_date: 2015-11-05 00:21:32
1. do you agree that decentralisation security is in a tradeoff with scale?
2. do you agree that decentralisation is important for bitcoins permissionless and ethos features policy neutrality, fungibility etc?
3. given there is a tradeoff - what trade off would you prefer?  unlimited is not a good tradeoff.
@_date: 2015-11-26 11:40:42
I think people are reading too much into this,  Gavin was just answering questions put to him by not advertising to start a flame war!
Anyway Miners and Gavin are pointing at the scaling bitcoin workshop in hong kong in a couple of weeks, for next steps, and there are multiple other implementations with various features and scaling characteristics.
I'm looking forward to the proposals to be presented at hong kong, which will be live-streamed and with IRC questions on 
ps It could be misleading to say BIP 101 is the only implementation, seems like some context was lost there - BIP 102, 103 have been implemented for months, and multiple other BIPs have been implemented for presentation at the hong kong workshop.
@_date: 2016-05-24 06:04:29


Actually segwit can be adopted incrementally, and even people who do not upgrade get access to more scale, because those who do opt-in leave space in the base block by moving the signature parts of their transactions into the witness space.
There are enough big wallets and transaction processors who have said publicly or privately that they will adopt in a timely fashion that there is no question segwit will provide fairly immediate access to more scale.
Also note transaction demand tends to grow gradually - there is no pressing need to see capacity go from 600-700k (whatever the current average transaction size is now) to 2MB overnight.
@_date: 2015-11-05 12:42:45
Sorry, no I liked btcdrak's post (and upvoted your post).  I was commenting how ironic it was that you got a large negative down vote for making a useful reading suggestion.
@_date: 2015-11-07 21:37:10
Not my BIP.  But I did hear explain the rationale for not including a miner vote - the idea that a hard-fork is a user decision not a miner decision.  Users upgrade, miners have to also.  Of course there is a balance - if no miners upgraded there would be no transactions or hashrate would be very weak.
also says that one should only do an upgrade when there is widespread agreement and coordination.  So I believe it's expected that everyone would upgrade well in advance of the date, and people would ask talk to other people and companies and make sure they upgraded.  
If you do not upgrade you have a potentially big security problem (you can get stuck on a low low hashrate dead fork and lose money to double-spend) so it's very important everyone upgrades.
It might be useful to have an indication of miner upgrade even if it's not a trigger just so you know if plenty enough miners are on to provide security on the flag day.  I maybe forgetting but I thought someone mentioned that as a possibility.
@_date: 2015-11-22 04:14:26
You mean like cipher block chaining modes like CBC mode (cipher block chaining), CFB mode etc?  That'd be something quite different.
@_date: 2015-11-05 01:24:18
Someone has to code.  They are quite inclusive and helpful to new people who want to learn.  There are more devs than there were last year.  Hopefully next year there will be more again.
Who would you sooner be doing the protocol design, review &amp; coding?  Someone who cant code?  It's an open entry system - write useful, mergeable code.
@_date: 2015-11-04 03:11:16
You know BIP 103 has an implementation?  (In the BIP itself).
@_date: 2015-11-04 19:45:42


Nonsense.  The world is littered with evidence of consolidation leading to central control.  Napster got shutdown.  Bittorrent didnt.  Digicash ran out of money and everyone lost their coins.  egold got shutdown.


I have been advocating the exact opposite: the rough consensus process in bitcoin core involves dozens of people either individuals or affiliated with or sponsored by various organisations.  I want there to be more developers with varied sources of funding.  Maybe a super high bitcoin price will create some independently wealthy ones that can self-fund.  Or maybe Bitcoin users could fund a good developer.
I'm not sure what your alternative plan is to make Bitcoin development more decentralised, but Mike particularly is arguing for it to be completely centralised: under his control as "benevolent dictator".


You have everything on it's head.  You argue for centralisation under Mike's control and call me centralist because I say we need more developers and rough consensus process is more decentralised.
@_date: 2015-11-12 11:48:45
That's kind of analogous to what redhat was able to do in linux.
@_date: 2015-11-22 01:20:50
I think you misunderstand the design criteria being used by Bitcoin developers who are working on scaling Bitcoin and who have done the large amount of scaling work done over the last few years.
You may like to listen to this podcast where Gavin and I discussed the tradeoffs and criteria.   
I am confident that Bitcoin will scale.  We must all listen to each others technical feedback in a calm manner and reason about the tradeoffs.  We will arrive at a better protocol if we understand and reason about all of the feedback. 
You (or Gavin) may like to attend or present at the scaling bitcoin workshop via video link.  I believe this has been suggested to you by the organisers.
I think things are exciting and a lot can be achieved: the Bitcoin technical community has awesome capability, I think it is an amazingly strong technical force with the IQ points, hot shot engineers and genius protocol designers who can pull magic out of a hat, like you would not believe.  I would not bet on a "bitcoin obituary", history tends to prove those wrong!  
Personally I consider Bitcoin's huge lead in network effect and the mining security of the Bitcoin network, and security track record, and the number of startups funded working on it and the amount and level of skill of human capital working on it to strongly lead towards the future being Bitcoin related financial networks.  I think we can scale Bitcoin compatible technology all-the-way and improve systemic risk by re-architecting the worlds financial networks to use it.  Given that the financial network is very interconnected, for block-chains to deliver the full potential we must have interoperability and ability to move assets and recombine assets between institutions without losing the programmable trust - ie without relying on a legal contract or manual settlement &amp; reconciliation as today.  Not all of this technology is yet public and not all of it is developed.
I do think we will have to write some code, and upgrade some software - in an industry with $1bil of VC money, I think it would be surprising if no code was getting written.  Internet protocols were also not born whole.
@_date: 2015-11-05 09:28:19
There is a BIP proposal coming for scaling bitcoin called flexcap.  It does this.
@_date: 2015-11-04 17:15:52


I think this is rather clear: in extremis more bandwidth constitutes a centralising force: 1GB blocks now, and how many full node validators will there be?


Regardless of protocol there are limits to data compression.  IBLT or better fountain codes at best asymptotically approach a factor of 2 reduction in bandwidth utilisation.
To some extent miners have mining income with which to buy bandwidth (though it is somewhat of a centralising force at the low end - if a users DSL cant handle the bandwidth, or not without unacceptably degrading the other uses they have for their DSL, maybe they stop mining).
However reasonable decentralisation of economically dependent full nodes is important for Bitcoins security as such full nodes enforce Bitcoin's consensus rules.  People running such non-mining, but economically dependent, fullnodes do not have mining revenue.
I havent seen any unreasonable demands made for validating proposals.  We do need to understand that there is a security scalability tradeoff however.  This is why I will be proposing a shorter-term compromise proposal in the direction of 2-4-8MB over 4 years.
@_date: 2015-11-22 03:09:43


Because insolvency, credit fraud etc is often not discovered for several years of audit cycles.


You are maybe thinking of some narrow scenario.  In current systems all balances and assets are editable by any party or group of parties either in direct fraud or indirect accounting shenanigans (moving debts around, creating fake assets, forward booking profits etc).  The only defences are trusted third parties who at times have been in collusion.  With proof of work the integrity of each stage is validated and auditable by all parties in real-time.  I think for the trust to mean more than a bare unaudited assertion of solvency to a relying party you need proof of work.  We have unaudited assertions today - how do private "blockchains" change that?
Another way to think about the difference maybe: one of the innovations of blockchains is to tokenise assets, and convert them into unforgeable, uncopyable electronic bearer assets.  A private "blockchain" does not do that.
@_date: 2015-11-22 20:16:43


Your interpretation of events was corrected by and on your own thread.
@_date: 2015-11-25 20:48:58
I'm not sure if you chose selectively, but Gavin and Mike are advisors to and have options AFAIK in various companies, eg Circle, Coinbase, A16Z, R3CEV variously at various times, and probably others.  I dont think they ever chose to list all their advisory positions.  Not that I am claiming a conspiracy, but a bit of balance right?
@_date: 2015-11-05 21:10:53
Szabo is quoted saying something about block-size in the second half of this article 
@_date: 2015-11-04 23:57:03


This has been considered before, but it doesnt work because it is gameable: as miners can fill blocks at no cost, they can increase the average block size over the last 100 blocks.  Generally btw people have proposed median but still the problem persists.  This is why people proposed flexcap so there is a cost to dynamically increasing block-size .
@_date: 2017-05-07 23:49:42


you're missing the macro picture.  by checking your payments you are helping others.  eg if you were not running a node and were defrauded you might accidentally pass someone else an invalid coin.  it's like the currency verifying devices in some stores, the fact that a reasonable number of stores have them, and that money changes hands p2p so it passes through them once in a while just on average - that itself protects the currency integrated vs counterfeiting.
@_date: 2015-11-05 12:46:49


I dont think voting to censor others who are making good-faith attempts to discuss trade-offs is professional nor ethical behaviour.  That is behaving in bad-faith.  Two wrongs do not make a right.
Also I believe that discussion of the topic is by policy explicitly allowed in the scaling sticky thread?
@_date: 2015-11-10 20:39:27
@_date: 2015-09-07 21:34:53


You should look at lightning it's better than you are thinking.  It is a write-cacheing layer for Bitcoin, and each transaction is a real transaction that can be posted to the Bitcoin chain but is traded securely in layer2 to get cheaper faster Bitcoin transactions.


LN transactions are Bitcoin transactions.


Not true.  There are offchain techniques that can provide offchain transaction compaction that still result in on-chain assurances and clearing.  eg observed some years ago that coinswap can elide intermediate payments trustlessly to increase on chain throughput.  Lightning uses that plus some features from payment channels and some new enhancements.


I would agree with you in terms of anything that reduces user control &amp; trustlessness.  But Lightning is more an integrated Bitcoin acceleration protocol.


About lightning people are coding it check out the github.
and the mailing list:
@_date: 2015-11-05 10:10:47


I'd say working on Lightning is planning for huge success.  Arguing endlessly about block-size is trying to induce failure.  Just when the price was picking up.  Please.
@_date: 2017-05-08 00:17:03


they might.  but running a full node in addition is a useful line of defence.  otherwise if a rogue amazon VPS admin ever runs amok a lot of people are going to have a bad day, week, month and year: ie they could wreak havoc, with the amount of centralisation already in AWS.
@_date: 2017-05-08 12:22:17
Well right, financial sovereignty assurance mechanisms in Bitcoin are multiple and complex: and in the absence of cryptographic fungibility, what assures that it is hard for someone to demand miners block your transactions is that's mining be reasonably decentralised. Which in turn requires a fairly level playing field or large miners can push out smaller miners, via economic loss.  That means leaving security parameters that advantage big miners at the expense of small miners as a check and balance with users.
Today rather too few legal orders in a few countries could change that.
@_date: 2015-11-22 04:34:55


nah try github pull requests :)
@_date: 2015-11-15 22:40:58
I think you understand.  Two different consensus algorithms on the same network are typically not going to converge.
@_date: 2015-11-10 10:58:24
The presentation from Greg just up now goes into more detail about bottlenecks and the work to fix them.  
For example the investigation into block relay latency, and the ~1 second block-validation time of largely signature-cached blocks, and block-sync time etc.  Multiple bottlenecks are being addressed in parallel in order to avoid complex things breaking as we scale.  The core approach is to fix and test latency and performance and security bottlenecks as a necessary part of scaling, as well as the direct scaling work.  Panic not As says first listen to the technical limits, tradeoffs and plans.  did say scale is important and he and core are working on it.  Eg on the panel he contradicted to point out people were and have been working on scaling and that it is important.  eg libsecp256k1 improves signature validation speed by up to 8x, that allows larger blocks before orphan rates go up - and avoids people taking counter-measures like validationless mining (SPV mining) that damages security and caused BIP66 deployment to fork.  
There are numerous BIPs being prepared with implementations for scaling Bitcoin in hong kong on dec 6-7th.  I am looking forward to seeing what scaling innovations can be achieved.
@_date: 2015-11-05 00:15:32




A hard-fork is different because the different versions ignore each others blocks.  That results in people losing money if they are not careful, and it does not automatically converge on a consensus answer like a soft-fork does.


Yes I like permissionless innovation, and had something to do with that.  But there is also the permission to break the network - for it to work, it assumes enough self-interest and education to not run competing consensus code to "vote on hard-forks and see what happens".  That doesnt work.
Note the "voting" happening now is not real, they are just miners indicating a preference, not running the code.  (And that is safe as it has no affect on consensus).
And can even be done from rogue implementations just like XT if they gain enough support (in XT's case 75%). Permissionless innovation! Wouldnt that be great? ;)
@_date: 2015-11-05 09:43:12
Maybe it would help if you think about selecting transactions as a security relevant activity - such that you want a wide diversity of internet links the transactions are broadcast over.
Bitcoin gets censor resistance and hence permissionlessness from being hard to censor by being broadcast over many different links in different countries.  If everyone (for example) put their nodes in amazon, it is no longer as hard to censor: amazon perhaps with legal demands from a court, would have the technical means to censor.
Clear enough?  You want a reasonable amount of decentralisation.
@_date: 2015-11-22 03:37:09


PoW is what makes assets into unforgeable bearer instruments.  Maybe a terminology issue but I think with blockchains we are talking about on-chain assets.  An off-chain asset is something not connected with nor tracked by a blockchain: balances in mtgox were offchain.  Like an off-balance sheet liability - a financial integrity blackhole.




That doesnt sound very private.  Do you mean a public ledger, or a shared ledger between banks?
Banks already do trade reconciliation.  Sharing the reconciliation data with the public would be a step forward but is still a weaker and less scalable assurance.  How is the public supposed to audit or even have the bandwidth to receive trade reconciliation data?  Proof of work provides an objective framework to efficiently scale validation with SPV, fraud-proofs, lightning write cache &amp; blockchain validated transaction servers so that assurances reach everyone.  Partial validation or validation only by central parties can only provide limited assurance and integrity protection.  I know it's simpler, but it doesnt deliver on most of the potential, and it's not very accurate to call those things blockchains in my opinion.
@_date: 2015-11-02 13:25:55
Calling for ethical constructive behaviour should not be viewed as negative unless...
@_date: 2015-11-05 09:24:12
here here.
@_date: 2015-11-21 23:28:07
They are not getting the bang for the buck.  Seems like they are crammed in at 2-3/day, limited warning/no advertising in advance for a few days, of which one is coming so people can prepare to be online and ask questions, and they are over after like 1/2hr with very few interesting questions asked or answered.
I like the intent and objective but it would probably work better if they were more paced.
Also if they are looking for feedback as to why the uptake is not what it could be, IMO the negative advertisement about censorship has been overdone and is not helping the AMA uptake.
Anyone can schedule an AMA anytime on reddit, also.  It is in a separate forum and not moderated by a given subreddit mods.
Maybe a better time for AMAs would be post hong kong scaling workshop when people are less busy.


The threading support is kind of painful also yes.  I believe is working on a site upgrade, and people have also suggested that there are FOSS reddit-like threading systems that could be used.
@_date: 2015-11-10 21:23:16


I think that might not ideal - selfish-mining results in bursty block-progress because people are withholding them.  I wonder that it might be possible for two 33% selfish miners to leech reward from the rest of the network composed of smaller miners.  The other thing is we know 51% mining is a fundamental threshold so the practical relevance of selfish-mining is relating to the centralisation of pools and miners where we really do have pools &gt; 25 or 33%.  We might be able to do something about that with tech (GBT like pooling protocols) and with education for power users and businesses to make it easier to not do that, and to encourage them to decentralise the hashrate by eg ecosystem companies running a bit of ASIC power, like say 1x SP50 would make a reasonable hash-rate contribution for presumably a not huge outlay.
Another simple thing with selfish-mining involving pools, to the extent the users are not complicit, is the client should broadcast the winning block (not leave it to the pool).
IBLT would be good.  I do wonder about IBLT though on a couple of fronts: it's a homegenizing force sort of acting like a weak incentive to follow group-think censorship (if you add transactions that no one else has, your blocks will sync slower), and also it is an average case, the pathological case for it is to fill the block with transactions others dont have (eg pay to self).  Also one would like a relaying tech which is a level playing field, otherwise smaller miners will cluster on fast relay connected pools and let the pool choose the block.  That seems like a hard-problem as simple centralised things (like the way people are using Matt's relay network) will tend to win over p2p due to hop-count and lack of manually chosen and sourced links (Matt has curated them and sourced VPS's in unusual places to get access to routes that dont naturally happen via BGP).
@_date: 2015-11-19 18:21:58
Core developers are responsible for Bitcoin scaling to where it is today.  Take a listen to  for a bit of history about how Bitcoin scaled since 2009.  Also I would expect it is core developers and other contributors who will scale Bitcoin in the future also.
@_date: 2015-11-07 19:04:48


We heard kind of the opposite from investors, VCs, traders and banks that the longer this drags on for the worse for bitcoin startup funding, price and credibility of blockchains.  I dont think this is good for Bitcoin, and we collectively should get our acts together and collaborate.  As I said in the question to Mike, it's time for the community to pull together.
In case you think about the flip-side, of us somehow having a motive to hurt bitcoin, that's not true either: blockstream and everyone of it's employees and founders is invested in Bitcoin (and we gave everyone time-locked bitcoin to ensure alignment with Bitcoin also).
@_date: 2015-11-22 17:59:43
I am not sure you took the right message from whatever it is that happened because you are publicly saying that blockstream blocked your paper, which is not what happened - I dont think we've even seen your paper, I certainly havent seen any of the abstracts submitted via the reviewer panel.  I'd be more inclined to chalk it up to disorganisation than conspiracy, which is why I suggested you ask the reviewers to comment on it publicly.


@_date: 2015-11-05 16:05:27


Not at all.  I said there were really interesting and genuine discussion that we really need to have, mixed in but largely drowned out by those bad-faith activities of a disruptive minority.


The exact opposite.  I am trying to do what I said I would do: preserve the ethos of Bitcoin and the users interests, and make Bitcoin more awesome, more secure, more fungible and more scalable.  Part of that has to be explaining to people FAQs and why Bitcoin works as it does.  That is not an insult, Bitcoin is extremely complicated and at the bleeding edge of human understanding.  Even developers, some of who are the smartest people I have had the pleasure to meet in my entire career, and I've known some pretty freaking smart people, who have been working on Bitcoin for 3-4 years, are still making new discoveries and realisations about bitcoin protocol security.  It is not an insult to discover that most "what-ifs" have been analysed and have a FAQ answer.


Hmm.  I talk to many of these people and we get along very well and have mutual respect.


It is not clear who is doing the voting abuse, but the evidence that it exists is hard to deny.  It's also not clear why.  Maybe their reasons for organising the attacks are even back-firing and bad for their intended objectives.  Such things happen.


I can assure you and put my reputation on the line that I am not act in conflict with Bitcoin.  If you disagree with me, you likewise might like to consider if you are misunderstanding something.  I have been working on cypherpunk things and ecash and censor-resistant and privacy tech for like 20 years.  It's not hard to see what kinds of things make me tick: a google search will dig up 1000s of posts.
I am very open to being disproved, and as I said there is much to learn still about the limits of what can be done with Bitcoin so I am happy to see something disproven as it improves understanding.


I made a pretty long post explaining the details of all that on reddit a few months ago.  I am not typing it up again, but someone could find it.  Went from like a) through p) or something about bitcoin options, parachute clauses, who founded the company, the objectives, the public comments of the investors, connection of investors to FOSS projects (Mozilla foundation).   I mean I dont think I'm hiding anything here - and it is slightly insulting to throw around brash accusations with no facts or evidence, dont you think?
@_date: 2015-11-05 16:55:01
It is inadvisable to run binaries with incompatible consensus protocols because it elevates the risk of network-fork as happened by accident during the BIP 66 deployment, that required rushed priority manual fixing.
We have to focus on agreeing on which protocol to use.  We can compile stuff later.
@_date: 2015-11-22 15:29:21


No, they are all running the same consensus algorithm.  There are policy choices (optional parameters) within the algorithm that do not change the algorithm.  If you change the algorithm, you'll get forked off the network by accident, or maliciously leading to you or your users losing money fast.  If everyone did it with dozens of competing (incompatible) algorithms, it would lead to chaos and failure. 
@_date: 2015-11-22 02:55:39
You say that as if known participants have never committed fraud, or that needing to trust counter-parties is a good thing for users, audit cost or systemic risk.
Mining presents a cost to fraud.  The argument is that this cost is cheaper than the audit and fraud risk because it is automated.
@_date: 2015-11-04 20:09:12
oops fixed.
@_date: 2015-11-04 23:55:32


They already have, checkout BIP 103.


You seem to be unaware of BIP 103.  It has code in the BIP, and has for months.  Jeff said he was working on two more implementations of other BIPs.  There are other BIPs being worked on.
You seem to be talking about a false dichtomy by not being aware of what has already been released. 
@_date: 2015-11-23 00:37:16
I would think you could reasonably ask them to waive the non-compete if they promptly canceled the contract before you hardly got started.
@_date: 2015-11-05 09:29:27
instant negative downvote.
@_date: 2015-11-05 09:33:04
Gavin sees both and doesnt see a problem but I dont think he is philosophically aligned with Bitcoin ethos.  I do see a problem, but that we can scale it anyway without the Bitcoin Ethos orbituary implied by "only a few fully validating nodes run by mega-corps."
@_date: 2015-11-05 00:19:10
I am not sure what your point is now.  The code is written, you apply the patch to bitcoind compile it and run it.
It is code not pseudocode.


I believe that has been changed in a recent version and your information is out of date.
It might be surprising to you but this is the code.  It is just not that much code to change a constant.
@_date: 2015-11-05 01:11:27


Sorry but there is evidence and apparently research going on demonstrating that there is organised shill and/or down-voting.  It's fairly transparent.
The discussion is flooded with positive votes for trollish comments and down-voted for balanced comments INSTANTLY.  Like -30 within seconds of posting.  (Not on this thread too badly, but on some threads before moderation got heavier).
There is also the deleted history bought or hacked accounts.
And the deleted inflammatory comment trick to dodge negative karma or whatever the point of that is.  (Easily combatted quote the text you're referring to by highlighting before clicking reply or quoting with &gt;)


Well OK if you want to look at it that way, it is soft-censorship because you can go see what was censored.
You can see what was moderated on bitcoin-dev also (there's another list).  Does bitcoin.com for example publish things it moderates - it does have moderators, so the difference is not the principle.


 
Yes I do this sometimes too.  Usually the trigger is that a trollish comment has a high vote, which probably means a better more balanced comment has been censored in reply.


It would probably be better if voting or collapsing could be disabled for the whole r/Bitcoin subreddit, it is being heavily and systematically abused.


I thought disproof by counter-example is quite simple.  Gavin says block-size does not make centralisation worse.  I say doh, of course it does.  Pick a number, any number that shows that excessively large blocks do make centralisation worse, and it's proven.


Nope.  There are many PhDs with comp sci degrees even who cant program or are sadly useless for real life protocol design.
Anyway I think arguments should stand on their merits not the claimed credentials of the person making them.
Schneier's Law maybe one exception for security design questions (which is a big part of Bitcoin - it being a security protocol).
@_date: 2015-11-08 14:57:15


I like that answer.  FWIW that was the question I was looking for an answer to solve that led to sidechains.  Perfect and freeze Bitcoin (like TCP hasnt changed in decades) and do all the innovative stuff on side-chains with Bitcoin - you can view side-chains as network routing for Bitcoin.
You might even try to modularise and simplify Bitcoin, eg take out fancier features or less secure features and put them in a separate module or chain.  To be realistic to freeze simplicity and composability on top (or to the side more accurately) is key I think.  Lots of work toget there.  You can view libbitcoinconsensus library work going on in core as part of that.  Another related idea is to re-implement consensus code in RISC-V or Moxie (abstract VM) because the VM code is much smaller and less complex than the consensus code.  Then consensus would be defined in a cross-platform bit-level consistent way simply by the compiled byte string.
@_date: 2015-11-04 23:59:23
And troll-voted down.  Awesome, censorship at work, by the same group that likes to complain about censorship.  
I am making a very simple logical argument "disproof by counter-example".  It doesnt relate to BIP 101.
@_date: 2015-11-10 00:21:05
Well I was more meaning a pre-hardened (ie validated, tested, secured even if partly manually) more distributed PoW tweak in waiting.
But the idea of a sidechain as a way to have a major version upgrade, was actually the original motivation (going back to one-way peg and then a switchover).  I suppose a parallel running sidechain, maybe, could act as a live plan B.  Have to think about how that could work, it's a novel concept.
It is possible to have a sidechain with a different PoW, but you do need an translator chain in between (that recognises both PoWs, and makes assertions towards Bitcoin based on proofs it validates from the alternate PoW sidechain connected off it).
@_date: 2015-11-30 19:52:18
I think you should re-read the presentation schedule more closely, there are multiple presentations specifically about scaling with concrete, implemented proposals.
@_date: 2015-11-10 17:00:08
In this thread, there is some irony in that comment.
@_date: 2015-11-06 22:31:32
BIP 103 is also implemented (code is in the BIP text)
@_date: 2015-11-07 19:24:34
Gavin did come to the previous one in Montreal so I dont think you should read into that.  I believe presenting via video had been suggested.  I guess it might be interesting to hear about IBLT which he's been researching also as that (average case) reduces block transmission latency and bandwidth.
Mike said before he wouldnt go to the first one.  Really I think he should, but it's his choice.  Internet arguments are *never* as bad when you talk with the guy behind the keyboard in person.
Note intentionally everything is live-streamed and there is  IRC to be inclusive - not everyone has the resources or time.  And realistically there will be testing and discussion before during and after the workshop.  It would actually be bad eg if everyone got in a room and agreed something without giving people not there opportunity to comment.
@_date: 2015-11-22 18:32:19
Kind of yes.  That's what was happening with the SPV-mining that led to an accidental fork during BIP66 deployment - apparently over 1/2 the hashrate was not validating blocks, meaning they were not waiting to receive blocks, just getting headers from collaborating miners to avoid block transmission latency and reduce orphans.
That same group of weakly collaborating miners could just withhold the blocks from everyone else for 10mins.  Then they would have 100% hashrate and approximately double their profits.  When they have 100% control they can increase minimum fees by policy.
They are not doing this, presumably for meta-incentive reasons (it would be bad for bitcoin and they are invested in Bitcoin via large capital outlays in ASICs), and perhaps they are not that closely cooperating either - that kind of behaviour can be undercut by people who break ranks from cooperating and start to mine transactions at lower price.
@_date: 2015-11-05 12:53:03
Thank you.  For comparison note it is the same exponential growth factor (2x per 2 years) that Gavin proposed.  The difference is to start at 1MB instead of 8MB, and to do it for a more predictable time-frame.  I may tweak those parameters a bit because of activation delay - ie if we could instantly turn it on, then it would start growing from now, but it for logistical reasons it takes 3months then maybe that growth should turn on at the activation date, rather than starting at 1MB.
@_date: 2017-05-08 05:47:46
it seems like they simultaneously believe some false narratives, and yet are blind to how dictatorial and monopolistic they sound. or maybe they dont care and are just trolling the ecosystem, and so failing to have the decorum expected of an ecoysstem security provider. either way it's not good for confidence.
having said that I would say the shortage of developers and researchers is a problem and more smart people should consider trying to learn. also you dont have to be a developer, or a CS, crypto, econ or game-theory researcher to have an influence, people should get involved and try to understand and discuss principles that are in trade-off for bitcoin's security, just to inform their own choices, and spot check and verify they agree with the assumptions and logic the developers and researchers are using. 
ultimately it is the users that decide, but bitcoin will work better if the users make informed decisions. 
bitcoin companies, including miners, are just service providers to users and they should not lose track of that fact - bitcoin is a p2p **user** currency.
@_date: 2015-11-22 19:57:40


And to be clear, because your initial post seemed to say otherwise, and you presumably do not feel it professional to list the reviewers private comments, can you never-the-less confirm that you are satisfied that your proposal was rejected based on normal academic review criteria and has nothing to do with blockstream?
@_date: 2015-11-21 20:45:18
Where'd you get that prediction from?
@_date: 2015-11-07 19:28:02


I think the mailing list is mostly fairly polite, and Mike certainly gives as good as he gets.


Yeah good question.  Just sticking my nose in.  often writes on reddit and is in a better position, but I think he's kind of busy focussing on implementing scaling BIPs.
@_date: 2015-11-05 09:25:54
You did not find a bug, your understanding is out of date.  You know the code was written by Pieter Wuille who wrote headers first, libsecp256k1, bip 62.
@_date: 2015-11-05 16:56:23
OK then, if you are too busy to justify your censorship with reason, I guess I am reciprocally too busy to bother arguing with you.
@_date: 2015-10-12 20:18:22
spondoolies is selling  its says bulk only but maybe someone on bitcointalk would make (or already did make?) a group buy.
They can be run with less than 10 blades apparently.  And each blade has it's own PSU so you dont need the full power requirements on one circuit.
May draw a fair portion of a residential grid supply though (if all blades are occupied).
@_date: 2015-11-22 22:00:55
It depends on the recirculation rate and velocity.  Maybe less capital with higher recirculation and higher velocity is also plausible.
@_date: 2015-11-05 10:44:36
Sure if people want to talk about balance.  That is not the way Gavin expressed it.  He has a habit (in writing and in words) to make technically untrue statements.  I find it misleading or tending towards fuzzy thinking.  Call me nit-picky if you like but if people say things like "block-size increases do not affect centralisation", excuse me if I point out that as stated that is trivially a logical fallacy.
@_date: 2015-11-05 09:57:10
The cost of orphan blocks is unevenly distributed.  The selfish-mining paper shows that orphan rates can be used as a mining advantage by large miners.
@_date: 2015-11-05 10:15:25
I agree hence the 2-4-8 proposal to give 4 years for Lightning development to be deployed and real use to be seen.
@_date: 2015-11-22 16:48:07
Most of the linked text seems to be non-technical in nature.
You did not defend the breaks of your proposal implicit in the text above:




In the selfish mining attack, and just in general, you are not at orphan risk for a block you created yourself.  Similarly for SPV mining (ie validationless mining) amongst a cooperating group.  Maybe you should start with a security considerations section (the non-technical promotion is premature until you have convinced the technical community the proposal isnt simply broken).  I understand the enthusiasm and the desire to decentralise Bitcoin because everyone shares this view, but it has to be grounded in security.
@_date: 2015-11-22 15:33:54
It's still a bad idea.  Gavin may have said that before the selfish-mining paper was published so perhaps that was less obvious.  Selfish mining says you can try to centralise mining, and make money while you're doing it.  Even without that (pretend we didnt learn that) it's still a bad idea because people can engage in anti-competitive pricing ie temporarily lose money to gain all revenue in the future.  That's called price dumping and monopolistic behavior.  Happens every day in the market.
@_date: 2015-11-21 23:40:41
@_date: 2017-05-08 12:29:21
Maybe answer the responder who asked for evidence. To me everything you asked seems angry, misinformed, assumes bad faith that doesn't exist and buying into conspiracy narratives.
@_date: 2017-05-01 00:38:08
it's just complicated, and they haven't thought ahead about the implications of no one outside of data centres being able to validate. the irony is if that is actually what they wanted, they can have it in a permissionless way: just use a hosted wallet that does in service netting. there are multiple available today. some of them even do batched on-chain cross service netting. a big sidechain could also do similar things.
@_date: 2015-11-05 09:34:09
What BIP 103 does is propose to increase in line with Cisco published internet bandwidth growth, FWIW.
@_date: 2015-11-05 10:09:14


If users and companies first agreed and then upgraded that would be fine.  But that is not what Mike proposed: what is proposed is to run competing consensus rules in parallel.
@_date: 2015-11-21 20:46:09
Yes that was who did that analysis.
@_date: 2015-11-22 18:41:09
This whole thing is stupid.  You cant rebottle the encryption genie.  Encryption is everywhere, anyone can link in an encryption library to a FOSS app.
@_date: 2017-05-07 23:38:14
there's still a cost
@_date: 2015-11-10 21:14:03


apropos of check out this proposal just posted on bitcoin-dev to consensus enforce weak blocks 
I am not 100% sure if that works, but it's a useful line of analysis.
@_date: 2017-05-08 11:52:15
You missed it? Was great: 
"...then everybody is walking around with a swiss bank account in their pocket"
Have to assume he thought that was a bad thing :) but bitcoiners think that is perfect.
@_date: 2015-03-25 00:09:58
There is a proposal in the sidechain white paper of how to do the peg. ( We have a working test version that is not yet released. We need to do a bit more work on it, but we hope to release the code soon.
We have shared additional information on how the two-way peg would work, etc., the most recent one is this podcast mentioned by the article linked to:
The two-way peg relies on a soft fork, so the test implementation, once released, will also serve as working example of the proposal and provide a basis for discussion.
We expect the bitcoin developer community and wider community will have feedback on the proposed mechanism or perhaps even suggest alternative mechanisms to achieve the effect.
The broader picture is sidechains are nearly, but probably not quite, implementable using existing bitcoin scripts. There are many possible small changes that could tip it to being implementable so the discussion is about which is the simplest and best way to soft-fork support. For that reason, I wouldn't describe it as a major change, though to do it efficiently, compactly, elegantly and maybe with some reusability for other purposes, a soft-fork for this capability would add complexity, so I also wouldn't call it simple.
@_date: 2015-11-05 10:12:26
and -8 for you.  Honestly this forum would be better to read in terms of useful comments with the scores inverted.  Is there anyway to disable voting on this subreddit?
@_date: 2015-11-05 09:27:20
well predicted -11 for you.  there should be a button to invert the votes!
@_date: 2015-11-05 12:50:50
Those are valid discussion points.  However I think you neglect a few second order effects.  Selfish-mining intentionally delays block-propagation in order to get an unfair mining advantage, therefore it is not a new cost in the weaker attack to have a bigger block.  It is counter-intuitive that this would work, however they successfully proved it works in the paper.  There are two thresholds 25% hashrate (individual or group of loosely colluding miners) to start gaining advantage proportional to how frequently you can race publication, once someone gets ahead of you; and 33% where you win period regardless of publication race.  That means if blocks are unlimited and there is a collusion group of miners at 33% or above, the network is toast.
@_date: 2015-11-08 18:59:35


Yes that was not clear, but I was assuming to base 2-4-8 on the spec and code for BIP 103 which changes every three months with linear growth between that so it is relatively smooth, so 2-4-8 just describes the size at the 0, 2 and 4 year marks with smoothed exponential growth in between quantised at 3mo periods where the growth slope changes.
(I think Gavin changed BIP 101 spec to get rid of the initial huge inflections at 2 year boundaries issue based on feedback).
@_date: 2015-11-21 04:58:30
Btw Andreas Schildbach is maintaining bitcoinj now 
@_date: 2015-11-05 16:26:23
bitcoin-dev some months ago posted by and @_date: 2015-11-05 10:14:40
Sure people are working on it.  3 or 4 companies, multiple individuals.  I proposed we increase the block-size over a 4 year time-period to give time to see how lightning works out.
@_date: 2017-05-02 10:37:14
me too, i'd like one or two of those!  one problem is you need reasonable utility electricity rates.
@_date: 2015-11-19 16:47:38
btw Tim Swanson (not Swason).
@_date: 2017-05-08 12:24:27
Ha didn't even parse the typo. Fixing.
@_date: 2015-10-08 01:33:28
That doesnt work.  Fails to various attacks.
@_date: 2015-11-10 16:58:25
He explained this before: he worked on viacoin only on R&amp;D questions of mutual benefit to Bitcoin, and it was part of his agreement with them.  I believe it was largely the same pattern with mastercoin, which is historic I would assume.
@_date: 2015-11-08 15:29:32
@_date: 2015-11-26 16:01:01


Yep me too: it's all we can ask - that people kept an open mind and a positive attitude and focus on which technology is best in a calm and analytic way.  
Btw I think the code in BIP 103 isnt psuedocode, - though I did see a couple of people think it was, I think because it was less lines than they expected.  I believe BIP 102 also said he'd implemented.
It is cool that is trying to get some real data so that the we have some test mileage on what happens to memory etc with various block-sizes.  That should be useful in general.  He's going to be presenting on that at the workshop so it will be interested to see that.  You may have seen BitFury published a paper on that topic also, though it was less clear what data they had used.
I agree that O(n^2) validation cost should be fixed.  And a few people did more adversarial analysis of some unpublished pathological CPU validation cost transaction cost types, I believe they are now public now after it was concluded that while they could be disruptively slow even at 1MB they could be detected and worked around if exploited.  Probably they also need fixing for larger blocks.
I think the other BIPs being presented have code also.
@_date: 2015-11-17 11:34:46
I also didnt say that.  You are making stuff up.
@_date: 2017-05-07 23:29:54
true, but you might not mind if it saturated your medium band internet for 1/2hr to catchup - because you were doing it for a reason.
@_date: 2015-03-25 17:26:37
a few related ideas: 
IBE addresses, another address type (aiming to be safely reusable and securely outsourceable to a full node to search for without major privacy leak)  
That should be more privacy preserving than stealth addresses with prefixes (one way to make stealth address less bandwidth expensive than being a full node and trial decrypting everything, which as a side effect exacerbates the network flow analysis attacks on privacy, or the other alternative of fully trusting and outsourcing search where a full node learns your full history for the requested address(es).)  Unfortunately IBE addresses also require changes so that runs into the difficulty of adding major features to bitcoin.
another model is to use a message bus:
"Relatedly I think bitcoin could do with a store-and-forward message bus with privacy and strong reliability via redundancy (but less redundancy maybe than consensus all-nodes must receiving and agree and store forever).  That  provides an efficient store-and-forward SPV receivable stealth-address solution that doesnt suck: send the recipient their payment, if they like it they broadcast it themselves.
As a bonus store-and-forward message mixes are better able to provide meaningful network privacy than interactive privacy networks.  You could spend over the same channel"
and of course side-chains and integrated sub-chains which are about making it easier for people to add new features on bitcoin connected chains.
@_date: 2015-11-08 16:43:13


I dont think users have contention about what they think Bitcoin is.
The block-size thing is mostly separate to my mind other than perhaps, arguably, some people maybe being a bit out of tune with what users value - or favoring what big-companies or VCs think they want.  I say think they want because indirectly I think they all want the same thing - because businesses only succeed by providing what users want.
@_date: 2015-11-22 15:26:35


That is kind of the point of blockchains: we do not trust those involved (the banks).  Or it's more secure to not have to trust everyone in the chain, weakest link argument.  Even banks dont trust each other.  At the edges, and even into the core in times of stress.  In terms of willingness to lend, faith in solvency, and at the edges even maintaining corresponding banking relationships suffers low-trust incentivised churn as banks get dropped, and find another bank willing to connect them.  This is because all transfers are based on trust of the integrity of an unsecurable counter inside a database record.
@_date: 2015-11-05 10:06:11
I dont know I talked to Mike for 4hrs in person at a starbucks and he was amiable, reasonable etc.  Then he posts rants like his most recent one which are filled with falsehoods.  Until the bitcoinxt.org site removes the stated objective of Mike being the "benevolent dictator" and how this is an improvement, I have a REALLY hard time understanding how that improves decentralisation.  It just DOES NOT by any conceivable stretch of imagination.  Over to you.
@_date: 2015-11-05 00:39:03




Yes it does use a very different mechanism: it sets a date.  No threshold.  Because it is a hard-fork I think that makes more sense and so do others.  It wouldnt hurt to have advisory support indication so you know what the hashrate will be when it triggers, but it is triggered on a date.  (And you aim for clear agreement before it is deployed).


It is described in the BIP I linked to.


They are not available for download because it is actually negative, like a bad idea, to be running incompatible consensus code in the network.  If BIP 100 and 103 had binaries up then there would be worse chance of network split due to software install inertia.


Core will upgrade (as will other implementations) and recommend to upgrade once there is rough consensus from the users and technical and business and mining communities.


It is false because people are claiming 101 is somehow ready and other implementations arent.  This is untrue 103 is at the same stage, just no one took the ill-advised step to make binaries available before there is an attempt to gain consensus.
@_date: 2015-11-08 14:43:58
One way to look at the second part what Trace is saying, is that other than what each person personally thinks Bitcoin is, or what they think it should be; an economically useful metric can be to use market research to find what the market thinks.
Of course if we ask that question neutrally to the market, and find the answer, it's possible that it might be uses that you or I find uninteresting, but it is an economically logical way to look at it, and it could be an interesting independent metric of what the market likes about Bitcoin.
There are also market distortions that can lead to the market seeming to say strange things: for example because of the lack of permissionless innovation in banking networks vs internet protocols, there is limited competition (a kind of high barrier to entry oligopoly exists) and so transactions are expensive.  That might mean for example the market was wiling to use Bitcoin purely to save transaction fees, when in fact a decentralised system is inherently more expensive than a centralised one due to huge redundancy and mining.  But maybe that is an indirect vote for the strong advantage of permissionless networks: a permissionless, but expensively decentralised system, can create freer markets and so maybe become cheaper even despite being inherently more costly in resources.  Or alternatively it's probably more likely that longer term heavy use of that would just act as pressure for the Banks to reduce fees, which they can easily do as their cost base is inherently lower running a centralised system as they do.  So I would view transaction cost as probably not a sticky, defensible advantage.  
Lightning might be enough once it comes online to change that long run stickyness of fee savings vs centralised systems as the assumption is the vast majority of transactions are then no longer broadcast - just routed like TCP via nodes between users, which is truly very very close to free, though there remains a transaction fee to cover the cost of capitalising the node.  However with high velocity that fee should be rather low I think.


Hmm I was trying to keep this positive :)  But it does seem to be related yes.  Well see this thread about assumptions, you might like to jump on that thread.  
ps Trace asked and myself this question over supper at the Montreal scaling workshop.
@_date: 2016-05-14 04:52:32
The encryption is designed in such a way that double-spend detection still works between encrypted &amp; plaintext transactions.  It's described how in the 2013 bitcointalk post.  The main trick is that when a transaction is spent, it's public key has to be revealed.  So the data is encrypted with a (different) hash of the public key as the key.  then whether the coin is spent in encrypted or unencrypted form that will be detectable.  Which is a neat trick because until it is spent the miners do not know which who the sender is, nor who the recipient is, nor how much is being sent.
@_date: 2015-11-07 23:10:24
You know, someone who reads Chinese said that what the letter said was more like 8MB was the maximum they thought they could tolerate worst case.  Got lost in translation perhaps.
@_date: 2015-11-08 16:29:01




I think those are valid balancing arguments, and FWIW I think you do a better job than either Gavin or Mike at articulating possible rationales.  Clear discussion leads to conclusions and action.  Good.
I have seen Mike suggest the first one before (getting wide-scale adoption makes it politically harder to shutdown).  However that's maybe more a political than technical argument.  As things stand now from what explains here  Bitcoin is already exposed.
I suspect it is naive to assume no one would politically attack Bitcoin via policy demands on centralised parts of the infrastructure.  All it takes a few letters as happened with lavabit or hushmail or e-gold or many other comparables.  The political will for courts or governments to enforce their will on given transactions or whole transaction systems, is well documented.
Gavin particularly says things like it is not a problem if validating nodes increasingly run in a data centres over time.  (If I remember it was only finally on the podcast [1] that I got him to say that clearly though I had guessed he thought that.)  And also that increasing bandwidth doesnt lead to centralisation which I think is false on a number of vectors: orphan rates, exacerbates selfish-mining, validationless/SPV-mining, cost and convenience of maintaining full-nodes, miners that have said otherwise etc.
It is true that miners somewhat could afford better bandwidth - where it is available, and that can be a real-life issue.  However it also makes validating nodes also centralised.  (Mining is already centralised and validating nodes the remaining decentralisation defence).  See Validator vs Miner balance section: 
I would also say Mike doesnt care so much about censor-resistance.  He proposed red-lists.  When I spoke with him in Zurich he didnt seem to have let go of that or related ideas.  To him it's more that control and revocability etc is inevitable and he doesnt see it as a red line.
With Gavin I mean more there are trade-offs.  Centralisation reduces censor-resistance.  He seems naively optimistic that no one would exploit the centralisation issues that articulates.  I think even now we have a risk overhang of that happening, and that only gets worse.
To be clear it's all a tradeoff (except red-lists - those are a redline to me) so we do have to scale, and we do have to make Bitcoin function well, and I myself proposed block-size increases.
btw Another subtle point has made is that we can use bandwidth for multiple things, so it depends what we want to optimise for.  We could use it for privacy features - eg Confidential Transactions, p2p Coin Join in wallets, future protocols in this direction TBD.  They use bandwidth also so there is a tradeoff between scale and privacy also.
[1] 
@_date: 2015-10-15 22:41:05






I disagree with your paper's conclusion that it is a safe and therefore desirable thing to do to have an unlimited and free floating block-size.  Greg presented the arguments for why your conclusions are wrong on bitcoin-dev a few months ago.  The other academic working in the same area who cited you and also posted on list, learned late about the errors in your assumptions.  I wont repeat arguments here, I believe you read the comments, and from what I understand acknowledged some of the limitations.
The phrase I used to explain the limit is above "It is simply a matter of what is technically possible within security margins."  Would you agree that security is a consideration for Bitcoin?


I didnt say it was or wasnt.  I think that concept is unsafe to use as a rule for block-size because block-size affects centralisation, orphan rates, policy risk and potential security failure to centralisation risks.  Only meta-incentive protects Bitcoin from failure in that model.  We're not sure if meta-incentive is enough.  We also have to consider mal-incentive from bad actors.






That is not what I said.  What I said is I want to support as many transactions as can be securely supported as balanced against decentralisation security.  You imputed the false claim that I would be arguing for this to drive demand for sidechains.  I do not think sidechains need subsidy and anyway it would be unfair to demand it.  I have explained that sidechains are not primarily a scalability solution.  I think sidechains can and should compete via features, and that features should be back-ported to Bitcoin where that is practical and where it makes sense.  Sidechains are about improving Bitcoin - think things like Confidential Transactions, Segregated Witness (robust malleability fix), etc.
I dont think your claim even adds up - why would I be working on Lightning - which is for all intents on-chain (it's just a cut-out protocol that improves scale while providing a write-cache for Bitcoin) - if I was trying to constrain the scalability of Bitcoin for some nefarious purpose.
Trust me if I had conservative crypto snarks I would publish today.  (And I did work on it a bit, and I will publish if I find a way to do it).  That would allow elevating SPV nodes to full node security and hence open up a lot of  on chain radical scaling possibilities.


I never said anything about subsidy being requested nor appropriate: I am quite happy and think it appropriate for tech to compete on merit.
I say only that we should not break Bitcoin's security through a misunderstanding about the game theory of Bitcoin's security.


Were it not for breaking security by doing that, I would very much agree.












This not.  But a number of other things (in the OP or eg your "blocking the stream" in your presentation.. kind of unprofessional dont you think for a workshop focussing on constructively improving Bitcoin?)  Anyway bygones etc no grudge, maybe joke in poor taste.  Learn that there are a lot of smart people in this space, and to assume good faith.  That way your behavior will not cause them to doubt your good faith, and if you're moderately polite and constructive they're more likely to understand your technical arguments.


But you incorrectly assume we are arguing because of *acting* on a conflict of interest.  We are not and I like to think would not act on a conflict of interests. I described to you incentives we gave our employees to ensure they would have an incentive to work in Bitcoins interest.  It's not like we arent cognisant of potential future risk of action on conflict - we spent time &amp; investor money to minimise the risk.  We are arguing because of security and game theory.  I believe your game-theory is mistaken, and provided detailed argumentation and you acknowledged during the discussion around the bitcoin-dev discussion of the topic months ago.
@_date: 2017-05-31 11:17:03
Yes but two things: a solution is in front of them and has been for 5months.  If you look at their own statistics on the announcement they have enough transactions to achieve a lot of extra scale by activating segwit.  Secondly acting in haste as a matter of short-term politics is a factor commonly leading to moral hazard, and groups of people dont think well under time-pressure.  We must think carefully about long term value and Bitcoin being here in 50 or 100 years as digital gold and permissionless global e-cash depends on conservatism.
They have incremental scale, if they would adopt it.  (Not them, but bitmain is holding that back, so they should talk with Bitmain about why).  And much more scale can be achieved by an ecosystem wide grand-challenge that is collaborative, developing and deploying technology - no technology can scale if no users adopt it.
This is also bad for Bitcoin confidence, bad for Bitcoin users both retail and digital gold.  Bitmain is also invested in bitcoin (suspected 85k BTC minimum) so they also should care about the long term success, and also the value of their company as a manufacturer of Bitcoin mining equipment.
Anyway a bit of Ent like stay calm and think carefully for the long term is also important.  Fast things can happen, but companies and users need to talk with Bitmain and find a way to move forward.  This is **NOT** a technology problem at this point.
@_date: 2015-10-14 12:31:32
See  the source also has code for most of the 2 way peg, but on testnet so far (a missing part is implementation of the compact SPV proof).
See also a liquid, a publicly auditable federated sidechain, including Confidential Transactions, customised for inter exchange settlement.
coming early 2016.
@_date: 2015-10-07 14:47:01
I dont think dwelling on negativity helps Bitcoin or any particular technical proposal achieve consensus.
If you have a technical contribution, make it.  If not do not barrage people who are trying to progress Bitcoin and make it more awesome and scalable with negative emotion.
If you would like to understand the gist of consensus process, please re-read the IETF document and watch the linked video.
@_date: 2015-10-08 00:47:04
See I told you there was something for everyone in this video :)  You picked out the "perfectionist and process obsessed types".  There was also the "try to derail the process" types that you did not mention.  I see it more as the latter being the current problem, though I am hopeful that people will focus on what is good for Bitcoin and not play political or tactical messaging.  Technical discussions can be extremely fun when everyone is neutral, focussed and earnest and direct in what they are saying.
@_date: 2015-03-20 10:04:38
I'd view it as similar at the highl level view that one value tracking system is parasitic on another via steganography.  In the chaum coin case the chaum bank cant block or even detect the nominal valued watermarked coins representing gold deposits or what-have you.
So its the same same concept.  Of course the tech and threat model of the systems are different so there are differences in how you make watermarking work in the two systems.
@_date: 2017-05-08 09:30:34


Well I agree on the ideology very strongly, so I think we agree.
It is useful to understand about what Bitcoin user and hodlers views are, and priorities of different use cases - it being a p2p currency, and there being tradeoffs that affect each other where improving one aspect tends to come at the expense of another.  But "all of the things" is still an answer: that says balance improvements across more scale/lower fees, better scalability, lower CONOP.  Coincidentally that's my view - balance, and avoid judging use-cases, let the market decide.  But we should recognise that market deciding typically means people who are willing to pay more make use of scarce capacity.  Of course a capacity glut could be nice, and maybe we'll get there soon with segwit and lightning, but at times when demand outstrips capacity market deciding means he who is able and willing to pay more.  That's kind of unfortunate given that Bitcoin in some ways delivers most relative value to people in emerging markets with unreliable or no accessible financial services.
@_date: 2015-11-05 00:11:11


It is not at all clear that in the event that we need to soft-fork that the users will have the power to soft-fork.  We're talking about a centralisation failure scenario, where mining is even more centralised.  Miners control soft-forks.
Or more likely we get a worse centralisation overhang and policy abuse starts to creep in and becomes defacto accepted, as paypal policies got worse over time (paypal started as bearer ecash on palm pilots).


Take a look at BIP103, it has an implementation and has for months.  It's right there in the BIP text.  It's a small amount of code that you're talking about.


Good for you.  We have to consider the level of decentralisation.  If more power users and businesses stepped up and ran full nodes we could scale faster with the same assurance.


No he made a calculation error and when it was pointed out he revised it to 8.


I am happy for scaling to start as soon as possible.  It will be much safer and faster if everyone works together professionally and calmly.
You should take a look at the number of transactions per day over the last 2 years.  2-4-8 is exponential growth far higher than the transaction growth historically which is close to linear.
@_date: 2015-11-22 19:28:57
OK on that thread, it seems your abstract does not define what the proposal is, but did not seem to think the direction was good.  Cant really tell what your proposal is.
@_date: 2015-11-05 15:54:53


I explained why in the post you are replying to:


Understand this is not a vote, and the consensus protocol has no way to converge on a single consensus algorithm when people run competing different algorithms.  For it to converge they must be running the same algorithm (or a compatible one).  Things like the BIP66 fork that was manually fixed, demonstrate empirically that this is the case.
The problem with making it a vote, is it is just philosophically wrong: it is not a vote, everyone must agree before hand.  They could hold an actual vote, or agree on a compromise or whatever, but only when there is a clear rough consensus on a protocol should software be run.  Running competing consensus algorithms is a bad method of voting with unnecessary risks of network fork.
The voting of intent by advisory note in the mined block is not dangerous though it probably sets the wrong mindset of partisan thinking IMO.  We just want to focus on making Bitcoin better and stop bickering.


IDK - google is your friend?  Sometime next year I believe.  The date could / would be changed pre-deployment, it's just an example.
@_date: 2015-11-04 18:09:02
Because it is not safe to have multiple incompatible consensus rules running in parallel in the network.  The satoshi consensus protocol is not designed to handle that.
@_date: 2015-11-10 20:38:13
It's counter-intuitive, but actually bigger blocks can be an advantage to the producer of them.  See 
and here:
Also the SPV mining would make it an advantage for similar reasons as said above 
@_date: 2017-05-08 08:17:22
I would trust a high credit rating swiss bank account fairly high on your chances of portfolio still being there in 50 years for your grandchildren. Their asset managers will manage according to your risk profile, and in conservative choices try to avoid "and it's gone" end of the spectrum or hedge it. Swiss banks are quite prudent compared to international norms, IMO.
The main problem is the minimum balance at $500k.  Probably you need $2m+ to be worth doing even, the $500k is just a minimum below which they wouldnt care to open an account.
This is why I liked so much Obama's "swiss bank account in your pocket" meme, that's kind of what Bitcoin does in one sense - gives you some privacy, financial guarantees independent from local regime you live in, which is one of the main domains of swiss banks, but at much much lower minimum balances.   It's pretty hard for local politics to touch a swiss bank account, unlike domestic ones that they can freeze as step1, viz Kim Dotcom's accounts being frozen.
(Disclosure I am half-swiss, some cultural biases:)
@_date: 2015-11-21 17:45:05


He did, however I do not think it is fair to blame him for the fork; it was quite hard to predict, and no one else saw it in review either, and it was more of a discrepancy between behaviour of leveldb and bdb than a bug.  One has to doubt it would have been a bugdoor - it created a fork risk, but it was fixed, so not really the characteristics of a theft risk.


Yes the Bitcoin Android wallet:
Richard "Gendal" Brown has written a lot of informative blog posts about blockchain, bitcoin and how they could be extended or used within finance at  if you scroll back well before R3 for example.  I dont know the Barclays guy.
@_date: 2015-11-04 10:39:37
you said you couldnt find on google, but it's the second link down ;) 
@_date: 2015-10-24 10:21:42
no blockstream either.
@_date: 2015-10-08 01:31:22
Yes!  And fortunately for us, with lightning it looks like we can probably kind of have both.  
(Thread participants excluded) so shouldnt we be all excited and coding lightning instead of trying to create a storm of emotional negativity to deter developers and sabotage bitcoin price, and confidence in bitcoin and investors in bitcoin.  Lighten up people!  Focus on improving Bitcoin!
@_date: 2016-05-12 03:02:43
Who are the guys above and below Blythe?  Nice photoshop skills btw :)
@_date: 2015-10-13 17:28:26
Maybe this article by will explain more 
@_date: 2015-10-08 01:08:45
I find these comments somewhat non-constructive.  What are you saying that all of bitcoin-core is stupid, malintent and trying to sabotage Bitcoin, and only you, Mike Hearn are the hero trying to thwart them?  Who do you think kept bitcoind secure and scaled it over the last 4 years?  It's not like this is an easy task, or that there are spare bitcoin developers waiting in a queue to take over.  The honey-badger &amp; anti-fragility *is* the developers.
You complain about poor argumentation styles, however you are yourself very prone to engaging in those exact behaviours.  Of the people on Bitcoin dev list, of coders, you are basically the most aggressive and some active developers have unsubscribed as a result of the negative environment this has created.
You basically said you had no problem with BIP65, but would try to block it by arguing about hard-forks and that this would force a political point about whether a dictator exists in practice.  What kind of message does that set?  That is not the way to improve bitcoin.  BIP 65 is partly about helping Bitcoin scale by supporting a more efficient version of lightning.  Why would you try to delay or sabotage that?  To paraphrase something you told me when I pointed out that adding X509 certs into Bitcoin was a bad idea (tm) because X509 is largely MITM by NSA et al, about completely rethinking BIP 65 deployment mechanism after a quite long period of work and review, "that boat has sailed".
The minority trying to take over Bitcoin appears to most people who understand the tech issues, to be *you*.
But anyway lets *please* focus on improving Bitcoin and reduce the political maneuvers.
I spoke with a professional trader tonight, who is cursing the block-size arguments and crediting it with the fall in bitcoin price recently.  Similarly I have heard from investors, VCs, banks that non-constructive argumentation is bad for Bitcoin credibility, bad for investments, and bad for the investability of Bitcoin companies from VCs.  Surely you do not wish all these bad things?  They are certainly a factor and you are a part of the problem, by focussing on the tit-for-tat arguments rather than trying to find a workable compromise and trying to keep the technical discussion neutral, cordial and constructive!
@_date: 2015-11-26 11:42:18
BIP 103?
@_date: 2017-05-08 17:05:26
see also common reporting standard  which is taking effect 2017 and 2018 globally in almost every country, and reduces financial privacy.  the offshore wealth business must be a busy time for trusts, international tax planning etc for 2017/2018.
europe already had something else called the EUSTD  for the last decade in stages, but that was affecting european passport holders in europe; CRS is nearly globally pervasive pre-emptive disclosures of financial information.
this 2017/2018 offshore structure and international tax planning turmoil may also be bullish for bitcoin.
@_date: 2015-11-05 10:07:44
Yeah it doesnt work that way.  I'll say it again "the network can not reach consensus with multiple competing incompatible consensus algorithms vying for control."
Sure it is a feature and a good thing if users and devs could force a change if there was a hostile action by a group of miners, or by miners under legal threat.  But this is not that.
@_date: 2015-10-29 11:08:30


So it seems at first pass that the router needs to know how much money I am paying you so it can have me pay it that, and then pay you the same. 
I think you can readily hide the balance of the user on the channel from the router (all the router needs to know is the user has the money which can be done without revealing the start &amp; end balance).  And the balance of the router on the receiving channel from me as that is the routers money.
I believe it could CT coinjoin the transactions without the router knowing the individual amounts, only the aggregate amount paid.  Coinjoin is improved by CT.
The limitation for the router is it cant hold unknown amounts of BTC because you need to know the balance you have to spend with CT.
@_date: 2015-10-13 08:14:25
I dont know about the latest model, but in the previous two generations spondoolies did sell bare ASICs to other manufacturers and there was some equipment you could buy made by other manufacturers with spondoolies ASICs in them.
@_date: 2017-05-29 00:50:07
being anti-segwit is dumb, it fixes the malleability bug and improves a bunch of things.
@_date: 2016-05-15 17:40:14
They cant detect which coins are spent until the keys are revealed later.
@_date: 2017-05-14 20:17:49
what do you mean? the linked explainer is about engineering realities, surely that is relevant.
@_date: 2017-05-08 12:26:16
Well that's interesting and I suppose bullish for Bitcoin.  If even private banking clients are finding higher friction  to persuade banks to take their money.
@_date: 2015-10-14 12:26:54
I was looking forward to micro satellites relaying blocks :(
@_date: 2015-11-10 12:42:56
Well no I suspect you have a point before in fact: a leader could lie about it's clock and keep submitting signed transactions past the next key block.  It's a distributed system so you cant distinguish that from slow propagation, and there is no universally secure time.
@_date: 2015-11-05 09:57:58
A miner does not lose his reward for filling a block with pay to self transactions, and we cant prevent it because that is not provable.
@_date: 2015-11-17 11:36:39
I did not say that.  Disagreeing with people is fine, but dont misrepresent what people say.
@_date: 2015-10-15 10:37:43
It's a federated sidechain.  See appendix A of the whitepaper 
The advantage is we can deliver better security sooner and things like Confidential Transactions now.
Of course we are also working on p2p 2way peg (see the source code for elements alpha it contains most of the code for a sample implementation of a 2way peg already).  And we are also working on lightning.
Objective overall: improve security.  Put more business logic in smart-contracts.  Move more things on chain.
@_date: 2017-05-08 12:16:47
Because then you don't have to trust miners.
@_date: 2015-11-05 10:27:49


Well yes it does say something, it says there is a smaller centralisation pressure arising as we proved and agreed on the principle.  Now we might say it is a reasonable tradeoff but we cant deny that it is a tradeoff of some proportion.
As decentralisation risk is already at an overhang we need to do two things: ask power users and companies to improve decentralisation metrics; and secondly be careful about not also eroding dependent full node security.


There might be some positive decentralisation if new users or businesses run economically dependent full nodes or run their own miners without pooling.  The current stats do not seem to point that way, but it may be a countervailing factor.  I suspect it would be more than countered by the centralisation issues.  But anyway this kind of uncertainty is why we should not make rash decisions with huge factors and exponential growth pre-set for decades.
@_date: 2015-11-21 23:41:46
Yes I dont really agree with this analysis.  Seems to too narrowly interpret what is configurable and not take into account that bitcoin is programmable - you can configure it and use it in a number of ways.  You can no more declare sweeping conclusions like that than declaring in 1985 what the internet cant do, or what the C programming language cant be used for. 
Also he appears not to be taking into account the mechanisms and IT equipment used in existing ledgers.  Ledgers are not modified, they are append only, and maintaining that is taken seriously by banks.  Banks buy expensive storage servers that are certified as append only and to withstand legal evidence standards for tamper resistant.  Same with bitcoin ledgers, but via PoW rather than certified rack-mount expensive disk arrays.
Some people may even have seen the effect themselves: if your bank or broker makes a mistake, you'll see the erroneous transaction, and the correcting transaction.  Seems perfectly straightforward and to not create any conflict at all.  Sure it means there's more of a default towards people not being able spend or borrow against your assets (if the system is configured in that way), without your approval - but that's a feature!
If you imagine that a brokerage account using blockchains, with say split custody (signature from broker and owner) would somehow be irrevocable in practice in the event the broker fat fingered a trade, and it was not noticed by the seller approving it, that's not the way things work.
Again drawing on existing practice - if you end up with money in your account that is not yours by accident, and you withdraw it in cash from an ATM, you will have to pay it back.  Now they cant click a button and "magic" it back, but the process is established by hundreds of years of legal precedent.  You are ordered to return it, and if you very bizarrely refuse and hold out, they will find you in contempt of court, or send the bailiffs around to seize and sell your business or household property to recuperate the debt.
Lots of other configurations are of course possible.  Eg a court or ombudsman could have a 2 of 3 signature.  It is far from the case that the existing financial network technology has no edge cases or "and then we go to court" stages, with their error prone settlement and reconciliation processes.  Smart-contracts and blockchains improve those things which is why people are interested in their potential to improve cost, security, settlement etc is that they can enforce a-priori real-time audit rules and constraints that are programmed.  I certainly dont think we are in a position at this early stage  to predeclare classes of uses that cant be programmed in a new area of technology that is a major paradigm shift, where the full implications of smart-contracts are not yet fully understood.
@_date: 2015-10-10 12:31:23
Definitely true, I have heard first hand multiple complaints in each of those categories.
I suppose the next time I could request that they please reach out to these guys personally and express their concern.  (Or via the management of companies they are advisors, consultants or share-holders of who maybe more in their circle of contacts).
@_date: 2015-10-08 00:43:22
I dont really have a side of the debate - I just want to improve Bitcoin, and believe me so does everyone else.  That may involve compromise and being cognisant of the fact that technology developments are uncertain (eg how well lightning works in practice).
When I see arguments falling into behaviour seen in other FOSS projects described in the video, I find it disappointing, but hope those doing it will return to constructive working patterns and see the value in working together.
I am not sure what the claimed unethical behaviour is.  I view the Bitcoin developers are highly ethical people.  For example they have personally fixed bugs they could have exploited for millions of $ of Bitcoin with no inclination to take your Bitcoins and often for no pay, and some not particularly owning a lot of Bitcoins.
If you like Bitcoin you should emotionally support not attack this group of people.
@_date: 2015-11-21 13:43:28
Mike developed bitcoinj the SPV java library used in some smart phone bitcoin wallets.  bitcoinj is now maintained by Andreas Schildbach.
@_date: 2015-03-15 13:03:23
You could do this.  I worked out some details and optimised the crypto a bit.    TL;DR is 1KB encrypted values vs 8 byte unencrypted values.  I expect you could soft-fork it if people were interested.  While the tx are bigger, you need less of them to get the same privacy.
@_date: 2017-05-08 12:01:06
So is that an argument that they have bigger worries and they should stay SPV, the whole country +/- other than perhaps a few super wealthy (by local standards) people?
Like one could argue it's better to have trust miners pseudo-sovereignty than be priced out, period. I guess in an ideal world maybe they could validate with low bandwidth, but it might be difficult with their network and used 386 or raspberry-pi class machine, if they even have mains electricity and internet other than perhaps a low cost basic smart phone.
What do you think a power user in a country with $500 average networth could get?
@_date: 2017-05-30 19:11:07
I dont believe all the people who signed the agreement agree, there have been conflicting public comments from different signers on what it means.  I think the developer should listen to community feedback and also not seek to bias the agreement against the wishes of those who signed it, or they would have signed something changed out under them.
@_date: 2017-05-02 10:36:07
not sure.  i think 21.com's asics were manufactured for them on 14nm? Intel fab?
@_date: 2016-05-14 02:33:51
For the time-lock encryption version, the delay would have to be a system standard say chosen long enough to make it hard to decrypt fast enough to censor (10mins) but not too long relative to the velocity of coin spends.
Note the data to send with the payment is not that large just a key, but the recipient either needs to be a full node, or to fetch the relevant data from a full node, in the way SPV clients do - but for each of the encrypted antecedent payments.
@_date: 2015-11-26 17:42:09
@_date: 2017-05-07 23:28:36
maybe people could think about it a bit like if you enjoy collecting or dealing small volumes of gold coins you might reasonably buy some simple assay equipment and the consumables for it (the fullnode).
and similarly you might install a modest home safe to store the coins (the hardware wallet &amp; crypto steel backup).
@_date: 2015-10-22 17:24:28
Well because it's filled?
@_date: 2017-05-31 17:14:26
This has been explained at length.  Read here for example 
@_date: 2015-11-07 23:28:51


Agreed.  The way Gavin put it was something like the compromise is struck where everyone is equally unhappy with.  (paraphrase).  2-4-8 was my guestimate at that.
@_date: 2015-11-08 09:41:08
BIP 100, 101 and 103 are quite similar at a high-level.  I also aimed for low controversy (variant of BIP 102 in intent) and used some parts of BIP 101 (growth rate 2x per year), and the 8MB number that Gavin did some testing with, but I also used the date trigger (from BIP 103) instead of the miner trigger from BIP 100 and BIP 101.  Because I think is right that this is better: it is a user upgrade, and everyone must upgrade.  It is not something that miners force on users, but something that users decide and miners follow.  (Of course there is a balance - however miners have shown maturity here and are literally committed to bitcoin's future in the range of $100Ms of ASICs so miners should be considered users to for the purposes of upgrade.  An informational indicator of miner upgrade that is not a trigger could be useful as some have suggested on this thread).  The main difference is to aim for a shorter time period (4 years vs 20 in BIP 101 and something like 37? in BIP 103) because the future is uncertain and we can have a faster growth rate with less controversy if we can see the end number (8MB) and it it is not a scary number (unlike 8192MB aka 8GB in BIP 101 - yes in the future, but it's hard to predict reliably 20 years out).
@_date: 2017-05-02 09:13:02
bitfury is doing their part - making more 7.5 PH containers asap!  your part would be to buy some and put them online so they can fund building more.
@_date: 2015-11-23 02:20:32
Well there's like a 50 page white paper, and I think Joseph &amp; Rusty and others seem pretty confident it can work, and there are 3 independent implementations at various stages of parts of it.  Which is not to say all details are finalised as there are a number of tradeoffs or arbitrary choices one could muse on to decide which might be more pragmatic or better.  But the basic mechanism seems to clearly work.
There are some more *interesting* questions which might make it work even better.  Like removing hot wallet risk, avoiding R-value linking (see the dev list, someone's filled in the details on that now), and reducing capital requirements, store-and-forward networking compatibility; lots of fun to be had yet.
@_date: 2015-10-13 18:58:19
Segregated Witness could probably be soft-forked, and sidechains-elements shows I think that it is a robust fix; however there is added complexity to soft-forking it vs hard-forking.
Btw Segregated Witness for people not familiar is a robust fix for malleability issues in Bitcoin that works by removing the signature and script input information from the transaction ID calculation.  In that way the data that determines how a transaction is approved can no longer affect the tx-ID, so malleability by changing signatures or script input is prevented.  But the data is still retained and committed to as part of the block, so it is authenticated by miners.  As a secondary nice side-effect if you dont care why a transaction is valid you could skip downloading it, which may save about 1/3 of downloaded data (and more on the sidechain as the Confidential Transactions proofs are quite a bit bigger)
@_date: 2015-10-22 10:19:41
Looks fair to me.  Zerocash you get improved fungibility for the cost of more bleeding edge crypto, complexity and a trapdoor that needs a deletion ceremony a slow to create proof but compact transactions.  Confidential Transactions you get moderate sized transactions (2.5kB range +- some parameter choices), completely conservative crypto assumptions (same as Bitcoin) and reasonably fast to create and verify, and no trapdoor.
In an ideal world we'd have a system that does both.  But until then chipping away at improving from both directions is as good a way as any to get there.
@_date: 2015-10-08 00:54:26
Mike, you have said you do not see the value of face to face meetings.  When we chatted in person in Zurich we had an amiable and pleasant discussion.
Online you are prone to saying rash things that you would never say to someones face.  This *is* the value of face to face meetings - it avoids the misunderstandings from people getting too rash behind a keyboard, or piling misunderstanding on misunderstanding, or imputing malintent where it simply does not and never existed.
Please consider coming to the next meeting.
@_date: 2016-05-29 12:36:32
Personally I am hodling for 10+ years.  If Bitcoin is like early stage internet we havent seen anything yet, another decade to come.  
@_date: 2017-05-07 23:31:02
you want to try to keep it secure and free from remote compromise also.
@_date: 2015-10-10 12:16:29
Well for example it exacerbates the selfish mining attack.  Someone with enough hashpower to do a selfish mining attack, or close to enough, can make increasingly large blocks to slow down other people's verification time until the selfish mining cartel is mining all blocks.
@_date: 2015-03-25 23:03:43
I am guessing the poster intended to link to this article (with the same heading) 
@_date: 2015-10-13 16:26:17
The federated pegged BTC are secured by a threshold of functionaries (say 5 of 8 exchanges).  You can audit their balances using a sidechaind fullnode.  
You can also assure yourself of exchange non-fractionality (to the extent you assume 5 of 8 exchanges will not be in collusion to defraud users).  You can get access to features not available yet on Bitcoin (confidential transactions and chain enforced limit orders).
Other systems for Bitcoin exchange service are typically IOUs with a single party (or in some cases 2 parties) having custody and users having access to an online database that has to be reconciled.
With the federated sidechain depending on how it is integrated and which features are used by the exchange, you can get control of your private key, and apriori prevent an exchange going fractional (up to the limit of the security of the threshold of functionaries).
@_date: 2017-05-09 08:56:34
the fee market is dynamic to demand, and users adjusting priority and forgoing alternatives or paying with alternatives or later.  
@_date: 2016-05-14 13:27:22
You can also buy shrink wrap machines on ebay for not much - no scalpel required.
The other thing is it was a *windows* laptop.  Among host security people it is known that just accidentally it is hard to connect a windows laptop to a network to download security patches - they tend to get remote compromised by worms discovering them via port scanning them and remote compromising to install the worm - faster than they can download the security patches to protect against the known 0-days.
As Craig was known to have a career in host security, hacking &amp; malware or have colleagues with these skills, it is actually pretty easy to setup a fake hotspot that takes over a virgin windows laptop the moment it connects to the network.
@_date: 2017-05-12 14:56:41
so activate segwit.  even for reasonable people on the fence, this is a no-brainer.  the alternative with new development leads to 1-2year delays just for coding, testing and wallet/service/miner integration.  we can see that already segwit soft-fork is 17months since inception.  a planned hard-fork has never been done before.
also, this from u/wtogami is highly pertitent to the continued apolitical status of bitcoin which must be protected at all costs, and is in the interests of all participants, whether they realise it or not:


no one with any view should want to force their view on the system by any means.  and they should want to resist anyone else arguing for group behaviour to do this.
@_date: 2017-05-25 03:55:18
great story, the bear whale speaks, and now the bull whale :)
hope you bought back in to pick up some of the recent increases.
@_date: 2018-07-06 14:12:01
business insider article author confirmed with SIX that the "platform that will serve as both a cryptocurrency and securities token exchange over time" 
@_date: 2015-11-23 03:03:41
You would not need an individual node to have enough BTC, it could be split across multiple nodes (payment in different parts).  Joseph Poon has said he expects each user to be connected to multiple nodes (so they could be paid to rebalance send money from one channel to receive the same + negative fee on a different channel).  Then an individual user can send you BTC from a mixture of channels they have BTC stored on.
@_date: 2015-11-04 17:03:22


See BIP 103,  includes code in the BIP text.  Has been published for months.
More BIPs coming for scaling bitcoin 2 in hong kong 6-7th december.
@_date: 2015-03-28 21:00:18
I guess you could allow the merchant to chose, by binding the acceptance of such transactions to the address type.
It might be safer to burn the coins than give them to miners - scope for collusion with a miner otherwise.
As a general principle I think you want to have people experiment with ways to increase the security of fast acceptance of transactions in parallel with not breaking the existing system.  Preferably in an opt-in way which doesnt break the existing unconfirmed transaction. 
A simple/crude share-broadcast could be to direct connect to big miners and pools and ask whats in their mempool - not as decentralised but more immediately doable and could quickly get an indication of whether a double spend is likely to happen or not from a high proportion of hashrate.
@_date: 2015-10-13 16:49:53
With ripple afaik, BTC are handled via a gateway IOU.
@_date: 2015-11-13 16:00:26
see also similar topic of recent thread  of a few days ago.
@_date: 2015-11-05 16:14:01
The idea is a bit weird but that it more than pays for the loss to suffer losses until you buffer up 2 unpublished blocks in a row, because when you do that you have an unfair information advantage: other miners are not working at the tip, and so are wasting their work - you can orphan them with very high probability even with no ability to race publication: you have 2 blocks in reserve.  From there you repeat the attack.
Pathological blocks that take others longer to validate can probably make that worse because when you release 2 blocks you can have others take minutes to validate them so they dont even switch immediately when they should to the longest tip.  has published attacks where there are existing quadratic computation worst case types of transactions that can take quite a bit of time to validate already with 1MB blocks.  Those things need to be fixed in order to increase the block.  knew some of this, but not all of it, because it was unpublished until it was shown to be non-dangerous and put one approach in BIP 101.
@_date: 2015-11-07 21:31:47
That's from 
@_date: 2015-11-05 15:49:33
I agree.  And here we are :)
So lets focus on the signal?
@_date: 2015-11-11 09:03:55
I think that or something else will be adopted in a bit (after review, testing etc).  Maybe a range of things in stages.
@_date: 2015-10-14 18:58:43
Well it down-voting clearly affects the default visibility of comments.
If the comment is generally uninformative or not on topic etc that is a useful function.
However it seems like in this subreddit more than half the down-votes are more like sabotage - the comments getting down-voted are often perfectly valid and good discussions.  The downvoters motives are unclear - troll amusement, difference of views that dislikes open discourse.  It's unproductive.  At that point it's debatable whether voting is helping or hindering useful discourse.
I think voting is good, but not when it's being gamed or stuffed and probably amplified by paid down-vote bots or tools.
@_date: 2015-10-19 20:53:26
related total hashes ever 
more than 2^80 by now.
@_date: 2015-10-08 01:29:02
Yes.  They can say what they *want* but they cant tell engineers or computer scientists how to do it, or what the technology can provide at a given point in time.
The people doing engineering and computer science are working on lightning to scale bitcoin.  check out the dev list, irc and github.  multiple individuals, multiple companies, multiple implementations.
Scaling bitcoin, like really scaling bitcoin, has little to do with changing the block-size.  However I do agree that a short-term block-size increase is useful to give space and time for that work to be done, and for people to see how well lightning works in practice.  Hence my 2-4-8 proposal over 4 years.
@_date: 2016-05-14 05:12:44
You can encrypt the key as part of the broadcast payment.  The sender needs the recipients public key anyway.
@_date: 2016-05-29 13:22:19
Suppose you could stagger them in trenches so you have the option to sell 10%/year rolling or reup (relock them) if you decide not to.  People do that with term investments sometimes.
@_date: 2015-10-15 10:24:52


Actually that is an unvalidated and quite possibly incorrect assumption for much of that time.


Change is change either way.  It was at no time in doubt, since the block-size limit was there, that it was there, and so by efficient markets hypothesis that fact is baked into the business plans and expectations about fees.  Note &gt; 99% of volume is already off-chain.  We see all around us the positive and negative effects of the fact that most transactions are off-chain.


Incorrect.  You did not appear to consider my suggestion eg 2-4-8MB parameter change over 4 years, while we wait to see what Lightning can achieve for improved scalability.
It is simply a matter of what is technically possible within security margins.  Decentralisation is quite weak right now, I assert Bitcoin's main differentiator is it's policy neutrality, permissionlessness, and user ethos features.  We at an overhang of risks right now to those features.
I and others are working to improve decentralisation via GetBlockTemplate-like technology, company education about running economically dependent full-nodes.  We also are working on Lightning along with others.
If you want to make a concrete scalability proposal or BIP, go ahead, and be sure to include justifications a rationale about decentralisation security.
You may want to read this explanation about the state of decentralisation security:


At times your level of discourse indicates that you have problems interacting in a neutral and constructive fashion, which is unusual for a former academic.  If you are interested in employment in this sector, you probably want to try to come off as more constructive in public, just some free advice.  I've seen others lose out on opportunities by getting too emotional or rude online, despite having good technical expertise.
Regardless Blockstream is basically "Greg, Pieter, Adam et al incorporated" ie a bunch of Bitcoin technologists who figured they could make Bitcoin more awesome faster by having a company and resources.  Making money by providing services and support is fuel to hire more people to make Bitcoin even more awesome and deliver value to end users by improving aspects of the financial system with financial institutions.  I still think Confidential Transactions are really cool even 2 years after thinking up the idea.  (I didnt actually write about it for 6mo back in 2013 because I wasnt pleased with the space overhead and was trying to optimise further for practical inclusion directly in Bitcoin, perfectionist factor maybe).
In an ideal world I think we would like ALL transactions to be on the Bitcoin main-chain and benefit from the same security assurances.  However in the real world, this is not possibly without compromising decentralisation security in the short term, and probably not possible period due to available bandwidth on the internet even ignoring centralisation risk.  (If all derivatives, forex, cash, IoT, wire xfer, credit/debit card, stock &amp; commodity exchanges were on chain, with a good degree of decentralisation as current ratio, it would likely more than saturate the entire planets internet bandwidth).
We would also like faster, more permissionless development so people can independently and in competition improve Bitcoin.  To enable that we need things like sidechains or extension-blocks (also a framework for extensibility).  Think like rootstock, truthcoin, zerocoin as sidechains and others too.
So given that &gt; 99% of transactions are offchain and suffering mostly from full custody risk, I think we should both improve Bitcoin scalability and improve the security of coins currently offchain.
That's what we're doing: what we say we'll do.  You like to talk about conflict, now technically a potential conflict exists for most people in the industry, probably yourself, Gavin/Mike - anyone has investments, contracts, employments, advisory positions with VCs, etc.  So I think the bigger question is are people firstly technically competent, playing fairly (no bullying tactics), and be working for Bitcoin's interests.  I can say yes to all of those.  Can you?
As we've said before Pieter &amp; Greg have parachute contracts to work on Bitcoin paid by the company we formed for a year in case Blockstream does something they consider unethical for Bitcoin (eg in event of management change leading to bad decisions).  Also everyone at Blockstream has Bitcoins awarded in addition to stock options to align them financially with Bitcoin's success.  Lastly I believe Greg is on record saying he has more $ in Bitcoin than Blockstream stock.
@_date: 2017-07-13 20:06:43
well I dont think 2MB is going to onboard a lot of on-chain users, people who think data-centres are fine, have talked about more like 8GB blocks or 20GB blocks and such numbers.  transactions being cheap has to do with supply and demand.  the specific and stated intent of the exponential growth 8MB to 8GB block proposal of a few years ago was to provide a keynesian discount to subsidise free transactions.
@_date: 2017-05-08 08:24:22
made some edits - that do it?
@_date: 2016-05-14 00:13:20
The sender encrypts the transactions and sends them on the p2p network as usual.  The miner assembles encrypted transactions into a block, checks the encrypted transactions are not double spent (which is still possible to verify), and mines them.  Later the keys are broadcast and second stage mining happens.  Invalid transactions can be ignored, but it becomes a consensus rule that valid now decrypted transactions txids and keys *must* be mined, or the miner can no longer mine.
@_date: 2015-10-20 12:59:21






I didnt even mention it, it's that obvious prerequisite to comment:
People who are expert in host security looked at the headers and tried to use the service and probe the service's security configuration.  No indication of spoofing was found.  
@_date: 2015-10-27 23:43:00
I tried to sign up for an account.  It failed.  adam3us / adam
@_date: 2015-10-21 11:21:40
A "blockchain share" is not a bad way to think about it.
@_date: 2015-11-10 00:07:54


It's easier when people dont assume bad-faith or get angry about simplified incomplete "solutions" not being adopted yesterday.
@_date: 2017-05-08 07:51:07
would you care to point out an untrue statement somewhere? sigh.
@_date: 2015-10-21 10:22:02
I saw the headers and discussion from a host security expert.  I believe others have analysed and posted online.  If you think I am lying that I saw the discussion,  I dont need to prove it to you, it's obvious, and you can google the public analysis.
@_date: 2015-10-25 06:06:57
Well we have the federated peg running (appendix A from the white paper) since June 2015, the code is on github.  In the code most of the 2wp is implemented, there is a bit more to do relating to compact SPV proof parameter tuning.  Once that is done it can constitute an implementation of an example mechanism for a BIP for discussion.  BIPs take a while for discussion, alternative variants and analysis; and the merge process takes a while also, though that should improve with VersionBits which people in core are working on in parallel.  (Allows multiple soft-forks to be adopted or not in parallel rather than one at a time which constitutes somewhat of a bottleneck at present).
@_date: 2015-10-14 13:02:04
Would hiding votes avoid collapsing (with [+] marker) massively downvoted articles for 24hrs?  That might be useful as reddit is mostly scrolling by - after 24hrs a thread is no longer so interesting.
@_date: 2015-11-19 18:25:01
There are others on the lightning mailing list.  And Joseph Poon and Thaddeus Dryja are working on it too at protocol level and are startign their own company.  And there are several other companies who have released alternative pre alpha stage implementations.
@_date: 2015-11-22 17:28:59
It's artificial due to the way it's measured - it doesnt really oscillate like that.  The hashrate is implied by looking at the rate of block-production which is the only empirical evidence that is reliably available.
If one instead managed to get a feed of shares from all the pools or trusted them for a information feed of current instantaneous hashrate some of the spikyness would be removed.
@_date: 2015-11-04 17:38:09
Maybe you dont code, but that *is* runnable code.  You maybe surprised by the short amount of code, but it is a small localised change.  Would you like to retract that?
@_date: 2015-11-05 15:44:38


I believe I said in the post you are replying to that in my opinion the security benefits of on-chain use are preferable.   I'm sure however that there are some things on-chain that dont particularly need to be, and many things off-chain that would much benefit from being on-chain.  For example did some analysis to show that 45% of transactions are under $1 in value.  
Chain-space is not free: at the very least there is a security cost (loss) to expanding it too fast.  If we erode security too much, then main use case of permissionlessness, and even Bitcoin itself can fail to policy abuse or centralisation.
If securable space is constrained by decentralisation metrics then it may not be a good tradeoff to erode security to make space for &lt; $1 transactions and UTXOs.  Hopefully we can have our cake and eat it with lightning, but for example it maybe better to see micropayment value transactions be off-chain (changeTip like) and &gt; $1 be on chain and preserve permissionless and network policy neutrality properties of Bitcoin, than force them all on the chain and break those assurances for everyone.  Some grey areas in there but I hope you see the tradeoff in a real world with market limits.  I say market limits because the ecosystem companies are by their collective actions expressing an economic (lack of) interest in the level of decentralisation by whether or not they run economically dependent full nodes, or small mining activities to decentralise that.  Most power users and ecosystem companies are freeloading and then simultaneously complaining about the effects of their actions, or arguing that they would like to erode security further from a weak point to save them the small cost of installing, running and securely maintaining a full node.
We as power users and ecosystem businesses could focus on improving to create headroom for more securable space.  I argue we should.  I have some miners, and I run a full node.  How about the people arguing that they we should reduce security to makeup the difference?
 
@_date: 2017-05-12 14:39:06


that part is incorrect.
@_date: 2015-11-05 16:28:56
I proposed 2-4-8.  Greg &amp; Mark proposed and improved flexcap.  There are other proposals also.
@_date: 2015-11-05 10:00:06
Because of the selfish mining attack - over a certain size a miner or a cartel of loosely cooperating miners can gain advantage.  (Counter-intuitively it is the to advantage of miners not to broadcast blocks once the collective is over 25%).
Note part of the BIP 66 discovery of the rate of unvalidating mining (so called SPV mining) was that there was a high rate of cooperation in sharing headers for validation free mining - that shows &gt; 25% cooperation is defacto possible, and even at many times individual miners have over that hash rate.
@_date: 2015-11-13 10:14:35
Nick Szabo answers the "What are Bitcoin's most important differentating properties to you?" question directly put by trace on a panel  video of panel segment 
@_date: 2016-05-26 16:14:05
The compact threshold multisigs (polysig, treekeysig and aggregated schnorr) are all built using Schnorr.  So that is related.
Accountability is selectable (if you want it/need it you can opt into it).
@_date: 2015-10-10 12:23:33
These bugs are rare, and get fixed once discovered.  They were more frequent in the really early days apparently.  So the risk is receding I would say.  An example would be the disclosed bug about  which would have allowed a malicious fork of 32-bit from 64-bit full nodes.
I think that would have been exploitable.  eg figure out a map of the full nodes of major miners and infrastructure companies as to which are on 32-bit node vs 64-bit.  Make a payment on one side of the fork and cash-out on the other.
@_date: 2015-10-15 09:51:53


It doesnt help anyone, for sure.
Maybe it would be useful to people doing this kind of thing to understand that it is bad for Bitcoin.  Investors, banks, and traders have all complained that it is bad for Bitcoin and to please stop the infighting.
You'll feel better about yourself also if you're participating in a discussion and you do so in a constructive way.  Getting angry, trying to be rude to people with various views is not useful to anyone.
And that's the people who like Bitcoin.  Those who dislike Bitcoin because they are invested in alt-coin things or proposing blockchain without Bitcoin as a model, they're probably happy or possibly, it is within plausible, that those kinds of people are funding the various sockpuppet, voting and shill attacks.
@_date: 2015-10-13 17:29:26
See also article by on bitcoin magazine 
@_date: 2017-05-14 19:52:41


u/luke-jr presented code to people present at the miner / dev meeting last july (2016), ahead of schedule.  BIP  and code
  what you are referring to is a different proposal released &gt; 6months later.
and the meeting transcript if you want to read the discussion 
segwit was a compromise, it increases blocksize to &gt; 2MB with todays transaction patterns.
what is unconstructive is people who dont understand technology, demanding things that will slow down access to scale.  "compromise" you say.  on what?  we went through how changing to a HF will take lots of extra coding, testing, integration and longer deployment.  
@_date: 2015-10-08 02:54:54
Yes I dont understand if a "root" is a "fixed exchange rate between sidechains fuel (Roots) and Bitcoin" doesnt that have an existing name, "bitcoin", or "pegged bitcoin" or "sidechain bitcoin".
@_date: 2015-03-28 21:24:21
I think share distribution for this purpose probably gets complex yes.  eg you need to actually send the block (or a precis of it) also or you wont know something is double-spent.  But thats lots of data unless you have invertible-bloom or relay network to compress it.  And if you actually sent thereby all the transaction variants you pre-arm miners to do RBF as a side-effect.  So I had suggested at one point to send a partial serialisation such that its verifiably committed to by the share but not serialised enough to mine for an actual block candidate.  IBLT or relay-network at full-network level might change decentralisation and independence of block selection policy leading to selection bias or group-think (I'll do what he's doing exactly as then I'll be less likely to have my blocks re-orged).  Miners are supposed to make independent block-choices to achieve policy neutrality, such things may erode that a little.
@_date: 2017-05-10 12:26:19
I think it is useful for discussion to think about each trade-off in isolation and hopefully focus on the multi-dimensional trade-offs and rationale rather than simplified forgone conclusions.
Quite interesting and slightly surprising balance of views on the last two straw polls.
@_date: 2016-05-29 13:23:54
@_date: 2015-10-10 16:13:17
Well the supply side inflation will fall, so to the extent miners are selling coins to pay their electricity bills, that should be good - maybe $500k less per day of Bitcoin coming into existence.
If hypothetically prices stayed flat through the halvening a number of miners would probably stop mining because they'd become electrically loss making even factoring in sunk costs of hardware.  So with the price held constant assumption, the hash rate would fall and after the difficulty adjusts within some weeks (however long 2016 blocks takes to mine at the reduced hashrate), that would make the remaining miners more profitable, which might bring some of the miners back but not all.  I guess thats good for people with efficient hardware and/or cheap power &amp; cooling.
@_date: 2015-10-14 08:05:22
57+ points for a trollish and false claim.  Apart from trolling r/Bitcoin seems to have ongoing upvote &amp; down vote attacks, maybe bots or something.
@_date: 2015-11-05 10:18:05


Not that I support censorship, but you realise breaking consensus breaks Bitcoin?  Ie you just said "people dont like it that I am campaigning to put bitcoin at mortal risk on the bitcoin forum" wel doh, of course they dont like it.
As you've seen I'm more inclined to burn cycles explaining and to argue against censorship.  But think about what you're saying.
I expect what you meant to say is campaigning to achieve consensus around a proposal to improve Bitcoin.  That should be and I think is in scope for the moderator policy for this forum.
@_date: 2017-07-19 21:08:35
you might note that segwit itself does use selective peering, as does bip148.  so this limitation should not be a total surprise.
@_date: 2015-10-13 16:51:49
The sidechaind includes code that validates Confidential Transactions.  Despite the amounts being not-disclosed (except to the sender, recipient and potentially 3rd party auditors), it is publicly auditable that the non-disclosed amounts add up.
@_date: 2015-10-13 18:03:52
With the federated peg, withdraws are same speed basically as normal bitcoin transactions.
Moving bitcoin into the sidechain may take longer (it's a chain policy subject to configuration).  But exchanges may bridge the deposit time for users as a service (time-preference) by keeping reserve coins already in liquid (or in a form that can be quickly deposited eg threshold multisig between offline exchange key and the federation, a kind of threshold multisig greenaddress).
Much of this is up to configuration or integration choice, so we'll see which features exchanges build from the sidechain tech, but that's the outline of what's possible.
@_date: 2016-05-29 13:11:26
Yes.  Thinking of using OP_HODL to resist the day trading impulse ;)?
@_date: 2017-07-28 12:54:48
I listened to him pitching people at a conference in amsterdam, and personally talked some people out of putting a big portion of their bitcoin into it.  Magical thinking nonsense it was.
@_date: 2015-10-14 09:40:53
See the reason I'd say there is some rentabot upvoting and downvoting goin on is for example above who makes a balanced reasoned commentary gets -ve votes and who posts something inflammatory and untrue for personal amusement gets +57 instantly.  Actually now it is +15 so maybe insta bot upvote, then slow human downvote.
Now up/down voting is cool etc but it should be one vote per user and no bots.
@_date: 2015-10-01 14:51:52
Obviously, but all indications are Bitcoin is over centralised already.
@_date: 2015-03-28 20:50:22
means transaction malleability.  The encoding of the signature itself can be varied a little, and the input script is not actually signed (the signature is a value in the input script).  They can be malleated somewhat though there are fixes implemented and planned for most of them see BIP 
@_date: 2015-10-08 14:11:22


I could say something similar, that a few days later you released XT (which is not viewed as a constructive move by most of the development community, and I was hoping you would not do, due to the non-constructive nature of the move).
About the class action netiquette beach: actually that was a private conversation about what a 3rd party said that someone misattributed to me saying, and then broke etiquette to post publicly and falsely claim I said it.  I believe I explained this to you before.  Let me correct that clearly again: class action law suits are a bad idea for FOSS and Bitcoin.  In fact I have declined to collect the funds from the several class action lawsuits on principle (you can be automatically added to class actions by being a customer of various US companies.)  That's probably another example of in person being better - people dwell on and remember the negative more than the positive from online things, and forget the clarification or the correction.  Probably an analog of negative news sells in the human psyche.  (To be sure when people started talking about it I did engage in the conversation about the hypothetical, but it was *not* my view.)  Btw the lawyer who was chatting about the legal theory of it on the twitter thread was at the conference and introduced himself and said it was a legally interesting hypothetical topic.  In case you didnt follow that, he seemed to view it as unlikely to work.  I think the bigger point is it would be a horrendous precedent for FOSS and Bitcoin if it did work!


Dude, you should take a listen to your own podcasts and videos sometimes.  You may have in mind what you meant to say, but what you actually said and what people interpret you to mean is often highly misleading, untrue, blatantly misconstruing what others are saying, or hugely insulting to wide swathes of technical people!


I think you affect things in a positive way by being a positive example: saying things in non-confrontational, realistic balanced way, suggest compromise incremental steps forward, and being polite and respectful of peoples opinions, so you can stay part of the dialog and striving to be accurate and balanced in your claims.
On actions and progress, I'm not done yet, and I dont think others are either.  People are working on BIP proposals for the Hong Kong Scaling Bitcoin 2 workshop.  Maybe you would like to also?


Well as you know I explained that Gavin seemed to have restricted availability and you dont work on Bitcoin on the weekends unlike others, and I was sitting in front of Greg (a while back now) when he opened his computer to see a message from Gavin something like 2hrs ago saying I can talk in the next 40mins with 1hr notice or something.
And then there was the other conversation someone tried to suggest but Gavin was unavailable.  (Though that person was quite remiss in my opinion in his also very last minute when doh people are not going to be able to be available on the drop of a hat).
Because Gavin &amp; Greg came to the Montreal workshop, they had a chance to meet in person.  Gavin &amp; I did the podcast with Trace Mayer   Gavin, Greg &amp; Trace &amp; I had supper and a few more hours of general conversation.  AFAIK you were invited, I expect there would have been a travel bursary even, but you declined at that time.
That's fine - people get tired of travel.  But I do think the demons recede in person.  I saw several other people deciding that after talking face to face in various hallway conversations in relaxed way that the other person was far more reasonable, probably didnt mean what he sniped at them online or that they were closer to a shared view point or at least understood properly the rationale than before going there.


Absolutely.  But action is not achieved without planning and rough consensus.  We dont get to rough consensus by dwelling on the rude things someone said in the moment of an internet flame war, but by genuinely trying to balance the motivations and needs of users and opinions of other experts.
Not by saying eg all other experts are idiots or are rejecting user views.  Both of these things are clearly untrue.
You should also really be careful of your construal of other peoples opinions: they are really inaccurate, speaking as someone seeing his views typified.  Really I think my views, if you try to neutrally understand them are I think reasonably balanced, or at least I strive to (of course like the next guy occasionally I retort to things).  I do think USENET flamewars and practicing holding tech discussions in insane signal to noise level forum is good practice for holding your cool and being constructive in the face of flames :)  Some misspent time from my time at university.
I do expect you have good intentions and want to meet your view of what is important for Bitcoin, but I think you are not balancing the other factors correctly, and are undervaluing Bitcoins main differentiating feature (decentralisation security) as Nick Szabo has pointed out a number of times.  Also that you or maybe more Gavin are naively optimistic that no one would attack anything, plus from Gavin really sort of lack of adversarial thinking or maybe inexperience with security protocols perhaps.  (More Schneier's law stuff).
To borrow from your book (the one which states how many years of experience you have in google or bitcoin) I've been working on privacy tech, distributed systems, and designs achieving censor resistance for &gt;20 years, have spent 20 years in industry on applied cryptography, security; have worked on and implemented p2p systems, and have a PhD in distributed systems, worked on ecash protocols and researched ways to do decentralised ecash with Nick Szabo, Wei Dai &amp; Hal Finney and dating back a similar time, and I'm telling you you're getting the balance significantly wrong.
Now that shouldnt deter you, and I'll be the first to be happy to hear an argument of how I'm full of shit, and I've misunderstood something.  But you do have to overcome the Schneier's law here, and in my view you've so far failed to convince anyone else of their respective mistake in logic or balance.
I understand frustration with decisions that seem wrong from ones perspective, but I have to say I consider there are ethical problems with unilateral lobbying people who dont understand the security tradeoffs to vote, like we can do reactor design by populist vote, or do vote stuffing as warned about in the IETF rough consensus doc posted on bitcoin-dev, I think that is not constructive and not the way to do security design tradeoffs also.  If you cant pass rough consensus you have to consider that you may be wrong or agree to disagree.  If you want to scale bitcoin, which is a good objective shared by all, the path is quite clear: go back to working on payment channels v2 as in lightning.  Ie write constructive code.
You may have technical points that people are missing or not reading properly if you mix them with too much politics or emotion and turn off the reader.  That would be bad, because we should clearly and cooly understand all technical commentary.  So if you think people are misunderstanding your technical argument I'd encourage you to try again perhaps in a doc phrased in a neutral way with point by point logic assumptions.
@_date: 2015-10-14 22:37:06


Changing Bitcoin parameters is very complex and requires careful analysis.  Having a lobbying campaign in backroom talks with companies, nor down-voting wars, name-calling, nor censoring comments are useful for security design.  Security design should be done calmly and listening to and evaluating technical comments, and analysing things.
If you want to know about how consensus works read  as he explains it's not a unanimous vote.
I also did a podcast with Gavin on this topic, you can listen to it here: 


I view lightning is an opt-in write-cacheing layer for Bitcoin.  It just makes Bitcoin faster and more scalable.  The main changes needed for lightning have been analysed and discussed for a long time now in bitcoin development, and they seem to be relatively uncontroversial, and with wide support.


I dont think I delete any arguments, I dont believe I have the technical means to delete anything or certainly have never used such means.  I have not personally attacked anyone.  Having a calm discourse is good - you hear other peoples opinions and maybe learn something.


I think there are some fundamental limits to scalability.  The more users adopt Bitcoin, and there more full nodes there are, the more traffic gets broadcast around.  It does not scale linearly, the bandwidth cost per transaction goes up the more nodes there are.


I would very much like to see this world get more decentralised.  Dont forget also miner decentralisation.


I do not think I have.  Name one.


I am not censoring any debate.  You have to consider the tradeoffs between lightning and a block-size that is larger but doesnt reduce decentralisation, vs a large-block and no lightning.  Lightning is a good thing.  If there is a huge surge in demand, then lightning should be able to support more transactions than would fit on Bitcoin at any plausible block-size (below that which would kill decentralisation).  Lightning transactions are on channels anchored by Bitcoin transactions, there will still be transaction fees to incentivise miners.  It maybe that miners see more transaction fees because there are more transactions, and one channel anchor can afford to pay more than fees on a cup of coffee because it contains say 1,000 cups of coffee sized payments.
I dont think most people have a negative view of lightning, even people who are not worried about decentralisation.


I do not think this is correct.  I think some people just like to focus on the negative or work up conspiracy theories.


I suppose you like the governance model of a benevolent dictator better than the current consensus based one where multiple views are heard, debated in a constructive way.  You are trying to construe a decentralised development model as a bad thing.  I am not controlling development.  My co-founders Greg &amp; Pieter have contracts that allow them to quit and be paid by blockstream for a year to continue working on Bitcoin independently, if they consider blockstream asked them to do anything relating to bitcoin code that was in conflict with Bitcoin's interests.
Anyway take a listen to the bitcoin.kn podcast.  I thought it was a reasonably balanced discussion.
@_date: 2015-10-07 10:50:42
This presentation by Ben Collins-Sussman and Brian Fitzpatrick, two subversion FOSS project participants, posted by is also relevant and interesting.  I think people should watch it and draw their own conclusions, something for all sides to be sure, it's quite balanced.
specifically 
@_date: 2015-11-12 11:38:43
Also incorrect: there are implementations of BIP 102, 103 and have been for months.  Other BIPs are being implemented for scaling bitcoin 2 in hong kong dec 6-7th.
@_date: 2015-11-05 16:49:59
I think you are reaching incorrect conclusions because you make an incorrect assumption that hard-forks can be voted on by hashrate and safely (though unprofitably) coexist like soft-forks.  Nakamoto consensus doesnt work like that - it cannot converge with conflicting incompatible consensus protocols.  That is because each version diverges and thereafter ignores other versions blocks.  At best you may get a warning.  It is unnecessarily risky and creates unhelpful partisan thinking.
If you want diversity of node code, you should IMO focus on using libconsensus to have diversity but using the same consensus code.  Before BIP 101, that is what XT did, with Mike adding opt-in features but with standard consensus rules.


You are describing the assumed result after everyone has worked together to change the consensus code.  That is the status quo eh?  There are competing implementations, all using or trying to implement the same consensus protocol, and an intentionally decentralised decision making process in one of them (bitcoin core).
However your proposed process to get there doesnt work for technical and human factor reasons.


What is your thought to the text written by Mike on the bitcoin xt site that he proposes to be the benevolent dictator.  Did you read it?
@_date: 2015-10-16 10:16:18


Sure I understand.  I was assuring you that I am not acting on any conflicts of interest for gain, as you seem to assume.  I think I would know if I was, I take fealty to Bitcoin's success seriously.  Bitcoin is bigger than Blockstream (more important for humanity), though understand Blockstream was setup with the intent to improve Bitcoin, by developers who were already working to improve Bitcoin, and have a long track record of doing so.  It's not some dark and unknown opaque megacorp - it's founded by core-developers and privacy technologists with long and good track records.


It would be better if there were more core developers, working for independent companies or even independently funded by users or by companies via a foundation.  


I agree, you should not have to trust any individual nor company.


I think I explained, we have done a number of things and are doing some more not yet announced.  We considered sponsoring a program to try to help encourage gifted developers to take up Bitcoin core development.  I tried to interest another Linux kernel developer who is a friend to start doing Bitcoin development (I did not so far manage to).  There are already two ex linux kernel developers in Bitcoin (Jeff Garzik &amp; Rusty Russell)  We also planned to produce better core code and algorithm technical documentation materials to make it easier to learn core stuff.
The founders of the company are pro-Bitcoin (which you might expect as most of the tech people were actually Bitcoin core or protocol developers) so we were concerned to ensure other people we may hire would also be aligned to improve Bitcoin.  We gave all employees a time-locked Bitcoin grant, like an option but in Bitcoins as well as blockstream stock options.
We also tried to reduce potential for conflict of interests: a number of legal employment contract terms I mentioned in the thread, and Greg and Pieters parachute right.
I think we've done significantly more than any other company to give back to Bitcoin core, and to be transparent about how and why you can trust us, but simultaneously dont have to.  The code is also open obviously, so anyone can see what is written.  I've argued for Bitcoin development to be open and decentralised.  Mike who is the "benevolent dictator" of the software on which subreddit you are hanging out, wanted to scrap that and make a centralised development model with him in charge.  What do you think about that?  Better or worse?
Open to other ideas of course.  I am very concerned to see Bitcoin development be decentralised, and stay that way, and to improve it's decentralisation against policy attack.  I wrote quite a bit about that online and talked about it on a few podcasts, including with Gavin on bitcoin.kn  and on epicenter with hosts Brian Fabien Crain and his cohost  Blockstream also co-sponsored Scaling Bitcoin to foster constructive and balanced discussion and analysis about how to scale Bitcoin securely.
I dont think I am the enemy here, and I am not sure what more we can do or we would probably be doing it.
@_date: 2015-11-07 18:12:10
Indeed, as they say in IETF "rough consensus and running code".  There are multiple BIPs already implemented: BIP102, 103, and several more being worked on for presentation at the workshop.
The workshop is live-streamed and there are some travel bursaries available for people who dont have funding to present.
There was also an IRC channel 
@_date: 2015-11-04 23:22:13
Have a look at transactions/day going back 2 years:
it has not been exponential.  2-4-8 is exponential and growing at a far faster rate than bitcoin has on that graph.
@_date: 2015-10-07 10:13:04
Very nice references to how consensus works in IETF.
@_date: 2015-10-14 17:00:33


You realise disabling voting (which apparently reddit doesnt support anyway) just means people cant play downvote games, irrespective of views.  I would think you'd like that as you've complained about censorship.  Cant say I am a fan of censorship either fwiw.
@_date: 2015-03-19 21:05:16
They werent called colored coins for sure but Steve Schear posed a question about whether you could watermark a different meaning onto a Chaum coin issued by digicash and I came up with a way to do it, this was probably around 1995ish.  Color coins are a similar concept - to watermark extra meaning on bitcoin that bitcoin itself is not aware of.
@_date: 2015-10-16 00:42:48


In principle it could, in practice I am telling you it is not a factor.  I think I am self-aware enough to know if I were influenced by a conflict and have a 20 year track record of speaking honestly online.  Ask around or people who worked with me before eg from ZKS etc.


I just explained why largely it makes no difference to Blockstream.  Sidechains and Lightning have advantages that are quite attractive even if an infinite sized block were somehow magically possible to do without affecting decentralisation security.  In fact Blockstream is significantly Bitcoin aligned naturally and by intent.
Also the same arguments about decentralisation were made publicly by Greg &amp; Pieter before blockstream existed or was planned, and you can find the comments on bitcointalk, IRC, bitcoin-dev etc.  If their views and actions are unchanged how can they be influenced by bias?


Because if one were to believe your imputed assertions, I would be thinking $$$ and maliciously doing something bad for Bitcoin, which I am not?


If everyone with a potential conflict recused themselves there'd be no one left!!!  Gavin has an advisory position and maybe pay or stock or options from coinbase, which has it's own financial objectives, probably other companies too, Mike is reportedly working for Andresen Horowitz VC firm which invested in a specific set of Bitcoin firms with objectives, and advisor to Circle, maybe others; Jeff consults for various companies and probably still owns BitPay stock or options, Peter Todd consults for various people.  Morcos &amp; Suhas have a company.  That leaves what Wladimir &amp; Cory?  Or are they conflicted - they work for MIT and the funds MIT are using came from somewhere, do they have implied are explicit strings?  (I am not asking that question, just showing if one wanted to spin up a conspiracy there one could be also).
I dont think that is a reasonable demand.  Our only option to protect Bitcoin security from people with incorrect assumptions would be to resign and go explain the technical reasons.
You would probably say Satoshi has a conflict (owns lots of Bitcoin) other than having publicly left, would that mean you demand he recuse himself from improving Bitcoin also?
The way these things work, eg if you look at linux, is that people are expected and held to a high standard of acting in a meritocracy.  The rough consensus process of Bitcoin helps also, as a biased attempted action would have clear counter arguments.
We are to be sure seeing arguments of course.  That is why people are trying to work towards some kind of compromise solution and the workshops that you participated in etc.  But it is false to say those arguments arise because of conflict, on Blockstreams or my part, they are because of a concern for decentralisation security weakening towards failure.  
I am not sure if that freedom from attempt to act on conflict is true for Gavin or Mike or the companies that signed the BIP101 letter.  You notice BIP101 subsidises fees, Gavin said this publicly and explicitly as a kind of subsidy trading off security to in his mind gain users, and to get cheap scale fast.  Notice also the companies signing the letter pay fees and are trying to increase volume a subsidy of both at the expense of security might be in their financial interests.  Increase Bitcoin usage and adoption is not a bad thing, but the attempt to act on conflict is probably there.  They also view their business outcome as good for Bitcoin, so that is what it is.  So I explain this just to balance these things out a bit with you slinging around the word conflict loosely.
ps Thanks for being gracious enough to comment on the presentation.
@_date: 2015-10-13 16:09:36
The potential future advantage of (native) issued asset support is that smart-contacts can be made using both BTC and USD.  Eg chain enforced limit orders where there is no exchange hot wallet risk, the traders can retain custody and not the exchange.
@_date: 2015-10-14 12:36:29
Yeah I am not sure.  Disable voting?
@_date: 2017-05-14 12:08:11
this is an idea that is repeated daily.  it doesnt work, it leads to more delays.  here's why: 
@_date: 2015-10-14 16:28:22


Honestly, its puzzling to me what you think I've personally done wrong.  We started a company (Greg, Pieter, and the other founders) so we could fund work on making Bitcoin more awesome.  We did things that people like before and after obtaining funding for the company.  We optimised and implemented Confidential Transactions which most Bitcoin community people seem to like.  We used some company funds to hire Rusty Russell to work on lightning, which I believe everyone thinks is a good idea too.
What gives?
@_date: 2015-10-13 18:56:31
The sponsors of the workshop reduced the cost of attending, and the workshop also offered bursaries to a number of technical people to attend who otherwise may not have due to cost and lacking their own commercial sponsor (like a bitcoin related company employer)  Most employees of commercial entities would be expected to pay their own way.
@_date: 2015-10-14 07:59:30


Well technically: extension-blocks allow soft-fork introduction of additional different sized blocks.  
@_date: 2015-10-08 17:23:24
Well sidechain elements alpha is all opensource and in github, and a testnet instance you can play with has been running since June 2015.  
It's quite possible they setup another sidechain using that software stack to try it out.
Some, but not all of the financial institution labs trying blockchain tech, have understood that blockchains with confidential transactions act like a kind of virtual private chain.  Yes your traffic goes over the internet, but there is nevertheless transaction confidentiality, analogous to a VPN.  I expect VPNs were a tricky proposition vs leased lines originally too.
Secondly most of these bank blockchain projects are at early phases so not all of them have thought ahead far enough to consider the interoperability.  The finance world is very interconnected.  Institutions are buying and selling and building financial products out of other institutions products in a very interconnected web.  The main value of blockchains is in reducing trust in third parties.  If there is no interoperability and the trust between institutions is a legal contract, most of the value has been lost.
The way I look at it banks can if they prefer start with a private chain and add mining and make it public later when they need to interoperate.
Bitcoin timestamping and/or mining is useful because it hardens security of a chain, and is an objective transferable security assurance in an automatable way without relying on human configuration, audit and value judgements.  The lack of those things is the status quo.
@_date: 2015-03-28 20:47:13
Somewhat, except that its voluntary and opt-in so it doesnt damage existing 0-conf.  I was trying to find a way to let both co-exist.  Introducing a new feature while simultaneously breaking an old one is not good.  Well RBF is partly just breaking an existing scheme and offering not much in return to make a point.  In the online version also double-spend multiples higher than 2x can make the user pays 2x price lose still.  My proposed variant doesnt involve paying a multiple of the price either which is kind of ugly as you note.
The other point was I proposed to broadcast double-spends at priority.  A related idea is to broadcast shares so the merchant gets a faster non-binding indication of what the network is mining on, and that they are not partitioned from the network.
@_date: 2017-05-02 10:06:38
if you calculate the cost of a block at 5c/kWh it's not looking bad right now!  ofc the 1.1MW power hookup could be a problem for residential :)  if only they made a mini-fridge version with 6kW draw!
@_date: 2016-05-26 19:53:12
There you go, looping!  It's turing complete!
@_date: 2015-10-08 01:13:54
Right but one that was analysed point by point by and others.
Hard-forks are in principle better than soft-forks because they give people a possibility to vote.  However they are riskier, and more costly because of the need for a full upgrade.
btw BIP 101 is itself a soft-fork not a hard-fork (for SPV clients).
Soft-fork is the fastest and safest way to upgrade BIP 65.  This argument has been had, it's a tradeoff, lets please move on and agree to disagree and deploy it so we can see what lightning scales to on top of it.  I think as an early innovator in Lightnings precursor of payment channels you would think this a good thing, and focus rather on helping lightning project and the features needed to enable the more efficient variant of lightning.
@_date: 2016-05-16 20:56:37
The sender is not visible to anyone other than the recipient, until some time after the transaction is mined.
@_date: 2017-07-15 23:38:39
Miners tend to follow profit which relates to difficulty to price ratio
@_date: 2015-10-13 08:12:59


On the plus side spondoolies does have a track record of shipping equipment on schedule.  Presumably they would tell you when shipping is if you sent a query about ordering as that's all important.


Nice efficiency.
About 16kW note it is in 10x 1.6kW blades.  You can populate less than 10 blades, and you can power the blades from different circuits.  Say you have two 240V circuits, with 35 amp fusing, that might do it.
I believe in the UK master fuse is 100amp (24kW) at least in some situations.  You'd have to be careful what you turned on in the rest of your house, or rig something to down clock the miner before turning on high power draw equipment (cooker, washing machine).
@_date: 2015-10-07 14:43:35
You may notice several people have said there is consensus to do BIP 65 (via soft-fork obviously).
As to why the discussion has suddenly attracted people who were not participating during the extended period of time BIP 65 has been worked on you probably want to watch the video linked and draw your own conclusions.  The discussion is not about the merits of BIP 65 and therefore I believe to most peoples minds doesnt affect consensus.
@_date: 2016-05-14 13:23:35
The recipients public key only has to be revealed to the sender.  When coins are spent their public key is revealed anyway (necessarily to verify the signature).
One could also use a hash lock as used in atomic swaps.  With that you have to reveal a hash preimage to spend - part of the script is y =? H(x) so to spend you have to reveal x, and the script checks H(x) == y.  With that model you could encrypt the transaction with x as the key.
Maybe encrypted transactions could be implemented using MAST (merkelized abstract syntax tress) with a few changes.  (Eg something like a feature to commit to the input and output transaction IDs into the scriptSig rather than the script might do it.)  @_date: 2017-07-17 20:54:44
I did suggest it to Bram a while back :)
@_date: 2015-10-24 23:38:16
See BIP102 by :)
@_date: 2015-11-04 23:18:48
It is the implementation of the BIP.  You replace that function in bitcoind with the code in the BIP compile and it's done.  It is not pseudocode, it is working, compilable C++ code.


@_date: 2015-11-05 10:33:04


No one is hitting pause, between trying to reason with people on reddit I may get some cycles to work on the BIP.


Why do you think we have not seen this behaviour?  There has been for years a policy limit that is below the hard cap.  Did you go test the blocks and correlate with traffic shape deduced per miner policy?  It could be done and it would be informative.  Pieter Wuille suspects this may have been happening to fair extent.
You also have to consider that there is elasticity of demand for on-chain, it moves off-chain as a result of business decisions of arcitecture to use.  Probably 90% or more of bitcoin transactions are off-chain on a daily basis right now so that principle should not be a surprise.
Clearly that is bad and for risk we would like all transactions on chain.  However the best way to do that is to work on Lightning.  We can smooth things a bit with some pragmatic choices like 2-4-8 but dont kid yourself that if some of the off-chain transactions move on chain that they could not insta-fill 8MB or 32MB etc.  As adoption grows same for 1GB, 8GB etc.  We have to plan for success here, not fixate on a parameter.  Success involves improved protocols, a write-caching module for bitcoin (lightning) and willingness to use code.
@_date: 2015-11-13 13:33:48
Nick Szabo on a recent panel on this topic:


Nick Szabo was answering the "What are Bitcoin's most important differentating properties to you?"  question directly put by trace on a panel  video of panel segment 
@_date: 2015-10-13 15:40:56
No, we were not tracking bitshares afaik, coincidence.
@_date: 2017-07-14 08:53:23
the side-effects have to be articulated or it sounds like a free lunch. not everyone is tracking the technical limits. it could have been made more neutral but hard to do so in the short space you have in a twitter poll.
@_date: 2017-07-02 17:30:36
The slow deposit would be on pegin. Exchanges may hide that by having cold liquid federation cosigned coins ready to swap for user deposits to give users a 6 confirmation experience.
The circumstances where conservative (72 for 12 hrs) number of pegin confirmations are  practically of value are rare events that happen once in a few years, like the bip66 fork which involved human intervention and saw 10deep? reorg due to miner SPY mining.
@_date: 2015-11-05 16:22:53


I dont think typically normal people down-vote good-faith technical discussion - they try to disprove or argue the counter-balancing factors.  I like to think that is mostly what I do, though of course like the next guy I occasionally retaliate to snarky comments.  Certainly if I post something more snarky I deserve any down-voting earned.


I think you are mistaken because I believe there is simple evidence for everything I said.  You could for example try to challenge one of the claims and disprove it.  You did not, you decided to prejudge it without evidence and contribute to censoring it.  You may like to think about why.
Certainly I admitted and said that some of the down-votes are not bots but people that disagree with a technical argument for various reasons.  I would encourage them to disprove the things they disagree with, if they are unable to their view may change and they may learn something.  Or if they disprove what I am saying we may both learn something.  That's progress!
@_date: 2015-11-19 18:03:06
rootstock.io Bitcoin with ethereum script
@_date: 2017-07-18 06:02:09
Iron sky was great, but you might like iron sky 2 better  touches on some of your "research" :)
@_date: 2015-10-29 20:38:52
I have heard from multiple people that the uncertainty was bad.  From traders, from investors, from businesses, from financial institutions.  The point that the uncertainty is unwelcome was made before, one could dig up the posts.
@_date: 2015-10-13 19:07:43
You should probably read  the improve Ethereum script was my impression after a quick read of a few things, I think it is claimed somewhere.  Yes here, though it is not explained in huge detail yet:


@_date: 2017-07-14 10:52:16
The honey badger hasn't even close to warmed up yet. Bring it on. It's like V for vendetta Bitcoin is an idea and a state of mind, it can not be killed. Once people have tasted freedom there is no going back.
@_date: 2015-11-04 19:37:38
No it is designed so that a hostile change that would be against the interests of the users would be hard to impose.  Imagine seizures and freezes by a central party, redlists, reversible transactions, inflation beyond 21m.
@_date: 2016-05-14 00:10:21
Hypothetically one could consider making unencrypted transactions non-standard or invalid potentially.
@_date: 2017-07-14 13:46:41
no not nonsense. the empirical evidence to date, is that is exactly what has happened over the last years.  think about it: it's like mails servers, more non tech users, more AOL users, less mail servers per user.
@_date: 2017-07-02 05:11:47
Hopefully we'll see p2p sidechains/drivechains too soon.  But it is interesting to reflect that the decentralisation of bitcoin pools today is itself maybe weaker than liquid decentralisation at 10 of 15.
@_date: 2015-10-20 13:12:37
Tell you what, you make a post to a mail-archive hosted list of your choice, showing headers matching the maybe Satoshi post in question and you'll have a point.  (Proof of possibility it was spoofed).
@_date: 2015-10-20 10:02:56
You realise it was actually from an address Satoshi used.  The only way it is spoofed as far as people could tell would be if the email account was hacked.  One of Satoshi's other accounts was known to be hacked.  This one was not known to be.  Therefore there is uncertainty - it could be real or may not be.
The text wasnt implausible either.
@_date: 2017-05-26 06:09:27
I know, but for blockchain we tend to say on the blockchain, not in the blockchain so I took some poetic license :)
nice touch translating back to black speech.
@_date: 2015-10-22 14:52:25
I dont think most wallets would try to spend the outputs (coins) stuck to the same address in preference to ones with one-use addresses.  So in practice that may not work so well.
@_date: 2015-10-13 10:54:10
Not sure about ethereum's days but things got more interesting anyway: smart-contracts code-forked and improved from ethereum, but on Bitcoin, and with a solid sounding dev team too.
@_date: 2017-05-08 05:59:30
note according to u/luke-jr stats the node count is actually much higher  closer to 50k. the other sites are showing listening nodes only.
By your suggested metric that would be more like $500/year or $44/mo.  that's closer to the $20/mo than the $200/mo.
in a sense it seems like it's non-rich people who could most use financial protection, and people with the most difficulty obtaining trustworthy banking and bitcoin services, ie emerging and 3rd world markets.  that may skew towards the $20 vs the $200.  I think i might think twice at $200/mo or focus on finding a way to lower the cost.  I wouldnt think twice at $20-40.
@_date: 2017-07-13 22:31:07
no. it's about KYC and AML with law enforcement, some exchanges and payment processors pre-emptively hand over all user and transaction information.  
@_date: 2017-07-14 14:49:38
throw insults as you may, and u/luke-jr is decisive and not always on things people agree with, but he's probably in the top 10 bitcoin internals experts on the planet.  you want that expertise for peer review because he might spot something peter todd misses or vice versa.
@_date: 2015-11-05 16:27:25
specifically 
flexcap propoal by Greg Maxwell see post by Mark Freidenbach
growth limited proposal for flexcap by Greg Maxwell
More improvements have been thought up since.
@_date: 2017-07-13 19:23:45
there are still buyers of BCU? seems like free money.
@_date: 2015-10-29 22:43:26
I think it was more the signal/noise level degraded at times with influx of new people wanting to discuss off-charter topics (non-development related discussion) which was causing people who were doing development to unsubscribe.  There is a companion list: bitcoin-discuss on linux-foundation (same list server) for wider topics.  View it as more enforcement of charter and basic etiquette.  The bitcoin-discuss list is unmoderated AFAIK.
Not a huge fan of moderation myself as a principle, but you have to admit the noise level was kind of getting out of hand, and personally I subscribed to bitcoin-discuss list too, so I wont miss any discussion as I think off-topic discussions and posts are moved there (automatically even?)
@_date: 2015-11-05 10:02:34
Fees are subject to supply and demand.  You cant expect that 100x blocksize results in 100x fees.  Gavin argued for a keynsian subsidy of fees for the wallet companies he advises at the expense of miners.  Ie He said he expects fees per transaction to fall by increasing blocksize and he likes that outcome.  Obviously free transactions at unlimited scale are a nice objective.  However we should not miss the fact that there are two losses of security: large blocks tends towards less decentralisation security, and lower fees erodes the potential for security to be paid for by fees.  Security is not free.
@_date: 2017-07-13 19:22:10
Yep, the privacy of liberty is eternal vigilance. Or the honey-badger is made of users just like us. Anti-fragility is not automated - it's people who care about bitcoin's ethos defending it with code.
@_date: 2016-05-14 00:14:47
There is a longer post exploring variants of this scheme here  from may 2013.  If you're interested in crypto it explains how miners can verify that the transactions have not been double-spent even though they cant decrypt the transactions (yet).
@_date: 2015-10-13 10:17:55


Not coincidentally the sidechain supports Issued Assets.  Those could be used to issue IOUs for USD or EUR etc.
@_date: 2017-07-02 05:16:11
It's just different - liquid is an exchange settlement mechanism.  Exchanges expect 6 confirmations on the main-chain because exchange transfers are often high value. liquid can get 2/3 confirmation with finality 1/100th that time or better.  
It's a better alternative to giving your bitcoin to custody of an exchange.  It has extra features like Confidential Transactions.  But it's not intended as an alternative to main chain bitcoin.
@_date: 2015-11-19 18:02:35
People are putting a lot of effort into scaling bitcoin.  What will scale it is improved protocols and running code.  Rough consensus and running code, to use the IETF description.
Watch and participate in person or online on IRC in the scaling bitcoin hong kong 6-7th dec.
@_date: 2015-11-23 03:31:06


Well with CLTV it gets more complicated than that.  The lock can be indefinite, there is no need to periodically refresh the channel it can stay up indefinitely so long as there is some use to that (eg if recirculation is working out).  When you want to close the channel you publish a transaction which starts the relative timelock, then there is a time-window to reclaim.  Relative lock-time is interesting because it reduces the amount of reload transactions and also enables shorter time-locks because they dont imply regular tear down and re-establishment of the channel.
@_date: 2015-11-22 04:53:49
Well it's less censorship if there's an uncensored sister-list right beside it that you are invited to continue the conversation on right?
@_date: 2015-02-22 18:01:18
They have the same property, and Lamport Sigs have the advantage you mentioned of remaining secure if quantum computers pan out; but I was referring to one-show signatures which work with DSA or Schnorr 
the mechanism is surprisingly simple.
You can alternatively get the same effect by defining that the miners can take the funds if they can collect two signatures.  The proposal was to use that though one-show signatures were mentioned also, and could be another alternative.
@_date: 2016-05-14 00:05:54


The miner cant but the recipient can, so the recipient can confirm as fast as normal.  You can even respend encrypted transactions before waiting for second stage confirmation by sending the keys to the next person.
When the key is later revealed to the network the miner can then do the second stage verification.
@_date: 2019-05-09 00:37:26
for the peg escrow yes. they are from the larger / more technically capable, geo-distributed, not too many in one country from the set of network participants.
mid-term we aim to add more dynamic federation support, and there it becomes "all of them" so then there's less value to not naming the individual boxes by operator.
I expect you know, but the timelock 2 of 3 multisig clause does not become active unless the network stops progressing so while the network is progressing, which is within the capabilities of the 15 functionaries, the 2 of 3 has no operational capability and is also very offline.
@_date: 2017-07-10 23:24:12
What's my advantage? I too don't want to lose bitcoin investments or see confidence loss from disorganised hard-forks, currency split etc. For HODLers stability is more important that malleability fixes, and they'd sooner status quo than segwit + rushed HF risk. 
We do need more scale for adoption, and malleability fixes for layer2 scale and other smart-contracting use cases, but in a consensus driven technically sound, planned way.
@_date: 2015-11-10 00:06:06
Possibly we should develop a plan B in preparation for such an eventuality which we hope not to have to use, but so that it is realistic to switch, else it risks being an idle threat.
@_date: 2015-10-13 16:06:29
Most users are buying and selling bitcoin on exchanges, this improves the security, auditability (run a full node on the sidechain to check it's valid), proof of reserves (keep funds in liquid, and run a full node), multiparty threshold enforcement of non-fractionality of liquid balances, reduces scope for front-running (because of confidential transactions), improves public privacy of inter-exchange transfers (because of confidential transactions), and maybe brings some dark-pool transactions back from private trades.
Traders and exchanges seem happy with the opportunity to improve liquidity, reduce flash crashes, and arbitrageurs and market-makers with the ability to get better use of capital and faster trades.
Some of these things are just affecting price adversely at present due to liquidity crunches when insufficient capital is online to satisfy demand.
Some exchanges may offer this feature (maybe for a fee) to users who want to do fast trades.
@_date: 2015-03-19 21:22:16
No they cite this paper "Traceable Ring Signatures"  by Fujisaki and Suzuki for the ring signature.  the proposal I made has the added benefit that the amount is encrypted so unlike bytecoin/monero/cryptonote the value is not visible, they propose to standardise the amount.  That means you have to make multiple payments so it creates more transactions.  Its also a different concept: the ring coin proposal is not traceable as the way you get ambiguity is by subtracting 0 value from other peoples coins, and the spent value from your own coin; you wont be able to do it twice because the transaction happens in plain sight, so the block chain will enforce (in zero-knowledge) that you cant inflate value.  With the traceable ring signature you are actually spending one coin from a set of equal valued coins, where its ambiguous which coin you're spending, so its important that you only be able to do it once.  
@_date: 2017-07-02 05:08:46
liquid is for exchange settlement, so it's an improvement to giving custody of your funds to a single exchange - the peg is a &gt;= 2/3 threshold across a set of exchanges.  the liquid sidechain also has different features that may be interesting to exchange users, like confidential transactions.
@_date: 2015-10-16 15:38:47




Well it's relevant, and you can do some basic research on the views and track record of people.  But for sure you're right that it would be better if development were more decentralised, and I wrote quite a bit in the thread about what we have done and propose to do about that to mitigate as best we can.  Short of people resigning from Blockstream or stop working on Bitcoin not sure what else can be done beyond what I already described as defences against conflict.
btw I am not sure if you noticed but several people at Blockstream in fact stopped contributing to core or participating much because the attacks were too emotionally draining.  I am not sure that anyone should feel proud of that, as they were major contributors to core and made huge differences to bringing Bitcoin to where it is today.
I guess it shows by example a side-effect of what you're asking for: slower core development, making Bitcoin less awesome than it could have been if some people were capable to hold a technical discussion without getting unprofessional (present company excluded).


True.  However XT manifesto proposes to have Mike be the benevolent dictator so that's worse by my or your definition, for development process decentralisation.


You know that is the first time I heard that view, it is not the justification Gavin or Mike give for XT.  I dont think most of the technical people feel that way, because they know and respect other developers, and trust them to act in an unbiased way and understand that everyone has some form of potential conflict basically.


It is not healthy, it is dangerous for security against network fork for two reasons I gave on this forum: a) accidentally slightly divergent implementations of the same consensus algorithm (lower risk to use libconsensus); b) intentional different consensus algorithms duking it out on the network increases risk of network fork.




I do not think this is true.  Most companies are interested to see the best outcome for Bitcoin and understand the value of constructive development review process.  Hence the large participation level in scaling bitcoin workshops.


I am happy for competitors, Bitcoin is a collaborative space in tech &amp; business - the bigger competition and pie is financial services.  However the blockchain consensus mechanism does not work with multiple competing consensus algorithms on the same network.
I think the individuals and companies largely just want what's good for Bitcoin.




It did not fail, the topic is ongoing.  Scaling Bitcoin in Montreal was viewed as positive and as helping progress and collaboration by the vast majority.




This is why we with investor approval put the legal protections I mentioned in place in incorporating Blockstream.  


I am generally anti-censorship.  It's not clear what to do about the disruptive gaming of voting, rating and trolling.  Open problem.  In principle one should just ignore it or write more text.
@_date: 2015-10-13 10:42:05
I read his comment to be code for whichever the selected approach is. 
I do not think it should be interpreted as support for 101 because that already has code, so saying we need code refers to the other proposals such as flexcap and the utxo accounting bip102 like proposal etc.
@_date: 2016-05-14 00:39:25
See  technical discussion and evolution (a bit long and multiple variants discussed).
Shorter / clearer version:
The sender stores the keys.  And they are also required to be provably time-lock encrypted in the transaction.
A key reveal deadline is chosen as a design parameter.  It could be 6 blocks or 144 blocks or...  (This wont interfere with respending because people who receive these coins can verify and respend them.  You dont want it to be spent too many times before reveal because the amount of data to download and check will grow with each respend).
The sender is supposed to reveal the key.  But in the event they do not anyone can decrypt it anyway using the time-lock decryption.  This is a form of encryption a bit like proof-of-work in that it intentionally takes a certain amount of work to decrypt, except it is chosen to be non-parallelisable so you have to do it on one core of one CPU.  Say it takes 1/2 of the deadline period on normal CPUs.
This is to prevent someone form stalling the network by not disclosing their key.
After the deadline miners are required to confirm the transaction-ids and keys of any valid pending undecrypted transactions.  Transactions being invalid are allowed to be excluded.  This mostly compacts the amount of information nodes have to fetch to validate encrypted transactions.
Encrypted transactions are protected from double-spending by other encrypted transactions or normal transactions.
A simpler variant could be that key disclosure is voluntary compaction by miners and not time-lock encrypted, nothing breaks and as the transactions are respent more and more people learn the keys so eventually someone will broadcast them for mining.  This allows arbitrary delay of information reveal though the amount of privacy depends on how close a community of people spending only amongst themselves as you learn all history when you receive a transactions.
@_date: 2017-05-10 09:22:19
thanks, edited.
@_date: 2017-07-21 00:19:54
thanks for writing some thoughtful comments down.
why not scale with layer2, more compact transactions (schnorr, mast), drive-chains and planned/consensus fork like spoonnet later.
there are limits to the decentralisation security vs scale tradeoff that are fundamental but you can go further with similar security by approaching things scientifically.
seems better use of resources to keep the same currency and build more software for scaling mechanisms - planning forks and multiple coins is a mess in itself that no one much wants to do.
i guess as Lombrozo said, the framing is wrong. it's not about scale vs not scale, it's about scale intelligently without breaking security.  and about scale via consensus, not via closed meetings, that is an anathema to Bitcoin.
@_date: 2017-07-13 19:38:05
that reminds me, I believe Jeff's company is also a member of blockchain alliance.
@_date: 2015-10-13 23:16:26
You can (technically) soft-fork a lot of stuff, the question is how complex would it get.  would know better.
@_date: 2016-05-16 04:02:04
And hashrate still going up at a fair rate.  Seems miners are confident about post-halving price.  
@_date: 2015-10-14 08:08:54
FWIW claim is completely untrue.  We could equally ask which bot service he paid to get +57 on his troll post.
@_date: 2015-10-13 18:25:46
two comments giving a more nuanced explanation of the tradeoffs.  TL;DR some scale, but bigger scale expected from lightning later.
@_date: 2016-05-01 11:23:03
Poon &amp; Dryja's papers, reddit posts and presentations? Probably google can find that for you.
@_date: 2015-11-07 19:43:58
The first one was more of a level set on requirements, tradeoffs.  This one BIPs, results and research on scaling including block-size and other things *is* the topic.
@_date: 2019-05-17 22:28:58
@_date: 2015-11-22 04:41:17
@_date: 2015-11-04 20:02:39
There is more to it than that, also argues that it is not a problem for full nodes to be relegated to the data center.
take a look at the code in BIP 103.  It is what 10lines of code?  2-4-8 is just parameter changes off that.  The code is NOT the bottleneck, despite some people's trumpeting of that like it's an achievement.  The work is in arriving at a compromise that everyone will agree on and upgrade to together.
@_date: 2015-11-10 01:54:37
Maybe you could do something defensive, and temporary until the hash rate gets high enough.  There have been precedents of sorts in alts that introduced novice bugs - they started centrally signed check pointing where a block is not valid if not signed by the authors central server (!!).  Probably a much more decentralised multisig checkpointing could be devised by a bunch of infrastructure and devs.  Certainly undesirable but we'd be talking disaster recovery and phase in of new PoW, for a time-limited probably one off-event.
@_date: 2017-05-07 23:20:50
you wouldnt have to keep your node online 24x7 unless you were configuring your hybrid spv wallet to connect to it.
eg power up your fullnode wallet, and wait for it to sync, when you want to send or receive larger bitcoin amounts.
@_date: 2017-07-14 08:51:14
yes the narrative has been 100% inverted the whole time, every person who works at blockstream commenting has been warning about this very issue.
@_date: 2017-07-10 22:10:50
losing track was that an argument in favour of 148 or NYA?
@_date: 2017-05-14 20:31:27
it took 12months from segwit inception to release code with coding, testing, wallet/service/miner integration.
we're at about 17months now with activation at 35% signal level or whatever, and some more integrations that at 12months.
if you want to reset and start most of that work over, you need a reason.  no logical reason has been provided.
and that's for a soft-fork, no planned hard-fork has been done before, and hard-forks take longer to activate, because you need vast majority of wallets and ecosystem to be upgraded, and also hard-forks are more complicated because wipe-out, replay, maybe difficulty adjustment need to be considered.
@_date: 2017-07-13 19:19:14
@_date: 2017-05-25 04:12:05
There's a misunderstanding here, I want to clarify: I was invited, but because of a question of independence of developers at blockstream, I felt it regretfully necessary to decline to attend the organised meeting.  The topic of Samson's participation was separate.  
The reason for not attending, is that protocol experts working on bitcoin protocols at blockstream have contractual independence, we feel it is important that bitcoin developers should be free to make proposals and review proposals, independently of their employer and with the interests of Bitcoin users first. We encourage other companies to adopt a similar principle.
I had proposed that Samson participate for blockstream and as someone with ecosystem experience from BTC China etc.  Unfortunately that didnt work out for reasons explained elsewhere, and *he* was excluded.
From the proposal, personally I hope people are able to take the positive energy on ecosystem collaboration, and intent for progress to activate segregated witness and proceed to the next scaling steps, and look forward to reviewing and commenting on the discussion.
@_date: 2017-07-14 12:33:32
but that's illogical, think about it: as the long tail of users join, they are less power-users, and so the ratio of fullnodes will naturally fall. and empirical evidence has shown this trend. "if we do more of the same it will reverse" nope.
@_date: 2017-07-14 08:51:28
clever :)
@_date: 2015-11-21 23:31:09
Yes.  And a good number of developers also are going.
@_date: 2015-10-13 11:48:48


You already trust the exchange you use for fiat IOUs.  Using block-chain tradeable Issue Assets instead reduces online hacking risk.
If there are multiple issuers and you end up with IOUs from an issuer you dont trust you would sell the IOUs for an issuer you do trust (more) via arbitrage.  In fact you could combine it in a atomic transaction:
1. you are a user of exchange A and somewhat trust its USD IOUs.
2. you sell some BTC on exchange B and receive exchange B USD IOUs.
3. you sell the exchange B USD IOUs for exchange A IOUs.
You could even combine the two transactions into one atomic transaction so you never have exposure to exchange B, even though you are picking up a price it offered (modulo the risk premium for exchange B IOUs).
@_date: 2015-10-02 07:57:25
Security is about the ratio of economically dependent full nodes, even assuming more users from larger blocks, it is most likely that the ratio will fall if the costs of running a full node are higher.
Consumer bandwidth is asymmetric, and people use their bandwidth for other things too - gaming, voip, youtube, email etc.  If running a full node degrades their internet they will turn it off.
See also the bitfury paper, they claim 90% of full nodes will drop off the network at 8MB. 
@_date: 2015-11-22 17:44:08
I am not sure.  Surely, surely they would answer you.  Did you send them a link to the above?  Or send them the same information?
It's an independent review panel from academia, industry and individual contributors.  As one of among 40 sponsors blockstream, like the rest of the sponsors, has no veto over proposals.
I'm not sure what someone said to you, nor who said it.  Sometimes things are disorganised or uncoordinated without conspiracy?
People in core and in blockstream are hyper focussed on improving Bitcoin and read all contributions that they get to see with interest.  I dont think people in blockstream generally have seen your proposal unless it's public, and it sounds like you havent written it yet.
Have you posted the abstract you sent to the reviewers publicly?  Why not do so?
@_date: 2015-11-07 19:42:22
He is exchanging emails about BIPs though.  There would be discussion, work and testing before, during and after the workshop.
@_date: 2015-11-01 10:54:37
You can think of cross-chain atomic swaps (and in chain atomic swaps) which can be chained together as like the original ripple (before ripple.com bought the brand and re-designed it to be more hierarchical and introduce XRPs).  The point of the atomic swaps is you can convert from BTC to CHF via USD without exposure to the issuer of USD if you thought the USD iou issuer was questionable: you swap BTC for USD atomically with USD for CHF (presuming you trust the CHF issuer).  That lets you trade via things you dont trust as long as other people are buying them with zero exposure.
@_date: 2019-05-08 20:02:47
bitcoinmagazine article on new integrations and liquid members 
@_date: 2017-07-15 22:29:23
it appears not. i asked for days now.
@_date: 2017-07-10 22:31:31
Fair enough. I'm supposing the visit to bitcoin.org is a vote for safety and security first, FWIW. 
@_date: 2015-10-18 08:38:01
buy &amp; hodl.
@_date: 2019-05-08 22:54:29
might not work due to all the crypto of confidential transactions and blocks 10x faster, maybe you want one of the faster arm64 based rock64 raspberry pi power versions 
@_date: 2019-05-08 21:54:30
see screen shots here of the process 
@_date: 2017-07-19 21:13:20
No it can be fingerprinted anyway for other reasons. Besides pools have DDoS protected infra and hidden IPs because people have an incentive to DoS pools and block withhold etc.
@_date: 2019-05-09 01:03:12
there was an issue at some point, which should be a temporary condition. (opportunistic defrag by pegging out from older addresses was supplemented in a later upgrade by defrag process to move forward if not spent).
the 2of3 keys are very offline but it is best if the condition does not arise, and does not arise in a systematic way - which should be closer to the case now.
@_date: 2019-05-09 01:06:55
the pegouts go to cold wallets managed by the participants (exchanges etc) but some exchanges may pay you from their hotwallet and you could request the payment go to your lightning channel funding.
also it should be possible to have a lightning channel route that covers LBTC and BTC eg a lightning BTC channel between A and B, and a lightning LBTC channel between B and C so that A pays C in LBTC and C receives BTC or vice versa. as lightning can in principle cover multiple assets, LBTC and BTC are simpler than some because the price is 1:1
@_date: 2017-07-11 08:27:47
i dont think you understand how IETF consensus process works.
@_date: 2017-05-14 23:49:36


there has never been a planned hard-fork in bitcoin.


the point is that requires software development, testing and integration.  likely &gt; 12months of it given the 17months todate on seg-wit.


why waste time delaying seg-wit activation
@_date: 2017-07-14 23:43:52
I would say this article is pretty accurate.
@_date: 2017-07-15 22:26:00
a hard-fork is opt-in and not really to do with miners. bear that in mind.
@_date: 2017-07-21 18:36:12


some people view the market as an AI design tool, even a few people I have quite a bit of respect for in their fields.  however it is not.
we have one Bitcoin not multiple.  if we encourage people who don't robustly understand security, protocols, safety margins - to promote design or code variants that break the main network, bitcoin loses confidence and network effect.  we only have one shot at this, bitcoin maintained the mindshare and network effect for actual payments, integration and use by retaining a secure, robust up-time, stable base.  there is more that could be done to improve scale via best practices, and on the network, but we should do that intelligently.
as someone who has broken several commercial deployed crypto protocols with &gt;&gt; 100million users, I feel I can say from my perspective that Bitcoin should retain a robust secure base, and use modularity to accelerate the medium security, move faster and break things, betas of those etc.  modular is not the same as layers.  most large scale network or extensible/programmable systems employ modularity and layers.  modular in bitcoin means sidechains/drivechains/extension-areas.  layering means lightning, tumbleBit, payment channels and other architecture composition.
scaling and modularity has never been progressing at a faster pace.  it would help greatly if people would communicate and collaborate more and better and listen carefully to each other.  the false claims that conflicts of interest are being acted on by some companies or individuals are indeed false, and should be calmed down, it is allowing some normally constructive people to cloud their own thinking.  let's focus on the prize, work together and improve bitcoin, in a respectful, constructive way where we work by open consensus.  we need a grand challenge on Bitcoin, that involves working together and using each individual and ecosystem players strengths, experiences and expertise.  the competition is outside the ecosystem, inside we have FOSS shared incentive to make the system more awesome, and friendly coopetition between startups.
@_date: 2015-10-08 14:22:57


Right, that was my complaint: why create a new term for an existing known concept with a well established name: those are Bitcoin (or in more detail pegged Bitcoin).


No it doesnt.  That makes as much sense as saying bitcoin fees for (main-chain) smart-contracts fluctuate - sure they do, but there's a fee market, fee estimation and client updates, user config, service provider config etc.  


I dont see how that helps nor makes any difference.  If anything it disincentiveizes users.
@_date: 2015-11-07 19:37:59
Actually Mike and I hung out and chatted in starbucks in Zurich for around 4hrs a few months back.  He's a polite and amiable guy in RL I find.
People are generally able to disagree about technical tradeoffs without being angry - it's all a big tradeoff - a fiendishly complicated one mind.  I think honestly the difference is in assumptions - if we started with the same assumptions we'd have close to the same conclusions.
I believe (and I think they are on record saying in the bitcoin.kn podcast  and elsewhere) that they think discounted/free fees, excess volume is more important to jump start adoption, than user ethos things like fungibility, policy neutrality, censor-resistance, privacy that arise from decentralisation buffer.  And more optimistic about a number of things: that anyone would attack via policy, or miner attack, that more bandwidth would have much difference on centralisation, that in their view it's not a problem if most nodes run in high end data centers over time etc.  I think that's a fair Mike/Gavin assumption braindump.  I think many other people think fungibility is super important so they want to scale, obviously, but are reserving more buffer due to the weak state of decentralisation.  Thats it.
If companies and power users want to help, they could improve decentralisation by running economically dependent full nodes, buying a bit of mining equipment and solo mining it and educated power users to do likewise.  (I have a few SP10s nice machines).  If decentralisation was in A1 shape, this would all be a no-brainer.  See this post by for a description of current centralisation issues: 
@_date: 2019-05-30 03:44:01
could be nice to see more donations to the fund also or some funding for such initiatives. 10btc = $80k not bad, but then hiring developers costs money also.
@_date: 2017-07-10 20:56:18
correct 2.2MB normal case 3.? adversarial case.
@_date: 2017-07-02 15:44:57
Its similar to the reason exchanges want 6 confirmations - they don't want users to trade and then see the deposit transaction be double spent - the exchange or another user could  lose money.  In exceptional circumstances eg the bip66 fork reorgs a bit deeper than 6 blocks were seen.  A much higher pegin number of confirms is therefore to have conservatively high assurance of finality even in exceptional network problem circumstances.
Pegout is immediate though, it's up to the recipient how many main chain confirms to wait.
@_date: 2017-05-08 15:58:19
There are a few people who prefer the tradeoff of miners and companies run powerful fullnodes on fast/expensive data-centre connections, and everyone else uses SPV.
I think that's a problem, and a bad idea, but just to say that's how they rationalise large blocks, and it is a rational argument - just one I disagree with.
But it can be helpful for them to admit their views, often it seems to me most people with this data-centric view do not want to admit it, because they know it is unpopular with users.
Some people with this view, also dont think decentralisation, nor censorship resistance is particularly important.
@_date: 2018-12-19 05:27:42
there's also this  kind of low res but being prepped for launch. these satellite guys don't seem very big on high res video / photos!
@_date: 2017-07-13 22:50:05
It can be that some may feel like it's a "trick question" to their perspective so they mis-vote?  (Like maybe they think bitcoin in data-centres is just fine as a tradeoff, and all users can be SPV, so then they protest vote?)  Or they're not much worried about censorship, seizure, sovereignty and just want cheap transactions - some people are utilitarian and maybe found a case that's convenient with no philosophical connection.
I'm not sure.  I would be curious also.
@_date: 2019-05-08 20:23:55
for now the LBTC model for green being integrated is as a separate chain (similar to how testnet is done currently).
@_date: 2019-05-08 22:56:00
the 3 letter ticker on Bitfinex deposit seems to be LBT, but it's not tradeable, you just convert it on-exchange to BTC to use. (that's just an exchange UI artefact.. effectively you can deposit BTC or LBTC and withdraw BTC or LBTC)
@_date: 2019-05-08 19:57:28
also you can use liquid-qt today. I just did a liquid-qt deposit of LBTC into bitfinex and had it be tradeable within 3mins. within bitfinex UI you click deposit, liquidBTC and copy the liquid deposit address to liquid-qt; after deposit you click on wallet (near top right) in bitfinex and convert LBTC to BTC (and which of exchange, margin you want it in).
@_date: 2018-12-21 04:30:27
@_date: 2019-05-09 09:51:27
Longer explanation of what I said above:
I am using defrag as an analogy for the change management in refreshing CSV expiry on coins. there is an on-the-fly defrag feature, which favors pegouts from old transactions.
this is similar to what  does for it's CSV for similar reasons too, but in liquid 11of15 rather than 2of2 in green (if outputs timeout in green you would eventually lose 2fa protection, it nags you to pay to self if you get close to the timeout by not transacting enough to make that automatic).
there were various limitations and usage pattern of the earliest version of liquid peg management code that resulted in things like the 2989 &gt; 2016 confirmation which has been since improved with additional mechanisms to push transactions CSV forward in addition to the on-the-fly / opportunistic transactions favoring old peg transactions first.
@_date: 2015-11-04 19:50:50


This claim is false.  I have made no suggestion in regards to block-size that is anything but with genuine motive for Bitcoin's best success and the interests of it's users.
It is curious to me that everyone attacks me, where everything is on it's head.  I am accused of being centralist (I have spent 20 years doing the opposite).  I am accused of acting in a conflict (I am very focussed on Bitcoin's success and defending the ethos of Bitcoin - I also defended the interests of PGP users going back some years against a key escrow plan from PGP Inc. I was successful in keeping the escrow out of the IETF standard).
And the people I am being contrasted with are the ones arguing for centralisation!  And are advisors to to some disclosed and a number of undisclosed companies, VCs etc with pay, options or what have you.  My affiliation is simple and disclosed.


Lightning is not a theoretical solution.  We are working on lightning which is a write-cacheing module for bitcoin that improves scale, reduces fees and gives instant secure 0-conf transactions (that Bitcoin can not do).
I never said anything about putting off block-size increase.  I think I am the person who is being most pragmatic and working on a compromise solution with Gavin &amp; Jeff and others, eg in the post snipped you are replying to:


(ie that proposal is to release nowish, the 4 years is the duration of automatic block size increase).
@_date: 2015-11-08 14:27:30
@_date: 2015-11-20 15:15:50
You know there are multiple other BIPs that have been implemented for months.  Eg BIP 102, BIP 103.  I think it makes more sense to use the best BIP not the first.  In fact as far as that goes BIP100 was before BIP101 (hence the lower BIP number).  Why pre-judge it, you havent even seen the new BIPs being presented at hong kong.
@_date: 2015-11-05 10:21:11
Somewhat stronger as there would be more users.
@_date: 2018-12-21 04:12:11
telstar18 satellite pre-launch prep photo
asia &amp; pacific coverage zones use bandwidth on this satellite
@_date: 2018-12-17 00:05:55
still misleading, because most of those coins did not exist in jan 2013
@_date: 2016-05-02 11:26:22
Well you wouldnt have to look far :) First para of hashcash paper:


proposed a CPU pricing function for the application of combatting junk email. Subsequently applications for cost functions
have been further discussed by Juels and Brainard in [3]. Jakobsson and Juels propose a dual purpose for
the work spent in a cost-function: to in addition perform an otherwise useful computation in [4].
@_date: 2015-10-08 01:24:57
I think everyone needs a well deserved rest from negative emotion.
Please lets focus on making bitcoin more awesome.
The need for scaling has been a bit overblown, and too many backroom discussions have happened.  I do not trust those because only one view was put to business people.  I would like these discussion to happen in the open, or to have a balanced presentation to business people.
I really dont want technical improvements to Bitcoin to be backroom discussions with companies lobbying.  Please can I ask that people do not do more of this or have the ethical fortitude to invite both sides of the discussion onto the call, or meeting to have a good faith attempt at balance.  Preferably have these conversations in public.
It is trivial to persuade someone to do something if they do not understand the tech if you say things like "do X and you will get free transactions for 10 years of massive scale" or contrarily "if you do Y bitcoin security will fail".  But please understand it is NOT ETHICAL to do that in isolation of having a balanced presentation of arguments.
@_date: 2019-05-08 22:57:09
coming to blockstream green aka greenaddress soon...
@_date: 2018-12-17 18:45:39
another article 
@_date: 2018-12-25 09:17:25
how does fixing malleability adversely affect "the core"?
@_date: 2018-12-17 22:59:42
link to other threads today on same topic, different articles 
@_date: 2018-12-17 19:55:51
coindesk article 
@_date: 2018-12-17 19:41:45
blog post 
original teaser trailer from Aug 2017 
aug 2017 announce blog 
@_date: 2018-12-26 03:30:53
you're looking at it upside down
@_date: 2018-12-17 22:21:19
bitcoin magazine article also now 
@_date: 2018-12-21 10:05:14
It's from about one year ago, HCPP2017 in Prague at Paralelni Polis. Looks like it was just uploaded to YouTube, anyway some of the discussion is about BCH vs B2X which has moved on since then: B2X cancelled and BCH split into BAB and BSV. 
@_date: 2018-12-17 23:31:48
bloomberg TV segment on Bitcoin Satellite with Caroline Hyde from aug 2017 
@_date: 2017-07-13 22:27:24
maybe there's a market for someone to offer centralised low fee bitcoin.  it's not hard to do.
@_date: 2017-06-09 08:51:17
if lightning and main chain are working together, obviously all else equal on-chain fees will fall, capacity will increase (a lot) and everyone will be happy.
you cant look at a dynamic system and assume fees are static when huge new capacity is added.
@_date: 2019-05-08 20:01:34
if you dont have bitfinex or therock account, sideshift has a test pilot (beta program)  while you get setup.
@_date: 2016-07-28 14:28:20
This is related 
@_date: 2018-12-17 21:24:45
video of a bitcoin satellite kit being built by some electronics &amp; bitcoin enthusiasts in Japan 
@_date: 2019-05-08 21:52:38
some screen grabs of the deposit process from liquid-qt to bitfinex, convert and block explorer 
@_date: 2017-06-02 01:06:07
he's not wrong.  people are enabled by Bitcoin to make the transactions they couldn't otherwise.
he had some current things to say about bitcoin development  at offset 74m
@_date: 2018-12-19 00:38:48
and telesat's image for telstar 18 
@_date: 2017-06-08 08:35:23
right in fact it's even there "still be really good if fees were much lower".
@_date: 2017-06-22 20:10:59
all employees at blockstream are part paid in bitcoin. except that the amount of bitcoin is locked in at start of employment. if BTCUSD price rises you get paid more.
@_date: 2018-12-18 07:40:31
Bear in mind many people have 2.5g tethered to mobile phone, but it's expensive for ongoing 10GByte/month, but cheap enough to send a few transactions.
Receiving Bitcoin data via satellite is also good for privacy, even if you have low cost, high speed internet because then your ISP doesnt know you are using Bitcoin.
There are also SMS gateways  and you could send over Tor etc.
For sending where there is no GSM nor internet coverage there are also bidirectional satellite services that are expensive per MB but reasonable per transaction given transactions are small, particularly if you can share those services across many users in an area via mesh networks etc.
@_date: 2017-07-15 23:52:24
the hypothetical is that segwit2x forks off in &gt; 3months time.  if they were to do that, hashrate falls a bit and life carries on.
@_date: 2018-12-21 04:55:58
telstar18 vantage (launched 10th Sept 2018) launch video including pre-luanch satellite footage 
@_date: 2018-12-17 21:23:45
there are a few projects trying to bridge satellite and mesh networks for bitcoin use cases.
@_date: 2019-05-09 01:21:55
see also sideshift's LBTC to BTC swap
@_date: 2016-07-28 14:53:00
The tweet you're replying to "Glad to welcome ** investor** 
@_date: 2017-06-04 22:13:30
moving exchange to cold wallet would be quite common also
@_date: 2018-12-18 21:27:05
it has 96kbits delivered data down from raw bandwidth of 312.5kbps using QPSK modulation. the delivered bandwidth drop is from a highly redundant approx 1/3 turbo code to make it resilient with small dishes (45cm) at the edge of coverage zone with rain.
@_date: 2018-12-17 19:59:20
video about Bitcoin Satellite kit project in Japan 
@_date: 2018-12-17 21:43:00
kryptonews article 
@_date: 2017-06-16 14:27:43
+1 that's why I'm interested in Bitcoin.
@_date: 2018-12-18 07:18:40
yes they have extra small dishes to point at the next satellite to receive. the uplink dishes are bigger in comparison.
@_date: 2019-05-09 00:27:41
well I can see it would be useful to know, but operational security suggests slightly better to not advertise. 
but bitcoin miners are dynamically anonymous and we call those fullnodes.
@_date: 2017-06-08 08:40:10
think about it. you wire transfer $50,000 to an exchange, $40 wire transfer fee. you buy bitcoin 20basis points buy commission = $100, cost so far $140. if it costs $100 to move to cold storage are you not going to do it? your trezor and cryptosteel cost $100 each. a bank deposit box to store it in $200/year. plenty of people make bigger wires than that.
I am not saying it's desirable, I am explaining the price inelasitcity of the digital gold investor, if available scaling technology isnt deployed.
@_date: 2019-05-08 20:43:18
traders are people too :) (don't dehumanise us!)
but also for people who want to play with confidential transactions, you can withdraw, deposit, store and transact LBTC to other users (with confidential transactions).
obviously not as censorship resistant nor secure for cold storage as mainchain so treat accordingly.
@_date: 2018-12-17 22:52:06
the research station scientists there have internet already, and the population density is super low.
@_date: 2018-12-18 21:00:16
(blockstream chief architect)  wrote an android bitcoin fullnode app: ABcore.  or on playstore.
@_date: 2018-12-18 23:41:43
there's an image of one of the satellites provided by telesat of telstar 11n (africa and europe coverage zones)  it's not a photo though, it's also a rendering they provide. but at least it's accurate and of the actual satellite.  from 
@_date: 2018-12-17 23:00:32
and podcast on blockstream satellite topic 
@_date: 2017-06-09 02:56:44
Because LN offers more scale fees would fall...
@_date: 2017-06-08 10:16:27
what are you talking about? segwit has been ready to deploy for 6mo.  sztorc drivechain.info is on-chain scaling too, and much more lasting than a 2MB increase.
@_date: 2019-05-08 19:59:23
you can do user to user liquid bitcoin (LBTC) or other liquid asset transactions. and run a liquid fullnode  look at blockexplorer  etc
@_date: 2017-06-08 09:27:23
I didnt say this was desirable.  But economically you maybe wrong: physical gold is more expensive, slower, harder to assay, etc. and it holds value fine.
@_date: 2018-12-18 23:50:26
also here's telstar18 (asia and pacific coverage zones) launch 
@_date: 2018-12-18 23:04:56
It's not over-provisioned because bandwidth costs money, but there is headroom for variance and message data. There are two streams: a) blocks now and b) blocks from 24hours ago, to help users with satellite only connectivity keep synced across a &lt; 24hr power outage, so they can catchup again. That leaves about 6Kbytes/sec per stream, but block intervals are 600 seconds so that provides 3.6MB/block but typical blocks are 1-2MB with largest seen at 2.3MB so there is excess bandwidth.
With the switch to transaction + compact block and multiplexing for API in Jan 2019 the headroom gets lower, because worst case there can be 100% overhead from sending transactions and then compact block (eg the block has none of the already broadcast transactions in it, or the user just turned on and has an empty mempool).  
Resending old blocks dont need to pre-send transactions so you can think of that as (worst case) three streams worth a) current transactions, b) compact block (worst case not containing any recent transactions), c) 24hour ago blocks. so then it's 4kB streams and 600 second blocks is 2.4MB/block interval which is larger than average blocks.
We also have some lossless data compression code we'd like to deploy at the same time, and can reduce the turbo code redundancy level a bit.
There are several advantages to users of sending transactions first: a) you can see pending transactions (0-conf transactions) faster if you're using a smartphone wallet connected to your fullnode without having to wait for the block which is average 10mins but can take up to 1hr once in a while), b) the latency to transmit a block is typically much lower, because you are sending a compact block at around 10kB range rather than a full block. Lower latency is good for using the satellite as a mining backup internet connection for learning about blocks and transactions.
@_date: 2017-06-19 13:10:30
Samson's got you: signalception
@_date: 2013-04-22 16:06:43
Ha .. just stumbled on this thread by accident - I talked to a journalist a few weeks ago so I was googleing to try find his article to see how badly mangled what i said, and btw actually he didnt mention me which is even better!.
Actually its even wore than that - I dont have a bitcoin address :)
@_date: 2013-04-26 01:03:33
I didnt know about the tip system auto-creating addresses so I thought I was safe.  But thanks - I believe they are in bit bitcointip managed address now!
@_date: 2019-05-08 21:26:01
terminology though: people still call it an ethereum fullnode (difficult I know due to scalability issues) when they're looking at an ERC20 of USDT, vs a liquid fullnode with a liquid USDT.
for a liquid BTC those backing BTC funds are operated unattended by the federated peg, by a threshold of participating exchanges with hardware modules validating the pegout goes to offline hardware wallet of participating exchange etc.  you could just say that for censorship resistance, unfreezability and storage security it is best to use the mainchain.
liquid is specialised for exchange traders, and better than exposure to an individual exchange which is otherwise implied. (and fast deposit/withdrawal from exchange, plus possibility for atomic OTC trade using native assets reduces single exchange time exposure and custody risk).
@_date: 2018-12-17 22:49:33
Stephan Livera podcast released today including discussion of Blockstream Bitcoin Satellite coverage expansion and lightning paid satellite data API 
@_date: 2013-11-18 09:32:30
From the Forbes article:
















Would you be able to explain how the above is not taint tracing?  I know you and Yifu (who replied to me tweet) focus now on talking about the KYC, AML certs, however the majority of the article was actually about taint tracing/clean coins/red-flag, which seems something quite different and with potentially dangerous adverse effects on fungibility.  The bad actors are not going to buy AML certs, and you cant provide "red flags" to businesses based on absence of AML certs.  I do not think you can fairly characterize articulating the risks to fungibility of taint analysis based red-flags as FUD.  It seems hard to reconcile the above forbes article quote with what you are now saying.  It seems more like you are starting with AML, KYC certs (good) and considering taint-tracing (dangerously bad) for the longer term, and so choosing to focus more on the less controversial former and gloss over the forbes articulated longer term plans.  I welcome your clarifications.  I see someone posted my full comments and it has worked its way up to the forbes top comments.
