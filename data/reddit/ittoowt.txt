@_author: ittoowt
@_date: 2014-02-13 17:25:49
Sure, the standard deviation increases sublinearly, but it still increases as the number of variables you add together increases, meaning you get more uncertainty rather than less.
@_date: 2014-02-13 05:46:47
Suppose the time to complete one block is a normally distributed random variable with mean 1 variance s^2 .  The time to complete ten blocks is then the sum of ten copies of this random variable and should follow a normal distribution with a mean of 10 and a variance of 10s^2 .  This has a larger variance than the individual block time, and that feature holds for distributions that aren't normal as well.  Is there something wrong with this argument?
@_date: 2014-02-13 01:32:40
Isn't that actually backwards?  Wouldn't the sum of ten random variables have a variance that is larger than the single variable variance?
@_date: 2014-02-13 17:09:09
The law of large numbers says that the variance of the average of many random variables decreases as you include more random variables.  In this case we are looking at the sum of several random variables (not the average of several random variables) and so the law of large numbers does not apply and the variance increases.  If we looked at the average time per block for ten blocks, we would find that the variance of the average block time decreases in accordance with the law of large numbers, but if we look at the total time required to observe ten blocks then we would find that the variance of the total time for ten blocks is higher than the variance in the time required for a single block.  