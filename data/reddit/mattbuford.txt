@_author: mattbuford
@_date: 2016-08-25 07:24:17
A few versions back they changed bitcoin-core so that instead of downloading all blocks from one peer, it now spreads the load and downloads from a bunch of peers at the same time.  This drastically improved the sync speed in most cases.
@_date: 2015-12-16 12:52:56
Bitcoin core already automatically forwards a port if your router supports it (UPnP).  If your router doesn't support it, or you have it disabled, then it has no ability to do this and you have to do it yourself.  How can it possibly be any more user friendly than that?
@_date: 2015-06-08 21:08:53
Looks like a log scale, which is exactly what is appropriate in an exponentially growing data set.  This is used in stocks (and bitcoin prices) all the time.
If this wasn't done, you wouldn't be able to see any of the old data because it would all be so tiny.
@_date: 2015-12-16 23:27:02
It is currently fully automatic if your router supports/allows it, and manual if not.  If the port doesn't get forwarded, the node still works and contributes somewhat to the network, just not as much as a proper node that supports incoming connections.  How can an app do any better than that for you?
The only thing I can think of is that there could be a better indicator to let users know when the incoming port is working.  This doesn't make opening the port any easier, but at least lets know you if you got it right.
@_date: 2015-06-08 22:41:56
A person reading that graph wouldn't be wrong in interpreting it as "stable" as long as they understand that it is a very long term view.  There are certainly fluctuations, but over a multi-decade view the trend is clearly a growth of a fairly stable amount.
Think about it this way.  If the stock market was perfectly stable and grew exactly 10% every year, if you looked at that on a normal linear graph, you'd just see a "hockey stick" where the entire graph is basically 0 until the very end when it skyrockets up.  This would be perfectly stable growth, but would look like a crazy spike on a graph.
However, if you took that same data set and graphed it on a log graph, then stable 10% growth will appear as a straight line that gradually goes up as it goes right.  Perfectly stable growth as a perfectly straight line.  This is the ideal way to view stability.
Since we're discussing the stability on a data set that grows by percentages over a long term, the graph type is exactly what needs to be used and does indeed show that the data does seem to trend near a straight line, and thus has fairly reliable growth over the long term.
@_date: 2015-06-16 06:05:23
To put this in perspective...  I don't know how many users Lastpass has, but if we assume at least 250,000 then it would take roughly a month of Titan X compute time just to try 10 passwords against the database.
In short, if your master password is "password" or something else absurd, you're screwed, but if your password is even mediocre then it is going to take them a while.
Of course, all this assumes your password hint isn't stupid easy too.  I'd say the password hints getting out is the only significant danger.
Also keep in mind that once they crack your master password, this does NOT give them all your passwords unless you haven't changed the master password in-between the time of the hack and the time they crack it.  The end result is that it is a good idea for people to change their passwords (there's no reason not to), but if your password is even mediocre there isn't even really any hurry and you aren't in any impending danger.
Edit: The article was updated to say there was an error and it is 10,000 guesses per second, not 10. But even that is pretty damn slow for cracking passwords.
@_date: 2018-08-16 00:01:20
I was worried about this until I realized USAA actually has Coinbase integration.  It just shows your coinbase balances when logged into USAA, but still, if they're willing to do that, they're probably not likely to ban customers for crypto transactions.
@_date: 2014-10-09 06:10:48
While I wonder the same thing, mag stripe cards do still work almost everywhere.  The only exceptions I'm aware of are automated train ticket machines and automated gas station pumps.
I just got back from visiting the UK, Italy, France, Belgium, Netherlands, Germany, Czech Republic, Austria, Slovakia, and Hungary.  I used mag-stripe everywhere (except trains) without issue.  There were 2 confusing events though:
1.  A waiter in London seemed confused, and I had to explain that he should try swiping my card.  He seemed unfamiliar with the process, but it worked.  No one else in London even questioned the mag-stripe card.
2.  When I wanted to try out my fancy new chip-and-pin card that I had obtained just before this trip (just to test it out), I used it at a Burger King in Spain.  I stuck it in there excepting to be prompted for my PIN, but instead the person reached over, took the card out, and then quickly dipped it for me, and the transaction was complete.  This left me confused, as I  arrived expecting everyone to use the chip and pin process, but apparently they didn't do it for some reason.  I later used this chip-and-pin card to buy train tickets at kiosks, and it worked as expected (requiring the card be left in the machine while I entered my PIN).
@_date: 2014-07-04 13:24:33
Personally, I use credit cards in a way that pays the balance off every single month.  So, although it is technically borrowed, it is only for a short term with no interest.  The credit card thus becomes effectively just a payment system.   Compare that to Oaypal where I have to load it up ahead of time.  Either way I go to a site and choose the method of payment.  The difference ends up being fairly minor for me other than that loading things ahead of time is a bit of a hassle.
So, I think when people say it will replace credit cards, they just mean as the common payment method.  I don't use credit cards because of the credit side.  I use them simply because they're the easiest method of payment and have the highest discount (because of cash back rewards).
@_date: 2014-07-04 09:30:18
You can generally reduce bandwidth by limiting the number of connections.  With less people connected to you, you'll probably use less bandwidth.  Not perfect, but better than nothing...  Another option would be to rate limit your full node to control bandwidth usage, but some have suggested that the network is better off without slow nodes...
I'm not an expert, but it seems to me that a reasonable compromise would be to run a full node with unrestricted bandwidth, but only part time.  If someone thinks this is bad for the network, feel free to correct me, but it seems the best idea to me.
For further reference, [here is a graph of my own connection.](  I have other things going on besides the Bitcoin full node, but all of the blue spikes you see are Bitcoin sending the blockchain to others that have connected to my full node.  Since the original post only showed daily averages, I'm posting this to give people a better idea of common mbps peaks.
@_date: 2014-12-31 05:20:21
Congratulations!  You are now reading the best comment ever posted to Reddit.
@_date: 2014-07-17 00:15:41
Most bitcoin QR code generators don't give you a choice, but QR actually supports multiple levels of error correction.  The catch is that more error correction means more dots.
Here is the same bitcoin address of mine with:
* [low error correction that can handle 7% damage](
* [medium error correction that can handle 15% damage](
* [quartile error correction that can handle 25% damage](
* [high error correction that can handle 30% damage](
If you compare, you'll find that the highest level has more dots than the lowest level.
The site I used that lets you make a QR code and select error correction level is 
@_date: 2014-07-04 13:10:00
Well, I'm thinking if you ran something part time (say 6 hours at least) you'd be offline say 18 hours at the most.  That is a pretty minimal amount to download compared to the clients that are downloading the entire blockchain or months/weeks.  Although I don't have any proof of this, I believe the big spikes I see of 3+ mbps that go on for 10+ minutes are clients connecting to me who are well beyond 24 hours behind.
@_date: 2014-07-04 13:13:44
Unless I missed a new feature, I believe the client is actually not very smart.  It picks one source and downloads everything from that source.  If it happens to pick a very slow source it will just stick with that and take forever to sync.  This is why it is strongly discouraged to run a full node on a slow rate limited connection.  People will sometimes choose you for the full block download and sit there hardly moving at all...  Since it is not smart enough to spread the download across the 8+ connections, it is important that NONE of those connections be slow.
@_date: 2015-05-09 06:29:08
would be 2015-04-23, wouldn't it?
@_date: 2014-07-15 02:23:23
Well, sort of.
Having a public IP that you can forward ports on is going to become rarer as more and more people end up behind shared NAT.  For the reasonable future, this will be less of a problem for servers and more of a problem for residential connections.  You could argue that servers in data centers are better places for full nodes than broadband links, but if you look at the OP's site you'll notice that currently many of the top full node providers are broadband providers.
Today, mobile connections are the main place the IPv4 crunch is already happening.  On many providers, your IPv4 address is behind a shared NAT and have no way to receive incoming connections.
If you get an Android phone from T-Mobile, it won't have an IPv4 address.  Any connections to IPv4 only sites happen through transition mechanisms that allow IPv6 only devices to hit IPv6 sites (which are generally less efficient and don't allow incoming connections).
Sure, mobile connections aren't really relevant to full nodes, but this gives you a preview of what is likely to eventually start happening to broadband land lines in the future...  IPv4 isn't exactly gone in these situations, but it becomes slower and loses the ability to have incoming connections.
@_date: 2019-10-11 14:29:14
In the US, there are very rarely minimum charges, but it isn't a common thing.  I can't even recall running into this even once in the last year.
This was admittedly 5-10 years ago so I'm not sure if it's still a thing, but I was very confused when I bought a pint in London and they charged my card their minimum (Â£10 I believe) and then handed me cash as change.  I have never run into anything like that in the US.  Restaurants there also seemed very unwilling to split the bill so everyone can pay with their own card, which was very strange to me because that's an everyday thing here.  More than one place got a little angry with me for wasting their time in even asking for this.
@_date: 2017-11-13 00:28:30
It isn't really healthy for the altcoin.  What you're suggesting is printing money faster.  Guess what happens when you try to pay people more by printing money faster?  :)
To the best of my knowledge, the lowered difficulty and resulting hashrate rush that produced blocks (and thus coin rewards) at ~2 minutes intead of 10 minutes should actually have driven down the value of Bitcoin Cash because of faster inflation.  I think the only reason that Bitcoin Cash actually went up instead of down is that people saw the mass hashrate move, saw that as proof of mass adoption, and the hype level went off the charts.  "Look, proof everyone is moving to Bitcoin Cash!  I have charts proving it!"  But of course, as soon as the crazy divergence balances back out, miners move again.
Take this all with a grain of salt though.  I wouldn't call myself an expert, and this is a pretty complex situation.  Quirks like the fact that coin production slowly phases out, meaning that if you increase inflation now you actually reach the end of inflation faster are hard for me to imagine how to factor in, though I suspect that is all very-long-term stuff not super relevant to the next year or two.
@_date: 2017-11-12 20:50:02
@_date: 2017-11-12 19:50:25
It adjusts, but only every 2016 blocks, and that's exactly the problem we're in now.  A massive amount of hashpower has left Bitcoin, causing block times to slow down.  Bitcoin will adjust, but we have to wait 1,849 more blocks until the next adjustment.  Because block times are now so slow, 1,849 blocks is a LONG time.  We're looking at 25+ days until the next adjustment at the current rate.
However, the reason Bitcoin lost so much hashpower is because Bitcoin Cash had a crazy low difficulty.  Massive amounts of hashpower going into Bitcoin Cash causes their blocks to speed up, making their adjustment time faster and their adjustment up higher.  They're about to have a huge adjustment up in less than an hour.  Presumably the sudden skyrocketing of Bitcoin Cash difficulty will cause lots of hashpower to move back to Bitcoin, speeding it back up without having to wait for the difficulty to adjust.
You can see the time until next adjustment of both here:
@_date: 2015-07-16 00:25:25
I'm using a monster of a case that I've had for 15 years now and keep reusing.  It's the Supermicro SC750A.  It has 6 5.25" bays on the front.  The thing is made out of thick steel, weighs a ton, and feels like it could survive being hit by a truck.  Here are links from an Anandtech review in 1998.  :)
Into those bays, I installed three 3-3.5" in 2-5.25" SATA trayless hotswap enclosures that I've had for 8+ years now and keep reusing for my NAS.
That provides me with 9 trayless hotswap SATA bays on the front.
I'm using btrfs, which allows me to just throw in all of the random sized disks I have lying around and it can make a redundant array out of them.  I don't have to have matched size disks for RAID anymore.  I literally put every old HD I had in my junk pile that was at least 100 GB in there.  Leftover many year old disks from parent's desktops, etc...  I even connected a few old PATA disks using PATA-&gt;USB enclosures just because I could.  The system has 12 disks spinning 24/7 plus 3 disks that power on at night for a backup and then power off when the backup is complete.
I still have a traditional RAID in there too just because I haven't migrated everything over to btrfs yet.
mdadm raid6 + lvm:
    md126 : active raid6 sde[4] sdd[3] sdc[1] sdb[2] sda[0]
      2930279232 blocks level 6, 64k chunk, algorithm 2 [5/5] [UUUUU]
btrfs on all other disks:
    Label: 'btrfs1'
    Total devices 7 FS bytes used 925.64GiB
    devid    2 size 465.76GiB used 361.00GiB path /dev/sdh
    devid    3 size 465.76GiB used 360.03GiB path /dev/sdg
    devid    7 size 111.76GiB used 6.00GiB path /dev/sdk
    devid    8 size 465.76GiB used 360.03GiB path /dev/sdn
    devid    9 size 93.16GiB used 42.00GiB path /dev/sdi
    devid   10 size 931.51GiB used 724.00GiB path /dev/sdf
    devid   11 size 111.79GiB used 7.00GiB path /dev/sdp
    Unallocated:
    /dev/sdf      207.51GiB
    /dev/sdg      105.73GiB
    /dev/sdh      104.76GiB
    /dev/sdi       51.16GiB
    /dev/sdk      105.76GiB
    /dev/sdn      105.73GiB
    /dev/sdp      104.79GiB
@_date: 2015-07-15 23:31:02
For anyone who wants to build their own J1900 system (perhaps not as small), I can recommend the Asrock Q1900M motherboard+CPU.  I bought it for $55 from Newegg to build a NAS.  Completely fanless/silent and around 15 watts idle (without spinning disks).
I put 2 4-port SATA cards in it and now have a 10 SATA port NAS with USB3 for additional drive expansion and still have a free PCIe slot.  The J1900 systems are amazing home servers for their super low price.
I'm thinking about buying a 2nd one to act as my router.
@_date: 2015-08-27 09:09:15
What if downloading of old blocks (say &gt;1 hour age) was rate limited, but newer blocks were not counted within the limit.  It has been my experience that the big data usage comes when the entire blockchain is being downloaded from me, not the normal day-to-day live blocks.
Especially considering slow upload links, it doesn't bother me when the client uses 1 Mbps upload.  What bothers me is when someone connects to download the entire blockchain and it suddenly uses 5 Mbps and pegs my upload for hours, causing me high latency.  If I could get the client to be a little closer to an average bitrate instead of having those huge spikes, it would make it much better for me.
@_date: 2016-02-02 17:56:06
Costs are not fixed.  The Internet is, by nature, oversubscribed.  This means that no one ever implements enough capacity to handle all users using all of their bandwidth at the same time.  Therefore, infrastructure costs are related to actual usage of those users.  If the usage of those users goes up, you have to increase your infrastructure to handle the increased load.
And that doesn't even get into having to pay providers more for higher usage...
But in both sides, costs are related to PEAK usage not average.  And caps are a statement of average usage.  So, it is certainly an imperfect measurement, but it is a simple one.  Network operators, and large commercial customers, are almost always billed using a method called "95th percentile" which is a more accurate measure of costs.  However, this method is much too complicated for home users to deal with.
@_date: 2017-11-12 21:29:35
Bigger blocks makes running nodes harder.  If you make running nodes too hard, few people will run nodes and you'll lose out on some decentralization.  People's opinions differ on how much of a problem this is, thus the disagreements about this whole thing...
@_date: 2016-02-03 00:38:22
It seems that the disconnect here is that you are saying "over subscribed" when you mean "congested".  These mean very different things.  The Internet is always built out as oversubscribed.  It's an inherent characteristic of the Internet.  However, a good provider will manage the oversubscription in order to make sure it doesn't get congested.
@_date: 2016-02-01 09:42:02
I have 5 Antminer U2+ sticks, which are cheap ASIC USB sticks and together they do roughly 9 Gh/s.
At current difficulty and exchange rates, this is getting me around 0.00114772 BTC ($.40 USD) per month, and dropping quickly as difficulty rises.  Current estimates are that at the next difficulty change in 5.7 days, my earnings will drop to $.34 USD/month.
Eligius is currently telling me that at the current difficulty level it will take me another 25 months to earn enough to enter the payout queue.  Of course, difficulty will rise so it will actually take quite a bit longer to reach that goal.
So, in summary, you can get some token bits to play with but certainly nothing of any real value.
@_date: 2016-02-01 19:37:17
If you're suggesting something like tc and matching on port (as many seem to suggest), what keeps me from doing this is that it would not only catch Bitcoin traffic.
For ports &lt;1024, you can catch traffic with port based filters as those ports are not used for anything else.  For ports &gt;=1024 you can not effectively match trafffic based only on port number because the ports can be used by outgoing connections.
This is one of those things that appears to work at first glance, but in reality something weird is happening, such as 1 out of ever 32,000 unrelated http connections gets caught by your rate limit too.
As someone who has made a living operating Internet backbones/datacenters, this is the sort of thing we try to be very careful to avoid.  I usually see this mistake in filtering (as opposed to rate limiting).  Someone tries to block a protocol port &gt;=1024 that they don't like and it appears to work.  Years go by.  There are random failures but they're so rare that no one puts it together.  They just press refresh on their browser and go one with life.  Then one day someone notices, for example, that an FTP of 100,000 small files is guaranteed to fail every time.  Or, they stress test their web server and get a steady rate of 1/60k TCP connections never complete and ask me why.
However, if you're running your full node on a host that doesn't really do anything else, and you either put the port matching directly on that host, or on your router and limit the IP to only the bitcoin node's IP, you're probably fine.  But if you just match all port 8333 traffic on your network at the router, or on a desktop/server that is used for many other things, you're creating the possibility of catching other traffic.
@_date: 2016-02-02 23:14:01
Telecoms bill on an APPROXIMATION of costs, not on exact costs.  95th percentile billing is a close approximation of network costs.  GB/month is a lesser approximation of network costs.  Both are based on costs, but one is more accurate than the other.
If your user base uses less GB/month, statistically you can expect lower peaks.  It isn't an exact correlation, but you can expect a clear relationship across a large number of users.  However, it is also possible to construct an example situation where users use more GB/s only off-peak and your costs don't increase at all.  This is not because bandwidth use doesn't increase costs, but because the customer-facing billing method is an imperfect capture of costs.  However, this inaccuracy doesn't change the fact that, if you give your users double the GB/month you can pretty much guarantee higher peaks.
Capacity is always oversubscribed.  On purpose.  Always.  There isn't any provider out there that isn't oversubscribed, or that even tries to be anything close to non-oversubscribed.
Occasionally in data centers you'll find islands of non-oversubscribed switching (such as between servers within a cluster), but they are very small and you're back to oversubscription as soon as you leave that small island.
So, if we put these two together, we see that infrastructure is only scaled to handle expected peak bandwidth levels plus a margin for error and growth, and that if you give your users more GB/month you can also expect higher peaks.  
Users using more GB/month is going to mean bigger peaks, which means bigger/earlier/more-expensive network upgrades.
@_date: 2016-02-01 17:23:00
Reasonably often, I guess.  Just keep in mind that finding a share isn't enough.  You still have to meet the pool's minimum payout before you get anything, and that can easily take months.  Here's the last hour's logs:
    [2016-02-01 10:20:22] Stratum from pool 0 detected new block
    [2016-02-01 10:24:10] Accepted 0067b64a AMU 0  pool 0 Diff 631/512
    [2016-02-01 10:26:49] Accepted 000a6bf6 AMU 1  pool 0 Diff 6.29k/512
    [2016-02-01 10:30:43] Stratum from pool 0 detected new block
    [2016-02-01 10:37:21] Accepted 0032dd32 AMU 1  pool 0 Diff 1.29k/512
    [2016-02-01 10:45:07] Accepted 006bc4fe AMU 1  pool 0 Diff 608/512
    [2016-02-01 10:45:13] Accepted 0055d4ac AMU 0  pool 0 Diff 763/512
    [2016-02-01 10:46:57] Accepted 00690920 AMU 2  pool 0 Diff 623/512
    [2016-02-01 10:50:42] Accepted 0039432f AMU 0  pool 0 Diff 1.14k/512
    [2016-02-01 10:51:28] Stratum from pool 0 detected new block
    [2016-02-01 10:52:16] Accepted 006cafbd AMU 1  pool 0 Diff 602/512
    [2016-02-01 10:57:35] Accepted 0039a5cc AMU 3  pool 0 Diff 1.14k/512
    [2016-02-01 11:03:12] Accepted 001a2df6 AMU 2  pool 0 Diff 2.5k/512
    [2016-02-01 11:04:46] Accepted 004734b2 AMU 0  pool 0 Diff 920/512
    [2016-02-01 11:11:23] Accepted 0074e0ae AMU 4  pool 0 Diff 560/512
    [2016-02-01 11:11:31] Accepted 001a8c08 AMU 2  pool 0 Diff 2.47k/512
    [2016-02-01 11:12:44] Accepted 00580f64 AMU 0  pool 0 Diff 744/512
    [2016-02-01 11:19:36] Accepted 00694f6a AMU 2  pool 0 Diff 622/512
@_date: 2016-02-02 21:12:34
I think the mistake you're making here is assuming the fiber is the hard part.  Yes, a single fiber pair can carry quite a bit of data, and in general when fiber is run, they tend to just go ahead and put a ton of it in the ground.  As long as you don't need to go beyond the distance that lasers can push light without needing regeneration, dark fiber isn't terribly expensive.
However, I think you'd be shocked at the cost of the hardware required to get all that data onto the fiber (specifically, DWDM gear).  And, the cost of this equipment is very much related to how much data you want to be able to push over that fiber.  Then, once you have the DWDM gear to give you a bunch of (often 10 Gbps) waves, you still need routers/switches to route that data around between the fibers.
Then, once that is all deployed, imagine your traffic levels double.  Guess what?  You now have to spend millions more to upgrade to handle the now higher level of traffic.  You can still do this on the one dark fiber pair you already have, but you need to add a lot more expensive hardware to do it with.
As for the billing problem and simplicity, 95th percentile billing is the closest thing anyone has come up with to linking bills to our actual costs.  However, it's very hard for end users to predict their bill, especially if they have irregular traffic patterns and/or don't monitor usage carefully.  For example, imagine I have a 10 Gbps circuit with 95th percentile billing.  If I use 10 Gbps for 36.5 hours and 0 for the rest of the month, my bill is 0 Mbps, as low as it can be.  If I use 10 Gbps for 36.6 hours and 0 for the rest of the month, my bill is 10,000 Mbps, as high as it can be.  Good luck taking phone calls from residential users who happened to do a big download for 36.6+ hours and are now facing a huge bill.
Even though GB/month is a less accurate representation of costs, it is something users can actually understand and reasonably predict.  But, since it is less accurate, as a general rule you'll never see it used for anything except residential, low end commercial links, and low end hosting.
@_date: 2016-02-03 02:53:12
To be honest, in the crossed terminology we've been arguing different things and I'm a bit uncertain what you're asking for a citation on at this point...  If you're asking to see actual graphs showing bandwidth usage on provider WAN links or uplinks, that is going to be tough to provide as they're typically NDA material.  Providers want everyone to think they have tons of excess capacity because that is what customers want to hear (practically dedicated bandwidth just sitting there waiting for you!).  Of course, the bean counters at providers want to hear that the provider is building out the minimum necessary capacity since networking gear is quite expensive.
Am I going down the right path in thinking that you're basically arguing that providers today have massive unused excess capacity, therefore a significant increase in usage doesn't really require any upgrades?  If so, I would say from a "fiber in the ground" perspective that's probably not an unreasonable statement.  We can push a LOT of bandwidth onto a single fiber pair.  However, from a routing/switching/DWDM hardware standpoint that isn't true.  Hardware to push data onto that fiber is very expensive and the cost goes up dramatically depending on how much bandwidth you want/need to put on that fiber pair.  The more people use overall, generally (but not exactly) this translates into higher peaks and thus more hardware needed sooner.
If you are arguing that off-peak bandwidth usage is cheap/free for providers, then this is mostly true.  A provider could say bandwidth caps only apply between 5pm and midnight or something like that.  This would not be hard to bill from a technical standpoint and it isn't signiciantly more complex for customers to understand.
I actually think we might see this happen as a compromise between caps vs no caps.  Probably the biggest thing holding us back from this is a lack of competition.  Since residential providers are typically duopolies at best, there isn't a lot of competitive innovation to disrupt the traditional billing systems.
Source:  15 years managing ISP and hosting provider networks.  I've spent a great deal of time looking at backbone circuit utilization graphs and making decisions about when upgrades are necessary, and then actually doing those upgrades.  When new locations were being built out that had no historical traffic, I had to guesstimate how big the initial circuits needded to be so that we didn't get congestion, but also didn't overspend on too much unused capacity.  Overall, the goal was to spend as little as possible on the hardware while ensuring there is enough of a safety margin that we don't get caught with congestion (due to normal growth, unexpected sudden growth, slower than expeted upgrade times, or DDoS attacks).
@_date: 2016-09-26 08:29:27
Unless you're doing the etching yourself, wouldn't this involve giving your cold storage private keys to a 3rd party to etch for you?
@_date: 2017-10-22 19:43:01
PIA isn't really a good mix with Bitcoin.  The way PIA works is that you don't get any ports forwarded by default.  If you want a port forwarded, you can request it, but you don't get to pick the port.  Their system replies back and TELLS YOU that on your current VPN connection, they have decided to forward port 9876 to you.  It is now up to you to put whatever software you want on port 9876.  There is no functionality to port forward a specific port.
In theory, you can just move your app to the port they give you.  I do this for torrents and it works fine.  However, Bitcoin happens to have a quirk that doesn't work well with this.  My understanding is that nodes looking for someone to connect to will AVOID nonstandard port clients except as a last resort.  So, if PIA assigns you 9876 and you put bitcoin on that port, you will successfully be able to receive incoming connections, but because of the way Bitcoin's logic works, none of them will ever decide to connect to you.  So, it ends up being no better than a node without port forwarding.
I'm not aware of any good way to deal with this.  I think you'd need to use a VPN that either lets you pick the port, or one that just gives you a public IP and avoids port forwarding completely.
@_date: 2017-09-18 07:22:37
It sounds like you're failing to see the distinction because you're trying to see more distinction than there really is.  There are just two different transaction networks.
Not all merchants support the debit network, but pretty much everyone supports credit cards.  So, debit cards made themselves compatible with credit card readers on the credit card network so that they would work everywhere.
Which network the transaction happens on doesn't change the fact that you're using a debit card, so you're expected to already have the money in your account and it will be removed immediately.  It does not take place as a credit transaction just because it occurred across the credit card network instead of the debit card network.
For example, Square is a popular system for reading cards.  They do not support the debit card network.  However, since your debit card can pretend to be a credit card, you can use it at these many merchants.
At places that support both networks (in my experience, usually grocery stores and gas stations), you generally are prompted to choose.  Which network you choose generally doesn't usually impact you greatly, though I believe it can impact what kind of purchase protection you get.
Personally, I've never had any reason to use a debit card, so I've always used credit cards.  I only use my debit card in ATMs to get cash.  I don't think I've done a single debit network transaction in my entire life other than cash at ATMs.
@_date: 2018-02-26 17:45:15
 tweets are often replied to by people like  with the same scam:
I feel like I'm sitting in Jita.
@_date: 2015-04-25 06:35:07
I think I'm too late.  So sad.
@_date: 2016-10-26 23:11:49
Their web site says it uses 4 watts:
4 watts 24/7 @ $.12/kWh gives us $4.20 per year.