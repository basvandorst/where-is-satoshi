@_author: 4x23
@_date: 2015-07-07 20:11:37
That is the verification time, not the download time. You too can measure the verification time on your blocks by running with -debug=bench. 
The server it is running on is a quad i7, 32GB of RAM, SSD boot disk and a RAID01 for storage of mass data (blockchain, electrum server, insight block explorer). The downlink is most certainly not dialup, and the distro is Debian. 
@_date: 2015-07-07 20:47:02
No, the comments about Electrum validation time apply to all blocks, not just blocks with abnormally large unverified transactions. Byte for byte most blocks contain roughly the same number of updates required to the database, at least as far as general statistics like this are concerned anyway.
@_date: 2015-07-07 20:46:09
No, the comments about Electrum validation time apply to all blocks, not just blocks with abnormally large unverified transactions. Byte for byte most blocks contain roughly the same number of updates required to the database, at least as far as general statistics like this are concerned anyway. 
@_date: 2015-07-08 00:35:50
Malicious person A pretends to be 50 nodes that all just proxy to being one, and denial of service attacks all the ones that aren't owned by them. The network is healthy because there are "lots" of servers, and malicious person A gets all the money. 
@_date: 2015-07-07 19:56:19
Yes. Electrum servers are run by volunteers with no funding and no means of recouping the cost of a running the service. **If** a block size increase goes above that level it will no longer be possible to run them on anything approaching normal server hardware. I benchmarked other Electrum servers to see what their setups are like, some are faster than mine (suggesting an SSD), but most are the same or slower. 
    48G     /media/raid0/bitcoin/
    23G     /media/raid0/electrum/
@_date: 2015-07-07 19:34:24
    
      - Load block from disk: 0.00ms [0.00s]
          - Connect 2034 transactions: 736.42ms (0.362ms/tx, 0.169ms/txin) [0.74s]
        - Verify 4349 txins: 739.20ms (0.170ms/txin) [0.74s]
        - Index writing: 45.79ms [0.05s]
        - Callbacks: 0.06ms [0.00s]
      - Connect total: 954.19ms [0.95s]
      - Flush: 24.53ms [0.02s]
      - Writing chainstate: 0.07ms [0.00s]
      - Connect postprocess: 20.76ms [0.02s]
    - Connect block: 999.57ms [1.00s]
    UpdateTip: new best=00000000000000000d667a9d215665741c700b9a0e884b52ac41ae68c7133762  height=364297  log2_work=83.043134  tx=74958850  date=2015-07-07 19:27:41 progress=1.000000  cache=24.9MiB(6327tx)
With a hot cache the performance is a bit saner, but Electrum still sucks. 
    blockchain: 364296 (184.933s)
    blockchain: 364297 (166.843s)
    blockchain: 364299 (340.340s)
@_date: 2015-07-07 20:01:50
Fees pay miners, not users and nodes who have to store and process them. 
@_date: 2015-07-07 19:31:18
It's being sent to stupid address like the brainwallet "cat". 
@_date: 2015-07-07 19:03:49
The transaction cache was cold for this one but normally that wouldn't be the case as much. If a transaction has been seen on the network before the verification is cached. For a 20MB uncached block you could be looking at easily 8 minutes to verify. 
This block also took almost 4 minutes for electrum servers to process. Electrum servers fall behind the network (can't keep up with new blocks) at around a 2.5 MB block size. This would mean that a large portion of users of Bitcoin would be unable to use their wallets which is obviously unacceptable. 
@_date: 2015-07-07 23:36:35
How do you prevent people setting up Sybil electrum servers that just proxy the requests to other people? 
@_date: 2015-07-07 19:35:18
That makes the problem worse, not better. 
@_date: 2015-07-07 22:29:14
Yes, like I said, the Electrum comment has *nothing to do with the abnormally large transaction*.
@_date: 2015-07-07 20:39:59
F2Pool is *cleaning up* the spam, not creating it. 
@_date: 2015-07-07 19:48:57
We still have to store and reprocess these transactions for all eternity, it's not exactly costless philanthropy. 
@_date: 2015-07-07 19:10:52
It was manually created by F2Pool, transactions larger than 100KB don't relay through the network. 
@_date: 2015-07-07 20:31:31
You can put bigger heads on babies but it's not much use if it flops over and breaks their neck.
@_date: 2015-07-07 20:05:32
Even if it was, clients aren't connected all the time. They need to be able to use old wallets they haven't synced in a long time, restore backups of wallets they put in a safe a year ago, and sweep private keys from cold storage. There's essentially no option for Electrum servers other than to store the whole thing, and the massive indexes, forever. There is some internal pruning of very large address histories (&gt; 10,000 entries), but that is neither here nor there (no reasonable use of a wallet will ever be pruned). It only saves a few hundred megabytes anyway. 
@_date: 2015-07-07 22:41:26
Maybe, but sharding like that is extremely hard with this sort of system. Addresses don't take a normal distribution, one address is several percent of the entire index size for example. It would also be extremely frustrating when servers go away and leave gaps, it would mean users are unable to sync until a new server is around.
@_date: 2015-07-07 19:30:26
F2Pool is cleaning up the spam, someone else is creating it. 
@_date: 2015-07-07 18:53:00
Yes, this one alone took close to 25 seconds for my node to verify. 
@_date: 2015-07-07 19:20:28
They charitably reduced the size of the UTXO database. 
@_date: 2015-07-07 20:00:43
You can not run an electrum server with autoprune enabled. You need all transactions for txindex, otherwise you wouldn't be able to show electrum clients their transaction histories. 
@_date: 2015-07-07 21:06:08
No, Electrum is perfectly operational with the 1MB block size limit intact. 
Electrum is not a centralised client and you will always have control and options with what to do with your coins. The client can't operate as normal without working servers, but you will not lose money if they do not exist. You can always convert an Electrum wallet into another type if desired. 
@_date: 2015-07-07 19:39:02
I'm saying that all evidence points to 20MB blocks being unobtainable with the current software, so either the transaction volume needs to be reduced or other solutions found which do not contribute to the block size. Increasing the block size to that degree would just make systems like Electrum unusable, so goodbye lite wallets. 
@_date: 2015-07-07 20:02:24
You're completely correct. There's no limit high enough to prevent spam, and a high enough limit will mean that people will start storing their facebook photos and stuff in the blockchain as well. 