@_author: cdecker
@_date: 2018-01-04 09:07:36
That's why, upon opening a channel, the two endpoints first agree on a [reserve]( value, below which the channel balance may not drop. This is to make sure that both endpoints always have some skin in the game as puts it :-)
@_date: 2018-01-03 12:18:04


Let me try to address this:
The notion that the lightning network will reduce liquidity by "locking up" funds is similar to the idea that keeping your funds in a wallet locking up funds, making them unusable to the rest of the network. The funds are always under your control, and you can decide to close a channel, and reallocating the funds at any point in time. One notable exception of this is the case when one endpoint disappears or becomes otherwise uncooperative. In this case you'd need to unilaterally close the channel, incurring in a dispute timeout, which may vary and be up to a few hours in length. During this timeout you cannot use the funds in question, yes.
During normal operation your funds retain the same liquidity properties that they had while sitting in a classic wallet. On the contrary one could argue that due to the instant confirmations and the lower fees, the liquidity of the system as a whole is much greater than the underlying blockchain.
Don't think of creating a channel as locking up funds, think of it as allocating the funds to a channel to maximize the utility you get out of those funds.
@_date: 2018-01-19 10:54:58
That'd be great, others might find it useful as well. We also have a [python]( and a [golang]( RPC implementation (thought the golang one needs a bit of love)
@_date: 2018-01-31 18:29:20
It's `lightningd/lightningd --network=bitcoin --log-level=debug` :-)
@_date: 2018-01-03 13:38:41
The point is actually a bit more subtle: for a cheat to become worth it, the opponent has to be absolutely sure that you cannot retaliate against him during the timeout. So he has to make sure you never ever get network connectivity during that time. Having someone else also watching for channel closures and notifying you, or releasing a canned retaliation, makes this even harder for the attacker. This is because if he misjudged you being truly offline you can retaliate by grabbing all of its funds.
Spotty connections, DDoS, and similar will not provide the attacker the necessary guarantees to make cheating worthwhile. Any form of uncertainty about your online status acts as a deterrent to the other endpoint.
@_date: 2018-01-17 00:51:34
You can use any of the three implementations:
 - 
 - 
 - 
@_date: 2018-01-18 21:56:11
Where are you getting stuck? I'd suggest starting with a testnet node first and only then move on to mainnet.
@_date: 2018-01-03 11:14:09
The node B may in fact attempt to cheat by publishing an old state (such as the A=0.5 and B=0.5 state). This cheat can then be detected on-chain and used to steal the cheaters funds, i.e., A can see the closing transaction, notice it's an old one and grab all funds in the channel (A=1, B=0). The time that A has in order to react to the cheating counterparty is given by the CLTV in the cheating transaction, which is adjustable. So if A foresees that it'll be able to check in about once every 24 hours it'll require that the CLTV is at least that large, if it's once a week then that's fine too. You definitely do not need to be online and watching the chain 24/7, just make sure to check in once in a while before the CLTV expires.
Alternatively you can outsource the watch duties, in order to keep the CLTV timeouts low. This can be achieved both with trusted third parties or untrusted ones (watchtowers).
@_date: 2018-01-17 17:14:13


Not sure, but it is possible to integrate some of the functionality into an existing bitcoin wallet, and some are already doing that. One of the nice qualities of having a layer 2 protocol is that we can build independently from the underlying layer, so we don't _have_ to push all of the functionality down the stack, keeping with the philosophy of doing one thing and doing it well.
@_date: 2018-01-17 15:10:51
Well, you'll also have to setup a channel first which requires an on-chain transaction, but after that you'll be able to transfer almost for free over that channel to other participants in the lightning network.
@_date: 2018-01-17 00:54:07
Just be sure to use them in mainnet mode. Opening channels between testnet and mainnet will not work :-)
@_date: 2018-01-18 22:26:25
Yeah, sorry for not being of more help, I'm not up to date with all that newfangled javascript all the webby whizkids play around /oldgrumpypeoplemode
@_date: 2018-01-19 10:52:42
Thanks for the contribution that was perfectly on spot
@_date: 2018-01-17 15:11:27
No problem, seems reddit catches them even like this, even though it doesn't get marked up :-)
@_date: 2018-01-17 11:01:45
It currently is a rather involved process of downloading and compiling your own lightning client, syncing a full node, getting some funds onto the lightning node and opening a channel. This is primarily aimed at tech-savvy users that want to help out testing things, reporting bugs and that would like a trophy for their work :-)
@_date: 2018-01-17 14:56:28
Good questions let me see if I can address them in a satisfactory manner:
Regarding the store being on mainnet: at some point we'll have to make the jump to mainnet, and that's always going to be the hard break from testing on testnet. People already started testing without us, e.g., TorGuard accepting mainnet lightning payments, so we decided to try it outself, you could say dog-fooding what we have been preaching. That allows us to gather first hand experience, and gives us direct access to eventual problems, making it easier to debug. With this announcement we have seen a number of new, tech-savvy participants, joining and reporting rough edges that we can now fix. For testnet there are a large number of demo applications out there to test, and they'll be available for the foreseeable future, but adding yet another demo shop where you can't actually buy things doesn't add much to what we had thus far.
For people that don't want to jump into the deep end, that's totally fine, in fact I'd encourage everybody to first try lightning on testnet and only making the jump once you feel comfortable with how things work, and that you've understood how lightning works under the hood. This is new software, and as much as we test it, there are still rough edges. That's also why we haven't released the c-lightning client itself yet, and haven't worked towards making it easy to deploy just yet.
You're already contributing to the development by testing on testnet, reporting issues to the [c-lightning]( project, participating in the discussion on the [lightning-dev mailing list]( or discussing on  on freenode, we have a friendly community there that will be happy to help out :-)
@_date: 2018-01-19 11:00:57
Your Ubuntu machine on DigitalOcean is a Linux machine, so all the instructions should work as expected.
The first steps to get started are:
1.  Install `bitcoind` (possibly the latest release from [bitcoin/bitcoin](
2. Start it with `bitcoind -testnet -daemon` and let it sync (you can check progress by using `bitcoin-cli getblockchaininfo`
3. Clone the c-lightning git repository `git clone  and compile it `cd lightning; make`
4. Run `lightningd/lightningd --log-level=debug` and it should connect to `bitcoind` and wait for instructions
Let's see how far we can get with this :-)
@_date: 2018-01-09 12:41:19
The payment forwarding already uses onion routing to hide source/destination from the forwarding node. All the forwarding node sees is that it got some funds from the previous hop and the instructions where to forward it next. It does not see who the other hops are or even how long the route is. For details see the [onion routing spec](
@_date: 2018-01-03 11:49:42
You could certainly do that, however it also means that in the case of a unilateral close, e.g., you just go offline and never come back, the other endpoint will have to wait for that timeout to expire to get its funds back. So peers might not accept channels with extremely high CLTV timeouts. 
@_date: 2019-07-06 12:45:42
I'd say a fundamentally different approach to how a client should be built. LL has an awesome feature set out of the box, and is rather opinionated as to how things should be done. We (c-lightning) try to build a minimal implementation, that has a large number of extension points (JSON-RPC, plugin interface for any language immaginable, and customisable subdaemons), and less opinionated as to how things should work.
Both approaches are worth exploring.
Re: advanced features: that is not really true, all the features are first discussed in the spec group, often coming from other teams as well ��
@_date: 2018-01-25 16:22:01
You're missing the build dependencies (`gcc` in this case), if you're on a debian based distro just do `apt install build-essential gcc`.
@_date: 2018-01-09 14:01:05


As the sender of the payment you have all the necessary to plan the route from you to the recipient. No need to contact anyone, just like Tor.


Yes, the HTLC construction used for multi-hop payments ensures that either all the intermediate hop payments happen or nothing happens at all. This allows you to retry upon failure, until you find a working route and the payment completes.
@_date: 2018-01-03 13:33:24
Why always these all-or-nothing scenarios? None of the system today, cryptocurrency or otherwise, can scale to accommodate the entirety of the world's population, why are you requiring this from a new system? It doesn't have to to be useful.
@_date: 2017-12-06 20:14:15
Nope, just as LN aggregates individual transactions, it also aggregates fees. So miners still get a share from the individual fees, but now they didn't have to put in any work for the large number of small transfers, just the settlements.
@_date: 2017-12-06 18:43:58


Or use the eclair wallet or c-lightning
@_date: 2017-12-09 14:03:00
Actually all you can really do is censor someone's transactions and doublespend your own funds if you are a 51% attacker. You cannot transfer someone else's funds, since you're still lacking their private keys and cannot sign transactions. So a 51% attack is painful, yes, and confidence in the system would severely suffer, but you still can't move someone else's funds.
@_date: 2017-12-06 22:08:48
Without bitcoin there is no lightning, it's as simple as that. We rely on the distributed and trustless nature of Bitcoin to be able to create lightning channels, settle them and secure them.
Besides that, there are use-cases that are perfectly suited for on-chain payments. Large payments for example tend to be less costly on-chain, since they are paid by byte size, not by the transferred value like in LN.
@_date: 2019-07-18 15:04:56
It can, as demonstrated by Richard Bondi: [
@_date: 2017-12-07 17:24:57
That's one possibility, but I think he was referring to the problem of not being able to use one card in another network at all, so simply having the ability to use my channel with any other participant is already quite different from the AMEX vs VISA example.
@_date: 2017-12-07 17:22:17
Most of the incentive for miners to join the network are independent from the transaction rate, since they earn most coins from the coinbase reward. So miners will always join, adding their computational resources and therefore their energy bill, as long as they make a marginal gain from the coinbase reward. LN does allows a higher payment rate, without adding to the energy costs, but it most likely will not reduce it either. As long as there are thousands of dollars to be made mining, people will be willing to spend thousands of dollars in electricity to grab those coins. That's a relatively stable equilibrium, not much we can do about it.
@_date: 2017-12-06 21:42:56
Yeah, my bad, I was using the testnet parameters, mea culpa.
If this had been an on-chain transaction it'd be 2 sat/byte though which is still pretty good. But yeah, fees will get much lower, I was just greedy and the only path between the endpoints. Anybody could have built a parallel path with smaller fees :-)
@_date: 2017-12-08 12:13:28
That's exactly the kind of strategic placement I think some users will attempt, creating bypasses to high fee regions, and shortening the distance between them. Any user can do that :-)
@_date: 2017-12-09 11:54:34
[lnd]( and [eclair]( work on Windows, c-lightning not yet. But beware that this is alpha level software at best and you should only test it on testnet unless you really want to jeopardize your coins :-)
@_date: 2017-12-08 12:36:07
No, it's a scalability layer built on top of Bitcoin. It aggregates smaller payments before settling them as a whole on-chain. By doing so it reduces the fees for the small payments, increases privacy (your coffee payment will not be stored for eternity in the blockchain) and adds real-time capabilities (once the payment goes through you don't need to wait for confirmations). Payments are denominated and backed by bitcoin, so if you have bitcoins you can use Lightning, no need to buy yet another coin.
@_date: 2017-12-08 14:58:23
Glad I could help :-) Those were really interesting questions to answer, sorry if that last one sounded a bit frustrated :-)
@_date: 2017-12-06 19:59:22
Right, collaborative closes are likely cheaper, but unilateral closes are key.
@_date: 2017-12-06 19:09:56
You can slow down the video playback on youtube, and lightning still is impressively fast :-)
@_date: 2017-12-07 12:26:18
There's no mining, all we need is Bitcoin, hence minimal electrical use for the lightning network itself :-)
@_date: 2017-12-06 20:41:56
Nope, he was explicitly talking about not being able to pay a shop that accepts AMEX with his VISA or the other way around. LN will be one contiguous network in which every node can transfer to any other node without needing any relationship with specific parties in the system (hubs, CC processor, ...)
@_date: 2017-12-06 19:24:43


Fees are intrinsically limited to the amount in a channel, so you're not going to make 10x on your funds by being a hub. Being a hub also makes you very attractive for attackers, and putting a large burden on you. My point is that if we can make channel creation and maintenance transparent, so people don't have to think about it, e.g., opening channels in the background, then everybody will share the load, instead of having to rely on single points of failure.


Hubs, being expensive, will likely attempt to leverage their central position in the network to ask for higher fees. So the implication that more hops are always more expensive is likely false.


Right, however there are sensible applications that don't lose the trustless features of bitcoin, such as lightning, and there are others that have different tradeoffs. In fractional reserves you're always trusting that the counterparty can actually recover the funds if you need them, there's no way of representing that as a trustless off-chain contract.
@_date: 2017-12-09 22:15:47
Opening a channel is just an on-chain transaction, so it'll take a few confirmations and the usual fees for on-chain transactions. Notice however that, since you don't need to open a channel to the merchant directly but only need a channel to any node in the network, your wallet can automatically open channels in the background, and before knowing that you'll want to interact with that merchant. So the flow might be:
 - Install a Lightning wallet on your phone
 - Go to the merchant. In the meantime the wallet has setup some channels
 - Do your grocery shopping
 - Go to the checkout and scan the QR code
 - Hit "Pay"
So eventually we plan to hide all the complexity of the underlying system from the end-user. You shouldn't have to know the tech in order to use it, or how often do you think about SMTP when sending an e-mail? :-)
@_date: 2017-12-11 14:56:16
No you'd remember the information from the last time you started the app and only sync the differences. This is not yet implemented, but it shouldn't be too hard to get a preliminary protocol working if that turns out to be a problem.
@_date: 2017-12-09 14:07:25
Eclair supports forwarding :-)
But yeah, you can outsource the route finding to some other party, with the downside that you'd be telling that third party who you're going to pay. This is a major privacy concern, that's why we decided to go for full information at first.
The protocol allows you not to announce a channel's existence if you don't feel you're adding to the network and are just interested in being an endpoint, and we have methods of selectively telling people about those channels if they need to use them, but ideally we'll start with a completely public network first.
@_date: 2017-12-28 23:17:18


A working system can beat a non-working one though :-)
@_date: 2017-12-09 21:50:52
Well if you have a connection to Alice, Alice has a connection to Bob, and Bob has a connection to the merchant, then you can send a payment to Alice, Alice will forward to Bob and Bob will forward to the merchant:
 &gt; You -&gt; Alice -&gt; Bob -&gt; Merchant
Using a few crypto tricks we can make sure that either all of the 3 transfers happen, or none of them does. So there is no way for example that Bob just pockets the money and doesn't forward. The technique is called HTLCs and has been around for quite some time.
@_date: 2017-12-08 19:16:22
Dunno, I found that people tend to be quite reasonable on either side of the debate once you take the time to address their concerns. The important thing is not to fall for the tribe mentality and keep an open mind :-)
@_date: 2017-12-06 19:01:22
You can still pay through that channel to other endpoints in the network, you're not limited to transferring to and from starblocks. Indeed in the video, there is no direct connection between lnd and starblocks. Instead they are connected to a c-lightning node in singapore and the payment is forwarded to the destination over 2 hops. You can extend that to 20 hops which pretty much covers the foreseeable network.
@_date: 2017-12-13 19:35:22


Just a minor correction, there is not really a necessity for any centralization by using Lightning, the channels are established in a peer-to-peer manner, without any kind of coordination. People always assume that large hubs will form due to the per-hop fees, however large hubs are likely to charge large fees due to their large upfront cost and small utility from channels that only go to endpoints. In addition hubs are a single-point-of-failure and an attractive target for attackers. Due to these considerations hubs are unlikely to form, and the network be just as peer-to-peer as the underlying bitcoin network.
@_date: 2017-12-09 14:47:09


Yep, it's like tor, and if you have a global view of the network, you could infer some information. That's one of the reasons I don't like hubs, since they could collude to uncover information about their users.
@_date: 2017-12-07 11:10:16
That only works if you actually see who the endpoints of a transfer are, in LN we use onion routing so you never see who the sender or the recipient are. All you see is that a payment came in from the previous hop and where the next hop is, so how could you enforce anything based on KYC/AML policies?
That's also a major reason we try to avoid creating hubs: having a homogeneous network allows you to use more hops to better protect your privacy and you can chose different routes if one of the hops is dropping your payment.
@_date: 2017-12-09 19:14:11
Channels allow you to perform any number of transfers to anybody that you connect to either directly or indirectly through a number of intermediate hops. It's not one channel per merchant, instead a single channel can open up connectivity to everybody else in the network.
@_date: 2017-12-06 21:11:44
LN should reduce the load on full nodes, since only setup and settlement transactions are confirmed on-chain, so reduced storage cost, reduced verification costs and less backlog than now.
@_date: 2017-12-06 21:52:05
Wait till I undercut your undercut ��
Let's send those fees to the bottom of the ocean
@_date: 2017-12-06 22:13:33
Sure, the spec probably is not the easiest explanation, I'd suggest the Spilman style payment channels here  The basic concept is that, if you want to open a channel with your counterparty, you create a shared account for the two of you. This shared account is a multisig address, meaning that both of you have to sign in order to spend funds on that address. Then you do an on-chain transaction, called a funding or setup transaction, that moves some funds onto that address. Once that confirms you know that the two of you need to agree on how to spend the funds, no one can run away with the funds.
The remainder of the protocol basically tries to ensure that only the latest agreement on how to split the funds between the two of you is enforced.
If you didn't have the funds to begin with, you couldn't have funded the channel since that requires an on-chain transaction. That's also the reason why you can't use the same funds in multiple channels, since you'd have to move your funds onto two different channels, which bitcoin doesn't allow.
@_date: 2017-12-09 11:52:51
That's indeed a concern, but also a nice problem to have, because it means that you have a big network in the first place. According to [Rusty's calculations]( we should be able to store 1 million nodes in about 100 MB, so that should work even for mobile phones. Beyond that we have some proposals ready to lighten the load on endpoints, but we'll cross that bridge when we get there :-)
@_date: 2017-12-09 14:15:53


Technically not true, even hops along the route only see a transfer coming in on the left and they're being told to forward it to their right. They don't see the endpoints, their position in the route, or even who else is involved. All they can do is try to infer things from the transferred amount and try to correlate by having many hops in the network.
@_date: 2017-12-07 13:15:55
Nope, they are prosecuting tor exit nodes, which bridge tor and clearnet, which in LN do not exist, it's all internal to LN and nowhere is anything transferred in cleartext or you know for whom you're forwarding payments. Also if one jurisdiction decides to criminalize the running of a certain software, these nodes get replaced by others outside of that jurisdiction.
Like bittorrent, any node is replaceable, and LN has no single point of failure. Got your channel killed because someone went offline? Just create a new one, maybe two or three for resilience, and you're back in business. Hence the importance of a homogeneous network. If you create hubs they may be attractive targets, also for prosecution.
@_date: 2017-12-06 22:02:16
Let's say you funded a channel with 10$, then the channel has a total capacity of 10$. Once you spent them, you no longer own them, so you'd have to stock up (on-chain). We have mechanisms to do so (splice-in and splice-out) though they aren't standardized just yet.
Much more interesting is, if you are being paid or forward payments for others you can get some of the capacity back. Let's say you have exhausted the channel's capacity, i.e., spent 10$. And later you earn some money, e.g., mowing someones lawn, let's say 5$. Then you can accept that payment over lightning which moves those 5$ back to your balance and you can spend them again. This can happen an arbitrary number of times, so the utility you get from those 10$ could be many times that.
@_date: 2017-12-08 14:51:57
Honestly I'm tempted to ignore this conspiracy, and since I am a Blockstream employee people will not believe me anyway, but let's try.
Lightning is not a sidechain, which I believe the whole argument in the video hinges on. Lightning channels are an agreement between any two endpoints to establish a channel and negotiate the ownership of the funds in the channel over time. At any point in time all participants have a bitcoin transaction in their hands to settle and payout their funds on-chain. There is no central intermediary and there is no requirement for special hardware. In particular Lightning is an open-source effort that multiple companies contribute to, working on the specification and implementing clients and applications. This is by no means a Blockstream only project.
The video talks about high fees for the settlement. It is one of our goals to lighten the load on the blockchain, by settling smaller payments off-chain and only reflecting the final sums on the blockchain. The result is that there is less load on the bitcoin blockchain, and fewer transactions that compete for space in the blockchain. In addition Lightning has some other nice features like real-time payments (no need for confirmations since endpoints can always enforce the agreed upon state on-chain) and increased privacy (not every coffee transaction is reflected on-chain for eternity).
The video also talks about forcing users to adopt Lightning or Sidechains. Both are open-source technologies that anybody can implement, and adoption is opt-in based: you like the tradeoffs of a system, you're free to join, if you don't you're free to continue using what you want.
The remainder of the video basically gives away the true motivation: pushing a forked off coin as the new bitcoin. We might have ideological differences when it comes to block size, but everybody should be able to think critically about the information that is presented, and not just follow what other people say.
@_date: 2017-12-06 21:33:10
Well we can't force people to run a full node, so making it easier and less taxing to encourage people to is what we do. Running a full node eventually should be an absolute no-brainer. Moving load off-chain is a great way to lighten the load for full nodes.
@_date: 2017-12-06 19:50:09
You can use any of the 3 compatible implementations:
 - c-lightning 
 - eclair 
 - lnd 
@_date: 2017-12-28 23:33:08
Without the blockchain underpinning bitcoin, there could not be a Lightning Network. LN still uses the Bitcoin blockchain to enforce the final state agreed upon by the participants of a channel, and as court in case of a dispute.
@_date: 2017-12-06 20:39:54
Yes, the closing party basically gives the other endpoint time to react and punish it if it tried to cheat.
@_date: 2017-12-08 14:31:06
Dunno, never asked for it. But if they deem me worthy I'd be happy to have it :-)
@_date: 2017-12-06 18:58:59


Actually no one has an incentive to create a hub, because they are expensive to operate, a network of homogeneous nodes that all share the load of network is far more desirable than a few hubs. And we're making sure that everybody has the ability to both use and support the network by forwarding payments over whatever route is best.


The whole point of this announcement is that all implementations are created equal, and can interoperate, so that there is a single unified lightning network, and if you have any connection to it then you can transact with any other party of the network, no need to have a VISA-lightning and an AMEX-lightning.


Absolutely not, in order to be secure the underlying funds in a channel need to be present, otherwise you open yourself up to fraud. Fractional reserve lending is not possible with LN!
@_date: 2017-12-09 14:45:41
Did not know that :-) Thanks that makes the testnet network even more impressive.
@_date: 2017-12-07 11:27:36


Just like we are doing with Tor and BitTorrent, P2P networks are incredibly resilient, and require a lot of coordination by all states to be successful in squashing them.


That's one theory, I guess we'll have to see :-)
@_date: 2015-06-03 08:54:22
I think you are mixing several things together, but we mostly agree: transaction malleability is a real problem and it has to be addressed. Using non-normalized transaction IDs to track transactions is definitely vulnerable, and I commend you for pushing normalized transaction IDs, as did I in a recent BIP.
This concerns the attack on the network, where an attacker modifies a transaction on the fly while it propagates in the network, which is the attack described in the press release on Feb. 10.
The part we disagree about is that MtGox was a victim of transaction malleability. We have shown that the on-the-fly modification described in the press release was not used anywhere near the volume alleged by MtGox. Was the additional interface MtGox provided used to attack MtGox? We don't know, but the claim that a bug in the Bitcoin protocol was to blame is definitely refuted.
@_date: 2017-12-06 20:50:47
No problem, all it takes is for your client to check in once a day to make sure channels are not being closed and that's it. All clients have reconnect support so you can go offline for some time. You just need to check that the other side doesn't try to cheat you.
@_date: 2017-12-08 19:12:07


That fully depends on the capacity of the channels that are being created, with channels in the 50$-100$ range we can easily support common payments for 5$-20$, which is what most day to day transactions are about. Micropayments is but one application, and we may be able to capture a lot of use-cases that are being pushed out by the current high fees. In the end there will be an equilibrium of use-cases that are better suited for LN and others that are better served by on-chain transactions. This equilibrium is not static and will adjust over time.


The idea of being able to maintain decentralization and just increasing block size to counter the increased load is also an illusion for that matter :-) We are only proposing one additional solution, whether people want to adopt it, and its features, or not is completely up to them.
@_date: 2017-12-06 20:46:11
Sure, the original paper is here 
Though many more concepts, ideas and improvements were added since we started the specification process, so the spec is more up to date: 
@_date: 2017-12-09 21:40:36
By "not using it" you mean he's not accepting Lightning payments? If that's the case you won't be able to pay him, but you might be able to pay him with an on-chain payment directly from the channel (not spec'd just yet, but on the roadmap).
If the merchant accepts Lightning, but you don't have an open channel with him just yet, you may have an indirect connection over which you can pay him.
If the merchant is unreachable through your existing network, you can open a channel, connecting two separate networks and making the network as a whole more useful :-)
@_date: 2015-06-23 08:43:47
I'd like to address your concerns regarding downsides:


The HTLCs presented in the paper allow for the creation of a forfeiture transaction, which is valid before the settlement transaction that would transfer the coins to the recipient, and instead refunds the sender. Should the recipient notice that it cannot claim the HTLC output, it can return the funds to the micropayment channel, thus reestablishing liquidity on the channel. The funds are not bound indefinitely to an HTLC that is not going to be claimed.


Unlike the OP claims, the paper is not using BIP 68 (nor BIP 65 for that matter). The channel cannot remain open after the timelocks expire, but the paper provides a refresh mechanism that can extend the lifetime of a duplex micropayment channel by committing a single transaction to the blockchain, and does not incur in the confirmation delay. The RCLTV proposals could possibly used to extend the lifetime of a channel, but since there is no progress there, it is safer to build a protocol that does not rely on them.


At any time there are at most d transactions that are valid, should one party unilaterally decide to broadcast an older version, then the other party simply releases its latest version, overwriting the older version. The timelocks are chosen in such a way that the reacting party always has sufficient time to react.


Although this paper is not using BIP 68 it shares this downside. Unilateral closure that does not incur in a time penalty on either side completely destroys the security of the protocol since it terminates the protocol without giving the reacting party a chance to react by broadcasting the actual latest state.
Full Disclosure: I am the author of the duplex micropayment channel paper.
@_date: 2015-06-02 08:56:40
Which we explicitly mention in our research as a possibility. However, your press release from February 10, 2014 states that an attacker on the Bitcoin network was able to modify the transaction in flight and gain from its inclusion in a block. It also mentions that other companies (not using your crypto lib) are potentially vulnerable.
What we did in fact refute is the claim that transaction malleability is a bug in the Bitcoin protocol that has immediate consequences for businesses. It simply is not true if a business uses a recent client that behaves correctly, and not some crypto primitives lifted from a 3 year old client.
@_date: 2015-06-02 07:28:17
As the author of the paper in question, I'd like to see the proof. We were monitoring the network for almost a year, specifically for double-spends and this would include transaction malleability incidents. I stand by the results: there was no transaction malleability misuse that is worth mentioning during the period MtGox was vulnerable.
@_date: 2017-12-08 12:38:07




How is it like a bank? You can set up channels with any other user, retain full control over the funds, gain the ability to send/receive them quicker and at lower cost, and you can close the channel at any point in time should you wish to use them elsewhere.
@_date: 2018-08-25 17:32:58
The `listfunds` output is divided into two parts: `outputs` and `channels`. Basically the funds listed in `outputs` are all available to fund a new channel, whereas the funds listed in `channels` are already allocated to a channel.
To sum up the funds you can use a bit of shell-trickery:
lightning-cli listfunds | jq .outputs\[\].value | paste -sd+ |bc
If you'd like to just fund a channel with all the remaining funds you can also use `all` as a value:
lightning-cli fundchannel [peer-id] all
@_date: 2018-05-03 10:53:53
Yeah, sorry about that, I might have buried the lead in some of the other explanations :-)
@_date: 2018-05-02 11:35:11
It definitely is handwavy at this point, I don't have a concrete idea (as in scripts and all).
Re-introducing the asymmetry at a higher level allows us to select how much of the channel we'd like to set aside for a punishment for example. Have the reserve split out into a separate output of the settlement transaction and encumbering it with a `shachain` or `elkrem` preimage. This is similar to the current mechanism of ensuring that all parties have some skin in the game.
Notice that I'm not opposed to having asymmetry at a higher level, but having the punishment as an integral part of the update mechanism is really painful :-)
@_date: 2018-05-31 09:42:15
Not really, the channels get configured with a variable timeout that governs how often the client must check in so that the counterparty can't cheat. If you configure it to be 24 hours (which is the default in all current implementations), all you need to do is check in once a day. Even if you don't check in there is a high chance of nothing going wrong: the timeout starts at the time the counterparty cheats, not the last time you checked.
The cheating endpoint would have to somehow know that you're going to be offline for 1 day when it cheats, and that you're not just pretending to be offline so you can punish it when it cheats :-)
@_date: 2018-05-16 14:21:39
You want the state number of the transaction that is being signed not to change, so that's why we explicitly put it in the nLocktime field. The state number that may change is the number of the output we are spending.
@_date: 2018-05-15 12:49:45
That's correct, and the reason we proposed `SIGHASH_NOINPUT` in the first place. The new sighash code blanks all commitments to the previous output making the transaction floating.
@_date: 2018-05-02 11:08:52
It would be possible to implement today's LN with it, but we'd have to re-engineer a lot of the scripts since `SIGHASH_NOINPUT` is more flexible, which may introduce the ability to rebind to transactions we don't want.
@_date: 2018-05-01 14:30:24
There are already a number of discussions about how sidechains can be simplified with the new sighash flag as well.
@_date: 2018-08-29 17:13:22


With 9.5 minutes to learn about the block we'd have an orphan rate of &gt; 90%...
@_date: 2018-05-01 14:29:36
Let's say you publish state 99,995, because it was the state at which you owned most of the shares. Then I, as your counterparty, know the later states (well at least I'll remember state 99,999), so I can use those to override your attempt at settling state 99,995. Since I don't want to play games with you, I'll just send 99,999, which will eventually get confirmed. You don't have anything else to add, since this is the last agreed upon state, so eventually the timeout will expire and we can publish the settlement transaction, completing the closure.
@_date: 2018-05-02 11:07:29
The point here is that we allow the update transaction on the blockchain but defer the transfer of control of funds until a timeout has passed, and then actually paying out through the settlement transaction. We're not revoking any on-chain transactions (which would have been necessary for satoshi's nSequence replacement), but we redirect funds to a newer update and its settlement, should there be one. A later update spends the output that'd be used for the invalidated settlement, thus making it impossible to confirm.
@_date: 2018-05-01 11:02:56
Yes, that's the goal. Segwit allows us to redefine an existing op_code or add new op_codes as a soft-fork by bumping the witness script version. The proposal we put forward simply adds `sighash_noinput` as a new sighash flag for `OP_CHECKSIG`, `OP_CHECKSIGVERIFY`, `OP_CHECKMULTISIG`, and `OP_CHECKSIGVERIFY`, through a simple change in how the signed hash is computed. It would also have been possible to implement it as a separate op_code but we feel it's easier this way.
@_date: 2018-08-25 19:20:19
Glad to hear :-)
I'll push for the `r` value support to make it in 0.6.2 :+1:
@_date: 2018-05-02 11:12:53
As you point out it can be very dangerous to just drop in `SIGHASH_NOINPUT` without ensuring that all rebindable targets are actually meant to be bound to. IMHO we could implement LN on top of just the new sighash flag, but we'd lose some of the other features from segwit (size discount, ...)
I'd definitely caution against just dropping `SIGHASH_NOINPUT` in and hope all works out.
@_date: 2018-05-01 14:53:31
I lack the insight into drivechain to make a specific proposal, but some (more informed) people seem to think so :-)
@_date: 2018-05-03 12:15:25
Not true, without your insights things would have never fallen into place like they did!
@_date: 2018-05-02 11:03:05
Excellent, I'll fix them right away and push a new version
@_date: 2018-05-01 15:56:04
Both systems allow you to react to a counterparty attempting a close with an outdated state. In LN you react by punishing the counterparty, stealing all funds in the channel. In eltoo you can present a newer state before the real settlement is presented, thus overriding the on-chain effects with a newer state.
@_date: 2018-05-01 14:25:03
In the current Lightning mechanism the publishing party indeed gets punished, since they misbehaved, and all their funds are claimed by the retaliating party.
With eltoo this is no longer the case, the old update gets committed to the blockchain, but can immediately be overridden by any of the later updates. This eventually terminates when the last agreed upon state was reached, so most participants will just short-circuit and publish the last state.
@_date: 2018-05-01 14:52:19
Exactly, you have something like 144 blocks to come forward with state 7, otherwise the settlement transaction for state 6 can be confirmed, which would then split the funds according to what we agreed upon.
So let's say at state 6 you and I had 5 and 1 bitcoin respectively. Now you transfer 1 bitcoin to me, and the new state 7 is 4 (you) and 2 (me).
You publish state 6, and I do nothing for a day. Now you can confirm the settlement, and you get 5 bitcoins, while I still get my 1 bitcoin.
If however I react to your old state being confirmed, then I publish update 7, which makes settlement 6 unconfirmable (it'd be a double-spend of the output from update 6). So we end up with settlement 7 which gives me my 2 bitcoins and you get your 4 bitcoins.
@_date: 2018-05-01 16:07:34
The offending party still has to pay the on-chain fees for all attempts he performs. In addition we can build a targeted punishment in at a higher level, meaning we don't conflate game theoretic stuff with what is a purely mechanical update mechanism. LN-penalty is an ugly mix of update mechanism mixed with a deterrent, in which we sometimes end up on the losing side (backups are impossible in a safe way with LN-penalty for exactly that reason).
@_date: 2018-05-01 14:25:56
The old update transaction may end up being confirmed on-chain, but it is overridable by any of the later updates, hence you don't get anything from having the old one confirmed.
@_date: 2018-05-01 11:12:03
We knew that this would come up, which is why we the announcement blog post has the following:


@_date: 2018-05-01 11:00:18
You need to compare the unilateral close in eltoo with the unilateral close of Lightning. The minimal unilateral close in LN-penalty consists of a commitment transaction, that creates the two "direct" outputs to_us and to_them, and adds any HTLCs. One of the two direct outputs is timelocked and needs to be claimed, plus we have an indirection for the HTLCs that need to be claimed as well.
eltoo adds a trigger transaction, and a settlement transaction, but removes the need to claim the deferred output, and the indirection in the HTLCs, so we should have the same total number of transactions on-chain.
Notice that in a collaborative close both schemes can use a single transaction that directly transfers funds to the owners, no need for anything else.
@_date: 2018-05-01 11:16:13
Both I guess, you'd need to download the blocks to learn their contents (and whether your transactions are in there) and you'd have to store them to allow others to catch up, or trace your transaction history.
@_date: 2014-03-25 09:20:48
Get those darn kids off my Blockchain!
@_date: 2018-05-01 14:43:43
Yep, it gives every party the chance to publish a newer state. I quite like the analogy used in the blog post: the parties are contractual partners, and the blockchain is the court. If the parties agree, the court doesn't need to intervene. If the parties do not agree, then the court gets involved, asking for statements, and waiting for witnesses to come forward, before it makes a decision.
As for pros and cons, we're still discussing them publicly, but so far the following seem to crystallize:
 + No toxic state (enables updates, simplifies watch-towers)
 - Less state needs to be kept per channel (old states cannot leak on-chain)
 - No need to commit to fees ahead of time
 - Symmetric scheme allows any number of participants in a single off-chain contract (sidechains, channel factories, ...)
 -  More on-chain transactions (disputed)
 - Need keep some funds on-chain to provide on-chain fees
 - Absolute locktimes need to account for replacement period (channels need to be settled before HTLCs can expire)
@_date: 2018-05-01 11:14:52
Broadcasting an old state really isn't free for the attacker, he'll need to provide fees to settle, and if the counterparty overrides the update, the attacker will be out of pocket.
Should the fee deterrent be insufficient we can always build new deterrents on top, but the point here is that the update mechanism shouldn't have to be encumbered with this deterent.
@_date: 2018-05-01 14:33:52
Not exactly costless, attempting to commit an old state will cost you the on-chain fees :-)
And nothing prevents us from implementing a punishment higher up in the stack, I just don't want it to be mandatory for the update mechanism itself :-)
@_date: 2018-05-02 13:25:38
Yeah, it's rather unfortunate that the unilateral close path is identical to the cheat path, but it seems they are intrinsically linked. There seems to be little we can do to disentangle the two, since a restore from an old backup will always look like a purposeful cheat attempt. What we can do is give a more predictable way to steer the penalty by using just the reserve for example.
@_date: 2018-05-01 11:09:09


Currently this is the best idea we have (thanks because it allows us to ignore fees altogether during normal operation. However, it requires us to keep an output ready to attach if we want to close. This shouldn't be an issue normally (how often do you really spend those five pence you have at the bottom of your wallet?), but it's something that we need to communicate clearly. Then again we already have some limits such as the reserve amount, so maybe we can fold some of these together into a single item in your balance :-)


That is indeed a possibility, though we don't see the computational limits to be much of a problem. It's a tradeoff between size and liveness: the bigger the group the more likely is that someone will become uncooperative (offline, crash, malicious, ...) at which point you'll have to close uncooperatively, which makes the funds unavailable for the timeout period. So it's more likely to be a protocol between a medium size group with reasonable expectations of cooperation :-)
@_date: 2018-05-01 15:53:38
Yeah, ran into this problem myself, trying to restore a node that I could have sworn was shut down before taking the backup. It turns out that it wasn't... :-)
@_date: 2018-05-01 15:50:14
Yeah, that's why we kept the activation section of the `SIGHASH_NOINPUT` BIP as vague as possible, to keep it compatible with as many improvements as possible and deploy them in parallel.
@_date: 2018-05-01 14:47:39






Can be built in at a higher level, it shouldn't be the core functionality of the update mechanism.


 You'd be paying fees for those 100k transactions, so it's in your interest to skip as many updates as possible, which should motivate you to cut out all the games and just publish the latest state. How is paying your fair share in fees to get something intermediate that is immediately going to be replaced a good strategy?


Again, not free, due to you paying your fair share of fees. And we can actually punish at a higher level.
@_date: 2018-05-01 10:55:40
Thanks Conner, glad you like it :-)
You are of course right, I was mistakenly assuming that the watchtower needs access to the commitment transaction, so this point is moot. My mistake. The major benefit with regards to watch-towers is probably that the data they need to store for each channel is constant, and consists of the latest update, its settlement and the HTLCs attached to the settlement.
@_date: 2018-05-01 11:18:20
Well, `SIGHASH_NOINPUT` really is a poor-man's malleability fix if you squint at it, since we can rewrite transactions to point to the malleated ancestor. It's very flexible but it comes with quite some caveats: binding only through scripts may be too flexible, especially in scenarios of address-reuse...
@_date: 2017-12-06 21:57:30
It's a shift in how the fees are computed. Off-chain transactions rely on being able to settle on-chain, so the off-chain fees have to be aggregated and pay for on-chain transactions. In addition with LN it is important to have a confirmation in a given timeframe, unlike classical bitcoin transactions that are just shoot-and-forget. So a settlement transaction will provide higher fees to get that guarantee.
So ultimately, LN aggregates both transactions and their fees, reducing the load on bitcoin nodes, but likely still providing comparable fees for their work.
@_date: 2016-03-05 23:45:23
Not intended, but indeed amusing :D
@_date: 2016-01-13 13:34:44
Yes, that is a very fundamental feature, allowing us to do transaction templating, i.e., collaboratively build a structure of transactions and committing to it once we agree that it is how it's supposed to. This cuts down on refund/CLTV transactions. It is also used as opt-in mechanism in Duplex Micropayment Channels.
@_date: 2019-03-17 13:16:02
Same here, still learning new things after tens years of doing this ��
@_date: 2019-03-26 09:37:10
Yes ��
@_date: 2019-03-17 10:47:52
Nodes may not relay an RBF transaction, that's true. But you can simply tell miners about your replacements directly. So that's hardly a protection for 0-conf.
@_date: 2019-03-06 20:07:57
Even without tor, c-lightning will try to re-establish connections to peers it had a channel with. If both peers are reachable from the network (no NAT or firewall) then the chances of them re-establishing the connection is quite good.
That being said, Tor is a far more stable since it gives you fixed public address like u/TracaChang mentioned.
@_date: 2019-03-17 11:16:15
Thanks xD
@_date: 2019-03-17 09:52:18
RBF is not a network enforced consensus rule. It can't be, that's why mining was introduced in the first place: to resolve the issue of conflicting transactions and syncing state among nodes.
RBF is a local policy that each miner may implement. If a miner decides it wants to be more profitable and just select transactions that give it more fees (replace by fees) the it can just patch it's node and start replacing.
It can't be disabled, you can only hope your miners aren't savvy enough and rational enough to enable it ��
@_date: 2016-12-03 12:03:49
Yes, the total amount transferrable in a single shot is the sum of capacities in the direction of the recipient. More precisely, it's the min-cut in the directed graph of remaining capacities.
You have two options: either split the payment into smaller payments, with some outgoing payments inbetween, or have the sender open a direct channel with the required amount to the recipient. The former requires that the exhausted channels get recharged with intermediate outgoing payments. The latter strengthens the network as a side-effect, eliminating the bottleneck for future transfers, but it's also slower since it requires a new channel to be created.
@_date: 2016-12-02 12:36:06
The number that is relevant is the total capacity of the channel, so if BestBuy foresees that it'll eventually have to transfer larger amounts to you, then they can add another 1 BTC to that channel initially owned by them. When a larger payment comes along, then they can tap into it.
This is for single-shot payments, which are limited by the total capacity. The total amount you can send and receive over the lifetime of a channel is unlimited. So if you continually receive an income stream of a few cents per second and spend at a similar rate, then you may incrementally send/receive billions of coins over a single channel.
@_date: 2016-12-02 12:26:01
Our hope is that with Lightning we can offer a cheap and fast alternative to on-chain transactions, especially for low value transfers, e.g., buying a coffee. This should result in a reduction in congestion for on-chain transactions, making our timing constraints less of an issue. Ultimately there will be an equilibrium between on-chain and off-chain transfers.
Notice also that, since we can amortize the channel costs over millions of individual transfers, we can easily attach relatively high fees, skipping most of the backlog.
@_date: 2016-12-17 10:54:20
In case anybody had any doubt which one is the _real_ crypto-valley :-)
@_date: 2016-12-02 13:26:05
Thank you for pointing out these things :-)
@_date: 2016-12-02 12:21:27


All my current publications can be found here: 
The payment channel related one is this one: 
@_date: 2016-12-02 12:32:20
It is off-chain in the sense that during normal operation we do not interact with the blockchain. You are right that the setup and settlement of channels happens on-chain. So 99.999% off-chain :-)
@_date: 2016-12-12 11:58:03
Yes, it's a bit of a whack-a-mole, especially since there may be inherent malleability in the ECDSA construction that we don't know about yet. Discovering such an attack vector while people rely on malleability being fixed can cause a lot of damage.
@_date: 2019-08-10 18:47:01
It's easily gameable and counterproductive in the long term. Remember that miners can stuff their own blocks with arbitrary transactions of their own for free (fees would go to themselves anyway). So what you end up with are just larger blocks with no upside. In the long run you are costing the network as a whole a lot of verification time and storage space.
@_date: 2016-12-04 19:19:14
Haven't had time to write it up, but the basic concept is based on the `refresh` in the [Duplex Micropayment Channel]( paper. I'll probably write it up soon :-)
@_date: 2019-08-12 08:21:22
@_date: 2018-06-11 10:43:48
Thanks ��
@_date: 2016-12-02 13:22:43
Good point, exchanges could be seen as off-chain in that sense, but these then require incredible amounts of trust. I think we can draw parallels here to Lightning. Think of setting up the channel as transferring the coins onto an exchange and settling the channel as your exchange withdrawal, only that now the Lightning protocol takes the role of the exchange. We just replaced the trusted mediator with a trustless protocol :-)
@_date: 2016-12-02 20:38:30
Yes, this won't happen on a random channel a user opens to another node. I was just pointing out that the funds may be provided by both endpoints, and in the case of a temporary imbalance, the capacity can be increased to create a buffer.
@_date: 2016-12-12 11:59:12
Yes, the current spec that we are working on relies heavily on malleability being fixed, simply because it makes the construction easier and cleaner.
@_date: 2016-12-03 11:58:02
If you are only ever going to make a single transaction, yes this has some overhead as compared to a single Bitcoin transaction. However, if you ever make more than one transfer, even to different parties, then you can use a network of interconnected payment channels to route transfers between any two endpoints in the network. So I'd say we are indeed targeting end-users, because who is only going to make a single transfer. We are also trying very hard to abstract the complex processes involved (routing, watching blockchain, etc.) in such a way that they are transparent to the end-user. So in the end it should just look and feel like a wallet today. After all when we're using a wallet today, we don't really know about sighash-handling and signature serialization, are we?
@_date: 2016-12-02 12:38:19
Hm, at that point we start getting very philosophical. The payment channel is a structure that exists alongside the chain, with some of its operations being on-chain while most of its operations are off-chain. I don't think we can say that the channel itself is either on-chain or off-chain, just its operations or effects.
@_date: 2016-12-04 11:51:12
There is no reason we have to use two transactions in this case. It's what I was hinting at earlier, a method to splice-in funds, splice-out funds or simply refresh the channel. We settle the channel and in the same transaction we create the new channel, so just one on-chain transaction overall. Since the funds in the channel never really touch a singlesig, i.e., are always kept on a multisig address owned by both endpoints, there is no possibility for a doublespend, and we can continue on the new channel without waiting for confirmation. This is in the case of a splice-out (sending a classical TX from funds locked into a channel) or a refresh. For a splice-in (adding funds to a channel) the funds must be locked into a multisig ahead of time.
This is a very flexible construction allowing to add funds to an existing channel, or make classical bitcoin payments out of a channel, without incurring in delays and with little to no overhead compared to just doing classical bitcoin payments.
That being said, if it is a one off payment and you never plan to do any more payments in the Lightning network, yes you'd be better off just doing a direct payment, which will remain a valid option. But as soon as you do 2 transfers to any participant in the network you have big savings, and nicer guarantees, such as the instant confirmation of transfers.
@_date: 2016-12-02 12:57:44
Two very good questions. Let me try to address them.


The channel itself can be frozen and unfrozen, so as long as the other party agrees to keep it open while your phone is offline then the channel can persist. So there is no long on-chain setup required if you go offline for a while. That being said you still need to react in reasonable time, should the other end decide to misbehave, publishing an old state. Reasonable in our case means a few hours, and it can be negotiated to match your preference for how long you'll be offline, so if you check in once a day then just set the timeout very high. The risk in that case is that your counterparty may not like that, because her funds are locked in for longer if you disappear.
To keep these timeouts reasonable we are working on outsourcing solutions. We have some drafts of untrusted third parties. These third parties will then watch the blockchain for any activity for which they have the matching response, and publish that response. The user simply transfers encrypted responses, i.e., punishment transactions, to as many third parties has he wants. Should the third parties ever see something matching one of the encrypted punishment transaction, then they release punishment transaction. The encryption ensures that the state of the channel isn't leaked and the third parties don't even learn what channel they are watching.


There are some inherent costs that are proportional to the transferred amount and some a fixed overhead for each transfer that each forwarding party incurs in a transfer. We reflect that by letting every node specify what its per-transfer fee and its per-transferred-satoshi fee is. The sender knows the path the transfer is going to take, and allocates the necessary fees accordingly. There is no way for a node to grab more than its allocated amount so it has to announce the correct fees it expects. So the fees are completely transparent to the end-user.
It may still be that the only route to the destination is very expensive, but then you just found a nice opportunity to place yourself in the network, acting as a bridge with slightly lower fees but still earning fees by forwarding other payments and strengthening the network as a whole :-)
@_date: 2016-12-02 13:08:10
Ah, I see, yes the coins never leave the blockchain. This is true for anything that is denominated in bitcoins, they are intrinsically bound to the blockchain they were created/mined on.
What we do off-chain is we negotiate over who owns how many bitcoins. In on-chain solutions this is done by committing a transaction into the blockchain, which is a one-shot process. In Lightning we may continually re-negotiate the ownership, without the coins on the blockchain ever moving until we decide to settle the channel, at which point the aggregate of all our negotiations (individual transfers) are reflected in a single on-chain transaction.
I agree that on-chain and off-chain are not very well defined, and I'm afraid with your definition there can be no off-chain ever, since coins cannot leave the blockchain.
@_date: 2019-02-20 20:49:36
Ouch, did you restore the node from a backup, or did you have any disk issues lately? In this case, where the other side has a newer commit tx you won't find the tx in the DB since c-lightning noticed the discrepancy and refused to sign and broadcast it.
This is kind of a worst case scenario, and you need to hope the other side closes for you.  
@_date: 2019-02-16 09:05:41
c-lightning can be pointed to a remote `bitcoind` using the `--bitcoin-rpcconnect` flag. I run several lightning nodes on a number of machines and they all connect to a single `bitcoind` ��
@_date: 2019-02-17 19:30:40
Ok, so the state awaiting unilateral means that we or the other side have initiated a unilateral close. You should be able to retrieve the close transaction from the DB using the following:
sqlite3 $HOME/.lightning/lightningd.sqlite3 "SELECT HEX(rawtx) FROM transactions
You can then try to broadcast them again. We'll eventually add a more convenient way of doing that.
@_date: 2017-11-10 16:22:05


Right, reallocating and rebalancing are similar, but with the mechanism described in the paper the channel that we add funds to does not have to exist at all before we reallocate. In LN this would require us to create a new channel and wait for it to confirm. In this scheme we can just take some funds from an existing channel and spawn a new channel from it.


This scheme allows an alternate channel creation mechanism, however once the channels are setup they work just like before. So the endpoints of a channel could decide to upgrade at a later point to use this scheme, without having to teardown the entire network and rebuild it on top of this. So, no, we do not need to incorporate this scheme right away, but we may seamlessly update later, that's one of the advantages of creating a layer 2 system :-)
@_date: 2017-11-10 16:54:53
Yup, been around about 150 years longer than the acronym squatters :-)
@_date: 2017-11-10 16:02:42
While the rebalancing is a rather nice feature of this system it is not the only one. Having the ability to reallocate funds without dropping on-chain allows you to adjust the allocations of your funds on the spot.
It also reduces the number of on-chain transactions needed to bootstrap the network. On-chain space is precious, so allowing a number of participants to collaboratively set up a number of channels with a single on-chain transaction preserves that space, while still enabling n^2 potential channels between the participants. Moreover it allows you to setup a channel without having to wait for a new setup transaction, simply by reallocating funds. This increases resilience against exhaustion and individual failures.
@_date: 2019-02-16 18:21:02
First of all, don't edit the DB manually. That can cause more issues than it resolves.
It might be that the channel is still closing. Unilateral closes result in the funds being sent to a temporary address (2-of-2 multisig address between the two parties) and it takes some time, before the node automatically resolves that and moves the funds back to your wallet. With `listpeers` you can monitor the progress, and if my assumption is correct then the peer should still be in state `ONCHAIN`, and will tell you how many blocks until it resolves all outputs.
@_date: 2017-11-10 16:06:26
They might be mistaken when believing that they'd make fewer in fees from a lightning network. LN taps into use-cases that no sane person would ever do on-chain, while keeping on-chain use-cases intact.
LN also introduces an urgency to some transactions, i.e., retaliation transactions, that need to be confirmed in a fixed amount of time, hence they'll be paying much more in fees than the confirm-eventually transactions. That's ok, because the LN users got their increased utility from the channel while it was active.
So the miners might have less work, but could potentially earn more.
@_date: 2019-01-03 14:58:59
It should absolutely not be a problem to change IP addresses or even transport (IPv4, IPv6, TOR). The one caveat is that channels that are established may take a bit longer to re-establish the underlying connection.
AFAIK all wallets will reannounce their current address as a `node_announcement`, which allow your peers to reconnect and re-establish. However the `node_announcement` may take some time to propagate, so you might need to be patient.
If you know the current address of your peers you may also reconnect manually and the channels should be re-established correctly.
@_date: 2019-01-02 10:55:51
A transaction spending an unconfirmed input (from a parent transaction) will not be able to be confirmed until the parent transaction is confirmed. It is however possible for both transactions to be confirmed in the same block as long as all dependencies (parent transactions) are listed in the block before the child transaction.
@_date: 2019-01-25 20:14:55
Wait, I know this place. Didn't know they accepted Bitcoin, that absolutely awesome!
@_date: 2019-01-08 12:45:13
We require segwit as a malleability fix, since we keep chains of dependent transactions off-chain, and need to be guaranteed that the relationship between then can't be severed (txid malleability).
It doesn't matter how many others use segwit in Bitcoin, just that we can use it when we need it.
Other malleability fixes would have worked as well, but performed worse (my Normalized Transaction ID BIP 140), or weren't invented yet (my `sighash_noinput` BIP 118, used for eltoo).
@_date: 2018-02-28 19:21:12
The key difference is that these tracks are only seen by the few parties directly involved with forwarding the payment. This is in stark contrast to on-chain payments where all tracks are permanently recorded for all eternity, and can be data-mined even by passive observers.
@_date: 2018-03-01 14:04:30
Absolutely, come to the lightning side, we have cookies :-)
On a more serious note, it's been fantastic working on Lightning. Building on top of bitcoin instead of having to push every detail into the bitcoin protocol makes it a lot easier to implement changes, and this added flexibility makes the process a lot more pleasant as well. Let's keep with the unix philosophy and let bitcoin do one thing and do it extremely well, while we build layers with more functionality on top.
So if you have a good idea on how to improve the protocol, with regards to privacy or otherwise, feel free to propose it and I'm sure we can implement it quickly.
@_date: 2019-01-08 13:36:03
BIP 118 ist still a draft, and it looks like it's going to be implemented soon. Notice that `sighash_noinput` is likely too flexible as just a malleability fix.
@_date: 2018-02-28 19:29:03
Thanks for the thoughtful reply. I'm not sure I get your point about end-to-end encryption. We encrypt at every possible level: the transport layer between the two endpoints of a channel is encrypted using the [NoiseXK protocol]( and the multi-hop information is encrypted using a [Sphinx]( variant.
The transport layer is aimed at providing secrecy from passive eavesdroppers and provide protection against MITM attacks. The sphinx routing packet makes sure that only the intended hop can read the forwarding information (and any additional instructions we may pack into the onion). As an intermediate hop you see that a packet came in from the left, you peel a layer off the onion, which tells you where to forward it next. You should not learn anything beyond that.
In addition we mask some of the information that goes into the blockchain, e.g., the commitment number is obfuscated in the commit transactions.
That being said, we're always open to improvement proposals. Being a layer2 protocol we can actually innovate very quickly. Any proposals should probably be directed at the [lightning-dev mailing list]( first, so we can discuss them in an open setting.
@_date: 2018-02-28 19:31:27


I totally understand this desire, but I found that comment sections on private sites tend to either be deserted, or abused. I'm trialing outsourcing the discussions to reddit, and so far it has been a very good experience :-)
@_date: 2019-01-03 15:50:54
Happy to help ☺️
@_date: 2018-02-27 16:12:45
Great catch will fix now :-)
@_date: 2019-01-02 12:46:36
No, in case of dependencies among transactions, they must have a partial order that guarantees that dependencies are processed before their children.
This stems from the fact that transactions are processed in the same order they are serialized in the block, and changes to the UTXO being applied incrementally. Each node maintains (at least) 2 UTXO set views: one is its current mempool UTXO and the other is the latest confirmed UTXO set view. When a block comes it that is a candidate to be the next blockchain head, the mempool UTXO set gets reverted to the confirmed UTXO set (or outright discarded), and the changes in the block get applied incrementally. If we were to process a transaction whose dependency hasn't been processed yet, it would fail the check for the UTXO entry that it is spending (because that'd be created by the dependency), and hence transaction verification would fail, and the block verification would fail as a consequence. In order processing guarantees that the UTXO entry is there when verifying the transaction, that's all.
@_date: 2018-03-25 19:47:30
That should not be a problem, Lightning Charge can be adapted to work with those implementations as well.
@_date: 2018-02-27 16:34:03
Glad you like it, hopefully it's useful.
@_date: 2018-02-28 19:32:06
I accept both descriptions :-)
@_date: 2018-11-15 16:40:30
Chatham house rules, sorry can't tell
@_date: 2018-03-25 18:55:50
Well not `lnd`, this is based on c-lightning and Lightning Charge, but yeah, lightning is great to monetize on APIs, independently from the implementation :-)
@_date: 2018-02-07 16:55:41
All we can really do is tell you the total capacity in a channel, not how it is currently allocated among the endpoints. We'll be annotating channels with their total capacity soon (see [issue 817]( for progress). The reason we can't really say anything about the current ownership is that this is highly volatile information anyway, and if nodes were to publish that information we could trace payments through the network, which we worked really hard to hide in the first place. If we see a series of channels adjusting their balances by a very similar amount we could infer where the payment came from and where it went.
@_date: 2018-02-28 19:19:11
Agreed, the issue of the limited topology is not very well understood, and should be quite interesting to look into. Sadly I'm not aware of any research that is directly related to this issue.
With regards to the issue of an attacker controlling the available hops, it should always be able to extend a route and create plausible deniability about the true origin of a payment or it's intended destination. In order to profile a node you'd have to be controlling all the channels of that node. This may work for a single node, but it won't for the entire network. On top of that you'd have to make sure that the monitored node does not have some hidden channels from which it is forwarding. Even a slight possibility that the payment you attributed to that node was not in fact from that node or destined for that node, will have a big impact on the correctness of your profile.
In the end it all comes down to the way the network is structured, and it is the primary reason why I personally hate the idea of hubs, even though they'd only be seeing partial information. With things like `lnd`s autopilot we can steer the topology in such a way that privacy leaks can be made less likely, without burdening the users with hard decisions about where and to whom to open channels.
@_date: 2018-03-24 23:31:59
If you do deploy, let us know, there might be a tip coming your way :-)
@_date: 2019-01-02 15:31:08
Anytime, glad I could help ^^
@_date: 2019-09-06 18:15:37
If you look at off-chain protocols (layer 2 such as lightning) in a certain way it turns out they provide the same capabilities as on-chain systems, so we can reuse a lot of existing tools ��
@_date: 2018-02-15 15:00:14
Depends on the failure case, only in the worst case (node crashes while payment is being forwarded) will we have to drop to chain, which would incur on-chain fees. On-chain fees also are paid to settle the channel, not the individual payment.
@_date: 2018-02-28 22:19:11
I'd like to apologize about the previous comment, it was oversimplified and I should have put more though into it. From my point of view though the simple fact that we are a) not broadcasting everything, and b) not storing information forever about the payments is already a step in the right direction.
As mentioned in the post, privacy is not a linear tradeoff, it is a multi-facetted issue, and making comparisons is very hard (which is why I don't try). I'd just like to address two points you mention above: unverifiable privacy and the trust in hubs.
There is no such thing as verifiable privacy, all comparisons of these systems rely on assumptions that may turn out to be false. If you assume that nobody data-mines the blockchain you can probably show that on-chain payments are perfectly secure. If you take a cryptocurrency that strives for privacy with various cryptographic tricks, but some of them turn out to be broken or the users simply don't use them, is that more or less private? As for the traditional finance system, some are incredibly good at keeping their clients' information private (I live in switzerland...), but there are also the Equifaxes and the Mossack-Fonsecas.
I totally agree that in the end it all comes down to how decentralized the network turns out to be, and we do our best to avoid hubs being formed. But we also need the help from the users to help build a network that makes it hard to trace.
@_date: 2018-07-07 22:03:33
I'm interested in this as well so I'm running the numbers now. Thanks for kicking this off :-)
@_date: 2019-09-07 08:35:31
It's rather simple really: eltoo separates state lock-in from effects by creating bit an update transaction as well as a settlement transaction which carries the state.
You can confirm any update transaction, ratcheting the state number forward, but attaching the settlement transaction has a timeout. So if it was an old update any other party can publish a newer one, preempting the old state since you can no longer attach the old settlement. Eventually the last update transaction is confirmed, and it can not be overwritten, allowing the timeout to expire and only then can a settlement be attached.
So the key here is that you can initiate a settlement with an old state, you cannot complete it, as long as a counterparty can overwrite it with a newer one. The outputs of the settlement are only available upon completion.
@_date: 2019-09-07 14:22:57
Depends on your interpretation of whether the update transaction is part of the state or not. I usually consider it the precursor to the actual state, since it doesn't actually contain any state specific information. But we're splitting hairs here.
The main difference between ln-penalty and eltoo is that with eltoo we eventually end up with the state that we negotiated, whereas with the penalty mechanism we end up either with the state we negotiated or with a prior state followed by a punishment. eltoo's guarantees are strictly superior because we don't need to handle the degenerate case in which we need to create a punishment for an old state, we are guaranteed that the old state never makes it on-chain.
@_date: 2019-09-06 20:36:56
It's not that far off and definitely one of my top priorities as well ��
@_date: 2019-09-07 17:56:38
Regarding your second question: the fees to publish the old update transaction are charged to the participant sending it. Overriding costs the correcting node a fee. So the misbehaving participant pays a fee without getting the desired effect, whereas the correcting participant pays a fee, but gets his way ��
@_date: 2011-03-23 12:19:06
Loving it ^^
@_date: 2018-07-07 21:52:01
That doesn't really get you the theoretical maximum flow from a source to the destination (though you might actually be rather close). Any max-flow/min-cut algorithm will actually be able to give you a better approximation.
@_date: 2019-09-07 17:41:01
Well, think of it this way, an update transaction nullifies all prior states, but doesn't itself contain any information relating the current state ( it doublespends the output the prior settlements would have used. 
When I say that no prior state leaks on-chain, I mean that none of the outputs built on top of a nullified settlement transaction ends being confirmed on-chain. No outputs going to individuals, no Htlcs, no other output that we negotiated and then removed. This frees us from having to deal with them accidentally ending up on-chain like it is the case in LN-penalty (which is the reason that punishment logic needs to be threaded into those outputs)
As an aside: I didn't call update txs "commitments" exactly to avoid creating confusion with LN-penalty
@_date: 2019-09-06 20:26:59
Richard Myers has recently written a proof of concept implementation on top of the Bitcoin signet.
@_date: 2016-10-05 21:31:34
You can download and compile the code right now. The documentation is not exactly self-explanatory yet, but it is possible to buy a cat today:  :-)
@_date: 2018-04-30 18:53:03
The watch-tower no longer needs to hold a canned response for any possible misbehavior from the counterparty (including HTLCs from older states, commitments, ...), it only ever needs to hold the latest update and settlement pair (with the currently active HTLCs), and it can discard any prior set of transaction when a new one is agreed upon. This makes the storage requirements on the watch-tower linear in the number of attached outputs to the settlement transaction, i.e., constant for most cases.
@_date: 2016-10-05 19:48:14
Yeah, Bitcoin rocks :-)
@_date: 2016-10-05 17:04:49
Yeah, that was necessary. Back in my research group we had a guy who'd explain all the jokes, maybe I should ask him to hang out on reddit with me ^^
@_date: 2016-10-05 20:25:57
That was the label associated with the invoice. If you go to  it'll generate new payment instructions and at the bottom it has a link with the invoice's label. Once you perform the transfer then the server can look up the invoice and verify that it's been paid using that label. If you paid, you'll get a cat :-)
@_date: 2016-10-05 20:23:31
The lightning node uses those funds to create a funding transaction for the channel, which is then sent to the bitcoin network for confirmation. The funding transaction needs to be confirmed before the channel is considered to have been established. If we were to provide the node with an invalid or inexistent transaction, then the funding transaction that spends the corresponding outputs will never confirm and the channel never be established, eventually timing out.
So, yes, you can give it a faked transaction, but, no, you can't build valid channel with it :-)
@_date: 2016-10-06 11:10:44
Thanks for pointing this out, ACINQ was testing on regtest, which is far less unpredictable, and they are actually using our lightningd implementation as one of their hops. It's a huge achievement to get these clients interoperable, so huge kudos to ACINQ for pulling it off! There really is no competition here, we are all collaborating and the teams are very friendly.
@_date: 2018-04-30 20:55:03
Even if it had, we couldn't have implemented it yet, because we need sighash_noinput :-)
@_date: 2016-10-06 11:16:06
Good question. We also thought that regtest would be trivial once we have regtest working, but it turns out it wasn't. We found a number of bugs and some assumptions that were wrong, specifically some things related to latencies in bitcoind nodes connected to a real network. In the video all nodes, 3 eclair nodes and one of our lightningd nodes, were connected to a single bitcoind instance, so all nodes would always see a consistent transaction history. In the real network, the blockchain can fork or node can be lagging behind so this test gave us a better view of what to expect when moving to the mainnet.
And I should point out that all teams are collaborating in shipping lightning as fast as possible. ACINQ have pulled off an incredible feat by making their client interoperable with ours, and we will be meeting in milan this weekend to see if we can work on a common protocol that all implementors will standardize on :-)
@_date: 2018-04-30 18:01:54
You can try to confirm an update transaction that isn't the latest one, but that'll give the counterparty the chance to publish any newer state, and you have just lost your fees, without getting any closer to getting the settlement you wanted confirmed. So it is in everyone's interest to just broadcast the latest state, and not waste on-chain space (for which they're paying with fees out of pocket).
@_date: 2018-04-30 19:33:06
Let me see: 1 GB * 1 Month / 10 Minutes = 4.3 Terabyte growth per Month... Yep, totally doable, now he only needs to show me where I can get that computer, I'm happy :-p
@_date: 2016-10-05 20:29:36
The first two are spot on :-)
You can do transfers between any two nodes that are connected through a path in the network, whether that is a direct channel between the nodes or a path with many intermediate hops, just like routing in the Internet works today. So you can use one channel to transfer to any reachable node, one off payments included.
@_date: 2016-10-20 12:18:08
Glad you like the sphinx implementation :-)
@_date: 2018-04-30 22:33:46
Sighash_noinput is basically a poor man's malleability fix :-)
@_date: 2016-10-05 16:38:01
Well testnet3 is not *that* bad, from time to time it is actually pretty good, and its instability is sometimes good to find edge cases and make sure they're covered.
@_date: 2016-10-06 11:35:02
Thanks :-) As you pointed out we are waiting for segwit, other than that we'd like to squash as many bugs as possible before actual money touches it and we'd also like to standardize the protocol so that we have interoperability with other implementations as well, that's how the lightning network will become truly useful. 
@_date: 2018-04-30 18:44:13
Not really, unilateral close still has a timeout during which we allow parties to submit newer update transactions to override whatever the initiator said. This also means that we need to watch the blockchain and be able to react in time before this (configurable) timeout expires. Watch towers do exactly that: if they see something they were told to react to, they'll release a canned response that enforces the agreement on-chain. They get a lot easier to implement though since we can just give them the necessary information without risking that they'd leak some information that could cost us money.
@_date: 2016-10-06 11:11:14
Maybe that's a nice someone will explore? :-)
@_date: 2018-04-30 21:26:02
Punishments can always be reintroduced at a higher level, no need to have it intrinsic in the update mechanism, where it prevents multiparty contracts with more than 2 participants and introduces the asymmetry that is so painful to manage.
@_date: 2016-10-05 19:46:19
Thanks :-)
Yeah, that last step was a bit quick. So if you go to the cat picture server ( then you see the data for the payment if you'd buy it youself. At the bottom of the page is a link with a unique random label. Once the payment is completed the server knows that it can show you the picture by looking up the transfer by that label.
@_date: 2016-10-05 21:48:25
Yeah, that's definitely needed. The good news is, we're working on it :-)
@_date: 2018-07-07 23:05:18
Hm, I had forgotten how incredibly slow max-flow algorithms are, and n^2 combinations takes a massive amount of time, will run this over night.
@_date: 2016-10-06 11:27:16
On-chain scaling and off-chain scaling are mostly orthogonal, I'd be very happy if a reasonable way of scaling on-chain is found, however years of research have shown that most of the simple fixes don't actually improve Bitcoin's scalability. So we're not putting all eggs in a single basket and are working on alternatives that may lessen the load on Bitcoin.
@_date: 2018-04-02 10:40:23
Sure, there is the wrapper Nadav wrote for charge: 
@_date: 2016-10-05 17:57:47
Thank you very much, glad you like it :-)
@_date: 2017-05-10 22:07:45
For now we have a simple gossip protocol that announces the channels and nodes to all participant in the network. This allows peers to compute routes locally, which also enables the onion routing. This should scale to a few thousands to a few tens of thousands of nodes.
@_date: 2018-04-30 19:48:15
I can't promise that this will be fast and easy, segwit has made me rather cautious in predicting how these things will be received by the community. That being said, it's a really small proposal that is hopefully uncontroversial enough so we don't run into the same issues. That, and most of the toxic people left :-)
@_date: 2016-10-05 18:30:16
For now this is just the unit of accounting internal to the implementation and once we settle on the blockchain we round up to the closest satoshi. This can be seen as a first approximation of the probabilistic payments :-)
@_date: 2017-05-12 20:20:27


There is no direct limit on the time, channels can theoretically stay open forever. However, the Bitcoin blockchain is the ground truth against which we settle. When one endpoint of a channel misbehaves, i.e., attempts to revert to an older state in which it owned more coins, we have to drop to the blockchain in order to enforce the newer state. We also settle on chain if we wish to get the coins out of a channel. There are a number of reasons to do so: our counterparty disappeared, the channel is no longer useful, or we want to create a new channel with someone else, which may be more useful for us. So we rely heavily on the bitcoin blockchain being there if we need it to, and we pay for that need with our on-chain fees.


Before actually sending the funds to the 2-of-2 multisig output, we ensure that we'd eventually get our funds back by having the counterparty sign a first settlement from that shared account. It's basically getting a guarantee to get funds back if the counterparty disappears. If it does we publish the settlement and eventually get the funds back. It is timelocked, hence the "eventually".


The individual transfers simply adjust who owns which share of the multisig, and we tally it up every time by creating settlement transaction that we do not publish, replacing them each time we make an adjustment. Only once we want to settle we publish the last tally in the form of the settlement transaction. Since it's us storing the intermediate transactions and noone else being involved we don't need to pay anyone else for the service :-)


Yes, we need access to the latest blockchain state, so we need to run at least a lightweight bitcoin node alongside the lightning node. We are careful to minimize the amount of data that needs to be stored, targetting mobile platforms, so ultimately you'll have to store something in the range of kilobytes to megabytes, depending on how many transfers you perform, and whether you route payments for others.


Bitcoin was complicated at first as well. I remember reading and re-reading the paper in 2009 because it was the only source of information. The documentation has made great progress, but it took time. Lightning is relatively new, so the resources are rather scarce, but I expect this situation will improve over time.
That being said, it is a layer on top of Bitcoin, so its complexity is added to the already quite steep learning curve of Bitcoin. Ultimately we want to make it easy to use, without having to understand the underlying technology. After all how often do you think about SMTP when sending e-Mails?
@_date: 2017-05-11 15:21:02
As others have mentioned there were a few tests that can be considered value transfers in crypto using lightning. From out point of view this is a stepping stone to getting Lightning on Bitcoin activated.
@_date: 2016-10-05 16:53:10
Oops, sorry for that :-) I think no one in their right mind would want to buy testcoins at this point :-)
@_date: 2017-05-12 10:28:00


Technically infinite is correct, as long as the channel is not settled all accumulated fees do not leave the channel and can be reused by the node that received the fees. In the example I used there were only two nodes, that were trading satoshis back and forth, the overall number of satoshis in the channel never decreases, so there is no degradation in this case. That and the final hop does not actually ask for fees :-)
@_date: 2016-10-05 21:33:56
I'll forward your request and we'll work on some more educational material. In the end we want to hide all the complexity behind a nice, easy to use, interface that just works, but we're not there yet :-)
@_date: 2016-10-05 16:14:43
Thanks, this is a big milestone for us :-)
@_date: 2017-05-12 18:52:13
Very good questions. Let me walk you through the lifetime of a channel. We first open a channel by sending some funds to a multisig output owned by the two endpoints on-chain. Once the transaction creating that multisig output confirms the two endpoints need to collaborate and decide how to split the funds up. That means that one endpoint cannot move the funds away while we are performing off-chain transfers (your last question). We perform transfers on the channel so that we either increase the amount owned by one end and decrease the amount owned by the other, or vice-versa. Now, doing transfers always between the same endpoints is nice, but doesn't get us very far. For that we have a mechanism with which we can chain multiple point-to-point transfers, into longer routes. This is similar to your Internet connection, you don't have a direct wire from your computer to Facebook, and another one to Google, and so on, instead you have one connection to your ISP, which will forward your packets in the desired direction, until it reaches the final destination. The same applies here, the individual channels build a network that connect any two participants in the network through one or more hops. So the channel may be used for transfers in which neither endpoint of the channel is actually the recipient or the sender. So the utility we get from a single channel is far higher than simply being able to make multiple payments to a single recipient, instead you may now make payments to any node that is reachable through the other endpoint (your third question).
Finally, yes we need to eventually settle on-chain, closing the channel and making the funds available for on-chain payments to the endpoints. Like the setup transaction, the settlement transaction is also on-chain, and incurs fees. So where's the advantage? Well, the fees you pay on-chain are quite high, however while the channel was active you could have sent the funds back and forth millions of times, without on-chain fees, so you for the fixed price of setting up a channel, you get to use your funds in a much more fluid manner. Think of how many fees you'd have to pay if all the off-chain transfers would have been on-chain (your first two question).
@_date: 2017-05-11 15:17:07
We have quite a few nice mechanisms that will allow to add funds to a channel, or pay out from a channel, without interrupting updates to that channel. It's out splice-in/-out mechanism that is not yet part of the specification, but will be added in the next version.
@_date: 2015-10-09 22:38:52
Well Monetas has my nomination :-)
@_date: 2018-04-30 20:07:12
We're working on the BIP on the mailing list, asking for people to give feedback and hopefully move it forward. The formal proposal is being discussed here 
@_date: 2018-04-30 22:33:11
Yep, that's the key insight: an update transaction commits to a state number, and any transaction that binds to it will check that it's state number (committed as its nLocktime) is larger than the one it is binding to. This ensures that the state numbers in a chain of updates are monotonically increasing, i.e., we move towards the latest agreed upon state.
@_date: 2016-07-03 10:25:01
You don't have to stop at a masters degree. I just finished my PhD on Bitcoin in January ( (and we are looking for interested PhD students *hint*)
@_date: 2019-05-05 08:24:48
Not really, since you are the one creating the invoice you can always pretend to have paid it without ever sending a single dime. The reason is that with invoices the proof-of-payment is done via a preimage that matches the hash in the invoice. In the normal flow the recipient generates a random preimage and tells the sender the hash of that preimage. The sender doesn't have the preimage so in order to get it, he needs to actually perform the payment. In both spontaneous send and the circular payment the sender generates the preimage, which breaks the assumption that the sender only gets the preimage upon paying.
The name Sphinx send is also a misnomer btw, since Sphinx is the name of the onion routing packet construction it gets really confusing. I guess the LL guys wanted to imply the preimage is transfered in the Sphinx packet, but it is causing quite a lot of misunderstandings. The spec always talks about "spontaneous payments".
@_date: 2016-07-26 17:38:30
Performance should not be much of a problem in this case. We are routing through an overlay network anyway, and assuming we don't take too much of a detour we do not actually add much compared to the case where we route "in the open". The far bigger challenge is actually finding a scalable way to select a route on the overlay from one endpoint to the other, or what I like to call "base routing".
@_date: 2017-05-12 11:28:47
Oh, right, sorry for misreading, there were two "infinites" in the top post ;-)
You are right of course that in realistic scenarios also LN will have to settle on chain incurring external fees, as is the case with all other systems. Infinity is just so big :-)
@_date: 2017-06-27 16:51:41
No problem, any time ^^
@_date: 2017-06-28 17:03:39


No what you need to supply is the maximum imbalance of incoming and outgoing funds that you foresee, and that's what you'd be doing anyway, since you refill only once a month. I agree that if the imbalance is high enough then it might not be sensible to use LN. LN becomes usable as soon as you have semi-regular inflows and outflows of funds, e.g., not all users coordinate to refill or withdraw at the exact same time :-)
Your very point is a good counterexample for big hubs to exist in the first place: if I have 100k users and I keep a channel open for each one of them, that's a lot of funds that I have to keep available for each channel, just for the occasional high imbalance on one of them. If however I have a few channels and connect to my users through an extended network, then I only have to keep enough funds for the sum of imbalances, which is less than having to allocate potential imbalances for all channels.
@_date: 2017-06-27 21:36:50
Funny you should say that, I am one of the implementers of c-lightning and participating in the Lightning Network specification :-)
@_date: 2017-06-27 20:51:29
Yes, a node needs to set aside some funds for each channel, and that means that well connected nodes either have tiny capacities on those channels or they have large amounts of funds online.
However, let me flip the question and ask why we'd need big hubs in the first place? There is no intrinsic value in operating a large hub, since the amount of funds you need to put aside, and the risk of a loss, increases almost linearly with the number of channels. Big hubs suddenly become very attractive targets for hacks, whereas nodes that just opportunistically open a few connections within their local cluster are unattractive. Commonly people mention that hubs collect fees, however the amount of fees you can earn is much more in function of how many transfers you facilitate and not how many channels you have. A small node that has two strategically important connections (bypassing a high fee cluster) can earn a lot more per coin than if your strategy is just to open hundreds of channels. And it is this strategic placement which I hope small nodes will engage and drive the network diameter down, while at the same time providing fault tolerance and decentralized routing.
Now, this is just me speculating, but so is everybody else until we see what really happens and how the network forms.
@_date: 2017-06-24 13:05:08
For a long time I shared this believe. In order to evolve the protocol hard-forks seemed to be the only viable way. However, I have since changed my mind, seeing how disruptive these changes are.
Take just the end-users for example: a hard fork, by definition, forks the network into two branches, one accepting the new rules, and an old one that did not upgrade in time. So if an end-user, that might not be following the bitcoin ecosystem closely, deferred upgrading his wallet he'll be forked off. This is incredibly hard to convey to end-users. Just think about how many routers out there use the default password. Now try to explain to these users that their coins are actually split, and can be spent on both chains, _but_ due to replay attacks the coins may actually be automatically spent on both chains simultaneously... It just makes for a terrible user experience, and will likely erode the confidence in the currency itself. Being tech-savvy should not be a requirement to on-board users.
Soft-forks on the other hand allow us to perform upgrades without splitting the network, allowing users to continue using their favorite software. This is particularly true for hardware wallets, which may not be able to update at all. These upgrades may be a bit more involved since we need to keep backwards compatibility in mind, but they offer a similar level of flexibility, and SegWit is a great step towards extending this flexibility with its versioned scripts, effectively making all future script changes soft-forkable.
Obviously this is just my personal opinion, and I can see quite a few compelling arguments for hard-forks, but trading backward compatibility for "simpler" upgrades is just not a trade I, and many other bitcoin devs, feel comfortable with.
@_date: 2017-06-27 16:37:55
Yes, the scripting language used by Bitcoin to set up the spending conditions contains some flow control primitives, notably `OP_IF` ( and we can build a whole bunch of interesting conditions. The important part here is that we can only increase the spendability, not reduce it. With this I mean that the timelocks allow us to invalidate some branches until they expire, but we cannot remove the ability for someone to spend after a timeout.
This also leads into the second part of your question: technically, yes, we'd need two transactions to close a channel, one initiating the timer and the second one to transfer the funds to a singlesig address. However, if we did not misbehave, and give the other party the revocation key, it is safe for us to keep our funds on the if-else outputs for as long as we want. So if our wallet understands that these are our funds we can defer spending them until we actually need them. So the claiming of the timelocked if-else funds can be a new setup, or a classical on-chain spend, or whatever you want to do with them. We don't need to move those funds somewhere else just for the sake of it ^^
@_date: 2017-06-24 10:26:58


SegWit was intended to be a compromise: it not only includes a number of fixes and features desired by Core devs, but it also included a soft-fork blocksize increase. The effective blocksize increase admittedly depends on what type of transactions are included in the block, but even conservative estimates expect over a 1.7x effective capacity after segwit is activated.
This compromise character is also reflected in the 95% threshold: this was expected to be unanimously accepted, but apparently the blocksize increase was not communicated effectively and miners saw the possibility to bargain for a further increase, making this whole thing very contentious.
What I'm saying is, please don't misrepresent segwit. Segwit is _a_ compromise, but apparently not the compromise the miners were asking for.
@_date: 2017-06-29 14:48:15
Simulations can only ever be as precise as the basic assumptions you make when writing the simulation, for example, how would you assume users to join the network, with whom would they open channels and what would the reliability of an individual node be? Depending on how you chose these, still very simple base parameters, you can create a system that either creates an random topology, completely centralized system, or a hierarchical network, and all of them would have very different outcomes. We could discuss for years what the real parameters are, or we could just see what happens, and I much prefer the latter.
@_date: 2017-06-24 13:59:01
All guarantees of Bitcoin stem from the simple assumption that there is no single entity controlling more than 50% of the computational resources for a prolonged period. If you throw out that assumption, as you do with the Paypal buying in example, all bets are off, and we can not make any guarantee whatsoever. I know it's a sad thought, but that one assumption is what underpins the entire system, that includes the antifragility and censorship resistance. Should you ever have a single actor, and it may not be the case that this is evident, since a single actor may masquerade as a number of actors, there is no way to recover from this state, not through soft-forks and not through hard-forks. On the bright side, all of the scenarios you list, can only ever happen if all miners collude to either enforce KYC or the censoring, by not processing those transactions and by not building on top of blocks that do not adhere to that policy :-)
As for being the sole upgrade mechanism, that simply isn't true, as demonstrated a number of times by soft-forks deploying incremental improvements in the past.
While I agree that many users will rely on SPV wallets or custodial services, it is IMHO one of Bitcoin's central value proposition that we give end-users the possibility to participate without intermediaries and with full auditability in the processing of transactions, even if they choose not to make use of it.
@_date: 2018-12-03 00:02:01
Check out my list (based on Brett's list but with newer papers): 
@_date: 2017-06-28 11:24:03
The spec contains all the gory details, and are probably not the easiest to read (and I say that being one of the culprits that wrote those docs) :-)
@_date: 2017-06-27 16:16:11
This is true for simple `nlocktime` based timelocks. For L2 solutions based on them we had to make sure that the settlement was initiated in time to react before the locktime expired.
This is no longer necessary with CSV, now we initiate the time delay by committing the transaction itself to the blockchain. So take the unilateral close of lightning for example: the settlement transaction that a unilateral close commits to the blockchain has the funds either going to the initiating party (after the timeout) or the other party (if they have the `revocationkey`). Only once the settlement transaction is committed in the blockchain does the timer start to tick. Now the other party has time until the timelock expires to grab the coins (this is the case that the settling party misbehaved and published a revoked state), and after the timeout the settling party can get its funds.
The takeaway here is that the misbehaving party may only collude with the miners if the miners are happy to mine a fork for the timelock duration, but at that point we're in deep trouble anyway, because that fundamentally contradicts any security assumption we have about on-chain payments as well :-)
@_date: 2017-06-29 14:40:08


This would be the case if both hubs were operated by the same entity. In this case the hub-hub connection replaces the need for either of the hubs to come up with the funds to establish 500 connections, i.e., the added utility by extending the network's reachability through that single channel is much higher than if it were just another enduser connection.


Funds on that bridge channel are far more likely to be balanced since random events on either side tend to balance out, large deviations due to natural churn are unlikely to happen.


True, more hops also mean that more people can ask for fees along the route. However, and this is the central point why I dislike hubs, if people were just connected to a single hub, then that hub could ask for exorbitant high fees, and why wouldn't he? This is why a redundant network topology is necessary: to keep nodes honest in what they ask in fees, and to remove any single point of failure (and to keep transfers private, by routing through multiple non-colluding hops). I think that more hops does not necessarily equal more fees.
@_date: 2017-06-28 14:39:05
The problem with simulations is that these systems are far too big and have far too many unknowns for a simulation to work, or have any predictive power.
All I can do is to explain the rationale behind the design decisions we are taking and speculate about their impact on the overall system. I try to be clear about our expectations and why we believe they might turn out to be true.
What I cannot deliver is absolute certainty that a scenario is the only possible outcome. Then again this is true for everybody, and if somebody claims that otherwise, then they are probably basing that speculation on a far simplified system.
@_date: 2017-06-24 10:41:09
True, the increase is solely for segwit txs. Then again segwit transactions have the same features (but more importantly, fewer defects) than non-segwit transactions, so there is no reason to continue using non-segwit transactions (except for backward compatibility). The increase through segwit was also necessary since it is what made the whole thing soft-forkable in the first place. I think that giving users a nudge to upgrade their software in order to take advantage of the new features is more than justified, as long as nobody was forced to move.
Notice also that people who started using segwit benefit the community as a whole, since they now use less of the legacy space, which can be used by non-segwit transactions.
@_date: 2017-06-24 11:46:21
Yeah, that's the core of the entire discussion: some people want a signal that the community is happy to kick the can down the road in the future, by simply increasing the blocksize whenever we come near the current capacity. While the other side of the discussion is afraid of creating just that precedent, i.e., that performing a hard-fork now could be taken as an excuse to do the same in the future again.
The fear in that case is that doing a hard-fork becomes the go to option to change things in the future. The problem with that is that hard-forks are very disruptive, and reduce the relative stability, technology-wise, that vendors could rely on in the past.
I think both sides have good arguments, but at some point we need to agree on a solution, that is acceptable to all parties, which is really hard for such a diverse community.
@_date: 2019-05-05 08:18:57
Just leaving this here  ��
@_date: 2017-06-24 11:08:17
There is not a lot opponents of LN could do to block it. The funding and settlement transactions are simple multisig transactions, and cannot be differentiated from non-LN transactions. The unilateral close transactions are a bit different and they could be delayed, but as long as some portion of the mining resources do not actively censor them, we can adjust the channel parameters to make them secure again (with considerable longer lock times, which aren't nice).
As to the motivation for actually blocking LN, it is often assumed that LN will reduce the fees that go to miners. This is false in my view. LN is an aggregation layer on top of Bitcoin, we aggregate millions of transfers and commit them as a final settlement to the blockchain. While the individual transfer is very cheap, the sum of all fees is considerable, and will be used to ensure that the settlements are confirmed by miners. Unlike classical Bitcoin transactions, LN depends on its transactions to be confirmed in a timely manner, since otherwise old states could be committed. So LN settlements transactions have large fees attached (c-lightning currently uses 5x the fee estimate), making them very attractive to miners (these fees are paid by millions of LN transfers).
So all together the miners need to do less work since they now only need to confirm the validity of the aggregates of transactions, not transactions themselves, and they earn more fees for the individual transactions, due to the time sensitive nature of LN transactions. I'd say that's an overall win :-)
@_date: 2017-06-29 14:20:23
Routing is indeed one of the hard problems we will eventually have to solve. As it stands now we have taken a simple approach, propagating network topology information to the endpoints, which allows the endpoints to select a route to the desired destination offline. This should scale to the first million or so users, with moderate hardware requirements (see this [article by Rusty]( on the topic). Beyond that there are some ideas on how to improve the scalability, including beacon based routing protocols from mesh networking, and switching to a system similar to how IP is routed in today's Internet.
So while this is not a solved problem, we still have some time to solve it, and we have some ideas on how to solve it. We're just concentrating on getting the simple network to work first, after all, the routing problem because we have too many users is a nice problem to have :-)
@_date: 2017-06-29 17:22:16
I try not to contradict people outright, however this is simply not true. The probability of deviating from the expected value by a given amount decreases exponential with the number of experiments, assuming that the experiments are i.i.d.: 
More precisely the sum of individual events, which gives the total imbalance at any point in time is a random variable that follows the Chebyshev Inequality which gives a bound that is proportional to 1/n^2 (unlike your claim of 1/n^(1/2)).
@_date: 2013-12-09 16:49:32
Finally some good news on this front.
@_date: 2017-06-24 14:02:01


I'll just leave this one here: 
Note: it's very hard to gauge the various stances of participants, this is one attempt, hopefully we can further back this with references to first hand statements.