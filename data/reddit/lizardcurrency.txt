@_author: lizardcurrency
@_date: 2015-06-22 19:01:37
Heard of sidechains? Lightning?
@_date: 2015-06-23 02:50:15
That was a good dodge, but you still haven't answered the question. Is Bitcoin *not* a success in your opinion if everyone in the entire world adopts Bitcoin, but they have to use Coinbase?
A big part of why people are into Bitcoin is they don't trust inflationary government currency, sometimes because their government currency is crashing. Coinbase is night and day better than inflationary government currency in certain cases. It's really night and day, regardless of KYC or their continual violations of user privacy.


Then at worst, it's only necessary for those people using centralized services to submit to KYC/AML over the short term. Lots of people voluntarily do it already, because the benefits of centralized Bitcoin exchanges make giving up privacy worth the sacrifice. As technology progresses, block size will increase until everyone can fit on the chain, using a full node and owning their own private keys.


A 21 year stretch in history is a figment of a figment of a particle of sand. Over a 200 year stretch, I'm 100% confident block size can see megasized upgrades, but why does it have to be bloated *now*? Why aren't you willing to take it slow? What gives you this level of confidence in Moore's Law?


There is already evidence to the contrary. Bitcoin companies like ShapeShift.io are already outsourcing their full nodes to BlockCypher.
Don't tell me you're now claiming you know how future peoples will spend their money. Heard of Tragedy of the Commons?
@_date: 2015-06-22 19:12:04
The LN authors claim it could handle the entire world's transactions with 200MB blocks... what does that say about 8GB blocks pushed through by contentious hard fork? It's beyond overkill and a completely ill advised decision that gained steam based solely on a PR campaign.
@_date: 2015-06-22 17:28:22
Because surely no Bitcoin promotional video has ever embellished or misrepresented the facts.
Heck, next you'll tell me penny stock pumpers want me to buy stocks that they own, without necessarily disclosing that they own them. Are you to tell me the information I read on the internet isn't 100% true to reality, or embellished in any way shape or form?
@_date: 2015-06-22 18:38:07
"Nobody goes there anymore, it's too crowded"
@_date: 2015-06-23 03:00:28
Another dodge of the original question, plus an ad hom? Bravo, now please answer this simple question:
**Is Bitcoin *not* a success in your opinion if the entire world adopts Bitcoin cold turkey tomorrow, but has to use Coinbase for some interim number of years?**
@_date: 2015-06-22 19:32:25
Umm, Conformal Systems [studied the technological limits of block size]( and found that, with a cluster of 10 high performance Bitcoin servers, the absolute brink of what is achievable with today's hardware is 320MB blocks - **with a cluster of 10 servers**.
Do you agree that the future of full nodes should be computing clusters?
Are you prepared to run 10 servers of your own in a cluster just to run a full node?
Who do you think *is* prepared to run 10 servers in a cluster just to run a full node?
Since 10 clustered servers *barely* handle 320MB blocks with today's hardware, what makes you think 8GB blocks is in any way shape or form *conservative*? What are you basing your performance calculations on?
To be frank, I'm not sure if any good solution exists for the question of how to handle determining block size. If it's determined by running full nodes, and the nodes that are run are gamed by resourceful companies like BlockCypher who have a vested interest in seeing more of the community become dependent on their services, voting for the largest blocks possible this time, makes it harder for their opponents to vote in the future.
I'd say if we're going by a game-able voting system such as this, there's little practical difference between it and voting on block size by proof of stake. Just give the most votes to the largest Bitcoin holders. It's troublesome for all the same reasons.
@_date: 2015-06-22 18:52:20
I perfectly understand where you're coming from, the more people who own their private keys, the better. But Conformal's research used a set of 10 clustered high performance servers which *maxed out* at 320MB blocks. If it in fact *actually took* 8GB blocks to do what you're saying, we simply couldn't handle it. Technological progress is slower than we might like, but the world doesn't revolve around Bitcoin.
@_date: 2015-06-22 17:50:39
[Scarcity]( is one of Cialdini's six principles of influence, and it's very time tested (just ask anyone selling IPOCoins).






Because full blocks lend credibility to the threat of losing out on faster confirmation times if adequate fees aren't paid, users will be more likely to pay a higher fee than they would if blocks weren't full. If blocks are continuously full, users must pay a higher fee to see their transaction included within the next block.
@_date: 2015-06-23 02:28:06
That's very debateable. If the entire world wanted to switch cold turkey to Bitcoin tomorrow, by your own standards you'd have to consider that a failure? They would all have to use Coinbase or Circle, and wait many decades until they could afford the immeasurable fees to justify exiting the centralized service. Is that still a failure mode to you?


Other than losing nearly all the full nodes on the network if you're wrong about Moore's Law? Just the ability to run full nodes as easily as you run SPV wallets today without freaking out about multiple hard disks or possibly even clustered computing. It may just matter what an engineer thinks of your currency's resource requirements in 2050, whether or not it's a bloated hog could matter a great deal.
@_date: 2015-06-22 17:15:15


Sigh. So we should increase block size limit to 8GB today? Scaling problems solved!
Oh wait, current hardware can't support 8GB blocks today. So what *can* be safely supported? According to [Conformal Systems]( ~320MB blocks are the absolute technological *maximum* that could be processed today, and that ONLY with **10 clustered servers**. Does that not sound *fatal* for adoption of full nodes to you? Are you excited to set up not 1, not 2, not 5, but 10 servers in a cluster just to field the world's transactions?
@_date: 2015-06-22 18:06:59
Because I'm not invested in Litecoin, and don't want any?
Your question is telegraphing to all you're invested in Litecoin and want to pump it, and regardless, your question is like asking why don't more people use BBQCoin for tipping since it's so much "cheaper" than BTC. When no one actually knows WTF BBQCoin is, that you can send 1 BBQCoin to me for a fraction of a cent counts for *nothing*.
@_date: 2015-06-22 19:57:59
Gavin says in the BIP:


If exponential growth in technology "cannot continue forever", what makes you so confident that it's going to continue for the next 20 years?
What are you basing your predictions for the future on?
Why do you feel *your* predictions have any more meaning to the future than anyone else's?
@_date: 2015-06-22 17:04:36
If the unconfirmed transactions can sit in RAM, they can be cached to the hard disk instead. Then the attack vector becomes more similar to flooding servers by filling up the /tmp partition with huge logfiles.
@_date: 2015-06-23 00:48:26


Engineers write the software at those "billion dollar" institutions.
Do you think it *might* be important whether you're enraging engineers a little bit by taking the default stance of throwing as much data at them as possible when they run full nodes? We shouldn't be striving to match new waves of technology with more wastefulness. That's like, why certain websites made in 1999 load quicker than the slough of ridiculously bloated client-side JS sites of today. Don't forget Google deranks slower websites in the listings. I'd be shocked if in 2050, cryptocurrencies aren't compared with "Resource Hog" being chief among engineer complaints.
How about you point out a single company doing multi-disk archival of the full blockchain? At a certain point, the full node becomes so unwieldly that full node users are an urban legend. You might think that's a good thing, and you'd be wrong because engineers aren't average users, and they decide what gets run on the backend at most companies.
Moore's Law sounds *really* good, but that's the most you can really tell me, isn't it. Because it's impossible to give me any strong guarantee that SSDs will be 10,000TB before 2036. You just can't give me that guarantee. Just want me to believe you based on all the groupthink and politicking running rampant.
Do you think engineers aren't people? That these people won't prefer trustlessly interfacing with cryptocurrencies that sync faster, completely reliably on any current hardware? Has it occurred to you that engineers won't *want* to do multi-disk backups just to run your product?
All of you by being in favor of big blocks at all costs are fundamentally agreeing to full nodes requiring a tremendous effort to maintain, like performing multi-disk backups. You counter with, "no one will ever run a full node". It's like hitting someone in the face and telling him "you're bleeding". We know why people don't run full nodes! It's too costly. Don't tell me your solution is to make it even *more* costly.
Finally, all of you by being in favor of big blocks at all costs are fundamentally agreeing to full nodes being done by clustered computing, because if you're wrong about Moore's Law, and people adopt Bitcoin XT by the billions, that's what will have to happen. Since the demand would surge beyond what any miner would ignore, blocks would just absolutely soar to that size whether or not it's technologically feasible for keeping up without a cluster of 10 servers. And the best you can do is point me to opinion leaders making logical *and informed* guesses about the future? How about this risk isn't worth taking when there's no crisis?