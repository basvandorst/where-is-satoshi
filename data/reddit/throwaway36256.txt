@_author: throwaway36256
@_date: 2016-08-01 08:13:54
It would be beyond stupid if they keep the vulnerability open 1 day after it was made public.
@_date: 2016-08-29 19:36:37
Bitcoin is not supposed to be reliant on miners being altruistic. No one knows when one of the hostile actor manage to gain significant amount of hashing power and started to abuse it (remember GHASH.io?)
Besides, SPV mining depends on attacker transmitting headers first which is not guaranteed.
@_date: 2016-08-06 03:06:56
ETC is the property of ETH holder before the fork. If you don't hold ETH in exchange before the fork you have no right to ETC. If you send ETH post fork without sending ETC the exchange shouldn't send you ETH+ETC.
@_date: 2016-08-22 04:32:54




I suspect we will see sidechains first. CT added too much bloat to be approved in mainnet.
@_date: 2016-08-01 16:19:12
2 years? LOL. How do you even remember that. Remind me not to make an enemy of you.
@_date: 2016-08-06 12:40:21


Yes, but you still have a valid claim to the ETC.


I don't think people ever claim total insolvency, only ETC insolvency (which could lead to total insolvency if ETC price continues to rise).


People lose money. That's the point. Doesn't matter who. Ideally, no one should lose money in a properly executed hard fork.
@_date: 2016-08-06 09:05:46


Everyone is aware now that it reaches 10-20% of ETH.
I think you need to rethink what I say. Deposit ETH only, withdraw ETH+ETC. Free money. Is that how it's supposed to work?


So if you put Bitcoin into exchange you can't withdraw your own Bitcoin? 


Yes, in a stock split you can sue your broker if they don't give you access to other split.


How does that even work when all other exchange are already listing ETC. 


They are mad because the ETC is rightfully theirs.
@_date: 2016-08-06 03:10:49
As can be seen from Ethereum hard fork anything that has probability of happening (replay attack in case of ETH) must be accounted for. He was not talking 4MB in terms of effective transaction capacity increase he was talking about 4MB in adversarial scenario.
@_date: 2016-08-29 17:14:11


Have you ever heard of quadratic hashing? Miner can gain advantage over other miner by spamming cheap transaction that takes a long time to verify. Classic works around this by introducing limit on # of bytes/transaction. The reason why Unlimited forks off of Classic is because they didn't implement this limit. 
But you don't like limits right? I mean what if this limit hinders smart contract functionality? That's why Core implements Segwit first. It is so that we can limit # of bytes/tx without hindering the script. This is the kind of long term planning that we need.
@_date: 2016-08-02 08:29:00
I think PoS has other vices that is seldom discussed:
1. As can be seen from NXT, Vericoin, and latest Ethereum hack obtaining a large amount of coin can be pretty trivial. Obtaining a large amount of hashpower is not so trivial.
2. I personally find the balance of power between developer, mining power, and economic power is quite beautiful. It forms Montesquieu's tripartite system of legislative, executive, and judicative. Had Bitcoin been under PoS I suspect there would be much more chaos. Right now mining power provides balance between the developer and exchange/payment service. Of course it doesn't stop economic power from acquiring mining service a la BTCC but normally the skillset doesn't intersect.
3. I believe in cooperative model like Casper there is higher tendency to form cartel than in PoW
With combination of (2) and (3) I'm not sure how consensus formed with PoS would be better than traditional financial system.
@_date: 2016-08-05 10:11:33
I was going to ask you to read the description on asymmetric and symmetric two-way peg but then I read this on Federated peg part:


I guess you're right federated peg is still considered a two way peg. Funny that the document doesn't give an official term on what to call SPV peg.
@_date: 2016-08-29 19:37:35
Headers first doesn't work well when the block rewards goes down. Not to mention when doing headers-first you can't add your own transaction so what's the point of producing a block?
@_date: 2016-08-04 22:44:39
Two way pegged sidechain requires Bitcoin's miner to verify sidechain's block header. Currently Bitcoin doesn't have this capability. Federated sidechain use multisig as a replacement to that so instead of trusting the miner you are trusting the multisig holder instead.
@_date: 2016-08-06 03:17:05
This is why sometime people just doesn't have knack of thinking adversarially (please note that I am not making an insult of you sometimes I am also not very good at it). Let's say someone send exchange ETH only (e.g from mining reward or by properly splitting post fork) and then this particular someone withdraw the ETH from exchange and the exchange send them ETH+ETC. This person has no right of the ETC. It is the property of whoever is holding ETH in the exchange prior to fork.
@_date: 2016-04-19 08:03:00
Bob is the bad guy? **GASP**.
I thought usually it was Eve or Mallory. j/k
Anyway congrats to Shapeshift for providing closure to the case.
@_date: 2016-08-24 11:20:28


Not totally true. For example Mimblewimble eliminates the need for archival node. Pruned node=Archival node. Signature aggregation will also help (although I haven't seen the detail whether this is enough to counter CT use).
@_date: 2016-08-05 00:14:46
I'm just using the definition in 
In two way peg section SPV proof is always required. There is a separate section for Federated peg. You can define pegged as having SPV proof of another chain so in a way Federated peg is a one-way peg.
@_date: 2016-08-29 20:20:53




Does not compute


And by mining headers first you make the DoS block much deeper. When initially only 1 miner needs to orphan the block now you need two miners instead.
@_date: 2016-08-24 00:40:20
Open terminal-&gt;Go to your newly created folder-&gt;run ./Copay
@_date: 2016-08-29 18:04:56


Unfortunately most miners is not qualified to do so, as can be seen in testnet fork.


So how exactly do you propose to address quadratic hashing? Choose to mine your own block if it spent too long verifying a block? You still waste time (depending on your timeout period) doing that. Not to mention risk of causing re-org chaos.
@_date: 2016-04-08 14:06:58
I don't think he requires any change to Bitcoin itself, so probably it won't require a BIP. What he wants is a review of the protocol, so bitcoin-wizards 
@_date: 2016-04-01 18:13:09
It is much closer than you think. Those actually developing knows that we are pretty close to that. Yes we probably will need blocksize increase for the next 1-2 years (or maybe 3-4 if you are being cautious). But after that Lightning should be ready. We can get there much faster if major industry player contribute.
@_date: 2016-04-03 22:53:04
Basically when you write the script you wrote the whole program but don't tell anyone what it is, only 'proof' that you wrote the program. When you actually 'run' the script you 'reveal' only the the branch that actually execute leaving the other branch remains unknown.
@_date: 2016-08-09 18:32:41


I believe Brian Armstrong mentioned that a couple of month ago.
Not sure if that's the all the reasons though.
@_date: 2016-04-03 22:07:05


MAST only works because Bitcoin script is stateless. Implementing MAST on stateful chain is not so straightforward.


Why would these run on chain? There is all sort of privacy risk to do this on chain. It is more rational run these off-chain where a secure channel is possible.
@_date: 2016-04-01 16:30:14
I see no reason why it shouldn't. The concept is sound. Even the most prominent critic John Ratcliff agrees to that:
@_date: 2016-04-06 21:22:43
Actually you do because you also need to verify that blocks that are older than the hard fork block is valid when you are bootstrapping a new node. 
@_date: 2016-04-01 16:07:54


The idea is that they should contribute to the effort by committing to it, and not just simply wait for other people to release it before using it. Personally I think this kind of commitment is necessary to show that everyone is in the same boat. There are a lot of problem to be solved in Lightning but they are not insurmountable. If the industry agree that Lightning is the way forward Peter Todd would be more willing to compromise. I think it is a fair deal.
@_date: 2016-04-21 08:48:01
I wonder if it is feasible to construct a SNARK circuit to prove permission verifier's private key and set up a ZKCP bounty for a leak. That would be fun...
Anyone familiar with both EPID and SNARK?
@_date: 2015-06-08 23:06:07
Again it is a bit political here, but basically Luke-Jr thinks that Bitcoin blockchain should be used solely for transferring Bitcoin. Other uses like colored-coin, counterparty, or factom is borderline spam.
@_date: 2015-12-20 00:18:10


But they CAN. Inclusiveness is an important feature. I would say that if that if there is no ASIC miner-vote is good since everyone can use their CPU to vote but currently this is not the situation


Too much power. The incumbents has the incentive to keep the block size low to get better price even though the economic activity has gone up. Smaller miner with better margin that wants to alleviate the situation by producing bigger blocks will not be able to do so. It is important to share the power between economic and hash rate power holder.
Also see the inclusiveness part above.


Once implemented we will have adaptable limit. No more need to fork (hard/soft) for any kind of circumstances.


The variable is an important security variable. In the long term I believe a hard-coded limit needs to go so that we don't need to fork anymore.
@_date: 2015-12-19 22:18:00


These custodians can provide a way to prove that they vote according to their 'constituents' (they can hold internal 'election' if they want), the method is quite similar to proof-of-solvency. If people don't like them they can move their coins during the next voting period.


They already can determine soft limit, asking them to determine hard limit is a little bit reckless.


It is generally hard to count the number of node operators that is resistant to sybil, that is why we need PoW in the first place. Node operators can vote, provided that they hold Bitcoins. 


idea below is also quite interesting.
All in all, I believe the complexity of these kind of solutions will probably prevent us from deploying them during the near crunch.
@_date: 2015-06-12 23:20:01


How is that decentralized? Tens of Thousands of company each getting a slice of the pie is decentralized
@_date: 2015-12-19 04:25:19


This is not true. Irregardless of how true the statement is today, Satoshi was hopeful that one day storage/bandwidth would enable us to get into micropayment level.
@_date: 2015-06-13 12:04:54
Actually the more I think about it the more I like jdillon's proposal. The problem is whether we can implement this on time
@_date: 2015-06-12 21:07:03


Uh, no. If your node says the block is invalid you will reject every transaction in it (even if it might causes you to be in a fork). If a significant number of full node says a block is invalid the miners won't get their revenue. Some fullnode (e.g exchange's, Coinbase, Bitpay's) are more important than the other though.
@_date: 2015-06-12 23:37:30
jdillon's idea is excluded vote is counted as status-quo so the miner won't gain anything by excluding it (unless of course they are for-status-quo, but that doesn't change much from current condition).
@_date: 2015-06-13 00:38:29
Perhaps I'm not getting myself clear. People vote weighted by UTXO. Of course miner can vote. But unless they have a significant amount of Bitcoin their vote won't matter. This is the proposal I'm talking about:
@_date: 2015-06-08 23:14:30


What kind of usage are we talking about? I'm using libbitcoin fullnode as a replacement for Bitcoin Core and I'm pretty happy about it (sync time is horrible though, because no header-first).
Edit: Seems like Coinkite is also pretty happy about it.
@_date: 2015-06-13 21:21:58


I think it is much fairer to give power based on economic size than hash power. Which is why I'd rather have jdillon's pos (petertodd's favorite) in voting for block size. The downside is complexity. If you favor simplicity 20mb is better because full node can still chose what they want (of course in the it will still be determined by economic size with coinbase/exchange/bitpay leading the pack).
@_date: 2015-06-13 18:34:47


I'm not talking about who gets to profit from the internet. I'm talking about who gets to provide and receive information to/from the internet. With the advent of tor/vpn/wikipedia/blogs etc. everyone can send/receive pretty much unlimited information. ISP cannot block anything.


If you look at my post I'm actually pro-20mb increase :). It's just that I want to remind other extreme pro-20mbers that we are losing something in the process. A 3-way split of hashing power is not something that we want.
Edit: Just to further clarify I'm pro-20mb but I'm against BIP100 solely because it took the power of full node away and give it to the miner.
@_date: 2015-06-08 23:18:54
Well, if these are considered spam, then we are not as near to the 1mb limit. We can just consider it spam and don't mine on it/don't relay them
@_date: 2015-06-13 00:20:59
They can't if they have to sign it with the related private key
@_date: 2015-06-13 00:49:58


Oh there are... Every country has one. Let me rephrase my statement. How is that more decentralized than what we have now? And if it is not what is the purpose of Bitcoin? 


Well internet manage to revolutionize information decentralization. It's about time we expand that revolution
@_date: 2014-07-25 23:55:08
Bitcoin protocol is quite flexible. Actually there are quite a few of work in progress built on top of Bitcoin


Bitcoin equivalent is Dark Wallet. Right now the mixing is still centralized but I heard the developer plan to have decentralized mixing in the future.


Bitcoin equivalent is Open Bazaar/Counterparty.


I believe this can be implemented with a gateway. An example implementation is 37coins.
 Hell we have people transmitting Blockchain through DVB-T
and even satellite:
Can't really say there is no innovation there.
@_date: 2014-03-03 12:19:05
I think he was talking about the denomination. Singapore notes are denominated in $2, $5, and $10 a piece. What he is saying is the ATM doesn't accept $50 notes (and above) yet. So you could only buy limited amount for practical consideration.
@_date: 2014-07-19 20:54:36
Guys, are we watching the same video??
I am going to attempt to transcribe the what he said.
(Audience ask about hard limit on 21 Million)


@_date: 2014-05-08 04:28:37
I think some of it is practical consideration. Grover's algorithm doesn't offer that much speed up over classical algorithm (O( N^1/2 ) vs O(N)) and it's not yet realizable. Blockchain bloat on the other hand is very real (compressed public key can help on this).
@_date: 2014-04-14 21:36:51
I don't think it is going to work. Blockchain.info already see the transaction: 
Even blockchain.info will not relay transaction whose output already spent (i've tried this before). 
An alternative would be contacting eligius:
But I think they also already saw the transaction. Not sure what is their policy on double-spent. OP will need to know how to create raw-tx though because he is only who has the private key to sign for higher fee tx.
@_date: 2014-09-25 13:32:06
Any response from bc.i yet? They will need to stop attempting to propagate the tx for it to expire. 


If you know how to code you can read isStandard() function in Bitcoin source code (I am not really familiar with that) and see which input is failing the test.


Well, it doesn't hurt to try. You will need to use non-bc.i wallet though as they already see the transaction (import privkey from bc.i) . I know Bitcoin-qt has a knapsack solver where it will choose the appropriate input. Just try to spend less than 0.22 and they should include only those 2 (I think). Not really sure about other wallet.
@_date: 2014-04-05 05:09:21
Guys, seriously what's wrong with all of you?? and are participating in meaningful debate down below. Why all the downvotes?? All the points are valid and no one is trolling...
@_date: 2014-12-29 01:33:47
The answer is some people do buy and sell coins for profits and not simply for expanding the economy. The first question to answer is where do the person selling bitcoin at localbitcoins.com get their bitcoin in the first place? For the kind of volume you regularly see at localbitcoins.com it is unlikely that they get their coin from the miner. So it is more likely that they get their bitcoin from exchanges like the one mentioned by OP. To gain profit they will need to mark up the price. 
As for being greedy if there is demand there will always be supply.
@_date: 2014-12-17 04:17:14
Well, the standard is open. Everyone can implement their own version of it. If in the future everyone doesn't use this standard anymore you can still ask someone with programming skill to decrypt it. If you are really paranoid you can just save the software/online webpages source and store it in portable hard drive/cd/dvd-rw/thumb drive and store it together with your paper wallet
@_date: 2014-11-26 13:53:30
You can try walletrecoveryservices.com or paging Quite a number of users recommend him. Example:
@_date: 2014-02-07 06:23:25
I am going to quote from a specific section from 7/2011 (translated via Google Translate):
1) Rupiah must be used in: 
a. every transaction with the payment; 
b. solution other obligations that must be met 
with money and / or 
c. other financial transactions 
performed in the Province of the Republic 
Indonesia. 
(2) The obligation referred to in paragraph (1) shall not 
apply to: 
a. particular transaction in order to implement 
estimates of income and expenditure of the country; 
b. acceptance or the grant or grants from outside 
the state; 
c. international commercial transactions; 
d. savings banks in the form of foreign exchange, or 
e. international financing transactions.
I think (2) is where the use of Bitcoin can be legal.
@_date: 2014-12-20 04:21:05


It actually does make sense. It makes sure that every data point in the chart represent 24 hour period. The first data point in your chart would represent less than 24 hours because technically Bitcoin has not been invented prior to that so it's not apple-to-apple comparison between 1st 24hours and 2nd 24 hours. It shouldn't make too much difference in the long run. I'd really wish we could stop nitpicking over this. The bigger picture (e.g trend of averaged transaction) should be more important.


I disagree. They are free to use whatever time they like. 
@_date: 2014-09-10 19:37:50
You can request bc.i to send backup wallet regularly through mail. The guy already have the backup wallet at hand (protected with previous password or not protected at all). When you transfer the LTC he will immediately move the btc.
Edit: Maybe for Justice Porn you can move the BTC??
@_date: 2014-09-23 08:48:18
Looks like most nodes haven't seen them. Since you know how to craft raw tx maybe you can just do a double-spend using only the two highest input (the one worth 0.12 and 0.1 btc). You can paste the raw tx here again for everyone to broadcast. I am suspecting some nodes reject it because they consider it as dust.
@_date: 2014-11-01 22:19:34
Basically they're using OP_RETURN to create a 'record' in Blockchain. Basically you can embed 40 bytes of data inside a transaction. Counterparty uses this to record events such as 'create asset', 'send asset', 'create limit order' etc. By tracking these individual events you can keep track of the movement of each assets. You can take a look at  for more detail.
@_date: 2014-07-24 23:27:37
Well, to be fair we also need to prepare for the increase in TPS (transaction per second) caused by mainstream adoption. To reach Paypal size the increase would be ~100x, ~10000x for Visa size (source: 
There are solutions such as blockchain pruning or Peter Todd's treechain but both of these method sacrifice something else for scalability.
@_date: 2014-06-17 10:06:25


Not true. The fee is to prevent spamming by malicious party. Google Enjoy Sochi. If those transactions are getting confirmed the Bitcoin Network will get jammed.
@_date: 2014-10-09 13:25:31
Well, there's nothing stopping them from issuing user-defined assets (Phillipine Peso) using colored coins or counterparty. I'd say it is still valid uses of Bitcoin. People are free to exchange their peso-coin to Bitcoin depending on certain exchange rate.
@_date: 2014-04-24 04:50:29
I think he is referring to this:
Also I don't think Cloudhashing is related to Ghash.io/cex.io
@_date: 2014-05-08 09:58:50
Actually cracking private key from public key is much easier from quantum computing perspective (Shor's Algorithm) as compared to finding public key from hash (Grover's Algorithm)
@_date: 2014-08-27 13:11:40
You can take a look at the website given by I will copy and paste the relevant part here:






$ ./keyconv -G
Pubkey (hex): 041d2e778ae6d9124736df131cd22d3a2483f336c55156d87a84c4bdc6d89f8518e33de85ae0f907a7128c476281bc8cc7742b43a54ccc2c7824dc4c4a438a7fbc
Privkey (hex): 61E00B1C57E7F0D508C7C3795F90C0ACEC1DCAF6A7B82C951D23F728FD53E4BE
Address: 15wRE5VA5uhxs5o6LayZC6imES2SeZeXd4
Privkey: 5JZPftgcsaG5Unp24cf47zP7JZEZkfnSAZzefezAVNRomKHZE8f




$ ./vanitygen -P 041d2e778ae6d9124736df131cd22d3a2483f336c55156d87a84c4bdc6d89f8518e33de85ae0f907a7128c476281bc8cc7742b43a54ccc2c7824dc4c4a438a7fbc 1Boat
Difficulty: 4476342
Pattern: 1Boat                                                                 
Address: 1BoatWxEHyVXkjS78d16LMuj8YMdZ1Kce8
PrivkeyPart: 5KCwog8Ndt64ZicNSGoDBRf4vACBptM2GUtSJCmkbqpieC8idcP


$ ./keyconv -c 5JZPftgcsaG5Unp24cf47zP7JZEZkfnSAZzefezAVNRomKHZE8f 5KCwog8Ndt64ZicNSGoDBRf4vACBptM2GUtSJCmkbqpieC8idcP
Address: 1BoatWxEHyVXkjS78d16LMuj8YMdZ1Kce8
Privkey: 5J1Jieusaa6vegTQZ7PNG3hMcsM2FjgHPK1BkPjbYyQsWb9k5vj


@_date: 2014-11-27 14:02:54
I think what he meant is the 2-of-2 multisig wallets is protected by 2FA (example: Green Address). I signed the transaction using my key and Green Address will sign the transaction after I supply my 2FA
@_date: 2014-10-23 15:15:23
From the article:




From Wikipedia:


How is that bogus?
@_date: 2014-05-20 04:49:41


mandated any sort of transaction timestamp in bitcoin software.
The question is what prevents anyone from falsifying the time stamp? That's the whole purpose of PoW, that is to obtain a distributed consensus on the order of transaction. I have serious doubt whether the author really understands Bitcoin.
@_date: 2014-09-26 16:07:43
As long as the link that you posted is still available the transaction is still part of their mempool. 
@_date: 2014-03-06 11:21:28
If you use electrum you can go to Wallet-&gt;Private Keys-&gt;Import and paste your private key there
@_date: 2014-07-03 23:37:35
If the cost can be increased 'enough' it will simply no longer be economical to create such machine. But then again all of these are merely speculation. Unless we have a specific algorithm to talk about all of these discussions are pointless. Just because Mike Hearn is a core-dev doesn't mean that he is always right (again, I'm not saying that he is wrong). It's just that I don't think we have enough point to extrapolate the future. After all human history has demonstrated many examples of surpassing the 'impossibles'.
@_date: 2014-09-27 23:08:45
The concept of stealth address and CoinJoin is described elsewhere
Stealth Address:
What is lacking is the details of implementation (which is still an ongoing  work)
@_date: 2014-03-06 07:47:42
I didn't read the whole article but judging from the text you highlighted it doesn't seem to mean CoinValidation. An escrow/multisig transaction can provide the protection.
@_date: 2014-03-31 18:21:33
I'm not trying to defend them or anything but just trying to state the fact. Presenting an alternative point of view if you will.
The GitHub page for Darkwallet was last updated less than a day ago: 
The wiki was actually actively updated. 
I've also actually compiled and used libbitcoin that Dark Wallet said it is going to run on and it actually works.
I'm not sure about the real status as well but it seems like there is some ongoing work.
Paging and for possible response.
@_date: 2014-07-03 21:09:43
My point is if anyone can falsify the timestamp on the transaction having any sort of mandated timestamp would serve no purpose.
@_date: 2014-07-19 19:41:42
The thing is hash-rate/dollar is not constant. As technology nodes advance that value tends to go up. So 1 petahash now is not equivalent to 1 petahash say 1 year from now. 
Like said it is more important to look at the cost (rather than hash rate value). 
If you want to see the current cost to do 51% you can refer to  
However that website made the assumption that the attacker is a rational actor (e.g. want to maximize profit) so they include lost opportunity cost that the attacker could make when they support the network instead of attacking it. If the attacker has other motivation the cost would simply be the cost needed to secure 51% hash rate.
Edit: Expand Method and Assumption to see the detail
@_date: 2014-05-20 12:12:46
I think neither are centralized. Maybe Pre-mined (~99% for XRP  and a certain percentage for Ethereum) but definitely not centralized. 
Where did you get the information? Just to make sure we can compare notes.
@_date: 2014-07-10 22:38:30


Not in the beginning.  When I first connected to Internet I need to use a dial-up modem, which was purchased separately from the PC (normally people don't sell PC together with the modem). The speed was pathetic (56kbps) and I need to pay by SECONDS. It was several years before the advantage is obvious.
I don't mean to circle jerk but let me refer you to well-quoted article (at least in in 1995 Newsweek:
@_date: 2014-12-20 07:07:14
CVE-2010-5139 comes to mind. Miner creates more than 50BTC Reward.
You also can consider CVE-2013-3220 (if you consider the probability of double spend that happened during that period).
Edit: Not 0-conf
@_date: 2014-06-18 01:30:15


Now there is a reduced flexibility in the system. It will be harder for genuinely "big" transaction like multisig to get confirmed. 
@_date: 2014-07-13 00:31:42
Hmmm... Not really sure about that. Koblitz himself called Q 'Public Key' though (sorry no link provided, I only read the hard-copy in the library). Maybe EC-Multiply?
@_date: 2014-10-24 19:25:05
Seems to be still more prudent decision as compared to the SNAFU that is BitLicense
@_date: 2014-07-13 00:20:00
Well, the way I understand it is that  it is actually the x and y coordinates of the point itself that is getting hashed (for uncompressed) so Q is actually public key.
@_date: 2014-09-23 09:53:50
Hmmm... It's actually quite complex. You will need another tool for this. I've been browsing around Blockchain.info for a while but can't seem to find one. Are you in a rush? If not just let it simmer for a few days/weeks before the transaction finally expired or bc.i staff take a look.
Otherwise you can probably try to 'sweep' the key to another Wallet like Electrum (Warning! I'm not responsible for any loss). Download Electrum, Login to your bc.i account, Go to Import/Export, choose Export, Select Bitcoin-QT Format, copy the 'priv' field (the one that starts with 5...), In electrum choose import, paste the private key, sweep/transfer it, and transfer it back to your bc.i address (optional, if bc.i is more convenient for you)
@_date: 2014-08-25 23:50:12
It would be faster the if you have GPU and use the GPU version (oclvanitygen).
@_date: 2014-10-23 15:39:38
I think some of the concerns are that Blockstream is a for-profit Organization. Perhaps you can explain the business model, e.g how are you guys going to make money?
Edit: Heck, the other threads is reaching the front page. 
Just reply there.
Edit 2:
@_date: 2014-08-13 10:16:52
A wild gamble: Paging +Bruce, the Foundation has failed Amir. As a President of Bitcoin Association do you think there's anything you can do for him?
@_date: 2014-12-05 13:49:59
I believe the initial discussion coming from the following blog post: 
So far I don't think there's any proof that secp256k1 is safer than the more popular/standardized secp256r1.
@_date: 2014-09-24 23:38:03
May I know how do you confirm that it is the 0.0047BTC that causes it failing to confirm? Actually the problem is one/multiple of the input is non-standard rather than unconfirmed (as my libbitcoin node accept it just fine). The problem is as far as I know only Eligius mine on non-standard transaction and they hate dice site (political reason, they think those sites bloat the blockchain). 
If you are sure that it is that particular input that causes it failing to confirm you can exclude them by creating raw transaction.
You can play around with bitcoin-qt/electrum/brainwallet.org. Just be careful. A misstep can cause your bitcoin to be 'donated' to the miner
@_date: 2014-04-24 07:49:34


True. But PoW arguably does a better job at wealth distribution. Quoting at the beginning of the discussion:


I came from middle income background with technical knowledge so I am probably biased when I said this: When I am paying transaction fee I'd rather pay someone with technical know-how (irregardless of whether they are rich) rather than someone who is simply 'rich'.
@_date: 2014-10-22 13:35:33


Blockchain pruning is not exactly 'silver bullet'. There is difficulty associated with bootstrapping new node if everyone is holding only the pruned blockchain (it's quite hard to verify which one is the longest chain). While it is quite easy to implement checkpoint it will lead to centralization (Bitcoin is meant to be trustless).
With sipa's latest block-header first it might be possible to hold partial blockchain but it is actually a lot of hard work to implement that.
@_date: 2014-12-01 07:10:17
The mark-up would still be visible in the blockchain. Any competing party in a tender would cry foul play if this happen.
@_date: 2014-11-12 19:20:22




That's why. I don't think it's a good idea to start a debate by such a direct statement (accusing your opponent wrong without any proof). It would be better if you provide refuting argument first or even better, an external link showing how your opponent was wrong.
@_date: 2014-12-11 00:06:09
Nope, it is not. There is a pull request for it though:
Eligius does implement it:
@_date: 2014-05-08 15:13:08
Actually the two are quite different. Grover's is used for database search while Shor's made specifically for integer factorization (of course it seems that it is also applicable for discrete logarithm used in Bitcoin's ECDSA). One cannot use Shor's for reverse-computing the hash.
@_date: 2015-05-06 03:29:45


I would say 20MB Block is a good flag-day. That's roughly paypal-sized capacity. Bitcoin would be usable for the better part of the population. If we can't solve it by then we'll just let it stay there.
@_date: 2015-05-22 22:57:41
Most mining pools are already connected in their own fast relay network so they are more or less equal in terms of connectivity. Any advantage well-connected pools have will probably be negated by slower propagation.
@_date: 2014-09-23 09:14:40
You can get npm form nodejs.org. 
@_date: 2015-05-23 07:17:06
I think wants to argue that mining nodes that is well connected contributes more to the network than the one that doesn't, hence it is fair that they are rewarded more.
@_date: 2014-09-23 08:40:25
Do you know which output/input was already spent? Blockchain.info says that it is non-standard but I'm not really sure which part is non-standard. I tried pushing using my sx/libbitcoin node and it works fine (although I'm behind firewall and probably a lot of node rejects it since it is non-standard) because I know libbitcoin doesn't check on non-standard tx.










@_date: 2017-02-14 05:21:30
Because most people assume that cash in whitepaper as in small amount of cash to buy daily grocery, which IMO not the correct context. Bitcoin aims to make transaction irreversible, something that is retained even with Lightning.
@_date: 2014-02-15 11:29:56
I am still quite new to this so if someone more know than I do can tell that I'm wrong please correct me. The multisig method that you described is a 'user-friendly' one. The sender only needs to send bitcoin to the multisig address (starts with 3). This can be done from most wallet. The transaction that you link is another way of doing multisig. But unlike the 'user-friendly' version it needs to be handcrafted using raw transaction. You can check  and compare it to the input/output scripts (Show Scripts &amp; Coinbase in Blockchain.info).
@_date: 2015-05-11 22:25:10
They're actually quite friendly and since you want to write BIP they are the best people to consult since the majority of BIP were written by them. I saw below that you want to know about protocol specification. It is quite simple actually. You can take a look at this:
@_date: 2014-06-13 07:47:43
errr... I hate to be killjoy but I think it's wrong website. Should be  What you have shown here is just another centralized pool.
Setting up for P2Pool is actually slightly more difficult...
@_date: 2014-11-07 23:38:37
there's already but it has been pretty much inactive. Seems like bitcointalk and  irc channel is a better place to have discussion for developer
@_date: 2017-02-09 14:39:08


Simple enough to produce invalid block, just had a major change a couple of months ago to fix "sticky gates", and doesn't even bother to handle median EB issues.
@_date: 2017-02-22 16:08:08
Miner will tend to underprice their service because they are not paying for full node;s cost. They shouldn't be in control of blocksize limit just like they shouldn't be in control of 21M BTC limit.
@_date: 2017-02-20 19:59:47


Why do you associate cash with "small amount"? This is what Satoshi meant by cash:


No promise were made that you can buy coffee on it. Only "sent directly from one party to another without going through a financial institution". Bitcoin still manage to do just that.
@_date: 2017-02-14 03:57:11
The solution he mentioned doesn't work if you increase block size.
@_date: 2017-02-14 13:15:24
Except the IoU is cryptographically guaranteed to be redeemable on-chain.
@_date: 2017-02-28 18:24:07


The problem is the current "block space" definition doesn't actually fit the true cost of processing transaction. In terms of "block space" it might be more expensive but if you define it in terms of "block weight" it's actually not.


I'm not really sure where you are getting your definition of technical debt from. This is Wikipedia's definition:


Which is the very definition of what you do in block size increase. It requires you for example, to deal with UTXO growth later on when there is no solution at hand yet. 
It also requires you to limit the size of transaction to deal with quadratic hashing. This will disable a large scale coinjoin later on for example, even though a subset of the transaction (e.g segwit-style transaction) is not affected by quadratic hashing. You also may be attacked when HF is not happening yet (e.g people producing &gt;100kb tx while HF is not yet affected) so to avoid that you will need to handle another edge case.
The worst part is wallet/services will still also need to handle replay protection anyway.
@_date: 2015-05-26 23:42:53
Basically your vote is based on how much Bitcoin you have. You cannot double vote since your Bitcoin is limited
@_date: 2017-02-09 16:36:01


Here's an exercise. Right now everyone is using EB1/AD6, right? So the default setting is EB1/AD6. Makes sense? Everyone happy? So miner upgrades to what? EB2/AD6? At the same time?(unlikely) Now everyone using EB1/AD6 would be at risk. So a default setting now may no longer be secure a year from now. During transition what default value do you offer? EB1/AD6 or EB2/AD6? How do you tell them how many conf is secure? The concern is not on people who knows what they're doing but rather those who do not.
@_date: 2017-02-17 07:55:59


Keep on repeating that lie doesn't make it true. The reason settlement network being pushed is because the technology doesn't grow like it used to in 80s-90s. Everyone wants to adopt as many use case as possible but there's limitation in the technology. That is just Physics.
@_date: 2017-02-14 23:25:25


That's what happen in Ethereum. It is actually pretty easy to do in Bitcoin as well. Just change the script rule.
@_date: 2017-02-16 05:09:02
Haven't really dived into the detail but normally any defense that is based on "your block not getting built on by other miner" fails when you have achieved enough hashpower (even sub-50%). Peter Todd has some write-up here:
@_date: 2017-02-22 05:39:53
Block size actually helps in this case. If you have no clue what you're talking about read the rest of the threads.
@_date: 2017-02-23 12:57:08


1. When block reward goes to zero the rational is how much money you can cheat vs transaction fee.
2. You actually can profit by sabotaging whatever the minority hashrate mine for. (e.g make big block transition early)
@_date: 2017-02-15 18:33:09


@_date: 2017-02-12 08:56:33


Sometimes they are being idiot though. Bitcoin.com's invalid block and ViaBTC's broken spy mining is one.


Pretty troubling isn't it? We don't have solutions for that one yet. I wonder if OP_CHECKBLOCKATHEIGHT can help minimize that.
@_date: 2017-02-15 07:10:54
Visibility is only 1 year ahead but honestly it doesn't look too good. We have just transitioned into 3D scaling and there are lot of new issues. The problem with 3D is that it will increase cycle time so we are having diminishing return here. Hopefully someone will invent a miracle in the next few years.
@_date: 2017-02-16 16:46:56
I am going to go out on a limb here (note: I defended you guys a lot in the past) but if I were to speculate I am going to say "HK Roundtable". Yes, the intention is probably good but the result, well not so much. In particular this term


Yes, it means exactly what it means. So everyone that goes there has moral responsibility to produce quality work that Core devs (and for that matter everyone else) can reach consensus on the hard fork. 
(Not really sure how true it is but Theymos says that those that went there forgot to calculate UTXO impact when the agreement was made, if that is true, well that is on you guys as well)
Personally I am starting to care less. 1MB is good enough for me.
@_date: 2017-02-11 18:46:06




And the code is available here:
@_date: 2014-10-25 18:06:44
5 hours with no response? Hmmm... This is unheard of. Probably you will get better response if you post this in its own thread. I am by no means expert so I might be wrong on some account but I will attempt to address some of the key things.


Nope, Electrum employs Bloom Filter. Invertible Bloom Filter is the one being used to eliminate the needs for full node to download whole block everytime miner find a new block by 'guessing' which transaction is inside the block based on block headers and transaction that are already inside the mempool. This feature is not yet implemented in Bitcoin Core.


Nope, rather than querying the balances SPV clients query transaction. Think of it this way. The way Bitcoin works is that everytime you receive a payment you receive single 'dollar bill' with 'serial number' attached to it. When you make a payment you need to refer to this 'serial number'. If you don't store the whole blockchain you may not know what is the 'serial number' of the 'dollar bills' that you have.
What the Bloom filter does is that it attempt to ask the Electrum server to pass only the transaction with serial number that is relevant to you. Of course you will need to pass some of the 'fake' request as well to attempt to protect your privacy (which the Bloom filter also provides).
You can refer to BIP37 by Mike Hearn for more details:
@_date: 2017-02-27 21:28:56
[You just had one transmission change back in 2013]( Current engine can no longer cope.
@_date: 2017-02-05 23:49:57
Now, if only BU has the guts to make similar pages.
@_date: 2017-02-25 13:22:12
He was responding to this guy though.
who explains it in the context of hard-fork. Naturally the assumption is to implement that for every single tx instead of new sig-hash.
@_date: 2017-02-11 15:41:02


And the difference between Unlimited and Segwit is **not** minor enough. 


So you instead of telling everyone how BIP17 is slightly better than BIP16 you will just concede? No, that not the right thing to do.


In our current case you could argue that gridlock is better than one of them without consensus because
1. Some people actually appreciate immutability
2. UTXO growth will worsen in either case (with Segwit being less)
@_date: 2017-02-26 06:51:57


If he did that there will be two chains. Even Mike Hearn's 250kb-1MB gets enough noise.


What do you think SegWit is for, dummy?


Uh, you **do** realize that it is not a flaw with secp256k1 right?
@_date: 2017-02-23 15:56:51


He makes his enemy spend power on useless chain. What if I sell a cake and I can find a way to poison my competitors cake at the cost of one cake with no repercussion? 
Here's another thing. Why do you think ViaBTC puts back EB1 instead of EB2?
@_date: 2017-02-08 15:29:54


Transaction fee now is around 5% of block reward (and hopefully continue increasing). That means in 3 halvings (12 years) tx fee will make up around 40% of block reward. Significant enough not to be ignored.
@_date: 2017-02-14 13:42:13


Sure, just in case I haven't made myself clear my gripe is with people who used whitepaper's "cash" to justify using solely on-chain transaction to achieve that.
@_date: 2014-11-14 23:18:15
Manually pushed the tx to eligius:
Trying to send...
array(3) {
  ["result"]=&gt;
  string(64) "6a392660a759e2505549fdc69aa8e3f44064fc39de6c0ff4c673022b0da1818c"
  ["error"]=&gt;
  NULL
  ["id"]=&gt;
  string(1) "1"
Response = 0
Let's see what happen...
@_date: 2017-02-25 05:12:54
Does that hypothetical malleability fix also enables signatureless IBD?
@_date: 2017-02-05 12:26:39


What? *sigh* where the hell are you this last one year?
@_date: 2017-02-18 15:28:56
No, here's what my chart shows. 
Before [March 6th 2013 block size is effectively constrained to 250kb]( (same as now where it is constrained at 1MB). 
 (last chart)
Back then fee/kb shows 0.002BTC/kb after block size limit increased to 1MB the fee drop to 0.0003BTC/kb (can't even compare even if you multiply by 4)


Block size increase from 250kb to 1MB happens back in 2014. There's no halving back then.
@_date: 2017-02-25 18:28:31


If anyone says NACK it won't be merged. That is Bitcoin's governance.


Citation needed. IIRC that quote is related to SegWit


Doesn't matter. If anyone disagree we won't proceed.
And now you shamefully accuse him of doing 180.
@_date: 2017-02-14 12:34:18


Guess which one is more representative of such system. "Gold" or "cash"?
@_date: 2017-02-14 23:46:46
Sure, I'm comparing them to government imposed fee (and minimum capital requirement) though.
@_date: 2017-02-05 22:58:12


Compliance with regulation is the least thing we have to worry. With quadratic hashing (1) someone could disrupt Bitcoin operation for days. 
With UTXO bloat attack (2) someone could prevent any home-based personal computer from running full node ever again (note: Gavin didn't consider worst case scenario there). Even with current block size UTXO **grows** faster than technology. So you can expect the number of nodes to continue to drop **even at current block size**.
We haven't even talked about Sybil. During Bitcoin Classic debacle it has been shown that it is possible to spoof 1/12th of Bitcoin node. So at 1/12th of our current node ratio it is possible that 50% of Bitcoin node are fake. Now it is really easy to triangulate the origin of a transaction and to run eclipse attack.
(3) and (4) isn't even about node centralization but rather about miner centralization. Now I'm not even sure you actually read through them.
OK. Be honest now. Did you just skip to (5)?
@_date: 2017-02-09 12:30:42


Sure, but in that way they don't have rights to tell devs the direction they need to take, especially since the devs need to sell their own qualifications..


Huh, status quo works just fine for me. The prices continue to rise. The honey badger doesn't care.
@_date: 2017-02-09 07:48:06


And these "nodes and miners" need to upgrade at the same time. Too slow and your block will be orphaned/you receive false conf, too fast and you experience the same thing. That is just a logistical nightmare.
@_date: 2017-02-22 23:23:42


Forcing people unable to stop running their node is unacceptable as well. 


No one ever said Segwit alone will suffice. Signature aggregation and MAST is coming. HF proposal is being worked on.
@_date: 2017-02-25 09:52:31


You can't get roadmap if everyone is working on different things. That's what it means to be decentralized. Even Core roadmap above is obtained after bloods, sweat and tears. People seems to underestimate the difficulty of gaining consensus. 
I'd rather have a split chain than negotiating further. The truth is any further blocksize increase can only be made after Segwit is online. Without studying the behaviour of the network at larger block it is impossible to deem whether further increase is possible (or even if it is necessary)


Repeat after me. Decentralization caused immutability. Immutability is feature, not a bug.
@_date: 2017-02-23 13:22:34
Ever run a business before? If you are underwater short term profit &gt;&gt;&gt;&gt; long term profit. 
@_date: 2017-02-05 22:59:50
Ah, yes. A typical anti-intellectual. You can identify them easily when they call a peer reviewed paper FUD. Just like climate change denier.
@_date: 2017-02-03 04:24:16


I think that's because they only consider block propagation time, which is alleviated with compact block, right? So I don't think the 4MB figure is still valid. I agree with the rest of your point though compact block just move the bottleneck elsewhere. I was hoping for Johnson Lau's block weight counting to achieve consensus but seeing how much opposition the current SegWit's block weight has I doubt it will have enough support.




Your time to shine Greg :P
@_date: 2017-02-28 13:34:46
Compact block breaks down when there's large difference in miner's mempool. Weak block/mempool sync is a class of solution called pre-consensus where there is communication between miner to sync their mempool before block is finally made
See also Byzcoin and Bitcoin-NG


But it address the concern of growing UTXO, which can address some of the objection regarding increasing block size. 


People need to realize that apart from bandwidth all other aspects of silicon-based technology has slowed down. When that happen it is entirely possible that there will be no more blocksize increase.
(Unless people can agree to Peter Todd's client-side validation, which is a little bit icky to me) 
@_date: 2015-05-25 00:46:27
One thing that I have problem with is they keep on saying  'this is risky this is risky' without:
1. Solid attack vector with data to backup.At least Gavin has done some simulation
2. Any plan moving forward. LN may never comes to light for all I know. (It will take a while until we see a good percentage of v3 block, implementing CHECKLOCKTIMEVERIFY will take another ~year?, and we haven't even tested the channels itself).
@_date: 2015-05-06 04:42:33
Well, nothing in live is certain. Luckily we have one year to ponder about that (and hopefully produces countermeasures). We're not going anywhere if we are not moving. Personally I have confidence in core-devs. They are among the smartest people I've known.
@_date: 2017-02-17 06:19:05


@_date: 2017-02-25 05:13:49


No, it isn't. Unless miners are upgrading to bigger block at **exact same time**


The only saving point from that is the next block was a segwit block.


Except there are better option, like BIP100. TBH the only one supporting BU are those without technical understanding of what a consensus system is.
@_date: 2017-02-14 16:59:25


They might not need to run one now. But they will need to if someone attempt to create more than 21M BTC for example, or try to confiscate their (or for that matter someone else's) coins for whatever reason. 
If they can't be bothered to do that, well I'm not really sure I want them to adopt Bitcoin.
@_date: 2017-02-20 19:13:24




Bitcoin transaction consist of 3 major parts: inputs, signature, output. Output is the smallest part of the transaction and yet it requires permanent storage (preferably in memory, especially at sync time). A typical 1 input 2 outputs transaction has 226 bytes. Each output only consist of 20 bytes but responsible for majority of storage. This is the reason why counting fee/kb is broken. An attacker could easily bloat the entire block with UTXO, leading to increased requirement on running a full node **permanently** (this is unlike quadratic hashing where the effects is temporary)


Because you need to be ready when the technology hits the ceiling.


UTXO grows by 60% last year. This is **without** attack (attack is very expensive when the block is full)
HDD price decrease by 10-20%. 
Memory price actually increase last year
All pointing that UTXO is growing faster than the technology. People don't make noise without good reason. It is getting more expensive to run a node.
@_date: 2017-02-09 07:05:59




You're assuming that block propagation is still an issue, which it isn't. At least not at current block size after xthin/compact block. With malleability and quadratic hashing fix 11% is a really small price to pay.


Relatively harmless compared to UTXO bloat. Witness does not need to be cached, permanent storage can be sharded unlike UTXO. As of now UTXO grows faster than technological growth **even at current blocksize**.
@_date: 2017-02-23 13:42:39
1. When block reward goes to zero the rational is how much money you can cheat vs transaction fee.
2. You actually can profit by sabotaging whatever the minority hashrate mine for. (e.g make big block transition early)
@_date: 2017-02-11 11:45:22
If only you could point out where the analogy breaks down. But you can't. *shrugs*
@_date: 2017-02-11 11:08:07


Yeah, sure. Let's not cache anything.


Doesn't matter, with UTXO growing faster less and less miner will be able to afford it.


Don't trust. Verify. Remember? But if you're really too lazy:
You want more recent data?
UTXO increase by nearly by 50-60%
Memory cost?
Better view:
Increase not decrease. LOL
@_date: 2017-02-23 14:35:59


No fund loss in any kind is acceptable.


1. Why do you think people are against hard fork?
2. What if the doomed chain actually is not?


I thought BU was all about optionality? If people want SegWit why don't they implement them? It is up to the people to activate just like what you said.
@_date: 2017-02-06 08:42:42


You mean like ETH/ETC split? Nope, not going to happen.
I think a lot of people seeing the parallel between BU supporter and Trump supporter. Fortunately Bitcoin is not a democracy. Instead of choosing one winner there will be a parallel universe where Hillary Clinton (or even Bernie Sanders) get to be president. Now just days after Trump becomes president people start to regret it. I'm pretty sure there will be a lot of people who is willing to move to a parallel universe.
Engineers are not businessman. They always show their card. They don't hide their "best offers" until the opposing side shows upper hand. Would you negotiate with 21M BTC limit? I know I won't.
@_date: 2017-02-11 09:19:00
UTXO grows faster than technology. Go and argue with that.
@_date: 2017-02-14 16:49:05


You're talking to him though. And he might just leave out of sheer frustration.
@_date: 2017-02-09 14:47:10
Do you realize how often the term Blockstream Core is used over there? That term itself is derogatory. Just do a search on "Blockstream Core" over there
@_date: 2017-02-20 12:38:30
1. It is pretty obvious to a lot of people with know-hows. The other argument is just a smoke screen.
2. Is the same argument used by people who wants to ban encryption. Companies should be wary of broadcasting their entire balance sheet to the entire world.
@_date: 2017-02-23 15:29:05


What? No. If you have 25% hashrate you have ~25% chance to find the next block but you will need to compete with the rest of ~75%. Now the 75% can sabotage the 25% so that they will be mining on different chain.
@_date: 2017-02-15 06:14:42


Luke-jr was asking for a soft fork to decrease blocksize and he gets nowhere. Why do you think it will be different in the future?
@_date: 2017-02-23 19:14:03
Any concern about git commit? I think those use SHA-1 as well.
@_date: 2015-05-11 22:06:16
I think that's a little bit flawed. By reducing block rate you will still roughly get the roughly same amount of security in same amount of time (e.g  1 1 minute block confirmation is equal to 1/10th 1 10 minute). I think Meni Rosenfeld argues that it is not exactly linear like that but I don't think you can get to the point where 1 minute block confirmation has same amount of security to 10 minutes. In the case of a car I don't think you should wait 10 minutes in the case of 1 minute block as has tested and it is possible to have 10 blocks reorg.
@_date: 2017-02-08 14:56:20
What do you mean? Blocksize limit is meant to limit the damage. 1MB of unverified tx needs less processing than 2MB or 4MB.
@_date: 2017-02-20 14:04:04
1. You think they can't score point when they show that they are both competent and provides all both sides need? (or at least make it optional, just like they did block size). By not supporting SegWit they breach their own "Be conservative in what you create" mantra, making them look both like hypocrite. BTW No one was asking about "long term scaling solution" (BIP109) until Segwit was out. 
2. And I'm arguing that these people are stupid. (Note that I never argue against you in any of my comment in this thread)
@_date: 2017-02-09 10:51:11


On reddit. Not on mailing list. 


What agreement? An agreement made by few individuals? It doesn't seems mature to take out your anger to the entire community when you have problem with individuals. Not to mention when the individuals in question (Johnson Lau, Luke-jr) is keeping to their promises when the other side didn't


What do they want? Because plain 2MB is not feasible. All the technical problems were explained. SegWit is the best we have. Luckily Bitpay and Coinbase already change their mind.


Status quo is better than Unlimited. BIP100 is better than unlimited. Ethereum's gas limit is better than unlimited. Nearly every single thing I can think of is better than Unlimited. If you want to go the stupid way I won't stop you.
@_date: 2015-05-11 12:32:31
Seems like I don't have the underlying background needed to understand the work. Try to go to  @ irc.freenode.net and see if you can withstood the test of bitcoin core-devs, or alternatively try to post to the sourceforge mailing list.
@_date: 2017-02-09 12:51:23


[I talk]( Segwit comes as a result. Not sure what is the problem there.


Because it can't. If Steve Jobs tell his engineer, hey I want you guys to work on phone that can has neural input, just need to think what button to press and it will press it for you any reasonably sane engineer would tell him, "I'm sorry Steve, that is just not possible". But maybe I can use eye tracking instead.
Similarly if someone wants to produce an mm-sized design rule IC using only transparency and a marker any reasonably sane engineer would tell I don't think you can do that. If you attempt to do that you will just produce scrap. But I probably can use lens to project the original image. 
There limitations and it might take multiple solutions to fulfill as many applications as possible.
@_date: 2017-02-14 16:34:19




Fair enough.


And my point is a lot of people in this thread made fiat (or more specifically banknotes and coins) as a substitute for "cash" simply because that's what they are familiar with.


Fair enough, I never said that Bitcoin is not something revolutionary, just that between gold and fiat its characteristic is closer to gold.
@_date: 2017-02-14 05:27:48


And the reason is because Nick Szabo never made an implementation of it, something that Satoshi did.
@_date: 2017-02-06 00:56:47


[Core has per-txout utxo cache on the pipeline to combat IBD sync time so that externality from blocksize increase can be minimized]( 
What has BU done lately to counter the externality from increasing block size?
[Not to mention there's still signature aggregation for on-chain scaling without increasing blocksize](
@_date: 2017-02-09 14:44:37
And who is going to educate new merchant? You?
@_date: 2017-02-08 10:03:13
Let me break it down for you


It allows miner to create blocks within 10 minutes period that has difficulty less than global difficulty. This allows miner to more or less know what other miner has inside the mempool. Gun Sirer's Bitcoin NG is one implementation of weak block (although Greg's implementation significantly differs from his). The current compact block/xthin breaks down if miner has significantly different transactions inside their mempool (which is possible since transaction doesn't propagate uniformly at higher tps).


Allows multiple people to combine their transactions into one (or single person combine their multiple inputs together) without penalty on processing (single verification). This will allow roughly [additional 30% capacity]( even without increasing blocksize limit.


You need to read the bottom part of the link.


This way we can ensure that compact block remains effective even at higher tps.


More tps without significant penalty on decentralization.
@_date: 2017-02-17 08:24:12


If only we have a way to measure the effectiveness of xthin and compact blocks at bigger blocksize in the real world to determine appropriate action. Oh wait! We do!


You know what else is natural? Poison Ivy.
@_date: 2017-02-25 07:54:28
I see... I think it is still workable (although bitcoin's volatility may cause problem along the way).
@_date: 2015-05-11 07:46:38
Well, certainly we could use the data but there's still not enough information about let's say about whether Sybil attack mentioned by below could be profitable (e.g once the ecosystem grow big enough):
@_date: 2017-02-28 08:08:06


Ethereum might have dynamic blocksize limit but it was saved by changing one out of 255 magic numbers. Do you know you still have a lot of magic number inside Bitcoin? Why don't you make emergent consensus on push size? Or script size? Why only block size?


With multiple hard fork you will need 2n line patches, and not only 2 line patch.


You need to be around to avoid downtime or getting attacked. What could go wrong^TM ?


You can't receive payment until the chain is doomed or you're risking accepting payment on doomed chain. You're wrong if you think miner has 0 incentive to extend doomed chain, especially when transaction fee goes to zero.


Where do you get 99%? You still have on-chain, Lightning, and sidechain. Even if Bitcoin's entire transaction fee replaces the current block reward it is still cheaper than a SWIFT transfer. And like I said you don't need to onboard 99% at the same time. You can't build anything if your only tool is a hammer.
@_date: 2017-02-21 12:57:15


When market cap is at $1,000,000 it is possible to do "small amount". When market cap increase it will be scaled as well.


There should be world peace too but we don't have one do we?
@_date: 2017-02-20 17:26:06
Why would he and I want to do that? I am fine even if on-chain tx fee increases by 100x or even 1000x. LN is for dolts like you who insist on buying coffee using Bitcoin.
@_date: 2017-02-15 07:52:36
Except we have failed to achieve the target last couple of years
@_date: 2015-05-10 02:04:29


Well the problem is no matter how long you study this you will never be 100% certain. There needs to be a cutoff. It is easier to prove that the limit is unsafe rather than the limit is safe.


You think Lightning Network is a 'business'? No, the creation of Lightning Network will help to ensure that Bitcoin remains decentralized. The problem is that it is not yet ready.


There is no guarantee that the core-devs (not that each core-devs might have their own) version will be the main version.


Everyone may agree, but I don't think they will be happy. I believe  a good solution is the one where everyone is equally unhappy (the one where everyone is equally happy is just impossible). I think you are being too much of an idealist here. There are cases where there is no 'good question' and 'good answer' available.


With adaptable block size miners are winners, full nodes are losers. With 20MB Block size whoever wants the network to grows wins, Strawpay, pro-decentralization loses. I just don't think such solutions would exist.


You could argue that Gavin is not crystal balling 20MB limit. He has done all the study he can to prove that it is safe (running testnet).


Well there are 'easy decisions' and there are 'hard ones'. Unfortunately block size is one of the 'hard ones'. As for your Peter Todd example I can provide one counterpoint: replace-by-fee.
@_date: 2017-02-23 16:22:04


How long did Bitcoin.com take to realize that SNAFU? Are you saying 25% upgrading first need to monitor the network 24/7. Remember this attack is not a one time thing. It can happen today, tomorrow, next week.


You think my own competitor won't do the same? The very worst thing  about this is that this is something that is avoidable.
Edit: Also remember that block reward is not going to be there forever. There might be time where you can do this more profitably.
@_date: 2017-02-28 13:55:52


The fear is not irrational. At 1MB block size miners who were not mining with Ghash.io is not as profitable (which were then fixed with relay network).
Study shows that 4MB is what we can achieve without centralizing miner the way it did with Ghash.io. 
SegWit gives half of that capacity because we also need to address concern for UTXO growth. Why do you want to hard fork to 2x capacity when Lightning can potentially give you much more than that?
@_date: 2017-02-11 11:55:46


Or maybe goatpig with sickpig/s1ckpig?
@_date: 2017-02-26 08:35:19


Script upgrade capability


If a door has a knob you need to turn it to open it. Of course there are other doors that can open automatically when you get close to it but if you see a door with know you should know what to do. If you bump your head, it is your fault, not because the door is broken.
@_date: 2017-02-28 10:19:57


**It is** when your use case is a store of value that can't be confiscated by government.


Government pressure, especially now that there is no one to stop you from doing that with non-mining node gone.
@_date: 2017-02-02 17:59:00


Personally I'm attacking them for their irresponsible behaviours. Selling their software as "best-tested" while nothing is further from the truth. I don't have any problem with alt-implementations like BTCD or libbitcoin.


What? You don't care if you are being fed fake news?


And they will end up looking like PayPal. With miners controlling the blockchain.


If the technology improves 10000x overnight I don't mind having 1000x increased capacity (provided the incentive is balanced) but it's not. Even then there is a gap that Bitcoin can't fulfill (e.g 0-conf will never be secure, sub-satoshi payment is not possible without forking)


"The only thing that makes increasing blocksize possible and safe"
The discount is the only thing that makes increasing blocksize possible without worsening this kind of scenario:


Fat chance that will gain consensus. Technology growth is not predictable.
@_date: 2017-02-27 17:17:30
Also 2010 Gavin




@_date: 2017-02-27 08:11:01


Means you don't understand UTXO growth concern on why only Witness part can be increased. It's like arguing with Vitalik on how to avoid Ethereum being DoSed. The reason we haven't been DoSed like Ethereum is because of block size limit. SegWit increase the block size without worrying about being DoSed. And now you guys just think that because it doesn't happen it will never happen.
There will be no blocksize increase **ever**. Only block weight adjustment. Segwit is first step.
And he doesn't say anything about multiple hard fork only singular, which is my point. And BU doesn't even bother to follow his solution.


Here's what BU node sets that connect Luke's node.
   1 80002 "/BitcoinUnlimited:0.12.1(EB0.1; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB16.8; AD3)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB1; AD12)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB2; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB2; AD6)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB32; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB4; AD2)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB4; AD25)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB4; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB4; AD99999)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB512; AD2)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB80; AD10)/" non-full
      1 80002 "/BitcoinUnlimited:0.12.1(EB8; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB16; AD3)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB16; AD5)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB1; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB2; AD12)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB2; AD6)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB4; AD6)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB8; AD12)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0(EB8; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB14; AD3)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB21; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB2; AD12)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB2; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB4; AD2000)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB4; AD6)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB84; AD8)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB8; AD4)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB8; AD6)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.1(EB8; AD9999999)/" non-full
      1 80002 "/BitcoinUnlimited:1.0.0.99(EB16; AD4)/" non-full
EB=1MB makes up the minority of the node, which means nobody follows your Best Known Method, which clearly support my point that most of BU supporters is clueless and doesn't agree with your definition of "Schelling Point".


The amount of merchant adoption shows how many people are willing to take that risk.


Fine, at least sets a clear transition on where to start to switch to bigger block and not a subjective number that anyone can decide, because most people have no idea what to set without jeopardizing their day-to-day.


Are you saying all 7 Billion people all currently use SWIFT with USD? No. Some people don't. There are other class of solutions that support other use cases, like Coinbase-offchain. 
Besides, some of those people will not on-board at the same time. We already have 8 years of Bitcoin, which is 1/10th of your estimate.


And my point is that people that support BU is clueless about a good Schelling Point and a good solutions for the network.
@_date: 2017-02-23 11:34:05


So it **is** no longer majority hashrate.
Here's a couple of questions. What happen when majority hashrate is not equal to majority economic power (temporarily this is possible, due to unevenness of information) which one is Bitcoin? What happen on transaction that is on one chain but not the other?
@_date: 2017-02-17 08:11:51


Jesus. The author of the paper itself determined that 4MB doesn't include complete picture on the situation (for a starter it only includes bandwidth, completely ignoring data cap, completely ignoring UTXO growth)


Paper is in 2016. The other jtoomim study is in Dec 2015. Hardly 2 years (not to mention the above)


Everything else except bandwidth is slowing down. 
We also need to consider blockchain **grows** even at constant blocksize. Without technology growth and other security models change (nothing acceptable proposed yet BTW) there's no chance we can avoid centralization.
@_date: 2017-02-28 11:47:28
Either that or stay at 1MB.
@_date: 2017-02-09 10:04:23
1. Moderation log is open. 
2. I don't see Coinbase/Circle participate in that. It is not the devs fault if they never offer feedback.
OTOH, 
I don't see what you're talking about. The bottleneck is the miner, for which there are communication issues from the FUD
@_date: 2017-02-14 08:18:49


1. What you use it for may be in conflict with my interest.
2. If you haven't figured out what Bitcoin is capable of now you haven't done enough research.


Ever tried using gold to transfer $1 milion dollars overseas? Ever tried to use gold to bypass capital restriction? Ever tried to use gold to avoid your wealth being confiscated? Yeah, figures. Just because Bitcoin is not useful to you because you can't purchase coffee doesn't mean it is no longer useful for many people.






What makes you think Bitcoin any less probable than fiat or gold to exchange for useful things in the future? There is only a limit before you sound like a buttcoiner you know?
We haven't even considered the fact that Lightning can fulfill all of your use case.


Uh, no. You know how many tps does an exchange support? You don't use SWIFT/FedWire for normal transfer, do you?


Can you please stop straw manning block size limit argument? You can start by researching on block propagation and UTXO growth. You can't run Bitcoin Core on rasp pi without waiting for weeks/months and most block propagation research uses DSL as standard. Upload limit is more important than download for the case of Bitcoin.


Just goes to show you don't know how much people spend for remittance. Normal WU transfer costs ~8%. When the amount goes up costs also goes up. In comparison if we replace entire block reward with transaction fee it will only cost ~2.5$ flat.
@_date: 2017-02-08 12:53:29
Accept lists of transactions offchain(example: BTCC). Mine transaction without broadcasting them. Other miners will be forced to re-validate the entire block because they don't have the transaction. This will cause a penalty in their mining time. Defense: block size limit.
@_date: 2017-02-04 12:25:18
ETC fork is also supported with overwhelming majority of hashrate (and economic power). Yet it still survive. Chandler Guo initially attempt to attack ETC and now he is one of its biggest supporter, which is freaking hilarious. The truth is 51% attack is the stupidest way to attack a coin. It shows the lack of creativity shown in majority of BU supporter. When you attempt to 51% attack a coin, you end up with the coin itself and with an actual demand of course there is a huge temptation to support that coin itself. It took an economically irrational person to do 51% attack.
Now take a look at the amount of money itself. $100Million dollars seems big but it is actually small. It took only 100,000 people to spend $1,000 to outdo you. I would be surprised if I can't find 100,000 radical Core supporter not worrying about mining at a loss. Of course we haven't taken into account botnet operators, rogue employee at supercomputing facilities, and altcoin miners. In the end when $100M is gone the chain will proceed as per normal, leading increased value in coin. This kind of shortsightedness seems to be the hallmark of BU supporter.
Lastly, isn't this the same BTC.TOP that "accidentally" mines SegWit block just a couple of days ago? Makes you really wonder if this is the same case of closet gays hating an openly gay people.
@_date: 2017-02-22 23:29:05


No, but if miner wants to print more than 21M or confiscate coin then they **need** to. I'd accept no less from people who wants to adopt Bitcoin.


Citation needed. There's a reason why Ethereum has ~10% inflation/year when they don't want transaction fee to dominate.




It will break, just like Ethereum breaks when their gas limit was set too high.
And no, I won't buy it.


The current normal node will become crappy underpowered when you increase the block size.
@_date: 2017-02-26 04:55:40


I certainly hope you're not describing SegWit. See my comment history for the reasons of creating two separate serialization.


[Fortunately Satoshi has enough foresight to create a viable upgrade path](


Happens to 25% of BU nodes apparently.


The only way that can happen is if everyone choose not to move from 1MB limit forever. Seems pretty successful to me.




Like how Ethereum refuse to bow down to Vitalik when it is getting DoSed?
@_date: 2017-02-25 06:05:30


**Only for historical data**. Once you are up-to-date you can start validating as normal (and have significantly more security than SPV). I would care more about what is happening recently vs what is happening in the past. Any miners confiscating coin in the past would be in the news already.
@_date: 2017-02-02 20:13:24
You won't find anything on Unlimited. Go ahead
@_date: 2017-02-23 10:44:38
Explain to me the rationale of choosing BU's mechanism over BIP100.
@_date: 2017-02-03 07:28:59
[Additional 30%]( I think additional 41% if everyone use CoinJoin-like scheme to combine their transactions
@_date: 2017-02-09 06:53:47
Already possible? Sure, it is. But normally any normal sane miner would put a "flag day" during the transition. Here's how Satoshi suggest doing that: 
    if (blocknumber &gt; 115000)
        maxblocksize = largerlimit
At least everyone knows where is the transition.
How BU do it. 


@_date: 2017-02-23 15:36:01
I calculate using this:
both give
According to
The hash only give 20bytes. Yours are more than that. Error in the tool chain?
@_date: 2017-02-25 18:19:28
How do you convince people that UTXO growth when block size is increased is no longer an issue? By developing solution for it. 
@_date: 2015-05-26 16:28:21
*sigh* I gave up. Looks like you're not going to read it anyway. He has pointed out how this could be catastrophic to the network in the article. Instead of addressing that, you went off tangent with your own view...
@_date: 2017-02-21 12:56:52


All the development happens on bitcoin mailing-list. Ever seen BIP being censored?




Back tracking much?


holdr for life. I only make like 1-2 on-chain. Save a lot. Do a single purchase at once and straight away transfer off-chain.




Back tracking much?
@_date: 2017-02-20 17:53:38


1MB is the only limit that saves us from that.


No, unless you know of a way making UTXO grow O(1) with regards to block size.
@_date: 2017-02-09 10:57:13
No, the worst damage you can do is you accept payment on bogus chain.
@_date: 2017-02-18 15:35:54


I find it hilarious that people can still claim this with straight face. 
1. Core consist of 100+ developers, each not always agreeing with each other. Peter Todd doesn't get his full-RBF in. Luke-jr doesn't get his BIP17 in. From what I heard Greg's UTXO sharding/weak block idea is always blocked by Peter Todd. Unlike certain other people these guys don't rage quit when their idea is being criticized.
2. Even if you discount Core, there's still btcd, libbitcoin, and NBitcoin (each already reach consensus on Segwit). 
Compare that to certain other team
1. 5 person team
2. closed door meeting
3. entry requires "pledge of allegiance"
Like, really?
@_date: 2017-02-22 21:26:16
Sure, Bitcoin will just becomes gold because it has proven itself as currency before. People are delirious if they think any alts will scale any better though.
My guess is DNM will be the first to integrate Lightning if Segwit is activated. They are really good at innovating
@_date: 2017-02-01 21:58:13
Even with 1 year time to upgrade you are still forcing people (also note the higher lead time). Right now 1 year post-segwit consensus alt-implementation like libbitcoin hasn't finished implementing them.
At the end of the day, it comes down to one question. Is the benefit worth it? 
To me the answer seems simple. NO. You are not gaining extra capacity for example, or adding extra features. Not to mention that if we have fraud proof or UTXO commitment in the future for example we will need to rearrange the structure in the block header again. Might as well do everything in one shot.
@_date: 2017-02-27 08:25:54


There's already work on that.
Actually BU dev is the one who is supposed to do this shit since they are the one who proposes hard fork but they are unfortunately too incompetent to do that.


You only need to do it once though
You only need to do it once for each UTXO though
@_date: 2017-02-15 06:46:36
1. Article is from 2014, just before immersion lithography/pitch doubling hits its limit
2. SSD cost/capacity is still higher than HDD
3. Take a look at my chart, it shows data past 2015
C'mon, you're arguing with someone who **actually** works in semicon here.
@_date: 2015-05-06 17:22:18


Now that's interesting. Care to elaborate?
@_date: 2017-02-20 00:04:54


For the case of Core you also can be one of the gatekeeper. You just need to do review. Wlad won't merge it if you NACK the change for a good reason.
@_date: 2015-05-08 07:25:21


Let me attempt to answer that. The answer is no. Reason is by doing blocksize increase I'm trading tps (hence usability) for less decentralization (which is still arguable because of technological advance). While by increasing the amount of newly made coin I'm reducing my net worth with no (apparent) benefit. 
I'm joining Bitcoin Community with the premise of a inflation-resistant asset with usable payment network.
@_date: 2017-02-05 05:23:02


People with superior engineering talent doesn't just decide the block space is scarce willy-nilly. They used scientific method to determine the risk of increasing the block size. That's how a lot of people comes to the same conclusion. Even then they still listen to the demand of the market. SegWit is the solution that they come about.
Anyone disagreeing that L2 is not a viable solutions like that "long time bitcoiner" above is a typical example of anti-intellectual proponent (e.g I am stupid and I am proud of it).
Take a look at routing problems in PCB/semiconductor. It is a simple problem of drawing two lines as close as possible without intersecting. When you have large circuit all you need is a marker and a transparency sheet. When you go to mm-sized line you will need to start to use a lens to project the original. At nanometre size you will need hundred million dollar tools with 50+ lens with special substrate with special photo-resist on top of magnetically levitated stage. In other words, you need multiple layers of solutions on top of each other. 
Now what BU proposing is let's make mm-sized line consistently without intersecting using only marker and transparency sheet. "I have a steady hand". Guess what, not even a year and they already short the circuit.
@_date: 2017-02-28 10:32:52
Is it conspiracy when the author specifically puts the research subsection?
@_date: 2017-02-22 12:45:26
1. That separate serialization will be useful when you want to attempt to add additional feature to bootstrap a new node without signatures. (less security than the current full node bootstrap but arguably optionality is always useful)
2. SW-HF will require longer block header, which means disruption to entire ecosystem and bigger SPV proof (although you can argue it makes it looks less hack-ish than with the current root-in-Coinbase setup, however you will also need to remember that [fast-inverse-square-root]( also look hack-ish but it works beautifully so now the question is if it is really worth it to change the location) 
@_date: 2015-05-08 22:14:47


Well to do this, you need to make an assumption about usage. For example is 20MB Block going to be open to an abuse? Can we support higher than 3 tps without hickup? How long before we reach there? Do we need to take action now? 


I think if you are talking about miner alone you are giving too much power to the miner. The way things are done now is full node operators + miner decide the way.


Can you give link to sourceforge/narkive site? I'm skeptical of the presence of such panacea solutions.


Well in the case of Bitcoin, this group consist of full node operators + miner. Which is as democratic as it can be since this group consist of everyone. Which is why it is important that everyone can run a fullnode while supporting a higher number of tps.
@_date: 2017-02-11 18:24:20


Great! Then maybe you could start promoting them in the other sub because a quick search would reveal other story.
@_date: 2017-02-18 16:02:05




A little bit slow aren't you? It's their own choice to rage quit. No one forces them to. Luke-jr could have quit when his BIP17 rejected, but he doesn't.


At least you don't need pledge of allegiance. You also can carry some of the load, you know? But you don't, do you?
Besides, let's ignore all the review. You think it is easy to do review?
Take a look at kazcw's review here:
or dcousens here:
But yeah, let's focus on the 10 people.




What? Don't get enough coffee or is this something normal?
@_date: 2017-02-26 13:46:49


If you want to be fair shouldn't you be concerned with who is funding Classic/Unlimited as well? As if that wasn't enough the meetings are closed door as well.
@_date: 2017-02-23 15:53:16
Here's another way to look at it. I will spend 1 block to make my enemy waste however many block invalid (until AD6 runs out). 
Seems pretty good strategy to me.
@_date: 2017-02-06 05:13:31


As said:




It's all about opportunity cost. If transaction fee stays at 1BTC/day now it is a matter of question which one is more profitable, earn transaction fee or
1. Double spending 5 BTC by faking 5 conf-tx or more, or
2. Earn the dollar equivalent of 1BTC through shorting. Whoever was attacking Ethereum was spending $4500 a day DoSing Ethereum. I am pretty certain he is in the black now.
@_date: 2017-02-28 08:10:50
1. There is no incentive for miner to keep 21M limit.
2. Miner now can serve as regulatory point where now they require registration for SPV that is attached to them
3. Miner can freely confiscate coin whenever they want.
Bitcoin without non-mining node is not Bitcoin.
@_date: 2017-02-17 06:17:39
My chart says otherwise.
@_date: 2015-05-09 03:02:57


Yes this has been proposed before. The full-node now have no control over the block size limit and all the powers are handed over to miner because miners are free to increase blocksize at their own pace instead of full node's.


If we can do this without a fork we would have done so unfortunately the way block size is determined it would be impossible to do so.


Is it possible to exploit weakness in 20MB block? No one knows for sure. It is like trying to prove that you don't own any Bitcoin. Some people like more time to study, some people like to do it in reasonable amount of time. This is hardly a technical decision.


Some people would beg to differ. Their reasoning is that blocksize limit is good to force technical innovation like Lightning Network. Again how you view this would depend on your vision of how you want Bitcoin to be.


I wouldn't count on that. Some people are highly opinionated. Mircea Popescu has already declared he won't agree to 20MB Block. Me myself won't agree to 1MB Block without any gameplan.




Well now you are just being inconsistent. You just said we shouldn't speculate on the future. Besides this is just as controversial not everyone agrees at the number and whether we can sustain this number for prolonged period of time.
It is just impossible to avoid being controversial
@_date: 2017-02-25 05:27:06
The last I checked it doesn't have different serialization for normal block propagation vs IBD. The author doesn't even seem to be aware of that particular segwit feature.
Can you link to the commit that enables that?
Edit: If it is blocked by automod just give me the pull req #
@_date: 2015-05-23 07:16:02
Ah yes, the 'may's. Like I said elsewhere it is pretty much impossible to proof something (e.g a change) is safe. If we can't prove that it is unsafe (e.g 'may not be so equal') in a certain amount of time (Gavin propose a year) then we need to move. In certain case it is necessary to take risk to progress. I'm open to other solutions though (e.g jdillon's pos? haven't read that one through)
Besides, like said above


And my second argument


still holds.
@_date: 2017-02-23 11:16:57


No rules against mentioning BIP.


If "hypothetically" Core deliver the promise within the next 5 years are you going to shift the goalpost again, saying "technology has already improved yadda yadda"?
@_date: 2017-02-25 08:32:24
Not to scare you or anything but Lefteris of DAO fame is also working on Raiden.
@_date: 2017-02-17 07:53:52
Here's Mark's point:
This is fine:


At least the concern can be addressed.
This is not okay:


That is just totally political. The reason they're blocking is totally unrelated to SegWit itself but to gain concession.


I'm not really sure which part you're talking about. I don't think anyone mention centralization in the discussion.
@_date: 2017-02-03 06:42:23
Basically same position as Lightning. And I **do** see Lightning dev pushing for SegWit 
@_date: 2017-02-08 15:08:51


You can't do that when the rewards go to zero (at least there's no point in doing that).
@_date: 2017-02-12 16:28:48


By your math 10 years should give us 2^5 =32 times improvement. Empirically we only see barely 6-8 times improvement. We haven't taken into account how late the latest 11nm node is.
@_date: 2015-05-08 14:45:56


Unfortunately the way you choose a metric **is** political. Everyone has their own vision of how they want Bitcoin to be. Take a look at Greg Maxwell's mail at the front page.


If this is your only metrics is right Bitcoin-core would run best with extremely small blocks. But remember, you also need to consider how many transactions per second you want to support. 
Tradeoffs are everywhere and everyone has their own opinions. You can't avoid from getting political if you talk about money.
Edit: Fortunately Core Devs won't be central bankers. The way Bitcoin works is that full node operators and miners will choose which chain they like (although a fork is ugly, probably there will be some sort of vote a la BIP16 style if it comes down to it).
@_date: 2017-02-03 07:25:04


Not by much and it is small price to pay to solve quadratic hashing/malleability.


The alternative (current situation) is people bloating UTXO, which is far more dangerous than people bloating witness.
Someone already attempted to do that. With 2mb block this situation is more dangerous.


Not much difference between Segwit as SF and Segwit as HF, only where to put the witness root.


We already did that with P2SH and there is no issue whatsoever.
@_date: 2017-02-25 10:07:14


It is something that is highly appreciated here. If you don't share the same value you are welcome to walk out the door


The very idea of leadership is antithetical to the concept of decentralization. Just because all software project has centralized decision making doesn't mean that Bitcoin needs to be one as well.
@_date: 2017-02-23 11:47:32
There is an easy way to test. **Activate Segwit**
@_date: 2017-02-10 09:14:08
I think 5% orphan rate during GHash.io time plays a large part for sure.
@_date: 2017-02-25 06:31:45


The question is whether the user has the understanding of the implication to exercise that power. To give an example. During the last bitcoin.com SNAFU 75% of BU nodes has an estimated convergence time in 40 minutes while 25% of BU node has estimated convergence time in 19 years. This shows that majority of BU node
1. Doesn't actually use that to verify payment.
2. Doesn't have understanding of what that power entails.


You are ignoring the possibility of bitcoin.com-like snafu, or even a malicious actor(like miner lying on their EB/AD setting).


It **is** incompatible. BIP100 guarantee convergence at nearly the same level at current 1MB limit. It is entirely possible that some BU miners are asleep when BIP100 miners decide to increase the limit beyond their EB.


Off-chain consensus mechanism is still better than how BU works. If you want to do off-chain, do fully off-chain, if you want to do on-chain, do it fully on-chain. BU can't seems to decide which want they want.
@_date: 2017-02-10 10:28:09
Do BIP100. At least you're being halfway sane. If you want moar human intervention visit a teller in bank.
@_date: 2017-02-15 16:51:39
SPV mining caused [this]( It remains a risk up to this day.
@_date: 2017-02-23 10:53:33
With ~70% hashrate in China it is just profitable. It is like running 51% attack covertly (e.g you can blame big block for high orphan rate). GHash.io did this until relay network comes out.
@_date: 2017-02-10 09:16:53
The idea is to minimize them and not to increase them
@_date: 2017-02-09 09:07:09


Not related to block size change.


You already gave consent when you run Bitcoin Core. OP_NOPs are written clearly there.


Dissenting node can run a competing soft fork or propose a hard fork. Lazy people will just follow.
@_date: 2017-02-03 10:35:12
Eh? Is it really worth it? I mean that will create hell for documentation. Coinbase was meant for transaction. I have mixed feeling about this. Are we going to put fraud proof commitment inside Coinbase as well?
@_date: 2017-02-14 13:07:58
[Increase the block size and transaction fee actually went down](
@_date: 2017-02-03 15:15:09
Except quadratic hashing . And UTXO growth. And some other unknown attack vectors (Ethereum got hit by CALL attack, state-bloat attack, and EXP attack precisely because they don't leave margin for safety)
@_date: 2017-02-10 23:35:10


That is because of resource requirement as well. If you can't sync reasonably fast people won't use it.
@_date: 2017-02-14 04:06:37
Gold already exist since time immemorial and gold doesn't even have Lightning.
@_date: 2017-02-23 11:31:47


Masquerading block withholding as orphaning due to big block


At 1MB only, at certain stage you will be limited by mempool mismatch due to uneven transaction propagation.
@_date: 2017-02-22 12:25:30
That's the very reason you should avoid ad-hominem. His BIP17 in retrospect is better than Gavin's BIP16 and you could argue that the reason people choose BIP16 is because of ad-hominem attack on Luke-jr.
He was also the one who first find out how to implement SW as Soft Fork (which despite what people say is actually cleaner than SW-HF)
@_date: 2017-02-08 16:31:45
It would start to make sense for some miner to start to force other miner to spv-mine as long as possible though. Imagine if you can mine 25BTC or 12.5BTC and you can force your competitor to mine 12.5BTC for as long possible so that your opportunity to mine 25BTC is larger. It would be pretty tempting I'd say.
@_date: 2015-05-26 15:45:07


Actually he didn't ignore them. Read "With Upgraded Codes"
@_date: 2017-02-20 07:55:11
Health as a percentage? Are you talking about game or something?
@_date: 2017-02-06 10:53:19


Based on Ethereum's and Bitcoin's testnet.
Someone did run a test on 1-minute block time on Bitcoin testnet and the results is there is a 10-block reorg. Definitely not something acceptable. Here's [Decker-Watterhofer study on the topic](


One of the main mistake people made on Bitcoin's scalability is modelling what your node can handle vs what the network can handle. Bitcoin is a gossip network, it doesn't scale the same way as a centralized system like website does
@_date: 2015-05-10 16:38:28
Child pays for parent 2nd try...
Edit: This is hilarious. It just refuses to appear. Take a look at my overview if you are still interested in my reply
@_date: 2017-02-15 15:49:20


How many HDD slots does your PC have?


At the cost of changing the security model and we don't have one on the pipeline yet. (Unless you're talking about UTXO pruning, which is already implemented and yet still grows 60% a year)
@_date: 2017-02-25 05:45:58


Actually that is one of the hardest part of Segwit. It is designed with this as one of the feature. I doubt anything else that doesn't consider this at the very beginning is viable as an alternative.


You will feel it when you have features that requires big signature, like Lamport (which is required for quantum-computing resistant) or CT (which is required to mask the amount for better fungibility).


I think you are mistaking something. SPV node can't validate the blockchain. The signatureless IBD is only used during IBD. After IBD is done the security is the same as full-node.
@_date: 2017-02-02 10:26:35


What's the point of running them on testnet if you don't use them for testing? I think the fact that [Andrew Stone doesn't care about Unlimited-Classic fork]( is saying something about his attitude on testnet. He doesn't even realize that happens until a month.
Not to mention this kind of shit should be caught in review, not in testnet.
@_date: 2017-02-14 08:50:30
"Without trusted third party"


allow online payments to be sent directly from one party to another
without the burdens of going through a financial institution.
Digital signatures provide part of the solution, but the main
benefits are lost if a trusted party is still required to prevent
double-spending. We propose a solution to the double-spending
problem using a peer-to-peer network. 
The only reason people associate "cash" with small amount is precisely because it is impossible to use case with bigger amount before Bitcoin.
@_date: 2017-02-18 16:57:19


You're saying Luke-jr doesn't invest much into BIP17? Or Peter Todd doesn't invest much into RBF? Yes, they do. But when the idea is rejected they still contribute.


No, they don't rage quit when they don't make noise when they leave.


1. I'm just arguing against your idea of "node counts" as a success. No, it is not a success when the reason of increased node count is not because of innovation but because of politics. Are they making any performance increase that can be merged back into Core? No.
2. It's a problem when they're pushing crap code as being safe. I don't have any issue with everyone working on their own private repo (at least if they using Core's codebase). It will be merged if it is good enough.
If it is crap like [Hearn's getutxo]( it will be rejected.


Like I said I don't have problem if it isn't crap.
@_date: 2017-02-17 08:05:43


Sure, just don't expect any of us to yield unless the HF is attractive enough. Bitcoin was meant to be apolitical money.
@_date: 2017-02-23 13:40:44
When miners are the only capable running a full node they have every power to inflate subsidy. 
@_date: 2017-02-09 12:05:44
Here's another radical idea. Why don't miner and ecosystem fund for a dev?
@_date: 2017-02-23 11:18:02
What happens when majority hashrate create more than 21M BTC?
@_date: 2017-02-25 06:48:17
Can't you just make it cash-like with multiple denominations? Like $1,$2,$5,$10. Each of these can be mixed separately. (Of course liquidity will dry up as you go higher)
@_date: 2017-02-03 15:08:41
1. Then how are you going to solve malleability genius?
2. If you limit transaction size you can't combine these transactions into one
Whoever made that transactions needs to make multiple transactions precisely because of transaction size limit.
@_date: 2017-02-11 19:05:39
IIRC BIP16 only allows 15 max pubkey instead of BIP17's 20 (same as raw multisig)
@_date: 2015-05-29 10:48:22
I wonder how much being open source plays a part in this incident (e.g people exploiting clear-in-the-air vulnerability instead of exposing them to bc.i). On thing I still don't understand is why don't they implement keyboard mash/mouse movement (or touch placement in mobile device) a la bitaddress.org.
@_date: 2015-05-26 16:12:51


Yes, he already mentioned it at one part.




There's Bitcoin Core and there's Bitcoin the Network. Mike was clearly referring to the latter. If you are going to make critical comments can you actually bother to read the article?
@_date: 2017-02-27 10:20:49
I see. The output **either** can be spent on higher nLockTime or lower nLockTime, with the higher nLockTime being revealed first.
@_date: 2017-02-06 06:06:25


And you're not going to get that simply by increasing blocksize. At somewhere around 25 tx/s you will start to see that only 1-2 miners making the block. You might as well call them Paypal &amp; co.
@_date: 2017-02-09 16:31:55


Ah, yes. Blame the victim.
@_date: 2017-02-25 11:22:14


It is going to be ugly though. Something like if (block &gt; ...) do something different.
@_date: 2017-02-21 16:04:14
Until today he still admits that he owns the website:
Note that comment is now deleted. Sounds like crappy attempt at damage control to me.
@_date: 2017-02-09 10:55:07
The question is does the user has enough knowledge to twiddle with the settings? A good software should come with good enough default settings. Seeing the dynamic nature of BU this is just simply not possible. When the user change the setting do they know what they're getting themselves into? When bitcoin.com opens up flood gate up to 25% of the unlimited node was split with estimated time of convergence in years.
@_date: 2015-05-06 03:40:53
The thing is, 20mb limit is buying time kind of solution. If we don't kick the can far enough there is not enough time to solve the scalability issue and we will be having this kind of debate again in a few years time. By that time the number off full nodes has already increased by far more and it will be much more difficult to coordinate the effort.


The limit is a couple years old. Satoshi himself thinks that this will be eventually changed.
Lastly, here's my question to you: if not 20mb what is a good block-size to you? If you choose to endure the limit (hit the 1mb), how long do we need to 'suffer'?
@_date: 2015-05-27 01:38:47
If it comes down to it 20MB fork will plays out in the same manner. The wealthy's  (e.g Coinbase, Bitpay) opinion will carry more weight the difference is that this time instead of 0/1 decision we have a compromise
Edit: What's interesting from this proposal is that Coinbase can proof to their customer that they are making decisions that will benefit their customer (Not sure how this works though, maybe can chime in?)
@_date: 2017-02-25 07:51:12


That's why SF is preferrable. The way I see it bitcoin can only take at most 1 more HF before it is frozen forever. A lot of people actually like immutability.


And now how are you going to set the AD? That will prevent you from accepting low-conf tx, just like what happen during bitcoin.com snafu. Customer will be complaining that they will see their tx in the blockchain but your node is not seeing that.


So until you realize that you need to change AD or EB you can't accept any tx. Customers will be angry. 
We haven't even consider the possibility of miners engaging in predatory behavior (purposely tricked other miner/merchant to extend the wrong chain).


And it appears from bitcoin.com incident BU's stakeholders doesn't understand what its software entails. If even they can't understand it who do you think are going to educate other people? Even most merchant understand the risk enough not to use it in production. 
Me, myself who spent quite sometime understanding consensus system can't tell the correct EB/AD setting for any particular use case. There are just too many variables.
BU seems to run on the idea that "God named Schelling point will make everything OK" while ignoring all the consequences
@_date: 2017-02-15 07:07:42


The problem is like global warming, it is obviously an issue but it is a slow moving one that there is no political willingness to do anything about it.


Bandwidth perspective:


I disagree with him though. Nielsen's law say the growth is 50%, so even then we still end up with slightly less than 1MB.
Beside, I got a little bit something of my own here. This is what causes baseline sync time will drift further and further, UTXO growth:
UTXO grows 60% last year. [Sergio says HDD storage grows by 40%]( Edit: Looks like he was basing that on Kryder's law though, that is a prediction made in 2005, from the chart we can see we have experienced slow down since then.
Memory costs actually increase last year.
@_date: 2017-02-23 13:18:53
Let's say during the upgrade from EB1 to EB2 25% of the hashrate puts EB2 on their coinbase. This time someone from the 75% can produce 2MB block just to screw with the 25%


No, the security is not measured in USD but in money supply.
@_date: 2017-02-28 18:21:10


The problem with that kind of soft fork is that it is actually as politically difficult to accomplish as hard fork to increase block size.
@_date: 2017-02-28 08:48:22


What if 100% mines chain without 21M limit? The same gain is enjoyed by everyone after all.


They have no choice but to follow if miners are the only one running full node.
@_date: 2017-02-11 11:36:38
UTXO grow faster than technology means that the current practice is unsustainable. After that being pointed out you just doubled down. You know who else do that? Climate change denier.
"It doesn't matter that the weather is getting warmer, human can survive until 70C/158F"
@_date: 2015-05-06 02:28:14
You are forgetting something. Just because there is a 20x change in Block size limit doesn't mean that suddenly everything will be 20x higher. The change will still be relatively gradual as the userbase of Bitcoin expands and you still can catch up as the technology advance (which is what the blocksize increase is counting on, not pretty but that's what we have).
So why do we need to increase the blocksize now if the limit is not yet reached?
Because it will be harder down the road. A hard fork requires everyone to change once we started seeing 1MB Block. As bitcoin usage grows, the number of full nodes that needs upgrade will increase and in which case it will be harder to coordinate.


That's assuming Block is full all the time, which is not true at all. Even now the maximum block size reached is only around 0.5MB (and is very seldom seen). The thing is we can't tell when we will first start seeing 1MB Block. Better to get prepared rather than getting caught off guard.
@_date: 2017-02-12 00:40:50
Depends on how you look at it. Coinbase says P2SH doesn't offer high enough n for their cold vault multisig (but they never tell what their n is)
@_date: 2017-02-10 09:10:35
Well, to be fair Satoshi made the same mistake of assuming that the technology will overcome everything. 


(Bonus irony point from the same thread: Gavin being reasonable
If I have to guess where Satoshi went wrong, these are the two words I will use
**Thermal Ceiling**
Satoshi, having lived most of his live in 80s-90s experiences scaling in both **speed and capacity**. As you made the circuit smaller you can get scaling in both transistor density and clock speed. That's how you go from KHz-MHz-GHz. The problem is as you increase clock speed you dissipate more heat and at certain stage you reach the stage where heat transfer in Silicon can't help you anymore. That's why CPU clock speed and memory throughput stuck where they are. Interestingly HDD tech experience the same thing, capacity increase with better media but r/w throughput hit the limit with mechanical performance being the bottleneck.
Of course you can be clever with parallelism (e.g pipelining, branch prediction in CPU) but it just simply can't be compared with raw speed scaling because by being clever you will introduce overhead somewhere.
Imagine if we actually have 1000x increase in those parameter (memory/HDD throughput, CPU clock speed) I think we won't need to worry as much about let's say about UTXO growth (core-devs can verify this?) because the bottleneck is now in bandwidth and bandwidth scaling is relatively straightforward.
@_date: 2017-02-28 13:55:28


I am going to say sorry but Bitcoin has a motto of "Verify, don't trust". So it is up to you to educate yourself.


I've posted over there before and I've posted over here, and I've been censored both time. But at least over here I can normally trace down what caused the post to be censored and repost. Over there I've been rate limited so badly that I can no longer correct misinformation.
@_date: 2017-02-02 17:19:33
The main problem with HF is that it leads to centralized decision making. I mean sure, Core devs can just say one year from now there is a hard fork. But that means that Bitcoin is no longer decentralized because now Core now takes leadership position, something that they refused to do (for the right reason too). This is in contrast with Ethereum for example, where all the decision making is done by Ethereum Foundation. Sure, it is easier to do hard fork but as a result it is no longer decentralized. I would say the end result is pretty bad with not enough external party scrutinizing the source code. Now all the responsibility of reviewing lies with the Foundation (for geth/solidity).
One of the main problem with decentralized system is the difficulty of making major decision (which, in turns give rise to advantage in immutability). For example, with SegWit Core devs didn't just say "Let's do SegWit!". They did seek feedback from lightning dev, joinmarket dev, wallet dev, exchanges, node operator etc. Only when all the major stakeholders green-light them does the "Core Roadmap" written.
Even then currently there isn't enough support from the miners.
@_date: 2017-02-28 09:30:42
That means their attack is only limited to how long they can sustain the operation without revenue. All of my tx has ~25,000 conf behind them. They can't steal it unless they can sustain that long without getting a single penny.
Worst part is this can be defeated by simply putting checkpoint and subsequently changing PoW 
@_date: 2017-02-15 06:29:39


And like I said Luke-jr's 300kb is not any easier than 2MB.




What majority? I thought we are talking about technology growth? And Luke shows with data that the current growth is faster than the technology. This is not voting, this is real world data. 
@_date: 2017-02-02 10:53:30
It doesn't matter if it reaches 100%. If they actually produces &gt; 1MB the block it will be orphaned by my node. The question of what happen then is equivalent to what happen if miners produces &gt; 21M bitcoin.
@_date: 2015-05-26 17:19:27
Based on 
Looks like Peter Todd is 'for'. Greg and Pieter doesn't seem to object, although I'm not really sure whether they have spent some time studying it since then. Unlike median of past block size, this proposal doesn't have miner-only loophole.
I saw Mike says 'a bad plan is better than no plan' (Link Pending). So probably we can have consensus around this?
@_date: 2017-02-28 10:41:30


Again, this is the premise of our original discussions. 


It isn't when everyone is running an SPV.
@_date: 2017-02-02 17:37:19




The network as in the miner? Because 50% of the nodes does support Segwit. Well, imagine their surprise when their chain doesn't have value. Even Coinbase is not insane enough to support Unlimited. 
@_date: 2017-02-09 14:20:34
UTXO is growing faster than technological growth. Not something to be taken lightly, even a constant factor is quite deadly.
@_date: 2017-02-27 09:52:31


I don't understand. Can't you just wait until the slower chain catches up with before you replay them? (assuming malicious actor, and not replay-by-accident)
I still feel safer with CBAH though. It minimizes the risk if, let's say 50-50 hashrate split.
@_date: 2017-02-28 14:43:27
Yes, so long as we have consensus and provided that there is a long lead time there's nothing to fear. But it is really hard to sell a hard fork when all it offers is "increase block size". The hardfork wish list itself is quite long:
And seeing how hard it is to activate Segwit this is probably the last chance we have to do a hard fork.
@_date: 2017-02-09 12:06:56
There is no good default value. Especially when it can change in the future when miner at their own whim change the block size as they want. This is the reason why the idea is ridiculed.
@_date: 2017-02-17 07:32:40


Here's what I think a better analogy. I worked in semicon. When you reach certain feature size 193nm litho tool will stop working so you need to upgrade to 193-i. People can't just complain that 193 can still do the job. No, it can't (at least not with acceptable scrap rate). That is just plain physics. You can't complain that "we don't have 193-i tool yet. The lead time is too long", etc. 
Space shuttle challenger is another example.
Everyone wants more capacity. We just have to do it in reasonable way.


If BU wants they can hard fork. RIGHT NOW. Declare every Segwit transaction invalid. 
@_date: 2017-02-20 11:21:19


Correction: They are against it because they can't. The codebase has diverged so much that they can no longer merge without properly reviewing and they simply don't have the manpower to do it.


Those people don't understand the reason Bitcoin exist. Had Bitcoin not decentralized it would have been outlawed. See also: Liberty Reserve. The whole raison d tre of Bitcoin is to make it harder to outlaw. 90% of cash contains cocaine, are we going to let the state confiscate 90% of Bitcoin?
@_date: 2017-02-22 07:41:06
Since miner doesn't pay for full node's operating cost they will tend to underprice their service. Miner doesn't control the blocksize limit just as much as they don't control supply of Bitcoin.
@_date: 2017-02-28 08:32:59


A terrible misunderstanding of how Bitcoin works.


With non-mining node gone. The economy left with no choice but to follow the chain.


If by everyone you mean the miner? From which there are only ~20 to choose from. Take that one out and you are left with less than 1% serving you.


Uh, wrong. You will need to do recreate the chain from the point where they first made the transfer. That would mean lost revenue




Edit: Numbering
@_date: 2017-02-25 07:59:05
Oh, yeah. There's that also. I think he already left though :(
@_date: 2017-02-14 15:20:07


Lived in third world country. Average per month income $300. A lot of people having no issue saving that amount of money in 1 one month


You just said $10-$100. Without government making barrier of entry it is doubtful it is any more expensive. What do you need? Just a pc and a one time fee to make on-chain transaction. You think that will be more than the cost to register a bank?


Economies of scale works against you when you are running hot wallet. See also: Bitfinex.


That just means block space will grow more and more limited.


CDO is not cryptographically guaranteed in the first place. 


And your long term scaling solution depends on technological growth like cocaine addict.
@_date: 2017-02-12 16:50:30


Assuming no one abused the system. Take a look at the Ethereum's chart below.
There's a bump in September-October and November where an attacker run DoS (miner then run temporary soft fork to limit "block size"). The DoS was bad enough to make Ethereum's economy comes to a grinding halt.
To fix that in the end they need to break immutability.
The reason block was not full was because there was less incentive to attack it. Now with 10billion dollars market cap and multiple competing cryptos there are more reasons to run DoS
@_date: 2017-02-20 15:19:31
There **are** ways to obscure your transaction to everyone except those you are willing share your details with. Ignorance is not an excuse.
The only valid explanations are they are working with the government to undermine Bitcoin.
@_date: 2017-02-09 09:32:16


Ability to trick other miners into extending your bogus chain so that you can reverse transaction or make them lose revenues is not "for shits and giggles".
@_date: 2015-01-30 00:39:53
Hmmm... The implication is more far-reaching than I thought. A disgruntled employee can use it to leak a trade secret....
@_date: 2017-02-03 07:59:21


I support Segwit and I am not happy with it. I am not happy that I spent the rest of 2016 facing full block every now and then and now I am not happy big blocker campaign to block the fastest way to a capacity increase. Segwit is a compromise. How hard is it for people to understand?
So now I am starting to think 1MB is actually not a bad idea after all. Big blocker already lost all of my good will.
@_date: 2017-02-25 18:43:32


Peter Todd actually develops solution. Who says anything is impossible?
@_date: 2017-02-28 10:27:13


Uh, no. If all 20 miners are now regulated and only miner runs a full node it is far easier to create invalid block (e.g set the script rule for certain address to always return true when the output is set to certain address).
You don't need to withhold a few hours or days now that all SPV will trust you.
@_date: 2017-02-14 23:30:58






Malleability, sure. Without quadratic hashing fixed you can't scale beyond 1MB.
@_date: 2017-02-05 23:34:00
Support one side, not supporting another side = preference.
@_date: 2017-02-09 14:36:30
Merchant needs to use full node. SPV wallet without fraud proof has no economic power.
@_date: 2016-03-09 00:56:04


Eh, that's because you only quote part of the whole statement. The original one read:


Although I'm not really sure about the conclusion because I'm not really sure VPS pricing these days:


@_date: 2017-02-06 09:04:17
People's transaction getting reversed. 
Run DoS transaction forcing another pool to be unable to include transaction ( [happen in Ethereum BTW]( )
@_date: 2017-02-22 16:04:27


Worked in semiconductor here. 
Moore's law is already broken (it is still growing but the blockchain grows faster)
@_date: 2017-02-27 22:37:13


Sure, so long as you understand that miner is not the only one who dictates supply.
@_date: 2016-03-01 18:27:05
Last time I used blockchain.info I used (long time ago though)  to access. Is that no longer the practice?
@_date: 2014-09-27 23:14:56


How do you know whether the wicker wallet still belongs to me, or for that matter the nylon? It might belong to some other person or merchant. 
Also merchant is not stupid enough to use the same address every time.   
If it is so easy to track the way Bitcoin moves all Bitcoin thief would have been caught by now
@_date: 2017-02-09 14:05:13
And what are you trying to say here?
@_date: 2015-05-10 16:42:28
Take a look at my overview if you are still interested in my reply
@_date: 2017-02-09 18:31:08


For Bitcoin that's the end game. That's the whole point of "Be your own Bank"


If you want to become Visa invest on V, not Bitcoin.
@_date: 2017-02-11 15:32:18
Man, you're being too obvious here. I was going to play a little longer. Hehe
@_date: 2017-02-25 06:17:48
That's not true. SPV can't verify 21M coin, which is one of the most important thing. SPV also can't help to verify transactions unrelated to them as well.
@_date: 2016-03-01 18:19:55
Pretty strange though since blockchain.info doesn't have similar vulnerability. 
Perhaps they have different certificate management practice?
@_date: 2017-02-22 10:51:09
The more active you are in the social media the more you act as a lightning rod. I'm not sure if you need me to look for evidence for nullc or luke-jr as they are the one who bears the brunt of the attack(although I remember that you seem to be in denial of this last time).
Even Johnson Lau and Alex Morcos have been affected.
Personally I've been asked (in PM) not to mention some of the more active Core devs on Reddit out of concern that they will be the next victim.
@_date: 2017-02-11 14:55:58


Which, in hindsight was the wrong thing to do. BIP17 is superior over BIP16.


You mean the side that was OK with 2MB increase until the other side's 2MB increase solution was ready?
@_date: 2017-02-22 11:11:36


Just happen to be in the front page.


You can add Mark Friedenbach to the list.
@_date: 2017-02-22 15:22:13


Of course you can. You just need to trust miner not to confiscate coin. This is still more secure than SPV, at least you still can verify 21M BTC limit. And it is still more secure than Ethereum's endgame, which is trust-your-friend-to-get-you-latest-UTXO. 
If we want to get people to run full node there will be some trade-off.
Finally like I said, you still can bootstrap the old way but you don't need to if you don't want to. Optionality.
Here's Mark Friedenbach describing it:


Where did I imply that? I only compare SWSF vs SWHF.


And you're forcing all the devs who might be working on other things to work on the HF. I mean if you want a centralized decision making it is fine but that's not how Bitcoin works. Core devs have repeatedly made clear that they don't intend to position themselves as a leader. 
Good think about SF is that it is optional. If people don't like it they can just leave it alone without splitting the chain.


You're trading off less SPV proof for readability. It is comparable.
@_date: 2017-02-06 08:41:55
XThin already out nearly a year ago. By then block propagation is no longer an issue.Now they're focusing everything on that front, ignoring the fact that bottleneck just shifted.
@_date: 2017-02-22 05:39:03


Lived in 3rd world country. Everyone can shell out $10.


Maybe you should listen to Gavin


$10 too expensive for you?


You can only donate high amount only using Paypal? Last I heard Paypal is still a slave to the government and doesn't allow irreversible transaction.


Like donating to Wikileaks?
@_date: 2017-02-09 18:10:06


The risk is unknown. It is highly dependent on people knowing what is the correct EB/AD/ depending on miner's setting. Unless you're expecting everyone to run a simulation every time miner change EB/AD. For example during transition to 2MB what is your EB/AD recommendation and what is your suggested  If you straight away put 2 you will be at risk of someone creating a single 2MB block and someone building on top of their blocks. If you put at 1 you are at risk of being left behind. Now you can't process automatic transaction without watching the network like a hawk. People are not all computer engineer, running simulations. Just to give illustrations of the level of ignorance up to 25% of the unlimited nodes needs 19 years to catch up with the rest during the bitcoin.com snafu. Now you expect this ignorant people to explain how to set EB/AD/ required.
@_date: 2017-02-20 07:07:28
Sounds like you are no longer coherent there. Are you having a stroke? Need me to call 911?
@_date: 2017-02-23 14:13:45
What's with reducing difficulty? I never said anything about difficulty. I am talking about eliminating competitor from competing with you on the next block.
@_date: 2017-02-23 13:20:45


Not only empty blocks. SPV mining is the cause of this. 
@_date: 2017-02-23 12:52:08


Uh, no. You will be at risk when you're not paying attention either way, especially when miner not running the same EB


Unless you're talking about catering to miner only. Which in that case makes sense. They have forgotten that Bitcoin meant more than just miner.
@_date: 2015-05-12 06:44:27


Well has it tested (although with 24 seconds block), see below:


Like I said to get 1 hour security you will need to wait 1 hour regardless of block rate. Personally I don't think 2 blocks (@ 10 minute block rate) is enough for car purchase, I certainly would wait for 6 blocks if I sell a car. Like mentioned below the only use case for higher block rate is for micropayment where only 1 block confirmation is required(current Bitcoin has problem with this because sometime block can be found in 1 minute at one time and the 1 hour the other), in which case there is other suitable solution, like micropayment channels.
@_date: 2017-02-18 17:07:00


And wumpus, and Cory Field, and Suhas, and Alex, and Johnson Lau....


LIKE I SAID DID YOU COUNT THOSE THAT DO REVIEW??!!


Says the guy who only quote one small part of my reply.
Rage quitting now? Go ahead, follow your idol.
@_date: 2017-02-09 18:15:52
Not something that would cause consensus failure isn't it? It's not even a bug if you put anything above 550 it will be treated as GB, not blocks, it's documented here:
So maybe RTFM next time?
Edit: LOL my comment downvoted and the original deleted. For posterity OP claims he found "two year old bug" in Bitcoin Core:
@_date: 2017-02-09 20:39:21


Wrong. Imperfection caused will also be permanent. That is how we end up with quadratic hashing and malleability. In this case any imperfection will result in inability to retain 21M BTC limit.


Soooo capacity increase is not urgent? Sure, we can wait.
@_date: 2017-02-14 14:39:52




This is a one time fee. A typical remittance using WU/SWIFT currently use that amount of money. I doubt anyone can't afford it. If you can't (or it is uneconomical for your use case) you probably just need to save for a longer period of time. Bitcoin was never practical if you are living paycheck to paycheck or perpetually on credit.


Why is everyone keep on assuming hub and spoke model? Being a lightning hub takes less capital than being a bank. You don't even need to spend capital on advertising. The software will find one for you.


[Except for slowing technological growth](


And Lightning is not one.
@_date: 2017-02-23 15:58:55


How long do you think it takes to detect the attack and change the software?


I am profiting from my competitor's loss. Why do you think [dumping]( is a thing?
@_date: 2017-02-11 15:11:59


And my point is contentious change won't result in optimal solution. 


Sure, you do. Think harder.
@_date: 2017-02-14 12:37:24
Ever written a scientific paper before? First you go with background, motivation, and scope. 
Background describes what is the current situation. Here's the background on the whitepaper.


trusted third parties to process electronic payments. While the system works well enough for
most transactions, it still suffers from the inherent weaknesses of the trust based model.
Motivation is what you meant to achieve. Here is the motivation part of the white paper.


minimum practical transaction size and cutting off the possibility for small casual transactions, and there is a broader cost in the loss of ability to make non-reversible payments for nonreversible services. 
Note that the motivation is **not** always achieved. This is the reason why so many pop-science magazine always say so-and-so scientist manages to cure cancer while what actually happens is that they **pave** the way to it.
The scope mentioned how the paper helps to achieve the motivation, which is described below:


Again, this doesn't mean what motivates the paper will be achieved. This is just the first step.
@_date: 2017-02-11 09:43:50


You run a full node? Publish your data here. This is something easily verifiable.
If you don't run one you have no say.


You're saying he gets this out of nowhere?
Bring your own witness with testimony.




Yeah? Really? If you're going to lie, be consistent.
@_date: 2017-02-09 08:58:25


Uh, no. Current system doesn't have an upgrade mechanism. BU proposes to change that to something hideous.
EB/AD doesn't even make sense. Change that to Block size/Flag day and you have something reasonable. But no, they're too stupid for that.
@_date: 2017-02-09 18:54:06


Now guess why BU doesn't have merchant adoption except for Coinbase?  Because no one can. Even Coinbase might just be bluffing, they missed the replay attack after all.
@_date: 2017-02-20 10:59:51
Even with pruning you will still need to keep UTXO. And it is growing by 60% last year.
@_date: 2017-02-23 17:34:40
Why would anyone wants to increase blocksize from 1MB? That will cause loss of decentralization?


@_date: 2015-01-20 03:49:09
Bitcoin's source code?
@_date: 2014-04-24 05:26:15
I've seen this argument used a couple of time to defend the PoS but I have problem accepting it. I think that when we are discussing wealth inequality it is not ratio that matters. But rather it is the difference is what actually matters.
Let me give you an example. Person A owns USD 1 million. Person B owns USD 10K. Let's say mining pays out ~1% of your total worth every year(very highly simplified version of PoS). Person A will get USD10K a year just by doing nothing (well technically he needs to run a PC but once it is setup everything is done). That is the total amount of worth of Person B. Meanwhile person B is (probably) struggling with all the bills, Person A obtains his total net worth just simply by owning coins. Is that really fair? I don't think so...
Compare that to PoW mining. Miner is actually doing work. They need to maintain their equipment, keeping the equipment upgraded, ensure the uptime, fending off all the DDoS etc... Do they earn their share? I'd say yes...
@_date: 2017-02-09 09:23:18


@_date: 2017-02-23 19:13:15






No, there is another reason, which is I could trick a certain person from accepting payment on one chain that I know for certain will be orphaned. Example: During 75-25 EB1/EB2 split I can make payment in a 2MB block that I know with reasonable certainty will be orphaned. This is what you should be afraid of.
@_date: 2017-02-25 18:11:03
1. Do you understand what is currently the biggest objection to that?
2. Do you understand how his work that I link related to that objection?
If you are not willing to educate yourself at least please don't spread misinformation. 
@_date: 2017-02-08 14:21:48
By limiting the possible amount of non-broadcasted transaction inside the blocks. If a tx is not broadcasted (e.g not inside miner's mempool) miner need to re-verify it
@_date: 2017-02-03 15:05:52
No, but I think after ETH/ETC fork there is still ~7500 nodes left
@_date: 2017-02-25 10:28:30
Tell me how?
@_date: 2017-02-10 12:48:34
No, he runs it to ensure no one inflates his 21M Bitcoin or attempt to confiscate his coin. (or alternatively to run his own lightning node if he is interested in spending them)
I'm running one right now just to ensure no one fucks around with the chain.
@_date: 2017-02-11 17:26:06


If both solutions result in 2x tps why do you care so much?


[It is being worked on, are we going to wait until then?](
@_date: 2017-02-03 06:31:11
Eh, so it doesn't require Segwit's script upgrade capability?
then why did he say


Just because of uncertainty in soft fork consensus?
@_date: 2015-05-11 03:12:59
I'm a supporter of 20MB Block but I'm also a believer of 'not everything needs to be in Blockchain. Here's reason why I believe 1 minute block is not as relevant as 20MB block:
1. The change is more dangerous because it will take effect immediately. 20MB Block won't take effect until we started seeing Block bigger than 1MB. Even then the change will be gradual.
2. You will change the network usage so that latency will matter more than Bandwidth. This will probably push miner to be more geographically concentrated.
3. Unlike blocksize increase there's no pressure from Bitcoin usage. This is a change just for convenience sake.
4. There's not enough study on the increase of orphan rate (which means more wasted effort from hashing). Ethereum can support less block time because they allow 'uncles' so they create less orphan. We don't have such a thing for Bitcoin.
@_date: 2015-01-19 05:35:20


Are we reading the same post? He has already explicitly stated the opposite:


@_date: 2015-01-28 13:20:42


Just because they can doesn't mean they will. As people earn more they will tend to spend more. 'Richer' people tends to either think:
1. I can afford to buy 'insert expensive things here' now. Probably I should do so now, or
2. Life feels boring doing the same thing over and over, probably it's worth doing a new venture. If they fail, well their fortune is now more distributed, if they are successful they probably have contributed to the society.
If someone actually manage to pull something like living like a monk while being filthy rich, well I'd say fair is fair. They probably deserve to get richer for being financially responsible.


Unlike a house, you can buy a fraction of Bitcoin. You don't need to involve any debt in having some bitcoin (well you could but there's no point if you're only trying to store your wealth). If suddenly Bitcoin crash it won't create a devastating chain reaction like what happen during last financial crisis. I'd say it is much healthier this way.


Perhaps you would be interested in something like Bitshares? From what I heard that's what they are trying to achieve. I don't have the detail though.
@_date: 2017-02-23 13:38:09
Yes, but when you are profiting from wasting your competitor's time it is a question of how much hashing power you dedicate to do that.
@_date: 2015-01-29 03:31:51
Bitcoin can operate without third party, however it doesn't mean that third party cannot enter. Consider a company that provides 2-of-2 multisig wallet (one key held by customer and the other held by the company), but only broadcast the tx 1 month after the customer sign the tx (nLockTime can be used by the customer to ensure this). If the user actually dispute the transaction within 1 month the tx is not broadcasted. And suddenly, you have a debit card company that can provides chargeback.
As for credit side, personally I am not a big fan of the concept of debt. There is actually an alternative financial system that is not debt-based, like Islamic Banking:
@_date: 2017-02-20 06:25:56
Same reason as there are altcoins...
@_date: 2017-02-23 14:17:17


When they are put in charge of block size they will eliminate everyone less able than them. When you have few enough you can do whatever you like.
@_date: 2016-03-06 18:11:25


If we are talking about mining pool individual miner can move to another pool. Also since DDoS is always a risk to the mining pool I am fairly certain they have lots of trick up their sleeve to handle this.


I would say that is a pretty dangerous chicken game over there, especially since the livelihood of the miner would depend on the community trust. I believe miner would act in rational manner.
@_date: 2015-01-21 03:39:46
People always complain about trouble with Banks, but those are most likely edge cases. Looks like similar edge cases exist for Bitcoin.
Maybe you can try Mycelium local trade? I remember reading article about someone from Utah living entirely on Bitcoin a couple of months ago. Or try to use Tor Browser/VPN to access localbitcoins.com. If you use Tor Browser make sure to type in 
@_date: 2017-02-01 04:45:16
2nd person to use Bitcoin.
@_date: 2016-01-29 15:02:47
Rockets eh? Two can play the game ;P
If I learn anything from KSP it is that the thing about rocket is the first stage is the one who will do most of the heavy lifting because
1. You are too close to the planet that the gravity is still very big.
2. You are still inside the atmosphere so drag is still significant.
As you go higher you will have more option for example 
1. If you are out of atmosphere there will be no more drag and you will have better option with rockets that only perform better in vacuum
2. Once you are in orbit you can do gravity assist to push you higher.
I understand that you are trying to design subsequent stage but remember if we falter before we leave atmosphere then we are doomed. So just food for thought: Do you have enough thrust in your first stage? (Not that I doubt you but just too keep you in check)
@_date: 2017-02-03 07:55:43
Wrong comment to reply to? :P
@_date: 2017-02-23 11:42:50


You would have me believe that. If only they don't put AD in. Instead put flag day and blocksize limit. It is much simpler to implement.


How do you define traction? There is a traction to implement SegWit inside BU yet they don't do jackshit about it. 
@_date: 2017-02-11 10:37:45
Surely you won't have problem calculating UTXO growth then?
@_date: 2017-02-09 15:30:18
The node has a default setting of 1MB, no EB, no AD. That means the node has certainty of following 1MB no matter what. With EB/AD there is no certainty how much confirmation you need to wait because that is highly dependent on what is miner's setting  fragmentation.
Think about it this way. Do you think miner will upgrade to EB2 at the same time? The first miner to upgrade will be vulnerable to attack by someone who produces 2MB block, miner building on the same block and getting orphaned. Same thing with node with EB2. Similarly after majority upgrades the miner node/miner with EB1 will be at risk. The only way to eliminate this risk is for everyone to upgrade at the same time, which is completely impossible. 
Satoshi's solution is to introduce flag day, something that is not configurable in BU.
@_date: 2017-02-18 16:12:11


Speaks more about their character than their situations. Do you see any of the 100+ others rage quit?


1. libbitcoin itself already has that much. btcd has additional 20-30.
2. The only reason BU got that far is because they copy Core's code.


Again, I'm not against alt-implementation, I'm against garbage implementation. btcd, for example is pretty competent.
@_date: 2017-02-08 15:09:12


If the block size is **limited**
@_date: 2017-02-11 09:18:30


UTXO grows faster than technology. Hasn't changed one bit.


Sent on Dec 7th 2015 
What happen then?
Scaling Bitcoin Conference.
But sure, just blame Greg on everything.
@_date: 2017-02-03 16:36:49


Penalize by..... reducing block reward? Well, enjoy your perpetual inflation...
@_date: 2017-02-22 20:32:24
Bitcoin's early days was marked with people mainly using it as a currency in DNM. Transition just happens faster with technology.
@_date: 2017-02-23 14:15:16


Same thing. Fund loss.


I could find more. Take a look at the amount of "I am not against layer 2 solution shit" just last few days.
@_date: 2015-01-28 09:36:04
Not immediately, no. The first thing you check when you receive your paycheck is how much is in it? Without a constant to compare it to it would be difficult to see whether you receive an increment or a pay cut.
@_date: 2017-02-09 09:19:16


Not an adaptive one.


Can't play victim now, can you? I'd really wish you guys would just go ahead and do that instead of pestering me all the time.
@_date: 2017-02-28 09:12:59
That's the initial premise of this discussion remember?


@_date: 2017-02-25 05:09:51


You can't. That's part of the deal.


Except no client offer that feature.
@_date: 2017-02-06 05:16:53
Also you need to take into account that the network is more "secure" because of block rewards.
@_date: 2017-02-17 06:24:09
Of course it is silly. Donald Trump becoming a president is silly. Brexit is silly. The whole fiat money business silly. The 2008 mortgage crisis is silly. The fact that people keeps on giving money to loan America even though they consistently runs a deficit is silly. As user base grows you can expect anti-intellectualism to grow. 
Gone were the days when knowledgeable pool operator like eleuthria or Tycho reign. Only slush remains.
To be honest I'm not sure if the meeting is net positive or net negative. Back then Segwit is not yet ready, ETH/ETC haven't split, Lightning Alpha not yet released so chain split is more likely.
@_date: 2017-02-20 19:39:01


Core dev doesn't own but I bet you'll come back next week with the same statement.


The first reply to Satoshi's mail is this doesn't scale.
Hal Finney backed the notion
If you think otherwise then blame your own ignorance.


I spent more running a node than in transaction fee last year.


Yeah, what an evil guy, right? Giving solutions?
@_date: 2016-03-02 08:20:06


Isn't that a bit naive? How is it supposed to deal with this part of the article on the Coindesk?




Locked funds changes some part of the equation (particularly this kind of attack which only requires attacker to lock fund, and not lost it).
@_date: 2017-02-14 06:22:26
Here's another counterpoint. If Bitcoin was meant to be spent why 21M limit? He could have made permanent 1% inflation.
@_date: 2017-02-21 13:04:08
I think there is a valid concern that someone used the newly bought account to scam people. So all in all, good to know.
@_date: 2017-02-25 05:35:46
Yes but for normal block propagation you will still need the signature, otherwise miner might confiscate coin, so you need two kind.
One with signature, one without. I don't see that in any competing implementation. They seems to only remove it from the calculation . But it is still being propagated.
@_date: 2015-01-29 04:18:15
Or for more efficient setup, a 2-of-3 multisig address can be used(escrow). One key held by customer, one key by merchant, and one key by third party. If both customer and merchant happy, third party won't even need to come into play.
@_date: 2016-03-02 09:30:17
Just a difference in terminology I guess. Not really sure about OP but normally when I talk about 'routing not yet solved' I am also talking about route selection on top of route finding.
@_date: 2015-05-06 03:27:24


I don't think securing enough hash power to produce 20mb block is trivial. Furthermore 20mb will propagates much slower than 1mb block. If everything else fails I will rely on the 'goodwills of the miner' aka 'it is in the miner's interest for Bitcoin to succeed' (Last one is the weak-ass of argument I know).
Here's my take on this: I know I'm choosing the lesser of two evils. Everything in this world is a trade-off. How 'secure' is secure? How 'decentralized' is decentralized? The way I see it Blocksize increase seems to be a better option (kick the can down the road, buy some time).
I'd really wish one of you core-dev that is against this would come up with alternate plan opposed to Gavin. Right now all I'm seeing is increase vs 'no plan'. I'd really need a concrete plan to judge how feasible it is. If you aren't going to increase the block size what do you propose? Stunt the growth? Let the fee increase? How high must the fee be before we increase the block size? For how many years? How long does it took to solve the scalability issue (e.g LN)?
@_date: 2017-02-20 00:07:22
Uh, no. The whole purpose of multiple implementation is to flesh out spec, to make it easier to review, and to innovate in terms of performance optimization. When you are mining (or for that matter for any real world usage) you should be doing that "behind" one code.
@_date: 2017-02-09 14:45:28
Except for Dev's incompetence, you mean? Every single alt already added SegWit except BU.
@_date: 2016-03-02 09:04:39
A little bit flaky I think. Even with Bitcoin I sometime have difficulty sending non-standard tx (having to disconnect and reconnect multiple time). With LN this issue seems to be a little bit worse because I cannot disconnect and reconnect at will since there's locked fund involved. 
Personally I think routing should do more than just find route but also find a reliable route.
@_date: 2017-02-23 13:51:53
Let's say we have 75-25 split of EB1/EB2. By producing 2MB block EB1 miners can force all EB2 to mine on a split chain until their AD runs out. That means the EB1 chain will have 25% less competition until then. 
@_date: 2015-01-30 00:36:48
I thought Coinkite were using them? Libbitcoin ran just fine for me though.
@_date: 2015-01-28 10:40:35
Probably something like Bitshares will work. However all things considered, I'd still prefer Bitcoin.
@_date: 2017-02-20 06:48:49
Nothing to do with the inputs. ACK=merge, NACK=don't merge.
@_date: 2017-02-23 17:16:01


Uh, it does. You are making the system inherently less secure for no good reason. Right now any merchant can be reasonably certain that 2-conf is as good as final. With BU that guarantee is gone. 
I mean if you want miner-controlled blockchain BIP100 can do what you want. There is no technical drawback to that.


Actually I find it very funny that people who supports BU keeps mentioning "Schelling Point". That's the same words Vitalik used before ETC slaps him in the face.


Like bitcoin.com disaster? This statement is without any base, just like a leap of faith. It will require miner to upgrade **at the same time**. Even in critical patch like BIP66 it took miner 2 months to upgrade. The worst part is ViaBTC wants to have only 75% of hash rate only to activate.


So what are they working on now? You can't tell, because it is a closed door meeting.
@_date: 2017-02-25 05:57:16


That is a significant misunderstanding of how Bitcoin work. To spend output you need to answer a question. utxo-that-is-soon-tobe-txo is the question, signature is the answer. So you only need signature during spending. To be a properly validating node you only need to store the question (utxo), the answer is only need to be provided once.
@_date: 2017-02-23 15:46:37


That's the key point. For 10 hours, maybe not. But forever, yes. How about until your AD6 runs out and with significantly less difference in hashrate? How much advantage can you get? This is even better than selfish mining.
@_date: 2016-03-06 18:01:48
Reading political undercurrent is definitely not easy but right now my impression is most miner will defer their judgement to exchange/core devs. As long as both sides agree I don't think miner will block it. 
Also since mining has Poisson distribution the probability of the fork getting activated with less than 95% hashpower is more than 0...
@_date: 2015-05-11 04:46:16


Here's my opinion. Short term because of (1) limit increase should be the way to do it. Long term efforts should be more directed towards micropayment channel rather than changing critical security parameters.
@_date: 2017-02-09 09:44:45


1. Actively attacking my competitor is rational.
2. It is only large sums of money because there is inflation now. Without inflation it is transaction fee vs the amount transacted you can cheat.
@_date: 2017-02-08 16:02:35
Sure, that just means you can almost double your income simply by including tx fee
@_date: 2017-02-27 19:41:42
You mean one side was adjusting the fuel-air mixture ratio and stroke length for better performance on top of adding entertainment system while the others just simply opt to change only the transmission while keeping the engine the same.
@_date: 2017-02-21 16:43:08
Just for you:
Why would you delete that, right? Attempt at being sarcastic backfires?
@_date: 2017-02-12 08:19:21
Lay off on the weed dude. Ghash.io participate in double spending (and possibly selfish mining). F2Pool, Antpool, ViaBTC, and I don't know who else is doing spy-mining, causing July 4th incident. Bitcoin.com running unlimited unintentionally creating an invalid blocks causing all unlimited clients getting banned.
@_date: 2015-05-09 02:43:11
You can take a look at the implementation of BIP16 vs luke-jr's proposal.
@_date: 2017-02-25 10:26:36


Like I said, the same thing preventing this from happening is the same thing preventing 21M limit being lifted. SegWit will happen I'm telling you, even if it takes 25 years to do that.


Not sure about that. What if BU or some other shitty alt implementation  manages to pull it off?


Lead maintainer is a janitor, not a leader. He sees people NACK he doesn't commit. He sees people ACK he commits. Just need to make sure that the reason for NACK and ACK is reasonable. For the time being I see that as what Wlad is doing.
@_date: 2015-01-08 07:34:18


One example of improvement is the fact that most stock exchange doesn't open 24 hours.


It may not be obvious now but to get the tx in blockchain you will still need to pay the miner (who will only accept 'pure' bitcoin, not colored one).
@_date: 2015-01-22 06:27:44


I did not know that BitCoin is using secp256k1. 
I am surprised to see anybody use secp256k1 instead of secp256r1. 
Way to go Nick! This time you paste only the part of Dan Brown's opinion that supports you. For those of you that is not familiar you can take a look at  (since bitcointalk appears to be down). Basically Dan Brown has more neutral opinion on secp256k1 as summarized in the last paragraph:


TL;DR secp256k1's parameter appears to be chosen random enough to be secure as according to Mr. Brown
I'm aware that this is probably ad-hominem attacks but considering his last paper on Bitcoin gets destroyed by DeathandTaxes I would hardly consider this guy as an expert:
(Sorry for the Google Cache, bitcointalk is down)
@_date: 2017-02-03 04:54:44
I was referring to this part:


Signature aggregation is his brainchild, which requires SegWit
@_date: 2017-02-09 15:53:58


And without doing so BU solution should not be pushed to the mass. This is just the tip of the iceberg though.


The fact that miner can make change is irrelevant. My point is the relative security of default value proposed in the software can change at any time because miner can change their block size setting at will. This is my entire quote:


BU program you download a year ago might no longer be secure today. The security will be the weakest especially at transition/upgrade stage. People unaware of this will be bitten pretty hard. BU doesn't offer smooth transition for people. Unless you are assuming miner is going to put 1MB forever. In that case I have no issue.
Core, OTOH has pretty absolute guarantee with miner and node agreeing on 1MB limit. If there is going to be a blocksize increase it won't happen by mistake (or attack)
@_date: 2017-02-20 07:26:46
Huh, TIL. Didn't know you could get a fraction of a stroke.
@_date: 2015-01-28 05:41:23
As a saver myself I can see the appeal of deflation in Bitcoin. However one thing that is hard to avoid is wage stickiness. Just like price of goods tend to drop over time so does people's earning. I believe there is a psychological effect that makes it difficult for average Joe to accept. Which is why I don't think fiat will be going away any time soon.
@_date: 2015-01-19 05:49:45
Nope, he never imply that. He just stated that there is high traffic and it is important to get the facts right. As he has already stated otherwise it is no longer 'certainly what you're implying'.
@_date: 2017-02-28 08:18:48


Neither does on-chain.


That's why there are work in the pipeline like signature aggregation, weak blocks, MMR TXO, etc. But without that it is not prudent to increase block size.
@_date: 2017-03-18 17:17:06
*sigh* Do you realize that there is a third group all along? The "Digital gold" guys. These people are not exactly excited about Segwit and a true enemy of BU. They really don't want to change 1MB at all. They have been quiet because they are getting what they want so far. Pro-segwit people are actually the middle ground.
@_date: 2017-02-10 10:26:35


This one, which trigger everyone to use Ghash.io


Because of the relay network. That was how the network brought back to normal.
@_date: 2016-03-04 14:21:28
Yeah, my brain somehow filtered short story part (perhaps I associated the contract part with ZKCP as I recently read that). Overall it is pretty entertaining, it is just the initial shock that hurt (sort of the same as the feeling when you are blindfolded and someone telling you to drink a milk when they actually give you orange juice)
@_date: 2017-02-22 07:37:56
Yeah let's ignore everything about lightning.
Calling blocksize limit protectionist is as much as calling 21M limit protectionist. Why do we protect all the hodler?
@_date: 2017-02-25 07:10:43


Now you know why BU doesn't gain adoption among merchant? Because they don't want to figure out EB/AD setting.


25% of the non-mining nodes was using AD of 99999. 


See above.


At least there isn't anyone suggesting to change the value in their software. Just because people want to commit suicide doesn't mean that doctor should help them.


Yeah, because users are always at fault when it is actually the developer's job to minimize this kind of thing.


Eh, actually Core chain will be worth more. What innovation do you have on BU side? I don't think people over there are even aware 2MB block doesn't means that it will always consume 2x resource.


Decide at which block you want to fork, and hard code that into the software. At least that doesn't require you to be awake when the transition happen.
@_date: 2017-02-11 17:52:30
But you're ok with Classic but not with Segwit?
@_date: 2014-07-25 00:17:22


Yes like I said the solutions won't be free. Personally I'd rather not see off-blockchain transaction as it introduces counterparty risk already existing in current financial system. The idea of Bitcoin is to become your own bank.


I've worked both in hard drive (~1 year) and ssd industry (~5 years) and I'd really wish I can share your confidence. My estimate is the exponential growth wouldn't last longer than ~10 years. But then again, the technology visibility is always shorter than 3 years so we'll see....
@_date: 2017-02-25 18:04:00
[Still on track AFAIK](
[Why do you think he is working on this otherwise?](
@_date: 2017-02-28 08:57:33


Changing PoW does nothing when miners are the only one running full node.
@_date: 2017-02-15 06:07:33


HDD speed already reached its max with SATA interface. Memory bandwidth already level off as well. All trends point to slow down in HDD and memory capacity. 
CPU's 11nm node is late and basing on last few years improvement will be marginal.
@_date: 2015-01-28 09:46:30
I disagree here. With current inflationary system it means that there is always increase in money supply. The question is who receives this increment? Is it the poor? Nope, it is mostly the rich. Let's take the recent QE as an example. Who receives the printed money? The Bank right? The same irresponsible Banks who causes 2008 Financial Crisis. 
The poor can't do anything. If they save, their net worth will decrease over time due to inflation. If they spend they will lose it. So what can they do? They spend it on something they can't afford with the hope that it will raise in value, e.g houses which is one of the causes of subprime mortgage crises.
Now consider deflationary system. The poor can fight back by saving. Being rich means nothing if you are not financially responsible. Right now, with bailout you are basically rewarding those who are financially irresponsible.
@_date: 2017-02-28 09:47:15
1MB, some people already think that even that amount is too big.
@_date: 2017-02-09 07:26:32


Yes, and how are you planning to upgrade? Between block x and block x+1? Surely nothing could go wrong there.
@_date: 2017-02-26 14:40:19
All I know is all devs you ask will dodge the question. At least Blockstream is transparent. If you pay attention to Bitcoin development Blockstream only make up a small portion of the devs. 
Not even 50%, if there is a vote they won't win (not to mention the governance is by consensus, if 1 person said no it won't be merged)
@_date: 2017-03-19 03:34:16
Same thing, you also didn't explain about acceptance depth. Note that Segwit's explanation doesn't need to involve miner so the threat model involved is still pretty much the same.
@_date: 2017-02-09 13:06:07
Meh, I am just feeling like highlighting how unreasonable all of you BU supporters are. I don't think you guys will ever figure it out though.
@_date: 2015-05-06 05:09:18


Hopefully, the same IBLT will save us from Bandwidth problem.


Anyway, there aren't necessarily easy answers here, nor will any one tech solve the problem 100%
Right now I'm seeing that the opposition is in disarray. You/They are only telling why Gavin's proposal is bad and not why yours is better.
@_date: 2016-03-03 15:13:50
There are a lots of good reasons for don't wanting but I think some of the one you listed are bad ones:


I think it is too premature for this. Personally I am a hodler so congestion doesn't affect me too much but right now my wealth is being continuously being diluted. I, for one, would like to think it is being diluted for a good cause and I think having a fee market develop so early is against my ideal. A temporary one might be ok but not a permanent one.


The same can be said on hard fork.


Sure, I think the current 1 year is pretty reasonable.


Two side of an argument here. Yes we don't want it so easy to hardfork (e.g 21m limit) on the other hand we also don't want it too difficult(e.g pow change in case of 51% attack).


Well that is just plain bad reason. It is nearly the equivalent of an ad-hominem attack in a debate.


Yes this is a good one. Although blocksize limit won't do much to fix this. A really good fix will probably require a hard fork. 


Yup, this is a really good one. Which is why the exponential nature of BIP101 really scares me.


True, a control-freak leader will probably only attracts a bunch of 'yes-man' which is probably a bad thing. On the other hand no guiding hand also lead us to what happen today with community on the verge of fracturing.


Personally I think Wlad should force everyone to come into consensus long time before (I think Jeff raise this issue multiple times in the past). Don't release 0.10/0.11 until everyone agrees on a roadmap to increase the limit. Sure it is easy to make a decision on easy things (OP_CLTV, SegWit, opt-in RBF) but the only time leadership counts is when deciding on difficult things, like right now.
A benevolent dictator is much better system than democracy (unfortunately it is also much more fragile since no human is perfect).
@_date: 2017-03-15 18:28:37


Did you notice the node settings fragmentation before attack? The nodes version are all over the place. Some people are still running 0.12.1 or even 1.0.0 (which doesn't affect you if you don't mine). Here, take a look at this snapshot at 03/07/17:
Automatic updates doesn't explain that.
@_date: 2017-02-01 21:03:52
With HF approach you're breaking every single light clients and block explorers out there, in addition to forcing everyone to upgrade. It is difficult enough to convince people to upgrade to 0.13.0 because of C++11 and now you want to force all developers to do your bidding? With SF approach at least you're giving people time to understand and implement the change. If in the end HF is necessary there is a minimal change required. 
@_date: 2017-02-11 18:34:09
[Repeating same tired old lie?](
@_date: 2017-02-02 10:59:40
You want compromise? Why don't you ask Roger and his merry gang to fund development on fraud proofs/UTXO commitment/treechain instead of whining about blocksize? At least you are doing something productive by trying to convince people that it is safe to increase block size.
@_date: 2017-02-09 10:03:14
1. Right now miners are engaging in SPV mining to the detriment of users. That's a short term gotcha. Especially when this strategy doesn't work long term.
2. You don't need mining farm to produce a single block.
3. When 4-blocks reorg is the new normal do you think there is a long term damage? No.
4. Does it take malice to screw up the network? No. Just took another incompetent Bitcoin.com pool to split the network
@_date: 2017-03-02 17:26:41


**That's** a promise. (And fee can be gamed) by miner


No, that's only one of them (and bigger block will just lower the fee again). Others are:
1. UTXO growth
2. Block propagation
3. Unknown attack vector
(1) is pending for TXO MMR. (2) already partially alleviated with compact block but it requires testing in real world for effectiveness at bigger block, which means segwit activation. Same with (3).
Even TXO MMR might not be approved. It is still in conceptual stage. It may or may not work. Someone may not agree with it and choose to NACK it. There is no guarantee ever. 
If you want further capacity increase signature aggregation is still  closer than a hard fork (which again requires Segwit to function effectively).
So activate Segwit or no deal at all.
@_date: 2017-02-02 14:46:32
LOL, you mean like how they attack ETC? A PoW change is always on the table. OTOH How much do you think a chain that is not Lightning-ready worth? Or for that matter, a chain without light client and block explorer support (yes people, those need to upgrade too)
@_date: 2017-03-16 04:21:49
*Sigh* Again, you only need to compare with the competition.
In terms of capacity increase: Better than 2MB block both because it avoids supply shock and making worst cause UTXO growth the same
In terms of quadratic hashing: Better than limiting transaction to 100kb
In terms of malleability fix: The only malleability fix that offers signatureless IBD, avoids increasing UTXO set compared to BIP140, not whack a mole like BIP62
Nothing is better than what segwit offers.
@_date: 2017-03-18 17:27:42
You can add Antpool to the list now.
@_date: 2016-03-03 06:40:42
Eh, I don't think theymos ever contradict himself. He did say that he doesn't mind blocksize limit increase, the only thing that he disagrees with is changing that in contentious way. As in, he requires everyone to be in consensus. Although how practical that is would be another question.
@_date: 2017-03-14 14:17:50






Price drives the miner and not the other way around. People don't care so much about the 'security' of the chain, only its feature.


Possible. Median EB has not been addressed, and neither does sticky gate. All of these have been handwaved away.


All of those are possible. BU doesn't have Lightning remember? And since it doesn't have Segwit signature aggregation or Lamport is not possible.


Uh, that's not how majority is defined.
@_date: 2017-03-14 16:34:13
You do understand that undoing a soft fork is a hard fork right?
@_date: 2017-03-18 17:15:04


With node count steadily dropping and asic production in the hand of one company?
@_date: 2016-03-06 17:45:06


I still don't get it. What is the reason behind the objection to 95%? AFAIK no miners are vehemently against the increase (even if there is I seriously doubt they could be as high as 5%). As long as Core dev and pro-big-block side agrees on the code miner will just follow. As can be seen from BIP66 deployment as long as there is overwhelming consensus we can reach this number nearly as fast as 75%.
@_date: 2017-03-14 04:39:46


Price discovery. Ever heard of it?


So it is no longer majority rules then? Because if it is majority rules you should be following Core.
@_date: 2015-05-07 09:43:29
My response to you will be centered around single most important (to me) question:
Are we okay with letting the tps number constrained by the Block Size for a significant period of time?
Personally I'm not okay with that. Maybe I'm okay with seeing occasional 1MB Block for around a year (just consider it Work in Progress for Better Future, We Apologize for the incovenience). But after that I'll probably look for something else with Black Jack and Hooker. 
My reason: I've already subsidized the miner with inflation and they're charging me again for making transaction? Who do they think they are? The Government? Asking to pay tax after printing money? I'm okay once the subsidy goes down to 3.125BTC/Block, but before that? No Way Jose. 


I believe our current consensus is that we are not yet ready for this (I saw Mike Hearn's Dead Kittens).


Maybe we have different ways of solving the bottleneck. The way I do it is I hammer the  (while working on the rest in background). Reason: Whatever I do for  bottleneck won't matter if I don't solve 




This will require some sort of fork in itself that is probably more dangerous than 20mb block increase.


Here's the question. We're going to do this at some point in the future right? We might as well do it now rather than wait until the network goes 10-100x bigger. To me the shadow of 2013 fork is more real than the hypothetical decentralization-loss/miner-manipulation.


OK, we need more study. I can accept that but remember we also have deadline (at least to me).
@_date: 2016-03-06 19:30:06
Huh, you holds surprisingly moderate opinion. Normally I find that you are leaning slightly towards the Core side.
I consider myself moderate as well. Really wished that there are more of us...
@_date: 2017-02-14 08:36:57


You mean like quadratic hashing? Or transaction malleability? Or using longest chain instead of most-work chain? Or using BDB such that bigger block can cause consensus failure? Well certainly BU dev could probably compare to that.






A solid 5/7. Liar liar pants on fire.
@_date: 2017-03-15 18:22:52
You do understand the difference between sustained attack that makes temporary impact and the one that makes permanent impact, right? With compact block the bandwidth risk is already minimized. With full blocks this kind of sustained attack is really costly.
@_date: 2017-03-17 14:10:04
What I mean is replace BofA with drug dealer. There are a lot of money in there. They can spin up Bitcoin hub to compete with BofA instead of worrying how to launder money.
@_date: 2017-03-03 19:01:39
What lies? You think there's no need to study how block and transaction propagate at bigger block? Or the way UTXO grow with Segwit incentive? Or how the fee react when there is a sudden increase in capacity?
This is science, not politics.
@_date: 2017-03-16 00:02:56
Do you happen to have a guidebook you follow over and over? I keep on repeating this that I'm getting hoarse


Which is not an accurate metrics for resource measurement.


Which is why increasing block size linearly, instead of adjusting block weight is stupid.
@_date: 2015-05-11 02:43:26
I'm afraid I have to agree with you. 20MB Block is important because of pressure from Bitcoin usage. This time it is just change for convenience sake. We have to remember that change to some number in Bitcoin can have major impact on the way Bitcoin works.  At least we need to study orphan rate and stress on the bandwidth, especially the small miner's. No test (at least not any that Gavin mention) on testnet and he just throws it into the crowd. 
@_date: 2017-02-09 19:54:59
For example 75% of the miners are on EB1, 25% of the miners are on EB2. If a node put EB2 they are at risk of someone mining 2MB blocks, being extended by 25% of the miners by x blocks and then all those x+1 blocks are being orphaned by EB1 miner so they will need to increase the number of confirmation. By how many confirmation? You will need to run simulation. 
That is just for 2-way partition. 3 way partition or more will require more simulation.
Sure you can just ask to require for more confirmations but that will just piss your customers off.
@_date: 2017-03-19 10:05:58
Again, I thought we were comparing the blocksize increase aspect. Segwit keeps that hardcoded, BU added something more. How Segwit achieves that matters less.
@_date: 2017-02-26 04:32:29
Yeah, any idiot can tell you that correlation between x and y means either x causes y, y causes x, or z causes both x and y. By putting log scale he actually makes more emphasis on Bitcoin flash bubble. During bubble of course people make more transaction because they want to take advantage of it (move BTC to exchange). It's not that Bitcoin's value comes from the number of transaction but rather the number of transaction comes from Bitcoin's value.
Here's my attempt to recreate the chart in linear scale:
There's period between 2014-2015 where number of transactions goes up while bitcoin value goes down or flat (edit: A period conveniently missing from the chart). The reason Metcalfe's Law doesn't hold is Bitcoin is still primarily used for speculation.
Like Greg says, data manipulation, plain and simple.
@_date: 2015-05-25 02:03:49
Here's my thought. Based on what I have 20MB change is safe. I am, however open-minded (based on our exchange I get the feeling that you aren't). Unfortunately due to asymmetry on the proof I can't show that this change is 100% safe. 
You, on the other hand can give an example of how this change can be exploited. If you do so you can change my mind.
Right now if Gavin actually forces a Gavincoin in 2016 I will be on his side. And by then we might actually have 2 coins, which is going to be ugly for sure.
@_date: 2017-03-09 07:49:26


I never said that although other people did. In fact I was wondering why they were always silent about their funding. This makes more sense than Roger providing the funding. 
It seems plausible that it was spread purposely as a red herring. It is easier to cover up the fact that Acceptable Depth provides advantage to the miner when you claim that the funds comes from someone that doesn't have anything to gain.


Don't put word into my mouth, I've never said that. What I said is BU favors the miner, of which a subset includes Jihan (who also happens to produce ~70% of the ASIC).


Wow, you tried really hard at straw manning my argument, aren't you?


1. Bitmain provides the funding to BU
2. Acceptable depth gives advantage to miner to set minimum resource requirement to run a full node.
These are facts, and not conspiracy theories.
@_date: 2015-05-08 22:15:11


User can do this by running a full node.
@_date: 2017-03-06 16:22:16


People need to stop telling this lie (or misunderstanding, I'm no longer really sure which).


Accepting payment doesn't require anyone to mine.
@_date: 2017-03-14 05:49:41


And how do you intend to measure "economic power" ? 
Besides, It is entirely possible that in the first 4 years BU has more economic power and started to fall under its own weight and Core started to catch up with Signature Aggregation, Lightning, etc. BU will be totally wiped out by then, unless they lie when they said "support the majority".


4x you mean? Just nice the maximum limit of a single difficulty adjustment period is 4x. So after the first difficulty adjustment everything goes back to normal.
@_date: 2017-03-18 19:12:35


*sigh* the discount is to avoid UTXO bloat.... I don't know how many times I need to repeat this.
@_date: 2017-03-09 07:18:53
Which chain has more value, the one supported by people who can afford high fee (and have higher confidence of keeping 21M BTC limit) or the one supported by people who can't?
@_date: 2017-03-14 18:39:13
If there is NDEBUG compilation will fail so you can't define NDEBUG, meaning this bug affects production build.
@_date: 2017-02-23 15:02:37
Try to recalculate?
@_date: 2017-03-13 19:03:28


The problem with checkpoint is that it goes naturally against "emergent consensus". Their reasoning is that longest chain is valid chain. By checkpointing they are no longer allowing the consensus to emerge. 
This means Core's chain is actually more antifragile than BU's chain. When Core's chain is losing the worst case would be higher difficulty until the next adjustment period. When BU's chain is losing OTOH their chain is completely wiped out (And now people hodling on Core's chain suddenly found an extra stash in their pockets).
@_date: 2017-02-08 09:25:21


Bonus point: All of that are **on-chain scaling**
@_date: 2016-03-13 15:12:21


Which is why I compare and contrast the approach of the two devs. Like it or not the opinion of the devs held more weight than the user(in the case of Bitcoin even miner).


Never said they never work on it. Just said we don't have the option until at least July.


I don't think I ever said that.


No worry, we are all on the edge after these debate.
@_date: 2017-03-21 10:56:55
He was the one who pushes for Segwit activation...
@_date: 2017-02-09 12:45:25
BU add them back in:
Surprise! Parallel block validation doesn't work, just like all of their ideas.
@_date: 2017-03-18 19:46:41
There you go guys. A living proof :)
@_date: 2015-05-08 06:08:09
Errr.... I think you are looking for buddy...
@_date: 2017-03-09 07:46:26
Linked in my comment. Name other contributor if you can. I can do the same for Bitcoin Core, it is only fair that you do the same. (Note if one person is being funded by two different people it doesn't count, because moonlighting is always a thing)
@_date: 2017-03-17 13:04:48
@_date: 2017-02-28 18:55:37


After signature-less IBD is implemented signature won't need to be downloaded or stored for some of the node. Signature also doesn't need to be stored in memory whose price just increase last year. 
Even if you insist on storing the signature it can be sharded.


By activating SegWit the tx fee will go down again. The decrease in fee is nearly the same. Besides, who's to say those unspendable tx won't be split further anyway?


And we have no plan to lift the restriction in the future right?
@_date: 2017-03-07 19:26:56
I (along with everyone who runs a full node) have always been in control. That's the beauty of Bitcoin. And they want to take it away from me.
@_date: 2017-03-14 12:54:54


He was targeting the mempool. After the attack everyone increases minrelaytxfee the attack becomes less effective. After full blocks and mempool limiting in 0.12.0 the attack totally disappears.


Miner cleared them up with gmax's help and some people already taken some part of the output that the UTXO can't get back to previous level. Take a look at my chart.
@_date: 2017-02-16 04:40:52
Takeaway: A lots of alts plans to, already implemented, or even already activated Segwit. Number of alts implementing the [genius]( that is BU:0


I'm pretty sure they are at least competent enough to add a clear transition point.
@_date: 2017-03-17 14:05:59
Or Drug dealer run a hub for you. The thing  is you don't need permission to run a hub. No government regulation to tie you down.
@_date: 2017-03-19 16:02:54
You want code? It's here:
If  mining pools want they can fund development for that instead of Bitcoin Unlimited. At least Johnson Lau is more competent than BU devs.
@_date: 2017-03-17 04:51:36
Not so sure about that. I warned him that state manipulation that he did in the first HF will cause technical debt in the consensus layer. What do you know? That happens to be the cause of the chain split in the third hard fork.
@_date: 2017-03-19 03:48:07
There's the voting though. Who can vote? 
@_date: 2017-03-19 09:52:58


You have no idea how wrong you are.


No, not people with merit. Anyone. You can still be anonymous noob and still NACK something with a good reason.


If "non-expert" made decision the result is 13.2BTC loss and a remote shutdown.


Users that want something should fund a dev to work on it. Preferably someone who is not easily frustrated with a peer review process.
@_date: 2017-03-14 04:28:59
So let's say BU chain 100 block heights further than Core but Core now owns 1.5x BU hashrate. Are you going to invalidate Core's block?
Because Coinbase definitely will.
@_date: 2017-03-09 13:09:29


Credit card networks is centralized. That's why it can be regulated.
@_date: 2017-03-14 14:51:36


Who's lazy now?


Majority is not consensus, although consensus is (super) majority.
@_date: 2017-03-17 08:38:57


The last time I check there is still 1000x-5000x write cycles


The UTXO is not. Some people spend BTC, UTXO becomes TXO, and create a new UTXO. (unless you want keep archival node, which with capacity limitation is also unwise, even then you will still need to keep separate db for UTXO)
@_date: 2017-02-02 09:24:07




I don't see anything else to prove. Bitcoin Classic was the main champion just until SegWit is released. That alone is enough to prove that the opposition is just being contrarian for being contrarian sake.
On the other hand there are people who is perfectly happy with 1MB. To tell you the truth these people starts to rub on me.
@_date: 2017-02-27 08:21:50
The problem with Nassim Taleb is that he always oversimplify everything. Take a look at his-butcher-as-surgeon example. He assumes that the butcher already worked a long time as a surgeon. He doesn't consider the probability that, let's say the butcher is only hired by the hospital owner so that it fulfills head count for regulatory requirement. Or that the butcher bamboozle the hospital owner so that he could be admitted to the hospital. If the butcher has worked a long time and has a good track record, sure. But otherwise I will suspend my judgement out of curiosity and do further investigation. (BTW we have a "butchers" in Core dev, Peter Todd only has a Fine Arts degree, also hard-core-Catholic Luke-jr, the last person you'd expect to make a capable devs)
Similarly if 99% of neurosurgeon already declares you have meningitis you should take antibiotics, not aspirin. 
@_date: 2015-05-07 05:13:41


Ok, so you want some form of IBLT to deployed first? Fair enough. Seems like miner's network already use it. How long before we can fully deploy this?


Fair enough. How long do you need for testing?
Here's how I view this. Gavin already has a plan. March 2016 20MB Block increase. What I need is for the opposition to gather behind 1 banner and propose competing roadmap. 
Take a look at the Asimov's The Gods Themselves and compare between the fate of Denison and Lamont. Those who only voice a real concern will be accused of fear-mongering while those who actually provide solution will be hailed as hero.
@_date: 2017-03-18 19:46:00
Like I said, more like they are quiet :). I wouldn't be surprized if there are just as many of them as BU supporter. The only difference is BU supporters are more vocal because they do not get what they want.
@_date: 2017-03-02 23:43:18


No, that's not the point of the PDF. Read them again.
@_date: 2017-03-17 07:01:06
Wrong. Blocksize should scale with technology because 
1. Doing otherwise will promote centralization
2. There is infinite demand.
@_date: 2017-03-19 05:13:18


And you will be minority in BU chain. Most of BU nodes put a finite amount in AD. That means they very much rely on Jihan's kindness not to forcefully increase block size, like this time.


Because so far everyone has been playing along pretty nicely. July 2015 attack cause quite a lot of damages to the system.
The only thing preventing that from happening again the second time is full block.
@_date: 2017-03-21 09:57:52
A little bit difficult adding everything. Perhaps you can help?
@_date: 2017-03-17 04:01:32
If that is the case, and I am not saying that it is it wouldn't be the first time I quote myself :)
@_date: 2017-03-18 19:01:49
You can't tell who makes up the majority though. 
@_date: 2017-03-15 23:49:08
That means that it only took less than 11 hours from the bottom to reach 85% of original counts. That means during that period no one was sleeping and no one was doing their day job. The period where 150 nodes is up within one hour is especially suspicious. Most likely that is the same ~150 nodes that up within the single day of 02/13-02/14
@_date: 2017-03-17 14:48:51


Not with updating. You don't need on-chain for that.


Well that $50 is still reasonable for our scenario.
@_date: 2017-03-17 21:24:27


Like I said, I wouldn't be certain without a testnet/real world test. A paper napkin calculation doesn't substitute for that.


Sure, but limiting transaction size is not very clever.
@_date: 2016-03-15 21:42:43


Actually the growing is to account for Moore's law efficiency(just in case in the future it is possible to create SRAM with the size of DRAM). The timebomb comes from difficulty increase. 
@_date: 2017-02-09 09:33:53


The "ecosystem" can discuss and decide if they participate in Bitcoin-dev mailing list. Which is open for everyone. 
@_date: 2017-02-01 05:42:49


Bitcoin is not yours. If you disagree the only way is to convince people who disagree with you otherwise.


The invisible pink hand you're talking about can lift the block size limit anytime they want. The reason we are stuck at 1MB is precisely because the free market decides that it is the right size.


Satoshi's last post 
Even with 1MB limit Bitcoin is not DoS-proof. We should be adding limit instead of removing them.


It's not artificial if it is to prevent DoS.


Without block size limits Bitcoin can't retain its 21M BTC property.


all available transactions. If the block size is not large
enough to meet demand for transactions, we believe the
qualitative content of all our results continue to hold, but the
quantitative impact is mitigated.
@_date: 2017-03-14 12:41:08
1. Why do you assume that the fee remains constant at 100 sat/byte whether it is 10MB or 1MB? Because it's not. When the block size is full transaction fee will increase that the honest participant will outcompete the attacker.
2. The purpose of the attacker is to bloat the blockchain and not to make other people inconvenienced. You see that UTXO attack happening again today? NO. Why? Because the block is full that an attempt to push transaction will result in superlinear increase in transaction fee.
@_date: 2017-03-15 18:24:05




So you want to use the original design where he puts longest chain instead of chain with most work? 
@_date: 2017-03-02 13:18:17


Are you saying these people are not running non-mining full nodes?


That's not what you said though
**This** is what you said.


@_date: 2017-03-17 07:18:59
1. Let's say current technology grows 10% but demand grows 50%. That means people with lower budget will no longer be able keep up with the blockchain growth and drops out. The end result is fewer and fewer people can run a full node.
2. I would use Bitcoin as a dropbox for movie if I could (just encrypt the data to make sure no one snooping).
@_date: 2017-03-17 13:23:30


Edit: No, actually it came out on Feb 6.
It is increasing through time


























@_date: 2017-03-14 14:45:38


The experiment is there, you only to reword everything.


And how exactly would you design the experiment?
@_date: 2017-03-15 14:33:31


You do realize that Core will reject all blocksize &gt; 1MB right?
So if BU created 2MB block they can extend it as long as they want, my node just won't accept coins from them.
The opposite is not true though.


Like ETC did?
@_date: 2016-03-12 19:37:34




That's the whole blockchain. So the correct comparison is 10GB vs 30-40GB and 1.2GB(I think Jeff Wilcke reported this number somewhere as pruning is not yet implemented) vs 1.4GB.
Still looks pretty concerning.
Also note that the current Ethereum usage is comparable to Bitcoin usage in 2013 so it is not too bad.


Actually this is where things go pretty interesting. Bitcoin core developers choose to limit growth while developing solution(LN) while on the other hand Ethdev choose to let things grow (with centralization risk in mind) while developing solution (sharding in this case). 
Which approach will win? Who knows. Only time will tell. Personally I am just a spectator and it has been a really interesting match so far.
@_date: 2017-03-09 13:37:12


/tinfoil hat on
PBoC already did try hinder all the privacy enhancement through Bitmain. The reason the exchange's withdrawal was extended was due to their failure to affect the fork.
/tinfoil hat off
@_date: 2017-03-07 22:52:35


Except miner, remember?
@_date: 2017-02-10 12:37:06


Because he stored most of his wealth in Bitcoin.


Define priced out. $10 might be too expensive transaction fee to pay for daily grocery but not for let's say channel creation for monthly wage.
$100 might be too expensive for monthly wage transfer but not for yearly wage transfer. It's all relative. What is priced out for you?
You are exchanging your inflationary fiat for deflationary asset, of course there will be friction.
@_date: 2017-03-17 18:45:58


Again, with bigger block the behaviour is **accidental**. Miner who doesn't want to will still do it. We are just enabling the behaviour. They will just say "this is what the protocol allows" like what Antpool did when being confronted.


No, but their tx is still ~4x smaller than Bitcoin. You will still need to provide the proof for 100MB claims though
@_date: 2017-03-09 12:29:23


I hope now you see how your risk management breaks down. For most people Bitcoin is their only network. And clearly your use case is better served anywhere else.
@_date: 2017-03-04 02:25:47
@_date: 2017-03-14 06:53:49
We'll just see..
@_date: 2017-03-17 07:32:24
Most of your value is less than 10x. We just had 4x increase in 2013
Segwit gives you roughly another 2x. So the margin is mostly eaten up


I wouldn't recommend running a full node on SSD, write cycle limitation is still a thing and it grows worse with the number of bit per cell (also memory matters more, like you said speed only increase 2x and size only increase 4x). 
@_date: 2017-03-14 15:51:21
Luke-jr and Pavel Janik was later convinced off-line by the argument that mining pool doesn't use them anyway so might as well remove them safely rather than asking the pool to implement their own solutions. You even link dcousens event. jyap808 doesn't even bother to make a rational argument
Luke is still grumbling about that today though.
@_date: 2017-03-19 04:46:12
We don't have it even after 8 years of search. And without that the system is at jeopardy. Would you increase the block size to 1GB without the technology? Same thing with SPV transition.
@_date: 2017-03-15 12:52:50
Now you know the importance of peer review.
@_date: 2017-03-19 09:46:55
That's not related to the blocksize increase aspect, which we are comparing. Miner choose blocksize already causes havoc somewhere else.
With segwit you won't be affected if you have your node upgraded
@_date: 2017-03-15 18:55:50
So you will notice this then:


Have fun following the "longest chain"
@_date: 2017-03-19 16:17:44
Unlike soft fork in a hardfork there will be two "BTCs" let's say BTC and BTU. So the price ratio between BTC and BTU will depend on BTC/fiat and BTU/fiat ratio. That's the only way you can compare. Similarly hashrate ratio will follow that ratio.
@_date: 2017-02-20 06:25:27
As close as to a robot as you can get.
@_date: 2017-03-19 03:59:17


There's spoonnet proposal by Johnson Lau
There's MMR TXO by Peter Todd
If BU supporters want to cooperate they can help people involved in those proposals. 
@_date: 2017-03-13 08:29:59
Instead of putting the transition point as part of consensus they leave it all to the users :)
@_date: 2017-02-20 10:56:50


Doesn't work when block rewards go to zero (other than that miners already have their own solutions)


Your extra core is better spent verifying UTXO in parallel rather than blocks. Especially if the reason you need it is to avoid being DoSed because of shitty transition while there are other solutions available.
In the end that shit doesn't work either. BU needs to implement "excessivetxsize"
@_date: 2016-03-04 13:54:14
At first I thought Zohar of GHOST paper? I wonder what new idea he came up with this time. 
Nope, it was pun-filled story...
@_date: 2017-03-15 15:09:55
ETH is supported by the original developer though. Which client is supported by original developer now? (Hint: Not the one that make a miner lose 13.2BTC and definitely not the one that just had their nodes down over an exploit)
@_date: 2017-03-03 18:51:25
Well, you can always push to activate segwit first. Just because segwit is activated doesn't mean there will never be blocksize increase. In fact, further block size increase depends on segwit activation
@_date: 2017-03-19 15:19:08


50% of them? Probably Every single one of them? Unlikely
@_date: 2017-03-09 08:40:27
Yes, and the issue with BU is I only know Bitmain as the sole contributor. I don't know whether they have enough peer review from independent party. (they don't, as evidenced by &gt;1MB block they created).
@_date: 2017-03-01 13:04:47


I quote that to show similarity with people who is pessimist on Segwit transition when they haven't even tried that. I guessed that went over your head. OTOH I'm not really sure why you said "Dr. Seuss would post from his real account"
@_date: 2017-02-21 12:59:54
If you are both honest and know what you are talking about you will know that being a gateway to lightning as well as a fix to quadratic hashing is a small price to pay, especially with compact block deployed so that block propagation is no longer an issue.
@_date: 2017-02-14 04:08:19


The term cash used in the white paper meant that it is not IoU-based (asset-backed), in contrast to let's say Ripple with transaction being irreversible as a central tenet. This term may not be so clear to newcomer.
@_date: 2017-03-13 16:06:31
Haven't seen you lately :) Where have you been?
@_date: 2017-03-09 13:44:40
Why do you think no government hasn't banned Bitcoin? They are hedging from the possibility that someone else will fully adopt it. If some states (take a look at New Hampshire today) actually adopt a more liberal attitude towards Bitcoin all the states that banned Bitcoin will be at disadvantage. Especially at high inflation environment.
From game theory perspective there is just too much to lose.
@_date: 2017-03-17 09:57:30
1. There is still 250kb limits though. If you hit that limit fees will go up no matter what you do. This happens in 2013 BTW
2. No one knows about Bitcoin until a few years ago.
@_date: 2017-03-13 08:41:46


This is probably the thousandth time I have to repeat this passage to the Bible thumper:




NO, it is not an improvement. Satoshi's design provides a **clear transition point** such that the risk of a fork is minimized, something that BU clearly fails to do.
@_date: 2017-03-15 18:32:46
What if I make longest chain with difficulty of 1?
@_date: 2017-03-03 10:38:40


If you're talking about PayPal, yeah. But Bitcoin, no. Physical hardware cost is small compared to mining equipment.


No, the paper doesn't assume that. If a miner sees no more transaction in the mempool there will be temptations to orphan that block until there is enough transaction in the mempool.


Nobody ever says that. Miner is not the only processing the block. My full node also needs to. And miner doesn't pay for my full node. Ergo miner can't know the true cost of transaction.


Read them again


It is entirely possible. It is even potentially profitable if barrier of entry is high.
@_date: 2017-03-17 04:00:53


I would like to see some real proposal on a BIP instead of just sketch-in-the-air. Johnson Lau is working on that BTW. Like how much more do you charge? Do you accidentally cripple Bitcoin's feature by doing so? Also note that it is not so simple, whatever proposal you offer must still be valid even for blocks already inside the blockchain lest you add complication to the activation.


Once again, FT is bug riddled on top of not supporting Signatureless IBD


Are you reading from a script? I never even mentioned about blocking anything. BU can fork off anytime without my support. I don't care. Just don't come back crying if it is totally broken.
@_date: 2017-03-19 09:48:12


I don't use remote access software. That's a security risk.
@_date: 2017-03-17 20:27:33


You are assuming a linear increase with safety factor of 2. I wouldn't do that without a test in actual testnet.


That doesn't seems to work with pruning.


You will need to separate the accounting between the legacy and the new one. That will be another spaghetti.


Elliptic curve multiplication is actually pretty sequential. The only reason vanitygen works is because they are checking adjacent private key. You might be able to use FPGA/ASIC for pipelining though.
@_date: 2017-03-10 20:45:53
I just put the quote that shows otherwise...
@_date: 2017-03-09 08:25:53
If Blockstream is under scrutiny, shouldn't they be equally under scrutiny? At least with Bitcoin Core I know  of contributor with different sources of funding (MIT, Chaincode Labs). I even know an example of changes from Blockstream being blocked:
 
@_date: 2017-03-17 14:47:38
People will just start to move to off-chain transaction like Coinbase/Bitpay. This won't change until Lightning. 
As it is, the condition highly favors "digital gold" use case of Bitcoin. People will just simply need to compete with them.
@_date: 2017-03-19 16:06:24
Price decides the hashrate, not the other way around. During ETH/ETC fork the economy split 85-15 while the hashrate split somewhere around 65-35. When the split actually happens what is the hashrate ratio? 85-15.
@_date: 2017-03-19 05:38:52


You are assuming that BU users are rational, which they are not.


Nothing wrong with that. I am an empiricist myself.


That attack's worst damage is not increase in fee, but rather increase in resource usage.


Seeing how things goes I don't think we will need to wait until next year.
@_date: 2017-03-03 07:57:16


1. In (b) They still can't print more than 21M BTC nor confiscate coin
2. In (b) Pow change is still not an option
@_date: 2017-03-14 16:54:51
No, my point BU proponent claim that Bitcoin is the one where they say longest chain is equal to longest valid chain.
@_date: 2017-03-14 16:15:31


I would agree with you, except for the AD default of &lt; 99999.
@_date: 2016-03-13 06:06:35
The thing is the core devs refuse to even produce a working 2mb option(at least until July I think). The community tends to trust the core devs(at least as a guideline) on what is safe.
Looking at ethdev's analogue they do produce code with really high default gas limit (I think the original one they release last July is the equivalent of 8tx/s and now they add another 50%). Sure they allow the community (e.g miner) to vote it up or down but they do produce the code.
@_date: 2017-03-09 11:48:55
That probability is still larger than let's say the probability of someone breaking the private key of a UTXO.
@_date: 2017-03-17 06:28:33


With the guy who codes DAO (Lefteris) as contributor. LOL
@_date: 2017-03-11 16:27:04
Witness is part of the input, so the more outputs you "destroy" the transaction becomes relatively (but not absolutely) cheaper compared to before segwit.
@_date: 2017-03-18 19:00:52
I'm not against Segwit though. I think I can count a few through my time here. Ironically these people are often suspected as BU supporter. and are the main suspect I think.
@_date: 2017-03-07 19:38:34
[Safe number is 4MB](
[With UTXO growth concern]( you get Segwit.
@_date: 2017-03-15 18:50:47


@_date: 2017-03-02 23:50:23


That's about the only place you can find people telling you a bunch of lie like "Segwit is a technical debt".
@_date: 2017-03-17 13:36:39
1. Segwit
2. Signature aggregation
In addition to that if technology growth goes flat block size also needs to go flat unless you can make magic inside the program. Scaling is difficult.


Not really, low value transfer will just be replaced by high value transfer. People will just need to make tx once a month instead of once a day.
@_date: 2017-03-09 10:44:14
1. (a) A HF to large block itself requires around that many lines of code (b) Making a claim is simple, producing solution not so much.
2. (a) If your business model depends on blockchain being unlimited resource then it is broken. (b) I am storing other people's data just in case I will receive payment from them in the future. Since you are the only one verifying the payment it only makes sense that you and **you alone** (or the so-called "music industries" that stores the data. If you don't like it find some other alts for your use case. Last I heard Ethereum likes those very much (c) [Colored Coin can utilize Lightning]( Stop making excuse
3. What are you talking about? Soft forks means minimum change.
4. Ever tried to use BitPay to donate to Wikileaks?


The nodes that turn that off will be forked during the last Bitcoin.com SNAFU
@_date: 2017-03-17 07:04:44
Here's the thing. The same people who repeatedly claim that BU code is unsafe has been proven right two times. So shouldn't we listen to them when they said further increase than Segwit is unsafe instead of asking for "compromise"?
@_date: 2017-03-01 17:43:27


OK let's be objective. You can argue about  (there's no consensus on this but majority thinks that it's not a HF the previous behaviour is undefined) but  and  is just slinging insult. Do you agree? He doesn't even make an effort to be civil.
@_date: 2017-03-10 14:40:48
*sigh* Getting pretty tiresome debunking this. 
1. Right no solutions, repeat **no solutions** available that can fix malleability in old style transactions
2. Even if you want them the fix is soft fork (e.g BIP62), not a hard fork, although that is a whack-a-mole solutions
@_date: 2017-03-09 11:45:42
1a) A shitty fix that leaves miner to be solely responsible for a limit as critical as 21M limit. b)  I want to hard fork but I don't want to do all the job. Let's leave it to someone else.
2) a) That limit still exists and independent of consensus layer limit b) Satoshi did, never explain the reason
3) (a) Are you talking about BIP62? That fix is hopeless there are just too many edge cases (b) Two UTXO data sets? WTF are you talking about?


You forgot the part where you explain why.
@_date: 2017-03-14 13:57:11
First of all, you can't have a roadmap when you are dealing with decentralized governance. Just to give example of what I'm talking about. Take a look at BIP150/BIP151. End to End encryption. Good idea right? Well actually right now it is being blocked by Eric Voskuil, a libbitcoin dev. His reasoning is that node key that is to be used for key exchange can be used to identify a node, making it easier to do AML/KYC. That means that BIP can't proceed until Eric agrees that his concern has been addressed.
Similarly Peter Todd's full RBF actually give the benefit better mempool sync between nodes since the behavior for mempool replacement becomes deterministic but the problem is that it gives rise to easier double spend so it is not yet merged. Everyone who gives a good reason can block any kind of proposal.
What you can have instead is short term insight. In the short term once Segwit is activated you can actually have Signature Aggregation, which is roughly additional 30%. This have the benefit of both fungibility increase and additional capacity. I don't expect any opposition since it is overall a big plus (although I don't know if miner decides to block that for political reason).
All the parts below are still on navel-gazing stage so it is not yet guaranteed, anyone can decide to block it at any time.
There is work a on TXO commitment to address UTXO growth rate. 
Once this concern has been addressed it is possible that some form of better fee estimation on the tx is made:
This will make for a better block weight.
I think we have a couple of dynamic block size limit proposal but from what I heard keeping it incentive compatible is not so easy.
@_date: 2017-03-14 15:22:44
They mine a block and measure how long it propagates between node? How is that not a science?
@_date: 2017-03-17 13:12:43
You were asking for the code and I gave you.
Do you expect me to spoon feed everything to you?
@_date: 2015-05-27 00:08:04


Gavin wants someone to propose a code for any suggestion:
Unfortunately I don't think I am familiar enough with Bitcoin Core Codebase to do this within a year :/
Damn, I have been slacking for 2 years...
@_date: 2017-03-09 07:52:09
[Doesn't stop Circle from doing that though](
[Or for that matter Coinbase](
@_date: 2017-03-09 13:32:07
The state will just play a whack a mole. New York heavily regulates it, it moves to China. China regulates it it will just move to India, Japan (or even Localbitcoins). Just like drugs, the more you fight it the more expensive it will become.
@_date: 2017-03-14 12:46:24
Simple, as I have shown you the block was not full that time.
@_date: 2017-03-17 15:46:57


@_date: 2017-03-01 12:55:18


Nothing to do with block rewards. It's the technology. Once there is no more improvement in semiconductor (which has steadily slowed down in the past 5 years) there won't be anyone to support ever increasing block size.


And I've listed nearly all the wallets listed. Anyone else you can think of?


Again you don't need to upgrade to 0.13.1. There's nearly nothing there except Segwit.


Not even sure what's your point is.


I am not even sure what your point is. I was merely questioning what is the purpose of doing the questionnaire? For survey purpose?


Like I said there is no reason whatsoever to upgrade to 0.13.1 from 0.13.0. Nearly 50% of full node didn't upgrade immediately from 0.12.1 to 0.13.0 after ~4 months passed after 0.13.0 was released.
@_date: 2017-03-09 04:33:07


A change in supply curve would also dictate a change in price.
@_date: 2017-03-16 04:23:04
Again same thing. The longer your blocks propagate the more likely it is going to be orphaned because someone else find another block.
@_date: 2017-03-15 14:44:42
You mean coin with 7th largest market cap?
@_date: 2017-03-15 15:22:11




Apparently you did. And unfortunately that guy is gone now. This might be him though:
So the choice is between people who worked hard to secure the chain for 8 years and the who just had their clients being wiped out.
@_date: 2017-03-09 11:51:22
The 55% who supports may not be the same one with 55% who is ready. Same thing with SegWit (or for that matter BIP66 SNAFU).
@_date: 2017-03-07 12:16:41


Talked like what?


Please quote the tweet. The way I see it he is just giving his opinion.
@_date: 2017-03-13 08:31:11
What if we do hard fork that remove block size limit and replace it with block weight limit that can suppport 15x capacity? What is your block size limit now? NaN?
@_date: 2017-03-09 08:22:50


Right now he can't.


In the future when miners are the only one runs a full node it is entirely possible, especially when he has control over ASIC production


Maybe you can show an example of an article being clearly false?


If this is false why didn't Jihan deny it?


Jihan controls Bitcoin Development Grant.


Why the secrecy? Why the closed door meeting? Maybe you can ask Bitmain/Roger to clarify? Or perhaps even BU devs? All I know is unlike BU most of Bitcoin Core's contributor has a clear funding source.
@_date: 2017-03-04 10:20:39
Speaking of Jihan, anyone know who is the recipient of the last Bitcoin Development Grant?


The reason I'm asking is because if it happens that BU were funded by this grant there is a clear conflict of interest. Acceptable Depth clearly gives miner more power over valid chain. This kind of change won't be merged in Bitcoin Core.
Bitmain was the main contributor of that grant. 
And Jihan is actively using that.
This is why a small development team is really bad. There's just not enough check and balance. Say what you want but Blockstream doesn't even make up a majority of Bitcoin Core.
Don't believe me? Take a look at this
@_date: 2017-03-12 13:58:05


And exposing ourselves to various DoS? Thanks, but no thanks.
@_date: 2017-03-19 15:25:23
Here's the thing. There are two parties in the agreement. Some part of Core devs (who made perfectly clear they do not represent Bitcoin Core) and the miner.
From the devs:


Johnson Lau have it here:
But there's no pick up (mostly due to F2Pool, see below). So those dev who attended the meeting definitely already fulfilled their promise.
From the miner:


F2Pool already ran Bitcoin Classic. Now not only Antpool ran Bitcoin Unlimited they also fund the development. Who's at blame now?
Sure, miner has the option not to activate Segwit according to the agreement:


But running Unlimited? That's entirely different story.
@_date: 2017-03-21 10:53:09
So? They support both. Big deal. You were saying this though.


Which is completely false.
@_date: 2017-03-17 12:26:00
IIRC Luke-jr was against extension block. (e.g He would rather have a hard fork). care to comment?
@_date: 2017-03-04 11:57:15
Yes, they do. But the alternative is to be idling while they validate previous block or wait for the blocks to propagate. When the block reward is big compared to tx fee it is more profitable to do it this way while when the block reward is small enough you start to lose out. Hence the push for bigger block (because they intend to keep transaction fee small). 
OTOH Miners like BitFury who has optimized transaction inclusion prefers to keep block small. 
@_date: 2017-03-01 09:55:33


You will have no choice once the technology stagnate


[Aaron Voisine of Breadwallet and Lawrence Nahum of GreenAddress](
[Thomas V of Electrum](
[Jameson Lopp of BitGo](
Mycelium is the only one neutral AFAIK


Unlike 0.13.0 0.13.1 doesn't contain anything else apart from SegWit.


Not updating is much easier than updating.


I do not like them,
I do not like
Green eggs and ham.


If it's a soft fork what's the point? Are you saying they should be coding a competing soft fork?
@_date: 2017-03-19 03:36:27


Which is weaker than what it used to.


I would say even at current block size there is still a valid use case for Bitcoin. Honey badger just doesn't care.


Mostly because of perceived threats. Absent threats most likely it will continue to go down.
@_date: 2017-03-07 18:32:04
No offense Eric, but you did support Segwit and we get nowhere so I'm going to say your support is meaningless (not as an insult but as a statement of fact)
The truth is we need data from Segwit to show that further blocksize increase is possible.
@_date: 2017-03-07 18:29:06
Just in case you haven't realized what we are facing is a power grab, and not an attempt to find a compromise. BU is an attempt to seize power by hashpower from economical power. I mean take a look at ViaBTC's plan.
HF to 2MB? Segwit already provides that, with all the safety measures required, faster lead time and Lightning. Miners simply don't want more capacity. They want control over the network.
@_date: 2017-03-17 21:40:08
Better approach is to use sighash estimation instead.
@_date: 2017-03-14 00:09:02
On why we only get ~2x on Segwit
@_date: 2017-03-17 15:44:03


That's the same argument ETH used for breaking immutability BTW.


Again, there is no guarantee. A lot of people have been burnt. Those who attend the HK agreement experiences this first hand. F2Pool runs Bitcoin Classic and now Antpool runs Bitcoin Unlimited. Even when Johnson Lau provides a code as a recommendation to Bitcoin Core as per agreement:
In fact, Mark Friedenbach, the one who used to champion jlau's approach 
is gone because of Not to mention all the lies that have been spread about Segwit:
These people are already deadset against Segwit. Who exactly are we going to win here?
@_date: 2017-03-17 14:14:45
Remember if they cheat you you can steal their money instead.
@_date: 2017-03-14 16:36:29
As opposed to losing to Coinbase and BitPay's offchain? I guess I give them too much credit.
@_date: 2017-03-09 04:55:35
The chart doesn't (and can't) make any assumption on what the users is willing to pay absent block size limit (or block size limit significantly higher than demand).
Even with blocksize limit there is still time-dependency to consider.
@_date: 2017-03-19 04:33:54




Are you going to follow Satoshi blindly?


Good job for selective quoting. You forgot this part:


Do you have that?
@_date: 2017-03-14 17:14:58


Well, mostly since testnet coin doesn't have any value no one bothers to protect them.
@_date: 2017-03-18 19:34:25


I'm not so sure about that. Mark Friedenbach was the one who was concerned about UTXO. And you can see Greg Maxwell fought with Peter Todd/btcdrak here:


I think that is some sorts of a miracle though. Segwit is just a huge plus that everyone agrees to it. 
@_date: 2017-03-09 13:47:43
Ah, you just have to love all the 'labeling' attempt. "Think of the children". People who doesn't like the soft fork always has an option to opt for a hard fork.
@_date: 2017-03-14 13:41:15
Who says 1.7x will be the end?
@_date: 2017-03-07 11:34:45
And he argues about how insurmountable the task is...
I'm not really sure how you interprets that as "supports".
@_date: 2017-03-09 04:27:53


Yes, fortunately we have BU team, [who is solely controlled by Bitmain]( where progress can happen much faster.


Yes, you're right. [ViaBTC's plan]( of HF to 2MB is a significantly better solution. Who needs Lightning when you have Paypal?


You mean dedicating ~1.5 their manpowers? Wow, that sure looks like a lot of resources.


Totally true. Like I said above the competing team is only controlled by Bitmain and this will make decision making super fast. Miners always have Bitcoin's best interest at heart after all. Like mining empty blocks, or even increasing the bitcoin supply if it is needed when there is not enough consumption.
@_date: 2017-03-14 10:10:29


User's frustration is about the least damage you can do by 'spamming'. Because of no blocksize limit no one will be willing to increase their fee to defend the network. Result:
See the July 2015 spike, the result of these:
This vulnerability is not yet fixed. Block size limit actually helps to prevent those attacks.
@_date: 2017-03-18 17:44:39
Even among pro-segwit crowd I'm leaning slightly leaning towards your side. So there is not much to discuss :)
@_date: 2017-03-05 09:58:01


If you didn't notice those people are the same one that was being ridiculed by buttcoiner. Bitcoin has never been competitive on e-commerce front. 
You pay for your own fee instead of the merchant? 10 minutes confirmation time? XXX stop accepting Bitcoin because there is no demand?
The truth is the argument that a currency must be spent to be useful is Keynesian, which is antithetical to what Bitcoin is.
Instead why don't we focus on where Bitcoin is really good at? Store of value that can't be confiscated, High friction payment (e.g remittance), Censorship free payment (e.g Wikileaks, Drug purchase).
@_date: 2017-03-09 07:16:48
I am against Bitmain being the **sole** contributor of the funding. This result in a protocol whose decision making heavily favor the miner.
Core OTOH has universities, independents, and multiple companies providing the funding.
Diversity gives strength.
@_date: 2017-03-17 04:10:42
2/3 of those forks ended in disaster. The first one doesn't account for replay and the third one cause a chain split between two clients. Why should we listen to this guy again?
@_date: 2017-03-14 05:44:45


That would include increasing the 21M BTC limit.


Not going to happen.
@_date: 2017-03-17 04:00:47


That's an argument for block withholding, and not against. The more I can fine tune how long the competition need to wait for my block the better I can be. 
@_date: 2017-03-14 14:44:04


Provide rebuttal for each individual one of them since all are equally possible.


That's rule by consensus, and not majority if you haven't noticed.
@_date: 2017-03-14 17:13:59


What is centralized about that? You know I can participate in the governance process that create the said client right? Or for that matter so can you.


But why limit yourself to what the original client can accept? Don't you want to increase the limit beyond 32MB if it is possible?
@_date: 2017-03-13 08:03:49


Well, you can see it that way since if UASF hashrate exceed BU hashrate BU chain will get wiped by UASF chain, but not the other way around...
@_date: 2017-03-17 06:19:23
The main opposition is some people think it is unwise to HF to bigger block without data from Segwit. For example we had to increase soft limit from 250kb to 1MB in 2013.
As the end result this happens:
You can clearly see the impact here:
Segwit attempt to avoids that by solely increasing the space for signatures. But we don't know how safe it is for a further increase. Even this kind (e.g Segwit) of increase might already be unsafe (although it is safer than a 2MB increase)
@_date: 2017-03-14 06:20:49


Ah, yes. Blindly trusting third party. What could go wrong, right? I mean there is no possibility that miner doesn't think there's not enough transaction such that they want to stimulate the economy more right? Like, right now? Especially when increasing the supply comes at no cost to them.
I mean why would Roman empire want to dilute their gold coins? They will destroy the trust in the system...
@_date: 2017-03-10 20:21:56


Again, TCP/IP developers doesn't care if you can run video through it.


Everyone will have an incentive to run a node when something like BU threaten the network. We should always keep the option open for everyone.


When you're talking about UTXO the concern is memory, whose prices increase last year, and not bandwidth.


1. Actually the original 'soft limit' is 250kb. We just increased them in 2013. 
2. Even originally with 1MB limit Satoshi ignores quadratic hashing so even 1MB back in 2008 is already unsafe
3. In 2013 Ghash.io shows that 1MB limit is already unsafe. It was only after relay network was out the network returns to normal. 
@_date: 2017-03-17 15:11:05


No good purpose? There are technical reasons for that!!
From block propagation perspective:
4MB is the most we can handle.
From UTXO growth perspective
@_date: 2017-03-09 09:46:33
\*(Or a semi-trusted)
There's still TumbleBit, you know?
@_date: 2017-03-15 10:24:22
Except that they made up the 90% figures of full nodes remaining as acceptable out of thin air. Did you even read them? Even the author admits that:
The study I linked measures block propagation, which is a measures of mining centralization pressure. 
Jeez, are you an out of touch academics? Bamboozled by formality of paper?
@_date: 2017-03-17 07:38:51


You forgot to take into account Great Firewall of China, where miner happens to be located. Luckily someone already did a test.
Result: 4MB is the limit. Guess what? That is orders of magnitude less than the person I'm replying to estimates (e.g download a websites)
This gives you the explanation why we only get 2x with Segwit
@_date: 2017-03-09 13:15:57
Well, the duration of back log caused by sudden increase in transaction rate has grown less and less by now. I don't think I've ever seen it more than a day. You're welcome to waste your money though. If it happens that the original Bitcoin chain has higher value miner will just move back. There is no permanent allegiance.
@_date: 2017-03-18 17:21:52


@_date: 2017-03-17 17:10:17
Segwit does that for a good reason though. That is to enable signature-less IBD (you will need to re-use two different serializations for bootstrapping a new node). Meanwhile extension block described by Theymos does that solely to increase capacity. Read comment below for better description for argument against extension block.
@_date: 2017-03-17 18:05:22


Again, once you have enough hashpower you don't need to worry about getting orphaned. Read Peter Todd's writing above.


High orphan rates caused by bigger block is accidental (as opposed to block withholding). We may not even detect block withholding at bigger block, at least we know some baseline at 4MB.


Again, if you have enough hashpower you don't need to worry about your block getting orphaned.


Citation needed. At Ethereum testnet this behavior is observed at~15tps. Granted there are difference here and there but I don't think that warrants a 10x difference.
@_date: 2017-03-17 17:32:13


No, the problem occurs when the orphan rate is so high that it provides incentive for miner to centralize. Not something that can be fixed with parallel validation.
You also need to remember that miner has no incentive to create small block when they have enough hashpower


1. SPV mine doesn't work when transaction fee made up a large portion of block rewards. 
2. What matter is not the average, but the median. The longer block propagation still gives rise to higher orphan, whether or not the average goes down.
3. You also haven't commented on the part where at larger tps compact block is no longer effective.
@_date: 2017-03-14 16:45:33
OP never mentioned anything about "original rules". His basis of argument is "longest valid chain" instead of "longest chain".
@_date: 2017-03-10 19:52:17


That's what the person I'm replying to is concerned about though.


Developers only care about node's cost (processing, storage, bandwidth). TCP/IP designers doesn't care about whether Web Designer can run their HTML through it or if you can use it to stream video, all they care about is if nodes can still communicate even with unreliable route. It is the job of HTTP protocol designer or Web Designer to adapt, and not the other way around.
The fact that Bitcoin can't scale to fit all the transactions in the world has been known for a long time.
"Investors" and "Economists" needs to educate themselves to understand the technology's limitation.
@_date: 2017-03-14 04:03:07
Read the links. When the majority is pro-Core Andrew Stone advocates to invalidate the block.
@_date: 2017-03-19 10:05:08


There's no "rank". Do you know Eric Voskuil? He just blocked BIP150/BIP151.


Define contributing. People who do protocol research may not be the same one with the one who writes the code.
@_date: 2016-03-01 17:55:21
Never even heard of blockchain.com. You mean blockchain.info?
@_date: 2017-03-10 17:33:09
Apparently someone confuses relational operator with assignment operator. 
I'm dissecting a frog though.
@_date: 2017-03-10 20:41:52


I am just showing you that 1MB is already too high even back in 2008. So you can't say that 1MB is safe in 2008 and we can increase it even further now.


WTF are you talking about? Get your timeline straight.
GHASH.IO happens from Dec 2013
Until June 2014
Relay network out Aug 2014
And you never heard of GHash.io ever since.
@_date: 2017-03-19 15:45:35


You're saying botnet operators don't want money? It doesn't matter who secures Bitcoin so long as they do it.
@_date: 2017-03-07 22:53:10


If I am not in control miner already have 2MB blocks by now.
@_date: 2017-03-19 04:28:52


Meaningless if the said users doesn't simultaneously verify the rules (e.g 21M limit). Which is the current situation
@_date: 2017-03-15 14:41:02


So.... ETC can survive even though mining is controlled by Ethereum corporation that supports ETH. Hmmmmm.....
@_date: 2017-03-09 11:58:58
1a) That limits define who can or cannot run a full node. 
2) Like I said that Satoshi was the one who added the limit
If I have to guess it is part of bug fix, just like choosing most-work chain instead of longest.
3) Ah yes, "I don't know what I'm talking about and I'm simply trying to evade" defense


All are due to the following:
1. their equivalent of "block size limit" is too high
2. There is unknown vulnerability in the protocol
Both can apply to Bitcoin as well.
Unknown vulnerability is unknown vulnerability whatever technology you are talking about. 
@_date: 2017-03-17 15:16:52
From technical perspective, Segwit is the most we can handle right now. From the devs PoV Bitcoin is supposed to be apolitical money. Any changes should be made from technical perspective. The same political pressure to increase block size can be applied to increase Bitcoin supply in the future. 
Besides, have you talked to Jihan? Did he actually mentions that he will accept the compromise? F2Pool and Antpool both already break the HK agreement now. Why should the dev waste their time?
@_date: 2017-03-17 05:56:06
This again? My computer doesn't need to upload webpage to multiple people within less than half a minute. My computer also doesn't need to download 10 years of history of webpage just to get started.
@_date: 2017-03-18 17:12:34
That's because of wear leveling. A software feature, not hardware one. And it wont help much when you run Bitcoin Core.


I spent less than that on tx fee though, if anything tx fee should go up before I need to do that
@_date: 2016-03-29 17:07:56
Also to add in on Phillip Roth Wikipedia controversy:
Basically what Philip Roth need to do is get someone else to write news about him instead of asking directly to Wikipedia. That's just how Wikipedia works.
@_date: 2017-03-17 14:49:06
@_date: 2017-03-19 16:21:02
So the question is after hard fork which one is BTC? The one with the original developer? The one with fiat support? Or the one with hashrate support?
I would say the the one with fiat support, because hashrate follow the price.
Also this is no longer true:


@_date: 2017-03-17 15:05:39


So the devs spent many months writing the code (blindly, because there is no real world data provided by Segwit). Segwit activated, crashes in fire, further proving that all their assumption was wrong. What then? Are we going to still insist on activating the hard fork? Who is going to answer for the many months spent for nothing?
@_date: 2017-03-17 14:39:57


My point is that it will be much less than on-chain fee.


I'm talking about your assumption in this discussion.
@_date: 2017-03-14 17:15:32
No, you will need to create a competing soft fork for that.
@_date: 2017-03-17 14:03:59
They can't tell if you use multi-hop payment. Drug dealer can even run a hub for all you know.
@_date: 2017-03-18 17:44:21
You can try searching for Segwit on the other sub and see how many positive comment you can get...
@_date: 2017-03-09 04:19:09


And everyone who runs a full node. Having reading comprehension problem?
@_date: 2017-03-01 22:40:37
More importantly I don't think I've ever defended Samson before.
@_date: 2017-03-11 18:18:49


It's a stopgap solution while a better block weight is being defined, like this one here:


Similarly due to high fees those balances are now less likely to be used by attacker to bloat the UTXO set. People who have interest in spending those outputs already combined them back before the fee is rising.


Are you in favor of removing sigops limit, then? Or push size? Or maximum message size? Or script size? You need to remember that "the market" includes more than just miner.
You will also need to remember that even with segwit miner can still prioritize their transactions however they want (although they should prioritize it the same way as block weight if they want to maximize revenue)
@_date: 2017-03-10 13:49:27


You have BIP62, which is a whack-a-mole solution. You have BIP140, which increase UTXO set size. You have Flexible Transaction, which breaks all the wallets and block explorers. In addition to that none of them enables signatureless IBD and only FT solves quadratic hashing.
You want more things proposed or is one of those suits your need?
@_date: 2017-03-17 15:19:30


Segwit, the safest path to capacity increase already dies, because DoS. Why should HF survives?


When the technology can cope.


Change of plans? Do you mistake several individuals who attends HK agreement to represents the entire Bitcoin Core?
@_date: 2017-03-01 08:53:47
Litecoin never approached Bitcoin's level of transaction. Even at current transaction rate the level of decentralization is much lower than Bitcoin what with F2POOL holding 30-40% of hashrate. We only see GHash.io at 1MB block. I can't think of what will happen when Litecoin **actually** reaches 4x Bitcoin's level of transaction.
@_date: 2017-03-09 13:17:24
If you think no New Yorker ever used VPN I have a bridge to sell you.
@_date: 2017-03-07 19:13:34


I wouldn't say that. Their work proves that big blocker simply doesn't think that capacity increase is urgent enough. All their talk this time is bullshit
Nearly everyone already supports Segwit except the miner. What is their intention? To become the next central bank.


@_date: 2017-03-09 08:12:34
Sure, just trust the miner right?
@_date: 2017-03-14 06:45:45


Because of the threat of PoW change? What else keeping them from taking over?


It is literally a single change in the number the software...
@_date: 2017-03-03 16:17:43


You don't need to add mining equipment to add to block supply.


By whom? What if he happens to find the next block?


You just assumed altruistic miner instead of economically rational miner.


Yes, it does. Because I need it to ensure 21M limit and no miner dares to confiscate coin. The same thing that ~5000 other nodes did.


Does not compute. If barrier of entry high he can enjoys his monopoly longer
@_date: 2017-03-03 17:27:54


You mean like how miner won't increase block size now? Sure I could get behind that. 
But the thing is they were arguing for blocksize increase before, which actually shows that they are not aware of the true cost of transaction in Bitcoin.


Read what I wrote again.




Is higher orphan rate actually poison Bitcoin ecosystem? People seems to be fine with 5% orphan rate during Ghash.io
Leaving money on the table is altruistic behavior, and not rational.


What gamble? Here's a game theory. Current mempool size=0. I could build on top of latest block, in which case I get 0 fee. 
OR I could orphan that block and get the transaction fee. That block may be orphaned by other miner but it doesn't matter since the alternative is I get 0 fee. More importantly, if there is enough tx in mempool afterwards I can build on top of my previous block getting both tx fee for both blocks
If you assume miner won't take all the money in the first place you are already assuming altruistic miner. Have you ever seen blocks less than 1MB that is not SPV-mined? Nearly none.


Miner doesn't have any incentive to keep 21M limit or not to confiscate coin.
Miner's main expense is mining equipment, not full node. My main expense is full node. What is good for the miner may not be good for me.


There are two parts to this debate if you haven't noticed.


LOL, you actually believe that? They compete by hashpower, same as everyone else. 
@_date: 2017-03-07 19:56:05
[10 minutes](
You can fix that by limiting transaction size but you will limit smart contract capability (removing the limit after you place them is another hard fork).
Note that Segwit actually fixes that and now there is work on [a better metric]( than transaction size.
@_date: 2017-03-17 19:50:06


Errrr..... That's not how it works... You will still need to transport the mempool diff you know? So that people can tell which transaction is included and which transaction is not. How big is the diff?








Limiting transaction size presents problem where you can no longer performs a massive coinjoin, combine multiple inputs together, or even interesting application like confidential transactions.
@_date: 2017-03-09 09:53:42
To be fair that is considered a downgrade over the current BIP9 (or for that matter BIP34) though.
@_date: 2016-03-13 11:32:11


Eh, why the attack? I've never said that I'm not happy with that. 
In fact, I've actually stated the opposite in the past(however that is irrelevant for our discussion):
I'm just stating the fact. Please don't attack the messenger. Right now Core developer think that it is relatively unsafe to go beyond 1MB (that is a fact), and they decide that it is okay to limit the growth for now so that people can use the blockchain in more efficient way by fee discovery and compressing multiple transactions into one (again just fact, no personal opinion here). 


Again I'm not sure why the negativity. By putting the default number into the code the devs are basically green-lighting the change. As stated in my original post it is too early to see which side is actually the wiser. Please don't put word into my mouth.
@_date: 2017-03-17 09:09:20
1. I'm not really sure what your point is
2. Thanks to blocksize limit that is.
@_date: 2017-03-20 12:30:22


Round Table Consensus: Feb21
F2Pool runs Classic: Mar 02
Greg's well meaning dipshit comment: May 13
Get your timeline straight.


No, the agreement states explicitly otherwise:


And there was still a chance of that happening but a lot of people are turned off by F2Pool


They are still bound by this:


And they broke it.
@_date: 2017-03-19 16:33:50
For the record this is what people meant by economic majority. And not some flimsy node count (although if exchanges refuses to list the said coins it is entirely possible that the transaction moves to Bitsquare, which depends on the full node, this is what triggers Poloniex to list ETC BTW)
@_date: 2017-03-14 06:30:09


You understand that soft fork is a type of 51% attack, right? If UASF has higher hashrate the old nodes fork will be replaced by UASF chain.


UASF will change the equation. If UASF chain has higher value people will move their miner.
@_date: 2017-03-18 19:43:48


He doesn't even hold the commit access. Actually the only reason they signed onto it is because it is good. Even Peter Todd still raises concern about Segwit at the last minute
Right now his weak block is also being stopped by Peter Todd.


That was the reason why Gavin was "kicked" out BTW. Because Core doesn't like the concept of "leader". There is only "peer".
@_date: 2017-03-18 19:10:56
So you think if we remove the discount miners will magically signal for it?
@_date: 2017-03-16 10:17:05
Kudos to whoever predicts this a month ago.
@_date: 2017-03-14 16:21:29
Sure, it just invalidates the whole "Nakamoto Consensus" narratives.
@_date: 2017-03-17 07:14:47
Well Ethereum did put a safer version of emergent consensus. Their testnet got attacked after that.
Now you can't mine testnet without AML/KYC. LOL


@_date: 2015-05-11 09:17:52
Forgive me if I missed something because I admittedly skim it pretty fast. The problem that I have with this work is that it spends too much time on showing why reducing block rate is possible rather than why it is better than increasing maximum block size (the only one I see is one anecdotal evidence at the end that there is less line changed in the source code). In fact  and  shows exactly why it is inferior to increasing maximum block size.
@_date: 2017-03-15 18:34:25
So you will follow that chain instead?
@_date: 2017-03-14 19:05:10


And expose ourselves to UTXO bloat? Nope, we need something better than a straight block size increase, like Segwit.
@_date: 2017-02-02 20:19:38


This is why you have to be wary of "alternative facts". They are not paying Wlad, Jonas, Marco Falke, Cory Fields, Johnson Lau, dooglus, davecgh, Laolu, kazcw, Alex Morcos, Suhas Daftuar, Thad Dryja, ThomasV, Eric Voskuil, Jameson Lopp, Ben Davenport, dexX7 and many more. SegWit is a joint effort. Even the one on my list is longer than yours. 




1. Reverse transactions that he sends while he's in control. This has the potential to double-spend transactions that previously had already been seen in the block chain.
2. Prevent some or all transactions from gaining any confirmations
3. Prevent some or all other miners from mining any valid blocks
The attacker can't:
1. Reverse other people's transactions without their cooperation
2. Prevent transactions from being sent at all (they'll show as 0/unconfirmed)
3. Change the number of coins generated per block
4. Create coins out of thin air
5. Send coins that never belonged to him
If you want to extend their privilege go head just don't drag me with you
@_date: 2017-03-15 18:48:35
What's the time interval between two numbers?
@_date: 2017-03-14 06:43:13


Ethereum HF:
Developer support: 100-0
Economic support: 85-15
Miner support: 75-25 or 65-35 depends on the pool
Current BTC situation
Developer support: 100-0
Economic support: ?? (Currently it seems to support Core with Bitpay and PurseIO on board and Coinbase labeling to BTU)
Miner support: 30-30-40 (worst case 30-70)


Currently miner supporting Segwit is already 30%, why do you assume 90% leaving?
And secondly 100minutes is nothing if the competition is SWIFT.
@_date: 2017-03-07 22:57:22


And how much further have we gained? You can't answer that unless you release Segwit.


Bandwidth only grows 50% a year. Hard disk grows 10% a year. Memory prices actually increases. All are negligible.


Uh, it is the same problem.


No, the increased fees prevent those outputs from being split even further.


Nothing is suboptimal about Segwit. For example among all malleability fixes it is the only one that requires minimum change to all wallet software and enables signatureless IBD.
@_date: 2017-03-21 10:29:05
You can see BitGo's Ben Davenport there.
Jameson Lopp of BitGo. 
You can see Kraken and Bitstamp use BitGo. When BitGo save money both Kraken and Bitstamp also saves money.
Kraken and Bitstamp is also among the exchanges to list Bitcoin Core as BTC in the short term.
This is Coinbase:
@_date: 2017-03-20 19:15:17


And have you ever seen Wlad or anyone else disobey that? Forcefully commit the code?
@_date: 2017-03-18 19:26:20


With signatureless IBD, yes. (And also unlike UTXO bloat the 4MB spam transaction is non-standard so you can blame miner if that happens)


Pretty much, yeah.




@_date: 2017-03-10 20:39:23


From where else do you want input? Business can send their own reps. Jameson Lopp of BitGo, dexX7 of Omni, Charlie Lee of Coinbase and Colu already review them.
@_date: 2017-03-16 04:16:21
Do you understand standardness rule?
@_date: 2017-03-02 12:31:22


[Funny how fastly you backtrack from yesterday's discussion](
@_date: 2017-03-01 11:22:32
Heh, don't feed the troll. He is an equal opportunity offender though. He just trolls everyone from Ethereum, and whatever else you can think of.
@_date: 2017-03-18 19:23:45


Asking Core as a whole is like herding cats. It is just simply asking for the impossible. Even Segwit agreement only happens in the last minute.


My guess is that he wrongly assumes that those who attend the meeting has the power to push through the changes, just like what he is doing now. Well, he guesses wrong. Even those who attend the meeting receives reprimand afterwards. 
@_date: 2017-03-17 13:30:27
There is not enough review. Problem with Bitcoin is there is no one telling you what to do. So everyone will work on whatever they like. Mark Friedenbach used to be working on something like this until chase him away:
@_date: 2017-03-11 17:47:30
Note that you will also need to consider adversarial case. Some people just want to watch the world burn by splitting outputs. At worst case scenario people can just fill a single block with a single input and fills the rest with outputs, like this case
This is why it is important to have full blocks, so that people who wants to bad things will need to spend more while people who wants to do good things will need to spend less.
@_date: 2017-03-19 03:57:03


There's voting there. Clearly stated.
@_date: 2017-03-17 06:10:45
If most miners "activate" (whatever that means in BU world) BU there will be chain split. Depends on how you look at it that might be a good thing though.
@_date: 2017-03-18 20:17:29


I meant "kicked" out in the sense that his BIP101 is completely rejected and he started to lose respect among his peer.


Let's just say that this is where I disagree. Take a look at Ethereum. Having a leader means less than optimal solutions are often implemented that results in a mess in the network. You can say the price is higher now but I doubt that is a thing that will last.


I think he himself already said that he couldn't be careless about what happens with Segwit though. That is the mentality of someone who is used to decentralized governance. Anyone can reject anything at anytime. 
And you shouldn't be disappointed about that (although rejecting something because of political reason is regrettable at best). Immutability is a characteristics of decentralized governance and it should be rightly celebrated.
@_date: 2017-03-07 12:22:06
For the record. Eric Voskuil (libbitcoin dev) on the same topic
I don't expect them to be merged in Core. Eric has previously blocked buried development before (also in the same thread).
@_date: 2017-03-18 19:08:30
Eh, no. Segwit supporter likes digital cash as Lightning.
Digital gold supporter=immutability above all. I think you are just not aware of the other extreme.
@_date: 2017-03-20 19:24:43
If they don't you can always blow up like btcd did above.
@_date: 2017-03-09 12:52:20


Uh, you see anyone regulating who can and cannot run Bitcoin node?
@_date: 2017-03-09 09:07:32
Nope, if miners create more than 21M BTC I will reject the block. If miner attempt to confiscate coin I will reject the block. If miner attempt 51% attack I will change PoW.
@_date: 2017-03-09 12:20:39


The only reason I quote Satoshi is because you brought that one up:




And you don't even consider the possibility of the network getting DoSed as a risk factor even though it already happens in the past. Good Job!
@_date: 2017-03-11 19:46:50
It doesn't matter where the responsibility lies, what matters is the result.
@_date: 2017-03-14 15:34:08
Wlad doesn't resolve conflict. When someone says NACK he won't merge the said commit until said person says ACK.
Similary Luke-jr will provide the BIP# so long as the proposal is well written enough, he will let everyone to judge it on its own merits afterwards.
@_date: 2017-03-20 18:59:42
1. Based on ACKs and NACKs. Even if the said gatekeeper disagree with the NACKs he still won't commit until the said person ACK it. That's the reason Mike Hearn was frustrated.
2. What minority? You can audit the code yourself and NACK it and it will still be counted. See how many people audit the code here:
Or here:
@_date: 2017-03-23 04:36:31
And sometime status quo is better than compromise.
@_date: 2017-03-17 19:34:39


This part. Where do you get them?
Also note that we have to consider various other kinds of attacks (UTXO bloat, quadratic hashing)
@_date: 2017-03-17 21:08:20


That's with the current 4MB already deemed unsafe. And from those how many txs not already inside local mempool? You will need a real testnet for that.


To be effective aggregated signatures requires segwit's new script capability.
By limiting transaction size you will also be unable to provide accurate accounting. Example: You probably can fit more normal 226 bytes (e.g more than 500 of them) in a block than a single 100kb transaction


My experience with that is current GPU's kernel is too big that you can't get enough global work size. I would be happy if you can prove me wrong. 
@_date: 2017-03-18 21:13:35
Describing BU? Sounds about right...
Edit: 
Here's what Segwit do: Replace blocksize limit with block weight. Extra 2x capacity.
Now describes BU.
@_date: 2017-03-06 16:30:13


The problem is when the development is held by single authority, which is not the case with Bitcoin Core. There are a lots of universities, independents, and other companies (e.g Chaincode Labs) that contributes to the Core. [Even Blockstream has to eat shit sometimes](
OTOH You should be worried about BU, whose funding solely comes from Bitmain, and has shown that their willingness to bow to their source (e.g giving control over block size to the miner)
@_date: 2017-03-17 16:26:49


1. Why do you assume that two miners will just happen to find block at the same time? This only happens roughly 1-2 times a day. When this doesn't happen parallel validation will do nothing
2. Why do you assume that some people will just continue mining on previous block when they already receive more recent block?


Compact block assumes there is no big different between miner's mempool. At higher tps transaction propagates less uniformly, some miner may already receives some transaction, some miner haven't. 
@_date: 2017-03-09 15:36:49


However, I wanted to share one interesting fact. has noticed that OKCoin futures tends to be lower than the spot price quite recently. 
Because futures is basically a promise to deliver the goods in the future it is basically a prediction markets on how the goods will price in the future. 
Normally in bull markets futures tend to be higher than the spot price because people will expect to pay even higher price in the future. Similarly in bear markets the reverse happen. What we are seeing now is that since Dec 2016/Jan 2017 futures have been lower than the spot price by quite a lot.
Purple/dark green is spot price
Red/Light green is future
Anyone please take note Bitcoin's motto is Don't trust, Verify. I still have pretty shitty picture but if anyone wants to improve will be welcomed. I don't have Photoshop (haven't felt the need to use them for quite some years now)
Lastly I just want to repeat please take this with a grain of salt. This is just an interesting observation. Correlation doesn't mean causation.
@_date: 2017-03-10 18:00:39
[Fortunately unlike Unlimited, there's such a thing as peer review in Bitcoin Core](
@_date: 2017-03-20 19:21:12


No, you're trusting the peer review process, something which you can easily participate in. Someone would raise hell if their concern is not being addressed, like here:
@_date: 2017-03-12 14:04:15


And a bigger block is not a good scaling solution either. Old transaction just can't scale due to quadratic hashing.


So basically you're against adding new transaction type? Even if ECDSA is broken and Lamport is needed? Or are you even against P2SH?


If SegWit is implemented as hard fork old node will be vulnerable to a chain split by malicious miner. In SF miner protects old node, HF no ones protect old node.


Repeat after me: UTXO bloat in bigger blocks is more dangerous than signature bloat.
Besides there will be no block size increase in the future even if we do HF, only block weight adjustment.


It happens to fix all the problems at once! Don't you see how good a solution is? It's like a holy grail! It's how Bitcoin is supposed to be designed in the first place!!
Basically all of your arguments are lies/non-issues repeated by people who doesn't know what they're talking about.
@_date: 2017-03-07 15:10:56
Devs already in their pocket:
Miners are already concentrated in China.
@_date: 2017-03-03 06:26:18


pull req# or GTFO
@_date: 2017-03-15 14:24:01


Doesn't matter. Satoshi's point is that people with 51% hashrate can't change Bitcoin's rule as they like.


I'm not OK with it. I'm just showing that their ideas is shittier than Satoshi.


Unfortunately Core doesn't have to do that, because a lot of people don't want to BU.


Tell that to ViaABTC. They only recommend 2MB


@_date: 2017-03-17 08:02:21


Those of significance and multi trillion dollars behind them also seems to think that R3 is the answer so I'm not really sure what your point is.
@_date: 2017-03-17 15:33:29


Well, that would depend on the agreement. For example exchange will probably pay for you since you initially don't have any btc. Maybe you will need to pay them back in fiat or they will just provide you that as sweetener (in the hope that they will make return you use their channels).
@_date: 2017-03-14 16:50:42


Are you saying after every soft fork we create altcoin? No soft fork doesn't break original rule, it just tightened them.
@_date: 2017-02-09 12:31:58
1. Need manual intervention
2. As long as there is a split  (even at 90-10split) in setting the entire network is at risk.
@_date: 2017-02-14 13:52:04


I would say 1933 is modern enough. Gold standard wasn't taken off until then.


Again as I have mentioned elsewhere my gripe is with people who use the word in whitepaper's "cash" to equate Bitcoin with banknotes/coins using solely on-chain transaction.


Its "inflation" is much smaller than economic growth, which is my point.


And ensuring everyone can run a full node and can mine (we have partially failed here) is crucial part of the equation. 
@_date: 2017-02-14 05:56:48
Actually this happens once. Blocksize limited to 250kb by miner back in 2013. Mike Hearn asks miner to increase the block size.
As a result fee in BTC actually drops. 
(scroll to the bottom)
@_date: 2017-02-15 15:52:17
So you're saying we should use RSA instead of ECC for Bitcoin because it is less complicated? Grow up man.


A voting process that doesn't consider the rest of the economy. Satoshi's genius is that he actually limits the power of miner. And BU wants to throw that away. 
Here's a simple litmus test. Why does all alts implement Segwit instead of BU?
@_date: 2017-03-07 22:56:05


It has a **technical consensus**, which is entirely different than political consensus.
Now, apart from Roger and miners who is against Segwit?
@_date: 2017-02-13 10:14:51


My experience with semiconductor industry is visibility is only 1 year ahead. 5 Years might as well be Goblin Town. So never say never. Maybe in 5 years someone will find out how to work out Satoshi's fraud proof (or maybe no one will), maybe in 5 years someone will find out how to do UTXO sharding (or maybe no one will). Or maybe Sergio's scheme works (or maybe it won't).
However a good R&amp;D will always push the solution that has higher probability of working first. I think Core devs did a pretty commendable job at this. Lightning and Segwit has a decent chance of working with pretty high expected return. In the pipeline we have signature aggregation. Weak block and mempool sync are being worked on but Peter Todd doesn't think weak block is incentive compatible and Luke-jr thinks mempool sync does more harm than good but who knows? It's not R&amp;D if we have 100% certainty.
But more importantly R&amp;D needs data as well from the production. It is understandable that the production might have some concern because they need to do things they never do before. And there is concern that doing things new way may interfere with the old product (e.g cross contamination). This concern is valid but without data from the real word R&amp;D can't proceed. Who know Segwit/signature aggregation might  provide enough incentive to defrag UTXO that further block size increase is possible (or they might not). Or compact block may be more effective than we thought (or maybe not). Blocking new way of doing things is just the stupidest way if we want progress.


Those are things that produce scrap in semiconductor industry. What's the point of producing things that you can't sell?
@_date: 2017-03-09 10:24:57


What are you talking about? I could be careless about Segwit. A 10 blocks reorg OTOH will be enough to convince anyone to change PoW
@_date: 2017-02-09 07:28:04


You are still surprised of people's stupidity even at your age? You must have live a life full of luxury of not meeting stupid people :)
@_date: 2017-02-03 14:08:44


Ethereum starts with ~9000 nodes and now ends up with ~6000 nodes. No light client improvement in between. Only single blocksize increase and a few attacks.
@_date: 2017-02-11 08:54:14
I would chide my own mother if she told me vaccination cause autism.
@_date: 2017-03-09 11:05:32


The one that develops Lightning and Signature Aggregation.
@_date: 2017-03-17 17:33:15
Fungibility is a property of a sound money though. And his concern is valid.
@_date: 2017-03-01 08:50:30


That also applies to script size and push size as well. Are you against people using Bitcoin for smart contract? BTW do you know there is a maximum message size of 32MB in the protocol? Do you want to remove that as well? Because otherwise your blocksize can't be larger than 32MB. 


We were talking about Satoshi's approach in the context of whether he wants multiple hard fork.
1. Miner forgot to change the limit on time--&gt; Miss revenue
2. Merchant forgot to change limit on time--&gt; Getting tricked into receiving false payment.


Because no one was using them to actually verify payment.


Assuming that they will on board at the same time but you have shown yourself to be selectively deaf.


In terms of time? How often do you sell your house or for that matter liquidate your retirement account
In terms of fee? $2.5 is too expensive for you?


Assuming there are competitions that is good enough. Ever increasing fee shows otherwise.
@_date: 2017-03-15 23:38:00


Noticed how I quote him? He was the first one to bring that up.
@_date: 2017-03-17 06:09:38
Why does blocksize should be dynamic when the technology is stagnating?
@_date: 2017-03-17 12:45:46


If you can provide solutions that addresses all the technical concern regarding increasing blocksize willy nilly I would be glad to hear. If you are not aware of the technical concern regarding increasing block size you will need to educate yourself.
@_date: 2017-03-01 11:19:51
This was after was added as moderator. C'mon guys we can do better here.
@_date: 2017-03-05 04:11:08
It is not guaranteed to be profitable. Like you said yourself.


@_date: 2017-03-15 23:41:42


Nope, it is the same. If you delay your enemy node by x second you might as well withhold block by x second.


A transaction that just happen to have excessive witness? Sure, nothing suspicious here guys.


*Sigh* Again, UTXO bloat is scarier than signature bloat. You don't need to do shit about signature, just ignore them. OTOH creating outputs require I/O operation (memory in case of miners) that you probably will need to redo in the future. You can kill your enemy by a thousand cuts instead of wasting your stamina.
Not to mention creating outputs is ridiculously cheap. They only made up like 10% of the transaction size. You can make 10x more outputs by simply doubling the fee


Not related to our discussion.
@_date: 2017-03-18 20:04:25


You can say the same about BU supporter. 
I really doubt that there is less extremist on this side than on that side.
@_date: 2017-03-14 15:43:18
*sigh* 
TL;DR: Use multiple VPS, mine a block, measure propagation time based on 'inv' and 'getdata' from Bitcoin Core's debug log. How is that not clear enough?
@_date: 2017-03-15 14:26:18
Can't think adversarial. Downfall of BU supporters.
@_date: 2017-02-06 08:40:03
Maybe you will need to work on your reading comprehension...
@_date: 2017-02-23 11:36:52
Yup, there it is. A promise to shift the goalpost.
@_date: 2017-02-28 10:28:52


Similarly any altcoin that can result from 2MB hard fork is also fair game. The reason we haven't forked is that many people think that there's significant support for 1MB.


worldcoinninja (one of the Ethereum Olympic winner) is now working for ETC. 
You can even argue that the DoS attack was done by someone who was disillusioned by Ethereum.


The reason people are against HF is that because SegWit already puts too much pressure on the system already.
@_date: 2017-03-15 18:48:04
0.1 protocol or 0.2 protocol?
@_date: 2017-03-14 16:57:46


Whatever being defined by my current client as 'valid'.


What do you mean by centralization of rules? Post BIP-34 and BIP9 All soft fork is crystalized after miner signaling


So by your definition making P2SH anyone can spend is valid if there is enough miner support?
@_date: 2017-03-09 11:04:33


Does Bitcoin requires trust? In a way yes. You will need to trust miner not to do 50% attack. The only mitigation for this kind of attack is through social layer (PoW change). So yes, Bitcoin is semi trusted.
@_date: 2017-03-17 09:13:08


I am just making a point that scaling according to demand doesn't make any sense since demand is infinite. If you match supply with demand supply is infinite as well.


Depends on the use case. For example what if I want to be so sure that my movie will still be around 100 years from now.


Thank God blocksize limit will makes it costly.
@_date: 2017-03-14 05:51:54


What's the meaning if you increase block rewards by 100x (e.g when the block reward is too small) and price "crash" by 50x? You still profit either way. Unless you guarantee that the price goes to 0. That's what Central bank do BTW.
@_date: 2017-03-14 16:38:15
Sure, just make sure you tell everyone not mention "Nakamoto Consensus" or "longest chain" when you are defending your idea. Because that has just been totally invalidated.
@_date: 2017-03-14 17:34:00
Well, then you will just follow along the soft fork, hence not altcoin.
@_date: 2017-03-19 16:01:24
I would say it is more decentralized. Take a look at Ethereum. GPU based. Mining pool at 1st position is US Based. 2nd one China based. 3rd one Russian based. 4th one China based. 5th one I'm not really sure. Also note that the 3rd and 5th one are the mining pools that activates Segwit in Groestlcoin
@_date: 2017-03-09 13:41:14


If the bartender doesn't respond you can settle on-chain or pay through another route. If the bartender tries to steal your money you can steal his money instead (in case of two-way payment channel).
@_date: 2017-03-10 20:31:50
Satoshi only gives power to miner over **transaction ordering**. Anything else is not Nakamoto consensus. For example on the risk of 51% attack:


BU already fails this test.
@_date: 2017-03-17 12:53:42
Because the behaviour is non-deterministic, so that qualifies as a bug, and not a consensus break (not that I totally agree with them)
@_date: 2017-03-09 08:01:13
Enjoy your new Keynesian miner overlord while the rest of us shows you the value of apolitical money.
@_date: 2017-03-07 22:57:40


Ask miner to create more than 21M BTC. Go ahead. See what happens.
@_date: 2017-03-17 06:26:35


That's really stupid though. Layer 2 has always been a possibility. If not with LN it would be with Bitpay or Coinbase. LN just gives more value to the chain by taking all the use case can't be taken care off by neither centralized off-chain nor on-chain
@_date: 2017-03-15 10:25:45


On **SIGNATURES**. Signature bloating is less dangerous than UTXO bloating. This is probably the thousandth time I repeat this assertion.
@_date: 2017-03-14 17:32:28


You will need a source for that.


Goes to show Adam Back doesn't control Bitcoin Core right?


Actually blockstream is already around before blocksize debate, like in 2014
@_date: 2017-03-17 06:59:44


You are assuming 4 times x 1 hop or 1 times x 4 hop. 4 times x 1hop is definitely not enough because Kevin Bacon degrees of separation states at least 6. 1 times x 4 hop doesn't leave enough for redundancy (and still doesn't cover Kevin Bacon degrees of separation). Note that this is for 1MB alone, not 2MB or higher.
We haven't even talked about downloading the entire history.
@_date: 2017-03-14 18:40:54


From security purpose soft fork is safer since whatever you will do you can already do with the current software build so if it can be abused people already abuse it. Meanwhile with hard fork you are adding untested feature.
@_date: 2017-03-11 18:47:00


At least these people won't make UTXO bloat even worse.


Like I said **by preventing those outputs from being split even further**. 
Take a look at this chart:
1. Low fee enables July 2015-Sep 2015 UTXO bloat. You won't see those kind of attacks again these days
2. You can see that the graph is perpetually increasing, except for 2 regions. 
(a) The period where 250kb soft limit is reached  (well at least increasing at slower rate). Early 2014 is about time miners started finishing the conversion, take a look at the sudden drop of BTC/kb fee here
(b) Periods starting from 2016 when we started having full blocks again.
@_date: 2017-03-14 04:17:20


Uh, 'quickly' because Matt Corallo found the bug. Even then he has to fight Roger for it.


That commits includes lock-free validation (note: this is in conflict with BU's shitty parallel validation)
(Read Jeremy Rubin's tweets)
Cory Fields' network refactor
Ethan Heilman's eclipse defense that consist of many months of research.
So, yeah nothing much.
@_date: 2017-03-17 14:33:21
Updating a channel costs close to nothing. So let's say an exchange open a channel to you,  the exchanges pays on-chain fee assuming that they will get more from your transaction in the future. This is where you get your Bitcoin. 
You can then open a channel with the drug dealer hub(who happens to be loaded with cash, let's say Silk Road, or Agora who also assumes that they will get more from you in the future).
You can then transfer your Bitcoin from the exchange to the drug dealer hub to your drug dealer. Paying minimum fee each time. 
The exchange and the drug dealer hub expects that with enough transaction it will be enough to cover single on-chain fee.
How expensive do you expect the on-chain fee BTW?
@_date: 2017-03-15 14:25:11
Can you promise that if Core hashrate exceed BU's you won't do anything to save your chain? I would be happy getting additional BU coins even if just to sell them.
@_date: 2017-03-15 19:03:03


This cabal can withhold block instead of wasting bandwidth. Much easier to do so. Even then the study has already shown 4MB is safe even without compact block.


Whatever risks exists in Segwit is orders of magnitude less than 2MB blocks. If you don't want Segwit "discount" then you don't want capacity increase.
@_date: 2017-03-14 18:48:45
**Only** if you have 51%+ hashpower. But even then you will have to be willing to 51% from the very beginning of soft fork meaning lost revenue.
I also would be very surprized if original client owner is willing to be re-orged that far.
@_date: 2017-03-19 04:41:49
How dare you adding quote to the Bible! Blasphemy! 
Didn't you read the bible? Revelation 22:18 If anyone adds anything to them, God will add to that person the plagues described in this scroll
@_date: 2017-03-14 10:57:04


The only way for the cost to increase it limit the blocksize.
@_date: 2017-03-07 05:15:59
Fact: Even if we replace the entire block reward with transaction fee it is still cheaper than Western Union.
@_date: 2017-03-14 06:00:19
[Well, their testnet just got burnt for one]( Funnily because they let miner set the block size :)
@_date: 2017-03-17 15:40:42


That is no longer required with Segwit. In fact that is what Segwit all about.


Again, the exchange/drug dealer hub will probably pay you the initial fee of setting up the chain in exchange for your customer loyalty.
@_date: 2017-03-09 11:02:55
1a) I'm talking about BIP109. BU's change also implement around that many lines without replay protection and without wipeout protection.
1b)You shouldn't be making any claim to things you can't prove
2) Bitcoin is designed to have Block size limit. Even Satoshi's HF code indicate it as such
(No mention about increasing it indefinitely)
Hal Finney knows that Bitcoin can't scale
Even the first person to reply to Satoshi also knows that
If you don't know about that you shouldn't be making comments about "how to fix quadratic hashing"
3) That pieces of code fixes malleability, enables signatureless IBD, prevent UTXO bloat, and fixes quadratic hashing. Compared to BIP109 I'm definitely getting better return on my investment.
4) Nothing to do with our discussions. You were asking for what use case Lightning can fulfill that Bitpay can't. I just gave you one.


Ethereum case study shows how removing the restriction is bad.
@_date: 2017-03-20 16:02:28
1. Ethereum has quarter of the value of Bitcoin, running entirely on GPU 
2. Security will come to chain with most value, not the other way around 
3. I would be amazed if BU still has credibility after the 10th breakdown
4. If a security guard can't do his job properly he deserves to be fired. He is welcome to find job at shittier establishment.


Nicholas Dorier has been asking miners about their concern nicely


Meanwhile Jihan Wu has shown his childishness every step of the way. 
AFAIC it's not Core devs who fails to reach out.
@_date: 2017-03-14 15:05:31


You do understand that is a transcript from a presentation, right? Are you going to read your paper line-by-line in a proceeding?
@_date: 2017-03-14 17:34:34


Well, the said companies and miners can help to code a solution that helps to alleviate everyone's concern, that is how decentralized governance works. It is easier to keep things the same than to make the change.
@_date: 2017-03-14 04:02:18
Here's the damn thing though. There has been nothing consistent about BU. 
First miner decides block size. Now they add exception when miner is pro-Core. 
First people can freely change their settings. But they won't because afraid of fork (putting EB1). But in real life they actually do (EB1 actually makes up minority of BU node).
What's next? 21M limit no longer sacred?
@_date: 2017-03-17 14:00:08
Great! I hope they can continue R3's success story.
@_date: 2017-03-17 13:08:15
Same with your initial discussion about the price.
@_date: 2016-06-26 14:05:03
Take Lightning as an example. That's a two-party contract that limits its participant. There are quite a lot of hacker in the world but the only one who can affect the contract is pretty much the two involved
@_date: 2017-03-20 18:41:59
This again?
1. The said gatekeepers will not commit unless everyone agrees. He doesn't involve his own opinion at all. In decentralized governance it is easier to remains the same than to change. Just look at the current stalemate.
2. Committing something is more dangerous than not committing at all. You should be more worried about someone inserting a backdoor than retaining the original code.
@_date: 2017-03-14 17:35:49


Sorry, can you rephrase that? If I have a HF that original client can no longer sync from(example full e2e encryption) do you object to that?


Nope, I have followed the progress pretty closely though. That's how I know the governance is still better than BU.


Not a democracy. It is a rule by consensus. If someone disagrees we keep things the same.
@_date: 2017-03-14 06:24:42


Miner only matters for old nodes, and they are being constantly attacked by miners mining segwit (inadvertently). If that hashrate is bigger than 50%, well same as BU when Core hashrate goes up. Total breakdown.
Their only choice is to create a competing soft fork if they want to split or mine behind a Segwit node if they don't.
@_date: 2017-03-18 17:26:50


less on chain transaction != less money. that depends on the fee/transaction.
There is already Bitpay and Coinbase. Lightning just takes care of use case that can't be satisfied by neither centralized 2nd layer nor on-chain transaction.
@_date: 2016-06-01 09:51:00
Unbalanced channel is bad because it gives the incentive to the person with zero balance to close the channel with non-zero balance(prior state of the channel). Remember that this person has nothing to lose because he has zero balance anyway, if worse comes to worst the other party only has zero btc to steal.
@_date: 2017-03-19 04:34:51
You don't have neither fraud proof nor sharded verification right now, which is still unsolved problems.
@_date: 2017-03-18 21:00:51


I am not aware of any. Are you?


July 2015 incident shows that.


And that shows that absent blocksize limit miner wouldn't know what to do unless being explicitly shown (e.g non-standard)


Wallet needs to routinely combine inputs or be smarter in input selection. That is not an option in resource-scarce environment.


Well, luckily with Lightning you will no longer need to have a hundred of inputs that needs to be combined.


Think of it like carbon tax. You need to do it, or there will be no more blockchain to talk about.


Well, you will need to start to look into other options then, like payment channel, or even alts. Ideally we should have Lightning.
@_date: 2017-03-17 14:20:10


Uh, you have a channel open then...
@_date: 2017-03-03 09:48:52


The cost of adding transaction to a block is negligible, just like cost of adding supply to Bitcoin is negligible.


And some miner will not like it. It is up to the duty of the economic power to regulate miner.


Like I have repeatedly said before. Miner is not the only one deciding the supply of block space, just like they are not the only deciding the supply of Bitcoin


Actually the link you mentioned also says predatory pricing **will** reduce fee below cost. And it argues that it will not be a problem because competition will just spring up later. In Bitcoin's case the full node owner may not like it because that will cause instability.
@_date: 2017-03-17 16:03:38
1. Compact block doesn't survive adversarial scenario, so being conservative is best
2. There is no study on how compact block react at bigger blocks
@_date: 2017-03-14 05:30:23
So if BU "activates" (whatever that means in BU land) and Core happens to have higher hashrate you will support Core then? Do you support wiping out BU chain?
@_date: 2017-03-08 04:04:27


Rational miner has all the reasons to inflate coins? What do you think Federal Reserve does?
@_date: 2017-03-19 03:38:31


It is not silly if the said person attempt to forcefully bypass the peer review person.


Not really, for example his signature aggregation actually depends on Segwit.


I would argue that immutability with war is still counted as immutability though.
@_date: 2017-03-14 18:47:38


So not being able to sync from original client is not an issue?


Freedom is slavery?
@_date: 2017-03-17 04:06:41


If people sleep at the beginning of the attack, wake up and go straight to office they will need 16 hours to upgrade (on top of downloading/compiling) (IIRC this is European timezone BTW, and not some third world country timezone)
@_date: 2017-03-23 07:53:56
I do, though. Any attempt in compromise will result in two chains, even if Core devs are the one who propose it. I'd rather lose BU proponent than whoever is pro-Segwit and against compromise.
@_date: 2017-03-17 13:03:49
Speculators gonna speculate. Personally I think having understanding of dev team's technical skill limitation is like having insiders knowledge in stock market in cryptocurrency. 
I know of recursive attack even before DAO attack and the reason I don't put my money in is because there's too much spaghetti in the code that I can't audit them properly. I thought Vitalik was aware of this attack, since he repeatedly argues the use of send over call. I assumed that he properly audits the code before putting his own money in. Guess what, apparently he doesn't. That's one sign of incompetence
Now don't get me started on all the DoS attack. Mainnet, testnet. Those breakdowns are something preventable.
@_date: 2017-03-10 20:06:42


And BU ignores all the risk that are already understood.


No, it's not. Simple block size increase has been discussed for 6 years. BIP109 is a simple block size increase, BU is not.
1. BU introduces a brand new game theory called "emergent consensus", which is completely incompatible with Nakamoto consensus
2. doesn't propose a replay protection even though they are offering a hard fork
3. can be wiped out if 1MB chain in the end comes up ahead, 
4. accidentally fork the network because of shitty peer review, 2 times nonetheless (once in testnet, once in mainnet, different root cause) 
5. vulnerable to UTXO bloat, 
6. vulnerable to medium EB attack, which is not yet fixed
7. Vulnerable to sticky gate attack, also not yet fixed


Segwit has been under development longer than "emergent consensus", and it is still within "Nakamoto consensus"
@_date: 2017-03-14 19:14:45


Are you saying that we soft fork without reasons?
@_date: 2016-06-22 12:55:51
Are you aware of the way Block Priority works? That means they are prioritizing one transaction over the other using non-fee based scheme. That means one transaction is no longer equal to the other. There is a little difference over this and suggested soft fork (prioritize whitehat over the attacker).
@_date: 2016-06-01 11:08:27
Yes, but remember not everyone can stay online all the time. Some part of the solution to this problem is that they pass the 'punishment' transaction to the third party under the agreement of reward sharing. It will be difficult to run this scheme if there is no reward to be shared.
@_date: 2017-03-17 19:15:05


You can easily detect that by orphan rate. If the case is severe enough people can demand PoW change. Looking at the current orphan rate I don't think that is happening.


You are assuming the mempool diff is still the same at 1MB with at 100MB.
@_date: 2017-03-09 12:10:34
1a) I didn't quote Satoshi anywhere on this part. Reading comprehension problem?
2) He puts it in main.h together with COINBASE_MATURATION (this is back when Bitcoin code was still less modular). If you don't define that as "consensus layer" I don't know what is.
3) None of John Blocke's medium blog has any technical reasoning. The fact that you can't explain it in your own words means you have no idea what you are talking about.


Anyone teach you about risk management? I would be worried about those people in "Music Industries" getting sold a snake oil now.
@_date: 2016-06-22 14:02:05
As I have said before they **don't** consider the fee. They are prioritizing their own transaction (the exchange) over the others irregardless of the fee. This is one form of whitelisting.
@_date: 2016-06-22 10:53:51
A little bit disingenuous thing for Samson Mow to say. 
There's a fine line between block priority and censoring transaction.
@_date: 2016-06-02 08:37:37
I'm actually a little bit disenchanted over all these blocksize limit debates (not really sure why I still bother probably just feeling like letting it all out) and you'll probably not read this anyway (it is over 9 hours after the original post after all) but I'll just post this anyway.


There's such a thing as soft limit which miner can freely determine(on top of minimum fee requirement). Of course you can complain that full node doesn't have any say over this but originally there is supposed to be no distinction between mining and non-mining node(one cpu one vote). Complaining about election result when you never vote is meaningless. Accessibility to mining equipment is a separate issue that needs a fix. From the network perspective there are only mining power and economic power, anything else is non-observables that are powerless.


It does. I think you are mistaking parent poster's view as no-limit at all rather than miner-imposed limit. Right now the limit is software enforced rather than miner-imposed.


The reason is because hard fork needs to be synchronized. There is a risk that by upgrading Bitcoin you will be split off the network. Satoshi is not ready to coordinate for that. Nothing to do with limit at all.


Uh, actually the default soft limit was 250kb(not really sure if there is any older limit before that). Before 2013 the limit was never hit. 
Anything that satisfy the fee requirement (or priority transaction criteria) goes. Mike Hearn removes that limit in 2013.


I think this is what OP meant. Right now the limit is not miner-enforced but rather 


Of course there is quadratic hashing issue but that shouldn't be solved with limiting blocksize (which is rather ineffective anyway).
edit: Aaaaand.... it's caught in spam filter. f**k
@_date: 2017-01-25 19:54:23
Using your comment as a placeholder to reply to sorry :(


At a cost of higher inflation. Try to do that in Bitcoin and people will slap you away. Not to mention short block time means you can't use compact block.


Except letting miners set a gas limit is not incentive compatible. It's the essence of regulatory capture. Monero has a better solution at a cost of perpetual inflation.


Unlike UTXO, account-based transaction model verification can't be parallelized.


At a cost of higher inflation and can't use compact block.


The only correct part of the post, unfortunately but seeing that currently Ethereum's blockchain is much larger than Bitcoin it is unfortunately not so true. At least its effectiveness is questionable.
@_date: 2017-01-06 04:23:59


will just say
1. You are changing the economics of Bitcoin, now you have 2 class of transactions, one with Schnorr and the other without.
2. This is so risky changing block size is much simpler
or some other variations of that. *facepalm*  There is no winning this one. It's like arguing with flat-earth proponent.
@_date: 2017-03-13 08:01:27


And BU doesn't raise it in the way Satoshi visioned, for example there is no blocknumber in their implementations.
@_date: 2017-03-17 13:59:26
No one knows what will happen in the future. Fee will continue to grow until it stops. Where it stops I don't know. I used to want a dynamic block size limit but with technology slow down I'm not really sure I want them anymore. Near term the math still works out. 
Personally I think we still have a lot of leeway in terms of fee. It is still less than a dollar now. Even if we increase by 10x or 100x many people still can afford it. 
But even if we do have that situation it is still better than status quo because
1. BofA can't do fractional reserve
2. BofA can't know where your destination provided you do multihop payment
3. Since it is a hot wallet a hub has an incentive to keep themselves small just to avoid being robbed. (although it is entirely possible there will be an asic just to run LN node)
4. BofA will still need to provide $1 for every $1 the client has.
@_date: 2017-03-09 14:42:00


The design assume fraud proof though.
@_date: 2017-03-14 07:02:49
What do you want? A peer reviewed journal? You can even write one out of first link.
@_date: 2017-01-23 21:29:00


It **is** true.
@_date: 2017-01-28 21:56:09


Wow, you're very productive with "alternative facts" today, aren't you? No, apart from miners signalling BU and miners signaling SegWit (e.g around 60-70%) miners are signaling for 1MB forever. Which actually makes sense, since they make more money that way.
@_date: 2017-01-29 01:12:35
What he is saying is that if big blocker wants to pay him he is more than welcome to accept it. The fact that he hasn't changed his opinion says something about his character.
@_date: 2017-01-12 19:47:38


Miner can print more than 21M BTC and send it to the wallet and SPV can't do jackshit about it.


How the heck am I supposed to do that when I need a bloody data center?


Sure, just ignores his comment about BitDNS
@_date: 2017-01-25 09:10:43
If you use --fast you are pruning.
Even on apr 2016 archive mode already reaches 15GB
@_date: 2017-01-25 08:36:10
Which doesn't exist yet. I can say Bitcoin also has treechain but guess what? It doesn't exist.
@_date: 2016-06-26 15:04:40


Well, to be fair I sort of see problem with DAO coming. In hindsight probably I should've been more vocal about it (unfortunately they push it so fast I don't have the chance to say anything about it). I mean there are people listing problem with it like here:
I've seen a lot of them are being dismissed. While it is true that most of them are not related to the recent bug the problem with bug is that most likely what you see is just the tip of the iceberg. When you have a list of bugs one or two of them are bound to be critical. List of bugs also meant that the concept is not being well thought out.


As long as you keep the system simple you can at least limit the attack vector. As far as Lightning is concerned I would say that it is simple enough that the only two parties involved are the one who can affect the outcome. 


Well 8 years track record shows that everything is fine, nothing is sure in the world. I see a lot of similarities between IC accelerated test and survival of a decentralized system. Most failure will happen within a few hours(IC)/months(decentralized system) and after that the failure rate will drop until it increases again in years(IC)/decades(decentralized system)(or perhaps century? to early to tell)
I mean in the real world someone can get a leak of your contract (e.g trade agreement) to take advantage of it (offer a better deal). It is pretty much the same thing.
@_date: 2017-01-25 11:06:47


Can't even be bothered to do apple-to-apple comparison. First of all I'm not really sure where you're getting 15 tx/s. 4,000,000 gas limit/21,000 gas used to make tx/15 s block time=12.7 tx/s. This is **theoretical** throughput, something you can achieve if everyone only uses Ethereum to transfer Ether to one recipient. 
In comparison Bitcoin can handle 7 tx/s if everyone only uses that with 1 input and 2 outputs (one for change address). With SegWit you will roughly get the same figures as Ethereum. All with 2GB pruned blockchain instead of 15GB.
Edit: Just in case 's reply suddenly magically appears below:


Were you there when we did Olympic? Because I was there. When we hit 25 tx/s ONLY 2 MINERS ARE CONTROLLING the blockchain. That's the main reason block time was being bumped to 17s from the original 9s.


Not enough of a safety margin to prevents the last attacks apparently.


You are neglecting that p2p can't be modeled the same way as centralized system. A new node needs to catch up from beginning it is not enough that your system can keep up, it will also need to be 100x faster to be able to contribute to the network.


Yes, putting the number in will give you 13.6 instead of 12.7. Not a whole world of difference there, isn't it?


If you are going to cite real world scenarios you should do so both for Ethereum and Bitcoin. A typical DAO transaction for example costs 100,000 gas
@_date: 2017-01-25 08:57:52


They are not paying for **my** hard disk space.
With xthin/compact block? Really small. .


[When you have enough hash power you won't need to worry about being orphaned](
@_date: 2017-01-28 01:10:10
Under best case scenario BU acts like Bitcoin Core.
Under slightly worse case scenario everyone frantically attempts to upgrade their software because last minute attempt of hard fork.
Under even slightly worse case scenario some people getting tricked into accepting 1-2 conf tx.
Going further down the rung enough people are getting tricked that the chain split into two because enough supporter on the other side.
You know, where I come from a system that acts the same as the old system only under best case scenario is not called an improvement over an old system. I don't think anyone sane could even call it a trade-off.
@_date: 2017-01-12 19:18:45


Are we going to play Satoshi says again today? This was his last words before he left.


So yeah, even with 1MB limit there are still ways to attack it. 
On top of that, it doesn't matter what Satoshi says. If enough people don't want to scale in data center we won't scale in data center, attempting to do otherwise will just result in split coin. 




The exact same view was held by Satoshi.




Funny how you appeal to authority when it supports your opinion and ignores it otherwise
@_date: 2017-01-25 06:45:44
Miner doesn't decide my node's supply side. Sure they can attempt to force it but that just ends up being with them on the other side of the chain.
@_date: 2017-08-09 23:56:38




My point is that the transaction itself serves economical purpose. OP_RETURN 0 transaction serves 0 economical purpose.


"Strange way of putting it"? What do you mean? Block weight is related to segwit discount. 4\*base+witness.
You are arguing that keeping the discount factor constant at 4 is important but you don't realize that keeping bandwidth rational is one of the technical consideration?
This is the link you provided:


So the reason the discount is 4 is to keep block size below 4MB.  If you change the block weight of course the discount factor need to be changed.


You idiot! Every single piece of segwit as soft fork has a purpose. There is no difference between swsf or swhf


There is already a split. How is Segwit2x can "heal some wound"? Antpool can support bcash anytime they want. 
And how exactly is Segwit2x can "heal some wound" when they **actively** reject advice?
@_date: 2017-01-25 07:23:11


Make **who** happy? will just come up with this kind of shit instead.
I'd say get SegWit activated first only **then** plan ahead. I think the current consensus is to replace block size with block weight. If no-brainer segwit/base data composition can't even get passed there is no doubt any kind of block weight composition will also not get passed
@_date: 2017-01-25 19:07:54
Where were you the last year or so?
First of all SegWit raises the blocksize to 2MB, only it does so in a safe manner.
@_date: 2017-01-29 01:54:03
So, basically you're agreeing with me? That the fact that he took money from Blockstream is irrelevant to his decision making process?
@_date: 2017-01-25 08:53:15
And now you're just adding mutability into the list. It is unlikely they will be able to pay for the subsidy for all the uncles with the cap.
@_date: 2017-01-12 20:06:28


Uh, no. 21M BTC limit is preserved whether or not 51% miner agrees to it.
Read the part on SPV.




This is his assumption on "scaling data center" something that we don't have today.
@_date: 2017-01-25 20:56:39
Pruned it is much smaller. Ethereum's pruned blockchain size was already 5GB back in July 2016.
Still, it is quite concerning from something whose normal load seldom exceed 1 tx/s.
@_date: 2017-01-29 00:59:15
So? He made that comment a year ago. There is a change in the website. Even it states clearly "contractor"
@_date: 2017-01-25 08:36:35
You do realize you're paying hidden fee in form of inflation right?
@_date: 2017-01-25 16:44:42
Bitcoin's current monetary inflation is ~5%. Ethereum's inflation is ~10%. Go figure.
@_date: 2017-01-29 00:54:39
Open Hash != Bitcoin Core
@_date: 2017-01-29 00:04:43
Wow, what a truly convincing proof.
But wait, I have counter proof:
@_date: 2017-01-30 09:05:13
That came from Satoshi's original codebase. And now you're blaming people who spent last couple of years trying to fix them (malleability, BIP66 fork, quadratic hashing, etc.) 
If there's any change that triggers 2013 fork it is [this contentious one by Mike Hearn]( Luckily we have now learned how important it is not to ignore contentious change. 
BU, on the other hand introduces a new bug on something that works perfectly over the years. The worst part is they manage to remove two safeties while doing that. It's like removing gun safety after you fail to shoot yourself in the foot the first time around and finally manages to do just that.
Apart from those two you mentioned, none has caused anyone to lose money.
@_date: 2017-01-31 10:30:50


Not entirely true. If they actually run Unlimited there is a good chance they will extend Unlimited's shitshow chain every time they screw up, tricking all the SPV clients. The truth is without fraud proof all SPV clients are now at risk.
@_date: 2017-08-17 02:35:29
Ethereum Classic survives with less than 0.5% hash power. Bcash survives with less than 13% hashpower. Besides, hashpower follows the market, not the other way around. How much value do you think a chain without long term plan has? The last commit was 26 days ago for crying out loud.
@_date: 2017-01-28 21:34:24


Is that an "alternative fact"?


No one is in charge of anything. How hard is it for people to understand Bitcoin's development model? Luke wrote a proposal and everyone needs to vet for it. In fact, the first reply to his proposal is [no, I don't agree with you]( For the record the person replying is Johnson Lau, who contributes significantly to SegWit development and **not** Blockstream employee. 
You also can write the proposal you know? Just make sure to make it reasonable (e.g, "no, miner won't do it" is not a valid solution to quadratic hashing)
@_date: 2017-01-01 19:46:44


I've seen a variant of this argument quite often (mostly in forms of decentralization is not a binary state). But guess what, even transistor is not exactly a binary state but it simulates one by having exponential change between 0 and 1. Anything that has superlinear relation can simulate a binary transition.


The UTXO attack OTOH has been done before.
The only thing preventing that from happening in a full blown scale is real economic activity on 1MB block
@_date: 2017-08-23 15:50:32


1. Wrong, ETH/ETC has an [opt-in replay protection]( (e.g created by community but not by Ethereum Foundation), you know, same as the one proposed by Jeff Garzik
2. No everything was not "fine". [Coinbase lost money]( So did [Quadriga **one year after DAO Hard fork**](
@_date: 2017-08-25 21:14:48


Citation needed. Bitwala just left
So did Yours
If anything it is dropping.
@_date: 2016-06-22 15:12:59


Well in this case the whitehats want to go faster and it's good for them. Let me remind you that bribing miner with fiat is one possible attack in Bitcoin. This is one type of those attack. It messes around with fee prediction for one. 
Let's have a thought experiment. Let's say BTCC's hot wallet is being hacked with both BTCC and the hacker is owning the same private key. BTCC will prioritize their own saving transaction over the hacker. Is this something wrong?


This time I'm the one who is perplexed. How does this relevant? I never hold significant amount of ether as I indicated in this thread:
I am also being critical of their development when they are doing something wrong:
I'm simply interested in both Ethereum and Bitcoin as they seems to be polar opposite of each other. I don't have any skin in the game so I consider myself unbiased.
Edit: Can't english
@_date: 2017-03-18 19:53:16




Well, I do blame miner on that UTXO blow up on July 2015
You can even see it on your own chart:


Not being spent means not being split further. So it won't grow.
You can see that there is faster growth about the time soft limit was lifted (Jan 2014). 


So now wallets must start to combine outputs. You can clearly see it on the chart. UTXO sometimes drops. (it was continuously going up before)


Please write to dev mailing list.
@_date: 2017-01-03 17:10:59
Pre DAO? Yes, perhaps it is decentralized. Post DAO? No, it's not really.
Don't believe me? Let's recap what happened before, during and post the last Geth-Parity fork.
1. No one raises an alarm that there is not enough testing done on the consensus mechanism
2. After all the "no, this won't set a precedent" bullshit during DAO you guys mess with the state, **again**. This time with no opposition. Even if all of you agree that immutability is worthless there should have been someone who disagrees on technical debt basis.
3. Miner agrees to forfeit revenue on 165 blocks no questions asked
4. When it was revealed that Parity has a bug Geth straight away agree to reproduce bug. What's the point of multiple implementation if in the end you guys still go for bug-for-bug compatibility approach?
Right now Ethereum is only decentralized in a name, really. It won't make a difference if the Foundation (or Vitalik, I am no longer certain if they are a separate entity now) code their key into the program to select which chain is valid.
@_date: 2017-08-17 02:29:10


And where exactly are these "hashpower" going to sell their coins? All exchanges already refuse to list all forked coins without replay protection
@_date: 2017-01-25 06:51:12


BitGo controls the backend of BitStamp and Kraken. BitFinex and BTCC are already on board.






@_date: 2017-01-30 09:32:34
A bit difficult when you are being accused of attacking them while pointing out vulnerability.


No, no, not an issue.


No, no, not an issue.


No, no, not an issue.


No, no, not an issue.
When this shit already happens you are blaming the lack of collaboration?
@_date: 2016-06-26 13:00:46
I think that's only true for the case where the contract involves a lot of anonymous party, like DAO. If you limit the number of participants into two like the normal contract in real world you will still have the same result with hoping one person is better than the other.
@_date: 2017-01-12 20:30:41


Yes, just your typical modus operandi when what Satoshi says goes against your belief you immediately dismiss it. There is nowhere in the whitepaper where he states that.


If you know for certain that SPV going to follow your chain no matter what where is the financial incentive to remain honest?


Already there since 2012.
@_date: 2017-01-25 07:26:30
@_date: 2017-01-25 21:23:41
Pretty much, yeah.
@_date: 2017-01-29 00:23:45


Yes, you did.


Bitcoin company != Bitcoin. The next thing you will say there is Bitcoin CEO.
@_date: 2017-08-17 02:49:01
And you think that is the sole factor that determine a coin's survival? No. The only reason those coins survive is because there is a demand for it. 
@_date: 2017-08-10 02:05:54
So you're supporting 2x now? LOL. What happen to "Bitcoin Unlimited"? Oh yeah it is called "Bcash" now. 
Unlike typical Bitcoin Unlimited supporter I don't care what people call the original chain I will just transact there. So will most of the DNM. Do you think they will just lie down and let the suits call up the shots?
@_date: 2017-01-15 23:32:17
A lightning node is only as much as a "financial institution" and a "third party" as a miner is.
Both are permissionless and has less barrier of entry compared to regular financial institution
@_date: 2017-08-24 02:20:53


It would be like saying your Signature Aggregation is a "Bitcoin Core" project. It is a project by Bitcoin Core Contributor and if there is anywhere it is going to be merged most likely it will be Bitcoin Core.


@_date: 2017-01-09 21:10:02


You don't have any power, economic or otherwise if you don't run a node.
@_date: 2017-01-25 19:40:03
It affects decentralization for one. By making it easier to run a node you are helping to diversify the network.
@_date: 2017-01-29 00:12:07


You did the same with the original info.


For jobs related to Blockstream in the past, not related to Bitcoin. 


Nope, but the fact is he is no longer paid by Blockstream. Which is relevant.
@_date: 2016-11-02 22:38:46


You're the one who started by suggesting "institutional investor will be able to push the price up". I am just mirroring your discussion. Speculation is just that. Speculation. I am more interested in provable empirical data.


Bitcoin has always been a bottom-up movement. I'd rather not have people who has been responsible with the current economy had anything to with Bitcoin just yet. 


Nope, the cost that I quote is actually less than cost per tx in Bitcoin if block reward is put to 0(something around $2.5-3.5 depend on whom you're quoting). But it proves that there is actually a demand. So we can make do without $0.01.
OTOH if you're hoping BTC to mirror PayPal you are looking in the wrong direction.


And what do yo use as an indicator? (2 years are actually long term in my book)
@_date: 2016-11-30 11:06:53


Uh, no. SegWit tx is non-standard, which means it won't be mined nor relayed in the old node.


Uh, no. How the hell do you verify the validity of the signature if it is removed from the transaction?


Again, no. SegWit is targeting all the fats for removal, a plain block size increase remove **both** the fat and the muscle.
@_date: 2016-11-27 15:56:52
A 2MB attack block spamming utxo would do more damage IMO.
@_date: 2016-11-29 10:07:26


UTXO is necessary to keep in storage no matter what. How would you bootstrap a new node if you don't sync a new node?


The blog post itself is already pessimistic. He doesn't even consider worst case scenario.


That's what a normal person do. A hostile attacker otoh...


It is pretty easy to calculate worst case UTXO growth. You want a neutral PoV? [Listen to jtoomim](
@_date: 2016-11-24 20:23:09
One of the reason for tx malleability is that Bitcoin accepts whatever OpenSSL produces as valid. If you try to reimplement OpenSSL in more than one implementations(like the work on libsecp256k1) you would have realized the deficiency in the encoding.
@_date: 2017-01-29 00:06:32


This is what f2pool is signaling in their block:


This is what Antpool is signaling in their blocks.


How exactly do you decode that into 2MB-8MB. LOL
@_date: 2016-11-12 06:12:39
But it's not. There's still F2Pool and BW, both are Chinese. So there is still balance on that side.
@_date: 2016-12-09 11:15:35


The main chain is not chain with the longest PoW, it is the longest valid chain with the most PoW. But I think most of you won't understand that. 
@_date: 2016-12-08 18:05:45


Yes, just like what happen in Ethereum, where Dwarfpool refuses to include transaction. There will be uproar over people's transaction is not included. Meanwhile you guys would be like 'it works like it is intended...'


It's not the LoC that matters. It is the complexity. Now it is getting more difficult to see how effective the solution is(or whether it introduces another failure mode). It might work for a year until someone find out how to break it, just like Ethereum.


@_date: 2017-01-25 08:52:04


Pruned. Pruned Bitcoin blockchain is 2GB in comparison. That's after 8 years of usage
@_date: 2016-11-27 16:28:27


It's all in the delivery. For example you won't ever catch Vitalik swearing.


I think that's also because he is "nice". 
@_date: 2016-12-10 19:17:33




Does not compute.


Why does FT initially claims to be "Flexible"? Because it enables soft fork in the end, the same way SW does. 
The only way a hard fork can be cleaner than soft fork is if you don't need to support older kind of transaction, which is not the case.
@_date: 2017-08-30 08:10:14


We still do have trade secrets. People just make decision whether or not to patent based on how easy it is to reverse engineer the technology instead.
@_date: 2016-12-08 16:14:05
Huh? That's a non-sequitur. Isn't even related to what I say... It will still cost less to break input into multiple output. SF or no SF
@_date: 2016-11-28 11:01:26
Ethereum has perpetual inflation, big difference.
@_date: 2016-11-17 07:05:18
As expected, he has stopped responding. ViaBTC always chickened out when challenged.
@_date: 2016-11-28 14:28:06
It is only as bad as if there is no increase from 1MB to 2MB. And with full blocks people will have difficulty doing that.
@_date: 2016-11-28 14:39:54
Where do you think is the bottleneck? [Hint: It's not bandwidth](
@_date: 2016-11-18 13:58:08
So  and  may already be fixed and you are just butthurt about Adam's comment that you dig it back? And  only affects debug mode? Can you explain this part?


@_date: 2016-11-01 17:43:07


That is the coin vote for block size, not for hard fork. I've yet to see PT's proposal for hard fork


You mean until AntPool uses their wallet to sign?
But seriously if people want to really do it don't do it halfway. It was big blocker who blocks the coinvote, not the other way round. 
@_date: 2016-11-30 11:31:27
Then upgrade. 
Because the alternative (hard fork) is your node won't even know that the rest of the world has moved on if you don't upgrade.
@_date: 2016-11-30 10:20:36
Now we've come back full circle.
@_date: 2016-11-28 23:11:28


Do you understand that UTXO is not static? That it is growing? Right now there's an effort to keep UTXO inside the memory.


And yet right now full node counts only 5000.


And you want to force everyone to upgrade before the computer being obsolete?


What do you think is preventing someone from making a **pruned** node that grows 10GB a month? Yes. A full block.
@_date: 2016-11-26 11:11:03
I would love to hear how he plans to totally fix malleability for old style transactions though. Sounds like the case of someone demanding the impossible. The truth is there is only so much improvement that can be done on the old-style transaction. Even FT will introduce a second kind of transactions that will destroy fungibility. Meanwhile, once inside an LN channel the fungibility actually **increases**, with no one knowing where you directs your payment.
Besides, even for old-style utxo you will need to send it to 2-of-2 multisig. That's like saying 1-of-1 utxo is no good here, go spend it somewhere else (2-of-2). That's just how Lightning works, you can't use 1-of-1 utxo.
One more point, with CSV and CLTV it is actually possible for people to create Lightning with normal 2-of-2 multisig. It is just annoying with its limited lifetime. People are free to code it (although I doubt someone would)
 I'm not sure would be commenting here though. Never seen him around so much.
@_date: 2016-11-25 20:51:02
1. Empirically miner is still engaging in SPV mining even with relay network (which ideally should also be retired). If the block size is optimal miner wouldn't be able to tell the difference whether or not they engage in SPV mining
2. 4MB is about the limit in terms of bandwidth for current technology. 
[Source 1](
[Source 2](
SegWit actually delivers 2MB-equivalent so it is not pretty bad. Why not 4MB? That is to keep the current worst-case UTXO growth the same as if there is no block size increase. Right now there is no incentive to keep UTXO growth minimal, which is why it was possible for SatoshiDice to put their messaging system inside the blockchain. 
If you want more capacity you probably could replace block size with block weight (SegWit is a step towards that direction), but it just wouldn't happen overnight.
@_date: 2016-11-05 07:43:24


Actually the magic number is somewhere around 4MB.
SegWit actually delivers 4MB under worst case scenario. 
Hopefully we could get more if compact block gives a good result but we will need to transition from block size to block weight since bandwidth bottleneck is partially lifted. This transition has been partially started with SegWit.
@_date: 2016-11-24 10:00:12


Miners are free to change prioritization. But they will prioritize it that way if they want to maximize income.


It makes worse case UTXO growth the same as if there is no blocksize increase, which is better than a plain blocksize increase.


Block size increase over 4MB is unsafe
Combine that plus an effort to keep worst case UTXO growth at the same pace gives you the figure for the discount.


Firstly, SPV security means that a node can't tell if 21M Bitcoin has been inflated, which is not the case. Secondly, 
in case of hard fork unupgraded nodes will have zero security.


Hard forking to a plain larger blocksize is a madness. Like it has been said before the incentive scheme in Bitcoin is not balanced yet. Paying per bytes only assumes that the bandwidth is a bottleneck, which can (and will) start to change.


The default setting is to accept maximum PoW at certain depth. That is the same as "leave it to the miner". I mean seriously, right now I can leave the maxblock set to 750kb, that will just leave me on a separate fork.
Besides, let's sybil and orphan each other's block until a consensus is found. A really barbaric solution. Not to mention opening up a possible attack vector.


That's not a totally bad thing. At worst altcoiner will fork away, at best a better solution will be found.
@_date: 2016-12-04 00:32:27


Who the fuck cares? There are 100+ other contributors to Bitcoin Core. I am not a Core dev and I can see clearly why increasing blocksize is a bad idea. Despite what wants you to believe Peter Todd doesn't work for Blockstream. Neither is Luke-jr. He was only a contractor at one point in time and seeing his hermit-like attitude I doubt he cares very much about money.
All the "Blockstream Blockstream" screaming just that. A lack of technical argument.


From what I see. Yes. There will probably be financial return in terms of network effect from Bitcoin usage.


IIRC they also have a small mining ventures. It certainly would help if they disclose but I don't see the needs for them to disclose it to people unless they own a shares in Blockstream. 
@_date: 2016-12-17 05:07:40


AFAIK compact/xthin block relay can't survive adversarial scenario. Shouldn't we wait until mempool-sync/weak-block before we re-assess the possibility of an increase?
@_date: 2016-12-04 00:19:25
A fork will always partially break Bitcoin's security model. That's why it is bad. Even hard-fork in the future would partially break Bitcoin's security model because there is no way to guarantee everyone has upgraded. At least with SF we can gauge the amount of security judging from the hashrate. With HF there is no way we can do that.
@_date: 2016-11-27 16:32:07


Actually I equally blame people who puts money in as well. I'm not really sure why but the market for cryptocurrency is somewhat inefficient in that information is not directly reflected in the price. The fork and the attack is worse than the DAO and yet the market seems to keep their calm.
@_date: 2016-11-15 08:32:22


Actually it **does** matter. Non-Upgraded nodes depends on miner to provide security for a soft fork. At 50-50 split there is no n where n-conf can be considered safe (for non-upgraded nodes).
@_date: 2016-12-19 15:16:42


If my node never upgrades I will never consider that as a "real Bitcoin" 


What if miner never switch? What if the PoW is changed (because the old guard threaten to 51% attack)?
@_date: 2016-11-25 13:15:37
1. When Ethereum first started geth constitutes 95% of the node simply because they have the best performance and portability. The nearest competitor (C++) has loads of dependency that just wouldn't compile nicely. If an alternative implementation wants to gain market share they should bring something new to the table, either from performance or portability point of view.
2. An implementation that shares ~90% of the codebase shouldn't even be considered "alternative implementation" because it shares 90% of the behaviour of the cloned implementation. It also doesn't bring anything new to the table as that implementation will also have the same bug as the original one.
3. What you have instead is [someone trying to modify the code without any clue what he is doing]( If you really want to be considered as an alternative implementation then rewrite it from scratch.
@_date: 2016-11-14 09:18:51


You can always spend it in an exchange. I mean if PayPal/Visa works out great for you that's great. I'm happy for you. That's just means you are not the target audience for Bitcoin currently. 
Right now there are people using Bitcoin to buy drugs, donate to Wikileaks, escape capital control, hedge against economy, and international money transfer. These are the primary customer of Bitcoin and they don't have much choice.  It's not a good idea to marginalize these people for others who has other options than Bitcoin. 
@_date: 2016-11-28 07:53:30


Around 10GB a month? Yes? In the meanwhile most likely caching UTXO in memory might as well be a luxury.
Besides, let's face it once HDD usage goes over 1/10th of total usage a lot of people turns off their node. No one wants to run multiple HDD just so that they can run a node.
OTOH, it is you **yourself** who [said that increase to 4mb is still safe]( this is pre-compact block (and FIBRE).


And that is something that actually happen to Ethereum. If that happen to Bitcoin we will be in full fire fighting mode instead of attempting to improve the protocol.
@_date: 2016-11-11 19:56:04


Dwarfpool is Russian based, I believe. And I don't think Ethpool/Ethermine is not based in China
@_date: 2016-11-29 23:57:27
1. It is crazy to develop a system based on future prediction. [Intel's 10nm has been delayed]( [Storage cost/gb is slowing]( Especially if an attacker can have access to resource that was catered for not-yet-available hardware.
2. To fully understand the implication of increasing the limit you need to understand nonlinearity effect. Just by doubling the limit doesn't mean you double the resource consumption. Ethereum's first attack was thwarted by decreasing the limit 1/3rd its original limit. The third one was contained by halving the limit. So it is not linear. There is a cutoff where things just 'work' and where things just 'don't'
@_date: 2016-12-08 13:17:38
SegWit transaction uses less resource on the system, so it makes sense to be cheaper to pay per byte. 
And old transaction is no way crippled, you still can make the exact same transaction pre and post segwit.
Lastly, miner can easily change the prioritization.
@_date: 2016-11-27 19:46:19


CMIIW but normal pruning would also prune signature. So the 3.8kb spam won't use storage. The kind of pruning that is not yet implemented is the one where an IBD doesn't require signature download.


Which doesn't reflect true cost of a transaction, that kind of counting only considers bandwidth. Ideally there should be another limit for the output part of the transaction, because it cannot be pruned. 


It is cheaper for both attacker and non-attacker. Attacker, OTOH has access to disproportionate storage usage at a discount. An output is only ~10-20 bytes of a transaction but it is the sole source of storage usage.




You just contradict yourself there. 
My point is with SegWit attacker still has to compete economically for blocksize limit with a user while for a straight 2MB increase they directly have access to the free space.
@_date: 2016-11-17 07:51:52
I retracted my statement. He is back. Just spouting propaganda though.
@_date: 2016-11-25 13:06:31


I was under the impression that the restriction was implemented under libsecp256k1. So it is actually outside? As in inside Bitcoin but outside libsecp256k1? Wouldn't that make it more difficult to work on libbitcoinconsensus?
Besides, my point is some of the malleability vector would be more obvious if you rework it from scratch, rather than reading someone else's code.
@_date: 2017-08-23 22:32:36
Explain the reasoning for the all efforts made for BIP91 to comply with BIP148 then.
They could have activated Segwit in September or October with better testing if BIP148 was not a factor.
@_date: 2016-12-16 20:09:45


How does it matter if it is a single employee or the whole pool in cahoot? Damage is damage.


No they didn't.


No. SPV mining was spawned as a way to counter orphan and is direct cause of [July 4th incident](
How does mining empty block helps a "jacked up mempool" anyway?


[Except they did this shit since a year ago](
@_date: 2016-12-08 13:13:47




Uh, SegWit also does... He knows that. The only nit that he has to pick is this:


And Satoshi also provides tx version byte, which he seems to happily use, essentially a reserved byte. It is really common to use reserved byte for future use.


That's because he doesn't calculate nlocktime and sequence number, [which he admits is not part of specification yet and doesn't know how to implement](


[Please try implementing the network layer first before reporting back](


Buzzword Buzzword Buzzword.
Oh, and lastly, while comparing with SegWit he mentions this


Not an issue. What?? That's the bottleneck for initial block download.
@_date: 2016-11-02 04:34:07
Yet the price continues to rise...
Are we talking about short term or long term? Do you agree that in the long term block size limit is needed? If you do agree then you would agree that Bitcoin Unlimited doesn't have any commitment to protecting 21M Bitcoin limit.
If you are talking short term there is SegWit. And another hard fork (see my comment above).
Bitcoin is not just another company. It is not PayPal 2.0. It is a sound money. As long as we keep 21M limit people will flock to it. The competition is currency, not PayPal. [FedWire itself process a measly 6tx/s] ( We don't want merchant adoption yet. We don't want investor who thinks of it as PayPal 2.0 either, they're missing the points.


How far do you think that transaction fee will go up? A regular SWIFT transfer costs $30. A regular WU transfer costs $10. At that rate we already can replace block reward. Why are you going after $0.01 market?


Where is that institutional investor when we quadruple the soft block size limit? The price actually drops.
@_date: 2016-11-11 21:08:56


Doesn't make sense that they use non-chinese mining pool though. I think General-Beck is Russian based. So did bit_novosti before he defect to ETC. 
@_date: 2016-11-28 12:32:51


Similar to the one I described above:


Miner doesn't need to pay fee. They can manipulate blocksize to be higher than necessary by producing fake transaction.
@_date: 2016-11-06 06:40:07


And the plan will include removing the block size and putting in block weight. This won't happen overnight so don't hold your breath.
@_date: 2016-12-15 21:52:44


Much easier to create a uniform but smaller block, let's say 750kb instead. That way they have better control.


Which doesn't make sense since they are pro-big block.
@_date: 2016-11-29 03:08:10


The only way it can have timeline is if there is someone with a final say on the development, which means a centralized development. Fortunately that is currently not the case.
@_date: 2016-12-16 22:55:19
What a truly compelling argument. I totally changed my mind after I read that /s
@_date: 2016-12-02 11:42:13


I can easily create a single tx &gt;3MB that is included in one block but not the other. During "convergence" this tx will surely not be in the other chain.
@_date: 2016-12-10 13:47:17
I probably wouldn't say that if he didn't say this.


After reviewing and he still doesn't understand that it **is either or**? If he **did** honestly review that it would be the first thing to notice.
@_date: 2016-11-06 06:44:57


By default miner won't include non-standard transaction so you will need malicious miner (whose block will be orphaned) on top of malicious user.


Standard transaction as according to the 0.13.1, not the version before that.
Just want to make sure but you **do** understand the difference between standard transaction and valid transaction right?


Unupgraded nodes only accept non-standard transaction when it is inside the block.
@_date: 2016-11-28 04:43:06


That's because you're not thinking "evil" enough. How many maximum UTXO do you think a single TX could create?
@_date: 2016-11-14 20:51:49


You might want to try Ethereum instead.


Because that's Bitcoin's killer app. That's one problem Bitcoin can solve that others **can't**.


You mean like ViaBTC throwing a hissy fit right now?
By becoming more PayPal/Visa-like you will be losing the primary customer. And that's game over, centralization means political money. This is the place where we need to make a choice.
@_date: 2016-12-02 08:05:14
Mars actually needs global warming to be habitable so still bad analogy.
The kind of planet we're talking about is still 99% earth.
@_date: 2016-11-18 13:30:54
Technically Adam isn't wrong you know? 
a. I have yet to see a proper research on how "emergent consensus" works in real life. For example what is the recommended confirmation you expect for a certain node settings fragmentation (remember there are a lots of parameters: miners, nodes, EAD, incoming block size limit, etc.)? How much miner loss in case of a consensus breakdown? How effective can someone disrupt the network in case someone creates a block that only half the network accepts? In Ethereum testnet I have seen first hand how a large scale Sybil (e.g Eclipse) can affect how the longest valid chain propagate. BU actually encourages this during dispute. Furthermore since it relies on social phenomena the repeatability of the research may not be so good. 
b. Show me research on how effective BU defense of QH is, which relies on the existence of a fork (which will fail because of SPV mining anyway, which ironically ViaBTC supports both)
Even if Adam is being childish that doesn't give you the reason to do the same. In fact you will probably gather more support by creating pull request and pointing that out, like [Greg did here]( 
@_date: 2016-11-28 11:01:02
Majority hash power can force a higher blocksize, because it will [benefit them the most]( at the cost of small miner.
The other kind of attack is also possible, where miner with higher hashpower with lower profitability force a blocksize decrease to increase the transaction fee. Miner with lower hashrate that has better margin who wants to bring down the transaction fee will be helpless.
@_date: 2016-11-28 12:36:16
Which is why your action to block the fastest way for additional capacity makes me question your sanity. Either vote to stay 1mb, activate segwit, or fork away (unless, of course you don't even know how to set a checkpoint). Even ETC is safe at 1/10th the hashrate of ETH. 
If your chain has any value the other miner will follow, not the other way around.
@_date: 2016-11-25 05:55:27
Ethereum worth a billion dollars at one single point in time. Doesn't stop anyone from using GPU to secure it just fine. If there is any weakpoint it is the developer. See which one more easily replaceable?
 I'd rather have a script kiddies botnet who activates SegWit than geographically-locked centralized mining farm that doesn't.
@_date: 2016-12-15 14:07:43


GHash.io, BTCGuild, Deepbit. Used to be leader, now no more.


Meh, they don't support SegWit. I'd rather they bankrupt themselves.
@_date: 2016-12-11 10:51:41


If only you could point out which part of SegWit is a technical debt? The networking part? The transaction verification part? The Witness segregation part? The implementation of compact fraud proof part? All this time you're talking in general term. I assumed that's because you can't pinpoint where is the flaw. If you can't do this I don't think you should be making an opinion on whether SegWit has induced "technical debt"


Uh, you just did. Here




That's why it can't be any cleaner than SegWit.


Again, you keep on repeating that without showing which part **specifically** where it's a technical debt.


HF Segwit is just SegWit with the merkle tree moved.


I wouldn't count FT as one.
@_date: 2017-08-09 23:54:11
The whole raison d'tre for Segwit2x is to prevent chain split. Now chain split already happen so riddle me this: what is the purpose of Segwit2x? If Jihan and co. really thinks that bigger block is the answer then they can support that chain instead.
I mean fucking seriously even Spoonnet is even more ready than Segwit2x at this stage.
@_date: 2017-01-30 22:49:50
So [I am no longer Peter Todd now?]( Can I be luke-jr next?
@_date: 2016-12-13 21:00:26


Hmmm.... I did explain on the the rationale on my reply to your very same comment. If only you would listen.
@_date: 2016-12-08 15:21:06


Again like what? If you upgrade the script you pretty much upgrade the whole thing.


Lightning uses Sequence. Do you have that in one of your "extension proposal"?


What happen if, by chance the UTXO grows beyond the amount of memory your system has?
@_date: 2016-11-01 22:11:26


The transaction fee has not been showing any sign of coming down. That means miner has been undercharging for their service. On top of that there is still SegWit to be considered. So the answer is I don't know. I will worry when the transaction fee is flattened. Besides, who says hard fork is not coming?


Please also read my other comment. That "urgent stress" is something we need if we want to keep Bitcoin inflation-free. If you think the "urgent stress" is not something you want in the future I suggest that you find some other altcoin.
@_date: 2016-12-13 21:15:00
And read my reply
@_date: 2016-12-08 23:21:31
aka not getting attacked aka invincible
@_date: 2016-11-01 22:05:14
That's not how it works. Let's say block size limit is 1MB. There are 2MB worth of transaction. If a miner mine 1MB there will still be left 1MB to be mined. But if the block size limit is 2MB after all 2MB has been mined there will be no more transaction. The next miner might be tempted to orphan that block to fight for the transaction fee. So it is really crucial that supply outweighs demand. Backlog is more than necessary, it is a necessity.
@_date: 2016-11-26 15:18:52


Uh, it can... You need to learn more about Lightning.
@_date: 2016-11-26 14:22:44


[Doesn't prevent anyone from running a simulation]( 


Even if right now we replace all the block rewards with transaction fee it would only cost $2.5 to create on-chain transaction. Too high a fee for you?


Again without quantitative analysis this is useless. I could say the opposite and it will just downgrade to he says she says


See his latest post.
@_date: 2016-11-26 13:20:05
Aaaand the data to support that is.... where? The truth is an overtly large hub will just paint a bullseye on their back for hacker. So there is an incentive to keep it small. That remains true whether or not block is full.
@_date: 2016-12-04 00:10:58
That doesn't matter. I can just mine that transaction without pre-broadcasting it. And the second transaction will only broadcasted sometime later after the block mine. I can still circumvent the limit.
@_date: 2016-12-19 15:06:06
*facepalm* So you're saying if miner decides to print more than 21m bitcoin you will just happily follow along? 
What if miner decide to redistribute 10% of the coin among themselves?
How is that any different from central bank?
@_date: 2016-11-25 14:38:01


My point is reading+doing will always be &gt; reading only (you can't rewrite from scratch without first reading the originals after all). 
Another example is the extra push on CHECKMULTISIGVERIFY. I don't see how that can happen if someone (apart from Satoshi) actually tried to re-write Bitcoin from scratch before releasing the software.
@_date: 2016-11-27 15:58:40
How is that a red herring? Witness is only needed on UTXO destruction, not creation. So by discounting the witness you are helping people destroying UTXO, and not creating a new one.
@_date: 2016-12-08 15:07:27
It wouldn't cost so much to break input into multiple output either.
@_date: 2017-01-25 09:55:02
Problem? Not really sure what you are talking about. The original argument was that Ethereum has worse scaling property than Bitcoin. 
Now it may not cause a problem (which is still arguable, some people is having trouble syncing just before you 'destroy' some of the state during last hard fork, this is something that is not gonna fly with most Bitcoiner) but in the long run the issue is going to accumulate. Back when I first started there used to be 7500 nodes, now down to around 6000 nodes. I can expect that number to continue to drop.
@_date: 2016-11-27 19:41:58
I don't think you understand the kind of attack I'm talking about. It is similar to the attack that causes Ethereum blockchain to grow 10GB overnight.  Not just an attack that causes inconvenience to some people.
@_date: 2016-12-05 15:44:54


Only this time 4 might the new 1. And 12 might be the new 2.
@_date: 2016-11-28 04:33:49
Where do you think it will shift when compact block happens?
@_date: 2016-12-15 21:50:28
Actually this is a common misconception. It is a little bit counter intuitive but here goes. When you create a bigger block it is true that it propagates slower but it doesn't matter if you find the next block. In other words, you risk orphaning your block but you also increase the risk for the rest of the network to get orphaned as well. When you achieve enough hashpower the net gain is positive.
If you want a quantitative analysis then read peter todd's analysis I linked above.
@_date: 2016-11-25 19:50:48
I don't think people understand. A lot of small blockers actually want a block size **decrease**. On top of that they prefer to prioritize fungibility improvement over throughput. (for the record I don't totally agree with that). 
The only things that make them agrees to SegWit is the amount of improvement we can have by having that activated. For example LN probably could lighten the load on the on-chain tx (also helps fungibility improvement). Script upgrade improvement would make it possible to work on Signature Aggregation that will help to incentivize people to use CoinJoin to save cost (fungibility improvement). In other words, SegWit is already the best solution we have. 
Traditionally Core never submits suboptimal solutions (which is one of the reason Hearn is frustrated with them). So unless someone pulls another rabbit-from-a-hat trick like Luke-jr did last year I don't see how it is possible.
To be honest, the fact that many miners think that further increase is possible is still quite worrying. That means they can't be trusted to judge over block size.
@_date: 2016-11-24 20:34:15


Which is why we have transaction malleability.


Doesn't stop people from creating libsecp256k1, though.


Again, why we have transaction malleability in the first place.


To reveal any hidden deficiencies?


Mostly because of work on libsecp256k1. You see my point? libsecp256k1 in this case is a "multiple implementation" of OpenSSL.
To tell you the truth even SegWit has contributions from multiple implementations (btcd, NBitcoin, and bcoin). I see that as a good thing.
@_date: 2016-11-19 21:41:12
Actually, big miners are being advantaged if their block doesn't reach other miner too soon.
@_date: 2016-11-26 14:43:08


See? Now you just reduces this argument to he says she says. You don't even attempt to argue against my point.




@_date: 2016-11-29 23:42:15
Developer consensus. Besides, I thought we are talking about setting a timeline? Now you want to move the goalpost?
@_date: 2016-11-29 12:45:04


Just provide Ethereum as case study to show what can go wrong if 1. Block size is too big 2. Bad thing during hard fork. If they can't comprehend that I'd doubt they're smart enough.
@_date: 2016-11-30 11:12:32


If it is not activated there will be no consensus on a hard fork. Bitcoin works just fine with 1MB limit. A compromise is a political process, not a technical one. We still can scale with Signature Aggregation/CoinJoin.
Even Lightning can be developed without SegWit.


Are you going to provide citation for that?
@_date: 2016-12-08 23:23:05
The only email is his own. Unless someone accuses him of doxxing himself I don't see how that happen.
@_date: 2016-11-24 21:05:45




You're talking about a single bad implementation that doesn't contribute anything. Generalization is not a good idea.


Just enough to features to be used inside Bitcoin codebase.


Make a specialized libraries whose testing and review process include recreating the very same features from scratch. I don't know about you but for me there edge cases that I can only see when I wrote features from scratch.
@_date: 2016-11-28 04:32:57
That's probably Ethereum's last word before their blockchain grows 10GB overnight. You are not thinking in terms of adversarial strategy. The truth is right now it is possible to use most of 2MB for UTXO (10-20bytes each) and creates tens of thousands UTXO. The only thing preventing them from doing so is a full block.
@_date: 2016-11-28 14:03:18
A pruned node that grows 10GB a month is not a "no effect". Most people will stop running a node if it even reaches 5% of total space.
@_date: 2016-11-20 00:39:06


Well, the creator of that article actually is the creator of btcsuite, who also happens to support SegWit
@_date: 2016-11-17 14:35:24
Can you take a look at this?
Is that the same comment that was removed? Because I saw it a few minutes ago. I think it is pretty shitty to remove comment asking a question. if you're reading this BIP vs actual client is where the mods draw the line (You can refer to BIP101 instead of Bitcoin X and BIP109 instead of Bitcoin C). I don't think they make any BIP for Bitcoin U though. (Disclaimer: I am on the fence regarding the this, and this should not be construed as agreement as to what they did)
@_date: 2016-11-28 23:07:38
When first time syncing a new node I/O is actually a bottleneck. That's why there's an effort to keep UTXO inside memory, not storage. 
An attack on UTXO **now** would be very damaging, output only constitutes 10 bytes of the transaction but is responsible for the sole storage costs. It is really disproportionate. The only thing preventing that from happening now is real economic activity with blocks being full.
@_date: 2016-11-14 10:43:20
Merchant is definitely not one. Seems like they're more interested in using Coinbase/Bitpay. And people who is happy with using PayPal/Visa is definitely not going to run a node unless it consumes significantly less resources than it is right now.
If I'm going to speculate (and your guess would be no better than mine) it would be exchanges, payment processors, miners (the powerhouses), and people who actually care about privacy/decentralization/security.
@_date: 2016-11-08 07:26:16


Good, Keynesian economist are the source of inflation. I'd like to see how programmers approach the issue given in the same problem.


It's precisely because you're not computer programmer that you don't understand why increasing blocksize limit is not that simple.


I've seen several things wrong with your model already.
1. Raising blocksize limit is not equal to shifting line from S1 to S2 but rather instead of hitting the vertical limit at F it is going to extend the straight line into let's say F'. You know what is equivalent of shifting line from S1 to S2? Core dev's work on libsepc256k1 and compact block.
2. The cost is not linear. Processing is quadratic at worst case scenario, and storage is an integration with respect to time (so the cost is time dependent). This is just cost to a single node. Cost to the network as a whole is probably quadratic because of the redundancy from network effect(Can anyone correct me?). So instead of hitting F' you will probably hit F'' which is actually a lot closer to F. 
3. As you increase the blocksize the increase in revenue for a small miner is not equal to increase in revenue for a big miner (because of selfish mining-like effect) so in the end the system will tend to centralize and we end up with oligopoly. This is what is called externality, something that is not modeled in Econ 101
If you want to properly approach the problem as an economist you will need to be a computer programmer first. You will also need to stop thinking about block size as a private good because it is actually a public good. I think a lot of people underestimate Core dev's expertise in economics (which a lot of it actually based on common sense). 
@_date: 2016-12-08 18:27:39


All those studies only take into account bandwidth-attack vector. There are other attack vectors as well.
@_date: 2016-11-28 04:51:23
The thing about storage is that it is there **forever**. There is no "undo" button unless you're willing to do "reset" on the UTXO (which sets a dangerous precedent). With bandwidth at least there is already mitigation with compact block.
@_date: 2016-12-02 07:44:30
Nice try, but
1. Just like Core devs the IPCC has neither the authority nor the jurisdiction over such matter. That's why global warming is still not slowing down. They can only make **recommendations**. It is the community who is self regulating.
2. Just like IPCC they make **recommendations** not to increase block size but to use block weight limits to replace it. Any half decent Engineering school would have taught you about Bhopal and Space Shuttle Challenger about not bowing to political pressure.
3. In fact, you are free to increase the limit yourself. Fortunately, this time around global warming on your planet won't affect my planet. 
Truth to be told, I already put most of big blocker on the same level as global warming denier and anti-vaxxers.
@_date: 2016-11-29 02:30:41


What do you think will happen when you increase blocksize? A 16 GB increase per month in an attack. That is jtoomim's word, not mine.


Huh, I thought we are talking about hard core users? What does VC has anything to with it? Hard core users will run node no matter what.


You mean like ASIC but just for full node? Hell, no. Go fund your own chain.


If blocks are not full then create a 1MB transaction with a single signature and a whole lots of UTXO. You can force full node to require 16GB/months. Jtoomim's word not mine.


Yes, they are pretty stupid in that. You know they got themselves forked in the testnet right? The only thing preventing a catastrophe is no one actually uses that to verify transaction. Even ViaBTC puts 1MB limit right now.


Any sane implementation will require 1MB limit.
@_date: 2016-11-30 10:30:44
Sorry but I am probably going to start using profanity since I'm tired of explaining this to every single person who comes around...


Why the hell do you cares so much about technicality? The maximum required bandwidth increases, the throughput increases. Are you going to fight over that one single variable?
Newsflash, a hard fork if there is ever going to be any would be in the form of block weight adjustment, not a block size increase.
Right now this is the block weight
    3*basedata + 1*witness&lt; 4000000
In the future it might look like something like this (not finalized)
    50*sigops + 4*basedata + 1*witnessdata &lt; 10M
If that number gives you 10x increase in throughput are you going to fight over "block size not being increased"?


Because most likely Lightning will be ready before there is a conclusion to what a safe block weight would be. Furthermore a hard fork most likely would be 2 years away even on most optimistic estimate (1 year coding and testing and another year for deployment).


Are you going to provide citation on that? Because 4MB is the current consensus. 
[Source 1](
[Source 2](
[Source 3](
And SegWit gives you 4mb maximum bandwidth. We might have more margin now with compact block but without a real network to test the extrapolation (e.g SegWit activation) we can't increase it any more


Ethereum increases their equivalent of block size during transition from Frontier to Homestead. Not only it is full just a few month ago, it is even worse, someone is using the free space to grow the state to 10GB overnight.
@_date: 2016-11-28 14:29:39
What's your computer spec and how long does it take for you to sync?
@_date: 2016-11-05 06:57:31


And people are busy arguing semantics. Why are you so particular about that variable? Effectively SegWit block can be 2MB or 4MB in size and that means increase in capacity. In fact it is better than just simply increasing MAX_BLOCK_BASE_SIZE because it is a **targeted** increase. Witness is the place where people least likely cause damage.
@_date: 2016-12-08 15:00:50


Like what? That's all that is necessary.


What percentage of transaction do you think Lightning would be in the future?


Try running with dbcache =100, see if you still can get 7 hours
@_date: 2016-12-10 18:25:24


Like Zander can't explain what nSequence is used for? Or he can't tell that Lightning used nLocktime? Or that he didn't realize that there is already work on improving the UTXO cache?
You yourself haven't answer to why SegWit is bad. You should be able to do that if you have "multiple sources"
@_date: 2016-11-26 14:53:03


Funny you say that after you simply reply these two arguments




simply with this




So don't cite his blog to support yours, especially after he retracts his argument
@_date: 2016-11-08 09:02:30


Your simplified model gives the wrong conclusion to the problem.  And big blocker will just use it as an ammo to support their cause. I think this kind of half-assed analysis is detrimental to the development. 
The truth is we nearly no longer have any margin in the bandwidth (the 4MB talked about in your citation is actually used up by SegWit). I am right now crossing my finger that compact block gives another breathing room from bandwidth point of view. Failing that we will have to resort to Signature Aggregation and Lightning.


Are you mistaking me for He was never known to be polite. I don't think I called names on you.


Please do so.  I'd rather read the 30 graphs rather than one that makes wrong assumption that leads to wrong conclusion (and could be abused by unsightly people).
But please remember that estimating cost is not that simple and given that you don't have CE background I have doubt on the validity of the solution. The reason Ethereum got attacked is because they make a mistake in the cost assumption (and Vitalik is a Thiel fellow, not really sure if that's just because the problem is too difficult or the threshold of being Thiel fellow is too low).


Please do a write up. We'll see if it holds up in peer review.


Increasing 2MB block size is a common sense economics though (and it is already used up by SegWit). I am hoping for something more than that.
@_date: 2017-01-25 21:21:14


Without paid uncles, the decentralization is much worse than Bitcoin with 
1. Higher orphan rate
2. No one paying orphaned block
The design decision doesn't come out of nowhere.


Where is the incentive for including uncle then? Since your subsequent block will have reduced payment.


You keep ignoring the fact that with faster block time centralization pressure exist and to alleviate this you need inflation:
For someone who worships Ethereum so much you seems to be underestimating the amount of analysis that goes into its design decision.


A 4x difference? With compact block you can get around 10x-100x difference in block propagation time.


I'd rather not argue about something that doesn't exist yet.


Except miner can collude to produce more Ether than necessary.


In the case of address reuse there will be a lockup.
I'm speaking empirically here but I synced Bitcoin blockchain from scratch much faster than Ethereum just a few months ago, even with Ethereum consistently having lighter load


Funny you said this prior to that:


You mean they don't value keeping blockchain small while designing the fee to be incentive compatible? Does not compute.
They even went so far as this:


What matters in the end is how large the database is, and how effective is the cache. 
Actually just an anecdote but I have actually produced dust in Ethereum by attempting to spend everything in my account but missed by a little amount. Unlike UTXO you can't guarantee that you have spent everything inside the account.


Yes, which is why it has worse scaling than Bitcoin.
@_date: 2016-12-08 14:11:43
1. [SegWit transaction is not affected by quadratic hashing](
2. SegWit transaction gives more incentive to destroy UTXO instead of creating one
3. SegWit transaction enables signature-less IBD.
@_date: 2016-12-02 19:25:45
Yes, but not everyone can upgrade. Some people are using old API, or can't compile C++11, or rely on some old bug in the old software to work with them and they can't upgrade. For these people we're giving them an option to upgrade whenever they have sorted their shit out. Hard fork doesn't give this option.
@_date: 2016-12-13 21:54:10


Witness can be pruned. You know that right?


Processing is limited by sigops, and that is independent of witness. You also know that right?


Apparently none of that affects your understanding.
@_date: 2016-12-12 11:23:51


What? NO! NO NO NO NO NO. You can soft fork to fix old format. This is an example for an early attempt (status: withdrawn).
You see the number of crap we have to deal with old format transaction? It is just not worth it. Might as well leave it alone. 
And please don't say FT. They don't fix old format transaction either. They only introduce new type transaction version where there is no malleability (basically inferior version of SegWit)
@_date: 2016-12-19 15:15:13


Because the agreement is there. It is implicit (think of it like a fine print). Right now we have a few unused OP_NOPs. It is quite transparent. By using Bitcoin right now you agree that the few unused OP_NOP can be used for a new feature in the future.
Similarly by using Bitcoin now you agree to 1MB limit. Attempt to "break" this agreement without consensus will result in a split chain.
@_date: 2016-11-17 15:36:49


Stream of lies? Now don't get me wrong I think John Blocke is an idiot but he actually sources a lot of things in that article. The fact is you banned one of the most reasonable guy among the big blocker. And you remove J. Ratcliffe, one of the most moderate big blocker from moderator position. Is that not a fact? Now explain to me how that will help reconciliation? 
I defend SegWit multiple times and yet sometimes my post still got caught multiple times in spam filter.
[This one]( and [this one]( still doesn't appear to this day.
@_date: 2017-08-10 01:57:40


What obvious flaw?


Witness is integral part of the transaction.


Not if you want to keep worst case UTXO growth constant. From the link you provided:


I mean fucking seriously if you want to keep the discount factor constant you need to understand the rationale. Seems so typical of clueless Segwit2x supporter.


No, they did not fork off simply because there is no demand for Bitcoin Cash.


If the result of the meeting is not subject to change by any means (example: timeline) by definition they are **actively** rejecting advise.


I followed Nassim Taleb's principle on insult
Basically you just keep on repeating bullshit from Segwit is an improvement. There is no part that is "technical debt". In fact I question everyone's understanding of "technical debt" when they said that Segwit is a technical debt.


Boo Hooo go and cry quietly in your corner snowflake.
@_date: 2016-12-20 10:48:42
When you upload whole blockchain to your peer you will need to use a large amount of upload speed. Just like how most likely you will max out your connection when you are seeding a torrent. At 15kb/s most likely he will use most of it to "seed" instead of helping to propagate block/transaction.
@_date: 2016-12-12 00:29:01


Read "Towards combined single block limit". There will be no blocksize increase in the future, only block weight adjustment. The block weight in SegWit is to prevent an attack on UTXO. Read jtoomim's comment on how bad it would be if someone actually do that here:


More like because Big Blocker is screaming "MORE CAPACITY" on top of their lung. It is not yet ready. Even doing (1) only is still a soft fork option.


GibbsSamplePlater is Greg Sanders.
Just to give a more concrete example. New address will not be using Base58.


Uh, you know that Satoshi doesn't make the code very modular right(maybe to decrease attack surface? I don't know)? Just take a look at main.cpp to see how bad it is.


We are still fixing a lot of things he left over. Core devs are working on libbitcoinconsensus when big blockers came over screaming.


1. You can't prove a negative. I don't see how you can make new tx version without inducing technical debt and neither does the Core dev. But that doesn't stop a genius (most likely not Zander though) to think of a way to do that. So Zander can produce working implementation to prove a positive. You see my point?
2. Zander's quote was just a few days ago


What? NO! NO NO NO NO NO. Read how OP_CHECKSIG works here:  It takes into account tx version. FT changes that (and it also changes the way tx id is calculated), so you can no longer spend old coin and expect the sighash to be the same. And you had the guts to accuse me to be on the wrong side of the conversation.


OK, then surely you can point out to the Github commit where he tackles the network object-fetch logic. I spent a lot of times sourcing information for you. It is only fair that you do the same.


Please build one and submit a pull request. Because Zander's last one apparently is not production ready.


It's his. And if it is not complete he shouldn't submit that.


Again I will be happy if you pointed out in Github where is the commit that tackles that.


Still pretty embarrassing. If he is a junior level contributor it might be acceptable but presenting that as an alternative to a well-developed protocol?
@_date: 2016-12-10 13:16:30


You can try listing them here. [I just tore apart Zander's argument the other day]( Let's see if you can do better.


Don't trust. Verify. If you can't, maybe you will need to start learning how to form your own opinion. That is the very foundation of Bitcoin (of course if you want to trust someone it is your privilege but now in return you can't tell which one is impartial view).
@_date: 2016-11-26 15:06:05


Our debate was about centralization. Not about Lightning in general. Unless you attempt to shift the goalpost...


You need to learn the difference between hot wallet (LN) and cold wallet (the way they store Bitcoin right now).


Uh, no. LN hub's fund can still be transferred anywhere, and they are just as irreversible.
@_date: 2016-12-02 07:48:43


Yes, there is an attack requires users to store 20 exabytes of data. Bitcoiner now found a method to store 20exabytes of data into a space of 1MB. No, that's not how it works. Engineering may seems like magic but there is an actual limit of what it can do.
Read Nassim Taleb's Antifragile. There's a limit to a system's antifragility. The limits ensures that we don't go over that bound.
@_date: 2016-12-08 20:28:59
In the same situation every Core node would ignore the big block and continue like nothing happens. No EB/AD bullshit.
@_date: 2016-11-30 11:29:54


I'm sorry I might have missed that. Can you cite the specific part?
@_date: 2016-11-27 16:14:32
A straight 2MB increase also means that an attacker gains an immediate 1MB to play with while SegWit-style increase means attacker still needs to compete with old-style utxo while people are converting to SegWit style tx.
@_date: 2016-12-13 21:06:29


Please list them here then.
@_date: 2016-11-30 11:23:07


Nodes that use default settings is the one we care about. Nodes like you know how to take proper precaution. If you are scared just run the default nodes.


WTF? 


Do you understand the meaning optional? You can if you want but you don't need to if you don't want to. SegWit doesn't prevent you from verifying the witness validity.
In fact verification-less node has not been implemented.
@_date: 2016-11-26 23:12:07
I know you are telling the truth. And I actually **do** appreciate a straightshooter. But I can see how people gets discouraged by these. 
You won't see Gavin and Vitalik engaging in these kind of comments (and personally it feels a little bit weird to me, feels a little bit too politician-like but apparently a lot of people like that).
Please don't get me wrong I am also a straightshooter but a lot of people gives me feedback that things I say can be done in a "nicer way" (I think point  is go easy on the expletives can't remember the rest LOL). Still learning how to do that though...
@_date: 2016-11-14 20:56:23


Unlikely. FT requires work on block explorer and wallet because they break compatibility.


Are you just repeating what chant everyday? If you don't prune the witness you will still have them inside the blockchain. And SegWit enables witness pruning, which can save storage cost.
@_date: 2016-11-28 14:52:42
Says the guy with no clue
@_date: 2016-11-14 20:52:57


That's what SegWit is. 4MB in worse case scenario.


I thought you agree for a scientific debate? Why do you cite yourself? Where do you get your figure? Do you think bandwidth is still the limiting factor there? Or did you just shift the bottleneck somewhere else?
@_date: 2016-11-26 12:54:01


You're thinking of hubs-and-spokes model. Lightning actually uses multi-hop payment model where every each hops only knows where the next hop (similar to onion routing) is and nothing else. The next hop might be the last. Or may not.
@_date: 2016-12-14 22:52:43
Now if only you could form a coherent scientific argument that doesn't ignore all previous findings...
@_date: 2016-12-10 13:11:45


Goes to show you don't understand what you're talking about. FT doesn't solve anything that SegWit doesn't. When you do two solutions for the same problem it is considered a redundant work. So it **is** either or. So far FT is a single person job and the shoddy quality shows.
[It is not yet ready for Lightning for example]( [And the author is still not very certain on how Lightning works](
@_date: 2016-11-20 00:36:30


Maybe BitGo should listen to [Satoshi when he said this](
@_date: 2016-12-14 21:45:24
OK you are assuming miner is a supplier that caters to people's demands, right? In a way they also control the production of Bitcoin. If they want to they can increase the amount of Bitcoin they produce at nearly no cost. What prevents them from doing so is also preventing them from increasing the block size limit.
@_date: 2016-11-29 13:43:35


It is really unfair to accuse them of doing nothing you know? Lightning, SegWit, block weighting discussion. Changing the limit before addressing the various DoS prevention required would require us to bring the limit back down just like what happen in Ethereum. Not to mention the embarrassment it would bring us.


They can still say that when the nearest competitor just shit their pants?
@_date: 2016-12-08 18:23:43


He is upset because now it is difficult to tell if it actually fixes the problem and not introduce another failure mode.


1. I don't see anyone complaining about P2SH
2. I don't see any sudden change to SegWit specification in last one month.
Worst part is someone actually dares to make argument that BU is 'well tested'
@_date: 2016-11-17 08:22:52
Normally in AMA it is considered respectful to indicate when you will be away and when you are going to return. 
He still refuses to participate outside the echo chamber though. Example: 
@_date: 2016-11-26 14:35:57
Disclaimer: I'm not staying in irc channel 24/7 and nor do I required to interact with Core Devs on regular basis so this is just my impression within my limited interaction with them.
With that being said I think Core Devs hostility is overstated. The truth is the learning curve towards creating a secure program is pretty steep. They are more than willing to teach you but if you are too stubborn (or stupid) to realize how the idea is bad even they will get frustrated. 
Personally I've seen multiple music teachers that mentally attacks you worse than the core devs (anyone seen Whiplash? Knock it down a level or two and you have non-fiction). Unfortunately that is also the reason that I never saw it through to see if they actually teach Evil 101 in their Pedagogy class.
Now I'm not saying they are perfect (I've been a victim as well in the past, see previous paragraph above). Peter Todd's latest tweet storm egging and shitting on Ethereum is definitely not a display of a model behavior (actually I'm guilty as charged as well LOL). My impression is also that Greg Maxwell is pretty butthurt that BU manages to get xthin out before Compact Block. But if I have to choose between nice but less competent people (Gavin and Vitalik) and a competent but less nice person to develop Bitcoin Core I would choose the second one anytime. Sure it would be nice to have someone who is both accommodating and competent but such a person might as well be a unicorn.
@_date: 2016-12-08 17:46:40
The best part of SegWit is that this kind of transactions will be even cheaper because there is a discount on the Witness.
@_date: 2016-11-01 22:44:32


That would depend on who is your target user base. Cheapskate user will just drag the fee down. And Bitcoin has been undercharging its user seeing that the fee is still increasing. When soft block limit is increased the total transaction fee actually went down:
Besides, user growth is not infinite, it will reach an end at some point.


What short term gain you're talking about? Orphaning other miner's block? If your business is running under the water you will do anything to keep it alive. Short term gain now might be long term gain later.
@_date: 2016-11-24 21:57:31
NBitcoin for one, libbitcoin another (pretty decent one although I don't think they contribute much back)
@_date: 2016-11-01 17:36:48




Using node count is not an option because of Sybil. Actually CoinVote and Miner vote was suggested as indicator of hardfork readiness during Satoshi Roundtable. It was big blocker who was against it.
@_date: 2016-12-11 17:49:50


I think (1) is not yet implemented and I think Greg Sanders mentioned somewhere we won't see it anytime soon. Why? Because that requires a much larger change to the codebase, some of them are consensus critical. 
Sure, if you want to say "Hey, SegWit is better than P2SH so let's replace it!" then yeah, you can have less technical debt. But you can't because people will still need to make P2SH transaction. And you will also need to redo all the infrastructure necessary. You can probably do that in an altcoin. I would probably buy one if you manage to pull it off.
OTOH P2SH, with all its weakness is actually designed for this kind of script upgrade. So it is not a bad choice.


That also happens in hard fork. The difference is in soft fork "can't verify" node is protected by hashpower. So it is the choice of lesser between two evil.


Generally, yes (like extranonce setup). But in terms of SegWit, no (at least not much). Not much you can do unless you are willing to forego all the old style transaction.


I mean "future implementation". I got sloppy because you said you're ending the conversation.


If you "remove the ability to make old transaction" then you destroy old coin. If you don't support that then you shouldn't be making that argument.


[You **do** realize that FT still have a lot of TODOs right?]( Core devs consisting 10-20 devs, some of them has implemented SegWit as HF in Elements Alpha has already said that in the case Bitcoin SW as SF is the best we can do and Zander who doesn't even understand how Lightning works,and what nSequence does (and whose code is filled with buffer overflow) says otherwise without full working implementation? I'd trust the first one anytime until Zander produces working implementation.
In Bluematt's word:


@_date: 2016-12-04 22:41:33
Show me how to fix malleability for old style transaction.
@_date: 2016-12-15 12:54:29
Empty block means that they mine only based on the header, meaning they didn't validate the previous block and simply assume that it is valid. 
Because they never validate the block they can't tell which transaction already included in the previous block and thus can't include any transaction in the next block they mined fearing that it is already included in the prior block. 
Because they can't include transaction they cant reap the fee. If the fee made up a substantial portion of the mining revenue they will lose quite a lot.
@_date: 2016-12-09 11:27:50


Nuh,uh. It is up to the miners to **create** block, it is up to the node (with economical power) to determine whether it is **valid**, that includes the blocksize limit. Just like a node can say whether a &gt;21M BTC is invalid a node also have a say whether a &gt;1M block is valid.


But the network **will**, as evidenced by the orphan rate. It is not **sufficient** that your node keep up with the throughput, it **must** also contribute to the network by delivering the payload (e.g block) from miner to miner at a rate much faster than the one required to deliver block in 10 minutes. That means if the block time is 10 minutes,  you will need to deliver the block from miner to miner in 10s or less **through multiple hops** (because you are not the only one in the middle) so that miner can remain competitive with each other (otherwise the miner that first find a block has an advantage over another miner)
In addition to that new people who wants to bootstrap a new node will also need to catch up in a reasonable time. If it took you a year to catch up a year's worth of data you will never catch up with the rest of the network because as you are catching up the network already adds the same amount of data.
These means requirement for a full node is actually much more strict than it seems. A node actually must be 100x-1000x faster than the network so that it remains decentralized


I know I don't mind paying $30 to get a substantial amount of my salary for inflation-free assets, so does people in India who is paying $300/BTC more than most people. Most people in first world country with stable currency may not understand this but Bitcoin already has a killer apps.
@_date: 2016-11-28 07:55:34
And the damage is much more minimized. Attack on UTXO is forever.
@_date: 2016-11-28 14:04:10
Can be said about any coin, really. And that includes Bitcoin as well.
@_date: 2016-11-29 10:15:20




@_date: 2016-11-28 14:02:49
Do you run a full node? Have you ever synced from the beginning? Especially after 0.10?
@_date: 2016-11-30 10:57:59


Because SegWit hasn't been tested in the real network? It hasn't even been activated. We need to know how much improvement compact block gives with regards to bandwidth. We also haven't figured out a good way to prevent attack on UTXO.
@_date: 2016-12-04 03:53:20
Still 2x the vote for Unlimited..
@_date: 2016-12-13 21:43:09


Infinitely more if you count by storage (UTXO) or processing (input). Counting by bandwidth is another matter. Do I need to explain how Bitcoin works? Please educate yourself on the matter.


To a full node. SPV node doesn't contribute anything. Miner, ideally should run a full node.


Again, if you can't tell what is witness, UTXO, and input I don't think you should be making an opinion.
@_date: 2016-11-01 17:33:02
No, but research says block size limit is crucial to ensure orderly transition to transaction fee only. Without blocksize limit miner has incentive to orphan each other's block
@_date: 2016-12-08 17:32:15


So does SegWit. My point is whatever technical debt (if there's any, unlikely since you don't answer the 2nd question) we can't remove it now. So no advantage for FlexTrans over SegWit.


Why can't you link it? I am not going to scour the other sub just to find that one post. You are already assigned a BIP for crying out loud, might as well use it.


In terms of what? bandwidth, disk space, memory? I still can't verify without a link though.
How would you feel if I suggest to do a hard fork to 1.05MB?
@_date: 2016-12-02 07:52:04
See no  again...
@_date: 2016-12-08 13:20:48
[Reposting my reply to your comment here](
@_date: 2016-12-04 22:44:10


Yes, and you think changing blocksize from 1MB to 2MB is not **rewriting large part of it**? Because the amount of change is not equal to the amount of lines of code changed.


What? How is that forced? Just do a hardfork to 2MB, and make all transaction with # of inputs=0 invalid (or change it to support other feature). 


False equivalency. See above.


Again, you are free to choose. You can ask Bitmain or ViaBTC **right at this moment** to produce 2MB block. Just make a checkpoint. 
@_date: 2016-12-05 15:51:05
The only way you can get 4 even for 50/50 case is if you don't simulate block propagation time, which even in the case of entire network being in consensus is non-zero (~15s?). In the case of emergence consensus I would expect it to be worse since everyone is doing Sybil on each other, so I don't think he actually simulates block propagation. Someone welcome to prove me wrong though. Edit: Actually even without simulating block propagation that doesn't actually makes sense. With 50/50 case there is zero probability that the minority chain exceed the big block at one point in time?
Also note that network splits into two is actually pretty optimistic case. [There are miners who puts AD as 6 or even 25 with EB ranging from 2 to 32MB](
@_date: 2016-12-08 14:13:16


[It's not](


[UTXO grows faster than memory, even at 1MB](
@_date: 2016-12-15 14:23:36
Hmmmm. You realized that. You must be quite a smart fellow as well.
@_date: 2016-12-11 00:44:05


Not really sure which part of my statement you're responding to...


The only part where SegWit did this is on where to put the witness root. If we do a hardfork it can be easily relocated.


By forcing everyone to upgrade? Nope. What if Satoshi never moves his coin? Are you going to destroy his coin? Destroy fungibility?


And I have yet read an argument on why it's not appropriate to use them in SegWit. Even you only speaks in general term without being specific






The only part where it is relevant is where to put the witness root, that's it. And that's such a minor part of SegWit.
@_date: 2016-12-08 20:20:33
Greg Maxwell was unbanned. The only reason he was banned in the first place was because the other sub is making a big deal out of it. If you didn't notice the original post I'm replying to doesn't mind linking to Github.
@_date: 2016-12-08 17:28:22
He is still guilty for not arguing against the removal of 2MB blocks though. In fact Classic now implements Unlimited's change.
@_date: 2016-11-28 07:55:44


Which is the only thing that matters for block propagation. An attack on UTXO cannot be undone.
Besides, you know what dbcache does? You know why changing that params can affect your sync rate by a lot?
@_date: 2016-12-15 22:56:10


Actually back in 2013 orphan rates also skyrocket (the problem is now partially solved by relay network which is not an ideal solution since it is essentially a centralized solution) and yet I don't see anyone pushing for a smaller block. The approach that miner prefers is to put the entire hashrate into one single entity that is Ghash.io
@_date: 2016-11-28 11:40:07


Big difference. With 51% attack economic power would demand a hard fork because of network instability. A collusion to make centralization worse would be more subtle, some people probably support that seeing the amount of push for bigger blocks.


Again big difference. You are assuming that there is no competition between miners. Competition is what drives innovation. With this kind of scheme it is possible for 51% miner to bypass Bitcoin's equivalent of antitrust law by forcing the rest of the miner to fall in line.
@_date: 2016-11-28 14:02:32
I think he was just responding to a more naive method of using block average to determine valid block size. A vote to increase block size is a more transparent way to do that.
@_date: 2016-11-25 05:37:43
There's btcd. [Oh, wait they support SegWit](
There's also NBitcoin. [Damn, they support SegWit as well](
Oh, I know, I know what about bcoin? [What, they support SegWit as well?]( 
Do you only consider consensus-breaking change client as an alternative implementation?
@_date: 2016-12-22 22:35:05
Read his statement again.


There will be no bailout. It's sink or swim. (which is a feature by the way, and not a bug, it's about taking responsibility for your own action)
@_date: 2016-12-13 21:14:39
I heard this from Mark Friedenbach himself. He puts it somewhere in the past. I need to dig it up but I don't think I have time for that.


UTXO and input costs more than witness. A LOT MORE. So the only way to make the damage minimum is to maximize witness (by virtue of greedy algorithm).
Of course you can tune the ratio better when you have sigops+utxo counting in the future but this is a starting point. I thought people want a band-aid fix? 
@_date: 2016-12-02 11:38:42


You mean a 6-conf reversal? Now a single miner can force a 6-conf tx seemingly safe while it is actually not.
@_date: 2016-12-08 16:10:59


Except we can't make an upgrade to the script right now. With script upgrade we can even make Ethereum style (God forbid) Script.
 BTW what 3 stuffs are you talking about? nSequence is only used to indicate which transactions is 'newer' and nothing else.


Now let's say 99% transactions are Lightning. How much savings do you have over SegWit?


Put the damn thing on Github if you are serious about it.




Besides, it doesn't matter what database you use if it can't be cached.
@_date: 2016-11-20 00:35:31
Read my statement again. I've never said that centralized mining is good. What I've said is bigger block will make mining more centralized. 
@_date: 2016-11-29 13:36:38


Yeah, because there's already a consensus. You didn't remember the 6 months prior to that where they are accused of stalling? What a selective memory you have...
@_date: 2016-12-16 16:43:16


[Ghash.io did this](
As a matter of fact I highly suspect they did selfish mining as well.
Even if they didn't doesn't mean they won't in the future. Artforz and Eleuthria never bother to cheat yet they didn't manage to stay in the game. Perhaps in the future miner would learn from their mistake and start to cheat. Even Jihan Wu says that he won't do validation because the protocol doesn't requires him to. Do you expect me to believe that he won't do double spend in the future because "the protocol allows him to do that"?


If I wanted to be "thankful" to anyone for the "privilege" I have been given to participate in financial system I would be using centralized system. Hell you could even give them rights to print more Bitcoin and call it "central bank".
Miner's sole job is to arrange transaction in chronological order and even then it is because there is no other choice. Everything else (21M BTC limit, cryptographic proof of ownership) can be done in trustless manner. You are crazy if you expect me to concede more power to them.
@_date: 2016-12-04 00:16:27


And this calculation would be as complicated as whether or not accepting a 0-conf tx. And all of the services that offers this kind of solution charges people fee for it. You actually expect someone to work this for free. Besides, All of this complication is for what? Politically palatable solution? There are better solutions out there. Hell, even Ethereum's vote-for-block size would work better than BU's let's orphan each other.
The worst part is this kind of solution is not yet ready and people still argue that BU is "totally tested"


That doesn't matter. I can just mine a single transaction without pre-broadcasting it. And the second conflicting transaction will only broadcasted sometime later after the block mined. I can still circumvent the limit.
@_date: 2016-12-14 21:48:01
A block that you can't verify on your machine. Ethereum is good example of that. They got attacked by someone who is producing a transaction people can't verify on a normal machine. This is solved by re-adjusting (e.g decreasing) their equivalent of block size limit.
@_date: 2016-12-08 14:59:42


Besides, you want to spend $500 a year just to run a node? Ask an average Joe
@_date: 2016-11-01 17:51:08
Why should I? Big blocker haven't agreed to use that as hard fork readiness.
@_date: 2016-12-14 03:20:19


Again, submit a patch if you think you have better fee model. This will produce significant complication since older tx is affected and SegWit tx is not.


We're talking about a full node, which by definition can be pruned.


You still can sync the old way by using torrent (which, also can be sharded) and verifying you're on the longest chain. You can even download from blockchain.info or coinbase.com. Pruning also gives you option how many GB data you want to reserve so you can store partial data (effectively sharding the past data).
Archival node is by no means necessary for the survival of the ecosystem.
On top of that, UTXO storage is in **memory**, eg. it is cached. So its storage cost is actually much higher than a normal storage How much more expensive is memory over SSD/GB?
 
I also noticed that you no longer mention processing so you agree that processing is limited by sigops?
Anyway, here's my point. Whatever the ratio is, it is more than 1:3, which is the SegWit discount (by a lot I might add). Doesn't matter if it is 1:10000 or 1:100. We are still being limited by the bandwidth.
Are you going to complain that you don't have 1/100th or 1/1000th extra for UTXO or input?
@_date: 2016-12-15 12:08:27
Actually the fact that they mine so many empty block means that they are not ready for the time when fee made up a substantial portion of mining revenue. Combined that with the fact that Antpool is the held most of the hashpower means that [they will reap the most benefit from bigger block](
Interestingly [according to this article]( Bitfury, CKPool, and BitClub Network doesn't mine empty block at all, meaning they would be more prepared when fee made up significant portion of mining revenue. All 3 of those pool are SegWit supporter.
This is why anyone that thinks miner could be trusted to oversee block size is really blind. Miner doesn't care about long term viability of the network. They only care about their own profit.
@_date: 2016-12-04 21:37:14


Which enables the following:
1. Fix malleability
2. Compact fraud proofs
3. Enable optional verification-less sync
4. Increase blocksize without worrying about an attack on UTXO
Now name one downside.


Everyone with a brain damage that is.
You would be insane if you think that a plain 2MB increase (I am not sure if this is the case for this hard fork, I wish there is a documentation on which feature they will support) will be any less controversial. A lot of people wanted to have block weight and dynamic limit for a starter.
@_date: 2016-11-28 14:47:11
So you don't know the answer and just blindly want blocksize increase? Got it.
@_date: 2016-11-18 13:55:36
And where is your bug report again?
@_date: 2016-11-28 23:03:01
Firstly, syncing node is UTXO-caching limited. So you need to consider UTXO growth vs memory. Secondly, blocksize should be limited by current technology, not future one.
@_date: 2016-12-02 19:31:24


**Precisely**. It is by **design**. This is why people are bad at adversarial thinking. I can design that tx such that it will be reversed after 6-conf with 100% guarantee. Remember, there will be no block rewards in the future. So if let's say block reward is less than 1M dollars I can make 3MB Block with 3MB transaction that will be orphaned after 6-conf with 1 output containing 1M dollars. My recipient is unaware, they accept that tx after 6 conf and finalize whatever deal they made. Surprize! that tx is no longer valid.


There is no way you can guess what kind of transactions is "big" because it will keep on changing. At some point someone will be bitten by this.


Uh, no. They never implemented that properly. That is the reason Classic-Unlimited fork in the testnet
@_date: 2016-12-02 07:40:35
It **is** but that guy insists on verifying the signature himself instead of trusting the miner.
@_date: 2016-11-29 10:09:06
And UTXO is related to sync speed.
@_date: 2016-12-05 15:44:17
Uh, you actually think that it fixes it for old style transaction?? I've got news for you...
@_date: 2016-11-24 19:43:37


Good thing about multiple implementations is that this kind of thing can be found out early. Just to give an example, if Bitcoin is developed using multiple implementations tx malleability probably would have been fixed earlier..
@_date: 2016-11-29 23:59:36


That's because there was no incentive to attack Bitcoin. [Quadratic hashing was only known in 2013](
@_date: 2016-11-20 00:10:32


It is still acceptable as long as the amount of income they get is still proportional to hashpower they own. [Larger block makes it the reward more disproportionate](


[Maybe BitGo shouldn't run 0.13.1 if they don't think it's the best way forward](
@_date: 2016-12-15 13:59:53
What if including fee is already optimal strategy right now only they don't know how to do that.
@_date: 2016-12-14 03:06:27


We still have to take into account of quadratic hashing remember? 


Go and submit a patch.


It will effectively result in the same ratio. Go ahead and try it.


Do you understand what pruning means?


You know you can use OP_DUP to duplicate witness right? You need to consider adversary scenario.
How about this:


@_date: 2016-12-08 13:06:43
I can still change the tx id for old style transaction....
@_date: 2016-12-09 11:14:10
Except I can't find the description that I was looking for.
@_date: 2016-11-02 22:30:07
A little bit difficult if you don't quote which part I'm talking about. If transaction fee goes up that means there is demand, and miner has been undercharging for a public goods. When there is no more growth fee will start to flatten (and probably go down, that's when we start to worry)
@_date: 2016-12-17 05:24:19


I'm thinking about using CB to simulate selfish-mining-like behaviour but yeah, I can see where you're coming from. You don't need to exploit CB when a simple block withholding works. Selfish mining is the real problem. I'm not sure if there is any solution to that.
@_date: 2016-11-28 23:00:49


A **month**. In two months it will be 32GB


Read the above again.


And you want to limit nodes to hard core user?


I think right now the target is a 4 years old computer.


Ethereum's famous last words.
@_date: 2016-11-01 08:34:07


The reason Core has taken a strong stance against hard fork is because there is no urgency. Changing the 21M BTC limit, on the other hand is against the [fundamental principle]( of Bitcoin. As I've said before [it is not a false dichotomy]( Giving the control over blocksize limit is nearly equivalent to giving the control over the inflation.






In 2013 accidental fork it only took [6 hours]( to reach consensus so depending on urgency people can come together pretty quickly. I believe gathering more than 75% will take more than 6 hours.


That's what people are planning to do with ETC too. At that point ETC worth 10% of ETH yet nothing happens.


It is unpopular because there is no base for it. Miner is the most easily replaceable component of the ecosystem. Which one would people choose? The one committed to retaining 21M BTC limit or the one that don't? The one who committed to give right to everyone to run their own full node or the one that signs away the privilege to the miner? The one who gives support to more secure 0-conf(Lightning) or the one that don't (remember [Unlimited doesn't want SegWit](


You mean like how Core agrees to lower the 95% activation threshold? 
You **don't understand**. There's no such a thing as Bitcoin Core. Bitcoin Core is not a single unified body. That's why it took nearly half a year to reach consensus on SegWit. And SegWit itself has gone beyond Core, reaching various [wallets]( and [business]( 
Overall I agree with the sentiment of other posters in this thread. All of this is useless posturing. Either do it or don't. Talk only is useless. We'll see how good your hypothesis is when all the dust is settled.
@_date: 2016-12-16 04:14:16


Actually fee already made up around 5% of mining revenue right now. For some miner that is equal to their profit margin.


Antpool-Bitfury case shows otherwise. Their preference for big vs small block largely depends on how dependent they are to SPV mining.
@_date: 2016-12-15 13:40:24
You mean they willingly forfeit the fee? Well, let's see how well that strategy goes when block rewards decrease
@_date: 2016-12-08 14:24:08
Except he doesn't specify which part he considers as a technical debt that hasn't been debunked.
@_date: 2016-11-29 10:22:31
If you want to confirm that UTXO is bottleneck run two Bitcoin Core node, one with dbcache=100 and the other with dbcache=8192 (if you have &gt;8GB RAM) then sync from the start. There will be big difference in time required (at least if your computer doesn't have a hardware problem/slow network).
@_date: 2016-12-19 15:10:15


The chain with highest value (in terms of "market cap", developer support) is the BITCOIN. Miner follow the value, not the other way around. During ETC-ETH split miner's voice is split 65-35 but economy split (and developer support) is 90-10, at the end of the day the "market cap" split is 90-10. The 35 that doesn't support ETH just being drag around.
@_date: 2016-12-13 22:05:58


How does SegWit matter here? Witness is always cheaper in terms of storage. It doesn't matter SegWit or no SegWit. The problem with older transaction is we can't count the witness separately (yet, not sure if there is any plan for that)


If Witness is 1000x cheaper than other data then you might as well treat it as infinite. There is not much difference. You should always consider worst case scenario.


You say processing, so you agree storage cost 0?
Which one do you think will hit the limit first sigops or witness?


Says the guy who says this


@_date: 2015-08-19 07:31:32


Well, if you want this to happen in Bitcoin just remove the automatic brake and the driver (miner) will sort itself out. The problem is in Bitcoin you can't trust the driver so we need all sorts of sensor to trigger the brake.
@_date: 2015-08-04 21:13:02
I have spent some time here and over at and if you take a look at post history I've always tried to keep a balanced view.
The problem that I have with this work is that it spends too much time attacking Vitalik's [2] (which is arguably the weakest) and not spending enough time on [1],[3], and [4]. In particular [4] (there might be some problem on [1] and [3] as well but it is quite late here and I can't really think clearly). I believe misunderstands that the capital+reward is taken not only on an attack but also for misbehaviour. 
As an example during the last BIP66 SNAFU F2POOL didn't validate the previous block's header, the result is they(F2POOL + whoever mining there) are losing quite a fair bit on the reward but in the end they still survive because they still have the ASIC. This is not possible in the case of Caspermint because the protocol will allow their entire capital (e.g the deposit) to be taken away. As an effect they will immediately go bankrupt. So the punishment for behaving badly is much severe than PoW system.
@_date: 2015-08-25 20:06:30
Yup! That's why I think that if we are going to vote over blocksize limit it is better to use Proof of Stake (vote weighted by UTXO instead of hashpower).
One interesting thing of Bitcoin that's different than the traditional financial system is that economic majority no longer has total control over transaction inclusion/exclusion, because there is another power, namely the miner. If you can't send your Bitcoin through Coinbase you can now do it through the miner.
On the other hand currently miner has the most power over blocksize limit (e.g at least they can set a soft limit by now). I don't think it's a good idea to give them more power, because power tends to corrupt, so we can give the power to economic majority instead.
This way there is a balance, with miner/economic majority sharing the control over both transaction inclusion/exclusion and blocksize limit.
Edit: Ugh, downvote with no counterargument? Just to clarify I suggest that we still using PoW for creating block but PoS for blocksize limit voting so that like said


Reference 
@_date: 2015-08-24 00:07:54
No. Proof-of-Work requires you to find nonce such that sha256(block header of current block) &lt; certain value. If some miner produces a block &gt; 1MB its block header (which depends on a lot of things, including transaction included inside, and previous block header) would be different than block produced by other miner which is &lt; 1MB. Since miner in XT accept the first block, core's miner will reject it so they will be working on a different set of problem.


That's because namecoin note that originally was not designed to be merge-mined. The merge mining was only supported after a hardfork. 
Edit: ~~
Sorry, wrong link
 (hard fork at block 19200)
Likewise, Dogecoin (which was forked from Bitcoin) doesn't originally support merge-mining. I don't think there will be any interest in merge-mining XT since its purpose is to force miner to make a choice
@_date: 2015-08-17 07:45:05


Uh, no. It's not a claim when I supported it with links. Block size limit is a known bottleneck for a very long time. If the discussion started long time ago we would not be facing this situation.


Well the code is the law. In a sense they are the 'legislative' part of Bitcoin since they are the one writing it.


The whole point of Bitcoin is everyone should be judged on the merit of their argument, and not their qualification.


Well, it's not exactly a throwaway when it has accumulated ~500 karma. It's just that I prefer to be on a separate account when commenting on cryptos.
@_date: 2015-08-26 15:39:56


Errr... Did you read the reference? How does that allow one to game the system? PoS simply means that if you have 1 BTC implies that you have vote weighted by 1/21 millionth.
Like it or not PoS is better than PoW in term of inclusiveness. Everyone who owns a Bitcoin can vote.
@_date: 2015-08-17 08:01:41


Fact is fact. I speak it like it is. The issue is long withstanding and they choose to ignore it for so long.


There are already a lot of solutions being proposed, each with their own merit. The only part left is coming to an agreement, which they fail spectacularly. 
Actually, the only link karma that I have comes from one of the possible solution.
@_date: 2015-08-23 22:27:34


No, they can't, unless the chain has been designed specifically to accommodate merge-mining. This will require a hardfork in itself. Take a look at dogecoin-litecoin merge as an example (hardfork at block 371337)
Edit: Just in case you are wondering why currently XT/Core mining is possible, it's because XT is setup to behave exactly like Core until a specific set of condition is achieved (75% vote + Jan? 2016). Once these conditions is achieved you can no longer mine on both chain.
@_date: 2015-08-05 03:23:04
Well, there are a lot of things still being finalized for Casper so until that happens I can't really comment about this.
@_date: 2015-08-19 06:04:31


That's a bad analogy. 1MB is not a brake, because brake is adjustable. If 1MB is a brake, it is an automatic brake that kicks in once we hit a certain speed (e.g 60km/h, sorry Americans). We can't win a race like this. Ethereum did pretty rigorous testing a few months back in Vitalik did mention that probably current Bitcoin can go up to ~10MB. 
From what I see the Ethereum Olympic seems to be a pretty good study of what the Network is capable of.
Maybe it is true that Gavin's proposal is equivalent to let's put the brake at 700km/h and let's hope that everyone plays nice, which is probably reckless. This is why the various flexcaps proposal is more attractive.
Here's the catch though. Can we actually expect the core devs to come up with something and not let the discussion die after a series of trolling like what happen in the past (actually even now I can see a lot of trolling in both in the mailing list and all over reddit)? I mean it is a little bit unfair that the Core Devs is expecting a better fee management from Wallet Developer while leaving the current 'brake' system intact.
@_date: 2015-08-19 07:14:38


I believe he has made an adjustment to what applies in Bitcoin since in that comment he has made a direct comparison to a paper that study Bitcoin and the result matches up pretty well.
@_date: 2015-08-26 14:20:14
If no vote was made, it is assumed to be status-quo (e.g. no change). 
@_date: 2015-08-23 19:38:24


Ugh, so many things wrong with this that I can't even...
First of all you can have a say, by running a full node (do you?). You can vote whether to accept 8MB blocks or not simply by choosing to accept or ignore the transaction through your node. You can even delegate this ability. Coinbase support 8MB chain and you want to support 8MB Blocks? Then buy your Bitcoin through them.


Miner is only responsible for transaction inclusion/exclusion. If you are talking about the 75% criteria then you can blame Gavin on that (and seriously you can even modify the Bitcoin Core to remove that criteria, or support other devs that has a better plan, for example Peter Todd has some idea about PoS voting on blocksize), but the truth is even with 75% hash rate it's meaningless unless you can get exchanges to support the change.
@_date: 2015-08-26 15:11:44
Well, I don't imagine people would want to change block size THAT frequently. Once every 3-4 years would be reasonable. I think Peter Todd has a proposal where the voting key is different from UTXO key but I haven't read through it.
@_date: 2015-08-22 22:15:01


Agreed, a simply 8MB would have been more palatable. 
I think better alternatives are available, like Meni/Greg's flexcap that takes into account miner's vote + economic activity (e.g whether the increase required is justified by economic activity, and not simply malicious miner attempting to gain advantage) or Peter Todd's PoS voting, allowing anyone that owns Bitcoin to vote on blocksize but if consensus is required not even these changes will be incorporated into the Core (e.g. sipa's plan has been said to be too conservative, and Peter Todd's PoS has been said to be too complex). If these were to happen we will be in a stalemate (again!), in the meanwhile 1MB is creeping in.
@_date: 2015-08-20 22:32:20
Not really sure about but for me a good leader should unites and not divides. I can agree with his prior tweet, something along the line of both sides need to cool off (exaggerating their own point of view?) but this time around he really puts pro XT people over the fence. 
He doesn't seems to understand that many pro XT people is frustrated by the blocksize discussion's lack of progress over the year and wanted 1MB replaced, by high-way or by low-way. Personally I'd rather trust the miner rather than the unadaptable (arguably) low limit. 
I understand that there are a lot of better alternatives, but it is meaningless if it is not being incorporated into the Bitcoin Core. I mean take a look at Greg-Mike-Peter's exchange below:
 
It is almost to the tone of 'My Father is better than Your Father'. Like Nick's current tweet, it doesn't contribute anything to the blocksize limit. This is not the first time this kind of exchange happen and not in any way limited to these 3 people(this is just an example). I can understand a debate being political (although it is REALLY EXHAUSTING) but once it becomes personal it is hard to get out(short of people being a saint). You must have been one hell of an optimist to think these people will actually comes into consensus.
@_date: 2015-08-17 06:35:11
Here's the way I see it. 
Whenever Buttcoiner mocks Bitcoin for supporting only 7tps we always defend that the limit is artificial. The 2012 version of Bitcoin wiki even says so:
Guess who's laughing now.
Jeff Garzik has been pondering about the issue since back in 2013 
and everyone in consensus agree that it was not the time. So you guys procrastinated until Gavin/Mike threat you by releasing XT (or to be more exact 20MB discussion).
Seriously right now I see Core Devs as no better than US House of Rep during Debt Ceiling debate.
So probably you guys are 'not doing nothing' but seriously you are pretty close to come to 'doing nothing'.
@_date: 2015-08-05 03:11:30


Well, there is a cost to keeping miner honest. [4] means that in PoS it is cheaper to do this.


I am not sure. It just feels pretty intuitive to me (definitely not worth spending lots of paragraph and figures on it). This is my biggest gripe with PoS currently.
@_date: 2015-08-23 20:45:21
*facepalm* 
Nothing at Stake, also commonly called short-range-attack means that there is nothing preventing a stakeholder from voting on both chains if there's a fork, just to ensure they will get their reward. This means that the consensus is unstable. There is nothing 'old, outdated, and proved incorrect' about this. That's why normally there is 'punishment clause' in PoS system (I mean why would you need a counter-strategy when it 'proven incorrect'?). Of course this strategy is also not 100% effective since the stakeholder can just vote out the block that contains the 'punishment'. 
There is also long range attack, where attacker steals stakeholder's private key from the past and start rewriting the chain (since signing takes a little time he can catch up really fast to the current block height). This can be avoided by checkpointing, but this will lead into things settled offchain (e.g which checkpoints is the correct one?)
PoS is good for many things but unfortunately chain organization is not one of them, at least not if you want things to be settled within the protocol, and not outside.
@_date: 2015-08-22 17:23:12


Pray, tell me then. Why does the chinese miner choose 8MB over 20MB? I agree that there is a risk but the truth is the game theory is much more complex than that. There are people with high bandwidth and there are people with high hashrate, and these two groups may not have intersection. 


True. But are we going to keep 1MB forever? Because if we start hitting continuous 1MB blocks the network becomes unreliable (either you are dropping transaction or keep Bitcoin running until it ran out of memory, take your pick). And Bitcoin 'the store of value' is useless without Bitcoin 'the payment network', because that's all Bitcoin is useful for really. 1MB needs to go, and if we continue to do what we did from 2011 (yup, the debate has been going on that long), we will end up going nowhere.


AFAIK there is no one ever said that XT will achieve 'morning coffee' level of transaction. It is meant to buy time until better solution happen. I will repeat my point that I said several days ago, if the devs can have consensus on better block size strategy, that's great, but we will also need an insurance, which is what XT is all about.
@_date: 2015-07-01 14:59:33
According to  it does affect block inclusion, because 50kb is reserved for high priority(which factors in coinage and amount), at least for reference implementation.
@_date: 2015-08-19 07:10:50


I see the blocksize as an exception. This kind of discussion has come up so often in the past but it always sputtered away. I'm not quite confident that This Time it's Different^TM
@_date: 2015-07-02 21:01:00


This is political, some people like to have payment network with lower fee. They don't care about supply cap, etc. You realized that ironically you forced your will to these people right? The only way to resolve this is by a vote. 


Yet that is not the case right now. Are you saying Bitcoin has failed?


You're aware that you're getting into political area here right? Some people would disagree. They would like to be able to send money to Wikileaks without hindrance. A higher fee is a hindrance 


Which you can easily change.


How does that benefit wallet maker?
I'm not here for political debate (got fed up at a gridlock around a few months ago)so I'll just stop here
@_date: 2017-04-01 11:51:47


That's what all Bitcoin Core post 0.13.1 does after activation... 
@_date: 2017-04-04 18:05:02


Oh, I do have an idea. Take a look at my comment history for criticism on extension block. BlueMatt already spoke against it, so did Luke-jr. There is zero advantage of extension block over Segwit.


Now guess why Adam Back and Johnson Lau moves to work on Spoonnet/Segwit and leaving extension block in the dust. There is a reason for that.
@_date: 2016-02-25 07:56:31
These are the same 'cheap' transaction which small blocker don't want in blockchain. Besides, the proportion of censored legal transaction vs legal transaction is really small.  There is no chance it will compete with illegal transaction. Take a look at 'transferring money to Snowden/Assange'. That is considered illegal even if it should not be. If Bitcoin is only good for this government won't hesitate to shut it down
Edit: I just realized this. **Governments**, banks, credit card companies, Paypal are censoring completely legal transactions daily. Well that is the very definition of illegal.
@_date: 2017-04-01 14:55:54


And you're breaking 90% of the code ever written and risking that the new format has a flaw. What exactly would we gain?


Define segwit in this case. If you define Segwit as "a subset of transactions unaffected by neither quadratic hashing nor malleability" then that statement is demonstrably false. 
@_date: 2017-04-21 13:28:55
So he signed them even though he doesn't agree? Doesn't make any sense.
@_date: 2017-04-20 05:38:08


Because Jihan is counting on the witness being moved into block header after the hard fork so that covert ASICBOOST still can work? Nice try though. I mean seriously, Bitfury, BTCC, BitmainWarranty, and F2Pool have no problems signalling Segwit even though they attend the HK agreement. Antpool is about the only one who is vehemently against Segwit.
@_date: 2017-04-05 04:38:17
So no blocksize increase then? I don't mind...
@_date: 2015-07-02 20:51:39
Didn't Gavin already did simulation on that? Probably just need to expand on the simulation. Simulation works better than the model after all.
@_date: 2017-04-06 13:26:02


It doesn't. That's why the fallback behavior during contention is to fall into status quo. Bitcoin still function even when Bitmain is lying.
However, it is generally considered a bad sport to have people running around trying to convince you that an upgrade is an improvement with minimal trade-off when the reason that they are so stubborn is because of conflict of interest. 
People shouldn't be surprised when there is an outrage.
@_date: 2017-04-20 18:21:46


What happens when that shit catches fire? Are they supposed to taint their reputation?
@_date: 2017-04-21 13:12:03
Implementation by BU.
@_date: 2016-12-04 10:11:07


Bad idea should be called out. How anyone sane could think BU is a workable idea makes me sick.
Yes, he doesn't even consider someone building on the chain without the excessive block and the consequence of receiving payment on that chain. That whole animation is just a red herring.
@_date: 2016-02-20 06:07:40
TL;DR Payment address can be verified to be coming from merchant while return address can't be verified to be coming from the same customer that make the payment 
(although it can be verified to be the same as the customer that open the HTTPS channel).
@_date: 2017-04-04 19:17:08
Political compromise=chain split. That is a fact.
@_date: 2016-02-09 12:23:38


I am not saying that it will. I am just saying that in the face of increasing demand (even in a situation of continuous doubling every two year like we have experienced so far) and constant block size some people won't be able to use the blockchain anymore.
@_date: 2017-04-04 12:26:31
The extension block proposal only allows to make Segwit transaction inside extension block, and not in the main chain.
@_date: 2016-02-09 04:13:44
Blocksize limit increase is a hardfork. Doing hardfork in emergency relief mode is practically a disaster in the making. The last time we had emergency relief during a fork is in 2013. During which time some whitehat manages to double-spend $10000:
Raising the limit needs to be done in planned way because everyone has to upgrade by the time the fork is finalized.
@_date: 2017-04-06 15:51:07
You can see clearly people (including me) are criticizing method 1, which is what bcoin is doing. Sidechain is method 2, which bcoin doesn't do.
Theymos also gave a lists of objections as well.
@_date: 2017-04-06 19:13:44


Looks to me that it is carefully worded just to cover the 'overt' version. Those are only true for the overt version.
@_date: 2017-04-27 19:37:56
I don't think it is a matter of a DoS, but rather a phone-home 'bug'. If they do know what the URL is supposed to do it should be enough for them to understand the issue. When people put "malicious code found!?" as a title for bug report they'd better take a look at it seriously.
That also means that they can't claim ignorance of this 'bug':


@_date: 2017-04-27 22:09:47
You do understand that contentions is part of being decentralized, right?
@_date: 2017-04-28 00:26:52
Geth chain was also being rolled back you know?
@_date: 2017-04-01 12:54:26
Nothing to do with our original discussion. We are discussing about the necessity of keeping the code necessary for old UTXO. 
The possibility of a flaw exists whether or not Segwit is implemented as HF or SF.
@_date: 2017-04-05 10:06:25


It is bad when an adversary can manipulate it such that it is growing faster than technology. Like what happen in July 2015


Current setup is to placate people who insist on a block size increase.
@_date: 2016-02-26 11:24:58
Hmmm... Now I'm not really sure we're on the same page.
Is this


a response to this


or to this:


@_date: 2017-04-06 16:36:45


Eh, that is not asic, no? sha256d generally is more simple than processors though.
@_date: 2015-07-02 20:41:05


"I'm so happy your software is a giant resource hog."
"Thankfully your software is as costly to run as possible - the costlier the better!"
Let me rephrase that 


This same perfectly sane person will actually do say that if there is guarantee that their transaction will get confirmed on time.


On the other hand cheaper full node will make people unable to get their transaction on the chain at a cheaper price. See the tradeoff there?


Err, you do realize that most SPV wallet are free right?
@_date: 2017-04-26 13:45:38
Haha yeah, edited.
@_date: 2017-04-21 14:25:54


1. A hard coded constant will do just fine in terms of market voting. In fact a hard coded constant will perform better over miner-voted in terms of making sure 21M BTC limit retained
2. There is some work on sacrificing difficulty for bigger block (which only makes sense if transaction fee can cover for the difference). Edit: Not really sure on what is the progress on this


Politics over technical superiority will result in two chains.
@_date: 2017-04-20 17:01:43


The problem is that once you stated your opinion openly you are vulnerable to smear campaign. For example are you certain is not a Core dev? What about Or (Note: I'm not saying they are, but from the comments they seem to qualify as one) 
Lots of knowledgeable people here on Reddit. Unfortunately you will need to be knowledgeable yourself to weigh each of their opinions.
@_date: 2016-02-29 07:03:16


This is just a variant of flexcaps with coin-age replaces miner.


The decision on economic policy is not a democracy, as all of it have been offloaded to a groups of people. Bitcoin allows 'voting' in transparent manner. (Economic power determines hard limit, and hash power determines the soft limit)
Edit: You have any idea why  doesn't appear?
Edit2: Those curious take a look at my comment history. It is in reply to comment above.
Edit3: Oh, there it is. Maybe just a CDN lag. Sorry for being paranoid.
@_date: 2017-04-05 04:43:00
How about quadratic hashing fix? Signatureless IBD? Script Upgrade functionality? No?
@_date: 2017-04-04 19:30:19


1. A 10x sig is still more expensive than a 1x sig
2. The discount is toward witness, that doesn't contribute to processing, storage, high-speed (memory) or low-speed (at least not with signatureless IBD)
3. UTXO bloat attack is still scarier than a witness bloat
4. People can take advantage of the discount for being altruistic (cleaning up UTXO set) or improve fungibility (Signature Aggregation)


People who upgrades benefit the network by using transaction that is not affected by quadratic hashing


Yeah, you can try to do that in the testnet with unlimited amount of fund. See if you can break it. (Hint: no, you can't, the discount factor is already calculated carefully)
@_date: 2017-04-21 14:08:43
There is infinite demand.
@_date: 2017-04-22 04:28:14
1. Lightning is still Bitcoin
2. Your transaction put heavier load on the system, as such it needs to pay more.
@_date: 2017-04-04 12:40:27
I don't know. All I see is that they are proposing a solution that is no better than Segwit, more contentious, and actually prevents Segwit from gaining traction in the main chain.
@_date: 2017-04-20 18:50:07
So surely they won't have any problem finding anyone competent to do create the code for them. Because no respectable devs are going to put their reputation on the line creating a shitty code.
@_date: 2016-02-25 05:16:46
Let's face it most of the use case for uncensorable transaction is a crime (even if it is 'victimless' crime like money laundering, buying drugs, or even circumventing capital control). If this is what constitutes most of the Bitcoin transaction government have more incentives to take down Bitcoin (and at the current size of Bitcoin let's not pretend that they can't do it, I mean even the traffic is unencrypted unless you are using TOR which if the case that will make even smaller block size limit to keep mining decentralized). The only way to make Bitcoin remain uncensorable is to get more lawful transaction inside Bitcoin, whether it is internet payment or remittance. That way government can't shut it down without raising public outcry.
@_date: 2017-04-01 11:25:06


X is Segwit.
Here's what would happen in alternate timeline.
* Community starts demanding more capacity
* Core (or a number of developers) doesn't think it is neither necessary nor safe
* People stick with 1MB
* People HF to 2MB while Core deploys Lightning using malleability fix while at the same time decrease block size(either Segwit or Sighash single)
* Watch the other chain debate whether or not to increase to 4MB the next year
Segwit **is** a compromise. And this is coming from someone who has been fighting for a block size increase of more than a year:
(Thanks I've been trying to dig this information but I can't get past 9 months of reddit history)
@_date: 2016-02-29 13:18:01
KNC, Slush, and Bitmain do plan to support classic.
It's up to anyone's guess but personally I think the support for Core comes from:
1. Core still has the best expertise all around. 
2. They do promise an increase. If they actually say 'no we will not do an increase whatsoever' I think that's when shit actually hits the fan.
@_date: 2016-02-09 07:52:42
That means some people won't be able to use bitcoin network (on top of higher fee and longer confirmation times). 
Let's say right now the block is full, that means whoever is using Bitcoin (whether DNM, Coinbase, Bitpay, Rebit etc.) is already maximizing Bitcoin capacity. Let's say tomorrow Amazon starts accepting Bitcoin. That would mean additional demand but the supply remains constant. This would mean some of the on-chain transaction needs to get shafted somewhere else. People who normally uses Bitcoin (or going to) is no longer be able to do so. 
Fee will go up because of the bidding war for block space. Transaction that normally can go into block on the 1st block probably need to wait until 2nd or 3rd block because they are being outbid by someone else.
Most likely one of the first one to go is the micropayment, then low amount remittance, and it will slowly goes up the chain until only the very rich can transact on chain (worst case). 














Or the alternative is someone who was going to use Bitcoin uses something else more cost-competitive because the block is too full. While this is probably not enough to kill Bitcoin it will probably damage the momentum that Bitcoin already has going.
Sure, you can go offchain but then you are already relying on third party. In the future there will probably be Lightning Network to offload the transaction onto but unfortunately it will not be ready anytime soon.
@_date: 2017-04-21 14:04:01


You underestimated the amount of knowledgeable people in Bitcoin who can easily circumvent such obstacle.
@_date: 2016-02-29 04:38:54


In the current state of hard-coded rule we will need to do a fork every time we increase/decrease the limit(soft for decrease, hard for increase) this has led to inflexibility/deadlock whenever we want to adapt. Are you saying you are against any kind of flexcaps?


I'm not really sure what kind of democracy you are talking about. I wonder how many people actually wants QE/negative interest rate to be implemented. Or having any say in economic policy in general.


Treat any 'abstain' vote as a status quo. That way it behaves similar to the current hard limit (note that only single transaction needs to get inside the blockchain while inside the voting period, I'm not sure how effective can the miners be at doing this)
@_date: 2017-04-21 13:45:16


1) Because in the long run blocksize limit is required to ensure 21M BTC limit.
2) Right now blockchain grows at 50GB/year. If it increases by 2MB it grows by 100GB/year. 4MB it grows at 200GB/year. That means at 4MB I will need to upgrade my computer earlier than I used to (5 years), and that is assuming that I kept all the 1TB drive free.
3) 4MB was also happened to be the limit at which the network can remain decentralized. 
4) UTXO at 1MB is growing faster than the memory growth
5) Already people are having trouble running a full node.
6) If Bitcoin can't resist pressure from a 1Billion dollars company (at best) it won't stand a chance from a state actor (which might even play a part right now) 


You have better chance with Lightning than that.


Reducing blocksize is as difficult as increasing one.
@_date: 2017-04-06 16:40:58
Normally you don't call a general processor AS(Application Specific) ICs.
@_date: 2017-04-05 10:07:42


Bigger than Segwit.


As such vulnerable to problem that the discount meant to avoid.


@_date: 2016-02-29 07:59:53
Pro 1MB(or whatever the current block size is). Since they are not aware of any votes going on means they are fine with 1MB
@_date: 2017-04-06 16:22:47
This is an entirely different area of expertise though. I doubt Greg Maxwell found the evidence himself (unless I severely underestimated him). This sounds more like Peter Todd kind-of-thing (he has electronics background) although I also doubt that he has knowledge of IC deprocessing technique
@_date: 2017-04-01 11:56:52
It is a soft fork. Only Bitcoin Core prior to 0.13.1 doesn't have privkey node enforcement. That's how P2SH deployed as well. Do you consider that as a not a soft fork as well?
@_date: 2017-04-01 12:28:09


That's a really roundabout way to do it though. It makes more sense to support Johnson Lau's work (like Adam says) than generating unnecessary contention.
@_date: 2016-02-29 07:09:07
You did not notice how the opinion split into two? Irregardless of where you are in the debate some people think that the block is full some people don't. This is the first time in 7 years of Bitcoin. If everything goes well we won't need to do this very often.
@_date: 2017-04-04 11:06:09


Guess why Johnson Lau moves to spoonnet instead?
@_date: 2017-04-07 00:27:37


The distance between this proposal and Greg's BIP is barely one day. I doubt that he has time to review your proposal properly. He only got to the part that confirms his observation. He needs to prepare for his own BIP after all.


I think I have mentioned this before but you lost a good deal of credibility once you contacted groups of people who have been antagonized for blocking progress before the rest of the community. Even if your idea is good you will face a backlash.
Edit: Also you're also missing a main point. Understanding social engineering is part of good adversarial thinking. Even if you're not a bad guy it is entirely possible that someone is using you (e.g delaying tactics)
@_date: 2017-04-21 10:30:22
Those two are already finished the development phase...
@_date: 2015-07-02 21:57:55
Well, I hope you don't mind getting the ball rolling, seems like you already have an idea of what you want. Just come on over if you need any help. I think most of us here would gladly help
@_date: 2015-07-02 21:25:30
Errr.... Doesn't the simulation suffice for this? For example blocksize increase by X, miner with bandwidth Y will be at a disadvantage, block propagation time increase by Z, etc. You can get all of these figures from the simulation. 
Again the budget will differs from person to person. Which is the hardest part.
@_date: 2016-02-26 08:34:22
In general payment routing is slightly trickier than network routing. In network routing shitty route imply disconnect and reroute, all within second. In LN routing shitty route means locked fund. There probably needs to be some sort of reputation system. 
On the other hand (honest) participant also need to ensure that the system remain decentralized so by right everyone should not end up with the same route.
@_date: 2017-04-04 23:02:37
Not with this version of extension block it doesn't. It is not compatible with BIP141. They are only allowing Segwit to live inside the extension block.
@_date: 2017-04-21 10:30:30
@_date: 2016-02-12 02:20:15
Yup, when BIP101 was created there was no such a thing as Core roadmap. If anything, BIP101 should be considered as a precursor to Core roadmap. In a way it exposes the fact that the emperor is naked, that there wasn't any plan (short term nor long term) to alleviate congestion caused by full blocks
@_date: 2017-04-21 13:15:10


And do you see that happening?
@_date: 2017-04-06 14:34:50


Plan B that is more contentious than plan A with zero technical advantage while "accidentally" benefit Bitmain? Yeah they're not selling me anything.


Sidechain? Yes. Spoonnet? Yes. Extension block? No as far as I know.
@_date: 2016-02-09 16:29:16


Actually the increase in fee in July is due to stress test: 
so it actually corresponds to a simulation of what happen when the blocks is full (also note that we are talking about attacker with limited fund, when we are talking about real world demand everyone is an attacker and there is unlimited fund so the effect will be worse).


This will no longer be the case after 0.12 (actually can you show me where zero fee tx are being processed without delay? because there is a post in front page saying that at 0.0001 BTC/kb it is still not getting confirmed so definitely there is conflicting information)
@_date: 2017-04-20 18:38:32


What politics? Avoiding DoS is not politics.


What is supposed to happen when they don't agree how to fork?
@_date: 2017-04-21 10:39:37
Those two are already fully functional once the community wants it...
@_date: 2016-02-29 05:29:43




Agreed. UI part is really tricky.


1. Have a bunch of people who supposedly know more than you decide what is the best? How is that any different than how Federal Reserve work?
2. The current debate is proof that there is a disconnect between Core developers and the users. AFAIK there was no agreement on how to increase block size until Gavin made that mess a year ago. We need some sort of signaling mechanism between the user and core developer.


Let's limit this to block size shall we?


Agree to disagree then. I want a censorship resistant money that everyone can use, even if it means compromising. I think the current 2017 timeline is good enough, not everyone is happy but all can live with it. I, for one, however would like to have to deal with less mess and personal attack that currently happen if possible. 
@_date: 2017-04-06 13:04:37


Mostly because I think they are too competent to realize that that proposal has zero percent chance of being passed. Matt Corallo already made criticism in the past and even two of the ideas originator already abandoned the idea in pursuit of something else. That doesn't happen without a reason.
Similarly they seem to go out of their way to disable segwit on mainchain. There are ways to make extension block work with Segwit (like sidechain)
@_date: 2017-04-01 23:08:14
No, it isn't. That is a common misconception. Segwit's block that contains 2x transaction will still need 2x bandwidth to propagate.
@_date: 2017-04-27 21:01:26


Schnorr!=Signature Aggregation. Signature aggregation enables you to shave off the entire signature for the second, third, forth, and so on inputs.
@_date: 2017-04-30 12:15:14


Those plans depend a lot on
1. Data gathered from Segwit activation
2. Covert ASICBOOST being disabled (weak blocks, IBLT, fraud proof, TXO commitment etc.)
How about Bitmain support (2) if they don't want to support (1) to show good will? For all we know of most likely the next hard fork plan will be opposed for silly reason like 'Segwit discount' while the actual reason is to protect covert ASICBOOST.
@_date: 2016-02-25 05:41:14


No block size limit debate has never been purely technical. makes a good explanation about that here:
 Even the 1MB limit is arbitrary. There was never any testing before deciding that number whatsoever. Even for technical decision there is always a trade off that there is no black and white answer for. Example: weight-strength trade off in construction.


Government interference is a possible attack vector. 
@_date: 2017-04-06 12:13:12
Blocking Segwit?
@_date: 2017-04-06 17:15:32


Except that you're severely downgrading Bitcoin experience for people who wants to use Segwit, which offers a slew of improvement. Extension block requires you to wait to make sure that there is no re-org happening. People don't get pissed for no reason.
@_date: 2017-04-21 14:37:53


Of course there is. Are you aware of the implication of free energy? That means there will be no more world hunger. Space exploration. Or even immortality. 
@_date: 2017-04-01 22:47:44


That's what Segwit in current state is.


He is not telling that to you.


Does it address UTXO bloat attack? Do you have it in Github somewhere?
Without full blocks even 1MB is too dangerous for UTXO bloat. 
If you think Spoonnet is technically superior then start working on that instead of a compromise.
@_date: 2017-04-26 23:31:33


I just showed that this argument has no ground whatsoever.




And why doesn't he? Did you read the whitepaper^TM ? What makes it unlikely for miner to do 51% attack?
@_date: 2017-04-01 11:55:59


Some people already did. Read his comment.




Core is not a single unified entity. No one can promise you any timeline without consensus. Even timeline for Segwit is obtained only after consensus is made.
 I am surprised that I still have to repeat this. People are free to work on whatever they want. And with all the personal attacks it is not surprising that people avoid that.
@_date: 2017-04-04 11:08:08
[bcoin is probably funded by Bitmain as well](
@_date: 2017-04-21 02:32:21


I wouldn't be surprised if Blockstream if governed the same way as Bitcoin Core with individual having freedom. Samson Mow was still promoting UASF while Greg has spoken against it. 


What other matters? Just in case you didn't remember After Gavin brought up blocksize debate and small blocker was paralyzed, unable to come up with anything for about 9 months until Segwit comes out. Even then people seems to underestimate the effort required to reach consensus.


You know what being open source means?


The only thing they're currently in unanimous consensus about is Segwit. Spoonnet? Being debated. Luke-jr's proposal? Still being debated. UTXO commitment? Still being debated. When people can't stand the heat of debate of course they are being shown the door.


Yeah, let's just ignore the fact that they're not immune to criticism
Surely you would know that, since you're here since 2011 right?
Also let's forget about Adam Back's extension block proposal, which has also been rejected.


The ones who has openly stated their opinion. Now guess why not many people want to speak openly.


Just in case you haven't read them, Post-segwit roadmap is really vague. I'm not sure that they still follow them right now, especially with uncertainty around segwit.


Of course they can't. They are not unquestionable. btcd did that before:
@_date: 2017-04-29 10:19:53
Why the flying fuck are you using MAC address as identifier? Do you understand the implication?
@_date: 2017-04-21 14:40:52


Loaded has 40,000 Bitcoin. Mircea Popescu probably has more (some even speculated around Satoshi level). Have you asked them? 
Unlike other cryptos there are people who invested a large amount of money back when Bitcoin was still in its infancy. And you can't consider these people "normal"


Do you think PoW change is not a thing? Or manual difficulty reset?
@_date: 2017-04-06 17:23:10


Yes, and when selfish people goes against the rest of the network it is normal for the networks to fight back, which is what is happening. Selfish mining is profitable but if miner actually attempt that people will just change the PoW (or PoWA).
@_date: 2017-04-27 00:28:36


I guessed he also doesn't expect people to actually audit the source code...
@_date: 2017-04-01 12:15:37


Old UTXO depends on non-segwit code for validation...
@_date: 2017-04-21 15:14:21


1. Variance
2. You need more than miner support. Big blocker's main weakness: only lobbying for miner, ended up being used as a pawn for Bitmain.


Like, who?


The main objection over BU is miner's control, not the amount of increase. I'm not even sure how you're going to appeal to big blocker now..




No compact block support and no Segwit support. LOL. At least they need to replace xthin you know? That is totally borked.
@_date: 2017-04-21 13:21:32
So you're saying Charlie intends to break that promise if there is a pushback from the community? And sets off another Litecoin Core dev breaks promise shit later?
@_date: 2017-04-01 12:17:56


You **are**. Upgrade to Segwit or your coin made invalid
@_date: 2017-04-01 14:34:06
This was the original point of contention:
Old outputs will still be affected by malleability unless you figure out a way to make BIP62 works. There's not much difference between SWSF and SWHF.
@_date: 2017-04-04 12:24:21
But old nodes will still see the input and the output. This means that bitcoin is still fungible. Every nodes still verify every input goes to the next output (although it is visible as anyone-can spend). This is not the case with extension block (unless you want to make extension block compulsory, which is no better than a hard fork) where some part of the economy is totally invisible to the old node. Now you have two classes UTXO, the one stored by old node, and the one doesn't. (Ironically this is one of BU supporters objection to Segwit, although it doesn't actually have two classes of UTXO)
@_date: 2017-04-21 14:03:05


No, it is not required. Fee market will just price out some people. 
Also, I forgot to comment about this part:


What happen when the community doesn't want an increase? Is Charlie going to force it through?
@_date: 2016-02-26 11:55:54
Now let's say this is my only use case for Bitcoin(getting paid weekly to explain for the recurring part so I spend some part of it on let's say drugs, or remittance). Let's say I don't use it for anything else. Why would I open channel anywhere else?
@_date: 2017-04-07 07:28:23


But he can't be 100% sure that it won't break something else in your proposal unless he spent at least a couple of hours reviewing them. With his own bomb to drop he has other priorities. 
@_date: 2017-04-21 15:16:35
Only recently added apparently
@_date: 2017-04-01 12:39:44
You still can spend from and to old style outputs in UASF chain. There's no confiscation exists anywhere.
@_date: 2017-04-01 22:36:12


That's not what Spoonnet is. That is different from Luke-jr's proposal.


Because they already reaches consensus when the timeline comes out.


Then fork away.


They aren't supposed to. If the big block community wants to reach consensus they will work with Johnson Lau and address all the objections as they arise. If they don't they can start planning for a fork now.
@_date: 2017-04-21 10:19:54
Mostly same criticism as BU
1. No wipeout protection
2. No replay protection
3. No quadratic hashing protection
4. No UTXO bloat protection
Also take a look at Meni Rosenfeld's criticism here


They're just rehashing all the old rejected proposals. Extension block, and now this (and they don't even attempt to hide their effort to protect ASICBOOST lol)
At least the chain might converge though, however it is the same team that develops BU so most likely it is still a shitchain
@_date: 2017-04-07 00:23:39


Except you're making it more difficult for people who wants to use SegWit?


@_date: 2016-02-26 13:19:51


That's where the problem is. I don't want to receive my paycheck in Bitcoin. Most of my spending is not in Bitcoin. And my employer may not want to find connection to Bitcoin. It is the chicken-and-egg problem described by here:
@_date: 2016-02-29 13:19:49
I think when Lightning first released this is generally a good idea to follow (irregardless of how the routing will be) since it is semi-experimental after all. Hopefully as the technology matures we can start to entrust more to it.
@_date: 2017-04-21 15:23:38


No. The way to prevent that is to incentivize people to make a normal transaction (1 input 2 outputs) or clean-up transaction (3 inputs 2 outputs) over abnormal transaction (1 input 17 outputs). Multiple payments can be routed over Lightning instead.
@_date: 2017-04-27 19:57:18


What makes you certain that the implementation that doesn't crash and burn is not accepting invalid block in the same scenario? Multiple implementations is good for audit purpose in the early stage of protocol development but in the real world you are supposed to run behind "one" code (or at least run all of the implementations and raise alarm if one of them fails)
@_date: 2015-07-02 19:58:21
Still a little bit naive I think. Bitcoin block size limit has never been fully a technical discussion. It is partly a political one. For example this point:
 &gt;In most cases the min spec is based on entry model machines that are available during launch
While it is quite obvious that you can deal with this sort of thinking in game-dev(of course company want to make profit) you can't just straight away port this into Bitcoin. Some people would like full node to be ran only in server-grade hardware to support higher tps, others would like more people to verify the blocks while sacrificing tps. 
@_date: 2017-04-04 09:28:36


At least LN doesn't attempt to invalidate community's work for the last 1 year or so. Not to mention that we hear it firsthand from you and Tadge yourself. Did you seriously not foresee this reaction?


Not just to the press. To Wang Chun and to whoever leaks to Samson Mow. The first thing I think about when I heard about this was how to create a competing soft fork to invalidate this new vector of attack. How do I know you are not in cahoot with Jihan? He is wandering around promoting BU now. Are you saying that this is just a coincident? Together with Sergio's 2MB?


Normally there's a BIP before things get out to the press.


What timeline? Someone gave you a deadline? Like Jihan? You are not really thinking this through. The manufacturer of 70% of ASIC in market just attempted a coup. People are in high tension all around. Even if your proposal is good (I don't think it is) people will be turned off.
@_date: 2017-04-28 01:11:44
So did R3. Remind me what happened to them.
@_date: 2017-04-27 21:12:51


NO. 21M BTC limit is more important than NC. Preventing coin confiscation is more important than NC. Even block size is more important than NC. NC doesn't even come to play during the split I mentioned above. Proof-of-Vitalik does.


OR the system simply doesn't change when there is contention.
@_date: 2017-04-06 17:29:10


Eh? You sure about that? A more honorable person would forego his (unethical) benefits he has for the good of the networks. (Or if he is less honorable at least he won't lose face over this scandal)
@_date: 2017-04-05 04:34:17
I don't believe for one second that they simply forgot about this. They are too competent for that. It is done in deliberate manner. 
@_date: 2017-04-04 17:55:40


Joseph Poon (along with Thad Dryja and Laolu) experiences first hand how this is not true.


If the objection is technical it can be fixed however since it is not we shouldn't settle for shittier solution.


This one is more unlikely to gain consensus than Segwit.
@_date: 2017-04-01 12:35:40
You're confiscating coin in the new chain. Doesn't matter how you phrase it.
@_date: 2017-04-26 21:32:02
And which date was that? (Hint: I gave you a link)
@_date: 2017-04-01 22:39:33
Some people think 1MB is already too big. If Segwit is rejected it is more likely the block size increase part will be removed instead in the next proposal.
@_date: 2016-02-09 06:45:47
Let's talk about planning then. When you mention that we are **not at that stage** did you calculate the buffer time for pre-planning? Because extrapolating from
Block size roughly double every year since ~2012, so even with success of SegWit we'll probably need to do hard fork at least sometime in 2017. Ideally I'd prefer that we have 1 year of grace period. What's your ideal grace period? Or are you one of those people who prefers stunting growth?
I support Core's roadmap and I understand that they will probably need to evaluate the effectiveness of SegWit/IBLT/Weak block before hard fork but they will need to do so ASAP.
@_date: 2017-04-29 10:18:30
What change?
@_date: 2017-04-06 12:17:48
1. That only makes sense if only collaborators knew about the proposal beforehand (Poon, JJ, Stephen Pair, Fedor). The list of people who knew about the proposal beforehand includes Wang Chun, whoever leaks to Samson Mow (which can only be explained by an attempt to secure miner support beforehand), and Forbes (only can be explained as PR attempt). That's not how this works, that's not how any of this works.
2. If I were you I would lay low now. You are either a puppet or a an accomplice:
@_date: 2017-04-27 13:12:41
1) That means they ignore this 7 months old issue:
2) When you are talking about money incompetence and malice will produce exact same result.
3) We are talking about the same shady groups of people who just purposefully delayed shipping Litecoin miner just for the purpose of delaying Segwit and threaten to 51% attack a minority chain. If you believe there is no malice involved I have bridge to sell you.
@_date: 2017-04-21 10:11:03
Are you talking about maintainer? If yes,
1. None of them attend HK meeting
2. If there were any indication that they might abuse their power, they can have their privilege removed, like what happened to Gavin
3. Maintainers are janitor, not leader.
@_date: 2016-02-26 06:11:54


Eh, I actually mentioned routing


The original whitepaper mentioned 'super node' that is comparable to tier 1 ISP. But this can be easily regulated. Blockstream mentioned they already solve this but I have yet to see the whitepaper. I consider decentralized routing would be pretty hard to solve


Well that would depend how high of payment. Let's say you have $50 weekly recurrent payment. Do you use on-chain or LN? LN would require $50x4(4 weeks)x6(6 month) =$1200 locked up inside the channel for 6 month. Do you have this kind of fund? If you use on-chain how much fee do you expect to pay?
@_date: 2017-04-21 13:57:31


There will still be two chains. A lot of people already determined to keep the old chains alive.
@_date: 2016-02-24 05:23:55
Mods need to give you flair....
Just so that everyone can see a little bit ray of sunshine
Note: Alex Morcos is a core dev
@_date: 2017-04-26 16:54:38


Buy a ton? Where? There was no liquidity whatsoever. Poloniex just listed ETC. Not to mention he was a miner, so he already held a lot of ETC (from F2Pool late conversion I presume)
@_date: 2017-04-27 19:47:02


Nakamoto consensus doesn't apply to different consensus system. If Alice pay Bob is a valid tx in one client but invalid in another Nakamoto consensus can't resolve the difference. This is a concrete example:
In this case Bob and Charlie are miners (two different miners accept coinbase for the same block according to two different clients). You can have Proof-of-Vitalik in case of Ethereum but not in the case of Bitcoin.
@_date: 2017-04-06 18:24:53
I'm going to be honest with you. It is really difficult.
1. It is not clear what the proposal aims to achieve, replace Segwit? Does the contributor unaware of extension block criticism that makes the idea abandoned?
2. I'm not sure what could be gained by informing miner prior to everyone else. In fact I would hope this will never happen again in any kind of scenario. This just sets up a really dangerous precedent, especially in soft fork scenario. I hope this never happen again, **ever**
3. Similar with Forbes, in fact this reminds me of the time Bitcoin Unlimited attempt to fork. They called the news media first.
4. The scenario just happen to benefit Bitmain, really? If anything I would be suspicious that one contributor is not telling everyone the whole story.
5. Add to that the Bitcoin Development Grant circumstances and you will no longer certain what is happening.
In other words, sorry but I don't think you can convince me otherwise. Perhaps just bad luck (but really, it takes everything to align perfectly for this to happen)
@_date: 2017-04-26 13:27:27


People who thinks that SWHF is good but SWSF is bad is in very tiny minority. 


Even he himself later does a perfect 180 degrees:


So which one is it? Is it technical debt or is it not? Or he just simply trying to help Jihan hiding ASICBOOST. Which one is more plausible.


Except there AXA conspiracy doesn't offer this level of circumstantial evidences.


So you're saying Bitmain produces Antminer with AB at extra silicon space, applying for Chinese patent, proven to be working by multiple peoples, saying that SWHF is good but SWSF is bad, pushing for extension block, pushing for 2MB+SW, refusing to implement soft fork to disable AB, producing empty block at higher occurence than any other miner **for no reason at all**? I think said this better than me:
@_date: 2017-04-20 07:22:36


There's no such a thing as "Core". There is only individual contributors to an open source project. "Core" is not run as a top-down management where people at the top can order people at the bottom. Each individual contributor needs to reach near-universal agreement on what is being merged. Likewise, they also need to take into account what the community want (I wouldn't be surprised if anonymous whale-eater like Loaded in Bitcointalk already convinced some of the contributors that they will continue the old chain)
"Core" doesn't sign the agreement, only a few individual signs the agreement (possibly under duress). These individuals have no power over what is being merged into "Bitcoin Core". In fact when they signed the agreement they receive the same treatment like what is being received by bcoin team when they released extension block proposal. Even so, the way I see it each of them still persevere even though Antpool is running Bitcoin Unlimited and F2Pool is running Bitcoin Classic. Johnson Lau is still working on spoonnet and Peter Todd is still working on TXO commitment (which is probably will also be blocked because it is incompatible with ASICBOOST)
Personally I think HK agreement is now moot since Antpool is already running Bitcoin Unlimited and F2Pool is already running Bitcoin Classic.
@_date: 2017-04-26 17:37:35




@_date: 2017-04-06 17:31:47
He did mention that though:


would have been made to avoid incompatibility-- simply to separate
concerns.  But the best methods of implementing the covert attack
are significantly incompatible with virtually any method of
extending Bitcoin's transaction capabilities; 
@_date: 2016-02-24 15:18:07
The thing is there was such a thing as priority transaction:
which took into account bitcoin days destroyed. Unfortunately even this is already removed (initially by some miner and now by the Core developer). (Someone should update the wiki)
@_date: 2015-07-02 20:31:51
Ah, I see your point now, a hard-number-only requirement for the current Bitcoin operating at maximum capacity. I think most of them is already available, just needs a compilation, OpenSSL capacit) is on the wiki, storage capacity can be easily extrapolated, sipa covers networking side, etc. 
Personally I don't think there is a big disagreement on the numbers (although a compilation would be nice, just to make sure everyone is on the same page).
@_date: 2017-04-04 17:06:34
At the very least is the dynamics is already more or less understood. P2SH is deployed the same way. You can't say the same about extension block, where the old nodes can't see some of people's UTXO.
@_date: 2017-04-28 00:27:43
Apparently not enough to stop a consensus failure. Or to check that Parity still has error in its implementation. But you prefer that over bickering right? After all miner burns electricity for free right?
@_date: 2017-04-06 12:12:54


No, it isn't. A malleability fix by itself doesn't guarantee that (e.g BIP62, FT)
@_date: 2017-04-20 18:39:17
@_date: 2017-04-21 13:13:17


NO. They kept their promise. This is the code mentioned:
However, unlike Charlie Lee they can't speak for the communities (hence it was rejected)
@_date: 2017-04-26 15:33:35
I think it was in front page for around 6-7 hours...
@_date: 2017-04-06 17:24:07
Not if it manages to replaces all SegWit's functionality + more. (or at least has an acceptable trade-offs compared to Segwit, which bcoin's proposal doesn't)
@_date: 2017-04-01 12:18:23
Yes. Confiscating coin. Like I said.
@_date: 2017-04-01 12:09:12
Extension block will produce 2 classes of UTXO though. Some people like Luke-jr doesn't like it. I don't think we can reach consensus on that...
@_date: 2017-04-06 12:53:31
* I see I misread your original statement.
* That news is after ASICBOOST is revealed.
* Even if you truthfully don't know anything it doesn't change the fact that your name is used in a malicious scheme. That makes you a puppet (e.g a useful idiot). It is only right to be careful with whom you associate with lest your name will be tainted together with theirs. If you are truly honest I hope you learn the lesson this time.
* Your post lately doesn't really help. (Censorship, compromise?)
@_date: 2017-04-21 13:13:50
And you think this proposal won't result in two chains? Watch again.
@_date: 2016-02-29 07:16:22


This is speculation. The only way to prove whether or not this is true by voting in the blockchain. If you really think this is manufactured the vote will shows.
@_date: 2017-04-06 19:11:09
Half of it is being smear campaign as well. Real professional guys.
@_date: 2016-02-24 19:26:18
I have no idea what is the new rule. I'm not that familiar with Bitcoin codebase. Unlike opt-in RBF there was no documentation/BIP published. I only realized that the priority is removed when someone mentioned that in Reddit.
@_date: 2017-04-01 22:41:02


That's already proven.
@_date: 2017-04-01 11:40:45


That means anyone who uses Segwit tx pledges loyalty to Core chain. I don't see anything bad with that. UASF is nearly equivalent to Segwit as a Hard Fork. Miners can choose whether or not they want a split chain (be reminded that as is, the original chain can be wiped out if UASF hashrate exceed that of the original chain). 
Also note that even if Segwit is implemented as a hard fork it will still be anyone-can-spend. The replay protection will exist outside Segwit.
@_date: 2017-04-26 15:57:45
BTC-e lost nearly lost all of its ETC this way...
@_date: 2017-04-27 21:00:06
@_date: 2016-02-26 09:42:37


Interesting, but that would imply opening another channel, right? So another on-chain transaction.
@_date: 2016-02-26 12:36:49
Well, I don't have $1200 to open 6 months channel. And by the look of it on-chain transaction is too expensive. So what option do I have?
You mentioned channel rebalancing. Which channel is being rebalanced?
@_date: 2017-04-01 16:47:10
And depend on how you define segwit I still can argue that my statement is correct.
@_date: 2017-04-05 04:34:50


1. That's what spoonnet is. 
2. If multisig is actually cheaper to process than what it seems it should be made cheaper.


Yeah, I don't see any proposal from you.


Yeah, just need to convince everyone there will be no block size increase for the next I don't know, 5 years?
@_date: 2017-04-04 17:22:27
@_date: 2017-04-04 05:38:57
Technical community should have heard this firsthand, and not journalist (at least if you want to gain good will). Doing otherwise in this highly contentious environment is just asking for trouble. IIRC Lightning whitepaper is released the same way.
Samson Mow heard the leaks from somewhere else that means someone else (probably apart from Wang Chun) already knows this. Who else is in the cahoots?
@_date: 2016-02-29 04:25:39
custodial holder can proof that they vote according the wish of their users through proof-of-reserve (or at least scheme similar to that, just include the vote as well as the bitcoin amount)
@_date: 2017-04-04 05:12:55
Unless I get this one wrong it seems like I won't get Segwit on the main chain. That's a big NO-NO. By disabling Segwit on the main chain you will not be getting script upgrade capability. You won't be getting signatureless IBD either.
Want to use Signature aggregation? Use extension block. Want to use Lamport because quantum computing? Use extension block. Not to mention loss of fungibility on the 2nd set of UTXO.
@_date: 2017-04-27 22:15:40


There is no way of resolving contention quickly without the decision making being centralized. You just didn't realize that there is not enough people doing fact check on what you do.
@_date: 2017-04-22 04:28:27
So does unlimited block size...
@_date: 2017-04-21 13:56:12


Doesn't change the fact that only miner has a say.


I see. Apparently they made an update to the older proposal (Dated Dec 2016). Again, that is still inferior to Johnson Lau's sighash estimate. You can fit more than 50000 normal sized transaction 224 bytes over a single 1000000 bytes transaction. Counting bytes is pretty stupid.
@_date: 2017-04-26 17:22:06
So you're saying that LTC.TOP received their sudden hashrate out of nowhere?


@_date: 2017-04-27 22:12:09


The fact that Geth decides to roll over and not scrutinize Parity enough says something about the decision process. When you have decentralized decision making you do a fact check over everything the other party says. If you have "whatever" attitude you already bow down indirectly.


Why not a rollback? That's the most technically correct solution. Or for that matter why not a shutdown in the first place?
@_date: 2017-04-01 13:19:10
You think there's not enough awareness? Or that rbtc isn't loud enough yelling all-you-can-spend? You can start spreading the word. But either way they will have to go out of their way by a lot to get conned. Not to mention that the original chain can be easily wiped out if there's no protection.
@_date: 2017-04-26 13:51:31
Fun fact  I don't think anyone has ever heard of Jiang Zhuo'er or BTC.TOP back in Nov/Dec 2016. It is entirely possible that he is just another puppet raised by Jihan.
Fun Fact  He is complaining about HK roundtable even though he doesn't sign them:
@_date: 2017-04-28 00:27:13


Uh, not correct enough apparently. How long did you take to make that decision? Hours?
@_date: 2017-04-27 21:37:36


If the client developers bows to you everytime it reduces to Proof-of-Vitalik. I mean Parity has bug, Geth has bug. Why does Parity has higher precedence? Geth developer should fight for a rollback instead. Why, instead of letting the chain shutdown while the cause of split being determined people choose to run Parity instead?


The devs asked the exchanges and the miners (with the exchange, especially Mt.Gox, having bigger says). They don't decide between themselves. That's why 0.7 have higher precedence over 0.8, although 0.8 is the technically correct one.
@_date: 2017-04-04 17:15:24


1MB is still a problem with UTXO bloat when you don't have a full block. Rather than extension block HF is still a better approach. All of this squabbling really doesn't help when
1. Segwit is still a better option
2. There's already an effort on Spoonnet where people can contribute instead of muddying the water
3.The extension block idea works better as a sidechain
@_date: 2017-04-06 13:28:36
Even worse: Firestone only sell those tires to cars made by Firestone Inc. and start lobbying congressman to refuse to have the road treated because "it causes cancer".
@_date: 2016-02-29 04:50:03


Treat any abstain vote as a status quo. In that way it will behave similar to the current hardcoded limit. I expect that people only would want a change in the limit in extreme situation (like now)
@_date: 2017-04-05 04:36:26
The most important thing is that we are not unnecessarily splitting UTXO. Not to mention extension block is more vulnerable to a re-org.
@_date: 2017-04-28 01:13:35


[You sure about that?]( The consensus part is bread and butter of the implementation, not performance.
@_date: 2017-04-06 16:37:30


Oh, I see... When they mentioned hardware I thought it was internal to the chip.
@_date: 2017-04-06 19:08:01


Hmm... Are they calling those "mobile processors"? I am under the impression that those term normally reserved for Qualcomm/Intel Atom.
@_date: 2017-04-04 19:21:06


Yes, but now you're making it more likely to happen on extension block because it will be empty. Once that happens people will be reluctant to run validation on extension block
1. No, Segwit is technically better. You can't achieve signatureless IBD with extension block. You also break fungibility in worse way than Segwit
2. Rather than working together towards a better solution these guys try to invalidate something that people have been working on for the last year. And no, segwit and extension block is not compatible


It's not good enough for me. I'd rather have a chain split rather than have working on a solution that is neither ready nor technically better
@_date: 2017-04-26 15:56:33
It wouldn't if you move the witness commitment into block header, something that most people would expect.
@_date: 2017-04-04 19:25:17


While being technically sound at the same time (BIP16 was somewhat an exception because no one realize its defect when they are supporting them).
@_date: 2017-04-21 12:42:47
The fact that this term is there should raise a red flag for you:


That means Charlie Lee decides that unilaterally unless you can show me that the community already agrees to that beforehand.
@_date: 2017-04-01 12:04:01
100% of tx as SegWit? What happen to all previous non-segwit UTXO? Made invalid? You're confiscating coin...
@_date: 2017-04-04 05:33:13
I am mad (not sure about him) because the proposal is out to journalist before the technical community. I myself heard this first from Samson Mow's tweet. I should have heard about this from the team firsthand.
After Sergio, this? Are we really turning into a circus? I expect better than this...
@_date: 2016-02-26 03:16:31
Maybe you should eat first and re-read the article. I am not saying what he is talking is 100% correct but he did include all the reason. I need sometime evaluate the correctness of it










Every bidirectional channel includes two users. So while every transactions between these two won't need to happen outside channel, every transaction that needs to be done with other party will need to happen inside other channel. That would require opening other channel. Opening channel will require on-chain transaction. Routing can solve this but apparently routing problem in Lightning is not yet solved.


See the part on microtransaction above.


Uh, sorry to burst this but priority is removed as of 0.12
@_date: 2017-04-06 18:54:50
Normally you use the term "processors" for general purpose one though.
@_date: 2017-04-20 18:31:05
Creating a piece of software is nearly equivalent to endorsing them. If they don't think an idea is good they are not supposed to implement them. There is probably a market for a medically assisted suicide but it is unethical for any doctors to practice that. 
@_date: 2016-09-27 18:22:51
But I wouldn't want my money back if I lost it in DAO. (I am not foolish enough to spend it there after all).
Neither do I want my USD back if Bitcoin goes to 0. 
You know why? Because doing so is making an insult to people who put their skin in the game and it is unfair to other people who actually lose their ether making mistake other way than DAO.
You seem to have trouble understanding the importance of taking accountability for your own action, which is the very foundation of cryptocurrency.
@_date: 2016-09-19 09:39:36


How they charge fee for example. Charging fee per kb has never made sense. This requires additional complexity(e.g max sigops, max block size, max transaction size to prevent quadratic hashing, SegWit charging more for tx that creates more UTXO etc.) to prevent DoS. OTOH Ethereum only has gas limit and stack depth limit (which could probably be rolled into gas limit in the future? IDK).
Using Turing complete script also makes it easier to develop compiler for. Creating compiler for Bitcoin script is not that straightforward. You could argue that using high-level language is not putting you in proper mindset for creating smart contract but I personally find it interesting to see what kind of smart-contract people creates if the barrier of entry is lowered.
@_date: 2016-09-23 16:22:30
And why is that? You want to trim as much fat as you can from your operation. If you can run mining node with pruning you should. The majority of expenses should be on mining hardware.
At this point in time unpruned node needs 97 GB. HDD costs per gigabyte chart already plateaued. 
In the future if the blocksize continue to increase there will be time when you need to upgrade drive every year or so.
@_date: 2016-09-27 03:10:08
I don't think Peter Todd has indicated any disdain for the Feds though...
@_date: 2016-09-23 16:59:27
Uh, you do realize that to create a block you need only UTXO, right? You know, something that even pruned node has?
Why would you need signature from block  or TXO that has already been spent on block 
@_date: 2017-04-21 14:54:12


If not Luke Chris Belcher already made promise to do so. Probably he will take JoinMarket with him. So did bitusher. You are underestimating the amount of support small blocker to do that. 


The fact is all big blocker attempt to fork so far has failed. So maybe you are the one who is overestimating the amount of support pro-hard fork people has.
@_date: 2017-04-26 16:36:40


Welp, that's pretty concerning. If the extension block was actually BIP141 compatible you will lose a lot of face there. That also means you will be seen as a bully who made Joseph Poon run away to mommy for nothing. Your case need to be airtight otherwise people will just use it to discredit whatever you are saying.
@_date: 2016-02-02 23:18:27




If you are a developer, and you don't follow every development in Bitcoin space you are just plain irresponsible. See also: transaction malleability and the (hopefully) upcoming hardfork.


Actually nSequence was broken before, and RBF is the fix.


No, the risk is still the same. Opt-in RBF is far more transparent option in double spending. Other options are less easily detectable


This won't happen unless wallet suddenly adds RBF feature, which would be stupid.


Wallet should handle the complexity, not the user.


No it is not worse than it already is.


Peter Todd succeed on the first try the other day. That's why he was temporarily banned from Reddit.


As far as I know no one has created GUI for RBF. It is RPC-only. So people still need a command line to do RBF. Unless wallet software started adding this feature (which they should do at precaution) everything will work the same.
Edit: I also find this interesting:


Actually Bitcoin itself is only good for few edge case.
@_date: 2016-09-19 21:49:34
Lightning wallet needs to replace SPV client as well for a starter (and later scale to at least a few billions as well if everyone is using Bitcoin) so 2500 is on the low end of the scale. It is not too shabby for early work but we will need to know how the performance scale with the number of nodes(i.e do we expect that to be O(1)?).
@_date: 2016-09-22 18:55:00
Going Vitalik's route, eh? I still would say verifying that a piece of code has not been tampered with is still easier than verifying that UTXO has not been tampered with (i.e sacrifice trustlessness).
@_date: 2017-04-26 16:33:59
Yet it lives. Chandler Guo fails to kill it.
@_date: 2016-09-10 14:27:51
I can see where you're coming from now(although we are arguing too close to semantics to my liking now).
The kind of "immutability of rules" you are talking about is the equivalent of introducing a "special transaction" in double entry accounting where for this exceptional case there can be imbalance between let's say capital and debt.
Of course you can do that but now that defeats the entire purpose of double entry book-keeping where people can just explain unbalanced balance sheet by pointing to several entries of "special transactions".
@_date: 2016-09-21 16:21:50
pssst.... I think you need to remove /edit from the link.
@_date: 2016-09-23 16:43:36
Are you appealing to the miner's moral? No it doesn't (and shouldn't) work that way. Miner is a businessman at best and attacker at worst. That is the only way to model the protocol if we want Bitcoin to survive. 
@_date: 2017-04-21 13:25:53
At least contributors who attended HK meeting make sure this part is there as a fallback:


In Litecoin's Roundtable there is no such term. That means he actually intends to lie.
@_date: 2017-04-06 19:18:01
The general purpose one? Qualcomm Snapdragon/Intel Atom? At least that was my impression. I'm not aware that the term "mobile processors" is used for DSPs/ASIPs used for network communication/voice coding.
@_date: 2016-09-27 09:28:13


OK, then. You can easily prove it to me. Ask miner to increase the gas limit. Let's see if everything is still fine.


I wouldn't call people speculating ~40m instead of donating them to hungry people in Africa innocent. They are not even responsible enough to audit the code. You don't see how destructive these people are to the ecosystem?


Sure they are. They will also probably inherit your dictatorship.
@_date: 2017-04-21 15:38:12


If you depend on falling apart as 6x increase in price sure. Or for that matter 99.9999% uptime.


Why do you blame Greg? Do you think Greg is the only one who responsible for this? Slush was against him until Segwit is ready. Jameson Lopp only thinks for himself. So did Chris Belcher, Nadav Ivgi, Alex Morcos, Johnson Lau, and Suhas Daftuar. Sure he puts himself in the front line but that doesn't mean the silent one can't think for himself.


How do you think he convinces no-hard-fork-at-all people into accepting Segwit? He was the one who foresee the trap behind HK Roundtable. Jihan "Fuck your mother if you want fuck" on the other hand...
@_date: 2016-09-27 02:54:39


It can handle peak loading. Can it handle continuous loading? If it can reducing gas limit doesn't make any sense. Neither does changing the opcode economics.


8 years of not doing micromanaging is pretty good track record I'd say. On the other hand nearly EF did everything I'd say within one year except the last one (and there is pretty good chance you will do either that or the opposite in the future).
@_date: 2016-09-26 13:13:02


Well, at that time the entire "Market Cap" of Bitcoin is less than USD 100,000 so the only way the comparison is valid is if an Ether worth 1/10,000th the current value.
Secondly in the entire 8 years of Bitcoin history AFAIK there are only 2 major disruptions (2010 overflow incident and 2013 BerkeleyDB limit) as for Ethereum I could count 5 (3 mentioned by killerstorm above, DAO hard fork, and [double-suicide consensus issue]( for a little more than 1 years.
@_date: 2016-09-28 15:41:30
Good point, it explains why Vitalik is OK with playing FED :)
@_date: 2016-09-26 17:45:28


Appealing to moral won't work. DAO attacker shouldn't steal all the Ether but he did anyway. Miner shouldn't prune their node but they will anyway, especially after they find out it is cheaper and faster, especially since it is easier to store it in SSD instead of HDD.


1. You haven't explained the memory cost.
2. Storage cost/gigabyte just hit the floor. What do you think will happen when you increase the block size genius?
And lastly that is related to UTXO commitment? How?
@_date: 2016-09-27 08:14:30


I don't think you read my comment completely.




I find unstated disclaimer is a little bit dishonest. I don't think any of these is "just fine"


You mean under reduced gas limit?


Not EF's problem. Slock.it's problem. It is pretty concerning that you don't understand the danger of blurring the line everywhere. EF shouldn't stick the their nose where they don't belong. Separation of power exists for a good reason.
We haven't even get into the fact that EF convinced exchange not to list ETC. 
@_date: 2016-09-11 01:06:48
Accounting mistake is so expensive that we shouldn't even be able to afford one. Example: Arthur Andersen, SWIFT hack (this one is also irreversible)
@_date: 2016-09-23 06:22:55
later cited by
The plateauing is recent (2010-2015). I worked in HD industry before. After r/w head improvement and perpendicular recording there's only so much we can go before we hit the ceiling. Truth is patterned media and HAMR is late and it is unknown how effective they would be and whether we can continue scaling.
@_date: 2016-09-22 17:40:13


This chart begs to differ:
We need to get ready for technology to plateau. Winter really is coming. And let's face it, pruning is not exactly free (although it does have a pretty low cost). You make it more difficult for people to bootstrap new nodes for a starter. 
@_date: 2016-02-03 14:29:05
According to wiktionary remittance is defined as payment into remote recipient:
So technically what you did can't be considered as remittance. Normally people use the term remittance as a way to transfer from one person to another in two different countries.
If you have other asset(forex, gold, etc.) on hand when you cross the border pretty much anything is better than Bitcoin.
@_date: 2016-09-27 06:34:58


He did what was within his responsibility. He didn't "instruct" neither miner nor exchanges. Miner might be gray area since they are inter-related US President can veto any legislation after all. For example gas block limit (at least in Ethereum) and cost is within miner's realm for example and developer shouldn't have any say on it but new OPCODE is entirely different matter. But exchange should totally be off-limits.




Does not compute
P.S Remember our discussion about how smart contract can be expensive one day and cheap another. Well, I've been looking around 's implementation of ring signature and guess what? He made a bunch of CALLCODE's to his ECADD. I think 
you just broke his contract. 
@_date: 2017-04-21 13:14:11
Made one in the other thread..
@_date: 2016-09-23 15:01:29


Because not all bytes are created equal. Those bytes that create UTXO is more expensive because they costs more storage. Those bytes that is part of signature doesn't need to be stored so they costs less.
Why do you think SSTORE is the highest cost operation in Ethereum?
@_date: 2017-04-01 12:38:05
And what if there is a flaw in Segwit? Or there is actually some valid use case that can only be satisfied with old txs. Now you leave people with no way back. 
@_date: 2017-04-21 13:49:14
I'm just saying if Segwit is not activated that this proposal won't be activated without causing two chains as well.
@_date: 2017-04-01 12:13:33
But you will still need to support old transaction so from code perspective there is not much difference. If Segwit offers enough benefits (which it is) people will transition voluntarily.
No one should be coerced to do something they don't want.
@_date: 2017-04-20 18:26:11








@_date: 2016-09-25 04:45:20


Layer 2 is not an option and right now Bitcoin still leads the way in Layer 2 Development. 
Let the industry find solution elsewhere. They will come to the same conclusion in the future.


You do understand that SegWit is a response to a block size increase request right? My impression is that Core Dev would prefer to work on project that improve on fungibility/scalability rather than throughput, like Schnorr or UTXO commitment. Prioritization on SegWit is a major compromise from their side.


Yeah? Like what? Do you consider LinkedIn, Yahoo, Ashley Madison, Target, Home Depot bug free? Because the recent hack shows that they're not. These are centralized system, so a bug is more forgivable. In decentralized system like Bitcoin once there is a bug the consequences are catastrophic. Ethereum just learned this the hard way.


If you think that changing block size is a "relatively small enhancement" you couldn't be more wrong Mr. Project Manager. The Unlimited-Classic fork in testnet is the proof. Luckily someone actually made the attack in testnet. Now Classic quietly remove the safety feature just because Unlimited is gaining market share. I can't wait until someone run a quadratic hashing attack against them.
@_date: 2018-03-20 17:17:21
Because anonymity, like transaction throughput, is often times at odds with decentralization due to higher resource usage. UTXO growth is bad enough as it is. With Monero-style ring signature we need to keep TXO on top of UTXO. Better anonymity means nothing if the state actor can enforce a whitelist.
@_date: 2016-09-10 11:52:33
Actually not sure where refers to Ethereum but meh.


This is true for Frontier-&gt;Homestead.


This is true for hard fork DAO.


Actually I consider it as two separate operations. Reverse the theft, but since by reversing the theft you still enable someone else to steal it move it to WithdrawDAO. So two separate operations (1)Erase the Theft and (2)Move to WithdrawDAO.
@_date: 2016-09-24 04:18:42
Uh, you know UTXO commitment is not mining with pruned node, right? It is just something to eliminate the need for archival node.
@_date: 2016-09-26 17:52:23


Is that before or after you cut gas limit to one third its original limit? I still wonder at which point people will start to admit that Ethereum Foundation is the new Federal Reserve?
* Ethereum Foundation thinks miner should increase their gas costs
* Ethereum Foundation thinks miner should cut gas limit
* Ethereum Foundation thinks exchanges should stop trading
* Ethereum Foundation thinks [gas costs for the following opcode should be raised](
* Ethereum Foundation decides present situation demands bailout
* Ethereum Foundation decides the current block subsidy is not enough to support the system


Luckily we didn't listen to you when you said 10MB block is safe:
@_date: 2016-09-24 04:16:33
It is easier to made up your own false input than an actual input from block  Doesn't make a single difference.
@_date: 2016-09-26 12:47:00
Like I said Mining on pruned node doesn't depend on UTXO commitment so UTXO commitment had nothing to do with our discussion. Why do you insist on changing the topic?
@_date: 2017-09-17 01:16:56
And British and Roman Empire used to rule the world too. I don't see your point
@_date: 2016-09-27 03:02:38


DAO HF is not technically motivated.


You'd think it is easy to say no to EF? Maker's Rune and Nikolai disagrees with the bailout fork and yet they decided to stay with ETH.
I think strive is necessary, has evolved into cesspool but the concern they originally raised is valid. From my POV it seems almost like EF is trying to cull everyone who disagrees with them (and successful for the most part too seeing that everyone follows what they said like a sheep).
@_date: 2016-09-14 05:21:31


You're not having the whole picture. Miner needs to compete against each other. For this to happen blocks need to be transferred near instantaneously. If we need the entire 10 minutes required to discover the block just to move the block between miner the original miner has a significant advantage over the other. (If this were done intentionally it is called block witholding attack but in this situation the effect is unintentional). Current safe range for blocksize to increase is from 2MB-8MB depending on whom you quote from but it is nowhere near 375MB/block
Tech like compact block or xthin can reduce the number of data to be transferred when block is found but we still need to evaluate their effectiveness.
@_date: 2016-09-22 19:02:37
Sounds bad? Wait until you hear about Bomb 2.0 AKA Vote-a-fork-regularly
@_date: 2017-04-01 12:52:24
People who wishes to spend to Segwit outputs do so willingly. There's no coercion nor confiscation.
@_date: 2016-09-24 05:26:38


5 years break in something that follows the curve so closely for 30 years not a trend? LOL.


Yes, every technology will follow exponential curves indefinitely, just like flight airspeed record:
You know what else is fine until it isn't? Housing market. 


Moore's law doesn't apply to HDD if you didn't notice. And secondly transition from 2D to 3D is as complicated as transition from subsonic to supersonic. Try plotting the airspeed record in log chart. You will see something like this:
Notice the lull between 1940 and 1960? Yes, that's where we are. We probably could get 2x/3x in 20 years if we are lucky. You heard the news that Intel kept on postponing their 11nm node? 
You know what is the historical equivalent for this? Transition from vaccuum tube to field effect transistor. You know what year transistor was invented? 1920s. Source:
What year did Moore's Law started? 1980s. 60 Years from R&amp;D to real world technology.
@_date: 2016-09-19 22:29:51


I don't think this represents OP. He did mention this after all:


Sure would be nice if it is O(1) scaling though.
@_date: 2016-09-23 16:02:09
You mean miner doesn't want to prune their node? And why is that? Last I heard there is no free HDD for miner-only promotion.
Not to mention to keep things efficient it is more convenient to store UTXO in memory. Is memory free for miner-only these days?
@_date: 2017-09-17 01:44:12
Gold survives the fall of Holy Roman Empire. Their currency didn't.
@_date: 2017-09-28 11:57:19


Since when does the burden of replay protection falls on status quo chain? Forked Ethereum implemented them, so did BCH. The only reason BTC1 refused to implement replay protection is because there is not enough support.
@_date: 2017-09-28 11:54:26
Because there are similarity. The reason why gold survive and ducati didn't will be the same reason Bitcoin survive and USD won't. And if you don't notice MBS is nowhere near "antiquity" 
@_date: 2016-09-19 13:07:13
Eh, there is actually a reason why some OPCODE is disabled in Bitcoin:


Also TBF the current reason for Geth node crashing had nothing to do with it having Turing complete script but rather a memory leak in one specific implementation
@_date: 2017-09-09 18:33:40
That is in no way binding. No one was "signaling" for BCH before it suddenly has ~40% of Bitcoin's hashrate. That has to come from somewhere. Some pools like Slush and F2Pool ran BIP91 exclusive code (and most likely has already started some evaluation to switch back to 0.15/0.14 after it was ensured those compatible with each others). No one in their right mind would actually continue to run code filled with bit-rot. 
Segwit doesn't stand alone, it requires things like Lightning/MAST/Signature Aggregation to take full advantage of it and none of the people who knew how to implement them stand with NYA. At this stage Segwit 2x is practically a chain without Segwit. Even BCH is more competitive than Segwit2x.
@_date: 2017-09-17 00:59:10


Mortgage Backed Security used to be considered AAA, until it isn't
@_date: 2017-09-28 12:01:29


No there aren't. Forked Ethereum implement them, they have no objection because unlike btc1 they have enough support to confidently do so. The only reason there is no replay protection is because they intend to coerce everyone to follow their chain.
@_date: 2017-09-28 14:41:48


Ethereum Classic was the "weaker" chain and yet Ethereum was the one who implemented the replay protection.


If 2x chain actually had enough support they won't resort to coercion and fraud. Not to mention that Ethereum Classic doesn't die. In terms of support 1X &gt; BIP148 &gt; Ethereum Classic. And both BIP148 and Ethereum Classic prevails.
@_date: 2015-09-06 16:19:45
I would say both the fed and private bank prints money. The fed prints the 'base' money supply and the bank prints money  in the form of depositor IOU(albeit in more limited fashion since they do have to keep the reserves amount).
@_date: 2015-09-06 09:11:22
Well, for all intents and purpose the money that the car maker takes do come from thin air. It is just being printed into existence. It doesn't come from 'real' economy (for example, manufacturing/agriculture/mining where there is value being produced).
@_date: 2015-09-22 01:20:58
Actually it is a little bit more nuanced than that. The thing is at the test chain's stress test they put targeting part of Bitcoin's equivalent of blocksize limit (gas limit) at a really large number (miner vote on valid gas limit, I think they are hitting somewhere around 20-25 tx/s at some part of the test). Most miner doesn't bother to set soft size limit, much less attempt to target lower gas limit, because it is a stress test after all (and the fact that codebase is in Go probably doesn't help). So as an end result there is a centralization seen. All in all, I believe that it is a good experiment, just to see how much centralization one can observe by changing the block size.
@_date: 2015-09-22 07:00:47


Personally I believe that there is a sweet spot where the uncle reward is low enough that most people will prefer to remain on the main chain instead of aiming for the uncle and yet still give enough incentive to secure the chain. It remains to be seen if Ethereum has already reached this sweet spot


Selfish mining is always profitable, even in Bitcoin yet you don't see anyone do that. Perhaps we pay too much attention to that? Most miners are honest/lazy. Even now I wonder what will the Core Devs do if some miner actually attempt selfish mining.


There is economic incentive since people are getting rewarded for mining blocks, there is also special reward most blocks mined.


That paper doesn't rebuke my observation. Fact is Bitcoin is more decentralized when CPU mining was still a thing. On the other hand let attempt to rebuke that paper. 


The point is moot. A good PoW should be the one that is close to thermodynamic limit when it is mined using tools most commonly available to men. If there is a PoW that can be mined using dirt at thermodynamic limit then it is an ideal PoW.
Just to give an illustration, let's say someone attempt to 51% the network where CPU mining is still competitive. In this case every Bitcoin user can rally to defend the network using their laptop, PCs, etc (even though normally they don't mine). This is not the case in the current ASIC situation.


Actually the paper provides counter argument to that in [9]


Which is what partly inspires Ethereum's PoW


PoW doesn't have to be totally ASIC-resistant. It just has to limit the advantage ASIC has over off-the-shelf hardware. If ASIC is just ~5x more efficient than let's say GPU, GPU mining is still pretty competitive because of its accessibility and miner might have advantage in other area, like electricity. Besides that someone can easily do non-competitive mining.


At GB size memory, DRAM is the most cost effective solution, and it is a commodity, meaning it is available to everyone. Litecoin's scrypt failed because it is meant to make CPU-mining competitive by designing the PoW such that it runs in CPU cache, which is fine and dandy until someone design an ASIC with lots of SRAM in it.


See the 'dormant defense that can come online' anytime above.
@_date: 2015-09-02 11:03:37
C'mon Mike. Just give them a chance. There are two parts to the workshops. Maybe the debate/decision will be made at the second one? The letter does give a sense of urgency in resolving the blocksize limit. I'd prefer that no one has a bad blood once this is over.
@_date: 2015-09-06 00:12:03
I think there's an easier way to get there. Now there is double-count that happens. Let's say received the loan of $100 and give it to the person he buys the car from. Note that this money comes from the depositor. The question is who owns $100? The depositor or the 'car person'? 
The worse part is yet to come. This car person might actually store the amount in the bank again which is then used again to lend people money and more double count happens.
Assuming minimum proof of reserves of 10% and bank actually used all of them up, with original $100 in deposit you could end up with 100+90+81+72.9+... = ~10x of the original amount circulating
@_date: 2015-09-06 00:32:56
I just see no point in speculating over a person's original intention. Attack the idea, not the person.
@_date: 2015-09-02 00:06:11
Sure, just get Greg/Sipa/Wladimir/Adam/etc. to agree on it and we are good to go.
@_date: 2015-04-08 12:10:25
Actually modern fab can recoup the initial cost within 3 years. Whatever comes after that most likely will be sold with very low margin (remember you still need to pay for gases, high purity Silicon, electricity, service contract for equipment, ultra purified water, etc.). 
Source: Worked in a fab
@_date: 2015-09-01 23:40:55


In the meanwhile people will keep losing money because there is no easy way to do multisig. What if there is no good solution that can be found within 1 year? 10 years? Are we going to keep on searching?
@_date: 2015-09-02 01:53:58
Debate has been going on since at least 2013 for the record
@_date: 2016-10-27 04:33:28
Just because you repeat it enough times it doesn't make it true. If you own &gt;20% of hashpower you **actually** benefit from witholding blocks.
@_date: 2015-09-22 03:40:03


It is actually achievable with GHOST. The testnet demonstrate somewhere around 10-15 tx/s without centralization risk. They could probably end up getting more after the block time is being relaxed now.


I don't see this as a bad thing. Bitcoin is more decentralized back in the days when CPU mining was still a thing (GPU/FPGA/ASIC has not come about)
@_date: 2015-09-06 00:53:29




Perhaps not an intention but definitely speculation
Edit: I take that back


@_date: 2016-10-25 08:41:26




Actually your source agrees with mine that a slowdown is happening:
 (see all the x)


Actually it is in the best of interest of big miner to do this as this is one kind of selfish mining. Remember if you control a higher amount of hashpower (~20%) it is more likely that you will find the next block before your competitor (whose block will also need to travel)so it is better if you can arrange it such that your competitor doesn't get your block too soon.


Their solution is to depend on someone mining another block to save their bacon. Which is pretty stupid since you can actually cleverly create a block that won't get orphaned and still take a large amount of time to verify.
@_date: 2016-10-13 02:27:57
OR we can remove block size limit entirely and replace it with something more sane. But this is a very delicate decision to make and it won't happen overnight. Ethereum made a mistake and they need to redo some part of the calculation now (and having limited throughput in the meanwhile)
@_date: 2016-10-24 13:10:29


Then explain why Ethereum lower their block size when they are under attack? That's because it is more expensive to attack when the block size is low. Your hypothesis has a real world counterexample.


Which unlimited has none. SegWit fixes that without crippling the transaction.


Again, Ethereum proves otherwise.
@_date: 2016-10-12 13:54:35


Precisely. There is a separate limit for a signature just because that it is safer to expand on that side.
Classic's approach on this issue is to limit the number of bytes/transaction but I think this approach less preferable than that of SegWit because like I said not all bytes are created equal.


No problem. I am just hoping I can bring back unity.
@_date: 2016-10-14 14:05:45
My guess is that if majority hashpower moved to hardfork Core wouldn't be comfortable with staying on the same hash algo.


Yeah, pretty much justified too. This kind of change will achieve immediate consensus.


I found it pretty sad that you have to explicitly state this just to avoid hostility. I wished we are at a better time
@_date: 2016-10-14 14:33:13


Which actually fits Terbium really well.
Boring Grey in color
Malleable so that it can be cut with a knife
Not a good conductor in electricity resistivity (1.15x10^-6 m), compare that to materials commonly used in electronics copper (1.6810^8 m), Tin (1.0910^7 m), Lead (2.2010^7 m), Tungsten (5.610^8 m)
In fact citation in Wikipedia that specify its uses only exists after 2000.
The problem is I have never heard of Terbium, which makes me wonder what is Satoshi's original profession? Chemist? Physicist? Or just a hobbyist? I don't think metallurgist would be familiar with material not commonly used.
@_date: 2015-09-01 19:06:46
is not inside? Is he really burning the bridges? Or is that because he is 'conveniently' forgotten? Either way this doesn't bode well for reaching consensus...
@_date: 2015-09-09 08:29:37


Actually I have read [Rusty's series of summary on Lightning Network]( and I **do** feel that it is complicated, perhaps because I'm not that smart. It really feels like something that is hacked together to make something works in what Bitcoin is not designed to do. The explanation sounds like, OK, so we want to do A so we do B, but it doesn't cover use case C so we do D, We also have to cover for edge case E so we do F, etc. At the end of the day I was left wondering whether it will really work. The other time I feel the same way is when I read [Vitalik's Slasher Ghost](
In contrast it seems like Bitcoin, Cryptonote's whitepaper, and [your CT]( is more straight forward. We want to achieve A so we do B, and you do get the general feel of how it works. 
@_date: 2015-09-22 01:49:45
Actually they did tinker with non-outsourceable puzzle for a while. But because of Vitalik's affinity with Proof of Stake most of the idea is getting discarded. Vitalik himself said that PoW is just a placeholder until PoS is in place, and if he were to start over he would just use SHA3 as a PoW. Which is quite sad since I'm leaning towards PoW myself.
Personally I think most of the miner in the pool never tried doing solo mining because from my experience it is actually far more profitable to solo mine.
(other user with similar experience)
@_date: 2016-10-01 13:39:55
I don't think you are reading my assumption correctly. 
Let's say when ETH vs ETC fork ETH is actually under PoS.
Now staker can mine ETH while at the same time destroying ETC.


Yes, this is my case. Under PoW ETC can still survive without any HF. With PoS you are lowering the requirement for hard fork (quite significantly too I would say).
Edit: HF is also required under long range attack.
@_date: 2015-09-01 20:20:43
I am not against replace by fee (at least the safe version). But using replace-by-fee as a way to get around block size limit that is nearly 100% full all the time is not a good idea.
@_date: 2015-09-01 23:57:27


Hindsight is 20/20. Back then can you guarantee that waiting a few months will give a better alternative? Or are you going to suggest to wait for a year?


No problem with that, just make sure you guys **actually** come up with something this time.
@_date: 2016-10-13 00:37:30


You want to make a choice? Just design a Bitcoin fork with # of inputs=0 invalid. There, now you can choose between SegWit soft fork and your own soft fork.
Alternatively Bitcoin Unlimited can make 2MB block, then all can choose themselves what to support.


I have yet to hear an argument why hard fork is a proper solution.


You forgot that deploying soft fork is much faster than deploying hard fork.




So you disagree with that? Then it's okay. Apparently we don't have consensus. We will just stick with 1MB limit for the time being. You are crazy if you think just by blocking the soft fork you can force other miner to suddenly make 2MB block. 
@_date: 2015-09-01 19:19:11
Replace by fee is a pretty ugly solution. You will need to resend the tx every time it is not getting confirmed. It is a nightmare for usability. 
IMO Ideally block should be ~70-80% on average (hitting 100% only during peak). We can have fee market working at that utilization with tx with higher fee getting confirmed faster (within 1 block vs within 3 blocks).
@_date: 2016-10-12 14:58:29


On the contrary it would be more difficult. We should expect the protocol to ossify as time goes by. As adoption grows, so does the difficulty of coordinating a fork (so does the risk of doing so).


Based on the whitepaper?
Actually several PoC is around:
Lightning actually depends on SegWit, not the other way around. So you need to have SegWit before you have Lightning. (well actually you can have Lightning without SegWit only that it is more annoying to develop).
@_date: 2016-10-22 11:18:57


That's why all Lightning participant need to open more than one channel so that everyone can ensure that you can always find path between each other
@_date: 2016-10-11 17:23:04


Unlike P2SH, major wallet developer has pledged to support SegWit from the get-go:
Let's face it if adoption is slow, that would be because no extra capacity is needed.
If you want to hard-fork you might as well do major reform like block weightage or remove fee/kb (which is one of the reason others are reluctant to increase block size) and replace it with something more sane.
@_date: 2016-10-12 14:19:09


Since 2010, so for the most of its lifetime. Prior to that, no one has even tried to attack Bitcoin


That's Ethereum's attitude, see where they are now.
@_date: 2016-10-03 11:05:06
Who's lazy now? I gave you a link already and you didn't even bother to click it.
@_date: 2016-10-25 22:02:48


It is a very important to transition to this model (please also read about why block size is important if we want to go to 0 inflation if you have time)


Enough to solve the issue in near term while better solution is being developed. No one says that segwit will be the end. There will still be hard fork and lightning.
@_date: 2016-10-03 13:34:11


Doesn't mean jack shit here. We are all judged by the merit of our opinion, not by who we are. That's the point of cypherpunk


I've seen people challenged you to disclose what project you are talking about to compare the scale and you never took it. Makes me really wonder how true the statement is.


You do realize that most SegWit effort is done by Johnson Lau, Suhas Daftuar, and sipa right? GMax is responsible for reviewing afaict. And that means pondering a lot. Sometime a security issue that was never seen before pop up just like that.


Well too bad, we just don't have the technology yet.
@_date: 2016-10-31 08:46:57
Let me remind you that a substantial portion of the community supports SegWit, including [Andreas Antonopoulos]( [Erik Voorhees]( and [various wallet]( has supported SegWit. And all the Lightning Development so far has been done on SegWit. [This is the same SegWit that Unlimited refuse to merge previously]( So by activating Bitcoin Unlimited I can consider that you have acted against the community.
This is not to mention the fact that [block size limit is crucial by the time that block reward goes to 0]( That means there is no guarantee that you will be able to keep the 21m Bitcoin limit promise.
Also changing PoW is not the only solution we can also adjust the difficulty manually (although I'm not too sure which would be the more preferable solution seeing that if we change PoW you have two hostile miners, BTCC and BitFury on your side, we will see if Unlimited's claim that "quadratic hashing is not an issue" really holds well).
@_date: 2016-10-12 14:16:07
Other voluntary updates doesn't have full support from the wallet from the get-go:
Hard fork is also a voluntary update you know? So 2 years until everyone update?
@_date: 2015-09-01 23:52:06


To provide better user experience? (edit: I'm assuming BIP100 scenario where miner actually controls the blocksize)


I meant from design level of perspective, within 5-10 years PayPal level of tps is reasonable.
@_date: 2016-10-03 11:35:31


I didn't say that. I say in 2010 discussion Satoshi reject the idea of raising block size. If you actually bother to click the link you will see this:






I mean come on man. A simple ctrl+f...
@_date: 2016-10-28 21:21:49
See my comment history :)
@_date: 2015-09-02 12:27:51
Can you stop the personal attack? I don't see what you're trying to achieve by smearing his name.
@_date: 2016-10-23 14:50:24
I agree with you if you're talking about SegWit
@_date: 2015-09-02 12:26:33
That only speaks for the one at Montreal right? Doesn't say anything about the one in Hong Kong
@_date: 2016-10-12 13:08:24
That is not a concern as long as the node is still running. The attacker still lose money after all.
What is a concern is when the attacker manages to bring down a node so that he practically doesn't lose money (or lose relatively low amount of money). See again why Ethereum needs to lower their block size limit
@_date: 2016-10-01 13:09:57
Let's do this again. Imagine a case of ETH vs ETC fork where there is a fork due to ideological cause. What prevents staker from colluding to destroy ETC? Remember they do have economic incentive in this case (network effect)
@_date: 2016-10-13 00:07:26
We don't have neither SegWit nor block weightage 2+ years ago.
OTOH SegWit can be deployed right after it was released. So that is the best choice we have right now.
@_date: 2016-10-24 13:36:15


Vulnerability is the same no matter what the mechanism is. Lower block size=more expensive to conduct. 


What do you think will happen to the transaction fee when block size goes up? It goes **down**. And attacker can still fill it with lower fee.


No, it is by **design**, not a side effect. The reason the increase is so small is because by increasing non-signature part of the transaction you are increasing attacker's space on most vulnerable part of the transaction (input and output)
@_date: 2016-10-23 09:14:16
OR, the market reacts to the release of 0.13.1 RC2. See? Two can play the game.
@_date: 2016-10-27 04:48:13


For 1/3rd original capacity for a month, 1/8th original capacity for 3 days and even now it is still less than one-half its original capacity with people complaining their node unable to sync. Not to mention miners refusing to put tx into the block. Well, I guess I know what your "everything is fine standards now". No wonder you disagree with my grave assessment.


Yes, and what is the expected 3-4 blocks reorg probability under Unlimited? And what assumption do you make?


Are you conflating RBF with doing RBF because of full block? Because those two are separate concepts


And RBF tx is explicitly labeled it is RBF.


So that means you are OK with RBF? Because by extension 0-conf is no longer secure either.
Besides, 3-4 conf? How much node setting fragmentation do you assume? I'd like to see a real study on that.


Yeah? explain to me then.
@_date: 2016-10-13 06:26:07
You remember the whitepaper? So long as the 51% is honest. That is the lowest threshold of Bitcoin working. Not an ideal which we want to achieve. An ideal we want to achieve is 100% hash power.
What happens if 10% of the miner wants to block donation to wikileaks? That's an attack.
Explain to me how Bitcoin works. Go ahead.
@_date: 2016-10-13 00:06:25
If you think block size debate is that simple you are way out of your depth.
@_date: 2016-10-20 08:51:20
Well, perhaps the limit adjustment can be targeted on SegWit only? Just leave the old transaction be. The agreement only says non-witness increase. It doesn't say whether or not the increase applies everywhere.
@_date: 2016-10-23 15:01:02


That 4MB is also available to the attacker. And as can be seen from Ethereum, they might use it more "efficiently" to weigh down the network.
@_date: 2016-10-17 22:57:48


Huh, interesting. Are you sure the math is right? Because that means even without block reward Bitcoin already can beat SWIFT. 
@_date: 2016-10-16 14:33:04


Or we manually adjust the difficulty. If there is a will there is a way. Testnet chain for example allows block created at min difficulty if there is no block for a certain amount of time. I think people severely underestimate the fact that Core still has monopoly on the talent.
@_date: 2016-10-13 22:35:27


How is that different? People are free to change them without any discussion.


That's what causing lost revenue and network instability. You can game 1 conf or even 2 conf during this period. And their "assumptions" of "converging rapidly" has been proven wrong by ETH/ETC fork and even the current 10% holding down the soft fork. It will not converge rapidly. It will cause a fork.
@_date: 2016-10-18 12:05:09
While blocksize initially looks like DoS limit for bandwidth it also actually serves as DoS limit like other things like storage (UTXO) and processing (quadratic hash) so if we increase that limit we also need to put a substitute for storage DoS limit and processing DoS limit. 
And the DoS limit for these two doesn't scale linearly with blocksize limit. 
@_date: 2016-10-12 15:48:13
It's a better form of governance. Just like jury's decision need to be unanimous to achieve anything meaningful.
Sure anyone can disrupt the plan but they are damaging themselves as well.
@_date: 2016-10-28 22:25:07


It **does**. To introduce transaction version 2 that address all the shortcomings of version 1 so that you can scale you will first need to move all the coins from version 1 to version 2. That means 100% of the community needs to break out their cold wallet and transfer it to a new one.


See above.


He did, here:


@_date: 2016-10-23 21:27:57


Congestion is not an attack. Full node running out of memory/ crashing because of high processing/high I/O is an attack


1. The transaction fee is no longer 0.001btc if you make the blocks 4x bigger. 
2. Ethereum's situation shows that lower block size favors the honest person more than an attacker


One need only to study Ethereum's case study to shows that evidence point the other direction
@_date: 2016-10-11 16:49:48


Well, the other option (hard fork) is everyone left them and they are left vulnerable to someone doing sybil and rent a hashpower to fake a 6-conf. I'd rather rely on herd immunity than the pack leaving the wounded alone.
As for being second class, well they can capitalize if actually manage to pull it of so it is a fair deal.
@_date: 2016-10-24 14:31:36


And the attacker can pay a little bit more too (hint: it is still cheaper than when the block is full)
And what if the attacker creates a block that crashes a full node? When you are using pure block size limit this is actually possible. Ethereum economy is practically crippled.


Attacker lose money doing this. He won't be able to sustain it. That's why all the time attacker did this to Bitcoin in the past he always stopped (and never tried again for nearly half a year). Ethereum's attacker OTOH is still going at it today.


Like I said Ethereum provides counterexample to this. If the block is not full there is not enough demand to compete with the attacker.
@_date: 2016-10-23 14:43:43


I don't think that's true. Remember the reason people can't say anything about money supply is because they don't have any say over it. Take away people's ability to run full node and you take away their power.
@_date: 2016-10-12 06:56:19
FT is just SegWit copy cat without all the benefit. Seriously if you want to hard fork you can have more options so you definitely can do better than that.
@_date: 2016-10-12 13:11:24
So it is only a single case right? An anecdote? And you don't believe me? You need to study why Ethereum needs to lower down their block size limit. Because block size limit is pretty shitty as a DoS prevention. Sure we will need to HF in the end but first we how to replace the block size limit.
@_date: 2016-10-22 16:19:23


Basically what it does is when a full node sees a block at height n it can force whatever transaction it made to be mined only at block n+1 so that miner have an incentive not to orphan block n (because otherwise they can't include that transaction).
@_date: 2016-10-13 01:00:00
I just don't think people understand what Bitcoin Unlimited proposition is. They intend to change consensus rule on-the-fly and claiming it will just work. Which is fucking insane. ETH/ETC fork prove that it won't work, Bitcoin's block size debate prove that it won't work. There will be a split. 100% guarantee.
On top of that there will be a network instability and lost revenue. I don't understand how anyone could support that kind of chaos.
@_date: 2016-10-25 08:28:58


Yes but the fee is very low if the block is not full.


But it **is**. The higher the block size the easier it is to play with the parameter to crash the node. For example the higher the block size the more processing power you need, the more memory you need, etc.


Bitcoin prices has continuously increased alongside the fee. The thing is there is demand for non-censorable asset transfer and judging from the people's willingness to pay it is still too cheap. 


That's where you went wrong. It **will not**. Because if the block size goes down the fee also goes down (unfortunately same thing applies to regular customer and attacker). Here, let me show you some figure. In 2013 the block size was capped at 250kb. Mike Hearn asks miner to increase the blocksize:
What happens to cost per kb?
It takes time to adjust but in the end it settles around 1/4th of its original value.
At the end of the day it will still cost $1M to attack the network even at most optimistic assumption. You need to note that attacker will create more harmful transaction than a regular user. If the attacker is a miner he won't even need to pay.
And attacker's purpose would not be to increase cost (that attack is not sustainable) but it is to make a node dysfunctional so that the economy is crippled.


Like I said you assume that the fee will remain the same as the blocksize increase, which is untrue because at that time the supply will exceed the demand and the price will drop.
@_date: 2016-10-16 09:02:53


At current block size the damage is limited


SegWit increase the capacity without worrying about consequences of the vulnerability. Classic provide a fix by crippling the transaction. Unlimited doesn't even provide a fix. 
@_date: 2016-10-17 22:54:24


Hub has an incentive to keep themselves small, because there is a risk that they get their fund stolen


Actually wallet will run the wallet p2p-style, with peer discovery and stuff so they don't need to run their own hub.


Actually this already happens. The difference is Bitfinex-like hack will no longer happens because every user can secure their own fund.
@_date: 2015-09-01 23:31:41


No disagreement over there. 


This is where I disagree. Like I said above we should aim for 70-80% utilization to keep network being reliable (not dropping txs needlessly). 


In the near term we should not aim for thousands of tps. For example PayPal level of transaction is definitely achievable within ~5-10 years. I would say that is quite an achievement for decentralized network to compete to a centralized solution.


Personally I am satisfied if let's say Bitcoin manage to achieve PayPal level of transaction. Just keep the blocksize nowhere near full. Even PayPal/Visa has different treatment on peak/normal capacity.
@_date: 2016-10-12 13:51:24
If you ignore an actual risk you will need to step backward after stepping forward. And this will actually take a longer time Just like Ethereum (gas limit-&gt;3,000,000-&gt;4,500,000-&gt;1,500,000)
@_date: 2016-10-12 13:57:59
I still don't know how do you get 2 years figure anyway.
@_date: 2016-10-25 11:09:28
Happy cake day! You will probably get bigger pay though as you have more credibility as small blocker. How I envy you...
@_date: 2016-10-27 10:17:58
I'd really wish you stopped doing that H2O2 crap though. It doesn't help anyone understanding anything.
@_date: 2016-10-24 09:13:58
If [this slide]( manages to convince Chinese miner that bigger block size equals bigger revenue I would have lost faith in humanity.
Case in point:
See that drop in 2013? You know what is the cause?
@_date: 2016-10-15 05:06:14


Similarly miner can refuse to converge just by insisting on orphaning each other's block.


No, that's not what I'm claiming. What I'm claiming is orphan rate will go up because miner refuse to update their setting to follow whatever the network majority prefers (which can be easily gamed with Sybil anyway). That's not an if, that's a certainty. This will result in higher number of 1 conf getting reversed. People can game 0-conf already. By timing the tx or cleverly splitting the network people can game 1 conf now.
Edit: Here's another scenario. Someone tricks miner by running Sybil on the network to raise block size. Miner follow (they're stupid anyway, they're the blue collar worker of the network). Then someone crafted an attack block that only miner can process (they have better hardware after all). In the meanwhile all the customers (full node) are brought down. Now there's no demand on the market. This is what happen in Ethereum BTW
Now what do you think happen when miner is trying to bring the block size back down? Yes, they will orphan each other's block in the process (because they can't upgrade at the same time) because the consensus doesn't state how to coordinate the process.
I mean seriously if you are going to decide whether to orphan other miner's block there are probably other parameters more appropriate than block size, especially after xthin. Block size only consider bandwidth and doesn't consider processing and I/O cost after all. I mean seriously?
Edit: Here's another attack. I'm an evil miner. Most of the capacity is running at 1MB. With some running at 2MB and 4 MB. What happen when I created 2MB block? There will be a fork. And if the person I'm double spending happen to accept 2MB, what will happen. Now I can game 1-conf (perhaps 2 conf with luck). I mean this method is just full of hole.
This is just something I can think of in half an hour. It is probably a swiss cheese.
@_date: 2016-10-23 14:48:39


We are one year+ into the debate and we can already see how both sides won't change roadmaps.
I can assure you. If you force a fork there will be a split.


@_date: 2016-10-12 16:19:28
Common sense. How else are you going to implement the weight?
Vitalik seems to be agree:
@_date: 2016-10-01 23:25:14


Ethereum seems to be using  but I'm starting to question all their design decision. (although for our current purpose seems like this will be a perfect match)
@_date: 2016-10-27 09:53:25
Eh, that's levelDB related, no? I don't think it is related.
@_date: 2016-10-13 06:28:35


Not a lot. The only difference is where to put the witness root. That's it. The disadvantage of FT severely outweighs its advantage


Which part is complex? How is the part that affects Segwit doesn't affect FT? How is FT going to take care of quadratic hashing? 
@_date: 2016-10-24 11:04:32


Why do you think it is called "attack" (either 70% or 30% depend on who you considered a good guy)? Because it is not legit. Let's say there are two bakers in town competing with each other. Townfolks are happy. Suddenly one baker seeing potential profit kill the other baker. Is this something you want to happen? Baker should compete on the quality of their bread and nothing else.


@_date: 2016-10-12 13:38:44


Good enough. Bitcoin capacity requirement historically doubles every year. So we have enough capacity for a year. Enough time to assess where we want to go in the future (block weightage?)
@_date: 2016-10-13 08:43:40
Not from China though :)
@_date: 2017-05-17 23:04:31
@_date: 2016-10-16 01:18:53
When Core devs are not coming into consensus: They are too perfectionist.
When Core devs actually coming into consensus: It is an ugly hack. 
Which one are they?
@_date: 2016-10-20 00:15:42
Unlimited flags for BIP109 while they actually haven't implemented the sigop limit. Roger Ver tests his mining pool in testnet using Unlimited. Since they get 75% hash rate in testnet BIP109 is triggered. Someone makes a tx that breach the sigop limit in testnet and since Unlimited doesn't implement the limit they actually mine it. Classic node refuse the block so they are getting forked. Now since Unlimited is gaining traction Classic removes the limit as well to prevent being forked. And that folks, is why in general you never mix politics in technical discussion.
@_date: 2017-05-22 12:00:22


Uh, yes it is. Further capacity increase will only be done via responsible manner such as signature aggregation/batch aggregation/block weight adjustment, less technical debt than 2MB increase.


It's only anyone-can-spend for the non-UASF node, which will be re-orged if UASF chain is longer. 
@_date: 2016-10-03 13:28:46


I never claimed I did.
@_date: 2016-10-10 15:53:54
Actually the real danger is the network instability. Since miners are free to orphan each other's work some 1-conf or even 2-conf would be reversed. This means lost revenue for the miner. We have seen 0-conf being gamed. With this scenario it is possible to game 1-conf and 2-conf. 
Unlimited claims that miner will quickly converge to reach consensus but as can be seen with ETH/ETC fork this is not truly the case. Even if it is there will be lost revenue and instability.
@_date: 2016-10-12 15:03:04


Because blocksize limit is pretty shitty DoS prevention limit. If we are going to hard fork we are going to replace it, and not increase it:


@_date: 2016-10-24 11:52:29
By the time 2016 block passes there will be 100%
@_date: 2016-10-25 08:50:14


Actually fast internet speed doesn't even come into play. You need to remember where does miner transfer their block? Directly to another miner? No. You transfer it to a "peer", another full node, which then transfer it to another full node, etc. until it reaches another miner. So the bottleneck would be the full nodes, not the miner. Miner only affects the first hop.
And like what you said it is beneficial for big miner to keep their blocks a secret from their competitor (selfish mining)


Actually large liquidity also paints bigger bullseye on your back. So there is an actual incentive to keep things small.


If everything goes well running a channel will be like running a Bitcoin node. It will be very difficult to regulate. I mean what are you going to do? Ban the software?
Potential KYC, like always, only happen on fiat bridge.


The analogy is checking account and savings account. You put whatever you are going to spend on your checking account and whatever you are going to keep for a long time on your savings account.


I'm just offering counterargument up there, of course there will be potential issue in the future. But this is something we need to undertake to preserve 21m coins limit.
@_date: 2016-10-27 05:52:06


It's escalating because there is demand. We only need to worry the day it starts to stagnate.


Which is why there is SegWit. But the fact is this is something that we need to live with one day and we already can see which wallets caught with their pants down. Without this do you think wallets will bother to implement smart fee rather than say altcoin support?


No but without the innovation in place we can't increase capacity. That's like putting the cart before the horse.


Well, there is that and uncontrolled capacity increase without proper precaution will result in what happen to Ethereum. Block size limit actually serves as DoS prevention for a lot of things at once. And many of them are not linear. Say quadratic hashing, by increasing block size by 2 you will increase processing by 4 times. Or UTXO, which is a long term resource (not a one-time expense, unlike processing or bandwidth). Not to mention things we don't yet know where there is transaction where fee is cheap (only takes a small amount of bytes) but the damage is very big. Sure we can take out block size limit but we need to study what kind of adverse effect it will have and whether we need to put on another limit to replace it.
@_date: 2016-10-11 15:43:26
Apparently the big blocker thinks that capacity increase is not so urgent now.. *shrugs*
(Ironically I **do** think it's urgent but I am somewhat of an exception being a small blocker who thinks that way)
@_date: 2016-10-16 22:53:35


That's what happen in Ethereum's DoS


Happen during ETH/ETC fork


Tell that to average Joe


That's not what happen in Ethereum. In fact the reason DoS attack is successful is because this is objectively false


Point me to a time where 2-block re-orgs happen.


By assuming that "something bad is unlikely to happen" you have just made a definition of Black Swan event.
The more fragmented people's settings are the more fragile the network would be. The whole consensus system depends on everyone's setting to be the same. By targeting the difference between everyone's minrelaytxfee one can game 0 conf what you are proposing now is extending this vulnerability into 1-conf and 2-conf


That's because you haven't understood the extent of damage my scenario will cause


First of all RBF doesn't make 0-conf any more unsafe. OTOH Unlimited method objectively makes 2-conf more unsafe as you have confirmed. RBF enables cost-saving by combining multiple tx to be combined before the first one confirmed. Unlimited has no advantage aside from being more "politically palatable". 
Unlimited means you no longer have security on 0-conf,1-conf, and 2-conf (and probably more).
How is weakening security of the network counts as "safely"?
I mean seriously, Classic's 2MB is still considered ok, Ethereum's miner's vote is still relatively OK, but Unlimited? It's like they don't even understand Bitcoin's security model.
@_date: 2016-10-13 07:32:02
The question is what happen when they do? Not how likely it is to happen. Try again.
@_date: 2016-10-12 12:52:03


Actually that "side effect" is the outcome of scaling safely. 2MB block allows attacker to amplify their attack by more than 2. So by quadrupling the block size you can only effectively get 1.7x
@_date: 2017-05-30 15:37:42
Errr... Actually no. Exchanges are not inside for starter. Not to mention that Bitcoin is so old that you have no idea who is still hodling Bitcoin. Loaded himself probably has as many Bitcoins as Bitmain. Satoshi himself could come in and sell all his Bitcoin. We haven't even talked about Mircea Popescu or Bearwhale. This is the reason why Core won't release HF without proper precaution (e.g replay/wipeout)
@_date: 2016-10-12 15:46:52


You are not listening. There will no longer be 1mb limit. Like I said that limit will be removed entirely and replaced by something else.


Dynamic block size will ensure the miner will determine whether you can use the blockchain in the future.


That's because they are still assessing the risk.


Under promise and over deliver.
Using Lightning is the same as using main chain you know? You will still need to open/close channel.
@_date: 2016-10-20 03:52:34


TBF that's precisely why people can break it. Because no one to outbid the attacker.
@_date: 2017-05-30 04:49:50
At least better claim than Craig Wright. That is the same email address used to send the original whitepaper.
Unlike gmx mail that address is not yet known to be compromised.
@_date: 2017-05-29 15:37:48


That's not how decentralized governance works. You can't coordinate 25-100+ people when each of them is doing what they want. Guess what, even within the small group "NY Consensus" they can't even agree to activate Segwit first or Activate both HF and Segwit at the same time or HF first then Segwit.


Some people think it is a feature, and not a bug. And like I said you can't force them to change their mind..
@_date: 2016-10-28 21:24:13
Maybe you should enable JavaScript first...
@_date: 2016-10-11 16:33:43
It's like the Tea Party, man.
Or that two guys in 12 Angry Man (the one with prejudice and the one whose son had a fight with him). They won't listen to reason. I've spent sometime in trying to convince them with logic and none of them change their view. I don't think anyone can do that. They need to come to it themselves (or not). So now guilty, not guilty, hung jury, or stay in the room (I think we will stay in the room for the foreseen future).
@_date: 2017-05-30 10:38:18
And it fails to address quadratic hashing and UTXO bloat. Which is why it is not being merged.
@_date: 2016-10-23 08:57:28
Then, as often pointed out, explain the reason for May 2016 rally.
@_date: 2017-05-24 22:56:48
Jihan is against it though. Apparently he didn't realize the loophole. It was a real shitshow.
@_date: 2017-05-22 12:42:28


Who says people are afraid of chain split? Some BIP148 proponent is prepared to retain the chain no matter what...
@_date: 2017-05-06 00:55:21


Err... no. It is not safe, not for BIP109, and not for BIP101. There is no wipeout protection, no replay protection, and no UTXO bloat protection for a starter. Not to mention that unlike SF doing miner-activation is pretty stupid for HF.
@_date: 2017-05-27 21:51:33


Except Greg Maxwell, Suhas Daftuar, and Pavel Janik already spoke against it.




Besides, did you just completely ignore what OP wrote above? But hey, you're willing to ignore whatever doesn't suit your narratives right?
Unlike certain other people, someone actually has integrity for a change. Personally I do support BIP148 just to show rbtc how Core doesn't control Bitcoin.
@_date: 2016-10-27 10:15:32


Because I care about decentralization? TBH if Classic actually forks I don't mind. I would probably buy some but they don't so here we are. (it is still a better solution than Unlimited, I don't know how anyone sane could actually use that over Classic)
What do you people like to say? "Competition is good"? I still think Core still leads over Classic by a slight margin everything considered. That's why I never said anything overly pro-Core when Classic is still leading.
Secondly if the fee stagnate it is not too late. We still can respond if we have solutions ready. Right now it doesn't stagnate. The decentralization indicator OTOH is flashing red. 
I had no idea that [miner is not being disadvantaged by publishing large block](
I ran a full node. When the blocksize debate started it was still ~30-40GB? Now it is already nearly 100GB. Sure I can run pruned node but who will help people bootstrap a new node?


The witness data is the least harmful of all parts of the transaction. It doesn't contribute to UTXO and processing is still limited input. So the only thing it hits on is bandwidth, which is remedied by compact block. The other two (storage and processing) is not affected by compact block.


I am just making argument on the word **artificial**. As it turns out, it is not artificial. Just like global warming. We need to change the way we use the blockchain or there will be no more blockchain.


Which Unlimited doesn't bother to implement


Large scale CoinJoin for example. Sure it is an edge case but it is good to not limit tx size if we want to compete with the likes of Ethereum.


But the effect is cumulative and there is adversarial scenario to consider(it is surprising that something so small in byte size can be the sole contributor to storage). If someone actually do an attack on that we will suffer the same fate as Ethereum.


Both sides are to blame (that 75% vs 95% though, what are they kindergartner?).


No, but I would like to study the system more so that we can replace block size limit with something more sane


@_date: 2017-05-29 15:24:52


How do you propose people do that? By repeatedly re-spending the tx until one sticks? Seems a little bit inefficient.


Is there any open source tool to do that? Maybe implement Peter Todd's locktime method?
@_date: 2016-10-03 10:35:01


OK, I'd like to hear how would you "address all such concern without putting Bitcoin at any risk" 


Segwit works just started last year. In fact the earliest I have heard of block size is the following Jeff Garzik's thread. 
Which is just having its 6th birthday, not 7. Even then there was minimal follow up. Block size debate just started its escalation path when Gavin raised it some time last year (honestly he or someone else should have raised it sooner and don't back down when opposition encountered though) so it's actually 1 year old.
@_date: 2017-05-02 04:50:10


Sure, just let the users compile the client themselves because no respectable developers are going to do it for them for the same reason that no ethical doctors will participate in medically assisted suicide even though there is demand for one.
@_date: 2016-10-23 14:41:50


That's because it can't. At least not in terms of on-chain transaction capacity. I don't think it is ethical to trick new investor from thinking otherwise
@_date: 2016-10-27 05:56:29
Big blocker have 1 year to do hard fork or whatever shit they want and yet they don't. 
And you think by blocking SegWit you will do harm to small-blocker? No. A lot of small blocker don't even want to increase 1MB limit. All you people are hurting are people like me and who understood the importance of both blocksize increase and keeping the limit sane.
@_date: 2016-10-28 22:34:20
Yeah, go back to mommy and cry.
@_date: 2017-05-01 14:18:31


In those scenarios it is better for the system to shutdown until we figure out precisely what happens rather than letting whatever implementation continue to run. Consider 0.7-0.8 split you mentioned. Technically 0.8 ran as expected so we should follow 0.8 right? But in the real world since 0.7 was used by economic majority we switch to 0.7. 
Now consider the same scenario with Core-Parity split. Parity has the correct implementation but economic majority was running Core. I think it is wiser for Parity to shut down until we figure out the cause and achieve consensus on which chain to follow because 
1. It is still possible that Parity chain will be discontinued anyway because too many people have received payment in Core chain that doesn't exist in Parity chain (require bug-for-bug compatibility with Core)
2. Consensus break down can happen still affect Parity. Take a look at Ethereum's last split:
In that case actually **both** implementations got it wrong.
Also worth to mention that with more implementations there are more possible ways for chain split to happen C(n,2).
@_date: 2016-10-03 10:02:58
From this comment it seems like he was banned from this sub?
Can mod verify this?
@_date: 2017-05-30 13:47:54


At least BIP148 has a working code though.
@_date: 2016-10-03 10:50:03
Find it for me then. Remember he claims 7 years. The earliest I find is 6 years (above). Even then Satoshi is against raising the block size so you can blame him.
@_date: 2016-10-13 02:19:58
What do you think when 51% miner creates block that create more than 21m Bitcoin limit? Think again.
@_date: 2016-10-16 09:35:37


Except when the majority of people who actually understand the code doesn't like the hard fork. They won't hesitate to "fire" the miner by changing hash algo. I will be behind them 100% if they do this.
Edit: Oh, and Bitcoin Unlimited doesn't provide mechanism for safe-hard-fork BTW. So I don't know what the writer is promoting.
@_date: 2017-05-28 15:43:58


For those who don't know they made it such that the earliest Segwit activation to be sometime in 2018 so that the current activation expires first.  The hilarious part is James Hilliard found out a way to make it BIP141 compatible and Jihan straight out rejected it
"It's not ASICBOOST"^TM.
@_date: 2016-10-23 14:44:59
That's what they said about ETC too. The only difference is that this time the developers are in the "losing" side.
@_date: 2017-05-22 14:48:37


IIRC that doesn't include wipeout protection and replay protection. Exchanges are definitely asking for replay protection, especially with the number of people against horse trade deal.
@_date: 2017-05-31 13:36:44
Considering Jihan holds majority hashpower it is not exactly out-of-the-world scenario that original chain survives although the odds are stacked against them and actually I was replying to his other comment, I should've made that clear 


@_date: 2017-05-30 13:12:16


It will be in the future when fee makes up most of the miner reward. If there is a period of time where mempool is empty miner has incentive to take rewards of previous block instead. That is fact of life. Just because you don't like it doesn't make it less true.
@_date: 2016-05-21 17:19:13


The surge is only temporary now and there is a period where backlog can be cleared but the situation is already less than ideal. A prediction of 1 block away from confirmation can be easily 3-4 blocks away in real situation where there is a surge.


Which I mentioned already but it is already at a point where it is just overengineering.
@_date: 2017-05-02 04:44:59
If they are not a small minority there will already be a flag-day-based fork proposal like BIP8 and yet "the other sub" never proposes one. The fork criteria keeps on changing from 75%-60%-51% hashpower and even now I don't know what is the criteria.
@_date: 2017-05-22 07:52:46


There's no such proposal.


No small blocker would agree to the first one, much less the second one.
@_date: 2016-10-03 10:58:46
Link it for me. Unless you can't...
@_date: 2017-05-23 22:25:54


Protocol change has always been started with BIP. With community reviewing it out in the open. Not by closed door meeting by cabal deciding what will be Bitcoin.


And which entity was that?
@_date: 2017-05-17 23:07:47
Is this the result of the following closed door meeting Charlie?
@_date: 2017-05-29 12:08:14


I hate to break this to you but not even New York Consensus participant has a consensus.
James Hilliard and Jeff Garzik/Jihan Wu can't even agree on whether "bit 4" is supposed to activate segwit only or segwit+hardfork.
This proposal is also orthogonal to what Jeff/James is working on.
@_date: 2017-05-29 04:42:57


A bunch of pussies that is afraid of pulling a flag day on fork.




The only one I could think of are anti-Bitcoin professors Jorge Stolfi and Emin Gun Sirer.
@_date: 2017-05-17 20:50:31
Guess who mines that particular block if it isn't another one of Jihan's puppet?


Not to mention repeated 8 in the amount is a lucky number in Chinese.
@_date: 2017-05-17 23:34:10


No he doesn't say it's great. He says BIP148 is preferable over BIP149. Of course BIP9 is technically superior over both.


Peter Todd review binaries and write code for R3. Doesn't mean he endorse them.


Uh, no. He refuses to put his name on it because he isn't 100% sold that it is a good idea. Just like Cobra refuses to put UASF client in Bitcoin.org. Some people has principle to stick with.
@_date: 2017-05-28 23:25:20
Still relevant as of today




@_date: 2017-05-31 11:28:06
Literally almost every Core devs was against PoS. You can easily disprove this claim (also it shows that the antpool managers are lying):
Blue Matt:


Andrew Poelstra:


Greg Maxwell/Adam Back


I think what they meant is Lightning, which is also false.


Can they speak English? I find it very sad that miners don't actually follow development when Bitcoin actually revolves around international community. This makes them easily susceptible to lie and causes chaos where Bitcoin is supposed to be stable. This kind of thing also makes pro-PoW change crowd gains more supporter.
@_date: 2016-10-23 21:29:45


I disagree a 1TB portable HDD costs USD100 8 years ago and it still costs the same today. (And the website specifically mentions that they only focus on hard drive)


1. You don't understand. Miner will rely on non-miner to relay information so this time no matter what miners spend to download a block/verify a transaction they will need to wait for non-miner to finish. Non miner will act as a bottleneck
2. What do you think will happen when you increase the block size


Once again you don't understand miner **depend** on non-miner to relay information so if non-miner doesn't have enough power the power to make block is going to be concentrated on single miner


Which Unlimited doesn't even bother to implement
@_date: 2016-10-12 13:40:06


What happens when BTCC/Bitfury signals acceptance and then retract their support? Like what happens in the testnet
@_date: 2016-10-25 19:46:34


I'd suggest  (Please read his citation as well, it is a pretty comprehensive publication.)
@_date: 2016-05-21 17:35:15


I don't think adding variance into variance is a good idea.


It's overengineering because it work but there is actually a simpler solution.
@_date: 2016-10-27 06:13:35


At 2mb you might not have 100 satoshi/byte because there is no demand.
Actually we have an empirical observation. In March 2013 we reach soft limit, block produced by miner cannot exceed this because of a setting in Bitcoin Core. So Mike Hearn asks everyone to increase this limit:
So the fee drop to roughly 1/5th its original value
(scroll all the way to the bottom, took until 2014 though because fee adjustment is still manual)
So by increasing the limit you are actually providing more attack surface with roughly the same cost. So if we take into account the 2013 case and the current case (both cases having backlog). The transaction fee is still roughly the same.
But let's say it is. Actually the cost is the same (as long as we are talking per/kb limit). All it takes is 101 sat/byte to push 1 byte worth of transaction out of bound (or whatever the lowest transaction is) for both scenarios.


Personally I don't think this is an attack as long as the cost vs resource consumption is the same for both the attacker and the normal guy. What constitutes an attack is when there is a transaction that is ridiculously cheap (not proportional to its cost) and the attacker can use this to abuse the system.
@_date: 2017-05-06 00:53:06
@_date: 2017-05-30 10:52:41


Errr.. No thanks. The next thing you know miner start censoring transaction based on closed door meeting. Any proposal that comes out of closed door meeting should receive heavier scrutiny.


Again he was operating under the assumption that they are working for the same team. Evidently they are not.


And my economic incentive may not be the same as miner. (as a matter of fact it maybe the opposite). If the two run in the opposite direction then I might need to fire the miner.


No his goal is to seek control, which is far more nefarious than that.
@_date: 2017-05-30 04:57:57
Evidently you never did business with Japanese/Chinese/Korean. It is just part of their culture. Like tipping in America (which actually imply underpaid waitress/waiter).
@_date: 2016-10-01 13:55:38
Are you talking about ETC? See my comment above.
@_date: 2016-10-09 10:44:33


Yes, just like Satoshi suggest "Moore's Law" to address scalability issue. More handwaving.


No, it is not shoehorned. The solution was just happen to be that good that it fixes a lot of problem at once. 
The reason Gavin and Mike is frustrated is that Core doesn't accept any solution less than perfect. So we can see now the standard of Core's acceptance.




In a nutshell: "I can't provide counterpoint so let's do ad-hominem on both the person I'm replying to and the community"
Next time please check at least check the karma and account's age so that at least you can do more damage to your ad-hominem.
@_date: 2017-05-28 11:15:30
TFW you realize Bitmain is the real Borgstream
@_date: 2017-05-24 02:15:15


How about I give you compromise. BIP148. Jihan is pissed off. Greg Maxwell is pissed off.


Yeah? I'm not hearing any alternative. 8MB blocks?


If you stay in your own bubble that is.


And Bitmain's compromise is just attempt to disrupt Segwit for their ASICBOOST. 6 Months for a hardfork? Get Real. Pro-compromise folks like you are just playing into their hand.
@_date: 2017-05-29 15:15:18


Who do you mean when you're talking about "Core"? I still wonder how thickheaded you people are considering this has been repeated so many times.. No one can promise anything. If someone says NACK for whatever good reason (e.g non-acceptable tradeoffs) it is not going to get merged. No one has the power to do anything. Greg Maxwell doesn't speak for Pavel Janik. Suhas Daftuar doesn't speak for Johnson Lau. Alex Morcos doesn't speak for Pieter Wuille. Wlad doesn't speak for Eric Voskuil. 
Even BIP148 is not getting merged after Luke-jr's support. People can only write BIP. It is up to the rest to decide.
@_date: 2016-10-14 00:49:29


You forgot that majority of the talent still stay with Core. They have prepared for something like this since a long time ago. There will be a fork but Core will still survive (either by changing hash algo or otherwise).
Worst part is, if people actually support Core more (why wouldn't they? Core still has Lightning development light years ahead) those ASIC will be dust.
@_date: 2016-10-13 02:28:43


Now you have your voice heard. Aren't you glad we made the threshold 95%?
@_date: 2016-10-27 13:06:51
I don't think we can avoid that though. That one is going to bite us sooner or later. I'm not sure how much understanding we have over third party dependency (even including the recent transition to C++11 for example)
@_date: 2017-05-30 11:14:13
Now you are making it less likely for people to buy in. What is the value of a chain whose feature is 2x capacity? Even signature aggregation can give you additional 30-40% without hard fork.
@_date: 2016-05-21 11:17:31
Good job straw manning the argument. No, someone still goes to the restaurant but the figures remain constant (let's say 100 people at the same time). You can't get 200 people to eat the same time.
@_date: 2017-05-30 15:40:41


[Linking to my other comment here](


I would say I don't know but if the market is sane chain+segwit+wipeout advantage &gt; chain without segwit that can be wiped out anytime.
@_date: 2016-05-21 11:12:15


Not that simple. It is possible that the fee doesn't increase because everyone simply doesn't use Bitcoin anymore due to frustration of waiting for tx to confirm (or someone who is planning to use Bitcoin in the future cancelled the plan).
@_date: 2017-07-13 17:53:07


By variance or price discovery it is possible that a chain which was previously minority will become majority and vice versa. Someone who was following one chain can suddenly follow another. They can be tricked into accepting non-zero conf by anyone who replay-protect themselves. 


It is the responsibility of the **forking chain** to provide replay protection, and not the status quo chain. It was **Ethereum** who provides replay protection and not Ethereum Classic.


Because they might lose money otherwise.
@_date: 2017-05-07 00:36:35
It doesn't guarantee no chain split for one. Flag day at far away date (similar to UASF, but I'd prefer further) would be better.
@_date: 2017-05-30 11:15:19
Now you're just making it more likely for debate of "is this within the group's charter"
@_date: 2016-10-23 14:59:43


At 100GB currently many people can no longer run a full node. And HDD is no longer getting cheaper
Secondly to be totally efficient the UTXO must be stored in memory. Right now it is already around 1.4 GB. Pretty soon we might start to need to swap. And if you don't realize the reason Ethereum can gets attacked recently is because their state is too big that they need to swap.
Thirdly I think what many people don't think about is that it is not only sufficient that your node manages to accept the transaction but also contribute to the network (e.g. miner's effort). Remember miner need to spend most of their time hashing, and not downloading and verifying a block. If one of the node is a bottleneck no matter how good a miner's HW they will still be getting bogged down.
We haven't even addressed adversarial scenario like quadratic hashing.
@_date: 2017-07-12 09:07:29


Well, let's see. Funny that the same people who is counting on there will not be enough power users to prevent wipeout protection will assume that there will be enough power users to upgrade in 3 months. :)
@_date: 2017-05-22 05:16:32
Don't get me wrong I think Nassim Taleb is right on so many things. But the problem is that he has so much disdain towards IYI (Intellectual Yet Idiot) that sometime he tends to defend an actual idiot over an actual intellectual (case in point: Donald Trump). That's why tends to gravitate towards his opinion, not realizing how nuanced some the are.
I think an example of IYI in Bitcoin is Emin Gun Sirer. who also happens to be a pro-hard-fork. He owns no Bitcoin so he has no skin in the game. He doesn't write code, only paper so people can't see his idea actually being disproven in the real world. When he actually wrote a code it is actually a vaporware (Teechan). Even the idea the he was originally famous for (selfish mining) is actually a [prior work](
@_date: 2017-05-30 13:39:40
Let's say replay protection. Or wipeout protection. Are they going to argue that it is feature creep? Not to mention that lacking differentiating feature over the old chain makes it less likely for people to support them.
@_date: 2017-05-23 23:14:09


"It's Not Because of ASICBOOST"^TM
@_date: 2017-05-29 04:56:56
So? They are still being given an option.
@_date: 2017-05-31 11:41:08


Let me remind you that Ethereum Classic starts at 0 with no devs, no miners, literally 0 day to prepare and yet it still survives. Personally if the chain survives and a split chain happen I will happily support the other chain. It even gives pro PoW-change crowd something to play with. When that actually happen there will be less pro-BIP149 supporter (who has to live with BarryChain until they split). Personally I feel safer with BIP148 chain than any chain that still co-exist with Jihan.
And personally you (and to certain extent I) hold some degree of responsibility in that. You went "everything is fine, give miner sometime to upgrade just until the last minute". Even now you still insist that Bitcoin is awesome not realizing that some of the pro-Segwit crowd is actually someone who has been priced out of Bitcoin ecosystem who happily supports BIP148. And don't get me started on the importance of ASIC-resistant. I'm not really sure if Andrew Poelstra still holds by his statement:
@_date: 2017-05-29 15:52:36
You would have thought that they learned something from Ethereum splits but you can never be too sure.
@_date: 2017-05-30 00:07:08


Errr, no. Everyone that comes out of that room tells a different story. 
Guess which person attend both? Yup, you guess right. The exact same thing that happen to Eric Lombrozo happens right at the meeting.
Actually I have a crazy idea to avoid this, what if every proposal from now on made out in the open. With the protocol's detail being specified, with code implementation available if possible. We could even call it Bitcoin Betterment Proposal (BBP for short)
@_date: 2016-10-13 00:11:18
And how was soft fork deployed from time immemorial? 95% hash rate. That was how it has always been. Anything that miner implements with less than 100% hash rate should be considered an attack (e.g selfish mining, 51% attack)
@_date: 2017-05-29 22:38:39


Sure, let's forget about Greg Maxwell's effort reaching out to small blocker to agree to Segwit. Or Eric Lombrozo's effort reaching out to Bitmain. The only reason Segwit fails is because Bitmain doesn't come clean about ASICBOOST. 


would have been made to avoid incompatibility-- simply to separate
concerns. 
Well, **that** and the fact that Big Blocker is inconsistent do you want a band-aid fix or you want a permanent solution?. You can't have both at the same time. Segwit is a band-aid solution that is designed to minimize technical debt. If you want a permanent solution and are willing to wait then say so. 
@_date: 2016-05-21 14:21:26
Estimating fee is hard, especially because a lot can happen in the time span between one block to another. The both comments use different wallets (Mycelium and Multibit) and both affected. Even company like Shapeshift and exchanges fall into this trap.
@_date: 2017-05-26 09:27:05


Any decently specified proposal will be given a number. Name any one occurrence where specified proposal where it is rejected. Even shits like Flexible Transaction manages to get in.


1. Not in consensus layer
2. Supported by Jeff Garzik
3. Part of Satoshi's original design


1. Not in consensus layer
2. And what would be the objection to that?


ChainCode Labs/MIT actually employs more.


By your very liberal definition it is impossible to achieve that condition since either
1. Rules is so arbitrary that it is impossible to detect
2. Rules conflict a lot that orphan rate went up
A better measure would be how many hashrate controlled by a single entity? Let me remind you that 
1) Bitmain controls ViaBTC
2) Bitmain controls BTC.TOP




And guess why is that? Because the same developers that you accuse of being centralized put **95%** in the activation criteria.
@_date: 2017-05-28 15:29:48




Define "intended purpose".
For example is "longest chain" an intended purpose? Evidently it is not.


@_date: 2016-10-24 11:18:24


No, it is the longest **valid** chain. Read the white paper again. 51% Miner can create more than 21m Bitcoin and I'll just show my middle finger.




It is 95%+2016 block which is enough to give everyone time whether they want to follow the SF or go through a competing SF.
@_date: 2017-05-22 15:02:03
1. No it is not the same as, it is better.
2. No it is not ETC starts with Bitsquare. Exchange can come in later.


The difference is that all of that happens in the open


If exchange refuse to list trade will happen in Bitsquare.


Which is not what Bitcoin is all about. You have to do buy in for the **entire community** not just figurehead. Not to mention neither the exchange nor devs are even invited, which is pretty stupid
@_date: 2017-07-07 03:10:51


Read the paper again.


benefits are lost if a trusted third party is still required to prevent double-spending.
Also who's to say Jihan is not the attacker? 
@_date: 2017-07-22 01:07:58


Remind me again, who exactly refuses to activate Segwit for 6 months?
@_date: 2017-05-17 22:59:35
1. They better start releasing the software if they actually intend to let the original chain survive otherwise the original chain will be wiped out. BU can't even make a decent wipeout protection the last time I checked
2. Let's see how long they can survive lower profitability.
@_date: 2017-07-27 16:20:34


What is X? Oh, yeah you forgot to mention that it is Segwit activated block + some value. This is a prime example of shit spec.


We need more capacity so we need to fill a block with zeros.


Quadratic hash protection, UTXO bloat worst case, more time needed to write test, ensure no consensus break between implementation, discount the signature for legacy tx instead of foolishly doubling the weight etc. 
But more importantly proper governance. Note that some of the Core Devs already proposed some of the things I mentioned above and get rejected. NYA Signatories could have chosen to support spoonnet since February instead of running like headless chicken until May. I can only this as an effort to "Fire Core"
@_date: 2017-05-30 04:48:00
Like I said BIP or GTFO.
@_date: 2017-07-27 14:32:25


A billion dollar company spending an entire day coming up with press release having translation problem? I find it unlikely.


Again, if you are really interested you can send me an Antminer and I will show you.


Literally no one is saying that.


It will solve a specific form of ASICBOOST that will interfere with further development.


You mean Segwit activation? Yeah after we threaten to wipeout their chain finally we manage to activate Segwit
WTF are you on about? Overclocking !=ASICBOOST. Maybe you should consider hiring a professional to run your mining facilities...
@_date: 2017-07-10 22:28:24


That the mining code is not forced to produce &gt;1MB block. 
They should have used hard fork bit instead...
@_date: 2017-05-22 14:42:33
1. Segwit is effectively 2MB block
2. These "large portions of the community" are welcome to hard fork anytime. Just need to select a flag day, put out proposal and be done with it. Like UASF. They don't need to wait for backdoor deals.
@_date: 2015-03-18 10:40:22
You forget to include the price calculation. How much money do you need to fill a cubic meter with micro-SD Card?
@_date: 2017-05-22 14:39:58
[This again?](
It was BU that has unsound economic principle.
@_date: 2016-05-21 11:40:21
No, because they don't know what is the right price. 
Here, getting some link from outside or to give example of non-biased frustration (I found a lot of example in are being accused of 1 day user spreading FUD.
@_date: 2017-05-29 13:39:44
Ethereum Classic starts with nothing. No developers. No ecosystem. No miner. No wipeout advantage. Yet it is the 5th largest altcoin right now. All it takes is a demand for the coin and miner will follow.
BIP148 at minimum already has Luke-jr and Eric Lombrozo. Mycelium and Electrum seems to be onboard. Not to mention wipeout advantage. If anything I would be worried about the main chain. It requires consistent hashpower bigger than BIP148 chain to avoid being wiped out. Add to that the mess that is NY consensus. Personally I wouldn't want to run the Core client now.
@_date: 2017-05-28 09:43:55
You mean the one where they can't even agree on the sequence of events?
Or the one where they can't agree on the definition of "bit 4"?
That's your definition of "have their shit together"?
@_date: 2016-10-28 22:58:50
I don't think his comment is being antagonistic at all. He is just simply stating the fact. And if wants to be fair he should criticize both Unlimited and Core (which he didn't, and trust me risk analysis for Unlimited will reveal that it is a much bigger threat to ecosystem)
@_date: 2017-05-30 22:27:31


Eric Lombrozo has freedom of speech as well. And you can see people condemning milos or breitbart as well. Because it is the right thing to do.


The benefit of BIP148 is that it takes the decision making out of miner's hand and put it into the market's hand.


Why does gov print money anyway? Because benefit &gt; loss. If you bitcoin value drop by less than 10% but your incomes doubled it is worth it.


Bitcoin is meant to last 1000 years. Miner should not be able to print more than 21M neither now nor 1000 years in the future.


Yet that guy holds 40% hashpower.


In decentralized currency no one is telling you what to do and not to do. That includes BIP148


Not unfounded.


Block propagation and UTXO growth is a concern.


It enables Lightning which is a vertical scaling


It is controlled by a decentralized peer review process
@_date: 2017-07-25 22:46:51


*facepalm* If a chip support overt ASICBOOST it also supports covert ASCIBOOST. Those two work the same way. Both pass the midstate into the IC. The only difference is which part to grind (covert one grind transaction ordering while overt one grind the block version number). This part can be done outside the ASIC.
@_date: 2017-07-20 16:37:17


1. That means 1 conf and 2-conf is no longer safe. 
2. We don't know how long until 1 conf and 2 conf is considered safe
3. Considering that Bitmain is still not yet signaling on bit 1 the risk is quite big. 
@_date: 2017-07-05 16:23:29
1. You know the difference between segnet and testnet right? I guess not
2. The split was between two different versions of the client, which was expected. Bitcoin Classic split with Bitcoin Unlimited, which was not expected.
@_date: 2017-05-17 12:22:33
1) He is assuming a 100% yield on the wafer. 


As someone who works in semiconductor industry this is far from the case. In memory yield is only around ~90%, ~60% at early ramp. With logic in foundry it is even worse (probably ~60% at mature, ~30% at ramp).
2) He didn't take into account "insider discount". If you knew someone who knew someone (e.g like Chandler Guo or Jiang Zhuoer) you can get a discount on the equipment. That's how Chinese do business. Heck, some Chinese restaurant has menu that is offered only when you speak Chinese. Or give you discount when you pay in cash and speak Chinese(because IRS can't track them). How many percent of hashrate is using this discount?
3) Read his "Profit from mining section"


Yes, you read it right his profit from mining helps them during mining manufacturers downturn.
4) ASIC production is a one time fee. In the long term profitability is determined by electricity consumption. Because of increase in Bitcoin price the profit skyrocketed but this is only in short term. That calculation is only valid for now, in the future hashrate will also increase to compensate for increase in price. 
@_date: 2016-10-09 08:21:18


How is that a technical debt? Satoshi created OP_NOPs specifically for doing this. P2SH was also deployed the same way. OTOH Nodes that haven't upgraded will be protected by nodes that have (and miner). In HF nodes that haven't upgraded will be left to fend for themselves.


On an economic standpoint commitment to SegWit means zero commitment to a fork. If that is not the beautiful definition of "vote with your money" I don't know what is


You call that adversarial case I call that feature enabler.
Big Blocker when Ethereum has smart contract:"Wow such innovation!" Big Blocker when Core says 75% discount for smart contract: "How dare they!"


You think that 2mb means 2x damage? Wrong. WRONG WRONG WRONG WRONG WRONG. The reason signature gets discount is because that is the place people can do least damage. Messing around with input will get you quadratic hashing. Messing around with output will get you unbounded UTXO growth.


At the cost of the fact that they're not yet ready, deployment takes takes longer time because HF (unless you want to throw safety out the window), [doesn't help hardware wallet, and doesn't take care of quadratic hashing]( nor unbounded UTXO growth.
@_date: 2017-05-29 16:14:46
That's David Vorick I think. @_date: 2017-07-05 15:48:51


Guess who is "market"? Full node, whose code is written by someone. You just suggested that miner rewrite the code ran by full node into accepting that.


And yet Bitmain pushes shit that is Bitcoin Unlimited.


That's what happen in Ethereum though.


They're welcome to participate in the decision making. But they need to follow the governance process.
@_date: 2017-07-13 19:18:58
Question: Does any current SPV wallet actually interacts with nVersion? Because IIRC during BIP66 split they just ate whatever chain they were given with. 
Edit: I see. Old BitcoinJ uses nVersion to check for various soft fork activation. They intended to drag those old Bitcoin Wallets with them. Well, let's just hope the fucking risk is worth it. LOL. These people...
I mean, Bitcoin Wallets hasn't been market leader since I don't know how many years. It has been overtaken by Mycelium, Breadwallet, and to a certain extent Electrum.
Edit 2: Actually it still doesn't make any sense. Hard fork bit is only required for a single block.
@_date: 2017-05-30 00:10:00


Err.. Did you even read the article. His impression at the end of the meeting is that they have come to a mutual understanding.


@_date: 2017-07-01 18:41:40
Listening to him speak makes me want to scream JIAN YAAAAAANG! LOL
Seriously though why are we forgetting about [first use of SNARK]( that does all the computations off-chain so that it doesn't burden everyone. Or [various hash algorithms collision bounty](
Take a look at Ethereum. Their killer apps has been theDAO (LOL) and ICOs(another lulz). There is nothing smart about them.
@_date: 2017-07-27 11:03:11


Read the link. The B1 he talked about is covert ASICBOOST. Overt ASICBOOST is covered under A (and it is even more efficient at the cost of being overt)
@_date: 2017-05-22 08:54:14
It's not irrelevant when most of the core devs will support the other chain. PoW change is definitely within possibility.
@_date: 2017-07-10 22:41:21
You were asking which part is unexpected. I just told you which. That's it.
@_date: 2017-07-06 00:11:54


With a normal node that consumes roughly 600MB and took around 2 days to sync. Also note the non-linearity since platter is several orders of magnitude slower than memory.


1. Without limit empirically blocksize doubles every 1year so you can expect that limit to be reached within a year
2. At 200MB growth per year it will take 10 years to reach 2GB. I would assume users would only be willing to let a program to use only 20% of its memory (e.g browser takes around the same amount of memory)


Exactly the scenario you will have with 100MB cache. And like I said platter is still the typical storage. This is a typical memory-starved sync case
Note that he hasn't even hit the current peak load.


CPU doesn't even kick-in until it hits the assume-valid block


OK. My timeline is off by a a bit. It still doesn't explain Dec-Mar spike. Bitcoin price is still relatively stable back then. It also doesn't explain the taper off in June (which still has a 25% increase)
@_date: 2017-07-11 23:00:31
No, it doesn't absent hardfork scenario. My point is the default config shouldn't cause you to lose money.
@_date: 2016-10-12 13:37:12
Because that is the correct way to do it. Messing around with the input will get you quadratic scaling. Messing around with the output will get you unbounded UTXO growth. So the only way to increase the limit safely is by increasing the limit for signature.
This is the future direction we are heading towards (correct one too IMO). Go towards block weightage (gas limit in Ethereum). Block size is a pretty shitty DoS limit anyway.
@_date: 2017-05-02 04:41:47
There's no acceptance depth in BIP8. Big difference.
@_date: 2017-07-25 15:22:12


You think that can't be faked?


You can reverse engineer them yourselves from Bitmain's sample code. I don't have time to look around but this seems to be the part:
@_date: 2017-07-27 15:51:40


The signatories could have supported spoonnet from back in February instead of running like headless chicken until May. The question you should be asking is why they don't. (or in this case why you don't)
@_date: 2017-07-13 17:55:57
Thanks for the information!
@_date: 2017-07-13 18:37:29


No, it isn't. The contract was created by a third party and deployed to **both ETH and ETC**.
That was one of the Ethereum Foundation's irresponsibility, just like how btc1 is being irresponsible right now. At least in the EF accepted the responsibility.


What do you think will happen when there is more demand for legacy chain? Do you think that 80% will stick to the agreement?   Let me remind you that BTU value is only 10% of BTC value. Even if this is true for the 1st year do you think you can keep the chain longer for year    You idiots can't even think long term.


A minority can become majority anytime.
@_date: 2017-07-05 13:23:43


Already tried. Bitmain does that with BU and no one wants to run it.


Merge pull request to give themselves 21M BTC. Surely there is nothing that can go wrong with that.
@_date: 2017-07-05 13:14:30
Those still on the fence regarding BIP148 take a look at this at shit you have to deal with for another year. Core devs infighting on top of Jihan-Core fights. Not even BIP149 has consensus.


That's what is implemented in BIP66. The failure to do so is the cause of chain split.


Yeah you are completely ignoring the case of BIP148 splitting the chain causing people to lose money because of (Edit:)~~your~~ inaction. 
Miner need to realize that there is a difference between readiness signaling and voting. With forced orphaning we can be sure that miner won't asleep at the wheel and cause a chain split later on. If they are not ready they need to sit in the corner until they are ready.
Objection to the proposal need to be stated before the code is being finalized (with ample time being provided).
@_date: 2017-07-27 16:59:57


What? It **does** matter. You will still need to have one!! How am I supposed to know where to put the check in??!! Jesus Christ..
Besides, do you have a separate spec for when the hard fork will happen?


I would consider filling a block with something that serves no economic activity as spamming.


You are making an assumption out of zero real world data. If this is not needed no one would be opening this pull reqs


A link? You guys are the one proposing a hard fork. You are the one who is supposed to analyze!!! What the hell man.


The discount factor remains the same for Segwit tx, it is only changed for legacy tx


Something is wrong if what is technically more sound is being rejected.


Even though it is more technically sound? And why is that? Maybe just to suit the "fire core" narratives?
@_date: 2017-07-18 21:21:39


Peter Todd is not getting paid. He a sticky on his twitter about that just about a month ago. So the "users" and "miners" don't get to tell him what to do. The question is why the stupid fucks NYA participant hires incompetent shits like Peter Rizun and Jeff Garzik instead.
The answer is most likely because unlike both of them Peter Todd has ethics. He won't do things that could cause people to lose money.


Maybe the attack is only possible because of rushed implementations to meet the 6 months deadline? You know, the one that all of Core Devs have been warning about. Seriously you don't get to [unanimous disapproval]( unless your idea is ridiculously bad. Take a look at BIP148 (which is a half-bad idea) and compare it with Segwit2x. Or for that matter [BIP16]( which is actually semi-vulnerable to collision attack by a state level actor. 
Core devs don't have a single unified voice. When your idea is somewhat workable you will find some of the Core devs on your side.
@_date: 2017-07-08 04:02:01
*sigh* Here I was sipping my coffee on a quiet Saturday morning hoping that you will get away after the last comment


OK, let's talk about pCoinsTip cache strategy. pCoinsTip has three strategies, FLUSH_STATE_ALWAYS, FLUSH_STATE_IF_NEEDED, FLUSH_STATE_NONE, and FLUSH_STATE_PERIODIC:
You can take a look at the logic to determine what each state represents here:
Basically periodic=regularly flush, if needed=only if the usage is &gt; than allocation, and always=is always flush, and none is well, you don't need to flush.
ConnectTip() uses FLUSH_STATE_IF_NEEDED
In fact I've almost never seen FLUSH_STATE_ALWAYS (except during init). Mostly it is PERIODIC (during period of non-syncing)
I mean think about it, if you always use FLUSH_STATE_ALWAYS can your memory usage exceed 100MB when your block size is merely 1MB?
Are you going to leave my weekend in peace now?
@_date: 2017-07-05 11:32:10


The fact that no one can tell you when any features could be ready is quite telling. Only Signature Aggregation is somewhere near (although no quite know)


What do you propose? Give everyone commit access? 
@_date: 2017-07-12 21:19:04
Electrum has checkpointing feature:
Others (Mycelium, GreenWallet, Copay) connects to a centralized server IIRC. So yeah, I'm actually not really sure which "SPV" actually follow the most work chain given that said BitcoinJ can verify block size as well. At first I thought that it was the lite-client that he was talking about.
@_date: 2017-07-04 22:47:46


Take a look at August 15th


Why are we settling for sub-optimal solution just to appease a bunch of ASICBOOSTer? 
@_date: 2017-07-02 09:43:31
[Not really](
@_date: 2017-07-20 17:45:53
Because SNAFU happens from time to time? That;s what happen in July 2015
@_date: 2017-07-02 16:30:57
*facepalm* 


Signatures gone missing? SIGNATURES GONE MISSING? WTF?
He understood that upgraded node will still demand witness data right?
@_date: 2016-10-13 08:42:44
Agreed. Which is why holding down a soft fork is pretty stupid thing to do.
@_date: 2016-10-13 00:09:57


Yes, but we need to replace 1mb limit with something else, which is a very complicated process. The reason Ethereum needs to lower down their gas limit is because they made a mistake in doing it.
@_date: 2016-10-12 13:57:13


Under 1MB block size limit.


No, but it is possible to lower it back to 1MB. And we are back where we started. This will actually take longer time than if we do it right the first time
@_date: 2017-07-01 04:51:25
Errr.. No. It is asking them to spend money on a chain that can't be wiped out. OTOH Asking them on legacy chain is just asking to be reorged out of existence.
@_date: 2017-05-30 22:15:07


You know Bearwhale + Loaded holding is &gt; Bitfinex's entire cold wallet right?


1. There's no guarantee that it won't be censored
2. Loaded himself can turn the table on his signed message.
@_date: 2017-07-05 09:59:28


The rate **matters**. Just like global warming the rate of increase can make or break the survival of the ecosystem.


None of them (e.g TXO commitments, everything else is at even worse state, there isn't even a solid proposal) are anywhere near ready. Quoting offhand from bitcoin-wizards




Well they already rejected the efforts made some of the prominent contributor so far. I don't see why they should continue the path to reconciliation when that would imply higher likelihood of their idea getting rejected in the future.
@_date: 2017-07-06 13:00:24


Gavin used to have both. Once he decided to bypass the peer review process and be seen as compromised by vouching for Craig Wright he gets booted. Nothing prevents that from happening from Greg Maxwell or Luke-jr or Peter Todd or Wlad in the future.
@_date: 2017-07-04 13:44:34
Fun fact: The first onset of attack coincide with Segwit release:
Whoever does that really hates Segwit.
@_date: 2017-07-27 09:05:29


Can't even answer a simple question. **How much fees are there?**


That's why you will stay at 45KW forever and never expand.


Yeah, suuuure.
@_date: 2015-02-25 03:09:55
How do you change the monetary policy? That would mean the network will experience a fork in regular period. This requires high amount of coordination between the full nodes and the miners.
Now consider this the Fed just pay the miner directly. How does the rest of the network verify that the Fedcoin is valid? That the miner receives license from Feds? Well now you are just reinventing the Bank.
@_date: 2017-05-22 09:05:36
I find it very surprising that people still can't understand that closed door meeting doesn't work in Bitcoin. The reason Segwit gains traction is that it comes from an open source code Elements Alpha ( Someone not working for Blockstream even asks for the feature to be implemented in Bitcoin:
When Luke-jr submits his proposal it also happens in the open in IRC (can someone link a botbot link? why botbot search sucks). That's how it gain traction. Similarly UASF starts with the following email:
Compare that to spoonnet, which although was a good idea comes from closed door HK Roundtable meeting. If this kind of idea doesn't gain traction you can't expect any worse idea to be accepted (example: extension blocks coming from purseIO and Bitmain)
Even worse is the current closed door meeting, which apparently doesn't have any developer in it. It seems that they are promising the impossible with deployment of Segwit in alternating bit and a HF in 4 months.
@_date: 2017-07-10 22:58:30
To be fair that plan is inside UAHF


I wouldn't be surprised if he came up with this himself
@_date: 2017-07-06 16:13:08


Seeing that our sync time is within the same order of magnitude I can't see why our CPU usage is so different. Even if my bottleneck is somewhere else I shouldn't have 1/25th of your cpu usage (yes it hovers somewhere around 4%).


You can search for more people with dbcache issue. Not all of them are using flash disk. In fact that is number one problem people have.


The only way that could happen is that if the proportion of (sigma(delta(whatever_things_you_have_mentioned))/total_utxo_newly_created) is increasing over time, which entails an entirely different spending behaviour over time. I don't see how that could be true, especially when lost coins are less likely as bitcoin worth more and wallets are getting smarter to be rid of dust. 


My last sync? 2 days. My sync before that which is memory starved(and the guy that I linked)? 2 weeks. How long your node is supposed to sync using Atom processor assuming it is cpu-bound? 5 hours. Try to keep up, champ.
@_date: 2017-07-21 22:16:00
The same *someone* that threaten to split the chain if the proposal is used?
The same *someone* that insist on HF-ing in November?
@_date: 2016-10-25 20:04:12


**Adequate hardware**. Exactly. What is your target hardware? As an example this fellow is unable to make transaction during Ethereum's attack. 
I consider this an attack because legitimate people will no longer be able to outbid the attacker (while the attacker just need to relay his attack transaction somehow). 


Actually this is **not** what I consider an attack. Network security is very expensive, and it is important that someone pay for it. Whether it is attacker, government, or whoever.


Perhaps at that fee Bitcoin no longer is a use case to you (At least until Lightning arrives). But it is still **is** to someone else. As an example SWIFT fee is around $30 dollar, and last time I use WU the fee is around $10. People who uses Bitcoin as long term store of value or DNM user probably wouldn't mind paying that amount either.


I think the last attack only lasts around what 2 weeks? 1 month? And yet people still trusts Bitcoin.


You're assuming $1 fee right? There's still someone willing to pay $1.1 to outbid the attacker so I'd say the attacker won't be as successful as you think.


I'd say that is a good thing. An extra demand for $100M more Bitcoin a year? 
@_date: 2016-10-15 05:02:52


Actually that explains it :)


 Makes me really wonder how much of an insight that goes into Terbium selection as an example.
@_date: 2016-10-12 12:50:40


That's actually why we have SegWit, which is actually a 4MB blocks. Why we don't get 4x capacity you say? Because to scale safely the increase in capacity is not linear. That is just the fact of t he world.
@_date: 2016-10-15 16:34:12


You mean like people spending $5000 to attack Ethereum just for the lulz? In the end some people might appreciate lower block size limit. And when this happen you won't have enough preparation to guard against replay attack for example.


How do you know which block to orphan when you haven't processed them?Note: I am not talking simply about big block that a node haven't agreed on, but a block that a node have agreed on but contain a poison, like quadratic hash, or some other unknown vulnerability (my guess is some of the core devs knew but haven't disclosed them like BIP66-related vulnerability)
Until the chain is 4 blocks deep remember? Then they have no choice 


With current Bitcoin state I can confidently say 2-conf is set in stone.


It's as if you haven't learnt anything these few years. Those who underestimate the possibility of a Black Swan event will pay the piper when it actually happens.
"Mortgage Bond is the most stable assets" -&gt; 2008 Crisis
"TheDAO has been audited by all the experts"-&gt; Someone took everything away in the end
"ETC will die within a few days" -&gt; Nearly a month and its value is still nonzero
"No one will bother to spend money to attack Ethereum"-&gt; DoS attack
You also need to remember this is just some scenario that I come up with within a day and I am still not 1/10th as good as whoever is DoSing Ethereum right now (and they will probably have more time to analyze the code)


Big blocker when RBF is out: "ZOMG you are killing 0-conf". Big Blocker when Unlimited is out: "It's okay to wait 4 blocks instead of 2"
@_date: 2017-07-01 10:02:05
This shit again?
Here. ANYONE CAN SPEND THIS:
@_date: 2017-05-31 22:31:06
Just in case you didn't realize the entire hashrate running BU is powered by Jihan 
That's roughly 40%. (Well BitClub is not by btc.com is). You don't know who else is working for Jihan in secret. There was rumor that Bixin (previously HaoBTC) was being helped by Jihan in the past when their exchange went bankrupt. If BIP148 has lower value than main chain then split chain most likely will happen.
@_date: 2017-07-18 21:55:10
The problem is that Jeff Garzik attempts to "increase" block size limit by changing MAX_BLOCK_BASE_SIZE, which actually doesn't do anything because that parameter is only used in test (or maybe in belt/suspender somewhere)
It wasn't until someone pointed out to him that he knows that he needs to change the weight as well. 
Sergio did the same thing with his BIP






Duh that doesn't increase the block size.
@_date: 2017-07-12 07:09:40


There is a bug in the default mining configuration though. It will prevent miner from creating the required wipeout protection block. 
In addition to that it is quite likely that the wipeout protection required will fail in the real world scenario without actually spamming the blockchain. Logically people won't be making any transaction near hard fork time due to all the uncertainty. Doing so will require people to fiddle out with replay protection after all and most people will just adopt wait and see attitude regarding best known method to do so.
@_date: 2017-05-22 14:40:50


You can't fake the value nor the volume of a chain either. Hashrate follows the value not the other way around.
@_date: 2017-07-22 08:04:31


No, it isn't. 


Because 4MB block doesn't mean 4x increase in resource, especially in adversarial condition. Teach yourself about non-linearity.
@_date: 2017-07-20 16:34:49
Just signal bit4 but they will still build on non-bit 1 signaling blocks
@_date: 2017-07-13 06:19:00
No, it won't. Ethereum Classic had 0.5% hash rate of Ethereum and in the beginning yet no one bothers to attack it. CoiledCoin doesn't even have 1/1000th of Bitcoin hashrate at the time.
@_date: 2017-07-01 07:45:25
His expectation is that Lightning can bring back block size to 300kb. Fat chance that will happen but can't blame him to be hopeful.
Edit: add source


@_date: 2017-07-10 12:43:36


That is not strictly true. You will need to consider address reuse as well (or the value inside the output). Or at least study their effects.


Precisely Eric Voskuil's observation:


This is one of the reasons people are trying to keep as much of the UTXO in memory as possible.The current basic recommended sync strategy is to avoid flush as much as possible for those people we knew for certain to be I/O limited (dbcache=4096, which is the total number of UTXO 4GB). Although apparently 300-600MB is enough if you are network limited. I suspect that is the number for a single flush where most of the long term lost/hodl utxos are being flushed. This number comes from trial and error, and not from effort to keep flush rate the same or anything.


the cache limit and testing on various configurations.
Once you need more flushes it is pretty much unknown territory.
Most miners are also keeping the entire UTXO set in memory as well.
If you disagree with Eric, the burden of proof is on you.
@_date: 2017-07-10 12:51:36


To see this clearer it is better for you to take a look at the other formula, which is 4\*base+witness &lt;4000000. When you have no segwit tx the witness part is 0, which means that 4\*base &lt; 4000000 which reduces to base &lt; 1000000, basically the same as previous limit. 
Additional note:(that other formula comes from witness + base = total so witness = total - base so limit must be = 4 \* base + (total - base) = 3 \* base + total.
I find it a little bit surprising that it is less obvious to many people...
@_date: 2017-07-27 18:45:28


You haven't answered what we could have done more.


There was no Jeff Garzik until he was appointed by Barry Silbert. There was no flag day until jtimon brought it up (because Bitmain was so afraid that other miner would defect after Segwit was activated for miner-assisted hard fork, which is pretty stupid because there is no way to enforce that).


Like I said Eric and Matt attempt to contribute to btc1 only to be rejected. When the proposal was offered to Core Devs it was stated that the 6 months timeline is non-negotiable. How likely do you think that kind of scenario will happen? Really unlikely.


Like I said I have been spamming the spoonnet link every time HK agreement was brought up. You should stop looking up into only the people you know. None of the Ethereum Classic supporter knew each other. Most of the Monero Dev are anonymous.
@_date: 2017-07-05 22:36:44


I am talking about Bitmain in specific. The entire hashrate signaling for Bitcoin Unlimited is controlled by him


So they think Segwit is bad but they still do it anyway because we attach a block size increase? 
1. Segwit is block size increase
2. Proposal should be evaluated on its merit. If they think an upgrade is bad they should block it no matter what kind of additional feature we offer.
See? Irrationality.


Since everyone supports Segwit there is no need to distinguish between the two. Activate Segwit then talk about blocksize increase. Another evidence of miner being irrational


Let's not pretend that there is no resistance from Jihan
Here's another list of his power trip behaviors
1. Wanting to increase capacity but blocks the single most ready capacity increase proposal by at least 6 months
2. Wanting to increase capacity but blocks non-bandwidth effort (LN, Signature Aggregation, MAST, Rootstock) to increase capacity by 6 months
3. Work with Bitcoin Unlimited instead of Spoonnet even though it is a piece of shit that he himself doesn't run
4. Spam Bitcoin blockchain for 6 months
5. Delay the shipment of Litecoin miners when they attempt to activate Segwit there.
@_date: 2017-07-02 16:24:22
Answered up there. He should be embarrassed of doing exactly what OP accuses of.
@_date: 2017-07-12 08:56:35


Like I said, people will stop transacting near hard fork. I'm not sure where you're getting your 95% figures from.
@_date: 2017-07-03 04:22:41


LOL. Apparently you made the same mistake Jeff Garzik did.


We haven't even considered the fact that Segwit2x chain might introduce something like shitty xthin or whatever shenanigans in the future, induce merge conflict and getting remotely shutdown all over the place in the end.
@_date: 2017-07-03 04:25:55
You just moved the goalpost there. You said just change one into two. And you haven't even talked about replay/wipeout protection
@_date: 2017-07-26 17:26:33
Yeah, guys we have nothing to do with BCC *wink wink* 
@_date: 2017-05-30 13:46:50


That's like saying people doing criminal from time to time is wrong and cannot be avoided. So why bother protesting?


And closed door would make it less likely to be adopted.


You can't blame him for supporting BIP148 now. For his personal gain as well.


No. Miner has all the incentives to push 21M limit up for the same reason government print money. If they can't get enough money from tx fee what other method they can use to "increase consumption"?


We are talking about the same guy who pushes broken solution like BU. You can throw "sane" assumption out of the window.


Who says BIP148 is not part of the maneuver?


Nope. never meant to be temporary. Satoshi says 'it can be lifted if need to' but he never says what is the criteria and not to mention he doesn't have the knowledge that we have now.
@_date: 2017-05-27 10:04:09
Also tell them that the only reason Jihan spreads that lie is because he wants to cover the fact that he can use the same chips he sells at lower power consumption than all other people. In other words he is using a special mode that is not available to other miner. Segwit disables this mode
@_date: 2017-07-27 06:03:27


And how much fee do they collect in those two invalid blocks?


What files? You were talking about how-tos.


Because their boosted block is invalid.


What happen when you try to import them to US?
@_date: 2017-07-05 14:09:26


Oops I didn't mean to blame him specifically.
@_date: 2017-07-13 17:25:28


I am afraid this will be misunderstood. **"Core"** is not planning anything because there's simply no such a thing as **"Core"**. There's only individual contributors to a project called "Bitcoin Core". **Johnson Lau** has one such proposal, called spoonnet but **Johnson Lau is not "Core"**. The way I see it this proposal has quite a fair bit of support from let's say Matt Corallo, Adam Back, Sergio Lerner and AJ Towns but **they are not "Core"** either. Like you and me they will need to write a proposal to be discussed in public by other collaborators. Let's imagine that they do that.
Now let's switch the perspective to other contributors. You will need to remember that each contributors has their own set of views, projects, and priorities. How do you think they would react when the proposal was brought forwards? This is how imagine it.
"You are telling me to drop whatever I'm working for to work on this? Why? Capacity increase is urgent? Not the way I see it. Segwit is not yet activated after all. Besides all the company that was saying capacity increase is urgent are working on Segwit2x instead of your proposal. They don't seem to require our help. Why should we support them? Looks like they are more interested installing a government made of cartels... So yeah, I'm not going to help you."
There you go, HF is probably postponed to I don't know when. I think if you want capacity increase most likely signature aggregation will be proposed well, maybe sometime this year? That is required for scalability and fungibility improvement so most likely people will be more interested to work on that (although, again nothing is certain, some shitty miner might block that again or some other contributors might raise another fuss)
Frustrating? Perhaps. This is why most Core devs are not so concerned with Segwit activation. They are already used to disappointment (which might seem irrational from their point of view because you can't make two people see exactly the same thing after all.).
@_date: 2017-05-22 15:14:27
1. **Positive** Side Effects. Which still makes it better
2. That still manages to convince Poloniex to list them anyway.


The beauty of Bitcoin is that it enables autonomy, which is the opposite of governance by representation. I am still not sure why anyone wants representation when they can have the original political system instead.


I don't really like to repeat myself but
1. At least it happens in the open. The terms are pretty clear.
2. It **attempts** to buy in, that's why it's not inside Bitcoin Core yet. If people are not convinced they can make a competing soft fork or whatever.
@_date: 2017-07-27 12:07:18


*Sigh* If you are going to debate me on ASICBOOST makes sure you properly understood the topic. 
There are two types of ASICBOOST, overt and covert. Overt is the most efficient but detectable. Covert one (covered by B part) is what we are talking about here. There are two versions of Covert, the less efficient version (what we call B1/regular ASICBOOST) and the more efficient version (what we call B2 that is in the end going to be disabled by Segwit). 
Sure you can still use B1 after Segwit but that will require you to redo all the tooling (especially if you have FPGA/ASIC in the pipeline). You haven't even considered the fact that in the long run profit margin will tend to go to zero(remember that not so long ago Bitcoin price is still around 600$, and 200$ before that). In the short term this may not make sense but as Bitcoin price rise so will the hash rate. A 5% additional margin can make or break a miner when your profit margin is less than 0% without ASICBOOST.
@_date: 2017-07-06 14:22:08


Errr... No it is not. I've tried running simulation vs syncing electrum server while simultaneously syncing at the same time. Syncing while the electrum server is reindexing is much slower. I'm barely using one core when I'm trying to sync while it is idling. Are you sure you are not mistaking some malware as a full node?
OK, let's say it's cpu bound. Let's say multiplying up a merkle tree requires 2n where n is the number of transaction(does it even do that? Let's say it does this is the most expensive operation I can think of). Typical full block has 3 transaction per second. That means there are:
6\*60(seconds)\*60(minutes)\*24(hours)\*365(days)\*10(years-of-bitcoin)=1892160000 hashes
At 100khash/s that will take you ~5 hours to verify everything and yet it took you 8 hours. You see nothing wrong there? Note that I am using the assumption that block is full since day 1 (which it is not) and 100khash is a typical low end cpu. A higher end model would be 10x-100x faster. 


Who cares? As it turns out it was memory issue after all.


Are you saying the "hot set" has somehow a sub-linear correlation with UTXO size?
@_date: 2017-05-30 12:16:14


An existent userbase refusing to bow will stop them from doing so. Just look at how many Core devs supporting BIP148. A lot. Consensus building is the only thing stopping it from being merged into the official repo.
@_date: 2015-02-13 15:48:34


The Bank loan it to someone who use it to buy a car. So who owns the $900? The depositor or the car maker?


From Wikipedia on FRB:




You are limiting yourself to US. There's the recent case of Cyprus and the Indonesia in '97 Asian Financial Crisis.


Well, the problem is to offer this to general public you will need to conform to regulation by SEC. Otherwise you won't be able to do that. Bank can help to alleviate some of the requirement.


Normally the Bank wouldn't interfere with the operation of the corporation unless there's an indication of financial problem (tardiness in paying back). Which is another service provided by the Bank.


That's where free market comes into play. Alice can find Charlie, who is willing to deal with Widget Maker A.


During the Asian Financial Crisis of '97, Islamic Bank arguably does better than its peer.
You can find other similar studies if Google it.


You believe in Bitcoin, where are the $100 Billion Bitcoin company? Islamic Banking is relatively new (started in 1950s) so until we learn through multiple financial crisis we won't understand how much better it is. For now let's just say the higher growth rate doesn't come from nowhere.
@_date: 2017-07-27 15:57:12








And yet they list BCC. Normally exchange only list an alt only if there is significant demand from OTC. BCC is not even forked yet.
Not so "laser focused" now, are they?
@_date: 2017-05-31 22:31:42
I'd say Ethereum's PoW looks ASIC resistant enough.
@_date: 2017-05-26 06:52:38
Except that it doesn't guarantee that a regular PC will still be able to run a node. Miners are getting paid for it. Regular users are just running for the sake of sovereignty.
@_date: 2017-07-06 17:33:12
All the other miner not directly controlled by Bitmain (or at least not controlled as strongly) has already signaled for Segwit BIP141. Well, there's also Roger Ver but that's about it.
@_date: 2015-02-01 12:44:17


If there is no demand there will be no WU Agent.


I have, it is 5-10% fee. If you don't trust you can give the WU number a call.


That's good for you. But what happen to you doesn't happen to everyone. Please be open-minded.
@_date: 2017-05-21 21:41:25
Actually that's not true even in the code. A chain that prints more than 21M BTC is not valid no matter how long it is. 
@_date: 2017-07-10 23:27:58
So now that the problem is identified I assume the chain can move forward now? It should be trivially easy to spam the testnet.
@_date: 2017-07-19 06:59:07
Not really, as has been pointed out by Peter Todd/Luke-jr Segwit2x can even be activated by BIP148/BIP141
@_date: 2017-07-21 14:38:21
Does it occur to you that multiple changes implemented in Segwit2x (e.g bit 4 to bit 1 activation, timeline brought forward, etc.) to make it such that it is compatible with BIP148 comes from somewhere? 
Someone inside NYA meeting definitely threaten to walk out if their demands were not met.
@_date: 2017-05-17 22:10:39
If UASF chain happens to be worth more than original chain, the original chain won't survive, unless someone make a special effort to do so. So if anyone insist to retain the original chain they better start preparing from now.
@_date: 2017-07-05 13:38:50


Yet miner still attempt to patch their client to produce 50BTC after the first halving.
Had Bitmain have their say they will change Bitcoin Core into Bitcoin Unlimited, which will then get remotely shutdown.
Miner doesn't know jack shit.
@_date: 2015-02-02 05:47:19
Feel free to provide rebuttal in that thread
@_date: 2017-07-20 17:31:53


Like what happens here?
Miners are human, they made mistake from time to time.


And yet none of the exchange/payment service provider issues any advisories. That means they underestimate the risks. You can win Russian roulette from time to time but that doesn't mean that it is safe.


No, that is not the default behaviour
You will only have to trust them that they made the correct "modification"
@_date: 2017-07-27 16:30:02


He did an interview with Jihan in Korea:


1. Token is not an alt. 
2. Bitfinex also introduce their debt token so this is not a new thing for them
3. BTU has the support of Bitmain (at least until it crashes and burn) so there is definitely a demand for it.


If this is true why is there no interest from other exchange? Perhaps because the demand is made up wash trading?


My point is that they are hedging. If they already have a hedge I see no reason to compromise.
@_date: 2017-05-28 15:38:24
Some of his contribution still lives on
@_date: 2015-02-26 01:30:58
Well, whatever they came up with would still be inherently less secure than Bitcoin's hard-coded monetary policy.
Quoting Gavin: Complexity is the enemy of Security.
@_date: 2017-07-03 04:29:15
Hashpower follows the price. BU only has 0.11 price of original BTC. Segwit2x won't be any different.
Even as of now btc1 fork is 1377 commits behind bitcoin master.
Exchange won't list the coin without replay. So good luck trading it elsewhere since even Bitsquare won't do that either.
Oh, and too bad wipeout protection is already considered as necessary.
@_date: 2015-03-10 14:07:45
Totally agree with you. Growing Bitcoin ecosystem is a bit like grilling. We need to balance between firestarter (short-term solution) and coal (long-term solution). Not enough firestarter and the fire will fizzle. Not enough coal and the fire won't spread in the long term. I agree that block size limit will need to increase in the short term. I am not sure about the ever-increasing block size part though.
@_date: 2017-07-25 16:12:35
1. With replay protection people don't need to worry about getting replayed (they finally have one after getting scolded continuously for the last one month)
2. I think the best course of action (although economically irrational) is to just ignore the chain. If there's no volume exchange has to delist the coin in the end
@_date: 2017-07-04 10:44:01


It does. Segwit2x is basically Segwit. So unless miners lie when they said that they are going to support Segwit2x we won't have any problem.
@_date: 2017-07-10 14:04:34


This is what is recommended to people who have slower sync time because of slow I/O. A simple search would yield this result
Also worth to note bandwidth still increases, RAM/HDD access speed is not.


Like I said if we completely ignore access patterns


@_date: 2017-07-28 05:43:02
I agree with you but the problem is despite all the communication efforts made during the last 6 months business still doesn't understand the difficulty of implementing such features within the required time limit. You can see and keeps on defending btc1. "Hurr Durr what's so difficult about multiplying by 2" Don't even get me started on Bitpay's unexplainable sudden defection. LOL.
@_date: 2017-07-03 04:36:54


Errr... Actually I haven't seen Coinbase made any statement. And exchanges are not behind it.
@_date: 2017-07-11 03:22:33
Having default blocksize=750 won't cause you to produce invalid block though...
@_date: 2017-07-05 16:48:43


Who creates the repo for full node client then?


It is the same miner that spam the blockchain and creates uncertainty by threatening to fork that drives people into altcoin.


Basically they don't care if people actually buy into their endorsement and running unsafe software. Guess what. That only made people angry.


Satoshi broke it when he added 1MB limit (or for that matter 32MB limit). And he broke it again when he rejected Jeff Garzik's patch. And he broke it again by not coming up and removes the limit. Guess what? Satoshi is a scientist who values empirical observation over anything else. Not his fault that his view changes over time.


Only someone who never contributes can say that. No one does that. There's always a technical argument presented when something getting NACKed. 
@_date: 2017-05-30 12:23:40


No one says so. If BIP148 is not dangerous it would have already been merged into official Core repo. Every supporter of BIP148 knows this. The reason BIP148 is gaining traction is that it is a reactionary response to a power grab.


Sadly BIP148 comes out before BIP149. Had BIP149 proposed first we might gain a better support. But now the ball is rolling it is more dangerous not to support BIP148 than to support BIP148.
@_date: 2017-07-08 20:59:20
OK. Let's do this from the start. Let's say the size of cache is m. Let's say that there are n UTXO in set. The probability of a cache hit is m/n if we just use random cache. You are asserting that we can reduce n to dn/dt if there is enough temporal locality in the usage. The question is if there's enough temporal locality in Bitcoin UTXO usage to justify that reduction. Can you show this?
For all we know of we might have to increase dt by a factor of 2 just to keep the hit rate the same if we increase UTXO size by 2 times.
@_date: 2017-07-12 22:20:57




1. I'm still not sure what kind of risk it possess to the wallets seeing that AFAIK none of the wallet even interacts with nVersion
2. He is assuming that somehow the legacy chain will have lower hashrate even though miner will subject to the market force as well
The only explanation I can find for the real reason behind this is to make it more difficult for light client to choose the chain, which is consistent with Bitmain's power hungry behavior.
@_date: 2017-05-29 15:48:58


That's exactly what Bitcoin is. You need to do buy-in from **Everyone**


Do you honestly think that Gavin made any significant decision making previously? The only time he did that was during BIP16 deployment, even then he seeks feedback from everyone before in the end he overrules Luke-jr. And we all know how it goes. Luke-jr's solution was actually better.
Do you think Pieter Wuille worked on headers-first/secp256k1 based on Gavin instruction? No. Do you think Peter Todd works on Locktime based on Gavin's instruction? Also no. Do you think that Mike Hearn works on Bloom filter or leveldb based on Gavin's instruction? Also no. 
@_date: 2016-10-12 12:41:39
You are the one dreaming. Why do you think Classic and Unlimited fork off in the testnet?(Worst part is no one realize it after a few months, I mean how is that being responsible as a developer?) It is precisely why hard fork is risky
This is on top of the fact that SegWit solves a bunch of other problems than capacity and can be deployed rather quickly 
@_date: 2017-07-20 21:33:12


I am just pointing out on how this scenario could happen, which is in direct opposition to your previous statement


@_date: 2017-07-20 14:29:06
I did. This is your question


This is my answer:


Edit: Fix grammar
@_date: 2017-05-05 09:10:18


Not really. This was his initial reactions:


What made him change his mind? I don't know, maybe the fact that he failed to prevent Segwit activation in Litecoin, or UASF in Vertcoin, or the leaked chat logs being out in the open, or Johnson Lau moved to develop in Litecoin instead, or bad PR in delaying Scrypt miner, or even Antbleed? I think it is really unlikely that ASICBOOST play zero part in this.
@_date: 2017-05-30 10:57:29
Best part:
We will not be open to additional features or **work outside of the group's charter**
@_date: 2017-07-05 15:39:00


After this Bitmain shenanigans we have learned that miners might not be rational. Segwit2x is basically Segwit so they **do** support that. Activation on bit 4 is a blatant attempt to get everyone to switch to their client. As if that is not obvious enough with Bitcoin Unlimited. We need a way to take into account that miner might be having a power trip. (BIP148 works but there must be a better way with less disruption)
@_date: 2017-07-25 10:45:34


(note: now it has been moved to 


Shouldn't be too difficult when you are the one producing both software and hardware.
@_date: 2015-02-01 04:08:57


With 3 days delay and can't happen outside bank's operating hours.


Source and destination country matters. I've been charged 5-10% before transferring around $2-3k. There's a reason why Bitcoin thrives in Phillipines.
@_date: 2015-02-26 03:31:14


Perhaps, we may yet see. However personally I think Bitcoin is already cumbersome enough that adding another layer of complexity that results in a less secure code is not a good idea.


There's less at stake in https keychain because CAs by nature are relatively decentralized. Think Mt. Gox imploding vs Bitcoin imploding. 
Personally I think there are better alternative than adopting cryptos if you still want to retain control (take a look at the top posts).
@_date: 2017-07-11 01:23:02
OK. Run a Core node or Unlimited node then. Verify it yourselves. There's enough transaction there. Or spam them yourselves. See if you can make the chain goes forward. I mean seriously, do you think btc1 defender haven't tried this already? :)
@_date: 2017-07-13 18:50:14


There are hundreds of such scenario. When Lightning Network doesn't grow in the forked chain because people are too dependent on on-chain capacity. When Core finally manages to increase on-chain capacity by 100x which happen to be incompatible with whatever that shitty forked chain produces. When there is not enough fee pressure to keep the 21M BTC limit in the forked chain. When people manage to exploit RCE in the forked chain. When the cartels, being a central point of failure, is pressured by government to start confiscating their Bitcoin. When Core manages to introduce various anonymity feature in the main chain.


Doesn't matter when the software those group ran has an RCE inside them.
@_date: 2017-05-28 23:42:18


And give Bitmain some more money? No thanks.


OR I can refuse to accept coin from an invalid chain. Seems the second option is easier to me.
@_date: 2017-07-06 00:13:57


You can always count on "The Irrational Jihan" to contradict you
@_date: 2017-07-05 11:57:00


False. You are completely ignoring the concept of economic power. It was the economic power who triggers the survival of ETC, not the the hashpower. And running a fullnode gives you potential to be one of the economic power when all the exchanges are corrupt.
You can't be an economic power if you don't run full node.


Because there is no consensus. We could easily fix mining centralization by changing PoW but there is no consensus change on that either.
@_date: 2015-02-05 16:48:06
I believe that Electrum only connect to single server according to Also apparently there's also report on possible privacy leakage on SPV Client:
So you need to trust it to certain extent.
@_date: 2017-07-05 22:28:56


Any less than 300MB and you will sync in weeks instead days. 


It is less than 10 years for 1MB and much worse (&lt;3 years) for 2MB. That is assuming no one does UTXO bloat.


Sync is I/O limited for a typical PC.


Initial backlog started when Segwit gets released. And ends when NY Agreement was signed. Mempool was the worst in June, a period of low volatility that starts since since May.
@_date: 2017-07-05 13:08:05
I don't understand. So you need to produce a valid PoW to commit?
@_date: 2017-07-06 12:04:27


Syncing without verifying is at least 10x less CPU time than verifying. A typical CPU can verify SHA256 in the order of 100k-1M hash/s vs ~10K/s for ECDSA signature verification


USB 2.0? Perhaps. USB 3.0 OTOH is as fast as SATA.


*facepalm* Read the solutions. Increasing the dbcache works 


What? Of course there is. Mem usage scales linearly with UTXO. It is even worse than linear, it is block size * time, not just blocksize. 


No. Dec-Mar period has nearly the same magnitude in increasing fashion.


1. Mempool should be a lagging indicator
2. You don't see the same correlation in May 16 where price increase nearly the same amount.
@_date: 2017-07-04 10:41:46


Unless the problem with data growth is taken care of by gated sync or any other means it is unwise to increase the block size. Creating UTXO is too cheap as it is.


You must be blind.


Every single soft fork does that. Failure with BIP66 deployment is caused precisely by that issue.


If the newer client is backdoored there will be a fork with older client when someone tries something nasty.


NO YOU FUCKING IDIOT. There's only single parameter. It's called weight, which is 4*base+witness. In fact changing MAX_BLOCK_SIZE parameter in the code does nothing. Fee per byte is now replaced by fee per weight, which in the case of legacy tx reduces to fee/per byte because witness is always 0.


Attacks that happen on July 15


No, you don't. Like I said you can attempt to reconstruct unspent inputs from stratum.
@_date: 2017-07-26 17:32:53


The reason is they have to do it overtly. This will open a can of worm since the technology is actually patented. Doing covert ASICBOOST will require you to transfer your entire mempool into the miner and that will waste your bandwidth.




Does not compute


@_date: 2017-07-07 02:56:41


You never run a full node, do you? Unpruned storage requirement has went past that just now... We don't even need 8MB block to reach that.
@_date: 2017-07-26 19:34:11
Why won't Jeff Garzik tell us who fund him then? He is the sole decision maker for the project.
@_date: 2017-07-24 06:34:16
3 months before hard fork and they can't even get all the actors inside the chat.
Seriously why don't these clowns join BCC instead? At least there will be 2 chains instead of 3 now...
@_date: 2017-07-07 03:47:26




That feature is going to be in btc1 too!....not
@_date: 2017-07-02 12:25:33
On (1) basically older coins needs to make a mandatory fee. The older the coins the higher the fee. So it is basically stealing from the hodler.
I'm not that clear on (2) but looks like it is making an extension block where the owner of the current bitcoin receives multiple coins on several extension block.
@_date: 2017-07-25 14:51:43


How exactly do you "link" a demonstration?
@_date: 2017-07-28 05:20:58
Just don't be surprised when they de-list Legacy Bitcoin for Segwit2x though. They are part of NYA Signatories.
@_date: 2015-02-13 08:25:43
Well, the truth is that layer doesn't currently exists. Meanwhile the block size is continuously increasing:
Let's face it, right now sidechains doesn't exist. Not to mention it is difficult to tell whether sidechain is any safer than block size increase. The question is what happen when block size hits the limit while the proposed solution is not yet ready? Increase the tx fee you say? Well now you just damage Bitcoin acceptance among the crowd. Not to mention there will be some backlog of tx that needs to be cleared.
I'd propose a deadline for block size increase. If no one manages to come up with solution once a certain metric (average block size for a certain period of time?) hits the limit we need to increase the block size.
@_date: 2017-07-03 01:22:46


You must be dreaming if you can keep the patch minimal over the years.
1. When Core adds new features like MAST or Signature Aggregation you will have to convince Jihan, Craig Wright, and Roger Ver to accepts it. Fat chance that will happen.
2. Technical ineptitude is the reason that Segwit2x cannot be based on Bitcoin Unlimited. They have to rebase it on Core 0.14.1 instead
3. Add on to that the other side will have their own shitty roadmap to follow.
4. When Core finally proposes a hard fork you might find transaction incompatible with it in your blockchain. A 2x increase now will probably be incompatible with 6x increase later.
5. Segwit already gives you 2x. With 2 chains you will have 2x+4x capacity=6x. Even right now tx with fee as low 5 sat/b is being confirmed. How low exactly do you want your tx fee?
6. Signature aggregation alone gives ~30% increase. Not to mention Drivechain in the work. How much value exactly a 2x capacity adds into a chain? I'm pretty sure you can't even compensate for the technical incompetence. Take a look at btc1 discussion. Jgarzik proposes something that will self partition the network. And then he doesn't know that he needs to change the weight parameter. LOL
I agree with your sentiment though. It's not a big deal. I'm pretty sure you are going to regret it in the future though.
@_date: 2017-07-25 14:16:11


You keep on moving the goalpost. First you want to see the code and now you want a live demo....
You can either contact or (yes multiple people have confirmed this)
I don't own any Antminer HW. I don't see any reason to support any company having power trip.
@_date: 2017-07-07 19:28:38


What? Of course not. Bitcoin Core has sophisticated multi-level cache. You may be describing the validation cache. That is not the only cache in town. There are also pCoinsTip and DBView. Both lives in the memory...
You seriously can't expect we flush every block, can you?


"Good day to you Sir! I SAID GOOD DAY!!"
@_date: 2015-02-13 08:41:39
Yes, I can really see the benefit from your point of view. Now let's take a look from the point of view of your creditor (most likely bank). It costs them next to nothing to lend you money. They just 'print' the money in your account. That's Fractional Reserve Banking for you. In the meanwhile they can receive payment from you plus compounded interest. It is nearly risk-free for them. This encourages reckless behavior. In the case of default, hey it will be mostly depositor who will take the fall. If there are too much depositor the government will help to take the fall (bailout).
So how do we go about doing this? You need Widget Maker (and have a good business plan), and there are people with money doing nothing on their part. How about this:
1. Those creditor (which could be a bank) exchange money for share ownership in your company. Profit and asset will be divided share and share alike. You can buy back some of the shares if you want.
2. The creditor buys Widget Maker and rent them to you. Again you can buy back the Widget Maker from them.
In both cases in case of default you will not be left with 0 assets.
I believe these solutions is much healthier as the creditor's profit will be tied somewhat to their decision. I think this is some of the basis of Islamic Banking.
@_date: 2017-07-11 01:49:50


I don't think SPV node even check for block header currently...
@_date: 2017-07-27 02:17:17


Why don't you do the math?


I am pointing out contradiction in your statement.


You can get someone even before the patent is granted
@_date: 2017-05-17 20:36:22


No the change is not within 1 month. It is within one day.
@_date: 2017-07-19 14:24:39


Not just Segwit, Segwit2x 


Segwit2x (the hard fork part) can be triggered without BIP91, it only requires Segwit to activate.
@_date: 2017-07-11 02:13:17
Not quite. You seem to be in the right file though.
@_date: 2017-07-20 16:13:55


That would still be chaos though, since normal Core node will still accept those blocks.
@_date: 2017-07-07 02:57:26


Completely ignoring block propagation and UTXO bloat? Sure.
@_date: 2015-03-10 23:39:22
I am more worried on the storage side. It is a little bit too optimistic to think that Moore's Law will continue for another 20 years. Pruning is no good for bootstrapping new node. Probably the core devs will find a way to spread the blockchain across multiple nodes.
Edit: I've read your **Bitcoins and a bar of chocolate - Or: How I stopped worrying and learned to love larger blocksize**.


I don't think this is a conservative estimate at all. Right now for semiconductor we have reached the limit for 2D Patterning (EUV is nowhere in sight) and we have reached the minimum thickness possible for oxide (only few layer atom thick). Few big semiconductor player already move to 3D but it is unknown how successful this will be. We are at a crossroad here. If we compare this to Flight Airspeed I think we are at transition from subsonic flight to supersonic from 1930s to 1950s:
(Data from Wikipedia:
,sorry for the glitch at the beginning of the Graph, I'm on Libreoffice and not really sure how to fix that ). Even then they face another plateau around 1960s.
I'm not sure about magnetic technology but I believe they are facing the same problem as well
@_date: 2017-07-27 02:15:52


The question is who is behind the decision to limit the scope in excessive manner. That decision, by itself will ensure that there will be a fork comes November. (Unless you are saying that all 80 members of the signatories actually sign up for it)


Are you insider within the NYA signatories? Because there are private conference calls prior to github merges. There is also private slack that was being scrubbed before it was made public.
@_date: 2017-07-27 15:04:33


I find it pretty funny that everyone over there keeps on yapping about with implementation being the spec with Bitcoin Core and yet did the exact same thing. Where is the spec and the analysis (example: how long can we expect the mempool to fill up, especially in the case of no one wanting to make tx due to uncertainty)? Who is going to be responsible for spamming the network otherwise (Heh, even the fact that someone might have the responsibility to spam really reeks of political decision making similar to create a bill instead of technical one)
Are we going to do implementation first, spec second, and analysis the last?
@_date: 2017-07-13 19:40:31


SPV as defined by Satoshi **can** follow the ruleset by relying on fraud-proof sent by full node. 


transactions for as long as the attacker can continue to overpower the network. One strategy to protect against this would be to accept alerts from network nodes when they detect an invalid block, prompting the user's software to download the full block and alerted transactions to confirm the inconsistency. 
Lack of success in implementing this prevents SPV client from being fully fledged economic power.


No, it doesn't. (Pseudo) SPV client can simply ignore the version bit should they choose to (although only shitty wallet developer will do that).
@_date: 2015-02-01 04:29:43


Yeah, like no one cares to send email when you can send them through post.


Did you actually do it? There are hidden fees everywhere. I've actually made a transfer before.
@_date: 2016-05-24 22:27:16
Can't see anything written on the whiteboard :( Anyone has better quality recording? A little bit difficult guessing around based on what Peter said...
@_date: 2017-07-27 16:24:13


1. Johnson Lau, Matt Corallo, and Adam Back IIRC supports Spoonnet but unless they can convince the rest of the Core Devs that this debate is still about capacity and not about governance it is not going to happen.
2. Spoonnet needs NYA signatories to make it happen. And yet NYA signatories seems to be more interested Segwit2x
@_date: 2017-07-02 22:51:36


Yeah. Because that happens **everywhere**


And no one is going to buy Bitcoin from the main chain. LOL
@_date: 2017-07-20 14:15:11
Well, hopefully they enjoyed bit rot in their software...
@_date: 2015-02-01 03:20:47
Well, as a thumb rule you are supposed to use testnet when trying anything new with Bitcoin.
@_date: 2017-07-19 06:25:33
I assume they were talking about this then:
@_date: 2017-07-27 17:29:57


1. You are aware that not even Segwit does that, right? That is just Bitcoin is. Once you have that, you have a leader, and in a sense Bitcoin has failed. We don't need a Vitalik, not really.
2. Why don't you be that someone? Or for that matter any of the 80 NYA signatories.
For the record I've been spamming spoonnet link every time HK Agreement was being brought up. Where is my backup? Where is my cavalry?




Actually leadership being essential **is** the popular belief. That kind of popular belief is the reason why we don't see any decentralized governance until now. Because people keeps on looking up to find a leader. 
Look at BIP148. There is no leader. Shaolinfry is not a leader, neither is Luke-jr nor Eric Lombrozo. Or for that matter Ethereum Classic. Yet it still manages to achieve its goal.
But then again, if you seek a leader perhaps Segwit2x better suits you.


Until April Bitpay still believes that there is no capacity increase required. So did Bitmain, otherwise they would have activated Segwit. Why should any of the Core Devs challenge the assertion?


Matt Corallo tried to provide a bridge so that a hard fork is more palatable
So did Eric Lombrozo
yet they are being rejected outright.
Again, you should be asking yourself this question: Is this debate still about capacity? Or is it about "Fire the Core devs"?
@_date: 2017-07-27 10:46:21


That's 10K **over regular ASICBOOST**, which is 41K. 
Read jtoomim's comment again:


So it's actually 51K.
We haven't even considered the fact that most of the tx fee are probably generated by Bitmain spamming the blockchain themselves (essentially spamming the networks). Or even the 2048-transactions variants of the method (which requires FPGA/ASIC)
@_date: 2016-05-20 10:54:14
Source??!! I've never heard of this. Are you mistaking something?
@_date: 2017-07-11 01:51:54
My guess is that it is either someone else not related to btc1 or closed source development. Because you won't produce the necessary block by source code in the main repo.
@_date: 2017-07-19 19:33:22


Then miner need to start to understand that they can't negotiate with a decentralized entity in a closed door setting. 


That's what Segwit is
@_date: 2017-07-13 05:18:38
70-30 or 60-40 split won't require another hard fork for both two chains (or even 75-25!).
@_date: 2017-07-12 09:15:17


1. There is pretty much zero chance for CT to be implemented in Bitcoin due to its bloat
2. CT bloat the UTXO, something that we want to keep expensive
@_date: 2017-07-28 05:18:51


That figure is being pulled out of thin air. Don't forget that BCC devs are mostly former BU team, which was funded by Bitmain.


They already have a hedge. Let them use it.
@_date: 2017-07-27 02:13:01


Hard-Forked chain and non-forked chain chain is a real concept. Ethereum actually has to work extra to ensure the co-existence with ETC. That includes redoing all the light clients and web clients.
@_date: 2017-07-11 01:44:37
Well, like GalacticCanibalism said whoever mines that block definitely doesn't use source code from 
Actually it would be quite hilarious if they ignore this and they only realize it when it hits the mainnet
@_date: 2017-05-17 23:06:11
So what? Luke-jr doesn't control Bitcoin Core. In decentralized governance there is no one telling you what to do. Luke is free to do whatever he wants.
@_date: 2017-05-30 10:40:56
Again, how is that racism? That attitude is as common tipping is in the US. You will need to be prepared for that when you're dealing with Far Eastern Businessmen (which unfortunately Eric is not).
@_date: 2017-07-06 23:53:09


Like I said. It was I/O bound. Honestly I can't figure out how you could get a CPU-bound case when you are not even doing signature verification. (unless you are stupid enough to run something like Bitcoin Unlimited)
Even the LevelDB theory doesn't make sense. A database engine so successful (or so crappy) it becomes CPU bound instead?


That is a pretty nave caching strategy... You are assuming that everything not newly created will be immediately discarded.


Actually that is a sure fire of decreasing cache hitrate over time. What are the chances of UTXO will remain hot from block 1 to block n?


*sigh* Because obviously it is not cpu-bound?
@_date: 2017-07-04 10:45:05
Like what happen in BIP66 SNAFU? LOL
@_date: 2017-07-05 04:16:46


Increasing the size of utxo set is reason enough to block that BIP. Even from political perspective it doesn't make sense. These are the reason against Segwit (so far)
1. Not enough blocksize increase
2. Let's Fire Core
3. It's a soft fork
4. Witness discount
For (1), (2), and (3) you won't get anything different by BIP140. For (4) you can easily take out the discount (although people will still come back to (1))
The only valid reason people could change mind is if it is because of ASICBOOST, but that would mean Jihan is lying all the time and it is not enough reason to justify change in strategy. Bitcoin is so un-scalable that anything suboptimal that you do will prevent further scaling down the road. Not to mention future upgrade (IBLT, TXO commitment) will meet the same roadblock.


It doesn't matter. We shouldn't take out 21M BTC limit just because there is not enough on-chain transaction transaction.
@_date: 2017-07-10 23:32:48
That post predates btc1's wipeout protection plan though. And he **did** specify the mechanism there.
@_date: 2017-07-08 13:26:05


Except it's not... The cache is only flushed when it is out of memory... Oh, well.
 \\_()_/
@_date: 2017-07-27 07:00:45


Because those two were ASICBOOSTed that you said has lost some fee due to transaction limit? I don't even know why you are looking at non ASICBOOSTed block.


Only because they are incompetent. A competent ASICBOOSTer won't have any problem with that.


Prior art requires the method to be public. That is not the case with ASICBOOST.
@_date: 2017-07-05 12:11:48
1. Those business makes that decision without consulting their customer. All those pro-BIP148 user can move to exchange that support BIP148 chain when the time come. 
2. Segwit2X is compatible with BIP148 so those "business" actually support BIP148
3. Shaolinfry is not a leader. He can't tell me what to do
4. Take a look at Segwit2x governance process and look me in the eye and tell me there is nothing wrong with that.
@_date: 2015-02-01 05:09:21
Punching a number into online calculator is not equal to actually make a transfer


Western Union is not as flexible as you think. There are times when you have no other options but to use their agent, and that is the very definition of hidden fee.
@_date: 2017-07-02 05:47:28


For a guy who likes to quote Satoshi a lot he seems to ignore it when it is convenient...
@_date: 2017-07-07 19:17:13


Still better than Segwit2x.


Actually in terms of UI Lightning can be surprisingly user-friendly. No clumsy address to put something on to.


Nope. Bitmain has to stop in the end because the fee is too high.
@_date: 2017-07-10 14:25:11


*sigh*. How could it not be relevant when it has been observed by multiple people that changing dbcache setting so that it puts the entire UTXO in memory actually helps?
Would it be better if Core just skip the caching altogether? I don't know. What I know is when you actually uses the default value the sync becomes unbearably slow. What is considered "not-so-low-end" today will become "low-end" tomorrow.
@_date: 2017-07-05 04:14:17
Just roughly memorize at the back of my head of each important date?
@_date: 2017-07-06 00:22:29


If I could figure him out I wouldn't label him as irrational... The only thing I can think of are ASICBOOST, power trip, or under duress from Chinese government.
The first one is rational, but like I said people would be more sympathetic if he frames it as internal technical issue instead.
@_date: 2017-07-05 09:04:59


Provided that UTXO bloat is taken care of, sure. There are some sane proposals out there. But all have been rejected because it "comes from Core".  If they don't want to have Core devs who has kept Bitcoin safe over the years to contribute then sure, just fork away.
@_date: 2017-07-27 12:37:45
You can try contacting the two people I mentioned above. Hell, you might even get support from Bitmain themselves seeing that they actually posted the source code in github (and they already admit on having the chip capable of doing so)
I don't mind figuring things out for you if you don't mind sending me a miner to play with though. :)
@_date: 2017-07-02 15:52:13
There is one big difference in this scenario though. Ethereum has wipeout protection in the forked chain. 
OTOH if at any point in time hashrate in legacy chain continues to fall below BIP148 chain there will no longer be legacy chain. There might be people who tries to quickly sells their legacy coin before it is getting wiped out.
Not to mention that market tends to hate uncertainty. Legacy chain still has to contend with Jihan vs Core's shenanigans for at least another year while BIP148 chain has Segwit activated (which means, amongst other thing Lightning and doubling in on-chain capacity), which means that there is an upward pressure for BIP148 chain.
Of course nothing is known for certain. It is entirely possible that the market is getting irrational that legacy chain survives. Personally I can't wait until Aug 1st.
@_date: 2017-07-02 17:14:14
Strange, how do you know anyone downvoted him? The score is supposed to be hidden. Hmmm....
@_date: 2017-07-24 02:27:07
Why not both? The Troll Extraordinaire Wang Chun already has 148 in his twitter handle (and at one point took out NYA out of their coinbase tx)
@_date: 2017-07-01 18:12:48
ECDSA has 128 bit of security so I would say 128 bit. AFAIK the only thing that has 80 bits of security is P2SH (via birthday) where multisig is affected. Basically the attacker tricks the victim by pretending to give redeemScript that has victim's public key in it while actually having a separate redeemScript by collision that doesn't require victim's public key.
Note that P2WSH is not affected since it requires 256 bits hash so collision still requires 128 bits.
@_date: 2017-07-11 22:53:34
Can anyone up-to-date compare and contrast Peter Todd vs Pieter Wuille vs Bram Cohen's approach on UTXO commitment?
@_date: 2016-07-21 19:20:01


I am sorry I would have used 'we' but it is just a little bit embarrassing to admit at one point I used to defend Ethereum's technology. 
Also to add on, speaking of timelock, actually FBI also had a timelock in form of government bureaucracies (took months until the auction done).
@_date: 2017-07-24 23:40:48






@_date: 2017-07-13 01:00:19
OR Jeff was simply following whoever pays him.


That plan first appears here:


I am not even sure what risk changing nVersion entails seeing that AFAICT most lite client has 0 nVersion interaction. The only "risk" it possess is that lite client can easily select which chain they want to transact in. I am seriously in perplexed by the number of people bamboozled by Bitmain.
@_date: 2017-07-10 22:58:13
To be fair that plan is inside UAHF


I wouldn't be surprised if he came up with this himself
@_date: 2017-07-13 17:46:37
Didn't know it was broken... Do you know if it was in the circuit or in libsnark? I think early libsnark was broken by Gennaro as well. Goes to show how immature snark technology is...
@_date: 2017-07-01 18:30:53
Personally I don't think there's anything wrong with receiving funding from external sources for your work. It's reddit's favorite showerthought that politician should clearly display their funding source on their jerseys like an athlete. I mean, Greg Maxwell, sipa, Jorge Timon, and Mark Friedenbach are being funded by Blockstream. Matt Corallo, Suhas Daftuar, and Alex Morcos are being funded by Chaincode Labs. Cory Fields and Wlad are being funded by MIT. Since the code is open source producing good quality code will be a good PR for the company/university involved.
When the company involved has produced one dumpster fire after another, however...
@_date: 2017-07-27 16:46:48


WTF are you on about?
1. Johnson Lau wrote a total of 3 mails regarding forcenet/spoonnet inside the mailing list and receives exactly zero response. Not from Bitpay, not from Bitmain, not from Coinbase, and not a single one from any of the NYA signatories. 
(Probably more, I think I might be missing some)
This is Matt Corallo's support for Spoonnet
This is Adam Back:
Fuck, even Bitpay is still saying everything is fine back in April before pulling a 360 in May. 
How are Core devs supposed to judge the presence of community support? Are they supposed to read mind?
Now where is NYA signatories support when you need them?


Sorry, the way I see it the rest of Core devs are no longer convinced that this debate is still about capacity
@_date: 2015-02-01 04:52:07


I didn't, I addressed it in the Western Union section below.


Did you use it to transfer to Phillipine? Because if you do you would know that they have different policy for each country.
Also from 
Read the footprint:


@_date: 2017-07-14 03:10:19
The reason the BIP is still in draft status is because the author considers soft-fork-hard-fork approach (e.g evil hardfork) is superior to that.
But attempting to do something like that for Segwit2x will lead to PoW change.
@_date: 2017-07-01 05:58:31


1. 
2. Segwit2x timeline was changed to accommodate BIP148
Apparently those guys are not as stupid as you are.
@_date: 2017-07-05 11:46:09
libbitcoin implements ZeroMQ before Core did.
btcd helps in protocol development
Bitcoin Unlimited remotely shutdown by an attacker
Bitcoin Classic splits the testnet.
Notice the difference?
@_date: 2015-02-04 02:18:41
No, you are not. The only way to be safe is to mine the transaction yourself (and make sure your block is not stale). Even if you broadcast the tx yourself everyone who has seen your tx can make a race to spend your bitcoin. 
Edit: Seeing no one reply for one hour only to have Vitalik faster than me by a minute. Bleh
@_date: 2017-07-06 17:39:22


@_date: 2017-07-10 23:13:34


The one specified by jl2012 here **will**:


Miners also can still make blocks smaller than 1MB post transition too, you know?
@_date: 2017-07-20 14:32:38
LOL. He could just do that if he attempt to sow chaos though. Right now miners are heavily dependent on FIBRE and we don't know how many miners are fake signaling. Bitmain and their henchmen are still not yet signalling right now.
@_date: 2015-02-25 23:15:17
Newspaper's headlines: Central Bank's private key was stolen and published online allowing everyone to change block reward.
Single point of failure is always bad.
@_date: 2017-07-08 13:12:35


When to flush cache is not relevant for the cache strategy? Hmmmm....
@_date: 2016-07-21 15:37:59
1. You are reverting transaction that creates DAO and changing it to something else
2. You are reverting transaction that creates all the splits
3. You are reverting transaction that transfer the ether to darkDAO
How is that not reverting transaction?
@_date: 2017-07-24 06:51:25
It's like United Airlines incident, sure they give compensation after it was brought to the social media, but doesn't mean that there's nothing wrong here...
@_date: 2017-07-25 16:03:52
1. The two persons I mentioned already did just that
2. So did 1Hash apparently
3. Why would you open source something that makes you more money?
4. Why are we still arguing when Bitmain already admit to it?




@_date: 2017-07-22 08:20:55


Any arrangement made in closed door is unenforceable.


Adam said that this is something lost in the original translation. Who is right and who is wrong? Who knows. That's why everyone is against a closed door meeting.


No, it isn't.


Segwit2x has a total of 8MB because the one implements it only know how to multiply by 2. (He did try though, but he stupidly fails to do so)


How exactly "Core" do this? Do they put a gun in your head and ask you to run their software? It's not Core's fault that Classic and Unlimited crash and burn.


This is an economic system where agreement is made based on proposal laid out in the open for the entire community to review, not the one where agreement is made in secret closed door meetings.
@_date: 2017-07-20 16:13:49
Bit rot = no guarantee of long term survival of the chain.
@_date: 2017-05-28 22:40:22
Antpool is Bitmain


Oh, wait you're right though
So it's technically Jihan and Roger Ver.
@_date: 2015-02-17 16:30:35
I would argue that the skillset required to design an ASIC is different than the one required to evaluate a distributed system. 
@_date: 2017-07-04 13:49:16


How is it fictitious? It is inside the bloody source code.


You are not really that bright are you? Maximizing based on block weight is equal to maximizing based on byte if you only consider legacy transaction.


With stratum reconstruction you don't even need to download the whole tx.


No you fucking idiot. The rule is weight needs to be less than 4000000
@_date: 2017-07-11 01:10:34
Here's a hint:
This is a block explorer for testnet bitcoin:
Take a look at the block size, there's enough tx to fill multiple &gt;500kb block for the last 24 hours. How could there not be enough tx to fill a single &gt; 1MB block in btc1? Where the problem lies will be left as an exercise to the reader.
@_date: 2017-07-12 21:59:32
Does BitcoinJ checks for nVersion? Unless it does I don't see the objection for using nVersion to signal. Old BitcoinJ will work as it always does while not using nVersion will deprive people from an option to make the choice, which I can only assume to be malicious. (In the same way replay protection was refused to Ethereum)
@_date: 2017-07-04 23:01:55


That's what Segwit is, 2MB expected with 4MB max. Here's the author of the study's comment on the paper:






@_date: 2017-07-03 04:45:09
Well, let's just hope it doesn't end the same way as Bitcoin Classic:
@_date: 2016-07-30 14:07:11


Monero did periodic hard fork. Ethereum did Frontier-&gt;Homestead. 100% agree.
@_date: 2015-02-13 12:41:36


Unless the reserve ratio is one it is effectively printing money. Nothing is backing it up. That's why there's the term bank run.


Can you give me an example? There are other financing options.


The rent should take into account that the assets is depreciating. Besides, in real economy one should make careful consideration when purchasing depreciating assets, as it should be.
Edit: Fact check:
It actually works.
@_date: 2017-07-07 03:21:50


The reason BIP148 doesn't have any visible support is that because most actors still praying BIP91 will comply with BIP148. Once any of the miner pull back you can expect people to switch to BIP148.


The last I check Jeremy Rubin, Mark Friedenbach, and Luke-jr are opposed to BIP149. Most likely it will take several months of infighting before that is going to be merged.
@_date: 2017-07-08 13:54:48
Apparently Eric Voskuil disagree with that assertion...


continuous nor strictly segregated by usage.
@_date: 2017-07-05 22:41:41
I wouldn't call a power trip rational. Defending ASICBOOST is rational but
1. He has denied it
2. People would be more sympathetic if he comes clean about it or at least fake it as internal technical issues instead of coup attempt.
@_date: 2017-05-29 04:41:10
Those are the one running Bitcoin Unlimited. The others are still running Core. UASF will let them choose.


@_date: 2016-07-21 19:02:20


Ethereum community?


Those 3 transactions I mentioned are reverted.


Not Mt. Gox, Ulbrich. FBI is stupid enough to use a single address. Would have been easy to revert them in this case.
@_date: 2017-07-02 17:09:00


Are you implying that Craig Wright does? Because God have mercy on you if you do...
@_date: 2016-07-20 07:47:28
It's been a while since I last used libbitcoin so I'd welcome any correction from those more knowledgeable than me.
My understanding is Bitcoin always uses little endian when doing serialization. 
I would assume that you are using decode_hash for things it was not meant to(I think it was meant to decode/encode hash from a block/tx). Normally people would use random function as an input to secret parameter. If you are using them as a learning tool maybe you can create your own converter?
@_date: 2016-05-20 22:05:55
Nope, you're mistaken. That feature is Frontier-only and it is documented, like here:
The purpose is to prevent miner from mining on the wrong fork when consensus is still unstable. It is already removed in Homestead. Besides, miner can easily remove those from the code and still mine even after canary is triggered.
@_date: 2017-05-26 07:00:18


Except the only one who refuse to signal for Segwit is backed by Bitmain. And now they want to expand to exchange:
As well as development:
Tell me that is not an effort to centralize.
I am okay if they actually produces good idea. But that remains to be seen. BU is a nightmare. Extension Block breaks fungibility.


Are you going to accuse Blockstream again? Completely ignoring MIT, Chain Code Labs, Ciphrex, btcd, libbitcoin, independents?
Edit: Also those who keeps on chiming Blockstream funded by AXA, have you ever wondered who funds Bitmain? They seems to have unlimited source of fund.
@_date: 2017-07-11 01:35:58


You can replay the transaction. AFAIR replay protection is not yet out.
@_date: 2017-07-02 16:18:16


UTXO bloat for one. Eric Lombrozo and Matt Corallo offered some of the solutions to avoid this and get rejected straight.


It has been done in BIP16 deployment. Tycho, who owns ~51% of the hashpower disagrees yet it gets deployed anyway.


[Do you understand how to read chart?](


Do you appreciate that there has never been any case of hard fork in Bitcoin outside the attempt to mitigate a crisis? Do you appreciate the fact that people running a very old client to sync will help to ensure there is no backdoor in the newer client?


[took a painstaking effort to explain it to you how this is not true but apparently you are going to repeat it anyway]( Either you are too dumb or too malicious.


Do you understand that the increase to 2mb enables more dangerous spam than what Segwit enables? 


1. Did you know that the same miner can do the same with stratum? (yes, you can reconstruct the tx from the stratum template)
2. [Did you know there is an easy fix to this problem?](
@_date: 2017-07-08 13:40:34
Guaranteeing rate of flush the same != guaranteeing hit rate the same you know? Especially if rate of flush depends on hit rate...
@_date: 2017-05-22 12:43:29


Any BU proponents should have lost credibility long time ago. I'm not sure if there's any members who spoke against BU.
@_date: 2017-07-05 15:09:48


(Bitmain could have supported this instead of shit that is Bitcoin Unlimited, tell me how this is not power trip)


Lightning is still faster than hardfork. Bitmain's shenanigans cost us at least 6 months delay.


It already gains traction. 


And yet Bitmain has no issue at all spamming the blockchain. Again tell me how this is not power trip.


Signature Aggregation doesn't require hard fork. Neither does MAST. Or for that matter Drivechain. And guess who delays that for another 6 months?


Which crypto? Ethereum breaks down when it comes anywhere near Bitcoin's capacity. If there's anything I am afraid of it is Litecoin (and guess whose fault is that they gain an edge? Oh, yeah the same party who attempt to withhold the Scrypt ASIC to prevent Segwit from getting activated. Not a Power Trip^TM)


UTXO is growing faster than technology as it is.
@_date: 2017-07-01 10:11:09
Basically you will still need to break ECDSA. Birthday attack is not enough. (for P2WPKH, P2WSH has 128 bits security)
@_date: 2017-07-05 13:06:41


Wrong. Small consumer nodes can turn into economic power. That's how Ethereum Classic start.


No one raising valid objection. Had Bitmain stated their ASICBOOST as reason for objecting people might be more sympathetic to their cause. But they had to turn this into power play instead.
@_date: 2017-06-03 13:38:25
We were talking about full block, remember?
@_date: 2016-05-20 23:21:59
Do you see anything on the main program that actually make reference to it? Most likely just leftover. I can't find anything on go-ethereum repo that is equivalent. Still doesn't change the fact that miner can remove it. It doesn't declare any chain to be invalid, it only stops mining process.
@_date: 2016-05-21 16:51:26
I've seen people posting the same thing about Electrum.
The thing about fee estimation is it is difficult to predict a surge and whether it will be permanent. Let me give an illustration for a worst case scenario. You want tx to be confirmed within 1 block. Mempool shows the maximum fee density is 50 satoshi/kb. So you send tx with 51 satoshi/bytes. Everyone else sees this and start spending 52 satoshi/bytes and you get 1MB worth of tx all with 52 satoshi/bytes. So you get bumped, it's ok you might get confirmed next block right? Not really, because you might get another 1MB worth of tx between now and the next block with 52 satoshi/bytes. So when will it get confirmed? No one knows exactly how long. At worst case fee is permanently at 52 satoshi/bytes and your tx will never get confirmed.
Sure you can RBF your way out of the situation but you will need to stay online to make the transaction (and not fire and forget). Of course you can also nlocktime a transaction with higher fee at later block and give it to third party to deliver but at this stage it is simply just overengineering (not to mention you need a third party)
@_date: 2017-07-10 22:55:42


Yes, or alternatively stop mining until there is enough transaction in the mempool.
@_date: 2017-07-25 09:14:08


Not a native english speaker? Support=have. There are people who have actually tried the functionality. is one of them.


I worked in semiconductor for crying out loud.


No, it doesn't. Some of the circuitry can be shared.


It makes sense if you have your customer unknowingly pay for the chips and you have technical lead.
@_date: 2016-07-03 15:35:53
Sorry, just feeling a little bit pedantic.


adiabatic is not the same as isentropic :)
@_date: 2017-07-05 14:16:11


That's a big **IF**. Seeing no Core Devs is on board (even though they provide reasonable proposal) it is unlikely to be the case. 
Segwit is already a blocksize increase. Since they want blocksize increase they should activate Segwit. Irrationality doesn't have place here.


Of course it is. Closed door meting. You know those are the same people who supports BIP109, right? I guess we will just have to drill the same lesson over and over again. 
@_date: 2016-07-20 13:16:19


Well, it is not that surprising, considering that is Ethereum's endgame after transition to PoS.
Just a little bit of snippet:




I just didn't expect the trial run would begin so quickly.
@_date: 2015-02-01 01:53:00
Bitcoin actually support limited scripting. 
@_date: 2017-06-03 09:59:27
Eh, I'd say let them be. I hope that teaches them that consensus building is not equal to stalling.
@_date: 2017-06-02 06:27:06
I can have only 1 cake but not 2 cakes so I refuse to eat any cake at all. Because logic.
@_date: 2015-02-08 14:12:46
I believe is a pretty trustworthy member of community but for good security practice please save the source and run it from (for best result, permanently)offline (disconnected from internet) computer. It is good to make it a habit to be cautious.
@_date: 2017-06-03 09:21:47
@_date: 2017-06-14 21:38:45


The lead maintainer doesn't have power. Wlad supports BIP148 but he won't merge it because he doesn't have full support. If he actually attempt to merge it he will be kicked out like Gavin. Similarly if he attempted to merge Segwit2x he will also be kicked out. You can't keep on repeating a lie and expect that to turn into truth.
@_date: 2017-06-02 06:39:09
[tinfoil hat mode on]
Sequence of event:
Perhaps a temporary truce. But BIP148 supporter shouldn't let their guard down.
@_date: 2017-06-21 18:43:22


If you want compare then compare peak to peak (or at least average). Peak Bitcoin is up above 300k. You didn't even bother to mention that you are comparing within the same day on your original statement:




Again, you are barely within Bitcoin's ballpark capacity. And right now you are experiencing **another** backlog. And what you consider a "remarkable day" is actually a "normal day" in Bitcoin.


You **do** understand that unlike transaction per second recorded in blockchain a "backlog" is relative right? That would depend on how much you set the relay fee to be. I can set relay fee higher than 1000 sat/byte and I can have a 0 backlog. Similarly I can set my relay fee to 0 sat/byte and get myself DoSed to death.


Because of inflation. Even then you are seeing increased uncle count by roughly 25% from the time you start to hit 75%-80% capacity.
 
But unfortunately you wouldn't understand that metric and it would be a waste of my time to explain it to you.
@_date: 2016-07-31 00:34:05


Not if they deposit ETH post fork.
@_date: 2017-06-16 14:35:04
I don't care who supports the chain. Segwit code is open source and I can see all the improvements it will bring to Bitcoin and none of the backdoor. The beauty of open source code is that you can evaluate the change itself. The US government could say tomorrow "I will support Segwit chain" and I couldn't be careless.
@_date: 2017-06-18 12:55:16
That is **not** including the amount of money they made from currency spread.
run one such business.
@_date: 2017-07-27 18:08:17


1. There is no such a thing for Ethereum Classic.
2. So you are saying those two people plays more part than let's say Samson Mow? IIRC even Bitcoin_Bug is more active in reddit than both of them


So whatever Matt Corallo, Adam Back, and Johnson Lau has done is not enough? Or what I did? What more could we do? Because I definitely feel that I've done more than my fair share to promote that solution. The only reason it fails is because no one rallies around us. 
For that matter do you know any reason that Barry Silbert chose Segwit2x over Spoonnet? He could have slap a flag day and still get a better thing than Segwit2x
@_date: 2017-06-13 10:26:56
It is in miner's self interest to print more than 21M BTC if they knew for certain that the drop in price will justify it. That'd just mean they are hostile.
@_date: 2017-06-08 06:43:11


Also 3 working days to reach your destination and can only start at working hour though. Not to mention any larger amount will bring more scrutiny toward you (e.g  &gt;$500K) and in the end you wind up with a depreciating asset instead of appreciating one. I think a lot of people underestimate the unique value proposition of Bitcoin. But like Adam said let's try to keep the fee reasonable for now.
@_date: 2017-06-11 00:39:33
What are you going to run then? Bitcoin Unlimited? LOL
@_date: 2017-06-08 14:46:19


By your definition miner wants 1MB block. Because that is what is happening now. If you want more capacity Segwit is there. Even if you want more capacity you should activate Segwit first then fight another day.
There is just simply **zero** reason to delay Segwit (well, except for ASICBOOST). Let's say it's because they can't trust the devs. So how is delaying Segwit going to change dev's mind? They have even indicated that they are not in a rush to get Segwit activated. 
You know the only one who lose? The users of Bitcoin.
It's really difficult dealing with irrational people...
@_date: 2017-06-08 16:02:05


Yeah, you can see how well it goes for QuadrigaCX.


Alts don't have the same dev team nor governance. If UASF failed that is one of the thing in TODO list.
@_date: 2017-06-03 13:42:32


It is difficult enough maintaining infinite locktime channel with full blocks and now you wanted to add finite locktime channel management.


It is ready enough for 0.042BTC
@_date: 2017-06-21 17:37:42




It only reaches that figure for a month based on your chart and yet it already faces issue 3 times. Worst part is it brought down some of the exchange. Bitfinex was also affected.


Errr... No it isn't take a look at your own chart.
It is only **equal** to BTC.


My computer's resource is a limit.
@_date: 2017-06-03 13:20:24




That's why you shouldn't spend too long in It makes you dumber everyday.






The amount of locktime should correlate with the risk. How to quantify that? Well we never know if we never see how Lightning does in real network...


The fact that running a large amount on hot wallet would be enough to discourage anyone from doing so. You can ask how well it goes for Bitfinex.


The Bitcoin we know so well **works with 1MB blocks**
@_date: 2017-06-16 17:27:39


Never heard of anyone said that? Perhaps you can provide a link? After all changing PoW eliminates wipeout advantage.


Only if miners are hostile.


LOL. The other side practically decide to do HF **unconditionally**


Inability to make PoW change can be detrimental, especially if miner decide to make more than 21M BTC.


If it becomes incompatible miner will jump ship to BIP148.
@_date: 2017-06-16 16:50:29
If pre-HF chain worth more than post-HF chain that number is bound to change
@_date: 2017-07-28 05:17:46


And.... where is that? At the very least the spec should give a link there.  Take a look at BIP141, 142, and 143. They refer to each other by link. 


And.... where is that?


It **is** relevant as it serves an economic purpose.


I don't have an analysis ready because I am not the one proposing hard fork


*Sigh*  That is what is being proposed as part of hard fork, same discount applied to legacy transaction, keep the segwit part the same. 
I am not even sure you even that understand the reason behind segwit discount is to keep blocksize below 4MB, so Segwit2x already violates that.


We're talking about science here. There is a real difference between O(n) and O(lg n). Spoonnet actually implements more proper accounting for hashing, permanent storage (utxo) as part of its cost strategy instead of "hurr durr let's multiply this by 2".


And segwit2x is ready? As if. Spoonnet is never going to be ready when you keep on chasing stupid solutions like Unlimited, Classic, Segwit2x, or ABC. Spoonnet's draft is up in February. As for Segwit2x, well let's just say the last I check Sergio's proposal still attempt to "increase" base block size foolishly.
@_date: 2017-06-21 16:14:36
New node that turns up most likely use fast-sync though. Essentially different security model than Bitcoin which depend on the miner/EF's checkpoint.
Seeing that no one bother to check the last HF's spec that it causes a chain split this could be pretty easily corruptible.
@_date: 2017-06-08 15:11:49


Then they should tell loudly and clearly what their objections are. I want more capacity is not a valid objection as there is nothing to be gained by blocking Segwit.


Oh, hey. Another one that doesn't affect ASICBOOST(on top of increasing the size of utxoset) which you have been pushing all along. Maybe you should try to sell that to Jihan. I heard he pays good money


Except people who do so have demonstrably proven to be stupid. Even you have already discredit yourselves when you were pushing for BU.
@_date: 2017-07-26 19:57:05
The status quo is the one who owns the original blockchain. People can fork anytime they want provided that they do what is necessary to co-exist with the original chain. 
Most of Jihan's pet project (BU, Segwit2x) has refused to implement replay protection and changing block version number because they want to reuse original chain's resource. The only reason Bitcoin Trash finally implement replay protection is because all exchanges refuse to list them otherwise.
@_date: 2017-06-03 12:18:16


It is too late so let's delay it even further. BU-logic


Litecoin block is nowhere near full, hence there is no push to use segwit address.


Yeah? Tell me which solution is available right now that doesn't require malleability fix.


Just because you repeat it doesn't make it true. 


You do realize that there is one in the pipeline right? The one that waits for data from Segwit?
@_date: 2017-06-16 13:04:20
I would love for that to happen. I can see someone walking out already...
@_date: 2017-06-21 17:12:25
In my country a lot of think are being sold in pre-paid manner. Utility (e.g electricity) and mobile phone bills are two examples of them. IIRC MPesa works the same way (don't quote me on this though)
In fact paying in pre-paid manner is the only logical way in a system that doesn't allow credit.
@_date: 2017-06-08 14:33:05


And Peter Todd would have supported it? Or David Vorick? Or Nick Szabo? Or Alex Morcos? Or Suhas Daftuar? Or Loaded? Or BearWhale?




If Bitcoin users who has been demanding more capacity is not user
miner don't need to listen to user. 


Similarly I'd advise miner to be more user oriented toward activating upgrades, as it tends to less likelihood of them getting fired.


On top of pushing broken solution like BU who is blocking progress now?
@_date: 2017-06-08 14:37:50


There is no way to measure consensus. Satoshi could come post-fork and say 1M post-fork BTC for 100k pre-fork BTC and vola you have two chains.


Like I say, servants. Similarly devs also provide service that they are free not to use.
@_date: 2017-06-21 15:43:02
Like I always said I will believe it when I see it. Definitely not before.
@_date: 2017-06-21 13:14:29


Not running in mainnet right? Not ready in my book


Signaling on Coinbase not on Bit 4. Do you understand the difference? One will trigger activation the other doesn't. 


Jihan is also attempting to fund ICO for HF. We can't hold him to his word.
@_date: 2017-06-21 13:30:06


Bitcoin is actually taking 10k tx/hour. So I'm not really sure where you're getting 70-80% on normal day figures from. If anything peak ETH=normal Bitcoin.


It was cleared because Ethereum doesn't need to sustain the same tps as Bitcoin on normal basis. 
@_date: 2017-06-07 22:55:00
It doesn't make any sense though. There is literally no change required to the Core software apart from those already merged (well, except by making previously non-standard tx standard but Luke-jr already mentioned that it won't be necessary). By the same logic federated sidechain would require BIP...
@_date: 2017-06-21 17:50:20


If that figure is true that would be totally hilarious. The whole point of BIP91 was so that we can get segwit activated at lower threshold. If 95% is achieved then we might as well activate using BIP141...
@_date: 2017-06-02 06:37:22
Ethereum Classic survives because GPU is far more accessible than ASIC. When everyone thought that the chain will die a few dedicated people that mines at a loss (including myself)not knowing whether the chain will survive. Had Bitcoin faced this scenario I wouldn't be able to help because my GPU won't be able to do anything worth mentioning.
@_date: 2017-06-21 16:11:45


Like it or not block space is limited.


Because there is an inflation. Without inflation miner has incentive to orphan the previous block.


This is not the first time this happen. Same thing happen on Bancor ICO (which happen on June 12, the date you state that Ethereum reaches parity with Bitcoin)
@_date: 2017-06-16 14:01:12
You mean only after BU crash and burn, Segwit activated in Litecoin without issue, Extension Block dies in flame, Antbleed was revealed. Yeah, after people wiped the floor with his face he agreed. Even after that he is still attempting a last ditch effort to do another HF without Segwit. 
Yeah, LOL. I was not born yesterday. I'd believe that he agrees **only** after Segwit being activated
@_date: 2017-06-12 02:36:23


Of course it is relevant. We are talking about conflict of interest you dummy.


You are setting up an online shop here of course you have to be online. Are you saying that right now people put up irreversible payment even though the goods may not be available or the seller is unresponsive? People are more stupid than I thought...
@_date: 2017-06-16 13:40:01
That would be unfair to Bitfury, Avalon, and everyone else who bought from Bitmain but not using ASICBOOST. With that being said BIP148 was meant to be a loyalty test. If no support then PoW change is definitely on the table.
@_date: 2017-07-03 04:24:58
You will need replay and wipeout protection as well you know? That, by itself might render yourself incompatible with any future core updates. Not to mention whatever shenanigans they have in mind (e.g Lumino, Bitcoin-NG, Lightning-protection, etc.)
@_date: 2017-06-13 07:53:01
Just calling spade a spade. Bitcoin Core is flawed in that it doesn't expect 40% of the hashrate is hostile.
@_date: 2017-07-10 22:53:42


The mining code should synthetically be forced to produce 1MB block, otherwise they will be mining invalid block. Are you saying that miner unexpectedly spending hashpower to lose money is okay?


No, the problem is not that miners can fake it, the problem is that they have a habit to screw around with it that there is a little bit uncertainty that the transition will not be as smooth. But it  definitely beats creating 1MB block.
@_date: 2017-06-03 13:37:41
Doesn't invalidate my comment though. 


Simpler and cleaner also means more secure.
@_date: 2017-06-16 14:57:11


If there's enough hashpower there won't be PoW change. I don't see the problem there.


I think the message would be clear enough. You piss people off, people will piss you off. Better to tread lightly.


Why would he? That would be stupid. He has his own battle to fight in the original chain. Splitting his force would be totally stupid. He controls Litecoin ASIC and yet he can't win the battle there. GPU battle would be even tougher to fight. OTOH if you keep SHA256d Jihan can easily screw with your chain if there is not enough hashpower.


Again PoW change only happen if none of the other miner (e.g Bitfury, P2Pool, BTCC) refuse to support BIP148. Rogue miner would need to control 90% of the hashpower to trigger something like this. If BIP148 chain has 10-15% of the original hashpower that would be more than sufficient due to the snowball effect.


Luke-jr already prepared a Keccak one. Sure it will probably lead to another ASIC but hey so long as I'm getting rid of Jihan.


Anything less than 10% hashpower and you will be at risk of Jihan's attack.
@_date: 2017-07-05 10:35:08


And how much time do you think we have? To sync at reasonable amount of time it took 100MB of memory last year. Now it requires 300MB. This is at **constant** block size of 1MB. That number is expected to grow even at 1MB. 
We also need to take into account adversarial case. July 2015 attack manages to eat into 2 years worth of normal growth's allotment. We haven't even talked about memory price increase this year. That's about the third time the price increase in the last 10 years or so. We are already at thin ice as it is.


Yes, and we don't have them yet. It's like we don't have solar, wind, or nuclear but let's not pay carbon tax anyway.


Only to avoid embarrassment of being forced to activate Segwit not on their own term. I wouldn't be surprised if some of the miners (e.g BitmainClub/BitFury/F2POOL) threaten to walk away if their request is not being fulfilled.


I guess they could list additional capacity from two chains resulted from the fork as pros now. I mean seriously without Bitmain jamming the network with spam the capacity is at all time low right now. What do you need all the capacity for? 
@_date: 2017-06-16 18:45:50


Perhaps that's because your use case is better suited with other payment solution.


SWIFT is 30$, can only happen during working hours and 3 working days for transfer. WU is somewhere around ~10% for $1000 transfer plus currency spread. Stop being overdramatic.
@_date: 2017-06-14 21:57:50


Both have the same effect. Do you think people will still run Core if it only has Wlad in it?
@_date: 2017-06-03 13:23:10
Guess who has debunked that?
None other than Jihan himself
@_date: 2017-06-21 19:09:19
Claiming P !=NP is much easier though. At least people won't bother to ask you to convert an NP algorithm to P one. :)
@_date: 2017-06-08 14:11:56


Would have been stupid for that seeing that none of the original proposal has any replay protection.


1. Miners are not users, they are servants, just like the devs are. Users are people who either use Bitcoin as store of value or payment rail.
2. Unlike miners, devs are not being paid to contribute so rightly there is no right for anyone to demand anything.
@_date: 2017-06-21 16:22:59
A full node that is willing to run whatever Ethereum Foundation release without a thought is useless...
@_date: 2017-06-16 15:21:15
Code is here:
Guess what? They even contributed to Segwit2x




But hey, if you want to leap without looking go ahead. Just don't bring me with you.
@_date: 2017-06-14 23:44:42


@_date: 2017-06-08 16:03:12
That means they are stupid. Bargaining against whom? The dev? They already **explicitly** stated that they are in no hurry to get Segwit activated. The only one to lose in this scenario is users.
@_date: 2017-06-12 02:05:01
You mean the very same thing that causes testnet split?
@_date: 2017-06-08 11:25:02
1. The argument was whether people are willing to pay $100 for a tx
2. There is no requirement that says that Bitcoin has to be used on regular basis. It is what it is. How people used it Honey Badger doesn't care
3. Apparently you didn't even bother to read my last sentence
@_date: 2017-06-21 13:20:48


Released code != any random code.


Of course it matters. The same miner that signal in coinbase may back off when it comes to bit4 signaling. This is why people suck at adversarial thinking.
@_date: 2017-06-16 17:59:19
Anything with 3 months for a hard fork as part of the proposal deserve to be mocked. 
@_date: 2017-07-05 13:25:19


Politics have no place in Bitcoin. A proposal should stand on its own. If a proposal is good activate, if it is bad don't activate. If that is truly the case I hoped he learn his lesson this time. Power trip will get you killed here.
@_date: 2017-06-13 11:15:16
While that argument hold some ground that is not the main crux of the original argument. OP accuse that Eric Lombrozo has conflict of interest while I'm simply pointing out that miner has the an equal conflict of interest and Luke-jr does not. Not to mention I've never heard of Eric's name even once while I was active in ETH community. I'd think that his involvement would be quite limited.
@_date: 2017-06-16 18:08:40
Not to mention replay protection would probably require wallet to upgrade/be rewritten as well.
@_date: 2017-06-13 11:07:23
By your logic USD would be worthless yet it is not.
@_date: 2017-06-02 07:35:26


You mean the one where they are confused what the agreement was about until the last minute?


Because I don't want to get fat. Not to mention I can get a healthier diet on fruit once I get sufficient calorie from Segwit.


Says who? Jihan is buckling.
@_date: 2017-06-14 22:02:05
If there is demand for UASF chain miner will come.
@_date: 2017-07-18 21:55:50
This discussion didn't even have a technical content to begin with...
@_date: 2017-06-10 00:19:29
Actually he hasn't contributed for so long he has no idea how Segwit works:
@_date: 2017-06-16 17:59:10


All the exchanges are excluded for a starter.
@_date: 2017-06-16 13:55:51


Yet you just said that you don't see anything inherently wrong with ASICBOOST. 
@_date: 2017-06-16 19:07:51


Doesn't matter. People still use them.


And when is that going to be?
You seems to underestimate the difficulty of setting up international payment. I live in Asia and I can't receive neither SEPA nor Alipay nor Wechat.
@_date: 2017-06-03 09:18:29


QuadrigaCX still has to eat shit because Ethereum fails to provide replay protection on the first HF.
@_date: 2017-06-16 17:49:26




1. Those two groups are not the same people.
2. SF is safer than HF


Not sure about your definition of contributing positively but asking more time for test and review is contributing positively in my book.


No replay protection no UTXO bloat protection no wipeout protection. This point has been rehashed ad infinitum
@_date: 2017-06-10 13:34:02


Let me remind you that there are times when status quo can be harmful. An example would be quantum computing. Sure you can reason but anyone would be convinced that a break in ECDSA would be enough to convince anyone to upgrade but you have one flawed assumption, that is everyone is being rational. The current situation shows otherwise. Everyone already agreed to Segwit (yes Segwit2x is segwit) and yet it its not activated. 
In the meanwhile the party that controls 40% of the hashrate benefits everyday Segwit is not being activated while having enough money to bribe everyone not to activate Segwit. Bitcoin fails when there is big enough centralization and evidently we are heading that way. Even Peter Todd has enough sense to sell while GHash.io was holding that much hashpower.
A lot of people thinks that Bitcoin compete with gold for its stability but these people can't be any more wrong. Take a look at Ethereum. It is a piece of shit that breaks every now and then and yet people continue to pump money into it. Right now Bitcoin is a high risk investment. Maybe in 100 years it can compete with gold but now is not the time for complacency. 
If Matt Corallo or Alex Morcos or Greg Maxwell wants to continue the fight down the road that's fine by me. But it won't be my fight and all I can say is good luck to them.
@_date: 2017-06-21 13:35:39


Read Bittrexx statement again.




Here's the deal. In Ethereum's account based model the same "account" need to execute in order. So let's say you want send 5 ether to person A and 10 ether to person B it has to go in **specific order**. So let's say you arrange it such that tx to person A goes first. Until this transaction is mined you can't send to person B. 
The problem is that if txA doesn't pay enough fee you can't send to person B no matter how much fee you paid because it depends on txA getting mined.
This is not a problem in Bitcoin since each UTXO can be spent separately with no dependency.
@_date: 2017-06-13 02:06:31
There is no code whatsoever though...
@_date: 2017-06-08 00:00:04
It's a tad bit confusing now though. Does federated sidechain needs BIP? How about Peter Todd's OpenTimestamp? In HTLC pull request brought up yesterday it was mentioned that making non-standard tx standard doesn't require BIP. 
@_date: 2017-07-27 15:32:50


Well technically it works, just that you need to wait 29 hours for it (and run non-stock btc1 software)
@_date: 2017-06-20 16:16:10
In case you haven't noticed Eric Lombrozo and Matt Corallo offered their services and was promptly rejected. To me this indicates one of the following possible scenarios
1. Stalling tactics by Bitmain
2. "Toothless tiger" effort to save face by Bitmain
3. An effort to kick Core devs out of decision making
In all three scenarios only one right thing to do. Ignore them.
@_date: 2017-06-16 13:49:12


Did you just completely ignore Chris Belcher's point 
@_date: 2017-06-04 09:47:32


BU supporter doesn't seems to oppose them. If only they have enough guts to pull it off...


The market will determine how the devs do in a feedback loop
@_date: 2017-06-14 22:31:20


BIP148 vs BIP149 is one such scenario and we know how it goes.


ACKs and NACKs on the pull request.


A very limited degree. Definitely not nearly enough to do things Jihan like him to do.
@_date: 2017-06-21 17:03:36
Vast majority != all. I know some people who is syncing without checkpoint enabled or still uses a very old versions out of paranoia. OTOH People are gobbling up whatever Ethereum Foundation release without a thought for every hard fork. 
@_date: 2017-06-08 00:10:56
BIP is for documentation, because the alternative is under-specified bullshit like the mess that is NY Agreement. It is pretty easy to get a number.
@_date: 2017-06-12 01:00:21


It is so simple that it causes two separate incidents already:


Satoshi didn't know about UTXO bloat, nor quadratic hashing


Backlog is required to maintain 21M BTC limit


Only as complicated as necessary to avoid both quadratic hashing and UTXO bloat.
@_date: 2017-06-13 11:07:08
By mining two different coins they can pick winner and loser by hedging. By mining both Litecoin and Bitcoin Antpool has a backup plan if Bitcoin fail. OTOH a Bitcoin maximalist only have BTC as a fallback plan. I can't believe I have to explain to this to you.
@_date: 2017-06-16 17:45:40




Exchanging replay protection for "more support"? That is simply unacceptable.
@_date: 2017-07-12 08:24:22


Pretty sure miner won't agree to wait more than 1 hour having their equipment doing nothing. 
@_date: 2017-07-27 14:38:41
I am sorry I thought NYA was about compromising with big blocker. Every big blocker already left for Bitcoin Trash now. Who are we compromising with now?
@_date: 2017-06-18 13:21:04


1. We were talking about WU
2. They won't tell you about currency spreads upfront. But if you check their spread is not so competitive
3. They **do** have minimum fee


You kept talking about **between** national currencies meaning international transfers, right? Like I said run multiple Philippines corridor (rebit.ph IIRC) and yet it remains profitable.
@_date: 2017-06-18 12:57:04
That is highly dependent on country of origin and destination. Some corridors are easier than the others.
@_date: 2017-06-08 00:06:53
Well, at least so far all BIP has its interaction at layer 0 (e.g wallet, consensus, implementation, network message, etc.)
I mean BIP70 and BIP38 can technically be implemented in Bitcoin Core.
@_date: 2017-06-03 13:45:14
Sure, but Litecoin doesn't need them so there is no incentive for them to use it. I thought you were complaining about not enough capacity?
@_date: 2017-06-13 02:07:06


There are fast storage (memory) and slow storage(hdd)
@_date: 2017-06-21 16:19:39
Well incoming tx also comes from other user's outgoing transaction, who probably faces the same problem with the ordering.
@_date: 2017-06-16 14:32:46


1. I don't mind being an altcoin if it meant taking Jihan out
2. It is your choice if you want to fight for BIP149 against Jihan. In the meanwhile the other chain wouldn't be wasting time making progress by leaps and bounds. Don't be surprised if you see some of the prominent Core Devs jumping ships though.
3. That would only happen if none of the miner support BIP148


1. So long as the chain has value people will have incentive to secure it
2. That will teach a lesson for future miner not to go against community (e.g increase 21M limit) 
@_date: 2017-06-21 17:09:03


Guess where will pro-segwit miner go when Segwit2x fails?
@_date: 2017-06-13 21:21:24


My point is that something that started as having value because of limited supply can still have value when it is no longer scarce.


They actually did actually. Back when the reward drop 50BTC drop to 25BTC some miners actually attempted that. What they could do they would do.
@_date: 2017-06-16 16:24:22


Now guess what happen when Segwit2x blows up. You know? Like Jihan backing out for some bizarre reason? Yeah, that's right. Everyone on the fence will move to this side.


Destroy their entire business? How? 


PoW change is **always** on the table. It came out during BIP109 debate. It came out just before BU crash and burn. It comes out now. And it will come out again when miner attempt to do something stupid in the future.


And yet Segwit2x was made to be compatible with BIP148
@_date: 2017-06-21 17:58:27
Since Segwit part is ready might as well activate that part first. You can then spend your time to focus on 2X part. BIP91 just adds additional complexity on top of BIP141. Complexity is the enemy of security. By activating on BIP141 you can throw away BIP91 part and just simply modify Bitcoin Core 0.14.1 (or whatever suit your preference) to get the 2X part. 
There really is nothing, repeat, **nothing** that can ensure to tie the two. It is really difficult dealing with irrational people...
@_date: 2017-06-16 13:11:09
Adding to Chris Belcher's comment point  the current asicboost user already effectively holds 40% of the hashrate so things will get worse from here. I'd rather Bitmain splits immediately rather than makes thing worse from now.
@_date: 2017-06-20 16:12:31
Have a read at Greg Sanders and Christian Decker's (one of the paper's author)
























data I'd also like to point out that the 4MB number is indeed intended
as an **optimistic upper bound** on todays network capacity.
@_date: 2017-06-12 02:28:50
I was not invited. Neither to Hong Kong nor New York. The sooner people realize that Bitcoin represents more than a few dozen people that can fit into a room the better it is.
@_date: 2017-06-20 16:21:17
1. Segwit+2x is just something on paper. Code not yet released. Signalling not yet started. In the meanwhile there is an attempt to release an ICO on BAHF. 
2. That was what we thought before we knew about ASICBOOST. Now we know the real reason.
@_date: 2017-06-03 14:11:35
*Shrughs* I thought you want more capacity but apparently you don't.
@_date: 2017-06-29 15:30:28


Not a single serious mining nor economic activity committed to Ethereum Classic either. All it takes is for Poloniex to list it to tip the scale. Similarly when Segwit2x fails to activate before Aug 1st it is pretty much goblin town out there. Just make sure you won't get blindsided when the time come.
@_date: 2017-06-11 22:57:09
This is what a lot of idiots don't understand. Bitcoin's security comes from decentralization. The lower the barrier of entry to mining the better it is. A chain that is easier to attack will be the same chain that is easier to defend. If there's a PoW that can be mined using dirt that is the most ideal PoW. 
Hashpower from an ASIC is meaningless if production is being done within one company. Besides who's to say PBOC is not behind this shit? There's no such a thing as private company in China.
@_date: 2017-06-13 22:14:06
@_date: 2017-06-03 13:39:23


In the short term? The market. In the long term? The devs.
@_date: 2015-02-01 16:23:07


So why does WU give the ability to make payment from agent? It's a liability risk as the agent can run away with the money. Because there's demand that's why.


Sorry I don't make a habit of keeping the receipt after the receiver receives the money. It's a privacy leakage as the amount of money that I have can be easily linked to my identity.


Why don't they put the number online then? Because it's much higher that's why.
@_date: 2017-06-21 13:42:33
This is a bigger deal than most people think though. Miner can't tell how to maximize their fee without actually **running** all the possible account, which open themselves to a DoS attack. So now they have to depend on indeterminate heuristic to figure out how to maximize revenue.
My guess is that this is because unlike Bitcoin, Ethereum is designed to have perpetual inflation. I think a lot of people underestimate the number of thoughts that goes into ensuring 21M BTC limit is intact.
@_date: 2017-06-08 15:04:06


Soft fork vs hard fork remember? If Satoshi disagrees with SF he has to do HF. The onus of replay protection is then on him not on us.
Unlike hard fork it is really difficult to do cloak and dagger style sabotage like I mentioned.


There is also possibility of PoW change. After that like the merchant in your example the servant is also free to offer their services elsewhere.
@_date: 2017-06-13 22:42:35
Just in case you haven't noticed have turned into commodity these last few years. 
It has some period where prices went up because technology doesn't progress the way they used to. EUV is late af. Making a fab is not cheap, it is billion dollars worth of investment. Memory company is operating near margin all the time. 
A really cutthroat business. It doesn't make any sense to increase supply if that means they have to reduce income.
@_date: 2017-06-08 15:25:05


Actually I was implying you were being paid by Jihan but apparently that went over your head.


What? I can't even...


Boo Hoo
@_date: 2017-06-21 13:18:07


Exactly. None of the exchange needs to take their wallets down. A strength, not a flaw.
In case you didn't read


You won't see that in Bitcoin because of UTXO based model in contrast of Ethereum's account-based model.
@_date: 2017-06-12 00:57:14


Fact check: block size double every year if it goes unchecked


Fact check: You don't need to upload nor store those things you downloaded.
@_date: 2017-06-03 09:15:58
Anyone know whose interest JaredR26 represents? That idiot doesn't even understand how Segwit works.
( [although to his credit he admits that later on]( )
Fucking seriously this kind of guy doesn't have a place in peer review process. The worst part is github discussion is supposed to be a review on the **implementation code** and not the protocol detail (which is supposed to happen on mailing list/IRC). Looks like this is turning into another shitshow.
@_date: 2017-06-21 15:49:13


The point of blockchain is that everyone needs to see the same transaction. That's the whole point of blockchain consensus.


I'm not sure why people see backlog is a bad thing. Backlog is a good thing in Bitcoin because it is necessary to ensure miner will keep extending the chain. You can do instant transaction through second layer.
@_date: 2017-06-15 00:17:43
You just said highly unlikely and yet there is one such proposal on the table. I assume you will lead the charge to oppose that EIP then?
@_date: 2017-06-16 18:24:32


DNMs are not complaining so much so far...
Neither does Wikileaks. Or that guy in Venezuela for that matters.
@_date: 2017-06-21 17:04:27


That's what you are implying here:




It is only as artificial as 21M BTC limit.
@_date: 2017-06-10 14:10:11
Sure, just submit a BIP on how to do it if you have any idea. A lot of idiots don't understand. Bitcoin's security comes from decentralization. Not how much hashpower you pour into it. The lower the barrier of entry the better.
@_date: 2017-06-03 14:10:59
Nothing ever makes sense tbh, like pushing for more capacity but blocks segwit, push for BU even though it's broken. It's ASICBOOST if you ask me.
@_date: 2017-06-12 02:13:08


F2Pool mines Ethereum, Antpool mines Litecoin. So does BTC.TOP and ViaBTC. Luke-jr is the most anti-altcoin advocate I've ever known. I don't know what your point is. How do I even know your position on altcoin redditor for 1 month?


They should know there is a method of outsourcing channel monitoring, you know, the same one that Segwit enables?
Besides, why are we listening to the same Brian Hoffman who doesn't even know how to setup a border node?






@_date: 2017-06-11 23:07:17
You mean like how everyone follows Bitcoin Unlimited? This is just a series of failed coup attempt. An increasingly embarrassing one at that.
@_date: 2017-06-18 13:36:28
It is pretty sad thing really. Historically miners are not much "behind" Core devs if at all. Luke-jr ran one such a pool. Artforz contributed a lot to early Bitcoin development. Eleuthria of BTCGuild and Tycho of Deepbit also seems to understand quite a bit of Bitcoin itself. Now only slush remains. Hopefully he will still be around for quite some time.
@_date: 2017-06-14 22:16:58


Forcefully merging something despite opposition will lead to that, trust me. The other half will also leave even though they agree with Wlad.


The same president is highly incentivized not to do shits that can make him removed by the congress (not to mention Wlad himself has his own moral standard).
@_date: 2017-06-13 02:25:52
It won't. Core seeks to actively tracks consensus. If there is no consensus it won't be merged.
Running Core right now is equivalent to running Bitcoin Unlimited. You will let miner choose.
@_date: 2017-06-03 13:50:07


Like I said, short term.


Devs come and go. Better devs will attract even better devs. The ability to change your mind based on empirical data is strength and not weakness.
@_date: 2017-06-18 13:48:54
I suspect Alex Morcos' work starts to bear fruits:
@_date: 2017-06-02 06:26:07
Except that was the key to Ethereum Classic's survival.
@_date: 2017-06-16 16:13:36






























































Dig deeper.
@_date: 2017-07-05 16:14:57


You just suggest that miner can commit directly...


I am talking about hypothetical scenario where Bitmain is in control if repo right? Of course I am using future tense.


Nothing there says asking for "HK agreement"


I don't care what Satoshi says. Satoshi is not a leader much less God. That's what being decentralized means.
So miner wants bigger block? Let them create bigger block. Let them run Bitcoin Unlimited. Let's see what happen.


Uh, no. It is a place where everyone including non-miner has a say. Letting miner decide the rule is like saying the president should make the constitution. Not going to happen.
Here's the thing you want miner to decide things for you? Go ahead. But so far they are too wimpy to do anything so don't count on it. And you can definitely count on me not getting on-board.
@_date: 2017-06-21 18:03:13
The worst part is almost no one keeps historical data. So after multiple hardfork you won't be able to tell which HF affects your balance...
@_date: 2017-06-16 14:27:09
Again I will only believe that **after** Segwit activates. Jihan could simply refuse to signal saying whatever shenanigans he has. That would be totally consistent with his behaviour so far
@_date: 2017-06-14 22:44:45


100%. You can practically see people begging for NACKs to change to ACKs in the pull request/mailing list. Take a look at BIP151.


Arguments are judged from their technical value, and not from where they came from.


In reality it might actually happen but so far none ever happens. It can be pretty obvious when someone is NACKing just for the sake of trolling


Many of the nodes also don't upgrade because it is more likely newer version is backdoored. In fact any serious business should upgrade slowly.
@_date: 2017-06-16 18:03:56


1. You are assuming I'm not using my HDD for anything else
2. What about memory requirement?
@_date: 2017-06-11 00:20:45
Wrong. WRONG WRONG WRONG WRONG WRONG. Hashpower means nothing if it is being held by only 1 party. OTOH a system that is easy to attack also means that it is easy to defend.
@_date: 2017-06-16 18:54:59
Yet neither SWIFT nor WU goes bankrupt, doesn't it?
@_date: 2017-06-16 18:11:26


Let's not make the problem any worse.


You are not taking advantage of Bitcoin's main feature then.
@_date: 2017-06-13 14:11:05
It started as one. Search for gold standard.
@_date: 2017-06-14 21:49:20
Why would miner attack something that has value? UASF chain has Segwit. The other chain doesn't and still has to deal with Jihan's shenanigans.