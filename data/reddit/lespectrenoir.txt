@_author: lespectrenoir
@_date: 2017-02-03 23:53:19
Malleability is pretty simple to solve : Just remove the signature part from the transaction before calculating its hash. This is also what segwit is doing indirectly, and it is a good thing.
Also, I fail to see how it is related to scaling which is what I am pointing out. Doing an equivalent of segwit in a HF without the complexity of the added data structure and added merkle tree would also be quite easy, just remove the signature from it, also change the algorithm from a quadratic to a linear and voila.
Finally I am not against segwit, I just find this "infographic" to be pretty dishonnest.
@_date: 2017-02-04 08:28:33
1 - All the research reports on bitcoin concludes that the main bottleneck is bandwidth, not UTXO. I ll agree that UTXO is a problem however since it can not just "go away", but there is many way to manage around UTXO as well.
2 - How what you are saying is even remotly realistic ? Do you often see "users" doing making super transactions of 1 Mo ?
If anything, it is more intuitive for user to have a single data type (transaction) than transactions with an empty signature field, and a separate data storage with an extra merkle tree
3 - Agreed on the minimun fee. I ll argue that this argument (the lower cost of redemption cost) is a sideeffect and not one of the main goal of segwit.
I think that some kind of hard coded extra incentive might be needed on the future fees (reducing the number of UTXO should be free somehow), maybe with an allowed extra on the block size because else it is not possible to allow it. 
Unfortunatly thats not an easy problem to solve we can agree on that.
To conclude, while I agree with several of your points there is nothing in it that changes against the currently agreed bandwidth(bandwith) while average size of transaction will get slighly bigger
@_date: 2017-02-03 23:59:27
1 - Segwit does not make smaller transactions, which is the main bottleneck. So my point that segwit does not increase scalability still stands.
2 - Sticking a limit to a NÂ² algorithm to a fixed size, make it effectively a O(1) algorithm. Your point does not stand. Also if this size is limited enough, the computing size can be considered effectively negligible.
3 - Other stuff about UTXO bloat etc. unproven. If anything, continuously raising fees by a limited blocksize is a sure way to get a permanently big UTXO set : Any output worth less than the current median fees will never be claimed.
Of course you could argue that limiting the number of possible transactions on bitcoin will on the other hand limit the UTXO size...
@_date: 2017-02-03 14:30:19
Segwit does not improves scalability in any way compared to BU. segwit transactions are in total bigger than non segwit transactions, and the quadratic hashing speed probleme can be solved efficiently by a max transaction size.
@_date: 2017-01-28 18:36:08
They stated : 20% in support of segwit