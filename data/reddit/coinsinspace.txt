@_author: coinsinspace
@_date: 2017-02-07 00:10:17
Ok you're right.  
If instead of hashes addresses are public keys, what about making a hash commitment based on a transaction (inputs, outputs, defined order), then multiplying each public key as:  
firstInputPublicKey\*a where a = H(commitment)  
secondInputPublicKey\*H(a+1)  
then summing it all up to obtain a public key, and singing with it. 
edit: with multiparty computation it should allow total aggregation, in the extreme turning a block into list of inputs, outputs and one signature
edit2: ok it's secure under n-cdh


It's something I thought about while commenting on reddit in the middle of the night, not writing a system...   
@_date: 2017-02-05 17:57:38
The advantage is that I increase the odds of Bitcoin with big blocks, which would be beneficial to me. It's like seeing an empty bottle on the grass in my neighborhood. If its not too far away I may pick it and throw it into the bin. The individual impact is small, but good change happens when you add many positive individual impacts. 
@_date: 2017-02-18 18:54:20
Depends on what client you are using. In general, in bitcoin you don't spend addresses, you spend transaction outputs.  
Every transaction into an address creates (at least) one separate output. So if you got 0.1btc in 5 transactions, you have (almost certainly) 5 outputs. You can concentrate them by creating a transaction that spends them to one output. 
The output can even be the same address they were initially in.  
In newest Electrum there's a tab named 'coins', if not visible, enable in the 'Wallet-&gt;Coins' menu. That's a very clear presentation: every output is separate. That's what you spend. Press ctrl and click to select all outputs you want to spend, then right-click and 'spend'. Enter one of your addresses as recipient, in amount enter '!' which means all. This will create a transaction condensing all these outputs into one.  
It's best to preview the transaction and confirm there's only one output.  
Another clients may have something similar or not. At a minimum, the client should allow you to spend all your coins (some button called 'max' or similar). That would allow you to concentrate all your bitcoins into one output. 
In case of a dumbed-down wallets, it may be easier to import (not: move bitcoins) your addresses into Electrum. You would need to somehow export all private keys from your existing wallets, then in Electrum: create new wallet -&gt;  standard wallet -&gt; use public or private keys -&gt; paste every private key, or open a file with them. 
@_date: 2017-02-13 03:18:27
So assuming it's real, how?  
100x60x10 (transactions) x (minimum data per transaction) = 1M bytes (ignoring header). That gives... 16.(6) bytes per transaction. For separate transactions it's not enough for ECC, it would have to be some entirely new asymmetric crypto that gives 128 bits of security for 128 bit keys AND simultaneously allows encoding a new key while signing the old one, all while taking only 128 bits. 0.6 bytes could be enough for transaction amounts I guess, or including them in the key somehow? 
This ignores additional space requirements of current transaction structure, although I guess as a soft-fork you could create one giant transaction with new structure inside. 
More realistic:  
1\. these 100 tps refer to the best case scenario with very large multisigs/lots of inputs with one/few outputs, with each input and/or output being counted as a transaction.   
2\. Or, transactions are like physical coins, ie. each output key owns exactly the same amount. So 100tps would be a maximum possible if all transactions have the same value (like 0.01btc) or a similar limitation. I can see a sublinear aggregation here. 
3\. Or, 100 tps could refer to transactions that cancel itself out in time between blocks, ie. A-&gt;B, then B(unconfirmed)-&gt;C appears on the blockchain as A-&gt;C. Not sure if that complies with the on-chain requirement though. 
4\. A check system, in which relevant data is stored by the participants, and blocks contain only some proof for it. That would probably require the recipient to receive some data over other channels. 
Any other ideas? 


Hmm. Let me guess: all addresses/scripts already exists, so instead of storing it again, their id are used.  
edit2: 


In this case slight change would mean necessity of public key addresses (as opposed to their hashes) to enable signature aggregation. So that fits in with using ids of existing outputs/keys. 
@_date: 2017-02-26 02:45:10
Bribery is only when you pay someone who has limited control over something, but not ownership, to break the terms under which he got that control. 
Paying miners is absutely not bribery. 
@_date: 2017-02-05 21:43:17


No, with exception of installing and initial blockchain sync, the real cost is zero. So I have a node that runs on a pc. Unless I really need that disk space the cost is zero. It just starts automatically and doesn't interfere with anything. 
So what matters is the motivation to set up the thing. Big blocks increase it substantially. 
Setting up separate nodes is a wrong model. 10k people running nodes on their pcs, under different times zones, would create a vastly more resilient network than even a few hundred enthusiasts with dedicated 24/7 nodes. Note that it has an inherent demand scaling: there are more local nodes active when it's daytime.  
In the future bitcoin nodes could rely on smartphones, obviously with option to only use the wifi. 


No, it does provide incentive to run a LN hub. You don't need a full node for that. 


That's client, not protocol. To finance nodes part of fees or coinbase would have to be distributed to them, through some proof of storage. 
@_date: 2017-02-05 21:21:21


That's how bitcoin is designed, nothing can be done about it. 


So what economic incentives are there to run a node now, in your ideal system with small blocks?  
@_date: 2017-02-26 22:21:16
It's easy to show that PoS is more secure than PoW:  
there's NO possible state of PoW network where it's secure from external actors. A determined nation-state was and always is going to be able to destroy a PoW currency.  
There exists a secure state for PoS:  
as long as the attacker doesn't own ALL coins in one block, a more-valid chain can exist. It's enough to have just one honest stake-owner for every block that is never going to reveal his old keys to the potential attacker. 
That's fundamental. Everything else is an implementation detail. 
@_date: 2017-02-02 01:30:00


Yes, BU has problems and is ill-thought out. From a technical point there should be no limit at all, but that may be politically impossible. The worst part of BU is lack of protection against chain fork, especially core fork continuing. I don't expect BU to win but would be happy if it did. 


There's a market, but not a free one, as it's centrally planned. Exactly like government selling taxi medallions. A free market price is always based on true limitations. 


Not true, once you have a ~$500 pc there's nothing better (for bitcoin processing) to buy. Internet access is even more egalitarian for hundreds of millions of people with access to cheap unlimited fiber. While Roger indeed could get a much better connection than you eg. on the Sahara desert - why would you want to run a node on Sahara?


The poor can't actually use bitcoin because block is too small. I am a small time user and nevertheless paid $100+ in fees in the last year. 


Did you mean Lighting Network? Because in reality normal users would *never* be able to settle balances on the blockchain. A signed transaction for ~$100 is worthless if it requires more in fees to actually go through. Which means those with low balances would have to completely trust their hub. Or just not use bitcoin. 
Note that 'low balances' mean 'thousands of dollars' if bitcoin was to be used widely. 
@_date: 2017-02-07 09:23:33
So a working, although not optimal, scheme took a random reddit user an hour to figure out starting from a vague idea, while core is working on it for years and it's still in the research phase
This stagnation is pathetic, it's clear bitcoin needs a new team
@_date: 2017-02-13 09:15:07
Can't you steal electricity by connecting to the pole or something like that? Detecting power theft is way harder than just singling out those with high power usage on their meters. Especially in the most incompetent state on Earth. 
@_date: 2017-02-04 22:22:56
I don't know why BU doesn't want to use merged mining to kill a minority fork, using additional money to buy/rent additional hashing power creates unnecessary chaos and risk. 
Change to another pow is a pipe dream. 
@_date: 2017-02-04 16:49:20
\&gt;betting in bitcoin on a bitcoin hard-fork
@_date: 2017-02-05 21:24:51
No, I meant that getting segwit not accepted has become a symbol of defiance.  
From a pure technical side, while Segwit has issues, it's activation or not wouldn't change anything. BU would have to get updated to support it but that's it. 
@_date: 2017-02-27 14:03:32
That's only because a sudden hash increase increased the effective blocksize to ~1.3MB
Your 'spam' attack is going to magically reappear in 3-4 days, after the next retarget.
@_date: 2017-02-06 22:46:30


If you use an additively homomorphic hash for the public key, you could sign all your inputs once with the sum of inputs' public keys with already used ecdsa. The hash of the used public key would be the sum of hashes of individual keys. Individual public keys can be kept secret. How does that destroy privacy? Outside of case when n-1 keys are revealed, but that's very minor.  
@_date: 2017-02-20 22:59:43


Just like ECDSA. Schnorr doesn't bring any fundamentally new capabilities. It's slightly better in an evolutionary way. 
A hard fork with aggregated ecdsa sig opcode has a very big advantage, because it could support all existing pubkey hash addresses.
@_date: 2017-02-12 21:55:24
What a weird argument. That's a different version of using lines of code as a productivity metric.  
Also, [tfw]( you used cypherpunks as insult. What a difference to the early days. 
@_date: 2017-02-06 11:45:56


As opposed to? Just like bitcoin. 
While 160 bit hashes give 80 bits of  quantum security, there's no way to spend it safely.
@_date: 2017-02-21 05:06:18
That's what 'layer 2' means in practice. The only practical difference to idealized LN is that you can't force a withdrawal on the blockchain.  
Some people seem to genuinely think LN would result in a decentralized system with complicated routing, but why would exchanges accept random small hubs and channels? Why would shops? How would that be compatible with AML? :)  
Exchanges and payment gateways (like bitpay) would form a small tight network amongst themselves and everyone else would be limited to IOUs. LN would be used as a settlement mechanism only between exchanges and payment gateways. 
Trying to sell bitcoins external to that network would get harder and harder: you would have to prove their origin beyond any doubt and explain every transaction. 
That's why it's either on-chain scaling - so that there's no *economic* incentive for centralization (regulation incentive remains) - or another Paypal. The nice thing about scaling is that many possible solutions can at the same time also increase fungibility.
@_date: 2017-02-05 16:34:25


These people should not run a node. Hundreds of millions *don't* have datacaps. 
Increasing number of *users* is the best way to ensure there are many nodes. Imagine a guy in Romania with his wage of $600 per month, but having an unlimited 1gbit fiber connection. 
Is he going to run a node for something he can't afford to *use* due to fees? Definitely not. Something he *can*? With some probability - *not* related to bandwidth use! 
That's why bigger blocks are the best way to increase node count.
@_date: 2017-02-26 02:52:37


That's only possible for hard fork changes. 
@_date: 2017-02-21 04:19:04
Normal size, they wouldn't. Segwit only works for transactions spending from segwit outputs, that's the main drawback of a softfork. Spending from all old addresses remains unchanged.  
In principle you could add ecdsa aggregation in segwit but that would be nearly pointless, you're already in, use schnorr. 
Well as soon as it appears lol. But I guess segwit getting accepted would means fast subsequent arrival.
@_date: 2017-02-12 21:40:24
I'm sorry, but your title is self-contradictory. 
@_date: 2017-02-07 10:50:47


Did I make out a *proposal*? No. It's reddit's equivalent of musing on IRC, I didn't even think about how to break it. If I were making a *proposal* I would analyze it first. 
Just putting it in the equation form gives it away, attacker controls everything except publicKey2:  
P = publicKey1 + publicKey2
What about the second one:  
P = a\*publicKey1 + b\*publicKey2  
a = H(publicKey1, publicKey2, other data), same for b  
0 = a\*publicKey1 + b\*publicKey2  
a/b\*publicKey1 = publicKey2  
a/b is a function of H(publicKey1, publicKey2, other data). Safe for H being preimage resistant in the noninteractive case. In the interactive case (the victim signs a valid transaction with attacker-controlled noise), collision resistant. 
given assumption that solving the discrete logarithm problem for P = sum of n-1 attacker keys + unknownKey is infeasible. Attacker keys chosen before knowledge of unknownKey. 


Yes these would be great, but it's real-life, not research. A working solution today is infinitely better than a better one tomorrow. The better one can always be added later. 
@_date: 2017-02-26 02:32:29
Cheap asics. Technically you could have an electric kettle which mines bitcoins while heating water. 
@_date: 2017-02-06 09:31:34


Setting a higher fee does nothing except pushing the problem to someone else. 
@_date: 2017-02-10 22:57:27
I proved its security.
@_date: 2017-02-07 11:06:16


This response only makes sense in isolation because you cut out 'a working solution today' from the quote. 


Stateless (as opposed to ethereum's) script ops don't create any dependencies: the debt is negligible. Yet it would increase effective capacity close to the order of magnitude - years before today. 
Due to this stagnation Bitcoin is like myspace in ~2007: technically inferior and dominant only by a network effect. Or like CP/M before MS-DOS destroyed it. 
edit: No, Lisp is the best example, because exactly this kind of technical infighting killed it. Everyone wanted perfect  (as defined by them) and nobody accepted good. It's funny how similar it is. Even the fanaticism is the same... 
@_date: 2017-02-10 23:07:06


I proved its security. 


Apparently I can make a better solution in one hour than these 'heavyweight developers' in years.  
Not because it's hard - it's clearly a trivial problem. 
@_date: 2017-02-06 20:08:59


This has nothing to do with block size, it's only related to number of inputs in one specific transaction. As long as transaction sizes are unchanged the scaling - with blocksize as a variable - is linear. 
Segwit isn't a good solution to this, because it could be solved way easier in various ways, for example 
by adding one simple hashing script op, to which nobody would object. As a bonus it would also allow signature aggregation, resulting in just one signature regardless of number of inputs and their keys, making transactions much smaller, in fact smaller than Segwit.
@_date: 2017-02-18 14:55:30
Yes they are gone, unless an actual block size increase happens, or a hard fork which makes transactions smaller. Or bitcoin starts to die and 1MB blocks become enough again, I guess. 
I [made a warning thread]( for this, unfortunately it didn't get upvotes. I except much more threads like yours.
@_date: 2017-03-22 20:02:21


It's easily solvable by a third-party cosigner service. It could be made trustless if bitcoin supported a transaction that allows spending coins if two contradictory signed transactions are presented (ie. a security deposit by the cosigner). 
@_date: 2017-02-28 19:11:19


**Not true. A hardfork only ends in a split if blocks are *rejected* by old nodes.** 
Example: a legacy block with coinbase and a hash of the new block somewhere, perhaps in another transaction for 1 satoshi. New nodes get the new block with all true transactions, almost exactly like segwit. Old nodes accept the block but don't see any non-miner transactions. 
Conclusion: majority hash power can force a hardfork while preventing the existence of any fork. 
It's possible the people you talked to commented on the Classic hardfork approach, not hard forks in general. 
The only real differences between soft forks and hard forks are, assuming best implementations in both cases:  
A hardfork allows a ground-up redesign of a protocol, at the cost of forcing everyone to upgrade. Which also means that all existing outputs get to use the improvements (like an opcode that allows aggregated ecdsa signatures, compressed inputs, ... ). Several simple improvements could easily reduce size of transactions &gt;10x. 
Soft fork only requires nodes and wallets to upgrade if they want to use/understand a new protocol. That's the only advantage. Fundamental protocol redesign is impossible, significantly limiting possible gains, and added features are available only to new transactions, which have to explicitly 'enter' the softfork sphere. 
That's it.
**P. S. The way segwit is done is really inefficient.** All old nodes see is anyone-can-spend, which means an unlimited number of segwit transactions could be bundled into *one* small legacy transaction per block. The way it's done is so wasteful it's almost painful.
@_date: 2017-03-21 10:03:52
Gpus are trivially available to rent. Multiply the daily block reward by a reasonable price - for a chain with a new pow. 
That's your security.
@_date: 2017-02-04 14:58:25


Consensus literally means 'general agreement', which by definition can't be forced. The only way a core-incompatible client can succeed is if consensus changes! You used the word, but what you really meant is 'what I like'.  








when you start sounding like a fascist dictator perhaps it's time to think things over
@_date: 2017-03-17 16:16:46


If you refer to a miner creating a block with unseen transactions, that's where parallel validation comes in - this means that a block with known transactions is going to propagate &amp; get validated much faster. So either the block gets orphaned or manages to propagate in time. In both cases there's no problem.  
Such miners are guaranteed to be a minority because bitcoin assumes the majority of hash power is not malicious! So there's no additional risk :)


Why would it be any different. There's no phase change (for a lack of better word) just more of the same. 
@_date: 2017-03-19 00:54:49
Unless a hard fork at a specified date is certain, BCC is almost certain to be worth more than BCU because BCU is also a bet that a hardfork happens before end of 2017. 
The true market price for BCU would require something that results in no loss or profit with no hardfork. For example you sell one BCU implicitly contained in one BTC for $600. If there's a hardfork before 2018 you get $600 + BCC. If there's no hardfork you get BTC back and the seller gets $600 back. 
I wonder if that disparity is intentional on the part of bitfinex. 
@_date: 2017-03-17 19:30:17


Not sure what you mean. Higher tps than capacity ie. backlogs with 100MB blocks? That would be years in the future with much better internet
@_date: 2017-03-17 19:30:48
These attack vectors are academic and aren't going to be a problem in reality. 


Especially attacks completely unrelated to blocksize... nothing stopping you from generating gigabytes of valid, but unlikely to confirm, txs for dos purposes right now. 
@_date: 2017-03-24 09:43:10
Adjustable block size is pure free market, if you don't like larger blocks, you can just refuse to accept them indefinitely. If there are miners who think the same they are going to keep mining a smaller chain. 
Users of larger blocks can trivially prevent a deep reorganization, if for some reason a smaller chain got more valid by difficulty alone, by using the invalidateblock command. Or possibly something else, if there's really a demand for such solutions. 
@_date: 2017-02-15 19:14:17
Approval could result in lots of hedge funds trying to frontrun the launch. Hard to say how many. I wouldn't be *that* surprised to see an enormous rise after approval and dip on open.
@_date: 2017-03-30 07:27:57
Doesn't make any sense, to mine a new block you need a new block. So block transmission doesn't come into action, it would manifest in orphans. At best empty blocks mean that *existing* implementation can't handle validation fast enough. 
@_date: 2017-03-20 07:18:24
LOL that's because some of these nodes were downloading *old* blocks, and the issue is sustained bandwidth needed for propagation of *new* blocks. 
@_date: 2017-03-28 20:13:51
Mempool growth chart is *completely irrelevant*.  
What happens when there are 30 places in a bus that arrives every 10 minutes, but every 10 minutes 31 people arrive? Those that can't get in wait for up to three days. 
After three days 432 people are waiting. 
@_date: 2017-02-05 16:55:38
Because nobody in their right mind would run a node for core for free. That would be like helping Paypal run their servers. I already paid &gt;$100 in fees in the last year due to them.
Guess what - recently I started a BU node, as against all odds they appear to have lasting momentum. 
@_date: 2017-03-18 13:18:17
Link to a tweet that links a tweet that has a screenshot with a now deleted post on r/bitcoin, deleted because its author confessed it's ['just a guess based on his social media posting patterns'](
Solid research deserving a lifetime of reddit gold
@_date: 2017-03-19 06:21:49
LOL you have a script with ready answers and couldn't find another matching one. 
That's just sad.  
That link is a good-looking and seemingly reasonable answer which could convince non-technical people, but you used it in the most hilarious way possible by trying to prove Core's research about block propagation wrong :)  
Which means you have zero understanding of the issues and are just mindlessly using pre-made answers made by someone smarter. Probably by matching keywords.  
Which is exactly how paid shills work. 
@_date: 2017-03-17 21:20:24


This is included in the average bandwidth use. 
Anyway, do you even know somebody with less download than 1MB/s? I don't. Now realize the calculations are about 100MB blocks. What about 32 MB blocks? :)


Hard fork changes don't need that, ECDSA also supports aggregated signatures - just needs a new verification opcode for that. It has the advantage of supporting all existing addresses. 
True scaling is not possible with soft forks, the required changes are too deep. 


On the scaling to do list gpu acceleration is a nice addition, but not a priority. Chances for scaling bitcoin in general aren't looking great. 
@_date: 2017-03-29 05:30:22


Why is a blockchain necessary to distribute data?


It's either an altcoin, a direct competition to ethereum, in which case it has as much to do with bitcoin as any altcoin. However as I understand it, it uses bitcoin as a unit of account, which means trust in that federation is a fundamental part of the protocol.  
Which is why I claim it's *already centralized* and the blockchain part is pointless and wasteful. What's the point of mining? What's the point of making everyone replicate contract execution and store everything? It works much better in a centralized manner: every contract only has to be seen by the interested parties. 
@_date: 2017-03-19 03:38:30


uh huh. I'm still waiting for any technical argument. 
@_date: 2017-02-05 17:52:05
I'll try to be impartial:  
**Core** sees increasing costs to run a bitcoin node as the main cause their numbers are decreasing. The same is supposed to be true for miner centralization - the bigger the blocks are, the more advantage there is to mine your own (ie. mined previously by you) chain. Look up selfish mining for related problems.  
All this means that significant scaling on-chain is impossible, so the only viable future for Bitcoin is as a settlement layer for centralized payment providers (but many of them) - LN, and perhaps decentralized sidechains. Basically Bitcoin is supposed to become the interbank transfer layer, with p2p transactions priced out.  
Segwit makes it easier, mainly by fixing transaction malleability issue. It also increases by the block size by amount that's different depending on a transaction. If current usage profile persists and everyone switches to segwit, it would be equivalent to about 0.7MB increase. It also improves on several minor performance-related things. 
From a technical POV, the best way to add Segwit is through a hard-fork. However, Core thinks a hard-fork is very dangerous, so instead Segwit was added as a soft-fork, which allows old nodes to propagate new blocks. From the perspective of old nodes segwit transactions are spendable by everyone, so transactions including them are going to look valid. Miners have to upgrade. 
There's also Mimblewimble project with unknown potential, started by an anonymous guy under French Voldermort's name :) It's unclear what chances, if any, are for its inclusion in bitcoin.  
**Bitcoin Unlimited** believes on-chain scaling is possible and that bitcoin should remain p2p money. Instead of block limits set by developers, block limits are supposed to be dynamic. If you want bigger blocks, you set your node to accept them immediately. Let's say at some point the majority of miners and a significant number of nodes are ok with 4MB blocks. A miner makes a 4MB block, it's accepted by these nodes but rejected by others. However, after the chain with big block grows by several blocks, the node 'changes its mind' and accepts that chain. How many blocks to wait before accepting is another configurable number called 'acceptance depth'. The most common value on the network right now is 4.  
On a technical side, BU is not opposed to hard-forks, which allows much more freedom in adding new capabilities or improving existing ones. 
BU is opposed to Segwit both on technical and political grounds. On technical side there are many in-depth criticisms elsewhere, focusing mostly on the things forced by the soft-fork. On the political side Segwit became a symbol of defiance to Core plans to make Bitcoin into a settlement layer. 
**Fork**. If BU forks off at 75% of mining power, all core nodes are going to reject its blocks. At this point there are three main possibilities.  
1. Remaining miners and economical majority (exchanges, shops, etc) switches to BU and core chain dies. That's the best option for big block supporters. Probably price drop from uncertainty, but afterwards, fees should drop and transaction backlog will disappear, so there's a reasonable potential for an increase.   
2. Core chain slows down for several hours, but near complete lack of acceptance of BU blocks by the economical majority, or some other factors, causes miners to gradually return back. Enormous transaction backlog. A short time later BU fork dies. Price drop from chaos, but later the situation returns to status quo, so price may too.    
3. The worst one. Some important services accept BU, some not. After initial fork some mining power returns to Core, and both forks have comparable hash power. The situation lasts more than a day, which means there are now two bitcoins. Price panic. Both sides blame each other. Hard to say how it could end. 
From a technical side, once BU forks, 1 is the most probable one, 3 the least. Core has the inherent disadvantage because there's going to be an enormous transaction backlog with resulting very high fees, while BU is likely to almost clean mempool with each block, depending on how high the block increase is. 
@_date: 2017-03-29 00:44:37


@_date: 2017-03-19 07:25:04
What do you mean? A hardfork to a different pow?
@_date: 2017-03-24 15:58:47
That's a fantastic idea! I hope devs and supporting miners start implementing it soon. 
@_date: 2017-03-23 10:53:08
What you call a 50 bit key has the same probability of existing as any other key. 
@_date: 2017-03-29 00:29:12
It's going to require trust. 
There are only two possible ways:  
- make bitcoin verify a zk-snark of a computation (requires adding new opcode(s) to bitcoin + as of now key generation for zk-snark requires a trusted setup)    
- make bitcoin script turing complete and just repeat the computation... but that defeats the point of a sidechain
tl;dr marketing BS
@_date: 2017-03-19 03:17:37
That sentence uses 'decentralization' as a meme devoid of meaning. Nothing real to respond, it's like 'think of the children'. How exactly larger blocks damage decentralization and at what size it starts to occur?
@_date: 2017-03-10 15:48:58


No, what happens is that another block arrives in the interim and 1GB block gets dropped before its validation finishes. 
@_date: 2017-03-14 00:56:47
That's not how BU works. Blocks are to be validated in parallel, so a block too large is going to be orphaned. It has the beautiful result that blocksize stochastically follows the actual technical capabilities of the network. 
@_date: 2017-03-22 20:23:00
Jihan Wu selling most of his bcc would be great :)
@_date: 2017-03-19 03:28:36
Great, because bitcoin with 100MB blocks allows that. Blockchain storage can be achieved via decentralized storage (through rateless erasure coding). 
Although I don't necessarily agree that full nodes on smartphones are necessary. Storing, sending and computing it is one thing, but just constant *connection* eats battery significantly. 
@_date: 2017-03-19 03:57:26
Decentralized storage means that n average nodes are required to restore the full blockchain. According to luke jr [there are 50k+ full nodes]( 
If blockchain is split into 200 parts it means that 0.04% of current full nodes are required for a full reconstruction and that storage for an average node grows as if with 0.5MB blocks.  
However, with decentralized storage number of nodes would rise, as that would mean everyone can contribute, even with only few GBs of storage. 
If someone wants to store the full blockchain they could do it for [$4/TB per month]( 100MB blocks mean 5.1TB new data per year which would cost $20.5 per month to store. Compare that to transaction fees paid today, if someone is actually using bitcoin...
Bandwidth requirements are trivial, 100MB per 10 minutes is 170.6kBps, even with 2x overhead that's 341kBps, but 2x overhead is an overestimate. 
@_date: 2017-03-30 08:00:11


Even if there was a transmission issue, you can have validation servers all around the world, or at least close to other major miners, and send the filled block header to the actual mining place. With that, you could run a big mining operation on 32kBps. 
Which means it's either that updates to validation code are urgently needed, or that the reason for empty blocks is not due to technical limitations. It could be 'technical' in a way that the simplest arrangement has these problems and they don't care to change it. 
@_date: 2017-03-17 21:53:56
Ok that makes sense
@_date: 2017-03-19 05:26:32
Because for a normal user there's zero incentive other than ideological, it also requires some technical knowledge. Also high fees make supporting core network pretty pointless. Why would an average person run a node for a system he has to pay through the nose to use? One transaction can easily cost more than cost of (in additional electricity) having a node for a year!  
 
I only started running a node once BU gained some traction, zero reason to support Core's expensive network. 
Only miners and large bitcoin using companies actually *need* full nodes. 
Making bitcoin used much more widely is the only way to increase number of nodes. 100MB blocks getting full would mean 100M+ users. Bitcoin would easily be above $100k in that case. That would be enough usage to support things like [multicasting]( blocks globally, which would make all possible bandwidth problems go away. 
@_date: 2017-03-17 19:48:02
Perhaps, but increasing blocksize doesn't make any attacks worse. Blocksize limit has no direct relation to broadcasted transactions per second or mempool capacity. 
@_date: 2017-03-29 08:08:19
That's enough for an individual two-chain exchange case, but not for a general peg. For individual exchange you could indeed send coins on the other chain to a jointly crafted address with locktime, then create a bitcoin transaction that unlocks with other party's secret. 
It's not enough for creating that bitcoin transaction before the state on the other chain is known, even in the simplest case you would need to follow the chain of signed transactions. 
Then there's a separate issue about how a bitcoin transaction is supposed to know if the chain it's presented is valid, but that could be made an academic concern with pow chains I guess. 
@_date: 2017-03-17 15:48:23
You know that this paper uses a completely absurd assumption that nodes *need to* receive an entire block after it's mined? 
The only thing that needs to be propagated is a block header + list of transaction *mempool ids*. Look up [compact blocks]( and [XThin ]( 
"**An average full 1MB block announcement can be reconstructed by the receiving node with a block sketch of 9KB**, plus overhead for each transaction in the block that is not in the receiving nodeâ€™s mempool. The largest block sketches seen top out at a few bytes north of 20KB."
That's from *Core*. The limits obtained in that paper are *completely irrelevant*. Bandwidth-wise what matters is blocksize divided by time between blocks. 64kBps as a minimum acceptable receiving node bandwidth gets you 32MB blocks easily. 
@_date: 2017-03-15 21:14:09
It's funny it's here because this article is really more about Core. Neither Classic nor BU created the moronic requirement to use asserts in release, contrary to all sane development practices. That's why that assert remained - it would be ok in all normal projects.  


According to you, but checking invariants in that way is perfectly valid for debug. A form of unit testing.


That assert for new is pointless, but technically new can return null if exceptions are turned off. No word about whether they are. 
@_date: 2017-03-24 10:41:35


How does the existence of a cryptocurrency with big blocks impact non-users? 
Environmental pollution impacts everyone because air, sea water etc. is indeed common to everyone on Earth, it's impossible to opt-out. 
Blockchain is a public good exactly in the same way 'health' is. That is, not at all. Accepting that it is shortly leads to war on drugs and things like banning sodas. Because if your health is a (part of) public good everything you do becomes a possible threat to that public good. 
@_date: 2017-03-23 11:04:31
If you start finding more addresses that would mean the whole private key -&gt; public key -&gt; sha256 -&gt; ripemd160 -&gt; sha256 -&gt; sha256 process loses a significant number of entropy bits somehow. Kudos for original thinking and questioning 'obvious' assumptions. 
@_date: 2017-03-19 02:24:21
Core wins: Bitcoin becomes exclusively a speculation toy for bored speculators, a digital version of beanie babies. The only practical LN hubs are major exchanges, with more strict KYC/AML than banks and paypal, so no one uses it anyway. 
BU wins: eventually you can pay with bitcoins for bread in Venezuela, where it started to be used by the masses trying to hide their wealth from the socialist government. Blocks are 100MB which is enough for 2-3million of efficiently encoded transactions. 300kBps of download bandwidth is an easily achievable minimum to operate a full node. 
Choice is easy. 
@_date: 2017-03-28 19:58:37
Yeah I'm not. You really wrote it like having a wall, electricity and an internet connection makes you privileged. It doesn't. It means you're not it the world's poorest ~20% and that percentage is shrinking very fast. It makes your whole premise absurd. 
The real difference today is not that eg. Africans live in mud huts, but that their computers and smartphones are *cheaper and/or older*. That's it. 


That aspect is completely irrelevant. For every niche there's some X that's only widely known to people in that niche. It has nothing to do with being 'privileged'. 


Which is also true for the overwhelming majority of the human population. The places where it's not feasible are **exceptions** - places like North Korea, Bhutan, Venezuela or Zimbabwe. 
@_date: 2017-03-29 03:25:15
It's one of these projects that would be actually better without any blockchain, but uses it for marketing purposes. 
@_date: 2017-03-22 20:11:34
Malleability is good if you consider layer-2 scaling horrible.  
LN in practice:  
coinbase is a LN hub, one of the largest in the world. 
most shops only accept coinbase-bitcoins because it has the lowest fees on average, due to network effects    
coinbase refuses to accept any external coins whose origin can't be proved and/or the owner anonymous. full kyc/aml.  
the end. 
@_date: 2017-03-30 07:33:26
Honestly I expected -1, but reddit is fickle like that sometimes. 
When I wrote that nearly all upvoted posts were super enthusiastic. 
@_date: 2017-03-17 20:13:22


You only need one utxo id per transaction. Right now it's 26 bits. Maybe it grows even to 32 bits. So going with that and ~1000x increase that's ~2.5million transactions = 9.7MB. That's why I included 1x overhead for things like that. 


That's related to wasting space, for confirmed inputs there's no reason to include input hashes in actual network packets, it's better to put in utxo id + reference block height and allow everyone to compute txids locally. This turns finding input tx into either O(1) or O(lg utxoSize) operation on a ssd depending on how utxo set is organized. In any case much easier than finding by hash. 
Same with block storage. Actual hashes are necessary only while signing &amp; verifying. 


I agree, no reason to not add aggregated signatures and remove these limits altogether. There would be literally zero reason to use legacy ones so they may as well stay severely limited. 


Much less of a problem with aggregated signatures, can be gpu accelerated if need be. Today even budget smartphones support opencl 2.0 with relatively powerful gpus...
@_date: 2017-03-29 00:20:56


**In the same way, Bitcoin has FULL verifiable computation capabilities RIGHT NOW - you just need a 2-of-3 multisig with an arbiter to verify the results**.
The fact that it got so many upvotes really shows the state of r/bitcoin...
@_date: 2017-03-19 06:06:02


You know that even 1GB blocks require only 1.7MB/s + some overhead? Easy to calculate. 
Bandwidth is absolutely not a limiting factor in anything. 
@_date: 2017-03-31 14:37:20


Bitcoin isn't really fundamentally different. If it magically replaced US dollar the issues could be much worse. Ideally there would be no money and technology is slowly getting to the point where it's going to be possible. 
@_date: 2017-03-24 14:12:53


And your is? Would you like to be able to lock people up for doing that? 


Someone who writes that 'it's idiotic to subject &lt;x&gt; to the free market" clearly *IS* a socialist. The opposite of free market is central planning. So another way to write what he wrote is:  
"Block size should be centrally planned". 
@_date: 2017-03-08 09:55:32
The purpose of a cryptocurrency is to be useful, not to be a get rich quick scheme. 
You're so deep into a ponzi mindset you can't even comprehend of other motivations than price
@_date: 2017-03-19 06:58:57
It's not forcing anything, hardfork doesn't have to occur in 2017. Yet BCU on bitfinex expires worthless if it doesn't. So the price of BCU is (estimated probability of a hardfork in 2017) * (market value of BCU). A successful hardfork could occur on 1.01.2018, killing the core chain, but the price of BCU would be zero. 
Still it's being presented as a market valuation of BTC after BU fork in general. It's well designed propaganda. 
@_date: 2017-03-18 21:12:18
They can't, bitcoin pow is only secure because hardware is so expensive and specialized. The actual electricity cost is way too small to provide any reasonable security. 25 blocks require about $300k in energy. Just add up block rewards. A reorg that deep would create orders of magnitude more economic destruction. 
@_date: 2017-03-22 20:18:18
The market you speak of includes a bet that a hard fork happens before 2018. 
Even if a hard fork were to be absolutely successful on 1 of January 2018, the value of btu on bitfinex would be zero. 
@_date: 2017-03-22 19:34:02
@_date: 2017-03-21 09:36:39


Well for Americans. Why not allow full utf8 instead? An address in simplified chinese letters would be much more practical in China, especially for writing, it would also be much shorter. Cyrillic in Russia. Etc. In general an address with emojis would be kinda hilarious and relatively easy to remember. 
The first byte after bc could specify the range of characters to use. 
@_date: 2017-03-17 17:24:46
Bitcoin nodes ban hostile nodes, as otherwise DOSing would be trivial. No difference in risks to current situation. 
@_date: 2017-03-20 05:25:37
Segwit is designed in an intentionally wasteful way to 'prove' afterwards that on-chain scaling is infeasible; its only real goal was to fix malleability, needed to force everyone to use centralized layer-2 solutions. With a 4MB blocksize 40x scaling was possible, but the only thing segwit gives is about 1.7x...  
A full analysis would result in a full length article, so just one simple example of an intentional waste, from [Segwit's BIP]( 
"[P2WSH's] scriptPubKey occupies 34 bytes, as opposed to 23 bytes of BIP16 P2SH. The increased size improves security against possible collision attacks, as 2^80 work is not infeasible anymore" 
That *sounds* sensible - but why only P2WSH? Because finding collisions for P2(W)PKH requires ECC multiplication, and 2^80 ECC multiplications are infeasible - a method of key stretching. Ok, but... the same could apply to PW2SH! Just treat the SHA256 of a script as a private key, generate the public key and hash that.  
**So either P2(W)PKH addresses are insecure and also need 256 bit hashes, or Segwit is intentionally wasting 14 bytes (per p2wsh tx) for no reason!**  
There's no performance argument because sending 14 bytes across the world is going to take orders of magnitude more time than one ecc multiplication; even loading these 14 bytes from ssd takes more time, it also increases required storage. 
So sadly, it's intentional waste - because it's impossible to not realize all these things during design. They are hard to notice by others though - sort of like underhanded C contest. 
Do you really want people who do things like these to have decision power?
@_date: 2017-03-17 19:09:00


So you want to rely on miners' altruism or what? Trying to herd cats. Mining is amoral. If selfish mining is profitable it's going to happen. It can be hidden by presenting one operation as several independent ones. I would be very surprised if it weren't already the case. 


100MB is 167kBps with cb/xthin/similar. Even if you multiply by 2 for overhead, in 'On Scaling Decentralized Blockchains' they provide the 90th percentile node bandwidth as 378kBps, and that's from 2015. So ~100MB blocks is a very conservative estimate for a point where bandwidth problems start to appear. 
With aggregated signatures and general space optimization that means 1000x on-chain scaling is easy to achieve
@_date: 2017-03-17 20:37:27


Even 36 bits don't change much - 10.73MB, and that's certainly enough. 


I meant that when sending tx you compute its utxo ids say 10 blocks in the past, not utxo ids from blocks its inputs are in. 


Aggregated signatures require just one new script op for ecdsa. The accounting is trivial - is there non-aggregated sig in a transaction? Limits, else no limits. 


Yes, one multiplication, but every transaction is parallel, then every public key multiplication is parallel, but just parallelizing over transactions may be enough. 
@_date: 2017-03-29 09:03:54
Sybil attack is not possible in the authenticated case. 
@_date: 2017-03-22 19:36:37
Compromise is only possible when both sides want the same thing, but disagree about the road to it. When goals diverge only war remains. 
Core wants off-chain scaling and doesn't want on-chain scaling as it makes off-chain less appealing. BU wants on-chain scaling. 
@_date: 2017-03-17 17:58:13


Ok, but that means blocks always have to be validated fully before extending, so orphan risk is directly related to propagation time, which results in miners seeking optimal blocksize. 


I wrote about average bandwidth, which is what matters for nodes - very slow nodes may get delayed for a moment, but are guaranteed to catch up as long as average bandwidth is low enough. 
High orphan rates are a possible decision of one specific miner, not a general property of the protocol:  


I did in both parts, but explicitly: including non-propagated transactions increases orphan risk by slowing block propagation. So a rational miner wouldn't put a new transaction immediately: either wait a while, or have listening nodes all around the world to verify its propagation. There's some optimal combination of all these variables.  
Anyway it's all too academic, these concerns only really start to matter with 100MB+ blocks.  
@_date: 2017-03-24 14:10:44
Great, so you can stay on your Core chain. 
What you *can't* do however is to tell miners they *can't* switch their mining. 
@_date: 2017-03-18 13:05:16
Absurd... PoW without ASICs is not secure by any means, especially with current block rewards. 
@_date: 2017-03-23 15:15:08
Have you thought about going downwards from a maximum private key? Leading zeros could be a result of some weird bug (probably assuming 256 bit randomness that really returns a 64 bit integer), but something in the 2^255 - maximum range would be much harder to explain. 
@_date: 2017-03-17 07:26:06
I like monero for its anonymity and ethereum for constant innovation.  
Monero's ring signatures make it inherently much less scalable. That's one problem, but a pretty important one. 
Regarding ethereum, I'm not convinced there are actual uses for stateful smart contracts. EVM seems to be too weak to do actually useful stuff with high computation cost, but it makes ethereum very complicated and resource-intensive.  
Ethereum is also too centralized: it's hard to imagine darknets using ethereum, whose developers have already proven their capacity to selectively filter&amp;alter ownership. The Ethereum Foundation would eventually get a court order mandating them to freeze selected accounts, and due to DAO event there would be no excuse not to do so. This also applies to other things, perhaps even debt collection! So Ethereum is not a replacement for bitcoin. 
Imo an ideal and practical cryptocurrency would be a hybrid of these three: instead of monero's ring signatures, a much simpler per-block coinjoin with aggregated signatures (so ideally just one per block). Instead of stateful ethereum scripts, turing-complete stateless scripts which would allow instant confirmations &amp; trustless exchange with other coins. So better at scaling than all existing ones, better privacy than bitcoin&amp;ethereum and better scripting than bitcoin&amp;monero. For the same reason it probably wouldn't get much adoption: jack of all trades, master of none. Except scaling, but scaling is only a problem *after* adoption happens... 
A mimblewimble-like solution is another option, but unless something changed it works like a check system: transaction requires the action of the recipient to be committed. This has its own privacy dangers. 
P.S. I also like zcash's zk-snark general solution, but not zcash itself. Making anonymous transactions optional turned them into a coin tumbler with few users. 
@_date: 2017-03-17 15:55:52


@_date: 2017-03-29 06:31:36
The smart contract case would require an op code for verifying zk-snarks
@_date: 2017-03-19 02:43:47
Intentional as in trying to artificially depress btu price. It's easy to ignore the hard fork time bet part and just compare prices. In fact I expect r/bitcoin submissions with exactly that relatively soon. 
@_date: 2017-03-09 06:44:35
That's the general convention for opcodes
@_date: 2017-03-24 12:50:49


There's nothing wrong with creating a fork that increases the number of bitcoins. 


How exactly are miners forcing you to accept a new chain? 


That and is misplaced, nazi = national socialists. 
@_date: 2017-03-21 13:50:44
He's r/bitcoin's Emmanuel Goldstein.
@_date: 2017-03-24 12:04:07


Stop using absurd analogies. Blockchain is more like a subscription to an online magazine. It may happen that there's a disagreement and the redacting team splits into two. You don't have to pay &amp; read the version that you don't like. 


Nobody is going to change old blocks.   
@_date: 2017-03-17 19:43:16


100MB/600s, ok that's actually 170kBps
cb/xthin spreads total bandwidth over, there's variance but that's already covered


That's not a practical problem


Neither is this, the quadratic growth is per transaction inputs in one transaction, blocksize is irrelevant unless there's no separate maximum transaction size limit. Anyway aggregated signatures fix quadratic hashing implicitly and theoretically even allow everyone to interactively coinjoin every transaction, resulting in just one signature per block. 
@_date: 2017-03-19 05:57:17
[Your post illustrated]( - just change the flag. 
@_date: 2017-03-29 08:41:23
Except it's not, if there's a trusted entity distributing the last state is way cheaper. 
@_date: 2017-03-18 14:33:12


@_date: 2017-03-23 11:28:12
Yes, my mistake. 
Are you aware of a detailed calculation for total entropy loss? Taking everything into account, like the fact that (slightly less than) 2^256 private keys are mapped into two valid bitcoin keys: a 64 byte uncompressed public key and 32byte+1bit compressed. 
At the end I would guess like two bits?
@_date: 2017-03-17 10:01:19


He predicted the backlog situation that is occurring now and concluded it dooms bitcoins in the long term.  
What he didn't predict was price in the midterm, but that just means he's not a fortune teller. 
@_date: 2017-03-30 07:48:25
That's a weird security model, it requires the majority of miners to verify the other chain. So it basically replaces the federation with miners. I'm not sure if there's any point. You could as well ask major miners to take part in a multisign transaction. 
@_date: 2017-03-18 20:57:35


Or lack a time machine. "Here's this cool stuff that we *maybe* manage to actually put in by 2025"...  
@_date: 2017-03-17 04:10:13


[You really don't remember this?](
@_date: 2017-03-22 19:45:19
So owning shares in a company is 'socialism-statism regulation'? 
@_date: 2017-03-22 09:05:50
Asserts are for checking design invariants exclusively during debug, for runtime errors there are runtime exceptions. 
Wasn't original bitcoin 0.1 code windows only and used asserts only in debug? Unless he specifically enabled them in release.
@_date: 2017-03-29 08:48:32
nope, the trusted entity is there to authenticate the current state
@_date: 2017-03-17 18:31:01


You could as well flood nodes with low value transactions. 


It can be treated as a potential DOS attack and just refused. 
As a semi-relevant note compact blocks could be improved a bit: it uses 48 bit txids, but only 26 bits are required - deterministic utxo id of first input instead, or in-block index for spending unconfirmed txs. That's a 45% saving in space
@_date: 2017-03-20 06:55:26
Every node uploads to another node, it's physically impossible for every node to upload same block to 28 other nodes, unless every node downloads the same block 28 times. 
Every node downloads one block once, not four times. 


Tell your boss that there's an important difference between Mbps and MB/s.
@_date: 2017-03-26 21:11:16
That title directly contradicts the contents of that screenshot, which makes it malicious. 
@_date: 2017-03-21 18:05:10
You do realize latin alphabet is used by a minority of human population? There's nothing inherently superior in ascii characters. Dns supports unicode as well. Once unicode is supported the emoji range would have to be explicitly excluded for no reason. 
The fact you find usage of non-latin characters absurd has strong racist undertones.  
Hardly surprising for a blockstream employee, the exclusionary nature of small blocks stems from the same core.
@_date: 2017-03-29 06:09:50


This is true but mostly irrelevant, because with encryption censorship at choke point can be made impossible. Well as long as encryption in general is allowed, but that's an independent concern. 


That's true, but only for bitcoin and pow cryptocurrencies, and is not related to block size. 
@_date: 2017-03-24 10:15:16


Thanks for expressing your socialist ideology so clearly. 
As all socialists, you think you own other people and are eager to use force if they 'misbehave'. 
[EIN BITCÃ–INERS, EIN BLÃ–CKCHAIN, EIN CÃ–RE!](
@_date: 2017-03-07 07:46:03
That's a bribe in the same way outbidding other people on ebay is. 
Just yesterday I bribed a shop owner to give me his chocolate.
@_date: 2017-03-20 06:36:42
For uploading that calculator assumes that every node downloads the same block 28 times, but for downloading 'only' 4 times.  
You really should tell your boss to delete that answer from a script. 
Also 


Even on that idiotic site it's **0.04625MB/s = 47.36kB/s**. 0.37 mega BITS per second.   
What an amateur shilling operation. 
@_date: 2017-03-24 12:54:22


You choose to incur it by using the specific chain. 
@_date: 2017-03-17 17:18:25


I don't. The problem with bandwidth occurs if block creation outstrips network's throughput. 'Same time' is blocksize dependent. If a big block manages to propagate it's not a problem anymore. One 20MB block in 20 minutes is as good as two 10MB ones. 
For 10GB blocks the 'same time' is probably infinite. Empty blocks have the fastest validation. It's a monotonically increasing function. There's an optimum somewhere between zero and infinity, which depends on actual technological capability. Parallel validation finds that point stochastically. 


Emphasis on *receive*. Note what happens if they SPV mine: they can only mine empty blocks before full validation as they don't know utxo. But that means that average blocksize gets smaller, decreasing average required bandwidth! A negative feedback loop. The only thing that changes is variance, but bitcoin's design has very wide tolerances here. 
@_date: 2017-03-19 02:55:27


Buying drugs with monero is much safer than with bitcoin, also transactions are cheaper and [less problematic](
@_date: 2017-03-28 19:33:51


There are very few people like that. You have a vision of the world from 1980s. 
"Smartphone connections in Africa stood at 226 million by the end of 2015 and are forecast to increase to 720 million by the end of 2020"
"**Twenty per cent of the continent already have access to a mobile broadband connection, a figure predicted to triple in the next five years.** "
@_date: 2017-03-17 05:30:39




(this was added by him later)
I'm definitely not going to do that because bitcoin isn't anonymous. 
@_date: 2017-03-23 17:34:48


that's a tautology which makes you a statist
@_date: 2017-03-17 18:36:02


Selfish mining is profitable regardless of blocksize and nothing can be done about it. So it can as well be ignored. 


Does ethereum have the equivalent of compact blocks? 
And what does 15 ethereum tps mean in terms of size
@_date: 2017-03-17 04:53:16
I'm involved with Bitcoin since late 2010. I sold everything (except one bitcoin) shortly after etf denial.  
Why: bitcoin was supposed to be an agorist money empowering oppressed people. That means fees close to zero (block reward is more than enough), not &gt;$1, and certainly not centralized off-chain solutions, even if they magically were to become successful. LN in practice would result in a very small centralized network with full KYC/AML and SARs, comprised of Coinbase and similar entities. That's because LN has enormous economies of scale due to frozen deposits &amp; on-chain channel closing.  
"Grey" bitcoins outside of that network would eventually become illegal. 
If lack of scaling was for technical reasons all this would be sad but inevitable, but it isn't. 1MB blocks alone could support 10x more capacity with hardfork improvements. Make blocks 10MB (which means just 16.6kBps of continuous bandwidth to download! [Even Mt. Everest has better internet]( and that's a 100x capacity increase, enough for the next several years. 
The reason I didn't sell in the past is because etf approval would almost certainly create an enormous bubble. 
@_date: 2017-03-18 14:42:01


Everything wrong with r/bitcoin summed up
@_date: 2017-03-22 19:51:48
It's like saying you can't go to the Moon with a car. The problem is in that 550bytes/tx.   
Protocol is in urgent need of real scalability upgrades. Technically a block size (naked bytes, not current structure) increase isn't necessary now but politically it's the only feasible way. 
@_date: 2017-03-24 10:50:29
Which are paid for by the users. 
@_date: 2017-03-24 11:01:57
Are you trolling at this point? Miners are just one type of users - those that mine. Mining or non-mining, users who don't like the arrangement any more can just leave. 
@_date: 2017-03-21 21:55:15
It wasn't, but there was no way to profit from it. 
2012, mtgox was the only relatively big exchange, no shorting. Smaller shops like bitcoinica very unlikely to pay out anything after such attack. Didn't pay anyway xD  
No way to short and profit.
Also the inflation was much higher, so the relative cost to attack was higher too.
@_date: 2017-03-19 06:14:40
Why not 1TB/s if you're already making ridiculous stuff up? 
The only thing that needs to be propagated is a block header + list of transaction *ids*. Look up [compact blocks]( and [XThin ]( 
"**An average full 1MB block announcement can be reconstructed by the receiving node with a block sketch of 9KB**, plus overhead for each transaction in the block that is not in the receiving nodeâ€™s mempool. The largest block sketches seen top out at a few bytes north of 20KB."
That's from *Core*. Bandwidth-wise what matters is blocksize divided by time between blocks.  
Even that is slightly inefficient: it uses 48 bit txids, but as of now only 26 bits are required - deterministic utxo id of first input instead, or in-block index for spending unconfirmed txs. That's a 45% saving in space.
@_date: 2017-03-19 06:49:28


Which is related to running a node how?


[Yeah, about that...](
you got manipulated by bitfinex, sorry. 
@_date: 2017-03-17 21:37:00


Well all this is like $500k-$1M worth of developers' work. Unlikely to happen in the current arrangement. 


Only for old non aggregated ecdsa signatures, the limits are already there. The only sensible use for them is if someone has an old timelocked transaction or otherwise signed tx but not sent. 
All new transactions can use aggregated signatures with no quadratic hashing problem. It's not such a problem for 1MB but 100MB is a different story
 I don't see any negatives
@_date: 2017-03-23 15:21:36
World War 3 is going to happen eventually, this time with nuclear weapons or something even more powerful, doesn't mean we have to rush it. 
@_date: 2017-03-19 03:02:06
You wrote that you are a software engineer. Think about how bitcoin protocol works, how it can be scaled and you will arrive at similar numbers.  
@_date: 2017-03-22 11:45:48


So an assert failure in core means a buffer overflow somewhere? That's not an appropriate level to detect these attacks. Are stack canaries enabled? Runtime bounds checking? It's even hardware accelerated on skylake+ (mpx).  
These simple errors are mostly a thing of the past with them and most importantly they keep the code clean. And any exploit that goes past them could also deal with asserts.  In fact if you're really checking for impossible conditions there's a very high probability they are optimized out, or could be in some random gcc version. There were lots of bugs due to that.  
Are you setting -fno-strict-aliasing? Github search finds no match. [Gcc having fun with strict aliasing rules is the worst offender](
@_date: 2017-03-17 17:33:12
Compact Blocks are vulnerable to non-miner DOS only by providing fake txids for a new block, but the origin of fake data is easily identifiable. 
@_date: 2017-03-24 09:27:42


That's like saying going to a mass protest and yelling '&lt;DICTATOR&gt; OUT!' along with other protesters has no relevance, because you don't *really* want the dictator out of power.  
@_date: 2017-03-26 21:06:17
1. It could be someone from medium  
2. He probably meant that it was ok for that person to share it with others, just not publicly
@_date: 2017-03-17 18:49:14
Ok, so instead of refusing compact block protocol transactions are withheld before. This means that neither block times nor blocksize are relevant because similar attack works today. If you control all connections to one node you can pause all traffic for eg. an hour and dump everything at one moment.  
@_date: 2017-03-29 00:36:58
Title is wrong, it crashes after trying to **read a segwit blockchain from disk**. NOT when it sees blocks on testnet. 
**This is a reasonable behavior, data from a not supported format is indistinguishable from data corruption.**
@_date: 2017-03-19 04:19:37
That's very little data. You may live in an otherwise rich country but $120 for consumer internet is ridiculous. Hundreds of millions of people in the world have unmetered connections, enough to support the rest using spv clients. 
It's not a secret that American consumer internet is horrible. 
@_date: 2017-08-25 11:00:05
7x8MB per 12 hours is equivalent to 9.33 hours of 1MB blocks. 
That's not death. Hilariously that's actually higher capacity than BTC's at the moment (3.33blocks/hour vs equivalent of 4.66blocks/hour). 
Even if it occured, sooner or later there would be a hardfork to some other difficulty algorithm and that would be it. Hardforks *are not a big deal*. Really. 


If a hostile miner stops mining, EDA gets activated. 
As long as there are miners willing to mine 6 blocks at a loss, or paid to do so, there's no way for the BCH chain to die.
@_date: 2017-08-21 14:28:48


What? There's no 'exploitation', correcting the difficulty after upward adjustment is *the whole point* of EDA. Rational miners should mine the most profitable chain only. Right now multipools are being implemented.  
Very likely that soon overwhelming majority of hash power is going to be on the 'most profitable chain at the moment' setting :)
@_date: 2017-03-23 17:26:29


Which is done by what?  


The point is not to exploit some implementation quirks, but to detect a possible fundamental problem. Vast majority of bitcoin's keys were generated by a known software, so a key that can't be explained by their faults would be much more interesting. 
@_date: 2017-08-21 21:14:27


Coins that can survive massive drops in hashing power remain in a perpetual oscillation. 
@_date: 2017-08-11 22:32:31
LN is actually easy to understand with the right analogy - it's a network of personal (as opposed to bearer) certified checks. It's possible to perfectly emulate expected behavior (ignoring malicious actors, as that requires cryptography) with the following scheme:  
- everyone can create checks, provided that each check is payable only to a specified individual, **and that you set the physical cash needed for that check aside**. Creation of a first check (or pair of them) between two people is equivalent to opening a channel in LN. 
- everyone can unilaterally deposit any check to his name with a delay (equivalent to going to a bank). Unilateral channel closure in LN. 
- to get cash from a check instantly, payee and signer have to cooperate - ie. the signer gives the payee cash. Bilateral channel closure in LN. 
- there's always at most *one* valid check between any two people - the most recent one; all previous are invalid. Updating the channel state in LN. 
@_date: 2017-08-25 12:12:56


Clearly an unheard-of thing in bitcoin :)
@_date: 2017-08-19 01:30:27
What? If mining was done on individual cpus a big block fork would be done a long time ago. Centralization is why it occurred so late. 
@_date: 2017-08-10 05:10:39
First post


Second post


Because staying indefinitely on one address is so private...
@_date: 2017-01-30 22:23:06
Only once, all subsequent transactions are in the extended block. Eventually, the legacy block would wither away due to lack of spendable inputs. 
@_date: 2017-01-30 05:04:22
Why? Block can be increased as a softfork infinite number of times. 
Just use one of nop opcodes to make a transaction that can be only spent in the extended portion. Ie. op is a nop in legacy portion, but something else in the extended.  
eg. OP_DUP OP_HASH160 &lt;pubKeyHash&gt; OP_EQUALVERIFY OP_CHECKSIG OP_1NEGATE OP_NOP4
Where OP_NOP4 means pop only in the extended portion. Can be extended infinitely by making OP_NOP4 take an argument on the stack. 
I don't understand why segwit wasn't done in this way though
@_date: 2017-08-20 18:10:04
He is not 'clarifying' the *entire point* is that latency can lead to orphans. 
@_date: 2017-01-25 22:09:49
In Venezuela you 'steal' electricity if you use it for purposes the state doesn't agree with. 
@_date: 2017-08-21 13:52:56
There's not going to be any frozen state because of emergency difficulty adjustment. 
@_date: 2017-08-11 00:37:03
It's going to take months before segwit alleviates space shortage to any noticeable degree, as at the start everyone is still using current addresses. 3 months is absolutely not enough. 
@_date: 2017-01-25 21:12:45
That's absolutely *NOT* a proof of spam. 
Mempool stays at ~0 as long as new transactions between blocks fit in the next one (on average). All it takes is ONE transaction more and mempool increases until nodes start to drop old unconfirmed transactions. 
@_date: 2017-08-11 02:44:09
Meanwhile you can rent a dedicated server with 8TB hdd + 32GB ram at [hetzner]( for $55/month. Argument disproved. 
Also, to accept payments a pruned node is enough. 
@_date: 2017-08-21 21:06:17
Why no mention of EDA? That's the most important difference. 
@_date: 2017-08-22 18:49:13
Anything more than 1satoshi/byte is overpaying. That's about 0.15 cents now for a typical tx. 
@_date: 2017-08-28 04:28:43
LOL what a BS, you would need to be Satoshi
@_date: 2017-08-20 14:32:51
There's also no room for infinite humans, so let's permanently limit human population to 1M.
@_date: 2017-08-24 10:55:12
Privacy, there's no difference in fees. 
@_date: 2017-08-22 18:50:35


Don't worry. 1 satoshi/byte is enough, seriously. 
@_date: 2017-08-08 19:22:47


What you meant as a 'big, absurd number' turns out to be about 1MB/s with efficient transaction format. 
In other words, something that could easily run on a LTE smartphone TODAY. 
@_date: 2017-08-20 15:19:27
That 'objective' analysis is completely bogus. They claim 2GB *used* RAM per 1 MB of block size because minimum requirements for running a bitcoin node are 2GB *total* - installed in a PC. Which is off-the-scale absurd. Especially because 8MB blocks were processed recently and didn't use 16GB. 
They base their claims of node bandwidth based on statoshi's node bandwidth use, which is as absurd for three reasons:  
1. Every node downloads everything only once. Which can mean that one node with the fastest upload uploads everything to everyone, or that every node, except the last one, uploads data to another one. If few nodes use most of bandwidth it's because they *can* and have best connections. The only reasonable assumption for average use is one upload and one download.  
They claim **148kB/s for 1 MB = 86MB per block. There's nowhere for that 85MB to go! There's only one 1MB block!**
2. Bandwidth use of a live node includes uploading old blocks, which doesn't impact propagation of new blocks and transactions at all, as they either are or can be prioritized. 
3. All this *doesn't matter* for really big blocks because their existence means bitcoin's use is so widespread as to allow use of multicast, making bandwidth a complete non-issue until 1GB+ blocks. 
In summary, the paper you linked to is so ridiculous it reads like a satire made by a big-block proponent. 
@_date: 2017-08-20 14:31:19
Latency is only impacted by size if available bandwidth is saturated. So the question is 'what bandwidth is readily available to miners'. The answer is 10Gbps.  


Yeah that's all you need to know whether to listen to them. 
You can physically double any possible bandwidth by doubling the amount of network cables, or lasers, or however you transport data. Magic. 
Technically there's a physical limit where the energy density becomes so great that your data packets would collapse into a black hole, but somehow I don't think that's what this guy meant lol. 
@_date: 2017-08-11 00:54:33
The proper way would be to implement any proposal and allow miners to vote on it. Instead what gets into Core is decided by a small clique of self-appointed dictators.  
The *real* function of BIPs is to waste energy of any outside developer till they go away. It's much smarter to let an enemy keep an illusion of possibility and make him waste energy on pointless endeavors rather than blocking outright.  
There's zero point for any outside developer to propose anything - as the chance of getting anything accepted is zero. 
@_date: 2017-08-20 17:15:47
I ran a node actually and haven't noticed any extensive resource usage. It wasn't noticeable really. 


Which I already explained:  
"If few nodes use most of bandwidth it's because they can and have best connections."
Every node downloads a block *once* which means every node, *on average* uploads a block *at most* once. Which means that's all the average node has to be able to do. 
@_date: 2017-08-20 20:54:37
Just because there exists a size that is big enough to be infeasible is not an argument against smaller increases. 
For all you know, by the time usage grows to saturate &lt;currently practical size&gt; most people are going to use 10Tbps neutrino wireless internet. 
@_date: 2017-08-26 00:31:45
You had a chance to write something intelligent for a change but it's clear you are unable to articulate any coherent argument, so it's pointless. 


Yes, I agree that average fee of $8 proves that small blocks are horrible. 


You clearly weren't as you would know it was 32MB lol
@_date: 2017-08-21 16:27:53
As opposed to 170 days in btc's case.
@_date: 2017-08-20 17:21:59
What you quoted is not relevant in the slightest, it's about Segwit counting signatures (spending scripts) as 1/4 bytes. 
@_date: 2017-08-24 17:58:35


Number of inputs and outputs, not addresses in itself. It's transactions that are spent, not addresses. 
@_date: 2017-08-24 18:21:08
An utxo is an unspent *transaction* output, whether it's the same address or not is irrelevant. Two transactions to the same address create two utxo
It would be called uao otherwise :)
@_date: 2017-08-31 14:58:18
That's not a good information. 
Disrupting regulations is the whole point of cryptocurrencies. 
@_date: 2016-12-17 19:27:55
1. What timezone? UTC?  
2. I think you should change the format. It doesn't work well with public predictions, because the most efficient answer is to bet one cent above/below the closest answer to what you think is right. So the most efficient idea would be to post at last minute taking that into account.  
3. 'Wisdom of the crowds' loses its efficiency when people are aware of the popular answers.  
The best method would be to post your public key and tell users to encrypt their answers. 
@_date: 2017-08-25 20:52:30
Your whole post is full of insults and baseless assertions without even one actual argument.  
It's on you to prove the impossible - that blockchain would magically self-destruct with 128MB blocks. That's all that's needed for 2000+ TPS.  
On-chain scalability was never an actual technical problem. 
@_date: 2017-08-20 17:10:28
He explicitly talks about latency resulting in orphans, start at 49:50
at 50:01 "and when you done mining it"
@_date: 2017-08-08 21:41:54
Consensus-defining entities in bitcoin are miners, not relaying nodes. Users just need to be able to download a block (from miners) before the next one comes (on average). 
@_date: 2017-08-11 04:44:08
It's a textbook black swan because majority dismisses it automatically as impossible, yet it's unlikely but possible, and it would be very likely fatal.  
If bitcoin was the only viable sha256 coin that would be a much smaller danger. In that case the mining power would have to completely disappear for long. It's much more likely if miners can switch, especially if the other chain is more profitable. 
Once that happens there are several factors all accelerating the problem:  
(1) Mining rewards can only be spent after 100 blocks. Normally that's about 17 hours. If 90% of mining power disappeared that would take a week. So that's a strong incentive to mine something else (if available) in itself.  
(2) Bitcoin economy grinds to a halt, as transactions become increasingly impossible. This leads many people with coins on exchanges to buy other coins just to be able to transact, which lowers the price, making the alternative chain even more attractive for miners.  
Which means that, as miners leave, the higher incentive the remaining miners have to also leave. In the event that almost all miners leave the difficulty reset never happens as chain dies. 
@_date: 2016-12-08 19:51:08


The purpose of one account is to use multiple inputs if fewer aren't enough. So by using one wallet you already assume it's one entity. So eventually all addresses will be revealed in some transaction more or less connected to you.  
You could freeze addresses etc., but that would be just a weird manual way of having a completely separate account. It's also easy to make mistakes. So it's better to use a completely separate entity. 
@_date: 2017-08-21 15:21:09
It's not an exploit but a feature. Figure out why :)
@_date: 2016-12-08 15:17:52
There are less nodes *because* of low blocksize. Nodes were run mainly by enthusiasts; bitcoin used to be about freedom from the state, hope and sending $0.01 without fee to friends to show them what it is.  
Now it feels like a government-friendly corporate product that doesn't care about happy users because of network effects. Like paypal. Why would I run a node for paypal? 
P. S. TB ssds are very cheap now.
@_date: 2017-08-25 00:03:34


This is equivalent to spv mining which could lead to invalid blocks, although it's much worse with segwit because they are going to be correct for old nodes
@_date: 2017-08-10 00:52:55
Not to defend the scam that is bitfinex, but $300M in deposits is not a ridiculous sum given the size of the bubble in altcoins. 
Afaik currently the only real source of tethers is withdrawal from bitfinex. So any usdt on poloniex had to come from bitfinex. 
To get usdt, people would have to deposit either (1) coins or (2) dollars from Taiwan. There was a period of depressed btc price which would be compatible with (1). Depressed price increased arbitrage by users and most likely by Bitfinex itself. Most of that arbitrage went to tethers which went mainly to poloniex. 
...Which would mean that bitfinex is sitting on an enormous amount of cash sprinkled over several shell companies, making it a very fat target. 
@_date: 2017-08-31 23:13:53
You're right, but your words ring hollow to most as long as the price continues to rise.   
Bitcoin has a maximum price point - or more precisely *average* over a year - but its value is hard to estimate. 657000 bitcoins are mined each year, for the next three years. At $4750, that's $3.12 billion annually. That much has to flow in - ending up nearly 100% as energy cost - to keep the price stable. 
At $475k/BTC - a 100x rise - the world would have to throw in roughly the entire GDP of Denmark to buy energy for Bitcoin mining. Just, no. 
At $47.5k/BTC it's $31.2 billion a year. Which is still absurd - but at least feasible. 
@_date: 2016-11-27 15:39:42
Hi, I own nano s and just checked, using it with one hand is very simple. You may need to invert the screen though (in settings) so that two buttons are on the top. 
@_date: 2016-11-25 07:13:09
That's not the correct chart for that  
This one is. Mempool's size is going to start increasing into infinity as long as rate of new txs &gt; tx throughput. 
@_date: 2016-12-27 21:51:33
No, that's not how bitcoin works. You don't spend addresses, you spend transactions. 
@_date: 2016-12-08 18:22:37


Yes, although that's what the account field in BIP44 is for. Only subaccount keys are publicly derived. 


It's also true for SPV, an electrum server knows all addresses I have in one wallet, but given how bitcoin works, that's not a real difference.  
If you want reliable privacy you need a completely separate set of addresses + a separate network identity anyway. Not only IP but also packet structure. A separate spv wallet from another pc (like a vps) offers more privacy than a full node on the same computer, and is much easier &amp; faster to set and use. 
@_date: 2016-12-08 03:10:24
The happenings in India are getting weird... their government is either off the scale stupid, or is preparing for war. 
@_date: 2016-11-24 02:25:20
This is really sad... they're really going to destroy Bitcoin.  
1. is false, because it's easy to create a fork that invalidates another chain via an implicit 51% attack. So there's zero risk of two chains, one wins and that's it. ETC only exist because Vitalik was arrogant enough to think nobody would bother with mining the old chain.   
2. A static system is synonymous with a dead system. It's delusion to think Bitcoin can survive without changes. It only seems entrenched compared to altcoins, but in the grand state of things it's WordStar. It was a dominant word processor for DOS, but it eventually lost to Word, as it turned out there are way more potential new PC users than there were existing ones.  
3. This one probably stems from the fact that most (all?) c-re developers are American and automatically assume USA is best in everything. In fact America has horrible consumer-level internet infrastructure, outside of few projects like Google Fiber. Now even in a third world cities fiber net is very cheap - [$17/month for 200Mbps]( in China. ~$25 for 600/60Mbps in Poland, [~$9/month for 1/0.5Gbps]( in Romania. There are many other examples. Those with slow net and/or data limits should just use SPV clients, possibly over tor. It may well be that running a node in America is feasible only in a few places with fiber net, I don't see how is that a problem.  
Regarding disk space, requiring nodes to use full blockchain is completely unnecessary, as utxo set + ~month of blocks offers equivalent security, as long as state of utxo set (ie. a hash of merkle tree) is included in the blocks. The security is equivalent because if someone hostile has enough power to create a winning &gt;month-old fork bitcoin is worthless anyway.  
@_date: 2016-11-24 04:18:43
Try to prove it somehow then, right now you're insisting the equivalent of - the Sun orbits the Earth just because it does. 
@_date: 2017-08-27 22:01:10
With reversed prices bitcoin core would die and that would be it. EDA is problematic but the standard difficulty algorithm is a massive security hole.  
So many people don't realize how hard a problem this is. It requires time-dependent difficulty adjustments separate from blocks, but making miners follow true time is a problem.
@_date: 2016-11-24 04:08:45
You're disagreeing with objective, technical facts - ie. reality. I'm not surprised though. 
@_date: 2016-11-24 02:56:58
1 is false, because it's easy to create a fork that invalidates another chain via an implicit 51% attack. So there's zero risk of two chains, one wins and that's it. ETC only exist because Vitalik was arrogant enough to think nobody would bother with mining the old chain.   
@_date: 2016-11-25 06:25:36
Just because Ethereum's developers are incredibly arrogant and have next to zero QA &amp; QC doesn't imply anything about hardforking in general
@_date: 2016-12-08 16:13:20
"Average Joe" doesn't and isn't going to care about bitcoin regardless of the blocksize and cost to run a node. 


Objectively wrong, I used to and would run a node if Bitcoin was something to support. Instead I was told it's not for me and others, it's for 'settlement' between payment hubs. 
For those that care even 1GB would be too much, for the rest storage is not an issue. You probably spend more on coffee monthly than what 1TB hdd costs. **I definitely paid more in tx fees in 2016.**
Bandwidth is practically free. 
32 MB blocks require 55kB/s + overhead. I had enough bandwidth for that in 2000, 2Mbps/512Kbps I think. So bandwidth-wise, I guess something like 8MB would be apt for 2000. Obviously storage was much more limiting then.
@_date: 2017-11-15 01:07:12
Your experiment ignores size of transaction. 
People with the highest fees have lots of inputs. Most don't know what this means so fee seems random. 
@_date: 2017-04-17 02:26:44
You got banned for posting lots of duplicate submissions, it's called spam. There's no way reddit didn't warn you about that. 
[Example 1](  
[Example 2](
It appears you wanted to be banned to create a false narrative. 
@_date: 2017-04-19 13:31:10


By listing the entire list. Or having a structure where you can prove that in some more efficient manner. 


It's not efficient. It's easier conceptually but sucks in practice. In fact every optimization possible for this approach is also possible for the gas based one. 
@_date: 2017-04-16 17:44:15
That... sort of defeats the whole point of a hd wallet
@_date: 2017-04-01 01:35:40
Temporary binary-only releases are the only sane solution to a publicly unknown exploitable bug. They don't impact security in any way because it's still very easy for any competent coder to check what the changes are; what they do protect against though are script kiddies who don't know how to do that, but know enough to create an exploit given a source-level patch that fixes it, potentially with more details in a commit or related comments.
@_date: 2017-04-17 02:54:20
No, that's probably the reason he started spamming with links like these.  
it's not a mistake, reddit explicitly notifies you if a duplicate exists
anyway his posts are of very low quality so hardly a big loss
@_date: 2017-04-12 06:24:27
There's no hypocrisy. It wouldn't even be hypocritical if he had owned patent himself, but he doesn't. Disagreeing with something doesn't make it go away. Paying an income tax while being opposed to it is not hypocritical. 
@_date: 2017-04-16 19:32:28


?!? That's so non sequitur I don't even


Said a guy who made yet another post about roger that got on the frontpage. 
Was there even a day in the last three months without a popular roger-is-evil post? That's overdoing it even by Oceania's standards  
Right now I count five, going just by the titles... that's 20%
@_date: 2017-04-12 06:43:34
In bitcoin the only full nodes planned within the incentive system are either mining nodes or ran by businesses for payment processing. Both camps gain with increased number of transactions.  
Other nodes aren't necessary and are set up only for political or altruistic reasons. At best they may decrease the bandwidth load of non-altruistic nodes, but that's valuable only in the very early phase. Mature phase means multicast which would make them completely redundant. At worst, if there's too many of them, they may actually pointlessly increase bandwidth needs of real nodes. 
A pruned node is enough if you are paranoid about a temporary 51% attack. 
If you show up uninvited and start cleaning floor in the supermarket don't get mad when it gets dirty from all actual paying customers. 
@_date: 2017-04-01 03:16:20
It's not only easy, but *trivial*, unless code is obfuscated, but that would be a warning sign in itself. 
It's not reverse engineering of a completely unknown program, but a minor change in something with a known source. 
@_date: 2017-04-14 00:41:33
Are you referring to something that's defined somewhere, or just a general idea?
It's true that blocks can be made about 10x more efficient, curious if anyone is actually implementing something like that 
@_date: 2017-04-14 23:06:29
It's not veiled at all, it's alt-right's semantic tag for Jews
@_date: 2017-04-23 03:44:17
Apparently inter-Taiwan withdrawals still work. So if you can open a Taiwan bank account, you could transfer money out. 
@_date: 2017-04-17 04:22:26


That's only because use during weekends drops enough so that a backlog disappears... usually  
The paradox: bitcoin works as p2p cash only during weekends (holidays are an additional bonus) if no newcomers arrive to do the same...
@_date: 2017-04-29 16:15:46


Already possible. The *only* thing segwit allows is *downloading* that data and knowing it's pow-valid, because it's hashed separately. 


Nope because signature is a fixed part of a normal transaction, but spammers get the full discount. P2WSH spending script is fully discounted and is limited to 3600 bytes (relay policy) or 10k (consensus), required non-discounted data is just a few percent of that.  
So yes, it's a fact that segwit prioritizes spam. 
@_date: 2017-04-15 02:11:25
They claim 2GB *used* per 1 MB of block size because minimum requirements for running a bitcoin node are 2GB *total* - installed in a PC. Which is off-the-scale absurd.  
They base their claims of node bandwidth based on  statoshi's node bandwidth use, which is as absurd for three reasons:  
1. Every node downloads everything only once. Which can mean that one node with the fastest upload uploads everything to everyone, or that every node, except the last one, uploads data to another one. If few nodes use most of bandwidth it's because they *can* and have best connections. The only reasonable assumption for average use is one upload and one download. 
2. Bandwidth use of a live node includes uploading old blocks, which doesn't impact propagation of new blocks and transactions at all, as they either are or can be prioritized. 
3. All this *doesn't matter* for really big blocks because their existence means bitcoin's use is so widespread as to allow use of multicast, making bandwidth a complete non-issue until 1GB+ blocks or so. 
In summary, the paper you linked to is so ridiculous it reads like a satire made by a big-block proponent. 


With aggregated signatures (which don't require schnorr) and better data format average transaction can be compressed about 10x. 128MB should be enough for visa scale. 
@_date: 2017-04-25 12:55:44
No.  
LN is way too complicated conceptually. I don't mean implementation. User interface can hide *implementation* but not basic functional blocks. Attempts to hide the latter ends in complete disasters like [Microsoft Bob]( or Clippy.  
Funding exhausted payment channels, frozen funds? 'I have 1 bitcoin, why could I send 0.1 instantly an hour ago but now have to wait for confirmations?'. Dealing with hostile counterparties? Forget it.  
The overwhelming majority of bitcoin users already think bitcoins sit at an address, which ends up in a very confusing behavior regarding transaction fees. A good example of a complex technical detail that directly impacts function which makes all attempts at hiding it futile. Most wallets show only addresses in a misguided attempt to make it simpler, which worked only with near-zero fees. 
That complexity is not a LN-specific problem, it seems to be inherent to these technologies. 
@_date: 2017-04-24 16:55:58
You shouldn't compare transaction counts like that.  
All of these except 50kB are 1-&gt;1 transactions. 5235 of 1-&gt;1 p2pkh could fit in a standard 1MB block.  
Maximum number of transactions for a segwit block is 9173 of 1-&gt;1 p2wkh, 75.2% more. 
@_date: 2017-04-25 08:48:09


Which is a major disadvantage. Following transactions without being able to validate or spend them is pointless. Pure waste of resources - bandwidth, storage, memory and cpu time.
@_date: 2017-04-29 19:09:38


How often do you see yourself sending a jpg image in a pw2sh spend script (compressed to 3597 bytes )? Or divided into several 3597 byte parts. 
@_date: 2017-04-18 23:04:58
Because the past norm with Lenins doing speeches on the street is so much better  
I'm going to choose a high-functioning autist instead, thanks
@_date: 2017-04-29 18:34:23
Not equally, normal (fully segwit using) non-multisig users get about 1.7bytes for one byte weight, but spammers almost 4 for one byte weight. Which translates into spam being 2.35x cheaper. 
@_date: 2017-04-01 03:34:32
The closes thing is Chrome, it has binary autopatching and changes in Chromium appear with a delay. In general severe bugs are commonly kept secret to the general public until the fix is out. 
In general there are not that many open source projects that (1) have a centralized binary distribution (ie. one web page/server, not a distribution's repository) and (2) can have remotely exploitable bugs. Outside of browsers I can't think of any other. 
@_date: 2017-04-01 15:25:26
Can't tell if it's satire or serious. Which I guess is a necessary property of good satire. 
@_date: 2017-04-19 16:14:58
It should be 24 hours, as that's the usual period for a dynamic ip change.  
You're counting a relatively big subset of the nodes 30x. 
Another option is to weight past connections by proportions based on current connections (per client string). You can get an estimate of overcounting by comparing the distributions. 
@_date: 2017-04-30 16:10:47
Standard behavior of [Orange Livebox]( connection. Their userbase goes into hundreds of millions. Not only them, very common for dsl in general. 
[Random recent French thread]( "You cannot change the IP address of the Livebox, it's dynamically allocated by Orange and changes each time you restart your internet connection."  
[Older from the UK]( "I get Dynamic IP Address, which means everytime I reconnect to my network, it will give my computer a different IP. "
Nothing explicit about 24h as most users don't leave computers running that long... but that's the standard lease lifetime
Then there's mobile internet where ips last a few hours.  
You really have a habit of assuming everyone is like you do you, in reality being very far from the mean. 


I explained to you how to get a much better statistical estimate already. Not an opinion, but an objective mathematical fact. 
@_date: 2017-04-01 03:54:49
As a temporary measure
@_date: 2017-04-19 06:02:26
**"gas based witness":** 'every account from list X that has A in its name gets 1 plumbus'.  
List X can be really big, or searching in it hard, so for every step executed during search you have to pay a gas unit.    
**"trace based witness":** 'DFXAX is in the list X and contains 'A' so he gets 1 plumbus. YTUA is in the list X and contains 'A' so he gets 1 plumbus. DRAX is in the list X and contains 'A' so he gets 1 plumbus'  
Conclusions in the presentation are nowhere as strong as what the title suggests. It's basically 'sometimes the second approach is better, sometimes the first one'. Ethereum uses gas. 
@_date: 2017-04-30 14:14:22


Equivalent to trusting sufficiently difficult POW, already possible without segwit.  
Not validating signatures is equivalent to not validating full transaction chain. There's no difference between stealing 1M btc (fake old transaction) and creating fake 1M btc -&gt; both lead to total failure. 
The only new thing enabled by segwit is easier downloading of history for the purpose of blockchain analysis. 
@_date: 2017-04-30 16:29:26
\&gt;53.2% of hashrate for a hardfork  
\&gt;sees that as a win for segwit
@_date: 2017-04-30 22:21:06


Every moment is equivalent. Every 15 minutes could be used. Add percentages over last 30 days and divide by number of samples.


Yet that appears to be a major actual use of this. 


That's just not possible with one node. If you don't have data making it up is not a substitute. 
As you make knots you could add a statistics module that reports ips to a central server (as long as the node owner agrees). If you managed to get enough nodes from all around the world, summing all unique ips active in 24 hours could get something close to the true number. 
@_date: 2017-04-28 21:25:39


LOL no  
that's pure marketing to make dumber customers think it's a regulated pharmacy. No online Indian pharmacy actually cares. 
@_date: 2017-04-30 15:20:14
Ok, it indeed prevents double-spends of old transactions in recent blocks in a way that's not possible today.
@_date: 2017-04-14 01:28:17
50 to 100 fold? You mean per byte? Ok that's impossible in the general case.  
It would be nice if you could provide more details though 
@_date: 2017-04-17 23:40:47
Parallel validation is the only real fix to performance issues. It means the validation time of a transaction impacts its required fee. In the best possible way, determined by real costs incurred, rather than arbitrary constants, like gas price.  
It doesn't increase resource use (although their implementation may and seems to really suck, based on a shallow look). The fact they they talk about *threads* points to a fundamental misunderstanding. The only new structure you need is a tiny (&lt;1kB) lockless queue.    
Optimization is all nice but there are limits to it. 
@_date: 2017-04-28 15:45:21
Can it survive 100 degrees?
@_date: 2017-04-18 07:34:14


The hashing function for bitcoin version 1 addresses, which is what is being tested  
f(x) = ripemd160(sha256(x))


It's unlikely it was an attack, everyone who would run it, most likely runs it in chroot/jail/sandboxie/etc anyway  
It's not something for an average user
@_date: 2017-04-15 18:10:07
There's already [an older post]( with this tweet, without editorialized title
@_date: 2017-04-15 18:12:30


That's called socialism  
Free market is a direct opposite...
@_date: 2017-04-14 22:52:01


What? Life is not a computer game where you find parts of encryption keys lying on the floor. 
@_date: 2017-04-18 08:07:57
Input data as good as any, and nobody would care about it if weren't connected to bitcoin. Very good marketing. 


your point? do your run untrusted software on your normal account?
@_date: 2017-04-25 13:17:48


It's you who stated the security is worse, so you should provide a counterpoint. Proving that 2=2 is a complicated endeavor. A scenario in which not following transactions has worse security just doesn't exist. Listing every case in which they are equivalent is not a very effective use of time. 
@_date: 2017-04-28 21:19:13
I can't tell if this is an ad for that pharmacy or if someone genuinely just discovered that. Probably (like 90%...) the former. 
Still it made me feel like it's 2012 again. 'Did you know you can buy drugs with bitcoin?!? \*gasp\*'
@_date: 2017-04-19 00:32:59
I'm not being sarcastic. 


Like what? Unless you are doing something that uses 'complicated math' itself, it's not needed at all


Which can be learned in few weeks of doing algorithmic competitions... nothing complicated here


The main thing that comes with experience is learning to tone down the abstract as it ends up being overengineering
Sorry but you sound like someone who started programming while at a university, while Vitalik more like someone who was a lisp zealot at 15... (probably not *exactly* that)
@_date: 2017-04-24 18:01:49
That would only make sense if all counts were restarted today. Multiple counting already happened: 
["could be but it also may be that Luke's technique is flawed or hey maybe we really got 60k more nodes in 30 days"](
@_date: 2017-04-01 09:58:19
Look up IDA and hexrays. It's really trivial. 


Not possible. The point is what to do once an exploitable bug is found, not how to prevent them.
@_date: 2017-04-12 16:45:55
If large mining farms are suddenly banned bitcoin stops working anyway.


You keep repeating this, [I explained to you already]( that 128MB blocks are more than enough for visa levels. 


Zero conf actually works perfectly well for smaller payments if blocks aren't full.
@_date: 2017-04-14 22:46:19
I don't even...
@_date: 2017-04-15 04:15:59


argument from authority


ad hominem


proof by assertion
If you were trying to demonstrate logical fallacies in practice, you managed to hit three. If you had some other goal you failed miserably. 
@_date: 2017-04-01 10:12:41
You shouldn't use a wallet on a listening node, also it should be ran separately. At least in chroot or sandboxie


Are you really verifying all commits?
@_date: 2017-04-27 21:01:45
This bug is hilarious 
@_date: 2017-04-13 14:48:59
It's best to stay far, far away from anything in any way connected with Mircea Popescu. 
@_date: 2017-04-01 10:02:48
No but at worst they preserve structure, especially with relation to external calls.  
Source: look up ida &amp; hexrays. In this case finding what changed is really trivial. 
@_date: 2017-04-28 20:37:02
That node counter counts any ip seen for four weeks afterwards, significantly overcounting any nodes with dynamic ips. [Source](
@_date: 2017-04-01 15:17:29


Which is an independent property, no reason not to sign binary


Neither BU nor Core is GPL. Still it would be legal as long as it's temporary, they could send source via snail mail. There's no online requirement in GPL
@_date: 2017-04-30 21:04:12


I explained that to you previously. Every set of active connections, at one moment, is a random sample of the distribution. These *percentages* should be averaged over time, not ip count. That's the only mathematically sound way to estimate the true distribution. 
@_date: 2017-04-24 17:31:48


That node counter counts any ip it noticed as active for 4 weeks.  
It's not even close to accurate. A dynamic ip that changes every 24 hours is enough to get counted 28x. 
@_date: 2017-04-17 04:23:53
Or he just had many small outputs... value of transaction has nothing to do with its fee  
Dumb wallet + lots of small outputs (faucet, automatic affiliate % payments, lots of small buys &amp; withdrawals) = pain
@_date: 2017-04-30 13:11:44
Technical questions are not resolved by a popularity contest.  
**Did you know that Segwit makes spam over 2 times cheaper than normal transactions?**  
The way segwit works is that bytes used for spending scripts are divided by 4. For simple, N to N non-spammy transactions these scripts contain signatures and there's nothing more to put there - the total discount comes out to about 1.75x. Ie. real total size is divided by 1.75x and that's counted into the 1MB limit.  
No such limit exist for spam, because spending script can be 3600 bytes long (P2WSH), and it's divided by 4 entirely! That's per input. Non discounted overhead required to set that up is 5% *at worst*, making the final discount 3.5x.  
3.5/1.75 = 2.  
**Spam is 2x cheaper than normal Segwit transactions, or equivalently, there's 2x more room for spam than for normal Segwit transactions.**  
It's even worse for non-segwit, current (p2pkh) transactions - spam is 3.5x cheaper!
What do I mean by spam? Storing data purely for storage, like cat pictures. Or dicks. I find the idea of storing a preferentially-discounted dick photo on the blockchain hilarious.  
No sending money for you, have a 2x cheaper-per-byte penis instead. 
@_date: 2017-04-19 17:06:49


Only online nodes are reliable. I could easily manufacture hundreds of fake stats by tethering through a mobile connection, different ip each time. Or even accidentally, by going on a train which would result in frequent reconnections. It's entirely possible you are counting one node of one frequent traveler &gt;1000x.


Each connection set is a statistical sample of the true distribution. If on average over 30 days 1% of connected nodes are client X, but they are 10% of supposed nodes, the most likely explanation is you overcount that type 10x, so divide the supposed count by 10.
You can't get true numbers anyway, I can even see node strings on my node you don't have at all ("/Coinscope-GH:0.2/",  "/bitnodes.bitcoin-russia.ru:0.0.1f/"). The only thing you can try to achieve are true proportions. 
It may turn out you have true proportions already but that seems unlikely
@_date: 2017-04-25 11:34:10


Better. Equivalent security for much smaller impact on old nodes.  
From old nodes' pov any softfork is a DOS attack - they are made to spend resources for something they don't gain from. Segwit is much worse than extblocks in that regard. 


You can't spend a segwit output with a wallet that doesn't understand segwit outputs. 
@_date: 2017-04-18 23:18:31


What?  
From his about: 
"In late 2011, I participated in a high school programming competition where players program the code for a team of simulated robots that then fight each other. I won third place."  
I'm pretty sure he was a programmer since early teen years like most... 
@_date: 2017-04-15 01:34:09
I can't tell if you are using reverse psychology or is your post actually sincere. Still, it's all written in big letters on the bitcoin.com [pool site]( 


"Massive"? That's ridiculous. 1TB was massive sometime about 2005. It's 2017, 1TB *SSDs* are now normal and cheap, I have one for three years now. For the same price you can get a 10TB hdd. 
There are people who would consider all this expensive - most of them are in third world countries and earn less per hour than current median tx fee. Big blocks mean they could use bitcoin, and perhaps start earning more due to that. 
@_date: 2017-04-19 14:59:03
It is, as mining has infinite economies of scale.  
But imo there's some time till the last phase... the most economical use-case of mining is heat cogeneration. 
@_date: 2017-04-30 20:27:29


The orange livebox router reconnects every 24 hours and gets a new ip. It's important to remember that for those planning on playing online, as if it's getting close to 24h, it may be a good idea to reset it before playing. Otherwise they would get violently disconnected. 
Most users never notice that because it almost always happens at night, and with exception of multiplayer is hardly noticeable. 


There it is again. Not 'mobile internet' but 'mobile internet in usa' or perhaps in your state or even smaller. I get a public but different ipv4 address every time on my smartphone. Everything works, including torrent and a http server. 
@_date: 2017-04-18 07:03:36


That's only true assuming the hashing function behaves like a random oracle, which is what this is attempting to test
@_date: 2017-04-02 16:58:43
Ah, Hexrays has the same unofficial piracy policy as Microsoft... semi-recent pirated version are regularly made available and they don't really fight it. Most (if not all) reverse engineers start as 13 year old crackers who could never afford IDA anyway. 
@_date: 2017-04-19 15:20:01
That's only true in a static world. You may be best at making a particular thing and get closer and closer to a monopoly, but it all ends when somebody ends up making something entirely different that makes your thing obsolete. 
Like a writing machine, made obsolete by computers. 
In the case of PoW in general that would require a replacement by something that doesn't rely on PoW. 
@_date: 2017-04-24 17:40:06


[A node gets delisted] ["4 weeks after the last time the stats saw it (so probably 4 weeks minus a few days in practice)."](
As this was pointed and ignored, it's clear deception is intentional. 
@_date: 2017-04-17 23:19:34
I think the real goal of his tweet is that he wanted to boast that he has a MBP with a 1tb ssd.  
That's the only way it makes any sense. 
@_date: 2017-04-18 23:40:35
â€œIt seems to be almost a law of human nature that it is easier for people to agree on a negative programme, on the hatred of an enemy, on the envy of those better off, than on any positive task. The contrast between the "we" and the "they", the common fight against those outside the group, seems to be an essential ingredient in any creed which will solidly knit together a group for common action. It is consequently always employed by those who seek, not merely support of a policy, but the unreserved allegiance of huge masses. From their point of view it has the great advantage of leaving them greater freedom of action than almost any positive programme.â€
*- F. A. Hayek*
@_date: 2017-04-25 12:28:36


Which has equivalent security. 


That's not a segwit output then. 
@_date: 2017-04-14 00:29:06
Read between the lines: they are against, but afraid of r/bitcoin's ire. 
@_date: 2017-04-25 13:27:34
Ideally Core would be open to all improvements. There would be lots of active proposals and they could be voted on in blocks, activating after attaining a reasonable threshold, like 70%. In that world segwit would be activated a long time ago because it wouldn't be an exclusive alternative to other solutions.  
You want choice because you are for core and want segwit, but the whole conflict is because core is against users' choice. A funny contradiction. 
@_date: 2017-09-05 05:38:11
It's flabbergasting how you think that's *not* a good argument. Fully downloading a hd movie while taking a pee is not a problem but 8MB blocks magically are. Uh huh. 
Latency only starts to become a separate  problem from just bandwidth above 1GB as that's tcp's window scaling limit
@_date: 2017-09-02 00:43:42


Everything can be free if you ignore all fees. The channel has to be created and then closed. A direct transaction would be much cheaper. Not like litecoin tx fees are high but still. 
P.S. Same hype from [2015]( Literally the same functionality. Turns out no one actually needs payment channels. 
@_date: 2017-09-05 12:30:27


You know that even with magical l2 solution that would solve everything you still need to upload the intermediate data? So no difference for users. For mining in particular block size has no impact, as all you need is a block header, validation can be done elsewhere. 


Mining over tor is an absurd idea. That's something that sort-of made sense when PoW was imagined as a network of PCs, not when mining involves a big industrial facility.


I heard it's not a problem anymore, but again, miners can just validate blocks elsewhere and only send headers to the mining location. Hong kong has very good internet. 


Every transaction can be validated in parallel. Validation times are never going to be the limit.
@_date: 2017-05-03 07:25:02
You know rootstock requires trusting them with bitcoins? That's literally how it works, you send bitcoins to their multisig address. 
@_date: 2017-05-04 09:33:34
When you wrote your post it was 15:40 in Taiwan, so probably peak daily arbitrage - now most of arbitrageurs' funds are in the withdrawal process.  
I would expect spread to narrow again tomorrow (Taiwanese time).  
Overall, it seems disparities are slowly shrinking - especially percentage-wise. 
@_date: 2017-05-03 15:43:33
People would instead start creating local currencies. In fact they would already if that weren't illegal.  
I hope for money to disappear eventually. It's a low-tech solution to trade that creates many distortions. 
@_date: 2017-05-17 17:45:03
Good point! Without protocol changes, a 2-3x compression is possible, but with a fork adding aggregated signatures, ~10x.
@_date: 2017-05-02 04:55:24


 
\&gt;crime?  
\&gt;must be those untermenschen from the east


stay classy
@_date: 2017-05-16 19:21:05
Network effects + brand. Bitcoin is the best known crypto.  
It's not going to last much longer though. In the bitcoin social bubble it may be easy to forget how tiny cryptocurrencies, as a whole, really are. Bitcoin is not going to be 'digital gold' or anything when other crypto has &gt;100x more actual economic transactions daily. 
@_date: 2017-05-06 22:01:17
This problem is completely artificial. 
Litecoin has nearly empty blocks. Why? Because miners don't actually like spam, as it damages the network. Same would happen with bitcoin. Removing the limit doesn't mean that blocks get to that limit unless there's actual demand. 
@_date: 2017-05-14 20:30:31
Regulatory capture. 
@_date: 2017-05-03 08:12:45
oh god the cringe  
and this is something that pretty much everyone with basic math can figure out, no need to be a cryptographer  
so ecdsa signing has this:  
    nonce = random number
    s = (message+r*privateKey)/nonce
*message*, *s* and *r* are public and known. So it's trivial to get a private key if you also know *nonce*.
(r is generated from k and is a second part of a signature) 
@_date: 2017-05-03 13:00:50
A nonce known to be between 0 and 2^32 is technically 'unknown'. Or using the same random nonce for many signatures. The other guy is not a journalist but a [well-known cryptographer]( which is a very strong prior that he's not arguing over some idiotic point. 
"NC: Well, thatâ€™s the question. I mean, if from one single signature it is possible for the private key to be compromised.  
 
CR: Show me."
That's would be a very weird response from someone who knows what NC means. 
@_date: 2017-05-03 12:42:47
Except he didn't, it's clear the issue is about extracting private key from one signature if a nonce is known (which includes 'is known to be within a practically bruteforceable range' etc)
1. "I mean, you cannot say **a bad random**"  
2. "Itâ€™s a basic fact about ECDSA that if for example you have the **source code of the random number generator**"  - the only reasonable interpretation is that there was some talk before about (Craig's?) nonces being predictable if you know how they were generated  
3. **"Well, thatâ€™s the question. I mean, if from one single signature it is possible for the private key to be compromised."**


@_date: 2017-05-06 22:04:22


Outside of land on Earth other resources are practically infinite. 
@_date: 2017-05-15 17:37:44
Ok? I'm not the one turning them down. 
@_date: 2017-05-14 22:37:31
That's the exact same argument used for taxing &amp; limiting CO2 emissions.  
Somehow, bitcoin ended up with wannabe EU bureaucrat in charge. So absurd. 
@_date: 2017-05-04 09:26:50


Yeah, any proof of that? I'm pretty sure if you actually did a poll on r/btc users the result would be overwhelmingly negative. 
@_date: 2017-05-01 03:57:25


That's a completely flawed argument that only makes sense in a world before computers. In fact the exact same calculation problem is solved by every company, scale of the problem proportional to how diverse a company is. 
 
Socialism doesn't work because it perverts the incentive system, innovation, hard work etc. no longer makes any sense. That's it. There's no calculation problem. 
@_date: 2017-05-01 00:12:03
Threads like these are a good source for 'potential scammer' res (and other) tags.
@_date: 2017-05-05 21:20:32


They are increasing because block space is fixed. The *absolute* value doesn't matter now, it just has to be high enough to push other transactions out - ie. high *relatively* to other transactions. 
Like a bus with 30 seats, 60 people want in. To get in you have to outbid 30 people, even if that means offering 2 cents compared to their offers of &lt;2 cents. 
@_date: 2017-05-16 12:22:28


Genuine new users having problems due to full blocks? Impossible. Clearly Roger's shills are the only possible explanation. 
@_date: 2017-05-15 17:34:06
How is that in any way relevant
@_date: 2017-05-17 17:36:58


Maybe not impossible but slow, fortunately gpus solve that.
Just like with mining, cpu just aren't the good tool for the job.
@_date: 2017-05-07 00:28:07


Transaction demand is clearly not infinite - how many transactions do you actually do each day on average? I would guess it's something like 3. It's harder to estimate business transactions, but SWIFT for example only processes [27.45 million]( transactions (I assume that's what these messages are) a day. 
So no, it's not trillions, more like several billions a day. Which sounds big until you realize a typical HD movie contains 4 billion bytes. Efficiently written, 50 billion daily bitcoin transactions are roughly equivalent to 1120 HD movies a day - that's nothing for a planet-wide system and it's feasible today - in ten years it's going to be trivial. I could expand on the calculation if you're interested. 
The problem is with spam, by which I mean data storage - but there are various ways to mitigate that. Litecoin's solution appears to work well at this point. 


There's nothing bad about off-chain scaling in general, unfortunately Lightning Network in particular has horrible centralizing effects, and it's unclear if it can work ever in the most perfect (unrealistic) configuration. 
@_date: 2017-05-15 17:54:11
Which is a semi-separate point from


Yet miners ARE 'censoring' and litecoin blocks aren't full. Which means the assumption is empirically false. 
@_date: 2017-05-03 09:48:27
Not sure what you're asking... how can bitcoin smart contracts work without a trusted sidechain? Without a very unlikely fork or extremely expensive cryptography, they can't. 
@_date: 2017-05-14 22:51:10
He did, by showing the basic premise as false. 
Look at litecoin - why aren't blocks full? Miners are free to include as many transactions as they want. 
@_date: 2017-05-16 12:11:55
Current difficulty comes from the fact that blocks are full - this drags into the front light the existence of utxo (as opposed to common understanding of accounts), mempool and its expiration, fee calculation mechanism (per byte, not per amount as is common elsewhere), convoluted solutions like children-pays-for-parent.  
In the past, average user - that bought from exchanges and paid for things with bitcoins - didn't even have to think about confirmations too much. 
For businesses, before blocks were full 0-conf transactions worked as instant payment for retail - as if you are going to steal, it's way safer to physically take the item, rather than staying in clear view of the store camera, pay, only to later attempt to double spend that. 
It also worked perfectly as payment for on-going services - it's hardly the end of the world if someone gets (at worst) several minutes of free vpn time or whatever.  
Other services were hypothetically vulnerable but usually found that added value from better customer experience greatly outweighs the cost from malicious double spends.  
All that is gone now.
[mfw]( as a result of telling many people about bitcoin I'm now the first they ask for help with their unconfirmed transactions
@_date: 2017-07-04 16:32:11
It's a bit (unintentionally) misleading - signature aggregation is possible with ecdsa too, it would require a soft/hard fork to add a new opcode, just like schnorr. 
The main true advantage schnorr has over ecdsa is performance. 
Btw did you know that multisig addresses with ecdsa p2pkh (ie. the simplest most common address) is possible right now, which both saves space and is totally invisible to third parties? The difference is that it requires online signing process (ie. all required cooperate to sign). Online doesn't necessarily mean internet, just communication.
@_date: 2017-05-12 04:03:13


**As opposed to the current situation with mining facilities?**  
**Decentralization has nothing to do with non-mining nodes.**
What happens in the following two scenarios:  
1. ~99% of current miners get nationalized and are turned off.  
2. All relaying nodes disappear. 
Answer:  
1. Bitcoin is dead. That's one block every 16-17 hours.  
2. Nothing really - all node-wallets and SPV wallets connect to nodes set directly by miners, instead of miners' nodes mixed with relay nodes. 
Bitcoin network is composed of *miners*. That's how PoW works. You should read the original whitepaper - "The system is secure as long as honest nodes collectively control more CPU power than any
cooperating group of attacker nodes.". Node = miner. 
The bitcoin network today doesn't even use the old bitcoin protocol anymore - [miners use special relay networks]( They, collectively, form the bitcoin network.  
Relay and wallet nodes get their blocks *from* the bitcoin network, but they are NOT part of it - they are *users*. 
@_date: 2017-06-02 14:11:13


"Signatures are 41 KB"
Way too big when a simple extensible lamport scheme is 16kB + 32 byte public keys. 
Still that's 256 times larger than ecc. Even worse, there's no way to aggregate signatures. 
Other post quantum algorithms are also big.  
So unfortunately, with existing technologies, post-quantum cryptocurrency appears to be infeasible. 
STARKs look very promising however. 
@_date: 2017-06-02 14:34:56


\&gt;t. normie, Nov 2013
@_date: 2017-06-02 19:55:47
It's the rough equivalent of sending a raw bitcoin transaction and forgetting a change address, there were tons of these issues in earlier days. 