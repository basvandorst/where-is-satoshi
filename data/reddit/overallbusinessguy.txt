@_author: overallbusinessguy
@_date: 2017-04-29 13:31:10
Nice project.
If you're looking at a site-wide reputation system that is independent to the site and the site only,
Consider adding a progressional system where the reputation itself, represented by an ever-changing number (Could be linked to a certain stars - 1/5 system, based on a bell curve) is tampered with (locally, you) by certain activity points that are relevant to one's reputation.
For example, one metric to use would be if the communication between two entities - seller &lt;-&gt; buyer is consistent [layer1] and if [layer2] communication exists even on negative reviews.
Obviously the weights, w, of these (How meaningful are) differs and I'd say communiction alone has very low weight.
Based on the outcome of layer1+2, generate a small number to add to the end reputation.
1) Do it in phases and and random times. Hold a buffer with the reputation to be added, this way, it cannot be pinpointed to an exact action and -
2) Do not disclose the metrics you use for adition.
3) Have ceilings for how much can be added, infinitely adding reputation, even if the activity is correspondent to it and is legitimate breeds a lot of problems. Set a limit per a finite number of time, after it's done, clear buffer from, say, last week, beign anew, this ensures a refreshment of points and it cannot be exploited if you ever decide to add a time-multiplier (eg: Aha, you've decided to keep spending time, the more you spend, the bigger the points)
4) This can be trained ever further by implementing some outlier-watchers, where people with very high reputation are studied to see what generated most reputation, to create other layers in the future, for things to look for, so it's a robust starting system.
Write it as a simple 2-part program, Gatherer &amp; Interpreter, more modules can be added in the future for ML and study.
Most important thing is testing if a metric is relevant. I know you might have certain ideas about "if we look at this, it's meaningful", personally, I found certain systems which implemented these deep calcultions to work best and be most accurate when there's not a lot of numbers going, find what's relevant to you and the eco-system.