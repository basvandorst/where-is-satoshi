@_author: bashcosucks
@_date: 2015-03-23 12:22:33
What if that's not enough? What if it's too much? There's no precedent for this sort of thing and the absolute last situation you want is to have to change it again. 
@_date: 2015-03-23 16:24:01


I don't agree. 


If there's a hard fork with people on both sides both sides will get confirmations, so your rule really falls down here. The software does not handle this in any way, shape or form, because it's literally failed consensus. Doesn't matter how many confirmations you want for, it's still failed, and you just got double spent against and lost all of your money. The only monitoring Bitcoin Core does of this sort of things is designed to find valid chains with higher proof of work and warn you about it, but from experience it looks like absolutely nobody notices a little yellow bar at the top of their client. 


No, you just choose to parse it that way :)
@_date: 2015-03-23 11:19:03


Without any incoming connections, you are still making the default 8 outgoing connections to other people that are listening with a world-visible open socket.


You do not need to open port 8333 to be a fully validating node, you need to have it open to be a *listening* and fully validating node. Fully validating is talking about your level of personal security not if you are listening or not. It means that you have absolute confidence in the transaction information in your wallet, and that there's near zero chance anybody has tampered with it (this is not true of SPV or Lite clients). 
There's no security advantage to having a listening socket, it's purely altruistic and assists other people who wish to join the network. They are a limited resource, so it's good to be able to supply them if your connection supports it (not all do). Running any node burns 8 of the networks sockets, running a *listening* node burns 8 sockets but supplies 125 more to other people. 
@_date: 2015-03-23 14:26:59
You're not going to have partial UTXO storage nodes though. That would mean to validate a block you would need to make many outgoing requests to your peers who might or might not have what you are looking for. You eventually get down to the last one and never finding. 
@_date: 2015-03-23 17:58:27


Well the bitcoin whitepaper makes this assumption. We know ghash.io is certainly malicious, they stole millions of dollars with finney attacks, you don't think they're more than prepared to do it again? 
@_date: 2015-03-23 10:50:46


It's really not as close as people would like to have you believe. Some ridiculously large portion of all transactions is spam. If there really is a squeeze, spam paying low fees is the first to get the knife. A good portion of all miners use the default block generation settings, which happens to be 750KB. If anything the most realistic action to be taking is campaigning them to alter it, or just not mining on their pool if they are one. 
If the hammer comes down and the community decides that for some reason a hard fork to change the block limits and a breaking change to the network protocol is necessary, it's not like it's going to happen in a month, or even in 6 months. There's almost zero developer support for Gavin's proposed 20MB block size limit, so you've got a lot of convincing to do if you think that's going to happen. 
@_date: 2015-03-23 23:14:41
Good ideas have never been blockchain.infos strength. 
@_date: 2015-03-23 12:43:14
That's not strictly true, what about the ever growing UTXO size? There's no solution proposed for that, I'm not even sure most people know what the UTXO database is to begin with. 603MB and growing fast. Can't be pruned, can't be compressed, can't be forgotten. 
@_date: 2015-03-23 17:45:28
Oh no! 
Wait until more people find out they can just paste the xpub into blockchain.info, it'll be a field day! 
@_date: 2015-03-23 17:08:21
Yeah, by then you've already been double spent against and your money is gone. You'll probably get consensus eventually, but eventually is too late for someone preaching 6 confirmations as their god. 
@_date: 2015-03-23 16:03:19


You need to brush up on your basic understanding of how Bitcoin clients work. There's completely room for double spending cross fork here (it even happened during BIP50 against OKcoin), it's just a simple matter of spending an output on both sides of the fork and cashing out in USD for each. No client has ever attempted to monitor multiple chains for anything other than their existence and height, so I've no clue where you got that idea from. Any service which is caught on the "other" side of a hard fork will either have to switch, shut down entirely, or be robbed of all their money almost instantly. 


Was it? The word isn't in the whitepaper and I don't remember it ever being claimed by Satoshi to be able to replace all currency or anything like that. 


Not really, just saying that Gavin isn't part of the group that thinks that way. 
@_date: 2015-03-23 15:33:53


That's a soft fork water mark, not a hard fork one. For a hard forking change anybody who hasn't changed over will be broken away from the network and stolen from, so you'd better have more than 70% of services involved or enjoy the mass thefts and cross fork double spending. 


No, but there's a benefit in listening to those who are obviously more in touch with the technical side than we are. You're free to make stupid decisions all day long at your own detriment, of course. 


Lots of this is driven by people screaming that Bitcoin will go to moon if we just have more room for transactions. There's simpler ways of including more transactions, not in the least like getting companies to actually use compressed public keys like they should have been doing from the beginning. 
The only reason this particular variable in the source has a particular following and public interest is that it's remarkably easy to shed paint with, it's a simple concept that people can quickly form an opinion on without actually having to understand a great deal.


That's also the opinion of most of the people with a clue, Gavin not included.


There was a limit set by the network message size, it was just larger than 1MB. 
@_date: 2015-03-23 10:56:19
There's also some game theory stuff going on, depending how deeply you want to look at it. Even without fees miners are acting in their best interests to include transactions because it supports the price, which is what after all pays their power and hardware bills off. Part of being a miner is not acting in ways which destabilizes confidence in Bitcoin because that literally costs you money. 
Literally nothing prevents that though, miners are free to include as much or as little as they want.
@_date: 2015-03-23 13:12:44
When someone sends you a transaction, you need to verify that the outputs they are sending to you actually exist in the first place, and what their size is. Otherwise a miner could make a block that spends to a new 1000 BTC transaction and you would never know that it's not legitimate. 
@_date: 2015-03-23 10:34:40
There's an incentive for them to include transactions in blocks due to them getting transaction fees from it. If they don't include transactions, they get a lower income per block (it's about 0.5% of the total reward at the moment). All nodes in the network *verify* transactions, not just miners. Miners just happen to have the ability to pack the valid ones into blocks. 
@_date: 2015-03-23 11:42:33
@_date: 2015-03-23 13:02:34
All validating clients keep a database of unspent transaction outputs. Every output ever created that has not been spent is stored in a database and waits to be spent, if it's not provably undependable (ie, OP_RETURN) remains there forever waiting for someone to spend it. As part of the consensus system, when a new block comes in all the outputs it spends are removed from the Unspent TranXaction Outputs database, and new ones it creates are added. There's currently 17906689 unspent outputs in the database, totaling 631.6MB. 
Lots of people like blockchain.info and Counterparty made moronic systems which sent dust to addresses with which there is no private key, we can't prove to the system that they can't be spent, so however many tens of thousands of full nodes exist all must store them all, on disk, forever. A massive congratulations to them for misusing the system and vastly inflating the load on the network for their own benefit.  
Contrary to a particularly poorly written book on the subject by Andreas Antonopoulos, the UTXO database is not, and has never been stored in RAM. 
@_date: 2015-03-23 14:55:01


If you make a hard forking change in the Bitcoin network with whatever scraps of services are foolish enough to make that change, then get forked off the network and lose money. You need unanimous support from the nodes in the network, and all the services running nodes, if you have anything less the network will fragment and Bitcoin dies. 


Not in this conversation. If there's not unanimous agreement between the core people maintaining the client that's a pretty good indicator that you should step back and wonder why, rather than rabidly running at the problem because you think it will drop Bitcoin going to the moon. Out of any of us, the core developers absolutely know what's going on more than most, if they say it's not a good move to rush into making a block size change, then I'm inclined to trust their judgement.


Then the change isn't being made, end of story.


It's not working. The arguments for such a massive change and risk to the network are disproportionally weak. It strays dangerously into dunning kruger territory, if this change sounds like a good idea to you then it's probably because you're simply unaware of how dangerous it really is. 
@_date: 2015-03-23 17:41:10
No, you're showing yours. Your statistical assumption only makes sense if you assume absolutely zero malicious miners, and that all nodes are miners, neither of which is not the case. If I was a malicious miner and I knew you hadn't changed to the modified software it would be within my interests to mine on your side fork and get away with your cash after 6 useless confirmations. 
Miners have zero control over how a hard fork goes down anyway, they are literally at the hands of the nodes. Having 80% of them on board doesn't really mean much at all if nodes reject their blocks outright. 
@_date: 2015-03-23 13:39:39
SPV nodes don't store the UTXO at all, so that's not really a problem. 
@_date: 2015-03-23 13:11:41
In that comment I'm talking mostly about outputs which probably can't be spent, but still need to exist because we can't prove otherwise. 