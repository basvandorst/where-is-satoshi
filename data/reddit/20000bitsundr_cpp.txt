@_author: 20000bitsundr_cpp
@_date: 2016-01-18 18:06:55
Yes, I've read this... segwit, lightening, are priorities, and some day whenever the core dev's decide they feel like it, blocksize might get addressed.  I don't care who signs it, names mean little in this.  These guys are constantly stalling because they say "there are fundamental trade-offs between scale and decentralization" while never proving this, and then saying stuff like "trust us we are experts."  It is a joke.  Also, the same group is being thrust to the front of all conversation by agressive "moderation" policies while alternative proposals which actually fix the problem right now are cast aside.  And again they say, "don't listen to those guys, they don't know as much as we do," while never providing proof that their premise which they base their entire decision making process is correct.  Again, its a joke. 
@_date: 2016-01-30 02:51:27
Gaven was testing big blocks in 2014, and although the results were promising at the time, they required a great deal more testing.
This should have been built upon instead of being stonewalled by a group of core devs without alternatives that could be implemented in time for the upcoming halving and the coresponding boosts in transaction volume that are expected.  
@_date: 2016-01-18 18:10:29
Lol man.  Core good, classic bad, I get you.  Classic full of web programmers who can't handle CPP.  Very substantial.
@_date: 2016-01-18 14:03:15
The context of this fork is and always was of technical nature.  Politics entered the picture when core ignored a quickly approaching technical problem.  Even the "roadmap" they presented was only presented at hour 11, and only because because other people who noticed the problem earlier made enough noise to get core to even pay attention.  
Describing this as a political hard fork is ignoring the very real problem bitcoin is facing relating to scaling, which is at the heart of this matter, and ignoring the limited and inadequate response core was giving before the latest part of the debate began and continues to give now.  Remember that if core had presented a reasonable vision of scaling 2 years ago when they actually should have, we never would be in this position.  
@_date: 2016-01-18 13:39:10
"The Core Team" was built because bitcoin is revolutionary.  If classic gains traction, some of them will come work with classic.  This isn't a all or nothing situation.
@_date: 2016-01-18 18:37:53
Even nullic said that there are already fixes available for this problem.  It wouldn't be a single parameter, but it would be just a few changes.
@_date: 2016-01-18 13:31:03
Why would you think those wouldn't be in classic?  Also how is having  more than one implementation bad for anyone?
@_date: 2016-01-30 01:03:22
You seem to have no concern that fees are going to be significant far before a real user base has developed, and far before it is necessary to finance the security apparatus.  In fact, since core has been aware of this wall approaching for years, it is fairly obvious that they actually intend to drive a fee market.
When the halving occurs, if block size isn't 2mb, and segwit isn't already deployed, which isn't realistic, then your actions will directly be responsible for massively reducing user growth.  75% full blocks are fine until transaction volume grows by a factor of 10 as it inevitably will leading up to and after the halving.  The consequences of this are going to mess up the value of my bitcoin for years, and yours too if you have any.  
The technical solution exists.  Let it happen, and let the free market decide what is spam and what defines adequate fees.
@_date: 2016-01-11 17:48:48
Bob's burgers... really?  That show is not good.  Ranks right up there with the Cleveland Show but more boring.
@_date: 2016-01-30 01:12:37
The first significant actions from core on scaling have been very recently, most notably the roadmap, and while the core plan is fine, it is something that should have been introduced years ago when several notable people began to raise the issue.  At the point we are now, we are running into potential massive growth and publicity due to the upcoming halving, and we aren't even close to ready for this volume.  This will have a direct impact on price and user base growing which in my opinion is far more significant for decentralization than the risks from growing block sizes.
@_date: 2016-01-18 14:32:20
My point remains.  Those conferences were never scheduled before the actions of other people who noticed the problem years ago, and they were scheduled only at the last minute because those other people were making a big stink.  This is a failure of organization to deal with a technical issue that should have been addressed years ago.  Saying "these things take time" is disingenuous considering the large amount of time that prominent developers have calling attention to the issue, and the development of the political aspects surrounding this issue are primarily due to this mismanagement. 
@_date: 2016-01-18 13:36:02
This is nonsense.  
@_date: 2016-01-30 00:51:17
This is ridiculous.  You are acting like the block size debate is some conspiracy that was invented by people who work for governments and banks.  There are real technical reasons why this network should have already expanded, and the failure to already have done so is something that has lasting consequences on my money.  
The reality is that the block debate is being driven by individuals like myself who believe that what we have seen is a failure.  We are sitting here watching this train approaching an artificially erected wall that could be removed with a push of a button, and that is why we have been speaking up for years now.  Notice I said years...  The failure is that the core teams are just now realizing this is an issue. 
@_date: 2016-01-18 14:17:02
Why would soft limits not take care of this problem as they always have?
@_date: 2016-01-18 18:13:26
Sorry, but the article here basically says we are making increasing block size a priority but are actively testing it and awaiting results which will take time.  Core has not done this.  They have refused all efforts and data relating to large blocks, and aside from Gaven, have produced no data from large block tests of their own.  They are not actively testing, and that is why this article is way off from what the roadmap is.
@_date: 2016-01-18 18:19:04
Gaven was calling for changes years ago, and there were other developers who were calling attention to the issue as early as 2011.  The fact that the core team just started to address the issue in the last few months is a massive failure on their part.  Bitcoin is absolutely getting close to capacity.  This is not a debate, blocks are 70% full most of the time now.  Any spike in traffic would cripple the network and make fee manipulation the only way to get reliable transactions. 
@_date: 2016-01-18 14:14:07
No, this is not what core is planning at all.  It is what core should have decided.
@_date: 2016-01-18 14:15:17
Core has give no indication that they are willing to jump block size... ever.
@_date: 2016-01-30 02:12:28
Gaven had been testing big blocks in 2014.  He released results from his preliminary tests in January of 2015.  
Others had been bringing the issue up as far back as 2012, at least that I know of.  If segwit testing has been going on since 2013, then why is it not being implemented as it should be... in a hard fork?  Why is it still not seen as being correct enough to be implemented yet?... and if the answer is that it is extremely complicated, then why is it just now being given precedence?
Nothing excuses or explains why this roadmap is just now becoming focus other than a failure of foresight.  The halving approaching and its associated volume bumps aren't exactly blindsiding us, and this is going to cost everyone money as well as paint a picture to the world that we can't even get organized and prepared for the growth levels that virtually everyone expects.  
@_date: 2016-05-21 22:17:20
More users mean more businesses that accept BTC, which means more people that want control over their own security.  Naturally a larger user base would create more nodes.  What you should be asking is whether a larger user base would mean nodes would increase at a proportional rate with that user base or go up or down relatively.