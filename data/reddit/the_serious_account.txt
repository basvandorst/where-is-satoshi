@_author: the_serious_account
@_date: 2016-08-19 15:08:53
I do (or rather did) theoretical quantum cryptography.  unconditional security has an explicit technical definition that QKD falls under. 
Obviously you can still disrupt communication. Not sure what you mean about error correction. If you do add redundancy to your QKD protocol you'd obviously have to adjust for that. I'm not sure that'd make sense, though. Haven't done the math.
@_date: 2016-08-19 14:17:59
If you explained the protocol in its entirety, you'd obviously be explaining what it does as well. Mentioning only that you can discover people listening in makes it sound like it doesn't provide secure communication, but only provides the ability to discover that someone has broken the security.  A very typical misunderstanding
@_date: 2016-08-19 13:45:32
PhD in quantum cryptography here. Not sure what you're saying. 
Quantum key distribution allows two parties to communicate under unconditional security.  You seem to be confusing how it works with what it does. 
@_date: 2016-08-19 14:49:01
Right.  But you called it the correct explanation. 
@_date: 2016-08-19 14:40:27
You also called it "the communication". When people talk about communicating, they don't usually mean sharing random bits.
@_date: 2018-09-24 08:25:14
Saying there's "no reason" is a little harsh. There are some indications quantum computers could be useful in machine learning. [The HHL algorithm is an example.](
@_date: 2014-01-12 19:57:53
Correct. But it's still not NP hard. 
@_date: 2018-05-02 10:11:14
A global conspiracy is much more likely than you not just understanding an area of physics. 
@_date: 2014-10-16 12:45:03
It mentions elliptic curve which is the ec in ecdsa.
 


@_date: 2014-11-03 11:04:49


Give a source, your reasoning. Heck, anything. You make a radical statement about the field of quantum computing and completely refuse to back it up with anything. You can't cling to that strawman claim when I'm directly quoting you.
You're just finding excuses for not answering, because you don't have an answer. I'm curious what your next excuse will be.
Edit: Pretending to be too offended to answer seems like a typical tactic at this point.
@_date: 2014-05-08 09:17:46
Quantum computers will be so slow that Grover's algorithm is unlikely to be useful for a very long time
@_date: 2014-09-26 11:52:43
It doesn't make much sense to say that SHA256 is  NP complete. It doesn't make sense to say you can take any NP problem of any size and encode it as a SHA256 preimage attack. It's obviously not true. 
Secondly, quantum computers can (most likely) not solve NP complete problems in polynomial time. Certainly not "by definition". You can't just "pick a superposition". You're given one at random. 
@_date: 2014-03-11 18:09:47
Are you claiming there's widespread implementation of qkd among banks? I'd be getting as lot better salary if that was true. Implementing something like lattice based cryptography is just a software change and more likely. Qkd across the world requires technology we simply don't have yet. 
@_date: 2014-10-14 16:22:36
You're  misunderstanding the question. OP is asking about quantum cryptography, not quantum computing. 
@_date: 2014-09-26 11:33:18
I was more responding to the specific statement of sha256 being unaffected by quantum computing. For bit coin mining in particularly, it's my understanding the space of accepted preimages is rather large. Grover search can be extended to such cases and the complexity is sqrt(N/k) where k is the number of allowed preimages. 
@_date: 2014-01-12 19:16:52
Elliptic curve cryptography is not based on a NP-complete problem. But you're correct that their computer can't break ECC. 
@_date: 2014-03-11 18:06:15
I've been in the field for 10 years, we're not going to invent a large scale quantum computer from one day to the next. Yes, there's an issue with the private key of bitcoin, but the implementation actually allows bitcoin to switch to post quantum public key schemes. 
@_date: 2014-03-24 13:59:43
Sha is not about encryption. If you're using aha to encrypt, you're doing it wrong, because there's no way to decrypt it. It's a one way function, not a trapdoor function 
@_date: 2014-01-12 19:41:15
Like RSA, it's vulnerable to a large general purpose quantum computer. 
@_date: 2014-03-11 17:47:44




You're completely honest. Not to mention quantum computers are not as big of a threat as people think.
@_date: 2014-11-03 12:32:05
 &gt; The current understanding is that yes, ECDSA is deeply weakened with a QC, however nobody has successfully made anything but wild claims and that doesn't look like changing any time soon. 
So you agree that a QC would "deeply weaken" ECC. 
And you also claim that it is very unlikely that a QC will ever be able to do " anything interesting with EC"?
I think if you put those together you get the claim that large scale QCs are very unlikely to ever be built. This is certainly the goal of the field. So why is it a strawman to assume you are claiming the field wont reach its goal? It's exactly what you're claiming.


The reason you don't see that is because QC are decades away. Not that, as you claim, they are very unlikely to ever be able to break ECC or RSA.


Wildly misusing fallacies is way too common on reddit. What I said had absolutely nothing to do with our argument. On top of that, it was obviously a prediction. In no way did is misrepresent your view on the topic.
@_date: 2014-09-26 10:54:28


That's not completely true. A preimage attack on a quantum computer would only take ~2^128 operations compared to ~2^256 on a classical computer. 
@_date: 2014-01-04 15:11:47
This is tte simple and correct answer. Also, the field of quantum cryptography is really small. Can I ask why you left?
@_date: 2014-06-16 06:36:19
1) d wave is a scam
2) even if it wasn't a scam, it couldn't be used to break the security of bitcoin
@_date: 2014-11-03 09:10:45


I can assure you this is news. 
 &gt; There's a lot of skepticism about what people have claimed to manage with quantum computing to begin with,  the usually quoted example is dwave which is quite disputed to say the least. 
Everyone i know agrees d wave is a scam, but it's not really something they can control. Using that as an argument for why the field is doomed to fail is absurd
@_date: 2014-11-17 19:06:49
Quantum mechanics is required for a significant part of the word's economy. Including that computer you're using. I wish people who dismiss science were prevented from benefiting from its accomplishments. 
@_date: 2014-11-03 08:58:16


Source? I know several people who work in this field and I'm sure they would like to know their work is pointless.
@_date: 2014-11-17 20:55:55
@_date: 2014-01-12 19:19:52


I must have missed that as part of the scientific method. 
@_date: 2014-10-14 16:27:01
I don't see how quantum cryptography would become part of bit coin. It's possible quantum crypto will allow us to come up with an even better construction than bitcoin. There's some interesting work by Scott Aaronson on what he calls "Quantum Money". An obvious limitation of normal money is that it can be copied. A limitation of bit coin if that it cannot be used offline. Quantum money is an approach to money where it's both impossible to copy and also possible to use offline. The technology required is still far away, but it's extremely interesting if you're into theoretical cryptography. 
@_date: 2014-11-17 19:20:08
The article actually has a slightly different take on the issue than many before. Among people who understand quantum cryptography, it should be clear that you can implement better forms of crypto currency than bit coin. Whether that means bit coin will lose out to such implementations is a very different question. 
Bit coin would certainly take a huge hit if someone magically came along with a large scale quantum computer tomorrow. How it will handle it if it's a more slow development is a different question . Mining without a quantum computer could certainly become pointless. It depends on the memory size and speed of such machines. 
@_date: 2017-02-25 11:42:12
Except it wasn't actually faster. [We should note that there are algorithms, such as techniques based on cluster finding, that can exploit the sparse qubit connectivity in the current generation of D-Wave processors and **still solve our proof-of-principle problems faster than the current quantum hardware.** ](
D-wave beating classical computers has been "just around the corner" for years now. 
@_date: 2014-11-03 10:50:39
You said it would be unable to do anything with ECC which implies it doesnt work. 
@_date: 2014-02-02 12:22:29
How are they getting 2^80. That's an odd number
@_date: 2016-06-14 06:56:38
No, you don't need a quantum device for that.
@_date: 2017-01-20 07:33:16
They're based on different mathematical problems that no one has found a way to solve quickly using a quantum computer.  
@_date: 2017-01-18 17:34:09
Grover's algorithm, not Shor
@_date: 2019-08-08 08:44:08
Sure, but your statement was still wrong.
@_date: 2019-08-07 23:18:28
That's just not correct. The energy spend is under computational assumptions. **Assumptions**. Computational complexity is a lot of "we don't know". Is P=NP? Probably not, but we don't know. Are one-way functions possible? Probably, but we don't know. These are extremely important questions, but the answers are unknown. 
If P=NP how are you going to fix it? Yes, it's unlikely, but certainly not impossible.
@_date: 2018-11-29 12:43:56
Both classical and quantum cryptography have schemes that don't rely on computational assumptions. They would remain secure regardless of the relationships between complexity classes. 
@_date: 2016-09-25 08:56:32
We already have post quantum crytography as a counter measure. It's even been implemented in chrome as an experimental feature. 
@_date: 2016-09-25 09:08:40
No. Not within any reasonable time frame. 2^64 rounds is still a lot of computing. The first quantum computers will not be able to do computations at anywhere the speed of classical computers. That's something too few people realize. Compared to classical computers, quantum computers will be big and clunky. Think 1940s or worse. People aren't even concerned with speed at this point.  But they will be quantum, which is their advantage. 
Not to mention you can't really run the algorithm (Grover's algorithm) in parallel in the same way you can classical search, so simply buying more quantum computers isn't going to help in the same way it does classically. 
@_date: 2015-04-30 09:52:42


I just gave you a quote saying the lower limit of kT does not apply for reversible computing. In response you just insisted you're correct with no sources whatsoever. I don't know what to say. Do you want more sources that contradicts your claim?


lacks a single-valued inverse. Here it is shown that such machines may he made logically reversible at every step, while retainillg their
simplicity and their ability to do general computations. This result is of great physical interest because it makes plausible the existence
of thermodynamically reversible computers which could perform useful computations at useful speed while dissipating considerably
less than kT of energy per logical step


computing comes, however, often from the fact that these models are
information preserving. Landauer’s principle links information theory
and thermodynamics; all information has some physical representation,
so a loss of information must cause a thermodynamical entropy decrease,
which then leads to heat dissipation to obey the law thermodynamics. A
reversible computation does, thus, not have to use energy,




@_date: 2015-04-30 10:41:40


The amount of accessible information in N qubits is N bits. Not 2^N . The amount of accessible information in a single qubit is one single bit. Very basic result in quantum information theory. Also, you should probably have read your sources before attempting to calculate it yourself. 






That's the correct calculation. Let's say we have a quantum computer with a million qubits. The maximum von neuman entropy of this is of course one million. 
So following Schneier’s calculation, but for 10^6 instead of 2^256 we get that the minimum energy required to erase a million qubits is, 


Which is 4.4 × 10^-17 joules. 
@_date: 2015-04-29 13:31:41
No. The argument comes from [Landauer's principle]( It does not apply to reversible computing, which quantum computing is a form of,


 
@_date: 2015-04-30 17:55:26
I agree that's problematic. Especially in a culture were we expect extremely rapid development. 
Quantum computing is not from the 70s though. 
@_date: 2015-04-29 08:18:48
That article is not correct. It references Bruce Schneier’s calculations on the energy requirements to brute force a 256 bit keys. However, this argument does not apply to quantum computers.
@_date: 2015-04-30 17:30:27
Progress in something like this takes a lot of steps. If you're not interested in the scientific progress, but only the finalized technology, you should ignore articles like this until it's actually done. 
@_date: 2015-04-29 14:26:59


Measurement is only applied as the very last thing. Up until that point everything is reversible, which is what matters. The measurement will require some energy, but it's miniscule. 


Having the right conclusion (that it's practically impossible to brute force) does not validate your argument. 
@_date: 2015-04-30 15:45:50
You too :). It's not like this is an easy subject. It's possible there are other physical limitations. For example, can we really change the state of a bunch of qubits more than once per planck time? It's outside our current understanding of physics, but I wouldn't be at all surprised you could show some kind of physical limitation. 
@_date: 2015-04-30 19:19:37
Not actually sure when the experimental work started taking off. The huge theoretical breakthrough was error correction. Up until then, it looked like an impossibility because the computation would require the qubits to be completely shielded from the outside world. Error correction allowed us to say that it just have to be 'good enough. 
@_date: 2017-10-12 15:49:08
They use public key cryptography for communication. Most of those currently in use (eg. RSA) will be broken by large scale quantum computers. Hash function (eg. MD5) and symmetric encryption (eg. AES) will take a bit of a blow, but nothing as seriously. 
@_date: 2015-10-06 19:39:15
To be fair, I can tell 90% of those answers are worthless and I don't even know how Bitcoin works 
@_date: 2015-10-26 09:29:32


That's not correct. 
@_date: 2015-10-26 09:28:19
I mean, it reduces the security by a factor of about a billion billion billion billion or so. 
@_date: 2016-05-11 09:02:54
No, there isn't 128+ qubit computers. There's a company making those claims, yes. But you can find companies making all sorts of claims in order to cheat investors. That's luckily not how science works
@_date: 2015-02-23 16:24:04
The argument about a minimum amount of energy comes from a minimum amount of energy required to delete a bit of information. If the calculation is irreversible, it implies information is lost and hence heat is required. 
Quantum computing is reversible. That is, from the output, you can always compute the input. No information is therefor lost/deleted so the argument no longer applies. 


@_date: 2015-02-23 15:32:19


That's only true of irreversible computing. Quantum computing is reversible so the calculation that follows does not apply. Not to mention Grover search. Not to say it can be broken on a quantum computer, just that the argument doesn't apply to it. 
@_date: 2013-09-09 18:15:26


Yes you can.
[If Alice and Bob have an initial shared secret then they can use an **unconditionally secure authentication** scheme (such as Carter-Wegman,[20]) along with quantum key distribution to **exponentially expand this key**, using a small amount of the new key to authenticate the next session.](
Emphasis mine. 
@_date: 2013-09-10 07:42:28
Good. It sounds like you've almost got it now. At least you're moving the goalposts of your argument, which must  mean you've realized your previous objections are not valid. Ie, calling QKD 'redundant' as if there was any other way to accomplish what you can with QKD. 
Your argument has been reduced to a few seconds of a seconds computational overhead. Of course to even use the word 'overhead' you need to compare it to another scheme, which you don't. Other schemes need authentication as well. To just calculate it for one scheme and not the other is misleading.  But whatever, it's okay. If a few seconds is the price for unbreakable encryption, I can live with that. 


That would forever only be secure under a computational assumption. 
@_date: 2013-09-09 21:24:13
Sorry, but your post is really hard to read. You're using confusing terminology without explaining it. 
I assume 'tag' means MAC? 
What does 'length of hash' mean? The length of the input, the output or something else?
How does a 'message give you one time pads'?
And what does it mean to have multiple one time pads? Have you defined the size of a single one time pad somewhere?
What rounds are you talking about? Rounds of running QKD? And what does this equation talk about?




Please don't confuse one time pad and authentication. That's two different things. 
It sounds like you think you need to authenticate every message you send using the one time pad. That's not correct. 
@_date: 2013-10-24 10:57:05
No, it claims to do quantum annealing, which is very different. 
[Note that D-Wave itself now speaks about “quantum annealing” rather than “quantum adiabatic optimization.”](
Making even stronger claims than d wave does makes you look like an idiot, I'd recommend stopping it.
@_date: 2013-09-08 21:30:06


Verification of what? Authentication? That's required for any scheme.


The point is why don't know if RSA is secure.


You're suggesting to use public keys to share public keys? Talk about solving the wrong problem. Again, we don't know if public key crypto systems are  secure. 
@_date: 2013-10-24 21:18:46
It's a subset *and* very different. That can't be so hard to comprehend, can it? P is a subset of NP, yet P and NP can be different. Dude, get with the program. 
@_date: 2013-11-19 16:42:24
If you're referring to d-wave, then they've made claims but provided no evidence. That's not how science is done. 
@_date: 2013-09-11 00:28:58


You can never *prove* in the strictest sense that an implementation follows the model correctly. That's asking for the impossible. You can't mathematically prove that Eve won't take Bobs children hostage and force the key out of him. It's a silly requirement. 
@_date: 2013-09-10 18:27:20






Even without a polynomial time algorithm to invert sha256 it doesn't require 2^620 operations to break. With a polynomial time algorithm? who knows? Certainly much much less than 2^620. Grover's algorithm is irrelevant if we have a polynomial time algorithm to break the cipher. The fact that you mention it shows you don't know what you're talking about.
You're making absolutely no sense.


As you very clearly pointed out earlier, you don't understand exponential functions. They grow extremely quick.
@_date: 2013-09-09 19:28:32


All you need is *one* around of QKD. That round gives you many, many new keys to run other rounds. 
@_date: 2013-11-27 11:22:32
There's a wikipedia page on post quantum cryptography.  Have a look. We have no reason to think quantum computers could break sha256 in reasonable time
@_date: 2013-09-09 19:24:26
I thought you had been trolling me there. Alright, I wait. 
@_date: 2013-09-09 22:50:18


Right. So this is essentially a tree. The total length of the key you need is the height of the tree times the size of the family the hash functions are chosen from. Let's say that is 1024 bits * height. 
The height is the logarithm of the size of the secret key we want to generate plus some overhead in the actual QKD protocol. I don't recall the exact number, but let's say the overhead is a factor of 4. It's around that
Let's say we want to communicate 1 TB = 8x10^12 \approx 2^42.  The height of the tree is then log_2(4*2^42 ) = 44. 
So for a pre shared key of size 1024*44 \approx 6 kB you can perfectly secure communicate 1 TB data using one time pad. 
Of course, if instead you use that 1 TB of shared key to run a new round of QKD, the number of bits you can communicate is astronomical. 
@_date: 2013-11-28 00:05:04
What do you mean by mainstream? You can already buy quantum key distribution systems that use qubits. Within physics they're very much mainstream. 
Also, qubits are not smaller amounts of data than bits. If anything, it contains more information. 
@_date: 2013-09-09 19:01:38


Having the message grow exponentially with the initial key is exactly the same statement as the key grows logarithmically  with the message. So thank you for supporting my point. :)


I never talked about reusing a key. No idea where you're getting that from. QKD generates a new fresh unused key.
Edit: 


Where are you getting square from? Give me any link that relates the size of the message to the square of the key. 
@_date: 2013-09-10 23:09:26


Not really. You have to be careful when you map high level.theoretical results in cryptography to real world use. Researchers are very well aware of that.
If you could make a hash function and *prove* the work required to invert it was polynomial but extremely high for practical values, I'd be very excited. Any protocol where you have *provable* resource advantage is very interesting.
 


Literally the article you're commenting on says a billion photons a second.


I think the tolerable error rate is around 10%, but yeah dos is possible. I don't see why you would want to transmit that large a key in one go I'd you were having network problems.
@_date: 2013-12-06 17:04:04
I'd say it's more likely we'll find a flaw in the SHA256 algorithm, than we'll break it on a quantum computer. Doing SHA256 on a QC still requires an unreasonable number of calculations. 
@_date: 2013-09-09 00:12:03


No, I'm assuming there's no proof of one(which there isn't). All I'm saying is that there's no proof.


Yes,  but there's still no proof that you actually need that many. 


Maybe,  but there's no proof.


For all outputs??? Why on earth would you want to find inputs for all 2^1000 ? You couldn't store that information in the visible universe. I have no idea what you're trying to accomplish.  Anyway, if P=NP, secure hashing is broken. End of story. Also, I don't know why you're talking about hash functions. 


In any cryptographic sense, public key cryptography, and hash functions, are completely broken if P=NP.


No. You start out with a small secret you use for authentication. Then you run the QKD protocol  which generates a secret key of essentially any length. You use that key for one time pad. For the third time, I have agreed you need a key for authentication. Can we lay that part to rest? Yes, you need to share a key for authentication. From that small key of maybe 256 bits, you can create a key for one time pad of essentially any length.
@_date: 2013-09-11 00:27:32
You might be right. Anyway, it's a technology in development. I find the current state of affaires completely irrelevant. It's the potential that matters.  
@_date: 2013-09-10 21:10:41


This is confusing to me.The standard definition of security in the science of cryptography for such schemes is that the probability that any polynomial time algorithm can break your scheme is negligible (in input length). If P=NP then there are no such secure schemes *by definition*. You need to redefine to concept of security in cryptography for that statement to make sense to me.
I, and most people in the field, consider it very unlikely you could have functions where one direction was quick on the scale of Wegman-Carter, yet the inverse was practically impossible (in the case of P=NP). Essentially all polynomial time algorithms we know run with fairly small exponents. You're welcome to think otherwise. Can't argue with an opinion except to say I haven't heard it before.


You're forgetting (or unaware of the meaning of) unconditionally secure authentication. Unconditionally secure means there is no algorithm which can break the scheme. Even given infinite resources. It's actually explained in the link you gave earlier: 


So the only 'attack' you can accomplish is an online attack. After the first 2^32 failed attempts Bob will probably start to wonder what's going on.
@_date: 2013-10-20 17:12:42
How would you go about changing the encryption for bitcoin?
@_date: 2013-09-09 22:36:45


I don't want to reuse keys. Nobody is talking about reusing keys, but you. There's no link, no reference. *Nothing* that talks about reusing keys, so please stop. I already pointed this out once in a previous post. Stop talking about reusing keys. Alright?
I want to use the shared secret key I just generated using QKD. Not reuse some old key. Stop it. Seriously.
Please :).
@_date: 2013-09-08 22:50:31


No, that's incorrect. Measurements are chosen at random during the protocol and certainly not agreed upon prior. Not sure where you're getting that idea, but that's [not how it works](


We also don't know if AES is secure. QKD can use one time pad, which is proven to be secure. 


If you could prove that you'd win a million dollars.
@_date: 2013-09-08 22:17:36


We still don't know if *any* the schemes are secure.


No, you don't have to agree on any settings. You need to share a small key for authentication. After that you can essentially do as much secure communication as you need. You have the same problem with public key. How do you know you've gotten the right public key for a person?
@_date: 2013-09-10 19:15:41


No. The context was a cipher that was efficient and secure under P=NP.  


What you still fail to understand is that, if P=NP, to have an exponential increase for an attacker (eg. 2^100 to 2^620) you also need an exponential increase in input length. So it's great that it takes 2^620 operations to invert it, but input will be larger than the number of atoms in the visible universe. You really fail to see the implications of P=NP. 


We already talked about that once. It also requires exponential bandwidth! Why? Because that's how much data you can send. It's a good thing. But it at least sounds like you concede that you don't need as many rounds as you first implied?
@_date: 2013-12-23 23:30:43


Not how science work. They have the burden of proof. And they seem to be refusing to lift it.
@_date: 2013-09-10 17:08:00


No. 256 is enough to bootstrap the protocol by first making a smaller key than 1TB and then bigger and bigger. You still don't understand this part. Probably because you don't understand logarithmic and exponential functions.


More efficient than QKD?. Lol.  I can also make up outrageous, unproven claims. I don't, because I don't want to look ridiculous. You clearly don't know what having polynomial time algorithms mean.
@_date: 2013-09-10 23:12:22


I don't know what you mean?
@_date: 2013-09-10 19:20:47
You're probably good at convincing lay people you know what you're talking about. Your problem in this is that I'm not a lay person. I actually know this topic. I'm discussing complexity theory with someone who doesn't understand the logarithmic function... It's repeatedly a problem in your comments. You just don't understand that the generated key grows exponentially in size. And you're unwilling to admit that mistake. It's a little silly. 
@_date: 2013-11-19 16:41:31
In public key cryptography there's a public and secret key. Using quantum computers you can break (ie. much faster than brute force) several popular schemes. I believe that's what he's saying. 
@_date: 2013-10-20 15:54:24


No. All it does is it reduces the complexity from 2^(256) to 2^(128). And there's no straight forward way to run quantum algorithms in parallel. So you need to do 2^(128) rounds on *one single quantum computer*. That's nowhere near the realm of possiblity.
On top of that, D wave still hasn't provided solid proof that they have a quantum computer. And even if they do have a quantum computer, the type of quantum computer they're building couldn't be used to attack bitcoin. They can only run a very restricted set of quantum algorithms. 
@_date: 2013-09-09 07:19:45


My point with hashes and all that is that chances are that there's SOME cryptographic algorithm where the input is hard to figure out given the output, that can be used to construct a stream cipher or equivalent, allowing you to use that same key for classical crypto instead, and that this is FAR more likely than that you actually can build an un-MITM-able quantum system in which the key/one time pad can not be learned by the attacker.
Despite my several attempts, you still haven't understood how qkd works. It would be helpful if you at least read the wikipedia article before presenting such bold claims. Here we go.
Alice and Bob share a small secret key of some fixed length.
They use this small key run an authenticated instance of the qkd. After the run of the protocol, Alice and Bob share a much, much longer secret key. This key can be used for anything they want. It can be used for one time pad. It can be used for AES. Or part of it can  be used for authentication, so they can run the protocol again.
The small key can be used to bootstrap a completely secure communication of essentially any length.  
@_date: 2013-09-08 23:22:22


I've already agreed you need to share a small secret prior to the protocol to have authentication. Note that authentication can be done unconditionally secure. It doesn't require a computational assumption like pkc. 


I don't see the point in using a secret key for measurement in qkd like that. But you're welcome to find a link. 


If you can prove it exist. It would imply that P!=NP. 


By running a quantum key distribution protocol(!!) That's the entire point of the protocol we're discussing... Dude.
@_date: 2013-09-09 19:19:57
@_date: 2013-09-10 20:29:36


You said this.


While the truth is the growth is exponential so only after a very reasonable(non-absurd if you will) number of rounds you could have a longer secret key than you would ever need. The growth is exponential. if you indeed truly realize what exponential means you'd realize that it doesn't need an 'absurd number of rounds'.
EDIT: If you go back to arguing computational complexity again, you're truly moving the goalposts. Your claim was that an absurd number of rounds would be needed. And that's either true or false, regardless of computational complexity. 