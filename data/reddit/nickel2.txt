@_author: nickel2
@_date: 2016-06-21 22:42:42
It's not clear to me how this is [homomorphic encryption]( (HE), at least in any meaningful sense.
I'll admit I've never tried to understand the details of existing schemes, but my understanding of the guarantees was that the person running the computation had to modify their algorithm somehow. So, e.g., an HE scheme would proceed something like:
1. User encrypts her search query.
2. User hands it to Google along with a public key.
3. Google runs their usual search algorithm but, for each primitive gate G (multiplication, addition, control structures, etc.), substitutes a gate G'.
  These gates G', determined by the HE scheme, take encrypted input and the public key, and produce encrypted output.
5. Finally Google returns the overall encrypted output (the ranked pages) to the user who decrypts it using her private key.
But that's not what you're doing. You're simply handing a bunch of encrypted numbers to your users without any instructions on how to to compute on them. So most of them are probably just throwing a few scikit-learn models at these encrypted numbers, which may or may not do anything.
I have my misgivings about other aspects of this (complete opacity around revenue split being the main one), but those aren't technical objections.
@_date: 2016-06-22 18:07:46
That allows decision trees, but are there any other widely-used models for which that is sufficient? I think linear functions already get screwed up.