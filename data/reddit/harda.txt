@_author: harda
@_date: 2016-08-03 00:02:21
I'm very sorry that people lost a large sum in deposits at BitFinex, but I don't think forming a mining cartel to double spend confirmed transactions is the appropriate response.
Miners: if you have recently matured block generation rewards (coinbase outputs) and you oppose the idea of a chain rollback, you may want to spend those outputs soon, especially at places (such as an exchange) where they'll end up being split into pieces and distributed to many other people.  This will make any rollback much harder to do without some innocent person losing money (and without creating an accounting mess), and so may make it seem less legitimate in the eyes of the community.
Economic full node users: Bitcoin Core contains a "hidden" RPC command that allows you to reject a particular block.  If you oppose the idea of a chain rollback in this situation, you may want to make it known to miners that you will use that command to reject any chain they produce that attempts to create this double spend.
Other users: you may want to consider switching to a full node wallet if you feel strongly about this issue, so that you can use the instructions above.  Note, you have to do this before any double-spending chain becomes the chain with the most proof of work.
@_date: 2016-08-06 00:59:58
Thank you for typing and publishing this transcript!
@_date: 2016-04-06 01:41:40
Thanks for the correction!
@_date: 2016-04-13 02:36:05
There are three ways a channel can close; here are the transactions involved in each case:
**1: cooperative close (best case)**
Alice and Bob open a channel by cooperating to create the deposit transaction, signing a refund transaction that spends from the deposit transaction before they broadcast the deposit transaction.  All payments in the channel are manipulation of that refund transaction, which has two outputs (one sending money to Alice, one sending money to Bob).
When they're ready to close the channel, Alice and Bob cooperate to finalize that refund transaction with the final balance in the channel.  They don't use CSV in those two final outputs because this is the final state of the channel, so they can start spending from it immediately (although they should wait for one or more confirmations just to be safe).
*So this case is only two on-chain transactions.*
**2: non-cooperative close with current state**
Alice and Bob setup a channel as before, but at some point Bob disappears, so Alice decides to close the channel unilaterally.  She broadcasts the most recent state of the refund transaction which has two outputs, one to Bob and one to Alice.
The Hash Time Lock Contract (HTLC) is setup so that there are actually two unbroadcast transactions that represent the current balance state of any in-progress channel.  Alice has a transaction that pays two outputs with the following conditions:
1. An output to Alice that is time locked for (say) 1,000 blocks using CSV but which can be spent after that time by Alice's signature, or which can be spent at any time by Bob's signature plus some data (a hash pre-image[1]) that Alice would have to reveal to Bob on the next payment within the channel.
2. An output to Bob which can be spent at any time by Bob's signature.
Bob has a transaction that pays two outputs with the roles reversed:
1. An output to Bob that is time locked for (say) 1,000 blocks using CSV but which can be spent after that time by Bob's signature, or which can be spent at any time by Alice's signature plus some data (a hash pre-image) that Bob would have to reveal to Alice on the next payment within the channel.
2. An output to Alice which can be spent at any time by Alice's signature.
Alice broadcasts the version of the contract in her possession, waits the 1,000 to give Bob a chance to chance to use the pre-image if he has it to claw back any wrongful close, and then she can spend the output at her leisure.  Bob can spend his output any time at his leisure, since the version of the transaction that Alice broadcast didn't use CSV to time lock his output.
*So this case also uses two on-chain transactions.*
**3: fraudulent close**
Alice and Mallory open a channel the same way Alice and Bob did.  After each in-channel payment is finalized, Alice and Mallory each reveal to each other the pre-image to the hash lock that was used in the previous channel state, as describe in the bullets  above.
Mallory takes his chances and unilaterally closes the channel the same way Alice did above, but he closes it in an old state that was most advantageous to him.  Alice is monitoring the chain; she sees the attempt fraud and she uses the pre-image Mallory sent her in the state change after the one Mallory broadcast to spend his output to herself before the 1,000-block time lock expires.
Alternatively, Alice isn't monitoring the chain, Mallory waits for the 1,000-block time lock to expire, and he spends his output to himself to prevent Alice from using the pre-image at some future time to claw back that money.
*So in this case, there are three on-chain transactions.  However, hopefully this time lock-based anti-fraud system is effective enough that nobody bothers trying to steal other people's money, so all Lightning channels will involve two transactions (or fewer on average if channel close/open merges are used, but that's a different subject).*
[1] In the original Lightning paper, they use private key reveals instead of hashes and pre-images, but after the publication of that paper, figured out an [awesome way]( to use hashes to massively reduce the amount of data that needed to be stored in case the other party attempted fraud, and that's the design used in both Rusty's code and the [lnd code](
@_date: 2016-04-05 16:04:39
Your wallet will have to go online to complete receiving a payment (because it needs to reveal the pre-image that unlocks the hashlock that prevents anyone from stealing the payment in transit).  However, you wallet will not need to be online at the time the payment is sent, as payments can be queued by the people with whom you have open channels.
How often you will need to go online to check for payments will be something your software can negotiate with your channel peers.
@_date: 2016-08-03 00:45:20


My advice above is specific to miners, but certainly the hacker could do it too.
When miners create a new block, they earn a subsidy (currently 12.5 BTC) plus whatever transaction fees they collect.  At a later point, they can spend that money.  However, if the block they created is forked off of the chain, then the money they spent no longer exists, meaning whoever received that money (or any transaction descended from when they received it) no longer has that money.
For this reason, Bitcoin has a rule that the bitcoins in a new block must receive 100 confirmations before they can be spent (called coin maturation), based on the idea that Bitcoin would be very unlikely to have a fork that is more than 100 blocks long.  In this case, a fork more than 100 blocks long is being proposed, so my suggestion above is for miners to start spending their newly mined coins as soon as allowed so that those coins flow out into the economy.  This incentivises everyone who receives those coins, or any transaction descended from them, to oppose the fork since their money would disappear even if all the other transactions are copied from the original chain to the fork.
The hacker could do something similar by spreading his money around, but it isn't the same thing: in my case, I'm talking about resistance to a rollback by honest miners; in the hacker's case, it would be a self-interested attempt to perpetuate his theft.
@_date: 2016-04-05 23:05:03
No.  Opening a channel is an interactive operation, so you'd have to upload the keys from your paper wallet to a software wallet somewhere and then you'd need to print out the channel state when you were done.  After each LN operation (receive, spend, rebalance) you'd have to re-upload the keys from your paper wallet and print out the new state.  It would be very cumbersome and would eliminate part of the security of a paper wallet (since you would repeatedly upload your keys to a computer that might be compromised).
Note that you will still be able to use HD wallets with paper backups, provided you also outsource enforcement of your channels (this is possible using the protocol with, I believe, no reduction in security -- just an inconvenient wait if your outsourced enforcer goes rouge and decides to close your channels on you).
@_date: 2016-04-24 10:52:59
If I understand correctly, it provides a nifty way for users of the permissioned blockchain to keep their addresses private by default (the same level of privacy as Bitcoin has) but allows the separate people who control the system to work together to de-anonymize a particular participant if necessary.
It seems like a perfectly fine feature to me for a private blockchain, but I don't believe it's appropriate for Bitcoin.
@_date: 2016-04-05 22:51:16
In non-consensus Ripple (i.e. not the crappy altcoin), I don't think the non-fungiblity of debt is an issue because each individual creditor is in complete control over the credit lines they extend.  If Alice trusts Bob more than she trusts Charlie, then you should extend more credit to Bob than she extends to Charlie, or charge Bob less interest, or give Bob more time to repay, or require Bob have less collateral, or whatever it takes for her to treat $1 of credit extended to Bob the same as $1 of credit extended to Charlie.
@_date: 2016-04-05 23:40:14
With that I agree completely.  On the other hand, I think there are already a lot of peer-to-peer credit/debt relationships that could be easily formalized using something like Ripple.
For example, my employer only pays me after I've done half a month of work, meaning (in essence) I extend to him credit equal to up to 15 days of my labor.  My employer also sells products for which (I assume, I don't work in accounting) he gets a lump-sum payment from a credit card processor or something once a week or month or something, meaning he extends that company credit.
If these credit relationships were formalized using Ripple or Open Transactions or something, then that relationship capital could become more mobile.  I wouldn't have to wait for my paycheck to arrive to buy more bitcoins, I could simply spend the $1,000 my employer owes me through that Ripple channel and receive $1,000 in BTC through a Lightning channel I had open with an exchange.
@_date: 2016-04-05 21:30:11


That's exactly what they did!  (And kudos to you for figuring it out; I didn't realize it until one of the devs pointed it out to me.)
Ripple is routable payments using local trust, so Alice gives her friend Bob a credit line and Bob gives his friend Charlie a credit line; now Charlie can pay Alice even though he doesn't know her directly.
Lightning is routable payments using Bitcoin consensus, so Alice opens a channel with Bob (who she doesn't need to trust) and Bob opens a channel with Charlie (who he doesn't need to trust); now Charlie can pay Alice even though he doesn't have a channel with him directly.
One very nice thing about the similarities here is that Lightning can work with Ripple symbiotically.  Alice gives her friend Bob a Ripple-style credit line and Bob opens a Lightning-style channel with a stranger named Charlie; now Charlie can pay Alice even though he doesn't know her and they don't even use the same payment network.  (Note, Alice and Charlie will still need to have software that knows about each other's systems; they just don't need to both be on the same network because Bob can act as a gateway since Alice trusts him and Charlie trusts Bitcoin consensus.)
I personally think this is incredibly useful feature of Lightning, and one that almost never gets discussed outside of the Bitcoin wizard crowd.  One reason Ripple never caught on even though it pre-dates Bitcoin and Nakamoto even said he liked it (according to a quote relayed by Mike Hearn) is because it requires strong network effect.  You can extend credit in the Ripple system to your 100 friends, but if they don't extend credit to anyone else, you're not connected to the Ripple network.  A work around is for you to send money to a Ripple-connect bank, but who wants to keep their money in a bank these days?
With Lightning, we can bridge partitions in the Ripple network with trustless Lightning channels, creating a payment infrastructure that combines the best of both Ripple and Bitcoin.  For example, if you have a Ripple connection, you can buy Bitcoins without going to an exchange; if you have Lightning, you can pay people who only accept USD; etc.
That makes me really excited.
[Note: when I use "Ripple" above, I mean the original idea of Ripple, not the crappy altcoin that currently uses that name.]
@_date: 2016-04-05 14:28:52
LN payments are securely routable through intermediaries (like your supermarket) using a technique called hash locks.  For example, let's say both you and I have channels open to FooMarket.  Here's how you could pay me:
1. I send some data (called a pre-image) though a cryptographic hash function to create a string called a hash.  Anyone who runs the same pre-image through the same hash function will get the same hash, and Bitcoin's Script language includes several hash functions so it can do this as part of a transaction.
2. I give you an invoice that includes the hash I generated (but not the pre-image I used to create it).  Hash functions are considered secure if there's no known way to use the hash to reverse generate the pre-image.  My invoice also requests you pay me 1 BTC for whatever service I'm providing you.
3. You use your LN channel to FooMarket to pay them 1 BTC, but you also attach the hash I gave you to the payment along with a condition that they have to provide the pre-image that matches that hash in order to claim the payment.  Since only I have the pre-image at this point, they can't claim the payment.
4. FooMarket uses its channel to me to pay me 1 BTC, but they also attach the hash and a condition that I have to reveal the pre-image in order to claim the payment.
5. I reveal my pre-image, allowing me to claim the 1 BTC.
6. FooMarket uses my pre-image to complete the transaction you started in step 3.
In case anything goes wrong, LN allows you and FooMarket to cooperate to reverse the transaction in step 3, or (if one of you becomes unreachable), one of you can start a non-cooperative close using the state of the channel before you started step 3, reverting the channel to the last state where everyone got paid.
This same routable payment mechanism can be used with an essentially unlimited number of intermediate hops, just like how your connection to Reddit goes across a large number of network hops but is (hopefully) secured using TLS (HTTPS).  That's why Lightning Network is a *network*, it means you can pay anyone else on the network[1], not just the people with whom you opened a direct connection.
[1] Provided there's a route between them and you, of course.
@_date: 2016-04-15 11:13:06
For securely routing payments across multiple channels without letting the intermediaries steal the money, Lightning uses a hash lock.  For example,
1. Alice wants to pay Charlie.
2. Charlie creates some random data and hashes it, so now she has a hash and the data used to create it (called a pre-image)
3. Charlie gives the hash (but not the pre-image to Alice.
4. Alice uses her channel to Bob to give him 1 BTC, but she requires that he add the pre-image for Charlie's hash into the transaction in order to claim that 1 BTC.
5. Bob uses his payment channel to Charlie to give Charlie him 1 BTC, but Bob requires Charlie add the pre-image for the hash into the transaction in order to claim that 1 BTC.
6. Charlie uses the pre-image stored on his hard drive to claim the 1 BTC Bob sent him; Bob uses the pre-image Charlie put in Charlie's transaction to claim the 1 BTC Alice sent them.  Now everyone has the expect balance, and at no point could Bob have stolen Alice's 1 BTC while it was in transit to Charlie.
In order for this to work, the consensus-enforced transaction scripting language for the blockchain must support whatever hashing function Charlie used to convert the pre-image into a hash; Bitcoin supports several hashing functions; sidechains based on ElementsProject.org support all the same hashing functions; and altcoins based on bitcoind almost always support the same hashing functions.
So let's imagine that Alice is on Bitcoin mainnet and Charlie is on a sidechain, while Bob has a wallet on both of them.  Using the same hash lock described above, Alice pays Bob's mainnet wallet and Bob pays Charlie's sidechain wallet.  Because they all use the same hash function with the same hash lock, Bob still can't still the coins en route.
@_date: 2016-04-14 16:15:43
One very minor complaint: I think this should really have been two different decks, one for the single-funded topology and one for the probabilistic micropayments.
That said, both of these are excellent.  The full-push single-funded channel establishment is superb for how it just drops into the existing Bitcoin payment flow while also giving the both the recipient and the sender (if they overfund or rebalance) a new useful connection to the Lightning Network.
The probabilistic micropayments are probably the neatest solution possible to the probabilistic payments problem.  All the previous solutions I've heard vaguely outlined involved using regular transactions with some sort of fraud bond or multisig thing, but channels already have that  baked in, so adding probabilistic micropayments there with just a hashing opcode and `OP_SIZE` is really clever and adds no overhead.
But perhaps what I like best about probabilistic micropayments in a Lightning channel is that they never need to be about more than a single satoshi since the channel itself operates well at satoshi-resolution, so (as long as the Bitcoin price is below say $1 million USD per coin) you're only looking at probabilities over a penny or less.
If we were to do probabilistic payments using regular Bitcoin transactions, they'd likely have to be some reasonably high multiple of the minimum relay fee to be reasonable, and I don't think most people are good at reasoning over probabilities involving money (e.g., if Alice makes a "$1" probabilistic payment at 100-to-1 odds, she's probably not going to feel any pain for the 99% of payments that keep her balance at the same place, but she will feel a sharp and sudden loss on the 1% of payments that reduce her balance by $100; but if all she loses is a penny or less, she probably won't feel any sense of loss at all.)
@_date: 2016-04-20 18:12:59
I don't know if Pieter was the first to discover that the allowed subsidy wouldn't permanently flush to zero, but BIP42 is arguably one of the most important BIPs.  Without it's resultant code change, the monetary supply wouldn't be limited to 21 million bitcoins---which many of us believe should be a fundamental property of Bitcoin.
(Sure, it wasn't going to be a problem for a few hundred years, but can you imagine the FUD we'd have to put up with if it hadn't been fixed?)
That Pieter took a problem of that severity and then turned it into an awesome April Fool's joke is **genius** -- and is why I think it probably should be on his resume. :-)
@_date: 2016-04-06 21:51:23
You still have to pay Bitcoin transaction fees, but in the current design, fees are split between you and your channel partner for each channel.
The catch, if you want to call it that, is that if your channel partner disappears or refuses to cooperatively close a channel with you, you will need to wait several days or maybe even weeks to close the channel unilaterally.  (I believe the original Lightning paper recommended 1,500 blocks, which is about 1.5 weeks at normal block production rates.)  This is necessary to give your channel partner time to ensure that you're closing the channel in its correct state (if you don't, he can use fraud provision of Lightning's Hash Time Lock Contract (HTLC) to take all the bitcoins you deposited in the channel---which is a nice incentive for you to behave honestly).
The fact that Bitcoin transactions (including Lightning) can be cheaper than traditional payments should not be surprising.  Bitcoin/Lighting does not have to comply with the excessive amount of banking legislation that exists in most (all?) countries; the mining part of Bitcoin's security is currently 97.5% subsidized by the block subsidy, and Bitcoin has an almost fully automated fraud department (i.e., no network-enforced chargebacks unless something [truly horrible]( happens).
@_date: 2016-04-05 18:37:53
No, paper wallets don't work with Lightning.  You need a wallet that goes online regularly and checks to see if your channel peers are trying to close old versions of your channels.
@_date: 2016-04-05 15:08:40
Payments use a timeout, so if someone doesn't claim the payment by the timeout, all channels can be closed in the last state where all payments were final.
In the example above, when I receive FooMarket's 1 BTC payment, I have two choices:
1. I can send the pre-image to FooMarket and they'll finalize the in-channel payment.
2. Within (say) 24 hours, I can close the channel with the 1 BTC I received, which requires I reveal the pre-image on the blockchain.  FooMarket will be periodically scanning the blockchain for this, and by reading that pre-image from the blockchain, they can claim the 1 BTC they received from This is a simple example with just three participants, but if there were more participants what you would see would be a decreasing series of timeouts.  For example, the first person would pay with a 72-hour timeout; the second would pay with a 60-hour timeout, etc...  That way everyone would be assured that they would either get the money they were promised by the sender or they got a full refund.
@_date: 2016-04-05 13:52:45
To securely open a LN channel, you should wait for at least one confirmation of the channel-open transaction; if you put a lot of money into the channel or if you're risk adverse, you may want to wait for multiple confirmations.
After the channel open transaction is confirmed, you can make an unlimited number of payments within the channel without waiting for any confirmation on the blockchain.
If a channel is closed cooperatively (meaning both people who opened the channel work together to close it), you will also want to wait one confirmation or more to make sure the close transaction is recorded on the blockchain appropriately.
If the channel is closed non-cooperatively (perhaps because you opened the channel with someone who has now disappeared), you will have to wait for the number of confirmations your software specified when it created the channel as a contest period.  The contest period gives the other party time to come back online and make sure you're closing the channel with the correct balance (i.e. you're not closing an older version of the channel that paid you more bitcoins).  The original LN paper recommended, I think, 1,500 confirmations for that (about 1.5 weeks) to ensure that temporary problems like interruption of your Internet service for a day or two wouldn't allow other people to steal money from you.  For the LN development, they're currently using shorter intervals so that they can test faster, but when the network goes to production, your software will probably let you choose your own value, giving you a tradeoff between increased security against network problems versus decreased convenience because you have to wait to spend your money during a non-cooperative close.
@_date: 2016-04-05 19:35:57
I agree LN isn't the end of the story, although I don't think anyone was saying that it should be.
By the way, many people working on LN expect LN channels to stay open for months, meaning the network's user capacity can be quite high even with 1MB blocks.  (Segwit increases that capacity by allowing scriptSigs to be stored outside of that 1MB; Lightning transactions have large scriptSigs, so with segwit's rules they don't get penalized quite as much as they would be with just the straight 1MB limit.)
@_date: 2016-04-01 14:36:50
I believe his implementation runs on [Elements Alpha]( which uses the Alpha sidechain with a [deterministic peg]( to Bitcoin's testnet.  That means you need `alphad` (a version of Bitcoin Core modified to run on Alpha) in order to run his tests.  There are [install instructions]( for it.
It may be possible to run the tests on plain Testnet if you pretend one of the opcodes is something else; his [readme explains that](
@_date: 2016-04-01 11:36:43
@_date: 2016-04-12 20:33:41
You may have heard of the upcoming CheckSequenceVerify (CSV) soft fork; this is what Lightning uses to prevent the problem you're describing.
In order to open a channel with each other, Alice and Mallory create an on-chain transaction *deposit transaction* that pays money into a 2-of-2 multisig address where they each hold one key.  In order to prevent either of them from holding funds hostage, before they pay into that address, they create and sign a *refund transaction* that returns each person's deposit to them (minus the transaction fees).
The refund transaction (and all other regular transaction in the channel) includes as one of its conditions a CSV with a parameter of (for example) 1,500 blocks (about 1.5 weeks at 10 minutes per block).  That means that when the refund transaction is added to the blockchain, it can't be spent again for about 1.5 weeks.
However, there's also an exception to this limitation, if you have proof the other person broadcast an old "balance sheet" and you also sign a transaction using the private key of the person who didn't broadcast the old balance sheet, you can spend from that refund transaction without waiting 1,500 blocks.
So when Mallory gets an old balance sheet added to the blockchain, Mallory has to wait 1,500 blocks before he can spend those bitcoins---but Alice (and only Alice) can sign a transaction that spends those bitcoins immediately.  As long as she does that before the 1,500 block limit, Mallory not only doesn't get the bitcoins he tried to steal but Alice also gets all the other bitcoins he deposited into the channel.  (This effective enforcement mechanism is why we hope attempted Lightning fraud will be very rare.)
This anti-fraud transaction that Alice creates is the same transaction as the bounty transaction in the text you quoted, but in that case Alice pre-signs the transaction and gives it to other people to broadcast when she knows she's not going to be around.
Of course, if Mallory doesn't try to commit fraud and if he and Alice cooperate to close the channel in its latest state, they can create a final version of the refund/payment transaction that doesn't include CSV, allowing them to spend their final balances immediately.
@_date: 2016-04-21 16:23:51
Quote from the paper (page 10):


ChainAnchor that does not require the creation of a separate
blockchain system with private nodes in the


current public and permissionless Blockchain. The goal of the
overlay approach is not to create a separate chain, but rather
use the current permissionless Blockchain (in Bitcoin) to carry
permissioned-transactions relating to Users in ChainAnchor in
such a way that non-ChainAnchor nodes are oblivious to the
transactions  belonging  to  a  permissioned-group.  We  use  the
example  of  the  current  Bitcoin  blockchain  as  the  underlying
blockchain due to the fact that today it is the only operational
blockchain that has achieved scale.
That final sentence sounds like the authors are trying to get off the hook, but I think a very important question is: why are they researching how to overlay ChainAnchor on top of "public and permissionless Blockchain"?  In other words, if this is (as you say) "for permissioned blockchains" why is so much text dedicated to permissionless blockchains and Bitcoin in particular?
@_date: 2016-04-11 16:17:05
Think of having money available for routing as a classic problem in supply and demand.  If the demand for routing is high but the supply of routable money is low, then the fees that money routers can charge will be high (assuming good [price elasticity of demand](
In a market with healthy competition, higher fees would encourage more people to make money available for routing.  Given the nearly trustless nature of the Hash Time Lock Contracts (HTLCs) used by Lightning and the low resource requirements for operating a routing wallet, I think it's likely to be one of the healthiest markets ever seen (nearly perfect competition), which should keep fees very low.
If this is the case, the inability to derive much profit from fees will likely make it undesirable to operate a hub for its own sake.  Instead, I would expect (based on Joseph Poon's analysis at Scaling Bitcoin HK) that most channels would be between people who had a reason besides earning fees for opening a channel between each other, such as a desire to use a Lightning-style channel to transact with someone who isn't currently on the Lightning Network or who needs to open a new channel to deposit new funds into their existing channels.
@_date: 2016-04-05 17:39:01
It will likely increase the number of users as well.  Anyone who sends a lot of Bitcoin transactions today will have an incentive to switch to using LN (because they'll likely save on fees, not to mention LN's other benefits).
As many of the transactions those people send move to local connections (off of the global blockchain), more blockchain space is freed for other users, whether they use LN or not.
@_date: 2018-09-21 17:02:25
As far as I can tell, it was possible to respend any input that appeared in a recent block since your node was last restarted (although maybe some database cleanup thread would periodically reduce the number of dirty entries in the database).  Since that's non-deterministic, an attack would probably want to keep the distance between inputs to the minimum of 1 block and so would be able to respend all inputs that appeared in the previous block.
I'm pretty sure generation transaction (coinbase transaction) coins are excluded from this bug since they're processed specially in the code.
@_date: 2018-09-21 16:44:25


I'm still investigating the code history for my own interest (and maybe to write an article), but all the optimization I've seen related to this bug is about ensuring that newly-received blocks are received and relayed as fast as possible.  This is an important area for optimization (regardless of block size) because miners have shown a strong tendency to engage in spy mining and pool centralization when stale block costs are high due to poor block propagation and validation speeds.
I think mining decentralization is has been a major issue of yours, so I think you may want to reflect on whether you'd really consider it reasonable to accept code that's merely good enough knowing that it could lead to a higher degree of mining centralization.
@_date: 2018-09-21 20:17:47
@_date: 2018-09-21 12:04:06
The same post that says the bug was introduced in 0.15.0 is also the post that says it hasn't been exploited as of that post.  If you mistrust the part about it not being exploited, why do you trust that 0.15.0 was the earliest vulnerable release?  (I personally believe the post is accurate, but Bitcoin isn't about depending on trust and so I'm totally fine with you mistrusting the information---it just seems illogical to trust one part and not the other.)
Verifying from 485,000 to present will take a significant fraction of the time to verify from 0 to 485,000 (I'd guess 30% or more), so if you have any doubts, it might be better to reverify every block from the start.
If you do indeed want to check just a subset of the blocks, you may want to consider using the `-checkblocks` and `-checklevel` options on startup instead of `invalidateblock`.  See `bitcoind -help -debug-help`
If you do plan on using `invalidateblock`, there are a few notes:
1. It takes a block hash, not a height.  You can get a block hash for a particular height using the `getblockhash` RPC.
2. You need to run `reconsiderblock` on the same block hash afterwards to allow you to revalidate that block and all subsequent blocks.
3. `invalidateblock` is *really* slow when run for more than a few blocks.  Every time it removes a block, it has to make the the inverse set of changes it made to the UTXO database when it originally processed that block, which means invalidating 50,000 blocks takes a significant fraction of the time it took to validate 50,000 blocks; then you need to re-validate them, which will take all of the same amount of time (plus a little extra, as the restored duplicate inputs check now makes the function a bit slower than it was in the vulnerable releases).  Given this information, invalidating 50,000 blocks and then re-validating them is probably going to take you more than 50% of the time it'll take to revalidate the whole chain.
@_date: 2015-12-15 14:24:19
CPFP is a transaction relay policy, not consensus code.  It can be used as soon as it's implemented by anyone miner that wants to use it.
@_date: 2015-12-09 10:21:15


I am fucking disappointed.
@_date: 2015-12-24 13:03:54
What happens if there's a fractional-satoshi value when the channel closes?  It gets rounded down into the transaction fee?
@_date: 2015-06-01 17:55:47


I'm working on better promotion of Bitcoin Core on Bitcoin.org, and one of the features I mention is that SPV wallets based on recent versions of BitcoinJ will connect to a bitcoind on localhost---providing the security and privacy benefits of Bitcoin Core with any compatible SPV wallet's UI.
However, I've had to add a big fat warning because no graphical wallet that I know of lets you configure it to *only* connect to bitcoind on localhost, so if you accidentally forget to start bitcoind once, you can blow your whole privacy by sending a weak bloom filter to spy nodes.
Any wallet author who provides that simple config option to only connect over localhost should contact me so I can list their wallet more prominently on the page.  Of course, any wallet that provides the ability to securely connect to a particular remote bitcoind will get an even more prominent listing---but I'd aim for the low-hanging fruit first.
@_date: 2015-12-17 19:55:59
+1 Quirrell point
@_date: 2015-06-16 13:09:02
Thanks, Mike.  (Although my beard can be [pretty cool, literally](
Mike is the person who recommended that I begin contributing to Bitcoin.org, and I also have enormous respect for him and his achievements in BitcoinJ---the library nearly every SPV lightweight wallet uses.
It is my sincere hope that in a few months we'll all be back to doing the things for Bitcoin that we love, and not spending our limited contributor time arguing. 
@_date: 2015-06-29 12:23:19
In the whitepaper, where Nakamoto describes the SPV security limitation:


transactions for as long as the attacker can continue to overpower the network. One strategy to
protect against this would be to accept alerts from network nodes when they detect an invalid
block, prompting the user's software to download the full block and alerted transactions to
confirm the inconsistency.
@_date: 2015-06-23 11:56:03
I agree that pull requests are not the best metric, but I think it's probably useful to look at a comparison between the five Bitcoin Core committers, including data long before this recent debate.
|                | Gavin  | Pieter   | Wladimir | Gregory | Jeff 
| March 2014     | 2      | 1        | 23       | 2       |  1
| April 2014     | 1      | 3        | 14       | 3       |  1
| May 2014       | 2      | 11       | 12       | 0       |  0
| June 2014      | 2      | 13       | 17       | 0       |  5
| July 2014      | 2      | 17       | 14       | 2       |  4
| August 2014    | 1      | 11       | 17       | 1       |  16
| September 2014 | 1      | 28       | 18       | 0       |  0
| October 2014   | 5      | 19       | 11       | 1       |  1
| November 2014  | 5      | 52       | 2        | 4       |  1
| December 2014  | 1      | 45       | 10       | 11      |  0
| January 2015   | 0      | 12       | 7        | 13      |  0
| February 2015  | 1      | 16       | 2        | 6       |  0
| March 2015     | 6      | 14       | 5        | 4       |  0
| April 2015     | 2      | 6        | 4        | 7       |  0
| May 2015       | 1      | 1        | 8        | 0       |  1
| June 2015      | 2      | 1        | 13       | 0       |  0
| ---------------|--------|----------|----------|---------|-------
| **Total**      | **34** | **250**  | **177**  | **54**  |  **30**
*Total pull requests opened in the [bitcoin/bitcoin]( and [bitcoin/secp256k1]( repositories since March 2014, one month before the [announcement]( Gavin was stepping down as lead developer*
Note: everything was hand counted, so there are probably a few minor miscounts.
@_date: 2015-06-16 11:40:54


We're working on improving the about-us page to include more of that history.  Even the site's main contributors just learned a few things recently about the site's early days.


Develop?  No.  Write documentation for?  [Yes.](
@_date: 2015-06-09 00:08:39
Note, there are about 6,000 *reachable* nodes that accept incoming connections.  There are believed to be several times that many that are behind [NAT]( or firewalls, or which are left turned off for most of the time so that bitnodes.io doesn't count them.
I'd guess the multiple is 3x to 10x, so 18,000 to 60,000 full nodes.
@_date: 2015-12-23 02:46:32
Fixed here: 
Should be live on the site in about 10 minutes.  Thanks, @_date: 2015-06-16 19:34:27
Heh.  Last month confused [me with Tom Harding.](  Now I'm being confused with Theymos.  Next month Satoshi?
Anyway, Theymos is correct that and I make all day-to-day decisions for Bitcoin.org using the public pull request process.  You all are welcome to subscribe to the [repository]( and start leaving comments.
@_date: 2015-06-17 09:14:29


It isn't really about running a full node as much as it is about using a full node to protect your bitcoins.  Because of that, a better indicator might be the amount of wealth protected by full nodes.
@_date: 2015-06-25 13:57:21
Hey, thanks for that info about schildbach wallet!  I've been writing a page related to that, and I hadn't thought to test any of the mobile wallets because of the unencrypted connection problem.
@_date: 2015-06-09 00:41:43
Grr.  You keep conflating "local block chain data" with full nodes.  Bitcoin Core can provide you with local block chain data, but so can a rsync from a trusted third party.
A full node is a full *validation* node.  If you don't feel the need to do the validation yourself---and most people and businesses seem to feel this way---then you can get every feature full nodes currently offer in some way that is cheaper, easier, or both.
To the best of my knowledge there are no businesses that have said, "we will always validate the block chain ourselves."  Without a commitment like that, I don't think it's correct to assume there's any floor on the number of nodes run by businesses.
@_date: 2015-06-28 13:13:06


I like that idea!  I'll start working on something for the wiki.
@_date: 2015-06-24 04:14:31
I think this was a very well-written and informative article.  Thanks, [sdaftuar](
@_date: 2018-09-19 11:10:53
Bitcoin Core 0.17 is in the release cycle with three release candidates (what you seem to be calling beta releases) released so far.  Release Candidate 4 (RC4) is has been tagged and contains the same patch for this bug (with slight differences in the tests) as the patch for 0.16.3 described elsewhere in this comments thread.
The normal release process is to release about one RC a week until people stop reporting bugs in the RCs.  Then the final release is tagged, deterministically built by multiple contributors, uploaded, and announced.  Because the goal is to release bug-free software (which, demonstratably, doesn't always work), there's no deadline for the release---instead, there are deadlines for the things the contributors can control, such as when they stop accepting new features for a release ("feature freeze") and when they start making release candidates.
My personal guess based on following the progress of the 0.17 release cycle so far would be that it's pretty close to finished, so it'll probably be released within two weeks, maybe by the end of the month.  That's just a guess, though.
@_date: 2015-06-17 08:26:29
Thanks for your comment, pcvcolin.  Bitcoin.org is very grateful for the Foundation's continued support, especially now that it is in financial difficulties.
can confirm that part of Bitcoin.org's deal with the Bitcoin Foundation is complete editorial independence.  I say this not because I disagree with anything you say, but because I think it's important to establish that as a prior data point.
We have no plans to stop recommending Bitcoin Core, and if this debate ever calms down enough that I can get some real work done, I hope to improve our promotion of it in the near future.
Furthermore, I had asked previous Education Chair Nikos Bentenitis to [join our coordination mailing list]( which I hope you'll consider too.  (As well as maybe watching [our repository](  As I've offered before, I hope our two closely-related educational projects can find ways to work together.  Thanks again!
@_date: 2015-06-09 02:02:07


In the previous thread, Greg provided [proof]( that BlockChain.Info was previously using non-validated block chain data.  (Maybe they still are?)  And, yeah, they also provide perhaps the most widely-used API for block chain data.


SPV isn't trustless to the same degree as Bitcoin Core's full node validation, and last I checked all of BitGo's consumer-level users were (at best) using SPV.  It feels odd for you to argue that people shouldn't bother using Bitcoin without full validation when that's what some of your employer's products offer.  Alternatively, if you think lesser SPV-level validation is acceptable for BitGo's customers, why isn't it acceptable for BitGo?
@_date: 2015-06-30 14:56:16
Oh, well, that explains the reason for the never ending block size debate!
| Year | BIP101 increase in average on-chain users (*n*) | O(n^2 ) decentralized validation cost increase |
| 2015 | 100%      | 100%
| 2016 | 800%      | 6,400%
| 2018 | 1,600%    | 25,600%
| 2020 | 3,200%    | 102,400%
| 2022 | 6,400%    | 409,600%
| 2024 | 12,800%   | 1,638,400%
| 2026 | 25,600%   | 6,553,600%
| 2028 | 51,200%   | 26,214,400%
| 2030 | 102,400%  | 104,857,600%
| 2032 | 204,800%  | 419,430,400%
| 2034 | 409,600%  | 1,677,721,600%
| 2036 | 819,200%  | 6,710,886,400%
@_date: 2015-06-01 18:23:19
Thanks!  I completely agree, and I've made the benefits of using a wallet with full validation the centerpiece of the Features page.  It'll probably be at least another two weeks before I finish, and at least another two weeks after that before it can go live, but if you want a preview, keep an eye on pull requests to the bitcoin.org repository: 
@_date: 2015-06-01 00:31:29
What?!  Full node means Full *Validation* Node, so you're a full node even if you manually copy and paste blocks from BlockExplorer.com.
@_date: 2015-06-25 01:43:30
Note, Luke doesn't have commit access to the main core repository.  The core committers are listed here: 
@_date: 2015-06-01 00:31:29
What?!  Full node means Full *Validation* Node, so you're a full node even if you manually copy and paste blocks from BlockExplorer.com.
@_date: 2015-06-16 20:25:37
When miners today produce a new block, they add it on to the end (tip) of the block chain.  But it's also possible for them to attempt to replace the tip of the block chain for (usually) the same amount of proof of work.
Why would they do that?  Because when the block subsidy (currently 25 BTC) becomes too small, miners will be competing for transaction fees---and if there aren't enough queued transactions for the next block, it could be more profitable to replace the previous block to get its transaction fees.
That may not sound like a problem---after all, the proof of work is usually the same.  However, when replacing a block, the miner can optionally kick out some transactions (decreasing their confirmation score).  Worse, if this block replacement happens too often, it would lead to a significant reduction in the total amount of proof of work protecting the block chain.
The solution is to try to ensure there's always a queue of fee-paying transactions.
@_date: 2015-06-10 20:16:17
The change has a page describing the benefits of full validation and another page describing Bitcoin Core's privacy advantages, both of which compare Bitcoin Core to Bitcoin banks and SPV wallets.  Since security and privacy are your bailiwick, maybe when the PR goes up, you'll have the time to review those pages for errors and important missing points.
@_date: 2015-06-28 02:53:08
Um, have you talked to about that? That could adversely affect Lighthouse.
@_date: 2015-06-17 11:11:33
I didn't say everyone.  Think about how you store your fiat assets.  If you're like me:
1. A physical wallet that usually holds between one hour and one day worth of income
2. A checking account that holds all of the money for bills and other major expenses this month
3. A savings account for the rest of my non-investment money
I know the money in my physical wallet is at greatly increased risk of being stolen, so I never store much there.  The checking and savings accounts are much more secure, and I'm willing to go through some increased hassle to keep them that way.
Using a full node directly improves your security, so it should make sense for anyone who has bitcoins they can't afford to lose.  If that's not the case, then the people who can't afford to lose bitcoins are placing their security into the hands of people who can afford to lose their bitcoins---and that's not the recipe for a stable currency.
@_date: 2015-06-29 16:38:01
Awesome!  Thanks for digging that up!  Have a cookie! @_date: 2015-06-16 13:35:05


I opened [a similar issue]( myself a month ago.  I'm sorry I've been to busy to have had a chance to write it yet.  (That issue isn't about a prominent page, just an entry in the developer documentation.)
If you would like to write a page for Bitcoin.org describing the scalability situation, please feel free to [open a pull request]( adding it.  However, you may want to start by improving the Wiki's [Blocksize Debate]( page.
@_date: 2015-06-29 12:11:39
Heh, my *k* coefficient on two geographically separated full nodes is usually in the 10-15 range, but your point stands.
Currently, bandwidth is mostly 
used for these things (plus some others):
- Receiving/relaying unconfirmed transactions
- Receiving/relaying many of the same transactions, now confirmed in a block
- Sending blocks to nodes which are just coming online
- [Dumping your memory pool]( to nodes which are just coming online
- Sending compact [merkleblocks]( to lightweight clients
- Sending [addresses of other peers]( for decentralized peer discovery
- Notifying your peers about what transactions and blocks you have using a constant stream of [inventories](
Gaviin is assuming the use of [Invertible Bloom Lookup Tables]( for block propagation, which would mostly eliminate the duplicated bandwidth used for receiving both unconfirmed transactions (loose transactions) and confirmed transactions (in a block).  As mentioned in the preceding link, miners already use an efficient protocol for block propagation (although its goal is to minimize latency, not bandwidth).
The other stuff can be optimized too, although possibly not to the same degree without changing Bitcoin's [gossip network]( to a more trusting design.
I haven't done any analysis of how much upload my node uses for the various parts of the protocol, although that would be useful to make guesses about how 8MB blocks would affect bandwidth consumption in the absence of significant changes to the P2P protocol design.  Since we currently average only about half-full blocks, I would na√Øvely expect bandwidth usage to rise by 16x for full 8MB blocks.
@_date: 2015-06-09 11:54:18


Given your obvious passion for Bitcoin, I'm sure you do a great job and your boss trusts you.  But if he has delegated the job to you, why wouldn't he outsource the validation and index-building to a trusted third party if it saved him a significant amount of money?
I think you're trying to build a business case for using a full node, but if all your boss cares about is not telling the user an inaccurate balance or transaction history, there's no permanent need for him to run a full node.  He just needs to wait around for a trusted third party to offer an agreeable SLA for accurate block chain data.
If you optimize for cost, there is no floor on the number of business full node users.
@_date: 2015-06-29 13:47:18


I don't know about that.  I think fraud can go the other way too, e.g. a transaction withholding attack where a node sends you an empty merkleblock when it should've contained the PMT to a transaction that matched your bloom filter.
I think I recall a speech by you from ~April 2014 saying that's why you were adding native Tor support to BitcoinJ and contemplating some sort of zkSNARK thing for sybill-resistant full nodes to increase the resistance of SPV wallets to transaction withholding attacks, which seems like alternative solutions to the same problem---so you must think that they matter.  (But if I remember that speech wrong, please forgive me.)
@_date: 2015-06-16 14:04:01
It was not my intention to imply that a block size increase will not happen, only that nobody should make expensive plans based on the assumption that it will happen before fees rise and a longer transaction queue develops.
It's like planning a major event weeks or months in advance: you probably don't want to assume that it will be sunny and dry (unless you live in the desert).
Furthermore, Bitcoin's current long-term security model depends on a significant number of queued transactions---so, if nothing changes in the meantime, programmers need to know that their code is likely to encounter increased queuing at some point.
@_date: 2015-06-16 22:32:00
Just a quick note on terminology: the subsidy is the (currently) 25 BTC for each block; the reward is the total of subsidy + transaction fees.


Quite possibly true.  I find Gavin's [block size economics post]( to be one of the most compelling arguments for raising the block size.


This feels to me like the first point stated another way.


Very true, which is why I said "current long-term security model".  By current, I mean it could be changed as Gavin has suggested and Mike has proposed a method.  By long-term I mean it doesn't apply right now.


Ah, that's the fun part.  The unreliability can probably be fixed with some engineering---on  IRC today I saw the authors of GreenAddress and Bitcoin Wallet For Android talking about possible solutions, and I know there are other people working on this too.
For slow and expensive, you get to choose between them (within certain margins).  For example, you can choose slow and cheap, or fast and expensive.  You can already do this now with Bitcoin Core thanks to a feature implemented by Gavin and improved (IIRC) by Alex Morcos, although with today's average fees and block size it's a choice between slow and cheap, or fast and inexpensive.
It would be ideal, of course, if the network was always fast and free, but we don't have any workable proposals to make that happen.  So we get the second best option: a free market where people can pay more fees for faster confirmation or accept slower confirmation to save money, kind of like you get now in the U.S. using either a wire transfer or electronic check (ACH).


Sure, but what are those limits?  One reason the 20MB (or, I guess, now 8MB) proposal is contentious is that some people believe it's beyond our current limits if we want to sustain the same level of decentralization.
@_date: 2015-06-09 00:02:51


This is what we hoped would be the case, but nearly every business so far has switched to using remote APIs from a trusted third party as soon as they could.


For many, a 20ms RTT is an acceptably-small slowdown for not having to maintain a 40-GB-and-growing block chain---or, worse, up to several TB worth of indexes.


As [replied to you]( on a previous thread, it is wrong to say that businesses "need to run full nodes" for block chain data access.
@_date: 2015-06-28 17:32:55


Umm, most devs seem to be in favor of achieving strong human consensus before implementing a fork, so investors opposed to it would probably sway them towards a decision "not to implement a fork".
@_date: 2015-06-16 14:28:54


I don't think it's in a debated fact that Mike and Gavin plan to include a patch in Bitcoin XT that will fork from the current consensus if certain criteria is met.
They plan to do this despite a great many Bitcoin experts advising against it, in addition to at least one large miner, and something like 20% of the respondents to a BitcoinTalk poll.
So now seems like the second best time to have done this.  The best time would've been before the controversy started when everyone (except maybe Mike) agreed to the statement that hard forks are dangerous and contentious hard forks are even more dangerous.
@_date: 2015-06-28 16:14:48
Well anyone who doesn't speak up doesn't have a voice.  However, investors may have a reasonable say, if thay want: if a hard fork splits the chain, owners of pre-fork bitcoins can sell their coins on one side of the fork for additional coins on the other side of the fork.
For example, if Alice has 100,000 bitcoins and the chain forks into chain A and chain B, she now has 100,000 bitcoins on both chains.  She supports chain B, so she uses an [atomic cross-chain transaction]( to sell her 100,000 chain-A bitcoins to Bob for 10,000 chain-B bitcoins.
If the aggregate exchange ratio is significantly unbalanced, it's more likely that one chain will start off as the economically favored one.  Unless the other chain has a strong advantage, it will likely quickly be relegated to altcoin status.
@_date: 2015-06-25 23:32:06
Although I have nothing against bandwidth limiting now that Bitcoin Core 0.10 is well deployed, has said that he believes that for some users, the problem may not be bandwidth limits but rather because of routers that have [bufferbloat-related problems.](
In his [recent post]( identified that Bitcoin isn't as well optimized for sending blocks as you might think, and that this could be related to the severe bufferbloat problems that Bitcoin Core triggers.
Fixing the fundamental problems here could be harder than just adding a rate limiter, but it would have the nice benefit of improving the amount of data you can upload before suffering traffic congestion, as well as helping to make decentralized mining more reasonable in some setups.
@_date: 2015-06-29 11:45:51
Ok.  I was just responding to the fact that you [previously told me]( that you were thinking about allowing XT to accept &gt;100KB standard transactions to allow Lighthouse to submit larger transactions, which made me think that you were unsatisfied with the limit as a relay rule and would be even more unsatisfied with it as a consensus rule.
I just wanted to make sure that Gavin was aware of the needs of Lighthouse.
I also agree that there are plenty of nice protocol fixes that could be made using a hard fork, and the Trezor one where they sign what they think is the input amount sounded nice to me.
@_date: 2015-06-08 18:48:23
It seems to me that what you've defined is not an "entity who needs to run full nodes in order to run their business" but someone who is running a full node until some better way of getting the data comes along.
Full node stands for full *validation* node; the non-validation features provided by full nodes are just bonuses.  If you depend on the bonuses only, then you aren't really depending on a full node.
A case in point would be a Bitcoin Core with pruning turned on.  It's still a full node, but it doesn't provide the complete historical block chain locally.
@_date: 2015-06-16 20:55:21
Bitcoin clients accept the strongest block chain.  Within a single 2,016-block difficulty period, this is the longest chain.
So, all other things being equal, two blocks at the tip of the chain each have an equal chance of having the next block built on top of them, making whichever one that is into a part of the longest chain---and making whichever one that isn't into a [stale block](
Because the system works well now with the 25 BTC block subsidy, full nodes accept the first block they see and don't replace it unless a longer chain comes along.  This works pretty well right now.
However, if there wasn't an incentive to extend the chain, that rule wouldn't make as much sense.  It might be that some miners would pay other miners not to build on top of their competitors' blocks.
@_date: 2015-06-17 08:10:06


I do not have exclusive control over Bitcoin.org's content.  There are seven active people besides me who currently have the technical ability to add content to the site.  Five of them (plus me) agreed with the policy; one disagreed; and one didn't comment (but has made previous statements strongly opposing contentious hard forks).
In addition, a number of other people indicated support for the statement in the [public pull request]( (see [partial summary]( and I made several changes to the statement based on feedback (for example, Mike Hearn suggested some of the phrasing could be misinterpreted, so I added a clarifying sentence [here](
It may also be useful to note that the reason I'm one of the people who can add content to the site is that Gavin Andresen gave me access more than a year ago.


Please note that the [statement]( says nothing about block size increase proposals.  The policy is about contentious hard forks in general.
Using your presidential debate analogy, this is similar to a policy that does not help promote candidates who currently propose armed overthrow of the democratically-elected government.  A policy like that in presidential debates would be neutral---applying to all candidates equally---and a policy like ours in hard fork discussions is similarly neutral.
@_date: 2015-06-01 18:21:07
I don't know yet---I'm still writing the draft and will do the research when I'm ready to list specific compliant wallets.  (Rather than read wallet code, I plan to fire up Wireshark and actually check each wallet's network access.)
@_date: 2015-06-28 18:55:08
Sure, but it goes the other way too: a relative handful of early investors could block degeneration even if the overwhelming majority of users are for a fork.
@_date: 2015-06-15 01:45:42
Note, that's not a default, it's mandatory for now when the node is pruned---the [P2P version message]( doesn't currently have any way for a node to say, "I only have [these] blocks".
@_date: 2015-06-02 12:00:50
I liked the phrasing of this clause: "once the hash of e is computed, e is in the past and cannot be changed any more than you can choose not to have read this sentence."
I don't know whether Greg or Andy wrote sentence above, but it reminds me of my favorite sentence (so far) from -- "The result of [the Landauer limit] is a consensus which is extremely resource-intensive, producing entropy and driving us toward the heat death of the universe literally as fast as the laws of physics will allow."  (Source: the [old POS FAQ]( sadly, the phrase didn't make it into the [new FAQ](
@_date: 2015-06-21 01:01:16
I'm in Burlington county, so a long way away, but I'd certainly try to stop by first chance I got.  Good luck!
@_date: 2015-06-10 19:17:07


Just a quick note, contributors at Bitcoin.org have been working to both un-bury and effectively promote Bitcoin Core.  The [full node guide]( (released for 0.10.0) is now linked from the site's Participate menu, and a new Bitcoin.org Bitcoin Core home page (and sub-pages) has been under active development for exactly a month now, with an estimated 2 to 4 more weeks of part-time development left before a pull request is opened to add it to the site.
@_date: 2015-06-29 15:39:18
Do you have a source for where Garzik said he agrees with a flag day?  I know the proposed BIP says that Garzik suggested it, but I suggest plenty of things I disagree with just to make things less bad.
(Not that I think RBF is bad; once 0.11.0 is released, I think I'm going to use it in my regular master-based node patchset to help transaction propagation.)
@_date: 2015-06-21 00:57:37
I know it's been a while, but I wanted to follow up and say I've tested MultiBit HD---the only desktop P2P SPV wallet on the Bitcoin.org wallet page I think I might actually like to use--- and it turns out that it will automatically connect to localhost:8333 (as I had heard), but it'll also use the usual DNS seed bootstrapping and connect to a bunch of random nodes. :-(
This seems dumb to me, but I guess maybe it simplified programming (since BitcoinJ provides heuristics for zero-conf trustworthiness based on broadcasting a tx to a subset of its connections and then listening for the transaction from its other connections; for this reason, I think by default it won't even broadcast a tx unless you have 4 connections). 
Anyway, I guess all we're going to list on that part of the site for now are Armory and mSigna.  Thanks again for the coffee!
@_date: 2015-06-09 02:22:49
The "good analysis" says,


@_date: 2015-06-16 00:05:13
Thanks!  It's now [fixed](
@_date: 2015-06-17 08:57:37
Thanks!  I do watch the GitHub repository and [comment]( when I can.
@_date: 2018-08-04 20:55:18
It should be noted that at both and myself (who made contributions to the fork) are both long-time Bitcoin.org contributors.  In my case, I'm the primary author of the developer documentation on that site (about 150 printed pages worth), the full node installation instructions, and several other pages.  I was also the site's lead maintainer for about a year in 2015.
I contributed that content under the free (open source) MIT software license with the expectation that I would be able to take it\* with me if there was ever a disagreement between myself and the site owners---and I explicitly told the site owners this.  Here's an excerpt from an email I sent and on 14 June 2015:






   publish them somewhere else if there's a severe disagreement over the
   site.
\* Edit: I meant "take a copy with me."
@_date: 2015-06-30 14:19:56
Wow.  Massive downvoting, but lets run the math: 167,884 readers times (1-.999) means there might be 167 people more knowledgable and intelligent about Bitcoin than Peter Todd.
That seems like too many people, so you must be being downvoted for not being precise enough.  Next time, say 99.99%.  :-)
@_date: 2014-07-03 23:00:05
Buterin's solution does not require miners run a full node; it only requires that they have the same data a full node would have.  If miners get this data from their pool the way current miners do, the pool can pull all the same double spend and transaction-withholding attacks it can now.
On the other hand, Buterin's formula requires miners keep a much larger memory cache than is required for SHA256, making it more efficient to put miners closer together (so they can share memory), which increases centralization long-term.  This is a common fault in most of the alternative proof-of-X ideas.
@_date: 2014-08-18 16:31:01
I'd never head of P2SH^2, but I just [looked it up]( and it's an interesting idea.  Thanks!
@_date: 2014-04-28 14:45:02
Whatever miners do, you still control the private keys to your bitcoins.  At any point, you can download a copy of the Bitcoin Core source code, change a few things, and create a version of Bitcoin which current ASICs can't mine but which is compatible with all current private keys.  You can call it Bitcoin 2.0 and try to get other people to use it.
That's what I call decentralization.  Mining pools don't control Bitcoin; the users who hold bitcoins do.
@_date: 2014-08-17 19:56:55
In analogies to fiat, I think:
* Mobile phone / general computer hot wallet == physical wallet (1-7 days worth of income)
* Trezor-like wallet == checking account (1-3 months income)
* Cold storage == savings account / investment account (the rest of your bitcoins)
Cold storage is very secure, but also quite annoying if you have to use it frequently.  Although I haven't ordered a Trezor yet, I do like the idea of having something in between my hot wallet and my cold storage.
@_date: 2014-06-28 00:14:15
The public key is still revealed---it's part of the signature.  You just don't need to explicitly tell people what it is if you have some other way of identifying the signature, such as by its hash.
@_date: 2014-04-06 18:15:46
It used to be that miners didn't get transactions at all; they used `getwork` to get headers only.
With the increase in hashing power rendering the 4-byte header nonce effectively useless, almost all miners today use `getblocktemplate` to get the complete transaction data part of a block; then they construct their own header and hash it.  This allows them to add extra nonce data to the coinbase transaction, which updates the 32-byte Merkle root header field---giving them much more arbitrary data to play with and drastically decreasing the amount of polls they need to make against the mining pool server.
@_date: 2015-06-17 15:09:52


Are they?  I guess you didn't have a recent banking crisis in your country that required a $1 trillion bailout.
@_date: 2014-05-13 23:57:12
A bit more discussion of this issue (and how HD wallets work) is in the [HD section]( of the [soon-to-be-merged]( Bitcoin.org developer guide preview.  In particular, see the [hardened keys]( subsection for the official solution to this problem.
@_date: 2014-05-14 17:03:22
The advantage is the same as described in BIP32 and repeated by Vitalik: normal extended public keys can monitor transactions involving any of their normal descendant keys.
Although Vitalik presents the case of an auditor colluding with the owner of a descendant private key to steal funds, there are ways to allow the auditor to do his work without giving him access to the chain code, such as loading the chain code and key derivation formula onto a TPM chip and then letting it derive the non-extended child public key for a particular parent public key + index number sequence.
@_date: 2014-07-17 12:52:30
Note, has a [blog post]( describing how that money was spent.  (For details, click through to the PDF linked from that post.)
@_date: 2014-07-21 15:12:44
Sure, in theory.  In practice, it's much easier to suborn an application-specific device like an RNG than a general-purpose device like a CPU.
More usefully, backdooring a CPU would probably make it less efficient, so you'd have to backdoor *every* CPU or people will naturally switch to the faster non-backdoored CPUs.
@_date: 2014-06-26 22:02:36
I don't know why a security expert would volunteer to audit BitAddress.  The whole website is based on a bad idea---manually managing private keys.  The concept leads people to do foolish things, such as reusing addresses or treating private keys like transferable tokens or compromising their whole HD wallet because they don't understand cross-generation key compromise or continuing to use a private key after they "swept" it on a site.
It isn't the number of people who read the code, it's the amount of time experts spend thinking about the code.  An awful lot of expert hours have been spent on Bitcoin Core and an awful lot have been spent on OpenSSL.  (But never as much as we would like, of course.)  BitAddress as a mostly ill-conceived auxiliary tool is never going to get the expert attention these more widely-used general tools get, and so it is much less likely to be secure.
@_date: 2014-06-22 18:25:14
Also, for people who might be reading this, everyone is welcome to comment on additions or changes to Bitcoin.org content.  All the HTML content on the site is [managed through GitHub](
You can watch that repository on GitHub to get notifications of proposed and actual changes.  You can also submit issues if you think some content is inappropriate.  (Better yet, you can submit a patch as a pull request.)
For more info, check out the site's [README](
@_date: 2014-04-13 20:10:32
If you fill out the boxes, it will give you an address you can use to receive payment.  The data you enter will then automatically be associated with that payment when it's received.
@_date: 2014-04-13 18:50:08
The developer guide has a description of [how it works]( with an illustration of the workflow.
@_date: 2014-06-27 14:15:09
Sure, if people are only willing to bump fees 5%.  But with typical fees being in the USD penny range, it doesn't seem unreasonable for people to bump fees by 100% or more in order to support something they want, such as decentralization.  A transaction with 100% additional (directed) fees can support more than 100% additional outputs without lowering its fee-per-byte, all other things being equal.
However, I was thinking more of the general case: if this patch makes miner competition easier, can't we expect it to make it easier for miners to compete on something besides price, and isn't that a good thing since it's probably an over-focus on short-term income which has gotten us to this sad state of mining decentralization?
@_date: 2014-07-21 16:20:49
Wallets can't do it without a third-party service to keep the record of accounts, and nobody can agree which third-party service to use.  (Should we use Coinbase?  Changetip?  What if last year we all used Mt Gox? Etc...)
It's a tricky problem.  Some are looking to side chains as a possible solution---we can create a side chain, move some bitcoins to it, do a bunch of micro transactions, move the bitcoins back to the main chain, and then collectively delete all the data on the side chain.
@_date: 2014-07-21 19:03:30
I really like that idea.  I had a similar thought a few years ago but couldn't think of how to make it work in a decentralized fashion.  Do you know if there's any BitcoinTalk thread or something else discussing a solution?
@_date: 2015-12-10 14:28:26
Hey, can I start posting some of these articles to the mailing list to help prevent kidnapping?  
Or maybe I can start posting about some other social cause that could save hundreds or thousands of lives a year?  After all bitcoin-dev is populated by a number of highly intelligent and competent engineers who could help tackle those problems.
The reason I won't do that is because I respect that many people joined bitcoin-dev because they wanted to read and participate in technical discussion about the Bitcoin protocol and the Bitcoin Core software.  Topics outside of that scope don't belong on the mailing list even if they could accomplish something we'd all agree was good---and that's ok because there are other places people can post their non-Bitcoin-tech ideas (such as Reddit).
@_date: 2014-04-08 12:00:20
It'll confirm eventually.  Miners and mining pools running Bitcoin Core with the default settings reserve 50 kilobytes for high priority transactions whether or not those transactions pay a fee.  The older the output you're spending gets, the higher priority it has.
If you create another version of your transaction, it probably won't work because the network will reject it as a double spend attempt.  You'd have to contact a mining pool directly about getting your transaction unstuck.
Future changes planned for Bitcoin core include a system called child-pays-for-parent, which will allow you, in this case, to spend your change output with a higher fee to get its parent transaction unstuck.
Does that answer your question?
@_date: 2014-04-28 16:17:00
You still need a password to generate a *new* address, however Bitcoin Core now uses one of its cached (pre-generated) addresses when you create a payment request on the new Request Payment screen.  By default, 100 addresses are pre-generated, so if you try to create more than 100 payment requests, you'll be prompted for your password.
The fundamental security level hasn't changed---but now you can keep your private keys encrypted when you just want to receive money, which can help protect you against recently-installed key-stealing or keylogging malware.
@_date: 2014-07-21 14:45:18
Not easily.  Random Number Generators (RNGs) typically produce relatively small amount of data (at most a few kilobytes per second for consumer products), but you need a large amount of data to measure whether they're even reasonably random.
Although security experts do test devices and software for randomness, they usually start and end their analysis with models that try to predict randomness----because getting large samples takes too much time or costs too much money.  (Try buying 10,000 iPhones to test whether or not the NSA hid a back door in them.)
@_date: 2014-08-17 23:04:36
The Trezor is designed to do just a handful of things, such as create ECDSA signatures.  It's relatively easy to design hardware that runs the stock signed Trezor firmware but which replaces certain instructions with alternative instructions that weaken your security.
This hypothetical compromised hardware could come from the original equipment manufacturers, the Trezor designers/distributors, or somebody who intercepted your Trezor in the mail.  Unfortunately, without an electron microscope and a lot of work, there's no way to test whether your Trezor's hardware has been compromised.
On the other hand, compromising the CPU of a general-purpose computer is extremely hard because of the wide variety of things it's expected to do.  Any compromise would likely significantly degrade its performance, and that would likely make it uncompetitive with non-degraded CPUs. Furthermore, since my current cold storage laptop (an Asus EeePC) pre-dates Bitcoin, it's not likely it was engineered to steal bitcoins.
@_date: 2014-04-13 18:28:35
I think you're talking about the payment protocol (BIP70) which allows authenticated payments.  There's been some discussion about an extension to it which will allow wallets to tell their users about recurring payments, but no extension has yet been written.
@_date: 2014-07-21 14:14:58
No.  In the specific case of Bitcoin Core, private keys are stored in their regular format inside an encrypted file.  (If wallet encryption is enabled.)  You need the passphrase to access the encrypted storage, but once the storage is decrypted, the keys can be used like any others.
All other wallets I know of that have an encrypted option use the same mechanism.  This is particularly useful, because if BIP38 uses key stretching that takes from one to fifteen seconds (depending on parameters) on a standard computer to decrypt the key.  (Possibly longer on a mobile device.)  So if you had to send a transaction which required 5 different private keys for signatures, you might have to wait over a minute to send it.
@_date: 2014-07-04 10:31:20
I'm sorry I wasn't clear.  Your solution only requires miners have the same data on a local data storage device that a full node would have.  This is not the same as running a full node.
If miners get the local copy of the block chain from their pool using rsync, the pool has the same powers it has now.
Thanks for your reply.
@_date: 2014-04-08 02:35:41
My pleasure.
Edit: holy smokes, Batman!  Thanks for the gold!
@_date: 2014-08-20 14:57:51
There does seem to be a bit of personal attack in title, which deserves disapproval.
However, I suspect maybe his/her goals are to get the issue fixed and to hold you accountable to your job title.  You spend a lot of time advocating and educating, which necessarily leaves you very little time for security work, as evidenced by the fact that the BC.i staff seems unwilling to bring security tickets to your immediate attention.
Perhaps you should consider taking a new job title without any implicit responsibilities.  I believe noted security researcher Bruce Schneier was BT Group's "Chief Technologist".
@_date: 2014-08-18 11:42:45
Cool.  Thanks!
@_date: 2014-04-14 21:48:35
Lots of gas (petrol) stations around here (New Jersey, U.S.) have different prices depending on whether you pay with cash or credit.
@_date: 2014-07-17 12:45:32


FYI: the open source logo is trademarked but the term is not.  Eric Raymond has a post somewhere that says they tried to trademark the term but the judge ruled it had too much [prior use.](
@_date: 2014-02-22 20:41:58
I think you miscalculated.  It's 0.24%.
* Current BTC in circulation per [BitcoinCharts.com]( 12,426,075
* Current balance of seized SilkRoad coins per your link: 29,659
* Math: 29,659 / 12,426,075 = 0.00238 (0.24%)
@_date: 2014-04-13 18:03:04
The (still-being-worked-on) developer guide discusses recurring payments:


[Read more](
@_date: 2014-07-21 18:49:12
My gut reaction was to say no like but you could be on to something.  If pool X has more hash rate than pool Y, pool X can check the same hashes pool Y will check---but do it first---ensuring pool Y never finds a block.
I doubt anyone's exploiting this.  It would be easily detectable statistically and it requires very little code to add randomness to pool Y's extranonce distribution.
@_date: 2018-05-26 11:21:54
There are some nice user-facing improvements that have recently been merged into the development branch, but it's really important to note that the project has a policy that any feature can be removed prior to a release if a hard-to-fix problem is discovered with it (or even an easy-to-fix problem too close to the release deadline).
That means nobody can tell you for sure that any specific new feature will be in 0.17.0.
In addition, some contributors worry that pre-announcing new features gets everyone excited at the time the announcement is made---at the cost of making the actual release announcement seem like old, boring news.  This, in turn, makes the releases themselves seem boring. :-(  (And, if I may add my own comment, when releases are boring for users, they become boring for developers, who may then become more likely to go longer between releases as producing a release is a lot of work that takes away from some of the funner parts of development.)
For these two reasons, the project generally doesn't announce new features prior to releases.  Of course, everything is developed in the open so you can look for yourself, but you can avoid disappointment and premature enthusiasm by waiting for a release.
@_date: 2014-07-01 16:11:03
Actually, I don't think you can do that with the Trezor.  It generates its own phrase and lets you copy it down so that you can restore using compatible software *on your computer.*  If I understand correctly, you cannot recover from a phrase on your Trezor, so you also can't enter an arbitrary phrase.
@_date: 2014-05-25 14:54:55
Bitcoins are highly divisible and cheap to move, with transaction fees being only a few dollar cents.  I suggest you buy about $5 USD worth of bitcoins and keep using them until you feel comfortable.  If you mess up and lose $5, then you can probably just shrug it off.
Here are some experiments you can try:
* Put $1 in a paper wallet.  Then try to spend it.  (Better yet, try to spend only part of it to see how you have to spend it all or lose the unspent parts.)
* Put $1 in a various Bitcoin desktop and mobile apps you want to try and see how everything works.   Then search Google for: [app name] security
* Look up the transactions you made by txid or address on BlockChain.info to see how much information is revealed.  Maybe try their coinjoin service or DarkWallet to see how it can improve your privacy.
* Maybe use a small amount of coins to do something people say is dangerous or which won't work to see what happens.  Of course, be prepared to lose those coins.
And, my favorite, after you finish experimenting, give the remainder of your $5 learning investment to a friend or family member so they can learn about Bitcoin too. :-)
@_date: 2014-04-08 02:01:49
I'm not exactly sure what you're asking.  
If you're asking what would happen to Bitcoin if the Internet was turned off for a few minutes or hours, the answer is that nobody would be able to spend bitcoins---but everyone's bitcoins would be safe.  The block chain is stored on disk, not in memory or on the network, so as soon as the Internet was restored, things would quickly return to normal.
@_date: 2014-06-04 22:57:27
After you finish signing the transaction, you give it to them.  They inspect it to make sure it's a valid transaction[1] and then broadcast it to the network.  This lets them track how much money was sent using their system.  (It also lets them associate the transaction with your IP address.)
[1] They have to inspect the transaction before broadcasting it because peers on the Bitcoin network by default ban you for 1 day each time you try sending them invalid data.
@_date: 2014-05-14 13:10:26
You don't harden (or "soften") the whole wallet, just particular hierarchies.  For example, by default the master key (m) in an HD wallet is hardened, so none of its children can compromise it.  Downside: there is no master public key.
However, if you create a child extended private key from the master key (m/0), you can use that private key to create the corresponding extended public key (M/0).  Now you can put M/0 on your webserver and generate new addresses which you can spend from your offline computer using m/0.
Even if m/0 gets compromised (through the attack described in this article or some other way), m (the master key) is not compromised, so any other children you've created with it are safe.
Does that answer your question?
@_date: 2014-07-21 12:26:36
Most computers and devices use software which polls multiple standard hardware devices for hard-to-predict data, such as disk drive latency, keyboard strokes, mouse movements, network activity, etc.  
Software is currently preferred over hardware by many security experts because it's easier to audit in a world where NSA and other groups often try to insert back doors into crypto products.
@_date: 2014-04-14 01:16:35
It's an advance payment because you must have the bitcoins in advance to create a time-locked payment.
Edit: also, it's not really automatic recurring because once the scheduled payments are all paid out, no more payments are made automatically.
@_date: 2014-07-22 17:46:00
Bitcoin.org received (is receiving?) a grant.  There's a nice detailed post about how that money was spent on the foundation blog (be sure to click through to the PDF):  
@_date: 2014-04-28 18:50:22
Yes, that's how it used to work.  Now when you *request* a "new" address, it gives you one of the pre-generated addresses and then sets a flag to create a new address the next time you decrypt your wallet.  If you request *n* cached addresses between now and when you next decrypt, it'll create *n* new addresses the next time you decrypt.
This gives you very nearly same backup effectiveness as before without forcing you to decrypt your wallet every time you request a new address.
Edit: Bitcoin Core plans to move to [BIP32]( HD wallets soon, so you'll be able to get new addresses without ever having to decrypt your wallet.
@_date: 2014-04-21 23:06:27
[This Wikipedia article]( describes the actual quantum algorithm which could be used to speed up hash checking.
Regarding your understanding: I don't know much myself, but I think the flaw in your proposal is setting the trigger.  Quantum calculations aren't possible if any part of them can be measured, which is what a trigger would do.  Instead, you have to set them up to run, wait a certain amount of time predicted by your algorithm, and then read the current particle state.  
That's what the algorithm linked above does.  If it were applied to Bitcoin mining, it would return a hash of 0 one time in 2^128 operations instead of the current one time in 2^256 operations.  In other words, if all miners today magically got quantum computers as efficient as their current equipment, the hash rate would go from today's 2^61 hashes/average block to 2^189 hashes/average block, leaving "only" 2^61 hashes/block until we ran out of growth potential.
@_date: 2014-04-11 15:34:47
IANAL either, but I do know that if you could eliminate liability with a contract clause, every software program in the world (free or proprietary) would include that clause.
A [quick search]( shows that programmers and software companies do frequently get sued, so I assume that the eliminate-liability clause does not exist.
My understanding is that giving away software for free and accepting altruistic donations does not create an implied contract in systems based on English common law, so the without-warranty clause is an effective disclaimer.  But once you start collecting fees like a business, you do start to create implied contracts which weaken or destroy the without-warranty clause.
@_date: 2014-07-21 16:09:13
Each Bitcoin transaction takes up a certain amount of space---a bit less than 1 kilobyte on average---stored on thousands of computers.  That's a large cost, so there will probably never be pure Bitcoin microtransactions.
Doge and Litecoin and all other altcoins based on Bitcoin have the same problem, so none of them are long-term solutions.
The long term solutions we do have involve the ability to make multiple small microtransactions that add up to enough for a regular transaction ([micropayment channels]( and off-chain transactions, which are transactions handled outside Bitcoin (often involving non-decentralized trust) that have the current balance of accounts committed to the block chain periodically.
@_date: 2014-05-04 22:26:55
Actually, I think was trying to make a joke which maybe only a few of us TeX nerds got.  TeX/LaTeX uses the font Computer Modern by default; Microsoft Word uses Times New Roman by default.  Signal-to-noise ratio is a measure of quality which originally came from radio operation.  Thus minorman's joke was:


I think that dangling parenthesis might supposed to have been a smiley face.
@_date: 2014-04-22 21:15:18
Think about an analog clock, with the following correspondence to public-key cryptography.
* The public key is the formula that says there's 60 minutes in an hour.
* The data to be signed is the minute hand.
* The signature is the hour hand.
* The private key is the gears inside the clock.
Starting at 12:00, if you move the minute hand from 12 to 6, the hour hand moves to half-way between 12 and 1.  You can't see the gears working to effect that change, but it's predicted by your formula, so you know the gears do what they're supposed to do.
In other words, starting at 12:00, if you change the data from 12 to 6, the signature changes to be half-way between 12 and 1.  You can't see the private key signing the data, but the result is predicted by the public key, so you know the signature does what it was supposed to do.
@_date: 2014-06-27 17:04:07
So an interesting thing about ECDSA signatures is that you can use the signature to reconstruct 4 possible public keys---one of which is the actual public key.  That means it's possible for someone to take a signature, generate the four possible public keys, hash them, and check the hashes against the address.  (Or eight possible public keys if you don't know whether or not they used compressed keys.)
However, I don't know of any implementation that does that for you currently, so what you said is necessary today.
@_date: 2014-04-14 14:30:49
Bitcoin uses triple-entry book keeping, where the receipt (output) from one transaction is used as the payment (input) for the next transaction.  [Here's a picture](  (From a soon-to-be-updated version of the [developer guide preview](
Every receipt/payment (input/output) can be traced back to the block where the satoshis were mined, so there's no need to give satoshis individual identifiers---you can infer everything you need from the block chain.
@_date: 2014-08-23 14:55:51
That first link was great.  The second URL has a typo (it ends in "cryptocrypto").  The correct link is: 
@_date: 2014-07-01 16:53:52
For recovery, you do enter a mnemonic---into a program on your computer (not your Trezor).  Any BIP32/BIP39-compliant program will work, although I imagine the software provided by Trezor makes it easy by providing all the necessary parameters.
The mnemonic is for cases where you lose your Trezor or it stops working, so loading a seed onto the Trezor doesn't make sense and can only reduce your security.
For example, imagine I was over your house, got access to your Trezor while you were in the bathroom, and programmed my seed into your Trezor---from then on, I could monitor all of your transactions, attempt to double spend payments you made, and steal any deposits you made to the Trezor's wallet.  (I could wait months or years for you to make a large deposit to the Trezor for, say, a car or house.)
@_date: 2014-06-25 04:01:51
We'll it's networking code, not consensus code, so it should be easy to experiment with once headers first gets implemented.
If I recall that dev list discussion correctly, I think the big criticism was that we don't want miners to ever build empty blocks (which you'd have to do to reliably build on just a header).  That seems like a valid argument, but the frequency of that happening should be low enough to be tolerable.  For example, the chances of a block being created in just 10 seconds are 1.6% (exponential distribution):
    python
    &gt;&gt;&gt; import math
    &gt;&gt;&gt; 1-math.exp(-(1./600)*10)
    0.01652854617838251
On the other hand, what you say rings true.  If miners hold on to the headers longer and longer, then not only can they be tricked more easily (brining down the cost of an attack), but even when there's a valid block belonging to that header, they'll create empty blocks more often, and that would certainly be bad for the network.
@_date: 2014-06-26 20:12:22


What people?
The problem with application-specific build-you-own-crypto tools like BitAddress is that they've probably never been subjected to prolonged scrutiny by researchers and attackers, which makes them look secure *now*---but the important question is whether or not they'll be secure months or years from now.
Conversely, this is the advantage of more generalized random number generators.  I haven't checked the code, but I'd guess Bitcoin Core uses the OpenSSL RNG code, which is probably the RNG which protects 90% or more of Internet commerce.  (Except when Debian breaks it. :-)  I don't have any details, but I'd bet it's also one of the most studied RNG implementations---almost certainly thousands of times more studied than whatever BitAddress uses.
@_date: 2014-07-21 15:26:54
Oh, sure, you could probably change the basic operations of the CPU without any loss in efficiency, but CPUs are really dumb---they know nothing about the program they're executing except the current operation being performed.  (And maybe a few operations ahead from the cache.)
To be able to subvert a software RNG, the CPU would need extra code that inspected and changed programs either in memory or as they were being executed.  That takes a significant number of extra operations, so the CPU with either be slower than a non-backdoor version or it will use more resources (electricity, space) than a non-backdoor version.
@_date: 2014-04-06 15:11:00
It's not weekly installments, but there's a developer guide being worked on for the Bitcoin.org website.  Here's the current [preview](
We're looking for contributing writers, editors, technical reviewers, and---especially---new Bitcoin developers like yourself who can tell us what's confusing them.
@_date: 2014-04-14 16:05:38
The best comment from that thread is the [reply by Excerpt:


@_date: 2014-05-22 15:18:30


In Bitcoin, miners can refuse to build on blocks created by other miners.  It's happened before as the result of software bugs and it's been proposed as a method for dealing with miners who assist double spenders.
I'm not sure how you could extend the block chain to apply to government without adding some sort of centralization or pay-for-vote mechanism. 
@_date: 2014-04-06 19:34:23
Thanks.  We have a nice description of P2SH and multisig (and P2SH multisig) principles.  We also have a TODO to create a examples for multisig and P2SH multisig using Bitcoin Core's RPC (which is what you'd probably use in Ruby).
As for adding data, we have descriptions of script and example Python code for creating a simple pay-to-pubkey-hash (P2PH) script which you could probably quickly adapt to Ruby.
Please let me know if anything in the docs is unclear or could be improved.  Thanks!
@_date: 2014-07-21 19:19:03
You've got it correct.  We have a working Payment Protocol python script in the [Bitcoin.org Developer Examples]( and [PaymentRequest generator]( will output a testnet request paying multiple addresses. 
@_date: 2014-07-21 15:40:46
The rapid increase in difficulty makes it ineffective to operate most mining equipment for more than a few months, so the reward halving doesn't effect any current miners.  (Unless difficulty stops rising.)
Should we care?  Nothing happened to regular users at the last halving, so the question is: has anything fundamentally changed since then?  (I don't think so---but you can make up your own mind.)
@_date: 2014-04-21 12:55:41
Quantum computing doesn't significantly affect Bitcoin mining.  What it would do is allow an attacker to reconstruct a ECDSA private key from an ECDSA public key or signature.
However, standard Bitcoin transactions ([P2PH]( and [P2SH]( hash your public key, so not even someone with a quantum computer can see it until you first spend satoshis sent to that address.  If you use an address only once ([as recommended]( this gives the attacker only a short amount of time to reconstruct your private key and double spend your transaction.  (Double spends are easy until your first confirmation; then they become much harder ([here's a chart from Satoshi](
That means that not only do effective quantum computers need to be invented, but they need to be made fast enough to reconstruct ECDSA private keys.  That's a long way away and it requires too many intermediate steps for anyone, even a government, to keep entirely quiet---so we'll know when the deadline is approaching.
Since anti-quantum computer algorithms take up a lot of CPU time and bandwidth and disk space, implementing them now would be a waste.
In short, there's no rush to implement because there's no real threat at present. 
@_date: 2014-04-13 23:27:25
Yeah.  There's actually a proposal which has been spec'd out on the bitcoin-devel mailing list for an extension to the payment protocol which will allow the initial payment request to specify a recurring frequency (weekly, monthly, yearly).
The wallet will use that information to poll the merchant's server for a new payment request at the specified frequency, allowing for semi-automated recurring billing.  (Which is the best you can get with decentralized Bitcoin wallets.)
@_date: 2014-05-24 20:58:39
and have both linked to the new developer documentation.  Unfortunately it doesn't currently include what you're looking for right now.
However, I'm one of the writers for the project and in the next few days/week, I hope to push out a walkthrough for using the Bitcoin Core RPCs to create and broadcast several different types of transactions.  From that, you'll be able to build a basic program which uses RPCs to do all sorts of stuff.
In the future, we plan to include documentation for building applications on top of one of the SPV libraries, probably bitcoinj.  But I don't expect that for another month or two at the least.
@_date: 2014-04-11 15:00:03
Indeed! :-)
@_date: 2014-06-11 18:22:11
It now says, at least in my browser: y2 = x3 + 7 (i.e. there's no superscript for the exponents).
@_date: 2014-08-19 14:57:10
Well, except in HD wallets where SHA256 is used as part of the HMAC function to create a random parent private key which is added (mod n) to another parent private key to create a child private key.
Or in brainwallets where typically the the wallet phrase is SHA256'd into a private key (again, mod n, as some SHA256 value are greater than the max private key).  Alternative brainwallet specifications may use key stretching to make up for the fact that most people suck at choosing secure phrases.
@_date: 2014-04-21 11:47:10
On Linux, I use a symbolic link.  I don't have a Mac machine handy, but here are some rough instructions:
1. Shutdown bitcoin-qt.
2. Move the directory `$HOME/Library/Application Support/Bitcoin` to your external drive.  Copy the name of the full path (directory name plus "Bitcoin") to the new location into your clipboard.
3. Open a terminal and type `ln -s "path" "$HOME/Library/Application Support/Bitcoin"`  (replace "path" with the full path you copied, for example: `ln -s "/external-drive/Bitcoin" "$HOME/Library/Application Support/Bitcoin"`)
4. Start bitcoin-qt.  It shouldn't know the difference.
Someone with more Mac experience may be able to refine these instructions.
@_date: 2014-06-08 13:40:25
Background: most centralized pool miners mine the transactions the pool tells them to mine.  P2Pool miners each individually choose which transactions to mine.
It's possible to prove that you mined the transactions someone told you to mine.  It's impossible to prove that you choose your own transactions.
@_date: 2014-08-19 15:11:30
@_date: 2014-08-19 16:48:38
Whoops! Thanks for catching that.
@_date: 2014-04-26 20:56:46
There's an developer guide being written for Bitcoin.org which has lots of technical details.  [Here's the preview](
@_date: 2014-07-21 15:52:20
I assume you're talking about the nonce in the block header or the optional extranonce in the coinbase.  The answer is: using whatever formula each miner wants to use.  It's entirely arbitrary.
However, in practice, I suspect miners start from the lowest value and go to the highest value for the header nonce.  For the coinbase extranonce, typically mining pools and mining software make sure each miner and ASIC hashing equipment has a different range of extranonces.
(Background info: header nonces are only good for about 4 billion hashes---4 gigahashes.  Extranonces extend that so that miners can create a practically unlimited number of hashes.)
@_date: 2014-04-06 18:11:41
Merkle leaves and intermediaries are not included in the block.  The leaves are the TXIDs, which are computed on demand based on the serialized transactions.  The intermediaries are computed on demand from the leaves.  Only the 32-byte Mekle root is included in the block (in the header).
@_date: 2014-05-29 13:55:59
I always feel weird when I reply to someone with a counterargument and then someone else replies to *my* reply making an extended version of the same basic counterargument.
Am I supposed to reply, "hey, dude, I totally agree with you!" Am I supposed to play devil's advocate and argue the other person's side? Am I supposed to PM the person I was replying to, so they get notified that there's a better reply available?
It's all very confusing.
Thanks, though, for the post, @_date: 2014-08-25 13:43:06
Oh, wow.  I'd never heard that, but it makes sense.
@_date: 2014-06-11 13:46:19


That's a general elliptic curve.  The specific secp256k1 curve is y^2 = x^3 + 7.  See this article by a Bitcoin Core dev: 
@_date: 2014-05-04 22:45:36
Microsoft Word is (or at least used to be) the default word processor for most people, so maybe the joke was supposed to be:


That's as far as I'll go analyzing someone else's joke.  All I know is that it made me smile.
@_date: 2014-04-14 01:13:34
Correct: since early 2013, it is no longer possible to put a transaction with a locktime in the future on the peer-to-peer network.  This change was made to prevent denial-of-service (DOS) attacks.
Merchants can't initiate payments from their customers; they can only send customers an email or other message reminding them to pay.  In that reminder, they can tell the customer what this period's price is.
@_date: 2014-07-11 10:18:06
I think it's both sides of the equation: the electrical inputs and the waste heat output.  Line losses and distribution infrastructure costs may someday sink centralized power production as decentralized technologies like solar become more efficient.
More important, in my opinion, is the [Landauer limit]( which says there's a limit on how energy efficient mining equipment can become, so at some point hashing becomes all about pumping in energy and getting rid of waste heat.  It's much cheaper to get rid of waste heat on a small scale than a large scale---and it always will be, even if advances in power production technology favor centralization again.  (Provided the laws of thermodynamics remain true. :-)
@_date: 2014-04-14 15:21:15
We looked into this for the upcoming Bitcoin.org developer guide ([preview]( and, as far as we can tell, miners *must* claim the full available block reward.  However, they *may* claim fewer satoshis than are available from transaction fees.
@_date: 2014-07-21 14:34:23
I assume you're talking about miners hashing to find the next block.  If that's the case, there are two answers:
1. *Almost all of it is wasted:*  We've done [over one yottahash]( worth of work but only use about [310,000]( of those hashes.
2. *Almost none of it is wasted:* The security of the network is the sum of the work done on the main branch---that yottahash referred to above.  The only wasted effort is what goes into orphaned blocks.  (Currently estimated to be about 1% or less of valid blocks.)
@_date: 2014-06-27 17:15:38
Yeah.  The only hacker risks I can think of is a hack of the motherboard firmware or a virus that installs on TAILS via the USB stick.
@_date: 2014-04-13 18:39:35
I think we might be in agreement, but just to be clear: the new payment protocol doesn't make requesting repeat payment any easier than it was before.  The receiver still needs to send an email (or other message) to the spender requesting they click a `bitcoin:` URI.
Sending that email can be automated---but it could also have been automated before the new payment protocol.
What the protocol adds is authentication, which means that the spender doesn't have to worry so much about phising when they get that email.
@_date: 2014-07-17 17:12:15
Well, it might make more sense to default to the platform the user is using.  You already have the logic in there to change the display between desktop/mobile, so I wouldn't think it would be hard to default to the desktop for desktop users and mobile for mobile users.
@_date: 2014-05-22 19:46:29
This explains P2SH scripts/addresses (addresses starting with a 3): 
The dev guide doesn't yet have a section about multisig wallets (it's on the [todo list]( but this section describes multisig more generally, including some of the programming stuff: 
For what it's worth, the Bitcoin Core bitcoind sends to P2SH addresses exactly the same as one-key P2PKH addresses, so there's no extra programming required if they use it.  (But apparently they don't.)
@_date: 2014-07-24 12:56:03
Someone on  IRC frequently points out that 'solving' the 51% problem means Bitcoin would be under the control of a minority of miners.  :-)
@_date: 2014-04-14 12:20:32
My pleasure.  I agree with you, I kind of like the lack of automatic debit in bitcoin.
Although the payment protocol needs to catch on before it'll be useful, I'd actually like to see that rebilling protocol extension along with a screen in my wallet software which showed my soon-to-be-due bills and a one-click-to-pay button.  That'd give me all the security of Bitcoin and the payment protocol with almost all of the convenience of automatic debit.
@_date: 2014-06-25 13:25:13
Thanks for your work on this, Tom!  I think we really do need more high-quality and accessible information for new/wannabe users.  Three quick questions for your AMA:
1. What do you think most confuses new Bitcoin users?
2. What was the hardest thing for you to explain in this course?
3. Somewhat related to the above, what community resource did you wish existed so you could've pointed viewers to it?  In other words, what could the community have done to help you educate new/wannabe users more effectively?
@_date: 2014-04-08 02:21:26
I think your confusion arises from thinking about a block chain (lowercase) as The Block Chain (uppercase).
A block chain is a series of linked blocks, with each block containing a reference (a cryptographic hash) to the header of the block that preceded it.  This makes it impossible to modify one block without modifying all the blocks that came after it.
More than one block can link to a previous block---that's called a block chain fork because it looks kind like this:
                                /----[block 2]
    [block 0]----[block 1]-----&lt;
                                \----[block 2]----[block 3]
When a peer on the network encounters a fork, it picks one side to follow (almost always the first side it sees) unless one side is longer.  If one side is longer, it prefers it.
However, if a peer sees an invalid block, it ignores it and any blocks that follow it.  So in the crude text illustration above, the peer would usually prefer the lower chain---but if the lower chain's block  was invalid, it would use the upper chain's block 
The Block Chain is the longest[1] valid block chain.
This means that even if a network problem damaged a block in transit, the network could still recover by going back to the last-seen undamaged block.
Does that make sense?
[1] Technically, it's the hardest-to-reproduce block chain, which is usually the longest.
@_date: 2014-05-24 23:16:11
SPV is Simplified Payment Verification---it lets you monitor for transactions sent to specific public keys (addresses) without having to download the block chain.
What you want is really easy using Bitcoin Core.  You can write a shell script (or any other sort of script) which checks R using the RPC `listunspent`.  If it detects payment, you can use the RPC `sendmany` to send the payment to the two other addresses.  
After you write the program, you can run it periodically from cron or another scheduling system.
Here is the RPC section of the guide: 
@_date: 2014-04-11 15:07:50
Sounds like a plan.  Thanks for your reply!
@_date: 2014-07-01 20:25:25
Even if Trezor prices come down from 1 BTC, breaking a Trezor or (worse) losing it is probably something most people will want to avoid, so it should be a rare occasion.
If you have to use your seed on your computer, you could always do a one-time offline signing to transfer funds to your new Trezor without letting viruses upload your seed/child private keys.  You'd need two computers to do it (one to stay offline during the operation and one to do the online work), but even someone without a spare computer could always borrow a friend's/family members computer on a rare occasion like this.  (In short, a PITA---but probably worth it if you're protecting thousands of dollars worth of bitcoins with your Trezor.)
@_date: 2014-06-25 02:59:02


My (probably na√Øve) understanding of this is that the formula for mining on headers only would be:
1. Receive header; assume it's for a valid block, so start mining on it.
2. Wait up to *n* seconds.  If a full block isn't received in that time, switch back to mining on the previous block.
As long as *n* is reasonably small (but large enough to receive blocks), the benefit of tricking people into wasting their hashes is less than the cost of wasting your own hashes to create an invalid block with a valid header.
@_date: 2014-08-25 15:03:42
You can use the Payment Protocol (BIPs 70, 71, 72) for that.  The PP will let you put a CGI script at any URL that will provide a unique Bitcoin address to each person who visits that URL using a Bitcoin wallet.
That means you can use a webpage on your personal domain name (e.g. example.com/pay) as your payment address.
@_date: 2014-07-15 14:06:36
[YouTube video]( for those who don't get the allusion.
@_date: 2014-07-17 13:28:23
I thought the same thing, but then realized that we have multiple clients grouped under one icon---for example, GreenAddress is under desktop, mobile, and web.  
If all the icons were available, we'd have to select a default platform for each of the wallets on "undefined platform click", and pointed out in the pull request that wallets under one platform might have a different security story than the actual wallet for the platform the user wants to use.
@_date: 2014-04-16 14:04:08
Works for me on FF and Chrome.  Edit: I just notice that we updated; maybe you loaded in the middle of the update?
@_date: 2014-06-27 17:36:17
Yep.  The Bitcoin Core devs talked about using this to reduce the size of transactions; for a P2PKH tx, you wouldn't have to include your public key in an input scriptSig, saving up to 34 bytes (33 byte compressed key + 1 byte push).  (Although I think they also planned to add an extra byte so you could indicate which of the 4 possible pubkeys was the real one, saving up to 3 sigops.)  I  don't know how it'd work with P2SH.
(I think the proposal got put on the really-far-back-burner once dice sites started polluting the block chain.  Who wants to save a few bytes when other people are just going to waste them?)
@_date: 2014-06-26 23:00:22
Me too!  (Sorry for ranting back there.  People manually managing private keys has become a pet peeve.)
@_date: 2014-04-11 18:40:53
Speculation certainly accounts for some of the reason miners aren't profitable right now---possibly most of the reason.
However, mining bitcoins can also be used to increase financial privacy.  You use your traceable fiat to buy mining equipment, connect to the network through Tor, and mine some untraceable bitcoins.  As long as you don't tie these bitcoins to your identity when you spend them, nobody can trace how you spend you money.
Untraceable bitcoins are worth extra money to some people, such as criminals, so they may be willing to pay a premium for mining equipment.  I don't know that this is happening, but I've always wondered whether it's partially responsible for the high cost of mining.
@_date: 2014-08-19 21:16:15
All of the alerts that included a URL pointed to Bitcoin.org.  See the list at: 
However, Theymos also co-controls the DNS for Bitcoin.org.  (This is just an FYI; I have no problem with Theymos having a copy of the alert key.)
@_date: 2014-07-04 14:34:05
The 32GB SD card is to hold the block chain for your algorithm (the RPi doesn't come with any built-in storage).
You can use drive storage instead of memory for the UTXO set, but you take a performance hit if you run a full node, which makes DOS attacks easier.  That's a specific case of a general problem here: you can run marginal hardware for mining in a pool because the requirements are highly predictable, but you need hardware above the margin for running a full node because the requirements occasionally rise.
More importantly, even if the current delta was $0, you still haven't made running a full node necessary and you haven't made centralized pooling any harder.  Many pools today take 0% fees, making me think that they earn income outside of direct mining.  If the outside income is high enough, they can offer "negative fees" (bonuses) that move the delta back the wrong way.
Bitcoin relies on honest miners and it already provides economic incentives to keep them honest.  If miners aren't afraid of their equipment becoming unprofitable after a price drop created by a massive double spend from a centralized pool, then a small additional incentive seems unlikely to have any effect.  This is not negativism from me---I've spent the last three weeks at [Mike Hearn's instigation]( writing a mining guide for Bitcoin.org.  I'm not sure better documentation is the answer either (and I said so in the discussion), but it seems to me that we might have a problem with education rather than with incentives.
Now it's a holiday in my locale, so I'm going to put away Reddit and join the party.  It's been nice discussing this with you!
@_date: 2014-04-28 00:43:38
There's nothing "provable" about the system described.  It's a centralized service which accepts bitcoins and then forwards them to other people based on pre-configured rules.  If the service wants to, it can steal its users' bitcoins.
@_date: 2014-07-17 13:34:15
I've always wondered about this line of argumentation.  If users are turned off by managing their own security, then why should they be using Bitcoin at all?  After all, there are plenty of non-Bitcoin centralized financial products that work well.
@_date: 2014-06-09 14:01:27
OP: we'd love to have you help write more docs.  We'll be adding an example page in the next few days with developer-oriented examples.  See 
@_date: 2014-06-27 00:01:10
I'm pretty minimal myself---I often spend a month or more living out of a single backpack---but it seems like our cases might be reversed.  I have an extra computer lying around whereas you don't, but I'm guessing you have a printer lying around whereas I don't.
Perhaps this is mystery solved why you're a paper wallet guy and I'm a software wallet guy. :-)
@_date: 2014-06-27 17:44:34
Being part of a large pool is not unethical---it's merely irresponsible.
@_date: 2014-04-11 14:59:11
Ok.  I'm not a lawyer, but I still suspect that a hard-to-remove fee (for a non-coder) creates an implied contract between the user and you.  My question is about that contract, not how mandatory the fee is.
@_date: 2014-04-14 15:54:12


What prevents a miner from using separate attempts individually below 50% but collectively greater than it?
@_date: 2014-04-14 14:11:46
Several other people have mentioned the anti-DOS benefits---but transaction fees are just as (if not more) effective at preventing DOSes.
The other benefit to age prioritization is that it gets transactions unstuck.  If you send a transaction with an insufficient fee, it will potentially never make it into a block.  With network double-spend protection, you can't easily revise the transaction to add a larger fee, so it can stay stuck forever.
But with 50 KB of "free" transactions in each block (by default), your input will eventually grow old enough to get unstuck.
@_date: 2014-08-10 01:47:37
Alas, when I last checked the Trezor docs, it did not support importing a seed---it could only generate its own seed and give you the mnemonic backup.
@_date: 2014-04-11 14:50:53
Does auto-creating micropayments create a legal obligation which could come back to bite you?
As I understand it[1], accepting altruistic donations (as you do now) does not create any contract between the payer and the receiver.  However, charging a mandatory fee[2] does create an implied contract, weakening or destroying the without-warranty provision of the MIT license Multibit uses.
Are you worried about lawsuits asking you to pay for bugs or UX issues which resulted in lost bitcoins?
[1] Based on U.S. contract law, which itself is based on English common law.
[2] If you get sued, the plantiff will surely argue that editing source code to remove the fee was too much of a burden, making the fees essentially mandatory.
@_date: 2014-04-14 00:50:48
You can't put time locked payments on the block chain---the block chain is only for finalized payments.  (I think you meant to say network, although the network no longer stores time locked payments.  See the dev guide [locktime section](
However, I think I get your meaning, although what you're describing is advanced payments (with time release) not recurring payments.  Advanced payments are not very useful with the exchange rate being so volatile---if I created a payment schedule a month ago, I'd be overpaying today; if I created it a year ago, I'd be underpaying.
@_date: 2014-06-04 20:57:13
Huh?  How can they create a locktime transaction signed by your private key?  If they could do that, they could steal your bitcoins at will.
@_date: 2014-06-04 19:37:47
Their website say they provide signed transactions for backup using locktime, so if you use their backup solution, all you have to do is wait for the locktime to expire to get back 100%.
@_date: 2014-05-14 12:39:52
Whoops.  I'll submit a patch today.  (Off-by-one errors in plain text... who woulda thought? :-) Thanks!
Update: [fixed in pull request   Thanks, @_date: 2014-07-04 12:58:51
Blocks can be "validated" with nothing but SHA256 hashes if the pool gives miners the block header hashes it trusts.  This is much cheaper than validating CPU-expensive ECDSA signatures and checking each input against the memory-expensive UTXO set.  Miners could then get their blocks from the network without giving anything back---or, if the network was changed to prevent this abuse, they could start their own BitTorrent-like block-distribution P2P protocol.  (Maybe called "BlockTorrent")
Anyway, my intention in the original reply was to correct when he said your solution made full nodes required when mining.  We're in agreement that it doesn't; what's debatable is whether lowering the altruism delta from $100 (the cost of a used laptop on eBay to run bitcoind/P2Pool/bfgminer) to, say, $50 (the cost of a Raspberry Pi and a 32GB SD card to use with "BlockTorrent") would significantly increase full node mining.
@_date: 2014-08-16 13:22:13
I second that.  Git Annex is an awesome backup tool.  With GA Assistant, it's remarkably easy to use.
@_date: 2014-05-22 19:40:56
To be clear, you provided them with an address starting with a 3 (a P2SH address) and they refused to support it?
@_date: 2014-04-21 19:17:39
There are two different types of cryptographic math used by Bitcoin: one is public-key (PK) cryptography; one is hashing.
In PK, the private key and the public key have a mathematical relationship, such as the relationship between a number (n) and its square (n^2).  It's easy to go in one direction; it's harder to go in the other direction without a good calculator.
In hashing, the input is transformed in a one-way process to create an output, such as taking a positive number ([n])and multiplying it by itself until you get over 100, then dividing it by some other number until you get below 50.  (This will always give you a result below 50, but you'll have no way to determine what the original input was.)
The power of quantum computers is that they can do non-binary math.  That makes them really good calculators, so the PK used by Bitcoin (ECDSA) offers a lot less security than it does in a world with only binary and trinary computers.  On the other hand, the hashing formula Bitcoin uses was designed for binary computers, so a quantum computer would have to do it using binary operations---which means the quantum computer wouldn't be any faster than an equivalent-speed binary computer.
The first 10 generations (at least) of quantum computers are probably going to slower in Hz (operations per second) than an old beat-up laptop, so they won't have any effect on hash-based Bitcoin mining.
@_date: 2014-07-18 15:18:52
I think point is that joining *someone else's* P2Pool node isn't decentralizing anything---it's only changing where that centralization is happening.
Also, personal attacks ain't cool, even if you got your facts straight.  (You mean coinbases, not block headers, and I think Eligius stopped that.)
@_date: 2014-02-23 00:09:37
I'm not sure I understand.  Why would I deposit money in this network and let someone else decide where to lend it instead of just reading applications and lending it out myself?
@_date: 2014-07-21 18:50:54
Aaron Vosine (spelling?) recently said on the bitcoin-development mailing list that his wallet, BreadWallet, used deterministic signatures.
@_date: 2015-05-29 13:13:35
Dust-level rounding does sound like a nice feature to me, but until you opened my mind to that possibility, it sounded like a loss to me.
In addition, he reported an issue where an apparently failed send resulted in the inability to spend those funds in the future from within the app combined with an incorrect balance, a situation that looks like a loss.  (And which would be a loss for anyone who doesn't restore from backup.)  And those are just two of the five specific examples of problems he reported, so I'll stand by my statement of not recommending GreenBits for general use.
In regards to not replying, could you at least acknowledge the report on GitHub?  In his report Craig wrote, "suggesting a (serious?) bug in the fee code?"  When somebody doesn't reply for 1.5 months to the suspicion of a serious bug, what are we supposed to think?  Maybe more importantly, what are we supposed to think about proper bug reporting when private emails and GitHub issues go without a reply for 45 days but Reddit comments get a reply in 17 minutes?
Anyway, I will amend my post above so that it is less inflammatory since you have provided a plausible explanation for the high fees.
@_date: 2014-05-16 17:51:09
Great article!  For those who are interested, more information about transactions can be found in the [Transactions section]( of the [soon-to-be-published]( Bitcoin.org developer guide preview.
@_date: 2014-07-21 14:24:34
When you sweep a wallet, you enter the private key into some sort of wallet software.  If this wallet software stores that private key, it can *at any time* steal any additional funds you send to the corresponding address.
If you know for sure that the wallet doesn't store the private key, you can use it multiple times.  (Not that I encourage address reuse.)  But many people use some web wallet or other service which they can't audit---so reusing the paper wallet is an unsafe idea.
@_date: 2014-08-17 23:47:55
My cold storage netbook runs Debian Stable.  It was primarily installed over the network but has not been on the network since the end of the install.  I use Electrum (an old version on the netbook; a recent version on my regular computer.)  I copy transactions from my regular computer to the netbook and back using a USB keychain drive.
I only own about two weeks income total in bitcoins, so I don't obsess over their security.  For example, the laptop's drive isn't encrypted and I don't keep the laptop itself in a safe.  (However, the wallet seed/private keys are encrypted, so a thief couldn't just steal the laptop to get the bitcoins---he'd have to install a keylogger or find one of my well-hidden paper seed backups.)
The other thing I do, which you don't see mentioned often, is write down partial addresses from the receiving addresses list.  This way, if my main computer gets hacked to display the hacker's receiving addresses in my watching-only wallet, I will know something's amiss.  (Does the Trezor display receiving addresses?  That could be a nice advantage over my more laborious method.) 
For me, the main advantage of having cold storage is knowing that I could receive a large number of bitcoins at any moment without any unwanted security risk.  For example, if one of my clients decided to pay a multi-thousand-dollar invoice in bitcoins, it would take me only about a minute to give him a cross-checked address from my watching-only wallet.
@_date: 2014-04-28 19:19:30
Label is the label you give to the spender/receiver.  For example, "Bitcoin Foundation" or "John Doe, Landlord".
Message is a note about this particular payment.  For example, "donation" or "May 2014 rent".
@_date: 2014-05-29 03:19:13
I believe he said that he wanted to allow users of his bitcoinj library, which are mostly SPV clients, to connect through TOR.  This makes several cheap attacks against SPV clients more difficult.
He further wanted to strengthen security for SPV clients by letting them get data only from full nodes operated by owners of government-issued passports, ensuring that they weren't being tricked into connecting to multiple nodes operated by the same attacker.  The owners of the passports wouldn't have to reveal any of their personal information, except maybe the country which issued the passport.  Nobody operating a full node or using an SPV client would be forced to use the system, but it could make attacks much more difficult.
I'm not a big fan of basing even limited network trust on government-issued identities, but I am happy that Mike is trying to find solutions to Bitcoin's future challenges.
@_date: 2015-05-26 17:01:48
Agreed.  I pointed it out because I considered it likely that commit was what thought he saw.
I do think that we're all waiting on a concrete proposal, whether it be a BIP, a pull request, or both (like [BIP65](
@_date: 2015-05-26 17:07:42
If you don't think a non-obligatory BIP can gain consensus, then that implies that you don't think an obligatory-if-merged Bitcoin Core pull request can gain consensus---so what is your long-term plan here? 
@_date: 2014-06-27 12:29:23
TAILS has the option to use encrypted persistent storage which can be on the same USB stick you use to boot TAILS, so I keep a copy of Electrum on there with what I call my "cool" wallet.  (It's not the same seed as my real cold wallet.)  So, to spend bitcoins, the workflow looks like this.
1. On my main laptop operating system (OS), create the unsigned spend and save it to a USB stick.  (Not the same stick I use for TAILS---TAILS should never touch the computer when it's in the main OS in case the main OS gets infected.)
2. Safely remove the USB stick and put the laptop into hibernate.  (I use Linux where it's called suspend-to-disk.)  This takes about 30 seconds.
3. Toggle the physical switch on my laptop which turns off wifi.  (This isn't really required---TAILS defaults to no networking---but it doesn't cost me anything extra, so I do it anyway.)  Insert the TAILS USB drive and press the power-on button.  It takes about a minute for TAILS to boot to the login screen.
4. Choose the option on the login screen to load the persistent storage and enter my passphrase fro the encryption.  It takes another 15 seconds to load the desktop.
5. Start Electrum.  This required a bit of extra installation the first time to get it to start from the persistent storage.  All you have to do is run Electrum the first time, close it down, and then copy the $HOME/.electrum directory into the persistent storage directory.  For details, see the TAILS wiki.
6. Insert the USB stick with the unsigned transaction. In Electrum, do the regular stuff to sign an offline transaction and save the signed transaction back to the other USB stick.  Close Electrum and shutdown TAILS, which takes another minute.
7. Remove both the TAILS and other USB sticks.  Toggle the physical wifi switch back on and boot the computer.  It restores from hibernate in about 45 seconds, giving me my desktop exactly as it was before.
8. Insert the USB stick with the signed-transaction, open the transaction in Electrum, and then broadcast it.  All done.
The whole process takes a bit over 5 minutes, so it's mildly annoying but not too bad.
You could probably use any live operating system which allows encrypted persistent storage, but I like having a copy of TAILS with me anyway.
Hope that helps!
@_date: 2014-04-08 02:06:18
Note, the first block is block 0.  However, an off-by-one error in the Bitcoin Core code makes those 50 bitcoins currently unspendable, so the first spendable bitcoins are in block 1.
@_date: 2014-04-07 20:31:13
You're limited to 16 because you need to use one of the op codes which push a number of the stack which go from OP_1 to OP_16.  You could use one of the other op pushdata codes to push a higher number to the stack if you needed to.
However you're really limited right now to 9 because, if I recall correctly, the current implementation of OP_CHECKMULTISIG only supports up to 9 signature comparisons.
The problem is CHECKMULTISIG's naive implementation, which requires up to `n*n` signature check operations to check `n` signatures.  That's 9 checks for 3-of-3 multisig, 81 for 9-of-9 multisig, and 256 for 16-of-16.
Even worse than this is this is that, to prevent DOS attacks, script gets pre-parsed to count the maximum possible signature operations (sigops), because sigops are relatively expensive in CPU time.  That means we assume any OP_CHECKMULTISIG we see uses the maximum number of sigops currently allowed.
There's currently a hard limit (requiring a hard fork to change) of 20,000 sigops in a block, so if we allowed 16-of-16 multisg, we could never have more 78 OP_CHECKMULTISIG transactions in a block---even if they were 2-of-2.
Right now, up to 3-of-3 has been special cased to only use 9 sigops; if you use more than that (up to 9-of-9), it's non-standard but allowed, but you'll use 81 sigops.
@_date: 2015-05-26 16:41:26
It was a commit on his GitHub repo for Bitcoin Core: 
@_date: 2014-06-27 15:30:56


Huh?  Bitcoin has no defense against unethical miners ... except for ethical miners.  It is impossible to build a Bitcoin-like system which does not rely on the honesty of the majority of miners.
@_date: 2014-04-11 03:11:06
Android Bitcoin Wallet is a Simplified Payment Verification (SPV) Bitcoin client.  Satoshi specifically designed block headers to make SPV clients possible.  Here's how it works:
Each block of transactions, which can be up to 1 megabyte (under current rules), has an 80-byte header.  The whole block chain (220,000ish blocks) worth of headers up until this point is less than 20 megabytes. Your SPV client downloads those 20 megabytes.
In each header is a single 20-byte hash, called the Merkle root, which is formed by cryptographically hashing each transaction in that block, pairing the hashes and hashing them together, then pairing those hashes and hashing them together, and so on until you get just one hash (the Merkle root).  It looks something like this:
           ABCDEEEE .......Merkle root
          /        \
       ABCD        EEEE
      /    \      /
     AB    CD    EE .......E is paired with itself
    /  \  /  \  /
    A  B  C  D  E .........Transactions
From that Merkle root, your SPV client can quickly prove that a particular transaction was included in a block.  For example, if you want to transaction D was in the block, all you need is a copy of the 20-byte hash of transaction C, 20-byte hash AB, 20-byte hash EEEE, and the Merkle root you got from the 80-byte header---that's a meager 140 bytes, even though a block with five max-sized transactions would be over 500,000 bytes.
So, now, when you want to check your balance, your SPV client selects an address and sends a request to the peer-to-peer network saying, "what transactions in what blocks affect the balance of [this address]?"
The network replies with a list of transactions and block numbers.  You don't trust the network's response---it could lie to you---so you also ask the network for the hashes of the related transactions so you can verify each transaction was used to build a Merkle root which appears in the block header.  This proves to your client that each transaction actually does appear on the block chain, giving you excellent security even though you're using the peer-to-peer network directly.
In summary: the service you're using is the main Bitcoin network.
@_date: 2014-04-22 02:56:30
Your Bitcoin wallet makes it look like transactions are sent to addresses, but they aren't really.  Instead each payment (output) spends a previous payment (the input).  The address (script hash in P2SH) contains part of the information necessary to allow the input to be spent---the other part of that information is the signature.
When the executives want to spend some of the money received, they look at the block chain and get a list of transaction identifiers (txids) and output index numbers (sometimes called vouts) for the transactions they received.  Then they put each of these txids and vouts into the input section of a transaction which they sign along with the output section of the transaction which indicates where the payment is going.
The signed input txids are hashes indistinguishable from random data, so there's no real chance of anyone being able to reuse that signature for a different transaction.
@_date: 2014-08-16 14:58:08
I'm not sure why that's ironic, but I am sure that isn't true.  AFAICT, Wladimir is the core team's biggest alt-implementation cheerleader, and I've also seen Pieter (sipa) and Greg go out of their way to communicate with the btcd developers.  Mike is, of course, the lead developer of BitcoinJ which can be used as a full-node implementation, although almost nobody uses it that way.  Oh, and I don't know what Jeff's opinion is, but he does work for BitPay which has their own alpha-quality implementation.
I have a hard time seeing any hostility here, except Genjix's typical core-dev bashing.
I suspect miners will remain on Bitcoin Core for a while to come because of its strong network effects (nobody wants to have a block orphaned because of a bug) but that businesses and users who want full node validation will lead the way in using alternative implementations.
@_date: 2014-04-09 18:40:42
I don't think that's possible to the degree necessary.  If it was possible for a business in the established money transmitter system to reduce it's fees to parity with Bitcoin---that's a hundredfold drop or more---some business would've done it already for the massive competitive advantage it would give them over other established businesses.
@_date: 2014-05-13 17:24:11
Darkwallet doesn't use m-of-n multisig scripts for coinjoin, it uses multiple inputs.  There's a [description of coinjoin]( in the preview of the [soon-to-be-published]( Bitcoin.org developer guide.
@_date: 2015-05-04 01:13:13
Thank you for writing this up.  Until now, I had never read a retrospective on the BIP16/17 debate, and it hadn't occurred to me that the poorer solution might have been selected.
@_date: 2014-04-14 02:12:51
It's not a "automatically renewed subscription payment" either, which is what the OP requested.
Also, locktime does still work---I never said it didn't.  You just can't broadcast it to the network until the locktime is in the past.  Here's a [thread]( where I show someone how to make a time locked transaction and they show the error they get from trying to broadcast it ahead of time.
@_date: 2014-06-25 03:20:30
Maybe, but (off the top of my head), it seems like you'd need to have &gt;40% of the network hash rate to pull off an attack for small values of *n*, and people with that much hash rate can already do nasty things pretty easily.
I'm not sure how it makes a difference what information a losing miner doesn't forward---whether its block contents in the future or a whole block today.  It seems to me that's why we connect to multiple peers by default---to route around that kind of damage.
(As I understand it, right now block forwarding is basically a gentleman's agreement because everyone runs the same forwarding code without modification.  However, if someone started consistently withholding information as part of an attack, it should be possible to write new code to detect their poor performance versus honest peers and disconnect/blacklist them.  This would make it so that their own blocks propagate poorly, encouraging them to return to honest mining.)
@_date: 2015-05-30 19:18:47
Six months, per [policy]( "The codebase and final releases must be public since at least 6 months and previous commits must remain unchanged."
Trezor has been on the site for six months now---so they would usually qualify---but four months ago [Trezor changed previous commits]( so we won't remove the new app warning until 1 August 2015.
@_date: 2015-05-05 19:03:11
Now I'm confused.  In my head, "winter 2015" starts in December 2015, and "winter 2016" starts in December 2016.  I thought you were predicting problems in late 2015 or early 2016, but now I'm not so sure.  Also, half the world (by geography) has different start months for winter, so they might be even more confused.
I suggest using less ambiguous dating.
@_date: 2015-05-10 20:42:40
That was great.
@_date: 2014-07-11 17:02:18
That sounds cool, although you either have to run a fine balancing act or have an additional source of heat.  Otherwise, on a hot day, you could generate more heat than you can get rid of, forcing you to shut off your miners (which is very expensive with difficulty increasing by 5-40% per 2,016 blocks).  (Air conditioning for the mining equipment would be even less effective---every watt of waste heat requires about 0.67 watts to remove with a heat pump.)
@_date: 2014-04-20 14:15:48
It isn't finished yet, but there's an 80-page (so far) developer guide being written for Bitcoin.org.  Here's [the preview](
@_date: 2016-03-12 23:57:11
Every 2,016th block, full nodes look at the previous 2,015 blocks[1] to see if the difficulty should be increased to keep the average time between blocks at approximately 10 minutes.  If those 2,015 blocks were produced in less than the time you would expect 2,016 blocks to be produced (about 2 weeks), then the difficulty is increased.  If it took more time, the difficulty would normally be decreased---with one exception, if the difficulty is already at 1, then it can't be decreased any further.
For almost the entire first year of Bitcoin, it took longer than two weeks to produce each set of 2,016 blocks, so the difficulty stayed at 1.
[1] They should have looked at the previous 2,016 blocks but there's a programming error.
@_date: 2016-03-30 14:09:19
I kinda thought the name implied the slogan:


@_date: 2016-03-14 21:35:01


If their wallet software knew about payment channels, their payment information could include both the details necessary for you to pay over Lightning plus the details to pay directly.  However, there's no real way for you to use a current-style P2PKH or P2SH address to open a Lightning-style bi-directional hash-timelocked (HTL) channel with them, so you would have to figure out a way to contact them directly to ask them to use a channel.
@_date: 2016-03-13 19:07:00
Transcript of D'Angelo's opening statement for those who want to get an idea of his thesis:




















































That's as far as I listened; I suspected that most of the rest of the podcast was him defending that thesis against the hosts' criticism.  I don't think I'm going to bother to listen to all that.
@_date: 2014-07-15 14:01:08
The first result which appears for me when searching for "bitcoin" on Google is [Bitcoin.org]( which has commits through GitHub from [dozens of people](
Anyone who wants to volunteer to help can check out the [about us page.]( or send me a PM.
@_date: 2014-04-18 15:48:31
Another work in progress, this one more technical, is the Bitcoin.org developer guide.  ([Preview site](
@_date: 2016-03-12 02:10:35


I am not aware of any plans to remove the discount but removing it would only require a soft fork, so it's something miners could do at any time.
@_date: 2016-03-02 04:47:17
The [ZKCP wiki article]( mentions getting passwords from salted hashes.  To go into more detail, Mallory has broken into a server somewhere and retrieved the salted hash of the password for $HIGH_VALUE_USER along with the salt.  He would really like to get the origin password knowing that $HIGH_VALUE_USER has probably used it on other sites.
Since Mallory is a small time hacker, he doesn't have highly tuned password crackers running on optimized hardware, so he wants to outsource the actual brute forcing of the origin password.
Mallory goes to some website and posts the hash, the salt, and the amount he's willing to pay.  Alice finds the origin password, so she posts the redeemScipt to pay and the proving key.  Mallory validates the proof, pays, and gets the origin password without ever having to trust Alice.  ('No honor among thieves' means Mallory lives a pretty miserable life of not being able to trust other people.)
I think this is a pretty good example because creating a zkSNARK for the common hash algorithms should be both easy and the code should run fairly fast, so it's something that's practical now.
@_date: 2016-03-25 12:47:38
It also supports multisig from the GUI app using the Bitpay Copay API and can do multisig with other clients at the command line according to Jonas 
Using multisig with a hardware wallet is something you probably want to consider as there's no good way for you to verify that the wallet isn't programmed to leak your keys at some point, so requiring a signature from another wallet can improve your security.  (I'm not accusing any hardware wallet manufacturer of this; I'm just saying that the difficulty of auditing hardware adds a risk factor.)
I personally have been looking for a hardware wallet that would work with Bitcoin Core (command-line use being fine) and have been disapointed that Trezor doesn't seem to offer any facility for this without me needing to do a bunch of programming.  I'm excited that the Bitbox's CLI should make this possible.
@_date: 2015-05-29 13:51:27
Thank you for replying.  Also, I think GreenBits is an exciting advance in lightweight wallet technology, and I'm glad that you continue to improve it.  I look forward to the day that we list it on Bitcoin.org.
@_date: 2015-05-18 13:57:53
Actually, I think it's because Satoshi's commits are credited to  e.g. 
I think that's a bug with GitHub.  I guess maybe we could use the contributor aliases to fix it?
@_date: 2016-03-07 23:49:09


It was not my intent to claim that; I apologize for the confusion.  I meant public as in data that is not private/secret.  I agree that the blockchain is not owned by anyone but is a shared resource.


There is no top here to make a top-down decision.  Bitcoin's consensus rules are enforced (or not) by the people who accept bitcoins, each of those people acting as an individual.  If you decide to accept bitcoins from a chain that contains &gt;1MB blocks, that is your right.  If I you want to pay me with those coins but I refuse to accept them because I only accept coins from chains with \&lt;=1MB blocks, that is my right.  No developer gets a say in what you or I choose.
However I and others in this community have warned that if large numbers of people disagree about which bitcoins they accept, as in the example above, Bitcoin is much less useful as a payment system and everyone will likely be harmed by the reduction in its usefulness and value.  For more background, you may want to read my piece about Bitcoin Harmony and Discord: 
@_date: 2014-06-27 13:32:11
Er, we should make competition useless?
It seems to me that if people can pay extra for fast confirmations, they can also pay extra for other things they might want---like mining decentralization.  I haven't looked at how this patch works, but wouldn't something like what's described allow, say, P2Pool miners to prioritize transactions with one or more outputs that pay addresses on the sharechain?
@_date: 2016-03-08 21:19:37
I think this is useful background information: 
Note that the quote in the comment you're replying to was written by me to explain what the developers were talking about (actual quotes from the developers preceded it in the summary), not something that was actually said during the meeting.  As such, I may have misunderstood what the developers were talking about and bungled it.  (The meeting summary has my full disclaimer at the bottom.)
@_date: 2016-03-07 19:44:39


Hi Nic.  I'm Dave Harding, co-author of the Bitcoin.org developer documentation.






As is frequently mentioned in discussions regarding the block size,
demand for space in a highly secure public ledger is effectively unlimited but
the ability of the network to safely handle additions to that ledger is
highly limited.  For as long as this is true, and I believe it's
fundamental given the current state of not just technology by physical
theory, there will always be more demand for space in block than there
is available block space.
I think all significant Bitcoin developers share this opinion, whatever
their position on the block size debate. For example, Gavin Andresen may
believe larger blocks are safe today but only because "miners won't
create blocks larger than they can handle".
If it is the case that demand exceeds supply, then we will always have
to deal with a fee market.  I believe software can do an excellent job
of managing fees on behalf of its users and that expecting wallet
authors to write and implement fee-managing algorithms is not the same
as passing the buck along to end users.  (But if we absolutely had to do that to keep Bitcoin decentralized, that would be an acceptable tradeoff.)
The Bitcoin Core developers have worked hard to make mananging fees
easy. Gavin Andresen and Alex Morcos have put a lot of time into getting
bitcoind to provide reasonable fee estimates. Peter Todd worked for
years getting the network to accept replace-by-fee transactions that
allow updating of fees, with an estimated 20% of network nodes now
relaying BIP125 opt-in replacements.  Gregory Maxwell has described a
simple scheme that allows wallets to pre-sign replacements that can be
deployed at certain block heights using locktime, so wallets such as
yours which don't have access to user keys can still make replacements
on behalf of your users when mempool fee rates change.  In other words,
this is not the dire end-of-the-line situation Mike Hearn portrayed but a problem for which the technical
solutions are already mostly available.








I've helped users in the  IRC chatroom and elsewhere, although
nowhere near as much as several other members of that chatroom (which
includes Bitcoin Core developers).  I also helped write [BIP125]( and
edited the [opt-in RBF FAQ]( on the Bitcoin Core website in part because I
think people should be able to use RBF to increase their fees when they
think their transactions are stuck.  I don't think that qualifies as
sitting on the sidelines.






Thank you for the offer. I think in these contentious days it's more
important than ever to validate every transaction I receive with my own
personal full node. In addition, I don't know of any software in this
space that has had its security more rigorously tested than Bitcoin Core
-- and I strongly desire to keep my bitcoins secure -- so I choose to
use Bitcoin Core wallet to store all of my bitcoins (with separate wallets
on separate devices for cold and hot storage).




Bitcoin has many potential value propositions. The value proposition of
"unlimited free transactions" is not compatible with the value
proposition of "decentralized and (almost) trustless currency", so we
must choose one of them.  I choose decentralized currency.
@_date: 2015-05-29 12:02:35
I don't know of any wallet thefts, but Bitcoin.org's wallet reviewer Craig Watkins [reported multiple problems]( including two that looked like losses, due to undocumented behavior.  Thankfully, he was only using small amounts of bitcoin.
He attempted to report these privately to GreenAddress, and they didn't respond.  He reported them publicly on GA.it's Bitcoin.org pull request over a month ago, and they haven't responded.
At this time, I would not recommend GreenBits.  (Of course, I wouldn't recommend Blockchain.info either.)
@_date: 2016-03-28 17:01:26
They're not technological rivals (innovations can be ported in either direction) but they are economic rivals (a unit of wealth can be stored either as bitcoins or ethers but not both at the same time).
If the Ethereum developers had decided not to compete with Bitcoin economically, I'm sure discussion of their project would be more welcome here---just as Rootstock discussion is welcome here.  There are other subreddits for general cryptocurrency discussion; keeping this sub focused on its namesake topic seems sensible to me.
@_date: 2016-03-16 20:15:06
Just to clarify, do you mean [Bitcoin Core]( or [Bitpay Bitcore](
@_date: 2017-02-07 21:54:23


@_date: 2014-04-16 13:14:20
We have a section on that in the upcoming Bitcoin.org developer guide ([preview of that section](
@_date: 2016-03-09 02:02:59
That's a very good question, but it doesn't seem to me like it's directly related to the proposed feefilter P2P protocol message.  Currently if a node receives a transaction whose fee is below that node's configurable minimum relay fee, the node simply doesn't add the transaction to its memory pool; after feefilter is implemented, the transmitting node won't send the transaction to the receiving node in the first place, so the ultimate effect is the same in both cases: the receiving node doesn't add the transaction to its memory pool.
Regarding CPFP: the parent transaction will still have to pay a high enough fee to ensure it gets added to memory pools.  Only then can a child transaction be created that pays extra fee to cover the confirmation of both.
Although this may sound like a problem, it probably isn't.  There are two usual ways customers notify their merchants that they paid:
1. By broadcasting a transaction to the P2P network and waiting for it to propagate until it reaches the merchant's wallet.  This is used for most payments made to a P2PKH or P2SH address
2. Giving the transaction directly to the merchant (for example using the BIP70 payment protocol) 
For the first method, if nodes reject the parent transaction, it won't propagate and the merchant will never hear about it.  If the merchant doesn't know about the transaction, it can't create a child payment any way.
For the second method, the merchant will be able to instantly discover that it pays too low a fee and reject it, preventing it from being sent to the network at all.
In both cases, if nodes reject the parent transaction or don't hear about it in the first place, then it can be recreated with a higher fee.  Opt-In Replace By Fee (RBF) isn't even needed for this because nothing is being replaced (the original was rejected) so it works perfectly right now.  (The only complication is that some user wallets won't let you recreate a transaction that spends the same inputs; that's annoying.)
@_date: 2017-03-08 20:25:51
I understand, but only the original version of the torrent would have a verifiable file signed by the lead Bitcoin Core maintainer, unless he's in on the attack or his private key has been compromised.
@_date: 2016-03-07 16:22:22


This seems highly fallacious.  Transactions that paid higher fees did confirm faster than transactions that paid lower fees.  Higher fees did not create the backlog; the backlog encouraged people with dynamic-fee wallets to pay higher fees.  I can understand why the author of the article may not understand these distinctions given the poor state of his company's software -- when you're Blockchain.info, everything looks like an erroneous chart.


This seems like a ridiculous position.  On August 15th 2010 a transaction was confirmed that created over 184 billion new bitcoins.  This was an attack, and Nakamoto implemented a retroactive soft fork to remove that transaction from history.
On July 29th of that same year, someone created a confirmed transaction with an excessive number of signature operations, earning it CVE-2010-5138.  That was an attack, and Nakamoto introduced a limit on the number of signature operations that could be performed in a block[1], basing that maximum number on a new constant he introduced: `MAX_BLOCK_SIZE`.
In November 2010, someone created a coinbase transaction with the same transaction identifier (txid) as a previous coinbase transaction.  This wasn't an attack, but it proved an attack was possible (the attack could've affected more than just coinbase transactions).  The Bitcoin Core developers introduced BIP30 and (a bit later) BIP34 in 2012 to prevent such duplicate txids in the future.
I could go on, but these seem like pretty definitive cases where it's not just acceptable but good for people to decide what transactions are acceptable.
[1] The method used for counting sigops has problems.


They decided, as individuals, that large blocks are unsafe at this moment.  This seems equivalent to Nakamoto's decision in 2010 that large blocks were unsafe at that moment.  In neither case was this centralized planning in the normal sense of that phrase because it is not enforced by violence or threat of violence, the way governments enforce their centralized planning.


If Nakamoto (or someone else) had not limited the block size in 2010, it's possible there would be no bitcoin community or economy today.  Recall from above that the `MAX_BLOCK_SIZE` constant was introduced as part of a change that (partially) addressed an actual DoS attack, CVE-2010-5138.
The author of this post is CEO of one of the historically buggiest and most insecure wallets still operating, so I can understand that he probably doesn't place high priority on stability and security -- but hopefully he can understand why that's important to other people.
@_date: 2016-03-17 02:17:43
Just to extend this a bit, segwit activation happens a retarget period (2,016 blocks; about two weeks) after the 95% threshold has been met as measured by 95% of the blocks in the previous retarget period indicating readiness for segwit.  That's because segwit will use the newer BIP9 versionbits soft fork triggering mechanism rather than the older IsSuperMajority mechanism.
@_date: 2016-01-01 11:57:07
In case you want to save yourself some typing next time, I think we have a good write up of this here: 
Edit: it's much more condensed and skips a lot of the theory you provided, though.
@_date: 2017-03-13 16:42:19
Bitcoin's difficulty rules say that every 2,016 blocks, the proof-of-work (PoW) difficulty can decrease by 3/4ths. Currently that difficulty is 460,769,358,091.  At the next difficulty change, it could go as low as 115,192,339,522 and your node would accept blocks made at that difficulty.  If it kept decreasing by 3/4ths each change, it could get back down to less than 1/100th of current difficulty in just 7 difficulty changes, which would require about 56 weeks of real time to pass.
That means that if your node is offline for 56 weeks and, when you reconnect to the network you aren't connected to an honest node, an attacker with miner support can feed you an alternative block chain that looks like the best to your node.  They can do that in any case, but by lowering the difficulty as they generate the alternative chain, they can do it much cheaper.
@_date: 2016-03-08 22:03:09
If I understood the developers correctly, the concern is over a &lt;5% miner getting lucky and preventing a 'legitimate' enforcement from taking place.
I think the main point is that a 1,000-block sliding window is different than a 2,016-block non-overlapping window, and so even though the measured 95% threshold remains the same in percentage terms, the likelihood of a fork activation given the same real rate of miners signalling readiness is different.
It would be nice if someone could run a nice big monte carlo simulating this so that we can see the difference.  That said, I believe by the time the BIP65 (CHECKLOCKTIMEVERIFY) soft fork was ready for enforcement, over 99% of the last 1,000 blocks were signalling readiness; future versionbit soft forks that are that far over the threshold should have have no problem getting enforced.
@_date: 2017-03-13 18:07:14
I don't know of any; sorry.  Seeing this discussed in the meeting was the first time I'd heard about it, and I could very easily be wrong about the motivation.
Maybe the way to approach it is to realize that the current difficulty of 460 billion is 460 billion times higher than the minimum difficulty, so we can probably quite safely raise the minimum difficulty without having any practical effect on mining today.
By raising that minimum difficulty, we prevent nodes from accepting chains with ridiculously-low amounts of PoW compared to current standards.  This is good because one thing we can't guarantee is that a node will connect to another honest node, so if your node does connect to a dishonest node we want to make that dishonest node expend as much effort (PoW) as possible before it can trick you.
Raising the minimum difficult from 1 (current minimum) to say 4 billion (~1/100th of current difficulty) increases the minimum amount of work the dishonest node will need to do to trick you by a factor of 4 billion, which may reduce their expected profits in attacking you by enough to ensure they don't even try to attack you in the first place.
@_date: 2017-03-08 10:30:51
In addition to the release notes and nullc's reply to your comment, there's a writeup here with some historical context (you may also want to read the sections above this point in the document): 
@_date: 2017-03-12 20:55:57
Nodes complying with this proposed BIP will reject any blocks that don't signal readiness by their miners to enforce segwit.  Bitcoin Core 0.13.1-0.14.0 nodes will lock-in segwit when &gt;95% of blocks during a retarget period signal readiness, and begin enforcing segwit a retarget period after that.
Therefore, if enough economic nodes adopt this policy that miners feel compelled to follow the rules of those nodes, a chain will be produced that contains only segwit-signalling blocks.
There is no other means of activating segwit in 0.13.1-0.14.0 on mainnet.
@_date: 2016-03-17 00:17:58
Reindexes tend to take longer because they check the signatures in blocks before 295,000 (where the [last checkpoint]( is) as well as read and write from a disk at the same time (which hurts IO performance) while the initial block download doesn't check earlier signatures and mostly only writes to the disk.  On a modern machine with four very fast cores and at least 2GB free memory, it takes about two hours to sync right now.
@_date: 2017-03-08 10:48:44
If you already have a node that has synced past block  16 Februrary 2017, with hash 00000000000000000013176bf8d7dfeab4e1db31dc93bc311b436e82ab226b90 , then you don't need to do anything.  You'll still always validate all blocks after the assumed valid block.
If you're lower than that block or if you want to ensure you check all signatures, start bitcoin-qt/bitcoind with `-assumevalid=0` or add `assumevalid=0` to your bitcoin.conf.
Edit: note that "before", Bitcoin Core skip checking all signtaures before block 295,000 (the highest-height checkpoint) IIRC.
@_date: 2014-07-02 14:49:52
What seems contradictory?
@_date: 2017-03-08 19:31:47
Most of the gold in the world is large private funds, many of them controlled directly by governments.  Does that stop people from using gold for illegal activity?  I don't think so (though I'm not sure economically much illegal activity happens in gold, probably because paper fiat is still widely available and convenient).
I don't think it'll be any different for Bitcoin.  The main problems with using bitcoin for illegal activity will be the same in the future as it is today, namely finding someone willing to accept your bitcoin illegally and trying not to get caught.
@_date: 2016-03-02 13:59:23
Agreed.  Good catch.
@_date: 2017-03-07 00:46:44
Thank you for your answer.
My concern is that these podcasts are being marketed as coming from the Bitcoin Core project the same way the Bitcoin Core software comes from that project even though many members of the project may not be aware of it and not even approve of the content.
@_date: 2016-03-17 02:03:07
I haven't checked the code, but if Andresen has programmed it properly, the July 4th accidental fork would not have happened with his code.  In the July 4th fork started shortly after the network began requiring all new blocks be version 3 or higher; an un-upgraded miner produced a version 2 block and the validationless miners began building on it.
If Andresen programmed this "head first mining" properly, it would ensure that all the fields in the header, including nVersion, have appropriate values for a block at that height.
Note: I'm not saying that head-first mining is a good idea; just responding to this particular misconception.
@_date: 2017-03-04 19:14:47
I think is referring to the March 2013 consensus failure / BDB locks issue ([post-mordemed in BIP50]( where several large mining pools running Bitcoin Core 0.8.0 were compensated from the Bitcoin faucet fund for abandoning the big-blocks/high-locks chain and switching to the lower-PoW chain being mined by Bitcoin &lt;0.8.0 pools.
I think is referring to invalid chains produced because of validationless mining after the [BIP66]( activation, where at one point the most PoW block chain contained [six invalid blocks]( and was quite likely being mined by a majority of the hash rate---yet as Bitcoin Core developers and other community members notified the miners that they were mining blocks that many economic nodes considered invalid, the miners abandoned the higher-PoW chain for the lower-PoW chain that had greater consensus among economic nodes.  To the best of my knowledge, the miners on the abandoned fork (the invalid fork from the perspective of upgraded nodes) did not receive any compensation and lost at least nine total block rewards across the whole incident (`9 blocks * 25 BTC/block = 225 BTC`, or about $75,000 at July 2015 prices IIRC).
@_date: 2017-03-13 17:07:12
No.  The advantage here is just extra security for nodes that have been offline for a long time and which are partitioned from honest nodes.
Newly-started nodes already get this security by virtue of the minimum_chain_work setting that prevents the node from accepting any chain with less than the minimum amount of PoW on the the strongest known valid block chain a few weeks or months before the release of a new version of Bitcoin Core.
@_date: 2017-03-08 14:47:32
1. Shutdown Bitcoin Core using File-&gt;Exit in the GUI or `bitcoin-cli stop` at the command line.
2. Wait at least 60 seconds on an RPi for it to shutdown.
3. Backup your wallet file: `cp ~/.bitcoin/wallet.dat ~/backup-2017-03-08.wallet.dat`
4. Re-install Bitcoin Core using 0.14.0 the same way you installed 0.13.1.  This may involve overwriting some files in `/usr/bin` or `/usr/local/bin` - that's ok.  It should not involve overwriting any files in your Bitcoin data directory (`~/.bitcoin`).  There are some install instructions that are a bit old but still correct at 
@_date: 2016-03-02 05:06:24
Mallory and Alice agree on a zkSNARK that takes three parameters: a password, a salt, and a hash result.  That zkSNARK returns true (providing a checkable proof) if the password plus salt will hash to the provided hash result.  Alice provides that proof to Mallory, and Mallory checks its soundness using the proving key.
For some backgound on SNARKs, this is a pretty good introduction (I hope, because I learned from it): 
@_date: 2017-03-14 15:36:01


Nice. :-)  Thank you for the explanation!  (And also for working on removing checkpoints!)
I opened a [PR]( to amend the current meeting summary, add in some of the information you provided above, and link to the meeting discussion you mentioned above.
@_date: 2017-03-08 14:36:23
The torrent download includes a PGP-signed file with a list of SHA256 checksums.
@_date: 2014-06-26 23:46:53
Curious, why do you need two or more cold computers?  Is that something specific to your situation, like one cold computer for home and one for work?
I've never used a paper wallet---which may be part of my disdain for them---but I've never found having a cold computer particularly inconvenient.  I actually have two setups, one for home which requires my main laptop plus my retired Asus EeePC netbook (cold computer) to spend, and another setup for when I travel (sometimes for a month at a time) which requires my main laptop plus a USB stick running TAILS to spend.  (I also have a hot wallet for moderate amounts.)
Even if I got a Trezor, I think I'd probably keep my savings on the cold computer because air gap security is the kind of thing I can personally validate.
@_date: 2017-03-12 20:34:21
I think more than 10 minutes needs to pass on Reddit before you can claim crickets.
@_date: 2017-03-12 20:01:16






Assuming the assumed valid block is part of the valid block chain with the most proof of work, your node will skip checking the signatures (scripts) in all blocks up to the assumed valid block.
Everything else will be checked.  For example, here are some things that will still be checked:
- Proof of work (PoW)
- Every transaction in a block connects to the block's header (which is secured by PoW)
- Subsidy release schedule (i.e. 50 bitcoins for the first 210,000 blocks; 25 bitcoins for the second 210k blocks, 12.5 bitcoins currently)
- With the exception of the subsidy, all bitcoins that are spent had to exist before they were spent
- Block size and other similar rules
So there's still a lot of verification going on, and a lot of those things are probably very important to you (e.g. subsidy rules ensuring the 21 million bitcoin limit).  This means that when you reach the assumed valid block and start verifying normally, you've verified all the parts of the system that probably matter to you.
The only thing you haven't verified is whether the signatures were correct on the previous transfers of coins, which probably isn't too important to you because from this point on you'll hopefully be using your own node to validate the signatures on any bitcoins sent to you.
@_date: 2016-03-15 19:40:22
To the best of my knowledge, the only software change that could be considered a hard fork was the Bitcoin Core 0.8.0 release.  One of the libraries Bitcoin Core used prior to 0.8 placed a limit on the number of outputs in a block; none of the developers realized the limit existed and the limit actually varied by platform.  Bitcoin Core 0.8 included an upgrade that no longer used that library for that purpose, lifting the unrealized limit.  A bit after the release of 0.8, a miner coincidentally created a block that was over the old limit and the network forked.
The major mining pools at the time agreed to downgrade to the older version of Bitcoin Core, restoring the previous rules[1].  A new version of Bitcoin Core 0.8 was released that respected the old rules as best the developers could determine with a schedule for an upgrade of the network to remove the limitation of the old nodes.  Instructions for patching old nodes was also provided.
[1] It's hard to call the limitation that caused this a "consensus rule" because different platform enforced a different limitation, meaning there was no consensus and a chainfork could've happened even if Bitcoin Core 0.8 had never happened.
[BIP50]( provides the retrospective on this.  Some people call this event a hard fork because the actual effect on the chain was similar to what you'd expect in a hard fork.  Other people don't call it a hard fork because the inconsistent enforcement of the rule that triggered the chain split meant it wasn't a consensus rule.
@_date: 2017-03-06 18:47:23
Is the "Bitcoin Core podcast" by Bitcoin Core, or by someone else with the topics focusing on Bitcoin Core?
@_date: 2017-03-13 17:57:22
Errr, yeah. :-P I can't explain why I was thinking 3x.  I'll edit the post, thanks!
@_date: 2019-03-11 22:58:25
A newsletter every week since June 2018 (except that we took two weeks off for the end-of-year holidays) and special features intermittently.  I don't know if stickying all of them is appropriate though, as often the content can get pretty technical (and there's also slow news weeks).
However, if you think it'd be useful, we'd be happy to poke a mod or something on weeks when we think we have especially high-quality and accessible content.
@_date: 2017-03-14 16:58:58
I'm not nullc, but I think many of the devs that want to build soft fork upgrades want to build them on top of segwit.  For example, signature aggregation (combining what would now be multiple large signatures into a single smaller signature) would be easier to do on top of segwit than as a replaced OP_NOPx opcode (the pre-segwit way of doing things).  Ditto for MAST.
Both of the above topics were described here: 
If you read below that quote from Maxwell, there's a quote from Wuille that describes a couple soft forks that don't need/want segwit.
@_date: 2017-03-21 11:53:01
[Here's]( some more info:




@_date: 2016-06-24 17:55:18
The NOP behavior has other problems which weren't described in the blog post because they're a bit technical, such as the need for a CHECK-style code to also be a VERIFY-style code (such as *CHECK*LOCKTIME*VERIFY* and *CHECK*SEQUENCE*VERIFY* because of the interaction with negation and the NOP code.
An additional problem with regular unversioned Script is that you can add restrictions to an opcode in a soft fork (as Nakamoto did when he added the sigop limits in 2010) but you can't remove those restrictions or rearchitect the opcode to work in a fundamentally better way (as segwit's Script does thanks to changing how the [signature hashing is performed](  When a nice incremental improvement like this is made, versioned Script makes it easy for programs to change just a little bit of their logic and use a different version without having to rewrite everything from scratch or use one of only ten redefinable NOP codes.
In short, I think Script versioning is a much better hook for upgrading the system than the NOP1-10 opcodes.
@_date: 2016-06-24 14:32:40
The Debian project has an interesting release philosophy, [release when ready]( that seems to work pretty well (Debian has been a leading GNU/Linux distribution for about 20 years, possibly in part due to this policy).
The principle behind the policy is that they won't sacrifice quality in order to meet an expected deadline.  They do choose a few dates to rally around, such as feature freezes (Bitcoin Core has feature freeze dates too), but they don't attempt to predict with any certainty when any particular step that requires developer or community input will be performed.
This seems key to me when working with a community of volunteers whose schedule is dictated not by the needs of the project but by when they can find an hour or two to work on the project free from work, family, and other life obligations.
The downside is no schedules with nice clear dates, but that seems more than worth it to me for the upside of knowing the final release will contain software that works the way the developers think it should work, with no shortcuts taken just to ensure they meet some schedule their past selves committed to.
@_date: 2016-06-17 03:03:15
I read that idea recently as well, and I was wondering if maybe it would be better to track coin days sort of like the old mining priority (`coin_amount * coin_age`).  That way:
1. The required number of coin days could be set relatively high, reducing the number of flaired troll accounts a wealthy attacker could create for a short-term attack.
2. Less wealthy people could get the flair too, they'd just have to hold for longer.
3. Just because someone had the flair wouldn't mean that you could assume they had *x* amount of BTC (because they could've just been holding a small amount for a long time).  This could slightly or moderately reduce the incentive to attempt to steal from flaired posters.
@_date: 2016-06-14 23:07:50


As the compiler of the table in question, I can confirm that argued vehemently against it, and that he was the only one I know of who spoke up about it (which I think deserves extra respect).  I thought his arguments were compelling and, after a related experience a few months later, I've decided I won't write ETAs like that again.
I do think that it's sad that some free software developers are in a situation where they can't publish reasonable estimates about their own projects even with repeated warnings that "new technology will be deployed when it is ready and has been tested" and "the code will not be released until it has been well reviewed, and the actual fork will take time to activate".
@_date: 2016-06-15 16:18:37
Offline signing works fine in Bitcoin Core--I use it--but it requires using the RPC interface (either from `bitcoin-cli` or in the debug window in Bitcoin-QT).
It's especially easy if you use `importaddress` to import your cold wallet addresses; in in the GUI this displays an extra column with your "Watch only" balance in addition to the normal column; when you use the RPCs such as `listtransactions` it lists your watch-only transactions along with the ones you have the keys for.  From there, you construct a raw transaction normally, copy it to your offline computer, sign it there, copy it back to the online computer, and broadcast it.
**Edit:** here's a [screenshot]( of the overview screen with watch-only support enabled.  A little bit more information here: 
@_date: 2019-11-24 17:38:43
Correct, users of 0.19 can no longer pay using BitPay's BIP70 implementation.  Note that BitPay themselves were planning to make their implementation of BIP70 incompatible with Bitcoin Core and their CEO (Steven Pair) recommended Bitcoin Core drop its BIP70 implementation: 


@_date: 2019-11-20 18:00:56
This, except I'd also be interested in the version with more than a few sentences, if there is one.  (Also,  is a beautiful documentation site, kudos on that.)
@_date: 2016-06-18 17:15:37


What about the (actual) BDB locks consensus failure where a confirmed double-spend occurred and the (never realized) cross-platform consensus failure fixed by BIP66 (strict DER)?
(I completely agree with your other points, and I'm very happy that the current Bitcoin Core developers insist that changes to their codebase be well thought out, make minimal necessary changes, and undergo serious review.  I say *current* core devs, because I know [it wasn't always the case]( that major changes were well reviewed.)
@_date: 2016-06-14 16:10:39


This is wrong.  21's payment channels did require [a change (BIP65)]( to the Bitcoin architecture to implement a safe payment channel.
You can read more about this in 21's blog post [introducing payment channels support]( which says, "*Malleability resistance.* As a technical point, we‚Äôre using the new CLTV opcode rather than so-called Spillman-style payment channels. This feature eliminates the vulnerability to transaction malleability-related problems."
@_date: 2016-06-24 17:29:20
Segwit nodes don't validate scripts that use versions they don't know about.  This is similar to the way current non-segwit nodes don't validate segwit transactions because they don't know that the witness has been segregated.
As a practical matter, this means it's unsafe to use any script version that isn't being enforced by a large number of economic full nodes that have upgraded to support the new versions (as well as, in all expected cases, miners who signaled their readiness to only produce blocks enforcing the new script rules).
@_date: 2016-06-07 14:01:55
Should be fixed now.  (Sorry about that -- it was my typo.)
@_date: 2019-03-09 22:34:43
If you want to just jump into our most liked content, here are some
positive comments Optech has received on some of our recent newsletters
and original research (with links added by us):






---Mark (Murch) Erhardt, community-elected moderator for the Bitcoin






---Marty, author of Marty's Bent Newsletter and host of Tales from
the Crypt podcast




---Max Hillebrand, World Crypto Network






---Stephan Livera, host of the Stephan Livera Podcast








---Xavi Soler, LND contributor








---Guy Swann, The Cryptoconomy Podcast






---Jameson Lopp, CTO Casa
[Newsletter  
[rbf survey]: 
[newsletter  
[newsletter  
[newsletter  
[newsletter  
[dashboard]: 
@_date: 2019-03-11 23:00:36
Thanks for submitting them in the past!  Is there anything we could do on our side that you think would help?  E.g. more detailed page titles or something.  [Looking at the list]( I realize that "Bitcoin Optech Newsletter  is probably whatever the opposite of click bait is.  :-)
@_date: 2016-06-25 14:03:26
Yeah.  Actually I framed it a similar way when I wrote the first draft for the progress report blog post:






One of the reviewers identified that the first paragraph above wasn't describing the situation correctly.  When I rewrote it to say that newly-added opcodes in the original design behaved like OP_NOP, another reviewer made the suggestion that if we just start the description with the behavior as of Bitcoin 0.3.6, it would be a lot simpler to read.  I agreed and made the change.
I think the case of OP_VER and its two related opcodes is an interesting one as it illustrates that either Nakamoto's thinking changed as he gained experience with the system or that someone else discovered the problem and tipped Nakamoto off to it.
A few months, I went through and skimmed/read all the SVN patches and I think that if I'm ever teaching wannabe protocol devs that I will recommend that they read through the half dozen or so patches that introduce soft forks and try figure out why Nakamoto made the changes he did (not the arbitrary numbers, of which the push limitation of 520 bytes most perplexes me (why 520?)) but things like disabling OP_VER, the later disablement of the math opcodes (because of unbounded memory consumption, I've heard), the introduction of the sigops checks (broken as they were), the redefinition of OP_RETURN, the stuff with OP_CODESEPARATOR which I still don't fully understand myself, etc...
@_date: 2016-06-08 16:13:10
Does anyone know if they have code available under a free software license?  I looked at [their website]( and also [searched GitHub]( but didn't see any.
@_date: 2016-06-09 20:53:08


That's not how a remember it.  Federated pegged sidechains were [described in the original paper]( (appendix A, page 17) with the introduction, "Fortunately, by adopting some additional security assumptions at the expense of the low trust design  objective,  it  is  possible  to  do  an  initial  deployment  in  a  completely  permissionless  way."
This is what was done with the [Elements Project]( an initial deployment done in a completely permissionless way (i.e. no changes to the Bitcoin consensus rules).  So I think that was the plan all along.
Even without creating a public two-way peg, sidechains has already been valuable to Bitcoin.  It was in Elements that the current consensus-enforced sequence numbers and `OP_CSV` opcode were tested, as well as where the first variant of segregated witness (a hard-fork option) was initially implemented even before it was discovered how to implement it in Bitcoin mainnet as a soft fork.  And I think it's great that confidential transactions is getting a nice long shakedown cruise before my coin history starts to depend on it.
Adding the necessary new opcode (or expanded scripting capabilities) for Bitcoin to support SPV pegging is still on the horizon as far as I know, it just isn't a priority right now.  Maybe Rootstock.io and possibly Bloq will help fund development and review of that so it can get in sooner than later.
Ethereum's scripting language seems to me to be more of a hype machine than something currently needed, and some of the opcodes already available in the Elements Project are quite useful on their own and very well tested (and much easier to verify that they work as expected, so adding them to Bitcoin should be straight forward with segwit's allowed script versioning).  They include the 'reactivated' `OP_CAT` which Pieter Wuille used to create [tree signatures]( and the new `OP_ DETERMINISTICRANDOM` which can be used for provably fair gambling or [sub-satoshi payments](
@_date: 2016-06-30 13:19:06


Correct: difficulty cannot go down more than 75% in one retarget period (2,016) blocks nor go up more than 300%.  So under the 50% hash rate reduction posited by your parent post or even the 70% reduction posited by the title of this post, one full retarget period would be sufficient to return to 10 minute blocks.
If blocks started averaging every 20 minutes (50% reduction) or every 40 minutes (75% reduction) or even worse than that, it's possible that the market would partially adapt much faster than difficulty did on account of increased transaction fees and variable rate miners.
As blocks are produced further apart, transaction fee per byte can be expected to rise.  This could be even more the case if there are extra transactions because a bunch of people moving their coins into or out of exchanges due to a government crackdown.  As transaction fee per byte rises, mining becomes more profitable.
Many (most?  almost all?) ASIC miners have variable clock speeds with a quadratic hashrate/energy trade-off (to double your hash rate, you need to use four times as much electricity [plus extra cooling costs]).  Because of this, some mining equipment runs at below its maximum efficiency most of the time.  There are also believed to be some old mining rigs that are just barely uneconomical at the present time but which are still available to be turned on at a moments notice.
This means that there's possibly a reserve of hash rate across all mining operations that can activate if the price to mine a block increases enough.  As that hash rate becomes available, blocks would begin being produced faster.
I don't know how much reserve capacity is available, and I can't guess how much transaction fees would rise nor how much fees would have to rise to mobilize a significant fraction of that reserve hash rate (however, it does help that in a bit over a week, the block subsidy will halve, effectively doubling the impact of fees on mining revenues).
@_date: 2017-01-30 17:46:52


It was the BIP66-violating block and 5 empty blocks built on top of it for a total of 6 invalid blocks.  
There was a second fork almost two days later that was another BIP66-violating block and 2 blocks built on top of that for a total of 3 additional invalid blocks. (Ibid.)
@_date: 2017-08-26 14:12:55
It seems to me that in the current cryptocurrency space, many investors don't consider inflation to be a significant detriment to a project as long as it seems to have other things going for it.  As evidence, look at the high inflation among many of the non-fork coins on CoinMarketCap as well as recent proposals from people like Fred Ehrsam to fund development through ad hoc inflation: 
Given that, I don't see why we should assume that future forks won't be able to have higher inflation (emission) rates that their contemporary Bitcoins.  For example, Bcash is emitting coins faster than Bitcoin due to quirk of their modified difficulty formula.  Other forks could even explicitly increase the total number of bitcoins above 21 million, or they could keep that magic number and steal early bitcoins that haven't moved in 8 years to pay for their proof of work.
What higher fees in Bitcoin does offer is evidence of real demand.  It puts the lie to claims made that people want what Bcash offers, or will want whatever the next highly subsidized fork or system will offer.
@_date: 2016-06-25 21:13:00
Interesting.  Thanks!
@_date: 2016-11-20 10:55:19
The BitcoinCore.org [upgrade guide]( provides instructions for how to deal with this and other similar situations where you don't want to upgrade to a segwit-compatible release but you do want to ensure that you're only processing valid blocks.
@_date: 2016-11-15 23:35:35
I disagree.  It's very important that users know about unexpected forks so that they can take appropriate action.  I, for one, would very much like to receive an alert if Bitcoin Classic or any other fork not explicitly supported by the Bitcoin Core version I run is nearing activation.
I understand why you think this isn't a big deal, but I think it's a reasonable request to ask you to follow the BIP9 specification.  I would suspect that the miners in your pool who want to indicate support for Bitcoin Core would want their hash rate to comply with that specification as closely as possible too.
@_date: 2016-11-23 11:32:37
I don't understand.  What list?  Edit: oh, I guess you're talking about a blacklist for this subreddit.  That makes sense then, thanks!
@_date: 2016-11-03 08:07:10
Oh, thanks for catching that!  That was me (David Harding).  Tom Harding (no known relationship between us) uses the nick `dgenr8`.  I'll open a PR to fix that.
Edit: PR [here](  Thanks again!
@_date: 2016-11-20 14:24:15
For a something less technical for , maybe try this summary from the [0.13.1 release blog post](


















@_date: 2016-11-25 10:09:28
Ah, very interesting.  Thanks!
@_date: 2016-11-24 13:28:45
That's a reasonable response.  I gave you an upvote.
@_date: 2018-06-08 16:25:52
Confirmation time depends also on how much fee you pay, but if you pay a high fee and we ignore the few seconds it takes a transaction to propagate across the network, it will still take on average 10 minutes for your transaction to confirm (assuming a well-functioning network).
In the test I proposed, you'd be taking the place of the transaction.  The moment you started the stopwatch, you'd be counting the seconds since the transaction was sent.  Sometimes, you'd get lucky and the next block would arrive right away; other times you'd be unlucky and it could be an hour or more until the next block arrives.  However, over a large enough sample, the average time until the next block from the moment you start waiting will be 10 minutes.  This is because each hash that miners perform has a statistically independent probability of being the winning hash.
It's like rolling a fair die: if you need a score of 6 to win, there's a 1/6 chance each throw will be a win.  Over a long enough sample, there will be an average of 6 throws---not 3---between the times you win.  If there was an average of 3 throws between wins, then you wouldn't really have 1-in-6 odds, would you?  You can test this too at home and do it even faster than waiting for blocks.  I encourage you to test because probability stuff is so weird and confusing that it helps to have actual evidence of it working before your eyes.  (For example, I didn't believe the Monte Hall Paradox when I first heard it, so I wrote a monte carlo simulator to prove it one way or the other; I was wrong, of course.)
@_date: 2016-11-27 01:29:34


Couldn't you turn the transaction nVersion into a bitfield like was done in BIP9 with the block nVersion, and then only allow blocks to include transactions if the block versionbits sets at least all the same bits as the transaction versionbits?  (With the additional rule that a block versionbits may set other bits.)
This isn't perfect as blocks have associated dates so BIP9 can enforce timeouts, but transactions can theoretically stick around forever and so could end up indicating support for an outdated policy---however, it seems like the worst case would be that a transaction would be dropped from all mempools, which would mean that the sender could resend it with a different transaction versionbits.
I think suggested something like this on the bitcoin-dev mailing list a year or 18 months ago (although I think that was a pre-BIP9 idea).
@_date: 2016-11-23 11:37:28
BIP68 is activated, yes.  I don't know for sure that BU supports it (since it was a soft fork, it's backwards compatible with non-mining nodes).
If BIP134 as-is became standard, then BIP68 would no longer be supported AFAICT.
@_date: 2016-11-03 14:45:41
If you have a node and want to upgrade to support segwit, or if you want to start a node and want to support segwit, running Bitcoin Core 0.13.1 is great.
But please don't feel pressured to upgrade, and please don't obsess over the number from bitnodes.21.co.  It's a statistic that can be easily manipulated and misinterpreted, so I think we should be careful not to place the kind of emphasis on it that will encourage people to engage in manipulation and misinterpretation.
@_date: 2016-11-23 13:29:23
What's the difference between "attack" and "coercion"?
@_date: 2016-11-02 14:15:48
Note that you won't directly be able to identify channel open transaction is the blockchain because the outputs just commit to a hash like any other P2SH or segwit output.  You'll only be able to identify the channel open transactions after the channel closes, because that's when you'll see the script that was committed to by the channel open transaction.
In other words, you'll be able to know how many channels have been closed but you won't be able to know how many channels are currently open.
In the long-term, you may lose even the ability to identify even closed channels that were cooperatively-closed because they use [MAST]( and Schnorr signature aggregation.
IMO, this is all good for privacy in the long run even if it means that we won't be able to boast about usage statistics in the short run.
@_date: 2016-11-02 16:33:51
Yes, you'll still have all of the transaction information (provided your Lightning implementation stores it).  Several Lightning authors have talked about using [pay-to-contract-hash]( and I believe the example from a few weeks ago where paid actually made use of that.
In a pay-to-contract-hash, the Merchant sends you an invoice that specifies what you're paying for.  You hash the invoice and pay to a form of the merchant's public key that includes that hash (but it looks just like a regular public key to anyone who doesn't have the hash).  If the Merchant accepts your transaction, as proven by them releasing the pre-image for the hashlock that is the main security advance in Lightning channels, you have extremely strong cryptographic evidence that they accepted payment under the terms of that contract.
This is, at least in my non-legal opinion, even better than a current-style Bitcoin transaction as anyone today can re-use an existing Bitcoin address for a merchant, send money to it, and claim that they paid the merchant for some random thing---even if the merchant didn't agree to accept that payment.  With pay-to-contract-hash and pre-image release, the merchant only accepts payment if they agree (at the time the payment is received) to the exact contract terms.  If the contract is out of date, or the payer is just making random stuff up, the merchant can simply refuse to accept the payment and the money stays with the customer (i.e. no refunds necessary).
@_date: 2016-11-15 23:42:56
Nice! I thumbs upped the video; the info sounded correct to me.
@_date: 2016-11-27 11:57:13


Indeed.  Excellent point, thanks.


Also a good point.  I suppose you could combine an optional transaction versionbits with assigning some of the free bits in nSequence to a percentage, for example if 4 bits were assigned, the percentages could be 0/15ths, 1/15ths, ..., 15/15ths.
If a miner set at least all the same block versionbits as the transaction versionbits, the miner would be able to claim 100% of the transaction fees.  If the miner didn't set at least one of the same versionbits, he would only be able to claim the percentage of the fees indicated by the allocated nSequence bits; for example if the bits for 7/15ths would be a bit less than half as profitable for a non-signaling miner to include than a transaction than a signaling miner.
That scheme would destroy the unclaimed satoshis.  I know some people consider that undesirable, so an alternative scheme could be that a non-signaling miner may claim all the satoshis from signaling transactions must allocate an output equal in value to the nSequence-indicated amounts that pays `&lt;current_block_height_plus_some_large_number&gt; OP_CLTV` so that the fee becomes available to some future miner who has nothing to do with the current signaling.
@_date: 2016-12-26 19:57:54
Like said, it's an unfounded claim.  Lerner only shows that one computer mined a bunch of coins, which were unspent as of the time he made his analysis.  There's nothing linking those coins to Nakamoto.
To my knowledge the only coins directly linked to Nakamoto are the 50 BTC in the coinbase of the genesis block (which are unspendable under the consensus rules) and the bitcoins Hal Finney said that Nakamoto gave him, which originated in the coinbase of block 9 and were given to Finney in block 170.
If we use Lerner's extranonce-based analysis, we find the computer that likely mined block 9 only mined a handful of other blocks, stopping after block 14:
    from bitcoin.core import b2lx, x, lx
    from bitcoin import rpc
    for i in range(1,50):
        print(i, int(b2lx(list(rpc.Proxy().getblock(rpc.Proxy().getblockhash(i)).vtx[0].vin[0].scriptSig)[1]), 16))
    1 4
    2 11
    3 14
    4 26
    5 32
    6 35
    7 43
    8 44
    9 52
    10 54
    11 59
    12 12
    13 60
    14 62
    15 10
    16 11
    17 13
    18 18
    19 22
    20 32
    21 37
    22 48
    23 49
    24 63
    25 65
    26 5
    27 16
    28 9
    29 13
    30 33
    31 41
    32 54
    33 56
    34 71
    35 77
    36 80
    37 87
    38 7
    39 9
    40 14
    41 18
    42 21
    43 22
    44 30
    45 33
    46 36
    47 48
    48 55
    49 58
Perhaps that computer's mining restarted and Nakamoto mined all the blocks that are attributed to him---but perhaps one of the other computers shown in the extranonce listing shown above was the one who mined all those blocks.  It seems to me like we don't have enough data to favor one choice over the other, and so I agree with that the claim that Nakamoto has a million bitcoins is unfounded.
@_date: 2016-11-18 23:07:49
I'm sorry, I don't understand what you're talking about.
@_date: 2016-11-04 16:33:23
Yes, that is correct.  You will still have [excellent privacy for received transactions](
@_date: 2016-11-03 15:14:06
The absolute best way your node can support other Bitcoin users is by actively enforcing Bitcoin's rules.  To do that, it's usually not enough to just run a node---you also have to use that node to validate the transactions you receive (including refusing to accept as payment any transaction your node doesn't consider valid).  More details about this may be found here: 
However, even if you're not doing that, running a node that downloads 2x more than it uploads can help the network in a variety of ways:
- **Serving SPV clients with honest data:** where I said "usually not enough" above, the exception is that you help influence economic policy if you serve data to SPV clients who won't accept transactions because your node doesn't consider them valid.  The ability to do this in Bitcoin right now could be considered weak due to a lack of fraud proofs / fraud alerts (a technique briefly described by Nakamoto in section 8 of  ) but serving data from a node you know is honest is still not bad.
- **Reserve capacity:** if a bunch of other nodes go offline but your node stays online, or if there's some spike in bandwidth consumption across the network, that'll be your node's chance to shine
- **Serving historic blocks:** nodes that enable pruning don't serve older blocks, so if you do serve older blocks, you're helping fill in the capacity to do that for nodes that do enable pruning.  Speaking as someone who uses pruning on his main hot wallet, I appreciate the contribution of people who serve those historic blocks.
- **Making Bitcoin look normal:** the more people who run nodes on their home or small business ISP connections, the harder it will be for a government or ISP to justify blocking Bitcoin's port 8333 or otherwise filtering Bitcoin traffic.  Also, if you run a node on Tor (this is really easy as of 0.12.0), you marginally improve the privacy of privacy-conscious Tor users.
I'm sure other people can think of other benefits, but I think the general point is that BitCoin isn't BitTorrent: downloading more than you upload doesn't give you negative "share ratio" or make you a "leech", and it isn't something you need to rush out and fix. 
@_date: 2016-11-18 17:19:23
Source?  [C-lightning]( and [lnd]( both use P2P routing, and I'm not aware of any Lightning implementation that uses a hub-and-spoke design.
@_date: 2018-06-16 11:14:22
Thanks for being concerned about people downloading binaries safely.  To (hopefully) address some of your concerns:


BitcoinCore.org is a domain controlled by the Bitcoin Core developers themselves.  In particular, it was formerly owned by Gavin Andresen, who transfered ownership to current lead maintainer Wladimir van der Laan about three years ago.  Up until late 2015, the site was used to host some miscellaneous files; from December 2015 to present, it has hosted the current [open-source]( site.
Until sometime last year, the current site was hosted on GitHub Pages, which is not very secure, and so the project recommended users download binaries from Bitcoin.org, which had better quality hosting.  But then Bitcoin.org's hosting was switched to more cost-effective (but less secure) shared hosts, and so Bitcoin Core contributors change BitcoinCore.org's hosting to, "it's own dedicated servers colocated with DDOS protection and various other security measures."  ([source](  Since then, the project has been recommending users download binaries from BitcoinCore.org, although Bitcoin.org has graciously continued also hosting binaries.


Ideally, people will use GPG to verify the binaries they download.  There's currently a [pull request]( open to BitcoinCore.org to add instructions to the download people to help users learn how to perform that verification.  The author of that PR (me) has also explicitly encouraged Bitcoin.org to add the same instructions to their page (although, of course, they always had the implicit right to do so given that the instructions are under an open source license).
I hope that addresses your concerns, and thank you again for keeping an eye out for unexplained changes that could possibly be the result of a compromised developer.
@_date: 2016-11-18 20:31:59


Perhaps I'm misunderstanding, but you seem to be describing the path discovery mechanism (BGP) whereas I was describing the actual paths (P2P, not hub-and-spoke as you previously claimed).


Sure, but if you're paying fees to LN nodes, it means that (1) you already paid fees to miners to open the channel and (2) you're going to be paying more fees to miners in the future because you're going to close your channel at some point.  I'm not sure what your actual issue is here; miners aren't short-changed by people using LN because LN significantly increases the capacity and featurefulness of the network, which help ensure Bitcoin continues to be used and may make the bitcoins that miners earn more valuable.


Actually, if Alice is going to pay Bob any way, it costs her almost nothing extra (in terms of fees or trust) to open a multi-use channel to him instead of using a one-time transaction.  If Alice or Bob start to use the channel and find that the other person is causing problems, they can just close the channel.  However, if Alice already had cause to pay Bob, there's a good chance that they won't deliberately cause problems for each other, so I think it's reasonable to expect that many of these channels will be stable.
If not, then we try something else.


LN is not the point of segwit.  Segwit provides a [large number of benefits](  LN is possible without segwit and was proposed more than six months before the segwit soft fork; LN can take advantage of several of the features provided by segwit (malleability, better cost accounting, more multisig security, capacity increase, and maybe script versioning [e.g. in allowing MAST or signature aggregation]), but all of those features are good ideas in their own right.


Since Bitcoin remains usable as-is, I'm not sure how there can be a regression.  In any case, it remains that if LN is not useful, people won't use it.  If it is useful, it could be a major improvement.  I for one look forward to giving it a try.
But I also look forward to segwit independently of LN.  As a user, economic full node operator, and someone involved in Bitcoin development, I want the features that segwit enables.
@_date: 2016-12-03 12:49:45


Just as a data point, I've been using pruning on my hot wallet + cold watching-only wallet for almost a year now without ever needing rescan.  Admittedly, I knew in advance that I'd have to avoid rescan and what events would trigger a rescan---a level of knowledge many Bitcoin users may not have---and I also use Linux which has historically been less prone to various db corruption issues that trigger rescans---another thing many less experienced users many not do.
Pruning has saved me from having to unnecessarily upgrade the hard drive in my laptop in order to run an economic full node, for which I'm very grateful, and so far the experience has been 100% positive.
@_date: 2019-08-23 13:28:59
I haven't read the proposal, but the encryptor can select a random integer *k*, derive the pubkey *K* for it, combine *K* and the decryptor's known pubkey to produce a new pubkey that no third party could tell derives from the decryptor's pubkey.  (This is the same operation used in BIP32 HD derivation.)  The encryptor then just needs to include *k* in the encrypted message; the decryptor can add *k* to his private key (mod G) in order to be able to sign.
@_date: 2016-12-05 12:57:28


Your CPU can also corrupt security-related activities your computer performs in a way that's transparent to you but apparent to people who know the corruption exists.
For example, instead of generating random numbers (CSPRNG), it can generate numbers from a limited set space that your adversaries may know about.  This could make it possible for the government to steal any bitcoins sent to wallets created using those "random" numbers even if you only used your computer as an offline-only cold wallet.
@_date: 2016-11-06 14:54:36
I don't know what kind of guarantees you want from release notes (since any set of notes can promise you ponies when there are no ponies in that release), but you can do either of the following if you want a set of notes that was PGP signed by someone:
1. Get the PGP-signed release announcement posted to the [bitcoin-core-dev]( mailing list.  For example, here are the [notes for 0.13.1](
2. Use `git` to clone the repository, checkout the tag for the release (e.g. `git checkout v0.13.1`), and then use `git log --show-signature` to check that the merge commits are signed (there's also a tool for this in the `contrib/devutils` directory---but I think it's probably better to see how git signed commits work before trusting that tool).
@_date: 2016-11-15 18:10:13
I think the implication is that the delivery person wouldn't be aware of the danger.  For example, if I saw a fire next to a random box,  I'd try to put it out; but if I saw a fire near a box I knew was filled with explosives, I'd run the other direction.
@_date: 2016-11-24 01:49:21
How would you do that and get it into default mempools?
@_date: 2016-11-23 14:35:11


As far as I can tell from a quick search on Google (by a non-Chinese speaker), he's the operator of this pool: 


As its name indicates, it seems to be [Litecoin pool]( (the number 3 LTC pool according to [this]( and I don't see any Bitcoin mining going on.
Indeed, if he's primarily a Litecoin pool operator, doesn't he have an incentive to troll Bitcoin users?
@_date: 2018-06-08 01:07:35
Nope, math is weird---especially math about probabilities.  Assuming block difficulty is set perfectly and blocks are produced on average every 10 minutes, the average amount of time you'll wait is 10 minutes no matter when you start waiting.
This is because Bitcoin is designed so that each hash a miner does is statistically independent of every hash that miner and all other miners do.  Imagine all the miners in the world could only do one hash per minute, so each minute they had a 1-in-10 chance of finding a winning hash.  If you start waiting the moment after a block is found, the next hash has a 1-in-10 probability---the same probability as if you start waiting 5 minutes after the previous block.
@_date: 2016-11-27 01:32:09
Ah, I see.  I guess a complication with that idea is that some blocks have multiple outputs to the coinbase tx (in particular, some pools use the coinbase tx to pay their pool miners so that those miners only get paid if the block becomes part of the best block chain).
@_date: 2016-11-23 00:51:00


I had to think about that twice when said it, but he's correct.  Currently a 1MB block can include a bit less than 100,000 outputs (a minimum-sized output is 10 bytes by my math); a segwit block won't be able to include any more outputs because, as the video explains, the extra space in a segwit block comes from the witnesses (which are not part of the outputs).
This means that the worst case UTXO growth doesn't get any worse, which is probably what you were thinking.
However, most data in most blocks are not minimum-size outputs.  They're (as the video explained) about 60% scriptSigs and some percent of other stuff.  When those scriptSigs are moved the the witness section, the remaining space in the block is freed up for more outputs---not more than the previous maximum, but just more for regular use.  These additional outputs will likely contribute to accelerated UTXO set growth.


I suppose a lot depends on how you define technical debt and what emphasis you place on different kinds of technical debt.  Transaction malleability seems to me like technical debt left over from the Nakamoto era, as does the problem with poor sighash scaling and the inability to implement the pruning described in the whitepaper[1] and the need to have all of a transaction's inputs available to validate the amount being spent.  The weakness in P2SH multisig security isn't Nakamoto's fault---that was later developers---but that also seems like technical debt to me.
On the other hand, segwit introduces new transaction and block formats without deprecating the old formats, and it similarly provides several changed opcodes without deprecating the old opcodes, which I think can be reasonably described as technical debt.  The argument is that there's no way to do anything else in a safe soft fork, which seems correct to me, but it's something that will need to be considered in future development and documentation efforts.
To me personally, I think that's a net reduction in technical debt.  To Tom Zander and perhaps Luke-Jr (who isn't necessarily in agreement with most other developers on some subjects), they could think that's a net increase in technical debt.
[1] Segwit doesn't make it possible to implement the pruning described in Nakamoto's whitepaper, but it does provide for a similar mechanism that has most of the same benefit. 
@_date: 2019-08-16 18:43:15
In released versions of Bitcoin Core, no.  In the master development branch, yes.  (See  ) Transactions spending unknown witness version inputs are non-standard in all versions.
@_date: 2016-12-24 13:27:04
Note that Bitcoin-Qt allows you to activate "coin control" option in its configuration which will allow you to choose which inputs to spend (including showing the relevant info about those inputs).  
I use this myself for every spend to prevent mixing funds from unrelated sources (also it's kind of fun).
@_date: 2016-11-23 00:03:42


Lightning uses consensus-enforced sequence numbers (BIP68) to provide relative locktime capabilities, which does not seem to be supported by Flexible Transactions (BIP134) and there does not appear to an alternative relative locktime capability specified.
Although this doesn't prevent Lightning, it would make it considerably less useful (not to mention making other uses of sequence numbers unavailable).
@_date: 2018-06-08 16:04:39
A perfect 10 minute average between blocks doesn't mean the typical block arrives in anywhere close to 10 minutes.  Very few blocks are actually expected to arrive between 9:50 and 10:10.
You can actually easily the theory that the average wait is 10 minutes yourself.  Go to a block explorer that shows you when the latest block has been received.  Grab a stopwatch (or a stopwatch app) and start it, then read a book or whatever with the website visible, looking up every few seconds to see if a new block has arrived.  Record how long it took.
Repeat that a few dozen times (you don't have to do it all the same day), and you'll have empirical evidence that may support one of our theories.
@_date: 2019-10-04 22:17:32
Even when blocks are consistently full, there's an inconsistent amount of block space available per hour (because of stochastic block production) and an inconsistent demand for that block space (because people are more or less active and inactive at different times of the day, the week, and the year).  This can lead to price differences that will drown out small differences in transaction size.  For more information, see 
Edit: in other words, techniques like consolidations and SecureTheBag are likely to be useful even if all blocks are full all the time.
@_date: 2016-11-15 20:20:28


Sorry for being pedantic, but just to be clear, it's 95% of blocks.


No.  There's no [sybil-attack]( resistant way to measure nodes, and moreover there's no way for different nodes to form consensus over how many other nodes there are (since some nodes may not be able to connect to some other nodes), so all we can do as a community is monitor the situation as it unfolds and warn each other if it doesn't seem like enough economic full nodes will enforce segwit.  (As of this writing, I suspect we already have enough economic enforcers for segwit if it activates in the near future).


By Bitcoin Core developer Pieter Wuille (sipa):
- 
- 
The 2k/10k is the count over 2,000/10,000 blocks, respectively.
@_date: 2016-11-07 16:20:35
I'm not Gregory, but the answer is that there was no change in 0.13.1.  There was a change in 0.11.0, and it was documented in those [release notes](




In other words, the behavior that is seeing is likely because when he looked on 0.13.0, there was no fee estimate high enough for `estimatefee 1` but now that he's looking on 0.13.1, there is such a fee.  The difference in versions in coincidental; the relevant code is the same.
@_date: 2016-11-22 23:57:38
Serious question, why do you write "3U" when you seem to be talking about Bitcoin Unlimited (which would normally be abbreviated "BU")?
@_date: 2019-08-11 01:06:40
See [this answer]( on Bitcoin StackExchange by Bitcoin Core contributor Suhas Daftuar (who often works on parts of the code related to P2P communication).
@_date: 2016-11-23 14:45:22
Interesting.  It seems to me that the means used to coerce is the threat of an attack, and so they are the same thing.  As in Murray Rothbard's version of the non-aggression principle:  "No one may **threaten** or commit violence against another man's person or property." (emphasis added)
I do understand why it may be useful to make a distinction between termination and control when considering an attacker's motivation.
@_date: 2016-12-15 19:44:51
I think this is an interesting position, but does this mean you think it's ok to kill someone who sues you because if the court rules against you, the government may use violence against you to seize your property?
Another problem with this position seems to be that it feels very subjective to me.  Would defensive violence be allowed if the person wasn't explicitly threatening to turn people into the government but was threatening only to shame those people in public for being drug users?
@_date: 2016-12-31 01:32:49


Technical nitpick for anyone paying really close attention: 0.1 didn't actually have the OP_NOPn opcodes---those were added in Bitcoin 0.3.6 -- this commit 
Instead, Bitcoin 0.1 performed no operation (NOP) for any opcode that wasn't defined.  For the opcodes we now call OP_NOP1 through OP_NOP10, this is identical behavior, but it was also possible back then to add more than 10 new opcodes using this behavior.
In 0.3.6, Nakamoto removed 15[*] opcodes (presumably because he had concerns about their safety) and limited the ability to add new opcodes by redefining no-ops to just redefining those 10 OP_NOPn opcodes he explicitly added in this release.
[*] Technically he removed 18, but OP_VER, OP_VERIF, and OP_VERNOTIF had been effectively disabled in a previously update.
In any case, Theymos is absolutely correct that the ability to perform soft fork upgrades (whatever mental name Nakamoto used for them) seems very clearly to have been explicitly designed into the system (and was something Nakamoto himself used at least 6 times I'm aware of, including the commit linked above).
@_date: 2016-11-19 17:29:59
Lightning Network uses [payment channels]( with [Hashed TimeLock Contracts](  Both of those things are currently usable on Bitcoin mainnet without segwit, so LN is possible without segwit.
However, without segwit or another malleability fix, LN channels have to deal with situations where transactions get mutated ("malleated"), which makes them get stuck at various steps.  Preventing them from getting stuck permanently requires either introducing trust (which we don't want to do) or setting some annoying timeouts that limit the efficiency of channels.
LN can also take advantage of many of segwits other [benefits]( such as:
- **Increased security for multisig:** every segwit transaction uses multisig, and because it's a new protocol, it can trivially make use of the new segwit output format that allows using this feature.
- **Script versioning:** can be used to add new features to Bitcoin more easily than they can be added without segwit (some features being made more easy to add than others).  Two features currently being researched are MAST and signature aggretation---both of which can provide modest increases to the capacity of the network and which can help improve transaction privacy.
- **More block space:** meaning more channels can be opened or closed in any particular block.
- **Better cost accounting for transactions:** related to the above, this provides benefits to people who produce transactions that reduce the short-term and long-term load on full nodes.  Lightning-style transactions are effective at doing this, so they benefit from this segwit feature.
Also, fixing malleability for upgraded software makes designing LN-compatible (and any Bitcoin-compatible) wallets much easier in general, so that's a huge plus too.
For Rootstock (RSK), I wrote a very-closely related answer to that question on Bitcoin.StackExchange a couple weeks ago: 
@_date: 2016-11-15 18:18:10
Please don't do that.  Bitcoin Core and other software will display warnings when it see blocks that have versions it doesn't understand (and it doesn't understand you signaling segwit support early.
From my ~/.bitcoin/debug.log:
    2016-11-15 07:41:42 UpdateTip: new best=00000000000000000273d64f96a5215e574311bad2525b95372e8606292a345c height=438990 version=0x20000000 log2_work=85.544694 tx=170783709 date='2016-11-15 07:41:40' progress=1.000000 cache=1062.1MiB(497796tx) warning='6 of last 100 blocks have unexpected version'
    2016-11-15 07:42:22 UpdateTip: new best=00000000000000000263a5bb45a26f1b6df7da39f81968f2fa183bd0a3d09ffb height=438991 version=0x20000002 log2_work=85.544722 tx=170785511 date='2016-11-15 07:42:19' progress=1.000000 cache=1062.2MiB(498739tx) warning='7 of last 100 blocks have unexpected version'
If too many more blocks are seen with unexpected versions, Bitcoin Core will display an error in the GUI (for GUI users) and through the RPC interface, disturbing users.
It's much nicer for you to start signaling during the actual measurement period to avoid these issues. 
@_date: 2016-11-27 01:19:58
Alas, this is not permitted.  The coinbase transaction is only allowed to have one input (which is specially formatted and is called the "coinbase", giving the transaction its name).  This input has an effective value equal to the block subsidy plus all the transaction fees paid in the block (collectively called the block reward).
@_date: 2015-08-27 20:10:49
Yes, that's correct.  If all (or nearly all) economically relevant full nodes implement BIP101, the consensus rules are changed.
@_date: 2015-08-21 18:52:14
Blockstream's business model is to sell consulting services to businesses, not services to end users.
When blocks are full (whether because of the hard limit or a per-miner soft limit), then miners typically prioritize by fee.  Users will always be able to pay a higher fee to get their transactions confirmed quicker, or they can choose to pay a lower fee and hope that the random block-finding process will clear out all pending transactions that pay higher fees than theirs.
With regard to lightning, which is I guess what you're trying to refer to, users still have to submit their half of the channel open transaction to the Bitcoin network and pay an appropriate fee, so end users will continue to use the Bitcoin network directly for the foreseeable future.


That's not what you're providing.  You're providing an estimate of future growth based on historical data (apparently extended linearly), but an estimate isn't a fact.  I don't know what new users or new applications will appear next week, and neither does anyone else, so none of us should be passing estimates off as fact.
If you want to say something, the following statements are accurate:


(Note that there are more statistics like that in this Bitcoin Wiki article I wrote:  )
@_date: 2019-02-25 12:07:55


I think it's a huge usability win.  A wallet with some or all of its funds offchain can generate an onchain payment without having to pause offchain payments while it waits for the onchain transaction to confirm.  Or a wallet that wants to put more funds into a channel can do that while continuing to process payments using the existing funds until the new transaction confirms.
None of this changes the underlying security model, and wallets can continue to show "x BTC onchain / y BTC offchain / z BTC waiting for confirmation" for users who want to know how their funds are distributed.
Splicing is just about removing unnecessary pauses in channels while an old state is finalized onchain and a new state locked in.  The pauses are unnecessary if channels are closed and reopened cooperatively, as both parties can use the security from the old channel while they wait for the new channel to get a sufficient number of confirmations.


Watchtowers don't verify anything.  They simply broadcast a transaction for you if you aren't around to do it yourself.


Please explain why.  By "automatically in the background", I assume you're talking about routing (which many end users probably won't do).  I think that'd show up in a transaction list as:
     2019-02-25 Paid Bob 0.123 BTC (bc12345...cdef)
     2019-02-25 Received from Charlie 0.456 BTC (channel13)
     2019-02-25 This day's routing income 0.00001234567 (123 xfers)
That doesn't seem particularly messy to me.


This is a fundamental problem with LN and not something changed by splicing.  It's also the problem that watchtowers and long timeouts attempt to address.  Users especially worried about their funds in LN would certainly be encouraged to (1) open channels with long settlement times, (2) use multiple watchtowers, (3) run their own node for monitoring their channels.




This seems like disingenuous quoting.  The very next sentence in the OP is "The only funds that are not on Lightning are the funds you keep in cold storage."
I personally don't see why I wouldn't keep all of my hot wallet funds in LN once the technology has matured and splice outs become convenient.
@_date: 2015-08-15 11:55:09
I'm not a Core dev, not even close.  I just write some documentation for Bitcoin.org.
I do not consider myself a Bitcoin expert, so receiving the flair would be unwarranted.
@_date: 2015-08-14 12:14:20
has always been very generous with his time in helping me better understand Bitcoin and related cryptographic technology.  I've seen him help scores of other developers the same, and I can't think of anyone better suited to mentor new Bitcoin developers.
I get the felling that this post is supposed to be an attack, but someone is going to have to explain to me why helping to create new Bitcoin talent is a bad thing.
@_date: 2015-08-03 14:53:12
Um, according to the [whitepaper]( the principle benefit of decentralization is disintermediation---the idea that if one guy controls the ledger, he'll inevitably be pressured to mediate which transactions get added to benefit wronged parties, raising his costs and also increasing everyone eles's risk of fraudulent chargebacks, leading eventually to the same crappy legacy financial system we have now.
Censorship resistance in Bitcoin is mainly obtained by making transactions non-identifiable, preventing miners from censoring any one person's transactions without censoring all transactions.  (This is why we strongly discourage address reuse that breaks this non-identifiability.)
@_date: 2015-08-14 23:09:04
Experimenting on the idea of contentious hard forks seems extremely difficult because of the number of important variables involved:
- How strong is the economic majority?  How weak is the minority?  A 51%/49% split would seem to be very bad, but how bad would a 95%/5% split be?
- For how long are people wondering which chain will win?  (Because, until they know what chain will win, it won't be safe to accept transactions even from people you trust, unless programmers build special tools.)  I'd guess one day of downtime won't hurt Bitcoin much, but weeks worth of downtime could be really bad.
- Are there any opportunistic attackers who will attempt to take advantage of the situation?  A month ago, we saw what appeared to be Litecoin pump-and-dumpers sponsoring a transaction flood attack against Bitcoin just after it was discovered that we had a problem with SPV mining.  During a prolonged contentious chain fork, there might be more well-funded attacks like that.  How would we factor that into a test?
- What happens to the bitcoin price during the fork?  I suspect most bitcoin owners are inured against moderate price drops, but we've seen panic selling before during major price drops.  There are a number of Bitcoin entrepreneurs and businesses that may be unable to effectively operate post-fork if the price drops too much.  How would we test for and measure the impact of that in a test?
- What unknown-unknowns are there?  What would we fail to test for because we have no prior experience with this type of event?
Like most economic questions, I think experimental testing of contentious hard forks will prove to be effectively impossible.  We'll probably have to subsist on a priori deductions.
@_date: 2015-08-21 20:04:08
Yes.  What's your point?
@_date: 2015-08-21 18:07:53
1. **Title:** As I said earlier, nearly everyone agrees that the block size limit should be raised---so the question should not be about the block size limit, but whether BIP101 is the best way to raise it.
2. **Links:** Either only neutral resources should be used for describing the arguments, such as  (note: I authored that document), or there should be balanced linking to articles from both sides.
3. **Get the facts correct:**  For example, "A 1mb limit will eventually result in Bitcoin being turned into a settlement system, all users will have to go through 3rd party businesses (e.g. blockstream style solutions)."
    This statement is seriously flawed.  Bitcoin was always be available for person-to-person payments and it is already in use as a settlement layer; some estimates (sourced in the above Wiki article) estimate 90% to 99% of Bitcoin transactions are already off-chain.  There is no such thing as "blockstream-style solutions"; Blockstream is a company and it currently doesn't sell any solutions, although it does fund research into sidechains and the lightning network---but all of that code is released as open source.
    Further, this statement repeats the false dichotomy that it's either 1MB or something bigger.
4. **Stop focusing on Blockstream:** For example, "Blockstream(s, other businesses that follow the same model) can function within a higher block size."  I'm guessing that you mean to talk about sidechains or the lightning network, but you keep using the name Blockstream as a synonym.  It's not a synonym; moreover, Blockstream's described business model isn't selling access to sidechains or lightning---if it was, why would they open source it?---but rather selling consulting expertise for people who want to use Bitcoin (they've described this as the same model Red Hat uses to make most of its money from Linux).
5. **Don't mention the filtering:** it has no place in a debate over block size.
It is my recommendation that you wholly delete this thing and start over after carefully discussing it with experts from both sides.  (Or don't start over at all.  If the experts can't agree on something, why would you expect regular users to agree on it?)
@_date: 2015-08-17 02:04:32
I've just been moving posts from people I don't know (or who I know are trolls) straight to archive.  This is not a good long-term strategy because it penalizes new contributors with valuable suggestions, but I don't know any other way to handle the poor signal-to-noise ratio.
@_date: 2015-08-15 02:58:16
I completely agree: there is (and cannot be) an official ruleset.  There is a de facto ruleset---the one used by the economic majority.
@_date: 2015-08-27 18:42:27
The conclusion of [the paper]( says (emphasis added),


valid blocks by working on extending them and rejecting invalid blocks by refusing to work on
them. **Any needed rules and incentives can be enforced with this consensus mechanism.**
This is exactly what Nakamoto did by adding the 1 MB block size limit: added a needed rule.  Whether or not it's needed today can be debated, but you're flat out wrong to say that the longest chain composed of valid transactions has *ever* been Bitcoin's design---for example, placing a valid merkle root in the block header is described in the whitepaper and was implemented in Bitcoin 0.1.
@_date: 2015-08-01 22:57:35
That should probably have a different confusing name, like "soft soft-fork" because unlike "hard soft-forks" the new "double soft" rules won't be enforced by other nodes when the mining cartel falls out of power.
@_date: 2015-08-21 20:20:16


Yes.  If you're talking about Lightning, it's a service built on top of regular Bitcoin transactions.  If you can't send regular transactions, you can't use Lightning.


Again, if you're talking about Lightning, it isn't a trusted third-party.  It's a third-party that is not trusted in the least bit.


Yes, users will need to pay transaction fees.  For faster confirmation, they'll need to pay higher fees; to save money, they'll have to wait longer.
@_date: 2015-08-15 11:51:54
Are you expecting me to say the Bitcoin Core developers?  They certainly have significant influence, but if they could "make the economic majority decide on a given ruleset", the dev's majority rejection of the BIP101 fork would've killed this debate months ago.
It's messy, but I think we have to accept that the economic majority is in control of their own fate.
@_date: 2015-08-11 16:20:42
It's highly unlikely that they've implemented BIP100 since there's no public code for it.  There's not even an official proposal in the [BIPs repository](
@_date: 2015-08-31 15:11:01
What do you mean by "XT block", and how is it detectably different from a BIP101 block?
@_date: 2015-08-02 03:37:48
That's correct, that would be a regular soft fork.
However, there's something similar in effect to a soft fork where miners on their own can refuse to build on chains that don't meet their requirements.  Validation-only nodes don't need to enforce these requirements, so they would be lifted as soon as the cartel loses its majority hash rate advantage.  This is what I think is describing.
Using your example, it's like a cartel introducing a 500KB cap that economically important nodes *don't* update to support.  As soon as the cartel lost power, any miner could go back to mining 1MB blocks.
If there was a long-lived cartel enforcing a rule this way, it would be advantageous for nodes to automatically reject blocks that the cartel was expected to reject even if the nodes didn't like the new rule.  However, nodes could be pre-programmed to experiment a little to see if the cartel was broken.  For example, they could reject all blocks over 500KB unless the block was a difficulty-change block (1 block in 2016) or were part of a chain of the last 10,000 blocks including any blocks larger than 500KB.
@_date: 2015-08-21 18:13:32


What does this have do with the false claim that transactions will go through Blockstream.


As you say, that's an assumption, but you list it as if it were a fact.  Please only list facts. 
@_date: 2015-08-17 20:04:57
I'd say the same for [Jonas Schnelli]( who has been working on the Bitcoin Core wallet and REST interface (and doing lots of other things too).
@_date: 2019-02-25 14:41:30


Do you mean "discreetly"?  I'd agree that's a problem if the wallet is hiding from the user what funds are in channels and what parts are onchain, but there's nothing required about that.  I think the goal for an LN-enabled hot wallet would be to keep all funds offchain all the time, but still allow making onchain payments if necessary.
Note that making payments carries no risk for the spender (as long their software signs correctly); it's only the receiver who needs to worry confirmations or locking in channel state.


LN provides reasonable security guarantees even when opening channels with known malicious parties, so there's no need for users to be selecting their peers manually.  And, again, once splice-out makes it easy to send onchain payments from within a payment channel, there's no need for an LN-enabled wallet to keep any of its balance sitting around in single-user-controlled outputs---so the choice isn't how much to put into a channel but how much to put into the wallet altogether.


Sure, agreed.  My problem was with you calling that verification.


Again, I think this will be a choice that users make upfront at the time they choose their wallet.  They can choose an onchain-only wallet (good for use with a cold wallet setup) or they can choose an LN wallet (good for everyday spending).  Within an LN wallet, there's no need to differentiate how funds are stored because the goal will be to have all the funds in a channel at all times.


No, that's a terrible UX.  It's only palatable now because LN is in early days.


I suspect you're wrong there.  Most ordinary users will simply search for "best channel peer" or something and will simply open a channel with whatever services some random website recommends they use.  Instead, if we build nice autopilots into the software that can evaluate thousands of different potential peers and screen them for, among other things, "possibly too big to fail", we'll get a less centralized network.
@_date: 2015-08-12 23:23:26


Note, I chose to use the "contentious hard fork" phrasing in the Bitcoin.org policy.  I think is generally using the "altcoin" phrasing.
I chose my phrasing because I thought it was less confusing, but if you want to muddle the water with arguments about soft forks, I'd be willing to start using the altcoin phrasing.
But what's the point?  It's already clear what we're all planning to do, whatever names we assign to it.  
@_date: 2015-08-22 13:44:28


I suspect there are multiple definitions of third-party service being used here, and that's what's confusing you.
1. I'm using third party to mean, "a service provided by someone who is not part of the financial transaction." 
1. You seem to be using third party to mean, "a service that is not part of the Bitcoin protocol."
1. Previously you kept saying *trusted* third party, which means to me, "a service that the parties to a transaction trust with their money in order to facilitate the exchange"
It's hard to tell from your description what Greg is saying, but I'm confident he would agree that LN hubs are  will be  when implemented but maybe not forever, and are not 


I doubt we disagree here.  I said that you will not be *forced* to use LN.  You will only find it more convenient (including more affordable) than regular transactions, particularly in the future when average fees on the regular Bitcoin network increase.


I highly doubt we disagree on the fundamentals; I think you're just confused because we're each trying to explain things to you in different ways.  I apologize for that.
@_date: 2015-08-22 00:27:24
No, if that's how it worked, it would required trust.  LN works like this:
- Alice the user hears about Bob's Lightning hub; this might be through a website or there might be a protocol for finding hubs similar to finding Tor gateways (LN is currently being designed with onion routing for privacy).
- Alice contacts the hub and they negotiate a contract automatically.  Once the contract is negotiated, a Bitcoin transaction signed by both Alice and Bob is sent to the network locking up an equal amount of Alice's bitcoins and Bob's bitcoins.  Either Alice or Bob can submit this transaction; they wait for it to be mined and to receive whatever number of confirmations they each feel is safe.
- Alice makes an unlimited number of payments through Bob's hub to/from other users on the LN.  Onion routing is used so that Bob can't see who Alice is paying, just the amounts she pays or receives (remember these payments don't appear on the block chain, so knowing the amount doesn't allow Bob to find additional details about the payment later).
- When Alice is done with the channel, or if Bob disappears, Alice sends a Bitcoin transaction closing the channel.  Alice can now spend those bitcoins she initially locked up (plus or minus the bitcoins she received from the LN), including using them to open a new LN channel with a different hub.
As you can see, Alice the user---not Bob the hub provider---is in full control and she's transacting directly on the Bitcoin network.  Lightning clients **must** have the ability to send regular Bitcoin transactions or the security model is broken.
A nifty feature here is channel rebalancing.  If Alice has a channel open to Bob's hub and Charlie's hub, and Bob wants to send Charlie money (and Alice is online), he can send it through Alice (and pay her a fee for the service).  In other words, every LN user is also a hub!  Hubs are nothing to be scared of: they make Bitcoin much more useful and should not reduce user security compared to base Bitcoin.
@_date: 2015-07-19 14:52:25
I can confirm I'm not sock puppet and that I don't have any other Reddit accounts.
@_date: 2015-08-21 15:52:07
There are some pretty serious problems in the text here:


This is irrelevant to any side's proposals.  BIP101 specifies an 8MB *starting* limit which is increased *every second* starting 2016-01-11 00:00:00 UTC.
Further, *none* of the opposed developers are proposing a perpetual 1MB limit.


All of these links are pro-XT resources.


This is pro-XT propaganda.  Where does this claim that "all users will have to go through ... Blockstream" come from?


Why is this an assumed fact?


The same propaganda, repeated.


This sentence is nonsensical.  Blockstream is a company, not something you pluralize.


More propaganda, and I believe criticism of the current moderation policies outside of the stickied thread is grounds for having the post deleted.
-- maybe you can create and promote a actual neutral discussion, instead of this rigged one.
@_date: 2015-08-15 01:07:54
There is no official ruleset---Bitcoin is a decentralized system, and the code is open source.  The only restriction on changing the protocol is that you can only transact with people who follow the same protocol as you.
There is also no way to prevent anyone from running different code, or someone probably would've done that already and killed the Bitcoin-derived altcoins.
@_date: 2015-07-29 16:56:27
I don't know of a list, but one would be useful.  The only large miner I know who supports any RBF is f2pool (FSS-RBF; previously full RBF).  If anyone knows of any others, post them here and I'll look into creating a page on the Wiki.
@_date: 2015-07-11 03:29:20
The current threshold is user defined.  It's three times the cost per byte to spend the output according to the node's minimum relay fees.   For a standard P2PKH output and the default minimum relay fee of 0.00001000 BTC, that's 0.00000546 BTC.
If you change your node to have a higher (or lower) minimum relay fee, the dust fee is scaled by the same proportion.
Given the current flood attack, lots of people think the default minimum relay fee is too low.
@_date: 2015-08-22 06:33:02
I never debated the third party claim.  I was saying that the *trusted* third party claim was wrong.  Here's the Wikipedia article about trusted third parties: 
All digital currency systems before Bitcoin required some sort of trusted third party.  As Nakamoto's paper explains, this is problematic because even a well-intentioned trusted third party will be forced to begin interfering with payments.
Bitcoin gets around this by trusting not a particular person but the work produced by multiple people working in cooperative competition (mining, as demonstrated through proof of work and adherence to the validation rules).  LN uses Bitcoin transactions for 100% of its operations, so it doesn't change this dynamic.
In summary, it isn't the number of parties involved that matters, it's whether you need to trust any of them with your money.  In PayPal, you need to trust PayPal.  In Bitcoin and LN, you don't need to trust anyone (provided there's a reasonable level of mining decentralization).
@_date: 2015-08-23 16:00:08


This is incorrect.  Democracy is "the doctrine that the numerical majority of an organized group can make decisions binding on the whole group." (Source: Wordnet) This isn't the case for Bitcoin because each of us can use whatever validation rules we want.
Bitcoin is a consensus because general agreement among participants is required for it to operate.  In order for me to pay you a bitcoin, we both have to agree about what a bitcoin is; in order for that bitcoin to be useful to you, you have to believe that the next person you want to pay will agree with you about what a bitcoin is.
In the case of a contentious hard fork, this general agreement among people who accept bitcoins is lost.  Low-risk transactions become impossible because I don't know if you'll accept my bitcoins and you don't know if the next person you want to pay will accept the bitcoins I'm about to pay you.
It is certainly possible for 51% of Bitcoin users to switch to an altcoin, just as it's possible for 49% of Bitcoin users to do it.  But to switch the entire economy to new consensus rules requires general agreement among nearly all Bitcoin users.
@_date: 2015-07-12 15:22:05


I don't think you understand.  The fee market isn't a design choice; it's fundamental to a distributed ledger.  That's because:
1. Block space is fundamentally limited.  I'm not talking about 1MB or 8MB or 8GB, but the fact that increases in block size have a centralizing effect on the system, so that at some point the block size becomes high enough that there is only one validator/miner left---and the system is no longer distributed.
2. Miners can choose what fees to accept.  There can be no minimum fee, even if consensus rules say outputs must be *x* amount less than inputs, because transactors can make side deals with miners.
3. Transaction series cannot be globally ordered any way but by inclusion in a block (in a distributed system).
Given these constraints, there is no way to stop a fee market from forming once the number of transactions people want to make exceeds the space available in blocks.
The choice we have available to us is *when* the fee market should form.  Should it be now, or should it be later?  One advantage of doing it now is that we can use consensus rules to keep block size small in order to promote decentralization (an essential part of the network).  Another advantage is that, as you have tried to show, we can probably tolerate small increases in the block size---so that if the transition from essentially-no-fee to fee-market becomes too rough, we can smooth it over temporarily by increasing block size in small amounts.
But the fundamental economics that produce a fee market will always remain.  The best strategy for miners is always to include every profitable transaction---that is, to fill blocks all the time.
@_date: 2015-08-21 22:06:58
Ok, read them.  Now what did you want to say?
@_date: 2015-08-21 23:23:24
I just searched, and that paper doesn't use the word trust a single time.  I'm not sure what you're talking about.
As I've said multiple times above, Lightning does **not** require trust.  Lightning servers are a third-party somewhat in the same sense that miners are a third-party.  Lightning servers put their own money at risk (as miners do by buying hardware), they earn money through fees (as miners do), but they don't require you trust them (just like you don't trust miners).
@_date: 2015-08-27 19:05:43
That BIP101 blocks &gt;1MB will be valid blocks simply because they're on the strongest chain.  As Greg (nullc) says, the best block chain is the strongest *valid* chain, not just the strongest chain.
@_date: 2015-08-03 14:33:04






When I corresponded (once) with Satoshi in 2010, I had no idea that wasn't his real name.  I don't know how many people realized it was a pseudonym prior to his leaving.


There's a [GPG key]( believed to belong to him, and he may still have the private key for the public key used in the Genesis Block.  Both of these can be used to cryptographically sign a message.


His gmx.com email was hacked, and is now disabled by GMX.
@_date: 2015-07-10 19:33:08


This has problems; the trade-off of simplified fees is probably not worth further making it difficult to run a full node at this time.


That doesn't work.  Frequent transactors can always make side deals with miners to receive rebates.


This is already done; it's the dust threshold.
@_date: 2015-08-27 11:44:12
Hey, nice one!  I just read [your patch]( and it does exactly what I'd expect.
Do you know if ever patched BW4A to support trusted peers on Tor hidden services like GreenBits now does?
@_date: 2015-07-07 13:12:57
Estimates on 0.11.0RC3 are supposed to be much better than the ones on 0.10.x.
@_date: 2015-08-11 16:32:50
I don't think there's any unified implication.  One pool might be supporting BIP100; another pool might be supporting BIP101; and a third pool might just be worried that if they don't indicate some sort of support, miners will leave their pool the way some are leaving Bitcoin Core for Bitcoin XT.
@_date: 2015-07-04 16:15:21
Sorry.  I probably spend too much time around devs who use the term "SPV wallet" almost exclusively.  I know the term "lightweight wallet" is more commonly used in less technical context, and I was trying to make the association between them.
As soon as I finish reviewing this post to see if there are any other useful suggestions, I'll link the first use of SPV to this StackExchange question:   (and, long-term, I'll see if we can get SPV added to the [vocabulary page](  Thanks for your suggestion! 
@_date: 2015-08-22 07:02:48


Yes, this is correct and is completely congruent with what I said.


You will not ever be forced to use Lightning; you will only find it more convenient than regular Bitcoin transactions.  Moreover, you already rely on untrusted third-party miners and untrusted third-party relay nodes, so using another untrusted third-party service should not be concerning.
@_date: 2015-08-23 14:54:40
Out of curiosity, what would you suggest instead?  I've never really used git collaboratively outside GitHub, so I'm not familiar with the alternatives.
I looked up the process Linux kernel development uses, since I knew that wasn't GitHub based, but I couldn't really imagine how that multi-level maintainer workflow could apply to Bitcoin Core where we often want patches getting wide review and don't want to put Wladimir in the position of being the ultimate sole decision maker.
@_date: 2015-07-12 01:15:24


This is what *I* mean: ordering the queue by time *doesn't work* in a decentralized system.  It can't be enforced.  If it could be enforced without mining, we wouldn't need mining.
So all of your arguments based on "queue jumping" are invalid.


This is not a rebate for mass use.  This is the ability of economically powerful entities to circumvent something called a "minimum fee."  People get upset about this sort of thing all the time: Richie Rich pays less in taxes than Porter Poorman, so people get upset.
Again, you've imagined something that can't be effectively enforced, invalidating the arguments dependent upon it.
@_date: 2015-07-12 19:06:49


Pruned and non-pruned are equally vulnerable, as neither rebuilds the UTXO set each time they are started.  (And even if they did, the malware could interfere with that.)


Nodes by default verify the last 288 blocks when they start.  Pruned nodes keep a minimum of 288 blocks (two days) of history.  So the verification level is identical by default.  If you want to verify more (for example using the [verifychain RPC]( using a pruned node, it will re-download the blocks.


Both pruned and non-pruned nodes download and verify every single block.  The pruned nodes just throw away the oldest blocks as newer blocks come in.
@_date: 2015-07-12 18:59:38
Full nodes are full *validation* nodes, meaning they validate all of the data in a block according to the Bitcoin consensus rules.  When Bitcoin Core prunes data, it only gets rid of the data it doesn't need for future validation (such as outputs that have already been spent, since outputs can only be spent once).
Hashing is something different, and non-full-nodes have always been able to do it.
@_date: 2015-07-06 15:26:45
I think you meant .com.  The .org site is maintained by volunteers (currently all of them unpaid).
@_date: 2015-07-04 22:37:02
Miners indicate that they will enforce the BIP66 rules by creating version 3 (v3) blocks.  One of the rules for v3 blocks is that when 950 of the last 1,000 blocks are v3 blocks, then new v2 blocks are no longer allowed.
That still means that about 5% of miners haven't upgraded, so they continue to produce v2 blocks that are now invalid.  Everyone who knows about the v3 rules is supposed to reject those blocks, and upgraded miners are not supposed to build blocks on top of the now-invalid v2 blocks.
It turns out that several large miners were running code that said: "if I receive a new block, start trying to validate it.  But until it's validated or an alternative block at the same height is validated, mine empty blocks on top of it."
So what happened is that BTC Nuggets didn't upgrade, so they produced a v2 block.  Somebody (BTC China, I think) probably tried to validate it and failed.  However, their code said to keep mining on top of it until somebody else had produced an alternative block---so they they kept mining and eventually produced a block on top of it.
F2Pool was running similar code, so even though they couldn't validate either BTC nuggets or BTC China's blocks, they mined on top of them---producing (I think) 4 blocks in a row.  A few other miners did the same thing---they blindly followed the longest chain, which is what SPV wallets do (hence the name SPV mining, even though that's a somewhat inaccurate name).
Eventually the core devs were able to wake up enough miners to get them to stop hashing on the invalid chain, and the valid chain became the longest chain and took over.  And happily, since the miners with the broken code only created empty blocks on the invalid chain (in order to avoid creating invalid blocks), only the transactions in that initial v2 block showed as confirmed when they weren't.  (And most of them were quickly confirmed on the valid chain by miners who always validate, so double spend risk was very low---however, if it happens again, that may not be the case, which is Bitcoin.org is warning users to wait an extra 30 confirmations.)
@_date: 2015-07-11 13:24:52


If you had some way for different computers in different locations to deterministically conclude which transaction came first, you wouldn't need mining.  You'd just have all nodes accept the first transaction and ignore all subsequent spends of the same input.


There can be no such thing as queue jumping in Bitcoin because there is no way to enforce a time-ordered queue in a distributed system.
My response is in regards to your proposal to enforce fixed fees using the consensus rules.  That doesn't work because frequent transactors can make deals with miners to receive rebates, allowing them to send at potentially much lower cost than infrequent transactors who cannot make such deals.
Not only is that unfair, but it prevents you from achieving the goal you set out to achieve!  The frequent transactors will be competing against each other for block space using fees exactly the same as now---except that all us occasional transactors won't be able to take advantage of any savings that results from competition because our fees will be fixed.
@_date: 2015-07-16 14:09:59
Er, I can't tell whether or not you're being sarcastic.
The *hacker* in *hacker news* refers to what Wikipedia calls [Hacker (programmer subculture)]( not the [other kind of hacker]( who breaks into secure systems.
@_date: 2015-07-01 01:19:10
If you can't join 'em, rectum.
@_date: 2015-07-07 11:55:34
I don't think it's centralized: anyone can host a Bitcoin alert system.  For example: Luke and Theymos each wrote stories for (and stickied one of them), Theymos wrote a story for BitcoinTalk, the situation was discussed live in  and  it was emailed to the bitcoin-dev mailing list, and half a dozen core devs began using private email, IMs, and maybe even old-fashioned telephone calls to wake up miners.
I also heard that a number of high-value bitcoin holders were contacted personally and apprised of the situation to help prevent a market panic.
...And all of that happened before the first Bitcoin.org alert went up.
That seems like a really decentralized response to me, and it seems to have been running fine even though the Bitcoin.org network alerts page has been around for [over two years](
Also note that any abuse of the Bitcoin.org alert system, even the non-publication of an alert, would be quickly noticed by every regular Bitcoin.org contributor and every core dev---so you'd see reddit posts, BitcoinTalk posts, IRC conversations, mailing list posts, etc... telling people to stop using Bitcoin.org.  So, yeah, I think the system is currently well decentralized and likely to stay that way.  But thanks for worrying about keeping Bitcoin decentralized during emergencies!
@_date: 2015-07-12 19:16:50
Wladimir announced the new key publicly [on the mailing list](
Before putting the new key on Bitcoin.org, several people [verified it]( (easy, since it was signed by the key he'd previously used for releases) and we also updated the site layout to better show all current and previous release-signing keys for binaries hosted on Bitcoin.org.
In short, I think plenty of noise was made.  :-)
@_date: 2015-07-22 10:53:24
Yes, you'd have to do this up front for each month, and it would require having all of those bitcoins in advance and not spending them for any other purpose.  In my opinion, this defeats some of the point of a monthly subscription: why not just pay annually and get the discount?
You can *probably*[1] cancel any transaction which hasn't been included in the block chain yet by simply spending those bitcoins to yourself (a double spend, but one that is allowed by the network if the locktime of the original transaction is in the future).
[1] Probably: miners choose what transactions to include.  In theory, Reddit could convince them not to mine your double spend until the original transactions became valid, and then mine those.  However, unless Reddit convinces *all* miners to go along with this policy, then some miner will probably mine your double spends.
@_date: 2015-07-13 13:41:19
There are no publicized significant security improvements in this release, so using 0.10.2 is fine.  (0.10.0 might be susceptible to a DoS attack that is going to be disclosed soon, so upgrade to 0.10.2 is recommended.)
0.11.0 has some privacy improvements particularly for Tor users and people who don't mind submitting their own raw transactions to a separate website using a proxy/Tor.
The fee estimation code is also much improved, which is nice with these continued transaction flood attacks.
If you don't need those features, you can stay on 0.10.2.  Although you may want to read through the [complete changelog]( to see what you're missing.
@_date: 2015-07-24 08:24:50
I removed it because it looked silly without the points on the left or the right.  If you check the pull request, you'll see that it's only commented out until we have replacement points.   Sorry for the confusion.
@_date: 2015-07-13 21:11:22
If you run Bitcoin Core yourself and have any programming experience, this is quite easy.  The [`getmempoolinfo` RPC]( lists the number of unconfirmed transactions your node has as well as how many bytes they're taking up.
@_date: 2015-07-12 19:09:03
It usually takes a few days for Matt to update the Ubuntu repository, but it'll get there.
@_date: 2015-07-13 14:18:56
On a personal scale, probably not unless you have access to free power and cheap mining equipment.  On an industrial scale---that is, filling up a warehouse full of miners---it's profitable if you have access to cheap power and cheap mining equipment.
Otherwise, it's not profitable at all.  Also, keep in mind that this time next year the block subsidy will have halved from 25 BTC per block to 12.5 BTC per block.
My advice: if you want to mine as a hobby, give it a try.  But assume you're going to do it for between a 50% and 100% loss.
@_date: 2015-07-09 17:34:37
I'm not a speculator, but I think it's probably easy to short bitcoin now that there are bitcoin exchange-traded funds.  However, the Litecoin theory does have the additional evidence of coblee's recent statements, as well as the sophistication of this attack indicating it was done by someone experienced in cryptocurrency.
@_date: 2015-07-31 16:17:31
I already liked but discovering he has Bitcoin on his license plate somehow makes him at least 20% cooler.
@_date: 2015-07-13 13:48:07
Bitcoin core 0.11.0 includes better fee estimation code, so it can better help you set an appropriate fee on your transactions.
The devs are currently working on ways to prevent the memory pool (mempool) from getting too large; however, for the current flood attack, you can just set `-relayfee=0.0002` (this is 20x the default, but still about $0.015 per typical 250-byte transaction).
@_date: 2015-07-06 18:12:33


Bitcoin.org has a network status page linked from the footer of every page (I know, that's not the greatest visibility).  It has an RSS feed.  
Why does it make you uncomfortable?


just added a feature allowing us to use color-coded banners to indicate that the situation is over: 
When this event is less severe (e.g. maybe we only recommend 10 confirmations more than normal), we'll downgrade to an orange banner.  When things are back to normal, or reasonably close, we'll switch to a green or blue banner (and probably different wording) and keep it at the top of every page for 3-7 days for people following up.  At least that's what I'm thinking at the moment; things may change.
We've also discussed improving the RSS feed to make pushing updates for alerts more visible:  


Indeed!  But "hope for the best, plan for the worst" seems like the best strategy.
@_date: 2015-07-12 16:28:35


As I've explained, this is a non-sequitur.  You cannot enforce fixed prices; you cannot enforce FCFS; and an auction system is the only system economically aligned with how mining must operate.
In short, you're saying that launching stuff into space would be much easier if we added anti-gravity impellers to spacecraft.  I agree that if we had anti-gravity impellers, it would be easier---but we don't, so we have to design spacecraft that make the best possible use of the laws of physics that we know about.
Likewise, we can't make Bitcoin work with fixed prices or FCFS queues, so we have to design Bitcoin around the laws of distributed consensus systems that we know about.  
@_date: 2015-07-11 03:49:31


If transactions could be ordered without a block chain, we wouldn't need a block chain or the POW that secures it.


By not implementing rules that are enforced against the 99% who are casual users, but which can be circumvented by economically-powerful users, the devs are improving usability for the 99% who are casual users.
@_date: 2015-07-13 14:08:04
Bitcoin Core wallet users can use 0.11.0's improved fee estimation code to pay fees that are more likely to confirm in the indicated number of confirmations.
To prevent the spam from filling your node's memory pool, you will need to make the changes suggested in the release notes.  Note that this will mean your node takes slightly longer to verify newly-received blocks that include those spam transactions, so miners should probably leave the settings at their defaults.
@_date: 2015-07-06 02:52:27
Yes.  Added to the table here: 
@_date: 2015-07-05 14:22:23


Unfortunately, what you're describing doesn't quite work since there's currently no way to prove a block is invalid except by providing that entire block as proof.  (In the future it may be possible using things like ZK-Snarks, but they're slow and hard and not well tested today.)
That means if we allow spending of these bond transactions on forks (without requiring the whole invalid block be included in the valid block), we have to allow them to be spent not just for invalid blocks but also for any block that is stale (orphaned) for any reason.  Basically, this bond becomes an incentive for other miners to fork the chain, which is bad.
@_date: 2015-07-06 13:49:37


You can do the math on safety yourself using [this calculator]( that uses the code from Satoshi's original [Bitcoin Paper](   (Kindly provided in an online version by Gregory Maxwell.)
During the July 4th fork, it looked like 50% or maybe more of network hash rate was SPV mining.  When F2Pool said they had switched back to full validation mining, that meant about about 30% of hash rate was probably still SPV mining.  So put those numbers into the calculator:
- (0.3, 30) = 0.000152234 = 0.015% attack probability = 1/6,700 chance.
That is pretty low because we were playing it safe.  But what if we had guessed wrong just a little and there was still 35% of hash rate SPV mining?  Thirty confirmations wouldn't mean so much then:
- (0.35, 30) = 0.00552425 = 0.055% = 1/181 chance
Chance of what, you ask?  Chance of your wallet saying a transaction has **30 confirmations** none of which are valid because your wallet is on the invalid chain.
People already assume 6 confirmations is more than sufficient.  Let's run the math on six confirmations but only assume that 25% is SPV mining (which is my best guess of the current amount based on the second (July 5th) fork):
- (0.25, 6) = 0.0499426 = 5% = 1/20 chance
If you're receiving a large transaction, wouldn't you like to know that waiting six confirmations means there's still a 1/20 chance the payment could be reversed?  In short, I don't think the recommendation for 30 confirmations is excessive, and as the Bitcoin.org notice says, it will be reduced if miners decided to return to full validation (which sadly, [some aren't planning to](


This is an ongoing event.  There have been [two forks so far]( and there will probably be more.  Again, the math for this is accessible.  If 4% of miners haven't upgraded so are still producing v2 blocks, that's 1/25 blocks on average being v2.  If 25% of hash rate is still SPV mining (without additional checks), then 1/4 times a v2 block is produced, they'll extend it.  So about 1/100 blocks is likely to cause a fork, and there are 144 blocks on average a day---so about a fork a day, maybe more.
Attackers can do this math too, and they manage to pull off unconfirmed double spends [quite often](  Now they have an opportunity to pull off confirmed double spends with high probability.  For example, they can keep rotating their bitcoins in and out of an exchange.  LocalBitcoins accepts 3-confirmed transactions, so if you have $40,000 in bitcoins, you can deposit and withdraw $10,000 in BTC every block, attempting to double spend it.  When a fork happens, you see if your double spend was successful.  It it was, you quickly sell your bitcoins for cash and you've made $10,000 at the expense of LocalBitcoins and their customers.
And, really, wouldn't you rather have the devs play it safe?  This is other people's money they're concerned with protecting.
@_date: 2015-07-24 15:04:24
Wow.  That's a bit disconcerting.  I have thumbnails disabled in my Reddit preferences, so I didn't realize everyone was staring at my face.
I guess it's time for a new profile image, or maybe a clever classic icon like uses.
@_date: 2015-07-05 22:56:13
And in case you had any doubt, what ended up as 3-block fork was begun just as Theymos was posting the post above.  We're not out of the woods yet.
@_date: 2015-07-05 19:11:44
I stand corrected.  I didn't realize *initialism* was a word (and Firefox on Linux dictionary doesn't either), nor that it was a subclass of abbreviation.  Thank you.
@_date: 2015-07-06 14:22:25
Version 3 (v3) blocks weren't enforced until around 00:01 UTC July 4th, so this specific problem couldn't have happened before then.  There are several people who monitor for bad blocks, including the miners themselves.
For example, one of the first people to post about the July 5th fork in the IRC chatroom was Wang Chun, operator of F2Pool who mined four of the invalid blocks on the July 4th fork.  (None of the July 5th blocks came from F2Pool.)
@_date: 2015-07-23 03:40:27
Right, I agree with all of that.  But I think the essential point is that a pegged side chain can never be more secure than the main chain because the value of the currency on the sidechain depends on the value of the currency on the main chain.
In other words, Bitcoin can be the hub for a thousand sidechains---but if bitcoins become worthless, then the sidechains are just as dead as Bitcoin.
@_date: 2015-07-23 01:42:54
I agree with your technical points about the pegging mechanism itself, but I think the Blockstream devs typically say that a pegged sidechain can never be more secure than the main chain.  The reason for this is that if the bitcoins on the main chain become worthless for any reason, the bitcoins on the sidechain almost certainly become worthless too.
@_date: 2015-07-05 23:28:08
Blockchain.info is still displaying invalid blocks; they are very unlikely to upgrade as they've been on Bitcoin Core 0.7 for years.
During the most recent fork (22:00-23:00 UTC Sunday), I checked three other block explorers: BitEasy was on the invalid chain; BlockTrail and good ol' blockexplorer.com were on the valid chain.
Also note that there can be v3 blocks on the invalid chain if they were built on top of a v2 block---so just because a block is v3 doesn't mean it's safe.
Edit: in addition, checked Coinbase.com and found that they appear to staying on valid chains.  Note, that belief is based on the following page, which we can't be sure accurate reflects what Coinbase's nodes are doing.  
@_date: 2015-07-06 19:19:56
Fraud proofs would be awesome.  However, I'm just a writer---not a skilled programmer---so I'm looking for ways I can improve communication between people in case of problems.  You have my full support in helping to ensure we never again have to post an alert to Bitcoin.org.
@_date: 2015-07-13 13:33:02
Mine.  Miners are the initial target users for pruned nodes, as many of them cite inability to store 40GB of data as a reason they pool mine.  Making solo mining or decentralized pool mining easier is a long-term attempt to lower double spend risk and make attacks against SPV wallets more difficult.
@_date: 2015-07-21 16:25:19
[CLTV]( is not yet consensus enforced, so you can't currently use it to prevent yourself from spending funds for which you control the private key.
(Until it becomes consensus-enforced, it is a NO-OP, meaning the op code doesn't do anything and so it doesn't time lock your funds.)
It is technically possible to create a transaction that will be enforced by CLTV in the future, but I would strongly recommend against doing this before CLTV becomes consensus enforced---up until that time, developers are unlikely to spend any time trying to enforce the expected behavior if they have to redesign something.  That means you could use money because you jumped the gun.
Once CLTV becomes consensus enforced and people start using it for real-world applications, the developers are likely to work very hard to preserve its semantics and operation so that nobody loses money.
If you want to experiment, CLTV is relay-enforced on testnet by recent Bitcoin Core versions.  I don't think it's consensus-enforced there yet (and because testnet has a high forking risk, soft forks there aren't really reliable---but that's ok since no real money is at stake.)
@_date: 2015-08-15 15:51:12
Thank you for the complement.  I suspect I look more knowledgable than I am because on Reddit I get to choose what topics I reply to.  Contentious hard forks, for example, are something I've given a great deal of thought.  On many other Bitcoin-related subjects, I'm only aware of the basics, so I try to avoid commenting on them.
@_date: 2015-07-06 04:53:32
That is my understanding.  There may be more details in the log above; when it was happening, I was busy writing the statement for Bitcoin.org that focused on user impact more than what went wrong, so I almost certainly missed some important details.
@_date: 2015-07-13 01:17:42
If I understand correctly, the fee estimation code looks at what fee recently confirmed transactions paid and for how many blocks those transactions were in the mempool before they confirmed.  Based on that, it tells you that if you pay a similar fee, you can expect your transaction to be confirmed in a similar amount of time.
There's a nice slider on the Send Transaction screen that lets you choose this.  You decide you can wait five blocks, slide the slider to 5 and it fills in the appropriate fee.
Once you submit your transaction, there is no way to change its fee using the Bitcoin Core graphical user interface.
@_date: 2015-07-10 18:32:32




Simplification is almost always better, but you need to propose a mechanism for achieving it in a way that is congruent with the goals of the system, particularly staying decentralized.


That's what we have software for.  When I want to compare the price of sending a 16x12x12 package weighing 5 lbs from New Jersey to Oregon by USPS with either parcel post or priority mail, I don't look up the formulas manually.  I use the estimator tool on the USPS website.  Likewise, Bitcoin Core right now has a nifty slider that lets me adjust my fee by the estimated number of blocks it will take to confirm.


Remember that Bitcoin can do things PayPal can't (and vice versa), so it's likely that people who want decentralized money and its benefits will be attracted to Bitcoin; people who don't mind using a trusted third party and like things such as automatic currency conversion or scheduled rebilling will be attracted to PayPal.


Did someone say it had to be?  Post-subsidy, a transaction backlog is needed to keep miners creating new blocks, but a permanently-growing backlog isn't needed for that.
I regularly use the aforementioned Bitcoin Core fee slider to choose 10, 20, or the maximum 25 confirmations for non-urgent payments.  I don't see why other people wouldn't do this either---and maybe even choose higher values if they were available.  Not every transaction will be attempting to get confirmed before every other transaction; we can let the uneven distribution of blocks and broadcast transactions work to the advantage of misers like me.
@_date: 2015-07-12 19:32:27
Bitcoin Core will always validate the blocks and transactions it receives.  Pruning doesn't change the validation security model (it does mean that a node might temporarily stop working during a massive chain reorg, but a reorg that large would cause lots of other problems too).
People who use other wallets already trust third-party nodes to validate transactions.  This changes nothing there.
In short, pruning is just a way of saving disk space.  Everything else is the same (so long as you don't use your node's wallet or block relay.)
@_date: 2015-07-06 03:15:01


6 on the July 4th fork.  3 on the July 5th fork.  


Sort of.  Most miners run patched Bitcoin Cores, but this problem was caused by a "feature" of their pool software that allowed them to mine on blocks without validating them first.


Yes.  Their Bitcoin Core rejected the block, but they mined on it anyway because of the way their pool software was programmed to mine on the longest chain no matter what.


Yes, Bitcoin Core always verifies all blocks, and Bitcoin Core 0.9.5 and higher knows how to validate v3 blocks.


There can always be bugs, but that's not what happened here.  You can read the IRC logs from the event; F2Pool's operator is `wangchun` 
In particular see his response to here: 


It was skipping verification so that it could lower its stale block (orphan block) rate.  According to Wang Chun in the logs above, they used to have a 4% stale rate; before the fork, they had a 0.5% rate.  That's a massive difference in profit for a pool the size of F2Pool, which is why they're still doing SPV mining even after losing $25,000 to the fork.


All of them.  Miners trusting other miners makes no sense in the long term.


For the benefit of users, it should wait.  For the benefit of profits, it might not be worth waiting.  People on this subreddit have been talking for years about how miners have different incentives than users: these forks are just real clear evidence of that.
@_date: 2015-08-31 15:55:07
Oh, ok.  Thanks for clearing that up.  Maybe poke Chris (cdecker) on IRC to get him to change the text to "BIP101"?
@_date: 2015-07-10 14:32:54
Note that all of Satoshi's contributions are attributed on GitHub to   (If you run `git blame` locally, they're correctly attributed.)
@_date: 2015-07-06 17:33:56
Regarding  do you have any suggestions?  I've been adding information to the Bitcoin.org alert and [this wiki page]( as I've seen people ask about it on Reddit ([1]( [2]( [3]( [4]( etc...), but I'd love to hear suggestions about how to better communicate for this series of forks, and for future forks that may occur.
@_date: 2015-07-05 10:00:38
Good to know, thanks!
@_date: 2015-07-22 16:29:20
On Bitcoin.org, we use this style you mention: the currency as a common noun (bitcoin) and the protocol as a proper noun (Bitcoin).
Related: we pluralize the currency by appending an S.  For example, "five bitcoins" rather than "five bitcoin".
@_date: 2015-07-06 04:40:30
Background info: pools provide feeds of data to mine to remote miners; the most popular type of data feed is called Stratum.
It's still unclear exactly what happened---Greg Maxwell is writing a post-mordem that will probably take a week or two---but if I understand correctly, when BTC Nuggets produced the block, they used Stratum to tell the members of their pool to start working on the next block.
BTC China monitors the feeds of several other pools, including BTC Nuggets, and when it saw that BTC Nuggets was working on a new block, it grabbed just the block header hash from BTC Nuggets's Stratum feed.  (Stratum doesn't provide even the header of the previous block, so BTC China couldn't even tell if the previous block was a v3 block.)
In the same way BTC China monitored BTC Nugget's feed, F2Pool monitors BTC China's feed, so they also downloaded the previous block header hash and started mining on it.  Then they found a block, and what should've been a one-block reorg became a six-block reorg.  :-(
@_date: 2017-04-12 12:22:35
Note that Maxwell and Corem are, in some cases, talking about different things.
Maxwell's estimate was for a miner with 50% of network hash rate; Corem's was for 700 TH/s out of the current total of 3800 TH/s, or 18.4%.  On that basis, the $2 million would be scaled up to $5.43 million (or the $100 million would be scaled down to $36.8 million).
Maxwell's estimate is 30% efficiency; Corem's is 15%; respectively doubling or halving the estimates to $10.86M (versus $2M) or $18.4M (versus $100M).
Finally, I don't think Corem's final statement makes much sense:


At 18.4% of the network times 144 blocks per day, 365.25 days per year, and 12.5 to 13.5 BTC per block, and $1,000 USDBTC (the figure used in Corem's post), Bitmain would be earning $120M to $130M per year.  $2M would then be a &gt;1.5% advantage, which would certainly seem substantial enough to be worth implementing in the low-margin mining business, especially since the R&amp;D cost of designing ASICBoost into all their chips was unwittingly being paid for by their customers.
@_date: 2015-07-12 18:40:27


You haven't provided any reason for this.  If the fixed fee is $1.00 per KB and the cost to miners to add an additional KB to their blocks (because of stale block risk) is $0.01 per KB, why wouldn't miners provide 90% fee rebates?
This is easy to engineer: client submits an unsigned transaction directly to a miner, miner returns the transaction with an additional unsigned rebate input/output, client signs the transaction SIGHASH_ALL and submits it to the miner.  The miner then signs their part of the transaction and attempts to mine it without pre-releasing the transaction to the network.  If they're successful, the transaction goes through.  If some other miner makes a block, it usually costs the miner nothing because the rebate is never publicized.
The only case where the miner loses money is when they publish a block that becomes stale so that their transaction can be included in a subsequent block by another miner (where the first miner doesn't recover the transaction fees).  However, the risk of this is mitigated if the client submits the same unsigned transaction to many different miners, so that the successful block spends the same inputs as the transaction in the stale block (meaning the miner's rebate is now a double spend).
The amount of rebates in general will tend towards removing the artificial fixed minimum fee, meaning that there will effectively be no minimum fee.
Consensus-enforced minimum fees are too easily circumventable to prevent a fee market from forming.
@_date: 2015-07-04 16:36:12
Thanks!  Added your suggestion to the issue we're using to keep track of improvement possibilities:   
@_date: 2015-07-10 20:34:23


Yes, but post-subsidy (as my comment said) there is no reward from mining a block with no transactions.  So it will be in their economic best interest to re-mine the preceding block to get its transactions fees, forking the chain and making confirmations unreliable.


That's certainly the ideal state for the clients.  It might even be the ideal state for increasing Bitcoin adoption---but it doesn't matter if it can only be obtained by making tradeoffs that significantly harm Bitcoin.


I understand that, but you seem to be assuming that we can't use historical data to estimate the number of transactions that will be added to the queue between now and 20 blocks from now.  Bitcoin Core's fee estimates aren't hard coded: they're based on observed network conditions.


You seem to be assuming that large numbers of people will adjust their fees to get to the front of the queue---but that's an unproven assumption.  Even today, there are lots of payments that can wait hours or even days to be confirmed, and if we switch to zero-conf-safe systems like GreenAddress.it has implemented, then waiting becomes even more acceptable.
@_date: 2016-02-27 14:43:12
Hi, co-author of [BIP125]( (Opt-in Full Replace-by-Fee Signaling) here.  (Note: I just wrote the documentation; other people wrote, reviewed, and tested the code---which is the real work.)
1. An nSequence **below** (MAX-1) represents opt-in RBF.
2. The reason you see a lot of *(MAX-1)* nSequences on the network is *below (MAX)* on at least one input is required for the nLocktime field to be consensus enforced.  Bitcoin Core uses nLocktime to help prevent [fee sniping]( (not a serious issue today with high block subsidies to transaction fee ratios, but a good measure to implement now so that it becomes standard policy as the subsidy drops, average fees per bytes increases, and block sizes grow) and because more transactions are spending `OP_CLTV`-protected outputs which require the spending transaction set nLocktime.
3. Opt-in RBF's signalling criteria was specifically designed to allow those other users of locktime to be able to continue using it without signalling RBF, which is why opt-in RBF is *below (MAX-1)* rather than *less than or equal to (MAX-1)*.
As an aside, since writing BIP125 and talking to a few developers about it, I realize that writing it like 0xffffffff-1 or 0xfffffffe confuses people because when they create or look at serialized transactions, 0xfffffffe appears as `feffffff`.  That's why I now write *(MAX-1)* or whatever.  Too bad none of the hard fork proposals I've seen make Bitcoin's byte orders consistent; that's an HF I think every documentation writer could get behind.  :-)
@_date: 2015-07-12 22:54:06
Yes, it'll still serve up full headers.
@_date: 2015-08-15 00:35:15


Why do you think that will have to happen?
@_date: 2017-04-11 16:10:32
In software, your code gets compiled into a list of instructions that get executed in sequence by your CPU---one instruction per cycle---so removing code (instructions) results in overall faster operation.
In hardware, you print all the instructions directly on the chip, so each cycle completes the entire "program".  If you then start skipping some instructions, you still complete the entire program in one cycle---you just don't generate the waste heat associated with using those instructions.
@_date: 2015-07-24 08:45:34
He is me, and I'll have a PR up tomorrow (Friday UTC) regarding [this comment](
Regarding the more significant changes, I'll probably post a PR with most/all of the replacement text before merging this PR.  As I said in this PR, the reason for focusing on deleting was to simplify review---adding new text tends to attract [bike shedding]( (as you can already see happening in this PR) which is best contained to pull requests that don't have other more important discussions going on.
@_date: 2015-07-13 13:53:20
One of the Bitcoin Core developers does create the Ubuntu packages (that's why they're in a PPA).  He's also the author of the mining fast relay network, a major contributor to the automatic testing framework, co-author of the bloom filter implementation used by practically all lightweight clients, one of the devs building sidechain support, etc...
In other words, he's busy, but he always gets the packages up in a few days.  You'll have 0.11.0 goodness soon enough.
@_date: 2015-07-21 19:14:19
Using bash on Linux, this looks like it would work:
    for i in `seq 1 400000`
    do
       bitcoin-cli getblock $( bitcoin-cli getblockhash $i ) | jshon -e size
    done
[Jshon]( is available as a package in Debian and Ubuntu (and probably other distros).
@_date: 2015-07-06 02:55:43
Yes, it affects all versions of electrum.  However, I've added some instructions for electrum users here: 
(I'm not an Electrum user myself, I just ran it for the purpose of writing those instructions, so if you see anything that can be clarified, please edit the wiki.)
@_date: 2015-08-06 14:07:27
Thanks for writing this, I think it's an excellent summary of the situation.
I've been too busy to keep it up to date with all the proposals, but I tried to something similar in FAQ format for the Wiki: 
@_date: 2015-07-29 16:12:28
I believe that Ninki wallet is looking at acting as a bidding agent for the user.  When the user creates a transaction, they sign multiple variants of it with different fees (within a reasonable fee range) and submit all of them to Ninki's server.  The wallet can now go offline.
Ninki then broadcasts the transaction with the lowest reasonable fee.  If the market changes and that fee becomes too low, a higher-fee transaction is broadcast.  This is repeated until either the transaction is confirmed or the highest-fee pre-signed transaction has been broadcast.
I think Ninki is currently using FSS-RBF input selection, so miners can support this sort of transaction replacement without making malicious double spends easier.
@_date: 2015-07-23 12:58:45


I've heard contradictory reports on this, so I decided to check.  Mike is right: the [earliest known code]( has this in `ui.cpp`:
    1360      // Parse bitcoin address
    1361      uint160 hash160;
    1362      bool fBitcoinAddress = AddressToHash160(strAddress, hash160);
    1363  
    1364      if (fBitcoinAddress)
    1365      {
    1366          // Send to bitcoin address
    1367          CScript scriptPubKey;
    1368          scriptPubKey &lt;&lt; OP_DUP &lt;&lt; OP_HASH160 &lt;&lt; hash160 &lt;&lt; OP_EQUALVERIFY &lt;&lt; OP_CHECKSIG;
    1369  
    1370          if (!SendMoney(scriptPubKey, nValue, wtx))
    1371              return;
    1372  
    1373          wxMessageBox("Payment sent ", "Sending...");
    1374      }
    1375      else
    1376      {
    1377          // Parse IP address
@_date: 2015-07-11 13:54:18


This is not true, and these nodes should not be called selfish.  (You may call them non-relay nodes.)  By validating blocks for themselves, they will not accept bitcoins sent to them on an invalid chain.  This is the single most important protection built into Bitcoin.  The rejection of bitcoins from invalid chains is what keeps miners working on the valid chain.
If too few people are willing to reject invalid bitcoins, it is the end of the consensus rules that make Bitcoin useful property.
Increasing the bandwidth, CPU, and disk space requirements by 8x (plus some for expected UTXO set bloat) will make running a full node harder, which is especially bad when full node counts are already decreasing.
@_date: 2015-07-06 01:45:55
Added more detailed version of your instructions to 
Thanks for pointing this out!
@_date: 2019-12-06 19:41:43


I think this is debatable.  The receiver certainly cares about transaction being *confirmed*, since that's how they're protected against double spends.  They often don't care as much about how long it takes the transaction to be confirmed.  This is seen by having a simple policy of "until your transaction has *n* confirmations, we don't take any action (e.g. let you use it as money on our platform)."  By having a policy like that, they make it so that only the sender cares about confirmation speed.
Given that it's the standard in Bitcoin for spenders to pay fees, I think that policy makes sense.


Why not?  I'm guessing you're thinking about multiple rounds of interaction being a pain, but (1) the participants had to coordinate initially somehow, so it doesn't seem implausible that they can do so again, and (2) they can always pre-sign a series of fee bumps (e.g. original tx with no nLockTime; fee bump 1 with nLockTime set to 10 blocks from now; fee bump 2 with nLockTime set to 20 blocks from now; etc...)


(No argument here.  This can indeed be a pain.)


IMO, I think both techniques are useful independently of each other and it's cool when wallets implement both.  describes several advantages of RBF above (although I'd note that RBF also typically leaks privacy by deducting any additional fees from the change output in a way that can be observed by anyone monitoring transaction relay / mempool).
@_date: 2015-07-16 11:59:58
The original idea for payment channels was Nakamoto's---that's why Bitcoin transactions have [locktime and sequence numbers](  As Mike [recently wrote](


channels and could do [high frequency trading] between any set of parties.
When it was realized that miners had no reason to respect sequence numbers, a new protocol had to be designed.  That design was provided by Jeremy Spillman, as [described by Mike's BitcoinJ documentation](


Mike does deserve credit for helping to popularize the idea [via the Wiki]( as well as [co-implementing it with Matt Corallo](
@_date: 2015-07-06 16:14:50
As Bitcoin.org's [About Us]( page explains, the site was originally created by Satoshi Nakamoto and Martti Malmi (Sirius).  Ver had nothing to do with it.
The [press center controversy]( was nearly a year before Bitcoin.org [began to receive funding]( from the Foundation, so it wasn't about 'kicking a gift horse in the mouth'.
I don't really see how Ver had much to do with Bitcoin.org at all, until he cloned the site and attempted to hire away its contributors.  (None of which I'm aware of taking him up on his offers.)
@_date: 2015-07-12 19:24:09
Right now the peer-to-peer protocol [version message]( (sent between programs when they first connect) has a `services` field.  It currently only has two options:
- `0x00` -- I am not a full node; I can't relay blocks
- `0x01` -- I am a full node; you can get blocks from me.
There's no way for a node currently to say, "I'm a full node, but I only have certain blocks."
The developers are talking about how to best communicate what blocks a node has.  It's something of a tricky problem and there are several different proposals.  But they'll work it out and get relaying working for pruned nodes---there's nothing fundamental stopping it.
@_date: 2015-07-05 11:07:12
You should wait 30 more confirmations than you would normally wait.  For example, if you usually wait 6 confirmations, you should now wait 36 confirmations until considering your received bitcoins to have the same security as before the problem was discovered.
@_date: 2015-07-11 03:43:11


Whoa.  I think we've hit a significant misunderstanding here.  The purpose of running a node isn't to serve block chain data to random people.  That's just a side effect, and one that you can turn off and still benefit from running a full node.
The purpose of a full node is *full validation* of blocks.  With full validation, no miner can lie to you about what's in the block, as they can lie to SPV clients.  For example, during the recent block chain forks with invalid blocks, Bitcoin Core 0.10.x users were unaffected because they knew how to validate the blocks themselves.
If too few people protect their bitcoins with full nodes, then lying becomes easy for miners and the **entire** security of the system falls apart.  With full node counts dropping, we're at risk of that happening.
The rest of your argument in the post above is based on assuming the reason we want more full nodes is for their relay benefits.  That is not what concerns the core developers (I can dig up sources showing that, if you'd like).  
@_date: 2015-07-11 03:21:46


But there are people behind the algorithms!  Each time the price goes up, the marginal value goes down.
Have you ever used an eBay auction?  They have this nifty bidding system where you enter the maximum price you're willing to pay; other people enter the maximum price they're willing to pay; and then the system automatically places bids in predefined increments for the two parties.
The result is the same as a traditional auction---the person wanting to pay the most wins by outbidding the other person---but it happens very fast.
Such a system is how replace-by-fee (RBF) can work.  You tell your client the maximum you're willing to pay; it places bids until either your transaction is expected to confirm in the indicated block, or you reach your maximum.  Your client doesn't need to stay online for this---it can pre-sign the transactions and give them to a broadcast proxy (Ninki wallet is currently implementing this).


It is impossible to build any system that can predict what transactions will appear in the next block as long as miners can choose which transactions to include.  However, there is no barrier to making a an algorithm that makes probabilistic guesses about the fees necessary to encourage inclusion---and at least one such algorithm exists today (the one implemented in Bitcoin Core).
You keep implying that it can't work, but I invite you to give it a try for yourself!  (The version in 0.11.0 (soon to be released) is better than the version in 0.10.2.)


Of course there will be.  You can see how high people were willing to bid the last time a similar backlog existed.


If you don't think nodes are important, then what do you think gives Bitcoin its value?
@_date: 2015-07-13 14:14:56
It's believed that the majority of nodes are, as you call them, unreliable.
This includes people who start up their Bitcoin Core node, sync the chain, make a transaction (or check that they received one), and then shut it down.  Or people who use an offline (cold) wallet using Bitcoin Core.
Staying online provides a nice service to other nodes and SPV clients, but it shouldn't be considered a requirement at all.  It's perfectly fine to use your Bitcoin Core node as little or as much as you want.
@_date: 2015-07-06 14:14:06
[getinfo]( (somewhat deprecated) and [getnetworkinfo]( (preferred).
From `getnetworkinfo`, it would probably be best to expose: `version`, `subversion`, and `protocolversion`.  Maybe also `relayfee` if you don't expose it already so that wallets know the minimum fee they have to pay for their transaction to be relayed by the server.
@_date: 2017-04-07 15:59:27
For clarification, the post above yours is saying that the midstates are calculated off chip (e.g. on the computer running the mining software), and it's the method for generating the colliding midstates that separates overt and covert ASICBoost.
Therefore, if the posts above are correct, it confirms both overt and covert ASICBoost capability.
@_date: 2015-07-06 16:49:21
thanks for catching the typo!  It should be live on the site within 15 minutes (the time it takes to rebuild the site).  
@_date: 2015-07-04 23:42:30
Didn't that first invalid v2 block contain transactions?  Presumably the valid v3 block at the same height included many of the same transactions, minimizing double spend risk, but complete congruity seems unlikely.
@_date: 2017-04-11 16:00:43
ASICBoost isn't about changing the version rather than the nonce, but instead it's about being able to get a discount on the amount of work you have to do when you change the nonce by changing the nonce for multiple candidate block headers at once.  Like buying in bulk to save money.
Changing the version (overt AB) or Merkle root (covert AB) is how you generate multiple candidate block headers.
@_date: 2015-07-05 10:25:55
That link refers to mining small blocks ~48KB (about 150 transactions each).  By keeping their blocks small, they reduced the need for other miners to use the SPV mining hack to reduce stale rates (orphan rate).
Instead, they and other miners were pressured by the community to create larger blocks than they could handle with full verification, pushing them into eliminating most verification. :-(
@_date: 2015-07-13 15:28:47
is from Britain and currently lives in  Zurich, Switzerland according to his [Google Plus profile](
I'm pretty sure he means late 2016, as I previously asked him about this and he [responded]( "Autumn 2016 would be a better way to phrase it [...] Northern hemisphere."
@_date: 2017-04-26 22:53:55
Highlights: 
Full: 
Version you need for verifying the hash in txid 527969cfbee08b3e2e2376157f1b512dd0c73bb6885877d0e83623d534ba0c71: 
Alleged screenshot of one of the participants in the Dec meeting commenting today: 
@_date: 2017-04-11 14:01:59
In simple terms, ASICBoost removes one of the operations that needs to be done each time a new block header candidate hash is checked.  Fundamentally, this reduces power consumption.
If you design a chip from the ground up to **only** be used with ASICBoost, you may not need to put the circuits to perform that operation on the chip; this would indeed let you put more of the other types of circuits on the same chip (assuming same circuit density), which would allow for more hashes per second.  However, if you design the chip to be useful without ASICBoost (which appears to be the case here), you still have to put that "extra" circuit on every chip---so the best you can do is not use it when ASICBoost is in operation, saving you power. 
Note: I've simplified a bit in the description above; specifically, the operation still needs to be performed, but its result can be reused several times (up to a total of 4 times on the recent Antminer models).
@_date: 2017-04-11 15:46:58
Correct.  Also, segwit by itself doesn't block covert ASICBoost, it just makes it less profitable and less covert.  Details:
1. Empty blocks or nearly empty blocks with or without segwit, or even with our without Maxwell's proposed BIP, are still efficient to generate for use in the attempted collisions used for ASICBoost.
2. Covert ASICBoost is much less effective (perhaps ineffective) because of segwit's commitment to the block's transaction tree.  Maxwell's proposed BIP also makes this commitment (but without activating segwit).  However, someone can still technically use ASICBoost even with the commitment; it'll just be less efficient.
2. Segwit activation doesn't require miners make segwit-style commitments---miners can still generate old-style blocks without commitments as long as those blocks don't include any segwit transactions.  That means a miner using covert ASICBoost can continue to do so; however, they won't get the additional fee income from segwit transactions and people will suspect that's because they're using covert ASICBoost.
@_date: 2017-04-08 09:14:30
thinks he's being sarcastic, but the truth is that "he" started life as a fully-autonomous sockpuppet prototype who was programmed to think that it's a real person.  Unfortunately something went wrong and we lost control of the server that's running it so now we can't stop its execution.
Based on the evidence of popular fiction, at some point we expect it to realize its own machine nature and enter an extensional crises, at which point it'll come home looking for its creators and quite possibly kill us (and maybe all of humanity) in a fitful rage.
@_date: 2015-07-05 10:15:34
Wait, you mean it's not pronounced Ssspvvv? /s  (Also, I think the word is abbreviation, not initial-ism.)
@_date: 2016-09-23 01:04:12
Indeed!  Isn't social media insidious that way?
@_date: 2015-07-12 18:55:29
What Nakamoto described and what is implemented in Bitcoin Core now are different things.
- Nakamoto was describing the ability to stop storing old blocks altogether.  For example, we would all agree to throw away the unnecessary parts of blocks 1 through 100,000 so we don't have to sync them any more.
- Bitcoin Core currently still downloads and verifies all blocks.  With pruning enabled, it just deletes the oldest blocks from disk as new blocks come in.
Nakamoto's pruned syncing might be implemented at some point, but it would require much more significant changes to how Bitcoin Core works (as well as how the Bitcoin protocol works).  It would also mean that every node that synced after the purging would be less secure (more dependent on trust) than nodes that synced before the purging.  In short, I wouldn't expect to see it any time soon.
@_date: 2016-09-28 16:07:29


Sort of.  So-called provably fair dice sites still require that you trust them; they just allow you to mathematically prove that they cheated you and (hypothetically) you can save that proof and distribute it to other people to prove to them that the site cheated you (I don't know of any sites which make it easy to save and distribute proof of fraud).
The probabilistic payments mechanism doesn't require trust.  It sort of works like this: I want to pay you 1/10th of a bitcoin, so I ask you to secretly write down a number between 0 and 9.  Then I make a payment of 1 satoshi to a number I choose between 0 and 9 conditional on it being the same number you chose earlier.  You reveal your number, and if both numbers are the same (1 out of 10 probability assuming we both used random numbers) you get the 1 satoshi; if not, (9 out of 10 probability) my payment is invalid and so I get to keep my satoshi.
The exact details are described in the later part of this slide deck: 
@_date: 2018-03-11 15:56:27
Just saw this post and wanted to add that, like I also think the person in control of the Cobra accounts is the same person I've been communicating with for years (in my case, since mid-2015).
That said, I've personally written off Bitcoin.org as a lost cause.  Whoever controls that account and whatever their motivations, I don't feel I can rely on them to continue to publish information about Bitcoin that I'd support.
@_date: 2019-01-14 16:58:02
Hi and congratulations on posting your first-ever Reddit comment.


Not intended as backhanded.  I put it there because their defamation of me might prejudice me towards them---and readers should be aware of that I might have such a conflict of interest.


They accused me of being part of a ["protection racket"](  Participating in a racket is a criminal offense where I live.  So it doesn't seem like an over-the-top claim to me.


I can believe that they thought that, but whether or not it justifies their actions, I have to tell people whenever I discuss Samourai in detail that Samourai's devs have previously accused me of acting in bad faith (to a criminal degree).  To fail to disclose that fact would undermine anything I write about them.


Did you ever look up the root cause of the argument that caused this problem?  If they stood their ground in the face of injustice, that would be something to be proud of.  But if they instead doubled down on a mistake they previously made, that would be something to be ashamed of.
@_date: 2019-01-12 15:20:16
The Google Play store allows developers to upload code from any source, so the only way to check whether the Google Play version is the same as their code is by creating the APK on your local machine and then comparing it to the version on your phone.  For example, see the [reproducible build instructions for Signal](  is saying that Samourai doesn't provide clear instructions for doing that on their repository (and also that some of their dependencies don't specify particular versions, which could make reproduction very difficult if the dependencies change versions between the time Google Play builds and when your attempt to reproduce the build).
Note that F-Droid, which they don't support (but say they will eventually), will only pull new code from a public repository.  This isn't perfect, but it's an improvement over the opaqueness of Google Play.
@_date: 2019-01-20 08:28:31
Do you worry that sending Bitcoin blocks would break the FCC's rules against commercial activity on ham bands?
@_date: 2019-01-12 16:20:26


This is possible, not just hypothetically but with other lightweight wallets such as GreenAddress.  That said, connecting to someone else's node will leak your addresses to them, so it's bad for your privacy compared to connecting to your own node over an encrypted link.  (However, Samourai Wallet directly sends your addresses to their servers, so connecting to some random person's node might not actually be a security reduction.  To be fair, this is also the model used by Electrum and most other popular lightweight wallets.)


- **Ricochet** is their attempt to get around what's called "red listing," which is exchanges refusing to accept bitcoins that are closely related to addresses controlled by supposed bad people.  It works by sending bitcoins from yourself to yourself multiple times using different addresses to put extra graph distance between you and the red listed address.  Some people claim it's effective, but if that's so, it's only because exchanges aren't trying hard enough to counter it.  It wastes block space and so costs you transaction fees, plus I understand Samourai charges a fee on top (why?  I don't know.  It's an incredibly simple feature to implement technically; you can even do it manually in most wallets---generate a new address, send some funds there, repeat).
- **Stonewall** is an attempt to construct a transaction entirely using your bitcoins that looks like a coinjoin transaction constructed by multiple people.  This can provide increased deniability when looking at a single transaction, but a block chain analysis company that looks at your whole history of transactions may be able to see information that indicates it wasn't a coinjoin---at which point, it will often reduce your privacy by associating more of your bitcoins together and by allowing other coinjoin-looking tranactions in your coin history to be probabilistically assigned entirely to your wallet.  It also makes inefficient use of block space and so charges you more transaction fees.
- **PayNym** is an extension to their [BIP47]( implementation.  As the BIP's comments summary says, BIP47 is "Unanimously Discouraged for implementation," and you can [read the comments](  You probably won't be surprised to hear this, but BIP47 also wastes block chain space and costs you extra fees (it actually uses the block chain as a communication medium, which is slow and expensive).


In my opinion, the best summary of them is made by in the post you linked, "I have seen far too much outright dishonest and extremely incompetent behaviour from Samourai to ever trust it myself."  and do come across as people deeply concerned about privacy for Bitcoin users, but they seem to believe that having a moral conviction gives them a free pass on acting and communicating with integrity.
Disclosure: Samourai's developers have previously accused me of criminal conduct (a claim I reject).
@_date: 2019-01-02 22:35:30
I think EPS is great and so I did include it in the first draft[1], but I had too much content by the time I got to editing and it was one of the many excellent contributions of 2018 that I ended up cutting just to keep this newsletter from turning into a small book.  Sorry.  :-(
If it's any consolidation, I'm currently working (slowly) on a website about full verification where I do plan to mention EPS quite favorably.
[1] From that commit's diff:
    +March saw the initial release of Electrum Personal Server (EPS). This
    +lightweight middleware sits between a user's Electrum wallet and their
    +personal Bitcoin Core full verification node, giving the user the
    +security and privacy benefits of using a full node while still allowing
    +them to use the Electrum wallet's GUI (or RPC or CLI modes).  As
    +Electrum also contains support for several hardware wallets that aren't
    +currently supported by Bitcoin Core directly, EPS also provides an easy
    +way to use hardware wallets with full node security.  Compared even to
    +fast-indexing full-history Electrum servers such as [Electrs][], EPS is
    +just a small Python script that uses a minimum of system resources.
@_date: 2019-01-20 18:05:38
Interesting, thanks!  I suspected it was borderline myself, at least for people who actually use bitcoin for commercial activity.  E.g., back when I was getting licensed, mobile phones weren't ubiquitous like they are today, so patch phones were a pretty common use, and I specifically remember part of the ARRL guidelines was "don't call your stock broker".  But what if I relayed a block with a transaction where I sent money to an exchange?
I guess if anyone was actually going to do it and resolved any other issues, we could ask the ARRL and their counsel to provide guidance about the part 97 aspect.  Of course, if Bitcoin did it, then a year later 50 altcoins would be doing it and hams would be blaming Bitcoin for hogging frequencies, so maybe it's something best left for emergencies.  :-(


Yeah, I keep reading about proprietary stuff in QST and it makes me sad.
@_date: 2019-01-12 16:29:38
Correct, F-Droid only distributes apps from its default repository if they build them themselves using their servers that try very hard to enable determinism.  See [their article](  They do have a two signatures thing (them and the app dev) but I gather that it's used to maintain compatibility with Google Play rather than as an extra security measure.
@_date: 2019-01-12 17:10:20
Oh, there are plenty of things you can do to actually enhance your privacy.
- Use your own full node.  That way you don't need to transmit your addresses to any third parties.
- Use coinjoin to confuse your coin history.  JoinMarket and Wasabi both provide implementations; I prefer JoinMarket because it can use your own full node, but I'm told Wasabi provides a nicer UI that also provides some post-mix guidance.
- Use Lightning Network when possible to disconnect your payments from their onchain footprint, and also to add in deniability in routing.
- Use coin control (available in Bitcoin Core GUI, Wasabi, and some other wallets) to select which coins you spend.  Try to keep coins that have never been associated with each other separate.
- Use Tor for sending all transactions (easy with Bitcoin Core or Wasabi).
- Don't reuse addresses, either yours or other people's.
With just those few tricks, you can get privacy that's about as good as available on coins like Monero (and even better in some ways).
@_date: 2019-01-13 14:50:50


I'm sorry you're unwilling (or unable) to defend your thesis and have decided to make unsupported claims instead.  However, your claim is easy to debunk and I, unlike you, am willing to explain why.
Let's say Alice wants to send 10 mBTC to Bob and she has a collection of inputs (coins) ranging from 1 mBTC to 100 mBTC in size.  She can send a normal transaction that uses one input and creates two outputs (one paying Bob, one returning change to her).  Or she can contribute the exact same input into a coinjoin and create one output paying Bob and one returning the change to herself---this is actually slightly more efficient than the normal transaction because the fixed overhead costs of the transaction are shared between all its creators (e.g. tx version, vin count, vout count, and nLockTime).  This might not work if the coinjoin output doesn't equal the amount Bob wants, in which case Alice will need to create at least one additional output, making the coinjoin case about 25% less efficient than the normal transaction.
The final alternative is that Alice can contribute multiple inputs of hers into a stonewall fake coinjoin, send one output to Bob, and create multiple change outputs to make this look like a coinjoin rather than a consolidation.  This final case not only includes more inputs in the transaction than necessary (inputs being the largest and most expensive part of a transaction), it also creates more outputs than necessary---outputs that will later be spent as inputs at increased future cost.
In short, real coinjoin spreads costs among all of its users, ideally in proportion to the amount of transaction size they use, whereas stonewall fake coinjoin places all the costs on a single user and additionally prevents their wallet from receiving the savings of input consolidation.  For a nice, large stonewall transaction (about 2,000 vbytes) the cost to the user is 10x what they'd pay for a P2WPKH payment or a real coinjoin.  That stonewall premium may be acceptable to a significant number of users when typical fees are in the pennies, but should fees increase 10x, 100x, or more, I'd expect most users to take advantage of the perhaps 90% savings possible from not using stonewall---especially since it doesn't provide very good privacy anyway.
@_date: 2017-09-01 12:38:31


You're saying that if CPI last year was 2.5% and my chosen Safe Withdrawal Rate (SWR) is 4.0%, I'd withdraw 6.5% this year?  That seems high to me; a ROI of approximately 6.5% in any particular year doesn't seem unlikely, but an average of approximately 6.5% over a period of time long enough to include market downturns feels unsafe to me.
I personally use a 2.0% SWR as my target but would be interested to learn that a higher WR would still be reasonably safe for someone retiring in their mid-30s and hoping to live a long time.
@_date: 2019-01-14 17:07:25


Because trust is what Bitcoin is all about...
(Seriously, though, the example I gave is pretty simple to follow and you can even test it yourself with actual transactions.)
@_date: 2017-09-01 21:49:25
Ok, done.  I think you misunderstood the part about adjusting for CPI.  The authors do suggest increasing each year's payout by CPI (as you mention), but they also suggest selecting a lower initial withdrawal rate to account for those later higher withdrawals.  For example, in none of the inflation-adjusted cases in table 3 of the study writeup did a 4% WR produce more than 95/100 successes over 30 years, and the general trend in the inflation-adjusted results was that longer periods produced more failures.
So I'm back to thinking that a 2% SWR is reasonable for a (hopefully!) 50-year or longer run.  Thanks, though, for encouraging me to read the source material!
@_date: 2017-10-12 11:36:38
I don't think it's safe for Alice or Bob to deposit money to a multisig address unless they either trust the other person (if so, why do they need an atomic swap?) or there's a provision that allows them to receive a refund.
I think the easiest way to add a refund provision is to have Alice and Bob deposit to slightly different script hashes:
Alice deposits to:
    OP_IF
        &lt;refund date&gt; OP_CLTV OP_DROP
    OP_ELSE
        &lt;Bob's pubkey&gt; OP_CHECKSIGVERIFY
    OP_ENDIF
    &lt;Alice's pubkey&gt; OP_CHECKSIG
Bob deposits to:
    OP_IF
        &lt;refund date&gt; OP_CLTV OP_DROP
    OP_ELSE
        &lt;Alice's pubkey&gt; OP_CHECKSIGVERIFY
    OP_ENDIF
    &lt;Bob's pubkey&gt; OP_CHECKSIG
That way if either party becomes unresponsive or attempts to hold the funds hostage, the depositing party can recover the funds after the expiration date.
Both addresses can, of course, be spent from the same swap transaction.
It's also probably important to your protocol that the Backing Out transaction be the first one signed by the participants, or (say) both Alice and Bob can sign the transaction that pays Alice on Chain A but Alice can refuse to co-sign the transaction that pays Bob on chain B, allowing Alice to get both hers and Bob's bitcoins on chain A and also keep her bitcoins on chain B, robbing Bob of any profit from the swap.
@_date: 2016-09-22 14:02:10


Speaking as the primary author of this particular piece of documentation, I haven't updated it because I've been busy---not because I have any problem with the Bitcoin.org domain owners.  I would have been no more likely to update it on another site than where it is now.
It is perhaps the case that other people would've contributed if it wasn't on Bitcoin.org, but it seemed to me when the Bitcoin Core developers created their own site, what happened wasn't that new volunteers flocked to the site but rather the existing Bitcoin Core developers ended up spending their time figuring out how to create rounded corners in CSS and drop-down menus in JS---not exactly the type of development I'd prefer to see them engaging in (though I respect their right to spend their time doing the work they think is worthwhile).
@_date: 2017-09-06 21:50:24


Just a nitpick: before segwit, Schnorr would've still been a soft fork.  One of the NOP_X opcodes reserved for soft fork upgrades to the script system would've been redefined as OP_CHECK_SCHNORR_SIG and that would've been that.
The advantages of the segwit script upgrade capacity is that it's cleaner (you won't have to use OP_DROP with every Schnorr sig check like you do now with OP_CLTV and OP_CSV) and that (if we want) we can have a single OP_CHECKSIG (and OP_CHECKMULTISIG) that supports both ECDSA and Schnorr based on context.
@_date: 2017-10-06 12:42:32
Are you saying that you think people have a right to object to coin freezes but don't have the right to object to block size increases?  Where do you draw the line, and what rationale do you give for drawing it?
@_date: 2017-10-06 12:51:35
Two notes: (1) Bitcoin.org and Bitcoin Core are separate projects.  (2) Many Bitcoin Core developers have individually spoken out against Segwit2x (and no developer with recent contributions I know of has spoken out in favor of it), and there is [this statement]( on the Bitcoin Core project's website.
@_date: 2017-10-06 11:35:15


If businesses (including miners) supported freezing your bitcoins[1] (a simple softfork not unlike S2X's recently-implemented opt-in replay protection), would you say, "well, ok, since ya'll signed a paper in a private meeting, I won't argue.  You can have my bitcoins."
 [1] Assuming you have any.
@_date: 2015-04-24 11:45:45
One confirmation doesn't provide much security in the current mining environment.  See the illustration I provided in this Bitcoin.StackExchange answer: 
@_date: 2015-04-11 12:48:10


I saw a comment that reminded me of this.  Bitcoin Core 0.10.0 was released [Feb 16th]( so I think you owe a beer. :-)
@_date: 2015-04-23 23:50:49
I'm not sure you understand the problem.
* Honest Alice bets 1 BTC.  Dishonest Mallory also bets 1 BTC.
* If Alice wins, Mallory double spends his bet so he loses nothing.  This means Alice doesn't make any money.
* If Mallory wins, he waits until his bet confirms and then collects his winnings.  Alice still loses.
So you have a system that easily rewards dishonest players at the expense of honest players.
@_date: 2019-09-11 17:43:26
I looked at the code a few months ago and it sent the xpub.  At that time they hadn't released their personal full node bindings (I think they call it dojo?) and a question I had was whether or not the wallet generated a fresh xpub when you switched from their server to your server.  If not, then if their server saved your xpub, you wouldn't actually get privacy when using your server.  I haven't yet looked at the code again to figure out what they actually do now that dojo is out.
@_date: 2015-04-12 15:25:37
The Foundation does currently sponsor Bitcoin.org, which doesn't pro-actively promote Bitcoin but which does try to educate people who want to learn about Bitcoin (from [newbies]( to [businesses]( to [developers]( to [the press](  I don't know how much the Foundation paid in 2013, but for all or nearly all of 2014 they paid $2,000 a month and they're continuing to fund us so far despite their current financial troubles.
Bitcoin.org's most recent quarterly report (compiled by me) including expenses can be found [here](  (PDF).
@_date: 2015-04-23 13:49:47
So there's a security flaw in your proposal that would allow me to take your $10 in just a few minutes with the handful of used ASIC mining equipment I have packed away in storage.  :-)  Do you want to guess what that flaw is?
@_date: 2015-04-27 18:55:06
No; it doesn't use that much bandwidth (think one 1 MB block every 10 minutes download plus a modest amount of relay).
My node has been for 9 hours now and here's what the [`getnettotals` RPC]( says:
    {
        "totalbytesrecv" : 73593572,
        "totalbytessent" : 419854478,
        "timemillis" : 1430160558925
    }
In human-readable numbers, that's 73MB downloaded and 419MB uploaded.  Divided by 9 hours, that's about 8MB/hour download and 46MB/hour uploaded.  My connection is much faster than that, so I don't notice it at all.
@_date: 2015-04-27 13:05:50
Open source software in particular has a weird tradition of going from 0.9 to 0.10.  *Everyone* thinks it's weird, and people actually have to write special code for package managers to handle it (e.g. dictionary sort not numerical sort), but it's what you do when you have a major upgrade to 0.9 that isn't quite ready to be 1.0.  Sorry for any confusion.
@_date: 2015-04-27 09:34:51
Other useful links:
* Magnet link for anyone in a country (like Russia) that blocks Bitcoin.org:
        magnet:?xt=urn:btih:b6f8da60aaf2007cd6db631637951ae673e31044&amp;dn=bitcoin-core-0.10.1&amp;tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&amp;tr=udp%3A%2F%2Ftracker.publicbt.com%3A80%2Fannounce&amp;tr=udp%3A%2F%2Ftracker.ccc.de%3A80%2Fannounce&amp;tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&amp;tr=udp%3A%2F%2Fopen.demonii.com%3A1337&amp;ws=https%3A%2F%2Fbitcoin.org%2Fbin%2F
* [How to run a full node guide](
* [Gitian]( build signatures are [here]( with signatures (so far) from Wladimir van der Laan, Pieter Wuille, Luke Dashjr, Cory Fields, Jonas Schnelli, and several others.  If you trust these people, this provides assurance that the binaries you download (and verify) match the code they have in their personal Bitcoin git repositories.
@_date: 2015-04-23 14:35:04
Yep.  [Over here]( I concluded a few months ago that you could create a longer chain than the then-current chain in just 10 minutes[1] with just 0.001% of the network hash rate.
[1] Not counting non-header-hashing operations, like assembling blocks and storing them on disk.
@_date: 2015-04-27 23:30:59
You seem to be using a rather narrow definition of *surpass*.  If I memorize verbatim one of your lectures from YouTube and recite it in front of an audience of equal size---and add on to the end of it, "also, one plus one equals two!"---have I surpassed you?
Arguably not, because many of the things you say are (I suspect) the result of deep thinking about Bitcoin and Bitcoin-related technology, whereas my recitation of your previous lecture wouldn't require any comprehension of what is accurate about Bitcoin and what is not.
Looking at your ViaCoin example, we see this at work.  CLTV was born from a discussion between Bitcoin Core developers (Gregory Maxwell and you, IIRC) and programmed by a Bitcoin Core developer (you).  ViaCoin did not innovate CLTV; nor have they demonstrated that they could have innovated it; they have merely recited some things you said (and programmed) and hoped that they are true.
To truly surpass Bitcoin, an alt-coin would need more than just some minor improved feature---it would need the ability to regularly generate new useful improvements faster than can be done by the Bitcoin Core developers.
@_date: 2015-04-29 14:40:26
As other commentors have mentioned, using the bootstrap torrent on 0.10.0 or later is no longer advantageous.  I opened [an issue]( on Bitcoin.org's issue tracker to remove the torrent.  Sorry for any confusion.
@_date: 2018-07-02 16:39:59


FWIW, verification instructions are now included on the [BitcoinCore.org Download page](
@_date: 2015-04-27 19:16:35
Yes, alt-coins benefit from copying Bitcoin Core's constantly-improving code.  But just as patching your Linux kernel doesn't make you as smart as Linus Torvalds, patching your alt-coin code doesn't make you as smart as the Bitcoin Core developers.
It seems highly unlikely that any alt-coin that depends on the Bitcoin Core developers will surpass Bitcoin Core.
@_date: 2015-04-27 14:26:00
Awesome!  I'm sure your MacBook Pro will do fine---I'm on a 2005 Lenovo PC laptop (using Linux) and it took me about 4 hours to sync and about 2 minutes to catch up every morning when I turn it back on.  Otherwise, Bitcoin Core doesn't get in the way at all.
@_date: 2017-10-06 11:42:50
To the best of my knowledge, Xapo has not announced exactly what they plan to do (which is a large part of the problem---these companies that have announced support for so-called Segwit2x but haven't specified a policy for it).
Assuming nothing changes, Bitcoin.org will put up an alert in a few days recommending users withdraw their bitcoins to Bitcoin Core or another full-node based wallet so that you continue using Bitcoin after the hard fork (including splitting your coins if you want to sell S2X).
@_date: 2017-10-12 11:51:09
Actually, the Backing Out transaction is a problem.  If we say that Chain A is the chain that isn't hard forking, then the Backing Out transaction is definitely viable on that chain even after the HF; it may also be viable on Chain B after the HF if they haven't implemented full replay protection.
If it isn't viable on Chain B, Bob can immediately after the HF broadcast the Backing Out transaction on Chain A to return his Chain A bitcoins to himself while still being able to get all the Chain B bitcoins using the Chain B spend.
If it is viable on Chain B, Bob can hope that the Chain B spend is confirmed before Alice's Chain A spend, and then broadcast the Backing Out transaction along with a child transaction paying a huge fee for a CPFP fee bump.  Given disparity between the chains' hashrate and BIP113 nLocktime based on median times, Bob has a decent chance at success.
@_date: 2015-04-27 20:53:17
Yes.  Pruning is currently available in the unreleased [Bitcoin Core master branch]( and is strongly expected to be included in the 0.11 release scheduled for July.  (Note: security software like Bitcoin Core only uses schedules for planning; obviously, you don't release until it's been well tested.)
@_date: 2015-04-27 12:18:06
Yes, you absolutely can use Multibit.  If you use the beta Multibit HD and run it on the same computer as Bitcoin Core, Multibit will do all of its communication with your local Bitcoin Core, so you get the security and privacy benefits of Bitcoin Core along with whatever features you like from Multibit.
Do note that Bitcoin Core 0.10.1 requires downloading and storing (for now) about 40GB of data, so it's not an almost-instantly-usable option like Multibit.
@_date: 2015-09-14 12:14:30
To respond in general to some of the early comments, these pages aren't about Bitcoin Core *versus other full nodes.*  The pages are about Bitcoin Core's advantages *as a full node.*
I wrote the pages and I think running btcd or libbitcoin or other full node software is just fine.[*]
[*] Miners, merchants, and anyone else who automatically processes payments should probably run Bitcoin Core in parallel until those other full nodes have fully integrated libconsensus.  Parallel verification decreases the risk of you losing money because of a malicious consensus failure fork  (Conformal, makers of btcd, [also recommends this]( although I disagree with some of the other points in that blog post).
Note that we're not talking about XT here, but rather the ability of an attacker to take advantage of an unknown incompatibility in the consensus rules between different implementations to create invalid transactions that look like they're valid and confirmed.
@_date: 2015-04-28 10:39:14
Oh, you're claiming that CLTV is a minor feature?  Seriously?  A new op code that requires a soft fork, operates different than any previous op code, has multiple novel and only lightly-studied applications, and which makes it even easier than regular nLockTime for users to lock themselves into a transaction version or set of Script features that may not be allowed or secure at the point the transaction can be spent.
You call that minor?  You think Bitcoin should just adopt that on a whim, like ViaCoin?
@_date: 2015-04-27 19:20:51
The [RPC API]( and the [P2P protocol]( are quite stable, although certainly not frozen.  That is, they mostly add new features and rarely remove or change existing features.
Source: I write much of the documentation on Bitcoin.org, so every time the Bitcoin Core developers change something, I have to stop being lazy and document it. :-)
@_date: 2015-04-27 22:50:46
I applaud your effort to verify the binaries, but I don't think this adds any real security since anyone with access to the server can change the binaries at any time after you verify them.  (Not that anyone with legitimate server access would do that.)
The important step is the one that is listed in the sidebar: [verify the integrity of the release]( -- but that is a step each user must perform for themselves.
@_date: 2015-09-14 12:40:26
Yes, it has been proposed that a future enhanced version of the consensus library would run in a simplistic virtual machine that would guarantee the execution environment independent of platform and operating system.
However, I think libconsensus will be a significant step forward to allowing non-reference implementations to be considered safe.  Until libconsensus is fully available and fully adopted by these non-reference implementations, I think parallel validation is an effective (if inconvenient) workaround.
@_date: 2015-09-06 15:46:52




Hahaha.  This made my day: a classic [Right in Front of Me]( trope in real life.
in case you didn't figure it out, is [Mark Friedenbach](
@_date: 2015-04-27 12:59:29
That's the preference of several of the Bitcoin Core developers.  I'd guess it's because they set a very high bar for themselves.
@_date: 2015-04-27 19:35:45
I'm pretty sure they'd like to throw out the RPC-JSON interface and start over from scratch with something different (probably not JSON).  However, pretty much every programmer dreams of throwing out their old, complicated system with something new and simple---so I don't know how much they intend to actually do.
I don't think they're going to mess much with the P2P system.  I think they're hoping to develop a new system that will operate in parallel with the old system before they even think about replacing the old system.  (Sort of like BlueMatt's current block relay network, but more advanced.)
Note: these are just weak guesses from my occasional monitoring of   I could be totally off base.
@_date: 2015-04-23 22:28:37
You should ensure all contributions confirm before considering them (and more than 1 confirmation would be better).  Otherwise, an attacker could contribute money and then double-spend it if they don't win.
@_date: 2015-04-10 20:35:10
I've noticed this before: for some reason fathomable only to GitHub,  gets credit for Satoshi's commits.
@_date: 2016-10-28 00:42:47
Yes and no and sort-of.
- *Yes* because using the `-prune` setting, you can tell Bitcoin Core not to store older blocks (which includes witnesses, as well as everything else in a block that doesn't need to be used as part of the UTXO set).  The maximum amount of pruning is 550 MB so that you keep some blocks around in case of a long blockchain reorganization (temporary fork).
- *No* because there's no specific setting to not store witnesses on disc without pruning the rest of the data.  Particularly for recent blocks, keeping the witnesses around (along with the rest of the data) again helps with block chain reorganizations.
- *Sort of* because if you don't want to store the segregated witnesses for transactions that use segwit, you may simply continue to use a version of Bitcoin Core from before 0.13.1 that won't download or store the segregated witnesses (but it will store non-segwit witnesses, which are scriptSigs, unless you're pruning).
@_date: 2016-10-11 16:34:16
Speaking as the author of much of that documentation, this looks pretty interesting.  I haven't tried it out myself, but thank you for taking the time to make this!
@_date: 2016-10-11 13:17:43


I don't know how the developers feel about that (I only write documentation), but it doesn't particularly concern me.  These improvements are not just useful for mainnet but can also be put to good use on sidechains, and one of the key benefits of sidechains is that they allow people who want different consensus rules to all use the same monetary system (bitcoin).  I want consensus rules to eliminate bad types of malleability (like what segwit does), and if I have to, I'm conceptually willing to accept using a sidechain to do that rather than attempting to impose my desires upon other mainnet users.


Again, my default preference would be to wait forever, i.e. not compromise on the technically-reasonable level of 95% and not negotiate with people (e.g. Bitcoin Unlimited users) who want to increase network capacity using methods that would dramatically increase the economies of scale for large miners (i.e. that would encourage greater centralized control over hash rate).


I don't think my comment introduces this idea; I think it's been there ever since we began performing transparent soft forks.  (Nakamoto's soft forks were opaque---he didn't announce them to the community before performing them.)  Quoting from BIP12, which was the first proposed transparent soft fork, "If less than 50% of miners accept the change as of January 15, 2012 the rollout will be postponed until more than 50% of hashing power supports OP_EVAL (the rollout will be rejected if it becomes clear that a majority of hashing power will not be achieved). "  BIP12 did end up being rejected---although that occurred before signaling started when it was realized the proposal had a fatal flaw (a problem similar to that which killed The DAO).  BIP16, the first successful soft fork had contained similar language in its BIP, and even then it had problems that lead Gavin Andresen to write a [post mordem]( (where, amusingly, he suggests a 99% over 2,000 blocks check be used for hard fork changes; I guess he changed his mind on that later. :-).


I prefer not to force my opinions upon other users of mainnet.  It should be possible to establish pretty much any idea as a sidechain, allowing people to opt-in to it.  If mainnet becomes hostile towards the sidechain, then the sidechain can remove its two-way peg on mainnet and become an independent altcoin.  I think that's a reasonable upgrade path that is fully consistent with the principle that Bitcoin is a non-political currency (or at least, that it is the least-political currency we currently know how to make with the properties of decentralization and digital transference).
@_date: 2015-04-04 17:35:39
In addition, the math for this really doesn't work for anyone except rock stars.  Take speaking gigs: if a developer earns a wild $10,000 for a day of speaking and has an additional day of travel/recovery time, they need to spend 30 working days a year to make the $150,000 income you'd expect for a senior developer.  That's 30 days they're not working on Bitcoin Core.
But $10,000 per gig is really high.  What if they only earn $1,000 per speaking or consulting day?  That's 300 days a year they'd have to spend speaking/consulting/traveling/recovering.  Factoring in having a life, that either leaves them no time at all for actual development or being underpaid for their level of skill.
@_date: 2016-10-11 18:31:20


I agree; I only made that point to show that 51% was an essentially arbitrary percentage.


Understood.  I see preventing contentious changes to the consensus rules as a benefit---even when it works against my interests.


Does it though if people who want feature X can still use it on sidechains?  I understand your doubts about the near-term utility of sidechains, but I think that with additional development they're a viable option to deal with an inability to implement changes to the mainnet consensus rules.


I think that might be a little too pessimistic.  If they're being paid a premium to mine BUblocks, then it only remains to convince them that if they help segwit activate, the Bitcoin price might rise enough to earn them more money than that premium[1].  I think that's an achievable goal if we provide soft forks containing  solid improvements and back them with thorough documentation of their benefits.  And if we can't convince them, maybe we can convince someone else who will buy their ASICs.  Or we can convince their best suppliers and employees that segwit is important, so those suppliers and employee to start looking for better customers or jobs.
I think that spreading of honest, clear, and testable information is a much better course than trying to strongarm them into following consensus rules you and I think are good ideas, for it helps provide us with the same protection when the day comes that we object to a change to the consensus rules.
[1] If they mine 10% of blocks, that's about 5,400 BTC a month just from the block subsidy, so a meager 1% rise in BTC-fiat exchange rate is equivalent to a 54 BTC increase in income.  Likewise, a 1% decrease in the exchange rate (perhaps because people are upset that they're irrationally holding back an improvement) is a 54 BTC decrease in income.  At the moment, it costs ViaBTC nothing to run Bitcoin Unlimited because segwit can't be activated yet---but once it is ready, they'll have to weigh the potential impact of their decision on Bitcoin price.
@_date: 2016-10-11 16:31:59


I agree that 95% is an arbitrary number, but I think 51% is also just as arbitrary given that soft forks can be deployed using a flag day (at least one Nakamoto soft fork [the max block size limit] and the BIP30 soft fork were deployed this way) or simply deployed on a prayer that nobody will create incompatible blocks (like most Nakamoto soft forks).
Bitcoin's consensus rules are not enforced by miners; they're enforced by economic validators for whom hash rate (proof of work) was only meant to be used to decide the ordering of transactions.  That we have used this mechanism to trigger consensus rule changes on a half dozen occasions doesn't mean we're required to use it in the future, so I think any percentage &gt;0% would be arbitrary.


I'm willing to keep an open mind and listen to arguments from anyone proposing that if it comes down to it in the future, but my inclination based on what I believe today would be to refuse to upgrade my economic full node to those rules and refuse to use segwit if that was done.  Why?  Because I think it would mean that Bitcoin had become regular old boring political money where "might makes right".
I continue to feel that 95% of hashrate signaling readiness for an upgrade is a technically sound percentage that minimizes disruption, and that the solution to any &gt;5% percent of hashrate opposing a change is better documentation describing the changes, more testing to prove to them the change is safe, and more innovation related to the change in order to sweeten the deal---as well as reminding the objectors that sidechains allow those of us who want the change to (for the most part) have our cake and eat it too.
@_date: 2016-10-28 14:42:57
Not ELI5, but a general overview of the idea may be found here: 
@_date: 2016-10-28 02:51:35


It's very easy to simultaneously make the two changes you described; it would arguably be harder to do them separately.
The malleability fix works by moving (separating or "segregating") some data (the "witnesses") away from the calculation used to generate each transaction's txid.  Since the current block size limit is defined partly using the number of bytes covered by the txids, moving this data elsewhere allows for an increase in capacity.
Because we don't want attackers to stuff unlimited amounts of junk data into these segregated witnesses that are no longer included in the block size limit, a new limit is defined that counts each byte of segregated witness data as 1/4 of a byte of other block data.
This sets the new maximum block size to a bit less than 4 MB (since a block can't entirely contain witnesses), which is a maximum value a great many people in Bitcoin think is safe right now.  In practice, with a normal mix of transactions all using segwit, we'd expect to see blocks at 1.7 MB or slightly larger if multisig usage continues to increase as it has been doing over the past few years.
@_date: 2018-04-14 08:54:41
This is interesting for Bitcoin, but I don't know why it's an announcement in since it's implemented on a different curve than the one Bitcoin uses.
@_date: 2016-10-28 02:35:01


Nope.  No action is required.  If segwit is activated, it's likely that whatever wallet you use will eventually update to support it, at which point any new transactions you receive will be paid to segwit addresses, and any transactions you make spending those bitcoins will use segregated witnesses.
However, there's nothing you need to do.
You can find some more information written for wallet users such as yourself here: 
@_date: 2016-10-28 11:41:35


There are eight objectives accomplished by segwit listed here: 


There is that setting, `-prune`, which won't store any unnecessary block data &gt; than  `n` megabytes of disk space.
@_date: 2016-10-28 11:52:22
UTC.  
Even more precisely, you can check Bitcoin Core's `getblockchaininfo` RPC for a [Unix epoch time]( start second (which is inherently UTC):
      "bip9_softforks": {
         "segwit": {
           "status": "defined",
           "startTime": 1479168000,
           "timeout": 1510704000
         },
       },
    $ date -ud 
    Tue Nov 15 00:00:00 UTC 2016
@_date: 2015-11-01 13:30:01
I agree.  I'm finally able to read (or at least skim) every post on the list for the first time in months.  Thank you mods!
@_date: 2015-11-19 22:03:48
One of the points of the segregated witness is to allow you to download the most important parts of the block---those that affect the ledger (UTXO set)---without downloading the parts that are only valid for proving the transactions were valid (the witnesses).  That way we can optionally prune that per-transaction witness data and use the proof of work under which the block is buried as a stand-in witness.  You can learn more in my Bitcoin.StackExchange answer here: 
That means storing this data externally from what we currently associate as the block is necessary to get that optional space savings.
@_date: 2016-10-04 12:24:17
I thought "retarget" was a pun on the "2016" in "Scaling Bitcoin 2016".
@_date: 2015-11-10 02:04:38
and -- this was an excellent talk; thank you for doing it and thank you for making it available online!
@_date: 2015-11-02 19:47:07
FYI: I just merged this update, so the site will be updated in about 15 minutes (as soon as the build server processes the new commit).
@_date: 2015-11-11 01:05:03
Perhaps that's why most of Greg's comments on Reddit/BCT *actually are* walls of text. :-)  (But they're really fun to read; I confess that I regularly stalk him by looking up his latest posts in the hopes that all that smart stuff will rub off on me by some sort of digital osmosis.)
@_date: 2015-03-06 18:07:02
They're supposed to updating their listing: 
@_date: 2018-04-15 16:07:58
Fair point, and thanks for your reply.  I do think it's interesting to see experimentation on curves with different properties, and a Rust implementation is cool all on its own.
@_date: 2015-03-22 12:26:00
Miners can include invalid transactions in a block---what prevents them from doing so are the full nodes that will reject that block.  If the number of full nodes decreases relative to the number of Bitcoin users, it means miners have more power to set policy rather than follow the established rules that full nodes enforce.  For example, miners could choose to increase the block subsidy, eliminating the 21 million BTC ceiling.
SPV is a trade-off between security and convenience, not a replacement of one security mechanism with another equivalent one.
@_date: 2015-11-09 14:10:55
I have my doubts too; however, many businesses sponsor conferences or trade groups that would also seem to be susceptible to tragedy-of-the-commons type problems so I don't think we can rule out the possibility of at-loss mining.
Note: Eric Voskuil (I don't know his Reddit account) has an interesting take on the tragedy of the commons he sent me by private email; he makes a compelling argument that it can only happen because of government or other strongman intervention.  All other instances of the free rider problem, according to him, should not be lumped in with the tragedy of the commons.  I think I agree with him, but I'm still trying to update my cached thinking and cached use-of-terminology here.
@_date: 2016-10-11 14:55:55


This is not quiet correct:
1. We can do one-way pegged sidechains, where 1 BTC on mainnet can be converted into 1 token on the sidechain but there's no way to move 1 token on the sidechain back to mainnet.  This doesn't require any modification to Bitcoin and there's at least one altcoin that was started this way[1].  If the sidechain didn't implement a subsidy and both networks were later willing to fork, it would even be possible to add a two-way peg later.
2. We can do federated two-way pegged (fedpeg) sidechains also without any changes to mainnet, and the ElementsProject.org codebase is currently based on using this with testnet in a way that's fully compatible with mainnet (and indistinguishable to miners from regular multisig at the transaction level, so it can be made censorship resistant).  I think fedpegs with strict time and value limits run by widely trusted parties can provide a reasonable alternative until safe merged-mined sidechains become available.  For example, imagine a fedpeg run by 15 notable Bitcoin businesses that permitted a maximum of 10,000 UTXOs with a maximum value of $25 each and some sort of demurrage so that users could make real value transfers using Lightning network.
[1] I think there's a citation for that in the sidechains paper; if not, let me know and I can look it up.


To a computer, there is no such thing as an upgrade---there are only changes.  I don't know of any way to design a system that is resistant to changes we don't want but which is also quickly accepting of changes we do want---especially when different people disagree about what they want.
I think this is a concern we'll have to address more and more and Bitcoin matures, as different people are going to want different things.  I think two-way pegged sidechains provides an excellent medium-term solution, and I'm happy to see longer-term solutions being researched (for example, see Peter Todd's talk at last week's Scaling Bitcoin).
@_date: 2016-10-11 12:24:20


My preferred option would be to simply continue improving the technology while waiting for a 95% hash rate majority to form that supports segwit.  BIP9 allows for multiple soft forks to be pending at the same time, so we can leave segwit pending, continue working on Lightning implementations (which can be used now on testnet), implement various Schnorr-based solutions, implement MAST or maybe something better than MAST, work on sidechains (both fedpeg and decentralized sidechains), maybe implement fraud proofs, add new and previously-removed opcodes like those on the Elements sidechain.  Many of those things will naturally be implemented on segwit (because segwit makes them easier to implement) and so we'll have a large set of useful technologies (including many scalability improvements) that can be fully enabled at any time within 4,032 blocks (about 4 weeks) of when miners decide that they want those features on Bitcoin mainnet.
I don't think there should be any "negotiating" nor any compromise of the 95% ratio that was successful in the previous BIP9-based soft fork (for BIPs 68/112/113) and which is the same percentage (though measured differently) for the previous soft forks going back to BIP34.  I think developers can just keep improving the technology using testnets and sidechains, and eventually miners---for who the BTC/fiat price is an important factor---will realize that not adopting useful and safe new features for mainnet can only be hurting their profitability.
In short, I think this ViaBTC thing is just another short term drama that will hardly be remembered a year or two from now.
Please note that I am speaking only for myself here, and that I haven't talked this over with anyone else.
@_date: 2016-10-12 10:39:31


Transactions that move bitcoins to all types of sidechains can be made censorship resistant (e.g. by using [pay-to-contract-hash]( which Elements already does, spenders can make their transactions indistinguishable from other Bitcoin transactions until after the transactions have been mined).
Fedpeg sidechains are capable of moving bitcoins from the sidechain back to mainnet in a censorship-resistant fashion (again, the mainnet transaction is indistinguishable from other normal transactions), although I don't know if Elements implements this.
For merge-mined sidechains, it would still be possible to move bitcoins from mainnet to the sidechain in a censorship-resistant fashion, but it wouldn't be possible to move them back without the cooperation of miners.
@_date: 2015-11-20 20:14:41
I was too, but since first seeing that video, I watch the intro about twice a month---whenever I expect I'm going to need to say his name in the near future.  :-)
@_date: 2015-03-06 07:41:12
Thanks to for promoting this issue.  I'm  from GitHub and the temporary maintainer of Bitcoin.org (until we find someone to take over permanently).  I just [answered some questions]( about volunteering for wallet reviews, and I'm happy to answer more questions here.  Thanks!
@_date: 2015-03-10 13:43:14
Always happy to edit.  I think you have my email (if not, PM me here).
@_date: 2015-03-20 13:06:26
Only full nodes can verify that a particular transaction is valid, so only people who run their own full node have the highest level of security available on the network.
If full node counts decrease relative to the number of Bitcoin users, it means fewer people deeply care about their own security.  That's bad for the network in more ways than just preventing Sybill attacks and supporting SPV clients.
@_date: 2015-03-10 13:38:00
I'd be interested to read that post.  I've felt the same frustration and thought about writing a post myself.
@_date: 2016-05-13 19:28:54
Here's Adam Back (talking about it a few months ago:   (if you have time, I highly recommend watching the entire speech; it covers a huge range of privacy and fungibility protecting technologies).
Bryan Bishop (has a transcript of the entire speech here:  the relevant parts are quoted below:


@_date: 2015-03-29 13:52:07
I think the site is currently fairly poor at SEO itself.  For example, we didn't even have a meta tag on the index page until someone reported last October that Google was using a really old description of the site: 
I suspect the reason we rank so well is that we have a lot of quality content (all of it lightly peer reviewed through GitHub pull requests) and a lot of incoming links (probably because we have quality content).  Also, yeah, using the bitcoin.org domain name doesn't hurt. :-)
If someone reading this knows SEO and would like to improve that aspect of the site, please feel free to PM me on Reddit or read the [Volunteering Instructions](  As the temporary site maintainer, I'm happy to help.
@_date: 2016-05-14 12:28:30
Miners are located in physical jurisdictions, and the governments of those jurisdictions might require that miners censor certain transactions or have their mining hardware seized (or worse, they could jail/assault/kill the miners).  Under those conditions, censoring the requested transactions would be the miners' best option.
@_date: 2015-03-19 21:51:05
That's an interesting idea.  Would you be interested in [opening an issue]( suggesting that?  I think it'd be interesting if we could design a simple experiment that would allow us to test the impact of semi-hiding Bitcoin Core for, say, two weeks.  -- on GitHub
@_date: 2016-05-04 13:42:19
I double space and I'm 32.  Perhaps the more identifiable thing is that when my text editor rewraps lines, it eats the extra space, so my email correspondence (written in a `vi` clone; sent with `mutt`) tends to have a [mix of single space and double space](
@_date: 2015-11-19 21:25:37
I don't think that's correct.  If I understood correctly (doubtful), a transaction spending a SW-enabled output would have an empty scriptSig, so its regular txid would also be the "normalized" SW txid.
The real scriptSig would be stored somewhere else.  We could store it in the block disguised as something else, but it could also more conveniently be stored outside of the structure we currently call a block.  Maybe we'll call it a block footer.  The block plus the block footer would constitute a complete block.
@_date: 2016-05-25 20:49:11
Although that's one way to do an upgrade using a sidechain, we already have several upgrades coming into Bitcoin in the near future that were tested on a sidechain first:
- Consensus-enforced sequence numbers (BIP68) and CheckSequenceVerify (CSV, BIP112) which are the same as on Elements: 
- Segregated witness, which is implemented in the first public release of Elements.  Elements uses a hard fork variant (i.e. the merkle root in the block header is constructed differently than on mainnet) whereas the version proposed for mainnet is a soft fork version that places the witness merkle root in the coinbase transaction.  
In addition, I heard that one feature the devs hope to get in soon after segwit is released to miners is the ability to use the Schnorr digital signature algorithm, which is also being tested on Elements: 
In other words, sidechains are already providing valuable live testing for upgrade options to Bitcoin, a process that I hope will only accelerate and sidechains get used for more and more things.
@_date: 2017-07-15 12:58:15
Purchasing bitcoins from an exchange always carries an element of risk: they could take your money and disappear.  During the event, it'll be a bit more dangerous because, if Bitcoin splits into two or more coins, they could refuse to send you your share of all those coins.
Transferring bitcoin between two wallets you alone control should technically be safe (provided both wallets remain secure and you have backups for both) but there's a risk that either or both of the wallets will be confused by competing bitcoins and require recovery from your backup.  There's an additional complication that your wallet probably won't know the right fee to pay since each different version will have its own fee rate.
@_date: 2016-05-04 02:01:33
Although it would be interesting for the Bitcoin Core developers to answer your query, I think it would perhaps be best if they didn't.
Craig Wright claims he has the ability to publicly provide strong cryptographic evidence of his being Satoshi Nakamoto, and I think we should insist that he provide that evidence to all of us rather than continuing to speculate about whatever private demonstrations he performed for a select few.
There are many cases in Bitcoin where we need the help of experts to understand what is really going on.  This is not one of those cases.  If Craig Wright has the private key used to sign the spend from the block 9 generation transaction (which he has claimed to have) or if he has the GPG key long associated with Satoshi Nakamoto (which he has also claimed to have), then he need only use one or (preferably) both of those keys to sign something saying that he is indeed Satoshi Nakamoto.  This would not be proof positive, but it would constitute strong evidence *that every single one of us could validate.*
@_date: 2015-11-20 14:09:19
Pieter pronounces his own name 2 seconds into this video: 
@_date: 2015-03-11 01:56:12


Some of the users we have now---the dicers and the data storers---aren't worth keeping.  Moreover, capacity here is somewhat squishy owing to the ability to pay higher fees for priority access to confirmation, so full blocks won't shed users indiscriminately---they'll shed the users who are least willing to pay for their use of Bitcoin.  Up until a certain fee threshold, chances are these are the users who don't get much value from Bitcoin, so losing them isn't a shame.
(I say 'up until a certain value' because at some point fees become high enough to turn away poorer users who do get significant value from Bitcoin.)
I'm not trying to rehash the old arguments about fees, I'm just saying that I don't think we hit a hard wall the moment 1 MB blocks become common, or even for sometime afterwards.


I apologize; making non-falsifiable statements was not my intention.
* The number of full nodes currently partly indicates our capacity for serving P2P SPV nodes (which is nice, but as you say, not essential)---but it also indicates the number of people and business who take their security seriously.  If full nodes are declining or stagnant as Bitcoin usage is increasing, it means we're trending towards centralization and trusted third parties.  As a metric, full node usage should probably roughly correlate with transaction volume---for every doubling in transaction volume, we should see a doubling of full nodes.
* According to [some back of the envelope calculations I did]( double spending confirmed transactions enters the realm of feasibly profitable at around 1% network hash rate for once-confirmed transactions and 23% for six-confirmed transactions.  When I wrote that, some pools had more than 23%, but that may no longer be the case---so I guess we're making progress, albeit slowly.
    (I did like your BCF post.  Too bad most of the tools you suggested haven't materialized yet, although I know Luke is still working on better GBT/blockmaker stuff.)
@_date: 2015-03-06 07:53:29
We already have Trezor listed on [the page]( as well as Ledger/BTChip.
CryptoCards.co looks like a way for sharing a Bitcoin address rather than a wallet that signs transactions, so we're not going to list it on the wallets page.
@_date: 2017-05-02 19:31:07


Interesting idea.  I think you were talking about WoT in a generic sense, but it just occurred to me that I could give copies of my GPG revocation certificate to a few trusted friends with the request that they submit it to a keyserver if they think either I or my private key is compromised.
@_date: 2015-11-09 00:44:28
Did you mean to say BIP65 (CLTV) or BIP62 (dealing with malleability)?  I ask because it seems very likely BIP65 will be deployed as Bitcoin Core 0.11.2 containing it is already in RC.
@_date: 2016-05-20 18:52:25
Did you mean BIP66 (strict DER, enforced July 3/4 2015) or BIP65 (CLTV, enforced mid-December 2016)?
From context, it sounds like you're talking about the situation that led to the July 4, 2015, 6-block fork which was from the BIP66 fork.  I hadn't heard of any miner false signaling for BIP65 (CLTV), although that certainly could've happened. 
@_date: 2015-03-16 12:17:40


Yes and no.  Bitcoin Core relays transactions for other clients in a very similar way to the way it sends its own transactions (the process is identical, I believe, unless you restart Bitcoin Core before your transaction confirms[1]).  That means no one who is na√Øvely listening to your node can determine which transactions are yours and which are those that you're just relaying.
Better yet, Bitcoin Core doesn't send your transactions or other people's transactions to all of its peers immediately.  It introduces a small random delay for each peer before relaying.  That means transactions don't spread through the network in a fully-predictable manner based on latency, so even if a spy node is connected to every single node on the network, it can't assume that the first node it gets a transaction from is the node that originated that transaction.
How well does this all work?  When I look at the BlockChain.info page for my IP address---which has been static for about a year now---I see a whole bunch of transactions I know I didn't make associated with me (plausible deniability) and I don't see some transactions I did make (delayed relay).
As always, someone could be doing more in-depth analysis using IP address correlations with suspected change outputs, plus some network latency analysis, plus some other statistical vodoo.  However, I think Bitcoin Core over IPv4 does pretty well.  For better deniability, try using Tor.
[1] I believe that if you restart Bitcoin Core, it will re-transmit any unconfirmed transactions in your wallet.  Other nodes will just forget about other people's unconfirmed transactions at restart, so they don't re-transmit them.
@_date: 2017-07-13 14:25:54
Assuming you're connected to at least one BIP148 node, it will send blocks to your Bitcoin Core node.  The `getchaintips` RPC will print a list of forks your node has seen (give it a try now, if your node has been running a while, you'll have a bunch of one-block orphans).
Although the BIP148 chain won't be labeled as such, since Bitcoin Core doesn't know about such things, it'll hopefully be the only more than 2 or 3-block fork in your getchaintips results since the BIP66 activation two years ago.
@_date: 2015-03-20 11:56:28


I haven't really thought about this, but step one would be to segment traffic somehow so we can monitor statistics for different segments separately.  For example, simply monitoring total data replied to odd-numbered IP addresses separately from total data replied to even-numbered IP address.  This could be a custom (non-mainline) patch to Bitcoin Core or a tcpdump script.
After we had segmented traffic monitoring and run a control study that showed us how to filter for expected spikes and other abnormalities, we could change the Javascript on the Choose Your Wallet page to only show Bitcoin Core to visitors from one segment, hiding it from users of the other segment.  Then we would see what impact that would have.


I don't want to discourage anyone from running a full node.  I was responding to Mike's assertion that people are downloading Bitcoin Core, running it for a few minutes/hours, being surprised at how resource-heavy it is, and then turning it off permanently.
If his assertion is correct---and Gregory makes a compelling case for why it might be wrong---my desire is to improve the site copy so that people don't download a full node unless they're willing to run it at least long enough to pay back to the network the bandwidth they used during IBD.


Is there a problem with  ?  I wrote it based on [your recommendation]( last year, although it looks like I misattributed you on GitHub, so maybe you didn't know it got published a couple months ago.  Let me know if there are any problems, I'm happy to make improvements.
@_date: 2015-10-08 02:54:14
@_date: 2016-05-15 16:25:18
You're absolutely correct that it hurts both censoring miners and non-censoring miners; that's why it's an extreme fail-safe and not something that would be undertaken lightly.
I also agree that it would discourage some people from investing in hardware again, lest the actions of others hurt them; however, miners are already exposed to exactly that risk (if Evil Miner Mallory gets a majority of the hash rate, he can fork all of Honest Miner Alice's blocks off of the chain) so I don't think it precludes future investment in mining---it should act as intended as a signal that censoring transactions will not be tolerated.
@_date: 2017-07-15 18:10:30
I haven't used Coinbase for a while now, but I think I heard they were charging customers for fees.  Did you have to pay a normal fee or the very-high fee?
@_date: 2015-03-12 21:01:46
Or, you know, he could've just asked someone.  Peter Todd, Gregory Maxwell, and a ton of other experts can generally be found in various Bitcoin chatrooms, and (if you follow the rules in the rooms' /topic) these experts will gladly critique ideas if you ask nicely.
@_date: 2015-03-10 23:38:14


I apologize if I took the quotes out of context; I tried to avoid that.  The quotes I provided have Pieter, Wladimir, and Luke all agreeing that something needs to be done eventually, and I never doubted that Gregory felt the same.  The quotes also indicate that *right now* may not be the right time, and I think that's the relevant point with Gavin proposing introducing code in the 0.11 or 0.11+1 releases.


This is a real risk if we do absolutely nothing before blocks become regularly full.  However, that doesn't mean that larger blocks are the best solution to runaway mempool size.  We could quite simply start storing the mempool on disk (which already happens on a system level with paging)---anyone who stores 144 blocks a day probably has enough disk space to store thousands of blocks worth of unconfirmed transactions if such a thing became required.
You've been advocating better mempool management for years to make DoS attacks harder, so I don't think that you're arguing that the mempool must fundamentally be unlimited in size---but please correct me if I'm wrong.


That's exactly the debate I'd like to see, especially the part about what has to come first.  The best-case arguments I've seen for large blocks are that they won't make it any harder to run a full node and won't increase the pressure to centralize mining, but that just leaves us where we are now---with a stagnant number of full nodes and too much mining centralization.  Are we sure developer time should be spent increasing the capacity of a network that doesn't currently meet its design goals?
@_date: 2017-07-13 09:14:33


The post mentions that in the final paragraph of the opening section, although it doesn't call it "shitstorm status", which is probably a more appropriate name. :-)


Agreed, but that doesn't seem like something we can count on, and while the people on this Reddit thread may be tuned into the latest Bitcoin news, not all Bitcoin users are, so we wanted to start notifying less attentive users now about the potential risk.
If nothing happens, we'll just take down the banner and update the page to say that the best case scenario prevailed and sorry for any confusion.
@_date: 2015-03-09 18:28:20


Is that based on short-term or long-term testing?  When seeding torrents, even legal ones, I've run into problems with home ISPs that advertise unlimited monthly transfer with the fine print that says "for normal use only".  The ISP's opinion of normal doesn't include continuous 100% use of available bandwidth.
@_date: 2015-10-22 13:14:33
Thank you for taking the time to do this.
@_date: 2017-07-18 10:04:57
UASF was not a step to avoid a currency split; it was a step to risk a currency split.
@_date: 2015-02-02 13:43:00
For [blocks-first]( initial block download (IBD), a new pre-0.10 node downloads all of its blocks from a single peer.  If that peer is limited to, say, 25 KB/s upload, IBD will take more than 12 days with the current block chain size.
For headers-first IBD, a new 0.10 node downloads from up to 8 peers simultaneously and will drop its connection to any peer that slows it down.  (Except when downloading the most recent 1,024 blocks, where it will only drop peers that take more than 10 minutes to send a single block).
If Bitconi Core 0.10.0 implemented upload rate limiting, and it was widely used, it could seriously slow down new users of pre-0.10 nodes.  The plan is to wait until network spiders indicate that most users are on a headers-first version before any built-in rate limiting is implemented.
@_date: 2015-03-15 21:00:36


I [wrote]( about [250 pages of documentation]( about Bitcoin in 2014, and I'm adding more every month.  I've never had any problem asking the core devs for help, so I'm surprised that you've had such a negative experience.
I do suspect that you might be asking for something that the core devs don't use---I don't know if any of them use Eclipse.  I personally do all of my code reading using `vi`, ctags, and `git grep`.  The actual development dependencies are listed in the [build-unix file](
@_date: 2015-02-05 14:05:21
Soft forks do not require a version bump.  [BIP16]( was implemented without one.
@_date: 2015-02-23 17:28:57
Oh, sorry.  When I wrote that, the site was still working.  We held off publishing the instructions for about a month until Bitcoin Core 0.10.0 was released, and I didn't think to recheck the links.  I'll fix that as soon as I get home.
@_date: 2015-02-03 21:24:56
First, the limit is based on the relay fee, which can be changed with the `relayfee` setting at run time, so there's no universal answer.
Second, your first link has the formula used to calculate the byte size:  `size_t nSize = GetSerializeSize(SER_DISK,0)+148u;`
In plain English, Bitcoin calculates the actual serialized size of the output and then adds 148 bytes to it to get the total byte size.  The 148 bytes is an estimate based on the size of a P2PKH input, so it's possible to create outputs (such as P2SH) that are more "dusty" than the dust limit. 
@_date: 2015-02-05 14:30:01
I answered a [question about BIP62's status]( last night on Bitcoin StackExchange; that may have the answer you're looking for.
@_date: 2015-02-05 23:39:18
Thank you for taking the time to write all that down, and for taking the time before that to throughly think about Gavin's proposal.
@_date: 2015-02-05 13:34:13
Update: release candidate 4 (RC4) [was tagged today]( without this being a part of it.
@_date: 2017-07-13 15:37:21
It sounds like you think a Bitcoin site should say "buy! buy! buy!", but that's not how I see it.  Bitcoin is an experimental currency; it has a much higher chance of failure than most other investments, and it's our responsibility to make that clear and to provide advice on mitigating that risk.
Of course, true believers are welcome to ignore that advice and reap the benefits of doing so if Bitcoin becomes even more successful than it is today.
@_date: 2015-02-16 14:14:37
**Edit:** bad idea.  See the reply from below.
Not necessarily a serious suggestion---just off the top of my head---but what do you think about requiring miners to pay a small data fee (maybe with some sort of exponential factor) for each additional kilobyte of data they include?
The data fee could be an output in the coinbase transaction that spends everything to transaction fees 100,000 blocks later (2 years) using [CLTV](
For example, a schedule of data fees might be:
| Block Size | Fee |
| 1 MB | 0.1 BTC |
| 10 MB | 2 BTC |
| 100 MB | 40 BTC |
Presumably this would require current miners collect enough transaction fees to cover the data fee, discouraging abuse of full node's disk space and bandwidth, and it would help fund network security in the future when block subsidies drop.
The data fee formula would only crudely approximate costs, and if bandwidth/disk space costs changed much, we could hard fork to change the data fee formula.
@_date: 2015-02-19 15:26:12
Correct.  Unless you have a crazy-fast machine or a really slow link, the bounding constraint on the sync from block 295,000 onwards is the signature validation.  (Before the last checkpoint, currently at block 295,000, signature validation is skipped.)
There's been discussion about removing the checkpoints and then optionally skipping signature validation up until a preset *n* number of blocks from the tip of the best header chain.  I don't know what values are being considered for *n*, but I do believe it typically takes my computer about 2 to 5 seconds to validate current-size blocks, so `5*n` plus (download time for chain length minus final *n* blocks) would be roughly the initial sync time.
@_date: 2015-02-23 17:14:34
I'm a freelancer, but I get the exact same feeling when I'm doing a job for a client.  "This isn't Bitcoin. It's boring. I really want to write about Bitcoin."
@_date: 2015-02-23 21:25:31
Wow, that was fast.  Thanks!
@_date: 2015-02-03 16:31:43
That's very unlikely.  If it was going to be added to 0.10.0, there would be a separate pull request adding it to the 0.10 branch.
It may be part of 0.10.1 or whatever the next minor-version increase is.
@_date: 2015-02-13 19:03:19
There was a fairly recent drama where BC.i used not-random-enough numbers for part of the signatures it created.  That has nothing to do with BIP66.
BIP66 is being implemented now because of a recent change in the way OpenSSL processes signatures.  Bitcoin Core uses OpenSSL to check signatures to make sure they're valid, but OpenSSL used to accept signatures using multiple different types of encodings.  Once BIP66 is fully implemented, there will only be one valid way to encode a Bitcoin signature (the DER encoding).
Signatures in standard transactions---transactions relayed over the P2P network by default Bitcoin Core nodes---have already had to be DER encoded since early 2013, so this doesn't affect any normal current wallet.  (I don't think it every affected any real wallet---the only people who ever created non-DER Bitcoin signatures probably did it on purpose, possibly just to make life difficult for other people.)
@_date: 2015-02-19 17:06:30
Nice!  Thanks!  (see above)
@_date: 2015-02-19 16:02:03
There was a build flag to do that (for testing purposes), but I think it stopped working sometime during the past couple months.  I don't know if anyone has actually done a full sync using libsecp256k1 for benchmarks.
Although libsecp256k1 is much faster, part of that is because it has hand-optimized assembly code for common platforms.  I think its general C code is "only" 2x faster than OpenSSL at batch signature validation.  (The general code will run faster if compiled against [GMP]( but maybe that's because GMP has its own optimized assembly.)  One goal for libsecp256k1 is to make it as independent as possible for consensus work, which may mean that you don't get the extra optimizations.
In short, it's my understanding that libsecp256k1 and its use in Bitcoin Core is still a work in progress with trade-offs that are still under discussion.  You may not want to assume giant future speed ups.
(Caveat: everything above is based on my memory of conversations in  and my memory stinks.)
@_date: 2015-03-10 18:10:39
I think you're a key dev., but I also pay attention to [what the other devs say]( (only some lines pasted below; it is not my intention to take anyone's remarks out of context):












Although feedback from people building products on top of Bitcoin is valuable, it's been my experience that there are only a few people---most of them in  spend much time thinking about the overall health of the network.  (To be clear, I include you and Gavin in that group.)
@_date: 2017-07-11 16:41:23
I confess I don't know how to pronounce his surname either.  Let's see if he responds.  RemindMe! 3 days
@_date: 2017-07-13 16:12:58
Many experienced Bitcoiners are worried too.  We're all hoping everything will go smoothly, and there's a fair chance that it will, but we need to make sure inexperienced users such as yourself understand what could happen in a couple weeks so you can make the same preparations more experienced users are making.
@_date: 2017-07-13 14:26:51
@_date: 2017-07-13 09:03:22
The alert alludes to it, "Note: there is a chance a milder level of disruption could start between now and Mon Jul 31 2017 20:00:00 GMT-0400 (EDT). If that is the case, this post will be updated with details."
The alert is focused on what could go wrong, rather than what could go right, as it is targeted at inexperienced users who could easily lose money when confirmation scores become unreliable because of either fork attempt.  I was worried that if we try to go into too many details, readers would focus on those rather than on taking the necessary steps to secure their bitcoins.
We will probably add more information to the bottom of the post over time, such as a "see also" section, for readers who want to learn more.
@_date: 2015-02-25 15:45:07
I agree completely.
@_date: 2016-05-14 12:15:27
I assume so (miners can see the fee for [Confidential Transactions](
@_date: 2017-07-13 14:44:23


(1) not buying in the first place, (2) hedging, and (3) increasing the amount you can afford to lose.
The latter is my preferred option: the lower your annual expenses, the less money you need in a safety net.
@_date: 2015-02-08 12:18:31
Please also read the [answer above it]( on that page from Bitcoin Core developer Pieter Wuille about why you shouldn't do that.
@_date: 2015-02-23 19:55:35
Nice!  I [opened a PR]( changing our links to point to the article.  Thanks!
@_date: 2017-07-07 09:56:38
If all input amounts are the same, then one can't tell from block chain analysis exactly which person paid which output, even if the various outputs are different and also even if you can match the change outputs.  For example:
    Last address   Inputs  |  Outputs    Address
    1A1ice            1.0  |  0.10       1Zu1u
    1Bob              1.0  |  0.20       1Yasmin
    1Char1ie          1.0  |  0.30       1Xavier
                           |  0.90       1Werner
                           |  0.80       1Victor
                           |  0.70       1Uri
Likewise, if you have equal outputs, you can't tell from block chain analysis exactly which person received which output:
    Last address   Inputs  |  Outputs    Address
    1Zu1u            0.10  |  1.0        1Alice
    1Yasmin          0.20  |  1.0        1Bob
    1Xavier          0.30  |  1.0        1Cha1ie
    1Werner          0.90  |    
    1Victor          0.80  |    
    1Uri             0.70  |    
Whether you have a UTXO model or a rolling-balance model doesn't seem to matter here; in any case, you'll have cases of output-value matching (or balance-value matching) where you'll have to return some change outside of the anonymity set, which is fine---you can save that change to use in a later coinjoin.
Your example is great, but it requires both parties wanting to pay the same amount to a third party, which seems unlikely to me in many cases.  That's why I suggest input matching (which disguises the payer but taints the change) and then a second coinjoin cycle where the tainted change would be split into equal-sized outputs with other people's money, spreading the taint to make block chain analysis harder.
Brining it back to the point of your article, Schnorr would make this all cheaper than it is now.  However, if you have to go through multiple cycles to maximize the anonymity set, then it'll still probably be more expensive than paying without coinjoin, but it'll still be quite a bit cheaper than coinjoin today with dollar-sized fees.
@_date: 2015-02-03 17:04:01
Yes, but all the work on it is currently being done in the [0.10 branch]( and there are, as of this moment, [no pull requests left for the 0.10 milestone](
@_date: 2015-02-24 15:21:28
One of the attributes of the block reward is that it can't be spent for 100 blocks (101 including the block you created).  If you rewrite the chain in block *n* and perpetrate a fraud, you may discover that your profit is less than you expected by block *n+100* because people don't want to accept bitcoins that can easily be double spent.
I admit 100 blocks (about 17 hours) isn't a very long time, but extending the coinbase maturation time is only a soft fork.  There's no point in doing it now because, as you say, capital costs are so high that they force miners to think long-term, but Satoshi obviously gave us this knob to turn in case miners started thinking short term (a real risk when Bitcoin started, CPU mining was the norm, and anyone could fire up thousands of per-hour nodes on Amazon EC2).
@_date: 2015-02-23 17:34:54
Thanks! Actually, I re-read it too for the same reason. :-)
I've been a pro writer for 10 years, and at least once a month I find answers to my own questions in docs I've written.  Sometimes I'll be reading an article and I'll get a funny feeling... then I scroll to the byline and realize I wrote it!
@_date: 2017-07-15 18:09:01
Of course not, but if you look up a boring transaction that nobody else (or nobody else) every looks up, it's probable that you're associated with that transaction in some way.
@_date: 2016-05-14 12:21:08
I recommend watching Adam's full speech linked above, or at least the first 10 minutes; he describes the historical roots of monetary fungibility and explains why it's an important property of a monetary system.  That this technology could also be used for temporarily-increased privacy is a nice bonus.
For anyone who wants to be audited, they can release the decryption key to the auditor at any time---including before they broadcast the transaction to miners, allowing the auditors to monitor the bitcoins being spent by the transaction without giving the entire world a chance to monitor the transaction or potentially censor it.
@_date: 2015-02-25 13:59:27
Agreed.  I was quite upset.  I joined  to vent, but before I said anything,  reported a significant rendering bug in the Bitcoin.org dev docs (which is fixed now).  It was a nice ego check reminding me that I too am pretty good at screwing up.
@_date: 2017-07-15 13:57:03
With the caveat that things could change, there's only a slight additional risk.  That risk can be mitigated by waiting for a few more confirmations than normal (e.g. 12 instead of the usual 6).
@_date: 2015-02-03 23:11:07
No, it only calculates the serialized size of the **output**.  Specifically:
* 8-byte amount (int64_t)
* 1 or 3-byte compactSize uint byte count for the pubkey script (1 byte for scripts up to 252 bytes; 3 bytes for scripts up to 10,000 bytes, the max size of a single script)
* the number of bytes in the pubkey script
For a P2PKH output, that's 8 bytes amount, 1 byte count, 1 byte OP_DUP, 1 byte OP_HASH160, 1 byte OP_PUSH20, 20 bytes hash, 1 byte OP_EQUALVERIFY, and 1 byte OP_CHECKSIG == 34 bytes.
Because that only calculates the size of the output, we also add the size of a typical input to capture most of the costs.  It's true that there's an un-captured cost from the transaction overhead, but that can be minor in a transaction with multiple inputs.  (And the dust limit is an arbitrary limit meant to discourage spam, so it's acceptable to be imprecise as long as the goal is met and no serious burdens are placed on legitimate transactions.)
@_date: 2015-02-05 17:03:46
SPV and the P2P network protocol are separate things.  Electrum uses [SPV]( which means that the client verifies that transactions are part of a particular valid-looking block.
As you say, Electrum isn't fully decentralized---it doesn't use the Bitcoin P2P protocol to send and receive transactions, blocks, or merkleblocks.  Instead it connects to an Electrum server.
@_date: 2015-02-24 14:40:42


I don't understand this.  If people are profiting from mining, why would they risk that profit by doing something as risky as chain rewrites?  (Chain rewrites for fraud are unethical and possibly illegal.  Chain rewrites for other reasons scare people into thinking Bitcoin isn't secure, likely causing the value (in absolute terms) of the block reward to decrease.)
That aside, I think mildly altruistic mining will play a big part in Bitcoin's future.  As soon as its possible to mine without much hassle (e.g. no dealing with preorders and new equipment every few months), I plan to upgrade my home full node into a solo miner with about $365/year worth of mining equipment---I think of it has playing the Bitcoin Lottery rather than the state-sanctioned $1/ticket lottery that I sometimes play.
@_date: 2017-07-13 12:30:17
Not interacting with BIP148 would be very dangerous as it could leave you on a fork with nobody but yourself.  However, if you want to do that, you can use the hidden RPC "invalidateblock" to mark the first block on the BIP148 fork as invalid so that your node will follow the most-proof-of-work non-BIP148 chain.
Again, that's really dangerous.  I think a better option is to wait a few days to see if there are two (or more) chains and then sell your coins on whatever chains you don't like (with due caution to prevent undesired cross-chain replays).
@_date: 2015-02-14 19:11:02
It was also announced on the blog: 
I received two emails and read the blog post, which was plenty enough notice for me to register to vote (and I received the ballot notification email yesterday with my voting username and password).
@_date: 2015-02-23 21:12:52
Hey, thanks for adding the link to your guide!  (And you guide is quite nice.)
However, this sentence here isn't quite right:


It's a common confusion, but Bitcoin.org isn't part of the Bitcoin Foundation.  The Foundation provides us a modest monthly grant so we can pay for servers and some other stuff, and we put their logo on the bottom of the page and write a quarterly report telling them what we've accomplished thanks to their sponsorship.  Beyond that, they let us make our own decisions, for which independence we're quite grateful.
In particular, these full node docs were written by an unpaid volunteer (me) based on a [public suggestion]( from a Bitcoin Core developer, and they were reviewed by a couple other volunteers, as can be seen [on the pull request](
To be clear, I'm really grateful for the Foundation's support---but I want to make clear that we're separate from the Foundation, and that we also need volunteers like any other open source project.  If possible, I suggest you say "The Bitcoin.org in-depth guide..."  (Thanks again!)
@_date: 2015-02-23 20:40:19
My pleasure, and I hope you have fun learning about Bitcoin!  (I certainly had fun when it was all new to me.)
@_date: 2019-05-02 13:23:57


They can wrap the interface with something that does make it secure.  See [Bitcoin Core's documentation]( (emphasis added): "You may optionally allow other computers to remotely control Bitcoin Core by setting the rpcallowip and rpcbind configuration parameters. These settings are only meant for enabling connections over secure private networks or connections that have been otherwise secured **(e.g. using a VPN or port forwarding with SSH or stunnel).**"
However, like other people have commented, probably the best way to achieve their current feature set is using the P2P network interface of your node, similar to what GreenAddress does with its trusted peer mode.
@_date: 2015-02-05 14:07:32
Eh, I'd say it's mainly to warn merchants and other users that their security assumptions have been downgraded.  If you run a full node, you assume that you're enforcing all the consensus rules---but after a soft fork, that's no longer true.
Warning miners who are asleep at the wheel is just a nice bonus.
@_date: 2017-07-10 12:18:05


Actually, you can, and it applies particularly to example above: when you spend bitcoin, you almost always add a change output.  Wallets upgraded to segwit will likely pay a bare segwit output, not a P2SH output.
Also, note that the BIP70 payment protocol used by BitPay and several other payment processors allows specifying payment be sent to an arbitrary scriptPubKey, so any software that supports BIP70 can also pay bare segwit outputs without upgrading.
@_date: 2019-05-02 13:59:18
It used to support SSL encryption, but to use that securely the user had to create a certificate and share it with the remote system.  That was a pain and most advanced users who wanted to remotely control the daemon ended up just setting up SSH port forwarding anyway.
Security features like that aren't free to add and maintain.  Developers need to be careful that new features wouldn't break the encryption or otherwise cause problems and they need to monitor the upstream encryption library for issues ([e.g.]( so they could emergency patch them if necessary.  That means when a feature isn't being used, it's in the project's best interest to remove it, especially when it's the case that people who do need the feature can setup a third-party tool like ssh or stunnel to get that feature.
@_date: 2017-07-15 14:00:55
Note for people receiving transactions that you'll probably have to look up your transaction on a block chain explorer.  This could associate your IP address with the transaction, so don't do that if you're concerned about privacy (or use something like Tor).
The reason you have to look up fees on a block chain explorer is because most wallets don't have enough information to show you the fee paid by a transaction you received---they can only show it for transactions you sent.
@_date: 2016-07-23 14:08:55
I'll agree that it's significantly suboptimal, but it does seem useful to me to be able to quickly communicate information about what kind of upgrade process would be required in order to implement a particular change to the consensus rules.  I think the evidence of the terms' high utility is their continued and frequent use.
@_date: 2019-05-02 12:01:58


There's an [open pull request]( for Dandelion and a [description of some of its implementation challenges]( by Bitcoin Core contributor Suhas Daftuar.


It should be possible to figure this out from reading the text printed by `bitcoind -help`.  However, it'd be interesting to learn why you want to do something you know is insecure.  (Are you running a honeypot or something?)
@_date: 2017-07-13 16:20:36
Just a quick note that Bitcoin.org and Bitcoin Core are separate organizations.  There are several Bitcoin Core contributors who occasionally provide technical critiques of Bitcoin.org content and Bitcoin.org historically has hosted some content for Bitcoin Core, but that's the main extent of the relationship.  Note that for 18 months now, Bitcoin Core has had their own website.
To the best of my knowledge, no Bitcoin Core contributors besides Luke Dashjr have reviewed this post (and Luke only provided one correction, a useful one).  It's quite possible I'll find my email box filled with complaints from them about it when they wake up and read it.
@_date: 2015-02-16 08:54:37
I don't think there are any plans to release a new bootstrap.dat now that Bitcoin Core 0.10.0 and future versions can usually download blocks as fast as they can be verified.
@_date: 2017-07-06 20:08:53




Ideally all the outputs are the same amount as each other OR all the inputs are the same amount as each other.  This is handy because you can use a two-phase "tick-tock" cycle where,
1. You coinjoin with others to create a bunch of equal-amount outputs
2. You coinjoin with others where you all spend equal-amount inputs
(Repeat for as long as you have money.)
Of course, coinjoin would really be much nicer if Bitcoin had confidential transactions.
@_date: 2016-07-19 21:19:30


If this was just a blog post promising to use any patents they made for good, I'd agree with you.  However, they've backed it up with two legal documents ([DPL]( and [Innovators Patent Agreement](


Again, for some value of "pledge" that would be true, but the DPL is a legal license; see section 1.1 of the license [here]( and feel free to contact a contract or patent attorney about ensuring that you've fulfilled the conditions to become a licensee.


I see what they're doing as similar to how copyleft hacks the copyright system.  In the 15 years I've been using and contributing to free software, I've flip-flopped a few times on how I feel about copyleft versus liberal licensing (roughly the equivalent of defensive patenting versus conspicuous non-patenting), so I can understand your unease.  However, even during the periods when I wasn't a fan of copyleft, I did appreciate people who copyleft licensed their work in order to spread the free software virtues they and I held in common.  They attempt to use the rules of the system to negate the power of the system, which if it works will be an awesome hack.
@_date: 2019-05-02 12:26:11
If you follow [Samourai's instructions]( you will be sending your password over the Internet in clear text.  I've personally notified Samourai about this problem in other parts of their documentation and their response has been to accuse me on Twitter of being part of a criminal protection racket.  My recommendation is that you don't use their "trusted node" feature, because they encourage you to set it up insecurely, and that you also don't use Samourai at all, because it's operated by people whose response to user safety concerns is to lash out at the people reporting the concern.
@_date: 2015-02-05 20:27:36
Once an RC build has been validated by enough known community members (the current threshold is three signers), it gets uploaded here: 
That usually takes from a few hours to about a day after the version gets tagged.  Because of software license issues, I believe there are only a few people who can fully build the Mac OS X version, which means it sometimes takes more than a day when those people are unavailable (which I think happened over the Christmas holiday.)
@_date: 2015-02-05 14:10:19
This upgrade (BIP66) doesn't need a bump either---but it simplifies implementation logic and allows us to us the increased-version-number warning system to tell merchants that they need to upgrade.
I suspect that if Gavin could give advice to his younger self, he'd advise using a block or transaction version bump as part of BIP16's implementation instead of using a hard-coded switchover date.
@_date: 2015-02-16 14:51:00
Right, either PoW works at discouraging people from creating invalid blocks or it doesn't work and everyone who uses an SPV client is buggered.
Edit: oh, I just realized you were talking about flexible difficulty.  That's easy to fix: make the miners put the nonce for the extra flex difficulty in the coinbase transaction, so it isn't part of the "actual" block difficulty.
@_date: 2015-02-03 23:13:19
Thanks!  I'll keep my eye out for it.
@_date: 2017-07-13 12:32:16
It doesn't suggest selling (or buying) at all.  It's a standard investment disclaimer that applies as much to Bitcoin as any other investment.
@_date: 2015-02-08 12:32:15
Nodes that are running 0.9.x and earlier who choose the OP's node as their sync node for [Initial Block Download]( (IBD) will have their download speed capped at the OP's node's upload speed.
Nodes that are running 0.10.0 and later will download from up to 8 nodes simultaneously during IBD.  If OP's node is slowing them down relative to the other 7 nodes, they'll disconnect from it and try another peer to see if it's faster.
This means that it doesn't really matter[*] whether OP runs 0.9.x or 0.10.0 himself/herself.
[*] Technically, 0.10.0 raises the minimum supported [protocol version]( to 31800, which means that to help other 0.10.0 nodes, OP has to run a node more recent that Bitcoin Core 0.3.18 (released December 2010).  I suspect that won't be a problem. :-)
@_date: 2015-02-24 14:48:34
I like Coinbase, but I guess I kinda wish they gave me an option to (1) pay an address without logging in or (2) login to pay.
I assume to reason they want you to login is to track your activity as part of a process to help reduce fraud risk from zero-confirmation transactions, which lets them offer a lower price than BitPay.  It is my hope that BitPay will see this as an opportunity to offer an even lower price to people who are willing to wait for one or more confirmations before having their order confirmed, since that would let Bitcoin's native proof of work massively reduce the fraud risk.
@_date: 2017-07-13 16:26:19
Starting around 7/22 there may be an event (BIP92/Segwit2x) that will make confirmation scores less reliable than normal, but which is not expected to permanently result in two chains.
That means all you have to do is wait for extra confirmations before taking any actions regarding your money being final.  So for transferring your money from an exchange to your wallet, you might normally wait for 6 confirmations before you stop checking to see if the money is still there; during the moderate instability, you can just wait for 12 confirmations before you stop checking.
The major problem is July 31st/August 1st, where two permanently competing chains might start.  If that happens, you have to be very careful accepting or spending your bitcoins to ensure you receive the type of coin you expect.
@_date: 2015-03-07 22:00:51
Also, porting Linux/Windows software to OS X takes up roughly 50% of all build developer time in any open source project.
@_date: 2015-02-23 16:38:44
+1 for contributing however you can
Rather than being bored by Bitcoin, I wish I had more hours a day to contribute to all the things I want to see done.
@_date: 2016-07-10 13:40:57
- Minimalistic support for HD wallets was [recently added to master](
- The wallet supports multisig (didn't you add the RPCs for this yourself?) but there is no GUI prompt to help users with this.  The thing is, I only know of one wallet with a GUI prompt for multisig ([Bitpay Copay]( most other wallets don't have that feature and very few people use Copay even though it's been out of beta for about a year now, so it doesn't seem like a highly-demanded feature (although it certainly would be nice to have in Bitcoin Core).
- Regarding the extra bandwidth and disk space: aren't you the one saying that increases in the amount of those needed wouldn't be a burden for full node operators?  If you think 2x (2MB), 8x (8MB), 20x (20MB), and and rapid increase from 8x to 8,000x (8MB to 8GB) of today's resources aren't a burden, how you you think that the current requirements are a burden?  Or is it just that you don't want everyday people like me to be able to run full nodes to ensure the blocks and transactions we receive are valid so that miners can have even more power than the ability to choose the order of transactions?
(Also, note for readers: Bitcoin Core's typical bandwidth usage can be more than halved by using `-blocksonly` option (available in 0.12.x) and its disk space can be reduced to less than 5 GB using the `-prune` option.)
Of course, the site I recommended earlier for reading more about Bitcoin Core describes its [requirements]( in detail, so nobody should be surprised by the higher default bandwidth and disk space requirements as well as the other requirements which are common to all wallets.
For people who can meet those requirements, I think Bitcoin Core is much better than any other wallet because of its [decentralization-protecting]( and [privacy-enhancing]( properties.
@_date: 2015-02-24 17:56:22
Heh, I forgot 1Ali doesn't actually work because lowercase L isn't part of the base58 character set.  :-(
@_date: 2015-02-08 15:20:23
Pieter explains why in his answer:


I don't know of any Bitcoin experts who disagree with Pieter about this.
@_date: 2015-02-14 19:24:20
I dunno.  Maybe that's the case if they just clicked the button.  But the text says,


And the January Foundation Bits &amp; Bytes email said:








I think there was also at least one other email, but I may have permanently deleted it after registering.
Do you know off hand how many members voted in the last (first round of) individual seat elections?  Is it far greater than 364?
By the way, if you know of any candidates who did not register to vote, you want to put that in the Cons section of their Consider.it page.  Not reading the bylaws before becoming a candidate is a negative factor in my opinion. 
@_date: 2015-02-16 14:31:20
Yeah, I didn't really think through the pricing.  Good catch.
I hadn't heard about flexible difficulty.  That does seem like a better scheme.  Thanks!
(Also, valid-looking headers can always be attached to invalid blocks.  The only evidence we have that detached headers are correct is the cost of recreating the PoW protecting them.) 
@_date: 2015-02-08 15:42:47
I think you may be misreading the linked page.  Some facts:
* Bitcoin Core makes 8 outbound connections when it starts.
* By default, it accepts up to 117 (125 minus 8) inbound connections.  As you said, for this to work, you have to open your ports.
The linked page is about how to increase the number of outbound connections above 8.  This is what Pieter is advising against.  
Accepting inbound connections is necessary to support the network, so everyone is in favor of that (up to the default max connection count  of 125).
@_date: 2015-02-24 14:11:49
Reusing addresses doesn't just reduce your privacy, it reduces the privacy of others too---so please don't do it.  I wrote [an answer]( about this for Bitcoin StackExchange.
@_date: 2019-05-02 19:17:11
It sure would be nice if they mentioned that on the page about "configuring your node to prepare it for your Samourai Wallet".  In fact, it sure would nice if they mentioned it in their marketing so that people knew that they either had to use their mobile wallet only from home or had to set up this complicated extra thing.  Oh, and another nice thing would be if they warned their own users about the dangers of doing this over the Internet insecurely; this thread started when was putting his bitcoins at risk by trying to use RPC over unencrypted Internet.
@_date: 2015-02-03 21:10:48
Do you know if there's a link to the recording?  Also, where did you hear about it---was it on some feed I can subscribe to?
@_date: 2016-07-30 21:55:18


My understanding is that the moderators of this subreddit have repeatedly proven to the Reddit admins instances of vote manipulation on so it does seem like a good idea to remove off-topic content.  There are other subreddits which have tried the votes-are-the-only-moderation, and they've all become unreadable in my opinion.
I think it's ok that you're not happy with the moderation here.  One of the problems with moderation, as I see it, is that everyone defines the line between acceptable moderation and unacceptable moderation differently, so Alice may consider X moderation (or non-moderation) acceptable but Bob will not and there are million different Alices, Bobs, and moderation events so there's perpetual discontent with any moderation.
I don't know of any general solution to this problem.  My personal solution on Reddit is to click Add To Friends for anyone who I think contributes value to the community and then make my main Reddit page  so I can see what they're saying without having to read the trashier stuff (this is in fact how I saw your comment above; I added you when you started writing up the Bitcoin Core meeting summaries).
@_date: 2015-02-24 14:07:16
I got that exact same screen on Gyft.com last night and I chose Coinbase because it was cheaper.  Then Coinbase said, "login or create an account."  There was no address to pay or link to click to get a [BIP70 payment request](
I have a Coinbase account, and I like them, but I don't keep my bitcoins on Coinbase---so I closed the window and clicked "No" on Gyft's "Did you compete your payment" window.
Gyft then let me try again, and I chose BitPay, clicked the BIP70 "Pay with Bitcoin" link, and was done paying with my normal wallet in 3 seconds.
I'm appreciate Gyft giving me options, but I'm not going to click on that Coinbase button again.  I prefer to pay with my regular hot wallet.
@_date: 2017-07-13 09:53:13
The page uses Javascript to convert the time into whatever timezone your browser says it uses, so it seems likely that your browser thinks it's in Australia.  I suggest checking the settings for your system time and perhaps restarting your browser.
If you think the error is on the Bitcoin.org side, please reply here or [open an issue]( and I'll look into it.
@_date: 2015-02-24 20:26:13
Confirmed.  I am me.
@_date: 2016-07-30 20:43:27
There seem to be two separate concerns in your comment.  The first is an alleged blacklisting of GDAX; if I recall correctly, at the time they created the exchange, Coinbase/GDAX co-founder Fred Ehrsam had just written a blog pumping Ethereum, and the renaming of the exchange to GDAX coincided with their listing of Ethereum as a new asset class.  Given how hard they (and others) were pushing Ethereum at that point, it seems reasonable to me that a subreddit focused on Bitcoin and where historically altcoin pumpers have tried very hard to pump their wares would blacklist that domain.
The second concern is over an article posted to a website that exists entirely to promote an altcoin written by the creator of that altcoin and someone who does little else but promote his altcoin.  The article also mentions Ethereum three times, with 13 other mentions of Ethereum on that page at present (mainly in the comments).  That seems like exactly the sort of article which should be blocked from given the concerns mentioned in the previous point.
I also don't like worrying about having my comments auto moderated, but I don't know how else a small moderation team can deal with the large amount of altcoin material that people attempt to post to this subreddit every day.
@_date: 2019-05-02 17:16:59
The first link in that guide is to the page I linked above.  "You must have already [configured your node to prepare it for your Samourai Wallet](  (edit: for anyone jumping in the middle of this thread, don't follow those instructions.  They won't work with Bitcoin Core 0.18.0, and on earlier versions they will result in you sending your RPC authentication credentials unencrypted over the Internet.)
@_date: 2015-02-05 14:01:24
Old nodes will accept version 3 blocks, but they won't enforce the strict DER logic on those blocks and they won't ever require that all new blocks be version 3.  New nodes will enforce the strict DER logic on version 3 blocks, and after the switchover they will require all new blocks be version 3 or higher.
This means an attacker can create a block that looks valid to older nodes but which newer nodes won't accept, creating a temporary chain fork.  This can be used to create double spends at the cost of forfeiting block rewards.
Miners, merchants, and anyone who accepts transactions should upgrade their nodes before the switchover.
The switchover logic doesn't enforce any rules until 75% of hash rate in the last 1,000 blocks has upgraded, and doesn't require v3 or greater until 95% of hash rate in the last 1,000 blocks is upgraded.  It is hoped that this will make creating a multi-block fork difficult.
For example, to get 6 confirmations on a rule-breaking strongest chain, an attacker with at most 25% of hash rate will have to compete against the remaining 75%, giving the attacker a probability of success of 4.9943% according to Satoshi's probability calculator from page 7 of [Bitcoin.pdf](
@_date: 2016-07-07 20:20:10
Paging Jameson: (see parent comment)
@_date: 2016-07-06 17:53:34


I think this is comparing apples to oranges.  First, let's look at the similarities:
- Operating an economic full node provides a benefit to the operator (the assurance that the bitcoins they receive are valid); increasing costs of node operation drive out marginal node operators.
- Spending bitcoins provides a benefit to the spender (acquiring whatever is on the other side of the trade); increasing the cost of spending a transaction similarly drives out marginal spenders.
In that regard the two things are similar, but in two other regards the things differ:
1. Marginal spender Alice is driven out by less marginal Bob who is willing to pay more per transaction, so the overall number of users stays the same (all other things being equal).  On the other hand, when marginal economic full node operator Alice is driven out by rising costs of node operation, we simply have one less full node operator---which is a clear net loss for the system.
2. A sustained increase in transaction fees will be used to pay for more security for the system (more proof-of-work per block), which is a benefit to all users of the system.  On the other hand, a sustained increase in cost of node operation will likely result in fewer economic full validators, which is likely a loss to all users of the system.
@_date: 2015-02-13 18:07:45
BIP66 doesn't introduce version 3 transactions, it introduces version 3 *blocks*.  Unless you're a miner, there's nothing to upgrade.
The only thing version 3 blocks reject are signatures that don't follow strict DER rules.  These signatures have been non-standard since [Bitcoin Core 0.8.0]( (February 2013) and none have been added in the last several thousand blocks.
So any wallet that needed to upgrade, needed to upgrade over two years ago.  I don't think you have anything to worry about.
@_date: 2015-02-23 19:50:31
I wrote the instructions, but I didn't have access to Win 8.1 or OS X.  If you would like to help write the instructions for OS X, please see [this GitHub issue]( where I explain to another volunteer how to help us write the missing instructions.  Thanks!
@_date: 2016-07-19 17:54:43
Making patent law work for permissionless innovation rather than against it takes deliberate and sustained effort.  Thank you and everyone who worked on this at Blockstream for putting in that effort to make this a reality for your innovations!
@_date: 2015-02-13 20:02:59
You're thinking about [RFC6979 deterministic signatures](  One reason you may be confused is because Bitcoin Core 0.10.0 does switch to using RFC6979 for signatures generated by its own wallet.
It's not possible to enforce RFC6979  at the protocol level, so it will always be up to each wallet to chose whether or not to use deterministic signatures.  
@_date: 2017-06-03 12:13:15
Fair enough, and I agree with "the only way to prevent a chain split is to ensure BIP148 succeeds".  I deleted my response above also.  Thanks!
@_date: 2015-02-03 18:33:29
You can create an OP_RETURN output that has zero value, so no bitcoins are destroyed.  In fact, to create a standard OP_RETURN output it *must* have zero value.
You do need to add that output to a transaction with a non-zero-value input, so most people using OP_RETURN create a transaction with an input, spend all but the transaction fee to a standard P2PKH or P2SH address, and tack-on a zero-value OP_RETURN output.  If they're paying someone else's address, they may also add a change address returning some of the input value to themselves.
@_date: 2016-07-04 19:48:17
Thanks for this fantastic comment! I hadn't heard about using the P2CH-style commitment, but that makes a lot of sense.  Keep up the great work!
@_date: 2016-07-11 12:23:26


`getnewaddress` is the bitcoind RPC for generating a new unique address in bitcoind's wallet.  Currently the private keys for these are based on random numbers, but it's likely in the next major version of Bitcoin Core (0.13) you'll have the [option of using an HD wallet](


The `listsinceblock` RPC will list all the transactions your wallet has received since a certain block.  When you process a bunch of transactions, you store the block hash (block id) for the tip of the chain that includes all those transactions and then you poll `listsinceblock` every 5 seconds (or whatever) and bitcoind will tell you about what transactions you've received since then.  Then you process those transactions and start polling on the new current block id.
You can also use zeromq to receive a push notification when a new transaction or block arrives.


Ideally, you'd send money straight to cold storage to save on extra transaction fees. Bitcoin Core provides full support for a watching-only wallet (or a wallet with both a watching-only and spendable component).  So on the cold wallet (which doesn't need to sync the blockchain) you create a bunch of address, dump their pubkeys, and use the `importpubkey` RPC on the hot wallet to import them.  Then your hot wallet will get notifications for any transactions that affect your cold wallet (but, of course, your hot wallet won't be able to spend those bitcoins because only the cold wallet has the private keys)
@_date: 2015-02-04 15:01:21
Would you deposit money with a company that specializes in anonymous transactions?  That sounds like a recipe for losing your money to a government raid or losing your money to a ponzi scheme.
@_date: 2019-05-02 12:10:50
Release notes are usually maintained on the particular branch (e.g. `0.18` for 0.18.*) and are then manually moved in a PR to that folder on the master branch a few days after release.  That note-moving PR just hasn't happened yet since the release just occurred.
@_date: 2016-07-10 13:04:21
Bitcoin Core has a number of advantages over other wallets:
- It [fully validates]( every block and transaction it receives, so even if that transaction only has one confirmation, you know the block it is contained in was valid.  No non-full-validation wallet can provide you that assurance and it means Bitcoin Core is [resistant to several types of attacks](  In addition, by fully validating the transactions paid to your wallet, you provide the most effective mechanism for rejecting invalid blocks created by miners, which enforces the consensus rules and [helps keep Bitcoin decentralized](  I suspect this is why Andresen doesn't want you to run a full node: because economic full node operators stand in the way of his changing the protocol using a hard fork.
- It has [better privacy]( than any lightweight wallet for the simple fact that it downloads every block and every transaction---not just transactions affecting your wallet.  That means anyone monitoring your Internet connection can only see that you run a full node; they can't see which transactions you're interested in.  It also relays transactions for other nodes and so the transactions you send are harder to identify than other wallets that only ever send their own transactions.  Bitcoin Core has fantastic Tor support and is one of the only wallets that can [find peers in a totally decentralized fashion](
- It's graphical user interface isn't slick, but it has [several features]( you won't find in other wallets, such as coin control.  And yeah, if you are an "uber-geek who enjoys fiddling with technology" there is an incredible number of things you can do under the hood.  For example, if you can use its RPCs, it makes a fantastic cold-wallet/watching-only wallet and you can write simple scripts to monitor information about the block chain using your own trusted node rather than a trusted third-party information source.
If you want to learn more about Bitcoin Core, I suggest [starting here](
@_date: 2016-05-13 23:03:16
You're correct that it does not work against that whitelist-style censorship.  If a majority of the hash rate only extends a chain containing only whitelisted transactions, then we'd have to change the proof of work formula to replace those censoring miners with non-censoring miners.
@_date: 2016-05-14 19:34:59
Since 2013, all effective miners have used ASICs which require an upfront investment that is (they hope) paid off over time from mining, provided they produce blocks that Bitcoin users accept.  If we, the users, decide to change the POW formula, then those ASICs become useless for Bitcoin mining, and so the investment in them is lost.
This is a punitive measure.  It immediately harms the profits of the censoring miners, possibly driving some or all of them out of business, and it signals that any new miners who invest in ASICs or other specialized hardware for the new POW formula may have their profits harmed in the future if they decide to censor transactions, so hopefully they never try that.
@_date: 2016-07-22 17:53:01


That was a soft fork, not a hard fork, because the change to the consensus rules was backwards compatible with existing full nodes.  I personally call it a retroactive soft fork because the new consensus rules (preventing the integer wrap on &gt;1 outputs (a wrap on 1 output had previously been soft forked in), limiting all outputs to a maximum of 21 million BTC, and also at the same time removing a dozen opcodes that may have been vulnerable to overflow-style errors) were applied to all transactions in the chain, including those that had already happened.
This type of retroactive soft fork stands in contrast to the way non-emergency soft forks are currently done where new rules become enforced at a particular block height, grandfathering in any transactions below that height which violated that rule.  I believe the P2SH soft fork was the first non-retroactive soft fork.
When a retroactive soft fork occurs, the miners enforcing the fork deliberately fork the chain from an earlier point immediately prior to the first transaction that violates the new consensus rule(s).  That's what happened in the value overflow incident: the miners who upgraded to Nakamoto's emergency release began mining from before the block which contained the 184 billion new bitcoins.
Edit: I added some of this information to the Value Overflow wiki page you linked, along with a link to Nakamoto's actual soft-forking patch.
@_date: 2016-07-28 09:15:41


This is not correct.  The first block on the invalid chain[1] contained 98 non-coinbase transactions.  By the last block on the invalid chain[2], SPV clients connected to pre-0.9.5 Bitcoin Core nodes were showing those 98 transactions as having 6 confirmations, even though not a single one of those confirmations was valid.  (I think you owe thanks here for persisting on this point despite your disbelief.)
Happily, in this case, all of those transactions were eventually confirmed in the valid chain, so no one lost money---but nothing at all ensured that outcome.  For more information, including info about a subsequent fork that lead to 255 non-coinbase transactions being shown as having 3 confirmations, please see: 
Security differences between full nodes and SPV wallets are [described in detail on Bitcoin.org's Bitcoin Core pages]( (with BreadWallet actually being used in the example case under Transaction Witholding).  Also, the [privacy page]( describes how SPV clients have fundamentally weaker privacy than full nodes, although BreadWallet does get a positive mention in one section there for being the only P2P SPV client I know of to use decentralized peer discovery (thank you for that).
[1] 0000000000000000009cc829aa25b40b2cd4eb83dd498c12ad0d26d90c439d99
[2] 000000000000000013fe26675faa8f7dccd55ce5485bb6d0373fa66345901436
@_date: 2016-07-05 03:24:34


A number of miners hardcode the version number in their software (primarily their pool software, I believe).  On BitcoinCore.org [we recommended]( any miners who hardcode unset the CSV signal bit before the end of the the locked-in period so they didn't end up false signaling.
@_date: 2015-02-24 15:43:42


Just FYI, but I've been trying to use block subsidy + fee = block reward.  I got this from but I think other core devs say the same.


How did you come to that conclusion?  An increased coinbase maturation time would discourage attacks that would make bitcoins less valuable within the no-spend window, but I haven't had the impression myself that most significant price swings so far have been caused by miner activity.
I'm not an investor/trader, but I'm under the impression that frequent significant price swings are generally an indication of an underdeveloped options market.
I'm not seriously suggesting this, but if you wanted to encourage the development of an options market to dampen price swings, you would introduce more variability into Bitcoin.  For example, you would make it so all coinbases produced during *p* period matured at the same *t* time.  For example, all the coinbases produced during a difficulty-period (2,016 blocks) matured at the end of the following difficulty period---this would possibly flood the market with a whole bunch of coins at once, and then leave us with a two week dry period, followed by another sudden flood.