@_author: seriousjerry
@_date: 2017-12-19 16:32:31
I agree that fees are unfortunately quite high/cumbersome right now, but it's not correct to say that hodling was not part of btc's original (and current) philosophy. If it was solely to be used as a means of payment, it would have been created with a more inflationary supply, but it wasn't. So my guess is that HOLDing is a behavior that btc's creator wanted to encourage from the outset. 
@_date: 2017-12-17 06:59:07
Right, I guess the argument is that it would cut down on the number of "disgruntled customers" (people who buy small amounts of btc but can't afford to move/access that btc right now and may never be able to due to fees). Reducing disgruntlement seems good.
However, it would simultaneously reduce the potential market size. Now all of a sudden anyone with only a few dollars available to allocate toward crypto (and remember, that's all many of the early bitcoiners had too!) would be priced out and would necessarily look elsewhere, possibly to other networks. Reducing potential market size seems bad.
@_date: 2017-12-19 16:38:09
@_date: 2017-12-17 07:23:38
Yep, I tend to agree with your analysis there. 
@_date: 2017-12-17 07:02:13
Yes I know this, but thank you for pointing out that the analogy could be misinterpreted. I was referring to the transfer in/out of the exchange (hence the delivery fee) not the trade fee itself. Sorry if the analogy wasn't clear :-/
@_date: 2017-12-19 16:36:54
Hmm, maybe you can get that on the RSK side chain? :-)
@_date: 2017-12-19 16:36:07
MAST and schnorr seem like a good pair of tools to bring some reasonable privacy enhancements to btc. Is that how you see it too? 
@_date: 2017-12-19 16:40:43
I'm a little confused as to the references to segwit2x in multiple replies to this thread. Are you suggesting that, presumably due to fees segwit2x will be reinvigorated? 
@_date: 2017-12-19 16:35:05
So by this you mean you'd like to see both lightning and a hardfork to 2mb in 2018?
@_date: 2017-12-17 18:02:01
Lol, not yet but maybe with lightning :-)
@_date: 2017-12-17 07:05:53
Actually you bring up a good point. I'll edit the post to reflect that I'm referring to the FIRST order made by a customer. If the customer already has 100x the network's current avg tx fee, then they could if course buy just a marginal amount more. 
@_date: 2017-03-26 02:04:39
Random thought along the same lines: if bitfury has good hardware and is all for what the economic majority wants, perhaps now is the time for their investors to take a healthy profit and partially exit by to "going public" (the bitcoin way) where they sell/auction the majority of their shares off to bitcoin users/holders. Part of the deal could also include open-sourcing their asic design. This would be a good liquidity event for their existing investors and good for bitcoin as a whole too. Win win?
Probably a silly idea but figured I'd put it out there anyway :-)  
@_date: 2017-04-03 20:59:17
Answering my own post. I guess this concept is sort of a chicken and egg problem. There isn't any incentive for hodler's in regions with below market electricity/asic costs to participate. They are better off simply mining on their own in a standard pool. So that means that literally everyone in the proposed geographically distributed pool would, almost by definition, be mining at a loss. Doesn't mean that such a pool wouldn't be worth it for hodler's to participate in, just that there probably wouldn't be any pool participants that are actually mining at a profit, so there wouldn't be any "profit" for the pool to redistribute in the form of subsidies to the less profitable regions.
@_date: 2017-05-12 20:29:06
fair point :-) though I was mostly joking about a generalized OP_CHECKBLOCKBYTEn, the reasoning behind it is that we don't know what sorts of things that miners might pull in the future, so having an opcode like this would provide users an ultimate veto in the form of "you can have fee x if the block you put it in conforms to a,b,c otherwise you get fee y" where x &gt;&gt; y
Of course it's probably not practical to allow every transaction to reify and inspect the block in this manner, but man it would be cool :-)
@_date: 2017-05-10 17:52:57
another interesting side effect of this is that people would presumably open larger channels (thereby allowing more transactions to be conducted) with miners whose mining policies they prefer -- a nice feedback loop for all
@_date: 2017-05-31 03:26:19
Thanks Jeff for being level headed and reasonable. Happy to see this moving forward quickly too :-)
@_date: 2017-05-05 17:11:13
but since, by definition, the transaction would be larger than 1mb it would be causing an invalid block in the first place (for non-participating miners/nodes) -- couldn't a group of miners that want to mine on this transaction just ignore the segwit flag activation threashold and just treat it as "activated"? 
edit: clarification
@_date: 2017-05-07 21:06:08
Do we get to see the results of the survey?
@_date: 2017-05-05 17:23:58
my thought as to why it might not be possible is mostly because it seems like the current segwit deployment is only "accessible" by nodes once the flag threshhold has been reached? So to get around this (if possible?) my guess is you'd need to string together 2016*2 + 1 = 4032 + 1 transactions to cover the necessary timeframe to activate segwit. 
The first transaction would be &gt;1mb and have pay-it-forward outputs to another non-segwit transaction (no need for this one to be bigger than 1mb), followed by another non-segwit transaction, followed by another non-segwit, and so forth until the very last transaction which would be a segwit transaction (presumably the first one after activation).
Is there something wrong with this logic? probably, lol
@_date: 2017-05-18 18:25:54
Sorry, I'll try to explain the reasoning.
The overarching goal is to safely increase on-chain transaction throughput (aka blocksize). As long as this is done safely, then such a throughput increase benefits all users. So what does it mean to do it "safely?"
Well, there are time complexity costs imposed on the network's users. Users that run nodes (including other miners) would immediately have to spend more time verifying a larger block, and it would also take the larger block (assuming it is valid) longer to propagate through the network. As such, if nodes are to risk spending the time and bandwidth to verify and propagate the larger block, they need to be assured as early in the process as possible that the odds of the block being invalid are slim. 
By being able to *prove in the first couple transactions of the block that the miner has taken a larger risk than the validators*, this is a good incentive for the validators to verify the integrity of the rest of the transactions in the block.
One way we can reasonably and objectively infer that the miner is taking a larger financial risk than the validators is by delaying the miner reward by an amount of time that is at-minimum longer than the amount of time it takes the validators and network to validate and propagate the block.
So if miners right now are producing 1mb blocks and waiting 100 blocks for their reward, and we assume the network's validation and propagation time grows quadratic with blocksize (a conservative assumption), then the miner's reward should be delayed at-minimum quadratically to offset that time complexity cost.
A 2mb block would delay the reward 400 blocks.
A 3mb block wound delay it 900 blocks.
The 100mb block was just an example of this taken to the extreme. Even then though, let's say a miner did take such a risk and cleaned out most of the mempool. Now we have a bunch of happy "customers" (whose transactions are no longer sitting and waiting to be served) and happy validators since it only took them a small amount of time to verify the validity of the block and propagate it relative to the financial risk the miner is taking by locking up his reward for 18 years.
As such the miner that produces larger blocks is either:
1) benevolent/honest and believes in the long term and that the risk will pay off (good for all)
2) malicious but can't recoup the cost of *prematurely* producing larger-than-necessary blocks, thereby making the network more immune to his malicious intent
I hope this is making more sense now?
@_date: 2017-05-21 23:12:21
I'll start. My thinking is 50% chance of both. RSK seems like it will happen regardless. Too early to tell for UASF.
I hope I'm wrong and the answer is actually 99.99%
@_date: 2017-05-25 01:40:29
43 years ahead of his time!
@_date: 2017-05-12 20:20:02
personally I still think that something more akin to this ( would be optimal as it would perpetually be putting downward pressure on the blocksize and yet still allow larger blocks as long as miners pay for them via delayed rewards (thereby justifying the cost to the network of verifying/relaying them)
@_date: 2017-05-12 20:32:11
lol, true
@_date: 2017-05-12 20:07:01
Exactly. I mean it definitely puts more power in users hands to have more opcodes like this so I don't see the rationale for doing only one for checking the version number. Instead why not just do one that is for the entire block: OP_CHECKBLOCKBYTEn where you can check the value of the nth byte in the block and confirm it is to your satisfaction and invalidate your transaction if it is not :-) 
@_date: 2017-05-18 03:00:37
You're basically referring to transaction output that "expires." I think the problem is that the funds assigned to that output would essentially be lost forever if the transaction is not included in a block before expiration. I doubt many senders would be comfortable with that risk :-)
There might be a way to do it by opening a payment channel with a miner (or multiple of them), but I'm not sure.  
@_date: 2017-05-05 22:36:01
Thanks for the reply. Hmm, wouldn't it be possible though to sort of daisy-chain some bounty-related transactions together such that a) the bounty is only paid out when the final transaction in the chain is mined and b) the minimum "length" of the chain of transactions (ie: the number of blocks it spans) is longer than the number of blocks necessary to activate segwit?
@_date: 2017-05-31 07:37:46
Because it costs miners pretty much nothing "extra" to make bigger blocks, but absolutely costs the rest of the network (including other miners) extra time and money to validate and propagate the block.
I too would like a dynamic blocksize but would prefer it be such that the costs borne by the network for an increased blocksize are paid for (indirectly via additional PoW and/or delayed mining reward) by the miner that made the larger block.
@_date: 2017-05-12 13:54:03
Nothing stops that behavior right now in the network as-is, but what this proposal does is makes that behavior expensive for both the whale and the miner (ie they both better be pretty sure that the price will rise substantially to justify the risk).
@_date: 2017-05-12 19:55:53
Pardon my ignorance, but if we are adding op codes, why not also just add an opcode like, say, OP_CHECKBLOCKSIZE and which would allow transactions to signal the allowable maximum blocksize of a block that tries to include the transaction. If the block's size is above the number provided, then the transaction (and hence the proposed block) is invalid.  
@_date: 2017-05-18 15:09:30
Doing so is a distinct cost to the miner that is more than the cost to the network for the larger block. Miners want to maximize the present value of their rewards. Because of the substantial time delay, the time value of money wound eat into the present value of their reward. As such they would only do this iff they are confident that doing so does in fact maximize the present value of their reward. Otherwise they are better off publishing a block, say, half that size and waiting 1/3 of the time, and so on and so forth until they get back down to a 1mb block and 100 block (17 hour) delay.
P.S. thanks for reading my long post. I tried to make it somewhat story-like to help people really think through what it means to be a miner or a validator. 
@_date: 2017-05-31 21:13:58
Thank you for your reply. Of course you're correct that any rational miner who values the reward would not engage in this behavior. However, that's not my point. My point/question/thought experiment is more about other network participants with a nonzero balance. 
Surely there is "some price," that these nodes would in fact accept a larger 100mb block (or series of them, or entire chain of them, etc). It sounds like what you're saying is that a "charitable miner" who burns his entire reward would not be payment enough, so what is it then? If you knew that a 100mb block size also would cause a US$1MM coin price (remember, this is a thought experiemnt), then surely it is worth it then, no? 
@_date: 2017-05-26 18:55:01
Mining is one incentive to run a full node. It's currently being argued by some that the mining incentive is the only incentive necessary to run a full node.
However, there are other incentives to run full nodes, such as a) being an exchange b) being a large merchant c) operating a lightning/relay node (once segwit &amp; lightning are live)
The battle we are currently seeing is simply that miners know that the post-segwit network (as measured by full nodes) will start de-centralizing even further than it already is which will make it harder for them to control (via blocking various upgrades) the network's future.
Hope that helps.
@_date: 2017-05-18 20:19:03
Ok, so with your assumptions validation is approximately O(n^2) and in the worst case propagation is also O(n^2)....does that mean that the combined complexity is O(n^4)? or is it still O(n^2) ?
Thanks for your help!
@_date: 2017-05-19 03:50:19
Thanks, that's what I figured too.
@_date: 2017-05-12 13:58:29
No, if the maturity time for a larger block exceeds the miner's typical cashflow cycle (measured in fiat) then under this proposal it would be rational to make a bigger block only if the miner is confident that the price will be substantially higher when the reward matures. Same goes to a whale who might fund such a block.
Net result is that miners and whales can make higher blocks only if they are confident that price will rise substantially during the maturity time. Otherwise they will lose money. And that's the point. 
@_date: 2017-05-03 17:08:05
We need more context. 
Why only post "part" of Gavin's email if this is so atrocious? 
There is nothing wrong with giving someone honest feedback about the situation from the perspective of the sender (Gavin), and since this feedback (based on the excerpt of the email we have seen so far) pertained more to social nuances than technical details, it makes sense that it was sent as a private email rather than cluttering the whole list. 
What is wrong is just posting convenient excerpts of things. Mainstream media quotes people out of context all the time. Let's not be like them. 
 
@_date: 2017-05-06 00:54:00
got it...so the ironic thing here is that segwit is "too good" at not screwing up already-deployed nodes :-) Thanks for answering my questions.
@_date: 2017-05-22 14:05:53
So basically, presuming majority hashpower agrees to this proposal, they could use the new version bit as a way to guarantee sw-lock-in (original srgwit) in one difficulty targeting period? The new bit is just a convenience/tracking mechanism?
@_date: 2017-05-18 04:48:22
Good point. Perhaps it is possible. Though I'm not sure any of the existing op codes would let you do it. 
@_date: 2017-05-18 19:29:41
In exchange for collecting the transaction fees (in 18 years) on the entire current mempool's worth of transactions. Seems like a more than fair trade to me. :-)
@_date: 2017-05-17 15:36:57
Got it. Thanks for your reply!
@_date: 2017-05-04 04:22:05
Showerthought: is it possible to create a 1mb transaction like this that ALSO has a segwit component to it? Such a transaction if mined (and built upon thereafter) would immediately give bigger blocks AND segwit - albeit via a hardfork. 
Is such a transaction even possible?
@_date: 2017-06-05 16:04:50
Thanks. And good reminder to me to google first ask questions after :-)
@_date: 2017-06-05 16:06:38
Got it. Thanks so much for your reply. Rough order of magnitude is what I was wondering. Didn't know if it was 50k or a million gates. Sounds like thankfully it's closer to the lower end :-)
@_date: 2017-06-10 19:45:22
History isn't kind to people that underestimate the competition, and that's simply all I'm wondering now. Are we -- as bitcoin proponents -- underestimating the competition? Market so far seems to be saying yes.
@_date: 2017-06-02 18:53:56
Not sure what you're getting at here. Are you saying just mine empty blocks that have literally zero transactions in it (not even the coinbase reward tx)? Obviously in that case the system grinds to a halt, but due to the cost of mining a block like that it's also a highly irrational and costly thing to do.
@_date: 2017-06-20 20:22:31
Not sure I follow. What's the next "next best thing?"
@_date: 2017-06-03 19:39:21
No, mining a bigger block as-is (assuming the network supported it) would only increase the immediate revenue for that specific miner that mined that specific block. At the same time it would increase immediate costs for *everyone else.* 
Hence, it is important for the protocol to provide a mechanism that:
a) allows miners to create bigger blocks at-will, but 
b) only allows them to do so if/when they are willing to indirectly compensate the rest of the network for it's cost in validating and propagating those blocks
One way to do this would be to delay mining rewards (ie network would accept a block twice as big but only if the reward was delayed 4 times longer). This ensures conservatively that larger blocks wound only happen if it's best for all and won't cause a centralizing effect. 
@_date: 2017-06-10 20:00:54
While I agree with and feel your frustration. I guess to some extent the market is in fact deciding already? Despite Bitcoin being at or near highs, its growth lately has (sadly) been less than that of the competition. 
@_date: 2017-06-10 19:52:48
Lol. Fair enough. Though I did not mean for my post to come off how you may have interpreted it. I'm simply a longtime bitcoin hodler that is very frustrated by bitcoin's seeming state of affairs relative to the competition. The thing that bitcoin really has going for it is that there is no single "leader" with enough influence lead network participants through this mess without contention. While the lack of single leader is one of the reasons I love bitcoin, it is almost as if that property will the the reason why it will (perhaps temporarily?) likely give up its number one spot. I simply do not want to see that happen.
@_date: 2017-06-05 18:56:04
Apologies for the confusion. There would still be incentive to do it because there would still be a chance of profit (and hence also a chance of loss) -- it's simply that this would cause a miner to "think twice" about simply producing a huge block on a whim. In this scenario the future value of their reward (denominated in btc) is known (ie: subsidy + fees, delayed til whatever time). But since we know that miners have real expenses (denominated in non-btc), they will necessarily discount the future value of the reward at some rate to arrive at their own perceived present value of the reward. This present value is different for different miners (because they all have could have different time preferences and cost structures) and what this does is allows those with longer time preferences to still remain profitable by producing larger blocks (at the cost of waiting longer for their reward).
@_date: 2017-06-02 22:43:24
Precisely! This whole idea actually stems from my desire to have the reward lockup time be a (simple) function of the block height (ie a proxy for the network's "age").  Bitcoin is approx 8 years old. If miners today were mining rewards that are locked up for 4 years (rather than the 16 hours that corresponds to 100 blocks), we can be much more sure that the miners are thinking longer term.
@_date: 2017-06-10 18:30:09
I realize marketcap isn't a perfect metric. There isn't a perfect metric. The thing that worries me most is that I always thought when the rest of my friends woke up and finally decided that I wasn't crazy for talking about and investing in cryptocurrency (and specifically bitcoin) that they would, as their FIRST MOVE in to the space buy some bitcoin. Now I'm (sadly) seeing that many people's first move into the space is actually buying something else. The network effect of that alone is something that all of us longtime users/investors should be concerned about, no?
@_date: 2017-06-05 15:59:57
Block reward delay (currently a constant 100 blocks ) would increase slowly with network age. This not only weeds out marginal miners but also weeds out short-term mindsets. 
@_date: 2017-06-13 05:03:26
Blast! Thanks, I fixed it.
@_date: 2017-06-16 01:49:21
I would like to know this too. My understanding is that segwit could make the RSK's interop with bitcoin  less tedious.   
@_date: 2017-06-10 18:14:11
Yeah, you make good points. I agree that Core as a whole is both competent and wise. However I do get very concerned that bitcoin will not have much competitive advantage over altcoins once/if it loses its  spot by market cap. And high fees aren't doing any favors either. 
I have waited for the day when people are finally calling me out of the blue and asking how they can finally (better late than never, right!) join in the cryptocurrency revolution. What I did not expect though is that now 80% of the time when I hear from those people, the first one they want to buy is, unfortunately, not bitcoin. That is sad, and frankly, scary.
And yes, the most frustrating thing about Core to me is actually the contradictory behavior of "we want users to decide" but "we won't include user-driven flags/behavior" in the software. Can't have it both ways.  
As for miners, it's time to sh*t or get off the pot. We know that miners, in the long run, are not going to settle for anything less than a dynamic blocksize that allows for almost arbitrarily sized blocks. Any hard cap will simply not hold up in the long run. Therefore the discussion should be about not how large the blocks are to be but, instead, at what price (and how) can the miners compensate/pay the network as-a-whole for making larger blocks (they can recoup this cost via fees thereby keeping downward pressure on blocksize).
@_date: 2017-06-05 15:25:27
True, which is why it's important that any marginal revenue they receive from larger blocks is offset by a marginal cost incurred by that miner that is effectively, albeit indirectly, paid to other network participants. 
@_date: 2017-06-05 22:06:31
Usually I'd say that's true -- but there's a lot of psychology at play here too I think. If I were a miner, unless/until there is a true dynamic blocksize mechanism in place such that I can always, if I'm willing to take the risk, pump out a block of almost arbitrarily large size, then I'm going to feel penned/boxed in and be unhappy/disruptive.
@_date: 2017-06-09 22:18:03
Bitcoin MUST upgrade in some way, shape, or form on or before August 1st simply to prove to the world (and competitors) that a "leaderless" protocol CAN coordinate a network-wide upgrade. Longtime users and hodlers are fleeing to competing networks at least in part because of a fear that bitcoin's network is not ever going to upgrade. Bitcoin needs to eradicate that fear in the minds of its longtime supporters, or it risks losing them.
If the "upgrade" is in the form of some amalgamation of bip148, bip141, and segwit2x -- as long as it doesn't split the chain and we know beforehand with greater than 90% probability that the chain won't split -- then so be it! Let's do this!
@_date: 2017-06-05 15:18:22
Interesting. I like what you're trying to accomplish, but what about if the mempool is much much greater than 15mb at any given time? Why not a once daily 100mb block by the same argument? I'm guessing this daily large block wouldn't have any subsidy (no need) and just have fees?
@_date: 2017-06-16 21:13:21
Interesting. Thanks for your response. Hopefully more devs will also respond.
@_date: 2017-06-04 00:42:14
I agree with you. By "everyone else" I mean any full nodes, including other miners, that did not partake in the creation of that particular larger block and hence did not benefit from the increased revenue that it provided to the miner that mined it. To encourage those other nodes to play along, a big block miner should be willing to prove to them that he is adding skin in the game (perhaps via delaying the mining reward)...if they disagree with him and think that he was premature in creating such a large block, then they at least know their costs are covered (by delaying the reward it temporarily reduces supply) for spending the time validating and propagating the block, and they are able to sell their own coins and leave (thereby dropping the price and closing the much-needed feedback loop) all before the miner's reward is spendable. Net result: miners would only do this if it is beneficial for network health and the economy - which is what we want :-) 
@_date: 2017-06-13 00:25:15
Interesting. Thanks for the reply. Regardless of how it is done in the future (mined or not), the important thing is that a) it uses BTC as the internal unit of measure and b) it can underprice any/all competitors with regard to smart contract "gas." If RSK can do that, then I think bitcoin would be sitting very pretty from a smart contracting perspective!
Edit: typo
@_date: 2017-06-05 19:08:44
Probably better in your head to work through it with something like 100 miners of various relative "strengths" (ie put them in order from strongest to weakest). Play a few simulated rounds of the game (solving a block) and see what happens. With only 2 miners (or any scenario where one miner has greater than 50% of the strength) you start getting into weird territory that complicates things quite a bit. As long as there are lots of miners though it all works fine :-)
@_date: 2017-06-07 05:34:39
The parameter of 65% seems arbitrary if a simple majority is all that is necessary. Why not just make it a straight up 51%?
@_date: 2017-06-02 18:51:45
Thank you for your detailed reply. I'm glad you're also intrigued by the concept. 
While I like your solution (ie: reducing the reward directly rather than extending the wait time), the reason why I focus on the wait-time (burning coins = infinite wait time) is that it:
a) mathematically accomplishes effectively the same thing as reducing the reward directly
b) as blocks get bigger there would be more and more "locked up" mining rewards of various sizes and maturities. This is the first step to having a healthy "bond market" where these bonds are essentially backed by the "full faith and credit" of the bitcoin network. Hence these bonds could be traded (presumably off-chain initially, but maybe on-chain in the future) and the prices that they would trade at would inform all sorts of other use cases. For example, if you can look at the current trading price of some 5 yr bitcoin bonds then you would know the true "cost" of locking up coins in a lightning channel, etc.
What do you think?
@_date: 2017-06-05 19:15:21
Well, even with what you describe there would still surely be SOME miners that would mine segwit txs even if the others boycotted. And the irony is that the miners that do mine the segwit txs can demand higher fees since they would (temporarily) be the only game in town. The boycotting miners would see those fees and realize they are missing out and quickly switch over. Then all is well in bitcoin land again :-)
@_date: 2017-06-02 19:13:01
Just realized that I did not give an example of how to make it time based (in my example the subsidy+fees are just burned (or otherwise unclaimable) for eternity. Obviously that does not work, but the point is that there is probably some timeframe where it does.
I read somewhere that a worst-case time complexity cost on the network as a whole of validating and propagating a block is quadratic with the blocksize.  Now the network seems to at least be functioning correctly (ie: at or near capacity) with 1mb blocks and a reward lockup time of 100 blocks. Keeping a 100 block lockup minimum for security purposes is smart, so the simple math would be: reward_lockup_time = max(100, 100*n^2) where n is blocksize in megabytes and rewards_lockup_time is measured in blocks.
Miner wants to make a 100mb block and therefore lock his reward (subsidy + fees) up for 19 years? Sure...I don't see a problem with that.
Miner wants to make a 2mb block and wait 2.8 days (rather than the usual 0.7 days)? Again, I think that's a fine trade off for the network. 
More happy users :-)
@_date: 2017-06-10 19:59:10
I think for many of us, "Bitcoin" was/is supposed to be, at all times, the leading currency for hodlers relative to its competition. Its competition in this case is other cryptocurrency networks that either a) have the same goal or b) might achieve the same goal as a side-effect of another goal they claim to have.
@_date: 2017-06-10 03:46:39
This. ^
@_date: 2017-06-02 21:22:57
Yes, I think, for the most part, we are trying to say the same thing?
Basically I'm saying, if we know that increasing the blocksize linearly causes quadratic slow-down in validation and propagation costs to the network, then in order to compensate for that action, the reward associated with that increase should also be quadratically delayed. Doing so ensures (I think?) that miners will only take that action if they believe that it's the best thing for the network (ie: that doing so will raise the future value of the reward such that it compensates the miner for taking the risk of delaying the reward in the first place). 
Hope that what I'm saying makes sense :-)
@_date: 2017-06-10 18:24:53
Yes, I'm confused by that comment too.
@_date: 2017-06-20 20:24:47
This is fantastic! Thanks for sharing!
@_date: 2017-06-20 20:26:31
Ha, same here. 
@_date: 2017-06-02 21:38:48
Yes, in other words...it's not that big blocks are "bad" per say, they are simply "expensive." In this scenario, if other network users believe that miners are mining blocks that are too large they will start selling their coins, etc. Because the miner's reward is locked up for a period of time much longer than it takes for other users to sell their coins, well, then miners will absolutely think twice about increasing the blocksize on a whim. They will only do so if they believe the network (and market) are ready for it -- otherwise they risk heavily devaluing their rewards.
@_date: 2017-06-14 13:56:08
Isn't the more likely scenario that, despite what Bitmain's blog post says, it will split it's own hashpower between mining (publicly) the UAHF chain to get it started, and mining (privately ideally, but publicly in the worst case) EMPTY blocks on the UASF chain?
Doing so would give it at least a chance of rendering the UASF chain useless/chaotic for a long enough time that the "economic majority" might simply switch to the UAHF chain, for sheer sake of convenience if nothing else?
@_date: 2017-06-20 20:23:00
Fair enough. Just trying to think ahead :-)
@_date: 2017-06-10 18:26:08
Agreed! Activating Segwit now (or really any upgrade whatsoever) is necessary solely to prove to people/world that bitcoin CAN still upgrade.
@_date: 2017-06-05 15:34:30
Thanks for the links. Pieter's seems like a decent lower bound as long as the tech keeps up (probably a safe assumption), but still doesn't seem to address the fact that non-mining full nodes undoubtedly have higher marginal direct costs (bandwidth, storage, and compute) with growing block size.
Interesting that monero actively disincentivises big blocks. I wonder how that will play out as demand scales. Perhaps it's the closest to what I'm after though and will take a closer look. 
Which would be your favorite for bitcoin?