@_author: roconnor
@_date: 2017-12-02 22:54:29
Just to be clear, as far as I understand Antminers come with ASICBOOST circuitry physically manufactured into the chips and this fact is not in dispute.
Jihan claim is that he went through the trouble of manufacturing his chip with ASICBOOST circuitry in them, something that if he activated would save him money but that he has never used.  It's a good thing that he says he has never used it because if he did he might end up embroiled in a patent dispute.  What a relief.
@_date: 2017-12-02 22:45:17
My understanding is that ASICBOOST doesn't increase hashrate, rather it decreases electrical costs.
@_date: 2018-09-25 14:49:41
FWIW, people who get fancy like this end up with lost funds.
Splitting the set of 24 words into two pairs of 12 words each is just fine, since anyone who gets your two sheets of 11 words shouldn't be realistically stopped by having two words missing.
@_date: 2018-09-25 14:40:32
According to my count you have (12*11 + (11-8))=135 bits of entropy remaining.  This is beyond the 128 bits of security provided by Bitcoin's ECDSA signatures themselves.
BTW, from an information theoretic point of view the last word isn't special with regards to the checksum.  Missing the one word (of 24) means you have (11-8) = 3 bits of entropy no matter if it is the last word or any other word.
@_date: 2018-09-21 18:21:06
FWIW I tried using `--checkblocks` (and `--checklevel=4`) but AFAICT it only checked about 1608 blocks due to the limitations of the dbcache size.  I'm now trying `--reindex-chainstate` which I'm told will do what I want.
@_date: 2018-08-16 23:59:30


Yes.  I understand the purpose here is to prevent the sender from making a false request to make a payment and then immediately aborting, as a method of learning the UTXOs controlled by the receiver at no cost to themselves.
@_date: 2018-08-01 15:13:54
I don't necessarily disagree with this article.
It is important to understand that the Lightning Network is paving the way for a future of relatively high-fee bitcoin transactions.  Today transactions are 99% subsidized by Bitcoin's inflation with the coinbase reward paying out 99,000 USD of a 100,000 USD block reward.  In the future that subsidy goes away, and if we do not get upwards of 100,000 USD per block in transactions fees, plus a sufficient backlog of pending transactions to prevent instability due to remining of blocks, the Bitcoin network is going to end up losing the PoW that secures the network.
We only have another decade or so to get a system in place where Bitcoin transactions pay for Bitcoin's security, and if that doesn't happen, Bitcoin as we know it is going to fail.
@_date: 2018-08-17 17:42:14
How do you even know if you own any bitcoin if you aren't running your own node?
@_date: 2018-08-16 03:30:29
Let's take a look at some recent stats from 
**Transaction fees** (24h averages)
 | BTC | BCH
Sat/B | 17.62 | 6.77
USD/kB | $1.12 | $0.04
**Average block reward** (past week)
 | BTC | BCH
Coinbase | $78,759 | $6,947
Fees | $799 (0.13 BTC) | $2 (0.00 BCH)
Total | $79,557 | $6,949
Fee % | 1.00% | 0.03%
As you can see BTC's security is currently 99% subsidized by inflation.  So while you might pay  $1.13 per kilobyte of data (a standard transaction is roughly 1/4 of a kilobyte), the other $112 per kilobyte needed for security is covered by an inflation subsidy.
BCH's security (in as much as it has any security due to its much lower hashrate) is 99.97% subsidized by inflation.  So while it appears cheaper to transact, at only $0.04 per kilobyte of data, the other $138 per kilobyte needed for security is covered by its inflation subsidy.
It turns out that the real cost of transactions (fee + inflation) on both chains is fairly close together.  This just happens to work out this way because, although BTC has 10x the security (in hash rate) per block, BTC also has 10x bigger blocks currently.
Keep the above in mind while I tell you something very important:
The inflation subsidy is going away!
Let me repeat that because it is so important:
The inflation subsidy is going away!  It is going away on both BTC and BCH.  In only 6 years the inflation subsidy with be a quarter of what it is today, and in 10 years the inflation subsidy will be an eighth!
Remember the real cost of the security of both chains is currently at roughly $100 per kilobyte of data.  If there was no subsidy today, users of both chains would be paying the same fee, and that fee would be very large by today's standards.
How are you going to pay for security when the subsidy runs out?  What's the plan?  Do you have an answer?
AFAIU, the BTC plan is to use fee pressure with a backlog of transactions to ensure that we get fees up to around that $100 per kilobyte that is needed for the security level that we currently enjoy.  To mitigate this high fee, users will use the lightning network to amortize their on-chain transaction fee over a large number of lightning transactions.  A backlog also also helps mitigate the problem of re-mining blocks, which I will return to later.
What is the BCH plan?  AFAIU the plan is to keep fees per kilobyte low, if not even lower than the are today, and makeup the security costs with high volumes of transactions.  To cover their current costs of security, the will need 3473× as many transaction per block as they currently have.  If they want to actually be secure, they will want to meet BTC's security costs which at today's numbers requires BCH to have 34,730× as many transactions per block.  They literally need blocks averaging 1GB in size every 10 minutes for this plan to work.
In addition to that BCH, will encounter a second problem of re-mined blocks.  Suppose you are a miner and you are clearing the mempool with every block, which is a requirement if you are going to keep fees per kilobyte low, and it is a decade from now and the block subsidy is relatively small.  You could mine a new block with that small subsidy, ... but you are looking at that previous 1GB sized block with its $78,000 in fees.  You run the math and it turns out your are better off attempting to orphan that block and steal the fees than mining a new block until the mempool fills up again.  In this world, blocks end up regularly orphaned; transactions end up left in the mempool as a bounty so throughput begins to slow, and, against their best efforts, fees even begin to rise as participants try avoiding having their transactions be the ones left in the mempool as bounty.  Overall [mining becomes unstable](
With BTC's plan there will usually be a backlog of transactions, which should help mitigate this problem of re-mining of blocks.  As long as the backlog is "thick" enough, miners are better off mining a new block of transactions over the risky move of trying to orphan the previous block.
But even if BCH didn't have all of the above issues,  I'm not sure that 1GB / 10min is going to be practical for me to participate in even if they somehow manage to achieve that much volume.  AFAIU the BCH plan is for me not to run a validating node and just ask other people what they think my BCH balance is.  But if I want to ask other people what they think my balance is I can already do that today ... with my bank.  Asking other people what my BCH balance is doesn't provide me with financial sovereignty.  Financial sovereignty is the value proposition that BTC provides.  I don't have to ask anyone for permission to receive or send BTC funds and my funds cannot be frozen at anyone else's whim (like [what happened to Mr. Money Mustache recently](
Distributed ledgers will never be able to compete on transaction price with centralized payment processors because centralized payment processors are vastly cheaper to operate.  If ever a moment came when BCH transactions threatened their market dominance they can always react by lowing their prices.  They have a lot of room to maneuver here. 
I can only reach the conclusion that we must let go of the idea of cheap on-chain payments, a game that we will only lose, and focus on what we can provide: financial sovereignty, but that comes with its own price.
@_date: 2017-02-18 18:08:27
There are two different but related contexts where we use the term fork.  The first context is in describing the type of rule change being considered.  A soft fork is a rule change where every valid block under the new rule set is a valid block under the old rule set.  A hard fork is a rule change where there exist blocks that are valid with the new rules but not valid under the old rules.  The type of hard forking changes can be further subdivided, and there are further nuances that we could go into here but are not necessary for this topic.
Once we have classified the type of rule change, we can talk about deployment of rule changes.  Soft forks have the ability to be safely deployed by a miner signaling procedure which you may be familiar with.  Once an agreed upon supermajority of hash power is signalling, all signalling miners start enforcing the new soft-forking rule set.  Having a supermajority of hash power enforcing the rule set protects nodes that have not upgraded because any chain with now-invalid blocks will eventually be orphaned.
But soft-forks don't have to be deployed in a safe way.  They can also be deployed in a messy way without miner signaling.  That's what happened with the soft-fork that fixed this integer overflow bug.  Rather than using the miner signaling deployment, new miners just switched to the new rule set haphazardly. In switching to the new rule set, miners rescanned the blockchain, but now the "bad block" is not valid according to the new rule set, so the chain forks at this point.
This is the other context where the term 'fork' is used.  It means a branch in the blockchain.  As we can see, this branching can happen not only during hard-fork changes, but also during non-safely deployed soft-fork changes.
Continuing the story, once the majority of the mining power switched to the new soft-forking rule set, it was inevitable that the chain with the new rule set would overtake the the chain with the old rule set.
Anyone whose personal nodes were upgraded to the new rule set were already following the new rule set chain, even during the period of time that the old rule set chain had more work.  But, and this is **the important point**, because the rule change was a soft-fork, once the new rule set chain overtook the old rule set chain, all the nodes on the old software automatically reorganized to the new rule set chain.  So even if you were on vacation that week, when you come home, you wouldn't have even noticed there was an issue.  This is a property that hard-fork changes generally don't have, regardless of how they are deployed.
So I wouldn't say that the chain was "deliberately rolled back".  Instead a soft-fork was, messily, deployed and the protocol just took its natural course that follows from that.  The "bad block" was never mentioned by name nor by height during deployment.
@_date: 2017-02-11 15:44:25
s/rust bitcoin/[Haskell bitcoin](
@_date: 2017-02-09 14:28:48
Activating `OP_CHECKSIGFROMSTACK` will provide [efficient secure multiparty computation]( 
@_date: 2016-06-23 22:07:26


Just to emphasize this point from a theory of computation perspective:
Suppose someone is proposing a state transition of some kind (e.g. spending a bitcoin, or updating the state of some global computer) and you would like to write a program to capture the set of rules to determine if any proposed state transition is valid or not.  If you use a Turing complete programming language, this gives you the ability to define the set of valid state transitions as any [recursively enumerable langauge]( you want.  This is a nice broad class of languages, and you cannot program anything broader (except perhaps if you use interactive protocols).
By [Post's Theorem]( the class of recursively enumerable languages is (modulo encoding issues) equivalent to the class of sets that are definable by a Σ₁ formula in the [arithmetic heirarchy](  These are formulas (equivalent to ones) in [prenex normal form]( beginning with a single unbound existential quantifier, and all the remaining quantifiers bounded.
We define the class of  Σ₁-sets to be those sets definable by Σ₁ formulas, and, as we noted, this is the same as the class of recursively enumerable languages.
We define the class of  Δ₀-sets to be those sets definable by Δ₀ formulas, (i.e. those formulas with only bound quantifiers).
This means that every Σ₁-set (i.e every recursively enumerable language) is the projection of some Δ₀-set.  In other words, every Σ₁-set can be defined as {*x* : ∃*w*. (*w*, *x*) ∈ *D* } for some Δ₀-set *D*.  Because every quantifier in the formula defining a Δ₀-set is bounded, membership in every Δ₀-set is decidable and you do not need a Turing complete language to specify Δ₀-sets.
The upshot of all this is that you do not need a Turing complete language to check membership for your recursively enumerable set of valid state transitions.  Instead, you can write a specification of a corresponding Δ₀-set in some reasonable non-Turing complete language.  When someone is proposing the state transition *x*, you say, "Fine. But in order for our system to accept your proposal, you need to also give us some witness *w* such that (*w*, *x*) is in our Δ₀-set." (BTW, this witness can and should be segregated as there could be more that one possible witness for a given *x*).
By using Turing machines for specifying your set of valid state transitions, the person proposing the state transition is effectively saying, "Here is my proposed state transition.  Please everyone, do an unbounded search to validate that my proposal is acceptable."  Unbounded search is literally the defining feature that sets apart Turing complete languages from Turing incomplete languages.
There is no reason for using Turing complete languages to do validation.  Have one person, the proposer, do the unbounded search and present the witness to everyone else so no one else needs to do an unbounded search.
@_date: 2017-08-11 20:51:48
Atomic swaps have been possible for a while, since CLTV.
@_date: 2017-08-25 03:59:21
Bit 1 was being used to signal for Segwit.  After Segwit activated, Bit 1 was released from its duty to signal Segwit and no longer has any defined meaning.
However, for some reason, many miners continue to signal Bit 1.  This is confusing to clients, such as Bitcoin Core, because the Bit 1 signal no longer means Segwit. Bitcoin Core is worried that this Bit 1 signal may indicate some new feature is being soft-forked that it doesn't know about and is lightly warning you about that possibility.
I wouldn't worry about your warning from Bitcoin Core.  Instead, I might worry a little bit about miner's competency to write their own software.
@_date: 2017-08-25 04:05:47
See 
@_date: 2017-08-25 11:51:28
It is rounded downwards.  The total BTC produced will be slightly less than 21 million.
@_date: 2016-06-23 19:26:32
Unfortunately 'eval' rears its ugly head in Todd's DEX proposal and implies looping and recursion. :(
@_date: 2016-11-03 05:25:39
Furthermore, even if `OP_CAT` and `OP_CHECKSIGFROMSTACKVERIFY` were available on the main Bitcoin network, the scripts presented here are specific to the transaction format of Elements Alpha (which include things like confidential transactions).  Some minor modifications would be required to the scripts to have them work with Bitcoin's transaction format.
@_date: 2016-11-01 19:47:44
As the blocksize decreases, we can expect fees per transaction to go up.  On the other hand, the number of transactions goes down.  So there is a tradeoff. Under idealized conditions, there is optimum equilibrium size at a point where removing one transaction is exactly offset by the increased fees of the other transactions, but removing more transactions doesn't increase the fees sufficiently to cover the lost transaction.
However, and this is very important, this point is only an optimal point for miners as a collective, but not for miners as individuals.  This equilibrium point is **not** a Nash equilibrium.  At this point, each individual miner is better off adding as many transaction as they can, because anything else would just be leaving money on the table for others.  Thus the ideal equilibrium point for the collective is unstable and every miner ends up filling blocks to their maximum capacity, which is the Nash equilibrium, even if it may be worse off for the whole group.
@_date: 2016-11-03 13:52:58
This method of implementing convents uses the preexisting operations that are available in Elements Alpha.  That is why the construction seems cumbersome.
However, I think your observation is apt.  Before this work, I would have been somewhat hesitant to add new operations to provide direct access to transaction data since the choice to hide the transaction data behind the `CHECKSIG` operation seemed so deliberate.  However, since the full transaction data is so easily recoverable anyway, I feel there is no longer much reason to keep the transaction data inaccessible.
@_date: 2018-06-06 19:15:36
* 
* 




@_date: 2018-06-09 03:19:58
If you list all the times between successive blocks over a period of time and average them up, you get a 10 minute average.
However, if you pick a random point in time, then it is, on average, 10 minutes since the last block and 10 minutes until the next block, meaning that when you pick random points in time you expect to pick a block interval that is 20 minutes!  This paradox is known as the Hitchhikers paradox.
I wrote a [blog post on this topic]( but the resolution to this paradox is that when you pick a random point in time, you are more likely to randomly pick blocks that take longer than average than you are to pick blocks that are found quickly simply because there is more time between blocks that take a long time to find.
As a consequence, assuming you make a transaction as a random point in time (or simply independently of when blocks are found) you still expect to wait 10 minutes until the next block (half of 20 minutes), because you've probably randomly picked a block that takes an extra long time to find and you are half way through that period on average.
@_date: 2018-06-06 19:52:11
The banks don't take the box contents for themselves.  They have drilled and taken the box contents and handed them over to the state to be auctioned off for the benefit of the state since the bank "couldn't contact the box owners" despite the fact the owners were still regularly using a checking account and paying for their box at said bank.
I believe this suffices to answer your question "What's wrong with storing it in a safe deposit box at a bank?"  I don't know what more you want.
@_date: 2018-06-06 21:10:57
Suever v. Westly, 439 F. 3d 1142 (March 14 2006); Taylor v. Westly 402 F.3d 924 (9th Cir. 2005) (Kleinfeld, J.); Harris, et. al. v. Westly (2004) 116 Cal. App. 4th 214; and Fong v. Westly (2004) 117 Cal. App. 4th 841.
None of these cases have gone to trial because the State of California claims immunity to prosecution.  So you are right: none of these allegations have been proven in court AFAIU.
Feel free to assume that means all these claims were fabricated if that makes you feel better about the security of your safe deposit box.
@_date: 2016-12-26 05:18:01
Is this a scam bet?
The details of the bet only refer to the block height, not the block difficulty, so here is how you build a chain that satisfies the requirements as written in the bet.
Starting with the genesis block build a new chain with empty blocks of difficulty 1 with timestamps up to almost the end of Sept 2017.  This chain will be a little behind with regards to height, of where the real chain will be in Sept 2017, and a lot behind with regards to total work.  But remember, the bet has nothing to do with how much work is in the chains; the bet only mentions block height.
To make up the difference start mining chunks of 2016 blocks whose timestamps are 1 second apart at the end of the chain.  The difficulty can only go up by a factor of 4 per set of 2016 blocks, so we can begin making up the missing height.
Doing some napkin math, there are 3192 days between the genesis block and the end of September 2017.  Building a chain of difficulty 1 up to that point in time will have height 3192×24×6 = 459648.  Based on the height of the blockchain today, we can estimate that the real Bitcoin blockchain will have height 487000 by the end of Sept 2017, perhaps a little higher.  So our fake difficulty chain will be behind by around 27352 blocks.  By adding 14 chunks of 2016 blocks to the end of our low difficulty chain more than make up for the needed height, while only raising the difficulty to 4^14 = 268,435,456.  The current difficulty is 310,153,855,703, so the difficulty of our fake chain ends up less than 0.1% of the real chain's difficulty today.
Throw a larger than 1 MB block in at 100 blocks before the end of the fake chain by padding it with garbage data and we satisfy the requirements of condition 1.  To satisfy condition 2 we just need to add a few thousand more blocks to ensure the real chain doesn't exceed the *height* of our fake chain.  This is easy to do, because, remember, the difficulty of our fake chain is 0.1% of the difficulty of the real chain, even though our fake chain is longer.
I'd be tempted to bet yes given the wording of the bet, but I'd worry that they would pull a DAO and change the terms of the contract on me.
@_date: 2017-11-18 02:51:08
You want to prevent anyone from paying the same amount to the same recipient twice?  So if I order the same food from a restaurant again in a week, you are saying that I cannot pay them because the transaction amount will be the same?
@_date: 2017-11-18 03:25:01
At 50x leverage a 2% drop in the price of bitcoin is magnified by 50x into a 100% drop in the effective balance of his account (i.e. the value of the bitcoin he bought minus the amount of his loan).  At that point the bitcoin he bought is just enough to cover the balance of the loan and no more, so the exchange forces a sale to ensure his effective balance doesn't go negative.
@_date: 2017-11-18 03:54:56
You can open a $1,000 worth of BTC lightning channel, spend the money throughout the week.  Every payday you can buy Bitcoin with a lightning supporting exchange which will refill your channel without requiring an on-chain transaction (because lightning payment channels are bi-directional they can be refilled upto the amount of the original channel size).  In your simplified model, you will never need to make an on-chain transaction ever again.
@_date: 2017-11-18 04:06:27
Not necessarily. To keep things simple, lets say that when you buy bitcoin for dollars on a lightning supporting exchange, someone else is selling their bitcoin for your dollars.  On your counter-party's end, if they are holding their bitcoin in a lightning channel, then effectively they are sending their bitcoin through the lightning network to fill your lightning channel without making any onchain transaction, and the exchange is debting the dollar amount of your account with them and crediting the dollar amount of your counter party.  So no on-chain transactions are needed.
In reality the exchange is going to mediate the the transaction, so your counter-party will send funds via lightning to the exchange and the exchange will send funds to you via lightning, and there could really be several participants acting as your counter-parties instead of just one.  Nevertheless, this can still all happen off-chain.
@_date: 2017-11-18 04:58:30
If you buy at $7950 you will be forced to sell somewhere around $7791, and realistically they will force you to sell somewhat before then. 
@_date: 2017-11-17 20:02:29
The main problem with the method of accounts is that you need to engineer a way to prevent someone from taking your transaction and replaying it again (on the same chain) that would deduct money from your account and credit their account and second time (and third time, etc.).
This can be done; however bitcoin's UTXO system neatly side-steps the entire issue.
There are other reasons as well. 
@_date: 2017-11-21 14:09:53
The last byte of the signature data encodes the sighash type used for that particular `checksig`.
@_date: 2017-11-23 16:25:37
@_date: 2017-11-21 18:03:51
A lightning channel is effectively a joint account between you and the party on the other side of the channel.  As a joint account, updates require signatures from both you and the other party.  **You hold your private key to this joint account**.  However, to ensure that the other party cannot disappear on you leaving the account locked forever, before opening this joint account you get a pre-signed transaction, signed by both you and the other party, that returns your portion of the funds back to another private key that you own.  Only once you get this pre-signed transaction do you then fund the joint account.  If the other party disappears you can always use this pre-signed transaction to get your money back.
@_date: 2017-11-18 03:31:38
Nope. Bit Club, Bixin, BTCC, and BW Pool are *still* signaling NYA even though they are not mining the Bitcoin2X chain. This may come as a shock to some people, but it turns out that some miners who were/are signaling NYA are not intending to mine the Bitcoin2X chain after all.  So far there is no evidence that any miners who were signaling NYA are mining the Bitcoin2X chain, but we haven't seen from Bat Pool yet, for example.
@_date: 2017-04-19 10:56:02
Perhaps I'm the one missing something.  I'm not sure why you think it would be impractical for a users to execute the augmented run-time to generate the trace.
Because users are running fully validating nodes anyways they already have enough computation power to validate everyone's witnesses for every transaction, including their own.  I don't expect that generating their own trace is going to be more costly than that.
(Interestingly, if you did have a third party generate the witness, you would be able to validate the witness is correct.  After all, that is the whole point of the witness is to be able to validate computation.)
@_date: 2012-03-25 22:06:35
Bitcoins were never fungible.
@_date: 2017-04-19 02:01:29
My understanding is that recursive SNARKs manages to somehow compact the entire trace of computation into a single constant-time check using magic that I don't understand at the moment.
However, SNARKs requires a trusted setup, which is something that slipped my mind at the time I answered the question.  However, the next day at the Standford BPASE conference there was a presentation of STARKs which has the same properties as SNARKs but with no trusted setup!
@_date: 2017-04-19 02:05:20
Ideally we would build a system that lets you program naturally, but the compiler is augmented to also produce the &amp;Delta;_0 verification program and the run-time system is also augmented to build the trace or whatever witness is needed by the verification.
This could make everything transparent from the developer's perspective and still efficient for the network.
Designing and building such a system is going to require some work.
@_date: 2012-08-23 00:43:29
I think undoing a delete with complex rotations would be a more compelling example since this insert example is perhaps a bit too simple.  More compelling still would be actual code that preforms this rollback function for all cases, because I think such code will be extremely complicated and probably incorrect.
Even better, I'd like to see code for undoing all transactions of a block simultaneously using a single VO tree for all the transactions.  (Edit: is this even possible with the RB-tree design, since a VO tree for multiple transactions won't state the order the transactions were processed in?)


Yes, I know the shape is uniquely determined by the root hash, but that doesn't mean I can recover the shape from the root hash.
@_date: 2012-08-27 22:25:33
Because, in principle, someone could be building a hidden long fork an reveal it at any moment.  And if someone does reveal a claimed longer fork, it is basically impossible to verify it or not without having the chain all the way back to the fork point.
@_date: 2012-02-03 02:15:44
Sun Feb  7 07:28:15 CET 2106
@_date: 2012-08-22 20:42:54


I don't know much about DHT's; My ignorance says this solution doesn't sound simple.
The Patrica-tries design gives clients choice from doing linear traversals to reconstruct old UTXO's, storing every UTXO (probably using sharing), use skip-lists/check-points, or use a public distributed hash table.  I'm sure different clients with different resources and different connectivity will want the ability to make different choices.
The RB-tree design means either adding rotation information to the block header or taking the low-memory, low-connectivity, high-time option of linear traversal recovery of old UTXO's off the table.  And adding rotation information to the block header another nail in the plank of complexity.
@_date: 2012-08-22 16:10:40




Hi socrates1024.  I think this is an excellent scenario to keep in mind.  It illustrates some weakness of the RB-tree design and some weaknesses in both the Patrica-trie and RB-tree design.
Okay lets assume we have had a nightmare crash and all we have recovered is the hash of the last head of the block chain we encounter.  But, for whatever reason, we are confident in the integrity of this hash (i.e. we know that we did validate the block with this hash).
Now we request from the network the block with this hash, and, with some luck, we get a reply.  We verify the reply by checking that the hash of the block in the reply matches the hash we have on hand.  Once this checks out we know we have the right block.  Let use say the block contains some sort of a hash of the UTXO, say in the coinbase or whatnot.  We again query the network for a serialized version of the UTXO, and again we can deserialize the UTXO database and check that its hash is correct.  So far this all works the same for RB-trees or Patricia-tries.
After more queries to the network, we find out that our last head block is now on a dead fork of the mainline chain.  So to validate the new mainline branch we need to follow our dead chain back to the fork point.  This means we get the UTXO database by reverting changes as we follow our chain back to the branch point. The chain can easily be followed backwards since each block contains the hash of the previous block.  The problem come with trying to revert transactions in the UTXO database.
The first problem is that the current format of transactions does not contain enough details about the input coins needed to reconstruct the destroyed inputs of a transaction.  This problem applies equally to both the RB-tree and Patricia-trie design.
A second problem is that, even if we get the details of the destoryed coins, by having a second database of destroyed coins in the coinbase or some other way, inserting and deleting elements in an RB-tree are not inverses of each other.  So even more data will be need to be stored in the coinbase in order to undo the RB-tree rotations.  This problem does not happen with the Patricia-trie design where inserts and deletes are inverses of each other.
Now, one might try to argue that we don't need to revert changes at all. We can just trace the chain back to the forked point and ask the network to send a serialized UTXO database from that point to begin with.  Then we can validate the chain forward from that point.  However, this is only off-loading the problem to the network.  How is a client on the network supposed to satisfy the query of the UTXO database of an old block.  Well, they are probably going to want to take their current UTXO database and rollback the transactions in order to restore a copy of the old UTXO to answer the query.  If a RB-tree design is used then again they will have to store the RB-tree rotations in order to undo inserts and deletes.
I'm not saying that you cannot make the RB-tree design work.  Clearly you can use your skip-list-tree design and maintain checkpoints.  This lets you restore the an old UTXO database by jumping back to a checkpoint before the queried block and doing a forward reconstruction from that checkpoint.  But then you have to store these checkpoints.
But the larger point is that the Patricia-trie approach allow the option of having checkpointless UTXO databases.
I'm sure you are aware of all this.  But it is nice to have it written down somewhere.
@_date: 2012-12-10 04:40:29
With 51% of the network you can, at your will, exclude all blocks that other people mine.  So while others can temporarily get blocks in, they will all fall to the side should you, the attacker, chose to only build on your blocks.  So while this isn't the 51% attack, it is a 51% attack.
@_date: 2012-09-12 19:33:21
My very limited understanding is that these various key disclosure laws are for **decryption** keys only, whereas the keys in bitcoin are for signing.  The ECDSA algorithm doesn't do encryption/decryption.
Anyone care to correct me regarding the scope of the key disclosure laws?
(Edit: Now that I think about it, technically the private signing key is encrypted with a symmetric cypher, so technically there is some encryption going on.  However, I'm hopeful under current laws no judge would allow such decryption because (a) a random private key isn't incriminating by itself and (b) clearly the primary purpose of the passphrase is for signing, not for decryption of data.)
@_date: 2018-03-24 14:33:50
Please don't signal [BIP9]( if you aren't intending to invoke BIP9.  If you keep this up, you may eventually cause spurious warnings in Bitcoin clients and freak people out.
@_date: 2019-01-23 19:08:37
FWIW, the "last block mined" will be on Feb 7th, 2106 when Bitcoin's 32-bit unsigned time field reaches its maximum value. ;)
@_date: 2012-08-22 22:43:55


I understand you get the UTXO-**set**, but how do you get the **shape** of the RB-tree from this information?
Is this operation implemented in your python lib?
@_date: 2019-01-24 03:28:20
@_date: 2018-03-20 14:34:32
Yes LN uses millisatoshi for accounting and you can send these fractions of a satoshi as payment.
So what happens when you close a channel and one person has *x* + 4/10th of a satoshi and the other has *y* + 6/10th of a satoshi?
Both figures are rounded downwards and the transaction fee is bumped by 1 satoshi.
But this process still enables sub-satoshi micropayments to accumulate over time in a payment channel and become real satoshis.
@_date: 2018-03-25 15:34:22


Something has changed between then and now.  The ASICBOOST patent is now freely available for licensing from Little Dragon Technology subject to the terms of the Blockchain Defensive Patent License.
ASICBOOST in of itself isn't bad.  Decreasing the cost of the hash rate that secures Bitcoin is a good thing.  However monopolizing that cost advantage is a big problem, one that could undermine the security gains that ASICBOOST would otherwise provide.
@_date: 2019-01-24 02:55:53
After 6 consecutive blocks with maximal timestamps, there are no more valid blocks that can be added because they would be required to have a strictly larger timestamp than the maximum possible timestamp.
@_date: 2018-02-19 16:26:53
Another solution would be to have
    RIPEMD160 &lt;H&gt; EQUAL
for Bob's redemption while keeping
    HASH160 &lt;H&gt; EQUAL
for Alice's redemption.
   
@_date: 2018-02-15 03:49:16
As a follow up: I learned that with the current lightning spec you are allowed to start a channel with a $0 balance on your side, however that channel remains unidirectional until your reserve requirement get met.
@_date: 2018-02-22 04:09:52
I'm not really an expert on this, but there was at least one incompatible protocol change to the P2P protocol, adding a nonce to the `ping` message.  One should be able to use something like a version 0.6.0 node to act as a bridge to between the modern network and an old network (not certain I've got the right version here.)
Even that might not get you as far back as version 0.1.1 though because there have been early P2P changes.
Also early versions of bitcoin would get confused and crap out if a block was found during the initial block download, so even if you get 0.1.1 working, it will probably fail if you don't manage to download and validate the entire blockchain within 10 minutes or so.
Probably the best bet would be to hand-craft a custom bitcoin network proxy that can communicate directly with the 0.1.1 client and hand feed it only the initial block download and nothing else.
@_date: 2018-03-28 14:40:13
BTG is down 108.84%.  I question the reliability of these numbers.
@_date: 2018-03-20 23:40:45
Mining chips do not support Overt ASICBoost or Covert ASICBoost.  They support ASICBoost or not.  It is the software that is managing those miners that determines whether the ASICBoost used is overt or covert.  So if mining hardware supports ASICBoost then it can be run in either over or covert mode.
Covert mode is more expensive to run than the overt mode because you need to find suitable Merkle root partial collisions.  Covert mode is even more expensive when mining Segwit blocks.
@_date: 2018-02-14 21:08:47
Let me see if I can recall the issue in detail.  I believe the following is the issue:
Alice and Bob have been running a payment channel between them with many small payments back and forth.  After awhile it becomes the case that Alice's balance is 0 BTC and Bob's balance is 1 BTC in the channel.  Alice decides to defect and try to get a little extra money out of Bob.  Alice broadcasts an old balance giving her 5 satoshi and giving Bob 99999990 and spending 5 satoshi on fees.  Now Bob can activate his breach contract which will take away all Alice's funds and giving Bob 99999995 satoshi, but he will want to spend 5 satoshi on fees for the breach contract, leaving him with 99999990 anyways, so he might as well not bother.
By maintaining minimal channel balances, Alice cannot perform this sort of small scale attack.
That said, I'm not certain I got the relevant scenario correct here.
@_date: 2018-11-30 05:22:46
The core simplicity language consists of just 9 combinators, so Simplicity programs all look like that.  Addition of points on an elliptic curve looks something like [this]( and SHA-256's compression function looks something like [this](
Simplicity really is a low-level language that is more like assembly than Java or Python.  There is no point in building tutorials on how to write Simplicity by hand because Simplicity isn't meant to be written by hand.
At this point, anyone serious about creating Simplicity programs is going to first want to develop some front-end language that generates or compiles to Simplicity.  Those people are going to care more about the semantics of Simplicity than about example programs, which is why the typing rules and functional semantics of Simplicity takes centre stage.
@_date: 2018-02-22 04:43:45
Finding a block is not like waiting for a train.  While it is true that on average it will have been 5ish minutes since the last block has occurred.  The problem is that conditioned on the fact that there hasn't been a block in the last 5ish minutes, it is still the case the the expected time you are going to have to wait is another 10 minutes.  In fact, no matter how much time you wait when you condition on the fact that no block has appeared during that wait (or conditioned on anything really since Poisson events are memoryless), the expect time until the next block is always 10 minutes.  Such is the nature of Poisson distributions.
Edit: See the hitchhiker's paradox @  or @ 
Edit2: I believed I erred above and it in fact at any given moment the expected time since the last block is 10 minutes.  Math is hard.
@_date: 2018-02-14 14:24:16
You don't have to, nor do you want to close your channel to sell BTC for USD.  You want to keep your LN channel open so you can send your BTC to an exchange via lightning and lock in the USD/BTC exchange faster than you ever could via BTC's 10 minute blocks.
@_date: 2017-09-23 21:24:21
Alice and Bob agree to exchange *X* BTC from Alice for *Y* LTC from Bob.
Alice invents a random secret value *S*, and tells Bob *H* = Hash(*S*).  Hash is a one-way hash function, such as SHA256.  Bob doesn't yet know *S*.
Alice broadcasts a transaction on BTC chain with a contract that says Bob can redeem 'X' BTC if he signs with his key, and reveals the secret value *S* such that its hash is *H*.  The contract also says that after 3 days if the transaction hasn't been redeemed by Bob, Alice may redeem the *X* BTC.
Bob waits for the transaction to gain a suitable number of confirmations so that he is confident that the transaction is permanent.  At the moment Bob cannot redeem the funds because he does not know *S*, and Alice cannot redeem the funds because she doesn't know Bob's secret key, nor is her 3 day timeout over yet.
Next Bob broadcasts a transaction on the LTC chain to a contract that says Alice can redeem *Y* LTC if she signs with her key, and reveals the secret value *S* such that its hash is *H*.  The contract also says that after 1 day if the transaction hasn't been redeemed by Alice, Bob may redeem the *Y* LTC.
Alice waits for the transaction to gain a suitable number of confirmations so that she is confident that the transaction is permanent.  Notice that Bob's time out is shorter than Alice's time out.  If Alice walks away from the deal now, Bob will get his money back, and then Alice will get her money back.
Alice does know the secret value *S* so she can redeem the *Y* LTC funds.  However, in order to do so, she must sign with her key *and* she must reveal the value *S* on the LTC blockchain.
Alice redeems the *Y* LTC by sending them to herself.  Now that her redemption is broadcast, Bob can see the secret value *S* on the LTC blockchain, and Alice's timeout doesn't activate for at least another 2 days.  Bob has 2 days to redeem the *X* BTC using the secret value *S* that Alice revealed on the LTC blockchain.
Once Bob redeems the *X* BTC, the atomic swap is complete.
@_date: 2018-02-18 15:15:29
[While it is a well known CS result that a two-stack push-down automata has the same power as a Turing Machine, Bitcoin Script cannot operate as a two-stack push-down automata. Even though Bitcoin Script has two stacks, Bitcoin Script doesn't have an associated finite state machine that you can create.](
Bitcoin Script is not Turning complete nor can recognize recursively enumerable languages because every such programming language must have infinite loops while Bitcoin Script has no looping behavior at all.
@_date: 2018-02-19 16:28:18


The protocol demands that Bob fund his contract before knowing `k`.
@_date: 2017-09-24 03:51:54
Yes, thanks.  I've made an edit.
@_date: 2017-09-28 21:17:14


Bitcoin's blocks are already no longer capped at 1MB.  For example, the recent block  is 1104.57 KB in size.
@_date: 2017-10-02 23:07:50
I'm suggesting you should compute the time delta and place it on the screen and not count down at all.  When another block comes in, you can drop the time delta by 10 minutes.
@_date: 2017-10-02 20:59:07
FWIW, you could just check the block height and compute the expected time until block 494784 (a multiple of 10 minutes) and simply display that fixed value.  Not only is this simpler, but due to the way Poisson processes work, it is also a more accurate presentation of the expected time until block 494784.
@_date: 2018-02-14 19:14:56
Nope. One channel of sufficient capacity to support your business needs is sufficient.  The lightning network is a network after all.
In practice, it will probably be one channel you have open with an exchange, but that isn't necessary.
@_date: 2018-07-30 15:06:18
Sure there is an enormous risk to being orphaned, but that just becomes a constraint you need to optimize around.
Suppose you are a miner and the mempool is empty.  It is a few years down the road and the mining subsidy is all but eliminated.  You are faced with a choice between mining an empty block with essentially no reward, or you could remine the previous block, and get all the transaction fees of that block if you mine it and mine a block on top.   Sure that is maybe unlikely, but it is possibly a better risk-reward trade-off than mining an empty block with little reward.
In fact, you may leave transactions on the table, or better yet, produce an anyone-can-spend output with a fraction of the rewards you collected as a bounty for other miners to build on your block rather than remine it.  Then other miners are faced with a choice of mining on your block and taking the bounty or undercutting your block and producing one with an even larger bounty.
This undercutting reduces the effective total mining power because mining on orphaned blocks is wasted.  Apparently the math becomes kinda complex as suggested by "[On the Instability of Bitcoin Without the Block Reward](
@_date: 2018-07-26 02:13:24


The fee market provides some incentive to, at the very least, sweep low value UTXOs.  As Pieter mentioned above, the UTXO size is currently 2.7 GB, but this is down from its peek of almost 3.4 GB in January due to this sort of sweeping.
@_date: 2018-07-23 19:41:26
Generally speaking, you are trusting the hardware wallet manufacturers not to have inserted a back-door into their wallet's firmware (the firmware does have a cryptographic signature from the manufacturer).
The source code for the software that communicates with the hardware is typically open source and you can, in principle, inspect that to look for overt or covert channels of communication between the hardware wallet and the manufacturer.
Unfortunately, there are many possible covert channels.  For instance, the nonce choice that the wallet makes for signatures could be used as a covert channel.  Hardware wallets generally claim to use deterministic signatures.  You can test this claim on samples by importing the recovery seed into a computer's wallet and testing several signatures to ensure that they are following their claimed algorithm.  However, you can never be sure that the firmware isn't just choosing to leak information on some small fraction of signatures that you end up not validating.
(Edit: I've been made aware of some ideas about having hardware wallets generate bulletproofs to prove, with zero-knowledge, that the generated signature followed the deterministic algorithm.  Obviously that isn't done with today's hardware wallets.)
There are other covert channels, such as timing channels that might be leaking your private keys and these wouldn't even show up in the source code of communication's software.
@_date: 2018-07-23 20:30:29
Sometimes miners run full nodes with bugs in them: 
@_date: 2018-07-13 15:36:08
When you default on a loan, as a general rule, the amount forgiven is taxed as income.  You can search for "cancellation of debt income", but [here is a Forbes article on the topic]( and [the IRS page on the topic](
It sounds to me like you have only managed to transform you capital gains tax into income tax, which is usually taxed at a rate equal to or higher than the rate for capital gains.  So now you are worse off than when you started.
The Forbes article also mentions that, even if you never default on the loan and keep it outstanding, the IRS will deem that your loan wasn't actually a loan, but it was a sale, as indeed it was in your case. Tax Court agrees with the IRS in, for example, [Jonathan Landow v. IRS](
@_date: 2017-10-04 22:44:33


We just had a modest block size increase at the end of last August. 
@_date: 2017-10-03 16:13:36


This is false.
All Bitcoin core nodes 0.14 and above enforce segwit.  If you have coins protected by segwit, that means you are already running a Bitcoin core 0.14.0 or greater node and therefore enforcing your own financial sovereignty.  As long as you continue to validate the Bitcoin blockchain yourself, it is impossible for anyone else to take away your financial sovereignty.  The entire purpose of Bitcoin is to enable people to have their own financial sovereignty like this.
51% of miners cannot steal segwit UTXOs anymore than they can steal any other UTXO.  Both require mining an invalid block (i.e. a block that will be rejected by your node).
@_date: 2018-07-23 15:16:24
Difficulty isn't actually based on number leading binary zeros.  As you rightly guessed, the adjustment is finer than that.
Technically difficulty isn't directly part of the consensus protocol.  Instead there is a (binary) floating point encoding of the block's target.  This floating point representation has a 24 bit mantissa and an 8 bit exponent.  This floating point number is converted to a target and the little endian interpretation of the blocks hash value must be less than this target.
For more details see &lt;
@_date: 2018-07-23 23:59:39
What happens is that the borrower pays back half their loan+interest to the lender.  The lender then buys goods and services from the borrower using the interest they earned.  Then the borrower pays back the rest of the loan+interest.
This is what happens for most loans in real life except the lender only very indirectly buys goods and services from the borrower.  In practice it is more like the bank uses intermediate loan interest payments to pay their employees and issue dividends to stock holders, who then use that money (which came from loan interest) to buys goods from some guy, who then turns around and buys goods from some gal, who then turns around and buys goods from the borrower who now has their interest payment back (and is out some of their goods) which they can then use to pay back their loan in full.
@_date: 2017-10-03 13:35:30
The key difference is that it is always expected to be 10 minutes until the next block, no matter how much time has passed since the last block.  So truly the timer never counts down on a per second basis.
@_date: 2018-07-30 02:39:56
If you can learn and understand the [Verify your download]( instructions and keep your own copy of the Wladimir J. van der Laan (Bitcoin Core binary release signing key) &lt;laanwj Key fingerprint = `01EA 5486 DE18 A882 D4C2  6845 90C8 019E 36C2 E964`, then you could download Bitcoin from the shadiest website on the planet and still be secure (in knowing your copy of Bitcoin is genuine).
@_date: 2018-07-16 16:56:08
It looks to me that as the transactions were being confirmed more were being added.  This is why the UTXO set size was shrinking.
Today they are all confirmed and the UTXO set size has stopped shrinking.
@_date: 2018-03-25 15:23:22
AFAIK they are [still enabled](
@_date: 2017-10-03 16:26:00
We don't have a 1mB limit anymore.  Block 488122 was 1155 kB in size.
@_date: 2018-07-24 15:49:15
BTC on credit is not fungible with BTC on chain and you can distinguish which is which.
@_date: 2018-02-14 19:23:53


In principle the coffee shop can add 0 BTC to their side of the channel.  In practice it is in the best interests of both parties that everyone starts with, and maintains, a minimal amount of funds on each side of the channel to cover unilateral closing fees.


Yes.  If you are charging routing fees, you will end up with a little more than $100 in your channel with Alice.  However, you are not require to route payments.  You can just have a payment channel with your coffeeshop if you like.


If there is another route to the coffee shop via Alice, then you can still pay for your coffee.  I expect the lightning network to be well-connected enough that this will happen in practice, but that remains to be seen.


Alice needs to be online to route any transactions and to do cooperative channel updates.  (Of course, you start a unilateral channel close operation without Alice being online).
@_date: 2018-07-03 23:50:13
The checksum is one byte, so out of the 49 thousand combinations only 192 have a valid checksum.
@_date: 2018-07-25 15:21:15


I think a better way of phrasing this is that it would disenfranchise existing Bitcoin users by pushing their network requirements beyond the limits they originally accepted, stealing away their financial sovereignty that Bitcoin is supposed to provide them.
@_date: 2018-07-03 23:51:32
The checksum is one byte, so out of the 50 thousand combinations only 192 have a valid checksum.
@_date: 2018-07-30 03:37:56
A few failure scenarios for Bitcion:
* Large miners formally enter into a cartel and begin to exclude non-cartel miners.  Then they begin to censoring transactions or manipulating block timestamps to control Bitcoin's difficulty for their own benefit.
* Quantum computers undermine the security of elliptic curve digital signatures.  Post-quantum digital signatures turn out to be too large or to expensive to use in practice.
* A rapid and protracted drop in Bitcoin price makes effectively all mining operations unprofitable.  The next difficulty adjustment is pushed so far into the future as miners turn off their rigs that new blocks simply never appear ever again.
* After a few more halvenings, Bitcoin transaction volume hasn't increased to the point where fee pressure can pay for block security.  Previous blocks begin to become regularly remined, as it is more profitable to remine old blocks than to mine new blocks.  Very long confirmation amounts become standard requirements.   The system ends up becoming impractical.
* After over 10 years someone *finally* puts together a new blockchain protocol that is actually an improvement on Bitcoin and that new blockchain becomes more successful.  Perhaps a future Mimble Wimble could end up in this category.
* The demand curve for Bitcoin transaction space gets to the point where it is both impractical for ordinary users to afford transactions, and yet the blocksizes are also too large for ordinary users to validate the chain.  In a certain sense Bitcoin hasn't failed as such in this scenario.  But it would mean that Bitcoin has failed to give ordinary people financial sovereignty.
* On February 7th 2106, the Bitcoin's block timestamp reaches its maximum allowed value and no more blocks can be added.
@_date: 2018-07-30 04:22:31
I would imagine so.  If there is disagreement, then maybe even lots of hardforks!
Technically there are existing bugs in the protocol that could be exploited to let you postpone this event (by a lot!) and only using  a softfork. However, such exploits are maybe not palatable and would screw with existing time-based time locks (although that side effect could be minimized).
@_date: 2018-07-30 04:27:37
You do not need to create your own keys.
@_date: 2011-12-27 00:01:40
You guys are going forward with the scary OP_EVAL?!
@_date: 2018-07-31 00:05:29
After some discussion on freenode, it seems you cannot do anyone-can-spend so easily. If you attach it to the coinbase it cannot be spent for 100-blocks due to maturity, and if you attach it as your own transaction, then it can be replayed by the miner in their own fork.
So it would seem that leaving transactions on the table is the way to go.
@_date: 2018-07-30 02:53:08
A common problem.  But don't despair.  If you put in the effort you can learn to use GPG.  In the mean time, you can get some reassurance by downloading Bitcoin from both bitcoin.org and bitcoincore.org and use a file diffing tool to check that both are identical.  You can also verify that the cryptographic hash matches matches the hashes found in the SHA256SUMS.asc files.
There is a whole host of security concerns you need to take seriously if you are going to be your own bank, and what level of care you need to take depends on how much value you are trying to secure with Bitcoin and what your personal risk profile is.  Getting an authentic copy of Bitcoin is only the first of many things you need to take into consideration.
@_date: 2011-06-14 07:57:25
The miners also get the transaction fees.  When the supply is exhausted the miners will still continue to get transaction frees.
@_date: 2018-07-14 18:17:47
You can see the defrag working by looking at the [UTXO set size](  If you zoom out you can see that the number of UTXOs and the size of the UTXO set peaked in January and now the number of UTXOs is back down to what we had at the end of April 2017.
To learn more about the relevance of the UTXO set size, the pirate who can't be named has an informative article, "[My Thoughts On Your Thoughts]( in the form of an open letter to Erik Voorhees.
@_date: 2011-06-22 21:03:03
In principle they can be.  All you need to do is convince over 50% of the mining network to (A) not accept transactions from these marked coins, and (B) not to build on any block that does accept transactions from these marked coins.
Given how centeralized the mining pools are this might be doable if they are willing.
Furthermore, once 50% of the mining network agrees to the blacklist, everyone else will come on board too; because if the majority of the other miners refuse to build on their block, then their work will be worthless.
This addresses r3m0t's point 3. As long as 50% of the mining network has blacklisted the coins, they become untradable; even for those people willing to trade them.
@_date: 2011-07-03 19:09:11


A bitcoin private key is 32 bytes.  A bitcoin address (a hash of the public key) should only be 20 bytes (when you add an checksum and base 58 encode it expands to 34 ASCII characters).  I don't know where the 500 bytes comes from.
@_date: 2018-07-24 15:04:55
How can you confirm that the open source firmware is the same firmware on your Trezor device?  If you ask the device to dump its firmware, the firmware could lie and just print the open source firmware while not actually being that firmware.  If you try to upload new firmware the existing firmware could just ignore that instruction, or insert its backdoor into the new firmware being uploaded.
If you do generate your own seed, how do you know the firmware isn't leaking secrets through by manipulating the signature nonces or through some other sidechannel?
@_date: 2011-07-04 05:54:01
Where did you get your bitcoins to sell from?
@_date: 2011-11-07 18:18:54


Banned by who, and how?
@_date: 2011-06-14 07:55:08
You can keep a running tally of the unredeemed coins making the lookup O(log(n)) in the number of existing coins.
@_date: 2011-12-11 01:42:16
You don't need to be fully synchronized to spend your received coins, only synchronized as far as roughly the point in time that you received the coins.
@_date: 2011-06-14 22:25:13


There are two parts to the bitcoin network; the miners and the network peers.  It is sort of like a bicameral government.  Firstly the network peers must all agree on the bitcoin rules.  If they disagree then there are really two (or more) different networks support two (or more) different kinds of bitcoins (aka a chain fork happens).  Then for each network, 50% of the miners for that network effectively control which blocks and transactions are accepted.  The miners can filter blocks and transactions, but they cannot change the rules.  If they try to change the rules then they are effectively mining for a different peer network (a different kind of bitcoin).   If no peers are on this alternative network (other than the miners) then their new type of coins are not going to be useful to other people.
... I haven't quite explained this as clearly as I would have liked to.
@_date: 2017-07-03 01:24:24
Take all the processing power of the entire bitcoin network and shrink it down to a single square micrometer (1/1600ths of the cross section of a human hair). Pretend that this processing power can test Bitcoin private keys at the same rate it tests SHA-256 hashes.  Cover the entire earth's surface with these processors and start testing private keys.
While we wait, high up in the north, in the land called Svithjod, there stands a rock. It is a hundred miles high and a hundred miles wide. Once every thousand years a little bird comes to this rock to sharpen its beak. When the rock has thus been worn away, then this whole Earth computer will have tested every possible private key.
@_date: 2017-07-24 04:03:25


The txid is not just an id.  It's hash of the information that represents the ledger's delta. I.e. the txid captures which UTXO were spent and deleted from the UTXO set, and which new outputs have been created and added to the UTXO set.


You have it backwards.  The legacy txid was is one that is not the unchangeable contract because it could be malleated on the network.  The legacy txid is the one introduced a lot of chance for a bug to occur in wallets, and exchanges, and those bugs did occur because wallets and exchanges incorrectly assumed that the txid was unchangeable once they created it.  With segwit it is finally possible for wallets and exchanges to produce transactions whose txids are unchangeable.


Again you have it backwards.  Because the txid of segwit-only transactions are unmalleable, you can validate that your transaction made it into the blockchain by looking up the txid.  It is the legacy transactions that you cannot validate just by looking for your txid because it may have been malleated on the network prior to being mined.




The malleability bug just refers to the txid being malleable, and sigwit fixes that.  Transactions are still malleable, and it is not possible to eliminate transaction malleability entirely. Because of the scripting language it is always possible to build scripts where transactions can be authorized in multiple different ways and there is no way to ensure one specific way gets included in the block (via the wtxid hash).
This same kind of malleability exists in all kinds of digital signature schemes, including ones used by PGP, yet no one has been up in arms about digital signatures some how being invalid even though the literal syntax of the signature itself can be altered in transit.
@_date: 2017-07-02 14:11:21
[Bitcoin script is not Turing complete](
@_date: 2017-07-22 23:58:25
No it isn't true.  The PDF metadata for both the 2008 and 2009 versions of the Bitcoin whitepaper suggest it was written with OpenOffice.org 2.4.
(Also the timezone offsets in the PDF metadata suggest the papers were written on a computer with a North American timezone setting.)
@_date: 2017-07-23 21:57:52


1. With segwit, the full transaction data, including the signature datat is hashed, called the wtxid, and committed to the coinbase transaction of a block.  This is just as secure as the old transaction style.  You can lookup the wtxid in the coinbase and prove [to a court] that a particular transaction with particular signatures, was included in a particular block.
2. The old transaction style can have the signature data tampered with before committed.  This changes the txid.  This is the whole problem of malleability.  There is little the Bitcoin protocol can do to completely prevent all forms of signature data malleability, and there isn't and never was any guarantee that the literal transaction data you broadcast is the one that would appear in a block.  Essentially all forms of signature malleability are syntactic, but not semantic, changes.  Changing a low-S signature to a high-S signature doesn't change the fact that the transaction must have been authorized by someone who knew the private key.
3. Signature data malleability still exists with segwit, because, again, there isn't and never was any guarantee that the literal transaction data you broadcast is the one that will get into a block.  With segwit, this signature data malleability can change the wtxid; however it cannot change the txid.  That is the malleability fix.  Because the txid doesn't change we can build new smart contracts such as indefinite bidirectional payment channels and lightening.
@_date: 2017-06-29 13:41:45
I feel like this is the type of confusion that Jimmy Nguyen's article was meant to sow.  Even iang, who rightly dismiss  Jimmy Nguyen's larger point about e-signatures and contract law, is still falling into the framing that segwit somehow materially changes how digital signatures are handled in Bitcoin.  Segwit doesn't materially change anything.
Non-segwit transactions are passed around the network prior to inclusion in the blockchain together with its signature data.  When blocks are mined, this signature data must be included for the blocks to be validated.  Once validated nodes can prune this signature data.  Light nodes who do not do full validation must download this signature data to construct a transaction id but can throw it away afterwards and generally do not check the signatures and trust the proof of work instead.
How do things work with Segwit transactions?
Segwit transactions are passed around the network prior to inclusion in the blockchain together with its signature data.  When blocks are mined, this signature data must be included for the blocks to be validated.  Once validated nodes can prune this signature data.  Light nodes who do not do full validation may choose to not download this signature data at all and trust the proof of work instead.
The story almost exactly the same!  Segwit transactions only rearrange data within the protocol's data structures, but always the same data still occurs somewhere within the same data structures.  The only difference is Light nodes can optionally avoid downloading the signature data for the signatures that they were not going to validate anyways.
Let's look at iang's criticisms, keeping in mind that his criticisms apply equally as well to both segwit and non-segwit transactions.


Firstly, I ask why is Ian submitting his transactions without the signature data?  Recall, even with Segwit, transactions are sent around the network along with their signature data.  There is no reason to expect users to strip this signature data out of a segwit transaction before sending it to one's company's accounting department any more than one would expect users to strip out the signature data of a non-segwit transaction.
Secondly, a signed transaction by itself does not mean that the transaction was executed.  You can sign lots of transactions, but unless they end up included in the blockchain, they don't amount to anything.
In triple entry accounting, the issuer, Ivan in iang's example, must sign the receipt to make it valid.  Bitcoin doesn't have an issuer as an agent, rather the protocol itself issues Bitcoins.  In lieu of an issuer's signature, Bitcoin provides proof of work built on top of the transaction as evidence that the transaction is processed.
So, instead of checking the issue's signature, for Bitcoin, the accounting department must run a node to check the proof of work on top of the transaction. It is best if this node is a full node, and I would strongly recommend it be a full node, but if the accounting department wants to run a light node they can.  In this case they would find the block header that contains iang's transaction can retrieve the Merkle branch that connects iang's transaction to the header.  For non-segwit transactions the transaction would contain iang's signature data, if for some reason he didn't provide it.  ~~For Segwit transactions the light node would also need to retrieve a second Merkle branch connecting the segregated signature data to the header.  However, if the light node already has to get one Merkle branch to validate the transaction, retrieving a second branch is not significantly more work, and can both branches could be retrieved with a single request.~~ Correction: For Segwit transactions the light node retrieves a different Merkle branch connecting the segregated data to the header.  This segregated data contains the transaction data with the signature data just like the non-segwit transaction and one can validate iang's signature on this transaction.
So really, there is no semantic difference between segwit and non-segwit transactions here.  Any criticisms of the semantics of signatures for segwit transactions can equally be levied against non-segwit transactions.
@_date: 2013-12-03 23:35:30
I have.  I even found [a small flaw in the protocol](  It was fixed.