@_author: kasittig
@_date: 2013-05-07 04:07:35
Well, sites like yours make it very difficult to be a woman in technology who isn't stereotyped, regardless of your intention. But it sounds like you're more interested in making the consumer side work than making those of us who develop the actual technology that you're exploiting not miserable at work and at conferences.
Gender stereotyping may just be B.S. in your mind, but some of us live with it every day. I am offended by your self-centered attitude and your site. I would advise you on how to make your site not terribly offensive, but it sounds like you'd prefer to spend your husband's money and keep your head in the sand.
@_date: 2013-05-07 03:44:19
You also said that you're aware that the technology industry is full of chauvinism, and yet you're pandering to those stereotypes. "Tongue-in-cheek" is a poor excuse. You should be sensitive to the plight of other women in the industry. Can't you show people how cool bitcoin is without becoming part of the problem?
@_date: 2013-05-20 18:50:56
Some further investigation turned up [this paper about BQP](


Well, yes, this is vacuously true, as parallelization does not affect the complexity class of the algorithm. However, parallelizing factorization does make it significantly faster. "Computationally fast" and "computationally easy" are not the same thing. All crypto systems that are based on factorization hinge on the fact that factoring really big numbers takes a really long time on (most) modern machinery - but remember that the general solution to "my encryption is too weak" is "use a longer key" (see the "known attacks" section of [this Wikipedia article](
[Here's another article about Google's quantum computers]( that contains some super vague quotes from Professor Aaronson that kind of back up what you're saying, I guess. The only resource I was able to find on TSP was a tutorial on the DWave website, which isn't exactly Real Scientific Research. 
You must've missed the part where I already linked to the Wikipedia article on Shor's Algorithm. Would you mind making it up to me by finding me a paper that shows that there's a quantum algorithm for TSP that improves its asymptotic runtime?
edit: For future reference, this statement:


doesn't do you any favors. Integer factoring is not known to be NP-complete. I did misspeak in my previous assertion that there is very little that has led us to believe that quantum computers will be able to transform problems in NP to problems in P - I meant to say NP-complete problems.
I also realized that you missed my link because I accidentally posted this comment, thought it wasn't posted, rewrote it, and reposted it.
@_date: 2013-06-01 18:52:23
I'm totally aware of why this is a bad idea, and I am informing you that it is very unlikely that this is his actual information so you can stop making yourself upset about it.
@_date: 2013-05-20 18:28:26
Thank you for the article. I apologize for underestimating your knowledge of computer science, and for the confusion that I caused by oversimplifying a very complex problem.
You are correct (to some extent) that you can't "just throw hardware at NP-hard problems". However, there is no indication that quantum computers will be able to make any progress in this regard either. You may find [this article by Scott Aaronson]( interesting - this is a draft version, but I wasn't able to find a free copy of the Scientific American article.
I am unsurprised that Google is heavily invested in the development of quantum computers, given their investment in heavily parallelized infrastructure. Consider [Shor's algorithm]( - the great speed-up here is that a quantum computer is able to "explore" many different potential factorization at once. You can implement the same idea using Google's very own [MapReduce]( - it doesn't change the complexity class of the algorithm, but it does make the runtime faster.
So, back to your assertion that quantum computers will cause huge leaps forward in AI. This basically assumes that one of the current limitations on AI is that massively parallel problems can't be solved efficiently - but these are the very problems that Google is excellent at solving.
Which problems in AI would be significantly easier with a fully functioning quantum computer? What do you even mean by "easier"? Do you mean that many AI problems are known to be in [BQP]( I don't recall any off the top of my head, but maybe you could enlighten me.
@_date: 2013-04-07 20:04:52
@_date: 2013-04-12 20:44:23
It looks like you deposit bitcoins into your account and then are credited the equivalent amount of USD, depending on the MtGox exchange rate at the time of your deposit.
@_date: 2013-06-01 19:23:54
Ah, my bad. Someone sent me the link this morning because they thought it was hilarious how upset people were getting about someone "leaking their information", so I assumed it was recent. Thanks for alerting me to my error, and I'm glad that you've cooled off in the past three days!
@_date: 2013-05-07 03:44:57
Are you a miner or a minor?
@_date: 2013-05-20 15:27:07
...are you serious? Do you know what a quantum computer is?
Quantum computers are great because they enable better, faster parallelization, but the current problems in AI are NOT because modern computers are lacking in power. If all you had to do was throw more hardware at a problem, why hasn't Google solved anything?
I'm about to graduate with an advanced degree in computer science. My thesis was in machine learning. I have taken many, many theory classes at once of the best engineering schools in the world, including several from one of the most famous and productive professors in the quantum computing field. You have NO idea what you're talking about.
@_date: 2013-05-20 18:16:41
Thank you for the link. You clearly have a more nuanced understanding of computer science than you led me to believe with your initial comment. I did initially oversimplify because I (mistakenly, apparently) assumed that you had no idea what you were talking about.
I still disagree that many problems in AI will be made easier with the advent of quantum computers, simply because the existing models just aren't that good (or that good at generalizing to new situations). I would be very surprised if all it took was a quantum computer to bring about the singularity. But, of course, Google isn't exactly known for publishing all of its internal research.
Just a note - there is very little that has led us to believe that quantum computers will be able to transform problems in NP to problems in P. I agree that, to a certain extent, you can't "just throw hardware" at NP-hard problems, but there's nothing to indicate that quantum computers will do a better job solving these problems either. You may find [this article by Scott Aaronson]( interesting - it came out in 2008, but much of the theory has remained the same (the actual article was in Scientific American, but I'm having trouble finding a free copy). 
What problems will quantum computers be particularly good at solving? It seems like these problems are the same problems that can now be easily parallelizable (take factoring, for instance) - the same problems that can now be solved more quickly by throwing more (parallel) hardware at them.
Coincidentally, Google is basically b
@_date: 2013-06-01 18:11:23
It's fine. There's no way that he both has $3 million in investments AND is a complete moron, so at least half of this is a joke.
@_date: 2013-04-12 23:06:32
Yes, I am serious. Did you look at the link?
@_date: 2013-05-07 02:38:17
As a female computer scientist with a bitcoin-enthusiast boyfriend, I am offended by your use of gender stereotypes. You love spending his bitcoins? You want to review products? You want to connect with other women who also love to spend their husbands' money? Are you serious?
Why don't you channel your energy into learning about the technology behind bitcoin. The last thing that computer science needs is more uneducated fangirls.