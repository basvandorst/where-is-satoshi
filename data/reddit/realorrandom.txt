@_author: real-or-random
@_date: 2014-04-14 13:23:25
(Disclosure: I'm the first author of the paper.)
The protocol provides you with a proof that somebody misbehaved (in case of active misbehavior.) It's up to each of the individual participants how they deal with that fact.
It is possible to restrict the ban of this user to a certain period of time and only to this group of users. This makes even more sense for "passive misbehavior", i.e.,  somebody goes offline... There are honest reasons: the machine might just have crashed.
In the end, it makes sense to agree on a set of rules, first of all because it's not a good idea for anonymity if each user applies individual rules. 
It's similar to the rules for e.g., transaction fees: Crypto tells you that a transaction has indeed been produced by the owner of the coins. If the transaction pays enough fees depends only on the miner's policy. The miner might use the "default" policy but it's not mandatory.
@_date: 2016-12-27 18:19:17
It's not about pruning actually. ValueShuffle supports pruning but that's just because Bitcoin and CT support pruning already. (And ValueShuffle does not introduce anything that would prevent pruning, e.g., ring signatures as in Monero).
@_date: 2018-04-22 13:59:12
Actually I think privacy is often a yes-or-no question in some sense, at least for correlated data. Maybe "all-or-nothing question" is a better term. Privacy is so incredible hard, and one piece of data suffices to break it. 
The most important example of correlation is public amounts and anonymity. I think that some technology that hides the amounts will be crucial because without confidentiality of the amounts, anonymity is way too hard, expensive, unusable, and just unrealistic. And without anonymity, fungibility is broken.
This applies mostly to on-chain payments but I don't see how we can have good privacy without having good privacy on layer 1.
Buying the discrete logarithm assumption for CT (even just for today) is indeed a fundamental change, and I doubt that it can find wide consensus in the community (even though this is my unrealistic hope.)
But I think we need a debate about this! Otherwise it's not clear what the privacy people should spend our efforts on. If someone agrees with my argument that we need some form of CT, my question is: what does it need to have to be a realistic candidate?
In particular, what form of soundness? Post-quantum soundness? (A quantum computer does not help to break it). Based on hash functions or can we have something else? Statistical soundness? (Noone can break it unless incredibly lucky, no matter what computer they have.) Perfect soundness? (Just noone can break it.) This seem like technical details but they matter a lot.