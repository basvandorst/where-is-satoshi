@_author: michele85
@_date: 2016-04-23 11:14:22
some economists still dont get this...
@_date: 2016-04-23 15:05:19
it's not insane, it's politically motivated.
some guys are just dishonest, economists much more than others
@_date: 2016-04-10 01:53:10
just wait for sidechains, then we will have anonimity
@_date: 2016-04-29 19:00:29
@_date: 2016-04-23 15:18:07
ivy league rotting
@_date: 2016-04-11 11:03:48
is the Classic team willing to code a Classic version for Core 0.12.1 and 0.12.2?
if not, what are Slush F2P and KnC going to do?
@_date: 2016-04-24 15:08:08
yes. sort of
@_date: 2016-04-02 23:09:33
can you explain which stages segwit still needs to go through to be fully deployed?
can you tell me an approximately time-frame for these stages?
how long does it take from the moment it is released to the moment the soft fork locks in?
is classic willing to cooperate and write a 0.12.1 and 0.12.2?
@_date: 2016-04-02 23:41:33
hi Gavin, 
as far as you know, Classic will release a Classic version for 0.12.1 and 0.12.2 so to let the forks happen?
if yes, how long will it take to code those versions?
thank you!
@_date: 2016-04-28 14:23:37
i agree
@_date: 2016-04-02 23:19:35
what about witness data?
is it just hashed and passed into the coinbase or it's transmitted with the block as side-data?
how is witness data calculated toward the blocksize limit?
@_date: 2016-03-03 11:53:28


this is not an assumption. ALL miners said they are ok with 2Mb. 
You think they lied? why should they do?
and we have upcoming new tech to scale something like 10x from now
where do you see the fault logic? why 2Mb is not safe? core itself pledged to write the code for 2Mb
@_date: 2016-03-03 11:04:31
we have week blocks and iblt
@_date: 2016-03-20 00:44:33
reasonable timeline?
what do you think?
@_date: 2016-03-22 13:48:16
as far as I know classic is 100% for segwit
@_date: 2016-03-03 11:02:14
i'm just a small investor / sometimes user
anyways, think whatever you want
@_date: 2016-03-22 13:31:04
when a feature is good Bitcoin's price increases so it's good even for miners ;)
@_date: 2016-03-08 02:08:51
i don't understand your post
@_date: 2016-03-31 01:34:35


demurrage is utter and total evil
@_date: 2016-03-05 16:16:58
yes, we can wait and we will wait.
segwit MUST be implemented AS SOON AS POSSIBLE
but we must also raise the blocksize after it
and i hope for LN and sidechains to come as soon as possible
@_date: 2016-03-07 19:32:21
new settlement system?
what are you talking about?
is it irony or what?
@_date: 2016-03-04 01:32:39
not really difficult to code
@_date: 2016-03-03 11:06:23


i don't know with 1Gb, but 2Mb is ok right now, especially with tech like weak blocks and thin blocks and the like
@_date: 2016-03-03 00:59:13
ok thanks
i really hope it will came sooner than later
@_date: 2016-03-23 01:43:17
totally agree
Peter is a good guy that just does not understand how Bitcoin works
@_date: 2016-03-23 17:09:29


I myself have doubts about core. i spoke with luke and gregory and i got shady answers. i.e. i was asking questions like "if and when is safe to raise the blocksize are you willing to do that?" and received answers like "i cant raise the blocksize" which was technically correct but clearly not what i intended with my question.
and there were a lot of these situations. they avoided answers using cheap talk. it was disturbing!


as far as I know jeff, gavin and toomim said they support segwit (toomim disagrees only on discount for seg data)


my only hope is it's not too late and the damage is contained. And core was somehow unwillingly "forced" to promise a raise in the honk hong agreement


the problem is we will never know how many users dropped/will drop off the network for delays and fees and how many potential users were/will be driven away from bitcoin
@_date: 2016-03-20 00:26:19
well no, i mean when segwit will be ready on main chain to use for all users.
I can't find any indication on this from core.
(yes, i know, the soft fork must be accepted by the miners first but i assume it will be accepted as soon as it's out)
@_date: 2016-03-22 19:20:07
well technically speaking segwit is not scaling, it's just efficiency, but we need it.
i can't understand why anyone could be against it
toomim himself said classic team will incorporate it
it's not that i support classic, it's that i believe blocksize should be higher (5 Mb at least + segwit) for the short and long term health of bitcoin.
Core is unwilling to raise, thus i support classic 
@_date: 2016-03-03 00:38:22
they cut in half each transaction so they can store double the amount in the same 1Mb space
@_date: 2016-03-03 01:54:27


what do you mean?
Samson Mow won't upgrade?
@_date: 2016-03-03 02:23:59


this makes no sense at all!
a bitcoin user doesn't need bandwidth. 
I myself use bitcoins and i have a terrible bandwidth, but no problem using them. 
if blocks were 1Gb i wouldn't care, so why any user should be concerned?
@_date: 2016-03-03 01:50:09
why is a "short" schedule a problem? (i hardly see how 3 month could be anywhere short...)
why 1 year instead of 2 or 3 months?
what's the matter?
@_date: 2016-03-03 00:40:09
it would be very appreciate by me if someone explains when segwit is deployed (beginning or end of april) and how long is the grace period
@_date: 2016-03-05 16:18:41
this is not believable. not even in the slightest. BTW it can't be done without revolutionizing the whole bitcoin. i'm not even sure if it is indeed possible
anyways core should raise the blocksize just to cut off this vector of attack
@_date: 2016-03-03 14:52:15
is anyone there???
luke-jr himself has admitted there is no algorithm centralization-resistant
centralization of miners is just a natural process, it can't be avoided
in case you have missed it the difficulty is currently 163,492,000,000
how can solo-miners ever expect to mine anything??
how can solo-miners ever expect to be as efficient as specialized miners?
try to think about it.
there is nothing we can do and small blocks wont solve the problem
it's the random guy versus the industry. no match at all
@_date: 2016-03-22 13:34:17
i cant understand you.
i fully support classic, but i want to see segwit implemented AS SOON AS POSSIBLE
what's the matter?
@_date: 2016-03-03 02:26:01


I'm a Bitcoin's user and I just need a node to run things.
besides if the emergency hardfork is implemented why not upgrading blocksize along with inflation?
thus will be no concerns at all....
@_date: 2016-03-03 00:22:48
changing the difficulty algorithm changes Bitcoin's inflation rate even if slightly. Thus Bitcoin's economics are affected
(granted this is not a big deal) to me this is much more controversial than any possible change in the blocksize limit.
and besides that, i don't see how we can do such an hardfork with a short grace period and require 1 year for the 2Mb hardfork
things just do not add up here
I can't even start to understand your logic here
@_date: 2016-03-28 10:15:14
when 0.12.1 and 0.12.2 will be released?
@_date: 2016-03-03 01:16:18
here instead i still don' understand


this is not true
the change will make the inflation closer to the "simple explanation" not to the "original inflation"
even total bitcoin's number is not 21 millinos. that is an approximation as much as the 10 min inflation rate is.
for the same logic why not changing the total Bitcoin's number to be exactly 21 millions?


so hardforks can be done and can be done on a short timespam. 
so why the 12 months grace period for the 2Mb one? 
why not 1 month grace period when the 95% treshhold is reached?
i can't understand
and why not hardforking the 2Mb limit along with inflation while you are at it? validation time should be already addressed with segwit!
i really can't think of a valid explanation
@_date: 2016-03-22 13:23:57


can you please explain these bugs with some examples?
have you got any news from devs on segwit?
thank you!!
@_date: 2016-01-22 18:40:34
As far as I know classic developers are in full support of segregated witness.
They want the 2Mb fork PLUS seg wit, not instead of
@_date: 2016-03-23 19:33:13


maybe, but what i meant was clear and it went on and on for several questions with me not getting an answer at the very end.
This was reeeeeally disturbing!
these were public posts so you can read them on my profile if you want.




segwit is good code. it's useful, it's needed. I myself would prefer an hardfork for it's implementation and not having the signatures in the coinbase but i can live with the ugly soft fork. I dont know what these users are thinking, maybe these accounts have an agenda. I don't know. (btw i believe we really need an hardfork to clean the code and correct several old bugs)


i believe the utmost majority of classic community supports segwit. Maybe they can disagree on the process, but not on the code's scope. have you any evidence of the contrary?


as i wrote on these kind of things there could not be any evidence. 
and we will never find any. you can't have a proof for something that fails to come in existence.
So we will never know.


this time is different. previously there were only confidence crises and bubbles, now we have a real problem with the protocol (never had before) ad a real and big competitor (ethereum)


yes, but it's not a given, it's a process and it could occasionally fail or slow down. you are wrong if you take it for granted in the short run.


Truth to tell the only thing that prevented me from selling at least a part of my coins was rootstock and the whole sidechain concept.


transactions actually dropped hard 


this could mean a lot of people is wary and ready to sell if things get ugly.
@_date: 2016-01-19 11:52:13
Bitcoin has some base parameters and scalability is one of them.
not changing the block size is like altering the 21M limit. It's not supposed to happen
so we MUST change the blocksize.
@_date: 2016-01-30 09:28:58
Core vision, if you do the math, is not viable in the long run. 
There must be a considerable capacity increase when block reward diminish otherwise fees wont cover expences.
How can bitcoin live without miners?
@_date: 2016-01-30 13:24:29
yes, there is a time when you must scale no matter what.
And this time is now.
Cores are great developers but they lack economic insight and vision. 
The transaction bottleneck we are experiencing now is a HUGE problem for Bitcoin long term viability
Bitcoin is new, it's uncharted territory, so I don't blame them for this, but nonetheless they are making a great mistake which should be properly adressed as soon as possible.
Would I prefer elegant solutions over brute force? No doubt. But we can't afford this right now.
And BTW Peter Todd just said SW is not safe as a soft fork...
@_date: 2016-03-03 11:03:54
but emergency hardfork is ok, so why not a non emergency one?
and if 1 month is too short, why not 3 months?
3 months if far from being too short...
@_date: 2016-03-07 00:29:03
@_date: 2016-01-22 23:09:04
i prefere a contentious hard fork which market will take care of rather than bitcoin's slow death to blocksize limit
@_date: 2016-02-09 01:28:24
based on no data
every inch of scale is achieved renouncing a little bit of decentralization. costs will increase a little bit no matter what.
this is a trade off and we must face it. how much decentralization are you willing to renounce in order to scale? 
21M limit has nothing to do with this at all. the only thing that will become more centralized is mining (which is already on it's way) and less nodes around the globe.
keep in mind that if china raises electricity bill this will end in an instant
@_date: 2016-02-29 21:55:23
how dare you criticize 's judgement?? 
he is saying these transactions ARE spam
@_date: 2016-02-08 12:02:57
and when that space runs out?
and what about economics, investments, start ups, user's psychology, bitcoin social contract, alt coins that can steal market share, etc.. ?
all these things do not count?
@_date: 2016-02-08 17:09:24
i fail to understand how could it take O(N^2) work.
what's the bottleneck?
@_date: 2016-02-08 12:50:33
what if we create a new genesis block with all the relevant data, put it's hash in the blockchain so it's secure and then cut the old blockchain? (for full nodes obv)
is there any drawback?
@_date: 2016-02-09 18:10:09
as tech remains the same scaling is a burden on EVERY system, not only bitcoin.
hardware and software improvements make scaling less of a burden but there is always a trad off we have to face, no matter what
a bitcoin node will always have a cost to operate
@_date: 2016-02-08 12:53:38
so, what's all the fuss with large blocks?
@_date: 2016-02-08 23:53:20
the vast majority of people do not value decentralization as much as the core devs but they do value speed, low fees and 21M limit
scaling will happen
@_date: 2016-02-09 13:26:49


ehm, bitcoin was supposed to be digital cash... do you know a certain satoshi who wrote a paper a long time ago??


yes, but the market needs to get rid of core. core is hijacking bitcoin
@_date: 2016-02-08 12:09:24


this is not a feature, it's a bug. nodes should upgrade.


we can rollback from a 2Mb hardfork too.
and the rollback would be a 1 line softfork. the most easy of things


yes, less trauma!! just force all the wallets to upgrade to use it...
@_date: 2016-02-08 01:32:16
testnets do exist indeed
@_date: 2016-02-09 00:01:25


this is the whole point. is 2Mb too much? modern computers and bandwidth can get along with it, maybe higher limits will be problematic, but not 2Mb


yes, this is a problem, but the solution is full nodes pruning (which will come), not block size limit
@_date: 2016-02-22 23:02:41


I understand your position but i strongly disagree.
For a currency to have real value it needs to be also a commodity. Just like gold. i suggest you check out the "regression theorem". 
For this reason removing "spam" now without sidechains could be very dangerous IMO and harm the long term success of Bitcoin.


ok, wrong question. is core willing to write the code?
@_date: 2016-02-07 18:07:02


a lot.
on the other hand a lot of investors will sell if the system is struck and unable to grow
@_date: 2016-02-11 01:15:00
it's at least 5000 blocks, i know
@_date: 2016-02-05 13:39:22
yes, with Bitcoin you have an alternative to the banking system
isn't that enough?
@_date: 2016-02-08 12:48:52
how is the classic hard fork evolving? 
are chinese miners backing it up?
@_date: 2016-02-10 18:59:19
ehi Greg, core roadmap is too late (we need an increase now not in april) and segwit is just a 1 shot optimization. 
sure it's great and it should be implemented as soon as possible, but we need a blocksize raise as well!!!! and we need it now, blocks are full
@_date: 2016-02-22 03:55:49
ok, thank you very much for your answer!
this really explains a lot to me.


i really hope your figure of 60% spam is correct.
right now there are 40 btc a day in commissions. if it's 60% spam this means that 24 btc (10300$) a day, each day, are payed for spam.
I don't know who may be willing to pay such a huge amount of money just for spam.
I really hope you are correct about this, if not it could be very dangerous. 
An economic crisis is approaching and a lot of new users will adopt Bitcoin in the next years, maybe more than we can foresee right now. It would be a shame if Bitcoin is off guard and unprepared. It could be a huge setback. Hardforking is slow.
Crypto will be tomorrow's money and this will bring huge economic benefits to everyone. We should strife to spread adoption and growth as fast as we can


how much can the blocksize grow when we have all the improvements ready?


may I ask why you dislike altcoins, expecially eth? just interested in your personal opinion here.
@_date: 2016-02-29 21:53:11
do you have any time frame?
@_date: 2016-02-09 11:05:08


ok, is 2Mb blocksize limit too much? this is the question!!!
segwit should be implemented as soon as possible but has nothing to do with blocksize limit.


I mean cut the blockchain in order to cut historic validation cost
@_date: 2016-02-08 15:26:12
This is needed if the blockchain becomes too big. when you start a full node you need to download all the blockchain and validate it. It has also implications for the consensus code
no, i mean to put the hash once in a month and then after 1 or 2 years cut the blockchain and replace il with a genesis block + 1/2 years of the most recent blocks.
this way the size of the blockchain is not growing without limits and security is preserved.
sure, you will lose the "history" of all coins but you can still store the whole blockchain in some sort of archive that is not needed to operate the system
@_date: 2016-02-10 13:15:33
ok, now i understand what you are saying
@_date: 2016-02-25 18:51:50
when will LN be ready?
is there any timeframe?
@_date: 2016-02-25 01:58:38


try to ELI20+
I'd appreciate it
@_date: 2016-02-23 13:38:06


in regard to gold "spam" is all things that are done with gold that are not wealth transfers. all non monetary uses like jewelry or industry.
to me real "spam" is a transaction meant to make a DDOS attack or something like that.
And we do not know what will happen if we raise fees, if "spam" is driven out or wealth transfers are. We just can't know this will work out in advance. And we will know how many "legit" transaction won't be signed for the high fees. full blocks won't show eventual damages to the network.
this short video is circulating a lot in these days and pretty much sums up my fears
userbase shift is a slow thing in social networks, but a very fast thing with geek currencies. a poloniex account is a matter of minutes. 1 mistake and it will be all gone.
it is uncharted territory. maybe my fears are overstated, but if they are not?


no, not a raise to 2Mb, a raise to whatever size is safe. if it turns out that 10Mb is SAFE will you willingly write the code or not? and if it is 20Mb? or 100Mb?
I'm not asking to which size you will consider a raise safe in the future, just if you will contribute to a raise if it is, even if there are already LN and sidechains 
@_date: 2016-02-08 19:14:24
you where talking of CPU work, not broadcasting.
and besides if a single node was transmitting x Mb of data and the size doubles it will transmit 2x Mb so no O(N^2) here too
you do not broadcast to all the network, just to a few peers
am i missing something?
@_date: 2016-02-07 22:33:31
segwit is great, but it's a 1of and it's not ready jet
@_date: 2016-02-09 14:06:48
you can hash all the old UTXO and the other relevant infos in a new block and then after a period of time cut the old blockchain and replace it with a new genesis block
this would require an hard fork obv
@_date: 2016-02-08 22:06:32


validation on the single node just doubles, so O(2N) on each node


not relevant, we are speaking about broadcast and validation


same here. the broadcast band required on the single node just doubles so O(2n) for esch node


classic has the same transaction limits of core, but with double blocksize limit. you won't get bigger transactions in classic so it's still O(2N) work
@_date: 2016-02-09 11:21:29


yes, we must wait Bitcoin is replaced by an altcoin before we start executing decisions.
at that point Bitcoin will be dead
@_date: 2016-02-08 00:20:50
of course. thats one of the many reasons the 2mb fork is necessary right now
@_date: 2016-02-05 13:53:27
why the system should stay crooked?
with bitcoin you are your own bank after all...
@_date: 2016-02-09 13:29:02


yes, it was designed to be transferable, not bottlenecked as it is right now
@_date: 2016-02-08 19:18:30
yes, of course.
but is it really that much of a problem if we can prove ALL ours UTXO with a reasonable amount of PoW?
if we bury the hash of a genesis block under 50.000 blocks there is no chance anybody could cheat on it
@_date: 2016-02-09 14:23:16
don't hold your breath.
this wont come anytime soon
right now there are checkpoints: you download the whole blockchain and then only validate the last 6 monts
@_date: 2016-02-09 23:34:40
we should subtract satoshi's bitcoins from the equation
@_date: 2016-02-22 01:10:09
thanks for your answers.
just some other questions for clarification if you don't mind.
there are methods to lessen the bandwidth usage already avaiable such as this
and i know Matt Corallo has a relay network as well.
there are also other proposals like IBLT and weak blocks already in core road map
why can't we just implement one or more of these solutions and then scale the blocksize? 


can't we just make the clients verify in advance the transactions to hasten the verification process once a block is created?


how did you get this figure if transactions are encrypted? did you base your belief on the transaction amount? if so how can you judge if a transaction is legit only based on this metric?
a final question from an economic perspective:
high fees and delays really disincentivize users. what if users chose to use an altcoin instead of bitcoin? ETH market cap is already 1/20th of bitcoin. what if Bitcoin loses it's dominant position?
isn't it wiser to accept for a short period of time a less decentralized Bitcoin just to make the ecosystem grow until we get sidechains and LN and then maybe scale back blocksize limit with a soft fork? or maybe make a blocksize increase just for 2 or 3 years (150000 blocks) and then revert to normal?
isn't the threat of altcoins greater than the threat of less decentralization right now? 
this kind of things start very slow but becomes very fast when it gets going. we can wake up one morning and just see Bitcoin's position gone. 
And we still have all the techniques to improve bandwidth 
@_date: 2016-02-24 18:52:15
it is not
@_date: 2016-02-01 19:09:33
what pretty serious objections are you talking about?
I mean, isn't the core devs opposition the only objection here?
@_date: 2016-02-22 14:48:37
how can i distinguish legit transactions from spam transactions on the blockchain?
@_date: 2016-02-29 23:05:44
ok thanks
@_date: 2016-02-05 16:53:07


so goes life. everywhere early adopters have huge profits. btw it's not too late to buy cheap


economics 101 tells us this is great


not really. you trust an algorithm and the mechanism of consensus.


energy consumption is needed to provide security


yes, this is an issue but we are solving it


there is plenty of control, each transaction is public
@_date: 2016-02-21 23:56:41


can you give me a technical and detailed explanation?


what do you mean with "actual transaction volume"?
@_date: 2016-02-09 15:30:17
dont know
@_date: 2016-02-09 22:43:59
are you sure users want to use Bitcoin just because it's shiny if fees and delays are too high?
price will increase if demand doesn't drop meanwhile due to bottleneck
@_date: 2016-02-10 12:47:56
satoshi's bitcoins are effectively out of the market so for every metric they should be counted as non existent 
we should take them of from market cap
that's all
@_date: 2016-02-08 23:00:14


So if you have 1000 transactions you validate them in time x, when you have 2000 transactions you validate them in time 2x.
Where is the O(N^2 ) ?


the internet is faaaaaaar from being saturated by 2Mb.... 
this is not a point at all. we should look at the cost for the single node. that's what matters for decentralization 
@_date: 2016-02-08 23:19:43


you have lost me. what are you talking about? how can a single node's work double? Remember, the single node is what matters here.


ok, so no problem here upgrading to 2Mb. for higher capacity we will see and evaluate


it talks about sync, not node operation.
and we can just prune full nodes if this becomes a problem
@_date: 2016-02-09 11:07:49
Bitcoin is supposed to be decentralized cash, not uber decentralized payment settler. you can not have a decentralized cash if you do not accept small losses in decentralization (and this does not mean bitcoin becomes all of a sudden a centralized currency) it's a matter of tradeoffs as always
there should be a balance in all things
@_date: 2016-02-10 12:24:19
yes, reflected in the price but not in the supply
this makes a distorted relation
@_date: 2016-02-08 22:31:01


ok, i don't get this. how can complexity double? isn't each transaction validated on it's own? (besides computers do improve over time)


who cares about Network-wide, we just have to care about the work for single nodes as far as decentralization is concerned!!
@_date: 2016-02-15 13:28:40


you are not "the vast majority" 
besides that there are many many degrees of decentralization and there are trade offs in bitcoin
@_date: 2016-02-09 03:39:44


No data, no source, i'm not a market surveyor.
just speak to people and you ll get it too.


well that's it. we disagree. 
i believe your (core) vision is harmful in the long and short run. i believe economic incentives will force a fork on bitcoin sooner or later. it's just a matter of how many damages the network will suffer from core's opposition.
@_date: 2016-02-08 11:59:11
and it is far more complex too.
it's a huge and complex change
@_date: 2016-02-22 14:01:47


segwit is pure gold!
I don't know if you are right with the 40% legit - 60% spam figure and the blocksize bump is not too late.
I have no technical means to prove or disprove this assertion. 
I can only pray you are correct. Beware that if you are not this could lead to great damages.
As far as I know if someone is willing to pay for something there is economic value in it. There are many legit uses of Bitcoin beyond wealth transfer, and 10K a day is a big chunk of money to be squandered.
btw i also believe if you make an hard fork you should use it to clean the code from previous soft forks and upgrade with other nice stuff like Schnorr signatures.


yes ofc growth must be as safe as possible.


IF AND WHEN IT IS SAFE to bump the blocksize with IBLT, weak blocks, bandwidth technology improvements and whatever new tech will come, will core be willing to raise it? (even if there are already sidechains and LN)
in your opinion what's roughly the highest size we can reach? (just an esteem)


well ok. but i was referring to the ones that are not scams and have legit tech improvements.
ethereum is turing complete and is planning to release a PoS algorithm (i don't know if it works or not). it's a huge difference from bitcoin.
p.s. i don't think Pow could be ever made decentralized again
@_date: 2016-02-18 16:05:29


that would be the real end and the beginning of hyperinflation
they know it
@_date: 2016-02-08 13:06:11


yes, obv, but what if we cut with 1 or 2 years? isn't that enough time to guarantee security? (even if less than original blockchain)?
@_date: 2016-02-09 01:14:33
the vast majority of people IN BITCOIN do not value decentralization over efficiency, scale and a reduced decentralization 
the vast majority of people IN BITCOIN are eager to sacrifice a little bit of decentralization (which anyway is inevitable as we are seeing with chinese miners) in order to achieve mainstream adoption
i'm in this camp too.
Bitcoin is a revolution, it's liberty, it's getting rid of the existing financial system. lets bring a little freedom to all. 
Let's change the world for now, than we can build a super decentralized crypto to serve hardcore users. the code already exists
@_date: 2016-02-09 11:18:25
when the system is struck as it is now, people will just use other cryptos.
and the more the system becomes congested the worse.
with halving coming all miners will see their profits cut in half so they desperately need to double the price. 
if no new user enter the system due to blocksize there is no way the price could double cause no more users means no more investments and no more price growth
the endgame is even bleaker. demand for cryptos is there so users will flock to altcoins which can take over Bitcoin's dominant position if the blocksize is not raised.
at this point Bitcoin will become the altcoin, will lose most of it's value and miners will suffer huge economic losses.
this is not going to happen, miners are not idiots when their money is at stake
@_date: 2016-05-21 22:07:25
pruning is for spv
i'm talking about a semi-full node with a new genesis block (with the old UTXOs) and the last part of the chain
@_date: 2016-05-21 16:03:41
so, the solution?
PoW is what keeps the blockchain secure and 1 year of PoW is as good as we need to get security.
we need to cut the old blockchain and replace it with a new genesis
@_date: 2016-05-16 12:37:04
when 0.12.2 will be released?
when signalling for 0.12.2 will start?
@_date: 2016-05-21 01:53:49
your SSD will need replacement even at 1Mb limit in just 1 year.
the only solution is cut the chain and make a new genesis block