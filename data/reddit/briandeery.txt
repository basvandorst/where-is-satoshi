@_author: briandeery
@_date: 2016-08-25 04:09:53
This isn't just talk and announcements.  This has been running in test mode for months.
@_date: 2016-08-08 22:33:29
Thanks for typing this up.
The last time I was transcribed was for a deposition. :\
@_date: 2016-08-08 07:09:51
An interview about mimblewimble was just done with andytoshi and pwuille.  Enjoy.
@_date: 2016-08-08 07:20:14
Chris Odom, creator of Open Transactions is planning on talking about this next Wednesday on the Crypto Show.
@_date: 2016-08-26 05:30:41
This is fairly surreal.  I was in the room when we were trying to think of a term to describe securing data against the Bitcoin blockchain.  It has now become an industry term that everyone knows.
We were writing our whitepaper and were using the term "staking" to refer to securing things in bitcoin.  as in tent stakes.
This was an overloaded term which I know would be confusing, so I walked over to the office with a complaint and a few alternative terms.  I forget who came up with the term anchoring but it was either me, Paul, Dave, or Peter.  I think it was Paul, but can't be sure.    
I went back to old draft of our whitepaper.  November 14, 2014 8:45PM page 13 is when I updated it to "anchoring".  Here we are today, with it being thrown around and everyone understanding what it means without explanation.
Now it appears in the tile of news articles: 
p.s. I have always hated the term "colored coins".  It is an overloaded word in the US.  
I guess since this is an AMA: Can we change the term colored coins to something else please?
@_date: 2016-08-05 03:03:57
Having spent a little time with NC and listening to his lecture at Texas 2015, I can feel CW's pain.
@_date: 2016-08-03 05:16:12
that's exactly what I was thinking.
@_date: 2016-08-20 22:58:56
yes, to the title question.
also this, to prevent duplicate outpoints, which might be construed as a nonce.
@_date: 2016-08-28 20:30:57


Good point.  No one is seriously considering tokenizing real estate.  (Ok, maybe Bitfury is.)  The ease of transferring title is not the problem.  It is a record-keeping and confidence problem.  There will be no private key for the land-owner to lose.
Currently in parts of the developing world, citizens do not want to go through the process of upgrading their title to a computer tracked one, because those database administrators have been known to update the title without due process.  The computerized records are much easier to update undetectably than the paper ones.
Land titles are a messy business, even in the developed world.  In the US, the courts allow messiness to be washed away through the passage of time.  
@_date: 2016-08-26 07:14:50
Dustin Trammell was anticipating the release since the whitepaper.  He downloaded and ran the client as soon as it was posted.
also, read this: 
@_date: 2016-08-26 06:50:00
Q: Did you know this AMA was going to be mostly about nomenclature and less about technology when you started it?
@_date: 2016-08-08 07:45:43
It took less than a week to go from an obscure darknet published idea to the FM airwaves.
@_date: 2016-08-27 01:29:36
good info, thanks.
@_date: 2016-08-26 07:00:50
hmm, I thought that some flavor of colored coins was used in the nasdaq experiment.  I had assumed they were more mature, just without hype from token holders.  I admit I didn't pay close enough attention to be able to differentiate the multiple projects, though.
I could never find a good answer about what tech the nasdaq experiment was using.  do you know?
@_date: 2016-08-03 06:36:06
I was under the impression that Bitcoin fights harder against this, with the slow re-targeting.
The difficulty re-targets after 2016 blocks.  If only 10% of the hashpower remaining on one fork, it would have 100 minute blocks for 20 weeks.  That seems unusable to me.
Even after the 20 weeks, Bitcoin maximally re-targets downwards to 1/4 of the old difficulty.  This would give 25 minute blocks for 5 weeks.  
The markets seem to have short attention spans for the latest gimmick. Waiting half a year for normalcy of block times seems like a stretch, assuming you can maintain 10% of the former hash power for that whole time.  
Note, having 10% of the hashpower remain would give the equivalent of a 100 KB block size today.  It would only support 11% of the transactions on the other chain.
The counterargument is that traders on the exchanges don't have to worry about the fall in transaction rate, since all the exchange trades would be off-chain, so it might still have a price despite being unusable.
It would take some pretty dedicated miners to make a contentious fork in Bitcoin a reality.
@_date: 2016-08-28 21:01:49
It's not about the money, it's about the hashpower.
@_date: 2016-04-14 03:55:53


The doublespend problem is a subset of this.  In the 90s, the plan was to use digicash servers to prove that someone hadn't spent the money before.  Parsing the the Bitcoin blockchain shows you that a particular UTXO has not been spent yet.
@_date: 2016-04-28 04:48:19


[I do](  
@_date: 2016-04-26 01:56:03
For those that listen you'll learn about things like this:
Ironically: [Stealth Addresses]( could also be used to implement the tracking side of this.  You register your Stealth Address Scan Key with Authority.  They can identify transactions coming from and going to registered addresses, and it is private to anyone but the whitelisters, since the Scan Key is not public.
@_date: 2017-12-05 07:31:15
This is a better presentation:
@_date: 2017-12-22 06:15:23
Nice interview u/statoshi
I think too many people are getting hug up on cash meaning pieces of paper with dead people printed on them.
The term cash is much richer than that definition.  For example some types of contracts are "Cash Settled" 
To me cash means access to the final settlement layer in a monetary system.  The paper bills represent directly held claims on the federal reserve.  There is more indirection, but for a cash settled contract, this is value which represents access to the Fed's systems.
With this broader view of the term cash, then the whitepaper makes sense in a world of multiple layers.
@_date: 2015-12-17 05:06:13
yah, sorry about that.  It was raining nickels before the token sale.
Maybe it was a little inspired by the gospel.
Sending money to people so they pay attention...
@_date: 2015-12-05 10:16:00
Here is a radio show with the bitsim* guy
@_date: 2015-12-31 20:53:16
Don't we already have this?  
@_date: 2015-12-15 01:01:08
@_date: 2015-12-25 18:57:45
I have heard it pronounced as "Receive".
@_date: 2015-06-25 00:39:14
I liked the old interface better.  I was looking for mempool sizes the other day and couldn't figure out how to show it.
*edit found it now.  
@_date: 2018-05-02 13:01:06
hah, it looks like bloq took over the lease on the old Factom building.
What two buildings are those IRL?  I can't place them.
@_date: 2018-05-02 13:04:10
We have the 2016 version pinned up in our office.  I'll have to keep an eye out for the new posters.
@_date: 2014-11-17 23:59:31
If we just wanted to create Merkle proofs of the data, then yes, doing it yourself or using assorted services would be much easier.  
We wanted to go an extra step beyond that though.  We are defining bounded shared search spaces to locate transactions after the fact.
Bitcoin is a complex mechanism to create a bounded shared search space for BTC transactions which is simultaneously spam and censorship resistant.  These last two points are at complete odds with each other.  Since we are also trying to make a bounded shared search space, we need a complex mechanism to balance spam and censorship.
If the shared search space were maintained by a single party, like you are suggesting, that party would have censorship powers over the data it is collecting.  The censored party could put their data in a separate system which isn't censoring.  Now 3rd parties would need to now know to look in the 2nd system for valid transactions.
This would be analogous to looking in dogeparty for your counterparty assets.  If not all counterparty wallets respected cross chain transactions, the whole system would fork.  Would the entire counterparty community take the risk of doublespends in dogeparty just because someone was being censored in the Bitcoin search space?
We are using a system similar to blind commitments ( to make censorship by the system provable.
As far as the fees and a half-penny, go, though, that is probably a short term figure.  As the blocks fill up, fees will rise to get transactions confirmed.  If an application wants the irreversibility of the Bitcoin hashpower, they can use Factom to pool in a censorship resistant way.
@_date: 2014-11-18 01:08:30
hmm, there are two points in the Factom system.  There is the time before being included in the blockchain and the time afterwards.  This distinction would be similar to having the Bitcoin blockchain itself vs having miners continue mining.
Lets address the time after Factom is recorded in the blockchain.  All the data structures are stored in a P2P Distributed Hash Table (DHT).  Individuals can opt to join the DHT and share as much or as little of the full data set they want.  We are expecting that users will highly share data subsets that are personally relevant to themselves.  Also, proofs are possible with only a small segment of data, which can easily be stored locally.  
The DHT will survive even if all the Factom servers go down.  Historical data will persevere online if peers continue to share it.  
DHTs are public structures though, so users sharing contraband data will be advertising that fact.  If a determined world government wanted to stop a specific BitTorrent file from being shared, they could probably do it.
The second part of the question would be if the servers can survive a determined attack.  That is a trickier question.  The block building network is similar to Bitcoin's, being a flood fill network.  This can tend to obfuscate where the servers are.  Also, being a proof of stake system, large mining farms will not be target-able, because they don't exist.  The Factom server personalities can have multiple locations all over the globe which exercise their authority sporadically, making it harder to find them.  Also, if one server does get shut down, the same personality can pop up another one immediately somewhere else in the world.
A determined whole-world evil government will just turn off the internet, or have ISPs cut off anyone connecting to the networks, so no Factom cannot survive that.  However, if Factom were serving some useful function to the economy, the heavy handed approach would have political blowback.  It depends on what you mean by determined.
Edit:  Maidsafe and StorJ have potential to store Factom data as well.  Those technologies are coming later though.
@_date: 2014-11-25 00:25:04
Thank you for the comments.  I have fixed the URLs on the whitepaper.  Google makes some amazing collaboration tools, but they do have some quirks.
@_date: 2014-11-17 20:22:52
So, yes, it is secured by the full force of Bitcoin hashpower.
@_date: 2014-11-14 16:21:58
Yes, the goal is to have a decentralized system.  We are planning for 16 servers to share the responsibility.  To select the servers, there will be a voting system similar to delegated proof of stake.  It will be based on the stake actively participating in the system.  The voting shares will be of committed, non-tradeable value (Entry Credits).  The committed value cannot be assigned to a different public key, it can only be used to pay for Entries in the system.  The intent is to give active users of the system the role of deciding who runs it.
@_date: 2014-11-13 21:53:06
@_date: 2014-11-14 00:33:49
If you are just trying to timestamp a bunch of your own data, then I agree censorship is not a problem.  The problem is when we have a group of people sharing a repository.
Lets take the example of Mastercoin.  Anyone can submit a MSC transaction and publish it to Bitcoin.  An individual miner can decide they don't like Mastercoin, and refuse to include the transaction.  A different miner could later include the MSC transaction.  The censoring miner has two choices: 
1: Let the transaction go thorough, by building on top of the non-censoring miner.
2: Try reverse the transaction by orphaning the block with the MSC transaction.  This is risky and probably won't work if the majority isn't also censoring.  Satoshi teaches us about the Gambler's Ruin problem.
Anyone expecting MSC will scan the blockchain for valid MSC transactions going to themselves.  If someone were to just embed a hash of a valid MSC transaction, then other's Mastercoin software could not know it was a valid transaction.  Bitcoin is the only place to find any potential MSC transaction.
Let say that Mastercoin wallets were modified to look other places for valid transactions.  There have been other proposals for looking in dogecoin, etc.  Chains with less hashpower than Bitcoin can be reversed easier, and MSC can be doublespent.  That is why something secured by Bitcoin hashpower would be preferable.  
Now, how would the Mastercoin community decide where else to look for valid transactions.  Lets say that we define some method for your big ball of data that you hash and place into Bitcoin to contain a valid MSC transaction.  All the MSC clients would need to get that big ball of data.  Without some kind of restriction, you could make it extraordinarily large (gigabytes), filling it with mostly spam.  Bitcoin solves the spam problem on it's own, with the tradeoff of not being scalable.  
Lets say, the Mastercoin Foundation sets up a central server you are proposing.  They promise to keep out spam, so downloading gigabytes of junk is no longer a problem.  Now the Mastercoin Foundation is a censorship point.  They can classify Wikileaks as spam and censor them.  Wikileaks would not be able to spend their money (well, they would have to revert to the original tech of placing it in Bitcoin with higher fees, but Mastercoin would be a special case compared to a more generic system).  
If any one entity controls a chokepoint, then they can also censor.  This is why Factom is needed, to eliminate single points of censorship while preventing Denial of Service by spam.
After Factom seals the transactions and places a hash in Bitcoin, the transactions cannot be reversed by Factom.
In this example, all references to Mastercoin would still be valid if replaced with Counterparty.
@_date: 2014-11-14 01:36:43
There is a downward pressure on the size.  It is limited by how fast money can flow through the system.  Any single Factom server paying for spam would only get back a fraction of the money they put in.
The data structures which are needed by everyone are kept small.  They are just lists of which Chains were updated during that period.  Also, there will be a higher cost for inserting data which affects everyone.
Since the highest level lists (Factom Blocks) are needed by everyone, it is expected to have high availabliity, since everyone needs to share it to prove their own data.  
lower hierachy lists (Entry Blocks) will have varying levels of availability, based on their usefulness to individuals, and their desire to share.
If you absolutely need the data to be around forever, you can store your data subset yourself.  There will be various data preservation mechanisms outside of storing it yourself too.  The Factom servers will store the data too.
The lists are secured by placing the Merkle root in the blockchain, so any changes will be detectable.   
@_date: 2014-11-21 00:28:51
We are contemplating an adversarial system right now similar to what you describe.  The consensus mechanism is still being developed, but this is what we are thinking right now.  We envisage at least 32 full node servers.  16 of the servers (Federated servers) will be key to the consensus forming mechanism.  They will cooperate together to package the data into the Factom system.  There will be 16 additional servers (Audit servers) which have user votes assigned to them, but fewer than the Federated servers.  The Audit servers have an incentive to publicize misdeeds by the Federated servers.  If users are unhappy with a specific Federated server, they will withdraw their voting support.  If enough support is withdrawn, then the misbehaving server will be demoted down to an Audit server or below and the highest ranking Audit server will rise to the rank of Federated server.
Hopefully this is enough incentive for each of the systems to keep each other honest.  What do you think?
@_date: 2014-11-13 20:39:44
Also, data in Factom is organized into a hierarchy before the Merkle trees are created.  The Factom system has some organizational structures devoid of any user supplied data.  The organizational structure sorts data by Chains.  Chains are just Entries that are grouped together by some numerical identifier.  The Chain is specified by the user who submits the Entry, so the organizational structure is user definable.
In this treatment plan example, the hospital would sign the hash of a document, and place that in a Chain specifically created for your treatment plan.  Any unsigned hashes could be thrown away as spam.  Only the documents filed in your Chain would be relevant to your case.  Any of the other hospital records signed by them in other's Chains would be irrelevant to your case.  There is no need to even ask for them.
@_date: 2014-11-13 18:36:57
That only solves half the problem.  Censorship is still a problem.  Without having a decentralized competitive system, a single party can censor.
For example, right now, Mastercoin transactions are only canonical in the Bitcoin Blockchain.  Lets say Mastercoin wanted to scale.  MSC transactions would be canonical in two places: The Bitcoin blockchain, and in some collection secured by Bitcoin.  If the collection point is controlled by one party, as you are suggesting, they can unilaterally censor new entries.  Factom, like Bitcoin, is an elaborate system to make censorship non-trivial and expensive.  The entire federation would need to be censoring to effectively exclude an Entry.  Also, blind commitments are used to prove censorship is happening.  The Entries are paid for by committing a hash of the Entry before revealing what it is.
See Adam Back's ideas about blind commitments.  
Factom also creates a system to find relevant data in the collection.  One possibility is to bunch unstructured data together, hash it, then place the hash in Bitcoin.  Finding data of interest in that big ball of data would require having the entire ball.  Factom segments where the relevant data can be found, so a user does not need all data secured by Factom to find everything they need.
@_date: 2014-11-17 19:33:10
Factom is very much not an alternative to pegged sidechains.  Sidechains and Factom are trying to achieve similar end goals, but by orthogonally different mechanisms.  Both projects are trying to increase the scalability of Bitcoin by reducing transaction volume of the Bitcoin blockchain.  Sidechains moves BTC value off the blockchain, and allows people to trade value without incurring additional transactions in the Bitcoin blockchain.  
Factom is moving non-BTC denominated transactions off the Bitcoin blockchain.  Applications which need the irreversibility of Bitcoin but don't need to deal with BTC value transfer are perfect for Factom.  
Pegged sidechains implement a feature called atomic swaps.  When the technology is ready, Factom would like to have its internal token on a BTC-Factoid sidechain.  This would allow distributed instant swaps between the two value pools.
@_date: 2014-11-13 20:12:59
The plan right now is to store the data in two places.  The Factom servers themselves will maintain the data and make it available.
A parallel community maintained database is also planned.  The community storage system is a Distributed Hash Table (DHT), similar to BitTorrent magnet links.  All the data structures in Factom will be available on the DHT.  After data is entered into the blockchain, the minimum sources needed are the blockchain and the DHT.  The blockchain is needed as to find keys into the DHT.  Once the DHT is queried for the highest level hierarchy data, more DHT keys can be found for data more relevant to the individual application.
To be absolutely sure your data stays around, you would need to store it yourself.  The data hierarchy allows you to only store data relevant to you, in addition to some organizational structures.  You wouldn't need to store hashes of security camera footage if you are only interested in property transfer records.
Presumably, more popular applications will have more people sharing data relevant to their peers.  For example, popular files in BitTorrent have tons of availability from pure altruism.  If the data was needed to help run a business, there would be a monetary incentive to make the data highly available.
Keep in mind, the data stored in Factom won't be terribly large.  There are intentionally sized based fees to prevent storing bulk data in Factom.  The intent is to give a place to store a proof of existence.  The data is expected to be small, like a Mastercoin transaction, hyperlink, photo hash, property transfer record, or small text document.  Storage of larger files would be cheaper in other systems.  Factom would be a good mechanism for keeping an immutable record of where to find larger files in other systems, though.  
@_date: 2015-05-12 17:47:34
hmm. I have mixed emotions about this one.  on one hand, AML/KYC is a huge invasion of privacy.
on the other hand, maybe this is a first step along the way to one of the cypherpunks' goals.
They wanted to have an identity system that would only disclose the bare minimum a counterparty needed to make a decision.  
A real world example would be with a bouncer at a bar.  All they need to see is an ID with your photo, and that your age is above a threshold.  They have no business knowing your home address, if you are an organ donor, signature, or your driving qualifications. 
Why does coinbase need to have my water bill in order to continue a business relationship with me?  They have no business knowing how long of a shower I take.
The current AML is a complete joke.  You have to hand over all the information needed to spoof your identity to every company who wants it.  I have to trust them to maintain these records secretly, even though they are barely competent to do their main business.
I would rather trust someone who has protecting my privacy as their primary business.  
@_date: 2014-11-17 22:14:50
You bring up a good point.  We are kind of surprised a project like this hadn't been started earlier.  The combination of a DHT with OP_RETURN messages is one of the primary goals of Factom.  See this news article from back in March of this year:
Mike Hearn was advocating a DHT secured by Bitcoin in this article.
Ideas are easy, the hard part is implementation ...something about 99% perspiration.
After thinking about mechanisms to collect and package arbitrary entries, we realized it would quickly turn into giant morass of unsearchable data.  The users would be able to keep Merkle proofs of data they saved, but finding it later would require scanning the entire dataset, plus knowing what to look for would also be a problem.
Factom adds an user specified sorting mechanism, and combines it with a hierarchy, so that users can later find the data they secured.  The hierarchy also allows users to limit the total amount of data they need to download to do searches.
This would be all fine and dandy to do as a weekend project, but there are a few problems which would still exist.  
-There needed to be some way of rate limiting data being entered into the DHT to prevent spam.  Charging fees are an effective way of limiting spam.  
-Someone needs to pay for the BTC fees to get data into the blockchain.  Users paying servers with BTC transactions to avoid BTC transactions doesn't make sense.
-A centralized solution would cause a censorship point, so there would need to be some kind of distributed system, which Factom is implementing.
-Once you have a distributed system, you would need to have some enforcement of consensus.  In Bitcoin, the BTC generated by miners going against consensus would not be valuable, so it keeps them flowing with the main consensus.  Factom would have a similar system.  Similarly, the Federated servers need to maintain consensus in order to sell their Factoid tokens.
Factom is implementing a sort of Proof of Stake for steering consensus.  Pure PoS suffers from "Stake Grinding" problems that allow rewriting of history.    Factom eliminates the Stake Grinding problem by using Bitcoin to make history unchangeable.  We can build a system using PoS, where the active users decide who runs system is run instead of miners.
edit: formatting, details
@_date: 2014-11-24 18:02:55
If either Mastercoin or Counterparty were to expand onto Factom, it would solve 2 problems facing both :
1) Speed - the Factom servers come to consensus every minute, on a time, not probabilistic basis.  After 10 minutes, they create a transaction to timestamp it into Bitcoin.
2) Bloat - What would happen if Patrick Byrne got his way and all Wall Street transactions resolved to the Bitcoin blockchain.  There isn’t enough space to handle all those transactions as Counterparty stands today.  If we threw open the blocksize limit, and totally gave up on decentralization, then we might be able to do it, but at the cost of losing what makes bitcoin special.  
I re-read BIP70 and I do not see how the payment protocol will substitute for block confirmations.  Even in BIP70, there is the line: “﻿Merchant's server detects payment and after sufficient transaction confirmations considers the transaction final.”  
I suppose that having a signed address from the merchant would give the sender more confidence that they are sending to the correct merchant, but that doesn’t solve a doublespend from the merchant’s perspective.  Even if a new BIP did somehow allow for instant confirmations the bloat problem would still be there.  
This brings into question the nature of finality, and what it would take to reverse a decision.  Factom gives more granularity to finality.  
In Bitcoin, there is much talk about the number of confirmations.  The more confirmations, the more final a transaction is.  There is a gap between 0 and 1 confirmations, though.  Polling the network to see if there are conflicting transactions is how most systems solving this gap work today.  Even that, though, is fragile, since miners can include whatever transactions they want (See BitUndo) 
Factom fills that gap.  There are multiple rising levels of confidence Factom would give.
0-10 seconds: Transaction is broadcast and acknowledged by the appropriate Federated server.
0-1 minutes: Transaction is signed by the majority of Federated servers
0-10 minutes: Transactions over the past 10 minutes are signed by majority of Federated servers, and an OP_RETURN transaction is created and submitted to Bitcoin.
0 - ~20 minutes: A Bitcon miner mines the OP_RETURN message, making Factom unable to modify the contents of the blocks.
~20 - ~60 minutes the OP_RETURN transaction is buried under 6 confirmations in Bitcoin.
Depending on the risk tolerance for the individual transaction, they would wait anywhere from 0 to 60 minutes.  Same as with Bitcoin, but with more granularity before the first confirmation.
edit: formatting
@_date: 2015-05-12 22:39:18
I see the size of the UTXO being problematic for one thing, but not the one you are complaining about.  I see midweight wallets coming into existence.
UTXOs can be sorted by age.  It is far more likely that recent transactions are spent again.  A UTXO which is years old is very unlikely to be spent in the next block.  If it is 10 minutes old, it is way more likely to be in the next block.
This means that old UTXOs do not need to be stored in memory.  The UTXO set can be stored on the HDD and only the most recent ones need to be in memory.  (btcd currently stores all the UTXOs on disk, and it takes forever to confirm a block on a slow hdd.  validating time is &gt; 1 minute per block on my 8 year old computer.  they are changing that soon, though.)  If someone spends money they just moved, it will propagate as quickly as it does now.  When years old money is spent, the node would need to reach down into the harddrive before it can validate the transaction, and propagate it to other nodes.  This means that older money will take sligtly longer to propogate across the network.  
Bitcoin sends everything twice.  Once as a broadcast and once as a block.  Since the node is expecting a block with this transaction it keeps the years old UTXO outpoint in memory.  This is basic caching technology.  When a block comes along which includes this years old transaction, it is already in memory.  Validating the block will be fast, because everything in that block is in memory, even though the entire UTXO set was not.
The problem comes in with an advancement on the current bitcoin design.  There is a lot of ongoing discussion on UTXO Commitments.  it was also known as ultimate blockchain compression and several other names.
SPV clients cannot be lied to that a transaction does exist when it doesn't, due to the Merkle blocks.  Full nodes can lie, however, that a transaction does not exist when it actually does.  Full nodes can prove a positive that someone sent you money, but cannot prove someone has *not* sent you money.  Also, when you ask about a particular address you are revealing that you are interested in that address, and it is probably yours.
There are lots of proposals with many pros and cons, but here is the gist of it.  The entire UTXO set is turned in to an array.  A Merkle tree is formed from this array, and the mrekle root is placed in the coinbase.  Miners would orphan a block if it did not have this UTXO commitment.  
This makes for interesting privacy wallets.  Downloading 656 MB today will tell you if there is any money sent to you, that the wonderful tool shows.    You can get this 656 MB from a completely untrusted source, and verify it against the headers + coinbase.  This makes a midweight wallet while still having complete privacy over what addresses you are interested in.
The problem you are pointing out is that the miners will need to create this UTXO array, create a Merkle root of it.  Two Merkle roots would be in the header+coinbase.  The Merkle root of the current transactions, and the Merkle root of the UTXO set.  The UTXO commitment will be bigger.  
Depending on how the UTXO commitment array is arrayed, then it will be more or less difficult for the miners (and maybe full nodes) to calculate and validate each block.  The commitment might age out older transactions, having a constant size.  It is not a straight forward problem, and that is why there hasn't been much progress on it.  There are many different designs that work better when trying to solve different problems.  This is my pet problem:
is planning on just broadcasting the raw blocks from his satellites.  In his current plan, if you miss a day, or however long he repeats, then you need to get back to fast internet.  I asked him instead to broadcast the headers+coinbase and a Reed-Solomon reconstruction data set of the past month of the UTXO set.  This is similar to how you can download par files if you have most of a movie, and it fills in the few MiB of gaps in a GiB sized file.  This would allow you to download the current UTXO set when you are near civilization, and at least once a month, turn on your client when you are in the desert to see if someone has sent you money.  The UTXO Reed-Solomon reconstruction trades off more processing time and file storage space to get by with less bandwidth.  Since the satellite does not have 2 way communication and cannot act like an SPV node, it must send everything needed.  If everything is just the delta of the UTXO set, then it is way easier.
@_date: 2017-02-01 05:09:10
...or maybe all that mining is the [whole point](
@_date: 2016-01-01 22:45:09
perhaps something like this?&gt; $
@_date: 2017-02-26 18:58:22
Please stop conflating monetary inflation with price inflation.  
Bitcoin has positive monetary inflation, but negative price inflation.
With USD it is positive for both.
you should be comparing these monetary inflation graphs:
@_date: 2017-02-11 16:33:02
I disagree.  We definitely need MAST.  We lost it when OP_CAT was disabled way back when, but segwit allows it to be added back as a soft fork.  
MAST will enable a lot of the more complex scripts that the ethereum projects uncover a market for.  
You don't need loops if you unroll the program.  Also, the unrolled program would be part of the witness, so it would go into the larger available space.
@_date: 2017-02-28 07:29:31
it seems like is everywhere, including the Crypto Show!
@_date: 2015-05-19 15:58:08
Factoids use a different crypto than bitcoin.  As such, we needed to jump through some technical hoops in the purchase process.  That was all transparent to the purchasers.  
Hold onto the 12 words generated from the koinify wallet.  Those 12 words will be what you enter in a Factoid wallet.  
Factom is not live yet, so there is no wallet yet either.
ps. to understand how to get from the 12 words, to the private key, to the OP_return data, see this writeup.  It is intended for a more technical audience and is not a wallet.
To see an example of op_return data:
@_date: 2016-03-17 04:16:10
On Feb 6, John Barrett from Bitcoins and Gravy challenged theymos to a public boxing match.  Who would win and why?  How could it be made provably fair?
@_date: 2017-02-26 20:49:22
I was referring to the tendency of things purchased with BTC to cost less and less as time goes on (denominated in BTC) even though there are more BTC in circulation.


Perhaps.  Care to expound on this u/2cool2fish ?
@_date: 2017-02-14 04:29:02
WOW!  I have been listening to Econtalk religiously for nearly a decade now.  I never imagined that something I helped create would be talked about on one of my favorite shows.  
If you haven't read it already, "The Price of Everything" is worth a read.
I too can date my awareness of Bitcoin to at least the 2011 Econtalk episode.  I, like Russ, figured that it couldn't work.
I am still kicking myself for missing Hernando de Soto's lecture in North Carolina back in 2004.  My friends only told me about it after they got back from the speech.
I did get to meet Norman Borlaug though, which was probably a better deal.  Meeting Michael Munger was pretty neat too.
Jim, if you are reading this, the biggest thing that is happening related to Bitcoin south of the border I in my opinion right now is the Central Bank of Barbados issuing Central Bank money as Colored Coins.  A sovereign nation is now relying on the Bitcoin blockchain to conduct monetary operations and settle between banks.
@_date: 2017-03-07 08:53:42
sees it as a way to [pay people](
sees it as a way to bind [private states](
sees it as an escape from [financial oppression](
Andreas sees it as a general [tamper proof system](
others see it as a [smart contracting platform](
These are all smart people, and it is still unclear how Bitcoin will transform to fit these needs.  It is, however, beyond any of these individuals to even know the best uses of the system.  The crowd does though, or at least will.
@_date: 2017-02-06 01:28:23
I prefer his coarse [brother](
@_date: 2017-03-07 09:33:51
I have seen no proof myself, but several people I trust are convinced they have.
Even if I had the proofs, it would make sense to keep them private.  The world is better off not knowing for sure.  
I suppose I am just being selfish.  While it is obvious he has taken extreme efforts to hide then subsequently be dismissed, I want to know what the future holds.  If the stories are correct he (and presumably his team too) have been thinking about the implications for at least 50% longer than anyone else.  With that much of a head start and a group of brilliant people, one can only imagine what was envisaged.  
It is not the past I am interested in so much, it is the future, and the horizon is much clearer standing on the shoulders of giants.
@_date: 2016-01-04 04:33:09
he gave a speech about it.
also, the author probably won't comment [here]( 
*edit also
@_date: 2017-03-05 07:37:37
All in due time.  
@_date: 2017-03-06 22:05:37
Don't forget the transcript from the ATO investigation.
If this is a fabrication, it is more detailed and involved than any fiction that I have read before.
Perhaps the current thought leaders had heavily discredited CSW to preempt any pronouncements he makes.  I suspect that was the effect he was going for though.
His official silence is good.  Having a Vitalic for Bitcoin I don't think would be healthy.  There are enough enlightened people who will champion individual ideas when their time comes.
The world is not ready for the full vision of how Bitcoin will play out.  We are going to have to find our own way through the transition along the way from black market money to merchant payment system to speculative investment to global trust base to world-class central bank to impervious smart contracting platform to its operation being a considerable concern of nation states.
@_date: 2017-03-13 04:58:11
You left out this gem:
I learned about this bug after my system launched.  I trusted that satoshi had gotten things right.  If I hadn't been so paranoid it would have bitten my design too.  Luckily other features in the system protect against this attack.
@_date: 2016-06-12 07:50:11
My project is known as Uh... Uh... in India.
@_date: 2016-06-14 05:38:38
@_date: 2016-06-14 05:37:28
I second the Factom recommendation.
what are you trying to do?  The hard part about cryptographically signing a document is to tie the signature to something meaningful.
In bitcoin the signature is authorization to move the bitcoins.  it was made meaningful by someone else sending bitcoins to the address.  The original bitcoins were made meaningful by someone burning electricity.
The hard part is connecting something meaningful to the signature.
Ensuring the document is the real deal is hard.  garbage in garbage out, as they say.  Making sure something is the real deal requires a process to validate it as it goes into the blockchain.
Detecting that something hasn't been tampered with is fairly easy.  This is timestamping.
Detecting that there is not a slightly older document that contradicts the one you think you are agreeing to requires publishing, which is a higher bar to achieve.  This is what blockchains provide.
Here are [some thoughts]( about Bitcoin as a timestamped publishing system.
@_date: 2016-06-12 02:54:23
This made me a little bit sad.  
@_date: 2016-06-04 15:56:33
does this count?
Maybe it fails the last one, since we use Bitcoin indirectly.
@_date: 2017-08-18 23:56:55
This is confusing to me.  How would a consensus critical UTxO commitment be any less reliable than something like a `witness root hash`?  
`witness reserved value` is just sitting there waiting for something juicy.


The protocol is independent of the software that runs it.  What do you mean by this?


a signature by whom?
@_date: 2017-08-21 23:43:46
Miners can increase their "effective reward per day" as it stands today in Bitcoin. Fixing the time warp attack should be part of the next hardfork.
@_date: 2016-06-14 22:32:14
thing might get you started:
@_date: 2017-08-19 00:11:11


ah, I see.  You are describing a security level somewhere above SPV level, but less than full block download.  By "trust blindly" do you mean SPV security?
@_date: 2017-08-19 13:28:41
I think I get the gist of your concern.  Thank you.
@_date: 2017-08-17 14:40:34
I believe you are greatly discounting the signatory businesses' protecting their reputations.  These are long term players who have seen bubbles come and go.  This time the runup may keep going perpetually, but that is unlikely.
Since they are concentrating on long term, and reputation management is a long term effort, I expect they will stay on with the plan, unless something else changes.  The fear that some bad news of a split spilling out onto MSNBC, *which might pop the bubble*, would seem like wishing against the inevitable to them.
For these business people, asking them to permanently mar their reputation in order to keep the runup going for a few more months seems like a tall ask.  Who knows, maybe a recession in Q1/Q2 2018 will keep the runup going for a while longer, but that isn't factoring in to their decisions. 
When bcash changed their signature scheme to not be replayable, I believe it shifted the project from a takeover attempt to a teaching tool.  It is showing the exchanges how much money can be made in a hard fork.  It is getting the community practice to swap coins they got from nowhere.  It is showing wallet developers that there is a huge demand for handling both chains.
Also due to the alternate signature, it is giving the community the false belief that hard forking will be a relatively painless process that they can deal with on their own time.  The next fork will be a huge mess.  If bcash hadn't changed the signatures, I suspect that many people would have seen their bcash coins "lost" due to replays and subsequently shunned the fork.  If many of the exchanges, etc wanted to preserve their bcash, they would have had to shut down entirely for a few days while getting the engineering right.  The calculus may have been to just tell bcash to stuff it.  That may be the result in a few months.
Despite all the noise, I don't believe that bcash is really what the expansionist wanted.
The block size debate will not end as long as access to the blockchain is valued.  It is something we will have to learn to deal with changing every so often.
If Core were to merge in a hard fork that activated a year out, or even 2, that might be enough to cause some to defect from the agreement, but Core doing nothing will result in the fork.  Keep in mind, a crisis will likely precipitate right before the fork, which will push those contemplating defection to continue with the fork.
I agree with you that few businesses want to lose the high quality developers in Core, but are gambling on them coming back to the main chain after it is clear which fork got the economy.
@_date: 2017-08-29 14:53:28
Errata:  I mentioned that the replay protection was only for relayed transactions, but that they would be valid in a block, thus a false assurance.  If the code described here is what goes into the 2x fork, then the replay protection would instead be valid, and would prevent special Bitcoin transactions from being confirmed in the 2x chain.
@_date: 2017-08-21 23:26:15
Miners can increase inflation rate at will today in bitcoin.  Fixing the time warp attack should be part of the next hardfork.
@_date: 2016-11-22 02:08:16
[This]( might be relevant.
Even in a world of asset based money, there will still be plenty of demand for debt based tokens, like R3 is building.  Even in a Bitcoin Maximalised world, what they are building will still be very useful.
Debt is a [human institution]( and thinking that Bitcoin will make it go away is naive.  Introducing cryptography into the coordination process will cut down on confusion and corruption, and that is a good thing.
@_date: 2017-08-20 21:24:01
TIL independently invented Schnorr signatures.  
It wasn't clear from the presentation, but do both parties need to be in a channel directly?  Can the different potential payout states be generated across a route with many hops?  If I need to open a direct channel with my counterparty it seems less scalable.
@_date: 2016-12-28 07:32:38
This is pay to contract explained when purchasing goods.  It is close, but is not quite what nullc was referring to. It sets the stage quite well though.
sign to contract might be using the hash to commit as the R value in the ECDSA signature.  It has its own risks, namely of exposing private keys.
Here is some earlier conversation:
@_date: 2017-08-15 16:25:30
Seems like UTxO commitments would be helpful here.  That would allow midweight wallets, which would work well with a satellite.
Where did you leave off with UTxO commitments way back when?
Since it is yall's system though, you can broadcast a blockstream signed commitment.  That would get most of the way there...
@_date: 2016-11-30 04:56:18
What about [Gavin]( [Gavin]( and the other [Gavin](
@_date: 2017-08-20 04:12:31
Thank you for making your thoughts so clear.  
This is a tantalizing way to look at the world, seeing communities as the unit expressing a will, rather than individuals.  I tend to think this is an oversimplification, and that people are individuals with their own nuances and motivations.  I suppose when economic incentives are in play, it can be easier to generalize.
This lends explanation to why coinbase caved in the bcash circumstance.  The size and attention of the community was particularly large.  It was totally within their terms of service that they would ignore “Advanced Protocols” like bcash.  They have a long history of ignoring requests that required access to private keys.
Threats of lawsuits over bcash seem baseless, due to it unquestionably being a fork and customers agreeing to individual arbitration.
It seems like people should get mad at them failing to do the things they are supposed to do.  Canceling orders days later without warning is not something I would expect them to do, and makes people angry.  I guess the community was larger and all got angry at the same time at Coinbase, which had a different effect.


Which is why I am predicting a crisis again.  Segwit probably won’t have have broad usage in 3 months, so the losses incurred by miners paying themselves fees would be about as expensive as before the agreement.  I haven’t seen anyone find evidence of a miner induced backlog, but the timing was too coincidental.


Wow, this is already happening.  
Also consider who’s eyes they are trying to protect their reputations in.  There are countless internet trolls who come and go saying nasty things as a course of business.  They can’t keep everyone happy.  Their peers, however, they will be interacting with for the foreseeable future.  They need to rely on each others’ specialties for their own business to succeed.  For example, a news provider interested in the agreement already biases articles.  Breaking of the agreement would be something brought up in every article mentioning their company going forward for years.  This is an agreement ostensibly made amongst peers, who they will face at many conferences going forward.  It may have been made under duress of sorts, but most believe it was entered freely.  In a choice between an internet mob and longstanding peers, the choice seems clear.


This is looking past the fork.  While there is always the risk of a wipeout, Bitcoin was designed to make it very expensive to go against consensus for the miners.  I believe that the outcome of the fork would be decided within a day or so.  Bcash survived because they broke the security model of Bitcoin, and allowed rapid downward difficulty adjustments.  That won’t be the case with a core/2x split.


I’m presuming that you are referring to a choice between 2x and core.  I have not really seen them be particularly acrimonious toward overt ASIC BOOST, just covert.  I can see where they might start going after overt boosting if they had their druthers though.


Indeed they seem to have taken Nassim Taleb’s tyranny of the intolerant to heart.
Another piece of insight you may be missing is them protecting themselves against coercion later.  Some of them believe that if they can be pressured into changing Bitcoin, then it will set a precedent for them being pressured more directly later.  Only a few of the core devs are anonymous people.  If they are seen by those wishing to control Bitcoin as pathologically obstinate, then the pressure would be applied elsewhere.  There was a quiet rumor of a kidnapping in years past, which may or may not be related to bitcoin.  Either way, fears of personal risk likely weigh heavily on them.
I suppose this is where our different views of the world come into play.  Where you see groups I see individuals.  Presumably a number of the core devs also hold sizable accretions of bitcoins.  The rich will pay for defense.  They have more to lose.
@_date: 2016-11-16 05:38:53
That is kind of the point of the article.  SegWit is not done.  It needs to be used, rather than just be available.  Hard forking to increase the block weight is a much easier sell if the [quadratic validation]( problem is solved.  Users need to be mostly on board before closing that hole (and the other attacks mentioned in the presentation).  Updating the wallets upgrades the users.
@_date: 2016-11-14 03:08:00
This is going to come in handy when explaining how BU completely changes Bitcoin's security model.
@_date: 2016-12-09 22:59:43
It always tickles me hearing people talking about my project. 
They talked about land titles and birth certificates.
@_date: 2016-12-09 02:01:25
This was a good show.  Here are the articles being discussed:
@_date: 2016-11-01 01:21:33
So... are you trying to say that bitcoin is launching these tokens to the moon?
@_date: 2016-12-06 03:49:27
This is an exceptional amount of rebuttal research for a 250 word article.
@_date: 2016-11-22 07:30:54
as seen [here](
@_date: 2016-11-30 05:12:14
Circa 2012.  
@_date: 2017-11-10 01:47:17
I too was surprised by that level of risk tolerance when the show was being recorded.
I have gained a better perspective since then though.  Roger quotes Satoshi that the ultimate long term solution is let the block size get at big as it needs to get.
 
My belief is that we have not yet gone through the "Then they fight you" phase.  Society is still a threat to Bitcoin, and it needs to stay resilient against attack by the powerful.  Eventually, many decades down the line, society will become as dependent on Bitcoin as it is on the internet today.  At that point, it will be different nation-states [attacking each other]( over Bitcoin network policy, instead of attacking Bitcoin itself.  That is the ultimate long term solution being referred to by Satoshi.  We need to get past the point where society can freely dispose of Bitcoin though.
He is right about the outcome, but wrong about the decade.
BTW, good job on the article Kyle
@_date: 2015-08-04 05:49:40
hmm, it seems like everyone there was having a long / off day.
for example, it didn't help that Chris was using specific terms to describe things that those terms don't mean.  
2:58 talking about blocks, but referring to them as *mempools*.
4:40 you're storing the whole data not the whole *tree* into the actual factom...
when referring to merkle roots
5:36 it's not necessarily the data itself in the factom *raft* model, it's all the hashes..
When he refers to data stored in factom as what the consensus model is called.
@_date: 2017-11-10 16:04:11
I just got back from both devcon and scaling.  There were 2000 highly motivated, highly creative, not to mention funded developers building an ecosystem on top of the network.  It was an eye opener for me.  For a while I had been dismissive of that network due to the constant stream of catastrophes.  I no longer believe it is a passing fad.  It made me scared about the future of Bitcoin. The thing that pushed me over the edge was someone walking around with a large neck tattoo with the eth logo.  
When Mike Hearn built lighthouse, he claimed 5% of the work was the blockchain logic and the other 95% was the higher level interface stuff, GUIs, fault handling, etc.  The 95% of the work can be developed by people who aren't necessary world class.  While at this point, the killer app seems to be fund-raising, lots of capital is building the higher level applications.
Joseph Poon was also at both.  His remarks during his scaling speech about leaving the party really hit home.  There was a completely different energy between the two conferences.  The prevailing theme at scaling was that ICOs were evil, and there was no opportunity for nuance, community, or incentive alignment.
The Rootstock team also made an appearance at devcon.  I didn't see too much enthusiasm there for building a project on Rootstock.  I spent some time with one of the founders and researcher extraordinaire SDLearner.  He turned out to be a really nice and generous guy.  If he is any indication of the rootstock culture, then it is unlikely to be toxicity driving away projects.  I suspect the eth developers innately can sense that building on the main network builds more value than building on a parallel network.  Also, they have faith in the Eth core devs to keep the system running even under attacks.
For a while I thought this was kind of a tortise v. hare situation, where slow and steady would win the race.  I was hopeful when Simplicity started coming down the pipeline.  After talking with a few Bitcoin core devs the prevailing thought was all these projects were ultimately about transferring money.  They were happy to let all the experimentation and ecosystem building happen on another system.  It was sad to see a blind eye turned to the non-money aspects.  There was no recognition of value being created on ethereum.  This was manifested in the lack of urgency or even appreciation that a more sophisticated scripting system like Simplicity would bring.  There was also a lack of urgency for covenants, which would bring more statefulness to Bitcoin.
I'm not sure what kind of evidence will show the value and potential of Bitcoin being more than money.
@_date: 2015-08-07 04:57:07
Don't forget generation 3 sidechains which will use zk-snarks, or something like that to replace both the trusted federation and the sidechain miners who can steal coins.
@_date: 2015-08-29 05:08:22
Now that Ethereum has finally launched, Aethereum should be right around the corner.
@_date: 2017-11-16 21:52:29
It was sad that we ran out of time for this interview.  I think we covered enough of the major highlights though.
@_date: 2017-04-22 21:40:55
Actually no.  The private key can be leaked in the bitcoin transaction itself.
Unless the wallet is following the RFC-6979 standard, it is impossible to tell if the wallet is leaking small amounts of the private key.  Even if the wallet does follow the standard, to verify that it is not actually leaking data, you would need to audit each signature, which means that your auditing code needs the private key, defeating the purpose of the hardware wallet in the first place.
Unless you trust the entire supply chain, there is an opportunity for an attacker to get private keys.
@_date: 2017-04-30 02:28:12
Here are 3 Bitcoiners who have passed away:
Autumn Radtke
Dave Kleiman, if you believe possibly fabricated documents.
Jacob Dienelt
His passing hasn't been talked about on reddit as far as I could find, but his loss is a great loss to the industry.
@_date: 2016-02-05 03:56:46
Why, yes it is.
@_date: 2017-04-16 03:57:06
see page 31 for more Bitcoin Elephants.
@_date: 2017-04-05 04:54:09
It seems like this is already happening:
@_date: 2017-04-09 00:00:07
For reference, these shirts came from the Texas Bitcoin Conference.
Thanks to u/paulsnow
@_date: 2016-02-16 04:28:18
possibly relevant.
TLDW, something like this for email was a huge failure.
@_date: 2017-04-01 04:54:40
I liked this show.  This was the episode where I [accepted]( my moniker.  
I was a bit surprised myself by Roger's statement while we were recording the episode.  His thinking is far too narrow.  Governments will eventually be competing with each other over control of Bitcoin network policy.  They will defend their interests, violently if necessary. This is where bitcoin is headed if we are successful.
The world is getting fed up with [legacy systems]( and large fractions of the world economies' backend systems will be secured directly or indirectly by Bitcoin [hashpower](  The hashpower is historically what has been touted as giving Bitcoin it's security, as a differentiator from other systems.  The hashpower is a lot of what the world wants.  Most industries will be touched by Bitcoin in one way or another.  It is way more than a payment system, as many on both sides of the argument seem to be limiting Bitcoin to.
With this context in mind, I am disappointed that some core devs seem [blind]( to the fact they are now politicians in one of the branches of Bitcoin governance.  By focusing inward, on technical matters while eschewing concerns of their constituents is poor politics.  The concerns may be baseless, and better solved through existing proposals, but this is a fight over governance, and the battle is being lost.
The miners must not be the ones to dictate which is the default client, as the branches of governance must be separate, otherwise powerful interest groups will weaken the basic tenets of Bitcoin.
At my weekly Bitcoin meetup a few days ago, the tension was palpable.  People are afraid.  This is in contrast to the preceding year, where it has been more of an academic discussion.  The questions and discussion revolved much more about what to expect in a contentious hard fork.  Core developers do not seem to be feeling this tension.
The [hashpower]( is one of the largest factors of what makes Bitcoin valuable.  A change of PoW will be a concession of defeat.  Ethereum's main perceived value is the brains behind the project.  That is why most of the community followed the Foundation down their fork.  The brains behind Bitcoin are most certainly valuable, but the Bitcoin hashpower is comparatively more valuable than the Ethereum hashpower.  The outcome of a contentious Bitcoin fork following the existing devs is not as certain as it was with Ethereum.
I really hope the Core developers realize they are now politicians, and start acting like it.  A compromise would go a long way to easing the tension, even if it makes no sense technically.
@_date: 2016-02-05 04:25:07
Who is Alan Reimer?  Is that etothieipi's poetic doppelganger?
You must mean the Armory founder: Alan Reiner. 
@_date: 2016-02-28 07:22:02
Maybe something like [tlsnotary]( would work for this.
The zero knowledge proof would take in a tls stream from browsing the shipper's website.  Their private key from the global PKI infrastructure which authenticated their website also happed to sign the delivery acknowledgement.  The zero knowledge proof would parse the signed webpage as an input.
Two parties would be able to rely on cryptographic proofs from the shipper, without the shipper doing any more than they do today.
@_date: 2016-02-29 06:07:58
bummer.  I don't suppose there is some way to downgrade the connection to use asymmetric instead of symmetric encryption.
@_date: 2016-09-17 01:37:04
We are trying to build a public publishing system which is censorship resistant.
We are trying to make our equivalent of the miners do less. Then we can have an environment where all the rules are implemented client side, as in on the actual wallet or application, whatever it may be.  Factom will not be used for money, after all, and we use cryptographic proofs to determine that what is happening follows the rules that we want to follow.
Factom is enabling users to be able to publish data in a certain order.
@_date: 2018-03-27 21:00:39
I too love that he is embracing this characteristic.  I had always imagined a cartoon dog talking when I heard his speeches, but Kermit also fits the voice.
@_date: 2018-03-12 09:33:01
Here is 's Apprentice Wizard's walkthrough: 
Here is 's  lecture on the new address scheme: 
Here is 's speech of the bulletproofs tech: 
clarified off-air that to aggregate the proofs, they need to be made interactively.  This means unrelated transactions can't get the combined speed benefits.
Here is the course mentioned that is taught by Benedikt's advisor:  
@_date: 2016-09-24 20:26:56
Factom leverages Bitcoin in two ways.
1. The Factom network leverages Bitcoin's non-reversibility to show that the ledger state has not been [tampered]( with.
2. The Factom network will show that a sibyl attack is not happening with the Bitcoin blockchain.  The Factom clients can verify that they are all seeing the same Factom blockchain by examining the Bitcoin anchor transactions.  We are leveraging the sibyl resistance of Bitcoin.
Factom is a scam as much as Bitcoin is a scam.  According to the Satoshi Nakamoto Institute, Bitcoin is indeed a huge [scam](
@_date: 2018-03-26 01:49:53
Thank you for posting this video.  It seems like it was based on a few flawed assumptions.
As far as the limits to batching, lightning channels are not anything close to transaction input batching, like coinbase is doing when paying multiple customers.  imagine this scenario.  in the not too distant future, after your lightning channels get depleted since you had bought too many things, you won't be closing those channels.  Instead you will go to an ATM, telling it your lightning node address, and feeding dollar bills into it.  The machine will route value to you over the network, and it would rebalance the channels that are connected to you, up to the channel value.  no on-chain transactions were needed.  
Also, if you are worried about a 51% attacker, then drivechain is not your answer.  While you and everyone around can see that all the sidechain funds are in the process of being stolen, nothing can be done about it, besides a UASF.  We all remember how well that went the last time.
@_date: 2018-03-25 21:14:16
here is one example.  
@_date: 2018-03-25 20:47:23
One of the things that concerns me is lightning uses the same hash preimage for the entire payment chain.  I remember either Joseph or Tadge mention one time that adding a basic elliptic curve operation to Script would allow for different preimages to be passed along the payment chain.  It might have been a half-thought-out idea or maybe I am misremembering, but I can't find it again.  Do you know of any solutions to using different preimages per hop?
p.s. here is some info for newcomers on MAST: 
@_date: 2018-03-14 21:53:07
The breaks are imposed by the radio station that the show is produced and syndicated through.  The breaks are based on the clock and are rarely made at convenient times.  The station structures breaks this way for on-air commercials.  This is the cost of doing a live show.  [This]( is what you would hear if you were listening live repeated every 15 minutes or so.  The show is shortened from the 2 hour runtime to what you hear.
@_date: 2016-09-17 07:00:55
Thank you Paul for putting this together.  It was a good Friday night watch.  I especially liked the 4th video.  It presented some ideas which I had not come across yet.
I think I see where you are going with Block Scheduling, but if there are any high fee non-lightning transactions that show up during the SPV mining phase, I think that would throw off the whole expectation of mining the subsequent block as headers-first safely.
I liked how you expanded on the prisoners dilemma, showing how extended interactions and side payment pushed the outcome towards being optimal.
I was postulating to someone notable at the Montreal conference last year that the Scaling Bitcoin conference was a negotiation of the cartel agreement.  Not many talk so positively about miners being a cartel.
It is a shame that only 100 people have watched this so far.  It is good stuff.  I scoffed initially at the 2.5 hour runtime, but it was worth it.
I appreciated the extra effort to remove the silences between thoughts.  That shows a lot of respect for your audience's time.  What software did you use to create this presentation?
@_date: 2016-09-15 01:15:24
I guess they will join the ranks of coinbase, blockchain, consensys, chain, decentral, 21, asicminer, ledger, and elliptic.
@_date: 2018-02-22 05:15:25
I'm impressed.
Why a 64 bit bulletproof?  You only need 51 bits to represent all the satoshis.  Are you planning on more inflation? ;) I thought Pieter fixed that in the BIP to answer the ultimate question of life, etc.
Are the general proofs you describe circuit based, like SNARKs?  I like the assumption on the DLP for general proofs.  This seems like a bigger deal than the range proofs.  Where would I find more about this?
I am intrigued by the Zero Knowledge Merkle proofs.  log(n) sized proofs seemed pretty good, but this would be an almost constant sized proof.  I can see where this would be useful in Bitcoin fraud proofs.  I suspect the Ethereum guys will like it too when even the EVM state itself gets too [monsterous]( to store.  
@_date: 2017-09-23 06:15:42
Alan did mention one time that he impressed himself by getting the polynomial math right the first time he implemented SSS when first coding the split backups.
@_date: 2018-02-23 06:28:40
Sadly, when I hear about Pedersen commitments I think of [this](  Not as bad as Schnorr though.
@_date: 2018-02-23 06:47:10
Thank you.  What is the OWF assumption that you list for STARKs?  
Do all the generators in the multiexponentiation need to be the same when they are batch verified?
@_date: 2018-03-14 21:29:50
Done, thanks.
@_date: 2017-10-26 12:38:08
no, that wasn't me.
@_date: 2017-10-31 04:47:28
The paper talks about Jets where various common functions like ECDSA operations are templated and accelerated.  Does this mean that all the elliptic curve multiplication steps, etc would be spelled out in the witness proof?  This would change the amount of blockchain space needed to verify a single OP_CHECKSIG from a single bytes to many many bytes of code in the blockchain.  The templating operation would make the signature verification far more efficient, but would still take up a lot more blockchain space than currently happens.
Am I misunderstanding how jets work?  Will they be instead more like EVM accelerated instructions and be granted relative costs by meta-consensus?
@_date: 2017-10-19 13:52:05
A Vegemite sandwich?
@_date: 2017-10-01 23:07:05
This isn't the first time NYA caused controversy in this industry.  The first time was back in 2014.
@_date: 2017-10-08 20:04:21
Ethereum Bitcoin used to be called æthereum, but no one could type it.
@_date: 2017-10-12 06:00:56


This is a huge assumption.  BCH totally revamped their signature scheme a week before launch.
BTC-NY has started and discarded two different versions of replay protection already.  Who knows, they may decide to do bilateral replay protection after all, invalidating presigned transactions.  CLTV deposited addresses would be safer, since they would survive changes in the signature scheme.


Why would I want my counterparty to have the option of backing out of the deal if the market dynamic changes between when we start and when it forks?
You might be able to have the first party, the one with knowledge of the HLTC secret post a large bond ahead of time.  This way even if it doesn't make sense to follow through with the swap, since the market moved against the secret holder, they would still be incentivized to reveal the HLTC secret before a clock runs out in order to get back their bond.  The bond must be more than they could lose by walking away from the swap.  time lock on the non-replay protected chain is way better protection than a mega-transaction.  Also, you would want to use segwit to protect yourself against 
2/3 multisig with a neutral arbiter seems like the best bet with so much in flux.  The goal should be to prevent the split in the first place, and everyone get their coins back.  These technical schemes are fragile when the protocol is changing around them, and the first blockchain won't know if the other one never comes into existence.
edit: I skipped over the part where you specified a mega-transaction as replay protection.  This would work unless they implemented bilateral replay protection.  limiting the globe to 144 swaps per day seems silly.


Spending the coins first on the BTC chain with replay protection.  Later a later timelocked transaction valid on both chains can be sent to the Segwit2x chain.  It can't be replayed because the BTC coins are already [moved](
I notice you don't sign the backout transaction before sending funds to the multisig.   I was going to complain about not using segwit, because malleability can goof up the pre-prepared refund transactions, but you don't have them.  if the counterparty disappears, or just doesn't fund their side of the deal, your funds are locked in a multisig with them, potentially locked forever.
There are many trust points in this transaction as it is described.  I would not feel comfortable with this procedure.
@_date: 2015-04-06 03:41:16
Yes, that could be one use case.  
Satoshi solved the proof-of-the negative problem, which in bitcoin is a doublespend.  to prove the negative, full nodes need to view all transactions ever.  Solving a doublespend problem would also be useful in factom.
One example of a non-crytocurrency doublespend would be property records.  I would like to know if the person selling me property has sold it to someone else before.  This is currently done at the county seat, but they can tamper with the records.  Proof that the old title is obsolete would be a good way of looking at it.
@_date: 2017-10-03 19:57:11
He did suggest some things I had left out in an earlier draft.  I was tempted to do some commentary on the various implementation options, but 1) wrong forum and 2) people who have dived deeper into wizardry would have better sense of the tradeoffs. 
@_date: 2015-04-06 04:35:31


Sure, if all they wanted was proof of existence.  Proving something didn't happen, while maintaining censorship resistance is hard.


not at all.  proving to others (or yourself later) that something hasn't changed doesn't really require a blockchain either if you trust your backups.  Sadly, if your backups are online, then hackers can get to those too.  Bitcoin's proof of work makes altering history (or backups) impractical.   


In Bitcoin, all data that is entered into the system is associated with a payment (BTC transaction).  Counterparty must couple a BTC transaction with every counterparty transaction.  Factom uses a separate accounting system to make sure data gets paid for, but clients who parse the chains don't need to be bothered with all the payment overhead.  They can just download the asset reallocation data, and not download the transactions used to pay for the entry.


It accepts ~10K of arbitrary data.  if your original fits in that much space, then it will fit in factom.  If it is not too much bigger, you can split it up over several entries.  If it is a PDF of JPG, etc, then yes, a reference to an outside system would be needed.


Suppose there is one palace where a community goes to find records.  If the party which filters out spam decides that *you* are spam (or otherwise undesirable), then they are censoring you.  
@_date: 2015-04-06 04:00:47
Factom records arbitrary data, not just hashes.  If you can describe a transfer in ~10 Kb of text then it can all go into one entry.  
Bigger things like maps can be stored on non-trustworthy databases.  The map hash plus a signature from the county registrar makes the map trustworthy and uneditable.  It can be floating around anywhere on the internet, and since it is just data, it will be easy to replicate.
As far as laws mandating things, all we can do is make a platform which makes altering history out of reach.  Getting a working platform is required first.
@_date: 2015-04-06 04:12:28


Yes, checking for a doublespend requires know all possible other spends.
 
The data entered into Factom does not need be a hash.  We are setting an upper limit of ~10K of arbitrary data per entry.  A lot of signatures and asset reassignment can happen with 10k.
If you want to put PDFs, JPGs, etc in Factom, then you would put a reference with how to find them.  It could be a reference to storJ, Maidsafe, or just a bittorrent infohash.




Hmm, If we wanted atomic swaps, they should probably go in the same chain.  There might be a pototocol to separate gold and silver while preserving atomic swaps, but I haven't thought hard about it.  


Excepting atomic swaps, you are right on.
@_date: 2015-09-07 16:05:27
ah, ok, i thought you wanted to forgo that rule to make it sorted.  
If we are hard forking, that rule can go, it just requires some extra memory when processing a block, which may open up attacks in and of itself.
If we keep the parent-must-appear-first rule, and add the sorting rule, wallets can mine for TXIDs by using a signature R value as a nonce.  the wallet can give the customer the expected result that way.
This would be saddening, because transactions until now are completely ignorant of blocks.
That opens up some interesting attacks too, where I can pay someone with a TXID i have mined to be very high.  In order for the recipient to spend it in the same block, they would need to Txmine more than the sender.  This would be combined with some other attacks to mitigate countermeasures.  One that comes to mind is Replace by Fee, and the scorched earth response by a merchant being charged back.  The merchant would not be able to make a fee only paying transaction since they would have to spend hours mining that transaction.
What features does your proposal lose if the sorting rule is not used, or if only the proof tree is sorted?
@_date: 2015-04-18 04:57:25


I think I understand sidechains.  The blockstream guys seemed to be pretty adamant about using merge-mined proofs for unlocking coins on the main chain for gen-2 sidechains.  Would a merge miner audit transactions mined into an ethereum contract?
If that is the case, then all they are doing is auditing a specific blockchain.  It seems like Factom could be superior, since the overhead is significantly lower to audit and use as a customer, since it was designed for scalability from the beginning.  It is made non-reversible by the same miners who are deciding to unlock coins.  Yes, it requires an interpreted coin (ie counterparty) rather than an audited one (ie, bitcoin, ethereum), but the auditors are auditing anyways, so no big deal.
Is this what you mean by implementing as a contract?
gen-3 sidechains with zk-SNARK proofs only need a blockchain who's consensus can be determined programatically.  Is that what you mean?
PS, I like where you are going with using voting as the gen-1 federated unlock.
@_date: 2015-04-06 06:14:39
correct.  The factoids provide a method to limit spam.
Adam Back's hashcash from way back when was a method to require a value sacrifice from people sending email.  A POW proof would be needed for everyone sending email.  One could imagine email spammers making an FPGA to send out way more email than someone with just a CPU based email client.
Instead of making end users burn electricity, we can enforce a sacrifice based on a market rate.  We now have cryptocurrency.  This allows a provable sacrifice without an individual sender personally burning electricity.
@_date: 2015-04-07 02:51:59
from the counterparty FAQ: 
"You can use a local copy of the blockchain just fine. The only difference between Counterparty and Bitcoin here is that Counterparty doesn’t support SPV" 
"a local copy of the blockchain" &amp; "doesn’t support SPV" = **all the data** in the blockchain is needed to validate.  
Factom allows interpreted protocols like this counterparty to ignore other's data.
the faq goes on to say "We’re working on solutions to this issue now. Protocols like VerSum offer excellent models for untrusted verification here."
The VERSUM paper: 
says "VERSUM is a new system for securely outsourcing computations"
I don't fully understand it, but the crux of it is that someone will show how they performed some computation.  You ask several distinct servers for their computation proofs, and compare amongst them.
The security properties of this may not be as strong as simply having all the relevant data and running the proof yourself.
@_date: 2015-04-23 19:43:01
How many others imagine what Hippo compliance would look like?  
Your data must wallow in the waterhole all day, and kills more people than lions.
@_date: 2015-04-06 04:49:30
Since Factom uses new crypto than Bitcoin, they cannot share private keys.  Koinify found a way for your BIP32 seed (12 words) to derive your factoid private key.  
With the master passphrase you can get to the factoid's private key.  I have published a script here to show how to get from the 12 words to the payment data.
We very much expect people to use coinbase to buy factoids.  They must send them to a Koinify wallet first, since it is the only wallet which also attaches the properly formatted op_return data that we need to credit your public key with factiods.
Bitcoins sent directly to the [35gLt_DoNotSendDirectlyHere_6p1MGf6]( address will not have the data needed to assign the tokens.  They will be a gift to the Factom project.
@_date: 2017-10-12 02:40:25
Thanks &gt; Poelstra has however also made the very intriguing point that it is not actually required for the two blockchains to be operating on the same elliptic curve group for the construction to work.
This is one of the reasons I am interested in Schnorr on Bitcoin.  It will allow these types of swaps with the Ed25519 signature scheme my blockchain uses.
@_date: 2015-04-06 05:48:57


Proving a positive indeed does not need to be decentralized.  Proving a negative does if you want censorship resistance.
Exhibit A: Counterparty.
If Patrick Byrne gets his way and all of wall street goes on the blockchain, then bitcoin may very well collapse under its weight.
Soon, one of two things will happen. The 1MB limit will be raised, or not. 
* Raised blocksize. In order to see if your Counterparty asset was doublespent, you will need to parse through many terabytes of Bitcoin transactions to find the few MiB of Counterparty transactions. You would also need to wade through all the other embedded protocols like Omni, ProofOfExistence.com, and all the others in your search for Counterparty transactions. Factom is setup so that interpreted protocols like Counterparty do not need to wade through all other protocol's data.
* Block limit stays. Each Bitcoin transaction becomes expensive. Each transaction might rise to $5, $10, $15, who knows. Distributions to asset holders would cost hundreds or thousands per dividend.
A censorship resistant scalable platform needs to exist in order for counterparty to scale to wall street sizes.
@_date: 2015-09-06 23:00:01






That's odd, how do you figure that?  It seems just as easy to insert a txid which spends btc in the same block as one that one that spends from earlier blocks.


What is the Bitcoin™ approved language for describing the process of proving btc has not been doublespent?
*edit ™
@_date: 2017-10-01 15:32:49
This time they are right though.  A cross chain HTLC between chains lacking replay protection results in a race condition.  
Only after the fork emerges, and coins are "split", will the trustless swaps you are referring to become possible.
The two sides of the bet could place coins in a 2/3 multisig, with a neutral arbiter as the 3rd party.  After the fork, they could work together to split the coins, or resolve in a different way if the fork doesn't happen.  This seems like the current thought line of There is likely a way to do it with the old school TierNolan style atomic swaps.  Those used to be unsafe, but now that segwit has solved malleability, they are now safe.  Combine this with the [opt-in replay protection]( and long enough timeouts on the [NYA]( chain transaction, and you have yourself a safe swap (assuming nothing else about the fork changes).
Note: This was not something that can be "Googled".  I have not heard this method described elsewhere.  It is particular to the circumstance of the BTC/NYA split.
You see, more than just this sub is afraid of cross chain replays.  
edit:  Apparently the final version of replay protection is still being debated.  
It seems like multisig is the best solution, knowing that the design of NYA is still so very much in flux.
@_date: 2017-10-01 17:08:58


Who gets the name Ethernet?  
While there are elements of centralized control, the brand does not seem to be one of them.
A few years back I was helping to bring an industrial ethernet SCADA product to market.  Part of the process was assigning a MAC &amp; OUI to each device.  Our parent company had already registered an OUI.  Getting a new OUI required a signed letter from the president of the company declaring that 95% of the address space was used.  This is about 16 million devices, which was unlikely to have been used by the parent.  No one in the parent company was able to determine which addresses had been used.  It would have been nice to have a global public database tracking which addresses had been used.  The ethernet address space is controlled in a hierarchal top down manner.  Luckily in the OUI case, accidentally doubling spending a MAC address is low risk.  The probability that the same MAC appears on the same LAN with unrelated hardware is very low, and if it does, the consequences are manageable.
The brand doesn't seem to have the same level of control.  These guys seem like a single-issue fork advocating for **moar gigabits per second**.    
There is zero mention of the IEEE in their [adopter agreement](  I didn't see anything in the agreement about reverse compatibility, which one would expect developing a new ethernet standard.
Who controls the ethernet brand if this were considered abuse?
@_date: 2016-10-16 01:50:29
I hope moves his coins before then.
@_date: 2016-10-16 19:20:27
@_date: 2015-04-07 02:05:11
A sidechain can represent two assets simultaneously.  This will allow atomic swaps within that particular sidechain.  This is way better than the current tier nolan atomic swaps, which take a day to unwind.
I didn't see this in the sidechains paper after looking for it again, though.
Here is one of the sidechains paper authors talking about how atomic swaps with other chains can work on a sidechain.
 
the hard part is getting a two way peg on bitcoin.  on a parallel chain, the difficulty will probably be lower to implement a two way peg.  The same proofs to go into and out of a sidechain will work for both Bitcoin and a separate value blockchain.
@_date: 2016-10-16 19:10:59
The Economist Magazine was making this same argument when they put Bitcoin on the cover [turning]( the world.  It secures the things in the follow up [article](
I proposed that providing an immutable publishing platform was the main driver for Bitcoin, detailed [here](
You cannot forget the price, because that is what is providing incentives for the miner.  My article proposes that BTC are an [app-coin]( to extract value from savers to fund mining.  If that is the case, then BTC should be optimized as a store of value.
@_date: 2016-10-27 04:39:01
Thank you for posting this.






This is what I have been saying for a while too, but not just about the financial industry.
Every relevant industry that I can think of has coordination and document management issues.  The world is a very broken place, and not just with money.
I initially got involved in Bitcoin because I was fed up with the 3 day ACH transfers, and felt that if the banks saw a little bit of competition then they would get their act together.  It seems like that is what's happening here.
Despite our belief that asset based digital money will supersede debt based money, that will take a long time.  Organizations will need to coordinate better for a long time to come, and I'm glad it is being led by the likes of Ian Grigg.
As I started to understand Bitcoin, it began to open my eyes to how dollars work. ([him too](
Gendal helped me understand with this article too:
  I highly recommend it.
hmm, I just saw this [too]( having just got a t-shirt with that moniker on it from the nice people in [NZ](  Does anyone know if he originated the meme?
@_date: 2015-09-06 03:40:30
In your proposal, you construct the Proof Tree using the block hash.  You have set up some circular logic with the hashes if you are spending outpoints created in the same block.  You cannot include a hash of the block you are in, without changing the block hash.  Its easy to fix, but it is a detail you left out.
I would also put the proof tree in the coinbase instead, making it a soft fork instead of a hard fork, at the cost of delivering the coinbase transaction with your proof.  You do have this as an alternate proposal, but as an output to the coinbase instead of an input.  doing that would maybe change more rules, like the 1 OP_RETURN rule.
You sort the transactions by TxID, but the coinbase must always be first.  you couldn't sort that one too.
If we are going to hard fork with the merkle tree, we might as well put a bunch more stuff in there too, like all the various UTXO set commitments, since there are several proposals, each with tradeoffs. 
**"a block is valid if it contains a valid proof that all the transactions in the block are valid"**
This gets into proving a positive vs proving a negative.  To prove a negative, you need to examine the entire domain where that thing can exist, i.e. scanning the entire blockchain.
You could probably take a shortcut by combining the proof tree with a UTXO commitment to get closer to proving that negative, but you are still trusting the miners who made the UTXO set commitments.  
I really like the idea of fraud proofs, and would have certainly helped out July 4.  Those are great for proving positives of stateless and some stateful frauds.
It seems dangerous to think that a single block can contain a lot of little proofs of the positive can prove a negative.  It doesn't seem possible, at least with what you described.  It will make it easier to construct a fraud proof, but it is certainly not "a valid proof that all the transaction in the block are valid"
I though you were going down the road of having a ZK-SNARK proof of the block validity.  With that, you could have a short proof in the block which would prove the negative without examining all previous blocks.  That is something I could get behind.
@_date: 2015-09-21 04:31:49
That thing is real?!  I though you were referencing this skit:
@_date: 2016-10-08 23:18:12
Bitcoin miners cannot steal main chain bitcoins without a hard fork (getting all clients to upgrade, like ethereum demonstrated).  The bitcoin protocol does not stop miners from taking all the bitcoins in a side chain, though.  It only relies on economic incentives to prevent the theft.  It is inherently less risky to store value on the main chain than a side chain.
It will not be life altering if someone steals my wallet from my pocket.  It would be life altering if someone steals all the dollars saved in a Certificate of Deposit.  This is why normal people do not carry around life changing amounts of money, and only enough for transactional purposes.
Also, bitcoin only loses anonymity when you interact with others.  If you don't interact and merely store value, it stays anonymous.
Sorry, I guess I misread your original question.  You are postulating that all the stored value would be transferred to the side chain.  I suppose people would by default run the sidechain software, and not run software validating the main chain.  This would have a similar trust model as sidechains have to bitcoin now.
If you are only validating one chain, and you are relying on the miners to validate the other chain, you are reduced to SPV security.  If the miners decide to break the rules of the other chain that you are not validating, they can steal coins from the other chain.  They could "soft fork" in a transaction that takes 0 btc in and outputs 1,000,000 btc.  The other chain would not know about this, since it just trust the miners blindly.
So to answer your question, if most of the economy were only running the sidechain client, then main chain bitcoins could be stolen by miners.
@_date: 2016-10-08 17:31:48
Main Chain is where large amounts of value would be stored, and p2p transactions would happen on the sidechain.
Similar to the difference between dollars in your wallet and dollars in a Certificate of Deposit.  They are fungible with effort, but one is easier/better to transact with however has a higher risk of being stolen.
@_date: 2015-03-09 17:49:01
indeed, Factom is that bigger boat.
@_date: 2015-11-25 06:19:00
hey, cool, I made the memories page.  I'm in some good company too.
@_date: 2016-10-16 01:44:52
Bitcoin uses ECDH?  It will when [BIP151]( activates, or [BIP47]( but I can't think of any places where it is used now.
Sorry, I'm being pedantic here.  I think you mean ECDSA.  Other than that this seems right.
If the OP wants an hour long lecture on QC and Bitcoin, I recommend this one.  Here is the part where Vitalic snaps his fingers and steals your bitcoins:
@_date: 2015-11-20 07:26:37
Are a particular set of signatures/witnesses committed to by the miners?  
I realize this is still early, but this is something we struggled with in our system, and want to know the blockstream guys's line of reasoning.
I am guessing the signatures would be in a block footer or something like that.  The question is if the signatures will be hashed into the Merkle tree somehow, or just be loosely coupled and malleable themselves.  Will there be a parallel Merkle root of the balance information in the coinbase input or in a coinbase OP_RETURN?
Committing to signatures is something I thought about a lot, and has been the topic of much discussion here in the office.  In our antispam token, we baked in essentially segregated witness at launch.  We do it by making two merkle trees, one with the full signed transaction, and one with only the balance information.  Our authority set commits to a particular set of signatures.  To me it seems like a matter of optimizing for the present or the future.
These were the tradeoffs we faced:
-Commiting to signatures means that we have attacks in the present.  If someone malleates a signature, or makes a doublespend (or multiple spends) with the same balance info, then the network has to have intelligence to mitigate that attack, and recover when the authority set decides on one signature.  This causes a little more complexity in the present.
-Not committing to signatures means we have attacks in the future.  If someone spends from a 1 of 2 multisig address, signing with key  it would be valid.  Later in the future a signature from key  would satisfy validity, and could be spread silently on the P2P network, giving different meaning to the transaction.  Future participants would be unable to detect the deception.  The argument is that future people shouldn't care how the value moved, only that it has a valid authorization.
Another aspect to the tradeoff is allowing for reduced validation for historical data.
Assume a node wants to trust the consensus mechanism for sufficiently old data, they can download the blocks with signatures, but can skip validating those signatures, just checking the tx hashes.
If the signatures are not committed to by consensus, malicious peers can supply invalid signatures to these nodes.  While these nodes do not care, they would be unable to later serve up these signatures, since they are invalid.  This hurts the network's ability to propagate blocks when fully validating nodes connect in a world of consensus trusters.
The consensus trusting class of node would be severely weakened by not having the authority commit to a particular signature.
@_date: 2015-11-20 23:18:06
Are witnesses/signatures going to be hashed into block headers? (many tradeoffs either way)
@_date: 2015-11-22 07:16:40
don't forget aethereum too.
@_date: 2016-10-16 19:16:36
Factom is using Bitcoin right now.
@_date: 2015-11-23 01:47:10
Dear god is the database slow.  it took me 4 weeks to download and index the mainnet chain last month in btcd.  my ssd did not help.  
I am happy, though, since bitcoin core doesn't have indexing at all, so still better.
Keep up the good work.
*I even used the latest bootstrap.dat file
**wow, it looks like core has added indexing since the last time I checked.  
***nope, sorry, just confused.  btcd is still the best way to locally search for transactions related to an address.
@_date: 2016-10-30 05:32:16
It's not [normal]( at all.  It's actually [exponential](
@_date: 2017-05-09 11:25:00
I don't really understand the controversy around the key.  There are a few potential histories:
1: the key was made as the paper purports.  While possible, this seems unlikely.  If the GPG community was anything like this one, then I believe things like defaults would have been argued about for the 8 months between the key date and the code merge.  This would explain the odd ordering.  Someone that plugged into the security field would want to be on the cutting edge.  This seems extreme though.
2: The key was backdated, but not by much (i.e. the key was created before June 2011).  This seems most likely.  Since the date on the key doesn't really matter, and it is trivial to change the PC's clock, it could be used as just another form of signaling, like the name and email address.  It is unlikely that the email address would get used again, but something needed to go in that field.  It was reported that CSW had a tendency to stretch the truth to the point of white lies.  This may be a manifestation of that.
As to the key not being on the keyserver, it was (and is) considered rude even to upload someone else's key to the server.  originally it was feared that the keyserver would be harvested for spam, but if no one you don't already know is expected to email you, then why publish the key?  Presumably everyone who needed to know the keys got their fingerprints through normal channels.
3: The key was backdated by a lot (made after June 2011).  This would be evidence that the Tulip Trust Redacted document was faked later on.  It seems like we can't tell if it is category 2 or 3 though.
To put this in perspective, I monkeyed around a bit with my own gpg key.  I followed some blog to allow the signing and decryption keys be detached from an offline long-term identity key.  GPG is such a disappointing mess, though, I have no idea if it even worked.  If a key is compromised, I probably wouldn't use the offline key to update the other keys, due to said mess.  When making the keys I had contemplated setting the system clock to an interesting date, since it didn't really matter much.  I ended up not changing it though.  
I also disregarded the defaults when making my RSA key.  I followed the lead of another crypto-geek and made a 4096 bit key, instead of the suggested 2048 bit.  The key size argument being unusual for the time is a weak argument in my mind.
Either way it went, the Tulip Trust Redacted document always seemed like flimsy evidence to me.  It had a lot of ancillary info, incomplete thoughts, and excessive narrative.  It doesn't seem like it is of the caliber to protect even the $100,000 of value it claims.  That might just have been his personality though...
There is a better question to ask though.  Perhaps it wasn't the CIA or Wikileaks that ended the Satoshi postings, but rather the Palm Beach County Sheriff's Office.
**Did the busting of David's chum precipitate dissolution of the Satoshi?**
The last BitcoinTalk post was Dec 12, 2010, a few days after David's good friend was [caught]( for something he was eventually fired for.
@_date: 2016-10-07 05:39:50
Are you liking the glide package management system?  Go get is severely limited, and we have been using bash scripts to compile various git branches and need to move on.  Glide has been mentioned.  How do you like it from a developer perspective?
@_date: 2015-11-24 03:55:44
Do these tests use the --addrindex flag?  I sync the chain and build cross references for searching.
I haven't profiled the code, but the CPU is only seems maxed out when a block is being checked.  Most of the delay looks like it is from reading/writing to the disk.
I am using a 2010 era laptop with a "Intel(R) Core(TM) i5 CPU       M 520  @ 2.40GHz"
cache size      : 3072 KB
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt aes lahf_lm ida arat dtherm tpr_shadow vnmi flexpriority ept vpid
Granted, it doesn't help that I am now using encrypted disk + btrfs, but it was about on this order a few months ago with an unencrypted ext4 partition.
@_date: 2016-10-05 20:32:59
Because they do different things.
- Tierion does timestamping.
- Factom does publishing.
In [this]( walkthrough of a problem set the difference between timestamping and publishing is elucidated.  A much more usable system can be built with publishing than with mere timestamping.
@_date: 2016-10-16 22:00:46
I think most people are missing the point.
Why is immutability good?  So that things cannot be backdated.  This is useful and important, but only one of many factors.
There are several different axes that are commonly associated with these higher layer protocols.
* Timestampsing vs Publishing
Bitcoiners celebrate how Bitcoin solved the doublespend problem.  This is a specific case of proving a negative, where the negative is that the BTC have not been spent before.  If Bitcoin were built on a system with only timestamping and no publishing, then doublespends would be trivial.  It is often not enough to just have immutability.  As others have pointed out, with timestamping it is trivial to switch to competing provider and get the same benefits.
* Centralized vs Decentralized
This one determines how easy it is to censor new things that need to be recorded.  Your bitcoins are not very useful if the miners are censoring your transactions.  History may be immutable, but it is the future you care about.  With mere timestamping, the service providers are [fungible]( so if one shuts down or censors, you can shift to a new one.  To prove the negative, you need to [examine all possible places]( where a transaction can be valid.  If free entry is allowed into the system, then spammers can trivially make the amount of data needed to sift through impractical.
* Storing vs Serving vs Securing
Many people conflate these, but they are not the same.  If I have a private agreement with a series of documents that need to be proved to others later, then I can publish a signed hash of the document into a blockchain.  When I need to prove the negative to a third party that no documents are missing, I can deliver the full documents offchain.  The 3rd party can examine the blockchain and assure themselves that I did not lose any documents.  If all I were doing is timestamping, I could just omit that merkle branch when handing off the document set.
In a land title example, if the local bureaucrat removes a page from the land title book, you as a citizen have little recourse.  The title book is the part that matters, and any documentation you have is indistinguishable from fraud.  With a blockchain based system, even if the bureaucrat deletes the original, if the landowner has a copy of the original document; its hash will match the signed hash in the blockchain.  This makes [digital records]( usable if held by individuals.
This is slightly analogous to the lightning network, storing offline transactions, and then only when there is a dispute publishing it to the Bitcoin blockchain.
Storing data is mostly a solved problem in today's world.  The main problem is finding the correct version of the data.  Serving data is slightly harder, but if someone has a motivation to share some data with others, they will pay for it to be served up.
Think of blockchains as glorified newspapers.  You do not store things in newspapers.  You put information in them such that a copy of the info is distributed to anyone who might be looking for it.
    |                                                                                      |
    |Timestamping -------------------------------------------------------------- Publishing|
    |                                                                                      |
      ^Tierion, OpenTimstamps                                                            ^Bitcoin, Factom
    
    
    |                                                                                      |
    |Centralized ------------------------------------------------------------ Decentralized|
    |                                                                                      |
      ^Tierion   ^OpenTimstamps, Factom(now)                          ^Factom(future)    ^Bitcoin
    
    
    |                                                                                      |
    |Securing ------------------------------------------------------------- Storing/Serving|
    |                                                                                      |
      ^Tierion, OpenTimstamps                     ^Factom                 ^Bitcoin
    
@_date: 2016-10-17 19:26:17
If you are careful, then you will see that the offline device is sending to a different address.
Without the offline device knowing the input balance, there is no way for you to counter this attack.  It may not be the most profitable of attacks, but if an attacker wants you to lose money, there would be no way to prevent it without checking the inputs.
@_date: 2015-11-20 06:20:00
This is really exciting.  Will Segregated Witnesses be presented at the hong kong conference, or is it too soon?  
Also, will confidential balances be one of the witness payloads, or is that too soon as well?
@_date: 2016-05-18 04:52:21
That camelcase spelling of Bitcoin hasn't been in vogue for many years.
@_date: 2015-03-30 21:43:07
Yes, for some strange reason I had in my head that the coinbase was part of the header rather than the inputs to the first transaction.  I guess they are the first thing right after the header, that might have something to do with my earlier confusion.  
@_date: 2015-03-16 22:07:08
Ethereum used an updated address scheme.  This made the usual process of using your bitcoin private key as the ether key unworkable.  They used the power of Bitcoin to specify the public ether key without using a trusted third party to keep track of addresses.  The ether pubkey was encoded directly into the payment.
Factom is learning from other projects too.  When Satoshi started Bitcoin, Edwards curves were still patented.  There are a lot more things that can be done better with these.  The Ripple project would be better with updated crypto, but they have an existing user base which cannot easily switch over, etc.
Since this project is starting from scratch, we can use the updated crypto to be better in the long term.  Since this also rules out the traditional method for us, we are following the Ethereum model.  The intermidiate wallet, which you hold the private keys to, will send a special transaction to the Factom Multisig address which has the Ed25519 pubkey encoded into it.
Ethereum was able to create a transparently generated genesis block based on Bitcoin payments.  We will too.
@_date: 2017-05-26 21:56:04
In the [words]( of Craig Wright: "[You used the Wayback!?!](
@_date: 2016-10-17 00:50:56
Bitcoin Armory wallet has been waiting for this since 2013.
It would have made offline signing device not need to have all the full previous transactions (potentially megabytes).  Otherwise, your offline wallet could be tricked into paying huge fees.
@_date: 2015-03-16 21:42:45
yes, Factom does not claim to store data, only to secure it.  We are not optimized to store data anywhere near the way StorJ is.
We are building a publishing platform, which will be a good way to find bulk data stored in StorJ.  
On top of that, it will be expensive to secure bulk data in Factom.  The system requires a value sacrifice to keep spam to a minimum.  It is in the spirit of Adam Back's HashCash, where a sacrifice would be needed to send email.  
we are currently targeting around $0.001 per KiB.  which would be $1048 / GiB.  
@_date: 2015-03-26 20:28:07
my guess is that the name is considered one word.
@_date: 2015-03-16 20:45:26
Yes, Ethereum did a really good job with their sale technically.  We are using many of the techniques they developed for their project.
@_date: 2015-03-30 21:38:04
To me
timestamping = proof of positive.
Proof of Publication = proof of negative.
If all you are doing is proving something has happend, then there are numerous ways to get a merkle root hash into the blockchain.  
A lot of people want proof of the negative (IE any cryptocurrency).  This is where Factom really shines.
@_date: 2017-05-30 20:21:13
Don't forget to get rid of the time warp attack!
Miners can soft fork themselves more coins today if they wanted.
@_date: 2015-03-20 21:42:35
I added more thoughts on the bitcoin-mailing list, and figured it couldn't hurt to cross post them here, since this thread has been removed from search results.
I like to think in audited vs interpreted protocols.  Think Bitcoin vs Counterparty.  Bitcoin won't let an invalid transaction into the system.  Counterparty filters out invalid transactions after the fact.
Proofchains are good for audited protocols where there is a predetermined auditor.  There is a gatekeeper who only adds in valid transactions.
Factom is good for interpreted protocols.  A user's software will filter out transactions which do not pass a ruleset that they agreed to.
Both are immutable and serve as proof of publication (POP).  Sure the POP in Factom is more complicated, but the publishing powers are shared.
On the bitcoin wizards [IRC]( phantomcircuit seems to have gotten close, the conversation resolved with Alice burning her house down.
There are applications where proofchains will work just fine.  If you are securing your own blockchian for your own data, proofchains will work.  You are not worried about censoring yourself.
If two rivalrous institutions are sharing a blockchain, then giving one of them exclusive power of making the blockchain is undesirable for the non-authoritative institution.  No need to discuss that arrangement anymore.
With threshold multisig, now multiple institutions would need to cooperate amongst each other to create a communal blockchain. In this example, a majority of keyholders can directly censor the minority. The minority might have recourse like in Szabo's property club blog post to fork the chain and start an alternate system, but if the minority is too small, then the network will not jump to the fairer fork.
OK, lets move authority to an industry group.  For something like property records, it is shown to work in a centralized model.  Making that model immutable with proofchains will certainly work.  Property records are highly gated as of now at the county seat.  Transitioning the county property database to a proofchains based POP will work. They are audited records, and the auditor is predetermined.  They already have censorship powers, and would in Factom too.  The only difference would be that in proofchains an invalid record would not exist, and in Factom, an invalid record would exist, but not be signed by the county.
As the individual players in a system become more numerous and less powerful, it becomes harder to have a disimpassioned industry group. This is similar to politics where we see dispersed costs and concentrated benefits.
Lets jump to the end and try to imagine how Counterparty would run on proofchains.  Who would be the one to package the transactions?  The counterpart devs can censor now, by updating the software to blacklist certain addresses.  They are already the predetermined auditor.  The Counterparty Foundation could package the transactions in a proofchain.  The difference to me lies in how easy it is to censor. It feels harder to censor by baking specific blacklists into the software than keeping a blacklisted party from ever publishing at all. One is very visible and the latter maybe not as much.  (Something like proofchains is how I initially imagined Mastercoin and Counterparty would work, since it seems silly to have every transaction be a BTC transaction too.  I underestimated their desire for censorship resistance.)
In the end it comes down to the data being published, and how/when it is audited.  Proofchains prefilters data and couples the auditor with the packager.  Factom allows the users to choose how they audit data independent of the packager.  How much power do you want to invest in one entity?  Factom allows splitting of those powers. 
@_date: 2017-05-12 04:39:45
It is the difference between timestamping and publishing.  
Timestamping proves that some data is at least as old as a point in time.
Publishing means you can find the data if you are looking for it.
here is some historical reference:  
For example with Peter's new project, no one, not even the IA themselves, can insert a webpage into their database and make it look like it was older than today.  They can, however delete it and pretend it never existed.  There is nothing in this cryptographic proof that will identify omissions.
By publishing in a blockchain instead, one can iterate the chain to find any omissions, as well as have the timestamping.  A good example of this is the Gutenberg library which we secured in the Factom blockchain a year and a half ago.  
Publishing goes a step farther too, as you can attach signatures to show authenticity.  For example, Paul Sztorc's Blockchainz book is masquerading in the Gutenberg library chain.  It doesn't have a valid signature though, so it can be rejected as a fake.
This is similar to the difference between full wallets and SPV wallets.  full node wallets know they are not being tricked by the hashpower because they can examine the entire blockchain.  SPV wallets are relying on the economic incentives of the miners not to fool them.  It is the difference between being protected against a doublespend or not.
@_date: 2015-10-10 00:37:44
Sunday nights at Brave new books still happens.  First Sunday of the month is better organized than the rest of the weekends.
Tuesday nights at the Factom offices happens every week too.
@_date: 2017-05-12 05:03:09
I too am impressed by his ability to iterate the entire IA, more so than the building of the hash tree and timestamping of it.
@_date: 2016-05-21 22:54:40
@_date: 2017-05-06 16:03:58
I have found that this graph gives a lot of perspective on the fee issue.
With Bitcoin as it currently stands, even ridiculously stingy 10 satoshi/byte transactions tend to go in over the weekend.  Eventually, though, even this widow will close off, just lile 0 fee transactions pretty much have.  10 satoshi/byte transactions will not typically get confirmed, but people will put them out there just in case a miner wants to consolidate their incoming payments.  
I have no doubt, though, that into the medium term future there will by cycles of demand like this.  The higher fees will be paid by people who are more time sensitive, while people who can wait on low traffic times will be able to pay lower fees.  The fees will separate transactions that need to confirm soon from those that can wait.
@_date: 2015-03-17 00:49:25


That is only part of the story.  Factom is attempting to make a publishing platform which is simultaneously censorship and spam resistant.  This is what makes Bitcoin magical, and what Factom is trying to accomplish.  Last Summer, I went down the road that you are going down and kept coming up with a system that was susceptible to either one or the other.  I gave the entities you described the glorious name **Compaction Service Providers** (CSP) and even wrote about it [here]( back when we were Notarychains.  With free entry of CSPs, censorship would be limited, but the entire system would get spammed quickly, and there would not be a good way to accurately locate the data you needed.  Without free entry, once a specific CSP (or proofchain packager) was selected by a network, the CSP could selectively censor within that network.  Lock in effects would be strong, so switching the entire network over to a new CSP would be expensive.
The CSPs (and Proofchain packagers) could "exclude, delay, or reorder the customer's timestamped entries".  This is fine as long as the CSP doesn't have an incentive to do these things.  
You claim that proofchains packagers will be the very business that issues a stock.  Since stockholders are trusting the company to return dividends in the first place, the trust can be expanded to managing all the stock trades too.  In my mind, the company who issues the stock still may game the system they control for their personal benefit.  What is needed is a scalable disimpassioned 3rd party.  Something of the scale where if the company president calls up and says "Delay these disfavored parties" that the packagers tell him his company isn't big enough to push them around.
I think **Factom sits in a sweet spot between** your proposed **centralized** solution **and** Bitcoin's anonymous membership authority set (**Proof of Work**).  The Federated servers must cooperate to move Factom forward, but like Bitcoin, require a majority to effectively censor a transaction.  It is a whole lot easier to censor with Proofchains.


Yes, to this point, Factom being forked is way worse than seizing up.  The Federated servers are constantly watching their peers and keeping them honest.  Since we have a defined majority instead of an anonymous membership set, if one Federated server goes rouge, the honest majority will all place the correct anchor.  You will see 1 anchor where someone is maybe trying to defraud you, and 31 anchors that have the correct data.  


I had considered merge mining, but your [arguments against it]( in reference to sidechains is compelling.  Without a majority of miners, then the system is vulnerable to consensus attack.  We gain the non-reversability by placing anchors in bitcoin without needing to recruit mining pools.
We could have gone to proof of stake, but then someone who funded it early on would have a disproportionate say in how the system was run.  Since we have the two step payment process, we can leverage that to determine who is actively participating in the system, and let them determine who sets policy.


We are making the system so that it is visible if someone is trying to do this, and the other members fight against it.


But what you are proposing is a single trusted third party.




I disagree.  Bitcoin is optimized for proving a negative over the domain of Bitcoin value transactions.  Lets take a closed system like Counterparty's current implementation.  To prove the negative (that an asset has not been sent to someone else first) you need to parse the entire Bitcoin blockchain looking for Counterparty transactions.  One of two things will happen soon.  The 1MB limit will be raised, or not.  
* Raised blocksize.  In order to see if your Counterparty asset was doublespent, you will need to parse through many terabytes of Bitcoin transactions to find the few MiB of Counterparty transactions.  You would also need to wade through all the other embedded protocols like Omni, ProofOfExistence.com, and all the others in your search for Counterparty transactions.  Factom is setup so that interpreted protocols like Counterparty do not need to wade through all other protocol's data.
* Block limit stays.  Each Bitcoin transaction becomes expensive.  Each transaction might rise to $5, $10, $15, who knows.  Distributions to asset holders would cost hundreds or thousands per dividend.  




You are making economic statements with technical arguments to back them up.  I think the economics and technicals are not as tightly bound as you imply.
Factom is trying to be a censorship and spam resistant disimpassioned 3rd party, like Bitcoin.
*update formatting
@_date: 2015-10-13 20:09:01
Tonight we have two special guests coming here from Stash Crypto, the relaunch of the exciting Open Transactions project. Chris Odom, the creator of OT, and Cliff Baltzley, founder of Hushmail will be in attendance.
Join us to hear about their new project to bring smart contracts, and financial privacy to the market.  
@_date: 2015-03-26 20:32:31
If you want more Satoshi history, I recommend "The book of Satoshi", written by my friend.
I learned a lot in that book which helped me understand Bitcoin more.
@_date: 2016-05-22 20:51:57
This event was fun.  I hope the photos get posted somewhere.
@_date: 2015-10-10 00:43:51
thursday nights at the chicon collective/liberty bar as well.  
Austin is the bitcoin capital of texas.
@_date: 2015-03-10 17:56:28
no fees for asset purchases?
Is there a way to take delivery of the hard asset?
@_date: 2015-11-20 17:57:02
Are witnesses/signatures going to be hashed into blocks or not?
@_date: 2017-07-11 18:42:11
Happy cake day!  
This was the same cover art that used on his [Book of Satoshi](  So incredibly circular.
The latest [cryptoshow]( we were talking about someone who had claimed to be Satoshi, who named himself after Pikachu's chum, unrelated to Bitcoin's ThePiachu, then ThePiachu using the cover photo from the Book of Satoshi.
@_date: 2015-03-09 17:55:19
Tether will leverage Factom, which leverages the bitcoin POW.  The ecash market is being covered by Monetas/open transactions. Different applications would require different levels of transparency.
@_date: 2015-02-13 19:01:11
I'm not really sure if we can claim the battle for merchant adoption is won.  Merchants are only really taking bank deposits quicker than credit cards currently provide.  From the customer's perspective, merchants take it, but in reality they don't.
When pay-to-contract protocols become popular, merchants will actually be taking bitcoin.  
This will allow trusted commerce to happen on an internet with questionable security.
Also, when we actually get escrow agents holding bitcoin in a 2 of 3 signature like we were promised years ago, then I will consider merchants as accepting bitcoin.  Openbazaar is planning on using these features where merchants take bitcoin and there is an escrow agent who can resolve disputes if the transaction doesn't go smoothly.
@_date: 2016-07-08 07:05:41
I think statoshi has this guy beat
@_date: 2016-07-18 21:22:10
It will help an eth smart contract to move bitcoins, along with a future distributed exchange.  A contract will basically offer to send $X+$N eth to an ether address if $X BTC show up in a specific bitcoin address.  The ether address would be controlled by the person who is sending the bitcoins.  The person sending the BTC would then show the smart contract the BTC movements using BTCRelay, and they would automatically receive $X+$N eth.
This is how an ethereum smart contract will be able to pay someone BTC, since they are unable to hold Bitcoin private keys.
@_date: 2016-05-18 04:49:07
This is his latest project: 
Jason has always been open about his treacherous past, about being homeless himself, and worse.  
@_date: 2016-07-15 04:00:06
Felix is a cool guy.  I met him at our meetup here in Austin.  
I'm glad you got home safe and had so much fun.
@_date: 2016-07-13 22:46:17
Of all the people in this space to trust with BTC, Rassah would be high on my list.
 
@_date: 2017-06-24 01:20:42
This was a good resource for understanding what asicboost is at a technical level. 
I would love to get the OPs opinion on the idea that asicboost enforcement would push mining underground to hide from the patent holders.  That would also make it harder for governments to locate miners and exert control.  More [here](