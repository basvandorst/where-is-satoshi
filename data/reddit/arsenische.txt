@_author: arsenische
@_date: 2016-08-30 19:01:41
Yes, we had downtime: 
Sorry for the inconvenience.
@_date: 2016-08-14 11:15:28
Full nodes are run out of the necessity to reliably receive bitcoins without a need for a third party. You can purchase a PC and an internet channel and run your node for cheap.
Come on, you can rent a hardware server 10 times cheaper at Hetzner: 
It is not that expensive for businesses neither for computer geeks.
@_date: 2016-08-14 11:39:32
There is always a range, but for $20-30 you can easily find a server that would probably be able to handle up to 20Mb blocks (that probably won't be a typical blocksize for years).
I agree that there is plenty of space in the middle. Even increasing the block size to 4Mb would boost bitcoin adoption while maintaining acceptable cost of running the full node. 4 times cheaper transactions / 4 times more space for transactions would make Bitcoin much more valuable and accessible for users. It will likely increase the decentralization because more users would attract more businesses running a full node.
@_date: 2016-08-04 07:27:58
@_date: 2016-08-13 10:23:23
I agree, once we hit the technical limits, on-chain won't be scaling as fast as we'd like to. But the block size can be increased without a problem right now while preserving simplicity and reliability of the whole system.
It is unrealistic to expect everybody to run a fully-validation node anyway since light/SPV wallets are more efficient for the end users.
It is perfectly fine to drop out volunteers (that run bitcoin nodes out of a pure enthusiasm) to attract a swarm of new users and businesses into the ecosystem.
Bitcoin fully-validating nodes shouldn't be designed for shitty computers with shitty channels, it should be designed for enterprise servers. There are more than enough businesses in the world that will always be able to afford a fully validating node thus preserving sufficient de-centralization.
@_date: 2016-08-13 21:21:57
Why do you want to run the full node yourself? It will take your resources anyway. How much are you ready to pay for it?
Bitcoin is a P2P network, but SPV wallets are the fine for most individuals.
Businesses and IT geeks always have money to buy a multi-core computer with 32GB RAM and 100Mbit channel. Isn't it better to utilize this hardware instead of targeting low-end computers and limiting the capabilities of the network?
Most of the end users will use SPV wallets from their mobile devices anyway. And more normal users we have - more incentive there is for businesses to run their own fully validating bitcoin nodes.
Otherwise high transaction fees may force users to use fiat or altcoins instead thus preventing Bitcoin from ever reaching the mainstream.
@_date: 2016-08-13 21:30:29
If you don't want to depend on the third party, you run your bitcoin node yourself. I think it is a good enough incentive to run a node.
@_date: 2016-04-04 05:48:54
If the source of the additional transaction pressure comes not from blockchain.info - that doesn't mean it comes from the spam bots. There is a great variance of the amount of the blockchain.info's wallet transaction volume:
So the spikes you highlighted could be just noise.
It is hard to know how representative is this data. But it pretty clear that it would be much more expensive to spam the network with the higher blocksize limit.
@_date: 2016-08-14 09:45:29
Patience is a virtue, but the market won't wait, it will move towards the system that has the right balance between utility de-centralization.
There is no much sense in running a node if transactions become too expensive or too few people use the block chain.
Since you you are using SPV wallet yourself, you admit that it doesn't break the P2P system.
But you didn't answer my question regarding the number. It always costs money to run anything. What do you think is an acceptable cost of running a full node?
We are not talking about clusters yet. Just a normal multi-core PC with 32Gb of RAM and 100Mb channel is all you need for significantly bigger blocks (drastically lower fees and wider adoption). Can you afford that?
@_date: 2016-04-12 10:12:55
The cost of running the Bitcoin network moves from holders to users. This should happen eventually, but it discourages the use of the network. I'd prefer to postpone this in order to increase Bitcoin's chances to reach the mainstream.
@_date: 2016-04-12 10:07:40
Look for higher bitcoin price as a miner.
Hint: limited capacity with high fee per transaction may reduce the utility of the Bitcoin network and drive the price down.
@_date: 2018-01-06 00:34:08


As I told you about 5 months ago, "it may easily turn into $10 or $100.". 
So how do you like the fees now?
Thank the No2X crowd.
@_date: 2018-01-06 12:44:28
Thanks for your response.
In my opinion Segwit2X would be good for decentralization (more people using Bitcoin, more businesses running full nodes, more parties participating in the protocol development).
Meanwhile I am forced to use off-chain payments via third-party services and to spend resources on adding support for altcoins deposits/withdrawals to my bitcoin business.
I am really forced to, because my customers and partners won't wait 7 months to see the result of this experiment. And I am sure I am not the only one.
Bitcoin is loosing its first mover advantage and network effects. Let's see what happens in 7 months. I hope Bitcoin will become useful again because a useless coin won't be decentralized.
@_date: 2019-07-09 13:07:34
Because the amount of bitcoins in circulation grows over time, see [
@_date: 2017-12-16 15:28:15
Well, not all the people are happy when their names or the names of their projects get abbreviated.
I think if your opponents don't recognize your right to be called by your name and start demonstratively calling you by a word composed of the first letter of your name and your last name, you would be insulted too.
The branding is important and I think no single team should have a monopoly on the word "Bitcoin".
Since there are competing forks of Bitcoin, they can be distinguished by adding new words to it ("Bitcoin Cash", "Bitcoin Gold", etc). The majority chain can be called just "Bitcoin".
The neutral way of shortening "Bitcoin Cash" is just "BCH", it is even shorter ;)
Hope it answers your question.
@_date: 2017-12-20 16:25:30
well said
@_date: 2017-12-15 13:32:11
Bcash is an insult because it is a name given to the Bitcoin Cash project by its opponents who dominate in this sub.
Bitcoin Cash is a minority chain which forked off from Bitcoin in August 2017 to implement the on-chain scaling plan and keep transaction fees low as long as possible.
If you had Bitcoins on your own wallet at the time of the fork, you probably have the same amount of Bitcoin Cash as well.
@_date: 2015-12-07 22:33:28


There is no way to reliably verify the node voting. Bitcoin holders can use bitcoin signatures to vote with their money, see 
@_date: 2015-12-31 09:11:57
Chinese miners are better connected to each other than to the rest of the world. And since they control the majority of the hashing power, increasing the block size could give them advantage. Though there are ways to optimize block propagation algorithms to minimize this problem.
@_date: 2015-12-14 09:58:03
The hardware is bought not by transactions but by bitcoin holders since the main source of miners' income is the block reward, that comes from the value shared by holders via their share dilution.
Transaction fees will become the major source of income many years later. When blocks include millions of low-fee transactions and block reward becomes negligible. No need to impose high fees on users now.
@_date: 2015-12-22 05:17:05
Freezing the block size limit is a change. 1Mb was never meant to be forever, it was set up as a temporary anti-spam measure. And currently almost everybody agrees that 2Mb is safe enough, but still the core devs don't plan to do it ASAP.
Bitcoin holders are in favour of [0-confs]( and [large blocks](
You could call them unqualified, but:
a) it is their money they risk
b) neither Gavin Andresen, nor Mike Hearn are stupid yet both support same things.
Despite this, core devs go against the whole bitcoin ecosystem by imposing censorship (why are the comments sorted by controversy here?) and pushing their vision.
@_date: 2015-12-08 03:41:33
Nothing. Moreover it is a legit use case (e. g. you signed the message, then you moved the BTC from that address since you changed your mind, then you can change your mind again, etc).
Bitcoinocracy [fetches signer's balances time to time]( and updates the arguments' validity accordingly.
@_date: 2015-12-17 09:40:11
The only real risk I see right now is that mining centralization undermines the value of Bitcoin since [it depends critically on censorship resistance, monetary sovereignty, and the personal control made possible by decentralisation]( Some believe that even 1Mb is too much already and large blocks are breaking Bitcoin.
But [the status quo is risky]( too.
@_date: 2015-12-14 01:01:23
There is no controversy here. You can't use it without holding it for at least a few moments. Longer you hold it - higher the price. Higher the [velocity of money]( - lower the price of the currency.
By acquiring and holding it you give it a value. If everybody is tried to get rid of it as of a hot potato then it would cost much less than it is now.
Update: you can play with velocity here: 
@_date: 2015-12-19 00:06:39
So long to wait... Hopefully they'll do it before halving.
@_date: 2015-12-14 18:25:37
Nobody is saying about handling them today. That's the long term plan, it may take a few dozens of years of technological advances.
If the adoption curve appears to be steeper than the technological curve then Lightning and other solutions on top of Bitcoin will help to overcome this obstacle (it may take a few months or years for them to appear).
As for today - Gavin [says]( we can handle 20Mb blocks right now, whereas Luke-Jr  says 1Mb is already too much and 300Kb is about right.
It is hard to reach consensus when highly proficient bitcoin experts have such a different views on the topic.
@_date: 2015-12-22 10:02:12
No proof provided so far that we are close to technological limit.
@_date: 2015-12-14 09:47:30


Wow, thanks for mentioning it. Where can I learn more about this incident? When did it happen? Was it that dangerous? How low did the bitcoin price drop?


In April 2011 MAX_BLOCK_SIZE 1000000 was already in place, see: 
Are you intentionally misinforming me or am I misunderstanding something?


Yes, there were "stress tests" on the network and you can [notice these spikes on the charts] ( But I don't see the reason to disregard the long-term statistics. If you claim that a about a half of transactions is spam then you should provide convincing evidence of such a claim rather than a conspiracy theory.


Miners are the strongest bitcoin proponents. Their main source of income is the predetermined block reward that may cost nothing if they don't do their job properly.
People complained when the biggest mining pools got about a half of the hashing power - they lost it. Peter Todd convinced them to introduce full RBF - they did. Others complained - they replaced it with FSS RBF. Miners align themselves with the needs of people they serve. And perhaps they learned their lesson from the mentioned incident.
@_date: 2015-12-14 06:26:09
Gavin Andersen a year ago published research that showed that 20Mb blocks would be fine. 
Bitcoin successfully lived with 1Mb block size limit for years, it is more optimized now and the communication channels became much better, so increasing it wouldn't harm. Or am I wrong?
Could you please provide a link to any research that shows that 1Mb is the right and necessary limit?
@_date: 2015-12-10 02:32:02
AFAIK there is no risk if you publish just 1 bitcoin signature per address.
But if you create many signatures with the same address then there is some risk of exposing your private key.
Sorry, I am not a math/cryptography guru and I don't know how to quantify that risk.
If I understand it correctly, it is negligible unless you use a faulty random number generator.
This article gives some hints: 
@_date: 2015-12-11 19:37:06
Why do you think it is a spam transaction? It looks like it reduces the number of UTXOs and thus is useful for the health of the Bitcoin network.
@_date: 2015-12-22 06:00:26


Is there any proof that the majority of transactions are spam? (it would be a relief for me).


There are a lot of BIPs to increase the block chain. Are their authors all uninformed? The scaling roadmap suggested by Gregory Maxwell implies increasing the capacity with Segwit, so I assume most people really think it is not a problem to double it.
If you pay attention to alternative bitcoin-related subreddit called "btc" (forbidden to be mentioned here), you'd notice that ~15% of bitcoin enthusiasts do already use it. That's the active minority, it is reasonable to asume, that it is the people who tolerate censorship at are mostly uninformed.
Update: voting at bitcoinocracy is noise-resistant since is backed by bitcoins; if you claim that the voted statement is invalid - just find somebody to leave a signature to prove your point.
@_date: 2015-12-14 06:36:00
Research showed that 20Mb blocks would give a temporary ~0.3% advantage to the big Chineese miners that doesn't sound too afwul but greatly increases the adoption potential for Bitcoin. Current BIP 101 proposal of 8Mb is already a compromise. And I believe its apologists would agree to 4Mb as well, especially after the segwit got published.


Quite the opposite: to increase the block size limit you need to make a hard fork, but to decrease it - just a soft fork. If it becomes obvious that Bitcoin is at danger, that would be an uncontroversial soft fork. Otherwise there is no reason to decrease it.
@_date: 2015-12-13 19:40:00
On the established market it is more or less clear what fee is needed to get the transaction confirmed quickly.
If you want to save on fees then you are risking that your money get stuck. That's the risk you are aware of. It is not a big problem nor for you, neither for the merchant who sees the transaction fee and evaluates the risks.
Perhaps there should be an expiration time for a transaction (so that if it could be removed from the mempool if it got stuck for a few days).
Right now you can accept the low value 0-conf transactions if they are broadcasted to many nodes and no double spends detected. This feature (that got a lot of traction from the market) will be broken.
The utility for the average Joe (who can to buy things immediately) and for the merchants (who need to accept immediate  low-value transactions) will be reduced.
Average Joe doesn't create transactions manually. Default fees calculated by his wallet should be enough to get confirmed in a few blocks (or in a few hours if he is unlucky). He might not even notice them while they are small, but he will surely notice a 10-minute delay and probably prefer another payment methods instead of Bitcoin.
RBF + low block size limit = expensive transactions, no 0-conf transactions, more people turn away from Bitcoin before it even reached mainstream. Yes, it somewhat decreases the centralization pressure on the miners (though it doesn't really matter if Bitcoin looses the competition with other payment systems).
FSS + high block size limit = cheap transactions, 0-conf transactions for small value, increased adoption of Bitcoin. It adds to centralization pressure, but not too much ([like ~0.3% for 20Mb blocks!]( And this pressure will be solved with technology advances and bitcoin optimizations.
@_date: 2015-12-17 20:18:15
The fee subsidy for 25 btc per block is there for a reason!
@_date: 2015-12-20 21:08:54


Same is true for 100Kb blocks and for 20Mb blocks. Is there any proof that 1Mb block size limit is the right value?


Any proof of that claim?
I see the opposite: amount of bitcoin transactions doubled during a year and is hitting the block size limit. It confirms that we need larger blocks.
If TOR devs artificially constrained the bandwidth to some arbitrary constant that seemed safe ~10 years ago, a competing technology/p2p network would have emerged and gained traction instead. Is it what you want for Bitcoin?
@_date: 2015-12-22 12:18:18
Regarding First-seen-safe RBF I think the following paragraph is not accurate:


AFAIK F2pool is using it, so it is implemented. See 
Also, any RBF violates your privacy since when you replace a transaction, its new version gets broadcasted and the observer can compare your outputs.
@_date: 2015-12-19 06:45:48
What's the mechanism of that influence? I can see that [some capital (over 10M USD in bitcoins) is in favour of BIP101]( but I don't see how it influences. The closest we got is BIP202 - 2Mb + slow linear growth of 1Mb/year.
@_date: 2015-12-18 21:35:42
Well... If you think it will be that bad, then you better sell bitcoins and buy weapons and the canned food. They will cost much more than any digital asset.
@_date: 2015-12-14 03:29:06
If you disregard that amount of transaction grows exponentially until it reaches saturation due to the block size limit then that is true, RBF could make it cheaper in the short term at the cost of killing the 0-confs (that insecure but are currently usable) and removing the 'low priority' transactions. I don't think it worths it since there is a simpler solution that was expected from the very begining: when we are close to the block size limit, it should be increased (unless we hit the technological limits). And also it reduces the utility of Bitcoin
As for developers' plans, I made a citation and a [link to the source]( to support my claim. 
If you provide a citation with a link to their promise to increase the block size to any specific size within any specific timeframe, I would be be grateful.
So far I saw only one ready and tested solution that could safely fulfull its promise. But I would probably support other solutions too if they appear soon. Will they?
@_date: 2015-12-13 22:02:18
do you see my comments? it appears I got banned.
edit1: not banned, but I don't see my other comment unless I am signed in (this one:  . why?
edit2: the edit1 to this post took some time to appear. is the premoderation taking place here, or just caching issues?
edit5: or is it because I mentioned some other subreddits?
edit6: ok, got it. don't mention other subreddits here or your comments won't be visible.
@_date: 2015-12-13 11:35:52
There is no RBF right now. Do we currently trust every single node of the network?
@_date: 2015-12-18 19:31:35
What's wrong with going parabolic?
@_date: 2015-12-21 00:31:50
Resources are limited - true. But the bandwidth, storage, memory and CPU power grow exponentially! The block size limit should too.
Block space is expensive - true. But bitcoin holders agree to pay the price. They pay it by holding bitcoins and giving value to bitcoin. That's why miners get their block rewards. Bitcoin holders subsidize transaction fees that are currently the main source of miners' earnings. Transaction fees at this stage should not be thought as a business model for miners, but should be thought as an anti-spam measure. Mining is paid by holders!
And let it be so until the natural exponential growth of capacity and amount of transactions doesn't reach saturation.
By that time block reward will be 0, blocks will be large (but still cheap to store, transfer and process due to the technological progress) and fees per transaction will be low because there will be many hundreds of thousands or millions of transactions in each block.
Bitcoin is for everybody.
And Coinbase is just a trusted third party (that Bitcoin was supposed to make obsolete).
@_date: 2015-12-11 23:05:37
There could be many reasons to create such transactions, e. g. here are the couple of use cases:
1. Imagine somebody has an old wallet with many change addresses that have fractions of BTC and wants to pay for some service OR to defragment his/her wallet OR to move the funds to another wallet.
2. Imagine some company, e. g. a gambling service that has a lot of players that deposit tiny amounts to their accounts. Time to time that company needs to move these money in order to pay the winner (or to pay its other costs).
The fee is low because the sender is interested to minimize expenses. If there is no hurry then it is OK to have the minimal fees.
Transactions that have many inputs and just 1 or 2 outputs are good for bitcoin since they reduce amount of unprunable UTXOs that are stored at every bitcoin node.
But even if this transaction was the opposite (1 input, many outputs), it could be a legit transaction too. E. g. a company paying dividends to its shareholders.
You never can be 100% sure which transaction is spam and which is not. But I don't see anything wrong with the transaction you gave a link to. It looks like a good bitcoin transaction.
@_date: 2015-12-14 01:59:48
Merchants that accept them need to do some work on their side to handle this flag. That is not 'opt-in', that is 'opt-out' for them.
Moreover bitcoin wallets have to implement the indication of this flag. It is 'opt-out' for them too.
Moreover miners will have incentive to wait until the same low-fee transaction gets doublespent with a higher fee.
And this flag can't force miners to use FSS. Once 0-conf transactions become useless due to this "opt-in" RBF, they will just quietly switch to full RBF and nobody will oppose them because all the bad things would have happened by that time.
@_date: 2015-12-17 09:29:58
Hard fork is not that a big problem if it requires supermajority of mining power (the proposed solutions require it).
If supermajority is reached then the remaining miners will have a strong incentive to join it and bitcoin users will receive alerts to upgrade their software. There will be some 'grace period' for them to do it before the fork happens.
There will be no BitcoinA and BitcoinB for any significant amount of time.
Hard forks happened before. The 1Mb limit wasn't there at the very beginning.
The uncharted territory is not the raise of the block size limit (as I said, it happened before without a problem), but a "Fee event" ([that is what going to happen if we don't increase the block size limit soon]( We are heading towards FE and it could be catastrophic for Bitcoin adoption. I hope the block size will be increased soon.
@_date: 2015-12-13 16:15:19
So it is a political, not a technical solution.
Thanks for your arguments, by the way. They shifted my opinion on RBF a little bit. Since FSS is not enforceable by the protocol, I see the conflict between miners' incentives and the popular use case utilized by many merhants (including BitPay).
However I still think it is a huge mistake to adopt full RBF right now. It looks like most miners are OK with running the default core and using FSS, so why to incline them to reduce the utility of Bitcoin before it became the mainstream? The only big pool that is known to use RBF is the F2Pool (and it uses not a full RBF, but FSS RBF for a reason).
@_date: 2015-12-10 02:09:41
Think of it as a shareholder voting. Isn't it fair?
@_date: 2015-12-22 12:34:59
Though if you add inputs and outputs, it might be not obvious whether you are just bumping your old transaction, or also are merging your old transaction with your new (yet unbroadcasted) transaction.
And it could be a good idea to bump by merging (so that observers couldn't reliably deduce which of the outputs are for change if any).
E. g. if Alice pays to Bob, her transaction [Alice -&gt; (Bob, Change)] gets stuck, she can replace that transaction with a payment to Bob and Tom [Alice -&gt; (Bob, Change, Tom, Change)] with a higher fee.
And that would be pretty First-Seen-Safe RBF. Though, yes, more inputs would be linked to each other. But at least they are spent already and nobody will know how much you have left!
@_date: 2015-12-10 02:18:45


If your bitcoin address holds funds then it is already exposed. No personal data is needed for signing the argument.


You can sign it offline if you want.


Then funds belong to the 3rd party (you don't own them, you just own IOUs from that party or some other contracts).
@_date: 2015-12-18 21:50:06
So you think there will be a crisis that is more severe than the Great Depression, will peacefully last for centuries and people will still lurk online and use Bitcoin for payments?
@_date: 2015-12-28 04:07:49
Agreed. FSS RBF could be a compromise.
@_date: 2015-12-18 19:06:07
The block reward is a fee subsidy. True, it will eventually be 0 (and hopefully we'll have orders of magnitude larger blocks by that time).  While there is a block reward, there is no need to rely on fees as a way to compensate miners. Fees are currently just anti-spam measure and should be kept minimal to increase adoption of Bitcoin. The market is far from being saturated yet.
Fees are currently ~0.2 btc per block. If blocks include 10 times more transactions preserving the current level of fees then the sum of fees will be greater than the block reward soon.
But the 1 Mb block size limit is kept then the fees will rise and constrain the adoption of Bitcoin. 
@_date: 2015-12-14 01:25:08
Did I mention the $5 fee somewhere? Where did you get this number from? $5 fee is surely too much if you want to pay $3 for hosting. In many countries the meal costs just $1 (sorry, not everybody lives in America).
Anyway, here we see the artificially created scarcity of the block space imposed by the core devs. It is against the nature of Bitcoin that seemed to be the people's currency. It may raise the fees unpredictably and slow down the adoption rate of Bitcoin. 1Mb blocks were set as a temporary measure in 2010. It was supposed to grow as technology advances.
20Mb blocks were tested about a year ago. Now it is almost 2016 and no official plan for the block size increase was announced. But there is a plan to fit all the "important" transactions of this global payment network into 1Mb blocks at a fee with RBF.
We are hitting the limit, and the core devs think it is not an urgent problem. How do you suggest to freeze the block size limit, increase the adoption and prevent the rise of the fees at the same time?
@_date: 2015-12-22 00:59:46
If everybody agrees that the capacity can be safely doubled then why not to make it ASAP with a simple hardfork?
Segwit is a more complex solution that requires months of work and a soft fork anyway. If there will be consensus by that time that Segwit + 2Mb block size is dangerous then the same soft fork could be used to decrease it to the appropriate number.
@_date: 2015-12-03 15:00:43
Perhaps there is a hope that they will change their opinion.
[BIP 101 is the implemented and tested solution that gives Bitcoin a chance to scale with respect to the long term technological trends (and can be fixed without a new hard fork if they discontinue).](
@_date: 2015-12-21 02:03:43
Everybody agrees that decentralization is vital for Bitcoin.
But there is no reason to believe that the long term technological trends stop immediately. There will be plenty of time to adjust if it happens (and the soft fork can be rolled out really fast in case of emergency).
There is already sufficient progress in both the technology and the bitcoin code optimization since 2010 when the 1Mb anti-spam limit was introduced. If that limit was good enough back then then it is pretty safe to increase it now. Refusing to raise this limit  before we hit it while technology allows it is irresponsible. Have you read regarding the [Fee event](


If you earned $300 per year you wouldn't say that.
@_date: 2015-12-13 11:28:15
[You are not the only one]( whom they ignore.
This problem is related to the lower block size limit. Just increase it and there will be no need for RBF!
@_date: 2015-12-12 09:17:53
I don't know whether the incoming transactions are spam or not. Maybe they are colored coins, coin mixing transactions or payouts from online services. I don't know, didn't spend much time to investigate it. But the transaction itself looks fine (consolidation transactions are good). 
@_date: 2015-12-14 06:22:03
Bitcoin is not a startup by a team of developers.
It is the autonomous decentralized organization that belongs to all the bitcoiners. Bitcoin holders funds miners with value that comes from their holding, they are the shareholders and should have their voice. Satoshis are the shares of Bitcoin.
Of course nobody is obliged to listen to bitcoin holders, but nobody is forced to keep their value in Bitcoin either, nor to run the reference bitcoin node. So it is wise to listen what bitcoin holders want unless you are short on bitcoin.
@_date: 2015-12-14 10:01:48
Wow, there is something to read and think about.  Thanks for your time and the links!
@_date: 2015-12-14 03:02:42


No, they work fine, just get delayed. That's the predictable behaviour, you wallet probably sets the adequate fees already. When you manually set the lower-than-normal fee, you accept the risks of your transaction being delayed. No need to fix that, it is not broken.


Many trade with a pure bitcoin node or bitcoin client.


True. But they don't. They don't want to harm the network since they are mainly paid by bitcoin holders (transaction fees are not that important yet), see how F2Pool rejected full RBF in the original post. It will probably be fine to run FSS RBF in future (when we have both large blocks and lightning), but not full RBF today.


No, they just wanted to calm down the public. Satoshi raise the limit to 1Mb in 2010 when the code was much less optimized than it is now and the bandwidth/memory/cpu power were much more expensive.
Gavin tested 20Mb blocks a year ago. We could increase the block size limit at least 10-fold immediately without a problem. There is an implemented and tested solution that would work just fine.
If the core devs agreed to this solution (even starting from a 4Mb in January with future segwit development) it would be fine.
But the core developers' plan is to [continue to set the stage for non-bandwidth-increase-based scaling, while building additional tools that would make bandwidth increases safer long term](
You know what it means? That means 1Mb blocks for months or even years (now, when we are already hitting this artificial limit!). 
RBF is needed to fit the most high value transactions into 1Mb blocks.
That means higher fees, delayed transactions, artificially constrained capacity.
They put on stake the future adoption of Bitcoin.
@_date: 2015-12-21 23:55:30
Why to run nodes on home PC? Isn't it sufficient that businesses that don't want to rely on the third parties run full nodes on their servers (and there will be a lot of them with big blocks) while their clients run SPV wallets as envisioned by Satoshi?


Oh, you think there should be some non-elected government with oppressive power that can make decisions nobody has a right to question?
If we continue this analogy, then the Amazon has stakeholders that decide its future. They talk to each other and decide the adequate pace by shareholder voting. If some disaster happens (e. g. fire destroys half of the trees = exponential technological trends discontinue) they will have an urgent meeting and adjust their policies to defend their future.


So what? You continue taking pictures (and videos) with your camera despite the data bloat on your disks. Same here. We will store it till the end of the days (or use pruning if it becomes a problem).


So what you are saying is that Bitcoin is not for everyone. I disagree. I believe there is more incentive to invest in it if more customers actually use it.


I don't have anything against it. But I believe the block chain is for everybody including the unbanked people of Africa, not just for payment hubs that establish payment channels to their customers. And I believe there will be more investors if exponential growth can be maintained.
@_date: 2015-12-14 01:50:48
How do you decide what should be the price for entering the block?
It is obvious that smaller the block size limit - higher the price.
There is no need for fees yet since we didn't reach the technological limit. We just reached the temporary artificial limit set 5 years ago that can now be safely increased 10 times or more without a problem.
Bitcoin transaction fees would make sense after bitcoin reaches the mainstream adoption and the block reward becomes too small.
Right now most of the mining is paid by Bitcoin holders, not by transactions. So there is no problem to add as many free or cheap transactions as is required for increased adoption.
In future large blocks with millions of transactions in them will generate enough revenue with small fees per transaction. That was the original vision of Bitcoin.
@_date: 2015-12-10 22:42:48
What does
     your bitcoin address here&gt;/balance
return then?
@_date: 2015-12-14 03:49:36
If core merged BIP101, they would gain miners' support. If they reduced the initial ~~20Mb~~ 8Mb to 4Mb, that would probably be a compromise.
There were many proposals made, but nothing merged to the core.
Was there any promise to implement anything related to the block size limit problem except RBF, Segwit and Lightning by a specific date?
We've hit the block size limit already. We shouldn't have done it before the mass adoption happened so that miners could charge small fees from millions of transactions included in blocks. 
And the core devs have different priorities and pretend that it is not an urgent problem. This is a negative symptom with probable long-term consequences. 
@_date: 2015-12-14 07:15:47


Thanks for pointing this out. Not sure if discussion that had happened a few years before RBF got merged is relevant to this post, but if you provide a link to it, I will add it to the beginning.
@_date: 2015-12-19 04:12:48


(c) u/petertodd
Who are the stakeholders?
@_date: 2015-12-18 08:18:09
2) new input doesn't necessary mean new address, but even if it meant - it wouldn't make a difference since you would need to use it to set a higher fee anyway (with RBF or without it). Or am I misunderstanding anything?
3) Most nodes follow the default policy of Bitcoin core. And I don't think they want to keep transactions in their mempool forever. 
Miners don't care too much about transaction fees currently because they are being subsidised by the block reward.
That's why miners rarely use RBF (even though nothing stops them from) and the only major mining pool that uses it (F2Pool) started doing so because Peter Todd convinced them to. And they quickly switched from Full RBF to FSS RBF. No major players want to abet fraud and devalue Bitcoin.
@_date: 2015-12-12 01:14:05
What's the percentage of users with a single input that get their transactions stuck (and can't wait until they get confirmed or forgotten by the network)?
@_date: 2015-12-24 05:20:38
"Transaction fees with bitcoins are extremely low: 0.0001 BTC per 1000 bytes." will it be true when exponential growth of bitcoin transactions smashes over the fixed 1Mb limit over the following few months?
@_date: 2015-12-24 01:31:13
 This is a privacy leak: in this use case people know your change addresses even if you don't need to bump a transaction.
If you are OK with the world seeing which of your outputs is for change, then FSS RBF is not at disadvantage. E. g. if transaction has "RBF" flag and more than 1 outputs, then the last output could be modifiable. That would be needed only if you don't have inputs to add to the transaction. 
If you have additional inputs then FSS RBF could work without the RBF flag, without exposing your change addresses, and could be used to "compress" your transaction by merging it with yet unbroadcasted ones.
It is better to leak inputs than change addresses because inputs have already been spent while change addresses show your current balance.
And it is better not to leak anything if you transaction didn't get stuck! Just precompute the fees and in the most cases you won't need to flood the network with copies of your transactions.
@_date: 2015-12-22 09:35:18


Then we are doomed because exponential growth is the only way technologies are becoming mainstream. Well, the first phase is supposed to be exponential, then it turns into sigmoid (we are far from it yet).
However this chart [looks exponential]( Doesn't it? 
[The latest 2 years look straight in logarithmic scale] ( - that means it exponential.


Oh, here it is sorted by popularity. But in [this thread]( it is sorted by controversy. Why? Because the majority doesn't support the published roadmap.
@_date: 2015-12-24 02:29:39


1) Number of transactions has been growing exponentially since Bitcoin got traction.
2) Block size limit is fixed. 
3) We are hitting it already.
Do you need an explanation of possible consequences?
On the other hand "small blockists" say Bitcoin is becoming centralized (yes, everybody is upset about it too, but it is not clear whether 1Mb is the right value for the block size limit).


Larger the block size -&gt; Higher the orphan rates for poorly connected miners -&gt; Chinese miners gain advantage because they control most of the hashing power and are better connected to each other than to the rest of the world -&gt; mining centralization -&gt; Bitcoin fails


Lightning Network makes it possible to set up payment channels via the blockchain and then use them to transact without writing to the block chain. So it is seen as a possible solution to the bitcoin scalability problem while keeping blocks small enough to maintain the decentralized nature of Bitcoin.
The problem seen by "large blockists" is that the Lightning Network is our bright (non-guaranteed) future, but Bitcoin hits its limits today that might slow down adoption and even cause a death spiral (small blocks -&gt; expensive transactions -&gt; slow adoption -&gt; low bitcoin price -&gt; some miners quit -&gt; lower confirmation times -&gt; expensive transaction -&gt; ...).
Large blockists envision Bitcoin as a global cash system (everybody should be able to write to the block chain). 
Small blockists see it as a settlement layer for a more sophisticated solutions (block chain is too expensive for everyday transactions).
@_date: 2015-12-14 06:28:18
BIP 101 is better than BIP 100 for many reasons. But I would applaud if Bitcoin core devs merged BIP 100 to the core. They failed to do it in time despite the miners' support (is it even implemented) and we are hitting the limit. Why?
@_date: 2015-12-18 21:55:28
Japan had a depression for decades. Did it affect its technology?
@_date: 2015-12-14 01:47:08
In case of successful adoption, fee market will be needed when we have large blocks with hundreds of thousands or millions of transactions in them.
Artificial low block size limit reduces the chances for successful mainstream adoption of Bitcoin.
@_date: 2015-06-13 23:28:40
Do some advertising at 
@_date: 2015-12-13 23:53:55


From the protocol point of view that is true, but from the real economy that is not. There were quantifiable risks involved with 0-confirmation transactions, and many (including such a giants as Bitpay and Coinbase) utilized them without a problem. It provides convenience for the end users and it is worth it.
Miners are not in hurry to take much from the fees at the expense of double spends. Their main income comes from Bitcoin holders. So they are interested to keep the high value of Bitcoin. They even agreed once to increase the block size to 8Mb. It is the core developers who seem to push their agenda by promoting the low size limit and RBF.
Is there any compromise bitcoin core devs agreed to? I never heard they announced any particular date and size for the block size increase. If they said "we agree to exponential block size limit increase, but lets start from 4Mb in January" - I would applaud them. Instead they say that the block size is not an urgent problem.
That would be much more helpful to increase the block size rather than to kill 0-fee transactions.
Segwit does nothing to the amount of data being spent (it may even add some data), it just moves data to a different structure that is not counted towards the block size limit. And according to Gavin it would be nicer from a coding perspective to make it as a hard fork, not a soft fork (and it shouldn't be a problem since nobody is opposing segwit).
The 1Mb limit was imposed in 2010 as a temporary measure. It was supposed to be increased with time. Gavin tested 20Mb blocks about 1 year ago, so 8Mb is pretty conservative. I think with segwit large blockists would support 4Mb or even 2Mb in January. Why wouldn't core devs announce it?
@_date: 2015-12-11 01:29:19
I don't quite understand what you mean.
1. Standard P2PKH transactions have inputs (senders' UTXOs) and outputs (that contain hashes of recipients' public keys and thus are associated with recipients' bitcoin addresses).
2. Outputs are called UTXOs until they are spent.
3. Thus UTXOs are associated with recipients' bitcoin addresses (at least in the context of P2PKH transactions).
Or am I misunderstanding something?
@_date: 2015-12-26 03:35:42
The [mentioned miner rejected Full RBF in favor of FSS RBF](
RBF is just a node policy. Miners could always use it but they chose not to do it. No need to incline them to do it!
[RBF should not be adopted](
@_date: 2015-12-18 20:35:27
That's not an answer. Almost everybody is generating exponentially more data every year and that's not a problem because technology growths exponentially too in order to meet this demand.
Just imagine that in 90's engineers decided that 1Mb RAM with linear growth of 1Mb per year was enough. We'd have only ~20Mb of RAM in our computers by now (~1000 times less than we have now).
@_date: 2015-12-24 01:42:34
RBF leaks the change addresses anyway.
So if there is RBF flag, then the last output could be considered a change address and the FSS rules could ensure that all the other outputs are preserved.
And if there are additional inputs and all the outputs could be preserved, then there would be  no need for RBF flag.
Would FSS RBF enable all the legit use cases of the opt-in full RBF without breaking the current risk model of 0-confs?
@_date: 2015-12-22 04:48:44


Let's reduce the block size limit to make it even more decentralized.
It requires only a soft fork (much better than a hard fork, isn't it?)
Let's do it gradually to avoid the supply shock. Exponential decay would work just fine!
@_date: 2015-12-19 06:38:41


You can if your new transaction is not broadcasted. Just add new inputs and outputs but don't modify the old ones. That's not the point of RBF anyway. It was meant to bump the stuck transactions, remember?


Oh, did Bitpay stop accepting 0-confs from everybody?


Agreed (though to set up a payment channel you still need to wait for confirmations). First adopt it, then kill 0-confs if you believe it is required.
@_date: 2015-12-26 01:38:00
You can also show your support with your bitcoin signature here: 
@_date: 2015-12-14 00:06:28


They never meant to be safe, but they were safe enough to be used by BitPay, Coinbase and others. Many buyers and merchants utilized instant bitcoin transactions. That's a great user experience that shouldn't be discarded as nonexistent.
Most of the miners use the reference client and obey the FSS rule. Of course we can't force them to continue doing so. But they want the best for Bitcoin and the fees are low relatively to the block reward, so they do so.
Why are core devs pushing them to adopt RBF reducing the utility of Bitcoin for the average Joe?
Update: oh, and "opt in" is a joke. merchants will need to opt out from that by performing software development on their side.
@_date: 2015-12-17 19:56:00
[The activation time will be the timestamp of the 750'th block plus a two week (1,209,600 second) grace period to give any remaining miners or services time to upgrade to support larger blocks.](
@_date: 2015-12-14 00:44:04
I thought that since most of the network and miners use FSS, then once the transaction is propagated through the network, there is a relatively small chance of it being successfully double spent and undetected in seconds, and many users utilized his feature. That explains why Coinbase director opposed full RBF, but Green Address CEO promoted it.
So what you are saying is that neither Bitpay nor Coinbase would suffer from adoption of RBF, and the risks of accepting 0-conf transactions will remain exactly the same?


Let's cross our fingers that it really gets developed, tested, deployed and adopted before Bitcoin users and investors switch to other payment systems.
@_date: 2015-12-14 03:56:36
Is there a better place for Bitcoin shareholders to discuss the direction of development and the requirements for bitcoin software?
@_date: 2015-12-20 23:04:19


We don't know about it. ["Fee event" (perfectly expained by Jeff Garzik)]( is a major risk, Bitcoin has never faced it. It may not only slow down the adoption, it may launch a downward spiral: 1) adoption expectations broken -&gt; 2) lower price -&gt; 3) mining less profitable -&gt; 4) lower hashing power and security, longer confirmations -&gt; go to 1).


However there is no proof 1Mb is the right number, this number is not a natural limit. It was a temporary arbitrary limit set by Satoshi in 2010 that was supposed to increase exponentially as technology advances. You are applying the central planning principles to Bitcoin. Who is the authority to make the decision? 
@_date: 2015-12-13 11:50:11
Why does the RBF merged into Bitcoin core require a special "opt-in" flag then?
@_date: 2015-12-10 16:38:51
Thanks for your feedback. Could you please elaborate on that?
@_date: 2015-12-19 06:41:37
I admire your well deserved self esteem but would still be thankful for links that clarify and/or prove your point.
@_date: 2015-12-14 08:35:16


You've already spent a lot of time chatting with me. Thanks for that!


I admit, that might be a problem. But that can be explained by the introduction of SPV and was invisioned by Satoshi in his paper. Merchants do run nodes for their security (and for monitoring of double spends as well). Bigger the blocks - more merchants there are.


AFAIK they just optimized the process by sending the block headers. If they mine invalid blocks, it won't be accepted by the network and will damage their reputation and financial interests.


The change was [introduced in 2010]( and activated in 2011 at block 115000.  It is almost 2016 now. How is that 2.5 years?


Number of transactions doubled during a year. And the only reason why they stop increasing exponentially is the block saturation due to artificially created scarcity (despite the exponential technological trends). Is that what you want?
We are far from mass adoption yet. If you agree that technology advanced since 2011 and bitcoin core got optimized then you should admit that it is too early to freeze the block size limit and to profit from transaction fees.
@_date: 2015-12-18 20:28:02
No doubt transactions need confirmations. 
Everybody agrees with Satoshi that "0/unconfirmed transactions are very much second class citizens". But they are still citizens, don't kill them!
There is a quantifiable risk of unconfirmed transactions. If your business model accounts for that risk then it is OK to use them. It is a great user experience of instant transactions utilized by BitPay, Coinbase and others, that shouldn't be sacrificed.
Satoshi [was in favour of FSS RBF]( that would not sacrifice it.
And I agree that transaction propagation is a node policy, not a consensus rule. But the default policy should not abet double spend fraud.
@_date: 2015-12-14 09:51:51
Me too. About a year ago Gavin tested 20Mb blocks on a desktop computer without a problem. Bitcoin became much more optimized than it was in 2010-2011 (when 1Mb block size limit was set) and computers became more powerful.
@_date: 2015-12-10 21:41:06
You are right, the signature itself doesn't prove that it holds any money. But with bitcoin blockchain is proves it, doesn't it?
Bitcoinocracy checks the blockchain time to time and updates the value (though it does it through a third party currently, but this can be fixed).
@_date: 2015-12-22 07:02:20
So you made analysis 6 months ago, noticed a few spam spikes later and now you assume that all the growth was due to spam? You might be right, but I am not convinced. 
Look at your own graphs. You can notice that during the second half of 2014 amount of transactions nearly doubled. Maybe it is just a seasonal rise of activity?
I don't see the reason why it shouldn't double in 2015, 2016 and other years unless we constraint it artificially.


About a week ago I mentioned in my comment and it automatically became invisible to public until I removed it. Now it works, thanks for your hint.


oh, sorry, I meant 15% amount of users has. That's less than 15% of bitcoiners of course.


Then why are the comments sorted by controversy by default but not by popularity (and points are hidden)? Isn't it an attempt to hide the truth supported by majority?
@_date: 2015-12-17 10:18:43


I am not sure whether it is true. I thought there had been a lower limit before 1Mb was introduced.
Do you want to say that there were no hard forks at all, or that they damaged the value of Bitcoin somehow?
RBF (merged to master of Bitcoin core) changes quite a lot.
Instead of "stuck" transactions (that may take days to get confirmed) people will double-spend them with a higher fees. Merchants and payment processors will have to re-write their accounting software to handle it correctly. Fees will raise and considering that 0-conf transactions will be destroyed, it is likely to damage user experience and adoption of Bitcoin. And that's the direction chosen by core devs.
@_date: 2015-12-18 06:39:32
2) That is no different from how common transactions work. If user  set a higher fee at the very beginning, the same amount of information would have been shared. Moreover if transactions are not recorded to the blockchain - that doesn't mean they won't be recorded elsewhere.
3) Sorry, didn't get it, why new type of message is required? Just remove the unconfirmed transaction from the mempool if it resides there for 72 hours or more.
@_date: 2015-12-22 06:15:57
If the core team thinks it is safe to increase the capacity with segwit, that means there is consensus that 2Mb blocks are more-or-less safe.
Why not to increase the block size limit with a hard fork ASAP, when it is needed? The risks are low since everybody would support it.
Later, when segwit is production ready, you'll need a soft fork anyway. And you will be able to reduce the limit in the same fork if necessary (hopefully won't be necessary).
@_date: 2015-12-10 16:39:48
Is it true that a single bitcoin signature exposes no personal data and can't be used to calculate the private key?
@_date: 2015-12-31 09:26:35
Theoretically it gives them advantage, but AFAIK it is not very significant (&lt;1%).  The price of Bitcoin is much more important. So they would support whatever is best for Bitcoin. The problem is there is no easy way to determine it with 100% confidence. So they just trust bitcoin core by default.
@_date: 2015-12-20 23:28:37
I expect the capacity to scale exponentially with respect to technological trends. And many other bitcoin enthusiasts too.
Lightning and other technologies on top of Bitcoin are good, but they should not limit the usage of the Blockchain.
Bitcoin is supposed to be the global electronic cash system. And it can fulfil its promise if you don't constraint it artificially.


You are obviously lucky that you don't live in Kongo with an average anual salary below $300 a year. Btw, I tried to get registered at Coibase, but I couldn't, because I am not American.
@_date: 2015-12-13 23:59:41
Did I mention Bitoin-XT anywhere? No I didn't.
As for economic majority - it is chicken and egg problem. With &lt;1% of hashing power nobody would run it. And most of the miners use the reference client. Would be much easier if bitcoin core devs didn't pretend there is no problem and merged at least something to increase the blocksize limit.
@_date: 2015-12-14 07:52:53
So BIP101 is the only solution ready for adoption. And there is no problem with it: miners won't mine large blocks if it not profitable for them.
@_date: 2015-12-14 02:29:04


It was profitable for many companies to rely on small value 0-conf transactions. It was a quantifiable risk for them and a great user experience for their customers.
Now you are advocating to force every merchant that used this feature to invest into development and make buyers wait for minutes to hours or days (for their transactions to get confirmed) and serve them after that.
@_date: 2015-12-18 20:40:04
There was a quantifiable risk that could be accounted for. Most miners follow the default policy and don't abet double spend fraud. If RBF is the part of the default policy then it should be FSS RBF.
@_date: 2015-12-03 14:32:15
I am always curious what holders think. Could you please back your opinion with your bitcoin signature at  ? No registration needed.
@_date: 2015-12-14 08:01:29
Miners are hired by Bitcoin holders to do their job and get a decent Bitcoin reward that subsidies bitcoin fees. They will earn much more when bitcoin becomes mainstream: they will fill their multi-gigabyte blocks with millions of transactions and get much more fees from them than they could get from 1Mb blocks. Just don't shoot your own foot, let the mass adoption happen.
@_date: 2015-12-18 20:59:36


I live in the developing world. Exponential growth is still there. Or are you saying that computers in the developing world have 20Mb RAM only? No, costs won't increase exponentially, they will be the same or even lower.


I agree. There will be a lot of future optimizations and scalability improvements. But it shouldn't constrain the adoption. 1Mb limit was set  years ago. Communication channels improved and Bitcoin became much more optimized since then. And those improvement trends will continue. If not - we'll have plenty of time to soft-fork and limit the block size to be safe.
@_date: 2015-12-22 04:31:43
Who has a vote, Luke?
Ideally the market should choose.
But there is no freedom of choice currently (because network effects are powerful). The whole bitcoin economy is a hostage of a single team of developers that defines what is Bitcoin and what is an altcoin.
Or am I wrong?
@_date: 2015-12-23 09:07:15


Ok, look at [your own data](
* 2012-01-01: 16K
* 2013-01-01: 68K
* 2014-01-01: 138K
* 2015-01-01: 272K
That are only "Normal" transactions. Still doesn't look exponential?


Didn't understand this. Do you admit that that's a form of censorship?
@_date: 2015-12-14 07:11:59
Neither Satoshi Nakomoto (who set 1Mb temporary limit back in 2010), nor Gavin Andersen (who proposed 20Mb increase) are stupid. You might be smarter, but it is not enough to convince everybody. If you have any factual data, please share and eliminate the controversy.
@_date: 2015-12-21 23:37:20
I agree that decentralization is crucial or Bitcoin, but bandwidth costs are negligible in comparison with electricity and hardware. It is hard to believe miners can't afford to improve their communication channels.
Where does this number (723Kb/s) come from, is it correct?
What is the best block size limit for 723Kb/s?
How did Bitcoin survive with 1Mb block size limit for years?
@_date: 2015-12-22 04:38:03
Wow, interesting idea. Instead of holding the whole bitcoin economy a hostage of a single development team, let the free competition happen and see what the market decides!
@_date: 2015-12-19 06:31:30
I didn't say it prevented. It just allowed to get the quantifiable risk estimates and utilize 0-conf transactions in certain business models.
FSS RBF could be a viable compromise as it makes legit double spending practical without killing the utility of 0-conf transactions.
@_date: 2015-12-18 03:16:59
Thanks for your answer!
I am sure though that there will be parties that observe such transactions and save them. Not sure whether they publish or sell this info.
What do you think about 2) and 3) ?
@_date: 2015-12-23 12:52:31
Bitcoin holders pay 25 btc per block. If 1 Mb block contains ~2000 transactions then Bitcoin holders subsidy 0.0125 btc (~$5.5) per transaction. Bitcoin holders agree to pay it in order to boost adoption because they believe that the value of Bitcoin will increase if more people use it. And it works: amount of transactions roughly doubles every year.


We are shooting ourselves in the foot by prematurely spawning the fee market and slowing down the adoption before we reached the mainstream and technological limits. There is no way to reach mainstream without exponential growth, don't slow it down or it may not happen!
When Bitcoin becomes mainstream and block reward becomes 0, there will be millions of low-fee transactions per block. It is better to have millions of low-fee transactions, than thousands of high-fee ones. If fees are high then there is a risk that there will be no mass adoption and bitcoin value will drop.
@_date: 2015-12-13 21:14:28
Self-interested - maybe, but I can assure you that I am not wealthy yet.
However I believe that bitcoin holders have a lot on stake and may suffer if bitcoin goes the wrong direction. I don't know how many of them because there is censorship here, many switched to other subredits (can't mention them here).
If they want to be heared - they can just sign the statement, it costs nothing.
I got a feeling that bitcoin core devs have their own agenda and their decisions are biased. That's why they break 0-conf transactions and impose the low bitcoin block size limit (that was introduced as a temporary measure in 2010 or so).
@_date: 2015-12-11 00:17:22
The same defect is in my brain. Could you please help to fix it by clarifying your point? :)
@_date: 2015-12-31 06:21:20
Perhaps ideally the hashing algorithm should be changed automatically with a difficulty adjustment every 2 weeks, so that there is no time to build a specialized hardware for it.
Not sure though whether it is possible to automatically generate a new random hashing algorithm with predetermined security/performance properties.
@_date: 2015-12-12 01:00:42
Perhaps the sanity checks could be applied to limit the misuse of this feature?
E. g. allow to change inputs and add the new outputs, but don't allow to change the existing outputs.
Would this rule solve the problem?
@_date: 2015-12-22 09:40:25
It is too early for the fee market. Bitcoin is not mainstream yet. Bitcoin holders subsidy transaction fees for a reason. It is too early... :`(
@_date: 2015-12-28 12:21:29
That's correct. But when you decrease the value of the output, you leak information about your change address. If people know your change addresses, they know your balance.
If you don't want to leak your change address then just add new inputs and outputs, but don't modify existing outputs.
If you are OK with leaking your change addresses, then let's have a convention that if RBF flag is set then last of the outputs is for change and can be modified.
@_date: 2015-12-15 17:10:48


Could you please provide a link to it?
@_date: 2015-12-14 07:50:12
But he set the block limit to 1MB, not to 300KB. And he never said that was forever. He increased the block chain so that we don't hit the limit.
Do you have any factual data that proves that your number of 300KB is correct or do you just like it?
Do you have any factual data that proves that the number of 1MB is larger than adequate and not outdated as you claim?
Thanks for mentioning the [Rusty's blog]( According to his pessimistic assumptions the projected growth is not 100% per 2 years, but 70% per 2 years.
But it is better to be optimistic here because it is easier to decrease the block size with a soft fork than to increase it with a hard fork. And there will be less controversy with that if we see that it endangers Bitcoin.
About 5 years have passed since the last increase.  Miners were not mining 1Mb blocks all the time. Higher block size limit doesn't mean blocks will take all that bandwidth. Even now, when we are hitting the bock size limit, there are many empty blocks.
@_date: 2015-12-19 07:11:22
Are you saying that those who disagree with decisions made by Bitcoin core team should sell their bitcoins?
@_date: 2015-12-17 12:18:00
There are alternative implementations of Bitcoin. E. g.  . I don't want to mention the fork of Mike Hearn and Gavin Andresen that is not welcome here.
I think more implementations we have - better it is.
I respect the devs of bitcoin core and am thankful for all their work (even though sometimes I worry about direction they chose). There is nothing bad about calling them core devs IMO.
@_date: 2015-12-22 03:54:14
What's Re ?
@_date: 2015-12-18 21:14:18


In that case we soft-fork it to limit the block size. It is less risky than to hard-fork the block increase, and will be easier to reach consensus.
PS: have depressions ever influenced the technological curves?
@_date: 2015-12-14 02:37:12
It is opt-in for buyer, but not for the merchant. It will make 0-confs too risky for everybody. Why to repair what is not broken?
The block size limit is broken, not FSS. It can be safely increased 10-fold right now. The core devs have other plans, and I welcome those plans, but they shouldn't constrain the natural growth of Bitcoin until it hits the technological limits. 1Mb is far below those limits.
@_date: 2015-12-22 03:51:21


I mean do you have a link to the source? I think if the block size limit was higher, the miners would have upgraded their channels.


That is valid for any number.


Why not to reduce it to 100Kb with a soft fork and re-evaluate it later? Or is 1Mb just a magic number that is by accident right?
I think that we should increase it ASAP and continue working on code optimizations etc.


Here there was a strong financial incentive to execute an attack (attacker could short Bitcoin and then break it thus earning millions). And we saw this happening with vulnerable exchanges.
@_date: 2015-12-12 09:04:51
Is it possible to spend the unconfirmed change output with a higher fee in order to get both transactions confirmed?
First time wallets with a single input with a single very-low-fee outgoing transaction IMHO is a relatively rear event.
And it would rarely get stuck if (hopefully when) block size limit is increased.
@_date: 2015-12-11 02:57:49


So [this article]( 
) is incorrect?:


@_date: 2015-12-14 04:11:52
So what you are saying is that all the people who:
1) don't want RBF because it breaks existing use cases
2) don't agree with not increasing the outdated temporary 1Mb block size limit
should write to the mailing list and create/comment Github issues?
@_date: 2015-12-22 04:24:34


Yes, the link to the source that confirms that miners' bandwidth is really 732Kb/s. I want to know where this number came from. And why do you think that it is not going to increase if the block size grows.
Sorry, I don't have 55 minutes to watch the video right now, maybe will watch it later.


If I got it right, on the scaling conference miners agreed to whatever the core devs tell them to do.
They are mainly paid by block reward, so they would do whatever is needed to raise the value of bitcoin (it is much more important for them than amount of transactions and the fees).


Most of them agree that 2Mb is safe now. But instead of doing it now, they want to do it with a soft-fork in future, when segwitness when it is production-ready (by the end of 2016 if we are lucky). And before that they are going to create a fee market and kill 0-confs with full RBF (read more about it on other bitcoin-related subreddits, this one is being censored).


Do you remember Bitcoinica? It was available in 2011-2012 before it got hacked. Bitfinex [appeared in 2013 and allowed shorting as well](
@_date: 2015-12-01 13:17:27
[BIP101]( proposes to increase the maximum block size limit from 1MB to 8MB in January 2016 (if 75% of mining power supports it), then double it every 2 years.
[Gavin Andersen]( (the author of this proposal) performed successful tests with 20 Mb blocks [almost a year ago]( so 8 Mb limit is rather conservative.
If the long-term exponential trends of CPU/bandwidth/storage growth don't continue then this limit can be reduced as a soft fork (it is much easier and less risky than a hard fork).
@_date: 2015-12-26 03:38:27
There is a hope that they won't implement it too soon.
They could always do it, but they didn't so far.
Because transaction fees are being subsidised by the block reward. The value of Bitcoin and its adoption rate are  more important that transaction fees currently.
And because of the default policy of Bitcoin core software of course. No need to push miners into RBF!
@_date: 2015-12-14 04:25:52


That's not exactly correct, Gavin Andersen (the former Bitcoin core lead developer that helped Bitcoin to become what it is now) and Mike Hearn wrote some code and expressed their support.
Miners vote for bip100 because it gives them power, but it wasn't implemented nor merged.
Bitcoin shareholders currently support BIP 101 over BIP 100. If you know the opposite - it is easy to prove. Just leave your signature or find someone who agrees to do it, it is absolutely free.
Update: miners are hired by bitcoin holders, they will follow whatever decision is supported by community and pushed by the bitcoin core team.
@_date: 2014-08-02 20:42:51
Thanks for your feedback. We have implemented 
@_date: 2014-10-14 18:50:49
Probably people use search because they don't remember the correct address. IMHO Bitstamp should purchase and use bitstamp.com and bitstamp.org domains before phishers do it.
@_date: 2014-08-09 11:01:45
Having read several chapters I came to conclusion that this paper has valid points, but it could be much, much shorter. The author is explaining the same obvious stuff (regarding mining cost) again and again with various examples and analogues, even though all that could be expressed in one paragraph. Really, there is so much text that it is not possible to argue with it. You have to read and believe it. Or create a separate thread for each idea and discuss it separately.
@_date: 2014-01-19 06:14:19
Hi from Anonymous Ads ( we are looking for investment (sent a PM).
@_date: 2014-08-08 15:49:50
number of transactions tripled during a year (somewhat stagnating in summer, but this is to be expected, same was in summer 2013 
looks like a steady growth to me
@_date: 2014-12-26 14:31:54
@_date: 2014-06-25 18:45:01
Shameless plug: one way to do it is  ;)
@_date: 2014-01-09 07:31:15
Do you really think that high inflation is bad for governments? I think they benefit from printing money and suppress any economic activity of their population (they don't need taxes because they print money).
I think countries with low inflation that rely on taxes (not on printing money) are more likely to adopt Bitcoin.
@_date: 2014-10-21 23:00:39
I like the idea, but "bit" is ambigious. Perhaps we could use a short name "bit" in conversation and a full name "bit of bitcoin" in contracts. I like microbitcoin too. people got used to microsoft, why would't they to SI-compatible microbitcoin?
@_date: 2014-08-02 20:44:01
We will probably implement it in near future. Thanks for your feedback!
@_date: 2014-08-30 15:31:55
Shameless plug: added to  in case if someone wants to donate publicly.
@_date: 2014-01-10 21:17:18
Great app!
@_date: 2014-01-11 11:51:34
Nice one! I'd like to see a coub :)
@_date: 2014-09-24 10:28:20
mining efficiency is not important for bitcoin network as a whole.
power usage of bitcoin network is limited solely by market forces. the major factors are price of bitcoin, price of energy, block reward and transaction fees.
cost of energy consumed by mining 1 block will approach (block reward + transaction fees) * bitcoin price.
if we consider price of energy and (number of transactions + block reward) to be more or less stable then if bitcoin grows 100 times, energy consumption will need to grow at least 100 times too.
perhaps if bitcoin continues to rise, it will start affecting the price of energy. significant part of energy generated by human race may be used to support its payment system.
@_date: 2016-01-25 00:35:07
Probably [BIP 103]( was too slow for the large blockists because it was supposed to start a modest exponential growth from small 1Mb blocks and there was a better BIP 101 on the table. And now they just want to kick the can to solve the urgent problem ASAP. That makes perfect sense to me.
@_date: 2016-01-25 04:49:42
Why do you think the resistance for the necessary changes will be orders of magnitude greater?
The resistance for controversial changes will be greater - that's true. And that's good, isn't it?
Nobody promises "free to use" forever. But the block reward is here to subsidise the transactions. So there is nothing wrong with free use, it is a fuel to reach the mainstream, a common marketing practice.
@_date: 2016-03-30 11:49:51
If we assume that the potential demand for transactions is infinite (especially when robots take over our economy) then is unlikely that all the transactions can be stored in the blockchain. Hence off-the-chain solutions will gain traction when the block size increase becomes too expensive and eventually most of the transactions will be performed off-the-chain. I don't think we have reached this point though.
On the other hand it is almost guaranteed that the today's VISA capacity can be achieved on-the-chain at some point of future (if the block size limit is not artificially constrained). The only question is "when?". If the size of the human population stabilizes and the amount of transactions' doesn't grow exponentially then eventually it will be possible to store all the transactions on-the-chain and there will be no need for other currencies.
Who knows, maybe some form of trustless distributed blockchain will be invented so that nobody needs to store and verify the whole thing if it becomes too expensive.
The humankind generates, transfers, processes and stores the exponentially growing amount of data without a problem. Why do you think it would work for digital photos and videos, but wouldn't work for financial transactions? 
I admit that Hal Finney's vision might be right. But I am not sure what will happen in reality.
@_date: 2016-01-13 09:39:02


When you use RBF, you inform the world which output is yours anyway.
@_date: 2016-03-30 11:06:28
1) Once again, I don't advocate for 32Mb blocks now, but I don't see why they can't be feasible in the foreseeable future.
It is too early to worry about VISA's daily average throughput yet, but 32Mb would make a difference: it would make it possible to have 32 times more on-chain transactions with a 32 times lower fee per transaction.
I agree that the block size increase is not a panacea and that Segwit and Lightning are the promising solutions to solve the scalability issue.
2) Btcd team tested Bitcoin over a year ago. 10 minutes is unacceptable, but not that bad. Computing power is still growing. Modern computers are multi-core. Libsecp256k1 was recently released and should make the transaction validation much quicker.
I am pretty sure in a few years that wouldn't be a problem to process 32Mb blocks on a single computer. And current computers can handle 20Mb blocks (as had been tested by Gavin before libsecp256k1 was released).
3) I have nothing against Segwit or Lightning. I am looking forward to seeing them live. But they are not prerequisites (neither the replacement) for the block size increase.
PS: My investments in altcoins are just a few %. I've been Bitcoin enthusiast for years and it is pretty frustrating to see how the temporary anti-spam block size limit turned into the key "feature" of the protocol.
@_date: 2016-03-05 12:56:06
That's interesting. Do you have any evidence to support your claim?
@_date: 2016-01-18 16:42:18
Bitcoin inflation is not that huge and is ever-decreasing. 
Compare to 
@_date: 2016-01-02 15:05:46


If that logic is separated and frozen then I wouldn't call it a technical debt (since it wouldn't influence the software complexity, maintenance costs and architectural decisions). It is important to minimize entropy and to keep the code simple and structured. Since you are the bitcoin developer, you are more qualified than me to judge though.


The main reason to run the full node is to eliminate the risks related to the third parties. Isn't it a problem that a full node may accept invalid (according to the new rules) blocks and wouldn't even notice anything suspicious about it?


I guess you are implying the situation where the old nodes only see the old fork and the attacker double spends the coins using the new fork. Doesn't bitcoin software warn the user in such a situation?
@_date: 2016-03-28 09:52:33


In the poor countries inflation is high. Poor people don't have a chance to save! They know that they are being robbed by their own governments and that if they save anything then they would loose most of their purchasing power in a few years.
Bitcoin gives them a chance to save satoshi by satoshi, to participate in the global economy and to quit their poverty.
Unless you make the entry barrier too high by forcing them to pay high transaction fees.
@_date: 2017-02-01 19:57:28
Well said. The lack of consensus is obvious.
@_date: 2016-03-29 06:04:15
1) If you want to run a full node - nobody stops you from doing so. It costs something anyway, right?
Why do you think this cost should be equal to the cost of a small fraction of power of a shitty computer?
And at the same time you think that the block space should be constrained (=expensive) and most of the population shouldn't afford to transact on-chain.
Where is the logic?
2) I don't advocate for 32Mb blocks right now, but I think you don't need a cluster for 32Mb blocks anyway. Gavin had conducted 20MB tests over a year ago, before many optimizations took place. So I it is quite likely that 32Mb blocks would be OK right now. Even if they are not - then they will be just fine in a few years. 
And it is pretty clear that 2-4 Mb blocks are safe now. So 2-4 times cheaper transactions, 2-4 times more people able to transact on-chain. We need to rise the block size to keep the bitcoin ecosystem grow. That doesn't mean we shouldn't develop radical improvements such as Segwit or the Lightning network. But these improvements are not the prerequisites (neither the replacements) for the blocksize increase.
@_date: 2016-03-27 17:42:11
Decentralized has a much higher cost than centralized - that's true (especially if you ignore the cost of the human and security infrastructure for the centralized solution, that includes taxes and coercive force of government).
But it doesn't mean it can't be virtually free.
Nobody (except Luke-Jr) denies that the 2x capacity increase is safe (and makes the fee per transaction 2 times lower).
It is quite likely that with the software optimizations and hardware advances a 20x times on-chain capacity increase (20 times lower fees) would be possible in the near future. That would be virtually free for the current level of demand.
And when the growth of demand outpaces the growth of bandwith/space/computing power and the fees naturally increase then the Lightning network will solve the problem.
@_date: 2016-01-24 23:53:45
1) 17.7% per year is not that bad
According to Jonathan Toomim, [3 Mb is pretty safe]( (note: it is quite possible that current hardware could support much higher throughput, Gavin Andresen [experimented with 20Mb blocks]( over a year ago).
If we start with a conservative rate of 10 transactions per second, 17.7% per year would bring us to ~120 millions transaction a second in 100 years, and the current VISA-level peak transaction rate can be reached in ~52 years (if no other optimizations are made).
With optimizations Bitcoin will probably be able to handle the current average VISA-level transaction rate in a decade or two.
That's not so bad because adoption takes time too. If the demand grows quicker than throughput then the fees will rise and the Lightning Network will get traction. Nobody opposes the Lightning Network, but the block chain capacity should not be arbitrarily constrained.
2) It is better to have a fee event after Bitcoin becomes the mainstream and the block reward becomes negligible.
If the fee event happened in 2009, Bitcoin would never get traction. The block reward is here to subsidise the transaction fees. Higher the fees -&gt; slower the adoption -&gt; higher the risks of holding bitcoins.
Amount of work needed to secure the network doesn't depend on amount of transactions in block. More transactions in block - lower the fees per transaction for the same level of security.
Negligible fees won't kill Bitcoin, but slow adoption due to the artificially constrained capacity may give an advantage to altcoins.
So it is better to have a fee event as late as possible.
@_date: 2017-03-22 21:22:17
Sometimes shitty code is doing all the useful job for the end users, while the perfect code is awaiting for the world to become as perfect.
@_date: 2016-01-25 00:40:59


BIP 101 doesn't imply that no other innovation is allowed. There is no contradiction between BIP 101 and Lightning.
@_date: 2017-03-22 17:56:38


They are no doubt great devs. The problem is I think they don't have incentive to care about Bitcoin businesses. Or, more specifically, their interest and their area of expertise is science and technology, not business and economy. Since some of them are paid by companies with obscure business model, it is reasonable to suspect the conflict of interests. E. g. they may be interested to constrain bitcoin capacity in order to create the market for their second layer solutions.
Unlike developers, miners have the direct incentive to grow the value of Bitcoin. They want to satisfy the demand for on-chain transactions, to serve Bitcoin businesses and to rise the utility and price of Bitcoin. That is their interest and it matches the interests of the whole Bitcoin community. Unlike developers, miners have the responsibility, they have something on stake.
Unlike developers (who are just scientists and engineers -- type of people who are usually hired to pursue  interests of their employers) we can trust miners to increase the value of Bitcoin.


Segwit is all-in-one solution that plays with incentives and shapes the possible future of Bitcoin. Despite censorship (or maybe due to it) there is no consensus on this future.


Same is true about competing teams that propose a hard fork.
Anyway, it is better to trust miners than developers (I explained why).
Please note that Bitcoin Unlimited doesn't suggest to fork right away. It just prepares software for a fork. I'd be happy if Bitcoin Core team agreed to compromise on a 2Mb hard fork instead of ostracising the opponents and giving competing product the name of "altcoin".
With or without Segwit, a precedent of the planned hard fork would be great for Bitcoin. It would enable us to safely upgrade the protocol without creation of technical debt, it would prove that Bitcoin is not a product of a central planner (that has an authority to decide what is Bitcoin and what is not), and also would also show that Bitcoin is not fragile and it can be upgraded. Upgrades via hard forks will be necessary anyway.
Lets re-unite the community. Some reasonable compromise is needed.
@_date: 2017-03-25 15:00:09


So what about proof of this claim?


Just read about it at 
I have 2 questions:
1) What prevents biggest bitcoin miners (who have cheap electricity and hardware acquisition capabilities) from becoming the biggest in all the proposed proofs of work? (remember, altcoin miners are much smaller)
2) Who and how determines if the hard fork is malicious? E. g. the MR POWA itself is a hard fork. How do we know it is not malicious?
@_date: 2017-03-23 05:59:08
Yes, they started politicising, ostracising opponents and setting the financial incentives for bitcoin users. That's not their job and not their area of expertise.
I believe they are biased, because...
Firstly, they have already spent a lot of time doing something that nobody asked for (that's a typical behaviour for developers) and now they are trying to push it as the only option.
Secondly, some of them are funded by a single company with obscure business model and there might be a conflict of interests.
@_date: 2016-01-22 16:36:53
Could be, could be not. We don't know. E. g. here people that want a change loose: 
What we know is that there is a cryptographic proof that the owners of over ~3364 btc believe RBF should not be adopted (while ~1174 btc doubt it).
@_date: 2016-01-25 04:46:44
There is no doubt that Bitcoin can scale, the only question is whether it can scale faster than bandwidth (17.7% per year).
There is no reason to stop the growth in order to prove anything. 
Bitcoin is a living eco-system, it is immoral to constrain its growth by not increasing the arbitrary block size limit, that is currently far below the capabilities of the underlying infrastructure.
@_date: 2016-01-03 08:20:59
Nobody tricks people. They know that low fee transactions may require days to get confirmed.
The rules were there from the very beginning. Holders pay miners to include transactions in the blocks. That is important to boost adoption. Bitcoin price rises, so reward halving makes perfect sense.
It may take decades for bitcoin to become mainstream. The block size will be much larger than it is today. And Lightning will be there too. So fee per transaction will be lower.
We don't want stability. We want exponential growth. That's the only way to reach the main stream. Otherwise bitcoin will fail.
@_date: 2016-01-22 18:24:39


Nobody is stopping anybody from submitting one's signature. The voting is voluntary, no need to involve all the 15 million btc. If this matter is important for you - sign it. If not - just ignore.


RBF is not a consensus rule, it is just a node policy. That's what the core devs say. They don't try to find any kind of consensus on this matter.
@_date: 2016-01-21 22:36:46
I am looking forward to seeing it live too. Meanwhile the user experience and the adoption rate of bitcoin shouldn't suffer. Some form of RBF will probably be required at some point, it is just too early yet.
(edit: relaxed the last sentence since not sure about the future)
@_date: 2017-03-22 20:29:03
No, miners have no incentive to mine the blocks that nobody else would accept.
@_date: 2017-03-23 05:44:14


False, miners profits depend mainly on the price of Bitcoin. E. g. it is much better to get 12.5 btc  * $2000  than (12.5 btc + 1 btc fees) * $500.
High fees repel users and pull the price down.
Miners are interested to process more transactions for a lower fee. This will change when Bitcoin becomes mainstream, but it is unlikely to happen if exponential adoption is put on hold.


The hashrate would drop only if bitcoin price plummets. 
I would accept any outcome, but if Bitcoin capacity doesn't grow, it will loose its first mover advantage and I will need to spend time researching and developing support for alts.
Despite the fact that I am a big blocker and I don't trust Core's incentives, I trust their technical expertise and I'd still prefer their solution to the status quo. I don't like the current implementation of SegWit, but it is better than nothing.
@_date: 2016-03-05 17:04:56
Unfortunately unlike a 2Mb hard work, Segwit doesn't automagically double the capacity. It will take a lot of time to get adopted by the industry. And even after that, it will be equivalent to only ~1.7Mb block size increase.
It would be much better for the ecosystem to have a 2mb fork before the block reward halving, so that the miners could get compensated from a larger number of transactions (instead of increasing the fees).
@_date: 2017-03-22 21:36:13
why downvote? your comment does not contradict mine.
@_date: 2017-03-22 15:43:44
There is plenty of work on layer 2 solutions already. The problem is the fees are too high and it hurts Bitcoin businesses. Remember, miners are still rewarded 12.5 btc per block. There is no reason to rush with the fee market now.
Miners themselves don't want it yet, they are more interested to maximize the value of bitcoin and enforce the acceptable consensus rules, why do you trust developers (whose incentives are obscure) more than miners?
But there is a reason to upgrade anti-spam measures (the current anti-spam 1Mb limit diminishes Bitcoins' first moving advantage and doesn't play well any more).
Btw, how do you measure the overwhelming consensus?
@_date: 2017-03-18 19:46:10




Where did this number come from?


I am not sure whether it is really that bad. This quote doesn't have much info. Is 10 to 100x slower validation catastrophic? I don't know. But miners are naturally disincentivized to break the network and spend much time on validation (and, as you said, "you can blame miner if that happens").
Regarding the UTXO, please see this image:
Notice, that most of the UTXOs are less than 1 mBTC. If you constrain the on-chain capacity, you raise the fees and thus increase the amount of UTXOs that won't ever be spent. Also please note that small UTXOs are often being automatically created by wallets as a change.
So I believe that are other technical solutions can address this problem (other than constraining the on-chain capacity).
@_date: 2016-01-06 09:02:52
AFAIK there is nothing bad with the signature exposure unless you do it a bazillion of times (that you can't realistically do) and/or use a faulty random number generator. And a single signature doesn't leak anything at all. So you are safe even with a faulty random number generator until you spend the funds (and when you spend them and expose the second signature, the attacker won't have enough time to guess your private key and double spend it).  Please correct me if I am wrong.
@_date: 2017-03-25 13:56:42


Sorry, what do you refer to?
@_date: 2016-03-29 05:53:58
There is no such thing as "cash backed by BTC". Government-issued cash is the form of IOU. The idea of BTC is to get rid of trust to the third parties including the governments. Because governments always abuse their power to issue new money.
@_date: 2017-03-22 20:21:26
Well, it looks like Core are the most proficient and experienced devs here, so it would be very useful if they joined.
@_date: 2016-03-28 10:01:50
There is no need in millions of full bitcoin nodes running all over the world. Specialized clusters and light clients were envisioned by Satoshi at the very beginning. Anyway, if the desktop computer can handle 32Mb blocks then there is no reason to limit it to the 1Mb. Most people won't run the full node anyway.
We don't know whether the exponential technological trends continue or not, but we shouldn't artificially constrain the on-chain capacity. Capacity should be naturally constrained by available technology and market forces.
Perhaps the Lightning network is the future of Bitcoin transactions, but in the short term the block size limit should be signifiantly increased.
@_date: 2017-03-17 13:28:21
Perhaps if Core agreed to do SegWit without the "block weight" nonsense and then hard fork together for bigger blocks, then it could work.
@_date: 2016-01-25 01:00:18


You probably imply that it is cheaper to make transactions with a centralized database. Yes, it is true, so what?
It doesn't mean that we can't afford to have a less efficient solution and deploy it globally because we value some other properties of it.
@_date: 2017-03-07 18:14:23


Are you saying that the magic 1Mb number was objectively optimal when it was introduced as a temporary anti-spam measure when very few people used Bitcoin, and is still optimal?
@_date: 2017-03-22 21:10:46
No, the block size limit is easier to decrease than to increase. Decrease can be done via soft fork.
@_date: 2017-03-07 20:23:55
You refer to the article from 2015 that had been written before the [XThin]( was implemented and other software and hardware advances took place.
UTXO growth is a totally different problem. The increased fees exacerbate it by making the small outputs practically unspendable.
Why mix the things and make it more complicated? Nobody is against Segwit. Segwit is cool and solves many problems.
But the proposed complicated all-in-one solution that tweaks economic incentives via the soft fork is obviously contentious and probably suboptimal (especially if you consider socio-economic implications of the path chosen by the soft fork supporters).
@_date: 2016-01-27 20:36:51
Exponential adoption curve is the only way for Bitcoin to become the mainstream within our lifetime.
When you project the adoption curve, you will notice that the block size limit frozen at 1Mb is not normal. It is insanely small even if you assume that all the people use the Lightning Network. With small blocks only big institutions will be able to afford on-chain transactions (that are required to set up the payment channels). And nobody except them would be interested to run a full node (even if it is cheap).
@_date: 2016-01-22 19:25:08
What don't you like about this voting scheme?
@_date: 2017-03-26 09:34:21


Please apologize for your boorishness, stop attacking me, and provide a proof of your "fact", or, as you said, "Piss off".
@_date: 2017-03-09 10:06:17
Thanks to you too!
@_date: 2016-01-02 11:31:23
Just to make it clear: it was Gavin Andresen who [mentioned the technical debt in relation to the segwit]( Mike's article was published in August, nobody knew about segwit back then.
@_date: 2017-03-26 09:31:06
Sorry, didn't understand your point. If there is a hard fork, the lowest fees and fastest confirmation times will be on the side that has more hashing power.
@_date: 2017-03-25 08:33:33
Sorry for my English, when I said it is a not record-sized bird in hand, I meant that the USD value of the fees is not something in hand: it is volatile and may become negligible if people turn away from Bitcoin.


We don't need to guess. Pure logic. They invested this much in Bitcoin because they believed the value of mining reward will cover their investments and generate profits. This won't be the case with altcoins anytime soon. Miners are the most interested in the high price of Bitcoin. And they will do anything to maximize it. And they will definitely do something because the status quo is unbearable. Either SegWit or a 2Mb hard fork. I think the latter is closer to activation.


I think you overestimate the risks of non-contentious hard forks. Bitcoin is designed to be anti-fragile and I don't see the reason why miners wouldn't agree to a 2Mb temporary consensus. There is unlikely to be any noticeable loss of hashing power. And it doesn't prevent other scaling solutions after the urgent need in block space is satisfied.
And you probably underestimate the positive aspects of hard forks. The network is healthy when all the full nodes can fully validate all the transactions.
@_date: 2016-01-03 08:10:10
You are correct, people want stuff for free, so give it to them. We have this opportunity to popularize bitcoin at the expense of bitcoin holders that subsidize fees with a block reward. Bitcoin holders agreed to it when they decided to buy and hold bitcoins. By imposing fees earlier than needed, you rob them (since they still pay the block reward for a service that you make others to pay for too).
If you don't pay fees, you may wait hours or days for their transaction to get confirmed. So there is still incentive to pay it. But fees are not important yet, they are just anti-spam measure. And let it be so until Bitcoin becomes mainstream and block reward approaches 0.
@_date: 2016-01-06 20:16:59
The public key is supposed to be public. Shouldn't be a big problem. But I respect your decision and your right for privacy and security. Thanks for your feedback!
@_date: 2016-01-27 19:10:07
If you control &gt; 50% of the hashing power then Bitcoin has a problem anyway.


Quite the opposite. Small blocks means centralization because fewer entities (e. g. only banks) will afford to transact via bitcoin blockchain on a daily basis.
If you write to the blockchain only twice per year then you are unlikely to run the full node yourself.
Bigger blocks would allow more transactions and more entities to run a node. It is not as expensive as you might think. Virtually any bitcoin enthusiast/entrepreneur can afford to run a full node with much, much bigger blocks. Gavin Andresen didn't buy a supercomputer to conduct his 20Mb tests.
The mining centralization pressure grows with the block size - that's unfortunately true. But it is not the main factor (cheap electricity and hardware is more important).
The real problem is the Great Firewal of China and the fact that the majority of the blocks are being found behind it. Theoretically it gives Chinese miners a small advantage, but still the orphan rate increase for the 2-3 mb blocks is negligible. Further optimizations will allow to decrease it even more and allow even bigger blocks.
@_date: 2017-03-22 21:19:00
Most users don't run full nodes, they run SPV or light wallets on their smart phones.
Only miners and businesses have a reason to run full nodes.
But, as Raineko said, unlike the hashing power, node votes can be easily faked.
@_date: 2017-03-22 21:43:57
I personally will accept whatever miners decide regarding capacity increase.
update: Weird. Downvoted for my personal opinion. Do you always downvote the ones you don't agree with? Are you guys serious regarding the PoW change? :)
@_date: 2017-03-22 20:54:18
They won't because they know that if they did, the value of the currency (and hence their reward) would plummet and they would be left with tons of expensive yet useless hardware that nobody would have a reason to buy from them.
@_date: 2017-03-25 10:45:43


Miners don't have all the power. If they mine something the economic majority wouldn't accept, they loose money. They won't have resources neither incentive to mine the coin that is not demanded.
However miners must have some power because they are part of the Bitcoin ecosystem. They are the most heavily invested into Bitcoin infrastructure and they are the most interested in the value of Bitcoin. You can't just discard them.
So, both miners and users (including businesses) should have the power. Bitcoin has no a central authority. Not a single development team can dictate its solution as the only option. Developers is the only party that is not supposed to have any power. They just write the code and propose solutions. Miners and users decide.
@_date: 2016-01-25 19:15:20


If current technology can safely handle 3Mb blocks then BIP 103 is too slow because it starts from 1Mb. Current home computers can probably handle much larger blocks. However BIP 103 is still better than the fixed block size limit.


The cost of running the node is the reason why SPV exists. However it is still a matter of preference, you can choose not to depend on the third parties and run a full node yourself. Home computers and communication channels are able to handle much larger blocks. Gavin experimented with 20Mb blocks, remember?


Nobody is speaking about gigablocks right now. But in a few decades future your cell phone will probably able to handle them without a problem.
@_date: 2017-03-23 05:53:06
Bitcoin holders are the overlords. They currently pay miners about $12.5K per block in bitcoins to protect the network.
So if you own a little bit of bitcoin, then you implicitly pay them. Their have incentive to maximize the value of their rewards and your holdings.
@_date: 2017-03-23 05:18:02


They would anyway, the only question is the cost of running a node. It will be more expensive than SPV and light clients anyway. You can't rely on the end users as a typical node runner.


You may call it a dogmatism, but that's kind of a social contract accepted by early adopters who invested their time and money to Bitcoin economy and brought it to success.


While it is true that full nodes limit the fraud capabilities by checking the whole blockchain, well connected SPV wallets are pretty safe for personal use.
Yes, this requires some trust, but it is still decentralized. Theoretically Bitcoin can work without trust, but on practice you trust other developers and security experts to create and review the code. And that's fine as long as they are independent and there are plenty of them. Same is true about SPV wallets. Remember, it is sufficient to connect to just a single honest node in order to reliably verify a transaction.
And if you need an enterprise-level security to receive millions in transactions, then you can afford running a full node anyway (whereas your business might not afford to pay high fees while sending small amounts to millions of your customers).
Don't you see that "most users run SPV wallets + many businesses run full nodes + low fees" is a more plausible scenario than "most users run full nodes + fees are too high for most them to transact"?


Me too, but I don't see a solution to this problem yet. Economy at scale gives advantages. Even if ASICs were not possible, we would end up with large mining farms that buy the best hardware for the best price, pay the best electricity rates and use the human labour the best possible way.


Bitmain sells the hardware it produces. Why does it do it? Just think about it.
It is definitely interested to be a big fish (it would be foolish or even illegal to not use its competitive advantage), but it is not interested to diminish the value of Bitcoin that comes from its decentralized nature. Neither it is interested to shrink its markets. If/when Bitcoin becomes a stable mainstream currency, mining won't be a very profitable business, but developing and selling the hardware will probably still be.


It is OK to split if for a short period of time. Little splits happen all the time (orphaned blocks). But it is not OK to split off a significant part of Bitcoin forever.
I think it is quite likely that if over 75% of the hashing power decides to do the hard fork, the remaining miners will join it and the minority fork will die out pretty fast (or it will need to hard fork again to re-adjust difficulty or even change PoW, which is unlikely). And I sincerely hope there will be no hard fork until the proponents of the fork reach 75% of the hashing power.
@_date: 2017-03-16 08:23:13
That's fair, Bitcoin holders should have some influence! That's good for Bitcoin as a whole.
@_date: 2016-01-02 14:30:58
You might be interested in this project:  (even though it is a centralized service, it is transparent and uses the blockchain data to evaluate voting results). 
@_date: 2016-01-20 19:56:46
There should be no central entity that controls Bitcoin. Nobody fires the core devs. Competition is good. Let the market decide.
@_date: 2017-03-25 13:52:22


Not a fact.


Please re-read the Satoshi paper. It is about Nakamoto consensus and peer-to-peer electronic cash system. If you ignore it, there will be no long term for Bitcoin.
@_date: 2017-03-27 07:44:33


You probably read calculation based on some simplistic model that doesn't consider a lot of real life factors. On practice fees are set by market, they depend on luck, supply and demand for the block space.
SegWit increases supply of the block space up to 4mb but doesn't allow transactions (without signatures) to take more than 1 mb.  The remaining space is left for signatures (witness data). And it changes the way how fees are calculated: it subsidizes the witness data at the cost of transaction data.
Regardless of the scaling solution, if nobody uses Bitcoin, the fees will drop to 0. If Bitcoin adoption outpaces its capacity, the fees will continue to rise.
@_date: 2016-01-21 21:37:44
Cool idea, but not a panacea.
Alice could create a doublespend transaction that sends x/2 to Bob. In that case Bob doesn't have incentive to broadast tx2.
There are probably better ways to make 0-confs safer. Fees are just the anti-spam measure. We shouldn't worry too much about them while they are being subsidised by the block reward, or we risk to fail reaching the mainstream.
@_date: 2017-03-26 14:36:42


Can you prove it?
I think you misunderstand what SegWit is, how hashing power affects confirmation times and how block size and hashing power affects fees.


Maybe, but there is no consensus regarding SegWit. There are various solutions to solve the long term problems. And all of them, including SegWit, can be implemented with bigger blocks.
There is a consensus that doubling the on-chain capacity is OK and 2Mb blocks are safe.
@_date: 2016-01-03 07:58:58
So raise the block size limit, as easy as that. Bitcoin is not mainstream yet, it is too early for the fee market. 1Mb anti-spam cap worked for years (while hardware and software was being improved). It is time to raise it now.
@_date: 2017-03-07 18:46:04
this is not just some poll, this is the cryptographically proven votes of the stakeholders
@_date: 2017-03-25 13:44:45
Thanks for your answer!
By "we" you mean Core developers?
But that's not the developers who compromise, that's the community which includes many parties with diverse interests, including miners.
Developers' role is not to compromise, but to write a great code that would express the possible consensus. So I am just asking you to write or at least agree to accept the code that would express all the safe possibilities and let the market participants find a compromise consensus.
@_date: 2017-03-18 18:24:58


Did you even read my message up to the end? I answered this question in the very next sentence. I completely agree with you, people will turn away from Bitcoin before the average fee hits $100.
@_date: 2017-03-23 10:24:17


That's right in case if we set the block size to 100 Mb or so. My current bitcoin folder takes ~127GB. And I am happy that it is not 12.7 TB. But nobody is advocating for 100Mb blocks right now (perhaps in 20 years it will be possible, but not now).
Bitcoin economy is diverse, it won't just instantly die if some disk/bandwidth/cpu/memory usage hits a certain magical threshold. If something goes wrong and starts affecting users and businesses, there will be some time to adjust.
And I feel that now the high fees for on-chain transactions are affecting users and businesses, and it is the right time to adjust something in order to fix it.
I hope the Core devs eventually recognize that it turned into a severe problem that needs urgent fixing regardless of other things.
At least there is some consensus that doubling the capacity and the block data is safe.
@_date: 2017-03-18 19:06:41
The problem is it is hard to know what is the economic majority. But it looks like miners and [bitcoin holders are in favor of the fork](
@_date: 2016-01-02 14:32:57
Why would someone pay you to vote if it is possible to vote with one's money directly? :)
@_date: 2016-01-26 04:25:09


"[a few usually refers to an indefinite, but usually small, number greater than two](


Sure I am aware of it. There are physical limits on the transistor density, but the exponential nature of technological progress still exists.


You are breaking the causality. Lightning is a consequence of Bitcoin's traction (that wouldn't have happened in case of a permanent 64kb block size limit).
Lightning is a neat idea that will probably prove itself useful in the future. Ever-growing block size limit doesn't contradict Lightning.
@_date: 2017-03-16 20:43:17
And there will be no stability if it doesn't become mainstream. And it won't if it doesn't scale fast enough.
@_date: 2017-03-07 18:56:16
You said that "Objective reality rules all in programming." and that the arbitrary 1Mb block size limit is "not necessarily" an optimal number, but "raising it indefinitely isn't the correct answer" and "in a reasonable world, the 2MB hard fork is completely and utterly pointless.".
So it looks like basically you don't know care what is the optimal number in the objective reality, you just don't want to raise it. Are you saying that the blocksize limit is irrelevant?
@_date: 2016-01-27 01:21:08
Yes, it would. So what?
Web apps are also extremely inefficient, but are increasingly popular.
@_date: 2017-03-22 09:42:07


The bug is that it limits the effect of legit transactions as well. When it was introduced, all the legit transactions could fit the block. Now they can't, and its a bug. This limit was a temporary simplistic anti-spam fix. There was a clear intention to increase it when the amount of legit transactions approaches it.


Doesn't it allow more data in block than the 1mb limit is supposed to allow?
@_date: 2017-03-25 14:43:46
Who is going to fight back, sorry?
@_date: 2016-01-21 20:55:33
[Bitcoin holders think it should not be adopted]( So if released - should be disabled by default.
@_date: 2017-03-16 08:46:40
Politicians may say whatever they want. Regardless of what they say, they behave in their own interests. Unlike others, Roger has quite a lot at stake. He risks the value of his bitcoins. Whereas Adam is risking the value of his company. Do you see the difference?
@_date: 2017-03-22 15:33:55
How long would it take you to upgrade the node if it went down due to a software bug?
@_date: 2017-03-21 06:51:53


1 MB blocksize limit rule is not a consensus rule, it is a temporary anti-spam limit and there is obviously no conensus about it at the moment.
@_date: 2017-03-18 16:44:04
Fees are much more important than the cost of running a node.
Even if the cost of running a node reaches $100 per month, there will be plenty of businesses willing to run their own nodes.
But if the fees are $100 then nobody will want to use Bitcoin and run the nodes even if they are cheap to use.
The fees are unlikely to reach $100 though. Bitcoin price will plummet before that because people will use other coins as you propose.
@_date: 2017-03-16 08:19:13
Oh, that's good. It means his interests are aligned with interests of Bitcoin holders. His influence should be good for Bitcoin.
@_date: 2017-03-27 04:38:37
It looks like you haven't visited the link or do not have enough intellectual capabilities to understand what's written there and to argue in a civil manner. Since you didn't apologize and continued attacking me, I must end this discussion.
@_date: 2017-03-18 20:03:41
This voting platform had been created by me long before it was moved to Roger Ver's website. It is more or less censorship resistant, nothing gets deleted. Much more resistant than this reddit ;)
Imagine that Roger wants to censor something. How would he achieve it? By removing the signatures?
But the signer can always publish the signature elsewhere and Roger will be forced to put it back or the site reputation will be ruined.
The software is [opensource]( if you don't trust Roger, you can install it independently and use it to collect the votes. It is also possible to implement automatic signature synchronization since signatures are being published in a machine-readable JSON format, e. g.: 
Regarding wallets and public keys, it is a valid concern, but this factor influences both sides equally. If you are strongly pro/against something then you can take some (pretty low) risk to express it.
@_date: 2017-03-07 18:03:42


Are you the majority? Be vocal: 
@_date: 2017-03-09 08:48:28
Oh, it seems I mistakenly assumed that the native segwit address implies a hard fork implementation (that is not the case). That's an example of my bias and wishful thinking :) Thanks for clarifying!
@_date: 2016-01-25 00:52:49
After Bitcoin becomes the mainstream, small transaction fees won't kill it.
But artificially constrained capacity and premature fee event may hinder it from reaching the mainstream.
@_date: 2017-03-18 19:50:15
Perhaps. But they won't be able to do it with Bitcoin. Because if you want to transfer large amounts of money, the currency you use should be big enough. If most users turn away from Bitcoin, it will cost peanuts, and it won't be possible to send large amounts of money with it.
People that are ready to pay $100 per tx are not the typical bitcoin users. But it is typical users who give the value to the network.
@_date: 2017-03-25 16:31:12


Stop being rude, that doesn't help.
If you can't prove anything, then don't claim that it is a fact.


And desktop CPUs are mainly produced by Intel and AMD. So what? 
The economy of scale will lead to centralization anyway unless there is a force to compensate this tendency. E. g. when the price stabilizes and you will be able to buy a heater with mining capability, it will lead to de-centralization.
Didn't understand about Pleasure Island, not a native speaker.
@_date: 2017-03-12 15:04:28
Thanks for the explanation!


I see the problem here. It looks like almost any contentious change can be deployed via soft fork to circumvent the consensus requirement. Do you agree?
@_date: 2017-03-16 17:09:06
I think you misuse the word "IMMUTABLE" here. The most popular IP protocol is version 4, not version 1. And the block size limit is not mentioned anywhere in the paper, it was set as a temporary anti-spam limit. Satoshi proposed a way to increase it via hard fork. That was Bitcoin all the early adopters subscribed to.
I don't know you, but you look so confident that I must ask you: are you sure that your technical knowledge is deeper than Roger's?
What about Gavin Andressen, Jeffs Garzik, Mike Hearn, Vitalik Buterin? They all are just a few experts of many that want to have a blocksize increase via the hard fork. And they have good reasons for that.
PS: The decision to be made is not only technical, it is socio-economical as well. You can't just discard the technological advances, holders' preference and rise of competition. Technical experts that have nothing at stake are tempted to discard these factors in favour of their idealistic vision, but due to them the first mover advantage can be lost.
@_date: 2017-03-18 19:20:43
Do you mean that the size of the blockchain is not that important, it could be increased 4 times without increasing the centralization pressure significantly, but the on-chain capacity of Bitcoin should be increased only twice because otherwise the UTXO bloat will become unacceptable?
@_date: 2017-03-07 18:46:45
good point, perhaps a feature request.
@_date: 2016-01-13 09:32:03
Are you still not seeing any sign of censorship here? Try to collapse your own comment and notice the CSS bug that has been intentionally introduced to disallow it. All sorts of dirty tricks are being used to suppress the pluralism. 
@_date: 2017-03-19 00:19:47


Right, thanks for correcting.


I guess we were talking about the cost of bootstrapping the node.


If you are talking about Satoshi, who designed the system, then you are wrong, he expected it, and so did all the early investors. Exponential adoption is the only way for any tech to go mainstream. The blocks were not supposed to be full. 1Mb limit was a temporary measure. Satoshi himself proposed the way to increase it.
I agree that the adoption curve is likely to outpace the technological curve (though both curves are exponential). As Core developers said, the demand for storage is unbounded. But I believe that there is some room for on-chain scaling while the second layer solutions are being developed. There is no need to make the fee shock event happen, as it may destroy Bitcoin's first mover advantage.


Agreed. Unless the economic majority runs software compatible with the fork. If it does, then the majority fork will become the new Bitcoin, and the minority fork will probably die before it reaches the next difficulty adjustment. Nobody is going to fork with 51% of hashing power, but there are people who try to convince users to run a compatible software. It is difficult to do though due to censorship.
@_date: 2017-03-18 20:46:30
Assuming nobody is trying to fill the blocks with spam.
I don't think assumes this :)
@_date: 2017-03-18 20:36:13


You referenced to a lengthy post made 1.5 years ago. I assume many optimizations took place since that. Are you sure it contains a valid answer of why 6 tx per second is the maximum safe value for on-chain transactions? I can find even older post that demonstrated that ~60 tx per second are safe, but won't refer it to you because it is outdated and not that convincing.


Well, it was you who said first that miners could be blamed :)




If users stop transacting on-chain, then yes, it won't grow. But if they transact, then the tiny change will always be created by their wallets. It will be too expensive to spend it.


Wallets do combine outputs when it is needed. The problem is it makes transactions much more expensive. I had to pay ~$50 fee for transactions that had over a hundred of inputs. So, yes, maybe I contributed to the drops you mentioned. Don't want to do it again.
@_date: 2016-01-06 08:33:03
By moving bitcoins used to sign the statement you would kill the value of your vote (time to time Bitcoinocracy updates the balances to track the actual value behind each statement).
If you use 1 address per statement, then there will be no address reuse until you actually spend the money. The risks are marginal since cryptographic signatures are supposed to be secure (unless you use a faulty random number generator).
Btw, it is not exactly equivalent to [address reuse]( since no transactions that potentially link all bitcoin addresses of your wallet to your personality are broadcasted to the network.
Probably the major risk here is your computer that might leak the keys when you use them. Hardware wallets solve this problem.
@_date: 2017-03-16 17:24:47
Roger spoke about fiat and banks. I remember that MtGox had problems with fiat withdrawals. It took weeks to months to withdraw. These problems were not related to the theft of bitcoins (that nobody was aware of). So I don't see what you blame Roger for.
@_date: 2017-03-16 20:41:16
Are you saying that it is spammers who pay about 220 satoshi per byte or $0.6 per transaction? (according to 
Raise the block size limit and it will become much more expensive for them to fill it.
@_date: 2017-03-22 20:07:04
It looks like you assume that users run full nodes, but that is not the case. Users run SPV or other light wallets on their smartphones, they don't dedicate much resources to Bitcoin network.
Only miners and businesses have a reason to do it, and it is perfectly fine. If Bitcoin is used by many then there will be plenty of businesses that will afford running a full node. Satoshi predicted it, that was a vision we all subscribed to.


I think that Core devs pose the risk to Bitcoin. Despite the fact that they developed smart technical solutions, they failed to solve the real economic problem and brought us to the situation where users have to pay a fee of 220 satoshi per byte. The problem of the high fees had been totally predictable a few years before, and the Core devs just discarded it as unimportant or even a wanted outcome!
That's why I assume there is a conflict of interests and I don't trust them despite they are great devs.
You probably know from the other sub which company funds the most influential Core devs. If you think there is no conflict of interests, please let me know what is that company's business model and why it funds them.
I don't say that they want to harm Bitcoin, I am just saying that they turn Bitcoin into something that is good for them, but not necessarily for bitcoin holders.
And I believe that miners want to profit, so they would not do anything that hurts Bitcoin. You say they want to get more power, but it doesn't make sense as this power would destroy their own income. And unlike developers, miners have a lot of value invested in hardware, they can't just switch to another project.
Frankly, when the Core devs are seriously talking about the PoW change while calling the competitors an altcoin on the censored forums, I am happy that they don't have nuclear weapons, because it looks like they would use any means to eliminate contention and thus achieve their version of consensus.
Cryptocurrency will be decentralized. If Bitcoin protocol is taken hostage by a single development then de-centralization may be achieved by other ways, the value will just flow to other coins. Look on the [chart]( Don't you see a tendency here?
Bitcoin must not be split, it should be strong and should endure the protocol upgrade.
@_date: 2016-01-03 08:56:13
AFAIK only a small portion of the block is dedicated for the low-fee transactions and no, it is not first-come-first-serve. There is a formula to calculate the transaction priority based on various factors (age of inputs, transaction size &amp; value, etc). Not sure about the details though.
Bitcoin needs to cost much more than it is now in order to serve the big world economy. That's not just my personal interest.
Thanks for evaluating my attitude and the way of my thinking. Very polite of you, thanks again.
@_date: 2016-01-05 17:43:07
[I believe that RBF (Replace-By-Fee) policy should NOT be adopted because it breaks 0-conf transactions and needlessly imposes extra development costs on existing merchants]( -- signed by $~1.6M worth of btc.
@_date: 2017-03-25 10:56:40
Both on-chain and off-chain scaling will be needed, no doubt. I think opposing sides agree on that. The only question is what do we do in 2017 to overcome Bitcoin's self-imposed capacity limit.
@_date: 2017-03-28 08:57:06
Well said!
@_date: 2017-03-16 23:56:51
Same myths again and again. It is a myth that on-chain scaling is impossible without significant increase of centralization pressure. It is a myth that common users will be running full nodes on their PCs, laptops, tablets and smartphones.
Larger blocks mean lower fees, more transactions, more users, more businesses that run their own full nodes, more privacy and more decentralization.
Bitcoin should scale on-chain while it is possible. There should be no fixed limit. If hardware and software improves over time, then the block size limit should grow as well.
Core devs are right that the demand for the block space is unbounded and we need a 'caching layer' on top of Bitcoin. But nobody suggests to supply huge blocks right now. A modest increase would relief the fee pressure while second layer solutions are being developed and adopted.
If Bitcoin becomes mainstream, one bitcoin will cost over a million of dollars and most of the transactions will be done via payment channels.
But if you "sacrifice short term adoption" then you increase the risk that bitcoin will cost nothing and nobody will be mining it.
There is no such thing as "sacrifice short term adoption". Mass adoption can be only exponential. The short term is the most important thing. If Bitcoin is limited in the short term then some other coin will take the market.
@_date: 2017-03-23 09:48:26


Ok, now read something that "He states he did not author".
I don't quite understand your argument. I stated that bitcoin price is more important for miners than the fees. And it will be so for a foreseeable future. Bitcoin has the potential for doubling faster than the halfening of the block size reward.
Do you agree with that?


Nope. Price is the only thing that matters. If it is high then the equipment will be replaced.
If the blockchain forks then the mining power will support the most expensive fork. If the price plummets as a result of the permanent network split then, yes, the hashrate may drop. But if the hard fork is successful, it will go to the moon.


No, but I seriously believe there might be a conflict of interest. I see that the Core devs don't take interests of Bitcoin businesses seriously.
Due to the Core's inaction many bitcoin businesses are forced to adopt altcoins, limit deposits/withdrawals, impose additional fees on users. I had to pay ~$50 transaction to move the funds from multiple inputs to just 2 outputs. That is a fact.
It is quite reasonable to expect the Core devs to align their interests with the interests of the entity that pays them, don't you think?
Regarding the conspiracy theories, do you seriously believe that miners would block any solution that fixes malleability, including BU with flexible transactions?
@_date: 2017-03-22 20:26:50
No, this percentage means nothing.
Amount of work depends on the value of (reward+fees), not vice versa.
It would be much better to do 16% less work and get rid of high fees.
@_date: 2017-03-18 18:45:37


So they indeed increase the block size via a trick: they introduce a separate constant "block weight" (see  ) to circumvent the non-upgraded "full" (now in quotes) nodes and at the same time to subsidize the witness data. If I got it right, it will allow up to 2x more on-chain transactions while taking up to 4x more block space.
Please correct me if I am wrong.
@_date: 2017-03-07 18:25:54
Then are you saying that the optimal number is lower than 1Mb?
@_date: 2016-01-26 02:03:35
I didn't say anything about 20 years. But if you like this number, you should be aware, that 20 years ago (in 1996) something like Pentium MMX (166Mhz) with 16Mb RAM and 56Kbps modem was a high end PC with cool connectivity.
Modern smart phones are orders of magnitude more powerful.
x10 progress over 20 years is equivalent to x100 progress over 40 years.
So if modern desktop computer can handle 10 mb blocks now (and they can), then in 40 years a smart phone (or whatever gadget you use instead) will probably be able to handle 1Gb blocks without a problem.
That's a pure speculation, but imagine if Bitcoin was constrained to a fixed 64Kb limit back then. It would never get traction.
@_date: 2017-03-27 18:46:05


Miners are heavily invested in potentially useless hardware and have incentives to maximize the value of Bitcoin, not to diminish it.
And who is in charge of the block size limit now? A single development team! What do they have on stake, what are their incentives?
@_date: 2017-03-22 04:29:01


"Nodes can leave and rejoin the network at will, accepting the proof-of-work chain as proof of what happened while they were gone. They vote with their CPU power, expressing their acceptance of valid blocks by working on extending them and rejecting invalid blocks by refusing to work on them.  Any needed rules and incentives can be enforced with this consensus mechanism."
[(c) Satoshi Nakamoto](
You are right that the current 1Mb limit is technically a consensus rule. As well as it was the bug that caused a hard fork during upgrade from 0.7 to 0.8. I sincerely regret that a centralized action took place back then, it has set the precedent and authority of the single development team. But that bug was a de-facto consensus rule enforced by miners as well. So what? It has been fixed eventually. Protocol upgrades are possible.
Now  the 1Mb anti-spam limit turned into a bug too. It was a valid temporary solution when Bitcoin usage was not so widespread, but now it is just a bug that constrains Bitcoin capacity, breaks valid use cases and diminishes network effects by high fees.
And instead of solving this bug, the Core developers designed a way to circumvent the consensus rules enforced by full nodes and miners.
@_date: 2017-03-22 21:42:36
oops, sorry
@_date: 2017-03-27 06:40:13


That's the problem. We make judgements based on information distorted by censorship. If you really want to understand the opposing point of view, you might want to read the other sub.


The transaction may appear smaller, but the amount of data transferred and stored doesn't become smaller. SegWit potentially doubles the capacity while potentially quadrupling the amount of data to be transferred and stored. The capacity increase is not immediate though, it depends on user adoption of SegWit transactions. And if a hard fork happens and SegWit looses most of the hashing power to a 2Mb hard fork, then its capacity will be several times lower (and if users continue using it then the fees would rise dramatically).
@_date: 2017-03-18 21:54:09


You are not the only software engineer here. Doubt is a virtue, it is a sign of critical thinking.
As an engineer, you are familiar with big-oh notation and you measure the costs in terms of bandwith/storage/processing power.
These metrics indeed are doomed to grow linearly by design (assuming the block size limit is fixed). But this mathematical cost is irrelevant, the real monetary cost is what affects decentralization of Bitcoin.
If you freeze the blocksize limit, it is reasonable to expect that the cost of boostrapping and running the node will  decline (as long as technology and economy continue to grow exponentially), but the cost of transactions will increase until people realize that there are cheaper decentralized blockchains and move to them. But our goal is not reducing the costs, but increasing the adoption while preserving the reasonable monetary costs, isn't it?
I outlined this particular moment, because it prematurely breaks the expected exponential adoption of Bitcoin. If Bitcoin stalls here, it risks to never reach the mainstream. When people realize it, Bitcoin price will plummet and loose the first mover advantage. Due to the increased fees, many businesses are working to support altcoins. Bitcoin is not the only currency that can be used as a base layer for payment channels. Bitcoin dominance is an all-time low. You must be blind if you don't see it.


No, it is not Bitcoin, it is the Core devs that resist hard forks. Bitcoin by design can be forked with only 51% (though very risky and highly undesirable for obvious reasons).
@_date: 2017-03-25 14:35:03


I didn't mean there is no Chinese dictator. I meant please supply the proof of your claim before calling it a fact.


That's what I wanted to ask.
If you read more than 1 sentence from that paper, you would probably understand that "One-CPU-one-vote" is a simplistic explanation of voting based on proof of work. Faster CPUs always had advantage by design than slower ones because they did more work.
Even if Bitcoin protocol was based on proof of CPUs you would still see huge miners (who bought cheap CPUs at a wholesale price and set up their mining farms in places with cheap electricity) and accuse them in dictatorship.
That's just economy of scale and a free market with its tendency towards concentration of capital.
So you don't like proof of work? Or are you against the free market?
@_date: 2016-01-25 04:56:01
What's wrong with gigablocks in the far future? Do you really think the block size should be measured in megabytes forever? Why?
@_date: 2017-03-18 19:11:41
Gavin Andressen said "Segwit is cool" and many big blockers agree with that.
The problem is Core's implementation of "Segwit" comes with a hack to circumvent the "fully validating" nodes and to increase the block size limit 4 times while subsidizing the segwit data and increasing the on-chain throughout only twice.
@_date: 2017-03-18 20:20:48
Well, you assume that Bitcoin can't be scaled on-chain. But there is no evidence it is true. Bitcoin probably can scale on-chain exponentially (slower than its adoption, but still exponentially). Eventually most of the transactions will happen in payment channels. But at the moment, at this very important moment, we need more on-chain capacity. Unless you want altcoins to prove that 3 or even 6 tx per second is not the limit for a decentralized blockchain.
@_date: 2017-03-26 09:27:06
You pay too much attention to a single man, you assume that he:
1) controls most of the hashing power and can dictate his will to everybody else
2) is greedy but stupid and doesn't understand what's best for him
3) is proud and will do whatever is good for his ego, not for his pocket
4) is anti-bitcoin and wants to make a 51% attack on Bitcoin
I believe all of these assumptions are doubtable. 
1) I doubt he controls most of the hashing power. Please prove your claim.
2) I doubt that he is stupid. Stupid people normally can't start a business from scratch and earn wealth and influence.
3) I doubt that his pride means more to him than his pocket. Irrational people don't succeed in business.
4) I doubt that he is anti-bitcoin, his incentives are aligned with interests of bitcoin holders and users, and I believe "51% attack" is a wrong name for a protocol upgrade (especially if there is no proof that he owns 51% of the hashing power).
You also assume that the economic majority is represented by bitcon wallets, and 94% of bitcoin nodes are firmly against a BU hard fork. I haven't seen any proof of this. The numbers of wallets and nodes can be easily faked. Even if they are true, they don't mean much. E. g. I am running a Core node because this software is proved to be reliable, but I am not against a hard fork. I'd admire Core if it gave me an option to follow a fork if it happens.
I sincerely believe that unlike miners and users, developers shouldn't have power at all. They can't compromise because they don't have a power to dictate consensus. They only implement various options that might reflect consensus. And the market will chose the best option. If there is a demand, it will be satisfied, regardless of the team that implements the demanded option.
So despite all the propaganda I see here, most of it doesn't pass my critical thinking filters. Please let me know if I missed something.
@_date: 2016-01-25 14:25:19
No, I say that the arbitrary block size limit serves no purpose. If the block size limit is justified by the underlying technology then it serves the purpose of the anti-spam defence. But the technology has evolved and is going to be evolved at a pace of 17.7% per year (and libsecp256k1 alone gives immediate ~x5 increase).
Come on, bitcoin nodes run on virtual servers without a problem. Of course it would be nicer to have more nodes, but there is no necessity for everybody to run a node. Most of the users will use SPV-wallets anyway, it was expected and there is nothing to do about it. Most businesses and enthusiasts will always be able to run a full node if they don't want to depend on the third parties. And for miners running a node costs about 0% of their expenditures.
@_date: 2017-03-26 14:42:59
You said "Fact we have a Chinese dictator and we are not going to compromise.".
I doubt it is a fact. Let's start with the Chinese dictator. From you other messages I understood that you meant Jihan. To avoid copy-pasting, I am referring you to this comment:  
Feel free to reply there.
@_date: 2017-03-24 05:36:00


There is no such thing as a BTU coins yet, and I hope that the chain won't be split permanently. There is some significant support for the idea of emergent consensus from businesses and miners though: 


Because the fees are lower than volatility of Bitcoin. The price goes back and forth 30%, whereas the fees are about 10%. The fee revenue is not record-sized bird in hand, it is just noise (which USD value may become negligible as businesses continue adopting altcoins). Remember, we are talking about long-term changes. In the long term high fees would diminish the value of Bitcoin.


No, the price could have been much higher today if not the network congestion. Bitcoin dominance is all-time low. That means Bitcoin miners are leaking revenue to alt coin miners. That is much more serious than you seem to think. It is a huge problem and risk for miners who invested a lot in hardware.




Please stop appealing to the meaningless numbers. That's not about numbers at all. That's about the most influential developers who set the direction, benefit from censorship and ostracise the dissenters. Most developers contribute to the reference client because it is the most popular one. If Core looses leadership, many will probably realize that there is no central repository for Bitcoin and join other projects as well.


I don't doubt their expertise, they won't deliver low quality product.
But I have a reason to doubt their incentives because they directed Bitcoin development in such a way, that many bitcoin use cases became unavailabe and many bitcoin businesses were forced to start actively adopting altcoins.
That's the bigger picture and the total responsibility of the Core team which have been stalling the scaling progress for a few years!
The problem had been well known long before they proposed SegWit. It took 2 years to develop SegWit and it is not clear yet if it even gets adopted. And if not, they'll change PoW to make it happen? What a failure!
And they didn't even acknowledge it. They think they are right, because they don't care about miners and don't care that the average Joe won't be able to buy a cup of coffee on-chain. That would be OK to say after on-chain capacity hits the hardware limits and LN is already widely adopted. But they decided to sacrifice the Joe's ability to by a cup of coffee before that happened. It hurts businesses.


"Unanimousity" is not the right word here. Unless you mean North Korea type of unanimousity. E. g. Coinbase tried to be vocal and got abused and banned on the censored forums. Various companies have various interests. Of course there are fervent Core supporters as well.


Yes, I did. There are things that I don't like about SegWit. I don't think these issues are blocking, but they rise contention, though at the moment I'd be happy with any progress on scaling, because we need to take every opportunity to increase the throughput.
I agree that contentious forks are somewhat risky, but a 2 Mb hard fork doesn't seem to be contentious (since SegWit implies 4Mb 'block weight' limit and potentially doubles the capacity).
Hence 2Mb non-contentious hard fork could probably be a reasonable compromise. And after that other ideas (such as malleability fix, emergent consensus, UTXO growth incentives fix, flexible transactions, upgrading via soft forks, etc) could be addressed one by one. It would be much, much easier to get consensus on one change at a time.


How do you know it was he? In the post referenced by you there was a disclaimer that he explicitly said he was not the author of the text.
@_date: 2016-01-21 20:50:09
Opt-in for sender, but opt-out for everybody else.
Majority agrees that [RBF (Replace-By-Fee) policy should NOT be adopted]( So if deployed - should be disabled by default.
@_date: 2017-08-08 13:39:59




You are wrong.


Where do you see the inconsistency?
@_date: 2017-08-08 12:12:49


I think it is short-sighted to ignore the fact that low fees are crucial for preserving Bitcoin's network effects and first-mover advantage.
And yes, Bitcoin was born for people and businesses, not for a single government or organization to control it.
Please recognize the fact that currently it is controlled by a single team of trusted devs backed by censorship on the major discussion platforms. That's why this place is called "North Korea" on the other sub.


I was talking about the average transaction, not about multi-million dollar transactions only large businesses can profit from.
$1 is not cheap, but a bigger problem is that it may easily turn into $10 or $100. Large corporations (the ones you presumably oppose to) would enjoy the opportunity to send millions for cheap whereas average Joes won't be able to compete with them for the block space. And Lightning won't change this, it may even make it worse if it is used as an excuse to stall the future on-chain capacity increases. There is a risk that people would be forced to ask a permission to open or close a payment channel instead of just paying an affordable fee for it or transacting with strangers directly.
@_date: 2017-08-07 09:00:28


You banned a few links, but it was allowed to discuss/promote BIP148 here unlike other non-consensus software. Segwit itself (widely promoted here) got consensus only after the NY agreement. Hope the 2x part of it will be promoted as well and will not be treated as non-consensus software :)
@_date: 2017-08-08 14:12:29
You don't know what this word means.
@_date: 2017-01-24 12:49:45
Yes it is. That effectively turns them into 98% of potential customers that would call that a failure. Only 2% can be served anyway.
Or, to put it in other words, only users who really need to access your website would spend extra time/effort trying to access it under the load, while others would have to wait until the load decreases (or just find some other website to visit instead of the one that failed). So the analogy is quite correct.
@_date: 2017-08-08 09:03:04
The unity. Segwit2X has a chance of re-uniting the community. There will always be extremists on either side, but the network effects are much stronger when there is only one Bitcoin.
And a one-time non-binding increase of the block size wouldn't harm anyway. Don't delusion yourself with temporarily low fees. If Bitcoin is successful, they will grow again pretty soon. 
Update: though current fee of ~$1 per average transaction can hardly be called "low".
@_date: 2017-01-24 19:36:59
It does load within a minute with a 2% probability. According to your logic, if you don't want to spend an hour trying to refresh the page every minute then you don't really need it and hence it is not a system failure, but just your HTTP request was not that important. I condemn this approach considering that it is not that expensive to buy a more powerful server that would serve the current needs of all the users.
The 1Mb block size limit was a temporary anti-spam measure when the amount of real users was very low and Pentium 3 performance was sufficient to serve the all. It is silly or even malicious to freeze it.
@_date: 2017-08-07 15:35:36
Please, don't spread misinformation. Yes, there was some support of Segwit, but clearly there was no consensus, Segwit hadn't reached even a half of the total hashing power before the NY consensus. In fact, a comparable share of hashing power was explicitly against Segwit.
See your "consensus":  (hint: NY consensus was achieved in May)
@_date: 2016-01-25 14:29:25
I agree
@_date: 2017-08-08 13:36:27


This is a non-determenistic process with a certain probabilistic properties. If you want to be more or less sure that your transaction is included in the next block, you have to pay a decent fee. 3 sat / byte may work sometimes, but it may also require days to get confirmed, or it may even be forgotten by the network. If the block size is not increased, eventually the latter would be pretty common.
@_date: 2017-08-07 14:40:40


Perhaps sometimes alt clients' proponents had luck or even paid for ads, but most of the time you probably saw either negative information about them (which is allowed here), or a heavily moderated discussion with altered sorting order, hidden votes and comments moved down via CSS tricks.
@_date: 2017-08-08 11:56:29
Do you support contentious soft-forks?
@_date: 2017-08-08 13:31:40
Hard forks add features that are incompatible with older versions, it requires all full nodes to upgrade (or they won't be able to participate in the network).
Soft forks add restrictions that are unknown to the old nodes. They can still participate in the network without an upgrade, but their security properties will be stealthily degraded because they can't check the new rules.
@_date: 2017-08-08 12:50:33


It would be against their declared ideals. They prefer to create an illusion (perhaps even for themselves?) that there is consensus among the experts and users. This kind of illusion is easy to achieve on censored forums.
Segwit got less than a half of hashing power until the NY agreement. The mining community in general rejected Core's solution. But Core devs continued pushing it and took the whole eco-system as a hostage of their only solution. Don't forget that Segwit was accepted by the majority of miners only because of the promised 2X part of it.
I believe that small blockers won, they got all what they wanted including a witness discount. AFAIK they were going to increase the on-chain capacity in the after-Segwit future anyway. So please stop fighting, its time to work together for the common good.
@_date: 2017-08-07 19:41:21
The problem is that you can't measure the economic majority, you can only believe it supports anything based on the easily falsifiable data.
Moreover, in North Korea the economic majority really supports Kim Jong-un. But does it really mean anything aside from the fact that if you openly don't trust the official censored propaganda, you loose everything?
I believe Segwit as a soft fork is not an optimal solution, but it is better than nothing (in a similar way as it is better to get raped than to get starved to death). At least it gives a chance for survival or even success.
@_date: 2017-08-08 08:44:03
Well, you are right, there are companies that welcome Core's Segwit.
I call it "Core's SegWit" because it is bundled with a fee discount for witness data and a hack to deploy it via soft fork. Many people believe Core's Segwit is a convoluted trick that promotes the interests of a certain group, not of the whole community.
So, yes, you can verify some data points which confirm that community really wanted Core's Segwit (there is even a site with the list of the companies that support it).
But you can't get and verify a full picture. Quite the opposite: due to selection bias, propaganda and censorship, you might get a false image of consensus whereas it is relatively easy to determine that there was no consensus on Core's SegWit until the NY agreement.
As I see it, due to the threat of UASF, big blockers agreed to swallow Core's SegWit (which many of them deem to be a poisoned pill) in order to unite the community and save Bitcoin from the irresponsible UASF disaster.
That was the Core's plan and it worked. Thus Core's Segwit has been forced on the community. I personally dislike that the questionable changes can be forced like this. If the 2X part of the NY agreement won't be implemented, then the community may split again and we may see more drama and volatility.
Unfortunately the likely outcome is that Core wins and continues enjoying its monopoly on the protocol development and the right to define "Bitcoin", "consensus" and "economic majority". But there is still a chance that the conflict will be resolved peacefully with respect to the interests of all the parties.
In either case I expect Bitcoin to jump to the new heights after all the drama is over (unless it disrupts the network in such a way that Bitcoin becomes unusable and alts take over the leadership).
@_date: 2017-08-07 19:13:45
Don't discard miners, Bitcoin is secured by them, their incentives are aligned with Bitcoin success.
Economic majority is interested in unity, that's why miners (that are a part of that majority) agreed to support SegWit to prevent the UASF disaster.
And UASF would be a disastrous mess, nobody is interested in it except altcoin and fiat investors.
The community had a choice between 2 evils and rightfully chose a lesser evil. This decision was correct as indicated by the price growth.
But don't delusion yourself regarding the reasons of that choice and the "economic majority". There is no easy way to measure it and that is a part of the problem.
That's why proof of work exists and successfully has been used to secure Bitcoin by design.
Just don't trust everything you see on a heavily biased and moderated communication platform.
@_date: 2017-08-08 12:45:38
If you don't know what you are talking about - that doesn't mean others don't either.
@_date: 2017-08-08 13:53:10
Are you saying that "contentious soft fork" is an oxymoron?
@_date: 2016-11-24 03:52:18


In the long run.
Why do you think it is time to impose the market forces now, while the block reward is large, Bitcoin is small and the capacity is artificially constrained to the laughable 1Mb limit?
Larger the system - more stable and secure it will be. Don't deter [Alice]( from using Bitcoin.
@_date: 2016-11-23 08:43:45
You mean Alice should use ~~mybitcoin~~ ~~mtgox~~ third-party service instead of her own Bitcoin wallet? 
@_date: 2017-08-07 09:01:44
sorry, fixed
@_date: 2016-11-23 12:46:24


Or only the large established entities that transfer millions of dollars will use Bitcoin while preventing ordinary people from using it and thus destroying Bitcoin's value proposition. Amount of bitcoin users is more important than amount of the full nodes. Yes, it is a theoretical and debatable topic.
But you totally ignored the real aspects:
1) Alice doesn't select the transaction inputs (she is not a Bitcoin hacker).
2) Those inputs were created by strangers, not by Alice, and they paid the fees for that
3) There is no way to stop anybody from creating small inputs in your wallet if you give them your bitcoin address
4) It is good for Bitcoin to merge these inputs as Alice does, why penalize her for that?
@_date: 2017-08-08 12:54:08
Would you trust your money to strangers paid by some company just because they are professionals?
@_date: 2016-11-24 19:20:19
$0.2 fee is for transaction that doesn't have many inputs. 
But if you received your money in hundreds of transactions, then [it may cost you $30]( to move them.
@_date: 2017-08-07 15:22:15
I am not that familiar with what you see, I have drawn my conclusions based on my own experience.
I saw manipulated sorting orders, hidden counts, CSS tricks and noticed that my polite and discreet but opposing comments have been silently hidden from public. These are the facts. Have you ever questioned why the comment votes count are hidden here while other cryptocurrency-related subs don't need this measure?
That doesn't mean every comment gets always censored. Sometimes on some topics there is a severe censorship, but sometimes it is relaxed, especially when the battle is won and we are in the less popular branch of the discussion tree.
If you want to familiarize yourself with the history of censorship at this sub, you can probably find it you know where.
@_date: 2017-08-08 15:42:31


Because Bitcoin is a peer-to-peer electronic cash system as defined by Satoshi in his paper (
A better support for smart contracts is a cool feature that can be added to Bitcoin, but the current nature of Bitcoin proved to be successful and should not be sacrificed. Bitcoin is designed to be ruled by consensus. There was a long and painful path to achieve some compromise - Segwit2X. And I don't understand why people who reject it won't create another blockchain for smart contracts only instead of hijacking Bitcoin.


Do you claim that with 2Mb blocks it would take forever to start up?
@_date: 2017-01-24 11:48:27


Guess what happens if everybody pays a bit more to do so? The analogy is correct.
@_date: 2016-11-23 08:59:44
Lightning will be an important caching layer for Bitcoin, but will it be effective for occasional random clients that rarely pay more than once?
When do you believe it will be ready for the average Alice to use?
How likely is it that she will use Bitcoin by that time?
@_date: 2019-08-09 21:16:19
Yes, that was the reason.
@_date: 2016-11-24 21:11:00
You are lucky, your transaction is small.
Imagine how much you would pay if your transaction had 100 inputs.
I guess the fee would be about $10.
@_date: 2016-11-26 17:53:16
The price of running the full node will grow linearly, while due to the [Metcalfe's law]( the value of the network (and the incentives for businesses to run the full node) will grow quadratically. Therefore it would be good for decentralization.
The end users are not going to download the blockchain anyway, they run SPV wallets.
@_date: 2019-08-09 21:27:06
That's true, it depends on the situation and your risk management strategy. The amount of required confirmations may depend on the value of transaction. 0-confs could be viable for reasonably small transactions.
If you have a well connected node and monitor the network, you can detect double-spending attacks in a few seconds and refuse to process even non-RBF 0-confs in case if the attack took place.
@_date: 2017-08-08 13:45:19
So do you support a contentious soft fork?
This fork adds new validation rules that are contentious. Some nodes believe they are correct, others believe they are incorrect.
Are you fine with forcing such rules on the whole network without consensus?
@_date: 2019-08-09 19:16:56
If you use Bitcoin Core software, then all you need is to quickly make the following 3 steps while your transaction is unconfirmed:
1. Create a new transaction which uses the same input as your unconfirmed RBF transaction and new outputs: [ . Be careful when you specify the output amounts: transaction fee is a difference between transaction outputs and the value of its inputs, it is easy to make a mistake and send most of your money to miners!
2. Sign the new transaction: [
3. Broadcast the new transaction: [
If you use other software then you probably need to somehow remove the information about your unconfirmed RBF transaction from your wallet file, then start your wallet in offline mode and use it to create and sign a new transaction using the same unspent transaction outputs. Then you can use some online service, e. g.  [ to broadcast the transaction.
If your wallet software doesn't support this functionality, you should be able to export the private keys of your bitcoin addresses to the one which does (such as Bitcoin Core).
@_date: 2019-08-09 18:35:58
It was not trivial to replace a transaction: most nodes and pools wouldn't accept a double-spending transaction (and I doubt they would do it now for non-RBF transactions).
@_date: 2016-11-23 12:06:51
But those 250 transactions were not made by Alice, the fees have already been paid by their senders. You can't stop strangers from sending small amounts to your bitcoin addresses anyway.
Moreover Alice is not a Bitcoin expert, she can't choose which inputs are going to be used by her wallet software (moreover you should encourage spending low-value inputs to reduce the size of the UTXO set).
I agree, the ability to send millions of dollars virtually free of charge is a great benefit for the wealthy elites.
But isn't Bitcoin supposed to mainly serve the common people, such as Alice, and protect them from the predatory policies imposed by those elites?
Isn't it the main reason why Bitcoin sacrifices performance for the sake of decentralization?
@_date: 2016-12-04 09:37:11
On the other hand not all the transactions really need to be confirmed quickly.
@_date: 2016-11-26 10:02:15
Great explanation!
@_date: 2019-08-09 21:20:59
Yes, you normally can't do it via GUI. But if your wallet supports offline transaction creation, you can probably decrypt the wallet file, remove the information about your unconfirmed transaction, then start it in offline mode and create a new transaction using the same unspent outputs. Or you export the private keys and use Bitcoin Core to create it (see [
@_date: 2016-11-24 04:06:47
10 times higher capacity means significantly lower fees. 
You are right, the problem would be the same, but the difference for the end user and for Bitcoin adoption in general would be huge.
And, yes, it would give some time to develop and deploy the other scaling solutions.
@_date: 2019-08-09 21:14:26
Core v.0.17 allows signing a transaction with a spent UTXO if you pass the `prevtxs` parameter, just tested it and updated the links to the docs (AFAIK other versions allow it too, but the API is a little bit different).
@_date: 2019-08-09 18:31:15
Yes, I fixed the destination address, increased the fee and sent the new transaction to replace the old one while it had 0 confirmations.
@_date: 2016-11-23 11:43:13
Thanks for mentioning this. Just read about it at   , it looks great!
@_date: 2019-08-09 19:35:58
There was a FSS (first-seen-safe) policy: a legit node wouldn't accept a new transaction which conflicts with any other transaction in its mempool.
If your transaction got distributed across the network and reached the majority of mining nodes, it was unlikely that it would be double spent. No guarantee, of course, but it would be much more complicated to replace a transaction.
I assume that this policy is still working for non-RBF transactions, but I am not sure, didn't check it.
@_date: 2019-08-09 18:44:28
I used CPFP too :) It is good to have multiple options.
But CPFP doesn't allow to fix destination address of unconfirmed transaction. So if you send your bitcoins to a wrong address and react quickly, RBF can save you a lot of money.
@_date: 2016-11-23 11:48:22
Thanks for the explanation. I am not sure I understand how the channel paths are going to be found, but I agree with you that unfortunately Alice is unlikely to be able to use these features any time soon :(
I hope that the solution will be found before Bitcoin looses steam due to the restricted capacity.
@_date: 2016-12-04 09:10:36
On the one hand it looks like you are abusing the public service offered by ViaBTC. It is similar to taking too much of the free straws / napkins /  ketchup / cream from McDonalds.
On the other hand the transactions you pushed through have a lot of inputs. You reduced the size of the unprunable UTXO set thus saving some RAM of every Bitcoin node.
@_date: 2015-08-19 22:28:26
Actually the first version Anonymous Ads used bitcoin addresses as referral IDs. It generated bitcoin addresses for each pair of &lt;advertiser, publisher&gt; and appended them to URL. Advertisers sent fractions of BTC to those addresses in order to increase their share of publishers' traffic. And it enabled them to easily integrate their affiliate programs to our network. But this system appeared to be not very practical because bitcoin fees became higher than payment amounts.
@_date: 2015-08-19 21:09:39
Thanks for your advice. You are right, we are not particularly good at marketing ourselves. Since we are a tiny team of developers, we hope that our publishers market us (that's why we have a generous affiliate program). When we get enough resources to hire a marketer, we'll do it. 
@_date: 2015-07-25 19:04:56
ASCII symbols are alphabetic, numeric, alphanumeric or any symbols from the table?
@_date: 2015-08-29 12:51:07
I agree, [BIP101 is better than BIP100]( I doubt that [Bitcoin future should be decided by miners](
@_date: 2015-07-24 08:52:08
If you are a normal Bitcoin user then it is much easier for you to make a bitcoin signature than a pull request.
Just sign the statement "[I believe that Block size limit should be increased to 8 mb as soon as possible]( (or the opposite one) with your bitcoin address that holds funds and submit the form.
It is free, verifiable and no flood involved (I announced this project today: 
@_date: 2015-07-24 08:15:27
Thank you very much! :)
@_date: 2015-07-25 13:07:05
Why not to make a public voting using bitcoin signatures? [I believe/doubt that Block size limit should be increased to 8 mb as soon as possible](
@_date: 2017-04-04 05:39:49
You can do it with Bitcoin signatures without paying anything at 
Disclaimer: I am affiliated with that site
@_date: 2015-07-24 12:12:07
I am not sure whether democracy exists in real life. Perhaps it is just a show made by the rich for the poor (more capital you control - more power you have over the public opinion and thus voting results). Bitcoinocracy does the same, but in a transparent and verifiable manner, without spending much resources on democratic decorations.
I think it is somewhat similar to shareholder voting in the public commercial company. If you don't own a company, why would you decide what is better for its shareholders? More shares you have - higher your influence is.
@_date: 2016-02-26 13:21:58
As pointed in the article, in the long term the network security is proportional to the mining revenue.
When the mining subsidy goes away, the mining revenue will come either from a small amount of expensive transactions, or from a large amount of low-fee transactions.
The latter if preferred (and probably is the only way to reach the main stream and achieve the long-term viability of Bitcoin).
So the best strategy is to increase the blocksize and to keep the per-transaction fees low as long as possible without sacrificing the decentralized nature of Bitcoin.
@_date: 2016-02-09 08:20:18
1) Add smoothing and [see the exponential growth](
2) Zoom in the last month and exclude empty blocks to [see that we are running at 70% of capacity]( Further rapid growth is not possible due to a 1Mb cap], if we don't rise it then the exponential growth will end and we will asymptotically approach the 1Mb size (the average will still be lower than that due to the empty blocks).
*Instead of exponential growth of transactions we may see the exponential growth of fees...* Until users just turn away from Bitcoin.
3) Remove the smoothing and notice that we already [regularly hit the limit](
@_date: 2016-02-25 16:13:11


You can keep increasing the blocksize while the technological trends continue. At some point of future Bitcoin will be able to handle as many transactions as Visa can now (unless you constrain its growth).
It doesn't mean you can't use Lightning or other scaling solutions on top of Bitcoin. There is no contradiction.
2) 


I don't see anything good in the juncture of development centralization and mining centralization. They have "basically asked the Chinese to perform a 51% attack on Bitcoin." (a quote from another sub)


It doesn't matter who is Satoshi Nakamoto, the most important thing is the ideas/vision/code he presented to the world.
Same is true for Bitcoin Classic leaders. Leaders don't matter. The idea matters. If you share their vision then you can support the product that implements it.
I admire the Core developers, they are great devs, but I don't agree with them.
Segwit and Lightning are cool, but they are nor the prerequisites neither the substitutes for the blocksize increase (that was supposed to match the technological growth).


It works to some degree. It certainly works in the short time. And there is nothing unrealistic about the 16Mb blocks (the only question is should it happen in a few years or in a few dozens of years).
There is no contradiction between LN and blocksize increase. Don't mix these things. Increase the block size and implement Lightning. But don't artificially limit the on-chain potential. Let the market decide.


see 3). The size doesn't matter. The idea matters.


see 3). Leaders don't matter. The idea matters.
@_date: 2015-07-26 05:48:38
Perhaps he is a teacher of logic...
PS: I thought in that direction too:
    Predicate(P:X=0|1)
    Symmetric(ABC=CBA)
-- didn't work out
Though I didn't write code and just tried couple of variants manually
@_date: 2015-07-25 19:15:42
Well, yes. It is probably harder to check, than to buy 0.1 btc.
But he is a human being, not a random number generator. So it is probably more about guessing, not about brute-forcing. Kind of a riddle, or not?
@_date: 2017-04-05 11:08:51
Bitcoins don't move at all. You just sign the statement with the key that matches your bitcoin address and your signature (=vote) gains weight equal to your address' balance. If you move money out from that address it will cancel your vote.
@_date: 2016-02-22 15:23:25
So do you agree that freezing the limit of 1Mb doesn't serve the purpose of protecting it any more (as there is a consensus that the network can handle larger blocks)?
It looks like the Bitcoin protocol is taken hostage by a single development team backed by censorship and trust of the major miners.
And that single team now has the monopoly on defining the future of Bitcoin (and the alternative ideas are labeled as 'altcoins').
@_date: 2016-02-21 08:20:41
Why is the simulated routing fee 0.5%?
Currently you can send any amount of bitcoin with a fee that doesn't depend on the value of transaction.
Is it going to be replaced with percentage?
@_date: 2016-02-21 08:59:31
I feel it is too risky to constrain the on-chain capacity of Bitcoin without a clear and widely accepted vision of its Lightning future.
@_date: 2016-02-09 08:01:45
it will hard fork only if it gets the super-majority of the hashing power, won't it?
@_date: 2016-02-22 10:42:31


There is no evidence 2Mb blocks would have significant impact on the decentralized characteristics.
Moreover Segwit as proposed by the Core has about the same impact on the bandwidth/storage requirements as 2Mb blocks.
The whole industry would require a lot of time to support Segwit transactions in order to benefit from the extra space available via accounting trick (while attackers would be able to use it right away - just in case if you really believe that 2mb blocks are dangerous).
@_date: 2016-02-22 20:25:57
I am not arguing about the 1Mb limit, I am arguing about the fact of freezing it.
Since you admit that increasing it would be okay, I assume you agree that freezing the limit doesn't serve the purpose of protecting the network. 
It is not a technical/security issue any more, it is a political one. Do you want a single party to dictate the future of the whole industry?
I didn't present you any 'stupid conspiracy theory', I just presented the facts:
1) It is a fact that a single person owns and bitcointalk and uses his power to manipulate the public opinion in favour of the Core team.
2) It is a fact that the Core team monopolized development of the protocol and convinced the major miners to not accept any (good or bad) competing solutions.
They think that the hard fork sanctioned by the Core team is OK, but by other team - is an altcoin. And they would prefer not to hard fork at all, but to stealthily change the properties of Bitcoin via series of soft forks. It is not a conspiracy, it is what they say.
We are seeing the paradoxical situation in which there is a consensus that 2Mb is safe, but instead of embracing it and winning some time to fix the problem caused by exponential growth, the Core devs use various tricks to force the whole industry to follow their vision (that looks promising but is not something most of the bitcoin stakeholders voluntarily submitted to).
I think that the Core devs should present their vision without taking Bitcoin protocol a hostage. The block size increase doesn't contradict nor Segwit neither Lightning.
@_date: 2017-10-11 10:37:15
XAPO is a great company which has a right (and courage) to state its stance on the protocol upgrade.
The anti-2x and character-assassination campaigns on this sub are unfair and disgusting.
@_date: 2015-04-09 16:55:24
Hi, I am from a-ads, thanks for mentioning us!
Anybody can refer advertisers to a-ads and get half of the fees we collect from them.
Just [create an ad unit] ( of any type and append the link to any a-ads page with "?partner=&lt;*your ad unit id*&gt;", e. g.:
    
@_date: 2015-04-09 17:31:59
Payouts are automatic, but [we don't pay per click]( We don't use Javascript/Flash in our ads and can't reliably distinguish valuable clicks from fake traffic.
@_date: 2015-04-10 09:56:36
Sorry, what do you mean? You can't open  or you experience some other problem?
@_date: 2015-09-11 11:04:12
If you send it in 1 transaction to a certain bitcoin address, this transaction will have just 1 output. It will cost a minimal fee for the recipient to spend it.
@_date: 2015-09-04 05:54:51
If we believe that technology can handle 32 MB then why do we ask miners whether they want to limit the maximum block size to a smaller value? 
@_date: 2015-09-02 07:56:33
I you believe that BIP101 is better, then please [sign this statement]( to show your support.
@_date: 2015-09-15 21:13:06
Thanks for your feedback and kind words, contributors are very welcome!
@_date: 2015-09-03 19:09:02
[I believe BIP 101 is better than BIP 100]( because [I doubt that Bitcoin future should be decided by miners] (
@_date: 2015-09-14 20:54:14
If they control the coins then they own them. And the ones who you  think are the owners of those coins in reality are just the owners of the IOUs.
@_date: 2016-10-23 08:39:26
  -- On the 11th of October bitcoin price surged due to ViaBTC's announcement? no, according to rbitcoin, it was China!
 -- On the 22nd of October bitcoin price surged due to the [on-chain] scaling conference? no, according to rbitcoin, it was Paris!
@_date: 2016-10-24 14:18:33


That's not a problem. The problem is if the legit users can't get on the chain with a reasonable fee. If the attacker fills the block with cheap transactions, legit users will pay a little bit more and enter the chain. 
The problem happens if attacker fills the block with high fee transactions.
And it is N times cheaper to do with N times smaller blocks.
Larger the block - more expensive it is for the attacker to negatively affect (I mean increase) the per transaction fees and confirmation times. Isn't it obvious?
@_date: 2016-10-23 10:09:21
Wow, thank you, 1Gb blocks in 8 years looks... bold even for me, the big-blocker.
I am trying to understand if there is any logic behind such numbers, let's see:
1. Bitcoin network generates about 6 * 24 * 365 = 52560 blocks per year, that is about 52GB per year at 1Mb per block, or about 1% of the modern hard drive. Thus it is possible to increase the block size to ~100 Mb without a need for the data centre to store the full blockchain.
2. About 8 years ago, in 2008 the ~0.5 TB drives were quite normal, ~5TB drives are normal now and ~50TB drives will probably be normal in 8 years. Hence further increasing the block size limit from 100Mb to 1Gb might have some sense.
Of course, this analysis doesn't consider other requirements (network, RAM, CPU, etc), let them leave aside for now.
As for me, this plan is too simplistic and optimistic, but it can be somehow justified not as a strict plan, but as a general direction, a rough calculation of the possible economic model for Bitcoin mining.
There is no need to hard plan for 8 years, the block size can be re-adjusted with respect to the state of technology as we go, perhaps we'll only reach 10Mb blocks by 2024, who knows?
But there is definitely some room to scale on-the chain, don't you agree?
@_date: 2015-09-04 05:34:22
The block size should be constrained by the state of technology, not by financial interests of miners.
BIP 101 makes a pretty conservative prediction of technological progress and adjusts the blocksize accordingly, whereas BIP 100 just shifts the power to the miners (and at the same time by setting the hard limits to the range of [1..32] MB it admits that we can't really trust them!).
Miners are supposed to serve Bitcoin network, not to own it (though if you ask them - they will probably prefer to own it).
@_date: 2015-09-14 20:33:12
Similar idea to  ;) (opensource too)
@_date: 2016-10-23 17:04:32
Which claim do you want me to prove?
I don't think my claim "On the free market (without censorship) the coin with higher throughput and cheaper transactions (all other things being equal) would take over." needs to be proven because it just states the obvious result of a fair competition of the abstract coins A and B.
It is impossible to deduce the level of their centralization and the underlying technology from my statement. But you can deduce that they are the same for coins A and B.
PS: If you state that any block size limit &gt; 1Mb would significantly increase centralization of Bitcoin network then please prove that.
@_date: 2016-10-26 05:57:30
Yes, if you pick the right data points. But the data is noisy. Remove the averaging and see it: 
But the 2-year trend is obviously headed north.
@_date: 2016-10-26 05:33:04
Do you know what is a logarithmic scale? You are using it in your graph and it gives a flat line even though the numbers are actually changing (they are not changing orders of magnitude yet, that's why they appear flat on the logarithmic scale).
Click on the "Linear scale" link on the bottom of the page you are referring to, and also set the smoothing from 7 to to something like 30 days in the URL to get a better idea of what is happening to the confirmation times. 
Or better smooth it to 100 days:  to see the trend.
The confirmation time is gradually raising most of the time during the latest 2 years: 
@_date: 2016-10-25 21:00:31
Sorry, I don't have that much time to argue with you, I think I've said already all what I wanted to say. I am sure you can answer your questions yourself.
I sincerely believe that regular adequate block size increases are a good for both decentralization and utility of Bitcoin.
And that freezing the (arbitrary and temporary) anti-spam 1Mb block size limit is a very risky change to economics and potential of Bitcoin. Moreover one-time 1.7x increase won't solve the problem.
@_date: 2016-10-27 05:21:01
Come on. Segwit is mainly intended to fix malleability (a less urgent issue). 
The ~1.7x increase due to the separation of the witness data is just a one-time side effect. It is not much and it will take a lot of time to get adopted by the industry, that suffers from the limited capacity right now.
And then we'll have an even longer time period until the Lightning is fully adopted (and nobody knows in advance which problems will occur with that promising but complex solution).
Even if Lightning is smooth and successful, 1.7Mb won't be sufficient. So why not to increase the block size now, when it is needed?
@_date: 2016-10-23 13:46:32
I think they outsource it not because of the hardware/network requirements, but because it is easier to integrate with a third-party service than to set up you own server, ensure it is secure enough, and create your own solution based on the full bitcoin node.
Nevertheless a lot of tiny businesses run their own full nodes. It is up to entrepreneurs to decide what is more beneficial for them. But I don't think x2, x4 or even x8 increase would affect their decision. Disk space is the cheapest resource.
@_date: 2016-10-23 20:04:51
I think miners who create excessively large blocks would fork themselves out of the economic majority and mine a worthless coin. The right to make a fork is not a tyranny.
If you advocate for the system managed by an elitist group that has the exclusive right to authoritatively define what is Bitcoin and what is not Bitcoin, then you advocate for tyranny of the minority and for the extreme uncontrollable centralization.
@_date: 2016-10-28 04:31:41


False.  "this effectively results in an effective limit closer to 1.6 to 2 MB"


Many people say so, including such a famous developers as Jeff Garzik, Mike Hearn and Gavin Andresen. Also common sense is also useful here. The 1Mb block size limit was introduced by Satoshi as a simple temporary anti-spam protection to prevent the premature flooding of the blockchain. At that time 1) Bitcoin was much less optimized than today 2) Hardware was much weaker 3) There was no need for &gt;1Mb blocks because not many people used Bitcoin.
All the mentioned 3 factors changed a lot during the last few years and it is just a common sense that the limit should be increased to account for that.     




Says who? Segwit requires bitcoin clients to change the way how transactions are being signed and verified (in order to use the additional capacity). Thus all the wallets and business integrations that construct and check the transactions themselves need to rewrite code in order to utilize the increased throughput.


I have no idea what you are talking about. AFAIK there are Classic and Unlimited. What's wrong with them?


Blocksize increase doesn't require much changes, just upgrade your bitcoin client, it can be done in no time. As a Bitcoin user you probably do it regularly anyway. And if you don't -- you'll receive the alerts and have a strong reason to do it.
@_date: 2015-04-10 09:57:19
It should. Please provide more details on your problem.
@_date: 2016-10-27 05:35:03
Are you trolling me? :)
As a Bitcoin developer you are aware of the big-O notation. And you know that the constant factor is not that important for the things that are supposed to grow exponentially.
You also know that exponential growth is essential for any new technology. In fact it is the only way to reach the main stream before it gets obsolete.
That's why the log version makes perfect sense in this graph:  (whereas linear graph contains much noise that depends on unimportant temporary constants). It demonstrates the [Metcalfe's law]( (that is not an exact law, but rather an empirical tendency) and shows that Bitcoin's success (which depends on exponential growth) is jeopardized by the limited throughput (which got frozen for some reason at an arbitrarily chosen constant despite the exponential technological curves).
This artificial **premature** saturation is a clear threat to  the mass adoption of the technology and to the investments made by the long term holders who never expected the **artificially** constrained supply.
As for the confirmation time, linear scale makes perfect sense, since exponential growth is not expected here, and the constant factor is very important for the end users.
@_date: 2015-09-14 21:05:40
If people trust that much bitcoins to Theymos or any other entity - so be it. Power comes from people :)
@_date: 2016-10-23 13:25:24


I think there is a wide support for Segwit, I am not an expert, but based on what I heard: 1) malleability is not the most urgent problem 2) the proposed implementation adds a technical debt (in order to deploy it as a soft fork) 3) the proposed implementation introduces an accounting trick to subsidise the witness data.
I'd prefer the Core devs not to be afraid of the well planned hard forks and to generate the clean and simple solutions without playing with economic incentives (as if it were a central planning committee). And ideally there should be many competing development teams that would follow the emergent consensus.
@_date: 2016-10-23 08:21:44
On the free market (without censorship) the coin with higher throughput and cheaper transactions (all other things being equal) would take over.
Update: do you downvote because my statement is false, or because you just don't like the truth? ;)
@_date: 2016-10-25 21:37:18
Thanks for the article. If I correctly understood it, big miners benefit from block propagation delays and it contributes to the mining centralization. I admit that it is a valid concern that worries me and it is something to think about.
Update: doesn't SPV mining protect the network from the adversarial use of the block size (by decoupling mining from block propagation/verification)?
See this article: 
@_date: 2016-10-23 13:57:45


The roadmaps can be adapted to the changing situation, that's normal when there is no a central planning committee that utilizes a waterfall model.
I think that capital will find its way to the correct solution, and I hope that Bitcoin developed by Core and other teams will be such a solution.
@_date: 2015-09-15 21:10:37
Thanks! I thought I had created a similar constraint in the initial commit, but it appears I had forgotten to mark the index as unique.
@_date: 2016-10-23 18:35:36
There is a certain fee, starting from which users will start turning away from Bitcoin. Let's say it is 0.001 btc per transaction.
If the maximum block size allows only 1000 transactions, then attacker would need to spend only 1000 * 0.001 btc = 1 btc per block to cause the congestion problems and turn users away from Bitcoin.
But if the maximum blocksize is 4 times larger, then the attacker would need to spend 4000*0.001 btc = 4 btc per block, that is 4 times more expensive.
The mentioned numbers are arbitrary, but they demonstrate that larger blocks not only make transactions cheaper for the legit users, but also make attacks more expensive.
@_date: 2016-10-25 17:28:17


That's good, isn't it?
Ironically you used bold font to outline the 2 statements that are obviously false. I'll try to explain it to you again (the last time).
Your first mistake is that you think that the block size is somehow related to crashing the nodes.
The correctly written code running on the adequate hardware shouldn't crash no matter what the input data is. If it crashes then there is some bug that will be fixed and urgently deployed. A trouble, but not a big deal, not fatal for Bitcoin.
Your second mistake is that you misunderstand the economical aspects of Bitcoin.
The cost of the attack explained by me doesn't depend on the network stats (fees and used blockspace). It depends only on throughput of the blockchain and on the level of fees that would prevent users from using it.
The formula is simple: the cost of the attack = throughput of the blockchain * unattractive fee
E. g. if the attacker wants to raise the fees to the unattractive level of $5 per transaction and the throughput is 3 transactions per second, then s/he needs to spend just 3 * $5 = $15 per second on fees to do it.
Most of the users would not like to pay unattractive fees and will switch to other payment methods. That might cause a death spiral for Bitcoin (-&gt; lower price -&gt; miners leave -&gt; lower throughput -&gt; cheaper attack -&gt; lower price -&gt;).
But if the throughput is 3000 transactions per second, then the cost of the attack would be 15000$ per second to achieve the same $5 fee.
As for me, I think the fee of $1 is already unattractive and damaging. The cost of the attack is only $3/second. And we are already pretty close to that fee even without an attack due to the artificially constrained throughput :(
At the moment this attack is pretty straightforward and affordable for governments and whale speculators. And you can't do anything about it if it starts (unless you increase throughput).
For the attackers there is no need to sustain this attack for a long time. Just do it time to time until miners leave and people loose faith in Bitcoin. Though at current prices governments can sustain it forever. $100M per year? Nobody will notice.
@_date: 2016-10-26 06:11:03
I think I've seen more unconfirmed transactions during the stress tests, so it doesn't frighten me.
What scares me is that I (and my customers) can be pushed out off the blockchain due to the ever-growing fee pressure before everybody learns and integrates the scaling solutions proposed by the Core team.
@_date: 2016-10-23 17:13:17
Even with 100Gb blocks not every tx will be onchain. The potential demand for transactions is much, much higher. Just imagine all the smart devices exchanging satoshis all the time. Lightning will be needed anyway.
But if the throughput is low, fees are high and low amount of users is using the blockchain, then not many businesses will care to run their own full node. Thus small blocks lead to centralization. There should be some equilibrium that maximizes the utility and the decentralization. And I highly doubt that it is 1Mb.
@_date: 2016-10-23 12:24:38
Miners are not interested to raise the block size limit above what the network can handle. I agree that increasing the block size (even to 1Gb) is not a panacea. Lightning (or something of the kind) will need to be developed and deployed anyway. But the capacity increase is needed now, not in some hypothetical future, or Bitcoin may loose steam.
@_date: 2016-10-23 10:36:35
Core devs are really cool and proficient. Their expertise is a great value for Bitcoin. But Bitcoin isn't supposed to be controlled by a small elitist group.
Segwit, Lightning and other innovations are the powerful ideas to optimize and scale Bitcoin, they don't contradict to the block size increase (the demand for transactions is supposed to grow faster than the on-chain capacity anyway, especially when robots take over the human economy).
I hope the Core devs will join the fork and continue their innovations, that would re-unite the community and help the mass adoption of Bitcoin!
@_date: 2016-10-23 17:59:22
I agree, no matter what the block size is, there is always a cost to run a full node.
But most of the cost is NOT related to the block size. You need to integrate your site with the node, to set up your server and keep it safe and running. You may need developers, system administrators and security experts for that. That would be a major expense that is not related to the block size at all.
You can avoid such expenses and rely on the third parties if you like. But if you don't like it - you have an incentive to run a full node.
Once again, if you decide to run your node for any serious purpose, the hardware is the cheapest part of your expenses. More customers use bitcoin - more businesses have such a serious purposes - better it is for decentralization.
@_date: 2016-10-25 04:33:21


Portable drives are irrelevant as there is no much sense in using full nodes on portable devices. I doubt 1TB portable drives costed $100 in 2008. I don't know where to get the historical prices, but here is one source: 
I just picked up the cheapest drives for 2008 and 2016:
2008: 640GB 7,200 rpm, 16MB 	-- 74$
2016: 3TB 7,200 rpm, 64MB -- 84$
Note the difference is just 10$, that's almost exactly the inflation (see 
Well, that's closer to 5x increase than to 10x increase, but you never know the future, I don't think the exact numbers are important if the block size limit is going to be continuously re-adjusted.


Miner is not interested to publish the block that is too large for most of the non-miners to accept (or it will likely be orphaned). If the increase is adequate to the state of technology then nothing special will happen.




Frankly speaking I am not aware of that. Are you stating that they don't put any defence against that, or that they don't use this particular trick (transaction size limit)?
@_date: 2016-10-27 08:26:53
Bitcoin competes not only with centralized payment systems, but with altcoins too.
Why not compete for the transaction volume while we can and gradually (without loosing steam) switch to layer 2 solutions as we approach the technical limits?
@_date: 2016-10-25 17:44:34




If the competitor doesn't get and validate the block soon, then s/he won't mine on top of it and you are risking to get orphaned. Or am I misunderstanding something?
@_date: 2016-10-27 08:05:32
Yes, the proposed implementation of Segwit can eventually provide an 1.7x increase, but 1) that's too small 2) too late and 3) is a one-time upgrade that doesn't solve the problem.
Segwit's capacity increase is not available right away. To reach the 1.7x increase the whole industry has to adopt and actively use it. A lot of third-party software needs to be rewritten (not only the most popular wallets, but also the custom business integrations). That may take a lot of time and resources.
I think you know about the alternative solution that has been running in wild for a while and can offer a quicker and more significant capacity increases to solve the problem for the foreseeable future (a few years) and which doesn't require much code to be rewritten. On top of that you can run Segwit, Lightning or whatever you want to solve the long-term problem, there is no conflict.
The only conflict is that the Core team is ready to sacrifice the short time capacity gains in order to deploy their long-term solutions while keeping the monopoly over the Bitcoin protocol. And it leads the whole community through this path because it can.
To my mind the postponing of the exponential growth is not a good business strategy (I am not talking about ethics here).
As for the hard fork activation timeline - I have no idea, but if the community suddenly notices the negative effects of the increased fees and decides to adapt the hard fork, then it shouldn't take much time to upgrade, perhaps a few months would be sufficient.
@_date: 2015-11-29 12:58:47
They are not safe, but for small amounts if you wait a few seconds and notice that transaction has been broadcasted to most of the nodes without double spend attempts then the risk is marginal.
@_date: 2016-10-20 04:05:17
Moreover asking users to pay seigniorage and transaction fees is hurting the  long term bitcoin holders who agreed to invest in Bitcoin because they were expecting the natural exponential growth (and subsidising the transaction fees until bitcoin becomes mainstream). 1Mb limit prevents mainstream adoption.
The current Core's idea is to get rid of the original business model and to compensate miners via rare but expensive transactions on the chain.
This is a huge mistake as it is a competitive market. Miners' expenses don't depend that much on the size of the block. If Bitcoin doesn't offer cheaper on-chain transactions, then some altcoin will do it and take over the market (Lightning can be implemented on the altcoins too, there will be no reason to pay high fees to enter the Bitcoin blockchain).
I hope the Bitcoin Core developers will change their minds and implement the hard fork, about 15% of mining power is already supporting it, and this number is likely to grow with the fees and confirmation delays.
@_date: 2016-10-16 22:15:37
I see your comment.
@_date: 2016-10-23 09:05:49
Wouldn't changing the mining algorithm devalue the whole security of the protocol?
@_date: 2016-10-23 13:52:21


That would be true if the capacity increase was hadrcoded with respect to the Moore's law. Nobody proposes to bump to 1Gb right now or in 8 years. If I got it right, BU proposes the adaptive solution, that might generate 1Gb blocks by 2024, but doesn't have to.


I don't think you can bump to 1GB without the majority of hashing power supporting you.


Thanks god! So nothing to be afraid of?
@_date: 2016-10-25 04:07:34


Don't you realize that the cost for attacker increases with the increase of the throughput?


Then there is a bug that needs to be fixed. It is not related to the block size issue. Nodes shouldn't accept data that crushes them. Miners are not interested to persist and propagate such data and fork themselves away from the network.


True. Larger the blocks - more money s/he'll be loosing, less time s/he'll be able to sustain the attack.
There are just ~144 blocks per day. At 1Mb per block that is ~200K transactions per day. It would cost the attacker just $1M USD per day to raise the fees to $5 per transaction (that most users won't agree to pay) and profit from shorting Bitcoin.
At 10Mb per block the same attack would cost $10M USD per day.
At 1GB per block (at some hypothetical point of future) that would be $1B USD per day (in nowadays prices). That's expensive even for the most powerful players that are not seeking for profit, such as governments.
@_date: 2016-10-23 13:39:05


Yes, I don't get it.
Well, I understand, that if you start generating the 100Gb blocks now, then that would happen.
But I don't get, why ANY block increase would harm the decentralization.
The opposite is possible: bigger blocks -&gt; lower fees -&gt; more transactions -&gt; more users -&gt; more businesses -&gt; more full nodes
E.g. if the block size limit was only 1Kb, then you could run a full bitcoin node even on your smartphone, but you would have 0 reason to do it unless you are a 1Kb-block-lover.  Bitcoin network would be much more centralized (operated only by the 1Kb-block-lovers).
But if the block is 4Mb, then 4 times more people are likely to use it (than with 1Mb), hence 4 times more businesses will consider installing a full node (consumers will use SPV wallets anyway). That would increase the decentralization.
@_date: 2015-11-04 04:04:06
Unfortunately miners don't support BIP 101: 
But bitcoin holders seem to support  it:
 (yet not very representative)
@_date: 2016-10-23 16:49:22
I see your point and it makes me sad.
Sometimes software requirements change and you need to adapt, that doesn't mean the project you are working on is a failed experiment, let the market decide.
I appreciate all the hours spent by developers on Bitcoin. I don't know how much needs to be done in order to make Segwit code compatible with the possible hard fork (or preferably to deploy it as a hard fork without technical/accounting tricks), but I hope that not too much. Why would a block size limit increase contradict Segwit?
@_date: 2015-09-15 20:59:29
Thank you very much for your report! Fixed this bug. Sorry, had to remove some of your signatures.
@_date: 2016-10-26 05:11:41
Switch to the linear scale and you will need to add smoothing to make some sense of the noisy data: 
PS: I am not sure how exact is this graph (since nodes prefer not to accept low fee transactions to their mempool nowadays).
Update: wow, downvoted to hide the truth? weird deceptive/manipulative tactics.
@_date: 2016-10-23 12:29:18


... or decentralization -- this is also a probable outcome of raising the block size limit.
However it is extremely unlikely that 1Mb is the optimal block size limit for decentralization.
@_date: 2017-05-06 08:30:23
The problem is that with Bitcoin on-chain capacity artificially constrained to 1Mb limit we will eventually arrive to 1 of the 2 outcomes:
1) The 'correct' fees become to high for ordinary people to use Bitcoin (only big entities would afford to pay them for multi-million dollar transactions).
2) Bitcoin becomes irrelevant as its dominance compared to altcoins approaches 0.
@_date: 2016-10-23 19:55:35
Average Joe uses SPV wallet, doesn't she?
@_date: 2017-05-07 19:59:46


Thanks for your answer and sorry for my ignorance. But you segregate witness, don't you?
AFAIK if/when SegWit transactions fully fill the blocks, non-SegWit nodes will see only 1Mb blocks of transaction data without witness data.
I don't quite understand how it is consistent with your claim. Are you saying that SegWit nodes will send different blocks to SegWit and non-SegWit nodes? What about block hashes?


We've been discussing it long ago and that's what I remembered. Sorry, its hard to find the exact quote to prove it, but here is a couple of more-or-less recent links that kind of indirectly confirm it:
Here you assume that most of the available block space is used by spam:


Hence you propose that 356Kb in 2018 would be OK:


Or am I wrong?
@_date: 2017-05-06 11:25:19
True, nobody believes it should be 1Mb, but ironically it is frozen in the consensus rules:
SegWit changes transaction format and moves signatures out from the 1Mb block thus potentially achieving ~1.9x capacity increase while potentially quadrupling amount of data stored in the blockchain.
@_date: 2016-10-23 12:21:00
If Core joins the fork, there would be no reason to split the currencies. I think rbtc guys are against Core mainly because of the block size debate. Once this issue is solved, most of the hate will disappear.
@_date: 2016-10-23 09:14:59
You are right, but there is an obvious possibility for causal relationship here. I got a feeling that a strong anti-raising-the-block-size sentiment prevents it from being noticed.
I agree though that two data points are not enough and I have a bias too, let's see how (if) the market responds to the similar news in the future.
@_date: 2015-11-28 19:11:11


Satoshi among them, huh? ;)
@_date: 2016-10-26 07:10:39
Sorry, I didn't fully understand your analysis. What do you mean "spam" and how did you determine it? And why they are confirming before the ones people care about (is it really true?)?
If the average block generation time is ~10 minutes, then ideally the average transaction confirmation time should be ~5 minutes. According to the charts at blockchain.info it is approaching ~10 minutes.
I am not sure Blockchain.info considers all the transactions though, AFAIK default bitcoin client may not accept and relay low fee transactions nowadays.
@_date: 2016-10-24 13:20:30


I have no idea, I don't know much about Ethereum. Perhaps the attack you are speaking about is exploiting some other vulnerability.


Unlimited has other technical measures to control the block size growth, that allow cheaper transactions and make it more expensive for an attacker to fill the whole block with one's transactions.
Segwit fixes malleability and optimizes some use cases. The potential 1.7x throughput increase is just a side effect that is too small and too late.
@_date: 2016-10-23 12:43:35
Frankly speaking I don't quite understand why you expect a fuck up. I think it is a pretty straight-forward logic:
1) 1Gb blocks are not bad if they can be handled by personal computers (not only the data centers)
2) at some point of future a single PC will be able to handle 1Gb blocks
Please note that nobody schedules 1Gb blocks for 2024. The blocksize limit is not to be decided by a single person, it will be adjusted by the whole network to maximize the value (that critically depends on decentralization as well).
@_date: 2016-10-23 17:25:10
I think "(all else being equal)" includes the block size (if that abstract coin uses blocks to store transactions).
Just to prove that you are making a mistake by assuming that larger block size = higher centralization, consider a thought experiment: Bitcoin with 1Kb blocks every 10 minutes.
Do you think Bitcoin with 1Kb blocks (a full node can be run even on a smartphone!) would be more decentralized than Bitcoin with 1Mb blocks?
I think not, because most of the people won't have a reason to run it. A few enthusiasts could run the full nodes, but that would probably not be sufficient to achieve the current level of decentralization.
Do you understand now why I think that the argument that larger blocks always cause centralization needs to be proven (and is probably false)?
@_date: 2017-05-07 20:39:46
I agree with most of your points too. It is clear that the blocksize increase alone won't solve the capacity problem since there will be a potentially unlimited demand for transactions from bots and IoT.
But I believe the strategy chosen by Core is wrong and it hurts Bitcoin. A simple 2Mb hard fork proposal was pretty safe, and it would be easy to obtain consensus on it if Core really agreed to it. There were so many advances in hardware and software since 2009 that quadrupling the block size shouldn't be a problem at all. But if the 2mb hard fork was executed as agreed in HK, we would probably be using payment channels already. 


The problem is we don't have time. Customers won't just passively wait and see how their expenses grow, they will switch to other solutions. Bitcoin is competing not only with fiat, but with altcoins too. If the progress is stalled, the exponential growth will happen somewhere else. Bitcoin dominance is 53%, the first mover advantage and network effects are eroding.
@_date: 2016-10-23 10:13:16
Did you notice '(all other things being equal)'? There is no proof that increasing the block size would result in centralization. Moreover, there is an opposite point of view (more transactions -&gt; more businesses are interested to run their own nodes).
@_date: 2015-11-04 14:32:14
BIP 100 gives them the power to decide the block size by voting: 
@_date: 2016-10-23 18:46:29
Forget about "all else is equal" and my original statement, most of my previous comment was an attempt to disprove your assumption that larger block size = higher centralization in the context of Bitcoin. It is not related to the original statement regarding 2 competing abstract coins.
@_date: 2015-11-06 22:15:36
Please sign this argument to convince everyone that despite miners tend to support BIP 100, BIP 101 is more appreciated by bitcoin holders: 
@_date: 2015-03-15 21:47:50
You can use bitcoincharts.com to get the price on any exchange for any time range and period (click the chart to set parameters).
Or download a CSV of the average price from bitcoinaverage.com via this link:  (e. g. it could be imported to a Google spreadsheet with formula: 
  =ImportData("
@_date: 2016-10-24 13:01:49
Please re-read this:


This number is just an arbitrary example, I don't know the real value.  But please note that it doesn't depend on the block size, users don't care what the block size is. They care about speed and cost only.
Lower the block size - cheaper it is for attacker to make the cost and speed unattractive to users and thus kill Bitcoin's network effects gained due to the first-mover advantage. That's a real threat to Bitcoin.
The attacks mentioned by you are hypothetical and can be fixed via technical measures (yes, the block size limit is such a measure, introduced long ago on when the hardware was slower and bitcoin software was less optimized).
But the attack mentioned by me can be performed anytime by anybody and you can't do anything about it. The only thing that can potentially stop it is the high cost of the attack. Larger the block size - higher the cost.
@_date: 2015-10-12 20:31:27
I had exactly the same problem. Unfortunately Electrum doesn't work well when there are over 10K addresses.
The simplest solution is to create a new Electrum wallet and to send the funds from the old one.
However sometimes it is hard to do since public Electrum servers have limitations that make it almost impossible to synchronize large wallets. So I had to modify 2 lines of Electrum code to partially synchronize it:
1) In /usr/local/lib/python2.7/dist-packages/electrum/synchronizer.py I changed:
    self.subscribe_to_addresses(set(self.wallet.addresses(True)))
to 
    self.subscribe_to_addresses(set(self.wallet.addresses(True)[self.wallet.storage.get('start_index'):self.wallet.storage.get('stop_index')]))
2) In wallet.py I added a "return" to the beginning of the remove_transaction function.
That allowed me to specify start_index and stop_index in Electrum's console to synchronize the wallet partially and to send its funds to the new wallet.
Please see  for details.
@_date: 2017-05-07 22:02:07


Thank you very much for the clarification!




I think it is easy to estimate. If total transaction fees are 260 btc per day and spammers take 25% of space, they probably have to spend about 65 btc per day. Does it sound right?
I don't quite understand why they would do so.
@_date: 2016-10-23 08:15:32
Where did you get the numbers (1Gb, 8 years) from?
Please provide evidence to support them or stop spreading the misinformation.
@_date: 2015-11-28 20:19:10
 -- sign with your bitcoin address
@_date: 2016-10-23 12:56:22
If you design Bitcoin only for those that run the full nodes, then 1Mb might be enough. But if you target the mass market, you can't expect that every user will run a full node on his/her smartphone.
Bitcoin's success mainly depends not on the volunteers that sacrifice their energy and disk space for the common good, but on the businesses that run the full nodes and  the consumers that use the SPV wallets. Every serious business can afford to dedicate a computer to host the full node.
Big blocks -&gt; cheap transactions -&gt; many consumers -&gt; many businesses -&gt; many full nodes.
@_date: 2017-05-07 13:28:35


Yes, you normally align the tradeoffs with your priorities and capabilities.
Pruning nodes is not that easy to price out. More capacity Bitcoin has and lower the transaction fees =&gt; more businesses have incentive to invest in running their full nodes.
However it is very easy to price out typical bitcoin use cases. And there is no reason to run a full node if your use case is priced out.


Firstly, it doesn't make much sense to talk about any fixed number without specifying the date for it. E. g. even 1Mb blocks 30 years ago would be impossible, and at some point of future 100Mb blocks will probably be trivial.
Secondly, payment channels will greatly increase Bitcoin scalability in the future.
I think if the block size is increased, all the technical barriers for payment channels will be lifted pretty quick as well, it's the next priority IMO.
@_date: 2015-11-05 21:16:35
Do you [believe]( or [doubt]( that BIP 101 is better than BIP 100? Please sign with your bitcoin address that holds funds. Let's see what the public thinks regarding this consensus.
@_date: 2016-10-23 17:44:14
I think storage prices probably don't get cheaper because of SSDs, but 8 years ago 0.5 TB HDD costed about the same as 5TB today, so the HDD storage really became cheaper.
But even if the prices don't drop, you can always prune the blockchain after validating it.
The ever-growing UTXO is a valid concern though. I don't know how to address it, perhaps miners could apply the policies to prioritize transactions that have more inputs that outputs for their own good.
Most of the mining expenses are related to energy and hardware, not to downloading the blocks. If I get it right, they are already using a lot of optimizations to start mining ASAP and the increased block size won't affect it much. Moreover the proposed solution gives them the power to adjust the blocksize, they probably won't shoot themselves in a foot and fork themselves away from the rest of the network.
The adversarial scenario with too-big-to-validate transactions can be prevented with a simple transaction size limit.
@_date: 2017-07-15 17:13:47


It is not an assumption, it is an observation and an example (did notice "Sometimes the opposite works, e. g.:"?).
When Bitcoin had no users, there were no reasons to run a node. AFAIK Satoshi was mining alone for a while because nobody cared despite his paper had been published. Don't you think the system was more decentralized back then?


I never mentioned a linear increase, where did you get it from? I don't know whether it grows linearly or not, it depends on many factors.
Some factors may cause a decline of fully validating nodes. E. g. if people switch to altcoins, they will not run bitcoin nodes.
Also, are you deliberately ignoring the fact that mass adoption was happening in parallel to proliferation of SPV wallets (proposed by Satoshi)?
Read the paper, it was never supposed that all the users run fully validating nodes. But once there are many users, there are many reasons to run a business and invest in running your own node.


That depends on your definition of decentralization. If you measure decentralization as percentage of users running the full nodes, then yes, you are right, it is more centralized now. But when Satoshi was the only person running his node, it was 100% decentralized by this definition.
That's why I believe that per-capita approach is incorrect. In my understanding 7 billion of users with 7 million of full nodes is far more decentralized than 10 000 of users with 10 000 of nodes. 


Please stop attacking me personally. Attackers that ostracise opponents and split the community made a lot of damage already. I've presented a few facts and you may continue ignoring them or start being constructive.
@_date: 2017-05-17 03:35:59
Spammers? And what about 480 satoshis/byte fee as currently reported by  ?
@_date: 2017-05-07 20:58:56


Thanks for the clarification. What about the block hash, will old nodes and new nodes see the same block hash for 1Mb part of the data?


So you agree that most transactions are legit?
How much do you think spammers spend on fees per block and when will they run out of funds?


Makes sense, thanks for the clarification!
@_date: 2017-05-07 08:05:37


I don't see the contradiction. Won't SegWit supporting nodes receive up to 1Mb block of transactions + up to 3Mb witness data? How is it different from moving the witness data out from the 1Mb block?


That's already happening. According to , significant amount of transactions are spam, and we need just 300Kb blocks for real usage.
And we already know that many real businesses are being priced out and forced to use altcoins. It is much, much cheaper for attackers to price out legit use cases with 1Mb blocks than with 8Mb blocks.
@_date: 2015-11-29 10:49:08
If you read the original post, you'd notice the link to his message: 
@_date: 2017-07-15 07:09:10


You may argue that the ultimate decentralization is about 0 transactions per second because everybody would be able to run a fully validating node. But it is wrong, nobody would run it because there would be 0 reason to do so.
Hence cheaper nodes doesn't always mean more decentralization. Sometimes the opposite works, e. g.:
More people use Bitcoin -&gt; more fully validating nodes -&gt; more decentralization, price soars, everybody wins. Nothing bad in this.
Less people use Bitcoin due to the central capacity planning-&gt; less reasons to run a node, less decentralization -&gt; price drops, everybody looses.
The market is to set a reasonable balance between decentralization and utility, not a group of self-proclaimed experts and central planners.
@_date: 2016-10-23 20:11:18
You are right, I am not a native speaker. Thanks for noticing the mistake, I fixed it by replacing "isn't" with "doesn't".
As for the "she", I used it intentionally to fight the gender inequality. Women also have a right to use Bitcoin and male names ;)
@_date: 2016-10-23 10:18:20
Any proof?
@_date: 2018-12-01 10:49:47
According to this chart, we are on the exponential support line now, so if it holds, we may see 20K by the end of 2019. [  
Update: it looks like the chart needs to be updated though, the present price seems to be below the support line :(
@_date: 2013-12-09 12:15:07
Was it really a crash? Something similar happened just several weeks ago on 19th-20th of Novermber, when price dropped from ~900 to ~450.
Looks like a correction. Maybe a bit over-correction due to "bad news from China".
@_date: 2013-12-25 08:25:43
That's why I said "in the long term". In the long term bitcoin will be more stable and the hardware cost will be negligible in comparison with energy cost. See 
@_date: 2013-12-22 04:01:35
More days destroyed - the better. Coins move from early adopters to masses. Bitcoin economy becomes less centralized.
@_date: 2013-10-22 20:23:18
If to assume that all currencies survive, the future all-time top of Bitcoin can't be expressed in a finite number of fiat units (since unlike Bitcoin they are always inflating).
@_date: 2013-12-26 08:14:36
no, difficulty is just a consequence of mining profitability. when mining becomes almost unprofitable, difficulty &amp; power consumption will stabilize.
@_date: 2013-10-22 21:00:50
Seems to be possible to allow donations not only to project repositories, but also to sub-paths of them (and generate tips for each commit that changes files in that sub-path).
Or maybe each project could have tags, people would be able to donate not only to the project as a whole, but to any tag of it too, and developers could put that tags in their commit messages. If commit message includes the tag that is funded - we generate a tip.
So I think it can be implemented in future. Not sure yet if it will be demanded &amp; easy to use. But definitely needs some thought, thanks for idea, aenemic!
@_date: 2013-11-30 20:37:59
Shameless plug: we added it to Coingiving, so you can donate to Sean's Outpost non-anonymously, it is free and instant!
@_date: 2013-11-23 18:46:00
Maybe this guy can help you? 
@_date: 2013-12-24 10:40:16
Mining efficiency doesn't matter!
In the long term only 2 factors influence Bitcoin energy consuption: value of miner's reward (block reward + bitcoin fees) and price of energy.
If we assume that 90% of miners' expenses is energy, and 10% is profit + other expenses (that is quite possible on the saturated market), then the annual cost of energy consumption can be estimated as: value of miners' reward during 1 year * 0.9
Let's assume the market will be saturated in 4 years and the price of BTC will be 100 000 USD. Block reward will be 12.5 btc. Miners' reward during a year will be about 700K BTC, or 70B USD. 
If electricity rate is 0.15 USD/KW, then we'll use about 5 PW of energy during a year.
Current world energy consumption is about 150 PWh per annum, so Bitcoin would use 3% of world energy consumption. I think it is significant. Not sure how to estimate the consumption of current financial system though.
(that's just a rough estimation, please correct me if your estimation is orders of magnitude higher or lower)
@_date: 2013-10-21 22:35:33
Yes, some trust is needed. But it is just a tip, shouldn't be a big deal.
Since tips are often micro-transactions, Bitcoin fees can be significant part of our expenses (and we need some money to maintain &amp; develop the service anyway). What do you think is a reasonable way to cover them?
But thanks for your feedback, we'll discuss it and maybe reduce or remove the fee (we can't do it now because we are not allowed to edit files before the  competition finishes  :)
@_date: 2013-12-22 03:49:51
No, USD volume haven't increased significantly (see  Some early adopter moved his or her money, not a big deal. 
@_date: 2013-12-24 11:02:59
30% of banks' energy is a lot since we are not serving even close to 3% of world financial transactions!
we are going to consume about 3% of world energy consumption in 4 years, see my estimations here: 
@_date: 2013-05-03 12:34:19
Why don't bitcoiners vote with their bitcoins directly to development team members or other initiatives that are good for bitcoin? Do we really need any centralized &amp; regulated structure with all the possible regulations, bureaucracy, lawsuits, etc?
@_date: 2013-12-24 18:16:17
You could use  to donate and have a public donor's profile.
@_date: 2013-10-22 17:10:37
Sashazykov cross-posted it, thanks for your advise!
I didn't understand about sub-commits, could you please explain this idea?
@_date: 2013-11-26 21:05:03
IMHO hoarding is not a problem. Hoarders support the value of bitcoin. When you hoard fiat, you support your government. When you hoard bitcoins, you support all the bitcoiners.
@_date: 2013-12-09 04:11:47
Please note that if you want to keep track of your bitcoin donations and to make them public, you can use a free &amp; transparent service coingiving.com. Donations get forwarded to recipients instantly without a fee.
Web Archive has been added as a project there: 
@_date: 2013-12-25 04:11:40
I think in the long run hardware expenses will be negligible (there will be no reason to add hardware because profits will be lower than in other sectors of economy, and there will be no reason to upgrade the hardware because we'll approach physical efficiency limits by that time).
3% of world energy consumption is bad, but not too bad, since we are indirectly paying 3% in fees to Visa/Mastercard anyway. I would say it is an upper acceptable bound.
However if Bitcoin price goes up to 1 million or above that... Just think about it...  Bitcoin consuming over 30% of world energy, the whole planet working to supply enough energy...
I don't think it will happen. Bitcoin probably won't reach $1M before block reward becomes much, much smaller.
Free market is self-regulating. If Bitcoin price grows too fast, electricity prices will soar, other industries will suffer and cause inflation.
So I think $100K is an upper limit for 4 years, $200K for 8 years, $400K for 12 years, $800K for 16 years, $1M can't be reach before 2034 (when block reward drops below 1 btc). That is an upper, optimistic estimate.
@_date: 2013-12-25 04:25:46
I hope price doesn't soar too much before the block reward is significantly lower, otherwise it would be a catastrophy