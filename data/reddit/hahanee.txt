@_author: hahanee
@_date: 2015-06-19 23:20:37


We average 400k/block right now, which is where the tricky debate about how full average blocks should be is :) That is mostly a tradeoff between not all transactions fitting in a single block an increasing % of the time (which might actually be vital for security when the block subsidy drops) and some hard to quantify decentralisation measures. Remember that nodes should be able to download and verify a maximum size blocks is a reasonable time.
No comment on your speculative accusations.
@_date: 2015-06-19 22:30:35
So Satoshi in 2010, given the information available to him/her/them at the time, had a better understanding of the (often not intuitive) nuances in bitcoin than the current 'experts', who have had 5 more years of empirical study, academic interest, and community driven research/analysis? That sounds ignorant, insulting, and most of all extremely depressing.
@_date: 2015-06-20 14:20:24
They dropped RBF in favour of FSS-RBF, which doesn't improve the ability to double spend zero confs, but does allow users to increase the fees on their unconfirmed transactions.
@_date: 2015-06-16 23:26:58
Removing the ability to run a full node from some people is always a cost, and the tradeoff between this ability and the maximum transaction throughput is always here. 
Miner interests can be hard to predict, they might have alterior motives (bullying other miners, pushing users towards SPV clients/centralised solutions), and this maximum block size structure gives them more power.
The impact of an individual miner's 'soft limit' is limited, especially when the miner has a small percentage of the total mining power.
@_date: 2015-06-23 01:05:45


Basically, 51% attacks and selfish mining/block withholding attacks require a lower hashrate share to become viable and/or profitable. This follows from the fact that an attacker does not 'waste a part of his hashing power' by working on the not_longest chain. A shorter block time interval causes a higher number of stale blocks from the honest network working on different chains due to block propagation, thus, not publishing a block (for one of those attacks) gives you more of an advantage against the honest miners. In short, a larger part of the total PoW power is wasted on chains that are not the longest chain, which reduces security.
@_date: 2015-06-14 20:23:35


If by less friction you mean people not knowing they disagree with other users and losing money as a result of it, then yes. Making consensus critical parameters easily configurable is incredibly dangerous since well, people are dumb and will mess around with it. 


So essentially no block size limit except for when they don't like the size of it. This is not a question about miners btw, all users/nodes (those who enforce the consensus rules) will have to decide on whether the block is 'too large'. 
Fundamentally, the bitcoin users dictate the rules for the miners. In your scenario, users will have to guess on what block size other users consider too big.
Once again, the network is defined by all users who agree on some history of transactions, which can ultimately only come from an agreement of some exact set of rules. 
 
@_date: 2015-06-14 22:36:45
It was actually just a question to help me understand your thought process but it might be a slight strawman (as is ... "people are too dumb to expect them to act in their economic self interest"...), but if the rules are different between people while they believe they all follow the same rules there will be people who lose money of a result of this, it is just a matter of when. Users cannot reliably see different chains and who views which chain as the 'correct' one. 


There is nothing to discuss. Reliable (probabilistic convergence towards) consensus can only follow from a properly defined set of rules, not some subjective individual assessment of 'actual abuse'. You seem to be caught up thinking in terms of the economic majority, while we require consensus amongst all participants of bitcoin (all those who follow/enforce the same rules). 
@_date: 2015-06-19 16:54:30
Only if by invested deeply you refer to him being paid by people from viacoin (iirc he doesn't even own any viacoin) to work on solutions that are directly beneficial to bitcoin.
@_date: 2015-06-14 21:34:38
I was talking about individual users, whether the economic majority is too stupid is completely irrelevant. But the main point to take from this thread is that consensus is extremely fragile and hard to achieve, and that not properly defining the rules of the game is ridiculous, especially when we have the ability to properly define it.
@_date: 2015-06-20 11:54:52
Interesting to see that people were looking to burn Peter Todd alive for providing a mining pool with a RBF implementation and simultaneously donate to this "stress test". Both of which are aimed at showing a vulnerability in the current bitcoin wallets and/or protocol by exploiting it on the bitcoin main net.
@_date: 2015-06-19 19:15:31
A higher maximum block size might be slightly better right now, but that is not the whole story. The risk of a hardfork with the current state of disagreement on the optimal solution is incredibly risky and outweighs the potential gains imo. There are also other parts of the current bitcoin protocol that can be improved upon with a hardfork, why do you think they haven't been implemented yet? Hardforks are dangerous, especially without consensus, which is a good thing imo.
@_date: 2015-06-22 18:21:34


@_date: 2015-06-22 23:16:17


I agree, so we need a mechanism to ensure the fees pay for security, one such mechanism might be based on artificial block space scarcity. 


What do you base the 100+ year estimate on? The fact is, we don't know what the 'optimal' tradeoff between PoW security and the cost of said security is, nor do we know when the block subsidy will no longer be enough to provide this security (it might be yesterday, today, tomorrow, or in x years). 


They probably can, once we figure out how they would actually work, but it might not be accepted when we trick people into bitcoin under the premise of really low transaction fees and unlimited transactions. Evidence for this can be found in the parent  saying that low transaction fees is/should be a core competitive advantage of bitcoin, which is probably not sustainable long term and is only currently true because of the high level of inflation.
@_date: 2015-06-16 23:18:33


These two problems are fundamentally different. The difficulty is a rule set by users to keep miner subsidy ~constant and predictable, it is basically a rule to limit the power of miners. The same is the case for the maximum block size, it is there to keep miners in line. Your proposal removes this power from the users, and gives miners the control over the maximum block size, which opens up new attack vectors.


Your proposal does effectively the same thing, give miners the ability to abuse the maximum block size. Past transactions do not demonstrate the 'needs of the network', especially when you allow miners to have incentives to spam transactions.


It would not require a persistent filling of blocks for miners to potentially drive away competition (or push users away from using a full client), nor do their transactions require an 'adequate' fee. The only protection against miners spamming their own blocks would be the cost of a higher chance of stale blocks, which is becoming less and less of an issue as block propagation improves. 
@_date: 2015-06-19 23:04:25
I haven't read all Satoshi's posts to give a proper overview of his thoughts on the block size. I also haven't read how he envisioned PoW security after the significant drops in block subsidy, apart from 'transaction fees will take over', for which we have no proper mechanism, and an even worse one without a maximum block size. 
related: 
@_date: 2015-06-19 17:31:04
I don't know, and I never met the guy.
You claim he is invested deeply in viacoin without showing any evidence to support that claim. Afaik Peter works on a freelance basis for several (I lost count) projects in the bitcoin space and has no other special relationship with viacoin.
@_date: 2015-06-20 11:38:19
Of course we are dealing with hypotheticals... Bitcoin is a fragile cryptosystem and changing important variables requires us to think about all the potential new attacks it creates and all changes in the incentives for all possible actors. I don't give a damn about who designed the system, if the people who currently understand the system the best (most likely better than Satoshi in 2010) voice credible concerns about it. I am not even saying we shouldn't increase the block size limit, just that the argument that Satoshi said something about the problem, 5 years ago, as a rebuttal for actual technical arguments is laughable. 
@_date: 2015-06-14 18:33:08
Sure I can, I can even define a block as valid only if it includes exactly 17 transactions, of which there are no more than 11 that include a signature with more than one 6 in its hex representation, and solves a moderately difficult sudoku instead of a sha256 PoW. The 'problem' is that nobody else agrees with these rules and I thus fork myself from the 'main' chain. 
If everyone has different rules, the whole currency becomes useless since there is no point in time, after you receive a btc transaction, where you can be significantly sure that you're on the same history (the history where the person actually sent you those btc) as people that will accept these btc as payment. 


Then the solution would be to have no maximum block size, which is an option, but is generally seen as dangerous and undesirable. Participants having different validity rules is insanity (maybe even conceptually impossible, since they would participate in different systems).
@_date: 2015-06-23 00:16:12
Please don't remove later reactions and edit earlier ones, they mess up the conversation. 


I never said I believe 1mb blocks are optimal right now, let alone in the future. Miners enforcing their own 'soft cap' is only because they lack a better logic for transaction inclusion. Ultimately they will include all transactions for which marginal revenue from transaction fee &gt; marginal cost of larger block or some optimal selection of transaction that leads to the highest block reward if there are more profitable transactions than they can fit in a block. If they could always fit all the profitable transactions in a block, and with really low marginal cost of transaction inclusion due to better block propagation, users would only pay transaction fees slightly larger than said marginal cost. I believe that at some point in the future this will lead to a below optimal level of PoW security.
EDIT: 
Had a comment typed out for you deleted post, so I might as well post it:


No they cannot (ok they can kind of, based on their hashrate share, but it would probably be economically irrational), they can change the size of their own blocks, which they should based on the marginal net gains from transaction inclusion. 


Great, please share these other ways with us. I believe you would be the first. 


I believe you have a fundamental misunderstanding of what we talk about when talking about the security PoW provides. The hashrate not the relevant measure, the total cost the miners endure (mostly electricity) is. What PoW provides us with is the increasing cost to reverse transactions. If the PoW security drops, you have to wait longer to ensure the party that pays you in btc won't try to perform a double spend.
@_date: 2015-06-23 10:45:02


No, that's the point I was trying to make. If you have, on average, a smaller percentage of the PoW power working on the chain that becomes the longest chain, the chain will have a lower total amount of work.


Significance is extremely subjective and part of the tradeoff between security and confirmation granularity. I would be interested in the numbers tho. 


If true, that would be an argument against decreasing the block time interval since it would make these attacks more profitable.
@_date: 2015-06-19 18:31:22


Sure, there is a non zero percentage chance they have been paid by CIA, but they have stated otherwise and we have no real reason to doubt their claims. 


Ignoring credible technical concerns, which at least partially come from a better understanding of the fundamentals of bitcoin, as well as 5 extra years of observations, seems extremely foolish to me. Besides, any evidence that would suggest Satoshi implied ~before 2016 with "temporary", and not some time in the future where attacks, opened up by larger blocks, would have less severe consequences? 
@_date: 2015-06-18 21:52:04
It's only $3bn /s
@_date: 2015-06-19 18:48:21
I don't force my vision onto anybody, I'm just trying to figure out the best way to solve these problems without causing serious damage to bitcoin in the process. The economic majority is not really a meaningfull concept in this, since everybody loses if there are multiple conflicting chains, as well as a serious risk of individuals getting robbed and damage to the bitcoin image.
@_date: 2015-06-14 21:59:29
So you're suggesting we should only care about the economic majority and allow individual users to get robbed?
The only situation in which you do not have to properly set the maximum block size (note that this can be a constant, or some more complicated function based on past blocks) is if you remove the maximum block size as a consensus critical parameter. This can only be done by removing the limit and allowing blocks of any size. 
@_date: 2015-06-14 22:18:10
I agree with your general thoughts here. It is important to note tho that 10 min/block is probably not the optimal rate, and the tradeoff between easier attacks and more confirmation granularity is quite hard to measure/optimise. It is definitely not one of the most important/interesting problems atm tho. 
@_date: 2015-06-22 21:25:59
Ahh yes, the magical transaction fees everyone is going to pay even when they don't have to, because miners will include all transactions with a really low fee as their marginal cost of transaction inclusion approaches zero anyway. I also don't share your opinion that a &lt;0.01% scheduled inflation would provide an adequate level of security.  
@_date: 2015-06-11 14:43:52
Sure they can, I can just ignore all blocks that don't send me their block reward. The reason I don't is because I would just fork myself from the generally agreed upon chain. What you're suggesting results in a system where the 'soft limit' is no longer a 'soft limit' but a 'hard limit' since it is a setting that must be agreed upon to reach a stable consensus on which blocks are valid. 
It does not provide an easier way to increase the limit at all, since it is just the new 'hard limit'. It is important to note that the 'soft limit' is just a setting that miners use to limit their own blocks, with the only constraint being that it is smaller than (or equal to) the consensus critical 'hard limit'. 
@_date: 2015-06-22 22:22:05
Timestamps are unreliable short term, but more reliable for long term planning. Planning using block height would probably assume an expected average block time of 10min, which only holds true if the average difficulty change is 0. Difficulty adjustments are hard to predict due to the effects of ASIC innovation, BTC exchange rate etc. So there is a tradeoff between higher hardfork date prediction variance (possibly weeks for blockheight vs hours for timestamp) and possibly some extra block_validity_check logic for the timestamp approach.
EDIT: Actually, I don't think you need any extra logic, although I'm not sure about the exact way it is handled now. Iirc, a block is accepted if/as soon as the timestamp is not &gt;2 hours ahead or &gt;2 hours behind local time. So the first larger than 1mb block could be mined &lt;2 hours before the actual time the hardfork is scheduled. Obviously the earlier a miner mines a 1mb conflicting block the larger the risk that other miners won't accept it right away due to a conflicting local time. Following blocks can then only be &gt;1mb if the timestamp &gt; critical timestamp, so the safe implementation for miners would be just to only mine blocks &gt;1mb with correct timestamps after their local time &gt;critical time.
@_date: 2015-06-19 22:53:52
Bitcoin is a cryptosystem, for which Satoshi also made several objective security assumptions/requirements. There are cases where this is not just a disagreement but a statement that is provably false/incomplete. Let me give you an easy to grasp example. Satoshi argued that as long as 51% of the mining power was 'honest' the optimal strategy for a miner would be to also be honest (paraphrased). Academics later found a miner strategy, selfish mining, that would give said miner a higher expected revenue if the miner has 33% or more (actually lower than 33% for some latency factor iirc). 
@_date: 2015-06-19 13:30:01


@_date: 2015-06-16 17:37:15
I don't think I can explain it again without just repeating myself. Different users cannot be in stable consensus if they have conflicting rulesets.


Ofcourse, because they agreed that the validity of a block does not depend on its size. This could be a viable approach, but it is fundamentally different from what you're proposing, where people accept or refuse blocks if they deem them 'too large'.
 
@_date: 2015-06-11 14:22:25
This would almost surely destroy bitcoin. Trying to reach consensus on a certain chain while the 'rules of the game' are different for each node is insanity.
@_date: 2015-06-19 23:43:15
I'm quite tired so this might contain errors. 
Reading  "Assurance Contracts" I see a lot of handwaving and fundamental problems with no solutions. 


Sounds cool, let me know what the actual construction is that solves the free rider problem. How does one set an amount to force a sufficiently high percentage of economic activity to donate? He then accurately describes the problem of miners just filling the rest of the donation, for which he only provides the "solution" which requires all donators to reveal their identity. So yes, it's a fun idea to show more advanced contracts in bitcoin, but nothing more than that.
 What we would actually want, is a mechanism that "taxes" users in some set way (inflation, properly enforceable transaction fees based on transaction value/size/?, or a combination of those) to provide some level of PoW security where the social tradeoff between these costs and the provided security is optimal. Consensus critical transaction fees are easily paid out of band and a constant % inflation will face a lot of opposition, which leaves us with the maximum block size being the easiest (but still incredibly difficult) manipulable variable.
EDIT: I also found some btct threads, but I can't really be bothered reading it atm. Let me know if you think I'm an idiot and should read it.
@_date: 2015-06-14 18:49:04
How should users guess whether "the rest of the network" will accept them when they don't know which rules they follow?
Who defines abusive? Maybe all users should agree on a measure of abusive, perhaps measured as the size of a block?
 
@_date: 2015-06-22 20:54:43
No, I am not looking forward to massive adoption of the bitcoin system that currently has no proper structure to guarantee an adequate level of PoW security, especially if we risk long term survivability in the process.
It's unfortune that Satoshi chose for this, halving every 4 year indefinitely, block subsidy instead of one with a continuing final inflation level since it leaves us with a currently broken system and changing the reward schedule will (rightfully) face a lot of opposition. 
@_date: 2015-06-14 18:03:36
In bitcoin, we require all participants to agree on some set of rules. These rules answer the following main questions:
- What is a valid transaction? (valid signature, output(s) smaller or equal to the input(s), interpretation of the scripts etc.)
- What is a valid block?
To gain a history of transactions on which people can rely, that is, a history that they trust other participants agree with, we need some rules on which blocks are actually valid. These rules include the proper structure of the block, the coinbase transaction not exceeding the block subsidy + transaction fees, a proof of work lower than the current difficulty target, and the maximum size a block is allowed to have.
As an aside, I believe a lot of confusion is caused by people refering to the maximum block size miners mine themselves as the 'soft limit', which is not really similar at all to the actual consensus critical 'hard' limit. 
@_date: 2015-06-11 12:49:47
There is only one blocksize limit, the consensus critical 'hard' limit. The 'soft limit' is not really a limit, it is just part of the local node/miner policy. 
@_date: 2015-06-19 19:05:04


I don't think I have heard anyone else make this claim. So according to you there would have been no block larger than 1mb since the introduction of the limit if there would have been no limit? The risk of blocks larger than 1mb would have had no impact on the actions of miners, users, and spammers? I don't think we can have a meaningfull discussion if those are your beliefs.
@_date: 2015-06-19 17:04:03
We shouldn't ignore new evidence and arguments from people who have a better understanding of the dynamics and structures in bitcoin today and use the system Satoshi envisioned in 2009/2010. You should realise these are some of the people that have done the most work on improving bitcoin over the years, mostly without any financial support.
@_date: 2015-06-16 23:51:27
I also don't really like Jeff's current proposal but that's not really relevant. 


Jeff's current proposal requires 80% of the mining power to agree with a change, which is at least better than allowing any miner to impact the maximum block size at some hard to quantify, potentially really low, cost. 
@_date: 2015-06-16 22:51:28
I haven't looked closely at CT but it might be worth comparing the risk of cryptographic failure. You do mention CT being based on well understood cryptographic primitives while zerocash is more moonmathy, but I don't see a comparison of possible implications of failure; the ability to print money without being detected (correct me if I'm wrong) versus unmasking utxo/transaction values (just guessing here)? 
@_date: 2015-06-19 20:43:25
Most of all, it gives users as well as miners the assurance that blocks will not exceed some limit, such that they can predict their required banwidth, storage, optimal connectivity with other miners, etc. If there would be no limit, miners could potentially hurt their competition as well as push users away from running fully validating nodes. 


The incentives of miners and users are not always aligned. It might be beneficial for miners to include transactions that ~all of the users would consider spam (things such as 1 satoshi ads which most of the nodes filter from relaying). Simplification: nodes decide the rules for the miners and loosening those rules can hurt the users.
Note that I'm not necessarily against a larger maximum block size. I'm just trying to explain that it's not as black and white as people often try to present it and that a controversial hardfork is ill-advised. 
@_date: 2015-06-10 12:03:15
The concern about the declining number of nodes is not just about network propagation. In fact, network propagation would be fine with just a couple of 'data center' nodes. The point of full nodes is the independent verification of the work of miners. We could just host a couple of thousand nodes somewhere, but we actually want nodes to have different owners and economic activity  depending on them. 
Note that it is way harder to measure the amount of listening nodes, but iirc there are some estimates (and other qualitative evidence from businesses outsourcing their nodes) that indicate a significant drop [citation needed].
@_date: 2015-05-27 16:45:53
Yes, we shouldn't properly analyse and debate changes in a novel cryptosystem that can have a direct financial impact on a lot of people. /s
@_date: 2015-05-08 15:19:53


What? The tradeoff between decentralisation and potential transaction density is primarily an ideological and economic discussion, not a technical one. There are a lot of economic/game theoretical subtleties in bitcoin that are not well researched at all, maximum block size being one of them.
 


This shows a critical misunderstanding of the miner - user relationship in bitcoin. Users should dictate the rules for miners, not the other way around.
@_date: 2015-05-08 22:23:02
I don't quite understand your comparison with central bankers. First of all, a (most likely) majority of the discussion on the maximum block size is done in public and anybody can participate. The opinion of the core devs is useful and interesting, primarily because they have (together with several other community members and some others) the best understanding of the implications and tradeoffs that come with changing said mbs. They at most influence the opinion of others on this topic. Since there are no automatic updates etc., they do not decide on whether or not users adopt the change. 
Bitcoin is not a democracy, there is no direct or indirect mechanism that forces users to agree with certain rules (as opposed to elected people deciding on monetary policy, like in most traditional fiat currencies). 
Ultimately, people agree with a very specific, concensus critical, set of rules by running certain software. If a fork happens, users on each fork can actively compare their subjective valuation of both forks and switch freely. 
@_date: 2016-03-04 23:46:55
How can you possibly classify requiring a thorough analysis of the effects of a larger maximum_block_size on the only competitive advantages of Bitcoin as "perfect being the enemy of good"?
@_date: 2016-01-19 12:14:14


That's not how payment channels work. The whole point is that they are "normal" bitcoin transactions, with the benefit that they only have to be included in the blockchain when the counterparty misbehaves (or when opening/closing a channel). 
@_date: 2016-01-19 17:12:06
[You're not the only one](
@_date: 2016-01-19 22:11:54
It would actually save Bitcoin and most likely be a way less contentious hardfork than raising the block size currently is. 
@_date: 2016-01-18 16:10:22
In addition to this, "credit card replacements" are being built on top of bitcoin, either with semi trusted third parties (e.g. greenaddress) or without (e.g. lightning network). 
@_date: 2016-01-03 12:25:04
I would obviously consider them bitcoin users, just not Bitcoin users. There are significant differences in security and privacy, especially with the current state of SPV. 
@_date: 2016-01-03 11:50:37
Are you really asking how many Bitcoin users are necessary?
@_date: 2016-01-03 12:43:00
SPV level security is something a lot of users are not interested in, this might change in the future tho (e.g. with utxo commitments).
@_date: 2016-01-03 13:16:39
Using bitcoin the currency, sure. Using Bitcoin (in my book) includes using bitcoin, but also fully validating the work of miners, deciding which transactions to relay, etc. 
@_date: 2016-01-19 22:19:03
I'm not sure why people are surprised about this, it has always been the best defence against a large amount of "offline" hashing power. Note that this is also something that forced all somewhat serious altcoins to use Bitcoin ASIC incompatible PoW. 
@_date: 2016-01-03 11:47:36
Disappointing post, shows a general lack of understanding of Bitcoin (primarily the role of miners). 


Do you seriously consider increasing the minimum requirements to use Bitcoin a low hanging fruit scaling solution?


Most concerns are not about absolute numbers of nodes but about significantly increasing the requirements to use the Bitcoin network. 


Average block size != Maximum block size 
The average block size might have doubled over this period, but that doesn't tell the whole story. The maximum block size, which dictates some of the requirements to use Bitcoin, did not change during this period. Using observations from an increase in average block size and presenting them as a reasonable prediction for the effects of increasing the maximum block size is insane.


Not sure I would call it healthy when miners would directly benefit from the one thing Bitcoin tries to avoid, centralisation. 


It also massively increases the requirements to reliably use Bitcoin, with little gains in average transaction throughput. 
@_date: 2015-08-10 22:02:07


No, it does not. It creates a (EDIT: infinite round) bargaining situation in which the delivery of the product has no (economic) effect on the bargaining positions. It does however open up all sorts of scamming opportunities, e.g. credible cryptographic/legal commitments to not accept any deal that provides the scammer with less than some predetermined share.


Most, if not all, of those exit scams are from traditional escrow situations. 2of3 is fundamentally different since the arbiter (arbiter, not escrow) can only steal funds by colluding with one of the two trading parties. You can further secure the trade with reputation systems and/or some sort of arbiter-pool-based financial commitment. 
@_date: 2015-08-11 00:15:49
It's just a basic infinite round bargaining game with some irrelevant sunk costs for both parties. They don't even have to announce that they are acting dishonest ("Hey, the package got damaged during transport, we should split the losses"). Furthermore, some of these scamming attempts even have ~no cost. So you would need to have the entire population of traders to be willing to have funds locked up (or considered lost) to punish bad behavior. Once again, this might work well for low value trade in practice. 
Let me turn the question around, do you have any proper specification of the security model, and how well it holds up under different values for trade population, %scammer, %willing to punish, etc.?
@_date: 2015-08-03 16:17:45
Giving miners full control over the maximum block size is a horrible idea that will most likely not lead to a desirable maximum block size. 
@_date: 2015-08-03 16:33:15
Because miners don't carry the (full) cost of larger blocks, users do. Especially as block propagation becomes more centralised, the marginal cost of transaction inclusion for miners drops significantly. Since the demand for block space (for actual transactions, but more so for arbitrary data) is ~infinite at negligible cost, blocks will become larger and mining more centralised. 
The users/we care about miners, but we don't care about *the* miners.
@_date: 2015-08-19 04:07:19
I responded to some of the faulty parts of his post but I can't respond to parent anymore.


That's probably due to a lack of effort. You might not agree with their view on the importance and/or impact of certain effects, but not understanding why they don't agree with certain proposals is all your own fault. 


[citation needed]


[citation needed]
It is obviously not as black and white as you're presenting it to be, there is a fine trade-off between costs of using Bitcoin and negative effects from a limited maximum block size. 


Might I suggest actually reading the relevant discussions and arguments?


Their is probably some information lost in the conversion from the email to this reddit style summary. But I think the point the person was trying to make is that he or she believes Gavin's recent actions actively hurt Bitcoin by creating an altcoin and/or promoting a controversial fork (fwiw, I don't agree with several parts of this reasoning). 


I agree, so why shouldn't the Blockstream associate be allowed to speak his mind to you regarding what he/she believes to be reasonable grounds for reconsideration of Gavin's position?


Once again, it's not that black and white. They are against a sudden large (subjective) increase, scheduled high (subjective) annual increases, the way a fork is scheduled (i.e. the required acceptance rate), or a combination of these. Also, the 5th "core dev", who is not employed by Blockstream, shares at least some of the same beliefs. 
("Gavin is the only core dev who supports 8 mb block one year from now, he must be working for the cia!" /s)
Also, the cherry picking in your list of people is ridiculous, even including a non core dev, and ignoring the fact that there are other public voices sharing some of these concerns (i.e. Szabo or Ptodd).


Provably false; they have time-locked bitcoin "bonuses". 
@_date: 2015-08-03 17:45:37


Whether I personally have experience with mining is irrelevant. The point is that the incentives of miners and users are not perfectly alligned. Thus, we require certain rules to restrain the power of miners, such as a maximum block subsidy, block size etc. We don't care about the profit of miners, we only care about them providing an adequate level of security through their raw costs, level of decentralisation, etc. 


Marginal costs from an increase in stale blocks are way lower due to centralised block propagation, spv mining, and miner centralisation.
@_date: 2015-08-04 14:36:13
This has been discussed a gazillion times. There is a tradeoff between more confirmation granularity and a decrease in security against certain attacks.
See 
@_date: 2015-08-03 18:51:36
So you're saying that the purely economically rational miner equilibrium leads to the socially optimal state of bitcoin for the only relevent actors, the bitcoin users, if we remove the maximum block size? That would be great! Any proper analysis to support this claim?
@_date: 2015-08-10 23:31:12
Right, it's not an easy problem :) There are partial solutions to some of these problems (e.g. [TLSNotary] ( but it remains a matter of who to trust, and what to trust them with (with the removal of a classic escrow being a great start). 
The main point I was trying to make is that the 2of2 multisig is not some magical solution. It makes no sense from a game theoretic point, and claiming it to be is disingenuous.
@_date: 2015-08-03 21:51:01
@_date: 2015-08-10 22:22:02


Fundamentally, we have two parties (who have both put up some money) who can share some amount of wealth if they manage to agree on the distribution on said wealth. Following traditional game theory (i.e. not behavioral) we have the exact same game before and after the product is sent (or isn't sent). Once again, I'm not sure people are actually willing to put in the effort to create some elaborate scams, and it might actually work fine in practice, but the "fair" distribution is not some magic NE (I'm saying magic because it might be a NE based on some sets of beliefs). 


Right, if you want all parties to be anonymous it will be quite insecure. If arbiters have reputation at stake, or commited something else (e.g. money in a 50%+_OF_ARBITERGROUP msig) this could be resolved. 
@_date: 2015-08-03 17:01:36
As with most, if not all, consensus rules, the maximum block size is a rule set by users to prevent miner abuse. Miners have some freedom in their block architecture, but are restrained by these rules, to protect users. In the case of the maximum block size, users are given certain (maximum) requirements for participating. 
@_date: 2015-07-30 00:20:37


If not for Greg and other current Blockstream associates (and several others ofcourse) larger than 1mb blocks would be even less viable right now.
@_date: 2015-08-21 02:35:17
But it lowers security against several attacks (i.e. selfish mining and "51%" attacks require lower thresholds) since attackers don't suffer from the higher loss (of work) from stale blocks if they mine a different private chain. 
@_date: 2015-08-19 04:02:27
Because they are ~all scams and snake oil, except for a select few (i.e. monero).
@_date: 2015-07-30 00:39:19
Mostly just bitter about people being overly dramatic. 
Without the work of current Blockstream employees Bitcoin wouldn't run half as well as it does right now, let alone with larger blocks.
@_date: 2015-07-22 03:01:22
Bitcoin has by far the largest developer base, the amount of transactions a system can handle is not just a function of the maximum throughput/time and definitely not without externalities.
@_date: 2015-08-21 12:00:48
They currently advise people to wait 2880 blocks before considering their transaction confirmed. 
@_date: 2015-08-10 21:30:55
General setup and protocol seem pretty decent. 
It's a shame you went with the 2of2 "Nash equilibrium" approach, instead of a 2of3 arbiter one. The basic security idea behind it is fundamentally unsound and you put your full trust in the other party. These two party escrow schemes are unable to reach a desirable game theoretic outcome (assuming rational actors who only care about financial gains). It might work fine in practice, especially for low value trades, but please don't make claims about the unprofitability of scamming and/or some "good" Nash equilibrium. 
@_date: 2015-07-30 00:57:06
That's actually not at all what they're doing. They are being cautious about a massive increase in requirements to use bitcoin. There are already multiple centralised alternatives, and bitcoin wouldn't be able to compete with them. 
@_date: 2015-07-30 01:53:48
I don't give a shit about what Satoshi wants/wanted. Obviously we would all like to be able to have all transactions on the bitcoin blockchain while everyone is still able to run a full node on his or her toaster. Unfortunately, this cannot be done with current technology. The different opinions then form around the question of how difficult it should be to properly use bitcoin. The more centralised it becomes, the more it would have to compete with the likes of paypal. On the other side, lower requirements results in a limited amount of transactions, which can lead to a limited user base (or solutions such as lightning). 
@_date: 2015-08-10 14:30:48


You would be the first :) There is still a lot of discussion on the expected implications of a different maximum block size. 


This subreddit (especially if you pay more attention to posts with higher votes) is indeed a horrible place to find sane discussions on the topic. Search through the (although recently more and more noisy) bitcoin-dev mailing list [1] and the  [2] and  [3] logs.
[1] 
[2] 
[3] 
@_date: 2015-07-23 01:24:57


I constantly see people saying this, which I believe is a misunderstanding of his argument. Luke believes that we should keep the requirements to 'properly' use bitcoin (by running a full node) as low as possible, potentially at some costs others (myself  included) would disagree with. He uses his personal internet situation as an example of people not having access to the internet they might require with larger blocks. Ultimately, it is a disagreement about what bitcoin should be, and not about him only caring about his personal ability to run a full node.
@_date: 2015-07-22 02:55:40
Bitcoin-wizards is a low traffic research channel and constantly repeating these general questions and discussions on  wastes a lot of time and hurts bitcoin related research, so please refrain from doing so. Instead, search through the (lately unfortunately noisy) logs and/or ask for clarification on 
@_date: 2015-07-23 00:28:47
It is however important to remind ourselves that bitcoin is a complex cryptosystem, with currently poorly understood economic incentives and subtleties. So we find ourselves in this position where different groups of people have a different subset of ideas about and understandings of bitcoin. This is one of the reasons this "debate" is dominated by people shouting past each other, which becomes quite tiring. It is easy, especially on reddit, to jump to conclusions because a majority sees the scenario from a certain perspective, which corresponds with your own. I believe it was gmaxwell who gave the example of Zerocash, which people without a solid understanding of the experimental nature of the underlying cryptography gladly wanted it implemented in bitcoin. Recently, a bug in Zerocash, that could have lead to unnoticeable and unlimited inflation (iirc), was found. /rant
TLDR: Less shouting, more listening, and definitely less personal attacks and insults please.
@_date: 2015-07-29 23:45:57
You seem to define a denial of service as not being able to have your transaction included in some future block for some transaction fee, which is at best just part of the story. 
Generating a number of transactions with a transaction fee that is larger than the miners their marginal cost of transaction inclusion can only be considered a DoS attack if wallets use a static fee approach and/or there are no good and reliable ways to increase the fee on your transaction. Since losses from slower block propagation are small, the cost of filling blocks is rather low, not just for the current max 1mb blocks.
A more serious DoS attack would be the allowance of large blocks, which would make using bitcoin way more difficult for a lot of people. What's the point of having your transaction included in the next block for a lower fee if you can't even use bitcoin? 
@_date: 2016-02-01 19:51:42
[Reduce upload traffic](
@_date: 2015-09-02 17:38:25
The integral part of how Bitcoin works is that miners are free to include the transactions they like and that transaction inclusion policy is not centrally planned.
EDIT: Ughhh, that's probably what you meant. My bad.
@_date: 2015-09-02 17:01:53
Good to see miners actually using custom policies. 
@_date: 2015-09-20 10:35:07
I generally tend to agree, but it is important to keep in mind that bitcoin is a fragile cryptographic system in which people have invested large amounts of capital. What we now consider to be merely theoretical concerns could very well turn into practical problems, as it often does in these fields. Waiting for them to become actual problems for end users can be quite dangerous as it becomes more difficult to change the (understanding of the) system (e.g. [despite rc4 being completely broken, it is still widely used] (
@_date: 2015-09-04 01:55:36
To 8 peers in 30 seconds. 30 seconds being a subjective estimate for 'barely fast enough' block propagation.  
@_date: 2015-11-09 20:29:00
From the ~unlimited demand for cheap immutable data storage. This especially becomes a problem if the marginal transaction inclusion cost for miners becomes extremely low as a result of faster block propagation (read: centralisation). 
@_date: 2015-11-20 13:54:32
Exactly, xt intentionally operates with a different ruleset. The fact that they currently accept the same blocks as valid doesn't change the fact that they have different validity definitions. 
(I'm not saying it should be considered off topic on this sub or w/e, just pointing out that there actually is a significant difference between bitcoinxt and bitcoin-ljr)
@_date: 2015-11-30 02:47:08
Looks like the term double spending is double spent. We might want to commit some more energy to resolve this issue. 
@_date: 2015-11-28 01:33:39
FSS-RBF is extremely ugly and inefficient. You would have to add an extra input which makes transactions larger, causes usability problems, and greatly increases the complexity of wallet software (compared to unconstrained rbf). 
@_date: 2015-11-10 00:06:41
No, he means SPV mining won't be possible with utxo-set commitments (because you need to update it with the information from the previous block before you can mine the next one).
We obviously can't make the mempool consensus critical (if we could, we wouldn't need PoW at all!).
@_date: 2015-11-20 14:23:01
"Censorship" at the individual node level is encouraged. Users have full control over which transactions they want to relay and they are free to do so based on whatever criteria they like. Luke believes transactions with certain structures and/or characteristics do more harm than good so he uses and released this custom relay policy.
@_date: 2015-11-20 13:30:59
No, the consensus rules are perfectly compatible with bitcoin core.