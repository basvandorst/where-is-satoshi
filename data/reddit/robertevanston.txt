@_author: robertevanston
@_date: 2016-04-29 16:25:47
They've been fine for me.  I really don't trust exchanges with large amounts of fiat, and while 1% is a high fee, it still ends up cheaper usually than paying Circle's buy price (which is a few bucks higher generally despite 0% fees).
@_date: 2016-04-09 15:15:34
I agree with some of what you said.  Again, your original definition is wrong for reasons I already clearly pointed out.  Also, it is inconsistent with the classic definition of "spam" (Oxford dictionary)


Just because another network is better value for *you* doesn't mean your original transaction was irrelevant or inappropriate to Bitcoin.  There is no logical connection there, so I see your definition as a "redefinition" and would caution against using it implicitly.
What you are really doing here is defining low value transactions as spam.  Because Bitcoin is pay-per-space rather than pay-per-value (modulo node priority rules not part of the consensus set), low value transactions are disproportionately affected by increases in transaction fees.  To imply that low value transactions are inappropriate or irrelevant requires further justification that I imagine would not stand up to scrutiny.


That's a nonanswer.  When you're comparing utilities and you're including security in your calculation, you either need to quantify it somehow or discard it entirely.  Otherwise don't involve utility / optimization in your arguments.


What if the Bitcoin network wants to take your transaction at the fee you're paying for it, but there's an artificial limit not based on technological capacity preventing it from doing so?  You're analyzing this situation as if you're dealing with a free fee market, but when you have a cap the analysis needs to take this into account.
@_date: 2016-04-29 16:23:16
Look up group polarization.  It's a natural part of the dissenters being banned from here: they go there and become polarized over the issue they were banned for.  And this group, lacking those dissenters, becomes further polarized in their views as well.
Splitting any community in two on ideological grounds is a surefire recipe for the kind of distorted, nonsensical, emotionally charged arguments you've been seeing on both subreddits.
@_date: 2016-04-09 14:07:07
You can keep on your definition all you want, but persisting on an incorrect definition pretty much ruins any shot you have at an argument.  No economist or game theorist would take such a weak argument seriously.  Either way your arugment has just changed , before you said: 


My point is you can refuse to pay 2 cents and be willing to pay 1 cent on a transaction that is worth *way more than 2 cents* to you.  The *transaction* can have $100 of utility to you, but doing it over a different network that costs 1 cent can provide you with equivalent utility, so you will refuse to pay 2 cents.  That much seems obvious to you now right?


Better for everyone why?  How do you quantify security?  As for being better off on a lower liquidity chain, if you insist on this argument it implies that the Bitcoin network should only be used for high dollar-value transactions (as your exposure to the liquidity of the network is proportional to the value of your transaction).  
@_date: 2016-04-26 19:02:31
I think we can all agree that the real problems come when there are users likening alternative implementations to a coup or hostile takeover.  Those are meaningless terms in the world of decentralized development.
@_date: 2016-04-09 13:46:03
This analysis only passes muster if Bitcoin exists in a vacuum, which it does not.
Given that Bitcoin has competitors, not being willing to pay two cents does not mean the transaction has less than two cents of utility.  It means that 2 cents - (price of next best competitor) is less than the added utility the Bitcoin network provides over using that competitor network.  
@_date: 2017-12-05 03:02:19
Or, yknow, just keep on with the anti-intellectualism.
@_date: 2017-02-15 19:27:02


Well this is the crux of the issue.  You pulled the 100/1 figure out of your ass.  If there were verifiable numbers there I may agree with you, but there simply aren't.
@_date: 2017-02-15 20:13:28


In the end, the signal overcomes the noise (you), my friend.
@_date: 2017-02-15 13:50:13
That would be a 51% attack, and would signal the beginning of the end of the Bitcoin network.  I'd imagine many (myself included, medium-sized holder since 2011) would divest at that point.
@_date: 2017-02-15 17:26:35
Oh wow, you linked to yourself as a source.  Kewl.


You are imposing a very strange definition of "bitcoins" here, on which your argument rests.  Can I have the precise falsifiable definition you're using?  It does not seem consistent with any [definitions I have seen proposed]( in which both chains may be considered "Bitcoin" by the network.  
Also a very strange definition of "force".  I'd consider a network-based attack on my current system (which denies users inside the system who make no changes service) "force", whereas I consider the economic majority leaving for a different system (which I am free to join or not) the very opposite of that.
You don't have the right to the economic majority's trading activity.  You do have the right to use whatever consensus rules you choose without attack (Byzantine behavior inside the protocol you follow).
@_date: 2017-02-15 16:22:37


Slippery slope fallacy.  Nobody is promoting the adoption of a fork that violates 21M.  And if someone did, I'd want to be rid of them anyway.
@_date: 2017-02-16 00:27:40


What are you talking about?  Of course they can.  Just have IANA revoke the IP assignment of every Bitcoin node (or reassign it to a malicious fake peer if you want to *really* kill the network).  A sustained attack would involve automatically connecting to and blacklisting peers.  Unless you start running Bitcoin over meshnet, carrier pigeon, or sneakernet, the system is done for.  They can also easily put pressure on ISPs by threatening their blocks if they fail to actively police nodes.  Of course this would be a huge scandal way beyond Bitcoin, but it is possible.


I will tell you as someone who is using AWS for a significant node, you are wrong.  I need the node regardless of whether AWS chooses to run it.  I've been running nodes since 2011, long before AWS, and I will be running nodes long after AWS.
@_date: 2017-02-15 17:02:09


LOL!  No, no it doesn't.  The proposed coercive activation involves all miners following consensus rules A, where some miners decide to follow A' such that A' âŠŠ A.  Miners orphan all blocks that are valid under A and not A'.  Miners following A \\ A' then have service denied, even to nodes which follow A (and by extension A \ A' and A').
In a hard fork, all miners are following consensus rules A, and some miners decide to follow B.  Any miners still following A are not denied service w.r.t. nodes following A.  Instead, the miners following B (forkers) are denied service to these nodes.  This is a change they opt in to, unlike the miners denied service in the previous example.
The distinction is quite important, I suggest you try to understand &amp; internalize.
@_date: 2017-02-15 19:27:38


I do not consider this against the spirit of decentralization as long as all nodes are not in *the same* well connected datecenter.
@_date: 2017-02-15 16:59:01


Only alts that are created through copy-pasting the Bitcoin codebase are proposing SW.  Alts that are independently developed or substantially modified (Ethereum, Monero, zcash, etc.) are not.
@_date: 2017-02-15 17:36:57
The 95% threshold comes from BIP9:  
51% attack is explained here:  and also in the whitepaper
The user here is proposing that 90% of the miners "51% attack" the other 10% to reach the BIP9 activation threshold.
"51% attack" doesn't actually require 51%, this is just the neatly rounded threshold for the attack to succeed indefinitely on an infinite timeline.  If you do a 51% attack with 90% hashpower, you have an even higher chance of success than if you do it with 51% hashpower.
@_date: 2017-02-15 21:33:55
Bitcoin simply doesn't support the type of contracts Ethereum does.  Once it does, we can talk about whether the useful contracts will work as well on Bitcoin.  Especially with tx fees being what they are, my intuition is no (remember these transactions can be huge and far more expensive than what BTC processes today... a computation that requires 10x typical BTC tx power would cost $2+ on the Bitcoin chain for full everyone-verifies security).


No, it can't easily be gamed.  If you think it can, you can make a killing from doing so.
@_date: 2017-02-15 19:30:40


Ethereum is about as speculative as Bitcoin.  That is to say, "mostly".
Saying there are no real world uses for Ethereum is relatively ignorant though.  There are a wide variety of smart contracts that have achieved considerable adoption.  The DAO is a real world use case, as is MakerDAO, as is Augur, as is Digix, as is even something like EthPonzi, BTCRelay, etc etc etc.  People are using these systems today.
Either way this is irrelevant to the discussion, which is about Bitcoin.  I never personally mentioned Ethereum.
@_date: 2017-02-15 18:30:05


Have not seen any data suggesting they are more "prone" to this than any other node.
@_date: 2017-02-15 16:28:02
OK, fair enough.  You are right, I misunderstood.  
This seems to be a definition / notation issue.  Personally if two chains survive, one with 80% and one with 20% economic support, I'd say that one BTC in the old system = .8 BTCA + .2 BTCB, in which case 21M is preserved.  But this is just my preferred notation and I could also see how you could consider a split as creating "more than 21M tokens which could potentially be called Bitcoin".
@_date: 2017-02-15 18:41:36
Again, there is no way to quantify the utility/economic activity or number of such nodes, and no proof that people aren't doing the same on home connections.  As a user running an AWS node, I'm not on board with being discounted from statistics.
@_date: 2016-03-14 14:41:56
It's not censorship for a few reasons:
- Users can configure thresholds to hide posts at.  If they want, they can ensure no posts are hidden.  They can also choose sort orderings to view more controversial comments.
- Downvoted comments still get read.  The comments that are at -100?  That means at least 95 people read them after they were "censored", with the true number likely being much higher.  I know I tend to read all collapsed comments in a given thread, don't you?  This is not the same as wiping all traces of the very existence of a comment off the face of the Earth.
- Reddit admins have sophisticated tools to deal with brigading, botting, and other forms of vote manipulation.  They've been doing this for almost 10 years now, and it's not a problem exclusive to r/Bitcoin.  Votes from new accounts are often ignored in vote calculations, accounts that tend to vote often on the comments of specific users or subjects are ignored by the same filter, votes from IPs that tend to be known for spamming (such as through public proxies and Tor) are ignored or flagged, vote counts are fuzzed, etc.  
I agree we shouldn't be downvoting dissent to shit, but it's not really the same as removing it.  We should be encouraging all viewpoints, even when it's difficult.  Both subs have failed there.


Source?  I know some members of Core said they would investigate a potential HF, but I haven't seen a commitment to 2MB anyway.  I also haven't been paying attention for the last few months of this drama so maybe I just missed something.
@_date: 2017-02-15 20:15:32


You don't understand the problems a [decentralized prediction market]( solves?  Or a decentralized crowdfunding scheme?  Or BTCRelay, which can be used in things like smart contracts governing mining?  What about a [decentralized TV production pipeline](  An [identity system](  I can go on all day, but we're far off topic.  Either way, you're dead wrong about the lack of real use cases.
Most of Bitcoin is also speculation.  Doesn't make it useless.
@_date: 2017-02-15 21:42:22
That's not what he claimed.  He claimed that for every 1 legitimate AWS node, there are 100 AWS nodes backing no economic activity.  Obviously you can tell which nodes are AWS, but you don't know how many are actually useful (could be 99%, or even 1%, but guesswork is just that... guesswork).
So you can't take out all AWS nodes and say "these aren't useful", because many of them (including mine) *probably are*.
@_date: 2017-02-15 16:24:54
You understand that "51% attack" doesn't mean you need exactly 51% of hashpower?  It's a general term for maliciously using hashpower to orphan otherwise legitimately valid blocks for a sustained period of time.  You can do it at 90% hashpower, 51% hashpower, [25% hashpower]( ...


You are wrong.  It is a denial of service attack on legitimate miners, and an attack on the Bitcoin system as a whole.
If you want to activate a controversial soft fork without hashpower consensus, fork off to your own chain, don't attack the main chain.  
@_date: 2016-03-13 12:34:40
What?  This is patently false.  There is definitely such a thing as mining decentralization (google Bitcoin mining centralization and familiarize yourself with previous discussions on the issue, which date back to Satoshi and his analysis of the ongoing trend towards centralization in pools).
Consider the degenerate case, where 100% of the hashpower is controlled by a single entity (full mining centralization).  What attacks become possible?  Rewriting ledger history, arbitrarily doublespending, denial of service, and more.  There is definitely such thing as mining decentralization, one of the core assumptions of the Bitcoin network is an honest majority of hashpower (which is stated several times in the whitepaper).
Now consider the ideal case, where hashpower is evenly distributed geographically among all users.  This clearly increases the security of the network, making any of the abovementioned 51% attacks significantly more difficult and expensive.
There are many types of decentralization.  Node decentralization, mining decentralization, development decentralization, community/discussion decentralization, user decentralization, just to name a few.  We need to balance the tradeoffs that various changes like blocksize require on each metric.
@_date: 2017-02-15 18:23:39


I see you are not interested in a good faith discussion.  Sorry to hear that, cheers.
@_date: 2017-02-15 21:36:07
False dichotomy, there are more than two possible causes.  A [huge increase in bandwidth]( is going on right now, both in the US and globally.
@_date: 2017-02-03 19:39:30
I think it's your argument that is both weak and internally inconsistent.  Judging by your knee jerk, poorly articulated (featuring bad grammar, all caps and more) response though, I don't expect you to recognize such inconsistencies.


Can I then post all sorts of stuff promoting my own cryptocurrency, FUCash?  If not, why not?  Where is this VCash / FUCash distinction in the sidebar rules?
The crux of my argument is that mods apply rules inconsistently to further hidden agendas not explicitly enumerated in the sidebar, and your own argument has neatly substantiated my point.
@_date: 2017-02-15 22:00:02
100Mbit is also a common home Internet speed.  At my last four addresses (in the US), my connections have been: 100 megabit, 160 megabit, gigabit, and (now) 125 megabit.  All of them symmetric except my current connection, which is 50 up.
@_date: 2017-02-15 18:24:44


There's no way to tell what someone is using a node for, AWS or otherwise.  I run a node on AWS that I do use for purposes other than "propaganda/political", and I would hate to be excluded from network statistics.
@_date: 2017-02-16 02:37:47
What an eloquent rebuttal.  I'm sure you've got everyone convinced!
@_date: 2016-03-28 13:07:03
There are plenty of people who work to whom over $8k is a lot of money.  Statistically, most people who work full time don't have that much in savings.
@_date: 2017-02-15 22:12:15
What if I told you that it wasn't that simple, and that [every Bitcoin node currently operating can be shut down by 1 person](
If there are 1k nodes on AWS, and all 1k users will spin up a node elsewhere in the event of shutdown or compromise, they are certainly and undoubtedly useful.
@_date: 2016-03-14 15:21:21
No problem, remember it's the wild west of finance for a reason, there are lots of ways to lose your money.  Start small and treat everything you do as a learning experience.  If you get to the point where the amount of BTC you have makes a difference to your quality of life, make another thread here for advice on storing them safely.
@_date: 2016-03-14 14:56:55
No problem, glad I could be helpful.


I don't think this is even possible.  Incompatible currencies would fail to validate as valid TXs with both miners and nodes.  If you're talking about tokens that are built on top of Bitcoin (like XCP), I'm totally fine with those transactions on the Bitcoin blockchain as long as they're paying fees.  If the fee is high enough for a miner to include let 'em have at it.
@_date: 2017-02-15 19:28:04
Clearly you have not.
@_date: 2017-02-03 19:02:07
Yes, if you talk negatively about another altcoin then it's allowed.  It's only when you're "promoting" altcoins that it's banned.  Makes total sense.
Same with contentious forks; touting their evils is allowed, discussing their benefits (aka "promoting") prohibited.
Only without "overwhelming consensus" though, where both "overwhelming" and "consensus" are defined by moderators on a case by case basis.
@_date: 2017-03-17 04:43:35


Your analysis is actually flawed here.  UASF is equally risky to the equivalent hardfork.  UASF assumes economic majority support.  If the equivalent hardfork had this support, miners would also have that same exact, identical strong economic incentive to cooperate.  You said **than an equivalent hardfork**, which would be an economic majority backed hard fork, not a "miner forced" hard fork (which is equivalent to a "miner forced" UASF).
They are literally equivalent.  The differences are negligible.
@_date: 2017-03-31 14:38:40
Core has no center!
But make sure you run your idea through the 4-5 gatekeepers in  before you submit your "noise" to the mailing list, Mr. Non Expert.
@_date: 2017-03-17 14:07:53


We're not talking about BU here, are we?  I can see where the confusion comes in if that was the assumption, "emergent consensus" is independently risky 


This is not true for hardforks that are strict supersets of existing rules (like removing or lifting blocksize limi).  Like UASF, nodes on both sides will follow majority hashpower unless majority hashpower is incompatible with their change.  It's identical.
@_date: 2016-03-14 14:51:27
Don't invest what you can't afford to lose, and treat it as gambling.  Nobody can predict the future and you should be skeptical of anyone trying to predict Bitcoin performance, it's likely they have an ulterior profit motive in getting people to buy or sell coins.  That being said there are many people that think there is a significant upside to be had, and the price right now is half the previous ATH.  If you think Bitcoin will grow as a network in the future it's reasonable to conclude that the price will likely rise.
@_date: 2017-03-01 19:43:39
And yet Samson Mow does the same but worse (and far more often) on Twitter and people love him for it.  Come on, use your brain a little.  All of this shit needs to stop, post haste.
@_date: 2017-01-06 20:28:13
You are straw-manning with your last section.  While it is partially accurate, it omits the primary complaint of SegWit critics: the 75% discount on witness space was not chosen with any sound or concrete economic analysis in mind (if you disagree, please link to an academic publication by an economist analyzing the impact of this discount on the fee market.. note that the hand-wavy argument of "but it doesn't bloat UTXO" is not a sufficiently rigorous or evidence-based justification, nor is it a scholarly economic analysis holding any water).
Thus it is not an accurate or fair reflection, or even summary, of the majority of criticism of SegWit.  This is unfortunately a pattern I see borne out repeatedly on this forum.
If SegWit were proposed with 0% discount it would likely still be controversial, but likely substantially less so.
The other complaints have to do with the [HK agreement](  Particularly "We understand that SegWit continues to be developed actively as a soft-fork and is likely to proceed towards release over the next two months, as originally scheduled." followed by "The Bitcoin Core contributors present at the Bitcoin Roundtable will have an implementation of such a hard-fork available as a recommendation to Bitcoin Core within three months after the release of SegWit."
There is little faith in the signatories keeping these promises in good faith (even barring the missed deadline, this agreement was after all almost a year ago) (the "evil fork" being an example of technically satisfying these promises in bad faith).
@_date: 2017-01-07 15:00:27


You call for nuanced understanding and then present a false dichotomy.  I don't think anyone is making arguments of this form.
The problem I have with this "technical argument"/"political argument" distinction is that it leads some (many of whom are *not technical experts* in the slightest, but many of whom are) to push through their political agenda under the guise of objective technical superiority when such a thing rarely exists in these systems.  It is the enemy of careful study and evidence-based analysis, and should be eradicated as such.


It's tit-for-tat behavior in response to what happened to a blocksize hard fork, which was also "held hostage as a political football, independently of technical merits, or game theory/political ramifications" (there has been widespread support for such a fork since 2011-2012, with study showing 4MB as safe w.r.t. network latency).
A fork is a far more studied change and technically simple/clean change than SW, so you cannot hold one hostage for being unsafe or understudied while touting the benefits of the other without acknowledging the political reasons for such.
What is repugnant here is not the "political football", which is an inevitable, natural, and healthy part of these systems.  Rather, it is the effort of some users (and developers) to push through their own agenda at any costs, harming the ideals of censorship resistance and self-determination on which the system was built.
@_date: 2017-08-22 01:28:30


The ability of the community to do a frictionless hard fork and switch PoW in the event of a permanent fundamental tenet break (21M exceeded, censorship, etc.), making miner capital investments worthless is what stops miners from censoring.
Not whether it takes 2 pools to get to critical mass or 1.
Hard forks the fundamental censorship resistant property of all cryptocurrencies everywhere.
@_date: 2017-08-02 12:14:09
When you have a subreddit that encourages people not to understand the difference between a fork and an altcoin, you get braindead shitposts like this one.  
**Bitcoin Cash is an upgrade of Bitcoin**, Litecoin is not.
@_date: 2016-11-24 05:19:22


It's somewhat inappropriate to pretend there is no discount.  The default Core+SegWit behavior is to prioritize a SegWit transaction that is 300 bytes witness and 400 bytes total over a legacy transaction that is 400 bytes total paying the same fee.  If this is not a "discount" I'm not sure what it is.  There is a quite clear formula that this 75% discount is based in, as you know (couched in the terminology of "weight").
Trust me, I understand how block weight works.  Not sure what this explanation was meant to accomplish.


There is 0 proof that the SegWit discount solves (or even disincentivizes) UTXO growth.  You also say:


This is a very strong claim.  What proof do you have that this formula "better reflects the true ongoing cost to the network that the blocks represent"?  Where is your economic analysis?  Where is your data?  You have absolutely 0 to back this up, it's a false claim, and nobody buys this "the experts decided this better represents true ongoing cost" BS when you can't even provide *any* data to back up your case (or even a definition of what goes into "true ongoing costs").


If 75% of transactions are SegWit, old nodes verify 25% of transactions.  For the rest they are reduced to SPV security.  The original statement stands.


I'm referring to the logic that now that we have "4MB effective blocks", you may argue that 4MB blocks are unsafe (as they now allow for "16MB effective blocks").  In many ways, SegWit makes hard forking to a larger blocksize more complex, as you know.


I'm not confusing anything.  SegWit is activated by miner vote only. 


This is not true and it's FUD+garbage.  In BU, nodes can set their own policy on the max blocks they accept.  They do not need to accept larger blocks from miners if they don't want to.


You know as well as I do that Antpool is behind ViaBTC and that most miners are in favor of 8MB blocks today.
The arrogance of comments like this is why you will continue to be rewarded with non activation.  I hope you take some time to reflect on your role in the failure of this protocol upgrade and adjust your behavior accordingly going forward.
@_date: 2016-11-16 20:24:24
Nah, if they fuck around change the PoW on them.  Done.  They know that's what will happen and that at the first sign of trying to exert network control or malicious misbehavior their (substantial) capital investments are now worth shit.
@_date: 2017-01-06 22:46:35


Agreed.  The problem here is that some in the community demand a very high standard of evidence for some changes, mainly the ones they oppose, whereas they are willing to take changes they support on faith.  Study should be performed before implementing any major economic change like this.
An obvious argument is that a discount for SW transactions will not make any transaction cheaper; if demand for block space is unbounded (as hypothesized by Maxwell, Back), then the price of transactions will not change with a constant-factor blocksize increase.  This means post-SW transactions will cost as much as non-SW transactions today, making non-SW transactions more expensive.  Ad absurdum, if 100% of users use SegWit forever (under an approximately unbounded demand assumption), transactions are obviously no cheaper than today.  Whether or not this is desirable depends on your particular politics, as you say further study is required no matter what.


This is false; you can easily have an arbitrarily large SW blocksize increase with no discount, but in this case have to do 2D optimization if you want to support an apples-to-apples comparison with legacy transactions in transaction prioritization.  
This optimization makes prioritization slightly more difficult, but given that you're using a highly heuristic approximation to the bounded knapsack problem for transaction inclusion anyway, specifically using a greedy algorithm that can be proved to provide far worse than 50%-optimality in maximizing fees on arbitrary inputs, the added complexity is not necessarily relevant in practice (at least from a CS perspective).


I say this as a developer and computer scientist, not an economist or politician: there is no such thing as a non-political change to Bitcoin.  Any technical change that alters the currency in any meaningful way to its users is inherently political (as it is a change in the governance of the consensus protocol a network of people rely on as money).
I want to see this "decisions should not be political" garbage die in a fire yesterday.  This entire thread is both condemning and chock full of politics and bias.  The irony is strangling the community slowly.


Neither is anybody.  As far as I can tell, it was chosen because it allows for a 1D "weight" optimization under a blocksize increase to 4MB (safe under the Cornell study), but the benefits of or alternatives to this approach were neither studied properly nor publicly enumerated, making it difficult to support such a change based on evidence.
Personally I support SW development, but this is a political opinion (I think it is the best solution to urgent issues already on the table, even if it's a suboptimal solution).  I do not support SW activation, as despite its claims of being thoroughly tested it is an unstudied change.  I'd rather have Litecoin or another alt activate it on mainnet for a few months before having the confidence to make this recommendation.  Technically I [agree with Vitalik Buterin in that it's far hackier than simple changes to the transaction format achieving the same effect](
@_date: 2016-11-14 18:01:27


No, but it's unknown as to why.  Several theories:
- Lack of node incentivization (tragedy of the commons)
- Rise of SPV, centralized wallet providers
- Client diversification
- Failure of core node offerings to keep up with technology (eg - BTC Core + BIP32 adoption curve)
- Reduced merchant demand --&gt; less economic incentive to run nodes
- Increased resource requirements --&gt; more cost to run node
etc etc etc.  Truth is likely a combination of these, and if you think you know which effect contributes how much, you are simply bull shitting.
@_date: 2016-11-12 14:03:46


It has in the US, it's [objectively become 3x faster in the last three years alone](
And globally [Akamai releases statements]( every quarter, the trend is about a 25% increase every year.
Where do you get your facts?  Do you just pull them out of your arse or extrapolate personal experience?  Because objectively, there is no denying that global bandwidth is increasing and increasing quickly.
@_date: 2016-11-27 23:16:59


Kind of not really, Bitcoin's security model already features this assumption to an extent.  If an attacker can disconnect you from all honest nodes, the threshold for a successful doublespend tx drops from "~majority hashpower" to "enough hashpower to eventually mine 2n+1 blocks" where n is the desired number of false confirmations.  Disconnection would have to be maintained in mining these 2n+1 blocks.
To fool an SPV node with n confirms, you'd need enough hashpower to mine n blocks and disconnection would have to be maintained in mining these n.  Certainly n &lt; 2n+1, and certainly the assumption has not been rigorously analyzed to my knowledge, but it is to an extent there.
(the above makes the simplifying assumption that all honest nodes feature fraud proof capabilities, which is reasonable in the long term)
@_date: 2016-11-16 19:50:00
Popescu is *kind of nuts*?  You might be understating it a bit... this is the guy who:
- Is a poster child for the men's rights movement ideology, claiming that men are oppressed in modern society by feminism
- Uses certain racial slurs beginning with *n* frequently
- Advocates rape as a good thing (actually says there is no such thing as rape)  
- Frequently personally attacks people
- Generalizes people he disagrees with by calling them "jews" 
- Oh look, more rape apologism 
And that's just what I found in 30 seconds on Google.  God forbid you actually read his rag of a blog.
He's *kind of* nuts?  Yeah, sure.  And I'm kind of the pope.
@_date: 2016-11-14 16:21:00
Link data or GTFO.  You can't just say "data shows X" and not link the data.  Data is very easily misinterpreted (even by experts), so please provide sources.
Sorry and nice try.
@_date: 2016-12-14 00:02:22


There's no technical reason for this, you could easily write code to both prune the witness and count it separately in the fee calculation.
The reason that nobody does this is that *it's not useful to modify the fee calculation in this way*.


No.  You can't simply treat things as infinite because you feel like it, you need data to validate why they approximate infinity.


No.  Witness storage cost scales linearly with witness size.


I'm not sure what this means.  SIG_OPs *are* checking the witness.  They are one and the same.  


What I said is that anyone with half a brain knows that ""A LOT MORE" is not proof of anything".  That's not an ad hominem because I said nothing about you.  You on the other hand dismissed my argument because "I don't understand the system" with no proof of such.  I am attacking an argument, you are attacking a person.  Subtle distinction, but important.
@_date: 2016-11-15 18:50:33
Thanks Rusty, awesome post and great work!  I confess I'm only an observer, but these technologies are certainly fascinating in their promise and potential.


Awesome, wasn't aware there was code out there.  Still needs to be some work on anonymity in route discovery though, from the brief look I took at Flare it looks like it has the potential to leak lots of data to both neighbors and beacons.  I may be wrong because I confess I only skimmed that paper.


How do you accomplish this with two malicious nodes in the path?  Let's say I've routed successfully past malicious node A, and malicious node B now refuses to sign a tx for me in their channel.  When I go back to A and ask it to fall back, A can likewise refuse to sign an updated tx.  Is that correct or am I missing something there?  I suppose you can publish some sort of proof of cheating to the blockchain (or a channel they have money in) and steal the money they have locked in their channels, but this seems to open another potential exploit vector.  Can probably lock this down with the right analysis but I'm not sure if anyone's actually working on this right now myself.


It is great having an incorruptible global source of truth to punt to eh?


Looking forward to seeing how the network topology and churn rates play out in practice, because personally I have no idea what I even expect this to look like :).  I agree, for micropayments it seems far less of an issue than for large sums.
@_date: 2016-11-22 20:26:52
Do you really need to as a technical person in finance?  If you get fired you just take your 6 months severance pay and go on vacation, a new job won't take more than a month to find if you're any good.  Hell, 2 days if you have connections.
@_date: 2016-11-22 20:24:41
And if this happens, it will take soft forks off the table as a "non contentious" upgrade mechanism for anyone with half a brain, and probably cause an escalation in this game of politics that would make things even nastier for everyone.  Hell, the 49% can destroy the chain that is orphaning their blocks with something like a selfish mining strategy and targeted doublespends.
IMO either the fork activates peacefully with 95% or we need to move on to the next potential solution.
@_date: 2016-11-25 15:38:26
That has nothing to do with the discount formula.  What is the economic value of keeping the data?  What is the cost?  Does the cost exceed the value?  By how much?
You can *already* prune witness data (and indeed the whole chain) if you want, so the fact that the data is "prunable" does not imply that it should be cheaper.
So no, this does not constitute evidence of the claim (that the new formula better reflects cost realities).   Hell, the claim cannot even *be* supported by facts until you've more rigorously quantified it (whose true costs are we optimizing to; miners, SPV wallets, or nodes?  an average of these?  weighted average?  sum across the network?).
@_date: 2016-11-22 20:06:20
This is my perspective as someone who's worked with these people.  If you have an alternate perspective, provide it.  Look at everything the banks do though or talk to literally anyone actually involved and what I'm saying is obvious.  
@_date: 2016-12-13 22:19:13


Another straw man.  I've never spoken to Ver (online or otherwise), and I have absolutely no love for his relentless Randian rent seeking.
On a roll my friend.  Perhaps try to accuse me of trying to turn Bitcoin into PayPal next?  Seems to be the logical successor in this series of straw men.
All of which have nothing to do with how "cash" is defined in the whitepaper, the matter under discussion here (in case you forgot).
@_date: 2016-11-22 20:11:06
To quote my man Trump,  **WRONG**.
The two participants in the channel could collude to give you a fake history that they never intend to broadcast on-chain.
@_date: 2016-12-13 21:32:20


How much more?  To whom?  Give me numbers (preferably in USD, EUR, or a stable asset).  How much more do they cost miners?  How much more do they cost nodes?  How much more do they cost SPV clients?  How are you weighting the sums of these costs?  Just saying "A LOT MORE" is not proof of anything, and I'm sick of reiterating this fact, which **should be obvious to anyone with half a brain**.
@_date: 2016-12-14 02:57:13


I agree, this is unfortunate.
@_date: 2016-11-24 14:18:28


Are you honestly saying that the amount of bytes has no meaning in the new system?  No meaning?  No meaning in terms of disk space requirements for archival nodes, effect on cost to run a full node, verification time, RAM usage,  etcetcetcetc?
It has "no meaning" (your words, not mine) in the *fee calculation*, which clearly makes the fee calculation a piss poor reflection of system costs.


What a stupid thing to say.  The number of 1 bits set affects nothing of what I've mentioned above (except perhaps compressibility, but with a very loose correlation), so unlike the size of the transaction it actually **is** irrelevant to the fee calculation.
You still never addressed my other points, which are that you have **0 proof that this formula better addresses real network costs** than the old formula based exclusively on tx size.
@_date: 2016-12-14 00:06:50


The revolution is on hold because it's hard, guys.  Not surprised you use a CC for daily transactions.  It's hard to really understand Bitcoin until you live it.  Simply contributing to Core is not enough, you must both understand Core's code and use the product for a complete picture.




Most Bitcoin businesses **accept** zero conf transactions.  Again you'd have no way of knowing this, as you don't actually pay in Bitcoin.
@_date: 2016-12-13 21:57:34


Witness data can be pruned without SegWit.  You know that, right?  
**It still needs to be processed before pruning and stored by some nodes**.  AKA the cost is not 0.  You understand that right?


Asymptotic bounds are not the same as true costs.  Witness processing still has a cost that scales with witness size.  You also know that right?


Continue with the cheap ad hominems, they do nothing to bolster your credibility.
@_date: 2016-12-15 16:07:58
Delete this post.  99% of users only read the title, and you are peddling false and dangerous propaganda personally attacking a community member.  This is Fox News level crap.
@_date: 2016-12-15 16:53:37
Not correct.  There is a 4x max difficulty adjustment in Bitcoin.  If 10% of hashpower decided to fork (for simplicity assume at a difficulty adjustment), it would take them, on expectation:
- 201600 (20 weeks) minutes to mine the first 2016 blocks (difficulty adjustment 1)
- 50400 (5 weeks) minutes to mine the second 2016 blocks (difficulty adjustment 2, during which the system would have a 25 min block interval... usable but severely degraded)
A total of 25 weeks = ~6 months to normal service.  A fork that was activating today would have to have had 10% of hashpower support it around June.  And their mining on it up until this point would be nonprofitable (because no markets would accept it until its mining was stabilized).
You could correct this in any fork by just changing the difficulty adjustment.  Make it dynamic until the rate has (somewhat) stabilized, then restore the 2016 block criteria.  IMO.  Then you eliminate the nonprofitable mining period, make adjustment instant, and shield yourself against the inevitable massive fluctuations in hashpower in the first few days of the fork.
@_date: 2016-11-14 19:15:23
Now you're linking science, great job!
Curious that the first paper you linked supports an on-chain increase :).  Would be interesting to update both of these for the far improved propagation introduced by CompactBlocks.


This conclusion is not supported by the data you linked.  Up to a 4MB increase would be safe without CB.  With CB, the number is probably closer to 16MB (as there is approximately a 4x bandwidth reduction on an 8-connection node).  
Unless by dangerous you refer to the risks of a fork, which I think we can both agree are substantially overblown.
@_date: 2016-12-13 21:42:41
Why don't you [read the article instead of asking questions answered therein](  I don't have time to clear up such basic misconceptions for you...
The key product is not insurance, it's confidence estimation.  Their confidence in their estimation is why they are able to provide insurance products.
Nobody is arguing doublespends on 0-conf are impossible.  Hell, they are not even impossible with 20 confirms!  The argument is that the risk can be quantified using appropriate strategies modelling their probability, allowing informed decisions on payment acceptance.  And empirically, when using such informed decision strategies, the fraud rate is quite low.
@_date: 2016-12-13 21:33:33
Again I will reiterate that **this may not hold true in a fee market**.
You don't know what kind of probabilistic doublespend detection Coinbase was using anyway.  Or what security parameters were set by reddit (after all, if you doublespend them they can take away your gold and ban you at no cost to themselves [incidentally what happened to Todd, lol], so I doubt they would increase security parameters above bare minimum defaults).
I highly doubt he managed to bypass anything like [this](
So tl;dr yes naively accepting 0-conf without learning about the risks and tuning your security parameters appropriately is dumb.  It is possible to safely accept 0-conf in the absence of fee market uncertainty (evidenced by hundreds of thousands of transactions doing exactly this).
Anyway, you asked for evidence on fraud rates on cash vs. 0-conf and I gave you numbers.  Are you satisfied with my numbers?  If so I see no reason to continue the conversation towards irrelevant threads.
@_date: 2016-11-14 17:59:05
So I asked for a link and you couldn't provide.  Yup, that's what I thought.
Trust me friend, I've read many more charts than you.  If you want to have a concrete discussion provide links.


So why waste my time posting here at all?
@_date: 2016-11-17 14:07:16
I'm sorry but "women should take the sex they are given because there is no such thing as consent or rape" is not eccentricity, it's a dangerous level of insanity.
@_date: 2016-12-13 22:14:39


Nope.  You have no more proof of Satoshi's intent than anyone.  It remains unknown until he signs a dated statement of intent.
@_date: 2016-12-13 22:12:06
Your argument is hand wavy and useless.  I've already linked empirical fraud rates for both cash and zero-conf in the absence of the fee market.  Unless you have new data the conversation is done; I don't operate on supposition, and the only arguments I will consider here are data-driven (as we already have data pointing to a clear conclusion).
The $75/mo price might be artificially inflated by fee market or block size related uncertainties.  The fact that such a product wasn't necessary in 2013 further substantiates this hypothesis.  But then, it's only a hypothesis.  Just like your hypothesis that it's expensive because *p* is fundamentally high for all 0-conf transactions.  Resolving these hypotheses without data is literally impossible.


So if they sold a computer to calculate these risks would you argue that they're an insurance company because "insurance companies also use a computer to calculate risk yadda yadda"?  This argument is a non sequitur.  They are clearly not an insurance company.  One glance at their website is enough to confirm this.
@_date: 2016-12-13 22:16:23
Why would I waste my time sending an e-mail to an address that's known to be both inactive and actively compromised?
And where did I mention 1MB anywhere in this thread?
@_date: 2016-12-13 22:09:46


I'm not implying jack shit.  Stop putting words in my mouth.  Straw manning at its finest (not really, I wouldn't give you that much credit).


It is a whitepaper.  Every technical whitepaper has a similar raison d'etre.  [Whitepaper](


@_date: 2016-12-13 22:26:48


BitPay still offers zero conf today.  I've used it as recently as this morning.


Sure, but not every company that offers insurance is an insurance company.  That much is clear I think?
@_date: 2016-11-17 15:35:03
Why are you on the fence?  BashCo asked for examples of censorship and removed my comment providing such.  Is there any ambiguity left here?
I used to see their perspective, but their behavior is both totalitarian and unfair as I'm seeing it **in this thread** (forget about the Medium post).
@_date: 2016-11-14 18:20:36
Wow, you cited yourself!  And it's not even a scientific work!  How insightful and surprising /s.
What do Schnorr, Tumblebit, and OTS have to do with the blocksize debate exactly?  What I'm looking for is science on increasing the data throughput of the network in bytes, which you have not provided.  You've instead linked to an orthogonal protocol, a constant factor signature optimization, and OTS, which unlike these two isn't even tangentially relevant.
You call that science?  Are you a fool or something?  [This]( is what science looks like and is the standard of evidence I am requesting of you.  I want something on scaling on-chain today, not an additional protocol with unclear security assumptions or a constant-factor tx size optimization.  Hell, you could have linked MimbleWimble and gotten a pass, but you didn't even go that far.
0/10 attempt.
@_date: 2016-12-13 23:48:57
You asked what their product and business model is, I answered in their own words.  Your shifting of the target ("their customer testimonials don't directly mention this") changes nothing w.r.t. that.
They are not an insurance company in their own words.  We agree on this now, yes?


Must be hard to use Bitcoin to actually do anything in the real world (beyond holding or speculation) without using BitPay?  They process ~90% of payments (in my experience)....


The limits are that the merchant assumes the risk, and needs to provide some sort of resolution in case of a doublespend.  For Steam, the resolution is if (doublespend) { remove game from user and ban user }.  As a merchant you are free to define your own policies.
If you're not willing to inform yourself we're done here.  It's not my job to spoonfeed you basic facts about the ecosystem (nor is it relevant at all to my original argument that p_zeroconf &lt; p_cash, which I've already empirically validated with data... you have provided no data contradicting mine, so case closed I think)...
@_date: 2016-12-14 11:54:42
You really believe you've challenged my belief system in any way?  LOL!
@_date: 2016-12-13 22:21:57


And you accuse me of being unwilling to engage in good faith dialogue?  lol.  ok. 
We're done here.
@_date: 2016-12-13 21:53:12
It's proof of the operative definition of cash in the whitepaper, aka the matter under discussion here.
@_date: 2016-12-14 13:38:37
*sigh*.  Looks like you will stoop to any level of verbal gymnastics to avoid looking at what his comment was actually saying.
Notice how despite my dozens of replies to a comment of his, and his replies elsewhere in the thread, maaku himself never replied to correct me.  That's because **I was right** about arguing that his definition was not consistent with the whitepaper's.
He clearly said:


But when Satoshi said "p2p electronic cash" in the whitepaper, **it had nothing to do with privacy preservation as a defining characteristic**.  Clear now?
@_date: 2016-11-16 20:23:31
True, ASICs don't contribute to pools, but they *do* contribute to farms by making early access to hardware / proximity to hardware manufacturing / electricity cost by far the dominant factors.  Hence, centralization in China. 
@_date: 2016-12-08 14:57:06
Bitcoin is a peer to peer cash system that solves the doublespend problem with no trusted third party.
@_date: 2016-12-13 22:30:10
Jesus Christ, I never said coffee in any of my posts.


No, I am not implying this.  I am simply stating that the definition of cash used in the whitepaper **had nothing to do with anonymity**, as maaku implied.
This is why **I want you to quote me**.  To make you argue against *things I actually said*.  Not *what you think I meant*  
But since I haven't said anything incorrect, you're unable to do this.
@_date: 2016-11-14 15:19:04
Instead of doing science both sides are playing politics, and it's fucking depressing.
Start releasing data, start doing experiments, and maybe we'll start having answers to some of these questions that go beyond sticking our heads in the sand and claiming that how we understand the system is the One True Way.
So many people are confident and even arrogant in their views that are backed by absolutely no evidence that the outsiders who compare this to a religious debate are actually surprisingly correct.
@_date: 2016-11-16 15:15:55
Whether it's activated or not, it will be because of "some centralized Chinese mining farms".  That's just the state of the network today, and proposing changes as soft forks is a tacit acceptance of that fact and endorsement of that government methodology.
@_date: 2016-12-14 03:29:22
The "brand" (that's an idiotic term for it) of money you use determines its distribution.  Just because the current "brand" works for you doesn't mean it's optimal, and it doesn't mean you should be a dickhead to people who are experimenting with alternative forms towards both the illumination of fundamental truths about money and a determination of the efficacy of possible alternatives.
Again, your indifference to the "brand" is only afforded by your privilege.  Your delusion is that you've earned your privilege.  The reality is that you're just on the right side of the current "brand"'s lottery.
@_date: 2016-12-13 21:09:49
You provided 0 evidence, which is my claim.  I am not claiming there are no plausible justifying hypotheses.  I am claiming there is no substantiating evidence.  Do you understand the difference? (apparently not...)
To be clear, I am not arguing that &gt;4MB blocks are safe.  I am arguing that there is no evidence that (witness data) + 4(non-witness data) better reflects network costs than (witness data) + (non-witness data) (or other alternatives where the (1,4) constant pair are varied).
@_date: 2016-11-14 15:05:23
Hearn was disillusioned and tired from constant attacks, so he went somewhere where he would get paid and maintain autonomy.
Is that so hard to believe after his nickname in the community was literally "Agent Hearn" for years?  After so many accused him of trying to destroy Bitcoin?  After he couldn't propose any ideas without being told he's a government saboteur?  
I don't know if you were around for those discussions, but they really brought out the ugly side of this community, and if I were him I would have raised the middle finger and started looking out for my own interests too.
Have some self reflection on your role in this.
Also, what's wrong with working for R3 exactly?
@_date: 2016-12-14 02:55:59
Cute.  You can't stand being wrong so you sure put a lot of effort into that one.  I think I proved you wrong what, like 6 times in this discussion?  You actually didn't make a single point I haven't refuted with evidence.  If you think you have feel free to quote them and I'll quote myself refuting it and provide at least one source, guaranteed.  
How about discussing facts rather than spewing more idiocy into the cesspool that is this subreddit?  Or are you incapable?  Perhaps you feel stooping to ad hominem is the only way to redeem your obvious lack of technical or economic prowess, and hell, your basic understanding of society today.


Money governs the lives of every single human being on this planet, from rich to poor.  You are who you are because of how much money you have.  You were only able to move to the US because you had money.  You are only able to continue existing there because you have money.  Your money decides where you travel, who you associate with to a large extent, where you can live, what school your children go to, whether you can put food on the table tomorrow, and whether you can pay for medical care when you get sick.  
Pretending to reject money in today's society is about as idiotic as it gets, the highest degree of denial possible about the base system the world operates on.  Perhaps the most ironic part of all is that this denial is only afforded you by your income; poor people have no ability to engage in such a denial of the importance of money in their livelihoods because whether or not they gain money determines whether they will be alive or not, often in the coming days.  There are billions who are sending their young kids to work for pennies on the dollar, so you can sit there wearing your Nike shoes, throwing shade on the Internet because it makes you feel intellectually superior despite your unfortunate ability to form a cohesive argument anyone would ever really take seriously.  Perhaps the second most ironic part of this denial is that actively denying facts about money shows its governance over every aspect of your thinking far more clearly than accepting its realities.  
Sit in your house, drive your car to your useless job that creates 0 real value for the world, go home to your heated house where you have a refrigerator full of food.  Don't worry about where on the streets you'll sleep, how you'll pay for your cancer drugs, how you'll put the first meal in three days in your mouth today, or what shelter in your area has beds.  Sit there and deny the influence of money and keep pretending the unimportance of the system that is actively oppressing millions while others like you (and me!) have the luxury of a disproportionate share of resources on a global scale.
I pity you dude.  


In case you have any desire left to get educated, yes this is true.  But the idea of doing transactions this way is that the only path to widespread Bitcoin adoption is making it the currency of the Internet (look in the sidebar of this sub).  To do that, we have to get any merchants we can.  Once merchants are accepting high volumes of Bitcoin payments (let's say 10%), if they have suppliers oversees who are willing to accept Bitcoin directly to avoid high fees or long delays on international wires, they will close the B2B loop.  In such a scenario there is also high market liquidity and thus high price stability, making holding Bitcoin for the short to medium term (all businesses really hold non-investment capital for anyway) not altogether risky.
@_date: 2016-11-16 19:52:07
Most pools *are* backed by huge farms, often a single farm.  There are also theories that the same farm sustains multiple pools to give the illusion of decentralization (after ghash.io fiasco)  nuff said.
@_date: 2016-12-13 21:08:02
Sorry, I should have been more clear.  **had** a relatively low p.  These days with the fee market + full blocks I am unsure.
How do I figure?  Cost of doublespending a 0-conf transaction: miner collusion.  Strategy of attack?  Mine conflicting transaction within next block.  Mitigation strategies?   and   As of 2013 (before full blocks), BitPay had accepted over 10k transactions without a single doublespend.  Do you really think the cash fraud rate is less than 1 in 20k?  [Recent studies]( peg it empirically at around 1-3 in 10k *by volume of value* (rate by transnational volume may be higher as fake cash tends to be spent quickly), or observably and empirically higher than the doublespend fraud rate.
To attack zero-conf: Attack when miners use consistent mempool policies and businesses have a well connected detection system as above requires collusion with miner of next block.  Price requires bribing a set of miners.  Probability of success is the probability that a miner in this set will mine the next block.  The attack has a high non-zero failure probability (assuming you can bribe &lt;&lt; 51%; if you can bribe more than 51% you can doublespend confirms anyway and the question becomes irrelevant).  
To attack cash: you can buy counterfeit bills on the darknet today for pennies on the dollar and have them shipped via USPS.  Probability of success is very high for good counterfeits, and level of effort required is far lower.  
@_date: 2016-11-14 17:29:30
It's very easy to understand why.  He runs a mining operation from a swamp in Florida off a DSL-era Internet connection, and so he feels personally threatened by any changes requiring a competent level of bandwidth to run a full node.
@_date: 2016-11-23 19:41:37


The 75% discount being arbitrarily chosen, justified only through hand waving with little careful analysis of its effects on the fee economy and price of average Bitcoin transactions.  It's entirely possible that SegWit transactions won't be "cheaper", their price will rise to the current transaction's feerate, and legacy transactions will be penalized.  The effects of this on the economy are unclear.
Or the fact that SegWit was used as a political card against increasing the MAX_BLOCK_SIZE constant, delaying capacity improvements that we need [as the network is hitting capacity]( and [experiencing skyrocketing fees]( at a critical point in the Bitcoin adoption curve.  Or the fact that this change could be used to argue against future blocksize increases based on hard forks.  Or the fact that this reduces old nodes to SPV nodes with no code ready for alternative/exit, and represents an effective blocksize increase decided only by miner vote, disenfranchising large segments of the economy.
Oh wait you're right there are no real concerns that aren't addressed by this article.  Everyone is arguing against SegWit because they don't understand it, and I'm just here "trolling and spreading FUD".  All the miners who are opposing this change have "no idea" how Bitcoin works and are simply ready to destroy it and take their millions of capital investments down with this ship.  &lt;/s&gt;
These straw man "ELI5" shitposts thinly masked as objective explanations are really getting old.
@_date: 2016-12-13 21:59:49
The confidence estimation algorithm.  God damn man, [read their website](  Look under "Features".  Do any of those look like features of an insurance product?
I'm seriously not answering any more dumb questions from you that can be answered by the front page of the website of the company you're asking about.
@_date: 2016-12-13 22:59:07
[Can you please do some basic research before commenting?](  Please?  Their plans are on their blog and they specifically talk about charging for API rate limits.


Why the hell do you need a BitPay employee for this?  Try it yourself! Or read the source I linked. I do hundreds of Bitcoin transactions a week, mostly through BitPay (I suspect you do not or you would be more informed on zero conf).  The vast majority of services are accepting zero conf today.


No.  Just a user who has used them thousands if not tens of thousands of times.  And someone who works on other problems in Bitcoin full time.
@_date: 2016-12-13 22:44:41


You are dead wrong.  They put it on hold when the fee market emerged, but it came back not long afterwards.  Your info on Steam is also out of date.  Steam accepts 0 conf today.  [More recent source](  Go try it yourself.


The insurance in this case is exactly an extended guarantee on their confirmation confidence algorithm, which is the product.  They make money by charging vendors who wish to accept 0-conf for this confidence data.
Insurance is only offered on microtransactions, but their target market includes *all transactions*.  Their primary product is not for sub-$9 transactions, this is an auxiliary service.
@_date: 2016-12-16 16:46:04
This is a slimy cop out.  Even after the correction, more readers are reading only the title and not the correction.  That is how front page visibility works.
You are spreading false and dangerous propaganda and you should be ashamed for your role in the continued divisiveness and strife in this community.  Unacceptable, and unfortunate.
Anyone with a modicum of integrity would have deleted the post (actually, anyone with a modicum of integrity would have spent 5 seconds doing research before throwing around false and baseless accusations, but let's take Hanlon here and say your failure to do that was incompetence rather than malice).
@_date: 2016-12-14 00:23:42
It's not about living for money or about letting money control you, it's about making a conscious choice that you will not support an oppressive and unaccountable financial system.  It's about being part of a change that will eventually end the nontransparency of the global financial system, bringing auditable and transparent financial inclusion to all.  That is the whole point of this experiment.  You don't need to let money own your life to accomplish these goals.  
In fact, using Bitcoin on a daily basis is easy if you know what you're doing (personally I map bitcoin: URLs to Electrum in the browser, I can pay BitPay/Cpinbase/other invoices in one click, which is actually *more* convenient [and more secure] than typing a CC into a new site).  And it ends up being cheaper; either through discounts for Bitcoin purchases or through the exclusion of recurring transactions, which cost me lots of money back when I used a CC more frequently.
In fact, I'd argue that if you forsake your morals for convenience ("muh cashback!"), you are letting money exert far more control over your life than if you choose to use a transactional system that's in line with your ideals and morals.
Calling people who actually use the system you're on here spending hours discussing slurs like "Che Guevara" provides some great insight into the attitude underlying your treatment of this system.  Unfortunately it's not a good faith attitude.
@_date: 2016-11-17 15:51:45
I suspect you will not receive a satisfactory response to why discussing PoW changes is OK while discussing MAX_BLOCK_SIZE changes is not.
@_date: 2016-12-13 21:47:47


So witness data requires 0 storage or processing?  WTF?
At this point I honestly have to assume you are joking or something...


I've written code that deserializes a raw transaction into constituent components from scratch (and resolves inputs to addresses from the UTXO set), so I understand very well what all of these things are (I highly doubt you've done any of this).  Which is why I'm demanding evidence rather than waving my hands.
@_date: 2016-11-14 14:58:08
*The resilience of the network has already been compromised by 1 MB blocks.*
That's a strong claim that requires equally strong data to justify.  Data that you don't have.  Be careful asserting unproven hypotheses authoritatively in public forums.
You think the network would be more resilient if we dropped to 100kB blocks tomorrow?  10kB?  1kB?  Where is the line and why?  Unless you have data, your personal opinion is just that.
@_date: 2016-11-16 16:17:15
Saying "as it was so it should be" is a cop out.  Just because we've always done things that way (primarily because it's easier and less messy) doesn't mean we should do things that way moving forward or that we were right to do things that way, and I've pretty clearly stated reasons why not.
My original statement holds true:


@_date: 2016-12-13 22:51:28
Did you read my comment?


They charge for high volume API usage.  Look at their clients list.  Do you think any of these fucking people are buying insurance on sub-$9 transactions?  Honestly?  Purse, Xapo, Coinbase, Deloitte, BitPesa, Paxful?  All clients of a sub-$9 tx insurance company?   Really?
Also you chose to ignore this part of my comment, reproduced below:


@_date: 2016-11-14 16:02:32
If he'd thrown his expertise behind an altcoin, the same people who are attacking him for joining R3 (aka you) would call him an "altcoin pumper" and use it as proof that he never had the best interests of Bitcoin at heart.  Don't think we don't see through this game.
R3 has the potential to bring a lot of value to the world, and it's paying his bills.  You can't judge him from working there when they're developing a product that has absolutely nothing to do with Bitcoin (they are not opposed to Bitcoin in any way).  How are they opposed to everything Bitcoin stands for?  If you believe Bitcoin is the superior technology and is truly antifragile against attacks by the establishment, let it win.
I will also say that Bitcoin goes far beyond libertarian principles and can include users and developers of all ideologies.  But let's assume for the sake of argument only that Hearn is libertarian; your argument is "no true Scotsman" in saying he's not a "real libertarian", while you're also attacking him for freely choosing to contribute his skills and effort in a nonviolent effort called R3.  How's them for libertarian principles?
@_date: 2016-12-13 20:38:57
Cute theory but ultimately unsubstantiated by fact.  Unlinkability / untraceability of histories / privacy preservation was not mentioned in the whitepaper (other than a brief note about the pseudonymous model).  The document focuses exclusively on defining Bitcoin as a payment system where Alice can send money to Bob with no trusted third party, using this as the operative definition of cash. 
From the abstract, first sentence of the paper:


Specifically framed as intended to mediate commerce between buyers and sellers:


And that's just from the first page.  Read the whole document for dozens more examples.  Or early forum posts for many thousands more.
@_date: 2016-12-13 21:54:47
Yes, they offer an insurance product.  **BUT THAT IS NOT THEIR PRIMARY SERVICE**.  The confidence algorithm is.
Insurance companies have insurance as their primary service.  They do not provide the public with actuarial data.  There is no API you can use to determine why your insurance is being priced in a certain manner.  There are no public actuarial formulas.  They do not intend for actuarial data to be used outside of internal adjustment.  
I'm not denying that the insurance product is insurance.  **I'm saying that the insurance is a byproduct of the confidence estimation service, rather than its primary goal**.
Is the distinction now clear?  So when you ask:


**NO**.  It is not simply an insurance service.  
@_date: 2016-12-14 11:55:13
Look up this very thread.


Up the thread:


Please read more carefully before replying in the future.
@_date: 2016-12-14 00:11:25
Fair enough.  If you do I'll be sure to say hi.  Not terribly excited about any of the work I've submitted this year, but I can't personally turn down a trip to Malta :).
@_date: 2016-11-23 15:41:14
Because the global financial industry is running on Fortran scripts written 30 years ago and manual back office efforts on Excel spreadsheets.  Anything that kicks their asses enough to innovate and adopt modern distributed technology is of value to them.  Most "private blockchains" aren't even actually blockchains; there's no blockchain in R3's Corda smart contract platform.  But it doesn't matter, it's a modern technology and banks need it, and if they want to use the "blockchain" buzzword to get to that conclusion then by all means.
It's easy to say "a private blockchain is a database", which is essentially true but not particularly meaningful.  The problems we're talking about aren't solved by a generic SQL or Mongo deployment though, the banks require a robust high assurance auditable DB to fit into their business model and regulatory constraints, and the "private blockchain" "BS" is finally giving it to em.
@_date: 2016-12-16 16:52:26
It's more divisive witchhunt propaganda BS, just like that thread that was slamming Ver for a quote attributed to him **that the OP literally made up**.
Can we stop with these garbage-tier personal attacks already and talk about Bitcoin?
@_date: 2016-12-14 12:51:08
*sigh* your mental gymnastics to continue justification of something obviously false do not cease to astound.  Please reread the post if it remains unclear to you.


By this analogy, he was saying that all cash is untraceable, not everything untraceable is cash.  Is this how you interpreted the post?  If so my rebuttal was appropriate.
You also understand that you can have an untraceable transaction medium that is centrally controlled (eg - a credit card based on ZK-SNARKs)?  And that is very much not cash.
Please stop posting about cars and wheels and silly junk like that and *address my points* instead.
@_date: 2016-12-08 02:16:17
[Totally called it over six months ago](


Circle CEO:


No, it's not regulation that had them pivot out.  It's obvious to anyone with half a brain why this is happening, and have no fear, Coinbase is in the process of doing a similar pivot.  Sitting on here and flaming Armstrong and Coinbase all day while they're burning VC fighting for Bitcoin users in court will not reverse this trend.
At the end of the day, if you fail to cater to business needs you will lose business.  Accept &amp; move on.
@_date: 2016-11-22 20:46:11
Well the question was


and that seems to be the only way I can think of without hitting the chain.  Assuming you don't trust any of the participants.
@_date: 2016-11-24 19:58:58
Any evidence is better than the 0 evidence that he has provided.  Wouldn't you agree?


This is particularly ironic because human beings needed *a lot* of evidence before they believed the world was round.  Someone as unskeptical as you are and as willing to take claims on faith surely would have believed that it was flat for much of history.
The downvotes are welcomed BTW.  Show me how much this sub really advocates asking tough questions and engaging exclusively in fact-based debate :).
@_date: 2016-11-25 14:25:20
Point to a single argument that actually validates it provided in this thread.  You cannot.  I gave an example of *what an argument could look like*, but 0 argument was actually provided and I would have accpeted **anything evidence based**.
Blindly accepting the status quo is exactly what I refuse to do.  Show me the facts.  I have looked myself, and found none, nor have there been any in this subreddit at any point.
@_date: 2016-12-13 20:43:08
All payments are probabilistic, there is no such thing in this world as 100% fraud proofing.  Not with cash, check, card, or even blood.  Any payment has a failure probability *p*.  If p * value &lt;&lt; profit it makes sense to take the payment.
0 conf has a relatively low *p* compared to cash, check, credit, etc.  Its *p* has however increased with uncertainty around the fee market.
@_date: 2016-12-14 13:20:59


So we are in perfect agreement, great!!  Thus, traceability has **absolutely nothing to do with whether something is cash**, which is exactly what I was arguing (and not what maaku was saying).
As a reminder, maaku said:


@_date: 2016-12-03 03:12:50


Obviously not.  If only 10 nodes have full archival witness data, that is a form of centralization, as removing these nodes would make it impossible to fully validate the chain.
It's like SPV in that it's fine for some percentage of users to be using it, but if *everyone* uses it the network is severely degraded.
@_date: 2016-12-13 22:41:49
Are you going to Malta?
@_date: 2016-12-03 03:23:51
This doesn't solve the problem.  
a) a rational user is incentivized to choose 0 (this is classic tragedy of the commons).  b) your "bus factor" for chain history is then the number of nodes storing whichever block is the least common in the network.  If there are 100 nodes storing every block but  which only has 1 node storing it, take out that node and you lose the ability to validate any block after 3000.  
This is amplified further by the fact that there's no way of knowing how many peers are storing a given block (in the current network, you can approximate this by looking at the full node count).
The analysis is far more complex than implied.
@_date: 2016-12-14 03:12:10


Sure, there are many ways to accomplish this that have nothing to do with either SegWit or this discussion.


I said "the only reason nobody has written this code is because it's useless, undesirable, and uninteresting", and you're telling me to spend my time creating a patch for it?  What?  Perhaps reread the comment if you are confused?  I have more coding work than I can keep up with, you think I'm going to turn down thousands of dollars in work on Bitcoin that would be useful to code and test a stupid patch like that that has no chance of being merged?  LOL.


It's not my job to do math and get the data that supports your claims, it's yours.  If you want to have any chance at a serious contribution to the discussion.
I'm just saying nobody has done this yet.  It doesn't mean no data exists, but you can never pretend the data is obvious.  Because it's not.


Again **you can already do pruning**.  Some nodes will always need to store witness data, or the network becomes impossible to sync without central checkpointing + SPV verification.  For these nodes, the cost scales linearly.  Let's call this linear function *x*.   If *p* percentage of all network nodes are storing witness data, the network-wide scaling of witness data on storage is *px*, where *p* is a constant.  AKA linear in *x* (witness data size).  Even the amortized "per node average" cost is linear.  Sure you can get out of this linear cost by opting out, but you create a classic tragedy of commons scenario that way where too few people end up storing full history.  Even if all but one node drops out of the network, the cost is still amortized linear.
I'm going to guess you didn't study computer science?
@_date: 2016-11-22 17:21:39
LOL!  I know people who work on blockchains at Goldman and you are absolutely delusional if you believe something like this.  A few points:
- They already understand Lightning.  They've understood it since the original whitepaper dropped.  R3 even has published [internal reports]( talking about scaling Ethereum over Raiden.  The arrogance of believing that a bank has "just heard" about Lightning is staggering.  Its these guys' full time job to stay ahead of these technologies.  Trust me, Lightning is not news to them, and they understand both the benefits and the pitfalls better than I'm sure you'd believe.
- They are not buying Bitcoin on an institutional level.  We're talking about a highly regulated and risk averse industry that doesn't believe that Bitcoin is a hedge asset.  They're just not buying institutionally (some individuals in the banks certainly are though).
- Their vision is not that they will be using the Bitcoin blockchain.  They are averse to this for so many reasons other than scalability.  Confidentiality is the big killer here; banks don't want their data touching public *anything*, even if it's encrypted.  You say "public" and you've lost anyone who works at one of these institutions.
Want to know the real reason they dropped R3?  So do I, and I don't, but my speculation is just that they wanted to spend the money elsewhere and they weren't getting the commensurate value out of their $250k membership (perhaps they thought they could do the same R&amp;D with a single engineer in house, which is about what $250k covers).  Or perhaps R3 asked them to up the ante and conversations broke down from there.  Who knows.  I promise it wasn't because "they were explained Lightning" though.
@_date: 2016-12-13 22:01:20


The whitepaper is proof of the original design goals of the currency.  That is literally its raison d'etre.  It's not proof of how Bitcoin *should* evolve, but it is proof of **how cash was defined in the context of Bitcoin**.
The original claim was that the definition of "cash" in these systems was X.  I have just proved it to be Y, Y != X.  This doesn't say anything about how the future *should* play out, nor have I ever claimed that it does.
@_date: 2016-11-14 14:56:00
You don't have any data on how this trend will go.  It's possible more economic activity --&gt; more nodes, overcoming increased resource consumption requirements as more stakeholders see value in running a full node (businesses, payment processors, miners, etc.). 
It's also possible that more economic activity --&gt; fewer nodes as the cost becomes high and the tragedy of the commons sets in, with all of these users looking to freeload off the existing node network and no economic incentive to run a node.
There is absolutely no data either way.  Any assertion of either position is merely an untested hypothesis.
@_date: 2016-11-16 18:09:49
Yes it was.  Remember the GHash incident?  We've had pools approach 51% before.  Mining has been centralized since the advent of cloudhashing and ASICs.
@_date: 2016-12-13 23:52:05
No problem, glad someone appreciated the wasted hours :) (after all, I have Bitcoin related work that I should be doing that this is cutting into).
@_date: 2016-11-24 19:03:13
Yes, you can wave your hands around but it's not going to impress me.
You still have provided 0 evidence that the new "weight" calculation more accurately captures system costs than the old size-based calculation.
Evidence I will accept must include:
- A rigorous analysis of what "real system costs" are, and a quantification of the costs.  Storage cost per MB, bandwidth cost with regards to required transfer, latency, and throughput requirements, CPU cost, etc etc etc.
- A proof that the new formula objectively captures the above better than the old formula.  Note that saying the new formula includes X and the old formula does not is not sufficient; you must quantify how accurately each formula captures the above defined "real system costs".  It is possible that though the new formula includes more potential costs, it also less accurately reflects the *cost of real resources* required (eg - how much does maintaining a transaction in the UTXO set cost, in USD)?
- A proof that the new formula objectively captures the above better than **any other potential new formula**.  eg - a comparison to a 0% discount formula, a 100% discount formula, a 200% discount formula, ... and quantifiable proof of accurate capture.
All three parts are essential to the argument that the new calculation has any legitimacy.  Until then, stop asserting claims like "the new formula captures *true costs* accurately" on reddit, because they are simply unsubstantiated claims (and useless as such).
@_date: 2016-11-14 16:55:29
Simple Routing (aka every node tries to maintain a global network map through gossip) is the only proposed alternative for route discovery thusfar.


In my personal opinion (and please take this critically and with a grain of salt) there are three difficult problems here:
1. Dealing with channel churn.  Channel fund availability and balances may change frequently, whereas Internet link capacities are relatively constant and stability is relatively high.  This means that naive protocols may find stale routes or routes that are unable to provide the required capacity.  This is specifically a problem in the case of a byzantine channel which advertises false availability (and then when you get to it in the route, disappears), making you need to perhaps renegotiate a route mid-transfer.  This could potentially be anywhere from a mild annoyance to a dealbreaker.  Neither Flare nor Eclair deal with this problem at all.  The problem can be approximated by a high load Internet routing scheme in which links have both high churn and unknown dynamic capacities.
2. Privacy.  How to negotiate routes without linking payment info, specifically linkable to real-world data like IP, or increasing linkability between payments/addresses.  This one speaks for itself, there are some proposed onion schemes to do it after a route has been discovered but no complete implementations thusfar that I am aware of.  Internet traffic routing leaks like a sieve.
3. Fee optimality.  Internet routing approximates for "best link" (balance of latency and throughput), but lowest fees are critical here.  Best effort routing falls a bit short.
Another difference from Internet routing is that there is no assigned names authority (like IANA) to manage topology.  You can to an extent approximate this by sourcing this info from channel open/close txs on the blockchain, but unlike with a central authority there is no clear recourse for mitigating malicious behavior.
Any solution to the above will naturally require scalability to millions of users in a robust and decentralized manner, with Sybil resistance and robustness against Byzantine actors built in, to fulfill the promises of the technology. 
@_date: 2016-12-13 20:49:53
[I wrote a better]( (in my biased opinion) post about the downsides of SegWit.  Read my comments down the thread as well, which were unfortunately buried by groupthink-downvotes (but remain correct).
The primary argument against is, in my opinion, the discount being chosen arbitrarily, with 0 rigorous economic analysis or data of any kind backing the constant parameterization there.


You can't roll back a soft fork without a hard fork ever BTW.  Rolling back a soft fork *is inherently* a hard fork (rules made more permissive).  This is not unique to SegWit.


Your searching leaves a lot to be desired then, this is far from the primary argument espoused by reasonable people (basically only ytdm in r/btc posts this kind of stuff).
@_date: 2016-12-14 03:48:16
maaku claimed that untraceability was the key definition of cash the whitepaper used.  The whitepaper mentions this or any related concept 0 times.  
I claim cash is used, as you do, only to describe a transactional medium.  I provided two example quotes from the abstract and first page of the paper.
You insist on discussing coffee and LN and I never posted opinions or comments on any of these things.  I can't help but think you're confused.  And apparently I'm the one reading too much into things?
@_date: 2016-12-03 03:29:17


It's a vector for centralization.  Its analysis should concern you, and if decentralization of chain storage doesn't matter to you then I'm confused about how to continue this conversation.


So I can easily stop people from storing block 3000 by Sybiling a claim that "I'm storing 1000-50000" to every node, and then DoSing only downloads of 3000 (while legitimately serving the other blocks)?  That doesn't seem like a sound protocol to me.
Perhaps a proof of storage along with a PoW required for miners that made them prove full chain history storage every block?  That would perhaps approach the required guarantees more closely than your solution.
@_date: 2016-12-14 03:44:00


I never said you should use Bitcoin.  I said that if you don't want to use it, take your useless idiocy, your misinformed opinions unsubstantiated in fact, and your lack of system knowledge and fuck off of this subreddit already.


You said the current brand of the US's money is working well for you.  You said you moved to the US from another country.  Both of these things make you *insanely* privileged on a global scale.  Top .1%.
Why do I think that you think you deserve it?  Because you compared money to toilet paper.  Something that would be very offensive to someone who's endured any real financial hardship, or even has empathy for those that have.
@_date: 2016-12-13 21:10:19
[Read the linked comment, I already did.](
@_date: 2016-12-14 03:34:01
I have no idea why you keep bringing up the lightning network.  It really has nothing to do with anything we're talking about, and I've stated no opinion on it.
The original comment I replied to


I think you will find on reading the whitepaper, where it repeatedly frames cash as a medium for the facilitation of commerce and value exchange between parties and mentions nothing about coin tracing, that this definition of cash is not exactly what the cash in the whitepaper title refers to.
That is all I am saying.  Nothing about SPV.  Or second layer solutions.
@_date: 2016-11-25 15:06:06


Ad nauseam, you assert a claim, and back up with 0 evidence.  If you think that's convincing to anyone other than the simplest minded of users, you are incorrect. 
@_date: 2016-12-14 03:03:44


I literally never said it was.  I only said it contained a very clear notion of its operating definition of "cash" which contradicted the definition maaku presented.  This was an argument over the whitepaper title, so while the full rationale is not there, the rationale for the title is.
The rest of your comment seems irrelevant to the definition of "cash", which is what's under discussion in this thread.  I never posted about SPV, off-chain tech, or any of that.
@_date: 2016-12-13 22:24:57
No sir.  The OP is a shitpost.  There is nothing to refute because there are no hypotheses, data, or content.  I wouldn't waste my time engaging such garbage.  
I am refuting [maaku's definition of cash in the whitepaper title](
@_date: 2016-11-14 17:58:46
The science which you haven't linked.  Where is it?
@_date: 2016-12-13 22:15:27


Dumbasses like you are putting words in my mouth and extrapolating arguments I never made, then arguing against these as if this somehow makes me wrong.  It is the definition of straw manning.
In the future, if you're arguing against a claim I made, quote the claim and argue against it directly.
@_date: 2016-12-13 22:38:32


In order to "shoot down" anything, you must first quote it.  Can you quote what I said that you think you've "shot down"?  Quote what maaku said that contradicts my interpretation (also quoted)?
No?  So STFU and GTFO w the low value posts.
@_date: 2016-11-17 14:01:53
I hope I don't get banned for this, because I really do enjoy contributing here, but the people claiming censorship claim that *the sidebar guidelines are the censorship*.
Particularly this:


where the definition of "promotion" and "overwhelming consensus" (of whom? how to reach without discussion?) are unclear, highly subjective, and used by the mods to remove any posts advocating for clients which are not Core (while allowing posts about these clients that are negative, since this is not "promotion", creating a highly biased discussion).
For example, I have no doubt that half the comments in the linked AMA would be removed from this subreddit.  Would you agree?  
*braces for downvotes* (btw, to be clear: I am not trolling.  This is my only reddit account.  This is an honest devil's advocate viewpoint.  I do not represent a brigade of any type, my opinions are my own.)
@_date: 2016-12-13 21:36:16
Downvoted for the shitposting.
@_date: 2016-12-08 14:50:36
Similar to those who I was replying to six months ago, you stick your head in the sand with regards to the real problem.  I'll say it again:


The developers need to solve **real problems** in the ecosystem that **real businesses** and **real consumers** with real money on the line are facing.  Small constant factor optimizations simply aren't going to cut it in this climate.
Had Core said "OK Circle, Coinbase.  We hear your complaints about backlogs and potentially high fees.  Here's what we're doing: we're going to raise the blocksize limit to 20M on the testnet and see how the orphan rate / mining dynamics plays out, please any interested contributors point your ASICs to *x* or start a pool on *y*, let's gather as much data as possible and write up a report with actionable suggestions afterwards", not only would we not be having this conversation but Bitcoin would be in a far better position overall.  
Circle is simply used to having things work this way, because *this is how things work in engineering* outside this little Bitcoin bubble.  You identify a problem, you identify the problem's boundaries with your current code (block propagation, SIGOPS), you identify and evaluate (with data on the test infrastructure you used before) a solution to this problem, you write up the data you gather, and you form an actionable plan for change.  You *don't* engage in petty infighting and do shit like [this]( or [this](  You expect anyone to build a billion dollar business on that type of climate/attitude?
At the end of the day, if you fail to cater to business needs you will lose business. Accept &amp; move on.  Especially if you want to direct effort to be wasted on bad solutions to problems that nobody has (RBF is a perfect example of this; not only is CPFP superior UX-wise but RBF is actually useless from a business or user perspective if you have CPFP).
Instead when a developer wants to do something like this (as Gavin started to work towards with his simulations) they get called a traitor and ostracized for "threatening the decentralization of the system" (a property impossible to measure) based on nothing more than neckbeareded handwaving (I promise you these people are not doing data driven engineering).
Post another denial about how Circle contributed nothing if you wish, but the truth is that you reap what you sow, and continued denials only mean that Circle is not the last pivot on the horizon. 
[BTW, if you'd managed to actually *read the original thread* where I posted, you'd see I already addressed the style of denial you list above.  Here it is reproduced, though you really should read the thread:


@_date: 2016-11-16 18:11:23
They are not the only huge farms.  F2Pool, BW.com, HaoBTC, BitFury, BTCC, etcetcetcetc. 
The only large (&gt;5%) pool I've seen that doesn't actually look like it's backed by a huge farm is Slush.
@_date: 2017-04-28 16:49:16
Yes, I'm sure.  Read both codebases yourself.  Then code the same change on each.  Then come back and tell me I'm right :).
@_date: 2017-04-27 23:13:07
Meh.  It's true, I've read the full source of both Parity and Core and I encourage all others to do the same.  Parity is light-years ahead of Core.  Prepare for a new dominant node implementation.
They're also really good at benchmarks.  [I can't wait until their comparisons to Core come out]( (scroll to "Benchmarks").  My estimate is 2x faster at minimum.
This is definitely the biggest bombshell this week, and will be transformative in Bitcoin client development.  If they start adding features like Warp Sync that sync the full blockchain in minutes, well...
@_date: 2017-04-03 13:06:00
Hey, just wanted to let you know in rereading my posts that I apologize for being a massive dick to you.  I do appreciate your contributions to the space and efforts to revive Bitcoin Magazine.  On the other hand, I also believe that UASF is a dangerous proposal that has the ability to destroy Bitcoin, and I think this type of attitude is highly problematic for the future of Bitcoin:


Hopefully you reconsider and arrive at an attitude other than "my way or burned to the ground", if anything I think that this approach has a better chance of achieving that than just trolling you.
Good luck w your projects (really).
@_date: 2017-04-30 23:55:38
It's always been able to do so.  Go to restore wallet -&gt; from seed -&gt; advanced and check the BIP39 and additional word box.  The password is the additional word it'll prompt you for.
It used to be more clearly a password in the UI, but I don't know why they've changed it this way (perhaps because it's store on disk by default?).
Either way seeds can, by their very nature, be password protected.
@_date: 2017-04-14 17:32:51
Wow, you're so edgy.  I'm sure that showed him!
@_date: 2017-04-01 18:21:31
Wow, I cringed reading that.  This is what you think is appropriate public behavior for someone who wants to be part of a $20B project?  Alright then.
@_date: 2017-04-03 01:47:35
"Rebuilt" BitcoinMagazine?  Must have missed that, it's a pathetic rag.  The only worthwhile articles I've ever read there were written by Vitalik, too bad he moved onto better things.
You're just another early adopter who got lucky and now thinks his farts smell like roses.  No talent of which to speak.  Sorry if I offended telling it like it is?
At any rate, looking forward to the fork, so you can finally leave the community as you promise and I no longer have to see your garbage on my Twitter feed.
Good luck with 21!
@_date: 2017-04-02 05:25:06
Given that your contributions appear to primarily center around running VC-backed companies into the ground, the only thing I can really say to that is "good riddance".
@_date: 2017-04-30 22:23:49
You serious?  Spoken as someone who has no idea how seeds work in Bitcoin.  Read [BIP39]( some time.  Or use Electrum, the software in question.


@_date: 2017-04-03 12:26:36


LOL!!!! Plenty of the developers who work on Bitcoin are paid to do so.  As a full time position.
@_date: 2016-09-09 02:25:26
Your comment.  Read both my and your comments carefully and in context, including ancestors.
@_date: 2016-09-08 19:28:04
No no no no, just no!  This is a broken and flawed argument, and reveals a deep ignorance of the economics behind the fee market.
Imagine a world where 1 billion transactions per block are going to be demanded at $.02, and 0 transactions per block will be demanded at $.10.  With a blocksize cap that can fit 10 transactions per block, you may just see average fees hovering around $.02, because *nobody is willing to pay more*.  Despite these average fees not increasing, **there is unserved demand** (a billion minus ten transactions per block's worth)! The users whose demand is not getting met may prefer to leave or find alternatives than to pay higher fees.
That means you absolutely cannot look at average fees and extrapolate the demand curve for transactions, and claim that demand is getting met because fees are not growing.  It might just mean you have a somewhat elastic good with a quantity ceiling.
Not considering elasticity in this analysis and using it to draw conclusions is just wrong, full stop.  You need to analyze the demand curve separately, and this is far more difficult than just looking at average fees in a system this distributed.  Even just looking at the mempool as a metric for unserved demand is broken because it does not account for users who have left.  The only somewhat decent metric is the percentage of Bitcoin's total crypto market cap, which shows its dominance over competition and will fall with unmet demand.  Even this isn't perfect if people prefer to exit to fiat systems or non-crypto, or if another crypto increases in marketcap despite not meeting any unmet BTC demand.
Stop spreading misinformation.
@_date: 2016-09-09 02:24:13
Malleability fix is required for Lightning, off which companies that run hubs will profit (Lightning incentivizes short routing paths by charging per hop, which incentivizes the creation of rent-taking hubs).  Malleability fix can take two forms: SegWit, or a hard fork.  Some non-mining companies benefit from arguing against a hard fork by pushing people onto Layer 2 solutions off which they can take rent.  Only miners can take rent on Layer 1, so non-mining companies will never be incentivized to support Layer 1 scaling.
So, hard fork is out.  SegWit is in.  No SegWit, no Lightning.
@_date: 2017-09-26 22:15:08
Do the math.  Bitcoin difficulty can adjust by at most 4x.  At 5% you've got to go to 20, then 80, then 100% of mining power, so in the best case it's 3 difficulty adjustments.  The first one will take 2 weeks x 20 (you only have 5% of expected power), the second 2 weeks x 5, and the third 2 weeks x 1.25.  About a year to normal block time.
The good news is, if 95% of miners are doing and not switching back and forth it it's not an attack, it's a relatively safe fork.  If 95% of miners decide to launch an attack you are absolutely fucked, they could essentially do anything they wanted with the current Bitcoin network with soft forks to arbitrarily change the rules and reorg power to doublespend if they want to.
@_date: 2016-10-24 12:37:29
You are mistaken; 


This doesn't actually make anything "worse".  A majority of hashpower acting maliciously at any given time is enough to remove any security guarantees the network has.  This whole experiment only works under the "honest hashpower majority" assumption (and because of selfish mining, by "majority" we mean something like 70%+ hashpower must be honest).
So yes, a majority of hashpower can attack BU nodes.  But they can also attack any Bitcoin implementation ever, so this doesn't actually make anything worse in any meaningful sense.
Note that this doesn't exclude the fact that a new attack class is opened up that should be studied, just that upon study the class is likely not real-world significant given the attack prerequisites are already enough to exert total network control.
The capital investment incentivization argument that's used to prevent 51% attacks is also identical to the incentivization argument that would prevent such behavior in theory.
@_date: 2016-10-12 23:32:08
Repeat after me:
**There is no such thing as apolitical money.**
[Politics]( 


Any decision related to changing the characteristics of money (value transfer between individuals) is **inherently political**.  There is no such thing as a purely technical change; any technical change impacts how the money is used, thus governing relationships between individuals, making it actually a *political* change.
Look at the politics of a purely technical matter like the blocksize constant for proof of this.  You can make technical arguments until your face turns blue, but at the end of the day ignoring the politics is ignoring the reality.
All technical decisions have some impact on all users of the money, and are therefore political decisions.
Your insistence on having purely technical solutions to political problems is what's known in philosophy as [technological determinism]( and has been known for a very long time to be untenably reductionist and downright inapplicable to actual human interaction.
@_date: 2016-10-24 14:18:48
Again, partially correct but primarily incorrect.
Majority of miners already can change protocol rules; this is what's known as a "soft fork".
And before you counter with "they can only make rules more restrictive, not more permissive", this is actually incorrect.  In the event of an "evil soft fork" as described by luke-jr, they can make rules more permissive by forcing nodes that do not conform to their more permissive rules to upgrade.  This is really an arbitrary and arcane technical distinction with little real-world significance though; virtually any technical change can be expressed as either a soft or hard fork, and both are *very* powerful mechanisms.  
In terms of real world impact, majority miners already have large degrees of control over protocol rules (hence the repeated miner lobbying conferences/efforts, etc.).
I'll take it one step further and say that this doesn't matter at all; if a miner group can double spend, they already have enough power to attack anyone in Bitcoin or destroy the entire network at will (the whole point of the system after all is making double spends impossible).  So adding control over a very specific protocol rule does not at all increase their power, which is already maximal.
Not to mention that we're glossing over the fact that in the Unlimited model, full nodes can still override these protocol changes by setting their configuration to not accept these blocks regardless of what chain depth they reach or how much work they accumulate.
So, to summarize:


They can already do this through a soft fork (see: SegWit for one example, not exhaustive).
You cannot "shift" power to a majority of miners as a colluding miner majority inherently has the maximum possible power over the system (through a break in the system's fundamental trust assumption).
@_date: 2016-10-07 00:18:04
Have you ever actually read the Solidity documentation?  [Look into version pragmas](  Each contract targets a Solidity *version*, and all compilers that support that version will output bytecode with identical semantics for that contract.
If you want to update the Solidity version your contract is written in, you read the changelog between the old and new versions and make sure no breaking updates affect the semantics of your contract.  There has never been a Solidity update that has broken old contracts; they only add new features, not remove or change the semantics of old constructs.  Even the famous "full gas call transfer" that called the DAO didn't result in a semantics change for the call operation in new versions of Solidity, even though such a change would have removed a wide class of antipatterns.
This is like saying "gcc experiences upgrades, and C11 != C89 != C99, so C programs are write-once use-once".  Just totally ignorant and false.
There are real arguments against Solidity and **this is not one of them**.
@_date: 2016-10-24 15:51:07


That argument is absurd.  Let's break it down into two digestible pieces:


Correct, unless they are running the new code, in which case they have agreed.  And if they are running the old code and have not agreed, they will continue on the old chain, which is also what they agreed to when they started running the software.  So this part actually kind of checks out; in a way, the holders have agreed *which fork* to stay on.  They do not need to agree on whether or not there is a fork because this is an objective network reality that doesn't require input or agreement of any kind.


Ridiculous.  I just made the argument that any change, including but not limited to: censorship of accounts, modification of consensus rules, removal of the 21M coin limit, and more can be made via soft forks.  
If you say users "inherently accept" any soft fork, would you agree that users of the system today "inherently accept" a change like the removal of the 21M coin limit (given the ~30% of miner support required to activate this change as a soft fork)?  Of course not.
The articles you link are similarly utterly absurd.  Voskuil is saying soft fork rules aren't consensus rules?  They sure are to upgraded clients, who will orphan blocks in violation.  It's just clearly and obviously technically incorrect unless you redefine "consensus rule" to mean something very specific and not entirely useful in discussion.
@_date: 2016-10-28 19:10:26


This is obscenely false.  Do you have any evidence to back this up whatsoever?
@_date: 2017-05-16 19:23:52
I can't even tell if you're serious right now.
Of course it doesn't, or it would have activated long ago.  Miners are not on board.  Not even on slush, not on several large pools, etc.  Users are not on board; [all coin votes so far have been majority against activation](  And clearly a large portion of the community (reddit, Twitter, bct, etc.) is opposed.  As are several development teams (bcoin, Parity, BU, Classic, etc.).   [And under 50% of companies are in support]( 
If that's "overwhelming" consensus, well you must just mean "overwhelming consensus of people I agree with."
@_date: 2016-10-24 18:26:44


Thanks, but I'm quite capable of managing my own language as I'm sure you've gathered from this exchange.  My goal is not to convince people who are not open to reason, I could not care less if you insist on an incorrect position.
The argument you linked **is absurd**.  Whether or not you agree does not make it any less so to anyone who has studied consensus literature.
Do you agree that in a regular (non-evil) soft fork, the added rules are consensus rules to upgraded nodes?  If not, why not?


To clarify: I am not talking about an evil soft fork removing the 21M coins limit.  I am talking about a **standard soft fork** doing so.  The rest of your analysis is predicated on the assumption that I am discussing an evil soft fork; I am not, and it would be ridiculous to assume that the average holder in Bitcoin today has "inherently accepted" the removal of such a limit through a soft fork enforceable with as little as 30% hashpower.
This is similar to claiming that someone investing in the DAO has "inherently accepted" the inevitability of compromise to their funds; while this may always technically be a possibility, what is possible and what people expect and accept are rarely so cleanly aligned that such a reductionist analysis of their investment yields any useful data.


I've spent 30 years studying consensus, and I'm wary of redefinitions when there's a volume of literature already available on the matter that has established definitions that are crystal clear.  Generally when people are pushing redefinition, they are sweeping assumptions into their definition that they then use to draw vastly different conclusions than one would with the original definitions.  These conclusions become dangerous when they are then peddled to non-experts who are using the old definitions as gospel.  Consistency in language is important, and it's fine to add new definitions when you need them, but taking terms that people have been writing about since the 70s and making them mean something completely different to support your conclusions is disingenuous, at best.
Saying "soft forks don't change consensus rules" is just wrong under any reasonable reading.  That is so obvious the proof would contain one line and the words "by definition".  
Sure, you can change the definition to invalidate the proof, but don't expect people to see your argument as legitimate after such weaselwork.
@_date: 2017-05-15 17:01:26
Now you're just low level trolling.  The mining reward in USD has been increasing steadily since the advent of the system.  And the aforementioned stability problems with no block reward, while not relevant yet, have other solutions besides the fee market (pay it forward fees being such an example).
@_date: 2017-05-11 15:09:02






This could take days or weeks and needs to be manually verified though.
There is really no difference in what an operator of an old node needs to do in a hard fork vs. a UASF other than a recompilation.  In either case, they can't use / shouldn't trust confirms until the fork is resolved.
There's really absolutely no meaningful difference in terms of required precautions.
Soft forks are only safe when activated with miner majority.  The use of the word "soft" to a fork with miner minority to imply that it is safe is highly misleading and false.
@_date: 2016-05-26 14:13:25
I know a few people at Goldman Sachs and nobody there really takes Bitcoin seriously for public transactions, despite what a few stray documents might say.  The attitude is that it doesn't scale and will be regulated out of existence once the government starts enforcing compliance.
That's not to say that they aren't ready to buy it if it does end up scaling and gaining mainstream popularity.  The sharks won't go home, they'll adapt.
@_date: 2016-05-12 19:27:31


I mean other than Samson Mow from BTCC and a bunch of reddit trolls with viewpoints (and probably personalities) spanning the spectrum I haven't seen anything.  Since this thread seems implicitly directed at Brian Armstrong, can you link me to a non-constructive contribution he's made?
@_date: 2016-05-26 16:03:53
I never implied there was market support of a single chain!  Of course market can support multiple chains if utility is there, it is incentivized to support fewer over many through mining economies of scale and network effect (Metcalfe's law), but not required to do so by any means.  Please reread carefully:


I'm talking about individual market actors who move from Chain A to Chain B.  These actors are **discarding history**.
Is that clear now?


Why?  As long as they're in the shared prefix of the chain, their money will be available on both chains (unless they ship out goods / fiat during a doublespend of the conflicting prefixes).
The shared prefix will always be large, as the market is incentivized to preserve the history of its own transactions.  The risk of a doublespend therefore exists only during the upgrade period, during which market actors will be aware of the possibility (since they must be actively upgrading from Chain A to Chain B).
@_date: 2017-05-16 17:34:12
@_date: 2016-05-12 20:36:46
Am not the one who has devolved to ad hominems and groupthink us vs. them mentality.  And don't worry, I will enjoy my day.
@_date: 2016-05-19 07:39:15
Dead wrong again.  I'm referring to the creation of multiple incompatible chains through the modification of consensus code as the mechanism for creating multiple blockchains.  It's in the fucking paper I linked, Jesus.
There is no reason to have the consensus code be in any way compatible if you don't want to do pegs.
@_date: 2016-05-12 19:47:59
Look at the other replies to the parent of my first comment.
If not Armstrong &amp; ilk, what users is this post directed at?  
@_date: 2016-05-26 15:20:52
If you have market support of a chain, then you have a fork 1k blocks back from the head, and any market support moves from the former to the latter, that market support is "discarding" their history for a new one that starts 1k blocks back.  Any miners that did the same would inherently also be discarding history.
1000 blocks is almost a week of history.  This is not a trivial rearrangement we're discussing.
@_date: 2016-05-13 14:13:13
That attitude will drive users towards competitors that actually serve their needs.  And because Bitcoin's utility is proportional to users squares, this is highly damaging to Bitcoin.
On the other hand, I guess I shouldn't fight it too hard.  My altcoin investments have both made me wealthier than expected this year and paid my mortgage.  But I have my career and the last four years of my life's work invested in this currency, so I'll keep fighting for it and I won't take the door thank you very much.
@_date: 2017-05-12 04:51:29
*sigh*.  [Look at the coinbase of that block](  It was mined by Ant USA4.  Look at [the one before it]( Mined by ViaBTC B2.  So you have to account for propagation delay between China and US here.
Not only that, but two different data centers likely have two different clocks for their timestamps.  You know 0 about their infrastructure, so you can't assume anything about how long it takes them to validate blocks based on this.
I really wish people would think before posting and embarrassing themselves.
@_date: 2016-10-12 23:35:13
Also there is no bound on the confirmation delay you experience with full blocks.  And with nodes' mempool rules as they are currently, your tx will be evicted from the mempool after a significant period of non-confirmation (~1 week in practice).  So it is very possible to have a transaction that is rejected by the network due to overly full blocks.
@_date: 2017-05-12 15:15:57
Your comment was disingenuous FUD in practice.  You say "if this block took 4 seconds to validate for the largest mining pool blocks are clearly too big!"  Even though there's no evidence of the former, naive users will conclude the latter.  It's very transparent.
That's even before you get to the other arguments people have already made here, namely that your premise does not imply your conclusion (and 4 seconds is pulled out of your).
@_date: 2016-05-02 21:05:39
HSTS can be trivially stripped out of headers by a MITM proxy on a router.  This was a new laptop so I assume there were no saved settings in the cache.  He could have bypassed the real electrum.org entirely through a DNS-based attack.
@_date: 2016-05-13 03:05:23
Re: Medium
I guess we differ on our definition of constructive.  Brian is merely echoing some sound and battle tested development practices.
"Don't let perfect be the enemy of good."
"Release early, release often."
"Listen to your users and let their needs guide your development."


This is objectively true.  Until the recent slack there was no wider communication channels, and most decisions and discussions were made on either a highly cliquey mailing list or a highly cliquey IRC, both of which excluded both large Bitcoin businesses and most Bitcoin users.
Want more examples of poor communication skills?  Look no farther than reddit posts.


ETH market cap agrees?
As for systemic risk, the comment is that having any single team being in full control of development is a risk.  This is not how open source development usually works.  The specific quote is:


This doesn't say Core is a systemic risk.  Simply that having a single point of failure at any one group is a systemic risk.  That much is obvious to someone doing decentralized development?
@_date: 2016-10-30 00:11:29
Condescending rebuttal with 0 objective facts.  You can do better than that.  Link proof or don't reply.
@_date: 2016-05-13 06:27:23
The first lesson you learn as a developer building any kind of product is that your users do know what they're talking about, often better than you do.  The developers whose hubris drives them to ignore input entirely are often the ones building solutions nobody gives anything of a shit about, and for good reason.
@_date: 2016-05-03 01:31:35
Yeah you're right, by strip the header I meant after downgrading SSL (which is a given for a MITM proxy).
I don't think it's that unlikely.  This is basically skiddie stuff, seems to meld with Dr. Craig Wright.  But I'm sure Gavin at least considered this vector and took some preventative action/investigation.
@_date: 2016-05-13 15:30:19
You seem angry.  Maybe when you calm down, we can engage in civil discourse?  
@_date: 2017-05-15 17:02:57
Everything in that article is still valid to the best of my knowledge, unfortunately nobody is really actively taking a skeptical approach on LN other than some dense and difficult to understand papers.
@_date: 2017-05-18 19:24:11
Makes it that much more ironic that they don't remember the last time businesses were marked for their personal/political beliefs.
@_date: 2016-05-26 19:53:46
Let's try simplifying this because I fear you may be missing the point here.
Let A and B be the two competing chains.  Let P be their shared prefix.  Let b be the last block they share (aka last block in P).
If as of "b" I have 5BTC, you agree that there is no way for me to lose any BTC denominated assets (as I will continue to have 5BTC on both forks by virtue of P).  You also agree therefore that unless money leaves the ecosystem, I will not lose USD denominated assets (as I will now have 5BTC on each fork, the sum value of which is equal given that no money leaves the ecosystem).
So that much is clear: if you're holding/spending, no way to lose money unless you're denominating assets in fiat and fiat leaves the ecosystem.
What about if you're receiving?  In what cases would you lose money?  Well, you would need to accept a transaction on "A" (the original chain that non-upgraded clients are seeing) and assign it the value of a transaction in P.  So you'd have to be wrongly calculating the USD price of the BTC on A, in ignorance of the existence of B.
When can this happen?
- Forgetting to update software in ignorance of a major market shift away from "A".  This is **already a problem** node operators face with or without contentious forks: if you are handling large sums of money you **must be aware of upgrades**.  Otherwise you can be in a situation like this:  even if there is no purposeful contentious fork.  So yes, the onus is on the receiver to be aware of both market conditions and latest upgrades **already**.  A contentious fork doesn't change this.
- Trusting a payment processor who forgets to do the above.  In this case, you have legal recourse through the traditional court system.  This is indistinguishable from a hacked payment processor who fails to pay out: either case indicates gross negligence on the part of the processor, and since they're in business specifically to avoid that kind of negligence the probability of this remains very low.
So, in conclusion: if you are sending money, it is not possible to lose assets via a hard fork.  If you are receiving money, you may be tricked into a false confirmation if you are running on old software and/or unaware of the current market conditions behind a fork.  But the latter situation can happen anyway with no contentious or intentional fork, as it did here:   So the onus is on you to upgrade and to pay attention if you're handling payments.
The likelihood that any reasonably old transaction (at the time of the fork) that you care about is in P is extremely high, p ~= 1.  This is because as mentioned earlier the market is incentivized to choose B such that the common prefix is maximized (the market incentive here again is to preserve history).
@_date: 2016-05-12 21:39:20


You are right about this point by the way.  This is a very recent (1 month) development I haven't been kept abreast of.  It does look like a step in the right direction, and I hope that companies like Coinbase engage the process.  Any complaints about unfairness will then be made more concrete.
I naturally have a complaint with this portion of the program:




The notion of "rough consensus" and the process of deciding it in private seems a bit warped to me.  But hopefully it will shape out to be a fairer process than the one I'm envisioning. 
I believe that all reasonable and not clearly insecure or technically deficient proposals should be offered for user and/or miner voting.  
I only fear that it's too little too late, and that some Bitcoin business may have been permanently alienated by their exclusion from the development process to the point that they're now transitioning their business model away from Bitcoin.  Circle is a perfect example of a company I believe sits in this category.
@_date: 2016-05-12 20:23:08
I guess that comment says it all re: your mentality, especially on opposing viewpoints.
I post and will continue to post on both subreddits.  Unlike some I prefer to hear all arguments and decide for myself which is valid.
Call me a troll all you want, but if you honestly believe my comments are designed to elicit an angry response, why are you even replying?
@_date: 2017-05-12 15:14:46
What would this do that ERC20 ICOs don't already do better? 
@_date: 2016-05-12 19:20:12
Completely agree.  Most Bitcoin businesses have contributed resources to the open layer in the form of Bitcoin Foundation membership, which for a long time paid several developers and scientists.  There is no such channel for them to contribute currently, which is a problem we need to resolve as a community.  
Even if these companies wanted to contribute developer talent to submit patches that addressed their needs, there is a high probability that these patches would not see fair consideration under the current development / governance model.


All the criticism I have seen has been constructive.  If you had Brian Armstrong tweeting "Core is a junta that's owned by BlockStream" I'd agree with you, but that has not been the case.
@_date: 2016-05-12 20:09:06
I suppose you're speaking for yourself too then? :)
You have no idea who I am or what I've done for the ecosystem.  And I prefer it that way.  
But yeah, feel free to ignore my comments.  This discussion means literally nothing to me.
Again, look at the comment I'm replying to though.  Clearly directed at Brian Armstrong.  And he's done more for the ecosystem than Samson Mow could do given infinite time and money.
@_date: 2017-05-12 15:15:15
Yeah plenty of people mining in the US.  Ant has a datacenter and I personally know of at least a few BitFury crates operating stateside.
@_date: 2017-05-11 20:01:42


Too bad you can't rely on this because there is no way to predict or ensure economic majority support.  It is defined by market price and can exclusively be analyzed in retrospect.  Remember, measuring is not sufficient (there's no good way to measure either, but even if there was); economy can change its mind when the rubber meets the road.


If you're comparing BIP66 and the ecosystem then to the most contentious change in the history of the ecosystem and the ecosystem today, you may be missing brain cells.  Sorry.


No, as smarter people have repeatedly tried to describe, breaking down into arbitrary cases and assuming conclusions like economic majority support in this fashion means jack shit and matters for nothing.  What matters is a single question: how expensive is it to fake confirms on an old node?  It's the same cost as during a miner minority UASF as it would be during a hard fork.  And that's all that matters.
@_date: 2016-05-06 23:59:49
What central authority are you bribing to get my disk encryption password?  Or my BIP32 password?  His usage is correct.
@_date: 2016-05-12 21:28:24


Yeah, I think that would be news to any investor.  What's the point of a consensus protocol that requires consensus to execute?  The logic is circular.
The consensus is in the protocol.  It always has been.


You could not be more mistaken or misinformed on that point.  Satoshi did not foresee GPU mining - this doesn't mean he saw every user running their own nodes: 


-- Satoshi Nakamoto, [June 29 2010](
Coincidentally, Satoshi also advocated a hard fork for raising the blocksize limit:




           maxblocksize = largerlimit
-- Satoshi Nakamoto, October 2010.
Are you claiming to have a better understanding of Bitcoin's architecture than its creator, or knowledge of facts that allow you to discount that position?  Interesting...
Either way, this is not about the blocksize.  Even if you support 2kb blocks, you understand 1 CPU 1 vote is the chain voting mechanism used on the network today.




 &gt; Either way I won't bother entertaining someone who resorts to shoddy arguments citing holy scriptures as if there has not been 5+ years of innovation, knowledge and best practices acquired since. 
They're not holy scriptures.  They're the design principles laid out for the system.  That's not to say that they can't be incorrect, but if you want to modify a high-level design goal for the project like that you need a lot of conclusive evidence and a strong logical/technical argument.  You have neither against 1 CPU 1 vote, considering it's still how any PoW protocol runs today and still how they will always run in the future.
@_date: 2017-07-30 21:46:55
Lower your connection count to reduce bandwidth consumption.  Bandwidth figures are meaningless without further info (connection count being one of them).  Also, are you running CB or XThin?  On how many connections?
@_date: 2016-05-13 15:36:11
I've written a few things on top of Bitcoin, contributed to some Bitcoin repositories on Github on the library side, and yes, invested **a lot** of my own money.  
I've been doing it since 2011.  So if you want to believe I'm being poisonous and negative, that's fine.  But ask yourself why you are ignoring a legitimate argument on its face.  I hope you have the introspective ability to come to a crisp conclusion there.
Good luck.
@_date: 2016-05-12 19:16:45
The argument here is "if you don't like the way I develop it, shut the fuck up and deal with it".  What are your recourses in a typical project?  Forks under the open model.
There's no equivalent in Bitcoin.  You can't fork the project without being accused of running a coup.  We're dealing with consensus here.  The differences between the products are **extremely relevant to the point being made**. 
What strawman am I standing up exactly?
If anything is "absurd" it's the argument that Bitcoin development should proceed in a vacuum that ignores user and investor needs and positions.  
@_date: 2016-05-13 06:26:05
So when do I get my check from these "deep pockets"?
@_date: 2016-05-12 19:21:35
I edited it in one way, and one way only.  This was added after the fact:


The rest of the comment is original.  All edits were within 3 minutes of posting.
@_date: 2016-05-12 20:07:25


BIP 109.  BIP 100.  Xtreme Thinblocks is the best example though.  Patch submitted with fully working code, rejected because "the relay network solves the same problem", despite the relay network being centralized.
@_date: 2017-07-05 17:57:35






Oh God, can't wait for August 1st so we can finally do this thing and have all the idiots out.  On the other hand, I'm going to call your bluff here and stay you'll stick around and keep posting garbage.
RemindMe! 2 months
@_date: 2016-05-13 14:07:56
He may not have understood **everything**, but he understood **that** (you cannot code a client implementation without understanding 'the subtle difference that exists between longest chain as determined by miners "vote" and longest valid chain according to the network of peers. ').
Bold delusional all you want, it only self reflects.
@_date: 2016-05-26 22:32:32


By "update software" I mean "to the desired fork" not "to the next version of that software".  Sorry if that wasn't clear.
If you don't know whether to update or not, or what side of the fork to take, don't process payments into fiat or goods that can't be reversed.  This is an edge case - markets move fairly quickly on determining which chain has value, so there won't be any significant downtime.  And if you're using a payment processor this will all be done for you.


Fair enough.  Always a risk you take trusting someone else to manage your node though, regardless of whether there is a fork or not.
@_date: 2016-05-26 13:48:43
And what incentive would the market have to recognize that fork (it's not an altcoin, again nontrivial shared prefix w main chain) and discard 1k blocks of history?
p ~= 0.
@_date: 2016-05-12 21:59:06
You don't need sidechains to have multiple chains.  In fact, the architecture for allowing multiple competing chains that nodes vote on is outlined here: 
Side chains only matter if you want to be able to move coins back and forth and institute a peg, which for competing distributions (what I'm assuming we're calling consensus implementations?) isn't really necessary, and is in fact counterproductive to market discovery.
@_date: 2016-05-12 19:09:59
If you don't understand the difference between a piddly little Javascript library and a consensus-based project where any change directly affects a network handling $7B of investor and user equity, you have absolutely no business posting in this subreddit.  You're comparing apples to financial instruments.
And implying users should "shut the fuck up"?  What?  As a developer, if you're not listening to your users, you are fucked.  Your product will have no direction and no application.  That might be fine for a Javascript library, but does not work in the least for a currency.  Are you seriously suggesting that companies that have millions invested in building infrastructure on top of an open source system should "shut the fuck up" when it comes to the development of the underlying open layer?
Not to mention that if you don't like the way "hapi.js" is being developed, you can just fork it and develop it however you'd like.  Trying to do the same for Bitcoin has been referred to as a "coup" in the past.  The systems under consideration are not even remotely similar.
Complete shitpost.
@_date: 2016-05-26 00:06:33






If it's the nature of the free market to use up unused resources, why have blocks [only recently filled to 1MB](  Also what size do you imagine miners would be mining in an infinite mempool, no block size limit scenario?  And is there any history or data backing that intuition?
@_date: 2017-05-13 15:13:56
That's exactly what Jorge is saying though.  He's not saying that opening a channel and making payments on it doesn't work as in this video, that's worked for ages.  He's saying the decentralized, privacy preserving routing scheme *with the same guarantees as Bitcoin* that is vulnerable to Byzantine attack and massively scalable doesn't exist yet.  LN currently uses an IRC channel for routing.  Yeah...
Decentralized routing is known to be an incredibly hard problem.  That's not to say unsolvable, but incredibly hard.  Even anonymity systems like Tor use centralized routing.  Some decentralized systems exist, like in BT's DHT, but they're neither privacy preserving nor vulnerable to serious attack.  Proposals for LN like Flare haven't really been evaluated or battle tested, and can't be without the network topology.
To figure out the routing, you need to know the network topology.  How many users, how many channels each, with whom, what are the weakest links (the min cuts in the network graph, etc).  Then you can decide an algorithm.
That nobody has even thought about these for LN is what worries Jorge, and he's right.  It absolutely might work, but it doesn't today and banking a $20B currency on the solution to that currency is a risk everyone here should be aware of.
Additionally, his point is that it might not make sense economically.  If only 2 people use Lightning and they pay each other less often than they're willing to keep channels open, it obviously saves no on-chain txs (and actually decreases scale).  So the economic model is also important!  After all, how often do you do 100 transactions in 10 seconds with someone?  Sometimes it would be nice, like real time exchange or micropayments, but for daily use?
It's a cool idea, but 5 years out minimum.  We can't use it to feed engineering decisions for real problems Bitcoin is facing today.
[Jameson Lopp]( has a great article if you're interested.
@_date: 2016-05-19 07:44:53
That includes blocks that aren't full due to network latency (including empty blocks, there are plenty of these every day).  
The best graphs to consult are here:  (Princeton prof. and eminent Bitcoin researcher)
This also doesn't take into account miners that are intentionally mining smaller blocks.  Once your "blocks full percentage" graph plateaus but your mempool/discarded transactions are continuing to increase you know we've really hit network capacity as it stands.
@_date: 2016-05-12 22:31:30
Thanks for the time spent clarifying where you stand Peter, glad to hear that you favor letting the network decide what is spam through what it chooses to relay and what it chooses to mine.
@_date: 2017-05-05 14:47:07
The point is that if you're American (and yes, well served by Visa), your Starbucks transaction is a typical savings account for a lot of people in the third world.  
@_date: 2017-05-19 12:55:37
You realize that this idea (shut down minority chain during a hard fork by mining empty blocks on it) was also [proposed by a core developer as a BIP](  They didn't say that they had any plans to do this, just that it was on the table.  It's far from as big an issue as you're making it due to the hatred of Bitmain refusing SW blinding you.
@_date: 2017-07-30 22:34:21
Yeah, this is way too many and totally unnecessary for a home node.  Try running the defaults (8).  Your bandwidth stat is BS with all due respect.  You don't need that many connections, and arguing for crippling the network so that you can have unnecessary bandwidth wasting connections is silly.
Money is on that number going down further with CB/XThin.
@_date: 2016-05-12 20:32:19


Whoa!  


making.  If the majority were based on one-IP-address-one-vote, it could be subverted by anyone
able   to   allocate   many   IPs.     Proof-of-work   is   essentially   one-CPU-one-vote.     The   majority
decision is represented by the longest chain, which has the greatest proof-of-work effort invested
in it.  If a majority of CPU power is controlled by honest nodes, the honest chain will grow the
fastest and outpace any competing chains


leave   and   rejoin   the   network   at   will,   accepting   the   proof-of-work   chain   as   proof   of   what
happened while they were gone.  They vote with their CPU power, expressing their acceptance of
valid blocks by working on extending them and rejecting invalid blocks by refusing to work on
them.  **Any needed rules and incentives can be enforced with this consensus mechanism**
Ctrl-F vote.  It is mentioned many times in the whitepaper.
If we can't even agree on this, no point in continuing discussion.


The whitepaper mentions no such distinction.  The activation mechanism is identical.


I'm not looking to get banned, friend.  The diff is on Google for you to find.
@_date: 2016-05-12 19:30:45


You misunderstood.  I'm insinuating that because they are so different, conclusions made by the "hapi" devs do not apply directly to Bitcoin. 


Yeah, that's an unreasonable argument when the title here is "How to Use Open Source and Shut the Fuck Up At the Same Time".
@_date: 2016-05-13 15:44:35
No, **you** misunderstand the model.  Obviously developers don't take pleasure in being harassed.  But as an open source developer, what motivates me is seeing the practical impact of my software as people use it.  Because it sure as hell isn't money.  Without users I wouldn't bother, and I suspect most devs are the same.  Obviously you have a vision, but you let the needs and problems of your users guide that vision as it evolves.
You also need to look into the right to make and distribute forks, fundamental to the free software movement: 


 is a good starting point.  While I don't agree with some of Stallman's philosophical posturing, specifically against open but non-copyleft licenses, he is the father of the movement and he currently has the clearest treatise on what free software is and why we're doing it.
@_date: 2017-07-30 22:57:49
Yes, your stat/post is BS.  I can say I have 1M connections (of which 999k are to myself) and use 200TB of bandwidth, that's not a useful stat.  It's misleading as fuck.
Use a sane number of connections for a home node and get back to me.
Crippling the network is arguing for keeping an unnecessarily low block limit so that you can use excessive connections on your shitty Internet (FWIW, in the US I haven't had a bandwidth cap since 2002).
@_date: 2016-05-12 20:02:24
To further clarify without being accused of editing, the comment I replied to said this:


Who do you think that was directed at?
@_date: 2017-05-18 19:34:25
So if they were running the latest version of Core and signalling SegWit you would have done the same?  Sorry but I don't believe you.  
@_date: 2017-07-06 22:26:25
Yes it is.  1 August will be the failure of UASF and the lock-in of NYA SegWit and 2MB fork.  Can't wait.  You and luke can go start your own new-PoW chain together, rejects of Bitcoinland with no hashpower!
@_date: 2016-05-26 00:13:35


You can be in the genesis block and have it be worthless.
In either case p ~= 0 &amp;&amp; p != 0. 
A 1000 deep fork would essentially be a 51% attack on any chain.  If you have a 51% attack any blockchain is worthless.
@_date: 2016-05-12 20:21:00


All scaling patches thusfar have been discriminated against.  Their activation was not implemented in Core.  Had they been implemented in Core, miners would still have been free to reject or accept as per the built-in voting mechanism through which all BIPs are deployed.  The fact that miners could not vote on any scaling BIPs without switching away from the Core client **is discrimination**.
As for XTB, I don't know if I'm allowed to link the code on this sub.  [Here]( is Greg's response though, where he ignores the data that has shown a 2x propagation increase in practice and claims that the fast relay network subsumes the need for thinblocks.  Ignoring the fact that the fast relay network is centralized, run by a single person, and imminently facing shutdown.  
In your link, Greg is comparing XTB to a similar proposal.  Their implementation is however entirely independent.  From your link:


Submitting a PR to Core would be an exercise in futility when a project leader whose consensus is required for a merge has already actively opposed the idea.


I can say the same for you.  See how that's unproductive discussion?
@_date: 2017-05-21 01:48:49


Of course it applies.  Linking to UASF binaries is linking to software that attempts to alter the protocol without overwhelming consensus.
[See here]( for BashCo's explanation as to why UASF binaries are currently not allowed to be linked here.  It's perfectly consistent with the removal of links to Unlimited and XT.
@_date: 2016-05-12 22:28:46
Who are you to decide that someone else's transaction is unnecessary (given that they paid a fee for it that was sufficient for miner inclusion)?
There is an issue you're hinting at here that nodes are not being compensated for their service, which I agree is a design flaw (but a difficult one to robustly technically overcome).  If you were receiving a portion of the fee surely suddenly that transaction would no longer seem to be "spam" to you?
@_date: 2016-05-02 18:04:33
I promise you he did not, Gavin specifically mentions using Electrum to verify the signature not some janky OpenSSL script.  Three possibilities:
- Gavin is lying in the comment linked.  I doubt this, the words are chosen very carefully and are more detailed than what one would expect from an outright forgery.  Also there are some other independent verifications of likely the same demo.
- Craig MITM'd the copy of Electrum that was used to verify the signature.  Certainly possible if he had access to the laptop, chose the software, and/or had access to the Internet connection used to download it.
- Craig has some connection to Satoshi.
@_date: 2016-07-01 20:37:32
100% of blocks are also prunable.  Store the UTXO.  If you're not revalidating signatures, dump the witness anyway and put the TX hash in a new data structure.  Checkpoint blocks and dump old data.
Any pruning you can do on SW you can do on existing transactions with some modifications to internal client data structures, providing functionally identical security guarantees.
But you already know all of this.
@_date: 2016-07-05 17:33:53
 is the only such study, and is already out of date.  With new P2P routing technologies that reduce block propagation times, like XTreme Thinblocks, Compact Blocks, and the Falcon Network for miners, blocks larger than those concludes as the maximum by the study are possible with the current network.
Note this study only analyzes the effects of blocksize changes **on the current network**, not on any possible future networks or theoretically ideal networks.  Lots of work still needs to be done in that space, and I don't think we can rely on the Cornell researchers... we have to do it ourselves.
@_date: 2016-07-01 22:26:39


Are you serious?  Miners have to take into account both the non-witness data size and the total transaction size, against two separate limits.  SegWit space is discounted at a fixed percentage, and it's unclear if the set percentage corresponds with network realities of cost.  If the percentage is at all too high or low (and to check this you need to do an optimization problem anyway), you've degenerated to the same optimization problem.  
I have to believe you're just jerking me around when you say things like this.  I can prove it with a concrete example if you really need me to, but I think you already know exactly what I'm talking about.


That applies as much to the system today as it does to the current system + any possible set of changes.
The rest of your arguments are circular and have already been addressed.


All can be fixed trivially if you *intelligently* rather than blindly increase the size limit.
@_date: 2016-05-12 21:22:20
Can you please link me to a non-constructive contribution from either?
@_date: 2016-07-08 15:02:22
I daily a sports car to work in a city known for its traffic.  I love it.  Nowhere near as fun as driving a sports car on empty roads, but don't kid yourself it's still way better than sitting in traffic in a base Camry.  For something I spend at least 12 hours in every week, it's worth the extra few bucks to get something I actually like.
 If comfort is only priority, by all means don't (though there are tons of comfy sports cars too), but if you care about things like driving dynamics, engine note, maneuvarability, etc. and you can afford it comfortably, by all means go for it.  [This guy]( for example is doin it right.
@_date: 2016-05-13 15:29:16
What a crisp argument.
@_date: 2016-05-12 21:49:46


Are you honestly saying Satoshi didn't understand this?  That's laughable.   Any time he said "longest chain", "longest valid chain" was implicit as per that node's view.


No, but he is certainly someone worth listening to.  


Maybe as a collective, but **your** understanding is certainly not superior to Satoshi's (and neither is mine, or any single party's).
@_date: 2016-05-12 19:49:15
I never said your comments were.  I said "this thread".  
The only non-constructive criticisms I've seen are from trolls like Samson Mow, and a bunch of reddit users who have absolutely no say in development anyway (and are easily ignored).
Nobody whose words hold any gravitas has made such comments, at least not that I'm aware of.
And if this thread is entirely complaining about reddit trolls, I ask why this is even a problem in the first place?  They are so easily ignored when their arguments are non-constructive.
@_date: 2017-07-30 21:47:50


Kind of sad that people downvoted me and upvoted that :(.
@_date: 2017-06-19 06:09:26
You are aware that you are changing the subject?  Luke is not pushing SegWit because it is a blocksize increase, he is pushing SegWit **despite** the fact that it is a blocksize increase, by his own admission.
luke-jr has stated repeatedly that he believes 300kB is the optimum block size today, and even provided calculations in BIP-BLKSIZE to this effect.  Your goalpost shifting is just as lame as calling luke's BIP a "blocksize increase" (or implying that luke at all supports block size increases; he does not and has repeatedly stated such).
So yes, luke is a proponent of SegWit.  But your implicit assumption that SegWit support =&gt; large block support is false, and you need only luke-jr's own calculations to back this up.
@_date: 2016-07-01 22:05:08


It is, on both SegWit and the block limit increase (the two changes being compared).


All of the benefits.


And SegWit's discount and effects on UTXO doesn't complicate a multi dimensional optimization problem?
Fortunately, multi dimensional optimization problems under constraints are what markets are by far the best at solving.
@_date: 2017-06-27 14:21:07
He actually never wrote a rebuttal to my counterargument, and his original post was a deeply flawed and naive rebuttal of my argument.  
@_date: 2017-06-27 14:20:24
BU is SegWit compatible, silly.  It'll accept and extend a SegWit chain, and can process SegWit blocks.  It just won't mine or create *new* SegWit blocks.  So if you support SegWit but don't want to mine SegWit blocks yourself, BU is exactly what you need.
Presumably if the miners who are running BU later want to create SegWit blocks, BU will merge SegWit (assuming it is successfully activated on the main chain I think this is a given).
@_date: 2017-06-19 06:04:24
Fuck no.  In the same way that if I wrote a BIP that let you have 32MB blocks but required 200K of actual data padded with 0s, that would technically absolutely be a "blocksize increase".  But nobody would actually take you seriously if you billed it as such and suggested its adoption.  Leaning on definitional semantics to argue for flawed proposals is lame.
@_date: 2017-06-19 05:53:41


LOL!  Sure, technically speaking.  But effectively it was absolutely a blocksize decrease.
300kB today, with a slow increase to today's current 1MB level to be hit in 2024.  After that, conservative increases.  It's a blocksize decrease today, an increase after 7 years (where with any sane scaling plan we'd have far greater than 1MB blocks as in luke's proposal).
@_date: 2017-06-27 14:31:38


Merging SegWit takes 5 minutes (I've done it).  Checking its interactions with all your changes may take longer, but do you really think the BU team will spend months on this?  I think the 2 week activation period is plenty of time and I think if I were them, I'd be working on it anyway given the NYA and 80+% hashpower committing to "we will activate".
@_date: 2017-06-24 13:29:08
I find this position deeply and fundamentally flawed.  Hard forks are not only a feature of the Bitcoin protocol, they are **its fundamental upgrade mechanism**.  Why fundamental?  Well, one of the key properties of Bitcoin is its antifragility and censorship resistance.  Where do these properties this come from?  What if someone like PayPal buys up 51% hashpower and uses it to make the network anticompetitive?  What if miners start censoring transactions?  What if KYC is imposed on-chain?  What if a flaw is found in double-SHA256 PoW?  How do we route around these?
The answers to these make it quite obvious that hard forks are absolutely critical to the success and proper operation of the protocol.  Now the question becomes "when are they worth their risks?"  The answer to this is again simple.  Given that we **will** need to hard fork, likely many times, in the evolution of this cryptocurrency (the core design is after all not perfect), what we should be doing is **building the infrastructure to fork safely** rather than arguing that doing so is hard.  Wallets and node software that detect and respond to divergent chains and difficulty drops, user interfaces that simplify this to the maximum possible extent for users, and more.
The crowd of "router password defaults" that you're talking about is always and without exception going to be using either SPV wallet providers or more likely custodial wallets like Coinbase.  For this crowd, a hard fork is absolutely a nonissue, as they defer their decisions and the burden of informing themselves to their wallet provider or backing node operator.  The router password default crowd will and should absolutely never and in no circumstances run a full Bitcoin node, which should be obvious enough by talking to any of these people.  You need some expertise to maintain security when you run your own node, and complete amateurs doing it is actually detrimental to their correct use of the network, not beneficial.
I don't think anything is or will ever be as harmful to the BItcoin protocol as the lies and FUD that was spread fighting hard forks during the XT/Classic days, and it's highly unfortunate that these untruths have lead to a severe ossification of the protocol rather than continued work on ensuring that its inevitable hard forks will proceed smoothly, safely, and effectively.  Too much complaining that this is hard, too little doing.
@_date: 2017-06-19 06:10:45


Restating bullshit don't make it true!
@_date: 2016-07-01 14:14:35
SegWit with 2MB effective blocks has the same exact disk space and bandwidth requirements as a 2MB hard fork.  
@_date: 2017-06-24 14:04:13


The in-protocol guarantees, yes.  There is an entire class of extra-protocol guarantees that I am describing here, and antifragility and censorship resilience lie there.


We cannot make any in-protocol guarantees, as an extra-protocol community we can agree to fork to a chain that embodies the original ideas and preserves state in a way that "Bitcoin" will continue under a different chain.  An example of this would be a PoW change release from the "Bitcoin Core" project; it leans not on in-protocol guarantees but on extra-protocol infrastructure.


The sole upgrade mechanism for controversial changes, how about that.


I agree that giving users the **option** to run a node is great, but we should not cater the protocol design to a class of users that will simply never, ever run nodes.  These users do not care enough to run full node software even if given the option, and would rather save the money and go with a delegated node or custodial option.  Talk to some of them yourself sometime and you'll see that I am right.
At the end of the day, it is the enthusiasts who will be running nodes, and we need to keep giving them the option to do so.  The enthusiasts however understand the concept of a fork and will respond accordingly, especially with built-ins like difficulty drop and chain split detection.
@_date: 2016-07-01 21:29:06
That wasn't your original argument.  Your original argument was that 100% of the space increase is prunable.  All of those items can be pruned without SegWit.  Everything I said *is* the case, despite your insistence to the contrary.  Read my comment again and see that yours confirms it.  My rebuttal was to this:


As for increasing efficiency by constraining UTXO: Do you have any data to indicate that SegWit would lead to more UTXO efficiency *in practice*?  A 1MB block *can* have 1MB of UTXO increase, but let's be realistic.  It practically never does.  Also, what would stop a UTXO limiting soft fork from doing the same?
@_date: 2016-07-01 21:34:49
As the other commenter said, full SegWit blocks @ 1MB of non-SegWit data can have an effective size between 1 and 4 MB when including Witness data, depending on transaction structure and utilization percentage.