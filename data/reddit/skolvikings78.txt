@_author: skolvikings78
@_date: 2017-03-23 22:59:40
Except that Schnorr's signature aggregation doesn't reduce the input/output address data that counts against the 1MB hard cap, so it's really 1 MB -&gt; 1.7 MB (SegWit) -&gt; 1.4 MB (full usage of Schnorr sigs.)
Great for data efficiency (TX/MB), no impact on transactions per block (assuming full transition to SegWit).  
@_date: 2017-03-22 19:59:13
If Satoshi Nakamoto wanted there to be real transaction fees in 2017, he'd have scheduled the mining reward to trend toward zero in 2017.  
@_date: 2017-03-28 13:42:32
Classna was merely repeating exactly what was stated by Mao Shihang in the OP, not making any personal judgements.
This is a pretty straightforward thread:  OP asks why doesn't F2Pool pick a side and links to a feed that clearly quotes an F2Pool guy saying "BU's code still sucks", and "Core's people are douchebags".  That's why the aren't picking a side.
@_date: 2017-03-26 02:37:10
Andreas is spot on: it changes the rulers on max_block_size from the development team, who has been maintaining the current max_block_size since it was first installed, back to the miners, who originally ruled on the topic.
Note: that the miners are also economically incentivized to optimize bitcoin parameters for the good of the network as it maximizes their profits.
@_date: 2017-01-20 14:30:13
Be careful, you get banned here for telling people that they get banned here for stating facts.
@_date: 2017-06-28 13:15:13
That was the whole point of the original article.  A decentralized peer to peer LN is impractical or even impossible.  The only possible topology is a hub and spoke system.
A hub and spoke system is a centralized system, obv.  This leads to single points of failure, less censorship resistance, and a trusted model...all things bitcoin was designed to eliminate.
@_date: 2017-06-27 18:10:39
Correct.  The whole point of the article is that a purely decentralized, distributed lightning network is mathematically impractical.  Therefore, the only LN topology solution is to have large hubs.
It's expected that from there, many people will be able to extrapolate that large hubs = increased centralization.  The article highlights at least one major attack vector that is created with this increased centralization.  There are actually many, which is why LN is a long, long way from being a usable scaling solution.
@_date: 2017-06-28 13:11:38
Jonald also fails to grasp the point from the original article that a 10 branch-6 hop network with no redundancies is going to be one of the most efficient ways to interconnect 1M members.  If you add in a bunch of redundant paths, as several of the responses require, then you will need many more branches or many more hops.  This in turn, makes the network significantly more impractical.