@_author: veqtrus
@_date: 2016-08-26 12:48:05
He didn't. Bloom filters were invented by... [Bloom](
@_date: 2016-08-12 23:20:57
Why should we want mass adoption?
@_date: 2016-08-27 18:15:53


@_date: 2016-08-27 04:20:26
@_date: 2016-08-15 08:01:13
What? People shouldn't develop software because there are idiots in this world? The target audience of Bitcoin isn't idiots.
@_date: 2016-08-09 05:07:19
Unless you increase dbcache which reduces hard disk reads/writes.
@_date: 2016-04-16 16:24:21
Uh, it already is. There is a P2P network protocol version and block versions.
@_date: 2016-04-20 09:08:14
The CSV related soft forks are already part of 0.12.1 and hashpower majority activation will begin on the 1st of May.
@_date: 2016-08-25 10:34:16
Checkpoints aren't updated anymore since headers-first.
@_date: 2016-04-20 08:21:28
If the difficulty could change more easily it could be manipulated more easily.
Remember that we trust miners to set the correct timestamps for their blocks. If it becomes profitable to lie about the time they will.
@_date: 2016-04-19 16:43:24
Correct but there will be no performance increase for them.
Edit: you won't be able to download blocks efficiently from older nodes.
@_date: 2016-04-08 19:25:37


They are relayed by default for up to 3 keys.
Edit: [BIP11](
@_date: 2016-04-01 11:58:19


I'm not sure how using Bitcoin would help someone get laid.
@_date: 2016-04-30 07:29:32
I've set a static 80 μBTC fee in Bitcoin Core and never had a problem. Couldn't be simpler. I used to have it at 50 μBTC but have increased it just in case.
@_date: 2016-04-20 11:22:40
The limits can't be tight because there's loose consensus on what the time is on the network.
Also miners need to be able to set the timestamp before that of the last block because the previous miner could have lied.
@_date: 2016-04-29 13:08:15
1. Go to C:\\Program Files\\Bitcoin\\
2. Hold Shift and right-click the Windows Explorer window
3. Click "Open command prompt"
4. Type `bitcoin-qt -zapwallettxes` and hit Enter
@_date: 2016-04-29 12:21:28
The witness root hash is the merkle root of the witness parts and is stored only once in the *generation* transaction (coinbase is the first input).
@_date: 2018-01-08 08:19:01
There is no such thing as a fee discount, it is a weight discount. Weight utilization and fees aren't linearly proportional.
@_date: 2016-04-28 06:26:24
You do realize someone has to write sources, right? What matters is what the source says not who wrote it.
@_date: 2016-04-27 06:37:30
You forgot to mention that the costs of building new lanes will not be paid by those using them the most.
@_date: 2016-04-29 12:38:23
What operating system are you using?
@_date: 2016-04-20 17:21:16
Settlement is peer-to-peer in Bitcoin.
@_date: 2016-04-30 20:58:18
BIP9 itself doesn't need activation.
@_date: 2016-04-19 16:42:02
@_date: 2016-04-30 05:54:47
I'm fine with not everyone using Bitcoin. Is PGP/Tor/BitTorrent used by everyone?
@_date: 2016-04-03 08:23:35
@_date: 2018-01-07 12:39:50
But why? Why would a typical user need the RPC interface?
@_date: 2018-01-09 22:45:10


Bitcoin still exists because various contributors to the project fixed the numerous bugs present in SN's software which *only a mediocre developer would make in the first place.* Something as stupid as multiple off-by-one errors is not something non-mediocre developers do.
More reading:
@_date: 2016-04-30 07:04:21
It would be better but I'm not sure how can you simplify deliberately creating a transaction which will take some time to confirm. I'm fairly certain that all wallets prefer confirmed UTXOs.
Also if you dumb down a technology you might lose its benefits.
@_date: 2016-04-21 12:03:44
There is no centralization in a system where the barrier of entry is nonexistent.
@_date: 2016-04-24 17:07:22
BitGo and BlockCypher then.
@_date: 2018-01-08 14:06:02
Because it is wrong.
@_date: 2016-04-29 17:30:31
Exactly. If we decide to change the discount we will do a fork.
@_date: 2016-04-12 18:28:45
Exactly. A "successful" "classic" hard fork would mean that pop-bitcoin became fiat. I would continue to use it just as I continue to use traditional fiat.
I don't think altcoins are bad. If a centralized bitcoin becomes more popular (not that unlikely) we can continue to use proper-bitcoin which while at that point would technically be an altcoin, it would be a better cryptocurrency.
@_date: 2016-04-29 17:00:13
Via consensus rules changes i.e. soft/hard forks.
@_date: 2018-01-08 13:45:23
BTW the proper way to pronounce μ is "me".
Source: native Greek speaker
@_date: 2018-01-03 00:29:55
Most users do not transact frequently enough to have to worry about bandwidth. Those who do would have a custom setup anyway.
@_date: 2018-01-08 14:05:44
High *miner* signaling threshold has nothing to do with a fork being contentious or not.
@_date: 2016-04-14 17:21:55
Good. People are always free to resort to pseudoscience and wishful thinking.
@_date: 2018-01-09 03:12:12
Only incompetent devs think segwit is complex.
@_date: 2018-01-09 13:57:44
How is it trustless when the moderators are hard coded? Just because it's a desktop app and not a website doesn't make it decentralized.
@_date: 2018-01-12 09:16:29
Because they use Gavin Andresen's payment protocol exclusively which is as stupid as it gets.
@_date: 2016-04-30 06:51:01
Let's say someone uses the optimization without buying the patent. How will the author know?
@_date: 2016-04-08 19:31:00


@_date: 2018-01-08 01:57:58
So why didn't you merge the patch yourself? Or do you expect others to spoon-feed you?
@_date: 2018-01-12 09:27:41
You must be an incompetent dev. then. Bitcoin is a protocol, it is up to each user to use it properly.
@_date: 2018-01-09 22:19:57


a clean blocksize upgrade at this time. Continuing on the current path
could divide the community and be a setback to Bitcoin’s growth.
The only way for the community to be divided is if there are divided chains which in turn is possible only if users run full nodes which reject 2x. SPV nodes would blindly follow the miners.


Segwit is a block size increase and I am in favor of it. Unlike a hard fork to 2MB it introduces the concept of weight which is necessary to properly align the incentives of miners. More info here: 
@_date: 2016-04-20 10:01:09


@_date: 2018-01-08 14:17:11
Only get rich quickers claim Bitcoin is ready for mainstream use.
Also Bitcoin is closer to Linux than Apple.
@_date: 2018-01-12 21:23:38
No I'm referring to LN participants trying to publish older versions of a channel therefore cancelling their transactions. It is necessary to periodically check for such transactions and react by claiming the thieve's coins.
@_date: 2016-04-02 09:51:55


I suggest websites which don't aim to profit at the expense of accuracy: 
@_date: 2016-04-08 19:29:39


@_date: 2018-01-08 13:51:25
Only if you don't merge the patch yourself.
@_date: 2018-01-12 12:58:38
Bitcoin URIs work just fine. There is no reason to use a complicated protocol just to get an address.
@_date: 2018-01-08 15:48:40
Or the part where he contradicts himself in the whitepaper making his whole argument about the viability of SPV wrong. Or maybe the part about the numerous off-by-one errors demonstrating his sheer incompetence as a developer.
@_date: 2018-01-10 00:35:14
It makes restoring from backup a lot easier as you only need to scan one type.
@_date: 2018-01-10 00:34:12
The P2SH wrapped segwit address (starts with 3) and legacy address (starts with 1) is controlled by the same private key.
@_date: 2016-04-30 18:45:24
I think mainstream users should be kept as far from the core protocol as possible e.g. with Lightning. This way they will have a good reason to actually use Bitcoin (truly fast and cheap transactions). OTOH they won't develop an opinion on technical matters which they don't understand and hence the risk of politics messing with the protocol will be reduced.
@_date: 2018-01-09 20:12:06
Yes, if people don't care about decentralization they should use systems which don't offer it instead of trying to change Bitcoin.
@_date: 2018-01-24 13:53:37
Do you hand-craft your non-segwit transactions bit-by-bit?
@_date: 2018-01-09 02:33:49
Literally all your sentences are wrong. I didn't think that was possible. Please go back to /btc where your stupidity is welcomed.
@_date: 2016-04-19 14:25:27
It does introduce new message types and increments the network protocol version so the new block relay mechanism is not compatible with existing nodes.
@_date: 2018-01-10 00:28:33
An exchange could pay you via LN.


Hard to predict because widespread LN usage could attract more users.
@_date: 2018-01-09 17:24:05
Completely wrong. Consumers do not buy hardware and bandwidth in bulk.
@_date: 2018-01-09 03:26:46
For each sentence: print '[citation needed]'
You are arguing for hard forking so it is up to you to provide evidence that this is desirable.
@_date: 2018-01-09 03:03:20
If you are referring to Nakamoto he was as incometent as it gets. (when compared to cypherpunks)
@_date: 2016-04-24 05:29:21
I wouldn't be so sure about businesses. Most of them already outsource it to Coinbase and BitPay.
@_date: 2018-01-09 21:09:11


Sounds like Ripple "decentralization".
"Oh you can apply to become a centralized validator. Would be shame if we didn't let you."
@_date: 2018-01-09 02:57:45
The speeds are irrelevant. The hdd will simply die after a few months of heavy usage.
@_date: 2018-01-08 14:07:22
Tough luck I suppose. You could use electrum which is more noob friendly.
@_date: 2018-01-09 20:59:06


All your points are wrong and there is no escape from the fact that *you* need to provide evidence if you want to be taken seriously.


[citation needed]


*You* are arguing for hard forking so it is up to you to provide evidence that this is desirable.
@_date: 2018-01-09 20:29:32
So where exactly do I add arbitrators? 
@_date: 2018-01-09 20:06:43
Excellent rebuttal. Keep up with your logical fallacies.
@_date: 2018-01-10 02:36:37


At least you can admit you were wrong all along. Props for that :)
@_date: 2018-01-08 13:59:29
People who can't think for themselves isn't the target audience of Bitcoin. Your mother not using Bitcoin is not a loss. Bonus points for upsetting get rich quickers.
@_date: 2018-01-09 03:31:03
Bcash is Bitcoin without the decentralization. Might as well use PayPal.
@_date: 2018-01-09 03:25:51
No because segwit is a bug fix.
People who think that Bitcoin from 4-5 years ago was sustainable can use PayPal. Pseudoscience like that flood networks scale is not welcome here.
@_date: 2018-01-01 00:00:49
Why would you type it? You can copy paste or scan the QR code.
@_date: 2018-01-08 15:45:33


I see it as a good thing get rich quickers are moving to scams instead of polluting Bitcoin with their transactions.
edit: spelling
@_date: 2018-01-09 01:52:10
[citation needed]
@_date: 2018-01-08 16:48:59
So what was your counterargument again?
@_date: 2018-01-08 14:36:36


I'm fairly certain these people aren't hand-crafting their transactions.
@_date: 2018-01-10 02:07:52


Or I could continue running my full node and people who want bigger block sizes can use PayPal. They don't seem to care about validating their transactions anyway.


You don't need to be constantly updated about all the channels. Worst case scenario is some of the channels will not be available when you try to use them. Big deal, use others.


Doesn't invalidate what I said. The current model doesn't scale but it won't be a problem until much later. Unlike in Bitcoin when it is a problem now.
Also unlike in Bitcoin more efficient routing protocols already exist. Note that LN's routing problem is very similar to Tor's and Tor works.
@_date: 2016-04-21 12:08:29
It's median of last 11 blocks to 2 hours in the future.
Get the idea that honest miners will reject certain blocks out of your head. The only way this would happen is after soft fork activation.
@_date: 2018-01-03 17:09:48
Because despite the increased complexity it offers no security or UX improvement.
@_date: 2018-01-10 01:06:26
@_date: 2018-01-12 20:55:29
To monitor the blockchain themselves for fraud attempts in LN.
@_date: 2018-01-08 08:15:43
So why are most blocks over 1MB?
@_date: 2018-01-08 16:14:39
In case it wasn't clear your mum won't be spoon-fed either. She can continue using fiat if being her own bank is too much for her.
@_date: 2018-01-10 00:54:13


Most of the building blocks were already there.


It remains to be seen whether it will actually work. The current mining centralization certainly doesn't help.


And this is where SN's incompetence kicks in. He contradicted himself in the whitepaper and essentially proved that SPV doesn't work. 


Last time I checked the amount of data that needs to be transferred in LN's flood network is much lower than Bitcoin's. So even at much higher transaction volume LN's flood net will be able to cope. It would be wonderful if LN was so successful that route finding would be a problem.
@_date: 2018-01-09 21:59:42
Now that's some intense mental gymnastics. Segwit2x was called off *by its creators* because it was clear the majority of full node users (weighted by their economic activity) will be rejecting 2x blocks.
As for hard drives:
1. Good luck not throwing the hdd away after a few months due to frequent seeking due to running a full node. At least the most recent blocks need to be stored on ssd.
2. Storage was never a problem because of pruning.
Edit: Also segwit is a block size limit increase. You just have to use it.
@_date: 2018-01-08 14:01:24
So why is nearly every Bitcoin block over 1MB? Are you sure you aren't referring to bcash?
@_date: 2018-01-08 14:35:15
Why are you assuming that? Core supported mining segwit transactions from day 0.
@_date: 2018-01-24 14:00:01


So it affects only Bitcoin users? Seems relevant to me.
@_date: 2018-01-02 15:24:19


You only need to store one transaction per open channel belonging to you. We are talking about a few kilobytes at most. How expensive do you think that would be?
@_date: 2018-01-03 19:06:39
I'd just like to interject for a moment. What you're referring to as segwit, is in fact, block size increase/ segregated witness, or as I've recently taken to calling it, block size increase plus segregated witness. Segregated witness is not a capacity increase unto itself, but rather another free component of a fully functioning scaling solution made useful by the libsecp256k1 optimisations, layer 2 solutions and vital system components comprising a scalable payment network as defined by various BIPS.
@_date: 2018-01-12 09:13:19


Um, no. The payment protocol is just a retarded way to exchange a Bitcoin address created by no other than Gavin Andresen. The transaction still happens on-chain. 
@_date: 2018-01-09 11:08:10
Without running a full node you aren't using Bitcoin.
@_date: 2018-01-10 01:17:09
Thanks for the gold! I'm glad that I could help.
@_date: 2018-01-08 15:52:37
Where are your contributions to make it more user friendly? No one is going to spoon-feed you here.
@_date: 2018-01-09 23:26:00
My initial claim was that he was incompetent as a developer (for which I later provided evidence). This means that anything SN claimed (regarding protocol development) has to be taken with a grain of salt. The fact that he made a scientific advancement doesn't change that in any way.
@_date: 2018-01-09 22:37:40
Core developers don't need to claim anything when segwit2x's creators themselves did that.


That is also your burden to prove because the established chain is bitcoin not b2x. *You*\* are required to prove that somehow it was not the economic majority that made it happen.
The established science is here: 
\* 
@_date: 2018-01-08 15:50:15
Oh she absolutely is allowed to use it. For now that is because it still is quite decentralized.
@_date: 2018-01-10 00:09:31
SN is evidently not competent regarding protocol scaling. Flood networks don't scale *regardless* of implementation and the Bitcoin protocol requires a flood network to function (this was in fact the first response to the whitepaper announcement).
In fact he compared the future of Bitcoin nodes to USENET's NNTP servers while USENET is massively centralized and practically dead.
@_date: 2018-01-09 02:42:33


That's exactly what we want. People who don't want to use Bitcoin can use any scamcoin they want. That doesn't mean Bitcoin should change.
@_date: 2018-01-12 09:29:29


Native segwit addresses start with bc1. 
@_date: 2018-01-08 18:26:46
Cool. You are free to use the incompetent businesses then.
@_date: 2018-01-10 00:36:27
You could merge the patch yourself.
@_date: 2018-01-10 02:30:17


Yes, I have heard how broken it is from the whitepaper. It's almost like you didn't read my previous posts.


Neither does a LN node so quickly that this would be a problem. Link utilization on the Internet is constantly changing and yet routing protocols can cope with that.




\&gt;&gt;&gt; [PayPal Here]( &lt;&lt;&lt;
Also if you are into that. Oh you are.
@_date: 2018-01-14 16:31:58
Perhaps he should have said until fees become lower. Mempool can't be full anyway since there is no fixed size limit.
@_date: 2018-01-24 13:52:35


I don't see how is that a problem. People who don't want to be their own bank are not the target audience of Bitcoin.
@_date: 2018-01-08 19:06:34
No. Schnorr signature aggregation will most likely be in a new witness program version.
@_date: 2018-01-02 15:20:05


It would be better if that BIP was depreciated. The only reason it exists is because Gavin Andresen thought it was a good idea; it is not.
@_date: 2018-01-08 19:01:19
Actually it's mostly bandwidth. The blockchain can be pruned once downloaded.
@_date: 2018-01-09 03:06:21
Ethereum runs on Proof Of Vitalik though.
@_date: 2018-01-08 14:09:34
@_date: 2018-01-09 21:39:02


But I will provide a counterargument for your first point. Segwit2x was rejected despite the majority of miners signaling that they will adopt the fork.
@_date: 2018-01-09 23:08:35
1. You provided evidence that hard drives are cheap.
2. I explained why that is irrelevant and you agreed with my argument by asking "What's your argument against bigger blocks if storage isn't an issue".
3. You asked for a source on segwit2x being called off due to full nodes rejecting it.
4. I provided evidence from the segwit2x authors themselves. (Also explained how established science is in agreement with my claim by linking to the wiki.)
5. You asked for a statement from the Core devs.
6. It is not my burden to provide a statement from someone who is not an authority on segwit2x. Core devs. themselves do not need to issue a statement on established science. (It is as if you asked for a quote from Einstein that 1+1=2)
And now:


(Which I already answered by saying that I am in favor of a block size increase: segwit. I know that bigger blocks can hold more transactions. Use segwit to make that happen.)
@_date: 2018-01-08 01:50:06
There was a block size increase, it is called segwit.
@_date: 2018-01-09 03:21:44
PayPal also "works".
@_date: 2018-01-01 21:31:34
Create a new normal wallet and write down the seed. After checking your recovery procedure remove that wallet from your computer.
@_date: 2018-01-08 18:58:29
The metric system provides all the tools we need to divide bitcoin amounts (milli-, micro-). Unlike the US the rest of the world isn't allergic to maths.
@_date: 2018-01-09 02:54:30
In the same universe where the Internet was created.
@_date: 2018-01-09 01:55:05


@_date: 2018-01-09 01:26:28
Miners are free to ignore the weight discount. It would be against their interests but they can.
@_date: 2017-12-15 22:38:07
What's the resource usage like?
@_date: 2017-12-20 09:23:39
Good thing we have blocks over 1MB then.
@_date: 2017-12-08 22:32:03


PayPal already solved that in the same centralized way.
@_date: 2017-12-20 04:21:36
Devs have been using the term hashers for years to distinguish entities which don't make their own blocks. Most "miners"/hashers are merely selling their computing power to pools.
@_date: 2017-12-15 22:41:35
@_date: 2017-12-20 03:59:44
Those are called hashers. Miners refer to entities which produce blocks which are mostly mining pools controlled by humans.
@_date: 2017-12-14 17:57:32
Oh you mean companies actually have to do something to benefit from lower fees instead of socializing their costs to volunteers running full nodes?
@_date: 2017-12-08 23:10:19
Most people don't use Bitcoin.
Bitcoin was supposed to be a P2P cash protocol. It turns out (was known from the beginning by people who understand the tech) that flood networks don't scale. No amount of wishful thinking will change that. The solution is to change the network topology which is what Lightning Network is doing.
@_date: 2017-12-15 22:47:03


Man it must be so hard to change a few lines of code to use functionality already available in dozens of Bitcoin libraries.


@_date: 2017-12-28 14:55:10
People using Coinbase are already using a glorified form of PayPal. LN is strictly better than that since users control their private keys and LN nodes can't steal your coins.
@_date: 2017-12-14 18:09:53
Oh you mean ordinary people shouldn't be running full nodes. Gotcha.
\&gt;&gt;&gt; [PayPal Here]( &lt;&lt;&lt;
@_date: 2017-12-28 20:35:47


Well yes, that's a property of flood networks: their resource usage grows exponentially which means that on small parameter values the resource usage is small.


\&gt;&gt;&gt; &lt;&lt;&lt;


[citation needed]


Scaling of flood *networks* doesn't have much to do with long term storage.


Good luck not throwing them away due to frequent seeking.


[citation needed]


\&gt;&gt;&gt;  &lt;&lt;&lt;


Your ignorance is not an argument.


I'm not in a hurry.


I don't remember electing them to decide for me.
@_date: 2017-12-20 04:02:57


Is there anybody preventing you from contributing to the Lightning Network?
Wishful thinking that flood networks scale is not very helpful.
@_date: 2017-12-08 23:11:40
@_date: 2017-12-08 22:30:42
It is also practically impossible to run an ETH full node on typical consumer equipment so you might as well use PayPal if that's your thing.
@_date: 2017-12-28 14:58:19


It's not that difficult to have that uptime.


Not at all. You don't need to have a website for the node which is what would be hackable.
@_date: 2017-12-20 03:57:14
I don't see how pricing out people who don't use Bitcoin in the first place is bad. If anything it will lower the fees for people who do.
@_date: 2017-12-15 22:20:42
Try running an ethereum full node then. Or are you not running a full node at all?
@_date: 2017-12-29 14:10:50
    npm --add-python-to-path='true' --debug install --global-windows-build-tools
@_date: 2017-12-20 04:03:55
You can merge the segwit in wallet patch yourself.
@_date: 2017-12-28 19:09:42
Note that this type of centralization is desirable. As long as these big players route your transactions you are fine. If not you can use some other route which may be more expensive.
Since your node is calculating the route and intermediate nodes do not know the full path the centralized entities will not be able to discriminate you based on transactions you do that they don't approve.
@_date: 2017-12-28 19:00:02
Well if your fork is based on pseudoscience like that flood networks scale it is only appropriate to call it a scam.
@_date: 2017-12-15 22:19:49
My full node has no problem validating the signatures. Perhaps you have accidentally downloaded bcash and got forked off the network?
@_date: 2015-12-20 05:31:53
Bitcoin has a limit on the signature operations that have to be done to verify a block. Those are not counted accurately.
The mining target is calculated based on previous 2015 blocks instead of 2016.
@_date: 2015-12-23 09:12:39


If devs did what users want they would just set up a simple static webpage pointing to PayPal.
@_date: 2015-12-16 17:24:30


@_date: 2017-12-04 10:46:52
Actually it was more like "I'm offering these numbers in exchange for this service" and someone else agreed.
@_date: 2017-12-20 04:18:56
Debating is great and all (assuming technical knowledge) but not very useful for actually scaling.
@_date: 2015-12-27 08:23:11
Finish my joinmarket GUI wallet and contribute some code to NBitcoin in the process.
@_date: 2015-12-31 00:11:06


means that an attacker can create such blocks. SW is meant as a temporary increase which can be deployed with only hashpower majority.
@_date: 2015-12-29 02:11:12
The tests on testnet have shown the opposite of what you claim.
@_date: 2017-12-20 20:55:40
LN doesn't require network consensus.
@_date: 2017-12-20 04:25:12
Core devs are in no way obligated to provide software to companies.
Anyway there are a lot of libraries which have implemented segwit wallet functionality.
@_date: 2015-12-30 23:37:27


I upvoted you too :)
@_date: 2015-12-30 00:23:41
You can already create anyone-can-spend outputs. And after enforcement there will be *fewer* ways to create such outputs.
@_date: 2015-12-30 11:55:34
Where does it check that the main `vtx.size() == 1`? Also how are new blocks transported? And what is the point of a soft fork which completely breaks old clients?
~~Edit: Maybe it will work: 
@_date: 2015-12-12 17:50:46
    priority = sum(input_value_in_base_units * input_age)/size_in_bytes
@_date: 2017-12-28 19:03:42


In principle no though it is highly recommended. It is technically possible to operate on SPV. You could use a pruning full node though.
@_date: 2015-12-22 23:31:00
@_date: 2015-12-20 05:27:53
XT could reach consensus but currently that's not the case. Discussing the changes proposed by XT is fine and encouraged. It's not like you will be censored because you promoted an incompatible implementation in a forum where that is on-topic.
@_date: 2015-12-05 17:01:51
The [code]( has been updated, just needs to make an official release.
@_date: 2015-12-31 01:01:25
As an amplifier you could construct a script which checks the signatures multiple times. If you want I can construct one.
@_date: 2015-12-16 13:32:49
After a soft fork in order to spend coins locked in a sidechain you will have to prove that the withdrawal transaction is in the chain with the most work. If a miner can create a strong enough chain with an invalid withdrawal transaction he can steal locked coins.
@_date: 2017-12-14 17:59:56
That's exactly what we are asking. Why do you want so much to put your nearly worthless transactions on an immutable ledger?
Considering you probably don't run a full node you get the exact same security benefits as using PayPal.
@_date: 2015-12-22 13:30:26
Maybe it would be better for the past 20000 blocks to observe the change over the last 4.5 months?
@_date: 2015-12-16 16:06:52
I view sidechains as a way to test stuff and for low value transactions.
@_date: 2015-12-29 10:40:23
Consensus rules aren't altered through proof-of-stake.
@_date: 2015-12-31 02:15:10
Are the two sides symmetrical? Not all transactions will use SW.
@_date: 2015-12-30 13:13:44
Peter, from what I see the code sends the same blocks to new and old clients which means that old ones will calculate the merkle root incorrectly. It that correct?
@_date: 2015-12-19 18:20:59
The flag day of the present proposal is too soon but a hard fork would be a good opportunity to fix things like sigop counting or the retargeting algorithm.
@_date: 2015-12-02 09:33:56
It's sad that this misinformation is being spread. Unfortunately it is reinforced by the fact that miners vote for soft forks. But no, miners don't decide for hard forks. Even if 99% of miners leave and mine an altcoin the remaining users will be able to mine Bitcoin, even at loss.
The definition of the Bitcoin block chain is the longest *valid* chain. This is not the case with SPV clients since they don't validate, which is why it is important that the economic majority runs full nodes.
I will protest only against proposals which remove my ability to protest. Currently this is only BIP101.
@_date: 2015-12-19 17:44:23
Everyone since Bitcoin's security relies on being able to spread new blocks quickly.
@_date: 2015-12-28 17:36:57
Upvoted for the entertainment value.
@_date: 2015-12-30 22:49:52
This would be a hard fork which would defeat the whole purpose of the proposal. Let's assume a SimpleCoin where transactions have only one input:
Transaction | Input
A | * 
B | A
C | B
D | C
If you try to post only A and D to the legacy chain, D will be invalid since old nodes don't know about C.
LN does what you want via a network of payment channels. See [my explanation](
@_date: 2015-12-28 21:45:22
Tell that to the spammers not me.
@_date: 2015-12-16 15:52:30
I don't remember devs saying that Bitcoin is good for everything so it is not even unethical.
@_date: 2015-12-17 14:49:35
Why would it? Ever heard of meritocracy?
@_date: 2015-12-28 09:22:43
Also they could just fill it with "OP_RETURN data".
@_date: 2015-12-30 21:34:02
Read the second sentence maybe?
@_date: 2015-12-29 23:49:37
In what way is a hard fork segwit cleaner?
@_date: 2015-12-12 17:31:34
Is the `&lt;hash&gt; OP_TRUE` method likely to be used or would it be like `&lt;hash&gt; OP_CHECKSEGWITVERIFY OP_TRUE`? The later seems to be less ugly. Either way why would `OP_TRUE`be needed? `&lt;hash&gt;` is considered to be true anyway.
@_date: 2015-12-31 00:03:48
A hard fork segwit [isn't really cleaner](
@_date: 2015-12-30 12:52:40


Transactions need to reference UTXOs. You can't trick nodes into accepting transactions spending UTXOs they don't know about.
@_date: 2015-12-16 16:34:43
Yeah, the free market will definitely preserve forests. All those laws are useless. /s
@_date: 2015-12-18 18:19:14
Great! With this proposal the cost of running a full node might eventually decrease.
@_date: 2015-12-29 01:59:33
Mostly UTXO set polution, to less extend OP_RETURN misuse. Spamming the UTXO set shouldn't be cheap for security reasons and in the future a limit should revolve around that.
@_date: 2015-12-29 12:09:12
Mostly because the "community" is unable to do shit.
@_date: 2015-12-29 19:28:13


I'm developing one in my spare time.


Windows has Remote Desktop preinstalled. For all OSs you can use VNC.
@_date: 2015-12-23 14:28:00
Consensus means that there are no significant objecting **arguments**. The "community" apparently doesn't have good arguments.
@_date: 2015-12-14 11:10:24
The timestamp of each block is allowed to be up to two hours ahead of the present time.
@_date: 2015-12-14 08:43:18
That's the price for decentralization.
@_date: 2015-12-29 02:02:02
Why the sarcasm? Bitcoin is inherently meritocratic/capitalistic. The masses are just noise.
@_date: 2015-12-16 13:10:26
While having 50% of the Bitcoin hashrate would be difficult we are talking about the hashrate of each sidechain individually. Also the reason entities are not trying to attack Bitcoin is that there is so little to gain; at worst they can reverse *their own* transactions (assuming that the economic majority runs full nodes). With sidechain SPV proofs an attacker can actually steal coins.
@_date: 2015-12-28 21:44:15
If Bitcoin centralizes the exact opposite will happen. Why would the new payment processors operate for less revenue than systems relying more on trust?
@_date: 2015-12-19 17:47:10
I didn't say that 2MB will damage the network. Neither did anyone else AFAIK.
@_date: 2015-12-29 16:15:43
@_date: 2015-12-31 01:56:15
Apart from less code to be written soft fork SW requires no modifications if you don't intend to use it.


Except it wouldn't.
@_date: 2015-12-30 21:45:39
Adam Back proposed extension blocks a few months ago and that isn't even the first idea.
If we are going to effectively increase the block size limit (i.e. not only the scriptsig like SW) it is preferable to do it in a hard fork because:
* If it's controversial it shouldn't be done anyway.
* If it's not a hard fork should be fine and a soft fork offers no advantage.
Let's not pretend that a soft fork is good for all things.
@_date: 2015-12-12 19:32:46
Why would the average Joe want to use Bitcoin in its present state?
@_date: 2015-12-29 16:23:58
Personally I'm fine with non-currency use of the blockchain and in fact have increased the maximum OP_RETURN data size on my node. I expect users to use efficient protocols though. Timestamping every separate trade is excessive; merkle trees are trivial to implement.


The problem is that a the size is not the major cost. In the future we will need to replace the block size limit with a limit on actual resource usage; mostly to limit the growth of the UTXO set.
@_date: 2015-12-30 12:34:16
But then other transactions will have to be transported separately. This isn't coded yet.
Edit: or at least transport different blocks based on protocol version.
@_date: 2015-12-19 17:08:56
Actually it is Gavin who looks stupid.
@_date: 2015-12-30 23:30:44
This scales worse than plain blockchain. See my other reply.
@_date: 2015-12-16 15:31:37
Bitcoin full nodes are SPV clients of each sidechain otherwise they would need to process the blockchains of all sidechains.
SPV clients blindly trust miners.
@_date: 2015-12-21 12:25:04
Discouraging mindless upvoting.
@_date: 2015-12-02 04:33:35
Of course Bitcoin was supposed to scale. That doesn't mean though we shouldn't do it carefully. Making decisions during a conference isn't careful.
@_date: 2015-12-23 10:00:28


Cool. Bitcoin usage is voluntary. Though with proper wallet support they might change their mind.
@_date: 2015-12-06 20:41:45
Reposted [here](
@_date: 2015-12-28 12:28:52
Or better yet, let's have a convention that if the RBF flag is set then the transaction can be modified in any way the sender wants. If receivers want the false security of trusting miners they can tell the senders to replace with final transactions when they are ready.
@_date: 2015-12-05 21:09:41
Well, some coordination is needed. After all, this is how BIP65 was released.
You could modify the block version on your own and some people do it but at some point the pool will need to start rejecting invalid shares.
@_date: 2015-12-29 17:27:30
I use Bitcoin Core as my main wallet, for P2Pool and JoinMarket. I keep some money in Mycelium for when I can't connect remotely to my home server.
@_date: 2015-12-30 22:04:02
Block explorers will continue to show the same info. Other participants need to upgrade only when they want to use SW which will likely be built in Bitcoin Core's API.
@_date: 2015-12-18 16:19:15
IBLT doesn't compress blocks; it just reduces the bandwidth needed to transmit them.
@_date: 2015-12-28 20:07:39
Consensus rules are still immutable.
@_date: 2015-12-05 16:39:15
P2Pool will need to hurry.
@_date: 2015-12-23 05:25:00
You may want to try a [program]( I made.
@_date: 2015-12-12 15:21:19
As you noted it is better to focus on the current state since technically anything could be changed in the future.
The use case is described [here](
@_date: 2015-12-19 17:21:01
Altcoins are indeed Bitcoin's competition. They are off-topic though.
@_date: 2015-12-30 00:50:28
You are assuming that we will ever reach that point. It is much more likely that (mostly) gambling sites will move off-chain reducing blockchain usage.
@_date: 2015-12-30 12:11:39
There is no indication that he intends to not have regular transactions in the main block which makes this a hard fork.
Edit: there won't be regular transactions in the main block
@_date: 2015-12-30 00:58:18


Not really, if one chain makes it pointless to use it some will never switch.
@_date: 2015-12-30 21:53:36


The whole ecosystem needs to upgrade with forced soft forks. Soft forks are prefered when a feature is optional or doesn't affect most of the ecosystem.
@_date: 2015-12-30 00:47:32
Why would miners mine on a chain almost nobody recognises?
@_date: 2015-12-20 05:44:18
It's not like people want Bitcoin to be used only as a settlement layer but evidence suggests that increasing the limit too much will damage the peer-to-peer, not decentralized, nature of the present Bitcoin. It would be great if we could have a limit above average usage and handle spikes without problems but miners will fill blocks especially when there will be no subsidy to lose.
@_date: 2015-12-28 10:01:46


The answer is that I will be running a full node with RBF enabled and there is nothing you can do about it. Your "risk assessment" has failed. Some use cases can be found [here](
@_date: 2015-12-30 00:25:14
Miners don't decide on hard forks.
@_date: 2015-12-23 17:39:24
It's not about being above others. Science is not democratic. No amount of popular support will change reality.
@_date: 2015-12-29 11:38:21
I really don't understand why some people believe that the interests of miners aren't similar to PayPal's. Miners should decide only what full nodes can't: the order of transactions. And I say this as a hobbyist miner.
@_date: 2015-12-22 04:48:15


@_date: 2015-12-16 15:41:07
Actually it is not criminal since Bitcoin Core's license explicitly states that there is no warranty whatsoever.
@_date: 2015-12-08 14:30:30
You are confused because there is no such thing as an address as the protocol is concerned. Bitcoins are sent by creating transaction outputs with a certain puzzle to prevent anauthorized spending. The puzzle/script encoded in a version 1 address doesn't contain CLTV by definition.
@_date: 2015-12-30 22:27:38
Please ping so that I can continue the discussion.
@_date: 2015-12-29 02:14:29
Nobody said that every non-programmer should be able to write wallet software.
@_date: 2015-12-06 18:16:11
misinformation is disturbing...
@_date: 2015-12-28 17:27:23
"The Real Bitcoin" is no longer the reference implementation though.
@_date: 2015-12-19 17:39:04
Bandwidth is a fixed resource for the whole network. When you have n participants the data needed to be transfered are a * n and have to be transfered b * n times. The result is O(n^2 ).
@_date: 2015-12-21 11:31:25
You mean [the original bitcoin]( was anti-bitcoin?
@_date: 2015-12-16 16:13:12
I've read it and obviously scaling needs to happen but having every full participant process all transactions has its costs.
@_date: 2015-12-12 14:50:44
It isn't possible. Otherwise the escrow applications would be broken since you could prevent spending indefinitely. Also transactions cannot be modified after they are included in a block.
@_date: 2015-12-19 17:51:20
If the growth was only for a few years it would be quite good.
@_date: 2015-12-29 10:08:28
Difficulty is stored in a header field called "bits".
Edit: Actually it is the target that is stored there in compact form hence the need for conversion.
@_date: 2015-12-30 01:02:45
It's a valid concern but what makes you think that a sensible hard forking code released yesterday would satisfy them?
@_date: 2015-12-29 16:53:17
The UTXO set is a database which ideally would fit entirely in RAM since it gets updated every block. Otherwise there is significant strain on storage media.
If users encode data in addresses and store them by sending a small amount of money without spending them they bloat the UTXO set. This has already happened with  and spam attacks. Unfortunately there is no way to detect this since it is indistinguishable from normal money transfers. If the cost of performing blockchain writes is not insignificant such uses will be discouraged.
@_date: 2015-12-28 17:29:16
Null is literally zero.
@_date: 2015-12-19 17:16:02
Not understanding the limitations of a system where every full participant has to process every transaction is not very smart.
@_date: 2015-12-31 20:25:13
Instead of redefining the meaning of a single data push couldn't they redefine a NOP to CHECKSEGWITVERIFY? P2SH is ugly already.
@_date: 2015-12-21 17:46:30
Seems fine. One of the things boost has that was added in c++11 is easier looping through lists.
@_date: 2015-12-31 00:35:20
I disagree with Gavin. With his proposal *all* clients which use the full merkle tree would need to be rewritten. This includes *stratum mining protocol* clients which are part of the firmware of miners.
@_date: 2015-12-04 14:23:41
Lighthouse has to verify if an output has been spent or not. Normally that would mean having to query your own full node so Hearn thought it was a great idea to be able to query random nodes and not being able to verify the result at all. What could go wrong? 
Anyway his proposal (getutxos) has been accepted into Bitcoin Core but was reverted because it contained a bug and since then it is only found in XT.
@_date: 2015-12-30 14:10:59
If it was possible to create a transaction spending UTXOs a node doesn't know about it would be possible to create money out of thin air.
@_date: 2015-12-25 22:52:51
I think the bitcoin ecosystem benefits from its participants not having false expectations (like 0-conf being reliable) therefore I will be upgrading to RBF.
@_date: 2015-12-29 16:13:45
Miners absolutely should set their own policies. This doesn't mean that there shouldn't be limits. Especially once the subsidy fades away the cost of adding transactions to blocks will be minimized since there will be no subsidy to lose.
@_date: 2015-12-02 18:01:00
I think this has more to do with it being a shitpost... to the point it was removed.
@_date: 2015-12-29 12:37:05
Most small block proponents don't want the limit to stay at 1MB indefinitely.
@_date: 2015-12-25 23:14:41
Ah yes, [transaction replacement]( was indeed a feature which was later removed.
@_date: 2015-12-27 20:22:20
Other than replacing transactions with low fees RBF is good for adding outputs to existing transactions before they are confirmed instead of making entirely new transactions.
@_date: 2015-12-19 18:28:35
What does this have to do with currency velocity? They would use bitcoin the currency only for transaction fees.
@_date: 2015-12-19 18:02:02
We all do stupid mistakes. That doesn't discredit past contributions.
@_date: 2017-12-20 03:28:54


Might as well use PayPal if you are going to use a centralised ledger anyway.
@_date: 2015-12-14 11:06:06
There is no guarantee that any transaction will be mined. It's entirely up to miners to choose their policy. Also Bitcoin's consensus rules don't apply to unconfirmed transactions.
@_date: 2015-12-30 00:32:21


What does it have to do with their irrelevance? If users are unable to enforce the rules they have no say in modifying the rules.
@_date: 2015-12-22 12:16:55
I wrote [this]( a few months ago but things likely have changed since then.
@_date: 2015-12-30 00:12:37
What workarounds? Merged mining was always done using the coinbase.
@_date: 2015-12-30 12:04:45
From the email:






@_date: 2015-12-16 16:28:59
AFAIK I'm only against BIP101 and schemes where the limit is increased when blocks start to be full as that is essentially no limit.
@_date: 2015-12-05 17:20:58
After activation (75%) blocks with nVersion &gt;= 4 will need to comply with the rules of BIP65. After enforcement (95%) blocks with nVersion &lt; 4 will be rejected.
@_date: 2015-12-29 16:55:25
* 
* 
@_date: 2015-12-15 11:20:02
If you specify the time in terms of block height you could lock for up to ~9500 years but this can vary greatly due to variations in hashpower.
@_date: 2017-12-20 21:29:11
The key word is eventually. So far even segwit isn't fully adopted.
@_date: 2015-12-29 10:37:28


@_date: 2015-12-21 14:02:24
As long as full RBF isn't on by default it's fine.
@_date: 2015-12-24 10:15:10
Polluting the blockchain shouldn't be cheap.
@_date: 2015-12-21 20:50:15
These arguments are pointless because if at least opt-in RBF doesn't make it into Bitcoin Core it will likely make it into Bitcoin LJR and then I and others will simply switch to that (at that point it will likely be full RBF). So relying on people not running certain software is stupid.
@_date: 2015-12-29 02:05:52
If Blockstream's interests benefit Bitcoin why not?
@_date: 2015-12-30 23:24:12
My point is that this isn't coded yet. [I know it can be done.](
@_date: 2015-12-12 09:30:22
Luke-Jr just gives more priority to reducing full node resource usage than micropayments on-chain. Also notice the date of that quote.
@_date: 2015-12-16 15:55:37
So because some miners are good it means that every miner will be?
@_date: 2015-12-12 18:24:39
While it is unlikely that the limit will stay the same the reasoning is flawed. If Bitcoin was what the average Joe wanted it to be it wouldn't exist in the first place.
@_date: 2015-12-30 00:27:07


What percentage of those run full nodes?
@_date: 2015-12-23 14:03:00
There is consensus on deploying SW.
@_date: 2015-12-21 13:07:15
It's a feature; not a bug. *Unconfirmed* transactions were always meant to be replaceable.
@_date: 2015-12-19 18:17:33
You still need to somehow get the blocks so the overall health of the network is still important.
@_date: 2015-06-22 11:25:20
Bitcoin transactions are grouped in blocks (being mined on average once every 10 minutes) which currently can be at most 1 MB in size. This is not enough for bitcoin to be used by a lot of people. The question is, how should this limit be increased. Small blocks - low number of transactions possible; too big blocks - difficult to transmit and store them.
@_date: 2015-12-19 17:09:59
What's the alternative? Core does a pretty good job.
@_date: 2015-12-20 05:18:21
The linked proposal is a block size limit increasing hard fork. While segwit could address accurate sigop counting (in its embeded scripts only) the difficulty retargeting algorithm has to be fixed with a hard fork.
@_date: 2015-12-12 15:10:04
The nLockTime field of each transaction is 4 bytes, similarly to the timestamp field of each block. Thus the maximum date that can be stored is 2106-02-07 06:28 UTC.
@_date: 2015-12-15 13:05:25
9500 years ago we wouldn't even think of such numbers :)
From the technical perspective we will need to fix the block timestamp before 2016 anyway. I would be in favour of taking one byte from the version field.
@_date: 2015-12-19 18:00:11
You might be correct but it doesn't scale linearly with the number of participants. Certainly it would be more efficient if there were only a handful of full nodes.
@_date: 2015-12-21 20:27:15
Adoption through misinformation is not a wise thing to do.
@_date: 2015-12-16 15:50:46
Offloading the costs to full node operators is not conservative.
@_date: 2015-12-29 12:34:04
If you don't want to run a full node don't run one but don't expect protocol changes that will prevent others.
@_date: 2015-12-31 02:02:17
I can create the script, the testnet P2SH address and the spending transaction but someone will need to mine such big transaction.
Edit: I can test the time locally though.
@_date: 2015-12-20 05:22:11
* It doesn't have unlimited blocksize
* Its message format is incompatible with the rest of the network (although could work with a suitable proxy)
@_date: 2015-12-08 13:55:23
CLTV is technically possible outside P2SH but sending to a version 1 address is safe.
@_date: 2015-12-30 12:19:44
~~Maybe it will work: 
It won't work since old nodes will calculate the merkle root improperly; they don't know they have to discard non-coinbase txs.
@_date: 2015-12-14 20:53:25
The scriptsig is the redeemscript + inputs but otherwise correct.
Edit: to clarify by inputs I mean of the script not the transaction, e.g. signatures.
What is signed though is the hash of the transaction with scriptsig replaced with the scriptpubkey of the previous output.
@_date: 2015-12-12 17:40:44
Thanks, glad I helped :)
@_date: 2015-12-30 21:27:10
Because that would be worse than doubling the size. There are fixed delays regardless of size.
@_date: 2015-06-29 13:32:02
Work is the amount of converted energy and it has nothing to do with time. Maybe you are thinking of power=work/time.
@_date: 2015-12-19 18:25:32
Competion is a good thing but it shouldn't disguise as being the same as Bitcoin.


Who should appoint them then?
@_date: 2015-12-13 21:59:37
@_date: 2015-12-30 23:19:25
Okay this would work but at that point you just have a limited version of LN.
@_date: 2015-12-07 21:43:12
Checking a regular expression is more computationally expensive than just the beginning of a string.
@_date: 2017-12-28 18:55:39
Oh those evil devs, god forbid they get paid for their work. /s
@_date: 2015-12-19 17:29:13
SPV users are not full participants.
@_date: 2015-12-24 21:13:22
Once better methods are implemented trivial purchases which don't need the full security of the blockchain shouldn't be processed by all full participants.
@_date: 2015-12-29 23:26:49
That would create a fork since upgraded nodes won't stop enforcing it.
@_date: 2015-06-25 20:51:40
I haven't had the chance to buy anything with btc in Cyprus. In fact even at the time of N&amp;B I saw only one advertisement in Limassol.
Thanks for the tip :)
@_date: 2015-06-26 16:16:44
Yes. You could make such script and use it as redeem script in a P2SH transaction.
@_date: 2015-12-30 01:13:23
Personally I could upgrade within days and would be fine with 2-4-8 but why do that if it's not necessary? I think it's better to try to educate users first.
@_date: 2015-12-30 22:31:20
LOL! We need to be careful of the Dark side of the Force though.
@_date: 2015-12-30 00:14:48
Eventually yes. Maybe in late 2016?
@_date: 2015-12-28 09:53:32
BU is the sure way to a few companies dictating what the limit should be. It's not like miners are using all nodes for block relay between themselves.
@_date: 2015-12-19 17:56:53
I agree about too small blocks. That's why I think the linked proposal with growth restricted to a few years would be a good compromise.
@_date: 2015-12-13 17:40:30
It's a mining pool named Discus Fish.
@_date: 2015-12-28 19:50:30
The context wasn't computing but rather statistics where null is indeed zero (like null hypothesis).
Also in computing null can be represented as a pointer to address 0 and it is perfectly possible to add one like this:
    int* i = null; i++;
@_date: 2015-12-18 23:30:15


@_date: 2015-12-30 09:10:01
There is both theoretical and practical evidence that we can't arbitrarily increase the limit.
It's more like wishful thinking with some Peter__R pseudoscience vs reality.
@_date: 2015-12-16 16:55:41
So we agree that both directions are changing things. Now the issue is how to balance the tradeoffs.
@_date: 2015-12-12 09:55:08
I already run a full node and would use LN for payments anyway so I will probably put some more bitcoin than I would normally keep and help with routing payments.
@_date: 2015-12-31 18:12:06
 and 
@_date: 2015-12-12 14:47:44
The digit on the right specifies whether you are using the CLTV option or not. The zero on the left is necessary because of a bug where OP_CHECKMULTISIG pops one more item from the stack than needed.
@_date: 2015-12-19 01:09:00
I have to disagree. Misinformed people won't suddenly disappear.
@_date: 2015-12-28 20:13:32
This is a false dichotomy; some think the limit should be what technology allows and has nothing to do with demand.
@_date: 2015-12-29 02:08:18
* Transaction timestamping is subsidized by inflation
* VC money burning processors don't count
@_date: 2015-12-30 13:44:53
Can you elaborate on what you mean?
@_date: 2015-12-22 23:08:12
I made this program to experiment with OP_CLTV and thought I would share it.
Non-Windows users could try running it with [Mono](
@_date: 2015-12-27 22:22:48
Full nodes don't choose the "resolution" of the blockchain. 
*Analogy failure*
@_date: 2015-12-25 22:58:20


No problem with that. Still gonna upgrade to RBF.
@_date: 2015-12-16 16:21:57
The issue is that the rational thing to do for the majority of miners might not be good for full node operators. Especially since it seems that most users are not interested in running nodes.
@_date: 2015-12-23 09:14:10
Correct, the Bitcoin LN will work with valid Bitcoin transactions. The X LN will work with valid X transactions.
@_date: 2015-06-27 20:38:45
@_date: 2015-12-19 19:15:07
I think it is clear that Bitcoin in its present form has a hard 1MB limit. This might change but we are not there yet.
@_date: 2015-12-16 16:38:04
What matters is your own full node. So people in developed countries should definitely be able to run a full node on a desktop computer.
@_date: 2015-12-30 21:57:20
So you are trusting miners to decide who owns what.
@_date: 2015-12-30 00:43:41


Yes, assuming these technologies work as expected and there is general agreement that we are ready for a hard fork developers can release hard forking code in late 2016.
Considering we still have quite a lot of block space left and segwit will be deployed before mid 2016 there is no urgency.
@_date: 2015-12-16 16:31:38
The purpose of the limit is to limit the resource usage of full nodes so changing it is not the status quo.
@_date: 2015-12-19 12:34:32
Rising difficulty makes it more difficult to attack. Rising block size limit makes it easier to attack.
@_date: 2015-12-01 21:08:34
Huh? RBF was first proposed in 2012. Hardly an immediate implementation.
@_date: 2015-12-30 22:00:13


But you are sending blocks which have non-coinbase transactions and old nodes will attempt to include them in the merkle root calculation.
@_date: 2015-12-22 12:48:00
I can generate one if you want. What time range are you interested in? I could also send you the C# code that gathers data from Bitcoin Core for importing in any program supporting CSV.
@_date: 2015-12-28 21:40:35
Not really; the demand for cheap data storage is potentially infinite.
@_date: 2015-12-01 21:11:56
You mean the entities which *benefit* from centralization? They can use an altcoin if they want.
@_date: 2015-12-30 11:41:43
BIP101 is based on Nielsen's law which isn't really working. BIP106 has effectively no limit.


[Circular reasoning is circular](
@_date: 2015-12-21 20:37:09
Bitcoin doesn't secure unconfirmed transactions and yet people were saying otherwise to describe transactions as instant. They do propagate almost instantly but are not secure until they have at least one confirmation.
@_date: 2015-12-01 20:46:24
Dream on.
@_date: 2015-12-12 17:11:58
The 0/1 digit is not directly related to CLTV.
The [example]( you took the scriptsig parts from contains an [`OP_IF` statement]( [0 is `OP_FALSE` and 1 is `OP_TRUE`](
Certainly there are transactions with CLTV on the testnet but I don't have one.
@_date: 2015-12-28 10:04:07
FSS RBF doesn't allow you to decrease the value of outputs (needed for adjusting the change output).
@_date: 2015-12-19 17:40:20
That XT hasn't diverged yet doesn't mean that it doesn't intend to.
@_date: 2015-12-30 23:33:10
SW has little overhead. It's role is to move the scriptsig away from the hashed fields. That's it. Increased capacity through soft fork is just a perk.
@_date: 2015-12-30 00:55:56


Science isn't really democratic.
@_date: 2015-12-19 17:12:30




Yes, big blocks could indeed kill it. Fortunately that isn't likely to happen.
@_date: 2015-12-15 12:14:48
LN won't require insurance. Stop spreading FUD.
@_date: 2015-12-28 20:29:05
Through PoS?
@_date: 2015-12-30 10:34:21
You aren't forced to use segwit. Anyway mostly exchanges which generate a lot of volume and use multisig benefit.
@_date: 2015-12-01 19:01:37
There is no way any competent developer would implement a solution just to please the uninformed while setting a system at risk.
So, no, Core won't implement any changes immediately.
@_date: 2015-12-29 02:27:05
SW doesn't reduce the costs of full nodes.
@_date: 2015-12-19 13:00:48
LN allows sending money between any participant by using multiple payment channels in between. You don't need to have payment channels with everyone.
@_date: 2015-12-28 20:30:28
I'm not talking about Coinbase users.
@_date: 2015-12-19 17:32:16
Companies not using Bitcoin as a cloud storage method is not bad news.
@_date: 2015-12-30 23:21:40
It's worse than LN actually since updated nodes will need to process both the normal transactions and the summaries.
@_date: 2015-06-25 19:10:13
You are using the Poisson distribution which models the *number* of blocks in a time interval and **not** the *time* between two consecutive blocks. Thus for one hour:
* λ=6 (average blocks per hour)
* x=3 (only 3 blocks found in that hour)
* P(x=3)=0.0892
If you want to calculate the probability of a block being found in more than 20 minutes you need to use the Exponential distribution:
* f(x)=λe^-λx (pdf)
* F(x)=1-e^-λx (cdf)
* μ=10 (mean)
* λ=1/μ=1/10=0.1
* P(x&gt;20)=1-P(x&lt;20)=1-F(20)=0.135
@_date: 2015-12-29 16:18:09
Considering that the size of the current UTXO set is less than 1 GB this doesn't seem excessive especially if there are multiple spammers i.e. users of inefficient timestamping protocols.
@_date: 2015-12-05 21:49:59
Payment channels are off-chain and yet can have the properties you enumerated.
@_date: 2015-12-12 14:40:51
The maximum is 2106-02-07 06:28 UTC.
@_date: 2015-12-05 21:21:51


@_date: 2015-12-29 11:50:34
Spamming the blockchain is not a right.
@_date: 2015-12-29 10:35:16
If we can trust miners why not get rid of mining, have them pay a membership fee to the Bitcoin Foundation and give them keys for signing blocks?
@_date: 2015-06-25 17:39:14
I first heard about Bitcoin back in summer 2013, own some and host a [full node]( I know a few people who also know about Bitcoin and some of them own some.
Unfortunately there are a lot of people here who think that Neo &amp; Bee represented Bitcoin in some way.
@_date: 2015-12-14 13:07:44
Bitcoin will not reach widespread adoption if it offers no advantage. Low costs are not feasible as centralized systems are inherently less costly.
@_date: 2018-08-01 16:56:31
The "Nobel" prize in economics is just a bank award.
@_date: 2015-12-02 04:48:48
I didn't mean XT specifically but it is an altcoin since it intends to deverge from Bitcoin when it has enough hashrate even if there is significant opposition from users.
Centralization doesn't happen after a specific size. Even now full node count is continuously decreasing so if we really want the benefits of bigger blocks we should scale in accordance with predicted technological improvements which are ~20-30% yearly bandwidth increase. Those increases aren't going to last for long either.
@_date: 2015-12-06 20:03:19
That SPV mining is not bad and your reasoning. Though to be fair it makes no difference to full node users.
@_date: 2015-12-04 22:44:00
Well, to be fair, keeping BerkeleyDB instead of LevelDB would also be problematic. As for P2SH read 
@_date: 2015-12-30 11:37:32
What if a transaction in the main block spends an output which appeared in an extension block?
@_date: 2015-12-30 18:02:07
Transaction D spends C's output which old nodes don't know about. You can't change a transaction after it is included in a block to reference A's output instead.
@_date: 2018-05-20 21:46:40
If you need to protect yourself from a government which is supposed to represent you then the problem seems to be mostly in the ability of the populace to elect representatives.
Not surprising given the state of public education in the US.
@_date: 2018-05-20 21:51:24
Your lack of quality schooling is showing.
@_date: 2018-05-13 23:19:01
The average block size is under 1MB even though there are a lot of blocks above 1MB.
See 
It seems to be a result of more efficient block space utilization since a lot of blocks could be bigger if there was enough demand.
@_date: 2018-05-09 19:45:18
Also a block hashing algorithm change is one of the few hard forks that SPV nodes can't be fooled into following.
@_date: 2018-05-21 09:44:09
That's one option I guess. I will stick to civilized Europe though.
@_date: 2014-12-01 13:33:03
No, private keys are much longer than the average password and are used to cryptographically verify that you own a Bitcoin address so that you can spend the coins sent to that address. Your password encrypts your private keys so that if someone gets access to your wallet file (s)he will not be able to spend your money.
@_date: 2015-12-19 16:04:06




@_date: 2015-12-28 21:47:33
What centralized systems can handle is quite different from what decentralized can.
@_date: 2015-12-30 00:17:38


Yeah, you have no idea what you are talking about.
@_date: 2014-10-14 17:13:20
[CodeCademy]( is a good website for learning basic programming. After you learn the basics you could buy a book from the Head First series; there are books for a lot of programming languages. When you understand really what programming is all about research Web APIs and you will be able to use one from blockchain.info or directly connecting to Bitcoin Core.
@_date: 2015-12-28 10:12:22
Well, I suppose you could configure **git** to create .vpatch files and the mailing list is essentially a **hub** for patches so...
@_date: 2015-12-28 20:09:50
Yeah, keep telling yourself that Bitcoin users actually want a significant limit increase.
@_date: 2015-12-28 15:08:19
If miners stop enforcing soft forks their blocks **will** be ignored assuming the economic majority upgrades to software which enforces them. This is the case with soft forks so far.
@_date: 2018-05-23 01:51:17


@_date: 2014-12-03 14:58:00


@_date: 2014-11-15 16:10:24
HD (Hierarchically Deterministic) wallets are supposed to change addresses each time one is needed. All your addresses derive from a seed value (those words that you need to write down in order to backup the wallet). The app displays a new address so that you use a new one each time you want to receive money but it is aware of all the past. This is to make it harder to link your identity to your addresses.
@_date: 2014-12-29 15:07:31
I have some questions regarding P2SH transactions. The first is: what is hashed by the OP_HASH160 opcode? Isn't the ScriptSig of the spending transaction ending with OP_VERIFY or another opcode calling it? That is, isn't the stack empty at the time OP_HASH160 is to be executed?
@_date: 2014-09-22 10:43:29
Thanks for the tip :)
@_date: 2014-12-30 07:18:19
I've read the [BIP]( and it appears that the scriptPubKey part is only executed by nodes which don't recognise that the transaction is special. That means that they don't actually execute the redeemScript.
Newer nodes first hash the redeemScript, check if the hash matches the given hash and then execute the redeemScript as if only the signatures and redeemScript existed. Note that OP_HASH160 would remove the redeemScript from the stack if executed.
@_date: 2014-12-10 19:31:31




Mostly true but there have been some bugs in the past which have been resolved without serious losses. They were regarding Bitcoin Core, the reference implementation of the protocol.






If you mean that higher Bitcoin price attracts miners or that more security would be preferable, yes. But larger transaction number doesn't require more mining.




Well, generally yes but people could still volunteer if not. When mining becomes less profitable some quit, the difficulty decreases and mining becomes profitable again.


As above if I understood correctly.


As above; not necessarily.


Again, the system is self-adjusting.




Higher usage generally correlates with higher Bitcoin price which attracts more miners. If Bitcoin grows security should not be a problem. Even now the Bitcoin network is the fastest "supercomputer" on earth because of the incentive.




Computing power relates more to the available technology than volume right now since miner fees are a small portion of the reward.
If technological advancement slows down and miner fees are the main reward source the graph should be roughly a straight line.


No, only the average work to find a block is known. Although estimates are possible considering available hardware.


The system adjusts itself so that the mining costs are slightly less than the reward since lower costs attract more miners increasing difficulty and thus increasing mining costs.
@_date: 2014-12-29 15:25:25
So the scriptPubKey just tells the client to check whether scriptSig matches the given hash and to execute only the scriptSig? Is it a code quirk?
@_date: 2015-05-23 15:07:12
transaction fees: 450 bits @_date: 2014-09-21 15:45:12
I also run a [full node]( on my home server. There are usually only two running here in Cyprus. At some point I had to put some QoS restrictions because of high bandwidth; it was probably when btcd nodes started syncing.
@_date: 2015-05-23 15:08:00
you accidentally tipped yourself
@_date: 2015-05-23 13:38:12
    block 4: handsomechandler sent werwiewas $1 previous=02f0c39e4576776a9721d0bfd85d694780a116155b85a44d131d7a41b49636aa
    solution=33
@_date: 2015-05-09 08:22:40
Bitcoin Core 0.10.x reports using BerkeleyDB. Is it used along with LevelDB and if so for what?
@_date: 2017-02-14 07:19:38
ln(2^160 )/ln(2048) ~ 15. You would probably need 16 words for a reasonable checksum. Pubkey hashes are 160 bits.
@_date: 2015-05-23 13:01:31


Hash: `02f0c39e4576776a9721d0bfd85d694780a116155b85a44d131d7a41b49636aa`
@_date: 2017-02-15 15:54:55
What about verbs?
@_date: 2014-12-03 14:43:47
And I'm pointing out that he had to spend about the same amount of computing power as the first miners. The first block meets the lowest difficulty.
I would argue that implementing the first cryptocurrency is not an average task.
@_date: 2014-12-10 13:38:03
Check Reward-Drop ETA on [Bitcoin Clock](
@_date: 2017-02-14 06:34:26
Using the same word list as mnemonic seeds you would need ~15 words to encode an address.
@_date: 2015-05-23 13:21:45
that's because reddit doesn't show newlines. try:
    block 4: handsomechandler sent shludvigsen $1 previous=010a3ed71c5800b05228e3b744a1e4c4a3b58a23a6c775c3fa499206018673e6
    solution=88888
@_date: 2014-12-03 14:27:56
Isn't that how you (usually) mine Bitcoin? If I'm not mistaken the code to generate the first block is still part of the Bitcoin Core code as a comment.
@_date: 2015-05-23 15:39:10
transaction fees should slowly replace the generation reward
@_date: 2016-03-06 12:27:32
Why would they want to implement a stupid proposal? They are trying to show why it's stupid but there is so much you can do for misinformed people.
@_date: 2016-01-09 15:00:00
Dream on.
@_date: 2016-01-08 12:33:17
Bitcoin.org admins continue to not engage in populist politics.
@_date: 2016-03-05 08:35:29
@_date: 2017-02-22 10:20:20
I'd just like to interject for a moment. What you're referring to as segwit, is in fact, block size increase/ segregated witness, or as I've recently taken to calling it, block size increase plus segregated witness. Segregated witness is not a capacity increase unto itself, but rather another free component of a fully functioning scaling solution made useful by the libsecp256k1 optimisations, layer 2 solutions and vital system components comprising a scalable payment network as defined by various BIPS.
@_date: 2016-03-26 11:24:03
Please don't use services which spam the UTXO set (one of the reasons to keep blocksize small). OP_RETURN is ok though.
@_date: 2016-01-06 18:32:55
IIRC the difficulty can go up to 4x in either direction at each retargeting.
@_date: 2016-03-17 20:11:46
Only poorly managed ones.
@_date: 2016-03-16 20:04:06
[Yeah, right...](
@_date: 2016-03-26 21:32:53
SPAM doesn't need to be malicious. Users of not optimized protocols are also harmful.
@_date: 2016-03-26 22:01:54
So that practically everyone can audit the blockchain? This ability differentiates Bitcoin from other systems.
@_date: 2016-03-19 11:09:13
Are you complaining that he is actually using Bitcoin?
@_date: 2016-03-02 03:08:38
Versionbits are not ready yet. Though they should be ready by the time segwit is.
@_date: 2015-01-05 17:39:32
Well, you may wish to post your question to or too.
@_date: 2017-02-06 20:43:58


Well, considering the whitepaper *itself* explains why fraud proofs are impossible to implement I guess this is yet another of Satoshi's mistakes.


be aware of all transactions.
@_date: 2016-03-05 18:24:33
When a transaction is evicted its hash is kept so that it is not redownloaded. Stop with the FUD.
@_date: 2016-03-17 19:05:32
Mempools don't have consensus either.
@_date: 2014-12-03 12:48:45
Actually he had to mine it and then hard code the result.
@_date: 2016-01-16 15:30:19
The problem is that they didn't ask.
Seriously if a thing like Classic passes I will crowdfund an attack to make a point. Any competent dev. could construct a long to verify transaction - do you think a malicious attacker won't?
@_date: 2016-03-26 21:09:22
Please don't disguise your ignorance as facts.
@_date: 2016-03-06 13:11:29
I'm talking about BIP 109.
@_date: 2016-03-04 23:36:04
So he is basically lying as the majority of network development happens on the Core repo.
@_date: 2015-01-05 16:34:37
In case you would like to learn about *ECDSA* read this [blog post](
Would you like though to learn how are the signatures used to ensure someone owns a bitcoin address (spend a transaction output)?
@_date: 2016-03-26 21:26:11
The fast block relay network and thin blocks are a thing.
@_date: 2016-01-15 23:09:31
It makes sense to first fix O(n^2 ) transaction validation with a soft fork (segwit) and then do a hard fork for all transactions.
Core developers are not as incompetent as the mob would be.
@_date: 2016-03-06 20:07:53
They still run full nodes though (at least they should).
@_date: 2016-03-03 18:09:52
Engineers can sometimes be stupid.
@_date: 2016-03-09 11:57:23
You are describing a relay node which doesn't actually need to be fully validating.
@_date: 2017-02-04 09:43:43
What is summed is 2^256 / target (which is directly proportional to difficulty) since the target is **lower** for more difficult blocks.
@_date: 2016-03-31 11:32:55
It depends on which version bits wannabe altcoins will choose for their hashpower majority activation.
@_date: 2016-03-05 19:13:01
Upon receiving a transactions its hash is added to the known inventory list since ever. I'm on mobile so can't link to code.
@_date: 2016-01-11 13:20:10
Are there any segnet Windows binaries or instructions on how to (cross)compile for Windows?
@_date: 2016-03-06 13:46:35
You realize neither all websites nor all torrents have to be processed by every user not wanting to trust third parties?
@_date: 2016-01-17 01:11:47
Because the ecosystem would fail to adapt quickly to the other changes needed to safely bump the blocksize. Those changes will be included in segwit so that all participants can adapt as soon as they can and after some time the plan is to do a hard fork.
@_date: 2016-01-24 21:09:40
@_date: 2016-01-05 15:02:57
Yes, I had bitcoinj in my mind. Is it still maintained by Hearn?
@_date: 2016-03-18 19:45:44


Or they would outsource it to said companies like they currently do.


We are talking about the potentially infinite demand for cheap permanent storage.


This myth has been repeated for way too long.
@_date: 2016-01-05 20:32:34
This applies mostly to large transactions. If a block has only one transaction besides the generation it will have a lot of inputs. Each input has different signature hash whose calculation scales linearly with the transaction size. But the number of inputs also scales linearly with transaction size so linear*linear=quadratic.
@_date: 2016-03-06 13:12:16
There is nothing correct in your post.
@_date: 2016-03-06 13:16:59
The popularity of Usenet should be telling.
@_date: 2016-03-05 07:39:19
What's your problem with how people spend their time? What does this have to do with technical competence?
@_date: 2016-03-17 16:22:17
Segwit itself doesn't but a new format is being worked to address the shortcomings of the base58check encoding.
@_date: 2016-01-11 14:18:45
 ?
@_date: 2016-01-09 19:09:31
[Ask F2Pool](
@_date: 2016-01-09 15:22:50


Single point of failure?


You misspelled Amazon Web Services.


You can't know because mining is anonymous if behind a pool. We do know that the public has very limited options on ASICs. Isn't this evidence that the notion of pools is meaningless?
@_date: 2016-01-16 20:24:59


@_date: 2016-03-26 18:18:41
They were not required. Transactions with high priority could get into the blockchain for free.
@_date: 2016-01-16 14:24:17


You are assuming that the reddit mob has enough technical understanding to make a well thought decision.
@_date: 2016-03-13 13:43:34
As I understand it changes to Bitcoin's consensus rules can first be tested on sidechains like they have done with relative locktime and segregated witness.
@_date: 2016-03-01 11:04:17
The point is to rate-limit transactions which appear to be spam.
@_date: 2016-03-06 20:04:57
The whitepaper was wrong from the begining - it contradicts itself.
@_date: 2016-03-26 21:35:21
I don't think there is significant support for reducing the limit which is a soft fork.
@_date: 2016-03-18 18:44:53
If you link to a binary download site and promote running forking software in production environments your post/comment will likely be deleted. Otherwise discussing changes to the protocol are fine.
@_date: 2016-03-26 22:52:28
By audit I mean being sure that my money actually exists. Why would I care about individual transactions? For individual transactions payment channels are optimal.
@_date: 2016-01-25 20:51:13
You need to increase the fee by at least the minimum relay fee which is proportional to transaction size.
@_date: 2016-03-05 19:10:54
Peers first send inv messages with transaction hashes and then nodes can request specific ones with getdata. Peers sending unsolicited tx messages are banned.
@_date: 2016-03-18 21:11:34


If all but few companies can run full nodes (let alone actively participate in the gossip network) that clearly won't be the case.


I must have missed the payment for this storage because altruism has its ends.


Tell that to all the altcoiners who have changed only a few of Bitcoin's consensus rules with no hashpower.
@_date: 2016-03-05 07:40:17
There is segwit in between.
@_date: 2016-03-11 17:38:46
Security has nothing to do with raw hashpower but whether someone malicious can outperform. If most miners leave we can change the pow algo.
@_date: 2016-03-07 20:44:49
\* compressed public keys
To save blockchain space.
@_date: 2016-01-11 23:02:25
If I send you a product are you obligated to pay? If yes, I will PM you my unique message signed with one of my Bitcoin addresses. Cost: only €10.
@_date: 2016-03-04 23:36:47
Non-existent refutation.
@_date: 2016-01-05 15:08:41
You don't need payment processors anyway.
@_date: 2016-01-09 14:54:16
What are your qualifications?
@_date: 2016-03-15 15:55:23
If you run a full node you don't need the network, i.e. random peers which you have to trust, to verify for you.
@_date: 2016-01-08 12:25:10
All of those actions were good. If Gavin hadn't abused his popularity we wouldn't be stuck with the present P2SH, which is the worst of all implementations proposed. Good thing is that SW replicates its functionality in a better way.
@_date: 2016-03-11 17:58:16
It's certainly better to have miners on-board but them not cooperating is an attack.
@_date: 2016-03-11 15:01:26
Miners can't increase the blocksize limit. They can create their own altcoin though.
@_date: 2016-03-07 04:40:10
We are talking about proportion of miner adoption. Assuming the sample is reasonably big (it is) the proportion is **normally** distributed. Due to this distribution the actual proportion can be less than the measured.
[We are using the Normal approximation of the Binomial distribution]
@_date: 2016-03-30 10:23:34
It will have transaction fees.
@_date: 2016-01-12 14:25:34
Not all "Bitcoin Experts" are Core devs.
Which economists are you thinking about?
@_date: 2016-01-09 16:32:29
* Their definitions of forks are accurate
* XT and Unlimited don't follow Bitcoin's consensus rules
@_date: 2016-03-16 18:39:50
Even if you just limit the number of connections their crawler may not be able to connect.
@_date: 2016-03-04 12:10:00
This has nothing to do with atomic cross-chain trading, which is described on the [wiki]( Note that the scripts are outdated now that we have CLTV.
@_date: 2016-01-08 12:44:54
Not really. This may be worse than BIP101 since miners are encouraged to form a cartel and inflate the limit at will.
@_date: 2016-01-17 14:15:50
The interesting part is this:


signature hashes
Instead of optimizing the signature verification algorithm like SegWit does Gavin introduced more limits.
@_date: 2016-03-08 20:33:45


The beauty of Bitcoin is that you have to take responsibility of your own actions.


Yeah, they should have debated the ethics of deploying incompatible improvements on a test network. /s
@_date: 2016-03-01 19:14:34
Guess we have feedback. Personally I always copy-paste the address and amount.
@_date: 2017-03-31 05:20:50
You provided the justification. Any configuration except the consensus one renders your software either an altcoin or an SPV client making configurable limits useless.
@_date: 2016-01-16 14:20:48


This is the sure way to destroy any system. If technical merit is discarded in favor of populist politics you get fiat.
@_date: 2016-01-11 21:37:20
Technically Peter hadn't paid them at all so there was nothing to steal.
@_date: 2016-03-02 18:02:29
Why? We definitely need to be ready for such situation as the hardfork would be an emergency.
@_date: 2016-03-06 13:32:36
You presented no evidence yet the burden of proof is on you.
@_date: 2016-01-17 00:28:50
At least wallets based on bitcoinj don't show them since transaction replacement was a feature of the original bitcoin software i.e. it was well known that it could be re-enabled.
@_date: 2016-03-06 06:09:35
There are 2^256 hash combinations and even more header values.
@_date: 2016-03-25 21:11:53


You may want to check the stats.
@_date: 2016-03-06 07:29:45
TIL vote bots are users.
@_date: 2016-01-17 15:11:10
@_date: 2016-01-24 21:23:28
Not the same type of DOS attack. See 
@_date: 2016-01-10 13:39:20
To some extent yes.
@_date: 2016-03-06 04:30:38
First of all, NACKs need arguments. If anybody has good arguments against a change it won't be merged until the concerns are resolved. Except when it is client specific so the maintainer can decide on his own.
Then if the community doesn't like something they can use another implementation. They shouldn't expect others to do so though.
@_date: 2016-03-15 14:27:32
[As if we haven't learnt anything in the last 4 years.](
@_date: 2016-03-05 07:59:43
There is no leadership in Bitcoin though.
@_date: 2016-03-05 00:18:22
Unfortunately there are a lot of users who oppose any fee market. Anyway devs are willing to reach compromise even if that could set a bad precedent.
@_date: 2016-01-06 18:19:05
The subsidy halves on block 420000 though.
@_date: 2016-01-09 19:26:24


@_date: 2016-01-17 01:54:09






Yes, we shouldn't ask idiots how to develop software.
@_date: 2016-03-26 15:44:23
The raw number of nodes isn't that important - it's just Sybil attack protection. What matters is your own full node.
@_date: 2016-03-04 23:12:45
Correct, but there were no arguments to refute.
@_date: 2016-03-06 13:09:44
Some of [these]( Also read [this](
@_date: 2016-01-05 11:41:50
@_date: 2016-01-24 23:21:08
I don't have an account to check but CPU/GPU mining is dead anyway.
@_date: 2016-03-01 06:18:59
If there are different policies the risk of false positives is reduced.
@_date: 2016-01-16 20:52:18
I keep reading this but this is not necessarily true. The only reason SegWit can make the block size &gt; 1MB with a soft fork is because old nodes don't see witness data. After a hard fork there won't be a need to count the sizes independently.
@_date: 2016-01-24 15:20:31
@_date: 2016-03-08 21:29:44
Interesting nonetheless.
@_date: 2016-03-13 14:44:00
There is a minimum: zero.
@_date: 2016-03-07 03:08:05
Whether you choose to believe the system creator or not you will still be wrong.
@_date: 2016-01-13 19:43:16
It's kind of pointless to use reason for defending against demagogic attacks. Demagogues appeal to the ignorance of the masses after all.
@_date: 2016-01-09 16:23:36
There is nothing to refute because you made no arguments.
@_date: 2016-01-05 15:35:21
I refuted that miners completely control the blockchain. Of course if the economic majority changes the consensus rules Bitcoin will change.
BTW changing the retargeting algorithm is on the hard fork wishlist.
@_date: 2016-01-05 15:05:05
Full nodes discard nonconforming blocks even if they have enough work. This was the case since day 0.
@_date: 2016-01-09 18:56:32
The whitepaper doesn't include a lot of things. Public keys are rarely included in transaction outputs since we have the scripting system. Also the description of difficulty as the number of required leading zero bits is disconnected from reality where we have higher precision.
On top of that the paper contradicts itself. Satoshi states that


be aware of all transactions.
But then claims that


protect against this [attacker's fabricated
transactions] would be to accept alerts from network nodes when they detect an invalid
block, prompting the user's software to download the full block and alerted transactions to
confirm the inconsistency.
You can't prove the absence of transactions which are used as inputs.
Satoshi clearly states though that the chain with most work should not be blindly trusted.
Satoshi was also incompetent in how he treated soft forks. He introduced them without notifying users and encouraged them to promptly upgrade. [When discovered one of them Satoshi told him to not inform the public](
@_date: 2016-01-01 10:50:45
If miners start attacking people should be able to resort to full nodes even if they don't do now.
@_date: 2016-03-06 12:31:05
Please don't pollute the thread with your misinformation.
@_date: 2015-05-23 15:27:08
transaction fees: 450 bits @_date: 2016-03-07 09:08:11
You may want to increase the database cache. Append dbcache=4096 or higher to bitcoin.conf
@_date: 2016-01-10 15:28:02
Why turn Bitcoin into PayPal when the latter already exists? Ah yes, Bitcoin wouldn't be a get rich quick scheme then.
@_date: 2016-01-06 22:37:20
What if bitcoind can't produce a block of size exactly 1 MB?
@_date: 2016-01-17 20:40:43
That would require two hard forks.
@_date: 2017-03-26 18:47:21
@_date: 2016-03-26 20:30:47
The block size limit is there to restrict *miners*.
@_date: 2016-01-09 19:59:54
@_date: 2016-01-09 12:42:16
Miners in China now benefit from increased block size because they have more than 50% inside the GFW.
Also the notion of miners and pools becomes the same when the majority of hashrate is controlled by the owners of the pools/ ASIC manufacturers.
@_date: 2016-01-11 22:32:24
The analogy would be that Peter added a product to his cart, Amazon considered that a payment but Peter didn't proceed to checkout.
@_date: 2016-01-24 11:56:31
Who said that?
@_date: 2016-03-19 12:30:26
These are ways to pretend you are using Bitcoin.
@_date: 2016-01-09 19:22:51
@_date: 2016-01-08 13:49:51
Users == full node operators.
@_date: 2016-03-07 17:50:01
Nothing, it just happened that I commented on that thread.
@_date: 2016-03-09 07:30:45
Yes, a full [validation] node.
@_date: 2016-03-25 18:47:46


They have more experts?
@_date: 2016-03-06 12:54:47
People who have the alert keys can also disable the alert system.
@_date: 2016-03-19 11:27:34
It they revolt we will fire them.
@_date: 2016-01-08 13:53:10
Increased difficulty makes it more difficult to attack but increased block size limit has the opposite effect.
@_date: 2016-03-08 17:32:18
The author of the summary is David Harding  @_date: 2016-03-05 07:44:08
* luke-jr's fork
* Peter Todd's RBF patches
* btcdrak's addrindex patches
* statoshi
* btcd
Hardly a single team.
@_date: 2016-01-15 21:56:31
@_date: 2016-01-23 15:38:51
Ο Αντονόπουλος όμως δεν εκφράζει τη δική του άποψη με βάση τις αντιθετικές. Απλώς λέει ότι τις υποστηρίζει όλες.
@_date: 2016-01-10 13:30:43
BU has SPV security.
@_date: 2016-01-08 12:31:24
To some extent yes. There are also "firm forks" but my opinion is that those should be avoided.
@_date: 2016-01-11 22:02:32
He did if they improperly considered unconfirmed transactions a payment.
@_date: 2016-01-17 20:50:57
From what I understand yes.
It would be a developer's dream to have two chances to reduce the length of the [Hardfork Whishlist]( But the risk is high enough with a single hardfork.
SegWit cleanup is planned anyway.
@_date: 2017-03-27 21:55:55
"Magic numbers“ are necessary because a program can't know the cost of running a full node, which is a major parameter. 17% was derived from empirical data of bandwidth growth.
@_date: 2016-03-18 18:10:07
Capacity is 1MB/10minutes. Peak demand may be higher but currently that's not a problem.
@_date: 2016-01-09 13:10:05
"simple" and "hard fork" should never be in the same sentence.
@_date: 2016-01-05 14:45:53
*You* are misinformed. Start from the Bitcoin Wiki and stackexchange.
@_date: 2016-01-24 09:44:09
Before 2014 they were fairly frequent since otherwise no pool was privilaged (other than payout variance which is insignificant above maybe 5% share).
@_date: 2016-03-18 20:55:46
You still have to download and process all transactions.
Edit about storage: just because I could technically give away a portion of my hard disk doesn't mean I want to.
@_date: 2016-01-09 16:29:29
While Coinbase alone shouldn't be removed I think all custodial wallets should be.
@_date: 2016-01-09 19:18:26
Probably for brigading.
@_date: 2016-01-25 14:15:49
Confidential Transactions aren't implemented in 0.12. Then again you are either a troll, an idiot or both.
@_date: 2017-03-12 21:21:55


Full nodes offer the ultimate protection since they can fire the miners at will, either one block at a time or by punishing all (current) miners at once by changing the proof of work method.
@_date: 2016-01-05 21:04:01
If these fields change the signature hash also changes for each input, therefore O(n^2 ).
@_date: 2016-03-26 21:24:40
I don't generally believe in conspiracy hypotheses but if you want to just don't disguise them as facts.
@_date: 2016-01-23 12:57:30
Δεν είναι λογικό να υποστηρίζεις αντίθετες απόψεις - έτσι κάνουν οι δημαγωγοί.
@_date: 2016-01-24 15:52:26
Can't there be more than one null-data outputs?
@_date: 2016-01-29 22:38:11
Eligius does IIRC.
@_date: 2016-01-16 14:54:32
Soft fork segwit makes more sense - I think I explained it to you before.


I agree that segwit is not about blocksize. There is no way the whole ecosystem adapts to the new hashing algorithm as soon as the reddit mob wants an increase though.
@_date: 2016-01-10 14:08:33
Core doesn't validate signatures up to the checkpoints which can be disabled for extra security.
@_date: 2016-03-18 19:09:14
Of course: if only few companies run full nodes they will be able to decide it themselves
@_date: 2016-01-24 09:00:14
It is not. It was known since quite a lot of time that IBLTs only work with common mempool policies.
@_date: 2016-03-06 19:05:04
You've got it backwards: the validity of a chain depends on the consensus rules the economic majority follows. Everything else isn't Bitcoin which is why SPV users are arguably not Bitcoin users.
@_date: 2016-01-05 20:23:14








are dependent on the particular input so the hash would need to be recalculated for each input and we are back to O(n^2 ). If we *really* need to hash these fields (we don't) it should be done once for all inputs.
(unless I misunderstood the BIP text)
@_date: 2016-01-24 15:15:39
Thankfully we have ~~Bitcoin XT~~ ~~Bitcoin Unlimited~~ Bitcoin Classic to save us! /s
@_date: 2017-03-08 06:21:05
Segwit outputs aren't anyone-can-spend from the perspective of your own upgraded full node which is all that matters.
@_date: 2016-01-05 21:24:49
I get it now, basically the data that are hashed repeatedly for each input are small compared to the whole transaction.
@_date: 2016-01-16 14:22:28


Not really, never had any problems with transactions. People should demand wallets to use sensible fees.


So is a hard fork.
@_date: 2016-01-24 11:28:09
Again the myth that the capacity can be increased by changing a constant.
@_date: 2016-01-16 15:12:55


In order to fix O(n^2 ) transaction validation transactions will have to be signed in a different way. This will be first deployed in segwit because using segwit is optional (in a soft fork).
Alternatively we could wait longer and deploy segwit for all transactions in a hard fork which would change the structure of all transactions. That would be my preference. But devs. realize that the mob will not wait and want to deploy it sooner as a soft fork.
@_date: 2016-01-24 20:45:19


By just increasing the constant the network would be opened to significant DOS risk so the network could have zero capacity for practical purposes.


By increasing capacity with technically sound solutions when needed. It could even be automated to an extent with flexcap.


By keeping capacity reasonably low and incentivising UTXO consumption using SegWit's block cost mechanism.
@_date: 2016-03-18 17:40:06
Discussion yes, like for all other proposals. Promotion of binaries will likely be deleted though.
@_date: 2016-01-09 19:39:16
They could have used SIGHASH_NONE which wouldn't have the aforementioned problem.


That's the point with changing the algo. Big transactions could be useful in the future with coinjoin and confidential transactions.
@_date: 2017-03-31 00:04:37
This isn't something that can be configured on per node basis.
@_date: 2016-01-06 18:23:32
Last time people were sending high fee transactions to reward the miner who found the first lower subsidy block. Will we do this again?
@_date: 2016-01-24 20:56:46
[SPV mining]( seems more profitable nowadays.
@_date: 2016-01-11 21:51:02
Reusable payment codes don't need any fork.
@_date: 2017-03-25 06:59:27
There is no such thing as a "from" address. First learn about Bitcoin and then try to write programs for it. The Bitcoin Wiki is a good start.
@_date: 2016-01-17 13:20:36
@_date: 2017-03-31 08:00:38
Of course it doesn't. What matters is the reality which is compatible with what I wrote.
@_date: 2017-03-19 07:50:57
Miners don't ignore anything. Edit: And your comment doesn't really explain what segwit is.
@_date: 2016-03-11 20:43:22
@_date: 2016-03-16 11:44:55
Other than their product having nothing to do with Bitcoin it is only "useful" as a toy.
@_date: 2017-03-09 16:57:29
P2SH wasn't non-controversial at all.
@_date: 2016-01-05 21:08:14
@_date: 2016-01-12 17:53:43
Sounds like you are the problem.
@_date: 2016-01-05 21:22:12
Ah okay, basically the data that are hashed repeatedly for each input are small compared to the whole transaction.
@_date: 2016-01-09 14:56:45


Only if Hearn's FUD was correct.
@_date: 2016-03-01 11:03:12
So what is it?
@_date: 2016-01-27 13:45:56
When they will be ready is unknown since they are still researched.
@_date: 2016-01-29 14:48:10


No, it doesn't.
@_date: 2016-03-02 04:02:18
If a portion of the hashpower doesn't include certain transactions in their blocks those transactions are rate-limited; not stopped due to the censorship-resistant nature of the network.
@_date: 2016-01-04 11:00:53
@_date: 2016-01-11 16:47:43
@_date: 2016-01-05 20:51:34
    ss &lt;&lt; txTo.vin[nIn].prevout;
    ss &lt;&lt; static_cast&lt;const CScriptBase&amp;&gt;(scriptCode);
    ss &lt;&lt; amount;
    ss &lt;&lt; txTo.vin[nIn].nSequence;
Doesn't seem to be the case.
@_date: 2016-01-11 21:34:49


Keep telling yourself that.
@_date: 2016-01-09 15:39:37


Yes, which is why Core plans to do a block size limit hard fork but after improvements in block relay are deployed. would be pissed if they did a hard fork without increasing the limit.
@_date: 2016-01-15 22:17:52
[Why would they scam their costumers?](
@_date: 2016-01-01 22:13:42
In the background it will use satoshis just like bitcoin but wallets can use whatever they want.
@_date: 2016-01-09 21:09:31
1. Construct the link according to [BIP 21](
2. Encode in qr code with a tool like  (type must be url)
3. Add a small image in the middle (optional)
@_date: 2016-01-10 13:29:52
 is a good article about the technical change.
@_date: 2016-03-06 13:30:20
Almost nobody uses Usenet because:
* access is expensive
* content can be censored
OTOH almost everyone can host a website or a torrent.
@_date: 2016-03-18 06:59:05
It is case sensitive. Personally I don't like the current proposal though.
@_date: 2016-01-10 14:52:31
@_date: 2016-01-17 16:34:37
didn't need RBF...
@_date: 2016-03-26 21:10:20
I hope you forgot this: /s
@_date: 2016-01-10 14:52:04
Antonopoulos again demonstrates his lack of technical knowledge.
SIGHASH_ANYONECANPAY is a way to sign transactions so that *anyone can add inputs*. Old nodes receiving SegWit transactions will think they are "anyone can spend". They won't know there even needs to be a signature so no "blank signature" is needed.
@_date: 2017-03-17 13:47:44


This is already fixed in SegWit.
@_date: 2016-01-05 14:49:52
If most nodes don't upgrade how will SPV users sync to ForkedBitcoin? The seeds could even exclude nodes not following the Bitcoin blockchain.
@_date: 2017-03-26 07:59:31
If you want to signal readiness for UASF/segwit you can add `uacomment=UASF-Segwit` to bitcoin.conf and your User Agent will look like `/Satoshi:0.13.1(UASF-Segwit)/`.
@_date: 2016-03-04 22:17:09


Good, we don't need demagogues.


Ad hominem.


Good, no need for pseudoscientists.


See: pseudoscience.


Yes, it's basic CS knowledge that broadcast networks don't scale.


That's not what they are arguing - they are just unwilling to do hard forks as a form of bail-outs.
@_date: 2016-01-10 15:29:07
Blockchain.info shouldn't be used at all.
@_date: 2016-01-24 08:22:13
Say goodbye to the argument that miners will limit the size of their blocks because of stale risks.
@_date: 2016-01-06 23:01:43
If the poolserver wants to choose transactions it will need to understand confidential fees.
@_date: 2017-03-26 07:57:43
For your question  will help in understanding the fields.
Although if what you want is accepting payments I would suggest not reinventing the wheel and using something like 
@_date: 2016-03-01 05:49:19
That doesn't mean policies can't be set on individual level.
@_date: 2016-01-24 09:32:22
Those on the other hand require miner cooperation.
It's nice to have them both but we can't rely on them.
As a side note the lack of DOS between pools lately is suspicious.
@_date: 2016-01-10 17:03:34
I'm fully convinced but how are you, oh Lords, going to convince the heretics with an SPV node?
@_date: 2016-01-10 14:53:46
Checkpoints are set by core devs. They are usually round heights.
@_date: 2017-03-19 06:10:31
In that case sha-only miners will be at advantage and eventually will have the majority of hashrate according to unupgraded nodes so the soft fork will fail.
@_date: 2017-03-16 18:57:34
These technologies only work when miners aren't attacking the network.
@_date: 2016-03-11 17:36:05
There are two solutions:
* change the pow algo and make the current miners irrelevant.
* "hardfork bit" currently the MSB of the block version number cannot be 1 so by requiring it be 1 on the activation block miners need to choose explicitly which chain they will mine. They can still be harmful but not accidentally.
@_date: 2016-01-08 12:42:06
This is useless though since the limit is there to restrict *miners* so they certainly shouldn't be encouraged to form a cartel to increase it at will.
@_date: 2016-01-02 14:22:47
1. SN doesn't have commit access.
2. Such commit would be quickly reverted. You can't just modify a piece of software and expect people to run it.
@_date: 2016-01-10 16:58:36
Oh Lords, I'm sure you are our saviors but can you do something to convince our nonbelieving brethren?
@_date: 2016-03-26 21:57:48
Guess node operators disagree. It's almost as if there are multiple ways to categorize transactions.
@_date: 2016-01-07 14:13:33
The average time to find a block from any time under theoretical conditions is always 10 minutes because the Exponential is a memory-less distribution.
@_date: 2017-03-11 06:38:50


Actually just before it.
@_date: 2017-03-22 18:36:11


is not using SPV but centralized servers.
@_date: 2016-01-13 19:48:05
The thing is that while ignorant masses may be loud they don't really decide on anything. If investors can't understand it then I would argue that we don't need them.
@_date: 2016-01-16 18:46:32
Something tells me that ClassicCoiners aren't planning a soft fork...
@_date: 2016-01-28 17:41:58
Why the obsession with deploying a hard fork as soon as possible? First **properly** fix the transaction signature hashing algorithm and then deploy a block size limit increase. Introducing more limits is the wrong way to do it.
@_date: 2016-01-09 19:01:23
The fear is that an attacking miner could do that. Standard transactions according to Bitcoin Core are up to 100KB anyway.
@_date: 2016-01-09 18:30:06
The problem with increasing the limit is the [quadratic scaling of signature verification]( I think the plan is to roll SW fisrt, leave some time for the ecosystem to adapt to the new transaction hashing algorithm and then do a block size limit hard fork which changes the above for all transactions.
@_date: 2016-03-26 21:39:44
Because stale block risk isn't enough.
@_date: 2016-03-05 00:13:42
Where are those objectively good proposals that were rejected?
@_date: 2016-01-27 13:27:35
[It's already there](
@_date: 2016-01-06 21:17:56
I think a major downside is the increased complexity of poolservers.
@_date: 2016-01-16 16:32:33
It both [exists]( and is clearly [defined](
@_date: 2016-01-15 22:36:10
I wouldn't be surprised if they didn't. I don't think they are so incompetent that would release a hard forking client which would allow [serious network-wide DOS](
@_date: 2016-03-18 17:35:51


@_date: 2017-03-25 19:28:54
 and the "technical articles" in general.
@_date: 2017-03-14 03:52:19
The first version of Bitcoin had bugs which could be found whith so little testing that even developers as incompetent as BU could probably find them.
@_date: 2016-03-18 18:41:38
In no other system decentralization is desirable. Also blocks will naturally be full.
@_date: 2016-03-06 05:06:01
@_date: 2017-03-13 07:17:01
Full node user not affected!
@_date: 2016-01-11 14:59:37
That would be the worst PR move ever. Also that would actually increase the frequency of double spend attempts...
@_date: 2016-01-16 18:40:41
Actually that's not true. If miners don't agree but everyone else does the hashing algorithm can be changed and miners would become irrelevant.
@_date: 2016-01-17 14:53:41
This is what you asked since it is necessary to either limit the hashed data or optimize the signature verification algorithm. The latter is first included in segwit.
@_date: 2016-01-29 17:47:07
The masses like those who appeal to the lowest common denominator of the masses.
@_date: 2016-01-24 09:51:00
Yes. Pools were DOSing to privilage themselves.
@_date: 2016-03-31 15:22:54
Until they deverge their clients have semi-SPV security.
@_date: 2016-03-02 18:05:39
The weaker chain would probably change the hashing algorithm anyway.
@_date: 2017-03-15 13:20:18
No, running a node is not a vote. Bitcoin is not a democracy.
@_date: 2016-01-09 11:45:25
This is idiotic, you aren't forced to go fast if your car allows that but with Bitcoin that's the case.
@_date: 2017-03-15 13:35:42
That's correct.
@_date: 2017-03-19 06:32:45
Please don't mislead with your ignorance.
@_date: 2017-03-19 06:42:22
Bitcoin transactions are added to the blockchain in blocks. Blocks are currently limited to 1MB in size which limits the transaction capacity and increases fees. A way to increase the block size limit is Segwit. Segwit replaces the size limit with a "weight" limit; different weight is assigned to different parts of each transaction according to how difficult it is to validate each part. The calculation of the weight and the maximum weight of a block was programmed such that full nodes which don't upgrade can still follow the blockchain. This makes it safer than an upgrade which requires everyone to upgrade.
@_date: 2016-01-04 19:21:41
@_date: 2019-03-11 14:41:40
There is no such thing as an address as far as the protocol is concerned. Addresses are just for humans.
So the nodes won't reject your transaction because they don't know about the checksum in the first place.
@_date: 2016-01-19 21:24:55
This should be used only as defence against miners.
@_date: 2016-01-15 22:06:05
Does Bitcoin Classic solve O(N^2 ) transaction validation without Gavin's idiotic transaction size cap?
If you prefer the simple solution be prepared for some nice long to verify transactions.
@_date: 2017-03-17 17:33:46


To be fair there is some truth in this. From the POV of a spammer segwit offers very little additional capacity since the capacity of *outputs* is not directly affected by segwit. A spammer is mostly interested in creating a lot of outputs but not necessarily spending them while a legitimate user's transaction will have roughly the same number of inputs and outputs. Edit: In fact entities who receive a lot of payments and consolidate them will benefit even more.
Since spam is used as a tool to justify hard forking it is reasonable that hard fork proponents will be opposed to something which makes spam less relevant.
@_date: 2017-03-23 04:19:35
If you don't know where to start you probably shouldn't. There are a lot of details in the protocol whose "documentation" is forum/ mailing list posts.
@_date: 2016-01-09 15:02:51
Isn't that what's happening with IPv6? Why would you deploy such big change, and mind that you can run both IP versions in parallel, if there was no shortage of IP addresses?
@_date: 2016-06-12 11:18:03
Not really, physically transporting the bills is.
@_date: 2016-06-22 15:05:52
This doesn't improve block propagation between *miners*. Also it doesn't affect downloading historical blocks.
@_date: 2016-06-27 16:51:01


With the discount given to witness data that would be too much.
@_date: 2016-06-14 13:35:08
* millibitcoin
* microbitcoin
How is that difficult to pronounce?
@_date: 2016-01-13 20:03:42
From the point of the 50-btc-coiners miners are stupid for not claiming 25 BTC as part of the reward. They have voluntarily degraded to SPV security.
@_date: 2016-06-20 13:02:13
I'm not talking about the block header version.
@_date: 2016-06-22 17:17:55
You can also use [CLTV]( and specify the exact timestamp.
@_date: 2016-06-12 11:17:11
If you are willing to wait as much as you would wait with Western Union $0.01 will suffice.
@_date: 2016-06-30 07:32:01
You are right, the average person doesn't need Bitcoin. Neither Tor, PGP or Linux.
@_date: 2016-06-08 21:40:48


Because doing a hard fork just for a blocksze increase is a lost opportunity. 
@_date: 2016-06-22 15:12:15
Miners are already using the Bitcoin Relay Network which is specifically designed to be used by miners. It's certainly better to have an alternative if the BRN isn't available but BRN is the best we currently have.
@_date: 2016-06-29 22:00:27
Satoshi's bitcoins are spread over a lot of addresses.
@_date: 2016-06-12 11:21:49
Resend the same transaction during a period with less demand.
@_date: 2017-01-29 18:56:57


1 MB it is then...
@_date: 2017-01-08 10:43:39
Why would I want people who don't even have **basic** understanding of maths/science to use Bitcoin?
 - I think this can be applied to scientific illiteracy as well.
@_date: 2016-06-18 08:27:56
Of course ownership is dictated by consensus. If there is consensus that your coins are worthless that's what they are. It doesn't matter how hard you believe they are worth something.
@_date: 2016-06-22 12:03:07
In the case of centralized pools by "miners" we mean pool operators and people who own hardware are called "hashers". Mining requires making your own blocks.
@_date: 2016-06-22 15:23:19
Of course having Compact Blocks isn't a problem. The point is that they improve the *worst case* which isn't enough to significantly improve scalability.
@_date: 2016-06-10 09:37:59
Also if the change is large enough in the original transaction one might need to add only one output.
@_date: 2016-06-05 17:55:01
Also I don't see the benefit of getting paid more than once a day on average. I mean how often do they have to pay their bills?
@_date: 2017-01-25 10:12:29
Protocol development should stay out of politics as far as possible. This isn't a democracy where the idiots get to decide.
@_date: 2016-06-12 11:19:02
That implies there is someone who decides what Bitcoin should be. There is no such person though.
@_date: 2017-01-21 19:53:26
I would like to point out that high number of sigops isn't inherently bad (there is a limit of 20000 anyway). The problem is that each sigop scales linearly with the size of the transaction which contains it. Segwit makes each new sigop ~constant-time.
@_date: 2017-01-28 04:53:48
Yes, that's what I meant.
@_date: 2017-01-21 10:38:20
Well, supporting Trump is indeed worrying.
Also you might be supporting Core for the wrong reasons. Reason and evidence should be everyone's priority.
@_date: 2017-01-16 04:16:13
It is also a misconception that it moves the data elsewhere. Instead a portion of each transaction can be stripped when sending to older nodes such that they can still validate them.
@_date: 2017-01-27 15:55:45


Actually I would prefer Luke to not waste time on polluting the bips repo with idiotic proposals.
@_date: 2016-06-21 18:19:16
It is available through the GUI of Core.
@_date: 2016-06-16 04:55:02
Miners don't vote.
@_date: 2017-01-08 13:41:09
@_date: 2017-01-29 13:03:30
If you are too incompetent to judge the facts on your own you may have to trust the experts. It's not the ideal situation, but convincing you to stop using Bitcoin might be difficult.
@_date: 2017-01-16 04:27:24
Currently you are in the "anger" phase. Hopefully soon enough you will transition to the "acceptance" phase of your own incompetence and wrong expectations.
@_date: 2017-01-09 06:17:01
Eligius supports getblocktemplate so I suppose miners can signal whatever they want.  @_date: 2016-06-27 22:30:00
Fixing the retargeting algorithm would be fairly uncontroversial (one would hope)
@_date: 2017-01-29 08:03:12


The sooner we get rid of incompetent people/businesses the better.
@_date: 2017-08-27 16:01:11
No. Jtoomim's fork is.
@_date: 2016-06-30 00:35:56


Stop blaming others for your inability to understand arguments.
Edit: For other readers:
Exchanging refund addresses at the time of the payment is fundamentally broken since there is no guarantee that the user will be actively monitoring or even having the private key to that address at a later time. Also it introduces unnecessary gaps for deterministic wallets. This functionality can be implemented using more traditional forms of communication *only when a refund address is needed*.
@_date: 2017-01-21 17:59:12
They can't understand full transactions but they never receive them; instead only the portion which they understand is sent to them. That doesn't change the fact that a block containing transactions with stripped witnesses is considered invalid by upgraded nodes therefore witness data count towards the size of the block. Therefore a block under segwit *can* be larger than MB.
@_date: 2017-01-21 19:57:45
Because the extra data are not sent to **old** nodes.
@_date: 2017-01-29 08:11:47


Not listening to incompetent people is not exactly banning...
@_date: 2017-08-20 21:46:50
What is preventing a user running my code with btc1?
@_date: 2016-06-03 07:59:19
Simply send your transactions with higher fee.
@_date: 2016-01-10 18:40:42
@_date: 2017-01-21 19:28:16
Of course not; otherwise there would be no change to the consensus rules. In a hardfork OTOH an unupgraded node cannot validate anything at all since it can't keep up with new blocks.
@_date: 2017-01-29 09:12:18
Even if that was true, since when is truth determined by popular vote?
@_date: 2017-01-16 08:02:50
I know you can get negative balance if you withdraw everything since the fee isn't subtracted from the amount sent. 0.23 is much larger than a typical fee though...
@_date: 2017-01-21 18:45:00
They will be validating what they can validate (since they don't see the witnesses) e.g. that no bitcoins were created out of thin air.
All of this is true for all softforks. A successful softfork is still backed by the upgraded full nodes of the economic majority. What makes them different from hardforks is that the economic **minority** can continue to use Bitcoin without upgrading.
@_date: 2017-01-08 11:03:28




Is this medieval times all over again? We are talking about things children learn in primary school.
@_date: 2016-06-07 09:24:44
Hand waving and GIF creation.
@_date: 2017-08-20 20:48:46
2x is the hard fork not the other way around. If users wish to follow a chain which doesn't have consensus as being compatible with the one they were previously mining they have to make a direct decision.
While 2x has majority hashrate non-binding support so had BU and it failed.
@_date: 2017-08-07 08:07:43
Like with ETH/ETC?
@_date: 2017-01-21 20:13:27
No because the definition of the txids (which are committed to the header by a Merkle tree root) remains what old nodes see. Witnesses are committed by adding a new output to the generation transaction but old nodes don't know they need to check this.
@_date: 2017-01-23 14:59:10
The change you are referring to actually *fixed* a bug.
Are you still worshiping Mircea?
@_date: 2016-06-30 00:21:03
The people who need BIP75 or BIP70 are the people who are okay with PayPal. Those people aren't the target audience of Bitcoin.
You may be right though that there aren't many people who need Bitcoin and that's fine.
You are a known troll. Anyone with the ability to use a search engine can discover your [nonsence](
@_date: 2016-06-22 15:06:14
@_date: 2017-01-21 19:36:07
A node doesn't work in isolation. If the whole ecosystem uses different consensus rules than your full node you might receive new blocks but they will be useless if the ecosystem ignores them. Essentially your full node can't validate the blocks which are relevant to your economic activities.
@_date: 2017-08-20 21:56:35


No. It requires that P2Pool is aware of all the forks which bitcoind signals as *required*. It's not my fault that btc1 signals 2x as required when it is not. What if btc1 signals "derp1561498" as required? Should I update my code?
@_date: 2017-08-29 23:01:44
So a flawed one?
@_date: 2017-08-26 13:03:05
It won't because by that point other blocks have been mined.
@_date: 2017-08-26 13:09:30
The "official" website is p2pool.in
@_date: 2017-08-27 07:23:45
P2Pool is ready but in order for the changes to activate the majority of P2Pool miners have to update. The restriction for segwit txs can be removed manually by each miner without waiting for an official release.
@_date: 2017-01-09 06:34:41
If you are a p2pool miner consider testing my segwit PR on GitHub.
@_date: 2016-06-03 09:02:20
1. There is no such flag
2. Outputs which anyone can spend are non-standard and are not relayed by default
3. If you encapsulate the script in P2SH and spend it once to reveal the redeemscript bots will double spend the transaction (don't ask how do I know)
4. Most miners don't run these bots
5. The method I suggested worked the last halving
@_date: 2016-06-10 08:15:04
Better - maybe, efficient - definitely not.
@_date: 2017-01-16 04:31:38
Addresses do not exist at all in the protocol; it's up to the client to validate them.
@_date: 2017-01-29 08:14:28
Well, to be fair, they promote running a client which doesn't enforce all of Bitcoin's *current* consensus rules (technically called an SPV client) so I think it is quite safe to ignore them.
@_date: 2017-01-29 09:11:24
Miners can only wait for someone to show them the door... I hear Keccak won the SHA3 competition?
@_date: 2017-01-21 17:37:45
This is wrong. Segwit changes the serialization format of transactions such that they are considered valid by older nodes after a portion of them is removed. There is no separate space/ "extension block" as some people incorrectly state. @_date: 2017-01-29 08:09:09
I don't understand why people care so much about what Satoshi said. Even in his whitepaper he proposes a system (light clients accepting alerts) as a scalability measure which is impossible to implement according to what he wrote a few paragraphs earlier (that the only way to know whether a transaction exists or not is to be aware of all transactions).
@_date: 2017-01-16 07:46:35
Well, if meaningless buzzwords are your thing...
@_date: 2017-01-16 12:34:15
0.0001 btc fee transactions are not refused. Your transaction was probably large and had too low fee to size (in bytes) ratio so it was deemed worthless since probably no one would bother to mine it.
@_date: 2017-01-21 18:46:32
This isn't a feature of a bitcoin(fiat)-denominated bank account.
@_date: 2017-08-20 20:27:49
While you allow overriding `SOFTFORKS_REQUIRED` this just asks for lazy miners to set the flag and forget about it.


This assumes miner honesty. There is nothing in your code preventing constant stuffing of fake new txns at 1MB/share.


by accepting shares no longer valid.
While some of your performance improvements are welcome they are irrelevant to the worst case scenario bandwidth usage.
@_date: 2017-01-08 08:31:38
I don't understand why do we need this. People who don't understand the S.I. notation are probably too incompetent to use Bitcoin.
@_date: 2017-08-07 06:08:42
Except that isn't happening either.
@_date: 2017-01-15 06:45:28
Yes and this is why segwit gives more weight to the outputs.
@_date: 2017-08-20 22:45:00
There is no voting in Bitcoin. This is not a democracy.
@_date: 2016-06-29 23:56:00
What makes you think we need people who want to use PayPal to be using Bitcoin?
@_date: 2017-01-16 04:21:59
It is not an altcoin if everyone considers the fork to be Bitcoin. The question is whether the clueless users/businesses left behind should be considered part of everyone. We don't consider the opinion of non Bitcoin users anyway.
@_date: 2017-08-20 21:08:12
Again, this only increases fairness when miners are honest. Giving people reasons to be dishonest is the sure way to have that.
@_date: 2017-01-21 20:06:34


This one is somewhat wrong because children are more noisy therefore cause more stress to the bus driver.
^(Hence the discount given to witnesses-backpacks.)
@_date: 2017-01-21 18:02:37
Then these people shouldn't make Bitcoin accounts at all. What benefits does their spam have if they don't get any of the benefits of Bitcoin?
@_date: 2017-01-21 19:32:15
Well, the quadratic scaling of sighash operations attack vector actually is mitigated by reducing the block size limit (actually the size limit of each transaction mostly).
@_date: 2017-08-26 10:56:44
P2Pool is "fine" in the sence that its creator finally merged my segwit PR. Unfortunately the majority of miners are on jtoomim's fork.
@_date: 2017-01-21 10:32:59
There are no two blocks. Instead certain parts of each block after segwit activates need to be stripped when sending to older nodes such that they can process it.
@_date: 2017-01-25 10:14:43
While it wasn't a main motivation behind RBF, it's great that people start to realize that there is no such thing as 0-conf security.
@_date: 2017-01-20 08:17:17
It can't even do that since the chips are provided with the precomputed midstate and assume that only the last 4 bytes of a 80 byte string can change.
@_date: 2017-01-25 15:41:18
No, it is a sign of a healthy network where there is actual demand in block space for economic activities rather than spam.
@_date: 2016-06-14 05:48:53
and I independently developed integrations; look at the PRs on GitHub.
@_date: 2017-01-16 09:58:56
The meaning of words is always determined by human consensus. This is why users shouldn't be too attached to the word "Bitcoin" as the clueless masses could decide that "Bitcoin" is some centralized system.
@_date: 2016-06-29 23:37:51
This is because there are a lot of people who want to turn Bitcoin into PayPal. But we already have PayPal so even if their use case for a payment system is valid it is irrelevant to Bitcoin.
Sorry to disappoint you but no matter how much you troll you won't become more correct.
@_date: 2016-06-22 15:35:46
Even if downloading historical blocks wasn't CPU limited in most cases you would still not benefit from Compact Blocks since the optimisation works only if you already have most transactions which obviously isn't the case for synchronising.
@_date: 2016-06-20 11:53:55
It is indeed a softfork since old nodes will still be able to follow the sharechain (until the minimum network protocol version is increased that is).
@_date: 2017-01-08 10:29:34
Understanding that you can buy a fraction of a bitcoin is literally a search engine query away. If people can't do this then they are too incompetent to use Bitcoin.
S.I. provides more than enough prefixes - like milli or micro - we don't need to invent new.
Edit: typo
@_date: 2016-06-20 13:15:46
That's what Forrest Voight (P2Pool developer) wrote.
@_date: 2016-06-20 13:25:37


This post links to the email written by him.
@_date: 2017-08-26 12:09:01
You can't mine a block with a timestamp more than 2 hours in the future (assuming bch didn't remove that check).
@_date: 2017-01-08 10:38:27
This is also the reason why kilogram is abbreviated with a small k (kg not Kg).
@_date: 2017-08-20 22:09:28






Emphasis mine.
@_date: 2017-08-20 22:24:47
BIP91 is no longer active as segwit has locked in.
@_date: 2017-08-07 13:08:49
Not at all, I'm pro-Core after all.
@_date: 2017-01-21 18:40:33
Well, it is indeed simpler to introduce new attack vectors than actual improvements.
@_date: 2017-01-30 06:52:30
A softfork is unsuccessful if the economic majority doesn't enforce it since miners aren't obliged to keep following the new rules.
In fact even if you personally don't use the new features your money can be stolen if any of your transaction's ancestors used them as they can be spent by anyone according to the economic majority (in the case of P2SH and segwit).
@_date: 2017-08-10 23:36:57
It doesn't. Segwit already delivers that. Segwit is a block size limit increase to 2MB or more.
@_date: 2017-01-25 10:26:51
Which is the optimal situation since it's a sign that people actually value what Bitcoin offers.
@_date: 2017-01-27 18:07:46
Where have you read that I am dictating what anyone should be doing?
Edit: I was referring to bips by random redditors.
@_date: 2017-08-07 06:07:12
Oh you mean Mr Bitcoin Wiki Plagiarist?
@_date: 2017-08-27 07:02:37
Because we can remove whole blocks without security degradation? The relevant parts of unspent transactions are kept in the UTXO set.
@_date: 2017-01-21 10:30:20
davout is among the idiots over at 
**tl;dr:** there are people who complain that their buggy software experiences inconsistent behavior
@_date: 2017-01-23 14:44:00


You are confusing him with the Toomim bros.
@_date: 2017-08-20 21:43:23


This assumes that the miner controls significant portion of the network's hashrate which is already problematic.
@_date: 2017-08-27 03:11:15
The pruning mode described in the whitepaper is completely unnecessary.
@_date: 2017-08-26 11:49:28
Problem is there is no "the mempool".
@_date: 2017-01-16 16:10:27
Also conspiracy theories I see...
@_date: 2016-06-14 16:40:43
Well, you can't simply omit hashing things since an attacker could trick you into downloading useless data.
On a side note, has anyone attempted to do it with unconfirmed transactions in the past?
@_date: 2017-01-21 20:32:55


means that there are multiple valid versions of each signature *which is covered by the block hash*.


refers to the problem that maleated transactions have different txids. Segwit makes txids constant by commiting witnesses (which are maleable) separately from the txids (which now cover only the portion which distinguishes what the transaction does).
@_date: 2017-01-09 06:13:46
You are right but unfortunately most users do not have the required knowledge to make an informed decision.
@_date: 2016-06-22 08:38:27
It is advisable you upgrade but you won't be forked of the network if you don't.
If you are manually creating transactions with nVersion &gt; 1 you will need to comply with the new rules regarding nSequence.
@_date: 2017-01-08 08:40:25
Delaying block size limit increases automatically drives incompetent users/businesses out of Bitcoin so there probably won't be a need to address them.
@_date: 2016-12-19 16:23:59
[Eloipool]( is a pool server not a pool.
[luke-jr used to manage eligius]
@_date: 2017-08-10 17:52:30
It will already be increased with segwit. The 2x hardfork isn't happening.
@_date: 2017-08-11 05:18:03
Yes. Some people want to do hard fork only 3 months from now to 4-8MB. "2x" is  very misleading.
@_date: 2016-12-15 05:30:32
Because the presence of the donation script in the output before the last is a p2pool consensus rule. In fact it is a consensus rule for the donation amount to be at least 1 sat (this helps identifying p2pool blocks).
@_date: 2016-12-22 18:29:07
Provide an example then.
@_date: 2017-08-10 12:45:00
PayPal has larger market share and yet we aren't concerned by it since it solves different problems than Bitcoin.
@_date: 2017-01-21 17:40:06
Probably nothing since it doesn't matter what "we" (whatever that means) *need* but what "we" *can* do.
@_date: 2017-01-16 16:16:28
The difference is that in order to use the same currency you have to follow the exact same consensus rules.
@_date: 2017-08-20 21:36:34
You **are** deciding for your users by requiring they run software which may or may not fork them off the network in 3 months unless they explicitly configure their node. My code doesn't require anything other than software which with very high certainty will be required *in a few days*.
@_date: 2017-01-21 20:14:21
"We" aren't trying to force anything, but your ignorance isn't a very good argument.
@_date: 2016-12-26 20:23:26


Which means it would be easier for someone to guess them.
@_date: 2016-12-23 13:09:21
Without a weight limit it would be possible to create a 100 MB block with most of it being witness data so by all means it is the weight limit that matters.
You are right though that by increasing the size "limit" of non-witness data spam capacity is increased which seems to be a major use-case of big blockers.
On a side note our conversation confirms that increasing capacity is unnecessary. Stupid people/ trolls shouldn't use Bitcoin.
@_date: 2017-01-21 20:01:14
While single-sig transactions aren't affected that much by segwit there is more space for them specifically because more complex transactions are more affected by it. Same goes for signature *"Schnorr"* aggregation.
@_date: 2017-08-22 14:51:31


Numerous times in fact.
@_date: 2016-11-22 13:46:16
The majority of the "Bitcoin community" doesn't run full nodes meaning that they don't benefit from Bitcoin.
That fees were in the past low was the result of offloading the costs to run the network to volunteers and subsidizing via inflation. As the network grows this no longer becomes sustainable.
@_date: 2018-10-04 12:59:11
At most `ceil(log(256^B, 58))` characters.
@_date: 2016-12-22 16:25:15
`weight = block_size + stripped_block_size * 3`
As long as `weight` is up to 4 M `stripped_block_size` is up to 1MB
@_date: 2016-11-22 10:13:30
Maybe those 20 shouldn't be using Bitcoin in the first place?
@_date: 2016-12-27 00:06:15
pdiff is pool difficulty. In the old days it used to be 1 (target 0x00000000ffffffff...ff) but nowadays pools will often refuse to offer such low difficulty work.
@_date: 2017-08-22 14:57:44
[Same with P2Pool](@_date: 2016-12-18 07:26:46
For a decentralized settlement network Bitcoin currently performs exceptionally well.
@_date: 2016-12-21 16:05:32
A block is invalid if it exceeds the weight limit (after segwit activation).
@_date: 2016-12-26 09:04:07
It's almost 2017, if you can't find this information with a search engine Bitcoin might not be for you.
I say this because if you have to trust people to give you an answer to something which was asked so many times you will (probably) never really get the benefits of a system specifically designed to replace trust with your own verification.
@_date: 2017-08-27 19:37:55
What if everyone stops using Bitcoin?
@_date: 2017-01-16 04:49:49
Well, even among bitcoin "users" a lot of people choose to use centralized wallets.
@_date: 2016-11-18 16:22:20
The whole point is that they don't have a say.
@_date: 2016-12-19 06:26:55


It allows them to ommit downloading witnesses as they can't validate them anyway.
@_date: 2016-12-13 16:34:22
Acting based on what they "feel" isn't a sign of competence.
@_date: 2017-01-21 20:26:04
Altcoins are more suited to be used as pump-and-dump schemes.
@_date: 2018-06-04 20:17:56
Unless your phone calculator can do SHA256 that won't be possible.
@_date: 2016-12-13 05:22:26
Without the malleability fix channels need to have fixed lifetime.
@_date: 2016-12-19 17:01:51
[Personal attacks]( aren't really arguments.
@_date: 2016-12-19 06:25:04
What makes you think block explorers will always be free?
@_date: 2016-12-19 13:44:02
We will lose VPS nodes but also nodes running at homes. If only VPS nodes would be affected you would be right but it is highly unlikely.
@_date: 2016-11-23 08:02:30
I'm not against raising the block size limit; segwit includes that after all.
I wouldn't mind a small amount of inflation as long as it is not bigger than the amount of coins lost.
@_date: 2016-12-13 12:28:20
I keep seeing this argument about lowering fees but it's not like centralized (SPV) servers are going to be free forever.
@_date: 2016-11-22 10:21:34
If you aren't following the protocol (i.e. not running a full node) by definition you aren't using it. There's no fallacy there.
@_date: 2017-08-26 11:08:56
The best alternative to using centralised P2Pool instances is to run your own.
@_date: 2016-11-18 19:08:09
Satoshi was also an incompetent developer (albeit with a clever idea) so I don't see why we should care what s/he "foresaw".
@_date: 2016-12-27 00:03:29
Well, it also proposes a system which is impossible to implement according to the paper itself (alerts).
@_date: 2017-08-07 06:28:02
Miners are irrelevant to hard forks.
@_date: 2016-12-19 16:30:36
Companies which oppose segwit generally are acting as middlemen so they will inevitably become irrelevant as Bitcoin's users are becoming more aware of Bitcoin's benefits. The good thing with small blocks is that those users who don't get these benefits are driven away to other systems better fit for their needs: PayPal/shitcoins.
@_date: 2016-12-19 17:26:58
Q: public key (revealed); P: ~~private key (obviously not revealed)~~ P is a point which is known in advance, k is the private key
P is theoretically *added* k times though almost always the process is optimised to "double and add".
Edit: For example we want to multiply P by 129 (10000001 in binary). Instead of repeating addition 129 times we can double P 7 times and then add P once.
@_date: 2018-06-09 12:06:15


That alone is a good reason not to promote them.
@_date: 2017-01-29 15:32:47
Miners using more restrictive rules is technically called a 51% attack. It is only a softfork if the restrictive rules are enforced by the economic majority's upgraded full nodes.
In this case the rules not enforced by the thebitcoin.foundation client (P2SH, CLTV, CSV) **are** enforced by the full node backed economic majority therefore are *consensus* rules and not simply miner preference.
@_date: 2016-12-19 18:14:23


@_date: 2016-12-19 16:51:21
I don't know though IIRC F2Pool uses a fork of Luke's [BFGminer]( (I remember that from the  time of BIP66 activation when devs had to reach to them to fix their broken SPV mining code ^(no wonder the most incompetent pools promote big blocks)).
@_date: 2016-12-19 06:31:02
Do you have any evidence for this claim?
@_date: 2016-12-27 01:01:39
This is not the system proposed by the paper.
@_date: 2016-12-10 00:05:28


How do you check it?
@_date: 2016-12-19 20:10:17
SegWit removes the max block size parameter...
@_date: 2018-06-16 23:00:08
Some more stats: 
@_date: 2016-12-19 17:06:16
GPL requires publishing modifications (unless modified for personal use).
F2Pool is not the only one either in this space; Antminer violated cgminer's license.
@_date: 2018-06-09 12:09:25
Plus it's mostly a meaningless buzzword.
@_date: 2016-12-26 17:01:20
bdiff is the difficulty calculated from the target (encoded in Bits) which is compared to the block header hash, the target which matters in terms of consensus. Note that bdiff isn't actually used, only the target.
Since pools aren't constrained by the limited precision of the Bits field they use non-truncated targets e.g. they set diff. 1 shares to 0x00000000ffffffff...ff (2^256 / 2^32 - 1) instead of 0x00000000ffffff0000...00.
@_date: 2016-11-23 08:25:32
The whitepaper doesn't mention the block size limit so you are wrong. Anyway the whitepaper is wrong about a lot of things.
@_date: 2016-12-26 19:00:27
It's great to get the general idea but it definitely doesn't describe the system accurately.
@_date: 2017-08-22 00:09:56
The version you get is the latest tag by forrestv. Since I'm not him the version you get is wrong.
@_date: 2016-12-16 19:54:15
While activation happens based on what miners signal it is important to realize that they do not decide whether it will be activated.
The reason softforks are useful is because they do not require everyone to upgrade. That doesn't mean that the economic majority backed by full nodes can't activate it on itself. In fact there will be 100% miner support in such case since those not following the new rules, by definition, will not be bitcoin miners.
In terms of what an unupgraded node sees a softfork and a 51% attack are identical. The difference is precisely in whether the new rules are enforced by the economic majority backed by full nodes.
@_date: 2018-06-11 22:43:11
Neither Coinbase nor BitPay implement multisig arbitration.
@_date: 2016-12-22 05:51:27
For new nodes but older ones don't receive the full block.
@_date: 2016-11-03 09:52:43
Its output value would be the sum of transaction fees.
@_date: 2016-12-22 08:24:33
We are both right: due to the way the weight is calculated it is impossible for the data without witness to be more than 1MB, therefore a softfork. Since witness data do not contribute to UTXO bloat the network is protected to the extend it is now.
@_date: 2018-06-09 12:03:49


If anything Coinbase is not reputable. They lost they reputation after supporting attacks on Bitcoin and through their sheer incompetence. They were largely responsible for high fees because of their inefficient use of block space.
@_date: 2016-12-21 09:26:28
That there exists an upper block size because of the weight limit is irrelevant; even without any limits blocks can't be larger than 2 GB because of the way the size is stored (4 byte integer).
In fact transaction selection is optimized for weight and not size.
@_date: 2016-12-16 20:42:04


I explained why it is economic actors (and their nodes) which matter in the end. The miners are there for our convenience (I have a few hashing machines myself though).
@_date: 2016-12-14 17:01:59
Only compromised devs would do that.
@_date: 2016-12-13 16:59:58
Well, they would still be wrong.
@_date: 2016-12-19 18:13:40
It is: that's what all unupgraded software does!
@_date: 2016-12-22 09:22:41
A *part* of the block is limited to 1 MB, the part which also happens to be bloating the UTXO set. The whole block is limited by its weight.
@_date: 2016-12-20 18:38:04
Signature data are part of blocks, it's just that they need to be stripped for older nodes.
@_date: 2016-12-15 14:28:32
^^^^is ^^sarcastic
@_date: 2016-12-23 09:08:39
It is impossible to have weight &lt; 4M and stripped size &gt; 1M. Provide an example if you think otherwise.
@_date: 2017-01-08 10:48:59
Altcoins are more suited to be used as pump-and-dump schemes.
@_date: 2016-12-14 17:15:42
By default not but a miner can reserve a portion of the block for high priority transactions.
@_date: 2018-06-04 13:55:33
So don't publish you personal data on the internet in the first place?
@_date: 2016-11-04 07:59:30
Output value of 0. This can be observed in some altcoins.
@_date: 2016-12-19 16:56:55
I'm fairly certain that they are not the only ones but most pools don't advertise what software they use unless they use their own (kano - ckpool; slush; eligius). In fact F2Pool violated the GPL of Luke's software.
@_date: 2016-12-14 17:16:48
That would be a p2pool hardfork.
@_date: 2016-12-27 21:56:27
CLTV became a consensus rule specifically because the economic majority supports it; otherwise it would be a 51% attack.
@_date: 2016-12-27 08:28:59
Difficulty in general doesn't exist in terms of bitcoin consensus; only the target encoded in Bits.  @_date: 2016-12-19 16:43:17
I think that their moderate limit increases are mostly there to make it easier for them to proceed to more aggressive ones - segwit doesn't give them that chance.
Another benefit of segwit is that while it is a block size limit increase it doesn't increase the space available for (null data) outputs so it doesn't benefit the spammers.
@_date: 2016-12-26 20:28:52
There is no question: miners try to construct a block in such a way that when it goes through a (hash) function the result has certain properties. The result of that function is unpredictable.
@_date: 2016-11-23 08:33:17
I don't need credibility. Go listen to your favorite clueless celebrity if you want to.
The facts speak for themselves:
* Retargeting doesn't work like described in the whitepaper
* There is this thing called script
* **Compact** alerts are impossible to implement
@_date: 2016-12-14 16:59:33
This isn't merely signaling support, but readiness to enforce the new rules.
@_date: 2016-12-21 07:23:15
They are part of the block but not for older nodes. See the spec.
@_date: 2016-12-19 17:55:49
On top of what others said if miners decide to tighten the rules without user agreement this is technically called a 51% attack and not a softfork.
@_date: 2016-12-13 05:18:33
CSV is already activated.
@_date: 2016-12-19 16:36:07
I wouldn't call it pain in the ass, after all I patched [P2Pool]( for it. You are right though that it might take some time.
@_date: 2018-06-11 21:51:24
Bitcoin was created to bypass middlemen and that's what these companies are.
@_date: 2016-12-20 13:46:18
Max block size is replaced by max block weight which is chosen such that it remains compatible with older nodes.
@_date: 2015-08-10 19:59:48
Sorry, the quote doesn't support what you said. P2SH was a hack on top of the existing scripting system; basically it required extra validation not expressed by the script. My personal opinion is that it would have been better to redefine a nop to support the functionality, i.e. the OP_EVAL proposal, as it would be a more elegant solution.
Anyway what they are suggesting is to ditch reenabling disabled opcodes (since that would be a hard fork) and instead make a new P2SH (they are referring to it as P3SH in the mailing list) so that the disabled opcodes are only usable inside the serialized script (since that would be a soft fork).
No sidechains necessary.
Their point is that while they would be reenabling opcodes they could include some others they need for sidechains in one soft fork (P3SH).
Anyway Gregory is wrong there. The original scripting system did not allow sidechains since it is not Turing complete. Verifying a Merkle branch would require loops. This is needed to verify that a transaction is in fact in a block.
@_date: 2015-08-25 15:21:46
The paper is quite ambiguous to be fair which is why I can't wait for the implementation. Most explanations I've read describe it that way (also wrote "minimum" as further explanation in the paper).
I think the rationale is that we want the majority of miners to be happy with the limit chosen.
@_date: 2015-08-19 17:43:36


The problem is when medium priority transactions are delayed. Right now we have extra capacity so during normal network operation there are no delays. Also if there is little extra capacity the delays of low priority transactions will not be "slight".


Could you explain how IBLT would result in centralization? The idea is that every full node will relay new blocks in compact form.


Why would that be the case? By periodically informing your peers about the transactions you have they could almost immediately give you the filtered block.
@_date: 2015-08-27 10:48:06
Yes, but:
1. I don't think BIP101 will reach 75% hashrate.
2. The majority of miners can orphan any block even if it complies with rules. We don't want this outcome.
@_date: 2015-08-29 16:56:22
If there was such protocol proof-of-work would be useless.
@_date: 2015-08-28 16:08:42
Miners can already attempt to orphan any block they like. With BIP100 they can express what they are willing to accept.
@_date: 2019-02-13 17:36:19
Please understand the definition of a softfork first.
@_date: 2019-02-23 12:06:12
I made a webpage with statistics on the increased Bitcoin capacity if every transaction used SegWit: 
With the current usage patterns (i.e. the portion of transaction data which is input scripts, and block sizes) we would indeed be able to squeeze a little more than 40% extra capacity.
@_date: 2019-02-25 19:21:22
Most are not, they connect to some centralised service.
@_date: 2015-08-19 09:58:52


Mike has implemented SPV with Bloom filtering and developed the most popular java bitcoin implementation (bitcoinj). Also proposed using LevelDB instead of BerkeleyDB which could have prevented the March 2013 fork if implemented/deployed earlier.
Gavin among other things proposed and implemented P2SH as it is currently used.


Elements is centralized. Unless an implementation of a decentralized sidechain is released I won't believe this crypto snake oil sidechains are.
@_date: 2015-08-10 21:35:24


No they don't. Except if you mean &gt; What is wrong with you?
I'm continuing to respond to you...
@_date: 2015-08-29 18:18:52
If the miner didn't receive the block obviously she couldn't verify that the block is valid. I'm referring to the situation when a block could be received but because of the size the miner chose to ignore it despite being valid under the agreed consensus rules.
@_date: 2015-08-27 09:44:04
The exact implementation doesn't matter; the vote could be encoded in human readable format or as an unsigned 32 bit integer or a lot of different ways. The general idea is described in the paper and is working on an implementation.


12000 blocks.
And Bitcoin is not democracy.
@_date: 2015-08-19 10:20:19
Not employee of Blockstream but Peter Todd lives in Canada.
@_date: 2015-08-25 12:35:46
I don't think smaller miners would choose a high limit. I would be more worried that an attacker might not let the limit increase.
That being said I prefer BIP100 over other proposals.
@_date: 2015-08-25 12:32:05
I'm also waiting for the code.
@_date: 2015-08-25 09:20:45
The 32 MB limit is not related to the data type used [1]; it's just the maximum message size. AFAIK the BIP101 implementation changes that.
[1] [the size of the payload is stored using an unsigned 32 bit integer](
@_date: 2015-08-29 20:28:31
I'm talking about bandwidth (currently that is the most significant bottleneck), pruning will probably be fully functional by the time it is needed. Also HDD disk speeds aren't impressive. Today I installed a 256 GB SSD for my node (reindexing is awfully slow).
You understand that new users are more mainstream and therefore less likely to run a node? Also they need to download the blockchain from beginning. Increasing the actual block size substantially won't help them.


Exactly. They will run the node for *their* clients, not necessarily strangers ([this is already being considered](
Basically it is important to understand that full nodes don't process only their transactions but also everyone else's. This is why in the long term solutions like Lightning will be needed, while BIP101 aims at VISA level transaction volume on chain.
@_date: 2015-08-26 20:07:32
You need to download the block before validating. If the new block would consist mostly of transactions not in the mempool the time to validate could also be non negligible.
@_date: 2015-08-01 14:41:49
In this case the output script is empty so the output can be spent by supplying any data (which would count as `true`).
@_date: 2015-08-29 17:27:28
Since this is a hard fork there should be general agreement before the final miner voting occurs. Full nodes can choose to not upgrade after all.
Miners are expressing their preference. Known entities can also express their preference. As for others there is no anonymous sybil-proof way to do it. Social media can provide some info but it is not reliable.
@_date: 2015-08-29 22:55:02
I have 8 Mbps theoretical download speed but usually I can download with ~300 kB/s.
I don't quite get what you meant with the email thing. Do you send spam emails all the time or what? And most transactions from personal experience are closer to 500 bytes (Core shows you that).
We could go over 1 MB already. It's the fast growth of BIP101 that concerns me. The optical fiber thing was about the 4 GB that BIP101 ultimately can achieve.
@_date: 2015-08-31 17:19:15
The mining pool except if you are using getblocktemplate, in such case you can alter it with your mining software.
@_date: 2015-08-25 09:27:33


No because the lower (and for some reason upper) 20% are discarded before choosing the common floor.
@_date: 2015-08-19 16:52:31
It would be a good compromise if the limit increase started earlier (I would suggest April 2016) and maybe start from a little higher limit (like 1.5 MB). After all, the reason the debate is so intense despite a limit increase being suggested years ago is that if the current transaction volume trends continue we will run out of capacity.
@_date: 2015-08-27 15:30:37
It is mostly that smaller miners are protected against too big blocks (from other miners) as bandwidth is a fixed cost compared to hashrate. Also smaller miners likely will have bandwidth similar to node operators.
As for the 21% attack there are far more effective methods to cripple Bitcoin (e.g. spam attack). The proposal restricts the decrease to 2x every ~three months and in case of such attack a minimum vote can be introduced as soft fork (also compared to the limit the minimum vote can be further increased with soft forks).
@_date: 2019-02-13 16:48:44
That's a weird definition of "trust". Full nodes either ignore or enforce softforks.
@_date: 2015-08-27 10:09:15
I agree with you. I was saying that those who prefer too big blocks are likely to not consider the implications.
@_date: 2015-08-29 22:02:06
Next year the subsidy halves. It's in the best interest of miners to allow enough transactions. Transaction fees can grow up to some level but after that users will simply leave to some other system.


For an increase 80% is required. The possible problem is that 20% can lower it so it would be better if the majority was 75% or even lower.
You can't count votes of non miners in a decentralized manner but they choose which code they run. BIP100 is probably not the best system we can implement. The decision hasn't been taken yet.
@_date: 2015-08-27 21:36:19
I didn't imply there can't be. I was responding to that if Bitcoin is not broken there should be no forks.
@_date: 2019-02-13 17:37:47
Miners always had the ability to choose transactions and blocks. Softforks don't change that.
@_date: 2015-08-18 08:29:51
The limit is there mostly to protect the smaller miners so I think it is reasonable to assume that they will not agree to a large limit. This is the reason I think the veto limit is "only" 21%. I say "only" because for soft forks we want at most 5% to not agree.
@_date: 2015-08-25 15:03:09
After the two 20% are removed the lowest value is chosen (hence common floor). Not removing the upper limit will not make any difference as the 20th percentile (which is chosen) will not be above the 80th percentile.
@_date: 2015-08-10 06:47:18
With the original opcodes you can't have a sidechain (I mean with their original meaning; it is possible to redefine their meaning but this is at least a soft fork).
@_date: 2015-08-29 20:49:43
It's really more about individual users than miners who are getting paid (hence the 80% hashpower agreement to increase the limit although it probably could be lower). Still, would it be fair for a miner to produce bigger blocks than other miners are willing to accept?
But what do you prefer? A too conservative predefined limit function or to have miners who will consider what the community wants? If it is predefined it can't be optimistic for a decentralized system. While you can't trust individual miners, collectively we assume that they can be.
The miners who vote for BIP100 are aiming at 8 MB eventually either way. 2 MB for start should be enough.
@_date: 2015-08-22 12:07:04
Too bad you don't get sarcasm...
@_date: 2015-08-10 20:54:17
Reread your previous posts please. Also bolding and italicizing what you said won't make it true.
@_date: 2015-08-29 19:18:37
Why do you think 8 MB is needed now?
@_date: 2015-08-31 20:31:26
@_date: 2015-08-10 21:21:04


@_date: 2015-08-17 20:26:00
Currently the maintainers of the GitHub [repository]( are Mike Hearn and Gavin Andresen.
@_date: 2015-08-19 19:24:50


No. You would get the hashes of the transactions you already have but the full transactions that you don't.
@_date: 2015-08-06 06:42:42
This is not how programming works.
@_date: 2015-08-29 07:03:57
The percentile needs to be below the 50th so that the majority agrees with the limit. With soft forks we use 95% majority so 80% majority seems reasonable.
@_date: 2015-08-22 10:54:47
Don't be angry,  will surely release a patch in case of a fork. Am I right?
@_date: 2015-08-29 15:33:42
I expect that miners *collectively* will not raise the limit when there is no such need, for example in the case of a spam attack. BIP100 accomplishes that by changing the limit every ~three months, restricting it to 2x and requires 80% hashpower agreement. An individual miner could be tempted to do that.
Also since we can't predict long term transaction rates and technology advancements allowing participants to vote is a reasonable measure.
@_date: 2015-08-25 09:24:25
[This is not true]( The fields in the protocol can handle 4 GB blocks.
@_date: 2015-08-27 08:43:30
If you want efficiency use a centralized system. Bitcoin does not yet compete with centralized systems.


Of course they can in terms of block size. Even if the majority of nodes adopted infinite block size limit miners could soft fork to BIP100.
@_date: 2015-08-11 08:55:41
It would be better if a third party network wasn't needed. IBLT is in the works though. Also Mike Hearn is thinking how it would be possible to make a simpler optimization using the current P2P network: 
@_date: 2015-08-27 10:22:38
Basically it is more meritocracy/capitalism. Anarchism in the sense that you can run whatever code you want.
@_date: 2015-08-25 15:52:47
Also miners are mostly affected by the time needed to verify blocks. Normal nodes could wait a bit longer to verify a block.
@_date: 2015-08-29 20:03:58
We aim to reach consensus on what a valid block is. If miners are just going to follow their own unique rules we are wasting our time.
@_date: 2015-08-28 16:15:05
Of course; increasing the limit with a soft fork is impractical. We need to have a hashpower majority since blocks smaller than 1 MB are still valid after the limit is increased.
Now the interesting thing with BIP100 is that a minimum vote can be introduced as a soft fork (even multiple times).
@_date: 2015-08-25 12:26:51
Yes we would need another hard fork for that if we wanted to increase the limit that much. Another thing that needs fixing at some point is that currently timestamps are stored using 32 bit unsigned integers. The problem is that would break mining hardware since the size of the header would need to increase.
@_date: 2015-08-27 16:41:29


They increase the time needed to download/process the block compared to the fixed 10 minute average block interval.
SPV mining could probably work temporarily.
But even then I don't see why would BIP101 need to be so optimistic. It aims at VISA-level volume on chain which is a waste of bandwidth where solutions like Lightning could handle frequent low value transactions. Why would every node need to process every transaction made? Merchants likely will not want to process transactions of their competitors.
Also you don't consider that miners would have dedicated connections for mining while home and business users will want to use their connections for other things. Since 80% of hashrate would need to agree to a limit with BIP100 we can expect that non-miners will be fine (I expect the majority of hashrate to understand why decentralization of nodes is important).
@_date: 2015-08-25 12:58:34
At 500 bytes per transaction 32 MB would allow for 106 transactions per second. I wouldn't call it exactly a *tiny* fraction. Also by the time blocks larger than 32 MB are needed Lightning Network and other scalability solutions will most likely be ready. There is no reason to do simple transactions on-chain when off-chain solutions could offer reasonable security.
@_date: 2015-08-27 08:09:05
Not in this case. Small blocks are compatible with new (big block) software.
@_date: 2015-08-29 20:54:14
But the point of this debate is to NOT have huge blocks. BIP100 addresses that by requiring 80% hashpower majority to raise the limit and restricts the growth to 2x every ~three months. There are other proposals addressing that either with a different way to count votes or by having a predefined conservative growth.
@_date: 2015-08-15 19:54:44
The new block version is 20000007 in hexadecimal or 536870919 in decimal.
@_date: 2015-08-25 16:10:06
First of all I expect Lightning to be used for day to day low value transactions which would be unprofitable to try to confiscate (remember that if your counterparty tries to defraud you, you are able to take all his money locked in the channel). For higher value transactions I expect on-chain to be fine.
Also if blocks grow too big I would be surprised if node operators *didn't* start to charge for serving SPV clients. Also they can censor transactions and even hide them once they get into a block which is why it is important that full nodes can be run on modern consumer level hardware and internet connection as to ensure decentralization of SPV servers.
@_date: 2015-08-21 08:58:27
Could you explain why? I view treechains as the worst "improvement" since the changes to Bitcoin would be very significant and likely wouldn't improve scalability as it is with sidechains. At least sidechains can be introduced via softfork.
@_date: 2015-08-18 17:00:43
So you would prefer if the maximum size that can be voted be increasing with time? That would probably make sense: let miners decide what they can handle but have a reasonable cap to protect full nodes. Since full nodes can afford having to download a block longer than miners it would play well for the whole ecosystem.
I'm particularly interested because I would like to try to implement the proposal or at least a similar one. I think BIP101 is currently popular because it is the only which had significant support from the developers that proposed it.
@_date: 2015-08-27 15:58:33
The problem is that home connections usually have lower upload than download speeds. Also bigger miners likely have direct connections between them. Thus they can quickly transfer blocks between them without caring much about slower nodes since they can wait longer. Now smaller miners get increased orphan rate.
After things like IBLT and alternative scaling solutions are developed and we have further info about bandwidth trends we could do another hard fork possibly with completely different approach.
@_date: 2015-08-27 09:48:05
The 20% thing is a possible attack surface, I agree and would be more comfortable if the proposal included a slowly increasing minimum limit to be voted. The good thing is that would be possible to introduce as a soft fork if the need arises.
@_date: 2015-08-29 23:05:33
Most nodes haven't upgraded despite being given the option. Even without the stuff XT offers. Majority of miners doesn't signal they support BIP101. Some bigger companies expressed they preference but still no clear majority. Even among redditors there is disagreement.
@_date: 2015-08-17 20:32:07
Some miners could handle blocks which others may not. This is to not  encourage centralization to even fewer miners.
Also with no limit it would be trivial to execute a memory exhaustion attack: the attacker would claim that (s)he has a 4GB block and the node would need to allocate that much RAM.
@_date: 2015-08-18 07:21:25
2 MB blocksize was proposed as the last choice as a *temporary* increase which would need another hard fork in the future. Given how difficult it is now to reach consensus doing it again would probably be impossible. Thus it would be better to decide on a long term proposal unless we start to experience severe problems where the 2 MB increase would be an emergency fork. I hope we won't reach that phase.
@_date: 2015-08-29 23:49:46
Let's wait and see how will this continue.
@_date: 2015-08-29 22:58:49
Explain how this is not the reality.
@_date: 2015-08-26 17:52:27
BIP| Pro | Con | More
100 | We don't need to predict the future. Has a reasonable max. limit. | 21% of hashrate can decrease the limit. | My favourite. A min. limit to be voted can be introduced as protection for the attack.
101 | Plenty of room for growth. Includes anti-DOS measures. | Too optimistic growth. | Better this and then soft fork to a more conservative approach than nothing.
102 | Simple change. | Temporary solution. | Should be chosen as last resort.
Sipa | Could be a potential compromise [1] | Too slow start and likely too late. | [1] if it started from higher limit and earlier.
@_date: 2015-08-31 19:21:46
I by all means think implementing it would be stupid but at the theoretical level this answers the question (how to force them to include more transactions).
@_date: 2015-08-27 16:42:40
getblocktemplate - how pool mining should be done.
@_date: 2015-08-29 19:28:33
Of course you shouldn't. Isn't the point of this debate to decide what is a valid block and what is not?
@_date: 2015-08-19 17:15:06


Luke, the average block size really doesn't matter that much, and this is not even college level statistics. Not only transaction volume has variance but also the time between blocks. [I analysed the distribution of block sizes]( and even without those "stress tests" there were some times where blocks were full. And this will likely become more common as Bitcoin becomes more popular. If the limit was still ~0.5 MB we would certainly have problems.


I don't think the problem is as serious as you think but anyway this is why Gavin is working on IBLT. Also it would be possible to use the current Bloom filtering mechanism to optimize block relay. See  .
@_date: 2015-08-27 07:16:44


I personally find Core to have the best interface of all wallets (coin control, fee control, import your own private keys, API access to the blockchain).


Hardly, Google Chrome takes more CPU.
@_date: 2015-08-29 21:43:34
I think you are confusing Mb with MB, we are having a 8 Mb (1 MB) limit right now. Also you almost never get the full theoretical speed (someone has to upload the block to you, right?).
And you can't download the block for too long. Your peer has other peers which probably want to fetch the block and you will probably want to be able to upload the block to some other peer. You can't just have the majority to only leech and not serve SPV wallets.
If Bitcoin was a centralized system downloading only would be ok. But P2P implies contributing. Running a node shouldn't interfere with normal browsing activity.
If we get symmetrical optical fiber internet in most of the world we can reconsider the limit. For now we don't even need 8 MB blocks. Even then though bandwidth doesn't seem to be growing 40% per year.
@_date: 2015-08-29 19:26:36
You can't assume that every miner will think this way. Spam transactions pay fees. Poorly implemented protocols using the blockchain pay fees. Changing the limit every 3 months incentivises them to think about the future (and allows time to gather the opinion of experts and the community).
@_date: 2015-08-18 07:31:59
The way you explained it to me earlier the attacker would need to control at least 80% of the hashrate to impose a higher limit than others want. Given that the attacker would already cause a lot of problems with more than 50% of the hashrate the proposal seems to be quite safe. Also the limit can change at most by a factor of two every three months.
@_date: 2015-08-25 06:53:05
One of the forks would need to incorporate code to acknowledge work on other chains.
@_date: 2015-08-01 18:35:21
[Yep]( Although it is currently non standard so it would be a bit difficult to broadcast it.
@_date: 2015-08-27 07:08:38
Of course. If we have a very small number of full nodes positioned in data centers and charging fees to access the blockchain there is no need for the limit.
Now whether we want such outcome is another story...
@_date: 2015-08-17 19:09:04
in BIP100 says:


20%, and then the most common floor (minimum) is chosen.
What does the "common floor" mean? If it just means to pick the lowest value after dropping the two 20%s what is the point of removing the top one?
@_date: 2015-08-09 19:06:51
Similarly to most SPV clients.
@_date: 2015-08-27 21:42:35
The parent comment asked for the opinion of each person. Obviously your is respected as well.
BTW I would be in favour of double the limit when subsidy halves (perhaps with BIP101-style smooth increments but not necessarily) but AFAIK there hasn't been a formal proposal.
@_date: 2015-08-27 15:14:44
I prefer BIP100 because miners can vote both up and down.
@_date: 2015-08-29 16:41:00
I think you misunderstood the idea of consensus. Orphaning a valid block is an attack to the network.
@_date: 2015-07-15 21:59:24
This is a flawed analogy. You can send packets as fast as your medium allows while Bitcoin blocks are limited to on average 1 per 10 minutes.
@_date: 2015-07-30 15:27:09


The old "we can fork within hours" nonsense. And no, it is not in the best interest to onboard people to an experimental currency without them understanding the implications.
@_date: 2015-08-25 15:34:35
Yes but if the limit is below 1MB everyone will need to make small blocks.
@_date: 2015-07-20 14:55:26
But how nodes are supposed to check what happens on the other chain? If they have to monitor the other chain sidechains are not a scalability solution as they are often presented.
@_date: 2015-08-27 08:31:48
Full nodes have a say in the rules. If the merchant/exchange node ignores a block you can't pay him. Miners want to be able to use their coins.
@_date: 2015-08-17 19:57:16
If XT becomes the popular fork then hopefully Core will adopt the changes and we would be back to normal. If not people can fork the code again; even if there is no blockchain fork planned.
@_date: 2019-02-25 13:30:12


Anyone knows where I can find that paper? @_date: 2015-07-13 06:19:32
The upgrade is risky because the majority needs to upgrade, not because of a potential bugs. The risk of bugs is there even for soft forks, yet the major problem is still the upgrade of node software. Keep in mind that most of the ideas for a hard fork are relatively simple in terms of programming.
@_date: 2015-08-27 15:06:27
I think the problem isn't the initial 8 MB but rather that it will grow too fast...
@_date: 2015-08-26 17:41:42
The point is that most miners need some protection against a miner creating a long to verify block. This is mostly true for smaller miners and we want to have smaller miners as well.
Also limiting the block size would not necessarily increase fees. Fees per transaction can grow but at some point users will switch to some other system. With BIP100 miners can choose a limit which would allow enough number of transactions. Also they can already choose a minimum fee per transaction they are willing to take.
@_date: 2015-08-19 14:12:17
@_date: 2015-07-13 10:59:37
What is the reasoning behind placing the previous output's scriptPubKey in the scriptSig of the input of a transaction for signing? Isn't it enough that the hash of the previous transaction is signed?
@_date: 2015-08-29 22:31:34
When blocks are not valid they are not orphaned. They are completely ignored. It's like they never existed in the first place. The node will not even attempt to store them in case they might become part of the longest chain.
If miners start to enforce their own rules they are essentially attempting a 51% attack.
I'm starting to feel like you argue for the sake of arguing as it is fundamental in Bitcoin to have precise rules saying whether a block is valid or not.
To quote Satoshi (maybe an appeal to authority will work):


(emphasis mine)
While normal nodes don't extend the chain they still reject invalid blocks.
@_date: 2015-07-22 13:24:25
Have you finished your analysis?
@_date: 2015-07-21 09:12:52
How long is the voting expected to last?
@_date: 2015-08-25 15:48:34
I'm not sure if we agree or not but just in case:
With BIP100 20% of hashrate is needed to lower the limit. At present more than 50% is needed.
@_date: 2015-08-27 12:48:45
My point is that most miners are in favour of voting for the limit and BIP100 aims at that.
The soft limit that gets repeated does not protect miners from others. This mostly affects smaller miners since bandwidth is a fixed cost.
Also smaller miners are more aligned with independent node operators. If you don't care about small miners and node operators then you might as well use a centralized system since node operators will not provide services to SPV users for free for ever if the block size keeps increasing too much.
I don't get why proponents of big blocks think that will prevent fees from increasing.
@_date: 2015-08-26 07:53:25
So you are telling me that a decentralized system could process ~6% of VISA's transactions with nodes receiving no compensation? I would say that's really awesome! I mean, it's great that centralized systems being paid fees can be more efficient than the Bitcoin system. When nodes start to receive incentive we can talk about increasing the limit to high levels.
Also, why do you think mainstream users will *want* to transact directly on the blockchain? Last time I checked they can't make their due diligence and thus need chargeback protection.


Wait, since when VISA processes "alternate uses for the blockchain"?
@_date: 2015-08-27 08:50:39
They are voting for BIP100 as it is in the paper. If the implementation turns out to not be good they will simply not adopt it.
The current voting is informal either way. After the implementation is deployed there will be another voting.
@_date: 2015-08-27 10:03:15
How is it democracy? Not everyone has equal votes...
This is the number to activate, the number of blocks whose votes for new limit would be considered and likely the number of blocks between changes to the limit.
Better have a good proposal with an implementation in progress than an implemented proposal which is simply wrong.
@_date: 2015-07-28 08:59:13
Try running with `-disablewallet`.
@_date: 2015-07-17 18:53:42


They already do; in the coinbase. A timestamp will provide greater accuracy as to when the fork will happen due to variations in hashing power.
@_date: 2015-07-29 07:43:52
Dude, [I think we talked about this a while back](
@_date: 2015-07-07 14:09:46
Bitcoin doesn't use SSL/TLS. OpenSSL is used for for digital signatures and encryption of the wallet file. For more info see 's answer.
@_date: 2015-08-01 09:18:28
This is what happens when you don't upgrade your node and continue to run [0.5.3](
@_date: 2015-07-01 05:23:31
UTXOs are stored in LevelDB on disk.
@_date: 2015-07-17 08:29:47
`MEG_FORK_TIME = 1447200000` is a [UNIX timestamp]( which is Wednesday, 11-Nov-15 00:00:00 UTC.
@_date: 2015-07-27 12:28:10


How is it so? Since when constructing the balance of all addresses is more efficient than filtering transactions based on bloom filter and letting the client figure the balance itself?
@_date: 2015-07-27 13:34:10


Yes, this is called [arbitrage](
@_date: 2015-07-27 12:52:43
Except Electrum does this for all addresses. I don't think every bitcoiner connects to every Electrum node. I am glad my Bitcoin node  doesn't waste resources. Also there are the privacy concerns...
@_date: 2015-07-26 20:42:42
What you say makes no sense. If miners are able to produce large blocks then *at least* they can handle them. Now propagating them across the network may be impossible since by the time they reach enough nodes another block may be found which will propagate faster.
And what is your point about variance? The block size cannot exceed the limit no matter what the variance is.
@_date: 2015-07-22 17:21:30
Under certain circumstances a miner *can* modify a transaction before including it in a block.
@_date: 2015-08-27 09:39:41
Exactly. Which is why BIP100 is a good proposal in that 80% of miners will agree to the chosen limit.
@_date: 2015-07-01 12:17:43
For an implementation to be feasible a soft fork is required.
@_date: 2015-07-13 16:06:09
The probability is 2.48*10^-3 so it is expected that it will happen once in 403 blocks which is 2.8 days.
@_date: 2015-08-09 14:07:00
If 75% of blocks are signalling support for bigger blocks both XT and SPV clients will follow the same chain. At worst XT could be flagged as an SPV client. XT doesn't force miners to produce blocks larger than 1 MB.


Sorry to disappoint you but this is not how Bitcoin or money works. It doesn't matter what you believe. You could believe that the soil in your garden is worth $5000 per gram. It doesn't matter, what matters is what others believe.
@_date: 2015-07-11 13:15:26
If we came to agreement about a hard fork we could consider including other ~~futures~~ features alongside the block size limit increase. It would be wasteful to do such a risky operation just to make one upgrade. Also if we would agree relatively soon there would be more time to test those extra ~~futures~~ features before releasing the updated software.
@_date: 2015-08-29 16:38:52
1. Moore's law doesn't predict bandwidth
2. It slows down
3. There is lag until consumers upgrade


If you mean that the limit will be too small having a too big limit can have the same result.
@_date: 2015-08-29 23:58:16
Considering my node maxed at position 7 of the BitNodes leaderboard  and it has regularly been on the first page I'm not sure what to think about internet speeds.
I wouldn't take past trends as granted. We'll see.
@_date: 2015-08-31 19:38:59
`getrawmempool` returns the hashes of transactions in the mempool. Then you can use `getrawtransaction "&lt;hash&gt;"` to get the transaction encoded in hexadecimal.
@_date: 2015-07-09 11:17:12
If miners don't implement appropriate fee/anti-spam policies they will eventually include spam transactions with or without any limit. This is not a valid argument against a change to the block size limit.
@_date: 2015-07-13 12:48:26
@_date: 2015-07-13 13:09:02
I asked the original question because if the scriptPubKey wasn't included the hash could be cached and the tx verification would scale linearly.
@_date: 2015-08-27 10:12:26
Re: Edit
Miner majority likely won't choose BIP101 so...
@_date: 2015-08-21 10:25:35
Perhaps it could be introduced via soft fork but it would be a significant change to how Bitcoin works which would likely mean that wallets would need to be rewritten.
Anyway I'm waiting until an implementation is released as neither the sidechains nor treechains papers define the exact way they would be verified by the main chain.
@_date: 2015-07-17 12:27:00


This can be faked as we saw with BIP66. Rational miners will follow what the community will decide.


The *block timestamp* matters, not the time of your computer. As long as the timestamp is not too off your computer's the block will be accepted.
Edit: The reason to use time and not block number is probably to allow devs to be awake when this happens.
@_date: 2015-07-14 07:51:32
It doesn't, you send the bitcoin to an address generated by the ATM.
@_date: 2015-07-22 23:06:17
Elements is a federated sidechain: the functionary can arbitrarily decide which transactions can cross the peg. We already have that: off-chain transactions recorded in a centralized ledger.
As for decentralized sidechains see Appendix B. Weak SPV security, for the whole sidechain.
Implementing a secure sidechain is theoretical.
@_date: 2015-07-23 19:12:08
"Forking" probably referred to forking the codebase not the blockchain i.e. Bitcoin XT.
@_date: 2015-08-26 19:49:39
Emergency hard forks are not the best way forward...
Also, seriously? Is Bitcoin so perfect that there can be no improvements?
@_date: 2015-07-24 14:57:38
Technically it would be possible to have a fork with &lt;50% hashing power by refusing to connect to older nodes... although that is definitely not something we should want to do.
@_date: 2015-08-27 09:29:28
The incentives of smaller miners are more aligned with node operators. So yes, they should survive. They should compete for the reward.


Ideally that would happen since then mining would be closer to "one CPU; one vote" as it is in the whitepaper.
@_date: 2015-07-06 13:38:03
You can hash any document and embed only the digest (usually 32 bytes) into an output (In the script of the output preceded by an OP_RETURN to terminate execution before reading the data). A company doing many contracts could include only the Merkle root of several hashes, say, once per day.
@_date: 2015-07-06 22:13:39
not a hard fork
@_date: 2015-07-29 11:40:03
You can browse the code yourself: 
@_date: 2015-07-24 07:39:12


You are not wrong (at least at this point). They are mostly writing C++ but their code defines how the Bitcoin system works so the implications are a lot more significant.


Sure, that's why there exists Bitcoin XT and other forks.


No, miners can introduce more restrictions but relaxing them, as in increasing the block size limit, needs the majority of the network to upgrade: specifically those who *receive* money.
Anyway if developers don't act responsibly someone will make a fork and if (s)he manages to convince the important people in the ecosystem that the change is necessary that fork will win. It would be better though if we could come to agreement without forks.
@_date: 2015-07-19 09:22:39


Of course not, how would you do that?


Full nodes will accept a header/block after verifying it. SPV clients only download a portion of the block so they will not know about the actual size.


Bad players can already limit their blocks; even to 1 transaction. This will not change what good players can do. When the median timestamp of the last 11 blocks is above the threshold not even an attacker will be able to produce blocks with size limit of 1 MB. But who cares? They can limit their blocks anyway.
@_date: 2015-07-27 13:40:51
Sure but it is misleading to say that every node needs to upload to 8 peers. There will always be faster nodes no matter what the block size is.
@_date: 2015-07-31 20:31:00
So it seems that they simply don't care about being independent. A home user can easily run Core pretty much as a background process. Heck Google Chrome sometimes takes more RAM and CPU.
@_date: 2015-07-14 06:34:07
They discovered that the ratio of donations to views decreased which was expected since a lot of bitcoiners just wanted to see that page.
@_date: 2015-07-20 15:27:02


What I want to know is *how* would this happen. How can a *full* node know whether a dishonest miner spending "locked" funds is wrong (without knowing about sidechains)?
@_date: 2015-07-15 18:38:27
The sidechain Elements Alpha is federated which means that it is not really decentralized. Ideally they will manage to make a decentralized one, although I wouldn't hold my breath...
@_date: 2015-07-16 08:24:12
That would take pool mining to a whole new level ;)
@_date: 2015-07-08 18:12:23


not necessarily


until you spend the output it is an Unspent TX Output, after that it is not. Also an output is a script which in some cases could not be encoded in an address at all.
None the less the output script is specified by the sender i.e. the spammer.
@_date: 2015-07-06 22:34:35
tl;dr: BIP66; no block size increase
@_date: 2015-07-13 11:06:17
Use `-datadir=&lt;dir&gt;`
@_date: 2015-07-26 11:15:16


The attacker didn't increase his/her fees; legitimate users will.


I agree that right now a change is not needed but if we agreed that an increase to, for example, 2 MB will be made, for example, during April 2016 third party developers would have more time to test their own software and we could consider including other scalability/performance improvements to the protocol like new sighash types.
@_date: 2015-07-27 12:57:30
The problem is that you have to download the whole block from some peer. This can be solved by sending only hashes since you already have most transactions in your mempool.
@_date: 2015-07-30 20:14:43


I suppose your response is exactly why you can't have a polite discussion with some people.
Point 2 allows for only one transaction between the two parties since you cant change the script in between. Your idea about using a different key for authentication made sense.
Unless you are willing to change tone I will not continue the discussion.
@_date: 2015-08-29 19:15:09
Obviously there will be some nodes that will process blocks valid under BIP101 but due to its overoptimistic growth less individuals could run a node. Right now Bitcoin is trustless because individuals can run a full node and serve SPV clients but with too big blocks (BIP101 growth is already above current consumer technology growth rates and they are likely to start to decline in the future) this likely will not be the case.
Neither too small nor too big blocks will break Bitcoin but both are likely to defeat the reason it was created.
Another problem with big blocks is that they don't discourage inefficient protocols. Why would a node operator want to process that?
@_date: 2015-07-06 09:22:02
You can google "what is my ip" and append the port number; 8333 in most cases.
You could get a domain name pointing to your IP address. You can get a subdomain for free for example from 
@_date: 2015-07-28 19:31:49
Subscribe here: 
@_date: 2015-07-23 16:49:45


I don't think you know what it means.
You are arguing that Bitcoin was imminent because much of its technology already existed. This is also the case with LN. The problem is that you argue that this justifies the length of the Bitcoin [whitepaper](
@_date: 2015-07-11 13:02:53
If you flip a coin 4 times and pad the result with zeroes you will also have a "legit private key". But private keys are 256 bits.
@_date: 2015-07-13 16:42:41
Because only counting leading zeroes would be inaccurate. Every time the number of zeroes (in binary) increases by one the difficulty doubles. Thus for ~~an increase~~ a decrease, blocks would need to take on average 20 minutes, or for ~~a decrease~~ an increase 5 minutes. Keep in mind though that internally Bitcoin stores the target and not the difficulty.
@_date: 2015-07-23 16:29:12
Perhaps if you actually read the Lightning Network paper you would know that payments channels aren't new either...
@_date: 2015-07-20 12:11:37
How would a 2-way peg be created in sidechains? I understand that you could create coins on the other chain by sending to an unspendable address on the Bitcoin's chain like the Counterparty protocol but how would this work in two directions?
I thought that miners could soft fork to check both chains but that wouldn't improve scalability.
@_date: 2015-07-08 16:54:28
Only if the spammer specifically chose to do so, which I doubt. Also there is no such thing as a "UTXO change address".
@_date: 2015-07-13 12:50:55
I didn't understand what you meant about the size. The substitution happens at the time of verification; it is not stored in the blockchain.
@_date: 2015-07-27 12:54:30
I wouldn't trust Luke Dashjr with maths: 
@_date: 2015-07-30 18:28:14
Dude, he is going with his wife...
@_date: 2019-02-23 17:03:32


How to spot an uneducated 'murican.
@_date: 2015-07-09 17:02:54
No, the block size increase hasn't been merged yet.
@_date: 2015-07-11 13:11:19
The block size limit increase hard fork is addressing *future* problems, not present. Currently bigger blocks may not be needed but think what happens when adoption increases *and* a spam attack occurs.
@_date: 2015-07-27 21:55:17
A block needs to be propagated relatively fast to not be orphaned, although I don't agree with Luke's 30 second figure. You can't upload a block before verifying it.
@_date: 2015-07-11 15:10:40
I'm glad we agree, although I doubt the blockchain will stop violent wars since it is not only about monetary policy :)
Certainly if a hard fork is successful, even only for the increase, it will be good not only because of the increase but as a proof that it is something viable.
^^Shameless ^^plug: ^^I ^^wrote ^^a [^^blog ^^post]( ^^about ^^the ^^current ^^block ^^sizes ^^if ^^you ^^are ^^interested. ^^edit:word
@_date: 2015-07-31 18:49:06


Maybe if Core had a better API it would be used more... Either way merchants in many situations want fiat so Core is little use to them.
@_date: 2015-07-09 11:35:15
A low block size limit reduces the amount of all types of transactions while a fee policy combined with the risk of orphaning too big blocks would reduce the number of spam transactions.
I'm not saying that the limit should be increased to high levels abruptly and would prefer a linear increase and not exponential.
@_date: 2015-07-13 13:44:46
You didn't understand my question. Please read the replies and if you don't understand something, ask.
@_date: 2015-07-24 12:46:04
If you think that the transaction volume is 350 KB/block (it is currently somewhat larger) with 1 MB maximum block size why are you opposing doing a fork which will increase the block size in the future given that there is no clear correlation between the limit and average size?
@_date: 2015-07-30 18:59:53
I have not finished reading the paper so I might not be able to enumerate you all the problems but here are some:
* If a hub does not cooperate the channel will need to be closed which (surprise!) requires fees. If intermediate nodes have to close channels they will need to increase their own fees to cover the on-chain fees.
* You can't use the full scripting system because that is how payment channels work. Both parties need to understand exactly what your script does and you cannot enforce it between other hubs.
* Unless you want to be online at all times you need to authenticate with the hub. This could be implemented by signing with your key and therefore increase the chance of duplicate r values in ECDSA and extracting your key.
* Since the same key needs to be used for all transactions for the lifetime of the channel the above further holds true.
* There are more problem if the necessary soft-fork changes are not implemented.
I'm not in principle against scalability solutions like LN but it is not ready.
@_date: 2015-07-27 14:55:01
And we expect them to come to an agreement on the current debate ;)
@_date: 2015-08-09 13:36:05
Until 750 out of 1000 last blocks are signalling support for larger blocks XT will follow the exact same consensus rules as Core.
Flagging it as an altcoin would make most of implementations also altcoins. Breadwallet, Schildbach's Bitcoin Wallet, MultiBit, bitcoinj and other SPV implementations do not check the block size and will accept a block larger than 1 MB already.
Good luck moderating posts suggesting Breadwallet.
@_date: 2015-07-16 19:56:12
There is no "the client", what you mean is the reference client, Bitcoin Core. There are lots of other wallets, see  If I weren't using Bitcoin Core as a wallet I would probably use MultiBit HD.
@_date: 2015-07-30 09:48:35
I hope you mean localbitcoins.**com**
@_date: 2015-07-27 15:00:47
Orphaned by retarded nodes that is. Newer will simply ignore them.
@_date: 2015-08-19 11:58:25
name is Luke Dashjr.
@_date: 2015-08-11 08:35:09
It is based on the assumption that all nodes need to upload a block fast (max 30 seconds) to 8+ peers. Both numbers were [arbitrarily chosen]( by Not only you don't need to upload a block to a lot of peers since you are not their only source but the 30 second figure would only apply to miners. As long as there are some nodes that can propagate blocks fast between miners we are fine. Slower nodes won't block the faster ones.
@_date: 2015-08-31 17:21:13
Theoretically we could introduce a minimum size and have miners pad the block with some other data if they don't have enough transactions.
@_date: 2015-08-21 11:18:50
Lightning is by far my favourite solution, mainly because it is quite precisely defined in the paper. I would be glad if along with increasing the block size limit a future fork would also include the changes Lightning needs.
@_date: 2015-07-29 11:33:18
Umm no, Mike was right.
@_date: 2015-07-27 13:25:10
This is not true. Some of your peers will *already* have the block which means they won't request it again.
@_date: 2015-07-22 09:56:56
Excuse me? When was that awesome time when the bitcoin network had approximately 118000 full nodes?
@_date: 2017-04-24 07:58:08
How is it a voting mechanism when not only votes but miners as well can be fired at will?
@_date: 2015-07-09 20:15:42
[Imgur album with graphs](
@_date: 2015-07-22 08:07:15
[&lt;reptile-&gt; The first time hypr opened a box of Cheerios and looked inside he yelled, "OH WOW! DONUT SEEDS!"
&lt;hypr&gt; wtf are donut seeds](
@_date: 2015-08-25 12:38:15
Well, BIP100 is kind of "upward soft fork". The 32 MB max limit should be enough until we need to do a hard fork anyway.
@_date: 2015-07-30 13:55:36
I speak Greek, know about Bitcoin *and* think this is a bad idea. How are we going to handle all those transactions on chain?
@_date: 2015-07-29 18:41:11
OK, I see you are in love with the concept of sidechains, despite not understanding how they actually work, so let me present you block size limit increase idea: [Extension Blocks](
The idea somewhat resembles a sidechain. Personally I would prefer to not make the protocol even more complex than necessary but if P2SH is there despite OP_EVAL being an alternative perhaps this not that bad idea after all.
@_date: 2015-07-27 15:04:41
As it currently is miners are allowed to claim less than the reward. In fact some miners were not claiming fees back when the subsidy was 50 BTC which means that they were destroying those fees. Thus the total number of bitcoins will be quite below 21 million.
@_date: 2015-07-31 12:17:14
I don't see the point of your "synopsis" of the protocol. Most of technological/science advancements build on top of existing work. It's not like you made some unexpected discovery. Care to explain?
@_date: 2015-07-24 08:13:26
* If you solo mine just upgrade to the newest Bitcoin Core/XT
* If you pool mine point your ASIC at a pool which supports the increase
@_date: 2015-08-27 09:45:25
Because a lot of people who support too big blocks do not run full nodes; not to speak about expending money on mining...
@_date: 2015-08-29 22:38:55
So what you are suggesting is that we should let miners attempt to orphan each others blocks? Instead I think we should work to make a proposal which expresses what both miners and the community want while not giving too much power to miners. BIP100 can be a basis for that.
BIP101 seems to not please either.
@_date: 2015-07-22 22:09:48
Please read the whitepaper. The system you describe is purely theoretical with no known implementation.
Link for your convenience: 
@_date: 2015-07-26 11:01:13
That a rapid increase in the rate of transactions is a problem. This was an attack so at some point it had to stop but what if we have a significant influx of new users? These new users would also adjust their fees. It is generally considered good to have some extra capacity available.
Edit: Either way the problem IMO is that we don't have some clear scalability plan and currently the sentiment among developers is that "we will do it when the limit starts to be a problem" which may be too late given that we are talking about a hard fork.
@_date: 2015-07-11 14:14:10


That *would* be a PR disaster. Bitcoin solved the problem of decentralized consensus. If there would be a split XT would certainly have smaller adoption and price. Users and merchants would prefer the original Bitcoin for the same reason that they don't use altcoins. That would probably change when the 1 MB block size limit started to be a problem but the proposed hard fork is there to *prevent* such outcome.
@_date: 2015-08-18 07:13:34
Satoshi hasn't expressed his opinion on Gavin's talk (which Gavin had publicly announced). In fact he wasn't active for some months already at that time. After the talk he announced that he would stop contributing but there is no indication that the talk was the reason.
Now for the fork to activate the "attack" would need to be more than 51%, 75% to be precise.
@_date: 2015-07-31 07:46:26
Romania, it can't control the technology outside its borders. The USA have a lot of terrain inside their borders.
@_date: 2015-08-21 08:35:59
I guess those downvoting you should read the disclaimer (the part written in all caps) of the [MIT license]( under which Bitcoin Core and a lot of wallet software are licensed.
@_date: 2015-07-29 19:34:26
Decreasing the blocks size is a soft fork so it wouldn't even be that risky.
@_date: 2015-07-27 09:25:43
There is a lack of roadmap in both sides.
Those advocating Lightning/Sidechains/Other can't have a roadmap simply because these technologies are at best at prototype stage and there's no evidence that they will work and even less whether they will be resistant to attacks and will be able to scale.
On the other hand there are a lot of people arguing for a significant increase in block size especially in the future which may not follow the technological advancements.
@_date: 2015-07-25 14:17:03
Na jakiej podstawie zaklasyfikowałeś osoby odpowiadające na "pionierów" i "ideologów"?
@_date: 2017-04-18 03:52:05
What about the regulatable 3rd parties called Coinbase and Bitpay who already process the majority of merchant payments?
@_date: 2015-07-26 14:39:13
If your full node cannot handle 4 or even 2 MB blocks then it is already harming the network.
@_date: 2015-07-24 07:47:50


Sure although mining coins which nobody is going to accept may not be profitable.
@_date: 2015-07-30 18:32:24
Technically it is using SPV but the implementations is less than optimal. Bitcoin Core accomplishes the same and even more.
@_date: 2015-07-30 21:08:48
If you are going to have escrow with a third party, yes that is a valid use case. Anything not having to do with signatures can be used only once because the first time the "answer" is used it is known and the "question" cannot be changed. For example you could time limit the transaction only once.
Now regarding your other thoughts:
1. The refund transaction returns the money you locked in the channel. By definition it is not the hub's money and therefore cannot be partly paid by the hub.
2. Cloud services can be used but it is sort of a middleman. A lot of users will probably be happy with that, but isn't Bitcoin supposed to prevent such outcomes? If it cooperated with the attacker it could freeze your money by not broadcasting the revocation transaction. If we are going to trust cloud services we could use SPV wallets. The full node cannot freeze your funds.
3. To attack the Bitcoin network you need to invest in mining hardware. In LN a sybil attack would cause troubles. This was the problem with the first attempts to create decentralized digital currencies.
4. LN may work in the future. It would be great if it did. But you cannot take this as granted. I acknowledge that Bitcoin on-chain transactions do not scale well. But we are not at the phase where the only way to achieve higher capacity is alternative solutions.
@_date: 2016-02-06 20:36:25
You can't change any of these and have not upgraded clients accept new blocks. See my other comments. Also those are some of the few things SPV clients can actually check so you can't even fool them.
@_date: 2016-02-22 20:19:32
You do realize you are risking a ban from that sub, right?
@_date: 2015-07-27 15:39:13
If there are miners producing blocks which the majority of the network can handle that will be the main chain. It may not have the most work but this is what nodes would be able to know about. Of course this is not going to happen because the limit will not be raised to unacceptable value.
@_date: 2016-02-24 17:55:00


Please, no more pseudoscience.
@_date: 2016-02-26 11:46:45
To this:


@_date: 2015-07-16 11:52:00
Currently it does because the main chain doesn't have all the features Lightning needs.
@_date: 2016-02-14 22:08:19


0 - such node would be useless.
@_date: 2016-02-05 22:47:45
I didn't criticize the arbitrarity of the limits (though the hashing limit is larger than that of the F2Pool megatransaction so maybe it should be lower - but that's not the main problem); rather that the actual problem isn't fixed. Also rushing things is never appropriate.
@_date: 2015-08-27 08:45:16
Even if every non-miner full node adopted infinite block size limit the majority of miners could choose any limit; even below 1 MB (soft fork).
@_date: 2015-07-20 16:18:00


It would not. A soft fork doesn't require everyone to upgrade because changes are backwards compatible. Once you start enforcing the new rules through your full node removing those rules is a hard fork. A block not enforcing P2SH will be ignored by updated nodes which currently are a majority.
This is the reason updated full nodes were not vulnerable after the BIP66 threshold was reached: they discarded any nonconforming blocks while SPV and not upgraded nodes didn't.
If indeed full nodes cannot enforce fund locking without knowing about the internal state of sidechains they will degrade to SPV security. The burden of verifying transactions would be shifted from "full nodes" to miners. Which raises the question whether sidechains are a solution we want to have.
@_date: 2015-07-13 11:22:31
The OP_CHECKSIG operation.
@_date: 2015-07-10 09:34:19
The input script(s) of the first transaction can contain arbitrary data since the script is not executed.
@_date: 2015-07-23 00:25:10
Either miners soft fork to check both chains and running a full node forces you to check both chains or a soft fork is made to check only SPV proofs originating from the sidechain. Both approaches do not scale.
@_date: 2016-02-13 20:44:21
You are probably thinking about [extension blocks](
@_date: 2016-02-01 23:17:11
Guess you will have to do your homework.
@_date: 2016-02-23 19:36:12
You could create a torrent and embed the infohash. Then when you want to update the note repeat and sign a message with your bitcoin address (or include any pubkey in your note).
@_date: 2017-04-24 08:03:57
Can you provide some examples?
@_date: 2016-02-07 10:42:52
If their engineers are incapable of constructing Merkle trees of their data and embedding only the root in a transaction once every hour then I doubt they are capable of doing anything useful with a blockchain.
@_date: 2017-04-11 05:33:26
[It already exists](
@_date: 2015-07-01 08:24:39
Gavin acknowledged that he was thinking about RAM as Random Access Memory which includes SSDs.
(also how do you explain my node using ~250MB of RAM if the UTXO set is ~756MB?)
Edit: Bitcoin Core caches a portion of the db in main memory for faster access. By default it is 100MB.
@_date: 2015-07-30 22:52:31
1. I'm not sure what you meant. A reputable hub could subsidize your transaction but this is not very decentralized. With the Bitcoin network nodes are pretty much equal. That's is why there is no need to identify them. But in the case of an attack you will have to make the revocation transaction yourself.
2. Well, this is more a problem of UX I suppose. With on-chain you only need your private key.
3. OK, the attackers certainly will be creative but it still will be quite expensive. If you have the infrastructure ready you can reuse it for a lot of sybil attacks.
4. I wouldn't worry too much about Gavin and Mike. Their change may be too optimistic but the good thing is that it can be restricted with a soft fork. 
Also perhaps they didn't change the parameters due to lack of constructive criticism. For the large part this debate has been whether or not to increase the limit and not how to actually do it. Gavin's test showed that 20 MB would be feasible so he probably sticked to what he found.
Re sidechains, there are currently pretty much two ways to implement them:
* Both chains opt to verify each other: apart from some extra features to be implemented in the sidechain it's quite pointless since it doesn't improve the requirements to run a full node.
* SPV proofs: would be possible for an attacker in the sidechain to steal user funds. Good thing is that it doesn't increase the cost of verification of the main chain much. This approach will not make your proposal necessary.
edit: typo
@_date: 2016-02-26 12:52:42
You have just a single connection to another node. You pay for goods and services. You receive your paycheck through the same connection.
@_date: 2016-02-22 05:28:07
Yes and shouldn't. The blockchain is not your personal cloud storage.
@_date: 2016-02-06 21:10:24
You aren't going to break even but if you want to mine as a hobby check out [these]( or [this](
I own an Antminer U3 but it needs to be restarted every few days.
You can also ask in @_date: 2016-02-05 18:19:31
It's opt-in for those who make transactions obviously.
@_date: 2016-02-07 10:17:23
The puzzle actually isn't complicated at all. It's just that finding the solution is random and on average requires many attempts.
@_date: 2015-07-11 14:22:47
Miners on their own are not enough since we are talking about a hard fork. Bigger blocks will be invalid if the majority of users don't upgrade. If merchants don't upgrade you will not be able to *use* your coins. Miners won't risk mining coins unless they are certain they will be valuable.
@_date: 2015-07-13 17:10:05


Yes, though it is stored using 4 bytes:
* 3 bytes for the first non-zero bytes of the target
* 1 byte for the exponent (with base=256)
This gives an accurate enough representation.
@_date: 2017-04-20 09:22:32
I suppose you also believe that ice cream is to be blamed for drowning based on research illustrating links between increased ice cream sale and increased number of drownings in the sea.
@_date: 2017-04-13 18:18:23
None of these technologies are based on a flood network.
@_date: 2016-02-07 13:28:33
Among others yes.
@_date: 2016-02-07 11:12:54
Hmm, the median timestamp of past blocks would be in favor of the majority so it seems that it would work. It would be pointless but would work.
@_date: 2016-02-07 05:29:35
Well, this would require a supermajority of miners and not mere majority (the honest miners could counter-fake the timestamps) but technically could be done. But as you can see the other changes aren't really possible.
@_date: 2016-02-07 06:03:04
Yes, it is 's fork.
@_date: 2017-04-15 22:35:12
The voting/signaling distinction should be clear and needs to be repeated. Miners are employees of the usets and therefore don't get to decide on protocol changes. Miner activated soft forks are convenient but when they fail users can push any chance they want; including firing all the current miners.
@_date: 2016-02-28 05:35:10
Actually the private key is in the same format; the different version byte tells your software whether to produce a compressed or uncompressed public key which correspond to different addresses.
 @_date: 2016-02-05 20:42:58
In a world where full nodes are run only by few megacorps and hard forks are centrally planned this may be more than enough.
@_date: 2016-02-22 11:28:27
@_date: 2016-02-24 14:41:30
This is what happens with checkpoints.
@_date: 2016-02-06 00:47:33
Miners can set the maximum block size they are willing to create and bitcoind will choose the most profitable transactions. By default it will give more priority to transactions using segwit but this can be overridden. If miners keep the default method the segwit space will be cheaper but due to competition output space will become more expensive and overall miners won't lose fees.
@_date: 2016-02-05 19:40:13


I don't know, fiat users are fine with inflation. Isn't mass adoption what bigblockers want?
@_date: 2015-07-23 01:04:31


Sure transactions inside the sidechain can be decentralized. But if you cannot freely move coins between chains you are effectively using an altcoin. There's plenty of them.


By creating large transactions because of the need to embed a lot of headers. Not to mention that the whitepaper conveniently doesn't mention how to actually check those proofs.
By scaling I mean increasing transaction rates. Sidechains not only will require their own nodes to verify them but Bitcoin nodes will need to verify their proofs or even the whole sidechain depending on implementation.


That's what we have testnet and altcoins for.
@_date: 2016-02-05 22:26:11


If that's the case the average is still 10 minutes.
@_date: 2016-02-07 10:51:23
@_date: 2016-02-16 12:22:12
@_date: 2017-04-14 07:17:50
BIP148 doesn't reject non-segwit blocks; it rejects non-segwit-signaling blocks. That's a huge difference as miners simply need to change their version number and can continue mining old style blocks (they just need to do it behind a segwit capable node).
@_date: 2016-02-06 20:37:37
Of course not. I'm just saying that such scenario is not impossible.
@_date: 2017-04-22 20:12:30
Both of these things are wrong.
@_date: 2016-02-24 22:03:36
I doubt anybody serious would choose the classic clown car path.
@_date: 2015-07-17 18:56:31
No. Transaction relay can be a p2p network rule because even if you don't accept one you will accept it if it is mined in a block. OTOH not accepting a block will fork you off the network.
@_date: 2016-02-24 12:52:05
Bitcoin is a settlement network (every onchain transaction is settlement). It can be used to an extent as a payment network but solutions on top of it could be better.
@_date: 2016-02-28 07:00:15
My point was that private keys aren't really compressed.
@_date: 2015-07-24 15:10:20
1. There is only one Bitcoin blockchain but there are a lot of clones of Bitcoin which have their own. Edit: this is not entirely true since different nodes can have a different view on the blockchain due to forks
2. The Bitcoin blockchain is around 38 GB and it is growing although the software needs to store some extra data. It is possible to discard some data by a method called pruning which is described in the whitepaper.
@_date: 2016-02-24 14:01:09
Increase dbcache.
@_date: 2016-02-05 20:00:35
If we have mass adoption and the masses are fine with inflation why wouldn't the 21m cap be raised?
@_date: 2015-07-27 13:31:43


It's 210000 blocks.
@_date: 2015-07-11 14:43:54
They are for a block size limit increase but not necessarily XT. They want an increase but may not want to be forked from the network.


As per the whitepaper, "If a majority of CPU power is controlled by honest nodes, the honest chain will grow the fastest and outpace any competing chains." This is true given that blocks are valid. The blockchain is there to reach a consensus on the *order* of transactions.
Our worries are that the new blocks will be invalid. Miners won't risk that. I don't disagree with the triger. The question is whether it will be reached.
In fact I am planning to switch to XT, absent any other options.
@_date: 2016-02-24 22:01:08
I wouldn't call allowing blockchain bloat "progress".
@_date: 2015-07-24 20:31:38
While I agree that a reasonable limit is required I don't think preventing spam by limiting real transactions is the right solution. While I don't think an increase is needed right now a plan is needed. The plan should definitely not only involve raising the limit but changes like new sighash types which would really improve performance.
@_date: 2017-04-20 09:40:48
In fact lack of DDoS would indicate that miners are too centralized to be affected by it.
@_date: 2015-07-26 07:57:29




@_date: 2016-02-01 21:55:27
No. Those are for private use.
@_date: 2016-02-01 23:19:16
Yes and this is by design. Storing outputs is more costly than inputs.
@_date: 2017-04-20 04:54:40
Downvoted for conspiracy theories.
@_date: 2015-07-19 08:29:46


No. For a brief period of time miners will be able to decide what the max size is. Which they can always do by limiting their own blocks. Other miners can (and probably will) set the correct timestamp for their blocks.
@_date: 2016-02-06 20:31:10
[Bitcoin LJR](
@_date: 2016-02-05 19:10:33


You are referring to an insignificant minority here; Core plans to do hard forks when those are needed. They are not needed yet. And it's not like Core devs. wouldn't like to do [hard forks]( if those weren't difficult to safely roll out.


I see you didn't read the blogpost.


You must be joking. We have the current P2SH implementation because:
* Gavin's OP_EVAL (an objectively better idea) wasn't well tested and bugs were discovered.
* Gavin wanted to deploy something ASAP because apparently multisig would be widespread any day now! (It took more than a year for P2SH to be used).
* Gavin's popularity weighted more than technical merit. (Luke Dashjr's OP_CHV lost against /P2SH/)
[As you see all those proposals were in fact soft forks as it made practically no difference to do  them as hard forks]
Now compare this with the present situation:
* Wrongly tested solutions were promoted (XT).
* Objectively better proposals are dismissed by the masses.
* Mass adoption any day now! (Apparently the average Joe is about to want to take responcibility of his own actions and be unable to phone someone when he sent his bitcoins to a friendly Nigerian prince)
* Gavin's popularity is still somehow an "important" consideration.
@_date: 2017-04-15 22:39:55
Address reuse is bad mostly for privacy reasons and in some cases this is desirable e.g. a transparent donation address.
While reusing addresses makes them vulnerable to quantum computing these things don't exist yet.
@_date: 2016-02-05 22:24:59
While the exact size proportion is arbitrary the discount accurately reflects the increased cost of storing outputs versus inputs.
@_date: 2016-02-07 06:11:23
That may be true. If Bitcoin becomes centralized it will be pointless to deploy sidechains to it.
@_date: 2015-07-25 16:06:24
Open source doesn't mean it will definitely work. Currently it is only a whitepaper and a prototype is in the works but there is no evidence that it will indeed work. In fact the whitepaper mentions possible attack vectors.
@_date: 2015-07-13 11:34:33
If you have the UTXO set you also have the corresponding tx hashes. Or am I missing something?
@_date: 2017-04-22 21:02:17
How so? Run a gbt-to-stratum proxy on your local network and connect your hashers to it. Example: P2Pool.
@_date: 2016-02-24 12:12:05
The free market won't solve the centralization problem in the same way it won't solve slavery or environmental polution. We have laws for a reason.
@_date: 2016-02-05 21:23:16
They won't have a say if they don't run a full node either.
@_date: 2017-04-22 21:51:03
Obviously "nobody" was a hyperbole :)
@_date: 2017-04-22 20:55:57
After segwit activates developers can simply not work on a block size limit increase hard fork (which is completely unnecessary because litecoin doesn't have that much transaction volume). Who is going to fire them, the employees (miners)?
@_date: 2015-07-30 19:49:21
1. No. YOU are paying the fees to close the channel, not the hub. Also attackers do not always want to get rich directly. They can be rewarded for the disruption they cause.
2. You have no say in what type of channel happens between other hubs. Therefore no wallet can enforce the full script.
3. Maybe your lifestyle involves having your computer open at all times but thanks everything that is holy that not everyone is like that. And not everyone has their mobile internet open at all times.
4. What is the point of LN if you don't keep your channel open for a reasonable time? This is especially true for inter-hub channels.
Presenting LN as a scalability solution when it is not proven is wrong. Satoshi first made a prototype and then wrote the paper. And if there was a prototype people could actually contribute.
@_date: 2015-07-13 13:42:46
This can be calculated using probabilities. See 
@_date: 2016-02-26 13:35:14
Substitute paycheck with exchange withdrawal.
Anyway this is an extreme example. Onchain fees aren't going to become prohibitively expensive anytime soon. You will likely have no problem creating another channel.
@_date: 2017-04-14 07:29:44
Which are these computer scientists? Please don't waste our time by mentioning Gavin or Stolfi.
@_date: 2016-02-05 23:23:17


And it seems that we still have plenty of time to act.


Big transactions are useful (coinjoin, exchange withdrawals). Limiting the hashed bytes simply incentives more and smaller transactions which are less space efficient.
@_date: 2016-02-24 12:32:46
* signature verification
* UTXO DB update
@_date: 2017-04-09 15:03:39
There is a consensus rule that the coinbase must start with the block height. It just happened that when decoded as text the last byte was numbers.
@_date: 2016-02-01 21:34:50
There is more block space for inputs than outputs so having more inputs is cheaper than more outputs.
@_date: 2016-02-05 18:13:20
This demonstrates the difference between Core and Classic. Core aims to get rid of the quadratic scaling of signature verification while Classic aims to introduce further limits. Sure it would work if we deployed Gavin's solution but that would be the second time his half-assed solution became an integral part of Bitcoin's consensus code. Let's not repeat the mistakes of P2SH.
@_date: 2016-02-07 05:57:13
I think ~~Classic~~ Gavin's patches ~~is~~ are well tested. The wrongly tested part about XT was whether the network can handle 8 MB blocks and whether bandwidth will be increasing at 41% a year (can't be tested). They later implemented [broken "thinblocks"]( but this isn't part of Classic.
@_date: 2016-02-07 10:43:54
No, they require only majority.
@_date: 2016-02-20 22:07:32


No. It can be done as a soft fork.
@_date: 2016-02-05 21:25:42
The whole method works by lying about the times between blocks to artificially lower the difficulty. If you claim that 15 minutes have passed but only 10 have in fact by 24 blocks your timestamp will be 2 hours in the future. Therefore this is not a soft fork.
@_date: 2016-02-29 14:01:01
@_date: 2016-02-07 05:20:47
If they upgrade to software which ignores the previous best valid chain it will work. But the point of a soft fork is that you don't need to upgrade.
@_date: 2017-04-24 02:38:44
Greg Maxwell proved that decentralized consensus is impossible, which is correct. Bitcoin doesn't implement decentralized consensus only a very rough good enough (probably) approximation.
@_date: 2015-07-24 21:29:58
I mean when I'm reading through a thread and someone decides to post something stupid.
@_date: 2015-07-24 21:24:45
ELI5 why should I be forced to see idiotic posts?
@_date: 2015-07-13 13:57:21
I did my A-Level Statistics this year and can relate :)
@_date: 2016-02-21 21:23:15
From the POV of full node users economically rational miners might become attackers. Given that miners serve full node users the limit should and is decides by those users.
@_date: 2017-04-22 20:53:05
AFAIK stratum wasn't designed in competition against GBT. Transaction selection etc isn't something every hashing machine needs to do; a single server a miner controls can get a block template using GBT and send work to hashing machines using stratum.
@_date: 2015-07-24 08:29:36
A hard fork is a great way to force those who don't realize that updating a security critical piece of software is important. I suggest you to read the red parts (starting from the third point) of this page: 
@_date: 2017-04-22 21:34:29
There are tons of altcoins based on litecoin.
@_date: 2015-07-27 13:13:58
His node also downloads transactions and inv messages.
@_date: 2016-02-22 21:06:14
I'm just saying that you aren't following their rules.
@_date: 2015-07-23 17:09:14
However you think...
@_date: 2015-07-30 15:50:46
If you allow comments you could distinguish the list's comments using CSS.
@_date: 2017-04-24 03:48:54
Fortunately there is no voting in Bitcoin.
@_date: 2017-04-22 21:10:13
Nobody uses GBT's decentralization features (like transaction selection) either.
@_date: 2016-02-05 19:58:07




By definition you can't do these in a soft fork.
@_date: 2016-02-26 12:57:39
I don't think so. At least I agree with that statement.
@_date: 2015-07-13 06:11:40
Nobody is hurrying. If we followed Gavin's proposal the hard fork would happen in 2016. I don't think this is hurrying keeping in mind that the block size limit increase discussion has been here for years.
@_date: 2015-07-30 07:30:33
Except you are limited to quite simple transactions: goodbye programmable money! Also it is not as secure as onchain transactions.
@_date: 2016-02-26 20:35:44
If more than 50% of miners signal that they will go with an altcoin the rational move will be to switch the header hashing algorithm and fire all the miners.
@_date: 2016-02-29 11:20:15
I suppose the first 2 hex chars are `6a` (OP_RETURN) and the next two are the null-data length.
@_date: 2017-04-12 14:22:35
There is no difference
@_date: 2015-07-26 10:55:45
Actually we are already starting to have blocks where 1 MB was not enough: 
The increased frequency at about 1 MB suggest that there were some blocks which corresponded to mempool larger than 1MB, hence the increased frequency. This is because mempools lower than 1 MB would correspond to a wider range of sizes.
Edit: This doesn't mean that increasing the block size limit is an emergency; it shouldn't hurt anyone to wait a few blocks for a confirmation.
@_date: 2016-02-01 00:16:12
If miners can't be bothered to set their own configuration values we have bigger problems...
@_date: 2016-02-05 21:05:23
Or a [babysitter](
@_date: 2016-02-07 19:16:17
* [BIP16]( was activated with 55% threshold.
* [BIP17]( aimed to be activated with 60% threshold.
* [BIP30]( was activated on March 15, 2012, 00:00 UTC with no miner voting.
* [BIP42]( will be activated on block height 13440000 with no miner voting.
* Satoshi introduced various soft forks without miner voting.
@_date: 2016-02-27 16:07:01
Any input: 
@_date: 2017-04-22 21:36:32
This doesn't split the chain in two.
Not that it matters: whether there is a chain split or not is irrelevant to the strict technical definition of a hard fork.
@_date: 2017-04-16 04:45:08
(Compact) Fraud proofs are impossible to construct.
@_date: 2016-02-01 20:50:32
Ignoring that you are unqualified to judge the complexity (or really anything about segwit apparently) the reason for the scriptsig size limit discount is to incentivise UTXO consumption and disincentivise creation.
@_date: 2015-07-26 11:48:08
I started reading the paper and it appears that it will be structured like the internet: hierarchically. There will be few bigger hubs with a lot of smaller hubs connecting to them and then clients connecting to the smaller hubs.
@_date: 2015-07-27 13:56:45
Read [BIP42]( ;)
@_date: 2017-04-01 06:53:16
Frankly, if the market decided that PayPal is Bitcoin it would create some confusion to the name "Bitcoin" but Bitcoin itself wouldn't change.
@_date: 2016-02-05 20:31:22


The author ignores that blocks with timestamps larger than UTCnow + 2 hours would be ignored by not upgraded nodes.
@_date: 2016-02-05 23:29:56
If the fee to create UTXOs is higher and the fee to consume them is lower the overall fee at equilibrium will be the same as normally.
Unless you are arguing that fees won't rise so this whole blocksize increase is useless.
@_date: 2016-02-26 12:09:35
Why should you?
@_date: 2016-02-26 10:49:50
Why wouldn't an exchange/employer use LN?
@_date: 2015-07-26 16:06:36
It *could* since all a node needs is the UTXO set, but it would be difficult for nodes to find a specific part of the blockchain. In fact with pruning a node can discard data not longer need. The problem is that it currently can't signal which blocks it has so it doesn't help the network much.
@_date: 2015-07-26 11:38:53


I think it is too soon: just look at all those who run "full" nodes not enforcing BIP66. Beginning 2016 would be better IMO.
@_date: 2017-04-14 14:55:27
But BIP148 still doesn't force anyone to mine segwit transactions. The only thing it forces is setting a bit in nVersion which is hardly disruptive.
@_date: 2016-02-05 16:01:59


Of course it is consensus critical. Try modifying the limit to 0.5MB and tell us if you succeed syncing.
@_date: 2016-02-05 23:25:30
Then Gavin's limits will still need to be there forever even if inactive for newer blocks.
@_date: 2016-02-06 20:49:37
If the real difficulty drops low enough the not upgraded miners will produce a chain with most work according to not upgraded nodes (they aren't limited by the new POW) and the soft fork will fail.
@_date: 2016-02-06 21:23:48
If you buy miners in bulk directly from the manufacturer (or you are the manufacturer) and have cheap electricity it is profitable.
Maybe if you bought an S7 and you really have free or very cheap electricity you might break even but with the upcoming halving there is no certainty.
@_date: 2016-02-05 22:54:29


So you are advocating that we don't raise block capacity at all?
@_date: 2017-04-13 13:01:29
SegWit makes it so that even if you change a transaction in certain ways its ID will remain the same. This is useful for some smart contracts and in general for users relying on unconfirmed transactions.
MtGox *claimed* that they lost bitcoins because of the ID malleability.
@_date: 2017-04-23 03:44:24
Are they also not following the Bible?
\&gt;&gt; &lt;&lt;
@_date: 2016-02-24 17:38:57
Since headers-first 0.10 there were no checkpoints.
@_date: 2016-02-05 20:40:39
In the initial period the difficulty would rise significantly unless the timewarp attack would be used. And even then eventually the timestamps would need to keep increasing faster than the real time so the problem would be temporary.
@_date: 2016-02-26 05:33:30
You missed the network portion of the Lightning Network. The whole point is to form a web of payment channels and route through them while only having a few connections.
Edit: also higher value transactions can afford higher fees.
@_date: 2017-04-16 05:39:36
So if I cpu solo mine my full node suddenly becomes a true full node?
@_date: 2017-04-25 17:35:02
The Bitcoin URI format is
    bitcoin:your_address
but Medium probably won't recognize it. Just write your address at the end of your posts.
@_date: 2017-04-14 14:46:33
The study doesn't recommend a 4MB limit, let alone 8MB. It suggests that the limit could be raised without major disruption up to 4MB. This isn't something you will read from shit bitcoin news sites though.
@_date: 2017-04-13 17:55:04


Just because you don't understand the way these technologies scale doesn't entitle you to making analogies with bitcoin.
@_date: 2017-04-13 17:55:49
Miners are subsidized by inflation.
@_date: 2016-02-26 08:59:59
The Lightning routing problem is the same as the Tor routing problem.
Channels can be rebalanced using other channels.
@_date: 2016-02-03 04:36:44
This is the policy most miners follow (except the fee rate is higher).
@_date: 2016-02-07 10:48:27
They will make it better for those who actually want to use Bitcoin.
@_date: 2016-02-17 18:06:59
The Lightning routing problem is the same as the Tor routing problem: the burden of route finding is on the user. Tor solves that with semi-centralized directories but (hopefully) we can do better.
@_date: 2016-02-05 15:40:09
Well, of course it would be technically possible to turn Bitcoin into an inefficient version of PayPal but I don't see why would anybody sane (or not looking to get rich quick) do that.
@_date: 2016-02-07 11:16:52
But why would a miner do that?
@_date: 2016-02-10 20:58:00
From 0.12 you will be able to download only blocks and not participate in transaction relay.
@_date: 2016-02-23 20:11:32
@_date: 2016-09-17 14:27:25
No. Read the post.
@_date: 2015-07-07 07:51:54
SSL (or rather TLS) is only one of the components of the OpenSSL library. Thus no, you are not right. The *potential* problem is with the library, not the SSL/TLS protocol.
@_date: 2016-09-29 21:32:06
The same applies for full node operators and miners.
@_date: 2016-02-06 20:42:02
The Classic code is "good enough". But P2SH is also "good enough". We had/have better solutions which were/are dismissed because of politics.
@_date: 2018-11-02 10:10:31
Yeah but they banned a conspiratard and some people seem to agree with him.
@_date: 2016-09-21 07:41:00
2) The ID is just a number given to the connected peers. Each of your peers will identify you differently.
@_date: 2019-01-05 22:38:25
All frequencies get absorbed by plant and animal cells. You not understanding physics is not an argument.
@_date: 2016-02-23 05:13:46
I suppose he is already banned - see the other replies.
He is x-posting and linking to the sub which is prohibited according to its sidebar.
@_date: 2018-11-02 10:08:33
Or perfectly reasonable when you aren't an idiot.
@_date: 2016-09-17 14:55:59
The post is about the new joinmarket protocol.
@_date: 2018-03-09 12:42:36


In the same way as quacks are educating?
@_date: 2018-02-27 21:32:17
That's wrong, the amount you can receive depends on the capacity of the counterparty you are connected to. It's perfectly possible to create asymmetric channels. Also for larger amounts you may want to use on-chain payments anyway.
@_date: 2019-01-08 23:44:02
The consensus enforced limit was always 100 blocks but the wallet used to prevent spending before 120 blocks.
@_date: 2016-02-24 12:39:48
Core is multithreaded.
@_date: 2019-01-14 19:01:58
He isn't losing it because the UK government, like most first world countries, provide a lot more for their citizens than the US government.
@_date: 2019-01-26 14:37:51
Anyone with rudimentary knowledge of physics can debunk those arguments. 
@_date: 2019-01-26 15:42:51
There has been zero evidence that increased usage of mobile phones has resulted in increased cancer rates and there is no scientific explanation of how minuscule amounts of radiowaves could harm living organisms. Everything else is correlation which does not imply causation.
Note that this would not be the first time regulators sided with technophobes. GMOs are banned in the EU and California is labelling everything as cancerogenous. You know what else is cancerogenous? Life.
@_date: 2016-09-30 03:13:11
There are very few miners controlling the majority of hashrate. In LN though you can simply ignore those "key hubs" since you are choosing the route.
@_date: 2017-09-07 13:50:30
I, for once, agree with jtoomim. Small payouts is among the smallest problems p2pool has.
The biggest problem with p2pool is that it is python spaghetti code. The best way to improve p2pool would be to abandon it and write a decentralized pool from scratch in a programming language which doesn't encourage bad programming.
@_date: 2017-09-23 20:09:59
People using trusted wallet providers aren't using Bitcoin; they use some trusted third party. So why would their transactions need to be on-chain?
@_date: 2017-09-19 23:16:06
Blockstream Satellite requires [Bitcoin FIBRE](
@_date: 2017-09-20 12:16:09
That's what I said.
@_date: 2018-02-18 09:31:47
You can get the bottom of the stack using `OP_DEPTH` and `OP_PICK`/`OP_ROLL`.
@_date: 2017-09-23 20:02:29


I don't have a problem with people not using Bitcoin by why would their transactions need to be on the blockchain?
@_date: 2017-09-20 07:04:55
It does: you can't because 0.15 doesn't have everything needed for decoding what the satellite sends. You need to use FIBRE which can send block data over UDP.
@_date: 2018-03-09 12:40:05
We know that fiat is only valuable because governments are forcing its use and that's why we use a better system called Bitcoin which is useful on its own merit.
@_date: 2017-10-23 19:30:26


That's not entirely correct. Most softforks deployed to date don't force adoption of new rules by others but this isn't necessarily the case. If we were to force other players to use only their left hands it would still be a softfork (an observer still sees a basketball game) but players who want to continue playing basketball with us would need to adopt the new rules.
@_date: 2017-10-01 14:35:36
Anarchy is indeed the intermediary step to feudalism.
@_date: 2017-10-18 11:52:58
The general public doesn't use Bitcoin to begin with.
@_date: 2018-07-04 21:23:32


Except it doesn't. BIP70 does not take care of fees at all. It is still up to the wallet to decide.
@_date: 2017-10-02 16:52:23
Science doesn't care about your beliefs.
@_date: 2018-07-05 07:19:26


BIP70 does not allow rejecting transactions; the client is supposed to broadcast the tx on the Bitcoin network and the ACK from the server is just a confirmation that they have received it.
I suggest you read [BIP70]( Hint: it has nothing to do with ensuring adequate fees.
@_date: 2015-09-03 16:31:03
From the user's point of view changing habits doesn't make sense.
From the provider's point of view keeping users on inefficient protocols doesn't make sense.
I could provide web hosting for hundreds of users. Why would I want to do that? Same applies to full nodes. If we can reduce the number of transactions that individual nodes need to process I'm all for it.
The block size limit according to BIP101 is neither needed nor feasible. And don't tell me how miners will not allow spam; last time they increased their soft limits instead of lowering them.
@_date: 2018-07-05 07:10:56
Sounds like they haven't read the BIP.
@_date: 2015-09-19 22:25:37
ITT: redditors are outraged that not everyone is willing to process all their transactions for free.
@_date: 2015-09-03 23:02:45
@_date: 2015-04-14 10:40:33
Take a look at  although it hasn't been updated since 2014.
@_date: 2015-09-04 11:54:09
So when will you start paying fees to full nodes? As you said, if it pays (all full nodes), it stays.
@_date: 2015-04-11 15:50:44
This is because in order to have twice as fast blocks the difficulty would need to be half. Ultimately what matters is the amount of work that needs to be done to reverse a transaction.
@_date: 2018-07-16 15:16:53
Yes, you can set it with `port=????` in `bitcoin.conf`.
@_date: 2015-04-07 13:15:11
 doesn't show anything wrong. (link to the site was on 
@_date: 2015-09-06 07:18:10
As opposed to one Satoshi? Programming is not parallelizable that much.
@_date: 2018-07-05 20:21:50
The client is supposed to broadcast the transaction before receiving an ACK. As it should be with censorship resistant money.
@_date: 2015-09-03 06:22:33
BIP101 is exponential but the logarithmic graph is linear.
@_date: 2015-09-07 08:07:11
Back in the day there were more individual miners. Nowadays ASIC manufacturers mine themselves and they won't move from their own "pool" *obviously*.
@_date: 2015-09-05 07:24:08
Not really, initially I was supporting BIP101 but after reading up a bit more and doing my own calculations I concluded that it is not a good proposal.
@_date: 2015-09-05 15:32:58
Sorry, Bitcoin is meritocracy not democracy.
Right now it is XT that tries to change Bitcoin from trustless digital money to a low cost payment network. And even that won't be possible when SPV servers start to charge you.
By making it more difficult to run a full node you remove the ability to have a say in this system.
@_date: 2015-09-30 13:11:50
The paper is quite technical. Take a look at my simplified [explanation](
@_date: 2015-09-03 06:12:38
The people in favour of such big blocks are mainly using SPV clients so it makes no difference to them... until they would be paying SPV servers and possibly providing personal information to sign up.
@_date: 2015-09-01 13:02:59
1. Have a not high block size limit.
2. Increase minimum relay fee on my node when needed.
3. Ideally rework the way Bitcoin Core handles transactions by forcing spammers to pay more fees on transactions containing small value outputs.
@_date: 2015-09-20 17:06:37
1. I'm not advocating 1 MB forever
2. On-chain fees will rise
3. You will probably still make high value transactions on-chain
4. Smart contracts are mostly on-chain
@_date: 2015-09-02 20:23:18
Also I'm quite sure that while people understand that the fork could happen after the the earliest day the limit would increase as if it started on the earliest day.
@_date: 2015-09-02 05:56:03
I love how people aim to reach mainstream adoption *before* the infrastructure is ready for that...
@_date: 2015-09-03 06:41:16
If you encapsulate them in P2SH they are mostly allowed.
@_date: 2015-09-30 12:25:11
Of course it should. If you like it, it's useful. If not, you can completely ignore it.
@_date: 2015-09-05 17:54:18
Lightning Network (LN) is a more advanced version of payment channels (PC). In classic PC you fund a 2-of-2 multisig transaction and the two parties adjust the spending transaction as to reflect the balances each party will have at the time of settlement.
The problem with this is that all previous versions of the spending transaction are valid. A misbehaving party could publish an earlier version to the blockchain therefore double-spending part of the payments. We need to be able to revoke past versions of transactions.
LN solves this by having both parties exchange the private key used to redeem past versions of transaction and using new for each version. If one party decides to publish an earlier version the other can attempt to "steal" the funds as she knows the private key.
As of now there would be a race between the two parties as to who will be able to redeem the funds first. By using OP_CHECKSEQUENCEVERIFY we can specify that the attacker will need to wait 1000 confirmations (little less than a week) before being able to withdraw funds. In this time window you can detect the attempt on the blockchain and publish an appropriate transaction to take all funds immediately.
Until now we can update a transaction unlimited times where attempt of fraud will result in confiscation of coins. This allows us to construct a transaction that can be spent only upon disclosure of a secret value by requiring presence of a value which upon hashing gives a known result.
When you want to transfer funds the receiver generates a random secret and discloses its hash to/through all intermediary hubs which update their PC to reflect this hash. Then the receiver discloses the secret to the connected hub which now makes the updated transaction valid. The secret passes from hub to hub until all PC are updated. At that point the receiver can generate a new secret for further receiving.
If any of the hubs misbehaves the appropriate PC can be enforced via the blockchain and a new route is chosen. Therefore LN works kind of like Tor: intermediary hubs don't need to know who the counterparties are. If a route is not reliable a new route can be chosen.
There are obviously some shortcomings like the need to backup relevant information and publishing the revocation transaction when needed but these can be automated and the effort of the attacker might not be justified due to the risk of losing all coins.
@_date: 2015-09-03 11:24:48
@_date: 2015-09-03 06:10:17
It's not sigmoidal the rate of increase doesn't decrease after a certain time...
@_date: 2015-09-06 07:11:10
If it is on github everyone can share it. That's part of their terms.
edit: maybe not
@_date: 2015-09-03 11:35:17
I know it probably doesn't matter but that is a 100% increase.
@_date: 2015-09-20 10:23:34
I think you are missing the fact that people who don't run full nodes also make transactions, which full nodes have to process.
Also new users are less likely to run full nodes because they are more mainstream and the Initial Block Download (IBD) is taking longer.
Anyway the raw number of full nodes is not a great measure of decentralization. Anyone with reasonably modern hardware should be able to independently audit the ledger.
@_date: 2015-09-29 16:35:11
@_date: 2015-09-24 17:29:50
Increased orphan rate. It is peer-to-peer after all.
@_date: 2015-09-01 09:39:30
When nodes start to misbehave because of the large UTXO set we will see whether that will stop the network from working.
Also, do you think node operators are willing to store spam?
@_date: 2015-09-03 10:51:23
CPU mining is dead since long ago. You could probably GPU mine... two years ago.
@_date: 2015-09-25 18:57:56
Centralized pools are well connected and they can notify all their hashers almost instantly with stratum. That the difference is non-negligible became apparent when even F2Pool started SPV mining.
Stale shares also matter because not all peers have equal hash rate.
As for running a node - every miner can and should have one.
@_date: 2015-09-05 07:35:17
Most developers who are working on the reference implementation are against BIP101 and they certainly have technical understanding of Bitcoin.
The problem is not whether companies can run full nodes but rather individuals.
Also miners only decide about soft forks (which can be introduced as hard forks if needed).
@_date: 2015-09-30 17:50:37
Too bad "the public" doesn't know how to modify the software... Anyway most of them don't run full nodes so it doesn't matter.
@_date: 2015-09-12 08:22:52
At this point fees are low enough for spam to cause more damage to the network than to the attacker.
@_date: 2015-09-26 13:27:48
Highly inefficient since ASICs. CPU mining is dead since long ago.
@_date: 2015-09-30 18:23:55
Trustless means that you are able to take care of yourself. In the case of Bitcoin running a full node is the way to do it. You can use Bitcoin without running a full node but you are trusting that others will verify transactions for you.
This also means that you need to convince them to update to a new version of full node software.
@_date: 2015-09-30 19:31:43
I understand that not everyone will be running a full node which is why I altruistically run mine with accepting connections. Note that you can run your own without seeding so you don't need to open any ports. Just add `listen=0` to your config.
LN hubs should not be any more centralized than Bitcoin nodes or Tor relays. In LN intermediary hubs don't need to know the source/destination of your payment so censoring it will be pointless.
What will bring centralization is individuals not being able to run nodes.
@_date: 2015-09-09 07:16:08
[Look at my explanation](
@_date: 2015-09-30 18:38:35
Okay, I didn't mention that you are vulnerable only if you are receiving payments. I suppose you will be getting your paycheck on-chain and making casual spends on LN.
Or you will need to increase the channel lock from the recommended 1000 confirmations (~week).
@_date: 2015-09-09 07:31:55
Actually 2-of-2 multisig alone isn't enough as one of the parties could publish a previous version of a transaction to the blockchain. See my explanation for more details.
@_date: 2015-09-20 17:37:30
Can *you* show me some calculations? If I could predict such things I would be rich.
The general idea is that since LN fees will be low, users will not have a problem to pay higher fees for the funding/settlement transactions especially when more blocks start to be full.
@_date: 2015-09-03 22:47:48
The fork date on testnet should be in the past for testing purposes.
@_date: 2015-09-30 18:16:51
All you need is SPV. I'm quite sure you can get online once every few days therefore being able to keep the channel open almost forever.
@_date: 2015-09-05 16:34:28
I think you have no idea how Lightning Network works. If you want I can explain but you can read the paper as well.
@_date: 2015-09-03 17:44:17
no. but reindexing is getting longer and longer either way (leveldb corrupts the files occasionally). also bandwidth definitely doesn't improve by 41% every year.
@_date: 2015-09-03 07:56:31
Try to sync a node with current block levels and then think about 8 MB blocks please.
@_date: 2015-09-03 10:41:22




These two don't work well together as long as every full node needs to process all transactions. Lightning solves that by having multiple hubs process different transactions.


As opposed to profit oriented miners? (Blockstream didn't invent Lightning you know...)


Except nobody serious is arguing for that. We are arguing against proposals involving VISA level volume on chain. I'm not aware of any proposal for increasing the block size limit which wouldn't be enough for relatively short term transaction volume growth.


I don't see node operators rushing to switch to the alternative client. If anything I see an increase in full node count which suggests that nodes were launched to force the change (some of their operators are even openly admitting it).


What liquidity? For me the process of buying bitcoin hasn't changed since two years ago when I got into Bitcoin. The way transactions work hasn't changed either.
@_date: 2015-09-20 11:14:58
No, BIP101 is above global bandwidth growth even now and it is likely to slow down in the future. While you may think that full nodes in data centres is a reasonable idea I and a lot of other people don't think so. I would prefer Bitcoin to not reach mainstream adoption than to rely on centralized entities.
I think double-limit-when-subsidy-halves is a good simple method. Alternatively BIP103 but I agree that it may have a too slow start.
@_date: 2015-09-04 19:31:26
Having a lot of identities is basically a Sybil attack.
@_date: 2015-09-20 07:19:40
Correct. With payment channels/LN we could have sublinear scaling though.
Also Big-O is useful when the parameter is large. In practice the constant of proportionality matters.
Also note that in the case of centralized systems the whole system scales at O(n) and not O(n²) since the amount of nodes is more or less constant.
@_date: 2015-09-05 17:07:56
At least two independent programmers have developed prototypes.
@_date: 2015-09-02 07:00:28
There are a lot of improvements to be made before users who can't copy-paste can use bitcoin.
@_date: 2015-09-20 06:48:17
Sure. The conclusion came from the number of downvotes comments criticizing the blog post initially received.
@_date: 2018-07-05 07:15:03
If you have malware it could install its own CA and make a fake bitpay.com certificate. Once you have malware you are fucked.
@_date: 2015-09-30 17:15:57
Exactly, with a soft fork you can choose to not upgrade your full node. And even if you choose to upgrade, CLTV is a minor change to transaction verification.
Being able to introduce new features without having everyone upgrade is a feature not a bug.
@_date: 2015-09-07 08:35:21
This could be accomplished with fiber optic but with radio such speeds aren't possible over long distances. You could transmit data over multiple channels but still that doesn't scale well as you need to have separate components for each channel.
@_date: 2015-09-11 19:33:02
@_date: 2015-09-20 06:50:59
The problem is that the amount of resources required to run a full node are a function of *all* transactions in the network and not that which the operator makes.
@_date: 2015-09-30 18:49:10
Those who accept payments and verify transactions on their own indeed matter most since they can create a strong incentive to change the protocol to what they want. Full node operators don't have to upgrade though. The network could split with both chains having their merchants.
@_date: 2015-09-11 21:12:23
Follow the link and read my reply. Storing spam is never the good thing to do.


Who is us? Certainly not the majority of full node operators which store transactions.
@_date: 2015-09-05 15:40:44
I suppose mathematics are vaporware as well. /s
You clearly have no idea how science works. Go read the Lightning paper, it is the most complete.
@_date: 2016-10-17 11:35:24
You could create symlinks for a portion of the block files.
@_date: 2015-09-20 10:43:12
So you are basically saying that the whole network scales at O(n²+n') where n is the number of full nodes and n' is the number of lightweight peers (which technically results in O(n²) as Big-O specifies the asymptotic behaviour).
Anyway as I said elsewhere Big-O doesn't matter that much since the parameter cannot physically become large. The point is that each independent auditor has to verify all transactions in the network. With LN though each operator verifies transactions passing through its node plus the settlement transactions on-chain (and relatively few high value transactions), which is scalable.
Therefore I'm for a moderate increase to the block size limit in a way that doesn't substantially increase the resources needed to run a full node.
@_date: 2015-09-03 18:14:52
intel i3 3 GHz quad, 6 GB RAM, 500 GB HDD + 256 GB SSD, 10 Mbps down 1 up
@_date: 2015-09-09 21:15:55
It's a lightweight (SPV) client.
@_date: 2015-09-03 07:53:46
Well, since nodes can't just reject transactions once they are included in a block a sane limit is required. And this is not only a problem for current node operators but future ones; they will have to sync the whole thing.
On chain doesn't scale well and we shouldn't force it.
@_date: 2015-09-05 16:35:40
You can use a single channel to a hub to pay a lot of people.
@_date: 2015-09-01 09:32:50
When you receive a spam message do you delete it or record it on thousands of CD's and distribute them around the globe?
@_date: 2015-09-25 19:06:13


No. Most users would use centralized systems anyway even if using bitcoin the currency. If they don't care about the problem Bitcoin solves why should we care?
Bitcoin should scale with what technology allows; everything else is irrelevant. And since those new users likely won't run full nodes they won't have a say in technical matters anyway.
@_date: 2015-09-30 18:03:28
Cool, don't use it. We (node operators) won't care.
@_date: 2015-09-05 16:23:50
Inputs: at least one
Outputs: two
The size of the outputs will be a little bigger than multisig.
@_date: 2015-09-19 22:37:43
Every full node verifies transactions from all peers regardless of whether it is connected to them.
@_date: 2015-09-03 18:03:39
how would using linux help that? luke-jr was getting similar behaviour and he is using gentoo.
reindexing is limited by hdd/ssd speed, i have ssd and it still takes some time.
if it doubles every two years that averages at a sqrt(2) multiplication every year. if it was just a limit we wouldn't need a limit at all.
@_date: 2015-09-04 12:05:57
@_date: 2015-09-08 16:43:25
Big blocks *are* hostile to Bitcoin. Maybe not to centralized providers but they can and already do use more efficient protocols (the traditional banking network).
@_date: 2016-10-29 20:36:53
Actually he has rather poor technical understanding. He wrote a book on Bitcoin which basically plagiarised the [wiki](
@_date: 2015-09-01 11:45:51
If I flood your inbox, will the messages be spam or not? I want a specific definition.
@_date: 2015-09-03 18:07:41
recently i had to reindex without power loss
edit: luke-jr has the opinion that 1 MB is currently is too much (which I have to admit might make sense) but still is in favour of a conservative increase of the limit.
@_date: 2018-04-16 22:29:57
They are just hosting it, they didn't create it.
@_date: 2015-09-03 09:40:35
I'm more against the fast growth rather than the sudden stop.
@_date: 2015-09-30 18:33:51
Using the most powerful computational network is not an inherent right. If you are not willing to perform full validation and pay for its security then perhaps you shouldn't be using it; there are a lot of people willing to do the above.
It would be great if we could provide access to many people but technology allows for it up to a certain point; after that off-chain solutions will be necessary.
@_date: 2015-09-07 08:19:36
BitFury: 15%
KnCMiner: 9%
21, inc.: 4%
Edit: At what point is Bitcoin destroyed? When home users can't run full nodes? When SPV users need to pay SPV servers? When SPV servers need to have an AML/KYC program? All this already exists within the current banking system.
@_date: 2015-09-09 07:17:18
I suppose relevant data will be written to your disk or even backed-up to your prefered cloud storage.
@_date: 2018-04-16 22:31:59
I didn't create it, but it's called running your own full node.
@_date: 2016-10-23 13:06:52
You probably won't make profit but if you want to learn, SP20 is a good miner.
Though keep in mind that the company behind it ceased operation so you will experience some difficulties.
@_date: 2016-10-20 18:35:41
ISM did have a 95% threshold for mandating the new rules. It also had a 75% threshold for new rules to be enforced for blocks *which signal readiness* to do so.
@_date: 2015-11-23 11:02:27
Blocks were never 80 bytes. That's the size of a block header.
@_date: 2015-11-05 22:48:49
Your math doesn't check out. Let's assume that we live in an ideal world where 3.9Mbps = 0.4875MB/s. It would take 16.4 seconds to download such block. Also upload bandwidth is generally lower than download.
@_date: 2015-11-05 20:14:09
You mean like not everyone runs a full node?
@_date: 2015-11-24 16:25:40
I'm not arguing that not full blocks are not fine but the amount of low priority transactions is potentially infinite so it is okay if they get delayed.
Also you need to understand that the stale block risk exists only because miners can lose the subsidy. Once it becomes less significant the risk goes away and miners have an incentive to include more transactions, to the point that it may be profitable for them to attempt to stale other blocks if they don't have enough transactions to bother mining (suddenly stopping mining is impractical at scale). That will not be a problem for a while so we don't need to worry from now though.
@_date: 2015-11-29 23:08:40
Replaced transactions will be relayed.
@_date: 2015-11-28 21:07:18
* Developers can work on whatever they want
* It hasn't been released yet (0.12 is scheduled for February 2016)
@_date: 2015-11-28 21:53:01
Yes, unless miners manage to reverse a transaction.
@_date: 2016-10-30 13:10:19
People who lack basic arithmetic skills shouldn't be using computers in the first place.
@_date: 2015-09-05 16:41:00
I'm on mobile right now but I will be glad to explain a bit later.
@_date: 2015-09-20 11:38:40
Any altcoin could have larger transaction capacity, in fact most of them do due to higher block rates. Bitcoin has the network effect which may allow us to have both decentralization and high transaction capacity through trustless off-chain solutions which are being built. If you are not going to run a full node what difference is there in transacting though Lightning or on-chain? LN has also the advantage of instant secure transactions.
Also, isn't Bitcoin a 'niche' at this point? Why do you think mainstream users will care whether they use off or on chain?
And I don't care much about the price.
@_date: 2015-11-08 12:52:51
The value of the block size limit is in the existence of an upper-cap of the resources a full node consumes. Running a full node is important to not going through middle-men as there is no difference between your own transactions and others. On the other hand an SPV node will relay only its own transactions and request filtered blocks so the full nodes it connects to are essentially providing a service (this is why the functionality will become [optional](
SPV wallets also have the limitation that servers can omit transactions. This is why even if you are not going to run a full node, which I understand is not feasible for everyone, it is important that most full nodes are operated by independent parties, preferably individuals.
Full nodes are also what keeps miners in check. Without them a majority of the hashing power could alter almost any rule, including coin ownership, and SPV clients wouldn't know.
Therefore I think it is important to not make it too difficult for individuals to run full nodes. Instead we should focus on a moderate increase of the block size limit and trust-less off-chain solutions like the Lightning Network. Since each LN hub will have to process only a fraction of all transactions we could achieve a higher transaction capacity without risking centralization.
@_date: 2016-10-20 08:36:46
I would say it's comparable to P2SH. New transaction type and also deployed in a soft fork.
@_date: 2015-11-05 13:40:52
You could sort comments by "controversial".
@_date: 2015-11-29 14:18:18
That makes even less sense.
@_date: 2016-10-17 14:04:49
Calling some altcoin bitcoin won't make it so.
@_date: 2018-04-14 04:06:20
You are still accepting bitcoin IOUs that way. You would need to be able to use your own full node.
@_date: 2015-11-18 17:57:58
If the other side doesn't have quality arguments...
@_date: 2015-11-23 22:22:15
Or we could design a system that uses Bitcoin's smart contracts to secure off-chain payments.
@_date: 2016-10-14 09:57:18


Yeah, sure.
@_date: 2015-11-27 18:17:15
I know how to do both.
@_date: 2016-10-17 09:49:22
But there is no vote. Miners don't have a say in *whether* but *when* the fork activates so that they don't lose money. If they refuse to upgrade we might need to fire them by changing the hashing algorithm. They are employees of Bitcoin's users after all.
@_date: 2015-09-01 17:14:38
If a transaction contains many small value outputs or forms a long chain of unconfirmed transactions it can be safely classified as spam and should pay higher fees.
@_date: 2015-11-07 02:05:40
Except everyone is allowed to discuss all sorts of proposals. Threatening to force a change, like Coinbase does, is not allowed though.
@_date: 2015-11-22 23:09:49
You need "centralized" SPV servers otherwise. Or you can run your own full node + hub since the costs of running a full node will be reasonable.
@_date: 2015-11-28 20:53:57
This is exactly what wallets should do.
@_date: 2015-11-27 15:56:05
If you "signed up" you are doing it wrong.
@_date: 2017-05-27 00:55:44
Why should we listen to big block populists and do a hard fork when segwit offers enough on-chain capacity increase?
@_date: 2015-11-05 21:55:49
Plain Bitcoin is not broken; it's just that it won't be enough with increased usage.
@_date: 2015-11-07 19:37:54
The idea is that in such scenario calling the 1MB version, or whatever else, "Bitcoin" would not be fair. Essentially the definition of Bitcoin would have changed.
@_date: 2015-11-29 21:50:44
Bitcoin Core 0.12 is scheduled for February 2016.
@_date: 2015-09-03 09:44:53
I don't understand this reasoning . Are on chain transactions the only method that could ever exist? Good that not everyone thinks like that.
And yes, speculators leaving would be a good move IMO.
@_date: 2015-11-07 07:10:24


Who are those?


Denying that big blocks is a centralization pressure will not make it true. I've already explained why it is like that.


That is still their job.
Remember: Bitcoin was created to reduce the need for intermediaries. If you want to use one you are free to do so but you should not expect others to sacrifice decentralization to fit your or some company's needs.
@_date: 2015-11-09 00:28:05
Only apps with root access can read other apps' data.
@_date: 2015-11-14 21:07:46


Except they don't.
@_date: 2016-10-21 19:29:21
You don't know the script until it is spent (in P2SH).
@_date: 2015-11-04 12:36:50
Actually yes, Bitcoin alone is not good at micropayments.
It is as if you were saying that it is bad that boats don't fly.
@_date: 2015-11-28 21:42:47
Technically yes but then someone would release a client accepting RBF even without the flag.
@_date: 2015-11-07 06:45:48


Who told you that? Right now using SPV wallets is reasonably safe because there are a lot of full nodes to enforce the rules. Too big blocks will make it more difficult to run one.
On the other hand if you are using Coinbase as a wallet you should not be concerned about technical details at all; it is their job.
@_date: 2015-11-03 15:40:33
It is implemented, the wallet will be enabled in pruning mode in Bitcoin Core 0.12.
@_date: 2015-11-13 16:34:54
Since CLTV/HODL will be encapsulated in a P2SH output we won't be able to know.
@_date: 2015-11-24 18:36:51
I refer to people with technical knowledge of how Bitcoin works. The effects of larger blocks are increased difficulty of auditing the legder (running a full node) and mining centralization which have been addressed even by proponents of big blocks.
@_date: 2015-11-28 17:59:38
More FUD that Bitcoin Core is controlled by Blockstream...
@_date: 2015-11-07 06:13:26
We do like adoption; it increases the usefulness of the currency as more places accept it. We don't like sacrificing decentralization for adoption's sake and trying to force a hard fork.
@_date: 2015-11-23 10:49:54
As long as you pay a reasonably high fee it is predictable.
@_date: 2016-10-30 14:10:31
→ ←
@_date: 2015-11-22 23:15:45


Almost nothing. Hubs don't need to be trusted so the software will just need to route through another hub.


Not really, smaller hubs could be used for micropayments exclusively.


That is not a problem since your wallet could choose which route to follow. If you care about decentralization you could route through smaller hubs paying somewhat higher fees.
@_date: 2015-11-09 12:35:34
Yes and so do upgraded full nodes. But this is after the majority of miners express their readiness to enforce the new rules.
@_date: 2015-11-18 18:10:53
Yeah, Peter R shouldn't be ridiculing himself.
@_date: 2015-11-14 20:55:14
*Most* people in developed countries should be able to run a full node or otherwise the network is essentially controlled by corporations. People should have the ability to reject any change to the protocol.
@_date: 2015-11-16 20:50:04
I'm not saying that a merchant can't accept an unconfirmed transaction but it is misleading to believe that they are secure. Double spending is not difficult even without RBF. Also it will be optional and turned off by default so no one can complain.
@_date: 2015-11-14 20:11:43
I wouldn't be so optimistic about consumer bandwidth growth. ISPs no longer have the same incentive to deploy new technologies since most customers don't care. Browsing Facebook or watching Netflix isn't that bandwidth intensive as running a full node will become.
@_date: 2015-11-05 20:25:56
Cool, run your own then.
@_date: 2016-10-31 06:03:22
I'm not talking about mathematics. Division is something you learn in primary school arithmetic. I'm fairly certain if someone doesn't even know primary school stuff s/he won't like the "take responsibility for your own actions" nature of Bitcoin.
@_date: 2015-11-29 14:41:22
The rule for transaction validity is very simple: if a full node you trust confirmed that the transaction has enough confirmations.
@_date: 2018-04-17 14:41:00
One works, the other is an altcoin which likely is a scam. Go figure.
@_date: 2015-09-28 19:27:46
The new opcode would just instruct miners to double spend a transaction; no new bitcoins would be created out of thin air because that would make the blocks invalid to non-upgraded nodes.
Anyway it has been known since the release of the whitepaper that miners can attempt to reorg the blockchain so it doesn't change anything.
@_date: 2015-11-05 21:04:47
Sure, just not too much as that would hurt its decentralization. I'm not advocating not increasing the limit at all.
@_date: 2015-11-05 05:22:02
Miners decide only on the order of transactions (and soft forks) because those are the only technical aspects of Bitcoin where truth is subjective. A full node can't know what everyone else believes accurately so we need a way to reach consensus: proof-of-work.
Everything else, including but not limited to the block size limit, can be and is indipendently verified by full nodes.
You are allowed to discuss and promote changes to the protocol but promoting an implementation without general agreement within the community is equivalent to promoting an altcoin which is off-topic.
Either way I'm sure most miners are well aware of the existence of XT and they are free to run it. It seems that they don't want to.
@_date: 2015-11-14 21:34:39


They haven't succeeded in transforming Bitcoin?


Why should I care? Those supporters aren't paying the costs of running full nodes.


No, unless you have the ability to choose the protocol version.


Or that they benefit from centralization. Seems to be working for PayPal.
@_date: 2015-11-15 18:51:39
Paging @_date: 2015-11-28 23:46:22
Each transaction input has a 32-bit sequence number (hence the maximum is 2^32 - 1 = 4294967295). These were originally meant for replacing transactions before inclusion in a block with updates by incrementing the sequence numbers. When the sequence numbers reached the maximum value the transactions were considered "final" in that nodes wouldn't accept further updates. Currently the vast majority of transactions have maximum sequence numbers. Unfortunately this feature was a DOS attack vector since updates were free and it was disabled. The solution to the DOS problem is to require updates to pay higher fees. RBF is born!
So don't believe anyone who says that RBF is against the "original vision" since RBF in fact restores it.
As an aside sequence numbers will be used for *consensus* transaction replacement by requiring that certain versions of a transaction have to wait more time after the parent is confirmed. More info [here](
Edit: **Sources:**
* 
* 
@_date: 2015-11-15 15:36:18
Are you using MultiBit Classic?
@_date: 2015-11-29 00:32:17
The greek variant is axiocracy (αξιοκρατία - axiokratia). So the antonym would be anaxiocracy (αναξιοκρατία - anaxiokratia).
@_date: 2015-11-25 12:33:39


And you expect people to take you seriously...
@_date: 2015-11-13 17:39:12


@_date: 2015-11-07 06:18:09
We aren't getting our way? The statistics on  show otherwise.
@_date: 2015-11-29 13:52:36
bitcore (javascript library) != bitcoin core (full node software)
@_date: 2015-11-27 18:15:43
RBF has nothing to do with consensus rules. No fork is needed.
@_date: 2015-11-05 21:00:19
Oh those evil devs, finding bugs which could be really dangerous. Pure evil!
Removing off-topic comments is not censorship.
@_date: 2015-11-28 22:11:50


They (transactions) have a sequence number lower than the maximum. Technically it would be possible to soft fork to disallow it.
@_date: 2015-11-16 20:13:44
I think you misunderstood. They don't care about your *opinion* and they shouldn't. If you have some reasonable arguments you are free to participate.
Bitcoin never provided security for unconfirmed transactions and it is misleading to think that 0-conf is a thing.
Plus, as you can see, there are far more important and interesting issues than the block size limit.
@_date: 2015-11-30 22:02:20
Isn't Eligius supporting getblocktemplate? I think you can set your own version.
@_date: 2015-11-27 04:11:44
@_date: 2015-11-07 19:28:01
Yeah, I was talking about the version where payment channels can remain open indefinitely.
@_date: 2015-11-14 21:22:06
These companies aren't a majority. Also just because some redditors were vocal doesn't mean that they have economic significance, especially since most of them don't run full nodes.
It would be an interesting experiment if those centralized companies tried to push a hard fork for real. If they succeed it means that Bitcoin is not really decentralized and maybe we should look for some other solution.
@_date: 2015-11-04 13:07:50
Fees are still below those of credit cards so it shouldn't be a problem in the near future.


It depends on what you consider "artificial" but yes, I and others would restrict it's growth if the growth would threaten its decentralization.
@_date: 2015-11-07 22:52:20
The ELI5 version would be:


Same with plain Bitcoin or VisaNet. The difference is in the technical details.
@_date: 2015-11-05 21:14:26
I guess we agree then.
@_date: 2015-11-05 21:01:33
Yes. It's not like we have an alternative.
@_date: 2015-11-20 19:31:27
You seem confused. You can learn [here](
@_date: 2015-11-07 21:27:01
How would that work though? From what I've read in the paper the revocation tx spends from the funding so without sighash_noinput the revocation transaction needs the txid of the funding before it is confirmed. With CLTV we could transform the funding transaction from simple 2-of-2 multisig to (2-of-2 multisig or user-sig + CLTV) so that the funding tx can be confirmed before the revocation is constructed. This way the receiver will need to publish the final version of the tx before the locktime to ensure she gets the funds.
@_date: 2017-05-27 12:58:57
So you want a cartel enforcing artificial production quota. Because otherwise there will always be miners making bigger blocks to get more fees.
@_date: 2015-11-15 18:56:23
could you update the bot to show the BIP65 deployment status?
@_date: 2015-11-29 00:43:22
aka populism
@_date: 2015-11-05 20:18:22
Do most people use colored coins? LN is supposed to offload trivial transactions which take most of the block space.
Although technically there could be hubs specializing in certain assets.
@_date: 2017-05-27 13:56:35
Why wouldn't a miner say "I will also include the 20 sat/byte ones?"
@_date: 2015-11-29 17:37:44
Not strictly antonym but yep. Demagoguery ("controlling/driving people") is indeed what Mike Hearn is doing.
@_date: 2015-11-05 19:16:11
Nodes need to be protected from attacks precisely because processing them is costly.


Well, Bitcoin is defined by what software the economic majority is running. I would be surprised if node operators chose to make it a lot more difficult for themselves to run one.
BIP101 is not a compromise; almost every other BIP is.
@_date: 2015-11-23 10:23:01


If you are directly connected to the misbehaving hub then yes but you should be connected to more than one hub at once.
If it's an intermediate hub you are not directly connected to you can go through another already existing route and it will be some other hub's responcibility to settle.


This wouldn't be such a problem since hubs don't need to be trusted. At worst you will need to route through a smaller hub charging more.
@_date: 2016-05-02 20:53:22


At least they had evidence in the form of 18 hours of static being recorded.
@_date: 2015-11-25 12:44:44


You seem to not understand how Bitcoin's protocol works.
@_date: 2015-11-28 18:49:28
I think anyone should be able to alter his/her own transaction before it is included in a block. After all, there is no consensus that the transaction exists at all before it goes into a block.
Edit: [Possible use case](
@_date: 2015-11-09 12:09:31
Soft forks require hashpower majority for that reason.
@_date: 2015-11-01 21:53:44
Yes, via  .
@_date: 2015-11-16 21:32:46
In your example it is irrelevant whether RBF is deployed since the merchant *trusts* that you won't risk going to jail for a beer. They are not relying on Bitcoin's security.
But if I really wanted to risk I would run a script on my server which tries to double spend when I send payments.
@_date: 2015-11-09 13:47:10
You are welcome :)
@_date: 2015-11-28 21:12:57
[I would like to remind everyone that transactions were always meant to be replaceable.](
@_date: 2015-11-13 15:10:28
By default their wallet will not recognise transaction outputs with OP_CLTV in them as theirs.
@_date: 2015-11-28 17:37:12
The receiver can refuse to accept unconfirmed replaceable transactions.
@_date: 2015-11-20 19:28:57
He is saying that XT is vulnerable. Core is fine because there is no hard fork voting (yet).
@_date: 2015-11-30 12:41:17
The *Low Orbit Ion Cannon* would also be [fun](
@_date: 2015-11-14 20:57:38
I respect your opinion but you should not expect people who run full nodes and essentially define the protocol to agree with you.
1. So a moderate increase is not a hard fork? If an altcoin community wants to increase centralization so be it. Bitcoin is not ready for mainstream adoption for a lot of reasons, mainly that the average person does not want to have responsibility over his/her own actions.
2. The size of the community has nothing to do with it. Only your own full node counts.
3. Again, you can run whatever software you want.
@_date: 2015-11-28 19:46:21


It depends on the definition of the "bitcoin community". If the community includes people who have no idea what they are talking about then yeah, you may be right. Such community should be ignored though.
@_date: 2015-11-14 23:39:46
Without running a full node you will not be able to "fork off". That is the issue.
@_date: 2015-11-28 21:28:01
No. If it was possible we wouldn't need miners.
@_date: 2016-10-27 15:49:53
Who cares about the masses? Even if Bitcoin could support their transactions they would still not use it because it requires taking responsibility for your own actions. The average idiot isn't going to do it.
@_date: 2015-11-14 21:39:56
If the economic majority decides that transactions should carry identification data the protocol will be altered in such way and without running a full node you will have no way to protest. Centralized wallets already collect personal data so this is not an impossible scenario.
@_date: 2015-11-29 16:05:33
[Satoshi]( and Core developers disagree with you.
@_date: 2015-10-03 10:34:59
This makes no sense; mempool flooding is not a problem as users can just raise their fees. Flooding the UTXO set on the other hand - that could seriously damage the network.
Edit: The soft limit affects the blocks the miner who has set it makes; not others.
@_date: 2015-10-01 17:57:59
If you run an updated full node you will be rejecting new invalid blocks. Only SPV clients are affected which is true for both soft and hard forks.
@_date: 2015-11-29 16:59:46
I see your reading comprehension isn't the best...
@_date: 2015-11-14 20:49:09
*Currently* most people don't have Google fiber and the 1MB limit is bearable (though still a full node is resource intensive in terms of bandwidth and storage). Therefore the limit growth should start from the current limit and at a pace not above predicted resource availability growth.
@_date: 2015-11-09 11:47:38
CLTV replaces ~~NOP1~~NOP2 which currently does nothing. If the time conditions are right the script will continue as if there was NoOPeration. If not the script will fail and should not be inside a block. Therefore not upgraded nodes will have no problem accepting new blocks and hence we have a soft fork.
@_date: 2015-11-05 20:20:28
Increasing the limit continuously is not a solution on its own either. There needs to be a moderate increase *and* deployment of off-chain solutions.
@_date: 2015-10-16 17:41:23
You will need to convince the wider ecosystem that 8 MB is indeed the optimal limit and then the developers will implement it.
Alternatively you can offer a bounty to modify Bitcoin Core to have a configurable limit but at that point it would be an altcoin.
@_date: 2016-05-29 13:14:04
Well, externally imposed restrictions are the best.
@_date: 2015-11-07 08:00:40
Why not? Most transactions will go through off-chain solutions like Lightning Network anyway.
@_date: 2015-11-24 15:51:59
Since full node count is continuously decreasing I think it is safe to assume that it is no longer just the convenience of lightweight  clients.
Enough full nodes is when practically anyone who wishes to audit the ledger can do so. Of course there will always be more powerful nodes but it is important that a significant fraction of individuals enforce the protocol rules.
We are bumping into the 1 MB limit frequently because that is the natural state of blocks; miners need to have an incentive to build blocks even after the subsidy fades away. Since the average block size is currently about 0.5 MB there is no reason to jump straight to 8 MB. I agree though that increasing the limit to 2 MB sometime in the next year would be reasonable.
edit: spelling
@_date: 2015-11-07 07:12:29
Bitcoin is defined by the software the economic majority runs. It has nothing to do with mods or devs.
@_date: 2015-11-05 22:21:57
No, I mean if the limit would stay at 8MB for some time.
Downloading a block should take at most half a minute so that the average node can contribute to the block relay. Also what if I turn of my node for some time? What if someone wants to bootstrap a new node?
Storage is not that much of a problem but still, not using SSD is starting to degrade performance.
@_date: 2015-11-14 19:49:33
Except that is precisely the reason the limit was put in the first place: to limit the amount of resources a full node consumes so that individuals can run them.
@_date: 2015-11-25 19:14:32
Yeah, you have no idea what you are talking about.
Bitcoin is a system where compatibility is critical therefore the actual code is the protocol. This is not strictly Bitcoin Core though. There's also Bitcoin LJR, btcd, Statoshi and other custom implementations with varying degrees of certainty of compatibility with the economic majority.
Now, not all code of a full node is consensus critical. For example how the UTXO set is handled or whether it is stored separately at all is implementation defined. Block pruning is also not consensus critical as storing full blocks is not strictly  needed (you do need the UTXO set in some form though).
As for CLTV and other soft forks they had consensus among people who bothered to understand what they do so it's not like devs with merge access decided it on their own (note that Blockstream doesn't even control the GitHub repository despite Mike Hearn's FUD).
And don't even get started on the block size since they are not the only ones who oppose handling the protocol as a toy or a centralized project.
Remember when Gavin tried to [push a soft fork without developer consensus]( Unfortunately he succeed.
@_date: 2015-11-23 22:30:33


Someone has to write the code. If you can't do it yourself - tough luck.
@_date: 2015-11-13 15:19:45
Block rejection based on nVersion happens using the [ContextualCheckBlockHeader]( check. So why do we need 951/1001 v4? IsSuperMajority should be true if we have 950/1000 v4 *already*. We reject the current block if `block.nVersion &lt; 4` and supermajority.
Edit: To clarify, this happens before other checks.
@_date: 2015-11-24 06:55:18
Most people having deep knowledge in the issue are concerned with the effects of larger blocks and their arguments make sense. Most bandwidth predictions also are below BIP101's growth. So it is your ignorance that you deem the risk negligible.
Bitcoin doesn't need a good image for the masses yet since the masses don't want to use a system where they actually need to take responsibility for they own actions.
This is how open source works; developers are free to work on whatever they want.
@_date: 2015-11-07 12:07:26
Everything you have said becomes irrelevant when you realize that *not everyone has to use Bitcoin*. The technology has its limitations so processing every transaction on-chain is not feasible. Therefore it should scale in accordance with technological advancements and ideally there should be no long term planning as we can't reliably predict the future.
BIP101 is above predicted technological advancements so adopting it would not be wise.
With the subsidy decreasing the incentive for miners to include as many transactions as possible increases so eventually the "natural" state of blocks will be being full.
It would be great if we could accommodate everyone with no downsides but the reality is different.
@_date: 2015-11-22 23:57:06
We don't increase the block size limit too much so that there is some competition between transactions resulting in higher fees. Either way LN can't conduct all types of transactions (for example timestamping) so there will always be demand for block space.
@_date: 2015-11-29 13:04:40
Another use case is that entities doing a lot of transactions can continuously add new outputs to existing transactions instead of making entirely new ones.
@_date: 2015-11-05 20:16:22
Since your wallet software will be able to choose which route to use to send a payment centralization will not be a problem. Is Tor centralized because some relays have higher bandwidth?
@_date: 2015-11-23 21:26:51
All those months of debating and you still haven't understood the arguments of the other side?
@_date: 2016-05-01 07:52:02
Well, getting rid of get rich quick bagholders is desirable.
@_date: 2015-11-08 12:55:59
There is one more slash in the xpub example link than needed.


@_date: 2015-11-05 19:58:33
There is also BtcDrak's [BIP105]( which introduces miner voting with difficulty penalties for voting for an increase.
@_date: 2015-10-28 06:56:55
It does scale, just not for big companies which want to bloat it (they can use [ChainPoint]( for their purpose).
@_date: 2016-05-31 13:05:39
Unless your rig has so low hashrate that you won't be able to recoup its costs before it dies.
@_date: 2018-07-29 06:20:51
When companies are too incompetent to build a mobile website on their own.
@_date: 2015-10-04 15:26:23
No, that would mean that the signature signs itself.
@_date: 2015-10-23 17:13:44
It depends on the exact script but probably not.
@_date: 2015-11-05 20:37:31
Extraordinary claims require extraordinary evidence. Where is yours?
@_date: 2015-11-28 17:49:04
There was [developer consensus]( and this is a node policy change. At least developers wanted it so here it is.
Why would merchants waiting for confirmations anyway refuse RBF transactions?
@_date: 2015-11-23 10:34:14


You can also set up payment channels whith as many hubs as you want.


Not a problem with onion routing proposed.
Either way centralization is not a problem since hubs don't need to be trusted and you can choose to pay more fees to any hub of your choice (like an individually run small hub).
@_date: 2015-11-28 23:56:40
It is possible with SIGHASH_ANYONECANPAY. This is what Lighthouse uses.
@_date: 2015-11-13 15:06:22
So if we have 950/1000 v4 and we receive a v3 block it will be accepted?
@_date: 2015-11-04 12:23:40
Technically it is possible to introduce bigger blocks via a soft fork. Basically the main block contains the hash of the extension block which is transmitted separately.
@_date: 2015-10-13 15:21:41
All your devices should have their IPv6 address publicly accessible so port forwarding is not needed.
@_date: 2015-11-14 18:54:55
I think the ~41% yearly increase is risky. I like the double-limit-when-subsidy-halves idea (~19% yearly increase), until 32MB. At 32MB there will be enough space for medium-to-high value transactions and during the 5 halvings/doublings we will be able to see how full node count changes, whether off-chain solutions work as expected, etc.
But I think the scaled down BIP101 could be a potential compromise. Perhaps doubling every three years?
@_date: 2015-11-09 12:56:45


Only the 5% of non-upgraded miners. [Version bits]( will have one retargeting period for the remaining miners to upgrade but the proposal is not ready for this soft fork.


Correct as far as they are aware. In the unlikely scenario when the majority of miners stop enforcing the soft fork a split will occur. That would be really bad.
Edit: Seriously I don't get who is downvoting you.
@_date: 2015-11-04 12:45:22
Reject, similarly to updated full nodes.
@_date: 2015-11-27 19:52:54
You create two transactions, one paying to the merchant and one paying to yourself. The first should have a very low fee, include OP_RETURN outputs etc. Basically you want it to be unlikely to be mined. Then you broadcast the first one and shortly after the second. With a bit of luck the second will be mined. The only cost is your time to prepare such system and possibly the somewhat higher fee of the second transaction.
@_date: 2016-05-21 17:22:44
Under perfect [Exponential distribution]( with μ=10:
* 36.8% of all blocks take longer than 10 minutes to be generated.
* 4.98% of all blocks take longer than 30 minutes.
* 0.248% take 60 minutes or more (which happens about once every 2.8 days)
@_date: 2015-10-02 15:24:50
For Lightning it is preferable to have CHECKSEQUENCEVERIFY actually.
Soft forks take about 6 months to activate.
@_date: 2015-10-09 12:16:18
Miners relay their blocks through a special network and are connected between themselves nowadays so the setting wouldn't affect the longest valid chain according to the economic majority which consists mostly of centralized entities. Therefore we need to come up with a limit which allows individuals to run full nodes if they choose so.
@_date: 2015-10-01 15:50:51
The node the SPV client connects to makes specific transactions possible.
I suppose the fee will be configurable so possibly there will be people running hubs out of pure altruism. I don't think taking a small fee is bad though.
At worst hubs will be ran as hidden services.
@_date: 2015-11-28 15:54:30
Unconfirmed transactions are not part of Bitcoin's consensus rules. Relaying/accepting double spends is part of each node's policy.
@_date: 2015-11-29 13:46:11
Yes. Just replace with a version with all sequence numbers set to the maximum.
@_date: 2017-05-24 16:18:20
Bitfury does sell miners but they are large containers not for the general public. They also sell their chips to resellers. Check out 
@_date: 2015-11-27 17:36:07
They were always easily double spent.
@_date: 2015-10-18 06:59:49
I just wanted to be sure about the exact method used since I will probably use Bouncy Castle.
@_date: 2016-05-31 18:31:08


It has its own 12V power supply.
For USB only the GekkoScience Compac is the best.
@_date: 2015-10-13 15:56:33
Well, I would have expected ISPs to initially offer IPv6-over-IPv4, not IPv4-over-IPv6... Have you tried contacting them?
@_date: 2015-10-01 06:20:48
If you are using an SPV wallet and the majority of miners decide to remove the 21 mil cap you will have no way to detect it. This is why full nodes are important.
@_date: 2015-11-13 14:51:06
It introduces a new opcode, [OP_CHECKLOCKTIMEVERIFY]( which allows constructing transaction outputs which can be spent only after a specific date or block height.
@_date: 2015-11-29 18:31:00
If you don't need absolute security there are other methods but it is important to realize the tradeoffs.
@_date: 2016-05-28 18:21:53


AFAIK the Blockstream method will have some basic fraud proofs.
@_date: 2016-10-30 05:37:52
You have to download every tx to fully verify even a single transaction because that's the only way to tell if an input to your transaction exists or not.
You may later delete used transactions, aka pruning.
@_date: 2015-11-05 21:34:07
It will be some time before on-chain fees become high enough to discourage medium value transactions. Initially LN will be used for micropayments like gambling, tipping, etc.
@_date: 2015-10-09 13:48:29
Well, you would expect that banks and governments would act in the benefit of their users but unfortunately that is not always true. With that proposal we assume that humans will be acting in an economically rational way which simply isn't always true. Also it is economically rational for companies to grow big, maybe too big (think PayPal).
Relying too much on human behaviour doesn't make much sense in terms of a digital currency. We should try to limit the ways humans can do bad things. Agreeing on a limit everyone will have to follow is such way.
Of course if you are running a full node you can participate in the discussion and eventually choose what software to run. But since Bitcoin is all about consensus we should try to reach one.
@_date: 2015-11-27 18:02:16
Block *times* are an Exponential distribution. Block *numbers* in a given time interval is a Poisson distribution.
@_date: 2017-05-27 00:23:14


\&gt;&gt; &lt;&lt;
@_date: 2015-11-23 10:29:24


Settlement transactions should have higher fees so that they have higher priority.


Similarly to Tor routing. Though you are right that there is still a lot of work.
Micropayments are fine on LN since settlement will not be a micropayment.
@_date: 2015-11-22 23:17:47
Salaries will probably be paid on-chain since they are high value enough to warrant the increased fees.
@_date: 2015-11-05 20:28:20
Centralized codebase? Who forced them to run it? Have you considered that the popularity of Bitcoin Core might be because of it being actively developed?
@_date: 2016-05-30 04:18:17
Wait, isn't he talking about the first input of a generation transaction?
@_date: 2015-11-15 15:51:56
You can import it into another instance of MultiBit Classic.
I would suggest though to install MultiBit HD, create a new wallet, write down the wallet words and send your balance to the new wallet. Then you will be able to import your wallet into as many computers as you want using only the wallet words.
@_date: 2015-11-05 19:37:23
Last time I checked full node operators are not paid for processing transactions so increasing the limit too much should not and will not happen (unless Bitcoin is not supposed to be decentralized).
When Lightning Network gets deployed you will be able to expect PayPal/Visa-level transaction volumes since each hub needs to process only a subset of all transactions and is paid for that.
@_date: 2016-05-21 17:35:17
You shouldn't. Nobody is forcing you to use Bitcoin.
@_date: 2015-11-07 12:13:33


I'm not advocating not increasing the limit at all. I would be fine with BIP103, BIP105, double-limit-when-subsidy-halves and maybe BIP102 as a temporary measure.
@_date: 2015-11-28 18:43:42
See eragmus's response.
Edit: [Here we go](
@_date: 2015-11-14 20:07:05
If all you care is performance go use your credit/debit card.
@_date: 2016-05-28 17:26:35
You could have Bitcoin miners vote on whether to process cross-chain transfers or sidechain miners providing proof-of-work for the Bitcoin network to verify. In both cases anything happening inside the sidechain needs its own consensus mechanism. In both cases also miners can steal coins.
@_date: 2016-05-01 18:52:23
Luke's emergency proposal is SHA3 which is GPU minable. Also it's simplicity (relative to for example scrypt) would mean that an ASIC wouldn't be difficult to design.
@_date: 2015-10-04 21:31:31
Great summary!
2000 bits
@_date: 2015-10-16 04:25:23
Bitcoin Core measures block sizes in bytes not bits, so you will need to use 1 MB instead of 8 Mb.
Just add blockmaxsize=1000000 to your bitcoin.conf.
@_date: 2016-05-08 20:43:05
ExtraNonce can be as large as you like; it's not really a field as far as consensus goes.
@_date: 2015-10-19 12:15:36
Is it possible to remove conflicted transactions from the transaction list in Bitcoin Core?
@_date: 2016-05-24 12:10:28
Yes? Who told you democracy works?
@_date: 2015-10-01 09:40:48
If you are connecting to an SPV server it makes specific transactions possible. In LN hubs are neutral as well. Anyone can run one and make a little money processing other transactions. Do you see Tor relays as non-neutral?
@_date: 2016-05-29 15:49:36
With CLTV you can keep the keys and not be able to spend for some time. Your advice applies to the "traditional" way of timelocking coins.
@_date: 2016-05-21 17:43:00
Nope. The Normal (Gaussian) distribution is symmetrical around the mean and has two tails.
@_date: 2015-10-17 21:07:13
Not OP but I'm also working on a GUI. I'm translating your code into a C# SPV wallet and I have a few questions:
* Would you like me to port the alert stuff?
* The crypto box thing just holds the EC pubkeys or is there something specific to libsodium?
@_date: 2015-10-03 14:18:07
Elements Alpha is a sidechain of the testnet but it is not decentralized.
For decentralized sidechains at least an appropriate soft fork would be required.
@_date: 2016-05-21 07:52:04
I'm not saying that a particularly cryptocurrency is a scam. My point was that you are appealing to the authority of the market (which obviously didn't work for all the scams).
@_date: 2016-05-31 06:49:34
Well, I guess people used to be very interested in snake oil.
@_date: 2015-11-25 19:17:13
AnonobreadlII's response satisfies me.
@_date: 2015-11-29 11:06:23
@_date: 2015-11-13 16:22:44


Node operators.
Say we have 950/1000 v4 blocks on our local block chain. Should we start rejecting *new* v3 blocks? Or should we wait for the next v4, i.e. 951/1001 v4, making it a fencepost error in the implementation? From what I see the implementation is OK.
@_date: 2015-10-23 16:35:56
This is an inherent limitation of SPV wallets which shouldn't be used for receiving bitcoin with a low number of confirmations from strangers. As long as you use an upgraded full node or an SPV client only for spending you are fine during soft forks.
The only disadvantage of soft forks is the limitation of rules which can be changed without much complexity which wasn't a problem in this case.
@_date: 2015-10-02 17:47:15
Probably shadowbans or reddit's spam filter. Nothing to do with the mods of this subreddit.
@_date: 2015-10-01 16:53:15
Not to mention the nasty checkpoint Satoshi Nakamoto introduced upon the genesis block.
*Mines a block. Creates a checkpoint to ensure it doesn't get orphaned.*
@_date: 2017-07-03 00:30:14
The burden is on you to prove the viability of "obvious" block size increases.
@_date: 2017-07-09 22:01:29
It may use flood style routing but unlike Bitcoin it doesn't flood transactions which are much more data heavy.
@_date: 2015-11-04 20:26:20
Miners creating big blocks is costly to node operators so my point stands.
The costs of bootstrapping a new node is continuously increasing. Also BIP101 has faster growth than global bandwidth growth so even existing nodes would become more costly.
@_date: 2015-10-19 19:07:27
@_date: 2015-10-31 20:49:55
Then maybe try to increase the amount of UTXOs you have. Generate a few (&gt;5) addresses and send your money to them. Your wallet software will be able to select a fraction of them each time.
@_date: 2015-10-29 18:34:37
Did you read the linked post? ChainPoint can timestamp practically unlimited documents in a single transaction. They would need to send a transaction maybe once per hour.
@_date: 2015-03-15 13:05:12
Transactions in Bitcoin consist of inputs and outputs. When sending bitcoins you are spending some of the outputs you can unlock and create new outputs for the receiver to spend. Thus transactions form chains like:
1. A -&gt; B -&gt; C
2. K -&gt; L -&gt; M -&gt; N -&gt; O
where the letters are Bitcoin addresses (they could be not but that's another story).
Obviously chain 2 is longer. Some of them can have hundreds of transactions which you may want to exclude from the reported number.
@_date: 2016-05-20 17:39:05


Not really, the only change is a restriction so it's a soft fork.
@_date: 2016-05-04 18:34:11
Well, there certainly should be more than one person having the ability to remove access to the repo. That doesn't change the fact that Gavin is not a good choice. Also Bitcoin != Bitcoin Core.
@_date: 2015-10-03 07:48:45
Because it is pointless with 1 MB blocks? Either way it does happen when there is a "stress test" and some of the spam transactions are included in blocks.
@_date: 2015-10-15 19:17:45
Why? In plain Bitcoin you would lose the funds forever. At least in LN if the counterparty cooperates you can retrieve your (relative's?) funds.
@_date: 2015-10-17 18:04:07


Also, `start.Arguments = string.Format("\"{0}\" generate", WalletToolPath);`; FTFY.
@_date: 2015-11-23 10:48:51
What does PC usage have to do with fees? As long as you pay a reasonably high fee it is predictable.
@_date: 2015-11-14 21:28:23
You can't be sure about the correctness of the block chain unless you run a full node. If an individual can't do this they are trusting someone else. Miners have an incentive to be honest just because the economic majority keeps them in check. If the economic majority decides to change the protocol even against the will of the users the miners will follow.
@_date: 2015-11-07 06:25:33
The [economic majority]( which consists among others of centralized wallets/payment processors/exchanges like Coinbase could try to force a change despite user disagreement since they are the ones receiving bitcoin.
90% of non-technical people do not know what they want. Let me explain:
* If they care about decentralization big blocks are a threat
* If they care about low fees they should use off-chain solutions
* If they care about speculation exchanges don't need to conduct every trade on-chain
@_date: 2015-11-06 14:11:58
Selling a million euro hamburger isn't a compromise just because you could sell it for a trillion.
Changing the limit *is* easy in the technical sense. Changing the definition of Bitcoin should not be easy though. If it was easy to change the block size limit it would be easy as well to change the inflation schedule; they are equally simple changes in terms of code.
@_date: 2015-10-03 03:49:55
You can message [this user]( on bitcointalk.org with your PINs, Bitcoin address and a photo of the receipt.
@_date: 2015-10-17 17:10:46


So do SPV servers and centralized wallets.
@_date: 2016-05-19 00:02:42
* μBTC: microbitcoin or me-bee-tea-sea
* mBTC: millibitcoin or em-bee-tea-sea
@_date: 2015-11-05 22:05:52
Currently we don't have full blocks, just an increased usage due to the rapid increase in price - this will not last long. Next year we will probably reach consensus on a limit increase so that we have more time until LN is ready for the production environment.
Yes, the plan is to eventually use LN for casual transactions where high security is not needed and on-chain for higher value transactions and settlements.
@_date: 2015-10-15 19:08:00
WTF are you talking about, both Electrum and MultiBit HD are available for Windows and work well.
Also there is the NBitcoin library for .NET development.
@_date: 2016-05-05 16:23:17


Regardless of what you thought Bitcoin is not a democracy. No amount of voting will change reality.
@_date: 2015-10-01 08:35:40


I know how Bitcoin works. Most devs seem to think alike anyway.


Again, I know how Bitcoin works...
@_date: 2015-10-12 19:00:31
Is it possible to remove conflicted transactions from the transaction list in Bitcoin Core?
@_date: 2015-11-05 19:59:34
Hubs are decentralized; anyone could run them.
@_date: 2016-05-20 01:20:43
It was rejected because not only the idea (getutxos) is fundamentally broken but the implementation was buggy.
@_date: 2015-10-02 17:22:23
By my count there are zero censored posts excluding the downvoted ones.
@_date: 2015-10-09 17:12:19
I was referring to nodes choosing the limit when writing about big blocks being accepted by the economic majority.
If we let miners vote for the limit there should be a maximum cap as a safety measure. Even better if voting happens similarly to BIP 105 where miners would be incentivised to increase the limit only if there is true demand for it.
@_date: 2015-11-25 12:15:02
I don't get why people are so attached to what the creator hoped. The engineering reality is far more important.
@_date: 2015-11-28 18:13:33
F2Pool started producing v4 blocks before Bitcoin Core 0.11.2 was "officially" released.
@_date: 2015-10-18 13:56:59
I will leave that approach for :)
@_date: 2015-11-14 20:31:36
Bandwidth predictions are below 41% so you can't argue otherwise.
Either way I don't think that the limit will ever need to be 2GB. Bitcoin is inherently a settlement system so we should focus on deploying payment systems on top of it. If we had no idea how to do it trustlessly I would be more in favour of large growth rates but Lightning Network looks promising from the technical perspective.
@_date: 2015-11-05 21:21:58


Or, you know, switch to some other hub? Like a DNM hub?
@_date: 2017-07-10 08:07:11
That's a false dihotomy. Coibase already offers off chain transfers for internal payments, why would they offer SPV services for free?
@_date: 2015-11-05 21:16:47
Yep. Even at 1MB the difficulty of running a full node has increased.
Maybe it would be bearable if it was constant and not doubling every two years.
@_date: 2015-10-15 16:58:49
Hubs function like routers: they form a web of payment channels. The  "IOUs" are valid Bitcoin transactions which can be broadcast to the blockchain at any time.
Read my [explanation]( of how it works. There are more links in this thread as well.
@_date: 2016-05-21 08:30:43


I'm asking again: are pyramid schemes useful because of their market?


If it is a pump and dump scheme i.e. bringing meaningless changes.
I don't think Ethereum is a scam since its smart contracts are an interesting experiment (the premine doesn't inspire confidence though).
@_date: 2015-11-14 20:51:17
So your solution is to commit to a long term scaling plan and hope we don't end up with a glorified version of the banking network?
@_date: 2016-05-20 16:55:03
And could be implemented in a soft fork.
@_date: 2015-11-05 20:24:08
This could happen with regular Bitcoin full nodes as well if governments really wanted to.
Although the hub doesn't have custodial control of user coins so it is essentially only routing them.
@_date: 2015-10-10 17:50:58
For script validation there are multiple flags/modes. One of them is [SCRIPT_VERIFY_CHECKLOCKTIMEVERIFY]( It is possible to verify different things in mempool ([AcceptToMemoryPool()]( and in blocks ([ConnectBlock()](
@_date: 2016-05-28 18:20:40
Unfortunately  that's not possible for the same reason perfect fraud proofs aren't possible: full nodes (or SPV clients in the case of fraud proofs) would need to download the whole blockchain(s).
@_date: 2015-11-23 10:25:06
The fee is updated every time you do a transaction.
@_date: 2015-11-05 21:08:35


I agree. The increase may not be enough to accommodate all transactions though so other solutions will be needed.
@_date: 2015-10-01 06:48:06
Accepting 0 or low confirmation transactions without using a full node is inherently insecure. Nothing new here.
Nobody objected so there is consensus. And since it is an uncontroversial change there is no reason to believe miners will not adopt it.
@_date: 2017-05-14 05:26:23
It is unspendable because in the original bitcoin implementation the outputs of the genesis block weren't added to the utxo set.


@_date: 2017-07-09 08:18:00


Might as well use "verifiable" banks.
@_date: 2016-05-31 18:41:37
They used to sell replacement controllers. See [here](
@_date: 2016-05-16 17:06:25
These are "votes" on CSV not SW.
@_date: 2017-07-24 09:36:19


@_date: 2015-10-10 10:37:54
An upgraded node will not mine or relay transactions invalid under future rules but will accept them if they get into a block.
@_date: 2015-10-01 08:36:37
So you agree that the same applies to normal Bitcoin nodes.
@_date: 2015-10-15 13:15:40
Set DB cache to zero and you won't have these problems.
@_date: 2016-05-19 05:58:30
`getnetworkinfo` in console should have reachable: true for the respective networks.
@_date: 2015-10-23 18:29:04
Not only you do not understand what [full nodes]( do and how [Lighning Network]( works but you are also under the impression that [CLTV]( is only useful for LN.
@_date: 2015-10-01 07:00:58
There were no objections to the opcode. And since Mike's claims are incorrect we can safely ignore him. Objections without justification are irrelevant.
@_date: 2016-10-06 18:08:53
The public key can be recovered from the signature and checked against the address.
@_date: 2015-11-13 17:48:34


You don't need a pubkey. The redeemScript could be:
    &lt;now + 3 years&gt; CHECKLOCKTIMEVERIFY DROP DUP HASH160 &lt;pubkeyhash&gt; EQUALVERIFY CHECKSIG
@_date: 2017-07-10 08:05:13
Seems you have a lot to learn to be able to participate in the scaling debate.
@_date: 2015-10-17 21:26:13
I will preserve your abstract class structure. Initially I'm going to implement SPV and then maybe Bitcoin Core as BlockchainInterface.
Do you know if libsodium does something else other than ECDH?
@_date: 2015-10-17 21:53:22
I'm translating your python code into a standalone C# application with a GUI. This way the application could display more info to the user and there would be more control of the coinjoin process. Alternatively I could modify the python script to allow interacting with a GUI but it shouldn't take a lot of time to translate and then I will have more control over what the backend does (I'm more familiar with C
@_date: 2015-11-13 14:45:53
I know but why wouldn't it be 950/1000?
@_date: 2015-11-14 20:36:05
LN should suit your needs. I don't think we should commit to a long term scaling plan before we consider alternatives.
@_date: 2015-10-16 02:35:24
This can and will be automated by wallets. You would just need to be online once in a while depending on the lock period.
Also, if you are technically illitarate you might be already using centralised wallets so it will still be an improvement if you use a reputable hub which doesn't control your keys.
@_date: 2015-10-04 15:20:16
Are you talking about SIGHASH_NOINPUT?
@_date: 2017-05-27 02:10:23


This is why it is wrong to be a big blocker. You think you understand the trade-offs because populists like Gavin, Mike et al simplified them for the uninformed masses (who don't actually use bitcoin in the first place).
Witness data do not have to be stored forever in the UTXO (**U**nspent **T**ransact[**X**]ion **O**utput) set so they are cheaper to validate. UTXOs OTOH impose a cost on full nodes for ever as for each block the set has to be updated and the larger it is the more costly it becomes.


That means ~0 fees, like we had in the past. Why would a rational actor pay fees when the transaction will confirm anyway?
Anyway there is no argument about "on-chain vs off-chain". It is "decentralized-off-chain vs centralized(Coinbase/BitPay/etc)-off-chain".
@_date: 2017-07-24 22:25:00
By changing the pow algo Core would prevent becoming an alt.
@_date: 2015-10-31 21:12:13
Eventually yes as the change goes only to one output. Though I suppose once in a while you will be getting new bitcoins from elsewhere.
@_date: 2015-11-27 16:12:44
Developers are free to work on whatever they want. If you want something else either develop it on your own or pay someone else to do it. You should not expect others to agree with you though.
If you don't like it or think that you didn't agree to such "rules" I suggest you to read the MIT license under which the reference implementation is licensed.
@_date: 2015-11-07 18:17:50
Lightning Network would need a malleability fix, which while would be possible to achieve in a soft fork ([draft paper]( Appendix A Resolving Malleability, page 56), it would be better to achieve this during some other hard fork.
@_date: 2015-10-24 17:33:33
Once Lightning Network will be deployed full node operators will be able to run a hub or accept micropayments for serving SPV clients. In the meantime projects like could provide a small revenue.
@_date: 2015-11-03 22:17:23
Droid Sans: [sentence]( [character](
@_date: 2015-11-01 21:53:49
I've read somewhere that bitcoin.com was a misspelling of bitchin.com.
@_date: 2016-05-29 12:49:04
Do you think if I use CLTV now it will still work in a few years?
@_date: 2015-10-15 18:51:21
If you die the hub will be able to steal some of your funds.
If the owner of the hub loses the keys you will be able to steal a part of their funds.
Keep in mind though that you are only vulnerable if you receive payments.
@_date: 2017-07-09 21:44:20


@_date: 2017-07-09 22:30:27
Bitcoin's block gossip model is absolutely a problem related to scaling.
@_date: 2017-07-22 18:15:01
100% of miners are irrelevant to a hard fork.
@_date: 2017-07-10 08:04:48
Seems you have a lot to learn to be able to participate in the scaling debate.
@_date: 2017-07-24 07:54:20
Why would Core turn itself into an altcoin?
@_date: 2015-10-01 06:16:43
How would introducing CLTV via hard fork be different then? At least with soft forks we don't need to care about laggards.
The attack vector you are thinking of is the 51% attack. Bitcoin makes a strong security assumption that the majority of miners will not censor transactions against the community consensus.
There was consensus on merging CLTV into Core.
@_date: 2015-10-24 22:00:40
Mycelium doesn't use SPV; it queries centralized servers for blockchain data.
@_date: 2016-05-02 20:10:30
The preimage attack wasn't used or Bitcoin would be broken.
He just reconstructed the partial transaction which is hashed for signature verification.
@_date: 2017-07-09 21:41:38
Gnutella is a great example because it failed because of its flood network design similar to Bitcoin. Which is why BitTorrent's DHT is superior similarly to LN.
@_date: 2016-05-29 15:52:26
With CLTV you don't need to specify the spending transactions until you will be actually spending. Before CLTV you needed to construct a spending transaction with a locktime in the future, sign it and destroy the key for the input.
@_date: 2017-07-04 16:16:08


@_date: 2017-07-09 14:04:11
Assuming you can. In this case you don't.
@_date: 2015-02-23 21:23:57
It is not as you can see by following the link I provided. I used port 833 for example.
@_date: 2015-11-09 12:14:01
Comments like that show precisely the ignorance some people have about the issues discussed.
@_date: 2017-07-20 14:14:57
No. Segwit/BIP91 is happening. The HF will almost certainly be rejected.
@_date: 2016-05-20 16:59:36
There is no separate consensus mechanism in LN other than the underlying blockchain.
So he is wrong. Not the first time either.
@_date: 2017-07-22 18:12:50
The majority of nodes are segwit ready. The 2x part ain't happening.
@_date: 2017-07-09 16:31:08
PayPal should be good enough for you.
@_date: 2017-07-19 06:28:56
It is almost as static as the merkle root in headers i.e. not at all.
@_date: 2017-07-19 21:58:36
An unnecessary hard fork will be contentious especially when hacks like that are needed. One of the goals of segwit is to proceed towards a single resource limit to improve fee estimation.
@_date: 2017-07-24 09:37:49
Miners will probably know the intention of the economic majority in advance.
@_date: 2015-11-21 15:31:30
@_date: 2015-11-05 21:03:43
@_date: 2016-05-31 15:11:33
Antminer S7
@_date: 2015-11-26 21:42:20
@_date: 2017-07-19 21:55:19
Yeah, cultural differences totally don't exist just because communication has improved /s
@_date: 2015-11-28 19:28:18
It can't be because a full node can't know which transaction was first.
@_date: 2015-11-18 18:09:36
Not to mention that suppliers (full nodes) don't get paid by costumers.
@_date: 2017-07-09 14:08:46
Keep telling it to yourself. If it's so easily debunked why hasn't anyone done it?
@_date: 2016-05-21 07:26:11
Is the temporary "success" of a scam a sign of "merit, usefulness, and value"? I guess if the market says so...
@_date: 2015-10-18 07:48:18
There is a wrapper but since NBitcoin already uses Bouncy Castle I thought I would just go with it since I have used it before. If there is some problem with compatibility I will use libsodium as well.
@_date: 2015-10-28 13:08:00
For what exactly would they need higher capacity? Timestamping can be done efficiently [already](
@_date: 2015-10-17 18:15:41
LN hubs can share transaction information in the same way normal Bitcoin nodes can. In fact a hub will not know about transactions not passing directly through it.
Please try to understand the context *before* wasting our time.
@_date: 2017-07-29 23:54:37
Hashrate is irrelevant to hardforks.
@_date: 2017-07-24 07:38:17
Except the hard fork wasn't accepted.
@_date: 2017-07-29 18:46:08
Dream on
@_date: 2017-07-19 18:02:23
The tree wouldn't be empty though.
@_date: 2016-05-28 22:07:08


The default code [limits the version to at most 4]( My [pull request]( would need to be merged to change that.
@_date: 2017-07-19 21:49:47
No. The commitment is derived from the wtxids which are hashes of the whole transactions, i.e. both the witness and non-witness parts.
Edit: OTOH txids are hashes of the non-witness parts.
@_date: 2016-05-01 18:14:28


No. It's how hard it is to mine a block *relative to an attacker*. Miners abusing their power are by definition attackers.
@_date: 2017-07-24 21:30:46
A proof-of-work algo change is a perfectly reasonable action against misbehaving miners.
@_date: 2016-05-02 19:26:45
No. This could cause a fork if the result would be different for different nodes.
@_date: 2015-11-30 09:07:52
[BIP42]( is close enough.
@_date: 2016-05-05 08:58:31
* [P2Pool](
* [kano.is]( against [SPV mining](
* [Eligius](
@_date: 2017-07-18 14:14:02
Bitcoin doesn't solve the byzantine general's problem, it only provides an approximation.
@_date: 2017-07-04 09:30:07
Since your wallet determines the path you could avoid big hubs. Unless you mean that merchants will use big hubs exclusively which already happens with Coinbase.
@_date: 2017-07-09 16:30:11
By not verifying yourself you provide a financial incentive for miners to collude and disobey the consensus rules. For example if everyone is using SPV miners are incentivised to make huge blocks and centralise validation to their own servers. And by miners I mean an ever decreasing number of them.
@_date: 2015-02-23 21:14:26
[You can choose any port below 1024](
@_date: 2015-11-04 13:27:57
Care to elaborate? The limit was indeed put in place to not make the cost of running a full node too high.
@_date: 2017-07-20 09:43:55
There is nothing wrong with running Bitcoin Core. In fact it offers the maximum independence and privacy. The downside is that it uses a lot of resources and it probably doesn't let you send your bitcoins because it is still synchronising.
@_date: 2015-11-29 13:11:20
Correct. Also they don't need to have so many transaction outputs ready for new transactions.
@_date: 2015-02-22 14:07:13


OK, true. My point though was that Electrum's seed is not just any seed.
Why wouldn't the other explanation be suitable for new learners? After all OP doesn't seem to be interested in a very technical explanation.
@_date: 2017-07-23 23:57:13
His second mistake is thinking that miner support matters.
@_date: 2015-10-31 19:06:30
In Bitcoin Core you can send bitcoin to multiple recipients in a single transaction; just click "Add Recipient".
In Electrum go to Tools → Create transaction → From CSV text.
@_date: 2015-11-24 15:05:25
Empirical data suggest that even 1 MB is enough to make most users not run full nodes. A few days of testing bigger blocks is not enough to replace the empirical evidence we see every day. The more important issue though is that BIP101 proposes a ~41% yearly growth which is above predicted bandwidth growth.
Also there is the issue that an 8 MB limit is not needed at all...
@_date: 2015-10-02 17:51:30
I wrote [this explanation]( about how it works but maybe you would want something more specific?
@_date: 2015-10-24 18:53:30
There hasn't been a formal proposal AFAIK but that could be a potential use-case for micropayment channels. Serving SPV clients will be [optional]( though.
@_date: 2017-07-19 06:23:43
In theory bitcoin works under certain assumptions. In practice those assumptions have worked so far but that doesn't mean we don't have to work to keep them like that.
@_date: 2017-07-25 06:04:45
Have you ever used Usenet?
@_date: 2017-07-17 23:39:15


[citation needed]
@_date: 2015-10-01 06:12:14
It is not helpful in terms of resources but it is in terms of decentralization of blockchain verification.
You can have open channels with multiple hubs; how is that different from connecting to multiple SPV servers?
Since LN hubs don't have custodial control of user funds in terms of regulation they are like Bitcoin nodes.
@_date: 2017-07-09 21:39:04
That doesn't mean we should incentivise them to be dishonest.
@_date: 2017-07-09 09:04:27


Like bank-level confidence?
@_date: 2017-07-09 21:37:10
Bitcoin is already out-competed by PayPal for people who don't care about financial sovereignty.
@_date: 2016-07-31 08:00:03


Once you [install]( it (which isn't that difficult) you simply point your miners to the local node. Then you can forget about it until there is some fork and need to upgrade (which is very easy). Notices about the need to upgrade are posted on various communication channels.
@_date: 2016-07-03 16:51:04
Isn't your `vector` actually a matrix though?
@_date: 2016-07-02 19:52:17


I don't need to. Bitcoin isn't going to change because of users' incompetence.
@_date: 2015-11-13 14:32:11


Is this a continuation of the long tradition of fencepost errors in Bitcoin programming, famously introduced by Satoshi Nakamoto himself, or is there some other reason for those odd numbers?
@_date: 2016-07-03 15:54:55
You mean an N-dimensional vector.
@_date: 2016-07-02 16:09:49


One of the owners of the bitcoin.org website/domain.


Non-idiots generally don't judge a piece of text based on who wrote it but what it says.
@_date: 2016-07-01 19:37:11
The jr in luke-jr isn't junior.
Luke Dashjr  
luke(dash)jr  
@_date: 2016-07-02 16:26:11
Let me explain then.
There are a lot of people who treat the original whitepaper as the gospel. This is problematic and the author raised the issue and asks for comments on how it should be resolved. It's not even a pull request.
@_date: 2015-10-09 13:13:35
Correct, that was my point. The economic majority consists of companies which are paid by their users to run nodes so they will be able to accept blocks larger than individuals therefore centralizing Bitcoin. Also SPV wallets don't validate so they will follow the longest chain.
It's better to agree on a single function across the network since communication is hard either way.
@_date: 2015-10-17 22:15:47
C is Windows specific but it will probably work with Mono as well which is cross-platform. Think of .NET as Java of Microsoft.
@_date: 2015-10-12 12:01:34
Someone would need to prepare those "service packs" and that would be a centralized entity.
@_date: 2016-07-02 20:23:56
Most people who process transactions do not get paid at all.
@_date: 2016-07-30 16:12:07
It takes less space to store a small target than a big one since zeroes in front can be omitted.
@_date: 2015-02-23 23:50:32
This is what I'm talking about, you can forward 833 (or any other port below 1024) to $localip port 8000. Then in point 13 you execute:
    curl -H 'Accept: application/json; indent=4' -d 'bitcoin_address=$address' -d 'url= 
Note the port number in the `url` parameter. Look at my [node](
@_date: 2015-02-22 12:52:45
You are right that computers use seeds to generate random numbers but this is not the seed OP is referring to.
See 's [answer]( Electrum's seed is only user input. For the first time Electrum uses PRNGs to generate the seed but in order to generate the private keys it uses techniques such as hashing the seed or the previous private key. Of course the actual method is more sophisticated but the system time is not used since the keys generated need to be the same for each trial.
@_date: 2016-07-02 19:50:44
Sorry, religion is generally off-topic in this sub.
@_date: 2016-07-02 19:57:16
The current Bitcoin developers don't care about "Satoshi's vision" and such nonsense so I don't need to switch.
@_date: 2016-07-01 12:44:33
Only if it fits a particular group's agenda.
@_date: 2015-02-22 14:46:12
* 
* @_date: 2016-07-29 13:59:21
Why should we care what the majority of the population thinks?
@_date: 2017-07-22 18:53:56
The commitment isn't required if there are no segwit transactions.
@_date: 2016-07-02 16:51:59
It is [mostly]( correct because it doesn't include a lot of detail.
@_date: 2016-07-29 16:50:07


I don't think Bitcoin is a get-rich-quick scheme.


Things that influence the masses aren't always good.


Opinions are irrelevant to reality.
@_date: 2016-07-02 19:49:29


That's exactly the reason the link should redirect to a page explaining why the paper is no longer relevant.
@_date: 2016-07-02 16:32:47
But you can't change the original paper. You can create a new one and make  redirect to a page linking to both versions or at least modify the document to show a warning to readers. It won't be the original of course but a document containing the original text.
Also the notion that the original paper has any significance beyond as a historical record is ridiculous.
@_date: 2018-12-30 19:12:59


Batching isn't specific to segwit, it's just that with segwit the fee savings are increased due to the 'fee discount' for inputs.
@_date: 2016-07-02 21:50:57
The difficulty increases to make it more difficult to attack the network. OTOH increasing the block size limit makes it easier to attack.
@_date: 2017-06-21 08:24:23
\&gt;&gt; &lt;&lt;
@_date: 2016-07-02 20:00:33
It is outdated because the terminology has changed. Maybe you could read the linked Issue?
@_date: 2017-06-20 20:51:19
It is "locked in" only according to those who run SegWit2x. From the perspective of Core segwit activates like expected.
Personally I wouldn't be upset if Bitmain switched to mining altcoins exclusively.
Edit: The SegWit2x signalling bit activates mandatory signalling of SegWit.
@_date: 2016-07-03 07:16:38
The increased difficulty maintains the rate at which blocks are generated. Increased block size limit allows for bigger blocks.
Since mining provides security only if block propagation time is negligible compared to the block generation time interval increasing the size (and therefore propagation time) or decreasing the interval reduces Bitcoin's security.
@_date: 2016-07-02 16:34:34
Satoshi's vision is completely irrelevant; the community decides what Bitcoin is.
@_date: 2017-06-26 07:26:24
Why would we read a book on pseudoscience?
@_date: 2017-07-20 23:19:26
100% of miners are irrelevant to hard forks.
@_date: 2017-06-21 08:21:23


@_date: 2017-06-19 23:52:04
That's not exactly how it works. Namecoin only validates proof-of-work and that the generation transaction contains the header commitment and doesn't care about the rest of the block. This is done by attaching the Bitcoin block header and the merkle branch of the generation transaction to the Namecoin block. As a result of that **any** SHA256 coin can merge mine **any** SHA256 merge mineable coin.
Edit: In fact you could put fake data in the "Bitcoin" header; Namecoin only cares about proof-of-work.
@_date: 2017-06-20 20:36:12
Core doesn't have to do anything. SegWit2x activating just means that we will get the segwit softfork. The hard fork part will fail just like all of the previous attempts.
@_date: 2017-06-20 14:07:33
A rectangle is not measured in inches. The perimeter of a rectangle is measured in inches. Back to primary school for you.
@_date: 2017-06-10 16:22:07
Where is your PR?
@_date: 2017-06-28 13:01:38
**is not P2Pool**
@_date: 2017-06-20 20:38:31
Dream on.
@_date: 2017-06-17 09:40:09
Fortunately the wannabe dictators won't succeed.
@_date: 2017-06-19 20:58:23




    weight = bsize * 3 + tsize
    [weight] = [bsize * 3 + tsize]
    [weight] = [bsize] + [tsize]
    [weight] = [bsize, tsize]
Therefore weight has the same unit as size.
@_date: 2017-06-16 05:35:55
[Yeah, he is a great baby sitter as well.](
@_date: 2017-06-28 18:34:13
Greg doesn't defend p2xtpool but p2pool.
@_date: 2017-06-19 22:54:03
It is, just some components are given higher weight.
A transaction with base size of 100 bytes and total size of 200 bytes will have a weight of 500 bytes. Since 500/4 &lt; 200 it will need lower fees.
@_date: 2017-06-20 08:03:56
Why would they? Computers don't deal with units anyway.
Edit: For a unitless weight the equation would be:
    weight = bsize * 3 bytes^-1 + tsize * 1 bytes^-1
@_date: 2016-07-03 14:57:42
While we are at it why not ask for a matrix?
@_date: 2016-07-02 19:48:35
Nobody cares about your lack of knowledge. Just don't pollute the comment section.
@_date: 2017-06-17 09:43:45
Or simply the leadership doesn't exist as it should be.
@_date: 2017-06-20 20:34:18


SigWit2x activating doesn't mean that the hard fork will activate.
@_date: 2017-09-19 16:09:46
Why would increasing the base block size be desirable?
@_date: 2016-07-03 06:56:01


Where did you get that number? I know about the faulty retargeting algorithm but AFAIK it's an off-by-one error.