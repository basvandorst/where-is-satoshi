@_author: goatpig_armory
@_date: 2016-08-21 08:51:04
FWIW, this is the video in which I've heard this quote for the first time. Can't tell if he came up with it or if he is quoting someone else:
@_date: 2018-01-04 07:26:47
It used to be an alternative take on financial news, now it's just doomsday porn. The comment section is golden though.
@_date: 2018-01-20 11:39:06
There's quite a difference between "lock her up" and preposterous garbage of the flat earth kind.
@_date: 2018-01-23 13:55:43
At this point, Coinbase isn't looking after itself, leaving this much cash on the table in fees.
@_date: 2018-01-10 13:44:07
A comment very telling of how little experience and success Microsoft has in the fintech space, as really all they ever worked with is retail through payment processors and OEM licensing. 
Why anyone gives credence to the perspective of retailers in relation with the crypto space is beyond understanding. Retail in the current financial system is like L10, yet somehow they have the necessary expertize to figure out what should be done with a settlement layer? They wouldn't know what a settlement layer looks like if it was served to them on a plater. Case in point, Bitcoin.
Not to mention the current retail layer works just fine. I'm perfectly happy using a VISA NFC plastic card to buy my groceries. I have no motivation to modify that. I got into Bitcoin to deal with the submerged part, not the polished tip of the iceberg.
@_date: 2018-01-20 19:59:48
I'm not advocating for or against "lock her up". My comment simply was that "lock her up" is relevant to the topic, the rest isn't.
@_date: 2018-01-12 18:50:26
These are 2 separate issues. Coinbase making inefficient use of block space will fix itself through the market. Whether Coinbase is part of the solution or not, that's on them. I for one don't care either way.
As for the traffic, Bitcoin has not been taken down, nowhere near. At the technical level there was no failure. Instead, it increased the security of the chain by paying miners more. 
A large government can pump all the cash it wants in the form of fees, and we'll gladly have them. It only raises the cost of block space, it does not erode the network in any fashion.
Instead, try to imagine what would be left of a chain with an artificially suppressed fee market (i.e. increase block size to force low fees) if a government was trying to spam it.
@_date: 2018-01-20 23:34:36
I beg to differ.
@_date: 2018-01-20 19:57:17
I don't see how the average conspiracy theory is equivalent to claims of criminal activity levied against a former head of the state department. Looneys gonna loon, doesn't mean they should set the standard for a reasonable discussion.
@_date: 2018-01-04 13:12:18
I find it rather entertaining as long as you remember not to take it seriously.
@_date: 2018-01-29 03:22:40


It does not, stop peddling that nonsense.


Relying on isStandard for security? lmao!
@_date: 2018-01-04 07:16:31
Far from me to support ETH, I think it's a shitcoin too, but put in perspective with XRP, at least ETH is open source...
@_date: 2018-01-21 18:40:38


That's what I used for short of a better expression, but regardless of the intention, the result is the same, i.e. 2 chains. My analysis was targeted at that scenario. For that matter if think ETC/ETH is a "happy fork". At least much "happier" than BTC/BCH. And my point applies there: the ecosystem abandonned ETC once ETH diverged enough, and now ETC is basically abandoned.


That doesn't matter, it will amplify and splits the development effort regardless. If you have one fork exlusively for SegWit, one for Schnorr and one for Mimble Wimble, at some point the service providers have to pick which tech to support first, or just move on to a coin that doesn't tessellate its upgrade process.
Imagine the Android ecosystem if Google was overhauling the graphic library every major version, in a way that it is not only incompatible with the previous APIs, but also required steering chip integration in a way that obsoletes older hardware by design (rather than by technological lag).
Would app developers put up with this constant need for upgrading and recoding, or would they just favor IOS?
@_date: 2018-01-29 14:43:18
Hearn replaced BDB with LevelDB and just had that merged by Gavin. His patch caused a HF, something to do with how BDB handled larger blocks (&gt;900 KB) vs LevelDB. Clearly testing was not thorough. 
LevelDB itself was broken at the time, a flaw OSX Core users discovered quite quickly. That was figured out eventually by a Google engineer, but the real issue was that Google had basically dropped support for LevelDB a few months after Hearn shoehorned it into Core. You'd imagine he'd pick a DB that had a future, not just whatever his pals at his previous job put together and forgot about.
The worst part was that there is a procedure in LMDB to recover a DB state after an ungraceful shutdown. I'm not sure what Hearn did on that front, but for the longest time after 0.9 (I think that's the version that saw LevelDB introduced), corrupt DB states at restart would not be recovered, forcing a reindexing of the chain (which takes hours typically). It's only a couple years later that Core finally went around fixing that. That revealed some more of Hearn's ineptitude. Ask gmax about that one.
Maybe the sadest part about the whole LevelDB thing was that Hearn's patch was basically half done yet he was happy with his result, leaving sipa to wrap up what Hearn considered the "janitorial" parts. Yet it was obvious after the patch went live that the hard parts were half done as well.
That's about the only real piece of code Hearn ever contributed. His other ideas where implemented by Gavin, but just by looking at BIP70 you can tell Hearn does not understand the Bitcoin transaction model nor does he care to design around it.
@_date: 2018-01-22 18:27:15
The 2014-15 bear market basically made me stop giving a fuck about life as a whole =/
@_date: 2018-01-26 23:45:03


No, Hearn only ever contributed mediocre code and bad ideas to Bitcoin. His proposals were widely opposed, the only way he got anything done in Bitcoin is because Gavin would side with him and he had final word on all development while he was "benevolent dictator" as he would put it.
After Gavin stepped away (that's a cute version of history, he was basically push out by the rest of Core), Hearn quickly realized that he couldn't get his subpar proposals anywhere when he had to actually defend their (absent) merit to a quorum of his peers. 
This is why Hearn put BitcoinXT together. He didn't care about what Core was doing so much as he wanted to be reinstated in a position of unchallenged power, at the helm of Bitcoin development.
When he realized XT was going nowhere, he had the decency of walking away. Can't say the same of Gavin though... 
To conclude, Bitcoin was much better off after Gavin and Hearn lost their control over development. Hearn tried to capture it once more and quickly realized that was not gonna happen. God speed Mike, please don't come back.
@_date: 2018-01-29 22:53:38
The intent of SegWit is fixing malleability. The only way to achieve this is by removing all malleable elements from the computation of the txid. That means signatures.
Signatures are only used ever useful once, to verify the tx follows consensus. Other parts of the tx have varying degree of usefulness and can be arbitrarily requested. Not sigs. 
Once you get to the point where you remove sigs from the txid, might as well use the opportunity to increase block capacity since there's an evident amount of data you don't need for blockchain processing that is being otherwise being counted towards the cap.
The weight mechanism follows the capacity increase of SegWit, it does not precede it. The point here is that not all bytes are equivalent in a tx, notably txins thin the UTXO map while txouts burden it. However in legacy transactions, single signer scripts result in a scriptSig that is typically 4 times the size of the scriptPubKey that created it (100 bytes vs ~24 bytes). This results in an incentive to create more utxos than you consume, i.e. transactions with few inputs and many outputs.
Since a capacity increase would result in more UTXOs, which is the primary bottleneck for tx/block verification and an unbound cost in RAM, it had to be corralled. This is what the weight mechanic does, by discounting witness data in such a way that SegWit scriptSigs weight the same as their scriptPubKey counterparts.
This realigns incentives in tx creation and promotes UTXO map health, allowing for the higher capacity. A point that bcash couldn't care less about, btw.
@_date: 2018-01-21 00:59:02
1) There's a lot of visibility on EU and US markets as a result of their regulatory climate.
2) Asia didn't exist as a market until 2013.
3) It was evident the Yuan volume was bs. Once Chinese regulators imposed KYC and fees on their exchanges, their supposed 95% of market volume disappeared overnight.
4) Then came Japan. Same deal as China, a regulatory twlight zone with fee-less exchanges and weak KYC. As soon as the Chinese market clamped down, all that volume moved to Japan, which demonstrated China had no local market to begin with.
5) When the regulatory authorities moved on the Japanese markets, same exact thing as China happened. All the volume disappeared overnight and moved to Korea, again making it evident how thin the local market actually was.
6) Once Korea regulators did their thing, Japan got some of its volume back. When the Korea situation stabilizes, it will be revealed for the non existent market it actually is, like every other Asian exchange. The "volume" will either move to the next unregulated jurisdiction (India? Taiwan?) or evaporate.
7) This all leads me to believe that there is no native local market in Asia (or it's so thin it's about as insignificant as the EU), and that this volume bouncing around from loose jurisdiction to loose jurisdiction is actually driven by westerners, and the primary driver is tax optimization. The EU tax jurisdiction is a nonsensical patchwork with plenty of loopholes, therefor I don't think these westerners are Europeans, as it's easy enough to be tax free as a Euro Zone resident.
8) All trade operations in the US are taxable event, and the SEC is trigger happy when it comes to emergent markets and its users, therefor there is significant pressure and opportunity for US traders to take their business in tax areas that don't just fall on their knees and roll over whenever the US claims global jurisdiction.
This is my understanding of the market. My sources are just myself, as a Bitcoiner since 2011 and a wallet developer, I work with exchanges and have been exposed to a flurry of logistical and regulatory challenges in the field. 
I hope your argument isn't solely based on flaky volume figures from east Asian exchanges with giant arbitrage opportunities no one is seemingly able to act upon.
@_date: 2018-01-25 13:37:51
The funds in your wallet really just are a set of UTXOs on chain. Depending on your tx scheme, you may have several UTXOs using the same script (say multiple donations to a single address of yours). 
Consolidating these UTXOs on the cheap is desirable, as it will not erode your privacy, dramatically reduce your costs in fees for the follow up txs, and raise the "availability" of your coins (as opposed to small UTXOs that cost a relatively higher portion of the coin in fees). It also gives you an opportunity to move your coins to a SegWit output, so overall a win-win.
My comment referred to common tx schemes, which will have your wallet software send your change to a new address every time, as well as provide you with fresh recipient addresses when possible. In this case, chances are your UTXOs use mostly different scripts (i.e. your coins are spread accross multiple addresses). In this case, consolidation is not a win-win. The cost is a permanent loss of privacy. The blockchain is immutable and public after all.
I am not advocating for or against UTXO consolidation, it is each user's responsibility to take. I just wish users to be fully informed on the most likely undesirable consequence of consolidation. Too many threads leave out the downside.
@_date: 2018-01-25 01:55:37
If you consolidate outputs that do not share the same script (typical with any semi recent wallet sofware), you will forever erode your privacy.
@_date: 2018-01-21 14:19:18
Yes and no. Monero exists as a true altcoin in that it moves on promising Bitcoin research faster than Bitcoin itself. However the issue with Monero is 3 folds:
1) The tx model of Monero makes it harder to scale. This creates a catch 22 where for Monero to keep its edge, it needs to stay ahead of Bitcoin in terms of innovation. But to be able to achieve this, it needs to remain small enough that changes are adopted quickly. 
It is obvious that as Monero grows, the development inertia will follow. The focus will also shift away from privacy, towards scaling. Monero is therefor condemned to remaining a small, experimental lab for Bitcoin dev, or grow and be caught by Bitcoin in terms of privacy, at which point Monero will be obsolete.
2) Monero's only game is to stay ahead of Bitcoin's own innovations, but there is one it can't do much about: LN. LN naturally improves privacy on chain, and it would be significantly harder to implement on Monero due to their transaction model.
3) Monero's only usage atm is mixing for other coins. With enough channels and Schnorr, LN will take over that function, leaving Monero to innovate on its own for the first time. Who knows where that's gonna go.
@_date: 2018-01-28 01:46:45


I have no insight to offer on that end, however at a more fundamental level, maybe what you want to quantify is not necessarily centralization but cost of establishing a maximally connected hub. 
After all, decentralization in Bitcoin is desirable not on its own but because it promotes 2 of Bitcoin's core principles, which are robustness and "permissionless" access. I don't believe LN is exempt of these requirements.
Therefor, with a sufficiently high level of "access" (or low barrier to entry if you prefer), an apparently centralized topology can tessellate on demand.
@_date: 2018-01-29 19:45:49
bcash is some 8000 blocks ahead of BTC.
@_date: 2018-01-09 19:37:34
I sure as hell mind when the big players get bailed out after shitting all over the economy. I'll have all the stuff you listed it if means the end of the too big to fail death spiral. To each his own I guess.
@_date: 2018-01-12 17:39:06
Then Coinbase will keep on clogging the mempool, shills and trolls will keep on crying that Bitcoin is dead and all of this brainless mass of stupid will move on to whatever FOTM shitcoin while we go back to being productive. Nothing to see, business as usual.
@_date: 2018-01-08 20:01:20


This is just pedantry but assuming you got a typo in a P2PKH address and still passed the checksum, spending from it will most likely be impossible entirely (not just a very low probability). 
What you are paying to is the hash of a public key. Before you can even consider getting a private key for the relevant pubkey, you have to consider that pubkey may simply not exist at all. A public key is just the (x, y) parameters of valid point on the curve, and there may just not be such a point that resolves the hash you paid to.
Sorry for the nerd outburst.
@_date: 2018-01-25 13:41:04
Is this like a no fap challenge? Stop looking at the price and ignore news feeds?
@_date: 2018-01-21 14:05:36


Actually I would love that to be true but as soon as the Chinese volume evaporated I became very skeptical of the claim. I simply have a hard time believing an interest in crypto blows up seemingly out of nowhere in markets that otherwise couldn't care less a month ago.
But that would just be speculation on my part. My main piece of evidence is the large unmet arbitrage opportunities on Asian exchanges. All USD exchanges are basically within $100 of each other in price unless we're amidst a massive swing. If you compare it to the Euro value across most exchanges, the prices match as well. But every time an Asian market seems to run off with the volume, they are also overvaluating every coin by 10~20%.
There shouldn't be arbitrage opportunities in the crypto space. Every time a juicy spread sits in the open for months on end, something is off.
@_date: 2018-01-20 20:16:55
To be fair Bitcoin appears to be mostly driven by the US market.
@_date: 2018-01-21 16:12:32
There are several issues with contentious hard forks that make them widely undesirable (By contentious I mean hard forks that result in 2 viable chains).
The obvious ones are confusion and increased attack surface. Miner fragmentation and logistical difficulty for service providers are nothing to scoff at. But let's put those aside for now, with all other security concerns that typically undermine the survivability of these forks.
Let's look at it in the mid term. The primary issue with a contentious hard fork is the divergence in development (otherwise the minority fork will be obsolete, look at ETC for example).
This divergence guarantees 2 things:
1) A split in development effort. Suddenly devs are lost to the minority chain, which will slow work on the majority chain. If both chains survive, you end up with two networks that develop slower than the previous unified one.
2) Once differences are large enough, the split in development effort will hit the ecosystem as well. Case in point, BCH. Pre fork, all efforts of major actors in this space were focused on Bitcoin. After the split, you have resources funneled to support BCH, which results in deteriorating QoS of major Bitcoin service providers (BitPay) as well as slow innovation uptake and inefficient practices (Coinbase).
This is not going to get any better, as BCH diverges further from BTC. Imagine what will happen to exchanges if BCH implements FlexTrans.
The bottom line is, hard forks are not a magical shortcut for pushing changes. It may seem like they are, but if the network won't follow as a whole, the only thing it achieves is delaying the cost of the upgrade. Eventually the lag of the thinned development teams will catch up, and the cost to upgrade for the ecosystem is increased by the disruption.
However, "hard fork at all cost" proponents are quick to dismiss the woes of the ecosystem, as they are only ever concerned about the consensus layer. They want to embellish hard forks as the proper way to push changes on chain, ignoring that the ecosystem is driven by market demand and not consensus changes. 
As a matter of fact, I'd argue a network that HFs too often will risk alienating its ecosystem to the point where it will simply wither and die for lack of a service industry. The average crypto-currency user does not deal with the consensus layer at all. He needs the logistics of an established market to even be a potential user.
Therefor, TL;DR: Too many hardforks will risk killing the coin, outweighing the benefit of pushing out onchain innovation quickly.
@_date: 2018-01-29 19:48:53
SegWit is a malleability fix, not a block size increase per se. It's part of bcash's narrative to portray bigger blocks as a better solution than SW, implying the two are comparable. They are not.
@_date: 2018-01-23 23:18:53
Revenue != profit. You can have a bajillion in revenue and operate at a loss, look at Amazon these past 10 years. Obviously, I don't expect Coinbase to publish their profit.
Let's speculate on their operational costs for a minute:
GDAX pays the network fees. Only Coinbase itself pushes the fees on its users. You can transfer your coins from your Coinbase account to your GDAX account for free. If you think people won't stop for a minute and search for a solution when Coinbase wants to charge them $50 for moving coins out, you're grossly underestimating financial motivators. 
At the height of the mempool congestion in December, fee revenue surpassed coinbase reward. That's over 12.5 BTC a block, or at the price back then, about $250k. That makes for ~$37M a day, or over $1B a month paid in network fees.
The mempool shrunk in a matter of a few hours after Coinbase had to turn off its withdrawals a couple weeks ago, so if we go with the lowball estimate that Coinbase consumes 20% of the block space, this means December alone cost Coinbase $200M.
1) Why would Coinbase leave that much money table? Is it really more expensive to update its setup to SegWit and implement batching than to pay these enormous fees?
2) By ignoring the congestion they contribute to the increase in fees which hurts their own bottom line. Coinbase does not serve whales, they target small time, retail investors. If someone buying $500 in BTC has to leave 10% as fees to move the coins out, that's outright hurting Coinbase's bottom line. 
Basically they are inflating fees in such a magnitude that it cuts out entire groups of potential customers.
3) The less their customers have to pay in blockchain fee, the more Coinbase can charge them for their services.
@_date: 2018-01-29 14:26:51
I've read the BIPs, implemented support in Armory.
@_date: 2017-12-25 21:26:33
If you've read Peter Rizun's research paper that is the foundation for emergent consensus, you would know that the model he uses is undefined when coinbase inflation ends (not my saying, his own conclusions in the very paper). 
I wouldn't put it past him to argue for perma inflation at some point. After all, he his part of a coin that has made a commitment to hard fork twice in 2018. Nothing like ramping up the frivolous hard forks to prepare your user base to paradigm shattering changes.
@_date: 2017-12-02 00:30:29
If you're going to invoke a concept like inflation, you should distinguish between price inflation and monetary inflation, since they are quite different and often conflated.
Regardless, I think national debt and unfunded liabilities are better tools to project the long term health of national currency than monetary metrics.
@_date: 2017-12-15 13:12:11
I was gonna indulge, then I realized this video is 38 minutes. I've already wasted a day of my life debunking Peter's atrocious paper on block size factored via orphaning rate in 2013 (granted, that's not an achievement, everyone and their mom shat all over that one. It was so bad...). 
I'm not about to waste time going through this mess. Peter has no training in computer science (he has a background in physics) and he doesn't code, he lacks the skill set to even begin to criticize the design of SW. I've implemented support for the damn thing, I expect to be presented arguments that are least void of crass technical misconceptions and contradictions.
Feel free to summarize his technical arguments and I'll address them. Do not bother with his game theoretics analysis, Peter has long lost all credibility on that front with his trollish paper. And don't ask me for evidence of that, go dig the thread in D&amp;TD. I can't afford the time deal with the same troll twice, I have code to write, unlike others.
P.S: If you lack the chops to describe his technical arguments, or they are what you put in your OP, you are wasting everybody's time, give up. Also, I am being purposefully aggressive and snobbish. There is no room for feelings in technical arguments, you either have what it takes or you keep quiet. Silence is golden.
@_date: 2017-12-01 16:05:08


Where are you getting this trick notion from? A tightening of the rules implies they exist within the boundaries of the previous rules. I don't see what's so hard to understand. Go back to my addition and division example if you can't wrap your mind around it. 
If your argument is that constructing a script that is always spendable to old nodes to get them to skip further validation is a "trick", I guess you don't understand how versioning works.


Please use an example that would actually require a HF. It is evident the range of changes available to soft forks is encompassed by hard forks. Also, water is wet. 
If your encompassing argument is that you should always use a HF instead even when a SF is possible, then refer to the ecosystem rebuttal.


Bad example again. Only miners need to update to the SF for a reduction in max tx size to be effective. Nodes that wish to emit new transactions should update or they may construct invalid transactions.
If you increase any of these metrics, every node on the network has to update, be it miners or validating nodes. Otherwise, the first mined tx making use of the new metrics will grind all non upgraded nodes to a halt. Do you realize you just made an argument against hard forking to introduce optional features?


It is the responsibility of the node operator to keep up with update. If they don't, the worst they can assume in case of a SF is to fall back to the security model of a SPV node. In case of a HF, what they get is a full stop DoS. 


You can't choose to accept "unvalidated" blocks after a HF unless you outright downgrade to a SPV node (updated to the HF anyways, since any sane HF should use the header HF bit). There is no choosing in a HF. Either upgrade or loose service altogether. How can you not see the difference?


You are missing the point entirely. There is a development layer that exists in between the blockchain and the end user. That layer is the ecosystem. It dwarves the blockchain layer in terms of investment, development effort and innovation. It is the reason you can make any proper use of Bitcoin to begin with. 99% of all Bitcoin actors never deal directly with the blockchain layer, let alone discuss consensus.
The argument here is that a HF is a massive, compulsory burden on the ecosystem, whereas a SF allows the portion of the industry that doesn't care about the change to ignore it while others adapt in due time. With a SF, service providers choose what to do with it, in their own time. Again, P2SH....
With a HF, no one gets to choose anything. It is imposed on all actors to be ready at the time of the fork. 
Again, if your argument is "but but, muh full node", lemme me set this straight: It's trivial to update a fullnode to the next, compliant version, regardless of the fork. It is not trivial to implement the code to be either HF or SF ready. But at least with the SF, it's not compulsory with an enforced delivery date.
@_date: 2017-12-15 01:37:29
Do I? You have not elaborated any of your points, you are simply making unbacked statements. Should you insist despite your short and vacuous post, I'll simply reply to your points in kind:
1) You are wrong on all accounts.
2) You are wrong on all accounts.
3) You are wrong on all accounts.
4) You are wrong on all accounts.
I see no need to elaborate further, as you have not demonstrated any technical understanding of Bitcoin nor SegWit. 
Of course, were you to actually attempt to develop your points, I'll debunk them. However consider that I will not dedicate any more time to empty statements like those of your original post than I've done here. You see, I'm very familiar with both SegWit and the change set in Bcash's hard fork, seeing I've implemented support for both in Armory. Also, I've been technically knowledgeable about Bitcoin since 2011. So please do not try to bamboozle me, you will fail.
@_date: 2017-12-01 14:38:50


A hard fork is an imcompatbile change in consensus, a soft fork is a tightening of the existing rule set. Don't confuse the two.


How convenient of you to ignore the effect to users. With a HF, users have to abide by the new rules. With a SF, users can choose to use the new feature or ignore it. Case in point, only about 10% of all transactions use P2SH.
As for non upgraded fullnodes, you are putting "full on DoS" and "partially verifying" on same level. How is that even a valid comparison?
That doesn't even cover the ecosystem. You know, that massive layer that exists between the blockchain and the end user? With a HF, they have to update on time. With a SF, they can deliver the new features at their own pace. Makes it even harder to argue the virtues of a HF when the idiots at bcash forked in a week.


Nonsense. Again you are conflating consensus and actually using the features. When's the last time you used OP_CSV in a script?


Conflating again. There is a significant difference between outright breaking compatibility and refining the existing rule set. 
Let me help you there:
SF) pre fork: 2+2 = 4
post fork: 2+2 = 4
Added the new rule "division". You can still perform additions as before, whether you know how to divide or not
HF) pre fork: 2+2=4
post for: 2+2=5
Additions are completely different.
As for the accumulated work, I don't think that argument makes much sense anymore seeing bcash forked the difficulty adjustment rules as well.
@_date: 2018-09-26 12:18:08
\&gt;  Some wallets have not yet upgraded, meaning payments may not be 'seen'. 
I'm not sure what you are referring to.
You can always see which script you send coins to, regardless of the version of your wallet software. After all, your client needs no understanding of an output script to set the output value field, it only needs to understand the outputs it is redeeming.
A client that is not updated to bech32 cannot create bech32 addresses, therefor how could it receive payments in that address format? 
The only way such payment would be created from a legacy address client, is by the sender forcibly grabbing the pubkey hash from the legacy address and constructing a native segwit script out of it to pay to.
At this point the legacy recipient's wallet would need native segwit support to see the payment and later spend from the coin. But this has nothing to do with bech32 payments, it's only a matter of segwit support.
As for a legacy wallet paying to a bech32 address, that can't happen as the client can't make sense of the address.
There is no limitation in segwit to spend from a v0 script back into a legacy output. Again that has nothing to do with bech32, this is all segwit compliance.
\&gt;  or put their private keys in a client that's properly maintained. 
That's not necessarily guaranteed either, as only clients that exhaustively parse address combinations would be able to see the coin to begin with. After all, segwit compliance doesn't mean you have to use all possible address formats. Typically, each client only looks for formats it allows its users to create. Why expect coins on address types your software can't create?
@_date: 2017-12-01 18:20:40


The argument "hard forks can be optional to users" does not invalidate the argument "soft forks are optional to users". In fact, these 2 arguments are entirely orthogonal to each other. This is getting into word salad territory man...


Your entire argument against soft forks is that users would lose validation on full nodes if they don't upgrade. Then you pretend hard forks can offer them the same benefit if they so choose, __by upgrading.__ (to non compliant software if nothing else...). I am at a loss for words.


No it would not. You won't have the guarantee that the new rules your node ignores are contained with the rule set it knows of.


Is that the crux of your argument? Again you're talking about stuff have no knowledge of. Read BIP9. Your node will report ongoing SF activation and rule changes. As a node operator it is your responsibility to check and do something about the flagged SF bits your node is reporting. Hell, even the RPC will shove a warning in your face over that stuff.


No, it's a petty argument you are peddling via talking points you do not understand, based on falsehoods and half truths, for the sake of pushing a narrative about chain economics which in the end has nothing to do with technical parameters. You want to talk economics, you should be looking into a solution at the ecosystem level. You know, that layer you take for granted? At least be honest about your motivations, you aren't fooling anyone.


Meanwhile Coinbase has no issue operating on the Bitcoin blockchain after SegWit was locked in, but their users will have to wait till 2018 to get their bcash.
Again you miss the point entirely. The difficulty of implementing towards the feature that was soft forked is irrelevant. You have as much time as you want to integrate towards it, if you even chose so. With a HF, you don't get to choose. Implement or die.
@_date: 2017-12-28 16:18:27
Why would there be vendors if they do not have to rely on sales to live?
@_date: 2019-07-27 13:08:23
Current German stance wrt to Bitcoin is that you can cash out coins you've held for over a year tax free. You need to be a tax resident however, which requires living there for 6 months and a day within a fiscal year. Idk where this 2 years thing comes from.
  
Portugal has something similar: if you became a fiscal resident for the first time in the last 10 years, you can "repatriate" any asset/savings tax free on that first fiscal year. 
This stuff comes with caveats however. First of all, EU banks now require you to declare if you're a US citizen and share all of your financial data with the FBI and the IRS regardless. Second, while the local tax jurisdiction will most likely not bother you, there is no knowing what your home jurisdiction will claim you owe if you go back. You may have to defend yourself in court over this.
You can also try the UAE. I think Qatar let's you cash out tax free same day. Again, the risk is what the IRS will do to you when you go back, no so much cashing out tax free in a lenient foreign jurisdiction.
@_date: 2018-09-26 12:18:17
Bech32 is superior but there simply is no fee pressure atm, therefor the demand for the new format is low. It will come in due time.
@_date: 2017-12-03 22:01:12
I read that as "The government expects hegemony in all matters financial or otherwise to keep on functioning at the size it has grown itself to. Technologies that side steps their authority challenge their operational requirement, forcing them to rethink everything else. Certainly, we wouldn't want that?"
@_date: 2017-12-16 03:32:26
As in if all tx in the block are legacy, the coinbase construct is optional, because the txid and wtxid are identical for legacy tx, so the witness root hash is the same as header merkle root in this edge case. 
Check the "Hashes" section in BIP144. This stuff is pretty evident.
Please don't tell me you guys rejected SegWit without reading the BIPs?
@_date: 2017-12-16 03:06:51


That's tantamount to blind mining. Miners' entire purpose is to order transactions and append the chain. That's what they get paid for. If they don't run full verification on transactions they're just exposing themselves to easy DoS vectors by competitors, who can send them on a bad fork twice a day for a meager 1% of the total hash rate.
Case in point, the F2Pool blind mining fuck up that threw 1/3rd of the miners on a bad fork a couple years ago (can't remember the exact time sry). Even thought that was the result of negligence, it clearly demonstrated how easy it would be for an adversary to leverage that (throw off a large chunk of the mining power on a bad fork at the cost of a single orphan to you).


You cannot mine a witness tx without knowing its sig. The witness root hash in now mandatory in the coinbase scriptPubKey field. You cannot produce that hash without the signature data for all the transactions you are committing to your block, witness or not. Read the "Commitment Structure" part of BIP141.
Sorry, I won't watch Peter's video, I just can't survive that. I'd rather set my dick on fire while I jump in front of a train. I read this forum to take a break from grueling code, not to further my suffering.
I'd read a paper version of the claims, but now I'm very dubious of said claims. The whole Bitcoin Unlimited shtick is based off of Peter's emergent block size paper. His whole point was that orphan rate alone is incentive enough for a block size limit to form organically. While I disagree with his conclusions, you can't have me believe he would construct an argument against SegWit on the premise that miners would gladly ignore a blatant and actively exploitable orphaning threat. That position would be antithetical to everything BU is built upon. 
I do not have any respect for Peter's contribution to this space, but I'm not daft enough to believe he would openly contradict himself so blatantly. Are you actually trolling me? I'm being genuine here.
This goes back to my general criticism of your position. Whichever way I look at it, you are pushing points with no backing. When pressed to produce some sort of an argument, you produce a crass contradiction that reveals your profound ignorance of the subject. You either don't understand that what you are peddling is a contradiction, in which case I just informed you, so stop peddling it, or you are openly aware of that contradiction and peddle it regardless. This is a behavior which I can't characterize while remaining polite.
@_date: 2017-12-28 22:44:44
Less freedom, they have to pay for those that won't work in full now, remember? How else is UBI getting funded? You're just into slavery, admit it.
@_date: 2017-12-16 21:55:09


The outpoint has to refer to a valid UTXO by hash and txout id. The outpoint is a flat 36 bytes at the head of an input, it does not carry anything else. The scriptSig comes after that. SegWit moves the scriptSig out of the TxIn, the outpoint has nothing to do with that. Don't confuse this stuff, it's simple...


Ok, one last time: verifying a transaction and amending the UTXO set are 2 __different__ procedures. You can modulate your level of tx verification. All verifications are partial in a sense, you never check the output chain when appending new blocks, or previous sigs in the chain, you just trust your UTXO set state.
The verification strength you are describing is basically SPV. Fullnodes and miners should not use SPV strength verification. Why are you arguing they should?


You cannot verify the validity of a block using the SegWit rules without checking the signatures. What you are talking about is nodes appending their db without checking blocks in full. This falls under the SPV umbrella (Simplified Payment Verification).


This is already the case with P2SH, what the hell are you talking about? P2SH outputs are basically "anyone can spend" to non upgraded nodes. Have you ever seen an instance of a P2SH outputs redeemed in infringement of the P2SH rule set? Hint: no.


You do not understand Bitcoin game theoretics. It is in a miner's interest to actively orphan a competitor negligent enough to blind mine. There's more money for them in doing this! Bitcoin incentives are careful aligned so that it is always more profitable for miners to service the network than to attack it. This is why you don't fuck around with consensus when you don't know what you are talking about...


You saying the network would need to hardfork to steal someone's coins? Well duh...


This isn't Ethereum, sorry. The argument is moot anyways, you would need the same level of conspiracy to "steal" someone's coin whether they in a SW, P2SH or P2PKH output. Case in point, the Eth/Etc split.


Yes it is. If you do not upgrade to a softfork compliant version, you are downgraded to a SPV security model. That's how soft forks work!


Then why are you purporting miners would start to SPV mine under SW?


You're talking about a point Peter made. What you've presented here is in complete opposition of Peter's own papers in the field. Just pointing the obvious out here. 


I'm still figuring out which out of my dick or my brain I'd prefer to set on fire. You'll know soon enough.
@_date: 2017-12-15 03:33:35


It is nitpicking to attempt to distinguish between actual legislature and regulatory policy, in that regulatory policy for all intent and purposes is implemented in the same fashion as laws, and at least where I live, offenders will be prosecuted for infringing on these policies. 
We could argue about how these regulatory bodies derive their authority from Congress, but you have to realize that to forward this argument, you have to admit regulatory policy and law conflate at their source of legitimacy, which supports my point that they are essentially identical.
In fact, I would posit that Congress lacks the mandate to further decree powers to state agencies, seeing as Congress is a democratically elected legislative body, while state agencies stem by definition from the executive branch. Therefor this disposition is not only confusing the separation of powers, it also erodes the legitimacy of Congress.
If anything, you would have to agree the whole process is inconsistent, which undermines the credibility of government at the very least.


It can certainly refuse to cooperate, like the Fed has turned down requests to be audited by Congress. Bills to audit the Fed have passed the House but not the Senate 3 times in row already. In what world does a legislative body have to pass a bill to audit the very agency it bestows power to? 
Let's turn your statement around. Can Congress even begin to outlaw the Fed when it lacks the power to oversee its activities? The Fed either effectively overrules Congress' authority, or the whole thing is just a farce. Pick your poison.


That does not improve the distinction between regulation and law, and quite frankly only serves to demonstrate the Congress oversight of state agencies is far less effective than you'd be led to believe.
@_date: 2017-12-27 20:28:04
That comparison does not stand. Bitcoin transactions are way more expensive than Ethereum transactions. You'd have to compare some factor of tx count and cost of block space, in which case BTC crushes ETH.
You can't just look at tx throughput as if it's happening in a vacuum. ETH chose to subsidize its access to block space on the network where Bitcoin is letting individuals take the brunt of the cost. In terms of demand, the BTC chain vastly outpaces ETH.
@_date: 2017-12-27 23:43:29
No these are economical issues. At the technical level, Bitcoin is working the same regardless of the fee and miner hop.
@_date: 2017-12-11 23:14:18
Technically, it's usury that is forbidden. However, in ancient times, any kind of interest on a loan was considered usury.
@_date: 2017-12-28 19:37:17
So let me resume:
We live in a world that offers sufficient opportunities for individuals to become millionaires, sometimes even billionaires. Yet you are suggesting that in such a world, those individuals that can't do any better than selling produce at the local market will continue to be productive once their basic livelihood is seen to?


But they wouldn't "acquire more", it's not that simple. First these people would have to work to generate the portion of their income UBI is covering. Then they would have to work to cover their mandatory contribution to UBI. Afterall, this system has to be funded somehow, and at the end of the day you either contribute to the system or you benefit from it. Only past that threshold would these people finally be able to effectively "acquire more" wealth. That threshold, by definition, is higher than what they need to do now in order to see to their survival.
You are suggesting that individuals who currently only generate enough wealth to cover their own basic needs would somehow start producing significantly more when their primary motivation to have a revenue in the first place is gone?
I don't see how this argument is tenable, and it is largely contradicted by the current state of affairs: In the western world, and even more so in European style social democracies, the higher the minimum wage is, the shorter the legal work week gets.
@_date: 2017-12-16 16:02:25


I don't understand what you are refering to. You can choose to update your UTXO set without checking the validity of the block you are taking in. At this point you are operating on a quasi SPV security model. Miners and fullnode should not downgrade to SPV. I don't know what else there is to it.
Verifying transactions in full is the cost of operating a full Node. You need a full node to mine, that's a requirement, not some sort of negotiable arrangement. Again, refer to the F2Pool blind mining fiasco.
More over, amending the UTXO set is an expensive operation, as it's a large dataset and generally has multiple reader threads with active read transactions (as in database locks, not bitcoin tx), and any update will trigger some sort of rebalancing, being a binary tree of hashes and all that. Therefor, you cannot afford to operate on false positives. 
It is in a miner's best interest to have a valid and up to date UTXO set at all times. A corrupt/out of date UTXO set is the most straight forward way to increase a miner's orphan rate. This why SPV mining is done on empty blocks, because you are better off giving up all of your potential fee rewards than trying to mine on top of a bad UTXO set. SPV mining is evil, but even that is better than mining fake transactions.
I don't know where you get the idea that somehow SPV mining is desirable. Regardless of that, you cannot push for that alternate version of reality without contradicting the quintessential argument for BU and Peter's criticism of the block size limit. Therefor, I'm still dumbfounded that you are linking me to one of Peter's video as the backdrop to your point.
I'll try to watch the slides sometimes this week end just to conclude this whole thing. Don't keep your hopes up.


You, Peter Rizun whose ideas you are forwarding, and everybody else that forwards them.
@_date: 2017-12-28 19:47:37
No, I have enough money so I dedicate my full time to developing Armory for free. But I don't think I'm a representative case.
In general people work more than what they need to cover the day's expenditures because of a mix of factors:
- They are financially responsible for others, or plan to be
- They understand they won't always be productive and choose to work at the prime of their health, skill and intelligence in order to have resources for when they are old and decrepit.
- They are competing for social status, often their only path to acquire other resources, like acknowledgement or a desirable spouse
- Their character traits compels them to be producitve, i.e. highly consencious people. Consider that the opposite exists, i.e. people who can't stand the idea of being productive.
@_date: 2017-12-15 01:26:28
That's nitpicking. These are regulatory bodies with what is effectively decree power. The end result is really indistinguishable from legislation.
@_date: 2017-12-15 00:26:42
What a great pile of nonsense... No one buys this garbage, please move on already, you had your idiotic hard fork.
@_date: 2018-09-09 08:54:29
SWIFT is a privately owned company providing a 40yo protocol to financial institutions and banks, i.e. corporations that have intimate relationships with the state, and that mistrust each other (since they only have to answer to their jurisdiction).
Neither SWIFT nor their protocol is irreplaceable, and the only way SWIFT can operate at all is through state approval. It's a given they will bend to government demand, regardless of how much they want to posture. Matter of fact, you could argue this glaring point of failure in SWIFT is a desirable feature for a government.
@_date: 2017-12-15 00:50:24
You and I both know his elderly colleagues require him to spurt out confusing gibberish and buzzwords while they all nod knowingly, for no one in the room wants to make it too obvious how little they understand of the thing they are legislating about.
@_date: 2017-12-16 03:13:50
To give you perspective, it took me about 4 months do it, with unit tests, runs on the testnet, RCs and what have you, as a solo act. However, I was done in April 2017, seeing I had a whole year to go at the thing.
Not sure how good these guys' implementation is since it took the 3 of them a single day to my 4 months solo (a bit over a month each if I had 2 guys with me), but it doesn't change the basic reality: 
__they've had a whole goddamn year to implement SW support!__
@_date: 2015-06-23 08:14:22
It's not as simple as you make it sound. What you are talking about is technically to trust timestamps in the wallet file, which we decided against a long time ago, and for good reasons. 
We trust the content of our DB because it is built and maintained against a fully verified Bitcoin network peer. We do not trust wallet timestamps because it is unverfied meta data. If we had a reliable way to verify it, we wouldn't just use it to skip scans on fresh addresses. If you can trust timestamps, you can trust balance.
If you want to skip scans entirely once Armory is synchronized, you can try supernode, but that's a very resource intensive mode, not recommended for individual use.
@_date: 2017-12-28 18:47:05
But we're not talking about billionaires here, we are talking about vendors at the market. Or are you arguing billionaires and vendors at the market are indistinguishable in skills, intelligence, character and motivation?
@_date: 2015-06-22 17:34:17
Yes but the process is parallel now. You will be able to use Armory as usual while the added wallet is scanning.
@_date: 2015-06-23 23:16:46
If you mean adding a check box in the GUI to hint the backend that the addresses being registered are new, that could be done but I don't think I'll get the go ahead for that.
@_date: 2018-08-09 23:46:19
Inflationary fiat currencies favor debt over savings, i.e. savings are gradually losing value whereas debt gets gradually "cheaper". That's for the personal debt part, and the benefit can be enjoyed today.
On the gov side, Bitcoin exists outside of any jurisdiction, and is immune to monetary inflation, which means it is hard for governments to tax it. The more wealth flees into Bitcoin, the less of a pool can a government draw its income from, which in turn will force it to reduce spending, therefor debt. This probably won't take effect unless BTC is in the $10M valuation.
@_date: 2018-08-13 12:51:41
Twitter's IPO was the biggest ever in its time (maybe it still is today?) and they have yet to turn a profit. Some businesses operate only on investments until they have cornered the market, then they start figuring out how to generate revenue. Same goes for Amazon and YouTube.
As for why would this even be a thing, quantitative easing had a lot to do with it. Also note that this practice (operate at a loss until you smother your competition dead) is very common in China.
@_date: 2018-08-21 02:53:46
It's actually surprising how little game theoretics these people understand. When a consortium of miners also owns a large portion of coins, they are in no position to dictate anything, because they cannot sell their position or the price will crash before they can liquidate. Nor can they cut down on their mining effort because it will expose the coin to easy 51% attacks, which will in turn threaten the value of the stash they cannot get rid of.
It is bewildering that under these circumstances, CSW thinks he is in a position to dictate anything to the thin market still barely supporting the price level. It is somehow as baffling if not more that anyone can still think this tool is Satoshi.
@_date: 2018-08-24 21:54:34
Well I'm just relaying what the market felt like in both instances. I was of the opinion the halving will lead to a rally both times, but general consensus was price would correct instead. 
You have to consider that both halvings came about after long bear periods, and there was a very vocal group of Bitcoin skeptics calling the halving a final death rattle before Bitcoin was dead and gone. It blew upwards instead both times.
@_date: 2018-08-13 20:02:30


I was replying to this point in general, not the Bitmain specific case. There are (imo credible) rumors that Bitmain has significant ties with the Chinese government, which is a prerequisite for the Chinese "smother" approach, but that aside, I don't believe that's what Bitmain is gunning for with this IPO. 
I mean, this is an IPO, not an ICO, which means among other things that they're not accepting crypto for their shares. This is telling for a crypto company.
If you want my opinion on the matter, Bitmain is acting like a noobie day trader who got a good call on his first try. Now he believes he can lead the market instead of following it, and soon the idiot is parted from his money. Bitmain walked into a pile of cash, thought they were the heart and soul of BTC in consequence, and are burning up all their money over some messiah complex/ego trip. 
The IPO is probably the conservative/crypto skeptic elements within the organization trying to salvage something from the wreck.
@_date: 2018-08-10 11:59:36


I'm referring to government revenue as a whole, inflation is a tax for all intents and purposes.


The government would be faced with 2 choices to deal with the lower income: increase the national debt which would weaken the currency, or reduce spending which would shrink the debt.
If it chooses to weaken the currency, more people will flee to safe havens, since the premise is that safe haven financial instruments led to lower government revenue (as opposed to say, the economy tanking).
@_date: 2018-05-18 17:11:10
Some $100 laptop that can run Wheezy would do as well. Make sure you nuke the wifi card and encrypt the system disk.
@_date: 2018-08-24 11:32:12
\&gt;  It didn't. 
Where were you then? The prevalent sentiment both times was that the halving was already priced in months prior to the event and the price would correct downwards right as the halving hit, as the market overshot the prediction on supply shortage, or just used the occasion to manufacture a pump.
Both times we got intense rallies instead in the 6 months following. When inflation goes down, price goes up. Now consider what the next halving will be like once Bitcoin yearly insuance will finally sit below the average fiat centrally programmed inflation rate of 3%.
@_date: 2018-05-23 21:29:09


Yes, quite actively at that too.
@_date: 2018-05-24 13:12:49
It's called caveat emptor. It has been among other things a foundational principle of contract law for centuries now. 
You are delusional if you think you can escape this principle in a space where all code is open source and free of governmental oversight.
You are delusional if you think people like me would provide said code under any other circumstances.
@_date: 2018-05-24 22:45:32
Only that government has a piss poor record at shining light on anything.
@_date: 2018-05-23 12:02:38


Oh, such a Satoshi thing to say... To hell with decentralized networks, to hell with decentralized governance.
Fatoshi has spoken, no crypto for you!
@_date: 2018-05-24 19:53:26
You buy into Bitcoin, you should know what you are getting into. No amount of regulation would make Bitcoin as desirable as it is now. The risk comes with the territory.
I didn't realize I had to spell it out.
@_date: 2018-05-18 17:07:01


You can set that in the .conf files if all else fails. Better that than modifying the source.


It's mostly RAM use that causes that, not CPU. However, as you somehow stumbled upon, cutting down on the thread count will make it easier on your system, because each thread results in a bunch of memory overhead that is otherwise avoided. I guess I'll have to reduce the memory usage even further for the next version.
Also, if you're in need of RAM, know that you can bootstrap the DB without Core nor the GUI running. That should give you some extra room to breathe.


Honestly you're better off cross compiling the binary from a Linux machine:
@_date: 2016-01-23 22:51:22
This is the first time I hear any issue regarding blown out of proportion fee estimates in Armory. 
In our last update (sometimes in September 2015 I believe), we added a feature to query the local bitcoin instance for fee estimate, leveraging one of the new features in Core.
Sadly, I have no idea what version of Armory nor Bitcoin this particular user is running, since he has not attempted to get in touch with the Armory team afaik. I have seen no support ticket (I could be wrong) nor any post on Armory's sub forum at bitcointalk, which are the 2 places our user base can reach us at.
I need to see log files to troubleshoot any exotic issue with Armory. While the community delivers proper advice (only on our sub forum, mind you) with common place issues, anything complicated needs developer expertize, and at this point I don't even know what this user is actually running. I do not know what he expects to achieve asking for support outside the dedicated channels.
There is little we can do to help this user if he doesn't at least try to reach us. While Armory as a company is going through a rough time, the employees are still there manning the support channel, and I'm out available on the sub forum. 
The best advice you can give him is to create a support ticket or post on our forums.
@_date: 2016-01-08 18:42:35
- You can run Tails as either a "live" OS or install in on your computer and set up some persistent storage. The distinction between these 2 boils down to convenience vs security. A live Tails is always "squeaky-clean". A persistent Tails only needs to be setup once.
If you choose to go with live, you should save a set of dependencies for both Bitcoin and Armory, as well as prebuilt binaries (you can test and build all that on your offline system).
- As long as you are past that point (setup Bitcoin and Armory), you can plug in your blockchain and Armory data folders from external media (dongles, SD, external drives). Point your Bitcoin client and Armory to their respective folders (you can write a quick bash script to do that for you) and all operations from there on will not differ from using Armory over the clearnet, i.e. you still need to update your blockchain data and let Armory catch up with its own db.
- Setting up the offline machine is much simpler and you should consider only using live for that part.
@_date: 2017-03-20 16:36:32


Probably? That's unsubstantiated. The burden of accurately evaluating the impact on resources is on the advocates of capacity increase. Are you telling me you are supporting a 16MB average block size without any profiling?
My experience with supernodes taught me searching and modifying a highly fragmented data set on disk (keying by hashes will result in fragmentation) will increase exponentially without optimizing the access and write patterns to the data profile. etotheipi's tx hash resolver hit a wall on HDDs back at block  That's what I'm dealing with.
I shouldn't be here telling you this capacity increase won't fit on consumer hardware, you should be the one presenting me with research and code that demonstrates otherwise.




Pruned nodes are overly weak to local data corruption. But that's besides the point. You are dismissing all uses cases for full nodes. You cannot get transaction history will the full chain history as a 3rd party software. With a 16MB block size, you are baring first world consumer hardware from running analytics and processed blockchain data services locally. This puts all small to medium business bitcoin to bitcoin scenarios behind a high barrier of entry.


Try catching up a week of blockchain data on a HDD, then get back to me.


That pushes the bulk of the use cases behind large service providers, who impose AML KYC and are easy targets, centralized points of failures. Just look at Coinbase vs the IRS. The future of Bitcoin should be to phase off interfacing with fiat and move towards closed loop bitcoin to bitcoin use cases. The only thing lacking for this atm is the software stack, and I hope among others to deliver a piece of it through Armory, as a service running a fully indexed node. Kick all consumer hardware out of reach and all this effort is basically in vain.
And your definition of a win is to push these uses cases out to only increase user capacity by 5 folds? Were you even aware of these use cases until now?


That and all the use cases that rely on analytics. I guess in your vision, only corporations and universities care about academics and research on the blockchain. What is the point of decentralization in design if the data is effectively to be accessible only by large scale actors? Do you have a vision for Bitcoin that grows beyond mining and as a retail vector?
@_date: 2017-03-23 16:10:27


I didn't bother debating the guy that far, but I remember his first paper in which he advocated that a block size limit was not necessary to form a fee market (back in 2014 maybe?).
The basis for his conclusion was that orphan rate would force miners to keep themselves from stuffing blocks with low/0 fee tx, hence the block size limit was not a necessary metric to allow for a fee market to form and to keep spam under contorl. One of the funniest part was that his model was undefined (his own words) when the coinbase reward hit 0.
His angle to address the inconsistency, instead of admitting the model was broken or at least not future proof, was to dismiss the issue as something to be dealt with some 40 odd years from now.
The paper was thoroughly debunked on D&amp;TD, got a revision which was debunked just as quickly, but that didn't stop Peter in the least. Instead, he went on to create some sort of a Bitcoin scientific journal, make himself editor in chief and publish his paper as the first piece.
I really didn't expect him to lazy out on the inconsistency by just advocating for inflation instead. I guess isolating himself from his critics didn't turn out so well.
@_date: 2017-03-27 21:40:49
This is a bad model to mount a comparison with voting on capacity metrics.
 The experiment determines that with near equivalent lack of knowledge, a collective guess is more accurate than the guess of a single skilled individual.
The conclusion is painfully obvious and does not really need an experiment to confirm, for the intelligence of any participant, savant or not, is completely irrelevant. You are perceiving and guessing. It is obvious the mean of 1000 guess is more accurate than a single guess. The conclusion basically states if A &gt; B, then A &gt; B.
Allow the few mathematicians to compile their "guesstimates" and suddenly your 1000 plebes will be far out guessed.
A much interesting representation of that phenomenon can be found in probability theory, with an actual mathematical proof:
 This model does not apply to voting on the block size at all because:
a) Beans and jars are common, and you only need to look at them to understand the essence of their respective shape. In the case of the block size, the low denominator user doesn't even know what a bean is and what the jar looks like.
b) On the other hand, the technical community has a really good grasp of the elements at play. 
Therefore the comparison with the experiment doesn't stand: the many don't even know where to look at, the savants work with jars and beans all day long.
 my point is not to let devs set magic numbers
It is to reduce the reliance on magic numbers altogether. This is how I would go about: 
1. Identify a set of blockchain measurements that are affected by transaction capacity (fees, difficulty, UTXO set weight, what have you)
2. Draw a relationship between these metrics that allows it to model the existing data accurately
3. Run that model against usage and attack scenarios, then on the testnet, with the goal of refining it and fine tuning the implementation.
4. Fork to this model and let the blockchain auto regulate itself.


I would not support this kind of proposal, as it is just compounding a magic number on a magic number. The opposite of a magic number is a measurable metric, not complexity. Magic numbers should only be used to harmonize the real world metrics together, not outright set the metrics.
@_date: 2017-03-28 11:40:39


1) Market valuation can be deduced from difficulty. If it's going up, the market is growing, if it's going down, market is shrinking. Plain and simple.
2) Demand can be deduced from fees. The higher they go, the more BTC people are willing to pay to buy space into blocks. If you inversely correlate fee weight to difficulty, you get an approximation of demand in real world purchasing power.
3) You can deduce node health from UTXO set size and growth metrics + total chain size in bytes. Moving to a tx weight instead of tx size parameter to evaluate fees, which accounts for consumption vs creation of UTXOs and sighash + sig complexity will smooth the relationship between node health and fees.
You now have your tri force, time to research it.


My argument is neither that developers know exactly what the ideal block cap is, nor that they should be in charge of setting magic numbers. My argument is that average user can't even formulate a realistic guess, and that it is all irrelevant because swapping a magic number for another solves nothing.


This is just a less convoluted and safer way to do what BU set out to do, i.e. let miners set the block size. Magic numbers lead to politics, and miners have a big conflict of interest when it comes to the block size. I see this kind of approach as a downgrade, not a solution.
@_date: 2017-03-21 21:26:31




Yet there is nothing to stop miners from actually mining blocks that large, and only other miners actively orphaning such blocks would prevent them from being permanently committed. You are removing a hard cap and asking me to trust you and others won't abuse it. Why would you want to introduce trust where there needs be none?


That's irrelevant, no amount of discussion on reddit has the power to prevent miners from hiking the network capacity under BU's consensus. If it is possible for the community to change the block size by just "talking about it", what is stopping a dominant group of miners from having the same talk behind closed doors and imposing any block size they see fit? What was the HK agreement if not a closed door meeting with the majority of hash rate providers? Have you considered the scenario where the majority of miners want to enforce 1MB blocks ad vitam?


If the game is broken, changing players doesn't fix it. You can change king but you are still living in a kingdom. The fundamental issue with the block size is that it is a magic number. If BU was actually earnest about fixing the block size issue, they should have researched and devoted resources to develop automated, algorithmic solutions. 
Instead, we are just proposed a governance change, and one that is far more one sided than what we currently have. BU wouldn't even have room to exists if it wasn't for the current status quo that has Core developers require miner approval. BU effectively turns a 2 party system into a single one. I cannot see how this is beneficial in any way.






How am I moving the goalpost if you admit to 5-10c/tx being your target?
The main complaint I hear about the network from BU supporters is that fees are too high and transactions take too long to confirm. By putting miners in sole control of capacity metrics, what guarantee is there they won't be inclined to appease the angry masses? Isn't Roger Ver currently offering a 10% premium to whoever mines BU? With that precedent, is it so far fetched to imagine someone offering the cover miners for their missed opportunity in exchange for inflated blocks?


In a single party system, a lot can be achieved through lobbying. Suddenly, a vocal minority can succeed where a majority failed before.


I don't know where you are getting that metric from. Blocks currently average at a low end estimate of ~2 BTC in fee revenue. With a market to pay that much in fee, today's valuation, your target acceptable fee of 10c/tx and no effective block size limit, we'd be looking at 22k transaction/block, or ~6.3MB blocks.


Miners have a direct incentive to collect as much fee as possible from the mempool. With miners in charge of the block size, there is effectively no stopping any form of spam. It would cost an attacker $4000 to create 16MB block full of 10c transactions. How is that figure not a credible threat? Again, Roger Ver is currently offering a 10% revenue bonus to miners for switching to BU. 
Slashing fees lowers the cost of spam. Spam is not limited by bandwidth or processing power, only by sat/B. As long as conditions allow for a somewhat linear inverse relationship between tx fees and block size, the cost to spam a 1MB or a 16MB block (or any size block for that matter) remains roughly the same.
I do not understand where the argument comes from that spam won't get mined. How do you explain the 60k mempool from a week ago is down to 2000 tx today? Even nowadays 0 fee transactions and obvious spam gets mined.


With permissioned fast relay networks, work announce strategies and headless mining, how is this still an argument? 
Even if these technologies didn't exist today, do you really believe miners would not implement them in a heart beat if the reward was a 60k mempool ripe with fees?


It never was credible threat in the previous 2 halvings, why are we supposed to believe it will be the 3rd time around? If you are concerned about this, push for a more granular deflation curve. You would garner support for this among Core developers, believe it or not.
@_date: 2017-03-22 13:54:16


Is it? The PoW model defines that in the scope of a chain, an actor always stands to profit more forwarding the chain than from trying to orphan competitors.
It was never meant to instantly defuse irrational attackers, only to thwart them through attrition (tx fees and mining cost). It also never was meant to address attacks with overwhelming externalities.
If I commit a contract for a $100B purchase in the Bitcoin blockchain and receive shipment before payment, I am now highly incentivized to attack that chain.
@_date: 2017-03-19 15:25:43
The biggest cost to running a node is RAM. You need to be able to index, search and modify the UTXO set quickly to verify incoming transactions, which by nature are unpredictable. 
The price per gigabyte of RAM is on average an order of magnitude higher than that of SSDs, and 2 orders of magnitudes that of HDDs.
The other limitation with RAM is the hard cap on memory density. Consumer hardware could only house up to 8GB of DDR2 and 32GB GB of DDR3. Currently, Intel chipsets allow for up to 128GB of DDR4. AMD's Ryzen only supports up to 64GB.
For reference, my current full node eats about 3GB of RAM. My understanding (I could be wrong) is that BU defaults to 16MB blocks. The mempool loads we have experienced these past months (60k+ tx) would fill up to 24MB blocks. While I am not affirming the UTXO set scales linearly with block size, without actual research on that topic it is fair to assume it will grow significantly if we increase the block cap by an order of magnitude. 
So with your 4 years old machine and a BU chain running on its default settings, I do not believe your hardware can even house enough RAM to operate a node properly within 2 weeks of a fork.
Now, there are several credible criticism of BU's shift in the network's game theoretic that I personally believe will push towards more centralization. However, I don't need those points to see that BU will swiftly prohibit consumer PC hardware from validating transactions on a pure resource basis. AFAIK, SPV wallets need to maintain the UTXO set as well, so they can't side step this limitation either.
To compare with Core's approach, consider that the SegWit discount allows you to create tx inputs roughly at the same cost as tx ouputs, highly reducing the cost of utxo consolidation (which incidentally aligns incentives with a global reduction of the UTXO set).
@_date: 2017-03-29 14:12:48
The issue isn't the space req so much as the Pi arch. RPi 1&amp;2 run ARMv7, which is a 32 bit architecture, meaning it cannot address more than 2GB of RAM per process, and it needs more than that for IBD and to house the UTXO set.
What you need is a RPi 3 ($38 board, same form factor as RPi 2 and RPi B+), which runs off of a 64bit ARMv8 CPU. Also, you are better off syncing the chain on an actual desktop PC, then copy it on the RPi. RPis can keep the chain to date, but IBD is too rough on such lean hardware.
@_date: 2017-03-09 11:36:18
1) I don't think there would be enough miner support to activate even a 2MB HF. After all, we can't get a SF going at the moment, so 1MB is here to stay.
2) Industry wide proper engineering and good practices are a consequence of financial incentives. I don't think Bitcoin's valuation is high enough to elicit such behavior from miners yet. 
Maybe after 2 orders of magnitude increase in price the incentives will realign?
@_date: 2016-01-23 23:19:07
We're having trouble with our website as well.
This is where you can get 0.93.3, and probably where we will post the upcoming 0.94: 
This is also the version you would get if you were to pull the source from our master branch.
The user did not try to contact us in any way that I know of, so I don't know what his problem exactly is nor what version he is running.
@_date: 2017-03-20 09:57:44
While this is really cool technology, it doesn't change the underlying tenet: Faster memory is more expensive. Intel isn't trying to introduce new SSD technology to replace the old one, they developed this product targeting the gap between RAM and SSD performance and $/GB because there is a market for it.
@_date: 2017-03-20 15:18:30


This explicit control induces control over centralization and immutability, specifically a large attack surface for post confirmation double spends.
@_date: 2017-03-09 09:02:34
I don't think any service should list BU coins unless BU implements a clean HF. The "wipeout protection" caveat is highly understated. 
It is painfully easy to "taint" your coins on the BU chain as it supports larger blocks and lower fees than the Core chain, which will unleash financial attacks on both chains.
It should be expected that both BU and Core loyalists will short each other. I believe the Core camp financially dwarfs the BU camp, while BU is only gaining miner support.
This means a BU split, if it occurs, won't last past a Core retarget. As the BU coin gets shorted by the financial majority, its value will drop against the Core coin, while fees on the Core chain will spike. 
Once the Core chain hits its difficulty retarget post split, it won't be realistic for profit driven miners to operate on the BU chain anymore. Some miners may decide to throw themselves behind that chain, but they are just bleeding money at this point. The Core chain will overtake the BU split inevitably.
Miners follow the economic majority, they don't create it. This kind of vulnerable chain split is no more than a publicity stunt, regardless of how much hash power backs it originally. 
Consider the following: 90% miners forking the chain against the economic majority's benefit won't get it to budge. The same majority can fork to a new PoW algorithm and wipe out all miner investments with little effort.
People under the impression that such split can survive are painfully oblivious to the game theoretics of Bitcoin.
@_date: 2017-03-19 18:56:38
As I've mentioned previously, we have already seen mempool loads capable of filling 24MB blocks. Are you suggesting that won't happen with larger blocks? I expect lower fees to amplify traffic if anything.
@_date: 2017-03-20 09:54:07
How is that any different from the OS swap?
@_date: 2017-03-29 13:48:59
Ideally, develop useful applications around full nodes so as to increase the incentive to run one (and dampen the resource cost in the process)... or push for SegWit to activate so that we get LN rolling, which does exactly that.
@_date: 2017-03-22 16:15:08


Miners are strongly incentivized to pocket short term profits, by design. Again, you are pleading that I should trust miners with unmitigated power over the network transaction throughput, which is the one metric in direct control of their bottom line. This is a massive conflict of interest. Users have 0 power on block size with EC. You even argue later that they can't even RBF for their own sake, and yet you expect they will police the chain. Pick one.
Even if miners were exemplary in their conduct throughout Bitcoin history, all you'd have is an argument by authority. But we all know that is not true. Tycho's run was a horror story for one. Here is a quick reminder of miners' track record:
- Miners rarely if ever contribute to client or consensus development: name Core devs on miners' payroll.
- Instead they are in the habit of taking code donations from non miners: relay network implementations, thin block and work announce strategies.
- As a matter of fact they were more than happy to let the network topology and orphan rate deteriorate while Gavin banned all mining focused R&amp;D from making it into the core client, under his reign.
- They will cut corners when possible: SPV mining, signal for a soft fork without implementing the code (CLTV/CSV fork).
- They lag behind in implementing sensible fee strategies: how long did it take for CPFP to be adopted network after Eligius' started running it? Even today 0 fee transactions are getting mined (that btw undoes your orphan argument through and through).
In light of these facts, trusting miners is the last thing I want to do. Even so, you listed 4 incentives for miners to manage the block size cautiously, so let's go over them:


Completely goes out the window if an attacker is spamming fee paying transactions.


Node resource cost is irrelevant to miners in the face of profits. Miners have no incentive to fill blocks with 0 fee transactions, they have a direct incentive to fill them with fee paying transactions. Goes back to 1). How do you deal with that scenario when miners set the block size?
Faith in Bitcoin and price have been utterly irreverent of network health so far. Irresponsible miners antics such as pools nearing 51% hash rate and centralization in China has never impacted the price in a significant manner. The weekly BU crash exploit barely has an effect on the market. 
Breaching security at an exchange, on the other hand, is more often that not devastating, even though it is orthogonal to network security and operational capacity.


Selfish mining attack scenarios are basically all mitigated by delaying and balancing out fees through a reward pooling mechanism. Orphaning attack vectors are thwarted by pseudo permissioned fast relay networks. Why trust miners to police themselves when the attack surface can be shrunk technologically?


That suggests an awful lot of off chain coordination. At any rate, if BU can contentiously fork off of Core, so can warring factions within BU. What is  actually stopping you now and will stop them then is the absence of wipeout protection. You can't sell me on wishfully thinking and idealized coordination of a united miners coalition.


Miners and users are in contradiction with  Users want cheap, fast and plentiful transactions, miners want total fees.  is a non factor,  is the only point where miners and users motives align, i.e. let's avoid nuclear war. Hardly a good basis for fruitful discussion. At no point do you demonstrate  either of these groups care for the impact of block size on the network's health. Oddly enough I agree that it cannot be demonstrated.


Please don't appeal to the practices of a project ran by an idolized leader that still garners a zealot following after breaking his most sacred tenet. This is a bad position to take when advocating that a system of one sided governance will see the interest of all network actors respected.


Baseless assumption. People like me have our entire livelihood and life's work at stake in this game. Give us some credit at least...


In nation B, parties D and M are in equal footing in the legislative chamber. Only bipartisan bills stand to go through as both parties are representative enough to at least have veto power. According to your own analogy, D has no real skin in the game and M has a direct, glaring conflict of interest on certain key piece of legislature, called S. This makes S very contentious and heavily debated legislation.
Your proposal to undo the deadlock is to therefor give the M party full decisional power on legislature S and remove B's veto power. Your argument to back this change boils down to party M are the good guys, we should trust them. Oh and btw, M also already exercises considerable executive power.


I meant single digit fees, but sure, go ahead and argue that 1c is not in the same order of magnitude than 5c. Then compare that to $1 fees.


I had no idea his deal came with this caveat. I can just "move the goalpost again". What about Jihan's $100M set aside to attack the Core chain?


With all due respect, your position is irrelevant and so is the position of BU advocates. The only position that matters under EC is that of the bottom line of the majority hash rate holders in regards of the mempool fee sum.
Please do not try to argue there aren't people out there willing to attack Bitcoin and/or BU at a cost of their own.




Nonsense. This is the effect of demand. Spam only pressures fee higher because the utility of the service justifies a higher cost. If your analogy was valid, spam attacks would crash honest use and spammers would be left footing the entire bill of full blocks, running them out of money in a month.
Spam only ever has one lasting effect: bloating the chain. Everything else is gravy.


This is the absolute ceiling cost to spam the network full of 16MB blocks, paying the high end of your designated acceptable fee bracket. 
Actually this is cheap and very credible considering threats on the one hand by Jihan to attack the Core chain with $100M (orphaning attacks are a lot more expensive than filling blocks in the long run), and that on the other side Core ballers are sitting on large stashes of BTU comes the fork. 
We have also already established the current fee pressure would see the network fill ~6.3MB blocks at 10c/tx (again, your top end acceptable fee). It is disingenuous at best to expect the BU mempool won't have enough fee paying transactions that an attacker would have to meet the full price of attacking a block all the time.
But why am I even arguing this, miners mine 0 fee transactions in today's market!


Doesn't give miners' license to set any block size they see fit. This does not change the underlying argument: magic numbers are bad, voting about them doesn't make them any better.


The model you describe is that of an organic fee market pushing against a predictable block size. You spent half your previous post explaining how BU miners were keen on manipulating the block size to keep fees in a tight bracket. Organic fee market modeling is inaccurate in the the context you have described. My comment was not written in a vacuum.
@_date: 2017-03-27 14:10:59
I guess I have to clarify the position.
First and foremost, this post is linking to a commit on achow101's fork of the BitcoinArmory repo. For reference, achow is one of my few and esteemed contributors to the project. This commit is the subject of a PR to the ghpages branch on my repo, which is where I maintain the current Armory code base since ATI terminated support. 
You can see the PR here: 
The ghpages branch controls the layout of  the website I sanction as the official page of the project. This PR is still up for discussion and I have yet to figure out what to do with it. 
That being said, the PR itself references this post I wrote on the Armory forums: 
In this post, I lay out a detailed explanation of how to get Armory to see both chains and how to taint your coins, as well as general pros and cons of self tainting vs leaving custodial services to do it for you. This was done in the spirit of a PSA, not with the intent to endorse either chain. **If you read this post hoping to find a position on the fork in it, you are wasting your time.**
The post boils down to this:
1. Armory can work on both chains if you go through the proper steps. I detail the step as well as what to not do in order to keep both chains and databases segregated.
2. It is preferable to remove your coins from exchanges prior to a fork and taint by yourself. There is basically no risk in doing so, and a non negligible risk to rely on an exchange instead.
The excerpt achow uses focused on segragating the DBs as well as how to taint your coins. It is basically taken verbatim from the original post. **The first sentence in the post was written by achow alone, and so far does not reflect the official position of the project**. That PR is still in review and open to modifications.
Now for the politics!
Before getting into that, I need clarify the nature of my posts on the bitcointalk Armory subforum. That forum is for the project, not my personal opinion, therefore any of my posts in that subforum that is not explicitly about support or technical discussion is to be read as a PSA. It is not a place to engage in politics nor express my personal opinion, and while I do not moderate people insulting me or the project in there, expect me to move political discussions out of that subforum.
I tend to keep my opinion to myself, and if I want to get political I'll either start to blog on Medium or post here in relevant threads. Since this post got people speculating, you will be getting my position first hand.
I maintain and therefore represent Armory. It only makes sense that I express both a position for Armory, and a personal one.
 position:**
Armory is a free open source project. People are free to contribute code and try to take the project where they want. If my personal opinion differs from theirs, I will not assist them in the endeavor. They are free to fork the repo and post in the forums all they want regardless.
That said, Armory is a wallet, and the sole 2 criteria required for a feature to be eligible for development/inclusion are the following:
1. The design and specification of the aspiring feature ought to be technically feasible, sound and satisfy Armory's technological and security requirements.
2. There ought to be a demonstrable demand for this feature in the user base, or a reasonable expectation of future demand. The evident axiom to this proposition is that a new feature cannot alienate the existing user base for the benefit of another group.
As you will notice, there are no considerations for politics in this process. To put this in perspective, Armory is a wallet, and a wallet's job is orthogonal to the motivations behind a fork. Meanwhile, a fork will see users with coins on both chains, and Armory should deliver its users with access to both these chains, for that it is a natural development upon the wallet's original purpose. My opinion on the fork is irrelevant.
A look at the recent development cycle will demonstrate this position: I spent around 3 months implementing support for SegWit as well as compressed public key. This was done with the explicit intent of keeping the code paths separate. Indeed, people who do not want to use SegWit can ignore the new code. The legacy P2PKH feature still runs the old code path etotheipi implemented years ago. That code is time tested and robust, there is no need to force people off of it if they do not want to.
At the same time the use of compressed keys was introduced with better handling of fee/byte scenarios to enable users to lower their fees. Again, these features rely on their own dedicated code and users that do not wish to use them are not forced to. Same goes with the privacy improvements. All of it is opt-in.
This approach is in line with SegWit and soft forks in general, in that since the on chain feature is opt-in, the respective wallet feature is opt-in as well. Consider that this was not a benign choice to make, as it would have been a whole lot easier to force everybody on SegWit and stall the release until a chain activates the feature. 
During the development process, mempool saturation spiked and while very few Armory users complained about stuck transactions, it became evident CPFP was in demand, so I took another 2 weeks to support CPFP. Later the threat of a fork solidified, so I took another 3 weeks to add RBF to allow users to taint on their own.
For an example of something I would never allow in Armory, look at anything built around BIP70.
On the subject of fork splits, Armory has no position on them. Amicable forks are preferable to contentious forks by nature, but neither of these matter from the perspective of the project. However, Armory is strongly opposed to any project and community that supports following its fork split with a miner pogrom on the original chain. **This behavior stands against everything that is Bitcoin and should be denounced for the shameful, awkwardly disguised aggression this path of action results in.**
 personal opinion: 
If you do not care about it, stop reading now.
I am satisfied with the direction Core has taken Bitcoin in, both in concept, design and code. Core retains my confidence for the current set of features under development.
I disagree with BU on almost every point. I will list them out for sake of being thorough:
1. I agree Bitcoin needs scaled.
2. I do not agree that Bitcoin needs scaled this very moment. I would have been happy with a version of SegWit that also halved the block size limit to compensate for the increased capacity. IMO, a whole lot still needs done before scaling is desirable and technically sound. The increased capacity of SegWit is a compromise I am willing to make, seeing that the fee discount on witness transactions realigns incentives in favor of utxo consolidation (helps keep the UTXO set in check)
3. I disagree with BU's primary principle that the block size should be decided by user and miner vote. I disagree with the block size hardcap on the grounds that it is a magic number. Voting on a magic number does not improve upon this limitation. The only acceptable solution in my eyes is an algorithmic one. To imagine a technical metric is best discovered by popular vote is wishful thinking at best.
4. I disagree with BU's design choice in regard of the vote. There are plenty of simpler and more efficient ways to achieve what BU sets out to do than to signal block size per node/miner in a gossip model.
5. I disapprove of BU's implementation of that design (EC), on the grounds that it does not achieve what BU set out to do. It is an awkward and convoluted piece of code that tries to hide behind its complexity and an unjustified amount of pointless parameters the fact that only miners effectively have any say over the block size.
6. I've had a few discussions with Peter R in the past and I strongly disagreed with his understanding of Bitcoin and his take on the project's development. I suspect I will disagree basically on anything he has to say today, seeing the path BU has taken.
7. I strongly disapprove of the announced BU miners attack on the Core chain in the event of a fork. I wish to forever dissociate with the people that suggested and support that infamy.
8. I have a distaste for the bickering over Bitcoin's name and Satoshi's legacy that people are engaging in. I care neither for the name nor for the posturing of legacy. I only care for the technology. To whom the rest is valuable, you can have it.
9. I don't particularly care for the incompetence of BU devs. There is too much BU is getting wrong for me to somehow concern myself with how the codebase is maintained. Even if it was top notch, I'd never run it.
@_date: 2017-03-10 05:59:51




That's just wishful thinking on your part. I analyzed the danger of a vulnerable split through game theoretics. You are simply declaring which side of the fence you stand on, then purport it is a done deal. 
You have yet to make a point that is pertinent to my analysis. If you believe there won't be a Core coin/chain, you have to demonstrate it. To just state what is the obvious to you is not an argument.
@_date: 2017-03-20 12:52:50
I am very familiar with mmap'd containers. LMDB mmaps the entirety of its underlying on disk data, and I have personally modified LMDB to fit Armory's use case. 
My question to you is, how is an mmap container, which is simply a caching hint from the OS perspective, any better than memory swapping strategies?
Short anwser, it isn't. As a matter of fact, addressed memory is superior to mmap'd file descriptors because the former is actually addressed as the name suggests, while the second relies on free RAM to cache with. Addressing any RAM (through another process or within the current one) will always take priority over mmap'd containers.
There's also the issue of what data structure you are going to use. mmap suggests an underlying file descriptor hence a B-tree scheme. In RAM you'd be looking at self balancing BST (more often that not red-black). The B-tree variant in DBs is meant for large blocks of data (the minimum size read or write on a storage drive is a single cluster, usually 4KB). RAM can be accessed a byte at a time and UTXOs are usually 34~36 bytes in key and 35~40 bytes in value.
If the data set is relatively small compared to current hardware capacity (2GB of data vs an average of 8GB of RAM in modern mid-low end consumer hardware), you don't really need to concern yourself with these advanced design optimizations.
If you are proposing to inflate the data set by an order of magnitude on the same hardware, with a hard requirement on processing speed (ideally blocks should be verified under a fraction of the average median time to account for variance), you can't just push the new requirements aside like this.
@_date: 2017-03-20 00:17:02
I'm not sure what you are getting at.
@_date: 2017-03-19 22:43:26


They have to use swap however. Keep in mind that there is a difference between addressable memory and hardware RAM. RPis run off of a SD card for NVRAM, which can sustain acceptable speeds (significantly above the 4KB random access I/O of an HDD), so they can handle the current UTXO set if a few seconds delay on validation is acceptable (I don't know of a use case besides mining that can't operate on that delay atm).
This becomes different if you have to swap a large portion of the UTXO set in something like a HDD. I believe the current UTXO set sits at ~2GB raw data (you have to account for container overhead in RAM). Swapping in a SSD is obviously better but more expensive as well.


That's around when blockchain complexity gets "tough". Everything before that is easy mode. For reference, Armory's DB code on my machine covers the first 300k blocks in about 1 minute and the next 150k in 4.


I'm not familiar with Core's own code, I rarely sync the chain from scratch (I keep backups to save me the pain). From what I remember (and understand) of the process, the RAM cost is really just tied to the UTXO set size.


Which gets me to this question. The UTXO set is intimately tied to block capacity and fee structure. There is a hard cap to how many utxos the chain can maintain by simple virtue of block capacity limitation and value divisibility. That defines your ceiling. The fee structure is the most significant factor in controlling that value, as there is a disincentive to create a UTXO with a value lower than the fee to redeem it, hence the UTXO set tends to stabilize around a value, which is 2GB for the current metrics AFAIK.
So to summarize the reply, RAM usage does not scale with chain size, only with individual block size. Tx fees have a strong inverse relationship with set growth.
The main concern with the UTXO set however, is that it is a constant cost on RAM (as opposed to bandwidth/CPU spike at propagation).


It is easy enough to profile that stuff on your own, I believe most developers/researchers do not concern themselves with this metric since it has remained stable once the network hit capacity.


I can give you read speeds as a reference. On my own PC (DDR4), L2 cache runs at ~50GB/s, RAM is at ~16GB/s. I run 2 SSDs in RAID0 which gives me about 1GB/s of sequential reads. However, fetching from the UTXO set on a drive results in a 4KB random access (the smallest data packet a drive can return, ie a single cluster), which on my setup operates at around 100MB/s at full queue depth. As a point of comparison, single HDD usually runs around 2~3MB/s on 4KB random reads.
The key difference with RAM aside from the raw speed is that you can access single bytes instead of full clusters. The addressing speed is something else as well. This is a large dataset so you should expect a fetch to complete in 2 clocks. Since you expect the data to be in the RAM (and not the cache), you have to multiply the actual fetch cycle by the RAM CAS timing (~15 on DDR4), so you are looking at 16 clocks to start reading a pointer to your data. That's ~5 picoseconds on modern CPUs (I may have botched a 0 here or there).
For comparison, the response time on a modern SSD for 4KB random reads is ~100 us. We're talking 10s of milliseconds on a HDD.
I expect a large fragmented dataset running off a SSD to significantly slow down the verification process. As for by how much, I have no proper estimates for you, I'm not familiar enough with the real world metrics to tell you that with accuracy. This stuff is easy to profile however if you are willing to bite the bullet and emulate the load locally. This is definitely a test case I'd look into developing in the process of analyzing the network health and projecting capacity.


I do not have time to deal with that stuff sadly. Armory eats all of my time as it is.


I do not like the idea of voting for magic numbers because I believe there is no sane discussion to be had about them. It creates too large an alley for politicizing the debate rather than sticking to the engineering.


Happy to have one anytime.
@_date: 2017-03-25 19:19:54
As it stands, you could afford to double the fee rate on a SW transaction and still end up with the same total fee than with a legacy transaction. Not a bad deal imo.
@_date: 2016-01-09 17:20:23
Some people mistrust USB. Others are afraid of having friends/family members wiping off the particular device for their own use. It comes down to what you feel comfortable with. Persistent local disks are more convenient in a way, they also reduce how easily you can replicate your online system.
If you keep everything on external media, you could get your online Tails'd Armory running on any machine in minutes. You do need to evaluate if that's a good or a bad thing in your setup.
Whichever way you go, make sure to use full volume encryption on your storage device (LUKS would be the natural choice). You could try fancying things up with hidden encrypted volumes, to store your public keys behind another layer of secrecy.
@_date: 2017-03-19 20:40:58


I'm mostly concerned about RAM. In my experience with profiling the blockchain, I/O always dominates every other workloads aside from crypto. Hashes themselves aren't on my radar atm. It takes my machine less than 5 minutes to verify all merkle roots with the current chain. ECDSA is pretty expensive on the other hand, but Armory doesn't verify historical signatures, so I can't really give you an expert view on that.
Resolving Tx hashes without holding them in RAM takes the cake regardless. NVRAM and HDDs simply aren't good enough at random I/O to support these operations efficiently. RAM is a precious resource however, and you have to contend with other processes. Good management strategies aren't easy to design nor implement. 
With the natural growth of the blockchain, I've had to deliver database improvements in 3 separate releases just to keep the initial setup bearable. I'm due another soon enough.
On the other hand, quadratic sigops growth could be an issue with larger blocks. I don't know that BU addresses this yet. I'm not particularly versed in that aspect of the chain so I'll refrain from making predictions.
Storage can be an issue. 16MB blocks could yield up to 800~900GB of extra chain data a year. There is currently no way to split chain data across drives, you'd be left with setting up a RAID just to house this stuff within a year.


I'm not an expert in that field either. I can tell you a full node on a 10 MB/s upload fiber connection can serve upwards of several terabytes of data a month (mostly historical data) on the current block size. I can also tell you that user operated full nodes do not typically connect to miner fast relays nor use predictive block propagation strategies, so they are left to face acute resource costs at the time of block propagation. While the later issue can be remedied, the former will get prohibitive real quick.
I don't think the discussion on block propagation vs orphaning rate is relevant within the current context. There are no measures taken to favor single miners so the market naturally concentrates around a few pools. It's trivial to setup a fast, predictive relay network between a few known actors. 


I have advocated in the past for a mechanism that logarithmically ties block size to fee sum and fee sum to the inverse of the difficulty. This is a complicated system that needs proper research and calibration however.
I agree that a 1MB limit is not desirable on the ground that it is just a magic number. I don't believe voting to pick a magic number makes it any more sensible. I believe that in the absence of a solution that ties block size to blockchain metrics, a fee market is more beneficial to the network and the chain's health than otherwise, hence I see no reason to change from a magic number to another, these solutions are just flawed by design. To paraphrase Pascal, kings are picked arbitrarily, hence they are equally unfair to all.
At any rate, I believe we need to move a block weight mechanism before we can look at increasing the chain's throughput. Size alone is not comprehensive enough metric.


etotheipi created Armory. I became an ATI employee in fall 2013 and have contributed code since version 0.90. I have taken over the project since ATI withdrew support. I've been tasked with the database code since I started so this is my main field of expertize. I've been personally using Armory since it came out I believe.
@_date: 2017-03-19 16:58:15
I can't tell you, I have no hard data on the relationship between UTXO set size in RAM vs block size. My guesstimate is that it is reasonable to expect an increase of an order of magnitude in block size will result in an increase of an order of magnitude in UTXO set size in RAM.
So somewhere in the 30GB vicinity (i.e. no DDR3 system would be able to hold the set in RAM alone).
@_date: 2017-03-09 11:28:23


At the cost of immutability? 
@_date: 2019-03-23 14:22:37
Caveat Emptor
@_date: 2017-03-24 19:16:09


Bitcoin's security is its mining subsidies. To put it simply, the market purchases security off of miners. How miners deliver that security ("vast amounts of equipment and electricity") is not defined by the protocol. It is simply an equilibrium of the mining market. 
If a status quo is achieved in the mining market that enables actors to erode the network's security while pocketing subsidies, wouldn't you agree that the protocol needs to change in order to realign miners' incentives?
And I'm not referring to the current conjecture. There are selfish mining scenarios today that would undermine the networks security. Imagine what would happen if I was to emit a transaction with a 1000 BTC fee. What about mining only empty blocks?


Which gets me to this misconception. The fundamental security is the subsidy, not whom pockets it. You are bestowing motives upon miners that simply do not exists. The only motivation of miners is their bottom line. The health of the network is irrelevant to them. 
A straight forward analogy may help here: the network is a factory, the miners are the employees. The only constant in that relationship is the work for wages axis. Employees want to work less and get paid more, the factory wants to pay less and get more labor.
Employees should not be involved in the managerial decisions. If the factory wants to create different products, the only thing it needs to do in regards of the employees is to make sure they are ready and trained to handle the new workload. 
In order to be able to keep enough employees, the factory only needs to pay high enough wages to beat the competition. Employees are naturally free to move from factory to factory. Obviously if the factory's products aren't selling, it can't afford to keep wages up and will lose employees regardless.
Now here is a question: if the factory pays top notch wages to create poorly designed doodles, that will eventually fail to sell, do you expect the employees to: 
a) turn down the wages on the ground that the factory is not sustainable and try to take over management instead?
b) pocket the paychecks and move on when the factory eventually fails?
If you replied a), you do not understand the game theoretics of mining.


Their current actions are contradicting your statement. If miners wants high fees, why support any block size increase? Blocks are full, price is up overall and there are no signs of fee declining.
If miners care for fee rate and valuation, their best path of action is activating SW, as it does not erode fees while improving network capacity, which will lead to higher valuation.
A simple increase in the block size cap lowers the fee rate, because the newly available offer will overwhelm the demand, and pressure will only resume after the uses cases that can afford premium fees fill up the new capacity. 
Hard forks can't be granular enough. If you just HF the block size periodically, you will get this very effect. EC is worse however, as it gives control of the block size to miners. This opens the way for fee sniping (you can nuke a 60k mempool in a single 16MB block). That can only lead to either aggressive orphaning of larger blocks or centrally planning the block size among miners. Both of these options result in less security.
SegWit on the other hand is opt in, hence it has no direct effect on the block fill rate. If the fee rate is too high, people will start using SW. It allows premium use cases to gradually fill the new capacity without tanking the fee rate instantly at first.
@_date: 2017-03-19 19:29:09


I expect it to be. I see no reason why it won't.


My experience with full nodes leads me to believe otherwise.


16MB blocks would put the minimum requirements in the "prosumer" hardware range.
@_date: 2017-03-20 21:34:51


This is the current BU default, it's only fair to evaluate it. Also, as I understand it, one of BU's goal is to reduce transaction fees. I don't know what the target is, but don't expect single cent fees without at least 10MB blocks.


This is valuable data but it doesn't address my concern (UTXO set growth). I suspect a RPi3 could put out similar results with the current UTXO set. The question is, what will it look like when it's over 10 times as big.




These sentences contradict each other, but suit yourself. I didn't know that a discussion on the spectrum of use cases had to be emotionally loaded by nature.
@_date: 2019-03-22 16:17:52
If you were to run this same analysis with on chain usage instead of exchange volumes, I doubt the result would be any better for altcoins.
Also, bloated exchange volume would only account for inflation in Bitcoin volume, and would not explain why the rest of the market still follows the pareto plot.
@_date: 2017-03-24 22:11:47


I'm not sure what you are referring to. If you mean the network as the employer in the analogy, that's not hierarchical. Hierarchy is a system of authority. My argument is that the relationship between miners and the network is purely a business one.


That would be the economic majority, incidentally the same group that pays the miners (someone has to buy their coins). As for whether there is a distinction between economic majority and users, that's a topic of its own IMO.


In software engineering more than anywhere else, it is unjustifiably wasteful to "reinvent the wheel" for every project when there already exists a usable framework. 
I believe frictions in usability are a great opportunity to elaborate orthogonal solutions. It is hard to have that discussion when the opposite side believes cranking the raw capacity is the end all be all solution and won't concede to any technological improvements (which would yield benefits under any circumstances).


I'm going to assume you meant technological instead technical.




Miners do not run the network. They extend the chain and decide transaction ordering. Nodes enforce the rules, users emit transaction and the economic majority floats the project as a whole.
Saying miners run the network is like saying the NYPD runs the city of New York. They don't, they maintain the environment in which the city can run. The police shouldn't have control over the deliverance of building permits or what news paper is allowed publication within the city limits.
A soft fork does not circumvent security measures. It refines existing rules. Miners still need to be aware of and comply with these rules, but they shouldn't get to veto them. Soft forks are opt in by design. They actually are a very organic way to evaluate where the economic majority stands and the utility of a change. P2SH and OP_CLTV/CSV have very low usage. At the same time they remain very useful to the minority that uses them, without disturbing the operations for those who chose to ignore them.


They are paid for a very restricted and well defined service. Every other involvement they may have in the network is on a purely voluntary basis. Your statement is equivalent to saying a NYPD police officer is not an employee of the city because he participates in town hall debates and votes during municipal elections.


Removing them from an equation that was none of their business to begin with and handing the decisional power to the group it actually concerns is a good thing.
The current status quo has cops as the only body with ultimate voting rights on all city matters. UASF is a discussion on whether it is possible to safely migrate that voting power to the citizenry. The benefit of this change is self evident.


I'm getting tired of this bickering over names and legacy. For the record, I do not care what is named Bitcoin, who Satoshi is and what his vision was. All of the above are fundamentally arguments by authority, antithetical to the concept of decentralized truth ledgers. I only care for technological merit. If this is a matter of opinion and feelings to you, we aren't even approaching this from the same paradigm and a parting ways is not only unavoidable, it's preferable.


I don't know what others are arguing, my point is the following: UASF in principle is better than MASF. Can it be implemented in a non exploitable fashion? I'm too busy with Armory to elaborate a design. So instead I am waiting to see a spec and implementation and make my mind.
At no point am I suggesting that I will blindly support any UASF design on the ground that I agree with the fundamentals. I want UASF only if the design is solid. Otherwise I'll stick to MASF.
@_date: 2019-11-09 21:43:25
It's huge. Muh diabetus...
@_date: 2017-03-10 05:34:18
I clearly distinguished between BU coin/chain and Core coin/chain in the context of a vulnerable split. That post is out there for all to see. 
Your comment is intellectually dishonest and you reference to the white paper is disingenuous.
@_date: 2019-03-23 01:40:35
I was thinking more along the lines of tx volume.
@_date: 2017-03-20 11:05:47


You are suggesting block validation load will scale linearly with block size. I don't believe that to be true. A simple example is how response time for random 4KB reads on a SSD can spike up to 2 orders of magnitude when nearing capacity. Latency QoS in NAND is actually the main concern of the industry. 
That's without considering that the UTXO set is not read only. The cost of updating it mostly on NANDs is quite different from doing it in RAM. Keep in mind that for a SSD to update a single byte, it needs to wipe a full 4KB cluster first.
16MB blocks will fill a 1TB SSD in a year. That's ~$250 a year on the cheap, or $500 every 2 years. That's on par with enthusiast gamers' GPU budget. You could use smarter setups, where one SSD is dedicated as cache, but we are far removed from maintaining the chain on a $40 RPi 3 at this point.
Consider that I have users taking a week to sync the current chain on their hardware. These use cases should be considered in the baseline. 
It is obvious mining operations valued in millions of dollars can afford the hardware to handle the extra load (if they don't have it already). These nodes are connected to fast relay networks to begin with. Their load scaling isn't even comparable to the average validating node. Why base your estimates on the percentile of network actors least affected by capacity increases?
@_date: 2017-03-19 15:43:48
Corporate hegemony requires vertical integration and cornering the supply. This is more often than not achieved by lobbying the lawmaker to raise the barrier of entry (to make competition prohibitive). 
Oddly enough, in the case of Bitcoin the process unfolded the other way. Mining and hardware manufacturing is already centralized in China, but these same actors have no control over the development process (the law maker in the former analogy).
However the incentive still remains to lock down the current mining market status quo by taking over the development process, which BU conveniently delivers.
Just my 2 cents.
@_date: 2019-03-22 16:15:01
As he explains in the opening of his article, a power distribution is uniform across scale. The top 20% cryptos would hold 80% market cap of all cryptos, while the top 20% of this top 20% of cryptos would hold 80% of that market cap. 
He demonstrates this at the end of the article, where he plots volume bound capitalization between the top 5 cryptos. Bitcoin represents 20% of this group while concentrating \~85% of the indexed value.
@_date: 2019-03-19 01:19:12
The first 7 numbers on a debit/credit card are the bank identifier. Regardless of what internal VISA route your request takes, at some point VISA pushes this to the relevant bank for tx ACK/nACK. If the bank's own back office is down, no amount of VISA network will help.
@_date: 2019-11-07 11:30:43
Yes, my father's small business was audited twice for back taxes. 


You mean the scatter shot letter they sent out earlier this year? Has a single audit come out of it yet?
@_date: 2019-11-14 17:38:34
Emphasis on rich. Don't think the source of the wealth is all that relevant at this point. If you're all talk no actual hodl though...
@_date: 2017-03-22 13:41:33
The opposite argument is that there is no need to push the flat earthers out of campus, for your students should be educated enough to spot fallacies on their own, let alone that kind of blatant baloney. 
How do you expect them to ever function outside of a sheltered class room otherwise? And if they still can't after your best efforts, do you really want to associate with them anymore?
I believe Slush picked the right move, I'd prefer other miners would followed after his lead.
@_date: 2019-11-13 00:00:57
I would argue that it is significantly more likely Bitcoin goes 100x (the $1M mark) before we figure out the global energy issue. While a lot of Bitcoin mining is powered by renewables (and not awful ones like solar or wind), it is still bound to our current energy tech.
For Bitcoin to "take over", in the sense that it would be strong enough to keep central banks in check, the price can't stop at $1M. This will inevitably increase the power expanded on not only mining, but also manufacturing more miners to meet the demand. It will get much worse before it gets better.
It may take decades for that energy consumption to stabilize, then possibly revert. For now it's up and up. And I don't think we'll have figured out neither fusion nor got nearly enough thorium reactors going around by then.
The truth about clean energy is that it only comes as an added capacity to the current system, it doesn't replace anything. I don't expect that trend to change until we get a significant breakthrough, which I don't expect on this side of 2050.
@_date: 2019-11-06 22:23:14
\&gt;  Their power to size only matters if you keep all you money in btc and keep your person out of reach of the US government, which tends to be difficult. 
Not for high net worth individuals. Billionaires will buy corrupt politicians, move their assets to another jurisdiction, or leave the country as a whole. This is already the case, BTC just lowers the bar.
You seem under the assumption that the IRS has an agent available to put behind each and every US hodler. They don't even have the staff to prosecute the current load of tax evaders (again, how taxes be evaded otherwise). The IRS isn't dumb, they will prioritize low hanging fruit, i.e. wealthy people and organizations they can simultaneously wipe out and throw the full book at. 
Unless it is instrumentalized for political reasons, don't expect the IRS to come after plebes, they simply don't have the manpower for that. Again, how is the IRS to know you have realized a BTC profit if you don't volunteer that information? Why else would you be required by law to report your income, unless they simply don't have the logistics to find that out on their own? Even China can't get a hold on tax evasion and funds exiting the country, and they're about to have a CCTV for every 3 individuals.
The very reason the IRS hands out such severe punishment is specifically because they try to make an example of everyone they catch, since their first and foremost line of enforcement is deterrence. Case in point, this horror story you just conjured.
\&gt;  If that doesn't do it for them, they'll charge you with tax evasion and out you in jail. 
IRS agents have an unspoken requirement to prosecute cases where they can at least recoup their costs. Like any other alphabet soup agency, they don't have unlimited funds. They're not gonna spend millions to come after the measly 100k you swindled them for. 
The IRS mission is no different from the war drugs: the DEA, FBI &amp; ATF can't even put a dent in the US illegal drug market, and that's with the full power of the US federal government at their back. That's because the logistics just don't line up. As a result, more and more states are on the path of depenalization.
@_date: 2019-11-13 14:58:27
Should have been da bling. Missed opportunity.
@_date: 2017-03-19 17:49:19
While I understand the distinction, I personally expect a BU fork would see that default 16MB upper limit quickly become the norm.
@_date: 2019-11-08 12:46:03
You mean if everyone tried to sell their BTC for USD at the same time? That's a different matter. 
When you sell BTC, you get fiat, the counterparty gets BTC, and this affects the price accordingly.
If you were to redeem USDT, you're supposed to get 1:1 back in USD, and the Tether tokens ought to be destroyed as a result. There is no sale, there is no exchange. You have USD, IFinex has nothing. You will also notice the pegging ratio does not change. It's still 1:1, no matter how many tether would be redeemed.
While the price of Bitcoin varies through supply and demand, and a big coordinated selloff would crash its price, the specific attribute of Tether, and why people use it, is because it has a hard peg vs the USD. Any level of redemption should have no effect on its backing ratio.
Put another way, you could say the supply of Tether always perfectly matches its demand, which is why anyone with an ounce of sense should stay away from this thing.
@_date: 2019-03-03 19:31:45
Is it? You can pay premium for a coinbase output or buy Cascacius coins and their equivalents. It is significantly harder to move people out than it is to move money out, yet we've always managed to find a way, under stricter governments than nowadays China, mind you.
Fiat is centrally issued and regulated. You cannot move significant amounts within your own country without getting several licensed institutions involved, let alone across international borders. Yet Mexican drug lords are rich and Americans urbanites are high. Where there's a will, there's a way.
Bitcoin comes with the benefit of reducing the cost of moving funds. The average people can now circumvent legislation and government by moving its hard earned money out of reach. It is not reserved to the select few that can afford tax attorneys and top class CPAs anymore. You don't need an 11 meter ladder to climb that 10 meter wall if there's suddenly a gapping hole through it. Does it really matter if government knows where the hole is, as long as it can't plug it?
Bitcoin goes one step further. You don't even need to vote with your feet anymore. What good is a quasi slave to its state if his wealth is out of reach? Bitcoin let's you opt out of financing the government. No matter how traceable it is, if government can't cease it, you've already won.
@_date: 2019-11-05 00:21:26
So you think market actors colluding to set prices is actually a good thing for society at large? And here I thought it was price fixing.
At any rate, you're not arguing the point. The point is not whether minimum wage is good or a bad. It is that the state corrupts negotiations between market actors, because it's not about the economics anymore but about who holds the gun.
Also, intelligence is amoral. That people you perceive as super smart do something does not mean it's either good or desirable. Serial killers are notoriously smart, after all.
@_date: 2019-11-05 01:54:08
If you were applying logic, you would be addressing my criticism of your central point, not opining on a digression over a field you don't even hold a pedestrian knowledge of.
Unionizing to control the offer is the predecessor to price fixing. Lobbying the government to back your side with guns moots the underlying principles of the negotiation. Minimum wage is both calamities combined. Can you refute these points?
@_date: 2018-10-28 20:20:07
Soviet leadership and Stalin in particular did plenty of stuff that contradicts the Google definition. To name a few:
\&gt;  averse to change 
Purged academia, engineers, doctors. Seized land from the Kulaks and redistributed it. In that general trend, upended most established hierarchies.
\&gt;  \[averse to\] innovation  
Mechanized Russian agriculture in like 5 years. Built giant railroads connecting St Petersburg to the depth of Siberia.
\&gt;  holding traditional values 
Banned the Church and religion. Upended the feudal system.
Certainly, Stalin was opposed to all form of change that would lead to a challenge of his authority, but that's just part of being authoritarian, I don't think that alone makes him a conservative. 
To expend on this theme, you could argue Stalin's successors where conservative in that they attempted to maintain the regime Stalin left them. But does that really make them conservative? What if they're willing to implement any change that will sustain their power? Are they still conservative then?
This leads to the definition you offered. I don't disagree with it, but it is missing one key element: motive. Conservatives dislike change because they prefer the security of the existing order, flaws and all, to the possibility of unleashing chaos, were they to shatter this established order.
However, communism, and more broadly leftism, sees hierarchies are inherently unfair, and therefor prefers the risk of chaos to withstanding the existing hierarchy. In the case of Stalin, see purging the elites and the Kulaks.
Finally, there's another point I disagree with in your analysis. To not be progressive doesn't automatically make you conservative. Albeit, you'd have to define progressive to have a discussion about this. For my part, I'd argue these two ideals exists at the opposite end of a spectrum, and there's plenty of wiggle room in between.
@_date: 2019-11-16 02:59:56
There's still something to be said about that particular behavior. The fed can print money to help out banks with  liquidity, which in term motivates banks to tie up as much cash as they got into illiquid assets. This is incentivizing mismanagement IMO.
@_date: 2018-10-28 18:54:29
Gonna have to define conservative then.
@_date: 2016-06-05 14:10:08
New binaries can be found on my github's release page:
Development takes place mostly in the dev branch, tagged releases are in master.
@_date: 2019-11-08 15:47:06


The value of goods and other currencies vary against the USD so I don't think that statement is true. You should however argue that the supply is artificial rather than driven by market forces.
\&gt;  So whether Tether is fractional or not kind of doesn't even matter since the asset it is pegged to is fractional itself anyways. Right? 
If Tether was 100% backed it wouldn't be accurate to call it fractional. New Tethers aren't emitted when a random bank creates a loan. Tether is just meant to represent a discreet amount of USD IFinex holds. Think of how you'd create such asset: deposit X amount of USD in an account, emit X amount of a token you then trade in whatever fashion. You can claim that each token represents 1 USD. 
To me the issue with Tether is a compounded effect on its pegging pretense: Even if Tether was fully backed by USD, there is a utility value that has to be added to the price, i.e. there is friction to get USD in and out of crypto markets, therefor there is genuine demand for Tether, which isn't priced in.
If the price of Tether was following market forces, it ought go above $1 during bear markets (higher demand for "safe haven" instruments), and down during bull markets (it's now more profitable to hold crypto). Since the price of Tether does not change under these conditions, you have to assume the supply of Tether has to expand and contract accordingly, which then has to be reflected on the reserves.
A quick look at Tether supply history would tell you it isn't behaving like expected, and I believe in general that pegged instruments make no sense.
@_date: 2019-11-07 01:40:50
Have you checked those figures yourself? The % chance to get audited as a plebe is abysmal. Multiply that by the portion of people holding BTC and have a laugh.
An audit doesn't mean they'll find anything, let alone prosecute. These audits are broad net tactics, they're not pinpointed investigations.
@_date: 2019-03-19 23:20:35
It doesn't, as the Venezuelian government implemented tight control over the public's access to USD, which it can somehow enforce. Banning Bitcoin is another story though. 
Censorship resistance is one of the primary components of Bitcoin's value proposition. Valuation vs fiat isn't.
@_date: 2019-03-02 22:18:30
A government that has gone that far can prevent its citizens from effectively voting with their feet (i.e. emigrating), because it has the power to stop you from taking your wealth with you on the way out. Hence Bitcoin.
@_date: 2019-11-07 12:38:44
It will come, they will make examples. It won't be at a higher rate than the average joe. It will be low hanging fruit. Don't use Coinbase... You don't poke a sleeping bear.
Why do you think so many US residents were on Bitmex? You really think it was for the leverage?
@_date: 2017-08-18 00:07:52
I don't have time to explain to you what a KDF is and why BIP39's is weak. If you feel secure with that, go ahead. You've been warned.


A smart attacker would know how many coins to expect on your wallet, and that such a tiny, easily accessible amount is a canary, therefor these coins won't ever move and he has all the time in the world to crack your passphrase at a 2048 HMAC512 cost per attempt (hint: modern GPUs can do billions of those per second).
@_date: 2017-08-18 17:50:43
A HMAC computation can be optimized down to 2 hashes per computation. While SHA256 is not directly comparable to SHA512 when it comes to GPUs (it works on 64bit integers which GPUs aren't all that good at when compared to 32bit integers), a modern GPU will most likely achieve GH/s rates on this particular hash function.
I'm not going to guesstimate FPGA speeds as the field varies a whole lot more, but consider that at over ~4000 USD/XBT, some people may want to just go that far.
As far as "guesses" per second, you'd have to factor in the cost checking the chain for existing coins. This is a heavy task for a single machine setup and your direct bottleneck, but it can be parallelized at low cost with say, a botnet. This all from the perspective of an individual attacker, who has to weight costs to return.
If we're talking law enforcement, once they're up to speed with this stuff, a BIP39 encrypted seed is as good as gone if you don't swipe it within 48h I'd say. Until they get some crypto in them, you are "safe" by virtue of their ignorance, but that's a risk you have to assess on your own.
@_date: 2019-11-09 12:33:57
That doesn't work for obvious reasons. You cannot reduce the reserve of Tether without destroying supply accordingly, otherwise you either lose the peg or miss the reserve requirement.
There's no guarantee IFinex can by Tethers to destroy them, so this whole point is moot. Tether is basically Dogecoin, but less sophisticated.
@_date: 2017-08-17 08:33:58
This is not how you approach security.
BIP39 kdf is anemic, it's child's play to brute force the encryption. If an attacker suspects you have more coins on your trezor than he finds at first, he will try to brute force it. Canary/hidden container setups are meant for plausible deniability (you don't have any with this meager kdf) and warning you of ongoing attacks (smart attackers won't get caught).
The more coins an attacker expects you to be hiding, the higher his motivation will be. Hell, once he covers the cost of his brute force setup, he'd probably just leave it to run on any seed he gets his hands on. He is most likely preparing to run into encrypted seeds to begin with.
Even if the BIP39 kdf was somewhat stronger (it's not), this setup does not protect you: as long as your coins are on this seed and the attacker has access to it, he can attack the encryption. If he has good cause to expect lots of coins in there, he will remain patient, and you won't know what's going on until the point he wipes you out.
If you can think of an obfuscation scheme, you should expect attackers can too. This is why all crypto is developed in an open source environment: your setup is supposed to withstand direct attacks, instead of relying on the expectations attackers will never figure out your "clever" trick.
Your first layer of defense is your financial privacy. If it's easy to figure out your net worth, no amount of obfuscation is going to protect coins in a faulty device.
@_date: 2019-11-06 17:51:53


Past a certain net worth, it's cheaper to pay lawyers and accountants to hide your money than to pay taxes, otherwise tax evasion wouldn't really be a thing.
The taxman's deterrent comes in two folds: first they will take all your money, then they will ruin your life. With BTC, they can't take all your money. It is only reasonable to reassess the deterrent under these conditions.
The question isn't whether people would choose to have their lives ruined if it meant they get to keep the cash instead of losing it. It is one of logistics. With the current tax evasion status quo in mind, what chance does the IRS stand to enforce the tax law if its power to seize is neutered?
@_date: 2017-08-17 13:02:57
The idea of a hardware wallet is to be self contained. It should not require external code handling critical assets to secure your coins. If it does require external code, suddenly parameters have shifted and the device loses both in security and utility.
If, as the author claims, an attacker can extract critical assets from a Trezor, it has failed its purpose as a secure storage device. At this point, it's merely a signer. 
If your solution is to involve a software KDF, you have introduced the need for external critical asset handling code. Now you need an offline machine to KDF on top of your Trezor, which is not any less broken.
@_date: 2019-11-12 19:53:48
Sound money as opposed to the current system of ad nihilo inception, fractional reserve and artificial inflation rating, is already environmentally conscious in and of itself. 
If you are concerned about the environment, you should argue for Bitcoin to take over, which is to argue for more miners.
@_date: 2016-11-12 02:42:15
The installer framework (NSIS) adds its own stuff to handle the uninstallation process.
Armory only creates/updates the bitcoin: URI scheme in the registry. It does not use the registry to save settings across installations, it uses text files in your datadir instead.
@_date: 2016-11-26 05:29:37
C++11 was introduced in Armory in early 2014. Even today, I build Armory releases on old Debian Wheezy. The code builds natively on OSX, Windows and most flavors of *nix. 
It's even cross compiled for Raspbian, and I had a WinXP build of the first C++11 enabled version for internal purposes.
I won't lie, Armory has had its fair share of troubles to fully build in C++11 across all of the platforms it officially supports. But it could done and has been done. 
Somehow, I am very skeptical that it would take a for profit organization a whole quarter to figure out how to build someone else's code against this "new" standard (that isn't all that new anymore, the committee is going over C++17 atm...).
It's my humble opinion that this is a minor factor in what is actually at play.
@_date: 2016-11-09 14:47:45
How is it that some people in the USA deem Assange a traitor when he is an Australian national? Could never wrap my mind around that one.
@_date: 2017-08-17 12:31:40
Basically, you are saying "use a long passphrase". Sure, that's a way to counter a weak kdf. I don't need to explain to you how that defeats the purpose of a Trezor as a long term asset storage device. You're still back at the air gapped, software signer.
@_date: 2016-11-12 01:39:37
The installer is actually just copying the portable folder into program files. It's easy enough to provide, more of a matter of remembering to do it.
@_date: 2017-08-21 14:39:33
BCH still lacks a lot of things to be a clean fork:
1) They need to change their script hash prefix to signal their chain within addresses. Currently, wallets cannot tell the difference between an address meant to receive BCH or BTC. I cannot think of a technical reason why they did not take this step. Hopefully BTC will soon move to bech32 addresses for native SW, so that issue will be eventually resolved, but by no merit of BCH.
2) Their difficulty adjustment change and identical network port eases the execution of sybill attacks, where you can isolate a node, feed it enough full difficulty blocks at large intervals to stretch the median time to the point where you can drop the difficulty that node will accept to something meaningless for a modern ASICs, and run a bogus chain. 
Now consider their chain has ~1/15 of the BTC chain difficulty, so it's easy to compute those full difficulty blocks to begin with.
Pair this with the fact that BCH uses the same network port as BTC and have a tiny node count in comparison and it is painfully easy to sybill a BCH node. As a matter of fact, my BCH node takes sometimes over an hour to bootstrap with actual BCH nodes, while I have to manually kick the BTC nodes overwhelming it.
3) While their replay protection is a good step forward, they basically air dropped that some 4 days before the split. In general their development needs to be more open. You could levy criticism against the B2X fork because you could actually parse the changeset. BCH went out of its way to reformat a lot of code files for no apparent reasons and that makes reviewing their actual changes a titanic task for basically anybody. 
I dread their next version.
4) To this day I still do not know how to access their testnet. Say what you want about B2X, but it's sufficiently close to BTC that I don't have to preliminary test changes to signer code on the damn mainnet!
Let me clear, this post is not in defense of B2X over BCH. I personally believe BCH is poorly executed at the technical level and B2X is lined up to be even worse. 
For B2X to be successful, they'd need to do what BCH did without the mistakes (replay protection shenaningans, just HF the diff), do the extra stuff BCH is missing (change script hash prefixes, network port, magic numbers) and keep their development actually open (which neither BCH nor B2X appears to have a taste for).
I only wish separatists would fork cleanly so that we can both go our separate ways. The right to dissociate is a beautiful thing and I love Bitcoin for enabling it. But for the love of god, BCH and B2X people, fork cleanly. The only thing BCH has managed to achieve so far is to give service providers and wallet developers a massive headache.
@_date: 2017-08-17 11:53:25
Scrypt is a good kdf. Your Trezor can't handle it. That opens up a whole lot of other complications, which concludes with just using a software signer on an air gapped machine.
My comment was mostly to emphasize on how dangerous the illusion of security can be.
@_date: 2017-08-17 13:43:34
In the scenario that a Trezor has to rely on a software KDF from another machine, then its security is only as good as that machine. In this case, the Trezor is pointless. If the security of Trezor is not impacted as the author claims, then this discussion does not apply to Trezor. The security analysis is valid however.
On PCs, you can review and sign code. You can check the signature with different machines and implementation. You do not know what checks the signature within a blackbox. From your perspective, a Trezor is a blackbox.
On PCs, you can write you own code to challenge the assumptions of the software you are running. You can monitor the kernel, you can modify the code, you can run alternate implementations. You can swap the hardware as a whole and run the exact same tests to yield the exact same results. 
You can use solutions like Gitian to build the code yourself across several platforms and yield the same binary, in a verifiable way. 
You are right, an offline computer and a Trezor are not simply equivalent. A PC is far superior in all aspects.


That point is invalid. To get to my wallets, you need physical access to my offline signer. At this point you are better off going after my paper backups. The same applies with a Trezor: you will have a backup seed outside of that device, and that's easier to attack.
@_date: 2016-11-30 17:15:03
These kind of threads are better off in the dedicated Armory forums ( You will get more attention from the user base, and well, me.
First, make sure Core is up to date and running. Then, post your log files.
@_date: 2016-11-11 15:53:07
For windows?
@_date: 2019-10-21 14:36:05
I made 50BTC selling loot during the first month of Diablo3, just saying.
@_date: 2016-11-11 22:50:24
I'll consider
@_date: 2019-10-25 02:08:30
It is a well document fact that drug deals didn't exist until after crypto was invented.
@_date: 2019-10-28 10:13:04
He was neither. He was employed by an IT security private company that contracted for the US government. In his 10y+ run, he worked at the NSA and the CIA in that capacity.
@_date: 2016-11-09 17:11:48


Assumed your perspective from the wording of your sentence. Also, Assange is often branded a traitor in US media, so I hoped you would shed some light on the matter regardless, since you held that stance. Guess I won't get my answer today.
@_date: 2019-10-24 12:51:19


We're hard wired to track value and status though, not gonna happen.
@_date: 2016-11-11 02:40:32
There is no documentation as of now. This is the first version of the client server model, so it may change in the future.
This version uses HTTP over FCGI, you can see the reflection code on the server side here:
And here you got the client side socketing and ser/deserialization of packets:
I chose HTTP because it is a web standard, and I hope to deliver a JS API for easy client side deployment via web browsers. The idea is to turn Armory's DB into a web stack blockchain parser service. I'm looking at adding a websocket interface as well, and BIP151 for encryption. I don't particularly like the infrastructure around SSL/TLS, I prefer Core's approach in this case.
Once that layer has congealed, I'll come up with diagrams of the implementation and API doc.
As for the db modes:
1) DB_BARE is the 0.94 mode. Very light DB (~0.2% of the blockchain), but cannot resolve arbitrary tx hashes (it can't figure out the origin of received payments)
2) DB_FULL is the new (and default) mode in 0.95. It adds a small db (~1% of the blockchain) and can resolve any tx hash, albeit slowly. The db is used mostly to provide a one time resolution of payer tx hash.
3) DB_SUPER keeps track of all script history in the blockchain. This is the "block explorer" mode and it isn't available in my fork yet. I will reintroduce that mode (I wrote those in the ATI versions of Armory) after a few key feature are delivered:
a) SW support
b) BIP32/44 wallets
c) RBF and CPFP support
d) BIP151 for node and server/client layer
e) blocks over p2p
In other words, we aren't there yet, but it is my destination.
As for people concerned about the change in URL: I do not control bitcoinarmory.com, that belongs the ATI, the previous maintainer. With the help of achow101, we setup btcarmory.com. This is a gh-pages website, you can see the code here: 
Even though I have commit privileges on Alan's repo, I chose to fork it, since I have changed the licensing for all the code I'm adding from ATI's AGPLv3 to the more open and permissive MIT license. 
The releases are now signed with my offline key instead of Alan's. I'm also working towards autoconf support and breaking down the code in submodules to introduce Gitian support (deterministic builds), so hopefully people can verify my builds in the future.
@_date: 2019-06-25 09:37:39
I doubt it has anything to do with that. AFAIK he is still in the business of selling PMs. Can't keep those gold bugs buying if you suddenly jump ship. And it is my personal belief he is really cynical about it too. Why would he market that nonsense otherwise:
@_date: 2019-02-02 12:23:49


He would have been just as fine if the technical community had afforded him significant weight in the development cycle, like he had under Gavin. 
He supports the benevolent dictator model, that doesn't mean he doesn't value decentralization, or that he has to be the dictator. For one, he was on the side of multiple consensus implementations. However, you can certainly say he doesn't value decentralization enough to be a competent Bitcoin dev.


Again, I don't think he intended to centralize Bitcoin for the sake of centralization. I think he assumed more centralization was an acceptable cost to pay in order to push Bitcoin towards a payment processor role, ala Paypal/Visa. There are varying degrees of decentralization, it's not a binary.
Hearn never really cared for the censorship resistance. He saw it as a hurdle to regulatory adoption. In the same way, Hearn argued the project put too much emphasis on decentralization for its own good. He was a partisan of "don't let perfect get in the way of good". Now, if you want to interpret that as centralizing Bitcoin, it certainly is, all that is right of Marxism is alt-right to a radical leftist. It's a convenient shortcut, for sure.
But it's unfair to paint him as some active enemy of Bitcoin and decentralization, bent on the destruction of all that is valuable. Hearn gave his big blocks idea a shot after Gavin was deposed, which lost him his privileged access to Bitcoin development. It failed, he walked away. Compare that to Ver and his clique. 
I would argue Hearn was genuine in his concerns about design vs market adoption. I would also argue he was wrong. At least he had the decency to stick by his ideas and move on once they were rejected.
@_date: 2017-11-09 20:36:49
That's basically an argument by authority. I don't see how that helps.
@_date: 2017-11-18 01:11:40


I don't know, he looked pretty happy pushing the idea of aggressively orphaning the minority fork around the time BU had more miner signaling than SegWit, along with Peter Rizun.
He also systematically opposed all development efforts within Core that touched mining under his reign (before it was named Core, during the Bitcoin Foundation era). Not to minimize miner's irresponsibility in this never ending debacle, but try to imagine how the network would be today if there was a drive to push p2pool forward and implement it by default in Core back then?
@_date: 2015-08-21 22:19:24
It's the Bitcoin Core DB failing, not Armory per se, curtesy of LevelDB. Armory uses LMDB now, but Core still sticks to LevelDB, so there isn't so much we can about that DB's stability.
There are 2 main ways to contact us: the bitcointalk forums and our dedicated support channel. Armory developers do not read r/Bitcoin on a regular basis, as such this thread was linked to me.
Our FAQ details how to setup Armory and how to troubleshoot this very issue. This issue has also been addressed countless times on our subforum on bitcointalk, where the Armory community would get this user on the right track quickly if no developer was around at the time. Our direct support channel would take care of him painlessly as well. 
Instead I'm greated with what I can't help but characterize as an incendiary title, for what is a common and easily troubleshooted problem.
Armory is a free open source wallet with expert features, we expect our users to read the setup instructions and to be familiar with Bitcoin mechanics. It is critical for new users to read and understand the setup instructions, as it guarantees they use our software correctly. Otherwise they could be using Armory in an unsafe manner while remaining under the impression that their coins are secure.
I understand that my reaction came as disdainful and I apologize for my behavior. However, I hope you see where that feeling came from.
@_date: 2019-02-04 10:15:17
Maybe add a distinction among legal countries between friendly and hostile fiscal policy.
@_date: 2017-11-06 01:07:59


I guess I have to repeat myself. You cannot convince the technical community that your change is necessary until you demonstrate that the status quo is technically broken. You could argue that you change is better, but that does not hold when you insist on implementing it through a HF.
You're the one who wants to implement a change, it is on you to argue its virtue. It is not for the technical community to demonstrate the status quo is not failing. This is exactly like the justice system: you accuse, the burden of proof is on you.
Your claim of competitiveness is doubly pointless. Competitive against whom, at achieving what? And how does any of that even relates to the technical basis of Bitcoin?


It was technical sound and needed. The malleability on its own is a necessary fix. If you'd understand how malleability works and how you go about fixing it, you would realize the move to block weight is the natural follow up. Block size is a technically inferior metric to block weight. Block weight allows for the realignment of incentives proportionally to the costs of the network, the biggest of which is the UTXO set. The witness discount encourages a reduction of the UTXO set.
You can't possible expect to debate this point without substantiating your claims, do you?
@_date: 2017-11-06 14:43:52
I doubt these exchanges will tolerate arbitrage on a synthetic index.
@_date: 2017-11-05 21:44:48


Bitcoin was sound at $0.005, and it is sound at $7500. Your argument is not technical and it erroneously implies Bitcoin could not get to the point it is at today through whatever reasoning you do not bother to demonstrate. Do you expect me to take for granted an argument that contradicts history?
At no point have you argued that there is a technical basis against 1MB blocks, and neither have you bothered to argue for 2MB. So far you've only presented doom and gloom conclusions from conjecture based on unsubstantiated economic claims.
Let me give you context since you have so far not bothered to provide a proper argument yet continue to engage me. I am a member of the technical community. I donate time and expertize for free to grow the service space that Bitcoin operates upon. 
If you wish to implement a technical change to the core layer of Bitcoin, you need to first convince people like me that Bitcoin is technically broken and that your change fixes it. You have done neither. You may choose to take the likes of me for granted, or dismiss my technical expertize, and fork anyways. You will find yourself without me nor my kind on your side of the split.
Either convince the technical community, or do without it. So far you've only managed to demonstrate you can achieve neither.
@_date: 2017-11-05 14:25:14
What are you arguing here? Fees rising demonstrate increase demand vs stable supply. Is unmet demand destroying Bitcoin at the technical level? Do you have a __technical__ argument as to why the block size should be increased? Does this argument stand to common sense __technical__ criticism?
@_date: 2019-02-01 16:04:44
I don't think earn wanted to centralize Bitcoin as much as he wanted to be the lead dev/scientist of the project. He was fine ostracizing all major contributors and eroding network decentralization if it meant getting he would get his way.
@_date: 2017-11-06 14:21:09


You could "mine" your own CPFP, i.e. iterate a nonce and hash until the CPFP spender effectively comes after the parent respective to the canonical ordering.
You would shift the burden to individual users who wish to chain ZC transactions. Haven't thought about the pros and cons but that would probably allow for this change without any significant regression.
@_date: 2017-11-09 20:14:01


That only stands if you make an open commitment to call off the fork for lack of consensus, have proper replay protection code in place to cover for the worst case scenario (i.e. an actual split), while sticking to a sensible fork schedule (3 months really?).
Also, having a testnet would be nice, and seeing the damn code too. 
Instead of that, the fork was called off 10 days before the due date, with no indication that the splitting party had any intention to back off prior to that. I'll let you imagine how many developer hours have been squandered at various exchanges and services to prepare for this aggro fork.


Being polite does not give you license to be an aggressor. A civil argument does not bar you from insulting your counterpart's intelligence with borked reasoning and bogus claims (we got consensus).
If I politely argue with you that the earth is flat and employ my resources to stop you from boarding planes cause you will "fall off the edge of the world", am I not infringing on your rights? Am I not making a fool of your intelligence? But hey, I was polite.
@_date: 2015-08-26 21:02:48
I proposed a few changes to this dynamic algorithm, among which:
- to modify block size based on difficulty change if the conditions are met for a resize
- to only trigger a block cap increase in case fees were significantly superior from one difficulty period to another
- to get rid of the status quo condition and replace it with a decay function instead, that will always reduce block cap by a set portion if no increase takes place.
The original author only kept the first 2, skipping the last one, which is specifically designed to counter spam spikes and miners that try to game the system. The decay function forces bad actors to compound their effort to maintain the benefits of their attack, whereas the current status quo condition allows them to raise the ceiling and just ensure (at a relatively low cost) that no downsizing will ever take place. 
The decay function also helps sustain a proper fee market after too large a block cap increase.
@_date: 2019-02-20 23:49:28
He had to let it go I bet
@_date: 2015-08-30 10:08:17
You mean like mining dust spam transactions?
@_date: 2017-11-24 01:09:34
Each block sercures every tx in every previous block. It's a crass misunderstanding of PoW blockchains to pretend all that energy is expended for one block, as if that stuff took place in a vaccuum...


PoS does not achieve the same thing as PoW on the epistemological level. That makes it MUCH easier to attack by state actors than the primary PoW chain. But since you purport such a shallow misrepresentation of PoW chains, I don't expect you to have thought the problem through this far.
@_date: 2017-11-06 15:08:52
IIRC, the way Finex did this with BCH was to create 2 tokens. Each BTC you deposited pre fork could be split into one BTC and one BCH token. You could then trade these tokens, with a promise that they would materialize into actual BTC and BCH post split, but you could not withdraw either token pre fork without reuniting them into a single actual BTC.
I don't know how it's being done now, but I don't see why BitFinex, which implemented this back in July, would bother using a different system now. As a matter of fact, isn't the seemingly large arbitrage opportunity evidence that such methods are employed today?
@_date: 2017-11-27 20:12:55
If I actually did that IRL with a semi girl of my dreams, does it mean ima fuck up with BTC too?
@_date: 2017-11-09 22:35:22
It is an argument by authority when your only point is that they garnered respect at some point in this ecosystem therefor you ought to introspect your reasoning on the sole premise that their ways ought to be impenetrable. 


That's quite an unfounded statement. Plenty of early adopters are in support of the current state of Bitcoin and oppose hasty and irresponsible hard forks. 
And for what it's worth, I don't remember supporting any of the "early adopter turned big blocker" bunch even before they were vilified, and I wasn't alone in this, far from it. Remember the P2SH debacle? If you think the likes of Gavin, Hearn and Garzik are some sort of enlightened engineers, sole guardians of the soul of Bitcoin, you either weren't around during the Bitcoin foundation era, or you have a short memory.
My only exception was defending Gavin when the CIA invitation came about (I think that was late 2011?) but I was an idiot back then and I've learned from my mistakes. Gavin is a nice guy after all, so I was more inclined to give him the benefit of the doubt than not.
But I digress. No amount of credentials will turn a bad technical argument into a good one. Apparently taking the network hostage with an aggressive fork, and talks of actively orphaning the minority chain is what "respected experts" do? At least Hearn had the decency of moving on once he realized people were not interested in his vision.
At any rate, I don't see how you can still assign these people any wisdom anymore. Look at the garbage BCH is. Isn't that evidence enough?
@_date: 2015-08-21 19:50:45
Sigh... this is why you get Armory online *before* you fund your wallet. Follow these steps to get online:
1) Backup your wallet. Also backup your root key. 
2) Make sure you are using the latest version of Armory (0.93.2) and Bitcoin (0.11.x)
3) Start Armory in offline mode, in File -&gt; Settings, check off "Let Armory run bitcoind in the background". Save the setting then go to Help -&gt; Rebuild and Rescan. Finally, shutdown Armory.
4) Start BitcoinQt manually and let it load. It will probably tell you its database is corrupt then start verifying transactions from scratch. Ideally you want to start with a fresh /blocks folder, but if you want to cut corners, that's up to you.
5) Once BitcoinQt if fully sync'd, start Armory once again, let it do its thing and you should be fine. 
If you are having trouble with any of the steps, create a ticket here: 
One of us will walk you through.
@_date: 2017-11-05 17:36:09


I await your technical demonstration as of how Bitcoin is failing. So far you're construing your argument on an economic basis, which is __NOT__ the ground for a technical change to the protocol.
If your intent is to impact the economic side of the equation, you need to look at improving the service industry, i.e. layers that exist in between the blockchain and the consumer. 
Keep your facts straight or there is no debate to be had.
@_date: 2017-11-05 01:32:43


You are looking it backwards. You need to argue why a 2MB hard fork is necessary, not why the current settings are "good" (that's evident, Bitcoin is working just fine).
A hard fork is no small change to deploy. Without a strong technical argument for raising the block size, a 2MB HF is simply frivolous. If the community tolerates such a thing, it not only undermines any further changes of a technical nature, it also creates a precedent for increasingly worse changes. 
Just look at Ethereum, how many HF are they at now? Or look at BCH. It was a poorly executed fork, and now S2X is set to be even worse.
@_date: 2017-11-06 14:48:27
Why do you assume one exchange would aknowledge a future contract from another exchange? How do you expect to "move" your futures from one service provider to the other?
@_date: 2015-08-21 13:05:43
Would you consider inviting an advocate for each side of the fork from the technical community, through video conference? Or is this out of the panel's scope? 
I believe it would add a lot of value to see each side defend the points presented as long as it is moderated.
@_date: 2017-11-09 14:26:03


I don't have any hard data on this but it seems pretty evident. A good way to get a baseline for this is to identify out of band transaction volume, i.e. stuff that never hit the mempool but gets mined. These are typically the result of contracts between service providers and miners to reserve block space.
OOB is the reason why smart fee calculating algos cannot base themselves on mined tx and have to rely on the mempool only. It's also why they are so hard to get right.


What you want is a decentralized blockchain. Centralization at the service layer is another discussion and much more open to innovation and competition than the blockchain itself is. There is a very strong argument for keeping the blockchain layer "agnostic". Any kind of chain level changes that would steer the network towards a specific end user application will wreck havoc in the service layer.
Let the service industry figure things out on this front and leave the chain layer alone.
At any rate, some providers have to be centralized to offer the service you expect out them. This is true for any model that requires custodianship.
If your idea of retail in the crypto space is atomic on chain swap between btc and fiat bearer tokens, I don't believe that's a possibility nor something we should shoot for. Apart from the technical hurdles (and they are large), you'd still have to fight the legal battle. No thanks.
Even if such a system existed, custodian IOU corporate services settling their ledgers periodically (think coinbase and bitpay reproducing what's going on in the current banking system) will still be far  cheaper, faster and more efficient than any on chain solution.
As for LN, I see it as an innovation the service industry requires, same as SW. SW main innovation is the malleability fix. You may not ever care or see the effect at the customer/retail level, but this is a very significant change as it enables model that require chaining unconfirmed transaction. This is how Decred could perform that on chain pseudo atomic swap. 


Exchanges already KYC their customers. LN allows them to reduce their costs in miner fees (better for their customer) while reducing their on chain footprint (better for all Bitcoin users).
@_date: 2019-02-01 15:58:18
When Hearn and Gavin started to push BitcoinXT/Classic/whathaveyou, their main narrative was that LN was nowhere near ready, and would still require 100MB blocks to support VISA levels of tp/s anyways, so might as well get rolling with the size increases already. 
This is because LN was already the go to solution to tp/s scaling since years prior, yet the implementation was progressing at a slow pace.
  
SegWit came later, as a fix to malleability, a necessary improvement for efficient LN channel operations, but LN, at least as a concept, has been the primary reasonable solution for scaling since scaling was on the table.
@_date: 2017-11-08 21:02:00


That's a bad criticism. Service providers emit most of the transaction volume these days. They would have incentive to setup their own LN channels to cut down on their own fees, ergo cutting down on their on chain foot print. Stop assuming all scaling solution have to be tailored to end of line consumer use cases.
@_date: 2019-04-11 11:57:57
It's not that simple.
1) Snowden made it to Russia thanks to Wikileaks' help. He was stuck in a HK airport's international zone with  nowhere to go until Wikileaks lawyers managed to get him a visa to Russia.
2) Wikileaks has leaked on Russia and Russian allies. 
3) Snowden only leaked on the US intelligence community, and refused to give the data to Wikileaks on the account that they don't edit the sensitive parts out. Instead, he gave the leaks to the NYT, the Guardian, and Der Spiegel, which reportedly only released about 5% of the total content. All the while, the NYT is on record admitting to discuss the material to leak with the White House.
Snowden simply isn't in the same league as Assange, I doubt Russia would have him in the first place.
@_date: 2017-04-04 13:55:18


Would you care to elaborate on this assumption? My understanding on LN is that it does not introduce a new transaction format, it simply updates output values on valid Bitcoin unconfirmed transactions as a mean to update channel states, and does not bother with committing mid states to the chain. 
LN isn't even a softfork for that matter. How do you argue that LN breaks UTXO compatibility?
@_date: 2017-04-17 11:55:36
You can't really deprecate OP_CHECKSIG due to P2SH constructs. The only sound path towards effective abandon is a type of txin incentive ala SegWit.
@_date: 2017-04-08 12:29:25


It can but is it acceptable?
ASICBOOST let's you reuse the expansion step on the lower 16 bytes of the header with all colliding midstates. Since you can only use the header nonce without invalidating the collissions, you have a 2^32 space to search for a solution per collision.
Modern miners operate in the TH/s. Even with 16 collisions, a 1TH miner would eat through the search space in 15ms. I don't think you can afford to defer the collision search to a GPU. To really leverage the covert boost, I expect you need some dedicated silicon on the miner.


If Greg's SF only affects the collision search space on full blown merkle trees, then you are right that it has no effect on the boost in empty blocks. I was under the impression empty blocks were locked into a constant coinbase value (ie no extra nonce) but when I think about it that doesn't make sense anymore.
Killing the extra nonce grind in empty blocks will prevent that approach but at the same time miners can just shuffle a tiny set of pay to self transaction around if they feel so inclined.


Again, I think modern miners blow through the search space too fast to get any real benefit from collisions served by external circuitry. The latency of the transport protocol alone would damage the gains. I expect covert boosting hardware to have some sort of FPGA on board, dedicated to the collision search. 
Not like you can't reprogram the FPGA though.
@_date: 2017-04-13 23:24:01




How else do you propose to do this? You cannot trigger the BIP9 activation without forcing miner signaling on that chain. BIP148 only sets out to do that.


Post split is where you see the lay of the land. The thing with the economic majority is that it is hard to evaluate it. At best you can draw estimations, since words are just that after all. The split gives you a read of that majority instead, and about 3 months to let it cook. This should be enough time to know which side of the fence you are on.
Are you suggesting a UASF is dictating a monolithic move towards a soft fork? Otherwise why would you be concerned with the split? The header versioning acts as wipeout protection already.
@_date: 2017-04-06 14:16:52
There are other explanations as to why he didn't reveal his sources or name names. Usually that's because any significant piece of evidence would unmask the insider that had his hands on the particular piece of hardware. Consider that he didn't only omit the make and model of the hardware, he also omitted the name of whoever reverse engineered said hardware, as well as how the hardware was acquired.
If you read between the lines, this alleged boost is not available at the software level, but hidden in hardware. You could speculate that only a few select people can get their hands on this stuff outside of the manufacturer itself.
Obviously, you can't charge someone on allegations alone (I'm using legal lingo but referring to ethics in general). You need hard evidence.
However, the allegations of foul play and the existence of the exploit (in this case, the covert ASICBOOST path) are orthogonal. You do not need to find culprits to fix a vulnerability.
The discussion is not so much that someone is using this exploit, but rather:
1. Do we consider this computational shortcut, in its covert form, a vulnerability/exploit?
2. If so, does the proposed solution fix the vulnerability without introducing any other exploit or degrading security?
Detractors to this fix have to successfully argue against at least [1]. If they fail to do so (I would argue it is a vulnerability), they need to demonstrate how [2] does not fulfill its exclusive purpose, but then they are left to provide another solution, lest we HF the header format to nuke this short cut once and for all.
In conclusion, it is not relevant that the exploit is in use. It exists and needs patched.
@_date: 2016-02-04 01:50:47
I started putting considerable hours in 0.94 today, so I hope to get a testing build out this month indeed.
@_date: 2016-02-04 23:35:04
I'm writing the new DB with pruned nodes in mind so that I can turn that full functionality on sometimes down the road. The change is actually quite simple and rewriting the DB to only run off of the UTXO set (instead of parsing the full history) is significantly easier. 
But that's not what Armory is about, and while I will accommodate for pruned nodes, I expect users that want to enjoy the full extent of Armory's features will take it on themselves to disable pruning as a whole.
Anyways, it's preferable that I adapt Armory to Core rather than Core adapts to Armory.
@_date: 2016-02-14 15:34:53
Armory has a built in minimum fee feature that users can modify at will.
0.93.3 introduced a feature to query Bitcoin Core through the RPC for the proper fee per tx. This should apply to any raw, unsigned transaction. This feature is only available when Armory is managing bitcoind (otherwise it can't guarantee Core is running with the RPC password of its choosing).
If Armory is not managing Core, then it will fall back on its own fee calculation formula which is probably outdated. It has changed at least once per version in the last couple years and I'm not sure if it's any accurate anymore (2 major versions of Core where released since the last time that code was updated, in 0.93.0)
@_date: 2016-02-02 18:57:50
This is getting off topic so move to PMs if you want to further this conversation.
What you are talking about was 95% of what of 0.94 was about. 
0.94 was never released because of the company problems we are facing.
@_date: 2017-04-08 12:33:25
I don't think we are at the point of indulging in Karpeles parallels just yet.
@_date: 2019-04-11 11:48:05
He probably cheered when Obama renewed the Patriot Act!
@_date: 2019-04-13 07:18:40
1) Create tech to be your own bank
2) Pass the cash to a 3rd party for safe keeping
Adds up...
@_date: 2019-04-25 01:22:24
I dont get how XRP is even a thing.
@_date: 2017-04-02 23:56:43
roasbeef mentionned something like that indeed.
@_date: 2017-04-06 17:18:46


To believe the allegation of a manufacturer embedding the covert method at the hardware level, you would have to believe nullc on his word alone. Note that he didn't name any names, so there isn't much to believe to begin with. What nullc basically said is someone implemented the covert ASICBOOST path in their hardware.
You do not need to trust anybody to know that:
1. ASICBOOST exists
2. You can implement it in a non obvious fashion (to external observers)


The covert method does not imply empty blocks. It can be performed on blocks with transactions. It is cheaper to grind the coinbase in empty blocks however, but would be too obvious.
Miners mine empty blocks because they don't want to bother implementing towards technologies that improve their block verification time. The existence of the covert method is orthogonal to miners' laziness. That laziness has a cost, as an empty block is naturally less rewarding than one full of fee paying transactions. 
To infer that empty blocks are the sole marker of covert ASICBOOST mining is invalid. There's only minor conjecture to sustain that claim. But again, it does not disprove the existence of a covert ASICBOOST path.


Do I need to know that? If the economic majority wants to allow for ASICBOOST, it would tolerate overt method. We should get rid of the covert method regardless. This does not break compatibility with miners nor reduce the security of the chain. It does level the playing field with hardware that does not support this method. The normalization of ASIC performance across manufacturer is a desirable thing. It reduces the price to the consumer and increase market penetration. The economic majority should not tolerate the existence of covert mining corner cutting methods for this very reason.
@_date: 2019-04-12 14:47:04
Somehow I'm under the impression that was common knowledge prior to the 2016 election. Then it became an inconvenient point, and suddenly Assange is Putin's top spy...
@_date: 2017-04-07 00:18:38


This is the part I don't get. They are basically admitting that the covert ASICBOOST method is damaging to Bitcoin (otherwise where is the virtue in not using it), but somehow argue it is not acceptable to prevent it on chain?
@_date: 2016-02-02 03:42:39
It can support pruned blocks, you won't get the transaction history though, only current balance per address.
@_date: 2019-04-14 21:26:12
They're shielded by inane regulatory procedures. Getting MSB licenses in every state is demented. It costs millions and takes years. Coinbase is a lawyer shop, not a tech company. This is why they suck, and also why they're still in business. For a lot of US consumers, they are the only choice available.
@_date: 2017-04-07 21:09:55
My understanding of nullc's proposal was either:
1) kill coinbase grinding for legacy tx by forcing some constant as the extra nonce.
2) have miners commit to the SW Merkle form in the coinbase tx, which bloats the search space to the point where looking for a collision of the lowest 4 bytes in the header Merkle root becomes too expensive to justify covert ASICBOOST'ing.
I may be wrong in my interpretation of the effect of the SF, but if I'm not, wouldn't this also kill the covert boost in empty blocks?
@_date: 2016-02-03 21:51:34
1) Alan is the founder and former CEO of Armory. He hasn't been CEO for over a year now, he was CTO up until recently.
2) Quoting you: "...that for the time being the Armory wallet is not going to be further developed."
He didn't state that. He said he is leaving Armory, that ATI cannot continue to operate as a business anymore, and that I will be taking over open source development immediatly.
3) Quoting again: "...that longer term another developer will be taking over the development of the wallet."
Again, he said "in the immediate future". I committed code to my fork today. An active member of the community is already offering to implement RBF support.
4) "The future of the wallet at this time seems extremely uncertain, as the post raises a lot of doubts on how it will continue on, even with a single developer trying to keep it alive and the issues with the business side of the wallet continue to persist."
Armory had 6 developers, 5 of which were working full time on private features. I was the defacto maintainer for about 2 years, as I was the only one tasked with work that made it into the open source repo. 
I committed over half the code in 0.93 and over 90% of the code in 0.94, even though that version never got out of public testing. It was quite successful while it was still publicly available however: blockchain scanning went from over 1h to sub 10 minutes, and the DB shrunk from 40GB+ to ~250MB.
I developed that DB, I am fully capable of reproducing that again, and I am in the process of doing so as of this writing.
Instead you are all doom and gloom about the future of the project, when in reality I now have more time to work on purely open source code. As far as the users are concerned, that's a good thing.
5) You would have at least some of that information if you had tried to contact either Alan or me prior to releasing your article. You didn't try to contact me, and seeing how fast you released your piece, chances are you didn't try to contact Alan either.
@_date: 2016-02-03 21:09:42
Hmm, that's kind a sloppy article.
@_date: 2016-02-03 23:43:49
I'm up for all 3 really. I'm sad the Gitian work can't be salvaged, and that's something I'd really like to redo. 
Crypto++ is getting old and I don't like the idea of having that many unnecessary code for all that crypto we have no use for in Armory. I'd be looking forward to sipa's library just to clean up the code base.
Python 3 will be easier to deal with once I'm done with litenode, which splits the DB from the frontend (less SWIG snafu).
@_date: 2017-04-07 19:41:51
How so? If you can't grind the coinbase, the covert path is impossible without at least 1 extra transaction.
@_date: 2017-04-06 01:40:25
Just upgrading the block header format would be enough, and there is an arm long list of improvements in the waiting. 
However that's a HF, so it's not a desirable option on its own, but a much less damaging alternative to a PoW change.
@_date: 2017-04-07 22:24:29
You mean by replacing the script hash in the coinbase txout?
That would change the coinbase hash, hence the merkle root, sure. But we are talking about finding a collision in a 4 bytes space so an average of 2^16 address swap per attempted collision. That's a whole lot of ECDSA operations or a massive look up.
I think at this point, the I/O cost to swap addresses and push the work to the silicon and/or holding that large lookup locally (I think the latency in swapping work that fast hinders performance as well) defeats the edge you get by grinding the collision in the coinbase tx. 
Consider that the goal of the SF is not to prevent ASICBOOST, just to make it less profitable as a coinbase grind, because that incentive conflicts with a whole lot of desirable protocol changes.
Then again I may be wrong in my understanding of the SF or how far manufacturers would be willing to go to hold onto the covert path. I'm no mining expert after all. One thing I'm fairly confident of, is that if output grinding is viable, the current hardware is not built to deal with it.
This whole debate would go out of the window if we were to HF the header format to move all these new desirable commitment structures in there instead of shoehorning inside the coinbase. The current conjecture is not favorable to a HF at all, so that's off the table for now.
@_date: 2017-04-07 01:26:50
Let's not conflate issues here.
Miners are supposed to be selfish by design. Miners are also supposed to be straight up employees of the economic majority, and nothing else. If somehow their incentives misalign with what is expected of them (by the economic majority), then the incentives should simply be realigned. 
Swapping POW does not effect the incentives, it just fires the current set of miners, while not preventing the new batch from sustaining the same behavior.
The current situation can be rectified by UASF and getting rid of any hidden financial incentives that contradict technical evolution of the protocol (in this case some sort of merkle root collision via coinbase grinding "nerf").
The other side of the coins is that SHA2 is, believe it or not, desirable. Maybe moving to SHA3 to prevent these kind of padding attacks would help, but it doesn't change the underlying parameters for picking the POW algo.
The key parameter here is to reduce the barrier of entry into the market. You need a well understood and straight forward hashing function to forward this proposition. Swapping to multiple functions and/or a complicated function increases the optimization surface, which in turn increase the time it takes to reach computational power status quo among manufacturers.
That status quo is desirable. The long term solution to miner centralization is market penetration. Once we hit the physical limit of silicon (we are basically there with 7nm, slated for 2018), the only thing separating mining hardware performance is cutting corners in the workload. With a well understood and simple algo, there is only so much corner cutting you can implement until you plateau.
Reaching that point would see the mining hardware market stabilize, production streamlined, prices depressed and availability increased. Then it becomes viable for individuals and small businesses to invest in some mining hardware as an alternate path to burn extra unstorable energy/produce heat/consume cheap electricity. This isn't the case atm when your ROI window is ~6 months and it takes a month to ship the device.
If we swap out SHA256 today, we are setting ourselves back a few years to reaching this equilibrium. I'd rather we move forward without resorting to the nuke. And unless there is an aggressive fork with a miner attack, I don't believe we would benefit from changing the POW.
@_date: 2019-04-20 23:25:39
\- UBI
\- Bitcoin
pick one...
@_date: 2016-02-04 00:46:37
Shhh... don't spill out my plans man!
Also it would break Steve's heart, he really wanted to get Py3 out there.
@_date: 2016-02-03 22:33:18
Alan has been inactive on pretty much all public forums for a long time now, it's not surprising his signature would be out of date. The website is a complete mess too (no links to the latest version, 0.93.3, still states x86 support which has been out for over year).
Thank you for updating your article, much appreciated =)
@_date: 2018-03-22 17:24:40


The primary and foundational purpose of society is the economy. 
Just look at the socialist experiments of the 20th century if you want to witness what mankind turns into when this principle is ignored.


The only effective form of control is through the economy. Politics are irrelevant if there is no monopoly on violence up for grabs. Government produces nothing. Armies don't live on fresh air and patriotism. 
@_date: 2017-04-07 16:53:15
I think they are missing the point. It is desirable to neuter the covert path precisely because it is hard to evidence its usage. People who want to boost can just use the overt method all the same.
@_date: 2018-03-29 15:04:38
Is Charles Manson actually a murderer? This isn't so black and white.
@_date: 2016-09-06 05:01:57
We're not taking donations atm
@_date: 2018-03-21 18:13:04


Overt is marginally cheaper to begin with. It would always win against covert in a level playing field. The issue always was the patent. There is plausible deniability in covert ASIC boost afterall. 
The real underlying issue that anti overt ASIC boost proponents fail to see, is that to safely ban the overt boost, you need a HF. If you're left with cheaper hashes or a HF, is it even a choice?
@_date: 2018-11-24 12:20:12
That's a mistake. All alt coins are correlated with Bitcoin. When Bitcoin rallies, they follow within a month, when Bitcoin crashes, they crash twice as hard. At the height of December 2017 rally, bcash approached 20% of Bitcoin's valuation, now it's \~5%. Same with ETH, regularly hit 10% of BTC valuation during the rally, now looking at \~3%.
If your goal is profit, you should not HODL ever. You should ride the BTC rally, divert into the scammy alts ala XRP about a month later then exit out in fiat when the top blows off, waiting out the next rally.
HODL is for people who believe in the tech and sound money, neither of which bcash stands for. If you're here for profit, ignore the politics and treat all of this stuff as synthetic indexes. Also drop r/bitcoin, go to r/bitcoinmarkets
@_date: 2018-03-22 16:02:59
They want to abolish borders because it introduces jurisdictional arbitrage. Bitcoin is jurisdictional arbitrage in and of itself. 
History is not kind to those who reject technological progress.
@_date: 2018-03-21 13:47:03
You have an egregious read of history, you and I should agree to disagree.
@_date: 2018-11-29 17:02:04
This is unfortunate but somehow I'm don't expect Trevor Noah's audience to care about Bitcoin to begin with.
@_date: 2018-11-29 20:48:30
\&gt;  Every single feature increases the complexity of your project. Should we just leave the whole innovation business and pay with shells and beans instead?
I'm not sure where you picked that from. In my first point, I stated " Less dependencies is better, even more so when it comes to crypto libs." In my second point, I explained why BIP70 does not achieve what it sets out to do and concluded "therefor the cost in terms of security and code quality is not justified".
I'm not against innovation, I'm saying the cost is not justified in BIP70's case. The crux of the argument is that there is a cost to adding features, and you agree with this. If there is a cost, it has to be worth the return.
\&gt;  In Mycelium, the relevant crypto routines are from bouncycastle, not from OpenSSL but if we would kick BIP70, we would still depend on BC.
For a wallet to provide essential Bitcoin features, it requires EC crypto for secp256k1, sha2 and associated hmac, ripemd160, AES and a PRNG. There's a Core implementation of secp256k1, the rest is well known crypto with plenty of stand alone implementation.
This set is small enough that you do not need a giant crypto library. In this context, dependencies become a relevant cost. Even projects that rely on do it all crypto libs can consider the cost of sticking to a big, obfuscated lib or slim down to the barebones requirements. Which I am doing atm, and why you'll never see BIP70 in Armory.
\&gt;   And the latter is not resembling the credit card model where the merchant gets to take money from our account without proof of the account holder's intent
That was no my point. My point was there is a well defined transaction flow in Bitcoin. BIP70 is designed in ways that contradict this flow. That part of the design is not useful. I referred to the legacy payment system because the BIP70 flow evokes the "dealer acts last" approach.
\&gt;   and only that transaction the merchant can broadcast or not and this "or not" is a good thing
It isn't. The merchant should not be broadcasting customer transactions. The merchant has no guarantee the transaction he gets is what will be mined, because the merchant cannot prevent the user from broadcasting anything, nor can he prevent a double spend/replacement. The only thing the merchant can do is look at mined transactions and process from there.
You should not design for something you simply cannot deliver.
\&gt;  If the merchant has in his terms of service that a transaction fee of at least X has to be paid, he can stop the transaction instead of going the long route of dispute if the transaction ends up in limbo for days.
How? How can the merchant prevent me from broadcasting my tx if it doesn't agree with the fee? The current solution is to charge extra to cover for eventual CPFP, which payment processors, BitPay included, already do.
Contrary to what you are claiming, BIP70 cannot enforce any "or not" semantics. The whole fee thing is done poorly actually. The fees BitPay demands have been quite bloated. I haven't been using BitPay myself, but the returns I've got from people using it is that whether you are using the top fee from Core or a fee service like 21's, BitPay will flag your fee as insufficient, while the tx gets into the next block. As if BIP70 wasn't harming the UX of Bitcoin as it is.
\&gt;  where the BIP70 payment request was swapped for the hackers BIP21
The weakness of BIP70 is that it relies on CAs. There are 300 CAs in the world. The discussion here is not whether the attacker can swap a BIP70 request with a BIP21, but whether he can swap a BIP70 request with another BIP70 request, crafted with whatever free X.509 you can get out there registered to a name close enough that it will fool the average user. And again, BIP70 is useless if the attacker finds a way around SSL. Last time I checked only TLS1.2 isn't full of holes.
\&gt;  That said, I believe BitPay is a bad actor in our community. The removal of the BIP21 fallback caused a lot of harm and controversy.
Specifically because BIP70 is bad. Imagine if tomorrow BitPay forced the use of LN instead, would it actually be a bad thing?
@_date: 2018-11-29 16:38:45
This is not such a good presentation of the pros and cons. Real quick:
1. You do not want BIP70 in your wallet because you don't do not need X.509 code in wallets for anything but BIP70. As a matter of fact, BIP70 is the only reason Core needs OpenSSL. Less dependencies is better, even more so when it comes to crypto libs.
2. BIP70 breaks Bitcoin payment logic. It expects the signed tx be passed to the BIP70 provider for broadcasting on their end. This is an attempt to model transactions around the legacy pull system. In the legacy system, paying just means giving the authorization to the vendor to charge the customer's bank account. This is the complete opposite of Bitcoin, where payers have to push transactions.
The intent was to provide more control over payments to the vendor, where they could impose a minimum fee and demand a return address for refunds. However, this is not something you can enforce on top of Bitcoin, therefor the cost in terms of security and code quality is not justified.
3. There is no added security to BIP70. You are already relying on SSL to connect to the vendor. Adding another certificate check is pointless. The only realistic way to improve security with this setup is to introduce a 2nd factor. After all, if an attacker can compromise the vendor (as Andreas suggests), what added benefit is there to signing payment addresses that the attacker swapped in server side?
The only security "improvement" in this design is on the client side, which already relies on SSL to identify the vendor's server. Not only that, but BIP70 doesn't improve security with offline signing, as a matter of fact it can even get in the way. There is no effective benefit, this is a security theater.
4. You do not need to use 3rd party websites to resolve a BIP70 payment request into a bitcoin address, you can do that locally. Case in point: [
5. Wallet devs are not rejecting BIP70 on political grounds. We're rejecting it because it's bad. As a matter of fact, it is so bad it led to the removal of Gavin as Bitcoin lead developer, specifically because he implemented Hearn's BIP70 against the technical community's desire, wasting nearly a year on it. There were no politics there.
@_date: 2018-03-20 21:31:20
You use bits in the version field as a nonce instead of toying with the merkle root. Naturally, that makes it obvious (why else set values for unassigned bits in the first 4 bytes of the header?).
@_date: 2018-03-01 22:04:38
Intrinsic value, specifically its absence in this case, was the first popular argument against Bitcoin as a store of value. Needless to say that the people who support this nonsense have yet to demonstrate that you can eat gold.
@_date: 2016-09-05 18:19:38
It's free for open source projects.
@_date: 2018-03-29 15:18:52
I know what a shill is, my comment is in relation to this quote:


@_date: 2019-01-16 15:25:24
The bombing of Libya, the bombing and invasion of Syria, both initiated by the Obama administration. That same administration also turned down the twice proposed offer of denuclearization by North Korea, the same offer the Trump administration took. It may be a fools errand, but at least Trump is trying.
Meanwhile, the Obama administration had no issue backing the Iranian regime through lavish deals, despite its repeated IAEA code infractions. This same administration committed a trillion USD to the modernization of the US nuclear arsenal.
The Obama administration also backed the Arab springs and the Crimea episode.
This isn't old history, everybody knows about this stuff.
@_date: 2018-02-06 20:28:02
So you saying Newton wasn't actually hit on the head by an apple, he was just shitfaced on apple brandy?
@_date: 2018-03-23 16:56:45
Because soft forks are best suited for permissive purposes, i.e. add an opt-in feature. They shouldn't be use to restrict consensus, because the effective enforcement of restrictive rules amounts to "IsStandard() == false", when the intended effect is "IsValid() == false".
Put another way, for a softfork to successfully enforce a restrictive rule, it needs overwhelming network penetration. This is not a guaranteed thing, as was the case with P2SH.
P2SH was a bad softfork (thanks, Gavin) because while it introduced an opt-in feature (pay to a script hash), it redefined the semantics of certain opcodes: [op_hash160|hash|op_equal] would now result in popping the script from the stack, hashing it and checking it matches (original behavior), then pass the script to the pipeline to be processed (added behavior).
This new behavior was restrictive because of how it redefined the meaning of that PubKeyScript construct. Meanwhile, P2SH floated around 10% usage on chain, and DeepBit, the largest pool at time (and for still a year to come) was still running on its own customized version of Bitcoin 0.3.
In other words, if you want to restrict consensus, you should avoid doing it in a SF.
@_date: 2019-01-20 00:19:13
The people that invest in altcoins either have not done their research, have done it but the value proposition of crypto-currency went right over their heads (who else buys into xrp, neo?), or are in it for the get rich quick scheming.
I personally don't think Bitcoin is mature enough to suffer this kind of crowd yet. Just thinking about the BCH split, was it a curse to have this much infighting, or a blessing that Ver purged the Bitcoin ecosystem of its worst actors?
Back in 2011, there was a growing theme on bitcointalk that a deflationary Bitcoin was unfair because it advantaged early adopters too much. I prefer the people that think like that move to Doge than stick around long enough to weigh in on the next big soft fork.
Put another way, maybe we're better off without the altcoiners cash.
@_date: 2019-01-19 16:25:13
There is no competition to Bitcoin though. If you do some more research, this time on the relevant space, you would realize there is no innovation in the crypto space outside of Bitcoin. Case in point, Mimblewimble and CT were developed for Bitcoin. Monero and ZCash just implement that stuff, they never were part of the R&amp;D.
The typical motif for altcoins is actually the opposite of innovation. They would rather emphasis on a single feature by shoehorning it at the consensus layer instead of going through the harder route of implementing it as a layer atop the chain. This how you end up with pointless coins like eth (smart contracts state and computation at chain layer), ltc (faster confirmations, anti asic hash), bch (MORE SPACE!), xrp (centrally curated bankchain), monero (obfuscation), and that's naming the most viable projects =/.
None of these coins have a future because they forward their key feature at the cost of the careful balance that keeps the Bitcoin chain sane. Meanwhile, all of the features they promote can be implemented as an external layer atop of Bitcoin, if they are even desirable that is. All altcoins so far made the conscious choice to build on quick sand, and comeback to fix the foundations later. That's going so well for Ethereum, right? 
At best they stand as examples of what NOT to do with Bitcoin development.
@_date: 2019-01-22 16:52:41
I think the FDIC (federal bank run bailout fund) typically sets its reserve requirement in the 2\~3% during a bear market, \~1% the rest of the time.
Put another way, this is how much reserve the regulator expects bank to hold vs their outstanding loans in order to be eligible for a bailout, comes a credit crunch. The requirements are about the same in the Euro zone.
@_date: 2018-11-30 23:45:19
You're missing my point. The post I was replying to implied merchants use BitPay because they actively want BIP70 support. That's simply not true because merchants who use BitPay are mostly looking for plug and play solution, likely because they don't want bother with technical side of things.
@_date: 2018-03-04 11:03:40
No, I moved the goal post from eat to feed.
@_date: 2018-03-24 03:25:45






SegWit added an opt-in feature. It is contradictory to qualify an optional possibility as a restriction, even at the semantic level.


As long as everyone does it, it does not impact the security of new blocks, as there is no "cheater". The bigger concern with ASIC boost is that it weakens the existing chain, which no amount of overt or covert banning will remedy.


If you do not get sufficient network penetration, you cannot deploy this. This is the hard part, that's what make it an undesirable change as a SF. Forcing the value on unused bits is not only a waste of otherwise potentially useful resources, it cannot be construed as opt-in under any perspective. 
Soft forks should be used for opt-in features only. I do not know how to make this recommendation any clearer.
@_date: 2018-03-23 16:18:44


Emphasis on safely.
@_date: 2018-11-29 23:47:32
Time to look at BTCPay alright. I feel for you.
@_date: 2018-03-20 23:03:13
Basically you would rather an appeal to authority than judge a character by its merits?
@_date: 2019-01-19 18:35:30
There's no guarantee specialization is enough to sustain the alt on its own. Meanwhile that same specialization gets in the way of other features. Ethereum still doesn't sane have multisig capability.
@_date: 2018-02-14 20:14:13
Let's be real here, they're mostly get rich quick schemers with varying levels of sophistication.
@_date: 2018-11-24 00:24:14
If you're here for the tech, stay away from bcash.
If you're here for sound money, stay away from bcash.
If you're here for profits, stay away from bcash.
Should be simple.
@_date: 2018-03-21 14:39:36
I'll just repeat myself.


@_date: 2018-03-21 00:35:39
You want to dismiss the word of people who do not reveal their identity, regardless of their demonstrated merit. Therefor, you ascribe value to words through other means. That's the basis of an appeal to authority. 
Simply because you use that rhetoric to diminish someone's speech instead of elevating someone else's does not take anything away from the reasoning. This is also a patently insane argument to support in a space ushered by Satoshi Nakamoto, the biggest anon ever...
@_date: 2019-01-16 02:40:59
Considering Bitcoin grew despite the association with money laundering, terrorism, child pornography and the silk road, I think we'll do just fine.
@_date: 2017-09-23 14:55:16
@_date: 2017-09-26 05:41:57
There's no code to do that for you, and it's not trivial to write that code. From a security perspective, your statement is fine. From a feature perspective, it isn't.
@_date: 2018-03-21 15:50:57
I don't want to rehash points from June 2017, even more so after history established a clear victor. 
You are wrong on all the accounts you have presented about UASF, its intended and actual effect, and about the role of miners. You are so wrong I can only assume you come from a position that you cannot be dislodged from. Why bother?
Anyways, I'll give you something to chew on so that you stop pretending I'm dodging the issue. Hopefully, you'll leave it at this. You cannot convince me with your surface level mis-analysis. I do not want nor expect to convince you.


The community wanted SW, miners (Jihan, really) didn't. The community supported UASF, pushing all dissident miners into capitulation masqueraded as the middle ground proposal that was SW2X. The community didn't want the 2X part, and it never came to pass. Thus, even the miners face saving move was capsized.
A vocal, disgruntled and technically illiterate minority, misled by a handful of putschists, forked themselves into obsolescence, also revealing how small their portion of the market is, all of this to avoid SW. Their chain has no traffic and is effectively barren, since they cannot merge in Core's work anymore (unlike the pretense of alternative development that was BU/C).
The miners got none of their demands, neither through 2X nor BCH. The community got all of its demands. All it took was demonstrating it was willing to UASF. The threat of the community's ire via UASF actually turned out to be so potent that 2X was not even attempted, despite 85% miner support. 
There were no dissident voice in support of 2X after that. All putschists moved to the barren chain, revealing their true intention in the process: a coup, as opposed to purported technological reservations.
@_date: 2018-03-02 12:36:49
Best freudian slip ever?
@_date: 2019-01-31 14:03:35
The internet gave us information arbitrage. Bitcoin is jurisdictional arbitrage.
@_date: 2018-02-07 20:14:49


Because this is r/bitcoin and we don't really care about Ethereum, all things considered. If we're going down to the semantics, at least the eth forks are named sensibly. 
The side that forked kept on the name Eth because that's what the Ethereum community wanted. Put to the test, they realized they preferred a centralized, undisputed governance and a loose, untested framework over code as protocol rigidity and the technical competition at the top that would ensue.
Etc deserves the name classic, since at least semantically, they do no deviate from the original tenet of Ethereum, which is "code is law".
With BCH, the situation is reversed. A minority is forking off, and claiming they are the true depository of the original tenets. That statement is not true.
Now if BCH wants to argue they're the better iteration of Bitcoin, there's a discussion to be had. But that's not what they are arguing. They are arguing they are the only true Bitcoin, ergo everybody else is just frauds. That claim is simply false.
@_date: 2018-02-19 06:26:13
There will never be wide adoption of BIP70 because it is a bad standard with meh security, poor specifications and is basically incompatible with the Bitcoin protocol's transaction logic.
There has been talks, and there is a general willingness among wallet devs, to design a payment protocol together as an alternative to BIP70 , as more people oppose it than not. Most likely, you will see something to that effect once we get UTXO commitments. 
As for BitPay forcing the use of BIP70, it's not for the (absent) improvement in security, it's only for the expectation of getting a return address along with the signed tx, which allows for the automation of refunds. 
But even that is not guaranteed, therefor enforcing the use of a protocol which has been largely criticized since its inception, barely supported by the ecosystem (only BitPay ever really cared) and used even less, is to opt for very limited benefits at a big cost to the UX. This change is more likely to lose BitPay market share than to improve BIP70's
@_date: 2018-02-15 08:04:09


Not necessarily. Again, this is a matter of sophistication. Yes, there are idiots who believe in and hold these garbage coins. I remember a post on the Ripple subreddit about how XRP was going to hit $1000, back when fake Korean volume inflated it to $4. These people have drank the koolaid alright.
But there is also a sizable proportion of BTC players who divest into alts after BTC peaks, to amplify their gains. You cannot discount the opportunities for easy gains the alt market is.
After all, all alts just mimic the BTC price. When BTC goes up, they are bound to follow. But at the same time, when BTC goes down, they crash harder, implying if BTC dies it will take the shitcoins with it. 
The altcoin useful idiots should pay more attention to that if anything.
@_date: 2017-09-12 09:34:45
Before the fix, UTXOs where serialized together for a given tx. When a new block comes in, the code has to prune the outputs that block consumed. Since all UTXOs are serialized as a blob under their relevant tx, the blob of all those UTXOs for a given tx has to be pulled in RAM to prune just the one.
chjj built a regtest chain with a lot of super large transactions that had tons of outputs, then created one final tx that pulls a single UTXO from each of these tx, resulting in a projected 100GB of RAM footprint to load the relevant dataset.
What doesn't help this is LevelDB's transaction format: when you update the utxo set, you want to do this atomically (otherwise you may end up with a corrupted state). To do so, you start a DB transaction (do not confuse this with Bitcoin tx, this is just how you build a change set before pushing it to disk), update the change set then commit the tx. With LevelDB, as long as the transaction is live, the entire changeset will remain in RAM (usually a DB engine writes the changes on disk as you provide them, then updates internal pointers at commit time to apply the change), basically double dipping on the RAM hogging and I/O inefficiency.
@_date: 2018-02-08 01:37:14


That comparison doesn't stand cause PoW.
@_date: 2018-02-23 17:51:09


My understanding is the opposite: genpop wants to use it as a currency while libertarians see it as a store of value primarily, which is were the recent divide in community stems from: new comers (genpop) are outnumbering the oldschool (libertarians) and trying to stir the tech.
But I agree, TESO is a pos.
@_date: 2018-03-24 14:03:06


As long as every miner version rolls, I don't see what the issue is. PoW is about demonstrably expanding energy. The key feature is a level playing field, not optimal adherence to SHA256.


That's not how it works. To deploy a SF, you need overwhelming miner support. To deploy a HF, you need overwhelming network support. The latter is significantly harder to achieve, as well as to estimate accurately. Many a proposal with "enough key players" behind it was capsized last year, just look at 2X. 
For this change you are proposing, you need overwhelming network support. You have already met the HF requirement, why just block the unused version bits when so much more could be achieved by reworking the header format? Also, why use a forking mechanism that does not demonstrably reflect the required level of network support? You've already done the hard part.
Your insistence on using a SF for this is the same as arguing that you could prevent WW1 by simply giving Franz Ferdinand a bulletproof vest. The only thing you need now is a time travel machine.


If you roll an overt ASIC boost ban as a SF, you've created a situation where a significant part of the network is not updated. Meanwhile there exists a method to mine an invalid chain that is a lot cheaper than a valid chain, but that the non updated part of the network will accept regardless. If your answer is users should simply update, refer to the previous paragraph.
@_date: 2018-02-11 16:16:49
That's not really how it works though. People ride the BTC rallies, then divest into alts around the top, since alt valuation follows BTC, not the other way around. 
No alt trader is oblivious to this, it is just a game. The idiots getting shafted are the holders, that drank the koolaid on whatever incomprehensible or outright libelous argument they were offered as to how said shitcoin will take over Bitcoin's market share.
@_date: 2018-03-23 18:05:01
This is a strict definition of the unalienable effect of a softfork. It does not descrbie recommendations as to how to build features to be included in a soft fork. My explanation was such recommendation.


You have not demonstrated an understanding of my statement. I did not describe what a softfork is, I explained why it is unsafe to use a softfork in a restrictive fashion.
A car is a 4 wheeled self propelled vehicle. This is a description. You should not drive while drunk. This is a recommendation.
@_date: 2018-03-02 12:23:37
Oh you sweet nitpicker... Ok, I'll humor you! 
Dietary gold has no nutritional value, it's just guaranteed to not be toxic at the amounts consumed. Therefor, while you can ingest gold safely under certain circumstances, you cannot feed on it.
The ball is on your side.
@_date: 2018-03-20 21:34:46
BTCdrak is a well established, long term Core contributor. As far as Bitcoin is concerned, I'm more inclined to believe his word over that of outsiders like Samsung.
@_date: 2018-02-13 12:09:13
No idea how their system works but I could speculate. Have one sort of master address registered with some service as your id. Request short lived addresses from the service with different levels of account privileges, send an amount of coins to these from the master address that, defines the privilege TTL. Close the channel when you're done, expect some sort of reciprocity for coins or whatever.
Not sure how you'd go about bootstrapping the master address.
@_date: 2017-09-22 23:03:21
P2SH-P2PK uses compressed keys. I don't know if there will ever be P2PKH with compressed keys in Armory, as it conflicts with the legacy wallet format. 
Most likely I'll add support for native P2WPKH (which only accepts compressed keys) before I even look at a way to support compressed P2PKH.
@_date: 2018-02-12 17:12:34
I have no idea what these do. If you can't mine it, I'd stay away.
@_date: 2018-03-21 12:45:54


That's true. I can explain why if you care, but that sounds like a digression.
However, empty block ASIC boosting is a benign selfish attack. Empty block mining is the cheap way to covert boost. Once the incentives misalign (enough money in the mempool), empty blocks actually hurt the selfish miner, as he is leaving more cash on the table for his competitors.
Keep in mind that during the mempool congestion of December, the fee reward per block was on average superior to the coinbase reward. As we move closer to the next halving, this exception will turn into a rule.
@_date: 2018-02-11 18:29:39
That statement is a slippery slope. The question isn't whether the FOTM ICO is a pump and dump scam. You should operate on that it is the case for all ICOs by default. 
Same goes for all newcomer altcoins basically. They promise a lot, have very little developement, and their only selling point is manufactured FOMO by relentless shills and useful idiot holders.
The question is this: which of the top 20 coins are not shit? I'll try to sum it up simply:
- If you do not think BCH and XRP are shitcoin extraordinaires, you are beyond saving.
- If you think LTC is a legitimate innovation over BTC, you are misunderstanding the scaling challenges Bitcoin is facing, to an extent. Also you harbor misconceptions about mining and the game theoretics around it.
- If you do not think ETH is a shitcoin after the bailout fork, you are in trouble. If you did not think it was a shitcoin before the bailout, you have a "shove it all in there" conception of consensus and chain resource management. 
I'd say you need to go over your understanding of a the value proposition of Bitcoin, see how ETH diverges from that, and ask yourself the essential question: Do you think cryptocurrencies are meant to operate at the retail or settlement layer?
- If you do not see Monero as a legitimate altcoin, then admit that you are into alts for the getting rich quick opportunities, and tech arguments are just how you rationalize it.
@_date: 2017-09-12 19:08:52


There are lots of transactions out there can be characterized as spam (basically creates lots of sub spendable outputs by virtue of the current fee rate).
If you assume one guy is controlling these most of these, he could create a transaction that would tank "under RAM'd" nodes. This isn't particularly useful on its own, but I could see this as an overkill way to sybil some nodes. Couple it with a weakly distributed network like Bcash and their inane difficulty readjustment, and such spammer is actually predisposed to attack key nodes on that chain (like some minor exchange).
Not that anyone was preparing for this but rather that the circumstances aligned for as long as the inefficiency was in place.


Basically. You could say this is an "attack" on LevelDB's ACID compliance more than any given implementation. The UTXO blob serialization is inefficient regardless. But there are DB engines that aren't vulnerable to begin with (like LMDB).
The lessons to take from the attack are fascinating regardless. Bitcoin has to be the first case where big data loads meet consumer hardware. The current approach to big data is to just throw more hardware at it. If this was a vulnerability of say Paypal, they would have never even noticed the issue when their servers runs behind a monolithic interface powered by a massive EC cluster.
With Bitcoin it's completely different. You have to use the engineering approach of MCU devs in the scope of large scale network applications. This isn't something people had to do in a long time. Makes you think twice when someone supports the idea that increasing the block size is perfectly fine and just a matter of "changing a 1 to a 2".
@_date: 2018-02-03 19:07:30
Actually a metric of intputs per tx would be necessary too to distinguish if the slow down is an actual reduction in blockchain use or if we're looking at a case of input crunching (fees have quite low after all). 
I guess the better metric overall would be the UTXO set size.
@_date: 2018-02-14 21:26:21
I understand your point but I think such system would be better off built atop of LN rather than stand on its own. 
Using existing LN topology would allow the id scheme to benefit from properly aligned economic incentives of a network built for an otherwise orthogonal use case, the same way it's preferable to run colored coins schemes on an established blockchain rather than creating your own for that specific purpose. 
Therefor I expect this the path MS is taking, but obviously this is just speculation on my part.
@_date: 2018-02-13 09:46:01
MS is trying to shove this on the LN network, not a blockchain per se.
@_date: 2018-02-07 16:09:48
Wouldn't that lend credence to my apple brandy theory?
@_date: 2018-11-29 19:59:26
\&gt;  Umm, no it doesnt? 
I gave a technical explanation. I invite you to read the BIP and see for yourself.
\&gt; 90% of the in person merchants use BIP70 
You're pulling numbers out of nowhere. If we're going with that, I haven't used a BitPay merchant in over a year. I'm not go out of my way to avoid BitPay. Merchants I use simply moved on from BitPay on their own. 
Your statement is a fallacy to begin with. Merchants do no use BIP70. They use payment processors that may or not may not implement BIP70. On top of that, whether the merchant that support BIP70 are actually enforcing it or even recommending it is pure speculation. You're gonna have to provide evidence of this 90%.
BitPay is the only payment processor I know of that actually enforces the use of BIP70. Anecdotal evidence and my own experience lead me to believe they have been losing market share.
\&gt;  It seems like if a feature is used by almost the entire point of sale device market, then it is a useful and important feature that merchants care about. 
A merchant that uses BitPay doesn't understand a thing to Bitcoin, he only cares for some plug and play setup to exit in cash instantly. Merchants that actually care about Bitcoin would specifically use something else than BitPay.
\&gt;  But people are using this right now. So it works. 
BIP70 was set out to provide 3 features:
1. Improve security. It does not achieve this in any meaningful way.
2. Guarantee vendor's expected minimum fee. You can't achieve this in Bitcion, fee is always set by user.
3. Provide a return address to automate refunds. BIP70 design cannot enforce this. It would have 0 usage if it did, as the implementations I know of that aren't Core (Hearn/Gavin's own garbage) nor Copay (BitPay's wallet) actually bother with the last few steps of the BIP70 protocol to begin with.
Seeing it achieves none of the features it sets out of deliver, it's hard to pretend it works. What's working is typical Bitcoin transactions, BIP70 fails to augment that flow in any meaningful fashion. 
Imagine BIP70 is a dead GPS and the Bitcoin network is the road system. You are arguing your GPS works because you can drive on these roads.
\&gt;  Ok, and what about merchant devs 
There really isn't such a thing. You don't really seem to know what you are talking about. There's no Magenta for Bitcoin. The only thing to come remotely close is BTCPay, an open source payment processor service, and it was started in response to BitPay's  2017 shenanigans. No one is really working on the merchant side of things at the Bitcoin layer. There are people working on this at the LN layer, but BIP70 doesn't apply there.
\&gt;  How can you say it is a waste, when basically every single in person merchant uses it? 
Again, merchants dont use BIP70, they use payment processors. A lot of them used BitPay because it basically was the only game in time at first. Then BitPay did stupid things and opened the door for competitors.
It was a waste cause Gavin spent a year on that useless thing (which no one uses in Core btw), meanwhile blocking efforts to deal with needed stuff, like BIP32 support in Core, propagation latency, seed discovery, tx broadcast efficiency, buggy leveldb (another gem from Hearn) and another dozen of outstanding issues I can't remember off the top of my head. 
One of the major criticism of BIP70 was that no one was going to use it. And no one did. BitPay kept supporting it because of their cozy relationship with Hearn. Absolutely no wallet supported BIP70 for over a year after its release in Core, and no one actually uses Core as a wallet. This prompted BitPay to develop Copay just to have one piece of software out there that supports this nonsense.
Eventually Hearn moved on and BIP70 was dead and burried. Then BitPay in an idiotic move figured they should zombie this disaster of a protocol because of so called fee issues damaging their UX. BIP70 never did a thing for this, and it is losing them market share. As to why they are so stubborn with it, I don't know. I would have dropped it a long time ago if I was in their shoes.
That's the definition of a waste. Spend time and effort on something no one wants. Meanwhile the stuff that needs done isn't getting done. Where's BitPay's SegWit support again?
\&gt;  What about the desires of the merchants?
The kind of merchants BitPay caters to care neither for Bitcoin nor do they understand a thing to payment security. They want some publicity, fiat at the end of the day and low fees.
\&gt;  And the people writing merchant software? 
You have no idea what you are talking about. Who are these people? I've been around since 2011 and I can't name you one "merchant dev". There are payment processors, they exist at the extremity of merchant's stack in their current form. There doesn't seem to be any demand for more than this.
@_date: 2018-02-08 04:27:30
Forking Linux is orthogonal to the code being functional. Forking a PoW coin is a doomed venture.
You either fork the PoW function as well and you have no chain security, therefor your coins will hold no value (think BTG), or you will stick to the same PoW and are completely vulnerable to the majority chain miners (which has already happened with BCH).
@_date: 2017-09-26 04:40:26
This only concerns Armory's SSS implementation.
@_date: 2017-10-28 00:32:46
1) 2X is forking off, not Core, therefor it is their responsibility to do so cleanly.
2) It sets a precedent where the next fork happy bunch will demand the parent chain does all the heavy lifting while they airdrop yet another shitcoin.
3) Implementing replay protection isn't particularly hard. S2X has no replay protection because it serves their agenda which is to strong arm the various actors of this space into following them around. This is achieved on the grounds that S2X has large miner support coupled with the lack of replay protection which effectively results in high disruption for the original chain. 
In other words, they do not intent to fork cleanly. Instead they want to kill the original chain through DoS attacks. If Core was to implement replay protection, S2X would then simply attack with empty blocks and massive reorgs.
4) Last but not least, a hard fork is not something you perform lightly. Proper 2 way replay protection requires a hard fork. If Core was to implement one, they would most likely plan it out over a year, which is the bare minimum. The schedule of a hard fork alone should tell you if the proponents of the change have any sense at all.
@_date: 2017-09-22 22:26:42
You mean compressed P2PK? If it's just about size concerns, the P2SH-P2PK is fairly lean and more secure.
@_date: 2017-09-22 23:18:53
It's kind of the only full node wallet out there besides Core, so it's hard to formulate a reply.
@_date: 2018-02-06 22:44:27
Therefor fell off the bed? Btw, Newton died a virgin afaik, so I'm doubtful of this one.
@_date: 2017-09-15 18:10:21
One would object the people have the government they deserve.
@_date: 2017-09-12 18:50:01
At first glance it doesn't look like it. This address has a lot of OP_RETURN outputs in other transactions, which are provably prunable therefor reduce the footprint of the serialized txouts to begin with.
To me it doesn't look like the pattern to trigger this vulnerability. Also, you're looking for a whole lot more outputs per tx to mobilize enough RAM to crash a node.
Think more in line of that one full block with only 2 giant tx, but with a single txin and lots of txouts instead.
@_date: 2018-03-29 16:44:19
There are people that are wrongfully found guilty. If there are false positives, why can't there be false negatives?
@_date: 2017-09-13 09:33:49


That and the fact that they have 8MB blocks =D


It's not that simple. You need to modify that tree each block. The modify operations will eventually fragment the dataset on disk and increase I/O latency (for databases that are not mmap'ed in RAM).
Part of LevelDB's transaction model is that it will reuse the slack and avoid fragmentation in the dataset, at the cost of large one time writes and RAM hogging. That's a tradeoff that is maybe preferable in this case. A tree of hashes is eminently fragmented, and you'll have to rebalance that tree for every major modification (LevelDB uses BTrees I believe).
Radix trees are elegant, but more sensible for static data, say the reverse bloom filter idea for SPV nodes (I'm going towards that in Armory too). 


There appears to be a lot to improve. I would argue the DB side is in this state for a lack of devs. To improve on this, you will want to profile a bunch of scenarios then fully implement one, which is a lot of work and probably not a priority.
@_date: 2018-03-02 12:21:01
You missed my point entirely. The argument is Bitcoin has no intrinsic value, therefor it fails as a currency and/or store of value. Then you list a bunch of properties of gold that only became relevant a century ago, when gold has been used for millenias as both store of value and currency, which only serve to demonstrate that other market uses for gold have nothing to do with its suitability as a financial tool. Therefor, neither can this argument be made against Bitcoin. 
In other words, "intrinsic value" is alien to suitability as a currency/store of value.


Missed the point again. The existence of intrinsic (i.e. objective) value is a hard point to argue. On the other hand it is easy to demonstrate value is subjective. This is why we have markets to begin with, to negotiate the price of goods.
The notion of intrinsic value typically conflates otherwise unrelated properties in hope of explaining the status quo (gold conducts electricity, electricity is useful, therefor gold is objectively desirable). That's just sophistry.
However, if you are willing to perform a full analysis of the concept, you will realize that intrinsic value can only at best be argued for these commodities that are essential to human survival, boiling it down to air, food and water. Hence the comment: "you cannot eat gold".
Even then, to argue that food has intrinsic value is debatable, since that proposition does not inform us on the valuation of food, only that it is supposedly always desirable. However it is evident that healthy food is better food than unhealthy food, yet there is unhealthy food that is more expensive than healthy food. 
Therefor, even if you can somehow argue that intrinsic value is a not a contradiction in itself, you would still have to argue that it does exist, and even then it would be a useless property as it would not inform you on the valuation of the relevant good.
If you'd be willing to stretch it, you could at best argue that what confers food, water or air its "intrinsic value" is its unbounded demand. Everyone needs food, water and air, all the time, everywhere. In this case, you would have to argue that Bitcoin also has "intrinsic value", since the demand for immutable, verifiable truth is unbounded as well.


That's irrelevant to the point at hand. You're conveniently ignoring the context, which is when talking about currency, that is to be backed "by government fiat", which means the only necessary and sufficient reason for this currency to be accepted as a form of payment is that it is that government says so. You do not need government to tell you that math is desirable or that a mathematical construct is sound.
The notion of currency in law is completely alien to reality. What is enforced by the government is legal tender, i.e. a form of payment that you are not allowed to turn down. The natural axiom is debt, and legal tender is its legal foundation. Bitcoin is not debt money, it is commodity money, and people accept it because they believe in its value proposition, not because they are forced to at gun point.


It isn't doublethink. Since you are so wrong about intrinsic value, maybe entertain the notion that you are also wrong about fiat.


You are a prime example of this. You fail to define intrinsic value, only providing some anecdotal evidence. You do not address the concept's outstanding contradiction. You assume context to justify the concept's practicality, which is some variation of an argument by authority. You conflate it with unbounded demand.
You conveniently ignore the context of fiat currencies to argue BTC is fiat too. You do not understand the legal basis for fiat (clearly you demonstrated that you believe if something is touched by government, then it is fiat). You conflate government fiat with ex nihilo constructions, then oppose it to intrinsic value, which is just abusing strawmen at this point.


What does that have to do with anything? Virtue signaling won't make your argument any less worse. As a matter of fact, if you really believe in the nonsense you wrote, maybe you need to reevaluate your involvement with Bitcoin, cause you do not sound like you understand what you are holding, at all.
@_date: 2018-02-12 23:34:52


The idea is, if you're going to use a PoW chain, you want the most secure chain out there. There is a whole lot more value in a PoW chain than just its tokens. 
Colored coin schemes can be a very powerful thing, but they do not directly participate to the security of the chain since they do not reflect on the coin's valuation. If you peg the deed for the house against an output on chain, the fluctuations in coin value does not reflect in the value of the house. 
But that's just one use case. In general, why would you pick a coin with less work? If you understand the point of PoW, then you want the strongest chain out there. This is just the network effect at play. 
Consider that no alt out there has ever tried to achieve more work than BTC. In relation, think of how much valuation is riding on Eth, considering all the ICOs and smart contracts. Now compare the work to valuation ratio. Which one do you think is the lowest hanging fruit from the perspective of an attack?


That's kind of a non sequitur. A private chain presupposes all participants are known and access is gated. You don't need PoW for this, just federation. As a matter of fact, just a timestamp server would do for this kinda of setup.
The need for PoW and blockchains is precisely because Bitcoin was designed to operate in a public, non authenticated paradigm. 


That is the fine line between core principles and pragmatism. As long as your actions are driven by your principles, the end result will be satisfactory. If you let pragmatism overrule the principles, then you're gazing into the abyss. Again, think Eth.


Can't help you there, this always was a marathon from my pov.


There certainly is, but we're closer to the end of the tunnel than the beginning now.


95% of BCH users have no idea what they're holding. The 5% left is comprised of shills and profiteers. BCH pretends to things that it cannot deliver, that's fraudulent. Yes, they are free to fork, more power to them. But I am free to call them out for what they pretend to be, but are not.
Also, my main gripe with BCH is how aggressive and shitty the fork was. Same port, same magic word, same address format, same hash function and bootlegged difficulty adjustment. Basically just going for disruption, and having no care in the world for the users nor the socialized cost of the fork. 
I mean, the replay protection was still in PR 4 days before the fork. And it only got in there because a whole lot of services threatened to ignore the coin otherwise. BCH couldn't care less for its users, and it was obvious since day 1.


Probabilities are kinda irrelevant given infinite time. Put another way, the longer we go, the more likely PoS will be used to hijack governance of its chain. There's also a much larger exposure to external interests.
Consider the mining arms race. Assume some malevolent actor wants a go at a PoW chain. Sure he could buy tons of mining power and start messing around, but he can't realistically rewrite history, i.e. he can't hope to orphan buried blocks. The best he expect is to disrupt the current appending of the chain, but he can't attack the chain past a certain depth. 
With PoS, that is not true. There is no work protecting the chain at all. If you have the opportunity to change a burried block in PoS, you can trivially rewrite a longer chain than the current "valid" one. Not to say that the network would accept it, but imagine this in the case of a Sybil attack.


If things remain as they are, 50y from now it will be very onerous to accumulate enough funds to have a stake at all in Eth. A key property of blockchains is that they are permissionless. Another way to look at it is that you can become an actor at any level of the network, any moment in time. And this is desirable, because this is how you keep the game theoretics operational. A miner is cock blocking your transaction? Mine it. A dev is pushing shit code? Take his place! A wallet is screwing up your coins, use another one! Don't trust a remote blockchain service? Run your own node! Of course, I'm not pretending it is easy to become a miner or a dev, but the only thing stopping you at this point is effort really. 
The question then would be: Is the concentration of funds in a few hands on a PoS chain eroding that property? Honestly, I can't predict that it will, but I speculate that it does.
The general rebuke to my skepticism towards PoS boils down to: "these are theoretical attacks, no one will be daft enough to risk their stake by harming the chain". And yet, if I had told you in 2012 that Eth would fork to reverse a hack of a 3rd party smart contract, would you have believed me?


One digression, this is more philosophy than game theoretics btw. The current financial system operates on an oracle model, the oracle being government. The assumption is as follows: bootstrapping the truth is impossible, therefor we pick an oracle that will do that for us. Our truth-sayer of sorts.
As an example, imagine the sale of a house between 2 parties. If at some point the seller accuses the vendor of never paying for the house, or that he never sold it to begin with, how do you settle this? What we use irl is a property deed, sanctioned by an acredited professional, and acceptable in court, all of which hinge on the power of government. Bitcoin sidesteps the need for the oracle. After all, as long as you can verify the truth, you do not need it told.
Now consider the following: in such system, how do you deal with multiple oracles? At some point they're going to contradict themselves, and you're thrown back into chaos. Therefor you have to ensure there is only ever 1 oracle. The way we go around about this is by backing the oracle with enough power that it can simply crush any competition. This is achieved through the government's monopoly on violence.
Next, realize that to ensure this monopoly is a very costly. A necessary cost, but a steep one. Now compare this to PoW. It is a very costly process, with the purpose of creating verifiable history. The conclusion? Truth isn't cheap, and Bitcoin is not immune to this. It only offers to sanitize the process, by sidestepping the reliance on corruptible oracles. It does not pretend to provide something very valuable (the truth) for free.
Finally, compare this to PoS. It reintroduces the oracle and presumes to deliver truth for free. Do you really think you can get something for nothing? Let alone the most valuable commodity of them all? Moreover, do you think PoS advocates even analyzed the epistemological consequences of Bitcoin, in light of this argument?
@_date: 2018-02-12 20:26:17


It can't. Eth heads just scoff at these issues. A typical pro Eth position is to argue Bitcoin is limiting itself on purpose in order to thwart theoretical attack vectors, which is just downplaying fundamental threats to crypto currencies. If you could define Eth in one word, it would be "reckless".


Sure, that's a way to put it. Or you could take the negative stance and argue the Eth community is happy to bite the hand that feeds (the blockchain).


Taking off in what sense? I don't doubt some alt will spin PoS in a somewhat successful manner, be it Eth or another. That doesn't make PoS any less shit. 
The whole point of PoW is to remove the element of trust. You do not need to ask someone what the true history is, you can outright verify the longest chain of work. PoS reintroduces trust, completely undermining the entire point of crypto currencies. Only crypto noobs and frauds would go for this nonsense. It also ruins the game theoretics.


So far, all valuable alts out there are spin offs of BTC research. No other alts offer innovations that diverge from what's being pioneered and battle tested with Bitcoin. You either get vaporware, scam coins or the kind of changes that look good on the surface, but come at the cost of undermining the value proposition and/or game theoretics. Eth falls in that later category. Do lots of "cool" stuff, at the cost of what makes a crypto currency desirable in the first place.


I don't know anything about Vitalik so I won't really extend on the subject. Back in the early days of Eth, he stroke me as the typical (original) altcoiner, i.e. the kind of guy who wanted to bring tons of new stuff to Bitcoin but didn't feel like defending the merit of his ideas, nor cope with the development cycle (very meticulous for BTC). 
So he went on and made his own coin instead. He would probably argue that BTC was just too different from what he had in mind to be a proper platform, but as a wallet developer myself I know all to well the ego trip of writing everything yourself, when you could use an existing lib/platform for faster, better results. And well, it's never fun getting your stuff scrutinized and criticized. Devs are human too (sometimes).


No, that's a terrible thing. Development was shit under Gavin cause he would just have final word on all matters. As soon as he was gone, it completely sanitized the process, seeing that Pieter (his replacement) made a point of using his commit access only for janitorial purposes. After that, only ideas that could stand on their own merit had a chance of making it into the code. Cult of personality just gives you that, a cult.


You realize the original moto of Eth was "code is law". Do you really believe they would have hard forked to revert the DAO snafu if it wasn't for God Emperor Vitalik himself reneging his own foundational principle? What is the value proposition of Eth if you take the "code is law" tenet out? Do you think anyone would have even looked at Eth at the begining if the value prop was "code is law, unless I feel otherwise". 
And yet people went with this abomination, cause Vitalik rationalized the short sighted option for them. Granted, I thought Eth was shit before that, so it didn't surprise me when they actually forked. Also I didn't expect ETC to survive at all, since it stands at the intersection of the people who understand the value proposition of crypto currencies and Eth.


Let it, less idiots to deal with in Bitcoin! Eth can have them all =). In all seriousness, Eth isn't remotely trying to deliver settlements, they are more interested in retail. You realize you can't even create a proper multisig output on Eth, right?
What's the point of catering to people that don't value your core concepts? Bitcoin never was about converting people in, it always was about demonstrating its merits for what they are. So far, posturing with buzzwords and fancy turing complete scripting only seem to lead to tamagochis and a whole bunch of scamcoins. If that's what you want out of a crypto currency, then by all means Eth is for you. 
Meanwhile in BTC land, we're working on sig aggregation, MAST and LN. Is it really that hard to pick between the 2?


No, there can only ever be one true PoW chain. All others are bound to die. But Eth is going PoS, obsoleting itself, so that's not an argument anymore.
@_date: 2018-02-08 23:48:05
You'd have to be an idiot to cheer on that BCH pump when it simply brought the price back to 0.15 BTC, which is where BCH was hovering at prior to these 4 weeks of sell offs.
This has probably more to do with day traders coordinating a pump along side the news exposure than any real market enthusiasm. Ver's gloating is about as tragic as when he assured MtGox was solvable.
@_date: 2018-02-12 17:11:38


People who saw Bitcoin for what it was understood settlement was the name of game, and a major breakthrough in terms of fintech. Scaling was not a concern at all. Gavin and Hearn would throw a tantrum about it every year or so, and no one paid them any attention. The main concerns "back in the days" (I got into Bitcoin in March 2011) where:
- Miner centralization. 
Satoshi always pictured mining as something fully distributed across to network. He did not foresee mining pools, which broke the assumption of "1 cpu 1 vote".
The main concern was how big some pools were getting (deepbit was the first one to consistently sit over 40% hash power) and it created central points of failure, even though the pools themselves owned no hash power. 
There was some talks around selfish mining attacks, in the line of "are Bitcoin game theoretics even viable?". What do you do when someone broadcasts a 10000 BTC anyone-can-spend transaction?
And before you ask, no one gave a shit about "Satoshi's vision" at the time. Everyone understood the guy couldn't predict it all, and it was only natural that the ecosystem steered itself in unpredictable ways. The white paper was no gospel.
- Development &amp; governance. 
The concerns were multiple on that front. There was no Core at the time (in terms of structure). No one working on what eventually became Core was getting paid back then. Gavin was a tyrant.
Eventually (late 2011 maybe?) came the Bitcoin Foundation, with the pretense of becoming the development oversight body along with a bunch of other stuff. They started paying Gavin to drive a point. They turned out to be a disaster. Gavin was still a tyrant.
Mike Hearn's ideas were all shit, and he didn't really code himself, therefor Gavin was doing all the grunt work. As a result, Gavin would reject all oppositions to whatever he and/or Hearn decided on. This is how we got a flurry of either useless (BIP70) and poorly designed additions (P2SH, SPV), or borderline broken changes (LevelDB).
Needless to say development was slow and unfocused. Eventually Gavin "stepped down" (that's a cute way to put it). The foundation was starting to fail at the same time, which basically go rid of all concerns in one fells swoop.
- Fees
Simply put, no one really believed a fee market alone will ever be able to sustain mining to acceptable levels. Back then we were operating on a 400kB softcap iirc, which was raised to 750kB in 2013 maybe? Full blocks were unicorns, until Satoshi Dice came along, which turned out to make for a very inefficient use of block space. That lead to the swift retirement of the original dice model.
And even then fees were not a thing. Minimum fees were put in place, as well as dust logic, to thwart attack vectors and chain bloating.
- Infracstructure
It took a while for Bitcoin to flesh its ecosystem time. Not to pretend its mature today, but you have to imagine that there was no private key encryption for wallets at first, let alone deterministic wallets or offline signing. 
Exchanges had terrible opsec. Not that you won't see heists anymore today, but the frequency, size and level of incompetence around the heists of yonder was keeping the entire project behind (think Bitcoinica, Gox).
In general, any fiat ramp was considered a prime point of failure, both on the Bitcoin side (opsec) and the legal side. They were also the public face of Bitcoin and mostly making a fool of themselves (every exchange would just blow up under the load of a rally). 
You could argue we aren't doing any better now, people just got accustomed to lower standards.
These were the legitimate concerns at the time. There were plenty of illegitimate, trollish ones too. Spinning up an alt over that stuff was also a thing back then. We had:
- The Bitcoin scripting language isn't Turing complete, it sucks for smart contracts! That led to Mastercoin then Eth.
- Block interval is too large! LTC.
- GPU resistance (asics came later)! Whatever stupid homebrew hash function. Too many failures to remember a specific one.
- Mining burns too much energy for nothing! PoS chains.
- We need to work hand in hand with the banking system, not reject it! Ripple.
- First mover advantage is unfair! Premines (shit you not).


It focuses on privacy. There is no financial freedom without privacy.
@_date: 2018-07-20 14:41:28
Fail safe scenarios, i.e. multiple unencrypted SSS shards distributed across several locations/parties.
@_date: 2018-07-06 13:46:34
As long as there's a jurisdiction out there that allows the use of cryptos, a local ban has limited effects at best, and probably none on members of the ruling party bent on diverting public funds. 
You could even speculate the ban was to cover their tracks and/or block the opposition from pulling the same scam.
@_date: 2018-03-31 16:22:31
I would argue taxes are slavery but I get your point.
@_date: 2017-10-28 09:57:14
Replay protection is a feature that ensures both side of the fork can continue to operate properly by offering users a strong guarantee transaction they intent for one side are segregated to that side. 
It is one of the elements you need to allow users to properly associate and dissociate from you. Short of that, neither can be achieved fully. The only thing you are achieving without the use of replay protection is maximum disruption for users of BOTH chains.
If your intent is degrading the user experience, then certainly a contentious fork is a good idea. If it's anything, you're doing it wrong. This is basically the same approach as chemo: "let's nuke everything, hopefully the parts we don't want will die first and we can recover the rest".
@_date: 2017-10-06 21:45:10
It is not a solution. It leaves you with no privacy whatsoever. At least with bcash, you could easily do 1:1 UTXO taints.
@_date: 2018-07-06 20:11:17
It's debatable that the Indian market has much sway on the price, if any. 
Also you don't know how they are moving this money once it goes into crypto. If their laundering scheme requires holding for months/years before full amount materializes in some bank account in Panama, chances are they stand to lose more by risking a bear market through needless FUD than otherwise.
@_date: 2015-09-06 07:30:00
Through command line arguments you can change the default paths:
@_date: 2018-07-01 11:08:08
This is a matter of block pressure, not user "coordination". As long as blocks aren't full, there is no pressure to pay above the intersection of the min fee to get propagated and mined.
As soon as blocks fill, sky is the limit. The market will organically discover the cost of next block transactions, i.e. how much people are willing to pay to get that &lt;10min confirmation.
@_date: 2018-07-17 23:13:19
With UTXO commitments you can prove a UTXO is unspent to an offline signer. This enables an on chain ID scheme that can be signed for and verified offline. The ID scheme is simple: put coins on an address, publicize the address as your "root address". 
Payers can trust that address for as long as that original UTXO is unspent. Offline signers need the headers + the merkle path to the commitment proving the UTXO is valid at the current top height. 
Payments can be sent to ECDH(key, nonce), where key is the public key for the "root address", and the nonce is picked by the payer, to forward to the vendor at some point in the future.
This respects Bitcoin's push model, does not erode your privacy and supports provable identity at the offline level. It also does not rely on CAs for requesting payment addresses, with BIP70 assumes is acceptable.
It also fixes the issue with return addresses, since you can also pay to a script with CLTV/CSV leg to get your coins back. You have to reveal a secret to the vendor to begin with, so you can go wild with the payout script.
@_date: 2018-04-28 16:41:08


It is not free at all. There is no such thing as a free meal. Healthcare in France is "socialized", that's different model from the US where coverage is mostly handled by the private sector.
But you are paying for it, whether you live in France or the US.
@_date: 2018-04-09 10:07:17
Fits the story indeed. At the same time I wouldn't put it past McAfee to "refresh" the bird every year or so.
@_date: 2018-04-28 14:21:54


I wonder. He is calling out Ver for failing to to topple Bitcoin with a looney fork he co-opted once S2X failed. He is not calling Ver out over the technical inanity that is the BCH roadmap, inanity that S2X was no stranger to.
Let us not be mistaken, BCH is garbage on its own lack of technical merit, regardless of how obnoxious Ver is. This fork isn't even at the point where implementation snafus would matter, because it would crash and burn on a perfect implementation anyways, seeing how terrible the ideas being implemented are to begin with.
Voorhees is critical of the tip of the iceberg. It's hypocritical, as he attacks the politics, yet conveniently ignores the inane technicals, even more so in a space where code trumps politics at every turn. I would even say he goes as far as saying BCH is sound, as he implies it would be Bitcoin if it had the most accumulated work.


Garzik isn't a rookie, he's just bad. 
@_date: 2018-04-06 13:22:28


You mean you are sitting on the pre fork BCH instead of doing anything with it? Now I get it.


Sadly I doubt there will be a better solution with time. That's what I did with mine anyways.
@_date: 2018-04-28 15:42:58
I was mostly focusing on why people leave out CSG when talking about the French crypto tax rate, because that tax is a given in here and it also encompasses all revenue, not just crypto. It's like VAT vs individual taxation of goods. If say the tax rate on cigarettes goes down, you just talk about that, cause you implicitly know the 20% VAT isn't going anywhere.


I don't think there's actually that much difference between any taxation system in the end. Bottom line, some people fund  gov, some people benefit from it, and the rest breaks even in terms of mandatory cost vs services.
As I outlined in another post, French health care does not cover all conditions, nor does it cover the admissible conditions/treatments in full most of the time. My dad has private insurance, and about half the people in my entourage also do.
@_date: 2018-04-11 14:26:28
This is speculation on my part but this kind of process (chip design) is incremental to begin with, therefor why not put out a batch as soon as you have something marketable? 
Not like you would stop your R&amp;D effort anyways, so might as well lock in some revenue, right? It's one of those "perfect gets in the way of progress" situations imo.
@_date: 2018-04-08 10:38:28
It is speculated that he has a pet turkey named dick.
@_date: 2018-04-25 23:15:42
I've always assumed men and women used the same gear. 5kg off the bar would explain it indeed.
@_date: 2018-04-28 15:19:27
It's not free. Gov mandatory healthcare contributions covers the cost of a set of medications and procedures to various degrees, going from ~30% (dentist) to 80-100% (most hospitalization in the scope of cancer treatment).
Any condition outside of the set is not covered at all.
@_date: 2018-04-08 11:17:30
Would a chicken live that long though?
@_date: 2015-11-04 17:42:30
That's just how LMDB works, it mmap's its entire file structure. The OS handles the RAM distribution, i.e. other processes will get priority over mmap'ed containers, but free RAM will be used to speed up DB access.
@_date: 2018-04-25 20:58:42
Big reds are 25kg, whites are 5kg, small reds are 2.5kg, braces are 2.5kg and the bar is 20kg. Looks there's an extra pair of tiny weight (green at end of the bar). Don't know how much these weigh, but that amounts to at least 90kg.
Oddly enough the panel shows 87, but that looks off to me.
@_date: 2015-11-30 21:50:47
You need the /blocks and /chainstate folders. I copy the entire parent folder, it's more convenient and carries your bitcoin.conf (as well as the testnet chain).
For Core, both the /blocks and /chainstate need to be in the same folder, the one you point to with the -datadir command line argument.
Armory only cares about the /blocks folder, pointed to by the --satoshi-datadir command line arg.
@_date: 2015-11-09 19:23:20
Make sure you:
make clean
The call it is failing on has been changed from 0.93.2 to 0.93.3. Looks like you are using the old shared lib with the new Python files.
@_date: 2015-11-09 18:54:49
What version of Armory?
@_date: 2018-04-28 15:22:39
The healthcare tax is based on your total revenue, the crypto tax applies to your gains only. 
Think of it this way, you made 20k in wages and 10k in crypto in a fiscal year, you owe:
* CSG (healthcare tax) on the whole 30k
* Whatever revenue brackets your cumulated revenue puts your 20k wages in
* 19% on the 10k crypto gains.
Therefor while it is accurate that the crypto tax has gone down, it is misleading to pretend crypto gains are "only" taxed at 19%.
@_date: 2018-04-06 11:01:35
You're better off dropping that BCH for Monero if you're looking to sustain your financial privacy. BCH is a low hanging fruit when it comes to unveiling users' identity.
@_date: 2017-05-02 09:39:26
Somewhat updated instructions to cross compile for RPi from a Linux machine. This is what I did to build it. It's more complicated to get it to package into a .deb, so I'll try to get that figured out for 0.96.1 (actual RPi builds)
@_date: 2018-04-03 17:45:32
I think what he is trying to say is don't start believing in Vitalik's techno babble just because he called out CSW's. Rich statefullness or whatever...
@_date: 2015-10-29 22:51:22
No, ARM builds are actually easy to pull together and have no compatibility issue with Qt4.
OSX just doesn't play right with Qt5, and to upgrade to Qt5, we need to upgrade to Python3 first. That's quite the task, and OSX will have to wait until then. However we have a few tricks up our sleeves on that front.
@_date: 2018-04-29 16:44:23
Not like Banque de France is all that relevant since the Euro.
@_date: 2017-07-27 13:22:52
I'm still alive and kicking, thanks.
@_date: 2017-07-28 12:27:42
Other Mac users have mentionned this quirk with the latest OSX. Will have to dedicate some time to the Mac package eventually.
@_date: 2015-11-26 12:14:57
Sweeping doesn't work in 0.93.x, sorry about the inconvenience. 
Depending on what you want to achieve, you should either import the private key and derive a WO wallet, or import the private key and create a transaction to sweep the funds manually.
@_date: 2015-10-28 22:17:41
Don't give up on us just yet. The open source version will survive one way or another =).
@_date: 2017-07-18 15:26:06
They have been away from development for a couple years at least, that's decades in Bitcoin time. So yes, I would argue they have little to no idea what's going on in the current state of Core.
@_date: 2015-10-30 13:37:14
We cross compile from Debian. We don't build straight from the device, that would take 1H at least.
@_date: 2017-07-28 12:23:55
You can grab the raw hex from the offline tx review dialog. That can be fed to sendrawtransaction as is.
@_date: 2017-07-28 13:53:54
No compressed public keys in P2PKH. This is to prevent disruption in the legacy code. P2SH single signer scripts use only compressed keys. Armory will match the script type of your payments in its change if you allow it to (you'd have to set the change type to auto).
@_date: 2018-04-27 20:22:49


That's a misconception.
Regardless of the hash rate applied, the Bitcoin consensus rules will always retarget the difficulty after the current 2016 blocks period to match a 10min average block time. 
If you have 2 chains using the same rules, one with 1Mh/s and with 2Mh/s, you can expect to always roughly have the same block height, even the difficulty of the first chain is half that of the second. Again, the difficulty rule aims for a constant block period, so a weaker chain cannot just run away.
The reason BCH is some 7k blocks ahead of BTC is because BCH changed its difficulty rule to drop by 25% if the block median time grows above 12h. This is a dangerous practice that jeopardizes BCH and has been openly exploited by miners to rake in extra coinbase profit. It also increases the surface of Bitcoin mining attacks, but I digress.
BCH changed its difficulty rule from the Bitcoin consensus one, therefor it is disingenuous to compare chain length or even accumulated work for that matter between BCH and Bitcoin. If your basis to decide which chain is Bitcoin comes down to the accumulated work from the genesis block, then you have to realize BCH is ineligible.
@_date: 2015-11-30 18:01:22
Keep a copy of a good blockchain state around, this way you don't have to verify the chain from scratch every time.
@_date: 2017-07-18 19:46:56
In term of game theoretics, sure. In term of implementation, that relies a lot of knowledge, which is perishable/obsoleted in basically a year.
@_date: 2017-07-18 14:21:48
This is my take on it:
These projects (Classic/BU/btc1 and so on) are all forks of Core. In order to implement these changes properly, these forking devs would need to be familiar with Core to begin with. 
To get familiar with Core, you would to start participating to development: take part in technical discussion, submit some PRs, review and get reviewed. My experience with other projects is that this a very involving process. You invest a lot of effort and "brain" time to educate yourself on the code, the tech, to produce quality code, to be relevant in discussions. Since Core development is high paced (compared to what I've witnessed elsewhere), the requirement is constant to maintain your knowledge and understanding of the code.
If you get this far, you are so invested that you are better off contributing to Core than forking away. In a way, you could say this is proof of work game theoretics applied to software development.
Therefor, I suspect all the people who fork Core are completely unfamiliar with its code base. This would explain why they mess up even the seemingly simplest of tasks.
@_date: 2015-10-31 19:35:59
Armory implements additional security and backup features on top of the full Bitcoin stack. That means you own your coins, operate a full node to get decentralized access to the network, and protect your privacy in the process. 
A service like Circle offers you IUOs instead of Bitcoins, runs fully centralized, and keeps tabs on every customer.
You pretend Armory is losing market shares, but truth be told you have no idea. This is just an intuition of yours, and I would return to you that in value, a lot more bitcoins are protected by the Armory software than by Circle. But that too is an intuition, because unlike Circle, we at Armory have no way of knowing this (and that's a good thing!).
Clearly businesses that are serious about Bitcoin don't look at Circle to handle their funds. They need a full stack like Armory offers, and this is why our true calling is with enterprise features. The ecosystem needs high grade enterprise solutions to move forward, and we work to provide that service in its fullest.
Circle does a good job on their end of the spectrum, but do not presume we operate on the same premises.
You complain Armory's interface is clunky but this is the level of knowledge and awareness it takes to operate the full Bitcoin stack. There is no security to be had with Armory if you do not use it properly. The complexity comes with the territory. You should keep 2 key parameters in mind:
1) Security is the antagonist of convenience. A 10 tons safe is secure, but inconvenient. Cash in your pocket is convenient but insecure. Credit cards are very convenient and terribly insecure.
2) The one thing worse than the lack of security is the illusion of security. At least with the former, you are aware of your limitations and can prepare accordingly.
Certainly Armory pales in the face of Circle if your goal is hold pocket change in a hot wallet to purchase coffee. A centralized system will always beat a decentralized one when it comes to performance and convenience. But at what cost? 
If you use Bitcoin without the decentralization, the privacy and the censorship resistance, then I would posit you are missing on some of its greatest features. 
Certainly it is not my place to tell you how to be part of the network, but do not believe your way is the only way. UX has its importance, yet it is not the be-all-end-all of Bitcoin, far from it.
Lastly, your UI improvement example is a bad one: it is important for people to know that Armory can run on the testnet as well as offline. People should test their stack on the testnet first, and it is very useful to be able to force the software into offline mode for various reasons.
@_date: 2017-07-23 00:03:12
To Hearn's credit, he eventually gave up and moved on. I wish the others had his wisdom...
@_date: 2017-07-28 12:25:51
If all of your balance is covered by the amount of blockchain history you already have, you technically do not need to wait for your node to catch up with the network to create and broadcast transactions.
They would appear as unconfirmed until your node catches up thought.
@_date: 2017-07-28 12:22:44
All existing iterations of the Armory backups, whether digital or physical, are still supported by the latest version of Armory, and there is no plan to drop that support.
@_date: 2015-10-31 22:49:33
Truth be told I hate UI designing. I would develop entire tools in command line if it was up to me (be thankful it isn't!). I respect the work our team has put in it (again, no thanks to me). I made the wallet recovery tool, and consequently I had to integrate it into the GUI, and I hated every minute of it. Qt4 + Python is like nails on chalkboard to me. Even though, my teammates chugged it along and delivered something that will qualify of fit for the task.
What you need to consider is how much effort UI development takes. On eachfeature we develop, UI takes about 50% of our time, and I expect this figure is low compared to the industry's baseline. For example, I'll take the last piece of UI I worked on: You may not have noticed it but the transaction ledgers are not broken down into pages anymore since 0.93. Instead, you simply scroll along, same as a tumblr photo wall. Implementing that was a biblical battle with Qt4. It took me longer to figure that out than to implement the scalability features in the underlying database. The teammate that took over me to fix the last couple bugs will tell you the same.
I am not saying we won't improve the UX because we are lazy (although I in particular am when it comes to that), but simply put, there are tons of stuff that take priority. Also, since we don't have a UX designer by trade on our staff, we usually go with KISS. That certainly isn't elegant, and far from me to pretend our UX is great. I will pretend that it gets the job done however.
We have had talks internally about UX. Our long term idea was to contract a pro to overhaul the GUI when we moved to Py3 + Qt5, since we could later leverage that work for web pages and mobile apps. The word until then is minimal changes. My crusade with the transaction ledgers was only allowed because it leveraged the backend's new scalability.
Now, don't get my wrong. I know what you mean when you talk about our market share on the consumer front, but truth be told, this is not our target demographic. Our ideal customer is a business that can afford IT staff, whom we direct to setup a supernode server. The officers in charge of funds management get a documentation detailing step by step how to handle cryptographic material and spend coins. They never see the technical side of Armory (they plug into their in-house supernode server through litenode clients) and they go through highly detailed steps to handle BTC. They pay us for a support license, which they rarely make use of because somehow we managed to do a good job with the entire stack, and everybody is happy.
That's what enterprise level clients want, and they're the guys we make a living from. The relationship with our open source users is completely different. We deliver free code, they give us free testing and feedback in return. This is another relationship where everybody is happy. Well, for the most part.
But clearly UX is not our priority. The business guys don't care, they get the instructions manuals. It's too much effort for the return to justify it only by demand of open source users. The users that don't like our UI we can't get with just a couple fixes. This is a huge battle that we will fight on another day. The users we currently have, they want open source development to be resumed. They want litenode capabilities, BIP32 wallets, blocks over P2P and tons of other stuff. UX is icing on the cake as far as they're concerned. 
I can fight that fight. On the other hand, the UX fight... allow us to procrastinate indefinitely for now =P
@_date: 2019-05-22 19:23:18
More like he needs a long history of claims. Long enough that it dwarves the counter claims to the uninitiated. Slapping frivolous cases on individuals is part of that strategy. Seeing someone in court is expensive, most defendants would rather delete a few tweets than bother. That thickens his long trail of claims with legal "victories".
10 years from now he can live lavishly off of his fraud by extracting value from high net worth wall street idiots through scammy investment vehicles, or patent troll billion dollars Bitcoin businesses.
@_date: 2017-07-28 13:51:17
Has been since April.
@_date: 2018-12-26 07:33:06
Not quite. To dissociate is an individual decision, to ostracize is to campaign for others to dissociate. The threshold for each of these is quite different.
@_date: 2019-05-22 19:15:42
You can sign any message with a private key. Bitcoin transactions are just messages constructed for the specific Bitcoin protocol, to be signed by the relevant private keys. The underlying math is not specific to Bitcoin.
What you have to reveal are the signature, the message and your public key. Anyone with these 3 parts can verify the signature is valid.
You cannot guess the private key from the signature. You cannot guess the private key from the public key. At no point did you have to show that private key.
@_date: 2018-12-26 06:42:31


Not since the civil rights act.
@_date: 2017-07-03 08:49:16
Bitcoin is not a network of trust. It actually removes the need for trust (and oracles) because any participant can verify the history for himself. That's the whole point of this experiment: I need not trust anybody because I can witness the truth at all times.
The most telling evidence that CSW is not Satoshi is not that he failed to produce a simple set of signatures (albeit that's very damning), it's that he thought displaying such evidence to a few notable individuals in the space is necessary and sufficient. That's the old way of thinking, the hierarchical system inherent to a trust framework.
Ask yourself this: If CSW presented evidence to all Core devs, and all these devs agreed he was Satoshi, but kept the evidence private regardless, would you believe he is Satoshi?
Chances are Satoshi wouldn't even consider a "vetting process" if he'd plan to reveal himself. The more likely scenario is that he destroyed all cryptographic material that could pass as strong evidence so that there would be no alley for identity theft.
@_date: 2019-05-25 17:13:13
This is a non sequitur. The primary role of miners is to secure the chain. The secondary role of miners is to order transactions.
While miners can choose to omit valid transactions at their own discretion, it is not their prerogative to attack the transactions validated in mined blocks, as it directly reduces the security of the chain as a whole. The secondary role is pointless if it erodes the primary one.
A simple example of how this behavior can be exploited to produce a 51% attack is to generate a valid transaction that a majority of miners will actively attempt to reverse. The attacker only needs to mine a single block with his payment and a politically incorrect transaction in to recruit the majority of miners against this chain head and undo his original tx.
Another attack is to identify transactions that will be actively rejected by a majority of miners and simply broadcast then with large fees.
There are enough selfish miner attack scenarios, there is no room to tolerate this kind of behavior. Miners have a simple job, they should stick to it. It does not involve politics. Predictability is desirable, the rules are set in code, miners should follow them without further interpretation. Their purpose is to sustain order, not forward their ideals.
@_date: 2018-12-20 09:30:37
IIRC, they squandered their cash over hiring amid the 2013 bull run to $1000. Then they had a period of massive layoffs and restructuring during the bear market, at which point they got involved with Jihan. This is when their stance with regards to Core changed.
@_date: 2017-06-23 09:22:19
^ this
@_date: 2018-12-26 06:44:35
There's a difference between ostracism and dissociation.
@_date: 2017-06-23 05:29:38


So did BU.