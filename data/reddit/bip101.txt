@_author: bip-101
@_date: 2015-12-22 21:11:53


I don't think this is correct. Correct me if I'm wrong, but if you receive a block and do not validate the SW transactions in it, you are not fully validating and you are risking that the block might be invalid. **This is not safe.**


Again, as far as I can see, this is wrong. Nodes that don't validate SW transactions risk to be soft-forked from time to time.
@_date: 2015-12-22 05:23:19
You cannot discuss Bitcoin by just looking at _technicalities_. From a pure technical viewpoint, Bitcoin is not supposed to work. But Bitcoin is more than that. This is a common mistake, [especially by current Core devs](
@_date: 2015-12-16 18:34:58


No they dont. In a future where Bitcoin is wildly successful, the price will obviously be higher. This means that 30 BTC per day can be more than enough. In fact, an increase in blocksize means that it is more likely that miners get paid in the future. **More users make the system more secure.** 
@_date: 2015-12-16 19:17:11


I did not say that Bitcoin the technology is fragile. I said the **bitcoin economy** is fragile. And this is a fact. But you guys seem to consistently ignore the ecosystem and just concentrate on your beloved fee market and how Bitcoin the software works wonderfully. _Great, we now have higher fees and people start slowly leaving. Bitcoin still works on my 10 years old computer running on dial up!_ What a joke.
@_date: 2015-12-22 21:14:02
Just because you have been brainwashed that everything has to be an agenda does not change the reality that Bitcoin is based on economic incentives and game theory that goes beyond traditional computer-science technicalities.
@_date: 2015-12-11 20:12:56


Yeah, no emergency here. We are absolutely fine. This is fine. /s
@_date: 2015-12-16 07:31:44


It will cost 24.3 of decentralization with an error margin of +/- 152.3
@_date: 2015-12-16 18:45:07
Are you kidding? Maxwell himself is saying that the current capacity situation is "no emergency" (because blocks are not completely full).
Yeah, let's run into a fee market with a small and fragile but growing bitcoin economy. What could possibly go wrong?!?
@_date: 2015-12-12 17:10:29


You sure are optimistic.
RemindMe! 3 months "Is SW released yet?"
RemindMe! 1 year "Is LN deployed yet?"
@_date: 2015-12-15 22:16:43


No, I'm saying that in Lightning, you must estimate bitcoin fees way more in advance. If your payment channel closes in 30 days, you must estimate a fee so that in 30 days it can actually be mined. CPFP is an option but only if your fee is high enough that the transaction in question enters mempools. This is assuming a crowded bitcoin network with a (low) blocksize limit and therefore limited mempools.
It works a lot better if the main bitcoin network is not under a lot of stress. But in such a scenario, you are probably better of using bitcoin directly anyways... 
@_date: 2015-12-18 10:48:22


I think this is very dangerous to say and outlines how out of place Pieter is.
If you think about it, this means that you can do soft forks without overwhelming consensus. Since soft forks are easy to do, why not bring down the block size in the next point release to 100 KB? According to Pieter that's fine. It is very convenient to Core devs to spread FUD about hard forks and use soft forks to sneak in stuff because it is "easy" and "secure" to do.
@_date: 2015-12-16 07:20:08
Standard arguments of small-block proponents:
* We need block-size limit encouraged fee market (no we don't, we have a fee market without full blocks)
* Increasing block size too fast is dangerous (but of course no metric/data given what should be the correct schedule and why)
* Altcoins, LN, etc.. will be future scaling, Bitcoin is a settlement layer
@_date: 2015-12-15 20:43:28
I think you misunderstood. I'm not talking about Lightning fees but actual bitcoin fees. If the underlying signed transactions in the case of a dispute need to be mined on the blockchain, there is a chance that the fee is not enough.
This can apparently partly be solved by child-pays-for-parent. But if mempools are full and the transaction in question does not even make it into the mempool because the fee is too small, there is pretty much nothing one can do other than wait.
It is similar to the large-hub-fraud case where a settlement load on the blockchain with a low block size can lead to funds being stolen.
@_date: 2015-12-16 08:39:38
Yes, I think the risk of alienating a sizable chunk of potential Bitcoin users during its critical growth phase is far greater than the risk of not being able to run bitcoind on outdated hardware in developing countries.
I understand where you are coming from but you must realize that forcing a fee market right now is actually very dangerous and unprecedented. 
@_date: 2015-12-16 07:08:44
The castle story is questionable at best and the whole post is anti-BIP101 FUD with no hard data.
We want to scale the block size because _technology improves_ and therefore our _cost_ to run the system stays roughly the same. There is no technology in the castle story. There are many errors in this article..


This is wrong, fees are paid today even without hitting the block size limit. In fact, a minimum fee can be made mandatory on the protocol level if the need arises eventually.


What? Miners get money for the work nodes do? This is interesting, where can I get my share of the miners reward as an independent node?
@_date: 2015-12-23 12:10:03




Are you serious?
@_date: 2015-12-16 18:49:10


I sincerely hope all you guys that want a settlement coin just go ahead and start an altcoin. This is not Bitcoin.
@_date: 2015-12-16 19:10:34


That is precisely the point why block subsidies are still so high and will be high for another 16 years!


This is a joke, right? So lets wait until users leave and then raise the block size limit because... why? How can you even arrive at such an incredibly illogical argument?
I'm genuinely interested, this does not make any sense considering economics, game theory and what not.
@_date: 2015-12-22 04:41:12


Both actually. You can say that splitting the network during an upgrade is bad, but it also has clear advantages because old nodes are more likely to upgrade (since otherwise, they are now on a forked-off network where nobody is mining -&gt; worthless). Many argue that the advantages outweigh the cost of old non-validating nodes still being in the network. Obviously not for every change, but generally favouring soft forks (as Core is doing) is a really bad idea.
So in the case of SegWit, it would be _really_ beneficial to do it via a hard fork since we'd want to upgrade the entire network as fast as possible. Remember, SW via hardfork has overwhelming consensus (both Core and XT devs).
@_date: 2015-12-18 13:44:43
So, what exactly is your counter argument? Other than an appeal to authority?
Saying that soft forks are the way forward because we cannot find 100% consensus on hard forks is just ... stupid (sorry). If you really follow along with this, the software can never meaningfully change because somebody will always disagree with a decision. Btw. this has been pointed a lot to the Bitcoin Core "consensus mechanism" and there never has been a proper response. In fact, there now is a response:
It seems like the idea is to construct complex solutions that may not get overall consensus but that can be pushed via a soft fork, and then clean them up later via a hard fork. The clean-up will then not be contentious because who wants a messy software, right?
@_date: 2015-12-21 02:37:48
True, but if nobody complains loudly we run the risk of this just getting merged. The headline is highly misleading though.
@_date: 2015-12-21 22:38:00
I am a little bit confused about the Bitcoin Core consensus mechanism here. Since Jeff Garzik (and of course Gavin and Mike) are very clearly opposed to not having an immediate increase via a hard fork, how does this have consensus?
@_date: 2015-12-18 12:59:51
Have we reached the point where to contribute to a discussion you have to be a Bitcoin developer? Why can't an argument stand on its own?
@_date: 2015-12-23 01:31:07
I find it absolutely ridiculous how the FAQ views payment channels (aka the Lightning network) as a proven method to scale Bitcoin.
It is now pretty clear that the Bitcoin Core scaling plan simply sets the stage for Lightning and that's it. It assumes once Lightning is there, major traffic will be handled by it. I think this is very important to point out.
@_date: 2015-12-16 07:46:28
Not that easily, no ;)
Why? Because if you think about it, Bitcoin today is not very efficient. There are many ways to make it more efficient that are in the pipeline (IBLT / thin blocks, weak blocks, etc..) and that is only what we know already today. Many concentrate on stuff like Lightning while there are a lot of ways to scale Bitcoin itself.
Even if we find out in 5 years that oh no, BIP 101 _maybe_ is too ambitious, we can **soft fork** the block size down to what is safe. Such a soft fork would be very straight forward to do.
@_date: 2015-12-22 03:54:44


No, this is just completely wrong and a generalization. It depends on the kind of change that is pushed via a hardfork. A simple block size increase would break almost nothing. SPV clients would be totally unaffected. Only all fully validating nodes need to be updated. Absolutely no API change would be required.
@_date: 2015-12-16 18:42:04
No, this is at the heart of the whole discussion. Bitcoin is not _just_ a technical thing. You have to take into account real users, game theory, economics, etc..
@_date: 2015-12-27 04:14:09
The exact reason for the censorship of BIP 101 software has never made sense, since a success of BIP 101 would mean majority in any case. Therefore, this behavior was to be expected and just shows how utterly ridiculous the censorship is.
@_date: 2015-12-22 03:51:04


Yes, exactly! During a soft fork, all outdated nodes are no longer validating. As regards network security, they are almost worthless (they still distribute blocks and transactions though, therefore "almost")!
@_date: 2015-12-15 14:48:33
I think he says that real world use of Lightning is years (not months) away.
@_date: 2015-12-16 16:03:08
Yes, it means we have a 25% capacity increase. But only until the next difficulty adjustment. 
@_date: 2015-12-21 22:54:32
TIL in Bitcoin Core world, soft forks don't require consensus.
@_date: 2015-12-07 21:09:11
No, this is FUD. It is easier to scale the block size down using soft forks than to scale up (requires hard forks).
@_date: 2015-12-15 16:18:20
CPFP = Child pays for parent.
Thanks, that is indeed a solution to the problem. But what if mempools are full and the first, initial transaction never makes it into mempools because its fee is simply too low? You still need to guess a minimum fee to get included in mempools. Depending on how fees develop, this might not always be trivial.
At the end of the day, I'm just worried how complicated and therefore fragile (due to many attack vectors) the whole Lightning design is. I only see it working for small and reoccurring payments since otherwise, a lot of funds need to be locked up. But we will see. It definitely does not make sense to rely on it as a future scaling solution.
@_date: 2015-12-16 08:14:08


More importantly, where is the analog of there being a bigger, more efficient and therefore more popular castle eventually causing the king to lose all of his population to that better castle?
@_date: 2015-12-15 16:07:24


Then it is also idiotic to not raise the block size because you are hurting real world businesses that use bitcoin today and soon are affected by congestion effects.
But if you believe that bitcoin only needs to work in theory and should not be used for payments anyways, fair enough.
@_date: 2015-12-16 18:40:09
Ya, that is also my favourite quote.
@_date: 2015-12-18 18:12:14


Agreed. My response was only regarding the limit as a policy tool to force a fee market. And this can not really be debated since a miner has the factor of bandwidth costs. At some point you have to just say that the other argument is simply incorrect rather than saying "I see your point". We definitely need a limit so we can control who can still run nodes (and also miners). But it does not make a sense to use it as a policy tool and this should not even be up for debate.
@_date: 2015-12-16 20:00:01










Sorry but I'm not going to argue on this level. Enjoy your ad hominem attacks. Bye.
@_date: 2015-12-16 20:17:12
Yes good idea. Let's further divide the community by calling a large amount of bitcoin users a "cesspool". [Maxwell is also guilty of that.](
@_date: 2015-12-13 01:42:17
Are you seriously trying to link transaction fees to price?
Holy shit this is getting ridiculous.
@_date: 2015-12-27 04:17:35
You are confusing _pool operators_ with _mining majority_. Pools can easily lose a lot of miners to other pools as sentiment changes. 
@_date: 2015-12-12 01:26:35
Relying on SW is a stalling tactic by Core. It is telling that instead of compromising on something like 4-8-16, not even 2-4-8 is planned (only later and "adjusted"). Instead, SW is sold as a scaling solution when in reality it is not. It is also not as straightforward to roll out as a simple block size increase.
All of this serves only one thing: Establishing a fee market so that Blockstream's Lightning Network is justified. I hope more people see this through all the distractions.
@_date: 2015-12-18 17:30:28


The block size limit was never meant to be a policy tool (read Jeff's excellent recent mails on the mailing list). A fee market exists without a limit (as we have seen when the limit was not reached). However, since many in the community don't seem to grasp this simple truth, even Gavin is now [thinking about a dynamic block size limit]( 
Even if we had no limit, a fee market could be established with a minimum fee for transactions. This is _a lot_ cleaner than abusing the block size limit to force a fee market. Gavin's quote: "My objection to flexcap has always been that it is just a complicated way of setting a minimum transaction fee..."
In any way, color me surprised if this BIP from Jeff gets Bitcoin Core consensus. It is actually quite funny that the very same people who have been arguing in the past that a block size increase would be simple and easy (+ fast) to do with a hard fork if the need would arise, are now saying _the exact opposite_.
@_date: 2015-12-16 18:35:59
Yes, but it is only limited by technological growth while the other castle is being artificially kept small to milk the population.
@_date: 2015-12-15 14:36:43
Hi Adam, can you please answer the following: Can the Lightning Network actually work with a fee market?








@_date: 2015-12-18 11:20:04
They are still citizens though. No reason to kill them ;)
@_date: 2015-12-16 07:56:35
Full node count is probably directly proportional to number of bitcoin users. We have not seen this in historic data because of the rise of light-weight wallets and everybody abandoning the Bitcoin QT wallet (which was/is a full node).
@_date: 2015-12-12 16:43:36
I don't see Lightning be deployed within 1 year. And even if it was, this would be a layer of complexity that makes adoption even harder (single transactions vs payment channels + transactions). I only see LN being viable in 5+ years for smaller/reoccurring transactions. And SW will not directly be a x2 increase. At most, it will be x2. I'm sure transaction growth might increase faster than that. Even if we did implement SW tomorrow, in 6 months we would probably have the same discussion.
So I think this scenario is not all that far off.
@_date: 2017-02-07 00:48:07
Your fee rate is 76.51041667 sat/B.
There are currently over 5000 transactions in front of your tx according to 
Your fee was too low for fast confirmation. It should get confirmed within 9 hours though. If it does not confirm in 9 hours, it might take another 24 hours.
@_date: 2017-02-07 01:41:46
You could try this: 
@_date: 2016-03-01 18:51:18
The difference to all those other times there was a temporary backlog of transaction, is that this time, the backlog was likely not caused by a temporary attack but rather just legit transaction volume (contrary to what you might believe if you only frequent this censored subreddit). In past scenarios, it wasn't a big problem because eventually, almost any legit transaction would be confirmed.
However, in the current situation where it is not completely ruled out that we now have a continuously growing backlog, legit low-fee transactions will be thrown out eventually (meaning payments will not even eventually reach the destination). We have not really experienced this situation before and this is what a lot of people have been warning about since 1+ years. The implications are not actually that the sky is falling, but rather that bitcoin is currently in its worst state ever and Core-devs are cheering because they finally have a fee market (that we actually don't need for another 20+ years).
@_date: 2016-03-01 12:25:06
What makes a spam attack most efficient is the low blocksize limit. A higher block size limit makes spam attacks more difficult and more expensive.
@_date: 2016-03-01 20:55:12
Still spam? Do you know how to extrapolate a graph?
@_date: 2017-03-24 06:14:03
You are really an interesting character. 


Nobody said that. The white paper says that there is an incentive system which keeps the miners automatically in check. If the economic majority does not follow the new rules of the miners, their mined coins would be worthless. But if the economic majority and miners agree on dynamically changing things on the fly, this is of course possible. A BU network could definitely work. I think the reason you are scared and now even use three exclamation marks to declare BU a hostile attack on the network, is that you do not understand the incentive system. And you share this trait with most Core devs thesedays. I'm not going to repeat the same arguments from over 2 years ago but just maybe try to entertain the idea that the incentive system works.


I'd appreciate if you would stop spreading outright lies. You can setup your BU node according to your own rules. If enough users and accordingly the economic majority do this, miners will not succeed in producing a chain with excessive blocks like you suggest. You simply fail to grasp the concept of emergent consensus - it is not a miner-only thing but an incentive based system, just like described in the white paper.
@_date: 2016-03-01 21:42:26


Better ;)
Yes, I think we can say without a doubt that there was unusual high traffic on Monday (and also on Sunday). But just because there is high traffic, it does not automatically mean it is all spam. Growth is not linear. For example, maybe a new service got turned on that resulted in a lot more tx. There can be many reasons. How do you identify spam on the blockchain? You cannot do it by simply looking at transaction counts. 
@_date: 2017-03-27 15:07:20
Learn to read.




@_date: 2016-03-01 21:05:01
Wait, so you think every time the mempool is showing a backlog there is a spam attack?
@_date: 2016-03-01 21:54:03


I'm not sure you understand the term order of magnitude, because it is clearly wrong. We are not suddenly (looking at month-to-month growth) seeing a 10x increase in tx counts.
@_date: 2016-03-01 13:31:40
Yes, but it is still better than 1 MB. The more expensive it gets, the less incentive there is to actually do such an attack. If we had BIP 101 implemented by now, a ddos would be _very_ expensive.
@_date: 2016-03-01 21:21:38
50%? Alright, lets see. To make a fair comparison, I'm gonna choose last Monday. Last Monday tx count: 237,569
This Monday tx count: 265,187
**That is an 11% increase.**
Now, lets take into consideration the mempool on Monday. I don't know about last weeks mempool so lets say it was 0. This week, it was about, lets say, 25000 tx. If these tx would have been mined, **the increase would still be only 23%**.
@_date: 2016-12-04 21:09:07


Alright, we agree to disagree and no, I do not believe the "things" I said here have been shown to be incorrect. Actually, there is no correct or incorrect here, just different ways of going about things (i.e. Core does not really want to do hard forks at all). It's just another mentality and it should be allowed and encouraged to discuss different visions rather than to cut certain voices out. Being able to post on this sub again is refreshing, I hope it stays that way.
@_date: 2016-12-04 23:29:37
If you just stay in your bubble then yes, everyone else is spouting FUD. Makes life easier, right?
@_date: 2016-12-04 22:34:15


"Bitcoin experts" here means Rusty Russel. And Rusty revised his bandwidth estimates to a growth rate of 30% per annum:


@_date: 2016-12-04 20:19:54
You are right, there are a lot of "ifs". But that applies to SegWit or any upgrade whatsoever as well. Using it as a black-or-white platitude and labeling one solution based on hope while not the other is just unfair and biased.
@_date: 2016-12-02 12:14:54
There were fee-paying transactions when there was no backlog. Miners have no incentive at all to mine no-fee transactions, especially long-term when block subsidy approaches zero. It is always a trade-off to include even a single transaction. Your argument is invalid.
@_date: 2016-12-04 20:15:32
This was true when blocks were literally tiny and miners did not care whether a block was 10 or 50 KB. But ever since blocks have become 500 KB and bigger, there are trade-offs to consider for including any given transaction - even without a blocksize limit. The trade-off is manifested in whether other miners will be fast enough to validate your block so it does not get orphaned if another, more simple block from the competition gets found.
@_date: 2016-12-04 20:09:44
You do realize that Bitcoin fundamentally is based on the hope that a majority of miners act rational and in the interest of the network, right?
Bitcoin is not working just because of technicalities, there is a sophisticated incentive system at play in combination with game theory. You could also say, Bitcoin is based on the hope that this incentive system works. 
People that say just because big block attacks are possible it would automatically happen (i.e. a majority of miners will collude to produce very big blocks to attack the rest of the miners) fail to understand the present attack vectors that are possible right now but are simply not happening due to incentives and "hope". You could even go so far to say these people do not understand bitcoin.
@_date: 2016-12-04 20:50:51
On an economic and incentive system level you are wrong: SegWit introduces a new variable, the 75% discount on SW transactions. What does this mean for current economics? Where are the simulations as regards the fee market?
Also, SegWit actually makes raising the blocksize in the future more difficult as the discount mentioned above scales with the non-sw blocksize limit (the 4 MB spam-attack problem, with 2 MB non-sw blocksize limit becomes 8 MB and so on). 
Long story short, SegWit would be more future proof and a cleaner engineering effort as a hard fork because you would not have to deal with such an arbitrary discount variable. In fact, abusing the fundamental concept of segregating the signatures from the transactions to shoehorn in an effective blocksize increase via a softfork is just very dishonest as it allows to call SegWit a capacity increase whereas in reality SegWit alone is not a capacity increase at all. Core just decided, they want a 75% increased blocksize for SW transactions. This would have been immensely more clean both from a political and technical point of view by doing a blocksize increase HF first and a SW HF later on (or even a combination in one hard fork) and I guarantee there would be almost universal consensus.
@_date: 2016-02-25 16:21:16


That's a joke, right?


Nobody is saying that, but _for the moment_ it is the best, fastest and probably safest method to scale. Also, technology gets better, so a continued blocksize increase in the future is logical.
@_date: 2016-02-29 19:23:46
No. A free market would not have an artificial supply limit (-&gt; blocksize limit).
@_date: 2016-02-29 14:25:16
Well yes, you can send a double spend tx. But since it is a double spend tx, it will get rejected by nodes and miners. Of course with a rising backlog, there may be a possibility that the tx got evicted out of some mempools, so there is a chance that can work. But I would not count on it. However, after 72 hours, it should definitely work.
@_date: 2016-02-24 12:41:17
So almost everybody agrees that 2 MB right now is perfectly safe. But let's drive business like micro transactions away prematurely because....  why??
@_date: 2016-02-24 16:10:40
I'm talking about low-worth transactions relative to high-worth transactions. I'm not talking about micro transactions.
If I have to pay a $1 fee for a $10 transaction, I might as well use centralized solutions that are cheaper. It drives away users and thus is a centralizing force where only high-worth individuals actually use the blockchain. I can still run a node - great, but why should I if I no longer use bitcoin anyways?
@_date: 2016-02-28 22:17:16
Your transactions have a fee rate of &lt;11:
We are going into Monday of the new week so transaction load will grow and we already have a mempool backlog. So if they do not confirm in the next ~7 hours I would suspect they will never confirm.
@_date: 2016-02-28 23:48:00
It probably was not on purpose. It was probably just a bad wallet that does not adjust the transaction fee to the current network load.
@_date: 2016-02-29 16:09:45
Welcome to the fee market. Thank Bitcoin Core. This is bitcoin now, as long as everybody happy with it.
@_date: 2016-02-28 21:58:36
Yes, or more precisely the coins never left the origin address in that case. A possibility would be child-pays-for-parent by spending the unconfirmed coins in a transaction with higher fees, but I'm not sure which wallet has support for that and how it works.
Long story short: The current low blocksize limit makes it a pain to handle 0-conf in-person or retail transactions. 
@_date: 2016-02-28 21:43:01
The fee rate is 13.4 which is pretty low and it may not get confirmed at all depending on how the transaction load on the network will develop. Since we are going in to the new week and transaction load will rise, the funds may be double spent because with the newest node versions, transactions are dropped after 72 hours from the mempool.
So long story short: If it does not get confirmed in the next days, the funds may be lost (I'm assuming this was an in-person transaction?). Next time, check the fee rate, i.e. here: 
Current bitcoin fees: 
(transactions under the red line, like yours, may not get confirmed at all depending on the network load)
@_date: 2016-02-29 14:34:42
Umm, yes, it does require RBF on all participating nodes and miners, otherwise they will ignore your transaction.
@_date: 2016-02-29 15:25:01
That transaction may not even be accepted into some mempools since the fee is 0. You can just try to re-submit it with a non-zero fee (practically double spending it). But use a 0.0002 fee since the network is very congested right now. 
If your wallet does not support this, you may have to wait a few days.
@_date: 2016-02-29 14:06:24
Empty blocks are due to validationless mining. You can regard these empty blocks as blocks that would otherwise probably not be there.
The huge backlog is due to the tx-byte-rate exceeding capacity. A 730kb block once in a while does not really change that. Also, you got it wrong: AntPool does not support bitcoin classic anymore.
@_date: 2016-02-29 14:09:05
I do not know a single pool right now that supports full-RBF (which you are proposing right now) - so no, this probably will not work. Best chance is to wait 72 hours (which is now the standard timeframe for tx expiration) and then resubmit with higher fee.
At the end of the day, some users will have to leave the network since blocks are full. You can thank Bitcoin Core for that.
@_date: 2017-06-20 00:01:37
It is popular because it is a direct, real-world measure that people are in fact leaving. You cannot see it directly in bitcoin's price since there are still new people coming to crypto in general with deep pockets that do not care about high fees. But once an alt takes over, be prepared for a shit show.