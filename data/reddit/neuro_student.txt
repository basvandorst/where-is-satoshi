@_author: neuro_student
@_date: 2014-06-07 15:36:40
Here's a link to the stackoverflow submission with more detail:
Multiplexer chip: 
@_date: 2014-06-06 18:58:50
I have not. But that's a good idea. I'm trying to figure out how to post a link now (I'm pretty new to Reddit)
@_date: 2014-06-07 22:51:25
You guessed it. 
I haven't run a profiler on it yet but I've used 'tic toc' on my data acquisition function and it can only acquire all 16 channels about once every 0.23s. When I reduce the number of channels scanned/read from 16 to 8, there is a proportionate speed increase to about once per 0.1s. This multiplexer writing/reading is definitely the rate-limiting factor for my loop. 
I'll try the profiler tonight and see if I learn anything new
I know I should probably be writing this stuff in C but I'm not very familiar with C. The time-cost of learning a new language currently still far outweighs the time-cost of trying to get it to work in Matlab. 
@_date: 2014-06-08 18:42:25
Currently I'm doing single scans, so my understanding is this is I don't need to specify read time or scan frequency. My script just goes through in a loop outputting a single scan, inputting a single scan, outputting a single scan, inputting a single scan, etc...
But yeah, I'm reading in a lot of channels
@_date: 2014-06-06 22:24:05
I have access to some of the same NSF supercomputers and the thought also crossed my mind. It didn't even occur to me that it might be illegal
Luckily a friend set me straight before I could do anything stupid
@_date: 2014-06-06 18:56:02
Unfortunately this needs to be done in Matlab, since the rest of my scripts are already written in that. 
Unless labview can somehow be used to send data to Matlab, but I've never heard of anyone doing that....but I do have access to labview through the university
@_date: 2014-06-08 19:26:38
I'm using an NI-6008
From what I understand I can only adjust the sample rate of continuous scans that occur offline. So, for example I could sample for 1s at 1000HZ, but my analysis loop would need to wait for an entire second before the data were available. Plus I only really need one data point per channel per loop.
I don't know if there is a way to adjust the default sampling rate of single scans.....If so that would be fantastic, but I just looked into it briefly and that doesn't appear to be an option: 
@_date: 2014-06-06 19:07:32
Hell yes
@_date: 2014-08-01 13:01:49
This is a good point. 
Strategically it seems smarter to spend time addressing the weaknesses of Bitcoin than daydreaming about its strengths. 
Yeah space travel is going to be awesome but you want to be sure there is nothing wrong with that spaceship before you get in and shut the door. I don't want to see the Bitcoin-flight blow up because of a faulty o-ring
@_date: 2014-06-08 18:04:40
I don't think so....My current ADC is actually 8 AI channels but the other 7 are in use. Actually, they are all doing the same thing. The whole setup is basically just a way for me to read in massive amounts of data through only 8 channels. 