@_author: tinybike
@_date: 2015-06-26 18:56:05
Nice!  I was wondering if someone was going to get it.
You're misunderstanding a key point, though: the prediction market isn't on the size of the different groups (although you could create a PM for that, too); it is simply whichever of those groups is largest is declared to be the truth and "wins".
So, here's a follow-up question: if *consensus is truth* -- i.e., the truth is whatever 51% of people say it is -- then are the other 49% of people *liars* or are they *nearly correct*?
@_date: 2015-06-24 10:13:30
Just want to correct a common misconception: the Augur crowdsale is actually set to be *two weeks after Ethereum's Frontier launch*, not two weeks from now!
In fact, we just launched our alpha testing version (details:   Everything's running great so far, but we want to give the alpha at least a month of "breathing room" before kicking off the crowdsale.
@_date: 2015-06-27 19:01:17
Hehe, yup.  This has always been our plan, actually!  But, since two-way pegs are about 5 years off (according to Greg Maxwell), we don't want to just wait around for them -- Ethereum makes it easy to get going in the meanwhile.
@_date: 2015-06-27 18:53:14
Point taken.  Deleted the bit of snark.
@_date: 2015-06-24 11:25:35
 -- built by two of the Augur core devs :) (myself + @_date: 2015-12-09 07:07:57
If you look at Linus Torvalds' writings when he first released Linux (and was an unknown) and compare them to the present day Linus' writings (when he's famous), it's striking how much more of an asshole he is now.  Just saying.
@_date: 2015-06-24 10:22:12
While, to some extent, I share your concerns about Ethereum as a platform, my opinion is that it's both promising enough and conveys enough benefits to Augur as a project that it's worth using.  And, if Ethereum somehow fails -- which, having worked with their team, I find extremely unlikely at this point -- it would be trivial to detach Augur from Ethereum altogether and simply run it as a standalone blockchain.
The bottom line is, we're building Augur on Ethereum because it lets us iterate and deploy quickly, and because of the numerous benefits associated with existing as part of a larger dapp ecosystem.  So far, Ethereum as a platform has been amazing, and we have no plans to go anywhere else!
@_date: 2015-06-24 10:24:44
As one of Augur's core devs, now the our alpha test has started, I can confirm that carefully ironing out bugs + testing the heck out of everything is pretty much my entire life at this point!
@_date: 2015-06-24 13:37:29
Question: "Will solid evidence that humans and chimpanzees descended from a common ancestor emerge by September 1, 2015?"
Scenario: a finding is released in August 2015 which evolutionary biologists agree is solid evidence.  But it's arcane enough that the average man-on-the-street would have trouble understanding it.
Now it's time to vote on the question.  You know the right answer is "Yes".  But you're also pretty sure that most people don't comprehend this new evidence.  And you also have a suspicion that, due to exceptionally good marketing that included lots of country music, about 40% of Votecoins are held by Southern fundamentalists.
How many Schelling points exist for this problem?
How would *you* vote?
@_date: 2015-06-24 11:43:38
Sidechains unfortunately don't exist yet -- and, according to the most recent estimates I've seen, full two-way pegs are about 5 years off.  A spinoff initial distribution is a great idea, and in fact, and I (both Augur core devs) are the creators of [Sidecoin]( which is a solution to the the spin-off problem.
Although we think spinoffs are super cool, the real "next best thing" to sidechains, in my opinion at least, is just a decentralized exchange.  The technology is already there (e.g., Mercury), it's just a matter of making it "invisible" (ala ShapeShift)!  Then you've got something that isn't a sidechain -- still a floating exchange rate at the end of the day -- but for an awful lot of applications, works just as well from the perspective of the end-user.
@_date: 2015-06-27 19:03:46
Well, it's going to be sidechained to Bitcoin, when two-way pegs are available (estimated to be about 5 years off) -- exactly the same as Augur.  We've always planned to sidechain to Bitcoin as soon as sidechains are available!
@_date: 2014-12-06 23:22:13
Hi teslika, no we haven't yet, but it's definitely something we're looking into!
@_date: 2014-11-14 22:11:15
SHRED app: guitar theme, in addition to a "pay" button it has a "face melter" button.  when you click it, it broadcasts a bitcoin transaction with an OP_RETURN containing a highly compressed face melting metal solo
@_date: 2014-07-07 22:01:18
Finally -- cryptos that actually do something :)
@_date: 2014-07-07 22:38:43
Can you explain a little bit about how the social predictions work?
@_date: 2014-11-14 22:01:00
This would be an extremely literal "man in the middle" attack
@_date: 2015-05-21 22:32:18


...and, after many time-steps, if the lie detection algorithm is any good, the liars will be filtered out.  If you look at the plots I constructed, you'll notice (1) that the x-axis is the number of consecutive reporting periods (i.e., time), (2) in addition to the steady-state outcomes, I used two separate metrics to see how the Reputation of liars evolved over time.


I'm not adding together the eigenvectors.  Did you even read what I wrote?
Look, if you have a real objection, I'd love to hear it.  I want Augur to be as robust as possible.  But I really don't have time for this "you don't understand SVD, you understand nothing, and how presumptuous of you to think you understand Truthcoin after a mere 9 months!!" stuff.  It's insulting and childish.
@_date: 2014-12-05 00:32:30
Like joeykrug says, our snapshot is just an example -- you're of course more than welcome to make your own!  "The blockchain" of course has the same information the snapshot does (actually, much much more), but the way it's stored isn't convenient for loading into a new blockchain.  A separate "snapshot" file is better because it is a) portable (it is 2+ orders of magnitude more compact), and b) is a simple way to provide a file that will be exactly the same for everyone using it.
You could imagine a workflow that goes straight from blockparser ( to block loading in block 1 of the new blockchain.  But this is time-consuming -- doing the blockparse itself takes time, and this also requires every user to download Bitcoin's entire blockchain.
@_date: 2015-05-21 02:59:48


This sounds right.  In fact, the Augur team convinced you that the LS-LMSR was the right choice, if I remember this debate correctly.


I think I have a pretty good understanding of PCA: I've taught linear algebra at the college level and have used PCA in my own research (e.g., 
To be honest, I would have liked to use the original Truthcoin mechanism, as it's simple both conceptually and computationally, and I wanted very much to focus on developing the software.  Unfortunately, your algorithm falls apart when half or more of reporters fail to give the correct answer, something you would have realized if you had ever bothered to carry out even the most perfunctory numerical analysis.  For example, here is one of the earlier Monte Carlo simulations I carried out:
("Big five" refers to an algorithm that uses the first five principal components; "Sztorc" refers to your algorithm.)  This simulation has 50 reporters reporting on 100 events, and has 65% of reporters give random answers.  Note that there are no "bad actors" per se here, no collusion, no conspiracy: just randomness.  Is your algorithm even powerful enough to distill the truth from white noise?  The answer (as you can see in the plot) is, sadly, no: look at the upper right square of the plot, which shows the fraction of correct answers.  Your algorithm hovers a little below 50%.  In other words, it's slightly worse than a blind guess.
The problem with your algorithm is that you only use the first eigenvector.  This is not the way Principal Component Analysis usually works: typically, you set a variance threshold (90-95% is pretty standard) and keep however many components are needed to reach that threshold.  This is, in fact, the method I outlined in the Augur whitepaper ( Appendix A).  This turns out to be overkill: for realistic ballot sizes, you get essentially the same result by simply always keeping the first 5 to 10 components.  For much more detail (and graphs, and math, and...), I direct you to  -- in particular, the "second eigenvector and beyond" section.  In addition, if you're interested, all my simulation code is open-source: 
Here's a particularly telling comparison between the algorithms: what happens to the people giving random answers?  How does their Reputation change over time?  The better the algorithm, the more strongly it should distinguish between lies and truths, so liars should do worse and worse over time: 
If you have an argument for using your original algorithm, please state it, and be prepared to back it up with evidence.  Otherwise, please stop pointlessly tearing down my team.  We are, after all, for the most part implementing your design, and have nothing but good things to say about it.  Yes, we've modified your design where it needed it; the consensus modification was unfortunately necessary.  But it's still principally your design.
@_date: 2015-05-21 21:59:42
Addendum.  You make the comment:


I went to the thread you linked to, where you just say:


Please elaborate.  What is it you think we're missing or misunderstanding about MSRs?  I'm not quite sure why you think my team and I don't understand MSRs, but I will point out that I created my own derivation of the LMSR from a general variational principle (maximum entropy) in Appendix C of the [Augur whitepaper](  This seems like it would be difficult (impossible?) without understanding it pretty well.
@_date: 2015-05-21 05:37:01
Yes, that is what I did.


This is too vague.  To be clear, I'm not claiming your ideas are internally inconsistent or that they are mathematically incorrect.  If "what was promised in the whitepaper" just means that your algorithm identifies the direction of maximum variability, you are absolutely correct.
Rather, I'm saying that your consensus algorithm does not reliably identify the correct answer in the presence of 50+% random noise.  (And, further, that this is a serious deficiency in a lie detection algorithm.)  I think any meaningful comparison must be between how accurately the algorithms can sift truths from lies.  Ideally, Thanos's intern would have gotten us some actual empirical data on this -- instead of trying to burn Thanos alive -- but since he didn't, I've been using Monte Carlo simulations.  If you have another source of data (or if you're inclined to conduct the mechanical turk experiment yourself), I'm all ears.
@_date: 2015-05-21 03:58:54
Sure, I'm willing to bet on it.  What form of evidence would you accept?  Presumably you have something different in mind than a Monte Carlo simulation?
Your description isn't quite right.  My method weights the first 5-10 vectors (depending on the version) by their eigenvalues, and the remainder of the calculation is the same.  The sum is the composite score.
@_date: 2015-05-21 21:15:38


If you require 51+% of users to be telling the truth for your algorithm to work, then what do we need Truthcoin for at all?  An ordinary vote will do just fine.  [Schellingcoin]( would work wonderfully.  The real value of SVD/PCA is that it cross-references reports, allowing it to extract the truth even if most of the users are lying, lazy, and/or ignorant.
Suppose the question is, "What was the high temperature yesterday at location X?", and the correct answer is 70 (degrees Fahrenheit).  35% of reporters give "70" as their answer.  The other 65% give randomly selected numbers between 0 and 100.  Because the 65%'s lies are more variable than the 35%'s truth, any lie detection algorithm worth its salt should be able to figure out which users are telling the truth.  But, yours cannot.




I think this is the crux of our disagreement.  You're proposing that scores on the principal eigenvector create "an index of tacit-(dis)coordination".  If this were perfectly true, then yes, any extra information would be unnecessary at best, harmful at worst.  What I'm saying is that this *isn't* perfectly true.
Think about it this way.  Why does projecting onto the principal eigenvector tell you anything about discoordination at all?  (Why not the second-largest eigenvector, or the smallest?)  The reason is because the principal eigenvector points in the direction of maximum variance: it has the maximum amount of the original data's variability that can be captured in a single dimension.  Projections onto this eigenvector tell you exactly how much each reporter contributed to that direction of maximum variability.  And, because lies are more variable than truths, the more you contribute to this direction, the more likely you are to be lying.
Hopefully this makes it clear why the fraction of explained variance is highly relevant.  In many cases -- especially if you have a large number of events being voted on simultaneously -- a single dimension is insufficient to capture most of the variability in the system.  For example, if the principal eigenvector only accounts for 30% of the overall variability, then *most* of the reports' variability is unaccounted for, and your measure will be quite poor.
Fortunately, this problem is easily remedied: just include multiple eigenvectors.  This makes sense conceptually, as well: if your original data has 50 dimensions, why would you expect that a single direction is sufficient to account for most of that 50-dimensional data set's variability?


I use the term "liars" because I also did more involved simulations where the non-truth-tellers actively colluded with one another.  In this simplest case, yes, I should call them "randoms" or something.  But, you have to deal with the randoms first.  Filtering out white noise is the easy part, which is why I was so surprised that your algorithm failed at it.
@_date: 2015-08-03 18:14:30
Augur is **not** Truthcoin.  Paul S. has said this (equally emphatically), as well. Augur uses some parts of the Truthcoin model -- and we cite Paul's prior work prominently in our whitepaper -- but by no means is it the same project. The principal differences between Augur and Truthcoin are discussed in the following posts:
Paul disagrees with our approach, as you say; he isn't happy that we're using some parts of Truthcoin's model and not others.  That's fine; he's running his project and we're running ours.  I encourage people to look at the data presented in those posts and make up their own minds.
I don't know what to say about the Truthcoin "FAQ".  A lot of that stuff is wildly, egregiously false.  A few of the more ridiculous examples: 1) our team **did not** release a coin called "Roxcoin" (??); 2) our team **does** have real blockchain/C++ experience (and I [implemented spin-offs]( 3) we're a non-profit foundation, not a for-profit startup.
I could go on -- the FAQ is full of "so wrong it's just silly" stuff like this -- but he-said/he-said disputes are honestly not a good use of my (or, to be frank, Paul's) time.
@_date: 2015-08-03 19:47:45


The only reason I mentioned my background at all was in response to the claim that we should defer to Paul's opinion because [he wrote the Truthcoin whitepaper]( -- i.e., it's an argument from authority made by a person who isn't even an authority.


I totally understand your point, and I really wish we weren't having this ongoing dispute with Paul, which I feel is unhelpful and distracting.


Thanks :)
@_date: 2015-08-03 18:56:15


For heaven's sake, we never offered you the job of "CEO".  We don't even **have** a CEO.  We're a non-profit foundation with a flat hierarchy, and we make all our decisions by voting.


We've implemented a decentralized prediction market.  Whether we "have the right skills" isn't a hypothetical.  The evidence is in; it turns out, we actually do have the right skills.


I'm incredibly tired of endlessly rehashing this, so I'll just say: we spent three months researching this [in enormous detail]( and the data is quite clear.  **Truthcoin's consensus system is completely, utterly broken.**  I suggest to you (for the 500th and final time) that you really, really, really should fix your design, as it **will not work** the way you have described it.
Look, I don't like to use my background like this -- I feel that our data and analyses should stand on their own merits -- but I feel obligated to point out that I'm the only person involved with decentralized PMs that has any experience modeling complex systems, any real [research experience]( at all.  My doctoral dissertation was literally on this exact topic: numerical models of complex systems.  So, if you have an actual counterargument to make -- or any real critique of our system at all -- then please make it.  But your argument-from-authority just doesn't hold water.
@_date: 2015-08-04 20:35:01


We have a guy with a very obvious ax to grind, who is actively building a competing product, who inserts himself into every announcement about us and tells everyone who will listen that we're a scam.  It's not clear to me how this could be further escalated.


I agree, absolutely.  And to be 100% clear, no one on our team is saying we have an un-buggy (or even feature-complete) product *now*.  We're all completely aware that it's going to be a ton of work to get there, and much of the remaining work is a combination of time- and money-intensive, such as security audits -- which is the point of the crowdsale, actually.
What I emphatically object to is the notion that our project is simply doomed due to our architectural choices (which we've justified in [enormous detail]( or our team being not up to the task intellectually.  The latter is so petty, and so manifestly incorrect, that it wouldn't deserve a response at all, except that Paul literally *follows us around and repeats this claim* so frequently that people have, evidently, started to take it seriously.
I would much rather people examine the evidence we collected, and make up their own minds.  But, it's apparently necessary to also counter the lazy argument-from-authority that _our analysis should all be ignored, because the people who created it are morons_.  Hence my mention of my research background: I have half a decade of experience doing exactly the kind of work we did in improving the consensus algorithm.  I'm really good at this kind of work, and I have a half-dozen research papers (and my dissertation) to prove it.


Has he published anything in a refereed journal?  That's usually the absolute minimum threshold a research effort has to cross to be considered "real".


Yes, I totally understand that, and, again, to be clear, we have no objection whatsoever to answering *actual criticisms* of our work.  I think our responsiveness on Reddit, Slack, and elsewhere demonstrates that.  If you have a substantive objection to any part of what we're building, or if you've found an attack vector you think we're not aware of, *tell us*!  My only concern here is making our system as robust and secure as possible.
@_date: 2015-08-03 19:23:33




Yes, I think this is basically why -- intuitively, I think of PCA sort of like doing k-means clustering with k=2 (where the "clustering" is done on the principal component scores).  So it has problems if the data is multi-modal.  (Btw, here's an interesting [paper]( on the link between PCA and k-means clustering.)


This is true!  And also why I find this protracted debate with Paul to be frustrating.  It's so completely unnecessary and avoidable.  Our consensus algo is an easy, modular, drop-in replacement that fixes a game-breaking problem with his design.  Why not just say "Thanks for the fix!" and use it, instead of going nuclear against our team?  There is no need for a priority dispute -- this is all open-source, for heaven's sake! -- and the fact that one is happening anyway just sucks tremendously.
@_date: 2015-08-03 19:32:36
Yes, absolutely!  This is something we're planning to have done anyway, and it would be fantastic to have the community help us out with it.
@_date: 2015-07-17 09:46:58
I'm one of the Augur devs.  My opinion, based on my experience [implementing spin-offs]( on a fork of Bitcoin Core v0.9.1, is that extending Bitcoin's source code is tedious rather than difficult.  Like any large code base, it has an initial learning curve, but beyond that I wouldn't describe it as "difficult" to work with, just time-consuming, mostly because the code is quite tightly coupled.  i.e., changing one thing requires you to also change 10 other things.  After working on it a bit, these changes are straightforward, but remarkably tedious.
Tedium isn't a deal-breaker, of course.  The bigger issue is that Bitcoin's source code didn't offer any real advantages.  (I trust that Bitcoin's code is secure, but I certainly would not *continue* trusting it after it had been modified to be a prediction market platform.)  We opted to use Ethereum simply because it let us iterate and test quickly.  We're a non-profit, operating on a shoestring -- I've personally gone broke twice during this project -- so for us, all things being equal, iterating fast is good.
Personally, I'm happy with our choice.  Existing as part of Ethereum's ecosystem will have other advantages, as well; for example, we're able to offer our oracles as a service to other smart contracts.
@_date: 2015-07-17 09:02:18


This is correct.  Augur uses parts of the Truthcoin model, but it is an independent project, not an implementation of Truthcoin.  [This blog post]( describes the principal difference, the event resolution system.
@_date: 2015-08-03 19:34:55
Yes, and you better believe we're planning on doing that -- it's something I'm deeply looking forward to, actually :)
@_date: 2015-07-18 23:15:46


Yes, exactly -- the security of a heavily-modified version of Bitcoin Core's source code vs. the security of Ethereum is something that is extremely hard to quantify.  So, we picked the platform that allowed for faster iteration.
@_date: 2015-04-18 06:25:37
Paul, I think the comments re: sidechains are in response to your remark that another implementation would be "more intimately tied to Bitcoin via a sidechain".  Perhaps you meant to say that this alternate implementation is more intimately tied to Bitcoin *by sharing some of Bitcoin's source code*?
@_date: 2015-04-27 23:30:13
We determine truth using a decentralized oracle.  In our system, anyone holding "Reputation" tokens participates in determining event outcomes.  They do this by simply submitting reports on the events to the network (after the events occur, so there's no element of chance to the reporting).
We created an incentive scheme to ensure that people report honestly.  Basically, lies are more variable than truths.  By using a statistical technique called Principal Component Analysis, Augur determines who is contributing most to the overall variability in a group of reporters (across multiple events).  Reporters whose reports are consistent with the consensus are rewarded, and those who are at odds with the consensus are punished.  This incentive scheme is based heavily on the [Truthcoin]( consensus mechanism, and is discussed in much more detail in our post on building a -[decentralized lie detector](
@_date: 2015-04-27 21:05:46
Thanks!  The Bitcoin blockchain itself doesn't support all the operations needed to build a prediction market.  (This is why we're using Ethereum -- a programmable blockchain.)  We expect it to be usable by the general crypto-community as soon as we release our UI, which will be very soon now -- we're shooting to have a first version of it out by later this week.  And yes, Augur does have a token -- we call it "Reputation", which is used to report on the outcomes of real-world events, after the events occur.  The Reputation tokens will be available for purchase starting June 1 (and for 45 days after that).
@_date: 2015-04-27 21:50:03
Yes, but since the person making the bribe is forcing the market price to deviate from its "real" value, they will lose money by doing so.  (Where the "real" value is the value that reflects the aggregate best-estimate of the event's probability of occurrence -- e.g., $0.42 = 42% chance of happening.)  And, since, the market's outcome is determined by independent reporters, the event resolution will not be affected by bribes offered to the market participants.
@_date: 2015-02-27 05:20:10
Two of the Augur core devs (myself + joeykrug) have done a previous project extending Bitcoin's source code ( This experience made us realize that building something as complicated as Augur on Bitcoin would be a nightmare!  Ethereum, on the other hand, is designed with projects like this in mind, and has been much, much faster to prototype with.
@_date: 2015-02-27 05:21:55
And, if you lose reputation because you were a deadbeat and didn't report, you're able to earn fewer trading fees as well -- so it's a nice little bit of feedback!
@_date: 2015-02-27 03:34:47
The short version: you're awarded reputation for filling out your ballot (correctly), and you lose reputation if you don't.  For more details, see our whitepaper ( and the original Truthcoin whitepaper (