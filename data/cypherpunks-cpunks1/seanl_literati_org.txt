
@_date: 2000-12-06 11:23:14
@_author: Sean R. Lynch 
@_subject: Destroying evidence (was "About 5yr. log retention") 
Fortunately the public key can be stored using steganography, or on some
medium that can be physically destroyed, or whatever.  Another option would
be to use an elliptic curve scheme that generates the private key on the
fly from a passphrase.  Fortunately they can't read your mind yet, though
keystroke readers could prove you knew the passphrase, but then again you
might claim that since the cops (and anyone else reading your keystrokes)
also knew the passphrase, that they had your private key as much as you
did.  And then there are ways to avoid having your keystrokes read.

@_date: 2000-12-07 09:15:02
@_author: Sean R. Lynch 
@_subject: Destroying evidence (was "About 5yr. log retention") 
Eek.  Sorry.  I meant the private key could be stored steganographically.
And the public key need only be attached to your nym.  Now the trick is not
leaving anything around that might be used to link you to your nym.

@_date: 2000-12-07 17:58:18
@_author: Sean R. Lynch 
@_subject: Signatures and MIME Attachments Getting Out of Hand 
Also, since when is crashing a proper response to *any* email message?
I don't think you have the PGP/MIME-using people to blame, nor should we
be expected to fix your lousy email program.  I can understand people's
desire to be able to read messages, but even if your MUA does not support
MIME, if you look at this message in plain text you can read it without
any sort of formatting problems.  Only mailers that have incorrect
MIME support will have problems with it, and that's simply not any of
our problem.
ASCII plain text *is* The Way.  But guess what, PGP/MIME *is* plain text.
You can even parse it with your eyeballs.

@_date: 2000-12-10 23:21:09
@_author: Sean R. Lynch 
@_subject: BS about RFC2015 messages being "attachments" 
Riad "fixed" his software by turning off RFC2015.  An "attachment" is a
part of a multipart MIME message that is not marked as "inline."  Any part
that *is* marked inline should be displayed inline by your MUA.  If you'll
look at the raw messages you're receiving, you'll see that the message
bodies of RFC2015 messages are marked as text/plain with a
content-disposition of inline, so they're not attachments.
To say that people are sending their entire messages as attachments just
because your MUA displays them that way, without accepting the possibility
that your MUA is broken (it is if it can't understand content-disposition
in other multipart types besides multipart/mixed), and claiming "Eurora
Pro handles MIME fine" without even understanding yourself how MIME works,
is disingenuous at best and a flat lie at worst.  Please get your ass off
the Internet until you can learn how to use it.  Barring that, at least
keep your mouth shut for a little while and open your eyes for a change.
Given that about 30% of my messages every day come from you and contain
very little content, I think you can put up with your MUA's broken
display of proper MIME messages or get a new one, and stop giving the rest
of us grief about it.
(message not signed because it's intended for someone with a broken MUA;
it's copied to the list lest someone actually start believing Tim's

@_date: 2000-12-10 23:49:58
@_author: Sean R. Lynch 
@_subject: Sunders point on copyright infringement & HTML 
Sorry, that last one from me was out of line.  I'm just tired of being
accused of sending my messages as attachments by people with broken MUAs,
and then their claiming that their MUA must handle MIME fine because they
can click on the pretty little icon and have attachments magically open for
them.  Having done tech support in the past, I've just heard this sort of
excuse one too many times.

@_date: 2000-12-12 10:34:16
@_author: Sean R. Lynch 
@_subject: About 5yr. log retention 
Believing that evil is a matter of perspective does not necessarily make
one a moral relativist.  I believe that both good and evil do not exist
objectively.  However, I don't kill people because a) I would feel bad
about it and b) I don't want people killing me back, and c) The type of
society I'd like to live in wouldn't function very well if people just went
around killing each other willy nilly.
I fully agree with this definition, yet I don't define anyone to be my
"enemy" except those who deliberately stand in the way of the things I want
to do (nobody right now except maybe the govt).
I'm assuming by murderously you mean arbitrarily, which makes them a danger
to others.
When you call someone evil, you're begging the question of their evilness.
I've heard lots of people (including myself) called evil to further someone
else's aims, that the word no longer has any meaning any more.  I'd rather
hear "he kills arbitrarily" than "he's evil."
I do use the term "evil" occasionally, but it's usually referring to ideas
or nasty hacks, and usually in a jocular fashion.
At first I thought in this section you were arguing against this particular
use of the term 'evil,' and then you go on to say that the use of this term
made it possible for the govt to convince people that bombing Serbia was a
good thing without having to argue about it, and you say that this is good?
How many other groups of people do you think have been convinced to do
violence this way?  I guess it's OK when the US does it, but not OK when
Hitler calls Jews evil?
Evil *is* a subjective concept, and whenever you hear it you should
immediately become *very* suspicious and ask why, regardless of whether you
think it's obvious that someone's evil, because I think sometimes the
answer will surprise you.

@_date: 2013-12-03 11:34:21
@_author: Sean Lynch 
@_subject: audiovisual (urls) 
While reducing loss will certainly help, the NICT paper you link to will
not. Quantum cryptography relies on only having a single entangled
particle going to each end, so that if anyone intercepts either particle
and attempts to measure whatever property you're using to derive the key
(polarization generally), the keys will not match because the quantum
state will be destroyed.
The paper you link to talks about creating large numbers of entangled
particles. While this is useful for sharing quantum computations over
long distances, it is not at all useful for quantum cryptography,
because one could intercept a small number of these particles, measure
them on each of the possible axes used for the cryptosystem, and figure
out the shared key.

@_date: 2013-12-03 22:14:41
@_author: Sean Lynch 
@_subject: audiovisual (urls) 
No problem. Not having read the actual paper, I'm not even sure what
they meant by "noise" preventing amplification of quantum signals in an
EDFA. Quantum states cannot be copied, which seems like a more
fundamental problem, but perhaps they are talking about the potential
for using an EDFA just to create a large number of entangled particles.
I'm fairly optimistic for a couple of different reasons. First of all,
progress on quantum computers has been very slow and the experts in the
field who have spoken up believe it's unlikely the NSA has a major
breakthrough on this front. Second, I'm skeptical that quantum computers
can even be made to work at all. While D-Wave and others have built
systems that they *believe* are quantum computers and shown some
evidence that they behave as one would expect for such devices, nothing
has yet been demonstrated that could not easily been achieved with a
classical computer, though much of this is due to the small scale of the
Even if quantum computers can be made to work, one can hope that by then
we'll either have quantum cryptography infrastructure in place (though
the need for physical infrastructure scares me here - maybe guerrilla
wireless quantum crypto?) or have widespread access to practical
quantum-proof public-key crypto. Maybe either the NTRU patent will have
expired or we'll have found alternative cryptosystems that do not
infringe, ala the Lucas sequence alternative to RSA. Of course, the
patent is only a problem in the US and its satellite states anyway.

@_date: 2013-12-07 13:15:34
@_author: Sean Lynch 
@_subject: infra-org (urls) 
(Take everything I say here with a grain of salt; I'm not a quantum
physicist, nor have I ever even taken a quantum physics class. I just
read a lot about this stuff and think about it a lot.)
Quantum entanglement is inherently difficult to explain because it's a
consequence of the prevailing interpretation (the Copenhagen
interpretation) of quantum mechanics, that the spin axis isn't actually
"chosen" until you measure it. Unfortunately, the information that's
supposedly "transmitted" instantaneously doesn't originate from outside
the system, so it can't be used to send anything useful to human beings.
There's an explanation that's slightly less awkward in my view: that the
information about what axis you're measuring the spin on actually gets
transmitted backward in time along the particle's path to the point at
which the particles became entangled. It's less awkward because it
doesn't require anything to happen faster than light, and it doesn't
allow paradoxes because you can't actually get anything useful back
out. This interpretation is known as "time symmetric quantum mechanics,"
but unfortunately there aren't a whole lot of papers on it because the
Copenhagen interpretation is quite dominant.
Special Relativity itself actually doesn't forbid traveling or sending
information faster than light; it just forbids accelerating a massive
object to or through the speed of light. There has been talk of
"tachyons," particles "born" traveling faster than light and possessing
imaginary mass, since the earliest days of SR. Since they would allow
the creation of paradoxes and have other strange properties such as
accelerating as they lose energy, most physicists assume they do not
exist. They've even created a principle, the "Causality Principle," that
forbids them. The Causality Principle simply says that all observers
must observe two events that are causally connected (i.e. exchange any
information between them) occurring in the same order. This property can
only be true if information is transmitted at or below the speed of
The Causality Principle is the weakest principle that prevents paradoxes
within Special Relativity, but it turns out a minor tweak to SR enables
a weaker principle to prevent paradoxes: the addition of a "privileged"
refernce frame. In particular, the reference frame in which quantum
entanglement is assumed to operate, which may also be the reference
frame of the cosmic microwave background. The revised, weaker Causality
Principle says that any two causally-connected events must be observed
to occur in the same order *to an observer in the privileged reference
frame.* That gets rid of the speed of light limit entirely, as long as
you don't travel back in time in this one particular reference frame. It
would probably also make the Copenhagen interpretation of QM preferable
to the time-symmetric interpretation, but I haven't thought that one
through yet (in fact, I don't understand how they measure the speed of
the quantum connection yet either).
That means quantum entanglement *could* actually carry useful
information, and we could (in theory, anyway) construct an Ansible.
Before you go off saying "but SR says there's no privileged reference
frame!" it actually doesn't. It says you don't *need* one. Lorentz
constructed the geometry Einstein borrowed for Special Relativity
specifically to explain why the Earth's motion relative to the
luminiferous ether could not be detected. Einstein's major contribution
(for SR, aside from E=mc^2) was the realization that Lorentz's geometry
obviated the need for a luminiferous ether entirely. But perhaps quantum
entanglement can give the luminiferous ether a new life.

@_date: 2013-12-07 13:22:58
@_author: Sean Lynch 
@_subject: infra-org (urls) 
This is exactly the model of the mind that I believed in when I was in
college. These days I believe that consciousness consists of information
but that information, far from being static, is actually the connections
among potential events. It's like a complex machine: pull lever A here
and gear B over there moves. The complex set of (abstract, not concrete)
connections that makes up the "model" of our reactions to various sets
of stimuli *is* our consciousness, versus there being some component in
there that produces the illusion of consciousness.
I'm sure that sounds sort of crazy; condensing such a large set of
varyingly intuitive leaps into a single paragraph is probably not such a
great idea. Happy to provide more background on the list or privately
for anyone who's interested.

@_date: 2013-12-30 16:00:11
@_author: Sean Lynch 
@_subject: Jacob Appelbaum in Germany 
The talk is titled "To Protect and Infect Part 2" and video is available at
If you can't view WebM you can find other formats by looking around in
parent directories.

@_date: 2013-12-03 11:34:21
@_author: Sean Lynch 
@_subject: audiovisual (urls) 
While reducing loss will certainly help, the NICT paper you link to will
not. Quantum cryptography relies on only having a single entangled
particle going to each end, so that if anyone intercepts either particle
and attempts to measure whatever property you're using to derive the key
(polarization generally), the keys will not match because the quantum
state will be destroyed.
The paper you link to talks about creating large numbers of entangled
particles. While this is useful for sharing quantum computations over
long distances, it is not at all useful for quantum cryptography,
because one could intercept a small number of these particles, measure
them on each of the possible axes used for the cryptosystem, and figure
out the shared key.

@_date: 2013-12-03 22:14:41
@_author: Sean Lynch 
@_subject: audiovisual (urls) 
No problem. Not having read the actual paper, I'm not even sure what
they meant by "noise" preventing amplification of quantum signals in an
EDFA. Quantum states cannot be copied, which seems like a more
fundamental problem, but perhaps they are talking about the potential
for using an EDFA just to create a large number of entangled particles.
I'm fairly optimistic for a couple of different reasons. First of all,
progress on quantum computers has been very slow and the experts in the
field who have spoken up believe it's unlikely the NSA has a major
breakthrough on this front. Second, I'm skeptical that quantum computers
can even be made to work at all. While D-Wave and others have built
systems that they *believe* are quantum computers and shown some
evidence that they behave as one would expect for such devices, nothing
has yet been demonstrated that could not easily been achieved with a
classical computer, though much of this is due to the small scale of the
Even if quantum computers can be made to work, one can hope that by then
we'll either have quantum cryptography infrastructure in place (though
the need for physical infrastructure scares me here - maybe guerrilla
wireless quantum crypto?) or have widespread access to practical
quantum-proof public-key crypto. Maybe either the NTRU patent will have
expired or we'll have found alternative cryptosystems that do not
infringe, ala the Lucas sequence alternative to RSA. Of course, the
patent is only a problem in the US and its satellite states anyway.

@_date: 2013-12-07 13:15:34
@_author: Sean Lynch 
@_subject: infra-org (urls) 
(Take everything I say here with a grain of salt; I'm not a quantum
physicist, nor have I ever even taken a quantum physics class. I just
read a lot about this stuff and think about it a lot.)
Quantum entanglement is inherently difficult to explain because it's a
consequence of the prevailing interpretation (the Copenhagen
interpretation) of quantum mechanics, that the spin axis isn't actually
"chosen" until you measure it. Unfortunately, the information that's
supposedly "transmitted" instantaneously doesn't originate from outside
the system, so it can't be used to send anything useful to human beings.
There's an explanation that's slightly less awkward in my view: that the
information about what axis you're measuring the spin on actually gets
transmitted backward in time along the particle's path to the point at
which the particles became entangled. It's less awkward because it
doesn't require anything to happen faster than light, and it doesn't
allow paradoxes because you can't actually get anything useful back
out. This interpretation is known as "time symmetric quantum mechanics,"
but unfortunately there aren't a whole lot of papers on it because the
Copenhagen interpretation is quite dominant.
Special Relativity itself actually doesn't forbid traveling or sending
information faster than light; it just forbids accelerating a massive
object to or through the speed of light. There has been talk of
"tachyons," particles "born" traveling faster than light and possessing
imaginary mass, since the earliest days of SR. Since they would allow
the creation of paradoxes and have other strange properties such as
accelerating as they lose energy, most physicists assume they do not
exist. They've even created a principle, the "Causality Principle," that
forbids them. The Causality Principle simply says that all observers
must observe two events that are causally connected (i.e. exchange any
information between them) occurring in the same order. This property can
only be true if information is transmitted at or below the speed of
The Causality Principle is the weakest principle that prevents paradoxes
within Special Relativity, but it turns out a minor tweak to SR enables
a weaker principle to prevent paradoxes: the addition of a "privileged"
refernce frame. In particular, the reference frame in which quantum
entanglement is assumed to operate, which may also be the reference
frame of the cosmic microwave background. The revised, weaker Causality
Principle says that any two causally-connected events must be observed
to occur in the same order *to an observer in the privileged reference
frame.* That gets rid of the speed of light limit entirely, as long as
you don't travel back in time in this one particular reference frame. It
would probably also make the Copenhagen interpretation of QM preferable
to the time-symmetric interpretation, but I haven't thought that one
through yet (in fact, I don't understand how they measure the speed of
the quantum connection yet either).
That means quantum entanglement *could* actually carry useful
information, and we could (in theory, anyway) construct an Ansible.
Before you go off saying "but SR says there's no privileged reference
frame!" it actually doesn't. It says you don't *need* one. Lorentz
constructed the geometry Einstein borrowed for Special Relativity
specifically to explain why the Earth's motion relative to the
luminiferous ether could not be detected. Einstein's major contribution
(for SR, aside from E=mc^2) was the realization that Lorentz's geometry
obviated the need for a luminiferous ether entirely. But perhaps quantum
entanglement can give the luminiferous ether a new life.

@_date: 2013-12-07 13:22:58
@_author: Sean Lynch 
@_subject: infra-org (urls) 
This is exactly the model of the mind that I believed in when I was in
college. These days I believe that consciousness consists of information
but that information, far from being static, is actually the connections
among potential events. It's like a complex machine: pull lever A here
and gear B over there moves. The complex set of (abstract, not concrete)
connections that makes up the "model" of our reactions to various sets
of stimuli *is* our consciousness, versus there being some component in
there that produces the illusion of consciousness.
I'm sure that sounds sort of crazy; condensing such a large set of
varyingly intuitive leaps into a single paragraph is probably not such a
great idea. Happy to provide more background on the list or privately
for anyone who's interested.

@_date: 2013-12-30 16:00:11
@_author: Sean Lynch 
@_subject: Jacob Appelbaum in Germany 
The talk is titled "To Protect and Infect Part 2" and video is available at
If you can't view WebM you can find other formats by looking around in
parent directories.

@_date: 2013-12-03 11:34:21
@_author: Sean Lynch 
@_subject: audiovisual (urls) 
While reducing loss will certainly help, the NICT paper you link to will
not. Quantum cryptography relies on only having a single entangled
particle going to each end, so that if anyone intercepts either particle
and attempts to measure whatever property you're using to derive the key
(polarization generally), the keys will not match because the quantum
state will be destroyed.
The paper you link to talks about creating large numbers of entangled
particles. While this is useful for sharing quantum computations over
long distances, it is not at all useful for quantum cryptography,
because one could intercept a small number of these particles, measure
them on each of the possible axes used for the cryptosystem, and figure
out the shared key.

@_date: 2013-12-03 22:14:41
@_author: Sean Lynch 
@_subject: audiovisual (urls) 
No problem. Not having read the actual paper, I'm not even sure what
they meant by "noise" preventing amplification of quantum signals in an
EDFA. Quantum states cannot be copied, which seems like a more
fundamental problem, but perhaps they are talking about the potential
for using an EDFA just to create a large number of entangled particles.
I'm fairly optimistic for a couple of different reasons. First of all,
progress on quantum computers has been very slow and the experts in the
field who have spoken up believe it's unlikely the NSA has a major
breakthrough on this front. Second, I'm skeptical that quantum computers
can even be made to work at all. While D-Wave and others have built
systems that they *believe* are quantum computers and shown some
evidence that they behave as one would expect for such devices, nothing
has yet been demonstrated that could not easily been achieved with a
classical computer, though much of this is due to the small scale of the
Even if quantum computers can be made to work, one can hope that by then
we'll either have quantum cryptography infrastructure in place (though
the need for physical infrastructure scares me here - maybe guerrilla
wireless quantum crypto?) or have widespread access to practical
quantum-proof public-key crypto. Maybe either the NTRU patent will have
expired or we'll have found alternative cryptosystems that do not
infringe, ala the Lucas sequence alternative to RSA. Of course, the
patent is only a problem in the US and its satellite states anyway.

@_date: 2013-12-07 13:15:34
@_author: Sean Lynch 
@_subject: infra-org (urls) 
(Take everything I say here with a grain of salt; I'm not a quantum
physicist, nor have I ever even taken a quantum physics class. I just
read a lot about this stuff and think about it a lot.)
Quantum entanglement is inherently difficult to explain because it's a
consequence of the prevailing interpretation (the Copenhagen
interpretation) of quantum mechanics, that the spin axis isn't actually
"chosen" until you measure it. Unfortunately, the information that's
supposedly "transmitted" instantaneously doesn't originate from outside
the system, so it can't be used to send anything useful to human beings.
There's an explanation that's slightly less awkward in my view: that the
information about what axis you're measuring the spin on actually gets
transmitted backward in time along the particle's path to the point at
which the particles became entangled. It's less awkward because it
doesn't require anything to happen faster than light, and it doesn't
allow paradoxes because you can't actually get anything useful back
out. This interpretation is known as "time symmetric quantum mechanics,"
but unfortunately there aren't a whole lot of papers on it because the
Copenhagen interpretation is quite dominant.
Special Relativity itself actually doesn't forbid traveling or sending
information faster than light; it just forbids accelerating a massive
object to or through the speed of light. There has been talk of
"tachyons," particles "born" traveling faster than light and possessing
imaginary mass, since the earliest days of SR. Since they would allow
the creation of paradoxes and have other strange properties such as
accelerating as they lose energy, most physicists assume they do not
exist. They've even created a principle, the "Causality Principle," that
forbids them. The Causality Principle simply says that all observers
must observe two events that are causally connected (i.e. exchange any
information between them) occurring in the same order. This property can
only be true if information is transmitted at or below the speed of
The Causality Principle is the weakest principle that prevents paradoxes
within Special Relativity, but it turns out a minor tweak to SR enables
a weaker principle to prevent paradoxes: the addition of a "privileged"
refernce frame. In particular, the reference frame in which quantum
entanglement is assumed to operate, which may also be the reference
frame of the cosmic microwave background. The revised, weaker Causality
Principle says that any two causally-connected events must be observed
to occur in the same order *to an observer in the privileged reference
frame.* That gets rid of the speed of light limit entirely, as long as
you don't travel back in time in this one particular reference frame. It
would probably also make the Copenhagen interpretation of QM preferable
to the time-symmetric interpretation, but I haven't thought that one
through yet (in fact, I don't understand how they measure the speed of
the quantum connection yet either).
That means quantum entanglement *could* actually carry useful
information, and we could (in theory, anyway) construct an Ansible.
Before you go off saying "but SR says there's no privileged reference
frame!" it actually doesn't. It says you don't *need* one. Lorentz
constructed the geometry Einstein borrowed for Special Relativity
specifically to explain why the Earth's motion relative to the
luminiferous ether could not be detected. Einstein's major contribution
(for SR, aside from E=mc^2) was the realization that Lorentz's geometry
obviated the need for a luminiferous ether entirely. But perhaps quantum
entanglement can give the luminiferous ether a new life.

@_date: 2013-12-07 13:22:58
@_author: Sean Lynch 
@_subject: infra-org (urls) 
This is exactly the model of the mind that I believed in when I was in
college. These days I believe that consciousness consists of information
but that information, far from being static, is actually the connections
among potential events. It's like a complex machine: pull lever A here
and gear B over there moves. The complex set of (abstract, not concrete)
connections that makes up the "model" of our reactions to various sets
of stimuli *is* our consciousness, versus there being some component in
there that produces the illusion of consciousness.
I'm sure that sounds sort of crazy; condensing such a large set of
varyingly intuitive leaps into a single paragraph is probably not such a
great idea. Happy to provide more background on the list or privately
for anyone who's interested.

@_date: 2013-12-30 16:00:11
@_author: Sean Lynch 
@_subject: Jacob Appelbaum in Germany 
The talk is titled "To Protect and Infect Part 2" and video is available at
If you can't view WebM you can find other formats by looking around in
parent directories.

@_date: 2013-01-11 10:08:59
@_author: Sean Lynch 
@_subject: [p2p-hackers] Distributed identity, chat, publishing, 
Very interesting. "Cryptosphere" is a good name for such a system,
though from what you describe there the project seems more concerned
about identifying content than people, whereas my idea centers around
identifying people, with content being secondary.
Yeah, to me verifying key fingerprints is a lost cause - people will
never do it. Instead we need the socialist millionaire protocol for
bootstrapping, and a web of trust. Or the very simple fact that you got
someone's public key via a MITM-proof channel in the first place, like a
QR code on a business card, NFC, etc.
Can you elaborate on this? By metadata I was thinking of things like
filename, content description, ratings, etc.
Given that the part that needs to be small is the public key, what's the
benefit of using the same private key? Once you have an Ed25519 public
key, you can always do an authenticated Diffie-Hellman exchange with an
ephemeral session key, which gives you perfect forward security if any
individual session private key is compromised.
I ran across CurveCP before and had forgotten about it. Embedding and
congestion control are primary requirements for me, and libutp fits the
bill, even allowing the user to provide a callback for sending and
receiving data, which is where I'd apply the encryption.
The system you describe could certainly make a good platform for what I
describe, though I'm far more interested in the "applications"
themselves, i.e. chat, publishing, sharing, etc., than in the underlying
infrastructure. My primary concern about the underlying infrastructure
is that it be secure, easy to install/use, doesn't use a tremendous
amount of CPU or bandwidth (this should ideally run on mobile phones),
and connects reasonably quickly.
All of the applications could even be written in Javascript and
distributed through the network itself, signed by their authors. They
could run as web workers using a particular protocol to talk to the main
app if the network runs in a browser, or in QtScript if it's a native Qt
app. I have no idea how to securely run untrusted JS in Java, though.
I'd like to implement as little of this as possible, since it's a pretty
big undertaking and will require a number of iterations to get something
usable. That's why I am thinking of things like embedding I2P and
Freenet or Tor and Gnunet. I'd prefer C++ and Qt over Java, though
building for Windows will be a bit of a challenge, especially for Gnunet
with its huge number of not-very-crossplatform dependencies like
libgcrypt, among others. I'd love to have it able to build in VS, but
Tor won't either IIRC.
p2p-hackers mailing list
p2p-hackers at lists.zooko.com
