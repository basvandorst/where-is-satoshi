
@_date: 2004-08-04 11:04:15
@_author: Hal Finney 
@_subject: On what the NSA does with its tech 
Not necessarily, if nanotechnology works.  128 bits is big but not
that big.
Eric Drexler, in Nanosystems, section 12.9, predicts that a nanotech
based CPU fitting in a 400 nm cube could run at 1000 MIPS and consume
60 nanowatts, performing 10^16 instructions per second per watt.
Let's design a system to break a 128 bit cipher.  Let's suppose it has
to do 2^10 instructions per test, so this is 2^138 instructions total,
or about 10^41.  Let's let it run for four months, which is 10^7 seconds,
so our necessary processing rate is 10^34 instructions per second.
This means we need 10^34 IPS / 1000 MIPS or 10^25 of Drexler's gigahertz
cubes, call it 10^25 cubic microns or 10^7 cubic meters, a cube about
220 meters on a side.
The system will consume 10^25 * 60 nanowatts or about 6 * 10^17 watts.
Now, that's a lot.  It's four times what the earth receives from the sun.
So we have to build a disk four times the area (not volume) of the earth,
collect that power and funnel it to our computers.  Probably we would
scatter the computers throughout the disk, which would be mostly composed
of solar collectors.  (Keeping the disk gravitationally stable is left
as an exercise for the student, as is the tradeoff involved in making
it smaller but moving it closer to the sun.)
Fortunately, exhaustive key search is perfectly parallelizable so there
is no need for complex communications or synchronizations between the
As you can see, breaking 128 bit keys is certainly not a task which is
so impossible that it would fail even if every atom were a computer.
If we really needed to do it, it's not outside the realm of possibility
that it could be accomplished within 50 years, using nanotech and robotics
to move and reassemble asteroids into the necessary disk.
Now, 256 bit keys really are impossible, unless the whole contraption
above can be made to operate as an enormous, unified quantum computer,
in which case it could theoretically break even 256 bit keys.
512 bit keys... now those really are impossible.
Hal Finney

@_date: 2004-08-04 11:04:15
@_author: Hal Finney 
@_subject: On what the NSA does with its tech 
Not necessarily, if nanotechnology works.  128 bits is big but not
that big.
Eric Drexler, in Nanosystems, section 12.9, predicts that a nanotech
based CPU fitting in a 400 nm cube could run at 1000 MIPS and consume
60 nanowatts, performing 10^16 instructions per second per watt.
Let's design a system to break a 128 bit cipher.  Let's suppose it has
to do 2^10 instructions per test, so this is 2^138 instructions total,
or about 10^41.  Let's let it run for four months, which is 10^7 seconds,
so our necessary processing rate is 10^34 instructions per second.
This means we need 10^34 IPS / 1000 MIPS or 10^25 of Drexler's gigahertz
cubes, call it 10^25 cubic microns or 10^7 cubic meters, a cube about
220 meters on a side.
The system will consume 10^25 * 60 nanowatts or about 6 * 10^17 watts.
Now, that's a lot.  It's four times what the earth receives from the sun.
So we have to build a disk four times the area (not volume) of the earth,
collect that power and funnel it to our computers.  Probably we would
scatter the computers throughout the disk, which would be mostly composed
of solar collectors.  (Keeping the disk gravitationally stable is left
as an exercise for the student, as is the tradeoff involved in making
it smaller but moving it closer to the sun.)
Fortunately, exhaustive key search is perfectly parallelizable so there
is no need for complex communications or synchronizations between the
As you can see, breaking 128 bit keys is certainly not a task which is
so impossible that it would fail even if every atom were a computer.
If we really needed to do it, it's not outside the realm of possibility
that it could be accomplished within 50 years, using nanotech and robotics
to move and reassemble asteroids into the necessary disk.
Now, 256 bit keys really are impossible, unless the whole contraption
above can be made to operate as an enormous, unified quantum computer,
in which case it could theoretically break even 256 bit keys.
512 bit keys... now those really are impossible.

@_date: 2004-08-10 17:18:08
@_author: Hal Finney 
@_subject: DAA and Credentials 
A few weeks ago Adam Back sent me a pointer to a paper with what was
basically a new anonymous credential system, by Brickell, Camenisch
and Chen, I've followed Jan Camenisch's work pretty closely over the years and
although he is only the 2nd author here, the paper is very much based
on his ideas.
Actually the paper is about a very controversial topic, trusted computing:
TCPA, TCG, TPM, the Fritz chip, etc.  Despite the questions about that
technology, the paper has some interesting ideas which could be applied
more widely.
One of the concepts in trusted computing is that the computer would
have a chip in it with an embedded key.  This chip is called the TPM
officially but is widely known as the Fritz chip after the senator who
was pushing some legislation that might mandate technology controls.
Fritz Hollings is gone and so is his CBDTPA but now the FCC seems to be
taking up the gauntlet.  But that's another story.
Anyway, the TPM generates a key internally and it gets certified by some
kind of CA established by the TCG (the TCG is the new name for the TCPA).
When someone wants to, say, download some DRM-protected data, they could
prove they have a real TPM by providing this certificate from the TCG CA
on their TPM key.  This would let the data supplier know he was talking
to a system with a genuine TPM that would protect the data and keep the
user from defeating the DRM.
That would be the simple way to work, but the TCG didn't do it that way,
because having the user show his TPM certificate everywhere would violate
his privacy.  It may seem strange that a proposal which is built on the
idea that the user is the enemy will care about his privacy, especially
since most TCG uses will require the user to pay for things, meaning
showing a credit card number, so he has no privacy anyway.  But that's
the political decision the TCG made.
Instead, they came up with a "Privacy CA", where the user would in effect
show his TPM certificate to the PCA, and the PCA would then certify a
temporary "pseudonym key" that the user would then use in place of his
TPM key and certificate.  The problem here is that this doesn't protect
privacy all that well, plus the PCA needs to have both high availability
and high security, two requirements that don't work well together.
So TCG has approved this new proposal, cryptographically based, called
Direct Anonymous Attestation or DAA.  There is no more Privacy CA.
Instead, the user directly proves that he has a valid certificate on his
TPM key, but he does it in zero knowledge.  He doesn't reveal the TPM key
or the certificate, nevertheless the verifier (which would typically be a
seller of DRM'd content) gets convinced that he is talking to a real TPM.
The way it works is a modification of a group signature.  Camenisch has
done a lot of work on these over the years, with various co-authors.
But the general idea is the same, that group members each generate a key,
which gets certified by a "group ownership manager" and that means they're
officially part of the group.   Then they can create signatures of which
it can only be determined that they came from someone in the group, but
you can't tell which one.  This is done by the method described above,
a zero knowledge proof that you know a key and you have a certificate
(signature) on it by the group manager key.  That establishes that you
are a group member.
One of the new ideas in the DAA paper relates to revocation.  The TPM
private keys are supposed to remain locked in the chip.  But suppose
someone uses some fancy lab equipment or perhaps a side channel attack
and extracts one.  They could spread it around to their friends, who
could use it to pretend to have TPMs, download DRM-protected data and
easily remove the protections.  The TCG wanted to deal with this.
The assumption is that a secret this good can't be kept quiet for long,
so soon there will be lists of TPM-cracked keys floating out there.
TCG-based vendors are assumed to have access to such a list, so when
someone shows up with their ZK proof about having a good TPM, they want
to know if the TPM key is on the list.  The problem is that the TPM
key is not revealed in the ZK proof.  So the authors propose that, if
the key is k, another value of the form u^k mod p gets revealed, where
u is perhaps chosen by the vendor, or is perhaps random.  This doesn't
reveal k but there is a proof that the k used in u^k is the same k that
got certified as a TPM key.
Now the vendor can compare the reported u^k value with computed u^k based
on all known "bad" keys.  If it matches for any of them, he knows that
he is being offered a bogus TPM key proof.
That's the basic idea of the DAA, but there are two additional points
of interest.  The first is that DAA is really complicated, more so than
most group signatures of this type I have seen.  The main reason seems to
be a desire to not make the TPM work too hard.  The authors have cleverly
and diligently split up the protocol so that as much work as possible
is done by the host computer and not the TPM, even though the host is
not trusted.  The concept is similar to the old "wallet with observer"
protocols of Chaum and Brands.  But the effect is to add many extra
phases and passes, which could probably be eliminated if we didn't care
about that.
The second point relates to the system as a credential system.  This idea
of proving in zero knowledge that you have a cert on your key is the
basis of an earlier credential system from Camenisch and Lysyanskaya.
The concept is that credentials are represented by particular signatures
from particular signers.  Say, AAA could give me a credential as a member
for the year 2004 by a certain signature.  Then I could show possession
when I made a hotel reservation and get a discount, by proving that I
had that signature by AAA on a key I owned.  Doing it in ZK protects
my privacy.
I actually looked at implementing the C&L credential system a few
years ago, but there was a big stumbling block right at the beginning.
It would only work with an RSA key of a special form, one composed
of the product of two strong primes (primes p and q where (p-1)/2 and
(q-1)/2 were themselves prime).  And worse, it was necessary to prove
that the modulus was of that form, without of course revealing p and q.
Well, Camenisch had a protocol for this, but it was very complicated.
I implemented it and it was intolerably slow, it took many minutes or
even hours.  It just didn't appear feasible as the foundation for a
practical credential system.
One of the improvements in the new DAA system is that it escapes from
the need to prove that the RSA key is built of strong primes.  This means
that it could conceivably be the foundation for a credential system that
would actually be efficient enough to use.  That's very exciting!
Unfortunately, as I said the DAA system in its present form is not quite
right; it is too complicated due to the need to split up the work between
TPM and untrusted host.  That complication is not necessary for a plain
credentialling system.  So some work would have to be done to clean it
up and get it into a form that would work for credentials.
Crypto is next week and I hope to see Jan there and ask him about this.
If he thinks it would work then this is another project I might try
in the near future.  I would really like to see some kind of anonymous
credential system available for people to experiment with.  I had looked
into doing one with ring signatures but it would not be very efficient.
Camenisch's technology is far superior.
Hal Finney

@_date: 2004-08-15 10:43:09
@_author: Hal Finney 
@_subject: RPOW - Reusable Proofs of Work 
I'd like to invite members of this list to try out my new
hashcash-based server, rpow.net.
This system receives hashcash as a Proof of Work (POW) token, and in
exchange creates RSA-signed tokens which I call Reusable Proof of Work
(RPOW) tokens.  RPOWs can then be transferred from person to person and
exchanged for new RPOWs at each step.  Each RPOW or POW token can only
be used once but since it gives birth to a new one, it is as though the
same token can be handed from person to person.
Because RPOWs are only created from equal-value POWs or RPOWs, they are
as rare and "valuable" as the hashcash that was used to create them.
But they are reusable, unlike hashcash.
The new concept in the server is the security model.  The RPOW server
is running on a high-security processor card, the IBM 4758 Secure
Cryptographic Coprocessor, validated to FIPS-140 level 4.  This card
has the capability to deliver a signed attestation of the software
configuration on the board, which any (sufficiently motivated) user
can verify against the published source code of the system.  This lets
everyone see that the system has no back doors and will only create RPOW
tokens when supplied with POW/RPOW tokens of equal value.
This is what creates trust in RPOWs as actually embodying their claimed
values, the knowledge that they were in fact created based on an equal
value POW (hashcash) token.
I have a lot more information about the system at rpow.net, along with
downloadable source code.  There is also a crude web interface which
lets you exchange POWs for RPOWs without downloading the client.
This system is in early beta right now so I'd appreciate any feedback
if anyone has a chance to try it out.  Please keep in mind that if there
are problems I may need to reload the server code, which will invalidate
any RPOW tokens which people have previously created.  So don't go too
crazy hoarding up RPOWs quite yet.
Thanks very much -
Hal Finney

@_date: 2004-08-16 23:04:10
@_author: Hal Finney 
@_subject: HMAC? 
My guess is that HMAC is not vulnerable.  The basic structure of HMAC is
The attacker does not know the key(s) and is allowed to request MACs
on chosen messages; then he must produce a valid MAC on a new message.
The initial paper from Wang eg al announcing the results is unusual in
that it merely exhibits the collisions, while providing no information
whatsoever about how they were obtained.  They are simply presented as
a fait accompli, astonishing in their very existence.  It reminds me
of the story of how Cole demonstrated that the 67th Mersenne number was
nonprime, by silently walking to the backboard and patiently working out
the value of 2^67 - 1, and then the product of its two factors, by hand.
The nature of the exhibited hash collisions is that they are values which
differ in only a very few bits: 6 bits out of 1024 for the MD5 collisions;
4 bits out of 512 for the MD4.  Obviously it's not the case that for
most strings, you can toggle these 4 or 6 bits and produce a collision!
Instead, the authors must have some technique to create very special
strings which allow the changes made by these few bits to cancel each
other out.
If the attacker could find two messages such that there was an inner hash
collision, Hash(key2 || Msg1)  ==  Hash(key2 || Msg2), he could break
HMAC.  He'd get a MAC on Msg1 and then he could use that same MAC on Msg2.
But it seems impossible to find a collision like this without knowing
key2.  These hash functions are highly nonlinear and the choice of Msg1
and Msg2 would be completely dependent on key2.  Change 1 bit of key2
and half the bits of Msg1 and Msg2 would very probably have to change.
If the attacker knew key2, it sounds like the new attacks would likely
work to find an inner collision.  But without knowing that, there would
be no way to choose Msg1 and Msg2.
Given the special form of the colliding values, it appears that the
new technique does not solve hash inversion, or finding collisions
with arbitrary bit differentials.  The one possibility that I could
imagine for a threat to HMAC is their comment that the attack on MD4
(for which collisions were already known) is so easy that it can be done
by hand calculation.  Maybe that would suggest that given the proper
differentials, a non-negligible fraction of randomly chosen values would
collide.  Then conceivably you could get lucky and find a collision
without even knowing key2.  But that seems like a very remote possibility.
Hal Finney

@_date: 2004-08-17 09:21:56
@_author: Hal Finney 
@_subject: RPOW - Reusable Proofs of Work 
A couple of quick responses to the questions on RPOW, as I am at
Crypto this week.
Taral asked about the attestation.  It is based on a root key
published in Appendix C of IBM's "IBM 4758 PCI Cryptographic
Coprocessor Custom Software Interface Reference", available from
It is also published on IBM's web page at
This tells you that the attestation refers to a valid IBM 4758.
Further, the attestation contains within it both a hash of the RPOW
program, and a set of keys generated by that program.  Using the methods
described on the rpow.net web site, it is possible to take the RPOW source
code and generate a hash which matches that reported in the attestation.
This tells you that you have access to the actual source code running
on the RPOW server.  By studying the source you can confirm that the
program never exposes its private keys or allows them to leave the
board.  This tells you that if you send a message encrypted to the RPOW
communications key and get a meaningful response (messages are protected
with HMAC), you are talking to the program described in the attestation.
Lynn Wheeler mentions the IBM 4758 break by Mike Bond and Richard Clayton
described at   This was not
actually a break of the 4758 but an exploit of a cryptographic weakness
in the application running on the board, which was IBM's CCA support
software.  RPOW does not use CCA and is not vulnerable to that attack,
and IBM has since fixed the CCA.
Of course it is possible that RPOW may have vulnerabilities and errors
of its own, being my own work and far from perfect.  I welcome review
and comment on the RPOW source code which is open source and available
from rpow.net.
Hal Finney

@_date: 2004-12-16 10:16:27
@_author: Hal Finney 
@_subject: Off-the-Record Messaging (IM plugin) 
It looks like Ian Goldberg's site might be a more authoritative source,
 .
One interesting feature is authentication + deniability.  You know who
you are talking to, but afterwards anyone who captured a transcript can't
prove who said it.  Usually we do authentication with digital signatures,
but the problem is that binds you to what you say and it can be used
against you afterwards.
OTR does it by signing the key exchange which creates a MAC key for each
direction.  (A MAC is a keyed hash which is then applied to each message.)
Each message gets MAC'd and this way you know that the messages are
authentic and untampered.
This already protects you against your conversant; both of you know the
MAC keys in each direction (one knows them in order to MAC new messages;
the other knows them in order to verify the MAC), so each guy can
forge messages created by the other guy and create a bogus transcript.
That means that neither person can publish a transcript and credibly
claim that it authentically represents what was said.
Then, there's another trick: when you are through with them you publish
your MAC keys, in the clear.  This does not compromise secrecy; all of
the data is encrypted with a different key.  But it means that now, anyone
could in retrospect forge a transcript showing you saying anything at all.
And that of course means that no such transcript has any credibility in
terms of providing cryptographic evidence of what you said.

@_date: 2004-07-06 14:47:43
@_author: Hal Finney 
@_subject: Email tapping by ISPs, forwarder addresses, and crypto 
Right, mostly for use as disposable email addresses.  I've used
spamgourmet to good effect, myself.
One thing I haven't understood in all the commentary is whether law
enforcment still needs a warrant to access emails stored in this way.
Apparently the ISP can read them without any notice or liability, but
what about the police?
Also, what if you run your own mail spool, so the email is never stored
at the ISP, it just passes through the routers controlled by the ISP
(just like it passed through a dozen other routers on the internet).
Does this give the ISP (and all the other router owners) the right to
read your email?  I don't think so, it seems like that would definitely
cross over the line from "mail in storage" to "mail in transit".
That's a great idea.  You'd want to be sure and encrypt the whole message
including headers, and make the whole thing an encrypted attachment.
Has the added side benefits of compressing the email, and you could even
have the server do some spam filtering.
STARTTLS support at the proxy should pretty much go without saying these
days, so you might as well do it, but if you're already PGP encrypting
then it's not adding that much security.  Well, maybe it does, but you're
talking about a different threat.  For the problem that ISPs can read
your email in storage, STARTLS doesn't help much because it will only
protect the email until it gets to your local ISP, who will store your
email for you and can read it then (which is where the PGP comes in).
Where STARTTLS would help is with power users who run their own mail
servers.  But those people don't suffer from the problem we are talking
about here, legal access to the email by the ISP (I think, see above).
Nevertheless a mail-receiving proxy that uses STARTTLS connections to
power users would be kind of cool because it would keep anyone local
from knowing anything about the incoming mail.  Hopefully, STARTTLS will
eventually become so widespread that this functionality will be redundant,
but we are not there yet.
Absolutely, look at the threat model.  You're not worried about someone
breaking into your computer, you're worried about your ISP legally
reading your email.  To address this threat, auto-decryption is a
perfect solution.
Recently there was a proposal for a nym receiving service,
 by Bran Cohen and Len
Sassaman.  They have a complicated protocol for downloading email
anonymously.  To hide the complexity, they propose to set up a POP
compatible mail server agent on the user's computer running as a daemon
process (Windows service).  He would configure his mailer to connect to
localhost:4949 or whatever, just like any other POP server.  The service
would periodically go out and poll for email using the fancy protocol,
but then it would make it available to the local mail agent in perfectly
vanilla form.  The point is that this architecture hides the complexity
and makes it transparent for end users to use arbitrarily complex crypto
for mail receiving.  Something similar would be perfect for your idea.
I think it's a great idea.  Of course as you say there is still the
problem that the forwarding server could read your email, so you have
only moved the threat from the ISP to another operator.  The difference
I suppose is that the forwarder would be selling privacy services, hence
different ones would compete to get a good reputation.  Any cheating might
be detected by insider whistle blowers or perhaps some kind of audit.
Hal Finney

@_date: 2004-11-04 15:01:15
@_author: Hal Finney 
@_subject: Your source code, for sale 
I've been thinking about how to do this kind of thing with ecash.
One project I'm hoping to work on next year is a P2P gambling game (like
poker or something) using my rpow.net which is a sort of play-money ecash.
You'd like to be able to do bets and have some kind of reasonable
assurance that the other guy would pay up if he loses.
In the case of your problem there is the issue of whether the source
code you are buying is legitimate.  Only once you have inspected it and
satisfied yourself that it will suit your needs would you be willing
to pay.  But attaining that assurance will require examing the code in
such detail that maybe you will decide that you don't need to pay.
You could imagine a trusted third party who would inspect the code and
certify it, saying "the source code with hash XXX appears to be legitimate
Cisco source code".  Then they could send you the code bit by bit and
incrementally show that it matches the specified hash, using a crypto
protocol for gradual release of secrets.  You could simultaneously do
a gradual release of some payment information in the other direction.
If you don't have a TTP, one idea for using ecash is Markus Jakobsson's
"Ripping Coins for a Fair Exchange".  Basically you withdraw ecash from
your account and in effect "rip it in half" and give half to the seller.
Now he gives you the product and you give him the other half of the coin.
The idea is that once you have given him the "ripped" ecash ("torn"
would be a better word because ripping means something else today),
you are out the value of the cash.  You have no more incentive to cheat,
as giving him the other half won't cost you anything additional.
(Even without ecash, a service like egold could mimic this functionality.
You'd create an escrow account with two passwords, one known to each
party.  Only with both passwords could data be withdrawn from the account.
Then the buyer would transfer funds into this account.  After receiving
the goods, the buyer would send his password to the seller.)
The problem is that if the source code you are purchasing is bogus,
or if the other side doesn't come through, you're screwed because you've
lost the value of the torn cash.  The other side doesn't gain anything
by this fraud, but they harm you, and if they are malicious that might
be enough.  And likewise you might be malicious and harm them by refusing
to give them your half of the coin even after you have received the goods.
Again, this doesn't benefit you, you're still out the money, but maybe
you like causing trouble.
Another idea along these lines is gradual payment for gradual release
of the goods.  You pay 10% of the amount and they give you 10% of the
source code.  You pay another 10% and you get the next 10% of the source,
and so on.  (Or it could be nonlinear; maybe they give out half the code
for free, but the final 10% requires a large payment.)  The idea is that
you can sample and make sure they do appear to have the real thing with
a fairly small investment.
If there is some mechanism for the seller to have a reputation (like
Advogato's perhaps, with some spoofing immunity) then the problem is
easier; the seller won't want to screw buyers because it hurts his rep.
In that case it may be reasonable to ask the buyer to pay in advance,
perhaps using the partial payment system just discussed.
These various ideas all have tradeoffs, and in general this kind of
problem is hard to solve because of the complexity of what constitutes a
successful transaction.  A reputation system helps a great deal to resolve
the issues, but opens up problems of its own.  The betting problem I
want to work on is relatively easy because there is no ambiguity about
who wins, but even then it is hard to make sure that neither party can
maliciously harm the other.
Hal F.

@_date: 2004-11-05 10:12:48
@_author: Hal Finney 
@_subject: Your source code, for sale 
Interesting.  In the e-gold case, both parties have the same bank,
e-gold ltd.  The corresponding protocol would be for the buyer to instruct
e-gold to set aside some money which would go to the seller once the
seller supplied a certain receipt.  That receipt would be an email return
receipt showing that the seller had sent the buyer the content with hash
so-and-so, using a cryptographic email return-receipt protocol.
Actually you can arrange it so that neither the partially-released code
nor the partially-transferred ecash is of any value until the whole
transfer finishes.  For example, send the whole thing first in encrypted
form, then release the encryption keys bit-by-bit.  If someone aborts
the protocol early, the best each side can do is a brute force search
over the untransferred bits to try to find the key to unlock the data
they received.
That's a good point.  Maybe you could use some kind of DRM or trusted
computing concept to try to force the buyer to lock up his received data.
For source code that would be pretty difficult though, it needs to be
handled in flexible ways.

@_date: 2004-11-05 10:18:22
@_author: Hal Finney 
@_subject: Your source code, for sale 
Yes, I'm looking at ideas like this for ecash gambling, but you have
a who-goes-first problem.  One side or the other has to "rip" their
own cash first, and then the other side can just go away and leave the
first side screwed.  The act of ripping cash is relatively atomic and
involves a transaction with the ecash mint, so they can't both do it at
the same time.
I guess the best fix is for each side to rip a little bit of cash at a
time, so that the guy who goes first only loses a trivial amount if the
other side aborts.  Then after a few rounds both sides are sunk pretty
deep and both have a strong incentive to complete the transaction.

@_date: 2004-11-08 10:51:24
@_author: Hal Finney 
@_subject: Your source code, for sale 
Of course there has to be a third party in the form of the currency
issuer.  If it is someone like e-gold, they could do as I suggested and
add a feature where the buyer could transfer funds irrevocably into
an escrow account which would be jointly controlled by the buyer and
the seller.  This way the payment is already "gone" from the POV of the
buyer and if the seller completes the transaction, the buyer has less
incentive to cheat him.
In the case of an ecash mint, a simple method would be for the seller to
give the buyer a proto-coin, that is, the value to be signed at the mint,
but in blinded form.  The buyer could take this to the mint and pay to
get it signed.  The resulting value is no good to the buyer because he
doesn't know the blinding factors, so from his POV the money (he paid
to get it signed) is already "gone".  He can prove to the seller that
he did it by using the Guillou-Quisquater protocol to prove in ZK that
he knows the mint's signature on the value the seller gave him.
The seller thereby knows that the buyer's costs are sunk, and so the
seller is motivated to complete the transaction.  The buyer has nothing
to lose and might as well pay the seller by giving him the signed value
from the mint, which the seller can unblind and (provably, verifiably)
be able to deposit.

@_date: 2004-10-01 10:11:38
@_author: Hal Finney 
@_subject: Federal program to monitor everyone on the road 
There was a brief mention of this technology at the Crypto conference.
I provided some pointers in a comment to an Ed Felten blog entry at
 (scroll
down to the 3rd comment).
Dan Boneh et al presented a proposal for a group signature scheme so that
the data collected would not be personally identifiable.  The problem is
that the data needs to be authenticated, otherwise rogue transmitters
could send false data and perhaps cause traffic flow problems or even
serious accidents.  So they want to use some cryptographic method.
Putting a common key in the whole system would make it too easy for
rogues to get access to, would be unrevocable, and we are back to the
rogue transmitter problem.  Using individual certified keys is the
default solution but has privacy problems: everyone would be constantly
transmitting a cryptographically verifiable record of their driving
patterns, speed, lane changing and who knows what else.
With the group signature, everybody has a unique key but their
transmissions are not bound to that key.  And if a key gets scraped
out and goes rogue, it can be revoked.  This is supposed to provide
flexibility, authentication, and privacy.
In practice I am skeptical that society will choose to protect privacy at
the expense of security.  One optional feature of group signatures is a
trusted party who can penetrate the anonymity and learn the identity of
the author of a particular message.  I suspect that any vehicle based
embedded communications system will retain that capability, a sort of
"license plate" in the virtual realm.  The ability to track the paths of
bank robbers and terrorists would be too inviting for society to give up,
especially if the data is only available to government agents.

@_date: 2004-10-18 12:49:27
@_author: Hal Finney 
@_subject: Crypto blogs? 
Does anyone have pointers to crypto related weblogs?  Bruce Schneier
recently announced that Crypto-Gram would be coming out incrementally
in blog form at   I follow Ian Grigg's
Financial Cryptography blog, Recently I learned about Adam Shostack's although it seems to be more security than crypto.
Any other good ones?
Hal Finney

@_date: 2004-09-01 09:57:51
@_author: Hal Finney 
@_subject: Remailers an unsolveable paradox? 
Spam is the least of the problems for remailers when it comes to
abuse.  You should be more concerned about possible liability for
illegal messages.
In a way, spam has actually made the remailer operator's life easier
as people today are used to receiving annoying and obscene email.
Ten years ago, when I ran a remailer, people were genuinely shocked
to receive unsolicited pornography.  Yes, it's hard to believe today,
but in those quaint times, when the Internet was in black and white,
most users got only a few email messages a day and they were all from
their friends, family and co-workers.
As far as spam, next-generation remailers should incorporate hashcash,
 to make sending an anonymous message relatively costly.
Let it take a minute or more to generate the "stamp" necessary for a
message to enter the remailer system and spam will not be a problem,
while legitimate users will have no barrier.

@_date: 2004-09-08 11:48:02
@_author: Hal Finney 
@_subject: Seth Schoen's Hard to Verify Signatures 
Seth Schoen of the EFF proposed an interesting cryptographic primitive
called a "hard to verify signature" in his blog at
 .
The idea is to have a signature which is fast to make but slow to verify,
with the verification speed under the signer's control.  He proposes
that this could be useful with trusted computing to discourage certain
objectionable applications.
The method Seth describes is to include a random value in the signature
but not to include it in the message.  He shows a sample signature
with 3 decimal digits hidden.  The only way to verify it is to try all
possibilities for the random values.  By controlling how much data is
hidden in this way, the signer can control how long it will take to
verify the signature.
This idea is nice and simple, but one disadvantage is that it is
probabilistic.  It works on average, but occasionally someone might
choose an n digit value which happens to be low (assuming the values are
chosen at random).  Then they don't get as much protection.  They could
fix this by eliminating too-low values, but then verifiers might exploit
that by doing low values last in their testing.
Another problem is that this method is inherently parallelizable, so
that someone with N computers could solve it N times faster, by having
each computer test a subset of the values.
An alternative is based on the paper, "Time-lock puzzles and
timed release Crypto", by Rivest, Shamir and Wagner, from 1996,
 or .ps.
They are looking more at the problem of encrypting data such that it can
be decrypted only after a chosen amount of computing time, but many of
their techniques are applicable to signatures.
The first solution they consider is essentially the same as Seth's,
doing an encryption where n bits of the encryption key are unknown, and
letting people search for the decryption key.  They identify the problems
I noted above (which I stole from their paper).  They also point out BTW
that this concept was used by Ralph Merkle in his paper which basically
foreshadowed the invention of public key cryptography.  Merkle had to
fight for years to get his paper published, otherwise he would be known
as the father of the field rather than just a pioneer or co-inventor.
The next method they describe can be put into signature terms as follows.
Choose the number of modular squarings, t, that you want the verifier
to have to perform.  Suppose you choose t = 1 billion.  Now you will
sign your value using an RSA key whose exponent e = 2^t + 1.  (You also
need to make sure that this value is relatively prime to p-1 and q-1,
but that is easily arranged, for example by letting p and q be strong
primes.)  The way you sign, even using such a large e, is to compute
phi = (p-1)*(q-1) and to compute e' = e mod phi, which can be done using
about 30 squarings of 2 mod phi.  You then compute the secret exponent
d as the multiplicative inverse mod phi of e', in the standard way that
is done for RSA keys.  Using this method you can sign about as quickly
as for regular RSA keys.
However, the verifier has a much harder problem.  He does not know phi,
hence cannot reduce e.  To verify, he has to raise the signature to
the e power as in any RSA signature, which for the exponent I described
will require t = 1 billion modular squaring operations.  This will be a
slow process, and the signer can control it by changing the size of t,
without changing his own work factor materially.
The authors also point out that modular squaring is an intrinsically
sequential process which cannot benefit from applying multiple computers.
So the only speed variations relevant will be those between individual
Another idea I had for a use of hard to verify signatures would be if
you published something anonymously but did not want to be known as
the author of it until far in the future, perhaps after your death.
Then you could create a HTV signature on it, perhaps not identifying
the key, just the signature value.  Only in the future when computing
power is cheap would it be possible to try verifying the signature under
different keys and see which one worked.
Hal Finney

@_date: 2004-09-09 12:57:29
@_author: Hal Finney 
@_subject: potential new IETF WG on anonymous IPSec 
To clarify, this is not really "anonymous" in the usual sense.  Rather it
is a proposal to an extension to IPsec to allow for unauthenticated
connections.  Presently IPsec relies on either pre-shared secrets or a
trusted third party CA to authenticate the connection.  The new proposal
would let connections go forward using a straight Diffie-Hellman type
exchange without authentication.  It also proposes less authentication
of IP message packets, covering smaller subsets, as an option.
The point has nothing to do with anonymity; rather it is an attempt
to secure against weaknesses in TCP which have begun to be exploited.
Sequence number guessing attacks are more successful today because of
increasing bandwidth, and there have been several instances where they
have caused disruption on the net.  While workarounds are in place, a
better solution is desirable.
This new effort is Joe Touch's proposal to weaken IPsec so that it uses
less resources and is easier to deploy.  He calls the weaker version
AnonSec.  But it is not anonymous, all the parties know the addresses
of their counterparts.  Rather, it allows for a degree of security on
connections between communicators who don't share any secrets or CAs.
I don't think "anonymous" is the right word for this, and I hope the
IETF comes up with a better one as they go forward.
Hal Finney

@_date: 2005-02-11 16:14:14
@_author: Hal Finney 
@_subject: Cypherpunk help with Hal Finney demo 
Here's a semi-urgent request.  I introduced the RPOW project last year
on this list, rpow.net.  It provides a sort of play-money form of digital
cash, an implementation of Nick Szabo's concept of "bit gold".
I am giving a talk at CodeCon,  on this system, in about
an hour(!) and I could use some help from you.
One of the things I have done to demo a possible use is to make a
patched version of BitTorrent, the widely used file sharing program, that
exchanges RPOW data objects in order to reward people for uploading and
seeding files.  In exchange, people with RPOWs can get priority on future
downloads, so by seeding today you can get a better download tomorrow.
That's the concept, although at this point it is just an experiment.
What I need is to have a dozen or so people doing regular BitTorrent
downloads of a file I will offer during the demo, which will be at
about 5:15 PM Pacific Standard Time, 8:15 PM EST, 1:15 AM GMT.  That's 1
hour from now.  You don't need to use any special RPOW software, just
the regular BitTorrent client.
If you have a BitTorrent client and know how to use it, could you start
up and leave running a download of the following .torrent file:
This is fully legal, it's just a home movie of my dog Arky playing on
the beach with his brother.
Nothing will happen with the download until I start the demo after 5.
But if you could start up your BitTorrent client before then and just
leave it running, it would be a big help for me.
If you are able to do this, please send me an email when you start up your
BT client, at hal at finney.org.  If you've never used BT, don't bother to
try downloading and figuring it out.  I only really need a minimum of
4 or 5 people doing it, but as I said a dozen or more would be great.
Sorry about the last minute notice; I know that most people won't see
this until too late, but if anyone sees it now and you know how to use
BT I'd appreciate your help.
Hal Finney

@_date: 2005-02-17 14:25:36
@_author: Hal Finney 
@_subject: [p2p-hackers] SHA1 broken? 
The problem with the attack scenario where two versions of a program are
created with the same hash, is that from what little we know of the new
attacks, they aren't powerful enough to do this.
All of the collisions they have shown have the property where the two
alternatives start with the same initial value for the hash; they then
have one or two blocks which are very carefully selected, with a few
bits differing between the two blocks; and at the end, they are back
to a common value for the hash.
It is known that their techniques are not sensitive to this initial value.
They actually made a mistake when they published their MD5 collision,
because they had the wrong initial values due to a typo in Schneier's
book.  When people gave them the correct initial values, they were able
to come up with new collisions within a matter of hours.
If you look at their MD5 collision in detail, it was two blocks long.
Each block was almost the same as the other, with just a few bits
different.  They start with the common initial value.  Then they run
the first blocks through.  Amazingly, this has only a small impact on
the intermediate value after this first block.  Only a relatively few
bits are different.
If you or I tried to take two blocks with a few bits different and feed
them to MD5, we would get totally different outputs.  Changing even
one bit will normally change half the output bits.  The fact that they
are able to change several bits and get only a small difference in the
output is the first miracle.
But then they do an even better trick.  They now go on and do the
second pair of blocks.  The initial values for these blocks (which are
the outputs from the previous stage) are close but not quite the same.
And amazingly, these second blocks not only keep things from getting
worse, they manage to heal the differences.  They precisely compensate
for the changes and bring the values back together.  This is the second
miracle and it is even greater.
Now, it would be a big leap from this to being able to take two arbitrary
different initial values and bring them together to a common output.
That is what would be necessary to mount the code fraud attack.  But as
we can see by inspection of the collisions produced by the researchers
(who are keeping their methodology secret for now), they don't seem to
have that power.  Instead, they are able to introduce a very carefully
controlled difference between the two blocks, and then cancel it.
Being able to cancel a huge difference between blocks would be a problem
of an entirely different magnitude.
Now, there is this other idea which Zooko alludes to, from Dan Kaminsky,
 which could exploit the power of the new attacks to
do something malicious.  Let us grant that the only ability we have is
that we can create slightly different pairs of blocks that collide.
We can't meaningfully control the contents of these blocks, and they
will differ in only a few bits.  And these blocks have to be inserted
into a program being distributed, which will have two versions that
are *exactly the same* except for the few bits of difference between
the blocks.  This way the two versions will have the same hash, and this
is the power which the current attacks seem to have.
Kaminsky shows that you could still have "good" and "bad" versions of
such a program.  You'd have to write a program which tested a bit in
the colliding blocks, and behaved "good" if the bit was set, and "bad"
if the bit was clear.  When someone reviewed this program, they'd see
the potential bad behavior, but they'd also see that the behavior was
not enabled because the bit that enabled it was not set.  Maybe the
bad behavior could be a back door used during debugging, and there is
some flag bit that turns off the debugging mode.  So the reviewer might
assume that the program was OK despite this somewhat questionable code,
because he builds it and makes sure to sign or validate the hash when
built in the mode when the bad features are turned off.
But what he doesn't know is, Kaminsky has another block of data prepared
which has that flag bit in the opposite state, and which he can substitute
without changing the hash.  That will cause the program to behave in its
"bad" mode, even though the only change was a few bits in this block
of random data.  So this way he can distribute a malicious build and it
has the hash which was approved by the reviewer.
And as Zooko points out, this doesn't have to be the main developer
who is doing this, anyone who is doing some work on creating the final
package might be able to do so.
On the other hand, this attack is pretty blatant once you know it is
possible.  The lesson is that a reviewer should be suspicious of code
whose security properties depend on the detailed contents of blocks
of random-looking data.  One problem with this is that there are some
circumstances where it could be hard to tell.  Zooko links to the example
of a crypto key which could have weak and strong versions.  The strong
version could be approved and then the weak version substituted.
There are also some crypto algorithms that use random-looking blocks of
data which could have weak and strong versions.
So it's not always as easy as it sounds.  But most code will not have
these problems, and for those programs it would be pretty conspicuous
to implement Kaminsky's attacks.  At present, that looks to be the best
someone could do with SHA-1 or even MD5.
Hal Finney
p2p-hackers mailing list
p2p-hackers at zgp.org
Here is a web page listing P2P Conferences:
--- end forwarded text

@_date: 2005-02-17 14:25:36
@_author: Hal Finney 
@_subject: [p2p-hackers] SHA1 broken? 
The problem with the attack scenario where two versions of a program are
created with the same hash, is that from what little we know of the new
attacks, they aren't powerful enough to do this.
All of the collisions they have shown have the property where the two
alternatives start with the same initial value for the hash; they then
have one or two blocks which are very carefully selected, with a few
bits differing between the two blocks; and at the end, they are back
to a common value for the hash.
It is known that their techniques are not sensitive to this initial value.
They actually made a mistake when they published their MD5 collision,
because they had the wrong initial values due to a typo in Schneier's
book.  When people gave them the correct initial values, they were able
to come up with new collisions within a matter of hours.
If you look at their MD5 collision in detail, it was two blocks long.
Each block was almost the same as the other, with just a few bits
different.  They start with the common initial value.  Then they run
the first blocks through.  Amazingly, this has only a small impact on
the intermediate value after this first block.  Only a relatively few
bits are different.
If you or I tried to take two blocks with a few bits different and feed
them to MD5, we would get totally different outputs.  Changing even
one bit will normally change half the output bits.  The fact that they
are able to change several bits and get only a small difference in the
output is the first miracle.
But then they do an even better trick.  They now go on and do the
second pair of blocks.  The initial values for these blocks (which are
the outputs from the previous stage) are close but not quite the same.
And amazingly, these second blocks not only keep things from getting
worse, they manage to heal the differences.  They precisely compensate
for the changes and bring the values back together.  This is the second
miracle and it is even greater.
Now, it would be a big leap from this to being able to take two arbitrary
different initial values and bring them together to a common output.
That is what would be necessary to mount the code fraud attack.  But as
we can see by inspection of the collisions produced by the researchers
(who are keeping their methodology secret for now), they don't seem to
have that power.  Instead, they are able to introduce a very carefully
controlled difference between the two blocks, and then cancel it.
Being able to cancel a huge difference between blocks would be a problem
of an entirely different magnitude.
Now, there is this other idea which Zooko alludes to, from Dan Kaminsky,
 which could exploit the power of the new attacks to
do something malicious.  Let us grant that the only ability we have is
that we can create slightly different pairs of blocks that collide.
We can't meaningfully control the contents of these blocks, and they
will differ in only a few bits.  And these blocks have to be inserted
into a program being distributed, which will have two versions that
are *exactly the same* except for the few bits of difference between
the blocks.  This way the two versions will have the same hash, and this
is the power which the current attacks seem to have.
Kaminsky shows that you could still have "good" and "bad" versions of
such a program.  You'd have to write a program which tested a bit in
the colliding blocks, and behaved "good" if the bit was set, and "bad"
if the bit was clear.  When someone reviewed this program, they'd see
the potential bad behavior, but they'd also see that the behavior was
not enabled because the bit that enabled it was not set.  Maybe the
bad behavior could be a back door used during debugging, and there is
some flag bit that turns off the debugging mode.  So the reviewer might
assume that the program was OK despite this somewhat questionable code,
because he builds it and makes sure to sign or validate the hash when
built in the mode when the bad features are turned off.
But what he doesn't know is, Kaminsky has another block of data prepared
which has that flag bit in the opposite state, and which he can substitute
without changing the hash.  That will cause the program to behave in its
"bad" mode, even though the only change was a few bits in this block
of random data.  So this way he can distribute a malicious build and it
has the hash which was approved by the reviewer.
And as Zooko points out, this doesn't have to be the main developer
who is doing this, anyone who is doing some work on creating the final
package might be able to do so.
On the other hand, this attack is pretty blatant once you know it is
possible.  The lesson is that a reviewer should be suspicious of code
whose security properties depend on the detailed contents of blocks
of random-looking data.  One problem with this is that there are some
circumstances where it could be hard to tell.  Zooko links to the example
of a crypto key which could have weak and strong versions.  The strong
version could be approved and then the weak version substituted.
There are also some crypto algorithms that use random-looking blocks of
data which could have weak and strong versions.
So it's not always as easy as it sounds.  But most code will not have
these problems, and for those programs it would be pretty conspicuous
to implement Kaminsky's attacks.  At present, that looks to be the best
someone could do with SHA-1 or even MD5.
Hal Finney
p2p-hackers mailing list
p2p-hackers at zgp.org
Here is a web page listing P2P Conferences:
Eugen* Leitl leitl
ICBM: 48.07078, 11.61144            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
         [demime 1.01d removed an attachment of type application/pgp-signature]

@_date: 2005-02-23 12:14:04
@_author: Hal Finney 
@_subject: I'll show you mine if you show me, er, mine 
Markus Jakobsson is a really smart guy who's done some cool stuff, so I
think this is probably better than it sounds in the article.  His web
site is  but I don't see any
papers there that sound like what the article describes.  I tried to
reverse engineer the protocol from the article, and the results are below.
But first let me put this into context.
The security property seems to be that you send something to the server,
and it sends you back something that proves that it knows your password.
But neither a passive eavesdropper nor a MITM can learn anything about
your password from observing or influencing the exchange.  The best an
attacker can do is to try to brute force your password by guessing it
repeatedly and trying each guess out at the server.  And this can be
easily prevented by having the server refuse to answer more than a few
bad password attempts.
Note that this is different from simple PK based authentication,
because the secret is human memorizable.  And it's different from,
say, having the server respond with a keyed hash of your passphrase,
because an eavesdropper could then do an offline brute force search.
The key feature is that the only attack is online brute forcing.
There are already a lot of protocols in the literature which do this,
often performing key agreement at the same time.  The original one
and most famous was SPEKE.  There is a long list of such protocols at
  I don't
know what properties this new protocol has that the old ones don't.
Maybe it does have some and I am missing the point.  Or there might be
some patent issues that it is trying to work around.
Anyway, here's my attempt at mimicking the protocol, based on the
description of envelopes and carbon paper.
You have a password, and so does the site you will login to.  (Or,
maybe the site has a salted hash of your password; you could use that
instead.)  You set up a homomorphic encryption system.  This is one where
you can send an encrypted value to someone else, and he can do certain
operations on the encrypted value, like multiplying it by a constant.
In this case I think we only need to encrypt the value 1, and let the
other guy multiply by his constant, which makes it simpler.
I think ElGamal could work: you encrypt 1 as (g^k, y^k), where you'd
make up a key y = g^x on the spot.  You send this to the other guy who
picks a random power j and raises both elements to that power, then
multiplies the 2nd one by c: (g^(k*j), y^(k*j) * c), and sends it back
to you.  This is now a valid ElGamal encryption of c.  But an observer
can't tell what c is.
For a first cut at this protocol, you take each bit of the password (or
salted hash) and create two encryptions of m = 1.  It would look like
E(1)   E(1)   E(1)   E(1)   E(1)  ...
E(1)   E(1)   E(1)   E(1)   E(1)  ...
You send all these to the server.  The server knows your password (or
salted hash) and, for each pair of encrypted values, multiplies the
one corresponding to password bit b_i by some constant c_i.  The other
one of the pair, corresponding to !b_i, it multiplies by a random r_i.
The server sets it up so that the sum of all the c_i is zero.  Then it
sends all of them back to you.  If your passphrase started 01101...
it would be:
E(c_1)   E(r_2)   E(r_3)   E(c_4)   E(r_5)  ...
E(r_1)   E(c_2)   E(c_3)   E(r_4)   E(c_5)  ...
Now, you decrypt just the ones corresponding to the bits b_i and add up
the decrypted plaintexts, giving you sum of c_i.  If the result is zero,
you know the server knew your password (or salted hash).
Actually this is not quite right, because the article says that you are
not supposed to be able to decrypt both ciphertext values in the pair
that corresponds to a password bit.  Otherwise an imposter might be able
to figure out your passphrase by doing one interaction with the server,
then finding an element from each pair such that they all sum to zero.
This is kind of knapsacky and it might not be that hard, I'm not sure.
So I think what you could do is to send a valid ElGamal encryption of
1, and a bogus value which is not an ElGamal encryption of anything.
But the remote party wants to be sure that you can't decrypt them both.
One way to achieve this is to arrange that the first members of each pair,
g^k in the good encryption, multiply to some fixed value F for which the
discrete log is not known.  Maybe it's the hash of "I don't know if this
will work."  You can't know the DL of that hash, so you can't find two
g^k values which multiply to that hash.  That means that if you have a
pair of ElGamal ciphertexts which have this property, only one is a real,
valid ElGamal ciphertext and so only one is decryptable (I think!).  So
you would send, in the example above:
(g^k0, y^k0)    (F/g^k1, junk)  (F/g^k2, junk)   (g^k3, y^k3)   ...
(F/g^k0, junk)  (g^k1, y^k1)    (g^k2, y^k2)     (F/g^k3, junk) ...
When the server did its multiplications as above you'd still get the
correct encryptions of c_i, but the other pair would be junk and you
wouldn't learn the r_i values:
E(c_1)   junk     junk     E(c_4)   junk    ...
junk     E(c_2)   E(c_3)   junk     E(c_5)  ...
Now you can still decrypt it and verify your password.  But for someone
who is impersonating you and doesn't know your password, they're going
to get a mix of c_i and r_i values that won't add up to zero, and that
won't give them any clue about what the real password is, other than
that they guessed wrong.
I'm not 100% sure this will work, that the attacker can't create a bogus
pair (F/g^k, junk) which will allow him to determine what value the server
multiplied by.  At a minimum I see that if junk = F/g^k then it will be
obvious what the constant was, so the server would have to check for that.
This is why it's good to have provable security!
This way of doing things would also be quite inefficient; there are
two ElGamal encryptions going back and forth (typically 2048 bits each)
for every bit of your password.  I'll bet the actual paper has a much
more clever scheme which improves the efficiency and has a nice proof
of security.  I'm looking forward to seeing it.
Hal Finney

@_date: 2005-03-02 10:40:39
@_author: Hal Finney 
@_subject: [FoRK] X.509 certificate collision via MD5 collisions (fwd 
Eugen forwards from FoRK:
The real news of the paper was the announcement that Wang's techniques
will be revealed this May at Eurocrypt.  I'm looking forward to finding
out what the secret is!  Presumably everyone will receive MD5 collision
finding software at around that time.
The cert collision is not a surprise, people anticipated this possibility
shortly after the MD5 collisions were announced.  And notice that Xiaoyun
Wang was an author of this paper; she was of course the lead author
on the original MD5 collision paper and presumably the originator of
the technique for finding MD5 collisions.  Using her technology it is
straightforward to do this kind of thing.  But no one else could have
written this paper at this time.
The only nontrivial part (given the remarkable ability to generate MD5
collisions) was arranging that both keys were valid RSA moduli with
known factors.  The did this by generating random bignums and trying to
factor them.
And keep in mind that her methods find random-ish collisions.  They don't
find matches to existing hashes, and (as far as we know) they don't
find structured collisions as would be necessary to get two certs with
different and plausible-sounding names in them.
these collisions are found is to start with analysis of the structure
of the hash, and decide on an XOR difference between the two inputs.
This implicitly makes certain assumptions about where and when carries
and other nonlinearities will occur in the hash calculation.  Then you
do a search for inputs which match that pattern of carries and for
which the pre-determined XOR difference yields an actual collision.
This doesn't give you much ability to control the content of the two
inputs that you create.

@_date: 2008-11-07 07:40:12
@_author: Hal Finney 
@_subject: Bitcoin P2P e-cash paper 
Bitcoin seems to be a very promising idea. I like the idea of basing
security on the assumption that the CPU power of honest participants
outweighs that of the attacker. It is a very modern notion that exploits
the power of the long tail. When Wikipedia started I never thought it
would work, but it has proven to be a great success for some of the
same reasons.
I also do think that there is potential value in a form of unforgeable
token whose production rate is predictable and can't be influenced
by corrupt parties. This would be more analogous to gold than to fiat
currencies. Nick Szabo wrote many years ago about what he called "bit
gold"[1] and this could be an implementation of that concept. There have
also been proposals for building light-weight anonymous payment  schemes on
top of heavy-weight non-anonymous systems, so Bitcoin could be leveraged
to allow for anonymity even beyond the mechanisms discussed in the  Unfortunately I am having trouble fully understanding the system. The
paper describes key concepts and some data structures, but does not
clearly specify the various rules and verifications that the  in the system would have to follow.
In particular I don't understand exactly what verifications P2P nodes
perform when they receive new blocks from other nodes, and how they
handle transactions that have been broadcast to them. For example, it
is mentioned that if a broadcast transaction does not reach all nodes,
it is OK, as it will get into the block chain before long. How does this
happen - what if the node that creates the "next" block (the first node
to find the hashcash collision) did not hear about the transaction,
and then a few more blocks get added also by nodes that did not hear
about that transaction? Do all the nodes that did hear it keep that
transaction around, hoping to incorporate it into a block once they get
lucky enough to be the one which finds the next collision?
Or for example, what if a node is keeping two or more chains around as
it waits to see which grows fastest, and a block comes in for chain A
which would include a double-spend of a coin that is in chain B? Is that
checked for or not? (This might happen if someone double-spent and two
different sets of nodes heard about the two different transactions with
the same coin.)
This kind of data management, and the rules for handling all the packets
that are flowing around is largely missing from the paper.
I also don't understand exactly how double-spending, or cancelling
transactions, is accomplished by a superior attacker who is able to  more computing power than all the honest participants. I see that he can
create new blocks and add them to create the longest chain, but how can
he erase or add old transactions in the chain? As the attacker sends out
his new blocks, aren't there consistency checks which honest nodes can
perform, to make sure that nothing got erased? More explanation of this
attack would be helpful, in order to judge the gains to an attacker from
this, versus simply using his computing power to mint new coins  As far as the spending transactions, what checks does the recipient of a
coin have to perform? Does she need to go back through the coin's entire
history of transfers, and make sure that every transaction on the list  indeed linked into the "timestamp" block chain? Or can she just do the
latest one? Do the timestamp nodes check transactions, making sure that
the previous transaction on a coin is in the chain, thereby enforcing
the rule that all transactions in the chain represent valid coins?
Sorry about all the questions, but as I said this does seem to be a
very promising and original idea, and I am looking forward to seeing
how the concept is further developed. It would be helpful to see a more
process oriented description of the idea, with concrete details of the
data structures for the various objects (coins, blocks, transactions),
the data which is included in messages, and algorithmic descriptions
of the procedures for handling the various events which would occur in
this system. You mentioned that you are working on an implementation,
but I think a more formal, text description of the system would be a
helpful next step.
Hal Finney
[1]

@_date: 2009-08-11 11:47:27
@_author: Hal Finney 
@_subject: Ultimate limits to computation 
[Note subject line change]
Things may not be quite as favorable as this. Here is a posting I made
to cypherpunks in 2004:

@_date: 2009-01-10 10:22:01
@_author: Hal Finney 
@_subject: Bitcoin v0.1 released 
Congratulations to Satoshi on this first alpha release.  I am looking
forward to trying it out.
It's interesting that the system can be configured to only allow a
certain maximum number of coins ever to be generated. I guess the
idea is that the amount of work needed to generate a new coin will
become more difficult as time goes on.
One immediate problem with any new currency is how to value it. Even
ignoring the practical problem that virtually no one will accept it
at first, there is still a difficulty in coming up with a reasonable
argument in favor of a particular non-zero value for the coins.
As an amusing thought experiment, imagine that Bitcoin is successful and
becomes the dominant payment system in use throughout the world.  Then  total value of the currency should be equal to the total value of all
the wealth in the world. Current estimates of total worldwide household
wealth that I have found range from $100 trillion to $300 trillion. With
20 million coins, that gives each coin a value of about $10 million.
So the possibility of generating coins today with a few cents of compute
time may be quite a good bet, with a payoff of something like 100  to 1! Even if the odds of Bitcoin succeeding to this degree are slim,
are they really 100 million to one against? Something to think about...

@_date: 2009-01-24 12:48:03
@_author: Hal Finney 
@_subject: Bitcoin v0.1 released 
Certainly a valid point, and one which has been widely discussed in
the debates over the years about electronic cash. Bitcoin has a couple
of things going for it: one is that it is distributed, with no single
point of failure, no "mint", no company with officers that can be
subpoenaed and arrested and shut down. It is more like a P2P network,
and as we have seen, despite degrees of at least governmental distaste,
those are still around.
Bitcoin could also conceivably operate in a less anonymous mode, with
transfers being linked to individuals, rather than single-use keys. It
would still be useful to have a large scale, decentralized electronic
payment system.
It also might be possible to refactor and restructure Bitcoin to  out the key new idea, a decentralized, global, irreversible transaction
database. Such a functionality might be useful for other purposes. Once
it exists, using it to record monetary transfers would be a sort of side
effect and might be harder to shut down.
It's important to understand that the proof-of-work (POW) aspect of
Bitcoin is primarily oriented around ensuring the soundness of the
historical transaction database. Each Bitcoin data block records a set
of transactions, and includes a hash collision. Subsequent data blocks
have their own transactions, their own collisions, and also chain to
all earlier hashes.  The result is that once a block is "buried" under
enough new blocks, it is essentially certain (given the threat model,
namely that attackers cannot muster more than X% of the compute power
of legitimate node operators) that old transactions can't be reversed.
Creating new coins is indeed currently also being done by POW, but I
think that is seen as a temporary expedient, and in fact the current
software phases that out over several years. Hence worries about botnets
being able to manufacture large quantities of POW tokens are only a
temporary concern, in the context of Bitcoin.
There have been a number of discussions in the past about POW tokens as
anti spam measures, given the botnet threat. References are available  "Proof-of-work system" on Wikipedia. Analyses have yielded mixed  depending on the assumptions and system design.
If POW tokens do become useful, and especially if they become money,
machines will no longer sit idle. Users will expect their computers to
be earning them money (assuming the reward is greater than the cost to
operate). A computer whose earnings are being stolen by a botnet will
be more noticeable to its owner than is the case today, hence we might
expect that in that world, users will work harder to maintain their
computers and clean them of botnet infestations.
Countermeasures by botnet operators would include moderating their take,
perhaps only stealing 10% of the productive capacity of invaded  so that their owners would be unlikely to notice. This kind of thinking
quickly degenerates into unreliable speculation, but it points out the
difficulties of analyzing the full ramifications of a world where POW
tokens are valuble.
Hal Finney

@_date: 2009-06-16 12:31:36
@_author: Hal Finney 
@_subject: Popular explanation of fully homomorphic encryption wanted 
Udhay Shankar N quotes wikipedia:
A URL for this paper is
 but you will have
to be an ACM member to download it. I was able to get a copy this  and quickly skimmed it.
This is IMO one of the most remarkable crypto papers ever. Not only
does it solve one of the oldest open problems in cryptography, the
construction of a fully homomorphic encryption system, it does so by
means of a self-embedding technique reminiscent of Godel's theorem.
Craig Gentry starts off by inventing a limited homomorphic encryption
system based on lattice encryption. For full homomorphism you want to do
both add and multiply - or expressed on bits, XOR and AND.  Think of  operation as a circuit made up of XOR and AND gates, then the limiting
factor in previous work has been the number of ANDs.  While many schemes
have been found that do just XORs, and at least one that could do a very
limited number of ANDs, the new scheme allows you to go deeper.
In lattice encryption, there is a multi-dimensional lattice of points
that have a hidden structure. Encryption puts you "near" a point on
the lattice, and decryption involves finding that point. But without
knowing the hidden structure, attackers can't tell which one is closest.
In the new homomorphic lattice encryption, AND operations cause the
error term to increase. After too many of them, too deep a circuit,
the error term grows up to roughly half the distance between lattice
points, and decryption is no longer possible. So you have a limited
depth homomorphic encryption system.
By itself this is a substantial advance. But now for the amazing
Godelian trick. The error term has grown and any more operations will
make decryption impossible. So Craig Gentry proposes to allow the server
(which is working on data encrypted under a key controlled by the  to decrypt the data - *homomorphically*. If the data is encrypted by
client key pk1, the client has also supplied the server a second key  and also a version of the pk1 *secret key* encrypted under pk2. Since
pk2 is homomorphic, the server can compute a circuit using the encrypted
secret pk1 key just like it can compute any other circuit on encrypted
data. The result is that the server ends up with an encryption of the
original ciphertext under pk2 instead of under pk1, and because lattice
decryption in effect performs error correction, the error term is  and we are ready for more.
The key idea here is that the homomorphic encryption system has to
allow enough homomorphic depth that *its own decryption algorithm*
can be expressed as a circuit that "fits" within what can be handled
homomorphically. This is quite difficult and most of the paper is taken
up with constructing such a cryptosystem and proving its properties.
The resulting scheme is apparently not practical (at one point he
mentions that the secret key bits have to be expressed in *unary*) but
it is still amazing that it is even possible. Again I have to go back
to Godel's and Turing's work to think of a comparable example exploiting
the power of self-embedding.
In its most basic form, then, the client must supply a set of public  pk1, pk2, ... with each key's private part encrypted under the next key;
the number of such keys would be proportional to the depth of the  to be evaluated. However the paper then points out that given reasonable
assumptions, you can dispense with the whole set and make it a loop,
even a loop of one: that is, you encrypt pk1's private key under pk1,
and stick with pk1 through the whole encryption, including the magical
homomorphic decryption circuit evaluation. In this form it is the pure,
fully homomorphic encryption system which has been so long sought.
Hal Finney
