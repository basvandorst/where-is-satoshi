
@_date: 2008-12-16 15:08:10
@_author: Zooko O'Whielacronx 
@_subject: [p2p-hackers] announcing tiddly_on_tahoe v1.0 
[This announcement is being sent to [1]tiddlywiki at googlegroups.com,
   [2]cap-talk at mail.eros-os.org, [3]p2p-hackers at lists.zooko.com, and
   [4]tahoe-dev at allmydata.com.  Please adjust follow-ups appropriately.]
   Announcing the 1.0 release of tiddly_on_tahoe!
   This is the combination of TiddlyWiki, which is a JavaScript wiki that
   runs in a web browser, with Tahoe-LAFS, which is a decentralized
   secure storage grid.
   The result of combining these two things is a "decentralized web
   app".  It looks and feels just like a web app, but it is decentralized
   like a p2p app.
   To see what one looks like and to make one for yourself, please follow
   this link -- read-only access to a copy of the tiddly_on_tahoe starter
   page:
   [5]
   au74tjwguu:h7bdxvjtvidlkcdbld3j2d5sbgyzsbqs7wdnu6yznqrejzssc5za/wiki.h
   tml
   To see one with real content in it, follow this link -- read-only
   access to my daily hacking journal:
   [6]
   3nbej53qoi:yhbnnuxl4o2hr4sxuocoi735t6lcosdin72axkrcboulfslwbfwq/wiki.h
   tml
   To edit one of these and save your changes on the Tahoe storage grid,
   follow this link -- writable access to a copy of the tiddly_on_tahoe
   starter page:
   [7]
   ey573b35paa%3Azshb54dvy4jmpdxjlptn6ttm4m7awi7xf7hqtwmvjriy6ryeb7ya/wik
   i.html
   Then change something, then click "Save Changes".
   Everyone has write access to that last one, so it may have changed by
   the time you look at it.
   For readers of [8]tiddlywiki at googlegroups.com:  Tahoe-lafs is a
   secure, decentralized storage grid.  All files are strongly encrypted
   and then split up into 10 pieces in such a way that any 3 of those
   pieces are sufficient to serve the file.  Then each of the 10 pieces
   is stored on a different server.  For more information:
   [9] .
   For readers of [10]cap-talk at mail.eros-os.org:  Please let me know what
   you think about the user interface here which is offering
   crypto-capabilities embedded into URLs.  This is an ongoing experiment
   in order to determine if crypto-caps-in-URLs work well for actual
   human use.  Please notice the "access control explanation text" at the
   top of each page.  See the appended JavaScript fragment which is the
   implementation of that explanation.
   For readers of [11]tahoe-dev at allmydata.org:  All of the URLs in this
   note point to the Tahoe Test Grid, but you can of course do the same
   thing on your own Tahoe grid, and customers of [12]allmydata.com are
   of course welcome to host their TiddlyWikis on the [13]allmydata.com
   commercial grid.
   For readers of [14]p2p-hackers at lists.zooko.com:  Isn't this cool?
   Decentralized web apps!
   Thanks to FND and Eric Shulman -- Tiddly Hackers -- for teaching me
   JavaScript and Tiddly.  Thanks to Douglas Crockford for jslint.
   Regards,
   Zooko
   P.S.  A bit of JavaScript to produce the access control explanation
   text:
   if (document.location.toString().match(new RegExp(HTTPLEAD +
   TAHOE_IMMUTABLE_CAP_RE_STR))) {
      wikify("This is an immutable view of this page.  Using this URL
   will always show this version of this page, even if a newer version
   has been uploaded.", place);
   } else if (document.location.toString().match(new RegExp(HTTPLEAD +
   TAHOE_NONWRITABLE_THING_CAP_RE_STR))) {
     wikify("This is a read-only view of this page.  If you share this
   URL with someone, they will be able to see the most recent version of
   this page, but not to change the page.", place);
   } else if (document.location.toString().match(new RegExp(HTTPLEAD +
   TAHOE_WRITABLE_THING_CAP_RE_STR))) {
     getReadonlyURLToThisPage(function (readonlyCap) {
       wikify("This is a writable view of this page.  If you share this
   URL with someone, they will be able to change this page.  Click here
   for a [[read-only view of this page|" + readonlyCap + "]].", place);
     });
   } else {
     wikify("You are not accessing this page through the Tahoe-LAFS
   secure, distributed filesystem.", place);
   }
   1. mailto:tiddlywiki at googlegroups.com
   2. mailto:cap-talk at mail.eros-os.org
   3. mailto:p2p-hackers at lists.zooko.com
   4. mailto:tahoe-dev at allmydata.com
   5.    6.    7.    8. mailto:tiddlywiki at googlegroups.com
   9.   10. mailto:cap-talk at mail.eros-os.org
  11. mailto:tahoe-dev at allmydata.org
  12.   13.   14. mailto:p2p-hackers at lists.zooko.com
p2p-hackers mailing list
p2p-hackers at lists.zooko.com

@_date: 2009-04-22 10:56:24
@_author: Zooko O'Whielacronx 
@_subject: [tahoe-dev] NEWSFLASH -- Coder Goes Crazy! Laptop Versus Axe! Film 
Dear people of p2p-hackers and tahoe-dev:
I presented Tahoe-LAFS at CodeCon last weekend.  CodeCon's prime
directive is that every presentation has to have a live demo of
working code, and that the presenter has to be an author of that code.
For my demo, I leaned an axe against the speaker's podium, strapped
safety goggles around my neck, and then I showed three laptops on
stage, each running a Tahoe node, and then uploaded a movie file to
the Tahoe grid made up of those three nodes.  (This means the file
gets automatically encrypted, digitally signed, and erasure-coded.)
Then I explained that after uploading your movie to the Tahoe grid,
you might turn off your Tahoe node and go away.  And while you are
gone, something BAD might happen...
I've also embedded this video into my blog:
(My blog is also hosted on Tahoe, the Axe-Tolerant Storage System.)
Thanks to Jake Appelbaum for the video.
Tahoe, the Least-Authority Filesystem -- store your data: $10/month -- I am available for work -- tahoe-dev mailing list
tahoe-dev at allmydata.org

@_date: 2009-01-26 06:41:17
@_author: Zooko O'Whielacronx 
@_subject: Proof of Work -> atmospheric carbon 
I was one of those people, a decade and a half ago, on the cypherpunks
mailing list.  In fact, as I recall I once discussed with John Gilmore
after a Bay Area Cypherpunks Physical Meeting whether he would pay me to
implement some sort of solution to spam, but we didn't agree on a
Hey, the future is long.  (We hope.)
Coincidentally, I just blogged today about how we are much closer to
this now than we were then, even though none of the smart people that
you were probably thinking of are involved in the new deployments:
WoW-gold, for example, appears to have at least millions of transactions
a day.  Does anyone have more detail about the scale and scope of these
Thanks!  I'll read this.

@_date: 2010-02-27 23:33:01
@_author: Zooko O'Whielacronx 
@_subject: [tahoe-announce] ANNOUNCING Tahoe, the Least-Authority File System, 
ANNOUNCING Tahoe, the Least-Authority File System, v1.6.1
The Tahoe-LAFS team is pleased to announce the immediate
availability of version 1.6.1 of Tahoe-LAFS, an extremely
reliable distributed data store.
Tahoe-LAFS is the first cloud storage system which offers
"provider-independent security" -- meaning that not even your
cloud service provider can read or alter your data without
your consent.  Here is the one-page explanation of its unique
security and fault-tolerance properties:
Tahoe-LAFS v1.6.1 is the successor to v1.6.0, which was
released February 2, 2010 [1]. This is a bugfix release which
fixes a few small regressions in v1.6.0.
The v1.6 release includes major performance improvements,
usability improvements, and one major new feature:
deep-immutable directories (cryptographically unalterable
permanent snapshots). See the NEWS file [2] for details.
WHAT IS IT GOOD FOR?
With Tahoe-LAFS, you spread your filesystem across multiple
servers, and even if some of the servers fail or are taken over
by an attacker, the entire filesystem continues to work
correctly, and continues to preserve your privacy and
security. You can easily and securely share chosen files and
directories with others.
In addition to the core storage system itself, volunteers have
developed related projects to integrate it with other
tools. These include frontends for Windows, Macintosh,
JavaScript, and iPhone, and plugins for Hadoop, bzr,
duplicity, TiddlyWiki, and more. As of v1.6, contributors have
added an Android frontend and a working read-only FUSE
frontend. See the Related Projects page on the wiki [3].
We believe that strong encryption, Free/Open Source Software,
erasure coding, and careful engineering practices make
Tahoe-LAFS safer than RAID, removable drive, tape, on-line
backup or other Cloud storage systems.
This software is developed under test-driven development, and
there are no known bugs or security flaws which would
compromise confidentiality or data integrity under normal
use. (For all currently known issues please see the
known_issues.txt file [4].)
This release is fully compatible with the version 1 series of
Tahoe-LAFS. Clients from this release can write files and
directories in the format used by clients of all versions back
to v1.0 (which was released March 25, 2008). Clients from this
release can read files and directories produced by clients of
all versions since v1.0. Servers from this release can serve
clients of all versions back to v1.0 and clients from this
release can use servers of all versions back to v1.0.
This is the eigth release in the version 1 series. The version
1 series of Tahoe-LAFS will be actively supported and
maintained for the forseeable future, and future versions of
Tahoe-LAFS will retain the ability to read and write files
compatible with Tahoe-LAFS v1.
In addition, version 1.6 improves forward-compatibility with
planned future directory formats, allowing updates to a
directory containing both current and future links, without
loss of information.
You may use this package under the GNU General Public License,
version 2 or, at your option, any later version. See the file
"COPYING.GPL" [5] for the terms of the GNU General Public
License, version 2.
You may use this package under the Transitive Grace Period
Public Licence, version 1 or, at your option, any later
version. (The Transitive Grace Period Public Licence has
requirements similar to the GPL except that it allows you to
wait for up to twelve months after you redistribute a derived
work before releasing the source code of your derived work.)
See the file "COPYING.TGPPL.html" [6] for the terms of the
Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either
licence, at your option.)
Tahoe-LAFS works on Linux, Mac OS X, Windows, Cygwin, Solaris,
*BSD, and probably most other systems. Start with
"docs/install.html" [7].
HACKING AND COMMUNITY
Please join us on the mailing list [8]. Patches are gratefully
accepted -- the RoadMap page [9] shows the next improvements
that we plan to make and CREDITS [10] lists the names of people
who've contributed to the project. The Dev page [11] contains
resources for hackers.
Tahoe-LAFS was originally developed thanks to the sponsorship
of Allmydata, Inc. [12], a provider of commercial backup
services. Allmydata founded the Tahoe-LAFS project and
contributed hardware, software, ideas, bug reports,
suggestions, demands, and they employed several Tahoe-LAFS
hackers and instructed them to spend part of their work time on
this Free Software project. Also they awarded customized
t-shirts to hackers who found security flaws in Tahoe-LAFS (see
the Hack Tahoe-LAFS Hall Of Fame [13]). After discontinuing
funding of Tahoe-LAFS R&D in early 2009, Allmydata, Inc. has
continued to provide servers, co-lo space, bandwidth, and small
personal gifts as tokens of appreciation. (Also they continue
to provide bug reports.) Thank you to Allmydata, Inc. for their
generous and public-spirited support.
This is the fourth release of Tahoe-LAFS to be created solely
as a labor of love by volunteers. Thank you very much to the
dedicated team of "hackers in the public interest" who make
Tahoe-LAFS possible.
Zooko Wilcox-O'Hearn
on behalf of the Tahoe-LAFS team
February 27, 2010
Boulder, Colorado, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] tahoe-announce mailing list
tahoe-announce at allmydata.org

@_date: 2010-06-09 09:27:45
@_author: Zooko O'Whielacronx 
@_subject: [tahoe-announce] ANNOUNCING Tahoe-LAFS v1.7N2! Please test! 
The Tahoe-LAFS volunteer hackers have done a superb job for the last
few weeks, iteratively testing and refining the major new features of
Tahoe-LAFS v1.7.
The current version passes our comprehensive test suite on many
platforms (see the Buildbot [1] especially the "Supported Platforms"
This is officially Tahoe-LAFS v1.7.0N2!
The plan is that this version will become v1.7.0 final except for
improving the documentation and packaging, and fixing any critical
bugs that turn up.
Tahoe-LAFS v1.7 is going to be a major new release, adding important
features and continuing our strong tradition of reliability and
WHAT'S NEW
There are three major new features (not counting various small
bugfixes and improvements): SFTP support, support for non-ASCII
character encodings, and Servers of Happiness.
* SFTP support
Your Tahoe-LAFS gateway now acts like a full-fledged SFTP server. It
has been tested with sshfs to provide a virtual filesystem in Linux.
Many users have asked for this feature. We hope that it serves them
well! See the FTP-and-SFTP.txt document [2] to get started.
* support for non-ASCII character encodings
Tahoe-LAFS now correctly handles filenames containing non-ASCII
characters on all supported platforms:
 - when reading files in from the local filesystem (such as when you
run "tahoe backup" to back up your local files to a Tahoe-LAFS grid);
 - when writing files out to the local filesystem (such as when you
run "tahoe cp -r" to recursively copy files out of a Tahoe-LAFS grid);
 - when displaying filenames to the terminal (such as when you run
"tahoe ls"), subject to limitations of the terminal and locale;
 - when parsing command-line arguments, except on Windows (to be fixed
on Windows in a future release)
* Servers of Happiness
Tahoe-LAFS now measures during immutable file upload to see how well
distributed it is across multiple servers. It aborts the upload if the
pieces of the file are not sufficiently well-distributed.
This behavior is controlled by a configuration parameter called
"servers of happiness". With the default settings for its erasure
coding, Tahoe-LAFS generates 10 shares for each file, such that any 3
of those shares are sufficient to recover the file. The default value
of "servers of happiness" is 7, which means that Tahoe-LAFS will
guarantee that there are at least 7 servers holding
some of the shares, such that any 3 of those servers can completely
recover your file.
The new upload code also distributes the shares better than the
previous version in some cases and takes better advantage of
pre-existing shares (when a file has already been previously
uploaded). See the architecture.txt document [3] for details.
HOW TO GET STARTED
Follow the instructions in the quickstart.html document [4].
Do not be too disappointed if you discover the following performance issue.
While this release makes it possible to use Tahoe-LAFS as a mostly
POSIX-compliant filesystem (thanks to FUSE and sshfs), it will have
very bad performance for some cases which have good performance on
your traditional local filesystem. In particular it is bad at making
small changes to large files (it actually stores the new file contents
every time you write to the file and re-uploads the entire file every
time you close it after having written to it). On the other hand it
has some nice scalability and load-balancing characteristics compared
to traditional POSIX filesystemsbyou will be able to easily add tens
or hundreds of computers to your distributed, shared Tahoe-LAFS
filesystem and it will take advantage of them in a nice distributed
pattern without going noticeably slower than if you had a single
Tahoe-LAFS server.
So, you should not assume that the POSIX emulation of Tahoe-LAFS v1.7
will perform sufficiently well at a particular use case or load
pattern until you've tried it, but if you do try it and it does
perform acceptably well then you can feel confident that it will
continue to perform that well as you scale out your filesystem.
Improving the performance in some dimensions is one of the goals of
the Google Summer of Code Project which will result in Tahoe-LAFS v1.8
this Fall (northern hemisphere).
This release continues the tradition of full backward-compatibility.
Use it without fear.
We think Tahoe-LAFS is a really cool hack with great potential. That's
why we spend our time on it as a labor of love. We hope you find good
uses for it.
Zooko, release manager of v1.7
[1] [2] [3] [4] tahoe-announce mailing list
tahoe-announce at allmydata.org

@_date: 2010-06-16 21:06:28
@_author: Zooko Wilcox-O'Hearn 
@_subject: [p2p-hackers] Alpha testers needed 
Wow -- music sharing network with integrated Chaumian ecash (the  "lucre" implementation thereof). I don't know what to think. Are you  familiar with the history of Mojo Nation?
p2p-hackers mailing list
p2p-hackers at lists.zooko.com

@_date: 2010-06-19 00:18:59
@_author: Zooko O'Whielacronx 
@_subject: [tahoe-announce] ANNOUNCING Tahoe-LAFS v1.7.0 
Dear people of tahoe-dev and tahoe-announce mailing lists:
I am *very* pleased to announce v1.7.0! This is an excellent release,
of highest quality, with improvements contributed by a band of
"hackers in the public interest" from all over the world.
This release carries on our tradition of compatibility and reliability
so that you can upgrade to v1.7 without hesitation.
Below is the official release announcement. Spread the word!
Zooko, Release Manager
ANNOUNCING Tahoe, the Least-Authority File System, v1.7.0
The Tahoe-LAFS team is pleased to announce the immediate
availability of version 1.7.0 of Tahoe-LAFS, an extremely
reliable distributed storage system.
Tahoe-LAFS is the first distributed storage system which offers
"provider-independent security"bmeaning that not even the
operator of your storage server can read or alter your data
without your consent. Here is the one-page explanation of its
unique security and fault-tolerance properties:
Tahoe-LAFS v1.7.0 is the successor to v1.6.1, which was released
February 27, 2010 [1].
v1.7.0 is a major new release with new features and bugfixes. It
adds a fully functional SFTP interface, support for non-ASCII character
encodings, and a new upload algorithm which guarantees that each file
is spread over multiple servers for fault-tolerance. See the NEWS file
[2] for details.
WHAT IS IT GOOD FOR?
With Tahoe-LAFS, you distribute your filesystem across multiple
servers, and even if some of the servers are compromised by
by an attacker, the entire filesystem continues to work
correctly, and continues to preserve your privacy and
security. You can easily share specific files and directories
with other people.
In addition to the core storage system itself, volunteers have
built other projects on top of Tahoe-LAFS and have integrated
Tahoe-LAFS with existing systems.
These include frontends for Windows, Macintosh, JavaScript,
iPhone, and Android, and plugins for Hadoop, bzr, mercurial,
duplicity, TiddlyWiki, and more. See the Related Projects page
on the wiki [3].
We believe that strong cryptography, Free and Open Source
Software, erasure coding, and principled engineering practices
make Tahoe-LAFS safer than RAID, removable drive, tape,
on-line backup or "cloud storage" systems.
This software is developed under test-driven development, and
there are no known bugs or security flaws which would
compromise confidentiality or data integrity under recommended
use. (For all currently known issues please see the
known_issues.txt file [4].)
This release is fully compatible with the version 1 series of
Tahoe-LAFS. Clients from this release can write files and
directories in the format used by clients of all versions back
to v1.0 (which was released March 25, 2008). Clients from this
release can read files and directories produced by clients of
all versions since v1.0. Servers from this release can serve
clients of all versions back to v1.0 and clients from this
release can use servers of all versions back to v1.0.
This is the ninth release in the version 1 series. This series
of Tahoe-LAFS will be actively supported and maintained for
the forseeable future, and future versions of Tahoe-LAFS will
retain the ability to read and write files compatible with
Tahoe-LAFS v1.
You may use this package under the GNU General Public License,
version 2 or, at your option, any later version. See the file
"COPYING.GPL" [5] for the terms of the GNU General Public
License, version 2.
You may use this package under the Transitive Grace Period
Public Licence, version 1 or, at your option, any later
version. (The Transitive Grace Period Public Licence has
requirements similar to the GPL except that it allows you to
wait for up to twelve months after you redistribute a derived
work before releasing the source code of your derived work.)
See the file "COPYING.TGPPL.html" [6] for the terms of the
Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either
licence, at your option.)
Tahoe-LAFS works on Linux, Mac OS X, Windows, Cygwin, Solaris,
*BSD, and probably most other systems. Start with
"docs/quickstart.html" [7].
HACKING AND COMMUNITY
Please join us on the mailing list [8]. Patches are gratefully
accepted -- the RoadMap page [9] shows the next improvements
that we plan to make and CREDITS [10] lists the names of people
who've contributed to the project. The Dev page [11] contains
resources for hackers.
Tahoe-LAFS was originally developed by Allmydata, Inc., a
provider of commercial backup services. After discontinuing
funding of Tahoe-LAFS R&D in early 2009, they have continued
to provide servers, bandwidth, small personal gifts as tokens
of appreciation, and bug reports. Thank you to Allmydata,
Inc. for their generous and public-spirited support.
Google, Inc. is sponsoring Tahoe-LAFS development as part of
the Google Summer of Code 2010. Google suggested that we
should apply for the Summer of Code program, and when we did
they generously awarded four sponsorships to students from
around the world to hack on Tahoe-LAFS this summer. Thank you
to Google, Inc. for their generous and public-spirited
HACK TAHOE-LAFS!
If you can find a security flaw in Tahoe-LAFS which is serious
enough that feel compelled to warn our users and issue a fix,
then we will award you with a customized t-shirts with your
exploit printed on it and add you to the "Hack Tahoe-LAFS Hall
Of Fame" [12].
This is the fifth release of Tahoe-LAFS to be created solely
as a labor of love by volunteers. Thank you very much to the
team of "hackers in the public interest" who make Tahoe-LAFS
possible. In this release we especially owe thanks to
David-Sarah Hopwood, who has dedicated many late nights to the
project and displayed superb software engineering skills.
Zooko Wilcox-O'Hearn
on behalf of the Tahoe-LAFS team
June 18, 2010
Boulder, Colorado, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] tahoe-announce mailing list
tahoe-announce at allmydata.org

@_date: 2012-12-21 11:28:01
@_author: Zooko O'Whielacronx 
@_subject: [cryptography] introducing BLAKE2 b an alternative to SHA-3, SHA-2 and MD5 
SHA-3 (Keccak) is a fine alternative to SHA-2, has a substantially
different design from the SHA-2 family, and has excellent performance
in hardware.
However, many use cases need an alternative to MD5 b something with
better security properties than MD5 but with high performance in
software. To that end, we've defined BLAKE2, an optimized version of
SHA-3 finalist BLAKE that is faster than MD5 on Intel 64-bit CPUs.
Target applications include cloud storage (my current field), revision
control tools, software distribution, host-based intrusion detection,
and digital forensics b areas where MD5 and SHA1 currently dominate.
We do not think that this superior software performance comes at a
cost of reduced security. We argue that much of the extensive security
analysis performed on BLAKE during the SHA-3 process applies to BLAKE2
and shows no cause for concern about BLAKE2's security. Please see the
blake2.pdf white paper for the details of that argument.
In addition, I'll make an argument here that we did not put into the
white paper:
A guiding factor in NIST's choice of Keccak over BLAKE for SHA-3 was
that they wanted SHA-3 to be substantially different from SHA-2 so
that it could serve as a fallback in case a breakthrough suddenly
revealed SHA-2 to be vulnerable. This was NIST's reason for choosing
Keccak over BLAKE even though by their own estimation BLAKE's security
margin was comparable to Keccak's and the depth of cryptanalysis that
had been applied to BLAKE was greater than that applied to Keccak.
That is a good strategy for choosing an algorithm to serve as an
emergency fallback, in case SHA-2 suddenly breaks. On the other hand
if SHA-2 has remains unbroken, and you are considering the security of
BLAKE2, then the fact that it is a traditional Add-Rotate-XOR design
like SHA-2 should give increased confidence. When the SHA-3 project
began, there was concern among many cryptographers that a breakthrough
might appear at any moment and reveal SHA-2 to be vulnerable. Since
that hasn't happened after years of study, this concern has faded, and
SHA-2 appears for now to have withstood the test.
I think a similar argument could be made for the way that BLAKE2
re-uses the ChaCha/Salsa20 stream cipher, which has not been found to
have any serious vulnerability.
In addition to the superior software performance of the basic
single-threaded, linear mode, BLAKE2 includes variants optimized for
32-bit architectures, for SIMD/multicore processors, for Merkle-Tree
applications, and for message integrity checking.
I'm particularly keen on the SIMD/multicore variant, a parallelized
mode named "BLAKE2*p", because almost all modern CPUs b even a lot of
the cheap and power-efficient 32-bit ARM chips b come with efficient
SIMD features. It looks like it will be possible to have 4-way or
8-way parallelized BLAKE2*p which are many *times* as efficient as
MD5, on both short files and long files. Once we've finished porting,
measuring, and experimenting with the different modes of BLAKE on
different machines, we intend to write a "b2sum" command-line tool,
which we hope will eventually replace "md5sum" in the unix user's
(Thanks to the performance engineering of J.P.Aumasson and Samuel Neves.)
cryptography mailing list
cryptography at randombit.net

@_date: 2012-07-03 12:17:15
@_author: Zooko O'Whielacronx 
@_subject: [tahoe-dev] switching from introducers to gossip? 
... snipping out a lot of useful, clearly written details about the
new introduction and accounting mechanisms ...
This is not true of the grid I'm most familiar with: volunteergrid2.
In that grid almost every node is either a client or a server --
almost no nodes act as both. (I think. This is just judging from
reading the volunteergrid2-l mailing list.)
Maybe we need two different names, one for the "p2p style" friendnet
that you describe in your letter (partially quoted below) and the
other for the "sysadmins offering one another access to their servers"
friendnet, such as volunteergrid2.
I don't understand enough to have an opinion on that specific
question, but in general I think there is a growing tension between
"p2p style" and "client/server style", and the above smells like
baking "p2p style" into the introduction protocol.
I think that's great! I love the idea! I hope you keep working on it,
and I will endeavour to help. If we succeed, it will be the
long-awaited reincarnation of the Mojo Nation dream.
But, it is rather different in deployment/management from what our
current users do with our current software. Maybe it won't work out.
It requires engineering effort to implement and maintain, makes the
behavior of the software harder to predict, and introduces more
complex failure modes.
If possible, I would like to support people continuing to use
Tahoe-LAFS as service administered by diligent sysadmins even while
extending it to be deployable by inattentive end users as you've
I think not too far down this path there might come a time to split
Tahoe-LAFS into separate packages targeted at different deployment
scenarios. Note that the i2p folks appear to have already forked it
for this reason -- in order to maintain different deployment features!
Also note that you, Brian, have published some experimental
forks/variants focused on different deployment patterns.
If you want "user friendly p2p software", then you probably want:
b" Which services? Each node operates, by default, multiple services --
storage server, storage client == web gateway, introducer/gossiper,
and in the future other services like relay server (to help get around
incomplete connectivity of the underlying network -- b" Which IP addresses? Nodes automatically detect their own IP
addresses, such as by inspecting the output of "/sbin/ifconfig" or
"route.exe", or opening a TCP connection to some helpful STUNT/ICE
server and asking that server what IP address your packets appear to
be coming from (
b" Which connections? Nodes advertise multiple IP addresses / DNS names
(possibly including those auto-discovered as above, plus any that were
manually entered by the user ( plus 127.0.0.1 or any
globally-non-routeable IP addresses revealed by ifconfig, and possibly
in the future including indirection through a relay server), peers
attempt to connect to nodes on all advertised IP addresses / DNS names
in parallel, then use whichever connections succeeded.
b" How to handle NAT/firewall/inconveniently-behaving-router? Nodes
utilize the latest and greatest Romulan packet technology, such as
UPnP ( "NAT hole punching" techniques ( or even B5TP (
or relay service ( to breeze through such impediments as though
they weren't even there.
b" Reverse connections? If a TCP connection is established from node A
to node B, then B can use that in the "reverse direction" to make
requests of A, just as well as A can use it to make requests of B.
This means that if A is behind a firewall which allows outgoing but
not incoming connections to be established, and A established an
outgoing connection to B, then B can use A as a server, but C, which
for some reason didn't get a connection from A, cannot use A as a
server. (
If you want "sysadmin-friendly software" then you probably want the
opposite of all these features!
b" Which services? Each node operates, by default, only the services
that the operator manually configured it to run. Even better you can
install the software sufficient to run a specific kind of node, e.g. a
storage server, without installing the software that would let it run
other servers, such as introducers or storage clients (
b" Which IP addresses? Nodes do not automatically detect their own IP
addresses, but instead use only the IP address that their sysadmin
manually told them to use. This is especially important for tor and
i2p people where any auto-discovered IP address threatens the user's
safety (
b" Which connections? You try to establish the prescribed TCP
connection(s) to your server. If that fails, you log/announce failure.
In the future you might even be able to configure it to run
exclusively over HTTP(S) and then pass all of its connections through
your HTTP proxies and Web Services tools ( (Although sysadmins may actually like the "try to connect to multiple
IP/DNS addresses at once" feature, if it is sufficiently
understandable and controllable to them. It would ease some headaches
provided by the Amazon Web Services EC2 TCP/DNS infrastructure, for
b" How to handle NAT/firewall/inconveniently-behaving-router? If you
can't establish a TCP connection to your prescribed target, then
obviously you should not talk to it. Either some wise sysadmin doesn't
want you to (firewall) or some stupid sysadmin has screwed up the
network config and needs to fix it. In either case you should log
failure and give up immediately.
b" Reverse connections? Clients connect to servers. Servers do not
connect to clients, clients do not connect to other clients, and
servers do not connect to other servers ( To violate this
principle means you will receive a visit from your keen-eyed sysadmin
who will want to know what the hell you are doing B9.
Don't get me wrong -- I think the p2p style, which foolscap already
implements part of -- is sweet. I'd like to improve it, in the
interests of making Tahoe-LAFS deployment more automatic for
end-users. However, we should probably pay attention to the fact that
many of our current users do not use those features, and some of them
are actively requesting the ability to turn off those features.
Maybe some kind of friendly fork or more targeted packaging would help
us manage these diverging deployment scenarios?
B9  UPnP
 STUNT/ICE
 tcp hole-punching!
 more
client-vs-server refactoring: servers-only shouldn't subscribe to
storage announcements
 implement relay:
allow storage servers behind NAT
 use plain HTTP for
storage server protocol
 make tahoe Tor- and
 merge manually
specified tub location with autodetected tub location
 HTTP proxy support
for node to node communication
 servers should
attempt to open connections to clients
 use Nleitl ICBM: 48.07100, 11.36820  8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE

@_date: 2013-01-14 02:34:28
@_author: Zooko O'Whielacronx 
@_subject: [tahoe-dev] revived: proposal to change the default to K=H=N=1 
I remember getting angry about this topic the last time we discussed
it. It's strange how I get all hot under the collar about minor
technical details such as the default erasure coding parameters in a
secure distributed storage system.
Anyway, the topic has come up again. I just posted this note on the ticket:
This issue came up again. Omnifarious on IRC was explaining why he was
giving up on his attempt to play with Tahoe-LAFS:
 Yeah, I have to create a bunch of storage nodes (I
think) and I think an introducer and figure out what the introducers
furl is or something.
Also I was hanging out with Brian Warner a couple of nights ago and he
tried to upload a file to a newly created test grid with only one
server and was annoyed that it didn't work.
For what it is worth, I have spent a lot of time over the years
talking to people who deploy Tahoe-LAFS and paying attention to the
process they go through and especially to what deters them or trips
them up. I've probably learned about the experiences of more than 100
different people who've deployed, or attempted to deploy, Tahoe-LAFS
over the last five or so years. I doubt that even one of those people
would have accidentally used K=H=N=1 in their production grid without
realizing the reliability implications. I think every one of them
would have chosen to change K, H, and N after testing it out and
before starting to rely on it for long-term storage.
Therefore, I would like to re-open this dormant ticket and *strongly*
suggest that we change the default values of K, H, N from 3, 7, 10, to
1, 1, 1, and we change the documentation to warn that if you want the
erasure-coding features of Tahoe-LAFS then you have to choose your own
K, H, and N based on your personal preferences and the shape of your
In addition to believing that this will not harm almost any users who
are relying on Tahoe-LAFS for safe, long-term storage, and in addition
to believing that this will greatly help newcomers who are trying to
experiment with Tahoe-LAFS in a few spare minutes of their time, I
also believe that it will help people understand the extremely
important security properties of Tahoe-LAFS, most of which are
actually independent of the erasure coding and are best understood
without the complication of the erasure coding.
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org
