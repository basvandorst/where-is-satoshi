
@_date: 1996-12-17 03:11:33
@_author: Arnold G. Reinhold 
@_subject: Hard to Tax Scenario 
Re: Hal Finney's exegesis on Robin Hanson's scenario of Ann, virtual MD
On the contrary, in a world of anonymous payments and nyms, there is a
significant value for connecting nyms and true names and, hence a thriving
market in any information that might lead to a connection.
Bounty hunters maintain an ongoing lifestyle analysis on every true person.
Hot lists of people whose visible consumption and reported work don't jive
circulate widely. Ann can't walk down the street in a new pair of shoes
without 5 people sending in an mpeg to claim the micro-payment. And she
lives in terror as she watches the offer price for info about her rise.
By the way, as a covert MD with a receptionist cover, whom does she date?
Arnold Reinhold

@_date: 1996-07-24 15:36:50
@_author: Arnold G. Reinhold 
@_subject: passphrase and Diceware [was Re: Length of passphrase beneficial?] 
reinhold at world.std.com
The Diceware Passphrase home page:
   The Diceware WordList:
   Technical rationales behind the list:
   Other stuff that may be of interest, including a survey on PGP passphrase
usage and a rant on why p=?np has nothing to do with crypto:
   Arnold G. Reinhold
reinhold at world.std.com

@_date: 1997-12-09 01:56:43
@_author: Arnold G. Reinhold 
@_subject: WoT discussions, Trust for Nyms 
I have always felt this to be a nearly complete and practical answer to
MITM attacks. Frozen versions of major key databases would be made
available on the net along with a master list of hashes. The hash of that
master list would be widely distributed by electronic and non-electronic
means. One would only have to do it periodically, say every year or two.
Why can't this be done now?
A public billboards would be a good location to post the master hash.  (I
like to call the whole approach the "Billboard defense.") I suspect one
could rent visible space on the back side of billboards quite cheaply.
Another good location would be on a bulletin board near a publicly
accessible library. The MIT "infinite corridor" comes to mind.
A variant is for PGP users to post their own fingerprint near their house
or place of business. A business-card-size sign in a window near the front
door would do. People who agree to post such signs would be identified in
the key server database. A suspicions John could then look up a suitable
public key holder in their area, visit their house, and verify the
fingerprint. John would then e-mail an encrypted request to verify a
suspect key to that person.
My PGP fingerprint is printed on page 232 of E-mail for Dummies, 2nd
edition, IDG Books Worldwide, which I co-authored.
Arnold Reinhold

@_date: 1997-09-11 22:00:41
@_author: Arnold G. Reinhold 
@_subject: Hiawatha Bray's column on key-recovery crypto 
Hiawatha, I enjoyed your column (Boston Globe Business Section Sept. 11),
but why don't you announce that you have a PGP key, print it's signature in
a column and ask people to use it to send you news tips? This would enable
a freedom of the press challange to GAK.
Count me in. My PGP key is available from my home page
 and the servers and its signature is printed
in E-mail for Dummies, 2nd Edition, page 232. People are invited to send me
ideas and tips via encrypted mail for future books.

@_date: 1997-09-25 04:21:39
@_author: Arnold G. Reinhold 
@_subject: The CipherSaber Manifesto 
In George Lucas' Star Wars trilogy, Jedi Knights were expected to make
their own Light Sabers. The message was clear: a warrior confronted by
a powerful empire bent on totalitarian control must be self-reliant.
As we face a real threat of a ban on the distribution of strong
cryptography -- in the United States and possibly world-wide -- we
must emulate the Jedi masters by teaching people how to build strong
cryptography programs all by themselves. If this can be done, strong
cryptography will become impossible to suppress.
While cryptographers like to wallow in the complexity of their art,
the basic elements of a strong cryptographic system are quite simple
and well known in the programming community. By choosing a simple but
strong cipher that is already widely published and agreeing on how to
use it, anyone with elementary programming skills will be able to
write their own program without relying on any products that can be
CipherSaber-1 (CS1) uses Ron Rivest's RC4 algorithm as published in
the second edition of Bruce Schneier's Applied Cryptography. RC4 is
widely respected and used in a number of products, including SSL. With
a long enough key RC4 is considered strong and it is also
extraordinarily easy to explain and to reproduce. As Schneier says,
"The algorithm is so simple that most programmers can quickly code it
from memory." Implementations of RC4 are available on the Internet but
it is actually easier to write your own version.
The legal status of RC4 is the subject of some controversy. The RSA
division of Security Dynamics still considers RC4 confidential and
proprietary. It is not patented and, to the extent that Schneier is
correct (and no one doubts him), it is not confidential. However,
anyone wishing to build a commercial product using CipherSaber might
find it cost-effective, as well as polite, to obtain a license from
RSA. Apologies to Prof. Rivest for suggesting individuals use his
invention without his consent. If there were another strong algorithm
so singularly suitable, CipherSaber would have used it.
CipherSaber-1 is a symmetric-key file encryption system. Messaging
takes place by attaching binary files to e-mail. Because CipherSaber
uses a stream cipher, an initialization vector must be used to prevent
the same cipher key from being used twice. In encrypted CipherSaber-1
files, a ten byte initialization vector precedes the coded data. For
decryption, the initialization vector is read from the file and
appended to the user key before the key setup step.
CipherSaber-1 can be implemented in 16 lines of QBasic (38 individual
Basic statements). The source code is short enough for tee-shirts and
coffee mugs. But there is no need to distribute source code at all.
CipherSaber can be passed on by oral tradition, if necessary.
The U.S. Congress is considering legislation that would ban the
domestic distribution of cryptographic products that do not provide
for immediate government access to the plaintext of messages. This
government access must be possible without the consent or even the
knowledge of the message{s sender or recipient. The stated intent is
to protect us from criminals and terrorists.
The simplicity of CipherSaber should prove once and for all that the
criminals and terrorists of this world will not be deprived of strong
cryptography simply because the distribution of unapproved products is
banned. They can get the necessary technology to make their own from
existing publications whenever they feel they need it.
Another goal of CipherSaber is to demonstrate that strong cryptography
cannot be banned without severe restrictions on freedom of speech.
Banning the sale of a complex computer program or even the
multi-volume printed edition of PGP source code may seem acceptable to
many people. Banning the simple instructions needed for CipherSaber
will require the starkest abridgment of the First Amendment.
Finally, CipherSaber can be a useful pedagogical tool, helping to
educate students by presenting them with a real-world programming
problem that has both technical and ethical dimensions. Teachers of
computer science and authors of books on programming should consider
including CipherSaber as an exercise in their courses and texts.
CipherSaber in some sense parallels the time honored doctrine of jury
nullification, where jurors simply refuse to convict persons of
violating laws that the jurors determine are unreasonable or unjust.
Similarly technologists may take lawful steps as individuals to
prevent their work from being used to build a totalitarian
infrastructure. It is not that the present U.S. Government is evil --
it may well be the most benign government in history. But once the
technology for totalitarian control is in place, this or any
government will inexorably use it more and more. And that technology
is coming together with alarming rapidity. George Orwell{s novel 1984
is not science fiction, it is just one more high tech product plan
that missed its original delivery date.
So what is CipherSaber?
CipherSaber-1 is a  simple use of existing technology:
1. The encryption algorithm is RC4 as published in the beginning of
Chapter 17 of Applied Cryptography, Second Edition, by Bruce Schneier,
 John Wiley & Sons, New York, 1996. RC4 is on page 397 in the English
edition, ISBN 0-471-11709-9.
2. Each encrypted file consists of a ten byte initialization vector
followed by the cipher text.
A new random ten byte initialization vector should be created each
time encryption is performed.
3. The cipher key, the array K(i) in Schneier's notation, consists of
the user key, in the form of an Ascii text string, followed by the
initialization vector.
The above is all a programmer needs to know in order to write a
program that can encipher and decipher CipherSaber-1 files.
Explanation of CipherSaber-1 features
The user key is a text string, rather than a hex value, because humans
are more likely to be able to memorize a text string with sufficient
entropy. To leave room for the initialization vector, the length of
the user key must be less than 246 bytes. A user key with a minimum of
15 random letters or 6 short words selected at random from a
dictionary should be used for medium security (70 bit entropy).  For
higher security use 20 random letters or seven random words. (90 bit
Any unique values can be used for initialization vector, but use of
random values makes encrypted files indistinguishable from random
noise. Note that the initialization vector is not kept secret. The
random number generation used to make the initialization vector does
not have to be particularly strong. The "rand" functions in most
programming environments will suffice for a moderate number of
messages, provided the function is seeded in some non-deterministic
way, such as using the system clock.
For file encryption, a user need only memorize one key or passphrase.
For messaging, users need to exchange pairs of keys through some
secure means, most likely in person. Maintaining a list of
correspondent{s keys or passphrases in a master file, preferably
encrypted, is less convenient than public key encryption. But it may
be all that is left in a few years if PGP key servers are banned.
It may even be possible to teach a manual version of the
Diffie-Hellman key exchange, perhaps using large number calculators
(easily built in Java 1.1). The D-H procedure need be carried out just
once per pair of correspondents, since CipherSaber eliminates the need
to exchange keys for every message.
Users can, of course, add features of their own to CipherSaber
programs. For example a secure diary system that stored files in
CipherSaber would be easy to write in Java or Visual Basic. However it
is important to keep CipherSaber itself simple so everyone can write a
program that will read and write CipherSaber files.
CipherSaber programs can be easily written in almost any programming
language. The Basic language, which used to come with all DOS based
computers, is suitable. It can still be found on the Windows {95
CD-ROM in the OTHER\OLDMSDOS directory. Just copy QBASIC.EXE and
QBASIC.HLP to your hard drive{s DOS directory and you can start
programming. Macintosh users can download the free Chipmunk Basic
interpreter from the Internet. Begin by writing a program that can
copy binary files byte by byte and then test it thoroughly before you
add the encryption algorithm.
Become a CipherKnight
To popularize CipherSaber, a "gif" file, encrypted using CipherSaber,
has been posted on the Internet at
 This file, when decoded, can
be printed as a CipherKnight wall certificate. The certificate may be
displayed by persons who met certain criteria, including writing the
program that decrypted the certificates. Here are the
honor-system-enforced rules:
CipherKnight requirements
1. Write you own CipherSaber program.
2. Write a letter to your political representative expressing your
opinion (whatever it may be) of the proposed ban on the distribution
of strong cryptography within the United States.
3. Download and install PGP,  generate a key pair and post it to a
public key server.
4. Use a CipherSaber to send an secret message to another person.
5. Decrypt and print the CipherSaber wall certificate using the
CipherSaber program you wrote yourself. The key is: "ThomasJefferson"
Any of the eligibility requirements above is waved if it illegal in
the applicant's local jurisdiction or if the applicant reasonably
believes carrying it out would place him or her in danger.
Test Files
The following files are provided on the CipherSaber web site,
 to help you check your work.
This is a short text file encrypted with "asdfg" as the user key. Here
are the contents of cstest1.cs1 in hex, in case you cannot download
the file for some reason:
6f 6d 0b ab f3 aa 67 19 03 15 30 ed b6 77 ca 74 e0 08 9d d0
e7 b8 85 43 56 bb 14 48 e3 7c db ef e7 f3 a8 4f 4f 5f b3 fd
This text file was CipherSaber-1 encrypted with the key
"SecretMessageforCongress" Remember that keys are case sensitive.
This file is encrypted with the key "ThomasJefferson" It contains your
CipherKnight wall certificate as a .gif file.
chalng.cs1 is a text file encrypted with CipherSaber-1 and a secret
key. A reward of $100 will be paid to anyone who can decipher this
Spread the Word
"It is the common fate of the indolent to see their rights become prey
to the active. The condition upon which God hath given liberty to man
is eternal vigilance."
John Philpot Curran, 1790
Even if the proposed ban on strong cryptography does not become law
this year, it is important that CipherSaber be distributed as widely
as possible throughout North America. Please help in any legal way you
Arnold G. Reinhold
Cambridge, Massachusetts
arnold at iecc.com
September 23, 1997

@_date: 1998-12-15 06:15:03
@_author: Arnold G. Reinhold 
@_subject: Text of Wassenaar regulations, with comments 
This is the definition of PD from Wassenaar's "DEFINITIONS OF TERMS USED IN
THESE LISTS"  I think that is pretty clear, but it might be wise for people who are
distributing open source crypto to include language in their legal notices
stating that the material is to be considered in the public domain for the
purposes of the Wassenaar arangement and waving any rights that would cause
the export of the material to be prohibited under that arangement.  Check
with a good lawyer first, of course.
Arnold Reinhold

@_date: 1998-07-07 05:46:16
@_author: Arnold G. Reinhold 
@_subject: IP: "CyberCash can't oust credit cards" 
Three orders of magnitude cost reduction as compared to what?  I can
believe that much improvement over running my credit card thru an imprinter
and processing the paper slip.  But I doubt you can get anything like1000X
over SET, ugly as it is.
Arnold Reinhold

@_date: 1998-09-18 07:14:12
@_author: Arnold G. Reinhold 
@_subject: Questions for Magaziner? 
One question I'd like asked is whether the US Gov will approve 56-bit RC-4
for export on the same terms as 56-bit DES. That would allow export
versions of web browsers to be upgraded painlessly, making international
e-commerce 64 thousand times more secure than existing 40-bit browsers.
(56-bit DES browsers would require every merchant to upgrade their SSL
servers and introduce a lot of unneeded complexity.)
Arnold Reinhold

@_date: 1998-09-20 14:15:03
@_author: Arnold G. Reinhold 
@_subject: Questions for Magaziner? 
I was under the impression that 40-bit RC4 was accomplished by revealing 88
bits of the 128-bit key in a header. If a new 56-bit-RC4 browser was
implimented by setting16 of those 88 bits to zero, would any existing
server know the difference? If not, you would get an immediate improvement
in security, at least for browser to server messages, without waiting for
the servers to be upgraded.
No doubt I am missing something, but what?

@_date: 2000-11-01 14:57:14
@_author: Arnold G. Reinhold 
@_subject: Paranoid Encryption Standard (was Re: Rijndael & Hitachi) 
I have some ideas on this, based on the earlier note, but I think I should take some time and write them up more formally.
Arnold Reinhold

@_date: 2000-11-20 12:10:42
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Public Key Infrastructure: An Artifact... 
At 12:08 PM +0000 11/19/2000, Perry commented:
Perry's last sentence gets to the heart of the matter. If CAs included a financial guarantee of whatever it is they are asserting when they issue a certificate, then all these problems would go away. The CAs would have a strong interest in clarifying the semantics of certificates and would choose technology and verification methods that optimized the risk vs cost (including difficulty of use) I believe the reason this has not happened yet is that various business interests perceive an opportunity to get the government to shift all risk to the consumer by snowing legislators with crypto mumbo-jumbo.  That is an even cheaper solution from the business interests' perspective.
Arnold Reinhold

@_date: 2000-11-22 11:00:34
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Public Key Infrastructure: An Artifact... 
It's still early in the game to be so certain. But if you are right, that in it self is an indictment of PKI. If there really is a market for trust establishment and a form of PKI is the low cost producer of trust, then someone should be able to make money by using their expertise to assemble a technology suite and sell trust insurance based on the spread between the risk perceived by the market and what they know to be a lower risk. If such services never develop, it either means there is no market or PKI doesn't have enough economic impact to cover the costs of starting such a business.
Arnold Reinhold

@_date: 2000-10-02 08:24:17
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: AES winner to be announced Monday. 
The following information from the Rijndael Page  may come in handy later today when NIST announces the new Advanced Encryption Standard (AES):
'Rijndael FAQ
     1.How is that pronounced ?
        If you're Dutch, Flemish, Indonesian, Surinamer or South-African, it's pronounced like you think it should be. Otherwise, you could pronounce it  like "Reign Dahl", "Rain Doll", "Rhine Dahl". We're not picky. As long as you make it sound different from "Region Deal".
     2.Why did you choose this name ?
        Because we were both fed up with people mutilating the pronunciation of the names "Daemen" and "Rijmen". (There are two messages in this  answer.)
     3.Can't you give it another name ? (Propose it as a tweak!)
        Dutch is a wonderful language. Currently we are debating about the names "Herfstvrucht", "Angstschreeuw" and "Koeieuier". Other suggestions are welcome of course. Derek Brown, Toronto, Ontario, Canada, proposes "bob".'

@_date: 2000-10-05 10:55:17
@_author: Arnold G. Reinhold 
@_subject: Rijndael & Hitachi 
Maybe I am missing something, but what would be the big deal if NIST did take patent claims into account?  There were five excellent candidates. If NIST picked Rijndael in part because it least likely to be tied up in court for the next N years, does that diminish their Quite right. There is plenty of credit to go around.  I was particularly pleased that NIST had the guts to pick a non-U.S. design. That's risky in Washington.
Arnold Reinhold
P.S. What is the licensing status of the other finalists? For example, I seem to recall reading that RC6 would be licensed to the public at no charge if it won the competition. What now?

@_date: 2000-10-10 09:44:59
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Non-Repudiation in the Digital Environment (was Re: First    
You may well be right about the accepted definition of non-repudiation, but if you are then I would amend my remarks to say that known cryptographic technology cannot provide non-repudiation service unless we are willing to create a new legal duty for individuals and corporations to protect their secret key or accept what ever consequences ensue.  I don't think that is acceptable.
I find the rest of your comment a tad too opaque.  Could you give some examples of what you have in mind?
Arnold Reinhold

@_date: 2000-10-10 13:44:13
@_author: Arnold G. Reinhold 
@_subject: Rijndael & Hitachi 
Thanks for the summary. My only problem with Rijndael is that it is still rather young. I recall reading that NSA takes seven years to qualify a new cipher. It took at least that long for the open cryptographic community to trust DES.  If someone asked me what cipher to use today in a new, very high value application, I would have a hard time choosing between Rijndael and 3DES. Rijndael appears to be a far superior design, but 3DES has enjoyed a lot more scrutiny.
I was thinking it might be useful to define a "Paranoid Encryption Standard (PES)" that is a concatenation of all five AES finalists, applied in alphabetical order, all with the same key (128-bit or 256-bit).  If in fact RC6 is the only finalist still subject to licensing by its developer, it could be replaced by DEAL (alphabetized under "D"). Since DEAL is based on DES, it brings the decades of testing and analysis DES has received to the party.  DEAL was dinged in the first round because "it is claimed that DEAL-192 is no more secure than DEAL-128" and "equivalent keys are claimed for a fraction (2**­64) of the 192-bit and 256-bit key spaces."  I don't think either issues is reason to exclude DEAL in this role, though if there were tweaks to DEAL that resolved them, they might be worth including.
PES would be intended for encrypting material of the highest value while AES undergoes additional years of scrutiny. Given Rijndael's outstanding performance, PES could prove 10-20 times slower than AES, but that should not be a problem on modern PCs. User's of PES could still face third-party patent claims, such as Hitachi's, whatever validity they may have.  To the extent that my ideas in this posting are patentable, I would happily place them in the public domain.
Arnold Reinhold

@_date: 2000-10-11 09:08:37
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Non-Repudiation in the Digital Environment (was Re: First     
The Abstract of the draft-ietf-pkix-technr says
My original point was the the technical definition of non-repudiation was much narrower that the legal definition.  This draft seems to agree. It goes on to say:
My concern is that the vast majority of informed lay people, lawyers, judges, legislators, etc. will hear "non-repudiation" and hear "absolute proof."  If you doubt this, read the breathless articles written recently about the new U.S. Electronic Signatures Act.
I don't think technologists should be free to use evocative terms and then define away their common sense meaning in the fine print. Certainly a valid public key signature is strong evidence and services like that described in the draft can be useful. I simply object to calling them "non-repudiation services." I would not object to "anti-repudiation services,"  "counter-repudiation services"  or "repudiation-resistant technology." Would the banking industry employ terms like "forgery-proof checks," "impregnable vaults" or "pick-proof locks" to describe conventional security measures that were known to be fallible?
Arnold Reinhold

@_date: 2000-10-11 14:55:46
@_author: Arnold G. Reinhold 
@_subject: Rijndael & Hitachi 
Ciphers are components of security systems, not complete security systems. How best to improve a  component is a legitimate engineering question even if there is reason to believe they will often be misapplied. At present there is no serious threat to 3DES, so why did we bother with the whole AES exercise?
[Look at the benchmarks? --Perry]
Anyway, I think there is an interesting theoretical question here:
Design a cipher algorithm P that assumes as primitives 5 ciphers, C1, ...,C5 (or more generally N ciphers for odd N > 1) with the same block size and key length.  P is to have the same block size and key length as the Ci and is to be provably secure against chosen plaintext attacks even under the following conditions:
1. One of the Ci is a strong cipher (i.e. there is no attack faster than trying all the keys)
2. An attacker gets to supply  the other four  Ci, subject to the condition that they be cipher like: i.e. they must be bijections between the input and output domains, the bijection is the same if the key value is the same and there are no extra outputs.
3. The attacker knows the details of the secure algorithm.
P should be as simple as possible not employ any additional cryptographic primitives (e.g hashes, S-boxes or special constants).
Derek Atkins adds:
The fact that some people put Medeco's in glass doors, doesn't mean Medeco should never develop a better lock.
Arnold Reinhold

@_date: 2000-10-16 19:06:34
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Non-Repudiation in the Digital Environment (was Re: First     
I don't have to imagine it. I have been on the witness stand trying to explain terminology in technical documents that was quoted out of context by opposing council. (We won, but it cost a bundle in legal fees and management time.) I would also remind you of the _NSAKEY flap and countless product liability cases where minutia in engineering documents played a pivotal role.  Also there is a big difference between comments in source code or Unix command names and a technical specification, like an RFC, that undergoes a formal review and approval process.  The last will be given much more weight.
Even if your spec contained an explicit definition of "non-repudiation" that made clear its technical limitations, there is a high likelihood that the public and the legal system will be mislead. But the definition you cite dose not even do that. Here is what my "Random House Dictionary of the English Language" says about the meaning of "prevent:"
"... Prevent, hamper, hinder, impede refer to different degrees of stoppage of action or progress. To prevent is to stop something effectually by forestalling action and rendering it impossible: 'to prevent the sending of a message'..."
No cryptographic technology that I am aware of can fairly be said to render the denial of an act impossible.
Arnold Reinhold

@_date: 2000-10-17 11:03:39
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Non-Repudiation in the Digital Environment (was Re: First     
This is the nub of our argument.  I believe the terms we use influence how our technology will be interpreted in a societal and legal context and we therefore have an obligation to be as clear as possible. This is particularly important with technology such as digital signatures and certs  which may profoundly alter the way individuals interact with the economic system.
To the extent we agree here, I would urge you to help insure that this message is crystal clear in all specs and documents whose content you can influence. And don't rely on which dictionary's definition of "protect" is correct.
The problem goes beyond simple impersonation in that the victims subsequently find it difficult to convince large institutions that they are who they say they are.   My understanding is that the term comes from victims' statements that they felt as if their identities had been stolen.  See  The question is relevant here, not as just another parallel question of semantics, but because exactly how the legal system treats "non-repudiation" can make the identity theft problem much better or much worse.
For what it's worth, when Congress responded to this problem by passing the Identity Theft and Assumption Deterrence Act of 1998, it did not define "identity theft" as a new crime, but merely amended 18 U.S.C. § 1028 "Fraud and related activity in connection with identification documents and information." The act includes provisions that appear to protect private keys, though they are not explicitly mentioned, while biometrics are (see 1028(d)(3)(C)).
Arnold Reinhold

@_date: 2000-10-18 06:59:18
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Non-Repudiation in the Digital Environment (was Re: First     
The legal and societal significance of this technology is open to debate, and will be decided differently in different places, based on local values, economic interests and raw political power.  All I am asking is that the debate be informed by accurate statements of what this stuff can and cannot do.
As well it should. There is a big difference between "can we do it?" and "should we do it?"
One other point, and let me shift to upper case for this one:  THERE ARE NO "SOLID MATHEMATICAL FOUNDATIONS" FOR ANY OF THIS STUFF!!!!! THE DIFFICULTY OF BREAKING PUBLIC KEY SYSTEMS HAS NEVER BEEN PROVEN MATHEMATICALLY.  It is all hypothesis and empirical argument. A lone mathematician working in his attic could come up with an algorithm that would blow some or all of the existing systems out of the water. Who get to cover that financial risk?
Well said.
Arnold Reinhold

@_date: 2000-10-19 16:58:09
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Non-Repudiation in the Digital Environment (was Re: First     
Eye twinkle doesn't come across in e-mail, I'm afraid. My apologies to Tony. This is obviously one of my hot buttons.
I'm not sure those contracts would stand up in court if there were massive public losses due to a collapse of the PKI. (Anyway CA CPS's stretch to notion of a "mutual agreement" pretty far. I purchase a $10 cert and am bound by over 100 pages of gobbldygook that only a handful of people on the planet can be expected to fully understand?)
But I am less concerned with CA legal liability then with who is left holding the bag when a massive subversion of the banking system is perpetrated, and how big that could be.
Arnold Reinhold

@_date: 2000-10-20 14:26:05
@_author: Arnold G. Reinhold 
@_subject: Paranoid Encryption Standard (was Re: Rijndael & Hitachi) 
I read the Massey and Maurer paper (One can find it at  1.pdf  ) and I have a couple of comments on it.
As I understand it, their argument goes like this: Let the concatenated cipher C1*C2 applied to plaintext P be C2(C1(P)). If C2 is subject to attack when the plaintext it gets has certain statistical properties, then it is possible for C1's ciphertext to have those properties and the concatenated cipher to be less resistant to statistical attack than either component.
Massey and Maurer give a very simple example to show this can occur. Here is a bit more realistic example: Suppose C1 simply permutes the input bits and that in doing so it takes the high-order bit of each plaintext byte and moves it to the first two bytes of the cipher text. Suppose further plaintext blocks that have the first two bytes zeroed are weak for C2. Then if C1 is fed ordinary printable ascii text with no parity, the first two bytes of C1-ciphertext will be zero, exposing the weakness of C2.  On the other hand, if C2 were used alone on the same ascii plaintext it would never see zeros as input bytes and thus would not be subject to attack.
However in the case of a chosen-plaintext attack, Massey and Maurer's argument does not work. In fact the proof they give of their "Proposition" can easily be adapted to prove that a concatenated cipher C1*...*Cn is always at least as difficult to break by chosen-plaintext as *any* cipher in the concatenation.
Here is an outline of the proof. Note, as they do, that the worst case is when you can easily determine the key to every cipher except one.  In their case it is the first cipher, in ours say it is Ci, 1<=i<=n.  Then any set of chosen plaintext, ciphertext pairs (PTj, CTj) that results in a break of the concatenated cipher C1*...*Cn can be converted in to a set of chosen plaintext, ciphertext pairs (PT'j,  CT'j) that results in a break of Ci as follows (I'll use CCk to denote the inverse cipher of Ck):
PT'j = (C1*...*Ci-1)(PTj)
CT'j = (CCi+1*...*CCn)(CTj)
One might ask why this proof works in the chosen-plaintext attack but not the statistical attack. The reason is that in the later,  while you can still compute each PT'j, there is no reason to expect that they will have the same statistical properties as the original PTj. However PT'1 is always equal to PT1, so the proof does work for the first cipher in the statistical attack case. That is where "the importance of being first" comes from.
My main question is how much weight should we give to this result in designing a crypto system by combining AES candidates? Remember that the AES candidates were designed to resist chosen-plaintext attack. Resistance to chosen-plaintext attack is a far more stringent demand on a cipher than resistance to statistical attack. And I have just shown that a concatenated cipher is at least as strong as any of its components against chosen-plaintext attack. So why should we even consider Massey and Maurer's result? The one argument I can think of goes like this:  Suppose we are wrong and all the component ciphers are subject to chosen-plaintext attack and, even worse, so is the concatenated cipher. The component ciphers might still be resistant to statistical attack and often this is the best attackers can do, so we would like the extra insurance.
But in the real world of AES candidates I claim even that argument should be discarded.  Massey and Maurer worry about the possibility that the output of one cipher may have statistical properties that cause weakness when that output is fed into the subsequent ciphers. The AES candidates were designed to have outputs that appear uniformly random and have all undergone extensive statistical testing  The have also been studied for weak inputs. Thus the first cipher in the concatenation can be expected to destroy patterns in the plaintext, not create them. While not a mathematical proof, the results of the AES candidate analysis and testing to date make it overwhelmingly more likely that the concatenation of AES-candidate ciphers will in fact be more resistant to statistical attack than any of the individual ciphers.
I don't think it is quite that clear. It might well be easier to prove,  say,  that Twofish is not the inverse of MARS for the same key than it is to prove the same result for separately hashed keys. But again, the likelihood of two different ciphers being accidental inverses is even lower than the likelihood of guessing the key correctly (there are (2**n)! bijections on n-bit blocks). And NIST has just released SHA-2 which provides 256 bit hashes,  so I suppose we might as well use it here.
Is this the Massey and Maurer result or is there something specific about these two ciphers?
The problem with OFB is that what you get is a stream cipher and that, in turn, means a unique IV for each message is required. I have spent a lot of effort in my CipherSaber project teaching people how to do that, and the risk of implementors getting it wrong is high. I've even seen commercial products that claim to use RC4 but don't do IVs. Note that IV reuse is far more catastrophic in a stream cipher than it would be in a block cipher used in a feedback mode.
Also OFB means that ciphertext is always bigger than plaintext (if you include the IV). That prevents encryption in place, for example. I'd rather have a block cipher if at all possible.
So here is my draft proposal for the Paranoid Encryption Standard, PES:  (P is a plaintext block and K is the user key.)
PES(P) =Twofish(Serpent(MARS(DEAL(AES(P))))), where:
the key for AES is SHA2(K||"Rijndael")
the key for DEAL is SHA2(K||"DEAL")
the key for MARS is SHA2(K||"MARS")
the key for Serpent is SHA2(K||"Serpent")
the key for Twofish is SHA2(K||"Twofish")
The character string constants are 8-bit ascii with zero parity bit.
The order of each cipher is determined alphabetically, except that I obviously could have chosen to put Rijndael under "R"  instead of "A."  By putting it first we can take advantage of Massey and Maurer's result and state the PES is at least as strong against statistical attack as AES.  The second cipher, DEAL, is based on DES, which has received the most public scrutiny of any cipher. I am not aware of any  statistical attack on DES inputs or any statistical weaknesses in DES output that might compromise MARS.  And, as we have shown above, PES is at least as resistant to chosen plaintext attack as any of its components.
PES is intended to address concerns that AES might have a design flaw or deliberate, hidden weakness. Confidence that neither exist can only come from additional years of testing and analysis.  PES, because it is at least as strong as AES and incorporates the strengths of  four other AES design teams and the decades of work on DES, might be a better choice for very high value messages, where encryption time is not an issue.
Some other comments I have received urged the use of salt.  Salt is very important is overall system design, but it is not part of the cipher per se.  As I mentioned in my earlier post, RC6 is not being used because it still requires licensing. No criticism of RC6 or its owner's decision to retain commercial licensing rights is intended.
Arnold Reinhold

@_date: 2000-10-20 17:32:11
@_author: Arnold G. Reinhold 
@_subject: Non-Repudiation in the Digital Environment (was Re: First  
I don't know of any solid basis for this claim.  There have been unexpected mathematical breakthroughs of that magnitude in the recent past. Schönhage and Strassen algorithm for multiplication, the Fast Fourier Transforms, formulas that compute outer digits of 1/pi without computing the earlier ones, etc.
That is already happening.
Well, that is the the big question mark as I see it. There are many choices in designing financial systems based on public key technology. If people use conservative approaches then you may well be right, but if they buy the PKI party line we could face some very serious problems. In particular, systems that depend on the security of one or a few master keys should be treated with suspicion. For example, a bank could keep its own customer's public key fingerprints on file or rely on the fact that all customers' certs are all signed.
If we throw out existing systems and base our entire financial system on public key crypto without enough independent backups, an algorithmic breakthrough could lead the the end of the world as we know it. Algorithm compromise should be treated as an explicit risk.
Let's not forget 2038.
Arnold Reinhold

@_date: 2000-10-26 13:55:00
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Paranoid Encryption Standard (was Re: Rijndael & Hitachi) 
Maybe so. I do agree that Rijndael is an excellent design and a good choice for AES. But it hasn't been tested enough for complete confidence, in my opinion. Supposedly NSA takes 7 years to vet a new cipher. If anything, the public cryptographic community should take even longer, given we lack the budgets and accumulated methodologies that NSA can bring to bear.
Testing is the most expensive part of any new cipher effort.  So I think there is a practical basis for at least asking if there is a simple way to combine the AES finalists and take advantage of all the testing that each has already undergone.  And, IMHO, it is an interesting theoretical question as well.  Even if the answer is "yes," I am not advocating that it be used in most common applications, e.g network security, because there are so many greater risks to be dealt with. But it might make sense in some narrow, high value, applications.
I agree that Massey and Maurer's proof requires independent keys for each cipher, and have tried meet that requirement in my design. But the fact that Massey and Maurer's proof fails does not mean that the keys must, in fact, be independent for the combined cipher to be secure. See below.
I have long felt that there should be some way to exclude using the inverse cipher in these counter examples just as we exclude the possibility that the attacker can simply guess the key. I think I have a different approach to formulating the problem which does that:
Let's define a modified version of your game: game2.  We'll stick with the two cipher case E(F()) for the moment. Here are the rules:
1. Just as in your game,  you get to choose two ciphers, one of which has to be strong.
2. You pick which is E and which is F.
3. The ciphers have to be bijections (one-to-one, onto functions) on {1,...,2**N}  where N is the block size in bits. In particular, this means each cipher has no internal state. The same input always produces the same output.
4. If K is the key for the combined cipher, then the key for E is also K, but the key for F is K xor M, where M is a bit string the same length as K that will be selected randomly AFTER you have specified your two ciphers. You will then be informed of its value (which will never change) and may use it in attempting to break E(F()), but you cannot input it into either cipher.
If a strong cipher is assumed to have the property that you cannot derive any information about the content of an input block from examining the output block unless you know the complete key, then I claim E(F()) cannot be broken without guessing M.
I am making a very broad assumption about what a strong cipher is, but even without it, I believe my version of the game breaks up all counterexamples that use the inverse ciphers to break E(F()).
Now you might say "this construction proves my point, you are not using the same keys."  That is true, but the keys are far from independent.   I can go even further.  Most block ciphers have some internal constants that can be varied. There may be constraints on how these constants are selected, but there is still some underlying variability. You can think of these constants as playing the same role as M in game2. If we were allowed to select final values for these constants in the strong cipher after the probe cipher was finalized, one could make a similar argument without a separate M.
Block ciphers are easy to test and audit and are hard to subvert (you have to alter the cipher at each node and at the same time.) On the other hand, IV generation schemes are hard to test, nearly impossible to audit, and relatively easy to subvert (you just have to sabotage the RNG at one node). It would be really foolhardy of me to introduce a stream cipher with those known risks, just to counter what I admit is a very small chance of an undetected flaw in Rijndael.
I am assuming SHA2 is a one-way hash as well. So breaking one of the component ciphers will not allow an attacker to derive the key for any of the other ciphers. It was an ad hoc response to your comment about the need for key independence. Better suggestions are welcome. My game2 construction, above, suggests that key independence doesn't have to be super strong. I suppose based on that argument I should use constants that were clearly derived after the individual cipher designs had been completed. One possibility might be to use voting results from the upcoming Nov. 7 U.S. presidential election: say, Alabama's for AES. Delaware's for DEAL, Maryland's for MARS and South Carolina's for Serpent, Tennessee's for Twofish. (Final voting results as decimal numbers in ascii, with no punctuation or leading zeros, in alphabetical order by candidate: Buchanan, Bush, Gore, Arnold Reinhold

@_date: 2000-10-27 13:29:23
@_author: Arnold G. Reinhold 
@_subject: CDR: Re: Paranoid Encryption Standard (was Re: Rijndael & Hitachi) 
o Your opponent has the cryptologic capabilities of the a major world power
o The content has very high value (multi-billion dollar deal, could bring down a government, could start a war)
o Long term protection is required (30+ years)
o You are in a position to properly secure the terminals at both ends
0 Efficiency is not a concern
For example, a chief of state's personal diary, an opposition leader's communications, best and final bids on large projects, etc.
In a way I see this question as how one should manage the transition from 3DES to AES. Does one keep using DES until the big day and then switch to AES? Or does a blended solution make sense in some cases?
While I think there may be a use for something like a Paranoid Encryption Standard in very unusual situations, I don't wish to waste more of people's time arguing with those who say there's no need for it at all. I don't have any compelling evidence.  It's pure I am really more interested in the theoretical "why not?" question, i.e. is there any real downside in combining ciphers in this way, besides efficiency?  Conventional wisdom seems to be more cautious than I think is justified and I am trying to prove that.
Arnold Reinhold

@_date: 2000-10-27 16:20:11
@_author: Arnold G. Reinhold 
@_subject: CDR: RE: Paranoid Encryption Standard (was Re: Rijndael & Hitachi) 
That is the theoretical question that I am asking. What you say appears to be the conventional wisdom, and I am claiming that it is wrong.  As long as there is some way to make sure that none of the ciphers in a chain are inverses of the others, or close to an inverse, in some sense, then I claim as long as one of the ciphers is strong, there is no way to get any information out about the keys from the other ciphers, even if they are all designed to reveal that As a practical matter, you may as well derive the sub keys from the master key using a one-way hash, but I am questioning the theoretical justification for doing that.  Massey and Maurer base their paper on oracles that give you the key for all component ciphers but one. I am saying such oracles cannot exist if one of the ciphers is strong and "inverses" of the strong cipher are excluded.
Arnold Reinhold

@_date: 2001-12-11 09:29:19
@_author: Arnold G. Reinhold 
@_subject: FreeSWAN & US export controls 
In the most recent ruling, Universal v. Remerdez/Eric Corley 2600.com (00-9185),  , the US Court of Appeals for the Second Circuit declined to overturn an injunction against the posting of DeCSS on the Internet. The Court held that software was speech, but did not enjoy the level of First Amendment protection accorded to pure speech because it is functional with little human intervention. This is a very disturbing precedent which I hope will be reversed on appeal, but given the post-9/11 mood and the limited technological understanding of most judges, I wouldn't count on it. Also I believe the U.S. Supreme Court has upheld export controls in the past, the First Amendment notwithstanding.
Having a body of open source crypto software that is not entangled by any U.S. input is not a foolish idea.  Surely there are good programers outside the U.S. who understand the importance of making FreeSWAN work seamlessly with Linux.
Arnold Reinhold

@_date: 2001-12-12 16:47:56
@_author: Arnold G. Reinhold 
@_subject: FreeSWAN & US export controls 
You make a good argument for dropping the non_U.S. only restriction. The risk may be worth the benefits of kernel integration.  That could result in wider corporate use of IPSec to fight real security threats and make it much more difficult, politically, to suppress.
My point was just that one cannot rely on the U.S. courts striking down any future crypto regulations. They should and I hope they would, but it not a sure thing. The most recent ruling is not favorable. I also wouldn't underestimate the U.S. government's ability to stifle crypto development if they choose to do so and get a green light from the courts.  Note today's Warez crackdown.
Maybe there is some compromise possible where a core crypto library is kept free of U.S. contributions?
Arnold Reinhold

@_date: 2001-07-27 11:33:08
@_author: Arnold G. Reinhold 
@_subject: Attention CipherSaber Users!! 
A draft paper by Scott Fluhrer, Itsik Mantin and Adi Shamir was released on July 25, 2001 and announces new attacks on the RC4 cipher that is the basis for CipherSaber-1. Some of these attacks specifically involve the use of an IV with a secret key, the very scheme used in CipherSaber.  Prof. Shamir states in an e-mail accompanying the release:
"Attached you will find a new paper which describes a truly practical direct attack on WEP's cryptography. It is an
extremely powerful attack which can be applied even when WEP's RC4 stream cipher uses a 2048 bit secret key (its maximal size) and 128 bit IV modifiers (as proposed in WEP2). The attacker can be a completely passive eavesdropper (i.e., he does not have to inject packets, monitor responses, or use accomplices) and thus his existence is essentially undetectable. It is a pure known-ciphertext attack (i.e., the attacker need not know or choose their corresponding plaintexts). After scanning several hundred thousand packets, the attacker can completely recover the secret key and thus decrypt all the ciphertexts. The running time of the attack grows linearly instead of exponentially with the key size, and thus it is negligible even for 2048 bit keys."
The paper itself, titled "Weaknesses in the Key Scheduling Algorithm of RC4," has been posted at  (in PDF format) and  at  (in Postscript).
WEP is an encryption system used with 802.11 wireless Ethernet that employs RC4, but the attack affects CipherSaber as well.  Note that "several hundred thousand" separate CipherSaber messages encrypted with the same key would have to be collected for this attack to succeed.  None the less, from a cryptographic standpoint, this is too close for comfort.
Accordingly I recommend that CipherSaber users switch to CipherSaber-2 with a parameter N=20 or larger. The RC4 state vector will thus be mixed 20 times instead of once. This large a value for N is probably overkill, but until there is time to fully digest the implications of this paper, it is better to err on the safe side.  If this is impractical for any reason, I recommend changing keys on a regular basis to limit the amount of traffic encrypted with any one CipherSaber key (even though the IVs differ).
If and when a consensus develops on the best way to fix RC4, I will announce a corresponding version of CipherSaber. Visit the CipherSaber page  periodically for updated information.
Arnold Reinhold

@_date: 2001-07-27 18:36:53
@_author: Arnold G. Reinhold 
@_subject: Criminalizing crypto criticism 
If you read the language carefully, you will see that 1201g only permits *circumvention* as part of cryptographic research (and then only under limited circumstances). There is nothing in the law that allows publication of results.
Even the recent Shamir, et. al. paper on RC4 and WEP could arguably violate DMCA. WEP could be considered a TPM since it protects copyrighted works (e.g. e-mail). More importantly RC4 could be used in some other copy protection system that we don't know about -- it's use might even be a trade secret.  There is simply no way to guarantee that a given cryptoanalytic result doesn't compromise some TPM. Even software that breaks Ceaser ciphers could be actionable. DCMA is *that* bad.
Arnold Reinhold

@_date: 2002-10-20 22:38:35
@_author: Arnold G. Reinhold 
@_subject: palladium presentation - anyone going? 
I went. It was a good talk. The room was jam packed. Brian is very forthright and sincere. After he finished speaking, Richard Stallman gave an uninvited rebuttal speech,  saying Palladium was very dangerous and ought to be banned.  His concerns are legitimate, but the net effect, I think, was to make the Q&A session that followed less hostile.
Palladium sets up a separate trusted virtual computer inside the PC processor, with its own OS, called Nexus, and it own applications, called agents. The trusted computer communicates with a security co-processor on the mother board,  and has a secure channel to your keyboard and mouse and to a selected window on your CRT screen.
How to prevent the secure channel to the on-screen window from being spoofed is still an open problem. Brian suggested a secure mode LED that lights when that window has focus or having the secure window display a mother's-maden-name type code word that you only tell Nexus.  Of course this doesn't matter for DRM since *your* trusting the window is not the issue.
All disk and network I/O is done thru the untrusted Windows OS on the theory that the trusted machine will encrypt anything it wants to keep private. Windows even takes care of Nexus scheduling.
A major design goal is that all existing software must run without change. Users are not required to boot Palladium at all, and are to be able to boot it long after Windows has booted.
The specific question never came up. As Brain did say, Palladium is just a platform. People can built whatever they want on top of it. It seemed clear to me that the primary goal is DRM, but as someone else in the audience said (approximate quote) "We always hear that you can't do this or that without trusted hardware. Well, this is trusted hardware."  I don't see why anyone would think protecting software copyright could not be done.
No. The SCP is based on a smart card core and is to be a "light weight, low pin count chip" with a target cost of $1 in volume.  I presume future deals between MS and Intel are always possible.
The SCP will support several algorithms, including 2048-bit RSA, 128-bit AES, SHA1, an HMAC. They may include another cipher and another hash. There will also be a FIPS140-2 Random Number Generator and several monotonic counters, but no time of day clock. Each chip will have a unique RSA key pair, an AES key and a HMAC key. The only key that the SCP will reveal to the outside is the RSA public key and it will only do that once per power up cycle.
There is also a change to the PC memory management to support a trusted bit for memory segments. Programs not in trusted mode can't access trusted memory. Also there will be three additional x86 instructions (in microcode) to support secure boot of the trusted kernel and present a SHA1 hash of the kernel code in a read only register.  There may be a hole somewhere, but Microsoft is trying hard to get it right and Brian seemed quite competent.
Near as I can see, the real trust comes from the RSA key pair stored in the SCP and a cert on that key from the SCP manufacturer.  There is no command to obtain the private key from the SCP.  Presumably they leverage smart card technology plus what ever tricks they think of to make it hard to get that key.   Differential power analysis or HNO3 might do the trick. We'll have to wait and see.
The real question from Microsoft's stand point is will the entertainment industry be satisfied with Palladium's level of security and release content that can play on Palladium equipped PCs? DVDs aren't Hollywood's main problem.  Movies are becoming available online long before the DVD is released.  Hollywood probably wants something that monitors ALL content for watermarks. Palladium as presented doesn't do this.  But again it is a platform. Once it exists, a later version of Windows might require it to be up and would then verify all content displayed.  If Hollywood doesn't convince Microsoft to do this, Sen. Hollings will be more than glad to introduce the necessary legislation. To paraphrase Stallman's rant, in the Palladium context Alice and Bob are corporations and Mallory is the PC owner.
Arnold Reinhold

@_date: 2002-10-21 21:36:09
@_author: Arnold G. Reinhold 
@_subject: palladium presentation - anyone going? 
One of the services that Palladium offers, according to the talk announcement, is:
It seems to me such a service requires that Palladium be secure against the local user. I think that is the main goal of the product.
Brian mentioned that the system will not be secure against someone who can access the memory bus.  But I can see steps being taken in the future to make that mechanically difficult. The history of the Scanner laws is instructive. Originally one had the right to listen to any radio communication as long as you did not make use of the information  received. Then Congress banned the sale of scanners that can receive cell phone frequencies. Subsequently the laws were tightened to require scanners be designed so that their frequency range cannot be modified.  In practice this means the control chip must be potted in epoxy.  I can see similar steps being taken with Palladium PCs. Memory expansion could be dealt with by finding a way to give Palladium preferred access to the first block of physical memory that is soldered on the mother board.
Brian also mentioned that there would be changes to the Southbridge LCP bus, which I gather is a local I/O bus in PCs.  SCP will sit on that and presumably the changes are to insure that the SCP can only be accessed in secure mode.
There are two cases here. One is a buffer overflow in one of the trusted "agents" running in Palladium. Presumably an attack here will only be able to damage vaults associated with the product that contains that agent.  The vendor that supplies the agent will have a strong incentive to avoid overflow opportunities.
The more dangerous case is  buffer overflow in Nexus. Brian admitted that this would be disastrous.  Obviously QA will be intense. They plan to publish Nexus source code. Brian was even asked if they would publish source for their C compiler. He said they had thought of that, didn't think they could get the VisualC compiler published but are considering coming up with a stripped down C compiler they can They realize that the whole back up/upgrade issue is a big concern. Brian briefly presented some very complex schemes for doing this which I didn't grasp.
Presumably an intact Nexus can trash any trusted app.  And I don't see how any data in the vault could prevent you from loading a clean nexus, say from CD-ROM, as long as the SCP isn't altered and there is supposed to be no way to do that from software..
Arnold Reinhold

@_date: 2002-10-22 15:29:26
@_author: Arnold G. Reinhold 
@_subject: Palladium -- trivially weak in hw but "secure in software"?? 
I think the most important phrase above is "at this point." Palladium is still being designed.  I'd argue that the software/firmware portion is the trickiest to get right. It seems rational for Microsoft to let that design mature, then analyze the remaining hardware threats and turn the hardware engineers loose to try to plug Palladium has to be viewed in the larger context of a negotiation between Microsoft and Hollywood (I include here all the content owners: movie studios, recording industry, book publishers, etc. ). Hollywood would prefer a completely closed PC architecture, where consumers' use of the computer could be tightly monitored and controlled.  They perceive general purpose computing as we know and love it to be a mortal threat to their continued existence. Keeping the content of DVDs and future media locked up is not enough in their eyes. They want all material displayed to be checked for watermarks and blocked or degraded if the PC owner hasn't paid for the content.
Microsoft wants to preserve general purpose computing because it realizes that in a closed architecture, the OS would become a mere commodity component and the consumer electronics giants would eventually displace Microsoft. On the other hand, Microsoft needs Hollywood provide the kind of content that will drive PC sales and upgrades. The base line PC platform of today or even two years ago is powerful enough for most consumers and businesses. People are keeping their PCs longer and not upgrading them as often. Most everyone who wants a PC (at least in North America) already has one. Microsoft needs something new to drive sales.
I expect Microsoft and Hollywood to haggle over the final specs for Palladium PCs and no doubt additional hardware protection measures will be included.  The actual spec may well be kept secret, with NDA access only. Hollywood will hold two strong card at the table: its content and the threat of legislation.  I'm sure Senator Hollings is watching developments closely.
The big question in my mind is how to get PC consumers a place at the bargaining table. It seems to me that PC consumers have three tools: votes, wallets and technology. The Internet is well suited to political organizing. Remember the amount of mail generated by the modem tax hoax? Consumer boycotts are another powerful threat, given how powerful and upgradable existing computer already are. Technology can provide an alternative way to gain the benefits that will be touted for controlled computing.  Anti-virus and anti-DDS techniques come to mind. Also, since I expect an eventual push to ban non-Palladium computers from the Internet, alternative networking technology will be important.
The Palladium story is just beginning.
Arnold Reinhold

@_date: 2003-05-20 14:03:39
@_author: Arnold G. Reinhold 
@_subject: Taking aim at denial-of-service attacks 
One interesting aspect of using proof of work (POW) to protect against denial of service attacks is that it can be implemented and demonstrated without the need for widespread adoption. The basic idea (as I see it) is that the servers that handle end-user PCs have the ability to demand proof of work from the end users before accepting packets and give priority to the delivery of packets where required work has been demonstrated. Higher level servers then give priority to packets where POW has been demonstrated.
To establish an initial system, large user, such as the Federal Government, a large corporation or a consortium of universities, only has to insure that there is chain of POW-aware servers between several of its sites. The selected sites should then enjoy protection from DOS attacks for inter-site communications and this would be evident when such attacks occur. Additional sites could be added incrementally and, as long as proper standards are created and observed, different networks that adopt POW antiDOS can be linked merely by establishing a POW aware path between the nets. Since POWawareness would likely be just a software upgrade the technology should spread quite rapidly.
Arnold Reinhold
