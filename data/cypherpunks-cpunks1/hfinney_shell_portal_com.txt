
@_date: 1993-08-11 12:47:23
@_author: hfinney@shell.portal.com 
@_subject: Secure voice software issues 
A couple of comments on the cryptophone idea.
First, there has seemed to be general agreement in our earlier discussions
of this concept that the hard part is compressing the voice to the point
where it can go over commonly-available modems.  The government-standard
CELP algorithm is too slow for general-purpose home computers.  You need
an algorithm that can operate in real time and compress intelligibly down
to about 13K bits per second.  It has to be either able to compress and
decompress simultaneously or else you need some switching logic to decide
which person is talking and which is listening at each moment, with both
sides reversing roles in synchrony.
Second, Diffie-Hellman key exchange will probably take about as long as
an RSA decryption with similar modulus sizes.  So speed would not seem to
be a reason to choose DH over RSA for key exchange.  If PGP is slow on
your machine, DH will be, too.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-12 09:18:12
@_author: hfinney@shell.portal.com 
@_subject: ANONYMOUS CONTACT SERVICE 
A few months ago, someone subscribed to the list through the Penet service,
and it ended up revealing the Penet aliases of everyone who posted.  Each
post was delivered to that subscriber marked as being from the Penet alias
corresponding to the poster.  All it took was a parallel non-Penet subscription
to break the anonymity provided by Penet.
Has this now happened again?
At the time, there was some discussion about using "an..." versus "na..."
forms of the Penet aliases, one of which would avoid this revelation.  Has
that been taken care of?
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-12 09:18:20
@_author: hfinney@shell.portal.com 
@_subject: under pressure from University Computing svcs, 
It's too bad that this remailer is being shut down.  I posted a few days
ago about this problem, and someone asked if there had been any specific
examples of shutdowns.  Here is one; I know Matt's is not the first.
If it would help, Matt, I could provide you with code to act as a "second-
tier" remailer, one which would only forward to one of the other Cypherpunks
remailers.  No person would receive messages from your remailer, hence there
would be no complaints to your administration.  Your remailer would just be
an extra "entry port" into the Cypherpunks remailer system.
I don't know whether the terms of the shutdown of your remailer would allow
you to experiment with what is arguably a different piece of code, one which
would not lead to complaints.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-12 22:18:18
@_author: hfinney@shell.portal.com 
@_subject: Making the World Safe for Steganography 
I agree with Tim's suggestion that it would be good if steganography
and cryptography tools were widely available, especially in light of
the government's obvious hostility towards cryptography.
But I can't agree that these tools will be sufficient to bring about
Tim's concept of "crypto anarchy", of "libertaria in cyberspace".  If
we really want to achieve these goals I think it will be necessary to
take political action.  Technology alone will not be enough.
After all, even today techniques exist which would in principle allow
a digital cash system to develop.  Yet no such system exists.  There
needs to be an infrastructure, a network of bankers, sellers, users, and
other participants.  All this will take time to develop even in the best
of cases.
But if the government is actively fighting such technology, I don't
see how Tim's proposed subterfuges with DAT's and CD's are going to be
enough to overcome this additional barrier.  Without the ability to
publically negotiate the tricky issues of standards and contracts, I
don't see how a financial infrastructure of the sophistication needed
for digital cash could arise.
As another example, suppose the government banned non-Clipper cryptography.
Despite the brave comments of some, I think it would be very hard
to overcome such a ban.  Look at the problems PGP has had, faced merely
with the relatively weak threat of patent suits (patents which have not,
to my knowledge, been tested in court).  PGP is constantly being taken off
FTP sites based just on letters from the patent holders.  Even Tim himself
suggested some time back that Cypherpunks should rethink support for PGP
given the patent situation.  Imagine how much worse it would be if the
government actually could put people in jail for using PGP.
My main point is that we cannot rely on the technology to save us.  A
concerted government effort could, in my opinion, stifle the growth of
individual liberties that cryptography may offer.  Clipper is just one
battle in this longer war.  We can't afford to fall victim to a smug
confidence that victory will inevitably be ours.  If we get to the point
that steganography is the only way to communicate privately, we will have
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-15 11:21:56
@_author: Hal Finney 
@_subject: Electronic Democracy 
The one comment I'd make on the wolves vs sheep analogy is this.  In the
real world, there *are* wolves and sheep.  Violence and coercion are part
of life.  Democracy, in a sense, recognizes the power implicit in large
numbers of people.  If they can't vote, they may revolt.  No libertarian
government will survive without the acceptance of the masses.
A populace willing to countenance a Libertarian society would perhaps be
wise enough to be entrusted with democracy, anyway.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-15 11:22:00
@_author: Hal Finney 
@_subject: Which remailers are up & working? 
I just updated the version of PGP on my remailers at Caltech and Portal
to use version 2.3a.  It turns out that, starting with version 2.3,
PGP by default creates messages that are not readable by versions
before 2.2.  2.2 can read the 2.3 messages, but 2.0 and 2.1 cannot.  I
was running 2.1 so I wasn't able to process messages created with 2.3.
If anyone else is running PGP versions before 2.2 on their remailers they
should upgrade them.
I just did a non-encrypted ping test to a list of remailers, and heard back
from the following remailers within 2 minutes:

@_date: 1993-08-15 11:22:01
@_author: Hal Finney 
@_subject: Cypherpunk trends & visions 
I have a shorter-term focus than Nick's proposals for digital coupons
and cash.  Here's what would be on my cypherpunks wish list:
Improved remailers:  The ability to handle reply messages; the ability to
Remailer standards:  An ad hoc assertion of standard remailer commands
Remailer proliferation:  Build remailer software into some widely used
Digital cash:  We badly need some implementation to start playing with;
DH:  I'd like to see more DH-based comm software so I can log in from
Cryptophones:  PC/Soundblaster or Mac based encrypted comm software using
This is a fairly daunting list, of course, but perhaps we should re-orient
ourselves to be a working group more than a debating group.  Split off
sub-groups, get people to volunteer for each one, put one person in charge,
have him make weekly or monthly reports to the main group.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-16 23:20:09
@_author: hfinney@shell.portal.com 
@_subject: CRYPTO'93, anyone here going? 
I happen to live in Santa Barbara, and although I am not signed up for
the conference (too busy at work) I am hoping to drop by and crash a
session or two.  Hopefully I'll be able to meet some other list members
while they are there.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-16 23:20:25
@_author: hfinney@shell.portal.com 
@_subject: PROTOCOL: Encrypted Open Books 
Eric had some good ideas in his protocol for verifying anonymous bank
deposits.  One thing wasn't clear to me: what if the bank creates
a fake account?
It would seem that the bank could explain away a sudden decrease in its
asset reserves (money that the bank officers actually spent on mistresses
and drugs) by creating a fake anonymous account which made a large with-
drawal.  The books would still balance.
It wasn't clear to me in Eric's protocol whether it would be expected that
the identity of accounts which made such withdrawals would be revealed.
Doing so would seem to go against the purpose of the digital bank.  But
without that ability it would seem that fake accounts could cover up any
amount of mismanagement.

@_date: 1993-08-17 22:20:29
@_author: hfinney@shell.portal.com 
@_subject: Digital cash references 
I got asked what would be good survey articles on digital cash.
Two good ones that are widely available are both by David Chaum:
Scientific American, August 1992, p. 96; and Communications of the ACM,
October 1985, p. 1030.
Unfortunately, neither of these really describes the mathematics,
instead discussing things in terms of analogies.  To get more details
you have to read the conference proceedings.  Many of the recent
Eurocrypt and Crypto conferences have discussed implementations of
digital cash.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-17 22:20:35
@_author: hfinney@shell.portal.com 
@_subject: [ari@ISI.EDU: New paper on electronic currency] 
I just ftp'd, printed, and read the paper which Derek mentioned:
  NetCash: A design for practical electronic currency on the Internet    by Gennady Medvinsky and Clifford Neuman
I didn't think it was any good.  They have an incredibly simplistic
model, and their "protocols" are of the order, A sends the bank some
paper money, and B sends A some electronic cash in return.
They don't even do blinding of the cash.  Each piece of cash has a
unique serial number which is known to the currency provider.  This would
of course allow matching of withdrawn and deposited coins.
"In particular, at the point that a client purchases coins from a
currency server by check, or cashes in coins, it is possible for the
currency server to record which coins have been issued to a particular
client.  It is expected that currency servers will not do so, and it
is likely that the agreement with clients will specifically preclude it."
Right.  It is expected that they will not do so.  I feel so much better now.
These guys seem to have read the work in the field (they reference it)
but they don't appear to have understood it.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-18 23:20:46
@_author: hfinney@shell.portal.com 
@_subject: Physical to digital cash, and back again 
Anonymous points out problems with managing and using digital cash:
It's true that this is a lot of steps.  This is one reason why we should
push to make anonymous mail easy to use.  If you start with an infra-
structure where you can communicate securely and anonymously across the
net, with return messages that don't reveal your true identity, you have
a good start on steps 1 and 2 above.
Another simplification would be to split the users of the digital cash
into customers and vendors, along the lines of the triangle diagram Tim
suggested.  In my experience, I make many withdrawals from my bank, but
often only two deposits a month as my paycheck comes in.  Applying this
to the digital bank model, customers would mostly make digital cash with-
drawals to buy things on the net, with occasional physical cash deposits
to keep their balance up. Customers would thus primarily turn real cash
into digital cash which they send to vendors; the vendors then turn the
digital cash back into real cash.  Customers can remain anonymous even
without physical mail drops, while vendors have less anonymity.
In this model, a customer sees some new software being sold on the
net.  He normally keeps enough digital cash on hand for such spending,
so he sends the cash to the seller, including one of his standard anonymous
return addresses for the return software.  If this lowered his stock of
digicash below the amount he likes to keep around, he sends another check
to the bank and gets another batch of digicash.
(This would be analogous to carrying cash in your wallet, and when it
gets low you stop by the ATM and withdraw more.  How often do you find
yourself depositing cash back into the ATM?  I suspect customers of the
digital cash bank would similarly not need to turn their digicash back
into real dollars very often.)
With an infrastructure like this, using digital cash does not have to be
I once posted some excerpts from the Code of Federal Regulations involving
the tax requirements of barter agencies.  These are organizations in
which their members exchange their labor without the use of regular
cash.  Often they use some scrip as a substitute for cash, or they may
just keep records in an accounting system.  It appeared to me that
virtually any form of digital cash would fall under this definition.
Barter agencies are not illegal, but there are many rules about reporting
transactions and members.  It would definately not be possible under the
current tax code for a barter agency to have anonymous members.  Therefore
it looks like anonymous digital cash would not be legal in the U.S. at
this time.  I don't know about Duncan's suggestion to use an offshore bank.
Paul Robichaux wrote, regarding the NetCash proposal:
Actually, blinding can do better.  Collusion between the bank and the
vendor can not break customer anonymity in a cash system using Chaum's
blinding protocols.  This is one of the things I found so surprising
about the NetCash proposal.  I am surprised they dare to call their
idea an implementation of digital cash when it does not even provide
this bare minimum of customer anonymity.  This anonymity is why we call
it "cash", as distinguished from other forms of money.  The NetCash
proposal is more like cashier's checks.
This is a good point, and is another reason why blinding is so important.
If you don't mind it being known in general terms that you are a customer
of the bank, you can send a check with instructions to turn it into digital
cash to be sent to your email address.  There will still be no way that
the bank can figure out when or where you spend that digital cash.  And
they are no more likely to just cash your check and pocket the money than
any other mail order business would be.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-19 22:50:51
@_author: hfinney@shell.portal.com 
@_subject: Encrypted cypherpunks list 
A reminder to old subscribers, and a notice to new:  I have some software
running on this system (related to the remailer software) which can be
configured to send a PGP-encrypted version of the list to subscribers.
This way you can receive this "subversive" material without any local
system operators knowing what you are doing.
Send me your address and PGP public key if you'd like to be put on the
encrypted list.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-19 22:51:38
@_author: hfinney@shell.portal.com 
@_subject: Physical to digital cash, and back again 
I agree with Anonymous that there are problems with the actual use of
digital cash in the near term.  But it depends to some extent on what
problem you are trying to solve.
One concern I have is that the move to electronic payments will decrease
personal privacy by making it easier to log and record transactions.
Dossiers could be built up which would track the spending patterns of
each of us.
Already, when I order something over the phone or electronically using
my Visa card, a record is kept of exactly how much I spent and where I
spent it.  As time goes on, more transactions may be done in this way,
and the net result could be a great loss of privacy.
Paying in cash is still possible through the mail, but it is insecure and
inconvenient.  I think that the convenience of credit and debit cards will
overcome most people's privacy concerns and that we will find ourselves
in a situation where great volumes of information exist about people's
private lives.
This is a place that I could see digital cash playing a role.  Imagine a
Visa-like system in which I am not anonymous to the bank.  In this model,
imagine that the bank is granting me credit similar to a credit card.
But instead of giving me just an account number which I read over the phone
or send in an email message, it gives me the right to request digital cash
on demand.
I keep some digital cash around and spend it for transactions as I described
in my previous posts.  When I get low I send some email to the bank and get
some more dcash.  Every month I send a check to the bank to cover my account
just as I do with my credit cards.  My relations with the bank are very
similar to my current relationships with the credit card companies: frequent
withdrawals and a single payment each month by check.
This has several advantages over the system which we are heading towards.
No records are kept of where I spend my money.  All the bank knows is how
much I have withdrawn each month; I may or may not have spent it at that
time.  For some transactions (e.g. software) I could be anonymous to the
vendor; for others the vendor might know my real address, but still no central
location is able to track everything I buy.
(There is also a security advantage over the ridiculous current system in
which knowing a 16 digit number and an expiration date allows anyone to
order anything in my name!)
Furthermore, I don't see why this system could not be as legal as
current credit cards.  All that really differs in this system is the
inability to track where users spend their money, and as far as I know
this ability was never an important legal aspect of credit cards.
Certainly nobody will admit today that the government has a vested interest
in moving towards an environment in which every financial transaction is
Granted, this does not provide full anonymity.  It is still possible to see
roughly how much each person spends (although nothing stops a person from
withdrawing much more cash than he will spend in a given month, except per-
haps for interest expenses; but maybe he can lend the extra digicash itself
and gain interest on that to compensate).  And it is oriented around the same
customer/vendor model that Anonymous criticized.  But I maintain that this
model represents the majority of electronic transactions, today and in the
near future.
It's worth noting that it is not trivial to become a merchant who can
accept credit cards.  I went through this with a business I had a couple
of years ago.  We were selling software through mail order, and this makes
the credit card companies very nervous.  There is so much phone fraud in
which credit card numbers are accumulated over a few months, then large
amounts of charges made against them.  By the time the user receives his
monthly statement and complains, the vendor has disappeared.  In order to
get our credit card terminal we went to a company which "helps" startups
with this.  They seemed like a pretty shady outfit, themselves.  We had to
fudge our application to say that we'd be selling something like 50% of
the units at trade shows, which apparently counted as over-the-counter sales.
And we had to pay about $3,000 up front, as a bribe, it seemed.  Even
then we probably couldn't have done it if we hadn't had an office in the
business district.
Under the digital cash system, this might be less of a problem.  The main
problem with digital cash is double-spending, and if you are willing to go
with online verification (reasonable for any business which is going to take
anything over several hours to deliver the merchandise) this can be
completely prevented.  So there is no longer any possibility of merchants
collecting credit card numbers for later fraud.  (You still have problems
with non-delivery of merchandise, though, so not all risks are eliminated.)
This might eventually make the system more widely available than current
credit cards.
I don't know whether this system could be used to support illegal actions,
tax evasion, gambling, or whatever.  That is not the purpose of this
proposal.  It does offer the prospect of improving personal privacy and
security, in a framework that might even be legal, and that's not bad.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-20 22:52:01
@_author: hfinney@shell.portal.com 
@_subject: anonymus@charcoal.com is going away 
It does not really surprise me that Kleinpaste is shutting down his
server.  He always seemed to be a weak supporter of anonymity, IMO.
I remember how he was one of the loudest complainers when the contro-
versy arose over Julf's anonymous remailer.
This is how I would have handled the situation.  If the sysop of this
system sent mail to me (he couldn't get my phone number, I don't think),
asking whether so-and-so sent mail to such-and-such, I would only be
able to say, "I haven't the faintest idea."  I don't keep logs, and one
of the reasons I don't is so that I have no expectation of being able
to answer such questions.
What I would then do is to ask the sysop for the addresses which are
receiving the objectionable mail, and I would add them to my "blocked"
list, so that my remailer would no longer send mail to those individuals.
They would then have no more reason to complain to me.
All mail from my remailer includes a header message telling people that
they should complain to me if they get objectionable mail.  In the several
months that I have been running my remailer, only one person has asked to
have his name blocked.
Parenthetically, this incident shows the value of remailers which add some
delay to the message forwarding process.  This would then make it harder
to correlate the arrival of anonymous mail with the transmission of mail
from a particular user.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-23 10:35:19
@_author: hfinney@shell.portal.com 
@_subject: Chaum on the wrong foot? 
A lot of our discussion is influenced by the ideas of David Chaum.  He
pioneered technology which could protect individual privacy while allowing
very flexible sorts of credentials and guarantees.  He has also played
a big role in the various proposals for digital cash.
But I think that Chaum has gone off in the wrong direction in the last
few years.  More and more he is concentrating on protocols which rely
on a tamper-proof, hardware implementation of a cryptographic protocol
which he calls an "observer".  This observer chip would sit in your
computer (which could be a Newton-style PDA or a smart card) and would
play an important part in the exchanges of information, cash, or credentials
which you would make with others.  The observer basically makes sure you
are telling the truth in your transactions, that you are not double-spending
your digital cash, or not claiming a credential which you don't have.
Now, this approach has the obvious advantage that it allows solving
certain problems which can't be solved otherwise.  There appears to be
no way to provide for secure, off-line digital cash, for example, other
than with something like an observer.
But it has the equally obvious problem of relying on a tamper-proof
chip as a necessary part of the protocol.  Recently it seems that many
of the papers out of his group are designed to explore observer-based
protocols.  This means that these ideas are not useful for software-only
implementations.  One of the (relatively few) strengths that we and the
forces we represent have is that free software can be spread very far
and very fast, making it hard for those opposed to privacy to successfully
stop our efforts.  Any technology based on special chips is going to
lose these advantages.
Another problem with the observer is psychological.  Although Chaum goes
to great lengths to design his cryptographic protocols so that even a
cheating observer can learn effectively NOTHING about the computer user
that would compromise his privacy, people may still feel uncomfortable
about having a mechanical "conscience" in their pocket.  People want to
feel in control of their computers, and I think supporting this control
is a big part of the Cypherpunks philosophy.
A related point is that there have already been comparisons on sci.crypt
between Chaum's observers and the Clipper chip, in that both rely on
tamper-resistant technology to implement features which are not entirely
in their owner's best interests.  Assuming we do manage to successfully
defeat Clipper, the taint of this association may increase resistance to
I wish Chaum and his group would stop directing their efforts towards
protocols which require an observer chip to be effective.  Granted,
there are some things that don't work as nicely without observers.  But
I think that a realistic appraisal of the pros and cons suggests that
non-observer protocols are more likely to further our ultimate goal of
personal privacy.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-23 10:36:21
@_author: hfinney@shell.portal.com 
@_subject: Attacks on remailers 
Chaum, in his first paper on "Mixes" (anonymous remailers) described
protocols which were designed to resist several attacks.  (See the
February, 1981, Communications of the ACM, p. 84.)  These can
be understood by considering a series of attacks of increasing sophis-
tication, with corresponding responses.
Our opponent has as his goal to track a message through a chain of
Attack 1: Just intercept the message from the sender, and look at the
commands of the form:
Request-Remailing-To: first-remailer
Request-Remailing-To: second-remailer
Request-Remailing-To: final-destination
The final command shows where the message is finally going to go.
Response: Encrypt the messages.  Use "nesting", so that all that is
visible as each message leaves a remailer is the destination of the
next remailer.
Attack 2: Look at the mail logs on the system running the remailer to
see which message goes out from the remailer account shortly after each
message comes in.
Response: Run the remailer on a machine which does not keep mail logs,
or on a machine to which you can deny the attackers access.
Attack 3: Monitor the messages in real time as they flow into and out of
each remailer machine, again looking for the message which comes out
just after each incoming message.
Response: Batch up many messages which arrive over a period of time,
only sending them out at regular intervals or when a certain number have
accumulated.  Send them out in random order.  Alternatively, delay each
message by a random amount of time before the message goes out.  (This
response will also deal with the previous attack.)
Attack 4: Look at distinguishing features of the messages which are
preserved by the remailers, such as subject line or message size, to
match up incoming and outgoing messages within each batch.
Response: Do not retain any header fields through remailers, not even
subject.  Use an encryption mode in which messages are rounded up to
some standard size so that all messages appear to be the same size.
Attack 5: Record an incoming message to the remailer, and insert a copy
of it into the incoming message stream, so that the batch will have two
identical messages.  Look for two identical outgoing messages.  Remove
one.  This is the match to that incoming message.
Response: Check for duplicate incoming messages in the remailer, and
remove all but one copy of each duplicate.
Attack 6: Insert a duplicate message multiple times in separate batches.
Observe the outgoing batches and look for a pattern of destinations
which are correlated with those batches in which the incoming message
is inserted.
Response: Check for messages which have been duplicated from earlier
batches and remove them.  Include time/date stamps on incoming messages
with a time limit so that they are no good after a certain number of
days; this way the check for duplicates only has to go back that many
Attack 7: Look at all messages coming out of the first remailer, and
follow them into their 2nd remailers; take all messages from those and
follow them on, and so on.  This will eventually lead to a number of
destinations, one of which must have been the destination of the original
message.  Over a period of time, look for correlations between destinations
and sources.
Response: Use large remailer chains of popular remailers.  With enough
mixing at each stage of the chain, the number of possible destinations
will become astronomically large, making correlations statistically
Attack 8: Correlate messages being sent from person A with messages being
received a certain time later by person B.  Even without the ability to
track messages through the remailers this can show a communication pattern.
Response: Send dummy messages at regular intervals, which bounce through
the remailer network and then die.  When you have a real message to send,
replace one of the dummies with this.  The sender's traffic pattern is
then constant and no information can be gained from it.
Attack 9: Bribe or coerce one or more remailer operators into revealing
their keys, or into decrypting the desired messages.  Alternatively, run
many remailers, pretending to be dedicated to privacy, while secretly
gathering information on the messages.
Response: Use many remailers in a variety of geographical locations, so
that it is unlikely that all of them can be corrupted in this way.
These are all the attacks I can remember being implicitly considered in
Chaum's paper.  Other people who have ideas for attacks should mention
them so we can think of responses.
Chaum also discusses anonymous return addresses.  We have a simple form
of these enabled in our encrypting remailers.  The idea is to encrypt
a series of remailing requests for the path the message will follow,
with the last request directing the message to the user whose anonymous
address this is.
Some more attacks are possible in this case:
Attack 1A: Look at the message content as it passes through each remailer,
to correlate incoming and outgoing messages.
Response: Encrypt the message at each stage to prevent this matching.  This
raises the problem of how to determine the encryption key in such a way
that the final user can decrypt the message.  Chaum suggested including the
encryption key in the anonymous address (a different key at each stage
of the chain), so that the user can decrypt the message.  Eric Messick
has proposed letting the remailer choose the key, with a protocol for the
user to communicate again with the remailer to get the message decrypted.
Attack 1B: Send two different messages to the same return address with
different contents, and look for duplicate address blocks in the outgoing
Response: Apply some randomization to the address blocks at each stage so
that messages to the same address don't look identical.  (Chaum did not
give this solution, as he viewed the next attack as being essentially
Attack 1C: Send many addresses to the anonymous address, and look for a
destination which receives that many messages in a correlated fashion.
Response: Chaum's response is that the remailer must not accept more than
one message with a given anonymous return address, just as it must not
accept more than one copy of a message in the regular case.  This implies
that anonymous return addresses must be use-once to be truly secure.
This conclusion is uncomfortable, as the requirement that an address be
use-once will severely impair its usability.  But this attack appears
hard to avoid.
There is always the possibility of giving up on anonymous addresses in
the Chaumian sense, and instead using other ideas which have been
suggested here, such as posting to newsgroups, or message broadcast
pools.  All of these ideas have the problem that they expose everyone
in some group to all of the messages intended for every group member,
hence the number of messages will scale as the square of the number of
group members.  This will quickly become unmanageable for large groups,
therefore providing only a limited amount of anonymity.
It's also worth noting that our remailers are vulnerable to almost all
of these attacks; at best we are safe against two or three of them.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-26 22:22:41
@_author: hfinney@shell.portal.com 
@_subject: Attacks on remailers 
This seems like a good idea.  Note that on the ftp site there are scripts
and a program which will set up a chained remailing if you are willing
to type in the names or numbers of the remailers to use.  Extending
these to use a random route or set of hops would not be a major job.
More and more I think this would be a good idea.  People are always
complaining about temporary "down time" among the remailers.  Perhaps
someone could run a service which would run every night, ping all the
remailers, and keep a file with a list of those remailers which have
responded in the last 24 hours.  This file could be made available by
finger, ftp, or some other method.  Perhaps someone could volunteer to
write such a beast?  This is another project that seems doable in a
moderate amount of time.
Putting these two together, as Sam suggests, would produce a more robust
and convenient way of using the remailers.
Nice ideas, Sam.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-26 22:23:09
@_author: hfinney@shell.portal.com 
@_subject: Viacrypt PGP source code unavailable 
I spoke briefly with Phil Zimmermann about the ViaCrypt deal this
afternoon.  He explained, as I understood it, that the company was
contractually obligated to use their own version of the RSA library.
This code is apparently proprietary and so the source is not currently
planned to be released.  Phil indicated, though, that he will discuss
this issue with ViaCrypt, and hopefully some solution can be found which
will satisfy users.
It was not clear to me whether the random-number code from PGP would be
retained.  I suspect that it will be, though, which would mean that if
you started with identical randseed.bin files, and RSA-encrypted identical
files, that the two programs should produce identical output.  PGP uses
the contents of this file to initialize its random number generator.
(PGP does put some random data at the beginning of the plaintext before
encryption, as was described; this is to make cryptanalysis harder, since
the first few bytes of the plaintext will not be known.  Again, this
random data is based on the contents of the randseed.bin file.)
To address a few other points that were made:  Phil reiterated his strong
committment to keep the freeware version of PGP at least as up-to-date as
the commercial version.  This is not a case where the freeware version will
be left to languish.  In fact, Phil expects the commercial version to be
based on the freeware version, with advances occuring first in the freeware
As to whether individuals will pay $100 or more for a legal version, that
remains to be seen.  In some ways the same question can be asked about many
commercial packages, for which pirated versions are available for free
from friends or user groups.  Yet still some people pay for software because
they feel better using a legal version.  People who feel this way would
perhaps also prefer a legal version of PGP.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-26 22:23:12
@_author: hfinney@shell.portal.com 
@_subject: Digital Gold, a bearer instrument? 
][adon Nash's digital gold concept is interesting, however I think it is
harder to use than existing cash systems in the literature.
In order to know whether to accept a given piece of digital gold in payment
for a product or service, a vendor must check a central database which
records all transactions anywhere in the world.  It must trace through
the chain of possession for that piece of digital gold in order to verify
that the ownership is legitimate.
In particular, if the person passing the gold is a cheater he may be spending
it twice, perhaps very close together in time.  This means that the database
must be updated and checked in real time.
This is the same communications requirement for the simplest form of
digital cash based on Chaum blinded signatures.  We have discussed this
cash several times on this list.  It is basically just an RSA-signed
certificate from a trusted bank, but one which has had the "blinding"
technique (which Karl has been describing) applied so that the bank won't
recognize the cash when it is returned.  For a vendor to know whether
to accept a digital coin, he has to check with the bank to make sure the
coin hasn't been spent before.  This is analogous to ][adon's check of
the gold-claim database.  The bank's job seems somewhat easier, as it
just has to look up whether the coin's number is present in a list.
Also, Chaum provides "offline" variants on his system in which the vendor
just trusts the person passing the cash, because he knows that if the
customer cheats, his anonymity will be automatically broken and he can be
sued.  It's not clear how the digital gold approach could provide any
such generalization.
As for the notion of transferring assets from person to person, using
aliases to provide for privacy, this has been discussed by Barry Hayes
in Anonymous One-Time Signatures and Flexible Untraceable Electronic
Cash, in the AusCrypt proceedings.  He describes a system, in some ways
an elaboration of Chaum's ideas, which works like checks which get
endorsed from person to person.  Just the other day I got a check which
was made out to person A but endorsed over to me.  I could endorse it
over to someone else if I want.  This chain can continue until someone
cashes it.  Hayes's system, like Chaum's, retains anonymity as long as
no one cheats.  If someone tries to pass the same check twice, their
identity will be revealed.
It's too bad that these papers aren't more widely available.  The math is
not that complicated.  If you can understand RSA, you can understand
digital cash, at least the simpler systems.  But the papers are mostly
only in the crypto proceedings, and not all libraries have them.
I have to say, though, that although I don't really think the digital
gold proposal is technically feasible, the proposal to own numbers shows
tremendous chutzpah and is quite creative.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-08-26 22:25:53
@_author: hfinney@shell.portal.com 
@_subject: Attacks on remailers 
As I indicated in my long posting, it is not necessary to send out the
same message that was received.  Chaum proposed encrypting the message
(the non-address-block portion) with a secret key at each stage, a key
which would be revealed to the remailer (along with the address of the
next address in the chain) when it peeled off its own layer of encryption.
If no encryption is done on the message body, there is another attack for
this case that I didn't mention.  It is:
Run a remailer.  For every anonymous address floating around on the net,
try sending a message to it.  Look at the messages which pass through
your own remailer and look for matches to the message you sent.  Any
anonymous address which includes your remailer as one of the elements
will pass through you.  You have then defeated all of the stages of the
chain before yourself.  In particular, if you happen to be the last remailer
of the chain, you have broken the anonymity of the anonymous address.
This attack, while not the most powerful on the list, defeats many of the
principles of remailer chains, such as that the chain is as strong as
its strongest link.  It requires you to strongly trust at least one
remailer in the chain (the last one), whereas without this attack you
would not have to especially trust any single remailer.  So it is sig-
Diffie-Hellman encrypting messages between remailers would not help against
this attack.
Also, rather than DH it would be just as effective to use the public key
of the next remailer in the chain, and more convenient: some remailers are
not able to participate in TCP exchanges, being connected to the net
by occasional uucp connections.
This lack-of-TCP problem also impacts the proposal to use a public telnet
port for message communication.  Another problem with that proposal is
that it would need the remailers to run as background processes.  With the
current software they can run as mail filters, which makes them much
less conspicuous to system managers.
The suggestion for remailers to send messages by telnet connection to
port 25 of some other machine (rather than by piping to sendmail as they
currently do) is perhaps reasonable (for those systems with TCP access),
although it makes the remailer somewhat harder to set up since you have to
find some other machine which will let you connect to their port.  Also,
I think some machines may log incoming or outgoing telnet connections to
this port, since it is a common technique for mail forgeries.  I have heard
that most systems will actually not allow public telnet connections to
this port.
I don't know that much about how widely available telnet and other TCP/IP
services are on the net, so if these techniques are more usable than I
am suggesting I'd like to hear about it.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-12-02 08:32:36
@_author: Hal Finney 
@_subject: NSA Insecure Remailers 
As Tim says, it is no secret on this list that the remailers are not
presently secure.  I posted a long message a few months ago outlining
possible attacks on the remailers.  It's worth noting that Karl Barrus'
remailer does batch up messages and send them out once a day.  If enough
people use it that will help mix them up.  There is still the message size
to match them up, though (and, believe it or not, the Subject: line!).
Karl is working on padding code.
Really, fixing these problems is not hard.  There will be some penalties
in terms of usability of the systems.  Subject lines will have to be
embedded in the encrypted message blocks, so the software which sets up
cascaded message commands will need to do this.  More intrusively, I think
all messages will have to be padded to be the same size everywhre in the
remailer network.  We need to pick a size large enough to accomodate most
messages yet not so large that padding all messages to that size will be
too expensive or wasteful.  Then messages bigger than that size will either
be rejected or at least some warning given to the user that his message will
be trackable.
The traffic volume problem should be solved by having a source of random
messages which traverse the network, mixing in with user messages.  This
will help, but you still have the problem that only user messages will leave
the network.
The biggest problem is that many remailers are on unsecure systems.  The PGP
keys and passwords for these remailers are on the disk IN THE CLEAR.  Anyone
who can get privileges on these systems (many hackers, these days, not to
mention the NSA) can get the remailer's keys and decrypt any messages sent
to those remailers.  Karl's monthly posting shows which remailers are on
private machines; those are the only ones which have any hope of being secure
against the NSA.
As I said, I think most of these problems are fixable, or at least can be
significantly improved.  Perhaps after the holidays interested parties can
set up a sub-list to discuss "Mark II" remailers which will more closely
approximate Chaum's vision.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-12-04 15:23:06
@_author: Hal Finney 
@_subject: Anonymity Offense 
FYI, here is the number of remailed messages passing through my remailer
for the past couple of months.  The first number is the number of messages
on that day, and the remainder of the line is the date.
   2 Sun Oct  3
   3 Mon Oct  4
   8 Wed Oct  6
   1 Thu Oct  7
   3 Fri Oct  8
   1 Sun Oct 10
   1 Tue Oct 12
   1 Thu Oct 14
   1 Fri Oct 15
   2 Mon Oct 18
   8 Tue Oct 19
   1 Wed Oct 20
   3 Thu Oct 21
   2 Fri Oct 22
   1 Sat Oct 23
   1 Sun Oct 24
   5 Mon Oct 25
   3 Tue Oct 26
   9 Wed Oct 27
   5 Sat Oct 30
   2 Wed Nov  3
   3 Thu Nov  4
   1 Fri Nov  5
   8 Sat Nov  6
   1 Sun Nov  7
   9 Mon Nov  8
   3 Tue Nov  9
  10 Wed Nov 10
   7 Thu Nov 11
   4 Fri Nov 12
   1 Sat Nov 13
   7 Sun Nov 14
   4 Mon Nov 15
   5 Tue Nov 16
   6 Wed Nov 17
  26 Thu Nov 18
   1 Fri Nov 19
   9 Sat Nov 20
   6 Sun Nov 21
   2 Mon Nov 22
   4 Wed Nov 24
  16 Fri Nov 26
  10 Sat Nov 27
  54 Sun Nov 28
  37 Mon Nov 29
  36 Tue Nov 30
  33 Wed Dec  1
  18 Thu Dec  2
  19 Fri Dec  3
  18 Sat Dec  4
Here is the corresponding table for just encrypted messages.  These are
included in the counts above.
   2 Sun Oct  3
   3 Mon Oct  4
   2 Wed Oct  6
   1 Thu Oct  7
   1 Fri Oct  8
   1 Thu Oct 14
   1 Tue Oct 19
   1 Wed Oct 20
   3 Thu Oct 21
   1 Fri Oct 22
   3 Sat Oct 23
   1 Sun Oct 24
   5 Mon Oct 25
   3 Tue Oct 26
   9 Wed Oct 27
   4 Sat Oct 30
   1 Wed Nov  3
   1 Fri Nov  5
   3 Sat Nov  6
   3 Mon Nov  8
   2 Tue Nov  9
   4 Wed Nov 10
   2 Thu Nov 11
   1 Fri Nov 12
   1 Sat Nov 13
   1 Mon Nov 15
   1 Tue Nov 16
  13 Thu Nov 18
   4 Sat Nov 20
   3 Sun Nov 21
   2 Wed Nov 24
   1 Thu Nov 25
   8 Fri Nov 26
   6 Sat Nov 27
  20 Sun Nov 28
  22 Mon Nov 29
  20 Tue Nov 30
  23 Wed Dec  1
  11 Thu Dec  2
   5 Fri Dec  3
   4 Sat Dec  4

@_date: 1993-12-04 23:09:37
@_author: Hal Finney 
@_subject: Anonymous Digicash 
Mike Ingle asks about digicash.  The simplest system I know of that
is anonymous is the one by Chaum, Fiat, and Naor, which we have discussed
here a few times.  The idea is that the bank chooses an RSA modulus,
and a set of exponents e1, e2, e3, ..., where each exponent ei represents
a denomination and possibly a date.  The exponents must be relatively
prime to (p-1)(q-1).  PGP has a GCD routine which can be used to check
for valid exponents.
As with RSA, to each public exponent ei corresponds a secret exponent
di, calculated as the multiplicative inverse of ei mod (p-1)(q-1).  Again,
PGP has a routine to calculate multiplicative inverses.
In this system, a piece of cash is a pair (x, f(x)^di), where f() is a
one-way function.  MD5 would be a reasonable choice for f(), but notice
that it produces a 128-bit result.  f() should take this 128-bit output
of MD5 and "reblock" it to be an multi-precision number by padding it;
PGP has a "preblock" routine which does this, following the PKCS standard.
The way the process works, with the blinding, is like this.  The user
chooses a random x.  This should probably be at least 64 or 128 bits,
enough to preclude exhaustive search.  He calculates f(x), which is
what he wants the bank to sign by raising to the power di.  But rather
than sending f(x) to the bank directly, the user first blinds it by
choosing a random number r, and calculating D=f(x) * r^ei.  (I should
make it clear that ^ is the power operator, not xor.)  D is what he
sends to the bank, along with some information about what ei is, which
tells the denomination of the cash, and also information about his account
The bank debits his account for the amount corresponding to exponent ei,
and signs D by raising it to the power di.  This leads to
E = f(x)^di * r, which is what the bank sends back to the user.  The
user divides E by r (this is done by calculating the multiplicative inverse
of r modulo the bank's modulus, and multiplying E by that), giving C=f(x)^di.
The user can then create the actual coin as (x, f(x)^di).  This should
also have some information appended to it to remember what exponent was
used (what denomination this is), so it would actually be (ei, x, f(x)^di).
There are some complications in this system.  The user may want to withdraw
several coins at once, and when he gets back the E values he needs to know
which is which (so he knows which r to divide by for each one).  So he
may want to include some unique tag with his D values he sends to the bank
and get the bank to send those back with the E values so that he can
distinguish them.
The bank will not recognize the coins (ei, x, f(x)^di) when they are
deposited (returned to the bank), due to the blinding.  But it will need
to keep a list of all the x values it has seen so far so that it can detect
double-spending.  If the ei values encode not only denominations but also
issue dates at some level, and if the cash is given a limited lifetime,
the list can be purged of old values periodically.
I do think a prototype digital cash system would not be too hard to do.
It would not have to address all of these problems right away.  The
larger problem is how to experiment in a meaningful way with diigicash
due to the difficulty in giving it value.  We've talked about this problem
before but I haven't seen any really good solutions.  Karl Barrus tried to
start up a non-anonymous cash system some months ago but there was nothing
to spend it on.  (Actually, he does have a remailer which uses his cash,
but since other remailers are free that has probably limited interest in
the for-pay remailer.)
I am continuing to work on a simple TCL interface to much of the PGP
functionality which would be needed for such a system (and for other
types of experimentation).  I have the MP library done, so the additional
entry points needed would include the MD5 one-way function, the random-
number generation, and the reblocking.  Perhaps in another week I will
have those hooks in place.  Then you could write the control software
in TCL, which would be easier for prototyping purposes since it's
Hal Finney
hfinney at shell.portal.com

@_date: 1993-12-06 08:45:01
@_author: Hal Finney 
@_subject: Authorized cash? 
I recall a few months ago there was some discussion of having David
Chaum come out and work with some cypherpunks to get them started on
an implementation of digital cash.  Did anything ever come of that?
Chaum has a patent, I've heard, on the "blinding" that is an important
part of at least the simpler cash proposals.  If he were willing to
authorize a cypherpunks cash system it would remove one legal hurdle
to its implementation.  Does anyone know whether he might be willing to
do this?

@_date: 1993-12-06 22:33:24
@_author: Hal 
@_subject: Name for crypto cash 
I thought of a new name today for digital cash: CRASH, taken from
CRypto cASH.  "How much crash have you got in your account?  Can we FTP
this GIF?"  "Not enough... Hey, can I borrow some crash?"  It has a nice
cyberpunk sound to it.  I don't know if we need a name for the units,
or if we could just get by without.
One of the lessons of the CP publicity is that having a sexy name is
a big plus.
(Apologies if I'm unknowingly regurgitating someone else's idea!)

@_date: 1993-12-07 08:20:19
@_author: Hal 
@_subject: digicash 
The point is not that B. Dolan's proposed cash is bad, it is that better
systems exist.  Chaum's blinded c{sh is simiXoar to Dolan's proposal, but
with the added feature that the "passwords" that~r authorize access to
the bank account can be altered by the users so that the bank does not
recognize them later, while still allowing the bank to verify that the
"passwords" are valid.  This eliminates the trackability allowed by Dolan's
(Sorry about the line noise!{

@_date: 1993-12-30 15:58:16
@_author: Hal 
@_subject: Trapdoor vs. Escrow 
I think the term "trapdoor" in this context merely refers to known
characteristics of the Clipper chip and does not imply any additional
abilities to decrypt messages other than what has been revealed.
A "trapdoor" is generally some secret which allows you to decrypt
messages which could not be decrypted without the secret.  It is
normally applied in the context of one-way functions but I suppose
an encryption system could be thought of as one-way.  In this case
I think the trapdoor may just refer to the Law Enforcement field
which, upon decryption, allows information to be recovered so that
the message can be read without the user's cooperation.
The comment about the trapdoor issue being independent of the escrow
issue harked back to Denning's original suggestion, which was that all
users of encryption would have to escrow their keys with the government.
This could be done in the context of any cryptosystem, such as DES or
RSA.  The trapdoor makes the system more convenient for users, hence
perhaps more acceptable.  But the escrow provision is the aspect that
the government really cares about.
BTW, there were some comments on sci.crypt about how this review document
showed that the government was not as opposed to our views as had been
thought.  On the contrary, my take was that this document reflected
something of a maverick view, one which was not politically acceptable
with those in authority.  Note the critical comments about the document
containing unsupported assertions, a common buzzword for "views I don't
agree with."  I don't think the author of this review has helped his
Hal Finney
hfinney at shell.portal.com

@_date: 1993-12-31 18:00:52
@_author: Hal 
@_subject: Anonymous Video on Demand 
Jim - That is a nice protocol.  Seems to work OK.  I had thought of
a variant:
Vendor creates a set of pairs of numbers and random DES keys:
(1,KEY1), (2,KEY2), (3,KEY3),...
These are sent via oblivious transfer to buyer such that he only gets
one but the vendor doesn't know which.  Suppose buyer gets (10,KEY10).
Buyer sends back a mapping of the numbers 1-N and a set of N movies.
He maps the number he got in step 1 (10 in my example) with the movie
he wants.
Vendor encrypts these movies with the corresponding numbered DES keys,
and sends them to buyer.  He will only be able to decrypt one of them.
These protocols have the obvious disadvantage of increasing the needed
bandwidth by a factor of N.  I guess we assume bandwidth is cheap.
Once I get the movie, what stops me from recording it and giving copies
to all my friends for free?  Nothing, as far as I can see.  Therefore,
it would be good to think of a system where N movies are broadcast all
the time (on N channels), all N encrypted, but with each person who has
paid only able to decrypt one of them.  You argued that people would just
share keys, but I don't think that is an issue since they might as well
just share movies.  This system is much more acceptable in terms of
bandwidth.  It would be interesting to think of a solution which worked
with this situation, where the encrypting keys are fixed.
The requirement is, given a set of keys, 1-N, which A knows, B ends up
knowing only key I, where I is chosen by B ahead of time, but A doesn't
know which key B got.  Off hand I don't see how to do this.
Hal Finney
P.S. with a little thought, a variant on my protocol can solve this,
and perhaps your protocol works too.  In step 1, A sends random keys
to B via oblivious transfer; in step 2, B sends a mapping of key numbers
and movies, pairing up the key he got and the movie he wants; in step 3,
which is different, A sends not the movies, but the movie keys which will
be used during the broadcast phase, encrypted with the random keys chosen
in step 1.  B is left with one key which will decrypt just the movie he
wants during the broadcast.
Maybe if this were done in tamper-proof chips like the encryption chips used
in current cable boxes it would be secure enough for most purposes, at least
as secure as current pay cable.

@_date: 1993-07-05 20:17:13
@_author: Hal Finney 
@_subject: Encrypted cypherpunks list 
As Eric Hughes suggested, I put together a little perl script to remail
cypherpunks mail, PGP encrypted, to all names on a list.  If you'd like
to receive your cypherpunks messages encrypted, send me your address and
your PGP key and I'll add you to the list.  Then you can unsubscribe from
the regular list.
I'll upload the script once I test it a little more.  Initial subscribers
should consider themselves alpha testers and feel free to complain.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-07-09 09:58:15
@_author: hfinney@shell.portal.com 
@_subject: Encrypted postings. 
Could we send our postings to the mailer in encrypted format?  That      is... I would encrypt the message with the public key for the mailer,      the mailer would decrypt and re-post to the clear-text mailer and to      the PGP group.  You can already do this, in a way.  Just post to the list using one of
the existing encrypted remailers like the one at extropia (or the one
at portal, for that matter).
You need to put:
Request-Remailing-To: cypherpunks at toad.com
And a blank line at the top of your message, encrypt the whole thing
with the public key of the remailer, and add:
Encrypted: PGP
and a blank line to the PGP file just before the "-----BEGIN PGP MESSAGE-----"
There are some scripts on the cypherpunks ftp site (soda.berkeley.edu,
The one disadvantage with this approach is that the source of the message
(namely, you) gets stripped off.  We might want to think about changing our
remailers to have a non-anonymous remailing command as well as an anonymous
one.  This way you could have "local" privacy from any sysop who snoops on
your mail going out, while still making it easy for people to reply to you.
Hal

@_date: 1993-07-14 21:50:10
@_author: hfinney@shell.portal.com 
@_subject: Relation between number theory and cryptography 
Clark Reynard, , asks about information and cryptography.
As I see it, a cyphertext has at most the same information as the sum of
the original message, the key, and the encryption algorithm.  Without
knowing the key a cyphertext may appear random, but actually it is not.
If it is the encryption of a lower-information plaintext (such as English
text) then it still basically possesses that low level of information, it's
just not obvious how to compress it.
It's not unusual for different compression algorithms to achieve very different
levels of compression.  In a sense, these different algorithms disagree
about the amount of information in the original data.  We discussed digitized
speech here some time back.  Ordinary compression algorithms such as Lempel-
Ziv or Huffman encoding don't compress digitized speech much at all.  Special
algorithms such as linear predictive coding can achieve great compression.
In the same way, there is no contradiction between the fact that an encrypted
file looks random and incompressible, and the fact that knowing the key it
becomes clear that the file actually can be compressed.  Any calculation of
the information content of a file can only be considered an upper bound.
A more clever algorithm may always exist which will reveal the data to have
much less information than was originally thought.  This is basically the
situation you have when faced with an encrypted file for which you don't
have the key.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-07-15 23:17:18
@_author: hfinney@shell.portal.com 
@_subject: Cypherpunks&Clipper in Scientific American 
In the Science and Business section, the August 1993 Scientific American
has a short, negative article on Clipper, which mentions cypherpunks:
Clipper Runs Aground
Everyone seems to be listening in these days: tabloids regale readers with
the cellular telephone intimacies of the British royal family, and more
sober articles on the business pages tell how companies - or governments -
devote resources to "signals intelligence" for commercial gain.  So the
Clinton Administration might have thought it was doing everyone a favor in
April when it proposed a new standard for encryption chips, developed with
the aid of none other than the National Security Agency (NSA).  Instead the administration met with outrage.  Along with the message,
Clipper, as the chip is named, sends out a string of bits called a law
enforcement field.  Its purpose is to enable the police and the Federal
Bureau of Investigation to decode conversations that they wiretap pursuant
to court order.  In addition, the chip's encryption algorithm, known as
Skipjack, is classified.  Thus, only a small cadre of cryptographic experts
would be able to study it to determine whether or not it was indeed secure.
Early in June the administration abandoned its plan to rush Clipper into
the marketplace and extended its internal review of the policy issues
raised by the chip until the end of the summer.  This decision presumably
also delays consideration of outlawing other encoding methods.   A peculiar coalition of civil libertarians and large software companies has
formed to plead the cause of unregulated cryptography.  Self-styled
"cypherpunks" argue that the government has no more right to insist on a
back door in secure telephones than it does to restrict the language or
vocabulary used in telephone conversations on the grounds that dialect
might hinder interpretation of wiretaps.  Companies such as Microsoft,
Lotus Development Corporation, Banker's Trust and Digital Equipment
Corporation are worried about the administration's proposal because they
believe it will hurt the U.S. in international competition.  Ilene Rosenthal, general counsel at the Software Publishers Association,
which numbers 1,000 companies among its members, points out that telephones
containing the NSA chip would be subject to export controls because
cryptographic equipment is considered "munitions" under U.S. law.  This
bureaucratic restraint could force U.S. manufacturers of secure telephones
to develop entirely different product lines for the domestic and
international markets.  Indeed, she says, even if the State Department did
license Clipper for widespread export, it is doubtful whether any foreign
government or company would buy a system to which the U.S. literally had
the keys.   Rosenthal contends that the U.S. has lost control of cryptography, citing
more than 100 different brands of strong encoding software sold by non-U.S.
companies.  Indeed, discussion groups on the Internet computer network have
been buzzing with plans for a do-it-yourself secure telephone that requires
little more than a personal computer, a $200 modem and a microphone.  It is not clear whether the administration will abandon its attempt to
stuff the unregulated-cryptography genie back in the bottle.  There are
already 10,000 Clipper-equipped telephones on order for government use, and
Jan Kosko of the National Institute of Science and Technology says the plan
for the standard "is being advanced as fast as we can move it."  Nine (thus
far unidentified) cryptographers have been invited to review the algorithm,
and Kosko reports that decoding equipment is in the works for "law
enforcement and other government agencies that feel they need it."  The
Justice Department is busy evaluating proposals for the "key escrow agents"
that are supposed to prevent the police and the FBI from listening in on
conversations without a warrant.   Some companies, however, are less concerned.  They hope for enormous sales
once privacy issues are resolved.  AT&T, for example, announced its
intention to sell Clipper-based telephone scramblers the same day that the
chip was made public.  "What the standard is," says spokesman David Arneke,
"is less important than having a standard that all manufacturers can build
to." - Paul Wallich

@_date: 1993-07-24 17:02:44
@_author: hfinney@shell.portal.com 
@_subject: REMAIL: replying to cp-remailed messages 
I want to elaborate on Eric's comment about the " pasting token.
The cypherpunks remailers are activated by mail header fields.  They look
for a header entry of the form "Request-Remailing-To:" among the Subject,
From, To, etc. headers.  Although it is traditional for user-defined extension
header fields to start with "X-", Eric argued that since we hope to extend
remailer availability to the point that it is a widespread and standard
service, it was reasonable to choose a non-"X-" field name.
Since some mailers don't allow users to insert header fields, Eric created
the "::" incoming pasting token.  If no header field is found matching the
ones the remailer looks for, it then checks to see if the first non-blank
line of the message is "::".  If so, it copies all the following lines of
the message into the header, up to the next blank line, and then restarts
processing of the message.  The "::" line is intended to be followed by the
user-added header fields like "Request-Remailing-To".
When the remailer does a remailing step, it strips all of the header fields
except Subject.  Keeping the Subject header impairs security somewhat because
it would facilitate pairing up input and output messages, but it adds a
lot of convenience for users.
What is little known is that there is another step which can be done.  Just
before the remailer sends a message for which remailing has been requested,
it again checks the first non-blank line, this time to see if it is the
outgoing pasting token "  If so, it again copies the following lines
up to a blank line into the message header of the outgoing message.  The
message is then sent without further processing.
This means that any header line can be added to an outgoing message by
this means.  In particular, as Eric pointed out, a Reply-To header could be
added which would reveal the true sender of the message for those cases
where that was wanted.  Subject headers could also be added at this step
as well as after the :: incoming pasting token.  Hal Finney
hfinney at shell.portal.com

@_date: 1993-07-24 17:03:51
@_author: hfinney@shell.portal.com 
@_subject: forged mail 
It's not so much a matter of "corrupt" remailer operators.  The remailer
scripts on the cypherpunks FTP site are distributed with automatic logging
of the text of ALL remailed messages by default.  This is intended for
debugging purposes, but some of the remailers still operate in this mode.
This could perhaps provide some protection against liability for operators
of remailers, because they can trace back the source of an abusive message
that was sent through their remailers.  However, it obviously seriously
impairs user privacy.
The only logs my remailers (on hfinney at shell.portal.com and
hal at alumni.caltech.edu) keep are the date and time when they did an operation.
No record is kept of any message header or content which would allow re-
construction of sender information.  The date/time stamps just give me a
general idea of how much my remailer is used.
However, Eric Hughes has pointed out that most Unix systems can be configured
to keep logs of all incoming and outgoing mail.  Such logs could be used to
reconstruct input/output pairs, by observing that a particular message sent
to me was followed by a particular outgoing message a few seconds later.  I
have not been able to determine whether such logs are kept on the machines
I use (the directories which would hold them are protected) but it's safest
to assume that they are.
I think a better solution to the problem than trying forged mail is to use
a chain of cypherpunks remailers, some of which are user-owned and -operated
and which (I think) have policies of not keeping content logs.  The monthly
postings of remailer lists include information on which machines are user-
owned, although no information is listed presently about logging.
Since the whole point of a remailer is to lose incoming-to-outgoing
correspondence, it seems to me that logging should be minimized, otherwise
there is little point to running a remailer.
Hal Finney hfinney at shell.portal.com

@_date: 1993-05-03 08:12:45
@_author: Hal Finney 
@_subject: Tough Choices: PGP vs. RSA Data Security 
(I sent a copy of this message this morning from my Compuserve account,
but it never appeared.  Fighting to control my surging paranoia, I am
re-sending it from this account.  I apologize if a duplicate eventually
shows up.)
-----BEGIN PGP SIGNED MESSAGE-----
I see several problems with this proposal.
1. It's not clear what it means to "reconsider our basic support for
PGP."  What exactly is Tim proposing?  That people stop using PGP?  That
they phase out their use of it as legal products become available?  I'd
like to see some clarification.
2. More generally, what about the issue of our advocating and supporting
other possibly infringing actions?  Which ones do we stop?  Just those
that upset Jim Bidzos?  He claims to have patents that cover many more
activities than RSA, including patents which cover the very idea of public
key encryption, and patents on Diffie-Hellman key exchange and virtually
any conceivable variation.  Should we respect all of these now?
3. David Chaum apparently has U.S. patents on many key features of digital
cash.  It looks like we would have to stop working on that, too, by this
4. What reasonable alternatives to PGP exist?  Is RSAREF really usable on
a PC?  I tried an early version and it was terribly, terribly slow.  PGP
is just barely fast enough.  A "legal" version of PGP which uses RSAREF will
presumably be considerably slower.
5. I am not as convinced as Tim that RSADSI is truly, positively, certainly
on our side.  Why is it that RSAREF has such a weak conventional encryption
algorithm (DES, with 56-bit keys)?  RIPEM has been out for many months, and
people have been asking for IDEA or triple DES all that time.  Bidzos has
supposedly said he'll give permission for improvements.  Yet as far as I
know RIPEM still only has this small key size, a key size which persistent
rumors say can be broken by government computers.  When Bidzos permits
RSAREF to run a conventional encryption algorithm with a secure key size I
will give more credence to the view that he wants people to have strong
6. How is it that one company has collected virtually all of the patents on
cryptographic technology in this country?  Jim Bidzos controls patents on
public-key encryption in general, RSA, Diffie-Hellman key exchange, ElGamal
signatures and encryption, and several others.  I can't help noticing that
it would be an extraordinarily convenient arrangement for the government
if such a company existed and were secretly working against public use of
cryptography while publically pretending to be doing all they can to bring
this technology to a reluctant market.  I still have not seen any specific
public action by Bidzos which would invalidate this possibility.  Yes, he
has engaged in this widely publicized tiff with NIST over the Digital Signature
Standard, and he's made some statements against Clipper.  But where are the
lawsuits?  Is AT&T receiving the same threatening letters that Stanton
McCandlish received when he said he was distributing PGP from his BBS?
7. Extrapolating from the widespread acceptance of PGP, which is free, to
conclude that there is a market for a commercial encryption product which
costs money is pointless.  Granted, some of us may spend a lot of time
talking about PGP and thinking about these issues, but most PGP users just
downloaded it from a BBS or the net.  There are a lot of things they'd
spend $100 on before they would buy an encryption program.
One of the things that attracted me to Cypherpunks is that they take steps
to make these tools available without worrying about upsetting the power
structure.  David Chaum may object to our implementing digital cash.
Jim Bidzos may object to our using RSA, or Diffie-Hellman, or almost
anything else having to do with cryptography.  If we're going to start
looking over our shoulder and not doing anything which powerful people
object to then we might as well pack up and go home.
Almost everything we have talked about over the last six months infringes
somebody's patents in this country.  I really don't see what role a group
like ours has if we have to tiptoe through the minefield of intellectual
property protection which permeates the field of cryptography.  Are we to
become a bunch of unpaid consultants for RSADSI, writing code which they
will then make profits on?
Phil Zimmermann has done more to put strong cryptography into the hands
of people all over the world in two years than Bidzos has managed in ten.
He has faced lawsuits by Bidzos and has undergone considerable personal
sacrifice in getting this software out.  People talk about this "feud"
as though the two are equally guilty, and ask (like Rodney King) "can't
we all just get along?"  But this is a cop-out.  To me there is clear
asymmetry in their dispute in terms of who asserts their power and who
is trying to empower individuals.
Look at what Tim is suggesting.  We abandon PGP, not because it is a bad
program; not because its author has behaved unethically; not because it
has failed in its goals; but because Jim Bidzos is throwing his weight
around and we don't want Jim to be unhappy.  If Jim were to accept that
PGP was no more threatening to his patents than RSAREF then the problem
would be solved.  I presume that Tim has decided that this won't happen,
so now he suggests Plan B, that we abandon PGP.
I have to suggest that the real obstacle to the wide deployment of strong
cryptography remains Jim Bidzos.  He has the power, by a single stroke of
a pen, to do more to encourage the spread of cryptography in this country
than any other single person (including Bill Clinton).  All he has
to do is to issue a policy statement that since PGP is freeware it falls
under the PKP policy allowing use of the patents for noncommercial use.
Presto - PGP is legal, and one of the main obstacles to its spread is
I agree with Tim that we need to look closely to see who our real enemies
are.  Perhaps Bidzos is a charming person.  I've never met him.  Certainly
the bay area Cypherpunks seem to be falling under his influence.  From my
perspective I find this cozying up to the PKP/RSADSI power structure to
be rather alarming.  I don't think it is a good direction for the group.
Hal Finney
74076.1041 at compuserve.com
hal at alumni.caltech.edu

@_date: 1993-11-04 21:47:41
@_author: hfinney@shell.portal.com 
@_subject: Signing keys for nyms 
Eric Hughes writes, regarding the problem of determining whether the
key of a "nym" is valid:
Eric goes on to describe a solution based on sending the key through
two different channels, with a return message via the pseudonym server
channel.  I think this is a good solution, but there is the possibility
that the evil pseudonym server could corrupt the return message so that
the nym did not find out that his key was being mangled (although other
people would find out, which may be good enough).
A more general solution is to use more than one pseudonym server.
Assuming they aren't both colluding, you can send your nym1 key to nym2,
and vice versa.  By providing two or more channels back to you as well
as out from you, you are able to detect corruption of your messages.
Eric suggested that if the pseudonym server signed the user's key, then
corruption of the key could be proven to third parties.  I'm not sure this
is the case, because it would seem that a user could falsely incriminate
a pseudonym server by claiming that he had never created the key which the
pseudonym server signed, that it was a bogus key.  I suppose reputations
would have to play a role then, in weighing the credibility of the pseudonym
server against that of the nym.
hfinney at shell.portal.com

@_date: 1993-11-04 22:37:41
@_author: hfinney@shell.portal.com 
@_subject: ANON: pools 
One point is being missed here - a chain of remailers is as strong as
its STRONGEST link.  As long as even ONE remailer in the chain is
trustworthy, hiding the connection between incoming and outgoing messages,
your anonymity is preserved.
The suggestion that remailers themselves choose the routing path means
that you have to trust the remailer that chooses the path.  If it is
corrupt, it can defeat the effect of the path.  To protect yourself,
you want to use many remailers in the chain, and use a system which
does not require you to trust any one remailer.  Having the remailers
choose the path does not really help.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-04 22:37:51
@_author: hfinney@shell.portal.com 
@_subject: message depots, packet routing? 
A few discussions of DC-Nets here show a small misconception.  The
network topology does not have to be the same as the DC-Net topology.
What I mean is this: the communication in the network may be a ring
or any other topology.  But that does not mean that you only share
random numbers with your neighbors on the ring.  You can share random
numbers (on a pairwise basis) with every other participant in the network,
in the most extreme case.
Look at this diagram, showing four people communicating in a DC-Net.
The lines represent shared random number one-time pads.
 \     / |
   \ /   |
   / \   |
 /     \ |
Each person shares random numbers individually with every other person
in the network, in this example.  A and B share their own random numbers,
A and C share a different set, A and D have their own, B and C do,
and so on.  But that does not mean that the network communication
topology has to be all to all.  Instead, a ring topology could be used,
with packets passing around the network A-B-D-C-A-B-D-C-....  At each
step, A would xor in the next random number from each of the three pads
that he is using, then xor in his message bits if he has anything.  Then
he would pass it on to B.  After the packet has gone all the way around,
the message (if any) would be revealed.
And in this case it doesn't matter who your "neighbors" are in the
communication network.  B and C colluding can't distinguish whether messages
come from A and D despite the fact that they separate them in the comm
So this concern about "knowing your neighbors" in the DC-Net is not as
serious as it sounds.  If truly paranoid people want to participate in
a DC-Net (and who else would?) then they can use a DC-Net topology
which does not allow partitioning.  This adds overhead and inconvenience
of distributing shared random numbers, but it does not require the
communication pattern to change.
BTW, I like the name someone proposed for a DC-Net: "Ouija Net".  The idea
is that messages appear in a DC-Net somewhat like messages appearing on
a Ouija board.  The true source of most Ouija board messages, IMO, is people
pushing the indicator around.  But because everyone is touching it, each
person has plausible denial.  You know that SOMEONE is moving it, but
there is no way to tell who.  This is similar to DC-Net messaging.
hfinney at shell.portal.com

@_date: 1993-11-07 11:12:53
@_author: hfinney@shell.portal.com 
@_subject: Real-world digicash 
I agree with Mike Ingle's points re NetCash.  I had some pretty strong
criticisms of their proposal when it first came out.  They didn't seem
too familiar with the literature on digital cash.  Their system was more
like cashier's checks than cash.  The anonymity was not strong.
Nick has some interesting ideas re the use of "reputation capital" to
discourage double-spending of dcash.  You wouldn't want to destroy your
reputation by cheating on a small sum of money, not if the reputation
was one which you had built up over a period of time.
In considering these ideas, there are a lot of questions about the
whole infrastructure in which the dcash is being used.  Is this something
which we would see occuring in the near future, the next couple of years,
in which case current systems of electronic communication would be used?
In that case, we might imagine people purchasing items via the more
progressive on-line services, like the new MUD-based systems people
are working on (metaverse, virtual city, ...).  Or companies might simply
advertise items for sale on the internet and accept orders by email or
perhaps TCP connection.
One technical detail is that dcash systems require a multi-step protocol
for spending and withdrawal.  This would make email orders more difficult
to deal with since mail would have to bounce back and forth.  Actually,
Chaum's simplest dcash scheme has a one-step protocol for spending (just
send the cash), but that requires on-line verification.  TCP connections
can handle the back-and-forth very quickly so that may be a preferred
communications method.
Today, most credit card transactions do an on-line check, so I don't think
that on-line systems should be ruled out, although eventually a dedicated
network separate from the internet would probably be needed.  The total
data transfer per transaction is not large, a few hundred bytes.
One question in considering whether double-spending is likely to be a
problem is whether bank accounts are anonymous.  One possible system
is for bank accounts to be non-anonymous, but for transactions to be
untraceable.  Then if someone double-spends the cheating is traced, not
to a "nym", but to a real person.  (There is still the possibility Mike
raised of stealing someone's cash, similar to how you might steal someone's
PGP secret key today, but perhaps this will not occur often enough to
be a problem.)
In this case you don't have to have an infrastructure of reputations and
credit ratings in order to use the cash.  Nick's idea sounds like it would
take some time to develop.  Our hundreds of years of experience in giving
credit will require some readjustement to a world in which "nyms" can
disappear much more easily than physical people can.
Another technical detail with the two forms of digital cash that I am
more familiar with, Chaum's on-line and off-line systems from his Crypto
88 paper, is that even the off-line system requires the vendor to communicate
with the bank for every transaction.  He has to send in the spent cash, as
well as the results of his protocol with the customer, for every piece of
cash he gets.  The difference is that he doesn't have to do it right away.
So this off-line system will actually require more bandwidth for communication
with the bank than Chaum's on-line system would (because of the extra
transaction information that has to be sent).
It seems that on-line and off-line cash systems both have pros and cons.
Initially my feeling is that an on-line system might be preferable because
there is less need for trust between the parties involved.  Each person
checks at each stage to make sure he is not being cheated.  There is no
need for a legal system to prove double-spending and force cheaters to make
good.  The protocols are much simpler and easier to understand.  And the
bandwidth requirements are less.  The main disadvantage is the need for
enough redundancy in the bank to allow continual accessibility, although
even this would not be an issue for purchases which are delivered after
a delay, typical of electronic purchases today.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-11 23:49:23
@_author: Hal Finney 
@_subject: Fractal cryptography 
There have been some discussions on sci.crypt within the past few months
on nonlinear/chaotic algorithms and their use in cryptography.  Fractal
cryptography sounds like it might be related.  The problem is that unless
an algorithm was SPECIFICALLY DESIGNED to prevent an intelligent adversary
from defeating it, the chances of it being an effective cryptosystem are
limited.  Just because nonlinear systems produce complex-looking results
does not mean that these results are unpredictable given enough data.
Now, maybe this particular fractal cryptosystem idea will actually work
well.  I don't know; I haven't seen it.  But the point is that these
complex types of systems have not provided a good foundation for crypto-
graphy in the past.
sci.crypt messages are available on (at least) ripem.msu.edu, in
which lists all the subject lines by message number, as well as a collection
of files each of which holds a couple of months' worth of messages.  You
can grep the subjects file to find those messages which might be i{terested.
The archives appear to go back a couple of years.

@_date: 1993-11-12 08:54:48
@_author: Hal Finney 
@_subject: (fwd) Netcom adds access in Denver area 
Unfortunately, netcom's nearest point-of-presence is a $.10/minute nighttime
long distance call away from me.  So this "free" service would cost me about
$6/hour.  There are several services which provide access via packet-switching
networks which have hundreds of POP's, including some local to me.  Two of
these networks are Sprintnet and Compuserve's network (which is separate from
the Compuserve service itself).  These networks charge $2-$3/hour off-prime,
so they are a better deal.  But the carrying capacity of these networks seems
somewhat limited, and you don't get the full throughput of your baud rate.
There are resources available on the net, the "pdial" and "nixpub" lists,
which provide lists of service providers for Internet access.  I don't have
access information handy....  Well, I just grabbed some info.  Here
is an excerpt from alt.internet.services FAQ:
I check these lists every so often, hoping to find cheaper access, but
still no luck.
But I agree with Graham Toal that a much better setup would be smarter
software on my home PC, with an intelligent protocol for communication with
the net service provider.  I wouldn't care if it was UUCP, POP, SLIP, or
whatever, at this point; it's probably better than semi-automated ZMODEM.
I hope that these facilities become more widely available at a price of
around $20-$30 a month or less.  Paying hundreds of dollars a month for
these capabilities is far beyond my budget.  I can't understand why England
is so far ahead of the U.S. in this regard.  No offense intended, but I
always thought of their telecommunications and computing infrastructure as
being several years behind the U.S.

@_date: 1993-11-15 11:54:01
@_author: Hal Finney 
@_subject: Portable crypto code 
One thing that frustrates me is the difficulty of easily providing
implementations of cryptographic algorithms that would be useful on a
wide range of machines.  A lot of these algorithms are really simple,
almost trivial.  Yet to write programs to implement them takes pages and
pages of code, and making them portable so that people on PC's, Mac's, and
Unix machines can use them is almost impossible.
Take the simple Chaum cash we have discussed here a few times.  The
user picks a random x and a random r, calculates r^3*f(x) where f is some
one-way function, and sends it to the bank.  The bank takes the cube root
and sends it back, then the user divides by r.  That's pretty simple.  Yet
to actually implement software to perform these steps raises a host of
First, we want to choose a "random" x and r in the range 0..m-1, where
m is the bank's public key modulus.  But we want these to be strong,
unguessable random numbers.  We need an unpredictable RNG,
and we need to seed it.  There are various URNG's that are provably as
strong as breaking factoring, discrete logarithms, and such, so these
would have to be implemented (as before, most are conceptually trivial).
Or you could run DES or IDEA in a feedback mode and take bits from there,
for a little less security but more speed.
For seeding the RNG you could do like PGP does and retain random numbers
from earlier runs, mixing in new randomness when feasible; you could do
like RIPEM and scan disk partitions hoping for randomness (I think RIPEM
has a lot of other ways of looking for entropy); you could use hardware
features like /dev/audio or the free-running, high-speed timers some PC's
have; you can get the user to click the mouse or type keys at random.
OK, we've got our random numbers.  Now we want a one-way function.  Again,
there are several choices: MD4 and MD5 from RSA; the Secure Hash Standard
NIST is pushing; Ralph Merkle's (I forget the name); others based on
conventional ciphers like DES or IDEA.  Implementations of these are
probably available, but portability is a question mark.
Now we need a multi-precision math package.  We may have needed one for
the URNG, too.  There are a lot of libraries available in source code
for these, but not many of them will work with 16-bit ints, and are
tested on DOS and Mac's as well as Unix.
Finally, to send the data around, we may want to convert to and from ASCII,
and once again there are a lot of choices, but perhaps not too many
portable libraries.  I suppose RFC1113 and MIME, which are similar but
not quite identical, would be the encodings of choice.
The point I'm getting to is that it would be nice if all this were done
ONCE, and a library made and tested which would work on a wide range
of machines.  Entry points for one-way functions, multi-precision
arithmetic, unpredictable random numbers, conventional encryption, and
ascii conversions could all be provided.  Multiple alternatives would be
supported as much as possible and it should not be difficult to add more
as time goes on.
Once you had such a library, it would be possible to add a user interface
to allow interactive use of the routines.  It could be as simple as the
Unix "bc" program where you can say "x = y*z" to do arithmetic, or perhaps
"x = md5(y)" to call a one-way function.  Or the library could perhaps be
linked into perl or some other high-level program (does mathematica have
hooks for compiled user code?).  The nice thing is that since most of the
compute time is spent doing the MP arithmetic in these algorithms, an
interpreted system which calls compiled libraries can be as efficient as
a purely compiled program.
I know that others here have made similar proposals in the past, but
I have not heard of many results.  I'd like to hear more about whether
these efforts have produced anything that could be incorporated.  It
would also be good to hear suggestions for specific existing packages that
would meet the portability requirements.  I've looked at a couple of MP
packages from ripem.msu.edu but so far I haven't had much luck running them
under DOS.
Perhaps a project like this could allow progress to be made more easily
toward cypherpunk goals.  By providing a toolkit to programers newly
interested in cryptography people will be able to try out ideas more
easily without having to re-invent the wheel each time.
Let me know if you would be interested in participating in this effort.
Hopefully a lot of the pieces already exist and it will just be a matter
of pulling them together.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-16 12:05:54
@_author: Hal Finney 
@_subject: Portable TCL-based crypto 
The work Strick is doing sounds very much like what I am looking for.
It is too bad about the export and usage restrictions but perhaps other
packages can be incorporated in the future which are more freely
available.  TCL itself appears to be widely ported and sounds like a
good foundation for this project.  I am hoping to learn more about it
I do have some concerns about the portability of the gmp library
specifically, but I know that the md4, md5, and rsaref packages are
very portable.  I guess we're not supposed to use rsaref as a "bare"
mp library, though.
Please keep us informed about the progress of this package!  I'm sure
many people on the list would be interested in beta testing when you
are ready.

@_date: 1993-11-18 08:56:30
@_author: Hal Finney 
@_subject: hohocon 
Regarding the issue of telnet'ing through an insecure system:
A general solution to this problem is to have the system you are attaching
to engage in some dialog with you to establish your identity.  However, the
dialog must be such that even if it is monitored by the system you are
going through, that will not allow them to later claim to be you.
This is the same basic problem as entering a PIN for a credit or debit
card in an environment where the PIN can be seen or recorded.  If someone
sees your PIN they can steal your ATM card (or dcash card, in the future)
and access your money.
Cryptographic solutions involve zero-knowledge proof systems but they are
too complicated to work in your head.  For the hohocon case you could have
a calculator programmed with some one-way function (DES is available for
the HP48); the remote system could generate a challenge number and you
would use your calculator to DES-encrypt it with a fixed secret key, then
type the result in, and the remote system would check it.  This would
not help the hohocon people because next time they tried to log in as
you the challenge number would be different.
There was a paper in the Eurocrypt 91 proceedings called "Human Identification
Through Insecure Channel" which attempted to address this problem.  The
authors proposed a system which was supposed to be simple enough that you
could work the response in your head, but which would be complex enough
that eavesdroppers would not be able to figure it out, even after seeing
many examples.
The idea was that the remote system would issue a challenge as a string
of letters or digits: 1982043765.  You will give a response of the same
length, but only certain positions matter.  Those positions are identified
by one of two secret words that you memorize.  Suppose the first secret
is 1246.  You will produce a response which embeds the 2nd secret word
in the positions where 1,2,4, and 6 appear.  Suppose the 2nd secret word
is 3124.  Your response, written below the challenge, would be:
-  - -  -
Only the marked positions matter; the others are random.
This sounds simple enough, but the problem is that for true security
the authors require a much longer string with a much larger set of
characters, 40 or 50 characters long.  I tried implementing their
algorithm, without even memorizing the secrets, just writing them down
(they had to be about 10 letters long), and entering in a reponse given
a challenge, and I couldn't do it.  It was extremely difficult to locate
the checked positions and put in the next letter.  It took forever to
do it, and I kept making mistakes.
Maybe with practice it would get easier.  Or, perhaps the technique would
still be useful with a smaller question size to provide less security but
still more than you would get without it.
It would be interesting to see if other people come up with approaches
to solve this problem.  I really don't think that protecting my smart
card with a 6-digit PIN is going to be adequate.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-18 13:31:36
@_author: Hal Finney 
@_subject: hohocon 
Don't type your PGP passphrase on a PC owned by someone else!  You
don't have to use your passphrase to exchange keys.  Keys can be
extracted, added, etc. without the passphrase being entered.
I don't see any way a virus could be spread via PGP key exchange.  At
best (worst) a virus could somehow attach itself to the PGP key file
but it would be just passive data.  It wouldn't do anything.

@_date: 1993-11-19 09:34:44
@_author: Hal Finney 
@_subject: All our eggs in one basket? 
Some of Jim's points can be addressed with existing protocols.  When
the bank sends you cash which you have withdrawn they would want to send
it in such a way that they get a return receipt from you.  That way they
can prove you have received it.  Schneier's book describes such a
"digital certified mail" protocol in section 6.3 of his book, but it
looks like it uses a lot of data.  More concise implementations may
Other forms of cheating could be imagined.  I could send cash to a
company, and they could refuse to send me goods, but claim that they
had done so.  Or I could receive goods from a company, but claim that
they never arrived.  These could also be addressed with certified mail,
either paper or digital, depending on whether the goods are physical or
In an online system, the bank could refuse to accept a cash deposit, even
though it was valid cash, claiming that it had already been deposited.
To prevent this, the bank would have to record who made each deposit in
the past and stand ready to reveal this information.  A merchant could
collude with the bank to provide forged deposit records to help with
this scam.
I don't see how to solve this one, but if it were done on a large scale
people might become suspicious about the excess of apparent double-spending
via a small number of merchants.  The bank's reputation would suffer, as
long as people found out about it.  Perhaps customers should demand that
banks publish statistics about (apparent) double-spending in order to
detect this scam.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-19 13:22:39
@_author: Hal Finney 
@_subject: All our eggs in one basket? 
Although Jim's protocol doesn't quite work, as Eric pointed out, because
of the re-blinding, it does suggest another approach.  If the bank sent
you a coin and you claim you never got it (maybe you're telling the truth,
maybe not), they can just send it again.  You can't cheat because at best
this will allow you to get two copies of the same coin.
Contrariwise, if the bank cheats and never sends you the coin, just ask
them to send it again.  They have no basis for refusal.
Here we see a case where the ease of duplication of digital money is
actually an advantage, rather than the disadvantage it usually seems
to be.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-26 11:30:15
@_author: hfinney@shell.portal.com 
@_subject: PGP math library 
Here's a little document I threw together this morning to describe
the PGP multi-precision routines.  After reading about Henry Strickland's
work making TCL interfaces for various crypto functions, I've been
putting together a similar interface for PGP's mp library.  This is mostly
to teach myself TCL.  But I have developed some familiarity with PGP's
mp library as a result, so here is some information that will hopefully
be helpful.

@_date: 1993-11-26 19:13:59
@_author: Hal Finney 
@_subject: META: Filter Detweiler 
It appears to me that Detweiler is not receiving the list; for example,
he apparently didn't see the posting giving the names of officials at
his university until it was forwarded to him several days later.
I would favor adding a filter preventing Detweiler's messages from
appearing on the list.  I know that this is a big step to take but his
messages have become so deranged that they have, IMO, no redeeming
value.  Whatever validity his original points may have had (and I do
think there was a kernel of a valid point there), his mental state is
such that his postings are now worthless.
I know that I can easily filter his messages myself, but it still wastes
list bandwidth and, worse, distracts people's attention from other,
more worthwhile, posts.  By lowering the quality of the list as a whole
Detweiler discourages people from subscribing.  New subscribers may
take his rants as typical of what we discuss here.  We are all harmed
by having people who could make a contribution leave the list, or be
distracted by Detweiler's messages and the responses to him.
Unless others strongly disagree, I urge Eric to install software to
eliminate Detweiler's postings.  I believe the evidence is strong
enough that the anon.penet.fi account nicknamed "S.Boxx" is actually
a Detweiler pseudonym that it should be filtered as well.  If other
pseudonyms appear I suppose we would have to consider them on a case
by case basis.
In order to conserve list bandwidth, let's try to avoid "me, too"
postings.  If you disagree, it's worth discussing, IMO, but if you
agree I'd suggest that messages be sent directly to Eric at
cypherpunks-request at toad.com or hughes at ah.com.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-26 19:15:44
@_author: hfinney@shell.portal.com 
@_subject: META: Filter Detweiler 
It appears to me that Detweiler is not receiving the list; for example,
he apparently didn't see the posting giving the names of officials at
his university until it was forwarded to him several days later.
I would favor adding a filter preventing Detweiler's messages from
appearing on the list.  I know that this is a big step to take but his
messages have become so deranged that they have, IMO, no redeeming
value.  Whatever validity his original points may have had (and I do
think there was a kernel of a valid point there), his mental state is
such that his postings are now worthless.
I know that I can easily filter his messages myself, but it still wastes
list bandwidth and, worse, distracts people's attention from other,
more worthwhile, posts.  By lowering the quality of the list as a whole
Detweiler discourages people from subscribing.  New subscribers may
take his rants as typical of what we discuss here.  We are all harmed
by having people who could make a contribution leave the list, or be
distracted by Detweiler's messages and the responses to him.
Unless others strongly disagree, I urge Eric to install software to
eliminate Detweiler's postings.  I believe the evidence is strong
enough that the anon.penet.fi account nicknamed "S.Boxx" is actually
a Detweiler pseudonym that it should be filtered as well.  If other
pseudonyms appear I suppose we would have to consider them on a case
by case basis.
In order to conserve list bandwidth, let's try to avoid "me, too"
postings.  If you disagree, it's worth discussing, IMO, but if you
agree I'd suggest that messages be sent directly to Eric at
cypherpunks-request at toad.com or hughes at ah.com.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-28 20:04:40
@_author: Hal Finney 
@_subject: Cryptosplit 2.0 
Norm Hardy posted some code for Shamir secret sharing here about a month
ago, a nice short routine.  At around the same time, I created a program
to do the same thing and uploaded it to soda.  It is still in
and source for building under Unix or DOS.
I did the polynomial calculations a little differently from Norm and
Ray; their approaches may be more efficient.  But I did go to some
effort with the random-number generation on which the security of the
scheme depends.  My code uses the IDEA.C module from PGP for the
pseudo-random generator, seeding it with the time of day and an MD5
hash of the file being split.  So I think this should be pretty secure
in terms of the randomness involved.
The purpose of this program, as with Ray's and Norm's, is to split a file
into n pieces (all as big as the original file) such that any k of them
are sufficient to recover the original file, but k-1 pieces give you NO
information about the contents of the original file (other than its size).
One possible application is to split up your PGP secret key file this
way and distribute the pieces to trusted friends such that several of
them have to cooperate to recover your key.  Then if you accidentally lose
your key you can get the pieces back from your friends.

@_date: 1993-11-28 20:14:41
@_author: Hal Finney 
@_subject: Traffic analysis and file size 
Scott Morham asks about how well file sizes are preserved by encrypted
remailers.  Generally speaking, in creating a nested encrypted remailing
request, at each stage PGP will attempt to compress the input, then encrypt
it, which preserves its size but adds a block to the beginning of about
the size of the public key (typically 100-150 bytes), then makes it ASCII,
which increases the size by 1/3, then adds a small header block of 50 to
150 bytes or so.
Since the compression is ASCII-encoded encrypted text, the best it can do
is to "undo" the ASCII encoding or compress by about 1/4, but I don't know
if it actually does that well.  Probably it compresses by somewhat less.
So generally each chain will add a few hundred bytes and scale the size of
the message up by probably 10 or 20 percent.
I think that this will probably allow pretty reliable matching of incoming
and outgoing messages on the basis of size alone, at least, more reliable
than I would be willing to count on to prevent attacks by this means.
Scott also suggests using .zip compression at some point, but this isn't
likely to help much since encrypted files look random and are basically not
What we have talked about here is adding random padding to change the file
size.  Because encrypted files do look random, you can generally pad them
with random bytes pretty easily and undetectably.  This depends somewhat
on the file format but it is basically easy.  I wrote some perl scripts to
pad .pgp public-key-encrypted files undetectably.  The extra bytes are
ignored when the file is decrypted.  The scripts aren't really production-
quality since they just use perl's built-in random numbers.  Good random
numbers should be used.
hfinney at shell.portal.com

@_date: 1993-11-28 20:19:40
@_author: Hal Finney 
@_subject: Remailers: Turnaround Times? 
Coerr asks about turnaround times for the remailers.  Karl Barrus posts
a list of remailers approximately every month.  On that list he shows
which remailers have high-speed, continuous connections to the internet
and which have intermittent connections which introduce larger than normal
delays.  In my experience, the direct-connected remailers generally respond
within a minute or two.  The other ones introduce delays ranging from an
hour or so up to overnight.  A good test is to send a "ping" (remail to self)
message to each remailer and see how quickly responses arrive.  In my
experience, the extropia remailer tends to take a few hours, while the rebma
remailer is usually a day or sometimes longer.  I don't have recent values
for the others.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-29 08:52:02
@_author: Hal Finney 
@_subject: Cryptosplit 2.0 
These can play a role in seeding a RNG, but there is probably not as
much randomness there as you might expect.  Knowledge of the approximate
time of day the program was run, plus some general information about the
characteristics of your system in terms of usage, can probably pin most
of those values down to within a factor of 5 or so.
I think multiple MD5 hashes of the total contents of /tmp (or, better,
any case, Shamir sharing requires a LOT of random bits ("k" times the
size of the file) so at best these sources of randomness could seed a
RNG, which would then "amplify" the randomness (in a cryptographic
sense) to produce the random bits needed for the sharing algorithm.
I believe the RIPEM public key package by Mark Riordan has a fairly wide
repertoire of techniques for searching for randomness, including some of
the above ideas.  This code might be worth adapting to a general-purpose
entropy-seeking algorithm.  The problem is that these kinds of things are
highly system dependent.  If you have an audio port, for example, listening
to an unconnected microphone can produce a steady stream of noise.  Or if
you have a high-speed timer it can be used to get perhaps a couple dozen
bits of randomness at program-startup time, or to get many bits per keystroke.
So you have to have customization for each target system to be useful.
I do think the RIPEM code would be a good starting point, though.
I once proposed a DOS TSR (a "background" program) which would monitor
your keystrokes all day long and condense the timing data into a file
full of random bits.  Then you'd use up the bits when you needed to do
cryptography.  I haven't learned enough about DOS to write such a
thing, though.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-11-29 14:27:14
@_author: Hal Finney 
@_subject: Banning any subscriber 
The problem with user-based filtering is that the noise may still drive
people off the list.  New subscribers won't have filters set up initially
(they may not know how to set them up, or it may take a while to figure out
who, what, and how to filter) and they'll be subject to a barrage of rants and
raves.  They're likely to unsubscribe in disgust before taking the time to
uncover the jewels amid the slime.
Also, Tim has noted problems with the user-based filtering on the extropians
list.  Different people have different filter settings, so there can be
multiple redundant postings of outside information - magazine articles,
other newsgroup or mailing list posts, etc.  Nobody knows what material
anyone else has seen.  There is also something of a learning curve in
using the extropians filtering, despite it being conceptually easy to
use.  A few weeks ago, it seemed that almost every day someone
accidentally posted a filter command to the list.  Tim noted at one point
that he had surveyed local list members and found a great deal of ignorance
about using the filters.
I think it works better if the list community is seeing a common message
stream, one which is of high quality, one which does not include messages
of disruptive posters.  Eric has given his blessing (at least implicitly)
to an alternate list, one which is gatewayed bidirectionally to cypherpunks,
but where such filtering is done.  New subscribers to CP who were upset
by the noise could be directed to this list when they unsubscribed.  This
would allow people to avoid receiving harrassing messages while still
participating on the cypherpunks list.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-03 19:19:03
@_author: Hal Finney 
@_subject: ECPA and Remailers? 
Not being a lawyer (despite my recent spate of "legal" posts, which were
based on several hours browsing through the library), I wonder whether any
provisions of the ECPA would apply to anonymous remailers.  Several
operators keep logs of messages and read them, occasionally rebuking
or perhaps even blocking users who send inappropriate messages.  (As
far as I know, no cypherpunks have done blocking, but other remailer
operators have.  Several cypherpunks have said they read messages.)
My feeling is that it is better for me as a remailer operator to have as
little to do with the content of the messages as possible.  I just don't
want to know.  If someone complains I will have, to the best of my ability,
NO POSSIBILITY of breaking the anonymity of the message they were upset
about.  Paradoxically, this very blindness to the content of messages
will, I hope, protect me if and when abusive or illegal messages are sent.
Frankly, I find it paradoxical for remailer operators to try to keep
secret information which will allow them to break the very service they
are providing, anonymity.  I think it represents confusion about just what
they are trying to accomplish.  And I think it could even get them into
trouble if illegal messages go through their systems.  Like the Fido sysops,
in trying to protect themselves they may be exposing themselves to even
more liability.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-05 11:34:57
@_author: Hal Finney 
@_subject: Crypto Idea; Multi-Part Sigs 
Some parts of what Christian asks about can be done; some can't.
You can't have it that each of three individuals can decrypt messages
sent to a key, while they all have to cooperate to sign messages.
Generally speaking, decryption and signing are identical in the RSA
cryptosystem.  Having enough information to do one implies teh a  the
ability to do the other.
However, you can divide a key so that people must cooperate to sign OR
decrypt.  Normally, in RSA, you choose a public exponent e, and find d,
the secret exponent, such that e*d = 1 mod (p-1)(q-1), where p and q are
the primes.  Instead, you can choose d1..d3 such that e*d1*d2*d3 = 1.
Choose d1 and d2 at random, choose e, and find d3 as in regular RSA.
Give d1, d2, and d3 to each of the three people.  Now they must apply
their exponents to the RSA block in order to sign or decrypt.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-08 14:05:47
@_author: Hal Finney 
@_subject: second order homophonic substitution 
This homophonic cypher sounds interesting.  If the authorities demand
your keys, you could scramble each row of the matrix (scrambling each
row separately), so that only the dummy message can be recovered.
Real ascii messages have a character set of about 2^6, so the actual
size of the key matrix will be 2^12, and that means that each entry will
be about 12 bits.  For full generality in handling binary data the
character set would be 2^8, meaning a matrix of size 2^16 entries with
each entry being 16 bits.  This is a 128K byte key, which is pretty
cumbersome.  Also, the cyphertext is twice as big as the plaintext,
which will stand out too.
Plus, once the authorities see your decryption algorithm it may be
pretty obvious that it was designed for this specific purpose, and
whatever pressures they applied to make you reveal the key may now
be redoubled until you reveal the "real" key.
A one-time-pad has the advantage that the key is the same size as the
file, and there is no size expansion in encryption, plus it's a plausible
approach to use for high-security encryption.  It will take less space
and still allows for multiple decryption.
hfinney at shell.portal.com

@_date: 1993-10-08 23:49:30
@_author: Hal Finney 
@_subject: Virtual City (tm) Network FAQ 1.0 (fwd) 
This Virtual City project does have an interesting conceptual link to
cypherpunk philosophy.  Many of us have been influenced by the fiction
of Vernor Vinge, particularly his "True Names".  In this story we find
many elements of our cypherpunks mythology introduced:  digital
pseudonyms, anonymous mail, untraceable identities.  The heroes of the
story are hackers, powerful on the net, but with their real identies
unknown.  Having your true name discovered was the worst disaster that
could occur, as it made you vulnerable to many kinds of attacks, both
from other hackers and from the government.
In Vinge's story, people online interact in virtual environments.
This Virtual City and the other projects like it are trying to move
towards an online virtual environment similar to that described in
Vinge's story (and cyberpunk fiction).  It would be nice if they had
crypto anonymity and digital pseudonyms built in from the beginning.
Unfortunately, although they talk it up, the author of the FAQ doesn't
seem to really understand PK crypto:
This is not how keys work: you don't need to connect to a public key
server to get yourself a key; and if they send something encrypted "to you"
then you wouldn't decipher it with their public key, but rather with your
private key.  Also, they should say whether they are using PGP, RIPEM,
PEM, or some new system for the public keys.  My guess is that they
haven't gotten that far yet.
Still, it might make sense for someone from this list to give them some
help on the crypto aspects.  This could be a safe and fun environment
in which people could be introduced to crypto, and it could even expand
eventually to include cryptographically protected business
relationships.  Tim May has suggested that strong crypto could be
initially deployed as part of a game, and this could be a beginning.
hfinney at shell.portal.com

@_date: 1993-10-19 22:47:40
@_author: Hal Finney 
@_subject: JUDGMENT PROOFING 
[Something in the way of a test post, to see if I can get through to
toad.com yet...]
This is exactly what anonymous remailers are for - to defeat traffic
analysis.  The goal is a situation where you, and everyone else, receives
and sends out a bunch of encrypted traffic every day.  There will be
no way a snooper can find out exactly what you are reading, what you
are writing, or whom you are communicating with.  That's what I call
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-20 09:27:46
@_author: Hal Finney 
@_subject: pseudospoofed out 
Dug writes that he intentionally strips out all identifying information
from his incoming mail that would show who it is from.  Truly this is
a radical solution to the problem of spoofing.  A basic principle of
discourse is that the validity of an idea is independent of its source
(which is why ad hominem attacks are considered invalid).  Yet this
principle is not widely followed (which is why ad hominem attacks are
considered effective).  Dug's solution enforces the discipline of judging
each piece of mail on its own merits.  Maybe more people should consider
this approach.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-21 08:32:45
@_author: Hal Finney 
@_subject: Mail delivery question 
I have a somewhat dumb question about mail delivery.  This has a CP
connection because it relates to a remailer enhancement I am working
on.  When I receive mail from cypherpunks, this is a typical set of headers
for an incoming message:
  From owner-cypherpunks at toad.com  Wed Oct 20 23:57:11 1993
  Received: from nova.unix.portal.com by jobe.shell.portal.com (4.1/1.34)
  	id AA14713; Wed, 20 Oct 93 23:57:11 PDT
  Received: by nova.unix.portal.com (5.65b/4.1 1.505)   	id AA18779; Wed, 20 Oct 93 23:57:09 -0700
  Received: by toad.com id AA20355; Wed, 20 Oct 93 23:47:55 PDT
  Received: by toad.com id AA20115; Wed, 20 Oct 93 23:43:21 PDT
  Return-Path:   Received: from netcom.netcom.com ([192.100.81.100]) by toad.com id AA20111; Wed, 20 Oct 93 23:43:19 PDT
  Received: from netcom3.netcom.com by netcom.netcom.com (5.65/SMI-4.1/Netcom)
  	id AA27104; Wed, 20 Oct 93 23:43:51 -0700
  Date: Wed, 20 Oct 93 23:43:51 -0700
  Message-Id: <9310210643.AA27104 at netcom.netcom.com>
  X-Mailer: Eudora
  To: cypherpunks at toad.com
  From: jamie at netcom.com (Jamie Dinkelacker)
  Subject: Re: Something Silly, Something Serious
  Status: RO
Now, my question is, when this mail is delivered to the Unix system which
I use, how does the local software know to deliver it to hfinney?  My name
does not seem to appear in the header at all.  In particular, the "To:"
address is not hfinney at shell.portal.com, as I would have expected, but rather
cypherpunks at toad.com.
I suppose there is some other information that is passed along with the
message when it is delivered to portal.com, information which tells my
user name.  It would be nice if this information were available to scripts
which would process the incoming mail.  Could someone explain how this
delivery process works?  Thanks -
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-21 12:52:48
@_author: Hal Finney 
@_subject: backing 
Banks are contractually obligated to turn over mortgage notes in exchange
for U.S. dollars.  These contracts are valid over approximately 30
years, and provide unencumbered title to valuable property.  These and
similar contracts may be said to give value to dollars independent of
government promises.

@_date: 1993-10-22 09:12:56
@_author: Hal Finney 
@_subject: Subliminal Channels 
Steganography, the art of hiding a secret message inside of an openly
readable one, can be thought of as a subliminal channel.  In the prisoner
example, the prisoners could have pre-arranged that, say, every 10th
character in the typed messages they exchange would be used to spell out
a secret message.  Or perhaps word or sentence lengths or spacings could
send a message.
In general, in any system where there is ambiguity, more than one way of
expressing a valid message, there is a subliminal channel.  Since DSS
signatures are apparently not unique for a given message (unlike, say,
RSA signatures as specified in the PKCS standards), they have such a

@_date: 1993-10-22 09:18:17
@_author: Hal Finney 
@_subject: Canon copiers 
The thing that makes me skeptical about this copier story is this:  the
money could have any orientation and position on the page.  It would take
a large amount of computing power to look at an image and deteri\\ determine
whether there is a certain bitmap anywhere on it.  Look at how poorly
optical-character-reader technology does now, and that is when it knows
how the letters are oriented.  Adding random orientations would make the
problem far worse.  And, will it look at the whole dollar bill, or just
pieces of it?  It has to respond to all the different denominations, too.
Plus, if it makes a mistake and permanently locks up the customer's machine,
the manufacturer is going to have a big problem.
In short, I'm pretty sure that there is a lot of disinformation going around
designed to scare people away from trying it.
However, there is another possibility, which is to look at hte color of
the bills.  This does not take so much processing power, although bills
may vary somewhat in color.  Years ago, I'd read that these machines would
not accurately reproduce the color of money.  Perhaps today they will turn
that color to black.

@_date: 1993-10-22 09:38:17
@_author: Hal Finney 
@_subject: Sharing a secret 
I will give a simple example of Shamir secret sharing.  Suppose you have
some data D which you want to split up into n pieces such that any 2
of them are sufficient to reconstruct D.  Shamir solves the problem for
any k of them being sufficient, but the case k=2 is especially simple.
Pick a random number m which will be the slope of a line.  Take the
equation y = mx + D, and substitute x = 1, x = 2, ... x = n.  Pass out
the y's for each value of x as the secret shares.
For example, if D=12, pick random m = 4, and pass out (1,16), (2,20),
(3,24), (4,28), and so on.
Now, suppose an enemy gets hold of one of these - say (2,20).  What does
this tell him about the value of D?  Nothing!  D could be anything,
depending on the value of m.
But suppose we have two of these values - say (1,16) and (2,20).  From
these it is easy to calculate m=4, and from that it is easy to see that
D=12.  Two points determine a line.
In the actual Shamir scheme, integers mod a prime p are used, where p>D.
The math is basically the same.  For k=3, a parabola is used instead of
a line, so that 3 points are needed; for k=4, a third-degree polynomial
is used, and for general k, a (k-1)-degree polynomial is used.  In each
case, knowing k-1 points tells you nothing, because there will be a
(k-1)-degree polynomial that would pass through any possible value of

@_date: 1993-10-23 10:53:06
@_author: Hal Finney 
@_subject: Warning about exposing anon id 
I agree with Alan's position that anonymization not be done automatically
on reply to mailers, but in fairness Julf has argued that the "least
astonishment" position goes the other way.  Apparently for several years
anonymous/pseudonymous servers have operated on the talk groups which
do the automatic anonymization.  People there have come to expect that
when they reply to an anonymous message their own identity will be protected.
Providing an anonymous server for which this established behavior does
not occur will no doubt astonish many experienced users of these services.
Still, I think the current behavior is wrong, and IMO the sooner people
learn a new way of using anonymous servers, the better.  When we do
deploy anonymous servers which allow replies, it will be important to
include disclaimers which remind people that their replies will not be
anonymous.  Unfortunately, some or most newsreaders do not show header
fields, and I dislike sticking disclaimers into the message body itself.

@_date: 1993-10-24 22:28:40
@_author: Hal Finney 
@_subject: A favor re Detweiler 
I'd like to expend some "reputation capital" here and ask people for a favor.  I am worried about Larry Detweiler's obvious mental anguish.  We tend to forget that we are dealing with real people on the net, flesh and blood human beings.  Larry is obviously going through genuine difficulties here.  As a member of our virtual community, I ask that we show him some compassion and consideration.
Larry believes that people have been communicating with him in private mail under multiple identities in order to confuse and mislead him.  Specifically, he has suggested that Jamie Dinkelacker is a pseudonym employed by Tim May.  I gather that he has received email from both names.  He also suggests that others have employed these practices.
Since I do not live in the Bay area, I have never met Jamie Dinkelacker, although I had the opportunity to meet Tim once when he visited southern California.  So I am not in a position personally to assure Larry that Jamie is a real person separate from Tim.  But I know many list members are in northern California and I assume several of you have met both Jamie and Tim.  I ask those of you who can vouch for Jamie's separate identity to send me private email saying so, which I will forward to Larry.  If enough people can do this, perhaps a PGP-style "web of trust" can be established which will reduce Larry's concerns about this particular case at least.
(I have considered the possibility that Jamie actually is a pseudonym employed by Tim.  This is certainly not inherently impossible, given the structure of the net.  As I told Larry, I myself have occasionally posted under apparently-legitimate pseudonyms in other times and places, although never on this list.  I certainly don't attach the moral significance to the practice that Larry does.  Nevertheless, in this particular case, the situation is so obviously causing mental suffering that I assume that if Larry's charges were true that Tim would have confessed in order to spare Larry this pain.)
I know that it's easy to just write people off on the net, the various marginal or fanatical personalities whom one runs into now and then.  That is why I am asking this as a personal favor.  If you have read and appreciated my essays on digital cash, or on the various legal issues involving crypto exports; if you have used the remailer code I worked on, or PGP for that matter on which I spent hundreds of hours of personal time, then I ask that you help me out with this request.  Do it as a favor to me regardless of your feelings for Larry, and I will just hope that my efforts will bring him some peace of mind.  Thank you.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-26 22:42:36
@_author: hfinney@shell.portal.com 
@_subject: True Names and nyms 
Some people have argued that there is no way to prevent the use of
multiple pseudonyms on the net, that it is possible today and that the
new crypto technologies will provide even easier techniques tomorrow.
This is an oversimplification, as Tim pointed out.  "Is-a-person" credentials
can be used to determine whether someone is a "True Name" or not,
which is really what Larry wanted to know.  Here is one way they might
(To make this clearer, it is best to think in terms of the equation,
pseudonym == public key.  A pseudonym is a public key.  We think of
pseudonyms as being names, like "wonderer" or "sam hill", or perhaps
as email addresses, like "hacker at univ.edu".  But from the point of view
of cryptography, these are just frills.  The important thing is the key.
With a public key, a pseudonym can sign his messages, so that nobody
else can successfully pretend to be him.  He can read messages sent to
him, messages which no one else can read.  If he has to switch email
addresses he can do so and still maintain his identity by continuing
to use the same key.  It is his key which is his real identity on the
net.  OK, back to the is-a-person credential:)
An is-a-person credential could be structured identically to the digital
coins used in Chaum's simple digital cash proposal.  You would go to the
credentialling agency and provide some unique form of identification,
something that no one else could forge.  Today this might be a thumbprint,
or in the future it could perhaps be a DNA scan.  However, you do not have
to identify yourself by name.  They don't need to know who you are; they only
know that you are a living, breathing human being, one whom they have not
seen before.  (There could be more than one credentialling agency, but they
would all share a database of thumbprints or whatever.)
You choose a special public key which you will use for all of your True
Name activities on the net.  This public key will be used to sign messages
which you want to prove are from a real person.  Any message sent with
that signature is known to be from a True Name and not from a nym.  Only
one True Name exists per person.
Note that this True Name doesn't have to be your real name.  If you want
to always post under John Q. Public and use this special key for that
purposes, you can do so.  But you won't be able to post under any other
name, including your own, as a True Name, not unless you use that same
key.  And of course if you do, people will be able to know that you are
the same as John Q. Public since you are using the same signature key.
The way this is established is that you take your True Name key, which
we'll call TN, and do as was done for Chaum's cash: pass it through
a one-way function f, and blind with a random number r^3: f(TN)*r^3.
You give this to the credentiallying agency when you come in with your
thumbprint, and they sign it by taking the cube root.  This is
f(TN)^(1/3) * r.  Back home, you divide by r, getting f(TN)^(1/3).
This is your True Name certificate.  You can submit it to a public key
registry along with TN; anyone can calculate f(TN) and verify the
credentialling agency's signature.  People will therefore know that this
key is the only one belonging to some real person which is signed in
this way.  Only one such key can exist for each person.
So, if people claim to be posting under True Names, they can prove it
very easily, by using their True Name key, signed by a credentialling
agency.  People can still post under as many nyms as they want, but only
one gets to call itself True.
Note that this solution doesn't reveal very much about the person.
Because the certificates are blinded by r^3 when they are signed, even
the credentialling agency has no way of knowing which thumbprints are
associated with which True Name.  (So, actually, it wouldn't be a problem
if the agency got your name and address when you came in - this still
couldn't be linked with your postings if you didn't want it to be.)
Nobody is forced to even use a True Name when they post; they could use
nothing but nyms.  On the other hand, if people want to reserve certain
conferences for True Names only, they can.  There is tremendous flexibility
to have as much or as little use of nyms as people want.
So, people should not be so quick to claim that crypto can only be used
to increase anonymity.  It is a powerful technology that can be used to
increase our control over information in many ways.  Chaum's papers
continue to amaze me with what is possible.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-10-30 18:13:35
@_author: hfinney@shell.portal.com 
@_subject: Signing keys for nyms 
The big weakness with public-key cryptography is making sure you have a
valid key for the person you are communicating with.  If you just get
a key off a key server, it's possible that the key has been faked and
does not actually belong to the person it claims to.  Key signatures
from trusted individuals testify that the key actually is associated
with the given userid.  Without a trusted signature, it's possible that
your messages could be read en route and then re-encrypted with the true
key of the recipient, who receives a properly encrypted message and
doesn't suspect anything.
In practice, this attack would normally be difficult to mount, as it
would imply some way of intercepting and altering the messages you are
sending.  But anonymous communicants are perhaps more vulnerable to these
attacks since their mail generally must go through a server system.  They
have to trust these servers not to reveal their true identity (at least,
with the penet.fi server), but there is also the danger that the server
could alter their messages as they pass through the server, possibly
posting false public keys for them.
If Wonderer, for example, communicated mostly through the penet server,
there could be many kinds of changes being made to his messages, and
he might not notice.  His key could have been changed, then when his
posted Cypherpunks message came back to him, it could have been changed
back to what he sent.  Encrypted mail to him could be read by the penet
operator and then re-encrypted with his real key.
(Naturally, I'm not suggesting the Julf would do something like this,
but the attack is possible in principle.)
Obviously this kind of attack could be defeated in many ways, such as
if Wonderer could check his postings through some other path than penet.fi.
But this might require him to expose himself in some ways (such as by
signing up to the CP list under his True Name) that he would prefer not
to.  Ideally, a nym should be able to explore interests completely
separate from any connection with his True Name.
In general, it seems to me that anonymity server operators are the ones
in the best position to create fake keys for nyms.  Eric's suggestion
that operators should sign the keys doesn't help much in this situation.
I'd say that other methods are needed to confirm that encrypted messages
to nyms are not being read en route.

@_date: 1993-10-30 18:14:21
@_author: hfinney@shell.portal.com 
@_subject: Chaum's credentials (technical question) 
In response to the recent discussions about identity, pseudonyms,
"is-a-person" credentials, etc., I've been studying Chaum's paper from
Auscrypt 90, "Showing Credentials without Identification; Transferring
Signatures between Unconditionally Unlinkable Pseudonyms."  This is quite
a dense and rather cryptic paper which requires careful reading.  It
doesn't help that the references got left off when the paper was printed.
There are also quite a few obvious misprints in some of the printed
I am trying to understand one particular passage, on page 258.  Chaum
uses the idea of a credential as an RSA signature on a pseudonym, where
the pseudonym is a number Px.  The RSA modulus has, in this case, two
exponents e1 and e2 which mean different things.  (Say, e1 means "good
credit risk" and e2 means "good driving record".)  The corresponding
private exponents are d1 and d2.  If a person has these two credentials
that means that he has the two numbers Px^d1 and Px^d2, from the
credentialling organization.  These RSA signatures prove that he actually
has the characteristics described in the credential.
Now, I am having a problem with Chaum's math.  This is a little technical
but I know we have some people on the list who know some number theory.
Here is what Chaum says:
   "Suppose an organization X were to require that you have each of two
   credentials, say both that with public exponents e1 and e2.  You could
   send X separatley Px^d1 and Px^d2.  It is also possible for you to use
   the two credentials to form the single credential Px^(d1*d2), which
   will be called their AND....  To create the AND, you: set g to the
   multiplicative inverse of d1 modulo d2; set h to the remainder after
   dividing g*d1-1 by d2; and computing
   (Px^d1)^g * (Px^d2)^(-h) = Px^(d1*d2)."
It would be really nice if this AND credential could be created like this,
because it might be applicable to digital cash.  Instead of having to go
through the complicated spending transaction for each piece of cash, you
might be able to combine all the pieces of cash into one, and just spend
that.  It would be more compact.
But Chaum's math doesn't work.  First of all, he says "you" should set g
to the inverse of d1 modulo d2.  But this seems to presume knowledge of
d1 and d2.  Yet "you" don't know these things; these are the secret
exponents of the signing agency.  So is Chaum actually talking here about
something the signing agency does?  It didn't sound that way from the
If the signing agency wants to compute Px^(d1*d2), given Px^d1 and Px^d2,
it can do so easily enough; simply take Px^d1 to the d2 power.  You don't
need to go through this rigamarole with g and h.  So that interpretation
doesn't make much sense either.
The other possibility I thought of is that he meant that the signing
agency would make g and h, as he defined them, public.  With g and h
then users could combine their credentials as he said.  But even that
doesn't work; his whole formula doesn't make sense.  g is the inverse
of d1 mod d2; this means that g*d1 = 1 mod d2, or in other words
g*d1 - 1 = k*d2 for some k.  That's the definition of the multiplicative
inverse.  Okay, but then he says h is the remainder when g*d1-1 is divided
by d2.  But look: g*d1-1 is a MULTIPLE of g2!  The remainder will always
be zero.  So that doesn't make any sense either.
So I thought, perhaps he really meant that h should be the quotient
rather than the remainder; it would be "k" in the equation I just wrote.
Then we'd have g*d1 - 1 = h*d2, which is somewhat encouraging because
it resembles his formula.  But his formula is (Px^d1)^g * (Px^d2)^(-h),
which is Px^(g*d1 - h*d2).  Rearranging the equation two lines above,
we see that g*d1 - h*d2 = 1.  So we end up with just Px, not Px^(d1*d2).
So this isn't right, either.
In fact, the notion that you can calculate Px^(d1*d2) from Px^d1 and
Px^d2 is pretty questionable, since the impossibility of doing this is
the basis of Diffie-Hellman key exchange!
In short, I haven't found any interpretation of Chaum's math that makes
sense.  Can anyone shed any light on this?  Was this just a mistake in
a paper which was, after all, just intended for conference proceedings,
not a refereed journal?  Thanks -

@_date: 1993-09-15 06:09:10
@_author: HFinney@shell.portal.com 
@_subject: Remail: errors 
I have been out of town for the last week, so I missed some CP mail.
It looks like some good things are happening with remailers, though.
Kudos to Karl, Sameer, and the others for their work!
I have received many messages to my remailer in the last week which
came from remail at tamsun.tamu.edu, which were PGP-encrypted apparently
in an effort to get my remailer to send them.
They did not work, though, because there was no "Encrypted: PGP" header
to trigger the remailer's decryption.  This can be arranged by
creating the message something like this:
Request-Remailing-To: hfinney at shell.portal.com
Encrypted: PGP

@_date: 1993-09-15 06:09:17
@_author: hfinney@shell.portal.com 
@_subject: caching scripts 
I am very excited to hear about Karl's progress in experimenting with
caching (batching) mail messages.  Karl, if it becomes convenient, I'd
appreciate seeing a copy of your scripts.
I have two thoughts about batching.  The first regards the mechanism
for arranging for activation of the batch scripts at regular intervals.
Karl mentioned at and crontab as two ways of arranging for this.  Some
users may not be allowed use of these functions.  I am not sure I can
use them on the systems which I use.
Another possibility, it occurs to me, would be an "activation" message
sent to each remailer from some system where crontab usage is allowed -
one of the systems which is owned by a remailer operator, for example.
This system would send out an activation message at midnight every night
to each remailer which had requested this function.  The activation
message would have a special header field which could be trapped by the
slocal program and cause it to run the batch script.
The other idea I had was to increase the volume of messages passing
through the remailers.  This way we could batch at more frequent intervals
while still having good "mixing" at each step.  Suppose some remailer
system took on the task of periodically injecting messages into the remailer
web.  Each message would be a large chain, perhaps through a dozen randomly-
chosen remailers, which would end up disappearing by being sent to a
"bit bucket" address like nobody at soda.berkeley.edu.  With the new
scripts appearing for producing random remailer message chains such a
program would be quite easy to write.
The message injection rate would be adjusted to give each remailer in
the system an average load large enough that batching would usually
have (say) ten or more messages to work with.  Perhaps nine of those ten
would be these dummy messages, while one is an actual user message.  But it
would not be easy to tell these apart, at least for user messages which
are in the middle of their chain; each message, dummy and real, is from
another remailer and to another remailer.  There is no hint as to which
are the actual messages.
It is true that user messages can be distinguished from dummy ones when
they are on their first or last stage in the chain; on the first stage,
they are the only messages coming from non-remailer addresses, and on the
last stage they are the only messages going to non-remailer addresses.
One way to fix this would be, instead of having the final destination
of the message be a "bit bucket" address, to instead choose a random
Internet address (say, from one of the "whois"-type databases), and to
send a message whose body starts with "Test message, please ignore".
With the tens or hundreds of thousands of addresses available (and with
the geometric growth of the Internet), it should not be necessary ever
to repeat an address.  So perhaps this slight annoyance to Internet users
would be tolerable.  Only a small fraction of users would ever receive
such a message.
The increase in traffic brought about by this dummy message source would
not be large in terms of the net as a whole.  It would only need to
introduce messages at the rate of (# messages per batch) * (# of remailers) /
(size of chain per message) per (batch interval).  Plausible values might
# messages per batch:      10
# of remailers:            20
size of chain per message: 10
batch interval:             6 hours
This works out to about 3 messages per hour, not too large a load.
Of course, this message injection system would only be maintained as long
as user message traffic remained too low to provide good mixing in a
batch system.  As user message traffic increases, the injection rate would
be decreased to compensate, until finally it might be possible to eliminate
the dummy-message injection completely.
Comments are appreciated, as usual.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-09-19 10:19:46
@_author: hfinney@shell.portal.com 
@_subject: Restrictions on crypto exports 
Like L. Detweiler, I can't resist the temptation to speculate a little
bit on the apparent legal crackdown on export of crypto.
The relevant section of the law is the Arms Export Control Act of
1968, codified in sections 2751 and following of Title 22 of the U.S.
Code.  Section 2778 deals with control of arms exports and imports.  In
that section, the President is authorized to determine what are "defense
articles"; the articles so designated constitute the "Munitions List".
"Any person who willfully violates any provision of this section...
shall upon conviction be fined for each violation not more than
$1,000,000 or imprisoned not more than ten years, or both."
So there are potentially very serious sanctions for violations of this Act.
One interesting point is the use of the word "willfully".  This has been
held in several court cases to mean that the government must show that an
accused not only exported munitions, but that he did so knowing that it
was illegal.  Legally, this means that there must be a showing of "specific
intent".  For example, in U.S. v Lizarraga-Lizarraga, the appellate court
wrote (in 541 F2d 826),
"At trial and on appeal, the defendant admits that he purchased the
ammunition and that he intended to export it to Mexico.  His defense is
bsed on the contention that he had no knowledge that his conduct violated
the law.  Hence, the appellant claims that to be found guilty under
22 U.S.C. 1934 [the predecessor to 22 U.S.C. 2778], the government must
prove that he intended to violate the statute....  We agree, and hold
that he was entitled to a specific intent instruction.  Accordingly, we
reverse his conviction and remand for a new trial."
The justice discusses several reasons for concluding that "willfully"
implies a need to show specific intent, among them that the articles on
the Munitions List are not obviously illegal to export, finally concluding:
"Accordingly, we hold that in order for a defendant to be found guilty of
exporting under 22 U.S.C. 1934, the government must prove that the
defendant voluntarily and intentionally violated a known legal duty not
to export the proscribed articles, and the jury should be so instructed."
There are several other court cases which agree with this conclusion.
Therefore, the government will have to show not only that PGP was exported,
but that whoever did it knew that the export was illegal.  For example,
the headnotes to U.S. v Malsom state, "Conviction for violation of 22 USC
2778 requires showing of criminal intent; use of circuitous shipment
route to ship replacement parts for military airplanes supports finding
of criminal intent."  Apparently in that case the parts were shipped in a
circuitous manner designed to prevent detection, and this fact itself was
evidence that the defendants knew they were breaking the law.
If PGP were exported overseas in some straightforward manner, such as being
made available for FTP in the U.S., it would be much harder for the
government to show criminal intent than if it had been written onto a floppy
hidden in a crate of frozen vegetables or something.  So it will be interesting
to see how the government approaches the intent issue.
Other interesting points come from the ITARs themselves, which implement
this section of the U.S. Code.  Subchapter M of Title 22 of the Code of
Federal Regulations is the International Traffic in Arms Regulations.
This subchapter encompasses sections 120 and following of that Title.
Section 120 has mostly definitions, section 121 has the Munitions List
itself, and the remaining sections deal mostly with regulations and reporting
Category XIII of the Munitions List, Auxiliary Military Equipment, includes:
"Cryptographic (including key management) systems, equipment, assemblies,
modules, integrated circuits, components or software with the capability
of maintaining secrecy or confidentiality of information or information
systems".  It is followed by a long list of exceptions, and exceptions to
the exceptions, none of which appear to apply to PGP or RSA.  So on the
face of it, this appears to be a fairly broad prohibition on the export
of cryptographic software.
However, there is an interesting sentence in part 125 of this subchapter.
In 125.1(a), it says, "Information which is in the 'public domain' (see
section 120.18) is not subject to the controls of this subchapter."  Note
that by "this subchapter" it must mean Subchapter M, the entire ITAR.
"Public domain" is defined in 120.18:  "Public domain means information
which is published and which is generally accessible to the public:
(a) Through sales at newsstands and bookstores; (b) Through subscriptions
which are available without restriction to any individual who desires
to obtain or purchase the published information; (c) Through second class
mailing privileges granted by the U.S. Government; or, (d) At libraries
open to the public."
So, this is a possible defense against a charge that exporting PGP or
other RSA software violates the ITARs.  If one could argue that the software
was public domain, and that the software could be considered "information"
(hard to argue against if it was exported electronically), then it is
not covered by the ITARs.
The public domain issue is not completely clear, but one could certainly
make a case that software available on BBS sites or by FTP fell into
categories (b) or (d) of the public domain definition, or at a minimum
that the degree of public availability in these situations is very similar
to that envisioned by the authors of this definition.
Alternatively, the defense could argue that irrespective of whether a
particular implementation was public domain, that the main cryptographic
algorithm involved, the RSA cryptosystem, was certainly public domain by
the letter of the definition.
So, if there is a court case, I'd expect that this might be one of the main
issues of contention between defense and prosecution.
The last issue I'll mention is the meaning of "Export".  This is defined
in 120.10.  "Export means, for purposes of this subchapter: (a) Sending
or taking defense articles out of the United States in any manner, or...
(d) Disclosing or transferring technical data to a foreign person,
whether in the United states or abroad..."
I've just listed the most relevant parts here.  Several months ago, Jim
Bidzos of RSADSI published a document attacking the legality
of PGP, and in that document he claimed that making PGP available for
FTP constituted export, and in fact that posting it to your neighborhood
BBS also constituted export.  (Ironically, a few weeks later there was
a flap when RSADSI made its own RSA software available for FTP, and some
foreign nationals downloaded it.)  The presumed justification for this
reasoning would be that making the information publically available in
this way could "disclose" it to a foreign person.
A similar argument was described in a very interesting post Dan Bernstein
made to sci.crypt a few months ago.  Dan was trying to get permission to
export information about a cryptographic technique he had developed:
   Excerpts from a State Department conversation
   Daniel J. Bernstein
   22 July 1993
   Here are some excerpts, edited for legibility, from a conversation I had    with Charles Ray of the Office of Defense Trade Controls on 26 March    1993. These excerpts are now in the public record. Please do not assume    that the comments below reflect any official State Department position,    although my notes list Charles Ray as a ``special assistant'' to DTC    Director William B. Robinson.
   Dots represent omissions, not pauses. DJB means me. CR means Ray.
   DJB: What I'm trying to understand is: Suppose somebody makes some
   technical data which is a defense article, it's on the Munitions List,
   and goes to a library. The library agrees, and puts it on their shelves.
   Then ... doesn't that make it public domain, assuming that there are no    contractual problems or anything?
   CR: Actually, that could be argued a number of ways. But it could also
   be argued that if the person made something that was a Munitions List
   item, and particularly if they did it knowingly and they put it in a
   public library where anyone has access to it, that it could be    considered a violation of the Arms Export Control Act. It would I think
   depend a lot on their motives for doing it.
   [Material elided]
   CR: ... Hypothetically, if a person deliberately created a Munitions    List item, and deliberately placed it in a public library so as to evade    the restrictions ... I think that person might still find himself or    herself subject to certain sanctions should there be an incident of this    information falling into the hands of a foreign entity.
So, here Ray is basically making that same argument, that putting something
into the public domain by putting it into a library could itself be
considered "export" if it resulted in a foreign entity getting access.
So, the government may be trying to set up a "Catch 22" situation here,
where any attempt to make information "public domain" will be automatically
considered an attempt to export it.
I would think that the defense could come up with some good replies to
any attempt by the prosecution to make this argument.  The ITARs are
intended to control foreign export, and it appears to be a large extension
of their power to attempt to control what things American citizens may take
to their own domestic libraries.
Of course, people should remember that the investigation is still at
an early stage now.  The grand jury may or may not decide to issue criminal
charges; if they do, the accused may choose to plead guilty to a lesser
charge rather than take the risk of a court battle; even if the matter
goes to court, the accused will of course choose his defense based on
his own considerations of advantage.  It's not clear that even a favorable
court decision will free the flow of cryptographic software.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-09-21 03:46:29
@_author: Hal Finney 
@_subject: REMAIL: policy 
hfinney at shell.portal.com
  hal at alumni.caltech.edu
I keep logs only of the date/time at which my remailers get used; no
logging is kept of the message contents.  I do this only to get a
picture of the overall volume of messages passing through my remailer.
The Unix systems on which I run these remailers may also do some
logging; I haven't been able to determine exactly what is done.  I
presume this might include incoming and outgoing addresses as well as
message date/time and possibly size.  (I am familiar only with uucp
mail and don't know where to look on these net-connected Unix systems
for sendmail logs.)
My account on alumni.caltech.edu is free, based on my membership in the
school alumni association (for which I paid some $300 about fifteen years
ago for a life membership).  My account on shell.portal.com costs my about
$20 a month in fixed costs, plus $2/hour connect charges which typically
run another $30 a month or so.  So I am paying these people quite a bit and
I hope therefore that this will give me some bargaining strength if political
problems arise from the remailers.
However, due to the large number of users on these systems, there are many
restrictions on my usage.  I cannot leave daemon processes running, nor can
I use at or cron to schedule periodic jobs.  The nice thing about the
current remailer scripts is that they can be triggered by incoming mail
without having a high profile to system administrators.
Both of these systems appear to be well connected on the net and are almost
always available.  Both support PGP encryption.
I am hoping to add batch capabilities to the remailers soon, based on Karl's
scripts.  I also like Karl's suggestion to add message padding to outgoing
messages.  If this system were used in conjunction with batching then if
all messages in a batch were outgoing-padded (undetectably) to the size of
the largest message in the batch then there would be total hiding of the
incoming-to-outgoing message mapping.
Earlier I had assumed that both incoming and outgoing messages would have to
be standardized in size but now I see that padding of outgoing-only messages
would be sufficient.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-09-21 03:47:30
@_author: Hal Finney 
@_subject: Timing of Moby subpoena 
Since Moby Crypto is, as I understand it, composed of material which is
generally available all over the world, it may not be necessary that it
be exported from the U.S. in order to exist in a foreign country.  One should
be careful about accusing others of conspiracy to violate the ITARs, even
qualifying it with "in essence".
The note that Steve is referring to is presumably this.  Note the date:
I think the relative timing of this announcement and the subpoena makes
it questionable whether the subpoena was in response to this posting.
According to Ward's later post:
This is two days after Ward's message, which is pretty fast response
for law enforcement.  But this is the date of service.  The subpoena
had to be issued and signed before this.  Did that occur after Ward's
Sep 14 posting?  It's not 100% clear, but what the subpoena itself, as
posted by Grady, says is:
If Sep 9 is the date on which the subpoena was actually issued, this was
five days before Grady Ward's post which supposedly triggered the subpoena.
Unless the Feds are prescient, they must have been planning to subpoena
Austin Code Works about Moby Crypto, PGP, and RSA long before Ward's post.
hfinney at shell.portal.com

@_date: 1993-09-23 04:07:12
@_author: hfinney@shell.portal.com 
@_subject: Propriety of crypto on Munitions List 
In U.S. v Martinez, Elizabeth Martinez and her fiance were convicted
of violating the Arms Export Control Act by exporting cryptographic
hardware, namely "Videocipher II" video descrambling devices.  (I
believe these are used to descramble satellite TV broadcasts of HBO and
other networks.)  Defendants appealed, asking the court to overturn
their conviction on the grounds that "the inclusion of 'cryptographic
devices and software (encoding and decoding)' on the [Munitions] list is
overbroad because this heading includes items already in the public domain
whose dissemination would pose no security threat, and which lack any
characteristic that is inherently or predominantly military."
The 11th circuit appellate court rejected this argument in 904 F2d 601.
The court decided that the question of whether an item properly belongs
on the Munitions List is inherently political and is excluded from judicial
review.  "The question whether a particular item should have been placed
on the Munitions List possesses nearly every trait that the Supreme
Court has enumerated traditionally renders a question 'political'....
No satisfactory or manageable standards exist for judicial determination
of the issue, as defendants themselves acknowledge the disagreement
among experts as to whether Videocipher II belongs on the List....
Neither the courts nor the parties are privy to reports of the intelligence
services on which this decision, or decisions like it, may have been
based....  The consequences of uninformed judicial action could be grave."
In these days of judicial activism, it is ironic that one time when civil
libertarians might wish the court to take a hand and reverse a decision
made by the other branches of government, the court chooses not to do so.
Shortly before this decision was issued, the AECA was amended by adding
the following section, 22 USC 2778(h): "The designation by the President
(or by an official to whom the President's functions under subsection (a)
have been duly delegated), in regulations issued under this section, of
items as defense articles or defense services for purposes of this
section shall not be subject to judicial review."
So Congress and the court agree that the propriety of an item's placement
on the Munitions List is not a matter for the courts to decide.  There
appears to be little chance that any prosecution for AECA violations
will result in the judical removal of cryptographic equipment from the
Munitions List.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-09-23 04:08:11
@_author: hfinney@shell.portal.com 
@_subject: First amendment and ITARs 
In U.S. v Posey, 864 F2d 1487, the defendant was convicted of violating
the Comprehensive Anti-Apartheid Act ("CAAA") and the Arms Export Control
Act ("AECA") by sending design documents relating to the C-130 aircraft
to South Africa.  Posey obtained these documents from the U.S. government
via the Freedom of Information Act.  The U.S. government agreed that these
documents were technically public domain within the meaning of the ITAR's.
However, the CAAA, which applies only to exports to South Africa, does
not contain the "public domain" exemption that the AECA (which applies to
exports in general) does.  The recent grand jury action regarding PGP
appears to involve possible violations of the AECA.
Posey appealed on several grounds, one of which was that these Acts
violated his first amendment rights, since the information was, after
all, freely available.  The court rejected this argument, with a lengthy
(and, to my mind, somewhat confused) discussion, which is worth repeating:
  VII. FIRST AMENDMENT
  Appellant's final argument is that the First Amendment bars the
  government from restricting the export of information that is already
  available to the public.  He insists that the data he sent abroad
  was available under the Freedom of Information Act, and therefore
  could be legally obtained by virtually everyone in the world.  He contends
  that the First Amendment prohibits the application of the AECA and
  CAAA to the export of such publicly available information.
  Our Court has already considered and rejected this argument.  In
  United States v. Edler Industries, 579 F2d 516 (9th Cir. 1978), we
  rejected an essentially identical challenge to the predecessor of the
  AECA.  The defendant was convicted of exporting certain manufacturing
  designs that were on the Munitions List but were not classified.  He
  challenged his conviction on First Amendment grounds, arguing that the
  government could not constitutionally prohibit the export of techno-
  logical data that was widely distributed within the United States.  In
  rejecting that claim, we explained that even assuming that the First
  Amendment offers some protection to the dissemination of technical data,
  the government has a strong interest in regulating the export of
  military information:
    The federal government undeniably possesses the power to regulate the
    international arms traffic....  As a necessary incident to the power
    to control arms export, the President is empowered to control the
    flow of information concerning the production and use of arms.  The
    authority to regulate arms traffic would be of negligible practical
    value if it encompassed only the exportation of particular military
    equipment but not the exportation of blueprints specifying the
    construction of the very same equipment.
  579 F2d at 520.  We accordingly concluded that the government could
  permissibly restrict the flow abroad of data included in the Munitions
  List.  579 F2d at 521.  Finally, we held that the government's power
  to issue such restrictions was not affected by the domestic availability
  of the regulated data:
    Given the unquestionable legitimacy of the national interest in
    restricting the dissemination of military information, the claim of
    public availability in the United States is not a defense recognized
    by the Constitution.
  579 F2d at 522.
  Appellant attempts to distinguish Edler from the present case by pointing
  out that the exported data in Edler was "cutting edge" technology and
  was not widely used in this country.  [Citation].  Whether or
  not this was factually true of the technology at issue in Edler, however,
  the Edler decision clearly assumed for purposes of its decision that
  the material was extensively available in the United States.  See 579
  F2d at 518, 522.
  Moreover, we believe Edler should not be read as permitting the govern-
  ment to restrict the export of only that information which is not
  widely available domestically.  Under appellant's reading of Edler,
  if the government wished to prevent technical data from being sent to
  foreign powers, it would be required to suppress the information alto-
  gether, at home as well as abroad.  This outcome would blur the fact
  that national security concerns may be more sharply implicated by the
  export abroad of military data than by the domestic disclosure of such
  data.  Technical data that is relatively harmless and even socially val-
  uable when available domestically may, when sent abroad, pose unique
  threats to national security.  It would hardly serve First Amendment
  values to compel the government to purge the public libraries of every
  scrap of data whose export abroad it deemed for security reasons
  necessary to prohibit.  We conclude that appellant's conviction does
  not violate the First Amendment.
(Hal speaking again here.)  The thing I find somewhat ironic about this
decision is this last paragraph.  The court is saying that if the First
Amendment implied that domestically available information could be exported,
then the government might have to restrict domestically available
information.  But, this ignores the fact that the AECA already contains
an explicit exemption for public domain information.  So, the court is
going to some length in this last paragraph to consider an argument which
is mooted by the public domain exemption in the AECA.  And in fact, as
we have seen, at least one government official is daring to argue that
this provision of the AECA does in fact give the U.S. government the
power to keep Munitions List information out of public libraries!
In any case, this decision and the earlier one it quotes both represent
rejections by the 9th circuit appellate court (which includes California,
where the grand jury investigations are taking place) of the argument
that the ITARs infringe on First Amendment rights.  This will make it more
difficult to use the First Amendment defense in any new charges of arms
export violations.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-09-23 10:20:32
@_author: Hal Finney 
@_subject: Mail outage 
My remailer at hfinney at shell.portal.com is apparently unable to receive
mail today and last night.  I have complained to customer service about this
and hopefully the problem will be resolved soon.
Hal Finney
hfinney at shell.portal.com

@_date: 1993-09-29 23:21:50
@_author: hfinney@shell.portal.com 
@_subject: REMAIL: Message expansion 
One of the problems with chaining remailers as we do it now is that
the message becomes quite a bit larger as you wrap encryption layers
around it, one for each remailer in the chain.
Currently, the remailers are all text-based, which requires that the
message be re-ascii'd at each stage of the encryption nesting.  But
ascii'ing a binary file using PGP's method increases its size by 1/3.
If this asciification could be avoided at each step, the message would
still grow as we add the PGP header and the remailing instructions at
each step, but this would be more moderate.  The PGP header is about
170 bytes, and the remailing instructions should not be more than
70 or 80 bytes, bringing the total to something less than 250 bytes
per step.
I did some calculations.  Suppose you wanted to start with a message
of, say, 4000 bytes which you will send through ten remailers.  First
off, we get an advantage because PGP will compress the message before
encrypting it the first time.  Let's suppose it manages to compress
it by a factor of two.  This means that we have a 2000-byte binary
message as our actual starting point.
In one model, we assume that we add 250 bytes per step.  This is what
it would be if we did not have to do the ASCII'ing process at each
nesting.  In the other model, we assume that we add 170 bytes, multiply
by 4/3, then add 65 bytes for the "-----BEGIN PGP MESSAGE-----" stuff,
and then another 80 bytes for the remailing instruction.  This is how
most of the chaining software actually works now.
Setting up for a ten step chain, the first method produces an output
file of 4500 bytes, while the second produces a file of 54046 bytes.
This is quite a difference.
If we wanted to add three more steps because we feel paranoid, the
first method increases to 5250 bytes, while the second balloons to over
120K bytes!
As a more extreme example, if the initial message was 10K bytes as we
have sometimes seen here, a ten-step chain would produce an output of
7500 bytes without expansion, and over 100K bytes with expansion.
(The smaller-than-input size in the non-expansion case is due to the
assumed 2-to-1 PGP compression of the original message.)
I think we should consider enhancing the remailers so this asciifying
step is not necessary.  It could be done something like this.
As each remailer receives the message, it must be in ASCII since that
is the only thing that makes it across the mail connections.  It decrypts
and de-ascii's it by running it through PGP just like it does now.
Suppose this produces something like the following:
Request-Remailing-To: The first part is in ASCII and is terminated by two new-line characters
in a row.  The rest of the message can be easily determined to be binary;
in fact, it is a binary PGP file, one readable for the NEXT remailer
in the chain.  This could be detected because PGP puts special bytes at
the front of the file.
All the remailer has to do specially is to asciify the binary portion of
the message, add the "Encrypted: PGP" header if we still use that,
and send it off as it normally would.  The next remailer receives a proper
ASCII PGP message which it can handle by the same rules.
Making this enhancment to the remailers would reduce the problems of
message bloat caused by the redundant asciifying of the message for each
stage of the remailer chain.  As we move towards remailers which do batching
and which do message padding so that all outgoing messages are the same
size, it will be more important to avoid this bloat since one big message
will force all others in the batch to be padded to that size by the
Hal Finney
hfinney at shell.portal.com

@_date: 1994-04-02 16:45:35
@_author: Hal 
@_subject: DEATH TO THE 
One thing worth noting about the burst of remailer messages is how much
worse it could have been.  Each message was sent to many remailers, with
requests to send it on to many more.  Potentially the message could be
duplicated n-fold at each step, until horrendous numbers of messages were
circulating through the remailer network and being sent to the other
Luckily, this didn't happen, apparently because most remailer software does
not support multiple recipients.  But the lesson is that as people deploy
new remailers and improve the software, "multiple recipients" should *not*
be added as a feature, IMO.  Doing that would make the network vulnerable
to these kinds of geometric-growth attacks.  It would be so easy to do it
that people would probably be tempted to try just for kicks.  So I think this
feature should definately be left out of future remailer plans.

@_date: 1994-04-02 17:34:50
@_author: Hal 
@_subject: REMAIL: standardized remailer syntax 
I like Sameer's goal of standardized syntax, but I have to admit that I
find the :: and  bit confusing, and hard to explain.
The way Eric Hughes' original remailer worked was that the "remailer
commands" were in the message header, up with Subject and In-Reply-To and
such.  However, many mailers won't let people put custom material there, so
the "::" pasting token was invented to take the following lines and put
them into the header before the remailer processed them.  The effect was
that you could put remailer commands after "::" and they would work.
But there were also some situations in which the user might want to
control message headers as they *leave* the remailer.  For example,
they might want to put a Reply-To to some anon pool so that they could
receive reply messages.  So Eric created the " pasting token for
those.  The remailers based on his scripts first look for "::" and add
in any headers following it; then they process the message, looking for
command lines in the header; then as they remail it they look for "
and stick any following lines in the outgoing message header.
This all makes sense but it makes for a complicated system.  I think people
would find it easier to understand an approach in which they put remailer
commands at the top of their message, marked in some way to separate them
from the rest of the message.  "::" on a line by itself could indicate the
beginning of a block of remailer commands, terminated by a blank line.
Or, as an alternate syntax, each remailer command line could start with
"::" followed by the text of the command.  Both approaches have been used
by different software on the net and they could be considered two different
ways of expressing the same thing.
This would get away from the add-to-header/process-header/add-to-header
approach of the current Perl remailer scripts and use a simple one-step
"process remailer commands" approach which I think would be simpler.  You
could still have all the functionality of the current approach (perhaps a
paste-outgoing-header command could be used for the " functionality) in
a package which is conceptually simpler (to me, at least).
Another advantage of this approach is that you could make use of the order
of the commands in the remailer block so that you could have finer control
over what you are asking the remailer to do.
I would suggest abandoning one of "Anon-To" or "Request-Remailing-To",
as they are redundant.  I know above I suggested two redundant ways of
specifying remailer commands; maybe that should be reduced to one, as well.
Many of the remailers pass Subject lines.  I don't think they should.
Chael's approach makes sense to me.  The best thing is to have a way to
set the subject as the message leaves the last remailer in the chain.  (My
"chain" program does this automatically.)
I sent mail a few minutes ago (before seeing Chael's message) suggesting
the danger of this in making it easy to create huge numbers of messages.
We have had a lot of talk about logging.  My feeling is that one should get
security in using the remailer network by going through a number of machines
in widely different regions.  It should not, as was suggested here some time
ago, be a matter of trusting any given remailer operator.  Privacy is not a
gift being provided by remailer operators to their users.  It is still some-
thing that the users must provide for themselves.  The remailers are just a
tool to help achieve that.
Thanks to Chael for re-kindling this discussion.

@_date: 1994-04-03 23:44:12
@_author: Hal 
@_subject: Cyberspace, Crypto Anarchy, and Pushing Limits 
A thought-provoking essay as usual from Tim.  However, I see a contradiction
The problem I have is that it is not clear that cyberspace is a space,
that one can identify regions which have boundaries, and which can be
patrolled by owners.  These physical, 2-D and 3-D concepts do not map well
to cyberspace.  Cyberspace is more of a mental conception, a meeting of
the minds.  It's not clear that it can be owned.
For a concrete example, who owns the Cypherpunks list?  Tim and Eric started
it, Eric keeps the software working, and John Gilmore supplies the machine,
as I understand it (apologies if I am leaving someone out).  Do they own
the list?  What about the role of the contributors?  Aren't they the ones
who give the list value?  (Granted, Tim, Eric and John have been some of the
best contributors, but that is separate from their role, if any, as owners
of the list.)
Suppose, as Tim implies, that the list someday evolved to be some kind of
virtual list, hosted on a flexible network of machines around the globe.
Who would the owners be then?  I would suggest that there would not nec-
essarily be any.  The list would be a voluntary meeting place for people who
had certain interests.  Its existance would be essentially defined by the
commonality of that interest.  It exists not in a cyberspace thought of as
machines on a net of wires and fiber, but in a conceptual space that
transcends the physical machines which support it.
The issue of the ownership of cyberspace has similarities more to the
ownership of intellectual property than of houses and roads and other
physical objects, IMO.  And the problems which arise when you try to
fence off part of intellectual property space will also be a part of
attempts to own cyberspace.
Just another view -

@_date: 1994-04-04 08:34:08
@_author: Hal 
@_subject: REMAIL: Ray's improved anonymous remailer 
I meant to reply to this several weeks ago, but was too busy then, so here
are some comments now.
This sounds like an interesting approach.  WEB is Knuth's methodology
for creating self-documenting programming projects.  You run them through
a filter to create the executable code, Perl in this case.  This should
help portability and ease of support.
These mostly sound like great features.  The virtual addresses are something
we have needed for a long time.  The idea of keeping records of which remailers
are responding should help with the use of the network, too.  The one problem
with this is that it might be tempting for the users to just trust the
remailers to choose their chain paths.  It would be much better for the user's
own software to hook up, find out which remailers are operating, then choose
a chain.  Ray's software will allow this, but this function could be split
off from the remailers to a specialized server, perhaps.
I'm not sure about the advantages of remailers signing and encrypting messages
between themselves.  It seems to me that the network should work even without
this.  Ideally we don't want the remailer network to be too centralized and
close-knit.  It's better for them to be strangers to each other since if they
coordinate their efforts they can defeat anonymity.
This was one reason I suggested supporting both old-style CP and the
extropians-style syntax ("::Anon-To").  As Ray suggests, in some cases we
might not have message headers in the RFC822 sense.  I think it is simpler
to think about a message which has remailer commands at the top.
The number of sites which allow users to run socket servers is far smaller
than the number which allow mail filters, so not many people will be able
to use this feature.  OTOH the mail-only sites are generally of low security
and an owned-and-operated system should be able to use this feature.  So it
is definately a plus for those who can use it.
This is a good feature, but it should also be available from non-socket
remailers.  There should probably also be a "Help" command to tell how to
use the remailer.  (A lot of people already have these features.)
Ray had mentioned above that these user handles can also map to encrypted
remailer strings.  This way users don't have to trust any one remailer op-
erator to keep their identity secret.  This need for trust is one reason
I am not enthusiastic about user as an
address, although it is admirably concise and easy to use.  The problem is
that it exposes the path to the first remailer in the chain.  I really feel
that paths must use nested encryption to be of much value.  Similarly, the
darkmodem requires the user to really trust the first remailer
in the chain.  Perhaps it deserves such trust, but I feel that a system which
does not require such trust would be superior.  (Again, Ray's proposal is
broad enough that it will allow non-trust modes of operation, as I understand
it; my main concern is that these other options are so easy that they will
tempt people to be lazy and slip into modes where they are vulnerable to
unscrupulous remailer operators.)
I am really looking forward to seeing Ray's software.  It sounds like a
good package of functions.

@_date: 1994-04-04 12:59:10
@_author: Hal 
@_subject: This List--Public, Private, or Other? 
I can find a lot more to agree with in Tim's clarification of his views
on ownership of cyberspace:
Getting back to the original discussion, though, I think the point remains
that such a tenuous and abstract form of ownership does not serve as a good
foundation for a model of cyberspace as private property.  Cyberspace, in
my view, is essentially a conversation.  Its value comes from the interplay
between different people who contribute, each bringing their own expertise
and points of view.  It seems odd to me for someone to lay claims to the
ownership of the conversation, especially someone who is not
One problem in thinking about these issues is focussing too closely on cur-
rent software in the form of mailing lists and usenet.  Already newer
forms of communication such as IRC, MUDs, etc. are breaking out of these
molds.  Other possibilities include more fluid communications models where
organization is provided by links between messages.  In such a system, there
would be no "cypherpunks list" as such; rather, messages on the kinds of topics
we find interesting would be linked together in various ways, with side ties
to messages on related topics as well.  Who would "own" this kind of
One possible unambiguous answer is to simply say that people own their own
words, and to leave it at that.  In that sense nobody owns the cp list;
rather, each poster owns his postings.  This is pretty uncontroversial, I
think.  But even then the value of a posting depends heavily on the context
in which it appears, and this simple ownership model does not particularly
capture that.
Because of these considerations, I think cyberspace is not really subject to
the kinds of ownership and control that we associate with private property.
Look at the Extropians list as an example.  They try to say that the list
is private property and feel free to kick people off.  But sometimes people
get disgusted with their autocratic practices and leave.  The list ends up
losing value.  The more they tighten their iron fist of ownership the more
individuals slip out of their grasp, to paraphrase noted cyberspace pundit
Princess Leia.  (I say this not to disparage members of that list, which has
a lot of talented people, but because to me it is a good example of the mis-
application of the idea of private property.)
My model of the ultimate future of cyberspace emphasizes selectivity
and filtering of a huge corpus of messages, articles, essays, debates,
etc.  The hard part is going to be picking out what is interesting to
you, and making your contributions in such a way that interested people
see them.  I really don't think our current infrastructure of mailing
lists and usenet does a very good job of this, and I hope that in the
future better approaches will be possible.  It's not clear what role
ownership will play in that system.

@_date: 1994-04-05 08:44:53
@_author: hfinney@shell.portal.com 
@_subject: Economic assumptions 
There is alt.privacy.anon-server.  BTW, while reading some postings in that
group just now I noticed that yesterday was the first birthday of the jarthur
remailer's key.  Happy Birthday!
Actually, I don't think most people are interested in remailers yet.  Most
people can't even use encryption.  I view encryption as being a first step
towards privacy, with remailers being a second step, protecting the destina-
tion of a message like encryption protects its contents.  Also, without
encryption the protection provided by a remailer is not very great.
OTOH, I could see someone arguing that remailer use, even without
encryption, is an important privacy technology in its own right, as we
have seen with anon.penet.fi.  The privacy provided by that system may
not be defensible against a powerful agency which can tap network
links, or even for hackers who can forge mail, but it is enough for
most people, most of the time.
Eric spoke of transaction costs in using the remailers, but to me the biggest
problem is obvious: there is no system that I know of that allows me to
send or post a message pseudonymously, such that no one person knows the
mapping of my pseudonym to my true name.  I know that a lot of people have
been talking about new systems lately, so maybe I am wrong about this.  Ray's
proposal would allow it, with his virtual encrypted addresses, but that is
not running yet.  I think this is the biggest barrier to using pseudonymous
Another thing worth noting is that pseudonymity has a terrible reputation on
the net.  Look at the complaint we saw here from Stewart Brand a few days ago.
And unfortunately, it does seem that most anonymous postings are of very low
quality, at least in the groups I read.  Perhaps we need a concerted effort to
make high-quality anonymous/pseudonymous postings in order to improve the
reputation of this technology.  Maybe then the books will start writing about
it.  (The recent newspaper article posted here was as favorable a treat-
ment of the topic that I have seen.)

@_date: 1994-04-05 22:48:23
@_author: Hal 
@_subject: Bekenstein Bound (was: Crypto and new computing strategies) 
The big bang is also perfectly consistent with an infinite and unbounded
universe.  This is part of the well-known debate over whether the universe
is "open" or "closed".  An open universe is infinite in extent.
However, at any given time only a finite portion of the universe is avail-
able, so the infinity is not really accessible.

@_date: 1994-04-05 22:49:54
@_author: hfinney@shell.portal.com 
@_subject: Proposal: some more standard remailer features 
Why look for *two* blank lines to end a command block?  Why not just end a
command block when you find a line not starting with ::?
This is reminiscent of MIME.  Have you looked at that?  They already deal
with encapsulation as well as message splitting, I think.  You could copy
their message formats without committing to full MIME support.  Plus it
might be possible to add encryption and remailing support to MIME mail user
agents by using the hooks they already provide.
The only thing that seems wrong about this is that the remailer apparently
has to know whether it is sending to a person or another remailer.  I think
you should follow instructions about pasting these header fields by what
the user has requested rather than deciding for him.  Maybe I don't under-
stand exactly how Ray is proposing that these commands be used.
I would recommend that they not be preserved, but I suppose that is up to
the operator.
This may sound crazy, but I am concerned about adding these features which
make the system too easy to use.  It seems that at the limit a person can
just put "::To: friend at college.edu at
the top of his message and his mail goes zipping down this extremely com-
plicated path.  But the problem is that this is really deceptive in
terms of how secure it is.  All this ease of use is at the expense of having
to put a lot more trust into one or a few remailer operators.
It's not clear that it's better to provide the temptation of easy-to-use but
falsely secure remailers.  At least with Julf you know you're trusting him.
With addresses like the above users may not realize how many eggs they're
putting into that first remailer's basket.
This kind of splitting would be more useful if it were carried through
to the end user.  Otherwise the reassembled message is conveniently
provided for inspection by the spooks as it goes to him.  Again, I think
MIME may provide for reassembly at the end user.
Would this be used with the "*" remailer-chooses-remailer feature?  If the
user specifies the path then presumably there is no provision for remailers
to make choices like these.
Despite my concerns, I think Ray has so many good ideas here that it will
be great to see his software operating.  The "market" for remailers is the
users who want both privacy and ease of use.  Ray's enthusiasm and energy
in putting all these ideas into code will go a long way towards finding out
what kinds of trade-offs the market wants.

@_date: 1994-04-05 23:14:21
@_author: Hal 
@_subject: Chaum on Traceable Cash 
I wrote something last week on whether digital cash should be traceable.
Here is a quote by Chaum in favor of traceable cash.  It is from Eurocrypt 87,
"Blinding for Unanticipated Signatures", on page 228:
"The ability to anticipate a large number of signature types can benefit the
payment system described in [Chaum, D. "Security without identification:
transaction systems to make big brother obsolete," Communications of the
ACM, 28, 10 (Octoboer 1985), pp. 1030-1044].  This would allow customers of
the bank providing a system to each supply a large number of blinded items
when their accounts are opened, without the customers knowing in advance
which particular type of signature will later be applied by the bank.  Not
only can this provide economy of data transfer, but it protects the bank's
customers from being able to (and hence from being coerced into) making
payments that they cannot later trace."
The technical basis for Chaum's statement is obscure, but the political
point is that if you can make an untraceable payment, you could be coerced
into doing so, for example by being robbed at gunpoint.  Contrariwise, if
the cash system used by you and your bank is such that all money is in-
herently traceable, it will be a lot harder to commit robbery, extortion,
kidnapping, and all those other horrors which people fear will come with
digital cash.

@_date: 1994-04-06 19:35:29
@_author: hfinney@shell.portal.com 
@_subject: Pseudonyms and Reputations 
New members of the list may not be aware of the background of some of
the technologies we discuss here, such as the remailers.  The purpose
of these systems is not really to help people mailbomb newsgroups or
send harassing letters to their fantasy girlfriends without fear of
One goal of remailer-type technology (which present systems don't
meet very well) is to allow people to use pseudonyms for their
electronic activities.  By using a "nym" a person is able to
engage in communications of various types without fear that some
aspect of what they say or do will impact them negatively in "real
life".  There are a lot of potential forms of harm which could arise
now and in the future from databases recording the various
interactions a person has had in cyberspace.  By preventing the
linkage between his online activities and his real identity he can
protect himself and his privacy.
At the same time, nyms allow for continuity of identity to be
maintained over a period of time.  A person posting under a nym
can develop an image and a reputation just like any other online
personality.  Most people we interact with online are just a name and
an email address, plus whatever impression we have formed of them by
what they say.  The same thing can be true of nyms.
Cryptography plays an important part in making effective use of
nyms possible.  The first thing it can do is to allow users to send
and receive messages under the name of their nyms without anyone
discovering the True Name (capitalization from Vinge's short story
"True Names") behind the nym.  Cryptographer David Chaum has proposed
two technologies for this; the network of "Mixes", on which our own
remailers are modeled; and the so-called "Dining Cryptographers'
Network" (DC-Net), which allows a cooperating group to send messages in
such a way that it is not possible to tell which member of the group
originated each message.
Cryptography can also help maintain the continuity of the nym,
by allowing the user to digitally sign messages under the name of the
nym.  The digital signature cannot be forged, nor can it be
linked to the True Name of the user.  But it makes sure that nobody
can send a message pretending to be another person's nym.
These techniques are already in use or under development, in some
form or another.  But there is much more that could be done to provide
privacy protection and flexibility in the use of nyms.
One possibility is a digital reputation system.  Presently people and
nyms develop informal reputations in the minds of their readers.  This
could be formalized by allowing readers to create endorsements of
various types for those who have worthwhile things to say.  An
endorsement could take the form of a digital signature by the
endorser.  In the simplest form, the endorser would digitally sign a
message which said, in encoded form, "In my opinion, person (or nym)
XXX produces high-quality messages".  This endorsement would be kept
by the person it was given to and shown when he enters a new
cyberspatial forum to help establish an initial reputation.
People who are able to bring a variety of endorsements from respected
individuals or organizations will be able to have their words carry
weight from the beginning.  Without these, a new poster may find that
not many people can even be bothered to read his messages amongst the
flood of others.  The endorsements can break through the barriers, the
filters which people use to decide what information to receive.  They
represent a digital reputation which can be carried to distant regions
of cyberspace.
One could imagine more elaborate forms of endorsements, as well.
Chaum describes a technique by which a numerical rating could be
given, say on a scale from 1 to 100.  Because of the mathematical
structure of Chaum's approach, a person who carries such an
endorsement can optionally downgrade it when he shows it.  Suppose
some paragon of wisdom has dozens of "100" endorsements from respected
individuals.  Entering a new group, he may not want to intimidate
people, so he displays his endorsements as a respectable "70+".  This
lets him be heard without overwhelming other participants.
Pseudonyms can prevent messages from being linked to True Names, but
there is still a privacy problem as information accumulates about the
nym itself.  As more and more activities take place online, if one
uses the same nym all the time, the buildup of information about that
nym, his preferences, his favorite places to go in cyberspace, his
political views, etc., may become burdensome.  All that baggage
accumulates and is easily available to others.  It may become as much
of a barrier to a nym's online activities as it would have been to the
True Name's real-life activities.
One solution is to use a nym for some purposes and the True Name for
others.  Then the information about the two is separate and nobody can
link them up.  This helps, but after a while again there is an
accumulation of information about both names, which is what we wanted
to avoid.
A better solution is to use multiple nyms, perhaps with different nyms
in different online fora.  Even the True Name could be used
occasionally where warranted (such as in an online relationship where
physical contact occurs as well).  Nyms could be changed periodically
as well, preventing the buildup of information about any given nym.
One problem is that the simple reputation system above does not work
with multiple nyms.  If you get a digital endorsement of one nym in the
form described before, you will not be able to use that endorsement on
your other nyms without giving away the connection between them.  And
when you retire that nym and replace it with a new one, the endorsement
is lost.
This is the problem which Chaum solves in his paper, "Showing
Credentials without Identification; Transferring Signatures between
Unconditionally Unlinkable Pseudonyms," from AusCrypt 90.  (A newer
version of this paper may be available from Chaum.)  He provides a
method by which various forms of "credentials", which would include
the endorsements described here, can be transferred among the
nyms used by an individual, without giving away information about
which nyms are related.
Chaum's system is complicated and requires a centralized agency which
gives out all endorsement certificates, as well as an agency which
validates pseudonyms.  His system does allow for optional restrictions
on nyms which, for example, would allow only one nym to be used in any
given online forum.  A user would not be able to control two different
nyms in that place, although he could have different nyms in other
parts of cyberspace.  There might be some situations in which this
duplication could be harmful (such as certain kinds of online voting
systems) and Chaum's method does allow this restriction.
A simpler system, though, can be created with technology very similar
to the "Magic Money" digital cash system created by the nym "Pr0duct
Cypher."  This system does not require any centralized control and
allows individuals to make endorsements without help.  It is somewhat
less efficient than Chaum's approach but could be put into place
more easily.
The basic idea uses what Chaum calls a "blind signature".  Above, the
endorsement certificate was described as a digital signature on a
coded message which named the nym or person being endorsed, as well as
some information about the type of endorsement.  With a blind
signature, the signer does not see the message he is signing.  It is
supplied to him in a "blinded" form, he signs it, and then the person
who supplied the message unblinds it.  What is left is a signed
message whose contents are not known by the person who signed it.
This technology can be used directly to create blind endorsements.
Suppose nym 123, who sometimes also uses the nym 456, gets an offer to
receive a "good writing" endorsement from user U.  He can supply U with
a blinded message which says, in effect, "nym 456 has good writing".  U
does not see the contents of the message when he signs it, so he does
not know that nym 456 is another name for nym 123.  But when 123 gets
the message back from U, he unblinds it to create an endorsement from U
on nym 456.
In order to control the type of endorsement ("good writing", etc.),
that information is not put in the text of the message, but is
determined by the exponent used in the digital signature.  Each user
would need to publish a table mapping exponents to types of
endorsements (or perhaps such a table would be standardized over all
users).  And since nym 123 may actually have many pseudonyms in use,
he would actually need to collect a large number of blind endorsements
from U.  In practice he would supply U with a large block of blinded
endorsements, U would sign them knowing that they were all different
pseudonyms of 123's, and 123 would keep them for use as needed.
123 could even include his True Name to receive a blind endorsement,
as well as other pseudonyms he hadn't used yet.  All of these would be
capable of being shown with U's endorsement.  Even when the original
nym 123 was retired, other nyms which had received that endorsement
could be put into use and they would carry the same stamp of approval.
This system would allow very flexible use of pseudonyms while allowing
the user to show endorsements and other forms of credentials without
compromising his privacy.  And the technology to do this is very close
to systems already in use today, at least in its cryptographic
The social problems of determining when writers should receive
endorsements, how much credence to give to endorsements from unknown
endorsers, how to appropriately display endorsements, and how to easily
validate and verify endorsements proffered by others, are harder to
solve.  Despite these issues, a modification to Magic Money to support
this application would allow for some initial experiments with the
concept, which might help show where the significant problems lie.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-04-07 22:19:42
@_author: Hal 
@_subject: Pseudonyms and Reputations 
I believe RSA requires a notarized statement, where you have presented the
notaries with three forms of ID.  I would imagine that notaries have some
experience with false ID, but no doubt they can be fooled with sufficient
effort.  Still, for the kinds of applications we are talking about here
(chatting on the net) this is probably adequate.  For more security
you could require a thumbprint which is compared with others on file.
Chaum was writing more about financial relationships with creditors,
businesses, etc.  My translation of his ideas into the cyberspace author-
ship arena was not something he discussed directly.
In one way it is easier than with pgp.  With pgp we are trying to guess
whether a person is really who he says he is.  This has all sorts of real-
world implications, and as tmp points out these are hard to verify.  With
reputation systems what you really want to know is whether a person's
endorsements are valuable.  Over time you can basically decide this for
yourself, by judging whether those authors recommended by a given person
are ones which you consider good.  Those endorsers whose opinions match
your own would be the ones you pay the most attention to.
With Chaum's system it should not necessarily dilute your reputation to
use a lot of pseudonyms.  OTOH, you are right that informal reputations will
not carry over, and in practice these will be important.
Negative endorsements, and negative credentials in general, are difficult
to achieve.  Chaum's paper has some discussion of these but it is
hard to follow.
The simple blinded signature model provides a pretty simple way to allow
only one pseudonym per True Name in a given forum, if you assume there is
some way to distinguish people in the real world.  Suppose Cypherwonks
wanted only one person per nym.  And suppose there was an agency which
was able to distinguish people, that is, it could tell when it had seen the
same person twice.  Now, Cypherwonks asks this agency to give a single
blinded signature of a type (exponent) which is unique to that list, to
anyone who wants it, but such that nobody gets more than one.
To be accepted on the Cypherwonks list, then, somebody would have to show
a signature of this particular type, different from everyone else's.  Each
person could only get one such token, which Chaum has called an is-a-person
credential (again, this is a simplification of his idea, I think).
Now tmp has what he wants, the ability for a list to have only one nym
per person.  And in such a situation, negative reputations are important,
because you only get one chance and can't start over with a new nym.
Well, you have to trust that the agency which is verifying uniqueness of
identity doesn't cheat.  But note that the agency does not get any great
privacy-infringing power, as they don't have to know the True Names or
identities of the people they are endorsing, and they don't know their
pseudonyms (since those are blinded when they are signed).
Chaum did, as I said, have some concept about revealing negative
credentials, perhaps along the lines you are suggesting.  As I followed his
ideas (which wasn't very well), you would have to submit an "I'm not a
jerk" credential with each posting, and the only way to get another
such token would be to get back a response from your posting saying, "OK,
you're still not a jerk."  But if you posted some trash ("Death to
BlackNet") then you wouldn't get back that "OK" token and you'd have lost
your "not a jerk" token for good.  This would work best in a situation
where there was one nym per person, otherwise he could use his other nyms
to endorse his worthless trash.
(I posted a variation on this idea a couple of weeks ago as a way of
handling anonymous remailer complaints without breaking the anonymity of
the remailer user.  A similar token-and-response system was used, also
based closely on the blinded signature system in Magic Money.)
Well, Larry, you have to realize that you caused us enormous hassle
several months ago, so it's natural that people will be somewhat hostile.
Other pseudonymous posters have not stirred nearly so much interest
(with the possible exception of Xenon, who had some of your own tendencies
to rant at length).  However, in your new incarnation I find your postings
much more interesting.
Chaum has some discussion about how you can go to library A and borrow a
book, proving that you have no overdue books at libraries B, C, D, ...,
without compromising your anonymity.  This sounds analogous to proving that
you have no negative credentials from other cyberspace forums.  Unfortunately,
this is a part of his paper I need to read more times to understand.

@_date: 1994-04-08 07:58:07
@_author: Hal 
@_subject: tmp@netcom.com 
Another way would be for people to get a *blind* signature from someone
else saying "I am not Detweiler" (if that is all people care about).  Sup-
pose some nym were able to exhibit such a signature from a respected list
member, ideally one who has given out a great many such signatures.  No one
would be able to link the nym to his True Name; all anyone would know is that
at one time the True Name corresponding to this nym received a blinded
signature making this assertion.
This allows a nym to keep his anonymity while still responding to accusations
like these, if he wishes.

@_date: 1994-04-08 08:03:31
@_author: Hal 
@_subject: Pseudonyms and Reputations 
This is true, but the main purpose of this technology is to prevent users
from creating large numbers of pseudonymous accounts.  No technology can
stop people from cooperating in an on-line forum, and the use of friends'
or family members' accounts is also very hard to prevent.  So collusion at
some limited level will always be possible.  But at least it should be
possible to prevent the massive use of nyms.

@_date: 1994-04-08 08:14:37
@_author: Hal 
@_subject: Pseudonyms and Reputations 
A (semi) real-world application of the is-a-person technology was suggested
to me a year ago by someone whom I think is now a list member.  To protect
his privacy I will change the story slightly.
He wanted to set up an online game which would be ongoing for some time,
and which new people could join periodically.  New members would be given
a certain amount of resources (fuel, money, etc.) to start with, and then
they would compete with others in the game to try to get more.  At any given
time standings would be available to show who had done the best in terms of
getting the most resources.
The problem was that based on the rules of the game it was hard to prevent
people from colluding to transfer resources among themselves.  This would
allow someone who was doing poorly to create a bunch of pseudonymous accounts,
enter them in the game as new users, and then to transfer their initial
resources to his main account.  The result would be that the standings would
reflect skill at creating pseudonyms more than the abilities which the game
was supposed to test.
He asked whether there would be some way to ensure that only one account per
person was playing the game.  Basically, he was asking for an "is-a-person"
credential.  One solution would simply be to get a name, address, and phone
number from each participant, but he didn't want to violate his players'
privacy to that extent.  Without an infrastructure supporting this kind of
credential, he decided not to go ahead with his plans for the game.  This is
too bad because the game was actually going to test some very interesting
economic and political theories and it would have been good to see it in

@_date: 1994-04-08 20:20:32
@_author: Hal 
@_subject: Pseudonyms and Reputations 
Nathan Loofbourrow writes, regarding the on-line game:
Some kinds of play-by-mail games have had a similar situation, but they
have generally not faced the problem in this form because they charge
money to enter.  This puts a cap on how many entries a person is willing
to make.  With a large number of participants, controlling two or three
players instead of one does not increase the average person's chance of
winning enough to make it worthwhile.
This does suggest an alternative form of "is-a-person" credentialling,
though.  Rather than trying to verify identity at a distance, one could
simply have a "he paid me $10" credential.  You would give these out
(probably just one per customer rather than multiple ones) as blinded
signatures for anybody who sent you the cash.  These could be substitute
is-probably-a-person credentials on the theory that most people wouldn't
be able to waste a lot of money purchasing a great many of these.
OTOH, it's not clear that anyone would be willing to pay this much for
a credential unless it had some real, tangible benefit (otherwise it
serves as an "I'm a sucker" credential), and if the benefits are great
enough perhaps it would be worthwhile to buy multiples.

@_date: 1994-04-10 16:25:04
@_author: Hal 
@_subject: Pseudonyms and Reputations 
You don't try to satisfy these simultaneously.  Rather, one or the other
goal is achieved by the participants voluntarily participating in a
In some contexts, absolute anonymity is desired and achieved.  In others,
the participants agree to some restrictions on their anonymity in order to
allow various kinds of agreements.  I may not be willing to loan you money
if you are totally anonymous; on the other hand, I might be able to loan
it to you if your anonymity would be broken only if you didn't pay it back,
for example.  If you didn't want to take the chance on breaking your anony-
mity, you wouldn't have to.  You would just choose not to play my game.
The point of a lot of this work with pseudonyms and credentials and
such is to create a lot of different possible options along the scale
between perfect anonymity and perfect identification.  That way people
will be able to trade off their various requirements and come as close
as possible to their ideal position.

@_date: 1994-04-10 16:31:52
@_author: Hal 
@_subject: Zero Knowledge, Hamiltonian Cycles, and Passwords 
I think something like this may be the idea behind "obfuscated computing,"
which Mike Duvos was writing about here a little while back.  The idea is
that you do this trick not just with a graph, but with a boolean circuit
composed of and, or, not gates, etc.  Take your algorithm and express it as
such a circuit, then obfuscate it by drawing in extra gates, connections,
etc.  The resulting circuit has your original circuit embedded in it, but
figuring out what the total circuit does can be computationally intractable.
Someone could build or emulate this circuit and get a result, but they would
not be able to figure out exactly what formula they were computing.
I'm not 100% certain that this technique is used, but Tim's posting reminded
me that I had read something about this several years ago, and this is how
I remember it.

@_date: 1994-04-13 23:21:27
@_author: Hal 
@_subject: New anon mailer idea? 
Graham Toal's suggestion for automatic insertion of an encrypted
return address block is interesting.  We had some discussion here last
year of a similar approach, although Graham's twist of using a symmetric
rather than PK cypher for the return address is new.  A few thoughts:
 - You'd want this feature to be optional.  Some people might not want
   their anonymity limited by having their return address recorded, even
   in encrypted form.
 - Graham is right about the advantages of use-once (or use-only-a-few-times)
   return addresses.  Chaum discusses how multiple use of return addresses
   allows these systems to be broken, similar to the way Graham describes.
 - The use of a symmetric cypher is a very nice way of getting the use-once
   capability, along with the "burn after reading" effect of a remailer
   chain which destroys itself as it goes.  But it could be a considerable
   burden on the remailer operator to maintain the database.  One possibility
   would be to fix a maximum time limit on how long the return addresses are
   kept "alive" and require some real money to keep them longer.
 - What we would really like is for the recipient to hit the "reply" button
   and be able to send his mail back.  It sounds like this system would still
   require some cut-and-paste.  We already have programs to create encrypted
   remailer chain addresses fairly automatically.  It would be nice to automate
   this last little bit.  Unfortunately, there seems to be no easy way to
   make this work under Graham's scheme.
 - It doesn't look like this would be an easy drop-in to the current remailers,
   unfortunately.  The syntax for how the address would be built up as it
   passes through a chain of remailers is a little unclear as well.
The idea does have a lot of promise, though, and I think it is definately
worth keeping in mind for the next generation of remailers.

@_date: 1994-04-13 23:36:39
@_author: Hal 
@_subject: Remailer reply addresses 
Graham's suggestion about automatic remailer reply chains reminded me of
a simpler system which I would like to see.
Suppose one site, somewhere, would create new mail addresses upon request,
and map them to encrypted remailer chain blocks.  (These are nested remailer
requests, where the outer layer is encrypted for the first remailer and tells
it where to send the message, the next layer is encrypted for the 2nd remailer
and tells it where to send, and so on.  No remailer sees anything more than
where it is sending the message and where it received it from.)  A new account
is created which maps, say, to a file which has one of these "anonymous return
addresses" in it.  Any mail incoming for that address simply gets sent to the
remailer in the file, with the ARA stuck in front of it.
This is not complicated software.  I wrote a Bourne/Korn shell script which
does the whole thing in a dozen lines.  What is needed is a sendmail hack to
allow mail to addresses in a specified form (say anxxxxx) to be piped to this
script.  I don't have a machine where I can do this.
If such a site were running, then I could create an ARA block and send it to
that site (via a remailer, of course).  The site would make me a new address
and return it via the ARA.  That new address would be my pseudonym.
Now, when I want to send something pseudonymously, I just stick a "Reply-To"
into the outgoing headers of the message as it leaves the last remailer.  The
remailer-chain-creation script can easily be modified to do this.  The
Reply-To points at the address I got back from the pseudonym server site.
With this software I could do something which cannot be done today.  I could
send mail to which someone could hit "r" to reply, and receive that reply,
without any one person knowing my pseudonym.  This is not that much to ask
for!  I'd say it is the bare minimum for the use of pseudonyms on the net,
yet we don't have it, after all this time.  And look how close we are to
being able to do it.
With this basic system in place, some of Graham's ideas about time-limited
or use-limited pseudonyms could be applied as well.  Other extensions people
have suggested would have the pseudonym server hold messages in inboxes until
people trigger a dump to a freshly created anonymous address.  A lot of things
are possible.
But we should walk before we run.  Right now I don't feel that we are even
crawling yet.

@_date: 1994-04-15 20:32:32
@_author: Hal 
@_subject: Time for a change? 
What's that smell?
Doesn't it seem a little... musty?  A little stale?  Something's getting
old.  Something needs to be changed.
It's your key.
There are a lot of old, stale keys out there.  Moldy, dusty keys a year or
two old.  It's time for those keys to change!
The need for regular change of public keys has not been emphasized enough.
The longer you use a key, the more likely something will happen which will
expose your secret.  Plus, it gives attackers more incentive to try to break
or steal your keys if they know they'll be able to decrypt messages for a long
time once they get them.
A lot of people seem to think of keys as quasi-permanent, sort of a
voluntary version of social security numbers.  One key, cradle to grave.
But this is not the idea at all.
I was reminded of this by Graham Toal's response to Bill Stewart:
Graham is thinking in terms of remailers which retain their keys for years.
What is a good interval for key changes?  I would suggest every year or so
makes sense, especially if infrastructure can be developed to make it easier
to propagate key changes.  Keys should be overlapped in time, so that you make
a new key and start using it, while continuing to support the old key for a
But for remailers, I'd like to see a considerably accelerated key turnover
schedule - maybe every month, or every week.  This would help defeat the
kinds of attacks Graham is talking about.  And the remailers should securely
dispose of their old keys to the extent possible.
Granted, right now the difficulties of distributing keys are rather high,
so the costs of changing keys may be large.  But as this technology becomes
more available, key changes should be scheduled regularly.
PGP has some fields for key expiration, but support for that was never
implemented.  The idea was that you would get warned when it was time
for you to change to a new key.  Users of old keys would be warned as well
that they should try to find out the new key they should use.  All this
was not done because there wasn't time.  Hopefully the feds will change their
mind about pursuing legal sanctions against PGP developers and progress can
be made again.

@_date: 1994-04-16 14:32:25
@_author: hfinney@shell.portal.com 
@_subject: Blind signature cash patents 
A little while ago someone posted about a new company that would do patent
searches via email requests.  For another week they are doing free searches
as an introductory offer.  I did a search on blind-signature based cash
systems, and these are the patents it found.  This might be useful for those
considering implementing electronic cash.  Full text of patents are available
for $4.95.  The kind of search I did for free will cost $149 after another
week.  People are allowed 3 searches per day for free until then.
For more info send a message with just "help" in the body to
spo_patent at spo.eds.com.
2     04977595   19901211    380/24       Method and apparatus for implementing
                                          ++electronic++ ++cash++
Inventor: Ohta; Kazuo Assignee: Nippon Telegraph and Telephone Corporation       In an ++electronic++ ++cash++ implementing method, a user makes a   ++bank++ apply a ++blind++ signature to user information Vi produced, by a   one-way function, from secret information Si containing identification   information, thereby obtaining signed user information. Further, the user   makes the ++bank++ apply a ++blind++ signature to information containing   authentication information Xi produced, by a one-way function, from random   information Ri, thereby obtaining signed authentication information. The   user uses an information group containing the signed user information, the   signed authentication information, the user information and the   authentication information, as ++electronic++ ++cash++ for payment to a   ++shop++. The ++shop++ verifies the validity of the signed user   information and the signed authentication information, and produces and   sends to the user an inquiry. In response to the inquiry the user produces   a response Yi by using secret information and random information and sends   it to the ++shop++. Having verified the validity of the response the   ++shop++ accepts the ++electronic++ ++cash++. 3     05224162   19930629    380/24       ++Electronic++ ++cash++ system
Inventor: Okamoto; Tatsuaki Assignee: Nippon Telegraph and Telephone Corporation       In an ++electronic++ ++cash++ system, K sets of ++blind++ signature   information are derived from secret information containing identification   information of a user, K/2 sets of them are opened and a ++bank++ attaches   a ++blind++ signature to the remaining K/2 sets of information. The user   obtains a signed license from the ++blind++ signature. The user generates   ++blind++ signature information from the license and a desired amount of   money and gets a ++blind++ signature of the ++bank++ to the ++blind++   signature information and obtains ++electronic++ ++cash++ signed by the   ++bank++ from the ++blind++ signature. The user presents to a ++shop++ a   residue power root of a node in a money hierarchial structure and the   ++electronic++ ++cash++, corresponding to the amount of money to be used,   and the ++shop++ verifies their validity and, if they are valid, offers   inquiry information to the user. The user offers, as response information,   a residue power root of the node corresponding to the amount of money to   be used to the ++shop++. The ++shop++ verifies the validity of the   response information and, if it is valid, acknowledges the payment with   ++electronic++ ++cash++ of the amount of money to be used. 4     04759063   19880719    380/30       ++Blind++ signature systems
Inventor: Chaum; David L.       A cryptographic system allows, in one exemplary use, a supplier to   cryptographically transform a plurality of messages responsive to secret   keys; the transformed messages to be digitally signed by a signer; and the   signed transformed messages returned to the supplier to be transformed by   the supplier, responsive to the same secret keys, in such a way that a   ++digital++ signature related to each original message is developed by the   supplier. One important property of these systems is that the signer   cannot determine which transformed message received for signing   corresponds with which ++digital++ signature-even though the signer knows   that such a correspondence must exist. 6     04914698   19900403    380/30       One-show ++blind++ signature systems
Inventor: Chaum; David       Numbers standing for ++cash++ money can be ++spent++ only one time   each, otherwise the --account-- from which they were ++withdrawn++ would   be revealed. More generally, a technique for issuing and showing ++blind++   ++digital++ signatures ensures that if they are shown responsive to   different challanges, then certain information their signer ensures they   contain will be revealed and can be recovered efficiently. Some   embodiments allow the signatures to be unconditionally untraceable if   shown no more than once. Extensions allow values to be encoded in the   signatures when they are shown, and for change on unshown value to be   obtained in a form that is aggregated and untraceable. 11    04949380   19900814    380/30       Returned-value ++blind++ signature
                                          systems
Inventor: Chaum; David       A payer party obtains from a signer party by a ++blind++ signature   system a first public key ++digital++ signature having a first value in a   withdrawal transaction; the payer reduces the value of the first signature   obtained from the first value to a second value and provides this   reduced-value form of the signature to the signer in a payment   transaction; the signer returns a second ++digital++ signature to the   payer by a ++blind++ signature system in online consummation of the   payment transaction; the --paper-- derives from the first and the second   signature a third signature having a value increased corresponding to the   magnitude of the difference between the first and the second values.   Furthermore, the following additional features are provided: payments are   unlinkable to withdrawals; a ++shop++ between the payer and signer can be   kept from obtaining more value than desired by the payer; the first value   need not be revealed to the signer or intermediary in the payment   transaction; the returned difference can be accumulated across multiple   payment transactions; and the returned difference can be divided between a   plurality of payment transactions. 19    04759064   19880719    380/30       ++Blind++ unanticipated signature
                                          systems
Inventor: Chaum; David L.       An improved ++blind++ signature system not requiring computation   during ++blinding++ for anticipating which of a plurality of possible   signatures will be made during signing, while still allowing the   ++blinding++ party to unblind and recover the unanticipated kind of   signature on what was ++blinded++. An exemplary embodiment ++blinds++ by   forming a product including a plurality of generators raised to powers   normally secret from the signing party, and unblinds by forming a product   with the multiplicative inverse of a signed form of the generators raised   to the original powers. Re-blinding allows a signature on a value to be   transformed into a signature on a particular ++blinded++ form of the   value. 23    04206315   19800603    380/23       ++Digital++ signature system and
                                          apparatus
Inventor: Matyas; Stephen M. Assignee: International Business Machines Corporation       A ++digital++ signature machine provides a simplified method of   forming and verifying a signature that is appended to a ++digital++   message. A sender transmits a signature with the usual signature keys and   with validation table entries that correspond to the unsent keys and with   the compressed encoding of the next validation table. The receiver uses   the compressed encoding of the next validation table to form validation   table entries from the signature keys so that the receiver has a full   validation table. This validation table is compressed and compared with   the compressed encoding which was received from the sender in a preceding   message.

@_date: 1994-04-17 09:45:26
@_author: Hal 
@_subject: 'Nother MIT talk on crypto... 
Right - here are some quotes from Micali's paper in the Crypto 92 proceedings.
"Abstract.  We show how to construct public-key cryptosystems that are _fair_,
that is, strike a good balance, in a democratic country, between the needs of
the Government and those of the Citizens.
"In this paper we show how cryptographic protocols can be successfully and
efficiently used to build cryptosystems that are fairer, that is, that strike
a better balance, in a democratic country, between the needs of society and
those of the individual."
Micali's system is basically a key escrow system that would be quite appealing
to those who love Clipper.  At least he has the honesty to make it clear that
such a system makes more sense if competing systems are made illegal:
"Of course, if using any other type of public-key cryptosystem were to be made
_illegal_, Fair PKC's would be most effective in guaranteeing both private
communication to law-obeying citizens and law enforcement.  (In fact, if a
criminal uses a phone utilizing a Fair PKC to plan a crime, he can still be
secured to justice by court-authorized line tapping.  If he, instead,
illegally uses another cryptosystem, the content of his conversations will
never be revealed even after a court authorization for tapping his lines, but,
at least, he will be convicted for something else: his use of an unlawful
cryptosystem.)  Nonetheless, as we shall discuss in section 4, Fair PKC's
are quite useful even without such a law."
When I first heard of this so-called "Fair" (one of the most misused words
in political debate) system, my reaction was to snort in derision.  But since
Clipper it starts to look like the lesser of two evils.  That just shows how
the terms of the debate can shift.  Eric is right that the best thing to do
is to remain firmly committed to free access to cryptographic technology for

@_date: 1994-04-18 19:01:14
@_author: Hal 
@_subject: Laundering money through commodity futures 
Sorry for adding to this arguably non-cp thread:
There is some ambiguity in the discussion of martingales and double-your-bet
schemes in general.  Most people think in terms of doubling when they *LOSE*
their bet.  This puts them in the ludicrous position Tim Werner described of
having to bet $320 to win $5.
How could this strategy break a bank?  Your bets will average far larger than
your winnings.  If the table had a bank limit of $10,000, you'd have to have
many times this in your suitcase.  A more efficient strategy would probably
be just to bet $10,000 at the beginning.
If you really want to "break the bank", a more likely strategy would be to
double your bets when you *WIN*.  Most of the time you will eventually lose,
and so you will see a steady loss.  But eventually you will exceed the table
"bank" limit, and the casino will not be able to pay off your bet - you will
have broken the bank.
Of course, this was stupid of you, since statistically this will only happen
as often as your total losings add up to what your total winnings would have
been.  If there is some "bank" limit on how large the bets are that the
casino will pay off, then you will actually get less than you should have.

@_date: 1994-04-19 09:07:15
@_author: hfinney@shell.portal.com 
@_subject: Press Release on Secure NCSA Mosiac 
I doubt that these electronic financial instruments will be designed to
offer new protections to individual privacy.  As more commerce moves onto the
net, opportunities for database linking will multiply drastically.  In such
an environment, electronic dossiers of buying and spending habits will be
far easier to develop.
So once again we have the command-and-control style key certificate
hierarchy.  Everyone is neatly ordered and positioned in the
structure.  A place for everyone and everyone in his place.
I suppose it goes without saying that the kinds of privacy-protecting
credentials we have been discussing are not what is being discussed here.
Rather, we have more authentication, more registration, more tracking of
every electronic financial move we make.
Evidently the "commerce" that is being planned here does not anticipate much
demand for encryption of messages from sellers to buyers; rather, the
important thing is encryption in the opposite direction to protect those
credit card numbers.  This also, of course, limits RSA's financial commitment
in making its technology available; my reading is that end-users get only the
ability to validate signatures for free, and that getting to use their own keys
will involve royalty payments.
I was pleased to see that in their later message they added support for
PGP to this list, although it seems that they are still thinking mostly in
terms of "officially sanctioned" systems:
This is outrageous!  Where on earth did they get the idea that non-U.S.
residents have access only to 40 bit keys and RC2/RC4?  As though the only
encryption the rest of the world has is whatever the U.S. government deigns
to let cross its borders?  What an insult to the rest of the world.  And what
an attempt at self-deception to pretend that these export controls are
effective.  I sincerely doubt that the international network community will
accept such a limitation in what claims to be an international standard.
The one good thing that may come from this initiative is that more people
will be using and relying on encryption.  Given the widespread skepticism
about the government in this country, it will be that much harder to get a
Clipper-like program into place.
But the initiative does clearly show the pernicious effects of the combined
restrictions of the RSA patents and the NSA export controls.  Together [RN]SA
provides a structured, ordered system which provides the minimal possible
privacy necessary for electronic commerce.  Far more is possible, but is un-
likely under the current legal regime.

@_date: 1994-04-19 09:25:35
@_author: hfinney@shell.portal.com 
@_subject: CRYPTO: Money laundering and traceability 
(In honor of the Extropians list discussion elsewhere in this thread I
include an Extropians-style message prefix.)
An issue related to money laundering is money traceability.  I posted
something on this a couple of weeks ago but I have a little more
information now.
We are inclined to believe that with cryptographically anonymous
digital cash, "money laundering" will be trivial.  A simply sends the
cash to B, and there is no way for the bank or anyone else to link the
two together.
While this is basically true with existing digital cash proposals,
there is one kind of linkage that is possible.  A knows and can
recognize the cash which B holds.  A and the bank could cooperate so
that if B goes to the bank to deposit his cash (or deposits it
electronically into an account linked to his True Name), B's anonymity
can be broken.
This has good aspects and bad aspects.  On the good side, it should
make robbery and extortion harder.  If you are forced at gunpoint to
enter your PIN into your cash smartcard, transferring cash to the
robber's "electronic purse" (love that name), then later you can call
the bank and report the numbers of the stolen cash.  When the robber
tries to deposit it, he can be caught.
Similarly, this could be a boon to law enforcement "sting" operations.
When the feds pay off the anonymous assassin-for-hire or kidnapper, and
he goes to deposit the cash, again he can be caught.
The other side of the coin, though, is that despotic governments can
use these tools to control and restrict what their people can do.  If
the revolutionaries try to use cryptography to isolate and protect each
cell from the others, traceable cryptocash may expose them.  Keith
Henson posted the start of an interesting story he was writing last
year, about some eco-activists using cryptography for protection as
they worked to sabotage some polluter.  This kind of dramatic scenario
might become less possible with traceable cash.
(It's possible that some banks would allow truly anonymous accounts, so
that even if the cash were recognized as it was turned in, the robber
would not be caught.  Still, the bank could refuse to honor the money
in this case, preventing the criminal from profiting by his misdeeds.)
The new information I mentioned comes from a paper by David Chaum in
the Eurocrypt 92 proceedings: "Transferred Cash Grows in Size," by
Chaum and Torben Pryds Pederson.  Chaum considers off-line cash systems
where the money does not necessarily have to be returned to the bank
after each transaction.  His main conclusion is, as the title suggests,
that the cash must grow in size at each step.  But a secondary
conclusion is that under the right circumstances a payor can always
recognize his cash at a later point, even after it has passed through
many hands.
Chaum describes these circumstances as the case where the payor has
infinite computing power, but it appears that the same effect would be
possible if the bank cooperated with the payor, as would be likely in
the kinds of cases I mentioned earlier.  The fundamental problem is the
impossibility of having the cash be "re-blinded" as it passes from
Alice to Bob (after it was "blinded" as Alice withdrew it from the
bank).  If this kind of multiple blinding were possible, so that
neither Alice nor the Bank could recognize the money that Bob holds,
multiple-spending could not be detected.
Chaum's arguments appear to apply to virtually any electronic cash
system which can prevent double-spending.  They suggest that traceable
cash will be the rule in any digicash system.  People planning their
future lives of crime under the new regime will need to take this into

@_date: 1994-04-19 13:16:46
@_author: Hal 
@_subject: CRYPTO: Money laundering and traceability 
This is a good point, although I think on-line systems are unlikely to
be used for payments to private individuals such as in the scenarios I
mentioned, because of the cost of accessing a centralized database for
every transaction.  In any case, this suggests that it might be unwise
to carry cash issued by such a bank, because of your vulnerability to
robbery.  Chaum even considered (in another paper) the threat of being
coerced into withdrawing cash from a bank in such a way that you don't
see the blinded cash.  He had an approach where you would get all of
your "blinding certificates" when you opened your account, and these
would be the only things you could use to blind cash.  So any stolen
cash could always be recognized.
I suppose one risk is that the robber exchanges the cash so quickly that
the robbee has no chance to warn the bank; and once exchanged the cash is
certainly anonymous.  Perhaps banks would instigate some minimum time for
handling an exchange in order to protect their cash holders from this

@_date: 1994-04-19 22:18:32
@_author: Hal 
@_subject: slow.penet.fi 
Afabbro quotes someone in Finland saying, re anon.penet.fi:
I wonder if this could be a concerted denial-of-service attack.  Julf's
remailer has had the highest profile of any, and he certainly has his share
of enemies.  Maybe somebody figured it was easy to shove a few thousand
messages a day his way.  This makes the server slower and less convenient for
others to use, as well as putting an extra load on the trans-Atlantic links
just for anonymous messages.  It also could cost someone some money which
could be blamed on Penet.  This could be an attractive strategy for an enemy
of anonymity.

@_date: 1994-04-23 17:04:24
@_author: Hal 
@_subject: Remailers 
Try chaining the message through multiple remailers, then to a bitbucket
address.  One such address is "nobody at soda.berkeley.edu".  Presumably there
are many of this type.
Send yourself an encrypted message, chaining through a bunch of remailers.
See the cypherpunks ftp archive on soda.berkeley.edu for scripts
which will let you do these things.

@_date: 1994-04-24 09:19:35
@_author: Hal 
@_subject: Crypto toolkit 
I think Tim had in mind something that was accessible more from a higher-
level language than C or C++; ideally, something interpreted so you could
sit down and type in a few commands to get something useful.  Perl and
TCL are two languages which Tim mentioned and which have been discussed
here in the past.  Smalltalk might do, although it is not as "freely" avail-
If you want a C toolkit, a good example already exists: the PGPTOOLS package
by Pr0duct Cypher.  It is available by ftp from csn.org in /pub/mpj to
US citizens, and probably from some European crypto sites as well.  This has
a bignum package as well as interfaces to IDEA and RSA encryption.  It also
supports processing of PGP message formats and key rings.  The latest
version has code for Diffie-Hellman key exchange.

@_date: 1994-04-24 10:00:57
@_author: Hal 
@_subject: Crypto toolkit 
Sorry, my mistake: the directory is /mpj, not /pub/mpj.  Again, the site is
csn.org.  You will have to read the file README.MPJ which tells the name
of a "secret" directory to cd to (which changes every time).  Then look at

@_date: 1994-04-25 20:44:46
@_author: Hal 
@_subject: Programming languages debate 
One thing not being emphasized in this discussion about languages,
crypto scripts, and such, is that a big reason why we don't have more
crypto tools is because they are a lot of work to write.  I can speak
from personal experience on PGP.
Just going from PGP 1 to PGP 2 took over a year, almost a year and a half.
That involved a lot of little cleanups: better handling of key rings, going
to IDEA in place of Bass-O-Matic (the cipher used in PGP 1); adding some new
packet types, etc.  But PGP 1 had most of the same basic cryptographic
functionality (RSA+conventional) as PGP 2.
And it was amazing, really, that as much got done as it did in that time
frame.  Most of that is due to Phil Zimmermann's managerial abilities.
People know Phil as a privacy advocate, a crypto enthusiast, a talented
programmer.  What they may not realize is that his greatest skills are (IMO)
in personal relations.  Phil is able to make things happen, to shepherd a
network of easily distracted programmers from point A to point B.
This means being willing to push, to call someone up and say, "do you have
that done yet," and "can you have it for me tomorrow."  Phil was not afraid
to keep the pressure on in order to make sure progress was made.  He had to
constantly keep this up for over a year to get PGP 2 out.
Granted, Phil was working under somewhat unusual constraints due to the
unique legal situation involving the RSA patents.  But most of the kinds of
things we are interested in playing with can't help but infringe on some-
body's "intellectual property" given the massive barbed-wire-fencing of
the cryptographic concept space that's been going on (see my posting last
week on Chaum's multitudinous patents).  Plus, now we know that any success-
ful public-domain cryptographic product is likely to leak overseas and ex-
pose the author to the threat of a prison term.  These are hurdles which
cannot be taken lightly.
I don't know whether the introduction of easier-to-use crypto tools will
really change things.  Pr0duct Cypher's PGPTOOLS was explicitly intended to
address this problem, but the only thing I've seen so far is his own Magic
Money (although I heard in email about another application being worked on).
I think what we really need is some motivated programmers who are willing to
learn crypto and work on projects.  I think that would be a better use for
this list than the kinds of discussions we have been having lately.

@_date: 1994-04-26 08:56:46
@_author: Hal 
@_subject: message splitting for better mixing? 
Jim Miller
Here is a program I found in the usenet archives which will do some of the
splitting and merging features.  Note that the merge is smart in that you
just cat the pieces together and process them.  The main feature of the prog
is that you can reconstruct even with a few missing pieces, necessary because
of the unreliability of remailer email.  I don't think the splitting is
cryptographically strong, but each piece could be separately encrypted if

@_date: 1994-04-26 09:06:47
@_author: Hal 
@_subject: spy satellites 
Two points re the spy satellite thread.
First, spy satellites want to be close to what they are looking at, so
they can see it better.  That means they are generally in low orbits, and
low orbits are fast orbits.  Typical speeds are on the order of 10,000 mph.
This means that any given spot is in view of a particular satellite for only
a few minutes on each pass, and due to the earth's rotation it is hard to
pass repeatedly over the same spot frequently.  This means you need a large
number of satellites in order to provide much coverage, and even then you will
probably get snapshots at an interval of hours at best (I don't know how many
satellites are flying).  This is OK for military bases where you are looking
at construction, ships, and other large equipment, but it is not at all
adequate for tracking the movement of terrorists.
Secondly, any technology which did allow the government to surveil us well
enough to track the physical movements and meetings of terrorists would be
far more of a threat than any Clipper chip!  Offering satellite surveillance
as an alternative to Clipper jumps from the frying pan into the fire, IMO.

@_date: 1994-04-26 09:18:27
@_author: Hal 
@_subject: Milgram & Authority 
I saw a documentary about this research about ten years ago, and they made
a point which hasn't come up here: that Milgram, in subjecting his exper-
imental subjects to such psychological stress (many were traumatized for
months afterwards about what they had done) was being just as unethical, just
as unfeeling and unthinking, as his experiment was designed to show his sub-
jects as being.  Why was Milgram willing to push his subjects to such lengths?
Was his obedience to the "authority" of abstract scientific research any more
defensible than his subjects' obedience to that authority?
In a strained attempt to tie this thread to the list, I will point out that
our own efforts to distribute cryptographic tools will be judged by their
consequences, not by our hopes.  We have as much responsibility as Milgram to
consider the likely results if we succeed.  It will be a different world, and,
we hope, a better one.  But some things will be worse, of that there is little
doubt.  We must constantly weigh the bad against the good and take actions
on that basis, rather than blindly and unthinkingly seeking to push the env-
elope just to see what happens.

@_date: 1994-04-26 09:19:07
@_author: Hal 
@_subject: Internet Relay Chat 
If you did hack your own IRC server, would it be possible to eavesdrop
on channels like  without anyone knowing, and without fear of being
kicked off?  It seems to me that this would be the true hacker's approach
if it were possible.

@_date: 1994-04-27 08:59:14
@_author: Hal 
@_subject: Crypto scripting language 
I'd like to hear more about your scripting language.  You could post it for
ftp to soda.berkeley.edu, or if it is something which should be export-
controlled you could consider asking mpj at csn.org to put it up on his U.S.-only
site.  In the mean time, perhaps you could describe the language here.  What
is its syntax like?  Interpreted or compiled?  What kind of special crypto
support does it have?  If you actually own the rights to it, I'm sure we
would be interested in looking at it.
Re Telescript: I sent away a few months ago for General Magic's press kit.
Telescript is a scripting language which they describe as being like "Postscript
for net communications" (not an exact quote).  Later this year, PDA's (Personal
Digital Assistants, like Newton) will be released which run GM software,
including the Magic Cap software.  Magic Cap provides a graphical user interface
that is said to be easier to use, with pictures of desks, buildings, etc. for
the user to tap on.  It will also run Telescript for its communications.
As I understand it, users will use Telescript to write agent scripts, which
will then be sent into the net where they can seek out information, negotiate
payment if necessary, even trade or sell things.  RSA is used for authen-
tication and protection.
It appears that these agents will require special software platforms where
they will run.  They won't just be able to surf the internet as it is today.
Instead, they will only run on Telescript servers, where typically sellers
of goods, services, and information will have their own agents waiting to
make deals.  AT&T is starting up a special network specifically for this
purpose called PersonaLink.  (It will also do ordinary email, presumably, as
this would be a subset of agent capabilities.)
In considering whether Telescript could become a new standard for commun-
ications and networking, one flaw I see is that it appears that the software
itself must be proprietary.  This would suggest that it will be difficult to
see Telescript servers spread through the Internet as WWW or gopher has done,
for example.  The internet as it is today does not mesh that well with pro-
prietary software.  Perhaps GM has a strategy for this but my impression is
that they intend to create their own network and put their efforts there.
I don't have any information on the language itself, so it's hard to judge
its suitability for crypto based protocols.  The RSA authentication and encryp-
tion is built in at some level, but I don't know whether it is transparent
(which would make it hard to replace) or explicitly called from the
scripts (which might suggest that other alternatives could be hooked in).
But the fact that the language is communications-oriented, and perhaps there-
fore is already set up to deal with the unreliability and delays we often see
with electronic communications, could be a good starting point.  Hopefully
when the PDAs hit the shelves in a few months we will start to see more infor-
mation on Telescript.

@_date: 1994-08-01 08:09:38
@_author: Hal 
@_subject: Lawsuits Against PKP 
That makes my day.  The name Schlafly sounds familiar (I don't mean
Phyllis).  Roger?  Does anyone know a crypto person with this name?
It would be interesting to know whether anyone else could join in these
lawsuits on a class-action basis, or at least send support to the plaintiffs.

@_date: 1994-08-02 07:32:33
@_author: Hal 
@_subject: Steganography 
One possibility would be to right-justify your  text,  as  a  few
people  like  to  do,  then  to tweak the algorithm for inserting
spaces into lines to depend on the next bits of the embedded mes-
sage.  Generally, you have N spaces to insert into M word breaks.
If M divides N, you don't have any choice, but otherwise you have
N  mod  M  "leftovers"  to  distribute among M.  This would allow
several bits per line.

@_date: 1994-08-04 19:43:56
@_author: Hal 
@_subject: Remailer ideas 
The MIRV idea for messages is not bad, but by itself it does not
provide enough cover.  If you have a 33K byte message come in and a
while later a 21K and a 12K byte message go out, there might not be
many other possible messages that could add up to 33K.
A more complete solution is to pad all messages to a standard size.
If every message which goes into the remailer is the same size, and
every message which comes out of the remailer is the same size, and
each has no carried-over header or message-body information, then
there should be no way of matching up incoming to outgoing message.
This was the simple solution in Chaum's original February 1981 CACM
paper, which I would strongly suggest that people read.  CACM is
probably the most widely available of the computer science journals
and should be at every university library.
Chaum's paper has some interesting aspects that are not often
mentioned.  He actually proposes two different solutions that differ
somewhat.  (People should also be aware of his alternative solution to
the traffic analysis problem, the "Dining Cryptographers" network.  I
think Tim may have scanned that in at some point, so it might be on
the net.  DC nets tend to be high bandwidth and are more suitable for
LANs or WANs than email, IMO.)
The first solution in Chaum's paper is the "Cascade".  In this there
is a sequence of "Mixes", what we would call remailers, which are used
in a FIXED order by everyone.  It's as though everyone first sent
their messages to soda, then to portal, then to catalyst, and so on
through some specific sequence.  Furthermore, these are all sent in a
set of batches which stay together as they move through the network.
A batch of messages starts at soda, then at a later time that same
batch pops out the other end, having been decrypted and shuffled at
each step.
network.  By keeping the messages together like this, the whole
cascade does no more shuffling than would a single mix.  Using the
cascade provides no more confusion of messages.
But the advantage it does provide comes from the fact that there is no
guarantee that the remailers are honest.  This is something which is
often overlooked by people who make suggestions that remailers should
cooperate, should automatically choose the message paths, etc.  Chaum
uses the cascade so that if even one mailer on the chain is honest and
uncorrupted, the whole chain is strong.  If you _knew_ you were using
a good remailer you wouldn't need a cascade.  But by using a cascade
you get that much more assurance that you have security.
The other reason for using a fixed cascade, I think, has to do with
the details of message padding.  The problem is that, generally, when
you decrypt a message it is not exactly the same size as it was when
you started.  Particularly with remailer messages, where there may be
some encrypted address information along with the message, the output
will tend to be smaller than the input.
By using a cascade, the messages will all shrink in step as they move
along.  All of the messages coming in to any mix in the cascade will
be the same size, and all the messages going out will be the same
size, but the outgoing messages may not be the same size as the
incoming ones.  It is this size differential which would make it hard
to safely combine messages which have gone through different numbers
of mixes.
Chaum does go on to suggest a solution to this as the second main part
of his paper.  That part is considerably harder to follow, but the
main idea seems to be that the mixes themselves will add padding to
the end of the messages so that they stay the same size.  Chaum
describes this in terms of messages composed of fixed-size blocks, but
it would seem that the idea could be generalized to a remailer which
added random padding to bring the output message up to the standard
size.  I can't see any security leaks in this generalization.
One interesting idea Chaum suggests is that after the remailer
decrypts the messages in its batch, it does not simply send each one
to the next address, but rather broadcasts them (perhaps to all of the
other remailers).  Those remailers try decrypting all of the incoming
messages and only those messages for which the decryption succeeds
will be sent on.
Again, I'd suggest people interested in reamailers read this
paper.  I believe there were some follow-ups in the Crypto 89 proceedings,
but my library is missing that volume so I haven't seen them.

@_date: 1994-08-05 21:00:33
@_author: Hal 
@_subject: US Postal Public Key 
Yes, towards the end they made it clear that this was not intended to
be a monopolized certification hierarchy, but one of many.  There was
even a reference to "peer-to-peer" certification, which I thought might
refer to a web of trust.
It's not nice to make fun of the Post Office; they're such an easy target.
But I couldn't help finding that the archaic all-caps format and the little
"^G" characters by the bulleted points reminded me of the old 110-baud
ASR-33 clankety teletypes I used in college, with each little bulleted
point going "ding", "ding", as it printed out (^G being the bell character
in ASCII).  It didn't exactly bring to mind the streamlined new PO the
speaker wanted to convey.

@_date: 1994-08-05 21:00:48
@_author: Hal 
@_subject: Voluntary Governments? 
The problem I have with this is that there is no such place as cyberspace.
I am not in cyberspace now; I am in California.  I am governed by the
laws of California and the United States even though I am communicating
with another person, whether by postal mail or electronic mail, by
telephone or TCP/IP connection.  What does it mean to speak of a govern-
ment in cyberspace?  It is the government in physical space I fear.  Its
agents carry physical guns which shoot real bullets.  Until I am able
to live in my computer and eat electrons, I don't see the relevance of

@_date: 1994-08-05 21:00:51
@_author: Hal 
@_subject: Remailer ideas (Was: Re: Latency vs. Reordering) 
Re putting remailer aliveness on usenet:
What I think is a better idea was proposed here last year, and I think
someone was doing it for a while.  It is for someone to volunteer to
be the keeper of the remailer aliveness information.  He runs scripts
every day to ping the remailers, keeps lists of which remailers are
currently active, and so on.  This information is collected and put into
a file retrievable by email or finger.  This way you need only check a
single site to find out which remailers are up, and you don't have the
usenet waste of sending stuff all over the world that only a few people
are interested in (yes, I know usenet does this already, but it won't
Just like people set up web sites that point to interesting resources,
some people will (and perhaps are already) run sites which point to good
remailers.  This is just as useful a service as running a remailer, and
a good deal less controversial.  This seems like a good solution to the
problem of finding running remailers.

@_date: 1994-08-05 22:11:28
@_author: Hal 
@_subject: Remailer ideas 
I would really like to see some kind of system for reliable email.  I'm
surprised that it doesn't exist yet.  How many times have we said,
"You didn't get my email?  I'll resend it."  What are computers for, after
all?  Automating repetitive tasks, classically.  This is a perfect appli-
cation.  A copy of outgoing email could be kept, acknowledgements received
on receipt, and the email deleted or re-transmitted as needed.  Serial
numbers would distinguish retransmissions so that redundant resendings
(where the packets "crossed in the mail", so to speak) would be dropped.
All this was designed in an afternoon in Xmodem.  It's conceptually easy.
The hard part is getting a standard and getting people to build it into
their Mail User Agents.
Then, once we had this, we could do another layer for crypto protocols.
Lots of protocols go in stages.  A sends X to B, receives f(X), sends
g(Y,f(X)), etc.  To do this in email would be impossibly cumbersome now,
but the kind of mechanism used for reliable email could be extended to
support these kinds of "stateful" protocols.
As one obvious need for reliable email, consider the transmission of
Chaum-style digital cash.  You don't want to erase your copy until you
are sure the other guy has received it, otherwise your money is permanently
gone (just like when you send cash in postal mail and it is stolen).  But
keeping track of which cash you have sent to which people, who has gotten
theirs, which needs to be re-sent, etc., is painful.  A simple reliable
email method would solve a big part of this problem.

@_date: 1994-08-05 22:42:43
@_author: Hal 
@_subject: RemailerNet 
I think Jim Dixon has some interesting ideas in the RemailerNet.  But I have
a philosophical difference.  I dislike solutions where the users have
to put too much trust in the remailer operators.  IMO, as much control
as possible should be left in the hands of the users.  To make the system
easier to use, mail agents should be enhanced to be more powerful, rather
than moving more power and control into the remailer network.  Trusting
a remailer to choose your path through the network is like trusting the
sysop at your BBS to create your PGP key for you.  Maybe it's OK a lot
of the time, but isn't it better to do it yourself?
This is just the opposite of what I would like to see.  I don't want the
remailer operators getting too friendly.  That makes it all the easier for
them to conspire to track messages through the net.  I'd much rather choose
far-flung remailers whose operators have never heard of each other.  Get
one from Helsinki and the next from Timbuktu.  Choose a path which will
minimize the chances of all the remailers being corrupted.
I think this is right, although as I posted elsewhere I don't think usenet
is the best structure for announcing remailer availability.  (As I said,
I'd rather see a few sites volunteer to do pings and publish the results,
or even better would be widely used software packages which let people
do their own pings.)  But the question of remailer reliability is hard.
What is the giveaway if a remailer is secretly archiving messages while
claiming not to do so?  How could you ever tell if the NSA infiltrated
your favorite remailer?
One possibility would be occasional physical audits, in which a remailer
reviewer visited the site, looked at the software, checked the system for
security holes, etc.  This would be quite expensive, obviously, but perhaps
eventually the remailer infrastructure would be extensive enough that this
kind of checking could be done.  Think of it as "Consumer Reports" for
remailers.  (Similar privacy audits might be de rigeur in the future for
other net resources, such as file banks or compute servers.)
What?  Again I would reverse this.  The user should have maximum control
of his path.  It's up to him to choose a random one.  Random number gen-
erators are widely available.  (I can get you a bargain on a used Blum-
Blum-Shub.)  If he has to trust the first remailer on his path, then if
just this one remailer is subverted, he's lost all his privacy.  By choosing
his own path no one remailer knows both the source and the destination of
any message.  That is the key.  No one must have those two pieces of
information.  Giving it all away to the first remailer means giving away
all your security.
The point, though, is that with Chaum's scheme you have security if even
one remailer in the network is honest.  The chain becomes as strong as its
strongest link.  Systems which put more responsibility and power into the
remailer network often can't achieve this.  They have single-point failures
where one compromised system can defeat the efforts of all the others.
Yes, I think this is a reasonable and cautious attitude, but instead of
saying "If I were running a remailer..." I'd say it should apply "if I
were _using_ a remailer".  There may be rating services and other sources
of information to help users, but ultimately the decision should be theirs.
One of the lessons of cryptography, IMO, is that you don't get security
by farming out the hard work to others.  The user should take responsibility
for his own security.
I'm getting too tired to reply to the rest.  I think Jim has a lot of
creative ideas and energy but I'd like to see it directed more towards
empowering end users rather than putting so much reliance on trustworthy
remailer operators.

@_date: 1994-08-06 08:31:20
@_author: Hal 
@_subject: Improved remailer reordering 
Here is an interesting result I came up with while lying in bed last
night.  It has to do with the latency/reordering issue.
As Eric and others have pointed out, what you want with a remailer is to
mix up the messages so you can't link incoming to outgoing one.  This
implies that you have more than one message to work with, otherwise you
don't have anything to mix.  And this implies some necessary latency; you
have to wait until you have more than one message on hand before sending
things out.  However, note that latency in itself is generally bad.  You
shouldn't wait longer than you need to to attain the desired degree of
One simple way this can work is by batching messages up.  This could be
done by running the remailer at regular intervals, choosing the intervals
so that you tend to have enough messages on hand based on average arrival
times.  But a simpler way is to simply wait until you have N messages on
hand, then to promptly mix them up and send them out.  This way you have
a predictable number of messages to mix each time.  Note that in a system
like this you might as well send them all out as soon as the Nth message
comes in; there is no point in holding on to them for any extra time as
it adds latency without improving mixing.
The interesting thing I came up with is that there is a simple modification
to this batching scheme which gives better mixing with less average latency.
To describe it I need some mathematics.
One way to measure the benefit of a given degree of message-mixing is by
looking at the uncertainty of position of a given message coming in and
going out.  If we had batches of 4, for example, a given message coming
in has its position known with certainty.  Going out, it may be any one of
four messages, and the probability of it being any one of them is 1/4.
A measure that is used for situations like this is entropy.  It is defined
as the negative of the sum of the product of each probability times its
log.  (I will use log to the base 2 for the calculations for simplicity.)
That is, E = - sum pi * log pi.
For the incoming message, we have just {1} as the probability distribution.
We know exactly where it is and the probability is 1 that it is there.
For the outgoing we have {1/4,1/4,1/4,1/4} as the distribution.  It may
be any of these four messages with equal probability.  Applying the entropy
formula to these we get E=0 for the incoming, and E=2 for the outgoing.
If we had batches of 8 instead the distribution would have been {1/8,1/8,
1/8,1/8,1/8,1/8,1/8,1/8}, for E=3.  Note that entropy is a log measure
like the Richter scale.  An increase from 2 to 3 is just as big as an
increase from 1 to 2.
To consider different batching strategies, consider a remailer where the
messages come in one per hour, at 1:00, 2:00, 3:00, etc.  A four-fold
batching strategy would save up messages until there were four, then
randomly reshuffle them and send them out.  For this case we'd wait until
the 4:00 message, then shuffle numbers 1,2,3,4 and send them out, say,
at 4:01, in some random order, maybe 2,1,4,3.  Then we'd save up more
until 8:01 at which time we might send out 7,5,8,6.  Note first that there
is no point in waiting till after 4:01; once we have the four messages we
might as well go.  Note too that the average latency for messages in this
system is 1.5 hours (the four messages have latencies of 0,1,2 and 3 hours).
Four-fold batching produces entropy E of 2 and average latency L of 1.5
hours.  Three-fold batching has E=1.58 and L=1; two-fold batching has
E=1 and L=.5.  Generally, N-fold batching has E=log base 2 of N, L=(N-1)/2.
Okay, with this background, we can consider the alternative which gives
improvement.  It is to have some "rollover" of messages.  Instead of sending
all of the messages in a batch out, you retain some of them and use them
to start the next batch.  I call an (M,N) rollover system one which uses
batches of M messages but retains N as rollover, sending M-N out each time.
By this definition the four-fold latency system above could be called a
(4,0) rollover where the 0 means we don't roll any over and send them all
The simplest rollover case is (2,1).  This uses batches of 2 messages,
where you choose one at random to send out and keep one.  Then when the
next message arrives you again choose at random between the new one and
the old one, send that out, and keep the other.
In the timing example above, suppose we have the message from 1:00.  Then
at 2:00 when that message arrives, we pick one of the two messages at
random and send it out.  Suppose it is number 2.  We retain number 1 until
3:00.  Then we choose at random between 1 and 3.  Maybe we pick 1 this
time.  We keep 3 until 4:00, then choose at random between 3 and 4, and
so on.
Each message has a 1/2 chance of being sent out immediately, a 1/4 chance
of being sent out after 1 hour, a 1/8 chance of going out after 2 hours,
a 1/16 chance of going out after 3 hours, and so on.  This means that the
outgoing probability distribution is {1/2,1/4,1/8,1/16,...}.  The entropy
of this probability distribution is 1/2+2/4+3/8+4/16+5/32+6/64+... from
the formula above, which works out to be 2.  The average latency is
0+1/4+2/8+3/16+4/32+5/64+..., which works out to be 1.
So, (2,1) rollover batching produces E=2 and L=1.  This is the same entropy
as (4,0) batching with less average latency.  Alternatively, it is more
entropy than (3,0) batching with the same average latency.  It also has
the advantage that you never have to hold more than two messages, compared
with three or four for the alternatives.  So this scheme has several ad-
vantages over simple batching.
Now, it does have one disadvantage, which is that there is no upper bound
on the latency of a message.  With the (4,0) batching you may have had
more latency, but you at least know that nothing would have more than 3
message-times.  With (2,1) there is a small chance of having very large
latencies.  In fairness, though, it should be pointed out that in a real
system messages arrive at irregular intervals rather than the clockwork
model I used above, so even (4,0) would have random latency ceilings.  Also,
it might be possible to modify (2,1) so that messages never waited more than
some maximum number of hours without seriously hurting the entropy.
I haven't tried working out the details of other rollover methods, but I
suspect that this will be a general method of improving entropy at little
cost in latency.  In real life we would want large entropies but starting
with a (10,0) I'll bet many rollover systems would be superior.

@_date: 1994-08-06 18:38:26
@_author: Hal 
@_subject: (none) 
List members who are internet connected might try doing "telnet toad.com"
and see if they get a login prompt.  The recent list outages have correlated
with a lack of response from toad, so I presume the machine was either down
or off the net.

@_date: 1994-08-06 19:09:27
@_author: Hal 
@_subject: e$: Cypherpunks Sell Concepts 
There are two legal problems that I could see being used against digital
cash.  The first is the civil war era prohibition on banks issuing private
bank notes.  This was done in an attempt to force people to switch over to
U.S. government notes, and was successful.  (Actually, it is not a pro-
hibition per se, but rather a prohibitive tax on the use of such notes.)
I don't have a reference to where this actually appears in the code, but
I have read about it in many histories of currency in the U.S.  It seems to
me that digital cash issued by a bank is functionally very similar to a
paper bank note issued by that same bank, suggesting that this law would
The second problem is the regulation of "scrip" and barter systems.  This
was pointed out on the list last year by someone who had actually been
involved in a private barter or scrip system which was shut down by the
government, at great cost to all concerned.  These regulations can be
found at 26 CFR 1.6045-1.  From subsection (f)(5)(ii), "Scrip is a token
issued by the barter exchange that is transferable from one member or
client, of the barter exchange to another member or client, or to the
barter exchange, in payment for property or services".  I think this one
will eventually get the "NetBank" people in trouble.  (You call a 900
number and in exchange for a charge on your phone bill they give you a
digital token you can exchange for property or services by participating
merchants.)  Barter exchanges are required to get the names and SS numbers
of all participants and report their transactions to the IRS.  This would
be inconsistent with the privacy we seek from ecash.
There are probably other regulations but I would think these two would have
to be addressed initially, at least by anyone thinking of setting up these
services within the United States.

@_date: 1994-08-06 19:15:45
@_author: Hal 
@_subject: Latency vs. Reordering (Was: Remailer ideas (Was: Re: Latency vs. Reordering)) 
I had an interesting thought.  Remailer networks are hard to analyze,
with messages whizzing this way and that.  But Tim pointed out that if
you have N messages coming in to the network as a whole and N going
out, all that zigging and zagging really can't do much better than
N-fold confusion.
This suggests, that IF YOU COULD TRUST IT, a single remailer would be just
as good as a whole net.  Imagine that God offers to run a remailer.  It
batches messages up and every few hours it shuffles all the outstanding
messages and sends them out.  It seems to me that this remailer provides
all the security that a whole network of remailers would.
If this idea seems valid, it suggests that the real worth of a network of
remailers is to try to assure that there are at least some honest ones
in your path.  It's not to add security in terms of message mixing; a
single remailer seems to really provide all that you need.

@_date: 1994-08-07 10:32:32
@_author: Hal 
@_subject: Latency vs. Reordering (Was: Remailer ideas (Was: Re: Latency vs. Reordering)) 
Once again I find myself with an understanding that is exactly the opposite
of Jim's.  I must be missing the point of his network design.  In the remailer
networks I am familiar with, each additional remailer introduces another chance
of being uncompromised, rather than being compromised!  Only if all the re-
mailers in the chain are cooperating and logging messages can they recon-
struct the path my message took.  If any one remailer is honest, my message
is successfully mixed with the others.  A design in which any one remailer
in the chain can compromise the privacy of the user seems to have a very
big flaw.
Yes, this makes a lot of sense.  Use different jurisdictions to make attacks
by government agencies more difficult, use multiple remailers in a chain,
etc.  I just don't follow the earlier comment which suggests a different
model of information exposure than I use.

@_date: 1994-08-07 20:13:53
@_author: Hal 
@_subject: Improved remailer reordering 
hughes at ah.com (Eric Hughes) writes, quoting Jim Dixon:
So, I guess what you are saying is, two remailer nodes connected by a
fully-encrypted link which carries dummy traffic so the data rate is
constant (and hence effectively invisible) can be thought of as one node
for some purposes.  So let me ask: how does a network which contains these
two nodes compare with one which has only a single node in their place?
I can see three models to compare.  The first is a single node network.
The second is a tightly-coupled two-node network with link encryption so
no information is available on the traffic between them.  Messages will be
sent into and out of this pair of nodes in such a way as to maximize
entropy of distribution.  The third is a loosely-coupled two-node network
where the nodes are used as a Chaum-style cascade, but with half the
messages going in each direction.
For the first network, if the bandwidth into (and hence out of) the single
node is N, we get the maximal possible confusion, as I suggested before.
If the total bandwidth into the remailer network is N, then the
tightly-coupled two-node network might average N/2 into each of the
nodes, with N/2 out of each of them.  For maximal confusion, half of
the incoming data would be sent over to come out of the other node, so
we have N/4 going in each direction on the link.  The net result is
that the two-node net has each node with a bandwidth of 3/4 N coming in
(and going out) to attain the confusion level of an ideal one-node
system.  This is superior in per-node bandwidth but greater in total
network bandwidth.
As for security against corrupt operators, this gives some improvement
over a one-node system, but not as much as with two independent nodes.
In this model, only half the messages go through both nodes, so only half
get the benefit of a two-node chain.  (Also, as I suggested before, we
might question whether two node operators who were able to cooperate and
trust each other well enough to set up this kind of link would be truly
For the third model, two nodes connected by an ordinary link and used as
two-node chains, each node now has an input bandwidth of N: N/2 from
users (who choose each node at random as the first of the chain), and
N/2 from the other remailer (where the node is acting as the second of the
chain).  So we have paid a price in bandwidth, with each node carrying N,
and a total net bandwidth of 2N.  But we have gained in security against
operator malfeasance: all messages now go through both remailers and
if either one is hiding the mapping then it is lost.
So, there appears to be some tradeoffs between bandwidth savings and
security against dishonest operators.  It will be interesting to see how
these results extend to larger numbers of nodes.

@_date: 1994-08-08 07:58:11
@_author: Hal 
@_subject: Anonymous Transport Agents (Was: Latency vs. Reordering) 
I can see two problems.  First, at least the first machine on the trans-
port path will see both your origin address and your destination address.
So it is in a perfect position to do traffic analysis.  Many users may
not have the ability to control which machine this is since routing is
usually automatic these days.
Second, if each machine simply saves a message and sends it on, then even
if the messages are encrypted there will probably be timing relationships
between the incoming and outgoing messages which will allow them to be
linked.  So someone monitoring the intersite communication channels may be
able to track a message through the network just by noticing when it comes
into and goes out of each node.  This is why Chaum introduces message
batching and mixing at each node.

@_date: 1994-08-08 08:02:43
@_author: Hal 
@_subject: Improved remailer reordering 
I could see this would come up in Jim's description.  Who exactly are these
"empowered users"?  And how much security do the second-class citizens ac-
tually get?  Will it work for everyone to become "empowered", or are there
scaling problems in terms of bandwidth?
It seems to me that the most sensible approach is to make message fragmen-
tation into standard-sized packets, along with reassembly, be at the
end user site.  This way everyone becomes a first-class citizen.

@_date: 1994-08-08 20:15:50
@_author: Hal 
@_subject: Remailer ideas 
I can see that there may be difficult cases, but I still think that
there would be real utility in the ability to specify that a particular
piece ofmail should be re-transmitted if it does not get delivered
to the destination machine within a certain period of time.  As I said,
this would help with the implementation of cryptographic protocols that
worked via email, not to mention the many other applications.
That's one reason I like the "enabledmail" approach.  All we have to do
is persuade everyone to run a system which allows anyone on the network
to get your computer to run an arbitrary program for them.  Then everything
will be fine.  One nice thing is that enabledmail scripts can
trigger either on delivery to the dest machine, or on being read by the
recipient.  This gives even more flexibility in how you want to define
a "received" message.

@_date: 1994-08-08 20:47:47
@_author: Hal 
@_subject: RemailerNet v0.2 
I'm glad to see Jim's description of his RemailerNet v0.2.  I still
have a few questions, though.
What is the goal of the RN as far as defeating traffic analysis?  Is it
just to get messages from one "gateway" to another?  Or is there also
a desire to prevent traffic analysis from one non-gateway end user to
What are the allowed capabilities of the opponent?  Can he watch all of
the links?  Can he subvert some gateways?
Does every user expose the source and destination information of his
messages to the initial gateway?  What other information is sent by the
user to the RN?
Are there any limitations on the information which spreads through the
RN?  E.g. are gateways allowed to send source/dest information
along with the messages?
Here are some questions related to Jim's specific points:
For 1.5 you defined what randomized means.  What does it mean here?
Do you mean that all gateways send the same number of packets per time
all the time?  E.g. all gateways send 100 packets per hour all the time
This could be accomplished by adding no latency at all during times when
the incoming traffic load happens to equal the desired internal traffic
level.  But presumably some latency is actually used to provide reordering.
What rule would determine how much latency would be used in that case?
What is a session?  Do you mean, during every session exactly (say) 1000
packets will be exchanged, or do you mean, during any session the
number of packets exchanged by each gateway will equal the number ex-
changed by every other gateway (but this number may vary from session to
To which gateway?  The source gateway?
Why do this?
What gateways would be in a position to charge users?  Only the source
gateway?  The destination gateway?  Others in between?
What are you trying to prevent by this, and what would happen if someone
wrote his own version of the RN software?
What kind of information would be available to them to create the ratings?

@_date: 1994-08-10 21:44:40
@_author: Hal Finney 
@_subject: RemailerNet 
This problem has long been recognized with anonymous reply blocks.  Chaum,
in his original 1981 CACM paper, suggested that anonymous reply blocks
should be use-once in order to prevent variations on this attack.  Of course,
a use-once address is of limited usefulness.
A problem with the maildrop idea is that the wiretappers can presumably
follow the messages to the maildrop.  Then the only question is whether
they would be able to tell when your message came in and requested further
forwarding of the collected messages.  Maybe this could be done securely;
I'm not sure.
Other ideas have been proposed for this problem.  Chaum suggested
having a public area where messages for a group of people would arrive;
everyone downloads all of them but can only read the ones for them.
For  this you would want a "stealthy" encryption envelope which did not
give away any information about the recipient's ID.  Miron Cuperman has
been running such a "message pool" for over a year now.
One problem with anonymous return addresses is that the address changes
deterministicly as each layer is stripped off.  This allows the message
to be tracked by introducing copies with different bodies but the same
ARA (which is why Chaum specified use-once).  Eric Messick proposed a
system in which the message bodies would be changed at each step by the
remailers involved.  I don't recall the details, but I think that in order
to read the message the user had to send it back through those same re-
mailers after receiving it, to undo the transformations which had been
done on it.  It was a complicated scheme and we really didn't spend enough
time on it.
I don't think anyone really trusts (or should trust) the ARA's we can
make now with the remailer network.  An ARA is a sitting duck, a tempting
target for attacks.  With an ordinary remailed message, by the time it
arrives and someone is interested in tracking it, most of the needed infor-
mation is (ideally) gone.  With an ARA you are entrusting your deepest
secret, your True Name, to a few layers of encryption with other people's
keys.  That is not a good feeling.
I view easy-to-use, secure ARA's as an unsolved (and perhaps unsolvable)
Hal Finney
hfinney at shell.portal.com

@_date: 1994-08-11 07:48:26
@_author: Hal 
@_subject: Are Remailers Liable for What They Remail? 
This is one of the things that worries me about the Digital Telephony bill.
In the various apologias and explanations from EFF, CyberWire Dispatch, etc.
about why EFF helped with this bill, it was mentioned that online service
providers have been removed from its coverage because they are not "common
carriers".  It only applies, they say, to common carriers like phone companies.
Obviously I haven't read the text of the bill (probably no one has ;-) but
this certainly raises the question of whether pursuing common carrier status
would cause electronic service providers to fall under the wiretap require-
ments of the bill.
Maybe I'll ask on usenet.

@_date: 1994-08-11 09:49:21
@_author: Hal 
@_subject: IDEA vs DES 
According to my references, the PowerPC 601 does an integer multiply
in 9 cycles (5 if the 2nd operand is 16 bits or less).  An integer
divide takes 36 cycles.  Adds, etc. take 1 cycle.
Floating-point multiplies take 1 cycle for single precision, 2 for double.
However, they are pipelined, so if you need to use the results of the
multiply on the next instruction, they will take 3 cycles.  Floating-point
adds take 1 cycle, again with the results available in 3.
There is a floating-point (but no integer) multiply-and-add instruction.
It has the same timing as the multiply.

@_date: 1994-08-13 14:06:41
@_author: Hal 
@_subject: Secret sharing made short 
I came upon a paper with this title in the 1993 Crypto conference proceedings,
by Hugo Krawczyk.  He pointed out that with the Shamir-type secret splitting
which we discuss here periodically you have considerable space expansion.
Splitting a message of M bits into N shares causes each share to itself be M
bits.  Krawczyk shows a simple system which basically has each share be only
M/N bits.  (I will ignore for simplicity the issue of providing a threshold
K<N such that any K of the N shares are sufficient to restore the message.)
He achieves this be foregoing "pure" information-theoretic secrecy in favor
of "mere" computational secrecy.  This is a reasonable tradeoff since most
implementations of Shamir sharing end up relying on computational secrecy
for their random numbers, anyway.
Krawczyk's idea, in the simple subset I am describing, is almost embarrassingly
easy.  Take your message M and encrypt it using a random IDEA or DES key.
Split the resulting cyphertext into N pieces (just carve it up) and give each
piece to a shareholder.  Take the IDEA/DES key and Shamir-split it into
N pieces and give those out as well.  (Shamir splitting for this case can
be done simply by having N-1 of the pieces be totally random, and having
the last piece be the xor of the IDEA/DES key and the N-1 random pieces.
Only by xor'ing all N pieces can the original key be recovered.)
Everyone ends up with slightly over M/N bits; they have M/N plus the size
of a DES or IDEA key.  But that is pretty close.  And unless IDEA or DES can
be broken they will have to recover all of the shares in order to recon-
struct the key and read the message.
For generalization to the K<N case you still use Shamir splitting on the
IDEA or DES key, but the message itself gets split up using an error-cor-
recting code concept so that K pieces are enough to reconstruct the message.
This requires M/K bits per share, plus the overhead for the DES/IDEA key.
This sounds like it would be a good enhancement to the Shamir splitting code
that was posted here.  The IDEA or DES module could be a source of random
bits for the Shamir splitting.  PGP's IDEA module is pretty self-contained
and has a random-number entry point.
(Oh, well, I've come this far, I might as well finish it.  The message
distribution scheme Krawczyk gives is this: split the message into K
pieces.  Treat each piece as the coefficient of a K-1 degree polynomial.
Evaluate the polynomial at X=0,...,N-1 and let the results be the shares.
Now any K of the shares will allow the polynomial to be reconstructed, and
by concatenating the coefficients we recover M.  This is similar to Shamir's
scheme but is not informationally secure and has shares of size M/K.)

@_date: 1994-08-17 21:21:16
@_author: Hal 
@_subject: Statistics on remail message sizes 
A couple of weeks ago Eric asked for statistical information on remailer
message sizes.  I put in a size-counter a week ago (just piping each message
into wc >> remail2/SIZE.REMAIL) or so, and here are some results.  They show
645 messages logged, a sample of what the logs look like, the average size
of a message in characters (counting the header) of about 15K, and a
histogram of message sizes rounded to the nearest 1000.  Note that the
histogram is pretty irregular, possibly being affected by repeated
sending of certain messages.
jobe% wc remail2/SIZE.REMAIL
     645    1935   16125 remail2/SIZE.REMAIL
jobe% tail remail2/SIZE.REMAIL
      58     189    3225
      16      90     850
      18     121    1016
      14      90     896
      23     140    1350
     653     803   41937
     710     860   45666
     710     860   45642
      20      96     901
      28     146    1344
jobe% awk '{sum=sum+$3} END{print sum/NR}' < remail2/SIZE.REMAIL
jobe% < remail2/SIZE.REMAIL awk '{print int(($3+500)/1000)*1000}' | sort -n | uniq -c
 229 1000
  82 2000
  50 3000
  21 4000
   3 5000
  45 6000
   9 7000
   1 8000
   1 9000
   3 10000
   2 11000
   1 12000
   2 13000
   5 14000
   3 16000
   3 17000
   2 18000
   1 19000
   2 21000
   3 23000
   1 24000
   2 25000
   2 26000
   2 27000
   1 28000
   1 30000
   1 31000
   1 32000
  39 34000
  37 35000
   1 37000
   2 38000
   2 42000
   2 46000
   1 48000
   1 49000
   1 50000
   1 51000
   1 55000
   9 59000
  69 60000
I did one other test, which was to see which message sizes were repeated
the most.  The first number shows the number of lines which have messages
of exactly the second number of bytes:
jobe% < remail2/SIZE.REMAIL awk '{print }' | sort -n | uniq -c | sort -nr | sed 20q > times2
  40 896
  40 1350
  20 5797
  14 1344
  11 33845
  11 1242
  10 892
   9 33992
   9 1248
   8 1753
   7 33975
   5 1765
   5 1757
   5 1236
   4 901
   4 1749
   4 1251
   3 59725
   3 59668
   3 5945
It is clear that there is a lot of repetition, probably standard ping
messages and the like.  This should give enough info to discard the highly
repeated sets from the histogram above in order to get a possibly more
representative set of numbers.

@_date: 1994-08-20 09:53:19
@_author: Hal 
@_subject: Brands cash 
Last year, Stefan Brands announced that he had come up with improved
versions of Chaumian cash and credentialling protocols which were
smaller, faster, and had provable correctness.  He still hasn't gone
public with them, but I thought I'd write up an introduction to his
earlier work so people can see what direction things are going.  IMO, if
he plays his cards right his technology could be the foundation for
electronic commerce.  OTOH if he is too greedy he'll be bypassed.  It
appears he is seeking patents on everything, a necessary step for
commercial interest, but we'll see how he markets it.
This is based on Brands' "An Efficient Off-line Electronic Cash System
Based on the Representation Problem", which was available on the net for
a while before he took it off.  I'm not sure what its status is now.
Perhaps he removed it pending release of his improved version.
Brands' work is based on discrete logs rather than RSA.  The discrete
logarithm problem is the "other" widely-used foundation for crypto
primitives, underlying Diffie-Hellman key exchange, ElGamal, Schnorr, and
DSS signatures, and many others.  I'll do a brief intro to using discrete
logs and then get to Brands' cash.
Discrete-log based cryptosystems generally work with a modulus n which is
prime, along with a "generator" g < n such that the series g^0, g^1, g^2,
... , includes all values from 1 to n-1.  It is pretty straightforward to
find such n's and g's.  It is easy to compute g^x for any x, but
intractable to calculate x given just g^x.  (Notation: ^ represents
exponentiation, and all math is implicitly mod n).  x is called the
discrete log (to the base g) of g^x and the difficulty of solving this is
the foundation of these protocols.  Note that unlike RSA, where taking
eth roots is hard for everyone except the owner of the secret key, taking
discrete logs is hard for everyone, without exception.  There is no trap
door here.
Diffie-Hellman key exchange
As an introduction, consider Diffie-Hellman key exchange.  In this
protocol, two people, Alice and Bob, want to publicly exchange data and
end up with a secret value which only they know.
1.  Alice chooses a random x and sends GX = g^x to Bob.  Bob chooses a
random y and sends GY = g^y to Alice.
2.  Alice calculates GY^x, which is g^(y*x).  Bob calculates GX^y, which
is g^(x*y).
3.  These are equal, so they use them as their shared secret value.
An observer sees only GX and GY, and without knowledge of x and y is
unable to calculate g^(x*y).
DH-based identification protocol
An identification protocol allows someone to prove that he is really who
he claims.  In this context, the prover Paul will convince the verifier
Vicki that he knows the secret key corresponding to Paul's established
public key.  In this and the following systems, Paul has a secret key
x<n, and a public key GX = g^x.  Again, note that it is impossible to go
from GX to x assuming discrete logs are hard.
1.  Vicki chooses a random y and sends GY = g^y to Paul.
2.  Paul calculates GYX = GY^x = g^(y*x) and sends that back to Vicki.
3.  Vicki confirms that GYX = GX^y; both should be g^(x*y).
This is like DH except that Paul exposes the secret information he
calculated, and only he could have done this.  One problem with this
protocol is that perhaps Paul calculating xth powers for Vicki might
reveal something about x.  The next protocol solves that:
Schnorr identification protocol
This comes from Schnorr, Journal of Cryptology, v4 n3, 1991.
1.  Paul chooses a random w and sends GW = g^w to Vicki.
2.  Vicki chooses a random c and sends it to Paul.
3.  Paul calculates r = cx+w and sends that to Vicki.
4.  Vicki confirms that g^r = (GX^c)*GW.  Both should be g^(cx+w).
The extra step of Paul sending g^w for a random w makes this protocol
reveal less information about x.  For any one run of the protocol, there
is some value of w which would produce a given r for any x, so knowing r
and c doesn't tell you anything about x.
Chaum discrete-log interactive signature protocol
This is the basic signature used by Brands, but I believe it comes from
Chaum&Pederson, Crypto 92.  It is an extension of the previous protocol
to allow signatures.  A digital signature on a value m is a certificate
which could only have been produced by the owner of a particular public
In this protocol, a message m (<n) is being signed.  The basic signature
value is MX = m^x, which Paul sends.  By itself, though, this signature
is not obviously correct.  Without knowing x, Paul's secret key, there is
no way to confirm it.  So, Vicki must engage in an interactive protocol
with Paul in which he will prove that MX is equal to m^x.  It is very
similar to the previous one:
1.  Paul chooses a random w and sends GW = g^w and MW = m^w to Vicki.
2.  Vicki chooses a random c and sends it to Paul.
3.  Paul calculates r = cx+w and sends that to Vicki.
4.  Vicki confirms that g^r = (GX^c)*GW.  Both should be g^(cx+w).  She
also confirms that m^r = (MX^c)*MW.  Both should be m^(cx+w).
This is the previous protocol plus one extra number, MW.  The fact that
the same r is used for both m and g shows that m was raised to the same
power as g in creating MX vs GX.
Chaum Discrete-Log Signature Protocol
Interactive signature protocols may have advantages in some
circumstances, but in most cases we would prefer a signature which can be
checked without help from Paul.  There is a simple trick which can turn
most interactive signature protocols into regular signatures.  The idea
is that instead of c being chosen at random by Vicki, it is calculated by
using a cryptographically strong hash function (such as MD4, MD5, or DHS)
on the values which are publicly known by that point in the protocol: m,
MX, GW and MW.  Since both Paul and Vicki could calculate the hash, there
is no need for Vicki to send c to Paul.  Instead, he can do everything in
one step.  This leads to:
1.  Paul calculates MX = m^x.  He then chooses a random w and
calculates GW = g^w and MW = m^w.  He then calculates c = hash(m,MX,GW,MW).
He calculates r = cx+w, and sends MX, GW, MW and r to Vicki.  The tuple
(MX,GW,MW,r) is the signature on m.
2.  Vicki calculates c = hash(m,MX,GW,MW).  She then verifies, as
before, that g^r = (GX^c)*GW.  Both should be g^(cx+w).  She also
confirms that m^r = (MX^c)*MW.  Both should be m^(cx+w).
This protocol is not interactive.  Once Paul has completed step 1,
the signature can be published and anyone can play Vicki's part in
checking it.  Such a signature is functionally similar to the PGP
signatures we see on messages on the net, but as you can see the
mathematics behind it is completely different.
OK, that's all for now.  Next comes the good part: blind signatures.
Unlike Chaum's original blind signatures, which are the foundation of his
cash system, the discrete-log blind signatures have "restrictive
blinding", where there are limitations on what kinds of changes can be
made to the number being signed during the blinding process.  This allows
Brands to dispense with the clumsy cut-and-choose techniques Chaum was
forced to use in his advanced cash and credential systems.  I'll write
more about this later today or tomorrow.

@_date: 1994-08-21 10:07:06
@_author: Hal 
@_subject: In Search of Genuine DigiCash 
rah at shipwright.com (Robert Hettinga) writes (quotes are Eric Hughes):
One difference between ecash and bonds is that bonds generally pay interest
(to the bond holder, not to the lender!), while ecash may not.  I also
suspect that most ecash will have a fixed maximum lifetime beyond which it
is no good, due to technical problems in keeping lists of spent notes.  So
it would not necessarily be callable in theway Bob describes.
I think Eric is referring to how the notes are denominated, and the possibility
that they may bear interest.  A note could be marked as worth $1 + 6% per
year past 1994, expiring in 1998, for example.
Fair?  Who cares?  The question is, is it useful?  Sure it is.  I'd rather
use cash which bore interest than that which didn't!  Sure, it's a little
more complicated to buy something with notes which are worth $1.05 - $1.10
than $1.00, but that's what computers are for.  The value increase accrues
to whomever holds the note during the time they hold it.
Sure; just don't say "the solution is".  You issue non interest bearing
notes and live on the float; I issue interest notes and live off the
exchange fees.  Let the market decide.

@_date: 1994-08-21 10:16:34
@_author: Hal 
@_subject: In Search of Genuine DigiCash 
I think Eric was referring to simple double-entry bookkeeping.  I don't
have his original post in front of me, but I believe the suspension account
was a liability account which represented the digital cash in circulation.
In double-entry bookkeeping, every transaction alters two accounts so that
the books stay in balance.  It's not unusual to make up specific accounts
for the particular assets and liabilities of your business.
There's something I don't understand about this "immediate and final
clearing" business.  In an on-line cash system, the cash itself is not
"cleared" until you send it to the bank and/or have some guarantee from the
bank that it has not been spent before.  It seems to me that you could get
the same benefit from a checking account if you called the bank, verified
the funds were available, and electronically cashed the check on-line.
In an off-line system, is the cash really cleared immediately?  What if it
is double-spent?  Is the bank going to guarantee to cover all instances of
multiple spending, in the hope or expectation that it can sue the customer
who did it?  What if you're talking about huge sums of money, and the guy
doesn't just double-spend but hundredfold-spends it, then vanishes to Rio?
Are the banks going to cover that?  They don't cover bad checks, and I don't
see how they can afford to cover bad cash.
So for both on-line and off-line ecash there appear to me to be problems
with the notion that cash has a unique advantage in providing immediate
clearing of transactions.

@_date: 1994-08-21 10:25:53
@_author: Hal 
@_subject: e$: e-cash underwriting 
Come on, Bob, we've talked about a lot of problems in the last few weeks: the
prohibitions on most forms of bearer bonds; the prohibitions on banks
issuing their own currency; the stringent regulations for private scrip
circulation.  Our people who know securities law can probably list a few
OK, but also one way to find out whether it is legal or not is to test it.
If you end up in jail, I guess it wasn't legal.  Maybe that's not the
best strategy, though?
Send mail to netbank-info at agents.com for info on their non-anonymous (I
think) cash-like system.  I wonder whether they have worried about these
issues or whether they are trying out the strategy above.

@_date: 1994-08-21 10:37:12
@_author: Hal 
@_subject: Voluntary Governments? 
I like this idea of voluntarily "escrowing" some valuables in order to
lend credibility to my promise to follow certain laws, and to get various
privileges in return.  You could have digital certificates from the
enforcement agency (it does not fit closely enough to my model of a govern-
ment to warrant that term in my usage) to show that you are a "paid up"
Well, again, an organization which I voluntarily join (for a fee) in order
to get some benefit (forfeiting some of my otherwise refundable fee if I
break various agreements) is not coercive in my usage of the term.  I
suspect people will understand this idea better if you avoided applying
concepts like coercion and governments to it, concepts which are usually
associated with use of force.
In an on-line world it would be much easier to enforce banishment or
selective ostracism than in real life.  Filtering agents could look for
certificates from accepted enforcement agencies before letting messages
through.  Each user could have a set of agencies which were compatible
with his principles, and another set of "outlaws".  You could even end up
with the effect of multiple "logical subnets" of people who communicate
with each other but not outside their subnet.  Some nets might respect
intellectual property, others not, and so on.

@_date: 1994-08-21 14:24:36
@_author: Hal 
@_subject: In Search of Genuine DigiCash 
Well, I still don't follow this analogy.  By this reasoning virtually every
commodity that someone is willing to buy and sell is a callable bond.  The
local gold dealer may sell me gold coins for cash, take the cash, put it in
the bank and collect interest, then buy my coins back from me later.  Is the
gold a bond?  Am I "calling in my bond" when I sell the gold to him?  I don't
get it.
Re interest-bearing cash:
Let's see, I'm selling spindles for $2.59 and you come up with a piece of
ecash you bought ten years ago for $1.00, which is now worth $2.59, and I
sell my spindle to you for it.  I deposit the cash in the bank and it's worth
$2.59.  Now who isn't this fair to?  How is it different from you putting
$1.00 into your interest-bearing checking account ten years ago and writing
me a check for $2.59 today, the amount your $1.00 grew to?
Sorry, I guess I'm missing a lot of your points.

@_date: 1994-08-22 16:18:16
@_author: Hal 
@_subject: Brands cash 
In the last installment, I described a particular technique that could
be used for signatures based on discrete logs.  (There are many DL-based
signature algorithms, but this particular one lends itself to the blinding
technique.)  I should point out that this signature is due to Chaum, and
in fact everything I will discuss comes from Chaum's work.  Brands goes on
to develop some nifty cash systems based on it, but his extensions are too
complicated to touch on more than briefly.
Blind signatures are, IMO, the key to anonymous digital cash, and in fact
to many forms of anonymity.  The ability to engage in mutual information
manipulation with another person, while guaranteeing that no linkage will
later be possible between the data exchanged and the results of that
calculation, is the foundation for interacting in a complex way without
losing any privacy.  The significant feature of the blind signature I
will describe here is that it is a "restrictive" signature.  In the
original Chaum blinding technique, there were no limits on what was actually
being signed.  With this restrictive blinding, only a limited set of
transformations are possible between what is seen by the signer and what
is later exhibited as the signature.  These transformations fully protect
privacy, but the restrictions protect the interests of the signer and
end up simplifying the protocols (which were complex just to protect his
Recall that there were two kinds of DL-based signatures I discussed earlier.
In the interactive signature, Vicki the verifier came up with a challenge
number c which she went to Paul the prover (signer).  Paul produced a
response r which depended on c, and using r, c, and the other numbers from
the protocol Vicki is able to check and confirm the signature.  In the non-
interactive signature, the challenge number c is calculated as a cryptographic
hash function of the other numbers, and r is again shown based on c.  Vicki
no longer has to interact with Paul; she (or anyone else) can confirm the
signature based on r, c, and the other numbers.  The hash function basically
takes the place of the interactive verifier, and since it is cryptographically
strong c is essentially random.
The blind signature basically combines these two techniques.  Vicki wants
to end up with a non-interactive signature on m', which is a special trans-
formation of m.  To do this, she engages in an interactive signature protocol
with Paul, getting him to sign m.  But the c she sends to Paul is an easily-
undoable blinding of c', which comes from the cryptographic hash function
applied to m' and the other numbers.  The r she gets back is then easily
transformed into an r' that works with the cryptographic hash.  The result is
that she ends up with a non-interactive signature on m' because Paul was
willing to participate in an interactive signature session on m, and Vicki
chose the c carefully so it would work in the final signature she shows.
(This shows, BTW, that it is not safe in general to have a system which
uses both interactive and non-interactive signatures using the same keys.
This technique allows non-interactive signatures to be produced from inter-
active sessions on different numbers.  In the blinding protocol, Paul knows
what Vicki is up to, and he willingly goes along with the blind signature.
Similar problems were pointed out long ago with RSA signatures.)
Now for the mathematics.  Recall the g is the "generator" of the group,
the base of all of the powers.  x is Paul's secret key, and GX=g^x is his
public key.  The relationship between m', which is what Vicki will end up
with a signature on, and m, which is the number that Paul sees, is
In other words, a signature may be blinded by being taken to any power, and
multiplied by any power of the generator g.
This means that if Paul puts some restrictions on the m that he is willing
to sign, Vicki will not in general be able to end up with a signature on
an arbitrary m' of her choice.  Due to the difficulty of the discrete log
problem, she cannot in general find s and t such that (m^s)*(g^t) is a
desired m'.  Instead, she can do little better than to choose s and t at
random and just accept whatever m' comes out.
As the first step of the interactive protocol, Paul chooses a random w
and sends Vicki MX = m^x, GW = g^w, and MW = m^w.  In the non-interactive
signature, the challenge c is calculated as the hash of (m,MX,GW,MW).  Vicki
must transform these numbers so that Paul will not recognize them, but in
such a way that the mathematical relationships are maintained.
To do this, Vicki chooses two (more) random numbers, u and v (along with
s and t above).  These will be such that w'=u*w+v, although Vicki never
knows w (or w').  Then she calculates her numbers as follows:
    MX' = m'^x = ((m^s)*(g^t))^x = (m^(s*x))*(g^(t*x)) = (MX^s)*(GX^t)
    GW' = g^w' = g^(u*w+v) = (g^(u*w))*(g^v) = (GW^u)*(g^v)
    MW' = m'^w' = ((m^s)*(g^t))^(u*w+v) = [...] =
These are not that hard given the definitions above, except for that last
one, where I skipped a few steps :-).
Using these, Vicki calculates her hash c'= Hash(m',MX',GW',MW').  Now,
the c she sends to Paul will be used to calculate r = c*x+w.  She wants
to end up with r' = c'*x+w' .  This can be achieved by the following
two transformations, based on w'=u*w+v:
This c is sent to Paul, and the returned r is transformed to r'.  The
resulting signature on m' is (MX',GW',MW',r'), and it is perfectly valid
just like any other non-interactive signature using this signature function.
Well, the mathematics are a little complicated, I know.  The main things to
take away are that the restrictive blinding does require some interaction
with the signer in order to end up with a non-interactive signature, and
that the limitations on the blinding which can be done are to take the
signed number to a power and multiply it by some power of g.
There are a couple of easy applications of the simple blind signature.
(I made both of these up based on Brands' hints, so if there are
problems with these specific examples please don't blame him.)
The blind signature by itself is perfectly suitable for on-line cash.
The cash could be represented as any signed value using a particular
secret key.  Unlike with RSA signatures, it's not possible to conjure up
a bunch of perfect 3rd powers (or whatever).  The only way to come up with
anything that satisifies the tests for a valid signature is by participating
in the algorithms above.  So by itself (MX',GW',MW',r') and m' could
constitute a "piece" of digital cash.  It would be anonymous and untraceable
just like the simple Chaum online cash.
Another nice application is to a system of pseudonyms and credentials.
Chaum originated this idea but his implementation was complicated and
clumsy, involving cut-and-choose, hundreds of discarded validator terms,
and other messy stuff.  Using Brands' technology each person could have
an identity string I, and get that signed by the validator-issuer, reblinding
it to be I^s which would be the pseudonym at a given organization (you don't
need the g^t term for this application).  Instantly we have constrained
pseudonyms to be of the desired form without any mess.
Now if you get a credential from some organization ("good credit risk"),
and want to show it on your pseudonym at another organization, you get
them to sign I^s and reblind that to be a signature on I^s'.  You can do
this by taking I^s to the s'-s power, an allowed transformation under the
blinding rules.  And you can't turn it into a signature on some other
person's pseudonym because there is no way to know what power I^s would have
to be taken to to get I'^s for some other I' due to the DL problem.
So, pseudonym/credential systems practically fall in your lap with this
signature, and Brands has been able to extend his ideas a very long way
along these lines.  He has all kinds of different rules which can be applied
by modifying the basic idea.  I hope that he will be able to publish his
results soon so that we can see what the possibilities are.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-08-22 22:10:25
@_author: Hal 
@_subject: Brands cash 
OK, for those who have stuck with me so far, I will describe a slightly
simplified version of Brands' off-line cash.  Users' anonymity is protected
unless they double spend.  (At last we are departing from Chaum and
getting into some of the territory blazed by Brands.)
The first thing that is done is that the value which is signed by the
cash issuer in the creation of the cash encodes some information which
represents the identity of the user.  Let's call the user Irving, and
the number which encodes his identity (it might just be his bank account
number in this case) we will call I.  The rule is that the issuer will
only sign values which are of the form d*g1^I, where d is a fixed number
used in the cash system, and g1 is another fixed value which is used
here similarly to the g of the signature protocol itself.  (d can actually
encode the denomination by having a few different d values that are used,
or else denominations can be encoded by different secret-key x values of
the bank as is done in Chaum's cash.)
As in a simplified version of the on-line cash, the signature is blinded to
m' by raising it to the power s (we don't multiply by g^t here), getting a
number m' of the form (d^s)*g1^(I*s) for random s.  This totally masks
Irving's I so it is not revealed in normal use.
Now, the next new step is that Irving divides this m' value into two
parts, called A and B, such that A*B equals m'.  This can only be
done (due to the discrete log problem) by having A=(d^x1)*(g1^y1) and
B=(d^x2)*(g1^y2) such that s=x1+x2 and I*s=y1+y2.  In other words, the
exponents on d and g1 are split randomly into two parts and these used
to form A and B.
If anyone can find out s and I*s after the cash is spent, they can learn
Irving's identity.  They know m', A, and B, because they get revealed
when Irving spends (as shown below).  But this is not enough to learn
s & I*s.  If you find out x1, x2, y1, and y2, though, this allows s and
I*s to be deduced, and therefore also breaks the anonymity.
In spending the cash, Irving must reveal the signed m', along with A
and B.  (B can actually be deduced as m'/A.)  Then, the store comes up
with a challenge c (this is a different c than in the withdrawal protocol).
Irving has to reply with two numbers: x1+c*x2, and y1+c*y2.  This
is pretty scary!  He's really putting his cojones on the line, here.
s(=x1+x2) and s*I(=y1+y2) will give him away, and here he's revealing a
simple linear combination of x1&x2, and y1&y2.
But he's actually safe in doing so - as long as he doesn't double-spend.
x1+c*x2 still perfectly blinds x1 and x2, since nothing is known about
these values, and likewise for y1 and y2.  Just like in the original
signature protocol where Paul gave away c*x+w, x his secret key, this is
safe.  (Well, it does appear that he should make sure c!=1.  Then he
would be telling x1+c*x2 = x1+x2, which is what he doesn't want to give
Irving might be tempted to lie about x1+c*x2 and y1+c*y2, but if he does
he will be caught. The shop calculates A*(B^c), and this should be equal
to d^(x1+c*x2)*g1^(y1+c*y2).  Once this is verified, the shop, having
checked the signature on m', accepts the cash.
Now consider what happens if Irving tries to spend the cash again.  This
second shop will produce a different c challenge; call it c'.  Again
Irving must respond with x1+c'*x2 and y1+c'*y2.  But now his goose is
cooked.  Once the bank gets the information from both shops it knows both
x1+c*x2 and x1+c'*x2, and it knows c and c', so it can deduce x1 and x2.
Likewise it can calculate y1 and y2.  Adding these up gives s and I*s, and
dividing these gives Irving's identity I.  He's caught.
There is one significant complication I have skipped over here, and that
is the possibility that Irving could choose different A and B values
(always with A*B=m') each time he spends.  Then the x's & y's would be
different each time and he wouldn't get caught.  This is avoided by making
a small change to the signature-checking algorithm.  Earlier recall that a
non-interactive signature on m' was defined by (MX',GW',MW',r'), and that it
was checked by setting c'=Hash(m',MX',GW',MW'), and doing the special
calculation with c' and r'.
For this off-line cash we make a small change, which is that the hash
function is calculated as c'=Hash(m',MX',GW',MW',A,B).  We include the A
and B in calculating the hash function.  The bank never sees A and B, just
like it never sees any of the other values in the hash function, but c'
depends on them.  If Irving tries to change A and B, then the c' which the
shop calculates (using this longer hash formula) will be different, and it
won't work with the r' that Irving got back from the bank.  So by including
more terms in the hash input we in effect get those things signed as well
in a blinded way by the bank.  (I think a similar hashing trick is how Schnorr
signatures work, BTW).
Once again, this protocol looks complicated, but compare it with Chaum's
original off-line cash: there is no cut and choose, and the amount of
data exchanged at each step is not very large, a few multi-precision values.
I wrote up a long description of Chaum's off-line cash at a similar level
of detail to this one, and I really think Brands' cash is far superior.
Hal Finney

@_date: 1994-08-24 07:53:17
@_author: Hal 
@_subject: Brands cash 
Unfortunately, I don't think perl is suitable, as it has no facilities for
multiprecision arithmetic.  I was talking to Henry Strickland at Crypto and he is working on a package that would use the scripting language tcl
(which is a little similar to perl) and could do this stuff.  Alternatively
you could use a public-domain package like gmp or perhaps the pgptools library created by Pr0duct Cypher.  That last one has MD5 hash built in so
it would have everything you need.  For that you would have to program in C
or perhaps C++ though.

@_date: 1994-08-24 08:08:06
@_author: Hal 
@_subject: Fast modular exponentiation 
In the Crypto 93 proceedings, there is an article by Bosselaers, Govaerts,
and Vandewalle comparing the speed of three algorithms for modular reduction
which is the main time-consuming step in modular exponentiation.  They
compared the classical algorithm from Knuth, a modification to it by Barrett
which speeds up the estimate of the first digit of the quotient, and Montgomery multiplication (which is inherently modular).
Montgomery was the fastest for taking 1024 bit numbers modulo 512 bit
numbers, but not by a lot.  For exponentiation, though, where the reduction
happens a lot, Montgomery was fastest for all but the very smallest exponents.
512 bit exponents took  about 2.93 seconds for the classical algorithm,
2.85 seconds for the Barrett improvement, and 2.55 seconds for Montgomery.
The crossover point (below which Barrett is best) is exponents of about 32
So, Montgomery multiplication was best, but the percentage improvement is
not that large.
Sometimes, as I mentioned yesterday, you can restrict the size of the exponents
without losing security (as in DSS), but it depends on the algorithm.

@_date: 1994-08-25 09:23:46
@_author: Hal 
@_subject: Brands cash 
A few closing notes on Brands' technology:
There is a trick which is used in a lot of the discrete-log algorithms
which reduces the storage space needed and speeds up the calculations
by a factor of up to 4.  Originally I described the generator g as being
one whose order is equal to n-1; that is, the series g^0, g^1, ...g^(n-1)
encompasses all the numbers from 1 to n-1 before looping.  However, it
turns out to be advantageous in many cases to choose a generator which
has a smaller period.
The period of the generator must be a divisor of p-1, as it turns out.
Choosing a generator with period q, a prime which divides p-1, allows
all of the results to continue to work as long as a couple of small
changes are made.  Exponent arithmetic must be done mod q, since
that is the "wrap around" point.  For example, where the signature
algorithm does r=c*x+w, this would be done mod q.  (It actually needs
to be done mod n-1 in the full-cycle-generator case, but I didn't get
into that detail.)  The other thing that has to be done is that when
random numbers are chosen, they should be from 1 to q if they are
exponents (as in the case of w from the signature algorithm), and they
should be in the group generated by g (that is, the set of values
g^0, g^1, g^2, ...) if they are bases (like g1 and d in the off-line
cash algorithm).
A typical set of values for q and n are 140 bits and 512 bits.  This
is what is used in the government DSS (at least in the first version;
I'm not sure what other options they came up with).  This means that
exponentiation only has to be done to 140-bit powers rather than
512-bit powers, which only takes about 1/4 as long.  It also means
that everywhere in the protocol that an exponent is stored or transmitted
only about 1/4 as many bits have to be sent.  Yet even with these smaller
exponent values solving the discrete-log problem is believed to be as
difficult as with full-sized exponents.
Sometimes people ask how the difficulty of discrete-log compares with
factoring.  I haven't been able to really get a clear answer on this.
One quote on sci.crypt last year said that discrete-log for 1024 bits
is harder than factoring for 512 bits, and likewise factoring for 1024
bits is harder than discrete-log for 512 bits.  But this isn't saying
much considering the 1024 bit problems are probably a million times harder
than the 512 bit problems.
I've sent email to Brands every few months gently hinting about when he
might be willing to publish his results.  Originally he was going to
publish earlier this year, but then he decided to hold off for a few
months while he looked for investors.  I don't know what luck he has
had with that, but recently he said that he'd be publishing before the
end of 1994.
I sent him my ideas for a pseudonym/credentialing system, and he very
kindly said that he used similar concepts for some of his technology.
However, a limitation of my idea was that a credential can be transferred
only to one specific other pseudonym, although the credential issuer
does not know what pseudonym it is.  Brands said this is one of the
types of credentials he can do, but that he also uses "a different
mechanism" to provide for credentials which can be shown at any shop
where one has a pseudonym.  I haven't been able to figure out how to do
One nice thing about this credentialling system, BTW, is that the
credentials can be issued by the shops/companies themselves.  In Chaum's
system only one agency can give credentials.  That is because RSA sig-
natures are used, and you can't have two different RSA signers both share
the same modulus n.  (They would both have to know the factors.)  But
with the discrete-log signatures, many people can share the same n,
have their own secret keys x, and issue signatures.  So, at least with
the simplified credentials I described, shops can issue their own cre-
dentials in the form of signatures on pseudonyms which were validated
by the validating agency using its own signatures.  Everyone would share
the same modulus and therefore be able to make their own signatures.
Hal Finney

@_date: 1994-08-25 09:48:03
@_author: Hal 
@_subject: Is pay-per authentication possible absent trust? 
One thing I don't follow here is under what circumstances a "challenge"
will occur.  Presumably Microsquish will not blindly accept all of
Ingve's assurances since they are backed only by promises.  Can
Microsquish force Ingve to go to his clients and make them produce
certificates?  Who pays for that?  Maybe if you factor in that cost it
won't look so bad for Charles.
Also, just because Charles can't get what he wants for his certifications
doesn't mean he is being cheated.  It's a market, after all.  You could
just as well say that somebody else opens up a certification shop that
sells certifications just like Charles' for less.  It's not the fault of
the protocol that Charles' business dries up.  If the value of his
certifications drops (as in your scenario) then his business should decrease.
Last, I'd say your problem exists just as clearly without Ingve.  You
could make a deal with Microsquish promising that you would be able to
get certifications if asked, with some agreed-upon procedure by which
Microsquish could demand that you produce one, with appropriate
penalties.  In that case probably Microsquish would believe some
percentage of people and Charles' business would again fall off.  In
practice Ingve might be useful to help even up fluctuations but the
problem arises just as clearly without him.
You might look at it in terms of a priori vs a posteriori probabilities
that you do in fact have the ability to gain a certification.  If
Microsquish was inclined to believe you before (say, because you had
demonstrated good faith in the past), then the exhibition of an actual
certificate is less valuable to Microsquish because it adds less
information.  So it makes sense that certificate challenges, with their
associated costs to you and Microsquish, would occur less frequently in
that case.  Again, it appears that the situation is simply reflecting
market values of information.

@_date: 1994-08-25 13:47:10
@_author: Hal 
@_subject: Is pay-per authentication possible absent trust? 
Jason W Solinsky  writes, quoting me:
One thing I'd add is that Charles still makes money whenever there is a
challenge.  If there were no challenges then there would be nothing to
keep people honest.  So it's not a matter of eliminating pay per use of
certifications, it's just a matter of the frequency with which they are
used vs other kinds.
Also, as the challenges become less frequent, Charles can actually raise
his rates and still let everyone else make money.  He can even charge
more than the 10 that Micro is paying for challenges, which he could
probably not have done in the non-probabilistic (pre-Ingve) system.  It
sounds like Micro is paying the challenge fees (in at least one version)
and if the penalties against cheaters are great enough it won't challenge
very frequently, in which case a larger fee by Charles can be absorbed.
Another approach, BTW, is the "undeniable" signature, which allows an
authorization which can only be checked with the cooperation of the
issuer.  (One of the ones Chaum came up with was described in a posting I
made last weekend.)  But again, the same "problem" arises where people
could check only a fraction of signatures with voluntary penalty clauses.
There is also the reseller who checks a signature interactively, paying
Charles' fee, then sells his own certifications that you have a valid
Charles certification, only these are use-many.  The thing is, the amount
of information being provided in a certification like this is so small
(in effect, one bit) that the "information copying" problem hits pretty
hard!  If you can't stop people from copying a 1 MB game you're going to
have a tough time keeping that single bit corralled.
These tend to be non-local solutions, with a lot of overhead and extra
mechanisms.  Maybe you can make it work with your "government" but I'm
afraid you may come to lean on it as the solution to all of your
problems.  Why bother with cryptography for anything; just have a
"government" where everybody has posted a ruinous bond which they forfeit
if they break a "law", then legislate communications privacy, non-
duplication of electronic cash, bit commitments, etc., with heavy
incentives for people to report cheaters?
Again, though, people could just swear they've seen a Charles certificate
and these witnesses will undercut Charles.
As I said, I think there will still be a place for per-use
certifications, but the market will decide how much they are used vs
other kinds.  I don't think you should worry so much about trying to fine
tune the system so this one technology wins.  There are a lot of
possibilities that people may come up with.

@_date: 1994-08-25 13:58:33
@_author: Hal 
@_subject: $10M breaks MD5 in 24 days 
I am not attending the Crypto conference, but I sat in on the evening
"rump session" the other day.  One of the more interesting papers had
a claim (with little detail, unfortunately) that for ten million dollars
you could build a machine that would "break" MD5, in the sense of finding
another message which would hash to the same as a chosen one, in 24
days.  This result did not depend on any internal structure in MD5, but
was purely a result of the hash size (128 bits) and the time it takes
to calculate a hash.
The main new result which allowed this was a more efficient way of
handling a parallel search for collisions (two messages which hash to
the same thing).  In some earlier methods, n machines provide only a
sqrt(n) speedup.  The new method improves this, although my notes don't
show exactly how close they come to an n-fold speedup.
The Secure Hash Standard (SHS, aka SHA) is, they said, 64K times slower,
hence this technique would take 64K times longer (or cost ~64K times
more?) to break that hash.
I don't think this is probably anything to really worry about, but
maybe it points out a need for a longer hash in the next few years.
P.S. The paper was by Paul C. van Oorschot & Michael J. Wiener.

@_date: 1994-08-25 20:21:26
@_author: Hal 
@_subject: Cash, cheaters, and anonymity 
This is a response to an untitled anonymous post which raised some
good issues.  My answers may be a little controversial; feel free to
One question is the ease of theft in a digital cash environment, and
the consequences of claiming that secrets have been stolen.  This
problem was recognized very early on in discussions of digital
signatures.  The whole point of a signature is so that someone can be
held to a commitment.  But an easy "out" would be to "accidentally on
purpose" let the secret keys be stolen, then to claim that the
signature was actually forged.  Contrariwise, a business might
be vicitimized by actually having its secrets stolen and a forged
signature created that committed it to an unfavorable action.
I don't know what the best solution of these kinds of problems will
be.  Probably in the next couple of years we will see some test uses
of digital signatures, and then we can see how these conflicts will be
handled by the courts.  Obviously, traditional methods like
handwriting analysis which rely on physical imperfections will not be
useful.  Instead the issues to be examined would include the security
methods used to guard the secrets, who might have had access to them,
what the reputations are of the parties involved, and so on.  It seems
like these cases will not be easy to resolve cleanly.
On the other hand, I would hope that people actually can learn to use
care in safeguarding their secrets.  The pass words and PINs we use
today may be complemented by physical checks for voice patterns, thumb
prints, perhaps (ironically) handwriting.  Another approach would be
to raise people's IQ to about 1000, so they could do an unbreakable
authentication protocol in their heads :o.  Failing that, there have been
suggestions (one here a couple of days ago) to use various kinds of
information exchange between the authenticating device and the human
user in order to prove authorization in such a way that even a thief
who has snooped on past exchanges will not be able to use the device.
This approach is sometimes called the use of "pass algorithms".
Applying this to the double-spending case, I suspect that Bob Hettinga
is more on the right track in seeing the solution in the legal system
rather than a simple "shucks, you caught me" forfeiting of a bond
worth triple damages.  There really should be no excuse for double
spending, even of a penny, and the penalties could be made strong
enough to deter most people.  If a bank does not think they will be
able to find and prosecute a person who is withdrawing off-line
digital cash, they will probably not give any to him.  Then if the
money is double-spent, the person who withdrew it would be prima facie
responsible, with a reasonable presumption that they did it unless
there is significant evidence otherwise.  I don't know that this is
how it will work out but it is one possibility (unless the uncertainty
just scares everybody away - but I think the digital signature
experience will get people used to the concepts and problems).
The other point I wanted to discuss was this issue of the bank
authenticating the people who receive the cash.  This does raise the
spectre of a big brother system where there is some way to identify
people with 100% certainty.  Obviously this could be abused.
My feeling is that there is a rather fine line we could walk in which
this potentially-oppressive technology exists, but in which it is
wielded in a way which enhances privacy and gives people the maximum
degree of control over information about themselves.  By analogy,
think of a surgeon using a scalpel.  This is a tool which is capable
of terrible damage, and it is only by using it with the utmost skill
that it brings about great benefits.  Shunning knives altogether would
be as bad as allowing everyone to hack and slash indiscriminantly.
In a similar way, authentication technology is IMO a necessary
enabling step for uses of cryptography which will enhance privacy.
Off-line cash is one example.  We have to protect the interests of all
parties involved in a transaction or else it will not occur
(voluntarily).  A bank will not want to give out ecash tokens for
which it is liable unless it is confident that it has some recourse in
the case of fraud (such as double-spending).  If users have to
identify themselves to the bank in an utterly non-private way, that is
only so that they can then spend the money in perfect privacy.  The
authentication that exists at the withdrawal step is wiped out by the
blinding of the cash that is done before it is spent.  It is a matter
of balance.
Without the authentication, you're not going to have off-line cash,
IMO.  You will be stuck with on-line systems in which everyone has to
verify everything before accepting it.  This means you pay a cost in
communications overhead and possibly other foregone opportunities.
Another example would be digital credentials.  These can be thought of
as digital tokens, somewhat like cash tokens, which have specific,
published meanings.  One might mean, "salary > $40K".  Another,
"age > 18 years".  Like ecash, they can be issued and then re-blinded
so they are not recognizable.  Here we do not have the double-spending
problem, but there is still a need for authentication.  In order for
these credentials to be trusted, the organizations which issue them
will have to validate your eligibility.  You'll have to show birth
certificates, pay stubs, and all of the other kinds of paraphernalia
you do today.  The thought of this may grate in the minds of those
seeking the freedom of digital anonymity.  But, again, once this
authenticating step is completed, you gain the advantages of a system
where you could potentially borrow money, rent cars, and do other
things which all involve authentication today, in complete privacy.
You authenticate yourself once, and from then on the system works for
So, my vision of the ideal future is neither a database society, where
everything is recorded and tracked and privacy is protected only by a
flimsy shield of laws that are widely flouted, nor a digital anarchy
where identity is meaningless and trust among transitory pseudonyms is
virtually impossible.  Rather, I see a foundation of careful,
nit-picking authentication upon which is built an elaborate structure
of information flows fully under the control of the individuals
involved.  By adding the option for authentication to the mix, you
actually expand the opportunities offered by digital privacy technology.
Hal Finney

@_date: 1994-08-26 07:49:55
@_author: Hal 
@_subject: You can hide from the Chip, but not from the Man. 
I am confused by the word "thus".  None of the three things in the CPF
mentioned in the previous sentence (where to find the LEAF, the LCM,
the KF (BTW, I thought the family key was a big secret?)) include the
manufacturer or the data protocols in any apparent way.  Are there more things
in the CPF than the three you listed?
Also, isn't it likely that RCELP will be widely used by all manufacturers
to be compatible with AT&T, so in practice all will use the same protocol,
and so this does not really identify the manufacturer?
As for recognizing bogus LEAF's, this would be only after decrypting with
the family key, right?  This is not supposed to be done routinely, although
it doesn't require access to the escrow database.  It's true that if a
family-key-decrypted LEAF using Blaze's rogue technique "stands out", that
certainly could call unwelcome attention to the users of his ideas.

@_date: 1994-08-26 07:55:48
@_author: Hal 
@_subject: Program to circumvent the Sep 1 Legal Kludge part 1/5 
I've been receiving these, too.  It seems to be a program which has the
same effect as a one-line shell script to add the "+legal_kludge" option
to the command line for PGP2.6, so that it generates backwards-compatible
messages without violating anyone's license agreements.  It's easy to
do such a shell script in Unix.  Is there a good way in DOS to add a few
command-line arguments in front of the ones the user has supplied?  If
so that would seem easier (and smaller) to distribute.

@_date: 1994-08-26 13:26:46
@_author: Hal 
@_subject: Cash, cheaters, and anonymity 
I don't have time to write much now, but lots of good points have been
made.  I'll just toss out the other main idea for handling offline cash,
which is Chaum's "Observer".  The Observer is a tamper-proof device that
sits inside (or plugs into) your computer, smart card, or PDA, and makes
sure that you don't double spend.  In fact, it is impossible to double
spend because the Observer has to participate in every transaction.  Yet
Chaum has designed the protocols such that the Observer learns nothing
about who you are or where you are spending.
The technical requirements of the Observer in Brands' scheme are that it
store 146 bytes plus 18 bytes per coin, and be able to do the discrete
log signature, which basically requires 512-bit multi-precision
arithmetic.  And it has to be tamper-proof.  At one time I was skeptical
about that but we see with Clipper that the NSA appears to be confident
that data can be protected in tamper-proof modules.
With Observers you can have off-line cash that is as secure as on-line
but without the costs of on-line validation.  As a vendor, which would
you rather accept: off-line cash where you rely on legal sanctions to
track down cheaters; on-line cash where you call the bank and verify it
for every transaction; or off-line cash where you can validate it right
there locally without checking with any bank?  Depending on the costs
which the Observer adds to the digital wallet, that latter choice might
be the most attractive.

@_date: 1994-08-26 22:07:54
@_author: Hal 
@_subject: MATH: Brands cash, Hal's posts 
Karl Barrus  writes a very nice set
of examples of some of the discrete-log protocols using actual numbers.
I did leave one thing out:
This works, but it will be more efficient to take r mod the order of g,
which would be n-1 in this case.  The same thing applies to all of the other places where we multiply and add exponents.
This should still be true with r = cx+w mod (n-1).
I departed from the nice step-by-step description for the actual cash
protocols because they are so complicated and I wanted to explain it as
I went.  If Karl gets far enough to try doing that it would probably be
worthwhile to rewrite that portion first.

@_date: 1994-08-27 09:09:53
@_author: Hal 
@_subject: FCC Regulation (fwd) 
It fooled me for the first few paragraphs, too.  It's traditional in these
spoofs to have some "tipoff", a strange date or name, at the top, but I
didn't notice anything like that.  I think it's a bit unethical to send
this kind of thing out; someone who just skimmed the first part may come
away with entirely the wrong impression.
(It was an entertaining spoof, no question, I just wish they had taken a
little more care to avoid misleading people.)

@_date: 1994-08-27 10:07:16
@_author: Hal 
@_subject: Cash, cheaters, and anonymity 
Tim has made a lot of good points, and I'll only try to respond to a few:
In Demolition Man, Wesley Snipes plucks the eyeball out of the victim to
hold it up to the retinal scanner and escape.  Hacked-off thumbs may provide
similar workarounds for fingerprint protection.  Maybe what we want is
a system where some pass code is an alternative to physical ID.  Giving up
a secret pass phrase is a superior alternative to giving up your life, and
worth it for a few hundred dollars.  (I'll point out that this doesn't work
if duress codes are widely used which give away the bad guys.)
I think this is where the tamper-proof wallet idea comes from; it is the closest anyone has come to providing truly conserved digital cash.  With
such a system you can get the benefits of on-line clearing even in the off-
line environment, just as people will accept cash today without taking it
to the bank first.
I think this is the key point.  All of our speculation about the relative
advantages of the various forms of cash is largely irrelevant, as long as some
form of privacy-protecting payments comes into existance.  Then the details
of the implementations will determine the relative costs and the market
advantages of each approach.  The hard part will be getting that first cash
system in place.
Oops, I've got to go.  I'll just make a quick couple of points.
Dollar bills got their start this way.  At one time they were just "claims"
on the real dollars in the bank vaults.  Yet most people find it more con-
venient to think of them as money, even back when you could still turn them
in for gold.  I think it's useful to think of ecash as being money as well,
although granted it is money with its own characteristics different in some
ways from banknotes, checks, or coins.
One thing I think is clear is that off-line cash will not be issued to
anonymous recipients.  Imagine a magic quarter which would reappear in
your pocket after you put it into the coke machine.  How many people would
be willing to resist using it?  That's what you'll have with an off-line
coin issued to a pseudonym.
This is probably right, although ironically the infrastructure for off-line
cash might be simpler.  On-line cash needs 24-hour availability, quick
(nearly instantaneous) response, a fully automated cash validation system.
We have this now, with the Visa cards, but it didn't appear overnight.  And
I doubt that the Internet is a suitable communications medium for it (due
to reasons of availability, reliability, and security).  Off-line cash could
be handled with longer turnaraounds in a machine which is not on the net,
using manual intervention so pass words and such are not stored on-line.
Of course the disadvantage is that the off-line cash requires identity
authorization during issuing.
Tim's ideas about escrow agents and a credential-less society are very
interesting as well and I'll try to make some comments on them later.

@_date: 1994-08-28 12:27:26
@_author: Hal 
@_subject: In Search of Genuine DigiCash 
"Fully identified cash" is not widely discussed in the literature because
it is (relatively) trivial, and here because it is not privacy
protecting.  "Fully identified cash" is equivalent to a check made out to
"cash".  All you need is a signed directive to your bank to transfer
money from your account number such-and-such to the bearer.
Such "cash" can be used on-line if the receiver sends it to the bank
right away and gets confirmation that the money has been transferred from
your account (that there were sufficient funds to cover the check, etc.).
It can be used off-line if the receiver checks your ID so that he knows
if the check bounces he can sue you or press charges.
See?  You already have all the technical requirements for your fully
identified cash by firing up PGP or RIPEM.  Just find a bank which will
honor your signed messages.  The CommerceNet people implied that such
payment options might be forthcoming.

@_date: 1994-08-28 12:58:49
@_author: Hal 
@_subject: e$: e-cash underwriting 
It was nice to finally meet Eric and other CP's at the Crypto conference.
To me, double-spending is analogous to passing bad checks.  I don't think
people will be satisfied to simply view it as a formal property, any more
than they are in the case of checks.  In either case you are getting an
explicit or implicit assurance from the payor that the instrument is
good.  Intentionally cheating would be viewed as fraud.  I think this
approach would increase the likelihood of digital cash being accepted.
That's a big "if".  I don't follow the proposed solution below.
In any case, discussions about the role of identity are purely
speculative.  I think what we want is a system where people are free to
use these technologies as they wish.  If one bank offers certain
advantages to people who are willing to authenticate their identity (as I
think some will), that is fine.  If a person chooses not to take
advantage of those opportunities because he doesn't want to divulge his
identity, that is fine, too.  The real question is the degree to which
adding identity authentication increases the likely range of situations
that can be covered in a privacy-protecting way, and the degree to which
it may lower costs.
The problem is, the fraud doesn't occur (typically) when the note is
redeemed at the bank, it occurs when the note is exchanged at the
market.  Is this proposing to charge the merchant when he in good faith
turns in the cash which was given to him by the customer, and it turns
out bad?  What cruel irony!  Here he is already cheated once, and the
bank will charge him an extra fee as additional punishment?
I must be misunderstanding.  This seems not to deter double-spenders at
Here I am lost completely.  Whose identity is in escrow?  The person to
whom the coin is given in the first place?  But I thought we were
referring to a double-spending protocol in which users revealed their
identity to the bank.  Apparently not?  Is the idea here that the bank
doesn't know the user's identity, but some other escrow holder does, and
it gets revealed only if the user double-spends 10 times?  But that would
still be identity-based, just with different rules about when it gets
exposed.  I really don't follow this at all.
To me, there is no problem with revealing identity in certain situations
as long as it is unlinkable to my other activities..  And I will be much
more willing to lend credit or other forms of trust to pseudonyms if I
know that they are willing to pay the ultimate price of punishment to
their own very physical bodies if they cheat me.  What more assurance
could I want?  And yet, as long as all parties are honest, we have no
fear of our identities being revealed against our will.
This is no more a contradiction than is the existance of one-way functions.
Both are manifestations of control over information flow.  If this
control is possible, why not make use of it?

@_date: 1994-08-29 12:01:13
@_author: Hal 
@_subject: Problems with anonymous escrow 1 
There has been some discussion here about how anonymity/pseudonymity
can be applied to a wider range of relationships.  One possibility
that Tim May and others have mentioned is to have escrow agents be
anonymous.  (I will use "anonymous" and "pseudonymous" more or less
interchangeably because the former term is more familiar.  But I am
really referring to a case where the agents maintain a certain amount
of continuity via secret keys and such.)
(Let me make it clear that I am not arguing that there SHOULD NOT be
anonymous escrow agents.  I am questioning whether they are likely to
be viable entities due to the problems I am listing here.)
The obvious problem I see with anonymous escrow agents is that it is
much harder for them to become and stay trustworthy.  With an
identified (non-anonymous) agency, you can have a lot of information
on which to base your judgement.  You can look at its assets, at its
employees and hiring procedures, at its record.  You look at the
jurisdiction in which it operates and judge what protection the legal
system may offer.  You can look at other agencies in that jurisdiction
and what their track record has been.
I would guess that most of that information would not be available
from an anonymous escrow agent, not in a validated form.
Perhaps some of it could be done with credentials (a blinded statement
from a reputable accounting firm that (this?) escrow agency has assets
of $X).  But generally thinking I think it will be very difficult to
get nearly as much high-quality information about an anonymous escrow
This leaves the possibility of using its public record to judge
trustworthiness.  It may be able to offer certified statements (again,
credentials of a sort) from earlier customers to show that it behaved
honestly.  Tim has suggested "pinging" such businesses, performing
various dummy transactions to make sure that they are still behaving
honestly.  All this can help establish a record, but how well can this
be extrapolated into the future?
One of the problems with anonymity which has no underlying identity
certification is that you are pretty much forced to adopt the stance
that "the key is the identity."  Your only channel of communication
with the agent is via its key, and any message signed with that key
has to be assumed to be coming from the agent.  There is nothing else.
The problem with this is that keys are not people.  People, and
businesses, have a certain continuity, a certain predictability.  Keys
do not.  A key may change its personality, literally overnight, and
you will not have any warning about this.  In an identified business,
if it changes hands, acquires new management, or has some other change
which might lead to new behavior, you generally have some warning
(especially if it is a business which is selling trustworthiness, in
which case it will probably provide customers with an unusual degree
of access to the business's internals.)  But with an anonymous
business this is not the case.  An escrow agent who has been as steady
as the sunrise for years may, without any warning, become totally
dishonest.  Hidden behind the shield of anonymity there is no way for
its customers to discover the change.
What are the motivations for an anonymous escrow agency to stay in
business, to not take the money and run?  Legal sanctions would
presumably be ineffective.  One proposal is that as long as the
expected future stream of income is worth more than the current value
of all contracts being held by the agent, it is worthwhile for it to
be honest.
There are a couple of problems with applying this.  First, it is
necessary to know about how many contracts the agent is holding at one
time.  But this will be complicated by the possible desire on the part
of many customers to keep their activities secret (even beyond their
presumed shield of anonymity).  So there must always be the worry that
more contracts are in progress than you suspect.  This is especially
true when you consider the possibility that other agencies may
secretly be owned by this one.
But more importantly, judging whether a future income stream is worth
more than a present sum depends on knowing the escrow agent's personal
time preferences.  Some people like to have their money now, some are
willing to postpone present gratification in favor of future income.
Neither position is inherently right or wrong, but obviously a
customer would feel more comfortable with an agent which favored
future income.  And the fact that an agent has been in business a long
time suggests that this is indeed its view - if the agent is stable.
But combine this with the ease with which a key can change its
personality without warning and it suggests that even a long track
record of stability could be fragile.  The business is passed from
father to son, it is acquired, it is coerced away, the owner
experiences a change of circumstances due to illness or other
catastrophe, and suddenly the agency has changed.  Now, future income
doesn't look so attractive compared to present money.  Now, the owners
have an incentive to close the business and (I firmly think the word
applies) cheat their customers.
Again, with an identity-based business these kinds of changes will be
monitored closely by customers.  And after a change like this the
customers will be nervous and may go through a period where they don't
fully trust the changed company.  But with an anonymous agent there is
no way of knowing when these things happen, and this uncertainty will
constantly threaten the safety of the customers.

@_date: 1994-08-29 12:02:31
@_author: Hal 
@_subject: Problems with anonymous escrow 2 
Besides the question of trustworthiness, another problem I see with
anonymous escrow agents applies more generally to any form of
anonymous business.  Anonymity makes sense to me for the individual.
Each person manages his own affairs and he can keep secret or reveal
what he wants.  But at the business level it is going to be much
harder to keep the same level of secrecy.  It is hard for me to see
how a business larger than two or three people can really expect to
operate with the kind of anonymity we are talking about here.
These escrow agents will need significant assets to be useful, and
probably staffs of at least dozens or hundreds of actuaries and other
professionals who will judge the safety and appropriateness of the
various deals the agency is offered.  How can you expect to keep the
location and true identities of the business principals secret?  It is
said that no more than three people can keep a secret; can we really
expect a staff of hundreds not to reveal that they actually work for
the mysterious XYZ escrow agency, accessible only through Blacknet?
Even with the Mafia, everyone knows who works there (judging from the
newspapers).  Can we really expect more secrecy for these anonymous
I think that it is really impossible for a business of any significant
size to be anonymous in the same way that an individual can.  The idea
of an escrow agency that retains its anonymity seems impractical to

@_date: 1994-08-29 12:04:03
@_author: Hal 
@_subject: Problems with anonymous escrow 3 
(Note - I originally wrote this and my other two postings on this
topic as one big message.  So when I refer to "above" here I really
mean my posting on "Problems with anonymous escrow 1".)
Another argument sometimes advanced in favor of trustworthy escrow
agents is the "iterated prisoner's dilemma".  This refers to Axelrod's
simulations of computer program agents which repeatedly interacted in
a simple "prisoner's dilemma" game which captures much of the essence
of the trust relationship (see his book "The Evolution of Cooperation").
His results generally have consistently shown that agents which are
never the first to "cheat" in a relationship do better than those
which try to take advantage of their counterparts.  The main
requirement for Axelrod's results to hold true is that there be a
history of interaction, so that agents recognize when they have
interacted before (and implicitly expect that they will interact
again).  It has been argued that interacting pseudonymous entities
satisfy the basic requirements for Axelrod's analysis because their
pseudonyms have continuity over time, and people can use past history
as a basis for future predictions (as in the escrow agency example).
There are some significant differences, though, between Axelrod's
scenario and the anonymous agents we are talking about.  One is the
issue of pseudonym continuity.  Although it is true that pseudonyms
can have continuity, they are not forced to, unlike in Axelrod's
experiments.  One of the main reasons why cheating is a bad idea in
Axelrod's runs is that the cheating is punished in future
interactions (generally, by being cheated on in return).  But of
course in real life situations, cheaters don't hang around to receive
their punishment.  Implicit in the escrow cheating scenario above was
that the agent vanishes.  He isn't forced to stay in business to be
cheated repeatedly by customers until they get even.  He is able to
opt out of the system.  Axelrod's programs don't have that option.
Worse, a pseudonymous cheater has other options which allow him to
continue to benefit from interactions with others while cheating.  He
can use multiple identities to, in effect, wipe the slate clean when
he has cheated.  This plays havoc with the crucial assumption in
applying Axelrod's results of a history.  With multiple pseudonyms
there is no way to know that good-guy pseudonym A is connected with
the nefarious pseudonym B.  In effect, a pseudonym can cheat and not
carry over the record of that cheating into future interactions.
(I know, as I said above, that cheating does have a cost in the form
of lost reputation.  But the costs are not applied in the form they
were in Axelrod's contest, where the results of a bad action are
carried forward more or less forever.  This is a reason why his
results are not applicable to this situation.)
Another difference between real life and Axelrod's situations is the
possibility of bankruptcy, which may result in the death of a
pseudonym.  Axelrod's tournaments were predicated on the implicit
assumption of an indefinite number of interactions.  (This is my
recollection; I'd be interested in whether experiments have been tried
with a known fixed number of interactions, and the agents knowing how
many more there were.)  It had long been recognized (pre-Axelrod) that
the prisoner's dilemma might reach a stable cooperative solution with
multiple interactions, but that this becomes unstable if the parties
know that they are reaching the end of their interaction period.  In
particular, on the last interaction, it is hard to avoid cheating
since one knows that the other player will have no opportunity to
apply punishment.  But then, if it is a foregone conclusion that the
last round will result in cheating, then it is hard to justify not
cheating on the next-to-last round, since the results of the last
round are foreordained and hence don't really provide feedback for
what is done this time.  This leads to a disastrous regress in which
one finds that the stable cooperative solution collapses into a string
of cheating interactions.
Although in real life it will not frequently happen that both parties
know that a particular interaction is the last, it may be that one
party will know.  If a business has suffered reversals and is doing
poorly, it may know that time is running out.  In that case it will be
more likely to cheat and quit while it is ahead of the game.  (This is
a variation on the argument I made above where the escrow agent
changes its policies due to bad circumstances.)  The problem is that
business is, to a certain extent, a random walk.  Most years you make
money, but sometimes there is a run of bad luck and you lose.  If you
ever get down to negative assets, you are basically out of the game.
But in a random walk like this you can show that eventually you will
visit every point on the line, which means that eventually every
business will fail.  This is no great surprise, of course, but it does
represent another way in which Axelrod's results, which presuppose an
indefinitely continued series of interactions, fail to model the
situation we are discussing.
Based on these comments, it would be interesting to consider a
variation of Axelrod's game, one modelled more on what we feel are the
properties of a system of interacting pseudonyms.  We might include
the possiblity for competing programs to "quit" by retiring old
pseudonyms and to create new ones.  We might also simulate bankruptcy
by having a rule that if the cumulative score of an agent ever became
negative, it was out of the game.  It would be interesting to see
whether these changed rules again promoted the development of "nice"
strategies or whether they tipped the balance in favor of cheating.
This might actually be a doable project for an interested programmer.
It would be interesting to see whether others agree that it could shed
light on the problem.

@_date: 1994-08-29 18:05:28
@_author: Hal 
@_subject: Cyberspatial governments? 
I have been very impressed with the imagination and depth of Jason
Solinsky's ideas, especially considering his apparent youth.  However, I
want to take issue (not semantically this time!) with the idea of a
government in cyberspace, which IMO Jason tends to rely on too heavily.
As I understand Jason's proposal, his government does not rely on force,
but rather it acquires authority by people voluntarily putting themselves
at the mercy of the government to a certain extent.  The principal
mechanism I have seen suggested is for people to put some money into
escrow or a bond which they will surrender (according to agreed-upon
rules) if they break the laws of the government.
Now the simple objection I offer is that most people don't have enough
cash lying around to effectively obligate themselves.  Most people,
unfortunately, spend their money rather than saving it.  Even people who
do have large sums of cash are, for that very reason, able to tolerate
larger losses, so they will apparently have to put up very large bonds,
which would have to be a strain on their liquid capital as well.
And, for people who do have the money, how can they tolerate tying up a
large sum of cash for such a long period of time?  Does the government
offer interest?  How are the funds invested - safe or risky?  Low
returns or high?  People want to diversify their investments, and I
don't think they are going to be willing to put all their cash into
this one lump sum bond.
When people do save money, it is often with the intention of spending
it later.  They save money to put their kids through college, or for
retirement.  Sooner or later their comes a time when they have to start
consuming the nest egg.  Will this entail withdrawal from the benefits
of the cyberspace government?
To sum up, I don't think most people's lives are structured in such a way
that they can credibly obligate and commit themselves to a potentially
risky contract.  With physical governments people might say "as long as I
live on this island I agree that the government can shoot me if I kill
someone," and I will be inclined to believe that they will not try to
commit murder.  But that promise is much less credible if all they will
do is forfeit a $2,000 bond, if that's all the money they've managed to

@_date: 1994-08-31 14:17:35
@_author: Hal 
@_subject: Force is not physical 
One question I have been thinking about based on the recent discussions
with Tim May, Eric Hughes, Jason Solinsky, and others, is whether it
makes sense to say that nothing done in cyberspace should be considered
to be punishable by force.  This leads to the position that double
spending is OK if you can get away with it (but we set up the system so
you can't get away with it).  It also suggests that contracts as such
cannot really be binding (in the usual sense) since they are just words
and people can repudiate them freely.  Nobody puts a gun to your head
and forces you to believe someone else's promise to pay you for work
you do and deliver.  If he wants to say, "tough luck, ha ha," then
there's nothing much you can do about it other than try to be more
careful next time (and let other people know who screwed you).
I think this position is consistent and interesting, but it does seem
like it may be inefficient compared to a system in which people can
authorize the use of physical force applied against themselves under
agreed-upon circumstances.  It also seems like historically people have
not used non-binding contracts as much as binding ones, and I wonder
whether this suggests that non-binding contracts are less useful.

@_date: 1994-12-01 08:27:12
@_author: Hal 
@_subject: Brands excluded from digicash beta 
Last month I complained that my multiple attempts to request an account
to try out the digicash beta-test ecash system had been ignored.  I got
half a dozen replies from people who had had exactly the same
experience.  Shortly afterwards, though, I got email from digicash
saying that my account would be activated in a few days.  This was on
Oct. 21, and I have heard nothing since then.
I just figured that I didn't have enough clout for them to bother to
respond to me, but today on the www-buyinfo list, Stefan Brands, who
many think has the best ecash technology available today, posted that he
had had the same experience!  Brands himself has still not been given
an opportunity to join the beta test.  He did not sound very happy about
I can see that Chaum and Brands are potential competitors to an extent;
they both have or will soon have patents which will be necessary for
efficient offline systems.  But it is clear to me that some form of cross
licensing is going to be necessary to have a really clear patent situation.
Under the circumstances it seems silly for Chaum to antagonize such an
important player in the game.
Of course, it may well be a matter of incompetence rather than insult,
but the net result is the same.  The more I see of digicash's lack of
consideration towards their potential customers and important figures like
Brands the more I question whether they have the potential to succeed.

@_date: 1994-12-01 09:01:17
@_author: Hal 
@_subject: FWD: Oceania WWW site announcement 
We have had some discussion on the topic of new countries here so I
thought I would forward this short note.  I haven't looked at the web
page yet.  Apologies if you've seen it already.
========== Forwarded message ==========
SENDER: Eric Klien A new web site has opened containing files related to the new country
in development, Oceania.  You may get the Constitution and Laws, plus
information on related books such as The Atlantis Papers and The
Millennial Project.  You may also view true color pictures of Oceania
plus view back issues of the Oceania Oracle.  Animations of Oceania
are also online as well as information on how to receive an Oceania
The web is located at

@_date: 1994-12-01 14:51:07
@_author: Hal 
@_subject: Is it happening already ? 
Here is my key.  I just sent it to the keyservers.  I hadn't had a
chance to sign it with my secure key yet.
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: 2.6
-----END PGP PUBLIC KEY BLOCK-----

@_date: 1994-12-01 22:09:09
@_author: Hal 
@_subject: Scalability of Ecash System / Article on Internet Cash available. 
One thing that could be done with the on-line ecash system would be to
decentralize the task of detecting double-spending.  DigiCash could set
up a large number of coin validation centers on the net, dispersed
geographically to equalize the load.  Then the merchants would do a
simple hash algorithm on the electronic coin to determine which
validation center to use.  That center only records spent coins which
have the specified hash.  Since any attempt to double-spend would mean
re-use of a particular coin, both instances would hash to the same
validation center and so the re-use would be detected.
This way if a validation center went down it would hamper but not stop
electronic commerce.  Other coins could perhaps be offered in payment in
place of those which cannot be validated (although this would require a
certain amount of trust of the shop, but perhaps not much more than is
necessary already).
This might address some of the scalability concerns raised with the
on-line cash system.
Another idea comes from the NetCash people.  Here you have the customer
get a payment token from the bank which is made out to the specific
merchant desired and given a time-stamp, perhaps good for one day.  Now
the merchant can accept these, check the signature, and check its own
database of tokens which it has received earlier that day.  As long as
the incoming token is not in the database, the merchant can accept the
payment with confidence and turn the tokens in to the bank for credit
later as in an off-line system.  Effectively these tokens would be
digital cashier's checks.
The big problem with this is the difficulty of the customer getting his
payment token anonymously.  If the bank knows the customer who is asking
for a particular "cashier's check" to be cut then it learns the
customer's spending patterns, defeating his privacy.  So there would have
to be some communication infrastructure to allow for anonymous
connections in order for this system to work.  Chaum, as it happens, has
written on this topic as well, with his "Mix" and "DC-Net" systems for
anonymous communications.  Unfortunately, these systems have scaling
problems of their own and don't appear to be entirely satisfactory for
this purpose.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-12-02 14:27:40
@_author: Hal 
@_subject: First Virtual? 
Allow me then to repost this, a summary of how some available payment
systems work.  It is oriented towards remailers but has info and pointers
to several payment systems.
- From owner-cypherpunks at toad.com  Sat Oct 29 09:35:38 1994
X-To: cypherpunks at toad.com
This is an edited version of a posting I made to remailer-operators at c2.org,
discussing how some of the various payment systems which have recently
been introduced on the net might be used to support a for-pay remailer.
First I discussed some motivation, such as improving the quality of
service and discouraging spam attacks, then this was the part about the
various services.  If anyone knows of other alternatives please let me
I know of two systems that are VISA/Mastercard based.  One is called
First Virtual (  They are oriented towards information
sales and say that they aren't for service providers, but in practice it
looked to me like they could be used for services.  When a customer
wants to pay, he sends you his FV ID.  You send this to FV and they send
an email message to the customer asking whether he authorizes the
payment.  If he says "yes", FV credits your account.  You get a check
every month.  Customers who always say "no" get booted out of the system
(as do merchants who submit bogus bills).  They charge 29 cents plus 2
percent per transaction, but merchants can batch up multiple orders by a
single customer before sending it in.
There are a few problems with a system like this, many of which are
somewhat generic to our situation.  The most fundamental is that we
don't know who our customers are much of the time.  In fact, the whole
point of the remailer network is that we not know that fact for any case
except the first hop in the chain.  If we required customers to expose
their FV account ID at every hop, it would make it a lot easier to track
messages through the network (even if the ID's were hidden in the
encryption envelope it seems risky).  If we then sent a message to FV
saying that we needed to charge ID XXX, and FV responds with an email to
the person's home address, this offers more possibilities for tracing.
One solution would be only to charge on entry into the remailer net.
Perhaps remailer operators would even charge each other then, and the first
remailer would charge some larger amount to deal with a "typical" chain
length?  Many interesting possibilities here.
Another issue is that the overhead charges by FV would require batching
up messages before submitting them.  Let me make clear that the batch
must consist all of charges to a single user.  It doesn't do any good to
send one message to FV asking them to please charge a penny to each of
100 VISA accounts.  No, you would have to count messages from each user,
separately, and when user XXX had sent, say, $1 worth of messages, you
could send in the request to FV and get back 70 or so cents.
So this adds some overhead and record-keeping that we don't currently
have to do, although perhaps it is not so difficult.  But it would raise
new questions of authenticating FV ID's, and shares some of the negative
privacy impacts and message linking issues mentioned above.
The other VISA based system is called OpenMarket. I just read about it
tonight so I don't know it as well (  It is
pretty tied to the WWW so it would not seem to work for us.  Customers
get connected to a particular WWW server which authenticates them and
charges their VISA card appropriately, then they get redirected to the
merchant with some kind of token that says they have paid.
The NetBank (email to netbank-intro at agents.com) is a digital-cash like
system.  Customers get tokens which are basically large secret numbers
which have a cash value.  They send them to the merchants, and the
merchants then send them to the bank which credits their account.  The
NetBank sends you a check every month.
The interesting thing is how customers buy the cash tokens.  One way is
by connecting to a 900 number with your modem.  They charge the customer
$10.00 and give him a digital cash token worth that much.  Another way is
by faxing a check to them.  I wasn't clear on how you get the cash token
back in that case; I guess they email it to you at an address you
specify.  From the privacy point of view, these are not that great; 900
numbers have Automatic Number Identification so unless you are willing to
tramp out to a pay phone to get your cash then it could be linked to your
phone number.  And the fax system must have some kind of return address
that would link to you.
The other problem with NetBank is that the smallest denomination which
can be spent is 25 cents.  Due to the cash-like nature of the tokens, I
don't see a natural way to accumulate several messages into one payment.
Maybe we could layer our own low-value digital cash system on top of
NetBank, where users could buy our anonymous cash for 25 cents and get
enough tokens for 25 messages, then we would settle amongst ourselves (or
actually with the anon-mail-token bank).  Actually this might help with
the privacy problems, too.  Anonymous digital cash is heavily patented,
With a cash-like system, each message would include a numeric token in
the header which is the digital cash.  The remailer would strip that out
and send it in for credit.  This is a simple system and could be largely
automatic.  However there are some tricky issues about cheaters re-using
NetBank charges $4 per month, plus, for the 900-number-based cash, 20%
off of face value.
The last system I'll describe is David Chaum's DigiCash
(  Chaum is the inventor of digital cash and
he certainly knows his stuff, plus as I said he has the intellectual
property pretty well sewed up patent-wise.  The DC payment system is
also WWW based at present.  The customer has to be running a special
program on his computer, separate from his web browser.  This program
holds his digital cash, which is similar conceptually to the NetBank
cash but more sophisticated cryptographically.  When he wants to buy
something, the merchant's web server makes a connection to the
customer's DC program, and it transfers the cash to the merchant.
DigiCash says they are planning an email based system but for now their
emphasis is on the WWW.  Right now they are only in beta and not using
real money.  I don't know when they will be real and email based, and I
don't know if they have said what their commission will be.  But when this
comes up it may be the best approach if small-value transactions can be
supported.  DigiCash is fully anonymous in the sense that once a customer
receives the money, it is "blinded" in a special cryptographic way so
that the bank cannot associate it with that customer (and no one else
can, either).  This kind of anonymity fits in very well with our remailer
Well, I know this is a lot of information to work through, but mostly I
want people to be aware of the possibilities.  Most of this stuff is
very, very new, only weeks old, generally.  Probably over the next few
months we will see a lot more options appear.  I am confident that there
will soon be payment systems that would provide the technical basis for
fee based remailing.  I don't expect anyone to get rich by this, but it
might help compensate for the risks we all face, and it might serve to
improve the quality of the remailer network.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-12-04 10:00:24
@_author: Hal 
@_subject: Interoperability, one-use remailer tickets 
[Part about remailers deleted]
This is very exciting!  Could you show some examples of how your code
would be used with Perl?  Some kind of script that could work with MP
numbers or RSA decrypt a file?  It would be very good to have a
prototyping language like Perl with crypto addons.
Try looking for a package called Shade using Archie.  Here is an excerpt
from the doc file:
As for the remailer return address idea, I would suggest looking at
Chaum's 1981 paper from CACM which has a similar concept.  I believe it
was posted here recently.  Instead of using shared secrets he had the
secret key at each hop get embedded in the return address itself.

@_date: 1994-12-05 21:42:32
@_author: Hal 
@_subject: Interoperability, one-use remailer tickets 
Mike Ingle  writes some very nice ideas about
Bill Stewart pointed out some of the problems with one-shot reply
addresses, although he seemed to be analyzing them as features which the
remailers provided against the users's will.  I think Mike's idea was
that this is something which remailer users would like.  Still, Bill's
comments seem valid.  How useful is a single-use reply address?  If you
posted a message to a mailing list or newsgroup only the first person
would get through to you.  You could post a message with a list of
reply addresses but that would open up some traffic analysis problems.
Two people having a conversation fits this model somewhat well, with
each person sending a new reply address that can reach them with each
message.  But even in this case how often is there a strict alternation
of messages?  Perhaps a "one ahead" approach would work, where each
person at all times has either one or two addresses which will get
through to the other side as long as they are in "alternation mode".
Then when one person needs to get a message to the other out of turn,
he uses up his spare address.  Then he gets sent two new addresses in
the reply message since now he has none, and they are back in the
initial state.
As you have seen, this model is very similar to Chaum's 1981 paper except
for where the secret keys come from.  This is not to disparage your ideas
but it's just that as long as we have giants around, we might as well
stand on their shoulders.  Chaum's system was considerably simpler as it
used ordinary PK decryption of the address at each stage, with the header
including a secret key that would encrypt the body to maintain
unlinkability.  As you point out this has a certain kind of vulnerability
to coercion that your scheme is less sensitive to.
Chaum too used a list of message hashes, although his use was to
prevent the reply-replay attack.  I will note that this attack is going
to be pretty difficult to mount on your scheme as it would require
either saving all messages from a suspected target of an anonymous
address, or saving all messages into the remailer network in toto, then
perhaps playing (all of?) them back.  So it is not going to be easy to
set up this chain again.  In addition to your idea of hashes you could
use some time limits to restrict this kind of reply attack.
Yes, this is the kind of coercion that as you point out the Chaum
scheme is vulnerable to.  There we rely on the remailers to not send
two messages to the same one-shot address in order to prevent replay
attacks.  But as long as the remailer key is valid there is the chance
that the remailer could be coerced and forced to decrypt your anonymous
address, allowing it to be traced back to you.
I do think that your scheme is less sensitive to this kind of coercion
because of the difficulty of knowing which message to ask the remailer to
decrypt.  Ironically, your scheme is even stronger than "forward"
messages throught the remailer network.  Those are equally vulnerable to
this kind of coercion.  If a suspect sends a message through the remailer
network, it can be replayed in just the way that we are worried about for
Chaum replies, and the remailers coerced into decrypting it at each step.
We tend not to worry so much about this forward vulnerability as we do
about the reverse one.  Partially this is because our current remailers
don't implement Chaum's scheme, but partially too we sense that an
interesting public pseudonym is a more inviting target than the hopefully
anonymous true name behind it.  I'm not really sure how good an
assumption this is, though.  So I am less inclined to view Chaum's scheme
as broken since the remailer network inherently suffers the same
vulnerabilities.  We hope to develop enough independent remailers that
the coercion issue will not be a major problem.  Tim May has advocated
hardware, tamper-proof circuits to hold the keys so that coercion is
Plus, I think an important part of the picture which is not currently
being implemented is remailer key changes.  This can provide forward
secrecy similar to your scheme.  Once last week's key is gone, there is
no longer any danger of your message ever being traced (as long as you
trust the remailer to truly erase it, just as in your scheme).  This
would be useful both for ordinary remailing and for Chaum-style reply
blocks, which as I say are both vulnerable to the reply-with-coercion
There is one attack on all these schemes which you didn't mention, which is
that the bad guys are the first one to try the return address and coerce
each remailer along the way.  This might be especially dangerous in the
case of your "pigeonhole" described below, where the pigeonhole account
makes for a tempting target for the snoopers, giving them a chance to
intercept the reply message back to you and be the first ones to be using
That is a very nice idea for using DH.  Here is a variant which might use
less bandwidth.  Have each remailer create a lot of DH key halves, values
of hi = g^xi so xi is the secret discrete log of the public DH key half
hi.  All these hi get published.  Now you need to reserve one for
yourself to use in your return ticket, which you do perhaps with an
ordinary remailed message to that remailer as in your first solution.
You create a random y and use hi^y for your secret key for that remailer.
The reply block contains i and g^y which lets the remailer calculate the
same secret.  Then it deletes xi when it gets used so you get the forward
secrecy you desire.  This is not subject to the reply attack you were
worried about because all you told the remailer was i, and xi is gone for
good so they can't re-create the secret.
(Equivalently, have the remailers create lots of public keys and
publicize them, and reserve one in the same way.  Then have the remailer
erase the secret key when it gets used.  This is just another way of
describing the above.)
This is a good idea, although there is a tradeoff between frequent polls
of the pigeonhole, which might allow some traffic analysis particularly
if there is a suspected link between persona and true name, and less
frequent checks, which may cause high priority messages to be delayed.
Yes, well, we do this already with our current remailers.  Many
people have written clients to create these reply blocks, along with
little instructions to the baffled recipient to cut and past the reply
block at the front of the reply message.  Once in a while these even
work, I think.
With your pigeonhole idea you don't need this, you can just have a
Reply-To that points at the pigeonhole, which is one of its biggest
I agree with this.  This also relates to issue of message size
quantization with cryptographically strong padding.  I don't suppose the
RSAREF library could do that...
Yes, this is a good idea.  I first read about this in the 1993 Crypto
conference proceedings, in a paper called "Secret Sharing Made Short" by
Hugo Krawczyk.  You might find the paper useful although it sounds very
similar to what you have in mind already.
Considering all the pros and cons, I am afraid that even the security of
the one-shot return address is probably insufficient, especially when the
simple "post replies to usenet encrypted with this key" is so easy and
safe.  Granted it will be a problem once everybody starts doing that, but
flooding is going to be hard to beat for safety.

@_date: 1994-12-06 10:13:17
@_author: Hal 
@_subject: One-shot remailer replies 
No, I can't think of a fix, although your idea at the bottom might be
workable in some form.
You would want some confirmation that you got the key you requested.  The
broadcasted key list could be updated to show which ones have been
reserved already, marked with a "nonce" (a one-time use secret random
number you sent with your request) to show who reserved them.  In this
case you might not even need to request a specific one, just ask for one
to be assigned to you and then look and see which one you got.  Of course
this assumes a broadcast mechanism but perhaps this is tolerable if there
aren't too many remailers.
You'd have to watch out for attackers who constantly ping the pigeonhole
address and try to see which messages leave the remailer network in a
correlated way.
Yes, that is a good idea.  Many of the existing remailers are also
written in perl (calling PGP for decryption) but not much work has been
done to improve them in this way.  I think there is recognition that the
biggest security improvement would come with message quantizing (and not
passing subject lines through!) and until we have that the rest is
pretty pointless.
I have not looked at the Shade source.  Here is the posting I made to
cypherpunks on Krawczyk's method.  I wasn't very well organized but if
you read through to the end you may be able to get the gist of it:
This is true, but you said you are talking about things that can be done
today, and today Usenet already has a pool of probably a million users.
That is plenty of security.  The problem is if everyone starts using it
for their replies, but that won't be more than a drop in the bucket for a
long time.
This is an interesting idea.  It is sort of like broadcast except you
would be reducing the bandwidth requirements by only sending certain
information to each user.  One way to formalize it would be to say that
you have two datasets, D1 and D2.  These get combined into D12 = f(D1,D2)
for some combinging function f.  Then we ask whether there is a g(D12)
which allows reconstruction of just D1 or D2 in such a way that we can't
tell which one it will get just from knowing f and g.  Plus, g must
output data which is no larger than D1 or D2.
In this strict form I don't think it can be done, because you could
change D1 and see if g(D12) changed.  If it did, then it was getting D1,
and if it didn't, it was getting D2.  However if we let g be a little
bigger then perhaps it wouldn't be so clear.  I don't know...
Again, users may not be willing to live with it since they have an
alternative right now in usenet.

@_date: 1994-12-07 08:45:06
@_author: Hal 
@_subject: Ideal digital cash system? 
(This should be Okamoto & Ohta.)
This paper is not available electronically as far as I know.  The crypto
proceedings can be found in good university libraries.
I believe the Okamoto scheme has the problem that payments by a person
are all linkable.  Basically when you open an account with the bank you
get a "license" number B which you keep for all the time (and which the
bank doesn't know).  But every time you spend you have to send B.  So all
of the payments from a person will use the same B.
True, this doesn't reveal his identity, but it allows a given pseudonym's
spending patterns to be recorded and studied, which may be almost as bad.
Okamoto forgot unlinkability in his laundry list of ideal cash

@_date: 1994-12-09 09:01:02
@_author: Hal 
@_subject: cut & choose 
Schneier's examples are meant to be instructional in nature rather than
practical, showing how it would be done with paper envelopes and such.
The only example he has which is cryptographic is the "off-line" version
where Alice's identity is encoded in the cash in such a way that it is
revealed if she double-spends.  Chaum's off-line protocol also relies on
cut and choose for this (Chaum, Fiat, Naor, Crypto 88).  That is the
major improvement in Brands' scheme, that you don't have to use cut and
choose for his off-line cash system.

@_date: 1994-12-09 15:43:52
@_author: Hal 
@_subject: BofA+Netscape 
Here is a posting I made to www-security a few days ago when Netscape
announced SSL.  It did not get any response.  I see though that they at
least fixed their spelling...
X-To: www-security at ns1.rutgers.edu
I have a few comments on the proposed SSL and Netscape's HTTP-SSL
that uses it.
First, CHALLENGE is consistently mis-spelled CHALLANGE throughout the SSL
Second, 3 cyphers are specified in this version of the document: RC4,
RC2, and DES.  I would like to see 3DES and/or IDEA.  RC4 and RC2 have
not to my knowledge received much public scrutiny, and the 56 bit key
size of DES is of questionable security today.  Of course these would be
for the non-export versions.
Third, it is not clear how practical the use of X.509 certificates will
be.  For example, the "name" field in the certificate must somehow be
checked against the information which the client has about the server.
Typically this will just be a machine address like home.mcom.com or
something similar.  Is X.509 a good fit for this purpose?  I am not too
familiar with X.509 but generally the names that I have seen are not in
this form.
Fourth, it would be nice if there were some support for non-certificate
authentication of the server's public key.  For example, the client may
have obtained that key previously.  I believe SHTTP is more flexible in
this area.
Fifth, I don't really like the idea that the Netscape client
embeds "approved" certificate authority keys.  I suspect that the CA
situation is going to be in flux for quite a long time and one's client
could easily get out of date.  Note that the reliance on CA's seems to
have slowed the acceptance of PEM as a widely used standard.  PGP's
anarchic "web of trust" has perhaps been a better fit to net culture.
Sixth, the use of "https:" as a URL type for secure links provides
for a very strict separation of secure and non-secure connections.
Furthermore, this separation is chosen by the server operator.  I would
like to see a more flexible system, one where the client has more control
over what information is transferred securely.  The server may want to
set a minimum, and refuse to exchange certain information non-securely,
but it should not IMO also set the maximum.  Some clients may be more
privacy conscious than others.  Some may not want information about which
URL's they use to be available to local snoopers.  The Netscape approach
seems to put too much control into the hands of the servers and not
enough into the hands of the clients.
SHTTP also uses a special URL, but it seemed to be more open to the
possibility of a negotiation between client and server for secure
connections even on "http:" URLs.  This would be done by having backwards
compatibility with HTTP in which a non-secure-aware client or server
would ignore or reject the security enhancements.  The transaction could
then proceed in non-secure mode with appropriate information displays to
the user.  SSL does not appear to allow for this kind of compatibility.
Despite the negative tone here I think that SSL is potentially a good
step towards enhanced privacy on the net.  I think though that
eventually encryption will be used far more widely than Netscape seems
to have in mind.  The net is so insecure that I suspect people will
want privacy for all but the most casual uses.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-12-11 15:39:06
@_author: Hal 
@_subject: Storm Brewing Over Forged Bob Rae Posting? 
Ironically, I did not know about this brouhaha until reading about it
here today.  A few days ago I got this email:
This meant nothing to me so I ignored it.  But on reading the article
this appears to be a major incident, involving heated accusations and
walkouts on the floor of the Ontario legislature.  The Portal system,
the internet service provider I use, has apparently taken some heat but
they have not contacted me.
A thread in can.politics titled "The Bob Rae Forgery Caper" includes a
copy of the original message.  Here are some excerpts from the Globe and
Mail article, which was widely cross-posted.
I do not have any logs of this message.  However, my remailer does not
insert any delays so it is conceivable that sendmail logs could give
some insight into message flow through the remailer.  I don't know what
obligation I would be under to cooperate with any investigation.  The
message itself had some pointed political satire but did not look to me
to violate any US laws.  There is not much I can do to help, anyway.
The article indicated that the legislature has now gone into recess for
the year so hopefully this will all be old news by the time they
One thing I do notice on reading the discussion in can.politics is the
fact that despite the disclaimers in the message headers, some people
took this as a forgery attempt on my part.  I wonder if it might be
necessary to insert disclaimers into the body of the message as
anon.penet.fi does, at least for messages to known mail-to-news
There was also a misperception that my remailer was an official effort
endorsed by Portal (again, despite the disclaimers).  Note that it was
they who were contacted, not me (yet).  This might suggest that it will
not be possible to cleanly separate the remailer operators and service
providers when problems like this arise.  Both may end up being hassled
(time will tell whether I am).
It should be interesting to see what happens.

@_date: 1994-12-12 12:40:29
@_author: Hal 
@_subject: Misunderstanding of Remail Headers 
There was some discussion here last week about remailers which don't let
users put in "From:" lines.  This case shows a good reason not to allow
them.  "Reply-To:" should be used to force a reply to some anonymous return
address if you have one.  So perhaps filtering "From:" is a good idea.

@_date: 1994-12-12 14:19:48
@_author: Hal 
@_subject: Clarification of my remarks about Netscape 
What about the certification aspect?  Would servers be forced to pay
for an RSA key certification?  This was a point I raised in my comments
on SSL.  PEM's reliance on the RSA-based certification hierarchy has at
least slowed its progress if not doomed it altogether.
I understand that Netscape clients will embed certain Certification
Authority keys and use them to validate signed server keys.  Does this
also mean that only RSA-approved CA's will be allowed?  What if some CA
in some other country not covered by RSA patents came into operation?
Would your relationships with RSA still allow you to embed non-RSA-
approved CA keys?  I would hope so.  RSA is both respected and mistrusted
in the crypto community, so you wouldn't want to tie yourselves too
closely to them.
Have you heard of the "web of trust" concept implemented by PGP?
This allows users to designate chosen individuals as trusted key signers
and to authenticate keys on that basis.  It is non-hierarchical and
decentralized. (There is also plenty of bad blood between RSA and PGP.)
Will you be able to support decentralized authentication models like this?
I hope this is something you will explore.
(I have no financial interests in any of these companies or protocols!)
Hal Finney

@_date: 1994-12-12 14:30:12
@_author: Hal 
@_subject: Clarification of my remarks about Netscape 
I was going to say that an SSL-aware proxy daemon could play "man in
the middle" and pass through the SSL handshaking messages which occur
at connection time, so that the user client could authenticate the
remote server, then communicate using a key shared with that server but
which the proxy would not know.
But that won't work with SSL, I guess.  The SSL handshaking goes on
before any message data has been exchanged; in particular, before the
URL is sent to the proxy to tell it what server to connect to.  (Hiding
URL's is one of the features of SSL.) So in fact with SSL the only
authentication possible is between proxy and user, and then between
proxy and remote server.  There doesn't seem to be a place in the
protocol where the user could authenticate the remote server and create
a key which would not be known to the proxy.  This does seem to be a

@_date: 1994-12-12 17:57:11
@_author: Hal 
@_subject: Time to exhaustively break 40-bit RC4? 
This is not true, for a few reasons.  First, keys are replicated
(reused over and over) until 256*8=2048 bits have been used.  So
a 40-bit key would get reused about 50 times.  Second, the key
feeds into a PRNG which is mixed in with the swapping, so once you
swap with a different one you will swap differently from then on.
And third (and this is the one I find most interesting), SSL does not
just use a 40-bit key for the export versions.  They use a 128-bit key,
but they require 128-40=88 bits to be sent in the clear.  So the
potential keyspace is much bigger than 2^40.  This will make certain
attacks (primarily those involving pre-calculation, which actually
doesn't apply to your pipeline I guess) impossible.  I thought it was
interesting that this "128 minus 88" bit key qualified for the export
approval.  This suggests that NSA has no better attack than brute force
(nothing relying on cryptographic weaknesses of 40 bit keys, for

@_date: 1994-12-12 23:29:30
@_author: Hal 
@_subject: Clarification of my remarks about Netscape 
It is nice to have a lot of people on the list from Netscape.
Here is a question about SSL relating to the use of certificates:
          + The issuer name must resolve to a name that is deemed
            acceptable by the application using SSL. How the application
            using SSL does this is outside the scope of this memo.
What does Netscape actually do about this?  If I want to make a server
which will interoperate with existing Netscape clients what kind of
certificate do I need, and what kind of name should be in there?
Thanks -
Hal Finney
hfinney at shell.portal.com

@_date: 1994-12-13 09:44:50
@_author: Hal 
@_subject: Authentication vs encryption: CPs on the web 
I notice in these discussions of security on the web that the topic blurs
back and forth between authentication and encryption.  Particularly when
discussing using MIME with security extensions to "secure" a document by
pre-signing it, this form of security does not add privacy.  It does
provide a useful service by allowing you to verify authorship, but my
interests are in using cryptography to protect privacy.  I think it is
useful to keep a clearer distinction between these.
I notice that the people who come to this topic from an institutional
point of view tend to be more interested in the authentication aspects.
This seems to fit better into the control-oriented mindset.  With
authentication you can track what people are doing better; non-repudiable
signatures could actually work in some ways against the signer.  I think
that may be one reason Phil Zimmermann is famous for not signing his
messages. :-)  But encryption can actually work against institutional
interests (compared to individual ones) by making it harder to keep track
of people's activities.
I exchanged email on this with Vint Cerf during the PEM standardization
process.  I objected to the fact that with PEM you could not encrypt a
message unless you signed it.  Now of course you can always fake the
signature if you need to but the principle seemed skewed to me.  Cerf
honestly could not understand why you would ever want to do this.  What
security could there be if the message were not signed, he wondered.
To me the issues are separate.  Encryption is used to make sure the
message is seen by only those for whom it is intended, and signatures are
used to verify the source of the message.  The choice of which of these
two transformations to apply should be up to the users.
I don't speak for other cypherpunks, but my interests with regard to web
security extensions would lie in the following areas.  I want to be able
to use the web and maintain my privacy.  I don't want snoopers on the net
or on my local machine to know which web sites I visit or what material I
download.  (This ties into the electronic cash issue - what use is
"anonymous" cash if everyone can see where I'm spending it and what I'm
buying?)  I also want to be able to hide my identity from the web servers
themselves, at least if this is mutually agreeable.  If a server wants to
accept only authenticated connections where it knows who the users are
that it is serving, fine.  But I want the options to be there.
I want to be able to make payments to access and download information
while protecting my privacy.  I don't want to be put onto mailing lists
or get my name into databases of people who like X without my permission.
This implies a range of payment mechanisms including credit cards,
digital checks, and digital cash.  And it also requires the privacy and
anonymity features above.
I want these features to be a matter of mutual negotiation between
client and server.  The protocols should not build in veto power for
either side over how much privacy the transaction includes (although
either side may choose not to participate if mutually agreeable terms
can't be worked out).  And therefore these features should not be
restricted to just a small fraction of transactions, where we drop into
"secure mode" momentarily so I can send my credit card number.  I want to
be in secure mode all the time.
This is IMO the standard cypherpunks wish list as applied to the WWW.
But it does not seem to match up with either the commercial or
institutional interests which are driving the standards process.  I
hope those CP's who are involved in these efforts can work to spotlight
the need for individual privacy.  We should give as much power, choice,
and control as possible to the individual end-users of the web.
Otherwise privacy is going to be very difficult to maintain in this
world of electronic commerce.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-12-13 12:29:36
@_author: Hal 
@_subject: Authentication vs encryption: CPs on the web 
I don't think this is necessarily the case.  Anonymity is often a matter
of _not_ stamping identification onto a packet.  Rather than complicating
protocols it will often just be a matter of having options not to include
certain fields.  For example, the current HTTP has an option to send a
user name when the client makes connections.  I have heard that the
Netscape client sends this and has no switch to turn it off.  You can put
in a fake name (or none) but then when you want to send email your reply
address is wrong.  This is an example where support for privacy should be
in the client and can't really be added on.
I think this is a fine idea if this could work.  The way proxy support
works now, the client connects to the proxy and then sends it the URL.
This means that the proxy knows which clients are connecting to which web
pages and must be trusted to keep this private.  What you need is a way
of chaining proxies such that no one proxy sees both the client and
server addresses.  This is what we have with the remailers.  But again
this would appear to require changes to the clients and corresponding
Perhaps it would work to have a local trusted proxy running right on your
machine which implements the connection to a chain of web remailers.  You
can run vanilla clients with their nice UI's and other hot features, and
all of your net accesses go through your local proxy which cleans them up
and uses chaining for access.  This sounds like a doable project which
would be worth exploring.

@_date: 1994-12-13 16:48:21
@_author: Hal 
@_subject: Clarification of my remarks about Netscape 
"Amanda Walker"  writes, quoting someone from
This relates to the other part of my question, which didn't get answered:
what is the relationship between the name found in the X.509 certificate
and the server?  Does X.509 include an internet address like mcom.com,
and the Netscape client checks that this matches the address of the
server it is connecting to?  I am not very familiar with the certificate
format but I had the impression that it used a very different naming
Or does the client accept any valid certificate without regard to the
connection if any between the name in the certificate and the server to
which it is connected?  This whole area was left undefined in the SSL
spec but will be important for interoperability.

@_date: 1994-12-13 22:58:42
@_author: Hal 
@_subject: Encrypted Credit Card Numbers For Transmission.... 
It was "cypherpunk"/"cypherpunk", no "s".  But that's OK, it doesn't hurt
to have both.

@_date: 1994-12-14 14:36:53
@_author: Hal 
@_subject: Clarification of my remarks about Netscape 
Thanks, I had overlooked that in the appendix.  I notice you left off the
next paragraph:
          Finally, the CertificateInfo::subject field is checked. This
          check is optional and depends on the level of trust required by
          the application using SSL.
This subject field would hold the distinguished name of the server.  That
is pretty important to check!  Otherwise anybody with any old certificate
will fool you.  In your appendix D when you describe the man in the
middle attack, you say:
          The man in the middle operates by pretending to be the real
          server to the client. With SSL this attack is impossible
          because of the usage of server certificates. During the
          security connection handshake the server is required to provide
          a certificate that is signed by a certificate authority.
          Contained in the certificate is the server's public key as well
          as its name and the name of the certificate issuer. The client
          verifies the certificate by first checking the signature and
          then verifying that the name of the issuer is somebody that the
          client trusts.
This is in accord with your description above.  Note that the only name
check mentioned is the name of the issuer.  But later, in analyzing this
attack, you say:
          If the certificate provided by the
          bad guy is legitimate, but for the bad guy instead of for the
          real server, then the signature will pass but the name check
          will fail
Here you must mean a different name check, the optional one that checks
the subject field.  So this analysis is somewhat inconsistent with the
procedure I quoted just above.  Also, when you describe the subject name
check as "optional" and depending on the required level of trust, perhaps
you should say explicitly that if you don't do it you are vulnerable to a
man in the middle attack.
Actually, the attack is more general than that: if I could intercept
connections to your server and use my own certificate to make the user
think he is securely talking to you then I don't actually have to involve
you at all.  I am not a man in the middle, I am a spoofer pretending to
be you.  And you have marked the important step in the protocol which
would check for this as optional.
It appears from your docs that the Netscape client has a File menu item
that brings up a Document Information dialog box which displays the
distinguished names of the certificate issuer and of the subject (the
owner of the key).  This does provide a way of checking that you are
securely connected to the server that you expect (assuming that the
name is recognizable to the user).  But it sounds like this is not
something which the customer sees automatically.  Again, this seems
like an important security aspect which should be displayed more
BTW, what do you see in the dialog when you connect securely to
mcom.com?  What is the subject name in your certificate?
I hope these comments are helpful to you.  I am surprised that you
published this spec only after distributing implementations of it.  This
wil probably make it hard to change.  Usually it is better to do the
review before implementation rather than afterwards.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-12-14 23:38:27
@_author: Hal 
@_subject: Clarification of my remarks about Netscape 
I downloaded the latest Netscape client and tried the https: links at
the mcom server.  When you switch to secure mode, a large dialog box
appears reminding you to check the Document Information.  But it has a
"don't show again" button and I would imagine that most people would
soon use that.
The Document Information box shows this information:
Encryption Key:  Export [40]
Name of Server:	C=US, ST=California, O=Netscape Communications Corp.,
Name of Certifier: C=US, OU=Test CA, O=Netscape Communications Corp.
It would be nice if the CN field were the same as the server address.
Then the client could check it.

@_date: 1994-12-15 08:08:42
@_author: Hal 
@_subject: Question for remailer operators 
I see about 200 messages a day through my remailer, sizes averaging a
couple of K.  I had the impression at one point that the VAST majority of
this was "cover" traffic that someone is generating just to keep the
network busy.  I don't know if this is still the case.  It might be
possible to opt out of the cover traffic generator to reduce your load
to a politically manageable level.  Maybe people generating cover traffic
could estimate how many messages they are generating.
My remailer is a little unusual as the alumni.caltech.edu remailer always
feeds into this one, so this may represent two remailers' worth of

@_date: 1994-12-16 09:54:24
@_author: Hal 
@_subject: Question for remailer operators 
lcottrell at popmail.ucsd.edu (Lance Cottrell) writes, quoting Hal:
So, if the average interval is 10 minutes, that would be 6 messages per
hour or 6*24 = 144 messages a day.  Each message goes through 6 of
probably a dozen or so remailers or about half of them, so that would be
about 70 messages per remailer per day from your script.  My count above
is of messages through both the alumni and portal remailers, so that
would be about 140 from you out of around 200 or about 70% from your
script.  If you have more or less than a dozen remailers to choose from
that would affect this figure.
I really think this script is overkill at the current time.  Each message
has to be decrypted and dispatched, and this makes the remailer pretty
conspicuous.  I think the script could slow the acceptance of remailers.
In any case, I think I will ask you to take the alumni.caltech and
shell.portal remailers off of your list.

@_date: 1994-12-17 08:43:46
@_author: Hal 
@_subject: Thoughts on 15 day CJ crypto 
It is an interesting idea that the RSA actually helps with the RC4
decryption by letting them check a key guess.
This would suggest, though, that RC4 alone would not be allowed, only RC4
plus RSA.  If they allowed RC4 alone then unlimited-length RSA would not
seem any worse since with RC4 alone you don't get the key-checking
Also, are there restrictions on the encryption exponent?  A 1024 bit RSA
with a small encryption exponent would be faster to check than a 512 bit
RSA with an arbitrary 512 bit encryption exponent.  So if this were the
reason you might think they would put some restrictions on that.

@_date: 1994-12-17 12:58:30
@_author: Hal 
@_subject: Thoughts on 15 day CJ crypto 
That's what I mean.  "Usually" they are, but that helps a snooper to
check his guess.  Maybe it would be wise when using limited-length
session keys to use larger encryption exponents just to confound an
exhaustive search of the session key space.  I think it is surprising
if there is no limitation on encryption exponent size for these
exportable key systems, assuming that is the strategy the government is

@_date: 1994-12-17 13:50:01
@_author: Hal 
@_subject: Time to exhaustively break 40-bit RC4? 
I notice in the Netscape SSL spec the 40-bit export-approved RC4
key generation is a little more complicated than I would have thought.
First a 128 bit "master key" is chosen and 88 bits are revealed, leaving
40 bits secret.  Then the RC4 session key is generated as the MD5 hash of
this master key plus about 32 bytes of publically known but random
information.  I'm not clear whether the 128-bit output of the MD5 hash is
then used as the RC4 key, or whether only 40 bits are used (and if so,
whether there are any public bits in the key besides these 40).
If the former, then this extra hash step should really slow down
exhaustive search of the key space.  If the latter, then it is not clear
why the master key is key-size restricted at all since it is not likely
to be used in searching the key space.  Maybe someone from Netscape could
clear up how this is done.

@_date: 1994-12-19 22:25:03
@_author: Hal 
@_subject: SSL server experiment 
Here is a perl script which connects to a netscape-style "https" server.
The results of running it with "https.pl home1.mcom.com 443" is:
Attempting connection to 198.93.93.10
Sent message, length 40
Received length = 502
Message type = 4
Session ID Hit flag = 0
Certificate type = 1
Server version = 2
Certificate length = 472
Cipher specs length = 3
Conn ID length = 16
Supported ciphers:
        RC4_EXPORT40, 128 bits
This way you can see which of the 5 cipher options (RC4 or RC2 in full
and export versions, plus IDEA) are supported by any given server.  You
always use port 443 and just specify the machine name.  I was a
little surprised that Netscape's own server is only running the 40 bit
version.  I hope the export restrictions will not prevent the use of
full strength ciphers.
Here is the script, which I call https.pl:
# Perl script to test connection to http ssl port
# Usage: https machine port
# Standard internet stuff
$AF_INET = 2;
$SOCK_STREAM = 1;
($name, $aliases, $proto) = getprotobyname('tcp');
$sockaddr = 'S n a4 x8';
# Parse
if ( == 2) {
    ($them, $port) = } else {
    die "Usage: $0 machine port\n";
select (S); $| = 1; select (STDOUT);
socket (S, $AF_INET, $SOCK_STREAM, $proto) || die "socket: $!";
($name, $aliases, $type, $len, $thataddr) = gethostbyname($them);
$that = pack ($sockaddr, $AF_INET, $port, $thataddr);
 = unpack('C4', $thataddr);
$thataddr = join('.', print "Attempting connection to $thataddr\n";
die $! unless connect (S, $that);
print "Connected\n";
$cli_hello = 1;
$vers = 2;
$msg = pack ("C n4", $cli_hello, $vers, 5*3, 0, 16);
$challenge = pack ("d2", rand, rand);	 bytes
$cspecs = pack ("Cn"x5, 1, 128, 2, 128, 3, 128, 4, 128, 5, 128);
$len = 1+8+5*3+0+16 + 32768;
$h = pack("n", $len);
$totmsg = pack("a2 a9 a15 a16", $h, $msg, $cspecs, $challenge);
print S $totmsg;
print "Sent message, length ", $len-32768, "\n";
# Now for the interesting part
read (S, $phd, 2);
($slen) = unpack ("n", $phd);
print "Received length = ", $slen-32768, "\n";
read (S, $pm1, 11);
($smsg, $ssess, $scert, $sver, $sclen, $scspeclen, $scidlen) =
print "Message type = $smsg\n";
print "Session ID Hit flag = $ssess\n";
print "Certificate type = $scert\n";
print "Server version = $sver\n";
print "Certificate length = $sclen\n";
print "Cipher specs length = $scspeclen\n";
print "Conn ID length = $scidlen\n";
if ($sclen) {
read (S, $pspecs, $scspeclen);
$nscspecs = $scspeclen / 3;
 = unpack ("Cn" x $nscspecs, $pspecs);
 = ( "(undefined)", "RC4", "RC4_EXPORT40", "RC2",
print "Supported ciphers:\n";
for ($i=0; $i<$nscspecs; ++$i) {
read (S, $scid, $scidlen);
close S;
exit 0;

@_date: 1994-12-20 13:36:00
@_author: Hal 
@_subject: HTTP redirectors 
I posted some experiments on this a few weeks ago.  Some existing web
proxies, at least the one at CERN, will accept connections from anyone.
Set your proxy server to one of those and you have a bit of anonymity
There is a problem with trying to get much more anonymity than this -
most connections are for a very short period.  So there is not as much
possibility for batching and mixing as with remailers.  Only those
connections which are actually active at the same moment could have their
in/out mapping confused from the perspective of someone watching the
redirector site.  So generally our goals have to be somewhat more limited
than with remailers.
The way proxies work, as I understand it, is that normally when you
connect to, say,  it connects to the
special port number for http at site.org, then sends it the remainder of
the URL, dir/file.html.  When you use a proxy, it always connects to the
proxy machine, then sends the whole URL (possibly not including the
http:, I forget), e.g. site.org/dir/file.html.  This way the proxy knows
where you want to connect and does that for you.
The nice thing about this is that it is already built in to most clients.
The bad thing is that it does not lend itself to chaining.  Ideally, the
purpose of chaining is so that no single link in the chain knows both
ends.  That way no one person can betray your trust.  But with the
current client software the very first proxy server sees both your
address and your destination, so even if it went on to set up a chain you
would have to trust it.
One idea that was suggested here would be to have a local proxy process,
a very simple one which your fancy client connected to for all your net
accesses.  This would be where you would implement encryption, or new
protocols for chaining, etc.  This way we don't have to try to persuade
client writers to incorporate our improvements; the existing proxy
support provides the loophole we need.  One nice feature, for example,
would be a full 128 bit IDEA or RC4 encryption engine so that overseas
Netscape users (or domestic ones who are stuck with crippled versions)
can get good security.
However, running this kind of local proxy or a general chaining proxy
does require root access.  Most systems will not let you create a
low-numbered socket unless you are root.  So this is not something which
people will be able to do from their user accounts.

@_date: 1994-12-20 18:15:58
@_author: Hal 
@_subject: HTTP redirectors 
Yes, I think you are right.  I think you can set your proxy to
site.org:8080 or whatever and clients will use the specified port
number.  This is at least true of lynx, and I think they all use pretty
much the same conventions on this.
So I was mistaken in saying that you would need root privileges to set up
your own proxy.  And I don't see that it would be much of a security
hole in that it would be no more privileged than the user who ran it.
Most security concerns come because httpd is running as a privileged
process, I think.  An http redirector shouldn't be much more trouble than
a remailer, although the user who is running it would want some assurance
that his own files wouldn't be threatened.

@_date: 1994-12-20 18:24:18
@_author: Hal 
@_subject: No privacy with DigiCash 
One of the reasons we want http redirectors is so we could buy things
anonymously.  There is not much point in anonymous digital cash when your
web connections advertise who you are.
But, the current ecash implementation from DigiCash doesn't allow this
to work!  When you buy something, the vendor has to know your machine
name because he wants to connect back to your ecash wallet process.
So even if you did connect via a redirector, your anonymity would be
destroyed (or at least badly hurt) when you tell it your machine
name so it can connect to you.
This is a really bad way of doing it IMO because it seems to defeat
one of the big selling points of DigiCash.  Is there something I am
overlooking, some way to buy things privately with DigiCash?

@_date: 1994-12-20 21:10:59
@_author: Hal 
@_subject: Guerrilla remailers revisited 
I tried out a freenet system once.  You could not create files with
arbitrary contents.  There was a facility for setting up mail forwarding,
but it was all done via a menu-driven system where you specified the
email address to which your mail should be forwarded.  The system really
did not seem to have enough flexibility for procmail.

@_date: 1994-12-21 08:10:40
@_author: Hal 
@_subject: No privacy with DigiCash 
Bill Sommerfeld writes, quoting me:
I read about socks last night, and while it has some nice features I
don't know if it is suitable for a process which you want to have
persist and be able to accept connections on an ongoing basis.  With
socks, the ecash process would tell the socks server to open a listening
socket on its behalf.  Then when a connection comes in from a merchant,
it gets forwarded to the ecash process.
This is the problem: the socks server probably cannot generally get
the same port number as the ecash process.  I don't know if it even
tries.  So you have to note the port number.  Well, you have to do this
already because the ecash process may not get the port number it wants if
somebody else already has it.  But, with socks you only get one incoming
connection and then the socks server closes.  The ecash process would
have to request another listening socket each time it got a connection.
And each of those could have a different port number.  So this would be a
constantly changing bit of information that you would have to keep in
If the ecash process were integrated with the web client, this would not
be so bad, as the new port number could be supplied to the merchant
server automatically.  But with the current implementation this would
have to be done manually.
I was thinking of a socks-like model where you could have persistent
servers running behind a socks firewall.  The socks implementation is
really designed for ftp transfers, where the ftp server has to make a
connection back to the ftp client, and these are pretty transient.  For a
persistent server you would need a more complex structure.  Probably
there should be a persistent connection between your process and the
socks server, separate from a listening socket that your process sets up.
When a new connection comes in to the socks server for your machine, it
does a connection of its own to your listening socket.  Then there could
be multiple connections to your server active at one time.  The
persistent connection would just be a "lifeline" so that if your server
exited then the socks server would know to close down the proxy socket it
holds for you.

@_date: 1994-12-21 08:28:16
@_author: Hal 
@_subject: c'punks top 5 
I was reading about socks last night, and it does seem to be very close
to what is needed for this.  In fact, if you sat down to write a TCP
connection redirector protocol for anonymous connections, socks is
pretty close to what you would come up with.  Socks V5 even has some
encryption specified for it, although it has the deficiency that the
"forwarding" connection address is sent in the clear.
The basis idea of socks is very simple.  A socks server runs on port 1080
on a gateway machine.  If you want to make a connection through the
server, connect to it on port 1080, then send a 1-byte version number, 4,
a 1-byte request code, 1, the 2-byte port number you want to connect to,
the 4-byte IP address you want to connect to, and then a null-terminated
string which is supposed to be your user name (to help the server decide
whether to allow the connection).  It returns an 8-byte response message:
1 byte of version number, 4, 1 byte of result, where 0x5a means success,
2 bytes of outgoing port number and 4 bytes of server IP address.  From
then on, assuming success, it just forwards messages and you can talk
directly to the remote machine.
This lends itself nicely to chaining; simply make a socks request to the
first machine, requesting it to connect to another socks machine; then
send another socks request which will be interpreted by the 2nd machine,
etc.  You could build up chains of any size in this way, even responding
dynamically to failed or refused connections.
In fact, as with the CERN httpd proxy server, where existing
implementations might actually be useful already for laundering web
connections, it is possible that some socks implementations could be used
as well.  If the socks server did not check that requests came from the
local site (as the httpd proxy server sometimes does not), then you could
set your client to make socks connections to such a server and get
anonymous web connections already.
This also would mean that it might be politically easier to run a socks
server than to run an anarchistic http redirector.  Socks is pretty well
understood by security-conscious network people so might appear to be
less of a threat.  Plus, if it does turn out that existing socks servers
are useful for this purpose then this is something we could start using
right away.
Does anybody know of any sites running socks servers?  I would like to
experiment with whether they would accept connections and requests from
remote sites.  Thanks -
P.S.  I found information about socks by searching the Internet Drafts
archive at ISI.  This California server is a mirror of the main one in
Virginia, but is http based so is faster.  Use URL
 select "Locate internet drafts
by file name", and then do a keyword search for socks.  There are 3 of
them, V4, V5, and one about using pem for encryption.

@_date: 1994-12-28 12:04:44
@_author: Hal 
@_subject: Are 2048-bit pgp keys really secure ? 
One thing to keep in mind is that other things can go wrong than
Carmichael-like numbers in finding false primes.  You can get hardware
errors.  Here is my estimate of the chance of an undetected memory parity
Let us suppose that a 8 MB PC uses parity protection per byte and gets
one parity error per year of operation.  This is just a guess but I have
occasionally seen parity errors on PC's and I certainly don't use them
full time 24 hours a day for a year!
So the chance of a particular byte getting a parity error in a particular
one-minute period (approximately the time for a key generation) is 1/(8M
* 365 * 24 * 60) or about 2E-13 (2 times 10 to the minus 13).  The
chances of 2 parity errors, which would then be undetected, would be the
square of this, or about 6E-26.  During key generation let us just look
at the data and say that there are about 256 bytes in the active working
set at any time, so the chance of an error in an important byte is about
So if your chance of the Fermat test failing is much less than about
10^-23 then you would do better to invest in a more expensive PC than in
improving the test.  And of course there are other hardware failure modes
as well, which should increase this threshold.

@_date: 1994-02-01 08:10:34
@_author: Hal 
@_subject: PGP keyid collisions? 
Right, but the point is that you have to search for a prime q anyway;
PGP's algorithm is basically to repeat q += 2 until you find a q which
is prime.  It uses a sieve to speed this up a lot.  I was pointing out
that you can basically change the 2 to a 2^24, still use a sieve, and
find a key just about as fast.  So matching an existing key ID should not
take much if any longer than just generating a PGP key in the first place.
PGP actually uses a 64-bit key ID internally, only displaying the lower
24 bits for conciseness.  It would be practically impossible to get a
64-bit key ID collision by accident (well, almost impossible, anyway).
However, the technique I mentioned could easily generate such collisions.
PGP does check for the case of matching key ID and does something, but I
forget what.  24-bit key ID matches shouldn't have any effect except for,
as Bill says, extracting/deleting keys based on key ID.

@_date: 1994-02-03 23:19:44
@_author: Hal 
@_subject: Running regularly 
Most public Unix systems will not let you do this, in my experience.
The two Unix commands which usually give you the ability to run programs
at regular intervals are "at" and "crontab".  You can read the man pages
and try running these to see if they are enabled for you.
I had an idea for how to get around this, so that people could run batching
remailers which sent out mail, say, every 30 minutes or whatever.  (Unlike
Xenon, I am of a generation which is accustomed to waiting more than a few
seconds for mail to travel across the country!)  The idea was simply for
someone who DID have an account which would let them use at or cron, to
run a program which would simply send a "ding" message (not to be confused
with a "ping" message :) at regular intervals to a list of subscribers.
This message could have a special header field so that the remailer programs
could easily recognize it and take whatever action they wanted, like running
Karl Barrus' script to scan a directory for pending outgoing remailer mail
and send it out.  (Karl has had batching running for months, as well as
postage-stamp-based remailers (albeit with non-anonymous stamps).  He is
way ahead of most of this discussion.)

@_date: 1994-02-03 23:24:53
@_author: Hal 
@_subject: contemplating remailer postage 
As Jim points out, Matthew's scheme for one-bit-per-stamp has the
problem that it requires non-anonymous stamps.  Jim suggested a variant
on Chaum's digital cash where the stamp numbers would be re-blinded by
the recipient so that the remailer would not recognize them (but could
verify their validity).
Matthew's bitmap idea could still be used, though.  The incoming stamp
numbers could be hashed down to, say, 24 bits.  This could then be an
index into a 2^24-bit file, which would take 2 MB.  Set the bit when the
stamp is used, and reject the mail if the bit is already set.
Granted, this would create false rejections.  But email is already not
perfectly reliable.  You could send 160,000 messages before you had as
many as 1% false rejections (2^24 / 100).  I think this would be better
than trying to save this many digital stamps and check through the list
each time for duplications.

@_date: 1994-02-04 13:59:53
@_author: Hal 
@_subject: Magic Money Digicash System 
Wow!  Hot stuff!
I looked at csn.org, but I didn't find magic money.  The pgp_tools
has been there for a while, of course.  Somebody post when they find
Hats off to Pr0duct Cypher!

@_date: 1994-02-04 23:40:06
@_author: Hal 
@_subject: Magic Money Digicash System 
FTP to csn.org, cd to /mpj, read the file README.MPJ which will tell you
a directory to switch to, do that, cd to pgp-tools (or pgp_tools, or
pgptools, I forget which), and get magicmny.zip.  Then unzip and build it.
None of these things should cause major problems.  At worst useless coins
would be generated.  Initially, users might send their coins in right away
to confirm that they are OK until they get some confidence in the program.
This will practially never happen if they are chosen randomly.  Bad
randomness could produce coins which match ones which have already been
spent (if somehow your RNG got into exactly the same state as someone
else's), so they would be valueless.  I think the program makes you
initialize a random file before using it, so just make sure you put
something random there!
I don't think there are any values you can sign which would give away a
private key.  Even signing "1" or "2" should be safe, I think, since the
secret key is the size of the modulus.
I ftp'd a paper recently mentioned on imp-interest (on "anonymous
credit cards") which claimed that new cash could be generated from sets
of old cash in Chaum's scheme.  I don't believe this, and the ref was
to a paper "in preparation" by the authors.  I'll try sending them
email to ask about this.
Here is how this problem would arise.  Alice has some cash, which she
sends to Bob to buy something.  Bob sends it to the bank to be verified
and turned into fresh cash before he will send the goods to Alice.  But
the bank says the cash has been spent before, and Bob reports this to
Alice.  Alice insists that she has never spent this cash before.
Now, this is like a mystery story.  Who is telling the truth?  Maybe Alice
is lying.  Maybe the bank is lying.  Maybe they are both telling the truth
and someone broke in and stole Alice's cash while she was sleeping, copying
it from her computer and spending it before she could.
Ignoring that last possibility for a minute, it is basically Alice's word
against the bank's.  In general, in situations like this, we often go by
the reputation of the parties involved.  If the bank really is cheating,
there will be lots of other people like Alice, people with good reputations,
who are making similar charges.  This will make people stop trusting the
bank.  On the other hand, if Alice is cheating, this is probably not the first
time.  In time she will get a reputation for being untrustworthy.
The idea of publishing lists of used coins is interesting but I'm not sure
it helps.  Double-spending could easily occur close together in time, between
publication of lists.  A cheating bank could claim a coin had been spent
just before the actual coin came in.
The server should re-transmit the message if it does not arive.  We
discussed this a while back and it appears safe for everyone in these
protocols to re-transmit messages freely if the other person claims
never to have gotten them.  Even if they are lying, what is the harm -
you are just sending them information they already have.
Good questions.

@_date: 1994-02-05 14:05:45
@_author: Hal 
@_subject: Some stuff about Diffie-Hellman (and more :-) 
Quite a few misconceptions here, I'm afraid:
w is supposed to be a "generator" of the group of integers mod m.  It does
not have to be prime.  It is supposed to be such that the series w**0, w**1,
w**2,...,w**m-1 does not repeat but goes through all the integers less than m.
Testing for such w's is pretty easy if you know the factorization of m,
involving a few arithmetic tests.
b does not have to be prime; it is a random number less than m.
Likewise, c does not have to be prime; it is a random number less than m.
Carol does this, not Bob.
Bob does this, not Carol.
             ^^^^^-- generator
I don't think there is a need for this.  The two sides need to agree on
a pair but they could just pick it at the beginning.  If everyone uses
the same m,w it would help attackers of the scheme to focus their efforts
on these numbers.  I believe there was some discussion of using well-known
numbers in the Digital Signature Standard (which is based on the same
problem as DH) but I don't know what the resolution was.
PGP does not uses DH and has no well known numbers.
If you do want well known numbers, I really think it will not be that bad
just to put them into the program.  Coming up with an algorithm to choose
and test a generator from scratch is probably going to be larger and
certainly going to be far slower than just hard-wiring the number in.

@_date: 1994-02-06 20:00:32
@_author: Hal 
@_subject: Attack on Magic Money and Chaum cash 
I think there may be a security weakness in Magic Money coins, and in
Chaum's "online" cash system from the Chaum/Fiat/Naor paper.
Magic Money coins are numbers of a particular form, RSA-signed by the
bank.  They look like Y^(1/e) where Y is the number and e is the
bank's public exponent corresponding to the particular denomination of
the coin.
The structure of Y is a 0, a 1, a string of bytes of 0xff, then
a defined 18-byte string of bytes, then 16 random bytes.  This Y is
generated by the user, and is then blinded by multiplying by some
random r^e, and sent to the bank.  The bank RSA-signs Y*r^e to get
r*Y^(1/e), and the user divides by r to get Y^(1/e).  This is the
The coin is checked by raising it to the power e, to get Y, then
checking to see if it is of the proper form.  Actually, the Magic
Money code only checks the 18-byte special string (just above the 16
random bytes) to make sure it matches the exact byte sequence that is
always supposed to be there.  In addition the bank checks the 16
random bytes against a list of spent coins to make sure this coin
hasn't been spent before.
The other relevant point is that the bank has to sign everything you
give to it (with payment) - it can't check the bit pattern for
legality, since what it is signing is blinded.  So you can really get
the bank to sign anything.
Yesterday I opined that this would be safe, but now I don't think so.
The danger I would see is an attacker who gets the bank to sign 2, 3,
5, 7, 11, 13, 17, 19, ....  The bank won't know it is signing these
special numbers because they are blinded.  If someone gets a lot of low
primes signed he may be able to forge money, especially with the
incomplete checks in the Magic Money program.
The idea would be for him to try to factor a legal Y using just the
primes he has.  If he can find a factorization using only small primes
of a number which holds the magic 18-byte sequence in the right place,
he can multiply together the signed forms of the primes to produce a
signed version of that number.  This would be a successfully forged coin.
So, the question is whether it would be feasible to collect enough
signed small primes to be able to generate more valid coins than you
have primes.  (It costs you a coin each time you get the bank to sign
something, so for this to be a money-making venture you want to get
more out of it than you put into it!)  I think there are a reasonable
fraction of numbers factorable by only small primes.  Since there are
2^128 possible money values (based on the 16 random bytes) there
should be quite a lot which are factorable by only small primes.
Magic Money could help by checking the high bytes as well as the magic
18; it would be take more time to factor 1024 bit numbers than 272 bit
ones ((18+16)*8), and there would be fewer that are factorable by
small primes.  But the problem would still exist.  The attacker can run
a fast sieve to identify numbers which are factorable in his set.
The same attack would apply to Chaum's online cash.  His cash is of the
form, (x,f(x)^(1/e)), where f() is a one-way function like MD5.  To forge
this you would again get signed forms of the small primes, then keep
picking random x's, until you got a f(x) which could be factored by your
set.  Presto, you can create a fake coin.
I don't know how this attack can be prevented.

@_date: 1994-02-06 20:36:08
@_author: Hal 
@_subject: Attack on Magic Money and Chaum cash 
A quick follow-up: I suppose a cut-and-choose protocol in the withdrawal
would prevent this attack.  Instead of sending in one blinded coin to be
signed you'd send in 100 blinded candidates, then the bank would pick 99
and you'd reveal the r's for the others (remember, they are blinded with
r^e) so the bank can verify they are of the proper form.  The bank would
then sign the one remaining one and return it to you.
What a pain!  I hope someone can come up with something better, or show that
the attack doesn't work.

@_date: 1994-02-06 22:41:09
@_author: Hal 
@_subject: Magic Money attack 
I think it's great that you are able to fix these things so quickly.
It's natural that there will be a lot of shaking out in any initial
Knuth has some discussion of this in Seminumerical Algorithms.  The term
for numbers which have only small factors is that they are "smooth".  He
has some formulas for what fraction of numbers are smooth based on the
size of the largest allowed prime and the size of the numbers.  Unfortunately
I won't have access to my copy until Tuesday.  Perhaps someone else can
look it up.
Clever idea.  If only it wouldn't be so slow.
The 8192 cutoff might work.  We would have to check it out, but it
could be that finding 1024-bit numbers in a relatively narrow range of
+/- 2^64 which are composed solely of factors in the range, say, 8192
to 16384 would be infeasible.  I don't recall whether Knuth considers the
problem in this form.  This would be a great save if it works.

@_date: 1994-02-07 09:10:36
@_author: Hal 
@_subject: A Nice Summary of Motives for Clipper 
Several people on sci.crypt have pointed to the following paragraph
in Matt Blaze's report of the NSA briefing on Clipper, posted here and
in the newsgroups:
This could explain a lot.  In particular, if they can enforce this, it
could put an end to the dreams of multiple encryption.  For months people
have been saying, "Clipper?  No problem.  I'll just encrypt with PGP then
pass it through Clipper and the Feds won't ever guess!  Ha, ha, ha!"
Maybe this won't be so easy.  From Blaze's description it sounds like
such devices wouldn't be approved.  It could be the only Clipper phones
will be ones that don't do anything to keep the Feds from picking up the
People could still build non-Clipper encrypting phones (assuming that
the constant rumors of threatening midnight visits from NSA agents are
false), but the users of those phones could no longer blend in with the
Clipper traffic.

@_date: 1994-02-07 22:36:33
@_author: Hal 
@_subject: WRONG:  Attack on Magic Money and Chaum cash 
I was thinking over the attack I described on Magic Money and Chaum
cash, and I now think it will not actually work, especially in the case
of the Chaum cash.  Specifically, it will take as much work to forge
cash as to factor the modulus.
My idea was to collect signed forms of small primes, then try to find a
"smooth" number of the proper form, one which can be factored over this
set of primes.  By multiplying together the proper primes, one could
generate a signed number which would look like cash.
What I was remembering as I was driving tonight is that this is very
similar to a family of algorithms for factoring large numbers.  The one
I know best is the continued fraction algorithm, but I think the number
field sieve uses broadly similar principles.  In the cfrac algorithm,
the goal is to find two squares which are equal mod n.  This lets you
factor n immediatly by taking its gcd with the sum or difference of the
two numbers.
This is done by taking a bunch of squares and trying to factor them
over a set of small primes.  If you generate enough factorizations,
approximately as many as there are primes, you can multiply selected
ones together and generate two equal squares.
The point is, finding as many smooth numbers as there are small primes
will let you factor n.  But that is the same criterion I had to meet in
my proposed attack in order to make a profit.  So it seems that in
general my attack will not work; it will be as hard as factoring the
There may still be a problem with Magic Money because its cash values
leave the low order 128 bits free, but I'm not so sure about it.  I was
wrong, I think, to suggest that a simple sieve could quickly identify
smooth numbers.  Although a sieve will easily tell you that a number
has _no_ factors less than some cutoff, it will not easily tell you
that a number has _only_ factors in that range.  It may be that the
only way to identify smooth numbers is by trial division, which would
be the same situation as for Chaum cash.
So, unless there is in fact some trick that can be used to quickly find
smooth numbers given that the low order 128 bits are free, I don't
think there is any need to worry about my attack on Magic Money.  And
it looks like Chaum's online cash is completely invulnerable to this
Sorry to have raised a red flag unnecessarily.

@_date: 1994-02-14 18:01:32
@_author: Hal 
@_subject: SCHEME for FULL-SPEC RETURN PATH 
Is this some kind of RFC822 hack?  It doesn't work on my system.  Mail to
hfinney+xyz at shell.portal.com bounces.  Are you assuming some special
mail address processing has been installed by the administrators of the
machines to handle this "+" hack, or is my machine broken in not respecting

@_date: 1994-02-14 18:11:32
@_author: Hal 
@_subject: Detweiler abuse again 
I got a lot of complaints today about copies of Tim's old "Blacknet" posting
being sent to inappropriate groups:
I set up a log file for "blacknet" postings, and got this:
It seems Larry is sending this posting to lots of inappropriate groups
using several different mail-to-news gateways.  This is a good way to
get remailers shut down, which may be his ultimate goal.
I call upon remailer operators to block incoming messages from Detweiler's
known aliases.  Thos using the slocal-based "cypherpunks" remailer perl
scripts can add the following lines near the front of their maildelivery
# Filter Detweiler
Unless his access to the remailer network is blocked, he will be able to
continue to abuse the system until it gets shut down.
The alternative would be to block my remailer's access to all known
mail-to-news gateways, but I am reluctant to take that step because of
the loss of this ability for those who legitimately need it.  If his abuse
keeps up, though, that may be the only choice left.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-02-15 09:33:58
@_author: Hal 
@_subject: Detweiler abuse again 
I understand Eric's comments about the use of logging to "catch" Detweiler
in the act here.  Frankly, I expected more criticism of that action than I
received.  I should make it clear that I do not routinely log, but that after
receiving the complaints I forwarded to the list I added a line to my
maildelivery file to save all messages with the same subject line as the
offending message to a file.  Within minutes, the message from Detweiler
I'm not sure Eric's idea about connecting via sockets would eliminate all
possibilities of logging.  It seems that with telnet, at least, the systems
that you connect to are able to find your host name.  Still, host names
would be more private than full addresses.
Grepping the Blacknet log file for "request-remailing-to" shows the
following messages which have accumulated overnight:
request-remailing-to: comp.sys.ti.explorer at news.cs.indiana.edu
request-remailing-to: rec.mag at news.demon.co.uk
request-remailing-to: rec.sport.football.australian.usenet at decwrl.dec.com
request-remailing-to: alt.fan.addams at news.cs.indiana.edu
request-remailing-to: soc.history at news.demon.co.uk
request-remailing-to: comp.archives.msdos.d at news.cs.indiana.edu
request-remailing-to: rec.pets.dogs.usenet at decwrl.dec.com
request-remailing-to: comp.sys.sgi.graphics.usenet at decwrl.dec.com
request-remailing-to: alt.fan.vejcik at news.demon.co.uk
request-remailing-to: alt.fan.addams at news.cs.indiana.edu
request-remailing-to: rec.pets.dogs.usenet at decwrl.dec.com
request-remailing-to: alt.abortion.inequity at news.cs.indiana.edu
request-remailing-to: alt.security at news.demon.co.uk
request-remailing-to: alt.sports.football.pro.dallas-cowboys.usenet at decwrl.dec.com
request-remailing-to: rec.music.classical.guitar at news.cs.indiana.edu
request-remailing-to: news.announce.important at news.demon.co.uk
request-remailing-to: misc.health.alternative.usenet at decwrl.dec.com
request-remailing-to: alt.beer at news.cs.indiana.edu
request-remailing-to: alt.archery at news.demon.co.uk
request-remailing-to: alt.sports.basketball.nba.wash-bullets.usenet at decwrl.dec.com
One good thing is that he is apparently targetting just a few mail-to-news
gateways.  I was worried because one of the complaints I got came from
a mailing list; it would be completely infeasible to block all mailing list
addresses.  But blocking the mail-to-news gateways would be pretty easy.
(As an aside: how do these gateways take the heat?  Should I suggest to those
complaining to me that my system is intended for email, not usenet, anon-
ymity, and that they should direct their complaints to the mail-to-news
gateways which are the "real" cause of the problem?  Is this tactic likely
to be politically effective?)
Now, I haven't received any complaints from the administration at this
commercial system for which I pay about $30 a month.  In fact, I have never
received any complaints about my remailer from the admins, even though I
assume that at least some complaints have been sent to root or postmaster
here.  I know that the owner of the Portal system was at the hacker's
conference a couple of years ago (according to a report on the cp list),
and that he supposedly pledged his commitment to the concept of anonymous
remailers.  I have never contacted him, but perhaps I am protected to
some extent by his beliefs.
At this point, I will probably take no action and see if this blows over.
If I get more complaints, though, I will probably block the mail-to-news
gateways as outgoing addresses.
Another alternative would be for me to forward outgoing mail which is
directed to the mail-to-news gateways through another remailer, such
as Xenon's at netcom.com.  Thanks for the suggestions and advice.

@_date: 1994-02-16 21:40:28
@_author: Hal 
@_subject: Pen recorders and phone records 
I have read that if the police want to know who a person communicates
with on the telephone, they can arrange to have a "pen recorder" put on
their phone line.  This will record all phone numbers called from that line.
Supposedly the legal barriers to this type of surveillance are much less
than for a phone tap.
I am confused about the necessity for this if the phone companies routinely
record this information anyway.  Is this just an archaic and obsolete
terminology, and what really happens is that the phone company will give
already-existing phone records to authorized officials?
Thanks -

@_date: 1994-02-19 09:26:35
@_author: Hal 
@_subject: ;pgpit 
I was just logging out, by typing "logout".  I accidentally placed my
right hand on the wrong keys, offset to the right by one.  Instead of
"logout", what appeared on my screen was ";pgpit".  Good idea!  One we
should all take to heart. ;-)

@_date: 1994-02-22 09:44:59
@_author: Hal 
@_subject: RATINGS: Subject tags 
One issue is the purpose of the ratings system.  I don't think it will help
to solve the problem of intentional disruption.  If the disrupter is really
motivated, he could have multiple identities and give positive ratings to
his messages, so they would get through.
I think a good purpose would be filtering out uninteresting or lower-quality
messages.  Unless someone else vouches for a message, it would not appear
for a subscriber to the filtered list.
Eric asked that discussions on this topic use the "subject tag" concept,
putting "RATINGS:" in the subject line.  Subject tags are a good idea but
are not widely used.  If more people would use them it would help people to
read those messages that interest them.
My suggestion is that the ratings be based on subject tags.  A rater reads
a message, and if he endorses it as being worth reading he sends in one or
more subject tags (keywords) which apply.  Then someone on the filtered list
could subscribe based on particular tags that interest them.
The advantage is that this way even newcomers' messages are tagged with useful
keywords, tags provided by old-timers on the list when they approve the messages.
This also provides for the multi-dimensional aspect of approval, more useful
than a simple "thumbs up".
I won't try to suggest a syntax, but under this proposal a rating message
would include some message identifier (perhaps the list should produce
messages with an incrementing message number), along with a list of
applicable subject tags.

@_date: 1994-02-22 14:23:00
@_author: Hal 
@_subject: RATINGS: Subject tags 
This would imply that subscribers see the source of each rating.
You would have to know that in order to judge whether to believe one or
not.  But I think this might consume too much bandwidth.  With possibly
many raters, each producing a potentially multi-dimensional rating per
message, this would be a lot of stuff to send along with each message.
My suggestion would be to just present the union of all the subject
tags produced by the raters.  This is a moderate amount of information,
and to the extent that raters agree on subject tags it could in many
cases be a very succinct presentation.  We don't want to make this too
This makes sense, but there must still be two lists: one, the "raw" list,
which is seen (at least) by raters and contains messages which have not
yet been rated; and the other, the "rated" list, which has the rated
messages.  My suggestion was that messages which did not receive any
ratings by anyone would not make it into the rated list.  Obviously an
alternative would be to send it out tagged to show that no one cared
enough to rate it.
This could also be used for negative ratings: subject tags such as
"flame", "faq", "rant", etc. could be used to give more information than
just the topic of the message.  People could set up their own systems to
filter the message to exclude messages with certain of these tags.
Message-ID is probably OK, but it is kind of long.  Many mail agents will
insert an "In-Reply-To" into the header which identifies the message ID,
but not all will.  It would be a real pain to type one in manually.
Another advantage of numbering messages sent on the "raw" list would be
that people would be able to tell when they have missed messages (but that
is irrelevant to the ratings issue, I admit).

@_date: 1994-02-23 13:49:02
@_author: Hal 
@_subject: Digitally Signing Physical Objects 
Tim has an interesting point on the use of digital signatures.
A variation is to use an "undeniable" signature.  This is a signature which
can only be checked with the cooperation of the signer.  However, the protocol
is such that the signer cannot cheat and try to deny a valid signature
(hence the name).  This could be used by manufacturers to authenticate
their products only to certain customers; for example, to customers who have
paid for them.
This might be especially useful for software, although Tim's idea would
extend it to any object for which the authentication is especially valuable.
PGP is distributed signed by Phil Zimmermann using an ordinary digital
signature.  This allows anyone to verify that it is a good package, free
of viruses or trap doors.  If it instead had an undeniable signature, this
verification would require interacting with Phil (or his agent) via a
protocol; but at the end the same assurance would result.  This kind of
signature would be more appropriate with a payware product.
Undeniable signatures cannot be passed on from one person to another.
If Alice verifies Bob's undeniable signature, she can't prove to Charlie
that the signature is good.  She can claim it is good, and assure Charlie
that it is good based on her own reputation, but Charlie can in general not
be convinced unless he verifies it himself directly with Bob.

@_date: 1994-01-02 10:58:40
@_author: Hal 
@_subject: POLI: Politics vs Technology 
This position seems to be fast becoming cypherpunks dogma, but I don't
agree.  The notion that we can just fade into cypherspace and ignore
the unpleasant political realities is unrealistic, in my view.
Have people forgotten the Clipper proposal, with the possible follow-on to
make non-Clipper encryption illegal?  To the extent this proposal has been
or will be defeated, it will happen through political maneuvering, not
Have people forgotten the PGP export investigation?  Phil Zimmermann hasn't.
He and others may be facing the prospect of ten years in prison if they were
found guilty of illegal export.  If anyone has any suggestions for how to
escape from jail into cyberspace I'd like to hear about them.
Mike's SecureDrive is a terrific program for protecting privacy.  But
if we want to keep keys secret from politically-motivated investigations,
we have to rely on the very political and non-technological Fifth Amendment
(an amendment which Mike Godwin of EFF and others contend does not actually
protect disclosure of cryptographic keys).  Again, we need to win political,
not technological, victories in order to protect our privacy.
I even question Mike's point about the government's inability to ban books.
Look at the difficulty in keeping PGP available in this country even though
it is legal.  Not only have FTP sites been steadily closed down, even the
key servers have as well.  And this is legal software.  Sure, this software is currently available overseas, but that is because
PGP's only legal limitations are the U.S. patent issues.  Imagine how much
worse it would be if non-escrowed encryption were made illegal in a broad
range of countries, with stringent limits on net access to countries which
promote illegal software?  Here again, these kinds of decisions will be made
in the political realm.
Fundamentally, I believe we will have the kind of society that most people
want.  If we want freedom and privacy, we must persuade others that these
are worth having.  There are no shortcuts.  Withdrawing into technology
is like pulling the blankets over your head.  It feels good for a while, until
reality catches up.  The next Clipper or Digital Telephony proposal will
provide a rude awakening.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-01-02 16:38:42
@_author: Hal 
@_subject: Anonymous video on demand 
Of course, with tamper-proof chips this problem can be solved easily.
You don't need oblivious transfer.  Rather, you get digital tokens from
the video provider which you pass on to the tamper-proof decryption
chip, where each token is worth a certain amount of decryption.  Then
you choose which movies you want to decrypt.
The only question would be whether the tamper-proof chip would keep a
record of your viewing habits.  But you should be able to monitor anything
it transmits (if it has to transmit anything) and it should not have to
send any encrypted messages.  So your secrets should be safe.
One problem with this approach (and the other ones we have discussed)
is that the vendor loses any information about which movies are most
watched, which hurts his ability to set prices and choose which movies
to carry.  Perhaps he could resort to a separate anonymous
public-opinion poll to determine this info (protected with is-a-person
(is-a-customer?) credentials so that our friend Detweiler can't
pseudo-spoof with his multiple tentacles ;-).
Or, perhaps another approach is to have a different decryption key for
each movie, and to simply sell those keys to anonymous buyers.  They would
then load them into their decryption boxes.  This does seem vulnerable to
pirating the keys, though.  Piracy could be avoided if the decryption keys
were stamped with the serial number of the particular tamper-proof decryption
box they were for (so that they would only work with that one box).  But
then you lose the anonymity.  I'm thinking that some form of blinding could
be used to produce a key which would only be accepted by one box, but for
which the movie seller would not be able to determine which box it was for.
This is very similar to the requirement for electronic cash, and I think a
similar idea would work.  This solution also is a nice example of the uses
of anonymous networks.  I wonder whether the NII could support DC-nets? :)

@_date: 1994-01-04 09:29:10
@_author: Hal 
@_subject: Slack area behind files 
I use Stacker for disk compression on my PC, and this problem of
un-erased data is potentially worse with that software.  Probably
Microsoft's DoubleSpace suffers from the same problem.
If you erase a file on a compressed partition using some of these
suggestions, such as writing a pattern followed by its complement, you
won't erase the whole file.  That is because a repeated pattern is far
more compressible than the original file contents, in most cases.  A
4K byte text file may compress down to 2K on the disk, but 4K worth of
repetitions of 0xff will compress down to just a few bytes!  The majority
of your file will not be touched at all.
Norton has a "wipefile" program which overwrites files according to a
government standard, but I believe it just writes constant values repeatedly.
This will overwrite only the start of the file, many times.
Bruce Schneier recommends including one or more passes of writing
pseudorandom data to the file.  Since this data is not compressible it
should overwrite the whole file.  The data doesn't have to be cryptographically
random, just something that won't be compressed by straightforward

@_date: 1994-01-07 13:34:43
@_author: Hal 
@_subject: Softlock from alt.wired 
Saw this on alt.wired.  They are creating electronic vouchers which you
can use, in effect, to buy software on the net.  I have more comments
I got the press release referred to.  The business is to provide passwords
to unlock advanced features of software products distributed like shareware.
You can use a crippled version of the program for free, but to get the
advanced features you call Softlock and pay them money, then they give you
a code which unlocks all the program's features.  Softlock takes a percentage
of the fee and passes the rest on to the developer.
This is not that new, but one thing they do have is a pre-paid voucher
usable to purchase software password codes.  When you buy a new password to
unlock a program you can pay electronically by MC/VISA or by voucher.  (You
can also send checks and cash by postal mail.)
Presumably these vouchers could be given as gifts, or exchanged in other
ways.  If Softlock eventually develops a good range of useful software, this
could lead to a grass-roots form of electronic money.  It would be backed by
the Softlock software products, but could eventually be used to buy other
things, because people would know that the vouchers were worth real products
so they would accept them.  This route to backing money seems to have less
problems with the banking laws, etc.
The specific Softlock vouchers are not anonymous, I'm sure.  Anonymity would
add a lot of overhead and complexity in working with them (see our earlier
discussions of Chaumian cash).  But they could be a start towards a net-wide
electronic payment system.
The Softlock people are somewhat crypto aware, accepting RIPEM messages,
which is good if you want to send your VISA card number to them.  I wonder if
they might be interested in a more cryptographically advanced untraceable
voucher system.

@_date: 1994-01-11 22:31:55
@_author: Hal 
@_subject: Crypto and taxes 
I can agree that cryptography will make some kinds of illegal private
transactions easier.  What I doubt is that this will happen at a large
enough scale to seriously threaten the ability of governments to fund
themselves by taxes.
Take Perry's example of one person buying a rare, expensive item from
another.  This might be made easier to do anonymously with ecash.  But
how much significance will this have taxwise?  If these were private
individuals involved in a personal swap, chances are no taxes would be
paid even under current conditions.  I bought a car from my next door
neighbor a few months ago.  I doubt that he paid income tax on it.
And transactions of this magnitude are rare among individuals in a non-
business situation.
Most of our transactions are done with businesses, generally corporations.
Imagine taking $15,000 in cash to buy a new car anonymously.  I believe you
will find that the car dealers will not cooperate, that government regulations
(designed to crack down on drug dealers) will require them to get some ID
from you.  Digicash would presumably be under the same restrictions.
Furthermore, as I argued earlier, it will be much harder for a large business
to successfully switch to cash transactions in the hope of evading taxes.
A much larger group of people would have to be "in" on the secret, in order
to cooperate to prepare the false receipts and books that would be necessary.
Any situation like this will be risky and dangerous to maintain.
I don't fully understand Duncan's arguments for how taxes can be avoided
through being a non-citizen.  I gather, though, that this would require me
to either move to another country, or to go to work for a company that is
in another country.  Neither seems likely in the next few years for the
majority of citizens.  And if this did catch on, presumably this loophole
could be closed, so that you were taxed by whatever country you lived in.
(A similar situation exists today with respect to state income tax for
people who live in one state and work in another.  I don't think they are
exempt from all state income taxes.)
Sandy may be right that self-employed people who get cash payments do
widely under-report their income, and no doubt self-employed
programmers do the same to some extent.  But I'm really not sure why or
how a programming contractor or consultant, let alone an employee, will
be able to avoid paying taxes once strong crypto is common.  Won't the
company paying him still want to record those payments on its books, so
it can deduct them as business expenses?  I believe similar records are
used today to verify tax liabilities of paid consultants.  Why won't
this be true with crypto involved?  And for employees, companies are
still going to need a social security number, name and address, and
they will still submit records to the government showing how much you
were paid.  I don't see widespread tax evasion in the picture at all.
Sure, some smart people may be able to exploit the new technologies and
disappear into the cracks.  Self-employed information workers may have
the most to gain.  But the average worker and the average company aren't
going to have major new opportunities for tax evasion.  The economy will
keep plugging along as it always has, and if the government goes down the
tubes it won't be because of the advent of strong cryptography.

@_date: 1994-01-12 16:07:39
@_author: Hal 
@_subject: Crypto and Taxes 
I appreciate the thoughtful responses in this thread.  Let me just
make one point now, saving a more detailed response for this
evening.  Perry implied that I do not wish to see people avoid taxes,
and that was why I was arguing that cryptography would not make this
as easy as some had suggested.
That is not a reasonable inference from my posts, and I am surprised
Perry would suggest it given our two years of discussions on the
extropians list.
My primary motivation is of course simply to test what I see as a
discrepency between the world I live and work in and that proposed
in the crypto-anarchy model.  I also want to question speculations
that I see playing into the hands of law enforcement interests by
making cryptography look more threatening than it is.
Another reason is to discourage complacency that cryptography will
solve our political problems by automatically ushering in a
libertarian/anarchist utopia.  This is a follow-on to the posts I
made last week on this topic.  Today, Sandy still says "We've won".
The postings about life in Italy did provide an interesting portrait of
a society of tax evaders, but at the same time the government response
was chilling.  The U.S. is not Italy, and I suspect that neither the
widespread tax avoidance nor the draconian government measures could
happen here.  But it should give pause to those who suggest that our
political battles are won.

@_date: 1994-01-12 16:37:14
@_author: Hal 
@_subject: Apology to Perry 
I realize upon re-reading this comment that Perry was not suggesting
that I did not desire tax evasion, but rather that I did not think
tax evasion was widely desired, which is entirely different.
I apologize to Perry for accusing him of impugning my motives and I
will try to read more carefully next time.

@_date: 1994-01-15 08:58:04
@_author: Hal 
@_subject: SecDriver 1.1 versus 1.2 
Aside from the technical differences between the two packages, I think
the more significant difference is in the distribution.  Edgar's 1.2
documentation encourages users to put the package up for FTP, while
Mike's 1.0 (and, I presume, 1.1) docs ask that this not be done.
Mike wants to protect himself against a PGP-style investigation into
export of software.  But if 1.2 is put up for FTP, it could conceivably
lead to such an investigation.  And Mike would presumably be a
potential target.
This is a confusing situation.  What rights does Mike have to control a
derivative product like 1.2, given that he is releasing it under the
Gnu Public License?
Maybe the GPL is not appropriate for the release of crypto software, at
least if the author will attempt to restrict its distribution in this
I don't blame Mike for his concern, but I think we need to recognize an
inconsistency between the following three goals, for U.S. citizens at
least: public recognition as the author of a crypto package; avoidance
of Grand Jury investigations; free availability of the package in the

@_date: 1994-01-16 19:18:15
@_author: hfinney@shell.portal.com 
@_subject: PGP's e exponent too small?  Not! 
Matthew J Ghio, , argues that low public exponents
such as are used by PGP are unsafe in the RSA public-key cryptosystem.
I think his analysis is mistaken, although there were a fair number of
typing errors which make it hard to be sure I am understanding him
The issue is not whether the d power should be low; of course it should
not be, since that is the secret exponent, and choosing a small one
will make it easier to guess.  The question is whether small e values
are unsafe.  I think this is just a typographical mistake.
This is the fundamental error in his analysis.  The correct equation
or, in other words:
All of Matthew's reasoning about putting bounds on d*e (he often writes
of bounding p*q, but I'm pretty sure he means d*e) is based on this false
assumption that d*e is a factor of (p-1)(q-1)+1.  Actually, the true
relation is that (p-1)(q-1) is a factor of d*e-1.
The concern about low values of e in the Schneier book relates to the
issue of RSA-encrypting the same value with the same low e value and
different RSA moduli.  This might be done if you were using "pure" RSA
(which PGP and PEM do not) and encrypting the same message for multiple
recipients.  Kaliski is right that adding random padding to what is
encrypted will eliminate this attack.  PGP and PEM do add such random
padding, following RSA's Public Key Crypto System standard.

@_date: 1994-01-16 19:18:49
@_author: hfinney@shell.portal.com 
@_subject: Crypto and Taxes 
I'll just briefly recap some of the points:
Hal> I don't agree with the extreme position that cryptography will lead to
Hal> the failure of the income tax and the destruction of the government.
Perry> No one is arguing, by the way, that all the economy will go black. I'm
Perry> merely noting that whereas right now its hard to lead a normal life
Perry> entirely in the black economy (you suffer from a myriad of
Perry> inconveniences), an anonymous offshore banking system that you have
Perry> free access to changes all that.
It's not clear to what extent Perry and I disagree here.  I agree that some
people will exploit the new opportunities.  My doubt is whether the vast
silent majority on which the government depends for its taxation revenues
will do so.  I read the other day that the government gets something like
70-80% of its tax revenues from people making less than $35,000 a year.
These people are not financially sophisticated.
Duncan> In traditional Black Markets, the transactions are illegal.  In future Duncan> Black Markets on the nets, most of the transactions will be legal.  Duncan> Legality certainly encourages transactions relative to illegality.
I agree with the last point about legality helping, but I don't understand
why most transactions will become legal in the future.  I thought we were
talking about ways to evade laws via cryptography.  My assumption is that
governments would actually crack down when faced with lost revenue, similar
to what was described as happening in Italy:
??> Customers are fined for leaving businesses without a receipt.  Your car may
??> be stopped and searched for undocumented merchandise at any time.  Imputed
??> income taxes for self-employed people are at ridiculous levels (i.e. a
??> large degree of evasion is assumed).  Taxes are levied on everything (car
??> radios, the width of your driveway, electric lighters for gas stoves).
So I'd think even more transactions would be illegal in the future.  The main
issue, I thought, was whether people would widely risk violating these laws
in order to save on their taxes, and whether cryptography would let them do
so with impunity.
Duncan> You left out a few information purchases: education, much of medicine, Duncan> all of financial services, design, marketing, supervision, and
Duncan> management. Duncan is pointing out that more of the economy is in the form of information
than I was counting.  Even if we count these things as information, though,
the question is still to what extent the providers of these services will be
able to escape taxation.  Take medicine as an example.  I should be able to
go to a doctor today and pay him cash, off the books, at a greatly reduced
rate, for my medical services.  Yet no doctor I've ever seen, and I've probably
seen twenty or thirty in my lifetime, has ever suggested that.  I don't see
how cryptography will change this.
Duncan> Once the interface is good enough, virtual offices with full workgroup Duncan> interaction built of pure information will spring up and the
Duncan> "information" component of much of what we think of as physical work
Duncan> will become apparent.
Is this the key, people working for virtual businesses?  No one knows the
true name of anybody else, so no one is afraid of being caught?  I am still
skeptical.  A whole nation of people tele-commutes to work for companies
whose name they don't know, with co-workers protected by aliases, all so they
can be paid in cash for their services.  I find this notion implausible in
the extreme.  Joe and Jane Sixpack aren't going to want to work for a
boss who wears a mask.
Duncan> If you wander down the shopping street of a future MUD/MOO and you
Duncan> buy or sell things, what nation has jurisdiction for tax purposes.
Duncan> What if the MUD/MOO exists as a set of cooperative processes spread
Duncan> around the globe. This may be uncertain now, but I don't see why it would always remain
that way.  There is nothing to stop governments from declaring, say, that
residents in their boundaries are subject to their taxation, or that their
citizens are subject to their taxes regardless of where they do business.
More interesting from the crypto perspective would be the case where the
business in the MUD refuses to disclose its true nationality or location.
There again, though, I think running an anonymous corporation will pose many
practical problems.
Sandy> You don't need to
Sandy> *own* a car, to have the *use* of a car.  Imagine leasing a car
Sandy> and using your cyberspace bank digital checks, digital money or
Sandy> credit card to pay the monthly rent.  No audit trail, and no
Sandy> asset to be seized.  Similar techniques can be used for virtually
Sandy> all of your assets.
How does this bear on the issue of government collapse due to failure of
income tax?  This example actually strikes me as an unobjectionable use
of cryptography, one in which individual privacy is protected.  The only
tax consequence I see is possible avoidance of sales tax, which is col-
lected only at the state level and not the national level.  Sandy's
example shows that car rental agencies might be able to operate on a cash
basis, like the local fried chicken outlet.  I don't see how this brings
down the government.
Sandy> I think Hal hasn't been reading Duncan or my posts very closely.
Sandy> Here's a hint:  A Cayman Islands corporation is a non-US citizen
Sandy> even if it is owned by an American.
Sandy is replying to my question about moving out of the country to
avoid taxes.  I gather that he is suggesting that people could set up
corporations in the Cayman Islands and somehow divert some of their
income to them, so that the income would be shielded from taxes.
Can this be done today?  Can I go to my boss and ask him to start
sending my salary to this numbered bank account in the Cayman Islands,
and to stop troubling the U.S. government with information about how
much he is paying me?  Sounds great.  Why doesn't everybody do it,
and why will everybody start doing it in the future?
To sum up, I am willing to accept that people will be eager to avoid
paying taxes, but I still doubt that cryptography will bring down the
United States government.  Particularly when we consider the lack of
sophistication (both financial and technical) of the vast middle class
who provide the bulk of tax receipts, I think that virtual corporations
and offshore tax havens are not likely to become widespread enough to
seriously endanger the government.
(In response to John Kreznar's comments about my use of the term "cheating"
to refer to violation of tax laws, I accept the thrust of his comments
but I'll just observe that while preparing a false set of books may be
justified and in some circumstances even honorable, it is not honest.)

@_date: 1994-01-18 08:38:44
@_author: Hal 
@_subject: RETURNED MAIL, ANYBODY 
I sent mail to Schefter about this, and got a reply last night.  He
said this was his form of protest for having his unsubscribe messages
ignored.  I suggested that he bit-bucket the unwanted messages rather
than bouncing them, and give Eric a little more time to process his unsub

@_date: 1994-01-21 22:29:28
@_author: Hal 
@_subject: Remailers: The Next Generation 
Tim has made some excellent points regarding the remailers.  A couple
of quick comments:
I don't know if charging for messages can be made to work.  Karl has a
remailer which requires digital tokens.  You can get them for free just
by sending an email message.  But I'll bet almost no one uses them.
Why should they, when there are free ones?
That is the big problem.  The free ones undercut the pay-per-use
remailers.  Unless the pay remailers offer significantly more features
and advantages to the users, they won't be used.  Especially if we are
talking about actually mailing physical cash to the remailer operators
in order to receive tokens, this will be terribly inconvenient and will
further raise the threshold barrier against for-pay remailers.
So, the question is whether the value can be made large enough.  Most
of Tim's comments are focussed on the security of the remailers.  For
some applications this is important, particularly the more world-
shaking ideas we have discussed.  (And despite the skepticism I
expressed last week about the degree to which cryptography can change
the world, I do believe it can be a strong force for positive change.)
If people are fighting for freedom against a powerful adversary, they
will need the kind of security Tim is talking about.
But how much remailer use falls into that category?  Not much, right
now.  I frankly don't see improved security as a major problem that
needs to be addressed in the short term.  It's worth mentioning that
despite the charges of hypocrisy in the Detweiler affair (we are
supposedly violating our own principles of freedom and privacy) no one
has proposed trying to violate remailer confidentiality to produce
proof that Detweiler is behind the Squish posts.  Even with our current
network Detweiler has managed to achieve considerable privacy.
The fundamental purpose of the remailer network is to defeat traffic
analysis.  We want to protect the privacy of WHO you communicate with
as well as WHAT you say.  I agree with most of what Tim says, but I
feel that the biggest problems are with ease of use and social issues
rather than security at the present time.
In my opinion, what the remailer network needs is, first,
standardization, as Tim has proposed.  Secondly, it needs reliability
and robustness.  Third, it needs to be easier to do two-way messaging.
Related to this, we need software that can take a message from a
remailer and display it as coming from the sender, either as nym or
truename.  (Karl has a script which does this for elm or mh, I forget
which.)  Fourth, we need to find solutions to the political and social
problems the remailers cause.  Tim's idea of a global blocked-address
database is a good start here.
My picture of remailer use is a little different from what a lot of
people may be thinking of.  Just as we envision a world in which
everyone uses good, strong encryption to protect the privacy of their
electronic messages, I would like to see privacy protection with regard
to patterns of communication.  Who you communicate with tells a lot
about you, in some ways as much as what you say does.  In my ideal
future, remailers and similar technologies are as ubiquitous as
encryption, providing real protection of privacy.

@_date: 1994-01-24 09:36:38
@_author: Hal 
@_subject: REMAIL: Cover traffic 
Several people have suggested that the remailers could send bogus
messages amongst themselves in order to allow more "confusion and
diffusion" of the other messages passing through the remailer network.
The remailers could then batch up incoming messages fairly frequently
and still have many messages in a batch.
The problem with this that I see is that, looking at the remailer
network as a whole, you still may have one message in and one message
out a short while later.  The fact that it was temporarily mixed up
with a bunch of other messages doesn't help much if this message is the
only one to leave the network.  If the Opponent has the ability to
monitor all traffic into and out of all nodes of the network (as he
would have to do anyway to defeat remailers even without this cover
traffic) then he will easily be able to find the messages which are not
aimed at other remailers.
For cover traffic to be useful, it would have to be indistinguishable
from real traffic as it enters and leaves the network.  So messages
aimed at known "bit bucket" addresses, or at a few cooperating
individuals who accept and discard incoming addresses (the same thing,
really) will not help.

@_date: 1994-01-24 15:06:41
@_author: Hal 
@_subject: NSA museum now open, if you can find it 
That museum sounds fascinating.  I got to visit the NSA's so-called
"Friendship Annex" once on business.  This is not at Fort Meade itself,
but a few miles away, to keep the impure and unclean away from the holy
temple itself.
Whoever named this place had quite a sense of irony; the surveillance
cameras, briefcase searches, constant escorts, and armed guards did not
project a particularly "friendly" image.  I was hoping to pick up some
souvenirs, but when I asked about an employee gift shop they looked at me
like I was crazy.  One thing that really caught my eye was a poster which
was displayed widely, apparently a security-reminder-of-the-month thing.
This was the holiday season, and the poster showed Santa stopped at the
gate submitting his bag to be searched.  I'm surprised they didn't have
the old boy being strip-searched.  Anyway, I begged and begged but nobody
would let me have one.
I really think the government is missing an opportunity by not selling
NSA sweatshirts and such.  Recently the Los Angeles coroner's office
started selling souvenirs and they were overwhelmed by the popular demand.
Especially as cryptography becomes more popular, the NSA's sinister-but-
glamorous image could be a marketer's dream.

@_date: 1994-01-27 17:02:13
@_author: Hal 
@_subject: REMAIL: Cover traffic 
Several people have suggested that cover traffic is more valuable than
I had suggested in helping prevent tracing of messages through
I drew up some diagrams to show what I mean.  Suppose we have
remailers R1 through R6 exchanging dummy messages all the time that
are introduced into the remailer network by cover traffic sources C1
through C3:
      C1         C2         C3
          |          |
          |          |
          |          |
          |          |
       V          V          V
      R1<------->R2<------->R3<--------->R4<-------->R5<-------->R6
Now user U1 sends to user U2 through some remailers in this network:
      C1         C2         C3                      U1
          |          |                       |
          |          |                       |
          |          |                       |
          |          |                       |
       V          V          V                       V
      R1<------->R2<------->R3<--------->R4<-------->R5<-------->R6
                                          V
                                         U2
As you can see, it doesn't exactly take Sherlock Holmes to figure out
who is talking to whom.  If the "true" traffic through the network is
light and latencies low, someone monitoring the whole network can
track messages in this way.
Now, suppose we also had U3 send to U4.  Then there is some benefit:
      C1         C2         C3                      U1          U3
          |          |                       |           |
          |          |                       |           |
          |          |                       |           |
          |          |                       |           |
       V          V          V                       V           V
      R1<------->R2<------->R3<--------->R4<-------->R5<-------->R6
           |
           |
           |
           |
                                          V           V
                                         U2          U4
An observer may be able to deduce that U1 and U3 are sending to U2 and
U4, but they can't tell which is sending to which.  So the cover
traffic had some effect.  But consider: you can get the same result
from a SINGLE batching remailer:
                 U1        U3
                   \      /
                    \    /
                     \  /
                      R1
                     /  \
                    /    \
                   /      \
                 U2        U4
Here we also have U1 and U3 sending to U2 and U4, without being able
to tell which is which.
It has also been suggested that "bit-bucket" addresses, people who
would receive messages from the network and discard them, would help.
Here is how cover traffic might look with bit-bucket addresses B1
through B3:
      C1         C2         C3
          |          |
          |          |
          |          |
          |          |
       V          V          V
      R1<------->R2<------->R3<--------->R4<-------->R5<-------->R6
          |                                     |
          |                                     |
          |                                     |
          |                                     |
                 V          V                                     V
                B1         B2                                    B3
Here again, though, if true message traffic is light, and U1 sends to
U2, we will have:
      C1         C2         C3                      U1
          |          |                       |
          |          |                       |
          |          |                       |
          |          |                       |
       V          V          V                       V
      R1<------->R2<------->R3<--------->R4<-------->R5<-------->R6
          |             |                       |
          |             |                       |
          |             |                       |
          |             |                       |
                 V          V             V                       V
                B1         B2            U2                      B3
Again, the changes in the background pattern of communication reveal
the true messages.
The only way this cover traffic will work is if there are a very large
number of traffic generators, (C's) and a large number of bit-bucket
addresses (B's).  Even then it will mostly serve to cover messages
which are from C's to B's.  And you still have the problem that the B
addresses may become well known (people have to find out about them
somehow), making this analysis easier.
It has also been suggested that in pointing out these difficulties I
am overlooking the fact that at least the cover traffic makes the
eavesdropper's task more difficult, as he now must monitor the whole
network.  But I think he has to monitor the whole network anyway.  If
I send a chain-encrypted remailed message through half a dozen
remailers (even without cover traffic), the observer must watch that
message going into and out of each of those remailers in order to see
where it finally goes.  Looking at only one remailer will not help.
So, since the eavesdropper must monitor the whole network in order to
follow messages even without cover traffic, I think it is fair to
point out that adding cover traffic doesn't help much against an
eavesdropper who can monitor the whole network.
The real solution, as suggested by the diagrams, is to have a large
volume of true remailed messages in the network - messages which go to
a wide variety of people.  Individual users can protect themselves to
some extent by serving as cover-traffic generators and bit-bucket
receivers; but this does not protect other users who are not able to
perform these functions.

@_date: 1994-01-27 20:57:47
@_author: Hal 
@_subject: Remailing TO anon.penet.fi?! 
I set up my remailer on hfinney at shell.portal.com to block the password
address at anon.penet.fi just so nobody could set a password.  I also
set a nickname, something like "cypherpunks anonymous remailer".  I did
this some time ago but I think it is still active.  So you can remail
at least from my remailer to anon.penet.fi.

@_date: 1994-01-28 21:38:22
@_author: Hal 
@_subject: 2-way anonymous via SASE 
Jim's idea looks good for anonymous communication.  It is basically
the same as the one Chaum describes in his 1981 Communications of the
ACM paper.  CACM is one of the most widely available computer science
journals so I would encourage people interested in this topic to go
to the local university or junior college library and xerox it (CACM,
vol 24, p. 84, February, 1981).
The one difference is that Jim's B, C, and D are conventional rather
than public keys in Chaum's system.  This could be slightly more
We have had a primitive SASE capability available and documented on the
cypherpunks remailers for over a year.  Karl Barrus and I have written
scripts and programs to facilitate creating SASE's - you just type in
your address and a list of remailers to use and out comes the SASE block
which goes at the top of the reply message.
The weakness of the present system is that it lacks the B's etc. for
extra encryption at each stage.  That means that someone who can observe
net traffic can match up incoming and outgoing messages because the body
does not change, only the address portion changes.  (Of course, such
matching is already possible for the non-batching remailers based on
simple timing, which includes almost all of them.)
One other caution Chaum raises re the SASE's is that they should not be
used more than once.  If they could be it would be possible to send in
multiple messages using the same SASE and notice which output address
was similarly duplicated.  This non-reuse actually has to be enforced by
the remailer, else the Opponent can eavesdrop on an SASE-based message
and replay the address portion.

@_date: 1994-01-31 17:50:27
@_author: Hal 
@_subject: 2-way anonymous via SASE 
Unfortunately, return-paths are not exactly the strong point of the
current cypherpunks remailers :-).  That is what much of the discussion
in this thread has discussed: how to best allow for convenient but secure
return paths.
Your syntax is a bit hard to follow here, but I'm guessing that you are
proposing such a remailer as a way of providing for return paths.  The
remailer would remember the message-id's of outgoing messages, and would
remember where those messages came from.  Then if a reply came back for
one of those message-id's it could send it to that remembered address.
There were some proposals along these lines made last year, or maybe back
in 1992.  This scheme doesn't seem to generalize well to multi-remailer
paths.  Also, I think people would be nervous about having remailers keep
this kind of out-to-in mapping information.
It is interesting that it is theoretically easy to make a fake PGP
key which matches someone else's "displayed keyID", the low-order
24 bits of the RSA modulus.  If someone did this they could make a
fake PGP key for you with ID B75699, then fake finger and they would
be able to substitute their own key for yours.  Rather than displaying
your key ID it would be better to display your key fingerprint, visible
with "pgp -kvc", although it is 128 bits rather than 24 bits so may be
a bit cumbersome for a signature.
Here is how you make a key which matches a given low-order 24 bits.
Pick a random prime p.  Take the low order 24 bits of p and divide into
the given 24-bit "displayed keyID", mod 2^24, to get qx.  Now you
simply need to find a prime q whose low order 24 bits are qx.  This
can be done by picking a random q = qx + rand()<<24 (e.g. a random number
whose low-order 24 bits are qx), and repeat q += 1<<24 testing each
q for randomness.  This can even be sieved for a very fast test similar
to what PGP does.  It would be an interesting exercise to write such
a routine.
I understand there is already at least one 24-bit collision on the
public key servers, not unexpected given a few thousand keys.

@_date: 1994-07-01 18:30:23
@_author: Hal 
@_subject: Physical storage of key is the weakest link 
Here is a little-known fact.  In fact, I had forgotten it myself until
what Tim said reminded me.  Your PGP secret key file is partially encrypted
using IDEA keyed with the hash of your pass phrase.  But some fields are
left in the clear.  In particular, the number of bits in p and q is left
exposed, as is the number of bits in d, the decryption exponent.
Now, this is not really a big deal.  Usually with a 1024-bit key p and
q will both be 512 bits long, so knowing this for sure doesn't add that
much information.  And I don't think that knowing the exact number of
bits in the factors will help with the factoring when the two factors are
about the same size.  Nevertheless it does represent an information leak
that many people may not be aware exists.
One way an attacker might exploit this is as follows.  Suppose he wants
to do an exhaustive search of pass phrases.  As Tim said, a lot of people
may have ones which are easy to guess.  How does he know when he's guessed
correctly?  The secret key has a checksum (in the clear).  After decrypting
all of d, p, q, and u, PGP accumulates a checksum as it does this and com-
pares it with the checksum stored in the secret key.  If they match, PGP
(or the cracker) knows that he has used the right pass phrase.
This requires decrypting all four of these numbers, a total of about
320 bytes.  But he can do a provisional check much faster by using the
in-the-clear lengths.  Just decrypting the first byte of each MP number
allows you to see immediately what the bit length of the resulting MP
value will be since they are stored in MSB form.  For the most extreme
case, suppose the length of p were one more than a multiple of 8, say
505 bits.  Now we decrypt the first part of p and see if the first byte
of the decryption is exactly 1.  If not, we can know immediately that we
have the wrong pass phrase and move on without doing any more IDEA op-
erations.  This will immediately reject 255 out of 256 wrong pass phrases.
I don't know how much of a speedup you would actually see from this; IDEA
has a setup phase and you still have to run MD5 on each pass phrase.
But possibly it could be significant.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-07-02 16:11:38
@_author: Hal 
@_subject: MAIL: chained remailing strategy 
Several months ago arch anti-cypherpunk Larry Detweiler, about to lose
his account, set up a daemon to post an edited version of Tim May's old
"Blacknet" spoof to random and inappropriate usenet groups.  ("Blacknet"
was Tim's hypothetical cryptographically anonymous black market for il-
legal information exchange.)  He happened to use my remailer as a single
hop to the net.  I logged in and found my mailbox full of people complaining
about this message which "I" had sent to sci.med.diabetes and such.  So
I added a line to the .maildelivery file so that any message with the
subject line Detweiler was using would be dumped to a file rather than
forwarded.  This is the only kind of logging I do, other than recording the
date and time at which the remailer sends each message, the source of my
previous posting.
In the year and a half that I have been running this remailer, I have
been asked probably a dozen times if I could tell where some abusive
message comes from.  I am not able to do so since after the message has
been sent the information is gone.  At best I could insert a log if it
looked like something really vicious was going on.  Even then, if the
sender used chaining then every remailer on the chain would have to
anticipate and log his messages (or all messages).  My general practice
is to add every person who complains about receiving an unwanted
message to my list of outgoing blocked addresses.
I chose the ~512 bit key in recognition of the limited security provided
by my remailer.  Like every automated remailer, the decryption key has to
be on the system essentially in cleartext.  I don't come up and type in a
pass phrase for every message which goes through.  This means that anyone
who can hack Unix can learn my remailer secret key.  Under the circum-
stances, there would be no point in going with 1024 bits, and in fact it
would give an entirely false and unjustified sense of security.
I can't take any credit for either the promptness or reliability; that is
a function of my internet service provider, the Portal system.  Frankly,
I have not been too happy with the reliability and availability of the
system; mail and news seem to fail for 24 to 36 hour periods every month
or so, and the system seems to have unscheduled downtime a few hours a
week.  But I suppose almost everyone has complaints like this.  The one
thing I will give the Portal people high marks for is that they have never
said anything about my remailer.  I'm sure some of the nasty letters I have
received after inappropriate mail and news postings have been cc'd to the
sysops here, but I haven't heard one word.  I understand that at the
"Hackers' Conference" a couple of years ago the owner of the Portal system
endorsed the concept of remailers.  (This was reported by Tim May.)  Perhaps
he is silently offering me some sort of protection.  Whatever the reason,
I am pleased that I have been able to keep the service going this long.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-07-03 17:53:54
@_author: Hal 
@_subject: Password Difficulties 
(I tried posting on this a couple of days ago, but I never saw the
message.  Apologies if this is a rehash.)
Kent Borg makes a good point that our 128-bit IDEA keys are generated by
pass phrases of typically a few dozen bits.  He suggests doing things to
slow down the process of turning a pass phrase into a key, perhaps by
iterating MD5 multiple times.  A similar thing is done in the SecureDrive
software as well as in RSA's Public Key Cryptography Standards (PKCS).
The problem is that this doesn't help all that much.  If you slow down
the process by, say, a factor of 1000, that is about equivalent to adding
10 bits of entropy to the pass phrase (either way would slow down the
searcher by that much).  10 bits is perhaps nothing to sneeze at but it
doesn't really solve the problem.  I suspect that Kent is right that most
pass phrases don't have over 50 or 60 bits of entropy, far below the 128
bits of protection that we like to think IDEA is giving us.

@_date: 1994-07-17 16:34:51
@_author: Hal 
@_subject: Remailer Detweiler filtering 
The issue is not a desire to deprive Detweiler of the benefits of anonymity;
it is that he appears to do things which are designed to bring down the
remailer network.  By intentionally mass-posting to inappropriate news-
groups, and injecting exponentially-growing messages into the remailer chain,
he seems to be trying his best to deprive the benefits of the remailer net-
work to others.  This is, of course, in accordance with his well-known
position against anonymity.
If Detweiler succeeds, Nobody won't get to post anonymously (so to speak)
anymore.  I know that it is unfortunate that the remailer network is so
fragile that a lone crackpot is a significant threat, but presently that is
essentially what the situation is.
Pragmatically, I think that filtering Detweiler is more likely to provide
privacy than not doing so.  I understand the charges of inconsistency but
IMO the particular facts of a case are a better guide to the proper action
than abstract arguments.
If chained, encrypted remailing techniques are used, it is not a question
of "exposing" anyone.  Detweiler may be blocked from the network (if everyone
agrees to do so) but it won't be possible to find out just what he is being
blocked from doing.  Had he been sufficiently careful in the first place
there would not necessarily be any way of knowing who exactly was producing
the offensive messages.  In that case I believe most of the remailers would
no longer exist.
I suggest, then, that you run a remailer (it only costs $20 a month on the
system I use), and publicize the fact that Detweiler can use yours with
impunity.  Set up a mail-to-news gateway that other remailer operators can
use so that they don't have to worry about the consequences of abuse.
It's easy to talk about sacred ideas, but perhaps not so easy to keep an
unpopular and misunderstood remailing infrastructure in place.  "Xenon"
also accused us of hypocrisy, started up a remailer, and stopped it in just
a couple of days faced with these kinds of problems.
Detweiler is free to send any messages he likes; his service providers are
free to continue or terminate his accounts as they see fit; and remailer
operators are free to establish whatever policies they like for message
handling.  What better implementation of free speech could you want?
Hal Finney
hfinney at shell.portal.com

@_date: 1994-07-17 16:58:55
@_author: Hal 
@_subject: Key length security (calculations!) 
solman at mit.edu writes (quoting someone else initially):
I suspect this protocol is covered by the Diffie-Hellman patent, which is
quite broad, covering many sorts of key exchanges.  Diffie-Hellman is now
owned by PKP, the sister company to RSA.  If so, Shamir has not undercut his
own financial interests by this work.  (Also, this does not obsolete PK
since it requires several exchanges before communication can occur, making
it inappropriate for high-latency communications, such as for most email.)

@_date: 1994-07-18 09:30:21
@_author: Hal 
@_subject: Key length security (calculations!) 
As I recall, the patent is very general.  A sends a message to B, B sends
one back to A; this goes on for a while, then both sides feed their messages
into a black box and, presto, out pops a suitable encryption key which is the
same for both sides, but is such that no eavesdropper could feasibly produce
the key.  It's been a long time since I looked at it, though.  I would welcome
some verification.
(I should also add that my comment about Shamir not undercutting his own
financial interests was apparently incorrect if he has actually sold out his
interest in RSA as reported.)

@_date: 1994-07-20 16:35:02
@_author: Hal 
@_subject: Non-determinism forever. (was -- Re: GUT and P=NP) 
When I first heard about P and NP and such, I made a common mistake, one
which I think underlies a lot of the misconceptions people have.  I knew
that P meant "polynomial time" and understood pretty well what that meant,
but I mistakenly jumped to the conclusion that NP meant "non-polynomial
time", the complement of P.  It does not, of course; it means "nondeterministic
polynomial time" as others have described.  Basically, if you could _check_
an answer to a problem in polynomial time the problem is in NP, as others
have described here.

@_date: 1994-07-20 21:19:24
@_author: Hal 
@_subject: Card Playing Protocol? 
My system has been up and down last couple of days, and what with this
and the small downtime on toad.com I'm not sure if my message got through
on Karl's idea to use blackjack as an example crypto based card game.
First I'll mention that I was browsing rec.gambling this morning and I
saw several references to poker games being played over IRC.  They had
an init file posted which defined macros so you could say "/raise",
"/fold", etc.  This might be something which could be incorporated into
a good crypto-strong version.  (A corollary would be to hack the existing
code so you could win every time if possible.  I believe they are relying
on a trusted server at a well-known host.)
The point I had made earlier about blackjack was that Karl's idea is good
if there is just one player and one dealer.  The dealer shuffles and
publishes a hash of the deck so that he is commited to it.  Then they
play through the deck.  At the end the player can confirm that the hash
of the played cards in sequence matches that originally published.  Since
the dealer has no discretion in blackjack this works well and it is much
simpler than the more general protocols.
The one problem I saw was that if there were more than one player, the
dealer and one or more players could collude to cheat the other players.
The dealer could tell his players what the upcoming cards were, and they
could hit or stand in such a way as to hurt the other players.  The sol-
ution I proposed was a little bit complicated, but still quite a bit
simpler than the full-generality card-playing protocols, I think.  You
just have the players and dealer cooperatively choose the next card to
be played via a joint coin-flipping-type algorithm.  By using the English
version of blackjack, in which all cards can be dealt face-up, everyone
learns each new card at once and there is no opportunity for any players
to know what the cards will be ahead of time.
Of course, blackjack is not nearly as popular as poker, so perhaps a
more general implementation is desirable for this reason.

@_date: 1994-07-22 08:52:46
@_author: hfinney@shell.portal.com 
@_subject: Voice/Fax Checks 
It's pretty clear that credit cards don't work for some of the transactions
people want to do:
1) one-cent and fractional-cent charges for connecting to a useful Web
page or ftp site.  A useful resource like this wouldn't have to charge much
on a per-user basis to fund the equipment and people.
2) Transactions with individuals or small companies who are not VISA clients.
It's not that easy for a mail-order shoestring startup to get the ability to
accept VISA cards.  Because of the danger of fraud, the credit card companies
like to see a storefront and/or some previous history.  Someone who writes a
nifty PGP shell and wants to sell it for $10 per will have this problem.
3) People who don't like giving out their credit card numbers to an unknown
email address.  This is the flip side of the above.  The danger of fraud is
always present, and the more people I've given my card number to, the more
chance that I'll get burned.  Of course most states have protection laws in
place, but it's still going to be a major hassle.
Now, 2 and 3 can probably be addressed by electronic checks, and I think the
secure Mosaic announcement included that possibility.  I suspect that echecks
are a considerably stronger competitor to ecash than today's credit-card
infrastructure.  For one thing, an echeck can be sent in the clear, while
ecash has to be sent encrypted; an eavesdropper can spend ecash but not an
Example 1, the fractional-cent transaction, will be tough to address by any
technology IMO.  Even with ecash, there are a lot of questions.  Is it on-
line or off-line?  Does the server actually try to validate each half-cent
or does it just trust people?  If the latter, how much fraud is likely, and
how would we track down and penalize the half-cent counterfeiters?  Solving
these problems is going to add overhead which will make it hard to deal with
such small sums efficiently.  How many cash businesses sell low-value items
for pennies today?  Not many.
No, I don't think you can.  Ecash can generally be cashed by the bearer
so it has to be sent through secure mail.  That is why I was saying that
echecks might be better for those purposes.
I don't understand the Telescript agent world well enough to judge whether
it would drive a market for ecash.  I have the impression that at least with
the initial implementations the agents will not be on the Internet as we
know it but rather on a separate AT&T network of special servers.  So they
may not have much impact for a while on the "net" as we know it.

@_date: 1994-07-22 09:04:11
@_author: Hal 
@_subject: Double DES calculations 
I missed the start of this double-des thread due to system problems and
being gone, and I've never been able to pick up the main point since.  It
sounds like some kind of meet-in-the-middle attack is being discussed.
It is true that with current technology MITM generally seems more costly
in terms of space than time.  However, I have seen references to techniques
which shift this tradeoff some, costing more time and less space.  Un-
fortunately, I can't remember where I saw them!
I'll give you one similar example, though.  I think this is the technique
used in Pollard "rho" factoring.  You have an iterated series, x=f(x), and
you want to know if it has any cycles, any values which are eventually
repeated.  At first glance you might think that to look for a cycle of
length N you would have to store N values of the series and check each
value for a match, taking order of N in time and space.  The Pollard tech-
nique instead runs two copies of the iteration at once, one twice as fast
as the other: x=f(x) and y=f(f(y)).  Each time you just compare x and y
for a match.  This takes about twice as long but uses no memory.
The moral is, be cautious about feeling safe against MITM attacks purely
because of memory limitations.  If you don't have protection on the time
costs as well there may be a tradeoff which can kill you.

@_date: 1994-07-22 12:13:21
@_author: Hal 
@_subject: Voice/Fax Checks 
This seems like a good approach for a lot of cases.  You end up having
three classes of transactions: small, medium, and large, with slightly
different strategies for each.  For large, you do on-line checking; for
medium, you detect double-spending after the fact and use crypto to find
his identity; and for small you set up an account and dip into that a bit
at a time.  I am curious about whether you are focussing more on some size range
in your plans.
One problem I still see is the small transaction where you don't tend to
use the same provider again and again.  On the net there are a few sites
(well, quite a few, I suppose) which are heavily used, but there are a
lot of places I might like to just browse through.  Paying a penny per
site isn't going to bother me much, but if I have to set up an account
for each one ahead of time I'm probably not going to bother.  So I still
think there are problems with the fractional-cent-per-web-site model
which I have been hearing about.
Is this an approach where you determine to whom you will be sending the cash,
then make it into a "check" which can only be spent by that recipient?
Doesn't that require the bank's (cash issuer's) help?  Or is this something

@_date: 1994-07-22 20:35:48
@_author: Hal 
@_subject: Voice/Fax Checks 
How, though, would the ftp site which wants to know whether I'm "good for"
the one cent charge to download PGP do so?  Does it have to check with an
agent on the net somewhere which will vouch for me?  Aren't the communica-
tion costs then the same as an online system?  Or does it extend me the
one cent as credit and hope that I really do have an account with that
agent (or bank)?  Then that seems like a basic off-line system.  So I don't
understand the role of agents in solving this problem.
I find it confusing to imagine a situation where large numbers of goods
are sold for very low prices.  Will people tend to cheat, since it's easy
to get away with it (all those systems offering you one cent credits), or
will they tend to be honest, since the per-use cost is so low (but perhaps
adds up over a month)?  I suspect that nobody will pay if there is a way
they can use the servers without paying, even though they are only saving
a fraction of a cent each time.  Maybe that's just my jaundiced view of
human nature.

@_date: 1994-07-22 22:46:23
@_author: Hal 
@_subject: Double DES calculations 
I don't know how to speed this up.  Pollard rho was a cautionary tale of
how sometimes time/space tradeoffs exist.  If the main cost of double-DES
is in space but the time cost isn't that bad, then if there were such a
tradeoff it could be dangerous to use it.
Most of the time-space tradeoffs that I can think of for a basic MITM
attack like this are pretty costly.  For example, instead of trying all
the keys on both sides you could try just half the keys each time.  This
would take only half as much space but up to four times the time.  You
could also do some hashing to save space at the cost of false positives and
more time.  Again, the point is not so much that double DES is weak, but
more that if its strength is solely due to space costs that gives much
less of a good feeling than if you had an algorithm that was strong both
in space and in time.

@_date: 1994-07-23 08:30:44
@_author: Hal 
@_subject: Card Playing Protocol? (fwd) 
I thought of a simpler way to attack the blackjack protocol proposed
by Karl, where the dealer shuffles the cards, commits to a hash, and
then the player checks the hash at the end of the deck.  Simply, this
allows the dealer to stack the deck.  He can put the cards in any order
he wants, claiming he is shuffling them, commit to that, and the player
will confirm that the hash matches at the end.  Meanwhile the dealer wins
every hand.  So this won't do.
An easy fix would be for the player and dealer to mutually choose a random
seed for a PRNG that is then used in a specified algorithm to choose the
cards of the deck.  The dealer would commit to the hash of his part of
the seed but would not reveal his part until after the deck is played out.
The player's seed and the dealer's are then combined and the player can
reconstruct the sequence of cards which should have been played.
Again, this is only suitable for a one-dealer-one-player game since other-
wise the dealer can collude with some subset of the players and tip them
off to what cards are coming up.

@_date: 1994-07-23 15:15:37
@_author: Hal 
@_subject: Voice/Fax Checks 
I had the impression from that paper that with transferred ecash, a person
earlier on the trail could always recognize the cash even at a later point.
This followed, Chaum claimed, from the need to detect double-spending.
I'd be interested to hear whether you get this from that paper as well.
In the real world, I'd guess that most cash is not transferred very much
before it goes back to the bank.  I get money from the ATM and spend it
at the grocery store, which takes it to the bank every day.  The smaller
bills may circulate a few times because they go back out as change, but
even there I'd guess there are not many transfers.  So there are two
possible lessons from this: one is that perhaps transferrable cash is not
very necessary; or the other is that it's not a significant problem if
cash grows somewhat each time it is transferred because it probably won't
get very big.

@_date: 1994-07-24 09:54:46
@_author: Hal 
@_subject: legally circumvent the Sept 1,94 Legal Kludge, Program Part 000 
One thing I haven't understood with this "LEGAL_KLUDGE" business, where
the command line is kind of cumbersome.  Can't you get the same effect
by setting the parameters in the config.txt file?  If so you just add
two lines and forget it.  I haven't looked at PGP 2.6 so I don't know
why this wouldn't work.  It would certainly seem to simplify things.

@_date: 1994-07-25 20:51:10
@_author: Hal 
@_subject: Voice/Fax Checks 
OK, but one of the main characteristics of electronic cash is its anonymity.
If we don't care about serial numbers we can just use an RSA-signed message
from the bank saying "I'm worth $1.00" as the cash (at least in an on-line
system).  The whole reason we go through the blinding rigamorole is to make
it so that the cash is unrecognizable after transfer.  That is why I keep
raising the issue about recognizability.  You are probably right that most
people wouldn't care, though.

@_date: 1994-07-25 22:51:08
@_author: Hal 
@_subject: My anonymous remailer 
This is a pretty radical idea, but it is tempting.  Like other remailer
operators, I get tired of fielding complaints.  I don't look at the messages
when they go through, but incorrect ones end up in my mailbox, and I may
see them by accident.  So many are obscene, name-calling, etc., that it
kind of makes you wonder after a while whether the service is worthwhile.
Of course, I do tend to see the "dregs", users who are clueless about using
the service.  Hopefully the more capable users are doing something a
little more worthwhile with it.
Then there are the constant moral dilemmas.  I got flamed pretty well
for outing Detweiler on his "Death to Blacknet" spam.  I try hard not to
look at the messages, deleting bounced mail just from the headers, etc.,
but it gets to be a pain.  In some ways Graham's suggestion to just say,
screw you, I'm going to feel free to publicize everything that goes through
my remailer, is tempting.
Still, though, I think this would do more harm than good.  I get about
20 to 40 messages a day through my remailer, and only 5 or 10 of those are
encrypted.  Switching to a policy that would require chaining and encrypt-
ing to make it useful would make it a lot harder to use the remailer.  If
I have faith that the remailer is doing some good for someone, somewhere,
then it would be bad to take that away from the people who are using it
now.  (I just did a complete search of the news spool directory here for
postings from my remailer, and found only four, two of which were duplicates
of a claim that cable companies can listen to what you are saying in your
living room.  I wonder what the traffic through my remailer is?)
The other problem I see with Graham's idea is that I'm not sure the
technology is there to provide good security in the face of this much
information.  Not many of the remailers add delay, and a lot of people don't
like it when they do.  In that case it may be easy to figure out what
path even a chained encrypted message took.  Even the delaying remailers,
if they published message sizes, would usually reveal their in-to-out
correspondance.  So I think it is premature to do this.  Until we have
remailers which can support cryptographically strong message padding
with standard message sizes, running on un-hackable systems with delays
and batching to confuse the in-out relationships, it would be counter-
productive to do what Graham suggests.
Even once we have it, there is still the question of what the remailer
network is for.  I think news posting is responsible for a large fraction
of the complaints.  But does it also provide much of the utility of the
technology?  Do people use remailers for ordinary email, or just for
broadcast-type messages?  Unless we understand what the market is for the
service it's hard to know what features to provide.  In particular, if
cleartext output is prevented, how much does that impair the usefulness of
the network?  My instinct is that it hurts a lot, although it would be nice
for the operators since it would eliminate most sources of complaints.

@_date: 1994-07-26 09:08:13
@_author: Hal 
@_subject: e$ : NetBank legality 
I'm curious about the legality of NetBank in the context of our earlier
discussions about demand deposits and Chaum cash.  These people will take
your money and give you electronic tokens, and they will take the tokens
and give you cash (minus 20%).  Does this sound legal?  Are they a bank?
I wonder what their tax liabilities are.  Sales tax on selling the tokens?
Is this a barter system?  If so, they're supposed to get SS and such.
Maybe you have to give that information if you sign up as a vendor, but
legally I'd think ordinary users would have to be reported to the IRS
as well, and it doesn't sound like they're doing that.
This whole thing sounds pretty questionable legally.  It will be interesting
to see how it comes out.

@_date: 1994-07-26 13:53:40
@_author: Hal 
@_subject: New Threat on the Horizon: Software Key Escrow 
Look at the success RSA has had with Apple building their certification
structure into System 7 Pro.  There was discussion on sci.crypt about
whether PGP (or any non-hierarchical certification structure) could be
used, and the consensus seemed to be that the hooks aren't there.  If you
want to inter-operate with this software, which will presumably be widely
available in the future, you will have to join the official certification
hierarchy.  So long, web of trust.
Now, this approach does seem vulnerable to reverse-engineering the OS,
getting in below the software layers which you are supposed to use, to
defeat the restrictions the software is trying to place on you and have
built-in encryption of your choice.  But this will be a big job.  Still,
maybe the best approach when MSoft comes out with this encryption built-
in will be to get software out which will bypass it while still using
the other value-added features like hot links, automatic encryption/
decryption, etc.  Otherwise they may well succeed in getting a de facto
standard into place which does not protect individual privacy.

@_date: 1994-07-28 08:27:31
@_author: Hal 
@_subject: Just say NYET to censors 
As a parent, I can sympathize with the desire to shield our children from
some of the raunchier material on the net.  Many parts of the net are more
"Animal House" than "Public Library", and you don't necessarily want a
nine-year-old girl learning about sex from a.s.b.
I think there are real problems with Nathan's proposal, though.  Questionable
material on the net is not tagged with an R rating.  Newsgroup categories
could be rated by the parent, but there is nothing to stop cross-posting.
Trying to put ratings on each email message, news posting, web site,
MUD (although some MUDs do have adult areas), IRC channel, etc., is just
not practical.  No censor has that much free time.
Another problem is that even the "safe havens" where minors congregate
may not stay as pure as we would like.  Believe it or not, teenagers of
below the age of 18 are actually interested in sex.  In fact, many, perhaps
even a majority, are not virgins.  It's going to be necessary to censor
the kids' posts more than any others if you want to keep them from talking
about what they want to talk about.
For a good example of these problems, see that paragon of censorship,
Prodigy.  My kids use Prodigy a lot.  They are pre-teens and I don't
worry too much about what they will see on this family-oriented service.
Still, the "Teen" BBS on Prodigy gets a little steamy sometimes, even though
each and every message is reviewed by a Prodigy censor before it can be
posted (at least, that is how it worked at one time.  They may have auto-
mated filters now.).  The "fashion" topic, for example, often degenerates
into discussions of how the girls look in their hot lingerie.  Basically,
the kids are constantly pushing the limits.  Since every parent has their
own ideas of where these limits should be, Prodigy ends up with sort of a
"least common denominator".
I'd like to turn my kids loose on the Internet, let them surf the Web and
the other resources available.  They are very computer-aware and I know
they would get a lot out of it.  But the way the net is now I don't think it
would be responsible parenting to just let them loose, at least not for a
few years.  So, as I said, I sympathize with Nathan's problem, but I don't
think a good solution is at hand.  For now I think private, family-oriented
networks are a better place for young kids.
Hal Finney

@_date: 1994-07-28 20:45:12
@_author: Hal 
@_subject: What can one do for remail operators? 
Hmmm...  If you could do this, you wouldn't need remailers, would you?
This is what remailers are for.

@_date: 1994-07-28 20:50:33
@_author: Hal 
@_subject: Remailer ideas (Was: Re: Latency vs. Reordering) 
The real problem to be solved is this: given a set of input messages,
and a set of output messages which represent decryptions of the input
ones (along with perhaps a bit of extra processing), make it impossible
to tell which output messages go with which input ones.  Clearly, if the
messages are of widely disparate sizes, and output messages are similar
size to input messages, that won't do.  That is where the idea of padding,
and of standardized messages sizes, comes from.

@_date: 1994-07-28 21:07:26
@_author: Hal 
@_subject: Catch-22 
That's interesting that they went to the effort to track you down.
Do you have any idea of how they found out about your package?  Was
that the one that started all the fooferaw on sci.crypt with PRZ
upset about someone shipping a modified version of his program?
I don't know what the legalities are of registering when you are just
doing this stuff for fun.  Talking to a lawyer will probably cost you
several hundred dollars but that may be the wisest course.  It's not
impossible that you could be charged with felony violation of the Arms
Export Control Act, with penalties up to one million dollars and ten years
in prison.  The few months I spent doing a little work on PGP in my
spare time have cost me $1000 in legal fees just to retain a lawyer and
have him keep track of the possibility of prosecution.  It's sickening,
but you can't be too careful these days.  You can certainly see where
Pr0duct Cypher and our other anonymous/pseudonymous posters are coming
from.  Good luck!

@_date: 1994-07-31 17:22:00
@_author: Hal 
@_subject: Crypto Takes a Holiday (NYET, Children, etc.) 
In fairness to the original proposal, it's worth remembering that his
purpose was not specifically to impose censorship on the net, but rather
to protect BBS operators (and net access providers) from legal liability for
providing pornographic and other questionable material to children.
Granted, his method for doing so did amount to a lot of laws and censor-
ship, and I can't agree with that any more than others here.  But the problem
isn't going to disappear under an onslaught of rhetoric.  As I said, I
can sympathize with concerned parents, and although my personal philosophies
would not support a censorship-based solution, not everyone will feel as
There is a movement afoot to hook schools up to the net, part of the general
"superhighway" initiative.  This is going to raise the public profile of the
adult material on the net and increase pressure for ways to limit the
access of youngsters to it.  One response we can have is to dig in our heels
against any censorship, and say, "don't put your school on the net if you
don't want your kids reading about bestiality."  From my experience, this
would be equivalent to saying "don't put schools on the net."  That will not
be a politically acceptable solution.
I really don't know what the ultimate resolution of this conflict will
be.  IMO, the Internet as it stands today is incompatible with the
conventional mores of much of society.  Either the Internet will be
bowdlerized, or perhaps split into "X-rated" vs "G-rated" sections.
Maybe a completely new internetwork is needed, one with more controls and
limitations.  Then perhaps the current internet could continue to exist
in close to its present form.
I know that some people are optimistic that the Internet will change
society rather than vice versa.  They hope that as more and more people join
the net that they will become tolerant of the much wider range of views and
practices than are common in most people's home towns.  But I don't think it
will come out this way.  Society is a lot bigger than the net, and the
character of the net will inevitably change as the membership changes.
In some ways this is reminiscent of our earlier debates about whether
society would be able to prevent the advent of widespread lawbreaking
due to Tim's conception of "crypto anarchy."  I have always been
skeptical that our software and ideas can really succeed in the face of
strong social opposition.  For similar reasons I think that the net
will be cleansed of pornography if people feel strongly enough about
it.  So I do see a lot of connections to crypto issues in this

@_date: 1994-06-03 17:45:58
@_author: Hal 
@_subject: Black Eye for NSA, NIST, and Denning 
It was my understanding from what was posted here and on sci.crypt that
Clipper chips were only going to be given to phone manufactureres who
had an approved design.  This would mean no pre-encryption of messages,
and no hacks to defeat the LEAF block, would be allowed.
It's not clear to me whether the same restrictions apply to the use of
the Tessera plug-in card.  It sounds, from what was posted here, like
Blaze was able to feed sample LEAF's at his card until it accepted one.
Is that correct?  If so, apparently users of such cards have access to
low-level functions which would allow this kind of trick to be used.
Unless there is some way to get a supply of Clipper chips to allow you
to make Clipper-compatible phones which still protect privacy, then
all this theorizing is not too useful.
I am inclined to agree with Deadbeat that if you want to give the
impression that you are using Clipper on your phone calls (to blend in,
to keep a low profile) but at the same time you want the key escrow not
to work, then pre-encryption is a superior strategy to Matt Blaze's
idea.  Matt's trick only hides the session key if both sides are using
it.  And even in that case it appears to require particular key manage-
ment techniques that may not be standard (one side provides the session
key, or it is negotiated but both sides wait 30 minutes to talk).  So it
does seem that some pre-arrangement will be necessary in practice to allow
Blaze's approach to successfully hide the session key.
It's true that the Blaze technique hides the unit id, preventing traffic
analysis.  But that could be a negative.  Playing paranoid, suppose that
Clipper traffic is routinely decrypted with the family key.  Then the
fact that someone is using bogus LEAF's might be evident because the
unit id would change with each call.  Using pre-encryption makes you look
like a good little boy until they bring out the escrowed keys.
(Of course, they're not supposed to troll LEAF's, any more than they're
supposed to break escrow, but I'm assuming that the former will be easier
and more likely than the latter.)

@_date: 1994-06-23 08:28:40
@_author: Hal 
@_subject: Thoughts on the NSA's correction to SHA 
Bruce Schneier may be correct about NSA's views, but I think the
NSA gives itself too much credit.  There was another very significant
event in the 1970's which IMO played at least as much of a role in
the increased interest in cryptography as the DES.  This is, of course,
the invention of public-key cryptography.
I know that my own interest in crypto can largely be traced to the
Scientific American column by Martin Gardner in which he introduced
the RSA system (along with the famous RSA-129 number which was just
factored).  PK crypto combines simplicity with surprise to produce
results which attracted a lot of attention and interest.  In comparison,
the development of DES was of relatively little interest outside of the
few specialists in the field.  I would suggest that PK crypto did more
to attract attention to cryptography and to lure people to the field than
did DES.
If you look at the papers in the crypto conference proceedings you will
see a number on cryptanalysis of DES and on DES-like systems, especially
in the early days; but there are generally at least as many on PK and
related ideas such as zero-knowledge.  Much of what we think of as
"modern cryptography" owes itself more to the kinds of information
manipulation provided by PK than to the DES, which is often relegated
to the role of a "black box" in a crypto protocol, interchangeable with
IDEA or any other conventional cypher.
It's more defensible to argue that strictly from the NSA's goal of reading
other people's mail, DES was harmful by revealing a general approach for
constructing strong conventional cyphers.  But as far as stimulating the
field of cryptography in general, I think PK has played a more important
Hal Finney
hfinney at shell.portal.com

@_date: 1994-06-23 22:22:34
@_author: Hal 
@_subject: WARNING! 
I'd like to see PGP eventually remove artifical constraints on key sizes.
The MP package in PGP uses fixed-size buffers, but a more general approach
using variable-sized buffers is used in other packages such as gmp.  These
do not force you to use compiled-in limits on sizes like this.  The basic
multi-precision integer data structure in PGP does have a limit of 64K bits
but that is probably not worth changing.
Remember that it is the owner of a long key who pays most of the price of
using it.  He is the one who has to wait through lengthy signs and decrypts.
The signature-checking and encryption which other people do just involve
a few multiplications and should be pretty fast even for sizable keys.  So
I don't see any reason PGP should take this decision out of people's hands.
I'm still running 2.3.  I figure that when the time comes I'll hack it to
accept 2.6 messages.

@_date: 1994-06-24 10:00:53
@_author: hfinney@shell.portal.com 
@_subject: WARNING! 
After the RSA-129 factoring there was considerable discussion on sci.crypt
about how much harder a 1024 bit key would be using current algorithms.
There was some disagreement, but it did not seem that a 1024 bit key would
be good for 10000 years; as I recall, the time scale was more like a few
decades before it would fall to an attack as expensive as RSA-129.  Larger
keys with 2K bits, OTOH, were good for thousands or millions of years
(of course it's hard to extrapolate computer power out that far).  Does
anyone have more precise numbers?
People have been talking as though the only possible improvements
to factoring algorithms would be to jump to polynomial or near-polynomial
time.  Obviously it is equally possible that improvements will occur as
they have in the past, reductions to the exponents or constant factors but
still an exponential algorithm.  In such a scenario it is very plausible
that 1K bit keys would be unsafe while keys of a few K would be fine.

@_date: 1994-06-30 22:23:03
@_author: Hal 
@_subject: MAIL: chained remailing strategy 
Here are the times at which my remailer has received messages over the
past week.  (This is the only form of log which I keep, except for messages
titled "DEATH TO BLACKNET".)  In return for this information, please provide a
histogram showing usage as a function of time of day.  Thanks -
Hal Finney
Thu Jun 23 06:41:56 PDT 1994
Thu Jun 23 07:08:28 PDT 1994
Thu Jun 23 07:08:50 PDT 1994
Thu Jun 23 07:12:28 PDT 1994
Thu Jun 23 10:56:44 PDT 1994
Thu Jun 23 12:20:43 PDT 1994
Thu Jun 23 12:29:47 PDT 1994
Thu Jun 23 13:09:32 PDT 1994
Thu Jun 23 13:29:29 PDT 1994
Thu Jun 23 13:37:04 PDT 1994
Thu Jun 23 13:38:07 PDT 1994
Thu Jun 23 14:05:51 PDT 1994
Thu Jun 23 16:05:24 PDT 1994
Thu Jun 23 16:05:52 PDT 1994
Thu Jun 23 17:26:52 PDT 1994
Thu Jun 23 18:09:30 PDT 1994
Thu Jun 23 18:10:27 PDT 1994
Thu Jun 23 18:12:33 PDT 1994
Thu Jun 23 18:12:40 PDT 1994
Thu Jun 23 18:13:31 PDT 1994
Thu Jun 23 18:13:44 PDT 1994
Thu Jun 23 18:25:40 PDT 1994
Thu Jun 23 18:25:52 PDT 1994
Thu Jun 23 18:26:44 PDT 1994
Thu Jun 23 18:39:46 PDT 1994
Thu Jun 23 21:02:39 PDT 1994
Thu Jun 23 21:02:40 PDT 1994
Thu Jun 23 21:35:28 PDT 1994
Thu Jun 23 21:37:11 PDT 1994
Thu Jun 23 23:32:31 PDT 1994
Thu Jun 23 23:33:18 PDT 1994
Fri Jun 24 10:38:07 PDT 1994
Fri Jun 24 10:42:45 PDT 1994
Fri Jun 24 10:49:29 PDT 1994
Fri Jun 24 11:28:02 PDT 1994
Fri Jun 24 13:25:20 PDT 1994
Fri Jun 24 13:41:49 PDT 1994
Fri Jun 24 13:46:35 PDT 1994
Fri Jun 24 16:06:20 PDT 1994
Fri Jun 24 16:06:33 PDT 1994
Fri Jun 24 17:24:59 PDT 1994
Fri Jun 24 18:19:22 PDT 1994
Fri Jun 24 18:19:41 PDT 1994
Fri Jun 24 18:19:46 PDT 1994
Fri Jun 24 18:19:59 PDT 1994
Fri Jun 24 21:26:27 PDT 1994
Fri Jun 24 21:26:29 PDT 1994
Sat Jun 25 00:13:18 PDT 1994
Sat Jun 25 00:13:45 PDT 1994
Sat Jun 25 00:14:09 PDT 1994
Sat Jun 25 00:17:08 PDT 1994
Sat Jun 25 00:17:37 PDT 1994
Sat Jun 25 01:09:43 PDT 1994
Sat Jun 25 02:08:37 PDT 1994
Sat Jun 25 02:51:57 PDT 1994
Sat Jun 25 08:28:18 PDT 1994
Sat Jun 25 08:53:46 PDT 1994
Sat Jun 25 09:06:15 PDT 1994
Sat Jun 25 10:06:35 PDT 1994
Sat Jun 25 10:06:39 PDT 1994
Sat Jun 25 10:07:26 PDT 1994
Sat Jun 25 12:57:50 PDT 1994
Sat Jun 25 15:10:25 PDT 1994
Sat Jun 25 16:56:08 PDT 1994
Sat Jun 25 17:47:07 PDT 1994
Sat Jun 25 20:19:22 PDT 1994
Sat Jun 25 20:19:50 PDT 1994
Sun Jun 26 02:06:24 PDT 1994
Sun Jun 26 11:56:45 PDT 1994
Sun Jun 26 12:04:17 PDT 1994
Sun Jun 26 13:29:14 PDT 1994
Sun Jun 26 13:35:52 PDT 1994
Sun Jun 26 17:21:28 PDT 1994
Sun Jun 26 17:21:29 PDT 1994
Sun Jun 26 17:21:32 PDT 1994
Sun Jun 26 17:21:35 PDT 1994
Sun Jun 26 17:32:23 PDT 1994
Sun Jun 26 17:47:36 PDT 1994
Sun Jun 26 19:30:45 PDT 1994
Sun Jun 26 20:11:44 PDT 1994
Mon Jun 27 09:40:11 PDT 1994
Mon Jun 27 12:16:32 PDT 1994
Mon Jun 27 12:16:33 PDT 1994
Mon Jun 27 12:26:52 PDT 1994
Mon Jun 27 14:09:27 PDT 1994
Mon Jun 27 15:29:16 PDT 1994
Mon Jun 27 16:47:48 PDT 1994
Mon Jun 27 16:49:07 PDT 1994
Mon Jun 27 19:10:25 PDT 1994
Mon Jun 27 19:12:15 PDT 1994
Mon Jun 27 20:14:56 PDT 1994
Mon Jun 27 20:49:18 PDT 1994
Mon Jun 27 21:24:09 PDT 1994
Mon Jun 27 21:24:17 PDT 1994
Mon Jun 27 21:30:21 PDT 1994
Mon Jun 27 22:10:05 PDT 1994
Mon Jun 27 22:10:35 PDT 1994
Mon Jun 27 23:54:41 PDT 1994
Tue Jun 28 01:04:59 PDT 1994
Tue Jun 28 03:43:55 PDT 1994
Tue Jun 28 03:47:22 PDT 1994
Tue Jun 28 04:14:57 PDT 1994
Tue Jun 28 04:15:13 PDT 1994
Tue Jun 28 05:10:45 PDT 1994
Tue Jun 28 05:12:09 PDT 1994
Tue Jun 28 05:54:14 PDT 1994
Tue Jun 28 07:11:13 PDT 1994
Tue Jun 28 07:43:44 PDT 1994
Tue Jun 28 08:05:16 PDT 1994
Tue Jun 28 08:08:43 PDT 1994
Tue Jun 28 08:36:09 PDT 1994
Tue Jun 28 08:57:40 PDT 1994
Tue Jun 28 09:37:29 PDT 1994
Tue Jun 28 11:27:12 PDT 1994
Tue Jun 28 11:36:44 PDT 1994
Tue Jun 28 11:51:32 PDT 1994
Tue Jun 28 14:04:58 PDT 1994
Tue Jun 28 15:27:46 PDT 1994
Tue Jun 28 15:36:14 PDT 1994
Tue Jun 28 18:18:35 PDT 1994
Tue Jun 28 18:19:36 PDT 1994
Tue Jun 28 18:35:31 PDT 1994
Tue Jun 28 18:39:32 PDT 1994
Tue Jun 28 18:39:46 PDT 1994
Tue Jun 28 18:41:11 PDT 1994
Tue Jun 28 18:50:04 PDT 1994
Tue Jun 28 19:10:42 PDT 1994
Tue Jun 28 19:20:00 PDT 1994
Tue Jun 28 19:39:16 PDT 1994
Tue Jun 28 19:39:18 PDT 1994
Tue Jun 28 21:58:34 PDT 1994
Tue Jun 28 22:03:59 PDT 1994
Tue Jun 28 22:44:08 PDT 1994
Wed Jun 29 00:19:52 PDT 1994
Wed Jun 29 00:41:10 PDT 1994
Wed Jun 29 00:48:00 PDT 1994
Wed Jun 29 01:23:32 PDT 1994
Wed Jun 29 01:51:06 PDT 1994
Wed Jun 29 05:39:10 PDT 1994
Wed Jun 29 06:36:19 PDT 1994
Wed Jun 29 06:48:35 PDT 1994
Wed Jun 29 07:02:26 PDT 1994
Wed Jun 29 09:37:49 PDT 1994
Wed Jun 29 09:40:24 PDT 1994
Wed Jun 29 11:04:22 PDT 1994
Wed Jun 29 11:05:47 PDT 1994
Wed Jun 29 11:15:12 PDT 1994
Wed Jun 29 11:32:03 PDT 1994
Wed Jun 29 12:18:18 PDT 1994
Wed Jun 29 12:29:40 PDT 1994
Wed Jun 29 12:33:38 PDT 1994
Wed Jun 29 13:18:41 PDT 1994
Wed Jun 29 14:31:47 PDT 1994
Wed Jun 29 14:58:33 PDT 1994
Wed Jun 29 15:16:35 PDT 1994
Wed Jun 29 15:35:44 PDT 1994
Wed Jun 29 16:26:30 PDT 1994
Wed Jun 29 16:26:55 PDT 1994
Wed Jun 29 16:52:27 PDT 1994
Wed Jun 29 18:09:00 PDT 1994
Wed Jun 29 18:09:01 PDT 1994
Wed Jun 29 18:28:31 PDT 1994
Wed Jun 29 18:28:44 PDT 1994
Wed Jun 29 19:05:43 PDT 1994
Wed Jun 29 21:12:59 PDT 1994
Thu Jun 30 00:14:40 PDT 1994
Thu Jun 30 00:54:21 PDT 1994
Thu Jun 30 12:53:37 PDT 1994
Thu Jun 30 12:54:57 PDT 1994
Thu Jun 30 13:10:57 PDT 1994
Thu Jun 30 14:27:40 PDT 1994
Thu Jun 30 14:50:38 PDT 1994
Thu Jun 30 15:06:57 PDT 1994
Thu Jun 30 15:22:45 PDT 1994
Thu Jun 30 15:26:22 PDT 1994
Thu Jun 30 15:36:57 PDT 1994
Thu Jun 30 15:38:32 PDT 1994
Thu Jun 30 17:19:34 PDT 1994
Thu Jun 30 17:19:46 PDT 1994
Thu Jun 30 17:27:19 PDT 1994
Thu Jun 30 17:27:55 PDT 1994
Thu Jun 30 18:09:16 PDT 1994
Thu Jun 30 18:42:37 PDT 1994
Thu Jun 30 20:07:35 PDT 1994

@_date: 1994-03-03 08:06:49
@_author: Hal 
@_subject: Standard for Stenography? 
I share Jef's disagreement with the spectacularly bad "neon sign"
steganography header, but I don't think Sergey's approach was correct
and I hope he does not feel the issue is closed yet.  Bill Stewart is
IMO far more experienced and has far better understanding of the issue
than Sergey, who has been a list member for only a few weeks and again
IMO suggests a very naive security-through-obscurity approach.
Bill Stewart, Norm Hardy, and other list members who have more experience
and who have discussed these issues in the past will I think agree that the
correct approach is to separate the function of the stegonography program
to be a simple and clean insertion, and to have other components be
responsible for assuring that what is inserted is statistically indistin-
guishable from what is replaced.
This notion that a "secret offset" will prevent the stego from being
discovered is highly naive IMO.  The correct approach is to make it so
that the stego cannot be recognized even if the opponent knows where it is.
Adding offsets is like attempting to "improve" regular RSA by putting a
secret amount of noise padding at the front (not of a stego file, but of
an openly encrypted file).  This is unnecessary if you trust your encryption,
and if you don't trust it then this approach should not make you trust it.
Similarly, if your stego is so weak that knowing where it is in the file will
allow the opponent to detect it, adding a random offset should not make you
feel secure.  The correct approach is to have statistical identity between
what you are inserting and what you are removing.  The stego program itself
should then be as simple as possible.
Now I will add my own little moral lesson, in the spirit of Tim and Jef.
Sometimes when these discussions are re-hashed, old-timers are too busy or
bored to join in.  New list members express naive views that are not vigor-
ously refuted.  This is OK, but then some other new member takes these views
to represent list consensus.
I think it is great that Jef is working on a steganography implementation,
but IMO the notion of "random offsets" is so fundamentally misguided that I
hope he will reconsider.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-03-03 22:56:55
@_author: Hal 
@_subject: Security through Obscurity 
Security through Obscurity
Here's my view of the problems with the security through obscurity
approach.  First I'll discuss encryption, then steganography.  I use
StO to mean "Security through Obscurity".
It's true that obscurity can't hurt and might help.  If you can not only
keep your key secret, but your algorithm as well, then the attacker will
have a much harder time breaking your encryption.  And traditionally this
has been done.  I understand that much of the work in breaking the codes
during WWII was involved in finding out the algorithm; once that was done
then finding the keys was a considerably smaller problem.
I think the the "No StO" maxim refers to a design methodology for
the creation of cryptographic algorithms.  In this technique, you
divide the algorithm into those parts which must be kept secret, and
those which don't have to be.  The parts you keep secret you call the
key, and you accept that you will have to take extreme measures to
protect those secrets.  The other parts are less protected.
In other words, you conceptually draw a line between those parts which
have to be protected at all costs, and those which don't.  You then
analyze the algorithm's strength on the assumption that the secret
parts are kept secret.  You also carry out the analysis on the assumption
that the non-secret parts fall into enemy hands.  In the end, an algorithm
is judged on this basis.
In the context of this design technique, StO would refer to the hope that
the non-secret parts are also kept from enemy hands.  While this may be
desirable and beneficial, it breaks the rules of the method.
The advantage of this method is that it allows you to do a clean cost
versus benefit analysis.  You calculate the cost in terms of what it takes
to keep the keys secret, and you calculate the benefits in terms of how
much security you gain if you keep the keys, and only the keys, secret.
To also give credit for the additional security of keeping the non-key
portions secret, you would also need to calculate the costs of keeping
those parts secret.  Since historically it has been very difficult to keep
all parts of a cryptographic method secret, one has to consider these costs
to be very high.  Avoiding StO means avoiding falling into the trap of
counting the benefits of keeping the non-key parts secret without counting
the costs.
In this light, there is no inherent violation of the NoStO principle in
a cryptographic system which keeps the algorithm secret.  It simply means
that the algorithm has to be considered as secret as the key, and protected
just as securely as the key is protected.  In many circumstances this would
be excessively costly but in some limited situations it may be practical.
As long as you fully recognize that this line between the secret and the
non-secret portions is drawn to put the algorithm on the "secret" side,
you are properly avoiding StO.
In the context of commercial or public-domain cryptographic algorithms,
it is basically impossible to keep algorithms secret.  That is why any
cryptosystem of this nature which relies on a secret algorithm is scorned
as violating the NoStO principle.  It is generally not practical to expect
to keep a secret which is made widely available.
To sum up, obscurity is not bad.  What is bad is to confuse obscurity
with security.
Now, in the context of steganography, we should make clear what problem
we are trying to solve.  There are several components to this problem,
but I will focus just on the last step: hiding one bit pattern in
another.  Generally we do this by replacing some of the bits in the
target data with bits from the data we are hiding.
In encryption, the opponent's desire is to find out the original message.
What is the opponent's desire in steganography?  I feel it is to be able
to prove or determine with some degree of certaintly that there is a
hidden message.  We use steganography in a context where sending such a
message openly is for some reason undesirable.  Hence our goal is to
prevent the opponent from knowing that a message exists.
A test, then, for the success of a steganographic technique is this:
given some sampling of data items, half of which have embedded hidden
messages, can the opponent guess which ones have such messages with
better than 50% accuracy?  If not, the steganography is fully successful.
If he can do slightly better than 50%, it may still be useful depending
on the situation.  If he can guess with 100% accuracy, the steganography
has failed and is totally worthless.
Now, how does the NoStO maxim guide our attempts to evaluate steganographic
algorithms?  Again, the basic principle would be a need to separate that
which would be kept secret from that which would be publicly known.  Any
system which relies on keeping secret some information which must be
widely disseminated is not correctly accounting for costs when it touts
its benefits.
In the systems we have been discussing for a layered approach to stega-
nography, the actual embedding step has no secret component.  Rather,
the message is first encrypted and possibly transformed in such a way
that it is statistically identical to the bits which it is replacing.
The actual steganographic step simply does the replacement.
In this layered approach, there is no provision for key information to be
used in steganography.  Rather, the receiver of the message has only
publicly available data.  This means that when we "draw our line" we
exclude nothing from the knowledge of our opponent.  In counting the
benefits of the steganographic algorithm we assume that the opponent
will use exactly the same technique to de-steganize the message as our
intended recipient will.
Therefore, we are forced to assume that the opponent can successfully
extract the hidden message.  Now, the question that he must still answer
is, is this in fact a message or is it just random noise?  In order to meet
the goal above of making such a guess impossible with better than 50-50
chances, it follows that the message must appear identical to random
noise.  Any pattern in the message, such as a plaintext header, will make
the steganography useless.
This is also why proposals to scramble or permute the bits as they go
into the data, or to use a special offset instead of the beginning of
the data (then wrapping the bits around when we come to the end) do not
fundamentally help the situation.  By the basic premise above, we assume
that the opponent will be able to undo such artifices just as the
intended recipient will.  This way, again, we count our costs and benefits
on fair grounds.
Now, it is true that this is assuming that there is no "key" information
used in the steganography.  The NoStO principle would lead us to
investigate keyed steganography, where the receiver has specific secret
information which the opponent would not have.  But if we are going to
do this, we have to accept the costs.  That key must be kept just as
secret as the keys in an encryption system.  We can't just let it be
something obscure like a checksum based on a public key, information which
the opponent will have as well.  It has to be *secret*.  That is what
NoStO tells us.  If we want the benefit of a key, we have to pay the cost.
It's not clear whether keyed steganography has any benefits over the
unkeyed system discussed above which is used as part of a chain which
includes (presumably keyed!) encryption.  It would seem that the stego
would still have to match the statistics of the bits being replaced,
and if you can do that then the unkeyed approach would work.  But perhaps
there are useful solutions along these lines.
The important point, again, is that if you want a secret, you have to
keep it secret.  Looking at the advantages of a system which benefits if
some information is withheld from the opponent without calculating the
costs of actually keeping that information secret is the foolhardy
behavior which the NoStO principle warns against.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-03-04 07:22:16
@_author: Hal 
@_subject: Security through Obscurity 
I would not put it like this.  Rather, if you want a temporary increase
in security, you need to calculate, or at least assume, how much extra time
it will take for your opponent to defeat your temporarily-secret information.
Just saying, "oh, well this complication ought to slow him down some, heh
hey," doesn't cut it.  Again, you need to be explicit about exactly what
information you are keeping temporarily secret, and how long you expect it
to be kept secret.
I think this is a plausible, although less ambitious, goal.  But what's
this about "maximizing cost"?  Where does that fit into the analysis?  This
does not tell you whether your "maximization" has actually helped or not.
Instead, if you are going to adopt this goal, this means that the test of
your steganography is whether the opponent can extract the message.  It's
not that your goal is to "maximize his difficulty".  It's that your goal is
to stop him.  Again, NoStO emphasizes clear statements of your goals and
(The reason I say this is less ambitious is that if the opponent can
determine there is a message, but not what it is, they may be able to
bring penalties to bear on those communicating, depending on the circum-
stances.  For example, finding a stego'd file on someone's hard disk
might represent probable cause that illegal encryption was used, in some
hypothetical future.)
What key are you talking about here?  The public one?  That is not
secret.  As you say, the opponent has access to it.  Are you assuming that
the opponent cannot guess which public key was used?  How will you measure
the accuracy of this assumption without statistics?
I really don't think you have understood my essay.  The point, again, of
avoiding StO is to make it clear what you are keeping secret, and to count
the costs of keeping it secret.  If you are counting on keeping secret the
recipient of the message then you have these costs:
Any stego files found in the recipient's possession are broken.
Stego files can be exhaustively searched against a list of public keys.
If a particular group or person is targeted for surveillance his keys can
be used against all widely-known stego channels.
Further, your own test is so weak (inability to recover the actual message)
you have not attempted to make it impossible to guess when you have
recovered the message, even with the correct key information.  So in each
of the cases above the authorities know when they have the message in hand.
Now if you are tempted to say that this isn't true, because we could arrange
for the message ALSO to be unrecognizable even when successfully recovered
(so that the opponents don't know when they have recovered it) then you
have missed the whole point.  You earlier rejected this test.  If you had
accepted it, you wouldn't have needed your keys at all.

@_date: 1994-03-04 09:26:41
@_author: Eric Hughes 
@_subject: No Subject 
Sender: hughes at toad.com
[Maintainer's note: Sometimes the subscribe filter for majordomo works
too well.  This message came in a couple of days ago, got filtered,
and I've finally figured out how to massage majordomo into getting it
out into the list.  Sorry about that, Hal.--EH]
I run a simple script which will provide the Cypherpunks list in
encrypted form.  Send me your email address and a PGP public key and I
will add you to the list.  Once you have it working nicely you can
then unsubscribe from the regular list (I can't unsubscribe you from
the regular list).
Interestingly enough, I have been doing this for about a year, and in
that time about ten people have asked to sign up (I haven't publicized
it heavily).  All but two have asked to be removed within a week,
saying that it was too much hassle to deal with that volume of
incoming encrypted mail!
Let me know if you want to try it.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-03-05 07:32:51
@_author: Hal 
@_subject: Truly Stealthy PGP 
Eric points out the difficulty of making a "stealth PGP" which is 100%
indistinguishable from a string of random bits.  The problem is that we
have to encode the RSA encrypted number, m, which is less than n, the
RSA modulus.
PGP first puts out two bytes of bit length, then m.  This obviously won't
do, since the bit length is generally much less than 2^16 and so these
two bytes are a dead giveaway.  However, we could leave these two bytes
off and just output m as raw bits, padded to the length of n.  The
recipient knows n so he would be able to extract m.
The problem here, as Eric points out, is that m is less than n, so the
high bits of m will look non-random.  If the high two bytes of n are,
say, 0x0C12, then m's high two bytes will never be bigger than this.  This
will allow the opponent to do much better than 50% on guessing which files
have embedded messages.
This was discussed some time back on the pgp developers' list, and at that
time the suggestion was made to add a multiple of n to m so that it covered
a fuller range of values.  The recipient would then just take the exponent
mod n and try that.
Mathematically, call L the next multiple of 256 above n.  (0x10000... in the
example above.)  We want to choose k so that M = m + k*n is randomly distributed
between 0 and L-1 if m is randomly distributed between 0 and n-1.  This may
not be possible in this form.  Perhaps there is another deterministic and
reversible transformation would accomplish it, though.  In that case we
would have M = f(m,n) such that f can be reversed given M and n (we can
recover m).
As a trivial example of this problem, given n=2 and L=3, try to come up with
a way to turn a random 0/1 value into a random 0/1/2 value which is both
reversible and produces each of 0/1/2 with 33% probability.  Seems pretty

@_date: 1994-03-05 08:02:06
@_author: Hal 
@_subject: Security through Obscurity 
I don't think this is a valid measure of steganography's effectiveness.
I proposed my own measure, which I think is valid.  I think the fundamental
problem with your measure is that it counts a system which is easy to break
but very easy to implement as effective.  I would count such a system as
I don't think this is right either.  The problem is that "as difficult as
possible" does not allow for a measure of success.  Something which is
"as difficult as possible" may nevertheless be useless.  This whole notion
of maximizing difficulty as a goal is completely misguided.  The correct
goal is to achieve secrecy.  If you have not done that, then maximizing
difficulty is pointless.
Your goal in making a parachute is to create something that will land you
safely.  It isn't to "maximize slowness of fall".  Suppose I made a parachute
out of lead, designing it to maximize slowness among lead parachutes.  Will
you jump out of an airplane with it?  I'd think not.  The problem is that
this is the wrong goal.
OK, let me ask this: what is the harm done if the opponent guesses the
right offset?  How bad are things?  Some of your security has been lost.
How much?
Suppose your stego method is not completely invisible and does give away
its existence to some extent.  Would you still use it if protected by your
offsets, or would you refrain until you had an undetectable stego?  How
much would you trade off the protection provided by your offsets against
the protection provided by undetectable stego?
Suppose I am a naive user of your program asking these questions.  When
I receive a stego'd file and put it on my disk, should I re-format it
to change the offset?  How much security does this gain me?  Is it worth
Should I have more than one public key, so that the opponent would have more
offsets to guess?  How much does this help?
How much should I worry if I think I may be targetted for surveillance,
which would increase the chance of them trying my keys as the offsets?
Should I avoid controversial issues, keep a low profile, so that I can
prevent this from happening?  How much should I trade off against the benefit
of making my offset less likely to be tried?
I think if you are seriously proposing that your offset scheme adds security,
you need to be able to answer questions like these.  If it really adds
security, you must be willing to pay a cost to achieve that security (recall
the NoStO principle: count your costs when you count your benefits!).
If you can answer questions like these then you are not violating StO, in
my opinion.

@_date: 1994-03-05 13:20:23
@_author: Hal 
@_subject: Truly Stealthy PGP 
I'm not sure the point of this entropy calculation.  For the case n =
L/2+1, t=1, it seems to me that the RSA-encrypted session key (sk^e mod n)
is never going to have the high bit set, so with K such messages it should
be possible to tell that something is going on with probability 1 - 2^-K.
If the session key is chosen from [0,L), still the encrypted session
key m = sd^e mod n will be uniform in [0,n).  I don't quite follow here
how exactly we go from something uniform in [0,n) to something uniform in
[0,L), if that is what Eric is proposing.

@_date: 1994-03-05 14:03:00
@_author: Hal 
@_subject: Stealth PGP 
I never saw the posting below here, only on sci.crypt.  It seems
relevant to the present discussion.
I did take a look at the source code to stealth pgp; it is quite simple and
nicely done.  However it doesn't do anything special about disguising the
encrypted session key.  It just strips off the two length bytes PGP puts
at the front.  Not only is this revealing, it also doesn't always work.
Apparently the program can't always reconstruct the original mpi length
if the encrypted key's size happens to be much less than the modulus.
It does print a warning in that case that the file won't be able to be
de-stealth'd successfully.
Stealth PGP is a nice start but it needs to be improved to be truly stealthy.

@_date: 1994-03-06 11:21:28
@_author: Hal 
@_subject: Truly Stealthy PGP (algorithm) 
(I'm having a bit of trouble with my mail UA; all of my saved messages on
this thread keep disappearing, so I apologize for a slight lack of
continuity here.  I'm having to work solely from memory of the earlier
If I understand Eric's general idea, we would keep trying session keys
under a set of rules which would lead to the desired statistical
distribution of the encrypted key.  Here is an algorithm which would work.
(I hope I am remembering the notation Eric used correctly.)
Let L be the next power of 256 above the modulus n.  Let t be the integer
part of L/n, so that L = n*t + s with s in [0,n).  Call the PGP IDEA session
key SK, and the encrypted version of that m = SK^e.  Now do these steps:
1) Pick a random SK in [0,n).
2) RSA-encrypt it to form m = SK^e mod n.
3) Choose a random k in [0,t].
4) Calculate the "stegged" encrypted key as M = m + k*n.  This will be
uniform in [0,(t+1)*n) if m is uniform in [0,n), which I think it is.
5) if M is not in [0,L) (i.e. if M >= L) then go back to step 1.
6) Otherwise store M as a raw binary number taking log base 256 of L bytes.
The idea is that once we get M uniform in [0,(t+1)*n) we can make it
uniform in [0,L) simply by rejecting those candidates which were too high.
This will only happen if k=t and m>=s.
Now, it seems to me that the worst case for rejection is when n=L-1, in
which case t=1, s=1, and almost one-half of all initial SK choices will
be rejected.  Following Eric's reasoning, this would be an effective loss
of one bit of key length, from say 1024 to 1023, which is tolerable.
(Eric actually suggested that as many as two bits could be lost, but I
don't see that happening with this algorithm.  It doesn't really matter
anyway because both 1 and 2 are so small.)
Using this algorithm with the current Stealth PGP would produce a
"truly stealthy" version which I think would be indistinguishable from
random bytes without access to the receiver's private key.

@_date: 1994-03-06 19:40:47
@_author: Hal 
@_subject: Where'd pgptools go? 
I notice on csn.org:/mpj there is now pgptl10d.zip, PGP Tools version
1.0d.  However, 1.0d is not the whole PGP Tools program.  It is just an
addendum which implements Diffie-Hellman.  Apparently pgptl10c.zip is still
needed to give you the whole of PGP Tools.  Does anyone know of an FTP
site which still has pgptl10c available?  Thanks -

@_date: 1994-03-12 08:33:58
@_author: Hal 
@_subject: Niacin warning (was Surveillance cameras) 
I just want to warn anyone who is thinking of trying this that 400 mg
is not the place to start with niacin.  The flushing will be extremely
intense at that level and you will probably either think you are dying
or wish you were.  Try 50 or 100 mg to start with.
You do build up a tolerance to this effect of niacin pretty fast so
experienced users will need higher doses to get the flushing.  But for
a non-user lower doses are adequate.

@_date: 1994-03-12 08:46:28
@_author: Hal 
@_subject: Heavy remailer traffic source? 
For the last day or two I have been getting several dozen messages
(67 today, a similar number yesterday) similar to the following:
The "PGP" message appears to be just an ascii-armoring of random bytes.
Is this an attempt by someone to provide the "masking" remailer traffic
we have been discussing for some time?  This is OK, but I think the volume
is too high.
What is the Do-Inject: header intended to accomplish?
The message apparently is intended to provide multiple remailing addresses per
message.  However, my remailer only does one remail address per message.
Also, my remailer does not accept "Anon-To" but only "Request-Remailing-To".
So all these messages are ending up in my mail box.
Anyone want to explain these?

@_date: 1994-03-13 21:50:24
@_author: Hal 
@_subject: hal@alumni.caltech.edu up 
The Caltech system had some problems with break-ins so apparently some
disk reorganization was done in the clean-up which stopped my remailer
for a while.  I touched up a bit of the code tonight, nothing too
significant, and it seems to be working OK now.
Note that this remailer always forwards via the one at shell.portal.com.
It does have its own decryption key, but all outgoing mail goes via that
address.  This makes the mailer more politically acceptable to TPTB.  But
it does mean that when you "ping" the remailer you won't see the alumni
address in the From line, but portal instead.

@_date: 1994-03-13 22:20:02
@_author: Hal 
@_subject: Magic Money gripes 
I hate to complain.  Magic Money is something that people have been asking
for for a long time, and it's a very nice implementation.  A lot of aspects
have been really well thought out, particularly the money aging and replace-
ment.  But I've been playing with it off and on lately and there are some
improvements needed IMO.
I'll just assume interested readers know how the program works and jump
right into it.
 - The program handles encryption of messages to and from the bank auto-
   matically, but makes the user have to handle encryption of messages to
   other people.  I can see some justification for this - maybe the message
   (that is, a coins.dat file) will be sent via secure means like a direct
   or IR connection, so encryption is not needed.  But most of the time it
   is needed, in which case the user has to use PGP or something as a sep-
   arate step.
 - The program distinguishes between bank messages, which are signed blinded
   coins, and user messages, which are raw coins, by whether they are in
   ASCII text or not.  This is not the significant distinction between these
   two kinds of messages.
 - Bank messages look just like other PGP messages.  But the user has to
   know not to try to run them through PGP and instead give them directly to
   the MM program un-decrypted.  The only way he can tell is to notice that
   the sender address is the bank.  If the bank ever sends him a real coin
   file (which it may to prime the pump) then the user just has to know
   to treat these messages differently.
 - There is no way to know which bank an incoming coin file is for.  I think
   this is one of the biggest weaknesses of the system.  If more than one
   bank is competing I have to know which bank a given coin file is
   associated with and go to that directory to process that coin file.
 - There is no way to put coin files directly into your allcoins.dat file.
   There are a couple of cases in which you might want to do this.  First,
   you might pay out some coins and then change your mind before sending
   them, and want to put them back.  Or second, you might receive some coins
   from a trustworthy person (your mum, say) and just want to add them
   without going through the bank.
 - More generally, it is difficult to use the program in a safe way which
   deals robustly with errors of various types.  When I was first building
   the program I had some bugs which caused coins to appear to be double-
   spent, to not signature-check properly, to not be found in the proto file,
   etc.  The program did not appear to handle all of these errors safely,
   sometimes aborting in the middle of a file.
   In addition, the program always calls its output files coins.dat and
   output.asc.  If you run it twice without renaming these files you can
   lose data and lose money.  Then, when you send the files, you need to
   manually keep backups in case the email fails.  Again, otherwise you will
   lose money.
 - The money data structures do not allow for expansion.  I'd like to see a
   way of adding new fields in the future which will be ignored by older
   versions of the program.  For example, in regard to the above, I'd like
   to see a "bank email address" and possibly a bank key added to the
   coins.dat file.  Then you could mail the coins to someone without including
   a lot of out-of-band data about the bank they were for.  It would be nice
   if this could be done without totally breaking the current program.  At
   a minimum a version number could be stuck at the front so that old programs
   would recommend that users upgrade.
 - The program uses PGP algorithms and data structures, but not its files.
   The bank's key and user's keys are kept in separate files.  There might
   be advantages in putting these keys into PGP's regular files.  Also, the
   random number generation in PGP looks stronger than MM, since it keeps
   much more state from run to run.  MM seeds based on a very, very elementary
   hash on a file called rand.dat, which will tend to be fixed, and the time
   of day.
 - None of the MM files are encrypted on the disk.  The money files could
   be stolen by someone with access to your computer, and your secret key
   used for communications with the bank could be stolen as well.  This
   would be a major security flaw in some situations.
Having made these complaints, let me reiterate that I am very pleased with
this program overall.  I also appreciate mpd at netcom.com's efforts in running
a server.  I have built a Mac client for MM which is not too mac-like but
lets you drag-n-drop incoming files onto the MM icon and it handles them
right.  I'll tweak that a little more then upload it with the other clients.

@_date: 1994-03-14 10:33:47
@_author: Hal 
@_subject: Magic Money Complaints 
Mail to mpd at netcom.com, subject "Bank" will be processed by a Magic Money
server.  He calls his coins "Tacky Money".  Here is his bank's public key:
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: 2.3a
-----END PGP PUBLIC KEY BLOCK-----
To make things interesting, here is a $10 Tacky Token.  The first
person to turn it in gets it!  (This is just ascii-encoded; you will
have to first use PGP to unencode it then give it to your Magic Money
And as a "token" of my appreciation here's a little gratuity for Pr0duct
Here are some more constructive suggestions for how some of the issues I
raised might be addressed.
 - Mark Magic Money messages differently from ordinary PGP messages.
   (-----BEGIN MAGIC MONEY MESSAGE-----)  Alternatively, allow MM msgs
   to be decrypted by PGP to produce binary files which can be passed
   to the MM client.
 - Make the client handle bank and user messages both as either binary or
   ascii files.  Use internal type flags rather than ascii vs binary to
   distinguish them.
 - Allow the client to search the PGP public and private key rings for
   decryption and encryption keys.
 - Allow the user to specify a user id to encrypt for when he extracts coins
   for payment, search the PGP public key ring and encrypt for that user.
 - Check for the existence of an output file and warn the user if it already
   exists.  Allow the name of an output file to be specified on the command
   line.
 - Save a copy of all output files in a logging subdirectory.  Then if an
   email message is never received the user can go back and send it again.
   The file dates and perhaps file names can be used to help the user deter-
   mine which log file is the copy of the lost one.
 - Include the bank's key and email address with each coin file.  Allow
   users to combine the initialization and coin-receiving steps (already
   these appear to be very closely related in the software).  This way a
   user who receives MM coins for a new bank which he has never used
   before can begin using it in one step.
These don't really imply re-implementing PGP.  MM already encrypts and
decrypts PGP-type messages for the bank.  Adding the keyring searches is
the main part of extending that capability to user-to-user communication.
It also gains the benefit of encrypting the user's secret key.
I don't mean to be asking Pr0duct Cypher to do all of these things.  If
people can agree on the usability issues, maybe other members of the
community can join in and make some of these changes.  Now that Pr0duct has
done the hard work a lot of this is little tweaks which aren't that tough.
That's what happened with PGP.
BTW, I was astonished by how easily the program built for the Mac.  I did
 MSDOS,  BIGENDIAN, as well as the compatibility flags.  Then
there were a few of the typical header files incompatibilities.  Practically
once it linked it worked.  Very nice.

@_date: 1994-03-14 21:40:29
@_author: Hal 
@_subject: Magic Money promissory notes 
In the never-ending search for legal bases for digital cash, I thought
of promissory notes.  A promissory note is basically an unsecured promise
to pay back a loan, generally by a specified time with a specified interest
rate.  My wife's college loan was based on such a note.
I think these can be transferred from person to person, with the bearer
being eligible to redeem the note.  I recall old stories where a person's
note was passed from hand to hand, ending up in the hands of the villain.
Perhaps a digital cash system like Magic Money could serve as the basis
for digital promissory notes.  You send me money, I'll send you a certain
amount of digital cash.  That particular denomination and issue date
(determined by the exponent) will be redeemable in one year for X+delta
dollars.  You can hold the note and redeem it in a year, collecting the
interest, or you can pass it on or even sell it.
This might make people willing to accept the digital cash as valuable,
since they would know that it would actually be worth something in a
while.  And I don't think there are a lot of laws relating to promissory
notes, since I've heard of them being used in very informal situations
(scribbled on scraps of paper and such).  I will try to look into the
legalities in a few days.

@_date: 1994-03-16 13:24:19
@_author: Hal 
@_subject: digital cash 
I'm not sure about this.  Liquidity refers to the ease of conversion to
cash.  Some kinds of information may be easily convertible, others may
not.  Even with digital cash the relevant definition of liquidity might
be acceptability or ease of conversion to other currencies.  Digital cash
is easy to copy and so there will always be a risk in accepting it unless
the bank is accessible or it is highly reputable and is known to cover
bad (duplicate) cash.  Communications problems, whether technical or
political, may make such access difficult.  And banks, being unable to
collect assets by force to cover their debts, may be vulnerable to some
kinds of failures that governments are not.
Well, there are some more requirements.  The bank has to be in a setup
where it cannot easily be shut down, or more specifically it does not
experience any reasonable probability of being shut down in the near
future.  The net links have to be reliable, as I mentioned above.
The bank presumably has to convert digital money back to cash as well as
converting in the other direction.  The question is, how do you get your
cash to/from the bank?  Via an anonymous, private, electronic transaction?
If you can do that, you don't need digital money; your cash is already
electronic and private.  But if you have to send your cash the old-
fashioned way then you are still vulnerable to the same government pressures
you have today.
This is the point in these kinds of discussions that I always lose track
of things.  We are dazzled by the picture of monetary flows flashing all
around the world.  What I am always unable to pin down is, what exactly
prevents this kind of thing from being done today?
If you want to invest in gold, you can go down to the coin store and buy
some, right?  Or you can put your money into a gold-investing mutual fund
and use it as a checking account.  If you want yen, or marks, you can invest
in those.
If the point is to do so secretly, why is it easier to mail your paycheck
to the digicash bank in the Bahamas than to mail it to an existing bank
Perhaps my problem is that my financial affairs are too limited to really
benefit from intricate financial transactions.  Investing in a non-dollar-
denominated mutual fund would be a major adventure for me :-).
If avoiding taxes is the major goal, my problem is that by far the bulk of
my taxes are withheld from my paycheck.  I know, Sandy or Duncan said, "What?
You still have a paycheck?" but let's face it, most people do.
It seems to me that the weak point in these bypass-the-government digicash
schemes is the conversion between paper cash and digital cash.  That looks
like the choke point where the government can still keep control.

@_date: 1994-03-16 21:35:38
@_author: Hal 
@_subject: The Joy of Digicash 
It occurs to me that digital cash could be a collector's item.  Paper
money is widely collected, as are coins.  I got a book out of the library
on old American paper money, and many of the old bills are startlingly
beautiful.  Interestingly, the old money is still legal tender so there
is a floor under the value of the bills that you collect.
Until 1861, the U.S. did not issue any paper money, only coins.  In those
days, paper money was issued by private banks (usually with state charters).
The money was backed by dollars, coins, which the bank owned.  Unfortunately,
capitalism is a dynamic system and in those days bank failures were no more
unusual than corporate failures are today.  When this happened, the bank's
notes became worthless.  Counterfeiting was also a big problem with the
thousands of different banks issuing notes.  It is interesting to speculate
that digital cash might lead to an electronic system with some similarities
to those old days.
Collecting digital cash has some problems.  Collectors are generally
attracted to items that are beautiful, interesting, and rare.  Digital
cash is interesting enough, but its beauty is rather abstract.  Rarity is
also hard to evaluate; each individual note has a unique serial number,
and what it has in common with other notes of its denomination is the
bank key and the exponent.  Uncirculated notes are generally more
valuable than others in the paper world; with digital banknotes the only
way to tell whether it has been "circulated" would be to have access to
the bank's database of spent notes, to verify that the note had never been
Rarity could be determined by the bank's key and exponent.  The Magic Money
system has a provision for the bank to periodically move to another set of
exponents to represent the same denominations (in order to keep the size of
the note database from growing too large).  If banks would do this at regular
intervals, then particularly the early issues would be relatively rare.  One
might even have an early banknote notarized (digitally timestamped) so that
one could prove its value in later years.
Beauty is harder to deal with.  Strictly speaking, digital cash is invisible,
consisting only of an information pattern in RAM chips or on a disk.  The
numbers which represent the cash can be printed out, though, and this
representation could perhaps have some beauty.  Unfortunately, in my opinion
several lines of random hex digits are not beautiful.
I have been working on ideas to display the information in digital cash in
some other way that is more esthetic.  It would be nice if the display
somehow only worked for correctly signed cash notes, with forged cash
not displaying anything nice.  My general idea is to display a "fingerprint"
of each individual banknote, something that is unique to that note and
which has a sort of beauty.
One idea I have worked on is to seed a 1-D cellular automaton with a bit
pattern based on the digital cash.  This seed is then processed by the
CA algorithm to produce some pattern, with each row being a function of
the previous row.  My thought was to start the CA at the top and the bottom
of the screen with the two different functions applied to the cash which
should be equal if the cash validates (taking the number to the proper
exponent on one hand, and applying the MD5 hash of the serial number on
the other, for the case of magic money).  Then we work inwards with the
two seeds.  Proper cash will produce a symmetrical pattern.  By choosing
good CA rules, the patterns will be different for each bill, some nicer
than others, leading to attractive fractal-looking patterns for many bills.
When you wanted to "look at your money" you could run the program on the
digital cash.  People might even trade for especially attractive bills.
A similar idea is to use the cash as the basis for some fractal algorithm.
Many fractals have the property that most of the plane is plain, while
only a fraction looks really fractal.  Digital cash has the property that
when exponentiated it leads to a number most of whose bits are fixed but
which has a small number of varying bits.  If we had a mapping which took
the fixed digicash bits onto the interesting parts of the fractal, then
fake cash would not produce pretty pictures, while real cash would produce
some part of a beautiful fractal.  Again, you would have validation and
beauty being tied together.
I've been doing some experiments with the first idea, hoping to produce
something nice.  With a little more thought I hope to come up with a
viewer for your Magic Money that will bring out its natural beauty and
rarity.  This will be a must for all serious collectors of digicash.

@_date: 1994-03-22 09:41:36
@_author: Hal 
@_subject: Promise her anything... 
A few days ago I said I'd look up the legal requirements on promissory notes.
This was to see whether digital cash or similar instruments could implement
digital promissory notes.
I found a book of legal forms for a variety of situations, and one set of
forms dealt with promissory notes.  Here are some of the comments about the
sample notes below.
"All of our notes are negotiable - that is, they can be sold.  To understand
what this means, think of what happens when you write a check.  Your check
means that you owe the face amount of the check to the person you have made
it out to (the payee) and that your bank will pay this debt when the check
is presented to it.  The original payee of your check can either collect the
amount directly or, as is common, endorse the check to someone else.  This
new owner can then collect the amount from your bank or endorse the check
to someone else.  In other words, the check can pass freely from person to
person (that is, be negotiated) until it is presented to your bank for payment.
"Promissory notes can similarly be negotiated, assuming they contain the
following provisions and magic words:
 "names of the lender and borrower, and borrower's address
 "a statement that the debt is payable 'to the order of' the lender (promisee)
 "a specified principal sum to be paid and the specific rate of interest,
  if any
 "the address where the payments are to be made
 "the city where and date when the note is signed and
 "the signature of the debtor (promisee)
"All the notes set out in this book contain this basic information.  Although
we told you in Chapter 1 that you could alter our contracts to your
satisfaction, taking out any of these clauses will probably render the note
non-negotiable (though still valid).
"In fact, it is unlikely that negotiability will be important to very many
readers, as most will never transfer their note.  However, should one of the
parties die, become mentally ill, or otherwise not be able to pay or collect
the debt, the fact that the note is negotiable increases the chance that it
will be paid.  Why?  Because institutions in the business of purchasing
uncollected notes and collecting onthem may be willing to buy it.  If you
alter a note but want to have it remain negotiable, make sure it still
contains the elements listed above."
The promissory note in the book also has a clause regarding attorney fees.
I will eliminate it here which implies that each party simply pays his own
attorney fees.  It simplifies the note.
Here is the note.  The form is not important, but the information present
    For value received, I individually promise to pay to the order of
    ____________ $___________ on _____________ at _______________________.
    Date:                      _________________________
    Location (City or County): _________________________
    Name of Borrower:          _________________________
    Address of Borrower:       _________________________
                               _________________________
    Signature of Borrower:     _________________________
In considering how this could be presented in electronic form, the
basic information could be provided in a digitally signed message.  The
thrust of the legal discussion about the note is to make sure it can be
enforced in court if the borrower doesn't pay.  Digital signatures have
not, as far as I know, been tested yet in court, so lenders would not
currently have the protections with a digital promissory note that they
would have with a written one.
These notes also do not seem to lend themselves to anonymous transactions
very well.  The original note must contain the name of both borrower and
lender.  And I believe that if the note is sold, it must be endorsed over
to the buyer like a check.  So not only does the note record the names of
its owners, it also shows a trail of previous owners.  In general, this does
not seem to be an approach which would protect privacy.
I imagine it is possible for a person to create a "bearer" promissory note,
where he will pay back some loan to whomever presents the note.  In normal
circumstances, though, no lender would want to lend in exchange for such a
note, since the regular promissory note gives him more protection.  It's not
clear, too, how enforceable such a note would be, especially if presented by
someone not the original lender, say if the original lender contested the
note (claiming it was stolen or such).
The one loose end I did pick up from this reading was the general topic of
negotiable instruments.  These are financial papers which can be sold.  Per-
haps among the great variety of such instruments there would be some more
suitable to digital implementation using the anonymous-transfer technology.

@_date: 1994-03-24 08:58:07
@_author: Hal 
@_subject: Promise her anything... 
The other night at the library I had a chance to browse through the
Uniform Commercial Code as enacted by the state of California.  It had a
large section on promissory notes and commercial paper in general.
The basic definition of a promissory note did include a variation on what
Duncan quoted.  It would appear that the legal requirements and restrictions
on the issuing and sale of such notes are pretty flexible.
However, in the digital realm, it is not clear whether a promissory note would
truly be enforceable, in the event that the debtor refused to pay.  The main
question is the digital signature.
One thing I wonder about is this.  Suppose I simply create a file saying that
I promise to pay the bearer $100 on demand.  I then sign this using my PGP
public key, and give it to someone in exchange for $100.  This would be the
electronic analogue of the issuing of a paper promissory note.
The problem is, "forgery" of such notes, in the sense of duplication, is
both trivial and undetectable.  With paper, someone could Xerox a note and
end up with two, both claiming to be worth $100.  But in practice we could
distinguish the original from the copy.  Better forgeries might be harder
to detect but in principle experts should be able to tell the difference.
But with the PGP-signed document, any copies made would be completely in-
distinguishable from the original.  How could the debtor know to honor such
a note without being able to tell whether it was the original or not?  How
could the holder of the note sell it to someone without them kmnowing whether
it is valid?
Because of this uncertainty, it seems to me that in this simplest sense
digitally-signed promissory notes do not work.  Such a note, even though
signed, cannot be considered to carry value in and of itself because it
is too easy to forge.  The digital signature is of no value in preventing
forgeries since copies of valid notes are just as useful as plain forgeries.
Now, the more elaborate technology of digital cash can actually go a long
way towards solving this problem, at least in theory.  With this approach,
each note has a unique serial number, and part of the agreement is that only
the first presentation of a note with any given serial number will be
honored.  Then if the holder of a note wants to sell it to someone else,
they go through a protocol with the borrower in which he verifies that the
note has not been spent, and a new note is issued with a new serial number
that nobody has seen before.  This way the buyer of the note is protected
against being sold an already-sold note.  Plus, the digital cash technology
allows this to be done without the debtor finding out who is selling his
old notes to whom.  There is no reason for him to have this information; the
holder of the note ought to be able to sell it privately, and this is
a good way of preserving that aspect of the transaction.
So, the digital cash technology works pretty well for this application.  The
problem is that there have to be many additional restrictions and rules in
the handling of the notes - notes have to be transferred using the special
protocol, and only previously-unseen notes will be honored.  It is not clear
to me how these additional contractual restrictions can be incorporated into
the note without violating the simplicity that Duncan quoted above.
Also, in the technical sense, the blinded signatures used in digital cash
do not allow the signing of a textual document.  Instead, what is signed is
a simple number in a specified form, and the *exponent* used in the signature
is what determines the "sum certain".  So the formal structure of a piece of
digital cash does not match the requirement for a promissory note.  There
would have to be some additional documents which, for example, map the
signing exponents to the note values.  But again, there is no place in the
note itself to put pointers to such additional documents.  It is possible
that the note could consist in effect of two documents, one part which is
a PGP-signed text document laying out the terms and conditions which are
relevant, and which states that it only has value when accompanied by a
digital-cash data item, signed with the proper exponent, not previously seen
by the debtor, etc.
Again, then, you have to worry about fraud by the debtor, in which he claims
to have seen a note before when one is presented for redemption.  In order
for note holders to protect themselves against this fraud there would have
to be some way for debtors to prove that various notes had been spent.  This
might be difficult, especially if the people presenting notes for redemption
are anonymous to the debtor.  It's going to be hard to distinguish between
the twin frauds of a holder presenting the same note for redemption twice,
possibly at almost the same time from two different addresses, and the debtor
who receives a note for redemption, then quickly sends it to himself as
though from another holder, back-dating it a few seconds so he claims that
one arrived first.
Perhaps some form of registered mail for note redemptions, plus a requirement
that when a conflict like this arises both presenters must identify themselves,
could address some of these problems.  (These problems arise for digital cash
just as much, by the way.)

@_date: 1994-03-24 12:47:22
@_author: Hal 
@_subject: Promise her anything... 
The notion of a "cryptographically tamperproof software module" is interesting,
but I'm not sure such a thing exists or could exist.  The secure offline cash
systems I have seen rely on tamper-resistant HARDWARE modules which at least
exist although this requirement would be very inconvenient.
Again, I don't know how you handle the case of two almost-simultaneous
attempts to redeem the same note (or piece of cash).  Both notes are
identical, so having the two notes gives you no more information than
having just one, hence if one note is anonymous so will two be.  You know
someone is cheating in this situation, but who?  One of the redeemers may
have stolen a copy of the cash from the other; the two redeemers may be
working together; or the note maker may be working with one of the redeemers
having slipped them a copy of the note as soon as it was presented for
redemption.  How can a court decide who is right?
Maybe the answer is simply to handle this as a my-word-against-yours kind of
case, where reputations and histories of such conflicts would help decide
who is likely to be telling the truth.

@_date: 1994-03-24 22:17:30
@_author: Hal 
@_subject: Digital Cash 
I too would like to hear more about tamper-proof software modules.  They
would be a natural for software implementations of Clipper (although
perhaps too slow for many applications).  Imagine running the Clipper
algorithm on your own computer and it comes out with your key exposed
to listeners armed with the proper black box, yet you cannot disable
this exposure.  Interesting thought.
I doubt that these would work as digital cash observers, though, even
if possible.  It seems to me that the digicash observer has to retain
some internal state.  In effect, it has to remember which coins you have
spent and which you have not.  You can cheat, then, by checkpointing
your computer just before spending a coin.  After you spend, you restore
the computer to exactly the same state it was in before you spent it.
You then go somewhere else and spend the coin again.  The observer has
no way of knowing that these games have been played with its state, yet
you have obtained twice the value of the coin.
Most of the observer-based protocols are also after-the-fact double-
spending-detection protocols as well, so that if the observer is defeated
you can still catch the miscreant eventually.  But the two problems with
this are, first, that it prevents the client from being anonymous to the
bank, and second, that the cheater can still multiple-spend quickly and
then escape the country before being caught.
It was pointed out on sci.crypt some months ago the irony that Chaum's
privacy-preserving cash relies on similar tamper-resistant technology to
the privacy-destroying Clipper chip.

@_date: 1994-03-25 07:44:27
@_author: Hal 
@_subject: Digital Cash 
I sent mail to Stefan Brands yesterday asking about what kind of information
is retained by the (hardware-based) observer in his digital cash system.
Brands has worked with Chaum in the past and is now seeking funding (via
Usenet, apparently) for development of his own digital cash and anonymous
transaction technology, which he claims is greatly improved over existing
systems in terms of memory and computation requirements.
Brands explained that the way his system works, the user *never* has all
the information needed to represent the "digital coin".  Instead, the
user has part of the information, and the tamper-resistant observer chip
has the other part.  To spend the coin, the user and the chip have to
cooperate in the protocol.  Then the chip can mark its own information about
that coin as having been spent, or even erase it altogether.  It is this
change in the internal state of the observer chip which lets it prevent
double-spending (and which arguably could be defeated in any software rep-
resentation of an observer).
I have always been skeptical of this observer-chip approach, because it
wasn't clear that it was feasible to make a tamper-resistant chip
economically, and because the specialized hardware that would be
required would prevent the system from being used on widely-available
PCs.  However, now we see that our military rulers apparently trust
tamper-resistant technology well enough to put it into thousands of
public hands, without fear that even one chip will be opened and read.
Breaking an observer only lets you double-spend the coins it holds,
while breaking Clipper allows you to permanently defeat the escrow
provisions of the whole system.  So this suggests that the technology
is adequate for observers.
As for the specialized hardware, probably a more realistic picture of the
digital cash user of the future is someone holding a PDA in his hand, with
possibly an infrared or cellular modem link, rather than the hacker sitting at
home in front of his PC.  In that context it may be realistic to imagine
custom PDA's which support secure offline cash as a practical product.

@_date: 1994-03-26 09:53:47
@_author: Hal 
@_subject: Digital Cash 
I think there are two issues here.  One is the intractability of defeating
encryption protocols such as RSA, digital signatures, blinded signatures,
etc.  These form the basis for digital cash and they appear to be quite
The other issue, which I know less about, is the possibility of cryptograph-
ically strong obfuscated code.  Mike Duvos first mentioned this.  You could
have an algorithm running on your own computer and have it be impossible to
determine what it is doing, or (presumably) to effectively alter the internals
of the algorithm.
This seems a lot more difficult to achieve, since all the information needed
to tell what the program is doing is in principle in your hands.  Yet the
ability to actually determine this is computationally out of reach.  It's
not just a matter of the kinds of complexity and obscurity we have been
discussing here (self-decrypting code and such tricks), but rather some
mathematically strong transformation has been done on the structure of the
code to hide it in a cryptographically strong way.
I vaguely recall hearing about such technologies, but I can't remember
where now.  Can anyone provide some references, or (better) a summary of
how this works and what can actually be accomplished along these lines?
Thanks -

@_date: 1994-03-27 23:37:12
@_author: Hal 
@_subject: Solution to Remailer Abuse 
I was riding the train tonight, re-reading some old crypto papers, including
Chaum's Auscrypt paper on digital pseudonyms, credentials, and such.  He
described a method for letting libraries catch people who don't return
library books, while still preserving confidentiality of all transactions.
It occured to me that a modified form of his idea could help curb abuse
of remailers.  (It might also work for the anonymous video rental problem
we have discussed here from time to time.)
Chaum's idea was pretty complicated, but I think a simpler approach could
work using the existing Magic Money software.  One idea we have talked about
to help curb abuse would be to simply charge digital postage for every
message.  However, it was pointed out that in practice postage costs would
probably be so low that this would only help in extreme cases of volume
My idea is to have the coins not represent money, but to have them be
"non-abuse tokens".  With every message would be included a non-abuse
token in the form that Magic Money uses when you exchange incoming
money at the bank.  This is composed of the coin itself, plus what is
called a "proto-coin" which is a blinded version of what will become
the new coin.  The remailer would check the incoming non-abuse token to
make sure it hadn't been seen before, just like the bank does with
Magic Money.
However, it would not immediately sign and return the blinded proto-coin.
Instead, it would hold onto it for a day or two to see if any complaints
came back about the message.  This would require remembering the outgoing
message-ID along with the proto-coin, but nothing else would have to be
remembered about the message, and of course with remailer chains the true
source of the message would be completely unknown.
If no complaints come in (which is the case with the vast majority of
messages, in my experience) the remailer would sign and publish the blinded
proto-coin.  This would be put in some public place which was generally
available to all who might use the remailer.  The user who sent the message
would be watching for this proto-coin and pick it up, un-blinding it with
his Magic Money software, to produce a new non-abuse token which he can use
to send another message.
If serious complaints do come in about the message, the remailer would not
sign the proto-coin, and the sender would have lost a non-abuse token.
The nice thing about this system is that it protects the privacy of the user
of the remailer system.  With the Magic Money technology each non-abuse
token is blinded so there is no linkage possible between issuing of such
tokens and their use.  The big problem with the remailers now is that abusive
messages can't be addressed without trying to track down who sent them, which
is usually impossible.  This system addresses the problem without hurting
anyone's privacy.
A couple of issues that I have glossed over would include how the non-abuse
tokens are issued in the first place.  There is the obvious danger that an
abuser manages to keep getting new tokens by pretending to be a new net
user who would like to use the remailer.  Two solutions to this would be
first, to charge a significant sum for a handful of non-abuse tokens; this
would be a one-time fee for non-abusers but could get expensive for those
who abuse; or second, to only give non-abuse tokens to users who could be
identified by their True Names.  (This isn't a situation which needs military-
grade security; semi-secure methods of identifying true names should be
One other thing I suggested above which might seem a little controversial
was that the signed but still-blinded proto-coins could be made available
in the clear.  Since these are in the form r*f(x)^(1/d) where r, a random
number, is only known to the user who created the proto-coin, I think they
are effectively one-time-pad encrypted.  So I don't see any need for these
messages to be hidden with a public key.  In fact, I don't think Magic Money
would really need to have a public key for the user since it is only used to
protect these messages, and I don't think they need protection.  Comments
are welcome on this point.
One last point involves the definition of abuse.  As far as I am concerned
that is up to the remailer operator.  Last week I got a very polite and
worried letter from a girl wondering why she had received mail from my
remailer inviting her to such some guy's finger, except it wasn't his finger.
(Despite our recent discussion of this list's implicit "X" rating I am
reluctant to be more explicit.)  I don't get too many of these but I feel
bad about them all the same.  My current approach is to add each person to
the list of blocked outgoing addresses, but I think the technology would allow
for a more effective solution.

@_date: 1994-03-28 13:17:01
@_author: Hal 
@_subject: Magic Money simplification 
In my posting about remailer abuse, I mentioned a point in passing re
Magic Money that perhaps deserves a more explicit mention.
Presently, Magic Money has each user create a special public key just
for use by that program.  When MM sends a message to the bank, it includes
a copy of the user's public key.  Then, when the bank sends the return
message, it encrypts it with that key.  (Messages to the bank are also
encrypted with the bank's public key.)
Last night it occured to me that this encryption may not be necessary.
Messages to the bank are of the form f(x)*r^e, where f is a one-way
function, x is the coin's serial number, r is a random blinding factor,
and e is the bank's public exponent for this denomination.  The bank
signs this by taking it to the d power, were d is the RSA-inverse of e,
and sends back f(x)^d * r.
It looks to me like these two messages are secure even without being
encrypted with the user's or bank's public key.  r, and r^e, both act
as one-time-pads, blinding the underlying f(x) or f(x)^d value perfectly.
This blinding, of course, is what prevents the bank from linking up
withdrawn cash from spent cash.  But it should serve just as well to
prevent an eavesdropper from stealing the cash.
If someone manages to get f(x)^d * r, this is of no value to them if they
don't know r.  Since only the original sender knows r, this message can
be sent in the clear.  Similar logic applies to the message from the user
to the bank.
If this argument holds up, the usage of Magic Money can be simplified
considerably.  The user should no longer have to create a special public
key.  Nor should he need to know the bank's public key.  All he needs to
get started is the email address of the bank, to which he can send the
standard initialization query message which causes the bank to send back
information about the exponents and denominations used, as well as the name
of the money.
Of course, when users send actual un-blinded coins amongst themselves as
payment, those transmissions need to be encrypted or done via some secure
channel.  But MM never concerned itself with those.  It was only involved
with messages to and from the bank, and for these it seems to me that
encryption is not necessary.

@_date: 1994-03-30 09:16:44
@_author: Hal 
@_subject: Web of Trust? 
One of the key concepts widely used to describe PGP is the "web of trust".
This brings to mind a network of connections between people who know and
communicate with each other.  Two people who want to communicate can do
so securely if there is a path of connections in the form of signed keys
that joins them.
But this is not quite right.  The fundamental fact about PGP key signatures,
which is often misunderstood, is this:
You can only communicate securely with someone whose key is signed by a person
you know, either personally or by reputation.
In other words, if I want to communicate with joe at abc.com, I can only do so
if one of the signators of his key is a person I know.  If not, I have no way
of judging the validity of his key.
This belies simple interpretations of the "web of trust".  I may have signed
A's key, A has signed B's, B has signed C's, C has signed D's, and D has signed
Joe's, but this is of no value unless I know D.  Only then can I trust Joe's
This means that, in the "web" picture, I can only communicate securely with
people who are at most two hops away in the web of connections.  I can
communicate with the people I know, and I can communicate with the people they
know, and that is it.
This is unfortunate, because the simple web model ties into some famous
research which suggests that any two people chosen at random are only about
half a dozen steps apart in the web of who-knows-whom connections.  (This
result is where the title of the movie "Six Degrees of Separation" comes from.)
If you had a system which actually supported communications via such a web
model, it actually would have hope of letting two people communicate who did
not have a very long chain between them.  But PGP, with a maximum chain length
of two, will not allow this.
What would have to be added in order to allow a true web of trust model to be
used in a program like PGP?  Basically what is needed is some way to judge
the trustworthyness of signatures by people you don't know.  This would most
plausibly be provided by the people who had signed their keys.  For example,
if there were another type of key signature which did not only vouch for the
person's identity, but also for his trustworthyness and care in signing keys,
then a chain of such signatures could serve as the basis for a true web of
trust.  Obviously such signatures could not be given out nearly as easily as
the kind we have now, where a glance at some stranger's drivers' licence is
often all we get, but they could be given to close friends and those we know
and trust.
More elaborate systems might include numerical ratings of trustworthiness
which would help to estimate the strength of any given path.  The main point
is that some information of this kind would be needed in order to allow
communication with people distant in the web of connections.
Without this, I think we will continue to have problems with PGP being unable
to validate keys of people we want to communicate with.  People will collect
huge laundry lists of signatures in the hopes that whoever wants to commu-
nicate with them will know one of those people.  Centralized key validators
will appear (as in the case of the SLED service being started now, which will
sign a key based on a signed check with your name on it).  The result may be
a choice between using an unsigned key or using one signed by some faceless
bureaucracy, which is no better than the original PEM conception.
(People may be confused by this essay because they thought PGP worked this
way already.  PGP does have a follow-the-web model, but that is only for
following signatures.  In the example above, where I wanted to talk to Joe
and there was a chain to him through A, B, C, and D, we have to first sup-
pose that I know and trust all of A, B, C, and D.  Given that, what PGP can
do is to determine whether I have valid keys for all of those people.  It will
notice that A has signed B's key, so it is valid.  I know B and told PGP he
was trustworthy, and he signed C's key, so therefore that one is valid.  Sim-
ilarly, I know C and I know D so PGP can follow the chain through them.  Fin-
ally we come to Joe, whom I don't know, but because I know D and PGP followed
the web to determine that D's key is valid, PGP can determine that Joe's key
is valid.  But again, that was only because I knew D and everyone else in
the chain.  The bottom line is still that I can only communicate with people
who know someone I know.)

@_date: 1994-03-30 20:30:31
@_author: Hal 
@_subject: Crypto and new computing strategies 
British physicist David Deutsch has been writing for several years on
the theoretical properties of computers which would exploit quantum
mechanics.  Here is the abstract from his paper in Proc. R. Soc. Lond. A,
v 400, p97-117, 1985:
Quantum Theory, the Church-Turing Principle and the Universal Quantum
"It is argued that underlying the Church-Turing hypothesis there is an
implicit physical assertion.  Here, this assertion is presented explicitly
as a physical principle: 'every finitely realizable physical system can be
perfectly simulated by a universal model computing machine operating by
finite means.'  Classical physics and the universal Turing machine, because
the former is continuous and the latter discrete, do not obey the principle,
at least in the strong form above.  A class of model computing machines that
is the quantum generalization of the class of Turing machines is described,
and it is shown that quantum theory and the 'universal quantum computer'
are compatible with the principle.  Computing machines resembling the
universal quantum computer could, in principle, be built and would have many
remarkable properties not reproducible by any Turing machine.  These do
not include the computation of non-recursive functions, but they do include
'quantum parallelism,' a method by which certain probabilistic tasks can
be performed faster by a universal quantum computer than by any classical
restriction of it.  The intuitive explanation of these properties places
an intolerable strain on all interpretations of quantum theory other than
Everett's.  Some of the numerous connections between the quantum theory of
computation and the rest of physics are explored.  Quantum complexity theory
allows a physically more reasonable definition of the 'complexity' or
'knowledge' in a physical system than does classical complexity theory."

@_date: 1994-03-30 22:04:59
@_author: Hal 
@_subject: Bekenstein Bound (was: Crypto and new computing strategies) 
The Deutsch paper I quoted before was where I first heard of the Bekenstein
Bound which Eric Hughes mentioned.  According to Deutsch:
"If the theory of the thermodynamics of black holes is trustworthy, no
system enclosed by a surface with an appropriately defined area A can have
more than a finite number
        N(A) = exp(A c^3 / 4 hbar G)
of distinguishable accessible states (hbar is the Planck reduced constant,
G is the gravitational constant, and c is the speed of light.)"
The reference he gives is:
Bekenstein, J.D. 1981 Phys Rev D v23, p287
For those with calculators,  c is approximately 3.00*10^10 cm/s, G is
6.67*10^-8 cm^3/g s^2, and hbar is 1.05*10^-27 g cm^2/s.  N comes out
to be pretty darn big by our standards!

@_date: 1994-03-31 08:03:00
@_author: Hal 
@_subject: Bekenstein Bound 
Actually black holes do have a defined surface area, which is basically, as
you suggest, the area of the event horizon.  And of course this is larger
for more massive black holes, as you say.
I believe the Bekenstein bound is based on reasoning that suggests that
if the state density of a region exceeds that bound, it will essentially
collapse into a black hole and be inaccessible to the rest of the universe.
The surface area in that context can be the conventionally defined area.
To bring this back to crypto a bit, the point of this discussion was that
there can be only a finite amount of processing done in finite time by
a finite-sized machine, even when QM is taken into consideration.  Note,
though, that this result appears to require bringing in quantum gravitation,
a very poorly understood theory at present.

@_date: 1994-03-31 23:10:40
@_author: Hal 
@_subject: Traceable Digicash? 
The Magic Money digital cash system, which is based on one of the earliest
papers on electronic cash, is traceable.  That is, the payer can collude
with the bank and together they can recognize when the payed-out cash is
turned in.  In some situations, this could be beneficial.  If people have
bank accounts in their True Names, or are otherwise physically traceable
when they turn in money, then if someone steals cash or otherwise uses
coercion to acquire it, then they will not be able to turn it in without
being caught.
Virtually all of the digital cash proposals that I am aware of have this
property.  They protect the payer's privacy very strongly, but they don't
offer much protection to the payee.  Technically it is difficult to protect
the payee because the cash would have to be changed while in his hands so
that it is not recognizable to either the bank or the payer.  This would
require two re-blinding operations, one by the payer and one by the payee,
and it is hard to have a system which could do this and still detect double-
People might want to think about the pros and cons of traceable cash.  It
could limit some possible applications.  On the other hand, it may be good
to help prevent coercion.  One of the cash papers (I can't remember which
one) mentioned this as an explicit advantage of the cash that was proposed.
Does anyone know of any cash systems which protect the payee's privacy?

@_date: 1994-05-01 09:37:17
@_author: Hal 
@_subject: waffle remailer header blocks 
This was posted here:
Note the three lines at Reply to:.  These prevent chaining from working
from this remailer to my remailer.  To implement chaining, my remailer
expects to see "::" as the first non-blank line.  Instead, it sees the
"Reply to": as the first non-blank line.  Those three lines should be part
of the header.  If they can't be put into the header, they should not be
sent out at all.
(Several weeks ago, I got a great many messages from the rebma remailer that
looked the same way.  I haven't seen those in a while, so either Bill fixed
the problem or else people have given up on trying to chain from rebma to
my remailer.)

@_date: 1994-05-01 10:07:14
@_author: Hal 
@_subject: The American money capture 
There are a couple of things I disagree with in Gary Jeffers' post.
(Mild spelling flame - it's "fiat" money, not "fait" money.)  I am
interested not from the conspiracy aspects, but from the private-
versus public-money angle.
Until 1850, there was no official paper money in the United States.
The US government controlled coinage, but they had a lot of problems getting
enough money into circulation, especially in the fast-growing frontier
area.  Between 1800 and 1850 a great number of private banks were started
whose main function was to issue paper money.  Although this money was not
a legal tender (meaning simply that people could refuse to accept it) it did
circulate widely as cash, often displacing coins.
Although ostensibly backed by lawful money (e.g. US coins), this did not stop
the bankers from engaging in fractional-reserve banking.  Indeed, if they had
not done so, their banks would have been of no value, as they would not have
helped remedy the shortage of circulating money.
(Today, with our experiences of inflation in the 1970's and 1980's, it is hard
for us to appreciate the problems with deflation.  But I think deflation was
much worse.  The effects are similar to what we see today when the Fed
tightens the reins on the money supply - a halt to economic growth, business
bankruptcies, growth of unemployment, debtors unable to pay off their debts,
mortgage foreclosures, etc.)
(Also, note that a constant money supply in a growing economy is effectively
deflationary.  The money supply must increase at least as fast as economic
growth or it will serve as an active brake on the economy, IMO.  I don't
know what economic school this view comes from, but I first heard it from
Milton Friedman.)
Even though the cash was not "official", inflation was a problem.  In fact,
it was a chronic, overwhelming problem.  Once a bank realizes that it can
buy things simply by printing money, it takes more self-restraint than most
institutions (private _or_ public) have to keep from doing so.  Things were
made worse by the fact that our understanding of the inevitable bad results
of such inflation was simply absent back then.  The bankers did not under-
stand that printing more money would inevitably devalue the currency.  They
thought that the inflation they saw was due to psychological factors, people
not trusting the bank, or greedy merchants trying to take advantage of the
public.  (These arguments were echoed in the 1970's and 1980's, but they
have of course been widely discredited now.  The issue was far less clear in
Throughout the private-banking era, runs on banks, booms, busts, and panics,
all the traditional extreme manifestations of the business cycle, were seen.
And all this occured at a time when the only lawful, legal tender money was
hard currency: gold, silver and copper coins.  Clearly having such a money
is no proof against the pernicious effects of inflation.
Despite this historical record, I think that private currencies today
would have the potential to succeed.  The increased economic
sophistication about the effects of different monetary policies would
help bankers steer clear of the most egregious errors of the 1800's.
Digital cash signatures avoid the widespread counterfeiting and
discounting which also plagued that era.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-05-01 10:32:09
@_author: hfinney@shell.portal.com 
@_subject: Another remailer 
Found this on the nets:
X-PGP-Key-Fingerprint 67 91 9D E9 97 E1 0F D9  F7 A5 B2 58 EA AB 3A F9
X-Newsreader: Rnf 0.78
-----BEGIN PGP SIGNED MESSAGE-----
Hello Everyone!
announce the creation of a new anonymous mail/usenet server. This server is based on the PGP-compatible Cypherpunk mail servers and operates with the same set of commands. The address to this new server is remailer at jpunix.com. Here is a brief description of how to use the server:
    How to use the Cypherpunks Remailers
    ------------------------------------
    by Hal Finney, <74076.1041 at compuserve.com>
There are two general ways of specifying the remailing instructions.
The simplest is to add an extra field to the header of the message.
All of the Cypherpunks remailers will accept the field name
"Request-Remailing-To:".  (Several of the remailers also accept shorter
versions of this name, but there is no standard for the short versions
accepted.)  Simply put the address that you want the mail to be forwarded
to after "Request-Remailing-To:" in the message header, and the forwarding
will be done.  (Case is important in this header field, so be sure to put
in the capital letters as shown.)
This remailer software also supports "X-Anon-To:".
Many people have mailers which will not allow them to add fields to the
headers of the messages they send.  Instead, they can only put material
into the bodies of the mail.  In order to accomodate such systems, the
Cypherpunks remailers provide a mechanism for "pasting" the first few
lines of the message body into the header.  These lines can then contain
"Request-Remailing-To:" / "X-Anon-To:" commands.
This is done by having the first non-blank line of your message be the
special token "::" (two colons).  If the Cypherpunks remailers see this
as the first non-blank line, all following lines up to a blank one
will be pasted into your mail header.  Then the message will be processed
as usual.  Here is how the message above would be prepared if Sue were
not able to add lines to her outgoing message header.
This new server will also support posting to USEnet in the form:
Request-Remailing-To: news.group
where news.group is the newsgroup the user wishes to post to.
If you have any problems or questions, feel free to contect me at perry at jpunix.com. Please find the public key of the new server listed below for those of you wishing to encrypt to the server.

@_date: 1994-05-02 10:09:36
@_author: Hal 
@_subject: Blum-Blum-Shub source? 
The Blum-Blum-Shub PRNG is really very simple.  There is source floating
around on the crypto ftp sites, but it is a set of scripts for the Unix
bignum calculator "bc", plus some shell scripts, so it is not very port-
To create a BBS RNG, choose two random primes p and q which are congruent
to 3 mod 4.  Then the RNG is based on the iteration x = x*x mod n.  x is
initialized as a random seed.  (x should be a quadratic residue, meaning
that it is the square of some number mod n, but that can be arranged by
iterating the RNG once before using its output.)
The only questionable part about the RNG is how many bits of x to use per
iteration.  The original BBS paper proved that the RNG was secure if you used
just the LSB of x each time.  Later there was a proof that you could use
log-base-two of the number of bits of n bits each time; if n were 512 bits
then you could use 9 bits per iteration.  Some time back I saw a claim on
sci.crypt that you could use up to 1/3 of the bits each time safely, but I
don't think that was proven.

@_date: 1994-05-02 13:54:31
@_author: Hal 
@_subject: the value of money 
Blanc Weber asks about the size of the money supply.  Uni points out that
nobody paid him any Tacky Tokens for his list of state policies re ID's.
Somebody else also mentioned that nobody paid him any Tacky Tokens for
some .gif.
It appears that the Magic Money/Tacky Token experiment is not succeeding
in producing an informal digital currency.  People have offered services
in exchange for this money but have had no takers.  It may be that there
is not much demand for their services, and the lack of offers simply re-
flects that.  OTOH it could be a money-supply problem: there may not be
enough Tacky Tokens "in circulation" to allow them to be used as money.
(There may also be some problems in advertising these services.  I recall
Uni's post offering his list in exchange for Tokens.  He didn't explain
what the list was, just mentioned that it was about ID's.  I didn't remember
what he was talking about until he posted the complete list here.  Similarly,
the recent complaint about nobody paying for a .gif didn't include any
information about what the .gif was!  Folks, if you want to sell something,
make sure people know what you're selling.)
I think it would be interesting and helpful to our cause if reports
about Cypherpunks were able to say something like, "An informal form of
'digital cash', based on cryptography and providing complete anonymity,
has been used experimentally within the group to buy and sell
information and other services.  Based on the success of these
experiments, plans are being developed for more widespread deployment
of this 'crypto cash'."
Why don't we brainstorm a bit to see if we could come up with a way
to take this digital cash software and do something useful and interesting
with it.  It seems like too good an opportunity to just let it sit there and
do nothing.  I know there has been some abstract discussion about cash
systems in the past, but now we have something concrete and we should be
to discuss it more specifically.

@_date: 1994-05-02 22:31:12
@_author: Hal 
@_subject: the value of money 
What is Magic Money?
Magic Money is an implementation of one of the first "digital cash"
proposals, described by Chaum, Fiat and Naor in Crypto 88.  It is an
"online" system.  This means that the money must be checked with the
bank at each transaction to make sure it has not been spent before.
It was written by the pseudonymous Pr0duct Cypher, author of the PGP
Tools library.
What is digital cash?
Digital cash (aka digital coins) is a cryptographic technique for creating
information packets which can be authenticated as belonging to the issuing
agency, but in such a way that no one can link a piece of digital cash to
the transaction in which it was created.
In other words, the user is issued a piece of digital cash by communicating
with the bank via a special protocol.  This cash bears a digital signature
by the bank which can be verified by anyone, and which cannot be forged.
However, the cash creation protocol is such that neither the bank nor anyone
else will recognize that piece of cash as having been withdrawn at that
particular interaction.
This combination of characteristics makes digital cash an attractive
option for electronic payments.  The digital signature makes it unforgeable,
while the lack of traceability protects the privacy of the person spending
the cash (in contrast, say, to credit card use, where the credit card
company learns many details about the spending habits of its customers).
What gives digital cash value?
That is what I am hoping people will discuss.
Here is what Pr0duct Cypher wrote in his introductory message about Magic
As I indicated at the start of this thread, this model does not seem to be
working.  What steps could we take to give digital cash value?
What are Tacky Tokens?
Mike Duvos has been running an implementation of Magic Money that he calls
Tacky Tokens.  Sending mail to  with the word "Bank" in the
subject will cause it to be processed by a Magic Money server and the result
returned to the sender.
How do you actually use Magic Money?
First you get a client program.  ftp to /pub/mpj at ftp.netcom.com to find
a DOS client.  Sources to allow you to build Unix clients can be found at
csn.org by ftp; start in the /mpj directory, read README.MPJ, then cd to
the crypto directory.  cd to pgp_tools, get mgmny10e.zip and pgptl10d.zip.
Build these on your system.  I also made a half-hearted Mac port which still
uses a console window.
The client is pretty easy to use.  First you initialize it, which involves
creating a special public key which will be used for your communications
with the bank.  Then, whenever anyone sends you some Magic Money, you run
the client with the name of that file; the client shows you the denominations
of the incoming Magic Money digital "coins", and lets you choose new
denominations for when you turn these in at the bank.  This creates an
output file which you mail to the bank.  You'll get back another mail message
from the bank which you save to a file and run the client on, and the new
money is added to your collection.  To spend money run the client with the
withdraw option, pick the coins you want to spend, and they will go into
a disk file.  Send this to the person you are giving the money to.
There are things that could be improved about this; the interface could be
nicer, or it could be integrated better into the mail system.  But I doubt
that anyone has used it enough that they are tired of constantly switching
back and forth between their client and email system.  If we had that much
cash being circulated then it would make sense to work on these UI issues.
But I don't think these are the fundamental hurdles.
I hope this gives those who have not heard of the software some idea of
how it works and what its capabilities are.

@_date: 1994-05-04 22:53:15
@_author: Hal 
@_subject: Keyserver service outRAGE 
Let's not fly off the handle.
This _could_ be a very promising development.  IF source code is available,
this would be, at last, a U.S.-legal, free version of PGP.
Let's wait and see what Phil Zimmermann has to say.

@_date: 1994-05-05 13:42:30
@_author: Hal 
@_subject: Text of MIT PGP Announcement 
Here is what I found there:
                                    [IMAGE]
                            MIT PGP ANNOUNCEMENT
     _________________________________________________________________
These pages constantly under construction
     _________________________________________________________________
   [IMAGE] Jeffrey Schiller
     _________________________________________________________________
   The Massachusetts Institute of Technology announces that it will
   shortly distribute PGP version 2.5, incorporating the RSAREF 2.0
   cryptographic toolkit under license from RSA Data Security, Inc.,
   dated March 16, 1994. In accordance with the terms and limitations of
   the RSAREF 2.0 license of March 16, 1994, this version of PGP may be
   used for non-commercial purposes only.
   PGP 2.5 strictly conforms to the conditions of the RSAREF 2.0 license
   of March 16, 1994. As permitted under its RSAREF license, MIT's
   distribution of PGP 2.5 includes an accompanying distribution of the
   March 16, 1994 release of RSAREF 2.0. Users of PGP 2.5 are directed to
   consult the RSAREF 2.0 license included with the distribution to
   understand their obligations under that license.
   This distribution of PGP 2.5, available in source code form, will be
   available only to users within the United States of America. Use of
   PGP 2.5 (and the included RSAREF 2.0) may be subject to export
   control. Questions concerning possible export restrictions on PGP 2.5
   (and RSAREF 2.0) should be directed to the U.S. State Department's
   Office of Defense Trade Controls.
   [IMAGE] Return to Cyberstation Home
   mail commentsto
    webmaster at media.org

@_date: 1994-05-05 22:11:47
@_author: Hal 
@_subject: Lady Ada's Cryptophone 
Diffie-Hellman can be quite slow as well, depending on the size
of the exponents.  It involves calculating x**y, twice, where x
and y are about 512 to 1024 bits.  Some variants have the exponent
yl be smaller, around 140 bits, but if strong primes are used for
the modulus the exponent will be large like this.  And the Chinese
Remainder Theorem speedup used by PGP when RSA signing would not
be applicable here.  So calculating a DH key exchange could take
many times longer than an RSA signature by PGP.  This takes about
fifteen seconds on my old PC; doing a DH key exchange might take a
It might be possible to compute the DH in the background while the
conversation is going on, but if the computer is also compressing,
uncompressing, encrypting and decrypting at the same time, that's
not going to be easy.

@_date: 1994-05-05 22:18:40
@_author: Hal 
@_subject: Marked_Money 
It's not the depositor who generates the coin, it's the withdrawer.
Generally, he will be able to, in effect, "mark" the coin so that
when it is deposited at the bank (by whomever he paid it to) the
bank will be able to recognize that cash (because the withdrawer told
the bank what the numbers were).
However, with digital cash, it may be possible for the depositor to be
anonymous and deposit the cash without being identified, so that even
though the cash is recognized it does not necessarily reveal the depositor.

@_date: 1994-05-08 09:50:47
@_author: Hal 
@_subject: Message to Hal 
It has come to my attention that I am the only subscribed member of the
list at present.  Everyone else seems to have unsubscribed, or been unsub-
scribed, and only I have resubscribed.
So, I'll just take this opportunity to make a test post, without worrying
about swamping hundreds of mailboxes...

@_date: 1994-05-09 13:32:21
@_author: Hal 
@_subject: PGP 2.5 changes 
Below I have included the contents of the file newfor25.doc from the
PGP 2.5 beta release which I just grabbed.  It says that old (pre
2.3) signatures will not verify under 2.5.  That's too bad.  Also, key
sizes are limited to 1024 bits.  Tough luck for people who made bigger
ones, I guess.
Looks to me like there may still be a market for a non-RSAREF PGP.
Anyway, here's the file:
Changes to PGP 2.5:
                 ***** MOST IMPORTANT *****
This version of PGP uses RSAREF 2.0, so it's legal in the U.S.!  The
RSAREF license forbids you to (among other things; see the license for
full details) "use the program to provide services to others for which
you are compensated in any manner", but that still covers a lot of
people.  If you want to use it in a commercial or governmental
setting, talk to ViaCrypt (2014 West Peoria Avenue, Phoenix, Arizona
85029, +1 602 944-0773).
PGP 2.5 should always be distributed with a copy of the RSAREF 2.0
license of March 16, 1994 from RSA Data Security, Inc., so that all
users will be aware of their obligations under the RSAREF license.
Since the RSAREF license conflicts with the GNU General Public License that
PGP was formerly distributed under, the GPL had to go.  PGP is still
freely distributable, though.  (From a copyright point of view; export
controls or some other legal hassle may apply.)
*** IMPORTANT CHANGE:
RSAREF 2.0 can understand only the pkcs_compat=1 formats for signatures
and encrypted files.  This has been the default since 2.3, so old files
should not be too much of a problem, but old key signatures will
encounter difficulties.  This change will result in a hole being ripped
in the "web of trust" as many old signatures are invalidated.  Please check
your key rings (pgp -kc) and re-issue any signatures that have been
invalidated.  PGP by default offers to remove such signatures.  Even if you
leave them in, they are not trusted.
Another RSAREF limitation is that it cannot cope with keys longer than
1024 bits.  PGP now prints a reasonably polite error message in such a
OTHER CHANGES:
The support files are thinner.  The various contrib directory utilities
have not been updated since 2.3a, and since the PGP developers know how
annoying it is to have people using an ancient version and complaining
about a bug in a program that was fixed a year ago, they have been
omitted rather than annoy the contributors in this way.  Also, the
language translation file, language, is incomplete.  The strings
that were in 2.3a are there, and some that could be updated without
much knowledge of the language, but others that are new to 2.5 are
untranslated.  The format should be obvious and some tools for
manipulating the language traslations are included in the contrib
Printed KeyIDs have been incresed to 32 bits, as there were enough keys
out there that 24-bit keyIDs were no longer sufficiently unique.  The
previous 24-bit keyID is the LAST 6 digits of an 8-digit 32-bit keyID.
For example, what was printed as A966DD now appears as C7A966DD.
The config-file options
have been added.  Hopefully, the uses will be obvious.  With these, you can
keep keyrings anywhere you like.  Of course, they can also be specified on
the command line with +pubring= (or abbreviated to +pub=).
If the line
appears in the config file, the line "Comment: " appears in
ASCII armor output.  Of course, you can also use this from the
command line, e.g. to include a filename in the ASCII armor, do
"pgp -eat +comment=filename filename recipient".
PGP now enables clearsig by default.  If you sign and ascii-armor a
text file, and do not encrypt it, it is clearsigned unless you ask
for this not to be done.
The now enables textmode.  Textmode detects non-text files and
automatically turns itself off, so it's quite safe to leave on all
the time.  If you haven't got these defaults yourself, you might
want to enable them.
All prompts and progress messages are now printed to stderr, to make them
easier to find and ensure they don't get confused with data on standard
output such as pgp -m output.
PGP now wipes temp files (and files wiped with pgp -w) with pseudo-random
data in an attempt to force disk compressors to overwrite as much data as
On Unix, if the directory /usr/local/lib/pgp exists, it is searched
fror help files, language translations, and the PGP documentation.  On
VMS, the equivalent is PGP$LIBRARY:.  (This is PGP_SYSTEM_DIR, defined
in fileio.h, if you need to change it for your site.)
Also, it is searched for a default global config.  This file may
be overridden by a local config, and it may not set pubring,
secring, randseed or myname (which should be strictly personal)
The normal help files (pgp -h) are pgp.hlp or .hlp, such as
fr.hlp.  Now, there is a separate help file for pgp -k, called pgpkey.hlp,
or key.hlp.  No file is provided by default; PGP will use
its one-page internal help by default, but you can create such a file
at your site.
On Unix systems, $PGPPATH defaults to $HOME/.pgp.
PGP used to get confused if you had a keyring containing signatures from
you, but not your public key.  (PGP can't use the signatures in this case.
Only signatures from keys in the keyring are counted.)
PGP still can't use the signatures, but prints better warning messages.
Also, adding a key on your secret key ring to your public keyring
now asks if the key should be considered ultimately-trusted.
Prviously, you had to run pgp -ke to force this check, which was
Due to a few people distributing PGP without the manual (including one
run of a few thousand CD-ROMs), and the resultant flood of phone calls
from confused users, PGP now looks to make sure a manual is somewhere in
the vicinity when running to discourage this sort of thing.  (If you're
getting this warning and need details on how to get rid of it, try pgp -kg.)
On Unix, PGP now figures out the resolution of the system clock at run
time for the purpose of computing the amount of entropy in keystroke
timings.  This means that on many Unix machines, less typing should be
required to generate keys.  (SunOS and Linux especially.)
The small prime table used in generating keys has been enlarged, which
should speed up key generation somewhat.
There was a bug in PGP 2.3a (and, in fact in 2.4 and dating back to 1.0!)
when generating primes 2 bits over a multiple of the unit size (16 bits
on PC's, 32 bits on most larger computers), if the processor doesn't deal
with expressions like "1<<32" by producing a result of 1.  In practice,
that corresponds to a key size of 64*x+4 bits.
Code changes:
At the request of Windows programmers, the PSTR() macro used to translate
string has been renamed to LANG().
The random-number code has been *thoroughly* cleaned up.  So has the
IDEA code and the MD5 code.  The MD5 code was developed from scratch and
is available for public use.
The Turbo C makefile was dropped in favour of a Borland C .prj file.
You can use makefile.msc as a guide if you need one for a command-line
Turbo C.

@_date: 1994-05-09 23:27:15
@_author: Hal 
@_subject: This is an abstract from a talk at Cornell University... 
I would be surprised if quantum computers had the capability to factor
in polynomial time.  The special capabilities that I have seen claimed
for quantum computers have a probabilistic component, so that, in effect,
you can do a calculation n times faster but have only a 1/n chance of
getting an answer.  (This is an oversimplification but gives the idea.)
In the context of the Many-Worlds interpretation of QM, you might say
that the various instances of the quantum computer spanning the multi-
verse can be made to work together, but by a sort of conservation of
information production, only a fraction of the individual universes of
the multiverse get the answer.
The one loophole that I see is that this term "quantum computer" covers a
lot of territory.  They might sneak in some infinities in addition to adding
the strictly quantum capabilities.  It is known that ordinary computers which
can hold arbitrarily-large numbers (and do arithmetic on them in one time
step) can factor in polynomial time.  If the definition of your quantum
computer is so broad that you can squeeze in some outrageous capability like
this, then the claim of polynomial-time factoring is more plausible.

@_date: 1994-05-11 10:16:58
@_author: Hal 
@_subject: converting old keys to new MIT PGP 2.5 
I get "malformed or obsolete key signature" when I try to signature-check
this key using 2.5.  That is exactly what the readme file warned about.  PGP
changed its signature format in 2.2 or 2.3 but retained backward compatibility.
2.5 is no longer backwards compatible to signatures created in earlier
versions.  Old keys with signatures have been harmed to this extent.
I should add that PGP has always had a policy (one which I don't like) that
compatibility would only be retained across two sub-versions.  In other words,
messages and signatures created with 2.5 are only guaranteed to be usable with
2.6 but perhaps not 2.7.  So this change might have been made anyway even with-
out the move to RSAREF.
It's also worth noting that the old signature format was a bug.  The code
was originally supposed to be PKCS compatible (the format used in RSAREF
and PEM) but late changes broke it; the changes had to do with endian
conversions and the bytes ended up going out in reverse order.  This was
not a security bug, just a compatibility problem.  This problem was discovered
about a year later and was changed, but backwards compatibility was retained
by having PGP check for both signature formats.  So, there has always been
regret about the PGP 2.0 signature format and a desire to abandon it.

@_date: 1994-05-11 23:01:31
@_author: Hal 
@_subject: State Dept Response to my second CJ request 
There is a problem with these "hair splitting" approaches to avoiding the
ITARs (they accept the book; they reject the disks, so we ask to send some-
thing that is halfway between the book and the disks, etc.).  There is a
well-known fallacy (whose fancy name I don't remember) which says that even
though night and day change gradually from one to the other, and you can't
really draw a line separating night from day, that doesn't change the fact
that night is different from day.
We may establish that hitting someone with a baseball bat is against the
law, and hitting them with a feather is not; then we proceed to ask whether
hitting them with a pillow is against the law, and so on.  At some point
the law is forced to make an absurd decision that hitting someone with item
X is illegal while hitting them with Y is not, but X is almost the same as
Does this prove that no amount of assault is illegal?  No.  It just means
that lines are not always easy to draw.
In the same way, it is not easy to draw a line between a book which is
protected by the first amendment and a program which a person can sit
down and run to get military grade cryptography.  But that does not
lead to a strong legal argument that all cryptographic software is export-
able, IMO.

@_date: 1994-05-11 23:06:50
@_author: Hal 
@_subject: Message Havens 
Karl's idea about message havens is interesting, but I don't fully follow
how it differs from the anonymous pools we discussed last year (one such
pool is being run from the extropia site, I believe).  With a message pool
the receivers sift through all of the messages to see which they can decrypt
with their own public key.  Messages can be sent to the pool via anonymous
One problem is that there may not be too many subscribers to any one pool,
so there is not much protection to the users.  With a protocol more similar to
WWW or gopher you might have a larger population of users, although again
you don't have any guarantee of how many other people are downloading all of
the messages.
The other variant on this idea we have discussed is to use Usenet, as
we have seen when people post encrypted messages to Pr0duct Cypher on
alt.security.pgp.  This seems to me to be an inefficient way to send
mail (sending it to thousands of sites just to get to one person) but
it certainly seems to provide good cover to the receiver.  He could be
literally any of probably tens of thousands of readers of that

@_date: 1994-05-12 23:26:17
@_author: Hal 
@_subject: Message Havens, gopherholes 
One problem I see with Karl's suggestion (if I understand it) is that
there needs to be some pre-arrangement between sender and receiver in
order for the receiver to know what "tag" will be used to identify the
next message.  That way he knows to download it after scanning all the
tags (plus, he downloads a certain number of other messages as cover).
(In other words, every day he downloads five messages from the message
haven.  He does this whether he has anything there or not.  An eaves-
dropper doesn't know how many of the five are for him and how many are
just random.)
I think it should be possible to have a way of marking a messages as being
for a particular user without any pre-arragement, and without any outsider
being able to determine which messages are for which user.  Simply encrypting
some standard constant number with the user's public key would be close to
right, although you'd have to find a way to keep the modulus size from
leaking out.
The main down side to this is that the decryption and tag check might take
too long, while Karl's pre-arranged tag idea could be very fast.  Perhaps
both concepts would be useful in different contexts.

@_date: 1994-05-13 08:50:58
@_author: Hal 
@_subject: List moderation 
Two comments: First, from his past comments, I think it very unlikely that
Eric Hughes will want to see this list moderated.  However, he has indicated
that he would have no objection to a second list, run by someone else, which
took all posts from the CP list and moderated them, filtered them, encrypted
them, or whatever.  So some site would be needed to run the moderated list.
Second, is anyone actually willing and able to do this job?  I certainly don't
have time.  How much delay is the moderation process likely to introduce?
How available can the moderators be to handle and process incoming mail?
This seems like a potentially very large time commitment by the moderators
with little reward.

@_date: 1994-05-14 12:39:27
@_author: Hal 
@_subject: Message Havens 
Would it have to be public knowledge which message havens a given
pseudonym monitors?  Suppose I want to get mail to Pr0duct Cypher; don't
I have to know which haven(s) to use?  If we have only a (few?) hundred
people on each haven then this narrows down the pool of possible real
user who are behind that pseudonym considerably.

@_date: 1994-05-14 13:28:16
@_author: Hal 
@_subject: ADMIN: on penet and on paranoia 
Paranoia certainly got a boost here, though, by the recent and still
unexplained emptying of the subscriber list.  Was this actually, as many
have speculated, a malicious action by someone taking advantage of the
majordomo software, or was there a more prosaic explanation?  Or is there
no way for even the list managers to know?
Clear information is one of the best ways to dispell paranoia.

@_date: 1994-05-16 18:18:43
@_author: Hal 
@_subject: Fixing pgp 2.6 
I think there are some things being overlooked in this discussion.
First, note the strong hint in Schiller's message about operators of
key servers who accept pre-2.6 keys being guilty of contributory
infringement of the RSA patent.  I think we can expect strong legal
pressure from RSA to shut down the remaining U.S. key servers, even
those which don't use illegal versions of PGP.  They succeeded once in
shutting down the key servers which used PGP; they will succeed again
in shutting down the others due to the contributory infringement threat.
For the same reason, hopes of getting a non-RSA-approved "2.6a" (hacked
to be backwards compatible with 2.3) widely available in the U.S. are
not well founded.  FTP sites which hold programs or even patch files to
allow 2.6 to interoperate with 2.3 will be targetted by RSA as
contributory infringers.  In short, the legal advantages PGP 2.6 will
have over unapproved versions will be strong enough that it will be
widely used in the U.S.
However, this does not mean the loss of international encrypted
communications.  The solution is simple.  PGP 2.3a will be patched to
be compatible with PGP 2.6.  I don't know what we'll call it,
"PGP2.3e", perhaps, where "e" is for Europe.  2.3e will have the speed
advantages of 2.3a, no copyright problems with RSAREF use, be perfectly
legal outside the U.S., and will interoperate with 2.6.  Converting
from 2.3a to 2.3e will be no more difficult than converting from 2.2 to
2.3 was.
Although I hate Jim Bidzos' guts for what he has done to Phil, he holds
the legal upper hand for the next few years.  The present course does
allow for wider use of encryption by the public, which we can all support.
Look at it rationally, and 2.6 is a step in the right direction.
P.S. It's possible that pre-2.6 keys will not interoperate with 2.6,
in which case users of both 2.6 and what I am calling 2.3e will have to
generate new keys.  This is no great problem; people should make new
keys and retire their old ones every year or two anyway, IMO.

@_date: 1994-05-19 09:00:16
@_author: Hal 
@_subject: Patent infringement (fwd) 
This is the argument Schiller's message on 2.6 foreshadowed.  However,
there are some counterarguments you can make:
 - It's not clear that RSADSI has actually said that merely posting a key with
   the words "Version: 2.3a" in and of itself constitutes inducement or
   conspiracy to infringe the patent.  Schiller speculated that running a key
   server which accepted pre-2.4 keys could represent contributory infringement
   but I haven't seen any statements from Bidzos that agree with this, let
   alone the stronger statement Sternlight is making.
 - Just because the key says "Version: 2.3a" doesn't mean much.  This version
   string is appended by the program which turned the key into ASCII
   format.  It says nothing about the version of the program which used
   the RSA algorithm.  Granted, in practice this suggests that the key
   was extracted from a key ring using PGP 2.3a, but extracting from
   a key ring is not a patented process.  Only communicating using RSA
   is patented.  The mere existence of this key does not show that
   patent infringement is going on.
 - Possession of a 2.3a key does not necessarily constitute inducement to
   infringe the patent.  Perfectly legal programs exist which will work very
   well with a 2.3a key (versions 2.4 and up).  So by possessing a key labelled
   2.3a you are not inducing others to violate anyone's patents.
 - In any case, Sternlight does not have any standing in making this charge.
   He is not a lawyer and is not affiliated with RSADSI in any way.  At best
   his reports are second- or third-hand interpretations of his understanding
   of RSADSI's position.  Unless or until the patent holder speaks directly
   to make these charges, there is no need to respond.
Hal Finney
hfinney at shell.portal.com

@_date: 1994-05-19 09:12:52
@_author: Hal 
@_subject: Mosaic to support digital money in September 
I don't know to what extent this system represents "account based digital
money".  It doesn't sound that different from emailing your credit card
number, something you can do already using PEM or PGP2.4.  I suppose you
will have digital checks with this system as well.  But all of these
systems will allow total tracking of your transactions by the banks.
The digital cash systems we have been experimenting with do not know
"how much the client got, and how much he spent."  There is nothing stopping
a given holder of Magic Money cash from being anonymous to the bank.  He
does not have an "account" with the bank.  (The structure of the client
interface is somewhat misleading in this regard - the user has to go
through an initialization step in which he communicates with the bank, and
it might appear that he is in some sense registering or opening an account.
Actually, he is just grabbing an information packet which shows the current
exponent-to-cash-value mapping.)  In a (hypothetical) "mature" Magic Money
system, people could exchange cash tokens issued by a number of banks using
anonymous networks to communicate with each other and the banks.  There is
no need to trust the bank's circumspection or immunity to political pressure
to preserve your privacy.

@_date: 1994-05-19 21:00:01
@_author: Hal 
@_subject: D-H key exchange - how does it work? 
The problem with "strong" primes, primes for which (p-1)/2 is prime, is
that they are hard to find.  It takes hours and hours of searching to find
a 1024 bit strong prime on a workstation.  Granted, you don't need to change
very often perhaps, but some people would like to change every day.  They
may need a dedicated prime-searching machine to do that.
(The best way I know to find strong primes is to find a prime q and then
check 2q+1 for primality.  Finding 1024 bit primes takes a long time, and
the chances that 2q+1 is prime is very low.)
It's much easier to find a "strongish" prime, one for which (p-1)/k is
prime, where k is on the order of 100 or so.  Take your prime q in the above
and try kq+1 for k=2,4,6,....  This only takes a few minutes after you find
The question is, how good are strongish primes?  What fraction of elements
of the group will have short periods, given that p-1 has a pretty small
number of prime factors?
Also, given a strong or strongish prime, are the chances that
g^x has a small period good enough that it makes sense to check for that
case?  Any event whose chances are smaller than your computer making a
mistake is generally not worth checking for.

@_date: 1994-05-20 14:11:20
@_author: Hal 
@_subject: D-H key exchange - how does it work? 
I don't follow this.  If you never change the modulus (which is what it
sounds like Eric was recommending), then isn't there an even greater
persistency?  Or is it the assumption that everyone uses the same modulus
in that case?

@_date: 1994-05-21 09:28:38
@_author: hfinney@shell.portal.com 
@_subject: Is my DH exchange secure? 
With a strong prime, there is no need to use generators, as Eric implied.
Looking at Phil's list, we see 2's and 5's being chosen as generators.  Even
for those cases where 2 is not a generator, it has period (n-1)/2.  This
is just as good, from what I understand.  Finding the discrete log depends
on the size of the modulus, not on the size of the group, unless the size
of the group is drastically less than the size of the modulus.  That is why
the DSA uses a modulus of 512 bits and a group of size 160 bits.  Even a
group this small provides all the security associated with a 512 bit modulus.
(Caveat: I haven't been able to find my reference to this, but I read it a
few weeks ago in a crypto paper, and I am confident it is standard number
theory/cryptography.)  In the case of a 1024 bit strong prime, non-generators
(other than 1 and -1) have period of size 1023 bits, just as good for all prac-
tical purposes.
For what I was calling "strongish" primes, which are about 100 times easier to
find (primes of the form kq+1, where q is prime and k is around 100),  I
think it is also unnecessary to check for generator-hood.  Non-generators are
overwhelmingly likely to have periods greater than 1000 bits in size, which
provides all the security of the 1024 bit modulus.
Putting this together, secure Diffie-Hellman is much easier to do than the
more careful implementations require.  Picking a strongish prime need not
take much longer than choosing an RSA key of twice the size (e.g. it takes
about as long to choose a strongish 1024 bit prime as to create a 2048 bit
RSA key).  Then pick a random element as the base for the DH exponentiation,
choose your x's and y's at random, and go.  Adding the extra checks really
doesn't increase the security.

@_date: 1994-05-21 22:26:18
@_author: Hal 
@_subject: "Email-Firewalls" / Instant Corporate PGP 
A more secure way is not to setenv PGPPASS but rather:
setenv PGPPASSFD 1
and then
(echo "vinces passphrase" ; cat mailtmp.asc) | pgp -f >> mailtmp
The PGPPASSFD means take the passphrase from file descriptor 1, which is
the standard input.  This way it never appears in the environment of a
process.  Many unix systems have a switch to ps to show all processes'

@_date: 1994-05-22 10:49:16
@_author: Hal 
@_subject: "Email-Firewalls" / Instant Corporate PGP 
Oops; Ed is right, of course; that should be setenv PGPPASSFD 0.

@_date: 1994-05-22 11:11:08
@_author: Hal 
@_subject: Is my DH exchange secure? 
My wording here was a little clumsy; I was not contradicting Eric but
rather attempting to amplify his comments.  There is no need to look
for primitive roots (elements of maximal order); rather you just want to
avoid elements of low order.
I found the paper I referred to which described the tradeoffs between the
order of the group and the size of the modulus.  It is "Efficient Signature
Generation by Smart Cards", by C.P. Schnorr, in the Journal of Cryptology,
1991, v4, pp161-174.  This is the patented Schnorr signature which has been
the basis for PKP's claim that the federal Digital Signature Standard
infringes the Schnorr patent.  (Bruce Schneier recently posted on sci.crypt
that a paper presented at Eurocrypt 94 analyzed all the different discrete-
log based signature scheme, and in his opinion cast doubt on this claim of
Schnorr deals with a prime p, and a smaller prime q which divide p-1.
In his system, q is a lot smaller than p, just big enough to provide the
requisite security.  Small q's allow for faster calculation of g^x since
x is, say, 140 bits rather than 512 bits.  Here is what Schnorr writes on
page 163 (he uses "alpha" where we were using g, as the generator of
the group):
"The Security Complexity 2^t.  We wish to choose the parameters p, q so
that forging a signature or an authentication requires about 2^t steps by
known methods.  For this we choose q >= 2^(2t) and p such that 2^t is about
exp(sqrt(ln p ln ln p)).  The security number t may depend on the
application intended.  For signature we consider in particular t=72 rather
that [sic] t=64, since 2^64 steps may be insufficient in view of the rapid
technological progress in computing power and speed.  For p>=2^512 and
q>=2^140 the discrete logarithm problem requires at least 2^72 steps by
known algorithms.  (It may soon be necessary to increase the lower bound
p>=2^512 due to the current progress in computing discrete logarithms.)
The restriction that the order of [alpha] is a prime much smaller than p
provides no advantage in any of the known discrete logarithm algorithms
provided that q>=2^140.  The prime q is necessary to avoid an index
calculus attack and a square root attack (see Section 2)."
The attack described in section 2 is interesting.  Also known as the
baby-step-giant-step attack, it is a simple meet-in-the-middle-technique.
Suppose you wanted to solve a^x=y given a and y.  Suppose for simplicity
that x is known to be in the range of 0 to 100.  What you can do is to
calculate two lists.  The first is ( a^10, a^20, a^30, ..., a^90 ).  The
second is ( y/(a^1), y/(a^2), y/(a^3), y/(a^4), ..., y/(a^9) ).  Then
you just look for a number which is common to both lists.  If a^20 is the
same as y/(a^4) then we know that y = a^24.  So this takes square root of
q in time and space.  Schnorr says that Pollard has a trick to use less
space.  (Remember the discussion we had here some time back of the prac-
ticality of meet-in-the-middle attacks given the huge space needs for even
2^64 hashes?  I think Pollard's trick may apply to those as well.)

@_date: 1994-05-28 11:24:10
@_author: Hal 
@_subject: Detweiler's motivations 
This kind of suggestion, although made in jest, provides a clue to what
Detweiler is trying to do, IMO.  (These are just my speculations, and perhaps
they are obvious to others, but I haven't seen these specific points made
He posts innumerable messages, alternating between reasonable-sounding
arguments and insane gibbering.  He replies to himself, posting other people's
words as if they were his own.  He calls for accountability and decries the
use of pseudonyms while being one of the most prominent users and abusers
of this technology.
Some have concluded that Detweiler actually is insane, but I don't think
so.  I suspect that he is acting on a carefully calculated program designed
to discredit the kinds of technologies we support.  By posting trash to
the newsgroups under a pseudonym, and making clear that it is just a psuedo-
nym, he hopes to undermine tolerance for this method of using the net.  He
has largely ruined talk.politics.crypto as a forum for serious discussion of
the kinds of social changes which might be brought about by strong crypto-
graphy.  This kind of abuse will undoubtedly lead to complaints against his
service provider, as well as demands to know his true identity.
Detweiler also seeks to reveal hypocrisy on the part of supporters of
anonymity, as when I posted logs of his "Death to Blacknet" post bombs
to dozens of Usenet groups, breaking his anonymity.  He is saying that
anonymity is so bad that even its supporters will seek to destroy it
when provoked.  In this way he seeks to further discredit CP goals.
His bizarre practice of posting replies to his own messages, criticizing
his own words in scathing tones (apparently basing these messages on the
private email he receives) is designed to show that lack of clear ident-
ification of message sources is confusing.  This further advances his argu-
ment that psuedonymity is bad and that clear identification of identities
will be necessary for effective communication.
So, having failed to persuade by his words, Detweiler is trying to demon-
strate his points by example.  By taking all that he hates and becoming the
embodiment of it, to an exagerrated degree, he is trying to show that
anonymity is dangerous, confusing, and a barrier to communication.  In this
light, his behavior is perfectly rational.

@_date: 1994-05-30 17:19:11
@_author: Hal 
@_subject: IMP (was Re: ecash-info (fwd)) 
I agree with this, which is why I don't understand why you said:
You're jumping the gun here a little, aren't you?  There is no evidence
yet that Chaum's current proposals are going to catch on.  The CommerceNet
idea seemed to have more backing judging from the press releases.  And it
did not appear to support anonymous transactions.
I don't follow this argument.  You are suggesting that an anonymous cash
market would be more efficient than one based on checks and credit cards?
It would have lower transaction costs, so things would be available for lower
prices?  Why is this?  The hypothetical discussions we've had here on "if I
ran an anonymous bank" often talked about service charges.
Your use of the term "capstone" is unclear in this context.  Are you suggesting
that retaining privacy is more important for most people than trusting a
seller in most transactions?  Most people would rather buy from FlyByNight
Corp if they could stay anonymous than from Sears using their credit card?
I don't think so.  For some people, the kind who won't use checks today and
get by with cash and money orders, this might be true.  But I don't see
it as being the rule.
It seemed to me that the IMP list discussions degenerated into flame wars
between Detweiler and cypherpunks.  Those in the middle, which included
most subscribers, were shocked and disgusted by Detweiler's crude flaming
and this made everyone uncomfortable about bringing up the topic of anon-
ymity and cash.  With Detweiler on the list it was impossible to have a
serious discussion of the matter.
Chaum is trying to make money off his ideas.  In doing so, he is being
guided by the invisible hand of the market to try to find those niches where
his technologies can be most profitable.  Maybe going after the bankers is
the wrong idea, but it is understandably tempting to prefer trying to get
millions of dollars from a few people than a few dollars from millions of
people.  It does sound, though, like he is trying to branch out now and
spread his technology around.  Perhaps he will follow the lead of RSA and
make a "ChaumREF" free implementation of his cash technology.  The Commerce-
Net model had RSA supplying free client software while charging the vendors
licensing fees, I believe.  Chaum may be planning a similar approach.
It would be nice to see more details about what Chaum has in mind.  My
WWW access is very weak.  Could someone summarize what is available
at the page listed above?

@_date: 1994-11-17 23:40:23
@_author: Hal 
@_subject: Islands in the Net 
Yes, I think as Tim mentioned that safe-tcl is a possible way to go here.
You could really do a lot of what Telescript promises with safe-tcl, and
it is completely open and non-proprietary so anybody could run a server.
Basically, safe-tcl is a limited subset of the tcl scripting language
designed to allow "active mail", which can contain programs to run either
at the time the mail is put into your mailbox or at the time you read it.
Most of their interest is in the latter, because since tcl is married to
the X scripting package tk, you can actually have an incoming mail
message which puts up its own X dialog boxes, etc.  Somebody wrote a
sample mail-based tictactoe game, where you click in a box and it
automatically sends an appropriate program to the other player which will
put up the game board and let him click, etc.  Imagine this for crypto
But, back to the remailers, as Andrew says this agent-based or "active"
mail provides a whole new paradigm for viewing remailers.  Rather than
being this anarchic threat to the net as they are often pasted, they are
simply one of a wide class of servers.  If we can move to a model in
which semi-autonomous agents do surf the net, then remailers become just
a small part of a much bigger picture.  I may allow incoming agents to
use various resources on my machine, including the mail facilities.  A
remailer is then just a server which does not enforce a lot of
state information on outgoing messages to record their incoming path.
I suppose the thing to watch for here will be efforts on the part of
net.control freaks to force agents to be carefully authenticated,
regulated, ordered and tracked.  Just as the mail specs (RFC822)
emphasize the importance of a human owner of every piece of mail so you
have someone to complain to, similar motivations may play a part in
future specs for active mail and similar extensions.  This is going to be
a continual battle which we will have to be ready for.

@_date: 1994-11-19 18:21:48
@_author: Hal 
@_subject: I Like ASCII, not MIME and Other Fancy Crap 
Another thing to keep in mind is that, probably, two years from now
a considerable majority of people on the net will be people who aren't
using it yet.  They won't have twenty years of experience with ASCII
and Unix and /bin/mail, etc.  As Lucky Green says, they will get going
with Mosaic or derivatives and never leave it.  They will use Internet
in a Box (or an equivalent from AOL or Microsoft) and get set up and
running easily.  They won't have to use Archie to find a JPEG or GIF
viewer, it will be built in.  Most of them will use a PC running
Windows 95, a few will use Macs.  That will be the net in two years,
We should be ready for that world and working to keep it safe for
privacy.  As Phil Z. said in the PGP docs, "skate to where the puck will
be."  We need to look forward, not look back to the good old days.

@_date: 1994-11-20 21:56:10
@_author: Hal 
@_subject: DNA solution to Hamiltonian circuit? 
There is an interesting crypto connection here in that the work was done by
Len Adelman of USC, the "A" of RSA.
This research was reported in a recent issue of Science, but I am going by
a report in Science News.  What I will describe is the gist of the work, but I may have some details wrong.
The Hamiltonian path problem asks whether there is a path through a
given graph which passes through each node exactly once.  Adelman took
a smallish graph and encoded each of the 20-odd links as a particular
short DNA sequence.  He then made DNA sequences which consisted of
pairs of these codes connected together for each case of two paths
which shared a node.  Then he had some other pieces of DNA which could
stick these together if the codes on the end matched.  The net result
was that every possible path through the network would be represented by
a DNA strand which would self-assemble.
Then it was a matter of filtering the DNA for strands of the proper length
which did not have any duplicate nodes.  The SN article wasn't clear about
how this was done.
So, my take on this is that the clever part was casting the problem in
a way which matched the behavior of DNA strands.  Realizing that the
Hamiltonian path problem can be expressed in terms of self-assembly of
short strands was the real trick.  I doubt that any reasonable
extension of this technique would do modular arithmetic or the
complicated logic of DES, so this presumably doesn't represent any
immediate threat to crypto algorithms.  I suppose the question would be
whether there could be a compiler which would take logic equations and
turn them into DNA strands which mirrored the equations.  That seems unlikely
but more plausible IMO than the quantum computers people have discussed.

@_date: 1994-11-22 13:43:40
@_author: Hal 
@_subject: Borenstein Speech 
It's kind of ironic, because on the one hand Borenstein is using
some nice technology which would lend itsef very well to crypto
protocols, electronic cash, and other privacy-protecting transactions.
But it is being used to facilitate VISA card payments and many people
have raised questions about the security of the system.
When you place an order, you get a safe-tcl style "enabled mail"
message (which Tim would hate!).  This is readable but if you have
safe-tcl running it will actually pop up a dialog box or something
which you can click on to confirm your payment.  I think this would
be a good thing for DigiCash to copy if/when they start supporting
email transactions.  It would be fun for Magic Money too.
Borenstein and First Virtual also have a whole set of MIME extensions
for electronic transactions which might also serve as a model for
more general types of payments.  Maybe Rich could ask whether they
are considering that.
In general, FV has a lot of good ideas IMO, but it's too bad they
are still tied to the old models of payment.

@_date: 1994-11-22 14:12:49
@_author: Hal 
@_subject: California Code online 
For the "book disadvantaged" among us, I saw a reference today to the
California civil code online.  It is at:
  The form of this URL
suggests that other states might be there, too, but I didn't look.
This is a very nice presentation, structured with each section in a
separate page, and a nice table of contents.  I was browsing the
commercial code which has lot sof interesting info on commercial paper
and other subjects of interest with regard to digital cash.

@_date: 1994-11-26 20:48:01
@_author: Hal 
@_subject: Santa uses PGP 
is Santa's home page.  For your kids you can order
buttons saying "I emailed Santa", at $5 per.  Afraid to send your VISA
card number across the net?  No problem - they use PGP.  Key available
by mail to button-info at shop.net, orders to buttons at shop.net.
(I have no connection to this business - but it's nice to imagine a
bunch of kids pestering Dad to get PGP so he can order them a button!)
P.S. Here's the key.  pub   512/44C65CC5 1994/11/23 I e-mailed Santa Buttons  -----BEGIN PGP PUBLIC KEY BLOCK-----
Version: 2.3
-----END PGP PUBLIC KEY BLOCK-----

@_date: 1994-11-26 23:04:49
@_author: Hal 
@_subject: WWW "remailers" 
We have had some discussions here about privacy of accesses on the World
Wide Web.  Presently servers get a variable amount of information about
the people accessing their sites, depending on the particular software
being used and how it is configured.  This is potentially harmful to the
privacy of WWW users in that their access information can be recorded,
etc.  Here are some things you can do to reduce this problem.
First, try connecting to:
   This just displays environment variables, which shows what information
about you is being received by servers.  Look particularly at the lines
reading HTTP_FROM and REMOTE_HOST.  These may contain your user name and
computer address.
You may be able to remove your user name information.  Some clients,
including, I am told, NetScape and version 2 of Mosaic for Mac/Windows,
allow you to set your email address, which is handy, but then they send
it along to servers, which is harmful to your privacy.  You might want to
consider not setting this field and using other programs for sending
mail.  Also if people complain about this then perhaps the makers of this
software will add an option to suppress sending the info.
Even if you don't see your name in HTTP_FROM it still may be possible
for somewhat more sophisticated programs to log your access if the
REMOTE_HOST information is correct and you are running on a Unix system
or something similar.  This is done via the identd service if that is
running on your computer.  The server can use this service to ask for
your user name once you are connected.  One way to see if identd is
running on your computer is to telnet to your own computer on port 113
and see if anything is there (telnet  113).  If so
then this is potentially another privacy exposure.
I have recently been experimenting with using "proxy servers" to remove
even the REMOTE_HOST information from the server's view.  Proxy servers
are servers which basically receive WWW connections and pass them along.
Then when the data comes from the remote site they pass it back to the
originating user's site.  Because the proxy server is in the middle the
remote site never sees the host name of the originating user.  In this
respect they are somewhat similar to our cypherpunk remailers, hence the
title of this article.
(The purpose of proxy servers has nothing to do with this function; they
are designed to allow easy WWW access from users who are on firewalled
sites.  But they happen to serve our purposes as well.)
Interestingly, the standard nntpd (nntp daemon, the master server which
runs on a site which offers web pages) from CERN includes proxying
capability automatically!  All you have to do is to add a few lines to the
configuration file.  If this idea proves sound, perhaps some people
running nntpd will enable proxies and serve as "remailer operators of the
Normally proxy servers are configured to pass connections only from the
machines they are there to serve (at least, they can be configured that
way; I don't actually know how careful people are about this).  But
luckily I have found that the CERN proxy server itself accepts
connections from anybody (at least, it accepts them from me!).  So this
is useful for doing experiments.
And, the great part is, almost all web clients are set up now for proxy
support.  The way you enable it varies from client to client.  I believe
most of the Mac and Windows clients have a preferences box which allows
you to put in the address of your proxy server.  On Unix, you can set
environment variables.  Here is the suggestion from the web page at
        http_proxy="   export http_proxy
    ftp_proxy="    export ftp_proxy
    gopher_proxy=" export gopher_proxy
    wais_proxy="   export wais_proxy
    exec Mosaic
This is a little shell script which runs Mosaic, first setting four
environment variables to " which is the proxy
server I was referring to, the one which accepts connections from the
rest of the world.
For the purpose of the experiment, only http_proxy needs to be set.
Try setting that one and then run lynx or mosaic on your unix
workstation, and connect to the printenv URL above.  Compare the
information that is shown from what you got earlier without the
environment variable.  Similarly, on other machines, try the printenv
test with and without proxy serving enabled using the CERN proxy.
I find that the proxy server does in fact prevent the remote site from
seeing my computer's address, and without that the IDENTD can't be used
to reveal my name.
This technique has many ramifications.  For example, if a US proxy server
were available, ftp could be done via Mosaic to sites which only allowed
connections from American computers.  People have been talking about
writing special IP redirectors for this, but here it turns out the
capability has been around all along.
I got my information about proxies by reading:
  Specific information on
configuring CERN nntpd as a proxy server is in:
Modifications to the proxy server code would be necessary to provide some
additional features, such as support of encryption between user and proxy
server (via the SHTTP protocol extensions, perhaps; this way you could
get local privacy even when connecting to servers which did not support
encryption), or possibly chaining of proxies.  I think this is a fertile
area for discussion and further work.

@_date: 1994-11-27 08:49:41
@_author: Hal 
@_subject: WWW "remailers" (corrected copy) 
This is a re-post of an earlier message where I accidently wrote "nntp"
in place of "http".  I have added some more material, too.  Please
ignore the earlier message, and thanks to those who pointed out the
We have had some discussions here about privacy of accesses on the World
Wide Web.  Presently servers get a variable amount of information about
the people accessing their sites, depending on the particular software
being used and how it is configured.  This is potentially harmful to the
privacy of WWW users in that their access information can be recorded,
Far from being a hypothetical concern, I believe many companies are
collecting this information and using it to build up possible future
email mailing lists, etc.  I spoke recently with someone who is designing
enhanced server software for the web.  Their system will keep all kinds
of statistics about who accesses which pages on the server, correlating
that with which people request information on the products being sold.
We have also seen how even too-cool Wired magazine is demanding user
names to allow access to their pages.  (Remember: username cypherpunk,
password cypherpunk.)
Here are some things you can do to reduce this problem.  First, to see
how bad the problem is for you, try connecting to:
   This just displays environment variables, which shows what information
about you is being received by servers.  Look particularly at the lines
reading HTTP_FROM and REMOTE_HOST.  These may contain your user name and
computer address.
You may be able to remove your user name information.  Some clients,
including, I am told, NetScape and version 2 of Mosaic for Mac/Windows,
allow you to set your email address, which is handy, but then they send
it along to servers, which is harmful to your privacy.  You might want to
consider not setting this field and using other programs for sending
mail.  Also if people complain about this then perhaps the makers of this
software will add an option to suppress sending the info.
Even if you don't see your name in HTTP_FROM it still may be possible
for somewhat more sophisticated programs to log your access if the
REMOTE_HOST information is correct and you are running on a Unix system
or something similar.  This is done via the identd service if that is
running on your computer.  The server can use this service to ask for
your user name once you are connected.  One way to see if identd is
running on your computer is to telnet to your own computer on port 113
and see if anything is there (telnet  113).  If so
then this is potentially another privacy exposure.
I have recently been experimenting with using "proxy servers" to remove
even the REMOTE_HOST information from the server's view.  Proxy servers
are servers which basically receive WWW connections and pass them along.
Then when the data comes from the remote site they pass it back to the
originating user's site.  Because the proxy server is in the middle the
remote site never sees the host name of the originating user.  In this
respect they are somewhat similar to our cypherpunk remailers, hence the
title of this article.
(The purpose of proxy servers has nothing to do with this function; they
are designed to allow easy WWW access from users who are on firewalled
sites.  But they happen to serve our purposes as well.)
Interestingly, the standard httpd (http daemon, the master server which
runs on a site which offers web pages) from CERN includes proxying
capability automatically!  All you have to do is to add four lines to
the configuration file.  (See the URLs below for more info.)  If this
idea proves sound, perhaps some cypherpunks running httpd will enable
proxies and serve as "remailer operators of the web".
Normally proxy servers are configured to pass connections only from the
machines they are there to serve (at least, they can be configured that
way; I don't actually know how careful people are about this).  But
luckily I have found that the CERN proxy server itself accepts
connections from anybody (at least, it accepts them from me!).  So this
is useful for doing experiments.
And, the great part is, almost all web clients are set up now for proxy
support.  The way you enable it varies from client to client.  I believe
most of the Mac and Windows clients have a preferences box which allows
you to put in the address of your proxy server.  On Unix, you can set
environment variables.  Here is the suggestion from the web page at
        http_proxy="   export http_proxy
    ftp_proxy="    export ftp_proxy
    gopher_proxy=" export gopher_proxy
    wais_proxy="   export wais_proxy
    exec Mosaic
This is a little shell script which runs Mosaic, first setting four
environment variables to " which is the proxy
server I was referring to, the one which accepts connections from the
rest of the world.
For the purpose of the experiment, only http_proxy needs to be set.
Try setting that one and then run lynx or mosaic on your unix
workstation, and connect to the printenv URL above.  Compare the
information that is shown from what you got earlier without the
environment variable.  Similarly, on other machines, try the printenv
test with and without proxy serving enabled using the CERN proxy.
I find that the proxy server does in fact prevent the remote site from
seeing my computer's address, and without that the IDENTD can't be used
to reveal my name.
This technique has many ramifications.  For example, if a US proxy server
were available, ftp could be done via Mosaic to sites which only allowed
connections from American computers.  People have been talking about
writing special IP redirectors for this, but here it turns out the
capability has been around all along.
Can anyone supply addresses of additional proxy servers to try?  I had an
idea about how to find them.  Many web servers log accesses.  By
searching those access logs it might be possible to find proxy sites.
The server is given information about whether a proxy is used, as well.
This shows up in the HTTP_USER_AGENT environment variable on the
printenv page.  Servers could look for references to proxies in that data
and collect proxy addresses in that way.  There is a nice irony in using
server logging to collect data that would allow users to defeat much
server logging.
I got my information about proxies by reading:
  Specific information on
configuring CERN httpd as a proxy server is in:
Modifications to the proxy server code would be necessary to provide some
additional features, such as support of encryption between user and proxy
server (via the SHTTP protocol extensions, perhaps; this way you could
get local privacy even when connecting to servers which did not support
encryption), or possibly chaining of proxies.  I think this is a fertile
area for discussion and further work.

@_date: 1994-11-29 10:15:07
@_author: Hal 
@_subject: Transparent Email 
Just create a special key for your netcom account.  Use no pass phrase;
using one would give a misleading sense of security IMO.  Just pass your
mail through "pgp -saft" or equivalent and you've got it.  It is easy to
do this from most editors.

@_date: 1994-10-01 10:56:50
@_author: Hal 
@_subject: Technical Remailer Analysis. 
Good point.  There is a related attack which Chaum pointed out in his
1981 CACM paper: the attacker intercepts and keeps a copy of an incoming
message, then later re-sends it.  This one will go to the same place and
by repeating this multiple times we can figure out where the original
message went.
If I follow this, the attack is something like, every time Alice sends
a message Bob receives one.  Observing this happening over a period of
time we conclude they are communicating.  Could this be defeated by
sending dummy messages so that Alice sends exactly 10 messages every day?
Then the fact that Bob receives messages on some day can't very well
be associated with Alice.

@_date: 1994-10-05 08:37:29
@_author: Hal 
@_subject: Referrences to SKE and GAK 
Thanks to Carl for an interesting essay on key escrow.
What is being escrowed in the SKE proposals?  Is it the session key?
What is the advantage to the user of broadcasting a session key encrypted
to an escrow agent?  That does not sound like a spare key in the wallet.
What about the aspect of SKE which allows compliant implementations to
verify that the session key is actually being honestly reported to the
escrow agent?  Isn't that where most of the cryptographic challenge and
interest comes from, and again how does that benefit the customer?  It
seems strictly for the benefit of wiretappers.
What about key escrow systems which allow users to store encrypted
versions of their public keys?  There would still be the danger of the
user dying or forgetting his pass phrase, but in many circumstances
that is tolerable.  The KE agency then simply becomes a data backup
facility.  Is TIS working on this?  This seems like the true analog of
the spare key in the wallet.
I get the impression that despite all of the good and reasonable things
you can say about key escrow, the actual work and interest is strictly
going towards systems to allow government wiretapping.  No significant
efforts are going into these other ideas which might be useful to the
customer but are irrelevant to the wiretapping issue.  So I am afraid
that the actual work on SKE is only going to hurt privacy despite
Carl's hopes.

@_date: 1994-09-01 16:29:46
@_author: Hal 
@_subject: Is the following digicash protocol possible? 
(I have rearranged James' two paragraphs)
There are protocols to do essentially this, although they get
rather complicated.  It is necessary for each person in the chain
to have some knowledge of the person he is passing the money to,
so that he can confirm that that person is in fact revealing something
about himself that will incriminate him if he double-spends.  If all
parties in the transactions are totally anonymous then there is no
hope of tracking down a double-spender.
My reading of Chaum's paper "Transferred Cash Grows in Size" is that
if you have a system to satisfy the 1st paragraph, it cannot also satisfy
this.  It appears that if B, E and the bank collude, and B knows he gave
the cash to C and E knows that he got it from D, then they can tell that
C gave it to D.  Basically B recognizes the money E got from D, with
the bank's help.  Although Chaum wrote as though his results applied to
any conceivable transferrable double-spending-detecting cash system,
it wasn't clear to me how general his results really were.
Hal Finney

@_date: 1994-09-03 08:38:29
@_author: Hal 
@_subject: Problems with anonymous escrow 2--response 
This is similar to Tim May's suggestion for a credential-less society
(as far as possible).  Rather than trying to carry around a lot of
baggage in the form of certifications, credentials, reputations, etc.
(anonymous or not), people structure their affairs in such a way that
transactions can be completed using just the information at hand.
Blanc's idea for immediate demos to demonstrate competency could tie
into this nicely.
I didn't quite follow the rest of Blanc's message (a problem I have, I'm
afraid, with many of his postings) but I do agree that there are problems
with the use of reputations as a catch-all to solve the problems of
anonymity.  Faced with the ease of unpunished cheating in an anonymous
relationship, people introduce the idea of reputations, sometimes called
"reputation capital", and assert that cheaters would in fact be punished
by damage to their reputations, the loss of reputation capital.
What is this stuff, reputation capital?  What does it look like?  How can
it be measured?  How much is it really worth?  I think this concept needs
to be clarified and examined if it is to serve as one of the principle
foundations of pseudonymous commerce.  (I know there is a concept in
modern finance which attempts to measure the economic value of a firm's
reputation, called, I think, "good will", but I don't know how similar
that would be to what we are talking about.)
One question is, to the extent that a "piece of reputation capital" is an
actual object, a digital signature or token of some sort, how heavily
linked is it to a given owner?  If I run two pseudonyms, Bert and Ernie,
and Ernie earns a piece of reputation capital, can he securely transfer
it to Bert and have Bert show it as his own?
On the one hand, we would not want this to be so (or, expressed in less
normative terms, people would probably be uninclined to put much value on
reputation capital which had this mathematical structure).  If the
purpose of reputation capital is to, in effect, punish cheaters, this is
defeated to a large extent if it can be transferred.  Ernie can earn
a reputation, cheat, and then have Bert show the good aspects of Ernie's
reputation while being unlinkable to the bad.  Going back to the earlier
discussion of anonymous escrow agents this would seem to make it far too
easy for dishonest agents to succeed.
On the other hand, untransferrable credentials are undesirable from the
point of view of privacy.  That was the whole point of Chaum's work on
pseudonyms and credentials.  If pseudonym credentials are untransferrable
we have a problem where information builds up about a pseudonym that is
very nearly as bad as a completely identified system.  It is true that at
least the ultimate linkage between pseudonym and physical body is broken,
but to the extent that your on-line activities _are_ your pseudonym, it
is no more desirable to allow dossiers to be built up about your on-line
personality than your off-line life.
Chaum's system worked in large part because it was ultimately grounded in
an identity-based system.  People could have credentials and transfer
them, but there were limits on the types and numbers of pseudonyms you
could have.  I think these kinds of restrictions could limit some of the
problems which arise with transferrable reputation credentials, although
the general problem of "negative credentials", which is really another
word for the problem of punishing cheaters, was not fully solved by
Chaum's approach, at least not in a way that I understood (he wrote as
though he had solved it).
One final point I'd make is that Tim's idea about avoiding credentials,
along with the points Blanc made, is attractive but there do seem to be a
lot of situations where credentials are shown in life.  When that is
necessary it is tempting to fall back on a trusted authority, the
anonymous escrow agent or perhaps Jason Solinsky's cyberspace government,
but I think you still have the problem of those authorities proving their
honesty.  So the problems of credentials and reputations are still

@_date: 1994-09-03 08:59:03
@_author: Hal 
@_subject: How do I choose constants suitable for Diffe-Hellman? 
These requirements are slightly overkill, IMO.  n does have to be prime,
but what you really want is to have g generate a "large enough" sub-group
of the numbers from 1 to n.  One way to achive this is to have (n-1)/2
also be prime, in which case the order of g (the length of g^0,g^1,...,1)
is either 1, n-1, 2, or (n-1)/2.  The odds of it being 1 or 2 are
practically nil, so you could really use a random g since a period of
(n-1)/2 is more than good enough.  Or, you could test g by raising it to
the (n-1)/2 power and if the answer is 1 reject it and try another g.
That way you get one with period n-1 which is maximal.
There was a program posted here last time we discussed this (maybe four
months ago?) which sieved for both n prime and (n-1)/2 prime.  It was
pretty fast.
One thing you can do which IMO is just as good is to choose a g with a
considerably smaller period.  There are two known ways to solve
discrete logs; one depends on the size of n and the other depends on
the size of the order of g(|g|).  The second one is much weaker so if
you choose the size of |g| to provide about as much security as the
method based on the size of n you get something like n=512, |g|=140.
This is used in the DSS, I believe.
The advantage of this is that it is faster to exponentiate g^x in DH
since x will be only 140 bits.
So, to use this, pick a prime q of 140 bits, then find a prime n equal to
kq+1 for some k, such that n is 512 bits.  This assures that there are
some generators g which have a period of q.  There is an easy trick to
find one: pick a random number a < n, and set g = a ^ ((n-1)/q).  It
follows that g^q equals 1 (since it is a^(n-1)), and since q is prime it
must be the order of g.
As I said, you can always use the full DH, but you would be in good
company using the small-q version.  One question is the size of q to use
for n=1024.  I haven't seen a clear answer to that, but the general
principle is that if solving discrete logs becomes X times harder, you
should increase q by a factor of X^2.  So if DH is a million times harder
for n=1024 than for n=512 (it's hard to tell with all of the O(1) factors
in the formulas) then q should be 40 bits longer or about 180 bits.

@_date: 1994-09-03 20:50:51
@_author: Hal 
@_subject: Problems with anonymous escrow 2--response 
No, my questions were not rhetorical at all.  I do think that various
people have come up with ideas for what they call reputation capital that
are much more formalized and structured than what you are referring to.
This doesn't mean that they are right and you wrong, just that there are
a lot of different concepts floating around under this umbrella of a
As one example, consider how signed endorsements could be used to
create and validate a reputation.  We already see that today with
celebrity endorsements in advertising.  I once sold a product where the
main competitor had (years ago) collected a favorable comment by
Dvorak, the well-known computer columnist.  I'll bet a lot of people
had never heard of that company but when they saw Dvorak's quote the
image of that company was improved a great deal.  This endorsement
could be called reputation capital.  In a very real sense, it was one
of the principal assets of that company.  I believe many conceptions of
reputation capital consist of collections of such endorsements, along
with an infrastructure to support them (similar perhaps to the PGP web of
There is always the danger of legislative interference in any action but
I really don't think our discussions here are likely to bring disaster
down on us.
On the contrary, I think that a pseudonymous/anonymous world calls for
a re-examination of the concept of reputations.  Today there is no
implementation of a transferrable credential, where I could for example
prove that company XYZ considers me a good credit risk, without XYZ
linking my present nom de guerre with the one I used when with them.
Today there is no use made of blind signatures.  A few years ago
public-key encryption was almost unknown in the private sector.  All of
these technologies could have significant impact on business
relationships.  Things are changing, and we on this list are some of
the few people who are interested in talking about the effects of these
Right, I did discuss this point.  This helps prevent people from
certain kinds of cheating.  But the down side is that sellers have to
give up some (all?) privacy.  And, after all, practically everyone is
selling something, even if just their labor.  Is the solution that we
have privacy as consumers but not as sellers?  I don't think this is
the only possible answer.  It is worth considering whether privacy can
be provided to sellers as well.
As another example, consider the case of someone applying for credit.
Here the bank is, in a sense, selling money.  OTOH the applicant is
selling something, too - his ability to pay.  Do we just say that "of
course" dossiers of people's credit history and banks' lending history
are the desirable and correct way to solve this problem, as we have
today?  I would prefer to see whether solutions could be derived in which
more privacy is provided to the participants.  Obviously total anonymity
would make such lending virtually impossible, but perhaps there is some
middle ground between that and a system of total identification.  This is
where Chaum is coming from with his credentials.  His solutions have
problems, granted, but I don't think it is necessarily time to give up
and say that the kinds of dossiers we have today are the best way things
can work.

@_date: 1994-09-05 17:41:48
@_author: Hal 
@_subject: \"Reputations\" are more than just nominalist hot air 
I tried to post something on this last night, but Toad apparently
hiccupped and lost it.  My suggestion was that we do not discuss
"reputations", where I think James is right that the term already
refers to an opinion someone holds in his mind, but rather "reputation
capital" or perhaps "reputation credentials", which are information
structures which may be used to establish or support a reputation.
The example I used last night was that "reputation capital" is not "reputation" any more than the "liberty bell" is "liberty".
Then perhaps we can avoid arguing about what a reputation is, and instead
focus on the interesting issue of what the role of cryptography will be
in establishing reputations in a possibly-pseudonymous business network.

@_date: 1994-09-06 08:21:33
@_author: Hal 
@_subject: Problems with anonymous escrow 2--response 
Well, there are at least a couple of reasons why a seller might want to
do this, one (IMO) good and one bad.  The good one would be to allow
sellers to do socially or politically unpopular things without being
punished for them.  For example, someone selling pro-civil rights material
during the 1950's, or someone selling homosexual rights material today
might find themselves facing a certain amount of prejudice if they also
wanted to sell more mainstream stuff.  By being able to run two businesses
which are unlinkable but to apply their good credit record, good customer
response record, etc. from one business to the other, we encourage diversity
and a free market in ideas.
On the other hand, an unscrupulous seller could open up a string of
businesses, be honest for a few months to collect some good credentials
like this, then fold the business and keep customer money.  He then
opens up a new business and uses his old good credentials to get going
quickly, only to repeat the process.
Both of these kinds of activities happen today, but in the network
environment there are a lot more possibilities for records keeping.
Today it may be an open secret that "Praise the Lord Publications" and
"Hot Sex Novels" are both published by the same guy, but probably most
of his customers don't know it.  On the net it will be a lot harder to
keep this kind of thing secret because of the greater access to infor-
mation.  Likewise, the fly-by-night boiler-room telemarketing service
may have a harder time competing in a network environment where the lack
of a track record will be more obvious, but the cryptographic credentials
which solve the first problem may also allow this tactic to be more
successful as well.

@_date: 1994-09-06 15:20:33
@_author: Hal 
@_subject: Reputation Capital papers? 
I seem to recall a posting in outline form by Dean Tribble to this list
about 1 1/2 years ago.  It was some notes he had used in a presentation
to a CP meeting.  Maybe someone could dig it out again.
I don't think Chaum has particularly used the term or even discussed
the issue that much.  It doesn't seem like it is an issue which is
talked about in many places.  Your ideas are probably as much worth
hearing as anyone's.
Hal Finney
P.S. I did find a paper on the net called "Endorsements, Licensing,
and Insurance for Distributed System Services", by Lai, Medvinsky,
and Newman of Information Sciences Institute.  Here is the abstract:
"Clients in a distributed system place their confidence in many servers,
and servers themselves rely on other servers for file storage,
authentication, authorization, and payment.  When a system spans
administrative boundaries it becomes harder to assess the security and
competence of potential service providers.  This paper examines the issue
of confidence in large distributed systems.
"When confidence is lacking in the 'real world,' one relies on
endorsements, licensing, insurance, and surety bonds to compensate.  We
show that by incorporating such assurances into a distributed system,
users are better able to evaluate the risks incurred when using a
particular server.  This paper describes a method to electronically
represent endorsements, licenses, and insurance policies, and discusses
the means by which clients use such items when selecting service
Unfortunately, I can't recall where I saw the pointer to this paper.
I'm sure other people read the same lists and newsgroups I do so perhaps
someone else can provide a pointer.  Also, my copy of the postscript
paper would only print the first three pages, so I can't really evaluate
their ideas.

@_date: 1994-09-06 21:46:15
@_author: Hal 
@_subject: Reputation Capital papers? 
Thanks to Bob Hettinga for providing a reference to that paper which
discusses several issues related to what we might call "reputation
capital".  I was able to fix my Postscript problems and get the whole
paper printed.
Two of the three authors are the originators of the NetCash proposal.  I
gave that paper a pretty negative review here a few months ago, mostly
because their "cash" was non-anonymous, and was really a digital
certified check.  That's fine, although not IMO cryptographically
interesting and I really didn't see much about their proposal that wasn't
I find this paper more interesting.  They discuss the general issues of
servers establishing credibility with clients through various strategies:
licenses, where a legal agency provides a credential that the server
meets various minimum standards; endorsements, which are similar but
which tend to come from private agencies and will often have a range of
levels (like the 1 to 5 diamond ratings granted to hotels by the AAA);
insurance, where an insurance company guarantees that suits are possible
in the case of breach of contract; and surety bonding, which is similar
but covers a wider range of unsatisfactory completions to the relationship.  Most of these make sense in the context of business
interactions as well as traditional client/server computing.
After a promising introduction, the paper takes a mundane turn, proposing
data structures to encode information about these various kinds of
"assurance credentials", with slots for what is covered, to what amount,
under what conditions it would apply, etc.  I think it is way premature
to try to specify what kinds of information would be in these
They do get into some more interesting material when they discuss ways in
which these credentials might be shown and authenticated.  Generally, the
assurance credential is created or issued by some 3rd party: a bank, an
insurance company, a government, a rating agency like AAA or Consumers
Union.  (We would probably add, individuals known to the client.  The
authors have something of an institutional bias, and discuss institutions
providing credentials to benefit other institutions, neglecting the
problem of how individuals establish their own credibility.  This is
especially noticable in their section 7.3 where they point out that
institutions which hold large sums of money for their clients will have
much greater authentication requirements than those which grant credit.
The obvious symmetry of the two situations appears to escape the authors'
notice.)  Once the credential is given to the server, it can then show it
to the client.
They do appear to allow for something similar to blinded credentials.
The term they use for these credentials is "proxies" because in a sense
the credential acts as a proxy, a substitute, for the organization which
issued the credential.  (The real reason for this strained terminology is
to tie this paper in with the senior author's other papers, IMO.)  They
suggest that there would be two classes of proxies: "bearer" proxies,
which appear not to have the server's identity explicitly encoded, but
which are granted under terms in which only servers knowing a particular
secret key are considered to be valid; and "delegate" proxies, which
appear to explicitly encode the server's identity.  The author's
terminology is a bit hard to follow here, so it is possible that I am
missing their point, but it does sound like they have the germ of the
idea of being able to show a credential in a way where the credential is
not explicitly identity-bound.
Of course, they have missed the point of blinding of credentials (they
give no sign of ever having heard of the concept), and the bearer
proxies would actually be linkable by the proxy issuer.  It is not
really clear what the value is of the very limited form of anonymity
allowed by bearer proxies.
After this rocky portion (the authors really need to read the literature!
this is the same problem that NetCash had) they move into quite a
dramatic and impressive vision of a "web of trust" system of credentials
backing up credentials.  The point is that the issuing agencies
themselves may need backup (what is the value of an endorsement by the
Direct Mail Marketing Association if you've never heard of them?)  This
leads to the concept of "transitive assurance" in which A endorses B and
B endorses C, allowing you to follow the chain and give some credibility
to C.  Here is one good point they make:
"Transitive assurance may extend to an arbitrary depth, but longer chains
generally promote less confidence.  Where assurance is rated, heuristics
are needed for deriving the combined assurance rating from the metrics
and limits associated with the individual credentials involved.  Such
heuristics are a topic for further study."
Alert readers will see a connection to the PGP web of trust, and the
authors actually make this connection.  They go on to point out that in
PGP certifications pertain to identity only.  There is no mechanism in
PGP to endorse the signing and endorsement policies of other users.  This
was the point I made some time back in a posting here in which I pointed
out that the "web of trust" is a misnomer because you can only trust keys
which you have verified directly or where you know and trust someone who
knows the end user.  In contrast, a system of transitive assurance is a
true web of trust, where Consumer's Union endorses the Microwave
Manufacturers' Association which endorses Joe's Microwave Repair,
allowing me to trust Joe even though I've never heard of the MMA.
The authors have a nice diagram showing a web of credentials with clients,
and various kinds of authenticating and endorsing agencies, all in a
complicated system of connections.  I think this is very close to the
ideas people have had here for how a system of reputation credentials
could work.
They also discuss how assurance credentials could be used to give credibility
to an issuer of electronic cash.  Banks or other financial agencies could
provide credentials that the issuer had assets greater than a certain
amount (so you know the currency is backed), and auditors could provide
credentials that the books balance.  Once again they have neglected the
interesting topic of how or whether blinded credentials could work but
this is not a bad start.
In a way it is kind of sad to see how primitive the understanding is of
these issues in the "mainstream".  OTOH it is good to see any discussion
at all.  Hopefully papers like this will attract some interest on the
part of the many people who are trying to jump onto the internet-business

@_date: 1994-09-07 08:28:55
@_author: Hal 
@_subject: AIDs testing and privacy 
Let me point out that nothing stops you from filling the prescription
and then giving the drugs to someone else, so it would seem that a doctor
who would be willing to cooperate in any such protocol should also be
willing to make the prescription out to a pseudonym.
Chaum's "blinded credential" system is intended to solve exactly this kind
of problem, but it requires an extensive infrastructure.  There has to be
an agency where you physically identify yourself.  It doesn't have to know
anything about you other than some physical ID like fingerprints.  You and
it cooperate to create pseudonyms of various classes, for example, a
"go to the doctor" pseudonym, and a "go to the pharmacy" pseudonym.  These
pseudonyms have a certain mathematical relationship which allows you to
re-blind credentials written to one pseudonym to apply to any other.  But
the agency uses your physical ID to make sure you only get one pseudonym of
each kind.
So, when the doctor gives you a prescription, that is a credential applied
to your "go to the doctor" pseudonym.  (You can of course also reveal your
real name to the doctor if you want.)  Then you show it at the pharmacy using your "go to the pharmacy" pseudonym.  The credential can only be shown
on this one pseudonym at the pharamacy, but it is unlinkable to the one
you got at the doctor's.  (It would be possible to encode information in
the credential about which doctor wrote it, which would help track abuse,
although that would obviously make it easier to link up your pharmacy and
doctor visits.)

@_date: 1994-09-09 08:40:00
@_author: Hal 
@_subject: Cracking MD5 for $10M 
I mentioned a few days ago that one of the "rump session" papers at the
crypto conference claimed that a machine could be built which would find
MD5 collisions for $10M in about 20 days.  I wanted to write a little
more detail about how this attack could work.  It is similar to a "meet
in the middle" (MITM) attack which Norm Hardy suggested here in July when
we were discussing double DES:
The idea of saving only outputs where certain bits are constant is the
key to the "distinguished points" method which is used to save space with
only a modest cost in time.  The other key idea is that instead of
evaluating MD5(n) where n iterates on its own, you look for cycles in the
recurrence x = MD5(x).  Any cycle which is found which does not include
the x you start with will lead to a case where two values hash to the
same MD5 value.
For a trivial example, suppose the output of a formula like this consists
of the values 1,4,5,2,7,8,5,2,7,8,5,2,7,8,....  Here we have a four
element cycle which leads to two different predecessors for the value 5.
The brute-force way to solve this would be to save all outputs from the
formula, and with each new value to compare it with all earlier
values.  With MD5, which has a presumably random structure and 128 bits
of output, the birthday paradox suggests that you would have to create
and save about 2^64 output values before finding a match.  Creating
2^64 values might be possible today for the time and dollar values we
are talking about, but storing them appears to be out of the question,
as our earlier discussion of double DES (and other discussions of MITM
here) have made clear.
The distinguished points method reduces the space requirements by only
saving a fraction of the output values.  For example, in the list above,
we might only save multiples of 4.  This would lead to 4,8,8... and it
is easy to discover the match without nearly as much storage.  Note,
though, that 8 is not actually the value which has two predecessors, but
that once this match is discovered, you can go back to the previous
points (4 and 8 in this case) and run them forward more carefully,
looking for a match.
The other real advantage of the distinguished points method is that it
parallelizes very nicely.  Several machines can run x=MD5(x) with
different starting values, saving all of the distinguished outputs, and
we can look for matches between machines as well as in one machine.
Again, a match implies two different predecessors for the same value,
which is an MD5 collision.
With the size of MD5, suppose we generate 2^64 outputs but only save
those for which the low-order 32 bits are 0 as our distinguished points.
Only 1/2^32 of values will match, so we will end up with about 2^32
outputs, probably a manageable amount.  Chances are there will be a match
among that set.  We then go back to the previous distinguished points
before the match and work forward carefully to look for the exact pair of
values which lead to the same successor.  Distinguished points will be
about 2^32 apart so this step is easy and quick.  If you want to speed it
up still more you can do a recursive distinguished points pass for this
step using maybe d.p.'s with the low-order 16-bits of 0 and do it in two
steps that will both be very short.
The net result is that we have taken virtually no more time (the 2^64
creations of MD5 will dominate) and virtually no space (compared to 2^64
stored values) and we get the effect of a birthday attack.  This is
another cautionary data point about the risks of relying on space costs
for security rather than time costs.

@_date: 1994-09-09 11:25:43
@_author: Hal 
@_subject: Cracking MD5 for $10M 
Yes, this is a good point, the main advantage of the DP algorithm is
that it parallelizes.  Rho does have the problem that you have to run
3 MD5's for each step, but OTOH it does not have the overhead of saving
and checking the distinguished points, so which one would be best on a single processor would depend on the relative costs.
They didn't mention anything about this, and I would think they would have
if they had considered it.  My intuition was that x=MD5(x) would cover a
large fraction of the 128 bit output space, but on further thought Jim
appears to be right: with n input values into a random function (n would
be 2^128 in this case), the chance of a particular output being missed for any one input would be 1-1/n, and the chance of it being missed for all
n inputs would be (1-1/n)^n.  Taking the limit as n approaches infinity
gives 1/e as the fraction of values which would be missed.  This means
that the fraction of hits would be 1 - 1/e, much lower than I had
The way I figure it, if the fraction of the original n is f (which would be
1 before the first iteration, and 1 - 1/e before the 2nd iteration based on
the above), the chance of a point being missed is (1-1/n)^(nf), which is
1/e^f.  So f would be found by f = 1 - 1/e^f, iterating once per MD5
iteration and starting f at 1.  I just did an experiment of iterating this.
After 100 times f was about .02; after 1000 times f was about .002,
suggesting f = 2/iterations.  If this is right, you might be able to get
a birthday match after only the cube root of n tries rather than the
square root of n, or about 2^44 iterations or so rather than 2^64, because
at that point you are only looking at 2^85 possible output values.
This result is only really valid for serial machines; parallel ones
search more per iteration so this would move you back towards the 2^64
number.  It does imply that you don't really get k-fold speedup with k
machines if you take this effect into consideration.
Gee, my calendar must be off!

@_date: 1994-09-09 20:38:50
@_author: Hal 
@_subject: digital reputation capital 
At one time there was something similar to this called the Hawthorne
Exchange (or HEX) associated with the Extropians list.  Various entities
(like people and nyms, and later, confusingly, ideas) could be registered
and people could buy and sell "shares" in these registered entities.
The market price of a share was supposed to in some sense represent
the value of the reputation.  At least, that's how I understood it.  The
goals were never 100% clear to me.
It did not seem to work very well.  You need to give people an
incentive to participate, to register their opinions.  Because you
could actually make "monetary units" by buying low and selling high,
there seemed to be a lot of volatility and price manipulation in the
market, especially since there wasn't much to tie the prices to
reality.  You might check on the Extropians list for more information.

@_date: 1994-09-10 13:37:53
@_author: Hal 
@_subject: reputation credit 3/3 
Adam Shostack writes a very interesting set of articles on a concrete
proposal for reputation credentials.
A couple of suggestions: maybe you should distinguish between respecting
someone as a writer and respecting them as a reviewer.  In the real world,
we have editors, publishers, and others whose main job is to discover and
facilitate the good writers.  Just because you write well doesn't mean
you will be good at recommending other writers, and vice versa.  Adam
brings this up himself when he talks about a good writer who intentionally
makes bad recommendations.  Creating these two different kinds of credentials
would help solve this.
A related point is that doing this helps remove some of the normative or
reward/punishment aspects of this system.  Saying that you like someone's
recommendations is similar to saying that you have similar tastes to
theirs.  There is not so much stigma or insult associated with refusal to
give a credential saying that you like someone as a reviewer.  It just
means your tastes differ.
OTOH refusing to endorse someone as a writer is a stickier business.  It
may offend others and it could bring retribution upon yourself.  It could
be a way to create enemies.  Especially if you went with numerical
rankings so you said "I like John Doe's writing 5% of the time", this
could be insulting.  If you don't have these "negative" credentials it is
not so bad but it still may be noticable if someone endorses a lot of
people with a few notable exceptions.
The problem, then, is that people may be reluctant to be honest with
their opinions.  They may find it safer to follow the crowd and add their
own endorsements to those already popular than to take a chance with
honest praise of some pariah.  There was some discussion about this in
the development of PGP.  Should there be a way for people to say how much
they trust another person as a signer?  If you had this (in a public way)
then you could have transitive trust to some extent and it would expand
the web of trust considerably.  But again the concern was that people
would not want to expose what they truly thought of the signing policies
of their friends.  I suppose you could get around this by having one set
of opinions for public consumption and another set used for personal
message rankings, but that seems a bit extreme.
Still, I think it would be a worthwhile thing to try.  It would be nice
if we could do some more interesting cryptographic stuff than just simple
signatures, though.

@_date: 1994-09-12 23:05:45
@_author: Hal 
@_subject: RC4 
I thought this posting was very interesting.  RC4, as I understand it,
is a secret-key algorithm from RSADSI which has been kept secret.  I have
no information about RC4 so I can't judge whether this is really it.
A couple of comments, though.  First, there was one obvious typo:
          xorIndex = state[x] + (state[y]) % 256;
should clearly be
          xorIndex = (state[x] + state[y]) % 256;
The second thing I notice is, this is a surprisingly simple algorithm.
I say "surprising" for a couple of reasons.  First, it seems like this
algorithm would not have been difficult to deduce from disassembled
object code.  Of course, maybe that is where it came from.  But it has
been around for a number of years without this being published before.
Also, this algorithm is not too different from some "naive" algorithms
that get posted on sci.crypt from time to time.  It basically makes a
random (key-based) permutation of 0..255, then indexes into that table
a couple of times, adds the results, and uses that as the final index,
xor'ing the result with the plaintext.  It gets complicated by a simple
swap of the two index values, and the choice of the initial indexes is
a matter of stepping; one steps by one and the other steps by the table
value of the first index.
Despite the simplicity, there are no obvious (to me) attacks.  The one
thing that I notice is that with known plaintext you can recover the
table lookup values which are being xor'd.  If you can find two identical
xor values which are pretty close together, chances are the underlying
final index (the sum of the two lookup values) is the same.  But since
it is a sum there are still a wide range of possible values which made
up the sum.  It's just really hard to pin things down.  Without the swap
you could probably do it with enough text, but that swap is constantly
stirring the table at a low level, so by the time you had enough data to
try to get a handle on the table structure, the table has changed.  It's
pretty clever.
This raises the question about why it is secret.  It is (hopefully!) not
because the algorithm is weak when exposed.  Presumably it is a matter
of trade secrecy.  Now that the algorithm is exposed (assuming this is the
real thing) then this is an apparently unpatented secret-key cypher.  Would
it be possible for them to have a "backup" patent application that they
could push through now?  I recall some claims of a similar strategy with
respect to Clipper.
I haven't seen it anywhere but here.  We could probably get a lot more
informed comment on sci.crypt.  Maybe it will show up there eventually.
Yes, it will be interesting to see what comes of it.
Hal Finney

@_date: 1994-09-13 11:07:04
@_author: Hal 
@_subject: alleged-RC4 
Ah, good point.  So my "typo" doesn't really matter (although I think
it is a typo.)
A related point is how the key-dependent state-table permutation is set
up.  The algorithm is, in pseudo-code,
where j is incremented by state[i] plus the next key byte, mod 256.
Notice the similarity to the naive random-permutation generator:
where random (n) returns a random number less than n.  This naive
algorithm is not quite right, as it generates 256 to the 256th power
equally likely arrangements, when there are actually only 256!
arrangements and 256! doesn't even divide 256^256 evenly.  The
similarity I see is that j is chosen in the prepare_key as a slightly
complicated function of the key byte and the current state, and we can
view this as a key-dependent substitute for random (256).  So
it would appear that the prepare_key algorithm, even with a fully
random key, may produce a bias in the permutation table.
A correct algorithm for a random permutation is:
Here we choose the random number from among the ones we have already
done.  This algorithm can be easily proven correct.  Perhaps it would
be better if the prepare_key algorithm did a similar thing, choosing
the entry with which to swap modulo the current "i" value plus one rather
than mod 256.
One implication of the existing implementation is that there may be a
simple relation between at least state[0] and the first character of
the key.  Initially state[0] will be swapped with the value in the
table at the position of the first byte of the key.  Since the table is
initialized to 0..255, this means that state[0] will hold the value of
the first key byte after that swap.  Now, it is probable that state[0]
will be chosen "randomly" to be swapped with a later entry in the
table.  But as we discussed here a few days ago, there is about a 1/e
chance (about 37%) that it will not be swapped after its first
guaranteed swap.  This means that 37% of the time that this algorithm
is used, state[0] holds the first key byte at startup.  OTOH if the
modification I suggested above were made, no such conclusion could be
drawn and I don't see anything simple you could say about the likely
permutation after prepare_key is complete.
Now, having said this, I don't see any way to exploit this knowledge
to attack the cypher.  The "lookup, sum, and lookup" structure of the
cypher has too many degrees of freedom to allow this information about
state[0] to expose a hint of what the key might be, as far as I can see.
But it is an interesting aspect of the key setup, nevertheless.

@_date: 1994-09-13 21:02:52
@_author: Hal 
@_subject: alleged-RC4 
Another thing that is pretty obvious is that this kind of cypher is not
suitable for certain applications.  For example, if you wanted to encrypt
individually a lot of different files on your disk, all using the same
key, this kind of stream cypher would be totally unsuitable.  Any success
in guessing the plaintext which corresponds to a given cyphertext reveals
the XOR stream that the key generates, and that is the same stream that
would be XOR'd to encrypt any other file with the same key.  Doing this would be similar to re-using a "one time" pad for many encryptions.  This
kind of cypher is more appropriate for a communications channel where the
key is never re-used, and the two sides can keep persistent and
synchronized state.

@_date: 1994-09-15 08:26:33
@_author: Hal 
@_subject: RC4 compatibility testing 
I'm not familiar with this term, "submarine" patent application.  But
don't they have one year from the date of first publication to apply for
a patent?  It seems that this could count as first publication, so they
would have one year from now to get their patent application in.  As I
said before, the NSA has indicated similar plans if Clipper is ever
reverse engineered.

@_date: 1994-09-15 08:46:49
@_author: Hal 
@_subject: thoughts on RC4 
I'm not sure exactly how you would generalize it.  Right now it has a 256
entry table which holds a permutation of the values in 0..255.  A byte is
selected from this table and xor'd with the data stream.  To increase to
four bytes per entry and keep it as a permutation we would have to have 4
billion entries taking up 16 GB of memory which seems a bit much.
Altenatively we could still have 256 entries but have them four bytes
each, but then it's not clear that you keep the cryptographic properties
since you no longer have a permutation.
However a good application of Perry's suggestion would be to go to a
two-byte formulation.  You would have 64K entries of two bytes each,
holding a permutation of 0..65535, and then use the same algorithm with
the 256's replaced by 65536 and the chars replaced by shorts.  This would
retain the cryptographic properties and IMO would make many sorts of
attacks harder (at least requiring more data, probably by a factor of
256).  The main down side is that key setup takes 256 times longer, but
it shouldn't take much time to init a 64K entry table with a couple of
indexes and xor's per entry.  So on the whole it seems like a worthwhile
I wonder if the NSA would approve it?  I think it was Bill Sommerfield
who pointed out that it was a little curious that NSA approves RC4 with a
40 bit key when hardware-assisted search like the DES key cracker would
appear to be impractical.  Maybe some other parallel machine would be
suitable, though.  (But another possibility is that they can break the
cypher and the key length restriction is just cover for that.)
Trying to get a 16-bit RC4 approved for export would perhaps not work
for 40 bit keys because key setup takes 256 times longer, but key size
could be decreased to 32 bits to compensate.  OTOH maybe that is not
necessary because probably the whole array does not have to be set up
in order to tell whether a given key will work.  1/3 of the entries in
the table are fixed once they have been swapped once, so if you checked
after doing the first 20 entries, say, about 7 should have their final
values, and we can perhaps reject a key already in a known plaintext
situation just from that.  So actually the large table size may not
help against exhaustive key search.  (The mod I suggested to the key
setup would defend against this possibility, which raises the question
of whether this design aspect was chosen to allow for export approval.)

@_date: 1994-09-15 10:02:15
@_author: Hal 
@_subject: thoughts on RC4 
I realized a few minutes later that I was mistaken to write:
Just knowing several of the first few entries in the table doesn't allow
you to quickly reject keys because the algorithm selects entries from
throughout the table to xor with the data stream.  So this does not
imply that keys can be rejected quickly, nor does it suggest that the
particular setup algorithm used is particularly weak or was chosen
for export approval.  Sorry about the error.

@_date: 1994-09-15 14:21:00
@_author: Hal 
@_subject: The Importance of Filtering 
Script started on Thu Sep 15 14:11:52 1994
jobe% telnet toad.com 25
Trying 140.174.2.1 ...
Connected to toad.com.
Escape character is '^]'.
220 toad.com Sendmail 4.1/Gnu-smail ready at Thu, 15 Sep 94 14:12:08 PDT
250 toad.com Hello  (jobe.shell.portal.com), pleased to meet you
EXPN cypherpunks-outgoing
[hundreds of names elided]
250 221 toad.com closing connection
Connection closed by foreign host.
jobe% exit
jobe% script done on Thu Sep 15 14:13:16 1994
This suggests that there are three possible files which are already
archiving the list.  How frequently they are deleted is another matter.
The list volume is so high that the disk space to hold much of an
archive becomes a bit expensive.  Still, if one of thse could be made
accessible to anon ftp it might be worthwhile (if toad allows anon ftp).

@_date: 1994-09-16 20:49:46
@_author: Hal 
@_subject: RSADSI vs Remailers? 
Note the original post header.  It came via the jpunix remailer.
I wonder if there is any connection to this:

@_date: 1994-09-17 18:25:20
@_author: Hal 
@_subject: Stealth remailers 
One "quick and dirty" way to get the effect of a stealth remailer is to
have all messages leave the remailer net via one or more politically
strong hosts.  For a long time now I have been having my remailer on
alumni.caltech.edu, which I judge to be politically weak, forward mail to
shell.portal.com, which seems stronger.  When people see some anonymous
mail they don't like, they look at where it comes from.  They seldom
think to blame other remailers in the chain (partially because they can't
easily find out who they are).  It is the final remailer which takes the
heat.  If that remailer were in a jurisdiction and/or political position
that would allow it to withstand the various threats we anticipate, it
would provide cover for the other remailers.  And by using other
remailers in a chain before going through this final remailer, users
don't have to trust the final remailer with any significant secrets.
Some time back I proposed a variation of this idea: "second tier"
remailers, which always forward their outgoing messages through one or
more "first tier" remailers, which work like the current ones and take
the political heat as a result.  Second tier remailers would be very safe
to run and it would be rare that a sysop or supervisor would get a
complaint about the remailer's activity.

@_date: 1994-09-20 08:31:41
@_author: Hal 
@_subject: On the crime bill and remailers 
SOLONg discusses the "scienter" requirement in various laws.  I believe
this refers to the legal requirement that you know you are breaking the
law in order to be breaking the law (so to speak).  The export restrictions
we discuss so much here also have this requirement.  If you drive across the
border with your pickup truck full of ammunition, the government has to
prove that you knew it was illegal to do so in order to convict you.
Presumably this implies that if you mail RIPEM to your buddy in England
you would only be breaking the law if you knew about the legal restrictions.
It would be interesting to see how the government goes about proving this
knowledge if they ever bring an ITAR case.
Does this also suggest that our discussions about the legalities of crypto
export are harmful because they could take away a possible defense of
ignorance on the part of some list reader who is the victim of an ITAR
prosecution?  Perhaps this is really a case where "ignorance is bliss."

@_date: 1994-09-20 08:45:20
@_author: Hal 
@_subject: On the crime bill and remailers 
I strongly disagree with this.  Anonymous remailers as presently constructed
will be almost completely ineffective against any significant government
attempts to surveil email traffic.  The government does have the resources
today to defeat most uses of remailers.  Since present-day remailers lack
padding features, the correspondence between incoming and outgoing messages,
even with encryption, is relatively easy to establish.  This is made worse
by the lack of general support for reordering, which renders the task
almost trivial.
Instead, anonymous remailers are clearly targetted against non-government
traffic analysis, generally local associates, system operators, employers,
supervisors, and so on.  They allow people to communicate without
repercussions and retribution at work or at school.  They let people exchange
email in an insecure environment while hiding both the message address and
its contents.  They allow whistle blowers to expose malfeasance without
being punished.  These are the kinds of things the remailers are good for.
Claims here that remailers are designed to support sedition or to
prevent government surveillance are both wrong and harmful.  This kind
of material could show up at some future prosecution of a remailer
operator.  It is important that we understand clearly what the capabilities
and limitations of current remailers are.

@_date: 1994-09-20 17:04:46
@_author: Hal 
@_subject: On the crime bill and remailers 
I don't know how true this is in general, but my research into the
arms export question indicated otherwise.  Here is part of a posting I
sent to CP some time last year concerning a case in which the defendant
did in fact drive to Mexico with a truck load of ammunition:
Perhaps the arms export laws are worded differently than some others
and so the more stringent rules apply.

@_date: 1994-09-21 20:41:38
@_author: Hal 
@_subject: My response to NRC crypto study 
This is a slightly edited version of what I sent:
Thank you for giving members of the public such as myself the
opportunity to discuss our concerns as the NRC studies the National
Cryptography Policy.
I will make my points using the outline of issues dated September 14,
1994 as a reference.
One traditional method for limiting access by hostile foreign powers to
strategically important technology has been the defense-oriented
classification system.  Important discoveries made by government
researchers have been classified at various levels in order to prevent
their dissemination.  This general approach of secrecy has been applied
as well to the SkipJack algorithm used in the Clipper chip.
However, this approach has not been completely effective with
cryptographic discoveries that are made by private researchers not under
the control of the government.  Probably the most notable event along
these lines was the discovery of public-key encryption technology in the
1970's.  The concept of PK encryption, easy to explain and understand even
for a technologically knowledgeable layman, spread like wildfire despite
some early abortive efforts to suppress it.  This discovery has served as
the foundation for a wide range of research in cryptography and no doubt
is an important reason for the rapid growth of the field over the last twenty
Today, the electronic networks which circle the globe make communication
of new results far easier and more rapid than in the past.  And the
transparency of national borders on the computer networks means that
information, once made available, is available globally.  A discovery
made today comparable to PK encryption in the 1970's would have been far
less likely to be suppressed, and in the future we can expect this tendency
to increase.
Despite this, the US government is currently wielding clumsy policies
which classify all encryption software as munitions and require
complicated licensing procedures for their export.  There is a terrible
mismatch between these policies and the mechanics of information flow
today.  For one thing, the distinction between distribution within the
country and information which flows out of the country is nearly
impossible to make today.  It was always quite unrealistic to suppose
that technology which was widely deployed within the US was unavailable
across our borders, but the information networks make it clear that this
is a fantasy.  As the networks increase in speed, power, and ease of use,
the ties between countries will only grow.  The net will need to be seen
as a global phenomenon, and information on the net will no longer be
localized; made available to one, it is made available to all.
In this environment, the only way to stop information from making its
ways into foreign hands is by keeping it off the net entirely.  And that
implies restricting what kinds of technologies American citizens can
publicly discuss and what kinds of information they can exchange.  If we
want to keep cryptographic secrets, we must prevent people from knowing
or at least talking about those secrets.  This would require Draconian
policies more suitable to a totalitarian state than the world's greatest
democracy.  In short, keeping cryptographic technology secret is
incompatible with American principles.
Another problem with the present US policies restricting exports of
cryptographic technologies is their lack of responsiveness to changing
conditions.  Despite the fact that such basic algorithms as the RSA
public-key encryption system or the DES secret-key system are nearly
twenty years old, the government still restricts their export.  This is
ridiculous.  Those algorithms are in use all over the world!  From whom
are we trying to keep them secret?  This is really an illustration of the
well-known inertia and inflexibility of bureaucracies.
The only effect of these bans is to impair the competitiveness of US
business.  Manufacturers of cryptographic technology are not allowed to
export, and users of cryptography are not allowed to use modern
technology if the products might go overseas.  It would be as if the US
were still determined to keep the design of internal combustion engines
secret and so US car manufacturers were forced to use steam because the
cars might be sent across the border.
In the future, as new algorithms are discovered, the same problem will
present itself.  The rapidity and ease of communications ensures that if
the technology is publicly known, it is globally known.  Allowing US
manufacturers to use a technology but not to export it is pointless; if
they know how to use the technology, chances are the rest of the world
does as well.  Restricting exports can only benefit competitors in other
countries at the expense of US businesses.  It is pointless and
Cryptographic technology has some characteristics which are at odds with
the interests of law enforcement and security agencies.  In a sense,
cryptography is a "purely defensive" technology.  It does not threaten
anyone, it does not invade anyone's privacy, it does not cause damage or
harm.  On the contrary, it protects the user from various kinds of
threats and invasions of his own privacy.  In a way, it levels the
playing field, providing the weak with some of the same protections of
privacy and secrecy which have been traditionally available only to the
The problem is that law enforcement and security interests have gotten
used to being strong.  It may not have been easy to learn the internal
secrets of a powerful opponent, but eavesdropping on a poor country or
individual was easy.  Indeed, most people have intuitively understood
that they would be nearly powerless if threatened in any significant way
by law enforcement or national security forces.
Now, this may change somewhat.  It remains to be seen to what extent
these changes will occur, and what their full effects will be.  It does
appear that if free access continues to be granted to cryptographic
technology that people will be more immune to certain types of
surveillance.  This does not necessarily mean that the world will
descend into a nightmare of terrorism and war.  It does mean that the
agencies whose job it is to keep order will have to adapt, to learn new
technologies and new approaches.
Naturally, they will resist.  Change is never comfortable, and it is
all too easy to conjure boogeymen out of the unknown.  But before
allowing ourselves to be panicked by the thought of untappable phones
and unreadable mail, we need to consider the alternatives.  Because of
the tremendous ease with which information will flow, only extremely
severe and harsh measures can keep cryptographic technologies out of
the hands of those who want it badly enough.  This has been recognized
from the beginning by the government, as was seen in its flawed Clipper
chip proposal.  The fundamental inconsistency with Clipper was that a
voluntary standard would not be used by criminals, and the restrictions
which would be needed to force criminals to use it would be completely
at odds with American freedoms.  The government's attempt to have it both
ways only sowed fear and mistrust.
It may sound harsh, but it is true: the only way in which cryptography
which can be defeated by law enforcement will come into use is if people
are forced to use it.  And the problem is that people already have
technologies which are too strong for law enforcement to break.  It's too
late to put the genii back into the bottle.  The only choices at this
point are between Big-Brother-style restrictions on use of certain simple
algorithms, or a world in which privacy, unbreakable privacy, is a fact
of life.  Consider carefully whether the latter would be so horrible
before you accept choices which are at odds with our national traditions
of individual freedom.
In my opinion, the current suite of cryptographic technologies is well
suited for commercial purposes.  The RSA public-key system has withstood
nearly twenty years of attacks and new algorithms for factoring numbers
(factoring is the problem on which the algorithm is based).  At worst it
may be desirable to raise key sizes from the 512 to 1024 bit level which
are widely used today to perhaps 1024 to 2048 bits, a level which should
provide effectively impenetrable security.  As computers get faster the
larger key sizes can be handled efficiently, while the time to break the
algorithm increases at a much faster rate for larger keys.  The result is
that the passage of time and the increase in computer speeds only helps
the user of RSA rather than the attacker.
RSA is typically used in conjunction with a secret-key cypher for
efficiency, and here DES has been the choice for a number of years.  DES
is now showing its age; its 56-bit key size is beginning to be too small
to give confidence against an attacker.  However, two alternatives are
readily available: triple-DES and IDEA.  Triple-DES has a key length of
112 or 168 bits, depending on the configuration, and IDEA has a key
length of 128 bits.  Both of these are large enough that no conceivable
attack can be launched based on key size alone.  Triple-DES itself has
been cryptanalyzed almost as long as DES, and while IDEA is newer its
security should be much clearer within the next two or three years.  In
addition, there are a number of other conventional cyphers being
developed all the time.  Chances are that one or more of these will be
acceptable as well.  By the turn of the century there should be at least
three or four strong and widely accepted conventional cyphers.
In sum, there is no real commercial need for government involvement in
the development of new cryptographic technologies.  While new
approaches are always welcome, the range of technologies which already
exists is adequate for commercial encryption needs well into the next
century.  Here the best policy for the government is to simply
facilitate the use of these well established systems.
Cryptography is going to be a key technology over the next ten to twenty
years.  There is far more to this technology than simply maintaining
privacy, although certainly in the early years this may be the principle
market area.  But, more generally, cryptography is a technology of
information management.  It allows precise control over how
information is revealed, packaged, and disseminated.  Once recent
discoveries by cryptography researchers are commercialized and made
available to the public there will be whole new areas of business and
commercial interest that are barely imagined today.
Starting with the nearer term, cryptography will be used initially
primarily for privacy and authentication.  As commerce moves onto the
nets, so too will the need for confidentiality.  The insecure nature of
many existing networks will be addressed by layering cryptographic
protocols on top of the existing foundation.  And new networks may be
developed with cryptographic security built in from the beginning.
An important point will be to make the security trustable and transparent.
Trustable means that the end user does not have to trust some third party
not to betray his secrets.  In an increasingly competitive world where
government and corporate espionage are beginning to merge, a system which
tells its users to "trust me" is not going to be competitive with one
which allows users to determine for themselves that their communications
are secure.  This suggests that end-to-end encryption, where the message
is in the clear nowhere on the network, will be the preferred mode.  And
at the same time, the encryption will be transparent, built into the
software used for access to the network, with user-friendly controls and
indicators for the encryption status (and hence reliability) of each
piece of information displayed.  We see the prototypes for these concepts
already with the security extensions to the World Wide Web and its
associated software program, Mosaic.  Similar concepts are being designed
into personal computers as well.
Looking out a bit farther, the next big market for cryptography
technology will be electronic payment systems.  The potential speed and
flexibility of electronic commerce requires an equally fast and flexible
means of electronic payment.  There are many cryptographic technologies
which are suitable, including the electronic equivalent of bank drafts,
checks, cashier's checks, and, perhaps most controversial, digital cash.
It is worth discussing digital cash in a little more detail.  It may well
be that this technology will produce the next Clipper controversy.  The
situation is that digital cash provides for a means of payment which is the
electronic equivalent of cash.  It is private and anonymous.  In an era
when databases of consumer preferences and buying habits may be one of
the major threats to privacy, digital cash will provide protection by
allowing transactions to occur anonymously.  If there is no record of who
participated in the transaction, there is no privacy threat from
databases of such records.
In a sense, this is nothing new, no more threatening than paying a
dollar for bread at the corner grocery store.  But law enforcement
efforts which rely on tracking the flow of funds may be hindered by the
widespread use of digital cash.  This could have implications for money
laundering, income and sales tax collection, and other types of financial
regulations.  As with the prospect of encrypted communications, the
response by law enforcement is likely to be an attempt to block this
technology from coming into widespread use.  And once again the choice
will be between restrictions on what kinds of algorithms people can run
on their computers, and allowing people some privacy in their financial
Other cryptographic technologies which are waiting in the wings include
"zero knowledge" proof systems, which allow new forms of
authentication, and which make it possible to prove possession of
certain information without revealing the information itself; secret
sharing systems which allow for true "escrow" of information (unlike
the misnamed government "key escrow" which keeps secrets contrary to
the interests of the user, rather than on his behalf) with very flexible
controls on who can access the information; pseudonym-based credentialing
systems which will allow people to prevent linkage of information about
them in different databases while allowing them to control which
information will be revealed; secret-exchange systems which make it
possible for two people to simultaneously exchange secret information
in such a way that neither can cheat; many forms of digital signatures,
some of which are verifiable only with the cooperation of the signer, but
in such a way that he can't cheat; and a variety of others.  These
technologies will permit wholly new and unforeseeable approaches to
managing and controlling information, and will undoubtedly serve as the
basis for new companies and even new industries.
But these possibilities can only come about if people are allowed to use
them.  Any approach which requires law enforcement review of every new
encryption technology is going to hamstring American companies which want
to innovate and compete in the world.  The tremendous growth and success
of the US software business comes from the free-wheeling competition and
innovation which have characterized it.  Inserting law enforcement
restrictions into the picture can only harm American competitiveness, as
we see already in the cryptographic privacy area.  As we move into the
next century, information itself is going to be a key commodity, and the
monkey wrench thrown into the industrial machine by law enforcement
restrictions on cryptographic and information technologies is going to
have widespread impact.  This is not something we can afford in an
increasingly competitive world.
Narrowly speaking, the interests of the United States are best served
if our foreign competitors are faced with as many disadvantages as
possible.  On this view, foreign restrictions on cryptographic
technology should be welcomed, as they will only harm foreign
companies and make it harder for them to compete with the US.  In the
broader sense, though, the world market is all interconnected.
Inefficiencies and restrictions in one part inevitably harm the smooth
operations of other parts.  It is no longer easy or even possible in
many cases to distinguish activities which are foreign from those
which are domestic.  Regulations which apply to a company's activities
in one country inevitably influence its activities in others.  In this
sense, foreign restrictions on cryptographic technologies will end up
being harmful to US companies and individuals.
In the long run, then, it will be best for the US to work to reduce
foreign restrictions on the use of cryptography.  The prospects of
success are excellent since those countries will be feeling their own
domestic pressures from companies which are being harmed by those
restrictions.  And in an international world a country which stubbornly
maintains obsolete and inefficient restrictions on internal business
activities may simply find itself bypassed, as commerce flows to more
hospitable jurisdictions.
The great danger, and the one to be most carefully avoided, is the
establishment of an international cabal of law enforcement agencies, all
calling for uniform restrictions on encryption applied (as they would
have to be) in all countries on the globe.  This would represent a
pre-emptive strike against individual privacy, the formation of a
de-facto cartel in which governments around the world band together
contrary to the interests of their citizens.  It need hardly be pointed
out how opposed this is to our American principles and traditions.
Furthermore, such an approach is inherently fragile and unstable, as every
country has incentives to advance its own interests by releasing the
shackles which bind its industry.
US cryptography policy has clearly gotten off on the wrong foot.  With
the disastrous Clipper chip proposal, the government has simultaneously
alarmed privacy advocates and demoralized law enforcement.  Today, the
policy is in a shambles, with indications that the government is
withdrawing support for Clipper and searching for other alternatives.
The fact is that current cryptographic technology is perfectly adequate
for privacy protection.  There is no need for government efforts to
introduce new cryptographic systems.  To the extent that Clipper was
presented as a new, improved cryptographic algorithm, it is simply
unnecessary.  Of course, the stated purpose of Clipper was not to improve
privacy, but quite the reverse.  Again, as far as meeting the goals of
privacy protection, the government need only step aside.
Similar considerations hold for economic competitiveness.  Here the
export restrictions on public-domain cryptographic technology are a
ludicrous holdover from the past and serve only to hobble American
companies.  The single best step the government could take today would be
to remove RSA, DES, IDEA, and other international cryptographic standard
algorithms from the list of export controlled technology.
As for the national interest in public safety and security, cryptography
is simply not the threat that it is often painted by law enforcement and
security interests.  With only a few hundred authorized wiretaps a year
on a population of over 200 million people, it is clear that the impact
of secure communications will be only marginal.  Traditional methods of
law enforcement including physical surveillance, infiltration,
informants, and similar approaches have been the foundation of crime
prevention in the past and undoubtedly will be in the future.
Furthermore, attempts to put the cat back in the bag are doomed to
failure.  There are already widespread programs for cryptographic
privacy, and new ones are being written (often by amateurs, so
widespread and simple is the technology) all the time.  The kinds of
regulations which would be required to prevent people from
communicating privately would have to be severe and onerous.  It was
the recognition of this fact which forced the government to back down
from early hints that Clipper might not be a voluntary program.
Citizens of the United States simply will not tolerate the kinds of
government controls that would be necessary in order to return to the
days of free wiretapping.
So-called "key escrow", as pointed out by cryptographer Carl Ellison,
is misnamed.  What these systems really provide is Government Access
to Keys, or GAK.  That is the real purpose of these key escrow
systems.  All the discussion about escrow and restrictions on access is
window dressing to obscure the fundamental issue and to make it seem
more palatable.
A true escrow system would be one which held certain information on
behalf of the client.  An escrow agency has well-defined obligations to
the client and to other interested parties.  For example, in a sale of
real property, an escrow agent may hold the cash for the buyer and
pass it to the seller when title has transferred.  There are actually
many legitimate purposes for escrow in the context of information.  One
example would be the purchase of some data package over a computer
network (say, a music video in electronic form).  An escrow agency could
assist with the mutual exchange of payment (perhaps in the form of
digital cash) and the information package in such a way that both parties
are protected against cheating.
In this sense, a true "key escrow" agency might be one with which a
user could deposit his secret key with assurance that it would be held
safely for him.  Then if something happened in the future which caused
him to lose his key, the escrow agency could follow through with its
contractual obligation and return the key to the user.  Or, again with
appropriate authorization, in the event of the user's death or other
circumstances, the agency could reveal the key to the heir or agent of
the original user.  The key point here is that the escrow agency is
providing a service to the user; the user's interaction with the
agency is voluntary.
This kind of key escrow, if offered by the government, would not be
particularly objectionable (although there is no particular reason why this
escrow should be a government, as opposed to private, function).  Just as
the government indirectly backs the banks and provides security to the
depositors, so a government key escrow agency could provide secure
storage of keys (and perhaps other information).
If only this is what the government meant by key escrow!  Actually, of
course, the real purpose of key escrow is to allow the government to
defeat encryption if necessary.  Most of the variations on the existing
schemes involve what mechanisms are used to ensure that the keys are only
revealed under specified conditions.
The Clipper chip proposal has been widely discussed elsewhere.  The
difficulty of ensuring that copies of the keys are not made during the
programming process has been pointed out, as well as the problem that
knowing the family key (or having access to a family key based decryption
unit) allows traffic analysis without needing access to the escrowed
database.  The possibility of rogue units interoperating with Clipper
chips as discovered by Matt Blaze provides a further technical flaw in
this proposal.
A more recent proposal is also worth discussing.  So-called "software
key escrow" (SKE) provides similar functionality to the Clipper chip,
but in software.  A "law enforcement access field" (LEAF) is included in
each message by compliant software as with Clipper.  The main new feature
is that the software on the receiving end can check that the LEAF is
valid without knowing the family key.  This prevents rogue software
from interoperating with compliant software.
Although interesting, this proposal is unlikely to achieve its goals
without the kinds of harsh restrictions discussed above.  The design
goal of making it impossible for rogue software to communicate with
compliant software is really not relevant as that does not solve law
enforcement's problems.  It would be an easy matter to create a rogue
program which communicated compliantly with compliant software and
non-compliantly with rogue software.  This allows the hypothetical
criminal to communicate with his cohorts privately while communicating
freely with everyone else.  Again, the only way this system or any
similar key escrow system can succeed is if people are forbidden to use
anything else.
To the extent that this debate is expressed as a conflict between
government and citizens, it is already clear what has gone wrong.  There
should not be a conflict between government and its citizenry, not in a
democracy.  The citizens rule the government in the American system, not
the other way around.
What has happened here is that certain agencies within the government
seem to have forgotten this fundamental fact.  They see the people of the
United States as, if not their enemies, then at least their potential
enemies.  Law enforcement and national security agencies have become so
accustomed to wielding immense power that they cannot tolerate the
thought of giving up some of it.  Thus we have their desperate attempt to
turn back the clock, to freeze technology at a 1970's level, to prevent
people from using the cryptographic tools which are becoming more
widespread every day.
There is no need to balance the interests of the US government and
private citizens.  The only interests which are relevant are those of the
citizens.  What needs to be balanced are those citizens' interests in
public safety and their desire for privacy and freedom.
This conflict is nothing new.  It has always been true that there is a
tradeoff between security and freedom.  Different countries all around
the world have chosen to balance this tradeoff at different points.  At
one extreme we have totalitarian states where security is everything and
individual freedom is nearly gone.  The example of Singapore is widely
used today as a place where the citizens have, largely voluntarily, given
up a great deal of individual privacy and freedom in exchange for a
tightly regulated, but peaceful, society.
We in the US have traditionally chosen a different, and historically
superior, approach.  Our national traditions emphasize the importance
of the individual.  All through American history the lessons we have
learned have taught us to respect individual freedoms at the expense of
government regulations and controls.  This has been one of the
fundamental principles which has led to our tremendous success.
In the context of the encryption debate, then, the default position
should and must be one of individual freedom.  We already allow
individuals to use any encryption technology they desire.  Any proposal
to move from this principle, a principle which is firmly in accord with
American traditions, should be viewed with the utmost caution.
And, as the above discussion has emphasized, there is really no legitimate
policy position which moves us only slightly in the direction of greater
control.  The choice is not between privacy and a little bit of
regulation.  It is between privacy and very invasive, very intrusive
restrictions.  The nature of cryptographic technology is such that it is
so easy to use that only an intensive effort can prevent its use, or
force the use of a government-approved alternative.  The policy decision
is really between one which maintains American traditions of freedom and
one which takes a drastic step towards government control.
In the future, this situation will only become worse from the point of
view of those opposed to communications privacy.  As more countries
become computerized, as the global networks spread further, as more
people learn how easy it is to ensure their own privacy, it will be all
the harder to keep people's communications under government-approved
systems.  Technology sounds the death knell for traditional ways of
approaching the law enforcement and national security business.  The
longer governments are allowed to ignore that fact the more likely it will
be that the totalitarian solution will be imposed.
The traditional way to balance the competing interests would be to put
national security and law enforcement people, business people, and a
few "privacy advocates" on a committee, then let them make
recommendations to the Executive or Legislative branches of
government.  Although this may be appropriate for the initial
evaluation of the situation, it has serious problems.  It puts far too
much weight on the specific interests of security and law enforcement.
Although these are legitimate duties of government, they are not its
only duties, and they certainly do not override the traditional
American emphasis on individual liberty.
In the next century, the primary economic fact will be international
competition.  In a global world, there is no longer any place for
pointless government regulations which will interfere with the success
of domestic business or cause commerce and capital to flee to other
countries.  Attempting to mollify outdated law enforcement concerns by
restricting the use of encryption technologies will only hurt American
The fact is that, given these economic realities, the only policy
decision which makes sense is one which encourages, rather than
restricts, the use of encryption.  Government should relax export
controls, retire its key escrow proposals, reveal the SkipJack
algorithm used in Clipper, and turn its researchers to the task of
helping American competitiveness rather than thinking up new ways of
hindering US businesses.
The only "process" that is needed is the political courage to overcome
the objections of law enforcement and force them to concentrate on the
job at hand, stopping criminals, rather than working on new ways to
block encryption technology.  It doesn't have to be done right away.
It will take years for encryption to work its way into the economy.  We
probably won't see widespread encryption of telephone and other
electronic communications for five or even ten years.  This time must
be used productively by law enforcement to design new strategies to
meet the challenges ahead.  If the government wastes time on an
ultimately doomed campaign to try to freeze technology and restrict
encryption then we will all ultimately be the losers.
Thank you again for your attention.
Hal Finney
email: hfinney at shell.portal.com

@_date: 1994-09-23 16:06:09
@_author: Hal 
@_subject: Fast Modular Factorial? 
I find that for the numbers I have tried, that (p-1)! mod p = (p-1) if
p is prime, else it equals 0, with one exception (p=4).  So if this
is true (probably a standard result; it sounds familiar) then it might
actually be easier to find the factorial of a larger number mod a
prime than a smaller one.

@_date: 1994-09-28 09:00:32
@_author: Hal 
@_subject: Sufferance remailers 
Can't they shut down the closet just as easily as they would have
shut down your computer?
This seems to be a problem with all approaches which seek to hide
the "real remailer" A behind a "front machine" B.  They could just
shut down B.  So sometimes people propose that they will just switch
to a different front machine C, and R is still safe.  Then they shut
down C.  So we switch to D, etc.  But really, couldn't B, C, D, ...
just have been remailers themselves?  What do you really gain by
keeping A secret?  Perhaps if the front machines are much cheaper than
remailer machines it might make sense, but it really doesn't take
much horsepower to run a remailer; probably the net connection is the
expensive part, so B, C, D, etc. are going to be just as expensive as

@_date: 1994-09-28 14:18:10
@_author: Hal 
@_subject: Digicash Palo Alto 
Just browsing  I see a relatively new web page with some
info on various employees.  They also mentioned that there is a U.S. office,
        DigiCash Inc
        701 Welch Road, Suite 323
        Palo Alto, CA 94304
        USA
        tel +1-415 321 0300
        fax +1-415 321 0322
Bay area CP's might want to check this out (unless it is already common
(I notice Chaum has his own picture and initials on the DigiCash coins
in the graphics!)

@_date: 1995-08-03 09:26:31
@_author: Hal 
@_subject: Object Oriented Crypto API 
I enjoyed Ray's message about the crypto library interface.  I haven't
had time to study it closely, but I have a couple of quick comments:
I thought Wei's library looked pretty easy to use already.  Maybe Ray
could show an example of what would be needed with Wei's library to do
some "typical" crypto function, say encrypting a message with someone
else's RSA key.  Then we could compare it with how the same function
would look with Ray's proposed interface.
The other point is that there needs to be the ability to encrypt only
a bit of a message at a time.  Particularly with public key the first
message may be special in that it generates a session key which is used
for the remainder.  So an interface for piecewise encryption and
decryption is necessary.
I hope we will see more discussion about the library.

@_date: 1995-08-04 10:02:55
@_author: Hal 
@_subject: Java and Safe-TCL security 
The safe-tcl mailing list has not been active for a few months.  I think
a lot of interest has transferred to Java.  One problem is that safe-tcl
was oriented around email, so it lacks facilities for accessing web
I agree with Ray that the security of safe-tcl leaves something to be
desired.  I implemented a safe-tcl mail filter which would automatically
run incoming mail scripts which were in safe-tcl format.  This would be a
generalization of a remailer, so that users could write scripts which
would determine when the remailing would occur, etc.  However I ran into
a number of problems, particularly related to persistent storage (e.g.
disk file access).  This is a hard problem for a "safe" system to solve.
One solution is to just forbid it, but beyond that you need to have rules
about how much disk space a script can use, whether they can access each
other's space, etc.  There are some nice applications if they can do so,
for example the telescript model where two software agents come together
and exchange some information.
Another tricky issue is if you are going to let the script talk to the
outside world via email or tcp connections.  How do you prevent abuse of
this feature (sending junk email, or connecting to a web page and
entering bogus data into a form)?  But again, without this capability the
script is pretty much limited to drawing pretty pictures on your screen,
which isn't very useful.
Here is one message I sent to the safe-tcl list earlier this year
describing some of these problems in a little more detail.  Note that
there were also several bugs in the implementation which left security
holes, things being checked in the wrong context and such.  This is
similar to what Ray was citing.

@_date: 1995-08-04 16:37:13
@_author: Hal 
@_subject: Java and Safe-TCL security 
This sounds like an interesting approach.  I hear that Telescript uses a
remote procedure call concept for inter-script communication.  So one
script gets to call the public methods of another script.  I don't know
how it finds out what other scripts are arround for it to talk to,
though, or decides whether they have anything of interest.
The tuple space idea sounds good and is not too dissimmilar from the
get/setconfigdata in safe-tcl.  There are some problems about security
though.  Who gets to delete tuples?  How do you prevent a malicious
script from messing up the data?  Maybe it depends on the application,
what you want to use this data for.
BTW what kinds of facilities are there in Java for scripts to have access
to disk files?  I know there was some discussion of using scripts for
cryptography.  Presumably the user would want to give "read only" access
to the (public) keys he used.
And how about other forms of I/O, email and the like?  Can Java scripts
do this?  What are the restrictions to prevent abuse?  Safe-tcl has a
concept where a script can send mail, but the implementation pops up a
window and asks the user first if it is OK to send.  (Unfortunately that
doesn't work for a telescript like application where there is no user
around to vet the messages.)
Yes, there was some discussion about this on the safe-tcl list.  There is
also an agents list I was on for a while but they couldn't even agree
about what an agent was so not much progress happened there!  There have
been various proposals for standard ways agent scripts could specify what
capabilities they need to run, etc.  Doing web searches on "agents" will
track a lot of these down.  However most seem concerned with traditional
issues like compute cycles, memory usage, etc., and not with the more
difficult and important issues of knowing whether there is another agent
there (or a local database) which has the specific information my agent
is after.

@_date: 1995-08-09 08:36:35
@_author: Hal 
@_subject: Prime Number Gen's. 
There are algorithms for producing provable primes which don't take
too long.  However they do not work to prove a given probable prime
is actually prime, rather they generate a prime.  One was described
by Mihailescu Preda, , on sci.crypt on
December 13, 1993.  It is not clear whether this kind of algorithm is
suitable for RSA (where the primes must be kept secret) since it could
reduce the space of primes which are produced.

@_date: 1995-08-09 16:00:53
@_author: Hal 
@_subject: "S1" encryption system (was: this looked like it might be interesting) 
I suppose the unstated implication is that this might be Skipjack.
I have looked at the program a bit and have a few observations:
There is an obvious typo in the "g" function, whose first parameter
should be 0 or 1, but which tests it for 0, 1, or 2.  This suggests an
amateur effort.  The coding style in general suggests a lack of familiarity
with C (absence of "for" loops, with equivalent "while" loops substituted).
The program appears to be based on a hardware-based description of the
algorithm, judging from comments and style.
The algorithm uses two fixed arrays F and G.  Comments indicate that F
was designed as four independent arrays F0, F1, F2, and F3.  These are
suposed to be non-linear.  Each takes 8 bits in and 8 bits out.  G is
two arrays, each 8 bits in and 1 bit out.  The comments indicate that
it is supposed to be "pseudo-linear".  G1 is the odd parity function.
G0[i] is 0 0 1 1 0 1 1 0 0 1 repeated over and over.  This is unusual
because it is period 10 (the second 5 bits are the inverse of the first
5).  I don't know whether there would be a more concise algorithmic
representation of G0.
Key size is 80 bits.  The program implements the ability to hold 5 keys
at once.  Block size is 64 bits.  The keys are expanded internally into a
large array.  I haven't looked at the key scheduling in detail.
The encrypt and decrypt block functions have fixed xor's applied to the
64 bits of input and output.  This appears to be cryptographically
useless (or at least not very useful), similar to the initial
permutation in DES.  It is curious that xor's are used here rather than
a permutation.  That may represent an attempt to design the cipher to
run well in software.
The encryption function itself is a modified Feistel type cipher, with
the blocks broken into 8 pieces and xor'd with functions involving F,
G, the key and other pieces in a reversable pattern.  The loop iterates
32 times but only two of the 8 pieces are changed each iteration so
each 8 bit piece actually gets modified only 8 times.  The pattern is:
repeated 8 times.  Decryption goes in the inverse order as is typical of
these ciphers.
The key is basically 80 bits, however there is a function S1_create_key
which pads it with 16 bits of 0 and then encrypts it with two overlapping
encryptions using the all-zeros key.  The resulting 96 bit key is then
fed as input to S1_load_key which decrypts it and checks for the 0's to
ensure validity.
I am not much of a cryptanalyst, but from what I understand the overall
security of a Feistel-type cipher like this depends a great deal on the
structure of the F (and in this case G) boxes.  I would not be at all
qualified to analyze those.  So potentially this may be a strong cipher
or it may be weak.  The actual implementation does as I remarked show
some signs of amateur programming skills.  In addition to the points
mentioned it is curious that the G arrays are initialized with a list of
256 values rather than taking advantage of the apparent regularities
Hal Finney
hfinney at shell.portal.com

@_date: 1995-08-09 16:11:36
@_author: Hal 
@_subject: "S1" encryption system 
Correction, I just noticed that the four F functions have 4 bit output
not 8 as I wrote.  Realize that all this is based on a very cursory
examination of the code.
BTW I just was starting to look at the key scheduling and I noticed that
fullkey is indexed in its 2nd slot by i*2 where i goes from 0 to 31, but
is only declared as being 32 in size in that slot.  So I think this is
another typo, probably the index should be i.  This kind of thing does
not inspire confidence...

@_date: 1995-08-09 21:05:00
@_author: Hal 
@_subject: "S1" encryption system 
Sorry, yet another correction: the G1 box, G[1][i], is parity(i&0x17),
not parity(i) as I said, where parity is 0 or 1 depending on whether its
argument has an even or odd number of 1 bits.  I have checked via a
small program that this is correct and that the earlier formula I
posted for G0 is correct.

@_date: 1995-08-09 21:22:48
@_author: Hal 
@_subject: "S1" encryption system (was: this looked like it might be interesting) 
A couple of people have indicated that they did not see the original
posting.  I changed the subject heading in my followup.  The original
message was posted under the subject title, "this looked like it might
be interesting".  At least one person had commented on the similarity
to Skipjack which is what prompted me to look at it a little more

@_date: 1995-08-11 01:55:14
@_author: Hal 
@_subject: More "S-1" foolishness 
The other thing I noticed that really makes me question this is that G1
only uses 4 of its 8 input bits.  As I wrote, it is equivalent to
parity(i&0x17).  A bit is a terrible thing to waste, and it is hard to
imagine why it would do this intentionally.  G1 may not be that important
an element of the cipher but why throw away four bits?
It is possible I suppose that the F and G boxes are not the ones used
in the "real" version of whatever cipher this is, so this apparent
weakness and the ones which Matt has pointed out may not be that

@_date: 1995-08-12 02:35:47
@_author: Hal 
@_subject: "S1" encryption system 
There have been a couple of good messages on sci.crypt, one by Colin
Plumb and one by Thomas Jakobsen.  The latter mentioned something similar
re key scheduling.  I hadn't noticed it.  Chalk up another apparent

@_date: 1995-08-16 10:46:13
@_author: Hal 
@_subject: SSL challenge -- broken ! 
Although it is hardly necessary, I can confirm the accuracy of the
decryption found, and I extend my congratulations for this achievement!
Ironically, I understand that an independent effort coordinated by Adam
Back also discovered the key at approximately the same time.  In
addition, Eric Young had done a search starting at 8000000000 and
upwards; unfortunately the key value of 7ef0961fa6 was only about one
percent below his starting point.  Hopefully Adam will supply more
It will be interesting to see what the fallout is from this
accomplishment.  It should provide ammunition for the current effort by
Microsoft and other companies to try to persuade the government to allow
the export of full 56 bit DES.
Knowing the tendency of the media and the net to oversimplify, this will
probably come out as "SSL is broken" just as the RSA-129 result led to
"RSA is broken" stories.  This would not be as egregious an
oversimplification as in the RSA case, but in fairness it should be
recognized that SSL as a spec provides support for much stronger ciphers
than the intentionally weakened RC4-40 which was broken here, but
Netscape was constrained by the government to supply browsers with only
the weak encryption.
I am a little alarmed by the suggestion that this news could have some
marked impact on the Netscape stock price.  From our perspective this was
certainly an unsurprising result (not to take anything away from Damien
and others who worked on it).  It is a useful reminder that the things we
work on here can have profound consequences.
Hal Finney
hfinney at shell.portal.com

@_date: 1995-08-17 12:24:49
@_author: Hal 
@_subject: Breaking DES anyone? (was: Breaking RC4-40 for less) 
I don't see how you can sweep for more than one key at once at low cost.
Because of the salt, every possible SSL encrypted message has to be swept
independently.  You can't sweep for two messages' keys at once because the
input to the MD5 is different even for the same 40-bit key.
If digital cash in micro amounts became practical, people could be paid
to let the "idle cycles" on their computers be used for this kind of
highly parallel application.  (Some people have speculated that graphics
rendering would be another suitable choice.)  It would be interesting to
see what the market price of cycles became in such an environment.  That
would give a better benchmark for the cost to break keys.

@_date: 1995-08-17 12:32:03
@_author: Hal 
@_subject: SSL challenge -- broken ! 
I can see three ways in which RC4-40 is weaker now than it was when it
was approved for "fast track" export approval.
First, of course, computers get faster every year.  So any fixed cipher
becomes relatively weaker as time goes on.
Second, until earlier this year RC4 was secret.  Then it was posted
anonymously to the cypherpunks list and later to sci.crypt.  Before that
time, only a much smaller number of people would have been in a position
to launch an exhaustive search attack.  But now that the source is
public, virtually anyone can try to crack it.  So this is really a very
significant loss of security.  It also illustrates the difficulty in
keeping secrets which will occur due to the kind of technology we
Third, there is much more interest now in actually doing massively
parallel encryption attacks.  The RSA-129 project got a lot of publicity,
and it was followed by the attack on the "Blacknet" 384 bit PGP key by a
small private group earlier this year.  People are aware now of how easy
it is to use parallelism in this kind of work, and with the software Adam
Back has worked on this could become even more popular in the future.  So
all this talk about "6,000 MIPS years" will not be as impressive if any
moderately sized hacker group can put that much computing power together
in a few days.
With these changes, RC4-40 has lost a significant amount of the
cryptographic strength it may have had a year or two ago.  It is
certainly time for the exportable key size to be expanded.

@_date: 1995-08-17 12:39:52
@_author: Hal 
@_subject: Strong encryption for credit cards only 
In response to the SSL break, Netscape has said they are working on
improved encryption specifically for credit card numbers.  This would use
56 bit keys, presumably DES.  I got this from the SJ Mercury News online,
While we can applaud any measure to increase user privacy and security,
it will be unfortunate if this enhanced encryption, which will
apparently be limited strictly to credit card information in order to
get export approval, weakens support for efforts to allow expanded
export approval of all sorts of encryption.
There are many aspects to privacy beyond credit card numbers.  The bottom
line remains that overseas companies are able to put stronger encryption
in their products than American companies can in their export versions.
We need to keep offering good arguments for why users will need strong
encryption for more than their credit card info.  If the message gets out
that this new measure solves the security problems on the internet then
that will be a big loss for our goals.

@_date: 1995-08-18 21:59:48
@_author: Hal 
@_subject: Vacation 
Sorry to be bugging out at such an interesting time, but I will be on
vacation from Aug 19 through Aug 26.  Hope to see a lot of CPs at
Crypto -
Hal Finney

@_date: 1995-08-19 08:28:19
@_author: Hal 
@_subject: SSL Challenge #2 
OK, here is another "SSL challenge" for your cracking pleasure.  I hope
this time people will be able to put together more of a group effort to
show how large numbers of less powerful machines can crack these keys.
I am leaving for a week in the Colorado mountains in a few hours so I
don't have time now to format this nicely.  However the necessary
information should all be here.
This one includes a fake credit card number as well as other fake
information.  As with the earlier challenge, this is all data I created
myself and captured using the actual Macintosh Netscape browser.
Note that the breakdown by messages is based on the packetizing done in
the TCP communication.  There may not be an exact correspondence between
these packet breakpoints and the "logical packets" used in the SSL
transaction.  Particularly for the long sequence of packets which come
back from the server towards the end (because it rejected the transaction
so is re-sending the form data, I think) you will need to check the SSL
length fields to see where the SSL packets start and end.  I am not sure
why there is so much data sent from the server at the end, but whomever
cracks it can presumably find out.
Good luck!
August 19, 1995
Hal Finney
First message from client
0x80 0x1c 0x01 0x00 0x02 0x00 0x03 0x00 0x00 0x00 0x10 0x02 0x00 0x80 0x07 0xea
0x7b 0x9d 0x65 0xeb 0x61 0xfa 0xbb 0x41 0x74 0xe8 0x45 0x3a 0x5f 0xc6 first message from server
0x82 0x14 0x04 0x00 0x01 0x00 0x02 0x01 0xf6 0x00 0x03 0x00 0x10 0x30 0x82 0x01
0xf2 0x30 0x82 0x01 0x5b 0x02 0x02 0x01 0x8a 0x30 0x0d 0x06 0x09 0x2a 0x86 0x48
0x86 0xf7 0x0d 0x01 0x01 0x04 0x05 0x00 0x30 0x47 0x31 0x0b 0x30 0x09 0x06 0x03
0x55 0x04 0x06 0x13 0x02 0x55 0x53 0x31 0x10 0x30 0x0e 0x06 0x03 0x55 0x04 0x0b
0x13 0x07 0x54 0x65 0x73 0x74 0x20 0x43 0x41 0x31 0x26 0x30 0x24 0x06 0x03 0x55
0x04 0x0a 0x13 0x1d 0x4e 0x65 0x74 0x73 0x63 0x61 0x70 0x65 0x20 0x43 0x6f 0x6d
0x6d 0x75 0x6e 0x69 0x63 0x61 0x74 0x69 0x6f 0x6e 0x73 0x20 0x43 0x6f 0x72 0x70
0x2e 0x30 0x1e 0x17 0x0d 0x39 0x35 0x30 0x37 0x31 0x31 0x32 0x32 0x34 0x31 0x34
0x35 0x5a 0x17 0x0d 0x39 0x37 0x30 0x37 0x31 0x30 0x32 0x32 0x34 0x31 0x34 0x35
0x5a 0x30 0x7f 0x31 0x0b 0x30 0x09 0x06 0x03 0x55 0x04 0x06 0x13 0x02 0x55 0x53
0x31 0x0b 0x30 0x09 0x06 0x03 0x55 0x04 0x08 0x13 0x02 0x43 0x41 0x31 0x16 0x30
0x14 0x06 0x03 0x55 0x04 0x07 0x13 0x0d 0x4d 0x6f 0x75 0x6e 0x74 0x61 0x69 0x6e
0x20 0x56 0x69 0x65 0x77 0x31 0x26 0x30 0x24 0x06 0x03 0x55 0x04 0x0a 0x13 0x1d
0x4e 0x65 0x74 0x73 0x63 0x61 0x70 0x65 0x20 0x43 0x6f 0x6d 0x6d 0x75 0x6e 0x69
0x63 0x61 0x74 0x69 0x6f 0x6e 0x73 0x20 0x43 0x6f 0x72 0x70 0x2e 0x31 0x23 0x30
0x21 0x06 0x03 0x55 0x04 0x03 0x13 0x1a 0x45 0x2d 0x53 0x74 0x6f 0x72 0x65 0x20
0x54 0x72 0x61 0x6e 0x73 0x61 0x63 0x74 0x69 0x6f 0x6e 0x20 0x53 0x65 0x72 0x76
0x65 0x72 0x30 0x5c 0x30 0x0d 0x06 0x09 0x2a 0x86 0x48 0x86 0xf7 0x0d 0x01 0x01
0x01 0x05 0x00 0x03 0x4b 0x00 0x30 0x48 0x02 0x41 0x00 0xc7 0x24 0x0d 0xbd 0xfe
0x5f 0x21 0x09 0xb4 0x46 0x12 0xbb 0xc7 0x4c 0xbc 0x0c 0x98 0xe3 0x11 0x19 0x60
0x85 0x86 0x0a 0xa2 0xaf 0xae 0x8f 0xf9 0x43 0x86 0x92 0x1f 0xcc 0xd3 0x38 0xcf
0x92 0x14 0xa7 0x8c 0x89 0x07 0x26 0xd4 0x21 0x55 0xa8 0x43 0x2d 0xb4 0xec 0xce
0x24 0x73 0x5e 0x7c 0xe2 0xbe 0x22 0x2d 0xbd 0x96 0xbf 0x02 0x03 0x01 0x00 0x01
0x30 0x0d 0x06 0x09 0x2a 0x86 0x48 0x86 0xf7 0x0d 0x01 0x01 0x04 0x05 0x00 0x03
0x81 0x81 0x00 0x8f 0xbe 0x0c 0xae 0xc8 0xf0 0x22 0xef 0xae 0x83 0xb5 0xb1 0xe3
0xb4 0xd9 0xd6 0xa9 0x4a 0xb6 0x60 0x9c 0x0b 0x00 0x70 0x12 0x88 0x73 0xd1 0xef
0xe2 0x54 0xf6 0x3a 0xc7 0xa5 0xbe 0xe1 0xe0 0xdb 0x4d 0x20 0x10 0x3d 0x68 0x7c
0x8d 0xdb 0x16 0xf6 0x67 0xe7 0x1d 0x51 0xbc 0x19 0xa2 0xf6 0xbf 0x6f 0xa4 0x52
0xc7 0x7e 0x50 0x3d 0xb9 0x3e 0x1e 0x67 0xff 0xf6 0xf2 0x5d 0xe7 0x2b 0x7e 0x3a
0x7e 0x6c 0x40 0xb7 0x04 0x9c 0x2c 0x2b 0x89 0x0f 0x8c 0xb5 0x93 0xd8 0xac 0x94
0xe6 0x5f 0x84 0xe8 0x71 0x75 0x9e 0x10 0x6e 0x36 0xe6 0x14 0xfe 0xba 0xf8 0x11
0x71 0x9d 0x74 0x33 0x48 0x74 0xc1 0xba 0xcb 0xff 0x58 0x86 0x8c 0xba 0x9c 0x08
0xad 0xce 0x8a 0x02 0x00 0x80 0xd5 0xe6 0x38 0xd6 0x8c 0xa8 0xa1 0xae 0xca 0x2e
0xf8 0xc8 0xe2 0x96 0x02 0xa4 Second message from client
0x80 0x55 0x02 0x02 0x00 0x80 0x00 0x0b 0x00 0x40 0x00 0x00 0xfb 0xc0 0x09 0x91
0x60 0x10 0xa6 0x15 0x3f 0x8f 0x36 0x5a 0x19 0x06 0x8e 0x58 0xc4 0xfa 0xd0 0x73
0xd4 0x6d 0x20 0x97 0x2f 0x85 0x95 0xb3 0xa5 0x97 0xb5 0xe0 0x63 0x91 0x61 0xb7
0x76 0x3c 0x4e 0x62 0x8b 0x02 0x2b 0x05 0x98 0xd4 0x14 0x44 0x63 0xf3 0x43 0x7e
0xa0 0xa8 0x3f 0x16 0xb2 0x43 0x4b 0x24 0x76 0xae 0xba 0x8c 0x89 0x71 0xde 0x25
0x6b 0xce 0x89 0x77 0x8a 0x30 0x2a Second message from server
0x80 0x21 0x9a 0xc5 0xf7 0xd1 0x6a 0x5b 0x26 0x43 0x57 0x67 0x65 0xb6 0x3f 0x9a
0xe3 0x82 0x00 0x65 0x99 0xb6 0xd2 0xf2 0xa7 0x36 0xa0 0x7d 0xd9 0x94 0xcf 0xe2
0x33 0xb2 0x1b Third message from server
0x80 0x21 0x38 0x4f 0x4d 0x99 0x31 0x33 0xc9 0x72 0x0f 0xf9 0xb7 0x7f 0xd4 0x02
0x4b 0x4a 0x3b 0xdb 0x4f 0xc9 0x04 0xa4 0x09 0xd1 0x04 0xbe 0xee 0xb0 0xe6 0xed
0x7f 0x18 0x17 Third message from client
0x80 0x21 0x98 0xdb 0x86 0xf2 0xe0 0x67 0x8a 0x2f 0x04 0x5b 0xf3 0xf0 0x78 0xe1
0x96 0x83 0x34 0x38 0x2f 0x22 0x45 0x61 0xa0 0xac 0x7d 0x9f 0xa8 0xcc 0x16 0xec
0xd7 0x33 0xb9 Fourth message from client
0x83 0x64 0x05 0x8e 0x95 0x38 0x40 0xca 0x91 0xb7 0x6f 0xc5 0x48 0x33 0x0c 0xf0
0xde 0x75 0x7d 0x41 0x08 0x23 0xe4 0xd8 0x0c 0x63 0x31 0x20 0x54 0xae 0xd9 0x4f
0x3f 0xc6 0x1c 0xbb 0x55 0xe3 0x6b 0xdd 0x8e 0x10 0x5a 0x40 0x3a 0x01 0xd6 0x35
0x35 0x3b 0x0c 0x5b 0x0f 0x22 0xb2 0x30 0x37 0x00 0x6c 0x3f 0x3f 0xa5 0x80 0x45
0xf8 0xe4 0x8d 0x0d 0x5d 0x4d 0x97 0xc8 0x4d 0xb5 0x23 0x7c 0x26 0xa2 0x63 0xeb
0xbb 0xbb 0x27 0xbd 0x72 0x64 0x18 0x97 0x0f 0x11 0x0c 0x22 0xc6 0x84 0xff 0x26
0x87 0x56 0x41 0x9c 0x48 0x48 0x51 0xc6 0x35 0xe1 0xff 0x85 0xf4 0xf4 0xfb 0x6e
0xba 0xcb 0x4c 0x2a 0xf1 0x18 0x5e 0xa3 0x24 0xb2 0xfd 0xf6 0x33 0x0c 0xc8 0x66
0x90 0x0c 0x80 0x72 0xbe 0x8c 0x2d 0x66 0xff 0xd3 0x11 0x5f 0x3c 0x9d 0x0f 0xe5
0x8a 0x39 0x4b 0x5e 0x05 0xde 0xd7 0x2c 0xfe 0xe7 0x15 0x96 0xbc 0xa8 0x2a 0x45
0x55 0x84 0xb4 0xb7 0xdc 0x6f 0x1b 0x89 0x88 0xd0 0x39 0xd7 0xff 0xad 0x3e 0x54
0x19 0xf8 0x7a 0x46 0x15 0x18 0x2b 0xd5 0x2e 0x69 0x61 0x83 0x4c 0xc1 0x52 0xd2
0x9d 0x22 0xa8 0x75 0x79 0x7b 0x95 0xf6 0x1d 0xf8 0xab 0x9f 0xf2 0xf5 0xf1 0xb7
0x42 0x2e 0xf6 0x17 0x43 0xc5 0x36 0x09 0x35 0x4b 0xeb 0xf6 0x39 0x45 0x5f 0xe2
0xdc 0x5c 0xa2 0x2b 0xee 0x1f 0x58 0xac 0xc1 0x92 0x63 0xe7 0xa7 0x5a 0xaf 0x85
0x40 0xbe 0x10 0x9c 0x96 0x18 0xeb 0x01 0xc4 0xb9 0x9f 0x49 0x76 0x04 0xe0 0xe8
0xda 0xcc 0x69 0x12 0x4d 0x2f 0x8f 0x53 0x2a 0xe0 0x07 0x15 0x41 0x4e 0xe8 0x88
0x92 0xdf 0x4e 0x67 0xdf 0xc4 0x42 0xe5 0xcb 0x6d 0x30 0xaf 0x62 0x0e 0xe1 0x4b
0x6c 0x33 0x01 0x6c 0xf6 0x66 0x0b 0xee 0x83 0xdd 0x00 0x7b 0xbb 0xad 0x9b 0x95
0xc0 0x2d 0xa1 0xfd 0x8b 0x41 0x13 0x70 0x87 0x1f 0xd9 0x3a 0x45 0x1b 0xcb 0xec
0x1b 0x61 0x41 0x62 0x50 0x8f 0x64 0xbc 0x8f 0xa9 0x2e 0x14 0x7c 0x75 0xff 0xb6
0x82 0x61 0x10 0x8f 0xad 0x27 0xa5 0x51 0xc6 0x2c 0x45 0x0f 0x52 0x27 0x3b 0x6c
0xb2 0x70 0xfa 0x3e 0x57 0xd9 0x16 0x91 0x0a 0xa5 0xd9 0xe4 0x1d 0xc0 0x7e 0x5f
0x5e 0xae 0x26 0xda 0x36 0x36 0x15 0x91 0x40 0x6c 0x6d 0x4a 0x51 0x9a 0x02 0x54
0x84 0x6b 0x1b 0xd5 0xa3 0xda 0x48 0xea 0x22 0x58 0xad 0xbe 0x65 0x25 0xfd 0x98
0x59 0xbb 0x00 0x06 0x32 0x3f 0xc3 0xfb 0x3a 0xb2 0x91 0x9e 0x25 0x8a 0x73 0x39
0xc1 0xeb 0xac 0x99 0xcf 0x5f 0xef 0x2b 0x57 0x05 0x8c 0x06 0xc5 0xd0 0x48 0x3b
0xad 0xc3 0xdb 0x83 0xdc 0xa0 0x00 0x3b 0xaf 0xfa 0x06 0x6a 0x0c 0xbd 0xe3 0x7a
0xd7 0x7c 0x00 0xcc 0xce 0xd1 0x0f 0xf6 0xc1 0x1a 0xa5 0x58 0x7d 0xa6 0xc4 0x55
0x2e 0xc2 0x7d 0x26 0x61 0x7e 0x8c 0x3a 0x9e 0xd6 0xb2 0x16 0xa9 0x39 0x6f 0x55
0x47 0x4c 0x67 0x5d 0x6b 0xc7 0xea 0xcc 0xde 0x17 0x5d 0x22 0x1d 0x0f 0xba 0x66
0x0e 0x9e 0x2b 0x6f 0x75 0xe7 0x1b 0x7a 0x86 0xbb 0x7f 0x6c 0x5b 0xa0 0x7b 0xe4
0xcb 0x55 0x8b 0xe2 0x38 0xf2 0x86 0x24 0x77 0xc2 0x8b 0x80 0xb3 0xb8 0xb7 0x1e
0x29 0x1f 0x3e 0x63 0xee 0x39 0x4f 0x4f 0x48 0x2a 0x9b 0xd2 0xcc 0xe4 0xaa 0xdd
0x73 0x5a 0x6e 0xd3 0x2d 0xb0 0x4f 0xe6 0xf1 0xc3 0xd9 0x5b 0xee 0xb6 0xfe 0xd4
0x92 0x37 0x5d 0xa6 0x5a 0xe3 0x11 0x71 0x76 0x0a 0x8b 0x9a 0xeb 0xe3 0x13 0x38
0x30 0x70 0x56 0x80 0x81 0xb3 0x16 0xbd 0x66 0xd5 0x86 0x6b 0xc9 0xbd 0xd8 0x47
0x8e 0x72 0x67 0x56 0xcc 0xce 0xc0 0x14 0x00 0xab 0xc4 0x9f 0x0a 0x75 0xf1 0x1c
0x5b 0x5b 0xa6 0xaf 0x52 0x01 0xe6 0xb1 0xe9 0x24 0x10 0x9f 0x60 0xf7 0xbb 0xed
0x25 0x62 0xb6 0x3f 0x23 0x93 0xd0 0x3b 0x12 0xb6 0x03 0x33 0x7a 0xa2 0xc6 0x74
0x1b 0x6d 0x82 0x47 0x67 0x2d 0x72 0x18 0x7e 0x23 0xff 0x44 0x17 0x13 0x57 0x61
0x0d 0xb9 0xa5 0x49 0x57 0xae 0xaf 0xd2 0xf2 0xf4 0xf3 0xb9 0x42 0xf2 0x31 0xc7
0xff 0x18 0xda 0x69 0x03 0xc3 0xdf 0xae 0xe8 0xcb 0x5c 0x6c 0x25 0xd5 0xcb 0xb5
0xd3 0x82 0xdc 0x04 0xb2 0x4f 0x74 0x44 0xa8 0x80 0xe3 0x38 0x5b 0xee 0xf5 0x98
0x9e 0x32 0x33 0x19 0x96 0xf5 0xfe 0xc5 0xf5 0x12 0xab 0xf7 0x02 0xfd 0x2a 0xe6
0x0b 0xf8 0xf0 0x1f 0xce 0x72 0x49 0x07 0x49 0x3d 0xd5 0xe7 0x04 0x80 0x3a 0x5f
0xfa 0x40 0xc7 0x7f 0x02 0x2c 0xfb 0x6e 0x6d 0x9b 0x5f 0x5c 0x2e 0x3d 0xc0 0x88
0x88 0xcd 0x70 0xc0 0xd4 0xfa 0x42 0xf3 0x76 0x8f 0xa8 0x5a 0x1f 0xa6 0x65 0x33
0x51 0x3f 0xe9 0x06 0xa7 0x5c 0xf3 0x87 0xce 0x78 0xe8 0x98 0x3f 0x83 0x4e 0x97
0x44 0x12 0x43 0x61 0xc9 0x9d 0x5e 0x19 0xba 0x87 0x06 0x26 0x07 0xe1 0x0c 0xb5
0x07 0xad 0x26 0x92 0xa6 0x3b 0x93 0x94 0xd2 0x36 0x7c 0x73 0x7f 0xf8 0xdf 0x05
0x0a 0x18 0x30 0xef 0xf5 0x77 0xfa 0xab 0x09 0x71 0x48 0xc1 0xc2 0x7c 0x28 0xf9
0x1c 0x78 0x05 0x12 0xde 0x51 0x83 0xdc 0x8f 0xc9 0x88 0x15 0x60 0x5e 0xb5 0x2d
0x7f 0x65 0x97 0x3e 0xba 0x14 0x06 0x0d 0xcb 0x5a 0x2f 0x0e 0xba 0x92 0x05 0xe0
0xd8 0x87 0xb3 0x38 0x42 0xc3 Fourth message from server:
0x81 0x2b 0xf3 0x4a 0x59 0xff 0xcb 0xd5 0x3b 0x06 0x97 0xc5 0xa9 0xa2 0x3e 0xb7
0x5a 0xc3 0x8b 0xa3 0x71 0xc6 0x86 0x15 0x82 0xb7 0x21 0x0c 0x46 0x2d 0x4e 0x70
0x1b 0x45 0x7b 0xc5 0x7c 0x92 0xe8 0x1f 0x1a 0x3a 0x2e 0xac 0x3b 0xb7 0xb2 0xa9
0x4a 0xca 0x26 0xb6 0x92 0x44 0x1b 0xe2 0xed 0x87 0x4d 0x1d 0x88 0x5d 0xe4 0x3b
0xbc 0x4b 0xc9 0xeb 0xce 0xc3 0x92 0x58 0xef 0x2d 0xf0 0x38 0x18 0xc6 0x52 0x5b
0xa0 0xf9 0x07 0x34 0xf2 0x46 0x92 0x6a 0x29 0xaa 0x4d 0xd8 0xc5 0x71 0x51 0xf9
0x6b 0x89 0x7e 0x3d 0x17 0x33 0x49 0x26 0x09 0xfb 0x57 0xa8 0xac 0x28 0x66 0x77
0xa6 0x9b 0xdc 0xbb 0xa4 0xf7 0x6a 0x2b 0x62 0x81 0x02 0xeb 0xa1 0x6e 0x57 0x13
0xe5 0xd3 0x85 0x9c 0x4c 0xd2 0xe5 0xc4 0x2b 0xe5 0x39 0x75 0xd3 0xe6 0x7a 0x8b
0xc5 0xdf 0x31 0xdf 0x58 0xd0 0xac 0xbf 0xf0 0xad 0x87 0x90 0xba 0x87 0x5f 0x21
0x86 0x6b 0x8e 0x9a 0x9c 0xa9 0x58 0xc6 0xa3 0x15 0x4f 0xec 0xb7 0x6e 0x7c 0xb9
0xb2 0x52 0xf9 0x65 0xc6 0xd5 0x4c 0xab 0x92 0x9a 0x84 0x63 0x8a 0x87 0x71 0xe0
0x39 0xa7 0x43 0xda 0x0e 0xe3 0x40 0x91 0xc9 0x9a 0xb9 0x79 0x0c 0x9e 0xbc 0xdd
0x83 0xf0 0xa2 0xde 0x85 0xb4 0x64 0x24 0x9d 0xdb 0xf0 0xcb 0xbe 0xaf 0x62 0x07
0x04 0x0b 0x08 0x65 0x89 0xc0 0x42 0xda 0x4e 0x2a 0x39 0x2d 0xbc 0xfa 0x8a 0xcc
0xc8 0xff 0x34 0x23 0xea 0x4a 0x41 0x41 0xcd 0x44 0xd3 0xfd 0x93 0x79 0xde 0xf8
0x53 0x7c 0xc5 0x2e 0x1c 0xfe 0xec 0xe5 0x7c 0xde 0x71 0x34 0x69 0xc7 0xf1 0x83
0x64 0x81 0xaa 0x42 0xb6 0xca 0xe2 0xef 0x33 0x7b 0x84 0x68 0x2d 0x49 0x01 0xc7
0xbf 0x85 0xd2 0x50 0x4c 0x1d 0x0b 0xde 0xd6 0xf0 0x31 0x6b 0xe1 Next message from server
0x93 0x52 0xc4 0x98 0xf3 0xf1 0xe7 0x1f 0x84 0x75 0xd0 0x26 0x24 0x69 0xc6 0xc4
0x16 0x7d 0x85 0xd8 0x16 0xb5 0x26 0x46 0xcc 0x51 0x24 0xcb 0xfb 0x22 0x09 0xa3
0x72 0x67 0x54 0x7f 0xf3 0xdb 0x85 0x10 0x02 0x34 0x7b 0x47 0x06 0x6e 0xf8 0xc9
0xd7 0xc4 0xf9 0xe1 0xe8 0x96 0x2f 0x19 0x0e 0x6d 0x61 0xf2 0x9c 0x4b 0xbc 0x89
0x1c 0xa8 0xd8 0x47 0x33 0xf6 0x15 0xf2 0x76 0xc1 0x5b 0x87 0xb6 0x82 0xe5 0x48
0x43 0x92 0x02 0x21 0x46 0xec 0xa3 0xd0 0x28 0xdc 0xce 0x7b 0x63 0x05 0x7f 0xd2
0xe1 0x92 0x99 0x76 0xbb 0x40 0xb5 0x07 0x15 0x20 0x73 0x59 0xe9 0xc5 0x0a 0x6f
0x40 0x48 0x91 0x88 0x2c 0x63 0x6a 0x46 0x0d 0x1a 0x5a 0xa0 0xc5 0x36 0xd1 0x47
0x66 0x82 0x87 0x0b 0x98 0x95 0xb9 0xa2 0xf9 0x73 0x9d 0x6d 0xfd 0x84 0x25 0x1a
0x1d 0x93 0xc1 0x18 0xd0 0x72 0xb2 0x90 0xc7 0x72 0x2f 0xf7 0x1b 0x6a 0xaf 0x1f
0xbf 0x05 0xcb 0xda 0x6a 0x31 0xff 0xcf 0xfb 0x30 0x89 0xdd 0xba 0xe9 0x7f 0x6b
0xbc 0x4c 0xbd 0x6c 0x63 0x0e 0x7b 0x2b 0x2f 0x90 0xe9 0x09 0x24 0xde 0xc6 0x97
0x3f 0x19 0x2e 0x1f 0x4c 0x4a 0xe9 0xf6 0x3d 0xf3 0x01 0xba 0x28 0xaf 0xfc 0x19
0xb7 0x96 0xb8 0x8d 0xfa 0x74 0xc8 0x62 0xe0 0x7a 0xae 0xe9 0xad 0x73 0x8c 0xa1
0x56 0xb8 0xbc 0x88 0x57 0x00 0xcd 0x5b 0x96 0x09 0xfc 0x1b 0xf7 0xef 0xf1 0x0c
0x68 0xee 0x7d 0x71 0x06 0x2d 0xd9 0x5c 0xdd 0x89 0x39 0x83 0x99 0x39 0x59 0x7a
0x47 0xfe 0xd5 0xb0 0xa2 0xdb 0x2f 0x92 0x9a 0xf6 0xff 0x8d 0xe4 0x45 0x69 0xbf
0xdb 0x87 0x08 0x0f 0x23 0x28 0xb2 0xe6 0x95 0x37 0xf6 0xd6 0x8d 0xb9 0x82 0x38
0x7c 0x5d 0xd2 0x96 0xae 0x24 0xf4 0xe4 0xaa 0xf4 0x01 0xb8 0x10 0x88 0xc4 0x5a
0x9e 0xa3 0x72 0x22 0xc1 0xb5 0x11 0x65 0x69 0x92 0xfe 0x1c 0xdb 0x3e 0xdd 0xc7
0x72 0x6c 0xf6 0xe4 0x55 0xbe 0xb5 0x4b 0x3c 0x2e 0xb0 0x1c 0x62 0xd5 0x03 0x19
0xb3 0xc3 0x42 0xbe 0xf2 0x8a 0xaa 0xdc 0xb2 0xc8 0x86 0x3f 0x11 0x56 0xc0 0x7b
0x6c 0x64 0xdf 0x83 0xb1 0x71 0xa2 0x51 0xd7 0x81 0x0e 0xac 0x0f 0x65 0x3d 0x46
0xbe 0x4d 0x58 0x26 0x44 0x92 0xd0 0x65 0x2f 0xf7 0x00 0xbb 0xe0 0x39 0x95 0xac
0xb8 0xd5 0xb6 0x7a 0x02 0xf1 0xb5 0x18 0xc0 0xa3 0x62 0x79 0xee 0xe4 0x7e 0x4f
0x4b 0xa0 0x42 0x25 0x13 0xfd 0x97 0x8a 0x6b 0x57 0x79 0xc5 0x9c 0x0a 0xb0 0x04
0xcb 0x8f 0x84 0x24 0xd6 0x64 0x0d 0x46 0x0c 0x7f 0x72 0x54 0x66 0x75 0xbc 0x0d
0x3d 0x32 0xc8 0x20 0xad 0x62 0xf8 0xac 0xce 0x48 0xbc 0x82 0x14 0x36 0x49 0x5a
0x31 0x55 0x31 0x5b 0xa6 0xd8 0xfa 0xf9 0x27 0x8a 0x8a 0xf7 0x7b 0x3e 0xb6 0x19
0xbd 0xed 0xd1 0x55 0x2d 0x19 0xb0 0xf3 0x7d 0xb9 0xa8 0xd5 0x9f 0x2e 0x90 0xb1
0xcb 0xd7 0xbd 0x03 0x39 0xd8 0x1a 0x62 0x40 0xfd 0x1a 0xf0 0xca 0x63 0x70 0x0a
0x5a 0x60 0xc9 0xa1 0x5d 0x5c 0x4b 0x07 0x6d 0xcd 0xba 0xaa 0x2a 0xe7 0xbb 0xa5
0x8c 0x5e 0x56 0x54 0x2e 0x41 0xe3 0x86 0xa3 0x2e 0xeb 0x17 0x8f 0xb2 0x9c 0xca
0x68 0x08 0x07 0x05 0x83 0x4f 0x7c 0x4f Next message from server
0xb6 0xe3 0x4b 0x09 0xfd 0x73 0x6c 0xc0 0x95 0xbd 0x3c 0xee 0x82 0x06 0x48 0x01
0x39 0x3c 0xc5 0x06 0xc4 0x9d 0x0a 0x2c 0x68 0xe9 0x98 0x19 0x83 0xcb 0xd3 0x9f
0xd0 0x7c 0x7e 0x60 0xeb 0x37 0x0c 0x7d 0xfa 0xd6 0xe8 0x70 0x1c 0xbf 0xb8 0x90
0x68 0x23 0x4f 0x99 0x33 0xdf 0x10 0xfd 0x08 0x7b 0x93 0xe5 0xe8 0x74 0x39 0xd7
0xa9 0x3b 0xc6 0x99 0xae 0xcf 0x23 0xfb 0xea 0x80 0x9a 0xfe 0x88 0x32 0x4e 0x61
0x2b 0xfa 0x4c 0x01 0x73 0xdb 0xc4 0x77 0x6a 0xff 0x5b 0x73 0x31 0x4e 0xdc 0x7b
0x54 0xc5 0x58 0xa2 0x81 0xcb 0x49 0x5f 0x34 0x9d 0xf6 0xea 0x71 0x74 0x48 0x0c
0xf7 0xc0 0xa7 0x1a 0x38 0x1a 0x1f 0xf1 0x40 0x29 0x54 0xd3 0x50 0x8f 0xd7 0xec
0xa9 0x17 0x83 0xb4 0x85 0xeb 0xb1 0x32 0xc7 0xa5 0xda 0xb1 0xe8 0x61 0x97 0x2e
0x59 0xd3 0xf0 0x28 0x86 0x3a 0x18 0xd7 0x65 0xd5 0xdf 0x87 0xa1 0x7c 0xef 0x35
0x51 0xf2 0xcb 0xbe 0x58 0xb3 0x39 0xa7 0xd6 0x74 0xdd 0xc8 0xa4 0xf7 0x94 0xe0
0xdf 0xbc 0x9a 0x97 0x75 0x32 0xc6 0x2c 0xe3 0x41 0x93 0x3b 0xa1 0xf4 0xa9 0xc6
0x8f 0x30 0xc8 0xdc 0x54 0x23 0xc7 0x6e 0x4d 0x3e 0x83 0xcd 0xbe 0x53 0x9c 0xa8
0x31 0x7c 0x21 0x17 0x58 0xad 0x88 0x75 0x59 0x21 0xd3 0x63 0x2a 0xcb 0x11 0x5b
0xff 0x32 0x1a 0x10 0x1c 0x43 0xd7 0x12 0x09 0x2b 0xff 0xb9 0xa1 0x6c 0x87 0xda
0xb9 0x3a 0x2e 0xc6 0xfa 0x8d 0x8e 0x2c 0xc9 0xab 0x1c 0xad 0x21 0xf2 0xc1 0xe6
0x11 0x63 0x68 0x89 0xad 0x29 0x1f 0x42 0xed 0x39 0x79 0x88 0x58 0x4c 0xd0 0xc7
0x65 0xdf 0x9d 0x10 0xc2 0x91 0xd1 0x67 0xf0 0x48 0x19 0x88 0x14 0xbe 0xf4 0x88
0xb1 0xe2 0xde 0x2e 0x84 0x1d 0xcf 0x95 0xd4 0x9c 0xc8 0xa9 0xfa 0xac 0xfc 0xe0
0x5f 0x24 0xd4 0x2a 0xd3 0x44 0x20 0x2d 0x20 0x39 0x43 0x3d 0xd0 0x12 0xe5 0xf3
0xb1 0x22 0x96 0x5d 0xa1 0xa2 0x3c 0xa2 0x28 0xf3 0x87 0x4e 0x13 0xea 0x36 0x77
0xe0 0x65 0xc8 0xba 0x82 0xe7 0xfc 0x3d 0xe6 0x42 0x95 0xf6 0x29 0x78 0x58 0x7e
0x37 0x42 0x7e 0x5f 0x5a 0xaa 0x1c 0x37 0x1a 0x10 0x69 0x5c 0x90 0x4f 0xbe 0xc3
0x19 0xe1 0x6d 0xcc 0xaf 0x30 0x9c 0x75 0x2e 0x8d 0xc5 0x7c 0x14 0x7b 0x7a 0x17
0x87 0xd4 0xdd 0x7e 0xc4 0xc5 0xb6 0x78 0x1a 0x56 0x15 0x51 0xe1 0x7e 0xb3 0x8a
0xad 0x7e 0x9f 0x9d 0x12 0xcd 0x66 0x51 0x0d 0x6f 0x36 0x49 0x34 0x3b 0x1f 0x2e
0x24 0x3d 0x71 0xf2 0xd3 0x65 0x41 0x70 0x82 0x93 0x98 0x21 0x70 0x40 0x6a 0x7c
0x13 0xd5 0x7c 0xe6 0x1b 0x9e 0x67 0x24 0x21 0x1e 0xcb 0x59 0xa1 0xd9 0xe4 0xdf
0x66 0x29 0xd9 0xf3 0x8d 0x8a 0xc6 0x6f 0x34 0xb2 0xaa 0x45 0xe8 0xf6 0x1f 0x59
0x18 0xec 0x15 0xb3 0xe1 0xae 0xe4 0xd2 0x40 0x78 0xb6 0x95 0x2a 0xf4 0xe3 0x41
0x9a 0x4c 0x1c 0xee 0x8b 0x82 0x83 0xb0 0xde 0x47 0x94 0xa2 0x7f 0x0c 0x63 0xd0
0xd2 0x35 0xc1 0x23 0x1f 0x5d 0x4c 0xeb 0x6f 0x74 0xac 0xad 0xb1 0xae 0x4f 0x89
0x8b 0x50 0x4c 0x62 0x7d 0x31 0x01 0xa5 0x0a 0x79 0x2b 0x3f 0x03 0xa0 0x1e 0x4e
0xfc 0x34 0xff 0x09 0xce 0xa0 0x88 0x27 Next message from server:
0x4f 0x8d 0xb9 0xf5 0x24 0xb7 0xeb 0x32 0x12 0x01 0x58 0x88 0x35 0xec 0xc6 0x22
0x75 0x59 0x21 0xe1 0xa9 0x54 0x69 0x19 0x2b 0xc4 0x42 0xb5 0xe5 0x0f 0x8c 0x86
0xb3 0x35 0x7b 0xa2 0x91 0x8e 0x29 0x94 0x4a 0x9d 0xa2 0x1e 0x1a 0x96 0x71 0xbe
0xe7 0x77 0xad 0x5f 0x45 0xf6 0x8a 0x56 0x89 0xf0 0x61 0xdc 0x88 0x9f 0xde 0xc4
0x2e 0x34 0x3a 0x89 0x6d 0x38 0x5f 0xc4 0x99 0x5c 0x4e 0x5f 0x9e 0x44 0xe4 0x10
0x61 0x1e 0x27 0x8d 0x6b 0x0f 0x4c 0x63 0x5f 0x45 0x81 0x23 0x37 0x33 0x8e 0x36
0xd8 0x26 0x79 0x7c 0x20 0xd8 0xc1 0x90 0xd8 0x22 0x47 0x25 0x3b 0x97 0x58 0xa5
0xdd 0xaa 0xdf 0x71 0xdb 0xe7 0x96 0x6c 0x0f 0xb7 0xcb 0x39 0x0f 0x1d 0x59 0x82
0xb4 0xb1 0xf8 0xb7 0x7c 0xcd 0xd9 0xa2 0x93 0x8d 0xc1 0x02 0x37 0x19 0xc8 0xa3
0x65 0x2b 0x99 0x3b 0x0e 0x0b 0x3e 0x4b 0xb7 0x28 0xaf 0xf4 0xac 0xb6 0xfd 0xc6
0x37 0x8d 0x82 0x1a 0x1c 0x68 0xdf 0x09 0x48 0x9b 0x07 0xd7 0x3c 0xdb 0xb3 0x7f
0x01 0xf6 0x10 0xb1 0xb3 0x24 0x71 0xb0 0xc6 0xdb 0x8b 0x1a 0x28 0xc1 0xbb 0x17
0x73 0x1f 0xe7 0xba 0x45 0xa7 0x96 0x70 0xa3 0x7d 0x20 0xfd 0xff 0x37 0xfb 0x7f
0x72 0x7f 0xe5 0x86 0x06 0xde 0x6a 0x62 0xe0 0x70 0x0a 0x61 0x02 0xac 0x87 0xd0
0x52 0x6f 0x70 0xb9 0x17 0x47 0x7b 0x8d 0x9b 0x2d 0xa4 0x1b 0x3a 0x42 0x52 0x7c
0x46 0xdf 0x25 0x42 0x2e 0x65 0x5c 0x13 0x1c 0x42 0x98 0xc0 0x4c 0xf1 0x36 0x2c
0x79 0xb7 0x32 0x66 0xf5 0xb3 0x15 0x3d 0xee 0xf3 0xc8 0xd4 0x7a 0xf9 0xbe 0x5c
0xc2 0x52 0xf8 0xc2 0x2b 0xaf 0x45 0x18 0xde 0xe7 0x52 0xb4 0x66 0x60 0x3b 0x17
0x4f 0x53 0x35 0xa6 0x29 0x5a 0x3d 0x0a 0x6e 0x46 0x8d 0xaf 0x31 0x82 0x96 0x99
0xf2 0x30 0x37 0x53 0x6b 0xf5 0x8e 0x9d 0x76 0x9c 0x52 0x20 0x89 0x67 0x72 0x46
0x1a 0xd3 0x76 0xb9 0x4d 0x87 0xcf 0xd8 0x2f 0x00 0x1b 0x20 0x19 0xa6 0x10 0xc8
0x65 0x44 0x5e 0xab 0x10 0x51 0x14 0xdc 0x16 0xef 0x89 0x28 0xd8 0x5e 0x52 0x02
0xc8 0x62 0xbc 0xad 0x8d 0x65 0x7f 0x0f 0xae 0x75 0x62 0x6c 0xa7 0x40 0x02 0x6c
0x9d 0xd4 0x60 0x60 0x3e 0x78 0x4b 0xbb 0x52 0xfc 0xf4 0x29 0xe0 0xac 0x0f 0x9f
0xd8 0x01 0x5d 0xfb 0x99 0xfa 0xa4 0x7c 0xd1 0x19 0xb9 0xdd 0x56 0xb5 0x93 0xee
0x6d 0x2f 0xf7 0x6e 0xd2 0xc9 0xd8 0xcb 0x32 0x39 0xe0 0xa8 0xa6 0x6f 0x7a 0xc2
0xf3 0xce 0x62 0x7a 0x14 0x46 0xbd 0xad 0xed 0x9f 0x26 0xfb 0x22 0x3b 0x2c 0x29
0x81 0x6b 0x4f 0x8d 0xef 0x99 0x5c 0xb1 0x15 0x09 0xd3 0x27 0x92 0xc6 0x38 0xb2
0x1a 0xb5 0x7b 0x06 0x98 0x70 0x99 0x36 0xb6 0x43 0xc0 0x5a 0x88 0x41 0xe5 0x90
0x66 0x83 0xee 0x29 0xf4 0x51 0xba 0x24 0xdc 0x59 0x56 0x42 0xea 0x4e 0x27 0xf8
0x9b 0x4f 0x66 0x5f 0x12 0xb1 0x46 0x2e 0x5c 0x81 0x34 0xb8 0xf7 0x50 0xd2 0x9d
0xba 0x33 0x09 0x1c 0xdd 0x60 0x46 0x97 0x12 0xe3 0x63 0xad 0xf7 0xfb 0x6e 0x1c
0x2a 0x51 0xc7 0xe7 0xc6 0xbc 0x0f 0x7a 0x3b 0xb2 0xe8 0x2d 0x90 0xcc 0xac 0xa6
0xa5 0x6f 0x38 0x63 0x80 0xf8 0x39 0xf4 Next message from server:
0x88 0x69 0x56 0x44 0xb6 0x32 0xa3 0x81 0xb7 0x64 0x07 0x32 0xe3 0xe3 0x2e 0x76
0x1a 0x1d 0x39 0x82 0x71 0x24 0xf8 0xe9 0xfe 0x94 0xa3 0xa7 0xfc 0xba 0xce 0x6e
0x18 0xe3 0xa9 0x10 0x7a 0x85 0x35 0xc2 0x72 0xe5 0x90 0x07 0x2e 0x18 0xcb 0x3d
0x4b 0xea 0xb4 0xd8 0xe5 0x10 0xc9 0x65 0xa6 0x5a 0x11 0xfa 0x17 0x73 0x36 0xb1
0x7e 0x83 0x3a 0xc7 0x5b 0x16 0x28 0x42 0x4a 0xc9 0x43 0x58 0xd5 0x3a 0x51 0x4b
0xb0 0xf6 0x91 0x58 0xc7 0xaf 0x8e 0x0a 0xae 0x5d 0xcd 0x52 0xb6 0x8f 0xf7 0xa1
0x02 0x8e 0xb8 0x58 0xbd 0xeb 0xff 0x60 0xa0 0xa7 0xe7 0xce 0x59 0x91 0xdd 0x31
0xb9 0x0e 0xf6 0x83 0x82 0x6d 0x17 0x0a 0x62 0x6a 0xcd 0x62 0x38 0x18 0xc5 0x99
0xf3 0x2e 0x35 0x91 0x04 0xef 0xa0 0x10 0x61 0x15 0x77 0x4a 0xef 0xf0 0xd2 0xce
0x27 0xa8 0x6a 0xb0 0xd0 0xea 0x9e 0x18 0x60 0x0b 0x94 0xf7 0xf3 0x49 0x50 0x8d
0x7e 0xf6 0x2b 0x84 0x5a 0x31 0x35 0x82 0x72 0xd9 0x6a 0x24 0x05 0x1e 0xa0 0x34
0xab 0xb1 0x74 0x7f 0x6d 0x50 0x0f 0x58 0x91 0xce 0x86 0x89 0x64 0xa7 0xc4 0xc1
0xd9 0xf3 0x47 0xea 0x4d 0x8b 0x1d 0xe1 0xe4 0xdf 0xba 0x72 0xd1 0x4e 0x52 0x95
0x30 0x5a 0x88 0x76 0xb4 0xc4 0xf4 0x4b 0xbe 0x10 0xca 0x52 0x66 0x02 0x7a 0x15
0x9a 0xd1 0x6e 0x70 0x00 0x24 0x87 0xe3 0x0b 0x6b 0xff 0x6d 0x71 0x7e 0x14 0x88
0x6b 0xf6 0xd8 0x32 0x63 0x53 0x89 0x91 0xe0 0xde 0x58 0x25 0x5e 0x3a 0x9f 0x28
0x38 0x44 0x1b 0x67 0x78 0x76 0x52 0x98 0x3d 0x19 0x25 0x82 0xe5 0x95 0x27 0xe8
0x62 0xac 0x05 0x02 0xcd 0x7b 0x7f 0xf1 0x76 0xff 0x24 0x4e 0x8f 0x50 0x26 0xef
0xfc 0xa4 0x9f 0x65 0x91 0xa5 0x35 0xbb 0x91 0xdc 0xb4 0xaf 0xa8 0x23 0xf7 0x62
0x48 0x14 0xb6 0x38 0x84 0x81 0x48 0x24 0xaa 0x39 0x4c 0x8f 0x1a 0x99 0xd1 0x1e
0xff 0x22 0x43 0x7c 0x1c 0x70 0xdd 0xd9 0x07 0x30 0x8d 0xb5 0xa3 0x26 0xe2 0x10
0xf1 0xa8 0x27 0x1c 0x3e 0x9f 0x17 0xc9 0x9e 0x95 0x10 0xc7 0x7c 0xb4 0x5f 0x54
0xe6 0x60 0x1b 0xe6 0xe6 0xb0 0xe1 0x2e 0x51 0x08 0x1c 0x26 0x31 0xb1 0x93 0xa6
0x9f 0x13 0xac 0xc6 0x3c 0x54 0x97 0xa3 0xc0 0xb8 0x50 0x83 0x32 0xc8 0xc2 0x16
0x43 0x53 0x15 0x4e 0x9f 0x69 0x19 0xec 0x68 0x22 0xf9 0x13 0xb2 0x19 0x48 0xf9
0xd3 0x31 0x92 0x90 0xe4 0x14 0xaf 0xf8 0xd5 0xcd 0x51 0xaf 0xe3 0x5b 0x39 0x42
0x82 0xb1 0x61 0x98 0x73 0x9b 0xa0 0x27 0xdb 0xde 0x1b 0x3a 0x2f 0x8f 0x67 0xd3
0x63 0x17 0x25 0xf7 0x6c 0x78 0x2c 0xd0 0x35 0xa5 0x61 0x68 0x21 0x48 0x51 0x46
0x78 0x29 0x6b 0x6c 0x88 0x6b 0x0e 0x40 0x67 0xb8 0x17 0xfc 0xff 0xdc 0x6f 0x6a
0x5a 0xe6 0x9f 0xcc 0x4b 0x4e 0xe5 0xcc 0x87 0xcf 0x15 0xe4 0x5f 0x27 0xcc 0xd1
0x37 0x77 0xde 0x6e 0xd1 0x21 0x32 0x44 0x41 0xdb 0x0c 0x6f 0xa6 0x7f 0xa8 0xb8
0xc1 0xbd 0xcc 0xa7 0xc0 0x0f 0x64 0x77 0x5f 0x58 0x54 0x1f 0x1e 0x60 0x9f 0x93
0xbf 0x1b 0x6a 0x04 0xe1 0x61 0x16 0xc2 0xc3 0x1c 0xaf 0xf1 0xb5 0x05 0xed 0xba
0x93 0x78 0x05 0xe3 0xae 0x5c 0xfd 0xa9 Next message from server:
0x96 0x58 0x8d 0x06 0xc9 0xae 0x53 0x95 0x00 0x18 0x6f 0xf5 0x0e 0xae 0x74 0xdf
0x7a 0xe0 0xeb 0x0e 0x73 0x4a 0xe0 0x87 0x7b 0x1a 0xd5 0x1b 0x92 0x41 0x16 0x81
0xef 0xc4 0x5b 0x57 0x3a 0x37 0x8d 0xf3 0xd5 0x4b 0xee 0xdb 0x5b 0x79 0xa0 0xb5
0xcd 0x88 0x4d 0x9d 0x17 0x3b 0xae 0xe2 0xf2 0xbd 0x17 0xa2 0x2c 0xf7 0x30 0xb4
0x50 0xed 0xa1 0x5a 0x61 0x50 0x8a 0x9c 0xb4 0xd8 0xd9 0xfa 0x08 0x26 0xa3 0xfc
0x9e 0xcd 0x69 0x2f 0xd2 0x6d 0x47 0x41 0xcf 0x3d 0x83 0xa1 0xe9 0x3d 0x53 0x94
0xf1 0x0d 0xd5 0x10 0x25 0xcb 0x1f 0xaa 0x0b 0x6b 0x17 0x09 0x8f 0x8d 0x37 0x64
0x5b 0x92 0x74 0xed 0x7b 0x58 0x12 0x39 0xf6 0x00 0x68 0x82 0xd3 0x06 0xc6 0xff
0xaf 0xe8 0x49 0x89 0xae 0x10 0x48 0xc2 0x48 0xfd 0x17 0x35 0x4a 0x03 0x89 0x9c
0x25 0x9f 0x05 0xa7 0x73 0x16 0xaf 0xde 0xd9 0x65 0xf2 0xc8 0x25 0x08 0x6e 0x38
0x52 0xc7 0xa0 0xd6 0xf3 0xe7 0xab 0x48 0xa3 0x6c 0x13 0xa0 0x76 0x64 0xee 0x6f
0x3f 0xfd 0x61 0xda 0x1a 0x15 0x20 0xbd 0xa7 0xf9 0x92 0xe5 0xae 0x6e 0x43 0xb4
0xda 0x46 0xdc 0xc5 0x7b 0x12 0x9c 0xb0 0x78 0x55 0x6b 0x69 0x41 0xfd 0xec 0x20
0x25 0x51 0xc6 0xf4 0x4b 0x17 0x24 0x27 0x8a 0x07 0xaa 0x14 0x6a 0x2e 0x67 0x94
0xc3 0xaa 0x16 0x38 0x1c 0x4d 0x57 0x38 0x4a 0x43 0xc6 0x96 0xa3 0x44 0x6a 0xee
0xe2 0x80 0x08 0x36 0xe2 0xf5 0xf8 0x64 0xe5 0x91 0x75 0x81 0xbe 0xbc 0xd0 0x2b
0x59 0x48 0xd9 0x65 0x79 0xa4 0x16 0xc9 0x8f 0xe4 0xb4 0x9d 0xc8 0xaf 0x2d 0xce
0xfa 0xfb 0x36 0x83 0x5c 0xb2 0xd4 0x10 0x2c 0x86 0x1b 0x8d 0x4d 0xdf 0x35 0xcf
0x11 0x77 0x61 0x3c 0x73 0x7d 0xbd 0xf0 0x37 0xcc 0xf0 0x66 0x31 0x69 0x96 0x02
0x10 0x1c 0x9e 0x31 0x6f 0xd2 0x4e 0x7f 0x31 0x8e 0x9e 0x5f 0xec 0x68 0x86 0x48
0xeb 0x46 0x5b 0x37 0x87 0xe0 0xcc 0xa1 0x68 0x6c 0x39 0x11 0x34 0x69 0x5d 0x27
0x0e 0x15 0xa5 0xbe 0xf0 0xdd 0xed 0xce 0x4e 0x33 0x8e 0x43 0x55 0xcf 0x7c 0x15
0x3d 0x6e 0xe4 0x63 0x5c 0x35 0xc3 0x7a 0x3f 0xde 0xa0 0xb3 0xeb 0xa1 0xd7 0x34
0xd5 0x0b 0x3d 0x66 0xc5 0x3a 0x20 0x64 0xaf 0x61 0xcb 0xa1 0x44 0x6c 0x72 0x52
0xbd 0x68 0xbb 0xb1 0x7a 0x3b 0x58 0x47 0x0b 0x85 0x76 0xeb 0x8c 0x78 0xf9 0x16
0xfc 0x87 0x71 0x2e 0x80 0x4e 0xb9 0x99 0x1b 0x3b 0xe1 0x3c 0x47 0xa7 0x39 0x85
0xf2 0x3e 0xdf 0x84 0x19 0xcc 0xaa 0xb4 0xd0 0x2e 0xd2 0x86 0x1c 0x17 0x8a 0xca
0x5d 0x84 0x46 0x0b 0x32 0x46 0x9a 0xf6 0xe2 0x72 0x28 0xcb 0xfb 0x25 0xb7 0xad
0x65 0x84 0x94 0x15 0x5b 0x25 0x2a 0xe1 0x65 0x14 0x01 0x13 0xee 0x2f 0x05 0x6c
0xf8 0xc6 0xf9 0xd1 0x45 0x46 0xac 0xf9 0x08 0x4b 0x79 0xe2 0x73 0xc8 0x7d 0x8c
0x81 0x66 0x54 0xf0 0x76 0x34 0x84 0x30 0xb0 0xf6 0xb3 0x15 0xe0 0x59 0xbc 0x57
0x91 0xea 0xa8 0xaf 0x35 0x5f 0x27 0x28 0x3b 0x58 0xc9 0x8d 0x76 0x00 0xf3 0x10
0xe2 0x33 0x70 0xad 0x5e 0x34 0x9e 0xa9 0x49 0x98 0x06 0xbd 0x57 0xa9 0x79 0x02
0xf7 0xf2 0xf3 0xcc 0xad 0x26 0xa2 0x63 0x4f 0x43 0x12 0xc8 0x51 0xd0 0xac 0xb8
0x51 0xbe 0xeb 0xf0 0x91 0x02 0xef 0xc7 0x68 0x3f 0xbc 0xff 0xf9 0x73 0x39 0xcb
0x56 0x84 0x5b 0xe7 0x28 0x82 0x22 0xf2 0xc3 0x84 0xb8 0x2e 0x12 0xd5 0xd6 0xf6
0x71 0x91 0xac 0x44 0xc2 0xc9 0xab 0xe0 0x4a 0x26 0xe3 0x8b 0x9f 0x1f 0x2f 0x8f
0x45 0x63 0x86 0x9b 0x96 0xb6 0xa7 0xf0 0xcf 0x8a 0x72 0xe3 0x76 0x03 0xeb 0x1b
0x92 0x58 0xcd 0xeb 0xe4 0xa6 0xc6 0xa4 0xbc 0x46 0x26 0x04 0xa2 0x35 0x21 0x8d
0xa7 0xc3 0x06 0x8f 0x38 0x94 0x8b 0x31 0xd3 0xda 0x50 0xa1 0xbd 0xff 0x36 0xad
0x9b 0xf3 0xb5 0xef 0x12 0x8a 0x14 0xfa 0x0a 0xc7 0xf5 0xd9 0xd3 0x33 0xf1 0xa2
0x97 0x18 0x57 0x59 0x1f 0xb8 0xaa 0xcf 0x81 0x76 0x22 0xe8 0x79 0x74 0x0c 0xf2
0x9f 0xb7 0x8d 0x80 0x26 0xfd 0x3c 0xc5 0x94 0xd3 0x39 0x52 0x3d 0xcd 0x4f 0xfa
0xe3 0x11 0xea 0x14 0x7a 0xe2 0xf3 0x42 0xda 0xb0 0x1b 0xa6 0x5e 0xfd 0x45 0xd0
0x93 0x84 0xb0 0xe6 0xd3 0x56 0x4f 0xd8 0x73 0x7d 0x56 0x70 0xa2 0x36 0x91 0xea
0x0c 0xe5 0x43 0x5e 0x07 0x8f 0x30 0x15 0xbe 0x82 0x2e 0xcc 0x5c 0x55 0x62 0x84
0xd3 0x60 0xc8 0xd4 0xd7 0x45 0x2a 0x63 0x40 0x0a 0xaa 0x04 0xd4 0x3a 0xb2 0xb4
0xdc 0x3e 0x12 0xe2 0x81 0x72 0x1f 0xfd 0xde 0xae 0xb7 0xe2 0x10 0x2e 0xf7 0xf6
0xbe 0x7f 0xa3 0x0b 0xc9 0xa3 0x65 0x6e 0xa4 0x4e 0x56 0x3d 0x7c 0x7f 0xea 0x38
0xd1 0x3c 0x2c 0x2e 0xb1 0x21 0xfa 0xd7 0x58 0xb5 0x06 0xdb 0x2b 0xe1 0x6b 0xee
0xa4 0x9b 0x40 0x7e 0x98 0xe4 0x05 0xf2 0x4a 0x24 0x88 0xe6 0xfa 0x23 0x81 0x52
0xc0 0x34 0x68 0x3d 0x72 0xb6 0xa2 0xba 0x49 0x70 0x4e 0x5d 0xcb 0x02 0x86 0x96
0x16 0x04 0x9e 0xb1 0xb6 0x3b 0x12 0x49 0x25 0x83 0x57 0xb6 0x2a 0xc6 0xff 0x07
0xac 0x38 0x58 0x25 0x57 0x19 0x79 0x6c 0x16 0x8a 0x10 0x63 0x42 0x55 0x09 0xcb
0x26 0x6e 0xb7 0x34 0x67 0xef 0x1d 0xff 0x7a 0x7b 0xaa 0x98 0x4a 0xf0 0x50 0x2b
0xe2 0x90 0x7e 0x92 0x83 0x24 0x9a 0x33 0x3f 0x6c 0x80 0x49 0x9c 0x82 0x8c 0x86
0xc3 0x1d 0xc7 0xbc 0x0c 0xee 0x9c 0x3e 0x49 0x9b 0xa3 0xfc 0x62 0x4b 0xd0 0x81
0xd2 0x5e 0x14 0x58 0x8e 0xbd 0x22 0xa3 0x02 0xfc 0x7f 0x48 0xa3 0x34 0xf0 0xbf
0x4b 0x52 0xb9 0x46 0x60 0x8b 0xda 0x1b 0xf8 0xc8 0x3d 0x28 0x9e 0xc6 0xe6 0x97
0x9d 0x78 0x0c 0x86 0x83 0x65 0x33 0xa5 0x51 0x0b 0xdc 0x60 0x27 0x2f 0x3f 0x37
0x1d 0xf5 0x32 0x33 0x76 0xd6 0xa6 0x97 0x0a 0xfc 0x9c 0x29 0xe1 0x67 0xb6 0x3c
0x74 0x57 0x01 0xc1 0xe9 0x69 0x9c 0x79 0xe5 0x75 0xdd 0x7a 0x2b 0x53 0xea 0x87
0x6a 0x94 0x1d 0x8a 0x0c 0x49 0x9a 0x15 0x1f 0x37 0x63 0x1f 0x98 0xc1 0x1c 0x5e
0x90 0x0c 0xae 0xee 0xb7 0x65 0xd3 0x1b 0xf2 0xf5 0x33 0x46 0x2e 0xaf 0x89 0x35
0x01 0x3a 0x8d 0x33 0x6e 0x39 0xd1 0xe7 0xf7 0xec 0x53 0xb9 0xb5 0xfd 0x46 0xbe
0xc7 0xe2 0xec 0x4e 0x7c 0xe3 0xd1 0x7d 0xe4 0xbd 0x8b 0x1e 0x0d 0x9f 0x7b 0xcd
0x5a 0x47 0x0f 0x0a 0x73 0x8c 0x7a 0x2f 0x5e 0xa4 0xf7 0xf7 0x5a 0x96 0x4d 0x7d
Next message from server:
0x0e 0x25 0x18 0x58 0xf5 0x3e 0x6d 0x52 0x52 0x22 0xd5 0x42 0xe3 0xd6 0x85 0x3e
0x88 0x81 0x71 0x1a 0xcd 0xa5 0xea 0x0b 0xd9 0x7f 0x70 0x9b 0x0b 0x18 0xb8 0x3e
0x74 0x6c 0x78 0x3b 0x8d 0xbf 0x60 0xaf 0xa9 0x26 0xd0 0x3b 0xcf 0xe8 0x3c 0x7f
0x5c 0xd5 0xcf 0x15 0x48 0xc4 0x9c 0x5d 0xb9 0xe6 0x12 0x4a 0x3d 0xe0 0x14 0x10
0x9e 0x2f 0xcb 0x57 0xf9 0x39 0xb0 0x1e 0x06 0x5b 0x93 0x0c 0x5e 0x24 0xeb 0xab
0x80 0x5d 0x9b 0xe0 0x06 0xc4 0x82 0x5d 0xe3 0xdb 0xdd 0xc2 0x04 0x8a 0x33 0x78
0x8d 0xdd 0xa8 0xd5 0x2f 0xc7 0xbb 0xc3 0xac 0x2b 0x9c 0x1a 0xc0 0x73 0x97 0x7c
0xe4 0x41 0x39 0x72 0xeb 0xa9 0xb4 0x11 0xbd 0xa8 0xc1 0xc2 0xb9 0x73 0x0a 0x56
0x37 0x01 0x79 0x3d 0xc1 0x87 0x3d 0xdf 0x76 0x7e 0xfe 0xd0 0x88 0xc0 0x59 0xe2
0x0e 0x3a 0xda 0xeb 0xed 0xd7 0x38 0x59 0x91 0xe2 0xea 0xe4 0xa2 0x5c 0xc7 0xc2
0x3f 0x68 0x1f 0x61 0xdd 0xcc 0x11 0x58 0x58 0x56 0x03 0xc3 0xab 0x1c 0xad 0xf6
0x65 0xfc 0x66 0x8d 0x3d 0xc5 0x2f 0x28 0x9a 0xab 0xba 0x70 0x6c 0xdc 0x08 0x38
0xac 0x79 0x80 0x42 0x17 0x13 0xa5 0x0b 0x7e 0xb8 0xe3 0x9e 0x5d 0xe0 0x3b 0x27
0x40 0xdf 0x0a 0x52 0x5d 0x18 0x2b 0x13 0x93 0x01 0x18 0xa0 0xfc 0xde 0x24 0x62
0xb8 0x89 0xf9 0xc3 0xe0 0x94 0xf9 0x8a 0x1d 0x55 0x58 0x62 0xb5 0x92 0xbe 0x60
0xcc 0xfd 0x1b 0x19 0xf3 0x3f 0xc3 0x21 0x16 0xce 0xbc 0x1e 0xfb 0x33 0xea 0xa8
0xf9 0xc5 0xdb 0x01 0xf1 0x55 0xac 0x3f 0xbd 0x78 0x2d 0x1d 0xae 0xbd 0x4b 0x12
0xf6 0xaa 0x00 0x58 0xb7 0x96 0x37 0xb0 0x93 0x4f 0xef 0x07 0xd6 0x02 0x4d 0x65
0xe6 0xa1 0xf5 0x20 0x0a 0xa1 0xaa 0xe7 0x93 0x09 0x31 0xd2 0xba 0xdb 0xab 0x32
0x2c 0x14 0xc1 0x8d 0x64 0xe3 0x05 0x0b 0x23 0x77 0x55 0x28 0x4c 0xe0 0xb8 0x8e
0xbc 0xa1 0x1f 0xec 0xdf 0x13 0xe5 0x44 0xb7 0x5d 0xb2 0xce 0xed 0xef 0x83 0xdb
0x95 0x62 0x8d 0x03 0x95 0x29 0x56 0xf7 0xaa 0x5a 0xdb 0x7b 0x99 0x54 0x77 0xe1
0x8a 0x85 0x98 0x65 0x03 0x24 0xcf 0xda 0x65 0xb1 0xd9 0xdd 0xe2 0xd3 0x9a 0x3b
0xd1 0xef 0x8b 0x12 0x8c 0x77 0xc0 0x2f 0x5f 0x15 0xc6 0x62 0x62 0xe0 0x0d 0x6d
0xd6 0x12 0x42 0x01 0x87 0x35 0x43 0x06 0x6e 0x45 0xcd 0xe7 0xfe 0x69 0xab 0x5a
0x97 0x99 0xe9 0xef 0xb3 0x52 0x3f 0xa9 0x01 0x88 0xd7 0xa5 0x1b 0x85 0x79 0xc6
0x18 0xfa 0x59 0x65 0x57 0xb7 0xfb 0x97 0x5d 0xde 0x5c 0x6d 0x5e 0x9b 0xa9 0xce
0xa5 0x92 0x79 0x6f 0x17 0x11 0x9d 0x0b 0x16 0x27 0xe4 0xc3 0x4d 0xc2 0xf1 0xbc
0x61 0x96 0x22 0xdf 0x90 0x2d 0x69 0x4e 0xb2 0x29 0x3f 0x8e 0x70 0xf5 0x50 0xa4
0xeb 0x0e 0xf3 0xce 0x32 0x26 0x44 0x6d 0xd9 0xa5 0x14 0xce 0x80 0x83 0xe5 0x4d
0x99 0x7a 0x27 0x8c 0xe8 0x72 0x0d 0xd4 0x24 0xaa 0x97 0x07 0x98 0x2b 0x0d 0x7a
0xbd 0x59 0xb7 0xed 0xe5 0x6d 0x18 0xc8 0x08 0x09 0x32 0xfa 0xe8 0x99 0xd8 0xa1
0xde 0x45 0x04 0x01 0xc8 0x04 0x88 0xbe 0x09 0x09 0xbc 0xc7 0x10 0x02 0x1c 0x02
0x2a 0x99 0x68 0x4e 0x40 0x3a 0xe1 0xbd Next message from server:
0xd7 0x8b 0xe0 0xaa 0x46 0x08 0xda 0x7d 0x6e 0x08 0x82 0xbc 0x7e 0xad 0x45 0x86
0xf8 0x79 0x95 0xd9 0x73 0x90 0xb5 0xc9 0xe7 0x7b 0xe5 0x27 0xf2 0x2d 0xbf 0x86
0x2e 0xb9 0x0b 0x15 0x78 0x57 0x24 0xad 0x15 0x3b 0xfd 0xa6 0xfb 0x78 0x47 0x60
0x65 0xe2 0x4b 0x98 0x11 0xa5 0xb7 0x93 0xbe 0xc8 0x28 0x24 0xd6 0xb7 0x4d 0x80
0x79 0x7e 0x05 0xca 0xca 0x43 0x5c 0xbc 0x23 0x97 0x50 0xb1 0xef 0x69 0x65 0x05
0x0f 0x59 0x95 0x19 0x37 0x2c 0xcf 0xae 0xff 0x49 0xaa 0x8b 0xb2 0xe8 0xdc 0x91
0x89 0xf0 0x94 0x3a 0xa7 0x9b 0x56 0xa0 0x90 0xcc 0xcc 0xbf 0x0b 0xa7 0x7a 0x65
0x63 0x9e 0x96 0x37 0x71 0x70 0x43 0xd5 0x2d 0xe7 0x46 0x5e 0x75 0xf5 0x68 0x9e
0x0a 0xa6 0xbb 0xf8 0x26 0xee 0x84 0x74 0x67 0xa7 0x0b 0xe1 0xa6 0x04 0x8b 0x65
0x96 0x9d 0x60 0xc5 0xfc 0x74 0xc9 0xde 0xe2 0xdd 0xfe 0xb1 0xed 0x1c 0x7c 0x2a
0x78 0xaf 0x9b 0x6f 0x3c 0xc0 0x6c 0x77 0x15 0x16 0xfc 0x00 0xd1 0xe2 0x49 0x65
0x6a 0x2a 0x74 0xb6 0xa9 0x00 0x2d 0x7f 0xb4 0x88 0x70 0xba 0x8c 0x81 0xcd 0x97
0xc6 0x06 0x44 0x0a 0xd5 0x99 0xea 0x49 0x81 0xcd 0xd1 0x44 0x6a 0xf8 0x54 0xa8
0x45 0x84 0x84 0x24 0xa7 0x4f 0xc4 0x23 0x0d 0x3b 0x53 0x3e 0xfa 0x74 0x2b 0xea
0x82 0xc9 0x71 0x1c 0xcb 0x5a 0x2b 0x3a 0x22 0x33 0x18 0xce 0x4e 0xa1 0x13 0x0e
0xf8 0x1b 0x94 0x20 0x2b 0xc2 0x3d 0xdd 0xa4 0x88 0xc5 0x69 0x3b 0x37 0x21 0x62
0x2d 0x09 0x02 0xd9 0xeb 0x8e 0x3c 0x46 0x5a 0x18 0x0a 0xe7 0x03 0xc6 0x10 0xb1
0x32 0x34 0x7f 0xf2 0xe3 0xf5 0x66 0xa3 0x79 0x75 0x1c 0xae 0xf6 0x0f 0xaf 0xd2
0xef 0xe0 0xb1 0xe8 0x91 0x9e 0xdb 0x23 0x57 0x0a 0x71 0xcd 0x5f 0x64 0x3d 0xba
0x59 0x7a 0x50 0x78 0xf1 0x23 0x1e 0x51 0x15 0x4c 0x1b 0x0c 0x83 0x4a 0x0e 0x74
0x07 0x8d 0x26 0x45 0x05 0x3c 0x00 0x38 0xb5 0xff 0xbf 0x47 0xd1 0x3a 0x68 0xa1
0x6e 0x40 0xc7 0xa2 0x36 0xd4 0x42 0xcf 0x4d 0x60 0xc8 0x47 0x26 0x63 0x3a 0x9d
0x57 0x4b 0xae 0xcf 0xe8 0xc9 0x39 0x79 0x50 0x8c 0x22 0x0d 0x06 0x31 0xcb 0x3f
0x2d 0xe4 0xbe 0x7d 0x9a 0x2d 0xc6 0x45 0x75 0x8c 0x4f 0xb7 0xcd 0x10 0x3d 0x41
0x93 0x1e 0x4e 0x2e 0xc1 0xb1 0x9d 0x20 0x3d 0x1a 0x10 0x83 0xd2 0x77 0xbf 0x93
0xf9 0x31 0xb0 0x94 0x0e 0xfe 0x11 0xf4 0x9d 0xb4 0x0d 0x4d 0x23 0x37 0xca 0xef
0x5e 0xa9 0x48 0xab 0x9f 0x38 0xb7 0x42 0x10 0xeb 0xba 0xb3 0xa1 0x99 0x8c 0x2a
0xb8 0x6a 0xac 0xe1 0x4b 0x0a 0xdf 0x11 0xd0 0x97 0x99 0xe3 0x6b 0x96 0xff 0xec
0x21 0x6f 0x14 0x36 0x1e 0x57 0xc2 0x81 0xcc 0x49 0xdc 0x7f 0xe7 0xc0 0x91 0xab
0x2c 0x16 0x98 0x93 0xb2 0xb6 0x61 0xc1 0xb5 0x8f 0x14 0x1a 0x6f 0xc6 0x14 0x34
0x8f 0xdb 0x97 0x8f 0x75 0x00 0x05 0xb8 0x77 0x17 0xd0 0x06 0x9b 0xff 0x79 0xf9
0xcb 0x4e 0x5d 0x85 0xd7 0xeb 0x68 0xaf 0x53 0x4f 0x0c 0xd9 0x36 0x96 0x23 0x52
0x41 0xbf 0xc0 0xeb 0x44 0x7c 0x3e 0x78 0x56 0x3b 0x3f 0x8a 0xb1 0x58 0x33 0xf9
0x55 0xdd 0x60 0x1d 0x7b 0x5e 0x46 0x61 0x3d 0x7e 0x4d 0xa0 0xea 0xfc 0x56 0x23
0x61 0xbf 0xc5 0x1f 0x79 0x07 0x3c 0x7d 0xf4 0x9c 0xb1 0xd1 0xaf 0x5a 0x48 0x2c
0xb5 0x1d 0x81 0xcc 0xce 0x2c 0x50 0xa9 0x0e 0x8a 0x9f 0xb4 0xc4 0xb6 0xaf 0x0f
0xce 0x5d 0xb2 0xcc 0xae 0x9b 0x0d 0xbe 0x98 0x2d 0xa1 0x47 0xef 0xce 0x62 0xcd
0x62 0x79 0x3c 0x0f 0xa7 0x05 0xc8 0xcb 0x21 0xf2 0xa9 0x85 0x79 0xae 0x30 0xcb
0x10 0x98 0x65 0xdf 0xe0 0x95 0xe8 0x1a 0x35 0x85 0xb6 0xdc 0x80 0x5f 0x92 0x04
0xa8 0xb8 0xcc 0x13 0x5f 0x5c 0x79 0x8f 0xba 0x56 0x56 0x4e 0x35 0x1f 0xe4 0x63
0x65 0x67 0xaf 0xdb 0xdd 0x42 0x17 0xd5 0x11 0x92 0x23 0x4e 0xea 0x2a 0x43 0x55
0xde 0x22 0x07 0xeb 0x62 0xb9 0x9f 0x83 0x4a 0xaa 0xec 0xc2 0x97 0x52 0xb3 0xf7
0xa7 0x44 0xf6 0x31 0x10 0x23 0xc5 0x56 0xcc 0xbb 0x23 0xa9 0xaa 0x53 0x18 0xff
0x66 0x5e 0x87 0x8f 0xb1 0x6c 0x2e 0xf3 0xcd 0xf2 0xbb 0x0d 0xbc 0x13 0x9a 0xe3
0x3e 0xd2 0x22 0x3f 0x65 0x1c 0x53 0xd6 0x64 0x38 0x5f 0xd8 0x03 0x09 0x19 0x19
0xaf 0x64 0x16 0xc3 0xac 0x35 0x4b 0x99 0xf1 0xd3 0xb9 0xbd 0x09 0xe5 0x60 0x86
0x02 0x8c 0x00 0x99 0x58 0x7b 0x3e 0x69 0x4d 0xc6 0xcd 0x49 0x72 0x65 0xba 0xbb
0xd1 0xb4 0x3a 0x92 0x88 0x5e 0x34 0xea 0xa6 0xd5 0xfb 0xff 0x8f 0x29 0xbf 0x71
0xca 0x5b 0x1c 0xb5 0x06 0x28 0x8a 0x13 0x15 0x9d 0xf1 0xa4 0xb9 0x77 0xb9 0x2d
0xc8 0x37 0x3d 0xb4 0xa9 0x66 0x54 0x7a 0x32 0x21 0xb1 0x6e 0x19 0xb0 0x4e 0xd0
0x57 0x91 0x89 0x68 0x9c 0xb5 0xc3 0x8b 0xc6 0xa8 0xb2 0xc1 0x12 0xf7 0x81 0x78
0x09 0xdd 0x30 0xf2 0x3b 0x4a 0xcd 0xad 0xe2 0x0d 0x02 0x4b 0xf4 0x27 0x71 0xd5
0x06 0x1a 0xc1 0x8f 0x53 0x4f 0xf6 0xf2 0x3e 0xfe 0xb3 0x76 0x94 0x7d 0xea 0x71
0x6a 0x8f 0xb2 0xf6 0x48 0x6a 0xf5 0x18 0x27 0x62 0xa1 0xed 0xc4 0x33 0x82 0x11
0x9d 0x5c 0x68 0xb1 0x7a 0x03 0x9b 0x82 0x68 0xb3 0xda 0x51 0xe3 0x77 0x86 0x90
0xaf 0x11 0x70 0xae 0xba 0x42 0xb6 0x10 0x1a 0xd0 0xca 0x85 0x1e 0xee 0x1a 0x4b
0x0e 0x17 0x2e 0xd9 0x09 0x94 0x1c 0x1e 0x69 0x94 0xe5 0x35 0xdc 0xc6 0xd6 0xcf
0x6f 0xa4 0x37 0x26 0xd7 0xcb 0x3a 0xbc 0xe0 0x9a 0xe4 0x72 0x15 0x16 0xe9 0xf0
0x48 0x14 0xf9 0xa7 0xbf 0xc5 0x51 0xc0 0xf6 0x94 0xfa 0x49 0xef 0x28 0x96 0xd7
0xb3 0x23 0xb6 0xa9 0x35 0xe0 0xc4 0x2b 0xab 0x8c 0x13 0x3d 0x56 0x0a 0xa1 0xdb
0xb6 0x50 0x13 0xf1 0x09 0x21 0x1b 0x4d 0xbe 0x0c 0xb4 0x67 0x81 0x6e 0x2b 0x93
0x65 0x0f 0x90 0xf5 0x77 0xdc 0xf8 0x41 0x1c 0xe4 0x56 0xec 0xa9 0x17 0x77 0xb5
0x7e 0xeb 0x88 0x6f 0xc2 0x4d 0x5f 0xd1 0x54 0xee 0x9b 0x1a 0x35 0xd3 0x5e 0x84
0x47 0x51 0xa7 0x9f 0xe2 0xbc 0xd6 0x46 0x80 0xfe 0xfe 0xf7 0xd6 0xd6 0x93 0x8b
0xa7 0x16 0x35 0x27 0xea 0x24 0x22 0x5f 0x34 0xad 0xf3 0x85 0xbb 0xc0 0x34 0xae
0x2d 0x20 0x3d 0xe7 0xb2 0x5d 0x8a 0xa8 0xc2 0x05 0x80 0x05 0x09 0x3e 0x52 0x63
0x58 0xdd 0x7e 0x18 0x89 0xad 0x01 0x9a 0x19 0xb7 0x55 0x9f 0x0d 0x3a 0xcf 0xbc
0x6b 0xc4 0x6a 0xeb 0x3d 0x1e 0xe3 0x72 0x4a 0x5e 0xe1 0x2e 0xa2 0x7f 0x39 0x72
0xdb 0x06 0x7d 0x46 0xe8 0x21 0x2f 0xaf 0x07 0x23 0x96 0xf7 0x3c 0x92 0x54 0xa4
0xce 0xad 0xe2 0x11 0x7f 0x5c 0x22 0xce 0x1c 0x5b 0x72 0x1a 0x36 0x1d 0xb7 0x58
0x62 0x48 0x3f 0xba 0x2c 0xa7 0xf8 0x07 0x6b 0x32 0x0b 0xf6 0xe2 0x9d 0x2f 0x4f
0x6f 0xdb 0x83 0xf4 0x94 0x0d 0x52 0x25 0xb9 0x6b 0x8b 0x97 0xaa 0x9e 0x9d 0x6a
0xdc 0x1a 0xfa 0x3c 0x01 0x18 0x79 0xb7 0x32 0xda 0x2b 0xae 0xe7 0xfd 0x02 0xa3
0xac 0x0a 0x05 0x62 0x04 0x91 0xc7 0xc8 0x48 0x99 0x8c 0x76 0xe0 0x1a 0x32 0xb7
0xf4 0x6f 0x46 0xc0 0xe7 0x35 0x63 0xa7 0x7a 0x6a 0x3a 0x7c Next message from server:
0x86 0x84 0xc4 0x9e 0x31 0x8a 0xac 0x17 0x2c 0xb6 0x96 0x21 0x4b 0xf9 0x5c 0x29
0xb7 0x05 0xcf 0xc4 0xb6 0x20 0x3e 0xc8 0x8c 0x28 0x66 0x3b 0xa8 0xa6 0xb5 0xf8
0xde 0xd8 0x8d 0x13 0x66 0x39 0x54 0x81 0x49 0xe9 0x0f 0xf6 0x75 0x1d 0x00 0x6c
0xf8 0x27 0xa6 0x24 0xbd 0xa4 0x23 0x5e 0x05 0x54 0x4f 0x9b 0xe1 0x26 0xe2 0xf8
0xb1 0x69 0x49 0xa9 0xd5 0xcc 0x06 0xe8 0xdc 0xf7 0x67 0x77 0xc2 0xae 0x8e 0xdf
0x24 0xc6 0xc8 0x10 0xbb 0x89 0x18 0x8f 0xef 0xef 0x08 0x9b 0x20 0xba 0x90 0xc2
0x8e 0xa8 0xd5 0x74 0x3b 0x12 0x27 0xdf 0x50 0x9f 0xd4 0xdb 0xe2 0x8f 0x8d 0x96
0x70 0xd5 0x43 0x01 0xb8 0x81 0x50 0x74 0x9e 0x41 0x56 0xd1 0x2f 0xcb 0xbd 0xd9
0xe4 0x18 0x02 0x35 0x5e 0x48 0x54 0xd7 0x5e 0x14 0x56 0x8b 0x6c 0x21 0xd1 0xbf
0x09 0x02 0x61 0x72 0x77 0xdc 0xc5 0x1d 0x36 0xb9 0x61 0x67 0x19 0xf4 0x71 0x68
0xd4 0xa3 0xf0 0x02 0x7c 0x5c 0xed 0x9c 0xc9 0x3b 0xac 0x94 0x56 0x1d 0x82 0x44
0xae 0x9a 0x5c 0xa9 0xc5 0x43 0x3e 0xe1 0xc3 0xee 0x0e 0x58 0xcb 0xd3 0x2c 0x18
0x35 0xe4 0x2e 0xcc 0x44 0x38 0xf3 0x0f 0x65 0x0b 0x72 0x16 0x1b 0x40 0xb3 0xb5
0x39 0x50 0xc9 0x36 0xe3 0x46 0xe2 0xf9 0x2f 0x55 0x26 0x07 0xd2 0xfd 0x97 0x45
0x81 0xa0 0x7e 0x4d 0x87 0x7f 0xa3 0xb7 0xcc 0x76 0xe5 0x6f 0x5a 0x5c 0xa1 0x9e
0x11 0x4a 0x55 0xa7 0xce 0xd4 0x31 0xfa 0x90 0xf3 0x6b 0x25 0xef 0xfe 0x17 0x4f
0x2f 0x8b 0xde 0x73 0xde 0x77 0xd7 0x38 0x5e 0x9f 0x45 0x7a 0xd3 0xb4 0xc5 0x11
0xe9 0x8b 0x1a 0x84 0x5d 0x0e 0x41 0x01 0x21 0x6f 0x29 0xc4 0x2e 0x1f 0x0f 0x30
0x15 0x51 0xee 0xad 0x67 0xc3 0x5f 0xe2 0x2d 0xa8 0x78 0xff 0xbc 0xfa 0x02 0x14
0x16 0xd5 0xe1 0xc4 0xb7 0x8b 0x83 0x3d 0xa1 0x6d 0xbc 0x5e 0xa6 0xd4 0x73 0xd0
0x8c 0x19 0x30 0x4c 0x5f 0x14 0x81 0x69 0x59 0x3b 0x6c 0x7f 0x05 0xed 0x11 0x95
0x10 0x98 0x0c 0xc8 0xa8 0x03 0x4a 0x5d 0xc0 0xc4 0x9d 0xbb 0x44 0x2f 0x4d 0xd0
0xf0 0xa7 0x30 0x32 0x8d 0x75 0xad 0xb0 0xcc 0x12 0xcf 0x85 0xde 0x7c 0x3d 0xe8
0x85 0x1c 0xc4 0x45 0xd9 0xa4 0x57 0x23 0x34 0x75 0xf5 0xa8 0x2b 0xc7 0x02 0xfe
0x45 0xee 0xd8 0x6f 0x57 0x64 0x19 0xb2 0x51 0x0e 0x6c 0x88 0xd0 0xb7 0x6c 0x66
0x02 0x47 0x98 0x34 0xa2 0xd4 0x68 0x83 0x3f 0x8c 0x7a 0x03 0xa4 0x1c 0x59 0x17
0xb3 0xcd 0x2c 0x18 0xdf 0xf7 0x6a 0x8c 0xe0 0xb7 0x6c 0xb1 0x1f 0x3e 0x04 0x69
0x18 0x4a 0x64 0x70 0x57 0x78 0xda 0xcb 0xf9 0x98 0xee 0xa0 0x93 0xc8 0xe7 0x9d
0x14 0xb2 0x47 0xd8 0x32 0xa7 0xa2 0xaf 0x12 0xb8 0xe8 0xe7 0x76 0xb0 0xcb 0xcd
0x26 0x80 0x37 0xa2 0xd4 0x69 0x3b 0xc0 0x5c 0x8e 0xa0 0x2c 0xba 0x97 0x4e 0xba
0xc7 0x64 0x05 0x66 0x28 0x9f 0xb2 0x3c 0x4c 0x3a 0xc9 0x27 0x8c 0x5e 0x14 0x9d
0xbc 0x5e 0x2f 0x66 0x42 0xd2 0x6e 0x54 0x52 0xd9 0xa9 0x0c 0x94 0xf2 0x61 0xcf
0x0c 0xa4 0x4e 0x7d 0x83 0x64 0x20 0x1d 0xf1 0xcb 0xab 0x49 0x17 0x92 0x1e 0x49
0x88 0x52 0x59 0x29 0x02 0x04 0xa2 0x4e Next message from server:
0xf2 0xee 0x5e 0x17 0x82 0x91 0x8f 0x05 0x0a 0x47 0x66 0x3b 0x24 0x06 0xd8 0x27
0x52 0xfc 0x77 0xe5 0xc7 0x13 0x39 0x8b 0xb5 0xf7 0x64 0xf0 0xba 0x0f 0xd2 0x92
0x54 0x9e 0xbe 0x3b 0x71 0xef 0x74 0x28 0x94 0x36 0x1b 0xcf 0x31 0xfa 0x04 0xa9
0xb4 0xfc 0x5e 0x65 0x21 0x5a 0xad 0x5f 0xc2 0xe7 0xe0 0xf6 0x64 0x39 0x65 0x43
0x0b 0x61 0x0b 0xcd 0x05 0x73 0xe7 0xda 0xaa 0xec 0x5c 0x8f 0xa4 0x14 0x10 0x79
0x12 0x78 0xe4 0xa8 0x4e 0x03 0x5e 0x9c 0x40 0xe9 0xe2 0x44 0x0e 0x3e 0x53 0xf3
0x2c 0x65 0x14 0xad 0xd7 0xbf 0xc7 0x4c 0xa8 0x18 0xfa 0x6e 0x4c 0x3e 0x2d 0x7f
0x3e 0xfc 0x5f 0x82 0xc3 0x99 0x3a 0xa6 0x28 0x76 0x54 0x74 0x55 0xe0 0xd4 0x6d
0x30 0x5a 0x65 0x5b 0x2a 0x7b 0x65 0x78 0xc4 0xb9 0xfd 0x57 0xc4 0x8d 0xb3 0xf5
0x00 0x27 0x3e 0x45 0x95 0xb4 0x42 0xd7 0x96 0x87 0xa0 0x0c 0x9e 0x29 0xd6 0x59
0xba 0xc2 0xf5 0x27 0xc8 0x4d 0x71 0xd8 0xb7 0xca 0x15 0x8e 0x9a 0xcd 0x51 0x42
0xb8 0x9a 0x98 0xa0 0x79 0xb4 0x44 0x3b 0x53 0xab 0x0e 0x43 0x99 0xbc 0x7a 0xf1
0x09 0x99 0xc9 0x9b 0x5a 0x23 0x66 0x48 0xcd 0x6e 0x77 0x30 0x84 0x31 0xdb 0x69
0xa8 0x6a 0x18 0x1d 0x44 0x64 0x7d 0x18 0xa2 0xae 0x3a 0x76 0x8d 0xe9 0xc6 0x2e
0xfd 0xcf 0xc3 0x8c 0x2d 0x84 0x65 0x32 0xfd 0x07 0xb7 0x73 0x46 0x64 0xb7 0x98
0x89 0xde 0xb5 0x60 0x9a 0x61 0xe7 0x5a 0xd6 0x76 0x29 0xdc 0x6c 0xd2 0xf0 0x14
0xae 0x30 0x9d 0xcb 0x53 0xd4 0xb5 0x2c 0x80 0x40 0x75 0x1a 0x8e 0xd9 0x04 0x08
0x3d 0xe3 0xc9 0xbb 0x97 0xc6 0xac 0x70 0x99 0x91 0xa7 0xfd 0x1e 0xe6 0x41 0x04
0xdf 0x04 0xd2 0x8a 0x59 0xed 0x53 0x11 0x4c 0xbe 0xfa 0x0c 0x4d 0x5c 0x00 0xbd
0x97 0xb4 0x4d 0x6b 0xb2 0x23 0x59 0xff 0x9f 0xea 0x0e 0x9c 0x24 0x47 0x33 0x8d
0xd8 0x3e 0x66 0xaa 0x14 0xed 0xac 0x5a 0xd7 0xdd 0x23 0x17 0x7b 0x07 0x9e 0x88
0xaa 0xcb 0x38 0x7c 0xa6 0xa7 0x47 0x7c 0x7f 0xfa 0xd7 0xa1 0xed 0xb3 0x6d 0x01
0xfa 0xe5 0xaa 0x1b 0x2e 0xc6 0xcd 0x41 0x2f 0x90 0xce 0xc2 0xcd 0xa1 0xce 0x92
0x42 0x7b 0x9f 0x54 0x5f 0x01 0x0b 0xaf 0x39 0x31 0x67 0x65 0x45 0x59 0xa1 0x3e
0xa6 0xac 0x90 0xe1 0x2b 0x1b 0x7c 0x8c 0x3f 0x0b 0xda 0x0e 0x57 0xb7 0x17 0x45
0xba 0xd6 0x72 0x6b 0xbd 0x3e 0x0c 0xa7 0xa3 0xd3 0xb0 0xf4 0x9a 0xe3 0x89 0xbb
0x92 0xa5 0xb9 0x1f 0x42 0xd4 0x89 0xd3 0xba 0x23 0x84 0x81 0x58 0x98 0x4e 0x0a
0xed 0x14 0xcf 0x7a 0x42 0xa8 0xaa 0x0f 0xc0 0x16 0xa3 0x97 0x1b 0x8b 0xf4 0x50
0x83 0x35 0x8a 0xf9 0xaf 0x2e 0xb9 0xe3 0x69 0x72 0x3e 0xb1 0x54 0x1c 0xf3 0x6f
0xcc 0x1c 0xb9 0x34 0x06 0xf3 0xd3 0x67 0x78 0xd3 0xfb 0xdf 0x27 0xe9 0x4f 0xa9
0x8c 0xde 0x67 0xec 0x0d 0xa2 0x8d 0xb9 0xb8 0xcf 0xbe 0x21 0xd9 0x08 0xe6 0xb5
0x5a 0x00 0x07 0x8d 0xe1 0xe1 0x1a 0x4a 0xb8 0x7e 0x76 0xfc 0x49 0x68 0x7a 0xf9
0xc7 0xa6 0x99 0xeb 0xff 0x6f 0xd9 0xf6 0x10 0x78 0x55 0xc2 0x4b 0x6a 0x05 0xa3
0xb1 0x3d 0xce 0x55 0x41 0x8d 0x9c 0x3d 0x18 0xa7 0x90 0x37 0x60 0x90 0x6b 0x60
0xad 0x4c 0x20 0xcd 0x12 0x5c 0x53 0x54 0xff 0x39 0x65 0xff 0xfc 0x0f 0x31 0x80
0x9b 0x58 0xc3 0x7c 0xbe 0x09 0xf7 0x8e 0x67 0x60 0x39 0x4b 0x29 0xdf 0xcf 0x57
0x4a 0x6b 0xf5 0xe4 0xd3 0x5d 0x68 0x45 0xa0 0x87 0x06 0xde 0x05 0x7d 0x00 0xd2
0x3a 0x1a 0x86 0x01 0xbf 0x99 0x29 0x11 0x7f 0xf8 0x56 0x90 0x1f 0xd7 0xfd 0xe5
0x1c 0xd8 0xf6 0x95 0x4e 0xc2 0xfb 0x1f 0x93 0x2d 0x50 0x15 0xa6 0x1b 0x00 0x55
0x94 0x32 0xc6 0x47 0x9f 0xee 0xb5 0xae 0xb8 0x31 0xfc 0x9b 0xe1 0x76 0xd2 0x28
0xf3 0xf3 0xf5 0xbb 0x34 0x48 0x13 0xcb 0x54 0x25 0x0f 0x7b 0xa8 0xd1 0xa7 0x6b
0xcc 0x14 0x5b 0x8e 0xf4 0x43 0x6a 0x80 0x1d 0xad 0x43 0x57 0x90 0x86 0x7b 0x04
0x31 0x1e 0x78 0x88 0xdd 0x5d 0xd9 0xa3 0x02 0x4b 0xdd 0xdf 0x2b 0x95 0x92 0xa3
0xad 0x79 0x47 0xc1 0x34 0x3f 0xb2 0x01 0x89 0x05 0x2d 0x26 0xc4 0x75 0x34 0xaa
0x25 0xb2 0x54 0x2d 0xf1 0x92 0xea 0x9b 0xe7 0x9a 0x38 0xba 0x91 0x65 0x40 0x2e
0xff 0x2b 0x31 0x1d 0xd9 0xaa 0x6e 0x19 0xca 0x49 0xc3 0xda 0x40 0xa1 0x71 0x11
0x98 0xb4 0x02 0xe8 0x16 0xaf 0x51 0x72 0xe9 0xf2 0xf3 0x11 0x6d 0xf6 0x21 0x0d
0x1a 0xb5 0xbe 0xe0 0xbe 0x28 0x54 0xb2 0xb9 0x7c 0xf4 0xf0 0x94 0x32 0xa6 0xdd
0x43 0x94 0x96 0xa9 0x55 0x5a 0x8a 0x96 0x44 0x06 0x30 0x3c 0x74 0x39 0x33 0x01
0x1d 0x29 0x7f 0x0a 0xfd 0xe2 0x65 0x3c 0xf5 0x6b 0xee 0xef 0xa5 0xd6 0x15 0x57
0x93 0xca 0xde 0x46 0xee 0x93 0xb0 0x4b 0x32 0xfb 0xd4 0x6e 0xb4 0xa6 0xd7 0x77
0x40 0x64 0x08 0xd2 0x0e 0x57 0x51 0x5c 0xc9 0x2b 0x9b 0x17 0xcb 0x19 0x1f 0x03
0x23 0xcc 0x99 0x3c 0xfa 0x3d 0x21 0xe1 0x6c 0x83 0x1c 0xce 0x68 0x38 0xff 0x0d
0x53 0xcd 0xdd 0xd3 0xd1 0x78 0x6e 0x1e 0xee 0x01 0xe7 0x71 0x0b 0xab 0xd7 0x55
0x6c 0xbd 0x5b 0xac 0x47 0x2c 0x9f 0x23 0xf2 0xf2 0x27 0x1f 0xb3 0x26 0xd8 0x66
0xa6 0x30 0xb8 0x31 0x5e 0x50 0x35 0xba 0x65 0x9f 0x73 0xae 0x66 0x43 0x87 0x46
0x60 0x79 0x3a 0x29 0x21 0x85 0x9a 0xd9 0xcc 0x7d 0x57 0x13 0x9c 0xfc 0x8f 0xb5
0x98 0x3f 0x7c 0x38 0x4b 0x9f 0x43 0x02 0x8b 0xa0 0x2c 0x40 0x32 0x3b 0x7a 0x2e
0x61 0x5f 0xaf 0x91 0xf3 0x26 0x39 0xf0 0xc5 0x73 0xd0 0x2e 0x00 0x44 0x70 0xc3
0xca 0xdf 0xc6 0x73 0x5f 0x6b 0xd3 0xa5 0x3b 0x24 0xdd 0xd0 0x95 0x20 0x61 0x75
0x25 0xbd 0x30 0xb0 0x5b 0xe8 0xd2 0xe6 0xdd 0x02 0xea 0xc1 0x6f 0x91 0xaf 0xbe
0xb6 0x94 0xf6 0xd7 0x9d 0x5e 0xee 0x1d 0xa5 0x76 0x6c 0x22 0xb7 0x42 0x9b 0xa2
0x9a 0x35 0xfe 0xa4 0xb1 0xcb 0x4b 0xcc 0xb7 0xda 0x2f 0x86 0xd0 0x6a 0x6f 0x85
0x9c 0x7c 0xd5 0xae 0xa5 0x46 0xf0 0x06 0x03 0x23 0x51 0xcb 0xe7 0x7d 0xe4 0xbb
0xeb 0x2b 0x51 0xd6 0x9d 0xb2 0xd9 0x09 0xfe 0xec 0x66 0x43 0x71 0x8d 0x53 0x92
0x6e 0x9f 0xb9 0x1c 0x44 0x2b 0x5e 0xfb 0xe8 0x2a 0x2a 0xbb 0x91 0x48 0xdd 0x14
0x06 0x07 0x99 0xb4 0x88 0x86 0x1d 0xb5 0x37 0xf3 0xeb 0xdd 0xf3 0xfa 0x53 0xbb
0xd1 0xfb 0x6b 0xab 0x23 0x4d 0x30 0x7c 0x92 0x56 0x3e 0x18 0xee 0x19 0xff 0x19
0x26 0x55 0xa6 0x65 0xba 0x6f 0x84 0xc0 0x3a 0xd9 0x25 0x0e 0xf9 0x98 0x3e 0x32
0xd4 0xb8 0x77 0xf5 0x7b 0x55 0xdb 0x1e 0xad 0x42 0x36 0x39 0xb6 0x1e 0x51 0xff
0xef 0x60 0x14 0x2e 0xa1 0x8f 0xd2 0x20 0x0c 0x1e 0xf5 0x3e 0x02 0x47 This completes the communication.

@_date: 1995-12-03 05:33:05
@_author: Hal 
@_subject: towards a theory of reputation 
Sorry to be so late picking up this thread, but I was very busy this past
"Reputation" is a fairly broad concept.  It generally refers to our
expectations of how some person will behave in various circumstances.  To
some extent, every character trait can have a reputation associated with
it.  A person can have a reputation for honesty, for efficiency, for
steadiness, for accuracy, and so on.  Even looking at it solely from the
point of view of a consumer choosing a service provider, any or all of
these traits might be important depending on the situation.  If I need
the work done right away, I will choose a supplier with a reputation for
speed.  If I want to be sure it is right and doesn't have to be redone, I
will chose one with a reputation for care and accuracy, and so on.
I don't think the notion of a graph showing utility (an overall summing
up of value to me) versus cost really captures this notion.  Such a graph
is useful and adequate for some forms of economic analysis where certain
simplifying assumptions are made, but I don't think it will work in this
case.  One of the big issues we would want to analyze is the impact of
various sets of rules and conventions for how trades occur.  The question
is how trust could be established, or how trade could occur in its
absence, given the possibility of avoiding retribution for dishonest
behavior that anonymous communication allows.  In this analysis we are
going to need more information than just utility vs price.  We will need
to separate out those various factors which go to make up the utility.
Changing the market conventions (say, by introducing escrow agencies)
will change the weightings of the various factors that make up
utility.  If I no longer have to trust the honesty of the person I am
trading with (because we have an escrow agency to help us make the
exchange) then the importance of his reputation for honesty goes down.
The result is that the "reputation" curves will change rather
dynamically and unpredictably as we consider different possible
structures in the market.  This will make the analysis of them
intractable, I would think.
As I wrote before, it makes more sense to me to focus explicitly on the
issue of trust and honesty, since those seem to be the main issues which
are going to take on more importance in an anonymous market.  Yes, they
are important in already existing markets, too, and there are plenty of
fly by night, hole in the wall companies which exist solely to do
business dishonestly and then evade retribution.  But the ease of doing
these things could increase in an anonymous market.
The other fact that makes trustworthiness more important in such a
market is the cost it applies.  One of the potential benefits of
anonymity is privacy.  To establish trust by keeping a steady pseudonym
(as was suggested earlier, a trade name or brand name performs this
function even as companies and personnel change out from under it)
means giving up a certain level of privacy.  Even if the trade name is
controlled pseudonymously, the linkability of its transactions
represents a form of exposure which can be seen as a cost.  If the only
way to be successful in business is to give up some of the privacy that
anonymity would provide by working through a consistent pseudonym, that
would be an interesting result.  Again, the issue is primarily one of
trustworthiness, as I see it.
I do think the idea of analyzing costs in terms of "throwing away your
reputation" by cheating and starting anew is an interesting approach.
The question is whether you can really quantify the value of a
reputation.  I know in business now corporations do carry on their books
something called "good will" which I believe is roughly the value of
their good name and trade marks.  However it is not normally considered
to be a major asset, I think.

@_date: 1995-12-03 11:53:38
@_author: Hal 
@_subject: Questions/Comments on ecash protocol 
I was also reading it, and I share some of Ian's questions, but for some
things I have a few different guesses.
One rather cryptic sentence, which Ian alludes to later, relates to
cancelling payments:  "The 'payer_hash' is the one-way image of a by
the payer generated random number...".  In the diagram it shows it as
f(payer_code), where payer_code is shown as "random code generated by
player".  (And, as Ian points out later, the document inconsistently
says that "the player generated random number" should be kept secret
while requiring that it be sent to the shop - at least, this is
inconsistent if it refers to payer_code.)  Assuming the use of the word
"a" is not a typo but refers to some number, this suggests that f() is
at least potentially a two-input function, some value a and a player
generated random number.
It seems that the whole payment_hdr is sent to the shop, and only the
portion before the line is sent to the bank.  This is enough, as you say,
to calculate the payment hash, so the bank can decrypt the coins.  This
prevents the shop from changing any of the information in that first part
of the payment header before sending it to the bank.
My question in this part relates to coins made out to " which we have
been told can be deposited by anyone.  How does the bank know to which
account to deposit such a coin, given a deposit message?  The shop's ID
does not seem to be present in such a message, assuming that the
shop_accID field of the payment_hdr just has " in that case.  Is it the
userid field in the userhdr message which tells the bank this info?
BTW since apparently both deposit and payment messages are not encrypted,
coins made out to " are in danger of being stolen both while en route
from customer to shop and from shop to bank.  This is significant from
the point of view of payee anonymous systems, which will need to use such
coins.  More encryption will be necessary when such coins are passed
Well, I would think identification of the payer's bank will be
necessary for any coin based system so you know where to cash in the
coins, so I don't think this is going to go away.  Of course as of now
everyone has the same bank so it is not an issue.
The signatures are xor'd with the payment hash, but this is not the main
way they are encrypted - they are then encrypted with the bank's public
key.  The purpose of this xor is not so much to protect the coins as to
bind them unbreakably to the payment header.  Since the coins are always
sent around with that payment header I think they all do use the same
payment hash.
I was wondering about this too.  There is a reblocking problem in
trying to concatentate "pure RSA" operations.  In particular M must be
at least as big as N.  This is not necessarily a problem, but it is a
slightly unusual constraint on key creation.  However I agree overall
that this formula is a reasonable reading of the doc.
There also needs to be some clause for the " payee.  In that case I
think the payment is accepted if the signature checks, with credit to the
userID account.
That business about cancelling via payer_code I agree is not very
sensible.  It doesn't seem necessary - the coin can just be re-spent,
made out to someone else.
There is no such thing!  This is one of the most common misconceptions.
This version of ecash does not trace double spenders.  It prevents double
spending by checking each coin to make sure it has not already been
spent.  Tracing of double spending is only necessary in offline systems
where coins are not checked right away, but that is not present here.
My guess is there would need to be some manual intervention to do this.
Well, as I said, I think this payer_code business is pretty questionable.
I'm sure the next version of the doc will clear that up a great deal.  As
far as determining r, that is not possible from the protocol messages.
Chaum has proven that it is absolutely indeterminate.  So I don't
understand what you mean about "more security has to be added to the
present ecash system if unblinded withdrawals are allowed."  Do you just
mean that the coin messages should not be sent in the clear in that case?
I observed that coin withdrawal messages can be sent in the clear in some
postings I made last year - the use of r effectively encrypts them.  But
of course that can't be done with unblinded messages.
There have been claims that the long string you type in at startup time
deterministically seeds the RNG, so that if you lose your wallet but you
tell DigiCash this string (via some secure channel, presumably) they can
reconstruct the coins you should have.  Presumably they could figure out
what the r values were when you withdrew all your coins, reconstruct the
coin numbers, and see which ones haven't been spent.  This is both good
and bad, in that it provides a well understood amount of entropy (rather
than relying on whatever it can scrounge up), but of course is vulnerable
to lazy typing.  Also, you have to write down the string, and if someone
found this they could perhaps get your coins.
Very good comments.  I'm sure the next version will be much better if
they are careful to clear up the kinds of issues you have raised.

@_date: 1995-12-03 12:22:18
@_author: Hal 
@_subject: Info on Netscape's key escrow position 
I will join the chorus of criticism:
I don't understand this.  What is the better solution?  No other solution
seems to be discussed by Clark.  Most of his message is devoted to
rationalizing the inevitable changeover to key escrow, which he just
dismissed as unacceptable.
This isn't true!  The US government (and I believe most other Western
governments, France excepted) does not presently provide any
restrictions on providing products to US citizens which have strong
cryptography.  There are serious constitutional questions about whether
it could ever do so.  Clark's message seems to be based on the
assumption that legal restrictions on crypto are a fait accompli.
Nothing could be further from the case.  What makes me mad is that his
messages seems to promote an attitude which could increase the
likelihood of these kinds of restrictions.  If people think the battle
is already lost, they will be less likely to fight.  IMO this is going
to be a big, knockdown fight and the eventual outcome is far from
Again Clark is preaching acquiescence.  We have no say in the matter.
Our phones can be tapped any time the FBI wants.  What is the relevance
of this to the issue of network communications privacy?  Doesn't this
again sound like a justification for giving up the battle before it is
joined?  Where is his righteous indignation?  Where is the recognition
that the right to tap communications is not granted by God but an
accident of technology, one which can be taken away by technological
progress as easily as it was granted?
False!  I can open a company today in this country and take exactly that
position, and the US government will NOT put me out of business.  What
country is Clark living in?
As I wrote in another context, when a question is framed in terms of
conflicts between the rights of governments and citizens, it is based on
a totally misguided premise.  There are no conflicts between the rights
of governments and citizens in our country.  The only rights are those of
citizens.  The real issue is the conflict between the rights of the
citizens to privacy and freedom versus their right to security and
safety.  I think we all know what Ben Franklin had to say about that.
Again Clark attempts to anticipate the advent of a totalitarian style
system of controls on access to cryptography in this country.  Should we
really base our policies on the assumption that this will actually
happen?  Will the American people stand by for such an unprecedented
invasion of privacy?
Some governments are capable of all kinds of evil restrictions on
products.  Is Netscape committed to building in provisions so that their
software won't access sites owned by Jews, so they can sell in Arab
countries?  Obviously they will draw a line somewhere.  I urge them to
consider the moral issues involved in endorsing Big Brother GAK systems
before accepting them as just another cost of doing business.
I am afraid that what the companies really want is global consistency.
That way they can use one set of policies for all countries, and no one
company can get a competitive advantage over others by producing stronger
privacy protections, because they will be forbidden by law to do so.
Whether the policies protect freedom and privacy or not is not really
relevant from this view.
If this is the way things develop, I predict that it will not be
acceptable to the general public.  Netscape more than anyone has seen
how much pressure can be brought through a public perception of weak
software security.  Our own brute force key hacks as well as the RNG
seed problems have well demonstrated that.  Do you think the same thing
won't happen, only far worse, if the government tries to force weak
software down people's throats?
I understand that Jeff has stated that Netscape is actually opposed to
GAK.  It would have been nicer to hear that from Jim Clark, in
unequivocal terms.  The overall tone of his message, as I have pointed
out above, is one of accommodation and compromise with government
restrictions on the rights of free citizens to communicate securely.
He almost seems to think that free strong crypto is already illegal.  I
think he needs to take a good hard look around and remember that he is
still a free citizen of the United States.  My guess is that he has
spent too much time in the company of law enforcement people.  He had
better start trying to understand the grass roots members of his market
if he wants to continue to succeed.
Hal Finney
hfinney at shell.portal.com

@_date: 1995-12-05 12:29:11
@_author: Hal 
@_subject: towards a theory of reputation 
By the "utility function" I was referring to Wei's model in which each
person has an idea of how much "utility" (a general summation of
personal value and usefulness) they would get from another person, as a
function of cost.  The utility function takes cost as input and returns
"utiles" (or whatever) as output.  So, with this model, using an escrow
agent would change the utility function; for a given cost, the utility
of a person to me would change (say, if the person involved were
thought to be dishonest, then the presence of escrow agents would make
him more useful to me).  The utility function in Wei's model is a curve
where the Y axis is utility and the X axis is cost.  Changing the
importance of honesty will change the position and shape of this
I think it would be more tractable to have a model in which honesty
played an explicit part.  We might even make assumptions about the
mathematical relationship between honesty and overall utility - for
example, that utility to me would be monotonically increasing with
increased honesty of the other guy.
What I mean is something like this.  Let t be the degree of trust
necessary for a business relationship to be consummated.  For t=0, no
trust is needed, and the relationship is such that neither party takes
any significant risk - a cash sale, perhaps.  For t=1, in some sense
total trust is needed, and a party can cheat the other with 100% safety.
Now let h(t) be the honesty reputation of a person, so that the utility
which people expect to receive from them gets multiplied by h(t).  For a
person with a repuation for honesty, h(t) is close to 1 for all t.  For a
person who seems dishonest, h(t) will go from 1 to 0 as t goes from 0 to
This is all pretty hand-wavy, but the idea would be to come up with good
strategies to estimate h(t) from a person's behavior, and good ways to
choose what kind of behavior one should follow given the value(s) of t
which are prevalent in the market.  This kind of analysis would lead you
to focus on the importance of the amount of trust needed in a transaction.
The underlying utility function is based on such traditional factors as
productivity and reliability.  It won't change as we consider the
variables of our analysis, because we have factored out the honesty and
trust issues so that they are more explicit.  That's the kind of
direction I was suggesting.

@_date: 1995-12-07 10:03:05
@_author: Hal 
@_subject: Still more on the Digicash protocol 
There might be some situations where it is useful to send a wildcard
coin even via a TCP connection.  For example, a pseudonymous server
might pop up at some internet address different from its real one, make
some transactions, and then go away.  Or someone might set up an
anonymous account at some public server (like c2.org) and conduct
business anonymously on an ongoing basis.  In either case the payee
would be anonymous to the payor even though they communicated via TCP.
The shop would have to send its payment request using " as the
shop_accID field (I have heard of an undocumented "-X " switch
in the Unix ecash program which allows the shop software to control
this field in the payment request).
We have also discussed the "pipe-net" which would allow anonymous TCP
connections.  This does not look like it can be as secure as the remailer
net but for occasional or short-term use it can provide considerable
privacy protection.
I am glad that DigiCash supports this type of cash which anyone can
deposit.  Actually, I am surprised and puzzled that it does, given
Chaum's apparent reluctance to endorse schemes to allow payee anonymity
(due to political problems, apparently).  It would be interesting to hear
how DigiCash envisions this feature being used, and whether they plan to
continue to allow it.  Since it is not well documented (if at all) it's
possible that they don't plan to keep it.
But if they do, I think it would be good to adapt the protocols so this
feature is usable over TCP connections.

@_date: 1995-12-13 11:13:07
@_author: Hal 
@_subject: Time-based cryptanalysis: How to defeat it? 
I posted a similar idea on sci.crypt, but later I realized that Paul Kocher
is right.
Your algorithm works OK for the first iteration.  The amount of work is
pretty much constant regardless of whether bit 0 of x is 0 or 1.
However, at the end of that iteration R_1 will have one of two
different values depending on that bit 0 value.  And, the attacker can
know these two values, and if he controls y he can even choose them
(they will be either y or 1).
Now, on the next iteration, the time it takes will be different
depending on bit 0 of x.  It won't depend on the bit 1 value, but
different bit 0 values will cause R_1 to be different.  So the time of
this iteration will depend on the value of the bit used in the previous
iteration, and likewise for the following iterations.
If the attacker can choose y, he can arrange that the two different R_1
values will take different times on average for the rest of the
calculation.  So he finds out bit 0 as before, and from there he can go
on and find the other bits.

@_date: 1995-12-14 00:10:22
@_author: Hal 
@_subject: Blinding against Kocher's timing attacks 
I don't think it would.  Chaum's blinding protocol has one major
difference: the blinding factor is applied by a different person than
the one doing the signing.  The purpose of the blinding is different,
too; in Chaum's case the idea is to end up with a signature which is
unknown to the signer, while with Kocher's "defensive blinding" the
signature (or decryption) is an ordinary RSA one, and the blinding is
just done internally by the signer to randomize the timing.
(I gather BTW that the idea of the blinding is for the server to have
pre-chosen a random r and pre-calculated r^d mod n, and then when he is
given c to decrypt he first does c*r mod n and then decrypts this, then
takes the result and divides by r^d.)
It's conceivable that Kocher's blinding would be a patentable technique
in itself, and not impossible that he has already applied for a patent
before publishing.  Probably he would have said so if that were his
intention, though.
"Blind defensively - watch out for the other guy..."

@_date: 1995-12-14 14:02:29
@_author: Hal 
@_subject: Timing attack against RSA 
Here is how I gather the timing attack against RSA decryption would
work.  This is the chosen-ciphertext attack of Paul Kocher's.
You know n, the public modulus; suppose it is 512 bits.  You want to
know p and q, its prime factors.  You know the details of the server's
implementation of RSA.  The server will do a decryption of the RSA
message you send it, and give you some reply shortly after it is
You are going to send it bogus messages.  Normally, most random
messages will encrypt under RSA to numbers of about 512 bits, but you will
send it ciphertext which is about 256 bits long.  You are going to try
to figure out the value of p.
The server's algorithm is to take the ciphertext c, and first do:
cp = c mod p
cq = c mod q
It will then do two modular exponentiations, mod p and mod q, and do a
few more calculations, then return some result to you.
The attack is to try to choose c to be about the same size as p, with the
assumption being that if c is a bit less than p then c mod p will be fast
since it doesn't have to do anything, while if c is somewhat larger than
p then c mod p will be a little slower, since it will have to at least
subtract p from c.  Paul Kocher has measured this timing difference as 17
microseconds on one particular implementation.
This is not going to be an easy time difference to measure.  In
addition to doing the c mod p step, the algorithm also does all those
other things:  the c mod q, the two RSA calculations, as well as
whatever overhead is involved in the server's operation and the
communication link.  The variations due to the RSA calculations
themselves will have a standard deviation of about 250 microseconds,
based on Paul's numbers (higher than his reported value because two
exponentiations are done, plus some other work).  So this is a minimum
amount of "noise" we must try to see through even if everything else is
instantaneous.  This might be the situation in the case of a hardwware
token which is doing RSA decryptions with a secret key.
The first step will be to try to determine the length of p.  For this
we will send in c values which are around 256 bits long.  We might
start with some 250 bit values and some 260 bit values, hoping that p
is in that range.  We do a whole lot of these, and we take the average
time for them.  If p is between 250 and 260 bits long, then the 260 bit
values should take at least 17 microseconds more time to calculate on
the average than the 250 bit values.
One interesting question is how many samples we would have to take in
order to detect this difference.  One way to consider it is to ask,
given that the samples have a standard deviation of about 250
microseconds, how many samples do we have to take to reliably estimate
the mean within an accuracy of about 10 microseconds, or 1/25 of a
standard deviation?
According to my limited knowledge of statistics, if we want to be right
about 90% or 95% of the time, we need to have sqrt(number-of-samples) *
1/25 be > 3, or number-of-samples should be about 5000.  (Take this
with a large grain of salt!)  So we will have to do some thousands of
samples in order to average out the noise and get our mean this
accurate, with good confidence.
Once we have done these tests, we have determined that p is between our
two values.  Now we can sub-divide the interval and poll with values
which are, say, 255 bits long.  Again, we would have to do enough polls
to determine the true mean time to within about 10 microseconds.
After we repeat this three or four times, we will know the bit length
of p; in effect, we know its first bit.  Now we can continue the
divide and bracket procedure.  Each time, we must poll many times with
c values whose most significant bits are halfway between the two
bracketing values which we know contain p.  Each such sequence of about
5000 polls yields us one more bit of p.
We repeat this about 250 times, and we will have p, from which we can
derive q, and we have broken the RSA key.  So, taking the estimate
above of 5000 or so samples to get a bit of p, we will have to do about
a million tests total to find p.  (BTW, in Paul's implementation it
took about 1/3 second to do a decryption, so you're looking at about
100 days of solid work to do the job.)
This algorithm has some self-correcting features but it is not
completely so.  Suppose p's first bits are actually 1011.  We have
determined that it is between 1000 and 1100, and we want the 3rd bit.
We poll with values which start with 1010, and (since with 90% accuracy
we are wrong 10% of the time) we mistakenly conclude that the mean is
the higher value, hence that p is less than 1010 and must start as
100X.  We continue the procedure, and we will find that our new middle
values are consistently less than p, so we gradually work out our
estimate as 10011111...  Eventually this train of 1's might persuade us
that we may have made a mistake back there, so we would go back and
poll again to try to verify our earlier results.  (Of course, if
another mistake happens during the 1's that will confuse us further...)
Doing the attack across a network will be much more difficult because
there will be a lot more variation in the turnaround time.  This will
have the effect of increasing the standard deviation far above a
quarter millisecond, up by probably at least an order of magnitude if
not two or more.  Now we have to estimate a mean to within not 1/25,
but maybe 1/1000 of a standard deviation, or worse.  This would
increase the total number of samples necessary from a million up to the
level of billions or trillions.
One final note: two cases to which we might want to apply this would be
Netscape's SSL as implemented by its secure servers, and DigiCash's
bank software.  (I know Lucky said that DigiCash is immune to this
attack, but maybe we would want to test it to see.) In either case,
since we are sending a bogus 256 bit value, the data which decrypts
will not be valid.  In the case of SSL we will probably get an error
packet or maybe a broken connection to tell us when it has finished the
decryption.  In the case of DigiCash, it does not need to do anything
with the value it signs other than return it, so we will probably get a
return packet.  However, it is not valid cash.  In order to convince
DigiCash to send us this packet, it has to have deducted something from
our account, at least a penny.  If it takes a billion connections to do
the attack (which I think is an underestimate, corresponding to about a
10 millisecond standard deviation on the timing values), that will cost
10 million dollars.  So you better have pretty deep pockets to think
about mounting this attack in that case.  For SSL, misses don't cost you
anything, so maybe it would be worth trying, if you have a good,
low-latency connection and a server with a light load.  The full attack
would take too long but just determining the length of p would be quite a
Actually of course you would have to do some more research before
mounting this attack; specifically, you'd want to know more about the
timing of the software so you could estimate the costs of the mod p
operation you are trying to catch.  If the number ends up being much less
than 17 microseconds the attack gets that much harder.

@_date: 1995-12-16 00:29:40
@_author: Hal 
@_subject: kocher's timing attack 
As Kocher's paper implies, the known ciphertext attack is a TIMING
attack.  Simply accumulating known text/signature pairs as you would have
after a "key signing party" does not help.  You must know exactly how
much time each signature took.

@_date: 1995-12-16 02:01:58
@_author: Hal 
@_subject: Kocher's RSA attack 
This is not enough - Paul Kocher's attack depends on the individual
modular multiplies taking different times.  (Actually, that is for his
attack on Diffie Hellman.  The RSA CRT decryption attack uses a
completely different principle, but I guess we are ignoring that for
now.)  The fact that timing a modular exponentiation would give
information about the density of 1 bits in the exponent is not
particularly new or surprising, as has been mentioned here.  What is
new is that you can actually figure out the specific exponent value.
But that requires variable-timing modmult, not just variable-timing
PGP is somewhat unique in having a multiplicity of modmult algorithms
which can be selected at compile time.  I am not sure which of these
might be variable time and which might be fixed.  The most likely place
for time variation IMO is in the modular reduction rather than the
multiply; the multiply is generally deterministic with no variation due
to data values (although as was pointed out here, on some processors a
hardware multiply instruction may take variable time depending on its
inputs).  Some modular reductions involve trial division to some extent
or other, with different numbers of iterations possible depending on
certain (maybe unusual) values.  However I believe at least one of the
PGP modular reductions consists of multiplying by the reciprocal of the
modulus, followed by a fixed shift, and this one should be constant time
on a machine which has constant-time multiplies and shifts.  (This is
just going from memory, I haven't looked at the algorithm in several

@_date: 1995-12-19 17:30:30
@_author: Hal 
@_subject: E-cash coin questions (Mark Twain / Digicash) 
I don't know this offhand, but I assume it is at least 2^64.
It is not possible for the bank to have a list of the serial numbers on
coins produced, since it doesn't know this information.  Each coin is
created by a user's client software, which chooses the serial number at
random.  When it is sent to the bank to be signed, the serial number is
blinded by being multiplied by a random number, which is divided off
after the client gets it back from the bank.  So the bank never sees a
coin's serial number until it is deposited.
It is easy to make this number so large that it will take longer than the
age of the universe for this to happen.  It just takes a dozen or so
bytes per coin.
Assuming the serial numbers are of the sizes I suggest above, this
chance is so close to zero that your chances of being named King of the
Earth next year (along with the assumption that we switch to a World
Government and it is a monarchy) are much greater.
I don't fully understand what you are getting at, but there are several
false assumptions here.  The "coin" has several parts, one of which is an
RSA signed portion with a number in it, for which I am accepting your
terminology of it being a "serial number".  This terminology is not quite
right, as the coins are not numbered serially (that is, sequentially, 1,
2, 3, etc.), rather the numbers are random.  But it does capture the
essential idea that each coin's number is unique.
You do know the record layout of each coin, but that is because it is
documented and because your client creates coins, not because you could
decrypt it with the bank's public key.  The coin does not have the bank
name field within the RSA signed part.  There is other information
which goes along with the coin, including an identifier for the bank,
outside the RSA signed portion.
For the general question of whether inspection of a lot of RSA-signed
coins would allow you to deduce the private key, the answer is no, as
far as is known.  Actually the attack you can mount is stronger than
this; you can get the bank to RSA sign any number.  You could ask it to
sign "1", for example, and you will get "1" back (so that's not very
useful).  I have tried to think of a way of getting some useful
information from getting it to sign "2", since that is such a simple
number.  But it is raised to a very large power, and as far as I can
see what you will get back is just a random looking number, with all
hints about the exponent gone.
Again, as far as anyone knows, there is no way to break RSA using these
kinds of attacks, at least not any more cheaply than factoring the modulus.

@_date: 1995-12-20 09:21:19
@_author: Hal 
@_subject: King Kong Does e$ 
Thanks to Bob Hettinga for typing that long message about the Microsoft
"ecash" scheme.  That is some nimble note-taking.  I have a few comments
on the scheme as Bob presented it, and as it compares to Digicash.  I
will follow up with some commentary about the politics involved.
The withdrawal protocol has some similarities to online Digicash ecash.
In that system, you choose a random number s, calculate a one way
function h(s), and get that signed by the bank.  Unlike in the Microsoft
scheme, blinding is used for the signature.  I imagine Microsoft avoids
blinding because of the patent situation, and possibly due to legal
concerns about anonymity (more on this below).  With Digicash, the coin
is then the pair s, SIGN(h(s)).  This is then given to the shop as
payment.  It can check the bank's signature, but that is not enough;
being an online scheme, it must also turn the coin in at the bank to
prevent double spending.  The bank checks the signature and that the coin
is well formed to accept it.
The Microsoft scheme is like an unblinded version of this.  The bank
simply signs h(s) and gives that to the customer.  This allows a
simplification in the spending.  Instead of passing s, SIGN(h(s)), it is
enough just to pass s.  The payee gives this to the bank (since this is
an online system), which given s can calculate h(s) and check this
against a list of all valid coins.  It knows the valid coin numbers
because it saw them when it signed them (unlike with Digicash).  So there
is a slight space savings in the spending protocol.
It is also not necessary for the messages to and from the bank to be
encrypted during the withdrawal protocol; neither knowing h(s) nor
SIGN(h(s)) will allow an attacker to spend the coin, since he doesn't
know s.  A similar thing is true of DigiCash, though, where the blinded
pre-signed or signed coins are useless to an attacker since he doesn't
know the blinding factor.
The big problem then with the Microsoft system is that it is not
anonymous.  As a result, it is technically not electronic cash, at
least as the word is used in the literature.  However we are seeing so
many proposals like this, all of them wanting to capitalize on this
magic word "cash", that I suppose the definition has to be considered
to be shifting.  In the new usage, virtually any payment system can be
called cash if there is some way that users can be anonymous in using
it.  And since by allowing anonymous accounts virtually any payment
system can do this, the word is becoming meaningless.
The problem I see in practice with using their cash anonymously is how to
buy it.  If I have an account with the Bank of Microsoft, and I withdraw
some "mcash", deducting it from my account balance, that mcash will be
linkable to my account when I spend it.  In order to be anonymous I have
to buy the cash anonymously.  I can walk into the local bank with a
floppy and some dollar bills, but that is not practical in general.  I
could use mcash to buy some more mcash, but even if the second
transaction is anonymous, the bank knows that I was the one who withdrew
the first set of mcash, so it can link me to the second set when it is
The only good solution I can see is to use Digicash ecash to anonymously
buy Microsoft mcash, but I doubt that that is what they had in mind!
Frankly, what I see in this message is another example of something which
is starting to become common: marketing to cypherpunks.  In a way it is a
very positive sign, that our views and concerns are becoming so well
known and widespread that companies like Microsoft and Netscape are doing
their best to keep on the good side of people like us, who are concerned
about strong privacy and security.  In some ways our attitudes are
becoming dominant on the net, thanks to the many excellent writers here,
as well as magazines like Wired, and groups like the EFF and other
interest groups.
But this influence is making us a target of companies who know that
gaining our approval, or at least avoiding our criticism, is important
for success on the net.  In many cases, such as the recent flap over
Netscape's attitudes towards key escrow, I detect a whiff of two
sidedness, in which one attitude is presented for the benefit of
government and law enforcement interests, while another posture, more
acceptable to cypherpunks, is adopted on the net.  With Microsoft, they
use the magic word "cash" a great deal, in my view hoping that we will
line up in favor of the idea.  But as I have explained it is not really
anonymous, no more so than any other payment system.  And it is not at
all clear that the kinds of anonymous accounts that would be necessary
to really make it anonymous will be allowed.  In that case, Microsoft
can just shrug and say, "well, we tried."  They get the best of both
worlds.  They make the government happy by providing a traceable
payment system, while they look good on the net by pushing "electronic
I don't have any proof that this is exactly what is going on.  But it is
possible, and I think we have to be skeptical and at least open to the
possibility that this kind of manipulation is occuring, no matter how
many assurances we get from the companies involved that they are really
on our side.  Finance is a high stakes business and there is a lot of
government regulation involved.  Where our interests and the government's
diverge, we need to watch closely to see whether the companies' actions
match their words.  This kind of marketing is going to continue to increase,
I expect.
Hal Finney

@_date: 1995-12-21 10:29:06
@_author: Hal 
@_subject: Bit Commitment Query 
For Robbie Gates, I agree that the bit commitment he describes seems
more complicated than necessary.  The simpler one, where you just hash
(R,b), is the one I have seen used.  I suggest asking on sci.crypt.
Bruce Schneier and many other good cryptographers read that group.
For Futplex, the idea of using a block encryption algorithm in a similar way, encrypting (R,b) with a secret key K, and later revealing
K, is a little questionable because block encryption algorithms are not
designed to avoid collisions in the same way hashes are.  Futplex
suggests that it should be hard to find two keys K_1 and K_2 such that
E_K_1(R, b1) = E_K_2(R, b2) where b1<>b2.  But this is not necessarily
true.  A cryptosystem might have the property, say, that complementing
the key is equivalent to complementing bit 0 of the plaintext.  DES has
some simple complementation properties (although not this one).  Unless
you can show that a cipher with this property is inherently weak then
it is not a valid assumption that a cipher won't have this property.
There is some literature on creating hash functions out of block ciphers.
The two are really not interchangeable.

@_date: 1995-12-29 15:37:40
@_author: Hal 
@_subject: blind validation 
Those are very interesting thoughts Alex Strasheim posted about
blind validations.  The issue of people handing out copies of their
validations ("credentials" is the term Chaum uses) can be significant.
Chaum's way around it was basically to have some mechanism to give
each person a unique number of some special form.  There doesn't have
to be any agency who knows what number each person has (in fact, there
isn't, in his scheme), but there is a mechanism to assure that one
person does not get two numbers.  This is sometimes loosely referred to
as an "is-a-person" credential (although in this specific context it is
not actually a credential, just an identifier).
One way to achieve the goal would be to make each person give a
thumbprint, or some other biometric identification, in exchange for
giving them the is-a-person credential.  Another way would be to use
conventional ID, making sure their credential is blinded.
Then, the blind validations are mathematically structured to be linked to
the identity number.  Only someone who has a specific identity number can
show a specific blind validation.
The idea here is that this addresses the copying-validation problem
because a person would not only have to give away the specific
validation, but also his identity number.  This would in effect let the
other person masquerade as the first, and any bad things he did would
come back to hurt the person who gave away the data.  You can't just walk
away as in a totally uncontrolled blind signature system because of the
linked nature of the credentials, and because you only get one identity
So the result in effect is to make it difficult to give away just a
validation, without also giving away the ability to act as you.  Here
is an idea about another way to achieve the same thing, closer to
Alex's example:  Alice gets a blind validation as Alex describes based
on a simple blind signature.  (Alice hands a blinded number to Bob, he
signs it, Alice unblinds it, and uses the resulting signed number as
the validation to, say, access Bob's files.)  We add that Alice puts,
say, $100 into "escrow", encrypting it with the secret number and
putting it on some public server.  She proves to Bob that she has done
this using cut and choose.
Now if Alice gives away her secret number, anyone using it will be able
to access Bob's files, but they can also get the $100.  So now it costs
something for Alice to give away her secret.
(There are some major problems with this idea, the worst being that Alice
can extract and spend the $100 right after proving to Bob that she is
doing what she said, and before publishing her number.  Maybe someone
could think of some fixes.)

@_date: 1995-02-01 18:13:38
@_author: Hal 
@_subject: Lucky primes & omlets on my face... 
This would only be true for prime p, but with RSA we are dealing with
composite moduli.  What we want is ed=1 mod phi(n), where
phi(n)=(p-1)(q-1).  (Actually you want to use (p-1)(q-1)/gcd((p-1),(q-1)).
I forget what that is called.)
Conceptually, I gather you are setting e = 0x10001, then finding its
multiplicative inverse d mod phi(n) (or mod p-1 in your example).  Then
you are looking for other possible values for d.  I am a little unclear
on what the interval would be between suitable values of d.  I think it
would be phi(n)/gcd as above, or p-1 in your example, but I am not sure.
I still don't follow this.  Is k claimed to be d?  Where do we verify
that ed=1 mod (p-1)?  ed would be n1, right?  When you said "If (n1-1)/i
+ 1 is prime" did you mean "is p"?  I really don't think this whole thing
Let me tell you what I tried.  I inverted e to get a correct d.  Then I
looked at different d's to find one with lots of 0's.  This turned out
to be useless!  The reasons is that PGP does not use d.  It uses the
Chinese Remainder Theorem to do its exponentiation.  The two
exponentiations it does use exponents d mod (p-1) and d mod (q-1).
Adding multiples of phi to d does not change these values (since it is
a multiple of both p-1 and q-1).
Now one thing you could do is to use in place of d mod (p-1),
(d mod (p-1)) + k*(p-1) where we choose k to minimize the sum of the number
of bits and the number of 1 bits in this expression.  Unfortunately the
PGP data structures do not store d mod (p-1), it is constructed on the
fly when you do a decryption.  So there is no where to save a
pre-computed optimal value for the two exponents used in the CRT
exponentiations.  So, this was a good idea, but the implementation does
not fit into the current structure very well.

@_date: 1995-02-01 23:14:37
@_author: Hal 
@_subject: Why encrypt intra-remailernet. 
[ Re: remailers checking signatures on incoming messages ]
She doesn't get that.  A signature lets her prove that she sent a
message.  It doesn't let her prove she didn't send a message.
I don't really understand this threat that Alice may be "spoofed".  Why,
of all places, would her opponents try to spoof her through an anonymous
remailer?  Isn't this kind of like sending mail with no return address,
and pretending it comes from someone else?  This seems terribly subtle.
This would be a good thing, agreed.  And requiring signatures probably
would weed out a lot of the flakes, largely by raising the threshold of
cluefulness needed to use the network.
This is not clear to me.  My hope would be to persuade the PGP developers
(many of whom read this list) to incorporate a pad feature in future
versions so that messages can be easily rounded up to a standard size.
Alternatively the mixmaster client may include this capability.
I can see the problem with standard packets in a chaining context, that
they would shrink slightly in size as each successive remailer stripped
off its envelope.  Re-encrypting would solve this by providing more
padding.  OTOH you can actually stick padding into a PGP packet if you
know what you're doing.  I have a perl script around somewhere which will
do this.
It is true that encrypting messages intra-remailer would prevent this
attack as far as that one remailer in the chain is concerned.  But it
seems to me that the message still suffers from this attack against the
remailer network as a whole.  This points up the fundamental problem with
this form of encrypted reply block.  They are really not secure unless
the body itself gets transformed at each step as in Chaum's model.
None of this is news.  We have been discussing these attacks for years.
Even with intra-remailer encryption I think these attacks work against
the remailer net.
This will work when the message is heading to the net in the clear, even
if it is encrypted between nodes.
You can still match the message entering and leaving the net, even if it
is encrypted within.
As above.
Encryption with padding between nodes would protect against size
matching, I agree.  But it is the padding which is important, not the
That's why Chaum identified one of the main features of a remailer being
that it would reject duplicates.  Mixmaster does some version of this,
although that needs improvement to really meet this attack.
OTOH, if Alice actually has signed those messages, her jig is up pretty
good, wouldn't you say?  Do we really want to force people to use the
nets in a mode in which they can be incriminated like this by a hostile
Hell, Detweiler has the power to do this!  He's spoofed messages plenty
of times.  How do we know?  Because of remailer logging.  That's the real
threat, IMO (the logging).
Even if a message comes from a fake address that is hardly evidence of an
attack by a powerful opponent.  It could just be an extra-paranoid
legitimate remailer user who doesn't want to extend any more trust than
I meant to refer to encrypted messages identical in size and otherwise
opaque, so that your apparent rate of output is constant.
I was referring specifically to the correlation attack described by Wei.
The other attacks you describe need to be met by the kinds of
countermeasures we have been discussing: standard-sized messages,
remailer chains, not using encrypted reply blocks which leave message
bodies alone, rejecting matching messages.  All of these were discussed
in Chaum's 1981 paper.
How can Bob arrange to receive a constant number of messages each tick?
Do all his messages come from one remailer?  Or do all of the remailers
which might send to him check among themselves before sending to him so
they can mutually know how many fake messages to send?
IMO the real solution to the correlation attack is to have a constant
message generation rate.  That is sufficient.  Solutions to the other
attacks mentioned in Chaum are described in Chaum.  (This attack was not
described in Chaum's paper.)
I'm not sure what you mean by "matching the top of the body of messages".
Are you referring to an encrypted reply block, which might be the same
for two different messages to the same user?  Or are you suggesting that
messages would have some headers or some other structures at their top
which would be preserved through a remailer?
If the input to Bob really can be made constant across the whole remailer
net then this does seem to largely protect against duplicate-message
insertion, in conjunction with the intra-remailer encryption.  However it
would apparently also be necessary for every remailer to send a constant
number of packets to every other remailer.  Otherwise a bolus of
duplicates into one remailer would all leave to go to the next remailer
at once and would show up.  This means that the net as a whole has to
carry a constant traffic load on all inter-node links, which could mean a
large cost in bandwidth load.  I still think that rejecting matching
messages is a better solution.
No, of course message size standardization is a necessary step.  This has
been recognized for 15 years.
OK, but chances are your average number of real packets per tick is < 1,
e.g. if a tick is a few hours and you only send one or two messages
a day.  So when you do need to send that 500KB GIF it's going to take a
lot of ticks.
I would sum up by agreeing with several points: the need for standard
message sizes, and for a standard rate of message output.  I am neutral
on whether a remailer may want to super-encrypt a message to the next
link in the chain (whether a remailer or an end user) if it happens to
have a key handy.  I don't see any harm in this and the remailer
software will already handle this transparently on the receiving end.
I disagree with the idea of remailers checking signatures.  I don't
agree that inter-node remailer encryption provides significantly more
protection than padding.  I think that encrypted reply blocks are
unsafe even with inter-node remailer encryption.  See Chaum's paper for
ways that encrypted reply blocks can be used safely.  We have also had
some suggestions here for modifications to Chaum's method.  And I don't
see how you can arrange to receive a constant load from the net without
a highly centralized system, which would have its own dangers.

@_date: 1995-02-02 08:49:39
@_author: Hal 
@_subject: Adding padding to PGP files 
Here are a couple of perl scripts I wrote last year to add padding to PGP
encrypted files.  The usage would be:
perl pgppadt.pl filename bytestoadd
The output file is filename.pad.
It only works on binary ".pgp" public-key encrypted files (not ascii armored
files).  So there would be some work needed to make it a really useful tool.
It would also be better to use a strong source of random numbers.  I
think Carl Ellison recently posted some tools that could help with this.
The two files are pgppad.pl, which does the work, and pgppadt.pl, a very
simple test driver to show how to use it.  They are in a shar archive.
---------------cut here----------------
# to extract, remove the header and type "sh filename"
if `test ! -s ./pgppad.pl`
echo "writing ./pgppad.pl"
cat > ./pgppad.pl << '\End\Of\Shar\'
# Perl module to allow padding and some other manipulation of PGP
# files.
# Include this with the statement:
# require 'pgppad.pl'
# 10/16/93
# Hal Finney
# Read a PGP Cipher Type Byte and the following length.
# One argument: file to read from
# Returns several things, in this order:
# CTB, with the length information removed, as a number.
# Length of following packet.
# Name of this kind of packet, made up, see list below.
# Packed CTB/length packet, suitable for writing out.
# Returns an empty string on error.
sub read_ctb {
    local($file) =     local($ctb, $length, $name, $rctb, $rlength, $lengthlength);
    if (read ($file, $rctb, 1) != 1) {		# Raw ctb
    }
    $ctb = unpack ("C", $rctb);
    if ($ctb < 128) {
    }
    $lengthlength = $ctb % 4;
    $ctb -= $lengthlength;
    if ($lengthlength == 0) {
    } elsif ($lengthlength == 1) {
    } elsif ($lengthlength == 2) {
    } else {
    }
    if (read ($file, $rlength, $lengthlength) != $lengthlength) {
    }
    if ($lengthlength==1) {
    } elsif ($lengthlength==2) {
    } elsif ($lengthlength==4) {
    }
    $rctb = pack ("C a".$lengthlength, $rctb, $rlength);  # Packed data
    if ($ctb==0x84) {
    } elsif ($ctb==0x88) {
    } elsif ($ctb==0x8c) {
    } elsif ($ctb==0x94) {
    } elsif ($ctb==0x98) {
    } elsif ($ctb==0xa0) {
    } elsif ($ctb==0xa4) {
    } elsif ($ctb==0xa8) {
    } elsif ($ctb==0xb0) {
    } elsif ($ctb==0xb4) {
    } elsif ($ctb==0xb8) {
    } else {
    }
    return ($ctb, $length, $name, $rctb);
# Write a CTB and length field out.
# 3 arguments: file handle, ctb value, and length in bytes.
# No return value.
# Length gets output as 1, 2, or 4 bytes, the smallest in which it
# will fit.
# If length is negative we output no length field, but an "indefinite
# length" code is added to ctb.
sub write_ctb {
    local($file, $ctb, $length) =     local($rctb);
    $ctb = $ctb - ($ctb % 4);	# Be sure 2 low bits are clear
    if ($length < 0) {
    } elsif ($length > 65535) {
    } elsif ($length > 255) {
    } else {
    }
    print $file $rctb;
# This entry point always outputs a 4-byte count.  Length must be > 0.
# Otherwise like write_ctb.
sub write_ctb_4 {
    local($file, $ctb, $length) =     local($rctb);
    $ctb = $ctb - ($ctb % 4);	# Be sure 2 low bits are clear
    if ($length < 0) {
    }
    $rctb = pack ("C N", $ctb+2, $length);  # Packed data
    print $file $rctb;
# Pad a PGP public-key-encrypted file to the specified length.
# Arguments: input file handle; output file handle; new size.
# Returns negative value on error.  See the code for what the
# different values mean.
# Returns 0 on success.
sub pgppad {
    local($infile, $outfile, $size) =     local($ctb, $length, $name, $rctb, $insize, $buf);
    # Read ctb & length of pubkey header
    ($ctb, $len, $name, $rctb) = &read_ctb($infile);
    if ($ctb == 0) {
    }
    if ($name ne "pubkey header") {
    }
    if ($len < 0) {
    }
    $insize = length($rctb) + $len;
    # Read packet of pubkey header
    if (read ($infile, $data, $len) != $len) {
    }
    # Write out pubkey header, unchanged
    &write_ctb($outfile, $ctb, $len);
    print $outfile $data;
    # Read ctb and length of conventional packet
    ($ctb, $len, $name, $rctb) = &read_ctb($infile);
    if ($ctb == 0) {
    }
    if ($name ne "conventional encrypted") {
    }
    # Calculate size of outgoing conventional packet.
    # Assume rctb won't change size; it may grow by 1 or 2 in some
    # rather rare cases, in which case we'll be a byte or two too big.
    $size -= $insize + length($rctb);
    if ($size < $len) {
    }
    # Output CTB with new length
    &write_ctb_4($outfile, $ctb, $size);
    # Copy remainder of input file
    while (read ($infile, $buf, 32768)) {
    }
    # Note that this random number generator is probably not
    # cryptographically strong.
    srand (time|$$);
    while ($len < $size) {
    }
    return 0;		# Success
1;	# Non-zero return for 'require'
  echo "will not over write ./pgppad.pl"
if `test ! -s ./pgppadt.pl`
echo "writing ./pgppadt.pl"
cat > ./pgppadt.pl << '\End\Of\Shar\'
# Test program for pgppad.pl, showing how to use it.
require 'pgppad.pl';
open (IN, $ARGV[0]) || die ("Couldn't open $ARGV[0]\n");
open (OUT, ">$ARGV[0].pad") || die ("Couldn't create $ARGV[0].pad\n");
$padding = $ARGV[1];
 = stat(IN);
$size = $stat[7];
print "Input file $ARGV[0] has size $size bytes\n";
print "Output file $ARGV[0].pad will have size ".$size+$padding." bytes\n";
if (($code = &pgppad (IN, OUT, $size+$padding)) < 0) {
    die ("pgppad returns code $code\n");
close (IN);
close (OUT);
print ("Done\n");
  echo "will not over write ./pgppadt.pl"
echo "Finished archive 1 of 1"

@_date: 1995-02-02 09:46:29
@_author: Hal 
@_subject: Remailer encryption module 
For those wishing to follow this debate, here is a URL for this document:
I had trouble finding it since the filename does not contain "mime" or

@_date: 1995-02-02 16:15:01
@_author: Hal 
@_subject: Remailing in safe-tcl 
Suppose someone runs safe-tcl to process incoming mail, and supports the
"delivery-time" mode, where incoming mail programs are executed as soon
as they arrive.  (Support for this mode doesn't really exist yet, but
I am putting together a simple script to enable it.)  Here then is an
example of how a self-remailing message might look:
[Other headers]
Content-ID: <2269.791623082.4 at cryo>
------- =_791623442
Content-ID: <2269.791623082.2 at cryo>
# Get the other sub-part of this message and send it to the desired address
SafeTcl_sendmessage -to hfinney at shell.portal.com \
        -subject {Remailed message} -body [SafeTcl_getbodyprop 1.2 all]
------- =_791623442
Content-ID: <2269.791623082.3 at cryo>
This is the body of the message, which will get remailed.  It could be
a PGP message if the server supported automatic decryption of incoming
PGP mail.  Then it could have nested remailing instructions in it.
------- =_791623442--
This is a MIME format message with two sub-parts.  The first is the
script which gets run on delivery, and the second is the "payload", the
message to be remailed.  The script is a simple one-liner which sends
the second subpart to my email address.
Safe-Tcl does allow (rather vaguely) for automatic decryption of incoming
mail, as well as authentication (so you might allow messages signed by
certain people to get access to some special functions).  There is a
rudimentary mechanism for communication between scripts and server, and
(I think) among scripts themselves, with SafeTcl_getconfigdata and
SafeTcl_setconfigdata.  These let you put in {key, value} pairs that
other scripts can read.
I don't see any straightforward way for a script to suspend itself and
re-activate on some future event (such as the arrival of another
message).  Maybe it could put its whole self into the config database as
a {key, value} pair and rely on future messages to pull it out and
execute it.  But that doesn't seem too great.
There is a lot of interest in this notion of mail messages as scripted
agents which go zipping about the network gathering data which they send
home.  I am optimistic that we will be able to get remailing capabilities
out of this infrastructure largely for free.

@_date: 1995-02-02 18:26:30
@_author: Hal 
@_subject: Frothing remailers - an immodest proposal 
One point re remailer reliability:  Even though in my discussions with
Nathan I did not really agree with his suggestion to have remailers check
signatures on incoming messages, actually Chaum did propose something
similar in his 1981 paper.
He would have each remailer sign the batch of messages it outputs each
cycle.  (Chaum's remailers used a straight batching approach.)  The idea,
as I recall, was to allow a remailer to prove that it had not engaged in
a denial-of-service attack by purposely dropping some message into the
bit bucket.  If some customer put his message in here and it didn't ever
come out over there, I guess the remailer could prove that it didn't lose
the message by showing its signed batch.  I'm not clear on the details
though.  Anyway, here is an area where message signing and reliability
have some intersection.

@_date: 1995-02-02 21:15:55
@_author: Hal 
@_subject: Adding padding to PGP files 
Unfortunately, this approach is easy but doesn't really succeed in adding
undetectable padding.  The PGP message, once the ascii armor is stripped
away, has a byte count in it.  Anyone can de-armor the message and see
that this byte count does not match the size of the file.  So you also
need to bump this byte count to match the added bytes.  That's all my
perl script does that I posted.

@_date: 1995-02-03 10:33:32
@_author: Hal 
@_subject: to hfinney 
Perl does exist for ms-dos, and I think those scripts would probably work
OK there.  They don't do anything exotic, just some byte reads and
writes.  Maybe the random-number generation would need to be looked at;
as I said, that is the one weak part.  But probably they would work OK.

@_date: 1995-02-03 18:45:45
@_author: Hal 
@_subject: re to hfinney 
Rather than re-post them, I put a copy of my message up for ftp at the
cypherpunks ftp site.

@_date: 1995-02-04 10:11:09
@_author: Hal 
@_subject: There is another NetCash 
People interested in NetCash should be aware of a potentially confusing
name re-use.  NetCash is also the name of a payment system designed by
people associated with the Information Sciences Institute (affiliated, I
think, with USC).  A reference is: Despite the names, neither one is cash in the cryptographic sense:
neither uses blinding.  If you didn't want the bank to be able to create
a database of every transaction you make, everything you spend and with
whom, you would need to have some anonymous connection with the bank and
exchange your netcash through that connection.  This would be cumbersome
IMO.  Some payment system is probably better than none, but I hate to see
the name "cash" expropriated by these non-cash systems.

@_date: 1995-02-04 10:17:03
@_author: Hal 
@_subject: PGP padding scripts (again) 
Sorry for the bandwidth waste, but my anonymous correspondent was not
able to ftp these scripts.  I also got another request for the scripts.
So here again is my post with a pair of perl scripts which will insert
padding pretty much undetectably into a .pgp file.  The one limitation is
the quality of Perl's random number generator.
Here are a couple of perl scripts I wrote last year to add padding to PGP
encrypted files.  The usage would be:
perl pgppadt.pl filename bytestoadd
The output file is filename.pad.
It only works on binary ".pgp" public-key encrypted files (not ascii armored
files).  So there would be some work needed to make it a really useful tool.
It would also be better to use a strong source of random numbers.  I
think Carl Ellison recently posted some tools that could help with this.
The two files are pgppad.pl, which does the work, and pgppadt.pl, a very
simple test driver to show how to use it.  They are in a shar archive.
---------------cut here----------------
# to extract, remove the header and type "sh filename"
if `test ! -s ./pgppad.pl`
echo "writing ./pgppad.pl"
cat > ./pgppad.pl << '\End\Of\Shar\'
# Perl module to allow padding and some other manipulation of PGP
# files.
# Include this with the statement:
# require 'pgppad.pl'
# 10/16/93
# Hal Finney
# Read a PGP Cipher Type Byte and the following length.
# One argument: file to read from
# Returns several things, in this order:
# CTB, with the length information removed, as a number.
# Length of following packet.
# Name of this kind of packet, made up, see list below.
# Packed CTB/length packet, suitable for writing out.
# Returns an empty string on error.
sub read_ctb {
    local($file) =     local($ctb, $length, $name, $rctb, $rlength, $lengthlength);
    if (read ($file, $rctb, 1) != 1) {		# Raw ctb
    }
    $ctb = unpack ("C", $rctb);
    if ($ctb < 128) {
    }
    $lengthlength = $ctb % 4;
    $ctb -= $lengthlength;
    if ($lengthlength == 0) {
    } elsif ($lengthlength == 1) {
    } elsif ($lengthlength == 2) {
    } else {
    }
    if (read ($file, $rlength, $lengthlength) != $lengthlength) {
    }
    if ($lengthlength==1) {
    } elsif ($lengthlength==2) {
    } elsif ($lengthlength==4) {
    }
    $rctb = pack ("C a".$lengthlength, $rctb, $rlength);  # Packed data
    if ($ctb==0x84) {
    } elsif ($ctb==0x88) {
    } elsif ($ctb==0x8c) {
    } elsif ($ctb==0x94) {
    } elsif ($ctb==0x98) {
    } elsif ($ctb==0xa0) {
    } elsif ($ctb==0xa4) {
    } elsif ($ctb==0xa8) {
    } elsif ($ctb==0xb0) {
    } elsif ($ctb==0xb4) {
    } elsif ($ctb==0xb8) {
    } else {
    }
    return ($ctb, $length, $name, $rctb);
# Write a CTB and length field out.
# 3 arguments: file handle, ctb value, and length in bytes.
# No return value.
# Length gets output as 1, 2, or 4 bytes, the smallest in which it
# will fit.
# If length is negative we output no length field, but an "indefinite
# length" code is added to ctb.
sub write_ctb {
    local($file, $ctb, $length) =     local($rctb);
    $ctb = $ctb - ($ctb % 4);	# Be sure 2 low bits are clear
    if ($length < 0) {
    } elsif ($length > 65535) {
    } elsif ($length > 255) {
    } else {
    }
    print $file $rctb;
# This entry point always outputs a 4-byte count.  Length must be > 0.
# Otherwise like write_ctb.
sub write_ctb_4 {
    local($file, $ctb, $length) =     local($rctb);
    $ctb = $ctb - ($ctb % 4);	# Be sure 2 low bits are clear
    if ($length < 0) {
    }
    $rctb = pack ("C N", $ctb+2, $length);  # Packed data
    print $file $rctb;
# Pad a PGP public-key-encrypted file to the specified length.
# Arguments: input file handle; output file handle; new size.
# Returns negative value on error.  See the code for what the
# different values mean.
# Returns 0 on success.
sub pgppad {
    local($infile, $outfile, $size) =     local($ctb, $length, $name, $rctb, $insize, $buf);
    # Read ctb & length of pubkey header
    ($ctb, $len, $name, $rctb) = &read_ctb($infile);
    if ($ctb == 0) {
    }
    if ($name ne "pubkey header") {
    }
    if ($len < 0) {
    }
    $insize = length($rctb) + $len;
    # Read packet of pubkey header
    if (read ($infile, $data, $len) != $len) {
    }
    # Write out pubkey header, unchanged
    &write_ctb($outfile, $ctb, $len);
    print $outfile $data;
    # Read ctb and length of conventional packet
    ($ctb, $len, $name, $rctb) = &read_ctb($infile);
    if ($ctb == 0) {
    }
    if ($name ne "conventional encrypted") {
    }
    # Calculate size of outgoing conventional packet.
    # Assume rctb won't change size; it may grow by 1 or 2 in some
    # rather rare cases, in which case we'll be a byte or two too big.
    $size -= $insize + length($rctb);
    if ($size < $len) {
    }
    # Output CTB with new length
    &write_ctb_4($outfile, $ctb, $size);
    # Copy remainder of input file
    while (read ($infile, $buf, 32768)) {
    }
    # Note that this random number generator is probably not
    # cryptographically strong.
    srand (time|$$);
    while ($len < $size) {
    }
    return 0;		# Success
1;	# Non-zero return for 'require'
  echo "will not over write ./pgppad.pl"
if `test ! -s ./pgppadt.pl`
echo "writing ./pgppadt.pl"
cat > ./pgppadt.pl << '\End\Of\Shar\'
# Test program for pgppad.pl, showing how to use it.
require 'pgppad.pl';
open (IN, $ARGV[0]) || die ("Couldn't open $ARGV[0]\n");
open (OUT, ">$ARGV[0].pad") || die ("Couldn't create $ARGV[0].pad\n");
$padding = $ARGV[1];
 = stat(IN);
$size = $stat[7];
print "Input file $ARGV[0] has size $size bytes\n";
print "Output file $ARGV[0].pad will have size ".$size+$padding." bytes\n";
if (($code = &pgppad (IN, OUT, $size+$padding)) < 0) {
    die ("pgppad returns code $code\n");
close (IN);
close (OUT);
print ("Done\n");
  echo "will not over write ./pgppadt.pl"
echo "Finished archive 1 of 1"

@_date: 1995-02-05 20:23:55
@_author: Hal 
@_subject: Excerpts of signed messages 
(I forget if this was posted here last year, it sounds familiar.)
Suppose I get a PGP-signed flaming message, full of insults, and at the
end it says, sarcastically, "For a stupid moron, you've made some very
nice postings."  I could choose to excerpt this last part, "...you've made
some very nice postings", and exhibit it in signed form.  What I would do
is to run the MD5 hash calculation on the first part of the message, saving
the internal state of that calculation.  I then publish just that MD5 state
along with the rest of the message.  Someone can check the signature by
initializing their MD5 to that state, then running the algorithm on the
part of the message I publish.  This will end up with the signed MD5
value from the signature.
The checker would know he was dealing with an excerpt, and that it came
from the end of the message, but he would have know way of knowing what
was in the part that was removed.
Presently of course PGP has no mechanism to check such signature
excerpts, but that could be added.  Under some circumstances this might
be a desirable feature.  But people would have to be aware of the
limitation that the excerptable portion would have to be the tail end of
the message.

@_date: 1995-02-05 21:35:07
@_author: Hal 
@_subject: Remailer encryption module 
For reference, here is that old message with an algorithm that produces an
encrypted session key with a flat distribution over a specified number of
bytes, along with a proof that it works.  The purpose of this is you
could strip off the PGP header stuff and have a file which looked for all
intents and purposes like totally random bytes, but if you knew the
secret key then you could decrypt it just fine.
(I recently took my CP archives and indexed them using Mark Zimmermann's
(no relation to Phil, apparently) FreeText browser which lets me do
keyword searches.  Pretty nice.)

@_date: 1995-02-05 22:04:34
@_author: Hal 
@_subject: finney's perl scripts 
Unfortunately, my PC's disk died several months ago so I don't have one
right now.
pgppadt.pl sets the output file name with:
open (OUT, ">$ARGV[0].pad") || die ("Couldn't create $ARGV[0].pad\n");
This doesn't work on DOS since it appends .pad to the input file name so
it doesn't fit the 8.3 character format.
The other errors you are getting are probably due to the difference
between binary and ascii I/O mode on DOS.  I forgot about that
in my test script.  Try this revision of pgppadt.pl, and let me know if
it works on DOS:
--------cut here------------------------------

@_date: 1995-02-06 08:51:56
@_author: Hal 
@_subject: Cooperation 
I see your point.  I tend to have something of a knee-jerk reaction
against proposals which put more responsibility into the hands of the
remailer operators, but as you say the mere promulgation of a standard
does not in itself require cooperation.  We have de-facto standards
right now, which is what makes chaining possible.
And from the technical point of view, the idea of remailers encrypting
between themselves seems to do no harm and could possibly make the
attacker's job potentially more difficult by reducing the amount of
information he has available.
One problem is that one remailer may not know about all of the others.
So to the extent that your proposal requires a registry of remailers, a
centralized service which keeps track of all remailers, I still have a
problem.  This is where my vision departs from those who see the
"remailer net" as an entity, and for whom the notion that remailers would
treat messages to each other specially is a natural assumption.  If you
would suggest that at each stage the message included not only the
address of the next remailer, along with the "payload" which was already
encrypted (by the sender) for that remailer, but in addition a key for
that remailer and a request to encrypt under that key, then I would feel
much better about it.  This way there is no need for the remailer to know
anything about whom it is sending to.
Likewise if we wanted to specify in the standard that messages could be
signed, that also would not imply collusion.  However to specify that
signatures must be checked would have some implications about acquiring
the necessary public keys through some means, and I don't think that
should be done.
I do like the idea of standards.  In fact I wonder if the current "mark
1" remailer command set shouldn't be documented as an Internet RFC.  It
has been in use for a couple of years now, evolving somewhat over that
time, and some twenty or thirty remailers have operated for some part of
that time following that spec.  It would also give a certain amount of
(undeserved, perhaps) respectability to remailer operators if there were
an actual numbered RFC which they were following.  And it does seem to me
that this kind of thing is exactly what the RFC's are for.  Certainly
there are a great many "minor" RFC's which are less followed than our
remailer standards.

@_date: 1995-02-06 21:37:24
@_author: Hal 
@_subject: New directions in anonymity (needed) 
The repool could actually be somewhat worse than this.  Wei has
shown that if you don't send every tick then statistical information
builds up surprisingly quickly to link senders and probable receivers,
especially if there is a pair communicating frequently over a long period
of time, arguably one of the main forms of usage of these nets.  So
everyone has to send all the time at the rate of the maximum per-user
rate accepted by the remailers (say, one packet per tick).  If this rate
is considerably above the actual average communication rate of a given
user then this will be much higher than O(h*M) (although granted it will
not scale directly with U, increasing U will increase the desired packet
rate that would satisfy, say, 90% of users).

@_date: 1995-02-07 08:37:19
@_author: Hal 
@_subject: MIME based remailing commands 
Here is an example of how such a mesage might look.  I created it using
the safe-tcl scripting language.  Interestingly, safe-tcl can to a
considerable extent be considered a tcl extension to let you work easily
with mime messages.  It makes it easy to create and parse them.
The whole message could be encrypted and marked with the "Encrypted: PGP"
header as we do now, or when the new PGP/MIME standard is finalized then
that could be followed.
I made up two new content types for this, one to hold the composite
multipart message, and one to hold the remailer commands themselves.
Although these types are not implemented, I think it would be very easy
to make a remailer that would use this structure, built out of safe-tcl.
(The batching and latency would not be trivial, but the basic remailing
would be easy.)

@_date: 1995-02-08 12:25:47
@_author: Hal 
@_subject: skronk 
When we last left this story, only certificates from a few (one?)
signatory authorities were going to be accepted by Netscape clients.
Would this mean that competitors offering Netscape servers would have to
go to Netscape to get their keys signed in order to interoperate with
existing Netscape clients?  I think this is too limiting.
People should be able to choose their own key signers.  This should be a
configuration option.  It should not be compiled into the client!  That
hurts your own flexibility as well as interfering with interoperatbiliy.
Can I use this reference implementation and set up a SSL-compatible
service today, or do I have to go to you and/or everyone's friends at RSA
and get a signature first?  As long as it is the latter I think that SSL
is not going to be able to be a well-established standard.  People are
going to resent having to register with the authorities in order to set
up a secure web page.
Hal Finney
hfinney at shell.portal.com

@_date: 1995-02-08 12:38:30
@_author: Hal 
@_subject: MIME based remailing commands 
Well, that was just an example; I was making those names up off the top
of my head in order to concretize what I understood Perry was suggesting.
I can see that putting remailer commands into a specific part of a MIME
multipart message has some advantages.  Right now we are basically
having the remailing commands be mail header fields.  But really people
aren't supposed to just make up new fields like that.  I think the
"name space" of these fields is protected somewhat more than many other
aspects of communication protocols on the net.  Is there precedent for
adding service-by-mail functionality in this way?  I am not completely
comfortable with it.  And as we think of new functionality and new
commands they all have to get added at this top level, the same
visibility and name space as "Subject", "From", and "To".
OTOH it does have the advantage that it is easy to do, at least with the
"::" pasting token idea (which perhaps would need to be documented in its
own right).
If we did use a separate message part we'd have our own little name space
to use, with no fears of conflicting with someone else.  (Maybe "Latency"
might be used in a future extension of RFC822 for some other meaning than
what we are using it for.)  I am not sure what has to be done to get an
RFC approved but I suspect that adding mail header fields would be much
more likely to hit opposition than adding yet another MIME type.
What does Mixmaster use for its commands?  Does it use "::" followed by
Anon-Send-To: and such?  Or some other format?  Maybe it should be made
MIME compliant from the beginning.  This way we are moving with the
current, the flow of the net, rather than across it.

@_date: 1995-02-08 12:46:20
@_author: Hal 
@_subject: Selection key crypto protocol trial balloon 
Let me get straight where we are.  Rishab's concrete proposal was not an
implementation, but rather a set of requirements.  There was no
suggestion about any specific algorithms that would meet those
requirements, right?  The question is whether any such algorithm could
It is hard for me to see how this could possibly work.  The message
receiver sends this "selection key" to the intermediary, and that somehow
pulls out the saved message, but in a form such that the intermediary
doesn't recognize it.  And the intermediary himself can't tell exactly
which message is produced.  But it is nevertheless exactly the message
which was meant for this particular receiver.
The thing is, the receiver does not have much more information than the
intermediary.  At best he knows a secret key which may help decrypt the
message in some way.  But I don't see how that can be used to pull out
the message data since it can't be revealed to the intermediary.
I can't really prove that this is impossible, but it certainly looks that

@_date: 1995-02-09 08:41:47
@_author: Hal 
@_subject: Lucky primes--third time's the charm? 
I did not realize before that p was an output of your algorithm, rather
than an input.  That explains better what you were trying to do.  You are
in effect trying to search for a prime such that e's multiplicative
inverse has a lot of 0's.
This looks like it will work pretty well, with the caveat as we discussed
before that going too far with this could make searching for the primes
easier.  But the only obvious attack would be to try to reproduce your
prime-finding algorithm to find a p which divides the modulus n, and that
is basically a sqrt(n) algorithm, which is far from the worst-case attack
we face.  The search space can be reduced by a considerable factor before
it becomes competitive with modern algorithms.
I guess another point is that if i is 2 or 4 then p itself will likely be
0-rich and conceivably there could be some attacks against a modulus
known to be the product of two 0-rich primes even when the primes are not
weak in the normal sense.  (p = (ed-1)/i+1, d is 0-rich, and e has only
2 bits on so ed is likely also to be somewhat 0-rich; dividing by i is
just a shift right if i is 2 or 4, and adding 1 won't make much
Restricing i to other numbers would still give p a simple arithmetical
relation to a 0-rich number (i=3 --> p*3 is 0-rich).  Maybe you could
choose a d such that d itself was 0-rich while ed happens not to be
0-rich; this might feel safer since p would have less of an
arithmetical relation to a 0-rich number.
(Admittedly, I don't know of any factoring attacks directly applicable to
0-rich factors but there is at least a superficial similarity to weak
primes and that suggests caution.)

@_date: 1995-02-09 09:10:03
@_author: Hal 
@_subject: MIME based remailing commands 
Ah, I see how you are doing it.  Having re-read your docs, I gather
that when un-armored the file is in an encrypted binary format, and
when decrypted at least the non-header portion of the file is still
binary?  I think this is a good way to do it; it addresses the point
Eric made recently about size expansion when an armored file is
encrypted at each step.
The one thing I would mention is that "::" was not originally intended
as an indication that the message was to be remailed.  Rather, this was
simply a "header pasting token" which could be used to move a few lines
from the body up into the header for those people who can't set header
fields on outgoing mail.  Then the presence of "Anon-To:" or whatever
in the header is what actually causes the action.  So you don't need to
use "::", you can just set your headers directly and get the same
effect.  (This is not to say you need to do it like this, just that
that is how the original design that Eric created worked.)
If you did want to follow this model, you could think about using a
MIME header to indicate the type of the message contents rather than
the "::".  Another alternative would be to use a different special
field in the mail header, like perhaps your "Remailer-Type: 2.0", but
I'm not sure that a new top-level header field is the right place for
this.  It looks to me like most of the standard headers deal more with
moving the message around rather than with telling what would be done
with it on receipt.  It's kind of a fine line but it looks to me like
more of a job for a MIME content type since that is really what it is
for.  You could use something like:
Then the rest of the message could look just as you have it.  Or, to use
a little more of the existing standard, you could add:

@_date: 1995-02-10 08:40:21
@_author: Hal 
@_subject: MIME based remailing commands 
I think this might be caused by a disagreement between the To: address in
the message itself and whatever "To" address was passed to sendmail on
the command line.  If you pass -t to sendmail then it won't look for a
"To" address on the command line, at least as configured at my site.

@_date: 1995-02-10 12:27:59
@_author: Hal 
@_subject: why pgp sucks 
In my remailer, I use: pgp -f < infile > outfile.  This won't add keys.
If you capture standard error you can parse it (grep is probably good
enough) to see whether the message was signed, encrypted, had a bad
signature, had keys, etc.

@_date: 1995-02-10 12:32:05
@_author: Hal 
@_subject: why pgp sucks 
PGP of course looks up keys by strings in addition to numbers.  A widely
accepted practice is to use  in the user ID which allows the
lookups to be by internet address.  PGP was intended for use beyond the
internet, such as in bbs's, fidonet, corporate networks, etc., where DNS
style addresses may not be useful.

@_date: 1995-02-10 14:05:41
@_author: Hal 
@_subject: MIME based remailing commands 
For one thing, you might want to know that you have an encrypted
message on your hands and not just somebody's misfired GIF.  For
another, you might want to know where the encrypted block begins and
where it ends.  You might also want to have information about what
kind of encoding has been done on the output of the encryption (base64,
uuencode, leave it as pure 8-bit binary, etc.)  And you might want to
have information about what kind of encryption was used, what key
was used, etc., in case you are supporting multiple encryption
formats and keys.
PGP, FYI, does include most of this information in the clear, albeit some
in binary format.
This information is generally needed for the receiver to successfully
decode and receive the message, so it does have to be in the clear.  Now,
there may be some circumstances where this is not desired, and where you
really do just want to hand the receiver a block of apparently random
data, with no indications whatsoever what it is.  Then by some
out-of-band means you have to have arranged with the receiver that he
will know exactly what transformation to do to get back the original
data.  For that I suppose you could just use text/plain (or something
like application/data?), and it looks as opaque as could be desired.

@_date: 1995-02-10 16:29:58
@_author: Hal 
@_subject: why pgp sucks 
Could you have a distributed database where you lookup by key ID and get
a key?  Or is there a constraint that the key distribution infrastructure has
to be part of the DNS?
I could see a set of key servers where one deals with all keys that start
with 0x00, the next has all keys which start with 0x01, etc.  This makes
it easy to know which server to go to in order to look up a given key ID.

@_date: 1995-02-11 09:10:27
@_author: Hal 
@_subject: why pgp sucks 
PGP could be hacked fairly easily to do this (in fact there is a
program around called stealth that does this to some extent), however
in the context of this discussion we were discussing more the issue of
checking the signature on a file.  For that we do need a hint about
whose signature purports to be there.  PGP presently provides this in
the form of the low-order 64 bits of the key modulus, and this provides
problems in implementing the key database in distributed form.

@_date: 1995-02-11 17:06:32
@_author: Hal 
@_subject: Does PGP scale well? 
I was just reading RFC1034 about DNS, and one thing I noted was that there is a
"reverse lookup" feature.  This allows you to go from, say, 156.151.1.101
to portal.com.  This problem seems similar in some ways to the key lookup
problem since you have a relatively unstructured number and you want to
use it as a lookup key.
According to the RFC, if you want to know what host machine is at
address 156.151.1.101, you do a lookup of 156.151.1.101.IN-ADDR.ARPA.
The RFC did not make it very clear how this is done.  Does this use a
"flat" database?    Is it distributed in some way?  Or has this method
perhaps been superceded by some other?
I can see that the key problem is worse than the reverse lookup problem
because there are many more users than hosts.  Although in the long run
won't everybody have a computer at home that has an IP address?  Will the
nameserver hierarchy run into problems then?  There is no obvious
hierarchical arrangement as we have now with our .edu and .com sites,
unless we go geographical.  This seems analogous to the PEM/RSA key
certificate hierarchy problem.  In any case the reverse lookup problem
seems like it will be difficult then.

@_date: 1995-02-12 10:20:57
@_author: Hal 
@_subject: the problem that destroyed PGP 
Here is something I posted on this topic last year:
[Discussion of possible extensions elided]

@_date: 1995-02-13 22:41:38
@_author: Hal 
@_subject: Internationalism no panacea 
Two recent news stories cast doubt on the principle that the international
aspects of the nets will prevent governments from enforcing their laws
"in cyberspace".
One is the possible trade war between the U.S. and China over that
country's continued support of intellectual property piracy, in video,
audio, and computer software.  Apparently the U.S. is very serious about
imposing sanctions because of this problem, while China is threatening
retaliation.  It is quite amazing to me to see these two big countries
going to the mat over "just bits" but as we know bits are big business
Think of our recent discussions of putting data havens offshore.  If the
U.S. is willing to turn the screws on a nuclear power like China, how
much protection will some dinky Caribbean country offer when people make
Windows 96 and Jurassic II available for download for $5 ecash?  IMO the
trend is going to be toward international enforcement efforts, a general
movement towards uniform information laws.
The other story related to the idea that individuals can evade laws by
moving from country to country as tourists.  Apparently in the recent
budget bill was a little-publicized change in the tax treatement of
people who renounce their U.S. citizenship.  (The change would be retroactive
to last week and was kept quiet until then to prevent a surge of people
leaving.)  Since you earned all your assets as a citizen of the U.S.,
naturally when you leave the grasp of that country you will not longer
get to take it all with you.  Instead you will apparently have to pay
capital gain taxes on some substantial fraction of your assets.
The article I read went on to discuss the problems many countries are
having with people playing citizenship games.  The implication was that
this may be just one step in a crackdown to close many of the loopholes
that allow people to travel under one flag or another.
My take on this is that human ingenuity is sufficient that there will
always be new loopholes found, and that a sufficiently energetic and
motivated person will probably be able to stay one step ahead of the
enforcers.  However, this will not be a lifestyle that can be turned into
a cookbook; as soon as some trick became widely known, the loophole would
be closed.  So this is something which will be available to an elite but
not to the masses.  Hence I don't see "perpetual tourism" as something
which will be a serious threat to government power.
My views are somewhat iconoclastic for this list; I don't see
cryptography as bringing about a libertarian/anarchist state.  I continue
to believe that the best and only way to achieve freedom for the mass of
people is to convince them that it is a good idea.  A small elite can and
will continue to be able to avoid many laws, and crypto will no doubt be
useful to them.  But IMO it is not going to change the shape of society.

@_date: 1995-01-02 13:20:50
@_author: Hal 
@_subject: Anonymous payment scheme 
There are a couple of issues here.  One is whether you could get a
debit card with another name printed on it than your own.  Sandy
Sandfort and some others have suggested here that this would be legal
and possible already as long as you don't do it with the intention to
commit fraud.  You can open a secured account by mail and give a false
I'm not sure what you do in this situation if they ask to see some ID
when you try to use the card.  This would be rather embarrassing, it
seems to me.  Sorry, I guess I left my drivers license in my other
pants... Or, never mind, try this card.  That other one was from before I
changed my name...
The other issue is whether you could set up a payment system which did
not require social security numbers from the participants.  I think
this is much more questionable.  Although the phone cards and some
other restricted usage systems are apparently legal, bank accounts seem
to have many more restrictions.  Barter and scrip systems are also
heavily regulated.  All these laws involving reporting requirements,
etc., were passed to help the government track the flow of money.
There is no way the government is going to make an exception at this
point.  In fact, I suspect that if the limited systems expanded to
where they were used for general payments, the government would crack
down.  I recall reading that just such a crackdown occured in Las Vegas
when casino chips started to be accepted for non-gambling payments.
So, you may be able to have a form of anonymity from the person you are
transacting with, but I don't think you can be anonymous from the bank
and from the government.  And personally, I am more concerned about the
bank and gov't tracking my spending patterns than whether the guy I buy
gas from knowing my name.  The bank has a lot more information about me
which is much more threatening to my privacy.  A nom de guerre VISA or
debit card does not seem to help this problem.

@_date: 1995-01-03 09:44:37
@_author: Hal 
@_subject: Anonymous payment scheme 
Again, it is unclear here whether you are proposing that you would be
anonymous to the bank or just have a blank card.  As I wrote, banks are
required to get SS for depositers right now, and I wouldn't expect
that to change any time soon.  If anything, the trend appears to be
towards more tightening rather than less.  Duncan and/or Sandy have
suggested giving a fake SS# when you open your secured account; maybe
that would be legal but it sounds questionable to me.
I used my VISA yesterday, and after swiping it through the now-ubiquitous
card readers the vendor was required by the machine to manually enter the
last four digits on the card.  He complained that this was something new
and was happening very frequently now (maybe a change with 1995?).  I
have heard of fraud where people make fake VISA cards (or steal them) and
re-program the mag stripe to have a different number than what is on the
front.  Maybe this is a countermeasure for that.  It doesn't sound like a
blank card is the direction the industry is going.  Does anyone have more
info on this change?

@_date: 1995-01-03 14:44:36
@_author: Hal 
@_subject: San Francisco Editorial 
Another point re Cantor and Siegel is that there is now a service
calling itself CancelMoose which goes through Julf's anon server in
Finland (anon.penet.fi) to cancel spams.  (Spams are off-topic,
nearly-identical posts to large numbers of groups.) This is what Siegel is
really upset about.  She and her husband are publishing a book telling
businesses how they can use spam posts on usenet as free advertising.
But now CancelMoose is a relatively accepted counter to these
increasingly-frequent spams (pyramid schemes, etc.).  This makes their
book obsolete and really hits them where it hurts.  But they can't sue
CancelMoose because its identity is hidden.
Personally, I don't like the idea of cancelling other people's posts,
spam or not.  I would rather see news readers enhanced to detect copies
of posts I have already seen and delete them.  The awful thing about
Cantor and Siegel's Green Card spam was that they didn't cross-post, they
used a bot to individually post to all groups.  I was shown their
message headers for days.  Ordinary off-topic posts don't bother me much
because I can ignore them easily.  With a better newsreader the Green
Card spam would have been equally trivial to ignore.
The scary thing about cancels is that some proposals have actually been
directed at anonymous posts themselves.  Someone anonymously posted
what purported to be a grisly transcript of the last seconds of the
doomed Challenger crew as they fell to the ocean.  This caused a great
hue and cry and some calls for banning anonymous posts and/or
retroactively cancelling them.  This led to some very amusing events
which Detweiler has chronicled in his FAQ on anonymity, the net result
of which was that the idea was discredited.  But the emergence of
CancelMoose is not an altogether positive event in my view.

@_date: 1995-01-05 15:11:42
@_author: Hal 
@_subject: Vinge reference in Moving Mars 
Greg Bear's novel Moving Mars, now out in paperback, has a cute reference
to Vernor Vinge's ideas from True Names.  p.208:
"'Don't stick on the names,' Orianna said, shaping the living room into
more Regency.  'All my friends are into Vernoring.  They work and play
with fake names.  I don't know their true ones.  Not even their parents
"'It's a game.  Two rules - nobody knows what you're doing, and you do
nothing illegal.'
"'Doesn't that take the fun out of doin crypto?' I asked.
"'Wow - crypto!  Hide in the tomb.  Sorry.  I shy from two-edged words.
We call it Vernoring.'
"'Doesn't it?' I persisted.
"'No,' Oriana said thoughtfully.  'Illegal is harm.  Harm is stupid.
Stupid is its own game, and none of my friends play it.  Here's Kite.'"
The book is pretty good, lots of nano and other hot tech, but not much
crypto (sorry, Vernoring)...  A little slow in places, though.

@_date: 1995-01-06 20:32:28
@_author: Hal 
@_subject: Can someone verify this conjecture for me? 
My take on the paper is that he first presents the "mix", or remailer, as
a method of foiling traffic analysis.  Then he extends this to the
"cascade", or chain of remailers, which does not improve traffic analysis
resistence but as you say provides some immunity against a bad operator.
There are other differences which may be relevant in practice.  One is
bandwidth.  With a Chaumian cascade of N remailers you get N times the
bandwidth used, as well as increased latency through the remailer
One thing that is not often appreciated in Chaum's paper is that at least
in his first description of the cascade, the assumption is that all users
use the same sequence of remailers in the same order.  We OTOH usually assume
a different model, where the different possible paths are chosen with
some distribution and randomness.  I posted an analysis of some of the
impacts of this difference a few months ago.

@_date: 1995-01-07 14:59:27
@_author: Hal 
@_subject: Latency Costs of Anonymity 
I think this is a good point.  We have had some discussions about getting
anonymity with web browsing.  The "mix" or "remailer" concept doesn't
work so well there as the connections are very short, so there is less
chance of multiple communications going on at one time.
OTOH I have heard discussions of asynchronous transfer mode, ATM, as a
new packet-based network technology that could support high bandwidth
communications.  All messages, presumably even streams like video
signals, get broken into fixed-size packets, which make their way through
the network and are reassembled into a stream on the other end.  The
individual packets may not all take the same path through the network.
(I am far from an expert on ATM so I welcome corrections to this
This technology does sound like mixing could work pretty well to provide
anonymity.  There is some price in bandwidth and latency but ATM is so
fast that probably several steps of chaining and mixing would be
possible.  Naturally such mixes would have to be hardware based due to the
rapid speeds of the packets.  So this would be kind of a "souped up"
version of our current email remailer network, with vastly greater
bandwidths and switching speeds.
Another possibility with connection-based communications would be
Chaum's DC-Nets.  These are networks where message source cannot be
determined.  They do face potentially severe costs in terms of
bandwidth, though, depending on how much anonymity you get.  As both
mixes and dcnets have bandwidth costs, I wonder if it is provable that
anonymity implies such costs.
I think it may be more useful rather than speaking of "true" anonymity
to think of factor-of-N anonymity.  This reflects the bandwidth costs.  I
would guess that, if you have a packet-based video converencing system,
that today you could probably get factor-of-2 anonymity with custom
hardware, and perhaps even more than that.
One other point I would make, based on Wei's original post, is that no
doubt anonymity does exact some costs.  However this does not mean that
it is uncompetitive.  It also may have, in some circumstances,
advantages.  People may be more frank and critical when they are shielded
by anonymity.  I've read articles about companies which introduce
electornic "suggestion boxes" where people can post anonymously, and
upper management is often shocked at the results.  It is too early to
judge how much of a net benefit or harm anonymity will be in general.
Furthermore, it is likely that the net advantage will differ depending on
the business or organization.  At one extreme, a group working with
illegal or restricted technology would probably benefit more from
anonymity.  I think it was Keith Henson who posted a story here a couple
of years ago that he was working on, involving some kind of underground
protest group which organized itself using crypto anonymity.  So it is
really not a question of whether anonymity is good or bad, but rather
whether its costs outweigh its advantages in a particular situation.
Hal Finney
hfinney at shell.portal.com

@_date: 1995-01-07 18:40:47
@_author: Hal 
@_subject: Latency Costs of Anonymity 
Yes, good point.  It might be possible to use a stream model where the
separate packets which make up a stream use the same conventional key.
This allows the various packets which make up a stream to be identified
as such by outsiders, but still if there are a large number of virtual
streams going through the network at one time it should be possible to
confuse the streams pretty well.  ("I've got a crazy idea.  Let's cross
the streams!" -- Ghostbusters).  Then you only need to do the RSA work
at setup time, and you need a fast streaming cypher during the
conversation.  This is how the streaming-packet encryption models like
IPSP or Netscape's SSL seem to work.
By "factor-of-N" I meant anonymity where you can only pin the source of
a message down to one of N possibilities.  It appears to me that many
of the costs will be a function of N.  It will be relatively easier to
cloak your source as one of say 50 possibilities than to make it any of
one in a million.  This is why I suggested that factor-of-2 anonymity
would be the easiest.  The DC-Net concept would allow two users to
share a cryptographically strong pseudo-random stream, and each of them
to XOR their video output with the random stream; then these modified
outputs from each of them are themselves XOR'd together to produce the
joint output.  As long as only one sends at a time, the resulting
stream is their output, but it is impossible for an outsider to
determine which one is sending.  The hardware requirements seem quite
modest and perhaps would be adequate today even for video.
I don't think we would really expect everyone to be anonymous all of the
time.  In our personal lives, with friends and family, it doesn't seem
appropriate to expect anonymity (although my earlier quotes from Greg
Bear's sci fi story suggest differently).  But still I think that for
people who desire it and are willing to pay the prices, anonymity would
indeed be available in many or most electronic communications.  So if
that is your desire you should be able to achieve it.

@_date: 1995-01-08 09:41:01
@_author: Hal 
@_subject: The Value of Anonymity 
These are good points.  However I think your presentation is a little too
oriented towards the libertarian perspective of distrusting government,
and also comes off sounding harshly competitive:
I think most people don't think so much in terms of winners and losers,
of beating and being beaten.  Rather, I think it will be more acceptable
to couch the issue in simple privacy terms.  People do value their
privacy.  I don't think you have to overly justify the value of privacy.
A few examples of how little privacy people could actually have in a
non-anonymous network of the future should suffice to establish
motivation IMO.
I like this phrase!  It nicely connotes the transparency of the nets.
This is where I think you are getting too libertarian for a broad
audience.  Also, this wording invites the reader to assume that anonymity
will lead to tax avoidance and evading laws.  Most people feel that they
are paying their own taxes, and if others avoid them then it just
increases the burden on themselves.  So except to certain selected groups
I would avoid playing this angle up.  I think your next argument
will have wider appeal:
Be aware that this is in fact the "mainstream" solution to the problem.
There was some discussion on comp.org.eff.talk of some kind of committee
headed by EFF board member Esther Dyson which issued a statement on
privacy protection in the nets.  They issued the by-now traditional call
for laws along the lines of "information collected for one purpose cannot
be used for another purposes".  Like, VISA can't sell data on your
spending patterns, at least not without telling you.  Nobody criticized
this point; even the relatively net-aware civil liberties types mostly
explicitly endorsed this provision.  Laws like this are apparently
already in place in Europe.  So the momentum is in exactly this
I think your arguments are good ones; the government would undoubtedly
exempt itself from such rules (the IRS is already starting to use
dataveillance and matching to look for discrepencies between tax returns
and spending patterns), plus such provisions would seem to require a
labyrinth of exceptions, special cases, etc.  Eventually I could see laws
telling exactly what a business can and cannot do with the names of
people who phone or net in for information; yes, they can be kept on a
list for up to 6 months and sent additional promotional literature,
except that the business must require standard form 11832 to allow the
customer to get his name off the list, which must be handled within 5
working days for businesses with more than 100 employees, etc., etc.  You
could have volumes of this kind of stuff.  I think Tim wrote some essays
a long time back pointing out the absurdity of this approach, especially
if you tried to apply it to private individuals.
That's a good summary.  This is definately an uphill battle, though.  I
see no significant standards body or organization of influence (except
for CPs, to the extent that we have any influence) which is moving in
this direction.  Add to this the costs of anonymity as Wei has been
discussing and it really isn't clear how to proceed.

@_date: 1995-01-09 23:02:20
@_author: Hal 
@_subject: for-pay remailers and FV 
I had suggested an idea a while back where you would try to address the
abuse issue directly rather than charging per message.  I agree with
Pierre that any reasonable per-message charge will not help in many forms
of abuse, although it should address the worst spam attacks.
The idea is to have a sort of digital cash token, but it is free.  The
key is that each person just gets one of these, but they are reusable.
After a remailer sends a message, it waits and sees if it gets any
complaints.  If not, the token is re-blinded and made available to the
original user via some kind of pool.  He can then send another message.
But if he commits abuse, he doesn't get his token back.
Obviously there are problems with this, the worst probably being how we
can keep people from acquiring lots of tokens under different names.
Perhaps you could charge some small amount for them, but require VISA
payment, and check the names on the VISA cards.  (This doesn't hurt
anonymity when the tokens are actually used because of the blinding.)  To
get multiple tokens a person would have to commit some serious real world
name trickery, a considerably higher barrier than making up a pseudonym
on the net.
Another problem is that as stated above, you could only send one
anonymous message every day or two.  Perhaps we relax the rules and let
people have a few of these tokens; they can then abuse the system a few
times but each time they lose a token.
A similar idea might work for the data haven problem, although I don't
understand exactly what is intended there.  This approach is a variation on
the "is a person" credential, which attempts to make sure that each
person only gets one of something.  A lot of situations would benefit
from such a credential, although some people don't like them.

@_date: 1995-01-12 09:01:09
@_author: Hal 
@_subject: How do I know if its encrypted? 
The data haven concept as I understood it held data for public access in
some form (for sale or for free) which would be illegal in some
jurisdiction.  This might include credit information that was older than
the legal limit, libelous claims, damaging medical records, etc.
Frankly, I suspect that most usages would be directed towards reducing,
rather than increasing, individual privacy.  So this is not an area I am
interested in working towards.
The idea of offsite storage doesn't seem that helpful since you can just
store the data on your own disk in encrypted form.  Maybe if encryption
gets outlawed it would be useful, but then you can't use encryption to
communicate with the haven.
As far as remailers requiring encryption, one purpose would be to reduce
complaints by making it impossible to send some kinds of messages which
people would object to.  It would be hard to post to usenet, for example,
in a useful way.  And mail to private individuals could not contain
obvious obscenities or other objectionable material.
The problem with this is that if people become able to handle and deal
with incoming encrypted mail in a transparent way, this restriction is no
longer effective in the latter purpose.  Someone could get encrypted hate
mail and have it transparently decrypted and displayed just like normal
mail.  They will be just as upset as people are today when they get
objectionable mail from the remailer.
As far as usenet posts, if a particular decryption key were widely and
customarily used in a particular newsgroup, objectionable material
could still be widely read if encrypted with that key.  Tim May's
example of a fake encrypted post containing inflammatory material is a
good example of the heat which could occur, especially when the message
is real and not a fake one like he did.  So I don't think this
restriction would really accomplish the desired goal except perhaps in
the short term.
If the purpose is to have plausible deniability by the remailer
operator, I feel we can still get that by publicizing the remailer
software source, which has no provisions for manual filtering.  A policy
of sending only encrypted mail so that the operator can't filter would
be no more acceptable to critics of anonymity than a policy of just not
filtering at all.
Entropy checking is not adequate to detect encryption, as compressed
files have maximal entropy as well.  For these purposes, compression may
be nearly as good as encryption, except that standard compression formats
are already widely used.  An entropy checker might well pass a gif,
jpeg, or zip file, so this filter would by itself be useless to prevent
posting of unencrypted graphics.  It would probably have to be augmented
at least by some checks for these special file formats.

@_date: 1995-01-14 15:39:11
@_author: Hal 
@_subject: How do I know if its encrypted? 
If you want to not be able to read the files on your storage site, then
why not just try reading them?  Check their entropy to make sure it is
maximal, check that they can't be unzipped, unstuffed, displayed as gif
or jpeg files.  When a new format becomes popular add that to the list.
This is all you can do.
What does this gain you?  I'm not sure.  If someone posts encrypted
Windows 95, then publicizes the location and the key, people will get the
data just as easily as if it were not encrypted.

@_date: 1995-01-16 12:24:53
@_author: Hal 
@_subject: Jude Milhon in WIRED 
I felt the same way recently.  I had commented here about elec cash
prodigy Stefan Brands being among those not getting into the DigiCash demo,
it got cross-posted to www-buyinfo (which is read by DigiCash people) and
led to a big political stink that may have set back relations between
Brands and Chaum and therefore the prospects for high-quality digital
cash.  I really regretted my words as it was certainly not my intention
to stir up bad blood.  I still tend to think of this list as a relatively
private place to make comments "just among friends", unlike more public
venues which feed into a wider cross-section of views and where I try to
be much more circumspect.

@_date: 1995-01-17 21:57:08
@_author: Hal 
@_subject: EE Times on PRZ 
The Jan 16 issue of EE Times has an excellent article on the legal
controversy surrounding Phil Zimmermann and PGP, positioned top-right
front-cover for maximal exposure.  It describes the aftermath of a
meeting last week between Phil's attorney, Philip Dubois, and the
government lawyer handling the case.  "'We told the prosecutor our
concerns,' Dubois said.  'He agreed to consider them.  We might hear
back in a month or two.  He didn't make any promises.'"
(Sometimes it seems like the gov't is dragging this case out
intentionally.  I believe the uncertainty does have a chilling effect on
private development of strong crypto, which would be gone if the
government announced it was not going to pursue the case, or if they did
bring charges and lost.)
Another interesting quote: "Zimmermann is not in danger of being indicted
for willfully exporting PGP. Rather, the U.S. attorney's office, here, is
considering charging him for making PGP available in such a manner that
it could be exported by a third party."  What the hell is this?  Can
anyone point to the statute they may be referring to here?  This seems
awfully broad.
This, from a sidebar, is really surprising:  "In contrast, public keys
allow the overt publication of an encryption key, because decryption keys
can only be derived through a mathematically difficult process, such as
large prime-number factoring.  Contrary to popular belief, the NSA can
decrypt public keys of most practical key sizes."  I wonder what this
means?  If it is a claim that the NSA can factor 1024 bit moduli that
would certainly come as a big surprise.  If they are saying that they can
do 512 bits that would be more believable although of interest.  It is
strange that the author would include a statement like this without
attribution or evidence.
Generally, the article is very favorable towards Phil and an excellent
overview of the case.

@_date: 1995-01-18 21:04:22
@_author: Hal 
@_subject: Factorisation and Discrete Logs (was Re: EE Times on PRZ) 
DH uses prime moduli, I believe.  Solving the DL problem sufficiently to
break DH may not let you solve it for composite moduli, not without
knowing the factors.

@_date: 1995-01-20 08:24:38
@_author: Hal 
@_subject: traffic analyzing Chaum's digital mix 
This sounds like a good idea.  It was very interesting to see your
earlier result on the impact of dummy messages on this approach.  Even a
relatively small number of batches without dummy messages allows
continual accumulation of incriminating information.
I know that the Eurocrypt 89 proceedings had some articles on
cryptanalyzing Chaum's mixes.  My library has an excellent crypto
selection but is missing this volume.  Can anyone who has read this say
whether there is anything in those papers that isn't obvious?
Another interesting aspect of your analysis is the possible role of
latency.  Earlier I had thought of latency as primarily a way of doing
mixing, an alternative or addition to batching which mixes messages
without holding them up quite as much.  But in terms of this in/out
analysis latency could play a part in blurring the batch boundaries,
adding more uncertainty and making the job of the analyst harder so he
would need more data to establish his scores.

@_date: 1995-01-26 08:50:23
@_author: Hal 
@_subject: Reordering, not Latency (Was: Re: Remailer) 
I think there is a small terminology problem here.  In Eric's writings,
latency refers to delaying message remailing; reordering refers to
sending messages in a different order than they arrive.  I think it is
obvious that reordering is necessary in order to have any mixing; latency
may provide reordering, but it is not guaranteed to do so.  Latency
without reordering is not of much use.
More recently the discussion has been contrasting simple batch reordering
versus a form of reordering where some messages are "carried over" from
one batch to the next.  In the recent context this carry-over process is
being referred to as adding latency.  I think the recent comments about
the advantages of latency refer to the additional statistical confusion
which this carry-over process may add.
So these comments don't contradict Eric's earlier statements, but rather
the terminology has shifted slightly.  Reordering is still the primary
necessity; now it appears that reordering with some latency (carry-over)
is superior to simple batch-based reordering.

@_date: 1995-01-27 10:24:04
@_author: Hal 
@_subject: Mixmaster and remailers 
Actually I don't think I considered this aspect of the problem.  Probably
you are thinking of Wei Dai's posts along with LC's.

@_date: 1995-01-28 11:51:43
@_author: Hal 
@_subject: Secure (!?) Remailer Net 
Realistically, though, everybody is not a remailer, and there are no
prospects of everybody becoming a remailer anytime soon, so the analyses
of Wei and others are certainly relevant.
Mixmaster is supposed to do splitting and, I think, padding.  I hope to
have time to look at it soon.  It sounds very good.
I did not see why this should be done.
A better approach IMO is to embed the message length in the encrypted
information (as PGP does) and pad with cryptographic random garbage
(which PGP could be patched to do).
Why does the remailer care where the message came from?  What difference
does that make?  I can see the final recipient caring about the original
sender, so a PGP sig makes sense at that level, but why at each hop?
I don't think so.  The problem with Miron's extropy remailer is that it
only passes through the contents of a PGP block.  For anonymous addresses
to work, the (chained,encrypted) address must be in a PGP block which
precedes the message body.  I don't see how any cutmarks idea would
affect this.
Again, why does the remailer go to all this trouble to verify a
signature from Alice?  That sig is for Bob!  She may not even want to
post her public key for everyone; Bob may be the only one who has it.  I
don't understand why the remailer, which exists to hide identities, is
going to such trouble to verify them on its own.
Alice is the one who should encrypt the message for Bob, not the
remailer!  Are you suggesting that she should let the remailer see the
message contents?
Why on earth does he care?  I really don't see what problem you are
solving here with all this checking.
Eve would be more likely to subpoena Chaum's secret key ring.  A public
key ring proves nothing.
This mostly makes sense (although as I said I prefer simply enhancing the
crypto program to take a parameter for output pad size) but I don't see
where all the rest of it came from.
I believe Mixmaster provides a client mode to do this.  I prefer putting
more functionality in the hands of the users and not relying on kindly
old Uncle Remailer to do it for you.
This is a commonly made suggestion, but philosophically I am opposed.  We
got into this fix (lack of privacy) by letting people rely on others to
do things for them.  It's time for people to take responsibility on their
own.  The kind of thing you are suggesting provides the illusion of
privacy.  Never trust remailer operators!
Since the secret key d is effectively a random number from 0 to m, you
would have to create, say, 1000 key pairs to have a good chance of
finding a d that was as much as 10 bits shorter than m.  Then o(d) might
be 5 bits shorter.  So you'd be done from 768+384 to 758+379 or about a
1% reduction in time.  And it will take a while to generate 1000 keys.
To get a 2% reduction you would have to generate 1000000 keys.  I hope
you have a lot of time on your hands.
I'm sorry to have been so negative, but this message is part of a long
tradition advocating putting more responsibility into the remailer net.
I strongly feel that better solutions put power into the users' hands.
I oppose centralized solutions.

@_date: 1995-01-29 13:14:56
@_author: Hal 
@_subject: Secure (?) Remailer-net 
I can see the advantage from the sender's point of view.  If I sign all
messages I send, then I have some defense against the charge that I sent a
particular message, if it doesn't bear my signature.  (OTOH the
prosecutors can argue that I simply skipped signing that one.)  This does of
course expose me to the risk that if I _did_ send a particular message,
my signature will be incriminating.  In any case I am still puzzled by
your statement that you as a remailer operator would want to be able to
verify the source of all incoming messages.  Would you do things
differently with messages from different sources?  I hear you saying
that you care if you get a message claiming to be from Alice but not
bearing a good signature from her.  Why?  Again, what would you do
PGP already includes a cryptographically protected length field in the
message.  It will ignore any data past that, according to my experiments.
All that is needed is a simple patch to add junk data to the end.
I still don't quite follow this.  Exactly what attack would be possible
against Miron's remailer if it allowed encrypted reply blocks (as all
others do) which would fail if the messages were wrapped as you suggest?
Alice may not have a key whe wants the general public to use - she may
just be using one for her private correspondents.  Actually it seems to
me given the nature of remailing that it would be superior if it were
easy for people to "spoof" my use of the remailer.  That would give me
more credence to claim innocence.  The more useless return addresses are,
the less we even need remailers.
It's not my job to fix the damn Internet.  So what if I get mail claiming
to be from abc when it's actually from def?  I of all people care the
least, specifically because I throw away this data.  Virtually everyone
else on the net cares where their mail comes from, but I don't.  My whole
purpose is to discard the information about where it comes from.  That is
why I am so confused about your emphasis on checking signatures.
Although I agree with Wei Dai's mathematics, to my mind it points up the
importance of successful countermeasures rather than implying that the
remailer network is inherently insecure.  For example, if you send one
identical message every batch, Wei's math shows clearly that you can't be
traced.  Let's not get rumors started about how the remailers don't
Do you see your suggestion as protecting against Wei's in/out correlation
attack?  I don't see it.  If fixed-sized packets are used, with chained
encryption, I think you have as good a system as you do with all of your
inter-node encryption and signing.
Suppose one good encrypted message enters the net with 10 unencrypted
ones.  Won't the full path of each of the 10 be visible to an outsider?
Even if the remailer helps out those 10 doltish users by encrypting them
from there on out, the outsider already saw their whole paths!  They will
know how many unencrypted messages are going out to each destination, and
from that determine where the encrypted message is going.
Yes, I see that you are right about this.  It would be easy to generate
e,d pairs and get a d which is significantly short on 1's by 10% or more.
I did not quite follow your algorithm to do this (was n the modulus or
was it phi, the sum of the modulus' divisors?).  The one caveat is that
if "high-zero" decryption exponents are widely used, it could conceivably
reduce the search space somehow, although I don't see offhand how to
exploit this.

@_date: 1995-01-29 17:57:14
@_author: Hal 
@_subject: Why encrypt intra-remailernet. 
Of course it was Chaum himself in his 1981 paper (which I think is available
from the CP FTP site) who described the duplicate-message attack.  I don't
see that inter-remailing encryption helps much, because the attacker can
still notice that whenever they inject message A, _something_ goes to
Bob.  The real solution, as Chaum pointed out, is that the remailer must
reject duplicate messages, even when separated by days.  Doing this without
keeping a database of all messages ever sent is left as an exercise.
Another aspect worth mentioning is that message splitting can make the
kinds of statistical correlations that Wei Dai was looking at more of
a danger.  It's one thing if I send a message along with thousands of
other people, and Bob gets a message along with everyone else.  But if I
send 10 messages and Bob gets 10 from that batch, that fact alone can
help to link us up.  So splitting my big message into 10 standard ones
isn't that great if they're all sent at once.  Ideally you'd want to
dribble them out at some standard rate, a rate at which you always send
a message whether you have something to send or not.  But this may introduce
unacceptable latency.

@_date: 1995-01-31 20:12:54
@_author: Hal 
@_subject: remailers and multiple recipients 
We had some concerns here a while back that someone was trying to exploit
such a feature to create an exponentially-growing message that would
totally overload the remailers.  A message of the form:
Request-Remailing-To: Request-Remailing-To: was sent.  If all remailers had observed and honored the multiple
requests, there would have been uncounted trillions of messages flying
about.  So I would caution anyone considering implementing this feature.

@_date: 1995-01-31 20:53:20
@_author: Hal 
@_subject: Frothing remailers - an immodest proposal 
I have some concerns about Kevin's frothing remailers.  Like so many of
the proposals we see to put more responsibility into the remailer net,
this opens vulnerability to a single bad remailer.  If I trust the first
remailer in the net to choose my path for me, as I might be tempted to
do with a froth, then if that remailer is corrupt my anonymity is lost.
With user-supplied chaining I am secure unless all of the remailers on
the chain are corrupt.
I also do not like the kind of close-knit, cozy cooperation among the
guild of remailer operators which seems to be envisioned in this and
similar proposals.  Do you like the idea of messages on the remailer
operators list saying, I am getting objectionable messages from your
remailer, would you mind dropping in a log so we can see who is sending
these messages which violate the Politically Correct Speech Act?
I do like Kevin's ideas about a dynamic remailer net, but I think
another approach would put more smarts into the client program used by
the originator.  Granted, his information will be somewhat more out of
date as the message makes its way through the network.  But depending
on thie time scale at which the froth, um, froths, this should still
allow a lot more dynamism among the set of remailers.  Using either IRC
or, as Todd suggested, Usenet to maintain an active remailer list might
work.  We could also have a distributed set of sites which provide the
information by finger like the pinging sites we have now.
A few notes about Safe-TCL.  I posted some ideas on using this as a basis
for remailing some time back.  Safe-TCL defines three times at which
messages could be activated (scripts in them run).  One is on message
sending, one on message reading (so it can put up dialog boxes and
interact with the recipient in other ways), and the third on receipt,
which is when it enters the user's mailbox.  The actual safe-tcl
implementation does not include support for this third mode, but it would
be pretty easy to add.  If you had that, messages could come to your
machine and activate to do various things that you allow them to do.  If
you allowed them to send mail as one of those things, this would be a
start towards a remailer.
What you need then is some way for various messages to interact with each
other, so that, for examle, a message could wait until there were a
certain number of other messages inside the machine before it sent itself
out.  You would also want a way for a message to suspend itself until
some future event, such as having a certain amount of time passing, or
waiting until some message with desired properties arrived.
There has been intermittent discussion of similar topics on the safe-tcl
mailing list.  The motivation there is not supplying remailers, of
course; rather there is a desire to have something with similar
functionality to the much-ballyhooed Telescript, but less bound by
proprietary constraints.  Telescript scripts can move through the network
and interact with other scripts (at least, they will supposedly be able
to, but the exact manner is apparently secret for now).  Providing the
simple act of motion to mail agent scripts without stamping them with a
record of everywhere they have been is really all a remailer would do.
(I wonder if Telescript agents have to carry around with them a record of
every path they've taken?)
Sending a message through a safe-tcl based remail network might be more
cumbersome than our current techniques.  You might have to precede the
message body with a safe-tcl program a few lines to a couple of pages in
size depending on the complexity of remailing you want.  But again with
proper clients this can be hidden from the user.  I think emphasis should
be on smart mailer clients rather than more cooperation among nodes in
the remailer network.

@_date: 1995-07-12 10:23:37
@_author: Hal 
@_subject: SSL RC4 challenge 
Here is a challenge to try breaking SSL using the default exportable
encryption mode, 40-bit RC4.  It consists of a record of a submission
of form data which was sent to Netscape's electronic shop order form in
"secure" mode.  However the data I entered in the form is not my real
name and address.  The challenge is to break the encryption and recover
the name and address info I entered in the form and sent securely to
(A URL for info on SSL is Below is the data which was sent back and forth, along with some
annotations to help interpret it.  The connection was made to
order.netscape.com at port 443, the https port.
The following is the first message from client to server, the
CLIENT-HELLO message.  It is not encrypted.
0x80 0x1c 0x01 0x00 0x02 0x00 0x03 0x00 0x00 0x00 0x10 0x02 0x00 0x80 0xaf 0x84
0xa7 0x79 0xf8 0x13 0x69 0x20 0x25 0x9b 0x53 0xa0 0x60 0xae 0x75 0x51 This is interpreted as follows:
0x80 0x1c	Length field: 28 bytes follow in the packet.
0x01		MSG_CLIENT_HELLO
0x00 0x02	CLIENT-VERSION-MSB CLIENT-VERSION-LSB
0x00 0x03	CIPHER-SPECS-LENGTH-MSB CIPHER-SPECS-LENGTH-LSB
0x00 0x00	SESSION-ID-LENGTH-MSB SESSION-ID-LENGTH-LSB
0x00 0x10	CHALLENGE-LENGTH-MSB CHALLENGE-LENGTH-LSB
0x02 0x00 0x80	CIPHER-SPECS-DATA
0xaf...0x51	CHALLENGE-DATA [16 bytes]
The only cipher spec sent (and hence supported) by the browser is
0x02 0x00 0x80, which is SSL_CK_RC4_128_EXPORT40_WITH_MD5.  No session id
is sent, hence new key information will be calculated for this session.
And 16 bytes of challenge data are sent in the clear; this will be useful
as known plaintext returned encrypted by the server later.
The following data is then returned by the server, in the SERVER-HELLO
0x82 0x2b 0x04 0x00 0x01 0x00 0x02 0x02 0x0d 0x00 0x03 0x00 0x10 0x30 0x82 0x02
0x09 0x30 0x82 0x01 0x72 0x02 0x02 0x00 0x88 0x30 0x0d 0x06 0x09 0x2a 0x86 0x48
0x86 0xf7 0x0d 0x01 0x01 0x04 0x05 0x00 0x30 0x47 0x31 0x0b 0x30 0x09 0x06 0x03
0x55 0x04 0x06 0x13 0x02 0x55 0x53 0x31 0x10 0x30 0x0e 0x06 0x03 0x55 0x04 0x0b
0x13 0x07 0x54 0x65 0x73 0x74 0x20 0x43 0x41 0x31 0x26 0x30 0x24 0x06 0x03 0x55
0x04 0x0a 0x13 0x1d 0x4e 0x65 0x74 0x73 0x63 0x61 0x70 0x65 0x20 0x43 0x6f 0x6d
0x6d 0x75 0x6e 0x69 0x63 0x61 0x74 0x69 0x6f 0x6e 0x73 0x20 0x43 0x6f 0x72 0x70
0x2e 0x30 0x1e 0x17 0x0d 0x39 0x35 0x30 0x32 0x32 0x34 0x30 0x31 0x30 0x39 0x32
0x34 0x5a 0x17 0x0d 0x39 0x37 0x30 0x32 0x32 0x33 0x30 0x31 0x30 0x39 0x32 0x34
0x5a 0x30 0x81 0x97 0x31 0x0b 0x30 0x09 0x06 0x03 0x55 0x04 0x06 0x13 0x02 0x55
0x53 0x31 0x13 0x30 0x11 0x06 0x03 0x55 0x04 0x08 0x13 0x0a 0x43 0x61 0x6c 0x69
0x66 0x6f 0x72 0x6e 0x69 0x61 0x31 0x16 0x30 0x14 0x06 0x03 0x55 0x04 0x07 0x13
0x0d 0x4d 0x6f 0x75 0x6e 0x74 0x61 0x69 0x6e 0x20 0x56 0x69 0x65 0x77 0x31 0x2c
0x30 0x2a 0x06 0x03 0x55 0x04 0x0a 0x13 0x23 0x4e 0x65 0x74 0x73 0x63 0x61 0x70
0x65 0x20 0x43 0x6f 0x6d 0x6d 0x75 0x6e 0x69 0x63 0x61 0x74 0x69 0x6f 0x6e 0x73
0x20 0x43 0x6f 0x72 0x70 0x6f 0x72 0x61 0x74 0x69 0x6f 0x6e 0x31 0x16 0x30 0x14
0x06 0x03 0x55 0x04 0x0b 0x13 0x0d 0x4f 0x6e 0x6c 0x69 0x6e 0x65 0x20 0x4f 0x72
0x64 0x65 0x72 0x73 0x31 0x15 0x30 0x13 0x06 0x03 0x55 0x04 0x03 0x13 0x0c 0x41
0x72 0x69 0x20 0x4c 0x75 0x6f 0x74 0x6f 0x6e 0x65 0x6e 0x30 0x5a 0x30 0x0d 0x06
0x09 0x2a 0x86 0x48 0x86 0xf7 0x0d 0x01 0x01 0x01 0x05 0x00 0x03 0x49 0x00 0x30
0x46 0x02 0x41 0x00 0xa5 0xa7 0x7b 0x42 0xb1 0x79 0x2d 0x0b 0x35 0x08 0xb4 0x0d
0x74 0x1d 0x46 0x6a 0x29 0x07 0x47 0x08 0xdc 0x3a 0x76 0x36 0xbd 0x7f 0xb3 0xd4
0xa9 0x85 0x9d 0x4b 0x65 0x74 0xc1 0x00 0x56 0xec 0x5a 0x31 0x72 0x23 0x04 0xc1
0xcf 0x78 0x63 0x21 0x77 0x69 0xd9 0xf0 0x61 0xc8 0x73 0xf7 0xdc 0x4c 0xde 0xd2
0x22 0x99 0x79 0xdf 0x02 0x01 0x03 0x30 0x0d 0x06 0x09 0x2a 0x86 0x48 0x86 0xf7
0x0d 0x01 0x01 0x04 0x05 0x00 0x03 0x81 0x81 0x00 0x7e 0x4a 0x28 0x7d 0xba 0xfa
0x41 0x5a 0x19 0x1c 0x9a 0xea 0x6d 0x3b 0x07 0x1c 0x97 0xe0 0xf5 0xf8 0x4c 0xd5
0x92 0x0c 0x1c 0x30 0x49 0x06 0x72 0x42 0x9a 0x3f 0xfc 0x3b 0x11 0x17 0x78 0x7e
0x6c 0x27 0x8a 0x12 0x19 0xf3 0x08 0x18 0x6e 0xe0 0xc3 0xbe 0xe7 0x37 0xbd 0x4e
0xae 0xe1 0x9e 0x4a 0x3b 0xa9 0xbf 0xc0 0x92 0x59 0x2c 0xdb 0x37 0x34 0xc8 0xa0
0xc0 0xba 0xb8 0x6f 0xd3 0xd6 0xc7 0x48 0x88 0xbc 0xd6 0xff 0x7a 0xf7 0x76 0x70
0x2c 0x19 0x07 0xc8 0x7c 0x80 0x29 0x18 0x58 0xfc 0xd1 0x12 0x86 0x99 0x4e 0x32
0xee 0xb9 0xf5 0x11 0x70 0xd5 0x1b 0xf7 0x85 0x5b 0x4a 0x0e 0xd6 0xe6 0x6c 0x52
0xf5 0x8a 0x2c 0x97 0x3e 0x63 0x85 0x57 0x43 0xbc 0x02 0x00 0x80 0xbf 0xeb 0x90
0xf8 0x2c 0x0c 0xe1 0xea 0x18 0xac 0x11 0x4c 0x83 0x14 0x21 0xb6 This is interpreted as follows:
0x82 0x2b	Packet length, 555 bytes follow.
0x04		MSG-SERVER-HELLO
0x00		SESSION-ID-HIT
0x01		CERTIFICATE-TYPE
0x00 0x02	SERVER-VERSION-MSB SERVER-VERSION-LSB
0x02 0x0d	CERTIFICATE-LENGTH-MSB CERTIFICATE-LENGTH-LSB
0x00 0x03	CIPHER-SPECS-LENGTH-MSB CIPHER-SPECS-LENGTH-LSB
0x00 0x10	CONNECTION-ID-LENGTH-MSB CONNECTION-ID-LENGTH-LSB
0x30...0xbc	CERTIFICATE-DATA [525 bytes]
0x02 0x00 0x80	CIPHER-SPECS-DATA
0xbf...0xb6	CONNECTION-ID-DATA [16 bytes]
Most of the packet is the certificate.  SESSION-ID-HIT is 0 since no
session ID was sent by the client.  After the 525 (0x020d) bytes of
certificate comes the 3 byte code for 40 bit RC4, then the 16 byte
connection ID.  The main importance of the connection ID data here
is that it helps to calculate the session keys as described below.
The next message, from the client to the server, is the CLIENT-MASTER-KEY
sent mostly in the clear:
0x80 0x55 0x02 0x02 0x00 0x80 0x00 0x0b 0x00 0x40 0x00 0x00 0x0e 0x89 0x94 0xb8
0xbf 0x0e 0xb9 0x2e 0x50 0x44 0x07 0x8c 0x52 0xeb 0xef 0x44 0xc1 0x01 0x4b 0xc1
0x02 0xd2 0x2e 0x37 0x1f 0x1d 0x54 0xc2 0x83 0x45 0x79 0x6b 0xc8 0xe3 0x85 0x17
0xb8 0xd4 0x84 0xc6 0x9f 0xb1 0x6a 0x03 0x2e 0x97 0xae 0x82 0x75 0x10 0xf0 0x7b
0x5f 0x25 0x7b 0x88 0x75 0xc6 0x7a 0x33 0x5f 0xd6 0x96 0x99 0x94 0xd0 0x7a 0x78
0xae 0x50 0x32 0x1a 0xbb 0x66 0x50 It is interpreted as follows:
0x80 0x55	Packet length, 85 bytes follow.
0x02		MSG-CLIENT-MASTER-KEY
0x02 0x00 0x80	CIPHER-KIND
0x00 0x0b	CLEAR-KEY-LENGTH-MSB CLEAR-KEY-LENGTH-LSB
0x00 0x40	ENCRYPTED-KEY-LENGTH-MSB ENCRYPTED-KEY-LENGTH-LSB
0x00 0x00	KEY-ARG-LENGTH-MSB KEY-ARG-LENGTH-LSB
0x0e...0x07	CLEAR-KEY-DATA [11 bytes]
0x8c...0x50	ENCRYPTED-KEY-DATA [64 bytes]
The 11 most significant bytes (88 bits) of "master key" information are
sent in the clear as the CLEAR-KEY-DATA.  The remaining 40 low-order
bits of the 128-bit master key are RSA encrypted using the server's
public key, expanding in the process to 64 bytes, and sent as the
ENCRYPTED-KEY-DATA.  No KEY-ARG-DATA is sent since RC4 doesn't need an
initialization vector.
Now that these packets have been exchanged, from this point on, all
packets are sent encrypted.  For each such packet, after the packet
length bytes there is a 16-byte Message Authentication Code (MAC).
Then comes the RC4 encrypted data itself.
Two different session keys are used, both generated from the master key,
the 16-byte challenge data, and the 16-byte connection ID data.  The
CLIENT-READ-KEY, used for data sent from server to client, is calculated
"0" is one byte of 0x30, ascii 0.
The CLIENT-WRITE-KEY, used for data sent from client to server, is
calculated as:
"1" is one byte of 0x31, ascii 1.
MD5 produces 128 bits of output which are used directly as the key input
to the RC4 algorithm.
The next message, from server to client, is SERVER-VERIFY.  It is sent
0x80 0x21 0x37 0x68 0x3a 0x8c 0x7d 0x33 0xb2 0x2f 0xb9 0x66 0xeb 0xd2 0x63 0xcd
0xa7 0xed 0x71 0xa0 0xb6 0x2f 0xb6 0xe2 0x31 0xa4 0x2a 0x81 0xd3 0x25 0x61 0x58
0xbc 0xf0 0xf4 This is interpreted as follows:
0x80 0x21	Packet length, 33 bytes follow
0x37...0xed	MAC [16 bytes]
0x71		RC4 encrypted MSG-SERVER-VERIFY (0x05)
0xa0...0xf4	RC4 encrypted CHALLENGE-DATA from CLIENT-HELLO message
The first RC4 encrypted byte is MSG-SERVER-VERIFY (which has a value of
0x05).  This is followed by 16 bytes of challenge data from the first
client message, encrypted.  These 17 bytes represent known plaintext
which can be used to easily check any guessed RC4 CLIENT-READ-KEY.
Let me make this a little more clear.  The first RC4 encryption with the
CLIENT-READ-KEY, immediately after key setup, is as follows:
Plaintext (MSG-SERVER-VERIFY plus CHALLENGE-DATA):
0x05 0xaf 0x84 0xa7 0x79 0xf8 0x13 0x69 0x20 0x25 0x9b 0x53 0xa0 0x60 0xae 0x75
0x51 Ciphertext (from SERVER-VERIFY packet):
0x71 0xa0 0xb6 0x2f 0xb6 0xe2 0x31 0xa4 0x2a 0x81 0xd3 0x25 0x61 0x58 0xbc 0xf0
0xf4 The next message in the protocol is CLIENT-FINISHED, sent encrypted from
client to server:
0x80 0x21 0xed 0x59 0x0a 0x2a 0x80 0x50 0x42 0xec 0xcd 0xed 0x6c 0x96 0x0a 0xab
0x5c 0x0e 0xed 0x55 0xc3 0x21 0x6e 0x34 0x26 0x5b 0x46 0x41 0x35 0x51 0xb7 0xaa
0xec 0x57 0x9f This is interpreted as follows:
0x80 0x21	Packet length, 33 bytes follow
0xed...0x0e	MAC [16 bytes]
0xed		RC4 encrypted MSG-CLIENT-FINISHED (0x03)
0x55...0x9f	RC4 encrypted CONNECTION-ID from SERVER-HELLO [16 bytes]
This is the first message sent encrypted with the CLIENT-WRITE-KEY and
could also be used as known plaintext to check a guessed key.
The next message is SERVER-FINISHED, sent encrypted from server to
0x80 0x21 0x79 0x84 0xc6 0xb6 0xde 0xf4 0x4c 0xd2 0x52 0x56 0xdc 0x58 0x23 0xa0
0xfa 0x4d 0x06 0x7d 0x4c 0x12 0x32 0x32 0xea 0xaa 0x5a 0xb6 0xa7 0xb8 0x1a 0x66
0xeb 0x65 0x56 This is interpreted as follows:
0x80 0x21	Packet length, 33 bytes follow
0x79...0x4d	MAC [16 bytes]
0x06		RC4 encrypted MSG-SERVER-FINISHED (0x06)
0x7d...0x56	RC4 encrypted SESSION-ID-DATA [16 bytes]
The SESSION-ID-DATA has not been previously sent in the clear.  It would
be used to cache the key info for a future session.
encrypted and packetized.  The first two bytes are packet length, then
16 bytes of MAC, then the data.
First data message from client to server.  Presumably it is an http "GET"
request, with form information embedded in the URL.  This is the main one
to try decrypting (starting with 0x6b as the first encrypted byte).
0x82 0xf8 0x07 0x97 0xef 0x99 0x66 0x45 0x48 0x22 0xe4 0xdc 0x31 0xe4 0xf9 0x0b
0xb9 0x98 0x6b 0x99 0x2a 0x09 0x29 0xae 0xa6 0x8d 0xbf 0xb0 0xd3 0xa6 0x83 0xec
0x69 0x1c 0xcc 0x11 0x66 0x84 0x21 0x77 0xfb 0x86 0x73 0x10 0xfb 0xa9 0xe3 0x3b
0x2f 0xd4 0x0f 0xb9 0xbd 0x3f 0xa4 0x0b 0x41 0xd5 0xc9 0x90 0x6d 0xa7 0x34 0x7a
0x5a 0xc1 0x69 0x8d 0xe9 0x64 0xad 0x0d 0xa8 0xae 0x91 0xd1 0xa6 0x70 0xac 0xf9
0xe6 0x11 0x38 0xa0 0xa7 0xd9 0x7c 0xc7 0x18 0x17 0xe2 0x0d 0x8d 0x30 0xb0 0x1c
0x22 0x25 0xa3 0x61 0xee 0xa2 0xca 0xe5 0xf8 0x20 0x5b 0xe1 0x58 0xcf 0xa5 0x21
0xe3 0x23 0xa6 0xfb 0xf6 0x2b 0xba 0x69 0xca 0xa3 0xe6 0x4a 0x47 0x4c 0x77 0xb8
0xc2 0x93 0x8e 0xb7 0x5d 0x17 0x06 0x57 0x19 0x6e 0x00 0x34 0xd6 0xc5 0x64 0x5e
0x23 0x60 0x03 0xf9 0xb2 0x9d 0xee 0xb4 0x83 0x28 0xae 0xfe 0xbb 0xb0 0xe3 0x49
0xfc 0x8f 0x68 0x24 0x51 0x03 0x26 0x8f 0x2b 0xcd 0xc1 0x0c 0x6d 0x79 0xed 0xc4
0x7f 0x3a 0x1e 0x2a 0xc5 0x4e 0xd8 0xe9 0x35 0x27 0xb7 0xde 0x50 0xc3 0xac 0x49
0x84 0x55 0x90 0xa6 0x44 0xcb 0xf7 0xfc 0x69 0xb4 0x19 0xea 0xb6 0xf0 0x72 0x37
0xef 0xfc 0xdf 0x20 0xaf 0x34 0x10 0xa8 0xf9 0xc2 0x74 0xa8 0x64 0xb2 0xd5 0xe9
0x25 0xd8 0xf2 0xca 0xf6 0xb6 0xa0 0x35 0x6f 0x3c 0x6c 0x4c 0xc6 0x99 0x4e 0x51
0xc4 0x5c 0x32 0x8e 0x0b 0x7c 0x59 0x7b 0xda 0x19 0x3f 0x89 0x7b 0xd3 0x33 0x9c
0x2d 0x20 0x46 0x59 0x26 0xb4 0x20 0x61 0x54 0x49 0xb8 0x71 0xa4 0xde 0x2b 0x7b
0xf3 0xdd 0xb2 0x64 0xa1 0x1a 0x39 0x4b 0x50 0x20 0x21 0x6a 0x9c 0x3d 0x34 0xaf
0x91 0xf4 0x2e 0xe1 0x4c 0x74 0x6a 0xed 0x4e 0x18 0x3d 0x11 0xe5 0xa9 0xf6 0x87
0xb3 0x7a 0xf0 0xf1 0x5e 0x9b 0x9c 0x1f 0xc0 0x44 0x72 0xdc 0xc3 0xe9 0x62 0x88
0x0b 0xec 0x3c 0x71 0x29 0x99 0xac 0xfa 0x1f 0x31 0xdd 0xae 0x5f 0x84 0x3c 0x16
0x04 0xdb 0x9d 0x4b 0xbb 0xdf 0x6c 0x32 0x0e 0xa0 0xe7 0xa0 0xdc 0x6a 0xa5 0x49
0x12 0xd7 0x59 0xce 0x3c 0x5d 0x36 0x46 0xbf 0x0b 0xcb 0xf7 0x0e 0x41 0x50 0x37
0x53 0xb5 0xdf 0x6d 0xc0 0x7e 0x7f 0x35 0x75 0xf5 0xec 0xad 0x40 0xb5 0x69 0x3c
0xb7 0x5c 0x44 0x0b 0x48 0xe6 0x07 0x41 0xb8 0x4c 0x9d 0x2c 0x4c 0xdf 0xf3 0xa7
0x15 0xcf 0x12 0xdd 0x11 0xcb 0xeb 0x3b 0x89 0x11 0x2e 0x6b 0x84 0x1a 0x3d 0xd9
0x25 0xa2 0x51 0xed 0xdf 0x93 0x76 0x86 0xc4 0xa4 0xcb 0xe8 0x5c 0xd8 0x7a 0x41
0x7d 0xc8 0x70 0xa1 0x0c 0xa1 0xd8 0xda 0xe2 0x75 0x05 0x0b 0x0b 0x83 0x3c 0x6c
0x71 0x13 0x42 0x19 0xcd 0x5d 0xd0 0x99 0x7b 0x24 0xc9 0x7b 0xc2 0x1c 0x2e 0x6e
0x78 0xe0 0xad 0x7f 0x7b 0x4b 0x50 0x33 0x7e 0xa0 0xb9 0x93 0xf4 0x75 0x39 0x50
0x41 0x41 0xe3 0x2b 0x0f 0xf1 0xf3 0xbc 0x84 0x9d 0x6f 0xa7 0x27 0xa7 0x58 0x55
0x8d 0xc7 0xf1 0xa1 0xb8 0x60 0x6f 0x0f 0x19 0xac 0xea 0xef 0x2c 0xba 0x90 0x9b
0x79 0x7b 0x61 0x54 0x03 0xf6 0x92 0x10 0xb4 0x9c 0x78 0x85 0xf3 0x7b 0x3f 0x0e
0xf9 0x8e 0x3d 0xa3 0x43 0xab 0xf4 0x33 0xa4 0x55 0x4b 0x86 0x50 0x75 0x93 0x3a
0x50 0x24 0xae 0x70 0x0c 0xde 0xa7 0x52 0x28 0x43 0x07 0x35 0x5c 0x5a 0xeb 0xc0
0xe1 0xba 0x8c 0xcd 0x76 0xdc 0x07 0x1f 0xa4 0x57 0xdd 0x18 0xa3 0x4e 0xc3 0xf3
0x7b 0x2d 0x0e 0x6b 0xb9 0x92 0xc1 0xfb 0x54 0xc8 0xd7 0x33 0x31 0x43 0xe1 0xce
0xb5 0x89 0xbd 0x0d 0x4e 0x14 0xbc 0x64 0xc5 0xf6 0x28 0x58 0x84 0x64 0xe7 0x8c
0xb2 0xa9 0xd2 0x0b 0x9f 0x1c 0x28 0xfd 0x95 0x93 0x8e 0x51 0x9a 0x5b 0xeb 0x0d
0x51 0x60 0x93 0x35 0x7c 0x59 0x7d 0x6f 0x37 0xbd 0xa4 0x9b 0x2d 0x4f 0x75 0x92
0xbe 0x85 0xc6 0xc3 0x68 0xf6 0x41 0xcc 0x51 0x4c 0xfc 0xda 0x21 0xc3 0x77 0xc1
0xe2 0x79 0xe8 0x0d 0xc7 0x26 0xc3 0x14 0x9e 0x48 0x2f 0xa4 0x95 0x21 0x24 0x61
0x31 0xd5 0x3b 0x14 0x42 0x45 0xd1 0x6d 0x90 0xfe 0x72 0x28 0xa7 0x81 0xe9 0x07
0x47 0x8a 0x0d 0xda 0x08 0x99 0xbc 0x76 0x42 0xec 0x0b 0xfd 0xeb 0x69 0x47 0x58
0xd7 0x81 0x6b 0x71 0xf6 0xb6 0xbe 0xcd 0x4e 0x29 0xd9 0xdb 0xc8 0x12 0x5c 0x46
0xa0 0x3c 0x5b 0x57 0x2b 0x59 0x92 0x36 0x3c 0x6a 0xc3 0x4a 0x13 0x41 0x34 0x2f
0x12 0x13 0xa2 0x51 0xfb 0xf2 0xe0 0x0b 0x2f 0xfc 0x14 0x25 0xad 0x60 0x3a 0x35
0x62 0x7e 0xd2 0x11 0x4c 0x4a 0x29 0xa4 0xca 0x44 This is the first data packet response from the server:
0x80 0x84 0x16 0xc9 0xe0 0x80 0xd6 0x0b 0x4e 0xd8 0xfe 0x00 0xce 0xe2 0x07 0xe1
0xec 0xb9 0x03 0xa8 0x51 0x0b 0xc9 0xd5 0xd9 0x27 0x59 0x07 0x83 0x0c 0x2b 0x75
0x24 0x50 0xcf 0x0c 0xd2 0x8e 0x7b 0xbc 0xbe 0x65 0x48 0x23 0xc9 0xdb 0x82 0x2f
0x54 0x50 0x3b 0xf2 0x50 0xd3 0x15 0x30 0xec 0x78 0xa2 0x61 0x09 0x9a 0x2a 0xc8
0x9c 0x07 0x67 0x70 0x44 0x46 0xca 0xe4 0x65 0x1a 0x0e 0xd9 0x2a 0x77 0xeb 0xc1
0x7e 0x37 0x83 0x43 0x2e 0x26 0xde 0x5f 0x9d 0xa3 0x31 0x87 0xf2 0xe1 0x4f 0x67
0x8d 0xfc 0x4f 0x3f 0x00 0x2c 0x40 0x70 0x34 0x2b 0x62 0x80 0xcf 0x0d 0x93 0xff
0xc9 0x5e 0xd2 0x21 0xf6 0xa4 0xf4 0xd7 0x13 0x13 0x59 0x44 0x6c 0xd1 0xd1 0x05
0x8f 0x5f 0x15 0x10 0x08 0xed Here is the second data packet response from the server:
0x81 0x04 0xc9 0x4c 0x54 0xcb 0x2c 0xe0 0x8e 0xf9 0x13 0x31 0xb4 0xf1 0x82 0x92
0xd3 0x65 0xc9 0x45 0x7e 0x0f 0x8e 0x54 0x4f 0x7f 0x35 0xc8 0x20 0xa8 0x55 0x18
0x1e 0x27 0x5d 0x6a 0x53 0x79 0xd2 0x2e 0x01 0x5d 0x06 0x25 0x6f 0xaa 0x49 0x68
0x73 0x4e 0x35 0x6b 0x87 0x47 0x6d 0x26 0xb6 0xb0 0x1e 0xd0 0x96 0xd5 0xe6 0x4f
0x94 0x10 0x9f 0x5f 0x83 0x7e 0x0c 0x67 0x36 0x82 0xce 0xcb 0xb1 0xd5 0xc9 0xf9
0xf5 0x32 0xa9 0xf3 0x31 0xbf 0x40 0xe4 0xa6 0x24 0x0e 0xc3 0xfe 0x61 0x24 0x59
0x9d 0x85 0x35 0x0d 0x7d 0xbe 0x16 0x0b 0x8a 0x98 0x74 0x7b 0x5a 0x37 0x73 0x30
0xd9 0x66 0x6c 0x65 0xaf 0xd4 0xc7 0x2a 0x8f 0x14 0xe3 0xf6 0x06 0x63 0x19 0x53
0xc5 0x9a 0x69 0x63 0x29 0x04 0x7a 0x28 0x0e 0x7b 0x17 0xf3 0x60 0xee 0x9d 0xbd
0xe5 0x00 0x0a 0x9d 0x1b 0xc5 0x26 0x93 0x19 0x78 0x43 0x2f 0xe4 0x9a 0x27 0x3c
0x13 0x03 0x9c 0xab 0xad 0xad 0xe1 0xbd 0x8b 0x7c 0x04 0x74 0x7e 0x08 0x50 0xa6
0x19 0x28 0xb7 0x6c 0xbe 0x2b 0x48 0x14 0xd2 0xcb 0xa6 0xad 0x69 0x41 0x31 0x93
0x3a 0x8d 0x87 0x78 0x80 0xc1 0x85 0xa5 0x7a 0x79 0xd1 0x55 0xca 0xb8 0x94 0x0b
0x65 0x3e 0xf2 0x51 0x8d 0xae 0x89 0x87 0x96 0xae 0xd5 0x4d 0x2f 0x14 0x66 0xe6
0xcc 0x63 0x2f 0x50 0x98 0x98 0x59 0xfa 0xf6 0xeb 0xb6 0x44 0x9d 0xc2 0x6c 0xe2
0x7d 0xc9 0x47 0xfa 0x3d 0xa4 0x6b 0x71 0x52 0xcc 0x15 0xdf 0xb3 0x92 0x3f 0x67
0x8e 0x9e 0x84 0xd6 0x39 0xa0 This ends the communication.
To try to attack this, the most effective approach would be to calculate
CLIENT-READ-KEY by trying all possible values for the 40 least
significant bits of the MASTER-KEY, and feeding that into the MD5
formula.  Then use the known plaintext in the SERVER-VERIFY message to
check the result.  Once the proper 40 bit value is found,
CLIENT-WRITE-KEY can easily be calculated and the data messages
Good luck!
Hal Finney
hfinney at shell.portal.com

@_date: 1995-07-13 12:46:37
@_author: Hal 
@_subject: SSL RC4 challenge 
It has been pointed out to me that I made a mistake in my analysis of the
SSL packets.  The MAC at the beginning of the encrypted packets is itself
RC4 encrypted.  That means that the 17 bytes of known plaintext start 16
bytes into the stream, not at the beginning as I thought.  This just
means that after key setup, RC4 has to be cycled 16 times before we start
comparing its output with the XOR of the known plaintext and ciphertext.
I'll produce a revision of my "challenge".  If no other mistakes are
found I'll post it to sci.crypt.

@_date: 1995-07-19 22:53:50
@_author: Hal 
@_subject: Netscape the Big Win 
I also agree that Netscape and similar browsers are a good target for
crypto applications.  I am working on a program (tentatively called
webcloak) which runs on your PC next to your browser.  You set the
proxy in the browser to point at this program.  This is a dialog box in
Netscape and I think most browsers have this support.  Then all of your
communications go through this program.
Unfortunately progress has been slow as I have been having to learn
Winsock programming and re-learn Windows programming.  But I do have a
dummy program working which will pass commands through.  It does not
encrypt anything yet but simply redirects commands to a web proxy running on
the net.  Soon I will work on adding encryption, but the next step is to
add dialog boxes to choose the web proxy to use.  Right now it is hard
coded in.
Someone posted recently that the formerly open web proxy at
 is no longer responding.  Also, a list
member was running one for a while at but that is no longer working either.  I have been looking for proxies by
searching the incoming connection logs on this commercial system.  I
figure that some of the more frequently appearing hosts may be proxies.
I telnet to them on port 80 and type "GET   This is
just a URL I use because it is short.  Usually nothing happens but I have
found a couple of proxies that still work.  At this point I don't want to
publicize them because they might be shut down as a result.
I think running open web proxies (and another kind of proxy I will
describe in a future message) will be a good thing for Cypherpunks to do.
I know not everyone can do it; it takes more privileges and clout to keep
a server running than to drop in a mail filter.  But for those who do
have the ability to leave background processes running I think these will
be the remailers of the future.  I hope some list members will start
doing this.
As another solution, I have developed a Perl script which anyone who can
run CGI scripts can use to become a web proxy.  Fortunately (and somewhat
mysteriously) this commercial system lets me do that.  Basically if you
want to connect to  you instead connect to
  The
name of the CGI script and "?" is prepended to the desired URL.  The
script then receives the part after the "?" as its argv so it opens the
URL and passes it back.  So if you can't run a server but can install CGI
scripts then you can run this "poor man's proxy".
Unfortunately the standard proxy protocol will not work transparently
with this; the CGI script and "?" pasting isn't done automatically by
browsers.  However my PC "webcloak" program does work with this kind of
proxy; it pastes the required prefix string at the front of each URL.  So
if people do start using this approach the CGI proxies may be part of the
Soon I hope to be far enough along to ask people to start testing some of
this software.  Once I get the webcloak program able to be reconfigured
by the end user I'll ask people to try it to see if it works on anybody
else's PC than mine.  It should hopefully work with anything that uses
Eventually I hope to see a lot of people running web proxies and privacy
proxies (which just pass requests through to other web and privacy
proxies - these are very simple connection redirectors, but do encryption
and decryption for privacy).  The end user can connect to a web site and
update his list of proxy servers.  Then when he fires up his local proxy
interface program it can ping the various servers and print a summary of
their response times.  He clicks on the ones he wants, setting up a
chain.  Only the last one in the chain needs to be capable of proxying
http requests, the others just pass data through.
The local program connects to each of the proxies and negotiates a
session key using PK encryption.  This will be cached and used over a
moderately extensive period of time, at least a few minutes.  We can't
possibly do a PK decryption for each link in a proxy for every .gif file
in a page.  That would be too slow.  So instead it will just send a cache
identifier to indicate which encryption key is in use.
This is all pretty ambitious as you can see, but I am trying to do it
incrementally.  Even a basic system without encryption and where the user
has to edit a text file to choose his proxy chain will provide some
privacy protection.  So I hope I will be able to interest people in
providing the infrastructure needed for privacy protection on the Web.

@_date: 1995-07-20 07:54:57
@_author: Hal 
@_subject: Netscape the Big Win 
Unfortunately the main alternative to SSL being pushed now, SHTTP, also
suffers from RSA-itis.  It will support either PEM or PKCS-7 key
certificates, so I think ends up being pretty much the same as SSL in
this regard.
Note though that neither SSL or SHTTP requires that the certificates come
from RSA.  However the current versions of Netscape's browser do require this.
This has been the source of much complaint and Netscape has promised that
they will have some mechanism in the future to allow the user to
choose his certificate signers.  I am not sure how far RSA will let them
off the leash, though.
The current version of SSL supports client authentication (via X.500
certificates of course).
rsalz at osf.org writes re SSL:
I'm not sure what this is getting at.  SSL does use a separate RC4 stream
for each comm half.  Is this a suggestion that a single key should be
used for both directions?  There are two ways that could be done: keep
separate state info for each direction, in which case you are encrypting
data twice with the same pseudo-random string, a definite no-no; or try
to keep a single global state for the cipher, but this is impossible due
to the (potentially) asynchronous nature of the communications.
Back to Perry:
That is why I am working on the proxy approach.  Any browser should be
able to use enhancements supplied in this way.  Netscape is the big name
this year, who knows who it will be next year.  As long as IP
connectivity is available a proxy can get into the stream and apply

@_date: 1995-07-20 10:23:43
@_author: Hal 
@_subject: Netscape the Big Win 
It appears that support for PGP messaging has been removed from the
July 1995 SHTTP draft.  So it's X.500 all the way.
Frankly I don't think SSL is particularly weak cryptographically.  It has
gone through several revisions as various problems were pointed out.
The one thing I would note is that there is considerable known plaintext
being exchanged in the handshake.  This helps with key guessing and will
be the foundation for the SSL challenge that Adam Back is organising.
IMO at least some of this material could have been sent encrypted with
the public key so that an eavesdropper couldn't know it.  OTOH this
might have run afoul of the NSA's rules on export for at least the 40 bit
version since you'd have more than 40 bits of secrecy in effect.
SSL includes a 16 byte checksum with each packet.  IMO this is overkill
and wasteful for small packets.  One thing about SSL is that it
provides both secrecy and immunity to certain kinds of active attacks.
These big checksums include a sequence number and key information to
prevent replay attacks.  For some purposes you might be satisfied with
secrecy and not want to pay this overhead.
I think a lot of the criticism of SSL was based on the thought that it
would be obsoleted by the new IP secure protocols.  That may be true
eventually but SSL is here today, in use.  Order something from
Netscape and it is secured with SSL.  Buy the domestic version if you
want real security.  For IP, many of us we will have to wait until
the new IP protocols get built into our OS's and other infrastructure.
People have also objected to the use of the X.500 certificate approach.
But that seems to be de rigeur for any serious Internet standard these
days.  IMO the real solution is to come up with a PGP-like X.500
certificate maker so people can easily set themselves up as Certificate
Authorities and go about their business while the anal hierarchy
fans argue about liability.  Actually I think there is a PD certificate
maker around, possibily from Eric Young down under.

@_date: 1995-07-20 16:46:31
@_author: Hal 
@_subject: Java (was Netscape: the big win) 
So, what would be a "cypherpunk" thing you could do with Java?  I know
I can use it to download little applets to my system to do animations.
What can it do to enhance my privacy?  What would be the Java equivalent
of PGP?

@_date: 1995-07-21 10:28:50
@_author: Hal 
@_subject: Netscape the Big Win 
I agree with this general approach, but I looked into it in some detail,
and SOCKS has a fatal flaw for my purposes: the address to connect to is
passed as an IP 32-bit address.  That means the software on the PC
has to do the DNS lookup.  And *that* means that the ultimate site being
connected to is revealed.
One of my goals is to protect the secrecy of the sites that a person is
browsing.  If an in-the-clear DNS lookup is done for each site that will
hardly be effective, even if the actual connection request is encrypted.
An eavesdropper on the internet will be able to observe the DNS lookup
Now SOCKS V5 is going to change this; it allows the proxy to receive the
request as a hostname rather than an IP address.  So no DNS lookup is
necessary by the client.  Conceivably a modified winsock such as Enzo is
suggesting could use that protocol, although it is not really stable
Also, I don't know how easy it is to intercept winsock calls and modify
them in this way.  So the proxy I have written works using the HTML proxy
hook rather than the SOCKS hook.
This sounds very good if it already is almost working.  The TCP
connection which is opened would have to be to a server on the local
machine, so it would be important that the software support that.  Also,
the local SOCKS relay would of course not want its winsock calls to be
intercepted and translated in this way, so there would need to be some
alternative way to access "vanilla" winsock.  Can you give any
more information on the NEC work?
For chaining purposes you would connect to the relay on the net on the
secure port and request a TCP connection (not a SOCKS connection) to
the second relay in the chain at its secure port.  Then you negotiate a
secure connection from your home PC to that second relay so that the
traffic you send to it won't be visible to the first relay.  Once that
is done you send a SOCKS request to that second relay to connect to the
next machine in the chain.  So really only function (a) is needed for
the relays on the net.
The relay on the PC needs to be able to do (c), but more importantly it
needs to be able to set up encryption chains, where every outgoing packet
is nestedly encrypted, with the outermost encryption for the first relay
in the chain, the next layer for the next relay, and so on.  Each relay
decrypts and strips off one layer, then passes the remaining raw data
through.  This way no one relay knows who is talking to whom or what they
are saying.  The reverse happens for return packets.
I have written a simple dummy relay for winsock and it requires a pretty
different programming style than for Unix.  Netscape has a habit of
firing off a bunch of requests at once, so it has to be extremely
asynchronous.  For Windows this means you get a windows message every
time a packet arrives and use non-blocking I/O.  In Unix this is usually
handled by forking a new process to handle each independent connection.
Non-blocking I/O can be used in Unix but I don't think there is a
non-blocking connect as there is in Windows.  Maybe Windows 95 will allow
a more Unix-style communication model, though.  Should the proxy require
Windows 95, or will Windows 3 still be in widespread use for another
year or two?
Also IMO the requirements for the Internet relay are pretty different
than for the Windows relay.  The Internet relay needs only to be able to
decrypt/encrypt on the port where the request comes from while sending
plain data the other way.  It needs a config file so the owner can
control what kinds of outgoing TCP connections can be done.  The Windows
one needs to be able to do nested encryption (if chains will be allowed
eventually), to set up chains, etc.  So for these reasons I am inclined
to think that the two relays would be separate programs.
The Windows version would need to decrypt incoming data; you don't want
that coming in the clear.
The other problem with Netscape SSL is that it will only open secure
connections to URL's marked "  Similarly SHTTP has a special
URL "s  There is no provision in either one to open a secure
connection to "  A relay proxy would allow all connections to be
encrypted between the PC and one or more relays.
I am a little unclear on the certificate situation.  As we saw with the
PGP key servers before RSAREF PGP existed, RSA put pressure on these
public sites which they saw as contributing to the use of infringing
software.  Similarly having a certificate created by infringing software
might be seen as illegal, even if RSAREF was actually used for the
handshaking in the protocol.  Server operators are quite vulnerable to
threatening letters from RSA.
Another problem with RSAREF is that it does not allow you to exchange a
session key using RSA encryption in a straightforward manner.  The entry
points you have legal access to choose a random session key, PK encrypt
it, send it, and then encrypt the message using that session key with DES
or 3DES.  However I notice that SSLREF calls undocumented entry points
like RSAPrivateDecrypt and RSAPublicEncrypt.  I am not sure how they are
able to do this.  Maybe they got special permission from RSA.  I don't
know whether the SSLEAY library would be able to do this without such
special arrangements.
Yes, really there is no need to make it be SSL specifically except for
the fact that it is an explicit protocol for which libraries exist.
Yes, I think the overall approach is very promising.  Perhaps my desire
for chaining is too ambitious for a first attempt.  The transparent
intervention of SOCKS that you describe would be very nice if that is
available soon.
One other problem is the risk taken by people running the relay servers
on the net.  These could be used to launder connections by hacker /
cracker types.  So probably only a limited set of outgoing ports would be
permitted, say, 80 and 1080 which are the most common http ports.  This
would restrict the utility of the SOCKS approach for other uses like
secure telnet, unfortunately.

@_date: 1995-07-27 09:38:18
@_author: Hal 
@_subject: Full text of David Chaum's Congressional speech 
I believe this will work, in most blinded-ecash systems.  Another way to
express it is you force the user to withdraw cash such that it comes into
your wallet.
There are some technical counter-measures though.  One is to have some
secure tamper-proof hardware which enforces certain kinds of ecash
transfers.  The above transfer would not be a legal one.  Only transfers
which would allow various forms of traceability would be allowed.
Another approach was described by Chaum in one of his papers.  I can't
remember the details, but basically the user had to go through a
preliminary transaction with the bank when he opened his account, to get
a whole lot of tokens which would later be turned into ecash.  He has to
get a lot of them because these will be for all the ecash he will use for
a whole decade (or whatever).  Then the withdrawal protocol is one which
turns a token into an ecash value.
The result of this approach is that the blinding is in effect fixed in
advance and there is no way to force different blinding under duress.  I
posted more detail on this to the list sometime last year but I don't
remember when unfortunately.
Note of course that this whole traceability business only works if you
have to identify yourself to the bank whenever you deposit the money.  If
someone allows anonymous banknote exchange then the whole "advantage"
goes out the window.  IMO payee anonymity will be a desired feature of
ecash systems and I think Chaum is making a mistake claiming that it will
not or should not exist.
Another quibble is that blackmail is not a good example.  The payor
doesn't want to blow the whistle on his blackmailer; the blackmailer is
doing the payor a favor by giving him the option of paying money rather
than having the damaging information revealed.  Often the payor will know
who the blackmailer is.

@_date: 1995-11-03 00:34:44
@_author: Hal 
@_subject: ecash remailer 
It's very frustrating to have to speculate so much due to the lack of
information.  Imagine how we would react if Cybercash or Netscape had
gone forward with what they claimed were secure protocols but had
refused to publish them, referring simply to old papers on RSA and
DES.  Yet Digicash gets away with this.
We presume it works basically like this, but there could be elaborations.
In particular, I have heard (from people who claim to know) that the
payee is normally embedded into the coin at spending time.
Doing this would require the payee to be known at withdrawal time, which
is not apparently how it works.  I would speculate that actually what
happens is that the "basic coin" as above is encrypted, along with the
payee identity, all under the public key of the bank.  This was the
identity could not be stripped out by the payee or by a thief who snooped
the transmission.

@_date: 1995-11-09 09:35:07
@_author: Hal 
@_subject: ecash speed 
A few days ago I got my ecash account set up with the Mark Twain bank.
Presently only one merchant is officially listed at , Delorie Software.  As I understand
it, only people with merchant accounts are eligible to be listed here.
However, you don't have to have a merchant account to receive ecash or to
set up shop software.  If anyone else has set up a shop to receive Mark
Twain ecash using a user account, perhaps they could post here and we
could keep a list of unofficial vendors.
The other thing I wanted to write about is ecash speed.  One idea people
have had is to use ecash for micropayments, such as one cent to read a
web page.  The question is, is the current ecash software sufficiently
fast for this?  Maybe someone could set up a site using either Twain ecash
or DigiCash ecash which actually charged you a penny for each page you
browsed around.  It would be interesting to see how much of an obstacle
it presents in browsing the web.  The impression I've had from the few
times I've used ecash is that in fact it does slow things down way too
much for this to be practical.  But it would be good to actually do the
One reason I was thinking about this is reading a new paper by Rivest and
Shamir, .  It
is about a couple of proposed systems for micropayments, specifically
oriented towards the penny-per-web-page model.  They are offline systems,
designed so that a minimum of calculation is done by the vendor, user and
bank.  So they should be very efficient.
However, the big problem is that they are not anonymous.  The cash
tokens are recognizable by the bank when spent tokens are sent in by
the vendors - the bank knows who spent them.  Maybe for penny level
transactions that is not a big deal, although if for-pay web browsing
becomes common then it does seem like it would present a privacy
threat.  Every web site you visit (not the specific pages, but the
overall site names) would be known by the bank - quite a significant
piece of marketing data.
The point is that if the anonymity afforded by ecash is too costly in
terms of time, then we may end up stuck with a non-anonymous system
simply because that is the only one efficient enough to work.  It would
be good to find out if that is a serious problem.
Hal Finney

@_date: 1995-11-09 23:44:42
@_author: Hal 
@_subject: Pegasus Mail 
Even if he were in the US, I would hope that no one told him that.  One
of the elements of the offense of violating the arms export control act
is that the violation be willful.  The exporter has to violate a known
legal duty not to export the item.  One of the reasons for this is simply
that the ITAR list is long and technical and average individuals cannot be
expected to know all its details.  This is mentioned in the Lizarraga
case, at approximately 541 F2d 828:
"Two features of 22 USC 1934 strongly indicate that Congress used the
term 'willful' to require a showing of specific intent.  First, the
statute prohibits exportation of items listed by administrative
regulation, not by the statute itself.  Second, upon referring to the
pertinent regulation, 22 CFR part 121, we find that the regulation
contains an exhaustive list of items including amphibious vehicles,
pressure-breathing suits, aerial cameras, 'privacy devices,' and
concealment equipment (including paints).  Unlike those substances which
are known generally to be controlled by government regulation, such as
heroin or like drugs, these items might be exported or imported
innocently.  Under such circumstances, it appears likely that Congress
would have wanted to require a voluntary, intentional violation of a
known legal duty not to export such items before predicating criminal
So in this case I think widespread publicity about the ITARs can be
considered harmful.  All those helpful people going around warning others
that they are exporting software are actually removing a defense against
charges of export.

@_date: 1995-11-10 02:34:18
@_author: Hal 
@_subject: New patent rules 
Reading the latest Foresight Update articles in the sci.nanotech newsgroup,
I came upon an analysis of upcoming changes to the patent laws.  With
the signing of the GATT treaty the laws will change next year.  here
is one of the changes, quoting from the article:
    Infringement. Present U.S. patent law grants to a patent
    holder the right to exclude others from making, using, or selling the
    patented invention in the United States.  After about January 1, 1996,
    a patent holder has the right to exclude others also from offering for
    sale patented products or products made using a patented process.
    Thus, under the law as amended, the mere offer for sale of a patented
    product may be treated as an infringing act.  In addition, it will be
    illegal to import a product covered by a U.S. patent.
At first I thought this would not have much impact on crypto software,
which is of course heavily patented.  The current laws already prevent
people from making, using, or selling software which uses patented
algorithms.  The new restrictions on products made using a patented
process would not seem to be relevant.
But there is a possible interpretation which would be very significant.
What if data which has had cryptographic transformations applied were
viewed as a product of a possibly patented process?  An RSA-signed or
-encrypted message might then be such a product.  A blinded coin or other
credential, a key signature or certificate, virtually all of the things
we are interested in could be thought of in those terms.
We have occasionally discussed setting up offshore servers and such to
perform patented cryptographic algorithms.  But if the resulting data
is itself illegal to import, that would make this strategy much more
difficult.  Would it become illegal to "import" messages from
non-RSAREF versions of PGP, or to hand someone a Chaum-type cash token
issued by an offshore bank in a jurisdiction where his patents don't
I wonder if the lawyers on the list have any thoughts about whether such
an interpretation of the GATT rules is likely to stand.

@_date: 1995-11-10 10:17:22
@_author: Hal 
@_subject: ecash speed 
Consider, though, what happens in the current ecash system if it were
used to charge a penny per page.  You would click on a link in your web
browser to go to the new page.  It would set the GET request to the
remote server as usual.
The server would fire up a CGI script which will run the shop software.
That software will make a TCP stream connection back to your ecash wallet
software which is running on the system where your client is.  It sends a
request to get payed $.01.  Assuming the wallet is configured to
automatically approve such a payment, it will send a one penny coin to
the shop software along the opened link.  (This may also involve doing a
PK encryption on the coin as an anti-theft measure; this aspect of the
current ecash system is not documented AFAIK.)
The shop software then opens a TCP stream connection to the bank, and
forwards the coin there.  The bank receives it, and checks the public
key signature in the coin.  It then compares the coin against every other
coin which has ever been spent (within the validity period of the coin)
to make sure it is not being doubly spent.  If this all checks out it
sends back some authentication message to the original server.  The shop
software then delivers the new page to the client browser.
This all has to happen whenever you click on a link in your browser.
Even with fast CPU's I think the extra step of connecting to the bank,
having it check against all coins, and getting approval will be
considerable for each link traversal.

@_date: 1995-11-16 10:07:03
@_author: Hal 
@_subject: Anonymity and Intellectual Capital 
Here is a draft article by David Post of Georgetown Law Center.  He
offered it on the Cyberia list and it includes permission to
redistribute.  I thought it had some interesting ideas on anonymity and
pseudonymity, as well as our old bugaboo "reputation capital".  I have
reformatted it slightly to improve readability but made no changes to the
Pooling Intellectual Capital: Anonymity, Pseudonymity, and
Identity in Cyberspace    DRAFT OUTLINE
October 31, 1995
David G. Post [NOTE 1]
whether or not to regulate the availability of "untraceably anonymous"
messaging functions -- anonymous remailer services and the like -- and
the related question of how, in the special circumstances of
cyberspace, one might accomplish such regulation).  To be sure, this is
an important perspective; although we are embedded in a world in which
anonymous transactions are pervasive, we have never before been able to
manipulate anonymity, or to undertake as wide a range of anonymous
transactions, as cyberspace allows us to undertake (and we have,
therefore, only begun to think about the implications of being able to
do so).  At the same time, however, the technology offers, it would
seem, new prospects for eliminating anonymous communication, i.e., for
requiring (and enforcing the requirement for) completely "traceable"
     We need, in the first instance, to understand more about the costs
and benefits of anonymity in this new environment before we can
sensibly talk about the best way to regulate it (or whether to regulate
it at all).  Harms associated with an anonymous messaging  regime
include, notably, the inability of "law enforcement" (broadly defined
to include both public and private enforcement) to obtain information
on persons responsible for harm perpetrated by individual actors;
benefits include the ability of individuals to engage in communicative
activity without putting any aspects of their "identity" at risk (see
below for additional discussion of the reasons for the quotation marks
between anonymity and pseudonymity in cyberspace, new elements need to
be added to this equation -- primarily on the benefits side.  This
requires disentangling, at the outset, three related concepts:
anonymity, pseudonymity, and traceability.  We can define an
"anonymous" communication as one in which the message itself contains
(and hence the recipient of the message receives) no information
regarding the identity of the sender.[NOTE 2]  Although there can be
truly anonymous messages even in this strict sense -- messages
containing no information about the originator -- it makes more sense
to talk about anonymity as a continuous rather than a binary attribute
(present/absent) of messages:  even messages we ordinarily think of as
"anonymous," after all, contain some information about the author
(e.g., graffiti scrawled on a subway platform informs us that the
author was literate, and was geographically located in a certain place
within the last x months/years, all of which probably effects a
significant reduction in the reader's uncertainty about the identity of
the author by ruling out the vast majority of individuals in the world
as possible authors).
     Messages, however, rarely contain a fixed amount of information
about the sender's identity; [NOTE 3] the degree to which a message may
be considered "anonymous" is rarely (if ever) an inherent
characteristic of the message itself.  Relevant information about the
originator's identity may well often be available, but only at some
additional cost.  For example, an "anonymous" note slipped under the
door may be covered with fingerprints from which, were we able easily
to access both a fingerprint reader and the FBI's fingerprint database,
we could obtain significant information about likely originators.
"Traceabililty" measures the cost of obtaining information about the
identity of the sender in addition to the information that is "readily
apparent" -- i.e., obtainable at (virtually) no cost -- from the
message itself.[NOTE 4]
that contains information (of varying reliability, to be sure) about
the identity of the originator -- the cognizable entity responsible for
transmitting the message -- without simultaneously providing
information about the actual, biological, individuals responsible for
transmission of the message.  Pseudonymity, like anonymity, shields
aspects of the identity of the "real" actor from view; information that
a book was written by "Mark Twain" by itself gives you no more (or
less) information about the true identity of the author than does the
information that it was written by "Anon." Indeed, if Samuel Clemens
had chosen to publish each of his novels under a different pseudonym,
that would have been the essential equivalent of publishing all of the
novels under the pseudonym "Anon.," or "John Doe." Pseudonymity allows
each message to carry additional information, cumulative over time,
about the pseudonymous actor; i.e., the difference between pseudonymity
and anonymity is that the former, but not the latter, allows the
accumulation of reputational capital in the pseudonymous entity.  The
use of the a single pseudonym "Mark Twain" allowed Clemens to invest a
single entity with reputational capital, built up over time and across
different novels; "Anon." will not serve that purpose, primarily (if
not exclusively) because it is unprotected and used by any number of
other authors (many of whom might not be quite as talented as
Clemens).[NOTE 5]
individuals to act without putting at risk any aspects of their own,
personal identity (including their physical assets, reputational
capital, financial capital, and the like); pseudonymity differs,
however, from anonymity in that it allows the accumulation of
reputational capital in the pseudonymous entity.  Both anonymity and
pseudonymity are thus forms of "limited liability," and the extent to
which they serve that function effectively is determined, in both
cases, by whatever traceability requirements are imposed.  To
illustrate, take the extreme case, e.g., a requirement that all
messages contain certain information about specified aspects of the
originator's "identity."  This would not only eliminate anonymous
messages (at least to the extent it could be enforced), but it would
make certain forms of pseudonymity effectively unavailable as well; the
reputational capital belonging to "Mark Twain" and to "Samuel Clemens"
would be identical, and whatever aspects of Clemens' identity had to be
revealed would no longer be shielded in the course of any transactions
in which "Mark Twain" was involved.
     Most discussions of "the regulation of anonymity in cyberspace"
are really discussions about traceability requirements.  The potential
benefits and harms that accompany an anonymous messaging regime are
directly related not to the availability of "anonymity" per se, but to
the availability of untraceable anonymity.  I know of no serious
proposals, for example, to prohibit individuals from leaving their
electronic mail messages unsigned; the hard questions all concern the
nature of the traceability requirements that will be put in place in
regard to those messages, i.e., how easy or difficult will it be for
the recipients of such messages, third parties, or law enforcement
officials, to obtain additional information about the identity of the
message originator.
possibly a profound impact -- not merely on the availability of
anonymous communication, but on the availability of pseudonymous
communication as well. For example, a sufficiently high degree of
traceability eliminates both anonymous and pseudonymous messages;
requiring all authors to provide information about their "real"
identity not only makes it impossible for them to communicate
anonymously, it is, in effect, impossible for them to communicate
pseudonymously as well.  Analyzing the consequences of a "ban on
anonymity" in cyberspace needs to take more than the benefits and costs
of anonymous messaging into account; it needs to be evaluated in light
of the benefits and costs of pseudonymous communication as well,
considerations that have received less attention from those looking at
these questions. So the question "what is the best traceability
requirement to apply to electronic communication" needs to consider not
only the harms and benefits flowing from anonymous communication but
these additional considerations as well.
machine-mediated -- i.e., because the "identity" of the relevant actors
in a biological sense is necessarily at one remove from the
communication itself -- everyone acts "pseudonymously," at least in the
sense that you can only be identified by a stream of bits when you act
in cyberspace [NOTE 6].  The prospect for more creative uses of
pseudonymous action -- the ability for individuals to pool their
individual intellectual capital with great flexibility and with very
low start-up or transactions costs, into a wide range of new kinds of
actors and entities, each capable of accumulating reputational capital

@_date: 1995-11-21 07:38:23
@_author: Hal 
@_subject: Anonymity and Intellectual Capital 
The analogy between corporations protecting physical capital and
anonymity protecting intellectual capital is interesting, and I will
write a bit about it here.  I don't think it quite works in all ways but
it does suggest some ideas.
Capital, as I use the word, means stuff which helps you be productive.
Money can be physical capital, as can machines, computers, and so on,
but generally not consumer goods.  Traditionally, intellectual capital
by the same definition refers to training, knowledge, experience,
education - those mental skills and characteristics which help you
produce.  We have sometimes extended this notion here to reputation
capital, which we often use just to mean your reputation itself, your
good name.  But if we are going to call it "capital" it should really
be those aspects of your reputation which lead to productivity.  To the
extent that your good reputation helps you accomplish your productive
goals, it can be considered capital.  Particularly if you are a manager
or performer in some other position where people's opinions of you make
a big difference in how much you get done, you have a lot of reputation
capital.  Business reputations have many of the characteristics of
capital, too.
For some uses of anonymity it does make sense to think of them as
protecting reputation capital.  If you are going to send a message which
carries a risk of harming your reputation, perhaps because it is terribly
stupid or harsh, then anonymity can protect you in that way.  I think
some people do communicate anonymously for this reason.  However there is
another motivation, too, and that is fear of physical consequences.  Some
anonymous messages might lead to lawsuits or retribution in other forms,
such as firing or blackballing.  There is more involved in these cases
than just loss of reputation capital.  Physical capital is involved as
well.  So this is one way in which I think the analogy does not work.
Another difference relates to the number of people involved.  As I
understand it, the motivation for the corporate veil of immunity from
liability is so that people can safely band together in business.  If
there were no veil, and one harmful act by a member of the corporation
could result in any stockholder being held liable, then few people would
be willing to commit their assets to such an activity.  The risk would be
too great.  The point is that this protection is oriented towards
protecting large numbers of people.  It does not make much sense for a
single person to incorporate in order to try to protect himself from his
own harmful acts, and in fact I understand that the veil can often be
easily pierced in such situations.
On the other hand, with anonymity we are generally dealing with single
individuals.  There is no apparent need for people to pool reputation
capital in an endeavor, and have it be protected by the use of
anonymity.  The closest I can think of would be for a bunch of highly
regarded individuals to announce that they were going to join together
and create commentaries which would demonstrate all the insight, wit,
and other traits which gave these people such a high reputation in the
first place, but that the resulting missives would be released
anonymously, so that if one of them ended up reflecting badly on the
writers, there would be no way to know who had actually created it (it
could be a fake created by an imitator).
While I can't rule this out, it doesn't seem like a likely scenario, and
it doesn't seem to offer the opportunities that corporations do for
increasing productivity.
Another issue is the different forms of anonymity, which don't have clear
analogies with physical capital.  Using a pseudonym you can build up
reputation capital (or at least reputation) in the nym, but then you no
longer have immunity from harm if it commits some gaffe.  (Actually I
suppose this is not too different from the corporation whose assets can
be attacked but not those of the shareholders.)
Then there are the limited pseudonyms discussed by David Chaum, where
there are limits in how many pseudonyms of a particular type a person
can create.  You could have one "committed" pseudonym, unlinkable to
your True Name, which you post under; but you'd only get that one.
(You could post under other pseudonyms but they wouldn't be able to get
that "committed" stamp.) You'd have to be pretty careful what you say
via that nym, much as you are today with your True Name (which BTW a
lot of people don't realize yet).  Then people could filter so they
only received messages from committed nyms, figuring that senders would
be more likely to put meaningful content into these kinds of messages.
Chaum's system of credentials also could allow you to transfer
endorsements from one pseudonym to another.  We have discussed the idea
that such endorsements could be considered an embodiment of reputation
capital.  You could post a wide range of messages under different
pseudonyms, collect the positive endorsements (and discard the negative
ones), and attach them to your True Name or committed nym.  This might
encourage people to abandon their natural caution in making postings
which will come back to haunt them years hence (again, this will be more
an issue once people realize that this will happen).

@_date: 1995-11-21 10:16:33
@_author: Hal 
@_subject: remailer abuse 
The problem is that the time when someone complains about the remailer is
exactly when they have received some obnoxious message.  This is often
their first exposure to the idea of anonymous remailers.  Such people are
the last ones who are going to be receptive or interested in hearing a
lecture about how remailers are protecting the First Amendment.  I
generally do my best to avoid getting into a debate with these people.  I
tell them I have added them to the block list, and usually that is the
end of it.
So while I think Greg's approach is fine as part of an intellectual
debate over the pros and cons of anonymity, it does not address the most
frequent complaints I see as a remailer operator.  I hope that over time
more people will become exposed to the idea of remailers and anonymity
other than in the form of some annoying anonymous message.  Then I think
they will be better able to deal with it when they do get some problem
That message was not posted to Cypherpunks.  It asked in some graphic
detail whether this boy engaged in sexual relations with his parents.
However, the mother was surprisingly calm about it, and simply asked to
be blocked.  The fact that she knew about blocking gave me the
impression she was remailer-savvy, and as I wrote above this seems to
make a big difference.

@_date: 1995-11-21 12:55:56
@_author: Hal 
@_subject: Cyberpunk handbook 
You Bay Area people probably know all about this already, but I was
browsing through the local bookstore yesterday and saw Eric Hughes,
Cypherpunks co-founder, on the cover of the "Cyberpunk [sic] Handbook",
a slim satirical volume by the Mondo 2000 people.  The book has more
attitude than information, though.

@_date: 1995-11-22 07:07:41
@_author: Hal 
@_subject: Proving I'm not Bob. 
BTW, we had some interesting postings here last year from Jason Solinsky
(solman at mit.edu) about schemes involving advertising and payment, where
people would get paid to view advertisements.  Is this the kind of thing
you're thinking of?
I posted some ideas once on how to prove that you are not someone else.
Any such scheme has to be grounded in a physical mechanism to determine that
two people are different.  For example, you might be able to get some
special cryptographic signature or credential from an agency by showing
some biometric information, such as retina or thumb prints.  You wouldn't
necessarily have to reveal your name, identity, or any other information;
just something which would allow the agency to be sure that they had not
given such a credential out to you before.
If you didn't care about privacy, your problem could then be solved
simply by having each person exhibit his credential (these are often
called "is-a-person" credentials).  The more interesting question then
becomes exhibiting that credential in a privacy protecting way, but
still being able to tell if two people are showing the same or
different credentials.
There are various ways of doing this; one of the simplest would be for
the agency to give you a blind signature using a particular exponent,
where you would be allowed exactly one of each exponent.  You unblind
these, and to show you aren't Bob both you and Bob show your signatures
for some matching exponent, which will be different.  Because of the
blinding, no one will link the credential to your identifying
information, and because it is a signature from the agency, no one can
forge a credential different from the one they have.
Depending on the situation and your tradeoffs between convenience and
privacy, you might discard used credentials (for maximum privacy), or
you might reuse them in a particular forum where you have persistent
identity (for maximum convenience).  In the latter case, the exponent
used could be associated with the forum, which is the idea behind
Chaum's pseudonym system.
Hal Finney
hfinney at shell.portal.com

@_date: 1995-11-22 08:09:13
@_author: Hal 
@_subject: towards a theory of reputation 
This is an interesting approach.  However this seems to fold in issues of
reliability with issues of quality and value.  If I have a choice of two
vendors, one of whom produces a product which is twice as good, but there
is a 50% chance that he will abscond with my money, I am not sure how to
value him compared with the other.  It seems like the thrust of the
analysis later is to determine whether people will in fact try to
disappear.  But that is not well captured IMO by an analysis which just
ranks people in terms of "utility" for the price.
I am not sure about this last point.  It seems to me that a good
reputation is one which is most cost-effective for its owner.  Whether it
is good for social stability is not relevant to the person who is
deciding whether to use it.  ("But what if everyone behaved that way?
How would you feel then?")  It may be nice for the analyst but not for
the participant.
I don't really know what the first one means.  There are a lot of
different ways I can behave, which will have impact on my reputation, but
also on my productivity, income, etc.  There are other ways I can damage
my reputation than by cheating, too.  I can be sloppy or careless or just
not work very hard.  So the first two are really part of a continuum of
various strategies I may apply in life.  The second is pretty clear but
the first seems to cover too wide a range to give it a value.
It would be useful to make some of the assumptions a bit clearer here.
Is this a system in which cheating is unpunishable other than by loss of
reputation, our classic anonymous marketplace?  Even if so, there may be
other considerations.  For example, cheating may have costs, such as
timing the various frauds so that people don't find out and extricate
themselves from vulnerable situations before they can get stung.  Also,
as has been suggested here in the past, people may structure their
interactions so that vulnerabilities to cheating are minimized, reducing
the possible profits from that strategy.
It might be interesting to do something similar to Axelrod's Evolution
of Cooperation, where (human-written) programs played the Prisoner's
Dilemma against each other.  In that game, programs had reputations in
a sense, in that each program when it interacted with another
remembered all their previous interactions, and chose its behavior
accordingly.  The PD is such a cut-throat game that it apparently
didn't prove useful to try to create an elaborate reputation-updating
model (at least in the first tournaments; I understand that in later
versions some programs with slightly non-trivial complexity did well).
What you might want to do, for simplicity, is to have your universe
consist of just one good (or service, or whatever), with some producers
who all have the same ability, and some consumers, all with the same
needs.  Where they differ would be in their strategies for when to
cheat, when to be honest, when to trust, and when to be careful.
At any given time a consumer must choose which producer to buy from.
The details of their interaction would appear to greatly influence the
importance of reputation.  Maybe there could be a tradeoff where if the
consumer is willing to pay in advance he gets a better price than if he
will only provide cash on delivery.  (Unfortunately it seems like the
details of this tradeoff will basically determine the outcome of the
experiment.  However maybe some values will lead to interesting
behavior.)  Producers who want to cheat could do so by offering greater
discounts for payment in advance, offering low prices in order to
attract as many customers as possible before disappearing.  Consumers
might rightly be suspicious of an offer that looks too good.
Maybe it could be set up so consumers could cheat, too.  No, I think that
is too complicated.  Then producers would have to know consumers'
reputations and I think it gets muddy.  Probably it would be simplest to
just have producers have reputations.

@_date: 1995-11-23 05:00:59
@_author: Hal 
@_subject: towards a theory of reputation 
I don't have time to write much now, but I got a request for information
on the Prisoner's Dilemma problem, so I did a web search, and found an
interesting sounding paper at .  I have not read it
yet, but according to the web page this adds to the traditional PD
simulations the feature that participants can choose whom to interact
with (rather than having to interact with everyone or with a random other
program).  Maybe "reputation" would be more important in such a
simulation since the element of choice seems to be one of the key areas
where reputation matters.  I'll try to read the paper over the holidays,
but it sounds like it might be relevant.

@_date: 1995-11-23 09:24:23
@_author: Hal 
@_subject: ecash protocol: Part 1 
That's very interesting work!  What are the string formats, are they null
terminated or Pascal-style with a preceding count byte?  How did you
identify "an empty string", wouldn't that just be a byte of 0?  How did
you know it was an empty string rather than just a 0.
Did you get this by inducing a shop to send a payment request message to
some program you wrote which was listening on the ecash port?
I think a good way to get the rest of the information would be with a
proxy which logged message traffic.  I know ecash has some proxy support
but I'm not sure how it works.  There are SOCKS proxies and http proxies,
and I don't know which it uses.  I used a logging httpd proxy to derive
the data for the SSL challenges I did this past summer.  It might be
interesting to post the binary data from some ecash transactions.
I wonder if it would be legal to write shop software which sent such a
payment request, took the resulting coins, and deposited them in the bank
(if we could figure out all the protocols necessary).  This particular
sequence of operations would not appear to infringe anybody's patents -
there are no blinding operations involved.  It's not clear how useful
such a program would be but at least it would be one step away from the
DigiCash monopoly.

@_date: 1995-10-05 12:25:49
@_author: Hal 
@_subject: Certificate proposal 
(...WAY behind in cypherpunks mail...)
I don't understand this whole discussion.  A certificate is a signed
binding of a key and a unique name, right?  If the proposal here is
that the unique name be a hash of the key, you are suggesting a signed
binding of a key with its hash!  What is the point of a certificate
which binds a key to its hash?  What is such a certificate asserting?
It seems to be saying nothing at all.  Anybody can already tell if a
hash is right, for all the good that does you.  It's like a notarized
statement that 2+2=4.  I don't see the point.  As Carl goes on to say:
If in fact this is just a suggestion that we not have certificates, that
may have some value.  But as a literal suggestion that certificates bind
a key hash to a key, that just doesn't make sense to me.
The thing to keep in mind is, why do we want certificates?  Why not just
use unsigned keys?  If I encrypt a message for Carl based on some key I
found lying around somewhere which someone told me is his, and I send it
to his mailbox, and I get a reply back, how secure is that?  We all know
that you don't get the full security of the encryption if you do this.
Man in the middle attacks might not be easy to do in such a situation but
they are certainly possible.  It is such attacks that certificates (including
PGP key signatures) are designed to prevent.
I'd like to see some grounding of this discussion in terms of the role of
certificates, and ways to prevent man in the middle attacks.  I certainly
have no love for facist worldwide ID cards and hierarchical, organization
based naming schemes, but just using any old key because it seems to work
OK most of the time isn't going to fly IMO.

@_date: 1995-10-05 17:41:02
@_author: Hal 
@_subject: Certificate proposal 
OK, so suppose I want to send my credit card number to Egghead Software.
I get one of these new-fangled certificates from somebody, in which
VeriSign has certified that key 0x12345678 has hash 0x54321.  I think we
can agree that by itself this is not useful.  So, it will also bind in
some attribute.  What will that attribute be?

@_date: 1995-10-05 18:22:27
@_author: Hal 
@_subject: subjective names and MITM 
Carl Ellison has been arguing a similar point for some time, if I
understand him, which I may not!
The man in the middle problem is a difficult one, but I don't think
you're going to get away with defining the problem out of existence.
There is a difference between a MITM and the case you describe where you
are actually communicating securely with the person you think you are,
but he chooses to relay the messages around.  The difference is that if
you are actually communicating securely with an individual, you can form
some estimate of his personality, judgement, etc.  You may choose on this
basis to trust him, provide sensitve information, take risks, and so on.
But if he is actually behind a MITM then all bets are off.  All of your
judgement about him is irrelevant.  At any time the MITM can take
advantage of the information you provide.  He can even "blow his cover"
and take extreme action, to your detriment.
This situation with the MITM is actually about the same as if you were
communicating insecurely in the first place.  You are exposed to all of
the same risks.
So if you are willing to accept communicating systems that allow this
kind of attack, you almost might as well not use cryptography at all.
(Not quite, because the MITM is a more expensive attack to mount than one
on an unsecured wire.)
In fact, I can facetiously prove that cryptography is unnecessary.  We
are not communicating with individuals, but with communicatees.  All of
your messages are by definition going to the communicatee with whom you
are communicating.  If the particular communicatee who is receiving
your message chooses to relay it or spread the information around in
other ways, that is the right and privilege of the communicatee.  But
messages are going to the communicatee they are going to, whether
encryption is used or not.  So encryption is not necessary.
This argument seems to mirror the one for why we only communicate with
keys, that if a key wants to do something nasty we can't stop it (him?),
etc.  I say, we don't communicate with keys.  We communicate with people
(or occasionally programs).

@_date: 1995-10-05 21:20:34
@_author: Hal 
@_subject: Certificate proposal 
I may not have been clear: the certificate I was referring to was the one
from Egghead, the one which I will use to make sure that I have a valid
key for Egghead.  Such a certificate would of course not have my credit
card number; it would probably have some information related to Egghead.
My rhetorical point was that information would most plausibly be a NAME
by which I would refer to Egghead.  I am still trying to understand how
these proposals to take names out of the picture will apply to a
commonplace situation like this one.

@_date: 1995-10-05 21:41:13
@_author: Hal 
@_subject: Certificate proposal 
This would be, say, a DNS lookup on I get it by connecting to that IP address and asking for it, or perhaps
I have it cached or I get it from some public cache.
I see the certificate is signed by someone I trust and it certifies that
this key is good for connections to Egghead Software at OK, maybe this is some DNS variant that given  returns a
public key 0x12345678.
OK, so now I do another DNS lookup on  to get the IP
address.  Or maybe I even use key 0x12345678 as an alternative index to
get that address.
Now you've lost me.  Are you saying that the key is self-certifying,
saying "I belong to 192.9.8.7"?  That is, it is accompanied by a
signature issued by that key itself on this IP address?  I hate to be
difficult, but this does not provide me with a warm feeling.  Anyone
could have issued that key, claiming to belong to that IP address.  If
the person who did so is able to interpose himself between me and that
address then my messages are not secure.
Again, I don't follow how we gain this certainty.
This can be dealt with in the certificate context by having a
certificated key sign a statement that the IP address is now
I don't really care whether the name is called an attribute, a
distinguished name, or an ooblek.  I just don't see how you're going to
get along without it.  The fact is, we live in a world populated by
people and companies and we use names to identify them.  I will grant
that there are problems with uniqueness but I don't think the solution
can be to just give up on the whole idea of names since they are so
messy.  Pretending that keys are communicating beings is not going to

@_date: 1995-10-06 07:34:50
@_author: Hal 
@_subject: subjective names and MITM 
I can certainly agree with the attractive simplicity of this notion.  My
point is that it is practically useless.  I believe this is a seductive
but very wrong idea.  As I said, it amounts to defining the problem away.
Does that mean that the problem (of MITM attacks) never existed at all,
that all of the effort that people have spent over the year to try to
solve it was wasted?  I am baffled by the fact that people are taking
this whole notion of "communicating with keys" seriously.  Keys do not
One might as easily say that wiretaps are not an issue: I am not
communicating with the person I called, but with the other end of the
telephone wire.  If that wire end is actually (unknown to me) in the
hands of a government agent who has cut the wire and interposed his own
listening device, that's OK, because I'm still communicating with the
other end of the wire.  After all, I have no way of knowing whether the
person that I am talking to may actually be spreading my info to
anyone, so it doesn't really make any difference if he does it or the
wiretappers.  Etc., etc.  This is exactly like the argument about
communicating with keys.  Does this mean that we shouldn't worry about
wiretaps?  I hope not.  I really don't understand why the argument is
so much more persuasive in the case of keys.
The difference is that I form a judgement about the personality of the
person I am communicating with, whereas I can't form any such judgement
about the personality of the MITM.  Consider how, in life, we decide who
to trust.  Isn't it largely on the basis of communications?  We talk to
the person, we talk to other people about him, we take what we know of
him, and we decide to trust him.  If we suppose that there is in fact a
secure channel to another person, then I suggest that it is plausible to
suppose that we could enter into a trusted relationship with him, even
without a face-to-face meeting.  After all, what exactly does the face to
face meeting accomplish?  Yes, we see a little more about the person, we
can judge some non-verbal communications.  But it is not wholly
We can always be wrong - the person may not be as trustworthy as we think
he is.  There is some probability of that which we must always keep in
mind.  But, and here is my main point, if a MITM is a possibility (and
we're taking the attitude that that's just fine, we're communicating with
keys, no problem if there's a MITM involved, don't bother to take any
steps to prevent it) then these assumptions about extending trust are a
lot riskier.  The probability of a betrayal will be much higher if a MITM
is possibly involved than if he is not.  Most people do not try to betray
their communicants.  But if (in the worst case) all lines were tapped by
men in the middle, then in fact all conversations are subject to this
betrayal.  As I wrote before, I don't see the difference between this
situation and one where there is no security at all (at least from
Most of the time your judgement about the real person will be valid, at
least with some experience.  Most people are not AI's or teams of
conspirators.  But you have absolutely no basis to make judgements about
the MITM.  In fact the greater probability is that his interests are
opposed to yours.
I don't think so, or at least the risk can be minimized much more than in
the model where we just say that we're communicating with keys, therefore
a MITM is perfectly legitimate because it's just a matter of who holds
the keys.  Suppose I want to talk to PC Magazine columnist John Dvorak.
Suppose I find a VeriSign certificate for his key, with his name and
employment information.  I've never met him.  We've never had a face to
face conversation.  Yet I claim I can communicate with considerable
security with Dvorak using this certificate, certainly more than if I
just use any old key which is lying around with his name on it, one which
may be owned by a MITM.
If you are in fact communicating with the person you think you are, you
can use all the information you have about him (including other
conversations) to judge his personality and trustworthiness.  Yes, this
can be mistaken - but the same thing happens in the real world.  That
doesn't mean that we abandon the whole idea of trust.  We still can be
right most of the time.  However if you know that a MITM may be involved,
you will be much slower to extend trust.  In fact you have to act as
though you have an unsecured channel.
No, by definition the "communicatee" is the set of all the people who
see your messages.  So by definition between you and the communicatee
there is security even without encryption (since no one other than the
communicatee sees the message).  Sophistry?  The number of people who can
receive your messages is no greater without encryption than if you use
encryption but don't take steps against a MITM and in fact adopt a stance
which states that MITM attacks don't exist.
I don't know for sure, but if you tell me or give me the impression over
a period of time that you are keeping our conversations private, and I
decide that you are honest based on our conversations and what I know
about you from others, then I can make a judgement with a reasonable
chance of safety.  Yes, I can be mistaken.  But that doesn't mean that I
should abandon the whole idea of trust.  Otherwise I will never trust
anybody in any part of life.  But preventing MITM attacks is very
important to being able to extend trust in the online world.  Defining
them away is not a satisfactory solution.

@_date: 1995-10-06 09:09:12
@_author: Hal 
@_subject: subjective names and MITM 
m5 at dev.tivoli.com (Mike McNally) writes, quoting me:
Mike>Seems to me that the idea of "communicating with the person you think
Mike>you are" is intractably difficult if you're not sitting in the same
Mike>room. ...
Hal> I can certainly agree with the attractive simplicity of this notion.  My
Hal> point is that it is practically useless. ...
Mike>Oddly enough, it seems to me that Hal (if that really *is* his name)
Mike>and I (and Carl & others) are saying basically the same things, but
Mike>drawing completely different conclusions.  Strange.  I'm willing to
Mike>wait to see what the peer review process concludes.
I am afraid you have quoted this out of context and thereby exactly
reversed the sense of what I was saying.  Hence we are not saying the
same things, but rather we are saying opposite things.  The full quote is:
Mike>Seems to me that the idea of "communicating with the person you think
Mike>you are" is intractably difficult if you're not sitting in the same
Mike>room.  If you accept instead the idea of "communicating with the
Mike>entity possessing the private half of a keypair" then life gets a lot
Mike>simpler. Hal>I can certainly agree with the attractive simplicity of this notion.  My
Hal>point is that it is practically useless.
By "this notion" I was referring to the second sentence rather than the
first, the idea that we are communicating with whomever holds the key.
This was the one which you said would make life simpler, and so I hoped
that by agreeing about its simplicity it would be clear which of the two
competing ideas I was referring to.  Apparently it was ambiguous, so I
apologize for being unclear.
It is disturbing that even after reading that very long message my
position could be interpreted as being the opposite of what it is.
Apparently my arguments are not being well understood.  I will have to
think about this issue more and try to express myself better.

@_date: 1995-10-06 10:10:07
@_author: Hal 
@_subject: subjective names and MITM 
jbaber at mi.leeds.ac.uk writes (where I have taken the liberty of
reformatting for 80 columns):
Well, this is not necessarily the case.  A MITM may be signing my
messages for me, and then putting them back the way they were before I
am allowed to see them.  Granted, this would not be easy, and perhaps
the difficulty of this would be great enough that you will feel
comfortable using an unsigned key.  But if it were accomplished, then
your messages to me would actually be insecure.  No matter how
convinced you became of my sincerity and trustworthiness, actually our
conversations would be overheard by a third party despite both of our
efforts to the contrary.  Our use of encryption would be rendered
futile.  Doesn't this bother you?

@_date: 1995-10-06 21:02:00
@_author: Hal 
@_subject: MITM attacks and True Names (again...) 
Although I have been in effect arguing against using unsigned and
uncertified keys, I don't think the PGP web of trust model works that
well either.  I have an essay on this at .

@_date: 1995-10-08 10:23:23
@_author: Hal 
@_subject: MITM attacks and True Names (again...) 
One of the reasons people don't like solutions based on True Names is
because nyms don't have them.  Pr0duct Cypher can't very well go to
someone, show a drivers license, and get his key signed.
There is still a way in which signed, true-name-based keys can be useful
to nyms.  Maybe they can't get their own keys signed in this mode, but
they can check the keys of others.
If Pr0duct Cypher, under his secret identity, goes out and gets valid
keys that he can trust (maybe he sees Verisign's key fingerprint in the
newspaper), then if I send him my key signed by someone he trusts, he
can check the signature.  He can then send data to me encrypted with my
actual key, and the MITM can't do anything about it.  So the presence
of my True Name based key allows us to communicate securely.
This doesn't help for the case of two nyms who want to communicate,
though.  For that we do need a mode in which nyms can get their keys
signed.  I do think that there are some situations in which that is
plausible, based on the difficulty of mounting a MITM attack against
someone who is determined to try to detect it.  In the most extreme case
the MITM has to simulate the whole outside world with respect to the
person he is targetting, which is infeasible.  Various tricks like
sending hashes of future messages have been discussed; the MITM can't let
these through since the future message may include the true key that he
is hiding.  If people are then supposed to reply to these hashes, all of
the replies have to be simulated by the MITM.  Eventually it seems that
the MITM becomes enmeshed so deeply in his own lies that he would get
caught.  If steps like these are taken successfully it should be
reasonable to sign a nym's key, with the semantics being that either this
is the real key of the sender, or he has a nearly omnipotent MITM
surrounding him.

@_date: 1995-10-08 10:27:46
@_author: Hal 
@_subject: Certification Authorities in history. 
One key to rule them all;
One key to find them;
One key to bring them all
And in the darkness bind them.

@_date: 1995-10-09 08:55:40
@_author: Hal 
@_subject: subjective names and MITM 
That is not exactly my point.  My concern is avoiding the man in the
middle attack.  One way to do that is to find a certificate from Verisign
saying that this key belongs to Steven Levy, ideally with other
information that I can confirm relates to the on-line personage I wish to
speak to.  Presumably the MITM can't get a certificate for Steven Levy,
unless by coincidence his name actually is Steven Levy, in which case the
other information I mentioned will be helpful as well.
Would you propose just to use an unsigned key that says it is for
Steven Levy?  Or perhaps a key without any name at all that someone
told you was for him?  That is the policy which I have been arguing
against.  The whole idea of communicating with keys, or not having key
certificates or signatures, seems to me to leave open the possibility
of man in the middle attacks.  Isn't this a problem?  Or are the
difficulties of mounting a MITM attack considered so large that they can be
neglected?  I would just like to hear exactly what are the assumptions
being made regarding this problem by those who oppose certificates.

@_date: 1995-10-09 09:47:24
@_author: Hal 
@_subject: Certificate proposal 
I can see using keys with attributes in this way, for credentials or as
other forms of authorization.  But what about for communications privacy?
What is the attribute that tells you that using this key will prevent

@_date: 1995-10-09 12:04:29
@_author: Hal 
@_subject: Certificate proposal 
OK, but again, what about the man in the middle attack?  Suppose the
key that you found that claims to be from Bob is actually not his, but
another one created by a man in the middle, such as Bob's malicious
ISP?  Then that ISP is decrypting the messages Alice sends to him using
that fake key, and re-encrypting them using Bob's real key.  He is
reading all of the messages, and Alice and Bob do not in fact have
communications privacy.
I don't want to overstate the risk of this attack.  It would not be an
easy one to mount and I believe there are countermeasures which could
detect it unless the MITM had nearly supernatural powers.  But the MITM
attack is normally considered seriously in discussing crypto protocols.
It is a well known weakness in Diffie-Hellman, for example.  That is why
authenticated Diffie Hellman is used in some of the newly proposed key
exchange protocols for IP.  The risks of MITM attacks on public key
systems was recognized not long after those systems were proposed.  The
problems with fake keys have been discussed for over a decade.
Why is this all suddenly irrelevant?  Were these attacks never realistic?
Is it just not a problem somehow?  I am baffled by the fact that people
are just turning their backs on all these years of research and
experience.  If this is some kind of paradigm shift in which the idea of
communicating with keys is seen as the key to the puzzle, then I am
afraid I don't share the enlightenment.  To me the problem seems as real
as ever.

@_date: 1995-10-09 13:40:11
@_author: Hal 
@_subject: Certificate proposal 
Right.  My goal is to have a system in which two individuals who have
never met can communicate securely.  This is not too radical a notion, I
trust.  In fact, I would go so far as to say that to a considerable
extent it is the whole point of public key cryptography.
What difference does it make?  I'll tell you.  It means that their
conversation is not private!  It means that their cryptography is
useless, that it has failed.  It means they have an unsecure channel.  I
don't know how I can put it more plainly than this.  I wrote a long
article a few days ago arguing that they almost might as well not use
cryptography if they're going to adopt this stance.  Let anyone
eavesdrop, and from Bob's point of view when he thinks he is talking to
Alice he is actually talking to eavesdroppers+Alice.  From his point of
view, Alice is just an alias for eavesdroppers+Alice.  Etc., etc.
This is not a useful or appropriate way to think of the world, IMO.  If
you do this, then from your perspective people become bafflingly
unreliable.  I wrote all about this before.
Try to think of it not in relativistic or epistemological terms, but
rather look at it in terms of reality.  The real world exists, and in it
exist real people.  We can agree on this much, right?  Two of these
people want to communicate securely.  That is not such a stretch of the
imagination, is it?  By "communicate securely" I mean they exchange
information in such a way that other people don't receive it.
Now surely it is clear that with this definition of the problem,
approaches which redefine people to mean people+eavesdroppers are not
responsive.  Perhaps the motivation to do so is simply the belief that
the problem is not solvable as stated.  If so, I'd like to hear someone
say this.

@_date: 1995-10-09 13:55:12
@_author: Hal 
@_subject: Certificate proposal 
I will agree that there are alternatives to certificates.  I alluded to
this in the part of my message which you elided below, about defeating
MITM attacks via various techniques.  However, it may not be as easy to
automate these tests as to automate a certificate check, and in
particular the more automated the tests become the more plausible it
would be that the MITM could recognize and defeat a standard test.
The POV I am really arguing against is the one that defines identity to
be a key, that states that in communicating with a key you are by
definition communicating with the person you have in mind.  The man in
the middle attack does not exist because from your point of view the
entity at the other end of the communication channel is just the MITM
plus the person you think you are talking to.  This idea has been
expressed many times by other people in this discussion, and it is this
which I think is fundamentally flawed and even dangerous because it
encourages the use of untested keys.  In fact it seems to define away
the question of whether a key is real or fake.

@_date: 1995-10-09 16:17:41
@_author: Hal 
@_subject: Certificate proposal 
It occurs to me that perhaps I have been missing a point here when people
argue that having a "man in the middle" is not that different from
various forms of secure communication, such as where Bob has multiple
personalities or is a committee.  I have been taking this to mean that we
should therefore not worry about MITM attacks, which seems crazy to me.
Instead perhaps this was meant as a "reductio ad absurdum" argument for
why MITM attacks cannot be prevented in the scenario where people have no
out-of-band contact.  Anything which could detect and prevent MITM
attacks could, by this analogy, detect whether Bob had multiple
personalities.  Since the latter is obviously impossible, the former must
be as well.  Hence the problem has no solution and we should not
waste much time on it.
I don't fully agree with this but at least it is not as bizarre as the
first interpretation.

@_date: 1995-10-09 16:54:56
@_author: Hal 
@_subject: Certificate proposal 
I believe that the certificate wasn't spoofed by an MITM attack because the certificate issuing process requires face to face contact with some
proof of identity, in at least one way of doing this.  The certificate
wasn't spoofed because I got the key of the signer through an out of band
mechanism, such as seeing it printed in the newspaper.
The main requirement is to have some contact between Alice and the rest
of the world which doesn't go through the MITM, and the same for Bob.  By
using certificates, this contact only has to be done once (for each of
them).  There is no need for Alice and Bob themselves to have a face to
face meeting, nor for Alice and Charlie, Alice and Dave, Bob and Charlie,
Bob and Dave, Dave and Charlie, etc.  Just the one will suffice.
I'm not sure whether this is because you think MITM is so difficult as
to be almost impossible in any model, or whether you think that an MITM
attack is possible in some cases against relatively naive users, but that
certificates won't help at all in that case.
Let me make clear how I would see a MITM attack working.  There are two
main flavors, the permanent and the transitory.  Here is how the
permanent MITM could work.
Alice's ISP provides all of her email services.  She has created and
published a public key, but the ISP has detected this and replaced it
with a fake key.  Everyone who tries to send to her using that key gets
their message decrypted and read by the ISP, then re-encrypted using
Alice's real key and delivered to her mailbox.  This much would be
relatively easy.
But it is not enough.  If Alice gets hold of a good key for Bob, she will
send messages to him using that key.  The ISP can't read those messages.
If she signs them, Bob will notice that the signature doesn't check
against his copy of Alice's key (the one which the ISP has installed in
place of Alice's real one), and the ISP will be caught.
Therefore the ISP is going to have to make sure that every single key
Alice gets is a fake one, one for which the ISP has the secret key.
When Alice get's Bob's key, Charlie's, everybody's, the ISP has to
replace those with fake versions.  Then again it can do its
translate-and-replace trick on messages going in both directions.  This
is obviously a much more difficult task, but if people acquire keys in
limited, stereotyped and automated ways, it could conceivably be done.
With this, what more could trip the MITM up?  Well, if anybody ever
included any keys within the body of a message, those would have to be
detected and substituted.  Even key fragments might have to be handled,
although it is unlikely that this would be noticed.
The biggest threat would be if Alice used a different method to get
someone's keys, her own or anybody's that she communicates with.  She
could use a different ISP or use some "out of band" (off-net) method.
If she went to a key signing party the jig would be up.
Does this mean that the MITM attack is impossible?  Not necessarily.
I'll bet there are plenty of people who only use one ISP (AOL or MSN)
and who have never been to a key signing party.  Maybe they've never
even met someone in real life whom they communicate with on the net.  A
lot of people could fall into this category.
This is where the certificate comes in handy.  A certificated key from a
signer whose key Alice is able to verify out of band will not be
forgeable by the MITM.  Likewise if Alice's key distributed on the nets
is signed by a trusted certificator then other people can have confidence
that there is no MITM involved.  Basically the certificate is a way of
forcing people, at least once, to go around their ISP.  And once is
Now let me describe the other form of MITM attack, the transitory one.
In this one the attacker doesn't care if he's caught, he just wants to
peek at a few (possibly crucial) messages.  Here again his attack is to
replace Alice's public key in the databases with a bogus one, and to
intercept her communications.  Or maybe he is attacking SSL or some
other protocol where one side sends their public key to the other.
Then it is even easier to send a fake one.  People who trust and use
that key will lose their privacy.
This attack is obviously a lot easier to mount in some contexts.
Again, the use of a certificate should prevent these, and in fact SSL
does use certificated keys.  The MITM will not be able to supply a
certificated key with the name/address information for Alice.
(Netscape currently doesn't check to see whether the name in the key is
valid, so it is not getting much benefit from the use of certificates.
I hope it is clear that abandoning certificates or using ones without
any name or address information would make SSL very unsafe.)
What if you just want to talk to her securely?  I asked before what
"attributes" would handle that case, and the answer that at least Tim
gave was that talking to the key is talking to Alice.  I don't buy
that, at least not yet.
(Don't get me wrong - I don't have anything against attributes.  I love
Chaum's pseudonymous credentials.  I'm just worried that unless we have a
foundation of secure communication that the rest of the edifice isn't
going to stand.)
OK, I wrote at length above on how certificates can help against two
forms of MITM attacks.  What do you think?  Maybe it is hard to imagine
a long-term successful MITM attack, but wouldn't you feel uncomfortable
with an SSL which used uncertificated keys?

@_date: 1995-10-10 09:06:08
@_author: Hal 
@_subject: Certificate proposal 
Still, there is a problem here: how did the bank know that it _should_
honor requests to withdraw money from bank account x if they are signed
with a certain key?  How did it determine that that is a valid key, if it
never had a secure channel to the person opening the account?  I think
the answer is clearly that it cannot, that it must have had a secure
channel.  Would a certificated key presented by Alice have been
sufficient to create such a channel, do you think, or would a face to
face meeting have been necessary?  (Or would an uncertificated key be
What if you are accessing the bank via a MITM?  Consider this example:
Alice writes you a check, signed with a key (without her name) which
has a credential from the bank saying that it will back up the check.
But you need the bank's key to check the credential, so Alice gives it
to you, or you get it from a public cache.  Suppose the bank's key is
fake, and Alice is defrauding you.  How do you tell?  Wouldn't a
certificate on the bank's key be necessary, one which ties the bank's
name and reputation to the key?
Or what if the bank really is and has always been behind a MITM?  You say
that it is more profitable for the bank not to abscond with your money.
What about the MITM?  He doesn't make any profits until he cheats.  He
might well be collecting information which will allow him at some point
to abscond very successfully.  Would you really trust a bank which was
known to you only by a key and by a record of never having defaulted,
knowing this was a possibility?
Same problem as before: how does the credit card company know that the
key it is putting on the card is really Alice's?  What if Alice discovers
unauthorized charges because Carol was a MITM and substituted her key?
We can't just ignore this possibility.
It seems to me that a lot of protocols assume the existence of secure
channels.  Yet the MITM attack shows that public key cryptography does
not in and of itself provide a secure channel.  This is a problem which
IMO should not be ignored simply because it is inconvenient.

@_date: 1995-10-10 09:22:07
@_author: Hal 
@_subject: Certificate proposal 
Well, I don't think this is true.  First of all, the MITM has limited
powers.  He may be able to perform certain automated and occasionally manual
replacements on messages, but he is not able to affect communications
which take place off of the net.  In particular, he is not able to stop
Pr0duct Cipher from reading Verisign's key fingerprint in the newspaper
and comparing it with his own copy of the key.  And if PC has a valid
Verisign key then he can know that he has a valid key for other people.
If he then sends mail to those people using their keys, the MITM cannot
control that mail.  Hence PC can communicate securely with other people
even if the MITM controls all of his network communication, contrary to
the claims of impossibility.
If only one ISP is used (which is true for the vast majority of people)
and if they only get and send keys in specific ways then I would not say
it is impossible.  Look at programs like Satan or the internet worm.
They contain many different possible attacks.  Writing such programs is
almost an exercise in tedium as much as creativity.  In the same way it
would be possible for a filter program to anticipate a dozen or more
different ways in which a user might get keys from the net, and make
substitutions.  Doing it for any given method is not that hard, so it is
just a matter of motivation to do it for 99% of the ways people will
Not necessarily.  As I argued before, we do establish trust relationships
in the real world.  And we do that on the basis of communication.  Yes,
in real life there are wider communication channels, nonverbal ways of
judging the sincerity of others.  But over time I would guess that online
relationships can take on the same character.  In fact, I have read
countless puff pieces about friendships, even romances, formed online.
The notion that you can't possibly establish the sort of relationships
online which would induce you to share secrets is demonstrably false, at
least for many people.
That's an awfully limited way of looking at things.  We do a lot more
online than buy and sell.
No, I don't think this is at all useful.  The VAST majority of people I
talk to on the net are people I have never met.  What earthly use is a
credential that key so-and-so belongs to a person with blond hair, in
helping me to establish secure communications?  Should we only talk
online to the miserable few people we live near who share our interests?
The net is global!  Virtual communities allow niche interests (like ours)
to attract people from all over the world.  Any scheme which requires
face to face meetings between every pair of participants is doomed.

@_date: 1995-10-10 09:39:02
@_author: Hal 
@_subject: Chaum's patents 
I did a patent search a few months ago, with results at .  Chaum has several
patents; my lists doesn't have all of them.  The ones I have are dated
1988 and 1990.

@_date: 1995-10-10 17:26:34
@_author: Hal 
@_subject: Netscape & Fortessa 
There seems to be a convergence on this approach to a hardware
solution.  HP has been pushing for a model in which software with hooks
for hardware encryption will be allowed to get exported.  Then you can
plug in whatever level of encryption you are able to have in the
form of a card token.  Traditionally NSA has opposed export of software
with hooks but there are some indications that this method could be
accepted eventually.
Conceivably we could get to a situation where most encryption is done in
hardware, with the big, ubiquitous software packages like Netscape and
Word and their descendants just having hooks.  This would have some
advantages but overall I think it would be detrimental to cypherpunk
goals.  One of the biggest problems faced by those who want to restrict
access to encryption is how easy it is to do.  PGP and other programs are
virtually impossible to control.  They are easy to write and people can
spread them around trivially.
But hardware is not so simple.  If the only effective way to get
convenient communications with your net access software became to use a
hardware token, then it would be a lot easier to put on restrictions.  An
underground effort to manufacture and distribute tokens would be much
less practical than one to do the same thing for secure software.
I would like to see companies which add hooks for hardware also begin
adding hooks for software packages as well, at least in their domestic
versions.  In the case of Windows, for example, a DLL interface to
provide encryption functions should not be hard to add using a similar
API as for the hardware crypto card.  Similar interfaces should be
possible on other OS's.  Companies which do this will demonstrate their
commitment to making good quality cryptography available to their
customers.  A system which is "open" only to the extent that a hardware
card can be added is not sufficient.  A truly open system will allow
software add-ons as well.  Let's keep an eye on how this develops and let
the companies know how we feel.

@_date: 1995-10-11 07:16:11
@_author: Hal 
@_subject: Mean Men in the Middle 
If the MITM is really mean, he can overcome some of the suggestions I
offered for how credentials can be used to defeat him.
First, he could cause the user to download bad software.  PGP,
Netscape, and other secure programs could be patched to have holes.
Even the checksum program could be altered so publishing checksums won't
help.  With this attack he would not even need to substitute keys; he
can just make sure that the fake PGP picks guessable session and secret
Alternatively, he could defeat the use of key certificates which bind names to
keys by the simple strategem of substituting the name of the user when he
substitutes his keys.  If Alice has all of her posts appearing under
the name of "Bob" unbeknownst to her, then if Bob is the MITM he can get
a certificate and publish it.  All the messages which refer to "Bob" get
changed to refer to "Alice" as they are passed from the net to her,
similar to the key substitution which would also have to be done.  If
Bob's name were a bit unusual this could be done with a simple script.
So even fully valid key certificates may not be effective against MITM
attacks of this type.

@_date: 1995-10-12 07:05:56
@_author: Hal 
@_subject: MITM evasion MITM evasion 
This is true, but it doesn't mean that the threat can be neglected.  A
successful MITM attack may be a matter of reading even one message and
acting on it, if the participants don't find out until later that they
were robbed.  In fact, they might not ever notice that they key they
used Tuesday was different from the key they used Thursday, if they
didn't cache the keys.  (Yes, PGP does store the keys in a local key ring
cache but not all systems will necessarily work that way.)
Obviously the MITM cannot handle (most) communications taking place
offline.  But there may be a lot of people who don't use any of these
offline methods to validate their keys.  These people don't go to
academic conferences, don't read their key id's over the phone, and
don't print them on business cards (or if they do, they don't get
business cards from those they communicate with securely).  Maybe this
will change, maybe it is a matter of user education, but it is still an
extra effort which will be important to have secure communications.  I
don't think this is widely recognized (other than in the context of the
need for certificates and signed keys).
Note too that Mitch is not necessarily taking any risks here even if he
is caught.  "Mitch" could be a remotely operating program, a virus
embedded in Alice's computer or in some link between her system and the
outside world, which is performing these transformations and sending the
decrypted messages out anonymously.  So even if Alice discovers the
trickery there may be no effective way to track down the miscreant.
3. Mitch's MITM attack is transitory and he doesn't care if he is caught
afterwards, he got his goodies.
4. Alice doesn't go to a lot of trouble to check her keys via offline
means.  After all, MITM is so rare it can't happen to her.
Practice safe cryptography!

@_date: 1995-10-12 10:47:43
@_author: Hal 
@_subject: RSA Data Security, Inc. To Exclusively License Rights to RSA 
I'm sure that everyone will join me in a rousing Bronx cheer for RSA as
they continue their efforts to monopolise public key cryptography.  If
they truly have a patent on DSS this will be yet another important
algorithm for which people have to get RSA's permission.  RSA is fast
entering the list of such well loved institutions as the Post Office and
the Internal Revenue Service as one of those places you can't avoid
dealing with no matter how you try.
"Ever been sued for patent infringement?
You will!
And the company that will stick it to you?
Hal, the intemperate.

@_date: 1995-10-13 21:28:35
@_author: Hal 
@_subject: mental cryptography 
The Mad Scientist in the Middle writes via anonymous-remailer at shell.portal.com:
I am not familiar with WAKE but I doubt that you could literally hold 128
bits in your head and manipulate them.
This is a problem which I have wondered about for some time.  Presumably
if we went to a digital cash world we would use smart cards to buy
things, but how do we make sure that nobody steals and uses our smart
cards?  Just typing in a PIN doesn't seem very safe to me, especially if
the card doesn't have a keypad built in and you're using a keypad in the
card reader as is often the case today.  Even with a pad on the card you
have to worry about eavesdroppers.
Biometric ID's (fingerprints, and Senator Feinstein's retina scans that
she wants to put on our national ID cards) have been proposed to solve
this but they are expensive and unreliable right now.  An information
based solution would be best if it were possible.
I have read one paper which attempts to solve this problem, called "Human
Identification through Insecure Channel".  Unfortunately my papers are in
a mess right now so I don't have the reference handy.  It was by some
Japnese researchers, published in one of the proceedings books.  I
believe a follow-on paper was published within the last year or two which
had some improvements or corrections to their algorithm.  Sorry to be so
vague, I'll try to dig out more info over the weekend.
Basically they used a challenge-response system which was intended to
be simple enough that people could do it in their heads.  The card
would display a random challenge string, some characters of which were
special to the user and others which he would ignore.  He would then
input a response string, where it didn't matter what corresponded to
the "ignore" slots, but in the special slots he had to produce certain
symbols corresponding to the other symbols, with the rules changing as
you move along.  The intention was that even by capturing and analyzing a
great many challenge-response pairs you couldn't create a response to a
challenge you hadn't seen before.
I coded this up, and frankly, I couldn't do the required manipulations in
my head, at least not without taking a very, very long time, and thinking
very carefully.  Maybe it would get easier with practice, I don't know.
But my overall feeling was that this would be at the limits of human
capability even for fairly bright people.  (OTOH I suppose learning to
read and write might seem pretty tough if you'd never done it.  Maybe
the 1st grade classes of the future will spend months training the kids
on how to use these kinds of algorithms.)
It's a hard problem to solve in general because you have only a human
mind to do the identification algorithm but you have computers to try to
break it.  But I would like to see the problem get more attention.

@_date: 1995-10-16 13:52:40
@_author: Hal 
@_subject: Human ID through insecure channel 
Here is an example of the Matsumoto/Imai scheme for identifying yourself
via a shared secret over an insecure channel, a system which is simple
enough to be done in your head but which can withstand repeated
observations by an adversary without being broken.
The idea is that there is a challenge and response.  In one example they
give, the challenge is:
What happens here is that there are two secrets.  The first is which
characters are special in the challenge.  In this example let us assume
that is 1,2,4,6.  The second is a secret response string of the same
length; in this case let it be 3124.  Now what you do is to enter a
response string of the same length as the challenge.  Only the characters
in the same spot as those which held special characters in the challenge
(1,2,4,6) matter, and those four should spell out the secret word 3124.
So a correct challenge and response could be:
*  *  **
I have marked the spots in the challenge which use 1,2,4 or 6, and if you
look at the response in those marked spots you have 3124.
This is not too bad, but as more realistic examples the authors suggest
much larger strings.  In the first example the alphabet of characters
would be the lower case letters and the digits 0-9, 36 characters in all.
The challenge string would also be 36 characters long.  Your secret word
would be 18 letters, but the response alphabet is only the binary digits 0
and 1.
So, suppose the special characters are befhjkmnpqtvwz1468, and the secret
word is 011010111010110101.  The secret can be memorized in hex as 1aeb5.
This is not so much to remember, but try applying it in practice.  Here
is a challenge:
To create the response, we go across, putting down random 0's and 1's,
until we recognize our special characters.  The first is f, the 2nd
letter.  So we are careful to put down 0 there since that is the first of
our secret word letters.  Then the m is special, so we put down 1; the p
and 6 are special too, so we put down 10.  Then the 7 and y are not
special so we put random characters down there, and so on.  So our
initial response might be:
Try coming up with the rest of the response, and see if you think you
could learn to do this by memory.
Another example the authors offer uses a somewhat shorter secret word and
set of special characters, but as a tradeoff the challenge alphabet is 50
characters (upper and lower case letters, say, minus 2 of them), and the
challenge is 50 characters long.  The secret word need be only 10
letters, and the response alphabet is 3 letters, say 0, 1 and 2.  So
suppose the special characters are bruzCEHMOQ, and the secret word is
2012100211.  Here is a challenge:
Coming up with the response is left as an exercise for the reader.

@_date: 1995-10-18 06:55:06
@_author: Hal 
@_subject: Anonymity: A Modest Proposal 
Modemac proposes sending messages to remailers via newsgroup postings.
This is not a bad idea, although I would not use a shared secret key
for all remailers, but rather use a stealth system and encrypt for a
specific remailer.  However, it doesn't go to the crux of the problem.
of SENDING messages, not RECEIVING them.  This is how I can tell: my two
remailers, hal at alumni.caltech.edu and hfinney at shell.portal.com, are
different.  The first one is run on a "free" account whereas the second I
pay $20 to $50 a month for.  Also, the management at Portal has
demonstrated commitment to cypherpunk type goals.  So I view that
remailer as much stronger, politically.
As a result I have my alumni.caltech.edu remailer configured to forward
all messages via the portal remailer.  That means that no one will EVER
see an anonymous message from hal at alumni.caltech.edu.  People can send
messages to that remailer, but they come out via the portal one.
Now, since I have set it up this way, which was about two years ago, I
have not received a single complaint about operating the remailer at
alumni.caltech.edu.  Nobody sends me mail saying "your system is
accepting objectionable messages."  Instead, all the complaints I get are
about the Portal remailer (averaging one per week, probably).  People
complain when they receive a message or newsgroup posting that they find
objectionable.  They don't care if some system is accepting messages.
They care about the system which is sending them.
This has always been the weak link in the remailer system: the last
remailer in the chain takes the political and legal heat.  If there is
ever a libel or copyright infringement suit, or criminal prosecution,
against a remailer it will almost certainly be against the last remailer
in the chain.  Those are the source of the complaints and those are the
ones which people try to shut down.
So I don't think schemes to produce "virtual remailers" and such are
going to work unless you have a very secure remailer as the last in the
chain.  And once you have that there is not much need to change the
system for accepting messages into the remailer net.

@_date: 1995-10-18 09:38:06
@_author: Hal 
@_subject: Anonymity: A Modest Proposal 
I think splitting the message would be OK, but then the question is who
is responsible for reassembling it?  If there were a "reassembly
server" which took such messages, assembled them, and forwarded them,
then we would be right back where we started from.  If the end user is
responsible for reassembly, then that is tantamount to voluntarily
agreeing to receive anonymous messages, and that is no problem.  The
complaints we get are virtually 100% from people who didn't want to
receive such messages, or see them posted.  And of course anonymous news
postings via shadows would also have the reassembly problem.

@_date: 1995-10-18 09:43:43
@_author: Hal 
@_subject: Anonymity: A Modest Proposal 
I think a remailer which forged headers would get people even angrier
than one which was up front about what it was doing.  Forging headers is
really considered antisocial by a lot of people on the net.  If you could
do it safely, you wouldn't need remailers.  Since you need them, it's not
safe, hence the message will probably get traced back to the remailer.
This is prima facie evidence to get an account yanked at a lot of places.
The "human ID" thing requires a shared secret at both ends, which isn't
generally practical between a customer and a remailer.  Also, it was
specific to the needs of human minds; if you have a computer and a shared
secret you do a lot better to use DES or IDEA (and let the shared secret
be the key), and even without a shared secret you can use public key
techniques for identification and authentication.  So I don't think the
human ID approach would be relevant here.

@_date: 1995-10-19 07:28:13
@_author: Hal 
@_subject: 50 attacks... [NOISE] 
I had missed this in your original posting.  Here it is again:
Chosen plaintext attacks against RSA don't work in the context of RSA
signatures, because the input to the RSA algorithm is a hash of the
message being signed.  You can't control the hash the way you need to to
implement a chosen plaintext attack.  (You can't "choose" the hash.)
For example, one kind of chosen plaintext attack would be to get an RSA
signature on 2, on 3, on 5, on 7, and so on, on all the primes.  This
would let you create an RSA signature on any number by factoring the
number and multiplying the RSA signatures of its prime factors.  But
there is no way to do this in practice because as RSA-based signatures
are actually implemented only hashes are signed.  This is done exactly to
prevent this and similar attacks.

@_date: 1995-10-19 07:31:16
@_author: Hal 
@_subject: STT - useable in real life ? 
Usually, decrypt operations are needed to ISSUE certificates but not to
verify them.  Verification is equivalent to an encrypt operation using a
small exponent, and may be roughly about 100 times faster than a decrypt.

@_date: 1995-10-19 10:42:29
@_author: Hal 
@_subject: digital cash and identity disclosure 
There is an attack here, but the text doesn't go into detail about it.
You have to assume that (as with the current ecash implementation from
Digicash) people have non-anonymous accounts with the bank.  If Alice
wants to know Bob's identity she can collude with the bank to find
out.  As Tim describes, she gives Bob some money, then quickly deposits
the coins herself.  In effect, she intentionally double-spends (with
the bank's permission).  When Bob makes his deposit, his coins are
recognized as matching those which Alice double-spent.  So if Alice
was, say, an agent involved in a government "sting", and bought bootleg
software from Bob, his identity can in fact be learned when he deposits
the money.
Actually with the DigiCash system and in fact all of the ecash systems I
know about, you don't have to get so fancy; Alice can simply give the
bank a record of her transaction with Bob (the coins she sent him) and
these will be recognized when Bob deposits them.
Lucky Green has been discussing ways in which people could exchange coins
anonymously even with DigiCash's ecash in order to provide some immunity
from such attacks.

@_date: 1995-10-20 07:05:01
@_author: Hal 
@_subject: Polymorphic e-cash schemes was: digital cash and identity disclosure 
Unfortunately, in order for a coin to be POTENTIALLY spent in an off-line
way, the protocols require that the identity of the withdrawer be
embedded, in blinded form, within the coin data.  It is this step that
Tim and others object to, because among other things it requires
participants to securely identify themselves to the bank, hence does not
work well in a fully anonymous society.  The reason for this requirement
is that if the coin is double-spent, this is not found out until
afterwards, and so the identity of the cheater has to be available so the
bank can go after him.
So letting the payee choose whether to deposit the coin right away or
wait until later will not address this basic privacy problem with offline

@_date: 1995-10-20 07:55:08
@_author: Hal 
@_subject: Don't Kill the Messenger--A New Slant on Remailers 
To add some background, here are two recent complaints which I received.
They give some of the flavor of what people object to:
These messages show that most people are unfamiliar with the notion of
anonymous remailers.  Their first exposure to the idea is when they get
some objectionable anonymous mail.  So to the extent that the problem is
to be solved by education, we would have a very long row to hoe.
Fortunately, the vast majority of such complaints can be dealt with by
blocking the addresses of the people complaining from receiving future
anonymous mail.  This almost always satisfies people.
The idea of making people ask to receive anonymous mail is interesting.
It would not seem to apply to newsgroups and/or mailing lists, but for
individuals it might work.  The remailer would have to be able to
distinguish between "end users" and other remailers in order to know
whether it was just one step in a chain or the last step.  (We can't
depend on the sender to tell us that since it is abusive or harrassing
mail which will cause the problems, and senders of such mail would
presumably have incentive to get it delivered.)
It would require somewhat greater resources on the part of the remailer
to hold the messages.  I would guess from experience that a large
fraction of the messages would never be picked up, although my
perceptions may be biased since I only see bounced, poorly formatted, or
complained-about mail, and these categories probably have a larger
fraction of messages from clueless and obnoxious people.  But certainly
the messed-up messages I do see are mostly flames, "guess who's", and
similar worthless junk.  I hope there are some pearls going through that
I never see, but that is just a matter of faith.

@_date: 1995-10-21 13:53:08
@_author: Hal 
@_subject: Verisign and MITM 
I guess the one limitation is that you would either not get the
certificate (because the MITM kept it) or you would find out that it did
not include your public key (if he forwarded it to you).  In either case
the MITM would be discovered.  In the mean time he could wreak some
havoc, though.  But he would be found out after a few days.  That's one
of the things they need Certificate Revocation Lists for in their system,
but I don't know if they are used.

@_date: 1995-10-21 18:03:58
@_author: Hal 
@_subject: Encrypted TCP Tunneler 
This has a lot of potential uses.  It would be good if chaining were
possible, although that requires the client to double-encrypt.  That way
it can let people connect out without local snoopers seeing where they
are connecting.  However for this to work it is necessary that the DNS
lookup be done by the server rather than the client, and for the
destination (to which the server is supposed to connect) to be passed
I should mention by the way that I don't share the general pessimism
towards anonymous TCP/IP connections.  While truly strong anonymity
against a hugely powerful opponent is difficult, I think a system like
what Wei is describing would still provide important privacy protections
as more people get hooked into the net.
It should be noted that SOCKS V5 has basically the functionality that Wei
is describing, but I am not sure whether any implementations exist.  It
also has some other features which might not be appropriate for
this use.  The purpose of SOCKS is to tunnel through firewalls.
Unfortunately there is a also huge misuse of this program, as a
connection laundry for breakin attempts.  Hackers already go through
layer after layer of broken accounts, etc. to make tracebacks
difficult.  Read Stoll's "Cuckoo's Egg" for one account.  I think the
Mitnick story is similar.  These packet laundries would be extremely
inviting for this purpose.  The first time the ETT server is the base
of a lot of breakin attempts to military installations there is going
to be trouble.  SOCKS provides a config file for servers to limit what
kinds of connections will be allowed, but it is hard to see how to
filter out the bad guys while letting people go through who are
using services for which they are authorized.
Even if you don't try to provide anonymity with this service I think it
is still going to be a problem if breakins come from the server.  By
the time the traceback is initiated it is going to be a pain to figure
out where the connection was coming from.  The service would be similar
in this context to providing free guest accounts to which you could
telnet in and then telnet out.  I think any site which did this (some
used to in the relaxed old days) would take a lot of heat today.
I was toying with a limited form of this idea earlier, where outgoing
connections would be limited to http servers.  These are usually on a
small number of ports, although there are exceptions.  At least it
would be possible to filter out telnet and rlogin and such for that
application.  I don't think there are too many bad things you can do
just by connecting to httpd ports (probably I would be surprised,
though...).  But doing that would not make as much sense for the ETT

@_date: 1995-10-22 17:48:51
@_author: Hal 
@_subject: Real ECash from Mark Twain Bank 
will apparently have info on
its "real ecash" starting late Sunday, October 22.  It is not there yet
at 6 PM pacific time.
 will have a press
release soon, as well.  Here is what it says now:

@_date: 1995-10-22 19:55:36
@_author: Hal 
@_subject: How can e-cash, even on-line cleared, protect payee identity? 
One proposal I have seen here is to have a "coin changer" service which
turns the received coin in at the bank for you. Then the payer and the
bank and the coin changer all have to collude to identify you.  However
you have to trust the coin changer not to steal your money.  So it better
be a pretty trustworthy organization.
It would still be less than perfect to have all of a given nym's
transactions known.  In an ideal electronic cash system no transactions
are linkable if the participants don't want it.
In such a system you don't need an "account" as such, but rather the bank
simply allows used cash to be checked and exchanged for fresh cash via
anonymous connections.  This would be the most privacy-protecting system.

@_date: 1995-10-23 16:51:20
@_author: Hal 
@_subject: How can e-cash, even on-line cleared, protect payee identity? 
This is an interesting idea but it is more complicated than necessary, I
think.  The denomination can be carried in the exponent, in which case
there is no need for cut and choose and nobody can cheat the bank.  A
coin suitable for deposit is a signed number of some special form.  To
pay Bob, Alice does not withdraw anything ahead of time.  Rather, Bob
gives her a blinded coin, which she reblinds and gives to the bank.  The
bank signs it (debiting Alice's account) and gives it back to her.  She
strips off her blinding and gives it to Bob.  He strips off his own
blinding and verfifies that he is left with a signed number of the
appropriate form.
This system is in some ways the inverse of regular ecash.  Instead of
Alice withdrawing a coin ahead of time, and Bob checking it with the bank
right away, it is Alice who does the bank interaction at payment time,
and Bob who waits before interacting with the bank.  The computational
and communications costs do not seem much worse than ecash.
There is no way Alice can double-spend because she cannot anticipate
Bob's blinding factor and give him a previously-spent coin which will
unblind to the proper form.  There could be an issue of fraud, though,
where Bob insists that Alice's coin was no good even though it actually
was.  Since he has blinded it she will have no way of recognizing it when
he eventually deposits it.  In the current system this does not arise as
Alice can always give him another copy of the coin and prove that it is
good, and she can further determine if Bob has deposited it.  So some of
the trust in the bank necessary with regular ecash gets replaced by trust
between payee and payor in Simon Spero's system.
Still, I think this scheme has considerable merit and is worth exploring
further.  It seems to provide superior privacy protection over Chaum's
ecash.  The fraud issue can perhaps be dealt with by reputations and
credentials as we have often discussed.

@_date: 1995-10-24 06:58:19
@_author: Hal 
@_subject: Mark Twain Bank (was: Anonymity: A Modest Proposal) 
I don't believe this is correct.  The $250 refers to foreign currency
accounts and is not relevant for ecash users.  The ecash account has an
account opening fee of $11 and a monthly fee of $5 for the low volume
user.  That is all the minimum there is, as I read it.  You can reduce
the per-month fee by paying more up front, but it isn't a net savings
until you've had the account open for about two years.
It seems that there are three places "your" money can be: in the "World
Currency Access" account, where it is insured; in the "ecash mint", a
separate account at the bank, where it is not insured and in fact is
considered withdrawn (?); and in your ecash wallet on your computer disk.
You can transfer funds back and forth between your wallet and the "mint"
freely, but transfers are limited between the World Currency account and
the "mint" account.  It does seem like an odd approach, but perhaps there
are some legal reasons for doing it like this.

@_date: 1995-10-24 07:12:29
@_author: Hal 
@_subject: How can e-cash, even on-line cleared, protect payee identity? 
The problem with this is that Bob and the bank can now collude to trace
Alice, since he sees what she sent to the bank.  This is not as bad as in
the forward traceability case of regular ecash, because it happens after
Alice has completed her bank transaction, rather than before, but it
would be better to be untraceable since that is the whole point of this

@_date: 1995-10-24 07:27:12
@_author: Hal 
@_subject: How can e-cash, even on-line cleared, protect payee identity? 
This would work to protect Alice from certain kinds of fraud by Bob, but
it increases the amount of data considerably, and it still does not
resolve the main issue that Bob claims that his coin didn't unlind to
clean data.  Who is at fault in that case?  How can this be resolved?
Alice could give Bob bogus data, Bob could give Alice bogus data, Bob
could claim that Alice gave him bogus data (even though it was good).
If what she got from Bob was signed by him, she can prove that she gave him
back a bank-signed version of that.  (He has to sign it, otherwise she
could just exhibit two bogus numbers, one the cube of the other.)  Given
that, your idea seems good.  Alice can prove that she did her part OK, so
if she is able to show such a proof then Bob must be at fault.
Yes, I think so, so there is no need for the cut and choose.
I don't think they can.  All Bob sees is his own blinded coin, and the
signed version of that.  The bank sees a separately blinded number which
it signed.  Alice's blinding factor can be anything, so there is no
linkage between them.
However, the timing is a problem.  Bob knows _when_ Alice communicated
with the bank.  So he can collude with the bank afterwards to identify
those withdrawals which took place at that time, one of which must have
been Alice.  This could be a problem.
In regular ecash, the timing issue is potentially less serious because
the payee can in principle have a totally anonymous relationship to the
bank, and exchange his received coins for fresh ones.  But in this
system doing that is more difficult.  Alice must withdraw funds rather
than deposit them.  To do so totally anonymously she would have to
present coins to the bank at withdrawal time equal in value to the
amount she wanted to pay Bob.  The bank would replace these coins with
fresh ones that it signs, which are the doubly-blinded ones which Bob
has provided to Alice.  So this is a somewhat more roundabout
approach.  However, if you do this, and Alice communicates with the
bank anonymously, then both sides seem to be pretty well protected
against collusion.

@_date: 1995-10-24 10:14:29
@_author: Hal 
@_subject: subjective names and MITM 
Yes, this is a problem with the use of certificates to try to detect
the MITM.  As I wrote before, there is still a way in which certs can
be useful.  Your attack shows that you can't use true name certificates
to confirm that there is no MITM in front of Alice.  However, you can
use them to detect a MITM who is interposing himself between you and
the rest of the net.  In other words, if I am Alice, I can use
certificates to make sure that no MITM is behaving as above, altering
my messages and signing them "Hal".
What I do is to acquire a valid signature key via offline means, and use
that to validate the keys of people I want to communicate with.  I am
then able to send them messages securely, and ask them to confirm that my
keys and user name do match those which appear in messages I have posted.
The MITM is not able to know the contents of these messages which I send,
hence he can't stop me from finding out his existence.
IMO by itself knowing that the same person signed every one of a set of
messages is not that useful, since anyone can sign any message.

@_date: 1995-10-24 12:45:44
@_author: Hal 
@_subject: Hack DigiCash: Payee Anonymity 
I don't believe this $250 is correct.  The only place I see such a number
is on the application form, in the following clause:
"A maintenance fee of the foreign equivalent of $10 will be imposed each
statement period if the balance in your account falls below the foreign
equivalent of $250 on any day of the period."
This is for a "WorldCurrency Access Interest Account", which I don't
think is what is used for ecash.  For ecash the account opening fee is
$11 and the per-month fee is $5.  I don't see any reference to required
account minimums.
As far as the issue of coding up a payee-blinding cash system compatible
with this ecash, I agree that it would be good to see some specs now that
ecash is for real.  IMO Chaum has been getting a free ride based on his
reputation, with many people assuming that anything he is associated
with must be done right.  It is time for him to open his hand and reveal
his protocols so that people know exactly what they are trusting their
money to.

@_date: 1995-10-27 01:33:44
@_author: Hal 
@_subject: CJR returned to sender 
But lines are always arbitrary.  I posted about this a long time ago: it
is assault to hit a man with a baseball bat, but presumably not to hit
him with a feather.  Should we then ask if it is assault to hit him with
a straw hat, with a pillow, with a loaf of bread?  The lines which will
end up being drawn will also be quite arbitrary.  The line between day
and night is arbitrary but that does not mean that there is no difference
between day and night.  This whole exercise in line-drawing doesn't seem
that productive to me.
The appellate court has already ruled that restrictions on export of
printed materials do not violate First Amendment rights.  I wrote up one
of these, the Posey case, in
.  In that instance
the materials being exported were some manuals obtained from the US
government itself via the Freedom of Information Act!  The law in
question was not actually the ITARs but rather another one which applied
specifically to exports to South Africa, and which did not have the
public domain exemption.  The point though is that the court did not agree
that the First Amendment was relevant since the restrictions were
specifically on export and did not have any effect on domestic
distribution of the information.

@_date: 1995-10-27 11:47:11
@_author: Hal 
@_subject: Mark Twain Bank's DigiCash offer 
As far as I can tell there is no charge for moving funds between your
ecash wallet and the "mint" at the bank.  The charges are for moving
between the "mint" and the world access account.  If you had a shop
which was able to pay much of its expenditures in ecash it sounds like
there would be no percentage fee to the bank.

@_date: 1995-11-01 00:13:47
@_author: Hal 
@_subject: payee anonymity 
Another way payees could be anonymous would be to immediately spend their
received coins, and do so anonymously.  This works for the online ecash
system.  They simply pass the coins on without first exchanging them at
the bank.  There would have to be something they wanted to buy that they
could receive anonymously, though.

@_date: 1995-11-01 03:33:11
@_author: Hal 
@_subject: ecash remailer 
I think this is basically the scheme Lucky mentioned.  A more elaborate
version would have Bob sending Ed blinded proto-coins to be used in the
withdrawal.  However this would require hacking the ecash protocols to
work differently than intended, which would probably infringe the
What about this, though: Alice did not mean to pay Bob, but rather
Charlie, and Bob stole the coins.  He launders them through Ed's
service.  Charlie never got the cash, and Alice complains to the bank
that the coins were stolen.  The bank says, fine, we can identify the
perpetrator, let's see... it's Ed.  Ed is now charged with theft and
has an expensive and uncertain legal experience ahead of him.
Are you sure you want to put yourself in this position?  You might win,
but it could still be expensive (ask PRZ).  And if your service is seen
as a fencing operation to receive stolen goods with the legitimate uses
just a "cover", you could lose.
Also, I believe in normal use Digicash coins are marked as being for a
specific recipient.  This is not certain since no details have been
released.  And apparently it can be worked-around by the spender by
marking the recipient as just " (or some such string).  If this feature
is present in the Mark Twain cash then the payee-anonymity service may
not be very effective.

@_date: 1995-11-01 09:13:58
@_author: Hal 
@_subject: CJR returned to sender 
It is also worth noting that the ITAR violation is worded somewhat
differently from some laws, requiring "willful" violation, a "specific
intent" to break the law.  In this situation, good faith efforts to apply
with what the law appears to be would seem to me to be a strong defense.
See  for a writeup
I did on this a couple of years ago.  An excerpt, from U.S. v
Lizarraga-Lizarraga (541 F2d 826):
"Accordingly, we hold that in order for a defendant to be found guilty of
exporting under 22 U.S.C. 1934, the government must prove that the
defendant voluntarily and intentionally violated a known legal duty not
to export the proscribed articles, and the jury should be so instructed."
I am not a lawyer, however.  It would be interesting to hear what our
legal exports think of this argument.

@_date: 1995-11-01 14:29:00
@_author: Hal 
@_subject: Digicash tagged with payee? 
I have heard it claimed that when you make a payment with Digicash ecash,
the identity of the payee is encoded or embedded into the cash somehow.
This is an anti-theft measure (among other things, perhaps).  The bank
checks that the embedded identity in deposited cash matches the account
name which is doing the deposit.
My question is, how could this be done?  How can the payor, at payment
time, without communicating with the bank, embed a payee name
irreversibly into the cash so that a thief cannot strip it out and
replace it with his own name?
Is it perhaps a matter of encrypting the cash with the public key of
the payee?  If so, how does the payor get that?  Is it provided by the
payee during the TCP connection?  Is it authenticated with a
certificate, perhaps signed by some Digicash root key?
Off-list there has been some discussion about the role of certificates in
ecash, and in cash systems in general.  It would be interesting to know
if this anti-theft provision of Digicash is actually provided by means of
a certificate.

@_date: 1995-09-02 13:20:42
@_author: Hal 
@_subject: Crypto '95 report 
This was the first year I attended a Crypto conference (although for the
last two years I have "crashed" the evening rump session, where less
formal 5-10 minute presentations are given).  A number of list members
were present and it was good to meet a lot of new people.
I was a bit disappointed that few of the technical sessions were in areas
that I am interested in or that seem to have bearing on CP issues.  I
have read many of the Crypto proceedings and this year the pickings
seemed to be unusually slim.
Richard Schroeppel gave a very clear presentation on an implementation
of elliptic curve cryptography for a diffie-hellman-like key exchange.
This is a two-dimensional variation from the regular integers that are
used in most of the number theory based crypto, and has some
advantages.  This new implementation is actually faster than regular DH
for apparently the same security level.  It looks like elliptic curve
crypto is on the threshold of coming into widespread use.  I believe the
patent situation is one of the main reasons.
There were several papers on secret sharing, something we have discussed
here as an alternative to escrow for handling lost keys.  Amir Herzberg
et al had a method for "resharing" a shared secret periodically and
securely, so that if an adversary was stealthily sneaking in and learning
shares occasionally, he would be put back to square one when the secret
resharing phase occured.  Only the trustees are involved, not the
original secret holder, and the secret does not have to be reconstructed
during the resharing.
Bruce Dodson presented some results on using the Number Field Sieve
factoring algorithm.  Their implementation looks to be the fastest
available now, considerably better than the Quadratic Sieve that was used
for RSA-129.  I belive they estimated 1000 MIPS years would have been
enough for NFS to do RSA-129 compared to the 6000 MIPS years for QS.
They are now going to try another challenge number, RSA-130.  (RSA has
challenge numbers every 10 digits in size (or maybe it was 5): RSA-140,
RSA-150, etc.)
There was one paper on electronic cash, by Okamoto.  His technology is
distinguished by allowing divisibility - you can take a $10 and divide
it into 2 $5's without going back to the bank.  However he has always
had a problem that your various pieces of cash are linkable, although
not traceable to the user who withdrew them.  His new method uses
smaller amounts of data.  I was encouraged to see some progress on the
linkability issue: for the first time (that I have seen) he admits it
as a problem; he now has it so that theoretically the linkability is
only within a single divided piece of cash (so that if you didn't
divide you wouldn't have linkability).  Actually the overheads are too
large for this to by quite true, but it is a step in the right
direction.  He also included elimination of linkability as a future
goal.  Unfortunately his oral presentation was extremely shallow,
mostly describing what electronic cash was.
There was also a paper on "fingerprinting", the encoding of hidden
information into a document so that if the doc is leaked it can be traced
to the leaker.  The talk wasn't very clear but I was able to glean enough
that I now believe that this is possible whereas I didn't before.
I was discouraged to see a whole session on key escrow.  One presenter
described key escrow as a whole new area of cryptography, analogous to
the discovery of public key crypto when all that was known previously was
conventional key.  Now there are three areas.  The academic crypto
community seems to be greeting key escrow enthusiastically as a new
technical challenge.
The rump session had some good stuff, I thought.  Matt Blaze et al had a
paper on "Master Key" cryptosystems, a variation on escrow where the
government can read all the messages using a certain cryptosystem.  They
pointed out the similarity to the trap door concept used in public key
cryptography and concluded that an efficient master key system would be
an efficient public key system.  If you believe that the latter can't
exist then it follows that the master key versions can't exist either.
Bruce Schneier gave a talk summarizing the sketchy information known
about Skipjack (the cipher in Clipper), including some FOIA'd docs.
These included some comments from design reviews by Mycotronix on
earlier versions, which included references to F and G boxes or
tables.  This is the first I had heard of this and helps explain why
people thought S-1 was Skipjack or a hoax, since it had F and G
tables.  (I hadn't felt that the number of rounds and key/block sizes
were sufficient coincidence to preclude independent invention.)
A new crypto library was announced from AT&T.  It is written in C and
has a bignum lib (arbitrary size) and the usual crypto suspects,
although I think not RSA presuambly due to patent issues.  On a
reasonably modern PC it could do an RSA 1024 bit signature in 900
milliseconds.  Email to lacy at research.att.com with subject CRYPTOLIB to
be informed on when it will be released and how to get it.
Dhem and Quisquiter described CASCADE, a smart card system with voice
recognition for ID rather than the PIN usually used.
  This talk was hard to
understand due to the language differences.
Eric Hughes, co-founder of the cypherpunks, announced the formation of
Cypherpunk Laboratories, a California non-profit corporation.  It is
intended to be a common resource for people motivated by freely available
strong cryptography tools.  Among other things it will offer scholarships
and prizes to students who create relevant work and papers, consider
establishing an online journal focusing on implementations of crypto, and
work on software development.  One project Eric mentioned was to create a
replacement for PGP.
Ron Rivest proposed probabilisitic key escrow, which he described as
"translucent" crypto.  The idea is that with every message you send
there is a Law Enforcement Access Field, but there is only some
probability p that it is readable, and you can't tell if it will be
readable or not.  This way you don't lose as much privacy but criminals
can't take the risk that maybe they'll be unlucky and this particular
message will be readable.
Shamir had an interesting paper on preventing "flooding" attacks.  A
server may check for signatures on incoming messages to reject bogus ones
(only certain sigs are valid) but just doing a signature check may take
too long if it is really being flooded.  Shamir came up with a kind of
signature which can be quickly probabilistically checked, based on a
variation on the Rabin cryptosystem.  You can do almost all the work
using single precision and it should be very fast.  I will write this up
if anyone is interested.
Our own Wei Dai, at 19 the youngest author, has spent his summer
vacation developing with Josh Benaloh at Microsoft an improved modular
reduction algorithm, which unfortunately will be patented (or at least
they will try).  BTW a number of people from Microsoft were in attendance
at Crypto, including other list members.  Obviously this crypto stuff
is considered very important at MS.
One of the more interesting talks I thought was from cypherpunk Doug
Barnes, on "identity agnostic" electronic cash.  This is basically an
idea for creating a Magic-Money-type electronic cash server without
violating Chaum's cash patent.  What you do is to run the server and
publish a spec it will follow.  All the server does is do an RSA
signature on the raw data it receives and decrement the user's account
accordingly.  The user has a choice of doing blinding or not on the
Chaum's patent covers the blinding, so if the user wants to do that he
should be sure to license the patent or live somewhere it doesn't apply
(or ignore it if he figures he's too small potatoes for them to care
about).  But the server isn't responsible for checking all this.  It just
does RSA sigs, which is prior art as far as Chaum's patent goes.  Users
can blind or not, it doesn't care.  It is "identity agnostic" as Doug
The implication is that with an RSA license you could run this kind of
bank (online cash) and ignore Chaum's patents, while a horde of end users
violate the patents but take safety in numbers and get anonymity.
Lawyers like to go after big targets but the servers aren't violating
The other things I enjoyed in the conference were the non technical talks
by Bob Morris (senior), retired NSA, and later Adi Shamir.  Morris said,
with what I thought was peculiar emphasis, "never underestimate the
amount of time, money, and effort your opponent will put into breaking
your encryption."  He was supposedly speaking in the context of the
German (and Allied) mistakes during WWII, but I got the impression he was
talking about today, and in fact warning of NSA efforts to spy on people.
He went on to describe the many ways mikes and antennas can be planted or
used - he looks at a telephone and sees a microphone, and the hand cord
is an antenna.  All in all a rather chilling talk from someone who
obviously can't say as much as he would like to.
Shamir had some interesting anecdotes about the invention of RSA.  He
emphasized what amateurs the three of them were, claiming this was
probably an advantage.
Some of the other talks I enjoyed without following all the details were
the cryptanalysis ones.  A lot of systems were broken or weaknesses
found.  Most were not ones I was familiar with but it just emphasizes how
hard it is to really come up with something strong.  All those bozos on
sci.crypt with their "break this" challenges would benefit from seeing
some of these results.
All in all there were several interesting results even if the percentage
seemed smaller than usual.
Hal Finney

@_date: 1995-09-02 17:17:59
@_author: Hal 
@_subject: PGPfone over Appletalk 
I changed the preferences box setting, but then I exited and restarted
the program so that it came up in "appletalk" mode.  This is probably
the step you are missing.  I did this on two different machines, and
then when I clicked connect it no longer tried to open the modem,
instead it put up a dialog box allowing me to click on the machine
running the other PGPfone.  I did that and it connected OK.  There is a
nice audio simulation of an old-fashioned telephone bell ringing.
Unfortunately my appletalk "network" consists solely of my power mac
and an old 68030 mac laptop, the latter apparently being underpowered for
PGPfone.  The voice quality changed occasionally as the software
adaptively tried different coders, and the powermac instance of the
program finally printed a message saying that the list of coders had
been exhausted.

@_date: 1995-09-02 18:14:53
@_author: Hal 
@_subject: Quickly checking signatures 
Let me describe Shamir's method for quickly doing a probabilistic signature
check.  Since this was a rump session paper he didn't have it written up.
Shamir uses a variation of the Rabin system.  The Rabin encryption
system is similar to RSA, but instead of exponents which are relatively
prime to the predecessors of the factors of the modulus, the exponent
used is 2.  This requires somewhat different techniques.
A message M is encrypted by doing M^2 mod n.  The decryption is then
done by taking the modular square root.  There are a few technical
hitches that occur here but nothing major.  Similarly a message M is
signed by calculating its modular square root S such that S^2 = M mod n.
Note that with Rabin you can't just sign any arbitrary number as that
may allow the factors to be revealed.  However this is not a major problem
because practical systems in use today sign specially padded hashes,
not arbitrary numbers.
Now Shamir uses a slight modification to this.  Normally we have:
This can be written as:
for some C, which is simply the definition of modular equality.  Now,
what he suggests is that instead of sending S as the signature of M, you
send C.  This is justified on 3 grounds:
However, by sending C as the signature of a message M it allows a fast
screening to be done.  The idea is that the message should be accepted if
M+C*n is a perfect square (because then S can be derived as the normal
square root - that is how you get S from C as mentioned above).  And this
is something that can be checked quickly.
In number theory there is a notion of a "quadratic residue" modulo some
number.  If a number is a quadratic residue that simply means that it has
a square root, that it is the square of some other number using the
modulus.  With a prime modulus half of the numbers are quadratic residues
and half are not.  For example, with modulus 7 the q.r.'s are 1, 2 and 4
and the non q.r.'s are 3, 5, and 6.  It turns out that testing whether a
number x is a quadratic residue modulo a prime p can be done by
calculating x^((p-1)/2) mod p.  This will be 1 if and only if x is a q.r.
Now, the key idea is this: if a number is a perfect square then the
result of taking that number modulo a prime must be a quadratic residue.
This means that we can quickly determine that C is a perfect square by
checking whether C mod p for various random small primes p is a quadratic
By picking p to be a single precision prime of say 16 bits, the q.r.
calculation can all be done without using multiple precision arithmetic
and so it will be very fast compared to actually checking a signature.
So, the procedure for the check is as follows: given n, M and C, choose a
small prime p and calculate M+C*n mod p.  Then raise this to the (p-1)/2
power mod p and see if the answer is 1.  If it is, we give a
"provisional" acceptance to the signature.  If it is not, we reject the
signature; it cannot be valid.  This test may be repeated a few times
with different values of p to improve the rejection of bad signatures.
Once we have taken the input numbers mod p the rest of the arithmetic can
be done with ordinary single precision integer variables.
(One thing I overlooked is the possibility that M+C*n will be a multiple
of p.  In that case M+C*n mod p will be 0 and this is a provisional pass.)
Of course checking the signature the old-fashioned way just takes a
single multi precision multiplication, which won't be all that slow.
So this puts a limit on the number of p's you can check this fast
way before it becomes slower.  Also, you'd have to choose the primes at
random as otherwise an attacker who knew your p's could conjure up a C
which would produce a quadratic residue for some small number of known

@_date: 1995-09-03 08:18:22
@_author: hfinney@shell.portal.com 
@_subject: Slightly faster checking for encrypted messages to me 
One idea we have often discussed is to use a public message pool such
as a newsgroup or mailing list reflector as a means of receiving
messages anonymously.  Each message would be encrypted with my public
key (or that of my pseudonym), but with the identifying information
stripped.  Then I need to scan them all to see which ones are encrypted
to me.  Those are the ones which decrypt under the public key system to
a correctly padded session key.  Doing it this way eavesdroppers can't
even tell how much mail my nym is receiving.
The problem is that doing a PK decrypt is time consuming, and if we had
to do it to all the anonymous mail traffic in the world it could become
I had hoped that Shamir's idea which I posted earlier would help with
this, but I can't see an application.  His idea helps to check for
specific signatures, which is a thing anyone can do, but he lets you do
it faster.  We need a faster way to do a check which only the holder of
the secret key can do.
I have thought of a small improvement based on Shamir's ideas, though.
Use Rabin encryption rather than RSA.  In this system the decryption
involves taking square roots.  This is done by taking the square root of
the ciphertext mod p and q (the two secret primes) and using the Chinese
Remainder Theorem to get the square root mod n.  (This is also done in
RSA with eth roots.)
If p and q are 3 mod 4, you can get the square root of x mod p as x^((p+1)/4)
mod p.  This is done for p and q and you then combine them.  So the
amount of work is pretty much the same as for RSA.
However a speedup is possible to do a quicker check for a validly formed
encrypted message.  The idea is that the encrypted message is of the form
M^2 mod n.  This means that it is a quadratic residue mod n, and also
therefore a q.r. mod p and q.  So the speedup is simply to check whether
it is a q.r. mod one of the primes and to reject it if not.  This takes
about half the amount of time to actually try the decryption.
All valid messages will pass the test, and half of the invalid messages
will be rejected.  So this is not very strong, but it is perhaps better
than nothing.  Maybe Shamir will come up with some idea for this
As I wrote before, testing for a q.r. is done by raising to the (p-1)/2
power mod p, and seeing if the answer is 1.  I think this can be done
in such a way that if it does come out to be 1 we can use our
intermediate results to calculate the (p+1)/4 needed for the square
root very quickly.
Also, BTW Rabin encryption is not specifically patented, only the
relatively-untested and almost-expired patent which covers all public
key systems (with the failed knapsack algorithm as its specific
embodiment) would supposedly prevent its use.  However even PKP is
apparently becoming more reluctant to throw its weight around on this
patent, while they are still quite possessive about RSA.  So perhaps a
migration to Rabin is in order.

@_date: 1995-09-03 12:49:19
@_author: Hal 
@_subject: SSLRef (SSLtelnet) 
The link I used recently to get SSLREF is .  I don't now what
kind of export restrictions this enforces.
I was hoping to write a program which would sit on the user's PC and act
as a proxy for Netscape's browser.  It would connect using 128 bit SSL
instead of 40 bit.
The stumbling block is that Netscape won't connect to even the local
proxy unless it sees a valid certificate, one signed by a CA that it
accepts.  For this application I would need such a certificate, and make
the corresponding public and private keys public, hard-coding them into
the proxy.  Since the proxy runs on the same PC as the browser there is
no need for confidentiality between them, and the secret key can be
Does anyone have an idea for a way to acquire a certificate acceptable to
Netscape, perhaps one with a "broken key", that could be used for this

@_date: 1995-09-03 21:52:26
@_author: Hal 
@_subject: pseudonyms & list health 
An interesting point.  I have long wished that there would be a form of
"credential certificates" which people could give as special signatures
on other people's public keys.  Then using Chaumian credential technology
it would be possible to anonymously transfer these credentials from one
pseudonym to another.
This is not a perfect solution, of course.  Much reputation is informal
and simply resides in the opinions held in people's minds.  But perhaps
if a more structured solution like this became widespread it would help
to prevent the "concentration of reputation" which Vlad describes.
Along with the usual flames, I occasionally get messages saying nice
things about postings I have made, and I sometimes save these in a file
called "praise".  Here are some excerpts:
I certainly appreciate these kinds of comments, but it would be even
more useful if such messages were expressed as the kinds of
certificates I am describing.  I wonder whether people would be willing
to use a program which would let them issue such "reputation
signatures" of various kinds, and display the signatures which were
present on keys.
Discussion of such schemes has often bogged down in considering the
various categories or types of credentials people might want to give.
This is somewhat analogous to the "rate-the-net" schemes we have talked
about where a similar issue arises if we try to mark pages with a whole
range of characteristics so people can judge whether they should let
their kids read them.  Perhaps the solution needs to be found in
simplicity.  SurfWatch (as I understand it) gives a simple "thumbs down"
to selected web pages.  Maybe a simple "endorsement" would be useful as a
reputation credential without trying to identify exactly what it is about
the person you are endorsing.
I could see such a system initially being piggybacked on PGP keys (the
signatures would not be understandable by PGP though), although for
Chaumian credential transfers the keys have to be specially structured
and that would require a new approach.
Who would be willing and/or interested enough to use such a system if it

@_date: 1995-09-04 21:19:00
@_author: Hal 
@_subject: SSLRef (SSLtelnet) 
Yes, this is my understanding.  I have also heard that the process is
not easy or routine, that the business plan receives considerable
scrutiny.  What I would be doing with the certificate is
unconventional.  I would publicize the secret key, and ship out free
software which would use the certificate to establish SSL
communications with the Netscape browser within the same PC that runs
the browser.  The real purpose of the certificate is not to
authenticate the key of a server running remotely, but simply to bypass
the security checks within Netscape Navigator.  So I am not confident
that this business plan will pass Verisign's muster.  Among other things,
it would be difficult to enforce the one year restriction (unless
Navigator checks a date in the certificate).
I understand that Netscape's browser will also accept certificates
created by a Netscape-internal "test" CA.  I hoped that perhaps some junk
certificates from that CA might be floating around, ones which would be
useless for conventional purposes because their secret keys are exposed,
but which would be perfect for my needs.
There is one "fallback" strategy possible which would allow the 128-bit
SSL security proxy to work.  That is to filter *all* connections, not
just secure ones, and convert https: URL's to http:.  Then Navigator will
not attempt to make any SSL connections at all, and the proxy can talk to
it non-securely, using 128-bit SSL for the external connection to the
server.  However this would be much harder, and the proxy would have to
somehow remember which URL's had been massaged like this so it would know
which ones are eligible to have secure connections made.

@_date: 1995-09-05 16:11:53
@_author: Hal 
@_subject: Forgery, bills, and the Four Horsemen  (Articles and Comment) 
This is not completely correct; there is a degree of anonymity in
DigiCash's ecash.  That is anonymity of how a person spends his money.
Neither the bank nor the payor is in a position to learn who or where a
particular piece of ecash comes from (assuming that anonymous
communication means are used).
This is not trivial anonymity.  IMO the greatest privacy threat posed by
credit cards is exactly this, the tracking of spending information and
patterns.  With credit card payments a great deal of information can be
learned by the credit card company about what I do.  With ecash almost no
information is learned, only the raw amounts I spend.  And if I occasionally
make payments to myself even that is blurred.
Ecash is not all that we might hope it could be but it is more than a
myth that it allows untraceable transactions.

@_date: 1995-09-05 21:33:34
@_author: Hal 
@_subject: Forgery, bills, and the Four Horsemen  (Articles and Comment) 
This would be true for physical goods in any payment system, no matter
how anonymous, unless physical remailers are used (and they have their
limitations).  However software (including music, video, etc.) would be
easier to deliver anonymously.  It is generally agreed that more of our
economy is moving towards information exchanges and so ecash-like
systems can play an increasingly larger part in protecting privacy.  To
me, this is indeed a big deal.
Even for physical goods, the use of ecash is better than credit cards
because the information about purchases is distributed rather than
centralized.  Every time I look at my credit card bill I feel dismayed
at what the company is finding out about my family.
Ecash could also be used as a cash replacement in smartcards.  Consider
as an alternative a fully traceable payment system, where you use your
debit card at the supermarket, the bus station, the snack bar, the drug
store.  I suspect that if we don't get something like ecash then this
system will be the alternative.  It opens up possibilities for
dossiers that will fulfill Big Brother's dreams.  Virtually every move
of every citizen will be recorded in just a few centralized places.
IMO the protection of payor privacy that even Chaum's limited ecash
provides is very important.
Well, I have never fully accepted the notion that crypto was going to
usher in an age of anarchy.  As long as we deal with physical goods in
the physical world it seems to me that anonymity will be difficult.  On
the net it is easier but man does not live by bits alone.
For me, protecting privacy is a difficult enough problem.  Transforming
the world into a libertarian/anarchist utopia is somebody else's job.
P.S. Without seeing the technical specs it is hard to describe in detail,
but generally Chaumian ecash allows fully anonymous coerced transfers.
The payee/coercer supplies the blinded coins and forces the payor to use
them to make withdrawals from his account.  The resulting signed
tokens are passed to the coercer who unblinds them and now has fully
anonymous, untraceable cash tokens which he can spend.

@_date: 1995-09-08 09:12:45
@_author: Hal 
@_subject: GAK Hacks 
It is interesting to see that the proposed solutions to avoiding GAK
hacks (URL: largely revolve
around certificate restrictions.  Only keys signed with certificates from
accepted escrow agencies can be used, and there is a "root certificate"
used to authorize new escrow agencies.
This is similar to some of the restrictions in the widely used Netscape
web browser.  It only accepts certificates from a limited number of
agencies (actually only one which is public, the RSA spinoff
VeriSign).  This limitation is not based on escrow approval as in the
GAK papers, but it ends up with something of the same results:
interoperability with Netscape is only possible if you go through
approved channels.  And supposedly VeriSign does not make it too easy to
get a certificate if you are not a straight-arrow corporate type.
Maybe it would be good practice for a future GAK hack to try fixing these
problems with Netscape.  I could see two possibilities.
One would be to create a patcher which would let you change the set of
certificate authorities accepted by the browser.  Currently the browser
accepts at least one (an internal Netscape test CA) which is not needed
by end users.  Maybe its public key could be statically overwritten by
the patch program with the public key of the replacement CA.  This sounds
simple and safe.  The patch program can confirm that the data being
changed matches the test CA.
Another idea would be to patch the browser to emit full 128 bit SSL
rather than the crippled 40 bit SSL it currently creates.  This would be
trickier as it requires code changes, but they may not be as bad as it
seems.  The 40 bit SSL is actually calculated as 128 bits internally.
Then 88 bits are sent in the clear.  We would need to skip sending those
88 bits, and also change the transmitted bytes which encode which
encryption is being used.  This shouldn't be too bad as it mostly would
eliminate code or change some static values.  The one thing I am unsure
of is whether the 40 bit version sends the entire 128 bit SSL key in the
RSA encrypted data (88 bits of which would be redundant, also being sent
in the clear) or whether it sends only the 40 bits RSA encrypted.  If the
latter it would be somewhat more work to do the patch because now a
larger value will have to be packed into the RSA record.  If it is sending
the 128 bits all the time then the patch would be much easier.
This second patch is more advantageous for end users as it allows them to
have strong encryption rather than the weak 40 bits which we have been
breaking.  The first would be a more direct demonstration of the
difficulties of using certificate restrictions to limit functionality.
The criteria.txt paper suggests checksumming the cryptographic routines
to prevent patches like this, but generally I think such checksums can be
defeated pretty easily.  I doubt that Netscape currently has any such
thing, though.
Netscape says they will allow some form of user specification of
certificates in a future version of the browser, but they have been
saying this for quite some time and still it is not here.

@_date: 1995-09-10 12:13:27
@_author: Hal 
@_subject: Brand e-cash implementation? 
Brands has a web page at .  I don't know
of any implementations of his technology.  The last time I heard from him
was early this year and at that time he apparently was still looking for
BTW he has a new paper out as of July 95, available above, which
discusses some problems and attacks on some earlier papers.  He had
proposed a notion called "secret key certificates" in which some
problems have been found.  Basically a secret key certificate is just
like a public key certificate (a signature by someone on a public key
as in PGP) except that realistic-looking but ultimately worthless
secret key certificates can be faked up (simulated) by anyone.  No one
can distinguish a fake secret key certificate from a real one.
However, they are worthless because the faking process requires you to
choose a random public key, and you can't figure out what the secret
key is.
Brands has (re)expressed his digital cash technology in terms of these
secret key certificates.  But Berry Schoenmakers of CWI has shown a way
in which a faked-up secret key certificate can be used to spend a coin
which was never withdrawn.  However, to do so, you have to go through
the withdrawal protocol in a particular incorrect way.  You force the
bank to act as an "oracle" for a certain discrete log problem when you
do the withdrawal.  The data you get from the incorrect withdrawal
protocol allows you to spend the fake coin.
So this is not actually a dangerous attack, because you in effect have to
withdraw a coin in order to spend the fake one.  You can't make any money
from it.  Still it was not anticipated and that is a bit worrisome.  I'm
not sure why Brands' various proofs of correctness (which are one of the
big selling points of his technology) did not anticipate this attack.
(In effect this is a different form of a blind signature than what
Brands planned for, since you withdraw one thing and get another.  I was
thinking Brands should write this up under the title "Unanticipated
Blinding for Signatures", a pun on Chaum's "Blinding for Unanticipated
Signatures", one of his credential papers.)
Brands has a workaround to prevent this attack, but it hurts the
provability of his scheme.  "A rigorous prove [sic] of the effectiveness
of the measure may be hard to provide, though, since one must hereto
prove that the CA cannot be used as an oracle to perform the
cryptographic action in the showing protocol with respect to simulated
public keys."  So this may be a setback in Brands' attempts to get his
thesis finished and accepted.
As for the question of whether any digital cash scheme offers "true"
anonymity, I think you have to be more specific.  Virtually all cash
advocates will claim that they can offer this.  In the debate I had
earlier with Lucky Green I argued that Chaum's ecash does offer a certain
kind of anonymity.  The extent to which it does not is largely not
technical but a product of not allowing anonymous bank accounts.  With
anonymous accounts Chaum's technology offers as much anonymity as any
system that I have studied.
There is one technical problem with Chaum's ecash which Lucky mentioned,
but I believe it applies to all systems.  That is that the spender of the
cash can "mark" it or at least recognize it when it is later deposited.
If the spender wanted to attack the receiver of the money and it is
deposited non-anonymously then this will be a problem.
However, as we discussed here several months ago, Chaum's paper
"Transferred Cash Grows in Size" from a recent Crypto proceedings shows
that by colluding with the bank a payor of cash can recognize it at any
later stage of the payment chain.  So this kind of anonymity is very hard
to achieve.  Chaum's paper applied to off-line cash, though, so perhaps
an online system could do it.  But you'd have to blind the coins twice,
once when they pass from bank to payor and once when they go from payor
to payee, and I don't see how to do this.
Hal Finney

@_date: 1995-09-10 19:31:44
@_author: Hal 
@_subject: Digital Fingerprinting 
I'm not sure how to do it for software, but for novels it should be easy
to fingerprint.  Every couple of pages the author writes a sentence twice
in different forms.  This would not take a great deal of extra effort on
the part of the author.  Software can then choose from the alternative
variations in different patterns to produce a unique fingerprint for
every copy.
There would seem to be two approaches to removing the fingerprint.
One would be re-writing every sentence in the novel.  The other would be
to collect enough copies to identify all of the sentences which have
variations.  Most of the mathematics of fingerprinting research is
oriented around figuring out how many different points of variation there
must be to be secure against a certain number of copies of the
fingerprinted item being compared.
Perhaps a similar approach could be applied to software, where in many
cases a couple of statements could be trivially interchanged, or other
kinds of simple transformations could be manually generated.  Those
could be marked by the programmers without too much extra work.
I agree with Doug that fully automated fingerprinting schemes which post
process "vanilla" documents are going to be forced to rely on security
through obscurity, probably a losing battle.  Also as Doug says the
viability of legal sanctions against the source of fingerprinted docs is
questionable.  Maybe it could work if you had just a few copies out and
the people who were given copies can be seriously held to non-disclosure

@_date: 1995-09-11 21:54:01
@_author: Hal 
@_subject: Brand e-cash implementation? 
has a
good collection of earlier discussions on Brands' cash, as well as
pointers to Brands' work itself.
Brands' home page,  has a long list of
advantages which his system has over Chaum's original cash proposals,
mostly technical in terms of efficiency and provability.
Brands' and Chaum's systems have similar anonymity properties so I don't
see much to choose between them on political grounds.  Brands tends to
work in the context of off-line systems with "observer" chips which
prevent double spending.  But his protocols can be used in other payment
environments as well.
Hal Finney

@_date: 1995-09-13 07:35:26
@_author: Hal 
@_subject: GAK/weak crypto rationale? 
Responding to msg by futplex at pseudonym.com (Futplex) on Wed, 13 Sep  2:11 AM
I think this is setting up the rationale for software key escrow.  One of
the big loopholes in this idea has always been that it would be easy for
bad guys to superencrypt or otherwise bypass the legal encryption.  The
response has been that the systems will be designed so that compliant
systems will not interoperate with rogue systems.  And the counter-response
to that was that criminals (and privacy advocates) would use software
which would operate compliantly with conventional programs and maintain
privacy when talking to other rogue programs.
This new line will be used to respond to this argument, I think.  Even if
it is admitted that there is no way for the government to be able to tell
what the criminals say amongst themselves, it will still be useful to be
able to tell what they say to other people.  Therefore software key
escrow will be argued to still be useful even though it can be defeated.

@_date: 1995-09-13 14:22:36
@_author: Hal 
@_subject: Digital Cash on sci.crypt 
There has been some discussion on sci.crypt of digital cash and its
facilitation of kidnapping, extortion, etc.  Here is a posting I made
when mentions an on-line paper on the topic.  I had met the author,
Markus Jakobsson, at Crypto 95, but I only had a chance to check out his
web site yesterday.
There has been considerable discussion of this problem in the
literature recently.  A paper I found yesterday on the net is by Markus
Jakobsson and Moti Yung: Revokable and Versatile Electronic Money, at
 (postscript
format).  It has references to other work as well.
The specific attack I discussed earlier applies to the current DigiCash
scheme (or at least how it is assumed to work).  Offline cash systems
would be more complicated.  The references in the paper mentioned above
describe how these attacks would work on such systems and some ways of
avoiding them.
However there is a more powerful attack, which the Jakobsson paper
addresses, in which the bank as a whole is coerced.  Maybe terrorists
threaten to blow up the World Trade Center unless Citibank engages in a
specific protocol which will leave the terrorists with millions of
dollars in fully blinded electronic cash.  Even if the normal withdrawal
protocol has signatures, etc. which would prevent this, Jakobsson shows
that there is a corrupted protocol which if the bank is forced to follow
it will leave the criminals with valid but untraceable electronic cash.
The solution in the paper is to make it so that none of the ecash
issued by the bank is untraceable.  Under normal use it is anonymous,
but if necessary the authorities can break the anonymity.  This is
sometimes called "Clipper cash" after the U.S. Clipper chip proposal
which had similar privacy properties.
With Jakobsson/Yung's approach even the more powerful attack can be
defeated because the cash is traceable, and no amount of coercion will
allow the attacker to create valid but untraceable cash.
While these approaches are technically interesting, the political
implications are more ominous.  While Jakobsson labels the entity who has
the power to break the anonymity an "ombudsman", implying that he defends
the interests of the cash holder, he could equally well be called a
"policeman" because he is the one who catches the criminals.  It is all a
matter of how you look at it.
The question is whether these various threats of kidnapping, blackmail,
extortion, etc. are good enough reasons to go to a cash system where
privacy is protected only at the sufferance of government agencies.
There are plenty of precedents for governments misusing supposedly-
private information, such as the use of phone records to track down
those who resisted the German regime during World War II.  One of the
attractive aspects of electronic cash has been its immunity to this form
of governmental coercion.  The overwhelmingly negative response to the
Clipper chip proposal (other than in the cryptographic and law
enforcement communities) may apply to Clipper cash as well.
A related issue is the possible competition of rival cash systems.  As
with Clipper, where it would apparently be necessary to forbid the use of
alternatives, so with Clipper cash it would seem that people would prefer
true anonymity over conditional protection, even if you call the cash
tracer an "ombudsman".  So there would seem to be a need for governments
to criminalize the use of fully anonymous electronic cash in order to
force people to use the ones which the government could track.  Whether
this will even be possible in an increasingly global financial system
remains to be seen.
Hal Finney
hfinney at shell.portal.com

@_date: 1995-09-13 15:28:19
@_author: Hal 
@_subject: Can GAK be made "not interoperable" with PGP? 
Yes, I think this was the idea of the original "software key escrow"
proposal, from TIS as I recall.  The sender would encode the session key
with a government public key but there was some trick by which the
receiver would verify that the session key was in fact encoded correctly
and refuse to operate if it was wrong.  So any attempt to corrupt or
remove the LEAF would be detected if you were talking to a compliant
That is part of why Matt Blaze's Clipper attacks were so significant,
because they went to the heart of this requirement.  It was always clear
that you could superencrypt with Clipper, but Matt found a way in which
you could send a LEAF which would be accepted by a regular Clipper phone
but which had bogus data for law enforcement.  So this defeated the
requirement of not interoperating with rogues.

@_date: 1995-09-14 22:34:01
@_author: Hal 
@_subject: Why ecash is traceable 
There has been considerable discussion on sci.crypt and on the cypherpunks list about the fact that currently proposed digital cash is "traceable", or to put it another way, that there is no payee anonymity.  This is an annoying asymmetry, where the payor is protected more than the payee.  But there is a fundamental reason for this, which I want to explain here.  It is not just perversity on the part of digital cash The problem is that there is a conflict between the desire for payee anonymity and the need to prevent double spending.  And preventing double spending is far more important, since without that the cash would be worthless.  Here is how the conflict occurs.
Suppose Alice has a piece of digital cash which she wants to spend with Bob.  She goes through some protocol and transfers data to him.  Bob, then or later, sends some resulting data to the bank and gets his account credited.  Now if Alice spent that same coin with Charlie, we need to have the bank find it out.  When Charlie deposits his data with the bank, and the bank compares that with what Bob sent in, there must be a red flag that goes up.
The fundamental requirement of preventing double spending implies that
Bob's and Charlie's data, when sent to the bank, has some correlation
which will identify the fact that they both come from the same coin.
It doesn't matter exactly what the form of this data is, or how it has
been blinded and stirred, but if double spending is to be detected
there must be a correlation which the bank can see.
But this correlation is what makes the coin traceable.  Suppose Alice is paying a coin to Bob via an anonymous network, and she and the bank are going to try to figure out who he really is.  She goes through the payment transaction, and Bob sends his resulting data to the bank.  Before doing so, though, Alice simulates a payment of the same coin to Charlie.  Charlie doesn't actually have to be involved, Alice can just go through what she would have done if she had spent the coin elsewhere.  The result of this simulated payment has been shared with the bank.
Now, when Bob deposits his data, the bank compares it with the data Alice sent, the result of her simulated spending of the same coin.  By the argument presented above, Bob's deposit will be flagged.  It will correlate with the data Alice sent in since this will be the equivalent of a double-spending.  So when Bob makes the deposit he can be linked to the specific coin payment which Alice made, and his anonymity is lost.
It would seem that any system which is capable of detecting double-
spending just from the information which the payees send in to the bank would be vulnerable to this.  Systems which use tamper-proof observer chips to prevent double spending beforehand can avoid it, but of course if someone breaks an observer the whole cash system might crash.  In general it does not look like payee anonymity is possible without giving up other very important features.
Hal Finney
hfinney at shell.portal.com

@_date: 1995-09-15 07:49:44
@_author: Hal 
@_subject: Why ecash is traceable 
Sorry, I don't have time to write much now.  The missing piece in my
description was the assumption that people would have to send received
cash to the bank non-anonymously.  However as Tim points out that can
be avoided in on line systems, and in that case Alice cannot actually
learn Bob's identity.  However as was also pointed out the cash can at
least be detected and invalidated so technically it is still traceable.
The protection of the payor is still not really as strong as that of
the payee.
I should also mention that when we discussed this earlier Jason Solinsky
suggested that transferrable cash systems also provide a means for Bob
to keep his identity secret.  The cash is still traceable in that the
bank can recognize it when it is finally deposited, but it may have
passed through many people's hands in the meantime and their identities
are not known.

@_date: 1996-04-02 16:43:02
@_author: Hal 
@_subject: Java flaw is in bytecode verifier 
This is one of the more worrisome places for a bug to exist.  Much of
Java's security rests in the claim that it can screen for and detect bad
bytecode sequences.  This screening code is extremely critical for Java
security and I am surprised to see that it was implemented in a flawed
I've been writing Java quite a bit in the last couple of weeks, and I
find that I have crashed my browser, whether Netscape or appletviewer,
many times.  Granted some of my code has been pretty buggy, but it's
still not supposed to crash the browser.  Obviously some of the runtime
checks are not being done properly.  I had expected that the bug would
be in these areas, something like the stack overflows that we have seen
cause problems in the past.  A simple error in the bytecode verifier
(if that is what this really is) seems like a more fundamental security
The researchers have still not released full details on the bug, although
they had planned to do so by the end of March.  Maybe they are waiting
for the fix to be distributed.

@_date: 1996-04-03 13:22:42
@_author: Hal 
@_subject: What backs up digital money? 
I am curious to know why you say that ecash is not a currency.  One of
the main points of my original posting was to challenge this view.
Do you simply mean that this is a matter of definitions, that ecash isn't
a currency because it lacks some property X that, by definition, a
currency must have (such as, it must be issued by a national government)?
Or are you saying that there is an important functional difference, that
ecash cannot be used as we normally use currency (that is, the dollar
bills and coins in our pockets) because of reason X?  If so I would like
to hear what you think that reason is.  The one I have seen mentioned
previously is transferrability, so I discussed this in my original
The whole issue of why dollars have value is one which is poorly
understood, IMO.  There are several reasons, which are inter-related.
One of the big ones is that they are legal tender.  This term does not
mean what a lot of people think it does, but at least it means that
your dollars carry certain legal weight if you have a debt that you
need to pay off.  Another reason dollars are accepted is because you
know you can pay your taxes with them.  This is something that most
people have to do, and dollars are something they can do it with.
Another factor is that there are long term contracts, such as
mortgages, which are denominated in dollars.  You can use your dollars
to pay off your debt at the bank, and the bank is contractually bound
to accept them (even apart from legal tender considerations), and grant
you title to tangible property in return.  Interestingly, the volume of
outstanding mortgages is of the same order of magnitude as the
circulating money supply.  I know someone who claims that this is the
most important factor in giving dollars value.
And finally, the reason that most people think of, the fact that
everyone around them accepts dollars, and presumably will do so in the
future.  I don't actually think this is as strong as the others, since
there is no guarantee that people won't change their minds, and in fact
there have been historical situations where due to hyper inflation
merchants have come to view government money as almost worthless.  So
since these people haven't committed to accept the money, this
grounding is not that strong.  I think the earlier examples are more
important as an ultimate grounding, although they are not cited as
I would expect that an ecash issuing bank would make ecash loans just as
it makes other forms of loans.  So I don't see ecash as making this
kind of difference in a bank.  Just because a bank issues ecash it's
not going to roll back the clock to the 18th century.
One of the big advantages of multiple ecash currencies is that it turns
out that there is automatic control of inflation.  A bank which issues
too much currency (relative to its reserves) will find it becoming worth
less because it is trusted less.  There is an automatic balancing act.
We see the same thing in the international currency markets with
government currencies.  In the olden days, when international trade was
less important, a government could inflate without feeling much pain.
But today its currency will lose value, which will hurt its balance of
trade and make it hard to acquire foreign goods.  So this puts a brake on
the ability of governments to play games with the money supply.  The same
factor would be expected to occur with private currencies.

@_date: 1996-04-03 18:59:47
@_author: Hal 
@_subject: software with "hooks" for crypto 
Let me first point out that this procedure is not as easy as it sounds.
Phil Karn has an interesting description of what happened when he
actually tried to do this, as part of his suit to try to export the
Applied Cryptography source code on disk.  It is at .  This is
something that people have talked about for a long time, and it is
interesting to see what happened when he tried it:
   5. I began by first photocopying, on a standard office photocopier,
   the 18 pages containing the Triple DES source code listing from Part V
   of the Book. This took about 5 minutes. Second, I scanned in the 18
   sheets on a Macintosh Quadra 610 computer system equipped with an HP
   ScanJet II flatbed scanner and Omnipage Professional optical character
   recognition (OCR) software. The computer, scanner, and software are
   all readily available through normal consumer computer supply
   channels. The total scanning process took about one and a half hours.
   About an hour of this time was spent learning to use the scanning
   system and conducting trial runs, as I had only used it briefly some
   time ago. The actual scan of the 18 pages took about 15-20 minutes.
   Third, I transferred the resulting machine-readable file from the
   Macintosh to my own personal computer and brought it up under GNU
   EMACS, a popular and widely available text editing program that I have
   used for many years. In EMACS I compared, by eye, the scanned file
   displayed on my screen against the printed listing in the Book. I
   began correcting the scanner's many errors, such as mistaking the
   digit '0' for the letter 'O' or mistaking the vertical bar '|' for the
   letter 'I'.
   6. After manually correcting those errors noticed through visual
   comparison with the Book, I invoked the "C" language compiler on the
   (partially) corrected file. The compiler immediately pointed out
   additional errors I had overlooked in my visual inspection so I could
   also correct them by reference to the Book. I also noticed several
   errors in the listing printed in the Book. However, the programmer's
   intentions were obvious from the context of each error and were easily
   fixed. About fifty minutes later, I successfully compiled the file
   without error.
   7. The fourth step was to write a small test program to execute the
   DES code with the test vectors given at the end of the source code
   listing. This trivial program took less than 5 minutes to write.
   Unfortunately, the test did not succeed, meaning that at least one
   error went undetected by the compiler in either the code as printed in
   the Book or as scanned. Scrutinizing the code more closely, I quickly
   found another error in the printed version that was easily corrected.
   However, it still did not produce correct results. After about an hour
   of searching, I finally located the error in a list of numbers in a
   table -- another error in the printed version. By reference to the DES
   algorithm description in the first part of the Book, which includes
   the correct numbers in tabular form, I found and corrected the error.
   8. At this point the test finally succeeded, so I knew I had a correct
   program.
As you can see, it took a long time.  Part of the problem was that the
printed copy of the code was apparently simply wrong.  Presumably if you
printed it this would not be the case.  Also, your code is shorter than
the 18 pages that Phil had to work with.  Still OCR may not be that well
adapted to source code.  Most texts use ( a lot more than {, and the OCR
may not pick out that kind of difference well.
I will also note, parenthetically, that it is a credit to Phil that he
was obviously being very honest and above-board in describing what he
had to go through, possibly to his (and our) own detriment.  If the
process of turning the book into the floppy were easier and did not
appear to require so much expertise, the government's case might have
been weakened.
Your bigger question is about the legalities of it, and that is harder to
answer.  There is a continuum of cases.  At one end we can say that
it is apparently legal to discuss cryptographic algorithms with
foreigners.  This happens all the time at international conferences.  As
long as the material isn't classified, you can talk about the technical
issues.  At the other end, it is at present definitely illegal to export
a working cryptographic device.  In between there is a gray area.
Currently it appears that exporting cryptographic source code in machine
readable form on magnetic media is illegal, at least pending some
resolution of the Karn suit.  Probably exporting it in other ways, such
as by email, would be treated the same.
My guess is that exporting in machine readable form on paper, such as by
a bar code, would also be equivalent.  There is a little more effort
involved in scanning it in, but if the bar code has good redundancy and
is reliable, it is not much more.
The next step is printed source code.  There are fonts (or other tricks,
such as per-line checksums) which can be used to make scanning this in
relatively reliable.  I don't have enough experience to know how good it
can get.  But let's suppose it were practically error-free.
By the reasoning above, this would also be restricted.  OCR'ing the text,
if it can really be done mechanically and automatically (which is clearly
not the case with the technology that Phil Karn had access to) is not
much different from getting it on a floppy.
Yet we know that at least in the case of Applied Cryptography the book,
export permission was granted.  So at least in some cases, printed
source code can be exported.  I understand that the PGP source code
book is in an OCR friendly font.  It would be interesting to hear
whether Phil's experience above is actually made easier with the PGP
source code book.
I think the bottom line is that the government will restrict any method
which makes it significantly easier for a foreigner to get working
source code than by typing it in from a book by hand.  (BTW, Phil's
lawyer did have two secretaries do that.  It took under 3 hours,
although presumably the code was subject to some of two same printing
errors that Phil had to fix in his test.) So my guess is that
technically you could get in trouble by doing what you propose.
I'm not a lawyer though -

@_date: 1996-04-04 15:15:04
@_author: Hal 
@_subject: Disclosure of Public Knowledge to Foreigners 
It would be good if this happened.  Yet unfortunately I think it is
unlikely.  Absurdity is not necessarily sufficient to invalidate a law.
Especially in this case, if you read the judge's decision (at ) you see that
this issue is one which is "hands off" for the judiciary.
The question of designating whether items should be on the Munitions List
has been found both by the courts and by the legislature to be
"non-justiceable", something which the courts can't review.  It is
strictly in the purview of the legislative branch, which passes the law,
and the executive branch, which sets the policy and creates the list.
Courts are required to refrain from second-guessing them.
Of course this doesn't totally close the door, and if serious
constitutional questions arise, the court can consider this.  Phil Karn
attempted to do so, but did not succeed in this case.  Unfortunately
there is clear precedent at the appellate court level that First
Amendment concerns are not violated by export bans.  As long as you can
say whatever you want domestically, the government has a lot of latitude
to prevent you saying things to foreigners, even though that is illogical
in many contexts.
I feel, by the way, that this may soon present another line of attack on
the restrictions.  As the Internet becomes a dominant communications
medium, it will become more true than ever that these regulations have a
chilling effect on all communications relating to cryptography.  I can't,
right now, post crypto source code to this list without breaking the law.
Nor can I post it to sci.crypt.  How then can I participate in discussing
these matters in detail on the Internet?  Maybe I could put the material
on an export-restricted disk somewhere, but that does not allow for the
dynamic give-and-take which is so much a part of internet discussion.
So, in the context of the net, export controls are de facto content
controls on domestic discussion.  For now, maybe being unable to speak
in detail about crypto on the net isn't that big a handicap.  But in a
few years, Internet communication will be a big part of everyone's lives
(arguably) and being unable to present certain information will produce a
stronger First Amendment violation.
A couple more comments on Tim's message:
I can certainly believe it after reading about Phil's efforts.  And as I
point out, he actually did have a secretary type it in.  It is
disturbing, though, that the book had errors in it.  I wonder if it was
typeset by hand?  Is that possible in this day and age?
Unfortunately, as I noted above, so far no one has been able to come up
with a convincing Constitutional argument, especially in the face of the
Posey and Edler precedents, which are discussed by the judge in Phil's
case, and for which I have some excerpts at .
I think the real solution frankly is to get the laws changed.  If the
laws are absurd, people should be taught about them, and they should
pressure their legislators to change them.  This is not an attractive
solution because it implies a lot of work and a long, slow process.  But
in the long run it will be better to establish a national consensus about
how to deal with these issues.  Then it will be harder for government to
place new restrictions in place.  I think the recent legislative action
reflects the beginnings of this process.  It may not succeed this year,
but hopefully in a few years, as more people get on the net, it will gain
Ironically, the termination of the case again Phil Zimmermann may hurt
progress in this area.  Unfair and unjustified as the pending charges
against Phil were, they did at least raise people's consciousness about
the problems in current policies.  Phil did an excellent job of keeping
these issues in front of people in all sorts of media.
Now that there is no longer an articulate victim of unfair export laws
it may be harder to keep people thinking about the problem.  Perhaps we
need a new volunteer...

@_date: 1996-04-04 16:55:08
@_author: Hal 
@_subject: What backs up digital money? 
I'm not sure exactly what you mean by money "going onto the net and never
coming back".  Is this just a matter of there being a wider variety of
useful things to buy on the net?  Or do you mean that people who receive
ecash will not want to deposit in their bank accounts, but just turn
around and spend it?
I will point out that with regular currency, most merchants who receive
it just deposit it at the bank, save for a bit passed out as change.
Supermarkets don't actually take the cash their customers give them and
hand it to their suppliers.  They deposit it and pay with checks.  So
the "life cycle" of a $20 bill is pretty much from the bank, to the
customer, to the merchant, and back to the bank, only to repeat the
cycle.  Ecash, it seems to me, is already able to circulate to this
extent, although of course it is not yet widely used.

@_date: 1996-04-06 16:57:27
@_author: Hal 
@_subject: "Contempt" charges likely to increase 
I think Tim has hit the nail right on the head with this one.
I have been quite appalled to read the various analyses on the net (URLs
not handy, but they have been posted here before I think) which conclude
that compelled disclosure of a cryptographic pass phrase would probably
be OK despite the Fifth Amendment.  This seems to be an area where there
is widespread agreement based on recent precedent.
In the past, when crypto was not widely used, the issue didn't really
come up very often.  If a criminal chose to write incriminating
information diary or financial ledger, and it could be found in a
search, then it was used as evidence against him.  At one time not even
this was accepted but it has been this way for many decades.
But crypto, if it becomes widely and routinely used, raises the bizarre
spectacle of criminals commonly being forced to produce information
which will then be used against them!  Imagine if they'd found a file by
OJ on his computer, encrypted, which he refused to decrypt.  The judge
could actually jail him for contempt until he revealed the password.
This could become a routine occurance in many kinds of crimes which rely
on private records as evidence.
Currently, I don't think the subpoena power is widely used in criminal
cases.  Rather, the prosecution relies on search warrants and the element
of surprise to prevent the destruction of incriminating records.  I think
there is recognition that in practice subpoenas would not be effective,
that the records would not be produced, even if contempt charges were the
If so, then probably the tactic will not be that effective in forcing
people to reveal cryptographic keys.  Maybe if the jails start filling up
with defendants who refuse to go along with such order, judges will
decide that effective secrecy of records is now the new status quo.  The
law will then once again extend the Fifth Amendment privileges to
personal papers.

@_date: 1996-04-11 05:31:41
@_author: Hal 
@_subject: Tense visions of future imperfect 
DigiCash banks do not issue serial numbers.  Serial numbers are randomly
chosen by the user when he withdraws his cash. He blinds the serial
number before presenting the cash to be signed by the bank during
withdrawal.  So the bank never sees serial numbers until they are spent.
The uniqueness of serial numbers results solely from having a large
enough random space that matches are unlikely.
What the bank does is keep a list of all spent serial numbers, not all
issued ones (since it doesn't know those).  That way it can detect double
We have had some discussions here about how banks could recognize this
kind of counterfeiting, similar to the statistical measures mentioned in
Garfinkel's scenario, and steps that could be taken.

@_date: 1996-04-11 06:26:41
@_author: Hal 
@_subject: No matter where you go, there they are. 
Peter - didn't they say that the checking station is also listening
to the satellites?  That way they can tell that you are playing back
signals that you taped earlier because they won't match what the
satellites are broadcasting right now.
I think your idea would work if you wanted to pretend to be at a point
which was _farther_ from each of the satellites than where you actually
are.  Then you could delay all of the signals.  But the only way to
be farther would be to be deep underground.  You might be able to pretend
to be at the center of the earth, but that is not very useful.
Actually I suppose this only applies to those satellites which are shared
between you and the checkin station.  If you are far away then maybe you
only share one or two.  If you know which ones those are, you can lie to
your heart's content about other ones, and for the shared ones you can
again delay the signal and claim to be farther than you are.
If their authenticated repeaters are used then you have to assume the
checking station has all the satellite signals and again the best you can
do is pretend to be a Mole Man.

@_date: 1996-04-12 04:44:53
@_author: Hal 
@_subject: Anonymous Remailer threat: Scientologists may subpoena	  anonymous remailer records? 
Actually, this is not true.  The poster, from rumors I have heard, was
someone else with a Caltech alumni account (I don't know who).  I have
never been contacted by any representatives of Scientology with respect
to this case.  So it is apparently just a coincidence that this case
involved the same system as my remailer.

@_date: 1996-04-12 07:12:39
@_author: Hal 
@_subject: No matter where you go, there they are. 
I think the various comments are correct that Denning's scheme won't work
across the Internet as it currently exists.  Any network with latencies in
the multiple milliseconds and up will allow the fraud where the remote node
lies about its latency in order to allow it to move some of the received
data "forward in time", which is necessary but would not be possible if
latency were known and fixed.
Note however that Denning did not mention the Internet in her spiel.
I believe her method would be workable across lower latency networks, if such
exist or eventually exist.  Perhaps direct connections or leased lines would
provide low enough latency; I don't know.  In any case networks are likely
to become faster in the future and her method might eventually work.
Actually the issue is not just latency but whether the latency can be
lied about, and for some kinds of networks that would be harder.
The method of using authenticated devices which provide timestamped
data from satellites not visible to the authenticating site does not
need to provide that data in real time.  Even if it is delayed so it
comes in later than the data from the remote site, the verifying site
can still use it to calculate what the remote site should have been
seeing, and so get the benefit of using timings from all the satellites
visible to the remote site (again, assuming the remote site itself has
a low latency connection to the authenticating site).
They do mention that in urban or other obstructed locations a partial
view of the sky may be adequate.  But of course if all the satellites
visible to the remote site are in the south, it can move its apparently
location north by using older data.  So for the system to work there
must be satellites visible in all parts of the sky (no line you can
draw through your location which puts all satellites on one side of
that line).

@_date: 1996-04-15 02:16:28
@_author: Hal 
@_subject: carrick, Blowfish & the NSA 
Blowfish has not been broken in my opinion.  I wonder if Perry is
thinking of MacGuffin, the block cipher by Schneier and Matt Blaze
based on an asymmetrical Feistel network.  It was broken, and I think
it was at Eurocrypt.
Here is a message from sci.crypt a month ago where Bruce discusses the
status of Blowfish.  A weak key attack is known against a weakened
version, but I think the weak keys are rare.

@_date: 1996-04-16 06:03:54
@_author: Hal 
@_subject: What can the judge do to me? 
I thought this was very interesting and I appreciate Unicorn taking the
time to lend us his expertise.
I didn't understand what distinguishes civil and criminal sanctions.  Is
it the nature of the proceedings, whether it is a civil or criminal case
that is before the judge?  Or is it the nature of the contempt charge
itself, where not doing what the judge wants, in broad terms, is civil
contempt?  And in that case, what would be criminal contempt?
Would there be a distinction between contempt by a witness and that by
the defendant (in a criminal case)?  I could see justification for
attempting to compel testimony from a witness who can shed needed light
on guilt or innocence in the case.  A man's freedom or perhaps his very
life is at stake.  But it seems to be another matter to compel the
defendant himself to provide some information which will be detrimental
to himself.
The defendant has some Fifth Amendment rights, but for those cases
where what he is ordered to do has been found not to be protected by
the Fifth Amendment it still seems bizarre to imagine him jailed for
contempt if he refuses.  Are there precedents for holding a defendant in
contempt for standing mute at his own trial?
(Part of my problem with this scenario is my sense that despite gradual
erosion of the rights against self incrimination, verbally revealing a
pass phrase which will unlock an encrypted document seems like
testimony, and something which should be protected.  Is there such a
difference between "Reveal the pass phrase" and "Reveal what you did with
the knife", if the judge doesn't believe the denials of the ability to
I would guess that "turning over a key" here refers not to production to
the court by rather to passing a physical key between two contesting
parties, say a seller and buyer of some property that the key gives
access to.  The phrase "turning over" rather than "production of" suggests
this interpretation.  So this sounds like something which would be more
likely to occur in a civil proceeding than a criminal one.

@_date: 1996-04-19 12:11:33
@_author: Hal 
@_subject: why compression doesn't perfectly even out entropy 
I see two problems with this.
The first is whether this mysterious black box, the entropy estimator,
is really possible.  In practice the only way to know how much entropy
you've gotten is to have a model for how the data is being generated,
and to deduce from that an estimate of the entropy rate.  So the entropy
estimator can't be a general-purpose calcluation, but it must be one
which is specifically chosen, developed and tuned for the specific source
of entropy you are dealing with.
Given this, what is the point of filtering?  You already have a model.
If you want to be conservative, why not just take 50% more bits than your
model says you needed?
The other problem is the functioning of this filter.  I haven't followed
Jon's proposals closely, but at one point he was talking about
histogramming the input and throwing out data which he had seen too
often.  Now this is an implicit model as well - it assumes that the data
is supposed to be uniformly distributed on a per-byte (or whatever the
data elements are) basis.
Suppose your random noise from dubious sources includes some timing
values which vary in the range 90-110, roughly normally distributed.  You
have good reason to believe that it actually is a normal distribution,
and that there are 2 or 3 good bits of entropy per sample.  If you didn't
use Jon's filter you could just collect data, hash it, and figure that
each datum gave you this much entropy.
But now if you throw Jon's filter in there, it may start throwing out all
the values in the range 90-110.  Where are the 0-80's?, it wonders.  Where
are the 120's and up?  There are way too many 100's here!  If the filter
isn't smart about the data like your model is, it could end up throwing
the whole data set out.  Your entropy counter would be spinning its
wheels waiting for more data, and you'd think you never got enough.
So I think the lesson is that there is only one way to estimate entropy,
and that is to study your source.  I have to agree with Perry that this
filtering concept is not the way to go.  It is a red herring that lures
you in the direction of automatic entropy estimation, and that is really
not safe.
Hal Finney

@_date: 1996-04-23 15:51:15
@_author: Hal 
@_subject: PGP's +makerandom is broken (was: Re: Article on PGP flaws) 
I have a Java applet which runs 10K bytes of output of pgp +makerandom
through a noise sphere program.  It looks random to me.  I don't know how
it compares with jf_avon's observations.  Judge for yourself.

@_date: 1996-04-24 07:17:16
@_author: Hal 
@_subject: Golden Key Campaign 
I appreciate the temperate responses to my knee-jerk diatribe against
RSA's involvement in the golden key campaign.  The key logo doesn't
actually resemble RSA's very much, although the small versions do seem
similar to the golden keys shown in Netscape's browser.  So far as I know
though Netscape hasn't threatened any lawsuits to make people take crypto
off the net so I don't object to that...
Now that the patent situation with regard to public key encryption has
changed due to the RSA/Cylink split, it appears that the patent which
claims to cover all PK encryption has been seriously weakened.  There are
other PK encryption systems than RSA which are just as good, such as El
Gamal or Rabin encryption.
Rabin encryption would have the advantage that it could be used with
existing RSA keys as long as the modulus is a Blum modulus.  PGP at least
has always used Blum moduli, perhaps for this eventuality.  So an
alternative encryption program could use Rabin encryption and work with
the existing infrastructure of PGP keys.  It would not of course be
compatible with PGP for encryption and decryption.
This doesn't solve the signature problem; I'm not sure if there is a
signature algorithm which could use RSA public keys but which is not
covered by the RSA patent.  In any case since PGP key certificates use
RSA signatures it would not appear to be possible to validate key
signatures without infringing on the RSA patents, so that cancels out a
lot of the advantages of using existing PGP keys.

@_date: 1996-04-24 09:03:24
@_author: Hal 
@_subject: Childporn found in UCSB Dean's Computer 
This from my local hometown paper in Santa Barbara.  It illustrates
the use of search rather than subpoena to collect information in
criminal cases, as well as the dangers of having unencrypted files lying about:
   UCSB dean faces charge of child porn possession
   by Melissa Grace
   News-Press Staff Writer
   UCSB Dean David M. Kohl, under investigation for misues of universify
   funds, is facing a more embarrassing charge - possession of child
   pornography.
   While searching Koh's home for evidence in the investigation into the
   dean's alleged misuse of about $20,000 in fees charged to students
   applying to medical schools, campus police discovered photographs in
   Koh's computer files depicting minors engaging in or simulating sexual
   conduct.
   The pictures were downloaded by the 52-year-old professor into his
   computer from the Internet.  his lawyer said Kohl was unaware of the
   contents until he opened the unsolicited files, which were sent by an
   Internet user whom Kohl does not know by name.
   Kohl has no criminal record, and because of that the pornography charge
   was filed as a misdemeanor, according to the District Attorney's Office.
   No charges have been filed against Kohl for his possible misuse of
   university funds.
   The police found two computer disks, with approximately 15 files
   containing the sexually explicit, graphic material, said Stanley M.
   Roden, one of Kohl's lawyers.
   [...]
   Roden explained that Kohl had been exploring what are known as chat
   rooms on America Online when he was approached by another user and asked
   if he was interested in seeing unspecified files.
   "David never showed, disseminated, paid for, asked for, or looked at them
   again," said his attorney.
   [...]
   Possession of child pornography locally is an unusual charge according to
   campus and city police and watchdog groups for the Internet and child
   pornography laws.
   "There have been no arrests here for child pornography over the last 10
   years," said Santa Barbara Police Department Lt. Nick Katzenstein.
   The university police department's chief, John L. MacPherson, said he has
   never before had a complaint about child pornography.
I also heard an interview with the lawyer on the radio this morning.  He
claimed that this would be a "test case" because Kohl had only had the
files in the privacy of his own home and never looked at them after
realizing what they were.  "As soon as he needed a disk, that one would
have been erased," he said.
It's too bad Kohl didn't use software which automatically and
transparently encrypts his floppies.  Then they would have tried to
subpoena the key, thinking that the floppies might have incriminating
info related to the embezzling charge, never dreaming that they contained
child porn.  That would have been an interesting case.

@_date: 1996-04-24 16:40:03
@_author: Hal 
@_subject: Golden Key Campaign 
I see that a lot of good people are involved in this, and it sounds like
a worthwhile cause.  But I have one thing I want to get off my chest.
(Long time list readers will know that this is one area where I have
trouble being completely rational.)
The thing that worries me when I put crypto software up at my site is not
the export restrictions.  I can make people click a button promising that
they are USA citizens or otherwise legal.  A lot of other people do it
and while it might get me into trouble eventually I think it demonstrates
good faith.  (There has also been some discussion on the cyberia list
with regard to the communications decency amendment that "I am not a
minor" buttons would be adequate defenses for that law, and this seems
like a similar situation.)
No, the thing that worries me most is patent infringement.  And the main
company I worry about is RSA, one of the sponsors of this golden key
effort.  Note that RSA's logo is a key, and we see the RSA key at the
bottom of our Netscape screens all the time.  I don't remember if it's
It seems ironic for RSA to be casting itself as a friend of the
principle of availability of privacy tools when its own lawyers patrol
the net to make sure there are no unauthorized encryption programs out
there.  They fought against PGP for years until Phil trumped them by
going over their heads to MIT.
Look what happened when Wei Dai announced his fine crypto library.  It
wasn't the NSA which come down on him.  It was RSA lawyers who demanded
that he pull his library off the net until he had it clean enough for
I have not actually seen the new logo because I don't have a graphical
browser here, but I hope it is not too similar to RSA's key.  I hate to
see that company rewarded when it is acting counter to the interests of
people who need access to privacy tools.

@_date: 1996-04-25 07:28:02
@_author: Hal 
@_subject: NYT on MS Java, Net Radio 
In other Java news, the report from the Princeton scientists who have
found many security weaknesses in Java is now available at .  It is very critical
of the language design and implementation.  I don't fully agree with the
thrust of their criticisms, because I don't think provability is a
practical matter with programs complex enough to be useful.  But they
have certainly identified an alarming number of problems.  I will post
later today a list of the issues they have identified.

@_date: 1996-04-25 11:10:46
@_author: Hal 
@_subject: coderpunks not elite 
As far as I know, the coderpunks list is neither secret nor elite.  I
joined it about a month ago, andd there wasn't any problem.  Just send
mail to majordomo at toad.com saying "subscribe coderpunks".  It's just as
easy as cypherpunks.
According to majordomo, coderpunks has 355 subscribers, compared to 1284
for cypherpunks.  These numbers are hardly representative of an elite
The biggest difference between the lists is volume.  Some days coderpunks
gets a dozen or more messages, but for the last two or three days for
example there haven't been any at all.
The other difference of course is that coderpunks is for technical
discussions.  Where philosophy comes up it is more in terms of issues of
security and reliability than politics.
I do share Tim's concern about the political views of coderpunks
subscribers.  Despite the "punks" in the name it seems to be somewhat
more of a mainstream group.  Nevertheless I am determined to act as
though the group favors unlimited access to privacy tools by individuals
and to post under that assumption.  If it comes to the point that someone
complains there may have to be some air clearing but I don't think it's
likely to come up.
If the archives at hks.net ever come back people could take a look and
see if they would be interested in subscribing.  Mostly the discussions
are pretty dry.  A lot of them are on specific issues that are of
interest probably to only a few people.  It remains to be seen really
whether the list can sustain itself.  This has been the problem in the
past with offspring lists.
Cypherpunks continues to have a lot of vitality.  What I object to most
is the back and forth arguments people get into.  I don't mind reading
one message off-topic, but to have the thread drag on for days, with
dozens of messages, is wasteful.  People should just make their points
and let them stand.  They shouldn't feel they have to keep coming back
and refuting the other guy.

@_date: 1996-04-25 11:44:38
@_author: Hal 
@_subject: Java security weaknesses 
This is a quick summary of the attacks listed in "Java Security: From
HotJava to Netscape and Beyond", by Drew Dean, Edward W. Felten,
and Dan S. Wallach, Department of Computer Science, Princeton
University. .
Only attacks on Netscape will be listed here.  Several more were found
in HotJava, but that product is moribund at present.  The version of
Netscape used is 2.0.
Denial of service attacks
    Busy-wait to consume CPU cycles
    Allocate memory until no more is available
    Lock crucial system classes, e.g. java.net.INetAddress.  Blocks
    all hostname lookups.  Several other classes are suitable for this
    attack.
    Denial of service attacks can be moderated to degradation of service,
    possibly after a time delay, to make someone else's product look bad.
Covert Channels
    Can send mail via an SMTP port on server
    Lookup fictitious DNS name to send out info
    Tell browser to access fictitious URL (can be redirected back)
Information available to applets
    Can benchmark machine by reading system clock
    Java hashcode() defaults to address of object, might leak some info
Implementation errors
    DNS hack allowing connections to any machine (has been patched)
    Java disassembler (javap) has buffer overflows (not normally run by
    users)
Inter-Applet security
    Applets running from previous pages can learn of new applets by
    getting a handle to the top-level ThreadGroup and enumerating every
    thread running in the system.
    Can then call stop() and setPriority() on threads belonging to other
    applets, making them appear slow and unreliable.
Bytecode problem
    The big one: Java bytecode safety checker doesn't detect illegality of
    constructor()
    {
    }
    This is not legal in the language - super() must not be called in a
    try clause.  But the bytecode checker erroneously allows it.
    This allows subclasses of privileged system classes to be created.
    Normally those classes throw an exception in their constructor so they
    can't be instantiated.  But this trick allows it.
    This way users can create their own ClassLoaders, SecurityManagers,
    etc.  By creating a hacked ClassLoader the Java class type system can
    be defeated by resolving different classes against each other.  Any
    non static variable can be set, any public method can be called,
    including native methods.  The security is gone.
Package name problem
    If the first character of a package name is / the system will attempt to
    load code from an absolute path, which would be trusted since it comes
    from the local disk.  Any Java class which the attacker can get onto
    the user's disk can then be loaded in trusted mode.  Classes can be
    gotten onto disk simply by fetching URL's in Netscape, which puts them
    into its cache.  If you can figure out Netscape's class naming scheme
    you can then run any class, trusted.  (I think this one has been
    patched.)

@_date: 1996-04-25 12:09:53
@_author: Hal 
@_subject: Golden Key Campaign 
It is traditional to commemorate big events with annual observances.  I
say there's no reason the observances can't predate the event when it is
known in advance.
So I propose that September 20 be known as Crypto Freedom Day, and an
annual celebration be held on that day.  With each year closer to 2000
the party gets bigger, culminating on the day that the patent actually
expires.  We can all run our RSA in three lines of Java that Adam Back
will have prepared, and taste for the first time the freedom which the
rest of the world will have known for the past 17 years.

@_date: 1996-04-25 16:23:29
@_author: Hal 
@_subject: US law - World Law - Secret Banking 
I was encouraged to read the description by former NSA lawyer Stewart
Baker of Japan's attitudes towards crypto policy (from the URL posted
here by wb8foz at nrk.com,   We can
all take heart in what Baker finds alarming:
   In the United States and Europe, encryption policy is formed by a mix
   of interests. Advocates of business, national security agencies, and
   more recently the police -- all play a large role in the policy
   debate. This policy triumvirate is difficult to see in Japan. For a
   variety of reasons, commercial interests are predominant in Japanese
   government thinking about encryption. Time after time during my
   interviews, I was reminded that Japan was an island nation that has
   not had to defend itself for fifty years and so has not had to
   confront the national security concerns associated with encryption.
   And Japanese police face severe political and constitutional
   constraints on wiretapping, so the prospect of losing this criminal
   investigative tool seems not to be as troubling to the Japanese
   government as to the United States and many European nations.
   [...]
   All in all, the emerging Japanese consensus on cryptography could pose
   a major challenge to U.S. (and perhaps European) government hopes of
   striking a compromise between commercial and governmental interests
   with respect to cryptographic policy. If Japan puts the weight of its
   government and industry behind strong, unescrowed encryption,
   competitive pressure will quickly doom any attempt to influence this
   technology through export controls and standard-making. Governments
   will be forced to choose between overt regulation in the Russian and
   French manner or laissez-faire policies of the sort that now prevail
   in the domestic markets of countries like the United States, Great
   Britain, and Germany.
I love the description of the choice facing the government, between
laissez-faire policies versus the kind of system prevailing in Russia.
This is a remarkably clear and frank description of the policy directions
which are available.

@_date: 1996-04-26 17:16:11
@_author: Hal 
@_subject: US law - World Law - Secret Banking 
Another thing Baker said in that report about Japanese crypto policy was
interesting.  He was talking about key escrow and how he thought the
Japanese discussions about it were on the wrong track.
Apparently the Japanese idea of key escrow combines it with a government
Certification Authority (CA) infrastructure.  You get certified keys
which you will use in commerce, and these keys are escrowed.  (Japan is
not showing much enthusiasm for the escrow idea, to Baker's displeasure,
but they are discussing it.)
Baker's problem was that the keys would be used for signing as well as
for encryption.  He said that in the U.S. they had been careful to
separate these functions in their plans.  That's why we have DSS for
signatures and Clipper (Capstone, Skipjack, etc.) for encryption.  Only
the Clipper keys get escrowed.  The DSS keys are kept private.
The problem with using one set of keys for both functions (as for
example when RSA keys are used for both encryption and signing a la
PGP) is that the escrow people can not only defeat encryption, they can
forge signatures.  If escrowed keys were stolen, not only would privacy
be lost but also the reliability of signatures.
Now at first this seems strange.  Why would it be more of a problem that
a broken escrow could forge signatures than break privacy?  Well, from
the corporate point of view it could be a lot worse.  When you get a
signature on a business document you want to be able to trust it.  If a
company can hope to get out of a commitment by saying that hackers must
have broken in and stolen the keys, the value of digial signatures is
much reduced.
Privacy, on the other hand, at least from the point of view of someone
like Baker, is not as important.  His people eavesdropped all the time,
and it wasn't that bad.  So from his perspective it is reasonable that a
possibly insecure escrow system is acceptable for encryption, but not for
signatures.  And that is apparently a principle behind the US crypto
policies as they have unfolded over the last few years.
This may shed light on the battle a few years back over whether RSA
signatures would be adopted as the digital signature standard rather
than the discrete log system which was finally chosen.  It also
suggests that the government has long realized the difficulties of
keeping the escrowed key database secure.

@_date: 1996-04-29 17:35:54
@_author: Hal 
@_subject: Java security weaknesses 
To add to the list of Java security weaknesses from the Princeton paper
I posted the other day, I saw a new one on comp.lang.java this
afternoon.  It is another bug in the bytecode verifier, different from
the one discovered by the Princeton group, that allows you to bypass
the security mechanisms completely.  Details are not yet available.
Apparently the earlier bytecode verifier bug still does not have a fix
available.  However the nature of the bug itself was kept secret until
last week.  Now that it is out I hope Sun and Netscape will push to get
the fix available ASAP.  The bug appears to require considerable
sophistication to exploit (understanding the details of the class
resolution mechanism).  Still with the talent which is out there on the
net I imagine it will only be another week or two at most before a
demonstration exploit appears.
I hope the extended delay in making the fix available means that an
intensive review of the code is being conducted, so that for example this
other bug will have been fixed as well in the new release.  I certainly
hope that it won't be another month before a fix comes out for this new

@_date: 1996-04-29 20:36:01
@_author: Hal 
@_subject: The Joy of Java 
Somewhat independent of the security/safety issues regarding Java
applets, there are also questions about their suitability for crypto
applications.  Applets currently labor under several restrictions (at
least when part of the Netscape browser) which make it hard to do crypto:
  Applets cannot accept net connections, and they can only make outgoing
  connections to the host which provided them to the browser.
  Applets cannot read or write local disk files.
  Applets cannot access other local hardware, such as smart cards,
  printers, or microphones.
These restrictions make several things difficult.  Finding good sources
of entropy for random numbers is hard.  Applets do have millisecond
resolution event timers (provided that the implementation keeps times to
that resolution, of which there is no guarantee), so they can get some
entropy by keystroke timings or mouse movements.  But they have little
access to disk files or other sources of environmental noise.
Retaining secure information between runs is also hard.  Specifically,
there is no place to store key data other than by sending it to the
server and having it put it somewhere.  It would not be hard to have an
applet which created a public key, but the key would have to be stored in
an insecure location.  So the best it could do would be to encrypt the
key with a user specified pass phrase and hope that was strong enough.
The restriction on connections makes other applications difficult.  To
make an applet which can send PGP compatible email it needs to be able to
look up keys on the key servers.  This can only work if the host serving
the applet can look up keys for it.  It has to be either running a key
server or able to forward requests to one.  This requirement makes the
applet not "self contained" in that to put it on your web pages you also
have to have this other infrastructure in place.
Another problem is in trusting applets.  Imagine an applet to help you
participate in electronic commerce.  Just type in your ecash pass phrase
and it will help you open your ecash account and then charge you tiny
amounts as you surf the web.  But of course if the applet is capable of
withdrawing small amounts, it would also be able to withdraw big amounts
as well.  It could drain your bank account before you knew it.
Some of these problems might be fixed by giving applets limited access to
disk files.  But even then it would be risky to let an applet see your
PGP secret key ring or ecash wallet.
Signed applets can probably help with some of these as well.  If Phil
Zimmermann has signed the PGP applet, maybe you'll trust it as much as
you trust the PGP executable.  Likewise if Chaum has signed the ecash
applet you'll trust it as much as you trust the ecash software.
The thing to keep in mind is that you are already trusting people when
you use their code, or virtually any code for that matter.  PGP is
special because source is available.  Of course most people don't have
any guarantee that your particular binary was built from the source
that you see.  But all the other software you run makes you vulnerable.
How do you know that DOOM, for example, doesn't check to see if there is
a network connection and send out your PGP secret key ring?  You even
have a pointer to it in your PGPPATH environment variable.  Maybe that's
unlikely because you'd see your modem lights flash suspiciously, but how
about networking applications?  Suppose Microsoft's Internet Explorer
rummaged through key rings and wallets, piggybacking packets on your
output data as you browse?  You'd probably never know.
So there are limits to how much safety you can expect.  Hopefully with
signed applets it will be OK to authorize some overrides of the current
restrictions so that these other kinds of applications can be provided.

@_date: 1996-04-30 13:58:08
@_author: Hal 
@_subject: The Joy of Java 
Unfortunately in order to run Java applications it is necessary to have
the Java interpreter for your host.  You may also have to set up
various scripts or filetype assignments so that java files can be
easily and automatically run by that interpreter.  Right now the Java
interpreter is not (AFAIK) available separately, but only as part of
the Java Development Kit (which is free, but is a big package).  So
generally the infrastructure is not really there for Java applications
to be easily downloaded and run by end users.  The attraction with
applets is that if you have a recent version of Netscape and a 32 bit
OS you are already set up to run them (whether you like it or not, for
probably the majority of end users).
Also those security and safety features which exist for applets (buggy as
they may be at this time) don't exist at all for applications.  Java
applications can delete or modify files, make arbitrary net connections,
etc.  So certainly more care must be taken in choosing to download and
run a Java application than an applet, comparable to what is necessary
when you download and run a new PC application program.  Signed binaries
are probably again the way to go here.

@_date: 1996-05-01 07:31:19
@_author: Hal 
@_subject: Calling other code in Java applications and applets 
I understand that Sun is considering including a bignum package and
possibly other crypto support in native form in a future release of
Java.  There has been considerable discussion of this on the coderpunks
list.  Apparently Sun has said they will release their crypto API
within the next week or so.  However these kinds of things are often
delayed, in my experience.  An earlier version of the crypto API was
shared with Java developers at a meeting a few months ago, and the
response was quite negative, according to list memebers.  The class and
method design in many cases seemed awkward, spotty, and inconsistent.
Apparently there are also export considerations, with the NSA resisting
the inclusion of too many explicitly crypto oriented classes.

@_date: 1996-08-02 02:34:02
@_author: Hal 
@_subject: Cracking RC4/40 for massive wiretapps 
RC4 is a stream cypher, so it produces a random stream which is XOR'd
with the plaintext to produce the cyphertext (and vice versa).  With the
old SSL there were spots of known plaintext, but I don't know if that is
the case now.  If you do have some, then you can recover the output of
the cypher.
5 bytes (40 bits) of output should generally determine the key.  So you
could build a massive lookup table indexed by the output which produces
the key.  This would have 2^40 entries (indexed by output values) each
of which was 5 bytes long (key values).  This would take approximately
5K gigabyte disks plus some PC's to attach them to.  Total cost, one to
a few million dollars, perhaps a bit less if you get them wholesale!
(The task of constructing the table is left as an exercise for the
Then given that you know output you can quickly find the key.  No
search is involved, you just go to the PC which holds the range of
output values you are interested in, and do a single disk access.
Note that the known plaintext doesn't have to be contiguous, any five
bytes will do.  With fewer known bytes you can do a similar thing but
have a list of possible keys which can generate that set of output

@_date: 1996-08-02 05:17:20
@_author: Hal 
@_subject: Cracking RC4/40 for massive wiretapps 
When I wrote my previous message about the use of lookup tables, I forgot
about the use of salt, extra key bits which vary per message and are sent
in the clear.  That defeats the table lookup approach for searching for
messages which were encrypted with a given key.  There are really 128 key
bits per message, with 40 of them kept secret.

@_date: 1996-08-05 05:29:56
@_author: Hal 
@_subject: TrustBucks 
An interesting idea.  It reminds me of a barter system, with the similar
problem of trying to put together a complex trade which is mutually
acceptable.  I wonder whether it could be automated if people posted
their holdings and what they would accept.  Then software could go into
this database and try to put together a set of trades that will let
someone make a purchase.  However it would seem to be very harmful to
privacy to have to post all this information.
There are some "lightweight payment" schemes out there which have the
property that people only accept cash that is "for them".  Sometimes
there is a broker involved who actually issues the cash on behalf of the
merchant (the merchant trusts the broker to do this) so that customers
need only go to a smaller number of brokers.  Then these systems can be
based on heavier payment systems like digicash or credit cards which
people use to open accounts with the brokers.
I do like the decentralization idea, but these lightweight schemes have
some of the same advantages.

@_date: 1996-08-20 01:35:11
@_author: Hal 
@_subject: Why BlackNet *IS* a Data Haven 
I think part of the confusion here is the name "BlackNet".  As I envision
the concept, BlackNet is not really an anonymous contact service, or in
fact a network of any sort.  Rather, it is a vendor.  It buys and sells
information.  The name, while provocative, is a bit misleading in this
regard.  (This is just my model, and may not actually correspond with
Tim's or anyone else's idea.  But I think it more closely matches the
data haven concept, and in fact is more consistent with the original
BlackNet has a public key, and a known virtual location in the form of
certain newsgroups that it monitors.  Anyone can initiate a
communication interchange with BlackNet by posting a message to those
groups, encrypted with BlackNet's key.  Presumably in that message will
be included return address information in the form of a key and a set of
locations that will be monitored for replies.  In this way ongoing
conversations can be maintained between BlackNet and customers who are
either buying or selling to it.
BlackNet would not be used (as I see it) for direct communication
between buyers and sellers of information.  How would the BlackNet
public key fit into this model?  The existence of a specific BlackNet
public key is part of what drives me to picture it as a vendor.
Rather, BlackNet will buy information (plus unrestricted rights to
disseminate that information), add it to its catalog, and then
advertise its availability and price.
This model pictures BlackNet differently than I do.  As I see it, once
you sell your data to BlackNet you don't have to take any more steps.
There may still be problems, in that you may feel that BlackNet is
setting too high a price on the data you want to distribute.  However of
course anyone is free to start up a competing service, if they want to
take the risks.  BlackNet fees will in the long run be determined by
competitive market conditions based on the costs of maintaining
This is a little different from my picture of BlackNet, as I wrote above.
I would see BlackNet as being a particular seller of information, who
will respond to this message.  It could have competitors like SafeHaven,
StrongHold, InfoBase, etc., each of which will offer data for a price,
and each of which will have its own reputation for reliability.
Here is where BlackNet as an information middleman makes the most sense.
Its business model includes the costs of this sort of vigilance, which
after all can be automated.
Actually we now have "virtual malls" online.  These are in their infancy
but eventually they could become as easy to use and reliable as regular
malls (for appropriate kinds of goods).  All that BlackNet (as I picture
it) lacks is a WWW interface, and even that could be provided if the
gateway server could be made immune to legal pressure and if various
technicalities about anonymous WWW connections could be dealt with.
As for reputations, if BlackNet is one of several vendors of
information, like its competitors, they can all develop reputations of
their own for reliability, honesty, availability, etc.  There may be
problems if the testimonials of customers are all anonymous, but in
some cases such methods as signed transcripts of information exchanges
can be used by one side or the other to justify claims that the other
side has cheated.

@_date: 1996-02-21 15:54:16
@_author: Hal 
@_subject: anonymous age credentials, sharing of 
I think I wrote something about this before, but I can't recall whether
there was subsequent discussion...
In Chaum's pseudonym/credential system, you can be restricted in the
number of pseudonyms you can get of a given type.  You can transfer
your credentials among any of your pseudonyms, but you might only have
one pseudonym (and associated key pair) for a specific forum or
purpose.  So Carol could get her age credential by showing her birth
certificate, and get it on a non-anonymous pseudonym, then transfer it to
any of her other pseudonyms.  Maybe there is a particular nym which she
uses for access in some area, and she has to prove her age in order to do
so.  So she transfers the credential to that pseudonym and can get
Now Carol could give her pseudonym, credential and key pair to Bob, and
let him act as her within that forum (say, for access to a particular
archive).  He could then exercise all of the privileges that she
could.  This is in effect a shortcut for the case where Bob asks Carol,
"get me this file", "get me that file", and she does.  This is in effect
a blanket promise on Carol's part to respond affirmatively to all such
Obviously, as I think Michael wrote earlier, we can't stop Carol from
doing this on a file-by-file basis.  But we still might want to make it
so she won't give Bob full access, since that will make it even easier
for him to get these files he's not supposed to see, and it seems to
somewhat remove Carol from responsibility for giving each file to Bob.
One thing that might make Carol reluctant to authorize Bob to act as
her agent in this way is that she would also be responsible for any
negative consequences of things Bob does.  If Bob abuses the lent key
pair in some way, such that maybe he is even banned from that archive,
then Carol will suffer the consequences as well.  Given that she only
gets one pseudonym of a kind which can access this archive, she can be
hurt by giving Bob the full use of that nym.
Now, depending on the circumstances, this may or may not be a significant
deterrent for Carol.  If the archive has no material she would be
interested in, or there is no significant likelihood of abuse which would
lead to losing her access, then it won't matter.  But things could be
structured so that these bad consequences were more likely, and then it
would be a more significant consideration for her.
There is a tradeoff between anonymity and accountability here.  We gain
this degree of accountability only be limiting the number of pseudonyms
a person can have for certain kinds of usage, thereby reducing
anonymity.  The most extreme case would would to say that a person can
have only one identity for use everywhere.  That is, we would ban
anonymity.  At the other extreme, anyone can get as many nyms of all
kinds as they want, and transfer credentials in all ways, in which case
credentials are meaningless.  These seem to be the two endpoints
considered in Michael's hypothetical example.
But there are actually a whole range of intermediate points which are
possible.  One example, close to the non-anonymous case, is to give
every person exactly one online pseudonym, unlinkable to their physical
identity, but the only one they can use in their online life.  Now if
they behave abusively the consequences they can suffer are limited.
They can't go to jail.  But still the risks may be relatively severe, and
could include in the most extreme case loss of access to all online
resources, which will be a severe punishment in the future.  Another
point on the continuum would be the use of a single pseudonym for all
access to materials which are illegal for minors to see.  If Carol gives
hers to Bob and he screws it up somehow, she may be stuck watching PG
movies for the rest of her life.
I have tried to think of a better technical fix, such that in order to
give Bob the ability to show one of her credentials, Carol must
inherently give him the ability to use all of them, to act as her in all
forums.  Maybe some zero-knowledge protocol would be required to show a
credential, one which would only work if you knew some basic secret that
underlies all your pseudonyms, but which doesn't reveal it to anyone.
Then Bob could act as Carol only if he knew her innermost secrets.  But
still it would be necessary to retain unlinkability among pseudonyms.  I
can't see how to make it work, and maybe it is fundamentally impossible.
But if something like this were possible it would be a good solution to
the problem Michael has described.
Hal Finney

@_date: 1996-01-12 10:24:16
@_author: Hal 
@_subject: Certificates: limiting your liability with reuse limitations 
You write:
How do notaries public get around this liability problem?  It seems to me
that the checking done for a certificate might be similar to the checking
done by a notary - a glance at a driver's license, say.  Are they subject
to liability if they are fooled by fake ID?

@_date: 1996-07-04 08:50:14
@_author: Hal 
@_subject: Setting a PGP keyserver on my Web server 
I have simple code for a "proxy" key server on my web server.  It is not
a real key server, but just forwards requests to a real key server.  It
has a list of a few servers that it knows about and it tries the list
until one responds.  I use it for Java applets which get PGP keys from
the server; they have limitation that they can only connect back to the
server they came from.  So this solves that problem.
Code and a sample Java applet are available from: .

@_date: 1996-07-05 08:24:03
@_author: Hal 
@_subject: What remains to be done. 
I don't quite understand what is being proposed here.  If the
information on the web site is encrypted, who is supposed to be able to
decrypt it?  Just one person, or some select group of people?  My
concern is the difficulty of keeping keys secret if they are made
available to more than one or two people.
Once the keys are known to those who would oppose the publication of
the information they can go to the ISP just as easily as if the
information were not encrypted, and get them to take it down if it is
It would seem that an equally effective method would be to use no
encryption, but just a secret URL, one which is not linked to from
elsewhere - an "island in the net", so to speak (apologies to Bruce

@_date: 1996-07-14 04:21:26
@_author: Hal 
@_subject: Execution of signed scripts received by e-mail 
That sounds very impressive!  The one problem I've run into with mail
filtering software is that each message asynchronously spawns a separate
filter process.  This can cause some conflicts with accessing disk files.
I haven't used procmail so I don't know if it has this problem.  But if
so you may need to be careful if there are any cases where two processes
could be accessing the same disk files.  For example, what if two copies
of an identical email message arrive at almost the same time, would your
dup detection work.
The other issue is the possibility of mail arriving out of order.  Looking
for increasing timestamps may cause spurious rejection of some messages.
On the other hand this is a difficult problem to handle in general so
probably the current solution is OK.

@_date: 1996-07-16 16:53:42
@_author: Hal 
@_subject: How I Would Ban Strong Crypto in the U.S. 
There has been some discussion at the last couple of crypto conferences
about possible ways around this plan.  (I guess the idea goes back at
least a year or two.)
One idea is to register a 2048 bit public key.  You have to give the
secret key to the government in order to use the registry.  But what you
do is to create a second key and embed it in the first.  It is, say, a
1024 bit key which is the lower half of the 2048 bit key.  It has
different secret factors that nobody but you knows.  Then when people
send you messages they encrypt using this modulus rather than the
official one.
You get the benefit of the government-sponsored key certificate
infrastructure, but the government is not able to crack your
The discussion at the crypto conferences has centered on how to design
key systems which don't have this "subliminal key" property, where it is
impossible to create pairs of keys such that publishing one reveals the
other.  I think they were looking at some of the discrete log systems
since in RSA it is pretty easy to do what I have described above.  You
just create the 1024 bit key first, at random, then choose the 2048 bit
key so its modulus matches the 1024 bit key in its low bits.  This is the
same basic method as the so-called "dead beef" attacks against PGP key
ID's which were published earlier this year.
So it will be interesting to see whether any government sponsored PK
infrastructure takes care to avoid subliminal keys.

@_date: 1996-07-18 01:14:54
@_author: Hal 
@_subject: Cookie alternatives 
There has been quite a bit of discussion recently about the "cookies"
used by Netscape Navigator and their effects on privacy of users.  Here
is some background and some thoughts on alternatives.
I think the term "cookie" goes back to the 1960's.  According to
legend, there was a virus-like program called "cookie monster" which
would occasionally pop up on people's terminals and say "gimme
cookie".  You then had to type the word "cookie" to satisfy the
program, and it would go away.  The program was hidden in the core
memory of the large, multi-user computer systems which were common in
those days.
I first heard "cookie" used similarly to its current context in the
1970's.  It referred to a data item which would be given by a service
to a client of that service, and which would be used on later
interactions.  I think the usage comes from the cookie monster, where
you imagine the client saying "gimme cookie" to the server.  The cookie
is an "opaque" data item, that is, its structure if any is not visible
or documented for the client.  It has meaning only to the service.
There is a similar concept in cryptography, the "nonce".  A nonce is a
random value which is generated by one party in a cryptographic
protocol and which is exchanged at later stages of the protocol.  The
purpose of the nonce is to prevent replay attacks and to maintain
continuity during the (possibly) many exchanges of data which make up
the protocol.  When the client sends a request to a service it includes
a nonce, and the return reply includes the same nonce.  This way the
client can make sure that this is a reply to its current request and
not something which is replayed from an earlier interaction.
Cookies seem a little more general than nonces, in that nonces are
pretty clearly supposed to be just random numbers, while cookies are
more general and could have internal structure which is known by one of
the parties, although it is usually opaque to the other.
However I think in current usage on the web cookies are most commonly
used basically as nonces, random values whose purpose is to maintain
continuity in a series of interactions.  When a server gives a cookie
to a web browser, that browser supplies the cookie on future
interactions with the server.  The cookie probably does not have any
specific data about the user or the interaction, but is used only to
link up the interactions which take place.  It is most probably used as
an index into a database maintained on the server itself.  Its only
requirements for this purpose are that it is unique and that it can
easily be used as such an index.
One typical usage would be to maintain a "shopping cart" while browsing
at a store.  If I am visiting an online clothing store, I may choose to
buy some pants, a shirt, and a jacket as I browse around.  Each time I
click on the "buy" button, my browser includes the cookie I received
when I first visited the site.  This indexes into a database on the
server which is keeping track of what I have bought.  With each new
item, the cookie allows the server to add it to the correct virtual
shopping cart.  Then when I "check out", again the cookie allows the
server to display everything I bought.
Given that cookies generally work this way it is clear that the notion
of editing cookies doesn't make much sense.  If cookies are opaque data
structures, changing them is just going to make them invalid.  You
might as well just delete them.  This also implies that you don't have
much control over what kinds of information the server is maintaining
in its database which is indexed by your cookie.  In the shopping cart
example, the cookie is sent on every transaction, not just when you
click to make a purchase.  This will allow the server to track your
progress through the site, see which if any ads you have seen, and
generally record many details about your interactions.  More generally,
cookies are used for this purpose even on sites which do not need them
for shopping carts.
As a user of the web, I would prefer to have more control over the kind
of information which servers gather about my browsing habits.  Of
course, since web interactions are voluntary, a server is free to put
whatever restrictions it wishes on clients in return for letting them
access its information.  It can require clients to accept cookies, to
register with their names and addresses, or to FedEx their firstborn
children to the store, for that matter.  Nevertheless to the extent
that I have bargaining clout in these interactions, I will prefer
systems which do not infringe so much upon my privacy.
It is interesting to consider how shopping carts might be done without
cookies and similar technologies which allow servers to get more
information about me than necessary.  I would prefer a system where the
list of things I have chosen to buy is saved on my own computer, in a
format I can clearly see, and without linking my purchase decisions to
other browsing I may have done on that site.
Consider a system where when I click on "buy", a dialog box pops up in
the corner of my screen which is my virtual shopping cart.  It holds a
list of the items I have selected for purchase, with each new item
appended to the list.  When I go to check out, the contents of this
dialog box are uploaded (with my permission) to the site, where payment
arrangements are made.  Since I can see what is being put into the
dialog box and what is being uploaded, I know that I am controlling
exactly what information is being revealed about me.  I don't have to
trust the server to protect my privacy by not recording excessive
information about my browsing.
(Given the difficulties in creating new protocols for this kind of
support, I think a step in the right direction would be to change the
user interface so that cookies are only sent upon user request.  Maybe
you have to shift-click or use some other key modifier to send a cookie.
Then shopping pages could ask you to shift-click the buy button to add
the item to your shopping cart.)
All this is in accord with the general principle that we support here,
of protecting privacy by limiting the collection of infringing data,
rather than trying to pass laws to restrict the dissemination and
sharing of such information.  We support ecash since it allows
transactions without identification, rather than using credit cards but
trying to put legal restrictions on what the CC companies can do with
their transaction data.  Cookies allow many kinds of privacy infringing
data to be collected.  I would prefer to see alternate mechanisms to
allow for the kinds of transactions that cookies are needed for, which
allow users to protect their own privacy.  Are there other uses of
cookies for which alternatives are needed?

@_date: 1996-07-18 10:50:49
@_author: Hal 
@_subject: Crypto 96 
Crypto 96 is coming up in about a month.  This looks like a more
interesting program than last year, IMO.  According to the preliminary
program, here are some presentations which could be of interest to
Anonymous Communication and Anonymous Cash
   Daniel Simon, Microsoft, USA
Export Controls: Past, Present, and Future
   Andy Clark, Independent consultant
The Dark Side of 'Black-Box' Cryptography, or: Why Should We Trust Capstone?
   Adam Young, Columbia Univ., USA
   Moti Yung, IBM, USA
Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and
Other Systems
   Paul Kocher, Stanford, USA
[title to be announced]
   Cliff Stoll
Relation of Theory to Practice in Cryptography [exact title to be announced]
   Ron Rivest, MIT, USA
Family Crypto
   led by Michael Fellows
Key-Schedule Cryptanalysis of IDEA, G-DES, GOST, SAFER, and Triple-DES
   John Kelsey, Counterpane Systems, USA
   Bruce Schneier, Counterpane Systems, USA
   David Wagner, Univ. California at Berkeley, USA
Cryptographic applications in electronic commerce
   Ernest Brickell
Cryptology, Technology, and Politics
   Whitfield Diffie
Quantum Cryptography over Underground Optical Fibers
   R. J. Hughes, Los Alamos National Labs, USA
   G. G. Luther, Los Alamos National Labs, USA
   G. L. Morgan, Los Alamos National Labs, USA
   C. G. Peterson, Los Alamos National Labs, USA
   C. Simmons, Los Alamos National Labs, USA
New Results on Visual Cryptography
   Stefan Droste, Univ. Dortmund, Germany
Overall this conference looks very exciting, with possibly a more
political and practical orientation than some.  I am looking forward
to seeing other cypherpunks there.

@_date: 1996-07-20 13:29:24
@_author: Hal 
@_subject: MSNBC and cookies 
I find that MSNBC is now working OK without cookies. I tried off and on
during the day today (Friday) and last night and it didn't work, but it
is working OK now.  I can get in with lynx or with my cookie-blocked
Netscape.  I sent them a nasty letter this afternoon complaining about it
so either that may have helped or it is obsolete.  Maybe it was just a

@_date: 1996-07-24 00:26:27
@_author: Hal 
@_subject: Anonymous web servers 
[This is somewhat of a follow-up to Black Unicorn's idea about private
web pages a few weeks ago, also motivated by thinking about Ross
Anderson's Eternity service, about which I just posted.]
Right now you can get anonymous web pages at various places.  But
these are basically just regular web pages where you haven't told the
service provider what your name is.  If somebody doesn't like what you
have posted there they may be able to get your pages shut down just as
easily as if you were non-anonymous.
I was thinking about ways to allow more truly anonymous web pages.
The goal would be to allow them to operate even if someone powerful
didn't like them.  I'm not sure the idea I have really works but I
thought I'd lay out some possibilities.
The web is basically a client-server environment.  The server sits
there all the time ready to accept connections from users running
clients (browsers).  The client connects briefly to a web page and
downloads the data for the page.  It disconnects and displays the
data.  Some of the newer technologies have extended this model but
it is the original concept.
The idea I have is to provide a meeting place for anonymous servers
and clients.  There would be a sort of "meta-server" which runs
software which just pairs up interested parties.  The idea is that
both servers and clients would be relatively transient.
Two people would arrange in advance to interact via web protocols, and
agree on a transient URL which they would share.  The client and
server both connect to the "meeting place" host, specifying the magic
name they have agreed on.  The meeting place software would then pair
up connections which shared the same name and allow them to interact
via conventional protocols.  URL's for the meeting place server would
be interpreted in this context rather than simply as file names.
In some ways the role of the "meeting place" software is similar to an
IRC server.  In fact, this concept could be thought of as HTTP over
The big question mark is whether the meeting place would be blamed for
the possibly illicit transactions it facilitates.  It can argue that
it didn't know what people are doing (it might require people to use
SSL for their transactions so it doesn't see them).  But in practice
it may be easy for attackers to prove that illegal transactions are
going on (they just arrange to connect to an illicit server and
download incriminating evidence).  It does seem though that IRC,
despite having a reputation as a place where a lot of illegal
transactions occur, manages to keep running, without the servers
taking the blame.  Maybe it is just a matter of having a low enough
You'd also have a problem if a server, protected by anonymity, decided
that being transient was stupid and arranged to always be ready to
respond to one of the anonymous URL's.  Then there seems effectively
no difference between the "meeting place" with an anonymous server
URL, and an ordinary host with an objectionable file available via
URL.  In each case clients connect and get the same illegal data.
One thing we haven't seen (AFAIK) is anonymous posters offering to
supply illegal data to anyone who asks for it.  Something like "just
post your email address and I'll mail you (anonymously) some Holocaust
revisionism" (or Christian literature, or whatever else may be
banned in your particular jurisdiction).  This is the kind of
application where it would seem that the anonymous web pages would be
effective.  Maybe there is not much demand for it, after all.

@_date: 1996-07-24 06:14:46
@_author: Hal 
@_subject: Ross Anderson's Eternity service 
Sherry Mayo posted here a while back a reference to Ross Anderson's
Eternity service paper, .
He is also giving an invited talk on the subject this fall at a crypto
conference in Prague.
The goal of the Eternity service is to make published information
permanently and ineradicably available, despite efforts on the part of
powerful attackers to destroy it.  The attack model explicitly
includes governments.  This has obvious relevance to current
controversies involving copyright, trade secrets, etc.
It's difficult to evaluate the proposal because many of the issues
seem more legal than technical.  Can a service like this, which
would seemingly exist largely to circumvent legal restrictions on
publishing, possibly be legal?
Anderson's basic concept is of a network of storage servers in widely
scattered jurisdictions.  He uses cryptography so that although the
servers store data, no single computer knows exactly what is stored in
the encrypted files it holds.  Keys to the data are spread across the
network using secret sharing techniques, with mutual cooperation among
the servers being necessary to decrypt files.  (I believe the files
themselves are redundantly stored on individual servers, but they are
encrypted with keys which are split.)  Anonymous communications are
used among the network of computers to reply to requests, so that
attackers can't tell which computer produced a requested document.
The overall goal is apparently to arrange things so that each
individual server has a level of deniability if they are accused of
having provided information which is illegal in some jurisdictions.
It can deny having produced any particular document in question, and
if everything is designed properly it is not possible to prove
otherwise (other than by subverting a bunch of the other servers).
I won't try to go into much detail here (actually I found some of the
crypto details kind of hard to follow in the paper, but I will write
up my understanding if there is interest) but some of the other ideas
are that the service would charge money enough to cover its costs and
add new equipment as storage requirements increase (to prevent
flooding attacks), and that requests would be submitted by broadcast
to the network of servers, and information returned via a remailer
network.  The documents would be identified by some global names, and
one of the documents would be an index file which identifies the
others, with descriptions.
A few questions for discussion:
 - Would it be possible in practice to run a network like this?
 - Would there be much interest in it among users?
 - Would it be a net benefit to society for such a service to exist?

@_date: 1996-07-26 09:45:06
@_author: Hal 
@_subject: Twenty Bank Robbers -- Game theory:) 
I think the best way to approach this problem is to first try to solve
it assuming there are only two robbers rather than 20.  Then once you
have that figured out, try it for three, then four, and so on.  Keep in
mind that 50% support is enough for a proposed distribution to pass, you
don't need a strict majority.

@_date: 1996-07-27 00:56:20
@_author: Hal 
@_subject: Twenty Bank Robbers -- CLARIFICATION 
First, the line is established before the proposals begin.  So the
proposer is not determined by lot, everyone knows who will be  etc.  Second, I think the proposer gets to vote.  The wording is a bit
ambiguous, but it just says that "they" vote, and I think "they" pretty
clearly refers to the whole group.
Now here is the solution for two people:
 (first in line) proposes that he gets it all.   votes yes,  votes
no.  The proposal passes.
Here it is for three people:
 (first in line) proposes that he gets it all.   votes yes, probably votes no (since he will get it all if the proposal fails, by
the above) and  (end of line) reasons like this: if the proposal
fails, he ( will get nothing because  will get it all.  Therefore
voting yes or no makes no difference to whether  stays alive (his
first priority) or how much money he makes (his second priority).  But
it does make a difference in terms of keeping as many people alive as
possible (his third priority).  So he votes yes because of this third
reason.  Therefore the proposal passes and the first person in line
gets it all in this case.
Of course,  could have offered some money to  and gotten his vote,
but that would violate the terms of the problem:  wants to make as
much money as possible.  And since he can get  vote even while
offering nothing to him, that is what he will do.

@_date: 1996-07-27 06:45:40
@_author: Hal 
@_subject: Twenty Bank Robbers -- Game theory:) 
As we have seen apparently the intention was that he does get a vote.
However I don't think the answer changes even with Gary's interpretation.
With two people,  (the front of the line) must propose that all money
go to  otherwise  (who is the only one with a vote in Gary's
version) will vote against it (and get all the money when  dies).
With this proposal  will vote in favor since he gets the same amount
of money either way, and it keeps more people alive (see the post which
describes the goals of the robbers).  This is different than the
original problem, but it is the only case which differs.
With three people,  (in front) proposes to keep it all.   will vote
in favor since if the proposal doesn't pass,  will end up with nothing
anyway (per above).  So  third goal comes into play, maximizing the
number of players alive, and he will vote in favor.   may vote
against but  vote will be 50% ( and  get to vote in Gary's
version) and will carry.  So  keeps it all, the same answer as in the
original version.  Extensions to n players are again left as an exercise,
but I think the answers come out the same in Gary's version.

@_date: 1996-06-09 11:14:24
@_author: Hal 
@_subject: Anonymous return addresses 
Browsing through the 1995 IEEE Symposium on Security and Privacy
proceedings at the library, I found two articles of interest here.  The
first, "Preserving Privacy in a Network of Mobile Computers", is really a
method for anonymously receiving mail via reading it from a large
database such that no one knows which part you are reading.  This is a
topic which we discussed here at some length a year or two ago, but I
think this article has a new idea about it which I will discuss below.
The other one was "Holding Intruders Accountable on the Internet" and it
had one strange comment.  Basically it was about a way of trying to track
down cracker types who break into systems.  One strategy these people use
is to log into a whole series of insecure hosts, one after the other,
before attacking their target.  Then tracing back where they came from is
very difficult.  Cliff Stoll's "The Cuckoo's Egg" is the classic account
of how hard it is to trace these people.  Probably the new books about
Mitnick talk about the same thing.
The idea in this article is that you monitor the whole net and track
all the rlogin and telnet traffic between pairs of hosts.  Then they
describe a statistical technique for determining that two different
telnet sessions are chained together by recognizing the same patterns
of traffic on them.  Basically they count the frequency of spaces and
punctuation marks on minute-long time slices and try to correlate
them.  This way you can tell that the intruder attacking here is also
using these other hosts over there, and try to track him down that
I don't think this is very practical, and I have mixed feelings about the
technology - I don't favor breakins, but the kinds of surveillance that
would be necessary to implement their technique seem very threatening.
Also they do mention the obvious countermeasure of using encryption at
each stage, which would be easy with such things as the secure remote
shell programs around now.
The interesting comment came when they were discussing an alternative
scheme, which would be to have all hosts keep track of their incoming and
outgoing connections:  "The difficulty with all such host-based tracing
systems is that, when an extended connection crosses a host which is not
running the system, accountability is altogether lost at that point....
Even if most hosts could be secured, the intruder community could easily
maintain a set of machines to launder connections, just as they maintain
anonymous remailers."
So apparently in the view of these authors anonymous remailers are
maintained by "the intruder community."  It is unfortunate that we have
this image among some member of the larger community.  BTW, there are
periodic suggestions here to run general-purpose connection redirectors,
but people should be aware of the problem that cracker types would seize
on these as another shield for their crimes.  These would have to be
limited to specific uses, such as port 80 which is the http port and
which hopefully can't easily be used for attacks.
In any case, let me describe the message-receipt idea from the other paper
I mentioned above, which is by David A. Cooper and Kenneth P. Birman of
Cornell.  They have a few ideas, among them exchanging message labels
for the next message in an ongoing conversation, so that later messages
don't have any identifying information on them, but just opaque message
labels which can be scanned for matches to those of interest.  This is a
concept we have discussed before.  However you still have the problem
at least for the first message to an anonymous recipient of getting it to
him anonymously even though the message says what pseudonym it is for.
A simple idea is to put all such messages into a database and to let
everyone scan the message headers to see whom they are for.  Then when
they see one for them they download, decrypt, and read it.  For more
security, let the database machine be trusted, and let the download
request and response be sent encrypted.  Now only the database machine
knows which person asked for which message.  This provides a level of
security analogous to sending through a single remailer.
(Another idea is to download all messages, but that is generally
infeasable if there are a lot of people using the system.)
The new idea is to use multiple databases to get security similar to
using multiple remailers.  I'll describe it using two machines.  Each
holds a database of messages, and the two databases are exactly alike.
Some mechanism keeps the two synchronized.  Furthermore, all the
messages need to be the same size.  There will need to be some padding
and fragmentation/assembly mechanism to arrange for this.
Someone who wants to receive some mail anonymously first downloads all
the message headers as before, and determines which messages are for
them.  Suppose just one is, and it is message number 20 out of a database
of, say, 50 messages.  Now what the reader does is to choose a random 50
bit number (where 50 is the total number of messages in the database).
He makes a copy of this number, and toggles bit 20 in one of them (20 is
the message he wants to receive).  Then he sends one number to one of the
database servers, and the other to the other server.  Each one receives a
random-looking 50 bit number.
What each server does is to take the messages from the database which
correspondo to 1 bits in the 50 bit number, and XOR all those messages
together, byte for byte.  The resulting output will be the same size as
a quantized message.  It is sent, encrypted, back to the requestor.
Now all he does is to XOR the two messages he got back from the servers.
All of them will cancel out except for message 20, which is the one he
wants.  This can be generalized to more than two servers, by creating
multiple bit strings and arranging so that the XOR of all of them will
just leave the bit set for the message he wants.  If he wants more than
one message the protocol has to be repeated separately for each message.
There is no large amount of traffic needed, as each server only sends an
amount of data equal to one message.  The individual servers do not get
any information about which message the requestor wants (other than that
it is one of the 50).  Only by colluding and XOR'ing their bit strings
can they figure that out.  The same kind of collusion is needed to trace
a sent message using two remailers, so the security is similar to what we
get sending messages.
Messages would have a finite lifetime and would expire and be removed
from the database after a while.  The authors propose breaking the
database up into batches with a fixed number of messages, but I don't
fully follow the reasoning behind this.  I guess it reduces the load on
the server when it does its XOR's.
I'm not sure whether this particular scheme was proposed when we
discussed this concept in the past, but it does seem like an interesting
alternative way to receive messages.

@_date: 1996-06-12 09:30:38
@_author: Hal 
@_subject: Anonymous return addresses 
Yes, this is a good point.  It might be addressed by having the later
parts of a multi part message not be identified with the anon ID of the
receiver, but rather with a random message label which is revealed to the
receiver in the first part of the message (encrypted, of course).  Then
the database owner could not tell which message parts went together just
by looking at the messages.  Arrival times might give this away, though,
if all parts of a multi-part message were sent at about the same time.
Yes, there is a tradeoff with the batch size between efficiency and
privacy.  The multi-part message issue does seem to make the problem
potentially worse.  Maybe it would be necessary for anonymous receivers
to mostly receive small messages, and/or make the message granularity
relatively large.
Some of these kinds of volume- or correlation-based traffic analysis
techniques can be countered by requesting dummy messages, ones which the
receiver won't be able to read.  If he asks for five messages every day
from that day's batch then it doesn't leak any information about which
ones are for him.  Asking for a random number averaging five may work
even better, if occasionally he really needs to read six.

@_date: 1996-06-13 12:56:31
@_author: Hal 
@_subject: No Kidding 
This is beautifully eloquent.  I hope it will be persuasive with the
Supreme Court.
Does anyone know which witness came up with the quote above?  Obviously
it resonated with the judges.

@_date: 1996-06-14 14:01:31
@_author: Hal 
@_subject: Comments on MicroPayments and the Web 
Where does the money come from to run this proxy?
Consider two sites, one which acts as a proxy and cache but which
charges something under a penny per page, and another which acts for
free.  Won't the for-pay site be able to afford a larger disk, more
servers, and better net connections?  It will be a superior service.
Micropayments will allow new services and improved quality over what we
have today where we have to rely on charity and advertising as
motivations for much of what we find on the web.

@_date: 1996-06-14 14:22:15
@_author: Hal 
@_subject: doubleclick monitoring web browsing habits 
A post on comp.risks described a web adverstising service called
"doubleclick".  As described in its web pages at , this service provides targetted
advertising on the web.
Participating web sites include links to doubleclick to show graphic
images.  Advertisers sign up with doubleclick and specify profiles for
where and when they want their ads to appear.  Doubleclick then selects
an ad for each user who visits a participating site.  Participating sites
get paid for each such hit, and advertisers pay based on how many hits
are expected.
Apparently this is being used quite a bit.  But what I found disturbing
was the scope of the information being collected by doubleclick.  The
various parameters that advertisers can use in setting up their profiles
for where their ads should appear are described at  and include:
  TARGET BY WEB PAGE/SITE CATEGORY
  TARGET BY SERVICE PROVIDER (SP)
  TARGET BY GEOGRAPHIC LOCATION
   We determine a person's geographic location through the physical
   location of their network or through user registration. We have
   created an extensive map of both organization and Internet Service
   Provider (ISP) networks.
  TARGET BY USER'S OPERATING SYSTEM   TARGET BY USER'S BROWSER TYPE   TARGET BY HIGH-LEVEL INTERNET DOMAIN TYPE   TARGET BY ORGANIZATION TYPE (SIC CODE)   TARGET BY ORGANIZATION SIZE OR REVENUE
  TARGET BY PERSONAL INTERESTS
   doubleclick.net continues to add to an extensive database of user
   interests from activity on doubleclick.net member web sites as well as
   from publicly available sources like netnews. User interests are kept
   strictly confidential and will not be released to advertisers. We do
   allow advertisers to target ad banners based on user's interests. The
   more your ad banner is targeted at specific user interests, the more
   likely you are to generate a response. Personal interest categories
   include:
   Arts and Literature
   Business, Finance, and Economy
   Computers, Software and Internet
   Culture, Religion, and Society
   Education and InstructionalEntertainment
   Government, Politics, and Military
   Health and Medicine
   News
   Recreation and LeisureScience and Technology
   Social Science
   Sports
   Travel
This last category is the really worrisome one.  doubleclick monitors
the web browsing habits of users whenever they hit a doubleclick-
participating site, and builds up databases about users from that, as
well as from usenet posts.  This is exactly what people have been
talking about as an abuse of privacy on the net.
One question is whether enough information to uniquely identify users
is routinely provided by widely used browsers like Netscape.  I have
refrained from telling my Netscape browser my name and email address out
of fear that it would reveal this information; as a result, I can't use
mailto: links, which is annoying (and also suspicious; lynx allows me to
do mailto: without permanently entering an email address).
This points out the need for browser providers to be sensitive to the
privacy needs of their users and to clearly explain when and under what
circumstances private information is revealed.  It also suggests that
services like  will be increasingly important for
people to protect their privacy while browsing.

@_date: 1996-06-15 11:11:54
@_author: Hal 
@_subject: doubleclick monitoring web browsing habits 
When I run lynx (2.3.7 beta) to , it says:
   Here's a sampling of the kind of information that a site can collect
   on you (please wait a moment):
     Your computer is a Unix box.
     Your Internet browser is Lynx.
     You are coming from jobe.shell.portal.com.
     You just visited the Anonymizer Home Page.
No user name here.
Also, when I follow a mailto: link it asks me to input the email address
I want the mail to be from!  So I don't think it is using local user name
information, although certainly that is potentially available to it.

@_date: 1996-06-16 08:11:32
@_author: Hal 
@_subject: Remailer Operator Liability? 
The real problem with remailers and kids, from my experience, is not
kids who use nyms; it is people sending sexual material, unsolicited,
to children.  I have had a few complaints from parents where this has
I am pretty sure it is illegal, CDA or not, at least if the material
is obscene rather than merely indecent.  As Declan says, the issue is
accountability.  If the remailer operator ends up being considered the
person who sent the mail, he could be in deep trouble.

@_date: 1996-06-16 09:17:53
@_author: Hal 
@_subject: Proposal: PGPmail Plugin for Netscape/Mosaic 
There was a little discussion about this on the coderpunks list, but I
didn't get the impression that anyone was ready to run out and do it.
I'm not sure whether plugins could also be used for receiving mail in
addition to sending, but if so it does seem like a good way to add the
Also, as I understand it, Netscape plugins have to be downloaded and
installed ahead of time by the user, so it is not quite true that this
gives one-click PGP access to everyone with a browser; it will only be
for Netscape users who have downloaded and installed the right plugin.
Also, plugins are architecture specific so he would have to be running
the kind of computer for which a plugin is available.
I have a Java applet which sends PGP mail similarly to the model you
describe.  This will work in principle for any browser which supports
Java, and does not require anything to be downloaded or installed ahead
of time (other than the Java-compliant browser).  It is still pretty
rough and is more of a proof of concept than a production program but I
think it is another potential approach.  Look at  and follow the links to
the PGP compatible mail applet.

@_date: 1996-06-16 10:34:32
@_author: Hal 
@_subject: pretty good reputation 
No, this is not true.  PGP does not implement any form of trust
delegation as you have described here.  Rather, each person must
explicitly indicate that they trust someone as a key signer.  Without
that individual action, snoopy and bob in the above example are useless
to alice as key signers.
What PGP does do is that if alice has indicated that she trusts jane and
snoopy, and she needs a key for bob, she can use bob's key signed by
snoopy and snoopy's key signed by jane to decide that she has a good key
for bob.  Just having bob's key signed by snoopy is no good, even if
alice trusts snoopy, because she can't be sure that she actually has
snoopy's key.  So she needs snoopy's key signed by someone else that she
trusts, in this case jane.
There was considerable discussion in the design of PGP's key signatures
on this issue, and Phil decided against trying to let people express
publicly how much they trust others.  Among other things, he was afraid
that people would feel compelled to lie for social reasons, leading to
inaccurate trust estimates and weak key validations.
There has been considerable discussion in the "official" Internet
encryption working groups (PEM and its follow-ons, for example) about
issues of trust in the context of Certificate Authorities which exist in
a hierarchical structure and sign each others' as well as end users'
keys.  Different CA's may have different policies about how they check
identity, and figuring out from this how much trust to put in a key
certificate ends up being a potentially messy problem.
I also found a paper several years ago, I think by the USC/ISI
people, about systems which would allow trust delegations in a model more
like the web of trust.  Also some of the recent work by Matt Blaze and
(largely independently) Ron Rivest for generalizations of key
certificates could perhaps serve as a basis for extending trust in a web
Hal Finney

@_date: 1996-06-17 07:22:40
@_author: Hal 
@_subject: alpha.c2.org in deep shit? 
I peeked at a few messages passing through my remailer from alpha.c2.org
(mea culpa) to see whether the problem might be at my end.  As far as
I could tell, the messages were correctly formatted and all, but simply
lacked message bodies.  So it looked like the data being sent from
alpha.c2.org was already messed up and had stripped the bodies.  I set up
an alpha.c2.org alias a few days ago and when I sent mail to myself I
got mail without a body, so I think it is a definate screwup.  I sent a
report of this to remailer-operators list but have not seen a response
yet from Sameer.

@_date: 1996-06-17 07:37:15
@_author: Hal 
@_subject: Netscape Mail Security and PGP Plugins 
There are two main issues, export and patent.  Export laws keep it from
being used outside the U.S., and patent laws keep it from being used
within the U.S.  Everyone else should have no problem.
According to discussion on the coderpunks list, this is not presently
: From coderpunks-errors at toad.com  Sat Jun  8 18:33:32 1996
: Date: Sat, 8 Jun 1996 18:07:06 -0700 (PDT)
: From: thams at thams.com (Kurt Thams)
: Subject: Re: plugging in
: : : > > >> >You could hand any websurfer a Netscape PGP plugin without much work
: > > >> >at all, and you could easily build it on lots of platforms. After all,
: > > >> >look at how many platforms that lowly C code like PGP runs on.
: > : > not knowing what Netscape plugins do, : > let me ask the plumbing question: what would this do, and how?
: > allow users to send/receive encrypted PGP mail in the "netscape mail" window,
: > transparently like Raef's sendmail wrapper?
: > how do you invoke a plugin, when & why? : : This is not possible yet. The Netscape API doesn't expose the mail service
: to plug-ins. One would think that future versions of Navigator will do
: this, however. : : -- kurt thams
: -- thams at thams.com
However as has been mentioned here a PGP/MIME mail type could
theoretically be used to activate a handler for that incoming mail.  I
don't know exactly how this would work.  Glancing at the netscape plug
docs near  it appears
that plugins are activated on HTML page downloads, not (necessarily) on
mail receipt.  So unless you typically find your incoming mail on a web
page, it doesn't look like this will work.  I will ask about it on
coderpunks for clarification.
Sorry, can't help you here.

@_date: 1996-06-18 14:05:54
@_author: Hal 
@_subject: pretty good reputation 
Here are some references to the material on reputations I mentioned
     * Charlie Lai, Gennady Medvinsky, and B. Clifford Neuman.
       Endorsements, Licensing, and Insurance for Distributed System
       Services, In Proceedings of 2nd the ACM Conference on Computer and
       Communication Security November 1994.
This discusses some concepts related to extending trust relationships
through a network.
This suggests a formal way of specifying trust relationships among keys.
In effect you have little programs that get activated by certain keys, or
by certain signatures.  It is a very flexible methodology which could be
adapted to many ways of specifying trust relationships.
 (or .tex)
This is a key certificate structure which is somewhere between a
hierarchical and a web of trust system, somewhat influenced by Blaze's
ideas.  It is pretty limited though in the kinds of trust delegation it
allows.  You can accept another person's signatures on specific keys but
you can't mark him as a generally-accepted signer.  However you can
develop chains of signatures as in PGP and perhaps some extra mechanism
could be used to decide when to trust them.

@_date: 1996-06-19 17:10:40
@_author: Hal 
@_subject: Recipients get the postage 
I was reading old threads on remailers, where various ideas were
suggested to reduce abuse.  One was to charge postage, in order to
discourage spam and somewhat discourage nastygrams, as well as to
compensate the remailer operator for his risks.  A variant was to tell
the recipient that he had anonymous mail waiting, and possibly charge him
to receive it.
I had a different idea, which has probably been suggested before: make
the sender of the anonymous mail pay, but pass the money to the
All my complaints come from people who have received mail, never from
people who have sent it.  So obviously the steps we take need to make
recipients happier.  Paying them is one way to do it.
Of course there are lots of details: how much should be charged, will
recipients really be so thrilled when a "fuck you" note has a nickel
wrapped in it, how will they cash their checks, etc.  If ecash
were used this might be a motivation for people to open an account.
Nym servers could be funded by the nym owners to pay for a certain number
of messages.  Since the nym owner ends up receiving the cash it doesn't
actually cost him anything and he can easily afford to keep a pool of
cash in the nym server to keep the messages coming through.
Remailers which wanted to apply this rule would have to deposit the money
and immediately withdraw the same amount to include in the outgoing mail.
Users would basically have to trust the remailers to do this honestly.
Maybe it only needs to be done when the mail goes to a non-remail end
user destination, not for the intermediate links in the chain.
Postings to newgroups and mailing lists would make the cash available to
the first one who grabs it.  It can be a fun game; we've done it here
occasionally.  This might also motivate people to sign up for ecash.
Just a thought -

@_date: 1996-06-26 05:40:28
@_author: Hal 
@_subject: AT&T bans anonymous messages 
(I can't get through to  this morning.  Makes
me appreciate that dial tone I get every day.)
Is the WorldNet service an Internet access account, providing dial-in
SLIP or PPP access?  Or does it also provide user accounts like shell
accounts or like AOL?
The wording of this restriction is a bit ambiguous.  Technically if I
choose to resend someone else's mail I am not transmitting it anonymously
or under a false name, especially if I make clear what I have done.
He is anonymous, not I.
Rather, if I want to post a message anonymously I must access an
anonymous remailer to do so; if I want to post under a false name I must
hack my message headers or connect to someone else's news or mail server
and supply false data.
Doing the latter is something of a violation of the Internet rules, such
as they are, so I could see forbidding it, but forbidding use of an
anonymous remailer on someone else's system seems unreasonable.  AT&T
should not try to control what Internet services I access.
If I run an anonymous remailer on my home PC, connecting to WorldNet to
download the mail, decrypt it, scramble it, and re-send it under my name
but with a disclaimer attached telling what I have done, I have not
posted or transmitted anything anonymously or under a false name.  The
source of the material I choose to transmit, as long as it is legal, is
not something under AT&T's control.

@_date: 1996-06-30 03:06:32
@_author: Hal 
@_subject: anonymous mailing lists 
Since the PGP is run on private computers, and only at mail-reading time,
there should be no problem entering the conventional encryption
passphrase and checking to see whether the messages decrypt.  Actually
PGP puts a pattern at the beginning of the encrypted portion, so
successful decryption can be checked very quickly, without much of a
computational load.

@_date: 1996-06-30 04:13:04
@_author: Hal 
@_subject: anonymous mailing lists 
This was discussed here several years ago, under the name "anonymous
message pools".  Myron Cuperman, the operator of the extropia remailer
implemented one, although I don't know if it is still running (I
haven't gotten any mail from it for years).  It was basically just a
mailing list specifically for this purpose, that you would use as your
anonymous return address.  Of course a problem is that there may not be
enough people signed up to provide much privacy protection.

@_date: 1996-06-30 05:03:31
@_author: Hal 
@_subject: anonymous mailing lists 
Wei Dai did some nice statistical analysis of this type of attack
sometime a year or two ago.  Even with countermeasures such as you
suggest, if they are not perfect, so some information leaks correlating
incoming and outgoing messages, Wei showed that it was possible to
deduce the owners of the nyms surprisingly quickly.
The countermeasures do work - if you get and send exactly 50 pieces of
4K byte email every day, no matter what, then correlations don't exist
- but they are expensive to do perfectly.  For now we have much worse
weaknesses; none of the current return-address systems are really safe,
other than posting encrypted mail to newsgroups (and even that may be a
problem if they suspect who you are and are monitoring your computer
link to see if you download certain messages).

@_date: 1996-03-05 05:37:10
@_author: Hal 
@_subject: (Fwd) Gov't run anon servers 
I have run two remailers for about three years now, and I have never been
contacted in any way by law enforcement or government people in relation
to the operation of the remailers, or of any mail which has been sent
through them.  I get a fair number of complaints by private individuals,
but I have never heard anything from the government.
However, if I were a computer-savvy law enforcement agent, and I wanted
to track messages through one of my remailers, I would try a
technological approach.  I would first break the key for my remailer.
That is trivial.  The passphrase is in PLAINTEXT in the script file
which runs the remailer!.  It has to be.  That is true of all automated
remailers.  Anyone who can break into the remailer server and acquire
root permission can find the remailer secret key.  My keys have been
unchanged for three years.  Surely some enterprising hackers have
stolen the keys by now.
(That is why my keys are only < 512 bits.)
Then the LEA has to insert mail-monitoring software somewhere either in
the remailer system or on some connection to it.  That is probably more
difficult and may require cooperation from a system manager somewhere.  I
don't really know how hard it would be.  But breaking the key is the easy

@_date: 1996-03-06 03:43:44
@_author: Hal 
@_subject: (Fwd) Gov't run anon servers 
OK, I stand corrected regarding the operation of mixmaster.  However,
this does not gain much security, certainly not in comparison to the
effort involved to break a key.
It will be just as easy to steal the mixmaster executable as to steal a
script file containing a pass phrase.  And it might even be possible to
run the stolen mixmaster directly to decrypt intercepted incoming mail
messages, without even having to type in the pass phrase.  Failing that
the attacker could easily extract the pass phrase from the mixmaster
executable file.
The other suggestion that was made here, that the operator would have to
manually type in the pass phrase every time the computer rebooted, would
be a way of avoiding having the information in the clear on the disk.
However it would probably not be a practical method of operation given
the reliability of at least the Unix operating systems that I am familiar
with.  And even then the information is in memory.  An attacker who could
gain root privileges (and let's not pretend that the NSA can't do that)
can dump memory and later comb it for the key information.
My point remains that strong keys are pointless for remailers which run
on Unix systems connected to the net.
Now if you have your remailer on a PC at home, and you're not running
anything else on it (like http servers), maybe that is safe.  I am not
familiar enough with security holes in such a configuration to judge.
Probably it would depend on what mail-processing software you run, and
the nature of your net connection.
Recall that my original comments were in connection with the claim that
the government was running most of the remailers.  As I said, I still
think that is absurd when it would be so much easier to simply steal
their keys.

@_date: 1996-03-06 09:26:41
@_author: Hal 
@_subject: (Fwd) Gov't run anon servers 
I was speaking of present conditions.  If and when proven-secure Unix
systems start being used as remailer servers on the net then it may be
worthwhile having a larger key.
The point is that there is no advantage in strengthening an element of
the system which is not its weakest link.  Factoring my remailer keys
of 510 bits is not, I am sure, the easiest ways of finding the secret
It's not clear that this is the case, though, is it?  What is the rate of
creation of new remailers?  It doesn't seem that high to me.  We can't
know how quickly they are being broken, but it is just a matter of
getting root privileges on the remailer machine.  From what I hear of the
capabilities of experienced hacker/cracker types, it is very possible
that remailers are being broken faster than they are being created.  Of
course, there is no way to know.
I meant that the home PC system would have an ongoing connection to the
net, perhaps in the form of periodic uucp or POP connections.  By using
batching, traffic analysis would be no easier for such a system than for
any other.
I am not sure what you mean by this.  My experience is that new CERT
advisories come out every few months which represent security holes big
enough to steal remailer keys.  The most recent one, out just a couple
of weeks ago, is a bug in sendmail and maybe some other programs which
could allow remote users to get root access if they have access to a
DNS server:
Even if a remailer host operator is on the ball and fixes each one as
it is announced, he still was vulnerable before the announcement was
made.  In many cases these bugs are found by hackers who exploit them for
bad purposes before the good guys figure out what they are doing.
Suppose a reasonably large prize of several hundred or a few thousand
dollars were offered for someone who could break in and steal the key
of some remailer on a net-connected Unix system.  Wouldn't you agree
that the prize would be claimed before too long?
No, my point is that it doesn't really help to strengthen something which
is not the weakest link in the chain.  My rationale for having a short
key is that it more accurately reflects my estimate of the degree of
security provided by my remailer.  Actually probably an even shorter
length than 510 bits would be appropriate, maybe something more like 300
or 400 bits.  Going to a 1000 bit key would probably mislead people into
thinking that they only way an attacker could trace their message would
be by using a zillion mips-years of computing power or something.
Yes, I think I misstated my point here.  My real point was that large
keys are inappropriate.  Maybe you are right that it is easier to start
up a remailer than to break one.  On the other hand, unless you also break
the ones you don't run, you (as a LEA) are not in a position to
accomplish your presumed goal, which is to track criminal messages to
their source.  So in practice I think they would try to break remailers,
and again I am sure they will not do so by factoring keys, even for
It's also my personal impression that remailers are not mostly run by
LEA's, just on the basis of the occasional postings I have seen by
remailer operators here.  Frankly I doubt that remailers are enough of a
problem to be worth the effort on the part of a LEA to run one and deal
with all of the hassles.  But this may change in the future.

@_date: 1996-03-08 05:36:51
@_author: Hal 
@_subject: Square pegs in round holes, matchmaking, corporate mailservers 
To avoid a trusted intermediary, the problem can be thought of as a
secure multi-party communication problem with private inputs, which is
much studied in the literature.  The easiest formulation is pairwise:
Alice and Bob mutually engage in the calculation of "Alice loves Bob"
AND "Bob loves Alice".  Each inputs his feelings as an input bit, and
the output will be true only if they have mutual feelings.  Each pair of
potential lovers would then go through the protocol with each other.
This problem is solved in "Multiparty Computations Ensuring Privacy of
Each Party's Input and Correctness of the Result", by Chaum, Damgard,
and van de Graaf, in the proceedings of the Crypto 87 conference.  They
even discuss this application directly:  "Note that this AND-gate
computation, where both parties want to hide their input from each
other, has a meaningful application: consider the situation where Alice
and Bob have just met, and each considers dating the other.  Neither
wishes to lose face in the following sense: if Alice wants a date but
Bob doesn't, Alice does not want to let Bob know that she wanted the
date.  And the same holds for Bob.  In other words: if a party does not
want the date it does not find out the other party's decision."
The solution is reasonably practical, involving scrambled truth tables
and bit commitments, and is related to some of Chaum's work on
zero-knowledge.  The paper is a bit theoretical and hard to read,
though.  I can write up the protocol if anyone is interested.

@_date: 1996-03-08 05:42:12
@_author: Hal 
@_subject: Square pegs in round holes, matchmaking, corporate mailservers 
I don't think this satisfies the requirements.  Once Bob calculates H'
and sees that it matches H, he knows that Alice likes him, but Alice
doesn't know that he likes her.  The whole point of the protocol was to
be fair.  Bob must only learn that Alice likes him if Alice is guaranteed
to learn that he likes her.
I have posted an alternate solution in another message.

@_date: 1996-03-09 05:57:13
@_author: Hal 
@_subject: Web of Trust vs other models 
Let's not forget that the web of trust only works if you personally
know and trust the next-to-last person in the chain (the one who signed
the key you are interested in).  Chain length doesn't matter if you've
never heard of the last signer.

@_date: 1996-03-14 09:56:50
@_author: Hal 
@_subject: A lengthy preliminary analysis of the Leahy bill. 
Are you familiar with the Posey case?  That decision by the 9th district
court (which oversees export cases) explicitly rejected the contention
that restrictions on export of written materials violate the First
Amendment.  Although I am not a lawyer, I wrote some notes on this case at:
Below is an excerpt from that court decision in which they make it quite
clear that the First Amendment doesn't apply.  In this case, the item
being exported was a technical manual obtained from the US government
itself under the Freedom of Information Act.  Surely this is even closer
to what the framers of the constitution had in mind when they conceived
of the First Amendment, yet the constitutionality of restrictions on its
export has been upheld.  So you should be aware that the status quo is
that the restrictions you fear being legitimized by the Leahy bill are
already in place.
Here is part of the Posey decision [864 F2d 1487] (the AECA is the Arms
Export Control Act, which is what currently forbids the export of
encryption devices, and the CAAA is the Comprehensive Anti-Apartheid Act,
which applied specifically to South Africa, where the materials in this
case were sent):
    VII. FIRST AMENDMENT
    Appellant's final argument is that the First Amendment bars the
    government from restricting the export of information that is already
    available to the public.  He insists that the data he sent abroad
    was available under the Freedom of Information Act, and therefore
    could be legally obtained by virtually everyone in the world.  He contends
    that the First Amendment prohibits the application of the AECA and
    CAAA to the export of such publicly available information.
    Our Court has already considered and rejected this argument.  In
    United States v. Edler Industries, 579 F2d 516 (9th Cir. 1978), we
    rejected an essentially identical challenge to the predecessor of the
    AECA.  The defendant was convicted of exporting certain manufacturing
    designs that were on the Munitions List but were not classified.  He
    challenged his conviction on First Amendment grounds, arguing that the
    government could not constitutionally prohibit the export of techno-
    logical data that was widely distributed within the United States.  In
    rejecting that claim, we explained that even assuming that the First
    Amendment offers some protection to the dissemination of technical data,
    the government has a strong interest in regulating the export of
    military information:
      The federal government undeniably possesses the power to regulate the
      international arms traffic....  As a necessary incident to the power
      to control arms export, the President is empowered to control the
      flow of information concerning the production and use of arms.  The
      authority to regulate arms traffic would be of negligible practical
      value if it encompassed only the exportation of particular military
      equipment but not the exportation of blueprints specifying the
      construction of the very same equipment.
    579 F2d at 520.  We accordingly concluded that the government could
    permissibly restrict the flow abroad of data included in the Munitions
    List.  579 F2d at 521.  Finally, we held that the government's power
    to issue such restrictions was not affected by the domestic availability
    of the regulated data:
      Given the unquestionable legitimacy of the national interest in
      restricting the dissemination of military information, the claim of
      public availability in the United States is not a defense recognized
      by the Constitution.
    579 F2d at 522.
    Appellant attempts to distinguish Edler from the present case by pointing
    out that the exported data in Edler was "cutting edge" technology and
    was not widely used in this country.  [Citation].  Whether or
    not this was factually true of the technology at issue in Edler, however,
    the Edler decision clearly assumed for purposes of its decision that
    the material was extensively available in the United States.  See 579
    F2d at 518, 522.
    Moreover, we believe Edler should not be read as permitting the govern-
    ment to restrict the export of only that information which is not
    widely available domestically.  Under appellant's reading of Edler,
    if the government wished to prevent technical data from being sent to
    foreign powers, it would be required to suppress the information alto-
    gether, at home as well as abroad.  This outcome would blur the fact
    that national security concerns may be more sharply implicated by the
    export abroad of military data than by the domestic disclosure of such
    data.  Technical data that is relatively harmless and even socially val-
    uable when available domestically may, when sent abroad, pose unique
    threats to national security.  It would hardly serve First Amendment
    values to compel the government to purge the public libraries of every
    scrap of data whose export abroad it deemed for security reasons
    necessary to prohibit.  We conclude that appellant's conviction does
    not violate the First Amendment.

@_date: 1996-03-15 11:06:53
@_author: Hal 
@_subject: Kid Gloves or Megaphones 
As is well known, Chaum has been saying that one of the good features of
ecash (from the point of view of regulators and law enforcement) is that
payee anonymity is not supposed to be possible.  This means that if
someone sets up a shop to sell something illegally, they can be caught.
(I suspect that is at least part of the reason why you have to fill out a
multi page form to open an ecash account, so they have enough information
to arrest you if you break the law.)
It also means that various kinds of crimes would be prevented as well,
such as theft of funds or extortion.  Imagine that someone starts
lobbing mailbombs at the cypherpunks list, and demands a payment of $1
a week from each subscriber to keep him from doing it, said payments to
be posted to some newsgroup encrypted with a specified PGP key.  Right
now he could be caught when he tries to deposit his ill-gotten riches.
But with payee anonymity that could be avoided.
As a remailer operator I unfortunately see more of the seamy side of
anonymity than most people.  I do think there are people who will take
advantage of this technology in harmful ways.  So payee anonymity will
certainly make life more interesting.
However, Mark Twain Bank presumably went into this business with the
expectation that they were providing a non-payee-anonymous payment
system.  They have already shut down at least a couple of merchants who
were selling materials not to MTB's taste.  So if they find out that they
are now providing the perfect payment system for criminals, I would not
be surprised to see them suspend the ecash trial and demand that Chaum
redesign the system to truly make it non-anonymous for payees, if that is
So while I admire Eric's ethical concern about making relevant
information about the properties of ecash available, it is also important
to understand the possible outcome.
One thing I notice that was missing from Eric's posting was a description
or reference to exactly how the payee anonymity is achieved.  Is it his
intention to tell people that it is possible, yet to keep secret how it
is done?  This way there might be a debate about the desirability of full
anonymity, while not actually putting these tools into the hands of those
who would misuse them.  And it might lessen the chance of precipitate
action by MTB and other ecash issuers.
But on the other hand it's not clear that keeping it secret is possible
or desirable.  A full discussion of the issue will require
understanding of technical aspects.  How effective is the payee
anonymity?  How about a timing/amount coincidence attack, where
payments of X dollars to anonymous person A are always followed a few
moments later by deposits of X dollars to account B?  Does the payee
need to trust a "broker" who serves as an intermediary with the bank?
Is there any way the bank can distinguish a payee-anonymous deposit
from a normal one, and are there any countermeasures the bank could
take to prevent payee anonymity?  These questions would seem to require
understanding of how the scheme works.
Also, there were a number of postings a few months ago by people who had
ideas about how payee anonymity could be done.  They mostly had drawbacks
and may not be as nice as what Ian has come up with, but could perhaps
serve as a starting point for re-creating something similar to Ian's
ideas.  So keeping it secret may not be a practical possibility.

@_date: 1996-03-17 00:23:01
@_author: Hal 
@_subject: Java bignum package 
Bill is referring to an announcement I made elsewhere about a bignum
package I am working on in Java.  Take a look at  to play with a
little interactive "calculator" I made with it.  You need a Java enabled
browser to use it.
I think Bill's idea is a good one but I will discuss it further on
coderpunks since it gets into some technical aspects of Java that may not
be of general interest.

@_date: 1996-03-23 03:56:16
@_author: Hal 
@_subject: PGP key spoofing 
PGP checks specifically for the case of keys whose IDs match but the
keys themselves differ.  It has always been obvious that keys can easily
be synthesized with given IDs.  I added this warning in version 2.0
about four years ago, in the keyadd code:
"\n\007Warning: Key ID %s matches key ID of key already on
key ring '%s', but the keys themselves differ.
This is highly suspicious.  This key will not be added to ring.
Acknowledge by pressing return: "
As you can see, it does in fact literally ring an alarm bell - the "\007"
above is the ASCII bell character.
Disclaimer: I have not worked on PGP since version 2.0 so possibly my
code has been changed or eliminated, but I think that is unlikely.
Hal Finney

@_date: 1996-03-29 15:56:15
@_author: Hal 
@_subject: The Law Loft: Surviving the Biometric I.D. Card 
I have been surprised not to hear more about this aspect of the
immigration reform laws.  Unfortunately the alert which Tim forwarded
is out of date, and I believe the reforms did pass in some form.  I
view biometric identification as a very disturbing development and
I'd like to hear more about the wording of the bills as finally passed.
If they really want to give people a card which proves their legal
residence in the US, a less intrusive approach is possible.  Rather
than set up a database of all employees, and/or give each person an
official identity card, instead have people come and prove their residency,
then give them a card with the biometric information and a blind signature.
No other information goes on the card, no information goes into a
database.  The signature is a certificate testifying that the person
with the particular thumbprint is legal to work in the US.  The card
can't be transferred since no one else has that thumbprint.  But no
identifying information is recorded.  There is no advantage in people
coming in twice to get more than one card since their print will be
the same each time, so no database is needed.
A simpler approach dispenses with the blind signature and just issues a
regular signature on the thumbprint or other biomarker.  This is about as
good since proving residency will probably require at least an incidental
display of identity papers, so you are already trusting the agency not to
log you, and you can just as easily trust them not to log the signature.
This is an approach which accomplishes the goal with a minimal intrusion
into people's privacy.  I don't know how it compares with current
biometric concepts - maybe this is similar to what they are proposing,
minus the database.  But there is a general principle that government
regulations should use the least restrictive means where they violate
people's rights, such as the seriouss privacy violations in the current
proposals.  So I think it should be possible to make a strong argument
that privacy protecting alternatives which accomplish the objective must
be considered.
The key concept is to unlink identity from the credential.  That is the
crucial idea of credentials, one which has not yet pentrated the
popular consciousness.  Maybe we need to start pushing it more.  You
don't have to prove your identity to prove you have certain
qualifications.  There is no need to tie everything to a central
identifier.  A system of dispersed, stand-alone credentials will be far
better at protecting privacy.  Blind signatures can help protect against
cheating, but policy can work too, especially when credentials are issued
by a public agency on a large scale, so systematic and secret record
keeping is impractical since so many people are involved.
I know a lot of people will oppose even this form of biometric
information, which is not tied to identity.  Perhaps we could have some
discussion on the degree to which people see this kind of system as a
privacy threat.  If the credential concept is new we could discuss that,

@_date: 1996-03-29 17:19:09
@_author: Hal 
@_subject: What backs up digital money? 
Tim is right when he goes on to say that digital money is not exactly
like any of the traditional financial instruments.  However I think it is
more like cash, and for that matter more like currency, than like other
Here are some of the ways it is like cash.  It is basically anonymous,
with neither buyer nor seller able to learn the identity of the other,
even with the help of the bank.  It is untraceable; there is no way to
know, given a piece of cash, under which transaction it was withdrawn
from the bank.  It is a bearer instrument; anyone can hold it, and
whomever presents it gets the value (that is, it is not "made out" to a
certain individual).  A piece of dcash is an asset, a claim on the
bank.  When dcash is withdrawn, the bank must debit (reduce) the
customer's account immediately.  Likewise, when it is deposited, the
depositor's account gets credited.  Between those times the net amount
of money in bank accounts was reduced, by exactly the amount of
circulating dcash.  When the money supply is counted, circulating dcash
will need to be included with traditional currencies like cash and
coins (I think that is M1), since it is not counted in the bank
The difference with checks and wire transfers is that in those cases
there is a direct transfer of assets from one account to another.  These
are not bearer instruments; in fact wire transfers aren't really
financial instruments at all, and do not carry value.  There is normally
no anonymity or untraceability either, with these kinds of transactions.
So I see them as being very different from dcash.
The best analogy to dcash is the private currency which was issued by
banks and other financial institutions prior to about 1850 (in the US).
Until that time the US government did not issue paper money, it was all
private.  A bank would issue bank notes, which would circulate in its
local area as money.  They were backed up by "real money", specie,
metallic coins, which the bank kept in its vaults.  The digital cash
issued by Mark Twain bank is in many ways a throwback to these old bank
There are differences, of course.  A lot of attention is focussed on the
non-transferrability, the fact that you have to deposit the cash at the
bank after each transaction.  Some people say that this means that the
cash doesn't circulate, hence is not a currency, hence must be more like
checks, etc.  But I disagree.  I view this aspect of dcash as superficial
and unimportant.  First, it may not be technically necessary.  Some cash
systems have been proposed which allow for transferrability.  But second,
even if it is necessary to exchange cash after each transaction, that can
be done completely automatically.  In fact, the agency which does so
doesn't even have to be the bank, as far as the financial aspects go.
The exchange has no financial impact on the bank's accounting procedures.
And it can be completely automated for users.  They don't even have to be
aware of it.  Their software can turn in received dcash at the bank for
fresh banknotes, anonymously and automatically.
So I view dcash as a circulating currency, where the act of transfer in
some implementations requires some technical assistance from an agent
of the bank able to make digital signatures on its behalf.  It is more
than simply a mechanism for transferring funds from one account to
another (unless you think of government currency in those terms).  I
view it as possessing real value, as being a genuine asset in the same
sense as other forms of cash.

@_date: 1996-03-29 20:45:42
@_author: Hal 
@_subject: What backs up digital money? 
I have to disagree somewhat with a few points Mike made.  I would say
that gold and diamonds do have intrinsic value, based on their beauty
and the desire of people to own them.  I think it is too simplistic to
denigrate these desires as the product of advertising.  The feelings that
people have which make them desire these things are as legitimate as
other forms of desire.
Along these lines, I think one of the factors which made gold and
silver coins accepted as money was their intrinsic value.  Even without
being certain that another person would take the coin, a person might
accept payment in such a coin because of its inherent value to him.
Other early forms of money, such as beads or tobacco, also had
intrinsic value in their time and place.
One area I would agree with Mike is that these items may not always
retain their value, since part of it is psychological.  And as with any
other commodity, if new supplies became available their value would
fall.  This might be especially pronounced with gold and diamonds since
part of their value is due to their intrinsic rarity.  Diamonds as
common as glass would not be worth much more.  (Of course, government
money as common as paper is worth the same as well, as hard experience
has taught us.)
A particular issue of "digital cash" could be denominated or backed by
anything the issuer thinks there is a market for.  Gold backed digital
currency would have certain advantages and disadvantages.  Currency could
be backed by a basket of commodities, or a synthetic average of several
countries' currencies.  You would not exchange your dcash for a bushel of
wheat and a barrel of oil, but rather for dollars or pounds equal to the
market value of these commodities.  These and more elaborate possibilites
are no more difficult to imagine than mutual funds or stock market
index futures, not to mention the more complex synthetic investments.

@_date: 1996-03-30 20:51:12
@_author: Hal 
@_subject: What backs up digital money? 
I think this is an interesting idea, and no doubt will happen in some
form.  Coupons and other special tokens could be issued electronically.
But there are limits to how far it is likely to go, since these tokens
are competing with ordinary cash-backed tokens (digital cash).  It's like
today, maybe you could buy something at the swap meet using a handful of
50-cents-off toilet paper coupons, if the seller was agreeable.  But this
becomes in essence a barter trade.  Why do this, if the cash alternative
is much more widely accepted?
Another factor that arises is that if some token does catch on and
circulate widely, it could be subject to regulation.  I understand that
in Las Vegas, some people started using casino chips as money.  You
could buy things with them, and they were accepted since people knew
they could be turned in for cash at the casino.  But the Feds cracked
down and brought the practice to a halt.  (I will ignore for now the
question of whether such a crackdown could work on the net, but it would
at least be a barrier to the acceptance of such tokens.)
The idea of your "market square" token, which represents a basket of
other tokens, is interesting, but it seems like you're basically
re-inventing money.  I don't quite understand the specifics of your
proposal, where the market square token is based on the "market value" of
the other tokens.  In what units is this market value expressed?  It
seemed like what you had instead was a set of relative prices, where each
token was worth a certain number of each other kind.  I don't see how you
can get a unique market value for each token out of that system.  It
doesn't seem like the relative value idea really works, anyway, as it
suffers from the barter problem that there will be too few people who
want to trade their shoe tokens for fruit tokens.  That was what
motivated the transition from barter to money in the first place, or so
the story goes.
If your overall point is that even without digital cash, we would end
up with some form of electronic money eventually anyway, I think it is
true.  Entrepreneuers abhor a vacuum, and if the need is there it will
be met.  But the fact is that we are likely to have digital cash before
all these other things, so I don't really see the whole scenario coming
to pass.  I do think a lot of your specific applications are
interesting, though, and hopefully there will be many more creative
uses of this technology.  I know Eric Hughes a while back was talking
about a way for players to transfer wealth between MUD games using a
token based system.  There are a lot of game possibilites.

@_date: 1996-05-01 17:07:26
@_author: Hal 
@_subject: Why I dislike Java. (was Re: "Scruffies" vs. "Neats") 
Aren't you holding Java to a higher standard than ordinary applications?
If your traders run any software at all on their machines there is the
risk of harm.  The Netscape binary itself could be hacked to do bad
things.  Likewise with any other software they run.
Wouldn't it be safer to run a Java applet than a typical program from the
net?  At least applets run in an environment which is designed to
restrict the harm they can do.  In OS's like Windows 95 there are no
such restrictions on programs.
Take a specific example: Mixmaster.  This is a client for the remailer
network.  It is reasonably well suited to being implemented as a Java
applet given the current restrictions on the language.  If you had a
choice between downloading and running the client as a program on your
PC, versus loading and running it as an applet, which would you prefer?
Or if you would do neither, how would you go about acquiring this
functionality?  Would you forego it forever, or would there come a time,
say if no one else reported problems, that you would be willing to run
one or the other?
What I am really trying to get at is how you balance the risks that
come automatically when you interact with the net against the benefits
you get by doing so.  You have chosen a certain point on the
risk-reward continuum, one for which Java applets are apparently on the
too-risky side.  So I am wondering what principles you use to decide
where a proposed application falls.

@_date: 1996-05-08 10:36:18
@_author: Hal 
@_subject: Transitive trust and MLM 
I have a few thoughts relating to the "web of trust" versus
hierarchical key certificate systems.  This description is pretty
elementary and is intended more for people who have not been familiar
with the issues before.  First some background.
The problem to be solved is how to know that a particular public key
is actually associated with a particular person.  This actually gets
into some fuzzy philosophical areas in terms of what we mean by a
person and what this association involves, but let's avoid those and
just consider the specific question of binding a key to a particular
email address and/or user name.
Most of the "corporate" systems being advanced today use a
hierarchical approach.  One or a small number of trusted key
certification authorities (CAs) are at the root of a tree.  The root
CA issues key signatures binding keys to ID's.  However usually these
are not the ID's of end users, but rather of other lower-level CA's
who will be associated with some smaller domain.  These may sign yet
other CA's keys, until the whole world is partitioned into small
enough pieces that the lowest level CA's actually sign user keys.
This is often mapped onto a corporate model where a company has a
master CA key which gets signed by the root CA (or perhaps by a lower
level CA between the root and corporate level), and which then,
depending on the company size, may directly sign the keys of
employees, or at the other extreme will sign keys for a division,
which will sign them for a department, which will sign them for a
group, which will then sign the employee's keys.  Similar structures
can be used for educational institutions as well.
The idea behind this is that at each level only a relatively small
number of keys are needed, and the signatures are on entities closely
related to the key doing the signing.  So the key signer is in a
position to verify the accuracy of the signatures he is making.
PGP uses a completely different system which Phil Zimmermann calls the
"web of trust".  It also uses the idea of key signatures, but there is
no hierarchy.  Instead, each person individually decides which other
signers he will trust.  A key which has a signature from a trusted
signer is accepted as validated.  PGP also allows people to specify
other signers as partially trusted.  A key will be accepted if it has
multiple signatures by partially trusted signers.
It is important to eliminate a common misconception about the web of
trust.  Suppose Alice signs Bob's key, and Bob signs Clara's, and
Clara signs Don's key.  Suppose further that Alice trusts Bob and Bob
trusts Clara as key signers, but that Alice doesn't know Clara.  In
terms of PGP's web of trust, this does not give a chain from Alice to
Don which lets her trust his key.  Alice has to have a signature on
Don's key by someone she trusts.  In this case, since she doesn't know
Clara she presumably can't trust her, and hence Clara's signature on
Don's key is worthless to Alice.
I had many discussions with Phil during the time when he was
developing this concept, and he was adamant about the importance of
this point.  The phrase he used was "trust is not transitive".
Transitivity is a mathematical property where if A has some relation
to B, and B has the same relation to C, then A has that relation to C.
For example, "greater than" is transitive with respect to numbers.
But trust in general cannot be considered to be transitive in this
sense, as Phil saw it.  Asking Alice to trust Bob to sign keys is one
thing.  But asking her to trust everyone that Bob trusts as a key
signer is something else.  That requires a lot more insight into the
mind of the other person, to judge not only whether he is careful
about his key signatures, but whether he is careful about judging how
careful other people are about key signatures.
The situation reminds me of a maxim of multi-level marketing (MLM)
companies like Amway.  These businesses typically sell a product, but
they use a pyramid scheme for distribution where people not only sell
the product, but try to recruit others to sell for them.  Each person
not only gets profit for the sales he makes, but he gets a share of
the profit for sales made by the people he recruited, and a further
smaller share of the profits from the people they recruit, and so on.
If he gets a large enough "downline" of people selling below him then
he can actually retire and just live off the profits they are
producing.  At least, that is part of the sales pitch for these
To achieve success, though, the saying goes like this: You not only
have to sell; you not only have to teach your people to sell; but you
have to teach your people to teach people to sell.  Only once you have
developed this skill do you have a chance of having really big success
in MLM.  The idea is that being a good salesman is not enough.  You
have to recruit people and teach them to be good sellers, but that is
not enough either.  You also have to take your recruits and teach them
not only to be good sellers, but also teach them how to pass this
knowledge on down the line so that the whole downline thrives.
(It does seem strange that the saying stops where it does.  Don't you
also have to teach your people to teach people to teach people to
sell, etc.?  I think though the human mind starts to lose track of
what these increasingly abstract goals would mean.  Stopping where
they do conveys the idea that the teaching must be carried on
indefinately at each level.)
The analogy to transitivity of trust is this.  If you want to have
transitive trust, you have to be sure the other person knows how to
securely sign keys.  But you also have to make sure he knows how to
make sure that the next person knows how to securely sign keys.  And
further you have to make sure he knows how to make sure the next guy
knows how to make sure, and so on.
Note too that the hierarchical structure of the MLM is similar to that
used in traditional hierarchical key CA's.  So this points out one of
the big problems with these systems, which is the requirement to have
transitive trust.  Just trusting the root CA is not enough.  You have
to trust that it makes sure that all the CA's whose keys it signs will
be careful, as well.  And further it has to make sure that each
lower-level CA will pass on the need for care to all the CA's below
At the time this concept was created, several years ago, users of the
net largely consisted of students and employees of national labs and
large corporations.  The hierarchical idea mapped pretty well into the
large bureaucracies which ran these places.  But today things are
different.  It's hard to see how a hierarchy would work for the
subscribers to AOL or MSN.
So instead one idea is to flatten the hierarchy.  Instead of a CA
giving out perhaps a few dozen key signatures, it might give out
hundreds of thousands.  Obviously this is a totally different concept
in terms of the checking possible and the security of the resulting
signatures.  At least there is less delegation and transfers of trust.
But the logistical problems can be very large.
PGP takes care to avoid transitive trust.  When you mark various key
signers as trusted, it is very careful to strip out that information
when you extract a key for sending to someone else.  Phil had another
reason for this beyond the general difficulties mentioned above.  The
basic problem is the social implication of trusting or not trusting
another person as a key signer.  Revealing that information could
cause difficulties.  People might be offended to learn that someone
else doesn't trust them.  Worse, people might feel pressure to trust
someone else if this were public knowledge.  Maybe the other person is
in a position of power where publically offering trust would be
valuable.  These kinds of social interactions could ruin the meaning
of the trust markings.  So PGP doesn't allow it at all.
However the problem is then that with PGP it is hard to find someone
you trust who can reliably sign the keys of people you want to
communicate with.  In a small group with many social interactions it
can work OK, but if you see a random posting by someone who sounds
interesting, the chances that you know someone who has signed his key
are very small.  So I don't think that the web of trust in practice
works very well, at least for a lot of the communication that people
Unfortunately we are left with a choice between three not very good
possibilities: accept transitive trust and hierarchical key CA
structures; use very flat hierarchies where one signer validates huge
numbers of keys; or accept that only a small number of keys can be
validated by key signatures.  I think all these are troublesome and in
fact it makes me question the whole notion of key signatures.
Hal Finney

@_date: 1996-05-15 17:00:21
@_author: Hal 
@_subject: Why does the state still stand: 
James Donald writes a very interesting essay but I want to clarify one
aspect.  Let me quote just the summary:
I think the intention then is to create "fully anonymous" companies.
These would be organizations whose principals and employees are known
only by pseudonyms, even to each other.  Their only contact is
electronic, via an anonymous network.  And the employees are paid in
anonymous ecash, which they don't pay taxes on since it is unreported
These companies produce products or services which they offer for sale
across the net.  They accept payment in ecash, either from end users or
from other companies.
Such companies would be illegal, with everyone involved subject to
criminal penalties for tax evasion (and no doubt a myriad of other
violations).  But because the anonymity is protected cryptographically,
the government is helpless to learn the true identities of anyone
involved.  The companies continue to successfully sell their products
and services, advertising and recruiting openly from anonymous sources,
and there is nothing the government can do about it.
This is, I think, the model we have been talking about for several
years on this list.  There are obvious and non-obvious problems which
many people have brought up over the years.  It is still not clear to
me that it can really work in this form.  Still it will be interesting
to see when someone actually tries to do this, to see how it works.
James mentioned the issue of groupware to allow these people to
coordinate their efforts.  That is an interesting aspect that we haven't
considered much.  One trend which may be relevant is the increase in
telecommuting.  Once people are accustomed to working mostly from home,
interacting with co-workers and management by email, they would be good
candidates for recruitment by the anonymous firm.
It might be interesting to make a list of all the problems people can
think of why this idea won't work, paired with proposed solutions and
workarounds - sort of a mini FAQ for this important (some might say
ultimate) cypherpunk model.

@_date: 1996-05-16 11:41:45
@_author: Hal 
@_subject: SEVERE undercapacity, we need more remailer servers FAST 
The problem that I think the Scientology postings raise is that the
remailers cannot really be used to post copyrighted material.  That is
what got the netherlands hacktic remailer shut down.  This shows, BTW,
that being outside the United States is no guarantee of immunity.  Most
Western countries support copyrights.
Maybe the operators can try to plead that they are like "common carriers"
and should not be blamed for what people post.  Still it is going to take
deep pockets at best to prevail in this dispute, and it isn't even clear
that the remailer will win.  Maybe the lawyers on the list could comment
on legal liability of a remailer used to repeatedly post copyrighted
material, whether Scientology scriptures or Microsoft Word binaries.  I
don't see how it can happen.
(This ties in, BTW, with my posting yesterday about problems with the
"anonymous company" concept.  It is not clear that any of the
technologies we have discussed will allow continuous, long-term and
reliable broadcasting of illegal material.)
Presently all the remailers operate for free, which makes it even harder
to justify taking the chance of facing an expensive lawsuit.  On the
other hand, at least if no commercial gain is involved the operator might
escape some forms of damages if he loses.  A for-pay remailer which is
posting copyrighted material could be in even more trouble, it seems to
me.  Again, legal opinions would be welcome.
This was the basis for my suggestion that remailers may have to stop
supporting posting of messages, and instead be used for private mail
between consenting individuals.  Granted, this would probably eliminate
99% of non-cover remailer traffic.  But I would argue that as long as the
core functionality is there of letting people communicate with each other
anonymously and consensually, we would still offer an important service.
After all, what is the purpose of anonymous remailers?  It isn't really
to allow harrassing and abusive messages to be sent to one's enemies.
And it isn't to defeat intellectual property laws by proving that no one
can stop this material from being posted (remailers can't succeed in
doing this, as I said above).  Rather, I view remailers as a natural
extension of encryption.
Encryption hides the contents of the messages you send from
eavesdroppers.  But they can still see who you are communicating with.
Remailers extend privacy protection beyond "what you say" to "who you say
it to".  When used with pseudonym servers and some of the extensions we
have discussed here over the years (maildrops, etc.), they can allow the
anonymous two-way communication that is needed for real privacy.
This has nothing to do with tweaking Microsoft or Scientology by posting
information they own.  If people want to do that, they need to find
another method.  Maybe they can get usenet shut down if they try hard
enough.  I don't know how that battle is going to come out.  But I don't
see the remailers as playing an important role there.

@_date: 1996-05-18 18:02:04
@_author: Hal 
@_subject: Why does the state still stand: 
Thanks very much for making this list.  However I would not be so quick
to reject   It is run by long-time Cypherpunk
Vince Cate, apparently specifically for the kinds of purposes we are
discussing.  His project was discussed in a recent issue of Wired, I
think the May issue.  (I have no contact with Cate, and have never met
him as far as I can recall.)
For doing something like running a remailer which will post material
which is illegal and/or copyrighted in the U.S., you are going to need a
service which can stand up to pressure.  Presumably some monetary
incentive is going to be a necessity.  Of course by this standard $25 a
month is pretty inconsequential.
One issue is whether these banking-secrecy countries like Anguilla are
followers of the Berne convention or other international copyright
regulations.  Banking secrecy and software piracy don't necessarily go
hand in hand.  I hear a lot about copyright violations in China but not
in the Caribbean.  So actually it isn't clear that this country is the
right location for a remailer that can post arbitrary material.
As for the costs to the remailer operator, he simply passes those on to
his customers.  I think in the long run onshore remailers will be forced
to take measures to restrict copyright-violating posts.  So if your
choice is between paying nothing and not getting your whistle-blowing
message posted, or paying $10 and getting it out on the nets, then
hopefully it is worth that much to you.
We have discussed for-pay remailers and the consensus has been that no
one would use them when others run for free.  However now I think the
false premise is being exposed, that free remailers simply will not be
able to run in the current mode for much longer.  Once a single remailer
operator has been fined thousands of dollars because somebody posted some
copyrighted message, I don't think you will find many people eager to
sign up as operators.  So this dream of a volatile collection of
remailers popping up and going away just doesn't work in my view.  Why
would anyone offer a service knowing that he was exposing himself to
liability like this?  It would be just a game of Russian roulette,
waiting to see whether it is your remailer which gets the bullet in the
form of a post which violates the copyright of someone with deep

@_date: 1996-05-21 15:04:37
@_author: Hal 
@_subject: An alternative to remailer shutdowns 
Several remailers have shut down recently.  This may be in part a
byproduct of the ongoing struggle between dissidents and adherents of
the Church of Scientology.  Also, levels of abuse seem to be increasing
in general as more people come on the net and learn to use the
remailers.  Since by their very nature remailers prevent
accountability, there is nothing to stop one or more persons from
sending illegal material which will cause the remailers to be
threatened by legal actions.
I was contacted by the FBI on Friday due to some threatening mail which
was apparently sent through my remailer.  According to 18 USC 875(c),
"Whoever transmits in interstate commerce any communication containing
any threat to kidnap any person or any threat to injure the person of
another, shall be fined not more than $1,000 or imprisoned not more
than five years, or both."  I may not be able to continue operating
either of my remailers (alumni.caltech.edu and shell.portal.com) for
much longer due to this kind of abuse.
Shutting down remailers not only reduces the number available for general
use, it also causes problems for people who are using the remailers to
manage pseudonyms.  If their reply chains used a remailer which shuts
down they have to reconstruct the chains, which is at least a nuisance.
There was also a posting recently to comp.org.eff.talk by Jonathon Cline,
jcline at trumpet.aix.calpoly.edu, about efforts to set up fully anonymous
nym based mailing lists.  He mentioned that the decrease in the number of
remailers is causing problems with their plans.
An alternative I am considering would reduce the utility of the remailer
while still allowing these "consensual" uses to continue.  Presently the
remailers deal with abuse via "block lists", sets of addresses that mail
can't be sent to.  Generally these are created when someone complains
about some mail they have received.  By setting up blocking, at least
they will not get harrassing anonymous mail once they have complained.
But in some cases, as in the case that is causing me headaches now, even
one message is too much.
My thought is to turn the block list concept on its head, and make it a
"permit list".  Simply, the remailer will only send mail to people who
have voluntarily indicated their willingness to receive it.  Someone who
has not sent in a message granting this permission will not be sent
mail.  For larger forums such as newsgroups and mailing lists, permission
may be granted by some consensus mechanism.  Most would be blocked, but a
few like alt.anonymous.messages and the cypherpunks list would be
permitted, and others could be added if they wished.
This should hopefully essentially eliminate complaints about abuse,
much more effectively than the current method of block lists.  People
who want to test the remailer by sending mail to themselves, as most
people do when they are learning, can simply register themselves on the
permit list.  People who want to receive anonymous mail, or participate
in anonymous mailing lists, can register themselves.  People who want
to use nyms can register themselves.  People who run other remailers
can register.  It's all voluntary, and if someone does get some
objectionable message at least they will know that they granted
permission.  They can always ask to be taken off the list.
Feedback welcome -
Hal Finney

@_date: 1996-05-21 18:51:38
@_author: Hal 
@_subject: An alternative to remailer shutdowns (fwd) 
I think Jim is right about the knowledge requirement, which although not
stated explicitly in the statute, has been held by the courts to be an
essential element.  My point in quoting is more to show an example of the
kinds of clearly illegal postings which operators have to deal with.

@_date: 1996-05-25 13:55:00
@_author: Hal 
@_subject: Children's Privacy Act 
I think the reason (some) cypherpunks support things like offshore data
havens isn't that they think it's great to reduce the amount of privacy
people have.  Why would they support crypto and such if that were their
motivation?  The real reason is because we expect that such databases are
going to come into existence regardless of legal efforts.  They may be
"underground", or for that matter they may be run by governments
themselves, whom we are supposed to trust with our secrets.
The point is that the best countermeasure is to prevent the collection of
the data in the first place.  Ecash is better than credit cards for this
reason.  People should try to structure their lives so that as little
information is leaked about them as possible.  Relying on laws forbidding
people to keep information they have run across isn't likely to be
Now maybe the laws, while not perfect, can still at least reduce the
amount of this dataveillance.  The problem is, this is likely to lead
to a false sense of security, where people don't bother to protect
their own privacy because big brother is doing it for them.  We would
rather have these real privacy threats be right out in the open where
people can see them.
In a way, our position is like those revolutionaries who are convinced
the government is evil, while the populace mindlessly goes along with
the status quo.  Terrorists inflict terror largely to force the
government to crack down, raising popular awareness of its oppressive
nature, and fostering revolutionary feelings.
This is not the cypherpunk goal (as I see it) but still we share the
same sense of seeing trouble that most people aren't aware of.
Supporting offshore data havens, while harmful to privacy in the short
term, might at least awaken people to the problem.  If that leads to
greater awareness of the need to directly control the release of
information about themselves, then in the long run it will be good.

@_date: 1996-05-29 11:54:37
@_author: Hal 
@_subject: Remailer chain length? 
Or better still, run one remailer on the machine, and use it multiple
times in the chain.  It seems to me that one remailer on a machine is
better than several because it will allow more mixing of messages.  If
two messages enter a machine and later leave, it may be possible to
distinguish them if they went to different remailers and left with
different From: addresses (or other header fields as a result.  If they)
had both gone to the same remailer it would be harder to tell them
I understand that there may be political reasons to have the machine
owner and remailer operator be separate (although AFAIK the reasoning
behind this is untested), but technically it seems better to have one
remailer per machine based on traffic analysis issues.

@_date: 1996-05-31 15:24:01
@_author: Hal 
@_subject: NRC Cryptography Report: The Text of the Recommendations 
I read the overview of this, and while it is good that the report calls
for maintaining the legality of domestic encryption and some slight
loosening of the export rules, overall I was diappointed.
First, the report reads as though the intended audience is law
enforcement and security personnel.  The perspective seems to generally
be from the points of view of those bodies.  This is just a subjective
impression I have and it would be interesting to hear whether other
people feel the same.
Second, although they go to some lengths to emphasize the importance of
an open, unclassified process, and that the report itself is completely
unclassified, there are some curios omissions.  For example,
recommendation 4.1 is that 56-bit DES encryption should be exportable.
However, they follow that by saying, "Products covered under
Recommendation 4.1 must be designed in a way that would preclude their
repeated use to increase confidentiality beyond the acceptable level."
This is then followed with a couple of pages of justification for why
this relaxation of the export policies should be allowed.  Much is made
of the fact that people will be more likely to use 56 bit encryption than
the 40 bit which is currently allowed.  (This is an example of the
perspective issue I mentioned above.)  However, nowhere is it stated why
more than 56 bits is not OK, and why it is necessary to forbid repeated
use to increase confidentiality.  There is not one word of discussion of
this proviso.
I suspect the reason is that the NSA can break 56 bit DES but cannot
break higher levels.  But the report doesn't say so.  Presumably this is
because that fact is classfied.  Okay, but it seems hypocritical to make
much of the fact that the discussion is open, and then to limit the
recommendations by considerations which can't be discussed openly.
I also think it is sneaky that they bury this limitation in text which
will not be seen by people who read only the recommendations.
Third, although in broad terms the report is supportive of the use of
cryptography, the specific recommendations do very little to liberalize
current policies.  Free domestic access to cryptography is already the
law.  Raising the export size limit from 40 to 56 bits is a step
forward, but a small one.  Beyond 56 bits they recommend the
requirement of escrowed encryption.  Given current moves to standardize
on triple DES, this is a retrenching action.  They recommend
criminalizing the use of cryptography in committing crimes, admitting
that this may be used in some cases (as comparable mail fraud statues
have been) to bring prosecutions against people who cannot be proven to
have committed any other crime.  "[T]he committee understands that it
is largely the integrity of the judicial and criminal justice process
that will be the ultimate check on preventing its use for such
Fourth, recommendation 5.2, to promote the use of link encryption for
cellular phones, is designed to reduce privacy, not help it.
"Recommendation 5.2 is an instance of a general philosophy that link (or
node) security provided by a service provider offers more opportunities
for providing law enforcement with legally authorized access than does
security provided by the end user."  When I wrote my letter to the NRC
during their comment period (available at ) I made a similar point,
but with the opposite conclusion, that end to end encryption would be
Overall, I am disappointed that the report seems to adopt so much of the
point of view of those forces which will oppose the use of cryptography.
At best it seems to be a recognition that change is inevitable, and that
the most that can be hoped for is to ease the transition to a world where
people have free access to privacy tools.  But in the meantime it appears
designed to delay the transition rather than advance it.

@_date: 1996-09-25 07:04:05
@_author: Hal 
@_subject: Portal remailer shutting down 
The ISP which I have used for over five years, portal.com, is going
out of business at the end of this month (September, 1996).  This means
that my remailer at hfinney at shell.portal.com will cease operations.
I had asked that it be removed from the remailer lists a few weeks ago
due to some problems, so hopefully not many people have been using it
lately.  But now it will go away for good.
This remailer has been in operation since the fall of 1991.  I believe it
has been the longest continually running remailer on the net.  It was one
of the first "cypherpunk" remailers, based on Eric Hughes' code, to which
I added support for PGP messages.  (Actually there was a remailer running
out of Australia for a short time earlier in 1991 which was the first to
use PGP.  It was a very nice system but got shut down supposedly due to
traffic concerns, although there seemed to be some politics involved as
I have also been running a remailer from my account at
hal at alumni.caltech.edu.  However that one cannot tolerate abuse
complaints, hence I have been forwarding all mail out of that remailer
through the portal one, for a number of years.   Now that Portal is gone,
this will be a problem.  I plan to restrict the alumni remailer to only
send mail to other addresses on a fixed list, which will initially be
just the other remailers.  That way the remailer can be used to form
chains, but not to send to end users.  This limited functionality should
still be useful.
It may be possible to create a web page where people can sign up to say
they would not object to receiving anonymous mail.  Most people are
open minded and curious enough that they wouldn't mind signing such a
list.  Make it easy enough and you will collect thousands of names.  Now
people who want to create nyms using remailer chains for return addresses
can add their names to the list without feeling that they are
compromising their identity.  They can use a remailer which only sends to
people on the list as the last remailer in their chain, with some
confidence that the remailer is unlikely to be shut down due to abuse
