
@_date: 1993-12-04 16:09:33
@_author: Jim Miller 
@_subject: Pablo and NSA 
Hopefully this is a joke.  However, it does bring up a point.  The NSA can  put fear into people's minds by simply *claiming* the ability to  compromise PGP.  They don't have to really be able to.  Just start a  rumor, sit back, and watch what happens.
Jim_Miller at suite.com

@_date: 1993-12-04 16:44:34
@_author: Jim Miller 
@_subject: Speaking of hard disk encryption... 
Anyone out there have any experience with SafeBoot(tm) from SmartDisk  Security Corporation?
Here's what you get in the mail when you call them for info:
[disclaimer:  I am not accociated with SmartDisk Security Corporation]
Jim_Miller at suite.com

@_date: 1993-12-07 15:33:35
@_author: Jim Miller 
@_subject: ANNOUNCEMENT: DPSWG Crypto-Policy Statement to White House 
^^^^^^^^^^ ??
Why only "mass market" encryption?
The company I work for is developing a collection of runtime libraries and  utilities which software developers can use to create and manage portable  object-oriented distributed applications.  Think of it as a  object-oriented DCE-like tool set with a run-time environment and system  administration utilites.
Our customers are primarily large corporations, although it would be  useful to small shops, too.  We have communication software that can  perform encryption of user data, but the current export laws prevent us  from placing this capability in versions for our foreign customers.     We have to maintain two distinct versions of our product: a  domestic version and and foreign version.
Since we target other software developers, I don't believe our product  qualifies as "mass market" software.  At least, this is my interpretation  of the definition of "as is" in the Cantwell bill:
Although we don't make custom versions of our software for specific  customers, our software, due to its nature, is highly customizable by the  purchaser.  Neither the Cantwell bill, nor the DPSWG letter mentions this  type of software product.
As I see it, the main distinction between "mass market" software and our  software is that our software is used to create other software, whereas  "mass market" software implies final product "end-user" software.
My question to the DPSWG (and US Rep. Maria Cantwell, if I could e-mail  her) is:
Why only "mass market" software?
Or put another way:
Does the DPSWG want the government to keep export controls in place for  the type of product our company is developing?
Jim_Miller at suite.com

@_date: 1993-12-13 14:00:10
@_author: Jim Miller 
@_subject: Cypherpunks-related Cartoons 
Great idea!   I'll keep an eye out.
I have a "Calvin and Hobbes" taped to the wall next to my workstation that  is perhaps remotely related to things Cypherpunk.    It is more closely  related to technology in general.  Anyways, it goes something like this...
[Calvin and Hobbes are walking through the woods]
"You know, Hobbes, it seems the only time most people go outside is to  walk to their cars.
"We have houses, electricity, plumbing, heat...Maybe we're so sheltered  and comfortable that we've lost touch with the natural world and forgotten  our place in it.  Maybe we've lost our awe of nature.
"That's why I want to ask you, as a tiger, a wild animal close to nature,  what you think we're put on earth to do.  What's our purpose in life?  Why  are we here?"
Hobbes:  [contemplates]
"We're here to devour each other alive."
Calvin:  [stunned/blank look on his face, runs into his house]
"Turn on the lights!  Turn up the heat!"
Jim_Miller at suite.com

@_date: 1993-12-13 15:15:03
@_author: jim@bilbo.suite.com 
@_subject: Cypherpunks-related Cartoons 
Here are a couple of software-related cartoons.  They don't directly  relate to things Cypherpunk, but Cypherpunks may still find them humorous.
The origin of the first one is lost in the mist of time.  My copy is a  n-th generation photocopy of a photocopy.  It goes like this:
A woman and two children are standing beside a fresh grave site.  It is  pouring rain and they are huddled under an umbrella.  A man standing next  to them asks..."I know this may be an awkward time, but do you recall him  ever mentioning source code?"
The second cartoon is by Scott Adams and is dated 9-8-1992.  It was  distributed by United Feature Syndicate, Inc.  I don't remember were I got  my copy.  It goes like this:
[Three older-looking geeky engineer types are sitting at a table,  presumably taking their lunch break.]
Geek    When I started programming, we didn't have any of these sissy  "Icons" and "Windows".  All we had were zeros and ones -- and sometimes we  didn't even have ones.  I wrote an entire database program using only  Geek     You had zeros?  We had to use the letter "O".
Jim_Miller at suite.com

@_date: 1993-12-14 17:00:29
@_author: Jim Miller 
@_subject: anonymous video rental store 
I couldn't sleep last night and, as is often the case, my brain gets a  mind of its own and starts thinking irrelevant thoughts.  The irrelevant  thought that occupied my brain's mind last night was "anonymous video  rental store - Is it possible?"
Ignoring for the moment the "fact" that video rental stores will some day  go the way of the dinosaurs, would it be possible to structure a video  rental store with the following properties:
1) The store could not track which customers rented which tapes.
2) The store *could* tell which tapes get rented and which tapes do not  get rented.  The store would adjust it's selection of tapes based in this  information. (get more of the popular tapes, remove the unpopular ones)
3) The store could some how penalize customers that returned tapes late,  or not at all.  The nature of the "penalty" is flexible.  This implies  that the store could somehow verify that the tape a customer returned is  the same tape the customer rented, but without discovering which tape it  is.  (I believe this is the hard part)
I have a partial solution.  Here it is:
The store is arranged like a Blockbuster video store in that there are a  bunch of shelves with videos on them.  For each video, there is a box  describing the video and a variable number of tapes co-located with the  box.  In a Blockbuster video store, the tapes are in plastic cases that  identify the video on the tape. In the AVRS (Anon Video Rental Store), the  plastic cases would not contain any identification.  However, the tapes  themselves *would* contain some kind of identification (stickers with  video name and bar code, for example)
When a customer enters the AVRS, it (the customer) grabs a random handful  of tokens from an "available" bin.  These tokens each contain a unique  identifier.  The customer walks around the store searching for videos.   When the customer finds a video, it takes one of the plastic cases  (opening it to verify it really is the movie it wants).  The customer  inserts one of the tokens into a pocket that exists on the outside of the  plastic case.  The pocket is transparent and the token's identification  number can be seen.
The customer selects the videos it wants, inserting tokens into pockets.   When the customer is done, it returns the unused tokens to the "available"  bin and proceeds to the check-out counter.
The customer hands the clerk an AVRS id card.  The AVRS id card contains  information about the customer (TBD).  The clerk at the checkout counter  scans the id card and the tokens that were placed in plastic case pockets.   AVRS id card has rented N tapes on a given day.  (Actually, all the clerk  *really* knows is that the customer has rented N tokens.)  The clerk  collects some money, the customer leaves with the plastic cases, tapes,  and tokens.
The customer returns to the store a couple of days later.  The customer  removes the tokens from the case pockets.  The customer places the plastic  cases (with tape inside) in a "tape return" bin and places the tokens in a  "token return" bin, and then leaves.
Periodically throughout the day, a clerk examines the tapes in the "tape  return" bin.  The clerk opens each case and scans the bar code on the  tape.  This way the AVRS can track which tapes get rented and which tapes  do not get rented.  The clerk returns the plastic cases (with tapes) to  the shelves.
At the end of the day, a clerk collects the tokens from the "token return"  bin and scans them.  The computer marks the tokens as returned and clears  the appropriate customer record.  The clerk places the tokens in the  "available" bin.
The most obvious problem with this scheme is that the store has no way of  knowing if the tape the customer returned is the same tape the customer  rented.  A customer could return a blank tape without getting caught.
(A less obvious problem with the scheme is that the store could use  surveillance cameras to identify which tapes the customer selected, but I  chose to ignore that problem.)
The problem to solve, then is: how can the store catch dishonest  customers, yet be unable to track which customer rented which video?
There needs to be an additional step at the time a customer returns a  tape.  The store needs to be able verify that the tape a customer is  returning is a tape that was rented from that store and is not overdue.   The store doesn't need to know what tape it is, or who is returning it,  just that it came from that store and is not overdue.  If the tape *is*  overdue, then the customer must personally return the tape to a clerk and  pay a fine. (and risk a bit of anonymity)
Perhaps we could embed some electronics in the tape cassette (or sticker)  that would enable a clerk to store a signed "due-back" timestamp on the  cassette without being able to store any information that would identify  the tape.  The signed timestamp would have to be transferred through the  plastic case, since opening the case would reveal the tape inside.  Sounds  sort of like a blind signature.
Needless to say, it should be difficult for the customer to tamper with  the information on the cassette.
Any comments or better ideas?
Jim_Miller at suite.com

@_date: 1993-12-15 14:03:54
@_author: Jim Miller 
@_subject: anonymous video rental store 
I'm not convinced a simple anonymous customer/buy-back(or deposit)  mechanism is the ideal solution.  First, the clerk sees what videos you  rent and might be able to identify you from a picture.  Second, if the  store issues ID cards, then the store can track which videos are rented by  each ID.  Although the store doesn't know for your real identity, it  wouldn't be to hard to find it out in many cases.  The clerk coud look out  the store window and get the license number of your car.
You could avoid some of these problems if the store didn't issue permanent  ID cards, but instead issued one-time ID cards.  You would get a new ID  card everytime you rented some videos.  This would make it impractical for  the store to automatically track your rentals.
This doesn't eliminate the posibility of a clerk remebering your face and  pairing it up with a specific rental, or a rental pattern.
"Oh yeah, I remember that guy. he usually comes in late Friday night, just  before closing.  He always rents children's videos.  Is he some kind of  Jim_Miller at suite.com

@_date: 1993-12-24 13:56:26
@_author: Jim Miller 
@_subject: pseudoparanoia and poison 
On the Internet, everyone knows you're Detweiler...

@_date: 1993-12-30 22:30:44
@_author: Jim Miller 
@_subject: anonymous "video on demand" 
Does anyone know of a good, practical way of doing "video on demand" in  such a way that the video supplier can't track the videos you select?
I suppose the trivial solution would be to send your video selection  request (and service fee) through a "anonymous video remailer".  The video  supplier would send the encrypted video back to you via the remailer.
Since I don't see "anonymous video remailers" as being a practical  solution in the near future, I'm more interested in finding out if there  are other ways of solving this problem.
This sounds like an All-Or-Nothing Disclosure Of Secrets problem.   However, all I know about ANDOS is what I read in "Applied Cryptography",  and the algorithm it describes doesn't seem a good fit.
Are there other ANDOS algorithms that may work better?
Jim_Miller at suite.com

@_date: 1993-12-31 15:03:38
@_author: Jim Miller 
@_subject: Anonymous Video on Demand 
Electronic distribution.
"Anonymous video on demand" is a bit misleading, because I'm not so much  interested in preventing the video provider from knowing my identity, just  from correlating my identity with my video selections.
My feeling is that this architecture is too inflexible.
Here's the sort of thing I have in mind:
Customer browses the video supplier's catalog and notes the catalog number  of the video it wants
Customer randomly chooses 99 other catalog numbers to generate a pool of  100 catalog numbers.
The Customer and the Video Provider engage in a protocol so that the  Customer ends up receiving 100 compressed and encrypted videos, only one  of which the Customer can successfully decrypt (and uncompress).
The Video Provider never learns which of the 100 videos the Customer  successfully decrypts, but is sure that the Customer can decrypt only one
of them.
I don't know what the protocol would be, but it sounds like an ANDOS-like  By the way, I think that if the "rental" fee is low enough, the Video  Provider wont have to worry about cheaters.  If it costs you more money  (or time) to cheat the Video Provider than it does to simply pay the fee,  then most people will pay the fee.  I'm thinking the fee would be as small  as 25 cents/video, for example.
Jim_Miller at suite.com

@_date: 1993-12-31 16:58:36
@_author: Jim Miller 
@_subject: Anonymous Video on Demand 
As I think about it more, the "anonymous video on demand" problem can be  solved with an oblivious transfer protocol.
Here's how I see it working:
(The following is adapted from the oblivious transfer protocol described  in "Applied Cryptography" on page 98.)
Say Alice is the Video Vendor and Bob is the customer...
Alice generates a public/private key pair for each movie in her video  database and publishes the public keys in an electronic catalog.  Each  public key would be paired with a movie description and a catalog index  Bob downloads Alice's catalog and browses through it offline.  Bob makes a  selection, and also randomly picks 99 (or any large number) other catalog  Bob generates a random DES key and encrypts this key with the public key  associated with his selection.
Bob sends the encrypted DES key and the list of 100 catalog numbers to  Alice decrypts the DES key with the private key associated each catalog  number received from Bob.  In only one case will Alice successfully  recover Bob's DES key, only she doesn't know which case.
Alice encrypts each movie selection with the resulting DES keys from the  previous step and sends all 100 encrypted movies to Bob.
Bob will only be able to decrypt and view the movie he selected and Alice  wont know which of the 100 movies Bob selected.
Ta Da!
The nice thing about this protocol is that it doesn't really have anything  to do with videos.  It could be used for an electronic library, or any  warehouse of digital information where the Vendor wishes to charge for a  download, yet the Customer doesn't want the Vendor to know which item is  Also, the Vendor still can use statistical analysis to determine which  items are more popular and which items are less popular.  The Vendor could  keep track of how many times an item was mentioned in a Customer selection  list.  The more popular items would appear in more lists.  Unpopular items  would have different statistics.  This analysis breaks down if all items  are equally popular, or Customers don't chose the other 99 items randomly.
Jim_Miller at suite.com

@_date: 1993-11-03 12:47:26
@_author: Jim Miller 
@_subject: WARNING: direct-marketing email address list 
I receive an unsolicited e-mail from these people just the other day.  It said  something to effect of
"I have heard that you may be interested in implementing UNIX/Mac/PC  software...I have a database of contact addresses that may interest you...I am  NOT selling anything...If I have mis-read your intentions, I apologize.   However, could you forward this letter to someone would may be interested."
I deleted it.
Jim_Miller at suite.com

@_date: 1993-11-03 13:32:21
@_author: Jim Miller 
@_subject: WARNING: direct-marketing email address list 
Their address is the one mentioned in Stanton McCandlish's "WARNING:  direct-marketing email address list" post:   jim_mcbride at netmail.com
Jim_Miller at suite.com

@_date: 1993-11-03 19:12:21
@_author: Jim Miller 
@_subject: message depots 
The mailing list has been pretty quite today.  How about a new(?) idea to kick  One of the main unsolved problems with anonymous remailer networks is that,  somewhere, there has to be a remailer that knows the mapping from your  anonymous identity to your real identity (or at least your real e-mail  address).  This means that you will have to trust the person running the  It seems to me that as long as remailers use a message *delivery* paradigm,  this problem is unsolvable.  However, there is another paradigm that can be  used which can solve this problem.  I call it the "message depot" paradigm.
It wastes a lot of bandwidth and cpu cycles.  However, I believe that in the  not too distant future we'll have more bandwidth than we know what to do with  (Telecosm).  Perhaps someday we'll also have more cpu cycles than we'll know  what to do with (cray on a chip).  When that day arrives, this idea will become  practical.  Until then, it will probably just be a toy.  Still...
Here how I see it working...
Simplest case:  One message depot
Not too different from a message-only BBS where all messages are encrypted.
If Bob wants to send a secure message to Alice and defeat traffic analysis, he  will encrypt the message with Alice's public key and send it to the message  depot.  Alice (and everyone else) periodically grabs *all* new messages from  the message depot and attempts to decrypt them.  Alice finds that she can  decrypt one of them; the one from Bob.  If Bob signed the message before  encrypting it, and Alice has Bob's public key, she can verify the signature.   Of course, this doesn't means she knows who "Bob" is, just that "Bob" sent the  message.  Replace "Bob" with you favorite 'nym.
Since everybody is periodically downloading all new messages, the message depot    doesn't know which message goes to which person.  Also, since the only clue to  the sender's identity is the message signature, the message recipient may not  know the identity of the sender.  (It would depend on how the recipient got the  sender's public key.)
Scaling Up a Step:  Multiple message depots
Place a dozen message depots in the picture.  They each publish a unique public  key, which means that people can send encrypted messages to the depots as end  points.  The depots would poll each other for new messages to see if there is a  message encrypted with their public keys.
Example: Depot A polls depot B for new messages.  Depot A attempts to decrypt  the new messages.  It finds one that it can decrypt.  Upon decrypting the  message, the depot sees a depot command and more message.  The one and only  depot command will be: "PUT THE REMAINDER OF THE MESSAGE IN YOUR MESSAGE POOL  AS A NEW MESSAGE".  Any message the depot cannot decrypt will be discarded.
How is this useful?  Well, by nesting a message in layers of digital envelopes,  a sender can effectively move the message around the set of message depots  until it reaches a depot that the final recipient polls.
Lets say that Bob knows that Alice polls Depot E, yet, for some reason, Bob  doesn't want to send the message directly to Depot E.  What does he do?  He  first signs the message with his private key (if he wants to), then encrypts it  with Alice's public key, appends the depot command and encrypts everything with  Depot E's public key, appends another depot command and encrypts everything  with Depot B's public key.  He then sends the result to Depot B.
Depot B decrypts the message, sees the depot command, strips it off and places  the remainder in its message pool as a new message.  Some time later, Depot E  polls Depot B for new messages.  Depot B obliges.  Depot E attempts to decrypt  the messages, finds that it can decrypt one of them.  It sees the depot  command, strips and posts the remainder of the message to its message pool.   Eventually, Alice polls Depot E for new messages.  And you can guess the rest.
If Bob doesn't know which message depot Alice polls, he can send copies to a  number of different depots and hope that Alice will find it.  If he sent it to  *all* depots, Alice will eventually get the message (unless she stops polling  Messages depots will delete messages after a configurable amount of time.   Also, the depots will not keep track of who has sucked down which set of "new"  messages.  This implies that the people polling the depots will have to tell  the depot they want all messages since a given time.  The client-side polling  software can easily keep track of this for the user.
Interfacing to the rest of the world:
To support sending messages to specific e-mail addresses or news groups,  somebody will have to run a remailer that polls the message depots.  A sender  will encrypt a remailer command and a message using the remailer's public key  and direct it to the depot that the remailer polls.  The remailer will find the  message and interpret the remailer command.  The command could be "SEND THIS TO  ", or "POST THIS TO ", or whatever.
Replies would have to travel back through the depot net.  The body of the  message can indicate a message depot to "reply" to.
I believe most of this message depot idea can be automated.
As you can see, this mechanism consumes lots of bandwidth and lots of cpu.  But  it does not require that you trust any part of the system except the part that  sits in front of you.  I also believe that it successfully defeats traffic  "All the smarts will be at the fringes of the network." Jim_Miller at suite.com

@_date: 1993-11-04 09:57:38
@_author: Jim Miller 
@_subject: message depots 
It seems the message depot idea is not terribly original.  Oh well, I'm not too  surprised.  I suspected this and that's why I put "new(?) idea" in my post.  I  can at least pat my self on the back for reinventing it a few years late. :-)
Jim_Miller at suite.com

@_date: 1993-11-04 15:47:40
@_author: Jim Miller 
@_subject: ViaCrypt PGP has arrived 
My copy of ViaCrypt PGP arrived yesterday (Nov 3).  Since I worked late, I  haven't had a chance to play with it yet.  I looked through the manual.  The  commands look similar (if not identical) to "classic" PGP's, as far as I could  tell at a glance.
The bulk of the text for the manual was taken from the documentation that comes  with PGP, except all occurances of "PGP" where replaced with "ViaCrypt PGP".
The box looks pretty good. :-)  Looks like they hired a real graphics designer.
I suppose some of you are wondering why I'd fork over 100 bucks for something I  could get for free.  First of all, I can afford it.  Second of all, I simply  feel more comfortable using a licensed shinkwrapped software product than a  quasi-legal freeware one.  Call me a coward.
I realize that by not compiling the code myself on my own machine I basically  have to trust the ViaCrypt PGP implementation.  So be it.  If there is  something wrong with ViaCrypt PGP I believe it will eventually be discovered.   Somebody will no doubt disassemble it and look for backdoors.  If someone finds  one, ViaCrypt's reputation will be worthless.  It's in ViaCrypts best interest  not to put in any backdoors.
Jim_"Rebel without a spine"_Miller at suite.com

@_date: 1993-11-06 13:32:45
@_author: Jim Miller 
@_subject: some newbie DC-net questions 
I'm a newcommer to DC-nets, so the following questions may sound funny to  somebody that actually knows DC-nets...
1) What is happening on a DC-net when nobody is sending a message?  Is it  simply issuing a stream of zeros?  Are "coins" being continuously flipped, even  when no messages are being sent?
2) What does it look like (from a traffic flow perspective) when the DC-net  transitions from no messages being sent to a message being sent?  The stream of  zeros becomes and bunch of ones-and-zeros?
3) What happens when two members of a "table" attempt to transmit at the same  time?  How is this case handled?
4) Are there any DC-net papers available for downloading via FTP?
Jim_Miller at suite.com

@_date: 1993-11-08 15:48:26
@_author: Jim Miller 
@_subject: Modem taps/Caller ID 
Practical Peripherals sells a modem that also captures Caller ID info and makes  it available to your comm program.  I've also seen devices that do this for  sale in the back of BBS magazines.
Jim_Miller at suite.com

@_date: 1993-11-09 18:08:45
@_author: Jim Miller 
@_subject: sarcastic quote 
There is much to be said in favor of modern journalism.  By giving us the  opinions of the uneducated, it keeps us in touch with the ignorance of the  Seems an appropriate quote for today.
How do the key escrow agencies confirm that the LEAF presented with a warrant  is from a line that was legally tapped?
Jim_Miller at suite.com

@_date: 1993-11-11 09:39:11
@_author: Jim Miller 
@_subject: cypherplonks mailing list 
A couple of weeks ago someone jokingly proposed creating a parallel mailing  list for flames, rants, and other non-crypto posts.  If that ever happens, I  propose calling it the "cypherplonks" mailing list.
Jim_Miller at suite.com

@_date: 1993-11-11 13:34:12
@_author: Jim Miller 
@_subject: CUD 5.84 
The following was recently posted to sci.crypt.  I would like to get a copy of  the referenced issue of CUD and check out the "DES: Broken!" article.  I looked  in the EFF ftp site, but they only have CUD up to issue 5.76.
Anybody know where I can get CUD 5.84?
Jim_Miller at suite.com
Newsgroups: sci.crypt
Organization: Reed College,  Portland, Oregon
Lines: 29
Thought you might like to know:
Computer underground Digest    Sun  Nov 7 1993   Volume 5 : Issue 84
                           ISSN  1004-042X
       Editors: Jim Thomas and Gordon Meyer (TK0JUT2 at NIU.BITNET)
       Archivist: Brendan Kehoe
       Shadow-Archivists: Dan Carosone / Paul Southworth
                          Ralph Sims / Jyrki Kuoppala
                          Ian Dickinson
    Copy Eatitor: Etaoin Shrdlu, III
CONTENTS,  (Nov 7 1993)
File 1--Computers, Freedom, and Privacy '94 Conference
File 2--CFP '94 Scholarship Announcements
File 3--Korea 94: Call for Papers
File 4--CPSR NII Paper
File 5--DES: Broken! <-----------------------------
File 6--NAFTA mandates software patents (fwd)
File 7--Phiber Optik Sentenced to One Year in Prison
read it.  check it out.
The      _O_ "Darkness may cover me:  midnight may steal along my living veins;
Cannibal  |   yea and the ultimate futility, the ghastly nothing on which all
              things play may break ice-thin crust and freeze my soul"
pwilk at reed.edu   -=public key available on finger=-   - John Cowper Powys

@_date: 1993-11-11 18:34:17
@_author: Jim Miller 
@_subject: Brady Bill and Instant Check system 
I think I heard on CNN last night the the Brady Bill passed the House and is on  its way to the Senate.  I think part of the Brady Bill calls for the  development within 5 years of a nationwide computer system for performing  "instant" checks on people attempting to purchase handguns.
Without getting into a discussion on the issues of gun ownership (I'm *very* in  favour of it), how do you suppose this Instant Check system will work?  How  will they index into the database? SSN?  Health Security ID number?  I know TRW has developed a pilot fingerprint identification system for the San  Jose Police Department.  It's called C.O.N.F.I.R.M.  (COunty-wide Networked  Fingerprint Identification Remote Match.
I'm not suggesting that CONFIRM was designed for the Instant Check system, just  that the technology to create a nationwide fingerprints database exists, if the  Gov'mnt were to decide that was a good thing.
What can be done to insure that this Instant Check database idea doesn't get  out of hand?  (If it's not already too late.)
Can personal cryptography prevent the accumulation of information on people who  are arrested (regardless of whether or not they are convicted)?  I doubt it.   Only the elimination of the function of a police force would achieve that!
A related, and more philosophical question is:  Is there any room in  Cypher-topia for databases containing information that can be used to identify  convicted "rights-violators"?
Jim_Miller at suite.com
P.S. let me know if none of this is appropriate for the Cypherpunks list.  I'm  still new to this list.

@_date: 1993-11-12 14:19:39
@_author: Jim Miller 
@_subject: Instant check system 
What about the Nazi Abortionists who *do* realize that Libertarinaism is the  only true way to distinguish saffron from turmeric?  Will we still be able to  get guns?  :-)
I'm beginning to regret my 'Brady Bill and Instant Check system' post...
Jim_Miller at suite.com

@_date: 1993-11-14 19:45:27
@_author: Jim Miller 
@_subject: Key Servers 
It's not PGP, but RSA, Inc. and others (Internet Policy Registration Authority)  are already setting up a system for registering pubilc-keys that are "proven"  to belong to actual humans.  You can read about it in RSA's newletter available  at their ftp site (rsa.com).  The newsletter is called "Ciphertext - The RSA  Of course, their system for "proving" the identity of a human is not perfect.   If you can obtain some fake IDs, you can defeat their public-key registration  system.  This is probably true for any non-biometric identification system.
Jim_Miller at suite.com

@_date: 1993-11-16 15:00:56
@_author: Jim Miller 
@_subject: "Cyptography and Secure Communications" 
I was recently at my friendly neighborhood technical book store and I noticed a  cyptography book I hadn't seen before.  It is called "Cyptography and Secure  Communications" by Man Young Rhee.  The publishing data is 1994.  Does anyone  here know anything about this book?  How does it compare with "Applied  Jim_Miller at suite.com

@_date: 1993-11-18 13:08:48
@_author: Jim Miller 
@_subject: All our eggs in one basket? 
Theoretically, this problem is prevented by using protocols that incorporate  non-repudiation mechanisms.  The bank wound not be able to make such a claim.   Or, another way of saying it,  were the bank to make such a claim, you would be  able to prove them wrong.  However, proving them wrong while also retaining your anonymity may be a trick.   It would depend on the design of the non-repudiation mechanisms.
How do you prove to a third party that someone is falsely repudiating a valid  contract or transaction without revealing any information about yourself?
Conversely, how do you defend yourself against false claims of repudiation  without revealing any information about yourself?  After all, someone might try  to discover your identity by making false claims about you, and forcing you to  defend yourself.  (Sound familiar?)
Jim_Miller at suite.com

@_date: 1993-11-18 16:32:20
@_author: Jim Miller 
@_subject: All our eggs in one basket? 
Perry Metzger writes
So to prove that the bank is lying you show a third party your copy of the  digitally signed receipt of the disputed transaction?  I assume the third party  uses the bank's public key and your public key to verify the receipt.
This brings up a good question:  How does the withdraw of digital money from a  bank account work?  In particular, how does the bank simultaneously give you  money and a receipt that neither party could repudiate?
I can see how they could give you the money and a receipt signed by the bank.   I do not yet see how they could simultaneously give you the money and a receipt  signed by both parties. I imagine the bank would use one of the simultaneous contract signing protocols  and somehow produce an encryption key as the last step.  The key would be used  to decrypt the digital money, which was sent in an earlier step in an encrypted  However, how can the person withdrawing the money verify the digital money is  for the amount stated in the receipt if they only get the key after the last  step in the receipt signing protocol.  I am confused.  I must not be thinking  of the correct protocol.
How is this situation handled?
Jim_Miller at suite.com

@_date: 1993-11-18 18:51:42
@_author: Jim Miller 
@_subject: All our eggs in one basket? 
Perry Metzger writes
I'm still confused, only in a different way.  Let's let I want to withdraw  1) I send the bank a signed request to withdraw 10,000 dollars
2) The bank withdraws the money but doesn't sends it to me.
I go to the arbitrator and say: "The bank cheated me!!"
The bank says: "We sent you the money.  Here is your withdraw request, signed  by you.  You are lying."
How can I prove that the bank did not send me the money?  The withdraw protocol must somehow produce a receipt, signed by *me*, saying I  receiving the money.  If the bank cannot present such a receipt, then the  arbitrator shouldn't believe that the bank really sent the money.
Yet why would I sign a receipt before verifying that the bits the bank sent me  was a valid chunk of digital money?  Does this mean the bank sends me valid  digital money first and I reply with a signed receipt?
If so, what if I claim that the transmition failed and I didn't receive the  money, but I really *did* get the money?  I could then tell the bank that I  changed my mind and I want them to rollback the withdraw transaction?  I would  walk off with a valid chuck of digital money, yet my account was not  Obviously I'm still missing something.
Jim_Miller at suite.com

@_date: 1993-11-19 11:46:58
@_author: Jim Miller 
@_subject: All our eggs in one basket? 
Perhaps the bank would send the valid chuck of digital coin first.
If I failed to reply with a signed receipt, the bank could invalidate the  digital coin.  I assume the bank could register the coin in a "voided coin"  registry, placing my "name" in the registry along side the coin's ID.  If I  kept the coin, without sending a receipt, and later tried to spend it, I would  eventually get caught.  The coin would make its way back to the bank and when  it arrived, the bank would see that it was a voided coin and it would know that  I was the one who first tried to spend it.
Here's the protocol so far:
1) I send the bank a signed request asking to withdraw $10,000.  The bank could  use this request to prove it was given permission to withdraw money from my  2) The bank withdraws the money from my account, mints digital coin X with  value $10,000 and sends it to me.
3) I validate the coin, and send a signed receipt saying I received coin X with  value $10,000.  If I fail to send the receipt, the bank places my "name" and  "coin X" in a voided coin registry, and refunds my account for the value of the  What if I send the receipt, but the bank puts the coin on the voided coin list  anyways *and* fails to refund my account?  I would want some way of proving  that I received a valid coin, sent the receipt, and the receipt was received.
To do this, we modify step 3).  Instead of simply sending the bank a signed  receipt, the bank and I would engage in a simultaneous contract signing  protocol which would result in both parties receiving a "receipt" of the coin  If the bank tried to cheat me by putting the valid coin in the voided coin  registry, I would be able to prove that the bank sent me the coin (I still have  the coin) and that the bank received a receipt (I have a copy of the  simultaneously signed receipt).
If I tried to cheat the bank by saying I never received the coin, the bank  would be able to prove that I *did* received the coin (the simultaneously  signed receipt indicates that I *said* I received the coin).  The bank also has  the signed withdraw request proving it was authorized to withdraw money from  the account.
If I received the coin, yet fail to engage in the receipt signing protocol, the  bank would place the coin in the voided coin registry.
If the bank withdrew the money yet failed to send me the coin, I could show the  arbitrator my last two bank statements (before the cheating).  If the bank  could not produce the transfer receipt for the disputed withdraw, the  arbitrator would rule in my favor.
How does all this sound?  I'm not claiming to have just invented something.   I'm just trying to find out if I correctly understand the withdraw of digital  coins from a digital bank account.
Jim_Miller at suite.com

@_date: 1993-11-19 16:56:59
@_author: Jim Miller 
@_subject: All our eggs in one basket? 
Eric Hughes writes
I just got "Applied Cryptography" so now I know what you mean by "blinded form  of the coin".
I was thinking that the bank actually constructed the coin, but in fact the  bank merely signs one of my blinded money orders.  This signed blinded money  order becomes the "coin" (at least in this scheme).
That being the case, I still not sure how I am protected from a bank that  cheats by bring the protocol up to the point where I unblind 99 of the money  orders and the bank deducts the amount from my account but never sends me the  I have some more reading to do, it seems.
Perhaps I can simply trust the bank not to do this because it wants my future  business.  Still, if it were possible, I'd prefer not to have to trust the  bank.  After all, the bank doesn't have to trust me.
Jim_Miller at suite.com

@_date: 1993-11-20 15:37:25
@_author: Jim Miller 
@_subject: All our eggs in one basket? 
I agree these problems are not new to digicash, but if we can design a digicash system  that eliminates these problems, then we should.
I don't know if it has been designed yet, or even if it's possible, but I would like to see a  digicash system that does not force the user or the merchant to trust the bank.  The  merchant and user should be able to use an arbitrator to solve any dispute that may arrise.
(assuming it gets that far)
I don't feel it is good enough to trust in a reputation mechanism to prevent banks (or  anyone) from cheating.  We shoud try to do better.
Actually, disputes may arrise without any cheating involved.  Hardware and software  failures may create situations that appear to be attempts to cheat.  (I don't know this as a  fact.  Just my gut feel.)
The less trust required, the easier it will be for all parties to settle disputes.  (another gut  Jim_Miller at suite.com

@_date: 1993-11-20 17:22:11
@_author: Jim Miller 
@_subject: (fwd) Re: Prosody Release Cancelled Under "NSA" Pressure 
I thought the "Prosody cancellation" post was a hoax.  Anyone know anything  more about it?
Jim_Miller at suite.com

@_date: 1993-11-20 17:32:10
@_author: Jim Miller 
@_subject: Key Servers 
Therefore, reducing your dependency on trust will reduce the opportunities for  Jim_Miller at suite.com

@_date: 1993-11-23 16:23:03
@_author: Jim Miller 
@_subject: strong crypto => increase in rubber-hose attacks? 
I remember seeing a news report a while back that said the number of violent  car thefts has increased because more people are using sophisticated car alarms  and/or car tracking devices.
According to the news report, instead of breaking into cars when the owners  were away, car thieves would wait until the owner shows up and deactivates the  car alarm.  The thieves then pounce on the owner, killing or severely injuring  him/her, and take the car.
Regardless of the actually magnitude of this problem (the media would call  increase of 1 a major new trend) this did get me to thinking.
Assume you use strong crypto to protect your secrets.
Assume a lot of people start using crypto to protect their secrets.
Assume there are people who want to discover these secrets.
Might we some day see an increase in the number physical attacks as bad guys  resort to rubber-hose methods to get at the keys that protect the secrets?
Don't get me wrong, I'm still in favor of using strong crypto.  I'm just  wondering about some of the social implications.
Jim_Miller at suite.com

@_date: 1993-11-29 17:22:05
@_author: Jim Miller 
@_subject: really hiding encrypted data 
Let's imaging that the government has made it illegal to encrypt data unless  you use an "approved" crypto-system.
In a world like this, a person who wanted to encrypt data would have to find a  way to hide the encrypted data.  Many people have suggested placing the  encrypted data in the least significant bit of a binary picture file.  However,  I suspect it is easy to distinguish between the collection of least significant  bits of a normal picture file and the collection of least significant bits of a  picture file used to hold some encrypted data.  In other words,  your picture  file envelope could trigger an alarm in some government traffic sniffer.
This is probably a stupid question, but...is there anyway to take a chuck of  encrypted data (presumably with a high degree of randomness) and securely munge  it so it looks less random, while retaining the ability to reverse the munge  and decrypt the data.
Ideally, the munge process should not be based on obscurity.  The munge process  should be a keyed algorithm so the government filters can't systematically  "unmunge" to check for highly random (and suspect) data.
Unfortunately, I have a hard time imagining an algorithm that is secure AND  produces an output that isn't highly random.
Any ideas?   How about something fractal?     The "munge key" could be the initial state of the fractal engine.     I really don't have a clue about the randomness of the output of a  fractal engine.
 Jim_Miller at suite.com

@_date: 1993-11-29 20:02:06
@_author: Jim Miller 
@_subject: Cryptosplit 2.0 
I'm pretty familiar with the most recent iteration of Kerberos V  (pre-release beta 3).  There is no mention of /dev/mem in any of the  Kerberos V source code files.
As best as I can tell,  all DES keys and random numbers used by Kerberos  are ultimately derived from pass-phrases.
The random DES keys produced by the Kerberos administration utilities are  derived from the KDC master key and some other info (not /dev/mem).  The  KDC master key is derived from a pass-phrase.
All random numbers used inside the Kerberos runtime library are derived  from the user's or server's secret DES key.  A user's secret key is  derived from the user's pass-phase.  A server's secret key is derived from  a pass-phrase or generated automagically by the Kerberos administration  utilities mention above.
(all this is assuming you are using the DES encryption option)
Jim_Miller at suite.com

@_date: 1993-10-21 09:12:49
@_author: Jim Miller 
@_subject: Please add me to mailing list 
I would like to be added to the cypherpunks mailing list.
Jim_Miller at suie.com
[Sorry for broadcasting this to the entire mailing list, but I don't know of  any other address to use.]

@_date: 1993-10-25 12:34:29
@_author: Jim Miller 
@_subject: Interesting reading 
The following is one of the most humorous posts I've read in a long time.  It  made my day.
My experiment has gone far enough.
One of you has claimed that the Net entity "tcmay" (Timothy C. May,
putatively) is actually "jamie" (Jamie Dinkelacker, putatively). This
person has at other times claimed that perhaps Eric Hughes and Jamie
are the same person, and that the Net entity "tcmay" is the "lackey of Eric
It is all getting so confusing! Allow me to clarify.
I entered this list under a variety of pseudonyms, with the intent of
compiling information on all of you. I have been posting under the
identities of Tim May (who has actually never existed....the man
behind the mask on the cover of "Wired" was a hired actor, as were the
stand-ins for the personnas of Eric Hughes and John Gilmore), Sandy
Sandfort, Jamie Dinkelacker, and many others.
I disavow any connection to the paranoid "S. Boxx," however.
In fact, I think there are only five actual biological entities on
the list. Makes for some good conspiracy theories for the paranoids.
Finally, I also write under the nym de guerre of "Dorothy Denning."
The real Dorothy Denning is too busy grading papers for her freshman
crypto class to post, so I fill in.
My real name should be apparent to you all. I knew if I used it, the
other four of you would not take me seriously. But now the secret's
David Sternlight         When the mouse laughs at the cat,
                         there is a hole nearby.--Nigerian Proverb
Jim_Miller at suite.com

@_date: 1993-10-25 18:19:19
@_author: Jim Miller 
@_subject: the Joy of Pseudospoofing 
I just joined this mailing list a couple of days ago (you may remember my  clue-less subscribe request that I broadcast to the list).  Anyways, I expected  to lurk for a while, get a feel for the types of conversations that appear, and  then occasionally post something.  However, I simply must comment on "the Joy  of Pseudospoofing".
I'll go through it in steps.
I understand what you're talking about and I'm just a newbie.  I would hazard a  guess that almost everybody on the list understands what you're talking about.   The thing is,  most people on the list probably don't find "pseudospoofing" to  be an evil menace.
I generally don't care who authors a message.  I care about the *content* of  the message.  If the content of the message is interesting, I save it.  It's  boring, I delete it.  I often don't even look at who sent it.
As a member of a mailing list, I accept the fact that message headers can be  forged or that people can use multiple nyms for nefarious purposes.  It simply  doesn't bother me.  There will always be jerks.
I joined this list to acquire a good understanding of cryptographic technology  and how it might affect the world.  The discussions of the technology will  stand on their own.  The ideas will either be good ideas, bogus ideas, or  require further study.  I don't think it is possible for people to use multiple  nyms to somehow "corrupt" the discussion of the technology.
However, people could use multiple nyms to bias the discussions of the social  effects of widespread cryptography.  So what.  I have long since abandoned  using majority opinion as a tool for forming my own opinions.  I form new  opinions based on the quality of the debates, not the quantity of posts.
I agree that 'deception' is taking place.  Should this be permitted?  To even  ask this question show that you haven't fully grasped the implications of the  This paragraph says it all.  Many of the rules and assumptions that were  developed for regular social settings (e.g. face-to-face) are not valid for the  online experience.  This is something you apparently need to come to terms  What can I say?  I guess I have a higher opinion of the people lurking on this  list than does L. Detweiler.  To me, this is his strawman:
  *People are gullible and we need to protect them!*
So what's wrong with being perverted?  By the way, who defines perversion these  days anyways?  THEM, no doubt.
Here we go again with the "multiple posts" mechanism for forming opinions.  Well, perhaps trust is not something that carries over easily to the online  community.  Ever think of that?  Why do you continue to expect online social  settings to exactly parallel face-to-face social settings?  They are two  different types of fruit.  They are not directly comparable.
I don't like baseball because no one ever scores a touchdown.
Oh my god!  It's really happening!!!!!  Jim Miller
Software Engineer
jim at suite.com
(at work)

@_date: 1993-10-26 16:27:45
@_author: Jim Miller 
@_subject: Enough! 
"Philippe_D_Nave" writes...
Pretty presumptuous of you to attach a motive to my post.  I don't think my  post was abusive, and I didn't post it in an attempt to "gain stature".
Jim_Miller at suite.com

@_date: 1993-10-29 15:53:30
@_author: Jim Miller 
@_subject: ViaCrypt PGP on its way 
I ordered ViaCrypt PGP today.  They said I should get it by next friday.  I'll  post comments about it as I learn to use it.  I haven't used "classic" PGP so I  wont be able to make any commparisons.
Jim_Miller at suite.com  (camping on the mailbox)

@_date: 1994-04-01 15:37:45
@_author: Jim Miller 
@_subject: The President's Analyst 
I saw a movie last night called "The President's Analyst".  The movie  was made in the mid 60's.  It's an action comedy that stars James  Coburn as the President's psychiatrist who sneaks away from the job  because he doesn't like it.  Most of the movie consists of silly  scenes of spies from the world's major countries chasing after Coburn  under the assumption he knows all the President's secrets.  At one  point in the movie the Russian spy is talking to the US spy...
Russian spy:  You mean all the phones in the country are tapped?  But  this is America, not the Soviet Union!!
It's a moderately funny movie that contains more truth now than when  it was first shown.  I recommend it as a cheap laugh and somewhat  relevant to today's issues.
Jim_Miller at suite.com

@_date: 1994-04-05 10:49:37
@_author: Jim Miller 
@_subject: Headline News 
[My apologies if you see this twice.  I think the first attmpt got  lost when our system went down earlier today.]
At around 9:45 AM Central DST today, Headline News displayed the  following "Factoid":
[from memory]
Jim_Miller at suite.com

@_date: 1994-04-07 12:05:32
@_author: Jim Miller 
@_subject: I'm a little surprised 
A couple of days ago I posted that Headline News displayed a  "factoid" that stated US residents value privacy over police ability  to wiretap.  With all the excitement the Time/CNN poll generated, I  expected people on this would say hurray or something.  Nobody said  anything.  What's the deal?
Jim_Miller at suite.com

@_date: 1994-04-07 12:55:45
@_author: Jim Miller 
@_subject: I'm a little surprised 
Ah.  That explains it.
Nope.  I read almost all of them.  I just didn't pay enough attention   to the original article of the sig notice that the Time/CNN pool was  conducted by Yankelovich Partners.  When I saw the Factoid I thought  it was a different poll.
Jim_Miller at suite.com

@_date: 1994-04-10 19:49:27
@_author: Jim Miller 
@_subject: identity, privacy, & anonymity in cyberspace 
tmp at netcom.com writes/asks:
If this problem is not solved then all posts must contain a reference  to the poster's true identity.  Is that what you want,  tmp at netcom.com?  How would it be enforced?  Government approved  public-key pairs issued at birth?  Random identity checkpoints on the  Infobahn?  A ban on all un-approved cryptography?  Peer pressure?
Instead of asking "who are you?", ask "what are you like?".  I don't  usually need to know who you are, but in certain contexts it is  important to know what you are like.  Further, I don't need to know  what you are like in all contexts.
Identity-based systems approach the "what are you like" question by  demanding to know "who you are", and then determining "what you are  like" by accessing various and sundry databases.  These various and  sundry databases are rapidly condensing into a few logical  mega-databases.  The problem with identity-based systems in which  everyone has only a single identity is that it soon becomes very easy  for someone to learn more about you than is necessary or desirable.
Cross-referencing is the root of all evil!  :-)
I think much of the technology advocated on this mailing list can  enable people to answer the important "what are you like" questions  without creating systems that can also be used to pry into your  entire life history.
I agree it is an important goal.
I disagree.  I think cypherpunks want to retain (or re-acquire) the  ability to control who knows what about them and when and under what  contexts.  This is a bit different from "nobody knows anything about  me".  However, I can't speak for all cypherpunks.
If by "our society" you mean the society in which we currently live,  I'd have to agree.  That does *not* mean I believe all possible  societies become impossible under this constraint.  Actually, I  believe "under this constraint" is a strawman (see previous  Being a pessimist, I'll have to agree with you here, although for  slightly different reasons.  I believe that as long as there are  income and property taxes, the government will find ways to justify  prying into our personal lives.
Jim_Miller at suite.com

@_date: 1994-04-17 18:44:58
@_author: Jim Miller 
@_subject: Terra Libre? 
I recently received some junk mail from a group/company called Terra  Libre (I think that's their name).  Anybody know anything about them.   privacy technology this list promotes.
Jim_Miller at suite.com

@_date: 1994-04-20 09:16:42
@_author: Jim Miller 
@_subject: Remailer Musings 
It might be worthwhile to create a remailer package for a remailer  that only sends to other known remailers.  People hesitant about  running a full service remailer may still be willing to run a  behind-the-front-lines remailer.
Jim_Miller at suite.com

@_date: 1994-04-20 10:53:10
@_author: Jim Miller 
@_subject: Press Release on Secure NCSA Mosiac 
I find it hard to believe a company that does *not* collect marketing  data will have a competitive advantage over a company that *does*  collect marketing data.
Jim_Miller at suite.com

@_date: 1994-04-20 22:51:29
@_author: Jim Miller 
@_subject: Terra Libra (long) 
Well, it's been a couple of days since I asked if anyone knew  anything about Terra Libra.  Nobody has spoken up.
Since, on the surface, Terra Libra sounds like it would be  interesting to many on this list, I'm posting a condensed version of  the flyer I received in the mail.  I am not affiliated with Terra  Libra in any way.  Actually, I wonder it is really just a money  making scam.
Here goes...
Jim_Miller at suite.com

@_date: 1994-04-25 14:05:27
@_author: Jim Miller 
@_subject: CA fingerprinting welfare applicants? 
Has California has recently begun fingerprinting welfare applicants  to help detect attempts at welfare cheating?  I saw the tail-end of a  news clip about this on Headline News a couple of weeks ago, but I  didn't catch the whole report.
Jim_Miller at suite.com

@_date: 1994-04-25 15:30:49
@_author: Jim Miller 
@_subject: message splitting for better mixing? 
A variation of the many "send bogus messages through the remailer"  The idea:
1) write sender-side code to split message into N parts and send each  part through a different remailer chain.
2) decrypt the parts as they arrive as per normal encrypted remailer  3) write receiver-side code to detect "a part" and stuff it in a file  until the remaining related parts arrive.  When all related parts  have arrived, present the complete message to receiver.
Why?  To increase the number of "messages" flowing through the  remailers to make traffic analysis more difficult.
Comments welcome.
Jim_Miller at suite.com

@_date: 1994-08-03 16:25:23
@_author: Jim Miller 
@_subject: anonymous anonymous remailers? 
Here's an interesting idea...
Assume we create the alt.anonremailer.net newsgroup mechanism that  Jonathan Rochkind recently suggested (and it worked).
Could we then not use the newsgroup, in combination with a net of  well-known remailers, to give us the capability to have some remailers at  unknown locations by having some remailers post encrypted reply blocks as  their "addresses"?
Just a thought,
Jim_Miller at suite.com

@_date: 1994-08-04 09:43:35
@_author: Jim Miller 
@_subject: alt.anonremailer.net 
It is certainly better than anything we have now.  One nice thing about  your idea is that it can be brought online in steps.  It doesn't require  all remailers to suddenly switch over to using alt.anonremailer.net.
Any of the "ping" mechanisms you mentioned would work (some better than  others).  There's no need to limit the "ping" to a single mechanism.  The  "I am here" messages could have a field indicating the different "ping"  mechanisms the remailer supports.  Again, this could start out to by a  NULL field, and could be added to incrementally, as remailers get more  Jim_Miller at suite.com

@_date: 1994-08-08 12:22:36
@_author: Jim Miller 
@_subject: Digicash address? 
I see others have posted e-mail addresses..here's DigiCash's Web URL in  case you're looking for general info:
     Jim_Miller at suite.com

@_date: 1994-08-12 09:31:38
@_author: Jim Miller 
@_subject: EFF on why they did it. 
Paid for "by the government"?!!  And just where does the EFF think the  government gets its money?  Are there any taxpayers out there who don't  use the phone systems?  Looks like they're are going to get a big bill  from the government in the next few years.
I can't belive the EFF is actually using this as a pro argument.  I can't  believe the EFF is supporting the Wiretap bill.  The EFF is not getting  any more money from me.
Jim_Miller at suite.com

@_date: 1994-08-16 11:14:43
@_author: Jim Miller 
@_subject: In Search of Genuine DigiCash 
This bring to mind the following question:  Is there anything inherent in  NON-anonymous digital cash schemes that make them more vulnerable to  fraud, bribery or inside jobs?   (I assume the schemes account for double  spending and "counterfeiting" (however that applies to digicash).)
Can a case be made that anonymous digicash is less risky (to a bank) than  NON-anonymous digicash?
Jim_Miller at suite.com

@_date: 1994-08-19 13:38:01
@_author: Jim Miller 
@_subject: In Search of Genuine DigiCash 
A few days ago I asked:
There were no takers.  Therefore, I'll ask different questions:
Would a Chaum-style anonymous digital cash service be more profitable to a  bank than a NON-anonymous digital cash service?
Are the costs involved in offering and supporting anonymous digital cash  more, or less, than the costs associated with NON-anonymous digital cash?
In other words, why might a bank chose to offer/support anonymous digital  cash over NON-anonymous digital cash?
If a "bank-centric" case for anonymous digital case over NON-anonymous  digital cash can't be made, then there's little chance we'll see anonymous  digital cash any time soon.
Jim_Miller at suite.com

@_date: 1994-08-24 13:43:17
@_author: Jim Miller 
@_subject: Anonymous questionnaires 
Lucky Green asks how to:
1. Correlate my answers to the answers of my partner.
2. Verify that I have indeed sent in a filled out questionnaire (and send
   me a check for participating).
3. Allow a supervisory agency, such as the U.S. Department of Health and
   Human Services, to verify that the researchers did not just make up all
   the data - that is to allow an audit.
4. Protect my privacy by making it impossible to correlate my name to the
   answers given.
The following a complicated and impractical solution (but it was a fun  First, assume everybody participating in the study is on the Net and is  crypto savvy. :-)
Each participant generates a new public-key pair for the study.  The supervisory agency generates a new public-key pair and gives a copy of  the public key to each participant.  They do not give a copy to the  researchers.  The researchers generate a new public-key pair and give a copy of the  public key to the supervisory agency and each participant.
Finally, each participant generates a symmetric key, blinds it, and has  the supervisory agency sign the blinded symmetric key.
Ok, assume Bob and Alice are a couple participating in the study.  Bob and  Alice each get a copy of the questionaire, the researcher's public key,  and the supervisory agencies' public key.  They each generate and blind a  symmetric key and have it signed by the supervisory agency.
Bob fills in his copy of the questionaire and then signs an MD5 hash of  his completed questionaire.  Alice does the same.  Bob gives his signed  hash value to Alice and Alice gives her signed hash value to Bob.  Bob  appends Alice's signed hash value to the end of his completed  questionaire.  Alice appends Bob's signed hash value to the end of her  completed questionaire.  Neither sees the other's completed questionaire.
Bob now signs his questionaire with his private key.  Alice signs her  questionaire with her private key.
Bob encrypts his (now signed) questionaire and his public key with his  symmetric key.  He next encrypts the signed (and now unblinded) symmetric  key with the supervisory agencies' public key. Finally, he encrypts those  items, along with a cleartext copy of the completed and signed  questionaire, with the researcher's public key and e-mails the result to  the researchers using a chain of anonymous remailers.  :-)
Alice does the same.
Ok, the researches receive an anonymous e-mail message from somebody (call  him Ted) that is encrypted with their public key generated specifically  for this study.  They decrypt the message and get four items:  Ted's  completed and signed questionaire, Ted's encrypted and signed  questionaire, Ted's encrypted public key, and Ted's encrypted and signed  symmetric key. Since Ted's public key is encrypted with his symmetric key and the  symmetric key is encrypted with the agencies' public key, the researchers  cannot read these items.  Also they cannot verify the signature on the  cleartext copy of the questionaire.  However, they check that everything  appears to conform to the requirements of the test, so they credit Ted  with completing the questionaire and e-mail him (via the encrypted reply  block) an IOU signed by the researcher's private key.  More on the IOU  The researchers collect all the anonymous replies and send them as a group  to the supervisory agency.  The supervisory agency decrypts all the  encrypted symmetric keys using its private key, validates the signatures  on those keys, then uses the symmetric keys to decrypt the participants'  public keys and encrypted questionaires.  Since the symmetric keys were  blinded when the supervisory agency signed them, the agency does not have  enough information to be able to determine which participant completed  which questionaire.  All the agency can do is verify that the  questionaires were completed by people who had symmetric keys signed by  the agency.  Since the questionaires where e-mailed to the researchers via  anonymous remailers, the researchers can't collude with the supervisory  agency to determine who complete which questionaire.
The agency sends the decrypted public keys and questionaires back to the  researchers.  The purpose of the signed symmetric keys was to help prove  to the agency that the researchers did not fabricate the study results.   This is not perfect, the researchers could have pretended to be all of the  participants and could have filled out all of the questionaires.  However,  if they did that, they would be unable to produce any real participants,  if they were ever challenged.
The researchers use the decrypted public keys and the signed MD5 hashes to  group the questionaires into related pairs.  The researches can compare  the decrypted questionaires sent back from the agency with the plaintext  copies received from the participants to verify that the supervisory  agency did not substitute any of the real questionaires with bogus ones.
The researchers can now analyze the questionaire data, but they don't know  which participant filled out which questionaire.  However, the researchers  do know which questionaire is paired with which other questionaire.
More on the IUO:
How does a participant redeem the IUO without revealing information which  could allow the researchers or the supervisory agency to pair them up with  their completed questionaire?
Well, the IUO is really a blinded message sent to the researchers in the  anonymous message along with the other stuff.  If the researches are  satisfied with the plaintext questionaire, they will sign the blinded IUO  and send it back via the encrypted reply block.  The participant unblinds  the signed IUO.  The participant can now redeem the IOU offline without  giving anyone any information other than the fact the person was a  participant in the study.
Of course, if there was real anonymous digital cash, there would be no  need to use an IOU.
How to prevent a totally fabricated study:
As mentioned above, the researchers could fabricate the entire study by  pretending to be all of the participants, getting known symmetric keys  signed and so forth.  How can the supervisory agency determine the  difference between a real anonymous participant and a bogus anonymous  It is at this point that we have to step out of cyberspace and back into  the real world.  Ideally, the supervisory agency needs to determine two  things:     1) All of the participants were real people.
    2) None of the participants colluded with the researchers.
Requirement 1 can be satisfied by having the supervisory agency redeem the  IOUs using money they escrowed on behalf of the researchers.  When the  participant comes in to redeem the IOU (or snail mails it in), the  supervisory agency can check the ID (driver's license, SS whatever) of  the participant, verify the signature on the IOU, and hand over (or mail)  the check.  The signed IOU will not give the agency the ability to  determine which questionaire the participant filled out.
I know of no way to enforce requirement 2 without violating the anonymity  of the participants.  The researchers could hire a bunch of people to  redeem bogus (but correctly signed) IOUs, fooling the supervisory agency.   The only way I can think of to prevent participant/researcher collusion is  to have independent auditors standing over the participants while they  fill out the questionaires.  Not what Lucky Green had in mind, I'm sure.
So anyways, there it is, a complex and impractical solution that still  doesn't solve all the problems.  Oh well.  Time to go back and work at my  real job.
Jim_Miller at suite.com

@_date: 1994-02-01 16:25:29
@_author: Jim Miller 
@_subject: Why is Chris Knight a Twerp? 
Please take the "archiving mail-list" thread to e-mail.
Thank you,
Jim_Miller at suite.com

@_date: 1994-02-01 17:20:48
@_author: Jim Miller 
@_subject: SASE Suggestion 
As I understand it, the remailers don't "chose" the return path, Bob (the  sender of the original message) choses the return path when he creates the  SASE.  All the remailers do is interpret the part of the SASE that becomes  readable to them after decrypting the SASE portion sent to them from the  previous hop.  If all is working, what becomes readable is the address of  the next hop (closer to Bob) and some misc other stuff (postage, maybe,  and perhaps another encryption key).
Am I not understanding something correctly?
Jim_Miller at suite.com

@_date: 1994-02-01 21:20:49
@_author: Jim Miller 
@_subject: 2-way anonymous via SASE 
The SASE's that I've been describing are not type a, b, or c.
"b" is closest, except the next-hop address is not an "anonymousid at the  next remailer", rather, it is simply the e-mail address of the next  remailer to send to.
The SASE is structured somewhat like a message enclosed in a bunch of  nested digital envelopes.  If you don't understand "message enclosed in a  bunch of nested digital envelopes" then you will have a hard time  understanding SASE's (at least the type of SASE's I'm describing).
** Using Nested Envelopes for sending anonymous e-mail (simplified) **
Say Bob wants to send a message to Ted, routing the message through R1 and  R2, and finally to Ted.  First of all, Bob needs to know the e-mail  address of R1, R2, and Ted.  Bob also needs to know the public-key of R1,  and R2.  He will probably also want to know the public-key of Ted, but  that is not required.
[Notice that I did *not* say the Bob needed to have an anonymous account  id at each of the remailers.  There are different types of remailers.   Some provide anonymous accounts, others simple forward e-mail.  In the  description below, I am referring to remailers that just forward e-mail.]
To send to Ted, Bob constructs the following: (not considering SASE's yet)
      R1_PK(R2-addr, R2_PK(Ted-addr, Ted_PK(message)))
   XX_PK(stuff)     stuff encrypted with XX's public-key
   XX-addr          e-mail address of XX
Bob sends this mess to R1.
      R1_PK(stuff1)
R1 decrypts "stuff1" and gets:
      R2-addr, R2_PK(stuff2)
R1, strips off "R2-addr" and e-mails R2_PK(stuff2) to "R2-addr".
R2 receives
     R2_PK(stuff2)
R2 decrypts "stuff2" and gets
     Ted-addr, Ted_PK(message)
R2 strips off "Ted-addr" and e-mails Ted_PK(message) to "Ted-addr".
Ted receives
     Ted_PK(message)
Ted decrypts it, and gets Bob's message.
As you can see, you need to use a special type of remailer to get this to  work.  Not all remailers support the "decrypt, strip, and re-send"  You seem to be familiar with the type of remailer that sets up an  anonymizing "account" (e.g. an12345 at anon.penet.fi).  These "Penet-style"   remailers give you an easy mechanism for doing 2-way anonymous  communication.  Ted can use ordinary e-mail commands to send a reply  addressed to "an12345 at anon.penet.fi".
The "decrypt, strip, and re-send" remailers do not provide a trivial way  to send reply messages.  The SASE mechanism is an attempt to extend these  types of remailers so Ted can reply to whomever sent him the anonymous  message (Ted doesn't know anything about the original sender, not even a  anonymous id.  Ted only knows that R2 forwarded a message to him).
Jim_Miller at suite.com

@_date: 1994-02-01 21:40:48
@_author: Jim Miller 
@_subject: 2-way anonymous via SASE 
I finally got around to downloading and reading the remailer stuff from  the cypherpunks ftp site*.  I could have saved myself some embarrassment  if I had read it before posting my "original" SASE idea.  The file
     pub/cypherpunks/remailer/hals.instructions
describes a mechanism that is basically a simplified SASE.
Oh well...
Jim_Miller at suite.com
*ftp soda.berkeley.edu

@_date: 1994-02-03 15:14:49
@_author: Jim Miller 
@_subject: contemplating remailer postage 
If the remailer constructs the stamp, rather than just signs it blindly,  it could keep a log of which stamps were issued to which users.  The  remailer could then use this information to figure out the original sender  of a stamped message regardless of how many other remailers the message  passed through.
To thwart this, users would have to purchase stamps anonymously.  However,  this begs the question: How does the user anonymously purchase stamps for  the first remailer?  I suppose you could use "free" remailers to send  anonymous purchase requests to stamp-issuing remailers.
The system I described does not require you to purchase stamps  anonymously.  You can purchase stamps directly from each remailer without  giving the remailer the opportunity to record which stamp went to which  user.  To understand why this is true you need to understand how blind  signatures work.  The book "Applied Cryptography (Bruce Schneier)" gives a  good description of the properties of blind signatures.  That is how I  learned about them.
The remailer could still record the fact that you purchased stamps, thus  alerting the bad guys that you plan to use the remailer system.  However,  I don't think it is possible to prevent the bad guys from learning that  you use remailers.  I assume the bad guys will be logging all traffic to  the remailers and would learn about your use of remailers, stamps or no  Jim_Miller at suite.com

@_date: 1994-02-03 15:39:44
@_author: Jim Miller 
@_subject: SASE Suggestion 
Oh, I see.  I was confused as to which scheme you were talking about.  You  were refering (I think) to the "prepaid mailer" idea Tim May described in  his "Re: Anonymous Anonymous ftp" post of Jan 27.
Jim_Miller at suite.com

@_date: 1994-02-03 19:19:44
@_author: Jim Miller 
@_subject: On return addresses 
Let me see if I understand your idea correctly.  I am picturing  something like the following:
There will exist a bunch of remailers that, in addition to forwarding  mail, will also sell mailboxes.  (I'm combining the remailer with the  mail spools to add to the mix of messages to and from).  The  "mailboxes" are actually e-mail addresses referring to a  pseudo-account on some machine that hosts a remailer/mail spooler.
Bob would purchase a number of mailboxes scattered throughout the  remailer/mail spooler system.  Bob would give out the address of one  of these mailboxes to people so they can send "reply" messages to  him.  Messages addressed to Bob's "public" mailbox would be spooled  by the remailer hosting that mailbox.
Periodically (perhaps frequently), Bob would send an anonymous  message (via other remailers) to the remailer hosting his public  mailbox to command the remailer to send the contents of his mailbox  to one of his other mailboxes.  The remailer wouldn't necessarily  know it's sending to another mailbox, it's just sends to an address  supplied in the command message.
Bob repeats this process to move his messages from his second mailbox  to his third mailbox, and so on.  Eventually, he moves his messages  from his Nth mailbox to his "real" address.
Is this approximately what you had in mind?  I left out IP  redirectors and POP clients because I'm not familiar with them.
Jim_Miller at suite.com

@_date: 1994-02-08 20:32:13
@_author: Jim Miller 
@_subject: Crypto Regulation Reform 
Page 44 of "Applied Cryptography" discusses a point to point *public*  key exchange protocol called the "Interlock Protocol" (invented by  Ron Rivest and Adi Shamir).  This protocol is an attempt to foil the  man-in-the-middle attack.  The protocol does not provide a %100  guarantee against man-in-middle, but it does make it much harder (or  so says the book).
Perhaps Robert's device really uses a variation of the Interlock  Protocol, and not Diffie-Hellman (mentioned only as a red herring?).
Jim_Miller at suite.com

@_date: 1994-02-10 21:20:24
@_author: Jim Miller 
@_subject: message pools revisited 
Someone once said that a system of remailers is as strong as its  STRONGEST link.
"As long as even ONE remailer in the chain is trustworthy, hiding the  connection between incoming and outgoing messages, your anonymity is  While I agree with this in principal, I'm still not satisfied.  I  want a remailer system that is secure from eavesdropping and traffic  analysis even if ALL remailers are untrustworthy.
You might ask why I am not satisfied with current remailer designs.   My unease stems mostly from irrational fears and distrust of the  people running the remailers.  I don't personally know any of the  people who are running remailers.  How can I be sure they are not  colluding?  How can I be sure their machines haven't been penetrated  by the Bad Guys?  It may be true that the remailer system is as  strong as its STRONGEST link, but how do I know where that strongest  link is?  As long as there is any doubt, I'm not satisfied.  Others  may feel the same, and refrain from using remailers.
With sufficient traffic, messages exchanged via a message pool are  secure from eavesdropping and traffic analysis, even if the message  pool is untrustworthy.  The problem is, the message pool schemes I'm  familiar with (admittedly, not that many) don't scale up well.
One kind of message pool works like a mailing list.  People subscribe  to the message pool by sending the message pool server their e-mail  address (and perhaps also a public-key).  A member of the message  pool sends an anonymous message by encrypting it with the recipient's  public key and sending it to the message pool server.  The message  pool server sends a copy of the encrypted message to every member of  the message pool service.  Only the person who has the corresponding  private key will be able to decrypt the message.  All other members  of the pool will get garbage.  One benefit of this type of message  pool is that the messages come to you.  You don't have to go and get  them.  Also, if an encrypting remailer is a member of the message  pool service, then members can "route" messages through it to  Another kind of message pool works like a BBS system.   A person  sends a message by encrypting it with the recipient's public key and  sending it to the message pool server.  The message pool server adds  the message to a pool of messages it maintains.  Messages stay in the  pool for a finite time, and then are deleted.  People periodically  downlaod the current set of unexpired messages from the pool and see  if they can decrypt any of them.  If they find a message they can  decrypt, then the message was meant for them.  The advantage to this  scheme is that there is no concept of a "member".
Some time last year, before I joined the cypherpunks mailing list, I  posted a message to sci.crypt suggesting that people create a news  group called "alt.crypt.messages" so people could exchange messages  anonymously.  Some people said this was a good idea.  Others said  that it was suggested before by others (it had).  Still others said  it wouldn't work because people wouldn't carry the news group because  they wouldn't be able to know what kind of stuff was being sent  through it.
I think it is time to ask again.  Do people think it would be a good  idea to create a news group for exchanging anonymous messages?   Alternatively, perhaps some cypherpunks with free time would like to  code up a simplified distributed message pool service modeled after  USENET.  You would need servers to distribute the messages and  front-end "reader" apps to simplify searching for messages destined  for you.  Any takers?
Jim_Miller at suite.com

@_date: 1994-02-10 22:00:25
@_author: Jim Miller 
@_subject: message pools revisited - CORRECTION 
I realized only after posting that "routing" messages through a  remailer that is a member of the message pool you belong to is a  Keep in mind that I'm still speaking within the context of "all  remailers and message pool servers are colluding".
Jim_Miller at suite.com

@_date: 1994-02-12 16:51:09
@_author: Jim Miller 
@_subject: a protocol 
An idea came to me today for a protocol for exchanging keys  point-to-point (inspired by the Robert Cain messages).  The protocol  is a just combination of the Interlock Protocol described on page 44  of "Applied Cryptography" and Diffie-Hellman, describe on page 275.
Keeping with the terminology of the book, Alice will attempt to  exchange a key with Bob, and Mallet will attempt to sit in the middle  without being detected.
As has been demonstrated in the past, I haven't read a lot of the  cryptography papers that are out there, so for all I know, this is a  well known protocol (or simple variation).  However, I haven't seen  it, and it seems interesting.  Anyways, on with the show...
1) Alice sends Bob her public key.  (ala Interlock Protocol)
2) Bob sends Alice his public key.
3) Alice generates a Diffie-Hellman "n" value, encrypts "n" with  Bob's public key and sends half of the "n" message to Bob.
4) Bob generates a Diffie-Hellman "g" value, encrypts "g" with  Alice's public key and sends half of the "g" message to Alice.
5) Alice sends other half of "n" message to Bob.
6) Bob puts the two halves of Alice's "n" message together and  decrypts it with his private key.  Bob sends the other half of his  "g" message to Alice.
7) Alice puts the two halves of Bob's "g" message together and  decrypts it with her private key.
Alice and Bob's each now have an "n" and a "g".  Below, I try to show  that they can only have the same "n" and "g" if there is no  Alice chooses a random large integer x and computes:
Bob chooses a random large integer y and computes:
Standard Diffie-Hellman stuff.
8) Alice encrypts X with Bob's public key and sends half of X message  to Bob.
9) Bob encrypts Y with Alice's public key and sends half of Y message  to Alice.
10) Alice sends other half of X message to Bob.
11) Bob puts the two halves of Alice's X message together and  decrypts it with his private key.  Bob sends the other half of his Y  message to Alice.
12) Alice puts the two halves of Bob's Y message together and  decrypts it with her private key.
Now Alice and Bob's each have an X and a Y.
Alice computes k = (Y**x) mod n.
Bob computes k' = (X**y) mod n.
13) Alice encrypts a message using k and sends it to Bob.
Bob decrypts message using k' and validates success of protocol.
14) Bob encrypts a message using k' and sends it to Alice.
Alice decrypts message using k and validates success of protocol.
What can Mallet do to this protocol?
Mallet can substitute his own public keys for Alice's and Bob's in  steps 1 and 2.  Mallet can then capture "n" (from Alice) and "g"  (from Bob), although not immediately.  Mallet forward Bob bogus "n"  message halves and Alice bogus "g"  message halves.  Thus Alice will  get a bogus g, call it g', and Bob will get a bogus n, call it n'.
Mallet cannot forward the real "n" to Bob because of the interlock  protocol.  Similarly, Mallet cannot forward the real "g" to Alice.   Mallet only learns "n" in step 5 and "g" in step 6.  However, he must  forward half of a bogus "n" to Bob in step 3), half of a bogus "g" to  Alice in step 4.
At the end of step 6, Alice will have n and g' and Bob will have n'  and g.
Alice and Bob continue with the protocol and calculate X and Y.   Alice and Bob use the interlock protocol to exchange X and Y.  As  with n and g, Mallet will eventually get X and Y, but not before  having to forward a bogus X to Bob and a bogus Y to Alice (call them  X' and Y').
Alice and Bob, still unaware of Mallet, compute k and k'.  However,  since they are using different values for n, g, X, and Y, they will  compute different values.  The encrypted messages in steps 13 and 14  will expose Mallet.
I've only spent about fifteen minutes thinking about this protocol.   I can't say that it is without holes or even that it does what I say  it does.  However, I think it might have potential.  What to the  professionals think?
Jim_Miller at suite.com

@_date: 1994-02-13 13:01:14
@_author: Jim Miller 
@_subject: a protocol (that doesn't work) 
Did you ever wish there was an "unmail" command?
I realized about halfway home that the protocol I described not only  didn't work, but demonstrated to the world my lack of understanding  of the man-in-the-middle attack against Diffie-Hellman.  Oh well, I  guess I'll keep my day job a little longer...
At least I now have a better understanding of just how hard it is to  foil man-in-the-middle attacks.
is possible to arrange things so the man in the middle has to do a  lot more work.  It may be that Robert Cain has come up with a  protocol that increases the work necessary to maintain a  man-in-the-middle attack to the point where the attack becomes  impractical, although not impossible, in theory.  However, I think  that is this becomes the case, an attacker would simple cut Bob  completely out of the picture and change the man-in-the-middle attack  to a %100 spoof of Bob.  Since Alice and Bob have never met and don't  share any secrets, how would Alice be able to tell the difference  between the real Bob, and Mallet completely spoofing Bob?  In the  abstract, I don't see any way.
There may be some real-world situations where Alice can tell the  difference between Bob and pseudo-Bob.  It depends on the situation  and what assumptions Alice makes about a properly behaved Bob.  If  pseudo-Bob doesn't behave the way Alice expects real-Bob to behave,  then Alice could get suspicious.  But now we've existed the realm of  cryptography and enter the realm of human relations.  Of course,  there's still a lot of money to be made offering imperfect solutions  that are good enough for some people.
Jim_"still learning"_Miller at suite.com

@_date: 1994-02-13 14:51:15
@_author: Jim Miller 
@_subject: escrow-to-black box protocol 
Has the government published a description of the protocol the escrow  agencies will use to download the Clipper keys to the black boxes?   If so, is there a FTP'able description of it somewhere?
Jim_Miller at suite.com

@_date: 1994-02-15 08:40:26
@_author: Jim Miller 
@_subject: Clipper and Traffic Analysis 
Is it true that law enforcement can obtain phone records from the  phone company simply by asking?  Or do they need a supena(sp)?
It would not surprise me in the least to hear someday that the  government will allow law enforcement to record LEAFs without having  to obtain a warrant for a wiretap.  If Clipper becomes widespread,  and most conversations are encrypted, the government might  conveniently redefine the term "wiretap" to mean "decrypting a  Clipper conversation".  This would open it up for the government to  continuously monitor and record LEAFs, probably via the soon to be  mandated "wiretap" capabilities the FBI is pushing for.
"After all, the LEAF is just the electronic equivalent of your phone  record.  This new definition of "wiretap" does not give law  enforcement any new capabilities.  Since the actual contents of the  conversation are encrypted, there is no invasion of privicy.  We're  just trying to keep up with the latest technological advances."
Jim_Miller at suite.com

@_date: 1994-02-17 11:15:50
@_author: Jim Miller 
@_subject: Detweiler blocking 
I've seen this analogy before and I think it is a poor analogy and  should not be used.  I don't mean for this to be a flame, just a  comment.  The problem with this analogy is that you are comparing a  publicly available service that is being abused with a private  residence that is being abused.
It is the difference between "Everybody can use this remailer except  Detweiler" and "Nobody is allowed to shout in my bedroom at 4 AM, and  that includes Detweiler".  Do you see the difference.  The analogy is  comparing a service with a non-service.
Since remailers are services, the analogies used to discuss them  should compare remailers with other services.  For example:
"Detweiler is a disruptive client and I am within my rights to  prevent him from using my service."
Right now, remailer services are free, and that generates the  impression in some that they are public resources that *must* be  available to all.  If remailers charged even a small amount for their  service, it might make it easier to justify denying service to  specific individuals.  It's not logical, but people are seldom  persuaded by logic alone.
able to refuse specific users, when possible.  My point with this  post is to recommend abandoning the "bedroom" analogy.
Jim_Miller at suite.com

@_date: 1994-02-22 15:25:18
@_author: Jim Miller 
@_subject: Disinformation (or the Truth?) About Clipper 
The idea of a disinformation campaign to oppose Clipper really bothers me.   Isn't the true about Clipper damning enough?  Lying about Clipper seems like  moral and ethical surrender.  I agree that lying can produce favorable results,  but I'm not willing to stoop to that level.  If the anti-Clipper people (and I  count myself one of them) can't defeat Clipper with the truth, this tells me  the world is so fucked up it deserves Clipper and Capstone in every machine on  the planet.
Jim_Miller at suite.com

@_date: 1994-02-23 12:22:10
@_author: Jim Miller 
@_subject: Disinformation (or the Truth?) About Clipper 
I'm quite satisfied with this clarification (as if it matters to any  but me).
Still, I believe labeling your efforts a "disinformation campaign"  was a mistake.  It gives the pro-Clipper people something to throw  back in your face.  How about changing "disinformation campaign" to  "education campaign"?  It has a more positive sound to it and doesn't  limit you to only dry facts.  Education through speculation,  hyperbole, and satire can be effective and is ethical if the reader  can recognize when you are engaging in speculation, hyperbole, or  satire (my opinion, of course). Jim_Miller at suite.com

@_date: 1994-02-23 16:52:56
@_author: Jim Miller 
@_subject: Digitally Signing Physical Objects 
Could someone repost the "Digitally Signing Physical Objects" article  (or mail it to me).  It never arrived at my site.
Jim_Miller at suite.com

@_date: 1994-01-24 18:11:51
@_author: Jim Miller 
@_subject: REMAIL: Cover traffic 
How about extending the "send bogus messages" idea all the way out to the  users of the remailer system?  Part of the price of using the remailer  system is that you will occasionally receive a bogus message.
How might this work?
Assume remailers know the addresses of all (or most) of the other  remailers.  In other words, assume a given remailers knows if an inbound  message came from another remailer, or came from a non-remailer address.
All inbound messages to a remailer from a non-remailer address would be  considered a "use" of that remailer.  A remailer would maintain a list of  the addresses of "users" and would occasionally send bogus messages to a  randomly selected entry from its user list.  Inclusion into the list would  be automatic.  The list would be a large, but fixed sized FIFO, with old  entries dropping off the end automatically.
If the remailer system uses Digital Postage, then perhaps the bogus  message could be a token for a free Digital Stamp, good for one message.
I'm sure many will object to tracking the users of a remailer, but I don't  see how tracking can be prevented, other than by mutual agreement.  Can we  use tracking to *increase* privacy?
Jim_Miller at suite.com

@_date: 1994-01-24 20:18:51
@_author: Jim Miller 
@_subject: REMAIL: Cover traffic 
I assume the bad guys can generate their own record of remailer usage.   The record could include the addresses used to send messages to remailers  and the addresses receiving messages from remailers.  They can record when
a message enters the system from the outside, and they can record when a  message leaves the system.
Given they can know all this by just monitoring the remailer system, then  there is no reason why the remailers can't also use some of this  information.  Besides, the "user list" maintained by a remailer only needs to contain  the non-remailer addresses used to send messages to the remailer.  It does  not need to contain any time information or information about the messages  passing through the remailer.  It also doesn't need to contain destination  Jim_Miller at suite.com
P.S.  After sending my previous message I realized the proposed mechanism  still doesn't help Hal Finney's degenerate case where there is only one  sender and one receiver, but I've come to believe it is not necessary to  solve for that case.

@_date: 1994-01-25 15:26:53
@_author: Jim Miller 
@_subject: The Packwood Memorial Diary Server 
I often see threads debating whether the courts have the right to compel  you to reveal your encryption key.  Some say yes, some say no.
Under the assumption that courts *do* have the right (or power) to force  you to reveal your key, the problem now becomes:
How can you prevent the government from proving you have encrypted  One Answer: Don't keep encrypted documents in your possession.
Somebody could create a Document Server to store encrypted documents.   Users would somehow get an anonymous Document Server account number when  they subscribe to the service.  Users would use the remailer system to  send encrypted documents to the Document Server.  The account numbers  would be used to organize the document database and for billing (the  tricky part).
Given a Document Server, the problem now becomes:  How can you prevent the  government from proving you use a Document Server.  This seems like a  strictly technical problem, unlike the "can they compel you to reveal your  key" problem.
Jim_Miller at suite.com

@_date: 1994-01-25 17:06:53
@_author: Jim Miller 
@_subject: REMAIL: Cover traffic 
I like this idea.  It seems to use fewer CPU resources than having a  remailer route a bogus message through a random set of other remailers and  back to itself.
If I understand the encrypted remailer scheme correctly, the "route  through random set" mechanism requires a remailer to enclose a bogus  message in a set of nested digital envelopes (one for each remailer in the  random remailer set).  The "round-robin send to peers" mechanism only  requires the remailer to create one envelope per bogus message.
I also like the idea because it seems easier to analyse, and therefore  easier to describe/formalize the properties of the system as a whole.
Jim_Miller at suite.com

@_date: 1994-01-25 21:26:53
@_author: Jim Miller 
@_subject: The Packwood Memorial Diary Server 
Need it be any more secure than the crypto system you would use on your  own harddisk (which could get confiscated)?
Jim_Miller at suite.com

@_date: 1994-01-25 21:46:55
@_author: Jim Miller 
@_subject: REMAIL: Cover traffic 
There's a subtle difference between the "send bogus messages thru random  set of remailers back to yourself" protocol versus the "round-robin send  bogus message to remailer peers" protocol.  I don't know if it matters,  but it's worth pointing out.
In a simple round-robin protocol, bogus messages won't be contained within  nested digital envelopes.  When a remailer receives a bogus message from  one of its peers, it will unwrap the outermost digital envelope, and,  walla, a bogus message.
You could modify the round-robin protocol to create more complex,  multi-hop bogus messages (first hop is the next remailer peer, all other  hops randomly chosen), but then your basically back to the first protocol.
Is it important that your remailer peers know when you send them bogus  messages?  I suppose it depends on how many of your remailer peers are  really operated by the Bad Guys.  Jim_Miller at suite.com

@_date: 1994-01-25 22:32:15
@_author: Jim Miller 
@_subject: The Packwood Memorial Diary Server 
Cool.  Another paradigm is to think of the Document Server as an anonymous  digital safe deposit box server.
A user could purchase, via anonymous digital cash, X megs of space up  front, and then fill it up with whatever bits they wish.  However, done  this way, management of the contents of the box would be left to the user.    Perhaps the service would offer specialized boxes for different types of  Just random thoughts (well, not provably random thoughts, of course).
Jim_Miller at suite.com

@_date: 1994-01-26 18:57:22
@_author: Jim Miller 
@_subject: The Packwood Memorial Diary Server 
Are there really no countries in the world that would permit such a  server?  How depressing.
If true, I guess the next question becomes:  How can you offer a service  to the Internet, but make it impossible for a Bad Guy to physically locate  Perhaps the server shouldn't stay in any one location for very long.   Bring it up and post an Internet address.  Operate for a few days, then  shut it down and move to some new location, with a new Internet address.  Sounds possible, but damned inconvenient.  A wireless connection would  help.  The server host could be in a van or RV or something.  Jim_Miller at suite.com

@_date: 1994-01-26 21:32:12
@_author: Jim Miller 
@_subject: Anonymous Anonymous ftp 
I understand how you can do 2-way anonymous communication via message  pools and Penet-style systems, but I don't "get" prepaid mailers.  Could  you post an example showing how two people can converse anonymously via  prepaid mailers.
Jim_Miller at suite.com

@_date: 1994-01-28 15:02:36
@_author: Jim Miller 
@_subject: 2-way anonymous via SASE 
Here's an idea that was inspired by Tim May's prepaid mailer example.  I  call it "2-way anonymous communication using Self Addressed Stamped  The general idea is that each anonymous messages will include a SASE that  can be used to reply to the sender, without revealing the identity of the  sender to the message recipient.  To reply, the recipient will copy the  SASE from the original message and past it into a special section of the  reply message.  Remailers will examine this section of the reply message  and use its contents to route the message back to the sender of the  original message.  The syntax's for describing the mechanism gets messy fast.  I hope I can  describe it so others can understand it.
Here's how I see it working...
Small example:
Bob wishes to communicate anonymously with Ted via remailer R1.  (With  just one remailer, R1 would be able to track who sends to whom, but this  is just for example purposes.)
Bob constructs:
(stuff1)R1                   - stuff encrypted with R1's public key
stuff1 == Ted, (stuff2)Ted   - Ted's address and more stuff encrypted
                               with Ted's public key.
stuff2 == msg, SASE          - Bob's message and Self Addr Stamped Envlpe
All together, it looks like:
(Ted, (msg, SASE)Ted)R1
(i.e. msg and SASE, encrypted with Ted's public key, appended to Ted's  e-mail address, all encrypted with R1's public key)
The SASE contains the information Ted will use to send a reply message  back to Bob.  It looks like:
  R1, A, (stuff3)R1
  stuff3 == Bob, B, (stuff4)Bob
  stuff4 == A', B'
all together:
  R1, A, (Bob, B, (A', B')Bob)R1
  R1's address,
  A                  - a one-time public-key generated by Bob,
  ( Bob's address,
    B                - another one-time public-key generated by Bob,
    ( A'             - private key paired with A,
      B'             - private key paired with B
    ) encrypted with Bob's public key
  ) encrypted with R1's public key
Ok, Bob sends (stuff1)R1 to R1. This is just like using a regular  encrypting remailer.  R1 decrypts stuff1 and gets:
Ted, (stuff2)Ted
R1, strips off "Ted" and passes the rest to Ted.  Ted receives  (stuff2)Ted, decrypts it and gets:
msg, SASE
Which is really:
msg, R1, A, (stuff3)R1
Ted reads the message and decides to reply to whomever sent the message.   Ted composes a reply and encrypts it with public-key A, then sends the  following to R1 (he sends it to R1 because R1 was in the SASE):
(stuff3)R1, (reply)A           ==> R1
R1 receives this, decrypts (stuff3) and gets:
Bob, B, (stuff4)Bob
R1 encrypts (reply)A with public-key B and sends the following to Bob (the  guy mentioned inside of stuff3):
(stuff4)Bob, ((reply)A)B       ==> Bob
Bob receives this, decrypts stuff4, obtaining A' and B'.  Bobs decrypts  ((reply)A)B using B' and A' respectively and gets the reply message.  If  the reply message contained a SASE generated by TED, then Bob and Ted  could continue to converse anonymously by including SASEs in each reply.
Expanded example:
Bob and Ted use combinations of R1, R2, R3 to communication anonymously
Bob write a message and wants to send it to Ted via R1, R2, and R3.  He  constructs the following:
(R2, (R3, (Ted, (msg, SASE)Ted)R3)R2)R1
In this example, the SASE will look like the following:
R3, A, (R2, B, (R1, C, (Bob, D, (A', B', C', D')Bob)R1)R2)R3
ASIDE: As you may guess by now, Bob's message will go through R1, then R2,  then R3, and Ted's reply will come back via, R3, then R2, then R1.   However, the SASE does not have to specify the reverse route of the  original message, nor even use the same remailers.
Anyways, Bob sends
(R2, (R3, (Ted, (msg, SASE)Ted)R3)R2)R1      ==> R1
R1 decrypts it and gets:
R2, (R3, (Ted, (msg, SASE)Ted)R3)R2
R1 strips off "R2" and sends the rest to R2.  R2 and R3 do similar things.   Standard remailer stuff.  Eventually Ted will receive
(msg, SASE)Ted
decrypting obtains:
msg, SASE
Which is really:
msg, R3, A, (R2, B, (R1, C, (Bob, D, (A', B', C', D')Bob)R1)R2)R3
To reply to the sender of the message, Ted does just what he did in the  first example.   He constructs:
(stuff3)R3, (reply)A
and sends it to to R3.  R3, R2, R1 do their thing and eventually the reply  gets back to Bob.  When it arrives at Bob it will look like:
(A', B', C', D')Bob, ((((reply)A)B)C)D
verifying that the remailers correctly routed the reply.  If the remailers  did not correctly route the reply, or failed to re-encrypt the reply with  B,C, and D, then the thing Bob got at the end of the final decrypt would  have been garbage.
Phew.  I wonder if it really works?
Jim_Miller at suite.com

@_date: 1994-01-29 18:48:36
@_author: Jim Miller 
@_subject: 2-way anonymous via SASE 
Damn, just when I thought I might have had an original idea...
Probably most than just slightly (for the sender), considering the time it  takes to generate good public-key pairs.
If the SASEs incorporated the use of non-reusable Digital Stamps, then the  remailers could detect attempts to double spend the Digital Stamps placed  inside the SASEs.
I'm not exactly sure what you mean here.  I'm guessing that you mean an  eavesdropper could capture a reply message of the form...
Ted sends  (stuff3)R3, (reply)A      ==> R3
...and grab the "(stuff3)R3" part and try to use it.  However, he wouldn't  have the public-key A, so he wouldn't be able to use "(stuff3)R3" to send  a readable message to Bob (who constructed the SASE).  Bob would get  garbage at the end of the final decrypt step because the eavesdropper's  message was not encrypted with A.  However, the eavesdropper could still  use "(stuff3)R3" to send multiple copies of a garbage message in an  attempt to track back to Bob (as you indicated in your last paragraph).   If I was Ted and I was worried about an eavesdropper, I would not send the  reply directly to R3.  I would wrap the reply in a nest of conventional  digital envelopes and send the reply to R3 via a random set of other  remailers.  Something like:
(R21, (R3, ((stuff3)R3, (reply)A)R3)R21)R10
This would first go to R10, then R21, and then to R3, which would  recognize the (stuff3)R3, (reply)A format and forward the reply based on  the contents of "stuff3"
This would foil the eavesdroppers who were trying to figure out who Ted  was replying to.  An eavesdropper monitoring R3 would still be able to  caputure the SASE-based message forward by R3 (e.g. (stuffN) ((reply)A)B   ==> R2 ), but they wouldn't be able know that the forwarded reply  originally came from Ted.
This, of course, doesn't prevent Ted from abusing the SASE.  Will probably  need some form of non-reuseable Digital Stamps to do that.
Jim_Miller at suite.com

@_date: 1994-01-31 17:55:27
@_author: Jim Miller 
@_subject: 2-way anonymous via SASE 
Jon Boone writes
At no time do any of the remailers see a "full spec of the return path",  especially the last remailer in the chain of remailers used for the reply  You might view the SASE as a "full spec of the return path", however, only  the receiver of the original message sees the full SASE, and the SASE is  mostly a bunch of encrypted information nested in layers that only become  readable as the SASE gets "unwrapped" in its trip back to the original  sender.  Each remailer involved in the return trip sees only the layer of  the SASE that becomes readable when it decrypts the portion of the SASE it  received from the previous hop.  By the time reply gets to the last  remailer (inner most layer of the SASE), the reply contains no information  about any of the outer layers of the SASE.  All it contain is:
(Bob, D, (stuffN))Rx,  (((reply)A)B)C
(A, B, and C, indicates keys used to re-encrypt the reply.  They are not  addresses of previous hops.)
If Bob was really unlucky, it is possible he could build an SASE using  only remailers that are under the control of Ted.  If this happend, then  Ted would be able to trace back to Bob.  However, "Bob" could be an  anonymous Penet-style account and Ted would still not have learned who  "Bob" really is.
Jim_Miller at suite.com

@_date: 1994-07-01 09:25:39
@_author: Jim Miller 
@_subject: What was the House Rules Committee vote? 
The House Rules Committee was supposed to vote on the General Export  Administration Act HR 3937 yesterday.  Anybody know the result of the  vote?  Did they mark the bill "open"?
Jim_Miller at suite.com

@_date: 1994-07-07 08:13:31
@_author: Jim Miller 
@_subject: Any news on the crypto export bill? 
The House Rules Committee was supposed to decide if the General Export  Administration Act HR 3937 was going to be "open" or "closed".  They were  going to do this last Thursday.  What did they decide?  Or was the meeting  Jim_Miller at suite.com

@_date: 1994-07-12 13:10:28
@_author: Jim Miller 
@_subject: sci.crypt archive ftp site 
There's one at        ftp://rpub.cl.msu.edu/pub/crypt/sci.crypt
But I just looked and it only has up to April 94.
By the way, everybody should check out
          ftp://furmint.nectar.cs.cmu.edu/security/README.html
These are two budding cypherpunks WWW sites.  Somebody's been busy.
"Cypherpunks weave Webs!"
Jim_Miller at suite.com

@_date: 1994-07-13 14:35:56
@_author: Jim Miller 
@_subject: New version of Digital Telephony Bill? 
In the latest Wired issue (2.08) there is a small blurb about a new  version of the Digital Telephony Bill that the FBI has presented.   According to the blurb, a couple of Senators has expressed a willingness  to sponsor this new version.  Anybody have any more info on this?
Jim_Miller at suite.com

@_date: 1994-07-13 15:02:59
@_author: Jim Miller 
@_subject: INFOBAHN PANEL SEES WORLD THROUGH [..] BLINDERS 
A recent fax from The Center for Strategic and International Studies'  International Communications Studies and Political-Military
topic: encryption wars on the global information highway:  beyond the  clipper chip battle.  This introductory discussion will take place on July  14th, 1994, at CSIS, 4th floor conference room, 1800 K St., N.W., DC from  9:30am-12noon.  Dr. Michael Nelson, Special Assistant, White House Office  of Science and Technology, and Mr. Kent Walter, Counsel to the Deputy  Attorney General, will lead off the morning, followed by diverse industry  and expert views.  Since this by invitation only, please RSVP to Craig  Johnson by Monday, July 11 at either Fax: (202) 775-0898, or e-mail:  csis-ics at clark.net.
[Included with the fax was the following ILA report reproduced here with  permission from the author.  Is anyone on this list invited to the above  mentioned meeting? - jm]
What's Left Unsaid And Undone
INFOBAHN PANEL SEES WORLD THROUGH NARROW COPYRIGHT BLINDERS
Lehman Panel Leaves Later How To Deal With Other Issues
     The best way to understand the recently released
government report on protecting intellectual property is
to look at the credentials of its primary author: Bruce
Lehman, patent commissioner.
     Don't be misled by his title. Lehman is a copyright
lawyer and legislative aide by training. His report
reflects these points of view:
     If there is an emerging problem, as the economy
enters the digital age, when information can be quickly,
easily, and secretly copied, then the solution is to
tinker with the law. A patch here, and a new subsection
there, and Humpty Dumpty will be put back together again.
     "We tried to fine tune the dials of public policy,"
says Lehman, who emphasizes that the report benefited
from hundreds of sets of eyes, not his alone.
     The draft report was issued by a working group
underneath the Clinton Administration's National
Information Infrastructure Task Force.
     And while its recommendations on changes to
copyright law received wide attention earlier this week,
the report is only one arrow in a quiver to deal with the
theft of intellectual property.
     Faith in the rule of law is a good thing, in other
words, but it won't be enough. Just ask anyone who has
watched his or her copyrighted work flung through the
Internet in a seamless chain of infringement. Or a
software company that discovers 300 copies of a program
at a corporation and only one sale.
     The working group's recommendations by themselves
won't break the chain any more than stiffer laws and
penalties have cured the drug crisis.
     But there are other arrows to shoot. Next week, for
example, a different wing of the NII task force will hold
a public hearing on the "security, integrity, and
reliability" of information that travels through digital
networks. Yet another wing, headed by Arati Prabhakar,
director of the National Institute of Standards and
Technology, is at work on applications and technology.
GOTTA START SOMEPLACE
     Nearly everyone (except those who don't believe in
intellectual property) seems to think the law is a good
place to start. "Lehman has done an excellent job
bringing focus to this issue," says Henry Perritt, Jr., a
professor at Villanova Law School, who nonetheless has
concerns about some of the specific proposals.
     Among the major recommendations, which are all
subject to change (Possible objections mentioned by
critics are in parenthesis):
      It would be illegal to tamper with devices or
methods used to protect copyrighted material. (What
happens when the work is no longer subject to copyright?
If it is held in a technological envelope that is
unlawful to break, the work cannot enter the public
domain, as other works do upon copyright expiration.)
      Transmissions that may be considered both a
performance and a distribution, such as when a recipient
listens to a recording as it is being downloaded, would
be considered a distribution, if that was the
transmission's primary purpose. (Would this give more
protection to the creator than the consumer than now
exists in the law?)
      Recipients of digital transmissions of copyrighted
works would not have the freedom to redistribute the
material. Normally, under the so-called "first sale
doctrine," if Ted sells a book to Alice, she can then
turn around and sell or rent that book to Fred. This
recommendation would prohibit Alice from reselling that
book, if it is in digital form. The theory is that in a
digital environment Alice can keep the book and
distribute it, thereby destroying Ted's market. (The
first sale doctrine was meant to limit the copyright
monopoly so that the holder of the copyright gives up
control once he or she has obtained economic benefit. The
proposal may unhinge that balance. If the prior proposal
is a "look but don't touch" rule, this would be a "touch
but don't sell" rule, says Perritt.)
      Recording artists and record companies would
receive royalties on sound recordings that are
transmitted digitally. It is an anomaly of existing law
that sound recordings don't have a so-called "public
performance" right, as do plays, dances, and movies.
Without this change, consumers could simply download
top-quality recordings from specialized digital services,
bypassing the retail purchase. (The broadcasting industry
will put its full lobbying force behind blocking this
measure, arguing that airplay is a form of free
      A conference will be held on how to preserve the
"fair use" concept of copyright law under which consumers
are allow to use small portions of copyrighted work
without fear of infringement. As more information becomes
available on line, the ability to browse through material
in libraries and schools for free will be curtailed. It
will be possible to meter every usage of a work, even
those that heretofore were protected by fair use
doctrine. (Some copyright holders feel that fair use
developed only because the transactional costs of
charging for small uses outweighed any remunerative
benefit. If advanced metering systems reduce
transactional costs, then why not charge for all uses?)
BALANCING ACT
     Lehman calls these changes "very modest" and built
upon practices proven in other areas. For example, it is
already unlawful to tamper with the encryption devices
that scramble cable signals. And computer software has an
exemption from the first-sale doctrine. Otherwise, to use
the prior analogy, Alice could rent out the software to
Fred and his 15 best buddies, who would then produce
perfect copies for their own use.
     At the same time, the working group tried to balance
the interests of creators, by suggesting modifications in
first-sale and distribution language, and consumers, by
holding the fair use conference. After all, copyright law
is meant to protect the works of creators for the overall
benefit of society.
     Prior to becoming patent commissioner, Lehman was at
Swidler & Berlin. He cut his teeth on the Hill as the
chief legal advisor during the drafting of the 1976
Copyright Act and 1980 Computer Software Amendments.
     That experience, he says, shaped his belief in being
responsive to all sides of a debate. "If I was the
general counsel of McGraw Hill, I might be less inclined
to hold a conference on fair use," Lehman said.
     Still, he recognizes that the law can only do so
much.  "The most you can expect out of the copyright
system is to prevent hemorrhaging," Lehman said. "It
cannot prevent leakage," such as casual pirating of
software for home use.
     That function falls to the marketplace to develop
technologies that can envelop copyrighted material so it
can only be opened by rightful recipients and to
educators, according to Lehman.
     While the working group did not delve seriously into
technological solutions, it will sponsor a second
conference on education. The conference will explore
course work that can be used in schools and libraries.
Just imagine: Intellectual Property Education 101. It's
hard to envision the course being as popular as driver's
      Agencies Participating In Intellectual Property
                  Rights Working Group
Advanced Research Projects Agency
Commerce Department
Council of Economic Advisors
Energy Department
General Services Administration
Justice Department
National Institute of Science and Technology
National Library of Medicine
National Science Foundation
National Security Agency
National Telecommunications and Information
Office of Consumer Affairs
Office of Management and Budget
Office of Science and Technology Policy
Office of the U.S. Trade Representative
Patent and Trademark Office
State Department
Treasury Department
                                      Information Law Alert
    ||           ||||   * a voorhees report *
       ||         ||     || *                   *
       ||         ||     ||  *    718-369-0906   *
       ||         |||||||||   *        voice      *
       ||         ||     ||    *    718-369-3250   *
       ||         ||     ||     *         fax       *
411 First St., Brooklyn, NY 11215-2507         July 8, 1994
*     PLEASE KEEP THIS BOX ATTACHED TO NEWSLETTER    *
Information Law Alert (ISSN-1068-8129) is published 20
times a year by Voorhees Reports, 411 First Street,
Brooklyn, NY 11215-2507.
Subscription rates: E-mail subscriptions are available for
$195 a year. $550 a year for print newsletter. For
information, call 718-369-0906 or 800-369-4840, or fax
718-369-3250. E-mail address: markvoor at phantom.com.
On line: Information Law Alert is available
electronically to subscribers of NewsNet (800-952-0122);
Dialog (800-334-2564); and Dow Jones News Retrieval
E-mail subscriptions are also available through Counsel
Connect (800-952-0122) under the Resources section. Back
issues and bundles of stories are available at
Marketplace.Com. Gopher to Marketplace.Com or use the URL
Copyright 1993 Mark Voorhees. Unauthorized duplication
prohibited by law.
Anybody know where I can get a copy of the Lehman Panel report?
Jim_Miller at suite.com

@_date: 1994-07-14 16:04:40
@_author: Jim Miller 
@_subject: INFOBAHN PANEL SEES WORLD THROUGH [..] BLINDERS 
I'd like to correct a misunderstanding.
In the original "INFOBAHN PANEL SEES WORLD..." post I said that the ILA  report was included in a fax from the Center for Strategic and  International Studies (CSIS).  First, I was not an original recipient of  the fax.  I obtained the fax (and ILA report) via a forwarded e-mail  message so I can't say for sure that the original CSIS fax included the  copyrighted ILA report.  I originally thought the ILA report was part of  the fax.  I now suspect the ILA report was not sent with the CSIS fax but  instead was placed in the forwarded e-mail message by one of the multiple  Just felt like clearing that up.  Nobody at CSIS is demanding an apology  or anything like that.
Ok.  Onward.
The reason I posted the ILA report:
I fear that the desire to minimize electronic copyright violations will  give corporations an incentive to work with government to devise methods  to "control" the content of the Infobahn.  Now, I don't believe they could  ever completely succeed at controlling the content of the Infobahn, but I  do believe they sure as hell will try.
Do you really think the politicians of the world will just sit back and  say "Well, we really can't prevent electronic copyright violations, so we  wont even try"?  More likely they will try many different things.
I'm hoping the ILA report will prompt a discussion of the possible  approaches the government may take to control the content of the Infobahn,  and the side affects of said approaches.
Jim_Miller at suite.com

@_date: 1994-07-15 11:42:48
@_author: Jim Miller 
@_subject: intelligent networks 
There's an interesting article in the July 11'th edition of Communications  Week on page 8 of the Network Monitoring & Testing insert.
Here are some selected paragraphs:
"The convergence of technologies for multimedia promises a new age of  "super-smart networks" to give users the ultimate weapon in monitoring and  "These new multimedia networks...offer sophisticated self monitoring from  a central signal distribution point, or head end, to the customer's  "..hybrid fiber coax networks are, "a bit of a paradigm shift from  previous networks in the sense that a large part of testing is eliminated  and replaced by proactive maintenance in surveillance fashion."
"The hybrid network has monitoring everywhere, and that surveillance  allows us to do proactive maintenance and isolation of problems."
"You can ask the network about itself, and discover things such as whether  its healthy of not, whether it's got a phone call up, how a phone call is  connected through the network or whether or not video is enabled at a  particular home."
"...the network can test the NIU (Network Interface Unit) on the side of  every home to determine whether a problem lies between the central office  and the home or resides in a wiring flaw in the customer's home."
"...the set-top boxes in the network will belong to the service providers.   But for test and monitoring purposes, US West will be able to tap all the  information flowing back from that set-top box into the network, Emmot  With networks like that, who needs a Digital Telephony Bill?
Jim_Miller at suite.com

@_date: 1994-07-26 11:18:48
@_author: Jim Miller 
@_subject: CYPHERPUNKS TO THE RESCUE 
You don't even need encryption.
1) Initialize the garage unit and hand unit with a secret initialization  vector for a crypto-hash function.
2) Push hand unit button to send "open" signal in clear.
3) Garage unit send a large random number in the clear.  While waiting for  reply, garage unit calculates hash of the random number it just sent.
4) Hand unit hashes random number and sends result to garage unit.
5) Garage unit opens door if the received hash matches the local hash.
6) And best of all...YOU CAN EXPORT IT!
Jim_Miller at suite.com

@_date: 1994-07-26 16:08:19
@_author: Jim Miller 
@_subject: CYPHERPUNKS TO THE RESCUE 
Matt Blaze describes a couple of possible attacks against the simple  one-way authenticating garage door opener.  The attacks are basically the  ones that are often suggested against one-way login authentication  protocols.  However, I think the garage door opener scenario is just  different enough that the attacks he describes can be ignored or  eliminated without overly complicating the devices.
(The following idea is a combination of ideas stolen from earlier posts.  plus a couple of new ones.  Anyone following this thread should recognize  the earlier ideas and hopefully mentally credit the original posters.)
The transmission is one-way, from hand unit to base.  There is no  encryption involved, no hash functions, no counter values to transmit, no  loosely synchronized clocks.  The hand unit consists a transmitter, a  memory chip, a simple cpu chip, and some kind of jack or plug used to  initialize the unit.
Initialize the hand unit and base with identical sets of large random  numbers using a wall mounted panel.  The random numbers will be arranged  in groups of, say, ten.  I'll call each group a "family".  Since memory is  cheap, load hundreds of families of random numbers.
Both the hand unit and the base will maintain an internal counter of the  "current family number".  As numbers from a family are used, the "current  family number" is incremented.  If the two "current family numbers" get  off, then the hand unit and base will have to be re-initialized.
To open the door, push the button on the hand unit (duh) to send the first  random number from the "current family".  The base unit opens the door if  the received number is in the "current family" of random numbers.  If the  door opens, the "current family number" counter in the base unit is  incremented and the remaining numbers in the previous "current family"  become invalid for opening.  The "current family number" in the hand unit  automatically increments after about a minute from the time of the button  If the first button push/transmission didn't get received, a second button  push (within a minute) will send another number from the same family,  activating the door.  If the first transmission is successful, but the  driver continues to push the button, the subsequent transmissions are  useless to an interceptor/man-in-middle because the numbers transmitted  are from a family that has just become invalid for opening.
To close the door (within a minute of opening): pushing the button sends  another random number from the original family (i.e. the same family used  to open the door, now invalid for opening).  Since the door is in the open  position, the base unit interprets the transmission as a request to close  the door.  NOTE: the base unit ignores all button pushes while the door is  in the process of opening.
WRINKLE: If you wait more than a minute before trying to close the door,  the hand unit increments to the next family number.  Therefore, when the  door is in the open position, the base unit will actually check the  received random number against both the previous "current family" and the  current "current family".
The major flaw I see in this scheme is that the "current family number" in  the hand unit may become off frequently due to accidental button pushes.
Now that I've gotten to the end of the description, I'm not so sure this  scheme is practical.  I get the feeling that the delayed auto-increment of  the hand unit will create situations that violate the principle of "Least  Surprise".  In other words, the hand unit may not always do what you  expect it to do.
Oh well, I'll post my description anyways in case it induces some better  ideas in others.
Jim_Miller at suite.com

@_date: 1994-07-29 14:13:27
@_author: Jim Miller 
@_subject: AA BBS sysops found guilty 
The list is currently discussing use end-point filtering vs source-point  filtering vs total Net-filtering to control access to various  Net-material.  Well...
I read in the paper today that the sysops who run the AA BBS were found  guilty of distributing pornography.  For those of you who are not familiar  with the case, the AA BBS is an adult BBS residing in California.  A  Memphis TN postal inspector signed on to the BBS under a false name and  downloaded erotic material to his computer in Tennessee.  For various  reasons I cannot fathom, the Californian sysops were dragged into a  Tennessee count, tried by a Tennessee jury, and found guilty.
It is my understanding that the AA BBS sysops try to verify the  "adultness" of their subscribers.  It didn't help them in this case.   "Adultness" wasn't the issue.  "Accessible from Tennessee" was the issue.   It seems that the stuff on the AA BBS was legal for California, but  considered illegal pornography in Tennessee.
What I wonder is why the postal inspector wasn't charged with anything  (well, actually I don't wonder, the question is rhetorical).  Unless I'm  wrong, it was the postal inspector's actions that caused the erotic  material to be downloaded from California to Tennessee.  All the BBS  sysops did was make the stuff available via a dialup BBS.  It's not as if  the BBS sysops personally took the time and effort to physically mail the  stuff to Tennessee.  Is it valid to call an end-point initiated download  an "act of distribution" on the part of the BBS operators?  Apparently it  What is the point I'm trying make?  Well, the list is currently discussing  the benefits of end-point filtering to keep "bad stuff" from getting into  "good homes".  Of course, this implies the "bad stuff" is out there  somewhere waiting to be downloaded.  If this Tennessee verdict holds, just  putting "bad stuff" stuff out there will become a crime, regardless of  where in the US you put it.
"If you upload it, they will come!  (and get you)"
I'm hoping this case will get overturned on appeal to the US Supreme  Court.  However, even that could be a mixed blessing depending on the  wording of the SC decision.  At best, the SC decision could include  language says that persons downloading information are responsible for  ensuring that the material is not in violation of local laws.  At worst,  the SC could say that the operators of information systems are responsible  for insuring material is not made available to persons in certain regions,  if the material violates laws in those regions.  In either case, there is  an implied assumption that the material is somehow conveniently rated  and/or categorized.  This sets the stage for government sponsored rating  systems, and the bureaucracies to enforce them.
Jim_Miller at suite.com

@_date: 1994-07-29 16:38:54
@_author: Jim Miller 
@_subject: AA BBS sysops found guilty 
Exactly what I fear most from this case.  In order to assist users, sysops  may be required to rate and/or categorize all downloadable material using  a rating scale or list of categories determined by some governing body  (FCC?).  If the sysops do not following the guidelines, then they can be  considered participants in the distribution of "bad stuff" to "good  I think "At worst" is not very likely, for the reasons you state.  That's  why I worry more about "At best".
I think the only real good outcome would be that the verdict is overturned  because of some technicality, preventing the case from becoming some kind  of landmark.  However, this would only delay things until the next case.
Jim_Miller at suite.com

@_date: 1994-07-31 14:16:42
@_author: Jim Miller 
@_subject: Children of the Net 
Did you here about the new Steven King novel?  It called "Children of the  Net".  It about a group of children who stumble upon an obscure mailing  list and come under the influence of the evil sysop.  Lots of gore and  suspense as parents try to regain control of their childrens' minds.  I  won't reveal how it ends, but it involves a lot of nifty government  Jim_Miller at suite.com

@_date: 1994-07-31 14:28:12
@_author: Jim Miller 
@_subject: The Terrorists are coming!  The Terrorists are coming! 
Today's broadcast of "The McClaughlin(sp?) Group" had a short segment  discussing the likelihood that terrorists will get and detonate a nuclear  device.  The opinions of the five journalists varied from "not likely" to  "almost certain".  At the end of the show, when the journalists are asked  to make their predictions, one of them said that due to the terrorist  threat, the US needs a larger and more powerful intelligence capability  that ever before.
Jim_Miller at suite.com

@_date: 1994-06-01 11:37:45
@_author: Jim Miller 
@_subject: Clipper in patent trouble? 
Following smb's suggestion, I WWW'ed to town.hall.org and started poking  around.  I found a second Micali "fair crypto-system" patent that also  looks like it would cover Clipper.  It is patent number 05315658 (the  other was 05276737).
I found it by traversing to
and searching using "public key" as the search criteria.
The two patents seem vary similar, but it seems to me that the second  patent more closely describes a system similar to Clipper:
NUM     Claim Number:				7.
Claim 7
     7. A method, using a cryptosystem, for enabling a predetermined  entity to monitor communications of users suspected of unlawful activities  while protecting the privacy of law-abiding users, wherein one user has at  least a secret decryption key, comprising the steps of:
 having trustees hold pieces of information that are guaranteed to include
  shares of a secret decryption key; and
 upon a predetermined request, having a given number of trustees each  reveal the piece of information that includes the share of the secret  decryption key to enable the entity to attempt to monitor communications  to the user suspected of unlawful activities.
NUM     Claim Number:				8.
     8. The method as described in claim 7 wherein upon the predetermined
request all of the trustees each reveal the piece of information.
NUM     Claim Number:				12.
     12. A method, using a cryptosystem, for enabling a predetermined  entity to confirm that users of a system exchange messages encrypted  according to a predetermined algorithm, comprising the steps of:
 providing each user in the system with a secure chip containing at least
  one secret key unknown to the user; and
 having the user send encrypted messages using the secure chip; and
 with each encrypted message sent by a user, having the secure chip also
  send a data string, computed using the secret key, to guarantee the  entity that the encrypted message was generated by the secure chip using  the predetermined algorithm.
NUM     Claim Number:				13.
     13. The method as described in claim 12 further including the steps   providing trustees with pieces of information including shares of a  secret key; and
 upon a predetermined request, having a given number of trustees send
  information including shares of the secret key to allow the entity to
  monitor communications to a suspect user.
 Jim_Miller at suite.com

@_date: 1994-06-02 11:06:31
@_author: Jim Miller 
@_subject: CEB 5 - The Hangover 
Come on, cut the guy some slack!  He fucked up and got suitably flamed.   There's no need to pile it on.
Jim_Miller at suite.com

@_date: 1994-06-08 14:33:14
@_author: Jim Miller 
@_subject: Crime and punishment in cyberspace - 3 of 3 
Rather than spending effort developing technology for self-protection,  wouldn't it be better to spend effort developing a society in which  self-protection is unnecessary?  Think of all the energy and resources  that would be saved if people just got along.  I think the cypherpunks  should redirect their efforts into the fields of genetics and human  behavior.  Better people make a better world.  A committee should be  formed to develop specifications describing a good person.  The committee  could then launch a program to guide society to a future where everyone  met or exceeded the recommended specifications.  The project would include  frequent quality assurance testing to guarantee rapid convergence to the  desired goals.  Individuals who did not meet the specifications would be  removed from the program.
Citizen-Unit Miller

@_date: 1994-06-15 09:52:04
@_author: Jim Miller 
@_subject: NIST's ftp site 
A couple of days ago, somebody mentioned that NIST's public ftp site  contained the FIPS for DES in text form (I think the post was in a reply  to "Massive ITAR Violation!").  Could somebody mail me a copy of that  post, I deleted it and now I wish I hadn't.  Also, what is the Internet  address of NIST's ftp site?
Jim_Miller at suite.com

@_date: 1994-06-15 12:26:41
@_author: Jim Miller 
@_subject: [ANSWER] NIST's ftp site 
Thanks to all who responded to my question.
The answer is:  csrc.ncsl.nist.gov
Also, apparently, source for DES was in Appendix A of the file  "/pub/nistpubs/fips181.txt".  However, it was removed and replaced with  the following:
                                                 Appendix A
This section contained a listing of the source code referenced in the
Automated Password Generator Standard.  This section is not available
in electronic form.
Complete copies of FIPS 181, including this appendix, may be purchased
in hardcopy from the National Technical Information Service (NTIS) via
mail or telephone.
(Same address and phone number for discount prices on quantity orders.)
I wonder if they'll ship to an address outside of the US or Canada?  I  wonder if the people who package and mail the stuff even look at it?
Jim_Miller at suite.com

@_date: 1994-06-16 08:40:11
@_author: Jim Miller 
@_subject: [ANSWER] NIST's ftp site 
The point of my NIST ftp site question was not to find a place to get DES  source, I know I can get DES source in lots of places.  I was just trying  to find out if the NIST site still had FIPS-181 with DES code.  Its  presence on a internationally accessible *US government* site would be an  embarrassment to the anti-export camp.
I know, but I thought it would be kind of ironic if anyone could get DES  source directly from the federal government.
Jim_Miller at suite.com

@_date: 1994-06-20 12:13:09
@_author: Jim Miller 
@_subject: Crypto export legislation defeated in House Intelligence Cmte. 
Has the official report been placed online, and if so, where?
Jim_Miller at suite.com

@_date: 1994-06-21 09:49:27
@_author: Jim Miller 
@_subject: something I've always wondered 
Does DES (or name your favorite encryption algorithm) produce as output  all possible cyphertexts of length L, given all possible conbinations of  keys and plaintexts of length L?
Since there are more combinations of key and plaintext than there are  possible cyphertexts outputs of length L, you know there must be some  combinations of key and plaintext that produce the same cyphertext.
Just curious,
Jim_Miller at suite.com

@_date: 1994-06-28 09:34:23
@_author: Jim Miller 
@_subject: Lotto odds 
I have a completely different attitude towards mega-buck lotteries.  I  seem them as a form of entertainment.   For less than the price of a two  hour movie, I can purchase a ticket that is good for a few days of  Yes, I admit it, although the rational portion of my brain understands the  odds against winning are mostly zero, there still exists a portion of my  brain that says "sure, but mostly zero means partly non-zero".  I derive  pleasure from the daydreams of instant wealth that mega-buck lotteries  make possible.  Therefore, for me, it's not money down the drain.
Jim_Miller at suite.com
[regarding export of crypto]
What's the official government form I need to fill out to prove loss of  revenue from an inability to export a version of our product that was  never produced since we knew in advance we would not be able to export it?

@_date: 1994-03-04 12:06:36
@_author: Jim Miller 
@_subject: more steganography talk 
Stuff that Sergey Goldgaber, Hal, and others wrote induced the  following ideas in my head:
Goal - create a steganography system that hides cyphertext in such a  way that only the true recipient of the message will be able to prove  an encrypted message is hidden within a public message.  Nobody else  will be able to determine if the public message also contains an  embedded encrypted message.  In Hal's words:
If the LSBs of most picture files were truly random, then good  steganography would be trivial.  Anyone could just plop an  unremarkable encrypted message (Stealth-PGP) in the LSB's, starting  at the beginning of the file.  Since one sequence of truly random  bits statistically looks like any other sequence of truly random  bits, nobody would be able to prove the picture file contained a  hidden encrypted message.
Unfortunately, I doubt that most, or even many, picture files have  truly random LSBs.  It would be possible to write frame grabber or  scanner software to purposely place random bits in the LSB of picture  files to generate a source of useful picture files.  When this  software became widely used, good steganography would become trivial.
Unfortunately, I don't have much confidence that this could be pulled  off on a large enough scale.  If it could be done, great, but I'm not  holding my breath.
Assuming the LSBs of most picture files are not truly random, and  wont be any time soon, the next approach to good steganography would  be to figure out how to transform a sequence of random bits (your  encrypted message) into a sequence of bits that resemble the kinds of  bit patterns you see in typical picture files.  If you could do this,  and do it without requiring more secret keys, then good steganography  becomes trivial again.
[Actually, you don't have to transform your random bits into a  *sequence* of typical picture file LSB bits.  The steganography  algorithm could deposit the bits anywhere in the picture file, as  long the process was reversible and the result was undetectable.]
"Reversible, undetectable, without requiring additional keys."
Sounds like a good set of requirements for a steganography system.
I have an idea to help with the "reversible" part and the "no  additional secret keys" part, and it suggests a direction for the  "undetectable" part.
The idea:  Encrypt a widely known value with the recipient's  public-key and use the result as an initialization vector for a  clever transformation/steganography algorithm.  The message recipient  recovers the encrypted message by re-calculating the initialization  vector using the same widely known value and his public-key and  reversing the transformation/steganography step.
The initialization vector will be different for each message  recipient.  The "widely known value" could be a large block of bytes.    A large file of random bits could be shipped with the steganography  executable.  The intent is to make it more difficult and time  consuming for the opponent to determine if a public message contains  a hidden encrypted message.
It's not fool-proof.  The opponent could try to discover a hidden  message by reversing the process using every known public-key.   Worse, an opponent could narrow the search by only trying the  public-keys of suspected recipients.  However, I think it is an  improvement over the techniques being used today.
One significant property this technique does *not* possess is  deniability.  A perfect steganography system will produce results  that will let a recipient claim that they did not know a message  contained a hidden encrypted message (e.g. most picture files had  truly random LSBs).  If somebody sent you a hidden message using your  public-key and the initialization vector technique, your claim of  ignorance might not hold up.  Anybody could use your public-key to  recover the random bit sequence.  They would not recover the contents  of the hidden message, but they would be able to show that your file  did contain what appears to be a hidden message.  It might be enough  to tip the scales of justice against you.
In my mind, the perfect steganography system depends upon either an  environment containing ubiquitous random bit sequences or a  reversible algorithm that can transform non-random bit sequences into  random bit sequences without using encryption (unlikely).  However, I  believe a less-than-perfect, but still useful steganography system  could be created using the initialization vector technique described  Jim_Miller at suite.com

@_date: 1994-03-04 13:41:46
@_author: Jim Miller 
@_subject: even more steganography talk 
Another way to describe a successful steganography system...
I am the opponent.  I possess a collection of files that might  contain hidden encrypted messages.  My task is to determine if they  do contain hidden encrypted message.
A casual inspection of the files does not reveal any bit patterns  that deviate significantly from patterns found is most examples of  these kinds of files.  However, I suspect these files contain hidden  messages that were deposited using a steganography algorithm  initialized from a public-key generated initialization vector.
To test my hypothesis, I will reverse the steganography process using  a large collection of public-keys and then examine the resulting bit  If the steganography algorithm is a good one, reversing the steg  process will produce a sequence of bits that appears relatively  random, even if there is *no* hidden message.
What does "appears relatively random" really mean?  How do you  measure the randomness of a sequence of bits?  I'm not an expert in  this field, but I would guess you could measure the randomness by  attempting to compress the bit sequence.  If the bit sequence does  not compress much, it is relatively random.
How much is "not much"?  In other words, what threshold compression  percentage value should you use to declare one bit sequence random  and another not random?  I don't know.
To generalize, an opponent will perform some kind of test to  determine if the result of reversing the steg process produces a  random bit sequence or a non-random bit sequence.  The test will have  some threshold value below which indicates a random sequence.  If the  output of the reverse steganography step always falls below the  threshold, even if there is no hidden message, then the opponent will  not be able to determine if a file contains a hidden message.
Jim_Miller at suite.com

@_date: 1994-03-04 15:18:38
@_author: Jim Miller 
@_subject: more steganography talk 
I'm not really sure what you mean by "insecure for public keys".  I'm  not trying to achieve "security through obscurity".  I'm trying to  achieve "deniability through obscurity".
If the reverse steg process makes it look like all, or even many,  files contain hidden messages, even when they don't, then you can  plausible deny knowledge of a suspicious bit pattern in any specific  Jim_Miller at suite.com

@_date: 1994-03-05 17:38:04
@_author: Jim Miller 
@_subject: some technical steganography 
One of my assumptions was that the stuff you're trying to hide is not  recognizable.   In one of my posts I used the phrase "unremarkable  encrypted message".  I should have said "unrecognizable encrypted  I assert that an "unrecognizable encrypted message" will be a random  sequence of bits.  Is my assertion correct?  Should I be using the  phrase "high entropy" instead of "random"?
Assume for the moment that there is a way to produce an  unrecognizable encrypted message using public-key encryption.  (I  leave it to the experts to figure out the best way do that.)
I still believe that if the reverse stego process frequently produces  high entropy bit sequences, even if there is no hidden message, then  the steganography system is successful.  If the reverse stego process  *always* produces a high entropy bit sequence, then the steganography  system is perfect.
Of course, this assumes there is no other way to detect a hidden  message besides reversing the stego process and testing the result.
Obviously, if the forward stego process (inserting the bits) leaves  telltale traces, then it doesn't matter what the reverse stego  process produces.
To summrise, I believe a successful steganography system will include  the following steps and have the following properties:
step 1) encrypt you plaintext.
step 2) hide the encrypted message in a public message (duh)
property 1) the result of the encryption step should be a random  sequence of bits.
property 2) the bit insertion process must not leave telltale traces.
property 3) the reverse stego process should product frequent "false  hits".  In other words, the reverse stego process should frequently  produce high entropy bit sequences, even if there is no hidden  Am I correct?
Jim_Miller at suite.com

@_date: 1994-03-06 16:17:41
@_author: Jim Miller 
@_subject: some technical steganography 
I don't understand what you mean by "specific notion of randomness  hasn't been specified".  How many different "notions of randomness"  are there?
I agree.  The output of the reverse stego process should produce  similar results, regardless of the presence of a hidden message.   That's the point I've been trying to make.  I've been attempting to  make that point by describing a hypothetical stego system that, when  run in reverse, produces a random sequence of bits.  I suppose there  could be other hypothetical stego systems that produce non-random  output, but then you would need a decryption system that could  understand and decrypted that non-random output.  I prefer random bit  sequences.  Or perhaps I should say - bit sequences with no apparent  I agree completely.   This is a large part of what makes effective  steganography so difficult to achieve.
Jim_Miller at suite.com

@_date: 1994-03-08 16:02:00
@_author: Jim Miller 
@_subject: INFOPET 
I just called 1-800-INFOPET and sure enough, INFOPET is for real.   The guy who answered the phone was quite proud of their efforts,  claiming to have over a million people (yes, he used the word  "people") in their database (people == pet owners, veterinarians,  animal shelters).
Jim_Miller at suite.com

@_date: 1994-03-08 19:11:08
@_author: Jim Miller 
@_subject: Decoding the Electronic Future 
[..] Law enforcement authorities also say they are looking for no  more authority than they already have--. [..]
Perhaps LE is not asking for more *authority*, but they sure are  asking for more *capability*.  If LE had the capability to do  everything they're currently authorized to do (wiretaps, search and  seizure, follow people, undercover officers, sting operations, obtain  financial records, public security cameras, etc), on a nationwide  scale, the US would truly be a police state.  It's not so much the  amount of "authority" that is keeping the US from being a police  state, it is LE's level of capability.  Don't give LE more  One person's opinion,
Jim_Miller at suite.com

@_date: 1994-03-10 09:18:05
@_author: Jim Miller 
@_subject: The Coming Police State 
Cypherpunks could be the keepers (and distributors) of a "piss list"  of companies that use Clipper/Capstone/Tessera products.
Jim_Miller at suite.com

@_date: 1994-03-10 12:18:01
@_author: Jim Miller 
@_subject: anonymous credit? 
I'm wondering is anonymous electronic credit is possible.  At first,  it seemed to me to be an unlikely thing.  Banks and credit companies  usually want to determine if a person is a good risk, before  extending them credit.  If a person has a bad credit history, they  have a hard time getting credit cards and loans.  How could a bank  determine your credit history if they don't know who you are?   Assuming you did get a credit card using an anonymous id, if you  abused your credit and lost the use of the credt card, you could just  re-apply under a different anonymous id.  There would be no continous  credit history under a single identity.
After thinking about this a little is now seems to me that anonymous  credit is possible, but it wouldn't work like current credit cards.
A few assumptions...
1) there will be more people who pay their bills than people who  don't pay their bills.
2) some people will pay their bills late and be subject to fees and  3) there will always be some people who try to cheat the system by  getting an anonymous credit line, spending it, then disappearing.
Given these assumptions, I can see anonymous electronic credit  working as follows:
Anyone can get an anonymous credit line.  You purchase an anonymous  credit line by forking over some anonymous digital cash up front.   The more you fork over, the higher the initial credit line.  In  return for the upfront cash, you get an anonymous credit id and an  credit line to accompany it.  Your initial credit line will be equal  to the amount of your upfront money, perhaps minus a startup fee.   You can increase you credit line by paying your bills on time, thus  establishing a mini-credit history with that credit company.  The  *rate* of increase is the important factor, which I'll get back to  Instead of working like current credit cards, which give the credit  companies a detailed record of what you purchased, where you  purchased, and when, anonymous credit will work more like a generic  loan.  To tap your credit line, you will use your anonymous credit id  to make withdraws, converting a portion of your credit line into  anonymous cash using a Chaum-ian anonymous cash withdraw protocol.   You can then spend the anonymous cash anywhere you like, without  revealing the details of your spending habbits to the credit company.   The credit company would only by able to track your withdraws and  your repayments.
The credit company might charge a service fee for each withdraw.   They would most likely charge interest, fees for late payment, and  perhaps also a yearly fee.
Basically, it works much like an anonymous bank account, except you  can establish a good repayment history and increase your credit line.   The rate at which the credit company increases your credit line will  depend upon the credit company's assement of the risks invovled in  carrying anonymous credit lines.
The credit company knows that you can simply disappear at any time,  therefore it won't want to increase your credit line too fast.   However, the higher your credit line, the more interest it can earn.   Also, competition between different credit companies will affect the  rate of increase.
If most people repay their credit lines, the credit company will make  money.  If credit lines don't grow too large, too fast, the credit  company will not lose too much money from cheaters.  The credit  company should be able to determine a rate of increase that will make  them a profit.
Does any of this sound reasonable?
Jim_Miller at suite.com

@_date: 1994-03-11 10:51:36
@_author: Jim Miller 
@_subject: What's so bad about a Surveillance State? 
It is obvious to me that many people in the government wish to turn  the US into a surveillance state.  What wrong with that?  Seems like  a lot of good could come from it.
Now that I have you're attention...
E-mail me your reasons why a surveillance state is a good thing or a  bad thing.  I will summarize both the pros and cons and repost them  to the list.
Jim_Miller at suite.com

@_date: 1994-03-16 09:22:32
@_author: Jim Miller 
@_subject: (fwd) Re: What's so bad about a Surveillance State? 
I enjoyed Tim May's post.  I'm hoping you all realize my post was  simply an electronic stick jabbed into the hornet's nest.
I do *not* think a surveillance state is a good thing.  I  deliberately constructed my post to get people's attention.  I want  people (other than just Cypherpunks) to think about life in a  surveillance state.
One goal of mine is to construct a list of all the seemly positive  aspects of surveillance technology.  I don't think the US will  suddenly become a total surveillance state overnight.  I do fear the  US is evolving into one.  Each "positive" use of surveillance  technology may become accepted for one reason or another, because, by  individually, they may not seem too harmful.  However, the cumulative  effect of the incorporation of all these "positive" uses of  surveillance will transform the US (or any country) into a awful  place to live.
It may be easier to persuade people not to support government  sponsored/controlled surveillance technology if all the "positive"  uses are described together, rather than individually.  Then again,  maybe not.  I can at least try.
Jim_Miller at suite.com

@_date: 1994-03-16 13:53:29
@_author: Jim Miller 
@_subject: (fwd) Who's watching you...  01 
What do people think of the idea of creating a news group dedicated  to discussing surveillance technology and its potential impact on  Jim_Miller at suite.com

@_date: 1994-03-18 15:43:34
@_author: Jim Miller 
@_subject: What's so bad about a Surveillance State? 
Not as many as I'd hoped.  And most of them said pretty much the same     pro:  crime would be reduced
   con:  freedom would be eliminated
My primary goal was to generate thought and discussion.  In that  light, my original post did succeed somewhat.  However, I haven't  received enough variety in the responses to construct a good list of  pros.  I think I should rephrase the question and post again.  I should not  ask for the pros and cons of a "surveillance state", rather, I should  ask for the pros and cons of "government sponsored surveillance  I want to get people to think about possible benifits of government  sponsored surveillance.  Not because I like government sponsored  surveillance, but because I feel that thinking about the technology  from a "pro" perspective will give the "anti" (or better, the  "indifferent") people insight into how the pro-surveillance people  might attempt to justify the programs they advocate.
Jim_Miller at suite.com

@_date: 1994-03-28 15:07:01
@_author: Jim Miller 
@_subject: cfp '94 transcript 
(Unknown)                     My name is Barbolin (?) from GRC (?). I have a question concerning the algorithm that is used in the
Clipper Chip, Skipjack..[]..There is a certain amount of conjecture
that in fact the algorithm contains a deliberately encoded weakness
that will allow the NSA, without access to the escrow keys, to be
able to intercept communication in their mission to monitor on-
shore and off-shore communications..[]..
BAKER                         I'll answer it yes or no if you'll
tell me exactly the question.
UNKNOWN                       Does it or does it not contain a
weakness that allows you to intercept the communications without
access to the escrow keys.  BAKER                         No.       ObNit:  As has been said before by others, there's more to  Clipper/EES than just the Skipjack algorithm.  I think simply asking  if "the [Skipjack] algorithm contains a deliberately encoded  weakness" leaves too much room for a "truthful" No answer.
People have posted descriptions of mechanisms that could be used to  leak key information which do not rely on a deliberately weakened  encryption algorithm.  (depends on how broadly you define  A better question to ask would be...
Are there any software or hardware mechanisms, or combinations of  software and hardware mechanisms, present in the Clipper/EES system  that supports or enables decryption of intercepted Clipper/EES  communications without access to escrowed unit keys?
Does that cover it well enough?
Jim_Miller at suite.com

@_date: 1994-03-28 15:36:46
@_author: Jim Miller 
@_subject: cfp '94 transcript 
Ah, of course.  What was I thinking?  After all, this is a national  security issue we're dealing with.  I guess my idealism is showing  Jim_Miller at suite.com

@_date: 1994-05-03 16:21:37
@_author: Jim Miller 
@_subject: Why Digital Cash is Not Being Used 
Perry E. Metzger says
I see that my post was ambiguous.  I didn't mean that "time" would be  the currency, rather, "time" would be the "good" purchased.  For a  given task, one person's time would be more valuable than another  person's time.  Online reputation services would be necessary.
I guess what I'm really trying to say is that I believe anonymous  digital cash is currently more suitable for purchasing services  (time) than for purchasing goods (software, information, bananas,  etc).   This might change in the future when the use of anonymous  digital cash becomes wide-spread.
Jim_Miller at suite.com

@_date: 1994-05-03 20:21:31
@_author: Jim Miller 
@_subject: Announcement RE: Lobbying... 
Arsen Ray Arachelian says:
Section  of the ITAR defines "Defense Service" as:
  (1) The furnishing of assistance (including training) to foreign  persons, whether in the United States or abroad in the design,  development, engineering, manufacture, production, assembly, testing,  repair, maintenance, modification, operation, demilitarization,  destruction, processing, or use of defense articles; or
  (2) The furnishing to foreign persons of any technical data  controlled under this subchapter (see  whether in the United  States or abroad.
Section  defines "Export" as:
  [paragraphs 1 - 4 skipped]
  (5) Performing a defense service on behalf of, or for the benefit  of, a foreign person, whether in the United States or abroad; or
  [paragraph 6 skipped]
I expect that most on this list know that cryptographic software and  systems with the capability of maintaining secrecy or confidentiality  of information (excluding systems using cryptography for  authentication purposes only) are considered export controlled  defense articles.  (See section  Category XIII)
Posting instructions on how to use and/or build cryptographic  software to a mailing list containing foreign persons could be  interpreted by some as a violation the ITAR regulations.
However, I think they would have to stretch the point quite a bit,  considering the fact that it is legal to export cryptography books  and discuss cryptography with foreign nationals in an academic  setting.  Also, the posted instructions could be considered  "information in the public domain" (section  which is *not*  subject to the ITAR regulations.  My hypothesis:  The TLAs could shut down the cypherpunks mailing list  (as it now exists) by dragging all the U.S. list members into court.   The TLAs would probably lose the case, but they would still do a lot  of damage to the lives of the U.S. list members.
Jim_Miller at suite.com

@_date: 1994-05-04 13:45:01
@_author: Jim Miller 
@_subject: Hacking the ITARs 
It not as bad as that.  Well, actually, it's hard to say just how bad  it is because the ITAR regulations regarding cryptography are  contradictory.  It might depends on whether the class teaches only  from a book, or actually lets the foreign students write and  exchanged programs.  Here are the relevant paragraphs from the ITAR:
(the terms to keep track of are - defense article, defense service,  technical data, and information)
  Technical data.
  (5) This definition does not include information concerning general  scientific, mathematical or engineering principals commonly taught in  schools, colleges and universities or information in the public  domain as defined in   Public domain.
  Public domain means information which is published and which is  generally accessible or available to the public:
  (1) Through sales at newsstands and bookstores;
  (2) Through subscriptions which are available without restriction  to any individual who desires to obtain or purchase the published    (3) Through second class mailing privileges granted by the U.S.    (4) At libraries open to the public or from which the public can  obtain documents;
  (5) Through patents available at any patent office;
  (6) Through unlimited distribution at a conference, meeting,  seminar, trade show or exhibition, generally accessible to the  public, in the United States;
  (7) Through public release (i.e., unlimited distribution) in any  form (e.g., not necessarily in published form) after approval by the  cognizant U.S. government department or agency (see also   of this subchapter);
  (8) Through fundamental research in science and engineering at  accredited institutions of higher learning in the U.S., where the  resulting information is ordinarily published and shared broadly in  the scientific community.
  Fundamental research is defined to mean basic and applied research  in science and engineering where the resulting information is  ordinarily published and shared broadly in the scientific community,  as distinguished from research the results of which are restricted  for proprietary reasons or specific U.S. Government access and  dissemination controls.  University research will not be considered  fundamental research if:
  (i) The University or its researchers accept other restrictions on  publication of scientific and technical information resulting from  the project or activity, or
  (ii) The research is funded by the U.S. Government and specific  access and dissemination controls protecting information resulting  from the research are applicable.
These sections seem to state that it is ok to teach about  cryptography, and distribute information about cryptography, even to  foreign persons, as long as the information is in the public domain.   However, these sections do not seem to allow people to freely  distribute cryptographic software, even if that software is in the  public domain.  Why?  The ITAR defines software as *technical data*,  but not *information*.   Only *information* can be in the public  domain, according to my interpretation of the ITAR.
However, according to section  (f), the term *software*  includes system functional design, logic flow, algorithms,  application programs, operating systems and support software for  design, implementation, test, operation, diagnosis and repair.
I can understand using the term *software* for application programs,  operating systems and support software.  But it seems ludicrous to  define system functional design, logic flow, and algorithms as  *software* and not *information*.
Actually, it seems ludicrous to treat software on a disk as technical  data subject to export regulations, but treat software printed in a  book as information in the public domain.
So, can you teach a cryptography class and let your foreign students  write cryptographic software?  Yes, but only on the first Tuesday  following the second full moon after the summer solstice, unless its  a leap year, in which case they can only program in BASIC every other  Saturday, or until you annoy someone at the State Department,  whichever comes first.
Jim_Miller at suite.com

@_date: 1994-05-09 13:31:09
@_author: Jim Miller 
@_subject: ping 
This is an obnoxious, bandwidth-wasting test message.  Please  Jim_Miller at suite.com

@_date: 1994-05-11 11:33:55
@_author: Jim Miller 
@_subject: Tessera, National ID card 
I have recently started exchanging e-mail with the Technology Writer  for the Dallas Morning News (Tom Steinert-Threlkeld).  He is  interested in new angles for Clipper/Tessera articles.  He is currently looking for opinions on whether Tessera (or a  sibling) will be/could be used in the U.S. Card mentioned in  yesterday's RISK column.
If you have anything you would like to say about this, send it to me.   I will collect the replies and forward them to Tom.  Indicate in your  reply if you want me to withhold your name/eaddr.
Jim_Miller at suite.com

@_date: 1994-05-12 12:13:09
@_author: Jim Miller 
@_subject: Message Havens 
Here's an alternative to using tags that need to be agreed upon in  I call it "Indexed Message Pools"
The key ideas:
Each message sent to the message pool will be encrypted in the  recipient's public key. (nothing new here)  The Subject: line for the  message will be the MD5 hash of the message body.
For each message sent, the sender will also send a small, fixed  length "index message" encrypted with the recipient's public key.   The index message will contain the MD5 hash of the full message (and  a confounder?). The Subject: line for the index message will contain  an unencrypted copy of the message hash.  The index message will go  into an index pool.
Instead of downloading the entire message pool to check for messages,  you download the index pool (should be smaller in size).  You would  attempt to decrypt each index message (should be quicker).  A  decryption will yield something that looks like a hash of a full  message.  Compare this with the contents of the index message's  To get the full message, send a request to the message pool server.   The request will contain a list of message hashes.  One of the hashes  will be for the message that was sent to you, the other hashes are  chosen randomly from the collection of index messages you couldn't  The message pool server will send you the messages that have Subject:  lines containing the hashes you sent in the request.  You discard all  the messages that are not for you, decrypt the one that *is* for you,  and there you have it.
This idea scales up a bit, although not greatly.  I can imagine a  network of message pools that maintain a distributed index pool among  themselves.  You can obtain the complete index pool from any of the  message pool servers.  In this scenario, a index message would  contain the message hash plus the address of the message pool that is  holding the associated message.  Small detail: To avoid downloading sections of the index pool you've  already seen, the client-side software will need to maintain a  timestamp or something to keep track of the last index message you've  seen.  Pass this timestamp to the message pool server to request all  index messages since "timestamp".
Comments welcome,
Jim_Miller at suite.com

@_date: 1994-05-14 16:02:12
@_author: Jim Miller 
@_subject: Message Havens, Pools, and Usenet 
I agree with Tim May that Usenet newsgroups can do the job of a  global message pool.  However, it takes too damn long to get a reply.   It typically takes 3 to 4 days before I see replies to messages I  post to Usenet.  I wouldn't want to use Usenet for one-on-one  communication.  I'd prefer a network of indexed message pools like I  described in an earlier post.
Jim_Miller at suite.com

@_date: 1994-05-16 19:10:03
@_author: Jim Miller 
@_subject: Fixing pgp 2.6 
ViaCrypt PGP 2.4 is perfectly legal in the U.S.  U.S. operators can run  key servers that except only version 2.4 and higher keys.  I don't think  RSA has a legal leg to stand on the U.S. key servers reject all keys with  a version number less than 2.4.  Jim_Miller at suite.com

@_date: 1994-05-19 20:21:34
@_author: Jim Miller 
@_subject: cpunks quiz 
It came from one of the documents that John Gilmore received as a result  of one of his FOIA requests.  Here the relevant section from John's  Return-Path: Received: from localhost by toad.com id AA19157; Thu, 30 Dec 93 02:21:27  We sent in an administrative appeal on June 17th, 1993, of various
things that were withheld in the response to our FOIA request.  The
Office of the Secretary of Defense responded on December 21, 1993 --
six months later.  (By law, agencies have twenty business days to
respond to an administrative appeal.  However, agencies regularly
violate all FOIA time limits because the courts have largely refused to
censure agencies for breaking the law, and have refused to force
agencies to follow the law.  I will point this out each time it happens,
largely to educate you -- the general public -- about how pervasive a
problem this is.)
We did an administrative appeal of the parts they withheld and other
documents they did not provide.  The result is that one more doc came
out (a cover sheet for a review copy of the President's actual
directive, which is still classified and has been referred back to the
National Security Council for processing), and the previously withheld
paragraph of the last two memos below is now only blacked out for a  or two.
The newly released text is highlighted with XXXX's and explanation.
[first few letters deteled -jm]
OFFICE OF THE ASSISTANT SECRETARY OF DEFENSE
WASHINGTON DC 20301-3040
COMMAND, CONTROL, COMMUNICATIONS AND
30 APR 1993  (stamped)
MEMORANDUM FOR THE ACTING ASSISTANT SECRETARY OF DEFENSE (C3I)
[first six paragraphs deleted -jm]
(U)	Despite these concerns, the President has directed that the
Attorney General request that manufacturers of communications
hardware use the trapdoor chip, and at least AT&T has been
reported willing to do so (having been suitably incentivised by
promises of Government purchases).  The Attorney General has
also been directed to create a system for escrow of key material.
The Secretary of Commerce has been directed to produce standards
based on the use of the trapdoor chip.
[remainder of letter deleted]

@_date: 1994-05-25 10:48:47
@_author: Jim Miller 
@_subject: IBM's NetSP 
Exportable and limited to 40 bits?  Sounds like they're using RSA's RC2  Jim_Miller at suite.com

@_date: 1994-05-26 12:49:50
@_author: Jim Miller 
@_subject: RSA's "Sink Clipper" poster 
On May 20th, Bob Snyder mentioned he got a free anti-Clipper poster from  RSA.  Interested, I sent an e-mail to info at rsa.com asking how I could get  one of the posters (I included my business mailing address).
Kurt Stammberger from RSA replied "We'll send you one!"
A tube with three of the posters arrived today.  If anyone else want a  poster, all you need to do is ask RSA.
Jim_Miller at suite.com

@_date: 1994-05-26 15:49:35
@_author: Jim Miller 
@_subject: ecash Press Release 
I have a gut feel that this DigiCash(TM) system is going to become a  *really big deal*.  Real electronic cash, portable software-only solution,  free client-side software: sounds like a winning combination.  I'm  Jim_Miller at suite.com

@_date: 1994-05-27 12:22:50
@_author: Jim Miller 
@_subject: (fwd) Re: NSA Helped Yeltsin Foil 1991 Coup 
: It describes how Bush passed on transcripts of encrypted conversations  : between the leaders of 1991's failed Soviet coup to Boris Yeltsin.  :     "As soon as the coup started on 18 August, 1991, the NSA,
:     America's largest intelligence organization was able to decrypt
:     conversations between the coup's two leaders, Vladimir Kryuchkov,
How does the author of the article know that the NSA *decrypted* the  conversations?  For all we know, the NSA learned of the coup from  stratigically placed bugs or other mundane technology.
Jim_Miller at suite.com

@_date: 1994-10-06 15:25:58
@_author: Jim Miller 
@_subject: crypto game idea 
I'd be very impressed if you guys pulled this off.  Not to imply I think  it can't be done, just that it would be a pretty complex system and  success would be impressive.
Can you describe a little of how you're handling the cards?  How do you  keep players from forging cards?  How does a player transfer ownership of  a card to another player?  What's your mechanism for preventing  "double-trading"?  Are card trades anonymous, or fully identified?  How do  you keep somebody from drawing an individual card from their deck more  than once?  How do you prevent somebody from stacking their deck, without  revealing the contents of the deck?  Does the software evaluate the  effects of the cards (encapsulating the rules of the game),  or does the  software just provide the tools for handling digital trading cards?
Cool stuff.
Jim_Miller at suite.com

@_date: 1994-09-06 15:00:30
@_author: Jim Miller 
@_subject: Digital Cash mini-FAQ for the layman 
I recently wrote a description of digital cash for Tom Steinert-Threlkeld,  Technology Writer for the Dallas Morning News.  I figured I might as well  post it here in case there are any newbies that are still coming up to  speed.  Keep in mind that my intended audience is a person who is in touch  with the latest commercially available technology, but is not an engineer,  mathematician, or scientist.  I've intentionally generalized and  oversimplified the descriptions to keep from getting bogged down in the  details.  If I've made any gross errors let me know, but I think most of  the information is accurate.
Q: How is digital cash possible?
A: Public-key cryptography and digital signatures (both blind and  non-blind signatures) make digital cash possible.  It would take too long  to go into detail how public-key cryptography and digital signatures work.   But the basic gist is that banks and customers would have public-key  encryption keys.  Public-key encryption keys come in pairs.  A private key  known only to the owner, and a public key, made available to everyone.   Whatever the private key encrypts, the public key can decrypt, and vice  verse.  Banks and customers use their keys to encrypt (for security) and  sign (for identification) blocks of digital data that represent money  orders.  A bank "signs" money orders using its private key and customers  and merchants verify the signed money orders using the bank's widely  published public key.  Customers sign deposits and withdraws using their  private key and the bank uses the customer's public key to verify the  signed withdraws and deposits.  Q: Are there different kinds of digital cash?
A: Yes.  In general, there are two distinct types of digital cash:  identified digital cash and anonymous digital cash.  Identified digital  cash contains information revealing the identity of the person who  originally withdrew the money from the bank.  Also, in much the same  manner as credit cards, identified digital cash enables the bank to track  the money as it moves through the economy.  Anonymous digital cash works  just like real paper cash.  Once anonymous digital cash is withdrawn from  an account, it can be spent or given away without leaving a transaction  trail.  You create anonymous digital cash by using numbered bank accounts  and blind signatures rather than fully identified accounts and non-blind  [To better understand blind signatures and their use with digital cash, I  highly recommend skimming through chapters 1 - 6 of Bruce Schneier's book  _Applied Cryptography_ (available at Taylor's Technical Books).  It is  quite readable, even to the layman.  He doesn't get into the heavy-duty  math until later in the book.  Even if you don't write a digital cash  column in the near future, I still recommend reading through chapters 1 -  6 of _Applied Cryptography_.  Bruce does a very good job of describing the  wide variety of interesting things you can do when you combine computers,  networks, and cryptography.]
There are two varieties of each type of digital cash: online digital cash  and offline digital cash.  Online means you need to interact with a bank  (via modem or network) to conduct a transaction with a third party.   Offline means you can conduct a transaction without having to directly  involve a bank.  Offline anonymous digital cash is the most complex form  of digital cash because of the double-spending problem.
Q: What is the double-spending problem?
A: Since digital cash is just a bunch of bits, a piece of digital cash is  very easy to duplicate.  Since the copy is indistinguishable from the  original you might think that counterfeiting would be impossible to  detect.  A trivial digital cash system would allow me to copy of a piece  of digital cash and spend both copies.  I could become a millionaire in a  matter of a few minutes.  Obviously, real digital cash systems must be  able to prevent or detect double spending.
Online digital cash systems prevent double spending by requiring merchants  to contact the bank's computer with every sale.  The bank computer  maintains a database of all the spent pieces of digital cash and can  easily indicate to the merchant if a given piece of digital cash is still  spendable.  If the bank computer says the digital cash has already been  spent, the merchant refuses the sale.  This is very similar to the way  merchants currently verify credit cards at the point of sale.
Offline digital cash systems detect double spending in a couple of  different ways.  One way is to create a special smart card containing a  tamper-proof chip called an "Observer" (in some systems).  The Observer  chip keeps a mini database of all the pieces of digital cash spent by that  smart card.  If the owner of the smart card attempts to copy some digital  cash and spend it twice, the imbedded Observer chip would detect the  attempt and would not allow the transaction.  Since the Observer chip is  tamper-proof, the owner cannot erase the mini-database without permanently  damaging the smart card.
The other way offline digital cash systems handle double spending is to  structure the digital cash and cryptographic protocols so the identity of  the double spender is known by the time the piece of digital cash makes it  way back to the bank.  If users of the offline digital cash know they will  get caught, the incidents of double spending will be minimized (in  theory).  The advantage of these kinds of offline systems is that they  don't require special tamper-proof chips.   The entire system can be  written in software and can run on ordinary PCs or cheap smart cards.
It is easy to construct this kind of offline system for identified digital  cash.  Identified offline digital cash systems can accumulate the complete  path the digital cash made through the economy.  The identified digital  cash "grows" each time it is spent.  The particulars of each transaction  are appended to the piece of digital cash and travel with it as it moves  from person to person, merchant to vender.  When the cash is finally  deposited, the bank checks its database to see if the piece of digital  cash was double spent.  If the digital cash was copied and spent more than  once, it will eventually appear twice in the "spent" database.  The bank  uses the transaction trails to identify the double spender.
Offline anonymous digital cash (sans Observer chip) also grows with each  transaction, but the information that is accumulated is of a different  nature.  The result is the same however.  When the anonymous digital cash  reaches the bank, the bank will be able to examine it's database and  determine if the digital cash was double spent.  The information  accumulated along the way will identify the double spender.
The big difference between offline anonymous digital cash and offline  identified digital cash is that the information accumulated with anonymous  digital cash will only reveal the identity of the spender if the cash is  double spent.  If the anonymous digital cash is not double spent, the bank  can not determine the identity of the original spender nor can it  reconstruct the path the cash took through the economy. With identified digital cash, both offline or online, the bank can always  reconstruct the path the cash took through the economy.  The bank will  know what everyone bought, where they bought it, when they bought it, and  how much they paid.  And what the bank knows, the IRS knows.
By the way, did you declare that $20 bill your Grandmother gave you for  your birthday?  You didn't?  Well, you wont have to worry about forgetting  those sorts of things when everybody is using fully identified digital  cash.  As a matter of fact, you wont even have to worry about filing a tax  return.  The IRS will just send you a bill.
Jim_Miller at suite.com

@_date: 1994-09-22 16:24:54
@_author: Jim Miller 
@_subject: It's MEME time!!! 
I thought I'd jump onto the meme-creation bandwagon before it gets too     Cryptography - it's not just for governments anymore!
                ---
   Clipper and the Wiretap Bill: salvos in the War On Privacy!
                ---
   The price of security is continuous surveillance.
                ---
   Denning's Dilemma: Privacy or Oppression. There's no middle ground.
                ---
   Surrender Dorothy!

@_date: 1994-09-28 10:00:25
@_author: Jim Miller 
@_subject: FORTRESS REMAILERS 
To my mind, remailer vulnerability starts with the Net addresses used to  send to them and send from them.  It seems to me that a fortress remailer  must have solve two problems:
   1) Getting a message to the remailer without knowing the remailer's Net     2) Sending a message from the remailer without revealing a Net address.
Problem 1 can be easily solved by having users send messages to various  new groups the remailer scans.  The messages would be encrypted with the  remailer's public key.  The remailer continuously scans for new messages  encrypted with its public key.  When it finds one, it decrypts it and  processes it.
Problem 2 it the tricky part.  How can the remailer inject a message back  into the public Net without revealing its Net-location?  If the remailer  could sovle this problem, then why couldn't everybody use the same  solution, eliminating the need for remailers?  The one possibility is that  the solusion requires something that most average users can't do or can't  acquire economically (i.e. most everybody can grow their own food, but why  I haven't come up with any really good ideas here.  Here are a couple  a) Using various hacker tricks to forge "From:" e-mail addresses.
b) Use short-lived addresses.  Set the remailer up some how so it can  frequently acquire new e-mail addresses.  Each address would only be used  to forward a limited number of messages, and then it would be abandoned.
Jim_Miller at suite.com

@_date: 1995-12-14 08:19:42
@_author: Jim Miller 
@_subject: Attacking Clipper with timing info? 
Could this timing attack be used to obtain the various keys used by  Clipper devices?
Jim_Miller at suite.com

@_date: 1995-12-14 14:15:15
@_author: Jim Miller 
@_subject: Attacking Clipper with timing info? 
That brings up an issue I occasionally think about...At what point does  NSA's secrecy become more of a liability than an asset.  Should the NSA  reveal flaws in crypto-systems in wide use here in the US to protect US  companies and individuals from attack or should they remain quite so they  can exploit them in the interests of national security?
Jim_Miller at suite.com

@_date: 1995-12-15 01:10:11
@_author: Jim Miller 
@_subject: Attacking Clipper with timing info? 
That was indeed what I was wondering.  I expect we wont have to wait too  long before we hear whether Clipper chips require the same or a different  amount of time to encrypt/decrypt.  Should be interesting.
Jim_Miller at suite.com

@_date: 1995-12-16 17:05:29
@_author: Jim Miller 
@_subject: Java scripts to caputure remote timing info? 
I don't enough about Java to know if it is possible, but it's something to  think about.
Jim_Miller at suite.com

@_date: 1995-12-18 20:02:48
@_author: Jim Miller 
@_subject: Java and timing info - second attempt 
I asked about using Java scripts to capture remote timing info before and  got no response.  I assume everyone thought it was a stupid question.   Therefore, I'll ask it again.
The thing that makes Java a big deal is that you execute other people's  code on your machine.  You browse a Java-enhanced Web page, click on  something interesting, suck across an applet, and execute it on your  machine.  This setup enables a bunch of nifty interactive Web stuff.
Turn the picture around:  You setup a Java-enhanced Web page, include some  interesting buttons to click, write some clever applet, and people around  the world suck your applet onto their machine and execute it.
Combine this with some a standard crypto API for doing Web-based digital  signatures or authentication or encryption and you may begin to see some  Would it be possible to create a Java applet that causes the client  machine to sign or encrypt something with their private key, and then send  back timing info?
For the answer to be YES a few things need to be true.  There needs to be  some sort of standard crypto API in use that can be accessed by a Java  script, and Java scripts need to be able to capture and send back timing  info.  Does anyone on this list know enough about Java to know if it can  do any of these things?
Jim_Miller at suite.com

@_date: 1995-12-21 22:49:28
@_author: Jim Miller 
@_subject: Attacking Clipper with timing info? 
I don't know myself.  That's why I still occasionally think about it.  It  is sometimes comforting to think there is a US agency with the expertise  of the NSA.  At other times I wonder if we're getting the most for our tax  money.  Unfortunately, it would be impossible to generate a meaningful  cost/benefit analysis even if the NSA was not a secret agency.
Of course, if we did not pax taxes there would be no need to wonder if  we're getting our money's worth.  A self-funded,for-profit NSA?  Now  there's a liberatarian idea if I ever heard one.
Jim_Miller at suite.com

@_date: 1996-02-13 20:31:55
@_author: Jim Miller 
@_subject: A Cyberspace Independence Refutation 
remember the days when the net was composed of a
 UUCP connections eventually
Don't forget FIDONet.
Jim_Miller at suite.com

@_date: 1996-02-25 07:34:36
@_author: Jim Miller 
@_subject: "E-Money" is trademarked 
FYI, I learned tonight that Electronic Funds Clearinghouse, Inc., holds  the trademark "E-Money" which is licensed to E-Money, Inc. a Delaware Corporation.  See the Web page I guess I will have to rename my E-Money mini-FAQ.
Jim_Miller at suite.com

@_date: 1996-01-17 16:02:15
@_author: Jim Miller 
@_subject: Article on E-money 
I have no Web site of my own.  You probably saw my E-Money FAQ on someone  else's site and thought I was the site manager.  That's ok, you're not the  first to make that mistake.
I'll be happy to answer your questions as best I can.
Rather than answer each question individually, I'll just ramble on about  e-money for a bit and hopefully I'll convey some interesting opinions.
The first thing to recognize is that there are two arenas to consider when  discussing e-money; the on-line arena and the "about town" arena.  I'll  first discuss the "about town" arena.  It will take a decade or more, but  eventually e-money purchases will be as common as credit card purchases.   People will carry e-money cards right along side their credit cards.   Rather than handing over a few dollar bills, people will insert e-money  cards into readers.  ATM machines will provide an option to charge up  e-money cards.  Credit card systems and e-money system will co-exist, and  in fact you will be able to easily transfer value between credit cards and  e-money cards.  It is quite likely that the major credit card companies  will issue multi-purpose super-cards(tm) that can act as either credit or  e-money cards, reducing the number of cards people carry.  Paper money  will never go away completely (unless government stops backing paper  money), but there are a variety of reasons most people will switch from  using paper money to using e-money cards:
   1) The card can easily keep a record of all a person's e-money  purchases.  The record can be up-loaded into popular PC-based money  management software.
   2) The card can hold "change" and well as "large bills".  No need to  carry around a pocketful of coins.
   3) The money in the card can't be spent unless the proper PIN number  (or thumb print, etc) is provided.  Paper money can be spent by any thief.   Some e-money cards may allow you get reimbursed for lost or stolen  e-money.  Others may only be able to "void" the lost money.
   4) Some e-money system may allow you to make back-up copies of your  e-money, in case the card gets damaged.
   5) Paper money wears out, gets torn, etc.
   6) Paper money, even in moderate quantities, is bulky.
   7) Paper money has to be counted, and people must wait around while  change is tallied up.  Mistakes could be made.  E-money cards will be  relatively fool-proof and will work as fast or faster than current credit  And now the online arena...
People will be able to purchase inexpensive devices that can be connected  to their PC to transfer e-money from card to computer, and vice versa.   This device may become a pseudo-standard peripheral, much like a sound  card is today.  People will be able to purchase items securely over the  Internet using either credit card numbers or e-money.  A good question to  ask might be "If people can make secure credit card purchases over the  Internet, why would they use e-money over the Internet?"  There are a  variety of reasons people might use e-money rather that credit cards      1) The item may cost only a few pennies, or less.  Not enough to  warrant using a credit card.
    2) The vender may not accept credit cards.
    3) You may not wish to give the vender your credit card number until  you have established that the vender is trustworthy.
    4) You may wish to pay in "cash" rather than add to your credit card      5) You may wish to avoid revealing your "about town" identity to the  Why might a vender accept e-money, but not credit cards?  Well, it costs  money to accept credit cards.  It will probably cost less money to accept  e-money.  Very small companies that exist only on-line may not want to pay  the expense to hook up to the credit card infrastructure.  Cheap e-money  will lower the barriers to entry for online business.  Huge numbers of  very small players will come online.  The meaning of the term online  "business" will change as it becomes easy and economical for individuals  to charge very small amounts for data or services.  When something become  cheap and easy (ala World Wide Web), it will become very popular.  When it  is also a way to make money, it will become common-place.  Most everyone  with a PC will find a way to make a little money on the side by selling  something online.  Maybe people will sell idle CPU time or unused disk  space on their home PCs to people using future Java-like distributed  applications.  All this new economic activity will of course be taxed.  That is, if  government has any say in the matter.  And you can be sure government will  do its best to have a say.  From reading my E-money FAQ you know there are  two possible kinds of e-money systems: identified and anonymous.  For both  tax reasons and law enforcement reasons, governments will do their best to  insure that anonymous e-money systems fail in the marketplace. Perhaps by  outright banning them, or by subsidizing identified e-money systems, or by  not insuring bank accounts that accept anonymous e-money, or by mandating  accounting or identification systems that preclude the use of anonymous  e-money.  I'm sure there are other tactics government could use.
Should people care?  What's so bad about identified e-money?  What's so  good about anonymous e-money?  Most people don't seem terribly upset about  the personal information they reveal by using credit cards so it is  reasonable to assume most people will not be upset about the personal  information they reveal by using identified e-money.  I predict that  anonymous e-money systems will not fare well in the marketplace for the  following reasons:
    1) Government pressure against anonymous e-money.
    2) Identified e-money systems are easier to build.
    3) Certain technologies necessary for anonymous e-money are patented.   E-money system builders will tend to roll their own identified e-money  systems, rather than pay fees or royalties to the patent holders.
    4) The financial risks associated with anonymous e-money are more  complex and harder to evaluate than the financial risks associated with  identified e-money.  The conservative money will tend to back systems with  the lower perceived risk, even if the risks associated with anonymous  e-money are manageable.
    5) Identified e-money systems can provide the same external features  and conveniences as anonymous e-money systems and will most likely become  widely deployed sooner than anonymous e-money systems.  Once people become  accustomed to identified e-money systems, it is unlikely they will push  for a change to anonymous e-money systems.
It is hard for me to explain the reasons why anonymous e-money is  preferred over identified e-money.  The reasons fall into the "Do you  trust government, or not" category.  "Do you want the government to know  about every penny you spend?"  These sort of concerns are easily dismissed  as alarmist.  After all, say many people, if the government gets out of  hand we can just vote in different law makers.  That's how democracy  works.  Well, I don't believe it would be that easy.  Imagine how hard it  would be to get rid of social security cards.  The information conveyed  via identified e-money is directly useful to tax agencies and law  enforcement.  The information has other governmental and commercial uses,  too.  As with social security numbers, the infrastructure that utilizes  identified e-money information will become larger the longer the systems  are in use.  After a time, it will take a ideological revolution to  convince government and business it must do without such detailed personal  information.  And revolutions, ideological or otherwise, are never  painless.  I hope I'm wrong and identified e-money is nothing to worry  about.  And maybe big government can be trusted. :-)
Jim_Miller at suite.com
P.S. I CC'ed this reply to the cypherpunks mailing list.  You might get  additional replies from people on that list.
             The Internet is a land bridge for memes

@_date: 1996-01-18 07:01:06
@_author: Jim Miller 
@_subject: underground digital economy 
The existing underground economy uses the same money as the aboveground  economy (i.e. paper money, for the most part).  Could a significant  underground digital economy develop if the aboveground digital economy  used only identified e-money?
Jim_Miller at suite.com
             The Internet is a land bridge for memes

@_date: 1996-01-20 00:48:00
@_author: Jim Miller 
@_subject: underground digital economy 
This is the part that bothers me.  Wouldn't a gateway between anonymous  e-money and identified e-money would stick out like a sore thumb to  agencies tracking the flow of identified e-money?  Wouldn't identified  e-money trails start and/or terminate at the gateway?  Once the gateway is  discovered, all clients on the identified e-money side of the gateway  would be discovered.
I think the gateway could only succeed if there was a way to perform the  conversion anonymously.  But how do you anonymously generate/propagate  identified e-money?
There is probably an obvious solution, but I'm not devious enough to see  it.  One unstated assumption I have that may be confounding me is that I  assume the identified e-money system will completely replace paper money,  which will then be "discontinued".
Jim_Miller at suite.com

@_date: 1996-03-05 07:05:39
@_author: Jim Miller 
@_subject: art-stego 
The recent discussion "Chaff in the Channel" got me thinking about an  alternative to hiding random bit streams in picture files.  The goal of  steganography, as I see it, is to provide plausible deniability.  The  problem with hiding bit streams is that you can never be sure if the  opponent has developed an analysis technique to prove a particular file  contains a suspicious bit pattern.
The alternative to hiding bit streams is to not hide them.  Use them to  generate pretty pictures.  For example, modify a fractal image generator  to accept a bit stream as input.  Use the bit settings to influence the  values used to iterate the fractal function.  You don't have to use  fractals, any function that produces pretty pictures would probably work  as long as there was a way to extract the bit stream from the final  picture.  Brute force would probably work fast enough for humans.
One possibility is a screen saver that produces an "infinite" variety of  pretty pictures by generating a pseudo-random bit stream and using it to  help generate the next background picture.  Occasionally, the picture  might be so cool you will want to send it your friends or post it on the  Net or just keep it around to look at.
The goal is to create an innocent reason for passing around unique images  that contain random bit streams so we don't have to worry if somebody  finds the bit stream.  If you live in a country that doesn't outlaw  abstract art you have plausible deniability.
Jim_Miller at suite.com

@_date: 1996-03-08 01:48:47
@_author: Jim Miller 
@_subject: art-stego 
bit patterns"
You are assuming that the noise bits have the same statistical properties  as cyphertext.  I would be very surprised if this were the case.  It takes  special effort to achieve good random bit streams.  Image scanners may do  this by accident, but then again, maybe they don't.  This uncertainty is,  in my opinion, the fatal flaw in image-based steganography.  The same  reasoning applies to audio-based steganography.  Unless the devices were  specially designed to insert cryptagraphically useful bits in the output  (or, as Tim May suggested, good garbage bits are inserted later), then you  should not rely on the pictures or audio files to keep your messages  As an alternative to trying to hide bits, I proposed not hiding them at  all, but instead creating an innocent reason for passing around files that  contain, in some way or another, obvious random bit streams.  The first  idea that came to mind was to use the random bit streams to create pretty  fractal pictures.  I soon realized that any function that produces pretty  pictures would do the trick as long as there was a way to recover the  random bit stream given only the picture and the function.  Perhaps it  would be possible to use random bit streams to generate cool BioMorphs  (ala "The Blind Watchmaker").
If enough people start passing around pictures generated from meaningless  random bit streams, then other people could use this traffic to covertly  exchange pictures generated from meaningful random bit streams.
You could always claim you didn't know it was there, that you just  downloaded the picture out of curiosity.  It might help, depending on what  country you live in.
Come to think of it, if the picture files were larger than the random bit  streams, people very well might send just the random bit streams.
"Hey Bob, take a look at the picture this creates when you feed it to the  XYZ function (coefficient values A, B, and C)."
Jim_Miller at suite.com
P.S. In case anyone is wondering, the reason there is a large delay  between a post from me and a reply from me is that I'm not actually on the  mailing list.  I read the messages by pointing my news reading at
