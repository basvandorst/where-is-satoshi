
@_date: 2012-12-07 17:45:10
@_author: Paul Rabahy 
@_subject: [tahoe-dev] LAFS Weekly Dev Hangout notes, 2012-12-06 
First off, let me say that I enjoyed listening in to the hangout even
though I couldn't participate. For the last year or 2 I have been thinking
about building a distributed, untrusted storage system. When I found
Tahoe-lafs, I was ecstatic that it had already implemented about 90% of the
ideas that I had thought of and that it sounds like the remaining 10% are
being worked on.
I have some comments on Zooko's Proof-of-Retrievability paper.
1. Great job writing this. It was very easy to read and get up to speed
without having to read 10 other whitepapers first to understand the basics.
(I have some background in cryptography/secure computing from college)
2. I completely agree with the 3 levels of bad behavior (Greed, Malice, and
Adaptive Malice). In addition, I believe there should be a fourth level
which I will call "Accidental Greed". In this case, the sever stores the
data, responds to all requests properly, but one day fails (either a POR or
GetData request) for some unknown reason. This server will acknowledge
their mistake and attempt to reverse it once they are notified (restore
backups, patch bug, etc.).
2a. For POR, Zooko nailed this. We don't have to care about "Accidental
Greed" at the protocol level because if we cover our-self for Malice or
Adaptive Malice we already have a solution.
3. I am convinced that to prevent Malice or Adaptive Malice, there cannot
be a difference between running a POR or GetData. If there is either type
of attacker could respond correctly to the POR but incorrectly to the
3a. For my use cases I feel that having POR and GetData can have different
traffic patterns and not affect my experience as a customer. I realize that
will introduce a gap in the protocol so that Adaptive Malice could defeat
the POR. I would like for POR to cover me 90% of the time, but occasionally
I will actually download a file and will be able to catch the Adaptive
Malice server at that point. (This might seem like a contradiction, but
Tahoe already has the enormously powerful feature of erasure coding to
protect me from an occasional malicious server even if POR fails.)
4. Unfortunately Zooko lost me in Part 2b and 3. I understand the trade-off
between "(a) reduced performance for downloads, and/or (b) increased
bandwidth usage for verification", but I was never able to understand how
Tahoe is supposed to be convinced that a share is retrievable without even
contacting the server containing the share.
4a. Several times during the hangout, it was mentioned that increasing N
and K would help POR to work better. I don't follow that argument. I agree
that setting N higher increases the retrievability of a file (because it
can withstand more malicious servers), but I don't see how increasing
either of these will help me single out the malicious server.
5. I need to do more reading on the current Tahoe verify system, but I
don't understand how Tahoe can verify a file using B Bandwidth where B is
less than F Filesize.
5a. Using the Tahoe defaults (K = 3, N = 10) and assuming that F = 1(MB) it
will take 3.33(MB) to store all ten shares. Each share will take .333(MB)
to store. To verify the file, wouldn't you have to retrieve at least K
shares therefor B would equal .333(MB) * 3(K) = 1MB(F). To me, it seems we
didn't save any bandwidth.
5b. (Ah, just thought of this as I was writing). Does Tahoe maintain some
sort of tree/share based hash so that it can verify individual shares or
parts of a share without verifying the entire file? If so, I can see the
bandwidth savings.
6. I agree that TOR/distributed verification could help in the case of an
Adaptive Malicious server, but until I have a clearer understanding of my
points 5 and 6, I'm not sure if this description of POR will be have a
benefit for my use case.
Hopefully these points make sense. Let me know if I made anything confusing.
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org
