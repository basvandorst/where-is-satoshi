
@_date: 1994-08-01 15:23:54
@_author: Richard Johnson 
@_subject: Anonymous message failed (wrong password) (fwd) 
Julf -
You need to add something to that message.  I made no mistake, and no-one
has changed my password.  I simply mailed to a mailing list that has an
anXXXXX at penet.fi address subscribed.  Your service is too insecure to
notice :-), and automatically 'out's anyone who unknowingly posts to such
a list.  All someone has to do is subscribe via an anon ID, and via a
non-anon ID, then compare messages to associate anon IDs with regular
How about adding: "Either you mailed to a list to which an anonymous ID
has been subscribed, you have made a mistake, or...."
I'd also strongly suggest that you stop automatically allocating anon IDs
for folks who don't mail directly to your service.  Perhaps you could
reduce the load on your machine (and increase user security) by sending
directly to the bit-bucket any messages where the Sender: and From:
headers don't at least come from the same domain?

@_date: 1994-08-10 19:36:48
@_author: Richard Johnson 
@_subject: Speed of Curve Encrypt (Macintosh IDEA file encryption) 
How fast is Curve Encrypt 1.1?
Here are times to encrypt and DOD Wipe a 685,557 byte file on various
Macintoshes (System 7.1, booted with extensions off).  Disk speed is the
driver for wiping encrypted files, of course.  A fast non-fragmented disk
can also shave a percent or two off of encryption times (I used the
fastest disk on each Mac for my tests). Otherwise, the faster your CPU,
the better.
Native code on PowerMacs really blazes, even on my crude development port
to PowerPC.  Version 1.2 of Curve Encrypt will be buildable for PowerMacs
(at least using the Metrowerks compiler).  Be patient, for it is coming
soon to an export-controlled, Free-World-prohibited ftp site near you.
Machine & Disk  Compiler     Times (Averages over 5 encrypt operations)
 ------------    ------        Encrypt or Decrypt Encrypt & DOD Wipe
PowerMac 8100/80                ----------------   ----------------
  Quantum LPS270S
                Metrowerks 68k         17                23
                Think C 7 (&5)         16                22
                Metrowerks PPC          5                11
PowerMac 7100/66
  Quantum LPS270S
                Metrowerks 68k         22                29
                Think C 7 (&5)         20                27
                Metrowerks PPC          6                13
Quadra 840AV
  Seagate ST11200N
                Metrowerks 68k         11                17
                Think C 7 (&5)         10                16
Quadra 950
  Seagate ST11200N
                Metrowerks 68k         12                18
                Think C 7 (&5)         11                17
Quadra 700
  Seagate ST11200N
                Metrowerks 68k         12                17
                Think C 7 (&5)         13                18
  Hitachi DK515C
                Metrowerks 68k         20                27
                Think C 7 (&5)         21                28
Original (Think C 5) executable size:  63,454 bytes
Think C 7 executable size:             63,378 bytes
Metrowerks 68K executable size:        70,600 bytes
Metrowerks PPC executable size:        86,978 bytes
Compiler notes:
The Think C 7.0.3 was upgraded from version 6 via the patches on umich and
sumex-aim archives.  (I'm still pissed about Symantec's $100-too-high
pricing on an "upgrade" to a broken product, and won't buy a completely
new copy again like I stupidly did for version 6.  In fact, the only thing
that keeps me using Symantec stuff at all is CMaster 2.0, from Jersey
Scientific.  Ahem, sorry about the rant.  But get CMaster. :-)
The Think C 5.0.4 was my last stable version of THINK C.
The Metrowerks 68k was 1.0.1, from the CW 3.5 release
The Metrowerks PPC was 1.0.1, from the CW 3.5 release

@_date: 1994-08-14 16:22:24
@_author: Richard Johnson 
@_subject: Ecash beta test 
I've sent a few messages to the E-Cash address.  Never got so much as
an autoreply filled with propaganda.  My conclusion is that E-Cash
for regular folks is going to remain tantalizing vaporware for a long
while to come.
I wish them luck, but I'm not going to hold my breath waiting for the
authentication problems and lack of client availability to get fixed.
(Don't know what I'm referring to?  Just poke around on the E-Cash
web site...)

@_date: 1994-08-17 01:15:42
@_author: Richard Johnson 
@_subject: CompuTrace and the like 
Yanked from today's Edupage:
We need 'nyms with electronic reputations, and true electronic cash to
protect the "real" us from things like CompuTrace (not to mention the
USPS practice of selling to junk mailers whatever info you give them on
address change cards).
The alternative is yet another law...
I don't know whether to applaud the House bill, or curse.  Anyone have
the bill number?

@_date: 1994-08-27 01:18:06
@_author: Richard Johnson 
@_subject: Crypto Panel at Rocky Mtn. Inet User's Group 
Just a short announcement culled from the minutes of the last RMIUG
meeting.  It's of greatest interest to those of us in CO.  I
suppose the panelists on the list already know about it (but one
can never be completely sure).
The RMIUG meetings are held at the NCAR mesa facility in Boulder, CO
at 7pm on the 2nd Tuesday of the month.  To get there, find Table
Mesa (yeah, stupid name) or South Boulder Road, and head West on it
'till you reach the end and find the building Woody Allen rapelled
out of in Sleeper.  The auditorium is just inside the main entrance.
Show up at 6:30 for schmoozing.

@_date: 1994-12-02 07:51:55
@_author: Richard Johnson 
@_subject: Brands excluded from digicash beta 
But, for the most part out here, we can't tell.  I, too, have heard only
deafening silence from e-cash folks in response to my multiple queries and
requests for more information on their system, let alone joining their beta
test.  Like Hal Finney, I just assumed I was being ignored because I didn't
have enough clout.  As a result, I just gave up on e-cash as something I
wouldn't find useful any time soon.
I do understand the difficulties in dealing with releases on multiple
platforms.  Still, you might at least acknowledge e-mail from people who
want to help make your system work, who want to use it.  A form letter at
least, explaining that you don't need their help right at the moment but
will let them know when a system for their platform is being released for
a wider beta test, well, that might be a real good idea.  Ignoring people
after you've publicly asked for beta testers and said "mail to <...> for
further information" is definitely not a good idea.
My count:  4 messages over about 6 months asking for more info, no replies.
My reaction:  Well, it was a nice idea.  Maybe I'll check back in a couple
of years, when there might actually be someone there.
PS - I'm not posting this to two lists because I've seen that's the only
way to squeeze a response out of DigiCash, but you can be forgiven for
thinking things like that. ;-)

@_date: 1994-07-04 00:37:21
@_author: Richard Johnson 
@_subject: PGP 2.6 legal_kludge 
Because the license prohibits nuking the "legal_kludge".  You wouldn't
want to violate the MIT PGP 2.6 license, now would you. ;-)

@_date: 1994-07-22 13:01:47
@_author: Richard Johnson 
@_subject: clipper and export 
crypto export prohibitions enhancing national security is just a smoke
screen.  While there may be a germ of truth to those kinds of statements,
the _real_ reason for propping export controls up when they are no longer
effective, and no longer make sense, is to fragment the worldwide market
and give weakened state-sponsored encryption a window of opportunity to
become a standard.
As such, I'm not upset at how the administration finally is publicly
acknowledging their abuse of export control law for anti-democratic ends.
I'm just upset at their abuse, and consider it highly unethical, even
It's ironic that those who are engaging in these unethical, anti-
democratic acts are also asking us to trust them with access to our most
private conversations...

@_date: 1994-07-25 20:10:50
@_author: Richard Johnson 
@_subject: The Clipper Chip Proposal 
From the keyboard of:  rittle at comm.mot.com (Loren James Rittle) in an
  open letter to our Gorewellian vice president:
  I also support completely voluntary (i.e. no outside government coercion)
  encryption key escrow for all private individuals and private-sector
  companies, if they themselves so chose it.
There is, however, no reasonable reason what-so-ever for government to be
involved in this escrow.  Just as with escrow of funds during property
transactions, those involved will choose their own non-governmental
escrow agents.
A simple analogy may serve to illustrate this crucial concept for Gore:
If I wish to leave a spare house key with my neighbor while I'm on
vacation, there's no reason I have to also leave a spare key with the
Loudyellnet: Richard Johnson | Sneakernet: ECNT1-6, CB 429, CU Boulder
Phonenet:    +1.303.492.0590 | Internet:   Richard.Johnson at Colorado.EDU
   RIPEM and PGP public keys available by server, finger or request
   Speaker to avalanche dragons.   Do you really think they listen?

@_date: 1994-07-31 11:02:23
@_author: Richard Johnson 
@_subject: penet hack 
No coincidence.  For those that haven't figured it out yet, some less
than clueful individual has subscribed a penet pseudonymous id to
cypherpunks.  Again.  Then again, maybe it _was_ an intentional try
at 'out'ing posters to cypherpunks.  The perp will receive each post
twice, once with the 'real' header via their normal subscription, and
once with the 'anonymized' header via their penet subscription.
When a message from a mailing list arrives at penet, addressed to
a 'nym, penet anonymizes it and assigns a new 'nym for the address
in the From: line.  To me, this is obviously stupid when mailing
lists are involved, causing automatic 'out'ing of folks who didn't
know they were sending to a pseudonymous account.
Might it be better for penet to fix the problem by more intelligent
parsing on their end (using the Sender: line too?), rather than
forcing the rest of the world to patch around their little security
Such patches include not attaching signatures and real names to any
mailing list posts, making sure all your accounts have penet ids
protected by passwords, not signing posts using PGP or RIPEM, and
sending to lists only via anonymous remailers.  A whole lot of bother
for little gain...
Basically, this penet problem makes Julf's service less than useless
to anyone who wants their pseudonymous address to remain private.

@_date: 1994-06-02 12:03:54
@_author: Richard Johnson 
@_subject: PGP 2.6 FAQ 
From the keyboard of:  gtoal at an-teallach.com (Graham Toal)
"University politics is so vicious simply because there is so little at
stake." <-- reasonable accurate misquote
University politics are normally much dirtier than the real thing, and
much harder to stay out of if you spend more than 4 years at an
institution.  The battles over office space alone can make smear
campaigns via TV ads in a congressional race look like a friendly
Still, it seems from the outside that there wasn't much toe-stepping
going on at MIT with regard to their PGP release.  That's nice to see.
Perhaps, for once, the internal politics were calmer than the external
storm of paranoia?  :-)

@_date: 1994-06-05 08:40:27
@_author: Richard Johnson 
@_subject: Keep Out--The Journal of Electronic Privacy 
About "Keep Out": you might want to be more precise in your blurbs.  As
things stand, I'm leery of trusting anything I might see in your journal.
  From the keyboard of:  John.Schofield at f903.n102.z1.fidonet.org (John Schofiel)
RSA is not broken, as far as I know.  If you have verifiable details that
it has, that'll be quite a scoop.  If you meant to say "the _factoring_ of
RSA-129," well, you should have said that instead.
A publisher, of all people, really needs to understand what a copyright
is.  Note that we cannot copyright ideas, only our expression of those
ideas.  Referring to a copyright on "the algorithm used in PGP" is
nonsense.  Instead, PKP holds licensing rights to a system _patent_ on
using RSA to perform public key encryption.
Otherwise, your stuff sounds cool to me, though I'd really prefer that
those who stand to get money for something not do their advertising via
this list.  Submitting boilerplate for comment is fine, but leave it to
other interested parties to pass your advertising brochures to the list.

@_date: 1994-06-06 18:27:25
@_author: Richard Johnson 
@_subject: Applied Cryptography (correction to typo in email address) 
From the keyboard of:  NetSurfer That should be:
  Softpro - softpro at cscns.com
                      ^
The 'cscns' stands for Colorado Springs Community News Service.

@_date: 1994-06-08 07:19:49
@_author: Richard Johnson 
@_subject: PGP in Australia 
From the keyboard of:  rishab at dxm.ernet.in
Not so.  The RSAREF license is valid in countries outside the USA/Canada
crypto ghetto.

@_date: 1994-06-18 16:58:07
@_author: Richard Johnson 
@_subject: "The Virtual Hand": Free-market Internet guide 
This part of the audience is certainly not receptive.  I'm here to
discuss crypto and its implications, not to have my mailbox filled with
Keep the spam off.  Unordered e-mail advertising (beyond a pointer to
where to find more info) is indeed bad.  If I wanted to read that guff in
its entirety, I would have checked the Web, gophers, or FTP sites, etc.

@_date: 1994-06-18 23:13:22
@_author: Richard Johnson 
@_subject: Having your own computer means never having.... 
TimM > (I fear laws telling corporations they *can't* snoop as much as
TimM > I fear Clipper. The reasons are obvious, to me at least, and I
TimM > can expand on this point if anyone's really interested.)
MarkC > The implications in the field of industrial espionage leap quickly
MarkC > to mind.
MarkC > Beyond that, unrestrained encryption is dangerous to
MarkC > corporations, because what's to stop a ticked off employee from
MarkC > encrypting everything in the office as revenge for some imagined
MarkC > slight?
Mark Carter makes the same erroreous simplification many people do when
talking about point security.  I see it most often on the Firewalls list.
There, the standard answer to "Should I prevent ftp connections so
employees can't send our proprietary plans off-site?" appears to be "Do
you search your employees at the exit for floppies and magnetic tapes?" Security is a web, the strength of which is only as high as the biggest
gap between threads.
Encryption being available to employees can make industrial espionage
easier only if it opens a new channel (or clears an insecure channel) for
bad apple employees or contractors to get their stolen memos off site. An
encrypted channel is just a channel, and probably not worth it for the spy
(unless higher bandwidth per incident channels like DAT or 8mm tapes risk
Mark's rhetorical question about ticked off employees encrypting everything
in sight for revenge shows the same problem.  If an employee can encrypt
the files and lose the key, the employee can instead just delete them or
fill them with garbage.  It is indeed a security risk, but the sabotage can
more easily be performed without strong encryption.
However, strong encryption in the workplace can indeed be used to cause
I'm more worried about situations where a corporate officer or the like
leaves the firm, and "forgets" to let her successor know the pass phrase
for the key used to encrypt the payroll records.  Or, the executive
secretary to the Treasurer could be fired because he was caught trying to
embezzle e-cash, and subsequently refuse to release the key used to
encrypt official financial transactions.  In such situations, a smart
company will have used a secret-sharing scheme to split the key, and will
have escrowed it with their outside counsel and/or a couple of escrow
What other problems can we come up with?

@_date: 1994-06-19 10:24:49
@_author: Richard Johnson 
@_subject: Hardware generators was: your mail 
From the keyboard of:  roy at sendai.cybrspc.mn.org (Roy M. Silvernail)
How about a SCSI device instead.  Most UNIX boxes and Macs nowadays have
a few unused SCSI IDs.  The great majority of DOS machines with SCSI (all
those new ones with CD-ROMs, etc.) have unused SCSI IDs.  SCSI has the
advantage of being rather fast, and is a cross-platform solution.
Loudyellnet: Richard Johnson | Sneakernet: ECNT1-6, CB 429, CU Boulder
Phonenet:    +1.303.492.0590 | Internet:   Richard.Johnson at Colorado.EDU
   RIPEM and PGP public keys available by server, finger or request
   Speaker to avalanche dragons.   Do you really think they listen?

@_date: 1994-06-19 19:02:28
@_author: Richard Johnson 
@_subject: OJ`S CELL PHONE 
From the keyboard of:  mgream at acacia.itd.uts.edu.au (Matthew Gream)
Yes, it must.  If the handset is on standby, it won't receive calls
unless the cell can tell which number the handset is using.
The only sure way to keep yourself out of the "Position Escrow System"
is by keeping the phone turned off, and possibly disconnecting the
battery or car power lead.  "On Standby" == "In use."
Loudyellnet: Richard Johnson | Sneakernet: ECNT1-6, CB 429, CU Boulder
Phonenet:    +1.303.492.0590 | Internet:   Richard.Johnson at Colorado.EDU
   RIPEM and PGP public keys available by server, finger or request
   Speaker to avalanche dragons.   Do you really think they listen?

@_date: 1994-05-12 01:15:13
@_author: Richard Johnson 
@_subject: State Dept Response to my second CJ request 
Hal Finney mentions that the law is often forced to make absurd
distinctions between OK and illegal acts, simply because the line must be
drawn somewhere.  It's a good point, and worth keeping in mind.
It seems obvious to me that, for purposes of ITAR regs., the Dept. of
State and Dept. of Defense here in the USA have drawn the line between
printed text (OK) and ASCII text files on electronic media (illegal to
export).  Their line selection is probably based upon their interpretation
of the self-contradictory ITAR regs.
However, just because one part of "the law" has drawn a particular line,
we shouldn't assume that line to be the final word.  If we do indeed
believe that electronic expression and electronic publishing are the moral
and constitutional equivalents of paper publishing, there should be no
line at all.
A lawsuit could force the line-drawers to officially recognize this
fundamental democratic truth.

@_date: 1994-05-12 13:06:34
@_author: Richard Johnson 
@_subject: NSA Chief Counsel in Wired, to appear on AOL 
The guy in charge of marginalizing crypto users and privacy seekers for
the NSA, Stuart Baker, tries his hand at logical arguments with a minimum
of name-calling.
Do his arguments stand up?  Not really.  Note how he avoids the issue of
how easy it's getting for authorities to do 'drift-net' fishing -
trotting out the tired old 'no new capabilities' line.  He also seems to
believe that requiring court authorization for wiretaps provides good
protection against their abuse (NSA has its own pet court).
------- Forwarded Message
Copyright and distribution policy attached to the end of document. FYI.
X-within-URL:                      NSA'S CHIEF COUNSEL TO APPEAR ONLINE
   Stewart A. Baker, Chief Counsel for the National Security Agency and
   featured writer in WIRED 2.06 will host a Q&A session on the Clipper
   Chip. He will appear on America Online in Center Stage (from AOL type
   keyword: "center stage") on Thursday May 26, 1994, from 7-9 p.m. EST.
   Baker is the NSA's top lawyer and supports the Clipper Initiative. He
   worked briefly as Deputy General Counsel of the Education Department
   under President Jimmy Carter. His article "Don't Worry Be Happy"
   refutes seven myths of key escrow encryption and is a WIRED Exclusive.
     _________________________________________________________________
                             DON'T WORRY BE HAPPY
   Why Clipper Is Good For You
    By Stewart A. Baker, Chief Counsel for the NSA
     _________________________________________________________________
   With all the enthusiasm of Baptist ministers turning their Sunday
   pulpits over to the Devil, the editors of WIRED have offered me the
   opportunity to respond to some of the urban folklore that has grown up
   around key escrow encryption -- also known as the Clipper Chip.
   Recently the Clinton administration has announced that federal
   agencies will be able to buy a new kind of encryption hardware that is
   sixteen million times stronger than the existing federal standard
   known as DES. But this new potency comes with a caveat. If one of
   these new encryption devices is used, for example, to encode a phone
   conversation that is subject to a lawful government wiretap, the
   government can get access to that device's encryption keys. Separate
   parts of each key are held by two independent "escrow agents," who
   will release keys only to authorized agencies under safeguards
   approved by the attorney general. Private use of the new encryption
   hardware is welcome but not required. That's a pretty modest proposal.
   Its critics, though, have generated at least seven myths about key
   escrow encryption that deserve answers.
   MYTH NUMBER ONE: Key escrow encryption will create a brave new world
   of government intrusion into the privacy of Americans.    Opponents of key escrow encryption usually begin by talking about
   government invading the privacy of American citizens. None of us likes
   the idea of the government intruding willy-nilly on communications
   that are meant to be private.
   But the key escrow proposal is not about increasing government's
   authority to invade the privacy of its citizens. All that key escrow
   does is preserve the government's current ability to conduct wiretaps
   under existing authorities. Even if key escrow were the only form of
   encryption available, the world would look only a little different
   from the one we live in now.
   In fact, it's the proponents of widespread unbreakable encryption who
   want to create a brave new world, one in which all of us -- crooks
   included -- have a guarantee that the government can't tap our phones.
   Yet these proponents have done nothing to show us that the new world
   they seek will really be a better one.
   In fact, even a civil libertarian might prefer a world where wiretaps
   are possible. If we want to catch and convict the leaders of criminal
   organizations, there are usually only two good ways to do it. We can
   "turn" a gang member -- get him to testify against his leaders. Or we
   can wiretap the leaders as they plan the crime.
   I once did a human rights report on the criminal justice system in El
   Salvador. I didn't expect the Salvadorans to teach me much about human
   rights. But I learned that, unlike the US, El Salvador greatly
   restricts the testimony of "turned" co-conspirators. Why? Because the
   co-conspirator is usually "turned" either by a threat of mistreatment
   or by an offer to reduce his punishment. Either way, the process
   raises moral questions -- and creates an incentive for false
   accusations.
   Wiretaps have no such potential for coercive use. The defendant is
   convicted or freed on the basis of his own, unarguable words.
   In addition, the world will be a safer place if criminals cannot take
   advantage of a ubiquitous, standardized encryption infrastructure that
   is immune from any conceivable law enforcement wiretap. Even if you're
   worried about illegal government taps, key escrow reinforces the
   existing requirement that every wiretap and every decryption must be
   lawfully authorized. The key escrow system means that proof of
   authority to tap must be certified and audited, so that illegal
   wiretapping by a rogue prosecutor or police officer is, as a practical
   matter, impossible.
   MYTH NUMBER TWO: Unreadable encryption is the key to our future
   liberty.
   Of course there are people who aren't prepared to trust the escrow
   agents, or the courts that issue warrants, or the officials who
   oversee the system, or anybody else for that matter. Rather than rely
   on laws to protect us, they say, let's make wiretapping impossible;
   then we'll be safe no matter who gets elected.
   This sort of reasoning is the long-delayed revenge of people who
   couldn't go to Woodstock because they had too much trig homework. It
   reflects a wide -- and kind of endearing -- streak of romantic
   high-tech anarchism that crops up throughout the computer world.
   The problem with all this romanticism is that its most likely
   beneficiaries are predators. Take for example the campaign to
   distribute PGP ("Pretty Good Privacy") encryption on the Internet.
   Some argue that widespread availability of this encryption will help
   Latvian freedom fighters today and American freedom fighters tomorrow.
   Well, not quite. Rather, one of the earliest users of PGP was a
   high-tech pedophile in Santa Clara, California. He used PGP to encrypt
   files that, police suspect, include a diary of his contacts with
   susceptible young boys using computer bulletin boards all over the
   country. "What really bothers me," says Detective Brian Kennedy of the
   Sacramento, California, Sheriff's Department, "is that there could be
   kids out there who need help badly, but thanks to this encryption,
   we'll never reach them."
   If unescrowed encryption becomes ubiquitous, there will be many more
   stories like this. We can't afford as a society to protect pedophiles
   and criminals today just to keep alive the far-fetched notion that
   some future tyrant will be brought down by guerrillas wearing
   bandoleers and pocket protectors and sending PGP-encrypted messages to
   each other across cyberspace.
   MYTH NUMBER THREE: Encryption is the key to preserving privacy in a
   digital world.
   Even people who don't believe that they are likely to be part of
   future resistance movements have nonetheless been persuaded that
   encryption is the key to preserving privacy in a networked, wireless
   world, and that we need strong encryption for this reason. This isn't
   completely wrong, but it is not an argument against Clipper.
   If you want to keep your neighbors from listening in on your cordless
   phone, if you want to keep unscrupulous competitors from stealing your
   secrets, even if you want to keep foreign governments from knowing
   your business plans, key escrow encryption will provide all the
   security you need, and more.
   But I can't help pointing out that encryption has been vastly oversold
   as a privacy protector. The biggest threats to our privacy in a
   digital world come not from what we keep secret but from what we
   reveal willingly. We lose privacy in a digital world because it
   becomes cheap and easy to collate and transmit data, so that
   information you willingly gave a bank to get a mortgage suddenly ends
   up in the hands of a business rival or your ex-spouse's lawyer.
   Restricting these invasions of privacy is a challenge, but it isn't a
   job for encryption. Encryption can't protect you from the misuse of
   data you surrendered willingly.
   What about the rise of networks? Surely encryption can help prevent
   password attacks like the recent Internet virus, or the interception
   of credit card numbers as they're sent from one digital assistant to
   another? Well, maybe. In fact, encryption is, at best, a small part of
   network security.
   The real key to network security is making sure that only the right
   people get access to particular data. That's why a digital signature
   is so much more important to future network security than encryption.
   If everyone on a net has a unique identifier that others cannot forge,
   there's no need to send credit card numbers -- and so nothing to
   intercept. And if everyone has a digital signature, stealing passwords
   off the Net is pointless. That's why the Clinton administration is
   determined to put digital signature technology in the public domain.
   It's part of a strategy to improve the security of the information
   infrastructure in ways that don't endanger government's ability to
   enforce the law.
   MYTH NUMBER FOUR: Key escrow will never work. Crooks won't use it if
   it's voluntary. There must be a secret plan to make key escrow
   encryption mandatory.
   This is probably the most common and frustrating of all the myths that
   abound about key escrow. The administration has said time and again
   that it will not force key escrow on manufacturers and companies in
   the private sector. In a Catch-22 response, critics then insist that
   if key escrow isn't mandated it won't work.
   That misunderstands the nature of the problem we are trying to solve.
   Encryption is available today. But it isn't easy for criminals to use;
   especially in telecommunications. Why? Because as long as encryption
   is not standardized and ubiquitous, using encryption means buying and
   distributing expensive gear to all the key members of the conspiracy.
   Up to now only a few criminals have had the resources, sophistication,
   and discipline to use specialized encryption systems.
   What worries law enforcement agencies --what should worry them -- is a
   world where encryption is standardized and ubiquitous: a world where
   anyone who buys an US$80 phone gets an "encrypt" button that
   interoperates with everyone else's; a world where every fax machine
   and every modem automatically encodes its transmissions without asking
   whether that is necessary. In such a world, every criminal will gain a
   guaranteed refuge from the police without lifting a finger.
   The purpose of the key escrow initiative is to provide an alternative
   form of encryption that can meet legitimate security concerns without
   building a web of standardized encryption that shuts law enforcement
   agencies out. If banks and corporations and government agencies buy
   key escrow encryption, criminals won't get a free ride. They'll have
   to build their own systems -- as they do now. And their devices won't
   interact with the devices that much of the rest of society uses. As
   one of my friends in the FBI puts it, "Nobody will build secure phones
   just to sell to the Gambino family."
   In short, as long as legitimate businesses use key escrow, we can
   stave off a future in which acts of terror and organized crime are
   planned with impunity on the public telecommunications system. Of
   course, whenever we say that, the critics of key escrow trot out their
   fifth myth:
   MYTH NUMBER FIVE: The government is interfering with the free market
   by forcing key escrow on the private sector. Industry should be left
   alone to develop and sell whatever form of encryption succeeds in the
   market.
   In fact, opponents of key escrow fear that businesses may actually
   prefer key escrow encryption. Why? Because the brave new world that
   unreadable encryption buffs want to create isn't just a world with
   communications immunity for crooks. It's a world of uncharted
   liability. What if a company supplies unreadable encryption to all its
   employees, and a couple of them use it to steal from customers or to
   encrypt customer data and hold it hostage? As a lawyer, I can say it's
   almost certain that the customers will sue the company that supplied
   the encryption to its employees. And that company in turn will sue the
   software and hardware firms that built a "security" system without
   safeguards against such an obvious abuse. The only encryption system
   that doesn't conjure up images of a lawyers' feeding frenzy is key
   escrow.
   But there's a second and even more compelling reason why the key
   escrow initiative can't fairly be characterized as interfering with
   private enterprise: The encryption market has been more or less
   created and sustained by government. Much of the market for encryption
   devices is in the public sector, and much of the encryption technology
   now in widespread use in the private sector was funded, perfected, or
   endorsed by the federal government.
   And not by accident, either. Good encryption is expensive. It isn't
   just a matter of coming up with a strong algorithm, although testing
   the strength of an algorithm can be enormously time-consuming. The
   entire system must be checked for bugs and weaknesses, a laborious and
   unglamorous process. Generally, only the federal government has been
   willing to pay what it costs to develop secure communications gear.
   That's because we can't afford to have our adversaries reading our
   military and diplomatic communications.
   That's led to a common pattern. First, the government develops, tests,
   or perfects encryption systems for itself. Then the private sector
   drafts along behind the government, adopting government standards on
   the assumption that if it's good enough for the government's
   information, it's good enough to protect industry's.
   As encryption technology gets cheaper and more common, though, we face
   the real prospect that the federal government's own research, its own
   standards, its own purchases will help create the future I described
   earlier -- one in which criminals use ubiquitous encryption to hide
   their activities. How can anyone expect the standard-setting arms of
   government to use their power to destroy the capabilities of law
   enforcement -- especially at a time when the threat of crime and
   terror seems to be rising dramatically?
   By adopting key escrow encryption instead, the federal government has
   simply made the reasonable judgment that its own purchases will
   reflect all of society's values, not just the single-minded pursuit of
   total privacy.
   So where does this leave industry, especially those companies that
   don't like either the 1970s-vintage DES or key escrow? It leaves them
   where they ought to be -- standing on their own two feet. Companies
   that want to develop and sell new forms of unescrowed encryption won't
   be able to sell products that bear the federal seal of approval. They
   won't be able to ride piggyback on federal research efforts. And they
   won't be able to sell a single unreadable encryption product to both
   private and government customers.
   Well, so what? If companies want to develop and sell competing,
   unescrowed systems to other Americans, if they insist on hastening a
   brave new world of criminal immunity, they can still do so -- as long
   as they're willing to use their own money. That's what the free market
   is all about.
   Of course, a free market in the US doesn't mean freedom to export
   encryption that may damage US national security. As our experience in
   World War II shows, encryption is the kind of technology that wins and
   loses wars. With that in mind, we must be careful about exports of
   encryption. This isn't the place for a detailed discussion of
   controls, but one thing should be clear: They don't limit the
   encryption that Americans can buy or use. The government allows
   Americans to take even the most sophisticated encryption abroad for
   their own protection. Nor do controls require that software or
   hardware companies "dumb down" their US products. Software firms have
   complained that it's inconvenient to develop a second encryption
   scheme for export, but they already have to make changes from one
   country to the next -- in language, alphabet, date systems, and
   handwriting recognition, to take just a few examples. And they'd still
   have to develop multiple encryption programs even if the US abolished
   export controls, because a wide variety of national restrictions on
   encryption are already in place in countries from Europe to Asia.
   MYTH NUMBER SIX: The National Security Agency is a spy agency; it has
   no business worrying about domestic encryption policy.
   Since the National Security Agency has an intelligence mission, its
   role in helping to develop key escrow encryption is usually treated as
   evidence that key escrow must be bad security. In reality, though, NSA
   has two missions. It does indeed gather intelligence, in part by
   breaking codes. But it has a second, and oddly complementary, mission.
   It develops the best possible encryption for the US government's
   classified information.
   With code breakers and code makers all in the same agency, NSA has
   more expertise in cryptography than any other entity in the country,
   public or private. It should come as no surprise, therefore, that NSA
   had the know- how to develop an encryption technique that provides
   users great security without compromising law enforcement access. To
   say that NSA shouldn't be involved in this issue is to say the
   government should try to solve this difficult technical and social
   problem with both hands tied behind its back.
   MYTH NUMBER SEVEN: This entire initiative was studied in secret and
   implemented without any opportunity for industry or the public to be
   heard.
   This is an old objection, and one that had some force in April of
   1993, when the introduction of a new AT&T telephone encryption device
   required that the government move more quickly than it otherwise would
   have. Key escrow was a new idea at that time, and it was reasonable
   for the public to want more details and a chance to be heard before
   policies were set in concrete. But since April 1993, the public and
   industry have had many opportunities to express their views. The
   government's computer security and privacy advisory board held several
   days of public hearings. The National Security Council met repeatedly
   with industry groups. The Justice Department held briefings for
   congressional staff on its plans for escrow procedures well in advance
   of its final decision. And the Commerce Department took public comment
   on the proposed key escrow standard for 60 days.
   After all this consultation, the government went forward with key
   escrow, not because the key escrow proposal received a universally
   warm reception, but because none of the proposal's critics was able to
   suggest a better way to accommodate society's interests in both
   privacy and law enforcement. Unless somebody comes up with one, key
   escrow is likely to be around for quite a while. That's because the
   only alternative being proposed today is for the government to design
   or endorse encryption systems that will cripple law enforcement when
   the technology migrates -- as it surely will -- to the private sector.
   And that alternative is simply irresponsible.
   For more information on the Clipper standard you can access WIRED's
   Clipper archive via the following WIRED Online services.
     * WIRED Infodroid e-mail server: Send e-mail to infodroid at wired.com
       containing the words "send clipper/index" on a single line inside
       the message body.
     * WIRED Gopher: Gopher to gopher.wired.com and select "Clipper
       Archive."
     * WIRED on World Wide Web:  select "Clipper
       Archive."
     * WIRED on America Online: The keyword is WIRED.
     * WIRED on the Well: Type "go wired" from any "OK" prompt.
     _________________________________________________________________
   Stewart A. Baker is the National Security Agency's top lawyer. He
   worked briefly as Deputy General Counsel of the Education Department
   under President Jimmy Carter, and he practiced international law at
   Steptoe & Johnson, in Washington, DC. He has been at the NSA since
   1992.
     _________________________________________________________________
   WIRED Online Copyright Notice
   Copyright 1993,4 Ventures USA Ltd. All rights reserved.
   This article may be redistributed provided that the article and this
   notice remain intact. This article may not under any circumstances be
   resold or redistributed for compensation of any kind without prior
   written permission from Wired Ventures, Ltd.
   If you have any questions about these terms, or would like information
   about licensing materials from WIRED Online, please contact us via
   telephone (+1 (415) 904 0660) or email (info at wired.com).
   WIRED and WIRED Online are trademarks of Wired Ventures, Ltd.
------- End of Forwarded Message

@_date: 1994-05-13 17:50:29
@_author: Richard Johnson 
@_subject: MacPGP interface project 
From the keyboard of:  Black Unicorn Can someone fill the rest of us in on the true story behind this?  Why
is the (copylefted) source code to 2.3a V1.1 not available?
I figure there must be a reason, but I'm all out of guesses.

@_date: 1994-05-16 13:31:28
@_author: Richard Johnson 
@_subject: How to make fixes stick (Was Re: PGP 2.5 Beta Release Over, PGP 2.6 to be released next week) 
According to Jeffrey I. Schiller, PGP 2.6 will issue broken messages,
unreadable by earlier legal versions of PGP (Viacrypt's 2.4 in USA and
Canada, and any version outside backward-crypto-land)
In summary, how do we make our fixes to this obvious bug stick?
(Institutional paranoia on)
To me, this change is an obvious step in satisfying the TLA's desire for
a segmented crypto market to slow widespread use of strong crypto.  On
the one side, we have misapplied ITAR regulations preventing export of a
worldwide standard.  On the other side, we have a wrongly-granted patent
preventing use of an imported worldwide standard.  PGP is a de-facto
worldwide standard, and they're trying to break it.
(Institutional paranoia off)
  From the keyboard of:  Adam Shostack Adam has the right idea.  The question is, how do we make such a fix
stick?  In order to beat the "canonical release" advantage of the
broken 2.6, we'll need to spread the word widely (at least until a
2.6-compatible PGP is released and ported to the full range of current
platforms by our outside compatriots).
Some suggestions for after we create such patches:
Letters to computer magazines (Infoworld, Wired, PC Week, etc.)
Add entry to PGP FAQ about communicating with non-USA/Canada PGP users
Add entry to PGP WWW pages in UK
Weekly postings of the patches to alt.security.pgp (from outside NA)
Monthly postings of the patches to alt.sources.patches (from outside NA)
Press releases in other appropriate newsgroups, repeated
Come up with others, particularly for the non-net world. :-)

@_date: 1994-05-17 19:51:45
@_author: Richard Johnson 
@_subject: So PGP2.5 is becoming clearing... 
Lile Elam  graciously forwarded some comments about
the March 16 RSAREF license to us.
...[Mucho FUD (maybe warranted) about the RSAREF license excised.]
Overall, the license is OK, if a bit stupid in places.  Rather than deal
with supposition, let's get right to specifics in the license itself.
Note that I'm not a lawyer, though my Mom wanted me to be one.  Anything
that looks like legal advice in the following is just mere uninformed
supposition on my part.
"Performance improvement" purposes can obviously include allowing more
secure performance via longer (2048 bits anyone?) keys.
Note that the license suddenly starts referring to "Application Program"
in 1.c.  The implicitly explict ;-) definition of "Application Program"
is "other computer programs for your own personal or internal use" into
which the RSAREF Program is "incorporated".  The license later defines
this term explicitly, in line with the implicit use above.
The key here is "incorporated".  Since RSAREF is designed as a C
library, the only way to "incorporate" it is to call its functions from
a program.  Thus, if you don't call specific RSAREF functions, you're
not "incorporating" RSAREF.  "Incorporation" of RSAREF is thus not
Only "Application Program"s that "incorporate" RSAREF must be given to
RSA.  According to these definitions, PGP (which incorporates RSAREF)
must be given to RSA.  A mail user agent that uses PGP, however, does
not "incorporate" RSAREF.  Likewise, neither does an OS that allows the
mail user agent to employ PGP.  PGP is the only program that
"incorporates" RSAREF here.  RSA is thus not asking for sources to the
entire OS.
       d.   to copy and distribute the Program and Application Programs
            in accordance with the limitations set forth in Section 2.
We can thus freely copy and distribute RSAREF and whatever we build that "incorporates" it.  The section 2. restrictions: require us to
distribute source along with any executables we produce (like the
original FSF license did), require us to include the RSAREF
license (similar to FSF copyleft), and require us to get "written"
assurance from recipients that they will not use it for revenue
generation (onerous and weird, but doable).
One point about this really bugs me, though.  We cannot generate
"income" from distribution of RSAREF-incorporating application
programs.  Normally, I would not include recovering costs for
distribution media/time/bandwidth and shipping/handling as "income".
However, they make no explicit acknowledgement of this.  If you
do charge for BBS memberships, on-line accounts, or disks at your
user group meeting, you should probably make it explicitly clear
that you are not charging for specific programs, but for the media
no matter what the user is going to do with it.
In simple terms, RSA wants a cut if you make money (or try to) using
their RSAREF mess.  If you want to do that, the best approach would be
to skip RSAREF and license the use of a more capable and extensible
library from RSA.

@_date: 1994-05-19 22:50:02
@_author: Richard Johnson 
@_subject: Sternlight "kill" file 
From the keyboard of:  Tom Allard Heh.  Sternlight is really trying to throw his weight around here,
isn't he.  How sad, but not surprising.  His job will be much
easier if he can silence some of the opposition to his half-truths
and innuendo.
As Jim Thomas notes in the following post to alt.security.pgp, M.
Sternlight is somewhat ignorant of Copyright law and precedent,
including such things as fair use, implicit assignment of rights,
etc.  Note that Mr. Thomas posted his missive to a usenet newsgroup
that receives posts from cypherpunks.  The fact that we have to
use manual means to make the gateway go in two directions makes it
no less valid a gateway than those between other mailing lists and
usenet newsgroups (like comp.society.cu-digest, for example :-).
Newsgroups: alt.fan.david-sternlight,alt.security.pgp
In article ,
Not surprisingly, Sternlight reveals his ignorance of copyright law.
Sternlight has failed to demonstrate:
1) That the first alleged violation was, in fact, a violation, and not
   simply a labeling ruse. Sternlight has rushed to judgment and
   tried and convicted without evidence. An honorable person would
   first ascertain facts prior to taking action
2) Sternlight claims a second violation of netcom's agreement without
   demonstrating what the violation is. An honorable person would
   reproduce the relevant text of the agreement and then make the
   corresponding case. Instead, Sternlight asserts. This is consistent
   with his style in which he defames others and then complains that
   he is defamed when others hoist him by his own petard.
3) That Sternlight snoops through others' stuff and then leaps to
   judgment on the bases of superficial cues is, indeed, a matter of
   public concern. If Sternlight snooped through my system files and
   found titles such as suckme.gif, jailbait.gif, and 69riders.exe,
   would he have complained to our university officials that I am
   in violation of school anti-porn policies? If the facts of Sternlight's latest escapades are accurate, and Sternlight's
post seems to confirm them, then it is fully appropriate to alert
the public that a demonstrable defamer is actively perusing accounts and
notifying sysads of what he finds.
Perhaps Sternlight should look up "honor" in his dictionary.
Jim Thomas

@_date: 1994-05-23 23:54:31
@_author: Richard Johnson 
@_subject: MIT has released PGP 2.6 
What will we have to do to get MIT-PGP 2.6 via anonymous ftp from
Like with MIT-PGP 2.5, telnet to net-dist.mit.edu, and answer questions.
This time there are 4.  The first three questions help MIT protect itself
from possible legal problems related to their distributing PGP - they
cover their rear ends with regard to ITAR regs (questions 1 and 2) and
patent infringement (question 3).
First, we must assure net-dist that we're not trying to export MIT-PGP 2.6.
Second, we must promise not to export MIT-PGP 2.6. Third, we must agree to
the terms and conditions in the RSAREF license. Finally, we must agree
that we won't use MIT-PGP 2.6 for commercial purposes.  A "yes" answer to
that last question is the only thing specifically required by the RSAREF
Note well that we aren't required to obey strictures in some kind of
"README" file.  Remember this for when someone tries to muddy the waters
with baseless obfuscatory claims about what we agreed to in some auxiliary
file, and how that auxiliary file somehow overrules the license terms.
I find the RSAREF license quite reasonable, as I did their previous
version.  I have not yet seen the MIT license.  I don't know about the
source, because I haven't grabbed it yet.

@_date: 1994-05-24 12:04:47
@_author: Richard Johnson 
@_subject: SRA telnet and ftp (FYI) 
A note about a package that uses D-H to generate a key for telnet and ftp
authentication.  Has anyone here played with it?
------- Forwarded Message
After hearing about David Safford's SRA telnet/ftp package from numerous
sources, I finally went and got a copy (from ftp://net.tamu.edu/pub/security/TA
It's nice work.  I would like to clarify one point, though:  This package
uses the Diffie-Hellman code from the Secure RPC implementation, to securely
compute a session key which the SRA code uses to encrypt an authentication
transaction.  The code does NOT use the session key to encrypt the whole
session.  It would probably be relatively easy to add, but it's not in there
in the current code.
This is from my perusal of the code, and correspondence with the author.
------- End of Forwarded Message

@_date: 1994-05-27 14:38:44
@_author: Richard Johnson 
@_subject: v2.6 for the rest of us 
Try ftp://ftp.dsi.unimi.it/pub/security/crypt/PGP/

@_date: 1994-05-28 09:33:09
@_author: Richard Johnson 
@_subject: Email Stalking on CNN 
From the keyboard of:  lile at netcom.com (Lile Elam)
Does AIL, er, AOL have kill files?  The reporter trying valiantly to
cover the story with some kind of objectivity was reduced to observing
that some people just can't ignore any email - they have some kind of
weird need to read every message.  I guess this goes for messages even
from those they want to ignore.
In order to overcome this, do email kill files have to do their work
silently, so the user can avoid stress about what they're missing?

@_date: 1994-05-31 13:02:17
@_author: Richard Johnson 
@_subject: http://digicash.support.nl = NULL 
From the keyboard of:  bart at netcom.com (Harry Bartholomew)
Indeed.  This is a lynx bug that's bitten me before.  The work around is
to do a 'G'o to a specific URL, and type in:
                             with ^
I'm not sure if the lynx developers have fixed this in the latest beta

@_date: 1994-09-22 16:10:44
@_author: Richard Johnson 
@_subject: "Legitimate" needs of LE (Was Re: (Fwd) Internet Security: Secure Communications Over Untrusted Networks) 
That "legitimate needs of law enforcement" phrase raises my hackles every
time I see it.  My contrary nature makes me want to shout questions like,
"Just what *are* the legitimate needs of law enforcement?" and, "Who
decides what the legitimate needs of law enforcement are?  Law enforcement
personnel?  Bwahahahah."
A more effective response might be to point out (with sufficient force)
that "we still, as a nation, haven't decided what the legitimate needs of
law enforcement are."  Therefore, anyone, especially someone with a
political power interest in the matter, who asserts we have decided is
attempting to end-run our democracy and usurp power.
This whole business that Freeh keeps peddling, for example, about the
number of wiretaps (oh, excuse me, the number of wiretaps and remote
listening posts and oh so many other kinds of surveillance) to back up his
demands for big brother powers over all of us, well, it begs the

@_date: 1994-09-24 12:16:49
@_author: Richard Johnson 
@_subject: LD 
Heh.  Perhaps Lance Detweiler is spoofing Larry Detweiler.  It's worth a
good laugh at least.  The posts are short enough that either Larry D. has
gotten more abbreviated and lost his flowery touch, or Lance just doesn't
see any point in getting into long, involved pseudo-discussions with
himself, for our amusement.  Then again, maybe you're all a figment of my

@_date: 1995-08-10 20:34:59
@_author: Richard Johnson 
@_subject: PRZ encrypted voice software release imminent 
When I originally volunteered to help with coding on the PGP voice stuff,
the author (I think) of Nautilus sent me, and the rest of the PGP voice
mailing list participants, version 0.2 for review.  The initial plan was
to take the Nautilus code, rewrite it in a more modular fashion, and add
encryption to create voice PGP.  However, the incarnation of the PGP voice
mailing list we were using for the project just died, and I heard nothing
more about Nautilus after I submitted my comments and suggestions -- until
the release of Nautilus 0.9.
So if Nautilus code was not used in PGPfone, I suspect licensing or other
such issues got in the way, and Will Price and crew started from a
different base. Then again, perhaps Nautilus and PGPfone have much in
common.  We'll have to wait for the PGPfone release for the answer.

@_date: 1995-08-19 16:19:59
@_author: Richard Johnson 
@_subject: Certificates/Anonymity/Policy/True Names 
The certificate gets their messages into systems that demand a
certification, whether for transport or display.

@_date: 1995-07-28 16:37:03
@_author: Richard Johnson 
@_subject: RC4 
A acquaintance of mine at a now-defunct company compared the reverse
engineered RC4 work-alike that was released on the net with the source they
had licensed from RSADSI.  She noted that the implementations were quite
different (structure and variable names were both very different), so the
work-alike released on the net was indeed most likely reverse engineered.
Someone else queried two or three other BSAFE source licensees, and found
all agreed that the code was not cribbed from BSAFE sources.  Sadly, I no
longer have copies of the (anonymous) post.
Still, I'm not rich enough to punch through RSADSI's smoke screen...

@_date: 1995-11-09 08:15:34
@_author: Richard Johnson 
@_subject: Photuris 512bit Prime Challenge? (Re: Photuris Primality verification needed) 
Sounds like someone just threw down a gauntlet.
Is it even possible to do the precomputations in a distributed manner in
less than a year or two?  Or maybe starting a few years down the road?
It would be nice to give Photuris a chance to get established before the
least common denoninator shared modulus gets taken out, if we even can
take it out.

@_date: 1995-11-19 05:11:35
@_author: Richard Johnson 
@_subject: RealAudio website TEMPORARY PASSWORD 
I assume that temp password will be changed to cypherpunks soon.
Note that
          Username: cypherpu   [8 char limit]
          Password: cypherpunks
also works.  Someone set it up a few months ago.

@_date: 1995-10-19 16:20:17
@_author: Richard Johnson 
@_subject: Netscape rewards are an insult [NOISE] 
So a reviewer stepped in and accused the rock star of  having "sold out"...
Does working as a programmer for a "major label" on a top-40 hit mean
you're not true to your artistic roots any more?
Or does "working within the system" permanently disqualify you from
rebel/outcast status?
OK, sorry, enough of the cliches. :-)

@_date: 1995-10-26 09:19:31
@_author: Richard Johnson 
@_subject: HTTP Request-Header & Server Environment Echoes 
What Your Browser Says Behind Your Back
    what your browser told me about you when you weren't looking
echo CGI at UIUC mentioned on cypherpunks (
cpunks-9/0095.html) in Nov. 1994 seems to be down for the count (it was
 )).  It would provide you with a page
showing the information your browser had given to the server in the HTTP
However, others exist to take up the slack. Here's a directory I compiled
today (thanks to WWWW, Lycos, etc.) of current, working HTTP
Request-Header and resulting server environment variable echoes. I'm sure
I've missed some, if not many. Follow up with additions, if you want.
Better yet, add these and the additions to your favorite privacy and
security pages.
HTTP Request-Header Echoes
Machine Information at MIT (
    Feeds back your machine name, IP address, and finger info.  Not really
    a request-header echo at all, but useful.
Echo at TU-Berlin (
    Raw text echo of your HTTP request-header info.
Echo by Pierre Omidyar at best.com (
cgi) and at ebay.com (
    Two paths for reaching the same CGI script. Produces nicely formatted
    HTML output showing your HTTP request-header info. Simple perl source
    for the script is available from Pierre's Web Tips (
    com/~pierre/web-authoring.html) page.
Echo by mjd at cis.upenn.edu (
    Produces formatted HTML echo of your HTTP request-header info.
Echo at hyperreal.com (
    Produces plaintext HTML echo of your HTTP request-header info.
Echo at Whithead Institute--MIT (
    Produces formatted HTML echo of your HTTP request-header info. Simple
    perl source for this script is available in the Chapter 9 script
    examples ( from
    Lincoln Stein ( book, How to
    Set Up And Maintain a World Wide Web Site (
    edu/WWW/).
Echo by cloos at io.com (
    Raw text echo of your HTTP request-header info. Also provides a whole
    bunch more, including the script's runtime environment.
And now, again in the original HTML:
The what your browser told me about you when you weren't looking
echo CGI at UIUC mentioned
on cypherpunks in Nov. 1994 seems to be down for the count (it was It would provide you with a page showing the information your browser had
given to the server in the HTTP Request-Header.
However, others exist to take up the slack. Here's a directory I compiled
today (thanks to WWWW, Lycos, etc.) of current, working HTTP Request-Header
and resulting server environment variable echoes. I'm sure I've missed some,
if not many. Follow up with additions, if you want. Better yet, add these
and the additions to your favorite privacy and security pages.
HTTP Request-Header Echoes
Machine Information at MIT
Feeds back your machine name, IP address, and finger info. Not really
a request-header echo at all, but useful. at TU-Berlin
Raw text echo of your HTTP request-header info. Echo by Pierre Omidyar
at best.com and at ebay.com
Two paths for reaching the same CGI script. Produces nicely formatted
HTML output showing your HTTP request-header info. Simple perl source for
the script is available from Pierre's
Web Tips page. Echo by mjd
at cis.upenn.edu
Produces formatted HTML echo of your HTTP request-header info. Echo at hyperreal.com
Produces plaintext HTML echo of your HTTP request-header info. at Whithead Institute--MIT
Produces formatted HTML echo of your HTTP request-header info. Simple
perl source for this script is available in the Chapter
9 script examples from Lincoln
Stein's book, How
to Set Up And Maintain a World Wide Web Site. Echo by cloos
at io.com
Raw text echo of your HTTP request-header info. Also provides a whole
bunch more, including the script's runtime environment.

@_date: 1995-10-27 02:36:20
@_author: Richard Johnson 
@_subject: CJR returned to sender 
The CJR for the t-shirts was not frivolous.  Not in the least.
Letting the NSA/Dept. of State off the hook on this one leaves them with
wiggle room.  The goal of filing these CJRs is to find out just where the
NSA/Dept. of State draw their lines, and to _force_ them to draw lines
where they'd rather retain flexibility.  At the very least, we can point
out the rather strange ideas they have about what constitutes speech, for
the PR value, during the splashes of media attention silly CJR rulings
Even more useful: other things remaining equal, a rigid agency is safer
to deal with than one that retains the flexibility to selectively harrass.

@_date: 1995-09-03 12:26:51
@_author: Richard Johnson 
@_subject: Dumb Question: PGPfone over Appletalk 
My guess is that you're on a network with multiple AppleTalk zones.  The
"PGPfone 1.0b4 README" file mentions a known bug that causes PGPfone to
freeze when trying to bring up its AppleTalk Browser.  The Read Me file
then goes on to explain how to connect anyway.  Be sure to use a
semi-colon, not a colon, between the zone name and the macintosh name...

@_date: 1995-09-12 15:06:04
@_author: Richard Johnson 
@_subject: Leaked NSI PR About $50-Annual-Fee-for-Domain-Name 
Here's a pointer to a very interesting draft press release, apparently scheduled for release on 18 September 1995.
Short version:  The article specifies $100 one-time fee for new domain name registrations, and a $50/year annual fee for all .com, .edu, .gov, .net, and .org domains.
Long version:
