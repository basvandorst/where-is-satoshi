
@_date: 1992-12-03 18:31:36
@_author: Eric Hughes 
@_subject: FTP site 
We have an anonymous FTP site.  It's at soda.berkeley.edu.  The
directory is pub/cypherpunks.  Right now there's not much in it.  A
few miscellaneous documents are in the misc/ directory.  There's an
empty directory for listings of ftp sites in other places that hold
crypto software of various forms.
But most importantly the source code to the remailer as currently
running is in there.  I'd like to see even more remailers than three.
And if you can't put up a remailer (because, to take one of the few
good examples, you don't run Unix) I'd still like people to study the
We'll eventually have weekly digests of mail traffic from the list,
but those aren't created yet.

@_date: 1992-12-03 18:35:51
@_author: Eric Hughes 
@_subject: Suggest splitting things up 
A word on the subject of altering the list from the list maintainer.
There's been lots of discussion about splitting up the list into
various pieces.  In a word, it's not going to happen.
Look, this is the cypherpunks list.  Cypherpunks write code.  A
corollary to this is that cypherpunks take responsibility for the
volume of mail they receive.  If you're getting too much mail, use a
filter.  Many of you may not know that the remailer software as
currently configured pressed into service just such a filter.
In the just-announced ftp site, there's the source code, in perl, to
just such a filter.  You can change it to do whatever you like.  In
particular, you can install it to filter all your cypherpunks mail to
a separate mailbox, file, or subdirectory.
You can also use MH, whose slocal the above perl filter was based on.
slocal can filter all of your cypherpunks mail to separate places.
You can also send all of your cypherpunks mail to a separate directory
and use a newsreader to read it.  I've never done this, but certain
list members have.  If one of them (say, Mitra, who recently mentioned
that he does this) would post a short summary of how it's done to the
list and offer to answer questions off-line, I'd appreciate it.

@_date: 1992-11-11 08:24:36
@_author: Eric Hughes 
@_subject: Random number generators 
There seems to be some confusion over this random number device.
Perry Metzger forwarded me some information about Newbridge
Microsystems and the part number of a chip that made random numbers.
At the crypto BOF at hackers I mentioned that there was a need for a
hardware random number generator and that I knew of some chip to do
it.  John Draper, who was there, expressed a desire to work on such a
device.  I forwarded him the information about the chip.
What I didn't know was the cost or design of this chip.  It appears to
use a radioactive source to make random numbers.  This may account for
the cost.  In any case, it is likely that most applications don't need
this kind of chip.
What is needed, though, is _some_ kind of chip.  John Draper is eager
to manufacture such a device, once we have a design.  Would those
people willing to help on this design please get in touch with him
directly and start a conversation about it.  The conversation could
reasonably be discussed on the list, if enough are interested.
FYI, random numbers are used generally to create single-use session
keys in a wide variety of crypto protocols, including Diffie-Hellman
key exchange.  Hardware random number sources will be a standard
component of all computers in the near future.
As far as the design of the device itself goes, the numbers that come
out of it don't have to be fully random.  Non-randomness can be
corrected in software.  Two characteristics of the output, though will
help such correction.  First, the number of ones and zeros should be
the same.  Not only is this useful for correction, but it is easy to
do in hardware.  Second, effort should be made to make sure that the
generator does not pick up cyclic noise from its environment.  This
means attention to coupling, shielding, and packaging.  No extra
expense, likely, but definitely to be thought about some.

@_date: 1992-11-11 08:33:18
@_author: Eric Hughes 
@_subject: Mac PGP version 
I found the address for the Mac version of PGP.
anon-ftp to mac.archive.umich.edu
directory /mac/util/encryption
Would someone try this out and report back to the list how it works?

@_date: 1992-11-11 15:18:28
@_author: Eric Hughes 
@_subject: PGP problems with large key rings? 
P.S.  The maintenance release is in the works; it may fix the error
you describe.

@_date: 1992-11-11 18:47:46
@_author: Eric Hughes 
@_subject: Mac PGP version 
Here's the author of the Mac port I referenced:
This fixes the second of Fen's bugs.  Contacting Zig will fix the
first (no source).
And, Fen, you attached a PGP key.  Did you really ask the NSA to
generate one for you? :-)

@_date: 1992-11-12 07:57:00
@_author: Eric Hughes 
@_subject: (fwd) A Silver Bullet to Limit Crypto? 
Re: tying voter and crypto registration issues togther.
An excellent idea, if both succeed.  But since voter registration is
already a partisan issue, tying crypto registration to it make crypto
a partisan issue.  And once you've made it a partisan issue, you've
lost, fundamentally.  The way to succeed on any issue is to avoid polarization along party
lines.  One should not assume that there will be automatically a large

@_date: 1992-11-12 07:59:57
@_author: Eric Hughes 
@_subject: (fwd) A Silver Bullet to Limit Crypto? 
Re: Apple include a PKS with their Macs
Well, Apple does have a site license for RSA.  Tim Oren, who's on the
list, knows more about this than I.  I ask him to respond.
Maybe Apple could license the PGP code as a system utility?

@_date: 1992-11-12 09:45:09
@_author: Eric Hughes 
@_subject: random generator 
And higher data rates are more expensive.  If you're making one time
pads, you need high bit rates, but otherwise you don't.  10Kbps is
overcapacity for personal use.
Let's do an estimate.  Suppose all you use your random numbers for is
to create session keys for socket connections.  Now lets say you need
to open a socket about once a minute.  Since you need, say, 500 bits
for a DH key exchange, that's a bit rate of about 10 bits per second.
One can cache bits coming in from the random number generator in a
ring buffer.  You can make this ring buffer arbitarily large, or even
virtualize it to disk and make it appear as infinite in size.  Then
you could run your generator continuously and always have enough bits
available for use.
If you're using a generator for making session keys, then you just
don't need that high a bandwidth.  Now the $/bps for the Newbridge chip is much lower, but for personal
use you throw away too many of its bits to make it worthwhile.  This
higher bandwidth chip would be useful in a server of some sort, where
you are making session keys more than once per second.
Proposal: Make this random number generator operate at 100 bps.  If
higher bit rates are the same price, fine.  But a specific design
criterion of 100 bps should be a practical and economical goal.

@_date: 1992-11-13 01:20:39
@_author: Eric Hughes 
@_subject: Rander box 
Some simplifications I might suggest:
I only think you need an output connector.  See below.
If you can power it off the RS-232 line, you won't need a power
switch.  You should be able to draw enough power off, say, the DTR
line to power a simple thing like this.
For a dedicated random number generator with low bandwidth, there's
not much reason for variable baud rate.  I'd use a fixed baud rate of,
say 1200, or even 300.  If you make it low enough you could just
kludge together a serial interface, but with the low cost of UART's,
it's probably not worth it.  You might also consider using a PIC, which
has built-in serial.
I'd just make the thing spew continuously.  It's not like you're
losing real, er, information if you ignore a few random bits.  This
way you don't need the added circuitry for switching on and off.
The actual use of this thing is going to require a device driver to
buffer up random bits for later use.  So all the flow control to the
higher layer happens there anyway.  And if the UART buffer overflows,
so what?

@_date: 1992-11-13 08:57:54
@_author: Eric Hughes 
@_subject: (fwd) A Silver Bullet to Limit Crypto? 
Perry, Tom _is_ using PGP.  Please be aware of what the actual question is, rather than red-flagging
on keywords like "compromised."

@_date: 1992-11-13 09:21:09
@_author: Eric Hughes 
@_subject: Rander box 
Perry on random bit rates:
Cryptography is all economics.
The economics here is that John Draper is going to try to market this
thing, not play with it in the lab.  I don't know what experience you
have with electronic design, so pardon me if I condescend.  You don't
sell features that most people don't need.  You don't add parts when
only a few people are going to use the feature.  You make another
version if there is sufficient demand for higher performance.
One-time pads are expensive to make relative to other forms of
security.  Period.  No argument.  George Gleason and I had a long
conversation via email over a period of weeks about this.  He was
convinced.  If you don't believe me, ask him.
The largest need for random bits right now is for key material. If you
want to use one-time pads, fine.  They are secure, no problem.  The
random number generator we are discussing here is not suitable for
making one-time pads.  If you want one, build it.  It's not what most
people need right now.
In fact, if one-time pads are economical to use, then surely there is
a market for one-time pad systems.  Of course, if such a market does
not exist, then one-time pads don't provide economical protection for
the market as a whole.  Which do you think?
Re: continuous spewing of bits.
Perry thinks this is a bad idea because it won't work with
workstations well with respect to interrupts.  In my previous post, I mentioned powering the device from DTR.  DTR,
for those of you not familiar with RS-232, is a device control line
which is separately assertable.  To turn the device off, toggle DTR.
Presto!  No more power, no more bits.  Simple, when you know what DTR
My original point remains, though: you don't need a power switch.

@_date: 1992-11-13 18:59:39
@_author: Eric Hughes 
@_subject: PGP 2.01 2.02 
As of now, PGP 2.0 is the current version.  A newer one will be out
shortly (it's being tested).  The list will certainly be the first to

@_date: 1992-11-16 09:12:39
@_author: Eric Hughes 
@_subject: November 21 meeting, 12 noon, at Cygnus offices 
The Third Physical Cypherpunks Meeting: Project Planning
    It has become clear that lots of code needs to be written, and
that we will be writing it.  Therefore the Third Meeting will be
devoted to project planning and design review.
Time: 12 noon
Where: Cygnus Support offices
Who: you, and anybody you know who wants to come, and so on.  (Please
    do not post this announcements to public places, but do encourage
    private circulation.)
Positive-Confimation:  Please tell me if you are coming.  Replies to
    hughes at soda.berkeley.edu.
Please, I urge all of you on the list that can make to attend this
time.  This will be a pivotal meeting, since we are deciding
priorities here.  If you want to affect the course of development, you
ought to show up.  If you can't attend, corner someone on the list who
will be there and convince them to represent your position.
Eric Hughes
1.  Key exchange.  Bring a diskette with your PGP public key on it.
Bring a machine which can read this diskette.  Bring extra diskettes
to collect keys on and to give out.  Let us not be hypocrites and let
us all know each other's public keys.
2.  Project planning.  We need a list of crypto projects and who is
working on them.  This will help coordination and avoid duplication of
effort.  We need to prioritize the projects to avoid premature
development.  We need to create strategies and design criteria.
3.  Project logistics.  We need to talk about the best ways to do
widely distributed software development in this fairly anarchic
4.  Design review.  Hal Finney and I have been duking it out behind
the scenes working on a design schema for the next generation
remailer.  I'd like to present the design and have people critique it.
(would be 5.) We won't be playing the crypto-anarchy game this time.
It's not a dead duck, but this time we've got more urgent things to
Here is a reposting of the directions to the meeting place. Someone asked for better directions, and the original ones were
pretty skimpy anyway.  Here's a better try.
There's no phone service there yet.
Take US 101 toward Mt. View.  From San Francisco, it's about a
40-minute drive.  Get off at the Rengstorff Ave/Amphitheatre Parkway
exit.  If you were heading south on 101, you curve around to the
right, cross over the freeway, and get to a stoplight.  If you were
heading north on 101, you just come right off the exit to the
stoplight.  The light is the intersection of Amphitheatre and
Charleston Rd.  Take a right on Charleston; there's a right-turn-only
Follow Charleston for a short distance.  You'll pass the
Metaphor/Kaleida buildings on the right.  At a clump of palm trees and
a "Landmark Deli" sign, you can take a right into Landings Drive; this
gets you into the complex from the north.  Or you can go slightly
further along Charleston and take the next right, into a driveway with
a big "Landmark" sign in the middle.  No matter which way you got into
the complex, follow around it until you are on the side that faces the
freeway.  There's a clock tower that rises out of one of the
buildings, to the right (south) of the deli.  Enter through the doors
immediately under the clock tower.  They'll be open between noon and
1PM at least.  (See below if you're late.)
Once inside, take the stairs up, immediately to your right.  At the top
of the stairs, turn right past the treetops, and we'll be in 1937 on your left.
If you are late and the door under the clock tower is locked, you can
go to the deli (which will be around a building and left, as you face
the door), cut between the buildings to the right of the deli, and
into the back lawns between the complex and the farm behind it.  Walk
around the buildings until you see a satellite dish in the lawn.  Go
up the stairs next to the dish, which are the back stairs into the
Cygnus office space.  We'll prop the door (or you can bang on it if we
Or, you can find the guard who's wandering around the complex, who
knows there's a meeting happening and will let you in.  They can be
beeped at 965 5250, though you'll have trouble finding a phone.
Don't forget to eat first, or bring food at noon!  I recommend hitting
the burrito place on Rengstorff (La Costen~a) at about 11:45.  To get
there, when you get off 101, take Rengstorff (toward the hills) rather
than Amphitheatre (toward the bay).  Follow it about ten blocks until
the major intersection at Middlefield Road.  La Costen~a is the store
on your left at the corner.  You can turn left into the narrow lane
behind the store, which leads to a parking lot, and enter by the front
door, which faces the intersection.  To get to the meeting from there,
just retrace your route on Rengstorff, go straight over the freeway,
and turn right at the stoplight onto Charleston; see above.
See you there!

@_date: 1992-11-17 03:40:49
@_author: Eric Hughes 
@_subject: The Dining Cryptographers Protocol 
Let me continue to be a broken record.  Cryptography is all economics.
You want unconditional security, you pay.  Period.  Sometimes it's
worth it, sometimes it's not.  It is not up to the cryptographer to
make the economic judgement, it is up to the user.
This idea of "delays" providing security for a mix is a common, but
incorrect, notion.  I don't think Marc is incorrect about this here,
merely unclear.  In a well used mix system, the latency time to
accumulate ten messages would be only a few minutes.
It is the reordering of the output messages with respect to the input
that provides mix security.  Any delay in merely a consequence of the
time to collect.

@_date: 1992-11-20 14:18:02
@_author: Eric Hughes 
@_subject: The Cypherpunks Mail Project 
Hey, this means you!  Have you sent me the name of the software you
use to read e-mail with yet?
Even if you've never posted to the list or replied to any of the
messages, I expect to hear from you.
I not only want to collect a list of names of software, I want to know
which ones are in most common use.

@_date: 1992-11-20 14:18:20
@_author: Eric Hughes 
@_subject: The Cypherpunks Mail Project 
Step Two in the Mail Project is to gather together the social facts of
mail software development: where the source code is and who maintains
Participation in this step is not required, but a distributed effort
to find this information would be greatly appreciated.
Therefore, if you know where to find source code for your own (or any
other) mail reader, please send it along.  Be complete.  Include at
least the following information:
1.  The name of the mail agent.
2.  The current version number.
3.  A machine name where the code is located, presumably via anonymous ftp.
4.  The directory on the machine where it can be found.
5.  The author(s) and maintainer(s) of the software.
6.  The licensing status of the software:  public domain, Gnuware,   university property but publicly usable, etc.
7.  Any useful political information about convincing whoever to support
  encryption.
If your mail agent is commercial, then send the name of the
manufacturer and any other information you can think of.

@_date: 1992-11-20 14:18:40
@_author: Eric Hughes 
@_subject: The Cypherpunks Mail Project 
The time is now arrived for a more concerted effort to deploy
It has become clear from the discussions on the list here that the
first step should be encrypted e-mail.  Unfortunately, mail is not
homogeneous; there is no one place to push on the mail system to add
encryption.  Thus, regardless of the method used for encryption, we
will need to add support to every single mail user agent.
I now call for this work to begin.
We will begin with the first step: a survey of existing mail agents.
I volunteer to conduct the survey.  I want to collect the following
information from _everybody_ on the list:
1.  What mail agent(s) do you use to read your everyday mail?
2.  What platforms, hardware and software, do you use it on?
Reply to hughes at soda.berkeley.edu as soon as you read this message.
It only takes a minute to tell me how you read mail.

@_date: 1992-11-25 09:08:00
@_author: Eric Hughes 
@_subject: The Cypherpunks Mail Project 
Let me explain.  You can push on a standard, but that doesn't change
any code.  If everybody in the world read mail with /bin/mail, then
you could rewrite that and add encryption.  What certainly is the case,
though, is that there are a lot of mail readers out there.
It is also the case that the cypherpunks, of all people, should be
using encrypted mailers.  Otherwise we are hypocrites.
Fen advocates MIME, and Ittai concurs.
Ittai asks, relating to existing MIME development work:
It was my vision of this development that people here on the list
would do the work of integration and publish the results.
It is also my suspicion that simple PGP decryption support is fairly
straightforward, being mostly the ability to run a command on a block
and replace the block with the output of the pipe.  This model works
with regular mail and MIME, since it runs at the very top level of the

@_date: 1992-11-25 15:49:42
@_author: Eric Hughes 
@_subject: RS232 Crypto Dongle (idea for widely accessible crypto technology) 
In practice, it will be impossible to make a device that does anything
transparently.  Software has to be rewritten and redesigned around
crypto security.  It is wise not to underestimate or overestimate the
difficulty of doing this.

@_date: 1992-11-25 15:58:26
@_author: Eric Hughes 
@_subject: How far is to far? 
Easy.  This one, though, is not in the crypto literature to my knowledge.
Attack by regulation.
Not, mind you, that it will be enforceable without a bn on
cryptography in general.

@_date: 1992-11-25 16:30:25
@_author: Eric Hughes 
@_subject: RS232 Crypto Dongle (idea for widely accessible crypto technology) 
Phil's comment are right on.  There is a need for you secret keys
to be easily and physically relocatable.
Re: key compromise
It is my own opinion that there will be a market for personal
protection devices only when data is worth money.  Data will be worth
money when some data _is_ money.
I refer to this as WEEM: Write, Erase, Encrypt Memory
Depending on the silicon size and production volume, you could
probably use this device for all modular exponentiation operations.
Or a cheap version could use a DSP module from a cell library and do
all the arithmetic more slowly.
Not only a keypad, but a full 4-function calculator with an LCD
display as well! :-)
Smart cards have the disadvantage that their die size is pretty
severely limited.  They have to fit within the thickness of a credit
card and withstand repeated flexure.
Much better for this application is the PCMCIA standard, which has
plenty of room for circuitry.

@_date: 1992-11-25 16:36:39
@_author: Eric Hughes 
@_subject: The Cypherpunks Mail Project 
I myself read my own mail on an MSDOS machine acting as a terminal
over a dialin.  The unix host is not overly secure, and I'm not about
to go putting keys on it.  I've been thinking about how to solve my
own encryption problem, you can be sure.
But most of the people on the list are reading mail on Unix machines,
and a simple piping interface is the first thing to implement.  I myself
may not use it at first, but it is a start.

@_date: 1992-11-28 10:53:31
@_author: Eric Hughes 
@_subject: bounced mail 
We've made a small change to the way mail gets sent out to the list
which should alleviate the bounced message problem.  The change went
into effect last night.  It should take care of most, but perhaps not
all, of the problems.
So, take heart.  Starting in a few days, please _do_ forward bounce
reports to cypherpunks-request at toad.com.  At that point I'll want them
for further debugging.
with the list maintainer hat on

@_date: 1992-11-30 08:18:40
@_author: Eric Hughes 
@_subject: Electronic Banking 
[Hal Finney describes Chaum's blind signature scheme.]
One such social problem that Hal does not mention is that the blind
signature is a patented algorithm.  You'd have to get a signature from
Chaum.  Since any such company which wanted to deploy with blind
signatures whould be competing with Chaum's own company, DigiCash,
there might be a problem here.
If you wanted to do this as a business, you can start a bank with
(roughly) a million dollars in capital or you can buy an existing one
with at minimum (roughly) fifty thousand.  These minimum investments
are for bank regulation purposes, not operating costs.
So, if you really want to _be_ a bank, it's not that hard.  Your
greatest startup expense will most likely be attorney's fees for a
specialist in bank regulation law.

@_date: 1992-11-30 09:22:03
@_author: Eric Hughes 
@_subject: Secure key exchange 
As mentioned by Hal, the new PGP 2.1 (imminent) has a feature to
create an hash or a public key which can be read over the telephone to
make sure that a key transmitted electronically has not been altered
in transmission.
There's really no need for a physical authentication service with the
telephone verfication ability.
There is just such a plan underway to have a PGP key exchange table at
Usenix in January.
What could easily be printed is the hash function of the key.  That
would be even harder to duplicate.

@_date: 1992-11-30 09:37:45
@_author: Eric Hughes 
@_subject: Secure Key exchange 
Pat Farrell write:
I urge everybody to go out and quote this!
It's a great aphorism.

@_date: 1992-11-30 09:43:34
@_author: Eric Hughes 
@_subject: thoughts on digital cash 
Perry write:
OK, Perry, time to quote sources.  Exactly what laws _do_ prohibit
such bank accounts?
Most political dissidents don't seem to understand that the law is
interpreted accurately, for the most part.  There exist clear
statutory definitions on what a bank is.  If you don't meet those
criteria, you're not a bank.

@_date: 1992-11-30 14:14:20
@_author: Eric Hughes 
@_subject: thoughts on digital cash 
The definition of a bank is an institution that accepts demand
Demand deposits.  Any bank deposit which the depositor may demand
(withdraw) at any time in contrast to time deposit which requires
depositor to wait the specified time before withdrawing or pay a
penalty for early withdrawal.  Funds accepted by bank subject to
immediate withdrawal; such represent largest element in money supply
of the United States.
Certain mutual funds which have checks available to them do not fall
under this classification.  Such a mutual fund might be said to have
deposits, but they are not demand deposits.  You can't get them
whenever you like.  The fine print of such aggreements states that the
mutual fund company does not have to honor the check for up to thirty
days, typically.  Because of the time delay, such deposits are not
payable on "demand."
Mutual funds, though, since they are backed by securities, do fall
under securities law.  Again, from Black's:
For purposes of the Securities Act of 1933 and the Securities Exchange
Act of 1934, the term "security" embraces all investment contracts,
and the test is whether the investment is made in a common enterprise
which is premised upon the reasonable expectation of profits solely
from the managerial or entrepreneurial efforts of others; such test
contains three elements: the investment of money; a common enterprise;
and profits or returns derived soleley from efforts of others.
I merely pointed out that if you're not a bank, you're not under
banking regulation.  This does not preclude regulation under other

@_date: 1992-11-30 14:41:53
@_author: Eric Hughes 
@_subject: thoughts on digital cash 
You've certainly showed us that you believe this Perry, but otherwise
this statement contains no educational content.  This, to me, sounds
like a grown-up version of "Is so!!!" backed up by "My bank account
can beat up your bank account!"
I'd really like to know if ID is required or not, for one, because
that seems to affect the banks liability vis-a-vis presentation of
false credentials.
You made a claim of fact.  I'm asking for you to provide a reference
in support of your claim.  Simple rational discourse.
Now you're putting words into my mouth.  I made no judgement as to
whether I thought this was a good state of affairs.

@_date: 1992-11-30 15:04:22
@_author: Eric Hughes 
@_subject: Electronic Banking 
Hal mentions all the problems a going concern would have with an
electronic banking: patent on the blind signature, RSA license also
required, acceptable use policy, underlying legality.
I agree.  An experimental money system should be fine, practically
speaking.  There will be no problem if no goods or services change
hands.  If everything is scored in points, then there is no concern
about money at all.
More generally, a digital money system is isomorphic to a conserved
quantity server.  For example, if I were to write a distributed
multi-player simulation game, I could represent conserved quantities
such as fuel and ammunition as the equivalent digital money tokens.
That is, in order to fire, I have to "spend" a bullet.

@_date: 1992-10-04 18:59:32
@_author: Eric Hughes 
@_subject: Secure IRC 
The problem with central servers is that they are prone to single
point failure.  That failure may be computer down or key compromise.
A good criterion for this kind of design is not to use central
servers.  This is almost always possible.  (Or always possible,
depending on who you ask.)
There is also the question about getting permission to enter a room,
which corresponds to an authentication or a key distribution or a
voting algorithm or some sort.  You need to know how you want that
_social_ interaction to work before you design protocols.  You should
implement that sociality and test it without encryption to make sure
it's what you want.  Is this sounding familiar?

@_date: 1992-10-04 19:15:03
@_author: Eric Hughes 
@_subject: introducing public keys 
Building a key distribution system takes time.  Start off by having
people mail you diskettes.  Or if you don't mind typing, printouts.
Carry copies of your public key to give to people in person.
Get good security is not free, especially in terms of time.
If you can personally receive via out-of-band channels the public key
of another introducer, you can exchange all the certified keys you
each possess.  And then exchange those with another introducer you know.
Introducers are not a special breed.  Most people should certify
others public keys, if only for redundancy.
Remember, no one has ever set up a non-hierarchical public key
distribution system to the general public.  This is research.

@_date: 1992-10-04 19:17:52
@_author: Eric Hughes 
@_subject: Mail headers 
You aren't the only one Tom.  Apparently lots of Unix mail interfaces
don't let you arbitrarily edit the header or add lines.
I'm going to add a facility to make this possible for everyone.  The
design I have in mind uses only the message body.  No need to touch
the header.
Announcements when it's finished.

@_date: 1992-10-04 19:51:17
@_author: Eric Hughes 
@_subject: introducers 
Let's make this short.
The basic problem with public key systems is to make sure that what
_I_ think is my public key is the same thing as what _you_ think is my
public key.
If these are not the same, something is wrong.  At worst, an
interposer is getting all your mail, decrypting with one public key
and encrypting with a different one.
Servers, generally, are not desirable because they are too prone to
communications filters of the above sort.
For a more detailed reference, read the excellent introduction to the
whole topic of public key distribution in the PGP 2.0 documentation.
Please elaborate.

@_date: 1992-10-05 00:14:29
@_author: Eric Hughes 
@_subject: A statement of purpose 
I've had a bunch of people ask me about the group and what it's up to.
Accordingly, I drafted a small statement of purpose to send to folks.
Please comment.
The cypherpunks list is a forum for discussion about technological
defenses for privacy in the digital domain.  Cypherpunks assume privacy is a good thing and wish there were more
of it.  Cypherpunks acknowledge that those who want privacy must
create it for themselves and not expect governments, corporations, or
other large, faceless organizations to grant them privacy out of
beneficence.  Cypherpunks know that people have been creating their
own privacy for centuries with whispers, envelopes, closed doors, and
couriers.  Cypherpunks do not seek to prevent other people from
speaking about their experiences or their opinions.
The most important means to the defense of privacy is encryption. To
encrypt is to indicate the desire for privacy.  But to encrypt with
weak cryptography is to indicate not too much desire for privacy.
Cypherpunks hope that all people desiring privacy will learn how best
to defend it.
Cypherpunks are therefore devoted to cryptography.  Cypherpunks wish
to learn about it, to teach it, to implement it, and to make more of
it.  Cypherpunks know that cryptographic protocols make social
structures.  Cypherpunks know how to attack a system and how to
defend it.  Cypherpunks know just how hard it is to make good
Cypherpunks love to practice.  They love to play with public key
cryptography.  They love to play with anonymous and pseudonymous mail
forwarding and delivery.  They love to play with DC-nets.  They love
to play with secure communications of all kinds.
Cypherpunks write code.  They know that someone has to write code to
defend privacy, and since it's their privacy, their going to write
it.  Cypherpunks publish their code so that their fellow cypherpunks
may practice and play with it.  Cypherpunks realize that security is
not built in a day and are patient with incremental progress.
Cypherpunks don't care if you don't like the software they write. Cypherpunks know that software can't be destroyed.  Cypherpunks know
that a widely dispersed system can't be shut down.
Cypherpunks will make the networks safe for privacy.

@_date: 1992-10-05 01:23:23
@_author: Eric Hughes 
@_subject: Meeting Sat. Oct. 10, noon, Mt. View 
Second Meeting
Saturday, October 10, 1992
12:00 noon - 6:00 p.m.
Cygnus Support offices
1937 Landings Drive
Mountain View
The second meeting of the cypherpunks will be Saturday at noon.  John
Gilmore has graciously provided us with a meeting space at the new
Cygnus Support offices.  These offices are so new, in fact, that
Cygnus will not have moved in yet.  This meeting will be
bring-your-own-pillow (or chair), since it will be held in largely
empty space.  Directions are at the end of the message.
Attendance is transitive trust, arbitrarily deep.  Invite whoever you
want, and let them do so also, and so on.  Invite them also to join
the mailing list.  Do not, however, just post the announcement.  Time
for that will come.
I'd like everyone who plans on attending the meeting to send me,
hughes at soda.berkeley.edu, a message telling me so.  I'd like to get a
rough head count before Saturday for game planning.
We are starting at noon because of popular demand.  Eat beforehand or
bring a burrito or something.  It will be fine to eat during the first
segment; it won't be any more disruptive than the game is.
Bring your PGP public key for in-person key distribution, preferably
on diskette.  We'll need a portable PC or three to do key
distribution; if you have one you can bring, post to the list and tell
We realized after the first meeting that a strict schedule was
nonsense.  This meeting has a very informal schedule.
Starting at noon, we're going to play session two of the
crypto-anarchy game, in which players try to conduct business under
the watchful eyes of others.  We want to play for two hours and then
have discuss experiences afterward for about an hour.  Some of the
improvements over last time will be flatter denominations of money,
wider distribution of commodities, more watchers (governmental and
otherwise), and perhaps some pre-printed forms.
We'll take a break to regroup for about ten or twenty minutes.
For the second half we'll talk about the security of remailers.  I'll
lead the discussion.  We'll be designing protocols and analyzing
attacks and defenses.  I've done this with DigiCash for electronic
money protocols, and remailers are much easier, but still probably
more than an afternoon's discussion.  We'll do this until six or so,
when people will have to start leaving.
Everyone who wants to will go out for dinner.  I don't know the
restaurants down there; perhaps someone could suggest one?
It's at 1937 Landings Drive, Mt. View.  101 to Amphitheatre Parkway
(the bay side of Rengstorff Ave), go right at the first light,
pass a right turn, and just before the road crests a tiny hill,
turn right into the Landings complex.  We're in Building H.

@_date: 1992-10-06 18:30:07
@_author: Eric Hughes 
@_subject: Nuts & Acorns 
In large part the electronic environment is already pseudonymous.  I
don't know most Usenet posters personally and never will.  I have no
need to personally verify their identities; in fact, I don't even want
But for someone I'm going to deal with over a period of time, I do
want to make sure that it's the same person I'm dealing with each
time.  And if I never happen to meet this person face to face, or need
to know anything about this person as a physical being, so be it.  All
I really care about is persistence, not identity.
In the elctronic world, all you have are persistent pseudonyms.  Most
of them, true, are still linked to physical people, but there is no
particular reason why that need continue.
I think the changeover point will be this.  As soon as there is money
flowing through the networks which is tied only to pseudonyms and not
to physical people, then you'll see a _lot_ more virtual-only
identities.  When you can conduct business and get paid for it,
there's a big difference.  When some of your data has negotiable cash
value, you'll see privacy and security get *important*.
And most of these identities will have regular sounding names.
Handles, a la the underground, are more a mark of social identity than
of anonymity.  The best camouflage is not to draw attention to
yourself.  When most of the world is personal, look personal.  Who
will ever know?

@_date: 1992-10-08 08:57:23
@_author: Eric Hughes 
@_subject: Subscriptions, etc. 
Yow! I'm a hypocrite!
Now _I_ forgot to look at the reply line.  Damn.
Diligence, diligence.
In other news, the list membership is up to 60 people and one local
newsgroup gateway.  I have five more to add, some of whose addresses I
have to find out.

@_date: 1992-10-08 19:40:31
@_author: Eric Hughes 
@_subject: Oct. 10 RSVP's 
As of tonight, Thursday 10, the Saturday meeting is in two days.
I'd like to get RSVP's from everyone who plans to attend, so that I
know how many are going to be there.
SEND ONE EVEN IF YOU THINK I KNOW THAT YOU'RE COMING!
I can't keep everyone's attendance plans straight.

@_date: 1992-10-08 23:56:11
@_author: Eric Hughes 
@_subject: New feature of the remailer 
New!  Just finished.  Fidonet support.  Dumb mailer support.  Incoming
header line pasting.
Here's what's going on.  There are a lot of mailers, the Fidonet
gateway in particular, which don't allow you to put arbitrary header
lines in your outgoing messages.  Previously people using these
systems couldn't use the remailer because they couldn't put the
necessary "Request-Remailing-To:" in the header.
Now they can.  Instead of putting header lines into actual header, I
now support a syntax which allows header lines to be _added_ to the
header on incoming mail.  These extended header lines are in the body
of the message proper, but a filter on incoming mail effectively
adds them to the header.  This allows anybody who can send me mail with a reasonably unmangled
body to use any feature of the remailer that should ever get written.
------- cut here -------
Request-Remailing-To: Crusader_Rabbit at rocky.moosylvania.org
I just paid $2600 for this recipe [etc. etc.]
------- cut here -------
If "::" is on the first body line all by itself, whatever lines follow
up to the first blank line will be appended to the header when it is
scanned for special instruction lines.
This new feature is completely modular.  It doesn't (seem to) break
any of the other existing features.  I'll post the source with an
explanation tomorrow.
In the meantime, try it out.

@_date: 1992-10-09 09:43:05
@_author: Eric Hughes 
@_subject: The technical explanation of "::" incoming header pasting 
There's a new feature in the remailing software.
Some people can't add arbitrary header fields because of mailer or
gateway restrictions.  This restricts them from using the remailer.  I
have added a facility to allow new header fields to be pasted onto the
end of a header when the mail arrives.  This effectively happens
before processing by the remailer software.  These new fields exist
during transit in the message body, where they remain untouched.  Only
after the message is delivered to my account does this operator
take effect.
Syntax: If the first line of the body is the two characters "::", then
the following lines are appended to the header, up to the next blank
Here's how it works.
First of all, here's my new .maildelivery file:
------- cut here -------
# field			pattern	action/	string #				result	(quote included spaces)
Request-Remailing-To	""	pipe R	"perl remailer/remail.perl" Request-Remailing-To	""	file R	remailer/archive
*			""	pipe R	"/usr/local/lib/mh/rcvtty -biff"
*			""	pipe ?	"perl remailer/incoming.header.perl"
------- cut here -------
Comments are indicated by   The Request-Remailing-To lines have been
there.  The second of the makes an archive for debugging purposes.  It
will go eventually.  The third field, "*", indicates all fields, it
runs 'rcvtty' on my mail; this replaces the function of biff, since
mail is getting piped to slocal now, disabling biff.
The last line is the important one.  It says "If the mail hasn't been
delivered by now, run the incoming header rewrite script on it.  If
that doesn't work, continue trying to deliver it."
Now here's the trick.  slocal has no way of taking the output of the
rewrite and continuing to process it.  (It should.  It would make this
whole job easy.)  So in order to continue processing, you need to
redeliver the mail.  You could invoke sendmail and mail it back to
yourself, but that would mangle the existing header.  So the thing to
do is to recursively invoke slocal from within the perl script.
Here's the perl script to do all this:
------- cut here -------
  # First read in the whole header.
  # We check for the Second-Pass: line to detect infinite loops.
while (<>) {
  # We have just read the last line in the header.
  # Now we check to see if there is a pasting operator.
if ( ( $_ = <> ) && /^::$/ ) {
} else {
# There was a header pasting operator.
#   So we open 'slocal' as a pipe, effectively redelivering the mail
#   back to ourselves.
 OUTPUT, ">foo" ) ;
open( OUTPUT, "| /usr/local/lib/mh/slocal -user hughes" ) ;
select( OUTPUT ) ;
# print a "From " line to satisfy slocal
 = ( "Sun","Mon","Tue","Wed","Thu","Fri", "Sat" ) ;
 = ( "Jan","Feb","Mar","Apr","May",
($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) = localtime ;
printf "From hughes  %s %s ",  $wday ],  $mon ] ;
printf "%2d %02d:%02d:%02d 19%d\n", $mday, $hour, $min, $sec, $year ;
# Now just print out the message
print $header ;
print "Second-Pass:\n" ;
print "\n" ; while (<>) {
} continue {
------- cut here -------
Here's how the perl script works.
The first loop reads lines from the existing header.  When it sees a
blank line (regexp /^$/) it terminates the loop.  If it sees a field
"Second-Pass", it knows it has filtered this message before and exits
with a return code indicating that the mail has not been delivered.
The variable $header is appended with the current header line.
$header contains the whole header when the loop terminates.
Properly speaking, the Second-Pass test is not necessary to detect
infinite loops.  Since the pasting operator gets removed during the
rewrite, the script won't return an exit status of 0 more times than
the pasting operator appears.  But should something get screwed up,
such as a different module adding pasting commands (how? I don't know),
the Second-Pass test should prevent infinite recursion.
The next statement reads another line from the input file.  This line
is the first line of the message body.  If this line is the pasting
operator, then header lines are accumulated in $header as before until
a blank line.  The difference is that these header lines are being
read from the body of the message.  If there is no pasting operator,
the script exits undelivered.
At this point we now have to redeliver the message back to ourselves.
We first open slocal as the output pipe.
The next section is a kludge.  It turns out that slocal strips off the
out-of-band "From " (no colon) line that the mail delivery system
uses.  In other words, the message which slocal pipes into its pipes
is not identical to the message it itself received.  This means that
slocal cannot be directly recursed.  What this section does is to
create a "From " line to make slocal happy.  It calls localtime() and
then formats those numbers into the proper form.
It turns out that slocal will deliver this mail without the "From "
line, even to /usr/spool/mail, but it doesn't do so properly.  On my
system, in added some delimiters which I think I've tracked down to
the 'mtstailor' file, namely mmdelivery1 and mmdelivery2.  Since these
are not null on my system, there's some garbage added which screws up
separation of the spool file into messages.  Adding a "From " line
fixes that.  This misbehavior may not be so surprising, considering
that slocal was "meant" to be invoked only in a .forward file.
Now we print the variable $header which contains the whole header,
including newlines.  Using a single string removes the need for an
array.  We added the Second-Pass line and a blank line for the end of
the header.  The final loop prints out the rest of the message body.
There is another way to proceed to get the same functionality.  One
could write a filter to translate the first occurrence only of
\n\n::\n into \n. We could then pass the message through this filter
before slocal saw it.  And for now, that would do the same thing.
But suppose we want more that one rewrite rule active?  Then you would
only be able to apply each rewrite rule exactly once in fixed order.
You want to be able to rewrite a message and then apply all the
rewrite rules again.  At least one other rewrite rule is planned: automatic decryption.
Since decrypting a message will completely change the body, and since
some of the header fields may need to be hidden, you have to be able
to decrypt the body and then paste on header lines.  But since you
need to indicate an encrypted body by a header line (well, not really,
but it's more reliable), and since some people can't add these header
lines, you need to paste lines before encryption as well.
Thus the rewrite rules need to be applied asyncronously and hence I'm
using a fairly complex slocal scheme to do a simple filter.
Eventually I hope to write an equivalent to slocal which knows about
message rewrites and simple filters, but that's for later.

@_date: 1992-10-10 07:29:03
@_author: Eric Hughes 
@_subject: +-=*^ 
George recommends one-time pads.
The key distribution problem for one-time pads is *much* worse than
for public key systems, or even conventional secret key ciphers for
that matter.  You still have to exchange keys without transmission
(i.e. face to face meetings again, or mail, etc.).  Anything that is
secure for exchanging a one-time pad is also secure for exchanging
public keys.  Then you have to do this again when your pad runs out.
The bandwidth required for one-time keys is much higher than for
conventional keys to boot.
But the biggest advantage of public key systems is that I can sign
someone else's key, and if you know my key, then you know his.
To put it more humorously, you will have exchanged cryptographic
fluids with everyone I have as well.  This is a good thing.

@_date: 1992-10-11 11:52:00
@_author: Eric Hughes 
@_subject: one time pads 
The cost of key storage is trivial: a fraction
   of the cost of the yearly (or less frequent) travel to meet each
   correspondent in person.
Let me emphasize _each_ in that sentence.  One time pads are very
expensive on a per-link basis than public key systems for this reason
only.  Per-link is one person-to-person link.
   Consider replaceable hard drive cartridges (30 meg
   for about a buck a meg), digital cassette formats including applications
   involving videocassettes, and so on.  Suppose one cartridge per link.  That's $30 per link.  Per link,
that's a _lot_ of money.
   "Bandwidth required is much higher..."  In what way?  Whatever channel you use to transmit keys on, be it 30 Mb cartridges
or what, will be more efficiently used by an exchange which requires
less storage.  In the case of cartridges, the UPS cost to ship one is
still only about 1/5 of the cost of a cartridge.  A 3 1/2 inch floppy
can be shipped for one or two ounces of postage.
   However, RSA is just one mathematical breakthrough
   away from being obsolete, and we have no way of knowing when that
   breakthrough occurs.
It is also one breakthrough away from being known to be fully secure.
Not only do we not know when that will happen, we don't know which
will happen.
   It may also be that massively parallel processors can
   be built through VLSI technology, allowing the cost of brute force solutions
   to come down to a reasonable level.  Look at the figures for best know factoring algorithms.  Now estimate
the total amount of silicon output per annum in the US and estimate
it's computational ability.  I think you'll find that it would still
take on the order of years to factor a single 1024 bit modulus.
The difficulty of hard problems and the scale of the solar system are
two things which are both extremely difficult to get any intuition
   I would suggest that we need a number of different systems, and
   need to keep them all in fairly constant use.  [...]  Now I'm just
   suggesting that a One-Time system should be another one among the
   many.
Here's the bottom line: More security, more cost.  Perfect security is
not worth the cost in time, effort, or dollars when the marginal cost
of perfection is less than the marginal benefit.
Even SWIFT, the international monetary wire transfer system, does not
use one time pads for link encryption.  Now here is a network which
breaking into would be worth billions (that's thousands of millions,
let me remind you).  The chief executives of SWIFT exchanges keys by
post.  One time pads are useful for all sorts of things, but they are very
expensive to use.  They are useful in protocols for blinding and key
exchanges.  They do not seem to be useful for end-to-end link
encryption, however.

@_date: 1992-10-11 11:52:09
@_author: Eric Hughes 
@_subject: [gg@well.sf.ca.us: Re: +-=*^] 
There is a bit of confusion about the various lists and addresses.
My main address is hughes at soda.berkeley.edu.  The remailer runs from
this account.  All the perl scripts are there.
The account I use to maintain the mailing list is on toad.com, as well
as the mailing list itself.  Its software is nothing but sendmail; no
perl scripts.

@_date: 1992-10-12 08:20:43
@_author: Eric Hughes 
@_subject: Next meeting: Nov. 21 
The next physical cypherpunks meeting was decided on Saturday at
that meeting.  It will be Saturday, November 21, starting at noon at
the Cygnus Support offices in Mountain View.  I am announcing the date
now so that you can put it on your calendar.

@_date: 1992-10-12 15:40:05
@_author: Eric Hughes 
@_subject: Game items 
Re: drugs and simulation games.
At the meeting last Saturday, we played the second incarnation of the
remailing simulation game.  In a nutshell, the game is intended to
teach people about how to protect their privacy by using encryption to
prevent against monitoring and by using remailing to protect their
identities.  Since the game is also in part an economic simulation, I
tried to pick game objects which someone had some interest in keeping
quiet.  I picked drugs, of unspecified name, as a prominent game item.
This, by wide acclamation, is a mistake.  Since the primary reason to
pick this was a paucity of imagination, I now ask for help from the
We want to develop a list of game items, physical objects, which will
be the goods of transaction.  I would like to pick objects that have
been illegal in the past, but which are not anymore.  They should not
be primarily information, such as copies of _Ulysses_.  They should
not now be restricted.  Nor should they be weapons, such as crossbows
or samurai swords.  They should, however, be objects that are known to
have generated some emotional reactions in the past.
There are two suggestions that meet these criteria: contraceptives and
printing presses (or xerox machines).  I would like to find more.
Please make your suggestions.
Another possibility is to use items which have been the subject of
state-enforced monopolies in the past, such as pepper or nutmeg.
Be creative.  We'd like to get a good list of twenty or so items.

@_date: 1992-10-13 08:51:51
@_author: Eric Hughes 
@_subject: one time pads 
Previously I said about one-time pads: "High security, high cost."
(Well, not exactly that...)  I invoked it then in order to argue that
I personally didn't need to use one-time pads.  Implicit also in that
statement is the claim that when the worth of security is high, the
cost may be relatively cheap.  George and I agree on this point.
When you are fighting a military battle, when you have a government
pissed off at you in a serious way, you need as good as you can get.
Since you can get perfect end-to-end link encryption, you use it.
All cryptography is economics.  Repeat after me.  All cryptography is
I don't need one-time pads.  Sendero Luminoso does.  It's as easy as
that.  It's merely a matter of scale.  Large scale, high security.
Small scale, pretty good security.
Re: Mathematical breakthroughs.  George missed my main point here.  We
don't know whether factoring is "fundamentally hard." (Project your
own definition here.)  We should not assume that when the breakthrough
comes, that is will be found "easy."  It may be that factoring is
hard, and that RSA is secure for that reason.  (The astute reader will
see that these two are not exactly the same question.)  My current
thinking is that factoring is hard because of various randomness
properties of primes, that in fact multiplying one large prime by
another is like encrypting one prime with the other as a one-time pad!
But I'm no number theorist.
I do, however, agree with "caution in the face of an unknown."  And
for high stakes, George's "irrational caution" is not irrational at
Re: Relative security.  It seems I had an editing error.  What I meant
to say (paraphrased) was the following.  Perfect security is not worth
the cost when the marginal cost of perfect security is more than the
marginal benefits of such security.  This encompasses both the high
end and the low end.  I don't need one-time pads.  Abu Nidal does.
Repeat after me.  Cryptography is all economics.

@_date: 1992-10-13 09:03:14
@_author: Eric Hughes 
@_subject: Mr. Squirrel?  Just who is who here? 
Hugh asks how, in a broadcast network, we may verify identity.  The
answer is "statistically."  Not everyone needs to verify each message;
only those who communicate with the sender personally (and who thus
know the private keys) need to.
Hugh mentions the "one-on-one signed signature method" and that it is
not applicable to broadcast.  Well, signing the whole message is not,
but signing a message digest is.  This is the whole reason for message
digests, that a message may go out in cleartext, but the validating
information for that message be encrypted.  Thus everyone can read the
message, even without knowledge of the public key, but it is possible
to verify the identity if you know it, i.e. you know the private key.

@_date: 1992-10-13 09:15:29
@_author: Eric Hughes 
@_subject: Mail headers 
Hugh's comments brought up a idea to me.
RFC 822 is the standard for the format of Internet mail messages.
Anybody interested in the remailer should eventually read this thing.
In it there is already a standard header field "Encrypted."  It
accepts two optional arguments, a decryption type and an identifier
(say, for key lookup).  So we have a way of automatically telling
encrypted message without doing pattern recognition on the body.
I propose a couple more header fields.  "Digest" for signed message
digests.  "Key-Mgmt" for the distribution of new keys and key
compromise certificates, i.e. for automatic key distribution.
What else do we need to make a fairly automated crypto mail system?

@_date: 1992-10-13 11:49:36
@_author: Eric Hughes 
@_subject: Mr. Squirrel 
A signature on a message is dependent on the contents of the message;
it is not a free floating bit of information.  You can't copy a
signature, therefore, without copying the message or find another
message that hashes to the same value.  This is the design criterion
behind one-way functions--that you can't (feasibly) find a message
that hashes to a given value.

@_date: 1992-10-17 13:51:21
@_author: Eric Hughes 
@_subject: one time pads 
One time pad systems are expensive enough and in uncommon enough use
that I doubt they are going to get written as free software.  I
personally am not going to work on them, because I don't want to go
buy the necessary hardware to generate and hold sufficient key
material for a practical application.
You also need hardware random number generators for a secure OTP
system.  Such boxes are not readily available, or come cheap.  While
not obvious, making random bits is a very deep problem.  See Knuth
volume 2 for some insights.
I suspect that this same argument holds for all the rest of the people
in the group as well.  I don't know of anybody who wants to implement
this system for themselves, given the cost involved.
Cryptography is all economics, and the economics here are that one
time pad systems are expensive enough that the software that gets
written for them will be for in-house use or will be commercial.  In
either case, someone is paying someone else for developing the
It might be possible that there are enough people who do want this
that there is some money for development.  A perfectly possible
outcome is the creation of a consortium to hire some implementers who
would make some gnu-ware.  Such organization does not exist.  Until it
does, an off-the-shelf OTP system won't exist.

@_date: 1992-10-17 14:15:21
@_author: Eric Hughes 
@_subject: physical security 
Physical security for pgp is also necessary if you store your pass
phrase in memory.
As far as modification, detection is good enough, but you'd better
make sure your program to detect modifications is not itself
compromised!  (Does anybody detect an imminent arms race here?)
Eric Hollander is correct.  Ideally, your keys and your encryption
mechanism should be kept secure.  At some point in the future, a small
card which contains all of this will be standard equipment, as well as
a port to plug it into.

@_date: 1992-10-17 15:10:14
@_author: Eric Hughes 
@_subject: Keystone 
First, let me congratulate Loyd and the others involved with Keystone
for working towards the creation of a local distribution mechanism for
keys.  Every city in the U.S. needs something like this.  If it's not
happening in your area, start it.  Start by getting PGP and making your
own key.  Then exchange keys with people you know.
We have members of the list in many parts of the U.S., Canada, and
Europe.  There's plenty of work to do.  Look around.  If no one else
is doing this, you should.
There are, roughly speaking, two kinds of privacy; one is provided,
and one is defended.  Provided privacy is unstable, since the person
using the privacy does not create it.  Defended privacy is stable,
because those who want privacy create it themselves to the level at
which they want it.  Both systems do provide privacy, no mistake.
I would be hesitant to implement a system that _only_ required a user
to generate a key pair.  This, for the users, is too much provided
privacy.  It will not teach the users how privacy really works, nor
will it give them any good idea how their privacy is being maintained.
Defended privacy does not need to be difficult.  I would spend effort,
instead of modifying BBS software, to make it easier for users to
handle encrypted email with their own terminal programs.  Now, any privacy is better than none.  I don't really know if it is
easier to modify your BBS or your modem program.  But all other things
being equal, make it easier for users to maintain their own privacy.
Again, trusted systems can turn into provided privacy.  If there is a
distributed solution you can think up, use it.
This should not be such an onerous task.  It might be now, but that
can change.  Finding ways for users to manage keys, to get keys, and
to look up keys are all interesting and useful problems to solve.
Every user should encrypt outgoing mail on the home system before it
leaves and decrypt incoming mail on the home system after it arrives.
If this is not easy, it should be made easy.
Not every user need have the complete directory on their own system.
They merely need a way to communicate with those that they want to.
This probably means a directory service, where people can download
keys for the people they want to communicate with.  Moving around a
complete directory does not scale well.
As far as BBS support, if I want to respond to someone and I don't
have the corresponding key, I should be able to initiate a zmodem
transfer of that key relatively easily, for instance without leaving
the discussion area to go to a download area.

@_date: 1992-10-19 08:48:48
@_author: Eric Hughes 
@_subject: one time pads. 
Keith's CD-for-a-pad idea is a variant of a book code.  In a book
code, parts of the key are in various standard books, often the bible.
Advantages: easier key distribution.  Disadvantages: key material is public.  Should an internal spy learn
the few bits of addressing information (which CD, where), the cipher
is compromised.

@_date: 1992-10-20 08:33:46
@_author: Eric Hughes 
@_subject: More private PGP...? 
First, let me get on record as saying that Hal's "innocent mode" is a
good idea that should be implemented.
But it's not really a good long-term solution from a social point of
view.  Encrypted traffic should become the norm, not the exception.
Flagging that you're sending encrypted traffic should be encouraged.
When questioned about this, people should respond in shocked tones
"What do mean?  Aren't you encrypting _your_ email?" and then proceed
to suppress gentle laughter at them when they say no.
When it's cool to encrypt, only the uncool will be plain.
So, then, more peer pressure!  Consider someone asking you about your
encrypted mail to be an opportunity to start a conversation about
their position on personal privacy.  When your sysadmin asks why your
mail can't be read, tell him you are defending your privacy and ask if
there is any problem with that.  Then, when the sysadmin puts in a
filter for PGP traffic, use innocent mode.
Absolutely.  Ditto for signatures.  Both should be able to be
selectively removed.  In any case, it should be possible to have
nothing appear on the outer envelope.
Another feature for PGP would be automatic message padding.  To
properly do a mix you need to quantize the message lengths.  If PGP
were to automatically pad with random data, it would save a lot of
integration work for the mix.  PGP already has a random number
generator, after all.

@_date: 1992-10-20 09:15:10
@_author: Eric Hughes 
@_subject: Tempest. 
About Tempest.
The ability to monitor is real; it's more powerful than you would first
You can get a lot of insight into what is possible by looking at what
is sold as parts for Tempest certification.  There is some trade
publication devoted entirely to such matters; it's called EMI/RFI
News, or Interference Protection News, or something like that.  It's
free to qualified subscribers.  The articles are interesting, but
cannot delve into the really interesting stuff.  But the ads!  Look at
what people are selling, and remember that it is protecting against
something.  Stuff like copper impregnated gasket material, both for
computer cases and for doors (in walls).  Copper braid and cloth.
Conductive glues and caulks.  Special connectors.  Electrical
isolators.  Fiber optics.
(Aside: If you don't know how to be a qualified subscriber, you're no
hacker.  Look closely at the subscription card and then figure out
where the publisher of a free magazine gets its money.)
What is possible?  CRT monitoring.  A Dutch guy named van Eyck
demostrated six years ago or so a CRT monitoring system which he built
out of spare parts.  It consisted of an TV roof antenna, a non-detent
UHF tuner (which you can make yourself by removing the detent plate
from an old TV), and a multi-scanning monitor.  No amplification
beyond what was in the tuner, no sync stabilization, no special
directional antennas or any other tricks.  He was able to reliably
pick up monitor emissions from 100 meters, if I remember correctly.
Fancier equipment knows what your screen sync rate is, uses bandpass
filters, uses better antennas, knows to look for mostly-persistent
frame information, looks for emissions signatures, and is able to read
one CRT out of a hundred at half a mile.  I suspect this is a low
estimate of the ability of modern equipment.
Hal mentions using flat panel displays to combat emissions.  This
works, as evidenced by the continued existence of Grid Computer.
Remember Grid, who came out with these way-expensive gas plasma
laptops around 1985/6?  The reason they sold so many of those and are
still around was that a large number of them were Tempest certified.
(Even larger revenues!)  I understand that the Tempest spec Grids had
a thin layer of gold foil in front of the screen, even so.  Yes, gold
thin enough to see through.
Signal wire monitoring.  Using twisted pair or coax cable, reduces
transmitted energy down to very low levels, improving energy transfer
and reducing monitorability.  But even with zero radiated energy there
is still the near field of the wire which can be inductively tapped.
No conductive contact is necessary.  If you can put a wire next to my
phone line somewhere, you can tap my phone.  It's by nature a high
impedance tap, requring sensitive ampilifiers but at the same time
difficult to find even by a reflectometer.
Without a twisted pair, the situation is worse.  Keyboards for the PC
use a serial protocol at a fixed frequency.  The cables are not
twisted pair.  I haven't heard anything about that specifically, but I
presume that keystrokes can be read extremely easily.
CPU monitoring.  Yes, it's possible.  I've heard that it is possible
to actually run a CPU in parallel with a monitored one.  In order to
do this, you need to correlate signals in real time across a fairly
wide RF spectrum.  Each CPU pin or I/O bus signal occurs in a
different physical location inside the case.  The case is active in
terms of emmission, reflecting signals around like mad.  All these
different physical locations and reflections give rise to phase
differences and interference patterns.  Once you figure out what the
signatures of the various signals are, you can separate them out from
each other by correlation and deconvolution.  George's concern about
emissions through phone lines falls into this category.
Other stuff.  I've heard rumors about using microwave pinging to
determine stuff about electrical equipment.  Or about implanting
passive devices that alter the EM field locally in order to make
monitoring easier.  It's safe to presume that there is some amazing
stuff going on.  Read The Puzzle Palace for more hints.  (Like the
valley in WV which is one big antenna.)
Emissions monitoring is also all economics.  The price to monitor
increases with each more sophisticated attack.  CRT's are easy, CPU's
are hard.  I would like to see public research in this area, just like
there is public research in cryptography.  Until the public has a
better idea of what various attacks cost, there can't be rational
decisions about emissions security.

@_date: 1992-10-21 09:43:25
@_author: Eric Hughes 
@_subject: Keystone 
Where is the key pair generated?  It must be on the BBS since your
user may not have PGP running.  The private key isn't private!  The
work to do public key encryption in the first place is hardly valuable
if the owner of the private key doesn't hold it.
If you just want inter-BBS privacy, why not set up each BBS with a PGP
key pair, and use that for transfering messages?  There's not much
difference in security.  A monitoring sysop would be able to read all
the traffic originating on that board in either system.  The
difference is that such a monitoring sysop would not be able to read
replies.  Why?  Because the private keys are kept on the originating
But it sounds as though you're trying to prevent against external
monitoring and that you trust your sysops.  In this case there is no
advantage to issuing keys to individuals; it's just not worth the
This is the unfortunate fact of the situation, I acknowledge.  But do
you know what terminal programs are in the most common use?  I suspect
most of this stuff could be done with script programming in the
various terminal packages.
Do you know, in aggregate, how many users of each terminal program you
have?  You can poll your users to find out.  You'll need this data to allocate your effort.
And you've got lots of people willing to help, even if they can't
because they are working on other projects.  Everyone on this list,
for example.  Let me repeat, for those of you who did not previously
know you were willing to help.  Everyone on this list should be
willing to help Loyd write scripts for his users to use PGP.  Cypherpunks write code.
This will mean someone who knows Procomm, Crosstalk, Qmodem, Telix,
etc.  for the PC, someone who knows the various Mac, Amiga, Atari, and
other machines.  This will mean someone to write nice pretty visual
interfaces for PGP to put all the PGP options on menus where they are
all visible.  This will mean people to think about BBS/terminal
protocols.  This will mean lots of individual contributions, no single
of which need be large, but whose sum will be.

@_date: 1992-10-21 10:11:42
@_author: Eric Hughes 
@_subject: TEMPEST, Eavesdropping 
When banks start signing with private keys, then we get an even more
interesting monitoring problem.
Sometimes it is cheaper to build a whole building to be tempest-spec
than to buy all tempest-spec electronics.  What I have heard about
such stuff is solid copper walls and no windows.  No exacly your
classical Faraday cage; more like your classical Gaussian surface. :->
TEMPEST is an acronym.  I don't remember for what.

@_date: 1992-10-21 10:13:36
@_author: Eric Hughes 
@_subject: another service 
Re: digital timestamping.  Eric Hollander says:
Yes.  Send code.

@_date: 1992-10-21 22:35:21
@_author: Eric Hughes 
@_subject: Keystone 
Ah.  A small PGP subset.  You hadn't mentioned this.  When you said
you weren't requiring the user to run PGP, I assumed key generation
must occur on the board.
As for your fatal flaw I hadn't spotted, I had spotted it, and the
location of the private key was the critical point.  If the key is on
the BBS, the message goes out in the clear.
Look, it boils down to this.  If the message traffic to the BBS is to
be encrypted, then the user has to generate a key on his own machine
and decrypt it on his own machine.  There's no way around that.
But the user interface problem can be solved.  Just make a bunch of
.com files which do nothing but spawn pgp by invoking the correct
arguments.  Very simple; a few lines of C is all.  Even the PGPPATH
can be set before the spawn.  It's an easy encapsulation.  It will run
a bit slower for load time, but not appreciably.  And you won't have
to recompile PGP from the distributed executables.

@_date: 1992-10-22 08:51:19
@_author: Eric Hughes 
@_subject: Keystone 
Re: adding D-H key exchange to PC software
But source code is not available.  The trouble is that all the decent
terminal programs for PC's are shareware or commercial (or were
originally shareware and have become commercial).  I too would like to
know of any source-available PC terminal programs, but I suspect there
are none because of the prevailing shareware culture.
Re: getting an author to license D-H key exchange
The reason this will not happen is not the bootstrapping problem
(chicken/egg), but that there is no perceived value to an encrypted
link.  The sysop is already has access to everything on the dedicated
machine and may even have a policy of scanning all messages.  External
hackers can't really get in because shell access isn't really done
remotely.  The only ones you are protecting against are people with a
hard tap on the phone line itself.  For most people, this is not a
Since there's no perceived value and since all the software would
require license from RSADSI, it won't happen that way.
Re: using a protocol layer
That's not possible either.  Most terminal programs write directly to
the hardware.  This is single-tasking, standardized hardware,
remember, and the original BIOS interface for the serial port was
totally unusable.  Some communications programs use FOSSIL drivers,
but many (if not most) terminal programs don't support it.  (FOSSIL is
a BIOS-level serial port interface description which could hooked into
or rewritten to support a protocol.)
Look, I wish all this stuff were in use.  Everyone should encrypt all
their communications links as a matter of policy.  (That includes
voice, and if you thought the PC terminal program bootstrapping was
difficult ...)  Let's move incrementally, though.  If we can get
people to at least encrypt all of their e-mail, that will be an
excellent start.
One incentive would be for the BBS operators to phase in a policy that
they will accept no e-mail which is _not_ encrypted.  Comments?

@_date: 1992-10-22 23:02:09
@_author: Eric Hughes 
@_subject: BBS E-mail policy 
Re: distinguishing between encrypted mail, plaintext mail, and
I'm really glad this question came up.  I passed over it before
because I was more interested in the social issue, but the technical
one is important.
The basic technique is the foundation of cryptography: information
theory.  For this application, you can just measure the entropy; it
alone should be able to distinguish between the three sources.  The
entropy measures how well one can statistically predict the output of
a source.  A random source has eight bits of entropy per byte.  As
randomness decreases, so does the entropy measure.  (Mail me if you
want references in order to learn this stuff yourself.)
Now line noise, let's say, will appear random.  So its entropy should
be right near the maximum, 8 bits.  Text encrypted with PGP using the
ASCII armor uses only 64 characters out of 256 possible, or one fourth
of the total available.  Its entropy would be 2 bits per character.
English text is usually around four and five bits per character, if I
remember right.
To calculate the entropy, you first make a table (of size 256) of
character frequencies normalized to the range [0,1].  Call these p_i.
The entropy is then (TeX here) $ \Sum_{i=0}^{256}n - p_i \log_2 p_i $.
(The log base 2 give bits instead of natural units).
Now see if this number is in one of the following ranges:
This is a very simple measure.  There are other measures to look for
the deviation from an expected distribution, which give much more
accurate distinctions.  One can very easily separate languages from
each other just by looking at such measures.
Note that none of these techniques ever look at the content.  Nor do
they look at digraph (two-letter combinations) or trigraph statistics.
In fact, the content is completely destroyed by the scanning process!
Lots of this stuff is known; this is how the big boys crack codes.
I'm glad there arose a natural context to explain some of this stuff.

@_date: 1992-10-22 23:22:28
@_author: Eric Hughes 
@_subject: Keystone 
Re: about a policy to require encrypted email.
Here is a statement I would like to see become policy and law:
"A provider of communications services cannot be held liable for the
consequences of encrypted communications that pass though its system."
Here is the argument to support it.  If I am a common carrier, I am
already off the liability hook by the nature of common carrier.
Suppose I am not a common carrier, for example because I provide a
value-added service such as electronic mail.  Also suppose that I
can't observe the contents of traffic that flows through my system
because it is encrypted.  Then I have no means to take any action
whatsoever with regard whatever consequences might occur from that
traffic.  I cannot be held responsible for actions I cannot take, much
less know of the existence of.
Such a policy would give BBS operators a complete defense against
claims of liability arising from email traffic.  It doesn't solve the
problem for public discussion areas, but it's a good start.  It would
also drive the deployment of encryption technology.

@_date: 1992-10-23 09:30:05
@_author: Eric Hughes 
@_subject: Diffie-Hellman 
This is what I remember about PKP.  Public Key Partners is a
consortium of four, two industry and two academic members.  RSA Data
Security and Cylink are the industry partners.  I believe that
Stanford and MIT are the academic ones.

@_date: 1992-10-23 10:27:18
@_author: Eric Hughes 
@_subject: Keystone 
My proposal:
First let me point out that this wording is intended to be clear, not
to be legally useful.  This wording cannot stand for itself without
reference to the rest of the body of law.  I never intended it to.
It is also a mistake to think that I am advocating the converse,
namely, that the provider would be responsible for all unencrypted
communications.  Nor do I think that this should be the only defense a
provider has available.
The defense of encrypted communications is not germane here.  Such
knowledge did not come from the communications because they were
encrypted.  If the provider could read them, then they weren't
encrypted to the provider.  Therefore such knowledge came from some
other source.  A claim that arises from such knowledge is not met by
this criterion.
The defense of encrypted communications is not a blanket defense.
Then the defense does not apply.  If the provider has keys to the
communications, then they are not encrypted as far as the provider is
concerned.  The question is not the _form_ of the communications, but
their _legibility_.
If the keys are in the possession of the provider and the provider and
the user have an agreement that the provider is not to use them in any
way other than archiving them, then the law cannot expect the provider
to routinely breach that agreement to search for possibly illegal
content.  The court may then subpoena these keys if necessary.
The defense of encrypted communications is not germane here.  There is
a parent/child relation which creates a claim which the encrypted
communication defense is irrelevant to.
The test of due diligence may be applied.  If the state of the art is
that the encryption is unbreakable, then the communications should be
consider to be encrypted.  If the cipher is automatically crackable,
such as monoalphabetic substitution, then the communications should be
consider _not_ encrypted.  Remember, the question is not _form_, but
No, this is not the principle I was getting at.  I was referring to a
principle which was more restricted in its use but which is also
clearer in its interpretation.
This defense is a subset of the defense of no control.  If you can't
read the content, then _a fortiori_ you can't control it either.  It's
really very clear that if you have no basis for distinguishing
communications except for size, time, sender, and recipient, that you
can't act on anything that passes through the system.
This is a good sign.  I heartily approve.  But it is easier to define
legibility with regard to encryption than it is to define control.
Referring to encrypted communications is much less ambiguous and
should be considered a step in the larger direction.

@_date: 1992-10-23 10:33:40
@_author: Eric Hughes 
@_subject: TEMPEST 
It should be possible to jam your own emissions, but that same noise
might cause be picked up by your own equipment as well and cause
errors.  Also remember that most of these signals are detected by
correlation, which detects a signal even with a very high S/N ratio.
So it's not obvious just how to jam.  My first guess is to phase-lock
onto your own emmissions and then broadcast random bits at higher
With E/M monitoring, just like cryptography, you don't really know how
to make defenses unless you know how to attack.

@_date: 1992-10-23 23:20:44
@_author: Eric Hughes 
@_subject: entropy measures 
uuencoding will have a slightly lower single-character entropy than
the ASCII armor PGP uses because just about every line begins with the
letter 'M'.  This will skew the distribution slightly.  But a better
way of distinguishing uuencoding and ascii armor is to see that in
falls in the same entropy class, and then just looking at the
alphabetic subsets used.

@_date: 1992-10-23 23:27:22
@_author: Eric Hughes 
@_subject: multiple message destinations 
1) You can send it to a service which copies the message and resends
it as many times as you need.  Or send it yourself.
2) You can have the multiple recipients each share a key and let them
trust each other.  (Not recommended for the paranoid).
3) You can use a secret sharing system which is tied to a private key,
such that revealing the secret allows for the derivation of the
private key.  The secret itself is a different private key.  (I'm not
up on the details of these schemes.)

@_date: 1992-10-24 09:24:30
@_author: Eric Hughes 
@_subject: multiple message destinations 
Re: multiple encryptions of a message key.
Yes, it works.  Sorry.

@_date: 1992-10-26 08:55:04
@_author: Eric Hughes 
@_subject: entropy 
Re: entropy
There are lots of entropies available to measure.  There is "true"
entropy, the lower bound for all other entropy measures.  This is the
compressibility limit.
The entropy I was referring to was simply the single character
entropy.  That is, the probabilities p_i in the entropy expression are
the probabilities that a given single character appear in the text.
This will be higher than the true entropy.  Shannon's estimate for H_1
was 4.03 bits/character.  This assumes a 27 character alphabet.  The
entropy for ASCII-represented English will be higher because of
punctuation and capitals.
The true entropy of English is much lower than this, of course.  But
for an simple measure to automatically distinguish between plaintext
and ciphertext, it should suffice.
Re: uuencoding.  In my analysis before I assume that the uuencoding
would be of random data.  If it is not from random data, then the
entropy will be lower.  Thanks for the clarification.

@_date: 1992-10-26 09:38:01
@_author: Eric Hughes 
@_subject: Registering Keys with Big Brother 
Re:  Some angles of attack
I've thought for a year or so now that if the State Department was
going to class cryptography as munitions, then they have _de jure_
acknowledged that civilian use of cryptography is protected under the
Second Amendment.  Cryptography is not a weapon and should not be
restricted for public safety reasons.
This criterion may be valid, but I don't think it's needed.  As I
understand it, the restrictions on speech that do exist restrict 1)
certain contents, not speech as such, and 2) speech which is public,
not private.  Encrypted text, by the fact that it is encrypted, is
intended to be removed from the public domain.  And restricting the
transmission of encrypted text based on some assumed content is prior
I'm not sure that any of these arguments really touch a key
registration proposal, unfortunately.  Guns may be sold, but also
registered.  It is not the speech that is restricted, but the privacy
from the Justice Dept. which is restricted.
What I suspect may be more effective is to argue, based on the Tenth
(or Ninth? I get them confused) Amendment, that the Federal Government
has not been granted specific power to require the registration of key
material under any of its other powers.
But the percentage of users of cryptography for communications is a
small percentage of the total population as of yet.

@_date: 1992-10-26 09:40:33
@_author: Eric Hughes 
@_subject: Registering Keys with Big Brother 
Sounds like a recipe for selective enforcement, doesn't it?

@_date: 1992-10-26 09:53:38
@_author: Eric Hughes 
@_subject: entropy 
Hal is, of course, right.  I was getting myself confused between
entropy lost in the encoding and the entropy of the encoding.  The
channel uses up two bits of entropy per character in the encoding.
What's left is six bits.
As punishment for getting this so egregiously wrong, I'm going to post
some C code for measuring entropy so that you all can play with it.

@_date: 1992-10-26 12:58:58
@_author: Eric Hughes 
@_subject: entropy, with code 
The entropy-calculating code is at the end of this message.  I took
the opportunity to calculate some sample entropies:
entropy.c	5.283772	the source code
entropy.asc	6.052222	entropy.c, encrypted and armored entropy.as2	6.012493	entropy.asc, with the wrappers removed
entropy.pgp	7.830532	entropy.c, encrypted alone
entropy.obj	6.112890
entropy.exe	6.947111
randseed.bin	4.584963	from pgp, 24 bytes long
pubring.pgp	7.754017	my public key ring
The entropy of the source code is in the high end of the range for
English, which is not surprising given the amount of symbols in
ordinary C code.  The entropy increases with the object and the
executable, each of which has less overt structure to it.
The entropy of the encrypted and ascii armored source code is within
1% of 6 bits, just as predicted.  And with the wrappers removed, it's
even closer!  The binary version of the encrypted message has the
highest entropy of all these tests.
In randseed.bin, the entropy is much less than 8.  But the length of
the file is 24 bytes and log_2 24 = 4.584963, indicating that there
are no duplicate bytes in the file.  Hence the warning:  entropy
calculations with small samples _will_ be misleading.
Note that the entropy subroutine can be used to calculate the
frequencies of any distribution.  This will allow all you code-writing
cypherpunks to measure bit entropies, digram entropies, etc.
 */
   * of \x1A to EOF
 */
 STUPID_NEWLINE_TRANSLATE	1
 STUPID_NEWLINE_TRANSLATE
   NUMBER_OF_BYTES		256
long byte_freq[ NUMBER_OF_BYTES ] ;
 STUPID_NEWLINE_TRANSLATE
 * The list v gives counts.  v is summed, and frequencies are assigned  * as v[i]/sum(v).
 *
 * Uses the following definitions and identities:
 *   A = \Sum_{i=0}^{n-1} v_i
 *   p_i = v_i / A
 *   H = \Sum_{i} - p_i \log p_i
 *	   = log A - 1/A \Sum_{i} v_i \log v_i
 *   lim_{x \rightarrow 0} x \log x = 0
 */
entropy( long *v, int n )

@_date: 1992-10-27 11:57:12
@_author: Eric Hughes 
@_subject: list status 
As of today, the list stands at 121 members, at least one of which is
a mail gateway.
Breakdown of the list by top-level domain:
U.S. domains:
  42 com
  42 edu
   1 gov
   1 mil
  10 org
   6 us
All other domains:
   1 at
   3 au
   1 ca
   1 de
   2 il
   1 nl
   2 no
   1 nz
   1 pt
   1 se
   4 uk
   1 za

@_date: 1992-09-24 11:10:30
@_author: Eric Hughes 
@_subject: No Subject 
How to Make an Automated Remailer in Your Copious Spare Time with Easy
to Find and Inexpensive Software Tools You May Have Lying Around.
The basic remailer illustrates how to hook in automated software
processing into the Unix mail system.  Here are the basic elements.
1. .forward
2. slocal and .maildelivery
3. remail.perl
4. /usr/lib/sendmail
1. .forward
Unix mail provides a way to have accounts on many different machines
but to receive all your mail in one place.  That facility is the
.forward file, which resides in the home directory.  The file is one
line long and contains the email address to which the mail will be
But the .forward file has another mode of operation.  If the string
begins with the pipe character '|', the mail will be piped through the
program listed.  Enclose the string with double quotes if you need
spaces included.  Here is my .forward file:
"| /usr/local/lib/mh/slocal -user hughes"
Thus all my mail gets processed by the slocal program, described next.
I don't know where the man page for .forward is.  Perhaps someone
could provide a reference.
2. slocal and .maildelivery
The software system MH contains a bunch of useful tools for handling
mail, only one of which we need.  For details on MH, do 'man mh'.
MH has a nice little mail hook processor called slocal.  Its docs can
be found by 'man mhook'.  slocal can conditionally perform operations
on mail messages and consider them either delivered or not.  It allows
multiple operations on individual mail messages.
slocal reads the file .maildelivery when it starts up for
instructions. Here is my .maildelivery file:
# field			pattern	action/	string #				result	(quote included spaces)
Request-Remailing-To	""	pipe R	"perl remail.perl" Request-Remailing-To	""	file R	archive.remailer
The various pieces of the .maildelivery file are fully documented in
the man page.  I'll just explain what mine does.  Each line describes
one operation to be performed on each incoming mail message.  Fields
are separated by whitespace, so if you need to include spaces, use
The first field, labelled field, is the mail header field to look for.
slocal can selectively process on any header line.  If the header line
does not exist, then the mail does not match this line and no
operation is performed.  If the header line does exist, processing
The second field, pattern, is a text string to match with the contents
of that header line, i.e. with everything after the colon.  In my
case, I put the empty string in, which matches everything.  You need
the pair of quotes to have a placeholder for the field contents.
The next field, action, tells what to do with the message.  'pipe'
sends the message to the standard input of the named program.  'file'
appends the message to an archive or log file.  A useful pipe command
for testing is "tee foo", which makes a copy of the message in file
foo, but does not append, so that you get an exact copy of what slocal
is going to pass to your pipe.  This allows testing of the pipe
program without sending yourself mail all the time.
The next field, result, tells what to do with the message after
processing.  I am currently using R for Regardless to indicate that
this action should always be performed no matter what.  The code R
indicates that the mail should be considered not delivered after
processing; thus slocal writes the mail back into my local spool and I
see it as normal.  Later, after I'm sick of looking at all the
forwarded mail, I'll change this code to A, meaning if the processing
succeeds, then the mail is considered delivered.  The archive file
will always remain R.
The last field, string, is the parameter to the action.  It is a file
name or program.  Use quotes to include spaces.  The name of my mail
processor is "perl remail.perl", which is to run the perl script
remail.perl on the mail.
The .maildelivery file is also the place to put encryption hooks to
automatically decrypt the bodies of messages.  More on that in a
future version.
3. remail.perl
Perl is a wonderful language for doing all sorts of useful work like
processing mail headers.  Do 'man perl' for details, or get the
O'Reilly book and really learn how to use it.
The perl script, in summary, strips off the mail headers, saving the
--------- cut here ---------
while (<>) {
 OUTPUT, ">foo" ) || die "Cannot open 'foo'." ;
open( OUTPUT, "| /usr/lib/sendmail " . $addressee ) ;
select( OUTPUT ) ;
print "To:" . $addressee . "\n" ;
print "From: nobody\n" ;
print $subject ;
print "Remailed-By: Eric Hughes \n" ;
print "\n" ;
while (<>) {
} continue {
--------- cut here ---------
Here is a summary of the operation.  To really understand this, you'll
have to learn perl.
The while loop processes standard input.  'last' terminates the loop
as soon as a blank line is seen.  A blank line separates the header
from the body.  The subject line, if seen, sets the subject variable
to the whole subject line.  The Request- header line has its final
newline removed, the contents up to the colon substituted into
nonexistence, and saves the rest in the addressee variable.
Next the pipe to sendmail is opened and its output is selected so that
all print commands will go to the pipe.  There is a comment for a
different output channel to the file foo which can be commented in for
Next the remailed header is constructed out of print statements.
Lastly the rest of the standard input is passed through unmodified to
the output channel.  The while loop terminates when there is no more
4. sendmail
sendmail is the backend mailer; it expects complete mail messages and
does not usually generate any line itself except for the first "From"
(with no colon) line.  Any header you construct will thus get passed
through mostly unmodified.  Hence you can put in any "From:" line you
want and any other header info, such as my "Remailed-By:" line.
sendmail expects the name of the addressee on its command line,
otherwise it puts an "Apparently-To:" line in the header.
Any mail processor which remails should probably go through sendmail,
although it would also be possible to talk to an SMTP port directly,
were you so motivated.  MH also has some remailing programs; see 'man
A few words for tinkerers.

@_date: 1992-09-24 11:13:21
@_author: Eric Hughes 
@_subject: The aural Tim Pozar 
Just for the record, Tim's _are_ deft, but they are _not_ deaf.

@_date: 1992-09-25 11:37:12
@_author: Eric Hughes 
@_subject: the hopping remailer is done 
The hopping remailer is finished.  I wrote it this morning.
The change to make a hopping remailer is very easy.  Here's the new
perl script:
--------- cut here ---------
while (<>) {
 OUTPUT, ">foo" ) || die "Cannot open 'foo'." ;
open( OUTPUT, "| /usr/lib/sendmail " . $addressee ) ;
select( OUTPUT ) ;
print "To:" . $addressee . "\n" ;
print "From: nobody\n" ;
print $subject ;
print "Remailed-By: Eric Hughes \n" ;
# check to see if there are header lines in the body to collapse #   into the full header.
if ( $_ = <> ) {
} else {
while (<>) {
} continue {
--------- cut here ---------
Short explanation.  The 'print "\n" ;' line was moved inside the new
if statement.  The if statement reads a line of the body and stops the
script if there is no body.  The line read is tested to see if it
contains the two characters " alone on the line.  " is the ANSI
C token pasting operator.  If there is no pasting, a blank line is
printed to mark the end of the header and the first line of the body
is printed.  If there is pasting, then the conditional does nothing,
which has the effect that the body is appended directly onto the end
of the header, allowing you to add more header lines after the header
is rewritten.
Here is a sample message that I sent myself after the new script was
--------- cut here ---------
X-Hop: 1
Request-Remailing-To: hughes
X-Hop: 2
Request-Remailing-To: hughes
X-Hop: 3
This is a test message of multiple hops.
--------- cut here ---------
I received four pieces of mail after sending this to myself.  The
first was the actual letter, which is still delivering normally and
not being filtered.  The next two were the first and second
remailings; they had X-Hop: 1 and 2.  The last message was the final
one, had X-Hop: 3 in its header and was delivered normally.
At each stage, the header got rewritten and a new
Request-Remailing-To: line inserted.  When that mail got delivered, it
was again rewritten, with a new remailing request.  This process is
extensible up to the 50K or so practical limitatation on mail size.
Note that this system is not at all secure by itself.  But if each
message body were encrypted first, and the message first decrypted
before the header re-write took place, the routing instructions as a
whole would be hidden from prying eyes.
That's the next project.

@_date: 1993-04-03 12:06:43
@_author: Eric Hughes 
@_subject: WB: public kiosks 
One of the necessities of a truly effect whistleblowing system is the
existence of public kiosks where anybody can post from--the equivalent
of public telephones for the net.  This is useful when the sending of
any encrypted message at all will be grounds for reprisal.  (It is, of
course, useful for paranoids as well...)
Last night I spoke with Wayne Gregori, who runs a system called sfnet
(with some variant of capitalization) here in the Bay Area.  sfnet is
a coffeehouse network, with public terminals located in various
locations in SF, Berkeley, Oakland, etc.  There is the equivalent of
IRC and private mail for the users, almost all of whom use handles.
there is also dialup service available.
sfnet just got their internet hookup.  It's not integrated into the
rest of the software yet; that is being worked on.
Wayne is supportive of the idea of putting a whistleblowers interface
into the sfnet public terminals.
New slogan: Drop the dirty quarter!

@_date: 1993-04-05 11:58:33
@_author: Eric Hughes 
@_subject: wpcrack on archive site 
I just put up Ron Dippold's wpcrack code up on the ftp site, a program
that breaks the (very bad) encryption of Word Perfect files.  The
distribution is four files
in directory pub/cypherpunks/cryptanalysis.
The anonymous ftp site is soda.berkeley.edu.

@_date: 1993-04-05 17:28:01
@_author: Eric Hughes 
@_subject: WB: public kiosks 
For those of you not familiar with Community Memory, it is a Berkeley
only system intended to make community stronger in Berkeley.  Steven
Levy wrote about it in _Hackers_.
SFNET is an expanding commercial service; I want to use SFNET as an
example a springboard for much wider deployment of public access to

@_date: 1993-04-07 12:39:02
@_author: Eric Hughes 
@_subject: Real-time BBS Encryption?? 
Re: encrypting modem links
Yes, with difficulty, and not transparently.
For PC's, replacing the terminal software is really the best way.
There is no effective abstraction of serial port hardware in the PC
world.  The int 0x14 driver in the BIOS was rampantly defective, and
MSDOS does not provide a standard interface.
As a result, almost all comm software on PC's talks to the serial port
directly.  Now in MS Windows, there is abstraction for ther serial
ports, but I don't know how easy it is to insert a device layer.
It might be possible, using a 386, to make a driver that acted as if
it were hardware but actually did encryption.  Ick.  Reliability and
cross-program compatibility would be shit.  And it would have to be
made compatible with whatever else was taking over the 386.
Remember: I hate DOS.

@_date: 1993-04-07 12:46:31
@_author: Eric Hughes 
@_subject: WB: public kiosks 
I thank Marc Ringuette and Phil Karn for their comments on public
kiosks.  They remind me that public kiosks are not a panacea, and that
we need to educate others to that awareness.
Nevertheless, let us remember the econmonics of the situation.  It is
expensive to follow people around--more expensive, say, than an
illegal tap on a home phone line.  By increasing the cost of the
suppression of information, one ensures that more information, in the
aggregate, is released.
We may not be able to provide for any particular individual's privacy,
but we can take actions for which we know that we will increase the
total amount of privacy (however hard that would be to strictly

@_date: 1993-04-07 13:08:41
@_author: Eric Hughes 
@_subject: April 10 meeting 
Last month at Cypherpunks West, we decided that meetings would be held
monthly on the second Saturday.  So, for any of you planning to be in
the area any time, keep this in mind.
The April meeting for Cypherpunks West will be April 10, 1993.  There
was some delay getting this announcement out because our normal
meeting sponsor, John Gilmore, will be out of town.  Mike Werner, also
of Cygnus, will be sponsoring our meeting at the same location, so
there's no need to change plans.  Thanks, Mike!
Cypherpunks West April Meeting
Saturday, April 10, 1993
12:00 noon - 6:00 pm PDT
Cygnus Support Offices, Mt. View (directions follow)
Contact Mike Werner for physicalities: mtw at cygnus.com, 415-903-1421.
Arthur Abraham on hash functions
Mail services (works in progress)
Secure phones (updates)
Other stuff as announced
If you have anything you want to talk about, send me mail:
hughes at soda.berkeley.edu
Take US 101 toward Mt. View.  From San Francisco, it's about a
40-minute drive.  Get off at the Rengstorff Ave/Amphitheatre Parkway
exit.  If you were heading south on 101, you curve around to the
right, cross over the freeway, and get to a stoplight.  If you were
heading north on 101, you just come right off the exit to the
stoplight.  The light is the intersection of Amphitheatre and
Charleston Rd.  Take a right on Charleston; there's a right-turn-only
Follow Charleston for a short distance.  You'll pass the
Metaphor/Kaleida buildings on the right.  At a clump of palm trees and
a "Landmark Deli" sign, take a right into Landings Drive.  At the end
of the road, turn left into the complex with the big concrete
"Landmark" sign.  Follow the road past the deli til you are in front
of the clock tower that rises out of one of the buildings, facing you.
Enter through the doors immediately under the clock tower.  They'll be
open between noon and 1PM at least.  (See below if you're late.)
Once inside, take the stairs up, immediately to your right.  At the top
of the stairs, turn right past the treetops, and we'll be in 1937 on your left.  The door is marked "Cygnus".
If you are late and the door under the clock tower is locked, you can
walk to the deli (which will be around the building on your left, as
you face the door).  Go through the gate in the fence to the right of
the deli, and into the back lawns between the complex and the farm
behind it.  Walk forward and right around the buildings until you see
a satellite dish in the lawn.  Go up the stairs next to the dish,
which are the back stairs into the Cygnus office space.  We'll prop
the door (or you can bang on it if we forget).
Or, you can find the guard who's wandering around the complex, who
knows there's a meeting happening and will let you in.  They can be
beeped at 965 5250, though you'll have trouble finding a phone.
Don't forget to eat first, or bring food at noon!  I recommend hitting
the burrito place on Rengstorff (La Costen~a) at about 11:45.  To get
there, when you get off 101, take Rengstorff (toward the hills) rather
than Amphitheatre (toward the bay).  Follow it about ten blocks until
the major intersection at Middlefield Road.  La Costen~a is the store
on your left at the corner.  You can turn left into the narrow lane
behind the store, which leads to a parking lot, and enter by the front
door, which faces the intersection.  To get to the meeting from there,
just retrace your route on Rengstorff, go straight over the freeway,
and turn right at the stoplight onto Charleston; see above.
See you there!

@_date: 1993-04-12 09:53:09
@_author: Eric Hughes 
@_subject: Security Dynamics 
Re: security dynamics One could perform an interesting test with one of these Security
Dynamics card.
Aim a video camera at the LCD display so that the display takes up the
full width of the image.  Hook the video signal up to a digitizer
board, and recognize the numbers that appear on the face.  Spit them
out as often as they appear.  For someone with all the equipment, this
should be a one or two evening hack.
Now, if the number changes every minute, that's a little over 10,000
samples in a week, certainly enough to determine if they are using
weak random number generation.
I'll put the data on the ftp site, should anyone actually do this.

@_date: 1993-04-12 10:17:28
@_author: Eric Hughes 
@_subject: FWEE!: kiosks 
Dave writes on public kiosks:
I'm not talking about building a network of machines just for the
purpose of whistleblowing.  I'm talking about making interfaces to
existing systems.  In particular, the public machines at sfnet would
_also_ be interfaces to any whistleblowing system.  The incremental
cost is minimal; it's a small bit of software at the server.
There is a different kind of privacy in a public space than in private
space.  In a private space, everyone may know where you live, but
nobody knows what goes on inside.  In a public space, everyone may see
what happens, but no one knows who you are.  Please consider these
approximations to reality.
In particular, since it is anonymity which is desired, a public place
is sufficient.
The cost of placing a video camera to monitor a computer inside a
coffeehouse must also include the possibility of negative publicity
and lawsuit when such an emplacement is discovered.  Monitoring a
public place in advance of any "crime" being committed is _very_ bad
for job security and department funding.
I am also not talking about replacing the ability to post from home.
I am talking about expanding the number of entry points into the
distribution system.
The largest benefit for public-space access is that you can use this
if you don't have a computer at home.  You can also use it if you
don't have a computer at work.
A whistleblower system, by default, must be free of judgements about
what is "good" to be on it and what is "bad".  If someone thinks that
something ought to be brought to light, then I say let them speak, no
matter how trivial or inappropriate it might be.
It is easy to ignore messages you don't want to consider.  It is much,
much harder to read messages that the author hesistates to write for
fear of reprisal.  A whistleblower system can tolerate more noise than
usenet, since the core content of it can be so extremely valuable.
If there is only access to a whistleblowing system for those who own
computers or are provided access to them, then any such system will
remain only a tool of the wealthy.  You do not hear of abuses in labor
law from anybody but the employees; these employees do not have
Anybody who has NATIONAL SECRETS to tell is, I would guess, a fool to
post twice from a particular location.  Anybody who has anything
lengthy or digitally copied to say cannot easily use this system.
It's not conducive to digital signatures.
Public kiosks are not a panacea.  To argue that they should therefore
not exist is nonsense.

@_date: 1993-04-12 11:57:22
@_author: Eric Hughes 
@_subject: a new usenet group 
There is a new Usenet group that some on this list might be interested
in.  It's called
This group seems to have been created as a spillover for the debate on
anonymity in news.admin.policy.  My nntp server has seen less than 100
articles to date.
I would encourage those in this group who have strong opinions to
participate in this new forum, as it seems the advocates of strong
privacy are not so numerous as they are here.

@_date: 1993-04-13 08:15:58
@_author: Eric Hughes 
@_subject: FWEE!: kiosks 
This is the ideal scenario.  I suspect that kiosks for other purposes
will eventually contain some form of user-available I/O.  I'm guessing
it will be infrared, maybe rs232 serial.  Diskette drives are too
vulnerable and expensive to be feasible in a pay phone environment;
they're called armor phones, and for good reason.  In particular,
sfnet doesn't have diskette access.
No bother, we're not going to create the best system on the first
revision.  A good enough system will drive later systems.

@_date: 1993-04-13 08:18:34
@_author: Eric Hughes 
@_subject: Security Dynamics 
Re: checking distribution in 10^4 samples
The method of randomness-checking done here is to run a physical
simulation with the random numbers.  Direct statistical methods are
much more efficient.

@_date: 1993-04-13 08:29:10
@_author: Eric Hughes 
@_subject: Security Dynamics 
The experiment I was proposing would possibly answer 'yes' to the
question "Is the number generation weak?"  It would not say how strong
it was, or even if it was strong.  it would, however, give some lower
bound on its strength or else show that it was in fact not very strong
at all.
Since we are talking about a device in which a sequence is duplicated
on two ends, I did not feel the need to belabor the difference between
pseudorandom and random.  The context makes it clear that this can't
be a random device based on a physically random process.
That bit of information may mean that a 10^4 sample test is not worth
That changes our trust from no trust at all into trust in your friend's
ability and your assessment of it. :-)
Granted.  Their keeping the keys is worth, say, using a linear
congruential generator (or worse) in terms of overall security.
I was merely curious as to whether they were fools on all fronts, as
opposed just to the secrecy front.

@_date: 1993-04-13 08:41:42
@_author: Eric Hughes 
@_subject: how secure is secring.pgp? 
There are two security items here.  The first is that the secret RSA
key nott be revealed.  The second is that the name attached to that
key pair not be revealed.
This protection applies to the first criterion--your secret key is not
revealed.  No one can steal your key and impersonate you.
The second datum, name attached to a key, is protected only by one's
sole possession of the secring.pgp file.  If you are using a
pseudonym, and using an RSA signature to enforce it, and doing thing
with this pseudonym that you don't want identified with you, then
you'd better make sure that secring.pgp file is not discovered on your
machine.  The format of the keyring file is such that the name
attached to a key is in the clear.
This is really a huge hole.  Since secret keys are presumed to be in
the possession of only those who actually use the keys, possession of
a secret key on the secring.pgp is tantamount to proof that you are
that pseudonym.
In short: everything about a secret key ring should be encrypted.
A parallel (not as consequential): everything about a public key ring
should be encrypted.

@_date: 1993-04-13 09:02:00
@_author: Eric Hughes 
@_subject: forward: cryptanalysis talk abstract 
For exhaustive key search on any reasonably good symmetric cipher
(like DES), some simple entropy measure for n-bit-grams should suffice
to distinguish random from non-random.  These other approaches in this
talk seem like overkill in this context.  But then again, maybe we're
trying to break Enigma. :-)
A finite stationary Markov process is large fancy math-speak for what
a travesty generator does.  "finite" means that the total number of
states is finite, and that means you get to use matrices instead of
kernel integrals, which means that your averagely educated scientist
can follow this.  "stationary" means that the transition matrix is not
a function of time, that is, it's a constant matrix.  This means that
time appears only in an exponent.  A "Markov process" is a transition
from one state to another, probabilistically.  (Approximately.  All
these definitions are meant to explain, not to define.)
The talk looks interesting, to be sure, but it looks more significant
for making a better /etc/magic for file(1) than it does for

@_date: 1993-04-13 17:53:45
@_author: Eric Hughes 
@_subject: how secure is secring.pgp? 
I said:
Marc said:
As long as we're being precise, allow me to restate my claim.  If you
use a pseudonym with PGP, and you don't want it revealed, and for some
reason it is revealed (through some other security breach), then the
secret ring has a security failure (lack of encryption) which leads to
a breach of privacy.
The lack of encryption is a material cause of the privacy compromise.
As far as I can tell, I was using security to refer to material causes
and Marc was referring to end results.
So do I.  On an encrypted file system, this is not nearly so large an
issue.  A point of clarification for below: that's one's own personal copy of
a public key ring.
The point of a public key is that someone else can perform an
operation that only you can undo (and vice-versa, properly stated).
Public keys are for anybody that is not you.  This does not mean that
everyone will have them, or even that everyone should have them.  The
social form of fully published keys need not be the norm.
If this is the only datum available, that would work.  When another
list is available to intersect your keyring with, the attempted
diffusion may fail unexpectedly.
Keeping your identities of your correspondents private (through a
security mechanism on the keyring) is much the same as using some of
the stronger forms of remailers that have been discussed.

@_date: 1993-04-16 20:05:41
@_author: Eric Hughes 
@_subject: a cypherpunk's clipper reaction 
I will, in the coming weeks have much more to say on the matter of
this Clipper chip proposal.  For now, however, I have only one thing
to say.
No compromises.

@_date: 1993-04-16 22:26:39
@_author: Eric Hughes 
@_subject: Q&A DataBase 
Re: Q&A (a DOS database program)
One of the purposes of cypherpunks is to figure out stuff like this
and to help others learn how to do it.
In short, you figure it out, and tell us.
To begin with, make a database with some permissions.  Make a complete
copy of that database in another directory.  Now change exactly one
password by exactly one letter.  Use a differencing tool to find the
differences.  Save this copy as well.  Change the same password again.
Check to see if the differences are in the same place.
Do the same with different passwords.  Correlate this information with
the database structures.  Write some software to generate
plaintext/ciphertext pairs.  Get at least a thousand, preferably lots
more.  You'll use these later to verify that your reconstruction of
the algorithm is correct.
If the encryption isn't obvious by now (yes, some of this stuff is
extremely weak) hook up a debugger to the executable and start looking
for the routine which does password encryption.  When you find it,
reverse engineer it and write a C routine that matches the
Now you'll be considered having done your homework.  If you still
don't know how to crack passwords after knowing the algorithm, post
the algorithm here and we'll look at it.

@_date: 1993-04-17 08:36:36
@_author: Eric Hughes 
@_subject: History of Gov. Telecom Interception 
Harry Shapiro mentions what sounds like an excellent little book,
titled "The Invisible Weapon"
I've made a directory called clipper/ in the ftp site.  I'm looking
for information to fill it up with.
Harry, I'd like to publicly ask you to write an annotated bibliography
entry for this book so that I could put it up.  Full reference
details, of course, two or three sentences describing the contents of
each chapter, and a small summary.  Thanks in advance.
If anyone has an electronic copy of the New York Times article, please
send it in.
Please send all your submissions via email, as I don't have the
necessary permissions to use the incoming directory on soda.
Send submissions to hughes at soda.berkeley.edu.
Download stuff from soda.berkeley.edu:pub/cypherpunks via anon ftp.

@_date: 1993-04-20 11:01:07
@_author: Eric Hughes 
@_subject: Ad hoc Cypherpunks meeting April 24 
Ad Hoc Cypherpunks Meeting on the recent Wiretap Chip proposal.
Where: Cygnus Support, Mt. View (directions follow)
When: 12:00 noon sharp - 6:00 p.m.
I'm mad as hell.  I know that a lot of other folks are too.  So I'm
calling an ad hoc meeting to vent some spleen, to calm our heads, and
to plan a counterattack.  If you have any interest in this whatsoever,
please attend.
As with all cypherpunks meetings, this meeting is open.  Tell anyone
you want to tell.  Show up.  Encourage your friends to show up.  I'm
going to try to get some of the folks from RSA Data Security to show
up, as well as some others who would normally not attend.
Eric Hughes
cypherpunks list and ftp maintainer
12:00 - 6:00  Wiretap chip discussions.  There will be a break.
Take US 101 toward Mt. View.  From San Francisco, it's about a
40-minute drive.  Get off at the Rengstorff Ave/Amphitheatre Parkway
exit.  If you were heading south on 101, you curve around to the
right, cross over the freeway, and get to a stoplight.  If you were
heading north on 101, you just come right off the exit to the
stoplight.  The light is the intersection of Amphitheatre and
Charleston Rd.  Take a right on Charleston; there's a right-turn-only
Follow Charleston for a short distance.  You'll pass the
Metaphor/Kaleida buildings on the right.  At a clump of palm trees and
a "Landmark Deli" sign, take a right into Landings Drive.  At the end
of the road, turn left into the complex with the big concrete
"Landmark" sign.  Follow the road past the deli til you are in front
of the clock tower that rises out of one of the buildings, facing you.
Enter through the doors immediately under the clock tower.  They'll be
open between noon and 1PM at least.  (See below if you're late.)
Once inside, take the stairs up, immediately to your right.  At the top
of the stairs, turn right past the treetops, and we'll be in 1937 on your left.  The door is marked "Cygnus".
If you are late and the door under the clock tower is locked, you can
walk to the deli (which will be around the building on your left, as
you face the door).  Go through the gate in the fence to the right of
the deli, and into the back lawns between the complex and the farm
behind it.  Walk forward and right around the buildings until you see
a satellite dish in the lawn.  Go up the stairs next to the dish,
which are the back stairs into the Cygnus office space.  We'll prop
the door (or you can bang on it if we forget).
Or, you can find the guard who's wandering around the complex, who
knows there's a meeting happening and will let you in.  They can be
beeped at 965 5250, though you'll have trouble finding a phone.
Don't forget to eat first, or bring food at noon!  I recommend hitting
the burrito place on Rengstorff (La Costen~a) at about 11:45.  To get
there, when you get off 101, take Rengstorff (toward the hills) rather
than Amphitheatre (toward the bay).  Follow it about ten blocks until
the major intersection at Middlefield Road.  La Costen~a is the store
on your left at the corner.  You can turn left into the narrow lane
behind the store, which leads to a parking lot, and enter by the front
door, which faces the intersection.  To get to the meeting from there,
just retrace your route on Rengstorff, go straight over the freeway,
and turn right at the stoplight onto Charleston; see above.
See you there!

@_date: 1993-04-22 07:36:31
@_author: Eric Hughes 
@_subject: ADMIN: delayed mail yesterday 
Some of you may have worried that the list was down to due government
interference yesterday.  The truth is much more prosaic.
toad.com, where the mailing list resides, is on the commercial side of
the Appropriate use barrier.  In order to send to NSFNET hosts, all
the traffic must pass through uunet.  The default mail router that
toad uses, relay2.uu.net, was munged for mail yesterday.  All the
queue has been flushed out at this point.
Thanks to Hugh Daniel and John Gilmore for figuring this out.

@_date: 1993-04-22 08:00:04
@_author: Eric Hughes 
@_subject: Automation package. 
I may have already answered your letter about telix scripts, etc., so
pardon me if this is a duplicate.
The pgp developers maintain a collection of utilities that integrate
pgp into various other pieces of software.  You should send your stuff
to Phil Z. and he'll forward it to the right people.  It may be added
to the contrib directory of the next release.

@_date: 1993-04-22 08:14:26
@_author: Eric Hughes 
@_subject: CLIP: Legal Aspects 
It is true that evidence from an illegal wiretap cannot be used as
evidence in court; this is called the Exclusionary Rule.  While the ER
has been weakened in the last decade, it still basically holds.
Unfortunately, that is not where the main threat lies.
Exploratory wiretaps, illegally made and whose evidence is not
directly admissible, provide information that may lead investigators
to other information.  This secondary information _is_ admissible.
It would be a wonderful if the ER were strengthened so that all
evidence which resulted from an illegal search _and all of its
subsidiaries_ were conidered tainted.  That battle, however, is a much
longer one to fight.
Even in that situation, though, the defense would have to prove that
an unauthorized wiretap took place.

@_date: 1993-04-22 08:26:31
@_author: Eric Hughes 
@_subject: Thoughts on the proposal 
[rest elided]
Phil points out indirectly in this post one of the very clever tactics
used by the PR people on the wiretap side:
I've gone through some of the press coverage on the chip from last
weekend and their argument basically goes like this: "This is stronger
than most cryptography currently existing.  And it also lets us spy on
the BAD people!"  Now the first claim is true and irrelevant, since
most stuff is not encrypted.  And the second claim is presented without
mentioning that you can make strong crypto without backdoors.
Therefore, one educational goal must be that strong cryptography is
possible in hardware which doesn't have backdoors.  For press
coverage, the announcement of a new hardware device with longer keys
and no backdoor could point out this difference and could get press
coverage by explicitly denying the gov't claims.  I would suggest a
triple-keyed DES chip would satisfy this nicely and be very quick to

@_date: 1993-04-22 08:44:29
@_author: Eric Hughes 
@_subject: WIRETAP: boycotts 
Boycotting AT&T overall isn't going to do much economic harm, since
the number of anti-wiretap chips is small in comparison to the number
of long-distance companies.  If you want to hurt them, get them where
it counts.
1.  The AT&T wiretap phone is designed by a division in Greensboro.
Find out everything that this specific division makes.
2. Take this list and in the second column write down all the products
which directly compete with those in the first column; these are the
3. Get Communication Week to give (or sell) you a mailing list of
their subscribers; these folks are already qualified purchasers of
telecom equipment.
4. Send and educational mailing to this list, explaining that if they
support AT&T in wiretapping, that soon they'll be screwed themselves.
Include the list of AT&T products and alternatives and urge people to
voice their frustration by buying from someone else.  They might also
want to send in the sample protest letter you've included.
Now this strategy has a few characteristics I'd like to point out.
First, if no one buys wiretap chips, the wiretap chip doesn't gain
market share, a very important point where compatibility creates
positive feedback loops in the market.  Second, it's selective in it's
targets; the model here is to target one division.  When sales
actually suffer, there is the possibility of getting the division
manager fired for taking an action not in the best interest of the
company.  A shareholder lawsuit might also help here.  If you can
bring down wrath on one manager's head, you will deter others from
following the same strategy.  Third, since this is such a charged
issue, you might be able to get donated mailing lists, ad agency
consults (Jerry Mander comes to mind), etc. free or cheap.  At the
very least, such a campaign doesn't cost a lot (on corporate terms) to
do entirely commercially; CPSR and/or EFF could mount it.
As a second round, target the PBX division of AT&T, since that's where
the next round of chip deployments are.

@_date: 1993-04-22 09:38:52
@_author: Eric Hughes 
@_subject: Status of Voice Encryption with PC/Mac? 
Paul Rubin is going to demonstrate some of the voice coders he's been
working on at the meeting Saturday, hardware willing.
As far as soundblaster cards, I would recommend instead something like
a bigmouth board, which already has the phone line access and handset
on it.
Secure phones will be a large topic Saturday, since that's where the
first deployment of the wiretap chip will be.

@_date: 1993-04-22 10:04:16
@_author: Eric Hughes 
@_subject: non-cypher related question on audio analysis 
I've got a good book on DSP by Rabiner and Gold.
There are a few DSP newsgroups where the local experts hang out.  Also
the modem design groups.
After you know something, remember this: The FIR filter is the same
mathematically as a FFT, multiplication by a filter window function,
and an inverse FFT.  As I recall, you can process multiple FIR's in
All the DSP manufacturers come with lots of example source code for
standard filters (FFT, FIR, IIR, etc.).

@_date: 1993-04-22 10:30:37
@_author: Eric Hughes 
@_subject: ADMIN: Should we become "suits"? 
This is true for all of us right now.  This topic is a time waster.
As list maintainer and thus occasional bringer of order, I declare
this topic off limits for two weeks.  Don't talk about it on the list;
if you've got a gripe about this, mail me directly.
As for John Markoff, the New York Times reporter, he was put on the
list last September or October and was on until last month.
A special note for Perry: If you don't like the name, you are free to
do whatever you want, as you have said yourself in other forums.  You
are in particular free to start your own mailing list called
cryptoprivacy.  _Verbum sapienti satis est_.

@_date: 1993-04-22 16:25:11
@_author: Eric Hughes 
@_subject: Info on Mykotronx 
the vp from mycotoxin spoke, and some reporter said:
16 M is approx 2^24
80 bit wiretap chip key - 56 bit DES key = 24
Just because the key is 24 bits longer doesn't mean the chips are that
much more complex.
Biham and Shamir have reduced the security of DES down to 2^47 (maybe
down a few more in the exponent), but that does not mean that it has
been broken.  2^47 chosen plaintexts is not a feasible attack in a
reasonably deployed system.  This is the best known attack.  Biham and
Shamir are not computer hackers, either.
So assuming the reporter was basically accurate, what's the score for
our VP?  One deceit and one outright lie combined with a gratuitous

@_date: 1993-04-22 16:30:05
@_author: Eric Hughes 
@_subject: WIRETAP: press articles wanted. 
Speaking as the ftp site maintainer, I'm looking for all the press
coverage there is on this wiretap chip, both national and local
coverage.  I've seen quotes from several other sources, but not whole
articles.  So type in what's at hand and send it to me.  I'll put it
up for ftp.
I've got Saturday's article from the SF Chronicle here, which I
haven't yet typed in, but I should warn you that this piece is one of
the most slanted things I've seen in that paper.  (Those of you who've
read the Chron know this is a real insult.)  I'll get it typed in
myself unless someone can send me a copy.

@_date: 1993-04-22 16:42:50
@_author: Eric Hughes 
@_subject: Reaction time and Crypto 
Removing the headers from PGP will accomplish only the most cursory
security.  The PGP packet structure is recognizable out of a random
byte stream even without the headers.
More generally, just because _you_ don't know how to recognize
something doesn't mean your opponent is similarly lacking.  In order
to really know it can't be done, you need a proof, that is, an
argument that covers all possible ways of looking for something.
This principle applies to all forms of steganography.
See my comment above for my opinion on this.
I think work done to get PGP, for example, in mail readers is
something that should be done with a bit more zeal.  I, personally,
don't use it much because of my computing environment (receiving mail
on a widely-known-to-be-insecure Unix box, dialed in from MSDOS).  The
integration problems are pressing.
True up to a point.  Remember, internet users are still a small
percentage of the whole.

@_date: 1993-04-23 08:17:14
@_author: Eric Hughes 
@_subject: encrypted telnet 
Derek asks this, and suggests using Kerberos.  WSK responds by saying
that you could encrypt a session key with PGP and send it.
WSK replies properly that kerberos is a lot of overhead to get
running, but his proposed solution is missing forward secrecy.  If the
PGP key is ever compromised, then all recorded prior traffic will be
available to read.
The solution is to use Diffie-Hellman key exchange.  I'm not going to
explain the details of the algorithm right here, right now, but I'll
tell you it's salient properties.  Each party makes a random number,
applies a one-way function with very special properties, and sends it
to the other.  Then each party takes their secret number, combines it
with the number they were sent, and makes a new (arbitrary) number
which will be the same on both sides.  This number cannot be derived
from the publicly transmitted data.  (The very special function is
exponentiation in a finite field; those with sufficient math
background may consider figuring out the details "a problem left to
the reader.")
Encrypting session keys with PGP is suggested often enough that this
qualifies as a legitimate FAQ.  I'll write up a description of this
protocol next week if no one has one already written.
As a design principle, every live end-to-end session should use D-H to
make session keys.  Only when you don't have interactivity should
session keys be encrypted with a public key.

@_date: 1993-04-25 22:25:51
@_author: Eric Hughes 
@_subject: ADMIN: ftp usage statistics 
I get weekly statistics on the ftp usage at soda.  We've been up at
about near the top of the usage frequency for a while, but this week
we hit number one, with over one third of the total ftp traffic here.
We've even passed sfraves, which also runs on this machine.
Hoo! Things are hoppin'.

@_date: 1993-04-27 17:47:37
@_author: Eric Hughes 
@_subject: REMAIL: email to usenet gateways 
No problem.  Just use a berkeley.edu remailer as the final hop before

@_date: 1993-04-28 10:09:14
@_author: Eric Hughes 
@_subject: MYK-78 
Arthur sez:
And I've been peering over his shoulder for much of that time.  I'd
like to comment on some of the unapproved ways to use this chip.
The way that the chip enforces the wiretap protocol is by not working
as a pair unless the LEEF's are transferred from one chip to another.
Since these LEEF's are presumed to go out in the clear, tapping is
reasonably assured.
I really am astounded at the names these people use.  It does give
rise to a great new slogan, though:
Now suppose that there was a law requiring use of this chip.  One
could still create an untappable system just by not sending the LEEF's
in the clear.  So, for example, you do a D-H key exchange with a 600
bit modulus.  Then the originating chip transmits the CV, LEEF's, etc.
(as I count 282 bits), XORing with the D-H key, i.e. using a one-time
pad.  Now the LEEF's have been transferred, but not revealed to any
eavesdropper.  With a 600 bit modulus in the key exchange you could
transmit one set of keying material each way.
There's a great hack here to be had.  These AT&T secure phones with
the wiretap chip inside have internal modems and run some coordination
protocol to synchronize.  Almost certainly such an initial protocol
must have retry paths in its state machine; otherwise the reliability
would suffer.  So we could make a compatible phone that initially
tried to determine if another such phone was on the other end; if so,
proceed with the blinded LEEF transmission.  If not, drop back and try
the wiretap protocol.
In fact, those of you who have seen Shimomura's and Lottor's work with
hacked cellular phones know that it might be possible to put this
hacked protocol right in the AT&T phone itself!  If the phone has a
ROM of some type which contains the microcontroller code, it could be
reverse engineered and reprogrammed.  If I were mandated to use the chip in a commercial product, I'd put
three buttons on the phone:
Pressing the third button would use the AT&T protocol, pressing the
second would encrypt the LEEF's.
"AT&T: Helping the government to reach in and touch you."
There might be another technique.  There is a Write CV command that is
accepted in normal operation.  (Some CV must be put in during
initialization after reset to reach the idle state, i.e. the normal
operating state.)  This command requires the check word, but that's
easily generated in the normal manner.  It is possible that changing
the CV requires generating another set of LEEF's; that's not clear to
me, but Arthur thinks you can.  If, however, one can just change the
CV at will, one could send the LEEF's in the clear and then
immediately change the CV (session key).  Now the LEEF has been sent
but the conversation makes no sense.  My money is that this is
interlocked with IV generation, though.

@_date: 1993-04-29 14:05:29
@_author: Eric Hughes 
@_subject: Tough Choices: PGP vs. RSA Data Security 
Copyright (c) 1993 Eric Hughes.  Unlike most everything else I write,
I do not grant right to use this without my express permission.  If
you want it sent somewhere else, ask me.  I'll probably just send it
there myself.
I'm going to try to give an overview of the RSADSI and PGP situation.
This is long.  I've put it in the form of premises, assertions, facts,
lemmas, theorems.  I know that below I am mostly trying to justify
RSADSI's actions.  I offer the following so that you may understand
how they view themselves.  I also wish to offer my personal view on RSADSI.  I do not consider
them the enemy; I consider the enemy to be NSA/COMINT and those who
would destroy privacy to create Big Brother.  The RSA patent expires
in seven years; the NSA will be around long after that.  I have a
clear priority here.  This long term battle is worth winning to the
exclusion of some other desiderata.
I do not think we should pick fights with our allies.  The patent
battle will not be won by mere defiance, but by careful planning.  PGP
is not the right vehicle for this fight.
Every argument below is predicated on the first premise.  I know lots
of people are stronly opposed to the patents; I myself am of two minds
on the subject.  I do wish to point out that the validity of the
patents is not what I argue from, but their pragmatic effect in the
legal world.
Premise: The RSADSI patents are _de facto_ effective.  This is a
completely separate issue from whether the ought to exist, whether the
public really should have them, etc.  The fact is, the PTO granted
them, the courts will find them valid unless a lot of money is spent
in a legal challenge whose outcome is by no means guaranteed.  A large
organization with lots of money to spend (not the LPF) might have a
chance of a successful overturning, but that course of action is not
in sight.
Premise: Jim Bidzos is not in a unconstrained position; he has
repsonsibilities and restrictions and can't do whatever he might want.
The effectiveness of the patents gave rise to a commercial
opportunity.  That commercial opportunity is embodied in PKP and
RSADSI.  That opportunity was successful by any reasonable measure.
The success directly created a fiscal responsibility for the agents of
the patent owners to make money for the owners.  Bidzos can't take
actions which can reasonably be seen as threatening to his business;
the point of view here is that of the owners, no one else's.
Premise: PGP threatens the business of PKP and RSADSI.  This is fairly
explicit in the documentation; PGP intends to threaten their business.
The patent claims are denounced, variously, as unethical, immoral, and
stolen.  The docs says "Hey! we tried to get a license, and they
wouldn't give it to us, but here's the software anyway."  The point is
that the truth or falsity of these claims is not the issue.  These
statements on their face can be taken as harmful; that is sufficient.
Premise: RSADSI and PKP will defend themselves.  Seems obvious, eh?
The way to counter rhetoric is with more rhetoric, and the rhetoric of
business is the law and threats of legal action.  To my knowledge, no
actual legal actions have been made by RSADSI, but lots of threats
have been.  I also believe that RSADSI is ready to take legal action,
Premise: RSADSI's main business is licensing, and licensing
individuals is not very profitable.  RSADSI has had enormous
commercial success in getting large corporations to sign up.  The only
reason to license individuals is to allow them to use non-commerical
software of one form or another.  The brute fact of the matter is that
most people just don't use non-commercial software, as a percentage of
market.  (If you disagree, consider the size of the PC deployed base
vis a vis Unix, and then consider that most of those PC's are owned by
companies, who purchase their software.)
Lemma: Licensing patents is different than licensing software.  With
software, most of your revenue stream in the long run is upgrades, not
initial purchases.  The incremental cost to produce an upgrade over
its sale price is far less than for the initial version.  With a
patent license, you get one sale and that's it.
Premise: RSADSI created RSAREF in order to license individuals.  The
purpose of RSADSI is not to suppress cryptography--it is to promote
it.  They lose very little by making a free version and they gain a
lot in terms of goodwill and preparing and educating people to use
commercial versions.  Since they don't make any money from it, there's
no reason for them to spend much money paying lawyers to draft license
agreements for products which bring in no income.  Therefore they want
all non-income uses of the patents to be filtered through a single
Fact: Commercial licenses to RSAREF are available.  They have not been
advertised widely as yet, though.
Assertion: The reason that RSADSI requires that individual licenses be
mediated through RSAREF is that non-commercial software is inevitably
used in commercial contexts.  Remember, their main business is
licensing.  All software used in a commercial context must be
licensed, otherwise their main business is imperiled.  Were they to
make separate licenses for every low end product, they would be in the
same situation as if they licensed individuals--high overhead, small
return.  Therefore, they license RSAREF to companies; this allows
RSADSI to economically offer licensed use for all such low end
software packages.
Theorem: PGP does not need to threaten RSADSI's business.  By using
RSAREF, PGP can satisfy RSADSI's business requirement to control
licensing and satisfy PGP's requirement to have a free license.
Fact: RSAREF has a restricted interface which does not allow for
direct RSA cryptosystem operations.
Assertion: RSADSI is protecting their good name by restricting the
default RSAREF interface.  Jim Bidzos has told me that the reason they
use a restricted interface is to prevent people from making stupid
cryptographic mistakes and then claiming that the lack of security was
the fault of RSADSI.  Given the number of cryptographic numbskulls out
there, this concern is not unrealistic.
Fact: PGP cannot use the default RSAREF interface.  For one, DES is
embedded into that interface.
Fact: RSADSI has allowed products to go behind the RSAREF interface
before.  Their concern is that your not doing anything stupid.  PGP
isn't, so that concern is satisfied.
Fact: RSAREF requires a written request to go around the standard
interface.  Licensing is a legal issue; written words are pretty much
required in order to be responsible.
Fact: No one has ever made such a written request for PGP.  Part of
the reason has been that moving to RSAREF entails some architectural
changes, and these are still being debated.  The recent clipper
announcement delayed things as well.
Fact: RSAREF is slow.  It's only C code.  The 386 assembly code in PGP
runs about 15 times faster than the C code in RSAREF.  RSAREF
explicitly allows modifications for improved performance.  The plan is
to make the PGP assembly speedup modules available as RSAREF speed
improvements; this is another delay in getting a port done.
Fact: RSAREF can't be legally exported from the US because of the
ITAR.  Bidzos is seeking a Commerce Jurisdiction ruling for RSAREF,
which would mean that it would be permitted for export.  But until
then, PGP would have to support two versions: an RSAREF one for US
use, and a non-RSAREF one for non-US use.  This requires more
wrappers, and thus more work.
Fact: PGP development is already moving in the direction of RSAREF.
As I've stated, however, there are a number of practical problems that
have to be straightened out before software ships.

@_date: 1993-04-29 14:19:51
@_author: Eric Hughes 
@_subject: Tough Choices: PGP vs. RSA Data Security 
For those of you looking around for a good cypherpunk-style project, a
rewrite of RSAREF with an identical interface (external and some of
the internal) would be a good idea.  Such a body of code would prevent
RSADSI from using copyright as leverage against a non-US company or

@_date: 1993-04-29 19:24:16
@_author: Eric Hughes 
@_subject: Tough Choices: PGP vs. RSA Data Security 
I have a few more words on this topic at this juncture.
Tim was calling for an examination of the issue; he was not, to my
reading, recommending one course of action or another.  Possibly Tim's
pancritically rationalist sensibilities have offended some.  To them I
say "Cypherpunk is not a religion."  If you cannot question your own
beliefs, you are acting in a predominantly ideological mode.  We need
no zealots here.  Please, everyone, have a bit of calm purpose and
Reference is not advocacy.  One of the great and lasting advantages of
language over the visual is the ability to say "no," "might," "ought,"
"can," "may": the plethora of negations and conditions.  This mailing
list is not a TV channel; do not treat it as one.
I specifically request those of you who engaged the keyboard without
understanding this basic point please to reread Tim's article and to
alter and/or to retract you hasty words as appropriate.  I leave this
entirely as an exercise to the reader.

@_date: 1993-04-29 23:32:20
@_author: Eric Hughes 
@_subject: validity of the RSA patent 
Plenty of people gripe about PKP patents.  Assume for the sake of
argument that the patents will be upheld, that they are valid.  What,
exactly, is claimed?  The RSA patent claims the RSA cryptosystem.  So
we don't use that.  The Diffie-Hellman-Merkle patent claims all of
public key cryptography; in particular it claims knapsack algorithms.
So we don't use knapsacks.  But does this patent really prevent us
from using public key cryptosystems?
I think not.  Mind you, I'm only an amateur legal hacker, but this
seems like a straightforward situtation.  Consider use of another
public key encryption scheme, say LUC encryption.  Does use of this
infringe the "public key" patent?  Not directly, since we're not using
knapsacks (presumably).  We then look the equivalents doctine.  From
  Equivalents doctrine.  In patent infringement law, doctrine of
  "equivalents" means that if two devices do the same work in
  substantially the same way and accomplish substantially the same
  result, they are the same, even though they differ in name, form, or
  shape. [...] A doctrine which declares that a device infringes a
  patented invention if it does the same work as the invention in
  substantially the same way, even if it is outside the literal terms
  of the claims of the patent.  The doctrine prevents parties from
  infringing patents with impunity by making merely trivial changes in
  an invention.  The more significant the patented invetion the
  greater the scope of this doctrine.
So we have three criteria.  "Same work" refers to function, "same way"
refers to internal structure, "same result" refers to end product.
Now public key cryptosystems all have the same function, to provide
encryption and decryption with different keys.  The result is the same
at the end of each public key communication: a message has been passed
securely from one end of the channel to the other.
The structure, however, is completely different for the different
systems.  All three criteria must be satisfied in order for the
equivalents doctrine to hold.  The requirement of same structure is
not satisfied.
(Matt Miszewski has today offered to do legal research in anticipation
of a patent fight.  I'd like to ask him here to check out this theory
with some references to case law.)
RIPEM, as I understand it, came out originally with a different public
key algorithm and later changed it.  Perhaps Mark Henderson (who seems
to have done some work on it) could comment.
The equivalents doctrine seems to my mind to be a dual of the criteria
required for patentability.  There are four such criteria: statutory
class (is it the right kind of thing), utility (is is good for
anything), novelty (does it have new features), and unobviousness
(does it have new results).  The equivalence of function means that
the utility of the two objects is the same.  The equivalence of
structure meanse that the new invention does not exhibit novelty.  The
equivalence of end result means that someone already thought of that
before, i.e. it's obvious.  Statutory class is the same for both,
since if they're that close, they both are the kind of thing which
might be patented.
It is interesting as well to examine which can be patented: processes,
machines, manufactures, compositions (of matter), and new uses of any
of the above.  Note that a bundle of properties and purposes, e.g.
public key cryptography, is not patentable; it fails to specify
structure, so any structure would be novel.
The new use clause, though, is exceedingly scary.  Under this class,
existing equations could be used for different purposes and be
separately patentable.  For example, if you were to use the RSA
equations for some purpose other that public key crypto and digital
signature, that would be separately patentable.  It behooves us all to
think widely of possible applications and talk about them in order to
make them part of the prior art.
I'd like to see a document containing a good argument against the
claim that all public key crypto is covered.  It should have the full
scholarly apparatus with it and an appendix explaining the apparatus
to non-lawyers.  This document could then be circulated widely,
starting on sci.crypt.
After that, developing a test case is easy.  We would need for someone
to write some public key crypto code (it need not be very complicated)
and market it, claiming explicitly that the "public key" patent does
not apply. We'd want them to be extremely loud in their claims, for
example, writing the legal departments of all of the big RSADSI
licensees and offering their wares for sale.  If you could collect
money, so much the better.  This would almost invariably draw a
lawsuit, since it so directly threatens RSADSI's business.  Witness
the speed with which the recent PGP board was asked to shut down.
Assuming that we've already arranged for the up-front cost of legal
defense, we'd be ready to go.

@_date: 1993-04-30 17:14:39
@_author: Eric Hughes 
@_subject: 800 numbers 
I've been wanting to do this for years.  As soon as we get a digital
coin system running, I'm going to work on getting one up in Berkeley.
There are some interesting issues here similar to remailers.  Fancy
schemes tend not to be all that secure because the in-band audio
signalling is not conducive to crypto.  Just having the redirection
service is enough now to disrupt Caller-ID.  When ISDN is standard,
you can you the money transaction on the D channel, out of band, and

@_date: 1993-04-30 17:36:28
@_author: Eric Hughes 
@_subject: PGP on soda.berkeley.edu 
I have tried to make sure that it's not widely publicized, for reasons
stated below.
No.  I said that the cypherpunks site on soda is the most active one
on soda.  Quite a difference.
Look.  Bidzos is under fiduciary responsibility to exercise due
diligence in making sure unlicensed software is not distributed.  If
Bidzos were to get fired for not doing it, someone else would come in
and do exactly the same thing.
I've know Bidzos for a little over a year.  I've been distributing PGP
ever since the ftp site went up.  Not once have I ever told Bidzos I'm
doing this.  If I did, he'd have no choice but to stop it, having been
personally informed that infringement was occurring at a particular
place under a known agent.  I've asked Hugh Miller not to advertise
the site publicly, not because I don't want it used, but because I
don't want it to go away.  The site is registered with archie; if you
want it, you can find it.
Sometimes you have to be loud to get things done; sometimes you have
to be silent.  Domestic distribution of PGP right now is something
best done in silence.
Tim doesn't have anything at all to do with the ftp site.  I do it on
a guest account on the machine, which for tactical reasons of software
distribution I'd like to keep.  I have never heard anyword from Bidzos
that he even knows about the soda site, let alone that I maintain it,
let alone any pressure to remove PGP from it.

@_date: 1993-08-03 17:59:24
@_author: Eric Hughes 
@_subject: ADMIN: misconfigured host north.net has been removed from the list 
The host north.net is misconfigured to send mail to itself forever,
that is, until it bounces.  I've removed it from the list, so any
further problems with this host may be ignored.

@_date: 1993-08-04 18:30:13
@_author: Eric Hughes 
@_subject: CAKE--Citizens Against Key Escrow 
The cypherpunks remailer was designed to be run out of a user account,
and can be modified to be just such an email server.  The remailer as
it is now is just such an email server, whose only function is to
remail.  Handling lists and votes as above is straightforward.
I do take it that you're a patriotic cypherpunk, no?

@_date: 1993-08-10 08:42:07
@_author: Eric Hughes 
@_subject: August Bay Area cypherpunks meeting 
August Bay Area cypherpunks meeting
Saturday, August 14, 1993
12:00 noon - 6:00 p.m.
Cygnus Support offices, Mt. View, California
  Topics this time include the usual assortment of mailer topics,
politics, protocols, and rant.  There will be a discussion of the
Twain privacy service and privacy.net, among others.
  Meetings are the second Saturday of every month, at the same
location and at the same time.  There is frequently an informal dinner
at a restaurant chosen by concensus at the meeting.
[Directions to Cygnus provided by John Gilmore. -- EH]
Take US 101 toward Mt. View.  From San Francisco, it's about a
40-minute drive.  Get off at the Rengstorff Ave/Amphitheatre Parkway
exit.  If you were heading south on 101, you curve around to the
right, cross over the freeway, and get to a stoplight.  If you were
heading north on 101, you just come right off the exit to the
stoplight.  The light is the intersection of Amphitheatre and
Charleston Rd.  Take a right on Charleston; there's a right-turn-only
Follow Charleston for a short distance.  You'll pass the
Metaphor/Kaleida buildings on the right.  At a clump of palm trees and
a "Landmark Deli" sign, take a right into Landings Drive.  At the end
of the road, turn left into the complex with the big concrete
"Landmark" sign.  Follow the road past the deli til you are in front
of the clock tower that rises out of one of the buildings, facing you.
Enter through the doors immediately under the clock tower.  They'll be
open between noon and 1PM at least.  (See below if you're late.)
Once inside, take the stairs up, immediately to your right.  At the top
of the stairs, turn right past the treetops, and we'll be in 1937 on your left.  The door is marked "Cygnus".
If you are late and the door under the clock tower is locked, you can
walk to the deli (which will be around the building on your left, as
you face the door).  Go through the gate in the fence to the right of
the deli, and into the back lawns between the complex and the farm
behind it.  Walk forward and right around the buildings until you see
a satellite dish in the lawn.  Go up the stairs next to the dish,
which are the back stairs into the Cygnus office space.  We'll prop
the door (or you can bang on it if we forget).
Or, you can find the guard who's wandering around the complex, who
knows there's a meeting happening and will let you in.  They can be
beeped at 965 5250, though you'll have trouble finding a phone.
Don't forget to eat first, or bring food at noon!  I recommend hitting
the burrito place on Rengstorff (La Costen~a) at about 11:45.  To get
there, when you get off 101, take Rengstorff (toward the hills) rather
than Amphitheatre (toward the bay).  Follow it about ten blocks until
the major intersection at Middlefield Road.  La Costen~a is the store
on your left at the corner.  You can turn left into the narrow lane
behind the store, which leads to a parking lot, and enter by the front
door, which faces the intersection.  To get to the meeting from there,
just retrace your route on Rengstorff, go straight over the freeway,
and turn right at the stoplight onto Charleston; see above.
See you there!

@_date: 1993-08-11 09:46:59
@_author: Eric Hughes 
@_subject: How long would it take? 
re: a question about the security of RSA
This question is better asked in sci.crypt, since it involves
technicalities of number theory that are not in the purview of this

@_date: 1993-08-12 10:28:12
@_author: Eric Hughes 
@_subject: No Subject 
Q: What do you call a store that sells 'cryptographic paraphernilia?'
A: A mind shop.
If crypto is outlawed, then random numbers will be probable cause for
search for illegal cryptographic devices, software or hardware.
Q: What is a random number?
A: Anything I don't understand.

@_date: 1993-08-16 10:47:07
@_author: Eric Hughes 
@_subject: CRYPTO'93, anyone here going? 
I may show up for a day, for the Tuesday evening rump session, in
particular.  I won't be attending the whole conference.  There are a
few I do know are going: John Gilmore, Whit Diffie (who shows up for
every other monthly meeting, even though he doesn't participate much
on the list), Phil Zimmerman (who's not on the list, but ...).  Phil
called me yesterday to talk about what to do to promote PGP etc. at
the conference.  You might want to get in touch with him as well:
prz at acm.org.
As to your other question, about a cypherpunks meeting the weekend of
the 28, we won't be holding one.  As it is, our 2nd annual meeting
will be only two weeks later.  I'd not mind having an informal
cypherpunks party, but I don't know where we would hold such an event.

@_date: 1993-08-16 14:02:16
@_author: Eric Hughes 
@_subject: PROTOCOL: Encrypted Open Books 
Kent Hastings wondered how an offshore bank could provide assurances
to depositors.  I wondered the same thing a few months ago, and
started working on what Perry calls the anonymous auditing problem.  I
have what I consider to be the core of a solution.
All the following protocols and ideas are in the public domain.
The following is long.
My notation here will also be much less formal than I am capable of; I
don't want to make the uninitiated read TeX.
The basic idea is that summation can be performed encrypted by using
exponentiation in a finite field.  That is, if I represent an amount x
by g^x and an amount y by g^y, then I can compute the sum of x and y
by multiplying g^x and g^y, getting g^(x+y).  Very basic.
So let us take a very simple version of this protocol, which leaves
out many desiderata.  If a shared funds account, say, has a bunch of
transactions made on it, then we can publish each of those amounts x_i
(for the non-TeX'd, underscore means subscript) encrypted as g^(x_i).
I know what my transaction number, i, is, and what the amount was, so
I can verify that my transaction appeared in the public list.  We also
publish the beginning and ending balances, givings use a total
difference X.  Now anyone can verify that g^X equals g^(Sum_i x_i).
That is, everyone can verify that the aggregate effect of the
transactions is what is claimed without revealing the amounts of any
of them.
What does this protocol reveal?  It reveals the number of transactions
on each account and thus the total number of transactions.  It is also
subject to known plaintext attack.  If I get an account on this system
and make one transaction in each amount, I can decrypt by table lookup
the whole transaction flow.  The total number of transaction accounts
is also revealed, or, for a bank, the number of customers.
We can easily solve the known plaintext attack by blinding each
transaction.  Instead of publishing pairs , we have for
each transaction a blinding factor r_i and publish triples
The notation has grown.  g is a generator of a finite field G, and h
is a generator of a different finite field H.  We also publish R = Sum_i r_i in addition to X = Sum_i x_i.
What is the public verification procedure?  Basically the same as the
first case, but in addition taking into account the blinding factors.
Step 1.  Calculate Product_i h^(r_i) and make sure that it equals h^R.
This validates the blinding factors.
Step 2.  Calculate Product_i g^(x_i + r_i) and make sure that it
equals g^(X+R).  This, given the validity of the blinding factors,
validates the actual transactions.
How does this resist known plaintext attack?  Since the blinding
factors r_i are flatly distributed over their range (caveat! you pick
the order of G smaller than of H to assure this), the x_i + r_i sum
acts exactly as a one-time pad to encrypt the amount.  In summary,
what is going on here is that both the messages (amounts) and the keys
(the blinding factors) are being sent out as images of one-way
functions (exponentiations) that preserve exactly the relationships
that we want.
There's more.  For a real business, we want to keep double entry books
and not just single entry accounts as above.  By extending the number
of terms in the transaction, we can do that too.  In double entry
bookkeeping, the total amounts for each transaction must sum to zero
over the various accounts being transacted upon; I say this knowing
that when you print out the information for an accountant you'll have
to do some sign twiddling for the asset and liability/equity halves of
the books.  Also, a single transaction may involve more than two
accounts, even if in practice most involve only two.
The basic idea here is that each transaction is a set of the above
transactions whose sum must be zero.  So for a transaction i, we publish
a set of triples, indexed by j, where the subscripts are doubly indexed and where T_i,j represents the
account that amount m_i,j is changing.  Now we can perform, on each
transaction, the following very similar verification procedure for
each fixed i.
Step 1.  Verify that Product_j h^( r_i,j ) = 1.  This verifies that
the blinding factors sum to zero.
Step 2.  Verify that Product_j g^( m_i,j + r_i,j ) = 1.  Since the
blinding factors sum to zero, this ensures that the transaction
amounts sum to zero.
Not that both of these sums are done over j, not i.  In other words,
we validate each transaction individually.
Now we also publish aggregate changes in the public accounts just as
before.  The holders of private accounts know what how their accounts
have changed.  Then we can use the the single account verification
method as above to verify that the totals match.  Everyone can verify
that the public accounts match, and the holders of private accounts
can verify that they match.
To summarize: The transactions are doubly indexed.  If you group by
transaction, then you verify that each transaction sums to zero.  If
you group by account, then you verify that the change in that account
is as expected, be it public or private.
In the scenario that Kent originally proposed, one of the public
accounts would be a gold account, which through independent public
auditing would be verified to be accurate.  I personally would not use
gold but rather denominate certain accounts in shares of mutual funds,
which are resistant to the currency inflations of mining and stockpile
What information is still being disclosed?  The most worrisome to me
is that the total number of transactions per account is revealed, that
is, aggregate activity, but not total money flux.  I have an insight
that may allow the _account_ to be blinded as well as the amounts, and
be revealed in aggregate just as the amounts are, but I have not
worked out the details because I am not fully up to speed on the
relevant math.  BEGIN BIG MATH
I only expect a few people to follow the next paragraphs, so if you
don't understand it, skip it.
Here's the idea.  The modular exponentiation is performed in a finite
ring.  We choose a ring that has lots of distinct prime ideals of
sufficiently large order.  To each account we assign one ideal.  We
represent dollar amounts as elements of this ideal; since the ideal is
prime, this is straightforward.  The property of the ideal we use is
that the sum of any two elements of the ideal is also in the ideal.
Hence by partitioning the ring, we also partition the computation of
the accounts.  We are blinding the transcations by account because we
rely on the fact that blinding is not an intra-ideal operation, and
thus does not preserve that invariant, which would otherwise be
We must be careful not to allow operations that would result in an
element which was in the intersection of two ideals.  This requires
upper bounds both on the transaction amount and on the number of
transactions per cycle.  There might be rings of order p^n+1 which
would be suitable for this operations, but I am not sure of the
security of the discrete log in such cases, except for p=2, in which
case it is bad.
END OF BIG MATH
The protocol as specified, though, is useful as it stands.  I have not
specified all the details.  For example the blinding factors should
likely be created in a cooperative protocol at the point of
transaction; blinding factors for intra-bank transactions should not
contain subliminal channels.  Certificates of deposit and withdrawal
should be tied to the published transaction information.  Etc.
Remember, this is the core of an idea.
One criticism I do wish to address now.  I don't think it matters if
the bank manufactures fake transactions.  The customer can reveal the
sum of all the blinding factors for transactions on that account, in
public, and can thus prove what should have been there.  Since the
blinding factors were committed to in public, there is a strong
assurance that these blinding factors are what they are claimed to be.
This in itself can be made into an actual proof of liability.  Note
that even this revelantion does not compromise individual
transactions.  It only reveals the aggregate value change, which is
exactly what is at issue with the bank.
On the other hand, all of the bank assets that are held external to
that organization can be externally audited in the same way.  The
other institutions that hold money might be persuaded to undertake a
legal obligation to honor what the encrypted open books say they
should have; this may not be difficult because they can verify that
their record of the transactions matches what has been published.
If we use the contents of the encrypted books at the organizational
boundary points to create suitable legal opbligations, we can mostly
ignore what goes on inside of the mess of random numbers.  That is,
even if double books were being kept, the legal obligations created
should suffice to ensure that everything can be unwound if needed.
This doesn't prevent networks of corrupt businesses from going down
all at once, but it does allow networks of honest businesses to
operate with more assurance of honesty.

@_date: 1993-08-18 07:50:38
@_author: Eric Hughes 
@_subject: The Zen of Anonymity 
This question already has a known answer.  The author of the words is
the one that is liable for them.  No other parties are liable unless
they had prior knowledge; this would make them conspirators.
In libel cases specifically, if you can prove who the author was, you
can sue.  If you can't, too bad.  Heh, heh, heh.
I asked Mike Godwin about this specifically a few months ago.  I
mention him here to give him to opportunity to correct or elaborate.

@_date: 1993-08-18 21:50:46
@_author: Eric Hughes 
@_subject: META: on topics 
A message from your list maintainer.
I try not to interfere with topic selection too much.  I have only
once or twice specifically requested that some topic not be discussed.
Today, however, I want to offer a specific guideline about a group of
The guideline is as follows: Do not discuss topics on cypherpunks
which are already frequently discussed on sci.crypt or
alt.security.pgp and do not directly relate to cypherpunks concerns.
To illustrate this guideline, the recent thread on parallel DES
cracking has been well discussed on sci.crypt.  This initial
announcement was interesting, and maybe one round of short comments
were appropriate, but the discussion should be held on sci.crypt.
There is already a forum there, please use it.  The list is large and getting larger.  There are, by my guess, maybe
four times as many people who were previously on the list than those
who are on the list; most of these dropped out for volume, from the
comments I get.
I echo the call for self-restraint made earlier.
Others have recently written on what cypherpunks, the list, is about.
I have some comments myself, which are long, and go back to original
purposes, and such.  I will not elaborate too far in this message.
_Pace_ Tim May, I do think that there should be some guidelines about
list content.
Cypherpunks is not all cryptography to all people, and parallel
DES-cracking particular cryptography is totally mainstream.
Cypherpunks is not totally mainstream.  Cypherpunks is about
implementations of cryptography, particularly disapproved-of
cryptography--not just the privacy of epistles but the privacy of the
structure of society.
There can be no hard separation of topics between the newsgroups and
this list; I don't intend to enforce one.  Nevertheless, some things
clearly belong better elsewhere.  The existence of gray areas does not
prevent the existence of clear ones.
I do understand the concerns that some members of the list are new to
cryptography as well as cypherpunks.  Cryptology is a large and
increasingly technical field; there is no substitute for some hours of
study.  I myself have logged hundreds of hours reading technical
cryptography, and while I don't expect that many of the members of the
list will ever do that, I do expect that those who want to learn will
do some proactive reading.  You can't be spoon fed a working knowledge
of anything; working knowledge is the result of working.
Since meta-discussion can easily bring down a group, I will appreciate
it if responses to this position are short, cogent, and thoughtful.

@_date: 1993-08-20 11:01:34
@_author: Eric Hughes 
@_subject: building a sound sampler for cryptophone application... 
Perfectly on-topic, Graham.
That said, I think that designing custom hardware for sound sampling
is a waste of time, given the abundance of multimedia cards that
already work.
The barrier to entry to solder up even the tiniest, simplest circuit
is enormous for most people.  Cypherpunks is not the Privacy League
for Hackers.  The solutions that we make should be to the greatest
extent available to all without special prerequisites.  That means
that hardware should be freely purchasable, since the resource of
money is more widely available that the resource of hardware skill.
It means that software should not require root for Unix machines, nor,
if possible, knowing how to operate a compiler.
While I applaud your enthusiasm, your effort toward getting usable
secure phones would be much betting spent writing device drivers for
various soundblaster-type cards.

@_date: 1993-08-20 11:31:34
@_author: Eric Hughes 
@_subject: Blinded RSA signatures 
Apparently the first author (the one being quoted in the forwarded
message) had never been exposed to the relevant math before.  What is
therefore significant is that this person has exactly reconstructed
the basic Chaum blind signature, except for notation.
The basic blind signature does not work well in practice, since the
product of two such signatures is also a signature.  In practice one
signs a one-way hash function of the message text and exhibits the
actual text; this destroys the ability to multiply signatures, assuming
that finding multiplicative pairs for the hash function is hard.
This scheme of algebraic blinding is quite easy to apply, once you get
the hang of it.  For example, it is behind the core of the encrypted
open books protocol, where to blind g^x you create a pair g^(x+r),h^r.
Basically all of the atomic operations that recent cryptology uses--
e.g. exponentiation in finite rings, both in the discrete log systems
and in RSA, integer multiplication in elliptic curves--are amenable to
blinding.  The El Gamal signature scheme uses a random number to
create the signature pair.
Applications to existing protocols are left as an exercise by the

@_date: 1993-08-20 11:51:06
@_author: Eric Hughes 
@_subject: Crypto Protocols are Hard to Analyze 
Indeed.  It's a mess.
No matter how you do it, it seems, real corporations will have to be
involved, which means business plans, etc.  Not a low entry barrier,
unfortunately.  If you hold money for someone else, you'd better be a
corporation in order to limit liability.  And if you hold money for
someone else, you're either entirely within the regulated bank
environment or so close to its edge that your territory could be
included at any time.
It appears the easiest way to get digital money going is to be the
bank--a fully legitimate, above board, fully qualified financial
institution.  Fortunately, one doesn't have to be exactly a bank, in
the legal sense.  Other institutions are available, such as credit
unions, mutual savings banks, and S&L's--these are the so-called
thrift institutions.  These tend to have reduced regulatory burden in
exchange for limited power to transact.

@_date: 1993-08-20 12:01:56
@_author: Eric Hughes 
@_subject: ADMIN: Blacknet mailings on the cypherpunks list 
There was a recent PGP message encrypted for Blacknet that sailed by
on the list.  This message did not discuss any topic relevant to
cypherpunks from what I could read, since, _a fortiori_ it didn't say
anything I could read.
Encrypted traffic such as this is inappropriate for this list.  Take
it elsewhere.
Tim and I have already invented the proper forum for this.  It's a
usenet newgroup called
(Read Pynchon to get the joke) The charter for this group is that it
takes only encrypted messages.  No plaintext allowed.  Discussions
about alt.w.a.s.t.e must therefore occur in a separate discussion
group, named according to Usenet convention
If someone would kindly create these two groups, the BlackNet folks
can revise their announcement appropriately.
I was waiting for some reason to create the newsgroup, because I
didn't know what traffic would go across it.  Now there is some, and
it deserves its own home.

@_date: 1993-08-25 10:42:09
@_author: Eric Hughes 
@_subject: SEA Opposes Privatization of Digital Signature Standard (fwd) 
Simona Nass of SEA sent this over to me for y'all.

@_date: 1993-08-26 11:32:31
@_author: Eric Hughes 
@_subject: PROTOCOL: Encrypted open books 
Note: I started this reply last week; I've decided to post what I
know, since I don't have a solution and I've run out of simple ideas
for now.
Hal' criticism that (real) money could leak out of the system is
correct.  The problem is that while the books would still balance,
i.e. sum to zero, some fake depositor would have a negative balance,
the net result of taking out more money than you put in.  Negative
numbers just aren't allowed in double-entry bookkeeping, but they were
allowed in the first protocol set.
The first part of the solution is to allow no private accounts on the
left hand (asset) side of the ledger, in other words, no anonymous
loans.  A protocol for doing anonymous loans could be invented, but
since the first problem is merely to run a money exchange and not more
complicated financial services, this is acceptable.  Most of the money
that left the S&L's was by corrupt loan practices, so I don't consider
this omission a particularly glaring one right now.
Therefore all the private accounts must be on the right hand side,
that is, they are all liabilities.  In layman's terms, the bank owes
you; should you ask for your money, they have to give it to you.  If
we can verify that each of these accounts never goes negative, then we
can be certain that if the books balance, that the amounts of money in
each account are accurate.
Consider this.  If money was transferred from your account to another
one, that transaction shows up in the public encrypted transaction
record.  If you have due diligence over this record, you can assertain
that no transaction was performed against your will.  This case
corresponds to a debit and credit against two customer accounts,
decreasing one and increasing the other.
Another way that money might end up in a fake account if it were
credited with assets.  A debit to an asset increase its value and the
credit to the account increases that value.  This is the case of a
deposit; the bank gets cash (+asset) and credits someone's account
(+account).  Now if they want to give someone money this way, they
have to do so by increasing the assets somehow; in other words, they
money has to come from somewhere.  It didn't come from any of the
customers because they've already verified that.  It didn't magically
appear from one of the other asset accounts because these are all
publically audited.
In summary, we need to ensure that all accounts have positive balance.
Public accounts can be revealed and seen to be positive.  Private
accounts need a cryptographic assurance.
A private account starts off at zero.  This can be publically
revealed.  Then to the encrypted transaction log and the public cyclic
balances we add publication of the private balances in encrypted form
that allows us to verify to the blinded balance is positive.  This
balance is verifiably linked to previous cyclic balances via the
transaction log.  It is therefore linked all the way back to the
beginning balance which was zero.  Consider all the transaction triples for which the first element is
equal to the private account in question, since the account was
opened.  Take a product of all of the second elements and a product of
all the third elements.  It is clear that these products can be
calculated inductively from the previous cyclic products and the
activity in this cycle.
The products on second and third elements are equal to
where I've added a time index by cycle which was implicit before.  The
notation for the inductive calculation is different, of course, and
also obscures the underlying invariant.
What we want is a certificate that Sum x_i,j,t is positive.  Here it
gets a bit hairy.  There are likely other solutions to this technical
requirement; here is the one I thought up yesterday and today.
I thought I had an idea with promise on how to create such
certificates using quadratic residuosity, but it doesn't work.  I'm
still thinking about it; this certificate doesn't seem impossible to
create, but the standard ideas that I know about in algebraic protocol
design don't seem to work.
If anybody wants to work on this technical point off-line with me,
send me mail.  The math involved is advanced enough that I'd prefer to
post summaries of work rather than all the detailed discussion.
Another non-technical attack on the problem is to require periodic
bank holidays, where all private balances will be revealed to be zero
(preferably), or whatever is actually in the account.  This doesn't
prevent owner fraud, but does put an upper bound on the time in which
to perpetrate it.

@_date: 1993-02-01 16:04:42
@_author: Eric Hughes 
@_subject: Remailer abuse? 
Re: adding notes indicating remailing.
There is a standard RFC-822 field, Comment, which would be perfect for
just such an application.  The original remailer I wrote added the
header field Remailed-By to indicate this.
You could also use another standard 822 field, Sender, as follows:
Either way, the note goes in the header, where it can be seen or
stripped, but in any case handled without munging the message body.

@_date: 1993-02-02 19:20:21
@_author: Eric Hughes 
@_subject: mail policy 
As Hal points out, this is not true.
Let me make this point explicit, in case I haven't done so recently.
When I first picked the names for the header fields, I read RFC-822
carefully, and specifically chose *not* to use X- extension headers.
I fully intend to write an RFC, an extension to RFC-822, which
describes the syntax and semantics of anonymous/pseudonymous mail
messages.  There will likely be another describing the operation of a
"standard remailer."
(A note about MIME: I'm talking about the transport system here,
underneath the layers that MIME puts on.  At least that's the idea.)
The current policies favoring named mail originate in the conflation
of two notions of security.  The first, delivery security, is that the
mail be delivered correctly, i.e., delivered at all, to the correct
person, in a timely fashion, without alteration of the contents.  The
second, liability security, is that the provider of mail not be held
liable for content.  The provider removes liability by transferring it
to the sender of the message, who must therefore remain named.
One goal of remailer work is to cleave these two notions apart.  A
provider of email services should be responsible for accurate and
timely delivery, but should have no concern for or hand in content.
The service that the provider is offering is just that, computer
services.  It is not monitoring, not oversight, and not censorship.
Just as the phone company provides a communication channel on which I
may put whatever content I desire, so should any e-mail system offer
a communication channel and only a communication channel.
The origin, I believe, of this confusion is that e-mail systems were
by and large developed for internal uses and not for the open market.
That internal use, broadly conceived, might be for the military, for
academic research, or for intra-corporate memos.  In other words these
systems were provided (mostly) free of incremental charge to the
In this environment, where service is being provided by context, it
was the legitimate concern that the provider might be held liable,
since the provider, in some strong sense, had caused the service to
exist in the first place.  When the social structures and situations
or e-mail communications were all so similar, this system worked out
Today, however, people seek out e-mail services for their direct
utility.  These people often have no prior relation with their service
provider; indeed, they wish not to be tied to a particular provider as
a guard lest the quality of the service suffer.  These people pay for
service themselves, typically.
And hence the separation between liability security and delivery
security is complete.  I want to buy common carriers of e-mail.  I
want bit pipes.  (Or, perhaps, in the e-mail world, bit bucket
But the standards of yesteryear are still with us.  The structure of
named mail persists.  We are changing that.  We do not wish to remain
skulking in the corners of respectability.  We want to be standard.
We want the standards, too, to be ours and to reflect our concerns.
Let us act with the care and deliberation that behoove all those who
wish to create standards to which others comply.

@_date: 1993-02-05 10:31:51
@_author: Eric Hughes 
@_subject: Dear Mr. President 
I applaud the Clinton administration for making itself available via
email.  I do not think it advisable, however, to send a single
cypherpunks letter.  Rather I urge all interested parties to compose
their own letters, and send them in separately.
Stress privacy, and technological defenses thereto.
At risk of offensively stating the obvious, I also urge the following
general writer's guidelines:
1) Engage brain before typing.  Think about the one thing you want to
talk about, and talk about that.
2) Do not be paranoid.  Do not rant.  These are a sure ways to
indicate that more money should be budgeted for public relations.
3) Be brief.  If you cannot summarize your argument into a single
paragraph, neither will the reader of the mail.  The mail system is
already overloaded, and concision indicates politeness.
4) Write in standard English.  Use a spelling checker, and use
complete sentences.
5) Offer to help.  Offer to make timely review of proposed policies.
If they accept your aid, keep your promises.
6) Have someone else read your letter for content and for form.  You
can do this yourself if you put the text aside for a week or two.
Remember that obsession with keeping every cleverness you think up in
a text is the surest way to ensure that it never improve.

@_date: 1993-02-05 12:25:23
@_author: Eric Hughes 
@_subject: 'Sunday Times' article on GSM changes 
Cryptography is all economics.  Every barrier adds cost to interception.

@_date: 1993-02-07 18:38:49
@_author: Eric Hughes 
@_subject: Request from a new reader. 
anon-ftp to soda.berkeley.edu::pub/cypherpunks.  There's a copy of PGP
there.  Get the .zip version; it's a PC binary.  PGP was originally
written on PC's and later moved to Unix.

@_date: 1993-02-09 08:51:58
@_author: Eric Hughes 
@_subject: Debate about anon posts 
More important than anonymity in a public forum such as Usenet is
pseudonymity.  A strictly anonymous posting might well be ignored, and
in cases should be.  An alternate identity, however, can be more
easily believed if it has said useful things in the past.
After all, most of the people I know on the net are as good as
pseudonyms to me.  I've never met them, have never even had voice
contact, and am unlikely to ever.  This is the case for everyone.  We
rely on the human net of familiarity to assure us that these are real
But a pseudonym on the net looks to us like "someone else's friend."
We can't verify everyone personally, but we assume that someone has.
Therefore pseudonyms will always be possible on the net.
Indeed, they are already mostly with us.

@_date: 1993-02-09 09:12:00
@_author: Eric Hughes 
@_subject: Compressed/Encrypted Voice using Modems 
Not only that, he was single handedly responsible for the 15 minute
delay rule in reporting stock market transactions.  Evidently he
applied information-theoretic techniques to the data and was able to
make a load of money at it.  I have no references on this, and would
love to see some.

@_date: 1993-02-09 09:16:15
@_author: Eric Hughes 
@_subject: Compressed/Encrypted Voice using Modems 
Properly it is the integral of the S/N function over frequency, but that's
a simple continualization of the stated formula.

@_date: 1993-02-09 09:49:49
@_author: Eric Hughes 
@_subject: February 13 meeting 
Cypherpunks physical meeting
Noon sharp, Saturday, February 13, 1993
Cygnus Support Offices, Mt. View, California, USA
I apologize for not getting out an announcement for the the last
meeting.  It showed, both in attendance and organization.  My regrets.
I make a solemn promise to be there before 12:00 p.m.  Let's start on
time for a change.
I hear that photographers are going to be there, so if you don't want
to be photographed, bring your favorite mask.  They're nice
photographers and they'll ask your permission first so that you don't
have to wear your mask at all times.

@_date: 1993-02-10 17:51:26
@_author: Eric Hughes 
@_subject: Wired photo shoot at cypherpunks on Saturday 
Kevin Kelly, editor of Wired Magazine, former list member, and former
editor of Whole Earth Review, asked me to forward the following
message to the list.
OK, everybody, it's your chance for fame or the avoidance thereof.

@_date: 1993-02-21 13:58:03
@_author: Eric Hughes 
@_subject: Trapdoors 
Does anybody have a good idea what applications this is useful for?
My first thought is that it's a very quick way to do linear error
detection codes, since this instruction directly computes the Hamming
weight of a code word.
I can also see it being useful to detect correlations between
sequences, such as a trial random stream and a known pseudorandom
number generator.  One would XOR the streams together and then count
bits to calculate a correlation frequency.
Other ideas?

@_date: 1993-02-21 14:19:41
@_author: Eric Hughes 
@_subject: New document for ftp. 
Hal Finney recently sent me an instruction manual for the cypherpunks
remailers.  Its on the ftp site.
    soda.berkeley.edu:pub/cypherpunks/hal's.instructions
Spread the words.

@_date: 1993-02-21 14:32:28
@_author: Eric Hughes 
@_subject: RSA licensing policy 
This letter is not intended to start a flame war about patent rights,
licensing, or anything similar.  Reply directly to me.
I've spoken with Jim Bidzos, president of RSADSI, about this very
issue recently.  They have a very easy to understand principle that
governs the use of their patents.  I am rephrasing it; at no time was
this actually spoken.  It's very simple: "If you make money with it,
so do we."  Their licenses are not out of line with patent licenses
generally (and not just computer-related ones).
If you make public domain software and use it for personal use, RSADSI
will not come after you.
If you make commercial software and sell it without obtaining a
license, they will after you.  If you use the software as a
"mission-critical" part of your business and do not obtain a license,
they will come after you.
There are grey areas between these two poles.  I do not address them.

@_date: 1993-02-22 17:00:03
@_author: Eric Hughes 
@_subject: Remailer Use 
Re: not discriminating between remailer mail and user mail.
The problem of persons uneducated in remailers not distinguishing
between different kinds of mail is a problem that will scale badly.
It looks like a problem that will have to be solved for any design
which relies on user accounts for remailing.  I have one suggestion,
but I'd like to hear others.
Suggestion--Put a big "Comment:" field in each remailed message which
explains what is going on.  Regular users will get tired of it, no
doubt.  Perhaps it could be called "X-Remailer-Education:"

@_date: 1993-02-22 17:21:05
@_author: Eric Hughes 
@_subject: whistleblower newsgroup? 
The moderator to alt.whistleblower, instead of a person's mail
address, could be a mail alias which invokes a header field stripper.
That way it would be impossible to post to the group with your
identity in the header.  Every posting anonymous!  Sort of like a
mathematical dual of alt.forgery.
I would also suggest a periodic posting explaining exactly how secure
that is.  (Proof against casual attack, but not against local or
global network monitoring.)
It seems easy enough.  I'd do it myself if I had root anywhere.  The
perl scripts for remailing would be easily hacked.  You could even
retain the automatic PGP decryption for the more informed, the more

@_date: 1993-02-22 18:14:12
@_author: Eric Hughes 
@_subject: PC Eudora 
I sent some mail to pc-eudora-info at qualcomm.com about the status of an
MSDOS version of eudora that worked over a straight serial line (i.e.
a modem dialup) rather than a TCP/IP stack.  The reply I got back said
that they had talked about it, but had not planned it in yet.
Anybody itching to do the world a favor who can do this should contact
them directly and volunteer.  Consider this an open invitation.

@_date: 1993-02-22 18:18:28
@_author: Eric Hughes 
@_subject: Timed-Release Crypto 
By coincidence, I was thinking about time-release protocols the other
day.  I've got most of a system worked out, but I need to write it up
and look at it for a while to make sure it works.  what I think I have
is a system in which the sender is given a key by a beacon which he
can verify, at issuance time, will be revealed by the beacon at some
future time.  The implementation (but not the basic idea) relies on
using multiple public RSA keys with the same modulus.  I know there
are some attacks against this, but I don't know their nature.  If
someone who knows about this (or knows where to find out) could
contact me I would be most appreciative.
As far as sending money into the future goes, there are some tradeoffs
between anonymity of payment, length of time in the future, and
message size.  Anonymity of payment is difficult, since digital cash
has to expire in order for the bank not have to keep ever huger lists
of deposited numbers.  Large payments are less frequent anyway, and
provide less covering traffic.  If you continuously rotate your money
into the future, therefore, all the steps must be encapsulated, making
the size of the message grow linearly with the number of hops.  One
might be able to use a financial intermediary for anonymity, though.
It's not obvious to me that this will work.

@_date: 1993-02-23 09:31:42
@_author: Eric Hughes 
@_subject: Beware of anon.penet.fi message! 
Currently to mail to person 1234 at penet, you send mail to This mail goes out anonymously from the sender, either using an
existing mail address or creating one.  But if one were able to reach
person 1234 also with the email address, say,
the behavior could be _not_ to make this posting anonymous.
To wit, the 1234 indicates that you are replying to a pseudonymous
recipient, and the anon/name pair indicate whether the sender is
anonymous.  Thus no change in default behavior, and no new header

@_date: 1993-02-23 18:49:18
@_author: Eric Hughes 
@_subject: dispatches from the front lines of anonymity 
In an already supported sense, yes.  As I understand it, when a
moderated group is created, an email address for the moderator is
propagated with it.  So every time a moderated group is created, every
server already is "modified".
But the anonymity does not take place in NNTP.  The news server mails
every posting to the moderator's address.  The header filtering take
place on that machine, unbeknowst to the original NNTP server.  I hear
that this mechanism didn't used to work reliably, but that it now
basically does.  Comments?
In addition, the direct mail address should be advertised
independently, so that those without easy access to Usenet news can
still use the system.
The way to forge a posting to alt.whistleblower would be to post with
your real address in it!  That's not exactly a positive feedback loop
for the outlaw.
Granted.  Thus the need for a periodic posting stating exactly what
the security level of the system is.
Agreed.  That's why you publish the newsgroup entry point.  Then a
more sophisticated whistleblower could use a remailer chain to get to
the access point.

@_date: 1993-02-23 19:00:22
@_author: Eric Hughes 
@_subject: anonymous return addresses 
Re: options for anonymous return
A variant of (1) greatly increases the security.  Have the remailer
memorize an anonymous return address of type (2).  The information
that is contained in a remailer then, per pseudonym, is
  a.  the pseudonym
  b.  the address of the next remailer to use
  c.  a block of stuff to be prepended to the outgoing mail.  Presumably
        this is forwarding instructions for the next remailer.  It would
Thus, even if the whole pseudonym mapping list were compromised, it
would only reveal a list of sites to try and compromise next.  And at
some point the private remailer keys have to be compromised as well,
since all the remailing instruction are encrypted with them.
This system can also be chained, creating "routing pseudonyms" on
various remailers and encrypted instructions pointing one pseudonym to

@_date: 1993-02-24 10:23:56
@_author: Eric Hughes 
@_subject: Beware of anon.penet.fi message! 
Re: an1234 vs. na1234
You can determine the From: line by looking at the destination.
If the destination is to another alias, then you use "an1234", since
the reply should appear to be coming from another alias.  Using the
"an1234" address triggers the aliasing mechanism.  On the other hand, if the destination is to a non-alias mailbox, then
use the "na1234" form.  In this way the alias mechanism is not invoked
upon reply.
For messages with more than one addressee, split all the alias
destinations into one message, and all the non-alias destinations into
another.  Set the From: line accordingly in each message.  This avoids
the attack of using a two-recipient message to invoke an incorrect
alias behavior.
For newsgroup postings, where no particular addressee is listed, and
for mailing lists, I would suggest using "na1234", but this probably
is a change in the default behavior for newsgroups.  You would like
newsgroups and mailing lists to act the same, and that means either
keeping a list of mailing list entry points (ick), or using the
"na1234" form.

@_date: 1993-02-27 11:33:57
@_author: Eric Hughes 
@_subject: March 13 cypherpunks meeting 
Announcing:  The First Annual Post-CFP cypherpunks meeting.
The next physical meeting of cypherpunks will be March 13, 1993, at
the usual time, noon, in the usual place, Cygnus Support Offices.
This is one day after CFP-93, the third Conference on Computers,
Freedom, and Privacy.  CFP is an increasingly important conference
concerning an only slightly broader spectrum of privacy issues than
are normally discussed on the cypherpunks list.  At the first CFP
conference I met David Chaum, who awakened a latent interest in
cryptography.  This awakening led indirectly to the formation of this
There will be people from all over the country there.  We have set the
date of our meeting so that they could attend.  We are, in fact, going
to give out an open invitation there.
I would urge all of you who have been considering making a trek to
come to one of these meetings to do so this time.  And while I do not
expect Dorothy Denning to show up (although she would be welcome, if
uncomfortable), I do expect some surprises.  Please surprise me
yourself.  If you need a place to stay, ask on the list.  I myself am
already putting up some friends before the conference.
For that matter, I would urge all of you to come to the conference
itself.  If you can't afford to go, just remember that while the
sessions you have to pay for, the hotel bar you do not.  A word to the
wise is sufficient.
Thank you all.

@_date: 1993-02-27 12:11:00
@_author: Eric Hughes 
@_subject: more ideas on anonymity 
Well, yes.
There has been a huge conflagration on the pem-dev list lately
concerning naming issues, X.500, etc.  I am somewhat disturbed by what
I see as a fundamental mentality of PEM: the desire to lift intact all
existing political, economic, and social relationships into the
electronic domain.
Naming is done in the ISO way, that is, subordinated to existing
national boundaries.  Individuals are expected to be registered in the
naming hierarchy.  Identities in the electronic world are expected to
map to entities in the real world.
Does this not seems fundamentally limiting to the potential of the
electronic world?
I agree with Tim that we have made good progress.  But we need more
than simple remailers.  We need people to use remailers, and we need
to make that easy to do.  We need key distribution mechanisms.  We
need better meeting spaces than mailing lists and Usenet newsgroups
and private mail.  We need markets and contracts.
If we wish to re-envision the world, we must do so while there is time
to implement it.  Let us proceed quickly.

@_date: 1993-02-27 12:44:52
@_author: Eric Hughes 
@_subject: more ideas on anonymity 
For many transactions, identity is not an issue fundamental to the
transaction.  If I pay cash to you for an item, I have not made any
implicit promise to pay you at a later date, as I have if I've paid
with credit (card or account).  Every obligation I might have to you I
have already fulfilled, fulfilled by paying cash.  My name is not
relevant here.
If I perform some service for you, and you acknowledge that the
service is complete as performed, then you have no need for my
identity.  (As far as the two of us are concerned.  Other parties
intrude on this interaction usually.)
Therefore, should not discrimination against anonymity when names are
not germane be considered (depending on one's ideology) unreasonable,
inefficient, coercive, intrusive, or illegal?

@_date: 1993-02-27 13:02:53
@_author: Eric Hughes 
@_subject: more ideas on anonymity 
The only perfectly unambiguous position is that every use is a
legitimate use.

@_date: 1993-02-27 13:18:50
@_author: Eric Hughes 
@_subject: dispatches from the front lines of anonymity 
Re: alt.whistleblower moderation
Well, we can weekly publish the submission address.  It would take
slightly more intelligence on the part of the would-be poster.
What are exactly the politics of propagating this moderator's address,
anyway?  Is it particularly difficult?  Is it automated?
Please advise.  alt.whistleblower, in addition to being a public good,
is a great way to raise hell.

@_date: 1993-02-28 09:58:36
@_author: Eric Hughes 
@_subject: anon user on cypherpunks list 
I have changed the subscription name in the list to the "na" form, so
the immediate problem for cypherpunks is fixed.
But this problem will persist.  Many, if not most, mailing lists are
running automated list software and the address given in the
subscription request is the address added.  Even if the administrator
manually changes the entry, the old one can be added right back.
Mailing list software could be changed to notice penet anonymous
addresses, but don't hold your breath for that to be deployed soon.
There are two problems with the current anon at penet design that I see
as fundamental.  The first, widely discussed and the proximate cause
of the above problem, is automatic pseudonym generation.  The second
is ensured by the first and is subtler: the remailer does not allow
multiple pseudonyms per incoming email address.
Multiple pseudonyms allow compartmentalization and has two benefits.
The first benefit is unlinkability.  I have sometimes wanted to argue
both sides of an issue, but refrained because that is too confusing
for most to follow.  (The semiotics of "consistency/ignorability" and
"one mind/one opinion" are fascinating and, here, digressing.)  I
might also wish to argue in two completely different fora and not have
these seen as the same person.
For every reason you might want a pseudonym in the first place, you
might also want a "pseudonym from your pseudonym," especially if you
use it a lot.
The second benefit of compartmented identities happens when the
pseudonym is revealed, either by choice or by chance.  There are many
situations when a temporary identity might be desired; I leave it to
others to list them.  With the current single-pseudonym system, one
revelation of identity reveals all others.  When there is no
particular benefit to being seen as the same identity, I would rather
have multiple identities for exactly this reason.
As far as implementations go, having multiple pseudonyms requires that
a separate "request for pseudonym" be added, as well as a way to
indicate from which pseudonym (or none of them) mail should be from.
I would suggest bouncing mail to "an" style addresses unless a
pseudonym has been declared; the bounce message would, of course,
contain instructions on how to obtain a pseudonym or use the "na"
Therefore, I would suggest that a second version of the pseudonymous
system at penet do away with automatic generation and support multiple

@_date: 1993-02-28 10:09:40
@_author: Eric Hughes 
@_subject: dispatches from the front lines of anonymity 
Actually, I was thinking that whistleblower at anon.penet.fi would _be_
the moderator.  Then you just post directly.  All the messages would
come from that address, and no id's would be assigned.  Since all
messages are from "whistleblower", replies to a poster go right back
out to the list, also anonymized.
It's actually a much simpler system than is currently implemented,
since id's arenit involved at all.
PGP 2.1 contains the cleartext-signature feature, and the periodic
posting to the list should mention this.  This allows a real pseudonym
to develop, just like we want.

@_date: 1993-02-28 11:54:03
@_author: Eric Hughes 
@_subject: A Modest Proposal 
I make no claim above as to the propriety of an unambiguous position,
merely that there is one and only one completely clear position.
(There is another, that no use is legitimate, and we here conveniently
ignore that one :-)
The consequences of unambiguity must affect our discussions of this
matter.  If we desire unambiguity, then there is no need to
distinguish between uses.  If, however, the unambiguous solution is
not desirable, then there must be decisions made about propriety.  As
with every other question of power, the real question is
The questions "What are significant criteria?", "When is the decision
made?", and others are all subordinate to the question "Who decides?"
Roughly speaking, there are three situations regarding anonymous
communication: the sender, the carrier, and the receiver.  In each of
these, we can examine what decisions they are _able_ to make.
As sender, I can choose who I present myself as, whom I send to to,
what carriers I want, and what I want to say.  As carrier, I can
choose whom to accept messages from, whom to send them to, what
content I am willing to pass.  As receiver, I can choose what carriers
to receive messages from, and from whom to accept mail.
Well, an anonymous service _can_ do just that.  Whether or not the
rest of the world continues to communicate with them is a separate
question, an important question in the short run to be sure.
Acknowledgement that a procedure is an exigency does not make that
procedure desirable of itself.  All differential carriage based on
content is censorship.  I acknowledge the exigency of certain forms of
censorship in currently deployed anonymous systems.
Nonetheless, I will never desire censorship for its own sake and I
will also fight to remove the conditions which make censorship exigent
in the first place.
The problem is, who decides what is exigent?  We can either answer
that question, or change the world so that we never need ask it.
I decline to respond to the essay by Mr. D. Lewdud.

@_date: 1993-02-28 12:11:20
@_author: Eric Hughes 
@_subject: more ideas on anonymity 
Privacy costs.  It is possible to create a company which offers
insurance against damage and loss, paid for by the user, assigned to
the owner.  Such a policy could be presented to a car rental agency in
lieu of your name.  Your transaction with the rental agency would then
be anonymous, even if your transaction with the insurer were not.
Such an arrangement might even be preferable to a rental agency, since
it means they don't have to go after individuals with shallow pockets
in the event of damage or loss.
I can even imagine such a company which offers standard policies for
any number of different objects, written and digitally signed over the
phone.  Want to rent and apartment?  Get your damage and last month's
rent insured.  There is already such a thing as "completion insurance" for
construction and the like, purchased by the builder as a condition of
contract.  If the transaction costs of this and similar types of
insurance were lowered, anonymity in the real world would increase.

@_date: 1993-02-28 17:14:14
@_author: Eric Hughes 
@_subject: anon.penet.fi hacking 
Your call for this went unacknowledged but nevertheless listened to.
It was not until a week or two after the sig-kill stuff was over that
I came up with a solution.
The next revision of the remailer will have something like
The first character in the body that matches the regex, and every
character after it, will be dropped.  This not only makes it a
one-liner in perl (!), but it means that the user can be as
arbitrarily complex in recognizing sig blocks as the are able.
Of course, we'll document the most common of these:
For those of you who know nothing about regular expressions, this
recognizes a line containing two minus signs and nothing else.  If
your signature adder does it some other way, it's pretty much
automatically supported.  You could also put more of your signature in
the regex to ensure that it doesn't interfere unexpectedly with body
Summary: user-defined, almost every case handled, not automatic.
I hate my sample header field name.  Please, someone think up a better

@_date: 1993-02-28 17:51:38
@_author: Eric Hughes 
@_subject: Future of anonymity (short-term vs. long-term) 
Marc's short-term suggestion of bandwidth limiting from a particular
source seems like a reasonable exigency.  Let me suggest a way of
doing that which does not require keeping long-term logs.
Suppose your bandwidth limiter kept totals of all bytes sent in the
last week.  In order to keep that data current, it needs to know when
to remove byte counts that are a week old.  Thus it needs to keep logs
of the last week's worth of messages, at least in byte count form.
Instead of that, you can just make the byte count decay.  Once a day,
a process goes through the byte counts and reduces them.  Remove any
entries are <= 0.  If this decaying byte count is bigger than some
threshold, bounce the message.
I would suggest that the reduction equation be linear: multiply by
some constant between one and zero, and subtract off a fixed amount,
drop the fractional part.  The multiplicative factor, which I would
set between .9 and 1.0, means that an occasional large file could be
sent through without completely eliminating email delivery for a
while.  The subtractive amount cleans out the database more quickly.

@_date: 1993-02-28 18:05:54
@_author: Eric Hughes 
@_subject: header field indicating an anonymous address 
Marc R. suggests that we standardize on a header field to indicate
that a message was anonymous.
I suggest "Anon-Sender:".  There's already a "Sender:" field in
RFC-822, indicating who sent the message, as separate from who wrote
the message.  The "Anon-Sender:" field should contain an email address
for the maintainer of the remailer. Why? To facilitate complaints. :-)

@_date: 1993-02-28 21:40:04
@_author: Eric Hughes 
@_subject: A Modest Proposal 
A member of the list wrote back to me to say that this went over his
head because he wasn't a lawyer.  I am not a lawyer either.  Since a
compact statement has been too compact, allow me to be more verbose.
An exigency is something you do because you have to in order to
accomplish something else.  It's not something you do because someone
told you to or because you promised to do it.  Exigencies, if you
don't like them, are often called 'necessary evils,' with all the
connotations of that phrase.  In this case, restrictions on remailers
are an exigency, something you might have to do to stay on the net.
Now just because you have to do something doesn't mean that's a good
thing.  In California, you have to give out your thumbprint in order
to get a driver's license.  Giving the thumbprint is an exigency.  I
did not want to do that; I don't think it's a good thing; I did it
anyway because I wanted a driver's license more than I wanted my
thumbprint not to be digitized.
Differential means that two things are not the same and has the
connotation that one is preferable to the other.  Carriage is the noun
form of the verb 'to carry' and in this context refers to the act of
carrying an electronic message.  Thus differential carriage is
carrying some messages preferentially, such as refusing to mail to or
from a particular site, or to delay or alter some messages but not
I claim that all differential carriage where the differences in how
the messages are carried arise from the content (or expected content)
of those messages is, in fact, censorship and should be called such.
If am operate an anonymous service and I refuse to pass a message
because someone has complained about it, I have exercised a preference
and created a difference in the way I treat the message.  I have
exercised censorship over that message.  I have presented my service
as a public utility, and yet I have created a difference in how I
treat messages.  My domain of potential censorship is not large, but
it is there.
It is an unfortunate fact of the internet that there will be pressure
brought to bear against the operators of anonymous remailers, and that
in the interim such pressure might be strong enough to force such
operators off the net.  Some restrictions against content might be
necessary to keep these services online.  If so, then I believe that
these restriction should be implemented.  I'd rather have the services
Nonetheless, I deplore any such restrictions.
And if it not perfectly clear by now, let me finally state that I am
in agreement with Lance Detweiler on this point, that some restriction
may be necessary in order to keep anonymous services online.  But that
said, I still don't like it.
I will continue to dislike it, and I will work to make the necessity
for restrictions disappear.

@_date: 1993-01-21 08:14:31
@_author: Eric Hughes 
@_subject: PGP on BBS 
The scenario David Brooks outlines is extremely common: one host
computer providing information services to another computer which acts
as a terminal.  This may be a BBS, Compuserve, Lexis, or any number of
other services.  If there exists an implementable mechanism which does
not require trust of the host, then it should be implemented.
In the case of cryptography, this means that secret information should
not be transmitted to the host.  Hence all operations which use secret
information must be performed on the terminal computer.  These
operations include session key generation and signing of messages.
The solution is cooperative processing systems, where both the host
and the terminal cooperate to perform some task.  Unfortunately, there
is precious little software infrastructure to support such a
development.  Terminal programs on PC's are still for the most part
acting as dumb terminals, with the notable exception of file transfer
protocols such as zmodem.
I believe that cooperative communication software will be necessary
for widespread use of cryptography--not just pleasant, but a
precondition to large scale deployment.
Although this topic is not directly related to cryptology, it is
certainly appropriate for discussion on this list.  It is the
cypherpunk goal for widespread use of crypto by the masses, and the
exact nature of the infrastructure necessary for that task should be
debated, then implemented, then deployed.

@_date: 1993-01-21 08:38:55
@_author: Eric Hughes 
@_subject: random remailers 
This is an excellent suggestion.  I have to think about the
mathematical properties some more, but a few spring to mind.  Assume,
for discussion, that there is constant probability of delivery at each
hop, say p.
First, the expected number of hops is 1/p.  To see this just sum the
following series.
Thus the syntax for routing can be extremely simple, just specifying
the expected number of hops wanted.  If you want to have guaranteed
minimum delivery, you can manually route through a few hops, then

@_date: 1993-01-21 08:44:20
@_author: Eric Hughes 
@_subject: possible solution to the anonymous harrassment problem 
I asked Jim Bidzos about this last Friday.  He states that the purpose
of this clause is to avoid the situation where modifications to the
package decrease its cryptographic security.
I gather that such special permission should not be too hard to get.

@_date: 1993-01-21 08:48:34
@_author: Eric Hughes 
@_subject: RIPEM vs PEM 
A note on licensing: PKP is the holder of the patents.  The Partners
are RSA Data Security, Cylink, MIT, and Stanford.  PKP has a staff of
RSADSI is also entitled to license the technology.  Most people go
through them.  IBM dealt with PKP directly, evidently.

@_date: 1993-01-21 08:52:29
@_author: Eric Hughes 
@_subject: possible solution to the anonymous h 
I found out last Friday at the RSA conference that RSADSI itself is
going to issue "persona" (i.e. no attempt to find out who it really
is) certificates for free.
That's right.  No charge.

@_date: 1993-01-22 07:48:48
@_author: Eric Hughes 
@_subject: crypto, NSA, gnu, and cypherpunks in Boardwatch magazine 
Jack Rickard was kind enough to send me the following.  A new member
of the list told me he had found out about the list from this article.

@_date: 1993-01-22 08:11:25
@_author: Eric Hughes 
@_subject: PGP on BBS 
Dean asks:
Here are two basic examples:
1. Session key creation.  I regularly log in remotely to my account at
soda.  I'd like to have that modem link encrypted, with session keys
generated on the fly.  So I'll want to use some implementation of
Diffie-Hellman key exchange to make a session key.  The nature of this
protocol means that both my terminal program and my host have to do
calculations and exchange data.  Therefore I need software on my PC at
home and software on the host that work together.
2. Digital signatures.  I read and send my e-mail on the host.  When I
send PGP-encrypted mail, I have to compose the message on the PC,
encrypt it with a PGP command line, upload it to the host with zmodem,
and read it in to my mailer.  I'm certainly not going to put my secret
key on the host.  What would be ideal is a cooperative protocol that initiated (in the
background, away from my main connection) a channel, sent just the
data to be signed (an IDEA key, for example), have my PC sign the data
and send it back.  This not only entails software on each end, but
also a line multiplexer so that the signing can take place on a
separate channel.  If it doesn't occur on a separate channel, then I
have to see it, probably move to the shell in order to start it
properly, and in general make it non-automatic.

@_date: 1993-01-25 15:09:59
@_author: Eric Hughes 
@_subject: Coupled programs 
This is exactly the goal.  For example, zmodem has a widespread
deployment and a public specification.  What needs to happen for
cryptography is the development of such protocols for key exchange,
signatures, and other cryptographic entities.

@_date: 1993-01-25 15:20:38
@_author: Eric Hughes 
@_subject: security by obfuscation 
The disambiguating question is "What is the capability of your
opponent?"  Some opponents have only access to their own machine as
users, and some have access as root.  Others have access to all
traffic on the local network and can thus see all mail entering and
leaving a system.  Others, we might assume, have access to all traffic
on any non-local network.
The rule is the following.  If it's cheap enough to defend against
even the strongest opponent, deploy it.  Cryptography, with its
presumably exponential difference between the costs of defense
(encryption) and offense (cryptanalysis), allows for economical
solutions against even the largest of opponents.
Cryptography is a greater leveler than the Colt .45 revolver.

@_date: 1993-01-26 19:29:55
@_author: Eric Hughes 
@_subject: weak point of PGP implementation 
Matt mentions three potential weaknesses in PGP: RSA key length, the
IDEA cypher, the pass phrase.  Let me add:
4. The random number generator used to make session keys.  If this is
weak, then an opponent might be able to guess them feasibly.  This attack
does not require breaking the underlying cryptography.
5. Weak random numbers for RSA key generation.  If the numbers in the
random number pool are not as random as they should be, then one might
simply simulate the prime generation algorithm and compile a table of
potential PGP primes.  Simply running trial division on this list
versus a storehouse of public keys might reveal common factors.  Even
running Euclid's algorithm to find g.c.d.'s on a such a storehouse
versus itself might produce factorizations.
searches sequentially from a random starting point.  Thus it will tend
to find primes that are preceded by large blocks of composite numbers.
This alone reduces the search space some, possibly considerably.
Has anybody measured how good the keystroke timings are, anyway?

@_date: 1993-01-26 19:36:42
@_author: Eric Hughes 
@_subject: Computerized OTP (was 5th AMENDMENT & DECRYPTION) 
Taking 6-graph statistics, we seen that the entropy is 5.95, where it
should be 6.00.  Or in other words, .992 bits of entropy per bit
symbol.  That's not good.

@_date: 1993-01-26 19:41:31
@_author: Eric Hughes 
@_subject: Coupled programs 
I am talking about interactive protocols.  To generate a session key
for communication with some remote host will require both parties to
PEM is a standard for "privacy enchanced" electronic email formats and
encryption methods.  PEM is not a standard for interacting protocols.

@_date: 1993-01-27 20:50:44
@_author: Eric Hughes 
@_subject: Computerized OTP (was 5th AMENDMENT & DECRYPTION) 
At risk of belaboring the point about random numbers, I have some
more, hopefully different comments.
Let me at least make the following point clear.  Making random numbers
is a hard problem.  It is hard on the scale of designing a good
cryptographic hash function.
It is unwise to conclude that a source is random merely because it
looks like noise.  Electrical noise is often a poor source of
randomness because much noise comes from unshielded oscillators of one
sort or another.  Even a source based on thermal noise must be
carefully designed, since solid state effects such as avalanching can
generate characteristic contributions.
I would suggest that everyone look and volume 2 of Knuth for the
difficulty of designing pseudorandom number generators in software.
Making hardware random numbers is harder than that, since it requires
all that knowledge and then some.  The difficulty is in knowing that
your numbers are random, not in making noise.
This is not sufficient for a stream to be random.  I can have this
property and still have a very non-random stream.  For example,
suppose I have a random stream.  If for every two bits I output those
two bits and their xor (sum mod 2), then no two bits have any relation
to each other, but looking at bits three at a time shows awful
The actual statement is that the every conditional probability that a
configuration of size n occur given any other independent
configuration is 1/n.  In others words, every combination of bits must
be independent from every other combination.  This is much stronger than
requiring mere bit independence.
And as an aside, long runs of bits can be removed (as Scott Collins
mentioned) by compression, and short configurations of bits can be
removed by hashing.

@_date: 1993-01-29 11:36:05
@_author: Eric Hughes 
@_subject: is this true??? 
The piece about widespread worldwide modem monitoring has one notable
difference from most similar pieces: the presence of a bit of
falsifiable information, namely the credit history codes HN06443 and
Anybody know how to find an authoritative source for independent
verification of this data?

@_date: 1993-01-29 11:48:07
@_author: Eric Hughes 
@_subject: thresholding to enhance secrecy 
It seems that your "thresholding" schemes require an increase in message size.  Do I read this correctly?
It also seems that you need to generate one time pads to effect this
increase in message size, with all the attendant costs of making that
quantity of random bits.

@_date: 1993-07-21 19:19:50
@_author: Eric Hughes 
@_subject: ADMIN: cypherpunks@indigo.mese.com has been removed 
cypherpunks at indigo.mese.com has been removed from the mailing list
because it appears that mail being sent to this alias is ending up
back on the list.  This behavior is wrong.
If the list at large sees this, pardon me.

@_date: 1993-07-22 19:40:16
@_author: Eric Hughes 
@_subject: REMAIL: replying to cp-remailed messages 
There should be a way to do this already.  Just as :: does header
pasting when a mailer receives a message, so should  paste headers
when a mailer sends a message.  Then you just paste in a Reply-To:
header field when the message leaves the last remailer.
This technique is also useful for Usenet posting, for things like
Organization:, etc.

@_date: 1993-07-26 21:16:05
@_author: Eric Hughes 
@_subject: FASHION: temporary tattoos 
As long as we're in our graphic design stage, I'm not much into
ideographic clothing, but I wouldn't mind as temporary tattoo for my
forehead that said
All due credit to Neal Stephenson for _Snow Crash_ fame.

@_date: 1993-07-30 06:59:48
@_author: Eric Hughes 
@_subject: Paranoia and the Outlawing of Cash 
Arbitrarily small transactions.
The Dan-card system uses dial-up authentications for a large part (if
not all) of its transactions.  The telecom charges are causing the
system to run at a large loss; this wouldn't be a commercially viable
system.  The Danish government is looking at making 'DAN-coin', which
would be a smart card system that relies upon the physical security of
the device.  Since no on-line telecom charges incur, the coin system will be much easier to deploy.

@_date: 1993-06-01 08:19:29
@_author: Eric Hughes 
@_subject: Software infrastructure 
I think Hal is largely accurate here.  Certainly the "DOS box as
terminal" problem needs to be solved.  With the advent of 386BSD,
however, home Unix is going to be increasingly common.  As an aside, I want to harp again on what I call the software
infrastructure problem.  If email and telecomm systems were well
structured, instead of exhibiting so much history in themselves, most
encryption freatures would be extremely easy to implement--just grab
the right hook.  Unfortunately this is not the situation.  Hence my
Let's go back to the DOS-as-terminal issue.  The politics and
economics of DOS shareware is such that source code is almost never
made available.  Gnu public license software is rare in the DOS world.
I propose that interested cypherpunks write a DOS terminal program
which _is_ free software.  In order to overcome the inertia which Hal
properly observes is endemic to any software change, I submit that to
have source code available to fix or add features deemed desirable
will be a key factor in acceptance of this software.  I have my own
ideas about multiplexing the channel to support background POP and
file transfer, but I'll leave that for later.  Such software, of
course, would be properly layered to be able to add encryption at the
key junctures.
It would be entirely appropriate to discuss such architecture here on
the cypherpunks list.  When the developers's effort starts, I promise
to find a way for them to have their own mailing list.

@_date: 1993-06-01 08:30:06
@_author: Eric Hughes 
@_subject: Crypto anarchy in a VW? (not the bug) 
This presumes a model where the logical server is a single machine.
That doesn't have to be the case.  By using a secret sharing protocol
(M out of N reconstruction), one can multiply site any database, with
sites anywhere in the world.  A database then is in actuality not in
any single place.
Cryptography is all economics.  If you are doing something where the
location of a machine must not be revealed, then you've got the money
to pay for a satellite link.  High security means high expense, and
there is no way around that.

@_date: 1993-06-01 08:41:02
@_author: Eric Hughes 
@_subject: No Subject 
Currently that is the easiest way, to be sure.  Another way would be
to store the passphrase encrypted in a file so that at least it's not
findable with strings(1).  Here a quick hack for someone who's looking
for a project: a passphrase storage process which accepts requests
from a slightly modified PGP.
Hal's basic point, however is not mitigated.  Nothing is secure from a
clever root.
An excellent suggestion.

@_date: 1993-06-01 08:54:26
@_author: Eric Hughes 
@_subject: Crypto anarchy in a VW? (not the bug) 
We build the privacy into the system, not the government.  The
question is _who decides_?  If we decide by creating, then more
privacy will exist by fiat.
Absolutely.  This does not contradict our activity of building the
privacy into the system.  Any privacy system you can build on top of
an insecure network such as the internet can also be built on top of a
privacy-friendly network.
One of the really great techniques I've hear about recently is a data
channel that runs at 90% T1 speed over the ~900 MHz spread spectrum
band.  The legal limit is 1W transmitter power and 4W antenna gain
(transmitted energy focusing).  From what I hear, though, the antenna
gain requirements are being ignored by lots of folks.  What this means
in practice is that you can set up a directional antenna and easily
get a twenty mile hop on one of these units.
Cylink has had a T1 link encrypter out for years.  It uses D-H for key
exchange.  It's also costs (not-known-to-be-accurate) about 10K$ per

@_date: 1993-06-01 08:59:13
@_author: Eric Hughes 
@_subject: Electronic Contracts 
The Bellcore service is properly a timestamping service and not a
signature service.  Their timestamp is constructed out of hash
functions, not digital signatures.
The algorithm is patented.  Contact Bellcore for licensing.  I'm not
sure they are going to license; they may decide that they want all the
timestamping revenue themselves.

@_date: 1993-06-01 09:22:44
@_author: Eric Hughes 
@_subject: Clipperpunks Write Code? 
We are trying to build a sandbox, and the government is trying to
restrict the use of sand.
My apologies to non-US readers for the diatribe on US politics.
Unfortunately, if the US restricts cryptography, others are likely to
follow, either by coercion or by example.
I had dinner last night with, among others, John Gilmore and John
Barlow, who have just been to DC with the rest of the EFF Board to
talk to politicos.  Without being too specific (I leave it to those
who were there to decide the propriety of the details), but several
things became clear.
1.  Clinton has signed onto Clipper full-bore 100%.  Bush started it,
but Clinton, the ever-moderate, has told the eavesdropping community
that he can take their side on some issues.
2.  They're going to deploy Clipper without regard to public
sentiment.  That means that to be influenced by public sentiment, it
is going to have to be huge.  Educational efforts are going to have to
be large.
3.  Our government is looking at the "example of other governments" to
justify that restrictions on cryptography are not beyond the pale.
This is serious, make no mistake.  If, as in the White House statement
as reprinted in the Post, the government does restrict everything to
be Clipper, all anonymity and pseudonymity efforts are worthless.
That said, I also urge those who are writing code to continue.  To
those of you not writing code, however, I say start talking to your
friends and neighbors and communities and newspapers.

@_date: 1993-06-01 09:27:23
@_author: Eric Hughes 
@_subject: No Subject 
Could you post a more complete pointer to this?
Since you are going to be writing some of these, presumably, I take it
you'll be sharing your code with us.  Yes?
The directory is there as much to inspire the writing of such software
as it is to distribute it.

@_date: 1993-06-01 10:16:40
@_author: Eric Hughes 
@_subject: crypto '93: deadline for stipend 
For those of you who want to go to CRYPTO 93 and get paid to do so,
the deadline is this Friday.  The conference is Aug 22 et seq. in
Santa Barbara.
Details from the announcement are below.

@_date: 1993-06-01 10:46:28
@_author: Eric Hughes 
@_subject: Crypto anarchy in a VW? (not the bug) 
Please, everyone who is working on this, remember.  You can't do hard
disk encryption in software on the host CPU.  Thanks to Jim for
reminding me to stress this.
DES hardware is already available and tested.  Use it.  Use a
triple-keyed EDE version of DES.  Is someone selling a raw DES chip on an ISA card?  If so, use that so
that others don't have to hack together their own hardware.
The keying material for the disk should not be one key for the whole
disk.  The keying material could easily be one key per track without
the keys growing too large.
Ideally this keying material would be held on a removable PCMCIA card
and would talk directly to the device encryptor hardware with a
protected channel.  That will have to wait.

@_date: 1993-06-01 13:06:15
@_author: Eric Hughes 
@_subject: Crypto anarchy in a VW? (not the bug) 
I argue that encrypted hard disks should be encrypted at the transfer
Never fear.  Layered encryption is the way of the future.  One layer
of encryption for the disk as a whole, another for the users.  When
the stuff gets cheap enough, it will be everywhere.
The question is "Who is your opponent?"  If you are concerned with the
users against each other, then use user level encryption.  If you are
concerned with the outside world against the machine, then encrypt at
the disk controller or device driver level.  If you are concerned
about both, then do both.

@_date: 1993-06-01 13:09:11
@_author: Eric Hughes 
@_subject: Crypto anarchy in a VW? (not the bug) 
Performance.  Look at how long it take to do encryption via software
and how long by hardware.  Consider that a Unix box can do other
processor tasks while the disk is stepping.
Re: EPROM as key
A fragile device makes privacy for hackers only.  General privacy will
require something significantly more physically robust.

@_date: 1993-06-01 13:31:05
@_author: Eric Hughes 
@_subject: No Subject 
For just plain old reliability in the face of expected hardware and
connectivity failure, it is reason enough.  When one examines intended
such failures, the analysis must be more subtle.
Yes.  On any system at all, the portals that guard privacy are public.
For whatever architecture you chose, you still need an actual email
address that resolves down to some physical internet machine to gain
access to that service.
Shutting down service is all economics.  It you must simultaneously
shut down even two machines, that is a larger cost that shutting down
one, since there must be coordination.
Cost, cost, cost.  What is possible and what is fiscally available are
two different things.  Two machines might be in the realm of
possibility, but where is the cutoff exactly?
No, there is a single and incredibly salient difference--communicating
the change of address to all those who use the service.  Right now,
this changed information must either end up in people's head, or in
their alias files, or in their scripts.  Wherever it is, it would have
to change.  This effectively puts a fairly small upper bound on the user base for
such a service, given the characterstic time it takes to communicate
such changes.
Plus, if you want pseudonymous return paths, then you have to make
sure that data is transferred to a new system.
The scenario I envision for virtualized databases is a business
running such a network themselves or in partnership with other
companies.  Doing this all on netcom shell accounts just won't happen.
The hard part here is trying to get someone to pay for the secure
If there is a single point of failure, that's a problem.  This is a
design criterion, not an overwhelming roadblock.
One-point failure!  The politics of the connecting network are crucial
in the long run.  I have a separate message about that.
I see no reason why these two approaches are exclusive.

@_date: 1993-06-01 20:34:59
@_author: Eric Hughes 
@_subject: WH email petition. 
It appears that they are going to count responses and make totals pro
and con any particular issue that people write about.  Thus while the
particulars of the petition don't really matter, the basic statements
against restrictions on encryption technology do.
I also heard no mention that they were going to do any kind of sorting
by person or email address.  Thus it appears that you get to vote
early and often in this public opinion poll.
Heh, heh, heh.

@_date: 1993-06-01 20:58:31
@_author: Eric Hughes 
@_subject: Work the work! 
Paul, you of all people don't need to feel slighted when I urge people
to do something, anything, about the wiretap chips.  Therefore, let me
rephrase my exhortation to the list at large.
If you are doing something, continue.  If you are not, start.
The particulars of what one does are not so nearly important to me as
that one does something.  Anyone who understands at least one tenth of
this list understands more than your average reporter.  While I would
like all the details to be perfectly accurate everywhere, this is not
going to happen.  Even if you don't feel like you are an expert, you
are more expert than most.  With the aid of the documents in the ftp
site, and a few hours time, you can become even more expert.
The EFF is going to be involved with the cryptography issue.  More
than that and I defer to John Gilmore, who is on the EFF board and
this list and who can speak more authoritatively than I.
Here is my own very short version of my policy toward the wiretap
"The government has no right to restrict my use of cryptography in any
way.  They may not forbid me to use whatever ciphers I may like, nor
may they require me to use any that I do not like."
The hypothetical backdoor in clipper is a charlatan's issue by
comparison, as is discussion of how to make a key escrow system
'work.'  Do not be suckered into talking about an issue that is not
important.  If someone want to talk about potential back doors, refuse
to speculate.  The existence of a front door (key escrow) make back
door issues pale in comparison.  If someone wants to talk about how key escrow works, refuse to
elaborate.  Saying that this particular key escrow system is bad has a
large measure of complicity in saying that escrow systems in general
are OK.  Always argue that this particular key escrow system is bad
because it is a key escrow system, not because it has procedural
This right issue is that the government has no right to my private
communications.  Every other issue is the wrong issue and detracts
from this central one.  If we defeat one particular system without
defeating all other possible such systems at the same time, we have
not won at all; we have delayed the time of reckoning.
Trenchantly yours,

@_date: 1993-06-01 21:35:07
@_author: Eric Hughes 
@_subject: "Newsweek" Article on Clipper and Encryption 
I got a call one week ago today (Tuesday May 25th) from Josh Ramo at
the science desk at Newsweek.  I spoke to him for about an hour on the
technicalities and politics of encryption.  He was to my pleasant
surprise quite able to follow a telephone description of how
Diffie-Hellman key exchange works (!) and was quite conducive to my
explanation of some of the less public aspects of the clipper project.
I think we got extremely good coverage in this article.  Here are some
of the aspects involved.

@_date: 1993-06-02 06:39:06
@_author: Eric Hughes 
@_subject: ADMIN: incoming ftp site works now 
I've arranged so that the pub/cypherpunks/incoming directory will
accept uploads now.  So if you have stuff to send, please ftp it to
that directory rather than using e-mail.  Of course, if you don't have
ftp access, please continue to use email.
For those of you who tried this before, the problem was that the
wuarchive ftpd that the system was running needs a line in its
configuration file to say that uploads are peritted in a directory.

@_date: 1993-06-02 06:51:21
@_author: Eric Hughes 
@_subject: Term software development/design 
The reason to use FOSSIL, and it is a sufficiently strong reason, is
that with some layer of abstraction at that low level, you can't do
end-to-end link encryption transparently.
For example, if you want to do a download over a secure channel, if
you have to use an external protocol, and if that protocol talks
directly to the serial port, then you can't use it, because the
protocol will see only gibberish.  If, on the other had, the protocol
driver uses FOSSIL, and if your FOSSIL can set up an encrypted
channel, then the protocol will perform as expected without being
aware that it's underlying connection is encrypted.
The reason to use FOSSIL is not compatibility, but abstraction.  It's
the only abstraction for serial communications the PC has, and we'd
better take advantage of it.

@_date: 1993-06-02 07:12:49
@_author: Eric Hughes 
@_subject: Software infrastructure 
Let me clarify the discussion here about PC terminal software.  There
are two distinctions I'd like to make.
The first distinction is between a terminal program and a mail/news
reader.  Terminal access is necessary so that all functions of the
dialup service which are not mail/news can still be accessed.  An
integrated mail/news reader is desirable because this is a primary
activity of many users.  Ideally, you want both.
The second distinction is between stream and file encryption.If you
want to encrypt the underlying channel, you need a stream cipher and a
D-H key exchange.  If you want file encryption, you want a block
cipher and public keys for communications.
These two distinctions are correlated.  The terminal nature of such
software requires support for stream encryption.  The mail nature of
such software requires file encryption.  PGP is a file encryptor, not
a stream encryptor.  You can't use PGP for the terminal line; you can
you it for email.
One useful discussion would be to examine just what hooks are
desirable.  The capability 'encryption' is too broad; one needs to
specify just what variety and what purpose is desired.
Re: dealing with mail software intended for humans.
It is for exactly reasons like this that one of the hooks should be an
ability to specify how one gets one's mail.  For Unix, I would suggest
POP, as Paul Ferguson has mentioned.  For online services like
compuserve, aol, etc., a separate protocol which spoofs their mail
readers into sending you your mail en masse could be written.
This also implies the existence of offline mail readers.
Trying to spoof a whole mail system on a terminal seems doomed.
Offline readers are the way to go.
What editor you use is another hook.  I use Desqview, and I love to be
able to spoof Desqview into spoofing my editor (which is _always_
running) into editing my reply.  So the hook has to be a bit more
flexible that running an executable.

@_date: 1993-06-03 08:57:13
@_author: Eric Hughes 
@_subject: Software infrastructure 
Agreed.  The less hassle, the more use.
Buzzword alert.  What is "TPU"?  And who makes "Async Pro", and what
exactly does that do?

@_date: 1993-06-03 08:57:21
@_author: Eric Hughes 
@_subject: CryptoStacker, long term vision 
A related topic to encrypted disk drives.  Anybody who has a desire to
see their data around long term makes backups of their drives.  At
one of these backups is usually physically near the drive in
What good it is to have an encrypted disk if the backups are not also
Backups occur at the file system level, where an encrypted file system
does not appear encrypted, so that work here does not directly
leverage to encrypted backups.

@_date: 1993-06-03 08:57:38
@_author: Eric Hughes 
@_subject: CryptoStacker, long term vision 
If you want help, it is wise not to recklessly insult those who are
offering it.  By your own admission, you do not have a lot of
experience here; you seem to be saying "I know exactly what I don't
know," which, may I add, is a common delusion of the inexperienced.
You seem to have fixed a model of how the encrypted disk would work
and don't want to debate it.  The model is exactly that which requires
the most scrutiny, because it has the most far reaching effects.  If
the model is flawed somehow, that's what you want to know before you
begin, not six months later.
I take it that you want people to use this software after it is
written.  if so, then pay close attention to user acceptance issues
such as performance and key handling.  You neglect them at your own
Your model seems to be that of intercepting interrupts to the disk.
This could be made to work, but is the wrong way to do it.  If you
insist on that, though, any good PC reference book will tell you what
the disk interrupt vector in the BIOS is.  Ralf Brown's interrupt list
also contains the relevant data in schematic form.
The proper way to do this is as a device driver, however.  Grabbing
interrupts is messy and prone to interference.  Many anti-virus
programs monitor the disk interrupt to make sure that nobody uses it
unauthorized.  A device driver is the intended way to create new
devices, like an encrypted disk.  There are complete books about
writing device drivers; you will need one of these or some other good
DOS programming book which explains how to write one.  There are
lots of subtleties about them.
I would suggest that you first version just be a device driver that
has no encryption, but only the hook for it.  The device driver
skeleton for a disk will be difficult enough, as you have to support a
whole lot of operations just so you can have a place to put the
encryption.  This is exactly the software infrastructure problem in
another context.
After you have a device driver skeleton working, you can add both
hardware and software encryption modules.  There is no need to be
exclusive about this.  It is clear to me from your comments that you
haven't timed any DES routines and done a calculation of increased
latency times, and although I hate to see code development go to
waste, it's your time, not mine.
As far as picking an encryption algorithm, use DES.  DES is the
fastest symmetric keyed block cipher that is thought to be reasonably
secure.  DES is not particularly fast in software; it was designed as
a hardware standard and does lots of bit manipulations.  DES is fast
enough for serial communications, but that 1000 times less the
bandwidth than a hard disk.
Of course, you don't want to run DES in codebook (aka naive) mode.
(Codebook mode is where you just simply map block to block; the
problem is that identical blocks map to identical blocks.)  You'll
want some sort of other mode, like a counter mode, to make sure you
don't get identical ciphertexts.  It is also a bad idea to encrypt the
whole disk with one key; it makes brute force searches much easier.
Your keying material should be long.  I earlier suggested one key per
track.  These keys are going to have to be stored somewhere, and the
disk is the wrong place for it, clearly.  This implies that the user
is going to have to have some key-holding device (likely a diskette)
which will be necessary in order to unlock the partition.  the keying
material should be password protected.  This device will be have to
used at boot time if anything necessary to boot is stored on the
encrypted partition.
Keying material will need to be backed up.  This should be made as
painless as possible, otherwise there will be plenty of people losing
whole drives.
Keys in the driver should time out after some specifiable period.
Files that are open when the time-out occurs and the programs that
have them open are going to have to be dealt with gracefully.
This model of using a device driver means that there is going to have
to be at least two partitions on the disk: one to boot from, and one
to be encrypted.  The device driver itself and the operating system
can't be on the encrypted disk, because those components must be
loaded before the encrypted disk is accessible.  Most people are not
going to go out and buy a new disk to be the encrypted partition.
Thus, this is going to mean a full backup of the existing disk, an
operation with FDISK to do the partitioning, then, assuming the driver
works right the first time, restoring everything else on the encrypted
partition.  What is the effect of _this_ on user acceptance?

@_date: 1993-06-03 18:05:09
@_author: Eric Hughes 
@_subject: Hardware vs software 
I wasn't saying that DES was the fastest of all possible secure
ciphers.  I was saying that DES is the fastest of all ciphers which
are widely believed to be secure.  This aspect of security is
moderated by the key length of DES, which is too short to be secure
against a well-funded opponent at present, but which is perfectly
adequate for other purposes.

@_date: 1993-06-03 18:10:18
@_author: Eric Hughes 
@_subject: snake oil 
Post away.  If you upload a copy of the source to the directory
pub/cypherpunks/incoming on the ftp site, I'll make it available to
I would like to see this regardless of whether it actually is secure.
It is a well-founded maxim that no one should design a cipher without
having broken a few first.  There is a need, apropos of training the
desginers, for insecure ciphers, not so they can be deployed, but so
that other insecure ciphers will not be.

@_date: 1993-06-03 18:25:05
@_author: Eric Hughes 
@_subject: Clipper on CNN HN 
It is likely that this is a new clip rather than the old one.  There
is a large class of stories for which the print media drive the
televisual.  See _Bad Day at Black Rock_ for a first hand account of
this.  The CBS News staff read the New York Times every morning to
figure out what to cover.  In all likelihood they've just picked up
the story from Newsweek, slant and all.
It is because of mechanisms such as these that it is vital that people
get out there and start talking to local press, of whatever kind.  The
media predate on each other's research.  Getting the story out
_anywhere_ is useful, because it will frequently trigger more
coverage, and we desire the escalation of coverage.
We must make ourselves heard widely because if we can bring the
wiretap chip to public debate, we will have won.  The languor of
apathy creates a veil of secrecy for the public equally as effective
as lies and denials.  If we can get enough press coverage about this,
it will become an "issue".  One of the best things we could hope for
is that "Nightline" will have Ray Kammer v. Whit Diffie.  Public
opinion will not sit well with making it illegal to keep secrets.
Phone calls to CNN, asking for explanations of that short story will
help, hint, hint.

@_date: 1993-06-03 18:58:26
@_author: Eric Hughes 
@_subject: Work the work! 
Preempt government restrictions by fighting for the explicit right to
strong cryptography.  Point out how those foolish folks south are
going to screw themselves over by government mandated cryptography.
One of the arguments that is being made in this country against the
wiretap chip is that it will harm overseas business.  In Canada you
can turn this around and show what a great economic boon you have
available.  You can point out that the US has abandoned their foreign
markets in secure communications, which will, of course, be the only
kind of communications of the future.
Get Northern Telecom on your side.

@_date: 1993-06-03 22:17:48
@_author: Eric Hughes 
@_subject: CryptoStacker, long term vision 
There need not be a single method used.  This is the whole point of
making a system with hooks--hooks for encryption, hooks for key
management, hooks for drive control.  Not only does this make for more
flexible software, but its effect on modularity is striking.
One requirement of any keying method, however, is that the keys be
physically removable from the locale of the machine.  That nixes a
couple of the suggestions you mentioned.  Any keying material for the
volume of data represented by a hard disk will be longer than human
memory or tolerance of delay.
In an encrypted telecommunications system, the keys should be changed
frequently.  This is not necessary in the case of encrypted disks.
You will know when your drive has been compromised; it won't be there
any more.  Unlike telecommunications, where one assumes that the
eavesdropper has access to all of the data flow at all times, an
encrypted hard disk gets looked at once.
Of the two remaining solutions on the list, PCMCIA and floppy, there
is no reason to chose one over the other.  Properly modular software
should be able to support both.  Floppies will come first because
there's no new hardware, but I personally would be much more
comfortable using the more robust medium of EEPROM on a removable
The suggestion to use the MSDOS network redirector is also worth
heeding.  The CD extensions, for example, use it even though that
drive is sitting right there in the machine.  Using the redirector
would allow one to support both separate partitioning and filesystem
within a file.  Here's another case where modularity wins.  Many
people may only need a bit of encrypted data, and a one or two Mb file
might do it for them.  (Sector remapping, BTW, is no big deal.)
Again, you don't have to do both at the outset.
re: choosing DES for the cipher
Yes and no.
Yes, at first.
I remain to be convinced that software encryption of any kind is
feasible for efficient bulk hard disk encryption.  To be sure, there
will always be the need for less efficient but secure storage.  As I
said in another posting, DES is the fastest trusted symmetric keyed
block cipher around.
I do not think you are stupid for trying DES.  I _will_ think you are
stupid, however, if you go ahead and implement it without first doing
some estimates on the amount of time it will take and the effect on
disk performance and latency.  It is planning I am talking about here,
not any particular final decision.
You should allow hooks in the system for different block ciphers.  If
you do this, then some sort of algorithm byte should be present in the
partition information.
Single and multiple DES are still block operations.  Codebook and
counter modes refer to ways that block ciphers may be used; they are
not specific to DES.
Re: large amounts of keying material
There are two lengths here, do not confuse them.  The first is the
length of the key to the block cipher.  The second is the total length
of all such keys in aggregate.  The first length is not directly
relevant; it is the speed of the cipher which it keys that is.  For
simple iterated DES, however, these coincide.  Single DES takes one
third as long as triple DES.
As far as aggregate length goes, the only time here is for one array
indirection, which is miniscule in comparison to the encryption time.
For a standalone machine, this is not a concern.  For a networked
machine, one may simply consider that all of memory is available to an
intruder.  No memory protection is available.  There is no way around
such a fundamental limitation other than hardware.  Therefore, don't
worry about it, and inform the user of the issue.
As I did not mention previously, this is an extremely difficult
problem in DOS.
No good.  I use Desqview, which multitasks the machine.  There's good
reason not to require single tasking for this project.  Many TSR do
effective multitasking already.
This is a really sticky problem.  The criterion here is that programs
with open files whould still be able to access them, and possibly even
to write to them.  No other access would be permitted.  This requires
abstraction at the file system level, not the device level, and thus
would require mixing abstraction levels.  Ick.
The logging file systems mentioned in the context of Unix are what is
needed here, because the recent activity need not be encrypted.
If graceful shutdown cannot be achieved, there will still be times
when ungraceful shutdown will be useful.  One should not judge in
advance another's relative values of information compromise and a
slightly corrupted disk.  At the very least, there should exist a
program to zero out the keying material.
Re: conversion from non-encrypted to encrypted
That's fine, but that program is going to have to get written as well,
and it's going to have to be as reliable as a disk optimization
program.  After each sector write the disk is going to have to be in a
stable configuration, so if power fails at that moment, all is not
lost.  This will not be easy, since you'll be dinking with the
partition table all the time.
If you can get such a thing working, it would enormously increase the
actual usage of the encrypted disk drivers.  It is an elegant idea,
but a difficult one to implement.

@_date: 1993-06-03 22:25:56
@_author: Eric Hughes 
@_subject: Software infrastructure 
Reliability.  Scripts do not easily handle error conditions that might
result in lost mail.  They're fine for a few, but they aren't for all.
Integration.  Remembering what to do next is a large hurdle.

@_date: 1993-06-03 22:41:55
@_author: Eric Hughes 
@_subject: Term software develo 
What are NASI/NCSI?  Does it cost to use them?  Is source available?

@_date: 1993-06-04 06:54:47
@_author: Eric Hughes 
@_subject: CryptoStacker, long term vision 
The nature of crypto software is that is valueless unless you trust
it.  You don't have to trust a word processor, because you can see
immediately that what you typed on the screen comes out the printer.
For security software, however, breaches are invisible, or more
precisely visible only after the damage has been done.
This is the reason that I disregard DISKREET from Norton.  There's no
source, and largish companies are notorious for pushing compromised
software.  Norton's unlikely to ship source, so unless someone
decompiles it, I'm not biting.
You need to do a bit of research into what a block device driver
actually does.  It deals only with blocks of characters, not with
individual ones or arbitrary length strings.  The block interface at
the driver level is different than the file access at the API level.
Don't confuse the two levels.  DOS already does the buffering required
to turn a block device into a file system.  You don't need to
replicate it.
As a result, the cipher you choose needs to be a block cipher.  DES
works on blocks of 8 bytes at a time.  A typical sector is 512 bytes.
So you are going to have 32 DES (or iterated DES) operations per
Again, at the driver level, you don't know that a FAT even exists.
Ray Duncan's book _Advanced MSDOS Programming_ contains a good chapter
on device drivers.  You should be able to find code for a skeleton
block device driver on the net; check the msdos programming groups for
more info.
I would also suggest that you find programming partners.  If for no
other reason than to do code review, someone else ought to be
involved.  You wouldn't want to make the group too large, but three or
four is not overlarge.  The archive at soda is available for group
work, if desired.

@_date: 1993-06-04 10:50:04
@_author: Eric Hughes 
@_subject: Software infrastructure 
This is a huge hurdle for people who don't own their own machines and
haven't convinced a sympathetic sysadmin to do the configuration.
A solution that works from a dialup login account can still be a batch
solution and should require no extra involvement from the sysadmins.

@_date: 1993-06-04 13:14:34
@_author: Eric Hughes 
@_subject: Lobbying for Cryptoprivacy, non-U.S. 
The point Dean makes is important.  You want a positive right for
individuals to use cryptography in any form, not just a 'negative
right' which restricts government from creating key registration
requirements.  Such a positive right will _a fortiori_ exclude key
escrow systems, and that's what you want.  You want to make sure that
all _restrictions_ on cryptography are disallowed, that there are no
_restricted_ forms of cryptography.  The point is subtle, but
profound.  Both techniques get rid of key registration, but one is a
restriction on cryptography and the other is not.
There is another point to remember about constitutional democracies.
That which the legislature may do, the legislature may also undo.  The
level at which the prohibition against cryptography restrictions is
appropriate is at the constitutional level.  A constitutional
provision binds the government; lesser solutions are less effective,
even when they should be sought out as intermediaries.
At the first CFP conference, Lawrence Tribe made this point extremely
well, that the fundamental right of citizens should be invariant to

@_date: 1993-06-06 11:58:21
@_author: Eric Hughes 
@_subject: random access into an encrypted file? 
The model that has been most discussed recently has been that of
encrypting sectors on the hard disk.  In order to have random access
to files, you have to have random access to sectors.  Therefore, the
encryption mechanism chosen must support random sector access.
This is not difficult, but many of the techniques used for
telecommunication encryption do not work.  In particular, encryption
modes that depend upon some previous state of the encryption machine
do not work well.
Cipher block chaining is a mode of operation for block ciphers that
where the plaintext is xor'd with the previous block of ciphertext
before encryption.  The first block of plaintext, where there is no
previous block, is xor'd with an initial vector, which may be
considered part of the keying material.  Now consider what would
happen if you encrypted your whole disk in CBC mode.  You'd have to
start at the beginning of the disk and decrypt up to the point that
you want to read.  For a bit stream, this is fine, since one is
decrypting the whole thing.
CBC, however, is useful for doing sector encryption.  A DES block is 8
bytes, a sector is typically 512.  I assume here that one has to read
the whole sector out of memory, although with some very clever and not
obviously worthwhile optimizations one could decrypt on demand.  Now
CBC is a reasonable choice ifor in-sector encryption, because you have
to read the whole thing anyway.
Yet CBC requiress an initial vector.  This is where counter mode come
in.  A good block cipher has what is called the avalanche property,
which says that altering any bit of the input alters on average half
of the bits of the output.  (Note: if it altered more than half, the
1's-complement would change by less than half.)  Thus the initial
vectors do not need to change particularly much from one initial
vector to the next.  Hence an integer-valued counter works fine.  For
hard disks the sector number, already present, makes just such a
unique initial vector.
Summary: CBC within sectors, initial vectors provided by the sector
This characterization of keying material works for block ciphers
generally and yields a clean abstraction for the rest of the system.
The rest of the encryption code need only know these values.  Here are
some examples.  Lengths are byte lengths.
Nice and clean.

@_date: 1993-06-07 12:04:02
@_author: Eric Hughes 
@_subject: ALERT: PGP removed from soda archive site 
The ftp site at soda will no longer be able to distribute PGP, I'm
afraid.  It appears that CERT informed someone on campus that
"pirated" software was available on soda.  The word came down, and the
directory has been chown'd root and has had permissions removed.
There will be more later on this.  In the meantime, spread the word.

@_date: 1993-06-07 19:00:03
@_author: Eric Hughes 
@_subject: ALERT: PGP now back on soda 
You can stop spreading the word now.  PGP is back on soda.  Remember,
it is my analysis that soda is still able to distribute PGP because we
keep a low profile.  Please keep it that way.  You can find pgp with
archie, so I don't feel the need to advertise.
Lots of stuff happened today after I posted my initial announcement
that PGP had gone offline.  Because of the intervention of Eric
Hollander with the folks who are in charge of the machine,
reasonableness has prevailed.  What happened in a nutshell was the
following.  Person A, a fascist asshole by all accounts, simply turned
off the PGP directory without telling me.  I started getting questions
by email from folks trying to get PGP.  Person A's argument was that
PGP was illegal, therefore soda should not distribute it.  Eric
Hollander, after some initial rounds, played trump and observed that
the machine had been recompiled without the user limit that had been
part of the OS license agreement, and recommended that soda be shut
down immediately because the kernel that soda was running was contrary
to the license agreement.  Very quickly the president of the
organization which runs soda intervened and everything was OK.
What is still troubling to me is the nastygram that came down from
CERT.  We don't know how they were informed, nor what their policy is
on this.  I'll have another message on that angle later.

@_date: 1993-06-08 08:18:49
@_author: Eric Hughes 
@_subject: a great revelation from the bowels of NSA 
I think this neither ominous nor foreboding.  This statement was
apparent within a week or so of the original announcement.  The only
thing new about it is that it confirms what I've thought for over a
month: that the executive branch is trying to do an end run around the
I was quite happy to see this, since now we can argue from this
position not on the basis of surmise, but of quotation.  This single
quotation will be enormously useful in getting the legislature to take
specific and bill-oriented action about the wiretap chips.  In the
checks and balance system, the legislature makes laws; the executive
makes them happen.  The executive is not supposed to go charging off
and making de facto legislation.
I would recommend that this quotation be spread far and wide.  Put it
in .signature blocks.  Call for a return of the checks and balances
system of government.

@_date: 1993-06-08 08:27:34
@_author: Eric Hughes 
@_subject: CryptoStacker 
I've made available the following files on the archive site:
in the directory pub/cypherpunks/applications/crypto.msdos.disk.

@_date: 1993-06-08 08:36:25
@_author: Eric Hughes 
@_subject: ADMIN: upload ettiquette to the cypherpunks ftp site 
There are a few matters of upload ettiquette for the ftp site.
1.  Upload stuff for cypherpunks to pub/cypherpunks/incoming/ and not
to the general pub/incoming/ directory.  I'll be able to more
adequately handle files there.  (I can't erase in the other directory.)
2.  Whenever you upload something, also upload a short description of
what it is you are uploading.  I've got a few mystery files there that
are on the low priority end of things, since I don't know what they
are and I've got plenty of other stuff to do with the archive.
3.  Send me mail telling me what you've put up.  I don't have any
automated software to look at the incoming directory, and so I may not
notice.  My address is below.
4.  Don't bother uploading programs that don't have source code.  The
mission of the archive site is education.  Software distribution is
not a purpose, and software without source does not satisfy the
educational criterion.
Eric Hughes
cypherpunks ftp site maintainer
hughes at soda.berkeley.edu

@_date: 1993-06-08 09:24:11
@_author: Eric Hughes 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
Here, in its almost full glory, is the letter that CERT sent to the
admin at berkeley.  I've removed the addressee, since there's no need
to involve that person.  I have not, however, removed the name of the
Don't you just love that phrase "illegal trading of commercial

@_date: 1993-06-08 09:33:10
@_author: Eric Hughes 
@_subject: Getting on CERT's "Most Dangerous" List 
I would propose that we get the FBI to fund CERT's law enforcement
mission, rather that the DoD.

@_date: 1993-06-08 10:09:17
@_author: Eric Hughes 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
There is only one directory on the cypherpunks site that is writable,
and that is the incoming directory and it's not readable.
I still don't know what the real accusation is.  CERT is straight out
of a Kafka novel in this regard.  Maybe it's PGP, maybe it isn't, but
they don't seem to be offering that information.

@_date: 1993-06-08 12:30:12
@_author: Eric Hughes 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
The issues that Steve raises are   1.  use of ftp sites counter to the knowledge or desires of their owners
    a. for one time transmission
    b. for illicit archive
  2.  distribution of software contrary to the author's desires
  3.  abuse leading to shutdown of archives
I do not wish to quarrel with these issues.  The question is not one
of the ethicality of these actions, but of the relationship that CERT
should have to such actions.
CERT's mission is computer security, not copyright enforcement.  What
the letter offers is hearsay that illegal activity is taking place on
a particular machine in a particular place.  Such a letter might
properly be construed as slander, since there was no effort made to
verify the accuracy of this information and the letter even says this
What CERT might properly do is first, verify that an ftp site is
running.  Julf's case where the ftp daemon was not even enabled is a
particularly egregious case in point.  Next they should verify that
the permissions on the directories in question are set so that world
read/write access is available.  They could also do a tree search of
the directories and look for suspiciously named directories.  All
these actions can be automated; there is little excuse for making not
even the most cursory check.
In any case, CERT's response should be limited to issues of computer
security and not law enforcement.  They might properly notify an
archive owner that illegal activity has been known to take place on
archives configured in such a way, but to spread hearsay is
irresponsible.  Unfounded allegations of illegal activiy are socially dangerous,
especially when promulgated by a respected institution.  In the
fifties in the US in a similar context this was called "red-baiting".
Now if CERT receives reports about the improper distribution of
software and the archive site is properly set up, one might reasonably
assume collusion on behalf of the maintainers of the archive.  In this
case direct investigation should take place by properly authorized law
enforcement authorities.  CERT is not so authorized to my knowledge,
and as it is funded with military money it would be a bad policy to
give it a law enforcement function.  The FBI is responsible for
copyright enforcement in this country, and they are the proper ones to
do an investigation.

@_date: 1993-06-09 06:57:57
@_author: Eric Hughes 
@_subject: a "great" NSA revelation 
Protecting cryptography must be fought on all fronts.  If we disregard
the legislature, we will lose.  Period.
The Constitution is the highest law of the land.  As you may recall,
it was ratified by state legislatures.

@_date: 1993-06-09 07:31:36
@_author: Eric Hughes 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
The first CERT letter was sent to a contact for the berkeley.edu
domain, not to soda.  This original recipient then forwarded the mail
to root at soda, which is aliased to a number of people.  The root who
turned off the directory is not the same one who finally forwarded me
the CERT letter.
In short, they went over Julf's head, and they went over mine.

@_date: 1993-06-09 08:04:45
@_author: Eric Hughes 
@_subject: CERT: the letter from CERT to berkeley.edu admin 
Before the rumor flies to far, soda was not closed down.  One
directory on the cypherpunks site was locked for less than a week.
Had it not been for the intervention of a good friend who is also root
on soda to do local politics, that directory might still be locked.
The consequences could have been worse.

@_date: 1993-06-10 10:13:52
@_author: Eric Hughes 
@_subject: Encrypting the list 
Summary: Encrypting the cypherpunks list make no difference in the
security of information dispersal, but may make a large difference in
local security and as a spur to software development.
Michael, here is a word from your friendly neighborhood list
maintainer.  I don't have time to work on this, and neither to the
people who run toad.com.  So it's not going to happen on toad for a
The good news is that it doesn't have to.  You yourself can write the
code!  The code for the existing cypherpunks remailer is all you need
to get started.  Here's how.  You subscribe to cypherpunks and then
forward the list mail, encrypted, to all the people who have
subscribed with you for an encrypted version of the cypherpunks mail.
With the cypherpunks remailer, you can do all this with your own
account.  It is a pretty good skeleton for the creation of email
servers out of user accounts.  You don't need your sysadmin's
cooperation to get it running, although you may need their blessing to
keep it running.
You can implement a listserv type operation if you want, with
automatic subscribe/unsubscribe and add all the options you want to
it.  You'll have to deal with the bounce messages, of course, but you
can rwrite software to deal with that.
Someone who wants to provide digest service can to a similar thing for
There have been lots of people over the course of the list history who
have wanted encryption and digests.  I would suggest that those who
want them convince someone to run a secondary service to provide them
with these services.

@_date: 1993-06-10 18:52:12
@_author: Eric Hughes 
@_subject: cypherpunks physical meeting 
Cypherpunks Meeting
Saturday, June 12, 1993
12:00 noon - 6:00 p.m.
Cygnus Support offices, Mt. View, CA
I've really got to get some automated software running for posting
these announcements.  I apologize, again, for the untimeliness of this
message.  This time there will be a reporter from the BBC attending, not to
film, but to talk to people about electronic culture in the Bay Area.
We will also have some other visitors, I believe.
  1.  Clipper, of course.  The CPSR Crypto Policy meeting was earlier
this week, as well as the Markey hearings.  We will have reports on
  2.  Software development.  Mail, links, disks.  It is time to make
an overall plan for the architecture of encrypted life.  I want to
brainstorm to make sure we come up with a complete list.
  3.  Crypto '93 attendance
  4.  Other, as usual.

@_date: 1993-06-11 08:26:58
@_author: Eric Hughes 
@_subject: MAIL: logging that happens on soda 
I was rooting around soda for some other reason and stumbled upon the
mail logs (!) for soda.  I just sent myself some mail to generate a
sample entry.  It's got complete traffic analysis data, complete with
to/from pairs, time of day, and message size.
Jun 11 08:13:35 soda sendmail[11298]: AA11298: message-id=<9306111513.AA11298 at soda.berkeley.edu>
Jun 11 08:13:35 soda sendmail[11298]: AA11298: from=hughes, size=66, class=0, received from local
Jun 11 08:13:36 soda sendmail[11300]: AA11298: to=hughes, delay=00:00:01, stat=Sent
I would recommend that all remailer operators find out what kind of
mail logging, if any, takes place on their machines.  If you need a
place to start looking, the mail log on soda was in the same directory
as the syslog messages.
I would also recommend that this information on mail logging by the
system be put in Karl's remailer list.

@_date: 1993-06-11 11:05:40
@_author: Eric Hughes 
@_subject: MAIL: logging that happens on soda 
Re: sendmail logs
I have opened my mouth and removed all doubt.  I _am_ mostly
illiterate in the details of Unix; this is one system administration
detail I did not know.  I have known for a long time that these logs
were in principle easy for administration to keep, but I did not know
that they were an entirely standard feature.
I raise this because it affects perceived remailer security and I have
not once heard these specific logs brought up, on the list or in person.

@_date: 1993-06-11 18:00:51
@_author: Eric Hughes 
@_subject: Mail logging 
Well said.
If you externally observe a remailer, there are three basic items to
correlate incoming to outgoing with: body content, body length, and
redelivery latency.  Notice that items two and three are provided by
the mail logs on my machine.  A remailer which is a mix needs to
confuse all three.
The first, content, requires an encryption or decryption operation.
The second, length, requires length quantization and therefore padding
and packeting.  The last, latency, is only solved by random delays if
the traffic through the node stays above a certain threshold.  The
real important characteristic with latency is reordering the incoming
and outgoing messages.  The simplest way to do this is to accumulate N
messages, create a random permutation on N elements, and mail the
messages out in the permuted order.
The single most basic problem with mail development that we have is
that we don't have enough mail volume through the remailers we have in
order to be able to experiment with better systems.  In particular, we
need to examine other reordering algorithms for the case where volume
is low and delivery latencies would be too high with the simple
gather-and-permute algorithm.

@_date: 1993-06-13 07:40:57
@_author: Eric Hughes 
@_subject: what happens when you reply to nobody@cicada.berkeley.edu ? 
The name 'nobody' is frequently aliased to /dev/null, i.e. the bit
bucket.  I cannot speak for cicada in particular.  When I wrote the
first of these remailers, I remailed from nobody because it was the

@_date: 1993-06-13 08:14:53
@_author: Eric Hughes 
@_subject: Mail logging 
No.  toad.com is overloaded as it is.  It's slow as molasses already,
and adding any encryption at all to cypherpunks would make it even
worse.  Even forking a process per user would be way to much.
As I said before, any experimentation that people want to do with list
distribution can be done by hacking the current remailer code.  You
don't have to have any sysadmin privileges to do this.  You don't even
have to have my permission to do this.

@_date: 1993-06-14 07:36:03
@_author: Eric Hughes 
@_subject: request for patent info 
As much as we need this, we also need the actual text of the patents.
What a patent actually covers is often much narrower than what is
The experience of others trying to gather such information as this is
that you have to be proactive if you expect to get anything done.
Waiting for people to send you stuff is an exercise in patience.

@_date: 1993-06-14 07:47:25
@_author: Eric Hughes 
@_subject: digital cash 
I had a talk with a fellow named Joichi Ito at CFP about this subject.
He's a total MUD addict and told me, "I would pay real money for MUD
The legal issues involved in setting up a real world money system are
enormous.  Doing a game environment implementation would allow the
technical issues to be worked out without having to hire lawyers.  And
if some people transact for real money, we can't help that.
For MUD's in particular, there's a problem with conservation of mass,
er, gold.  It's really easy to create more MUD money.  However, if
there were a currency exchange system available between MUD's, you
would have a classical free banking environment.  Everyone issues
currency, and as gamemaster your money deflates to the extent that you
allow more gold to exist in your game.  I can't think of a better way
to get people to learn about monetary effects in macroeconomics.
I also spoke with Pavel Curtis at CFP, but only enough to interest him
in talking further.  Pavel runs the largest MUD on the planet.

@_date: 1993-06-15 09:04:47
@_author: Eric Hughes 
@_subject: request for patent info 
The main rationale behind granting patent monopoly is for the
disclosure of the technique to the public.  As such, patents are
public record.  There is no danger of violating copyright by
publishing patents, already public information.
Here is RSADSI's patent portfolio:
Public Key Cryptographic Apparatus and Method
("Hellman-Merkle")		No. 4,315,552
Exponential Cryptographic Apparatus and Method
("Hellman-Pohlig")		No. 4,434,414
Cryptographic Apparatus and Method ("Diffie-Hellman")		No. 4,200,770
Cryptographic Communications System and Method ("Rivest-Shamir-Adelman")	No. 4,405,829
Method For Identifying Subscribers And For Generating And Verifying
Electronic Signatures In A Data Exchange System
("Schnorr")			No. 4,995,082
In my own opinion, the RSA and DH patents are relatively strong, given
that they cover particular algorithms and not whole classes of
techniques.  The key word here is relative; they might not hold
themselves, but they are certainly much more likely to hold that some
of their others.
PKP makes the following statement.  This is right out of RFC-1421, one
of the Privacy Enhanced Mail (PEM) documents.
   "These patents are stated by PKP to cover all known methods of
   practicing the art of Public Key encryption, including the variations
   collectively known as El Gamal."
It is my opinion that this statement is false, and not only false, but
an improper extension of patent monopoly.
The weakest link is the Hellman-Merkle patent, which PKP uses to claim
all public key cryptography.  Public key cryptography as such is
certainly not patentable, since it is merely a collection of
characteristics of specific systems; public key cryptography is not a
specific process or method, but a collection of such processes and
methods.  Only specifics are patentable.  Public key cryptography is
an idea, and ideas are not patentable.
The next weakest link is the Hellman-Pohlig patent, which is, I
believe, that which PKP uses to claim that all uses of the discrete
log problem (e.g. El-Gamal) are also covered.  Here again, the use of
an item without reference to a specific process or machine is not
patentable.  The specific use of exponentiation in the H-P patent is
for an RSA pseudofield (i.e. mod pq), but with exponent two.
As such, if we are going to prioritize patents, I would gather them in
the order indicated.  As far as doing forward references, The H-M
patent is likely the most interesting, since it will lead to many
other patent public key ciphers.  The RSA patent is likely the next,
because it is so widely known and mathematically simple.

@_date: 1993-06-15 10:02:24
@_author: Eric Hughes 
@_subject: request for patent info 
Do they have electronic access at this library, or is it paper only?
I know they have a fax service for which they charge, but is there
downloadable text available?
As much as we need the text of the patents, we also need to gather
them in electronic form.  I thank those who have offered to do so.

@_date: 1993-06-15 10:16:12
@_author: Eric Hughes 
@_subject: REMAIL: X-Discard header line added 
The cypherpunks remailers use a little invention called 'header
pasting' where header fields may be added into the header after
receipt but before processing.  These pasted header fields may in
addition be put inside encryption wrappers, thus hiding them from the
outside world.  'Discard' headers may use this technique.

@_date: 1993-06-17 08:32:17
@_author: Eric Hughes 
@_subject: fast des 
If you know that your plaintext is 7-bit ASCII, then you can reject if
you see too many 8th bits set.  Assuming that the size of your
intercepted ciphertexts is generous, say ten blocks, then the
likelihood of a false decryption which has all the 8th bits off is
extremely small.  Hint for implementors: don't allow such easy bit
correlations in your plaintext.
In any case, the point of a DES cracker is to reduce the size of the
space of probable decryptions, so that more computationally expensive
statistical tests of possible plaintexts may be performed on a shorter
list.  If your cracker can reduce the size of the probable keyspace by
eight bits, then you can run, in parallel, tests which take 2^8 times
as long.  For example, you may be able to reject many potential
plaintexts from a CBC ciphertext stream after the first block; longer
tests would look at a longer stream.
This is where measures of n-gram distribution really come into their
own.  These measures can distinguish between text types extremely
finely, but are often expensive.  Nevertheless, they are highly suited
to automation, particularly to distinguish between different languages
and to recognize non-linguistic forms such as protocol encapsulations,
object code, and compressed text.

@_date: 1993-06-17 18:06:27
@_author: Eric Hughes 
@_subject: fast des 
The question is just how hard is "really darn hard"?
Compressed English text has characteristic patterns just as plain
English does.  The salient difference is that these patterns take
longer to emerge at the same confidence level.  The compressibility
limit is a limit not usually reached; the difference between that
limit and the actual compressed text will be non-zero.  This
difference manifests itself in patterns in the compressed text.
Some estimates of this size are necessary in order that the designer
have an assurance that automatic recognition of decrypted text is
These concerns are largely obviated by using ciphers with longer key
lengths, of course.

@_date: 1993-06-18 08:44:38
@_author: Eric Hughes 
@_subject: fast des 
Here are a few assumptions that lower this estimate for the NSA.

@_date: 1993-03-01 08:07:18
@_author: Eric Hughes 
@_subject: anon.penet.fi hacking 
OK.  It's a mess.  The backslash means line continuance.  Remember that
concatenation binds higher that alternation (|).
^--...([^B]|B[^E]|BE[^G]|BEG[^I]|BEGI[^N]|BEGIN[^ ]|BEGIN [^P]|BEGIN P[^G]\

@_date: 1993-03-01 09:45:32
@_author: Eric Hughes 
@_subject: anon.penet.fi hacking 
Julf challenged:
I posted something which didn't quite work, as Julf says:
^--(|.|..|...(|[^B]|B[^E]|BE[^G]|BEG[^I]|BEGI[^N]|BEGIN[^ ]|BEGIN [^P]\
Some implementations don't support empty alternation, so that could be
changed with the ? syntax, since (|a) and (a?) are the same.
That should do it.

@_date: 1993-03-01 12:01:37
@_author: Eric Hughes 
@_subject: more ideas on anonymity 
"How much reputation has an anonymous source?"
I think this might be key to solving the "anonymous libel" problem.
Simply declare "anonymous libel" an oxymoron!  We might argue that
otherwise libelous statements, when made anonymously, carry a
presumption of falsity, for otherwise the speaker would be willing to
speak truthfully in his or her own person.
Or, in other words, "Coward! He must be lying!"
Could some of the folks with LEXIS or WESTLAW access check and see if
there is any case law where the social status of the speaker is
brought into question?
Perhaps Tony Kidson could tell us some of the effects of libel law in
the UK.  The US law, which grew out of British law, seems to have gone
in the direction of reducing the power of a libel complaint, while
British law has done the opposite.  I can't speak for the UK, but
those who live there could.
In California, a very promising decision occurred last week: the first
test of the anti-SLAPP law (Strategic Lawsuit Against Public
Participation).  The law is to prevent lawsuits designed to drain the
resources of those exercising their First Amendment rights.  It
requires the plaintiff to show that they will probably win (I don't
know what the wording of the actual test is).  Defendants are entitled
to recover attorney's fees and court costs.
The suit was basically as follows.  One comic book company published a
Lensman comic.  The heir to the Lensman rights stated in print that
this company had not received permission.  The comic book company sued
the heir and the publisher of her words, claiming libel.  The case was
immediately dismissed based on the new anti-SLAPP law.
The law is designed to protect First Amendment rights, but it looks
like it will also have the salutatory effect of reducing libel claims

@_date: 1993-03-01 17:47:45
@_author: Eric Hughes 
@_subject: Future of anonymity (short-term vs. long-term) 
Re: authenticated news software
Why is there a presumption that any such authenticated news software
would be used without license?  RSADSI is not trying to sit on their
patents, but to make money from them.  What you believe to be real and what I believe to be real may be
different.  To claim that another is being unrealistic is to mask
what is foremost a difference in belief.
What assumptions here do you disagree with?  If you are explicit,
perhaps we can forge an agreement.

@_date: 1993-03-01 18:41:36
@_author: Eric Hughes 
@_subject: cryptographic activism 
Dave Deltorto, in a message to the list last week, was all fired up to
start some real political activism in this country.  More power to
May I suggest publicly, though, Dave, that you broaden your focus?
The US really does work pretty well.  For example, Fourth Amendment
protections agains search and seizure, while eroding in some ways, are
still basically intact.  I do not claim that the US does not have
problems, just that the nature of governmental violence against its
own citizenry is much lower here than in other countries.  Therefore I
suggest that we extend an international hand of cryptographic aid.
I suggest that we start with Singapore.  Singapore is highly
industrialized has a good telecommunications base.  So good, in fact,
that it supports their national payment and identity card system.
Purchases really are tracked and data is filtered to look for unusual
behavior.  The subway and the toll booths all take the payment card.
Singapore is, in many ways, the crypto-anarchist's worst nightmare.
I do not know if the government there has cryptography restrictions,
but I'm sure they will soon, if only as reaction.  So now is the time
for all of you folks to start writing your steganographic
(information-disguising) applications!  They are actually useful here.
I would suggest that interested parties listen in on
soc.culture.singapore for a while, and then carefully broach the
subject about deploying secure communications.
This is about as real-world as it gets, folks.  The need for
cryptography as a tool against oppression is real.  In the US and
Europe we deploy it to prevent oppression in the future, and we must
be grateful that is the future we speak about.  Nevertheless, others
are not so fortunate.  It behooves us to consider them.
Singapore is not the only place in the world this is useful; it is
only my first suggestion.

@_date: 1993-03-02 15:57:42
@_author: Eric Hughes 
@_subject: tapping 
Don't be so dismissive.  There is something interesting going on here,
even if it's not very complex.  This thing works with _shielded_ pair.
With twisted pair to begin with, you largely attenuate the inductive
signal.  (A very short lesson in physics: Current generates magnetic
fields.  Opposite travelling currents generate cancelling fields.
Fields do not completely cancel because the wires are not in exactly
the same place.)  Shielding a twisted pair further attenuates a
It sounds to me like it's an inductive tap with some sort of phase
locking built into it.  By the mentioning networks, it indicates to me
a digital signal.  I doubt this thing would tap a POTS line carrying

@_date: 1993-03-02 16:32:46
@_author: Eric Hughes 
@_subject: Poor Man's Time Release Crypto 
An obvious but very important point about any time release protocol
can be observed in the following one:
   1. Publish some non-random encrypted data.
   2. Wait.
Computational increases will eventually make cracking the code
feasible.  Your secret will be revealed, but you just don't know when!
Technological progress puts an upper bound on the amount of time a
secret can remain secret.  Likewise, Diffie-Hellman is forward secure,
but only until taking discrete logs in the chosen ring is feasible.

@_date: 1993-03-03 09:01:49
@_author: Eric Hughes 
@_subject: more ideas on anonymity 
"Externally verifiable" is the key phrase here.  An anonymous
allegation that Bush and Barb do unspeakable things their bedroom is
much harder to verify than the location of Jimmy Hoffa's bones.
The weekly posting for alt.whistleblower will contain an exhortation
to include such information as can be verified without requiring the
accused party to admit to something.

@_date: 1993-03-03 09:50:26
@_author: Eric Hughes 
@_subject: implementing positive reputation systems 
[emphasis added]
Marc Ringuette's observation about the distinction between content and
volume is relevant here.  The existence of high-volume noise sources
(and let us not call this abuse, merely an undesirable consequence of
the more desirable anonymity) means that you may not be able to get
everything you might be interested in.
Dean suggests filtering at the server.  This just pushes the same
problems with volume onto the server, which does have some benefit.
I too would like to see suggestions.
One of the basic problems with the model for internet news and mail
transport is the presumption that the receiving side will generally
accept everything it is handed.  Rejections of transmission are
treated as exceptions and not as primary elements of the protocols.
In addition, the protocols do not provide, in advance of full
transmission, a way for a receiver to determine whether to receive
based on message size, receiver, or signature.
The two protocols I am specifically referring to are NNTP (RFC-977)
and SMTP (RFC-821).  (For those of you not in the know about RFC's,
that's where all the internet standards are.  ftp to nic.ddn.mil in
directory /rfc.)  SMTP says who the sender is, but doesn't tell you
the length of the message or anything else about it.  NNTP allows you
to receive the header and the body separately, an improvement, but the
header can still be arbitrarily long.  Each of these protocols, at
minimum, should allow the receiver to look at the length of the
message before it receives to see if it will accept that message.
Likewise, sending other characteristics of a message prior to
transmission of the whole would be desirable.  Short messages might
take less time to transmit than to negotiate, so providing length
seems to be the first extension.
It seems that you could implement length notification and rejection by
only changing some of the informational messages, meaning that changes
to the basic protocol and the drastic reworkings of software required
could be alleviated.
Flooding attacks seem important to prevent, and I think that the
underlying protocols should enable this to the extent they can.
The second-most useful thing to add to the server are those functions
which require examination of the entire message body.  I am foremost
thinking of the hash function on top of which a signature is
generated.  Signature checking seems like a proper function for a
server as a common resource.  This is a separate subject.

@_date: 1993-03-03 10:05:26
@_author: Eric Hughes 
@_subject: Handling Abuses of Remailers 
Re: remailer price schedules
While it is not glib, it is also not very useful for planning.
As a general rule of thumb, market minima are set by costs, and market
maxima are sent by alternatives.  Alternatives in this case are
alternate transport means, such as fax and snail mail, alternate
carriers undertaken pseudonymously, e.g. attmail with a fake id, or
free experimental services subsidized by academia and which don't work
quite right.
Costs are easier to calculate.  Cost of a net connection, hardware,
staff (i.e. your own) time, and financial transactions (i.e. Visa
fees).  Make a reasonable assumption that each message takes a certain
amount of time to be processed on a certain class of machine (or
measure it!), call some vendors (i.e. alternet).
My guess on all this is that you could make an awful lot of money at a
dime a hop for a less-than-10K message.  Sell hops only in packages
of a hundred, in order to reduce your finance charges.

@_date: 1993-03-03 10:40:24
@_author: Eric Hughes 
@_subject: Let's look at this .... 
Paul Ferguson asks: "What are cypherpunk priorities?"
Here's my list, in order:
Technical track:
1.  More remailer usage.  You can't start rearranging the order of
incoming and outgoing messages until you have messages to reorder.
Right now routing is still hard, even using a script.  Thus priority 1
implies number 2:
2.  Outgoing rewriting systems integrated into mailers.  Until one can
in their mailer and have this turned into a double-hop, fully
encrypted message on the way out, I don't think you'll see a huge
amount of traffic.
3. Mixing remailers.  Until mailers mix, they are extremely vulnerable
to network monitoring.  Mixing is rearranging the order of incoming
and outgoing messages, with a known lower bound on the number of
messages it could have been rearranged with.  Mixing also requires
message size quantization, since reordering is only significant among
messages of identical length.  Note that this requires a significant
volume of traffic per remailer.  While this is a high priority, its
implementation is not imminent.
4. Positive reputations.  The very simplest reputation is a signature
claiming identity.  Deployment of signature-based communication fora
is the first step.
Political track:
1. Understand the nature of anonymity now and in the future.  We are
trying to improve the world, not just change it.  It is therefore
necessary that we try to the limits our ability to understand the
effects of the social changes.
2. Making our arguments public.  Once we have convinced ourselves, we
have to convince others.  This means public participation in
conferences such as CFP, in the editorial pages of newspapers, in the
IETF meetings, in Usenet newsgroups, and, if necessary, in courts.
And a word of advice: Arguments are more effective the fewer shared
assumptions between the parties there are.  In particular, while you
can convice another libertarian with a libertarian argument, you can't
convince a socialist with one.  Nevertheless, both libertarians and
socialists desire open societies and personal privacy.  We must base
our arguments on deep shared culture if they are going to succeed.
3. Going international.  There do and will exist national restrictions
on various and different aspects of privacy goals.  One can go around
many of these restrictions by going around the nation involved.
Knowledge is extremely difficult to contain, so let us make more of
it, everywhere in the world!
4. Fighting restrictions on cryptography.  In the US, that means
getting actively engaged in fighting key registration ideas.  This
means preemptively writing your elected leaders _in advance_ of a
specific issue.  It also means writing about export restrictions in
cryptography.  In France, that means raising public awareness on
cryptography restrictions and the eventual effects that will have on
the open society there.  In all countries, it requires vigilance.
5. Increasing awareness of privacy issues.  Most think they have
nothing to hide.  Most also hate it when they get extremely detailed
junk mail about their own lives.  Teach the defense of privacy.

@_date: 1993-03-03 11:42:43
@_author: Eric Hughes 
@_subject: You Aren't [I'm Not] 
I do not think this is an entirely forthright self-assessment.
Let me call that strong anonymity.  Let me also call the possibility
for revealment weak anonymity.
I interpret you to mean that it is not personal responsibility for
speech that you want, but the existence of someone to sue.
The placement of liability on the remailer does not directly affect
what the anonymous sender is going to say.  The assignment of
liability has, foremostly, legal consequences.  The way I see that it
will increase personal responsibility for speech is to make the legal
climate (in the U.S., at least) impossible for strong anonymity.  By
eliminating strong anonymity, you can ensure that their anonymity is
only conditionally revealed.
Now, you haven't directly stated that you think that strong anonymity
shouldn't exist.  If this is what you think, plase say so directly.
You can then make whatever argument you wish to support this position,
but I, for one, would like to argue against clearly stated positions.
No, not only time will tell.  This seems like an important enough
point to legislate into existence before a court test.  And for those
with objections to making legislation, remember that the issue will be
resolved publicly by law, but by lawyers in the courts.  How about
something like the following:
One can eliminate the negative effects by eliminating the positive
ones as well.  I do believe strong anonymity to be one of these

@_date: 1993-03-03 11:51:22
@_author: Eric Hughes 
@_subject: Let's look at this .... 
Re: key registration
We have received word on the list about publications in both IEEE
Spectrum and Communications of the ACM of Dorothy Denning's key
registration proposals.  What can we do?
Flood their mailboxes with thoughful outrage.

@_date: 1993-03-03 16:05:11
@_author: Eric Hughes 
@_subject: You Aren't [I'm Not] 
I thank Ted for such a clear reply.
This was the other interpretation I came up with, yet it did not seem
as likely to me as the one I assumed.  Excuse me if I ever implied you
were a freedom-hating, Dorothy-Denning-loving crypto-fascist. ;-)
Yes, there are plenty of large organizations who sue at the drop of a
hat.  Yes, it is likely that remailer operators would get sued.  I do
think, however, there are legislative and judicial defenses.
The place that this example breaks down is that silence is a commons,
and a communications network is not.  Society finds it profitable to
break up control of land into ownerships.  It is not, on the other
hand, profitable to do so with airspace as a sound-carrying medium,
because the cost of shielding, in addition to being expensive, looks
awful.  Thus sound has remained a commons wherein all maintain an
interest equal to their proximity.
A communications network, however, is an artifact, _i.e._ an object
created by design and technology.  As such it has no status as commons
unless the owners agree to grant it such.  One might argue that the
aggregate actions of backbone sites create such a commons.  Granted,
but the fact remains that the transmission of data in a particular way
or in a particular form or structure is not fundamental to the medium.
Like any other artifact, it can be changed.
Furthermore, the analogy of shouting at the neighbors does not
accurately reflect the facts of reception.  The sound from a
loudspeaker cannot be silenced except with great expenditure and loss
of sightline.  The speech of an anonymous posting source can be easily
silenced with filter.  There is a salient difference in effort here.
The loudspeaker example is that of an additive medium; all sounds come
over the same channel.  A telecommunications network, however, is on
the other end of the spectrum; every message comes in separately.  The
electronic medium is the most separable there is.  Filtering is not
possible for the loudspeaker; it is easy for the messages.
And again, no one requires a carrier to carry anonymous messages.
Practically speaking, you might easily end up with a situation like
the alt.* hierarchy, where only certain subnets agree to exchange
anonymous traffic.  I suspect this is inevitable in the short term.
But the phone company is not held liable when the call was made from a
pay phone.
I don't think it is irrelevant.  If we allow each person unlimited
personal freedom, that freedom include the freedom not to cooperate
with those one disagrees with.  Since the power of groups is larger
than the power of individuals, there is no such thing as unlimited
personal action.  To wit: "You may do what you like, but I don't have
to help, and I may actively hinder you."
Here is where we differ.  I do believe that strong anonymity is
desirable.  I believe that weak anonymity is undesirable for the same
reason that I believe key registration is undesirable.  (That said, I
think weak anonymity is not nearly as dangerous as key registration.)
The similarity is this: that an action performed in expectation of one
setting (privacy or anonymity) is later found to have been performed
in another.
[re: legislative protections of anonymous speech.]
A law which states that from now on that pi will be three does not
change the actual ratio of the circumference to the diameter.  A law
which says that certain facts of a situation are to be considered in a
certain way in a court of law does, in fact, change the way those
facts are considered.  If someone makes a claim and it is rejected because of protecting
legislation, then even if the person was offended, the law still says
there is no redress.  If you declared that claims of offense are to be
disallowed, then they are disallowed, regardless of whatever perceived
or even actual harm there is.
Can such legislation could be passed?  There's the rub.  We can
certainly work for it.
It is meant to describe society's reaction to the facts of the real
world, not to describe the facts themselves.
Any such legislation would not claim that people did or did not
believe them.  It would state that regardless of whether they did or
not, that as a matter of public policy it would not matter.
Your statement begs the question of whether anonymous speech can
cause "real damage."  I will leave this to another discussion.

@_date: 1993-03-03 16:22:08
@_author: Eric Hughes 
@_subject: SOCIETY: crypto impact 
For an interesting look at this, see _When Old Technologies Were New_;
I've forgotten the author.  It's about electrification and the
And remember, just because there's opposition, it could still be a bad
idea!  :-)  Let's not get too self-congratulatory here.
It really is unsettling.  There is, in fact, a speculative market in
personal information.  Some of these companies doing supermarket
systems had the collection systems developed, and then went looking
for customers.

@_date: 1993-03-05 09:49:13
@_author: Eric Hughes 
@_subject: Privacy awareness (Was: Cypherpunks priorities) 
Paul replies:
I agree.  I think junk mail may be one of the best examples from which
to extrapolate for the general public.  It becomes really clear
exactly that they do know something, because it says so right on the
letter.  It's usually easier to get people thinking about their own
lives than abstract privacy issues.

@_date: 1993-03-05 12:44:36
@_author: Eric Hughes 
@_subject: You Aren't [I'm Not] 
Existing controls on the signal-to-noise ratio?
However such postulated controls might function in practice, they
don't function well enough to make Usenet useful to as many people as
its bandwidth is capable of.  I don't read Usenet any more.  I can't
find enough useful information in a short enough period of time.  I have _no_ expectations about any controls of content on Usenet.
Ted postulates that standards of accountability provide a control over
the signal-to-noise level.  I grant that.  It does prevent the very
worst excesses from occurring.  It does provide an upper bound on noise
in discussion groups.
Yet this upper bound is ineffectual.  Let us take the widely used
analogy of Usenet as a sewer.  Reading Usenet is like wading chest
high through the muck.  But am I reassured that there is an overflow
valve so that it never gets past my chin?  Hardly at all.  I won't
drown, to be sure; what a _slight_ comfort.  (For those of you who
want a much more graphic depiction of walking through sewers, read the
relevant chapters in _Les Miserables_.)
I had thought that we had pretty clearly established that attacks on a
system of content and of volume were of different natures.  Lack of
robustness in mail software makes a mailbomb possible, not lack of
The structures need to be changed for much better reasons than to
prevent anonymous attacks.  I infer from your arguments that you think
that our current communications fora, newsgroups and mailing lists,
are not fundamentally broken.  I do think they are fundamentally broken.
(This doesn't mean that they are completely non-functional.)
I think they are fundamentally broken because they do not facilitate
human communication as they were intended.  They did when they were
small, I grant, but they did not scale well.  They even continue to
work when small and focused, but very few things with wide interest or
large import remain small.
We already have most of the features of anonymity and pseudonymity
already online, in the system that already exist.  I've made this
point before; I'll make again now.  I have never met most of the
people I've conversed with online.  I expect that I will never meet
most of them.  The personal responsibility that comes with personal
contact is mostly not present online.  The negative feedback loops
that are normally present in face-to-face conversation are not present
online, and it shows.
One of the greatest lacks in online life is the lack of restraint.
How many people online do you know who continue to rant about their
own positions without engaging in dialectic with another?  How many do
you know who, even given FAQ's, continue to ask newbie questions?  How
many do you know who jump to answer with the conventional
net-foolishness about whatever issue is at hand.  (For a concrete
example, consider patent legalities.)  Lack of restraint causes far
more problems that lack of accountability.
We have most all of the disadvantages of pseudonymity, but hardly any
of the advantages.  Our correspondents are able to be determined
readily by anyone with the ability to monitor (and that's quite a few
people).  We therefore cannot conduct our affairs online with the same
amount of privacy we can create in the physical world.  There is no
assurance, when exposing the corruption of a powerful figure, that
one's identity cannot be determined and punitive actions taken.  Those
who have some sort of taint imputed them by certain sections of
society do not out of fear speak freely.
The virtues of technically secure anonymity outweigh the negative
effects.  You can flame impersonally as much as you want right now,
and there is no recourse.  Yet you cannot keep private from your own
sysadmin the identities of those with whom you communicate.
Anonymity in communciations is fundamentally consistent with an open
society dedicated to free speech.
I will not press the point further than the following.  Whereas we
cannot change the physics of wave propagation in air, we can change
where the cables are laid.
Were there silence before in the neighborhood, I would agree.  The simple expedient of a standard header line has already been agreed
Re: crank calls
I think that networks will be common carriers, for the same reasons
that phone companies became such: that having a common carrier is
consistent with freedom of speech in an open society.
You can't protect the network unless you *do* protect individual
sites.  The network as a whole is not a legal entity, only the
companies and individuals that run them are.
I have left off a reply of the libel issue for such a time after I
have read up a little on the subject.

@_date: 1993-03-05 12:57:42
@_author: Eric Hughes 
@_subject: ANON:  Sysadmin policies at universities 
Let us remember that in this case the university is a state
university, which does not sove the problem, of course, but which does
change it in some significant ways.

@_date: 1993-03-07 15:09:42
@_author: Eric Hughes 
@_subject: pgp 2.2 
PGP version 2.2 has just been released.  Copies may be obtained from
the cypherpunks archive site via anonymous ftp.
There is a .tar.Z file and two .zip files.

@_date: 1993-03-08 19:20:10
@_author: Eric Hughes 
@_subject: You Aren't [I'm Not] 
Last night I spoke with Mike Godwin of the EFF about the issue of
anonymous libel.  Mike is not on the list, and I've copied him on this
message.  Mike knows more about electronic speech issues than pretty
much anyone else.  Here is my remembrance about what he said:
1. Anonymous libel exists.  Just because the speech is anonymous does
not mean it can't be libellous.  If libellous speech is made, and you
can infer the identity of the speaker, you can sue.  2. An anonymous remailer is not liable.  In order to be liable for the
libellous speech, the operator of the remailer would have to have
prior knowledge that the speech was libellous.  Since the operation of
the remailer is fully automated, prior knowledge is impossible.
Those two points are my summary of Mike's opinion.  For further
clarifications, please post to the list and to Mike.  Left out of this message is any consideration on the _realpolitik_ of
anonymous remailers: whether others will carry such traffic.  I'd like
to not fill Mike's inbox with clutter.

@_date: 1993-03-17 09:13:15
@_author: Eric Hughes 
@_subject: CYPHERPUNKS=EMAIL HARASSEMENT? 
Most of the unsubscribe message that have gone out over the list in
the last month are the _first_ messages sent out by people.
Therefore, let me repeat this.
To unsubscribe from the list, send mail to
A human, namely me, Eric Hughes, will read your mail and take
appropriate response.  Do not expect immediate answers; I am not a
If you send to the whole list asking to be removed, I will send you a
piece of junk mail (with the above info in it) and ignore your
request.  I don't do maintenance for the list on the same account as I
read mail.
Thanks you all.

@_date: 1993-03-17 09:39:05
@_author: Eric Hughes 
@_subject: The new welcome message, for your general information 
I've changed the welcome message for the list to update it with the
ftp site, and other changes.
I would like everyone to take a glance at this.  I've written down
some of the mailing list policies that have been _de facto_.
Please reply to me if you have any questions.

@_date: 1993-03-17 11:49:09
@_author: Eric Hughes 
@_subject: HUMOR: Manifesto anyone? 
I got the following message in my inbox today:
Hmm.  The thought of sending out encrypted manifestos...  I suppose we
could proselyte the NSA.
This one sounds like prime list member material, no?

@_date: 1993-03-17 11:54:59
@_author: Eric Hughes 
@_subject: RANTS: A Cypherpunk's Manifesto 
I've been meaning to write up a longer version of the welcome message
text for some time now.  I took the opportunity to do so before the
Computers, Freedom, and Privacy Conference.  I made up 300 paper
copies of this for distribution on the literature table.  All but a
couple dozen remained at the end of three days.
So then, this is my _real_ manifesto.  I took all the good lines out
of the previous version and added more.
I hope you enjoy it.  It's available on the ftp site in the rants/

@_date: 1993-03-17 12:03:13
@_author: Eric Hughes 
@_subject: ADMIN: ftp site 
I've cleaned up the ftp site a bit, set read permissions on one file
(oops), added a README, and generally made things more easy to use.
The site, for those of you who do not yet know, is
Here's a short intro:
README			an orientation primer
crypto.ftp.sites/	a place for external pointers
misc/			read, "I don't know where else this goes"
pgp/			PGP 2.2 distribution, DOS, Unix, Mac
rants/			for all those pesky manifestos that pop up
remailer/		remailer code and instructions and tools
welcome.message		the welcome message to the list
The site is yours to use.  If there is something you'd like to see on
the ftp site, let me know.  If you have contributions, let me know.

@_date: 1993-03-17 13:04:40
@_author: Eric Hughes 
@_subject: pgp2.2 in cypherpunks 
I obtained another copy of pgp22.zip for the cypherpunks archive site.
The previous one was the same length, but had some difference buried
in the middle.  The new one seems fine.  All those who had trouble
might want to download it again.  I also put up another copy of
pgp22src.zip, since it left and I don't know where it went.

@_date: 1993-03-23 10:40:07
@_author: Eric Hughes 
@_subject: FWEE! premature testing 
Dave Del Torto writes regarding Tim May's whistleblower test:
I think it was extremely helpful.  Especially when we are in a design
phase, it is good to know just how strong a reaction there will be to
some of these posts.  It benefits us to have had the experience, not
just an awareness of the problem.
Any guidelines must remain completely neutral about content of
postings.  A whistleblowers group is for expressing outrage.  The
things you are outraged about will be necessarily different from what
others are outraged about.  It is certain that one act of outrage will
itself be outrageous to another.  We have seen this already with Tim's
A whistleblowers newsgroup must remain value-neutral with respect to
all values except the freedom to speak.  When all agree in advance
that freedom of speech is a good thing, then we avoid problems when
specific speech is to one party's disadvantage.
Value neutrality must be taught; it will not come automatically.
This, and the ability to teach the defense of privacy, are in the long
run much more valuable than any one specific whistleblowing.
Dave mentions all these people are in favor of whistleblowing.  The
place where they can help the most is by affixing their signature to a
document that defends the whistleblowers group in advance of
"problems" with it.  If we can gather enough signatures from a wide
enough spectrum of the political process, the publication of the
document alone will be worth press coverage.  It might also be
worthwhile to take out a few big ads in major newspapers and print a
position paper.
[Re: comments from Ross Stapleton]
There's no need to preview anything.  Let people say whatever they
want.  Then, should the CIA wish to confirm something, they can issue
a statement with a digital signature attached to it, referencing the
post in question.
Review and verification is a valid concern; pre-review is not.

@_date: 1993-03-23 12:32:42
@_author: Eric Hughes 
@_subject: Idea 
My main goal for cypherpunks is to get people to defend their own
privacy, rather than relying on someone else to provide it for them.
There were several different methods recently mentioned that allow
people to take control of their own email flow.  I would suggest that
all those who would rather have another way of accessing the list do
so on their own computers.
In addition to all the methods for handling mail mentioned before, the
remailer source code includes a rewrite of slocal in perl done by Hal
Finney.  Available from soda.berkeley.edu:pub/cypherpunks/remailer.

@_date: 1993-03-25 23:11:23
@_author: Eric Hughes 
@_subject: ANON: Anon.penet.fi no more 
They won't harrass you, they'll harrass your connectivity provider.
To this end, it would be beneficial to collect connectivity policies
in the face of complaints from the major service providers.  Alternet,
for starters, and all the others I'm not really familiar with.
I learned a couple of weeks ago that Sprint is now offering IP
connectivity direct.  I would guess that Sprint has a good track
record from being in the long distance business for not telling their
customers to go away because someone they are talking to doesn't like
what they are saying.
To wit: who can I buy IP from who will not disconnect me unless I
don't pay?

@_date: 1993-03-25 23:15:24
@_author: Eric Hughes 
@_subject: Many Important Items in the News 
Potential imminent death of the Usenet predicted!
Usenet has survived lots worse than anonymous flamers.

@_date: 1993-03-25 23:30:20
@_author: Eric Hughes 
@_subject: Distributed anonymous posting (was Re: Many Important Items...) 
This is an excellent point of rhetoric.  Perhaps we should teach mail
and news forgery as a technique to the defense of privacy?   1/2 :-)
I have convinced myself that some form of secret sharing will be
necessary for a distributed system that is robust against single point
failure.  You don't want single point manipulability, either, if you
can get it.
There are two basic ways to proceed: hard nodes, difficult to take
down, or soft nodes, easy to reconfigure around.  Both approaches
should be looked at.
Hard nodes are more difficult politically; soft nodes are more
difficult technically.
A soft node necessity: a directory lookup service, distributed,
sharing data.  Merely specifying the first point of contact and
alternate paths doesn't cut it.  You don't want to have to retry a
bounced message so many times.
Who here knows enough about sendmail to consider the eventual
feasibility of integrating pseudonym lookup into mail transfer?

@_date: 1993-03-25 23:37:02
@_author: Eric Hughes 
@_subject: Many Important Items in the News 
It would help if there existed some filter software that automatically
installed itself in a user's .forward and filter out anonymous posts
(and nothing else).  Such a tool should be written in nothing more
than shell scripts and grep, for the absolute widest in portability.
(Not even perl, which, believe it or not, is not yet universally
Were such a utility posted to alt.sources, and if all a user had to do
was ftp it from an archive, unpack it, and run it once, we would be in
a much better position politically, (even if the utility received very
little use).
It is difficult to install mail filters.  Our argument for user
filtering would be much stronger if installation were simple.
A similar argument holds for anonymous posting filters in a global
KILL file.

@_date: 1993-03-25 23:55:59
@_author: Eric Hughes 
@_subject: REMAIL: cypherpunks strategy 
An excellent tactic, I think.
Automatic installation is key.  (Just as it is for anonymity
I have some comments on automatic installation.  In all cases, make
sure the shell can execute the filter before changing the .forward
file in any way.
Case 1.  The .forward file doesn't exist.  Easy.  Just write a new
forward file pointing to the software, "| remailer".  The remailer
must know how to deliver mail in this case.
Case 2.  The .forward file already points to a filter.  The
implementations of .forward that I have seen accept multiple pipe
commands.  Therefore if the .forward previously said "| ",
rewrite to "| remailer | ".  When the remailer handles a
message, it won't pass any output along the pipe.  Thus for remailed
messages, the filter is never invoked.  Thus the remailer looks
Case 3.  The .forward file points to a name.  Rewrite the .forward
as "| remailer | mail ".
Someone who knows more about writing portable shell scripts between
Sys V and BSD should tackle this one.  If we can get auto-installation
to work, we'd lower one of the larger hurdles there is right now.
Not to mention, it gives us time to design and write the code.  This
looks like a good use of vaporware as a political tool.  :-)

@_date: 1993-03-26 00:00:42
@_author: Eric Hughes 
@_subject: Many Important Items in the News 
What you are describing here is an alternate method of cancellation,
not a forgery of the main way of cancelling.
Of course, if they really want such an alternate method of cancelling,
let's write it for them, so that it also uses signatures to check
All the more reason to allow the backbone admins the power to not pass
anonymous articles.  It won't work, they'll feel like they're in
control, and everyone wins.

@_date: 1993-03-26 19:06:39
@_author: Eric Hughes 
@_subject: Remailers 
When I wrote this, I wasn't thinking.  When I wrote the original
remailer code, I posted it to alt.hackers along with a theory of
operation.  I don't know if I have a copy of that anymore.
Can someone provide it?  It was from last September.  Who gets
Usenet on CD here, anyway?

@_date: 1993-03-26 19:43:32
@_author: Eric Hughes 
@_subject: Many Important Items in the News 
Yes.  If someone doesn't want to pass traffic, let them.  It's
extremely foolish; they'll get a bad rep for it.  If they're a
commercial site, they'll lose customers.  If they're not, they'll lose
face.  Freedom to filter is freedom to shoot yourself in the foot.
But as Peter Honeyman points out, filtering anonymous posts won't work
to prevent them from being passed around, and they'll continue to use
external channels to pressure connectivity and administration.  These
channels have no technical amelioration; doing politics in the broad
sense is the only solution for this.

@_date: 1993-03-28 08:58:12
@_author: Eric Hughes 
@_subject: ANON: real-person newsgroups 
I am opposed to "is-a-person" credentials, especially of the type
"is-this-specific-person".  The knowledge of personal identity is in
most cases not salient.
We are in danger of creating a system similar to the SSN fiasco, where
a public identity is now not only a number but a cryptographically
protected one.  When such a system exists, there will be strong
pressures to use it for other purposes, just as there are with SSN's.
In short, do not support the PEM certification hierarchy in any way.
If you are in a corporate position with the power to make this
decision, nix it.  If you are an individual, do not get or use these
certificates.  Do not even get persona certificates; it strengthens
the person identification system by its negative.
Newsgroups could be the first structure to require identity, and they
wouldn't be the last.  We need alternatives before authentication
to real people becomes prevalent.
I fully agree that the creation of better structures is pressing on
us.  I would prefer to be the default and make PEM "the alternative".
The simplest replacement for "real person" is "public key."  Carl
Ellison argues mightily and well for this, and has for several years.
By going to just public key, you can support other models and retain
continuity of conversation, where that is desired.
We need to set up some replacement for the existing fora.  Here are
some of the characteristics I've thought about:
1.  Eliminate the default behavior to transmit everything received.
On both mailing lists and newsgroups, everthing anybody wants to say
to is sent to the whole group.  There are two common restrictions on
this.  One is closed mailing lists, where the same default
transmission occurs but is a closed group.  That group can get large,
however, and manifest all the probelms of an open group.  The other is
to use a moderator, or more accurately an approver, to pre-read all
the material before transmission.
So default transmission has to go.  What will replace it?  Whatever it
is, it must have the characteristic that there will be posts that will
not be sent to everybody when they first arrive.  Simple, but this is
an extremely important characteristic of any future forum.
I think the origin of this behavior lies in the UUCP origins of
newsgroups, where interactive use was difficult and expensive, and
where mail delivery turnaround times were measured in days.  Back
then, it actually was better to do default transmission, especially in
a fairly homogenous environment where most people got along OK.
2.  For bootstrapping purposes, default transmission must be supported
to some subset of the member of the forum.  This seems to directly
conflict the point made above.  Default transmission must be supported
to some, but can't be to all.  If you require that anybody who wants
to use this new forum install "work-in-progress" software in order to
participate, you'll cut out most of your participants.  Now people
won't participate unless there's some content to the forum, and that
will have to be provided by more than just the users of the new
2a. Corollary: A "lurker-only" mode must always be supported.  There
will always be those who just want to listen who are not expected to
otherwise participate.  A lurker mode, by its nature, will be default
transmission, but not of the whole discussion, perhaps.
3.  The social relations among individuals must not have any assymetry
enforced by the software.  A moderator, for example, is in a different
position than any other list participant.  That means that all people
must be able to participate in deciding what they want to read and
what they want to say about what they've read.
4.  The development of social assymetries must not be prevented by the
software.  Some people will want to ignore others and want to listen
only to others.  When these preferences become commonplace, there are
optimizations that can take place which create assymetries, for
example, by doing transmissions to lurkers based on the ratings of the
most respected group members.
5.  Since people must base their decisions on something other than the
content of the postings themselves, and since meta-traffic about
postings shouldn't completely overwhelm the forum itself, it is
desirable that ratings be specified in some contrained grammar,
preferably very small and machine-parsable.
6.  There must exist a mechanism for ensuring that the aggregate
rating information is not unbounded.  This is a subtle point which I
illustrate with an analogue: in an adventure game, there must be some
limit on the total amount of money.  If voting is completely
unconstrained, you quickly get vote inflation and the devaluation of
an individual's opinion.  If I can vote one hundred times for myself,
something's wrong.  Therefore I suggest that opinion votes be issued similarly to money.
Each person voting gets to withdraw one "permission to publish an
opinion" per message, withdrawn by a blind signature, and then gets to
use it however they want.  They can cast it themselves, or give it
someone else to cast by proxy.  (Note that a blind signature is an
interactive protocol.)  You want a blind signature to avoid the trap
of revealing privacy information by default.  If someone wants to say
what they thought, they are, of course, free to do so.
7.  Participants should have the ability to distinguish between blind
votes and public votes.  People should have the option of ignoring the
"prevailing wisdom," especially when that prevailing wisdom tends to
crush minority opinions.
8.  The rating system should be separable from the transmission
system.  This is to allow multiple rating systems to emerge.  A rating
collective built on top of a mailing list, for example, could get a
full feed of all posts, but not transmit all of them to all of its
9.  Someone is going to have to look at the really awful stuff in
order to rate it negatively.  "I just don't want it to be me."  Many
will say this, no doubt.
That's all for now.

@_date: 1993-03-28 09:13:28
@_author: Eric Hughes 
@_subject: ANON: Mark anon. posts a 
It is anonymous by default.  If someone wants to break anonymity, they
may.  I make this stronger below.
We create no new problems to be sure; we just bring them on faster, in
order to prepare for them.
I agree.  Hal argues that this means not marking anonymous posts.  I
disagree with this technique.
My solution to this is to make the posting anonymous but to sign the
post with your real name.  (Yes, that means however _you_ construe
your real name.)  If we wish to blur the distinction, we should make
the means of transport anonymous and the contents of the posting named.
Surely this blurs the distinction between named and anonymous posts.
People will ask "Why would anyone not want the routing information
revealed when they are saying who they are?"  This question, even
merely asked, has positive effects.  It makes one aware that identity
is not an email address, nor is accountability the ability to complain
to an authority.
It allows people to kill anonymous posts out of whatever spite they
feel to "those cowardly hypocrites".  It also allows the worst
excesses to be restrained.  Yet if there is a visible group of
respected individuals who use anonymous mechanisms for reasons other
than avoiding rebuttal, those who unrestrainedly ignore anonymity will
find themselves missing out.
I suggest that those who participate in news.admin.policy and
sci.crypt be the first to start this practice.  The more respected
users of anonymous servers there are, the greater will be the
incentive not to ignore anonymity completely.

@_date: 1993-03-28 09:17:40
@_author: Eric Hughes 
@_subject: REMAIL:  "Stealth" Remailers 
[added extra Received: fields to obscure the actual origin]
I do not think that any solution which requires deception in order to
work is a good solution for creating a social agreement.
We should implement systems that are upfront about their activity.  We
wish to say "I am protecting the privacy of others, and in doing so I
am protecting my own."  We do not wish to say "Who, me?" and be
roundly disbelieved.

@_date: 1993-03-28 09:26:28
@_author: Eric Hughes 
@_subject: alt.hackers post 
Rusty Babani forwarded me my hackers postings from six months ago.
Here they are (in two messages).

@_date: 1993-03-29 06:36:45
@_author: Eric Hughes 
@_subject: anonymous services 
Right now the cypherpunks remailers are designed as a back end.
Clever people can program the back end directly, but it's not for
It's the user's software that should provide a good front end.  That's the way the current remailers work (with the exception of Miron
Cuperman's).  But fundamentally, there's no good reason not to
encrypt, except, of course, for the last hop out of a Usenet post.
The user's front end software should encrypt automatically.
Remember, you need to encrypt everything, so that when you really need
the protection, it doesn't appear as though anything is different.
The remailers could just as easily be built on top of RSAREF.
Licensing is a red herring for this project.

@_date: 1993-03-29 06:47:27
@_author: Eric Hughes 
@_subject: a blackmail opportunity 
If you don't trust your remailer operator, use more than one.  This is
the whole point of multiple chainings.  A single point failure can be
any number of different threats: blackmail, coerced disclosure by
threat of violence, compromised equipment.  All of these can be
defended against by making a system proof against single point
For posting to news, one should always use two hops.  The first
destroys any the identity of the poster and the second one decrypts it
for transmission.  Both hops are encrypted, but the second relay sees
the plaintext and cannot link it to anyone because the first relay is

@_date: 1993-03-30 19:26:51
@_author: Eric Hughes 
@_subject: Another UUCP service provider 
This information is generally useful for the following tactical reasons:
1. Anonymous remailers are disapproved of.
2. Pressure is brought to bear against the operators of such systems.
3. All the owners of the machines and the communications channels must
   not give in to such pressure in order to avoid shutdown.
4. Private ownership of remailer nodes seems essential.
5. No organizations have volunteered use of their machines.
6. Personal ownership by individuals seems necessary in order to get this
   off the ground.
We don't need to discuss it much, but news is appreciated.

@_date: 1993-05-01 12:54:38
@_author: Eric Hughes 
@_subject: clipper and public key 
Tim mentions that the Clipper chip requires public key in order to be
useful.  This is not quite right.
The clipper chip is only a symmetric-keyed block cipher with a
peculiar (and condemnable) key setup feature.  the chip _per se_ does
not involved public key.
The problem is that you have to get the same key on both end of the
link without transmitting it.  There is a "public key" way of doing
this: Diffie-Hellman key exchange.  That would require licensing from
This is not, however, the only way to do this.  If you have a
symmetric cipher and a secret system key not known to the
participants, i.e.  embedded in hardware, then you can also transmit a
session key simply by encrypting it.  Of course if you know the system
key then you can read the traffic, LEEF's aside.  Such a system master
key could fairly easily be discovered, unless it's burned into the
chip by the manufacturer and the secret ends there.  (Yeah, right)
Hence in order for a reasonably (?) secure implementation of a
telephone which uses the clipper chip, D-H seems to be necessary.  In
fact, the AT&T 3600 phone does use D-H for key exchange.
Some have asked how come AT&T doesn't get sued by RSADSI.  Easy:
they're a licensee.
In summary: Does clipper require public key?  In itself, no.  In
implementation, likely.

@_date: 1993-05-02 10:40:04
@_author: Eric Hughes 
@_subject: PATENT: A legal way to use RSA! 
William Oldacre suggests just letting people roll their own encryption
packages.  Russell Brand exhibited a few relevant passages of the
patent law.  Allow me to make the argument clearer.
First, patent law covers all use, including personal use.  It would be
beneficial public policy to allow personal use broadly under statute,
but drawing the line between personal use and sole proprietorship is
difficult at best.  There are many cases where society might wish to
distinguish between profit and not-for-profit and personal uses, yet
however one looks at this, these can be difficult to distinguish at
their margins.  When, for example, does a hobby which turns into a
money making adventure actually become a business.  At the first sale?
At the first loss filed on Schedule C?  When specifically, might
patent licensure invoke?  Remember, this has to be a litigable
distinction.  For many of these reasons, all rights to patents are
vested in the patent holder.
Second, assume that personal use really was OK.  Then some people
really could build their own.  But you could even then sell kits,
because that would be tantamount to the completed object.  You could
sell all the parts, but you could agglomerate them into a single unit.
Big deal, you might say.  It is a big deal.  Most people, more that
99%, could not assemble a crypto system out of parts.  You would make
crypto protection available only to the programming elite.  This,
surely, is not my idea of a worthwhile end goal.
Patents are a restriction; they are designed to be a restriction.  We
can either use them by licensing them or go around them by not using
them but rather a substitute.  Any other way of dealing with them is
not generalizable to the public at large.  I am sympathetic to
personal and research uses of unlicensed patents, but my goal is the
whole world.

@_date: 1993-05-02 10:40:12
@_author: Eric Hughes 
@_subject: MONEY: escrow etc. 
The most salient thing for this response that Gavis says is
There are lots of interesting technical issues here, but I'll confine
my comments to the overall situation.
[exchange of money for data]
The first thing to realize about electronic money is that there is
always a third party involved.  Since information does not obey mass
conservation such as, say, gold does, you can't have free floating
money electronically.  The information has to start somewhere and end
in the same place.
So to say that there is no escrow agent is already stretching the
point, since in certain ways the transaction is already mediated.
"Provably decrypted" is really a useless concept here.  Suppose I am
selling information.  If I want to rip you off, I can send random bits
and claim that it is encrypted text.  I can also make up random text
and encrypt that.  In both cases, the bits I have sent you are
meaningless.  One uses valid encryption, one doesn't.  The separating
invariant here is meaning, not encryption.
There are protocols which allow for simultaneous disclosure of
information, where two parties want to exchange information
simultaneously.  This is not really the appropriate protocol, since
money is not necessarily valid by form alone.
But since you have electronic money in the first place, you have an
intermediary.  There's no reason for this intermediary not to be an
escrow agent.  In fact, there's really no risk for escrow agents who
requires that all bits be encrypted when passing through their
machines; there's no knowledge of content and it's just a commercial
transaction like any other.
As far as anonymity, that's easily solved by mail or packet forwarding

@_date: 1993-05-02 10:40:38
@_author: Eric Hughes 
@_subject: patent licensing 
This is correct as stated.  I don't think that loss of patent is a
motivation, though, for the suppression of PGP.  I think it is
perceived to cut into licensing revenues.
PKP is a partnership of MIT, Stanford, RSADSI, and Cylink.  Those
first two academic institutions are out to make money, plain and
simple, from their patent portfolio.  They are large corporations and
behave like such.  The other two companies are smaller and are more
accessible, but also have investors and a default requirement to make
money for their shareholders.
Any lobbying for better licensing practice needs to extend beyond just
Jim Bidzos to the owners of all these companies.  I presume that
Stanford and MIT both have patent licensing offices, and that each
also has a representative assigned to a particular patent account.  It
would be extremely beneficial to know the names of these people.  They
may be able to speak publicly where PKP is bound by confidentiality
agreements; PKP, remember, is in a subordinate position with respect
to its owners.
List of principals and investors in RSADSI and Cylink would also be

@_date: 1993-05-02 20:01:43
@_author: Eric Hughes 
@_subject: PATENT: RSADSI filings with the SEC 
RSADSI is a closely held California corporation.  What filings are
they required to make with the SEC for issues, dividends, etc.?  Are
these filings publicly available?  Do they contain names?  Perry, I
know you're familiar with this; could you comment?

@_date: 1993-05-02 21:54:38
@_author: Eric Hughes 
@_subject: Need some Advice 
Now that you've figured out how, could you write the method up in more
detail?  Please include facts like the location of the password inside
the database files, the version of Q&A you tested, etc.  I'll put it
up for ftp when you're done.
Share the work so that others can look at it.
The password was encrypted on a character-by-character basis?  Some
people really are foolish, either the ones who wrote the software
thinking it was secure, or the ones who pay the ones who wrote the
software to recover lost passwords.  Any encryption that allows
passwords to be recovered should not be called encryption; it should
be called snake oil.
Got a program?  You've got my email address.

@_date: 1993-05-02 22:08:09
@_author: Eric Hughes 
@_subject: PATENT: PKP patent numbers 
Eric Townsend extracted some of the text from RFC 1421 (PEM) and sent
it to me.  Thanks!  In it are contained the patent numbers for PKP's
patents, which I present below.  Note: PKP has since acquired rights
to the Schnorr patent; it relates to DSA.

@_date: 1993-05-02 22:42:37
@_author: Eric Hughes 
@_subject: PATENT: A LEGAL way---maybe! 
William Oldacre persists in believing that personal use of a patent is
permissible.  It's not legal, but if they don't know, they don't sue.
The differences between legality, the cost-effectiveness of a lawsuit,
and finding out in the first place are significant here.  We want the
protecting of legality, if we can get it.
I'm really glad for this observation.  One, however, must derate our
person-hours some because we aren't lawyers.  The basic idea, though,
is entirely accurate.
It has been rectified.  RSA is not a mathematical patent.  It is the
embodiment of some mathematical routines into a machine which is used
for a particular purpose and has certain security properties.
I got that one wrong.  It's the Hellman-Merkle patent.  I just posted
the actual numbers.

@_date: 1993-05-03 08:48:04
@_author: Eric Hughes 
@_subject: Tough Choices: PGP vs. RSA Data Security 
RSA might try to cash such a check, but if their bank is smart they
won't accept it.  A check is not negotiable if it contains a
condition.  Negotiable means it can be bought or sold.  If the check
is not negotiable then it can't properly be processed by the check
clearing house, since that would require a negotiation.  Only if the
check were drawn on RSADSI's bank would such a check be depositable,
since then your order to pay is being made to the same entity which is
receiving the check.
Return them, I would suppose.

@_date: 1993-05-03 10:05:12
@_author: Eric Hughes 
@_subject: PATENT: A LEGAL way---maybe! 
I first wish to apologize for a bit of impreciseness in a previous
posting.  I had said that a personal use exemption was not legal.  I
should have stated that personal use is not a defense against a claim
of infringement, and that barring any other defense (e.g. research)
such use would not be legal.  I hope this clarifies.
Peter Honeyman references a law review paper arguing for an
experimental exemption to patent rights.  This is a good document for
us.  Perhaps one of the many members of the Information Liberation
Front (ILF, which also stands for Information Longs to be Free) which
are around the country might arrange for an electronic copy to be made
available.  I have not read the paper, but I do have some comments on
its usefulness.
I think that an experimental exemption will not work for wider goals,
and I state two reasons below.  I also think that the existence of the
exemption is a huge rhetorical win for distribution.
First, an experimental exemption does not touch commerce.  PGP is
stalled right now in two areas.  The first, distribution, is not the
major problem given the number of overseas sites carrying PGP.  Lack
of commercial availability, however, is.  There are business that
would like to use PGP, but cannot.  Phil has mentioned some specifics
to me; some of these are large companies.  PEM implementations are
available commercially right now; they are not yet in widespread use,
but given the positive economic feedback in markets where
compatibility is key, PEM could easily and quickly overtake PGP
completely.  As far as I'm concerned, this issue is moot with respect to PGP.  The
development plans are already in place to put RSAREF into PGP in order
to legitimately license it.  But the same argument applies whenever
one might want widespread deployment of a system which infringes some
patent claim.  Digital money falls into this category squarely.
Second, even with a research exemption, you have to be doing _bona
fide_ research.  _Bona fide_ is Latin for "in good faith."  If you
merely claim you're doing research, that is not sufficient.  Bona fide
research certainly encompasses some academic research, but not all.  I
suspect that superconductivity researchers who used PGP to exchange
valuable technical information would be be consider to be doing
cryptographic research.  On the other hand, bona fide research need
not be confined to the academy.  The operators of remailers currently
could well be argued to be doing research, but when deployment becomes
widespread the defense of research becomes harder and harder to mount.
Both these concerns limit the extent to which a research exemption
could be used to promote the spread of cryptography.  This seems
entirely in keeping with the idea of an exemption for the purpose of
extending the state of the art, which is always conducted by very few
people.  The research exemption does not generalize.
The research exemption does have one extremely positive effect, and
that is on distribution from University sites.  Since the University
has a mission to research, distributing a research tool from an
anonymous ftp site is clearly within the purview or research.  The
question of bona fide research remains.  I would suggest that Peter
Honeyman simply start a research project "to study the distribution
mechanisms of public keys in a non-authenticated, highly networked
environment."  Peter, you could do this just by fiat, by creating a
document that says you're doing this.  This document could be handed
to the administrators at the University of Michigan ftp site, who
could then reinstate PGP with some measure of certainty that it was
legitimately there.
Yours in wiliness, but also in good faith,

@_date: 1993-05-04 15:47:25
@_author: Eric Hughes 
@_subject: checks 
For those who don't want to read about an arcane bit of commercial
paper law, please stop reading now.
  "[...] an instrument is not negotiable unless it contains an
unconditional promise or order. [UCC] 3-104(1)(b).  See 3-105.  That
is, the obligation must be expressed in terms which are absolute and
not subject to contingencies, provisos, qualifications, or
reservations which may impair the obligation to pay.  It must be a
'courier without luggage.' Overton v. Tyler, 3 Pa. 346,347 (1846)."
If a check is not negotiable, that does not mean that the order on it
is invalid; it means that the rights of third and later parties to
collect on the order are precariously held.  This might not impede the
money getting transferred, though.  The thing about the LD company checks is that their writing doesn't
seem to be a condition on the order to pay.  After all, you don't have
to indorse a check in order to get the money from it; you can always
take it to the bank it was drawn on directly.  The condition on these
checks seems to be a condition upon your indorsement of the check;
conditions on indorsements do not affect negotiability.
I agree.

@_date: 1993-05-04 21:13:04
@_author: Eric Hughes 
@_subject: ADMIN:  allowable use 
Re: a potential questionaire
Feel free to post your questionaire, but don't be surprised if you get
a hundred anonymous responses, skewing the results.

@_date: 1993-05-05 16:13:01
@_author: Eric Hughes 
@_subject: DH: Draft RSAREF/Diffie-Hellman specification 
Jim Bidzos sent the following to me, and I've received his blessing to
forward it to cyphperpunks.  Note that it is a draft specification,
not the actual one.  For those who have no idea what Diffie-Hellman
key exchange is, this document may give you some idea.

@_date: 1993-05-06 07:53:09
@_author: Eric Hughes 
@_subject: Cypherpunks meeting Saturday, May 8 
Cypherpunks Physical Meeting
Saturday, May 8, 1993 (the second Saturday, as always)
12:00 noon - 6:00 p.m.
Cygnus Support offices, Mt. View, CA
Even after our successful _ad hoc_ meeting two weeks ago, we're still
going to have our regular meeting.  There's more wiretap chip to
discuss; there's more encrypted phones to be discussed.  I apologize
for the lateness of this announcement; I've been busy putting a
machine on the Internet.
1. Norm Hardy has some time reserved to talk about money.
2. There will be some demonstrations of speech compression implementations
  that a couple of people have worked on.
3. There will be some stuff on remailers, as always.
[Directions to Cygnus provided by John Gilmore. -- EH]
Take US 101 toward Mt. View.  From San Francisco, it's about a
40-minute drive.  Get off at the Rengstorff Ave/Amphitheatre Parkway
exit.  If you were heading south on 101, you curve around to the
right, cross over the freeway, and get to a stoplight.  If you were
heading north on 101, you just come right off the exit to the
stoplight.  The light is the intersection of Amphitheatre and
Charleston Rd.  Take a right on Charleston; there's a right-turn-only
Follow Charleston for a short distance.  You'll pass the
Metaphor/Kaleida buildings on the right.  At a clump of palm trees and
a "Landmark Deli" sign, take a right into Landings Drive.  At the end
of the road, turn left into the complex with the big concrete
"Landmark" sign.  Follow the road past the deli til you are in front
of the clock tower that rises out of one of the buildings, facing you.
Enter through the doors immediately under the clock tower.  They'll be
open between noon and 1PM at least.  (See below if you're late.)
Once inside, take the stairs up, immediately to your right.  At the top
of the stairs, turn right past the treetops, and we'll be in 1937 on your left.  The door is marked "Cygnus".
If you are late and the door under the clock tower is locked, you can
walk to the deli (which will be around the building on your left, as
you face the door).  Go through the gate in the fence to the right of
the deli, and into the back lawns between the complex and the farm
behind it.  Walk forward and right around the buildings until you see
a satellite dish in the lawn.  Go up the stairs next to the dish,
which are the back stairs into the Cygnus office space.  We'll prop
the door (or you can bang on it if we forget).
Or, you can find the guard who's wandering around the complex, who
knows there's a meeting happening and will let you in.  They can be
beeped at 965 5250, though you'll have trouble finding a phone.
Don't forget to eat first, or bring food at noon!  I recommend hitting
the burrito place on Rengstorff (La Costen~a) at about 11:45.  To get
there, when you get off 101, take Rengstorff (toward the hills) rather
than Amphitheatre (toward the bay).  Follow it about ten blocks until
the major intersection at Middlefield Road.  La Costen~a is the store
on your left at the corner.  You can turn left into the narrow lane
behind the store, which leads to a parking lot, and enter by the front
door, which faces the intersection.  To get to the meeting from there,
just retrace your route on Rengstorff, go straight over the freeway,
and turn right at the stoplight onto Charleston; see above.
See you there!

@_date: 1993-05-06 22:13:07
@_author: Eric Hughes 
@_subject: PRESS: Markoff/NYTimes : "Big Brother & the Computer Age" 
The quotation of mine in the NYT today was one I gave to John Markoff
three weeks ago when the story first broke.  I called him up on the
afternoon of the announcment--his office is in SF, across the bay--and
told him I wanted him to give him an opportunity to quote me.  I was
surprised to see it in today's article.
The hook for this article was the recent FOIA disclosures.  Newspaper
articles usually don't get written unless there is something that has
changed, something that is "new."  An ongoing situation won't get
reported on until something specific happens; this specific happening
can be an event made just for the press--a press conference, a press
release, a public statement, or some publication.  For further reading
on this subject, look at _Reading the News_, an anthology by Pantheon
The FOIA disclosures about NSA's involvement in NIST was the hook, but
that wasn't the point of the story.  The facts of the FOIA were at the
back of the story, but they were there.  This illustrates another
principle of the newspaper: once you have a hook, there's lots of
stuff you can hang on it.
It really is easy to get quoted, but to do so, you have to make
yourself available to the press.  The recent FOIA story is a good
hook.  All the recent crypto events should be enough for a Sunday
article (but are not enough without a hook!).  I would encourage all
of you to make contact with your local media and offer to explain this
abstruse subject to them.  Reporters have little enough time to learn about what they talk about
as it is.  If you can present yourself as a bona fide expert (and this
does not necessarily mean as an academic) and make an offer to tutor
someone on the subject, not only will the quality of coverage improve,
but a friendship will have been made.

@_date: 1993-05-06 22:16:02
@_author: Eric Hughes 
@_subject: ADMIN: Eerie silence.... 
relay2.uu.net was down again today for a while, leading to big delays
and rearranged mail.
To repeat, no interloper is filtering mail or trying to disrupt
service to this list, to the best of our knowledge.  These
interruptions havefar more banal origins.

@_date: 1993-05-07 10:13:06
@_author: Eric Hughes 
@_subject: EFF letter regarding crypto policy 
re: AT&T questioning clipper and pushing clipped phones.
My guess is that AT&T corporate doesn't like the idea because they
know the long term consequences and the Greensboro division does like
it because it's income.  It's a classic case of corport schizophrenia.
Whether the patient ever becomes sane is an exercise left to the

@_date: 1993-05-17 09:07:36
@_author: Eric Hughes 
@_subject: Double encryption 
Re: group properties of ciphers, speaking of E1 D2 E3 DES mode:
That's not at all the reason.  One of the properties of groups is that
inverses exist.  If an inverse existed to DES encryption, then to
every encryption key K, there would correspond some unique other
encryption key L, such that that encryption by L was the same as
decryption by K.  Thus if DES formed a group, mixing inverses would
have no effect.
The reason for the inverses is for backward compatibility.  By setting
all the keys equal to each other, its the same as a single DES.  If
you encrypt EEE, you can't get backward compatibility since no DES key
yields the identity function.

@_date: 1993-05-17 14:39:40
@_author: Eric Hughes 
@_subject: NIST answers to RSADSI questions 
FYI. NIST has responded to my questions. Feel free to distribute.
Mr. Ray Kammer asked me to forward to you our answers to the questions you
raised in your e-mail of 4/27.  We've inserted our answers in your original message.  Subj:       Clipper questions

@_date: 1993-05-17 15:53:59
@_author: Eric Hughes 
@_subject: No Subject 
FYI. NIST has responded to my questions. Feel free to distribute.
Mr. Ray Kammer asked me to forward to you our answers to the questions you
raised in your e-mail of 4/27.  We've inserted our answers in your original message.  Subj:       Clipper questions

@_date: 1993-05-17 16:20:46
@_author: Eric Hughes 
@_subject: Third time's the charm 
OK.  This time this should work.  The previous file had some periods
on lines by themselves; this was causing my sendmail overhere to think
the end of transmission had arrived.  Damn in-band signalling.

@_date: 1993-05-18 20:39:40
@_author: Eric Hughes 
@_subject: Mixing ciphertext and plaintext 
What cryptosystem does Dolphin Encrypt use?  Is the algorithm
published somewhere?

@_date: 1993-05-19 11:55:18
@_author: Eric Hughes 
@_subject: FTP: new materials on the archive 
I've done a bit of archive maintenance in the last week.  A bunch of
the Clipper info I had has been cleaned up and posted.  I've put up
the sci.crypt FAQ, which I would like everyone who has basic questions
to read, as well as L. Detweiler's Anonymity on the Internet FAQ.

@_date: 1993-05-21 15:59:03
@_author: Eric Hughes 
@_subject: PI Compression 
Definition?  I have seen not this asserted even by theorem.  Not
surprising, since the statement is patently false.  There are
2^{\aleph_0} finite bit strings, and only \aleph_0 of those are
subsequences of pi.
For those of you without a math background, this means "They all just
don't fit."

@_date: 1993-05-21 18:00:57
@_author: Eric Hughes 
@_subject: Oops. 
There are not 2^{\aleph_0} finite sequences, there are \aleph_0.
Excuse me.  My brain was out to lunch.

@_date: 1993-05-22 09:29:25
@_author: Eric Hughes 
@_subject: WB: alt.whistleblower 
This is an open letter to L. Detweiler.
You've been hot to trot, eager to go, and ready for action.  What you
have interpreted as silence from others has in some case been work.
As you may recall, we were getting ready to go online two months ago,
with Julf's machine as the server.  Right after that, the penet
controversy started and things were put on the back burner for a
Let me review some of the arguments about the mechanisms of the
alt.whistleblower newsgroup:
1.  We want all postings to be anonymous.
2.  That every posting be anonymous requires software intervention.
3.  The software has to sit on some machine or machines, because it
    cannot easily be put into every posting client.
4.  Someone will own these machines.
5.  Whoever owns them must agree with the political goals of the service
    and be willing to take some heat for it.
6.  This excludes most machines.
7.  Whatever mechanism the servers use to connect with the net must
    also be reasonably proof against pressure.
8.  The link between the newsgroup posting and the anonymity server
    was to be the group moderator's address, which in this case maps
    to a piece of software ratherthan a person.
9.  A further desideratum is that multiple machines be able to perform
    the service, given the  constraints of the deployed base of
    news software, which require (to my knowledge) a single address.
10. In order to have multiple machines be able to map to a single address,
    you need to involve DNS, Domain Name Service.
11. In order to use DNS, you need a primary server and some secondaries and
    someone with access to the primary DNS server to do maintenance.
Now, I'll tell you what I've been doing.  I've put a machine on the
Internet in the last two months.  Never having been a Unix
system-level weenie before, I can say that I've learned a lot the
details of batty software.  This machine, because of the details of
its connectivity, is not suitable as a worldwide server, but it would
be suitable as a server for alt.whistleblower.ba, a Bay Area
distribution version of the same.  I've also gotten up to speed on
DNS, and in fact, am running name service on said machine.  (For all
of you who want to know what this machine is, I'm not telling.  There
are still too many half configured things, like sendmail.  I hate
I would recommend that if you are interested in newsgroup creation
that you read RFC 1036, which is the format for Usenet news messages.
(RFC's are available from nic.ddn.mil via anon-ftp.)  That plus
knowing that anybody can create an alt group, and you'll be set.  I
hope you have your server system set up correctly before you proceed.
The internet world has been without a whistleblower's newsgroup for
many years; a delay of a few months will not matter much.

@_date: 1993-05-24 11:17:32
@_author: Eric Hughes 
@_subject: Caller ID Question 
This is the distinction.  The underlying hardware and switching
protocols all have the capability for calling-number identification,
but the PUC didn't allow the consumer service "Caller-ID" to exist.
As a result, Pac Bell now offers services which use it in indirect
ways.  Not only do we have Call Return, but also Call Screen, Priority
Ringing, Select Call Forwarding, and Call Trace.
I just spoke to the business office and Caller-ID is not available
even on their business lines, not even the Pac Bell 800 offerings.
It looks like the only way to do this is to get 800 service from
another carrier.  Even then, I'm not sure that intra-California
service will be available.

@_date: 1993-05-24 11:20:03
@_author: Eric Hughes 
@_subject: MacWorld Special Report 
Re: MacWorld
Kudos to Mitch Ratcliffe for the MacWorld coverage.  He's a strong
advocate of privacy issues and makes sure his magazine covers them.

@_date: 1993-05-24 12:06:14
@_author: Eric Hughes 
@_subject: privacy graphics archive 
Re: graphic archive
A graphical archive for paper publication is a really wonderful idea.
I can keep or mirror the electronic archive on soda.
One of the projects that has been discussed is getting together a
presentation that we can hand out to people who will present it at
local meetings.  One necessary for any presentation is graphics.  Here
are some suggestions:
1. What the 'channel' model is.  Sender, Receiver, Eavesdropper.
2. How symmetric key crypto works over a channel.
[The New York Times had a good graphic of this.  My favorite part was
that the secret information decrypted to "... and get a quart of milk.
No, make that a half gallon."  An excellent subtlety to show that
privacy is for everybody.]
3. How public key crypto works over a channel.
4. How key escrow works.
5. How key escrow fails to work.
Not neglecting the obvious, I would suggest that any drawings such as
these, in whatever form they might have been created in, also be made
available in postscript.

@_date: 1993-05-25 18:07:48
@_author: Eric Hughes 
@_subject: Anonymity on the net 
For the complete details about this system, please see the ftp site:
There is complete source code to the cypherpunks remailer system,
instructions for use, scripts to set up encrypted paths, etc.
More generally speaking, if you have a question which you think might
be a newbie question, please check the archive site first.  For basic
cryptography questions, the sci.crypt FAQ (Frequently Asked Questions)
is available.  The full remailer is available, as well as a fairly
good collection of primary and secondary source documents on the
government wiretap chips.

@_date: 1993-05-25 18:43:54
@_author: Eric Hughes 
@_subject: Anonymity on the net 
If someone will type this in, I'll add to to the rants/ directory on
the archive.

@_date: 1993-05-25 21:14:46
@_author: Eric Hughes 
@_subject: RSA in CMOS? 
Cylink makes one, as well as Mykotronx.
I don't have data sheets here, but the Cylink chips are a fairly old
design, do modular exponentiation, multiplication, and addition.  One
is 512 bits wide (roughly), the other is 1024; these sizes are
inexact--the actual width differ by a few bits.  They run at 16 Mhz
(or at least one of them does).  They're implemented in an old design
process; just reimplementing them in .8 micron could speed them up a
lot.  They've been out for a few years.  The design is patented; I've
read the patent, and there are plenty of other ways to do the
The Mytronx chip, the MYK-80, has a full modular exponentiator on it,
as well as SkipJack.  The other name of the chip is Capstone.  It's
not yet shipping.  I take it, though, that this is unsuitable.
There are also at least four commercial announcements of European
exponentiator chips that I have seen, as well as some academic work
which is going to silicon in Britain.
There's no shortage of the chips, just the will to deploy them and the
market awareness for the need for them.

@_date: 1993-05-25 21:26:45
@_author: Eric Hughes 
@_subject: VinCrypt 
Re: vincrypt package blatherings
Can someone post the addresses of this company so that product
literature might be ordered?
I'm tempted to do a consumer education article exposing the danger of
secret and unreviewed ciphers, non-trustable encryption packages, etc.
It looks like these folks are prime candidates.

@_date: 1993-05-26 11:46:47
@_author: Eric Hughes 
@_subject: Questionable instances? 
This is the first of these messages we've had for six months, as the
bounce messages do in fact go back to the maintainer, me, quite
regularly.  I get on the order of 300-400 per week, since often a bad
address will queue up mail for a few days before bouncing it all.

@_date: 1993-05-26 16:29:12
@_author: Eric Hughes 
@_subject: Digital cash issuess... 
I take this with a grain of salt; see below.
I am not surprised that they find this interesting; David Chaum has
patented all the observer protocols.
Having read these protocols in the original, I can say this is not
much of an advantage.  The observer protocols are tremendously
expensive computationally.  Anything you build on top of it won't be
any faster.

@_date: 1993-05-28 21:37:49
@_author: Eric Hughes 
@_subject: ADMIN: sequencing problems 
Many have wondered why the mail comes out of order sometimes.  The
following comments are my surmise of the situation; I haven't done an
experimental confirmation of the situation.
The sequencing problem comes from the way that toad.com handles mail.
If it can't be delivered immediately upon arrival, it goes in the
queue.  If it can be sent out immediately, then it is sent out.  Now
toad.com routes to many sites through a relay at uunet; this relay
bogs down.  If toad.com can't connect to the relay, it queues the
mail.  The queue is processed only at intervals.  The next mail might
go out immediately, before the queue has been processed again.
I see the same thing at soda.  I'm not going to try to fix it.

@_date: 1993-05-28 21:37:59
@_author: Eric Hughes 
@_subject: VinCrypt 
PGP 1.0 had Phil's Bass-o-matic cipher, which he subsequently dropped.
When I first saw that, I thought to myself, "snake oil," but not in
those words.  I'm glad that lesson got learned.
I am in total agreement.

@_date: 1993-05-28 21:39:02
@_author: Eric Hughes 
@_subject: Data Insecurity Packages, etc. 
I hear the sounds of autonecrothaphty (digging one's own grave).  Was
it recommended by any of them, and did any of the test it?
Usually not.  This often comes as collateral information related to
the intercept.  In the case of a PC seizure, having a manual lying
around and an executable on the disk usually qualifies.

@_date: 1993-05-29 00:10:16
@_author: Eric Hughes 
@_subject: CIPHERS: Dolphin Encrypt public review 
I've never seen any names, nor any statements of their analysis.  As
far as I'm concerned this stands as hearsay.
Insufficient information??  And this is all you have for review?  Did
they even see code, or just an English description of it?  Look, if
saying they didn't laugh at it is digging your own grave, saying they
didn't even look at the full algorithm is acting as your own firing
Anything as significant as a new cipher needs to be publically
examined before it can be trusted.  The opportunity for such public
examination is not sufficient, only the actual publication and
subsequent responses qualify.
Therefore, I have a challenge for you to submit your algorithm in full
detail to the public scrutiny of the academic cryptographic community.
You have unfortunately missed the deadline for papers for CRYPTO 93,
but you can always submit a paper to the Journal of Cryptology.  If
the cipher is to be considered secure, it should be proof against the
most sophisticated attacks known; currently this means that it should
be proof against differential cryptanalysis.
Until this kind of high-level review has been made, I openly and
publically recommend that this cipher not be used.
As far as a product goes, Dolphin Encrypt would be much more useful if
its cipher were trusted.  A rewrite to use triple DES would be
straighforward and would greatly increase the trustworthiness of the

@_date: 1993-05-29 00:41:19
@_author: Eric Hughes 
@_subject: Trust, Amateur/Professional, use of PRNGs 
Re: disclosure
To my mind, selling the code for the encryption method does not count
as revealing the details to a very wide audience.  Were it freely
available, I would say that you had satisfied that concern.  Were it
even available on a non-compete covenant basis and free of monetary
charge I would be satisfied.
Let me see if I can paraphrase.  You'll sell me the code, so that I
can evaluate it or have someone else do this.  This evaluation is much
more for your benefit than mine, because where I might use it for
myself, this same information accrues much more to the value of the
cipher itself, which is yours.
Oh, please.
Re: An inappropriate historical comparison
The single salient difference that you ignore is fifty years of public
and intensive research into cryptography, starting with Shannon.  I
have seen nothing other than vague claims of security and one
statistic of flat byte distribution in the ciphertext (necessary and
easy to achieve).
I have seen very little awareness of any of this work.  In particular,
the most sophisticated analysis for ciphers to date has been
differential cryptanalysis.  I have not seen the results of any such
examination of your cipher.  To give you a clue as to how good this
technique is, Biham and Shamir were able to break FEAL-4 with a few
dozen chosen plaintexts, and FEAL-8 with somewhat more.
Re: levels of expertise
The state of cryptography two hundred years ago is not relevant to the
current state of knowledge.  Today there is much, much more to know
about the subject, and there is a lot of relevant prior art.
Should you claim that this prior art is not needful to know in order
to design new ciphers, I will not imply that your are a self-deluding
fool, I will explicitly declaim you as self-deluding fool.
Re: arguments _ad authoritatem_
But lacking both criteria, I have no belief at all that your cipher is
secure.  In fact, given the track record or the uncredentialled in the
last twenty years, I have exactly the opposite opinion.
Re: cryptanalysis
These and other such works are by no means the state of the art.  If
you've learned all your cryptography from these, it's time to do some
more reading.
One of the fundamentals of real cryptography is that exact solution
techniques are much less powerful than statistical methods of the
appropriate form.  Techniques of adding in 'noise' prevent exact
methods, but that is largely irrelevant.  Every useful statistic will
come through just as before, except that a larger data set is needed.
