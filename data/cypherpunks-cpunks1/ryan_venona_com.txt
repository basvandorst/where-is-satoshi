
@_date: 1998-12-30 10:02:48
@_author: Ryan Lackey 
@_subject: "Hit 'em Where They Ain't": Deploying Digital Bearer Transactions 
[BTW, there's a new mailing list to discuss how technical implementation
details of DBS would [hypothetically] affect market dynamics, user
experience, etc. -- send mail to pecunia-request at venona.org if interest.
It's for stuff a bit too technical for dbs, and stuff too tenuously
connected to cryptography for a mailing list like cryptography or coderpunks.]
Quoting Todd Boyle (tboyle at rosehill.net):
The same argument could be made for integration with the successful
shopping cart systems (for retail purchasing), the successful web server
(apache, maybe netscape and ms iis if you are feeling charitable), the
popular internet client platform (netscape or maybe msie).
I believe in this theory to an extent.  Unfortunately, it seems easier to
develop a platform-independent client for a DBS system first in standalone
mode, then work on integrating into various existing applications.
* Development and testing tools for generic systems such as Java are generally
far superior to those for closed systems
* A development team experienced in the other details of a payment system
(cryptography, network protocols, security) is more likely to be familiar
with generic software development than with developing for a specific
* Debugging a standalone client is generally far easier than debugging a
plugin for an application which may itself have bugs.
* Disagreements as to which particular proprietary systems should be supported.
While Quickbooks, for instance, may control the business accounting market,
packages such as quicken are more entrenched for individual (and perhaps very small business), and very large corporations use different packages.
Which market segment, even for just accounting, should be the target?
* The risk that a proprietary vendor will change the interface on the
development team partway through development, or will go out of business,
or become less important in the marketplace -- this is more of an issue
the longer the product development cycle is.
* Substantial minorities who are very attached to particular tools, in
contrast to the majority of the target market -- witness the macintosh
minority.  This is because of the interface, legacy plugins, or whatever,
and basically needs to be taken as a given.
Looking at another popular crypto application which I believe had considered
this issue is PGP.  The core functionality of PGP, especially until
relatively recently, has been to send encrypted email messages.  A
fairly compelling number of users use a small number of mail programs
(Eudora, maybe Netscape Mail, maybe MS Exchange/Outlook).  However, PGP chose
to develop and continue developing a standaline application, leaving it
to third parties to integrate PGP with existing mail readers.
One logic would have said PGP should have created a standalone mail program,
subsuming whatever functionality a tool like Eudora offers.  There are a
few reasons this might be worthwhile -- easier integration for the user
by virtue of only having a single tool to use, both in configuration and
in daily use -- perhaps market reasons such as greater profits -- greater
brand identity -- assurances of secure behavior by the underlying levels
(since they're integrated into the applications).
However, there are many reasons subsuming the mailer functionality into
the security application doesn't make sense.  First of all, it was not
necessarily known that electronic mail would be such a compelling application
for PGP (well, actually it was).  Additionally, they rightly noted that people
would be reluctant to leave their existing mail programs (additionally,
the market was a bit more fractioned at the time).  There were the same
problems with integrating into multiple applications, and also I don't
think Phil Z. or the other early PGP developers had much experience
developing application-plug-ins for any of the major mail clients.
There are probably other factors involved here which I haven't addressed.
My take on the question of how to do clients is that one should first
develop functional standalone clients, with a well defined API, then
either find existing people doing plug-ins or third-party applications
and get them to do the integration work (keeping the code in the main
line of the application, if possible, to keep it compatible with the latest
releases of the product).  Additionally, in some cases there exist
wide-ranging standards which are easy to implement (such as the UNIX
standards for stdin/stdout and argument handling, or perhaps HTTP/HTML,
or maybe at some point XML or OFX) which should be implemented.  There
are also some applications which are so widespread that their own internal
interface standard, if well documented and relatively unchanging, is worth
writing to -- perhaps this is the case for browser plug-ins for Netscape
and MS IE, perhaps for MS Office add-ons, and maybe the case for Eudora.
However, in most of these cases, I'd be much happier writing a standalone
system first, getting most of the development process out of the way,
then doing a shorter development cycle to integrate the well-tested
codebase into a third-party application...this lowers the window of risk
for changes in the third party application as well as providing the above
In the long run, though, I agree that integrating DBS into existing accounting
systems at least as well as current payment systems, and probably far
better, is of very high importance.  I wasn't aware quickbooks was that
popular, and will look at it soon...it sounds like it would be an interesting
package to work with.
Happy New Years,
ryan at venona.com

@_date: 2003-05-20 07:58:48
@_author: Ryan Lackey 
@_subject: Good things gro-o-o-o-w, in Ontario-o-o-o... 
I'd go with a dissociative, like Ketamine.
Of course, drugs are illegal, and illegal things are bad.
meal : sommelier :: movie : ________ ?
(ObSecurity: I assume people have read RFP's  on why he's not going to conferences and such)
Quoting Bill Stewart :

@_date: 2003-05-30 15:41:31
@_author: Ryan Lackey 
@_subject: web apps with large volumes of bidirectional http traffic 
I need to find some relatively widely deployed applications which have
frequent user interactions (rapid clicking on links, from as large a
population of links as possible, and also form filling and such).
(it should be pretty obvious what this is for)
I'd like:
0) *rapid*/frequent user interactions; fast clicking on things (like every
second, no more than 5 seconds)
1) "sticky"...long interactions with a given site (on the order of hours)
(also all links need to be under the same url/same server)
2) large number of potential links for users to click on, with
desirable properties for click distribution (I *think* I want them to
be nearly equally likely, but I might just want a defined
distribution, or I might even want the opposite of that)
3) relatively small data sizes for downloaded data, UNLESS downloaded
data is generated unique and "randomly"
4) widely deployed already on the internet, or compelling enough that
there would be a decent number of potential server operators.
Obviously I could *create* an app which has the desirable
characteristics, but I'd like something which can deal with existing
data or apps served over the internet)
5) good data on how likely users are to click on things, how fast they
click, etc., so one could easily operate within those parameters.
So far, the best ideas:
1) Porn
2) Mailing lists with lots of internal links (next, reply, etc.)
3) Sites with search engines with lots of linked data (encyclopedia,
4) html games (or flash, maybe) -- either imagemaps, or just tables,
things like chess, or puzzles, or whatever
I'd definitely appreciate any suggestions on possible web apps which
meet these criteria; reply to lists or ryan at venona.com.
I'll post when it's ready.

@_date: 2004-04-29 09:07:44
@_author: Ryan Lackey 
@_subject: message, but also test 
I have two questions:
1) Does anyone have actual performance measurements of ZKS from when
it was operational/at peak, in terms of bandwidth, MTU, latency, and
jitter?  Is there a good way to quantify just how far from
"acceptable" it was?
2) Does anyone know of any existing reviews of bandwidth cost in
multiple jurisdictions (say, per 1Mbps CIR international terrestrial),
as well as electricity (per-Kwh)?
I'm working on a research report which shows the 5-10 year costs for a
few specific businesses in as many different locations and
jurisdictions as possible, since otherwise it's almost impossible to
quantify how much "better" a jurisdiction is than any other.
I know bandwidth costs for all the markets I actually care about, but
I'd like to flesh this out to account for more individual countries.
The problem is the bandwidth numbers I have are public as well as very
aggressively negotiated, and there's usually a spread of 3-10x between
them, so I'd rather not have to go through that level of negotiation
for any additional data points.
(some people have been sending to cypherpunks at metacolo.com
vs. cypherpunks at cypherpunks.metacolo.com, which was causing a bunch of
cypherpunks mail to accumulate in the catchall spool for
metacolo.com.  I just added cypherpunks and cypherpunks-* aliases in
the metacolo domain as well, so it should work, of which this is a
(I also subscribed the al-qaeda node, and will probably finish setting
up the spamfiltered version of the list, as well as passing the back
archives through the same archiving software as current archives, and
search-indexing them, next time I get bored)

@_date: 2004-05-02 18:56:49
@_author: Ryan Lackey 
@_subject: message, but also test 
I've always used a special vmware instance whenever I wanted to do
something anonymously, as I assumed my OS choices and customizations might give me away to the other end as well, especially for anything I
don't notice (a good attack would be trying a well-known 0-day OS
vulnerability on an interactive counterparty, seeing if his machine
drops off the net -- you could do this several times and figure out
which OS is running).  Running a pretty much standard win2k/xp virtual machine with whatever
anonymity functionality running on the windows side OR the unix side seems to deal with that, as well as making it easier to sniff all
output from the machine in realtime to make sure nothing else is going
through.  And it would then be very obvious which nym you're using.
I don't think gmail would work well with a 500MB archive -- I've used
it, and their UI seems inefficient past a certain point.  General web indexing of html archives works pretty well --
("from, "to" searching would be equivalent to author searches, and
keyword + or - terms can be done through a web ui as easily)
I think I'd also prefer being able to do LOCAL searches on most of the
topics on cypherpunks, vs. web searches on someone else's machine, so
I'll just let people download raw archives when reconstructed, with a
5Mbps cap or something.
I am not sure how safely spam can be filtered from the list -- each
person would have his own view of what is spam.  I think ideally there
would be all messages in the spool, broken up by month or quarter or
year, and then a way to run various filters on it, like kill certain
senders, kill keywords, "traditional" spamassassin/bayesian type
systems, etc.  Then the ability to search over any subset.
Google doesn't support enough negative keywords to do this, and it
would be computationally expensive to do the filtering and reindexing
in realtime for each user.
If you had all the spools yourself locally, you could run whatever
spam elimination you considered proper once, and then search index,
with negative keywords for specific senders (or just excise certain
senders permanently as spam)
Quoting An Metet :

@_date: 2005-02-14 20:44:10
@_author: Ryan Lackey 
@_subject: U.S. Said to Pay Iraq Contractors in Cash 
Everyone does this openly over here.  Anything less than $500k or so
isn't even worth thinking about, since as a kidnap victim, you're sold
for about that much.
I really don't see why it's worthy of an article.
I've been buying cash from other contractors, as well as providing
cash on a short-term loan or wire basis, and these activities are
common as well.
It would be a good environment to deploy various electronic payment
systems, but nothing is really up to snuff for the kind of things
people do here -- large sums, and making purchases from existing
online vendors.
Quoting R. A. Hettinga :
