
@_date: 1993-08-23 18:41:41
@_author: Eric Hughes 
@_subject: Chaum on the wrong foot? 
I applaud Hal's insight into Chaum.  I was in Amsterdam last year for
a few weeks working for/with him, and I can substantiate what Hal
says.  I was only there for six weeks, which was supposed to have been
the start of a longer relationship, but I got out.
The observer, owned by the user, opens a communications channel to a
chip and to a central computer, both controlled by some company.  The
observer then mediates the communication between the chip and the
central computer to make sure that no privacy information leaks out.
This statement, while certainly true in Chaum's mindset, I no longer
believe to be true.  The question hinges on what 'security' means.  To
Chaum, it means that fraud losses are a mathematically perfect zero.
To a real business, however, the losses must be bounded.  The smaller
the bound, the better, of course, but real financial service companies
can and do tolerate some loss due to (technological) fraud.
If the cost of the perfect system is more than the losses from fraud,
there's no point in deploying it.  Make no mistake, the observer
system is expensive.  The reasons smart cards are not more widely
deployed is that they're too expensive per card.  The observer
protocols requires both a smart card and a small hand-held computer!
Not only not useful, but totally inapplicable.  The observer model
relies upon the fact that the computations inside the chip are unknown
to the user.  This just can't be the case with a software-only system.
This just won't happen.  The observer protocols are *patented*, you
see.  Anyone can design and build observers, because the spec is
public, but you've got to pay up.  Chaum seems to be basing his whole strategy for the future on
observers.  I think it's a gross strategic mistake.

@_date: 1993-08-23 18:51:41
@_author: Eric Hughes 
@_subject: (CuD) (CuNews) Smart Kard Forum 
Well, let's look at the applications.
Not necessarily     identifying
  identifying       ===========
===============     health care
payment             identification
transit             security
My guess is that anonymity isn't even in their heads.

@_date: 1993-08-23 19:02:05
@_author: Eric Hughes 
@_subject: Chaum criticism 
Both articles, as I recall from the abstracts, exist square within the
observer framework.
The two CWI papers do require observers and are useless for
software-only implementations.
The original blind signature still works.  It can still be money.
That hasn't changed.  Recall, though, that the blind signature is
patented by Chaum in addition to also requiring the underlying RSA

@_date: 1993-08-23 19:27:04
@_author: Eric Hughes 
@_subject: No digital coins (was: Chaum on the wrong foot?) 
Gold obeys a mass conservation law.  Information as such does not.
Everything unique about digital money stems from this basic
Here is a thought problem to illustrate.  If money were required to be
able to be xeroxed, would you be able to make a monetary system?  The
answer is yes, but it doesn't act the same way as a coinage system.
It is a problem only if you want to design a digital coin.  Once you
rid your mind of the need for that, it's not a problem but a design
No.  This is way off the mark.  Chaum's complete and overriding goal
is privacy, sometimes to the exclusion of other desiderata.  The
observer protocols sacrifice nothing in the way of privacy, but
perpetuate and reinforce the subservient economic relationships
between individuals and large financial institutions.  The system is
assymetrical; the central computer talks to its chip through the
observer.  There is no room here for person to person interactions.
The barrier to entry to deploy chips is high, as well.
In other words, the observer protocols preserve chasm of relative size
of Big Business over and above the individual.  This is a benign
oversight, to be sure; all the individuals look alike.  (You thought
you were a number before?  Now you're a _random_ number!)
Nevertheless, the observers are not egalitarian; they are the model of
cable TV as opposed to the telephone network, of newspapers as opposed
to electronic mail.
Chaums got privacy down, but I don't want the rest of his world.  No way.

@_date: 1993-08-24 11:15:28
@_author: Eric Hughes 
@_subject: No digital coins (was: Chaum on the wrong foot?) 
I count this comment as an intentional misreading of my position.
I am not a libertarian, nor is it likely that I ever will be.  I've
also read E. F. Schumacher's _Small is Beautiful_ and thought much of
it was just plain wrong, or, at best, unprovable.  I read your words as an attempt to enforce a sort of libertarian
political correctness, as insulting as that phrase will no doubt be to
The agenda of privacy is orthogonal to most partisan political
positions.  As strong as the libertarian presence is on this list, it
is by no means the only view.  It is precisely because cypherpunk
issues cut clean across the political spectrum that they are so
I expect no one here to wear seamless garments of any cut or cloth.
There are many on this list whose personal agendas call for making the
world safe for greater accumulations of capital.  This is not at all
my agenda, yet I have put aside my repugnance at this in pursuit of a
common goal.  While I expect no one to hold to any particular view,
I do expect that everyone here treat opposing views with respect, or
better yet, with silence.
The cypherpunks list is about creating privacy.  We assume that
everyone here wants the availability of more privacy than they
currently have.  We need not debate the particulars of these reasons,
nor need we suppress the statements of these reasons.  I am perfectly
happy with individuals stating their own reasons for desiring privacy;
these statements are powerful and useful, yet they should not engender
debate on this list as to their propriety.  Should anyone insist on
debating belief, private e-mail is always available.
I know that when the goals of personal privacy are achieved that the
people and opinions that currently cohere on this list will fragment
and splinter.  I do not want this dispersal to happen, however, before
our goals are acheived.  Disrespect for each other, or, in other
words, bone-headed stupidity, will certainly accomplish a premature
Let us work together while we need to, and no longer.

@_date: 1993-08-27 10:22:51
@_author: Eric Hughes 
@_subject: REMAIL: Attacks on remailers 
Attack (7) is made by an opponent who monitors all network traffic,
but has no access to the insides of the remailer nodes.
The defense is more subtle, however, than proposed.
Let us assume that these remailers have the basic characteristics of
mixes: encryption rewriting, size quantization, and message
reordering.  Furthermore, let us assume that the defense of using
'large' chains of 'popular' remailers is being used.
The possible number of destinations should increase exponentially with
each hop.  If gather-and-rearrange mixing is done, then the number is
the product of the rearrangement thresholds for each remailer.  If a
radioactive decay model for reordering is used, then it is the
expected value of the number of destinations which grows
exponentially, that is, the possible number of destinations (those
with non-zero probability) grows faster that the expected value of the
number of destinations.  They are both exponential, but one has a
larger base than the other.
What is more important than the reordering algorithm is that the
expected number of destinations grows exponentially with the number of
hops.  There will be correlations, but with linear increase in cost we
can get rid of them, we hope.  What is the nature of the remailer path, however, for which we have an
assurance that the correlations are too difficult to carry out?  Or to
ask a simpler question for a simpler environment where we assume all
remailers are equal, just how long does the path have to be?
We know that by making the paths "long enough" that we can prevent
correlations from becoming significant.  The question is how do we
find out what is long enough?
The fact that it would be difficult is not the issue for the theory,
but for the practice.  The extremely high cost, however, could be
justified for 'national security' reasons against a few targets, or
to break the system completely open looking for 'tax evaders.'
If our theory is good against an arbitrarily strong opponent, then the
system can withstand sustained attack.  If the existence of the system
is seen as sufficiently threatening, for any number of different
threats, we should plan for a sustained attack.  We need to know what
the limits of the capability are and not just guess.
I've been thinking about an invariant for communications systems proof
against traffic analysis which I call 'privacy diffusion'.  The
privacy diffusion is a probability distribution over possible
recipients.  One characteristic of the privacy diffusion is the
expected value of the number of different recipients.  This is a good
first measure, but I suspect it won't be enough.
The expected number of recipients is multiplicative in the diffusion
per node, as described above.  If different downstream nodes have
different mixing thresholds, they'll need to be weighted.  Since the
system is multiplicative, the weighting should be by geometric mean,
i.e. a downstream node with probability 1/10 should multiply by the
10th root of its own threshold.  One can see that if all the
downstream nodes have equal likelihood and identical thresholds, that
this formula degenerates into the simple one above.
In fact, there is a simple closed form expression for this value,
namely, e^-E(ln p), the inverse exponential of the expected log
probability.  This is exactly e^H, where H is the entropy of the
probability distribution.  e^H is also the expected size of the search
space, were we looking for encryption keys.
On the other hand, this situation is unlike a key search space in that
every value is not equally likely and that the priors are not
independent.  In a phrase, not everybody talks to everyone else, but
everyone who talks talks to someone else.  We can make a baseline
model of a communications graph with probabilities on it.  (This
doesn't take into account state, e.g. conversations tend to happen
alternately.)  Most edges on this graph will have p=0, i.e. these two
people have never communicated.  Let us remove these null edges.  What
we are left with is a sparse graph with lots of clustering (friends of
friends).  In this situation, if our message could have gone to ten
million people (say, 7 hops each with threshold 10), it is more likely
that it went to one of twenty or fifty.
Even if you don't know what the graph looks like, you'll know that it
is sparse, and you'll have some idea of what the characteristic
distributions are.  This is exactly the equivalent of studying letter,
digram, and higher order statistics for English and other natural
languages.  The statistics gathered as to the prior distribution will
appear in the observed output unless one has some good idea of how to
'confuse and diffuse' them.
I am pushing an analogy here between cracking codes and cracking
traffic patterns.  I am pretty sure that there are more parallels than
meet the eye.  The appearance of the entropy in the expected number of
recipients may be only the tip of a much larger correlation.
traffic			cipher
=======			======
statistics of		letter frequencies
interconnection		of the plaintext
observed messages	ciphertext
path through		key
mixing algorithms	encryption
null messages		padding
This whole mix system needs a lot more thought before we'll have an
assurance that it will be secure against sustained attack.
On the lighter side, I couldn't resist this next one.
And for the receiver, just subscribe to cypherpunks under several
different aliases.

@_date: 1993-08-27 10:32:52
@_author: Eric Hughes 
@_subject: Mailer hooks for PGP 
As a general rule, mere presence of a key on a keyring should not
indicate that this person wishes to receive encrypted mail.  There
should be a separate installation for that, either by an enhanced
alias file or similar.  There are many for whom reading encrypted mail
is not always desirable, because the effort required to download it
and decrypt it is more time than the content is worth.  I myself fall
into this category, unfortunately.
I mean, if you encrypted if there was a key for someone, and sent mail
to David Sternlight, he wouldn't be able to read what you wrote!  :-)

@_date: 1993-08-30 10:43:46
@_author: Eric Hughes 
@_subject: no ftpd on soda.berkeley.edu ? 
soda.berkeley.edu was down Friday to have a disk reformatted.  It was
the disk that the cypherpunks archive was one, BTW; if anybody notices
anything missing, please tell me.

@_date: 1993-08-30 10:53:46
@_author: Eric Hughes 
@_subject: Talked to Phil Zimmermann.... 
As Phil told me, the owner of the IDEA patent has recently been asking
for lots more money.  These actions don't affect the agreement with
Phil with respect to PGP.  Phil doesn't want to encourage the
patentholder's behavior.
I've cc: Phil should he wish to elaborate.

@_date: 1993-08-30 14:38:50
@_author: Eric Hughes 
@_subject: The need for FREE cryptography ... 
My own thoughts on packaging this kind of thing for general use is to
make a cryptographically enchanced PERL.
In particular, I'd add the following data types:
    - arbitrary precision integers
    - arbitrary precision modular integers (i.e. a value, modulus pair)
    - bit/byte/word vectors of specifiable lengths
I'd add the following operators
    - '*%' (ternary) modular multiplication
    - '**%' (ternary) modular exponentiation
    - '~' (binary) bit permutation
    - '~~' (binary) byte permutation
I'd add some functions
    - des()
    - armor(), disarmor()
    - gcd()
    - xgcd() which also returns the coefficients s.t. x*a + y*b = gcd(x,y)
I'd add some miscellaneous stuff like being able to read in a PGP
keyring as an associative array.  Some strong pseudorandom number
generators might be useful.  It might also be convenient to have a
fast parser for RFC822 email.
(Does everybody see where this is leading??)
And just because you _can_ easily write, say,
    $plaintext = &idea( decrypt, $ciphertext, or maybe something else, say,
    $p = & first_prime( & long_random( 510, 514 ) ) ;
    $q = & first_prime( & long_random( 510, 514 ) ) ;
    $N = $p * $q ;
    [...]
doesn't mean that the cryptographic PERL violates anybody's patent
rights in any way.
These are just my thoughts.  I'm not going to work on this, but I do
hope to inspire someone who might.

@_date: 1993-08-31 10:54:04
@_author: Eric Hughes 
@_subject: REMAIL: Attacks on remailers 
A user's crontab is not deleted at reboot, to my knowledge.  You could
simply run a cron job to schedule mail delivery.  (If you deliver on
cron, you don't get an even distribution of delivery times, unless you
use a much more frequent cron.)

@_date: 1993-12-04 07:53:05
@_author: Eric Hughes 
@_subject: IGNORE: useless drivel 
This sentence wins an Eric Hughes "Most complete misquoting of
Nietzsche in 1993" award.

@_date: 1993-12-04 10:33:05
@_author: Eric Hughes 
@_subject: Since we're on the subject of Nietzsche... 
"It is not when truth is dirty, but when it is shallow, that the lover
of knowledge is reluctant to step into its waters."

@_date: 1993-12-07 08:33:32
@_author: Eric Hughes 
@_subject: Name for crypto cash 
And of course 'snow crash' would be 'cocaine money', allowing us to
read an entirely new subtext in Stephenson's novel.

@_date: 1993-12-09 07:25:57
@_author: Eric Hughes 
@_subject: Announcement: Bay Area cypherpunks Saturday meeting 
What: Bay Area monthly cypherpunks meeting
When: Saturday, 11 Nov 1993
      12:00 noon - 6:00 p.m.
Where: Cygnus Support offices, Mt. View, CA
The Bay Area cypherpunks meetings are the second Saturday of the
month, at 12:00 noon at Cygnus, and have been at this time and place
reliably for a year now.  If you don't see an announcement, there will
still likely be a meeting.
This month:

@_date: 1993-12-12 10:27:22
@_author: Eric Hughes 
@_subject: "Cipher" 
The use of the word 'cipher' as 'zero', both for a number and for a
loser, has only fairly recently fallen out of general use.  I've seen
references to the word in works from the 50's and 60's where is use
was not meant as an obscuring device.
The use of 'cipher' in 'ciphertext' has this same connotation, that
the text says nothing, that is, by itself.

@_date: 1993-12-24 10:29:54
@_author: Eric Hughes 
@_subject: Merry Christmas, Cyberanarchists 
Once we had one, and everyone who posted got assigned an ID.  Now I'm
careful to add them as naXXXXX.
If people aren't getting an ID assigned when they post, there's no problem.

@_date: 1993-11-02 01:31:20
@_author: Eric Hughes 
@_subject: Your mother's maiden name 
re: cost of obtaining mother's maiden name.
Not very.  Birth records and marriage records tend to be public
record.  Organizations that do genealogical research tend to have this
data around, although they don't always make it easy to get data on
the living.
On the other hand, most organizations I've dealt with that use it just
use it as a password field.  You can just pretend that the person on
the other end of the line is asking "What is your password?" rather
than the standard question.

@_date: 1993-11-02 03:19:54
@_author: Eric Hughes 
@_subject: Chaum's credentials (technical question) 
Hal Finney writes about a paper of Chaum's, and near the end asks:
I think you're correct, Hal.  From everything I can tell, Chaum's
confused product and greatest common divisor.
First, though, there's a basic fact about the arithmetic of integers
which everyone who wants to learn more algebra should know.  Z is the
set of integers.
    For every m,n in Z, there is a,b in Z such that a*m + b*n = gcd(m,n).
One calculates the gcd by means of the Euclidean algorithm, and the
coefficients a and b by an extension of that algorithm.  Lots of basic
algorithm books contain descriptions.
a principal ideal domain.  The ideal (m,n) is composed of the linear
span of m and n.  Since this ideal is principal, by definition there
is a c such that (m,n) = (c).  Clearly c is in the linear span of m
and n, hence coefficients exist.
Note that reducing mod n gives a*m = gcd(m,n) (mod n).  If m and n are
relatively prime (means gcd = 1), the a is m inverse mod n.  Likewise
b is n inverse mod m.  This is a standard algorithm for calculating
modular inverses.
Here's the relevant passage, again:
I believe that Hal is correct when he points out that h is not a
remainder (which would be zero, as he points out) but the quotient.  I
originally misread this as quotient because I recognized the context.
First, the multiplicative inverse of d1 (mod d2) exists only if the
two are relatively prime.  Hal did not quote the whole article, so I
don't know if this criterion is stated elsewhere.  Let us assume the
d's have this property, since the d's can be so chosen.
The calculation of d1 (mod d2) is exactly the calculation of the
coefficients in the extended Euclidean algorithm above.  Consider a*d1
+ b*d2 = 1.  Reducing mod d2, we have a*d1 = 1 (mod d2).  That means
that a is d1^(-1) (mod d2).  Likewise (a*d1 - 1) / d2 = -b.  Chaum's
description exactly fits the gcd context.
That's my interpretation as well.  After the calculation, as Hal
observes, you just end up with Px, not Px^(d1*d2).  That's totally
useless, since you already knew Px.
It is certainly possible to create coefficients for combining
credentials such that you end up with a product in the exponent.  For
example, the pairs  and <0,d1> both work nicely, with the bad
side effect that you've given away a private key.  Let's try blinding
Suppose you have coefficients a and b such that a*d1+b*d2=0; the pair
 works here.  Then every such pair of product-combining
coefficients can be represented as  + r*.  Since the
exponents are mod phi(N), we can suppose that the pair doesn't _directly_ reveal the private keys.  But it's unclear to me
that this pair of coefficients doesn't reveal d1 and d2.  One doesn't
know phi(N), but one may not need to.

@_date: 1993-11-04 09:22:23
@_author: Eric Hughes 
@_subject: Er? 
It appears that last few fields in the returned header are responsible
for the problems.  Julf's mail also indicates why cypherpunks has had
a couple of duplicate posts recently.
The offending headers are "Return-Receipt-To" and "Errors-To".  The
"Return-Receipt-To" field is triggering a reaction in some other
mailers to bounce back acknowledgement of the mail.  Now
cypherpunks at toad.com was in the "To" list, and it appears that
acknowldegement mail was sent out to cypherpunks again.  All this time
the "Received" fields are increasing.  When there are too many of
them--the number is mailer dependent, but is typically 17-20, some
mailer along the chain bounces the message.  It sees the "Errors-To"
line and sends back the bounce to penet.  My guess is that a
significant fraction of the cypherpunks list is sending anon.penet.fi
back one message each per "Return-Receipt-To".
Not all that many mailers honor return receipts, but all mailers
bounce mail with too many Received fields.  Hence the first return
receipts sent didn't generate nearly so many errors as all the bounces
from the second time the message went out to the list.
How we solve this?  Well, let's list the mailers involved in the
particular message you sent.  The first one was the anonymous remailer
at caltech.  The message from there was directed to cypherpunks, so
that's toad.com.  From there it travelled through uunet (toad.com's
mail gateway for a large amount of traffic) to somewhere in the
gza/aktis/ov group of machines.  Somewhere in there the return receipt
was generated; note the "Return-Path: " field.
This mailer generated a message back to cypherpunks (toad.com) again.
One copy of this went to a machine in uci.edu, which bounced it to
I'd say that the mailer which generated the return-receipt back to
cypherpunks (assuming that happened) is the most proximate cause.
Cypherpunks was in the To: field, not the From: field, and even though
your standard reply might go to both parties (assuming the To: field
is larger than just you), a return receipt should only be propagated
to the original sender.
toad.com is a secondary cause, since the Return-Receipt-To: field
should probably not be propagated out to a mailing list, but rather
acknowledged or discarded before mailing list expansion.  Also, since
toad.com is not running reasonable mailing list software (which we
don't have), it's not detecting duplicate messages sent back to the
list and discarding them.

@_date: 1993-11-04 23:57:42
@_author: Eric Hughes 
@_subject: Signing keys for nyms 
re: my protocol for determining whether your pseudonym server is
spoofing your public key distribution.
The pseudonym server may deny service, that is either refuse to pass
the email at all or corrupt the container (a piece of email) so that
no message is sent.  As the owner of the pseudonym tries the protocol
multiple times and never gets a response, alteration at the server
become more plausible.
What the pseudonym server cannot do is read the contents of the
incoming message.  If this message contains a bit of data that was not
passed through the server, either a signature made by the
match-and-remail server or by an arbitrary number passed through the
anonymous channel, then the pseudonym server cannot make a valid
message to substitute for the return message.  The pseudonym server
can substitute any arbitrary message it cares to, since it does have
the pseudonym's true public key, but it cannot know what to put in
such a message, either because it does not hold the private key of the
M&R server or because it has never seen the arbitrary number passed
out of the other channel.
If the pseudonym server is signing keys, it will have to send one
certificate on the true key to the owner of the pseudonym and one
certificate on the false key.  The certificates have different keys
and the same identifier.  This pair of certificates, exhibited side by
side, is prima facie evidence of alteration of keys.  This is the
situation that I was speaking of.
The certificate that a pseudonym provider signs asserts the following:
"I certify that this key K is a key of name N who can be reached at
address A for which I provide final delivery."  Let us assume that the
pseudonym server is propagating a false key; we may also assume that
the false key has a certificate as above.  If the pseudonym owner is not using a public key, they're screwed.
The identity is the public key, not the email address, which is only a
form of delivery.  The server is asserting that a cryptographic
identity is reachable at that address, but the pseudonym owner thinks
that mail delivery is sufficient to prove identity.  In fact, a
cryptographic identity _is_ reachable at that address, it's just that
that identity is not the one whose mailbox it is.
In Hal's situation, the pseudonym owner claims that the server is
distributing a false key.  Immediately after such an claim, the first
question will be "Well, where is your public key and the certificate
made by the server?"  Unless the pseudonym owner can exhibit these,
the accusation holds no weight.

@_date: 1993-11-08 11:23:03
@_author: Eric Hughes 
@_subject: Private and Public 
I think that increasing the ability of parties to transact in private,
such that neither the contents nor the existence of a transaction is
revealed, is a Very Good Thing.
I do not believe that it is prudent for governments to continue to
fund themselves on transaction taxes, such as income tax.  Government
exists primarily because of the facts of geography, properties of
territory and boundary.  The digital world is not a geographic one,
and the geographic model of government is not appropriate for it.
Please respond to my personal email address.

@_date: 1993-11-08 14:58:24
@_author: Eric Hughes 
@_subject: Private and Public 
I specifically asked for responses to my morning's short note on tax
to be directed to my own mailbox.  I do not intend to discuss it in
this forum.  I post this message here to repeat my request.

@_date: 1993-11-09 13:48:40
@_author: Eric Hughes 
@_subject: ADMIN: Are we gatewayed to Usenet? 
Gateways to local usenet groups are fairly common for the list.  CMU
is behind one, and there are several others.  The most frequent reason
given is that it is easier to read a large list with news software
rather than mail software.  (I am just passing this own; don't quibble
with me over it.)
What I find most interesting is that I cannot identify where netcom is
getting their feed from.  None of the netcom addresses on the
distribution list appear to be gateway addresses, nor have I heard
from any netcom administrator about making such a gateway.
There are 34 netcom accounts on the list.  Perhaps if enough of you
asked where this distribution came from the answer would appear.

@_date: 1993-11-09 22:53:47
@_author: Eric Hughes 
@_subject: How long before Mr. Hughes CENSORS me? 
I have forwarded the recent ld231782 posting to the relevant
postmaster.  There is no need for others to do likewise, although at
this point I definitely think other complaints are in order.

@_date: 1993-11-09 23:23:29
@_author: Eric Hughes 
@_subject: the Amusements of Cypherpunks 
Posting private mail you have received, however rude, onto the
cypherpunks list is unwelcome and annoying behavior.  Please do not
continue to do this and other disruptive behavior.

@_date: 1993-11-10 12:03:21
@_author: Eric Hughes 
@_subject: Applications of cryptography 
There's no need.  Go out and buy Bruce Schneier's new crypto book
whose title I forget.  I has exactly the selection of articles you
want and comes with source code.
Cody's here in Berkeley has four copies on order; I'll bet they sell
out in a week once they arrive.  Bruce was offering to send people
copies in exchange for a check; details were on sci.crypt.
I'm sure there are interesting topics in there that you'd want
covered, but there's no need to duplicate the effort of a fellow who's
worked on this for a couple of years.

@_date: 1993-11-10 22:39:02
@_author: Eric Hughes 
@_subject: L. Detweiler's latest rant on comp.risks 
I would suggest that everyone with any interest at all in the latest
L. Detweiler rant, which appears on comp.risks, to send a short
message to RISKS attesting to the separate existence of the following
individuals, as listed by LD at the end:
In particular, I'd like to see short messages from each of the above
people to RISKS attesting to their own individuality.  Also, if LD has
accused you in public or private of not existing, please send a
message stating this.
The address is
Keep your comments short and polite, and mention "L. Detweiler" in
each of them.  We need everyone who has been involved to send a
Please speak out.

@_date: 1993-11-10 23:19:02
@_author: Eric Hughes 
@_subject: A short response to L. Detweiler: 'I exist as myself.' 
L. Detweiler's recent article on the RISKS of confusing an online
identity with a potentially knowable physical one are quite
interesting, if hypothetical.
I would be interested in hearing of situations where this practice
has actually occurred.  If any RISKS members know of any such
incidents from first-hand experience, please share them with the
Unfortunately, I think he really believes that the cypherpunks mailing
list has been dominated by a small cabal who have been using multiple
identities who talk with each other on the list in order to enforce
concensus and to suppress disagreeing positions, namely his.
It just ain't so.  Therefore, to set the record straight I feel I ought to make the
following public statement:
I, Eric Hughes, have never posted or communicated in any name other
than my own.  I can personally testify that I am not the same as any
of the other people listed at the end of L. Detweiler's post, and I
can testify from personal experience that Arthur Chandler, Hal Finney,
Tim C. May, and Nick Szabo are all different people.
I also decline to answer, point by point, the numerous defamatory
innuendos made by L. Detweiler against the members of the cypherpunks
mailing list.  Might I also observe that none of the statements are
specific enough to actually count as accusation, but merely as general

@_date: 1993-11-10 23:29:02
@_author: Eric Hughes 
@_subject: On my recent Bcc: to cypherpunks 
I just forwarded my own contribution to the RISKS digest.
Please, do not reply to the risks at csl.sri.com address unless you are
submitting something for publication!
I realized too lat what a blind carbon copy would do to repliers on
the mailing list.  Aack.

@_date: 1993-11-10 23:29:37
@_author: Eric Hughes 
@_subject: Meeting Saturday 13 Nov 93 
Bay Area Cypherpunks Meeting
Time: 12:00 noon - 6:00 p.m.
Where: Cygnus Support Offices, Mt. View, CA
This month we have planned so far the following:

@_date: 1993-11-19 12:21:58
@_author: Eric Hughes 
@_subject: All our eggs in one basket? 
Unfortunately for this idea, when the bank uses a blind signature to
issue coins, it doesn't know what coin it just issued actually looks
like.  The bank signs a blinded form of the coin.  The blinded form is
unblinded by the withdrawer, and the bank cannot know what it looks

@_date: 1993-11-19 14:21:58
@_author: Eric Hughes 
@_subject: All our eggs in one basket? 
In fact, if the bank signs a committment to give you a particular
coin, the bank can't claim to have never received your request.  For
high value transactions where timeliness is a concern, this prevents
the bank from claiming that they didn't get the original request and
thus making a "delay of service" attack against you.  Delay of service
is the denial of the service of timeliness.

@_date: 1993-11-19 14:26:59
@_author: Eric Hughes 
@_subject: Digital futures - the catastrophic edge 
re: # parties != 1 knowing secrets
The secrets in cryptography are too long to be memorized.  Therefore,
some computer hardware will need to be the storage container.  Secure
containers for such secrets can be constructed at much less cost than
the value of having the secret escape.  Since secrets come in
different levels of value, so will containers.
Since the secrets are data, they can be backed up as well, with a
variety of redundancy mechanisms and social constraints.  One can use
encrypted data with human-recallable pass phrase (as PGP secret keys)
or secret sharing to multiple trustees, or a combination.

@_date: 1993-11-27 20:14:19
@_author: Eric Hughes 
@_subject: 900 MHz Cordless question 
The two companies were VLSI Technology, who did the manufacturing, and
Mycotronx, who did the design.

@_date: 1993-11-27 20:34:45
@_author: Eric Hughes 
@_subject: On generating all primes less than 2^x 
re:  generating all primes less than 2^x
The basic fact of number theory here is the prime number theorem,
which says that (for the purposes of this problem) the number of
primes less than N approaches N/ln N.  For N=2^192 (say, for cracking
384 bit PGP keys), that number is 2^192/133, which is about 2^185.
The number of bits necessary to store all of these primes is even
larger.  A gigabyte is only 2^38 bits.
In plainer language, there's just too many to store.  This same
calculation also explains why there will never be a shortage of

@_date: 1993-11-27 21:04:19
@_author: Eric Hughes 
@_subject: Banning any subscriber 
Basically, yes, except for signed letters from previously
authenticated pseudonyms.  This is a simple form of a positive
reputation system.  A kill fill is a negative reputation--'not that
person'.  A positive reputation rejects all but a particular set of
Much of the debate on cypherpunks magically incants 'reputation
systems' to solve all sorts of sticky problems, but none have ever
been implemented in software, except for killfiles, which are not
effective against disruption in an anonymous environment.
Necessity is the mother of invention.  A motivated individual trying
to disrupt a communications forum and who has to avoid a kill file
will be necessary to create the need for a positive reputation system.
Once the need is there, the software will follow.  LD could become the
most valuable participant in the endeavor of creating a positive
reputation system, namely, the irritant at the center of the pearl.
Let us encapsulate him well.

@_date: 1993-11-27 21:14:20
@_author: Eric Hughes 
@_subject: On derivative information products 
I've never really made clear what is OK to do with cypherpunks list
material and what is not.  The answer is easy:
Hal Finney runs an encrypted cypherpunks list which sends you an
encrypted version of the main list.  Great.  If someone wants to
create edited or digested versions, fine by me.
If someone wants to create an LD-free list, it's OK by me.  In fact,
those who for whatever reason still pay by the message may want a
ranter-free list just to cut down their charges.
If you think you don't have the resources to do stuff like this
yourself, that's incorrect.  The cypherpunks remailer can be hacked to
run all sorts of email services out of a user account.  If you want
some special feature in the mailing list, do it yourself or convince
someone to do it for you.  If you want some feature and will not be
doing the implementation, feel free to ask on the main list for
someone to do it.

@_date: 1993-11-29 13:07:15
@_author: Eric Hughes 
@_subject: Banning any subscriber 
The point is not to erect insurmountable barriers against anonymous
newbies.  In an environment where 'free speech noise' is a problem,
some barrier to entry should be expected.  The cypherpunks list
already uses one barrier to entry, namely, we use a mailing list
rather than a newsgroup.
Pseudonyms don't come free, neither in time, effort, nor money.
Authentication, in this context, can take many forms.  It could be as
simple as sending a key to the mailing list server.  It could be
developed to require someone to vouch for the pseudonym.  It could
require a sponsor who would read and repost until a separate
reputation develops.
The point is to put a bound on the noise from disrupters both
inadvertent and intentional, not to completely prevent noise.

@_date: 1993-11-29 13:37:17
@_author: Eric Hughes 
@_subject: Let's Talk About Solutions 
I'll second Mike's statement by repeating a maxim I periodically need
to repeat here:
It is certainly much easier to create privacy systems that are
difficult to install and require much background knowledge about the
computer system in question than it is to create systems that are
simple to install and reliable to use.
If we create systems that only we ourselves can use we have
accomplished nothing particularly significant.  Only widespread
deployment counts in the long run, and that won't happen without easy
As much as I like what Mike Diehl has been working on, I don't
consider it complete.  The installation is far too tricky.  I'm
certainly glad he wrote it, and I'm glad he released it so that it can
be evaluated on technical grounds, but it's early to say that it's
ready for an average user.

@_date: 1993-11-29 14:22:02
@_author: Eric Hughes 
@_subject: Let's Talk About Solutions 
re: on forum disruption
I agree with this, I really do.  Nevertheless, I think this
characterization incomplete in two ways.
First, let us stipulate that for the near future the notion of the
named group, whose members are all expected, more or less, to share in
a common discourse, will remain useful and desirable.  The sharing of
discourse creates a group history, which in turn creates a group
identity.  The lack of completeness in Mike's characterization is to
recognize that group participation is not completely individualistic,
that to gain the benefits of a common discourse it is necessary to
participate in that discourse by saying one thing and not saying
Stricture creates structure.  The bottom up solution is not merely the
elimination of stricture but rather to increase the ability to choose
structure.  In a truly free society one has the ability to limit one's
freedom for whatever purpose desired.
Cypherpunks is like this.  I have no theoretical problem with turning
off list disrupters, although I do consider it a grave action.  It is
the practice of the list to broadcast anything requested to be
broadcast, yet this does not make this forum a public forum.  Each
person on the list has transferred, _de facto_, some agency to the
maintainer (that's me) about how the list will operate.
The second incompleteness is remedied by explictly referring to
transferability of preference.  One thing the extropians list software
does right is to allow filtering at the server; this is a transfer of
preference and can be an economic optimization.  Bottom-up solutions
are incomplete to the extent that they require the solution to remain
at the bottom.

@_date: 1993-11-29 17:57:15
@_author: Eric Hughes 
@_subject: really hiding encrypted data 
This may be.  The connection is not obvious, but there may be
correlations because of data conversions, mechanical scanner
characteristics, etc.
The first step in any such system which more closely hides data is to
study carefully the statistics of base images.  Until you understand
them, any attempt at mimicking them is bound for failure.
Seeking a good understanding of the statistical properties of messages
of various sorts is generally missing in cypherpunks activity.  The
area gets quite technical, and we as a group need to develop some
better understanding of it.

@_date: 1993-11-30 10:47:42
@_author: Eric Hughes 
@_subject: Banning any subscriber 
It's a positive reputation system (+RS), albeit primitive, but the
reputation system (RS) as such is not in software but rather in the
minds of those who must explicitly include what they want to see.
What the extropians list sofware (ELS) is in this case, as software,
is an information system that can support a +RS, but not that system
itself.  The distinction is fine, and not always easy to see.
Now I was careful not to claim that RS's had never been implemented,
but rather never implemented in software.  The ELS is almost a +RS,
but not completely so.  A +RS must have a database of objects (people,
threads, topics, lists, etc.)  to be sure, and some sort of statement
about preferences about these objects, but database is not per se the
The key that distinguishes an information system from a RS are the
rules of inference which connect the _preferences_ in the database to
_actions_ on the objects of the data.  The ELS does not contain
preferences at all but rather directly stores the actions on the
objects.  The connections between the preferences and the actions are
in the minds of the users of the ELS.
One can argue that the actions themselves represent the preferences,
but this is an argument to justify an existing design.  Ontologically
("what it is") preferences about objects and actions on objects are
different things; my attitude toward something is different than what
action I take toward it, although these may have been less
distinguishable when I was, say, fifteen.

@_date: 1993-11-30 15:32:51
@_author: Eric Hughes 
@_subject: Statistics of Low-Order Bits in Images 
An excellent idea.
It's not the imaging software which need do this, but the
steganography software.  The only addition is a random number source
and a way of using that instead of a file.

@_date: 1993-10-02 09:38:47
@_author: Eric Hughes 
@_subject: No Subject 
It's much more expensive to read a shredded document than an integral
one.  As always, though, if the expense to reconstruct is smaller than
the value of the documents, one should use a better method.

@_date: 1993-10-02 09:58:47
@_author: Eric Hughes 
@_subject: Single Value Pseudonyms 
Karl Barrus posted this, and I've been meaning to respond to it.
Basically, Karl's scheme doesn't work.  With any cut-and-choose
protocol, there must be some assurance that the two things offered are
the same thing, and, in a series of them, that all the things offered
are the same thing.
With a blind signature, the signature itself is that which has value,
not the thing signed.  Basically yes.  More accurately, the bank has one key for each
denomination for each particular time range.  The key is the
significant entity here, not the user name.  The blind signer could
make a regular signature attaching a name to that key, of course.

@_date: 1993-10-04 15:44:46
@_author: Eric Hughes 
@_subject: damn fine compression.... 
Read README.DOWNLOAD in the pub/cypherpunks directory.

@_date: 1993-10-05 13:19:09
@_author: Eric Hughes 
@_subject: Crypto Idea; Multi-Part Sigs 
You can, but the key can't be a regular RSA key.
That's right, don't use RSA as such.
Choose two RSA keys.  Make one as Hal describes for signing.  Use the
other one for receiving.  The public key in this system is a pair of
public RSA keys.  You break symmetry, and lose automatic PGP support,
but it seems to have the characteristics required.

@_date: 1993-10-07 09:55:42
@_author: Eric Hughes 
@_subject: ADMIN: required knowledge--how to get removed from the list 
I have a form letter, included below, which I send to people who ask
the list at large to be removed.
Unfortunately, I suspect that many of the people who wish to be
removed have already stopped reading the list, so that messages which
explain how to get removed are not read.

@_date: 1993-10-07 10:35:32
@_author: Eric Hughes 
@_subject: Monthly Bay Area cypherpunks meeting 
What: October monthly cypherpunks meeting
When: Saturday, October 10, 1993
      12:00 noon - 6:00 p.m.
Where: Cygnus Support offices, Mountain View, California
       (directions below)
The Bay Area cypherpunks meeting is the second Saturday of the month,
every month, at the Cygnus Support offices.  All are welcome and
encouraged to attend.
Here's what I know about for Saturday's meeting:

@_date: 1993-10-07 12:05:32
@_author: Eric Hughes 
@_subject: Correction in Bay Area meeting announcement 
The meeting is Saturday the 9th, not Sunday the 10th.  Sorry for the
The Bay Area meetings are always on Saturdays.

@_date: 1993-10-07 14:35:56
@_author: Eric Hughes 
@_subject: Weak RSA keys? 
Re: finding weak keys
The point with weak RSA keys is not that one can find other decryption
exponents deterministically given public information, but rather
probabilistically.  If gcd( p-1, q-1 ) is large with respect to pq,
then one can simply do a random search for these other exponents.
Greatest common divisors are quick to calculate, so there's no
practical problem with making sure that one does not generate weak
The rest of this message is a mathematical explanation of _why_ there
are at least two decryption exponents.
Warning: technical algebra follows.
Short answer: (Z/pqZ)^* is not a cyclic group, and therefore does not
contain elements of maximum order, i.e. of order (p-1)(q-1).
(Notation: the group above is the multiplicative group of numbers
modulo pq.)  The largest order of any element is lcm(p-1,q-1).
Longer answer: (Z/pqZ)^* is isomorphic to (Z/pZ)^* x (Z/qZ)^*.  The
isomorphism map is I: x mod pq |--> ( x mod p, x mod q ).  Let f =
gcd(p-1,q-1) and F = lcm(p-1,q-1).  Define f_p = (q-1)/f and f_q =
(p-1)/f; both are integers.
Note that since Ff = (p-1)(q-1), F = (p-1)f_p = (q-1)f_q.
I( x^F mod pq )
The last step follows by Fermat's Little Theorem.  Since the
isomorphic image of x^F is (1,1), we conclude that x^F == 1 (mod pq),
for all x.  (To see this, use the Chinese Remainder Theorem.)
Since p and q are both odd, p-1 and q-1 are both even.  Thus their gcd
must be at least two.
Out of curiosity, does anybody here know how to calculate any
expectations for gcd(p-1,q-1) for, say, 2^n < p < q < 2^(n+1) ?  I
don't know enough number theory myself.

@_date: 1993-10-10 07:56:04
@_author: Eric Hughes 
@_subject: DC-Net proposal,  comments requested 
Indeed, the DC-net protocol operates in any abelian (commutative)
group, such as, say, integers mod 2^56 (the size of a ping packet
body).  The modulus need not be a power of two, but there's little
advantage if it's not.  The vectors in a linear code might also be
appropriate for certain side effects.
In practice, this is a small problem.  Since many of the messages that
a deployed DC-net sends out will be text encrypted for some particular
destination, one needs no greater computational security than that of
the cipher used to encode the message.
There are several random number generators provably as secure as the
hard number-theoretic problems used for public key cryptography.  The
problems include quadratic residuosity, factoring, and discrete log.

@_date: 1993-10-10 08:21:05
@_author: Eric Hughes 
@_subject: The Bank of the Internet!? (fwd) 
Zeek forwarded a message written by Arthur Chandler which appears to
have appeared on Future Culture.  This reply is going both to the
cypherpunks list (worldwide) and also to the austin-cypherpunks list
(a locality); some comments may be obvious for one group or the other.
There are several small factual details incorrect in this post, most
of which I will not try to correct.  As he said, "I'm oversimplifying
all this."
One in particular, though, should be.  The EFF is not "backing" a
credit union, at least not the national organization.  Members of
EFF-Austin, a local chapter of the EFF, (well, the only local chapter,
but that's another story) are looking to form their own credit union.
Their efforts will provide a model for other such efforts.
True, it will use the "internet as the monetary highway" (a phrase I
delight in), but at least at the outset will neither issue digital
money nor deploy internationally distributed secret sharing.  I did
talk about both of these, but not as specifically regards any
particular financial project.

@_date: 1993-10-10 09:06:05
@_author: Eric Hughes 
@_subject: Virtual City (tm) Network FAQ 1.0 (fwd) 
On money in Virtual City:
First, a note of history.  Strata and I have been talking about money
in MUD-type environments (virtual, social, text-based).  These
discussions are reflected in her document.  I had decided after much
thought that the MUD type of environment would be a good place to
prototype electronic money.  I asked Strata about technical details,
since I knew that she was setting one up; discussions ensued.
A comment from Joichi Ito, a self-professed MUD enthusiast, which he
made to me at CFP-93 in March, started this train of thought: "I would
pay real money for MUD money."  He spends enough time on MUD's that
his personal life would be improved by spending cash dollars in
exchange for increased ability on the MUD.  One of the big problems in creating electronic money is that there
must be something to spend it on, that is, some notion of actual value
upon which to base the derived value of the electronic money.  MUD's
seem to have that property.  I don't know exactly whence that value
arises, but certainly it does factually exist.  This question, the
origin of value in MUD's, will develop a life of its own, no doubt, as
various explanations arise, but this question is not central to any
monetary system.  What is needed is only that such value exists.  Let
us stipulate this for the purposes of discussion.
Once there is value, an economy develops when there is a means of
exchange for such value, typically coins.  So the MUD needs a notion
of exchange and a notion of representation of value.  For exchange,
I've designed a conceptual MUD object which is a simultaneous
transacter.  You put your stuff on the tray in front of you, likewise
does your trading partner.  After you both press the big red buttons
in front of you, the contents of the two trays are magically
interchanged. (Magically, of course, since this is a MUD.)  Recall
the big rotating lucite contraptions that post offices are using.
In the MOO (MUD, Object Oriented), one can subclass this transacter
and attach robot servers to the other side of the glass, creating
vending machines.  One particular vending machine could take the coin
of the realm and exchange it for a bank note of the same amount.  The
bank note, digitally signed by the MUD bank, is an informational
object.  Because it is information and not a MUD object, the note can
be freely transmitted _outside of the MUD_.
Once you have the existence of such notes, one can set up inter-MUD
currency exchanges, test the theory of free banking, and the like.

@_date: 1993-10-10 09:29:42
@_author: Eric Hughes 
@_subject: Diffie-Helman example in g++ 
Notation: here 'a' is the base of the D-H exponentials.
Certainly.  ;-)
D-H works, i.e. a key is agreed upon, even if 'a' is not a primitive
root mod p, but the security may be adversely affected if it is not.
If 'a' is not a primitive root, then size of the search space which
the exponentials may take will be less than maximal.  In fact, the
order of the element 'a' gives the number of such possibilities.  (The
order is the smallest power of an element that is equal to the
Nope.  Being relatively prime to p-1 is not even involved.  Here is
the actual condition for primitivity:
   For every prime q which divides p-1, a^((p-1)/q) != 1 (mod p)
By Fermat's Little Theorem, x^(p-1) == 1 (mod p), for all 'x'.  Now
'a' is primitive if p-1 is the smallest such number.  Since the order
of an element much divide the order of the group, if no divisor d of
p-1 is such that x^d == 1 (mod p), then p-1 must be the smallest.
Burt Kaliski, of RSA Labs, told be he picked a D-H modulus p such that
p = 2q+1, where both p and q are prime.  It took a long time to find
such a pair.  The advantage is that almost half the elements of such
a field are primitive roots.

@_date: 1993-10-12 18:26:34
@_author: Eric Hughes 
@_subject: Virtual City (tm) and Virtual Capitalism 
I wish to clarify a point here.  The system as I envision it would not
have a single currency.  Rather, each MUD/MOO would create its own
currency or currencies.  Interdomain transfer would be accomplished by
trading promissory notes.
As to what the money buys, at the very least it could buy those things
which resolve down to CPU time and disk space and network bandwidth.

@_date: 1993-10-18 00:02:09
@_author: Eric Hughes 
@_subject: on anonymity, identity, reputation, and spoofing 
[...] That which can never be enforced should not be prohibited.
The claim that a person should have only one pseudonym per forum
indicates profound misunderstanding.  If someone wants to have
multiple cryptographically protected pseudonyms, they will be able to;
that is one of the main goals of cypherpunks software.
The situations you despise will occur.  This is reality.  Change your
own psychology or change your own software.  You will not be able to
change the other person.

@_date: 1993-10-18 11:22:15
@_author: Eric Hughes 
@_subject: ANON: _The Economist_ on South Korea 
The 11 Sep 93 Economist had an article on South Korea called "Too
clean for comfort" about their president Kim Young Sam and his
political housecleaning.  I excerpt a relevant passage.
      [...] One of Mr Kim;s first presidential acts was to bare his
   assets.  Then ministers, MPs and top civil servants were all
   required to disclose their net worth.  To no one's surprise, while
   the president's people were mostly clean, many of the old guard
   turned out to be rolling in wealth whose origins they could not
   readily explain. Many resigned.
      The "real names" reform, announced on August 12th, was Mr Kim's
   most radical step yet.  The issue had been hotly debated for over a
   decade.  Hitherto South Koreans had been able to keep bank accounts
   in any name they cared to invent; convenient for tax evasion, and
   for recycling the cash-stuffed white envelopes that for decades
   have routinely oiled the country's wheels of business and
   politics alike.
      Mr Kim struck out of the blue.  Only the secret task force
   drawing up the plan knew about it; they had told their families
   that they were on a course in America.  Even Mr Kim's cabinet was
   informed only an hour before the public announcement.  Not a word
   leaked out.
   [...]
      Anyone who upsets so many applecarts risks making himself a lot
   of enemies.  But Mr Kim's positioning is good.  Anyone who speaks
   out against real names or asset-baring must surely have something
   to hide.  Conversely, the whole campaign is widely popular with the
   public, chiming as it does with the widespread perception (even in
   a country with one fo the world's most even distributions of
   income) that fat cats are licking off the cream.
A new target market?

@_date: 1993-10-22 09:28:17
@_author: Eric Hughes 
@_subject: Backing 
I have only one small quibble with Perry's recent comments.
The question is not a bald one of access or no access, but one of
quantity obtainable in aggregate and timeliness of such accrual.
Experiments with LETS systems have shown that local economic activity
does improve in depressed cities when a barter currency is introduced
to supplement a paucity of the nominal national currency.  The city I
seem to remember is Manchester, England.
LETS (I forget the acronym expansion) is a barter system with a
virtual fiat currency.  Originally it used just a ledger; later, PC's
were used to keep the books.  The currency was zero-sum; all accounts
added to zero.  Reputation was provided by making all aggregate
balances public to the members of the system; you could decide not to
provide services to anybody, particularly if they had a large negative
Another example of how a dearth of transfer instruments affects an
economy was 16th/17th century Venice.  Coin hoarding did become
somewhat of a problem, and it affected the speed at which business
could be done.  This era was that of the rise of 'book-gold', or in
modern parlance, fractional reserves.
Perry is certainly correct that any commodity can be used as a
backing.  Recall, however, that promises are a commodity like any
other.  This is the unification of fiat currencies and gold
currencies.  It is also a basis for understanding that multiply
backed currencies can and do coexist stably.
Promises are not as fungible as gold is of course, which is one reason
that LETS systems do not scale well, since the characteristic effort
and communication needed to evaluate the worth of such a promise (even
an averaged promise as in a LETS system) is far greater.  One can
understand the rise of options markets as an effort to increase the
fungibility of the option promise, given that these markets are not
merely communications systems but also have some capacities as
guarantors and insurers (broadly construed).
Digital money has two characteristics that pertain to these issues:
denomination size and access.  The smallest denominable amount is not
limited in any virtual system (bank books included), whereas when in a
strict commodity system the unit of transactability may be too high
and cannot be infinitely subdivided.
For example, gold Spanish doubloons (from which the English 'dollar'
is a corruption) were too large for many transactions, so people made
them small by cutting them into eight 'bits', whence the equation of
'two bits' with a quarter.  But gold is not infinitely subdivisible,
but representations are.
The question of access arises as well.  Just as a LETS system is a
very econopunk system, digital money can be issued by any one person
or any group.  If no other backing is available, they can back it with
their own time and talent.  When these currencies can be easily traded
with other currencies, the problem of access to a more dominant
currency is alleviated.  These promises, being limited to a particular
geographic locale, are not fungible, but then lack of fungibility does
not so much prevent exchange as present some market-priced impediment
to it.

@_date: 1993-10-22 18:32:59
@_author: Eric Hughes 
@_subject: crypto technique 
I've looked at Matthew Ghio's encryption technique and have some
comments.  First let me summarize the system.
private key: a sequence of polynomial functions f_1, f_2 ... f_n of the
  form a_i x (x+1)/2 + b_i, where a_i is odd.
public key: the composition of these functions f(x) = f_1 ( f_2 ( ... f_n(x)))
  and a modulus P = 2^k
plaintext: a value 't'
ciphertext: the value u = f(t)
decryption: finding t such that f(t)=u, by using of the f_i
Matthew has repeatedly claimed that it can't be broken.  Now one of
the first rules of cipher design is don't claim that unless you have
some good reason to believe that it can't be broken.  Merely saying "I
can't figure out how" is NOT sufficient.  No flame intended, Matthew,
this is probably the single most common failing of people interested
in crypto.
In particular, Matthew has made the claim that one must find the
coefficients of the f_i in order to decrypt and claims that finding
such coefficients is difficult.  He calls this operation factoring;
properly speaking this is a 'decomposition', since the operation used
to make f(x) is not multiplication by composition (called iteration
when all the functions are the same).
As I suspected and Karl has demonstrated, these decompositions are not
unique.  Since the plaintext, ciphertext pair does not depend on the
representation of the function, only upon the coefficients of the
polynomial function which is the public key, any such decomposition
will suffice for decryption.  In other words, you don't have to find
how the function was created in order to decode.  All you need is some
way of inverting the polynomial function f(x).
Note that I am using the phrase polynomial function here, and not just
the word polynomial.  There is a big difference.  Polynomial functions
are real functions with a domain and range.  Polynomials are elements
of a ring created by adjoining an indeterminate 'x' to some ring.
Polynomials can be 'evaluated' as polynomial functions under some
circumstances, but not always.
A side note.  The function Matthew picks, 1/2 x(x+1) is not, properly
speaking, a function with coefficients in Z/2^k (integers mod 2^k).
It is, however, a coefficient in Z/2^{k+1}
There's one significant difference for the purposes of this proposed
cipher: polynomials have arbitrarily large degree, but every
polynomial function over a finite ring (such as integers mod N) is
equal to some polynomial function of finite degree.  One can see this
easily be recalling Fermat's little theorem a^N == a (mod N).  Thus
x^N == x (mod N) for polynomial functions, which limits the degree.
Matthew has proposed that arbitrarily many compositions will give a
function which can't be inverted.  This is certainly not the case if N
= 2^k as he proposes.  The following relation holds for all integers
n > 0 and for all integers t:
What this means is that as the 2^k grows larger, the maximum degree of
the polynomial functions grows as 'k', not as 2^k.  In other words,
the degree grows as the logarithm of the modulus, or linearly in the
number of bits in the modulus, if you prefer.  This is certainly not a
good sign.
Recommendation: don't use N=2^k.
It's a general rule of cryptosystems that if you use 2^k moduli to
speed your encryption, you will also speed the attack, and not just
from increased speed, but from algebraic properties of these moduli.
There have been some spectacular failures in this regard, notably a
chip which was built to do modular exponention for a particular 2^k
which was later found to be totally insecure.
Another property which decreases the security of the scheme is that
polynomials over Z/2^k don't have unique factorization.  Therefore the
polynomial functions don't have unique representations.  For example
This makes it all the easier to invert the polynomial.  The reason
that you don't have unique factorization is that Z/2^k has zero
divisors: 2 x 4 = 0 (mod 8), so two divides zero.  The presence of
zero divisors means that you don't get unique factorization.
There is, however, a twist.  If you don't even see the zero-divisors,
you can pretend they aren't there.  This is exactly what RSA does,
since if you find a multiple of one of the factors of the modulus,
you've broken the system.
But if you use a modulus of the form pq, you're basically using RSA!
RSA picks a particularly easy polynomial function to invert, namely
f(x) = x^e.  Other polynomials would work as well, and, in fact,
appear in the patent application, albeit without examples.
Now if you pick a prime modulus, you don't have a public key system
anymore.  This is the Hellman-Pohlig patent, which uses x^e (mod p) as
its encryption.  In this scheme 'p' is kept secret, since otherwise
the exponentiation could be reversed.
In short, I don't think Matthew's scheme can be made to work.  There
is an open question about how the base field increases with each
composition because of the presence of the 1/2, but I don't think
currently that this makes it work.
For a specific reference, see the collection _Cryptology and
Computational Number Theory_ which contains an essay by Kevin McCurley
"Odds and Ends from Computational Number Theory."  Section 3 of this
essay discusses the breaking of some similar schemes by some
non-obvious means.  I quote: "Moreover, it holds a valuable lesson for
those who tend to believe that a computational problem is difficult
just because the only apparent solution is difficult."

@_date: 1993-10-23 10:43:06
@_author: Eric Hughes 
@_subject: ADMIN: proposed new policy on the mailing list 
Cypherpunks is an experiment in anarchy whose participants share
overlapping concerns with respect to privacy and cryptography.
One of the commonly shared goals of the participants in this group is
to change the technical context of the political debate about
cryptography.  This goal has not been reached, nor even has very close
approach been made as yet.  I believe that we have been successful in
inculcating, at least in ourselves, a set of values and attitudes
toward encryption .  Unfortunately this mental presence has not
blossomed into actual culture and practice, although we have attempted
and practiced.
Not all systems are self-organizing, and ours is not dissipative in
the right way.  Therefore in true micro-Keynesian fashion, I am
considering creating an artificial inducement toward cryptography on
this list.  You will be, of course, free not to participate.  The
rule I am considering is the following:
   Digitally sign your articles or their transmission will be delayed.
In terms of email privacy, we have not yet even reached the level
where content encryption is standard.  Since software to make digital
signatures is almost always the same software needed for encryption,
and likewise for signature verification and decryption, an inducement
to sign one's posts will be also an inducement to encrypt.  At the
very least it requires some change in the status quo of one's own
email system.
The hampering above will not be outright rejection, since the cost of
rejection creates a step function to participation, an insurmountable
hurdle for most of us.  Rather I am considering hampering posts by
delaying their transmission, by destroying some of their timeliness.
Timeliness, as I analyze it, will be one of the few things that have
economic worth in a post-copyright environment.
Delaying unsigned posts does not prevent people from participating,
merely from getting very close the topicality of discussion.  If you
are debating delayed against an undelayed correspondent, you will be
at a disadvantage, as your points may be immediately responded to, but
the other's points will stand unopposed for longer.  Truth, in other
words what _you_ believe, might triumph eventually, but practical
epistemology is more a matter of rhetoric than of validity.
Nor does it prevent occasional use of the forum by lurkers and
learners.  The first article on any new subject has very little time
value, rhetorically, but the question still gets asked.  Furthermore,
it will tend to slow down debate, at least for a while.
My initial thoughts are that the delay should be about six hours,
which would limit the number of salient responses of the unverifiable
to about one per topic per day.  As more and more people begin to sign
their posts, that delay would be increased.  I have considered more
sophisticated schemes, such as allowing automatic delayed moderation,
which sends you back a ticket that allows immediate posting, but after
some number of hours, or perhaps longer delays for unsigned repsonses
to signed articles, but I think that a simpler system will work
better, certainly at the outset where people are coming to grips with
delay's effect on the discussion.
I invite discussion of this proposal on the list itself.  If you only
wish to express approval or disapproval, that is, to "vote", please do
so only in private e-mail to me.  I welcome further analysis of this
idea as well as evaluations of its desirability or odiousness in your
own value system.

@_date: 1993-10-23 14:18:29
@_author: Eric Hughes 
@_subject: ADMIN: proposed new policy on the mailing list 
So far I have received six comments on the proposed sign-or-delay
system, two in public, four in private.  All have been supportive of
concept, but there have been specific technical issues with it.

@_date: 1993-10-28 11:18:08
@_author: Eric Hughes 
@_subject: Signing our keys 
The key is the identity, period.  Let's get that straight up front.
Signing a key does not change the identity.
Signatures on keys are attestations that the key belongs to some
person or email address.  Signing a key attests that an identity has a
I've developed a criterion for signing pseudonym keys.  The only party
(other than the holder) who can gain any certain knowledge that an
e-mail address maps to the holder of a given key is the provider of
the e-mail address.  In other words, Julf's server should sign
wonderer's key.  The following applies to any system providing pseudonyms, i.e. mail
addresses.  The mail server should have a public key.  The public key
of a user would be encrypted with the server's public key and
forwarded to the server.  The server would accept as authentication of
this public key the same authentication that it accepts for everything
else.  Once it has the key, it can sign it and return it to the
individual, who can then publish it.
The one pseudonym is attesting that they reach the same individual
each time they send mail to the other pseudonym encrypted with the
public key claimed by that other pseudonym.  This attestation is not
as strong as person-to-person contact, but as long as the signer
reasonably believes that mail delivery system functions as it claims
to, i.e. no interposers, the signature does actually mean something.

@_date: 1993-10-28 11:48:08
@_author: Eric Hughes 
@_subject: Signing our keys 
RSA is running a persona certificate server for PEM keys.  They don't
ask for anything.  Their latest brochure diagrams these as "anonymous
internet users."  I don't know the address, but I do know that six
months ago it was running and being tested.
It would be interesting to know if such certificates worked in the new
Apple system 7.  If so, there may soon be a whole flood of Mac-owning
pseudonyms using PEM.

@_date: 1993-10-30 19:29:22
@_author: Eric Hughes 
@_subject: Signing keys for nyms 
They are certainly in the best position for good or for ill.
If the servers, however, don't sign keys, I don't think the pseudonym
can prove to a third party that alteration has taken place.  See the
protocol below, which detects signatures on false keys.
Here is such an "other method."
If a provider of any sort is the sole means of access to a series of
communications, there will be the possibility of tampering.  If some
public key must issue forth through this channel only, it is possible
to alter the pseudonym's public key each time it is passed throught
that channel.  Since every protocol which uses communications only
through the server won't work, every solution needs another channel.
Let us assume that the server is signing pseudonym keys.  We want a
protocol to detect key alteration.  If keys are being spoofed, the
pseudonym will have to be provided with a certificate which signs the
true key, but which the provider has transmitted only to the
pseudonym; everyone else sees the provider's false key.
Assume a third party cooperating with the pseudonym.  The pseudonym
sends their own public key as signed by the server--i.e. the
certificate the pseudonym has--to the third party both both through
the provider's pseudonym server and through an anonymous remailer.  If
the server is spoofing keys, the key that passes through the server
will be altered.  The message contains a random number used as an ID
to match up the two messages.  The third party encrypts the message
received from the server with the public key received anonymously and
sends it back to the pseudonym, again through the server.  The server
cannot decrypt this message, since it is encrypted with the true
pseudonym public key, not the false one.  The pseudonym then checks
that the certificates match.
The key to this protocol (and there are plenty similar) is that the
public pseudonym key is transmitted to the outside world by a
different channel than the server.  That's a necessary part of any
Note that this protocol can be completely automated.  The third party
could be another server which pairs up messages and sends them back.
Why not just send the pseudonym's certificate with an anonymous
remailer?  The reason is that, assuming that all communications to the
pseudonym do pass through the server, the pseudonym might never find
out that their own key had been compromised.  The protocol above,
while more complicated, notifies the pseudonym first of any

@_date: 1993-09-08 11:17:57
@_author: Eric Hughes 
@_subject: REMAIL: pasting 
In short, if there's a Reply-To: field present, the mailer is supposed
to reply to that address.  Some mailers don't, unfortunately.  Some
reply to the From: line in the mail, and some reply to the out of band
sender information, usually seen in the "From " line at the top of the
Let's face it, header pasting is a hack.  A very nice hack, in certain
ways, but still a hack.  As currently implemented, header pasting, be
it incoming (::) or outgoing ( is a syntactic operator, not a
semantic one.
The relevant RFC is 822, "STANDARD FOR THE FORMAT OF ARPA INTERNET
TEXT MESSAGES".  This RFC has several holes in it, however.
The syntactic structure of the header fields indicates that the only
fields which may appear multiple times are receiver fields (To, cc,
bcc, and the Resent-* version of these), Received, and the optional
fields.  (I avoid a too-long discussion of the Resent-* fields, whose
description seems to contradict this definition.)  Therefore, it is
possible to make syntactically counter-spec mail using header pasting.
It is also possible to make such counter-spec mail in emacs mail mode,
for example, but it doesn't seem to bother anybody much.
Yet RFC-822 is followed as much in the breach as in the observance.
In particular, 822 seems to specify that the recipient of the mail be
contained in one of the destination fields.  Yet sendmail takes
parameters on the command line for the destination and ignores the To:
field inside the message.  Now there is a flag for sendmail to parse
the mail and determine addresses, but this is not the default, much
less required.  I think this behavior of sendmail is good, but it does
appear to be counter to the semantic interpretation of the destination
fields as specified in 822.
My own philosophy on this is that one should never flagrantly violate
822 syntactically, and to take it semantically with a grain of salt.
What are the implications for header pasting?  I think it ought to
remain only syntactic, since the semantics that would need to be
defined do not have a solid base in specification, much less in
Yet this pasting does not allow 'overriding' of an existing header
field.  One could write an operator that removes header fields in the
context of header pasting.  In the current remailer situation, this
operator would allow one to remove the "From:" field and substitute
another--instant in-band forgery.
Whether the operators of remailers want to do this is left for

@_date: 1993-09-08 12:37:02
@_author: Eric Hughes 
@_subject: Second Annual Cypherpunks Conference 
Second Annual Cypherpunks Conference
Saturday, September 11, 1993
12:00 noon
Cygnus Support, Mt. View, California, USA
One hear ago this month, the first cypherpunks meeting was held in
Oakland, CA.  Therefore, the September Bay Area meeting is
megalomaniacally named
(but really, we'll just go out to dinner afterwards like normal.)
The theme this year is
In no particular order

@_date: 1993-09-09 11:18:12
@_author: Eric Hughes 
@_subject: Subscribe 
[Thanks for your hospitality last weekend.  The following is a form
The cypherpunks list is for discussions on implementing cryptography.
To mail to the whole list, send mail to
Every mail message sent to this address will be forwarded to everyone
on the list.  Make sure that the message you wish to send is
appropriate for such a broad delivery.
If you want to be added or removed from the cypherpunks list, or have
any other questions which pertain to list management, send mail to
I don't manage the list from my regular account, so such mail which
ends up in my ah.com account will just get you another copy of this
Eric Hughes    maintainer of the lists cypherpunks at toad.com and
   cypherpunks-announce at toad.com

@_date: 1993-09-09 11:37:22
@_author: Eric Hughes 
@_subject: REMAIL: pasting 
Even worse, there are mailers that respond to the out-of-band sender
information that appears in the first line (not in the header!) as the
"From " information.
Bounce message (almost) always go back to the out-of-band sender, so
we changed the cypherpunks list alias on toad.com to generate that as
the out-of-band sender.  Now bounce message return to a different
mailbox and my inbox at toad.com is clear for regular list
Nonetheless, I still get a number of attempted posts to the mailing
list at large _and_ requests for list maintenance (?!) to the
owner-cypherpunks alias.
If only mail software were consistent, ...

@_date: 1993-09-18 09:36:57
@_author: Eric Hughes 
@_subject: anon.penet.fi 
There is already non-pseudonymizing reply available for pseudonymous
mail.  It periodically comes up on the list, and is periodically
corrected.  The irony of the situation is that the solution was
invented on this list a few months ago.
Solution: if you send to na12345 at anon.penet.fi, then your mail won't
be pseudonymized; if you send to an12345 at anon.penet.fi, then your mail
will be pseudonymized.

@_date: 1994-04-03 08:31:52
@_author: Eric Hughes 
@_subject: REMAIL: standardized remailer syntax 
Hal sort of implies that :: came first.  Well, no,  came first,
because I wasn't thinking clearly at the time about header commands
with respect to encryption.  A minor point, to be sure.
No one should ever have to see :: and  unless they want to, much
less type them in.  The pasting syntax and all the header commands are
a back-end programming language, and really don't belong in the
average user's face.
User interface work is needed here badly.
I recommend the following four commands:
There are uses for both anonymous and non-anonymous sending of email
and posting to Usenet.  I originally used Request-Remailing-To
_because_ it was too long and not used.  It certainly doesn't need to
Hal is correct.  This was a misfeature in the original code base.
It's already supported.
In other lines of pursuit, it's time to do a MIME remailer.  The
proper MIME types would be much easier to install, as I understand it.
Perhaps those of you who use MIME (I don't) could work on this.

@_date: 1994-04-04 11:03:31
@_author: Eric Hughes 
@_subject: Cyberspace, Crypto Anarchy, and Pushing Limits 
A mathematical space need not be linear, even locally, and therefore
it need not have dimensionality.  While the use of the word space
started as a reference to our spatial experience, it has generalized
out of that restriction.
Here's how I explained it a recent cypherpunks meeting:
Insert your own conception of divine right of kings, etc., in order to
complete the analogy.  Should I ever move the list to my own hardware
and net connection, I get to be Napoleon.

@_date: 1994-04-04 11:34:49
@_author: Eric Hughes 
@_subject: Economic assumptions 
I just read (after a reference by Duncan Frissell on this list) an
essay by Nobel-prize economist R. H. Coase.  The essay is called "The
Nature of the Firm".  I have it in a collection called _The Firm, the
Market, and the Law_, published by University of Chicago Press.
This is a sure-fire antidote to the idea that "the market is the best
solution for everything".  This is the essay, evidently, that
introduced the idea of transaction costs.  Some of his basic points
are the following:

@_date: 1994-04-04 11:44:05
@_author: Eric Hughes 
@_subject: PHILIP ZIMMERMAN ARRESTED [NOT!] 
You can't get rid of anonymity such as this without also getting rid
of pseudonymity.  The first use of a pseudonym is as good as
anonymous, because it has no past history.  If the user of this
pseudonym never again uses the name, then it has no future history.
A one-time pseudonym is an anonym.
An arbitrary string of letters only become a name if it is presented
as a name and if it has persistence.  Identity is a persistence
through time of a source, be that a source of speech or a source of
action.  Without persistence there is no identity, but rather only
unconnected assertions in a formal (and sterile) symbolic system.

@_date: 1994-04-04 14:38:53
@_author: Eric Hughes 
@_subject: Economic assumptions 
[re: overload]
I only talked about text transmission, not about arbitrary bit
transmission.  The situation for automatic bit sources is not the
Look, there is a cost to using the price mechanism.  When the cost of
the thing being purchased becomes too small, it's no longer economical
to price it.  That doesn't mean that it's free.  It means there are
other structures for accounting.
One transaction per packet will almost always be more overhead than
it's worth.  There are other ways of paying for service, though, by
connection, by total bandwidth, by link.  The structure of the
transaction is different, because a different thing is being
Flat rate local phone calling is common.  The expensive part of using
a local phone switch is the switching, not the connection.
Maintaining the connection is cheap.
This is irrelevant.  The Libertarian-PC police aren't around, last I
Tim made the statement that pay-as-you-go was the obvious choice.
That's not at all obvious.  The accounting mechanisms are but one
aspect of the transaction costs involved.  It is quite possible that
the only economically viable communications services are aggregated
services.  Whenever you have aggregation, there is some persistence,
and that yields an identity.  (It need not be a personal identity.)
There are some interesting questions here.  What is the characteristic
length of that persistence?  It will vary depending on the cost to do
another transaction.  The length of persistence is the length of
exposure of an identity.  What are the forseeable tradeoffs between
link costs, switching, and general-purpose computing?  This gives some
idea about where the bounds of accounting will fall.
Analyses which disregard transaction costs are unrealistic.  The
question is not one of paying for service; let's bury this libertarian
hype against socialism right now.  The question is what the structure
of the communications market, both buyers and sellers, will be.
I want a system with low transaction costs, because that lowers the
characteristic persistence time of a communications transaction, and
the smaller the time, the better the privacy.  That means we have to
lower the transaction costs.
Let's take remailers as an example.  One current suggestion is to add
some sort of money system to the remailers as a condition of use.
This is exactly the wrong priority at the current time.  The remailers
are already hard enough to use, and adding a payment system on top of
that will make them used even less.  Making a system harder to use
increases the transaction cost.
The current priorities should be to lower these costs.  When the
remailer system begins to be overloaded, then adding some restriction
on use, perhaps by means of payment or a payment analogue, will be
warranted, because it will lower overall transaction costs, trading
off ease of use for throughput and reliability.
What are some of these costs that should be lowered?

@_date: 1994-04-04 21:06:01
@_author: Eric Hughes 
@_subject: Economic assumptions 
[re: other transaction costs]
Four words: Libertarian Political Correctness Witchhunt.
If it's not really clear that I was making a statement about
priorities, I don't think that repeating it a fourth time will help.
If, of course, I'm not all in favor of monetarizing remailers
immediately, could it be that I'm not in favor of ... money?
Are you talking about me?  It appears that you are, but I thought I
was only comparing priorities.
Enough of this.  I'd rather discuss lowering transaction costs.  rjc
comments on my list:
I point out this doesn't help if you don't know where the first
remailer is.  What I was specifically referring to was public
education.  Were remailers ubiquitous, there would be a chapter on
them in each of the latest rage of 'how to use the internet' books.
They could be a well-used service, like archie.  In fact, they are not.  There are numerous reasons for this, some of
which are self-referential (as in, there aren't a lot of remailers
yet) and some of which are not.  For example, there's no FAQ for
comp.mail.remailer, because there's no such group.  Why shouldn't
there be?
I specifically made this a separate item because it has a different
solution.  Let's assume the potential user has some beginner's
document about remailers.  How do they go about finding out what
remailers exist?
Well, the document could have a list of them, but that doesn't exactly
work well in the face of rapid changes.  Some centrality in the
initial query seems called for.  That could be a stable machine, or
some stable name, even.  What the query actually looks like is less
We need DNS or something like DNS for this purpose.  We need something
where changes can propagate outward rapidly, which pushes data out,
and unlike BIND (the standard implementation of DNS), which pulls it
in after it times out.  The standard DNS query format could be kept,
but the current back end may not quite work.
And what about users on Compuserve, AOL, Genie, Delphi, and Prodigy?
Certainly a standard way of listing the properties of a remailer would
help.  This seems to be mostly a matter of syntax.
There is, also, the question of trustworthiness.  That mythical beast
the reputation system might be applicable, but I know of none to judge
for suitability.  More generally, there are questions of policy.
What, for example, is the policy of the remailer in case of
administrative request for mappings?  Are there liquidated damages
available to someone whose privacy is breached?  These legal issues
are not so easily made into syntax.
I think the commands ought to be standardized, just like RFC-822
standardized on the To: field.  I realize this is going to create a
little havoc for the half-dozen or so remailer developers who have all
chosen not to talk to each other during their developments.
If you don't have standard commands, then you need a way of specifying
semantics for all these various commands.  Not good.
Personally, I don't think we need multiple algorithms for this.  Is
there any compelling reason, other than to avoid wasting existing but
not yet deployed code?
There's a transaction cost to switching clients which is huge.  It's
completely unrealistic to expect everyone to use a particular client
for remailers.  It just won't happen.  Far better is to rework
existing clients to support remailers and to get those changes into
the main distributions.
The dream of universal software.  When I can unpack some software and
type 'make', and do nothing else except read the man pages that 'make'
caused to be formatted, I'll call that universal software.  And not
I'm glad lowering these transaction costs garnered a response.  But
what I really want to see is, what did I forget about transaction
costs to use remailers?

@_date: 1994-04-05 12:45:27
@_author: Eric Hughes 
@_subject: CRYPT 
The first thing you want to know is what the underlying algorithm used
was.  The documentation might tell you.  The source code would tell
you.  Disassembled object code would also tell you.
Do you have any of these?

@_date: 1994-04-05 12:49:32
@_author: Eric Hughes 
@_subject: nsa digital cash? 
This statement betrays an enormous ignorance at the scale of Federal
involvement in retail transaction systems.  The Fed operates Fedwire,
for moving federal funds around, and also does check clearing at the
national level.  All the retail level transaction systems are in
private hands, be they ATM networks and consortia or the credit card

@_date: 1994-04-05 12:50:16
@_author: Eric Hughes 
@_subject: VISA Electronic Purse 
Probably the same number of Real Women that are going to carry an
electronic "wallet".

@_date: 1994-04-07 12:38:25
@_author: Eric Hughes 
@_subject: nsa digital cash? 
I have no interest in discussion with those who make strident claims
in reckless ignorance, who then expect other people to correct them,
and, worse yet, who finally insist on bickering over the accuracy of
anything one might say.
Use a library.  That's a place with lots of paper periodicals and
paper books.  Library materials not online, mostly, but it is still
where most of the world's encoded knowledge is stored.  If you don't
like paper, tough.  That's the way the world is right now.
If you like, I _will_ explain to you offline some resources available
in libraries about these topics, but only after I've seen some
evidence of a good faith effort to visit a library, such as, say, some
interesting story in a recent _American Banker_.

@_date: 1994-04-07 12:41:18
@_author: Eric Hughes 
@_subject: nsa digital cash? 
_Cocaine Politics_, by Peter Dale Scott and Jonathan Marshall.
Read up.

@_date: 1994-04-11 12:57:57
@_author: Eric Hughes 
@_subject: Prime Numbers 
It was first claimed that if (2^n-2)/n was an integer, then n was
prime.  That's false.  561 is the first Carmichael number.  If you replace 2 by any other
number relatively prime to 561, then the congruence still holds.  (The
second Carmichael number is 1729, if I remember right.)  It was
recently proven that there are infinitely many Carmichael numbers, and
that the density of Carmichael numbers is at least x^c, where c is
about .1.

@_date: 1994-04-11 14:35:56
@_author: Eric Hughes 
@_subject: Zero Knowledge, Hamiltonian Cycles, and Passwords 
You say something like "there exists a machine M such that ...".  This
can be put into a first order logic statement, but it requires a proof
of correctness that the machine works as advertised.
I don't think it would be practical to actually _do_ such a proof yet.

@_date: 1994-04-12 09:54:45
@_author: Eric Hughes 
@_subject: number theory 
I should point out that the standard argument that picking 'k'
different values for 'a' and then calculating the probability as
(1/2)^k is fallacious.  This would be true if the probabilities were
independent, but they aren't.  There was a paper on this about five
years ago whose awareness has not been yet widespread.  I no longer
have the reference.
For everybody that wants to really know about this, find out about the
Miller-Rabin test.
The 50% figure is easy to show with some considerations about
quadratic residues.  Tightening the bound is much more difficult.

@_date: 1994-04-12 10:02:46
@_author: Eric Hughes 
@_subject: number theory 
The figure I have for the Carmichael numbers is x^(.1), where .1 is
approximate.  Ray has the exponent at 2/7.  The exact one doesn't
matter so much, because compared to the density of primes (x/ln x),
these are both extremely small.  The chance of picking a Carmichael
number is very small.  But that's not the relevant density.
The problem with RSAREF's prime testing is that it will find
pseudoprimes base 2.  Carmichael numbers are pseudoprimes to any base,
but that's unneeded for the RSAREF test.  What is needed is the
density of pseudoprimes base 2.  I don't know that figure.  I don't
know that anybody does.
I would really suggest that someone with access to Mathematica or
Maple do an experiment to find out how many non-primes the RSAREF
algorithm passes.
Carmichael numbers do not, generally, pass the Miller-Rabin test.
Some might; I'll bet it's an open question.

@_date: 1994-04-12 10:15:07
@_author: Eric Hughes 
@_subject: more number theory 
As I pointed out before, this probability is not correct.  The trials
are not independent, so you cannot just multiply them together.
For some good information on primality testing, see
Chapter 9 is titled "Modern Primality Tests".  I give you fair warning
that you will not be able to understand this without significant
effort.  The Pocklington-Lehmer primality test is in Chapter 8
"Factoring in the Dark Ages".
There's a very interesting result stated here, "There exists a
probabilistic polynomial time algorithm which can prove or disprove
that a given number N is prime".  The result is by Adleman and Huang.
(Yes, _that_ Adleman.)
And for purposes of cultural literacy, the names are the Jacobi sum
test, the elliptic curve tests, Goldwasser-Kilian, and Atkin (a
development on G-K).

@_date: 1994-04-12 12:12:35
@_author: Eric Hughes 
@_subject: alias in phone book 
I would suggest first, to ask this professor to make a legal citation,
and if one is not forthcoming, to ask for a retraction of the claim.

@_date: 1994-04-12 16:26:52
@_author: Eric Hughes 
@_subject: alias in phone book 
As long as we're telling funny phone name stories, I had a friend who
had not only an "unlisted" number, but even if you knew the fake name,
it was also unqueryable.
A friend of his was trying to get in touch with him from another city
and only knew the alias.  The first time he asked the information
operator for the number for "Hugo Fokkersef", he got hung up on.
After the third hang-up, he gave up.

@_date: 1994-04-14 09:48:42
@_author: Eric Hughes 
@_subject: rng, anyone? 
If you don't need high-bandwidth randomness, there are several good
PRNG, but none of them run fast.  See the chapter on PRNG's in
"Cryptology and Computational Number Theory".  You, Erich von Hollander, should just go talk to Manuel Blum, who's on
the faculty at Cal.  He's the second Blum of the Blum-Blum-Shub

@_date: 1994-04-14 10:25:01
@_author: Eric Hughes 
@_subject: fake pgp messages 
You'll have to write a simulator for PGP messages.  This is
straightforward, since the outer part of a PGP doesn't contain much
information.  There's the destination ID (those naughty bits), an
encrypted session key, and an encrypted body.
I recommend that the next PGP release come with just such a simulator.
Fake messages are a useful primitive for certain tasks and their use
should be supported.  For similar reasons, a simulator for faking
cleartext signatures should also be distributed.
The destination ID should be chosen at random from a list of known
ID's, maybe with some randomly generated ones added to the list.
These shouldn't be flatly distributed because destination ID's are not
flatly distributed.  Download a big ol' public keyring and use that.
[There's a small opening here.  If the opponent were to seed the
public keyring with keys known not to be in use, they could detect
some of the messages as fakes, and certainly the presence of fakery.
On the other hand, if _none_ of the messages used known moduli, that
would be equally suspect.]
The encrypted session key should be less than the RSA modulus for the
given destination ID.  For arbitrary ones added to your list, make a
data structure which contains an upper limit, a substitute for the
The encrypted body is just the output of your favorite PRNG.  Since
this is a simulation of encrypted text, you don't need the really
strong characteristics of a good PRNG.  Here's my recommendation.
Take a cryptostrong PRNG and generate a seed of sufficient length
(like 128 bits).  Take this seed and seed a PRNG of lesser quality and
(much) greater speed; a linear congruential generator would be fine.
For each block of output, take a secure hash, like MD5.
[crypto-strong PRNG]
[slow seed 128 bits]
[crypto-weak PRNG] [block 1] -->	[block 2] -->	[block 3] --> 		|		|
		|		|
If the strong seed is too small, you could simply generate all
messages and do an exhaustive search.  If the space of the weak
generator is too small, that's where to do the search.  The reason for
the one-way hash is to prevent detection that a random generator is
behind it all.

@_date: 1994-04-16 21:13:56
@_author: Eric Hughes 
@_subject: rng, anyone? 
Re: PGP simulators
There is a problem with generating random numbers by repeated
iterations of a hash function when these numbers will be used to
simulate an encrypted message body.  The body can be seen to be
generated by the algorithm.  All you do is to apply MD5 to the first
block and see if it's equal to the second block.  This completely
identifies the message as a hash-chain generation, and thus as a fake
Indistinguishability is a harder criterion to simulate than other
notions of randomness.

@_date: 1994-04-16 21:16:56
@_author: Eric Hughes 
@_subject: 'Nother MIT talk on crypto... 
Micali's "fair" cryptosystem is a much better key surrender system
than Clipper, but it still allows non-intended recipients for a
For this reason, I don't like it either.
Fight _all_ intrusions.

@_date: 1994-04-16 21:26:02
@_author: Eric Hughes 
@_subject: Laundering money through commodity futures 
Guess.  Read that word again; it's important.
_If_ they're right.
So then, let's take the probability of guessing right at 1/2.
[then is described the double-up strategy]
Here's the flaw, in full glory.  This scheme is the classic
double-or-nothing martingale.  It doesn't work.  The "relatively deep
pockets" of A have to be infinite, because that's the expected value
of the amount of A's intermediate loss in the random walk to the
completion of the transaction.
The example is ludicrous, but the conclusion is valid.  More
transactions means more interactions between them and more possibility
to hide something inside the ever-increasing flux.

@_date: 1994-04-16 21:27:28
@_author: Eric Hughes 
@_subject: Table of Key Lengths and Brute Force Cracking Times 
[table omitted]
RC4 is a stream cipher, and thus not in the table of block ciphers.

@_date: 1994-04-16 21:34:45
@_author: Eric Hughes 
@_subject: Dolphin Encryption Tutorial 
Last time Dolphin Encrypt reared its insecure head in this forum,
these same issues came up.  The cipher that DE uses is not public and
was not designed by a person of known cryptographicc competence.  It
should therefore be considered extremely weak.
I repeat my recommendation of before: Do not use Dolphin Encrypt if
you want secrecy.  If you want something on the scale of a secret
decoder ring, fine.

@_date: 1994-04-17 08:02:57
@_author: Eric Hughes 
@_subject: Key Eater Needed 
One way to expire keys is to simply declare that any old PGP key more
than two years old is expired.
You can use the date in the PGP key structure to timeout on.
Everyone should sign their new keys with their old ones.

@_date: 1994-04-17 09:15:19
@_author: Eric Hughes 
@_subject: If however Dolphin Encrypt was extremely strong ... 
I repeat my advice: Don't use Dolphin Encrypt if you want secrecy.  If
you want something that will provide short term security against
unsophisticated opponents, it's probably fine.
For why I think this, read on.
1.  The description of the cipher used for Dolphin Encrypt is not
published.  It is available only by special arrangement.  It is not
open to casual inspection.  2.  Complexity is no criterion at all for ascertaining the security of
a cipher.  Complexity is not even necessary; for example, a stream
cipher based upon one of the number-theoretic PRNGs is quite strong and
simple to describe.
One of the very most basic errors of making ciphers is simply to add
layer upon layer of obfuscation and make a cipher which is nice and
"complex".  Read Knuth on making random number generators for the
folly in this kind of approach.
Designing secure ciphers requires some theory as why you expect the
cipher to be secure.  "Adding complexity" is false security of the
worst kind.
I've not seen the DE cipher.  I won't sign a non-disclosure agreement
in order to do so.  I have seen an outline of the cipher, and it
smacks of the "many layers of complexity" model.
The author of DE:
"Defined by the source code."  In a better world, I would need say no
more after pointing out this phrase.
Peter Davidson:
I asked the author of DE why it wasn't available.  He's worried that
he'll lose a valuable trade secret.  He greatly overestimates the
value of such secrecy, believing it to be positive instead of
This I am not ignorant of.  The author of DE knows only the very most
basic of statistical tests.  He goes on and on about the posterior
statistics of the ciphertext without even once examing the conditional
statistics of the ciphertext relative to the plaintext.  These
conditional probabilities are an absolute necessity to examine.  The
author of DE does not even mention them, much less mentioning advanced
techniques like differential cryptanalysis.
Ciphers are insecure until proven secure.
Ciphers carry the presumption of guilt, not innocence.  Ciphers
designed by amateurs invariably fail under scrutiny by experts.  This
sociological fact (well borne out) is where the presumption of
insecurity arises.  This is not ignorance, to assume that this will
change.  The burden of proof is on the claimer of security, not upon
the codebreaker.
Until a cipher has undergone testing by differential cryptanalysis, it
should be considered insecure.  Until a cipher has undergone testing
by linear cryptanalysis, it should be considered insecure.  Etc.
The person who says "If you can't break it, it must be secure"--well,
I don't feel very polite today--that person has their head up their
Yes, I do.  The rhetoric the DE promulgates is toxic.
It is not public.  Being available does not make it public.
The lack here is the lack of understanding that we have an
epistemelogical question, not a question of fact.  It may be that DE
is secure, but I sincerely doubt it.  Nevertheless, it should not be
considered that DE is secure until we know that it is secure.
Now this, _this_ is an insult.  Peter Davidson doesn't understand the
process of vetting a cipher, and so claims that I must be on a smear
campaign.  He doesn't understand the difference between public and
available-under-contract, i.e. private, and so accuses me of having an
unfounded argument.
Rather than simply discussing the matter, Peter Davidson chooses to
insult me.
One word:  projection.
Flattery of the audience.  How, er, quaint.

@_date: 1994-04-17 18:27:55
@_author: Eric Hughes 
@_subject: Laundering money through commodity futures 
You still need infinite pockets with transaction costs of zero.
Again, it's only this one example that's flawed, not other ways around
Ever been suspicious of the run-up in prices of Impressionist
paintings by the Japanese a few years ago?  Give someone an
inexpensive painting (or have them buy it), and then buy it at an
inflated rate from them, at auction.

@_date: 1994-04-17 18:30:14
@_author: Eric Hughes 
@_subject: rng, anyone? 
That'll work.  Take the seed as the secret value, and take the first
hash as the first block.

@_date: 1994-04-17 18:32:01
@_author: Eric Hughes 
@_subject: Key Eater Needed 
The idea wasn't just the keyserver, but PGP itself.  If we set the
time to three years, the earliest that will be is September 1995.  A
future version of PGP can enforce this.

@_date: 1994-04-18 07:46:55
@_author: Eric Hughes 
@_subject: Laundering money through commodity futures 
I was talking about a mathematical model only.
The model doesn't apply to rigged trades or to two players, both with
finite resources.  If you have as much money as the bank, you can
break the bank.

@_date: 1994-04-19 11:17:58
@_author: Eric Hughes 
@_subject: CRYPTO: Money laundering and traceability 
That's true for transferable and off-line cash systems.  The same
argument doesn't hold for on-line systems.  There you can have an
exchange protocol to deposit a piece of digicash and immediately
rewithdraw it, blinding it again in the process.  There need be no
account with the bank for this to happen.

@_date: 1994-04-19 13:59:15
@_author: Eric Hughes 
@_subject: CRYPTO: Money laundering and traceability 
The cost of communications on the internet is extremely low, and the
cost of doing a single database query is also.  An initial cost for
facilities only should be able to start out, right now today, at less
than 2 cents per transaction.

@_date: 1994-04-26 21:07:56
@_author: Eric Hughes 
@_subject: prime numbers 
[primes, that is]
There's a nice proof in Chapter 15 of Hardy & Wright.  (Need I say the
title?  _An Introduction to the Theory of Numbers_, still one of the
best introductory number theory books around.)
The basic reason is that -1 is always a quadratic residue for a prime
1 mod 4.  (You can simply calculate this with quadratic reciprocity.)
Therefore \exists x: p | ( x^2 + 1 ).  This yields an existence after
looking at primes in the ring Z[i], the Gaussian integers.
If you really want to know more, go buy a copy of the book.  It's well
worth it.

@_date: 1994-04-28 08:37:34
@_author: Eric Hughes 
@_subject: Anonymous remailer for Waffle 
Reply addresses in address comments (the parentheses) don't work
reliably.  They're comments--various mailers do odd things with them,
like drop them.  The question is reliability not function, because it
will work a lot of the time.

@_date: 1994-04-28 09:00:03
@_author: Eric Hughes 
@_subject: your mail 
Clipper has a front door.  Skipjack doesn't.
Skipjack may be a fine cipher, but I sure as hell don't want Clipper.
Last I heard you couldn't get one without the other.

@_date: 1994-04-28 09:00:56
@_author: Eric Hughes 
@_subject: No Subject 
FWIW, these are recycled jokes.  He used exactly the same lines at

@_date: 1994-04-28 09:03:18
@_author: Eric Hughes 
@_subject: Faking hostnames and inconvenient anon IP 
Evidently this _has_ been discussed.  It came out at one of the CFP-94
sessions, that some telecomm and law group had considered this very
I'll call it what I did then, during the Q&A.
Identity escrow.

@_date: 1994-04-28 13:33:34
@_author: Eric Hughes 
@_subject: ADMIN: Re: Paranoia 
This is not a cypherpunks topic.  Please do not reply on the list to
this message.

@_date: 1994-04-29 23:21:12
@_author: Eric Hughes 
@_subject: Cypherpunks as lobbying/propagandizing group 
It's a fine idea, except there's no way such a group can claim to
represent cypherpunks at large.
Or, Hey! get you own name.

@_date: 1994-04-29 23:48:16
@_author: Eric Hughes 
@_subject: Random #'s via serial port dongle? 
As Tim mentions, lots of people have talked about doing this, but few
actually have.  Nevertheless, the device is still needed and no one
has done it.
I estimate you could sell 500 at $50 each within four months if there
were PGP support for it.  And I'll give you advertising space on the
archive site.
Real random numbers should be a standard part of every computer.

@_date: 1994-04-29 23:50:40
@_author: Eric Hughes 
@_subject: spooks on cypherpunks 
That's because it won't.  Public key techniques will still be used for
key management and authentication.
The problem with Clipper is that one will have no secrecy with respect
to any sufficiently powerful entity, using the government as a vector.

@_date: 1994-08-02 09:55:52
@_author: Eric Hughes 
@_subject: "Anon" fake... 
I've
   pointed this out before -- unfortunately, the list maintainers don't
   have time to do it. Maybe someone could volunteer to do the change?
   You'd have to talk to Eric Hughes about how to do the work.
Hugh Daniel (hugh at toad.com) is the one who maintains the mailing list
software on toad.com.  Hugh is very busy, so don't pester him if you
don't have something constructive.
For the record, and to prevent future misunderstandings, I don't have
root on toad.com.

@_date: 1994-08-03 13:39:01
@_author: Eric Hughes 
@_subject: Egalitarianism vs. Strong Cryptography 
Taxation should be small, uniform, and applied to transactions
   and never to the earnings of individuals.  The earnings of individuals, however, _are_ exactly one sort of
transaction tax.  If you wish to make an exception for personal
income, then you wish to make an exception out of every transaction
where one of things exchanged is labor.  Therefore, you would have to
have a certificate which said "this is labor being exchanged."  My
suspicion is that the amount of the economy performed as labor would
Either you tax each and every motion of money or you require an
intrusive anti-privacy system in order to determine taxability.  I can
tell you now, large interbank transfers aren't going to be taxed.
Intra-corporate transfers aren't going to be taxed.
In order to tax transactions you have to know what the transactions
are.  A transfer of money is not always a transaction.  The simplest
case is where I move money from an account at one bank to an account
at another.  That's merely a transfer; there is nothing exchanged.
   A VAT would do the
   trick nicely and could be easily built into the DigiCash system
   of the future.
Such a "compromise" (read, sell-out) could technically be built into a
transfer scheme.  Requiring VAT on all transactions through this
scheme would effectively restrict it to consumer level sales.
Businesses wouldn't use it for wholesale transfers, and individuals
wouldn't use it amongst themselves.  Thus there would be alternate
ways of transferring money, and these ways could be used to settle
   If individuals wish to go to the trouble of
   avoiding taxes setting up secret businesses that encrypt all
   transactions, more power to them.  The small number of people who
   will bother to do this will not have any real impact on taxation.
Really?  It would be small?
Suppose we assume unrestricted encryption, as you suppose.  Assume the
USA for purposes of discussion.  Further suppose that's it's really
easy to set up a digital account, denominated in dollars, in a non-USA
jurisdiction, say, China.  All the transactions are encrypted, and
China's not talking to USA authorities--they don't have to.
I think the interesting question here is how soon the USA government
has to change its regulations because so much business (and hence
capital) has left the USA.
When capital flight for the individual is easy (and it's not right
yet), expect to see rapid changes.

@_date: 1994-08-03 17:06:37
@_author: Eric Hughes 
@_subject: My light bulb goes on... (was:Re: Tuna fish...) 
> Is this not the killer app that would get ecash off and running?
   The problem is not a need for a killer app -- there are dozens. The
   obstacle is regulatory problems, and finding a large and reputable
   sponsoring organization (like a big bank).
And these two issues are related.  Bank regulations in this country
are kept deliberately somewhat vague.  The regulator's word is the
deciding principle, not a detailed interpretation of statute.  The
lines are fuzzy, and because they are fuzzy, the banks don't press on
them nearly as hard as when there's clear statutory language available
to be interpreted in a court.
The uncertainty in the regulatory environment _increases_ the hold the
regulators have over the banks.  And the regulators are known for
being decidedly finicky.  Their decisions are largely not subject to
appeal (except for the flagrant stuff, which the regulators are smart
enough not to do too often), and there's no protection against
cross-linking issues.  If a bank does something untoward in, say,
mortgage banking, they may find, say, their interstate branching
possibilities seem suddenly much dimmer.
The Dept. of Treasury doesn't want untraceable transactions.
Need I say more?
Probably.  It's very unlikely that a USA bank will be the one to
deploy anonymous digital dollars first.  It's much more likely that
the first dollar digital cash will be issued overseas, possibly
London.  By the same token, the non-dollar regulation on banks in this
country is not the same as the dollar regulation, so it's quite
possible that the New York banks may be the first issuers of digital
cash, in pounds sterling, say.
There will be two stages in actually deploying digital cash.  By
digital cash, here, I mean a retail phenomenon, available anybody.
The first will be to digitize money, and the second will be to
anonymize it.  Efforts are already well underway to make more-or-less
secure digital funds transfers with reasonably low transaction fees
(not transaction costs, which are much more than just fees).  These
efforts, as long as they retain some traceability, will almost
certainly succeed first in the marketplace, because (and this is
vital) the regulatory environment against anonymity is not
Once, however, money has been digitized, one of the services available
for purchase can be the anonymous transfer of funds.  I expect that
the first digitization of money won't be fully fungible.  For example,
if you allow me to take money out of your checking account by
automatic debit, there is risk that the money won't be there when I
ask for it.  Therefore that kind of money won't be completely
fungible, because money authorized from one person won't be completely
identical with money from another.  It may be a risk issue, it may be
a timeliness issue, it may be a fee issue; I don't know, but it's
unlikely to be perfect.
Now, as the characteristic size of a business decreases, the relative
costs of dealing with whatever imperfection there is will be greater.
To wit, the small player will still have some problem getting paid,
although certainly less than now.  Digital cash solves many of these
problems.  The clearing is immediate and final (no transaction
reversals).  The number of entities to deal with is greatly reduced,
hopefully to one.  The need and risk and cost of accounts receivables
is eliminated.  It's anonymous.  There will be services which will
desire these advantages, enough to support a digital cash

@_date: 1994-08-04 08:20:28
@_author: Eric Hughes 
@_subject: Remailer stuff 
Sorry if I'm being dense - will someone please E-mail me and tell me
   why outgoing-only (or incoming-address-unavailable) remailers are    useful?
The original intention of remailers is to allow people _who already
know each other_ to do so without revealing that fact to the outside
world.  I would suggest that this use of remailers, rather than
pseudonymity, it much easier to integrate into existing mail software,
and would at this point be a good next step.  But we don't even have encryption and signing well integrated yet, so
I'm not too hopeful today.
My criterion for a successful deployment is when the authors of a
mailer distribute encryption, signing, and remailing support as a
basic part of their packages.
True pseudonymity further reduces risk of linking physical identity to
online identity, but simply concealing communication patterns
accomplishes a lot of that already.

@_date: 1994-08-05 20:34:00
@_author: Eric Hughes 
@_subject: Latency vs. Reordering 
This horse isn't dead yet.
The distinction between latency and reordering is if primary
importance to the cryptanalysis of a remailer network.  To repeat yet
again: reordering provides security and latency is a by-product of
I assert that anyone who's given a modicum of thought about how to
cryptanalyze a remailer network understands this distinction well.  I
also assert that those who haven't thought about cryptanalysis don't
understand the distinction, even if they do believe in it by
One of the oldest maxims in the book is "Don't design ciphers until
you've tried to break some."  A remailer network is intended to be a
cryptographic object, a new kind of cipher.
I assert that if you don't understand the distinction between
reordering and latency, you've not thought enough about the
cryptanalysis of remailers and shouldn't be designing them.
Therefore, in the future, from here on out, I will label the promoters
of latency as "sellers of snake oil."  It's the same fallacy as
creating a new cipher by putting lots of complicated operations inside
it without understanding where the security comes from.

@_date: 1994-08-05 20:36:16
@_author: Eric Hughes 
@_subject: Latency vs. Reordering (Was: Remailer ideas (Was: Re: Latency vs. Reordering)) 
Back to the start, I guess.
Let me repeat:
REORDERING IS OF PRIMARY IMPORTANCE FOR REMAILER SECURITY.
ADDING LATENCY IS NOT.
And I don't want to hear any excuses that you can say latency and mean
reordering, because that's self-delusion.  Not only is it false, but
misleading.  Reordering is necessary for security, and latency is a
by-product.  You don't get security by adding by-products.

@_date: 1994-08-05 20:36:22
@_author: Eric Hughes 
@_subject: email packet length size 
Message length quantization is necessary for security in a remailer
network.  Right now there's not enough traffic through the remailers
to warrant more than one such quantized length.
What length should that be?
This information can be readily calculated from the length
distribution of the current messages passing through the remailers.
If only one or two remailers would instrument their devices in order
to record just lengths, that would provide the necessary data.  Any
My complete guess is that it's going to be around 4-5 KB.

@_date: 1994-08-05 20:37:35
@_author: Eric Hughes 
@_subject: Remailer ideas 
Jim Dixon analogizes between the Internet and remailer networks.  The
analogy has some merit, but yet breaks down badly with the very first
      *	all packets should be acknowledged
This is not the way the Internet works.  IP, Internet Protocol, is
unreliable.  TCP, the reliable stream protocol, does not acknowledge
individual packets but rather advancement along a sequence.  The
lesson is that reliable delivery should be built on top of unreliable
Here the analogy breaks down on technical grounds.  With TCP, the
destination knows the source, yet in a remailer network this may not
be the case.  A good first cut, though, would be to forgo reliable
delivery for remailer-created pseudonymity and work out a reliability
mechanism for regular correspondents.  In this case the source _is_
known, it's just that it's not shown on the outside of the message.
Further, in email, there's currently no notion of a connection.  Email
message are much more like datagrams than bit streams.  In order to do
reliable delivery, there would have to be persistent state information
on each side of the communication.  If I send a message for the first
time to a party and there's no reply, I cannot conclude whether the
message was not delivered or whether the message was delivered and not
Connection-oriented email would be much more complicated than the
current systems.  It is, perhaps, time for email to become more
complex.        *	messages should be broken down into packets which are routed
Length quantization is necessary for security in the face of total
network monitoring.  Multiple quanta may be warranted in the case of
high volume, which is certainly not the case right now.  So this point
      *	users should communicate with trusted gateways
This point is only half true, because the analogy only subsumes one
kind of trust.  For remailers there is both trust in delivery and
trust in silence, the destruction of the message and information about
it.  On the Internet the only trust required is delivery; there is not
a desiderata in the design (although it's certainly in some people's
minds) that packet monitoring _not_ be possible.
      *	the gateways should frequently exchange routing information
Again, this works for trust in delivery but not for trust in silence.

@_date: 1994-08-05 22:37:16
@_author: Eric Hughes 
@_subject: What are Appropriate Topics? 
In fact, "Cypherpunks write code" is just one manifestation of the idea
   that we can actually change the world through the technological
   development of privacy-enhancing systems.
All the coding in the world doesn't matter if we don't know what we
want.  Political discussions which have some relevance to the
technical information structure of society are relevant here.  It all
reduces to writing code in the end, but it's not all just writing
I remind everyone that the phrase "cypherpunks write code" is directed
at every control freak, tyrant, oppressor, and spy out in the world.
I am not going to whine; I am going to do something, and much more
than just vote.
Let the complainers and the enforcers of dogma leave, and may the
doers and thinkers be welcome and remain.

@_date: 1994-08-06 09:54:18
@_author: Eric Hughes 
@_subject: fast 386 DES code figures 
Phil Karn wonders where all the speed comes from in reports of fast
software DES.
I believe that the really fast DES variants use extremely large
computed-at-key-init S-box tables.  As I recall, these implementations
tend to pay for it in terms of setup time, which makes them less that
completely appropriate for multiple IP encryption, each with its own
key and where only a few dozen encryptions are done per packet.  The
cost to change keys is paid for either in use of memory for multiple
precomputed S-box sets (an attendant swapping) or in a high key-setup
to encryption ratio.
For a link cipher where the key doesn't change much, these fast
implementations are right.  For a situation where keys change
frequently, they may not be a system win.
Thanks to Perry Metzger for alerting me to this issue.

@_date: 1994-08-06 16:31:20
@_author: Eric Hughes 
@_subject: Remailer ideas 
Given a connectionless network absolute delivery is impossible (well, not
   completely, but just about...)
Here is a theme I'm going to mention a few times today: the complexity
class of probabilistic algorithms is the one that matters most for
practical applications.
Which is to say, that when you have a partially unreliable
connectionless network, you can't, can not, can never _assure_
delivery.  You can, however, set up the protocols so that the
assurance in delivery is arbitrarily close to probability one, even
though it can't ever actually reach it.
Here's the fallacy which is common, that something which is
probabilistically bounded but is not deterministically bounded is
somehow flawed.
Or, rather, you can trust expected values.
Hal's random-send spool has an expected value of latency which is
approximately the size of the spool but has no deterministic upper
bound for that latency.  Fine.  Great.  No problem.  There should be
zero hesitation here, because the expected value -- the probabilistic
average -- is what you want.
When you start off with probabilistic assumptions about the underlying
reliability of the network, the best you can get is probabilistic
answers.  Even if the network components are deterministic, you still
get probabilistic results.  Adding probabilistic components also gives
you probabilistic results.  So what's the bid deal?
The hesitation to accept a probabilistic measurement is still
all-too-frequent.  I will refrain from commenting on why I think that
is, and merely admonish folks not to pull their punches and bewail a
probabilistic result about device behavior.

@_date: 1994-08-06 16:48:42
@_author: Eric Hughes 
@_subject: Improved remailer reordering 
About message mixing:
   A measure that is used for situations like this is entropy.  Indeed.  This is exactly the mathematical measure for what I've called
"privacy diffusion" in a remailer network.  It is, namely a measure of
of the uncertainty to a watcher of what ingoing message corresponds to
what outgoing message.
As soon as you begin to write down some of the equations for this
value, several things become distinct possibilities:

@_date: 1994-08-06 16:59:46
@_author: Eric Hughes 
@_subject: Remailer ideas 
the unlucky message sitting in the queue problem would be to store a
   timestamped, ordered list of messages waiting to go.
The key word in the above sentence is the word "unlucky".  When I
formalize the word unlucky, I get "expected value is arbitrarily close
to zero".  Therefore, I completely ignore this situation, because it
just doesn't happen often enough to worry about.
If you have a higher level protocol which corrects errors, then
staying in a mix too long is just another cause of failure.  It should
be tallied up with the rest of the causes of failure and then, once
its contribution to unreliability has been established, ignored.
The probabilistic reasoning which says that "the message will get out
with the following distribution of latencies" is perfectly fine, and
as long as the systemic consequences of late messages have a fixed
upper bound, the total effect of delayed messages does also.  Estimate
the damage, and if it's workable just don't worry about it.
And when I claim that some folks just empathize too much with that
poor little datagram who went on an incredible journey through lots of
out-of-the-way place to finally come home, well, I'm exactly half

@_date: 1994-08-06 17:34:17
@_author: Eric Hughes 
@_subject: Latency vs. Reordering (Was: Remailer ideas (Was: Re: Latency vs. Reordering)) 
In a system that is carrying continuous traffic, random packet delay
   is functionally identical to packet reordering.
OK.  Prove it.  Here are some difficulties I expect you'll find along
the way.
First, "continuous traffic" is the wrong assumption; some sort of
multiple Poisson distribution for arrival times is.  This is by no
means a hypothetical.  The backoff algorithms for TCP had to be
developed because packet streams are not continuous, but bursty.
There is such a thing as too many packets arriving at a router
simultaneously.  Routers don't swap packets to disk when they run out
of RAM; they drop them.  So given any relation between arrival
interval, processing time, and machine capacity, there some
_percentage_ of the time that the router is going to overflow exactly
because the traffic is not continuous.
Second, the beginnings and endings of operation are special.  The idea
of "stochastic deconvolution" hits me immediately, throwing out
completely any reasoning based only on steady state assumptions.
Third, these two effects interfere with each other, as there are
bursts of silence in Poisson arrival times which will tend to reset
the deconvolution.
Fourth, the problem is incompletely specified, since the distribution
of random added latencies is not made specific.  If I assume a flat
distribution over a given number of message intervals, that's not the
same as assuming a geometrically decreasing distribution, or some
other distribution.
I'd guess there are more.
   If messages are fragmented, random delays on sending packets out is
   functionally identical to reordering.
This is false; a system that concentrates on reordering has provably
better average latency that one based only on adding latencies.
Consider the following.  If I send out a message sometime between two
messages, I've acheived no more reordering (the significant thing,
remember) than if I sent out that same message immediately after the
arrival of the first of the two bracketing messages.
So I can take _any_ latency-adding system and reduce its average
latency with minimal effect on reordering by the following
modification.  When a message comes it, each message in the queue is
tagged to go out at some time relative to present.  For each of these
messages, I can calculate the probability that no other incoming
message will arrive before a particular outgoing time.  Pick some
probability bound close to 1, and send out all messages with
probability greater than the cutoff _now_, before waiting for their
time to be up.
The decrease in reordering can be normalized to zero by lengthening
the time scale of the added latencies.  You'll then find that the
modified system shows lower latency.
And that's only the first inequivalency.
Latency-adding systems are less efficient at memory usage than
reordering systems.  Reordering systems can get pretty close to 100%
use, since the queue can be kept full, as in Hal's threshold sending
scheme.  The random delays can't have full usage, because there's an
maximum to memory; it can't be borrowed like money when you
temporarily need more of it.  The analysis has similarities to
gambler's ruin.
Anyone else care to point out more inequivalencies?
   More importantly, RemailerNet as described defeats traffic analysis by
   more significant techniques than reordering.  Reordering is a weak
   technique.  Anyone else listening to this: I believe the above quoted two
sentences to be distilled snake oil.
   The introduction of noise, 'MIRV'ing of messages,
   fragmentation of messages, random choice of packet routes, and
   encyphering of all traffic are stronger techniques.
Encyphering is necessary.  Reordering of quanta is necessary.
"MIRV" messages may actually decrease security; multiple routes may
decrease security; fragmentation may decrease security.  Noise
messages may not be resource effective.  All the above claims require
some justification, and I have seen nothing robust yet.

@_date: 1994-08-06 18:01:04
@_author: Eric Hughes 
@_subject: <null> 
Those commercial remailers probably will be located around the world,
   so pornography could be send by using an "offshore" [=non-american]
   remailer as last link in the chain. One assumption here is that someone in one country can easily pay
someone in another country, and an automatic currency conversion can
take place.  The prerequisites to happen generally for that are the
electronification of retail money in both jurisdictions and a
retail-level currency exchange system.  None of this really exists
yet, although the first beginnings are here.  Also, for anonymous
payment for such overseas services, anonymous transfer in at least one
of the two currencies is necessary.
I point all this out to show that we're a long way from here to there.
   The jurisdiction where this remailer could be located, preferably    shouldn't care about pornografy. [Holland, Scandinavia ?]
Yes, that's the right attitude.  The mantra is "regulatory arbitrage",
or, always find a place to do something where it's already legal.
And it's not just the USA.  Expect Britain's libel system to be
stretched by anonymous overseas speech.

@_date: 1994-08-06 18:10:13
@_author: Eric Hughes 
@_subject: e$: Cypherpunks Sell Concepts 
I'll bite. I think that practically the only thing holding digital cash
   back at this point is pure and simple hucksterism. It certainly needs that, but I don't think it's sufficient.
   Having heard what Eric has said about potential regulatory problems, I
   think that most of them are inadvertant obstacles, because they certainly
   weren't put there to obstruct e$, which didn't exist when they were
   written.
The obstacles are certainly not for electronic money, which the Fed's
been using for some time now, but rather for electronic cash, which
includes anonymity.  The USA provides a fair amount of financial
privacy to everyone but the government, particularly law enforcement.
So the _business_ case for privacy is largely felt to be already
satisfied by the regulators.
   I think if a reasonable (i.e. not illegal) business case were put
   to the regulators, they would (as usual) conform to whatever business
   interests want.
The Treasury department, among others, really _doesn't_ want
non-recorded transactions.  Unless the banking community as a united
front _does_, I don't think it will happen domestically (USA) before
other deployments.  If there's not a united front, it'll be divide and

@_date: 1994-08-07 10:11:33
@_author: Eric Hughes 
@_subject: Latency vs. Reordering (Was: Remailer ideas (Was: Re: Latency vs. Reordering)) 
Sigh.  I say "A implies B".  You say, "not A, and so proposition is
   incorrect".  No, I say that messages distributions are not continuous, so the model
which assumes they are is not the right model.
   IF the traffic is
   continuous, THEN random delays introduce reordering.  I've never said they didn't induce some reordering.  That's not my
point, which is about known and not merely suspected properties of
Cryptography is about assurances as well as actual security.
Information security is a negative property; it works when nothing bad
happens, and something bad may happen without it being directly
observed.  Since one can't always see an actual cryptosystem failure,
unlike, say, a robbery, the way to extend the security is by
understanding what is possible.  And for understanding, proof is
always better than intuition, guessing, or supposition.
I'll reiterate again.  Reordering is what yields privacy, directly.
Adding latency adds privacy ONLY insofar as it adds reordering.  If
you feel like you have to have a latency based system, fine, but the
understanding of just how much reordering such systems actually induce
is still lacking.  It does not suffice to wave hands and say it
induces 'enough' reordering.  You need to know how much, and that
takes a calculation, which has not been done yet.
Furthermore, I demonstrated two reasons why latency-based systems are
less efficient in implementation than reordering-based systems.  So, in upshot, latency based reordering is not only less efficient,
but also less well understood.  Until someone comes up with a
latency-based scheme which can't be algorithmically modified to make a
more efficient reordering system, and has similar memory usage, and
until someone does some calculations on just how much reordering is
induced by various latency schemes, I will continue to call latency
based mixing by the name snake oil.
   > Fourth, the problem is incompletely specified, since the distribution
   > of random added latencies is not made specific.
   Correct.  You assume details that have not been specified, and then
   critique them at length.
By not specifying exactly what distribution of latencies you're
talking about, I assume that you are making a universal claim about
latency-adding systems with _any_ distribution.  I do not see you
claiming that there exists some special distribution that makes
latency systems work, because for implementation you actually have to
exhibit one.
Therefore, I point out that this is another lack of understanding.
And I _know_ that if you haven't thought before about the issue of the
distributions of the added latencies that you haven't thought very
hard about the cryptanalysis of such systems.
   His arguments also ignore the fact that reordering messages of different
   lengths is useless as a defense against traffic analysis, suggesting that
   this is polemic rather than a serious argument.
Oh, really?  You even quoted me explicitly not ignoring the issue:
   > Encyphering is necessary.  Reordering of quanta is necessary.
The phrase "reordering of quanta" seems perfectly clear to me.

@_date: 1994-08-07 10:23:58
@_author: Eric Hughes 
@_subject: Latency vs. Reordering 
This suggests, that IF YOU COULD TRUST IT, a single remailer would be just
   as good as a whole net.  If you could trust it and if it were large enough.  There's scaling
reasons to use multiple remailers as well.
Consider a network of mailers running on a private network with link
encryptors.  Whenever you join two nodes with a full-time link
encryptor you remove the information about message arrival and
departure, which is to say that you remove all the remaining
information not already removed by encryption and reordering.
In other words, two remailers (physical) hooked up with link
encryptors are almost the _same_ remailer for purposes of traffic
analysis, and almost only because of the link latency and relative
bandwidth.  Likewise, multiple remailers hooked up with link
encryptors all collapse to the same node for traffic analysis.  Open
links between two remailers which are connected otherwise by a path of
encrypted links turn into an edge from the collapsed remailer set back
onto itself.
Simulating any of the salient features of a link encryptor over the
Internet is an interesting exercise, particularly in regard to price
negotiation with your service provider.

@_date: 1994-08-07 10:52:24
@_author: Eric Hughes 
@_subject: e$: Cypherpunks Sell Concepts 
Is it possible to accurately estimate the cash transaction load of an
   economy?
I have some 1992 USA figures on this.  The number of checks was 58
billion (58 * 10^9).  The number of card transactions was 12 billion.
There were about 2 billion other electronic transfers.  72 billion
total.  Cashless transactions are about a tenth (roughly, this is from
memory) of the total.
So as a first cut, assume about one trillion (10^12) transactions to
be tracked per year.  Assume 1/8 Kbyte per transaction (that's a lot).
If you stored transactions on 8 Gbyte tapes, that's 2^40 xact * 2^7
bytes/xact * 2^-33 tapes/byte = 2^14 tapes, or about 16 thousand.  A
robotic retreival device for 16 thousand tapes is certainly feasible;
I've seen a similar system for about 2 thousand 9-track tapes -- it
was feeding a Cray 2 at Livermore in their fusion center.
Now that's just storage, not the whole system.  But it's apparent from
these estimates that a real system is certainly affordable, and,
possibly, relatively inexpensive as such totalitarian devices go.
Remember, "suspects" (10^-3 of the population) can be filtered out
before hitting tape and stored on about 128 Gbytes of hard disk, for
very fast retreival and realtime analysis.
   When *every* business transaction can be scrutinized (as much as physically
   possible, per above) at any time, for any reason the government deems
   necessary, it makes a sizable business case *for* traceable electronic
   cash.  This is probably the place to put the lever on the business
   community.
It might be, but remember that in making the case to business, the
financial privacy, such as it exists today, is _not_ "at any time, for
any reason".  It might be in the future, but then you're making a
perceived-weaker argument.
   Non-recorded transactions exist already. It's keeping them from
   dissapearing that we're really talking about here.
The number of non-recorded transactions, however, is dropping.  The
largest class, cash, got some reporting requirements clamped on it
recently.  We are talking about both ensuring that the current
non-recorded transactions stay that way and allowing for non-recorded
electronic transactions in the future.
   It might be the threat of
   international deployment and regulatory arbitrage which brings them around,
   and fires up the lobbying apparatus on our side of the issue.  With that in mind, shouldn't you have your first conference in London,
invite a bunch of US bankers, and raise the issue explicitly?  As soon
as you can get different countries competing for revenue, you're more
than halfway home.
   On the other hand if those reporting
   requirements are frictionless, they don't *need* to fight it, do they...
Nope.  And remember, the divide-and-conquer is likely already
starting.  The first bank to provide FINCEN with a live transaction
feed will likely see some regulatory hurdles fall, no?

@_date: 1994-08-07 10:59:47
@_author: Eric Hughes 
@_subject: e$: Cypherpunks Sell Concepts 
>There are two legal problems that I could see being used against digital
   >cash.  The first is the civil war era prohibition on banks issuing private
   >bank notes.
   It seems to me
   that one could just as easily treat digicash as securities denominated in
   dollars, [etc.]
It didn't occur to me before, but you could also have 'nonbank notes'.
If the issuer isn't a bank, does the regulation still apply?

@_date: 1994-08-07 16:54:00
@_author: Eric Hughes 
@_subject: Improved remailer reordering 
Imagine a RemailerNet (v0.2) that maintained a fixed level of
   traffic between gateways.
This is exactly what I was talking about when I posted earlier about
link encryptors, and effective collapse of nodes for traffic analysis
purposes.  Traffic analysis of mixes and remailers assumes, as an
abstraction, that all the messages going into and coming out of a
particular node are visible.  As soon as you remove this condition,
the analytical situation changes completely.
And it changes for the better, since the reduction in observed
information can only improve security.  Message arrival and departure
times are not irrelevant, and their removal gives less useful
information.  The desired net result is a single node for traffic
analysis purposes.  But even for a single node, estimates of
reordering still need to be made.
The problem with implementation of link encryption is, like everything
else, cost.  Link encryption off the Internet requires dedicated
lines.  Link encryption on the Internet likely won't get you into
trouble now, but likely will be an issue as subsidies go away.
   In general, the messages do not exist
   as wholes along the lines connecting the gateways, so a discussion of
   their reordering is a good way to waste time.
You still have to worry about reordering in the network as a whole.
The system you've described has reassembly done at the endpoints, who
might not be the final receiver.  I pass over the flaw of lack of
message quantization in the final sending of reassembled messages.
We may assume for discussion that they're all the same length.
Now, you still need to calculate the likelihood that a particular
outgoing message is the same message as a particular incoming message.
These probabilities have to do with message reordering.  You still
need to do the calculation.

@_date: 1994-08-08 21:39:20
@_author: Eric Hughes 
@_subject: ANNOUNCE: the TAZONO is here 
I'm flying to New York this week to go to the HOPE conference put on
by 2600, so I've arranged to throw a party.  Here's the announcement.
HOPE is the two days after this, so if you're planning on that, come a
day earlier.
You're all invited, but I only expect those in range of New York to
actually attend.  And I would like to meet all the NYC cypherpunks, or
at least as many as I can.  So show!

@_date: 1994-08-09 08:47:16
@_author: Eric Hughes 
@_subject: NRO spoof 
with Sen. John Warner expressing his displeasure with how the
   "intelligence community" has hidden the money for a massive
   construction effort to house the NRO.
Steal this line: "The black budget is taxation without representation."

@_date: 1994-08-09 09:04:30
@_author: Eric Hughes 
@_subject: EDDB/RN 
I don't know if anyone else has had this particular idea before,
Yes, lots.
   However, there should be a use for persistent store, for a remote
   encrypted database accessible anonymously.
The real questions are "how big is the market?" and "how much revenue
is there in it?".
Something like this doesn't get made reliable by volunteers.
   Ideally, the data is stored on a distributed data base, with some
   redundancy in case one or more gateways go down
Look in Schneier for secret sharing.

@_date: 1994-08-09 09:16:15
@_author: Eric Hughes 
@_subject: GAK & RSA 
the path towards a surveillance state, is it possible that the
   software GAK (SGAK) scheme could easily incorporate RSA's technology?
That depends on what you consider "RSADSI's technology".
First, there are the direct claims of the patents.  RSA and
Diffie-Hellman primarily.  The "public key" pattent of Hellman,
Merkle, Diffie is the knapsack, which doesn't work.  The Hellman,
Pohlig patent is for a method of exponentiation as a secret key
cipher.  These claims are not very arguable if you believe the
patents.  (And there's an 'if' there, too.)
But there's also the matter of patent extensions, the minor
modifications to the actual patents that are also covered.  I have
heard that RSADSI claims that all use of modular exponentiation for
cryptography are covered under their patents, as well as any public
key type system.
I think those claims are full of shit, myself, but that wouldn't stop
RSADSI from suing for infringement and arguing the case and turning
the attack from merit to one of lawyerdom.

@_date: 1994-08-09 09:24:58
@_author: Eric Hughes 
@_subject: broadcast encryption 
What I would like to see is low-level digital signatures on the level of IP
   or AX.25.  IP is doable, I would think.  What is the policy purpose for signing packets?  It will affect the
Do you want to identify users, processes, or machines?
If you want to reject packets not signed or badly signed _before_
further processing, that's one way.  If you want to detect
interposition in a stream parallel to the use of that stream, that
would be another.  Do you want each packet to carry an independent signature, or can
packets be aggregated for signature?  This is a separate problem,
since "aggregation" doesn't mean a delay, it means there is state
information carried which is involved in checking the signature.  This
question involves the abstraction level where authentication is taking
Too often a particular situation is in mind and remains unspoken.
Making assumptions explicit is necessary for good design and useful

@_date: 1994-08-09 09:27:37
@_author: Eric Hughes 
@_subject: Gore Letter and Software Key Escrow 
The problem comes that a natural term to use to describe this feature would
   be "key escrow".  However, the gov't has soiled that term.  Now, I need a
   new term, hopefully true to the language to describe a feature like this
   without calling up images of GAK.
"Remote Backup" seems to be OK.  Certainly backing up data is a
perfectly respectable thing.  Private keys are just more data.

@_date: 1994-08-09 09:34:45
@_author: Eric Hughes 
@_subject: e$ 
There is a small point to be made here which I think is really a big
   point.  The US government does not object to the use of financial
   instruments so long as they are backed by the US $ (or another
   accepted currency).  No, this isn't so.  They also object to barter schemes that are backed
by dollars.  The object to them not by making them illegal _per se_,
but by making it illegal not to report all the transactions that occur
inside them.
   You also need to be concerned about Federal regulations
   covering the import and export of money.  I think that at $5,000 or
   $10,000 you have to report the transaction.  This applies to cash and some cash-like instruments, not to "money".
Originally it was just cash; it has been extended to other
instruments, but not to all of them, insofar as I know.

@_date: 1994-08-09 09:57:22
@_author: Eric Hughes 
@_subject: legal hacking 
Such a person doesn't gladly
   suffer any legal technicality standing between him and the pound of your
   flesh to which he thinks he's entitled.  On the other hand, if you can convince them that they don't have to
contribute their pound of flesh likewise, they'll take that
   I wonder how he would respond to Perry here.
Well, Perry's right too, in that the amount of arbitrariness is
enormous and that makes it _extremely_ challenging.
I point out that one outlet for legal hacking is the legislature.
Some things are cut and dried.  Many more aren't.  For example, the
SEC has no jurisdiction on commercial paper of duration nine months or
less, by statute.  So that gets rid of one hurdle, if you can ensure
that your devices are considered commercial paper.  Using wording and
agreements which are close analogues of commercial paper will help.
[Aside: This is a practical failing with Chaum's digicash, is that it,
being relatively uninterpreted mathematics, can be _called_ all sorts
of stuff, some of which fall under more regulation than others.  The
regulators, of course, will pick the interpretation which gives them
the most control.]
So perhaps now you don't have to worry about the SEC.  There are four
regulators of banks in the USA, plus general regulation of commerce.
Lots and lots of obstacles to avoid.  And it's easy, easy, easy to
overlook something.
In addition, much regulatory power has be statutorily ceded to the
regulators.  In don't think I can stress this enough, because the
regulators make rules which have the statutory force of law.  The
regulators can change or extend these rules _at will_.  You won't get
much warning, if you get any at all.
Therefore, you want to avoid the purview of the regulators entirely,
if possible.  Moving offshore is one way.  Performing substantive
activity in another way also works, but that usually just means
switching regulators.  You can, for example, transfer value by moving
stocks and bonds, that puts you under the SEC; you could also transfer
value by moving real estate, and that's another set of law.
Legal hacking is not easy.  Syntactic hacks, for example, don't work.
The whole bit with "self-incriminating pass phrases" is a syntactic
hack; it doesn't work because it does not touch upon the substance of
the law.  Moving activity to another jurisdiction is not a syntactic
hack, and it works because jurisdiction is legally significant.

@_date: 1994-08-09 10:04:09
@_author: Eric Hughes 
@_subject: Key Coercion after encrypted message transmission. 
I am not sure that there is a good way of addressing this
   problem short of dividing the key in some way among multiple people so
   that Darth has a hard time seizing them all. This idea has already
   been discussed elsewhere.
Remote backup and secret sharing, yes.
   This problem could be
   called the transmission retroactive coercion problem (TRCP). This one has also been discussed here, just last week, by me.  It's
the problem of forward secrecy.  It already has a perfectly good name,
thank you.
The original author of the message should find out what Diffie-Hellman
key exhange is and how it can be used for forward secrecy.

@_date: 1994-08-09 10:15:35
@_author: Eric Hughes 
@_subject: Remailer ideas 
multiplicative decreases in cutoff probability, and it is
   therefore easy to set a cutoff value for delay which will occur
   with sufficient infrequency as to be useless to the cryptanalyst.
They will be useless only as long as you have an assurance that these
cutoffs are not correlated with anything "too large" (left
deliberately hand-waving).
In particular, delivery times are related to the retry algorithms at
the higher level of the protocol.  These retry algorithms operate
between some two ends and therefore introduce correlations into the
message patterns.  It's not obvious (and may not be true) that
arbitrary latency limiting is a safe behavior.
   By "cryptanalysis," I mean traffic analysis.  Considering the
   remailers to be a cryptosystem was suggested recently on this list
   by someone (I forget whom).
That was me.  I'll have more to say on that subject later.

@_date: 1994-08-09 10:17:56
@_author: Eric Hughes 
@_subject: broadcast encryption 
> What is the policy purpose for signing packets?  It will affect the
   > design.
   Anyone even making such suggestions has not been following the IPSP
   standardization work...
I wasn't asking what _the_ purpose was, but rather what the purpose
the original author (coming out of the context of a radio discussion)
had in mind.  I know _lots_ of reasons for signing packets in some

@_date: 1994-08-09 10:53:57
@_author: Eric Hughes 
@_subject: e$ 
If A writes a check to 'cash', pays B with it, and B passes it on to
   C, and so forth, are you saying that this is or will one day be illegal?
An individual note and its transfers are unlikely to be made illegal.
But that's not the whole story.  A company engaged in the business of
issuing such notes and not recording (perhaps, a fortiori, by not
being able to record) the transactions among people for these
instruments, however, could be ruled to be performing a separate
activity which could then be made illegal.
Just because a single act is legal doesn't mean that a bunch of the
same acts are.  For example, not reporting a $5000 cash transfer is
legal, but not reporting half a dozen of them made to the same person
in the same day almost certainly is.

@_date: 1994-08-10 07:35:20
@_author: Eric Hughes 
@_subject: e$ 
When you fly into the US, you must fill out a customs declaration.
   You are required to declare money in various forms (cash, checks,
   etc) What they ask for and what is required by law are two different
things.  It's not generally illegal to allow people to volunteer
information that increases the power of the state.
   Banks are required to declare cash deposits and international movements
   of funds over either $5K or $10K, I forget which.
In the US, the value is $10K, but that's only for cash transactions,
and it's not just banks that are required to report.  "International
movements of funds" are not subject to reporting requirements as such.

@_date: 1994-08-10 07:42:54
@_author: Eric Hughes 
@_subject: e$ 
Yes.  But my initial point was that a check for $1.00 does not constitute
   an alternative currency and you do not seem to be disagreeing with this.
Merely the fact that an instrument is denominated in USA dollars is
irrelevant to legality.  What I was saying is that there are other
activities that would be the ones ruled illegal.
   I think that whether
   the $5000 is transferred as greenbacks or as $e is irrelevant, if the
   creation of $e is handled correctly.
Irrelevant to whom?  As long as it's _not_ irrelevant to the
government, it will be irrelevant to very few other parties.
   >				   A company engaged in the business of
   > issuing such notes [etc.]
To clarify, I'm talking about a digital money company here, and since
USA regulation is what is at issue, I'm talking about a USA digital
money company.
   Every bank in the United States that allows checks to be made out to
   cash already does this.
The one-at-a-time has never been an issue.  And it's not banks that
"allow" this, it's the Uniform Commercial Code.     A second point, relating to this paragraph: obviously, a foreign bank
   cannot be constrained in the same way to report financial transactions
   to US authorities.
Well, this is just what I've been talking about for some time.  It's
clearly possible to have the issuer in another country.

@_date: 1994-08-10 15:59:57
@_author: Eric Hughes 
@_subject: ANNOUNCE: August Bay Area physical meeting is CANCELLED 
What: nothing
When: would have been Saturday, August 13
Why: summer doldrums
So I'm going to be out of town, and one of our main speakers
cancelled, and our host at SGI would just as soon have the day off,
and so, hey, we're cancelling for Saturday.
That means you can stay up until all hours on Friday and watch the
Perseids.  Cool.

@_date: 1994-08-10 16:50:07
@_author: Eric Hughes 
@_subject: e$ 
These are no different than checks endorsed by the payee without restriction
   (signed on the back).  Every time you just endorse a check, you have
   converted it into a bearer instrument.  Perfectly legal.
Just so folks don't misunderstand Duncan, the conversion to a bearer
instrument only occurs with a blank endorsement (blank, or Pay to
Bearer), not with a special endorsement (Pay To or Pay To The Order Of
somebody else).  And for minor terminology nits, an unrestricted endorsement is
different.  A restricted endorsement are words like "for deposit only"
or "pay any bank".  And these two categories are different from
qualified endorsements, which affect liability.

@_date: 1994-08-10 16:52:51
@_author: Eric Hughes 
@_subject: anonymous settlement 
>  Also, for anonymous
   > payment for such overseas services, anonymous transfer in at least one
   > of the two currencies is necessary.
   The last point is certainly not true.  If user X communicates with
   service A (a gateway) in one country to purchase something from
   service B in another country, X can settle accounts with A anonymously
   (say in US$) and then A and B can settle accounts with one another
   (say in sterling) openly.
May I point out that that in your example that X and A are performing
an anonymous transfer in dollars, which is one of the two currencies?

@_date: 1994-08-10 16:53:45
@_author: Eric Hughes 
@_subject: EDDB/RN 
We won't have a copy of Schneier here for three weeks or so.  Can
   you elaborate?
I can, but I won't.  Have patience, and wait for the book to arrive.

@_date: 1994-08-19 12:16:21
@_author: Eric Hughes 
@_subject: trusted time stamping 
They are trying to build a company to do this; perhaps Stu can update
   us on the status.
I don't know if Stu's on the list right now or not, but I saw him
Tuesday in Manhattan.  They're in the middle of development, which
includes much more than simply writing the crypto protocol that's at
the core of any real business.

@_date: 1994-08-19 12:23:06
@_author: Eric Hughes 
@_subject: CIA Using Remailer System? 
Wouldn't it be funny, if the CIA (or other agency) used the remailer system
   (alon with PGP) for regular communication with operatives overseas. Not particularly.  The CIA has used existing bank secrecy
jurisdictions for years for, let us say, congressionally
non-appropriated funds.

@_date: 1994-08-19 12:45:34
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
A piece of ecash is basically a callable bond.
A raw, non-modal "is"??  Digital cash doesn't exist yet, so saying
that it "is" something, is, well, premature.  The real question is
"What happens if we set up a digital cash system as a callable bond?"
And my answer to that is, "You really _want_ the SEC involved?"
   The issuer gets to
   keep the interest accrued on that money while the ecash is in circulation.
Perhaps in some systems this is so, but not all.  The unit of account
must be fixed, but the unit of account may not be constant currency,
but rather currency at a fixed interest rate.
   The underwriter looses money if the duration, and thus the total return, of
   his portfolio of ecash is less than the total return of the principal he's
   holding in escrow [...]
Why do you assume that the only source of income for the "underwriter"
is the return on investment from the float?  Sure, that's one business
model.  Transaction and participation fees can also be levied.
   When the ecash
   comes back, it's like a bond is called, and the issuer has pony up the
   principal.
The issuer has a debt mediated by an instrument, yes.  There are,
however, more instruments than bonds available for use.  Is the debt
secured or unsecured?  What happens during bankruptcy of the issuer?
These and similar issues determine the nature of the instrument.
   He then has to unwind a piece of his offsetting portfolio,
   incurring transaction costs and losing whatever future income those
   investments might yield. Any reasonable cash management system includes a segment in liquid
assets for this case, since the income not taken for this segment is
much less than paying for portfolio manipulations.  Remember, cash is
coming in as well as going out.
   If you thought that
   the ecash duration was 3 days and it stayed out there 3 months, 	
It's unlikely that these sorts of figures are not going to be known
shortly after rollout, during which phase the cash management function
for income is much smaller.
   In
   theory, if the fees are high, the money may never come back, and stay in
   circulation forever.
I think you may be getting confused here between "on-us" transactions
and a first class currency, which does circulate.  Digital cash cannot
"circulate forever".
I should note, however, that I agree with the basic point, that the
portfolio management problem for digital cash is not unusual.

@_date: 1994-08-19 13:27:13
@_author: Eric Hughes 
@_subject: ecash-info 
Anyway, when I screwed up the guts to ask, Chaum told me that the going
   price for the underwriter's license/code was $275K plus a percentage of the
   net profits.
It's no small wonder that he's not gotten anywhere.  Anybody who wants
an operational cut of a finance system is asking for way more money
than anybody might want to pony up.  A bank (or similar) wants to buy
technology, not a partner.
   the increase in traffic about his inactivity in promotion leads me to
   believe that he's either working hard in getting his product market-ready,
   which makes sense, or he's dropping the ball, which I would charitably say
   is an unfair reading of the facts.
A third possibility is that he's just not getting anywhere.  If you
want too much money for what someone else is willing to pay, you don't
make a sale.
There are three potential benefits from any Internet money system:
1. The ability to transact and settle to the outside banking system.
2. The ability to keep one's transactions private from one's counterparty.
3. The ability to keep one's transactions private from the bank, and
   hence the government.
Having property 2 subsumes 1, and having 3 subsumes both 2 and 1.
Here's the crux.  ONLY property one has large and direct and immediate
economic benefits to the issuer.  Property two has a very small
increase in revenue, and property three has an additional, even
smaller increase.  These relative revenues can be explained by the
fact that privacy for your average transaction is not worth a whole
lot, and so if you raise your rates to go after the lucrative market
who wants property 3, you lose most of your customer who only need
property one.
If you were a bank, would you pick system 1, 2, or 3?  System one will
result in direct customer fees.  System two will result in, perhaps,
very slightly higher fees, and some dissatisfied retailers who want to
be subsidized for the collection of transaction data.  System three,
again, has about the same revenue available, and in addition will get
the regulators pissed off!
So, with these three kinds of transaction systems in competition with
each other, which do you think will win?
Let me answer that for you.  It's system 1.
Now Chaum wants to offer system 3, and it's expensive to purchase.
Surprised at lack of success?  Not at all.

@_date: 1994-08-19 13:42:35
@_author: Eric Hughes 
@_subject: e$: Cypherpunks Sell Concepts 
FINCEN is the Financial Crimes Enforcement Network, a very scary thing
indeed.  A good article on it was in Wired, issue 1.5 as I recall,
which should be available from their infobot.

@_date: 1994-08-19 16:49:23
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
money for a no-transaction cash system.  With credit cards and checks    there is a transaction trail that you can follow to spot and get rid of
   fraud.  I trust that for "transaction" above you mean "audit".  You still have
transactions and you still have audits.  It's just that this
information does not allow for the derivability of the customer's
Assume four accounts in the books of an issuing bank: one asset
account, cash, and two liability accounts, one for a customer and one
suspension account for digital banknotes issued by not yet redeemed.
The withdrawal transaction posts a debit to a customers demand deposit
account (decreasing it) and a credit to the suspension account
(increasing it).  Now suppose the customer buys something from a
merchant, and the merchant redeems the digital banknote cash.  The
deposit transaction posts a debit to the suspension account
(decreasing it) and a credit to the cash account (also decreasing it).
As you can see, there are perfectly good journal entries for each of
the two transactions just described.  What is missing is an audit
trail to determine which debit to the suspension account corresponds
to which credit to the suspension account.  An assurance that these
match up is provided by two properties.  First, for each banknote
issued there is one and only feasibly computable modification of it
that is acceptable for redemption.  (In Chaum's scheme this is the
unblinding.)  Second, a database of the banknotes as redeemed is kept,
which prevents multiple redemption.
   Will it be a replacement to ATM and credit cards or would it be a concurrent
   working solution?
Concurrent, of course.  There's very little point to scrap any
existing system as a system.  Individual merchants may decide not to
support older systems eventually, but that is a different issue.
Nonetheless, I have argued at length at other times that digital cash
will not be viable as a physical retail system very soon.
Where digital cash is immediately useful is online as a retail level
wire transfer system.
Maybe a physical newspaper today, but the cost of networking is
dropping and the cost of computation is dropping.  I personally don't
expect that off-line digital cash techniques will ever actually be
economically most efficient.  Existing alternates (e.g. credit cards)
work well enough today, and by the time PDA's work well enough and are
cheap enough to be universal, the cost of an online verification will
be down in the fractions of a cent.

@_date: 1994-08-19 17:08:09
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
Can a case be made that anonymous digicash is less risky
   (to a bank) than NON-anonymous digicash? In certain circumstances, it might be.  Where a bank is at risk of
violence when it does not reveal transaction information, not
possessing such information poses less risk.  On the other hand, in
the USA a bank is at risk of violence when it does not possess
transaction information.
   Would a Chaum-style anonymous digital cash service be more profitable to a     bank than a NON-anonymous digital cash service?
Maybe.  It depends on what the demand curve for transaction services
of various kinds looks like and what the relative demand for privacy
If there were already a fully identified digital money system, then
creating an anonymous digital cash system would grab you most of the
market which was willing to pay a premium for privacy services.  That,
by the way, is not everybody.  There will be at least a local maximum
at some large premium, simply because certain benefits of bank secrecy
are so large.
On the other hand, there is likely also a local maximum where the
premium is fairly small.  In this case you get not only all the people
above, but a large percentage of the people who are willing to pay
just a little more for privacy.
As to where these local maxima actually are, and which yields the
larger profits, I have no idea.
   Are the costs involved in offering and supporting anonymous digital cash     more, or less, than the costs associated with NON-anonymous digital cash?
The costs associated with anonymous digital cash may well be less that
for identified digital money systems.  There are additional services
being sold in most identified systems, including statements of
transaction logs, reversibility of transactions, delay in settlement,
and availability of logs to government.  This last service is sold to
the government with each transaction, a hidden fourth party which
taxes the bank with the requirement to offer this service, in order to
permit the bank to operate.  These additional service take resources
to operate.  Reversibility, I suspect, is the most expensive to
operate, since it's all human labor that can't be easily handled by
Digital cash, on the other hand, needs a redeemed note database, but
this is one of its only unique costs.  Since settlement is immediate,
reversibility is not an issue, and neither is any delay in settlement.
There are far fewer long term records to keep.
It is likely that digital cash is more efficient economically, since
it unbundles a bunch of previously linked services and allows them to
be purchased separately by those who actually need them.

@_date: 1994-08-27 11:22:07
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
I just got back from CRYPTO '94 travels yesterday, and it's time to
continue some conversations.
Robert Hettinga and I were discussing some properties of potential
digital cash systems.  At least, _I_ call them potential.
   I meant "is". Like a triangle, or a limit, or an asymptote, "is".  It's
   okay to be non-modal here.
It's OK to be non-modal if you are asserting that your claims hold in
all possible such systems.  I do not agree with the assertion,
however, that all possible digital cash systems will be callable bond
   Digital cash has to be issued by someone, who
   *really should* back it up with real money, and should thus receive real
   money as collateral for the digicash on the net.  The basic distinction that is missing in your analysis is that between
legal structure and financial structure.  Here is my very short
clarification of the difference.

@_date: 1994-08-27 11:25:00
@_author: Eric Hughes 
@_subject: ecash-info 
Agreed. I was trying not to tread on the sainted reputation of the master
   by using the word "charitable".
Chaum's reputation in the crypto community is anything but sainted.
   It's possible that Chaum is immersed in the cryptographic details that he
   thinks that privacy is digicash's primary selling point.
I wholeheartedly occur.

@_date: 1994-08-27 11:31:12
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
NewJargonNotice("suspension account")
   Is this new nomenclature? It sounds less risque than "float", I must say...
As Hal pointed out, this term refers to the double-entry book notation
used to keep track of how much digital cash has been withdrawn but not
yet deposited.  I don't think I invented this use of the word
"suspension", but I also can't find where I might have picked it up.
One can consider that a digital cash exchange creates a delay between
the two legs of the transaction.  In between the beginning and end,
the transaction is suspended.  That's the sense of the word.
"Float" is a financial concept, not an accounting one or a legal one.
The issues are greater than financial ones only, and the terminology
needed is correspondingly greater.

@_date: 1994-08-27 11:38:01
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
>If there were already a fully identified digital money system,
   Is there one?
I don't think there is any digital money system at all, neither
anonymous nor fuly identified.
There certainly are digital funds transfer systems, almost all fully
identified.  These are not digital money systems, although they may be
   Eric, for the last three months, you have said that there was no way to
   prove whether digital cash was more cost effective than other forms of e$,
   and thus potential efficiency was useless as an economic argument for its
   adoption.
I still agree that you cannot really _prove_ that it will be more
efficiently, at least not from armchair business planning.  Given a
few million for a good study though, I'm sure answers might be
What is apparent, however, is that it is certainly reasonable to
examine the possibility that digital cash might be cheaper to

@_date: 1994-08-27 12:03:33
@_author: Eric Hughes 
@_subject: e$: e-cash underwriting 
By the way, I think the problem of double spending is a risk that can be
   managed, like the risk that a bank takes when a check is bounced.
Exactly.  There is some cost incurred by attempts to double-spend, no
matter what the outcome.  The costs are either direct, e.g. redemption
of duplicated notes, or indirect.  Indirect costs include the
implementation of systems to get rid of double spending and the cost
of dealing with rejected transactions when challenged.  In any case,
double spending creates costs.
   The culprit is identified, and it becomes a matter between the
   bouncee (however removed from the criminal transaction), the law,
   and the bouncer.
Why does everyone think that the law must immediately be invoked when
double spending is detected?
Double spending is an informational property of digital cash systems.
Need we find malicious intent in a formal property?  The obvious
moralism about the law and double spenders is inappropriate.  It
evokes images of revenge and retribution, which are stupid, not to
mention of negative economic value.
What is needed are techniques to prevent the possibility of double
spending from taking down the system.  These might include law, and
hence also identity, but need not.  What is the point of an anonymous
system if identity is needed to make it stable?  The contradiction
here is enormous.  The offline cash protocols suffer from this fatal
design flaw, namely, anonymity for "good people" and identity for "bad
people".  Why invoke identity at all if you can do without it?
Having a database of "spent money" is the primary technique for
prevent direct costs from being a problem.  So what is left are
attempts to redeem multiple times the same note.  They won't actually
get redeemed, but if there's a negligible marginal cost for trying,
well, then, some folks will try.
One solution is clear and direct: charge for each redemption attempt.
In that situation, multiple attempts get rejected, and the issuer is
recompensed for the attempt.  No morality need be invoked.
There remains an issue as to the size of this redemption fee, which
would have to be small.  In order to optimize the transaction costs of
charging this fee, a bank might be willing to accept identity in
escrow for the transaction and to remove the fee for good
transactions.  Identity might be a pseudonym revealed after 10 bad
attempts, say.  This system removes the requirement for identity and
substitutes it for an economic optimization based on identity.
An anonymous depositor, however, can still use the system with zero
risk to identity.
   Are there any non-proprietary, public sources of information on these legal
   and regulatory research efforts?  Are there archives of the c'punks traffic
   on this subject that I can look at?
The research efforts are basically my own, Hal's, and Perry's.  There
is no reference other than back traffic, which others can provide.

@_date: 1994-08-28 23:31:49
@_author: Eric Hughes 
@_subject: DigiCash ??? 
I would like somebody to explain how I would  go about using an anonymous
   digicash system to buy a automobile?                       Let us remember that the reason for anonymous transaction systems in
general is that if identity is revealed by default, there can never be
full privacy.  Merely because transactions exist where revealing
identity must occur, for example, in the transferring of vehicle
title, does not mean that the identity needs to derive from the means
of payment or any identity attached to that means of payment.
Just because the larger transaction itself is not anonymous is no
argument against the monetary transaction being anonymous.

@_date: 1994-08-28 23:31:55
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
To review, I said the following:
   >-- The financial structure matters when things go right.
   >-- The legal structure matters when things go wrong.
The reply:    The law and the enforcebility of agreements is what makes financial
   instruments exist.  Their behavior is a direct result of their legal
   underpinnings. This is absolutely false.  Both a promissory note and a bond can have
identical financial structure, but the legalities are completely
   The
   financial behavior of a security can thus be predicted just by assuming the
   efficacy of the legal system they're written in.
Certainly the probability of transaction failure can be factored into
the face value and behavior of the instrument, but the actions in case
of transaction failure are not determined by how the financial
transactions around the instrument are governeed.
   If you break the law or agreements creating a market, say if people didn't
   make their margin calls and got away with it, there wouldn't be a market on
   margin for very long. Sure, the legal system creates the stability that allows the financial
structure to become significant.  But neither side determines the other.
   Thus, by collateralizing what you would call a
   digital banknote, you are agreeing with the person you issued it to that at
   the very least, that dollar-for-dollar, there's money to back the note up.
Well, no.  At the _very_ least, you promise that there will be money
for them when they redeem the note.  There's no necessity to make any
promise about what happens to the money in the meantime.  Here, then, is most of the answer to the earlier pop quiz.  Promissory
notes need not be secured, whereas bonds by definition are securities.
Money paid for a promissory note might, for example, be immediately
lent out.  As long as there's money for redemption when it becomes
due, everything is OK.
In bankruptcy, secured debt is paid off entirely before unsecured debt.
   By the way, I figured out just now why this can't be called a digital bank
   note [...]   The issuing underwriter isn't anymore a bank
   than an institution offering any other piece of collateralized paper [...]
Even though the issuer need not be a bank, the phrase digital banknote
still captures most all of the intent of what these instruments are
meant to be used for.
   >Merely saying that the money sits
   >somewhere while it's in transit (which it clearly does) does not make
   >the instruments secured.
   But it does, Eric. Especially if the underwriter says at the outset that
   the money's secured (collateralized).  You are merely _assuming_ that the digital notes are secured; you do
not seemed to have considered the possibility that they are not.
   If money isn't secured dollar for
   dollar, especially in the early stages, you get a whole mess of legal, not
   to mention financial problems.  If I say that the notes I issuer are not secured, and yet for
convenience keep the money in 100% liquid reserves, is there a
contradiction?  No, because security is a legal issue, namely promises
to the holders of notes, and reserve structure is a financial
property, namely where the money sits for the duration of the
   It should be possible to keep an issue of
   digital cash fully collateralized (secured) and still make money.
You are confusing here, very clearly, the promise to keep a fund in a
particular way, and actually keeping that fund in that way.  If you
undertake a legal responsibility, that will affect you financial
structure, but merely naming some financial structure does not
determine the legalities around it.
   Again, Eric, if one digital cash underwriter has to unwind a fully
   collateralized bunch of digital cash, what's the problem?  Go do some reading.  In the case of bankruptcy, for example, the
issuer is not around anymore to do any unwinding.
   If the
   underwriter isn't fully collateralized, he's in violation of his issuance
   covenants and is likely to be sued by the trustee for the instruments, at
   the very least, long before a run on the cash started.  Finally the hidden assumption of full collateral is revealed.  Why on
earth are you assuming that this has to be the case?  Reasoning from a
particular model about a set of properties is a good way to ensure
that you don't see all the possibilities.

@_date: 1994-08-28 23:32:10
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
> There certainly are digital funds transfer systems, almost all fully
   > identified.  These are not digital money systems, although they may be
   > precursors.
   The U.S. banking system is largely a "digital money system" in the
   sense that the bulk of the money in the system is represented in book
   entry form in computer systems and has no other existance.
Well, just to pick nits, I'm referring to a retail-level, digital,
general-purpose, bidirectional transaction system.  That doesn't exist
yet.  (Credit cards aren't bidirectional.)
Certainly, though, the book entry money that is the world's high end
monetary accounting is all digitized at this point.

@_date: 1994-08-28 23:32:18
@_author: Eric Hughes 
@_subject: e$: e-cash underwriting 
>Why does everyone think that the law must immediately be invoked when
   >double spending is detected?
   It's obvious I gave that impression. I regret the error. I wasn't referring just to you, but to what is unfortunately and
surprisingly a general reaction to protocol failure in money
protocols, namely, "lynch the bastard!".  I assure you, as recently
as last week I had the same reaction from someone at DigiCash.
Anyone remember the rant of mine a few months back about language and
about how imputing motive into protocol makes you stupid?  Well,
here's a good example of that connection in action.  The dominant term
in the literature for the agent of double-spending is a "cheater".
And cheaters must not prosper, right, so let's punish them.  That kind
of reasoning leads without further thought to a reliance on law
enforcement and identity.
   If someone deliberately double (or million) spends, then they should get
   busted for fraud. Period.  If there's a charge for attempting a deposit, and this charge is paid,
even a million times, do you still think such transactions should be
considered fraud?
Turn fraud attempts from a security cost to a profit center.

@_date: 1994-08-28 23:32:29
@_author: Eric Hughes 
@_subject: e$: A prima facie business model for a digital cash underwriter. 
My favorite one, and the one which may be most
   apprehendable to the public, is an ATM-card gate in which the purchaser
   swipes his card into a secure mosaic screen using a card reader at home
   (they're pretty cheap these days, and could get cheaper if this became
   prevalent).
As a rule of thumb, the purchase of any hardware of any kind, no
matter how inexpensive, drops your potential market by a factor of
   That means anything put up on your spiffy Sparc machine and it's attendant
   code should be able to:
   1. Generate to purchasers and take in digital cash from sellers.
   2. Identify double spenders.
Why item two?  Have you made a decision that charging for deposit
attempts doesn't work, or that identity is still needed for some

@_date: 1994-08-28 23:32:35
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
As an aside, most finance professors consider accounting to be applied
   finance. I expect that accountants don't take to that kindly, however.
No, I imagine the accountants don't.  Yet the finance professors are
wrong, to boot.  Accounting covers more than finance, and plenty of
finance is outside accounting.

@_date: 1994-08-28 23:32:42
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
Eric, what would that "few million for a good study" buy?  Might it not be
   wiser spent on a full-blown market test, using software prototypes?
That is exactly the kind of thing I meant.  Several smart-card payment
systems have been deployed in medium size cities in Europe as trials
to see just how much they'd cost in practice to deploy.  These trials
cost more than just a few million, but prototype implementations of
each of online and offline sorts of systems, complete with standard
marketing tools such as focus groups and limited scale deployment, as,
for example, inside an amusement park.
Whatever the actual figures are, there are too many of them now to
each side's benefit to say definitively what will be the best in any
particular market segment, even if some of the choices are clearer
than others.

@_date: 1994-08-28 23:32:56
@_author: Eric Hughes 
@_subject: No Subject 
I doubt digital signatures will ever be
   used alone much for signing expensive contracts.  Not every binding signature is on a contract.  The signature at the
bottom of a check is not signing a contract, but rather referencing a
contract between the drawer of the check and the bank whereby the bank
agrees to accept such checks.
Expect models like this to proliferate, where one physical signature
initiates the use of many digital signatures in a proper context.
Such a system could be used, for example, in a new beast called a
"contract proxy", which is the nominal end of some contract, but which
is really standing in for some other party.
Activity within a contract is not the same thing as a creating a
contract.  This is one of the very first things I learned in this
field, and I thank Mike Godwin for pointing this out to me.
   I predict it will become common practice, or even    law, that digitally signed contracts over a certain amount are    automatically invalid unless further precuations have been    taken (signatures of notary witnesses, or perhaps some better    crypto protocol designed for this purpose).
This prediction is either far too premature, since the whole technical
and le
al situation with use of digital signatures in _any_ form is
not yet well enough developed, or totally tautological, since a
digital signature as such is merely a string of bits with little other
than mathematical interpretation.  What is certain is that the social
process involved in making digital signatures useful will be far more
complicated than the software needed to make the digital signatures.
   We may yet find protocols to mitigate or limit this kind of fraud --    make change traceable if linked to double spending, "Traceable to what?" is the real question.  One can consider systems
traceable to persons or systems traceable to security deposits, for
   Reliance on law enforcement flies in the face of
   cypherpunk goals, and indeed against the goals of good cops    as well A system that requires police for its stability is externalizing part
of its security costs to the governments of jurisdiction.  The
taxpayers of such jurisdictions are subsidizing these enterprises.
And in cases where the powers of the jurisdiction are weak or
non-existent, be that by accident or design, these kinds of systems
just won't work economically.
   A protocol that treats common
   accident the same as criminal fraud, when the stakes are
   so high, is pathological.
And not only that, it requires trafficking in identity.
   [...] we may not even need to recongize fraud in online
   cash -- just treat all online double spending as accident.      No bonding, secured accounts, investigators, ID badges
   or cops with guns busting down Janes's door after
   Iriving has million-spent her coins.  The economics of charging for deposit attempts clearly prevents most
double spending.  There may well, however, be an economic win for an
business which finds a way to save on clearing costs by eliminating
the deposit charge in lieu of some other notion of assurance against
abuse, like a secured account from which deposit fees are levied.
   If clearing costs are less than plausible offline cash
   fraud and fraud prevention costs, online cash is a winner,
   both now and increasingly in the future as bandwidth becomes    even cheaper.
I agree.  It appears to the back of my envelope that communication and
computation charges are dropping fast enough that by the time offline
smartcards are economical enough to deploy, that online systems will
be cheaper.

@_date: 1994-08-28 23:33:35
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
The reduced overhead increases economic efficiency. There are other reasons
   for not doing on-line transactions. Including credit checks, interest
   calculations on outstanding balances, vendor reserve requirements,
   transaction threading, on-line wait states and bandwidth, etc.
Whatever are you talking about?  Credit checks for an online system?
If anything, credit status for offline systems would be the salient
issue.  Interest calculations, if that's the product model, are
consistent with both online and offline systems.  Ditto for reserve
requirements.  Transaction serialization (threading) will be required
for both systems and look to be more complicated for offline systems
than for online.
There are some additional costs with implementing the high-uptime
systems required for online systems.  On the other hand, with the
right product structure, there's no need for identity at all in an
online system as there is in offline systems with the ability to
identify multiple spenders.

@_date: 1994-08-28 23:33:39
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
It's the behavior of the financial instrument I'm talking about. At some
   point, the principal goes away and has to be called from wherever it is (a
   bank account, the money market, etc.) to meet a cashed-out piece of
   digicash. In the meantime it earns interest. Thus it has principal, and
   interest, and it is called.  It's a callable bond.
Now, consider a promissory note which is redeemable on demand and
which pays interest at redemption.  This instrument has the same
financial properties as a callable bond.
Pop Quiz: why is this promissory note _not_ actually a callable bond?

@_date: 1994-08-28 23:33:46
@_author: Eric Hughes 
@_subject: e$ as "travellers check? 
But someone a long time ago brought up traveller's checks, and the
   similarity between them and ecash. [...]  You pay some money to
   American Express, you get a note issued by them, you give it to a
   merchant, he redeems in with AE for money. [etc...]
   I dont' know much about economics, but as far as I can tell this
   seems a pretty solid analogy.
What you have described is a financial model for digital cash, which
is only part of a complete model.  The financial model is, as you
point out, pretty easy.  You buy an instrument and then use it in lieu
of a more direct transfer.  The privacy to counterparty comes about
because the issuer's name is on the instrument, not yours; the issuer
is a proxy for identity.
   It's clearly not _illegal_ to issue
   travellers checks, No, but in certain places where they are used in lieu of greenbacks,
aka Federal Reserve Banknotes, it _is_ illegal to use them without
certain reporting requirements.  (Duncan can elaborate, as he's much
more up on the details here.)  Complicity in failure to report can
also be criminal.  And an issuer that sets up a system to thwart
reporting requirements could easily be considered _prima facie_
evidence of conspiracy to evade reporting.
When the government doesn't want anonymity, expect that it will be
difficult to create.

@_date: 1994-08-28 23:33:51
@_author: Eric Hughes 
@_subject: On humor in the NSA 
It was suggested by one of the NSA folks at CRYPTO that they should
have done a rump session talk on the "NSA Offensive Driving School",
which would completely explain the alleged threat to run Bidzos over.
In addition, not only were the 'behind schedule' shirts a big hit with
the NSA folk I saw, but at least some of them were going to get 'Sink
Clipper' posters for their offices.

@_date: 1994-08-28 23:34:12
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
By the way, "calling the bond" is actually exercising an option, and yes,
   the finance guys will tell you that there is no difference. I acknowledge that they're financially the same, which means that when
the transaction completes as normal, the financial effects are the
same.  When the transaction is contested, however, the two are not
identical; that's a legal difference.
More on this later; I wanted to point out an example early

@_date: 1994-08-28 23:34:18
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
>In an off-line system, is the cash really cleared immediately?
   Clearing in this case is when the cash passes from you to me.
This is a pretty non-standard usage of the word "clearing", which
happens when the issuer accepts the instrument for deposit.
Settlement happens when money actually moves.
The significant activity that happens at clearing is a liability
acknowledgement by the issuer.  This acknowledgement makes clear that
the issuer has a liability.  If the issuer clears but does not settle,
i.e.  accepts the liability but does not act upon it, the depositor
can use the clearing as a claim against the issuer.  (N.B. Here
'claim' is used in its strict legal meaning as the opposite of a

@_date: 1994-08-29 00:16:00
@_author: Eric Hughes 
@_subject: Zimmermann/NSA debate postponed 
It seems to me that a prerequisite for a transparent, secure mail system
   is an efficient, interactive, IP based key distribution system.  Wait!  Reconsider!  The problems of doing public key distribution are
large, and not yet solved.  Don't wait for a perfect world before
trying to make a better one.
The PEM folks got bogged down for four or five years with key
distribution, only to need to put out version 2.0 because of lack of
acceptibility.  You need not repeat their mistake.  Assume that key
distribution happens somewhere else, and simply use the keys in some
repository.  Manual key distribution will work just fine for common
correspondents, and that's most ofthe problem.

@_date: 1994-08-29 00:46:15
@_author: Eric Hughes 
@_subject: e$: e-cash underwriting 
To me, double-spending is analogous to passing bad checks.  Legally, it's one form of conversion.  Conversion includes forgery,
for example.
   In either case you are getting an
   explicit or implicit assurance from the payor that the instrument is
   good.
That's the case with checks right now.  The assurance you mention is,
in law, called an "implied warranty", and there are several kinds of
them.  Implied warranties are creations of law, and need not exist in
a newly designed system.
The system in which the issuer charges for a deposit attempt needs no
implied warranty of validity.  A deposit attempt is made, the fee is
paid which covers equipment and communication costs, and everyone is
   The problem is, the fraud doesn't occur (typically) when the note is
   redeemed at the bank, it occurs when the note is exchanged at the
   market.  Is this proposing to charge the merchant when he in good faith
   turns in the cash which was given to him by the customer, and it turns
   out bad?  What cruel irony!  Here he is already cheated once, and the
   bank will charge him an extra fee as additional punishment?
Fairness is overrated.
In the commercial paper world, there is the concept of the "holder in
due course", which is a legally protected holder.  In certain
situations there are parties who have to pay off both the holder in
due course as well as having already paid for the note, or in other
words, there are parties who incur a dead loss.
There is a public policy decision implicit in this doctrine that a
protected market in commercial paper is more important than fairness
at each stage in the transaction.
This is a profound principle.  Overall economic benefit was the goal,
not individual economic benefit.
Now, I should add that if the issuer charges a deposit attempt fee,
that a reasonable merchant would pass that fee right along to an
anonymous customer.  If the merchant wishes to extend credit in the
size of the transaction or in the size of the deposit fee, that's
their business.
So the question of intermediates is really not relevant.  An
intermediary, the merchant in this case, can derive some source of
income by being an intermediary, and either passes the deposit fee
along or averages it with other income.  The market will decide.  Any
merchant who must pay deposit attempt fees and who neither passes that
cost on nor makes any attempt to otherwise stochastically recover that
cost is, well, stupid.
queries, that is, deposit attempts, are being directly paid for.  From
a potential multiple spender's perspective, double spending gets them
nothing, and they have to pay for getting nothing.  They might be able
to convince some merchant to try the transaction for them, but it
won't succeed and the only difference is that someone else pays the
   But I thought we were
   referring to a double-spending protocol in which users revealed their
   identity to the bank.
I'm talking about an online system.
The idea of charging per attempt might also work in an offline system,
if only to get the merchant to pass the fee on to their customers.

@_date: 1994-08-29 00:56:58
@_author: Eric Hughes 
@_subject: e$: e-cash underwriting 
Can you explain exactly how charging a back-end load on a digital cash
   certificate prevents double-spending?
In an online system, double spending gets immediately rejected, so the
only loss incurred by the bank is the cost of a database query.  So
the bank gets reimbursed for the cost of that query.  From the point
of view of the double spender, they pay something in order to get
nothing, although perhaps they can convince someone else to pay that
little something for them.  In either case there is no direct benefit
to a double spender, and there is a waste of time incurred.
Now, in an offline system, this doesn't work the same way, because
presumably goods or services are rendered before payment clears.
Remember differential time lags, and Herstadt risk--same issue,
different context.  So the fairly simple solution of charging for a
deposit attempt doesn't work.  (Regardless that the end of my previous
message said that it might.)
Chalk one up to the efficiency of online transactions.  A simple
product change, with very low impact, can entirely eliminate to
participate in an identity regime.
Of course, if you've got your heart set on offline...  Have I
mentioned how much more computation and communication those systems
require by all parties?

@_date: 1994-08-29 09:44:36
@_author: Eric Hughes 
@_subject: Statistics on remail message sizes 
A couple of weeks ago Eric asked for statistical information on
   remailer message sizes.  I put in a size-counter a week ago [...]
   or so, and here are some results.
Based on Hal's numbers, I would suggest a reasonable quantization for
message sizes be a short set of geometrically increasing values,
namely, 1K, 4K, 16K, 64K.  In retrospect, this seems like the obvious
quantization, and not arithmetic progressions.  Live and learn.

@_date: 1994-08-30 08:28:17
@_author: Eric Hughes 
@_subject: In Search of Genuine DigiCash 
Anything that our government would come up with would be???
I was reading American Banker yesterday, and found an absolutely
amazing figure, which did not strike me that moment, so I don't
remember details.  I'm remembering this a bit dimly.
~"The cost of compliance in a typical USA bank is 14% of operating
Compliance refers to all the things the regulators make a bank do.
Some the bank might do anyway, e.g. for a hypothetical private deposit
insurance provider, but part of it is only for the benefit of the
Now 14% is huge in terms of relative competitive disadvantage.  In a
tight market, even a 3% price difference in a commodity service is
enough to capture a market.  It's these kinds of effects combined with
international competition which will cause banking deregulation in the

@_date: 1994-08-30 22:36:21
@_author: Eric Hughes 
@_subject: Cyberspatial governments? 
monolithic enemy.  It is a multitude of huge enemies.  This was my best joke during my crypto presentation at HOPE a couple
of weeks ago.  I was describing threat models for remailer networks.
1. Recipient -- any indirection works 2. Sysadmins, and then I added, "or anyone else with root access".
That got a big laugh.
3. Operators of the remailer nodes
4. Gov't -- law enforcement
5. Gov't -- national security
It was during my explanation on why the FBI doesn't really get access
to National Technical Means, e.g. NSA SIGINT, that I got the BIG laugh.

@_date: 1994-08-30 22:37:16
@_author: Eric Hughes 
@_subject: CFB description in Schneier 
The first text paragraph on p.161 has the correct description.  The
picture seems to be in error.

@_date: 1994-08-31 20:37:31
@_author: Eric Hughes 
@_subject: Force is not physical 
One question [...] is whether it
   makes sense to say that nothing done in cyberspace should be considered
   to be punishable by force.  I, personally, will steer clear of making any such broad normative
prescriptions.  We have barely yet begun the task of determining
whether violence-free systems can be stable in the long term.  It's
not yet fully clear to me that this is even true about a payments
system, even though I've argued that it may well be so.  And the
payments systems are the only ones for which I've seen anything
approaching a specification.
Normative statements are, generally speaking, ones which contain the
words "you ought to" or "you should" or "it would be wrong to".  They
imply some sort of obligation, but the recipient of that obligation is
rarely explicitly stated.  Normative statements create and bolster the
"policeman inside"; they are intended to create in the hearer some sort
of mental restriction--"I won't do that because I shouldn't".
Why do normative statements ever even work?  The simplest statement of
the situation seems absurd--one person says "you ought" and then
another person says "I will".
"Those who do not will are willed."  A wise man indeed.
Normative statement work because of the implicit threats contained
therein, threats of either violence or shunning.  Years of
conditioning, and not only by parents, are required to make these
threats effective, and their effects persist long after.
I want my threats to be overt.  I would much rather say "If you steal
from me I will hunt you and kill you" than say "People shouldn't steal
from each other".
One of the whole points of anonymity and pseudonymity is to create
immunity from these threats, which are all based upon the human body
and its physical surroundings.  What is the point of a system of
anonymity which can be pierced when something "bad" happens?  These
systems do not reject the regime of violence; rather, they merely
mitigate it slightly further and make their morality a bit more
(And now the flip side, where instead of saying "this is good" I will
rather say "this is what I want".)
I desire systems which do not require violence for their existence and
stability.  I desire anonymity as an ally to break the hold of morality
over culture.
Cyberspace is a substrate for identity whose locus is not a physical
body.  Not all of cyberspace will have these characteristics.  There
will be segments of the electronic world which are fully mapped
one-to-one with individual bodies, and the actions taken here will
be subject to the same morality of the physical world.
Anonymous systems are neither necessary nor inevitable nor, because of
the prevailing culture, obvious.  The will of many individuals will be
necessary into order to bring about their creation.  Anonymous systems
will start from a position of relative weakness, without the resources
and familiarity that identified systems will have.
I desire the anonymous spaces and the hidden places.  I rejoice in the
discussion of their creation on this mailing list.  I want to win rather than to feel good about losing.

@_date: 1994-02-02 07:40:56
@_author: Eric Hughes 
@_subject: New Remailer Up. 
The remailers could implement their own outoing SMTP, to get rid of
one end of the log, albeit the less important end.
They could also run a SMTP server on a non-reserved TCP port, but that
would require a few things:

@_date: 1994-02-02 08:15:32
@_author: Eric Hughes 
@_subject: On return addresses 
I've been troubled for many months by an invariant in all forms of
return address schemes: The outside world contains sufficient
_persistent_ information to find a real adress.  There are lots of
clever schemes to split this information up so as to require
reassembly between many parties, but the information is still out of
one's control.  (I use 'reassembly' rather than 'collusion' since the
latter indicates an intent; see my rant of a few days ago.)  The
fundamental problem seems impenetrable.
So how do we solve it?  By abandoning return addresses and using mail
spool facilities.
Consider the following service.  1. I have a machine and I'll sell you an address on it, say
"onyma at privacy.net".  This address is _not_ an account, merely an
address.  Your mail is password or public key protected.
2. When mail come in for you, it sits in a spool.  This service comes
with a spool of a certain size and an allowance for checking your mail
at a certain rate, with overages at extra cost for both.  (This is to
bound known promised capacity of the machine by a sufficient amount of
money to pay for it.)
3. Your mail sits in the spool until you access it with, say, a POP
client like Eudora.  Just point the client at a different address to
pick up mail.  The server can further support a number of protocols
for getting the mail, including a mail server command of "send me a
mailbox file of my waiting mail".
The main advantage is that the only _persistent_ information out in
the world is the address itself and the authenticator (password or
public key).  The address is already public and the authenticator is
arbitrary, so no identity information is persistent.  A complete chain could still be forged between sender and receiving
pseudonym, but we now have some amount of forward secrecy.  If in fact
an intermediate link does discard connection information, it is gone
forever.  With any kind of SASE, however, the information therein,
however encrypted, still contains a full path back.
Now consider two ways of getting your mail out of this service,
supposing you don't trust the service with your identity.
A IP redirector can be with POP service to conceal origin from the
mail service.  An IP redirector is a remailer for packets, with a
bidirectional link set up when the service starts and removed when it
goes away.  Matt Blaze has a name for this--'packet laundry'--which is
a wonderful but politically unfortunate term.  The IP redirectors can
be chained just like remailers.
With a mail server, the command to 'send me my mailbox' can be sent to
a remailer address with an encrypted remailing block prepended.  In
this case, however, the encrypted remailer block is provided with the
mail command that requests the mailbox and it is not by design stored
persistently.  (By design.  It could, of course, actually be stored.)
The address on the other side of the first remailer hop could be
another mail spooing service, in addition.
The elimination of persistent identifying information for return paths
is a worthwhile design objective.  I propose that we start thinking
about it more thoroughly.

@_date: 1994-02-03 15:24:48
@_author: Eric Hughes 
@_subject: ADMIN: list statistics 
I gathered some list statistics for the subscriber base as of
Thursday, February 3, 1994, 12:00 noon.
657 subscription addresses total. 49 contain the string 'cypher' and
are suspected gateways, either to individuals or large groups, so the
exact amount is extremely hard to pin down.
Here are the subscribers, broken down by top-level domain
 300 com	USA commercial
 204 edu	USA educational
  25 org	USA organizational
  18 ca		Canada
  15 net	networks
  13 us		USA geographical
  10 uk		United Kingdom
   9 uucp	UUCP links
   8 se		Sweden
   7 gov	USA government
   7 au		Australia
   6 fi		Finland
   5 no		Norway
   4 de		Denmark
   3 mil	USA military
   3 it		Italy
   2 fido	Fidonet
   2 za		South Africa
   2 mx		Mexico
   1 ve		Venezuela
   1 su		USSR (er, someone call a NIC)
   1 si		( ? Slovenia ? )
   1 sg		Singapore
   1 nl		Netherlands
   1 jp		Japan
   1 in		India
   1 ie		Ireland
   1 hk		Hong Kong
   1 gb		United Kingdom
   1 fr		France
   1 es		Spain
   1 ee		?
   1 ec		Ecuador
If anybody knows for sure where SI and EE are, I'd love to know.  My
list of ISO country codes is a little old.
Here are the top individual domain names.  We can see who has market
share, at least.
  51 netcom.com
  16 aol.com
   9 mcimail.com
   8 well.sf.ca.us
   7 delphi.com
   6 world.std.com
   5 umich.edu
   5 shell.portal.com
   5 microsoft.com
   5 cleveland.Freenet.Edu
   5 CompuServe.COM
   4 phantom.com
   4 panix.com
   4 gnu.ai.mit.edu
   4 crl.com
   4 apple.com
   3 ucsu.Colorado.EDU
   3 toad.com
   3 prodigy.com
   3 nyx.cs.du.edu
   3 mason1.gmu.edu
   3 engin.umich.edu
   3 ecf.toronto.edu
   3 anon.penet.fi
   3 access.digex.com
   3 CUNYVM.CUNY.EDU
Happy lack of trails.

@_date: 1994-02-03 16:04:48
@_author: Eric Hughes 
@_subject: ADMIN: list statistics 
Followups to me have yielded the following info:
SI = Slovenia
EE = Estonia
One subscriber each.
Thanks to Tomaz and Stephen for the info.

@_date: 1994-02-04 10:45:10
@_author: Eric Hughes 
@_subject: STEG: a real-life use for steganography 
I had an extremely interesting conversation with a fellow last night,
say, X.  A mutual friend of ours had steered him towards me.
X has contacts in a country C which will remain nameless.  The
government of C is extremely repressive and has a large internal
police force.  The situation, evidently, is one similar to the old
USSR, where masks behind masks were used in daily life, little is
exactly as it appears, and the default discourse is sideways speaking.
The scenario is almost worst-case.  There is a need for steganography,
since the use of cryptography is grounds for suppression; likewise
there is a need for covert channels.  There is a need for
double-blinding of identities, since one's friends may be difficult to
detect.  And so on.  The aspect that _is_ good is that C is not the whole world, and there
are plenty of us not in C.  The first most useful facility to set up,
X thinks, is simply news from outside of C as a bypass of the media in
C--wire service articles about C, for example, as well as a feed of
the newsgroup "soc.culture.".
Here's the technique we came up with last night.  C has an indigenous
music M which is periodically performed in the United States.  We were
thinking about pressing short-run CD's of these live performances.  We
all know where the news feeds go.  The CD's would be distributed via
standard music channels and would be surprisingly brisk sellers.  The
costs of the project can evidently be footed by willing members of the
M industry in C.
Now let me address the standard comment "Oh, steganography completely
solves that problem."  Please.  That's like saying, "Oh, just use an
internal combustion engine to solve your long distance transport
problems."  Such statements are a failure of imagination and
A practical system to carry this project out is quite large.  I see at
least the following pieces needed:
 -- A facility to gather the data being put on the disks.  This by
itself is no trivial task, since it involves the collection of many
disparate sources.
 -- An authoring system to arrange the data, once collected, into a
usable structure.
 -- An encryption system for the arranged data.  Such a system can't
treat the data as one long stream, because of the segmented nature of
the data.  The ability to mount the CD as a file system would be good
leverage for other programmers.
 -- A mastering system to combine a music master CD (done separately)
and a data master (in some format) into a new music master CD.  This
will, at the least require a machine with a CD reader and writer.
Blank media, FYI, for a CD writer are about $20/disk.  The CD writer
is about $5K.  These numbers are approximate and falling rapidly.
 -- A CD pressing facility.  These are commercially available at quite
reasonable cost in quantities in the 100's.
 -- A CD distribution system.  This will likely be the M industry, and
thankfully the details of international shipping and customs will be
taken care of, as well as retail distribution.
 -- A decryption system to get the data off the CD.
 -- Client software to make use of the information.  It need not all
be in text format.
 -- A key distribution system.  A secret key per CD and word of mouth
may be sufficient.  A system to make rememberable sentences out of an
arbitrary 128 bits (and the inverse) would be useful to facilitate
word of mouth.
This is no small task.  Those interested in participating may start
working on any of the above.  The tasks are fairly separable.  Here
are some that I can identify as critical.
 -- A standard for encoding data into the low bits of an audio CD.
This will likely require a lot of specific knowledge of the low level
encoding and error correction systems used in CD's.  I do know that
they are not simple, being much more than bit-correcting linear codes.
 -- A standard for the encoding of file system data onto these low
bits.  This should be a separate document, even though the design of
this will be influenced by the bit encoding standard.  Some adaptation
of existing file system standards may be appropriate.
 -- A standard for the encryption format for the file system.  It may
be that Matt Blaze's CFS cryptograpy can be lifted wholesale.
 -- Multiplatform software support for all of the above.
I am pleased to have a real example to work on, rather than a lot of
wixering about hypotheticals.
I welcome discussion of this topic.

@_date: 1994-02-04 16:59:57
@_author: Eric Hughes 
@_subject: CERT advisory 
Since active interception is not nearly so easy as passive listening,
it would be appropriate to use a Diffie-Hellman key exchange in this
situation.  This protocol has no persistent private keys, so the issue
of keeping a private key around securely is not an issue.

@_date: 1994-02-04 17:05:18
@_author: Eric Hughes 
@_subject: Running regularly 
To continue the explanation, no single process would ever execute for
a long time, since it would, phoenix-like, periodically die and be
A clever mail filter hack could also check to see if it was still
alive (say, with a socket) and then start it running again if it had

@_date: 1994-02-04 21:35:22
@_author: Eric Hughes 
@_subject: IMPORTANT: unsubscription 
This is the mail I send to everyone who tries to unsubscribe by
sending to the list.  After I send this message, I delete it from my
inbox and take no further action to that piece of mail.
Read it.

@_date: 1994-02-05 19:45:48
@_author: Eric Hughes 
@_subject: Apologies, but . . . 
Had you read the message closely, you would have read that I maintain
the list by hand and do not immediately get to all requests.

@_date: 1994-02-05 19:45:49
@_author: Eric Hughes 
@_subject: CERT advisory 
Possible?  Yes.
Trivial?  Bullshit.
It's all economics, and the resources required to intercept packets
and spoof protocols is significantly greater than that merely to watch
packets go by.  There are many fewer people with these greater
resources, which include access to routers.
Both active and passive attacks are possible in a packet forwarding
system.  Merely because both are possible does not mean that they are
the same.
D-H is not a panacea, but its use for password transmission would
completely solve the Ethernet sniffing problem.  That alone indicates
that active and passive attacks are different in nature and in the
defences appropriate.
D-H doesn't require any prearranged keying material, which is its
primary advantage against passive attacks.  Since distribution and
storage of keying material is an as-yet pragmatically unsolved
problem, it is unwise to insist upon prearranged keys when a partial
solution, D-H, is available immediately.

@_date: 1994-02-05 21:50:22
@_author: Eric Hughes 
@_subject: ADMIN: bounce from <MAILER-DAEMON@rosedale.org> ?? 
I've removed the relevant bouncing address from the list.
In the future, such question can be directed to me at hughes at ah.com,
since this kind of list problem is best dealt with quicker than normal

@_date: 1994-02-06 03:55:55
@_author: Eric Hughes 
@_subject: Some stuff about Diffie-Hellman (and more :-) 
The STS protocol is a regular D-H followed by a (delicately designed)
exchange of signatures on the key exchange parameters.  The signatures
in the second exchange that they can't be separated from the original
There is a digital signature required, so what is at root required is
a trusted public key of the other party.  One can use a certificate to
establish this trust and transmit it at session time, but any other
method of communicating a public key will work, include a trusted web
of trust or direct previous transmission.
STS is a well-thought out protocol, with many subtleties already
arranged for.  For the issue at hand, though, which is Ethernet
sniffing, it's authentication aspects are not required now, even
though they certainly will be in the near future.

@_date: 1994-02-06 11:50:30
@_author: Eric Hughes 
@_subject: a reference to STS 
Here's the reference for the STS paper.  STS is the Station-to-Station
_Authentication and Authenticated Key Exchanges_
by Diffie, Oorschot, Wiener
_Designs, Codes and Cryptography 2_, pp 107-125

@_date: 1994-02-06 15:16:08
@_author: Eric Hughes 
@_subject: TEMPEST - Electronic eavesdropping 
Can we get the urban folklore set clued into this one?
Electromagnetic shielding is not illegal.  On the contrary, in the
USA, the FCC finds shielding highly desirable.

@_date: 1994-02-07 08:56:22
@_author: Eric Hughes 
@_subject: ADMIN: list statistics 
I got .de wrong in the stats.
.de is Germany (Deutschland)
.dk is Denmark (the incorrect identification for .de)

@_date: 1994-02-07 09:06:21
@_author: Eric Hughes 
@_subject: Some stuff about Diffie-Hellman (and more :-) 
It wasn't standardization that was the problem.  The Sun modulus was
just too small.  My take on the idiocy was that the designers were
assuming that because they didn't know how to break such a large
modulus, that no one else did either.
It's not naive (as such), it's just that any such modulus must be chosen with
extreme care.
Here are some very basic rules of thumb:

@_date: 1994-02-07 12:31:28
@_author: Eric Hughes 
@_subject: DOJ procedures relating to Clipper Chips and key escrow 
This reminds me a lot of the language used when describing the changes
in FOIA policy, which was something like "The agencies are supposed to
be good, but if they're not, this change doesn't change your ability
to do anything about it."
Is this a Clinton administration policy to make such feel-good,
govern-bad pronouncements?

@_date: 1994-02-08 00:06:46
@_author: Eric Hughes 
@_subject: Magic Money coins 
Well, with Chaum's signature pairs of the form , you'd
still have to calculate some inverse value of a one-way function.
On he other hand, Hal says that his attack against MM coins doesn't
work.  That's OK, as far as it goes.
The problem is really quite general.  Given a set of signatures on the
same modulus, how can one calculate signed values of a particular
sort?  In the proceeding, let { < a_i, a_i^(1/e) > } be the set of
signatures one has, e the public key, n = pq the modulus, S the set of
acceptable signed elements.
Note that the product of any two signatures, pairwise, yields another
valid signature.  A signature can be multiplied by itself as well.
These are valid as RSA signatures but possibly not as any special coin
format.  Note that the Chaum signature pair above prevents
multiplicative combinations entirely.
The problem is then "Can we find an element of S in the multiplicative
span of the { a_i } modulo n?"  (The multiplicative span is any
product of the a_i, possibly taken multiple times.)
Hal's attack was about the about problem, _but without the modulo n_.
There's a subtlety to remember here: factoring doesn't mean anything
in a field.  The RSA ring is almost-a-field; if you can find a
non-invertible element, you've factored the modulus.  Factoring only
make good sense in rings where lots of elements are _not_ invertible.
So Hal's factoring attack only considered direct multiplication,
forgetting that that modular equality was what was relevant.
The upshot is this.  Let s be in S.  What we are looking for is a
factorable (in integers) number of the form s+kn.  Now s can be any
element in S, and k any integer.  That's a wide range to choose from.
A.  First off, what is the size of the possible multiplicative span?
The short answer is "It's likely the whole thing".
Recall that in an RSA cryptofield (my term for a ring where it's
infeasible for an outsider to find a zero-divisor) the invertible
elements form a multiplicative group which comprise all the 'normal'
operations in the cryptofield.  Its structure is the product of two
groups, one of order p-1 and one of order q-1.  Now the number of
generators of the Z_p is \phi(p-1).  (That's the Euler \phi function.)
The average value of \phi(x) is x * (6 / \pi^2), i.e. on average 61%
of the numbers.  [N.B. This is for random x.  p and q can be picked to
change these values.]  Eliding the rest of the calculation, we see that with a few
signatures, it's very likely that _every_ cryptofield number is in the
multiplicative span.
B.  The next question is "How tractable is finding particular
combinations?"  I don't know, but I wouldn't trust on the lack of an
efficient algorithm.
Remember, we can pick and set of numbers to get signed to span with,
any coin format to try to create [RANT: forge indicates intent] with
that span, and we're working in a modular cryptofield.  That's lots of
Here is one idea for such attack.  The numbers in S all have the same
upper bits.  Suppose one could calculate a number u which was 'close
to' 1 in a range containing S.  To be specific, suppose that
that is, multiplication by u likely doesn't move the value around by
more than the square root of s.  Then one can randomly pick coin
values, multiply by u, and likely get new coin values, since all the
upper bits are the same.
Are such u rare?  Maybe not.  Consider the number 3 and values near
n/2.  Observe that So for the numbers close to half the modulus, 3 is exactly such an
But can we find one for our given range?  I think so.  Here's my first
guess at how to proceed.  And it really is a guess, even if it is
inspired by a Gauss sum.
Consider the following.  Take the range S and choose random { x_i } in
S with, say, some truncated Gaussian distribution in order to favor
number in the center.  Now calculate the term
In other words, just calculate an average of a bunch of values that
move one element of S to some other element of S.  Such an element
*might* tend to preserve values of S near the center, maybe not.  It
may be that diddling the distribution helps.  It may be that a
different average works, say a geometric average (although taking
roots becomes an issue).  It may be that this technique works but
doesn't converge rapidly.  I don't know; I haven't tried it.
In any case, if it does work, there are lots of candidate u's that one
can sample.
It also appears that one might be able to directly calculate some of
these near-identities with continued fractions.
C. Recommendations
In any case, the issue of creating new signatures out of old is
sufficiently unsettled in my mind that I would avoid the issue
entirely.  1.  Don't rely only on format of the signed number for validity.
2.  Do use a one-way function in the signature in order to prevent
multiplicative attacks.
3.  Use both techniques above.
Therefore I recommend the Magic Money signature format be changed.

@_date: 1994-02-08 10:06:46
@_author: Eric Hughes 
@_subject: Magic Money coins 
In thinking about my own averaging technique for finding
near-identities, I realize it needs some modification.
Remember the example that 3 was a near-identity near n/2.  Well so is
5, and 7, and -3, -5, -7, etc.  Even though 3 (or -1) seems to be the
best of the near-inverses, any one whose action is sufficiently
bounded will do.
The new observation is that the candidates for near-inverses will be
clustered and not distributed flatly over the ring.  There will also
be more than one cluster.  So you've got two choices.  First make a
histogram of the candidate choices and only average by clusters.
Secondly, one might also be able to transpose the clusters onto each
other and average them all.  The inverse image of this transposition
may also yield more near-inverses.
I think that averaging can be made to work, but it's not obvious to me
exactly what the technique will be.

@_date: 1994-02-08 10:10:50
@_author: Eric Hughes 
@_subject: Magic Money -> Chaum Cash 
An example of reputation-based proof by obscurity.
I hope the main point came out, though.  There are lots of parameters
to pick from, and therefore lots of attacks can be contemplated.
Be careful when you say this.  Chaum has worked on lots of cash
protocols.  Better to say that you're now using a non-multiplicative

@_date: 1994-02-08 11:06:49
@_author: Eric Hughes 
@_subject: I support HR 3627 
Hey.  You.
Have you sent your letter of support to Rep. Cantwell yet?
It's now even easier than ever!
Just reply to this very message with your reasons for supporting the
bill (it's to allow export of crypto software, dummy), and your mail
will be automagically sent to the correct EFF address with the right
subject line.
(And don't include this message, OK?)
For the full text of the bill, see any of the following:

@_date: 1994-02-08 11:20:52
@_author: Eric Hughes 
@_subject: on Fedwire and FRCS-80 
A touchy spot?  Interestingly enough, the Fedwire network was only
recently encrypted.
The following information comes from a GAO report _Electronic Funds
Transfer: Oversight of Critical Banking Systems Should Be
Strengthened_.  GAO/IMTEC-90-14.  To get a fre copy, call 202-512-6000
or fax 301-258-4066.  And if you pay US taxes, you've already paid for
In a reply letter from the Board of Governers of the Federal Reserve
System, they talk about FRCS-80, the Federal Reserve Communications
System, implemented in 1982.  In September 1989 a request for proposal
went out to encrypt the backbone network.  Encryption was supposed to
have been completed in the first half of 1990.  (I hear that it
slipped.  Given that FRCS-80 was implemented in '82, are we
I understand that Fedwire-II is now in operation, but I don't know if
that's new hardware and/or new software.
Here's the curious thing.  DES came out in 1976, and was supposed to
be secure for financial communications.  FRCS-80 had plenty of
opportunity to use DES, but didn't, for at least the first eight years
of operation.
And save the conspiracy theories about the Federal Reserve for
alt.conspiracy, please.

@_date: 1994-02-09 07:52:22
@_author: Eric Hughes 
@_subject: Netcom remailers. 
[Increasingly rant-like towards the end--ed.]
The remailers already partially forge mail by not using the correct
"From:" in the header.  That's why they contacted netcom mgmt instead
of you, because your name didn't appear in the mail.  (Well, maybe in
the out of band info).
The problem is that every time you use the standard SMTP mechanism to
get mail into a machine (regardless of where it comes from) 1. a log
entry gets made on the receiving machine, and 2. a Received: field
gets put in the header which contains the name of the originating
machine.  So to forge mail you have to first send mail to someone who
doesn't log and who doesn't put Received: fields in.
The upshot is that if you use Internet mail, you're stuck with this.
If you want to send mail to people who only use Internet mail, then
you're also stuck.
It is certainly possible to use non-standard mail delivery services
(they'd have to be written, even if lots of existing code could be
moved) but the final leg of delivery to a standard Internet mailer is
going to make a logfile entry and put in a Received: field.  So you're
right back where you started.
Tough.  That's the way it is.  You want an network anonymous at the
hardware level, go read some sci-fi.
Putting the remailer hack on top of existing delivery mechanisms is
more interesting than a custom system, in many ways, because the
existing system, experimental as it is, has the capacity to reach far
more people than a custom system would.
In a wide area system which is not private by default, one way of
getting privacy is to get someone else to put their name on it.
That's what the remailers do.  I call this "proxy privacy".  If A
sends anonymous mail, B stands in A's place as the technical sender of
that mail; B is proxy for A.
So whine, whine, somebody complained.  The last hop, final delivery,
for a remailer system is always going to come from some proxy.  To
send to arbitrary addresses, there _must_ be a proxy.  Perhaps you
wouldn't mind sending to other remailers, but just not to general
And so you want to do good at no risk.  "Maybe someone will find out,
maybe I'll get in trouble".  Sure anarchy is for sale, and you're
buying it with the peace of mind from your good works, a semiotic coin
purchasing relief of bad feelings, rather than donating your risk and
Can you name any other network that has so much email connectivity
than the Internet?  Hmm?
Compuserve, attmail, mcimail, delphi, aol, prodigy?  They all use the
internet as their gateway to non-customers.
BITNET?  UUCP?
Fido?  As anarchist as Fido is, it's only 20K-25K machine, a fraction
of the internet size.
Netware mail?  Any of the LAN delivery services for PC's or Macs?
These people haven't even discovered wide area networking for the most
Look, Netware bought USL recently.  The most successful PC networking
company (one of Microsoft's only serious system-level competitors)
purchased one of the two major branches of Unix.  Can you guess why?
Wide area networking.  It already works--it _is_ the Internet.
Netware is a LAN protocol; your mail won't leave the building.  And
fat lot of anonymity you're going to get there.
Yeah, the internet technology is changing.  ATM is coming.  And guess
what?  People are already implementing internet protocols on top of
it.  The Internet is an idea implemented in software that can run, by
design, on most any 2-way communications technology.  Resilience by
And you think the Internet isn't where it's at.

@_date: 1994-02-09 12:12:24
@_author: Eric Hughes 
@_subject: ANNOUNCE: February meeting--"True Names" 
February 1994 Bay Area cypherpunks meeting
Saturday, February 12, 1994
12:00 noon - 6:00 p.m.
Cygnus Support Offices, Mt. View, CA, USA
  Our theme this month is "True Names", after the Vernon Vinge story.
We'll be talking about pseudonymity in virtual environments, whose
current implementations include MUD's, MOO's, Habitat, and various
other shared online environments.
  The schedule as of right now includes Chip Morningstar, co-author of
Habitat, speaking about that project and maybe what he's working on
currently.  I think some BayMOO folks are going to do something, but
that's not confirmed.  Other speakers will likely be added.  Plus the
usual mix of monthly progress reports and current events discussion.
  The March meeting theme is "Politics", a none-too-unusual topic,
except next month it's featured.  Start up the rhetoric-machines now;
we're going to have a soapbox session and possibly prizes for best

@_date: 1994-02-09 12:22:23
@_author: Eric Hughes 
@_subject: typo in ANNOUNCE: February meeting--"True Names" 
As was pointed out to me:
It was a typo.  Oops.
Thanks to my corrector.

@_date: 1994-02-10 07:25:24
@_author: Eric Hughes 
@_subject: Prime Numbers 
I've got 3 words for you: Prime Number Theorem.
There are at least 2^74 prime numbers in that range.  A gigabyte is
2^33 bits.

@_date: 1994-02-10 12:50:21
@_author: Eric Hughes 
@_subject: MOO: on the virtual meeting 
I didn't get a chance to get to the virtual meeting proper last night,
but I did stop by afterwards for a while.  This morning I got a chance
to see some what was on the videotape which was left in the camera in
the meeting hall.
My praise to Arthur Chandler for setting this up.  Definitely a
worthwhile experience, expecially given the topic of the Bay Area
meeting this weekend.  I've a few comments for now, though.

@_date: 1994-02-10 18:00:25
@_author: Eric Hughes 
@_subject: Magic money not working bigendian 
Try this:
On a little-endian machine, the least significant byte is stored
first; on big-endian, the most significant.  The address of a long
points to the first byte, i.e. the byte with the lowest address.  The
above program tests to see if the first byte is non-zero, which is
true iff the length of a char is less than the length of a long
(usually true) and if the least significant byte is first, i.e.
Further responses should go only to my mailbox.

@_date: 1994-02-11 07:00:30
@_author: Eric Hughes 
@_subject: MOO: on the virtual meeting 
Try ftp://ftp.parc.xerox.com/pub/MOO/clients.  There's one called
'tinytalk' in there which seems to work.

@_date: 1994-02-14 10:01:29
@_author: Eric Hughes 
@_subject: Safire Savages Clipper 
Will someone put a few "Big Brother Inside" stickers inside a stamped
 envelope and snail-mail it to Safire?
It _will_ get mentioned in a column.

@_date: 1994-02-14 21:04:45
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
My maxim for cases like Hal's monitoring of his remailer:
Therefore, we have two problems to solve.  The user of the remailer
got his anonymity blown, and the usenet groups got abused.
A. User anonymity
It has become very clear to me that the opponent model of universal
network monitoring is not the first model that we should be deploying
for.  This is the worst case, and the worst case is the hardest to
solve.  The opponent here was logging by the service provider, and the
technique was logging.  We should ensure that we can defend against
this opponent and this technique.
Any email-based entry point into an anonymous messaging system will
contain an identity-based address.  Yet an IP-based entry point will
only reveal the host.  The lesson:
This has the happy side-effect of removing default email logging.  It
also will allow for IP forwarders to have some reason for use and
B. usenet abuse
The automatic broadcast property of Usenet is profoundly broken for
the long run, since there is no upper bound on the amount of resources
required.  More immediately, this property also requires a 100%
completely distributed salience filter in all the posters for
newsgroup topicality to hold, that is, everybody has to stay on topic,
no exceptions.  Please.
The feedback mechanism of bitching and moaning to sysadmins does not
scale, however, especially when nodes spring up dedicated to
technologically-enforced freedom of speech, nodes which completely
ignore any particularities of content.
In the long run, Usenet will have to move to some method of
distributed moderation before widespread distribution.  Since salience
is determined by humans, humans will have to read messages before
transmission.  The scale of distribution may be wide.  One path of
development in support of remailers, therefore, has nothing to do with
remailers as such but rather with the re-creation of the public forum
which is suitable for anonymity.
In the short run, anonymous mail should not be posted to newsgroups by
parties unwilling to take the heat, both external flames and internal
guilt.  The operators of remailers who don't wish this should acquire
lists of known mail-to-news gateways and then filter.  The rest of the
operators may wish to install their own gateways in the remailer as
Eric Hollander has done.

@_date: 1994-02-14 22:11:34
@_author: Eric Hughes 
@_subject: ADMIN: mail loop fixed 
You may have received a few copies of the post in the In-reply-to:
field above.  I've removed the apparent cause of the mail loop.  Not
to worry.

@_date: 1994-02-15 07:11:42
@_author: Eric Hughes 
@_subject: Clipper and Traffic Analysis 
SS7 uses out-of-band signalling.  The clipper LEAF is an in-band
signal.  Therefore a tap for clipper yields two kinds of information,
content and identities.
Tapping an SS7 signalling network is more expensive and more difficult
to justify.  More expensive because it runs packet-switched, more
difficult because it's not the conversation of any particular party
except the phone company.

@_date: 1994-02-15 07:15:55
@_author: Eric Hughes 
@_subject: PGP 
A simple question:
An answer:
Another rule of thumb I have:
How do you know what the best interests of someone else are?  How do
you know when they change?  Calling PGP on netcom "useless" is blind
foolishness.  Using PGP on netcom does not protect against netcom
administration or netcom access hackers, fine.  That does not make it
Did you ask who the correspondent was?  Perhaps the protection is
against a sysadmin on the _other_ end of the conversation.  Did you
ask if security is really needed?  Perhaps the person wishes to
practice and to integrate PGP into their software system.
Any potential "jeapordy" is contingent upon something bad happening as
a result of revelation on the netcom end.  This situation is not
always true, and likely not usually true.
You may not mean to flame, but you were indeed flaming:
Not one of these words is justified without more information about the
PGP user and their situation.
There are certainly risks involved in the stated use of PGP.
Sometimes these risks constitute a barrier to prudent use, sometimes
they do not.

@_date: 1994-02-15 07:51:42
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
It's February, and time for the Second Annual Hughes v. Ts'o "Imminent
Death of Usenet Predicted" Debate.
For those of you not around this time last year (that's most of you),
Ted and I did this already.
I could take this analogy seriously if I thought that posting
off-topic to usenet were as serious as death.
Let's try equating speech to speech, OK?
How about the disruptive homeless barging into conversations on the
street?  They are, like it or not, already anonymous insofar as many
social relationships go.  One can't really shun them as a technique of
peer pressure, that's adding one insult to, well, years of insult.
If the street were usenet, there would be no way to escape the
disruption.  Usenet is completely open to all who wish to speak, with
no exceptions.  In the end, if complaining doesn't work, there is no
recourse but to leave usenet.
Cypherpunks is a mailing list.
A summary: I advised that only those should post who can to take the
heat.  One barrier to that is feeling guilt.
Ted is trying to instill guilt.  The reference to "rabid
individualists" is an implicit threat of societal rejection of a
madman embodied as a free speaker.  And "net.responsibility" refers to
whatever guilt you already have.  Ted says "there's such a thing" to
those who do not perceive it in themselves, and who may let the act of
looking for it become the act of creating it.
Let me be clear.  I think that instilling guilt sucks.  I don't want
it around me.
I desire the public forum.  I desire anonymous speech.  I desire
pseudonymous persons.  Usenet does not allow these simultaneously,
therefore it is broken for me.  Therefore I desire usenet as it is
constituted now to die, and as much as I desire that, I also desire a
new public forum to exist.
Questions of timing therefore resolve into questions of tactics.  We
are making sure that anonymity is part of usenet; that will break it
sooner or later.
LD is out *best adman*.
The holes are not in anonymity, but in the forum.  We should be fixing
the forum to allow technologically-strengthened anonymity.

@_date: 1994-02-15 08:01:43
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
In analogy with the way that these prosecutions are working now,
they'd be arresting the president and not arresting the equivalent to
the post office.

@_date: 1994-02-15 10:01:41
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
I did not mean to imply this.  Using daemons would get rid of the
_default_ loging that occurs on systems.  Changing logging from
opt-out to opt-in would make a large practical difference right now.
This was exactly my point in a previous article.  An email address
identifies both a machine and a user, where an IP connection (e.g.
telnet) only reveals the machine.  Now if the sysadmin of the
originating machine logs and shares information with the destination
machine, the user can be identified.  But again, this is an opt-in
monitoring system.

@_date: 1994-02-15 10:11:44
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
But an community of isolated remailers could get larger than the
cooperating set.
And coercing wildcats is, well, like herding cats.

@_date: 1994-02-15 12:11:42
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
I think, however, that a new system will still be called "Usenet" and
still be considered usenet and will be built on top of the existing
usenet.  I left this out before in order to make my point clearer.
If usenet as it is now must die, that's no reason to make that death
occur this week.
There is also no reason not to continue to press on the existing
system with anonymity.
The pressures for better salience and for the asking of fewer FAQ's is
already here, and has very little to do with anonymity.  Persistent
and anonymous disrupters do far less harm that the aggregate
blatherings of ten thousand eighteen-year-olds.  The net effect of
both is to increase the noise.
The problem is that one loud person is clearly to _blame_ for that
noise, but a single innocent question is not, even though both
contribute to the problem.  Anonymity removes the path through which
the disrupter can be shamed into submission.  The would-be shamer
subsequently feels frustration at the inability to induce guilt in
someone who ... should.
Thus does anonymity sharpen the debate about the quality of usenet.
It is now particular individuals who are the problem, not the system
as a whole.  The frustrated desire to blame creates a separation in
analysis where none need be.  People get so worked up about bad people
that they forget about the bad system.
Yet my argument seeks to show that the problem is already here, and
that the presence of anonymity changes the nature of the debate about
the problem much more that it changes the nature or even the scale of
the problem.
One can do this by building on top of newsgroup moderation, which is
the internal mechanism already present to capture salience.  Every
newsgroup should have moderation.  Whether the moderator is one
person, a group of people, or a program is an open issue.
I have a starting point of discussion.
Let the moderator of each newsgroup be a mailing list address.  The
members of this mailing list are the moderators of the group.  All
postings to a newsgroup go first to this moderation list.
The moderators then read news with software which rates the news
articles for inclusion.  (This could be a modified newsreader, for
example.)  After each article was read, a mail message is sent back
the mailing list address (or a parallel one) with the rating.
Some voting algorithm determines inclusion.  This voting algorithm
need not require all the moderators to make a rating before
transmission.  When an article is sent out, an indication of the
results of the voting system is included in the header, allowing
end-user filtering on moderation.
Three basic issues determine the exact character of a newsgroup of
this type.  (And each newsgroup should be able to be different.)
1. What is the nature of the moderation group?
  a. Is the size bounded or unbounded?
  b. Is membership self-selected or constrained?
  c. Is there a limit to tenure?
2. What is the nature of the rating?
  a. Size of the rating space
    1) yes/no/abstain
    2) 1-10
    3) Is there veto?
  b. Rating by category.
3. What is the voting algorithm?
  a. Any moderator may approve (result is the name of that moderator)
  b. Any N moderators may approve (result are these names)
  c. First majority with minimum (used in statistical signifance experiments)
  d. Voting window and percentage minimum, possibly with quorum
As a first and easiest starting point, one might choose the following
characteristics for experimentation:
  -- moderation participation is unlimited.  Membership may be restricted if
     many bad moderation decisions are made.
  -- yes/abstain
  -- any moderator may approve
The point of this kind of system is that the existing usenet
distribution mechanism can be lifted intact.  Likewise can the bulk of
the readers of news continue mostly unchanged, only unsubscribing and
The existing unmoderated groups will continue to be a sewer.  Fine.
New groups with distributed moderation can be created.  If these are
successful old groups can be moved over to this method.
Two main pieces of new software are needed for this scheme:
1. A change in newsreaders/mail agents to send off ratings.
2. A mail server to implement the moderation
  a. the initial mailing list   b. the voting algorithm   c. the actual posting
None of this software is particularly difficult in concept.

@_date: 1994-02-15 12:21:42
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
Why even bounce?  If you want to make the remailers do something with
unwanted mail, one could honor the remailing request, but not
anonymize it.

@_date: 1994-02-15 13:01:41
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
A set of remailers isolated from a restriction cooperative is a fully
operative set of remailers.  Adding them to the killfile doesn't
prevent these remailers from directly posting and directly mailing.

@_date: 1994-02-15 13:11:45
@_author: Eric Hughes 
@_subject: The Difficulty of Source Level Blocking 
I really doubt the problem goes away.  Message costs have some
restrictive effect, but they are not a panacea.  (They are a panacea
for supporting remailer services, but that should be obvious.)
Transmission costs are dropping so fast that it is conceivable that
the cost of a broadcast of a three page message to everyone in the
world will be less than a dollar.
Mailbombing might be solved by message costs, and will be a deterrent,
but mailbombing is such a blunt weapon.
As I recently argued, the problem is not individual disrupters but
salience in general.
Usenet is broken because it transmits everything which is sent to it,
without any sort of judgement as to the propriety of the message to
the newsgroups to which it is posted.  Paying for the message does not
solve the problem of newbie questions, or flame wars (low bandwidth
data, high bandwidth emotion; flames are extremely compressible), or

@_date: 1994-02-15 17:18:52
@_author: Eric Hughes 
@_subject: The Difficulty of Source Level Blocking 
I wish to note at the outset that Ted and I seem to agree on the basic
1. Use the ability to moderate newsgroups
  a. to restrict posting
  b. to get tendered articles to the moderators
2. Use multiple moderators and some weighting algorithm
I don't think it's necessary to sell it to existing groups.  Create an
alt group, set up the code, and see if people use it.  How about
alt.talk.crypto?  Surely any measure of moderation would be an
improvement over talk.politics.crypto.  If the alt group is
successful, the software can be moved over to talk.politics.crypto.
To summarize the specifics of Ted's proposal:
  1. mail to a central site is accessed by internet client
  2. moderators vote +/-/0/not now
  3. threshold weighting + and -
  4. selection of moderators left open
  5. security of approved header left open
I had thought of using email to distribute articles to the moderator,
but one might just as easily use NNTP.  The modified newsreader could
be pointed at the restricted-to-moderators NNTP site.  NNTP might not
even need extension, if the existing authentication procedures can be
hacked to work.  Votes/ratings can be in the form of articles posted
to a .votes or .ratings group.
The rating method and the particular algorithm for weighting will
take some experimentation.  I proposed the "one yes vote" system
because it is enormously simply to implement and because that's the
way the current system works: each person votes yes to approve their
own post.  Since not everyone will be a moderator, this method already
gets rid of most newbie questions.
If a disruptive moderator gets on board, their name would be attached
to the post.  If it gets bad enough, the bad moderator can be removed.
This removal can happen by popular demand or by the person or
organization which owns the central site for the moderator address.
Unlike usenet, which has no specific point of control, the central
site would have final say.
Later protocols could be developed to get rid of the hazards of single
central sites.  This central site is only for each newsgroup, though,
not the whole system.
I wouldn't worry about forged Approved: headers right now.  That bit
of usenet will take major public key surgery to fix.  I don't think it
will happen until the RSA patents expire.

@_date: 1994-02-15 20:19:46
@_author: Eric Hughes 
@_subject: The Difficulty of Source Level Blocking 
I'm not convinced this needs to be decided up front.  For the first
such group, whoever hosts the ratings site can decide who gets to
moderate.  A benign autocrat is ideal in this case.
The lessons of experience will be needed to decide how to do the
second and subsequent groups.  One of the reasons I outlined a broad
framework for distributed moderation is that we really can't tell in
advance what systems will be desirable, and whatever it is, it will
likely vary from group to group.
We will eventually need to figure out a way to have multiple groups
with the same topic but with different moderation techniques.
Fractious bickering will cause schisms, and creating namespace turf to
fight over is counterproductive when there need not be such a problem.
This is one of the reasons I suggested using a separate newsgroup for
rating/voting, to support multiple moderation groups.
On voting for a moderator:
I say fine, let them cry.  It would be impolitic to take over and
monopolize a particular topic, so that if there are complaints about
the moderated group, there's always another place to go.
This is another reason to think about how to do multiple moderation,
which is to say to the whiners "put up or shut up".

@_date: 1994-02-16 09:45:09
@_author: Eric Hughes 
@_subject: AT&T stopped talking to me 
If you ever get another phone line and wish to deal with them with a
different company name and a personal pseudonym, you might tell them
next time that you're working on a voice mail system with networking

@_date: 1994-02-16 23:20:29
@_author: Eric Hughes 
@_subject: on running a remailer 
Backfire on whom? Sounds to me like cold feet.  If you don't want to run a remailer and
put your actions out in the world, don't.  Very simple.  If you don't
want to take the heat, fine.  No one said you had to.
But don't expect anyone else to follow you.
You do sound a lot like LD.  "I'm right.  Everyone should do it my
way.  I'm going to throw tantrums until you do.  And if you don't I'm
just going to take my ball and go home."
You can escape your true name with cryptography, but not your own

@_date: 1994-02-17 07:55:24
@_author: Eric Hughes 
@_subject: Bye from Xenon. 
This is a flame.  You are forewarned.
Fuck you.
I have root on neither machine.  Either you don't know what this means
with respect to my ability to change configurations, in which case you
wish to insult me out of an unaware ignorance, or you do know, and
wish to taunt me with my lack of access.
_You_ put up PGP for ftp at any account under your control and keep it
there for more than a year and I'll apologize, and sincerely.
I'm leaning toward the ignorance interpretation above.
Or did you want your analysis spoon-fed?  All I heard from you was "I
don't get it.  Could you repeat yourself for my benefit?"
No.  If you had asked a question which had indicated the least effort
on your part to understand the posting, I would have responded.
And you think you've participated in debate.  God.  All I saw from you
was a bunch of shouting and no listening.
But let me summarize one of my points here for you.  You anticipate
taking heat for running a remailer.  That "taking heat" includes both
feeling guilty about what it's being used for as well as fielding
complaints.  Therefore you are shutting your remailer down, which is
exactly what I advised.
To make my advise crude, "If you're a wuss, go away."  And continuing
crudely, you're both a wuss _and_ going away.  It seems like a
perfectly straightforward and reasonable state of affairs to me.

@_date: 1994-02-17 09:50:43
@_author: Eric Hughes 
@_subject: Well known ports and name service 
Any forum which captures the desirable qualities of a public space
will therefore have to restrict content in some way.  The trick is not
to restrict content too much, and to make sure the restrictions cut
broadly across opinion boundaries.
The problem with a well known port is that it restricts remailers to
one per machine.  Then in fact only one person per machine could set
up a remailer.  This does make a difference, because the sysadmin is
not the only one technically able to monitor the remailer; its
operator is also able.
A pseudonymous service, like a pseudonymous person, should not need to
be linked to any particular machine except during an actual
transaction.  If I have a pseudonym, I can post from anywhere and my
identity is communicated by a signature.  Likewise should a
pseudonymous service be able to hop from machine to machine.
The techniques of location-independent computing, developed for radio
links, can be applied here.
What we need is a name service which has public keys as identities and
which can map virtual and pseudonymous services to various
combinations of IP address, port number, and protocols.  In the
decentralized spirit, this name service should not have a root.
Someone Saturday mentioned that there was a paper from some Plan 9
folk about rootlessness; pointers will be welcome.

@_date: 1994-02-17 10:10:45
@_author: Eric Hughes 
@_subject: Detweiler abuse again 
Jon, as I see it, understands this perfectly well.  Jon is urging
people to hand out bullhorns, not mandating that they do.
The distinction is between persuasion and coercion.

@_date: 1994-02-17 12:45:27
@_author: Eric Hughes 
@_subject: MONEY: cryptocash is transaction money 
I've been getting questions about digital money lately which indicate
a basic misunderstanding of its most important feature.  Crypto cash
is a way of moving money, not a way of holding money.
Crypto cash is like a check or a note rather than like the dollar,
franc, or mark.  Crypto cash is a way of increasing one person's
balance and decreasing someone else's balance.  Since it's not a currency, it's not sensible to talk about its
exchange rates.  Digital money can be denominated in any currency you
like, so long as you have a bank or other financial institution to
handle it for you.
This is only an obvious distinction if you already know it.  "Money"
is such an overloaded word that it's easy to get confused.
If this isn't clear, _please_ let me clarify.  If you don't get this,
none of the rest of the digital money discourse will be

@_date: 1994-02-17 14:00:52
@_author: Eric Hughes 
@_subject: SENDMAIL: a tutorial on how to add + to your addressing 
Here's a little tutorial I just wrote on how to get + syntax in your
email addresses.  It's a more reliable way of inserting aliases into
a remailer than using the comment capability of the address format.
This way mail to, say, hh+joebob at soda.berkeley.edu could get delivered
to whoever was behind the joebob name, by whatever arrangements have
been made.
The document is written in such a way that you can send this to your
sysadmin intact and ask them to install it for you.

@_date: 1994-02-17 19:25:30
@_author: Eric Hughes 
@_subject: The Difficulty of Source Level Blocking 
You're missing a few qualifiers.  The benign autocrat mentioned above
is for _bootstrapping_ a workable _distribution_ of moderation.  Once
the dynamic of moderator selection is stable, this autocrat then loses
most all power to influence, since the initial distribution of
articles to moderators need not be in any particular place.
I'm not proposing that every newsgroup be moderated, even in
distributed form.  What I am proposing is a system for a distributedly
moderated newsgroup which can compete for attention with other
newsgroups and other fora.

@_date: 1994-02-18 06:45:36
@_author: Eric Hughes 
@_subject: Enuf is enuf! 
Yes, with a pay-per-use information vending machine.  The reason that
some service are on CI$ to begin with is that they get money based on

@_date: 1994-02-18 06:51:07
@_author: Eric Hughes 
@_subject: killfiles 
There may be killfiles for certain mail readers, but I would prefer a
solution which filters the mail before it gets to my mail reader.  On
Unix, such filters can be installed as pipes in the .forward file.
One such filter is called procmail.
I just started using procmail, and it's great.  I'm now getting all my
mailing lists in separate mailboxes; this separation improves both my
regular mail and my mailing lists.  Try it.

@_date: 1994-02-18 06:55:35
@_author: Eric Hughes 
@_subject: Source Level 
No.  If all demand for unmoderated groups were to begin to disappear,
then the volume on them would drop, so that I could get better
attention posting to the unmoderated group than to the moderated one.
Therefore, there will be an equilibrium between moderated and
unmoderated.  Since there should be multiple moderated groups, there
will also be an equilibrium between moderated and moderated.
Remember, I have proposed a system of _distributed_ moderation, not a
choke point.  My first attempt would be to make it extremely easy to
let an article pass, just to get out the worst abuses of topicality.
There is not a single moderator!
In my first proposal, there are lots of them, and _any_ of them can
approve an article.  This may not work everywhere, or even anywhere,
but it's a good starting point.

@_date: 1994-02-18 07:01:07
@_author: Eric Hughes 
@_subject: Source Level 
My proposal does not have a single moderator.  There are many.
The proposal is to use the moderation facility of existing netnews
software in order to be able to support distributed moderation, which
is intended to shut down the worst abuses.
There isn't just one moderator!
(I am purposefully using argument by repitition, since I thought I was

@_date: 1994-02-21 15:25:49
@_author: Eric Hughes 
@_subject: ADMIN: another test message 
This is another test message.  Please don't respond to it either.

@_date: 1994-02-21 15:40:34
@_author: Eric Hughes 
@_subject: ADMIN: majordomo is running on toad.com 
The two preceding test messages were brought to courtesy of
majordomo at toad.com, to which all list requests should now be directed.
Sending a blank message there will get you a help file.  Sending mail
to cypherpunks-request will get you a different help file.
We enabled the unsubscribe filter that majordomo has, so that problem
may go away.
I've got some list traffic from the last day salted away, but I'm
pretty sure I didn't manage to snag all of it.  I'll get as much as I
can out this evening, but I'm going to discard all the commentary
about "how many messages".
I hope this all helps.
We didn't put up the extropians list software because we didn't have
it and because we needed something quickly.
There is a 'who' command available on majordomo, so it's even easier
to get a list of subscribers now than it used to be.  If you don't
like this, get off the list or get a pseudonym.  Removing the feature
requires majordomo hacking, which is not high on my priority list.
Many thanks to Hugh Daniel for doing most of the installation.

@_date: 1994-02-22 06:46:04
@_author: Eric Hughes 
@_subject: ADMIN: soda archive site 
Yes.  Soda had some disk problems, but is back up.
And with a big change.  The staff have moved the ftp directory to its
own filesystem, removed quotas for that filesystem, and set back
ownership of the rest of the files to me.
Soda has had a real disk crunch, and the staff installed tight disk
quotas of 10 Mb.  That's hardly anything at all.  The staff, in order
to spoof the quotas, changed ownership of some of the files and
directories to user ftp, after which I couldn't access things or
change them.  This included the main cypherpunks directory, so I
couldn't even add new directory trees.
Plus, I've got some overseas people automatically mirroring soda, with
a hand done exception for pgp, so it was problematic to add new
encryption code.  This is still not fixed.
I'm drafting some volunteers on soda to help with maintenance, so
things should improve there in the coming weeks.

@_date: 1994-02-22 07:09:11
@_author: Eric Hughes 
@_subject: the black budget 
The black budget is taxation without representation.
We fought a war over this, once.

@_date: 1994-02-22 07:23:04
@_author: Eric Hughes 
@_subject: ADMIN: cypherpunks-ratings created 
While we were creating majordomo groups, I had Hugh create a new
mailing list for our use, cypherpunks-ratings.
The ratings list is meant for the implementation of distributed
moderation similar to what I outlined for Usenet a week or two ago.
This experiment is slightly different, since we're going to leave the
main list as it is.
The ratings list currently doesn't go anywhere.  You can join the
ratings list, but that doesn't get you anything.  We'll turn on
distribution of the list later.
Here's the deal.  The ratings posted to the ratings list have to be
some fixed standard form.  This form has yet to be decided upon, and
should be debated on this list.  I will implement a filter which only
passes syntactically correct ratings, once the syntax is decided upon.
At this point we'll turn on the list.
Other motivated cypherpunks participants will have to come up with a
system to merge the two lists into a coherent whole, as well as
provide an interface for creating and sending ratings.
Ratings are intended to be broader than voting.  Ratings should be
manifold, in order to support various areas of interest.  Ratings
can support voting, but not vice versa.
Please use the RATINGS: tag in the subject line for discussion.

@_date: 1994-02-22 08:27:47
@_author: Eric Hughes 
@_subject: ADMIN: Unbridled Enthusiasm 
Repeat, repeat.  Matthew Ghio sent his message only once to the
cypherpunks list.  The mailer software, for unknown reasons, started
spewing it out continuously.
Can we stop with the commentary on "how many times did you get it?"

@_date: 1994-02-22 10:34:02
@_author: Eric Hughes 
@_subject: RATINGS: Subject tags 
If you read the whole list, nothing.
If you don't want to read the whole list, then the ratings are
supposed to help you decide what you want to read.  If you don't read
something, you have to rely on the opinion of someone who did read it.
The ratings list is a formal way of communicating these opinions.

@_date: 1994-02-22 10:52:03
@_author: Eric Hughes 
@_subject: RATINGS: Subject tags 
No one says you have to believe a particular rating.
The system I want to experiment with for cypherpunks is not filtration
at the mailing list server but rather filtration at the user's end.
The "filtered list" is whatever passes through one's own filter.  I am
not talking about making toad into an extropians-style list with lots
of server operations.
I suggest that one kind of rating be based on subject tags, or primary
topic, or keywords, or something similar.  I also suggest that other
kinds of ratings exist.
Hal's suggestion is to make a rating based on salience to topic.  This
is fine, it allows a sheaf of related topics and concerns to be
unbundled according to a particular reader's viewpoint.
There is already the right message identifier.  It appears in each
piece of mail in the header field Message-Id.

@_date: 1994-02-22 10:55:33
@_author: Eric Hughes 
@_subject: the black budget 
It took the Colonists several decades to get worked up enough to fight
a war.  We're only halfway through an equivalent time period.
And I don't want to change the situation only with crypto, but also
with public speech.

@_date: 1994-02-22 14:07:52
@_author: Eric Hughes 
@_subject: RATINGS: proposal 
This is exactly the reason.
We've already discussed saliency.  There are a few more criteria I can
think of immediately (including the one we know):

@_date: 1994-02-22 14:20:05
@_author: Eric Hughes 
@_subject: ratings 
Robert Hayden said:
You have to decide who that author is and what the subject is, first.
Therefore, as somebody said:
Likewise the true subject may not be apparent either.
Ratings are a means for a group in discourse to engage in a
meta-discourse about what they wish to speak and to hear.  Some form
of this is going to be necessary to support anonymity and
pseudonymity, which breaks the current social structures which hold
together the existing meta-discourse (facial expressions, body
positions, mere presence).

@_date: 1994-02-22 14:27:55
@_author: Eric Hughes 
@_subject: the black budget 
Public speech is not a series of public speeches, but rather one's own
words spoken openly and without shame.
Tim has answered your question admirably.  Here is part of my answer:
   "I desire a society where all may speak freely about whatever topic
they will.  I desire that all people might be able to choose to whom
they wish to speak and to whom they do not wish to speak.  I desire a
society where all people may have an assurance that their words are
directed only at those to whom they wish.  Therefore I oppose all
efforts by governments to eavesdrop and to become unwanted listeners."
You may quote me, as always, but I would rather you spoke your own

@_date: 1994-02-22 15:10:08
@_author: Eric Hughes 
@_subject: RATINGS: Subject tags 
One of the goals of this arrangement I've proposed is that it can be
used to rate _any_ existing mailing list.  There's no reason the
ratings address has to be on the same machine as the list software.
If someone wants to set up an alternate cypherpunks rating service,
great.  If someone wanted to set up an extropians or libernet (two
lists which I know have high crossover to here) ratings service, you
could do so, without requiring the cooperation of the list
Now, onto Hal's comments, about which the above paragraph are a
Yes.  I find this desirable.  The way it's set up now, there are two lists, cypherpunks and
cypherpunks-ratings.  The main list will not change basic operation
merely because there is a ratings list in place.  Subscription in the
ratings list is optional; a separate subscribe message must be sent.
I am unconcerned with the bandwidth right now.  For a mailing list, if
everybody sent ratings to everyone else, you get N^2 growth.  As it
is, very few people are going to have the software to generate or
accept ratings, so for prototyping this just doesn't matter.
As far as the long run, just as one will pay someone, somewhere for
delivery of a mailing list, one will pay for delivery of a ratings
list.  I would expect there to be an equilibrium reached where some
ratings-crunching service gets all the ratings and spits out digested
versions in succinct form.  The digested rating is just another
rating, after all.
No, that is not how I'm doing the cypherpunks experiment.  What you
summarize above is similar to what I proposed for Usenet.  I am
proposing something different for this mailing list, something which
is workable given the constraints on configurability and resources at
I am not saying that a rated list shouldn't exist, merely that it
won't be sent from toad.  I'm perfectly happy with derivative
information products based on cypherpunks; anybody who wants to delay
the feed and take into account the ratings should be free to do so.
I agree, and an excellent suggestion.  Perhaps a simple syntactic
solution is to have each rating be of the form
In other words, a key word followed by a fraction from zero to one.
The number of digits is left purposefully unspecified to allow for
finer and finer aggregate distinctions as the number of raters
This syntax appears to support all the criteria I mentioned in a
previous post.
So?  Look at the References: field in a typical Usenet posting that's
down in the discussion tree.  Gad.  The Message-Id is guaranteed to be
unique, and if it's longer than it might be, it's certainly easier and
more general to use that than to invent another unique identifier.
One is just not going to be able to rate easily without software, I
anticipate.  Not everyone is going to be able to take advantage of the
ratings immediately, either.

@_date: 1994-02-22 16:06:50
@_author: Eric Hughes 
@_subject: RATINGS: say what? 
The cypherpunks-ratings list is would not be transmitting anything but
ratings about cypherpunks messages.
I've not responded to anything else in the message because it all
assumes the incorrect model.

@_date: 1994-02-23 19:41:49
@_author: Eric Hughes 
@_subject: Digitally Signing Physical Objects 
This is the standard reason given why undeniable signatures can't be
passed on.  And it is correct, as far as it goes.  But the conclusion,
that "in general" the trust cannot be passed on, while technically
correct, is not of pragmatic consequence.
I'll start a service to perform any undeniable signature verification,
even ones for money.  I'll perform the verification, and then make an
attestation that I perfomed the verfication and whether it succeeded
or failed.  I sign this is a regular digital signature, the kind that
is infinitely duplicable.
Only a few such services need exist to assure the public of the
results of a signature verification.
True, there is a layer of mediation here, but of what practical
consequence is that?  In fact most transactions are mediated already.
If I expect to make money charging a dollar per verification, and if
there are some who will publish their experiences of the verification,
that reduces the total income I can expect to, oh, say, the logarithm
of the size of the market.  In other words, why bother?

@_date: 1994-02-24 10:38:49
@_author: Eric Hughes 
@_subject: RATINGS: Subject tags 
appears that strn uses materials which are mostly intrinsic to the
message base in order to rate articles.  Those ratings which are
shared seem to be binary in nature, simply to include articles in
virtual lists of articles.
The 'strn' package described might be a good place to start for a user
agent, but it seems not to have the social goals that the ratings
proposal I have in mind does.

@_date: 1994-02-24 18:01:40
@_author: Eric Hughes 
@_subject: No Subject 
And one usual method to verify external binaries is with a digital
signature, which brings us back to square one.

@_date: 1994-02-26 07:25:08
@_author: Eric Hughes 
@_subject: DH Exchange Code / Magic Money comments 
I know I recommended this characteristic for the modulus (and I got it
from Burt Kaliski).  Nevertheless, (n-1)/2 doesn't _have_ to be prime,
it's just much easier to prove that your generator actually is a
generator.  In fact, half the elements in such a ring are
multiplicative generators.  The algorithm to find moduli is simple,
even if it does take a long time.
There are faster ways of looking for moduli. One method is to take a
candidate prime and try to factor n-1, if you can.  (If you can't,
give up and go on.)  If you get a few small factors and one large
probable prime factor, then you can still look for known generators.
The candidate must first be relatively prime to the modulus.  Then one
checks that the candidate raised to each of the factors is not 1.
There are fewer generators in such moduli, but the moduli are easier
to find.
The security of the modulus to a precomputation attack is equal to the
size of its largest prime factor, so while the second method is
ever-so-slightly less secure with the same modulus size, the effective
security can be made the same by increasing the modulus size of the
second method.
Be careful about saying "indefinite".  It's not true in the long run,
so far as we can tell now.  As computational power increases, so also
do the lengths required to prevent attacks.
Remember, that every crypto system has a sunset after which there will
be enough computation available to read past traffic, if recorded.  No
cryptosystem is good forever.  One always needs to figure out just how
long one wants one ciphertext to be secure.
Or is that a sunrise? ...
(I pass over arguments about physical limitations of computation, not
because I think they are wrong, but because I'm not convinced that we
know enough to know we're asking the right questions.  Plus these
arguments do not yield key sizes that are yet practical to implement.)
And lastly, you can trust a thousand-bit modulus p where (p-1)/2 is
also prime.  Go ahead and use it.

@_date: 1994-02-28 11:57:12
@_author: Eric Hughes 
@_subject: I have FOIA'd the Clipper Key Escrow databases 
Should John's FOIA request for the clipper key database work, it
creates a wonderful hole in the entire key custody system.
It would require a legislative act to plug the hole.
This is extremely significant, since the whole clipper strategy is
based on unchecked and unbalanced actions by the executive branch.  No
laws were passed to create clipper and no judicial review has taken
John's request will be denied, no doubt, and will go to court.  Should
he prevail in court, the executive branch is bound by that decision.
A key custody database which was public would make the system insecure
and unusable.  The executive branch could not change this.  Only the
legislature could.
Now, how many legislators do you know that are going to make a public
record by voting in favor of Big Brother?
We are witnessing the genius of framers of the USA Constitution here,

@_date: 1994-01-04 09:09:10
@_author: Eric Hughes 
@_subject: ANNOUNCEMENT: January cypherpunks meeting is non-standard 
The January 1994 Bar Area cypherpunks meeting will not be the second
Saturday of the month, but rather the third.  Usenix is in San
Francisco the following week, and it was decided at our last meeting
to make it easier for some Usenix folk to attend.  We also decided to
give each meeting a theme in order to better focus discussion.
When: Saturday, January 15, 1994
      12:00 noon - 6:00 p.m.
Where: Cygnus Support offices, Mt. View, CA
Theme: Software Infrastructure for Cryptography
The lack of a unified software architecture is a major obstacle to
widespread deployment of cryptography.  Existing approaches have been
primarily for specific purposes or applications.  We'll talk about
infrastructure issues, technical, social, and political.  We'll review
existing work at the system level (cfs, swipe) and at the application
level (pgp, pem).
If you have a specific presentation, please send me some email
(hughes at ah.com) and I'll schedule you in.
[Directions to Cygnus provided by John Gilmore. -- EH]
Take US 101 toward Mt. View.  From San Francisco, it's about a
40-minute drive.  Get off at the Rengstorff Ave/Amphitheatre Parkway
exit.  If you were heading south on 101, you curve around to the
right, cross over the freeway, and get to a stoplight.  If you were
heading north on 101, you just come right off the exit to the
stoplight.  The light is the intersection of Amphitheatre and
Charleston Rd.  Take a right on Charleston; there's a right-turn-only
Follow Charleston for a short distance.  You'll pass the
Metaphor/Kaleida buildings on the right.  At a clump of palm trees and
a "Landmark Deli" sign, take a right into Landings Drive.  At the end
of the road, turn left into the complex with the big concrete
"Landmark" sign.  Follow the road past the deli til you are in front
of the clock tower that rises out of one of the buildings, facing you.
Enter through the doors immediately under the clock tower.  They'll be
open between noon and 1PM at least.  (See below if you're late.)
Once inside, take the stairs up, immediately to your right.  At the top
of the stairs, turn right past the treetops, and we'll be in 1937 on your left.  The door is marked "Cygnus".
If you are late and the door under the clock tower is locked, you can
walk to the deli (which will be around the building on your left, as
you face the door).  Go through the gate in the fence to the right of
the deli, and into the back lawns between the complex and the farm
behind it.  Walk forward and right around the buildings until you see
a satellite dish in the lawn.  Go up the stairs next to the dish,
which are the back stairs into the Cygnus office space.  We'll prop
the door (or you can bang on it if we forget).
Or, you can find the guard who's wandering around the complex, who
knows there's a meeting happening and will let you in.  They can be
beeped at 965 5250, though you'll have trouble finding a phone.
Don't forget to eat first, or bring food at noon!  I recommend hitting
the burrito place on Rengstorff (La Costen~a) at about 11:45.  To get
there, when you get off 101, take Rengstorff (toward the hills) rather
than Amphitheatre (toward the bay).  Follow it about ten blocks until
the major intersection at Middlefield Road.  La Costen~a is the store
on your left at the corner.  You can turn left into the narrow lane
behind the store, which leads to a parking lot, and enter by the front
door, which faces the intersection.  To get to the meeting from there,
just retrace your route on Rengstorff, go straight over the freeway,
and turn right at the stoplight onto Charleston; see above.
See you there!

@_date: 1994-01-22 13:36:26
@_author: Eric Hughes 
@_subject: ADMIN: toad got mailbombed 
Tim mentioned that he'd had some problems getting stuff back from the
list.  Others have sent me mail wondering about strange formats from
the mailer.  Well, toad got mailbombed.
The culprit--and no attempt at anonymity here--was 'css at netcom.com'.
He was trying to get off the list by sending to
owner-cypherpunks at toad.com.  Well that address is a bounce handling
address, and I don't read it very often, and then I ignore
non-computer generated messages.  Two words: clueless and projecting.
He made at least three separate kinds off attacks: sending mail back
to posters to the list, sending mail back to the list at large, and
mailbombing toad with UNSUBSCRIBE x 200 messages, many (several dozen)
at a time.
What is humorous to me is not the lost sysadmin time (hours) but the
lack of sophistication in the attack.  No attempt at hiding identity,
lack of creativity in bomb content, lack of specificity in targeting.
For example, he could have forged a post to one of the .test groups in
usenet with the list administrator (me) as target.  Hundreds of
messages would have flowed in to my mailbox over the next week,
cramping my ability to use my inbox.  Such a forgery could be done,
say, by using an anonymous poster and gluing in a Reply-To: field.
Or even better might have been picking a large mailing list that
doesn't rewrite header fields and making sure that it leaves the
mailer with 17 Received: fields and an Errors-To: field pointing to
the victim.  The cypherpunks alias on toad, for example, tacks on 3
Received fields in addition to the one or two that your mailer uses,
but you can just add empty Received: fields--the code that bounces
mail when it sees more than 17 (or 18-21, depending) Received: fields
doesn't look at their contents.  These fields can be added with
outgoing  header pasting, for example.  I do not recommend using the
cypherpunks mailing list for this purpose, however.

@_date: 1994-01-26 09:47:10
@_author: Eric Hughes 
@_subject: quote of the day 
Because of economics and political stability.
You can build computers and monitoring devices in secret, deploy them
in secret, and listen to _everything_.  To listen to everything with
bludgeons and pharmaceuticals would not only cost more in labor and
equipment, but also engender a radicalizing backlash to an actual
police state.
Of course, if one is paranoid, these considerations of the whole do
not hold, since for only one person the cost balance is reversed.
There is safety in numbers.

@_date: 1994-01-27 09:37:37
@_author: Eric Hughes 
@_subject: On crypto language 
This is a rant, touched off by an egregious example.
An MIT talk:
With no disrespect to Fiat personally, this title indicates one of the
seriously Bad with a capital B things about the modern crypto
Does "Traitors" really belong in a "pay television" context?  Please.
The implication is this: Hook up for a second copy of 'Beauty and the
Beast' and be killed by firing squad in a secret Disneyland star
Crypto can make strong systems for good or for ill.  Governmental
mandated digital signatures on required-to-be-public documents would
be *worse* than we have now.  We should always beware of making sure
are systems actually do what we want them to.
In the same vein, we should not lead others to believe that our
systems are designed for purposes other than what we intend.  The
descriptive language we use will create the first impressions, the
connotative impressions, of what we are doing.  Do we want to be
hunting 'traitors' or nabbing 'cheaters'?  Save that for someone who
wishes to pay a government for a police state.
One would think from reading the crypto literature that the modern
crypto community was employed by FINCEN to chase criminals, with all
the talk of 'cheaters'.  Make no mistake, I believe this to be
actually true in part, although the connection is semiotic rather than
direct.  Always, always beware of the uses of a system.
Here is my rule for describing protocols.
'Cheater' implies intent to defraud.  'Double spender' includes actual
cheaters as well as software and network failures.
'Spoofer' implies intent to lie about identity.  'Interposer'
describes an agent which is placed in the middle, which might be there
in order to spoof, but also applies to a router.
'Eavesdropper' implies intent to remain secret while listening, and a
'spy' is an eavesdropper with malign intent.  'Listener' merely
describes the listening.
'Enemy' is someone who wishes you harm.  'Opponent' is someone to whom
one is in opposition, which includes both enemies and a chess partner.
We communicate the protocols with mathematics but our own intentions
by our choice of words.

@_date: 1994-01-27 11:42:13
@_author: Eric Hughes 
@_subject: Anonymous Pools 
The message drop described was held at a single place, not transmitted
widely or even available widely, as a message pool is.  I've come to believe that message drops or, more generally, rendevouz
points are a big pragmatic win.
Here's why.  I have a friend out here whose BBS was seized in a civil
action by Sega.  Sega's lawyers made a pleading to the court based on
logs they had taken from the BBS.  The court granted Sega the ability
to search and seize the computer.
But all Sega had was the phone number.
So Sega first had a _subpoena duces tecum_ served on Pacific Bell.
This form of subpoena is not an order to appear but rather an order to
produce documents or items relevant to a judicial proceeding.  Sega
gave Pac Bell the phone number, Pac Bell gave them a name and address.
This was the same name and address that the US Marshall's service used
when seizing the BBS equipment.
Suppose that phone number was an email address or an IP address.
If the provider of message or packet delivery actually knows the final
destination, a subpoena to produce records will disclose that
destination.  On the other hand, if the 'public face' of the address
is only mapped to some authentication means (such as a password or a
public key), then such a subpoena will only reveal that authentication
info, not an identity or a location.
Willful ignorance can be a beautiful thing.
Furthermore, if the system is constructed such that the only way to
get at the information in RAM about current connections is to take
down the system, well, then there's no way to get at that information,
is there?

@_date: 1994-01-31 08:24:27
@_author: Eric Hughes 
@_subject: Anonymous Remailers 
1. If you fake mail by talking SMTP directly, the IP address or domain
name of the site making the outgoing connection will appear in a
Received field in the header somewhere.
2. Fake mail by devious means is generally frowned upon.  There's no
need to take a back-door approach here--it's bad politically, as in
Internet politics.

@_date: 1994-07-08 16:26:22
@_author: Eric Hughes 
@_subject: ANNOUNCE: Bay Area physical meeting tomorrow 
What: Bay Area cypherpunks physical meeting
Where: Silicon Graphics, Cafe Iris, Bldg 5 (directions below)
When: Saturday, July 9, 1994
      12:00 noon - 6:00 p.m. PDT
The theme for this month's meeting is swIPe, an encrypted IP package.
A Unix implementation is on soda.berkeley.edu:pub/cypherpunks/swIPe.
Please grab a copy and look at the docs before the meeting; it will
help focus the meeting.
swIPe may well be the PGP for the internet protocols.  The use of
encrypted IP channels can make remailers more secure, can help provide
real-time packet mixes.  Encrypted IP is an enabling element for full
crypto deployment.

@_date: 1994-07-08 16:30:56
@_author: Eric Hughes 
@_subject: ANNOUNCE: Last minute Crypto '94 registrations 
Today is the official last day to register for Crypto '94.

@_date: 1994-07-14 12:07:09
@_author: Eric Hughes 
@_subject: Probabilistic Encryption 
I hope we're not about
   to get the usual kiddy PRNG exor encryption lecture. A PRNG XOR-ed with a data stream is a perfectly good stream cipher,
provided the PRNG is sufficiently strong.  It's that sufficiently
strong part that usually goes wrong.  LFSR doesn't cut it (Linear
Feedback Shift Register).  Neither does LC (Linear Congruential).  I
should point out that these are both iterates of where the domain is Z_2[x] (polynomials with coefficients mod 2) for
LFSR and Z (integers) for LC.
Blum-Blum-Shub makes a very good stream cipher, even with just XOR.
For those of you may have interpreted GT's comments as to disparage
all PNRG-XOR combinations, I hope the above may help.
Graham, you can read up on probabilistic encryption on page 406 of
Schneier.  In fact, it discusses the BBS generator in this context.

@_date: 1994-07-15 13:51:13
@_author: Eric Hughes 
@_subject: Key length security (calculations!) 
> Factoring is suspected to be in the class NP (or
   > even harder, some suspect), but it has not yet been proved to be so.
NP is nondeterministic polynomial time, meaning that you can verify
the answer in polynomial time.  You need not be able to derive the
answer in P time.  The 'nondeterministic' part means that the machine
guesses the reason for the correct answer and then verifies that it
has the right answer.  The reasoning is encoded in a piece of data
called a witness.
Since one can multiply two numbers together quickly, factoring is
NP-hard.  (X-hard means that the answer comes from a 'short' sequence
of decision questions in complexity class X.)  The verification,
multiplication, is in P, so factoring, the inverse of multiplication,
is NP-hard.  Since every P problem can be verified in P time (by running the P time
algorithm without the need for a witness), P is a subset of NP.  The
unknown question is whether it is a proper subset.
   Those who have studied the matter generally believe that factoring
   is NP, but is not NP complete.
Factoring isn't in NP.  Factoring is NP-hard.  Problems in P and NP
are decision problems, i.e. problems which have true or false answers.
NP-hard means that the problem can be reduced to answering a short
list of NP problems.  In this case, those questions might be "Is the
second-lowest bit of the smallest factor a 1?" and so on, questions
about specific properties of the factorization.  Note that a
factorization makes a suitable witness for every such NP question.
   Factoring cannot be "even harder than NP" since a simple minded
   brute force attack is 2^(n/2), which is only NP
2^n problems give you E, exponential time.  There's also NE,
nondetermistic exponential time, problems which have witnesses
verifiable in E time.  Merely having an exponential time algorithm
does not mean that the problem is in NP.
NP is a subset of E, however.  The easy algorithm is exhaustive search
of the space of possible witnesses, which in exponential in the length
of the P time verification method, and therefore exponential in the
length of the input.
   As Timothy May points out, if factoring is NP, then modest increases
   in key length can easily defeat enormous improvements in factoring.
Also not quite true.  Consider a putative problem whose provably best
algorithm is O(n^(log log n)).  This algorithm dominates every
polynomial (and hence is _not_ in P), but grows extremely slowly.  How
extremely?  Take the log base at 10 and n = 1 googol.  The calculation
yields O(n^2).  No such algorithms or problems are known, I might add;
neither is their existence firmly denied.

@_date: 1994-07-16 10:13:10
@_author: Eric Hughes 
@_subject: Factoring 
> When discussing complexity it is usual to use a measure of problem
   > size that corresponds to the physical size of the answer or
   > the question.
Not quite.  The length of the answer is not typically used in measures
of complexity.
The 'n' in O(n^2), et al., is the length of the input.  Exactly that,
and nothing more.  The length used is the number of symbols used to
encode the input from some finite alphabet of symbols.  Thus, the
lengths are determined up to a constant factor related to the
logarithm of the size of the alphabet.
   > Thus thus if you are factoring a 1024 bit number, n is 1024, not
   > 2^1024
Yes.  Getting the wrong 'n' will make complexity theory meaningless
and impenetrable.

@_date: 1994-07-16 10:23:34
@_author: Eric Hughes 
@_subject: Factoring 
Factoring keeps being described as a 2^(n/2) problem, yet AFAIK
   [...], it's doable in linear (O(n)) time.
Remember that the 'n' is the length of the input.
   /* Algorithm:  To factor the number n, start with n boxes, each with on
      "marble."  Remove last box, put it's marble in box   If all boxes
      have the same number of marbles, the number is factored.  If not,
      remove last box.  Put marble in box   Compare.  Etc.
      possible optimizations: div by each prime l for a quicker starting
      */
This algorithm is equivalent to trial division by each number less
than n.  At each stage the 'box counter' is equal to the remainder and
the 'number of boxes' is the divisor.
Now since n can be encoded in lg n bits (lg = base 2 logarithm), the
length of the input is N = lg n.  The representation of the boxes can
be represented in O(N) bits; use two counters, each the length of the
input.  The number of trial divisors is about 2^N, yielding an
exponential time algorithm.

@_date: 1994-07-16 10:26:23
@_author: Eric Hughes 
@_subject: CPP: Card Playing Protocol 
I looks like I am going to have to track down the proceedings from
   Crypto 85, 86, and 87.  (Still in print?  Expensive??)  All the main
   sources seem to be in them.
As Tim mentions, the Crypto proceedings are about $60-80.  I'd
recommend a library for specific or occasional use.  MIT's libraries
are very complete for cryptography, for example.

@_date: 1994-07-16 10:45:44
@_author: Eric Hughes 
@_subject: Card Playing Protocol? 
only notices that she can now be part of the World Wide Duplicate
   Bridge Tournament that she heard about on All Things Considered.
Duplicate games won't work on the net because the assumption is that
the players have no advance knowledge of the cards of the other
players.  Even if the same hand is dealt simultaneously to multiple
virtual tables., the differences in order of play will reveal cards
early for some players.
The hole is the sharing of information between players.
Duplicate could still be supported with physically based, but
distributed, rooms of play, using the Internet for logistical support.
   Is there a flavor of effort I forgot?
There is a non-crypto issue of how one finds playing partners without
a central server.  An IRC channel seems to have the right properties:
real-time, centrality of name, distributed information paths.  IRC
might be able to be hacked into directly.
The code to find of playing partners should integrate digital
signatures for identity, in order to make possible long scale
tournament play.
Mutual agreement should be required for the formation of a group.
Automatic agreement can always be implemented in client software.
There is likely an interesting protocol here for the negotiation of
group formation without revealing preferences that are not manifested
in the creation of a group.
I would strongly suggest the separation of the communications, user
presentation, and decision parts of the client software.  Folks should
be able to pick the presentation of the cards that they want: table
layout, card backs, etc.  Decision in current card games is currently
all by user input; the user sees the cards, decides what to do, and
clicks.  People will want to try out card playing algorithms, and you
might as well leave a hook in for them.

@_date: 1994-07-16 10:58:36
@_author: Eric Hughes 
@_subject: Card Playing Protocol 
1) I am wondering whether a "digital deck of cards" is a good choice.
Premature abstraction is a severe problem if it happens to you.  Read
some of the literature to get an idea of the techniques before you
pick an abstraction.  Your remarks about knowledge models for an
abstraction proposal of "a table with stacks of cards" seem on target.
Most card games require a random permutation, mutually trusted to be
random, which can be revealed one card at a time.  That permutation
need not be generated in advance.  Games like Magic--The Gathering in
which each player shuffles their own deck, are easier to implement and
only require bit committment.
The revealing of cards cannot be global, since at the beginning each
player sees only their own cards.  The revealing of cards should
require that the cooperation of each player that sees the cards, and
possibly some others.
Time to read crypto.

@_date: 1994-07-18 11:09:22
@_author: Eric Hughes 
@_subject: Card Playing Protocol? 
If I implement a card playing protocol and Okamoto & Ohta's bankless cash
Bankless?  The paper I have from them (in CRYPTO '91) is not bankless.

@_date: 1994-07-18 11:37:39
@_author: Eric Hughes 
@_subject: Card Playing Protocol? 
(At a comms protocol
   level there might always be a single server per game--I don't know
   yet--but I would like to hide that sort of stuff from users.)
There's no need for a central server per game, even running on one of
the player's own machines.  What is possible with crypto is completely
flat distribution of the simulation.  The difference is profound.  I
would suggest that all who don't understand this meditate upon coin
flipping protocols, the simplest flatly distributed simulation--here,
of a random number generator.

@_date: 1994-07-18 11:40:42
@_author: Eric Hughes 
@_subject: Card Playing Protocol 
>Time to read crypto.
   HEY!  I've read Schneier (if that is what you meant).
No.  Schneier is a start, but the source papers are really a must read
for an actual implementer.
Schneier's book is very good as a survey of technique and ideas.  The
bibliography is _excellent_, and make the survey truly useful.

@_date: 1994-07-18 12:00:03
@_author: Eric Hughes 
@_subject: How to make a random permutation 
A deck shuffling method was presented:
   //shuffle the deck:
   for (i=0; i<=10000; i++)
    {
     c1=rand() % (4*13+2);
     c2=rand() % (4*13+2);
     swapcards(&cards[c1],&cards[c2]);
    }
I continue to be amazed at how few people know an algorithm to
generate a truly random permutation efficiently.  There's one (due to
Parnas, if I remember correctly) which generates each of the 52!
possible permutations with equal probability, runs with exactly 52
loop iterations (i.e. a 200 time speed up over the above), and is
provably correct by a simple induction.
Assume random(x) returns a random integer between 0 and x.
a[ 0 ] = 0 ;
for ( x = 1 ; x < N ; ++ x ) {
    i = random( x ) ;
    if ( i == x ) {
    } else {
        a[ i ] = x ;
    }
Proof is left to the reader.  (Hint: use induction on N.)

@_date: 1994-07-18 22:22:19
@_author: Eric Hughes 
@_subject: GUT and P=NP 
question struck me:  If a Grand Unified Theory exists, would it not    prove P=NP to be true?
No.  Hardly.
   behaviour we believe to be non-deterministic
   really isn't: it obeys the GUL.  So P=NP must be true, since NP is
   an artifact our pre-GUL way of looking at things.
Non-determinism will exist forever as an idea, just the same way that
no real number has ever been measured, merely approximations to them.
NP is an expression of that idea.  There are other ways to formalize
NP without resorting to non-determinism.  NP is the class of problems
for which there exists a witness to a PTIME computation.
Non-determinism is only another way of rephrasing the existential

@_date: 1994-07-18 22:26:26
@_author: Eric Hughes 
@_subject: Encrypting fax machine 
>We use an encryption algorithm called seeded pseudo-random
   >number generator, Mr. Varga said.  The company chose that
   >algorithm because it is in the public domain, he added.
   One would think that anybody who would go to the expense of designing an
   encrypting FAX machine could at least afford to read the introduction to
   any beginning crypto book.
I just said this last week.  PNRG-XOR can be very secure.  If they're
using Blum-Blum-Shub, it could be secure, since there are other things
to go wrong.  If they're using a LFSR, it's not secure.
It looks like a none-too-competent technology reporter to me.

@_date: 1994-07-22 10:27:22
@_author: Eric Hughes 
@_subject: Small transaction amounts 
Not yet. But I'm just a few weeks away from Alpha testing a very
   large web-based project which has all sorts of agents interacting
   with each other and dealing in very small amounts of money. It
   includes a second rate (but effective) digital cash protocol.
In a closed computational environment, there is no need for
cryptographic digital cash.  Telescript, for example, is a closed
computational environment, at least now.  Inside such an environment,
one can rely upon the fact of closure for security in money transfer.
The operators of the closed place provide an assurance that running
the agents will be done as expected, and that funds will flow as
I can't tell from the above quotation whether the project is closed in
this way or not.  Verbum sapienti ...
The cost of cryptographic computation, database lookups, and amortized
staff time (the most expensive, and not getter cheaper nearly as fast
as the others) for each transaction has some characteristic minimum
value.  The transactions cleared through such a system will have their
own minimum, which will be on the order of the cost of provision.
One can create closed environments expressly for the purpose of doing
this kind of low-cost low-level transaction.  These systems have
reduced resource requirements and will always be cheaper to operate
than a full scale digital cash scheme.
The closure, however, of these systems means that they don't scale.
That's bad, fatal, in fact.  That doesn't mean that closed systems
will disappear, merely that the largest systems must be open.
What is desirable economically is that the boundary between closed
clearance systems and open clearance systems be porous enough that the
market can find an optimal distribution between the two varieties.

@_date: 1994-07-22 20:06:00
@_author: Eric Hughes 
@_subject: Voice/Fax Checks 
This seems like a good approach for a lot of cases.  You end up having
   three classes of transactions: small, medium, and large, with slightly
   different strategies for each.
There are more categories than these, actually.  There's already a
banking distinction between large and very large.  One of the high end
funds transfer systems in the world has a _minimum_ transaction size
of about two million dollars.  You can bet that these are handled
differently than a one thousand dollar check (still "large").
In addition to direct costs of provision, there are also effective
costs of collection risk.  At each level, these collection risks have
to be estimated and taken into account.  Since the real desire is for
a known upper bound, some fraud or other form of transaction failure
can be expected.
When credit is being offered (even intra-day), the risk increases
proportionally.  Every off-line system offers some amount of credit,
however small.
   Paying a penny per
   site isn't going to bother me much, but if I have to set up an account
   for each one ahead of time I'm probably not going to bother.  You can still use an account mechanism, but with an intermediary whose
business it is to aggregate small amounts as these proposed and clear
the total periodically.  That's now one account setup for the

@_date: 1994-07-22 20:16:40
@_author: Eric Hughes 
@_subject: Small transaction amounts 
Right...I think.  What has to scale is the "semantics of money."
   Within a small area ("box"), security is guaranteed by how the enclosing
   system works, and over a larger area it's done by crypto There are several ways to make the boundary porous.
1.  Differing rates of clearing a smaller system to a larger.  I can
clear to a larger system once an hour, once a day, once a month, etc.
One can keep a risk bound steady in a system with increasing
transaction flux simply by increasing the rate of clearing.
2.  Probabilistic verification.  In a system where verification is
used, the transactions at the low end might be certified in real time
at some rate.  This decreases the cost of provision while keeping an
eye out for the upper bound on risk.
3.  Net settlement.  A system where one can both add and subtract
value can clear periodically only the net difference in funds.  Net
settlement works really well for small scale systems, but systemic
risk increases proportional to system size.  4.  Exposure caps.  In a net settlement system, there might be a
maximum positive or negative balance that would be permitted before
clearing to another system was required.  Futures markets have rules
similar to this.
5.  Intraperiod overdraft loans.  A "daylight overdraft" is a running
net negative balance in between clearing times.  By charging for this
money as a short term loan, there is an incentive to minimize its use.
There are more, certainly, and any student of financial markets could
name another five without too much thought.  There are some
interesting and significant issues involved in verification of some of
these policies.

@_date: 1994-07-25 19:43:08
@_author: Eric Hughes 
@_subject: Voice/Fax Checks 
A couple of pointers on current outfits trying to undercut the "transaction
   cost", none of them the ultimate we all root for, but nonetheless.
One very important point to remember, however, is the following.  When
money of any form is electronic, you can use it to purchase your
favorite cryptocash certificates from.

@_date: 1994-07-25 19:43:29
@_author: Eric Hughes 
@_subject: Voice/Fax Checks 
>You can still use an account mechanism, but with an intermediary whose
   >business it is to aggregate small amounts as these proposed and clear
   >the total periodically.  That's now one account setup for the
   >customer.
   How, though, would the ftp site which wants to know whether I'm "good for"
   the one cent charge to download PGP do so?  Does it have to check with an
   agent on the net somewhere which will vouch for me?  Aren't the communica-
   tion costs then the same as an online system?  Your agent would purchase the service and immediately resell to you.
This legal arrangement need not be the same as the communications
flows.  The service provider is selling to a large trusted customer;
they clear transactions once a day, say.  The intermediary provides
small amounts of credit to the individual customers, who clear with
the intermediary when, say, they go over a limit, like $10.
What you have here is a liability transfer from a small customer to a
larger intermediary.

@_date: 1994-07-25 19:45:03
@_author: Eric Hughes 
@_subject: Forward secrecy 
Hate to pick nits here, but isn't the acquisition and use of a public key
   "teaching" your machine to read Tim's "language"?
I agree.  Each public key creates a different encoding, or a different
language, as it were.  These encodings/languages are all related, but
mutually incomprehensible.  Encryption software has the capability to
read any of these languages because it is multi-purpose software.
Because the software is multipurpose, however, there is a greater need
for forward secrecy.  Forward secrecy is the property that an
intercepted communication cannot be read because the secret keying
material, however generated, has been destroyed by the time such
keying material is sought after.  For example, in a secure telephone,
forward secrecy begins when you hang up the phone, because the key
inside it, generated, say, by a D-H key exchange, is destroyed when
you put down the receiver.
For PGP and PEM, forward secrecy begins when you destroy all copies of
your private key.  This will leave you without a private key, of
course, and so should be done only after a key change.  The forward
secrecy also applies to the (previous) holder of the private key.  If
your only copy of encrypted email, for example, that you have after
you destroy your private key is just the encrypted email, then you
won't be able to read your own mail.  Therefore, all old traffic
addressed to a public key needs to be re-encrypted or kept in
This is one of the main reasons for periodic key changes, to achieve
forward secrecy for email.  After I change keys and destroy my old
private key, now the _only_ way to decrypt the messages is to derive
the private key from the public key--in RSA, to factor the modulus.
This is computational forward secrecy.  Diffie-Hellman key exchange also yields computational forward secrecy,
because the session key generated can be derived assuming a device to,
say, take discrete logs on the order of the size of the modulus.
If messages have been intercepted and logged, no seizure of equipment
will yield the private key.  Forward secrecy protects you, therefore,
from violence, be that the procedurally mitigated violence of the
courts or the arbitrary violence of another party.
Here, then, is the connection back to the original issue.  The courts
distinguish between acts of speech (fifth amendment protection) and
supplying objects, such as a subpoena provide the key to a safety
deposit box.  As Marc Rotenberg once put it to me, the court cannot
require you to incriminate yourself, but they can require you to
participate in your own downfall.  Forward secrecy protects you
against court order, because you cannot be held in contempt of court
for not providing something that doesn't exist.  If you destroy your
keys in a timely fashion, your exposure is limited to the time since
the last key change.
Needless to say, there's no real standard software support for forward
secrecy for email.  A good cryptographic system should store the
plaintext of an encrypted communication in a separately encrypted
place.  On Unix, one can use Matt Blaze's CFS to keep all of one's
mail on, but even then there's no support for keeping encrypted mail
around in such a way that allows you to prove, _without using the
private key_, which will be destroyed at some time, that a particular
ciphertext matches any particular plaintext.
Consider PGP, where the outer wrapper can only be decrypted with a
private key.  Once that public key is gone, that message is now
useless even as verification for anything, unless the session key is
also stored separately.  If you have the session key, the encrypted
session key can be generated by an application of the public key, and
verified to match.
Assuming you have the public key, that is.  If the public key has been
published, then you can safely assume that it can be retrieved.  To
achieve unconditional forward secrecy, however, requires that the
public key _never_ be published, but only given to correspondents.  In
this situation, one achieves unconditional forward secrecy when you
destroy both private and public keys and all your correspondents
destroy the public keys.
An aside: in a two cipher system, you only get the unconditional
security with respect to the public key cipher.  The secret key cipher
(like IDEA) is still only computationally protected, since the entropy
of the plaintext is not maximal.  This, however, is still an
advantage, since there's more uncertainty about the long term security
of the algebraically based public key ciphers than there is about the
secret key ciphers.
Now, as far as I know, there's _NO_ support anywhere for preventing
the correspondent to publishing the private key.  Even software which
was not informationally secure, which simply flagged a public key as
"not for further distribution", would be a help, since it would then
require custom software in order to distribute.  At the very least it
would allow mutually trusted parties to prevent accidents.
Another technique would be to develop a keying system in which
distribution of public keys were tied to the public keys of the
correspondent.  This might not prevent (informationally) the key from
being distributed, but one would want to it identify the distributor.

@_date: 1994-07-26 10:05:00
@_author: Eric Hughes 
@_subject: GUT and P=NP 
Okay.  So I should be so rude.  People please.  When someone, especially
   like berzerk or tcmay makes a strongly definitive statement, PLEASE try
   not to show your ignorance to the whole group.
Famous last words?
   Cantor demonstrated, near the turn of the century, that no such system
   can represent all reals in [0,1].  Boring technical explanation follows.
I think you've completely missed the point.  The proposed
computational device had as its symbol alphabet an uncountable set.
It's a perfectly good mathematical abstraction.  It's doesn't matter
that it can't be implemented.
And let's not call such a machine a Turing machine, OK?  Turing goes
on at great length in his original paper about how the symbols can't
be too similar to each other.
And to answer the point of another writer, this machine may have only
finitely many states, but the state transition table, being the
cartesian product of the states and the symbols, is also uncountable.
In fact, I would suspect that such a machine only needs a single
state; an interesting bit of research, to be sure.

@_date: 1994-07-26 10:10:51
@_author: Eric Hughes 
@_subject: CYPHERPUNKS TO THE RESCUE 
Why not generate a random number, checksum it, and sign it using a
   public key?  Or is that overkill?
That's overkill.  For an affordable microprocessor for the price point
of an electronic lock, you can't do a modular exponentiation in a
reasonable amount of time.  A two-second delay is likely too long for
_mass_ market, even if certain markets would bear it.  Sandy also
suggest public key.
A shared secret key for a symmetric cipher is sufficient, since the
binding between a single garage and a single opener is usually not
broken.  If your opener had to work with multiple doors, and if the
usual case pertained where two people share the permission to open
some doors but not others, then public key woudl be needed.
So you can do challenge/response, but there's no need to use public
key.  DES would be sufficient.

@_date: 1994-07-26 10:41:05
@_author: Eric Hughes 
@_subject: Forward secrecy 
One possible hole here is that since they share a commen algorith then
   the algorithm is the 'language' and not the actual messages. The algorithm does _not_ completely specify the encoding of plaintext
into ciphertext.  Therefore the algorithm cannot be considered a
language, since it's incomplete.
   There is also the aspect
   of once discovered you could be charged with obstructing justice which
   has very stiff penalties.
I am baffled as to what you could possibly mean here.  It sounds
ridiculous to me.
   They make you participate by giving you immunity in which case you have no
   choice but to reveal it or go to jail. This is not what immunity is.  Immunity is given for testimonial
evidence that would be self-incriminating.  By immunizing the witness
before testimony, the testimony, which would then be tantamount to a
confession, is no longer incriminating, that is, the testimony no
longer turns the witness into a criminal in the eyes of the law.  With
the presumption of innocence, it is _conviction_ that makes one a
criminal, not commission of a criminal act.
   While it is true you can't be held in contempt of court for not providing    something that doesn't exist they can get you for destroying evidence.
"Destroying evidence" only happens when the materials are destroyed
after they are considered evidence.  If you shred papers that contain
incriminating conversations before anybody asks for them, that's not
destroying evidence, because at the time of destruction the papers
weren't evidence.  This is true even if you think you are under
investigation.  You have no responsibility to cooperate in advance.
Since court proceedings are a highly structured form of social
epistemology (finding out the truth), if there is no proof that
destruction occurred, or insufficient proof that you did the
destruction, there is no conviction.
Consider Sandy's "little brother inside" idea.  What he left out was
the two-hour UPS battery, also inside, so that when seizure happens
the machine can't be turned off.  You'd have to disable the off
switch, of course.
Now, immediately after seizure, you call up the pager inside and
instruct the computer to start wiping disk.  This would be considered
destruction of evidence were it able to be proved that there was data
on it when it left your house, but not when it arrived at the station.
Since when the disk is _first_ looked at, it will be completely
random, there's no proof of alteration.
"What was all that disk activity the whole time?"  "Oh, factoring numbers
takes large amounts of scratch space."

@_date: 1994-07-26 10:44:02
@_author: Eric Hughes 
@_subject: more forward secrecy 
But I leave nearly all PGP-encrypted messages to me in encrypted form,
   using the "decrypt to screen" option. So communicated and stored
   messages are largely the same.
This is exactly the situation I referred to yesterday.  It's extremely
common, I suspect.  Tim does it, I do it, and I've no reason to
believe that most people do it differently.
Keeping the messages around encrypted with your private key does _not_
have forward secrecy.  Forward secrecy is a valuable property, and it
behooves us to think about how to achieve it.

@_date: 1994-07-26 19:04:25
@_author: Eric Hughes 
@_subject: LITTLE BROTHER INSIDE 
Why not just use an encrypted partition. I guess then it is a problem of
   not being persuaded to reveal the key. What laws/rights does the user have    as to revealing the key ? If the court order you to produce something, you have to or be in
comptempt.  The court will not order you to testify against yourself.
The court can make you show up with the electronic storage that holds
your keys, for example, because this is a physical device.  So the
issue hinges upon the question of whether uttering a passphrase which
makes the device usable counts as giving testimony.  Is explaining how something works (aka giving a passphrase) testimony?
Quite possibly not.  The explanation or passphrase is not
incriminating by itself; it says nothing and claims nothing.
One solution to this is to give the passphrase (or other access
information) to someone who won't give it back to you if you are under
duress, investigation, court order, etc.  One would desire that this
entity be in a jurisdiction other than where an investigation might

@_date: 1994-07-26 19:17:27
@_author: Eric Hughes 
@_subject: (None) 
For the Nth time, it's not latency, it's reordering which is important.
If you have a large enough message flow, adding latency gives you
sufficient reordering.  If your message flow is small, latency doesn't
sufficiently reorder.  Large and small here are message interval times
relative to added latency times.
Random reordering induces random added latencies.  The converse does
not always hold.

@_date: 1994-07-26 21:19:36
@_author: Eric Hughes 
@_subject: LITTLE BROTHER INSIDE 
What if the passphrase was something like "I do not pay income taxes"?
   (half-joking, half-serious)
Since this comes up frequently, I'll comment.
When, under oath, you utter the words "I do not pay income taxes", you
are less abbreviatedly say "I testify under oath that I do not pay
income taxes".
When, under oath, you tell the judge that the passphrase is "I do not
pay income taxes", the less abbreviated version is "I testify under
oath that the passphrase is 'I do not pay income taxes'."
The second statement is not testimony that you do not pay income
This distinction between the performative and the descriptive was used
by one of the video game companies to try to prevent compatible
cartridges from being manufactured.  Part of the protocol required
that the cartridge send back the string "(c) Slimy Video Games, Inc.".
The company then argued an unfair trade practice, claiming that a
compatible cartridge written by another party was asserting a false
designation of origin.
In fact, the sending of the string as part of the protocol is a merely
syntactic use of these characters for purposes of interoperation.  In
the same way that the meaning of a passphrase is immaterial as a
passphrase, so the transmission of the (c) copyright sign is not a
claim of copyright nor a designation of origin.

@_date: 1994-07-27 09:50:14
@_author: Eric Hughes 
@_subject: LITTLE BROTHER INSIDE 
Let us say you have, in fact, committed a
   more serious offense about which the government knows nothing.  If your
   passphrase not only admitted the crime, but gave information which could
   lead to corroboration of the admission, [...]
Well, I'd call that situation stupidity rather than cleverness.

@_date: 1994-07-27 09:57:05
@_author: Eric Hughes 
@_subject: LITTLE BROTHER INSIDE 
Prior to seizure/theft, you would make an    arrangement with an offshore "escrow agent."  After seizure you would    send your computer the instruction that says, "encrypt my disk with the    escrow agents public key."
You don't even need public key.  Just place a secret key in the hands
of your if-duress-no-release agent and put the same key in the right
place in nonvolatile, but erasable, storage inside the computer.  In a
standard PC, there's room for this in the battery-backed configuration
RAM, which has lots of extra space on many newer models.
The use of public key would still require that a session key for a
(fast) symmetric cipher be generated and then destroyed, so you're not
that much better off.  The advantage is that you don't have to destroy
the public key.  Since destruction is pretty easy for information, I
don't consider it much of an advantage.
And, lastly, if you were to use public key, you'd want the agent to
generate a key pair for your use only.  This avoids linkage with other

@_date: 1994-07-28 08:59:48
@_author: Eric Hughes 
@_subject: Latency vs. Reordering 
large scale, latency serves both purposes. I tend to think of these things
   on the large scale, which is the reason I pointed things that way.
That's fine, but say reordering if you mean reordering, and not
something else that merely yields reordering.  Reordering is the
important concept.  Latency is a derivative concept.  Reordering is
more important than latency.
If you use the "collect-and-shuffle" method of reordering, you get
_guaranteed_ reordering.  If you use random delay, you get no
guarantees until you do the detailed mathematical analysis of just how
much reordering that gets you.  Merely _measuring_ the amount of
reordering in a continuous message stream is an interesting
definitional problem.  Calculating these measures will require some
fairly sophisticated probability theory, and NO ONE HAS DONE THAT YET.
Cryptography is about assurances as much as actual security.  Adding
latency now yields NO GUARANTEES about the amount of reordering,
because the work has not yet been done.  Adding latency gives only
warm fuzzy feelings, and no understanding.
The maxim applies here: "I you don't understand how it works, don't
trust it."

@_date: 1994-07-28 18:08:30
@_author: Eric Hughes 
@_subject: Denning and Walker on SKE and International Escrow 
Oh, and this Denning-fest crypto meeting costs $500 to attend, as I

@_date: 1994-07-28 18:11:03
@_author: Eric Hughes 
@_subject: Local Cypherpunks (?) group 
Since the Chicago chapter of CPSR [...] has decided to develop
   aproject [...] the area of privacy (among others), it would seem to
   me to be more productive to work with them.
Unclear on the concept?
Organizations?  We don't need to stinking organizations!  (Withdraw
weapon, begin firing.)

@_date: 1994-07-29 10:47:07
@_author: Eric Hughes 
@_subject: NYET and international data services 
Even in the NYET proposal were implemented, it wouldn't accomplish
it's own objectives.  The existence of international data services,
not under the purview of the cabal of governments administering a
hypothetical mandatory rating system, would provide an end run around
any attempt at censorship.  The only alternative would be to shut down
international data links.
Whatever material someone might find objectionable will still exist,
because the proposal doesn't call for its suppression, merely its
labelling.  That objectionable material will go outside the bounds of
the system, and right back in.  In order to be effective, the system
would have to prevent telnetting to arbitrary international sites.
Do you really suppose China would participate in a Western-values (of
any sort) madatory rating system?  Please.  And I, for one, would be
happy to run data services out of China, and the Chinese would be
happy for the foreign exchange.
I have, in fact, considered putting up just such a service in
Tiajuana, right across the border from San Diego.  I might even be
able to use radio or laser links to cross the border, and not even
deal with international telecom arrangements.  Someone wants a non-US
web page?  I could sell them one.  They don't tell me their name, and
I can't tell anyone else.  If someone is offended, they get to sue in
Mexican court.
Internationalization solves most problems of local restriction, de
facto.  You won't be able to do mandatory ratings of any kind because
every jurisdiction, even the USA, is a local jurisdiction.

@_date: 1994-07-29 12:13:49
@_author: Eric Hughes 
@_subject: No SKE in Daytona and other goodies 
A technical question about the proposed SKE schemes: are they a
   proper superset of non-escrowed pgp/ripem type systems
I'm not sure what you mean by superset, but I suspect that however you
interpret it, the answer is no.
   As a previous
   poster mentioned, users could select null or locally controlled key
   escrow agents, and effectively have a non-escrowed system. The system I've seen (Whit's recollection of Steve Walker's) did not
allow a cooperating party to interoperate with a non-cooperating
party.  In other words, both correspondents must comply with gov't key
surrender, or neither.
Matt or Whit can comment better, since they've seen it first hand.

@_date: 1994-07-30 22:11:24
@_author: Eric Hughes 
@_subject: No Subject 
soda.berkeley.edu is moving, or undergoing an upgrade, or something
like that.  It should be up next week.

@_date: 1994-06-01 08:21:57
@_author: Eric Hughes 
@_subject: procmail 
My first guess: if you have a home directory on the sparcstation, but
a .forward file and procmailrc there.  procmail is pretty good about
being transparent for delivery.  If you have an empty .procmailrc
file, it should dump everything right back in your spool file.
You can look at the last Received line in your incoming mail to
determine what machine the last sendmail is running on.  Your binary
should go on that machine, I think.

@_date: 1994-06-01 08:28:09
@_author: Eric Hughes 
@_subject: Cypherpunks' Electronic Book2 
Well, my evil plan to volunteer Eric Hughes's time  for my
   Cypherpunk's Electronic Book has not worked out as well as I had hoped
If you really had me in particular in mind, you should use private
email.  Since you did not, I assume there are others you may be trying
to interest.
   Eric, it is crucial to the project that
   you give out permissions for some people to change Majordomo, I can't give you that permission; I don't have that permission myself.
More generally, just because the cypherpunks list runs on toad.com
does not mean that toad.com is a common resource for all list members.
Gary is not the first to assume this; I do hope he will be one of the
   I think
   CEB will generate a life of its own.
Four incarnation of a cypherpunks FAQ did not generate a life of their
own.  I see this as having strong parallels.
Let me repeat my earlier suggestion.  You, Gary Jeffers, can run this
out of your own account with a mail filter.  If you can't write it
yourself, you can ask for someone to help you set it up.  Everyone
who's put up a remailer has put up something similar to what you want.

@_date: 1994-06-01 08:50:54
@_author: Eric Hughes 
@_subject: Cypherpunks' Electronic Book 3 
I don't know the languages or protocols or mechanics
   of the Internet to do it myself. I was hoping to provoke an Internet
   guru to do this.
When I wrote the very first cypherpunks remailer in September of 1993,
I did it without knowing Perl, which I learned during that time, over
a 2400 baud dialup to an overloaded Unix host, using emacs to edit
(ever seen a page up in emacs at 2400 baud?), and having to read lots of
man pages on slocal and perl (lots more screen refreshes).
Now look.  If you want to do something really useful, don't assume
that it can be done easily or without a lot of committment in time and
   I have no idea
   how heavy the duties of an administrator would be. I would suggest that since it's your idea that you should administer
it.  If you're not already putting out similar effort, it is somewhat
foolish to ask others to do so.

@_date: 1994-06-02 08:30:34
@_author: Eric Hughes 
@_subject: IMP (was Re: ecash-info (fwd)) 
>Now, one cost of deploying any such system would
   >be the expected (negative) value of the risk taken in losing the whole
   >development investment to an adverse regulatory decision, let alone
   >possible actual penalties.
   True. That is a risk of deploying the protocol from the financial entity's
   standpoint.  It's a risk, that risk has costs both direct and indirect, and
therefore Chaum's systems are _more_expensive_ than they appear.  These
risk costs _will_ affect what gets deployed.
   Like most things in the banking system, a consensus (inside
   the beltway and out) would have to be reached. But this is a political, not
   a technical, challenge.
Almost all the problems in deploying a digital cash system at this
point are financial and political.
   re: IRS reporting
   I'm hard pressed to see the difference between $10K of paper money and $10K
   of e-cash.  That's the point of the technology. If you treat it the same
   way, you can regulate it the same way.
Smurfing is easier in the electronic domain by a long shot.  Smurfing,
for those, not in with the jargon, is sending out flunkies with a few
thousand in cash each to fetch cashier's checks (i.e. non-cash
instruments).  Since the transfer of e-cash and the creation of
nominal accounts is much easier, it's that much better for moving
anonymous money.
The Treasury Department will see this as a Bad Thing.  It will most
definitely be a regulatory hurdle.
   re: getting profitability
   If it is possible to sell, maintain and support software on the internet,
   there will be an incentive for sellers to use it to reduce costs.  [etc.]
I elided an important point.  It seems clear to us that there's a
large market available on the Internet.  Will it be clear to the
financiers?  Not without a lot of education.
   If I had an e-cash-register coupled with a transaction-ftp capability, I
   could sell my software without knowing who bought it, and put the money in
   the bank more efficiently than if I had to deal with checks, credit cards,
   etc., I would jump at the chance.
This is a feature of any all-electronic payments system, not only of
electronic cash systems.  There are alternatives which can work
economically.  Deployment of anonymous digital money is not an assured
   E-cash is critical
   because of it's efficiency.  Almost all the efficiency comes from the fact that it's electronic,
not that it's cash.  It is true that cash systems more quickly
consolidate receivables, but the advantage over paper is _relatively_
   With it, I can sell software or
   computer-related services from any net-connected machine to customers
   Singapore, or Japan, or down the street [...]
As soon as foreign exchange transactions come into play, life gets
more complicated real quickly.  I think there really is a large market
available in low level foreign exchange, but it's much more likely
that single currency money systems will be the first to be deployed.
   Suppose that all cash transactions had to be
   recorded and each party of the transaction had to be identified and
   reported to some other third party (the government, say). Besides the
   specter of big brother watching you, the economy would choke in
   administrivia (I *like* that word, Eric).
Choke?  I think not.  Costs would go up a little, certainly, but all
the reporting could be put into software.  Ever heard of the term
"compliance officer" in banking?  It's someone who goes around and
makes sure the firm doesn't inadvertently break any laws.  Well,
compliance for cash reporting would be in software from day one of the
requirement.  It might add a bit to computer system costs, but not
appreciably to labor costs.  After all, filing would be done
electronically, for real-time monitoring.
   If the people who control patents to the "wallets" and
   "cash-register" technology would let that be available for all, The 'purchaser' package of DigiCash will be freely distributed.  I
don't think the 'merchant' package will be.  I infer this from looking
at the questionnaire for self-qualification of DigiCash's that got
posted here.  There was a one category for banks, certainly to be
licensees, and one for merchants, therefore also to be licensees.
In summary.  Anonymous cash systems are not clearly better than
identity money systems.  It's not clear at all that one will win out
over the other.  In the USA, there are strong governmental forces
against anonymity.  The best we can hope for is that both get
deployed.  The market will then be able to choose.

@_date: 1994-06-02 08:35:13
@_author: Eric Hughes 
@_subject: New MacPGP 
Mike at mpj at netcom.com put it up within a day. That was a week after
   I sent it to both Erics, Nik at ndw1 at columbia.edu tried to send it to me through a remailer and
got the syntax wrong.  The operator of the remailer was kind enough to
send it along.
And I erased it.  I've had enough trouble with Mac distributions that
I'm only going to trust something uploaded via ftp and that has not
passed through a mail system.  YO!  Get the file README.UPLOAD and
follow the directions.

@_date: 1994-06-02 08:46:31
@_author: Eric Hughes 
@_subject: News Flash: Clipper Bug? 
>Its not pre-encryption. He's actually getting around the key escrow
   >features and using Skipjack in a secure manner. Its very slick.
   I've been saying it can be done for more than a year. This is different.  Matt's technique can be used to interoperate with
a _compliant_ device on the other end.  Only modification to your own
end is required.
Matt, on this list, will respond at some point to be determined with
the involvement of corporate lawyers.

@_date: 1994-06-02 08:49:20
@_author: Eric Hughes 
@_subject: patent musings 
I wonder what would happen if Micali sold his patent to RSADSI?  Might
there be another turnaround as with Schnorr/DSA?

@_date: 1994-06-02 09:25:16
@_author: Eric Hughes 
@_subject: IMP (was Re: ecash-info (fwd)) 
The advantage is that its electronic AND that its secure. Since its
   secure, the intermediation costs drop dramatically as the possibility
   of fraud goes down. But it is also possible to make systems that are secure and
non-anonymous.  Admittedly, I spoke of "identity-based systems", which
is not quite right.  Rather I should have said "identifying systems",
which include the identity but do not rely upon it alone to verify
payment, as do credit cards, say.  These kinds of systems can be just
as secure and completely lack anonymity.  To pick just one, consider certified digital checks.  The drawer
writes a check, the bank certifies it (and puts a hold on the
account), the check is transmitted and deposited.  Secure, low level,
and totally identifying.
   One could do electronic payments with credit cards
   and email right now -- but the costs would be pretty bad.
I agree.  There's an interesting parallel.  As it turns out, credit
card fraud is _dropping_, because of various educational programs and
anti-fraud measures.  The one segment that credit card fraud is
increasing is in technical card forgery, which is way up.
Transmitting card numbers electronically over the Internet can only
exacerbate that problem.

@_date: 1994-06-03 14:22:36
@_author: Eric Hughes 
@_subject: IMP (was Re: ecash-info (fwd)) 
> Transmitting card numbers electronically over the Internet can only
   > exacerbate that problem.
   Yes, if transmitted in the clear, PGP is legal now :-).  Vendors on the
   net need to be pushed to use encryption.
I'm not referring to the problem of sniffing credit card numbers off
the net.  I'm referring to the problem of credit card fraud by the
operation on the receiving end.  Even if the transmission is
encrypted, there's still risk.

@_date: 1994-06-06 11:18:27
@_author: Eric Hughes 
@_subject: The Illogic of Clipper 
No criminal is going to use a system that would allow the feds to    eavesdrop - that's worse than sending messages "en clair".  Who is the opponent?  For a criminal enterprise, I see two: law
enforcement and the other competing criminal enterpriss.  Clipper
protects against the competition, but not against law enforcement.
Therefore use of Clipper as such is not irrational.
On the other hand, if a secure phone at the same cost is available
which doesn't use Clipper, it is not rational to use that instead of
What you are seeing is the overweening arrogance of the spies that the
only individuals who can make secure phones will be in league with the
government.  The product announcements are not out yet, however.

@_date: 1994-06-09 09:55:15
@_author: Eric Hughes 
@_subject: Regulatory Arbitrage 
Here a quotation from a book I've been reading:
    "The eurocurrency markets represent a type of regulatory
    arbitrage.  Eurobanking is a managed financial package that
    combines the currency of one country (one regulatory environment)
    with the banking regulations and competitive efficiencies of
    another country.  This repackaging was made possible by
    improvements in worldwide communications links and information
    technology.  If the regulatory burden becomes too high in one area
    of the world, the bundle of eurobanking services can be
    reassembled in another.  Hence, national regulators must compete
    to maintain their respective shares of the eurocurrency business.
    Competition with respect to lending quotas, reserve requirements,
    capital requirements, deposit insurance, the taxing and reporting
    of interest payments, and the taxing of profits, dividends, and
    capital gains, all measured against any perceived positive
    benefits of local regulation, governs the geographical
    distribution of eurocurrency market shares."
of the Wharton School.  Regulatory arbitrage is an Important concept, as well as a great phrase.
The writer is square in the middle of the mainstream in the business
world, and note how effortlessly he speaks of avoiding governments and
playing them off against each other.  There is a lesson to be learned
here--that speaking of internationalization as if it were somehow
disapproved of, as if it were not absolutely matter-of-fact, is a
mistake.  If I refer to the internationalization of retail funds
transfer systems, for example, as if someone might not like that, I
also ask the hearer an implicit question: "Might you also disapprove?"
In a similar vein, exhibiting, with repsect to cryptography, the
analogue of teenaged glee in smashing mailboxes, somehow thinking that
you've also struck a blow against authority, is another mistake.  We
need not show up the NSA, we simply want them to lose.
Regarding the subject of the quotation, it is vitally important that
the residents of the USA who are on this list remember that the key to
strategic victory in cryptography lies internationally, not only for
the USA, but for every other country as well.  If remailers are
outlawed or supressed out of one country, the same functionality can
be made in another.  And so forth.
Arbitrage is smuggling, or rather, the transport of one good or
service purchased cheap in one place and sold dear in another.
Arbitrage always has one of two effects, either a transfer of real
wealth to the place more advantageous the buyer (as well as enriching
the middleman), or an equalization of advantage.  For financial
markets, the equalization always happens sooner or later, and the
price may either rise or fall in either the source or destination.
Arbitrage of regulation almost always leads to equalization, although
the time scales are much longer.  When equalization happens, it's
almost never that the advantage decreases for the destination buyer.
Rather, because there are many more than two markets available, any
tighter regulation invariably puts those two markets on an even
footing in disadvantage with respect to the rest of the world.  So the
arbitrage of regulation usually leads to a relaxtion of regulation.
We need to remember to make it possible for regulatory arbitrage to
occur.  If it can happen, it likely will, but only if the choice is

@_date: 1994-06-10 08:10:34
@_author: Eric Hughes 
@_subject: Regulatory Arbitrage 
Eurodollars were invented
   to get around American tax and currency regulations, and those of other
   countries. Eurocurrency and eurobond markets started about thirty years ago, as
the Bretton Woods monetary agreement was breaking down, which
officially happened in 1973.  So for a good clear twenty years there's
been this mediated market which uses regulatory arbitrage to provide
it's services.  It's been there _longer_than_modern_cryptography_.
One of the reasons eurodollars got created was that at that time a
London bank could offer higher interest rates on dollars than an
American bank could.  They offered better service than the
competition.  They could do so, in part, because neither the USA nor
UK governments put reserve requirements on dollar deposits held in
England banks.
There are real strong lessons here about how a private retail money
system will have to operate long term in order to be immune from local
government interference.
Suppose Bank of the X open a deposit account with, say, Barclay's, a
UK bank.  Barclay's can hold dollars at an account at, say, Citibank
in NY.  Citibank holds it's dollars at the Federal Reserve Bank, where
the buck stops (ahem).  The dollar account at Barclay's is a
eurodollar deposit, a deposit denominated in the currency of the USA
but not held in a bank under the regulation of the USA.  This is a
totally standard arrangement.
Now, suppose I tell you that part of that Barclay's deposit is yours,
after, of course, you give me some US dollars in the same amount.
Suppose, further, that the USA gov't decides they disapprove of you,
and want to take your money.  If they order Citibank to freeze the
Barclay's account, they risk international trade retaliation, because
only a small fraction of that money in Citibank is relevant.  And even
this presumes they know that Citibank is the USA depository bank--and
it likely won't even be the only one.
They might ask Barclay's, "pretty please, would you help us with this
bad person?"  And Barclay's will say (should say, if they still want
X's business) "I'm sorry, you'll have to go talk to X."
And X will say "Who's that?  I don't know who any of my customers
The same internationalization that will limit government action with
repsect to remailers _already_ happens with eurodollars.  I'd suggest
that those who want to know more about this hit the library at this
Did I mention that most eurobond issues are still bearer bonds?

@_date: 1994-06-10 08:45:21
@_author: Eric Hughes 
@_subject: ANNOUNCE: June SF Bay Area physical meeting 
The June meeting will be held tommorrow, Saturday, June 11, at Silicon
Graphics.  This will be our second meeting at SGI.  We're no longer at
Cygnus; thanks again to John Gilmore for the use of Cygnus facilities.
Thanks to Katy Kislitzin for arranging the use of SGI facilities.
This month's meeting will be about "Keys and Key Distribution."
Contributions are always welcomed; on-topic will have priority, but
off-topic will be fine if we have time.  This month's meeting will be
mostly roundtable discussion.
There will be no MBONE this month.  Look for it next time.
Time: 12:00 noon - 6:00 p.m.
Place: Cafe Iris, Building 5
       Silicon Graphics
       Mt. View, CA, USA
Theme: "Keys and Key Distribution"

@_date: 1994-06-10 17:01:50
@_author: Eric Hughes 
@_subject: Delayed self-encrypting messages 
I have a need to distribute some information fairly widely, but it's    critical that it not be openly revealed before a certain date.  The problem is underspecified.  What is the threat model?  That is,
what are to trying to prevent from happening, and what are you trying
to ensure will happen?
If you're just worried that the information will get suppressed if it
sits in one place, encrypting with symmetric cipher and a random key
and publishing the ciphertext does quite well.  You can then give
trusted parties the key.  This has been suggested.
If you want to make sure the message can be decrypted without further
intervention on your part, you need to farm that job out to someone
else.  Use another person, or a public key beacon, but some
other party will be involved.  If you can make that party a public
service (like a beacon), then you've depersonalized the problem.
The simplest public key beacon works as follows.  The operators of the
beacon publish a list of public keys, one per time period--let's say
days here.  The beacon is programmed to give out any particulare
private key at the beginning of its day.  To use this, simply encrypt
with the public key of the date you want the message to be revealed.
The message will be decryptable on that date, when the beacon's key is
An interesting research project would be to construct one of these to
sit in orbit.

@_date: 1994-06-13 21:05:57
@_author: Eric Hughes 
@_subject: (None) 
Might it be appropriate, though, to create an alt group for that purpose?
One has already been created:  alt.numbers.random
Check it out; it's really there, and needs some traffic.  In order to
make the numbers really look random (in order to satisfy the group
charter), though, please strip off any PGP headers before posting.
You may post factorizations of peoples public keys to
alt.numbers.prime, as well.
Thanks to Eric Hollander for actually creating the group.  The two of
us have lots more in the alt.numbers.* hierarchy.
Er, software to effectively use this forum would be appreciated.

@_date: 1994-03-01 13:26:43
@_author: Eric Hughes 
@_subject: Insecurity of public key crypto #1 (reply to Mandl) 
If part of your communications are encrypted and part are not you have
sent the message about what information is sensitive and what is not.
This difference in encoding is a fir-class message in it's own right.
Therefore _all_ communications should be encrypted at all time.  It is
no argument against the principle that this is difficult to do at the
current time.

@_date: 1994-03-01 14:19:35
@_author: Eric Hughes 
@_subject: Proposal: Another emergency session of Cypherpunks 
Since such a meeting would be only one week before our regular
meeting, and since we had ignorantly but presciently scheduled the
topic to be "Politics", I see no need.
[Background: we did voice-over-IP for the emergency meeting last year
right after clipper came out.]
I'd like to do this again.  Can those who are interested in setting up
this technically contact me directly for coordination?  Also, for
those who did it last time, even if you won't be doing it this time,
I'd like to hear from you.
And if someone can get us an MBONE channel for this, I'd be willing to
carry two or three hours of the meeting on a broadcast-only basis.
We'll be meeting at the same time, noon on the second Saturday, as we
always do.

@_date: 1994-03-01 15:31:54
@_author: Eric Hughes 
@_subject: On meetings 
Tim asked me to clarify the bit about emergency meetings.  I thought
he was consider moving the meeting time, among other things.  He was
not.  I mistook his article.
Sorry for the misunderstanding.

@_date: 1994-03-02 08:27:23
@_author: Eric Hughes 
@_subject: low-overhead encrypted telnet 
The reason that encrypted telnet is a good thing is that modification
at the network level requires kernel modification, and encrypting a
telnet does not.  Installing an encrypted telnet daemon does require
sysadmin cooperation, but it doesn't mean recompiling the kernel.
As such, encrypted telnet is a good intermediate while the long term
solution of encrypted IP gets developed and deployed.

@_date: 1994-03-02 08:30:14
@_author: Eric Hughes 
@_subject: Increasing the encrypted/unencrypted ratio (was Re: Insecurity of public key crypto #1 (reply to Mandl)) 
I'll consider doing this after a whole bunch more stuff is developed,
like checking for digital signatures on posts and delaying those
without them.
We're now running majordomo for the list, so if these features get
added to the standard majordomo distribution, we could more easily
deploy them.  That's a hint, since I have higher priority things to
work on.

@_date: 1994-03-02 08:37:22
@_author: Eric Hughes 
@_subject: Insecurity of public key crypto #1 (reply to Mandl) 
Yes, there would be a benefit for those who are working specifically
on mailers, but for those, like me, of course, who aren't, it would be
a royal pain in the ass.  This is an argument against the practice of
encrypting all traffic, not the principle.  And this argument only
holds in the present time; it won't hold in the future.
As Perry points out, we aren't where we want to be.  Yet.

@_date: 1994-03-02 16:36:49
@_author: Eric Hughes 
@_subject: clipper==bad, but how do you explain this to average joe 6-pack? 
is bad for you, they won't make beer illegal, they'll just raise your
insurance rates.  And because you can't protect your privacy they'll
know exactly how much beer you buy."
Substitute your favorite commodity above, such as motorcycle helmets,
condoms, greasy food, cigarettes, or pronography.

@_date: 1994-03-02 16:39:56
@_author: Eric Hughes 
@_subject: Laziness? 
This is one reason that we have not disable the 'who' command on the
toad.com majordomo server.  If you want the public not to know you're
on the cypherpunks list, get and use an alias.
There are two issues here.  I don't mind reading most mail on a shared
machine, but I'm sure as hell not going to let my private key inside
its RAM.

@_date: 1994-03-03 08:03:41
@_author: Eric Hughes 
@_subject: "Children's Letters to Benificent Stalin" 
And a good thing too for the remailers, since they're not secure yet.
This is not a problem, however.  There are two often overlooked
aspects of crypto deployment that the current remailers satisfy
1) People have to get in the habit of using security tools.
2) The non-cryptographic software infrastructure has to support security tools.
For practical purposes, these two aspects are more important than the
actual security of the systems created, because the best system is
worthless if it goes unused.
The remailers work sufficiently well to satisfy these two criteria,
well enough to support transparent encryption and remailing in the
mail user agents, e.g. elm, rmail.  Unfortunately, progress along
these lines has been slow.  The problem is not primarily technical,
however.  The way I see it, this is yet another manifestation of one
of the really bad social values in the Unix and Internet community.
Namely, that integration and ease-of-use just aren't cool.  Value and
respect are accorded to those endeavors which require high levels of
abstractional difficulty or complex optimizations, not to the person
who rights an auto-installation routine.  There is something of a
contempt for the person who's installing software if they can't just
tweak the Makefile or some configuration headers a bit.  Very few
programs don't take some greater or lesser skill as a programmer in
order to get working.
And Unix-lovers wonder why more people don't use Unix.
This hierarchy of value mimics society at large, where design
engineers are accorded much more respect that manufacturing engineers.
A design engineer creates a nice product and gives it to someone lower
on the chain to figure out how to make.  This is changing somewhat,
but the placement of design over manufacture is still firmly in place.
Let me praise Sameer Parekh here for writing an auto-install script
for the current remailer.  His work is not finished, but it's better
than nothing.
Also let me critique the ease of use of some of the other crypto
applications we have.
As far as interface goes, PGP sucks.  I've been trying to get a good
system running on MSDOS to read my encrypted mail more easily.  When
PGP gets an error, watch out, and don't expect predictable behavior.
PGP doesn't have enough separation of function to determine what the
problem is in an automated fashion.
Installation of Secure Drive requires, to my knowledge, futzing with
disk partition tables in order to use it on an existing harddisk.
More programmer skills.  The makers of this and similar efforts should
find some code for a disk defragmenter and write a program to
automatically create a partition, safely moving the existing
information out of the way or over to the other partition.
The remailers, and regular encryption of email, for that matter, are
going to remain mostly unused until these capabilities are integrated
into the average mail user agent, and then become part of the standard
distributions for these packages.
And lastly, for those that might want to call me a hypocrite, remember
that I'm working on packaging digital money into a business, the
necessary and inevitable ease-of-use packaging for this technology.

@_date: 1994-03-03 08:08:44
@_author: Eric Hughes 
@_subject: clipper==bad, but how do you explain this to average joe 6-pack? 
Never underestimate the capacity for opressive national governments
to put dissidents in mental institutions.

@_date: 1994-03-03 12:16:22
@_author: Eric Hughes 
@_subject: Next Physical Gypherpunks meeting 
The next physical meeting will be Saturday, March 12, 12:00 noon PST.
This is not an official announcement, but the time and date won't
change.  The title, for now, is
We're going to try to carry this one on the MBONE.  Details are in the
process of working themselves out.  The EFF looks like it will be
hosting one meeting at its offices in DC.  There will be another in
the Boston area, but I don't know the location yet.  I haven't yet
tried to jump-start a New York site.  Colorado is interested, but
needs to come up with a voice-over-IP site.  If we do MBONE, we'll
have a San Diego participant, but I don't know if he's going to be
hosting a meeting or not.
If you have a T1, a sparc, a speaker/microphone, a meeting room, and
the desire to host a meeting, get in touch with me.  We'll need some

@_date: 1994-03-04 07:33:46
@_author: Eric Hughes 
@_subject: Mail server for crypto files on csn.org? 
The standard cypherpunks remailer code, availabe on soda, is already
an automatic mail handling program.  All the basic principles for
setting up a mail server out of a user account are contained therein.

@_date: 1994-03-04 07:48:21
@_author: Eric Hughes 
@_subject: Standard for Stenography? 
A steganography program that uses a shared permutation and bit
selection schedule on each end is really a symmetric key cipher with
data expansion.
And because it is a cipher, it is subject to the ITAR.
Adding noise intermixed with a signal is a perfectly good way of doing
full scale cryptography, it's just that folks these days tend to
prefer methods that don't have bandwidth explosion.  In fact,
bandwidth expansion is only of the few ciphers that has provable
information theoretic properties, mostly because the method is simple
enough for the basic results of information theory to apply.  Hiding
encrypted text, which already has high entropy over various word
partitions, with an arbitrary embedding in random bits does provably
increase the security of the cipher.
I would urge Jef to write the code and then submit a Commodities
Jurisdiction request to see if the code is exportable.

@_date: 1994-03-04 13:00:18
@_author: Eric Hughes 
@_subject: more steganography talk 
How many public keys are there can there be?
Assume one hundred each for 10 billion persons.  That's 2^40 keys, or
an effective key length of 40 bits.  Since there are not more than
2^16 public keys right now (a generous estimate) we can assume that
this technique is insecure for public keys.
Of course, if the public key is not actually public, but only in the
possession of the sender, that's another matter, but just try keeping
a public key under close distribution sometime.  Both PGP and PEM fail
to support protocols to restrict the distribution of 'public' keys.
Public should mean that the key is held by someone other than the
holder of the private key, not that the key is necessarily available
to everyone.

@_date: 1994-03-04 23:28:13
@_author: Eric Hughes 
@_subject: New mailing list? 
No offense, Michael, but you've made a Frequently Offered Suggestion.
I really should put the answer in a cron job.  The mailing list won't
be split.
This proposal has been put forward before.  No doubt it will be put
forward again.  But it's not going to happen.  I sound cranky, I know.
Let's be explicit.  The list is not going to be split because I don't
want it to be split.  By my fiat.  It's not fair and it's not
democratic and it's not going to change.
Cypherpunks is where the politics meets the code.  It is the interplay
between software design and political desire which is where the all
the good stuff happens.  Policy separated from development lags the
reality of deployment, and necessarily.  There's already a newsgroup
for this: talk.politics.crypto.  Technicality separated from sociality
is unaware and harbors deep-seated contradictions.  There's already a
newsgroup for this: sci.crypt.
Programmers implement culture, and cypherpunks write code.
I want each reader of these words to reflect on the phrase
"implementing culture".  If you do not realize the magnitude of this
principle and have some respect for its enormity, I would sincerely
suggest that your time would be better spent reading some political
philosophy and some technological history and pondering over your
desires, to make sure that you know them.

@_date: 1994-03-05 00:51:54
@_author: Eric Hughes 
@_subject: some technical steganography 
Randomness is the wrong measure.  Suppose I take 2^10 random bits and
prepend 16 zeros.  How random is this?  Almost as random, and this can
be made precise.  How compressible is it?  Almost incompressible.
Now, what about 2^20 bit?  2^30?
It is not randomness but recognizability which is at issue.
Then the next issue arises.
The situation of one file is the wrong problem.  Suppose you have a
collection of files.  What you want is deniability for the group of
files as a whole.  This is much trickier, and the obvious thing
doesn't work.
Suppose the files contain some bytes of an RSA encrypted session key
concatenated to the bytes of a file encrypted with the session key.
This is a reasonable scheme, and is basically how a stealth-PGP might
work.  Because the mode of representation is concatenation, the
session key is represented as some arbitrary number X mod N, the
public key modulus.  Recall that N is public.
Now let k be the length of N in bits, rounded up to the nearest
multiple of eight.  Since the encrypted key is represented as bytes,
the bit length is a multiple of eight.  Now the probability that a
random number between 0 and 2^k will be less than N is N/2^k.  Easy.
If N is not chosen specifically with this purpose, the fraction N/2^k
is on average about 1/4.  The important thing is not that this number
is small but that it is less than one, say p.
Now take an arbitrary string of bits and apply the (public) extraction
technique for a given public key, and from this extract a candidate
for the encrypted session key.  Now you can check the candidate
against the modulus.  If the candidate is greater than the modulus,
then you can reject that public key as being a possible recipient of
that message.
The probability that a public key rejects none of a group of files
grows exponentially small, therefore.  Each time a file is not
rejected as a possible message with respect to a particular recipient
key, the probability lowers by p.
You could even check all possible keys.  You may not be able to
identify the recipient, but in aggregate the opponent will be able to
ascertain that messages are being sent.  That is sufficient.
Steganography not only seeks to hide individual messages, but also the
fact that communication is taking place.
There are some defenses.  One can look for public keys which give high
N/2^k ratios.  Unfortunately, this almost assuredly makes factoring
the modulus easier, if only by lowering the search space.
One can make sure the collection of files contains some ringers, such
that the ratio of ringers to real messages is 2^k-N:N.  This is
certainly possible if one is simply storing files, but if the
collection of files were intercepted in transit, the sender would have
to make sure to send files in the correct ratio.  Yet this requires
that the sender look out for you and your security!
What is most broken here is the N/2^k ratio itself, that is, the
artifact of the byte-oriented encoding.  In other words, a random
modular number is not random in the byte length representation.
More to the point, one can't simply lop the front off a PGP message
and get stealth-PGP.  So one way to solve this is to introduce some indeterminism into the
modular representation, so that the session key is evenly distributed
in all of its relevant representations.  This would mean that every
session on the range [0..2^k) was valid, and was taken mod N to
decrypt a session key.  This yields non-random session keys mod N,
which might be acceptable, since the entropy of the modular
distribution doesn't drop all that much.  Still, this requires the
sender's software to be secure.
Another way would be to use arithmetic coding to spread out the N/2^k
ration throughout the whole file.  For an exact solution, one would
have to use rational cooefficients rather than 2-adic coefficients,
but an approximate solution should be adequate.  One needs for the
approximate case, however, an estimate of the candidate acceptance
rate p above to make sure that the approximation is good enough.  This
solution doesn't require the sender's software to be any more secure
than is in the sender's interest.
In steganography, like cryptography, the different layers of
abstraction forcibly interfere with each other.  The pun here was that
an RSA key (represented by a modular integer) was being put into a
different representation where it didn't work.  These kinds of
level-shifting behavior are all-too-common, and are the cause of much
protocol failure.

@_date: 1994-03-05 10:27:54
@_author: Eric Hughes 
@_subject: Truly Stealthy PGP 
What I suggest is making the exponent (the encrypted session key)
completely random over the length assigned to it, since that's
visible, and just live with a slightly non-flat distribution of
exponents mod n.  It turns out that this can be made to work just
n is the modulus.  Divide L by n to get L = t * n + s, s in [0,n).
Assume x is random in [0,L).  The entropy of x mod n is
   E = - s (t+1)/L log (t+1)/L - (N-s) t/L log t/L
Rearranging, we get:  (get out some paper, do the algebra)
   E = log L/t - s(t+1)/L log( 1 + 1/t )
This makes sense, since if s is zero, E = log n, which is just the
entropy of the random distribution of [0,n).
What is the smallest value of E?  In other words, what's the upper
bound of the randomness we can lose?  It happens when when t = 1 and
when n = L/2+1.  This maximize the expression in t and maximizes s at
n-2.  This minimum value of E is
   E_min = log L - ( ln 2 - 2/L ln 2 )
In other words, the most entropy we can lose is two bits.  That's
right, only two bits.  Since the entropy of the session key is the
length of the modulus, for a 1000 bit key the entropy loss is
Therefore, my recommendation is that the session key representation be
chosen randomly over [0,2^k) and to use as an actual session key this
value mod n.  The effective entropy loss is small enough not to worry

@_date: 1994-03-05 10:36:45
@_author: Eric Hughes 
@_subject: Truly Stealthy PGP 
Scratch that.  I made an algebra error.  I'll repost with the right

@_date: 1994-03-05 12:13:51
@_author: Eric Hughes 
@_subject: Truly Stealthy PGP 
Scratch the scratch.  I thought I'd made an error in my entropy
expression, but I hadn't.  More confusion to follow, no doubt.  I hope
it just won't be mine.
I kept thinking that the location of the minimum entropy was wrong.
I worked out some examples with real numbers to prove to myself that
my intuition about the location of the minimum entropy was incorrect.
Intuition about entropy is difficult to develop, and I still don't
completely have all of it.  A word to the wise.

@_date: 1994-03-05 14:04:51
@_author: Eric Hughes 
@_subject: Truly Stealthy PGP 
OK.  Here's the situation again, hopefully more clearly.
Unfortunately, more clearly in mathematics often means more notation.
Let n be the modulus, and  be the length of the modulus in bits.
Let k be the smallest multiple of eight greater than   Let L = 2^k
be the bit length of the byte container for n and numbers mod n.
Call an encrypted session key as it appears in the cyphertext Q.  We
want the Q's to be randomly distributed over the interval [0,L).
Suppose the encrypted session key R = Q mod n.  The integer R is in
the interval [0,n), and so can't be evenly distributed over [0,L).
The session key S = R^d mod n, where d is the private exponent.
The entropy I calculated was the entropy of the distribution of the
R's with the prior condition that the Q's were randomly distributed.
In other words, if the key is byte-oriented and if the public
representation of the encrypted session key reveals zero information,
the distribution of the encrypted session keys must be non-random.  I
calculated exactly how non-random that could possibly be, and the
answer was, not much.
One more time.  We want the encrypted key, as it appears to the world,
to look random.  So let's assume it _is_ random, and see how that
affects the rest of the system.  If the encrypted session key, as
represented, is random over a range of bytes, it can't be completely
random over the modulus in question, since the modulus doesn't divide
two to the number of bits.  There's some left over, and therefore some
numbers map to more encrypted session keys than others.
Now, since we have a non-random distribution, we need to see how that
affects security, since a non-random distribution lowers the search
space for brute force search.  I calculated exactly how much it can
lower the size of the search space.  The maximum decrease in entropy
is two bits, or a factor of four smaller.  This isn't enough to worry
about for large moduli.
Therefore, we can conclude that it is safe to use a representation of
the encrypted session key which is random.
I've left out how we go from a non-uniform encrypted session key
(which must be generated with a distribution of the entropy
calculated) to a uniform distribution in the representation of the
encrypted session key.  This is not at all obvious.
No, in fact it won't be uniform.  That was the calculation I just did.
You just can't get uniformity over both intervals at the same time.
What I showed is that you can tolerate non-uniformity in one range in
order to get uniformity in the other.

@_date: 1994-03-05 21:37:13
@_author: Eric Hughes 
@_subject: some technical steganography 
It's neither correct or incorrect because the specific notion of
randomness hasn't been specified.
Your statement is falsifiable, however, since sometimes a non-random
string of bits is what you want to get out, if what you would expect
to get out normally was also non-random.  And you want them to be
non-random in the same way.
No.  This was the notion of random I pointed out that didn't work.  If
you add 16 zeros to the front of a gigabit random message, that's
pretty recogizable, even though the entropy is may be very close to
Don't count on it.  Statistical tests can find correlations you hadn't
suspected were there.  In fact, for some message types, _not_ finding
the correlations may indicate dithering, or maybe a steganographic
If the prior probabilities of the message type that you're hiding in
are not random, the steganographic extraction shouldn't be either,
because then there's a distinction between an unaltered container and
an incoded one.

@_date: 1994-03-05 22:01:23
@_author: Eric Hughes 
@_subject: Stealth PGP 
And as Hal and I have been discussing, that's not at all an obvious
problem.  A filter for PGP messages cannot make them completely random
for all the reasons presented.  The session keys must be generated
differently if the encrypted form if them is to have a flat
To wit, PGP itself must change in order to make a random PGP output

@_date: 1994-03-05 22:14:10
@_author: Eric Hughes 
@_subject: Update on user-level hack to do telnet encryption posted recently 
Perry doesn't like Graham's hack for telnet style encryption.  Graham
doesn't like Perry's attitude.  Such a _small_ teapot.
For the forseeable future, there will be the need for link encryption
where one is connecting to a site where the far end doesn't have
encrypted telnet available, _for_whatever_reason_at_all.  There are
lots of reasons, e.g. site managers are busy and the user did not plan
in advance.  It doesn't really matter.  If you can't alter the remote
end except by a user process, that's what you use.
Perry is absolutely correct that this hack is very bad as a long-term
solution, but it is labelled a hack, after all.  Nevertheless, there
is need for a short term solution.  Graham seems to have provided one
part of that.  Great.  Just because you shouldn't need to be using it
in two years is no reason to say it shouldn't be written.

@_date: 1994-03-06 18:37:08
@_author: Eric Hughes 
@_subject: some technical steganography 
Notions of randomness fall into two basic categories, probabilistic
and statistical.  The dividing line between the two of them is whether
you are doing inference forward or reverse.  In both cases the
randomness means evenly distributed.  Probabilistic randomness is inference forward.  One assumes a
distribution of states before, the priors, and calculates the expected
distribution of states after, the posteriors.  Quantum mechanical
randomness is probabilistic randomness, since quantum randomness is
held to be inherent in nature, and from that predictions can be made
about the future.  The analysis of gambling strategies is
probabilistic, since one assumes something random, like dice rolls or
deck shuffles, and infers what the likely outcomes might be.  Statistical randomness is inference backward.  One takes an observed
set of posteriors and tries to deduce whatever is available about the
priors.  Cryptographic randomness is of this nature, since one is
presented with ciphertext and asked to figure out the plaintext.  Two
major questions about statistical randomness and decidability, "Can I
see a pattern in it?", and compressibility, "Can I make a smaller
representation of it?"  Something is statistically random if one
cannot answer questions about it more accurately than by guessing.
There are various sorts of statistical randomness, depending on what
analytical tools are available.  If you allow any Turing machine, you
get algorithmic complexity concepts like Kolmogorov-Chaitin
randomness.  There is randomness which is incompressibility to a
particular coder.  There is randomness with respect to statistical
measures; one can take the difference of an observed posterior
distribution and a probabilistically calculated posterior distribution
and apply standard statistical tests.  How far is this distribution
from expected, and is the likelihood for this difference?
Your clarification makes a difference.  Randomness as lack of
structure can be quantified by looking for conditional probabilities.
E.g. P( x_0 = 1 | x_3 = 0 ) is the conditional probability that x_0 is
1 in the case that x_3 = 0.  If this probability is not 1/2 exactly,
then you have a correlation.  Conditional probabilities in general get
hairy fast, even when the predicates, i.e. the events, are limited to
particular bits equalling zero or one, and the standard propositional
connectives "and", "or", & "not".  There are questions of independence
whose resolution requires a detour into predicate logic.  E.g. P( x = 0 | x = 1 ) = 0, clearly, because the two events are
logically dependent.
One of the ways of measuring these probabilities in the aggregate is
with entropy measures.  The entropy of a probability distribution is
the expected value of the negative logarithm.  If you can determine an
entropy which is not maximal, then you've found a correlation, even if
exploiting the correlation might not be obvious.  This maximality
must be exact, and not approximate.
For example, in the example I gave with 16 zero bits prepended to a
random message, the bit entropy deviates ever so slightly from
maximal, but that indicates a correlation.  The problem is that that
entropy is a probabilistic entropy, not a statistical one.  Had we
measured the same entropy value, it would not have allowed us to
conclude anything, if all we had was the entropy.  We could have also
just looked at the first few bits.
Anyway, since entropies are expected values on probabilities, one can
also have conditional entropies as well.  The criteria for
non-recognizability is that all conditional entropies are maximal.
This, again, is a probabilistic notion, since the calculation of all
conditional entropies for a particular message is an exponential time

@_date: 1994-03-07 08:42:22
@_author: Eric Hughes 
@_subject: Truly Stealthy PGP (algorithm) 
I actually said nothing about how to get the particular distribution
of keys specified, since that was another issue.  I was more concerned
with just getting the one result across.
It does work, and I'll put down a proof sketch below.
Notation alert:
This random number in [0,n) is the wrong distribution, but that's OK,
since we'll be throwing some numbers away.
RSA encryption is a bijection (an 1-1 map).  If it were not, there
would be two or more possible decryptions for a given ciphertext.
Therefore RSA encryption is a permutation, and a permutation of
probabilities preserves expected values of functions of the
probability, such as entropy.  Since we assume the entropy of the SK
is maximal (probabilistic entropy), therefore the entropy of the m's
is maximal.  So the m's have a flat distribution.
(As always, the above statements about bijection hold only if SK is
multiple of one of the divisors of the modulus.  But then if you do
find one of those, you've also factored the modulus and thus broken
the key.  We assume this doesn't happen, since if it does little of
this matters anyway.)
Hal now observes that M is uniformly distributed.  This is correct,
and happens because m is in [0,n) and we are adding a multiple of n to
m.  This means that each M has a unique represenative as some pair
.  Since both m and k are independently random (max entropy, flat
distribution), so is M.
What we have here is a Markov chain.  We have accepting states and
rejecting/retrying states.  Since the probabilities in the chain are
independent of each other and are also time-invariant, the
distribution of final probabilities is the same as the distribution of
normalized accepting probabilities.
In simple terms, you can just retry until you get it right.  Since the
probabilities are all the same before, they will all be the same
after, only larger to account for the fact that some possibilities
didn't work.
[re: rejection and retry]
That's right, and that means that for m < s you have valid k in
[0,t+1) and for m >= s only for [0,t).  If you go back an look at the
entropy expression, you'll see exactly this difference in relative
probability for the two parts of [0,n).
Right, but the worst case for rejection is not the same as the worst
case for entropy loss, which occurs at n=L/2+1 and s=t-1, i.e. at the
other end of the spectrum entirely.
Actually not.  The loss of effective key length happens based on the
posterior distribution of the session keys, not on the number of
rejections that happen in the process.
Indeed.  Observe, though, that as far as deployment went, this would
require modification to PGP itself for it to be anything like

@_date: 1994-03-08 11:28:31
@_author: Eric Hughes 
@_subject: ANNOUNCE: Cypherpunks meeting March 12 
Monthly Cypherpunks Meeting
Saturday, 12 March 1994
MBONE: 12:00 noon PST - 3:00 p.m. PST
Bay Area physical:   12:00 noon PST - 6:00 p.m.
  Cygnus Support Offices, Mt. View, CA
Theme for March: Politics, Strategy, and Action
The time has come to go on the offensive.  We have labored too long in
reaction to the government attempts to restrict cryptography.  This
meeting will be a planning meeting for real-life strategies in the
political arena.

@_date: 1994-03-08 20:28:59
@_author: Eric Hughes 
@_subject: EFF's Barlow v. Denning on Clipper - AOL March 10, 9PM EST LIVE 
You don't suppose someone with a brand spanking new $10 credit AOL
account and who also had an Internet connection could provide a live
feed of the debate to the world, do you?

@_date: 1994-03-09 12:27:41
@_author: Eric Hughes 
@_subject: on tmp@lamar.acns.colostate.edu 
No, the Usenet post from that site is not forged.  I just corresponded
with LD himself there.

@_date: 1994-03-10 08:30:49
@_author: Eric Hughes 
@_subject: The Coming Police State 
Reliability in case of disk failure.  Disk failure includes disk
My private keys ought well to exist somewhere other than in their
usual place of residence and around that physical environs.  Likewise,
they ought to be stored somewhere other than publically known storage
locations like safe deposit boxes.
And private keys are ony the first sort of sensitive data whose loss
has extremely large consequences.
And, as Tim points out, if the data site if offshore, so much the

@_date: 1994-03-10 10:35:25
@_author: Eric Hughes 
@_subject: Who Owns the Words? 
And this brings up fair use, which seems to be mostly absent from
Mike's answers.
Mike, is not a short quotation considered fair use, in whatever
medium, lacking any specific prohibition against it?

@_date: 1994-03-14 08:29:43
@_author: Eric Hughes 
@_subject: digital cash 
Accounts will be able to be denominated in USA dollars, the central
bank money issued by the USA's own Federal Reserve.  Accounts will
also be able to be denominated in other major currencies traded on the
Foreign Exchange market.  Specifics have not been decided.
We will not be issuing a new currency.
Reply-To: uri at watson.ibm.com
X-Mailer: ELM [version 2.4 PL20]

@_date: 1994-03-14 08:38:03
@_author: Eric Hughes 
@_subject: spyproofing your house/work building 
Yes, fully half of it.
You need equipment to check whether your modifications are working.

@_date: 1994-03-14 09:01:17
@_author: Eric Hughes 
@_subject: brainstorming on cpunks' eve 
It is patented, and one of the first claims in the patent is just
signing a claimed time and the given document.  I don't think this
would hold up in court, because of obviousness, but the clause is in

@_date: 1994-03-15 07:06:55
@_author: Eric Hughes 
@_subject: digital cash 
Not only ridiculous, but impossible.  Even with one currency, it's
impossible.  Let us assume that all dollars have the same value.
(This ends up not being true with certain types of intervention--I
digress.)  Now, in the case of a Great Depression, say, where there is
actually less economic output, the number of dollars has not
decreased, and so each dollar buys less.
It's real value which is important in this case, not nominal value.
There is no guarantor of value.  If there were ever claimed one, I
would be suspicious that it was backed by coercion.

@_date: 1994-03-15 23:44:26
@_author: Eric Hughes 
@_subject: digital cash 
I thought I answered this as clearly as I knew how.  Let me use
shorter sentences.
Is this clear?  These are the plans I personally have.

@_date: 1994-03-17 14:50:40
@_author: Eric Hughes 
@_subject: EFF gun-shy of legally employing PGP (fwd) 
On not using PGP:
Yes, it would solve the problem.  Not every individual could have
verified the message, but enough people would have, and immediately
enough, that no question would have remained for long about the
The epistempology of authorship is of social nature already.  With
cryptography, one can lift authorship of public keys to authorship of
documents, but this is an optimization, not a necessity.  By allowing
those people who do use cryptography to verify authorship, one can
speed the process for the rest.  Not everyone currently uses crypto,
true, but better a partial benefit than none at all.  And the partial
benefit of a signed message is most of the benefit.
MacRIPEM is both easy to use and runs on a Mac.  There may be other
reasons not to use PEM and PEM-derived systems over PGP, but I do not
think they outweigh, at this time, the public and forthright use of
cryptography by the policy leaders, and I mean not only EFF here.
It is not my place to make internal EFF policy, but I will suggest it,
namely, that all public communications that go out to Usenet and to
public mailing lists be digitally signed by their authors.

@_date: 1994-03-18 07:26:38
@_author: Eric Hughes 
@_subject: Denning Presentation and Q&A at George Mason University 
For what it's worth, Brad used to be on cypherpunks, but didn't have
enough time to follow it full time.

@_date: 1994-03-21 18:17:01
@_author: Eric Hughes 
@_subject: Administrivia: Questions about the List 
The problem, from what I can tell, is that one of the mail routing
machines at uunet in Virginia was down.  For various political reasons
having to do with AUP's, toad.com routes NSFNet mail through uunet.
So one of the relay machines went down, and some messages were delayed.
Mail queuing makes no effort at all to preserve ordering, so if some
message doesn't go straight to the machine it's supposed to the first
time, ordering can get pretty randomly scrambled.
I took five penet addresses off the list.  Those people who were on it
from that site can add themselves back on with majordomo.

@_date: 1994-03-22 08:10:20
@_author: Eric Hughes 
@_subject: ADMIN: CFP will create an administrative outage 
I leave for CFP this morning.  The majordomo filter should take care
of most of the complainers.  The others should be told that active
administration will resume next week after I get back.

@_date: 1994-03-28 19:26:17
@_author: Eric Hughes 
@_subject: Shirt project 
The fellow involved was indeed from the the NSA, but he was by no
means representing it.  I understand from him that he did a bit of
bureaucratic hacking just to attend.  He also kindly offered to post from dockmaster that he had seen me and
some other tentacles in the same place and at the same time at a
privacy conference, but alas, there were no tentacles to be found.

@_date: 1994-03-30 07:51:12
@_author: Eric Hughes 
@_subject: Crypto and new computing strategies 
When quark theory was invented, it didn't change the conservation of
mass-energy.  When quantum computers are invented, it won't change the
fact that they're still Turing machines.  If it does, that's a
revolution; I'm not waiting.
A single tape Turing machine has the same computational
ability--though not the speed--of a multitape Turing machine, of a
multihead Turing machine, of a multihead multitape Turing machine, of
a register machine, of single/multiple instruction single/multiple
data multiple register machine, of the lambda calculus, of recursive
function theory, and of pretty much every other rich computational
system every invented.  If you still don't agree, I can only steer you
to pretty much any first year formal logic textbook.

@_date: 1994-03-30 07:59:31
@_author: Eric Hughes 
@_subject: Very funny, Polyanna :-( [namespace pollution] 
Presence on a keyring means that a key exists, not that the owner of a
key has a policy that it should always be used, or that it should be
used by everybody.  Both PGP and PEM get this completely wrong.  Not
every key will be used for every purpose.  Mere existence of a key
should not indicate permission to encrypt with it.
No current cryptosystem has a way of specifying policy in a public key
distribution system.  I want separate keys for separate machines,
separate keys for signing and for secrecy, separate keys for
contracting and for authentication.  The current systems don't support
this, and will, I suspect, not support this any time soon.  In the
meanwhile such policies will have to be created manually, even if
their operation is transparent.
The key servers are just serving data.  To add policy criteria to the
key servers is to extend their functionality beyond their original

@_date: 1994-03-30 10:04:20
@_author: Eric Hughes 
@_subject: the rest of the key 
"half" is a a random number which is XOR'd with 80 bits.  Both halves
look random.  The XOR of the two halves is not.

@_date: 1994-03-30 12:23:42
@_author: Eric Hughes 
@_subject: Crypto and new computing strategies 
The Bekenstein Bound gives limits both on the expected maximum number
of quantum states encodable in a given volume of space and on the
expected maximum number os transitions between these states.  If this
bound holds (and it certainly seems to hold for EM fields), then a
probabilistic Turing machine will be able to simulate it.
If you have infinite precision, the statement is unproven.  If you
have finite precision, you get a Turing machine.  You never get
infinite precision in real life, even with quantum superposition.
Steve Smale did some work a few years ago where he made Turing-type
machines out of real numbers, i.e. infinite precision.  P=NP for this
model, and the proof is fairly easy.  From an information-theoretic
point of view, you can encode two real numbers inside of another one
and do computations in that encoded form, because a real number
encodes an infinite amount of information.
If it's finite, it's a Turing machine.  If it's expected finite, it's
a probabilistic Turing machine.  If it's infinite, it cannot be
implemented in hardware.

@_date: 1994-03-30 12:31:37
@_author: Eric Hughes 
@_subject: Crypto and new computing strategies 
But these difference are differences in constant factors of
computation, not of computational expressibility.
You can design an infinite family of finite circuits which do 3SAT in
linear time as well.  The only problem is that it takes an
exponentially increasing number of gates.  It's exactly the same
asymptotic effect, which, as you should all know by now, comes as no
surprise to me.
I don't anticipate QM machines will be deterministic, but they
certainly will be bounded in the expected sizes of their state spaces.
This will make them simulable by, and therefore equivalent to,
probabilistic Turing machines.  A significant number of real-life
crypto algorithms are already using this model (like primality
testing), so there's no advantage in the computational model.

@_date: 1994-03-30 13:04:20
@_author: Eric Hughes 
@_subject: Cryptography banned in the Netherlands.... 
Yes.  Find the coalition that has repeatedly prevented the imposition
of national identity cards, and educate them about cryptography.  It's
much the same issue.

@_date: 1994-03-30 13:32:45
@_author: Eric Hughes 
@_subject: Crypto and new computing strategies 
The "EM fields" I was referring to mean electromagnetic interactions,
that's all.  The argument on the Bekenstein bound does not depend on
the nature of the particles mediating the field, but on the existence
of non-zero commutators for position and momentum, i.e. Heisenberg
uncertainty.  Bekenstein uses his argument to try to constrain the
possibilities of interaction inside the proton, for example.  I'm not
sure it works for that, but the argument is pretty clear about states
mediated by electromagnetic interaction.
You must not understand what the Bekenstein bound says.  It says, very
clearly, infinite precision does not exist.  If you disagree with the
applicability of the result, then say so, but you'd better know what
the result is before you go haplessly denying it.
The second half of the Bekenstein bound says that infinitely fast
state changes do not occur.  Again, no infinite precision.
"Zero time" is a different statement than "almost zero time" or "so
small that we can't measure how small."  What may be reasonably taken
to be instantaneous in one model, with it's own characteristic
approximations, need not be instantaneous in another.

@_date: 1994-03-31 08:36:59
@_author: Eric Hughes 
@_subject: Zero Knowledge Trust? (was Re: Very funny, Polyanna :-( [namespace pollution]) 
I feel like looking at it as a necessity.  Every system for
dissemination of public keys requires at least two paths of
communication.  If there is only one, an interposer can sever the
connection graph of key assurances and create two different key

@_date: 1994-03-31 21:26:18
@_author: Eric Hughes 
@_subject: Cryptography banned in the Netherlands.... 
This is where the education part comes in.  Start with the most widely
heard members.

@_date: 1994-05-02 11:01:49
@_author: Eric Hughes 
@_subject: The American money capture 
The Great Depression was pretty clearly caused by deflation in the
money supply.  To quote Milton Friedman:

@_date: 1994-05-02 11:25:25
@_author: Eric Hughes 
@_subject: Lobbying/Politics/etc. 
When did this happen?  You should tell me, I'd like to know.
I represent myself as cypherpunks founder, or cypherpunks list
cypherpunks: (n) an Internet mailing list about implementations of
cryptography.  Cypherpunks is a venue for those who believe in the
free and widespread use of cryptography; it focuses especially on the
social effects of such deployment.

@_date: 1994-05-02 13:52:18
@_author: Eric Hughes 
@_subject: The American money capture 
I have the opportunity of a group meeting with some of the SF Fed
operations staff a couple of weeks ago.  Their words:
Other tidbits:

@_date: 1994-05-02 22:44:53
@_author: Eric Hughes 
@_subject: Virtual Cash 
Denominate digital money in dollars in a demand deposit account in a
US bank.
Why reinvent the wheel, or, in this case, the unit of value?

@_date: 1994-05-03 10:11:09
@_author: Eric Hughes 
@_subject: Virtual Cash 
And a business?  They'd laugh.
For any system of digital cash to take off, it must be economical to use.
Since credit card rates cost business 2 1/2% - 4%, digital cash must
be more efficient in real terms in order to succeed.

@_date: 1994-05-03 10:18:21
@_author: Eric Hughes 
@_subject: the value of money 
These are the LETS systems, Local Exchange Transfer Systems.  They
seem to have been most successful in places of high unemployemnt as a
way of increasing liquidity for services (mostly).
So it seems that the money supply, that is, the amount of liquidity
available in the system, is not zero, but something else.  There
certainly are some interesting questions here, in particular the
effective exchange rate between the national and local units of value.

@_date: 1994-05-03 10:23:08
@_author: Eric Hughes 
@_subject: Virtual Cash 
Any pre-existing national currency will do.  My point was abbreviated
for clarity.

@_date: 1994-05-03 10:57:46
@_author: Eric Hughes 
@_subject: The American money capture 
Not completely fungible.  There is also trust in the trustee as a
trustee, who could abscond with the whole sum suddenly.  This point is extremely important.  The difference between "your
receipts" and someone else's means that you don't have a completely
fungible system.
It appears that you have 100% reserves, from the phrase _pari pasu_.

@_date: 1994-05-03 11:03:50
@_author: Eric Hughes 
@_subject: Digital Cash 
A 5 cent message unit assumes that a phone line and modem are being
used, and that there is a call setup charge that the business pays the
phone company.  There are more efficient ways.
You can buy "metallic pair" service from most phone companies.  That's
a rental of a single pair of copper wires without dial tone attached.
The cost around here is about six or eight dollars per month, flat
rate, of course.  One collocates equipment at the central office; this
means a nearby office in practice.  Now if you run, say, IP over this
link, the per-message charge is down in the fractions of cents.
This is not to say that online systems are going to be less expensive,
merely that the cost comparisons for possible deployments are not

@_date: 1994-05-03 11:08:23
@_author: Eric Hughes 
@_subject: Digital Cash 
Bad credit or no credit.  Having no record in the credit databases is
as good as have negative entries, for many purposes.
A significant part of this is that banks have simply moved out of a
lot of neighboorhoods, and checking accounts are simply not easily
available.  Many people grow up without interaction with the banking
system, and therefore don't get electronified.

@_date: 1994-05-03 19:12:07
@_author: Eric Hughes 
@_subject: Why Digital Cash is Not Being Used 
There _are_, however, systems which have been denominated in units of
15 minutes of labor.  (I've seen the scrip.)  The misunderstanding is
not unfounded.

@_date: 1994-05-04 13:38:45
@_author: Eric Hughes 
@_subject: Visual Basic (yes, Basic!), and "VBX" tools 
Classes are C++.  Foundation classes are Microsoft Foundation Classes,
are just a large library that Microsoft wrote which is also included
in the C++ compiler products.

@_date: 1994-05-04 13:40:46
@_author: Eric Hughes 
@_subject: PKP licensing of RSA 
The cost to negotiate an individual license for a sum of less than
$100 is prohibitive for RSADSI.  Don't expect it.

@_date: 1994-05-04 21:56:16
@_author: Eric Hughes 
@_subject: ANNOUNCEMENT: Preliminary announcement of May physical meeting 
PRELIMINARY ANNOUNCEMENT
Different Date:
New Location:
Audio Available:
See you then.
it's like PGP 2.3 and 2.4 (modulo maintenance tweaks) but uses RSAREF
for its crypto.  Thus it is entirely U.S.-legal.
I wonder what Sternlight will say to this.
   Eli   ebrandt at hmc.edu
"Users of PGP 2.5 should be aware that if copies are found outside
 of the U.S. and Canada, they could be charged with contributing
 to a conspiracy to export munitions to a foreign national."

@_date: 1994-05-05 07:13:28
@_author: Eric Hughes 
@_subject: The Value of Money 
Your Fidelity Mutual Fund account is denominated in dollars, held in
stocks, and clears through the ACH system.  Sounds pretty close to me.
Right now Fidelity nominally sells your stock when you withdraw and
buys more when you deposit (in practice they net their customers
against each other, I'm sure).  Suppose you write a 'check' (it's not
_really_ a check, just very close to one) on your Fidelity account and
someone else deposits it to their Fidelity account.  Fidelity can do
an "on-us" clearing of the check and it never leaves Fidelity's hands.
Only some accounting records have changed reflecting a change in the
distribution in funds.
Make this kind of transfer fully electronic and you have the
beginnings of a fully private currency.

@_date: 1994-05-05 14:25:15
@_author: Eric Hughes 
@_subject: Keyserver service outage 
IDEA is an international patent, from ETH in Switzerland.

@_date: 1994-05-05 14:25:56
@_author: Eric Hughes 
@_subject: No Subject 
It's on ftp.csua.berkeley.edu:pub/cypherpunks/clipper.

@_date: 1994-05-06 09:32:29
@_author: Eric Hughes 
@_subject: Linear Congruential Random Number Crackers.. 
Is your ciphertext the stream of numbers itself, or the stream used as a pad?

@_date: 1994-05-06 09:39:02
@_author: Eric Hughes 
@_subject: Regarding Mr. Nalbandian's Comments 
To paraphrase Perry, the cypherpunks list assigns primacy to action.
The political discussions are meant to inform the design of the
software systems we're working on.  They do not stand alone, and as
soon as they do stand alone, they become irrelevant.
The Usenet newsgroup talk.politics.crypto is for political discussions
about cryptography of any sort whatsoever.

@_date: 1994-05-06 18:06:38
@_author: Eric Hughes 
@_subject: The ITARs 
Are there any bills being considered for congress which would remove
   cryptography from the munitions umbrella ?
HR3627, sponsored by Maria Cantwell.

@_date: 1994-05-11 19:10:37
@_author: Eric Hughes 
@_subject: Here they come... 
The Times has two beat reporters for cyberspace. They are Peter Lewis
   and John Markoff.
Not quite.  I met Peter Lewis at CFP-94.  He has the official
cyberspace beat, which was just created this year.  Markoff reports on
the same issues, but is not assigned to that beat.
   Markoff's pieces in the times show remarkable understanding of the
   issues, but Lewis's make it seem like he's never even logged in.
   I encourage people to feed Markoff their interesting scoops and tips,
   and for people being interviewed by Lewis to ask why Markoff isn't
   covering a piece. I would suggest it would be more profitable to educate Mr. Lewis
rather than to hold another's reputation over his head.

@_date: 1994-05-14 12:39:27
@_author: Eric Hughes 
@_subject: ADMIN: on penet and on paranoia 
Paranoia is cryptography's occupational hazard.
Recently there has been a small rash of complaints about unwanted
assignment of penet pseudonyms.  The first reported was simply a
description, the most recent assumed that the assignment was the
result of someone trying to find out mappings in the penet database.
This clear illustration of paranoia setting in demonstrates the nature
of the hazard.  The effect of paranoia is self-delusion of the
following form--that one's possible explanations are skewed toward
malicious attacks, by individuals, that one has the technical
knowledge to anticipate.  This skewing creates an inefficient
allocation of mental energy, it tends toward the personal, downplaying
the possibility of technical error, and it begins to close off
examination of technicalities not fully understood.
Those who resist paranoia will become better at cryptography than
those who do not, all other things being equal.  Cryptography is about
epistemology, that is, assurances of truth, and only secondarily about
ontology, that is, what actually is true.  The goal of cryptography is
to create an accurate confidence that a system is private and secure.
In order to create that confidence, the system must actually be
secure, but security is not sufficient.  There must be confidence that
the way by which this security becomes to be believed is robust and
immune to delusion.
Paranoia creates delusion.  As a direct and fundamental result, it
makes one worse at cryptography.  At the outside best, it makes one
slower, as the misallocation of attention leads one down false trails.
Who has the excess brainpower for that waste?  Certainly not I.  At
the worst, paranoia makes one completely ineffective, not only in
technical means but even more so in the social context in which
cryptography is necessarily relevant.
The problem with assignment of penet ID's was not due to any malicious
intervention, but rather someone subscribing to the list with a penet
address.  Since the list doesn't alter the headers much at all, the
originator of a list message is sending indirectly to penet, forwarded
through toad.  I've swapped the address so this shouldn't happen again.

@_date: 1994-05-14 14:17:04
@_author: Eric Hughes 
@_subject: ADMIN: on penet and on paranoia 
re: on list deletion
   Or is there
   no way for even the list managers to know?
We don't know what happened to the list, although we suspect a
technical problem with full file systems.
   Clear information is one of the best ways to dispell paranoia.
It may dispell the attack of paranoia, but it does nothing to address the
underlying mental state, which is what I was talking about.

@_date: 1994-05-17 09:47:15
@_author: Eric Hughes 
@_subject: lies, damn lies, Internet-statistics, and "sinister" EDI (fwd) 
PS.  It occurred to me that this article appeared while you were not
reading your email, and while I was not therefore forwarding
cypherpunks list messages to you.  I will resume my forwarding

@_date: 1994-05-17 10:07:14
@_author: Eric Hughes 
@_subject: Makeing MagicMoney worth something. 
And suppose that I promised, on the net via a signed
   message, to trade MM coins for dolars.  [...]
     I don't belive I would be running a bank: I would maintain no
   deposits for anyone other than myself.  Nope.  You're a bank in this case.  A bank is someone who accepts
demand deposits, that is, money they give to you which you give them
back when they want it.  It matters not how the value is stored.  The
large banks store their value in bank accounts at the Federal Reserve.
     I don't belive I would be issueing a currency: Correct.  Digital money is not a new currency.
   Would the coins circulate?
Only among people who had pre-existing financial trust in each other,
and only if the bank fee for deposit/withdrawal were high enough to
justify a secondary market in coin exchange.
It is not particularly difficult to find books about the regulatory
environment of the banking industry.  I would heartily suggest to
those who are interested that they hit the library.  I also feel
compelled to mention this--it's not online, and get over it.

@_date: 1994-05-17 22:14:26
@_author: Eric Hughes 
@_subject: Makeing MagicMoney worth something. 
> Nope.  You're a bank in this case.  A bank is someone who accepts
   > demand deposits, that is, money they give to you which you give them
   > back when they want it.
   What you are, is someone who is issuing
   redeemable notes.
Issuing notes will not, _per se_, make you a bank.
   Or alternatively you are a trustee.  If I gave
   money to my escrow agent, to be paid to me when I want it, she
   would not be a bank.
If the value transferred is liquid, and the payment is made upon
demand, then, in fact, you are a bank, regardless of what else you
might call yourself.  This is the case in the USA.  Canada certainly
varies, as does the rest of the world.
   [...] but the key element
   in all of these matters is jurisdiction.  Who regulates all    of this?
   The answer of course is no one.
This is a rather hasty conclusion.  The real answer is that a country
will attempt to regulate this activity if it feels like it can argue
jurisdiction and win.  The easiest barrier to erect is to get some
country to claim jurisdiction; the others will then generally stay
away with their courts.
If there is no stated location, then a country can simply claim
jurisdiction if some of the facts of the situation give it an arguable
jurisdiction.  If, for example, the computers for a cypherspace bank
are known to be in the USA and the bank claims to be outside USA
jurisdiction, guess who wins.
   This
   would mean that the bank, would be everywhere simultaneously,
   without being anywhere at all.
One can imagine all sorts of things, but architectures that can be
built and economically deployed are much more important than
vague characteristics.
The problem of making a jurisdiction-less bank is a mighty difficult
one, and it behooves those who wish to discuss it to ground their
comments in economic and political realpolitik.

@_date: 1994-05-17 22:42:51
@_author: Eric Hughes 
@_subject: Rabin 
Karl posted a good answer about square roots modulo a Blum integer.
I'd like to explain some of the context for this math.
Recall that a multiplicative group modulo n=pq is the product of two
multiplicative groups modulo p and modulo q.  That is,
(The superscript asterisks denote multiplication.)  So an element of
Z/nZ can be represented by an ordered pair of residues mod p and mod
q.  This same situation explains why there is another decryption
exponent in RSA, a previous thread.
Anyway, if p is prime, then every square mod p has two square roots.
When p = 3 (mod 4), these square roots are easy to find.  See the
article in the current MAA Monthly for a discussion of the other case.
If  is a square in Z/nZ, then each component m and n must also be
a square.  Thus if =, there are four possible square
roots , , <-a,b>, and <-a,-b>.  These are additive inverses
in one pairing and conjugates in the other.
For completeness, it should be noted that the set of all squares of a
group is a subgroup.  The commutative case is easy; the
non-commutative case is much harder.  It is a good exercise to
calculate some square groups, to see how they generally behave, for
example, properties about their sizes.
Karl's explanations of using the Chinese remainder theorem to get the
canonical representations is fine, as is his observation about the
error in Schneier's text, although n-x = x (mod n), so the "n -" part
is unnecessary.

@_date: 1994-05-18 12:10:44
@_author: Eric Hughes 
@_subject: Makeing MagicMoney worth something. 
Eric Hughes says:
   > If the value transferred is liquid, and the payment is made upon
   > demand, then, in fact, you are a bank, regardless of what else you
   > might call yourself.
   Well, there is ONE subtlety -- entities like mutual funds and
   securities broker/dealers are not considered banks qua banks under
   American law On the other hand, Fidelity, for example, the largest of the mutual
fund providers, does not offer demand deposits, because you can't get
back your money "upon demand".  They don't have to give it back to you
immediately, so it's not "upon demand".  Check the agreement or the
"checks" you get for your fund account.
It seems conceivable to operate a business that took non-demand liquid
deposits, but which promptly serviced most demands for withdrawal
because of the competitive environment.  A "banc" of this form would
not survive if the liquid deposits were, practically speaking, liquid.
("Banc" is an avoidance of the regulation which puts companies with
the word "bank" in them under banking regulation.  It's amazing at the
number of companies with names like "Bancshares" or "Banc Holding".)
Since no such institution exists now, it would be currently outside
the regulatory framework, but one should not expect it to remain that
way.  Pragmatically speaking, one's best strategy would be to get
successful rapidly and then hire lobbyists.
Credit card and charge card companies could do this themselves right
now, were they to pay interest on positive balances.  The contract
between card company and customer would have to specify that the
positive balance was not available "upon demand", per above.
Otherwise most of the relationships could be the same.
As an aside, issues of commercial paper, including promissory notes
and hypothetically digital "bancnotes", whose term is nine months or
less are specifically exempted from SEC regulation.  There really seems
to be a gap in the regulatory environment.
Legal hacking is a lot of fun.  Prerequisites are a humility to learn
the structure of legal argument and access to legal materials.  The
study guides for law students are generally excellent introductions to
the subject.  Access to a law library is also useful for looking up
statute and decisions, but not essential, although reading at least a
few decisions is necessary for ensuring an understanding of the social
process involved in the creation of law.
And if what you want to accomplish with your computer hacking
requires, for implementation, something outside the computer hardware
and networks, legal hacking is almost a necessity.

@_date: 1994-05-18 12:24:56
@_author: Eric Hughes 
@_subject: In defense of paranoia in cryptography 
However, a successful cryptographer must be cautious at a level that would
   be judged paranoid in more civilized communities.  A correct analysis of the risks and the costs of prevention and
non-prevention is not being paranoid.  To be overly cautious is,
almost by definition, not to be economical.  It should be noted,
however, that there is enormous risk in ignorance of the other risks,
and so effort made in order to understand the risks is well spent,
_even_ if one spends more on that than the savings stemming from that
   If you need cryptography, it's because you have enemies.  This is dangerously false.  One uses crypto because one does not know
the nature of one's opponents now and in the future, with an emphasis
on the future.  This lack of knowledge includes an ignorance that
certain parties do not have your best interests at heart.  If you
think they do, you can always reveal the information.
Cryptography is primarily about how we get assurances of security.
Uncertainty has negative value all by itself.

@_date: 1994-05-18 12:46:40
@_author: Eric Hughes 
@_subject: ADMIN: on penet and on paranoia 
>Paranoia is cryptography's occupational hazard.
   Yes, that is indeed the nature of it since many of the protocols are
   designed to work admist mutually distrusting parties.  A degree of
   suspicion/ paranoia is necessary - for example, digital cash.  Paranoia is not necessary for protocol analysis.  While it is not
totally ineffective, it is certainly much less useful than
understanding the invariants of the protocol, for example.  Proof is
much more powerful than paranoia.
Evaluating the risks of a situation, even the ones of low probability
and large effect, is not paranoia.  The person who considers that
there might be people who want to listen it and uses cryptography
because the cost of deployment is less than the perceived risk (and
all risk is perceived risk) is not paranoid but prudent.  The person
who merely thinks there are people listening in and uses cryptography
to defend against them is just paranoid.
distinguish.  Both use crypto, both acknowledge the existence of
people who wish to harm other people.  Yet the paranoid has identified
with the victim.  An indicator of paranoia is an unsupported claim
about a state of affairs in which the speaker is a target.  This is
what happen with the penet id assignments; some people implicitly
asserted the existence of malicious individuals.  Those who merely
brought up their _potential_ existence.  The evidence for this
distinction is speech-acts, not the most reliable indicator.
Therefore my advice about paranoia is more directed to individuals
pondering their own states of mind than to the examination of the
behavior of others.  Sometimes you may learn that another person
actually is paranoid.  You cannot, however, usually tell just from the
use of cryptography whether or not a person is paranoid.
To summarize my original claim in light of the foregoing, the paranoid
does not do protocol analysis as well because of a misdirected focus
on certain risks and not others.
   example, a non-suspicious person may be tricked into digitally signing
   anything (by getting them to sign a blinded document).
And for this reason, keys used for blind-signing should not be the same as
for email signing.  But this is a different discussion.
   I think I follow most of what you are saying; all the same, in this
   case, technical error or not, malicious person or not, the paranoia is
   justified.  To assert the possible existence of the malign is acknowledgement.  To
assert the possible existence of the malign in some current situation
is suspicion.  To assert the actual existence of the malign without
good evidence is paranoia.
I don't think you use the word "paranoia" as I do above, which I would
term suspicion.

@_date: 1994-05-19 11:25:07
@_author: Eric Hughes 
@_subject: Penet ID allocated 
I did a who cypherpunks to    identify the culprit, but found this:
   na97762 at anon.penet.fi
I changed the an97762 to na97762, in order to fix the problem.

@_date: 1994-05-19 11:37:42
@_author: Eric Hughes 
@_subject: Mosaic to support digital money in September 
It seems that you have information that is not in the press release
you include, which talks (as far as I can tell) about catalog
purchases with credit cards.
   Enterprise Integration Technologies and friends will
   enable digital money transactions in Mosaic in September
Is this announced?
   The transaction model has a crippled mode for people
   outside the US and Canada
   They intend that you will be able to write contracts and
   internet checks on participating banks.  Will the recipient of the check be required to be at a participating
bank?  And you can already write contracts with existing digital
signatures.  A contract is just an agreement between two parties;
intermediation is not required.
   For this reason I think decentralized account based
   digital money is the best hope.
Account based money is identity based money, even if the identity is a
pseudo-identity.  The whole point of cryptocash protocols is to
separate the link between two account by mediating the transaction
with some instrument.

@_date: 1994-05-19 19:44:00
@_author: Eric Hughes 
@_subject: ANNOUNCE: Bay Area physical meeting May 21. 
SAME cypherpunks time!  NEW cypherpunks channel!  (er, location)
What: Bay Area physical cypherpunks meeting
When: May 21, 1994
      12:00 noon - 6:00 p.m.
Where: Silicon Graphics, Mountain View, CA
       Building 5, SGI cafeteria, aka Cafe Iris
Many thanks to Katy Kislitzin for arranging us a new and larger
meeting space.  With Cygnus meetings averaging 40-50 people each
month, we'd just plain run out of space in their small conference
room.  And many thanks to John Gilmore for the well-used Cygnus room.
We'll be in Cafe Iris, with 75 seats and plenty of A/V equipment.
There will be full MBONE support, including video.  We'll have a
camera, so those who want to broadcast their likenesses to the whole
world will have the opportunity.  The MBONE session has been
advertised on 'sd' already.
The New York Times magazine is doing a story on us, and a photographer
will be there to take a group photo, last I heard.
This month's theme is Protocols.  We'll be doing protocols and other
technical cryptography.  Here's what's known to be on the schedule
right now:

@_date: 1994-05-20 07:59:31
@_author: Eric Hughes 
@_subject: D-H key exchange - how does it work? 
It takes hours and hours of searching to find
   a 1024 bit strong prime on a workstation.  Granted, you don't need to change
   very often perhaps, but some people would like to change every day.  If they really want to change that often, they can buy a dedicated
machine.  There's no good cryptographic reason to change that often,
if the modulus is large enough.  In addition, changing the modulus can
have unpleasant effects on traffic analysis, if not done properly.
   (The best way I know to find strong primes is to find a prime q and then
   check 2q+1 for primality.  Finding 1024 bit primes takes a long time, and
   the chances that 2q+1 is prime is very low.)
Well, there are faster ways.  One can combine the sieve for q with a
sieve for p.  The biggest problem is that there are just a lot fewer
primes with the above property.
   The question is, how good are strongish primes?  Just fine.  The complexity of taking discrete logs is dependent on the
largest prime factor of the modulus.
   What fraction of elements
   of the group will have short periods, given that p-1 has a pretty small
   number of prime factors?
If q is the largest prime factor, then about p/q will have short
periods, namely, those divisible by q.  When p=2q+1, there is one
element of order 1 (namely 1), one element of order 2 (namely -1, aka
2q), and every other element has order 2q or q.  For primes of the
form p=kq+1, there are about k with short periods.

@_date: 1994-05-20 09:43:04
@_author: Eric Hughes 
@_subject: Is crypto cash patented? 
The blind signature algorithm is patented by David Chaum.

@_date: 1994-05-20 09:52:07
@_author: Eric Hughes 
@_subject: D-H key exchange - how does it work? 
I dunno. The paper by LaMacchia and Odlysko on how to break
   Diffie-Hellman quickly once you've done a lot of precomputation on a
   static modulus is sufficiently disturbing to me that I would prefer to
   be able to change modulii fairly frequently if possible.
Quoting K. McCurley about the above mentioned work: "Their experience
seems to suggest that it is possible to compute discrete logarithms in
groups GF(p)^* with p \wavyequals 10^100." [in _The Discrete Logarithm
Problem_, collected in _Cryptology and Computational Number Theory_]
The security of a 1000-bit modulus is just fine, thank you very much.
Some military applications evidently use twice that, though.  You need
to change it as often as you change RSA keys.  Since you can factor if
you can take discrete logs, you've got to worry about the security of
your RSA keys at the same time.
   > In addition, changing the modulus can have unpleasant effects on
   > traffic analysis, if not done properly.
   Of what sort?
For D-H, the modulus must be transmitted in the clear.  Unless you use
a different modulus for each conversation, there is a persistency to
the moduli that gives rise to a pseudo-identity.

@_date: 1994-05-20 10:52:59
@_author: Eric Hughes 
@_subject: D-H key exchange - how does it work? 
> For D-H, the modulus must be transmitted in the clear.  Unless you use
   > a different modulus for each conversation, there is a persistency to
   > the moduli that gives rise to a pseudo-identity.
   You don't HAVE to transmit the modulus in the clear. But we were talking about changing moduli and its effect on traffic
analysis.  If you change the modulus each conversation, you have two cases:
  1. Transmit before the conversation
  2. Transmit at the beginning of the conversation
For case 1., you could, conceivably, transmit the modulus for the next
exchange in a previous (encrypted) conversation, but that introduces
lots of system complexity, state, and general nastiness.  If the
modulus is previously transmitted unencrypted, then we're back to the
For case 2., you can transmit the modulus in the clear or encrypted.
If in the clear, then you have the TA issues as before.  If encrypted,
you need some method of generating an encryption key, like D-H, which
we're trying to do.  So you could use a fixed modulus to encrypt for a
second exchange; that's slow, and when the modulus goes, you reveal
the same TA data as before.  If you don't use D-H, and, say, public
key derived things are used, then you even more directly reveal TA.
The above analysis is not very rigorous.  It merely points out where
some of the problems are.
   Its often
   worthwhile to use D-H for key exchange even if both sides know the
   other's RSA public keys. It's called forward secrecy.  Sure.  But the issue at hand is TA.

@_date: 1994-05-20 20:39:13
@_author: Eric Hughes 
@_subject: D-H key exchange - how does it work? 
Or is it the assumption that everyone uses the same modulus
   in that case?
Yes.  Same modulus for all users.  Not so bad a thing, really,
although sometimes long-term secrecy is worth more than traffic

@_date: 1994-05-21 07:05:14
@_author: Eric Hughes 
@_subject: Is my DH exchange secure? 
[Please don't quote entire messages.  It's a good way to make sure
your words afterwards get read by far fewer people.]
   The one precaution I did not take is: (from discussion above)
[looking for number of small order]
   Does the careful choosing of n and g eliminate this problem, or do I need
   to modify my Diffie-Hellman code to check g^a for short order? How do you
   check a number for short order?
If you wish to use generators mod p, proper choice of the prime will
minimize the problem; the generator has nothing to do with it.  All
generators are symmetric, or, more precisely, the automorphism group
takes each generator to every other.  Picking the prime p so that
p=2q+1 and q prime will reduce the number of elements with small order
to 2, namely 1 and -1.
In the more general case, let p=kq+1, where q is the large prime
factor of p-1 necessary for security.  Now the order of an element x
must divide p-1, so if it's not of order q or larger, i.e. safe, then
it must be of order k.  So calculate x^k (mod p) and see if it's equal
to 1.  If it is, then x has small order.
On the other hand, the tests for small order can be minimized by using
a generator of the subgroup of size q inside the group mod p, rather
than a generator of the full group.  Let p=kq+1 and let g be a
generator of Z/pZ (notation for the group of integers modulo p).  Then
g^k has order q in Z/pZ.  Since g generates the group, kq is the
smallest positive integer t such that g^t = 1 (mod p).  g^(kq) =
(g^k)^q, so g^k has order q.
Now if you use h=g^k as the base for the D-H exchange, the only h^x
with small order happens when x=0.  One can simply make the range of
the random numbers from 1 to q-1.  Because h has order q, and since q
is prime, every h^x except x=0 will also have order q.  Therefore
there are no "bad" values for x.  They have been removed by
construction in advance.

@_date: 1994-05-24 07:45:06
@_author: Eric Hughes 
@_subject: compatibility with future PGP 
The only change the future post-September PGP 2.6 messages will have
is a change in the version number byte from 2 to 3.  PC's little hack
not to check version numbers will work, but as a patch it's not the
most robust.  It would be more robust if it checked for the range
Another thing a patched 2.3 release would have to do to be fully
indistinguishable is to generate new version numbers itself after the
given date.

@_date: 1994-05-24 18:27:55
@_author: Eric Hughes 
@_subject: patch to PGP 2.6 
> Another thing a patched 2.3 release would have to do to be fully
   > indistinguishable is to generate new version numbers itself after the
   > given date.
   Is "indistinguishability" the point or "interoperability"?
Reference is not advocacy.
I was speaking of what was necessary to ensure indistinguishability.
If that is your goal, then this is directly relevant.  If not, then it
may be beside the point.
The change in version numbers seems to have two effects, both of which
I addressed.  Use these statements as they are appropriate to your
P.S. The "you" is the general "you".

@_date: 1994-05-25 10:16:51
@_author: Eric Hughes 
@_subject: Graph isomorphism based PK cryptosystems? 
So, if JPP publishes it, it would be a matter of trust that he
   wouldn't patent it.  Okay, I have no problems with that.  However,
   it is still patentable.  What could be done to make it
   unpatentable?
You can eliminate any advantage to patenting by granting one or more
people unlimited sublicensing rights.
JPP and I could sign a contract.  He agrees to allow me to give out
licenses to his encryption system to whomever I want, as many as I
want, and for whatever money I want.  I give him one dollar for this
ability; some consideration (see legal dictionary) is necessary to
make the contract binding.  We can even put the intent of this
agreement--to make the cipher free and to ensure that people know it
will stay this way--in the contract to make our intentions clear.
JPP could do this with several people.  All these contracts could be
made public.  These people can all say publicly that they will
sublicense for free.  No single one of them will be able to charge
money effectively, when someone else will give it out for free.  JPP
could even make enough money for a couple of burritos this way.  :-)
Now, if JPP were to patent it, he could--no problem.  But I, say, have
been granted the right to grant other people the right to use the
cipher, so patenting does not do anything to restrict distribution.
The patent fees would be a waste of money.
Note that these contracts have two purposes.  One, to ensure that the
cipher stays free, and two, to communicate that to the general public.
Both are necessary.

@_date: 1994-05-25 10:20:15
@_author: Eric Hughes 
@_subject: PGP 2.6 is dangerous in the long term ? 
You have to assume that RSA isn't being run by idiots.  Either they're
   looking at closing their doors in seven years, or they've got a plan.
I asked Jim Bidzos about this last year.  He told me they're planning
on becoming a supplier of cryptography code and expertise.  By using
patent protection to restrict distribution of other implementations,
they can sell their own libraries now and get them deployed.  After
the patents run out, they can rely on the cost of changeover and
copyright protection to keep a viable business running.
Plus they're going to continue to buy up patents.

@_date: 1994-05-25 10:23:35
@_author: Eric Hughes 
@_subject: Graph isomorphism based PK cryptosystems? 
I only worry that if I publish, it could be patented.  And I don't
   want the algorithm to end up in the hands of the software patent
   folks.  Especially if they will be making money off it, and I wont.
If you publish, only you can patent.  One must be the 'true inventor'
(or some similar term of art) in order to file a patent on an
invention.  As someone pointed out, a system can be re-invented; then
that person is also a true inventor and can patent.
Publication is protection against patenting.  This is one of the main
reasons behind such publications as the IBM Technical Journal--the
publication of results not worth patenting themselves, but definitely
worth preventing others from patenting.  Publication of a result
precludes this.

@_date: 1994-05-25 15:22:18
@_author: Eric Hughes 
@_subject: My 2.3a Key is listed as a 2.6 on MIT 
I was amazed to see that my 2.3a key now carries a 2.6 version number and    lists an 8-bit key ID.  The key ID is identical to the old one with two    new characters up front.
You mean--gasp!--that someone downloaded the whole keyring shortly
before the server was due to go down?  And then uploaded all the keys
with new version numbers, since nothing else needed to change?
I'm shocked.  Simply shocked.
   Does this bizarre "upgrading" mean that my key, as downloaded from
   that server, will function as a 2.6 key and become incompatible
   with 2.3n versions after the September 1st deadline?
No, it means the keyring format didn't change in the new version, and
that 2.6 prints out more of the last digits of your key, which hasn't
actually changed.

@_date: 1994-05-26 08:00:08
@_author: Eric Hughes 
@_subject: My 2.3a Key is listed as a 2.6 (Aaargh!) 
Maybe  we should request to remove our keys?
Unfortunately, it wouldn't do much good.  The keyservers have no
exclude list, so even if they removed it, someone could reload it back
onto the keyserver and it would reappear.
This flaw is not, at root, a flaw with the keyservers but a flaw with
the key distribution in PGP.  You can't have a public key be anything
other than completely public, that is, you can't restrict the
distribution of a key in any way.
Why might not a key be made public?  The publication of a key sends a
message, and the message is this: "An identity of this name exists".
If you're worried about traffic analysis, you might well also be
concerned that there is knowledge that a particular key is being used
at all.  If you don't want everybody to be able to verify your
signatures, but wish to select those who may, PGP offers facility for
this.  There is no way to represent this desire syntactically and no
way to enforce the desire.
Why might not one want a key distributed?  It indicates use of
cryptography, for one, and, perhaps, the use of patent-infringing

@_date: 1994-05-27 20:59:25
@_author: Eric Hughes 
@_subject: v2.6 for the rest of us 
Versions 2.5 and 2.6 however are obviously illegal exports, and I
   think that it is the fact that people think of one as legal and the
   other as illegal that makes the difference, and therefore we who
   are outside the USA need our own version to be brought up to date.
Legality is always relative to some jurisdiction.  Let us stipulate
for discussion that export of PGP 2.6 from the USA was in violation of
the ITAR.
Is PGP 2.6 in Europe an "illegal export"?  To wit, it is in the USA,
but not in Europe, barring specific reciprocity agreements.  Under USA
law, it violates the ITAR (by stipulation--now may be the time to
reach for the dictionary).  So, if the USA could manage to extradite a
2.6-user from Europe, that person could be tried under USA law,
convicted, and jailed.
Think not?  One word: Noriega.
Noriega was tried under USA law for activities which never took place
in the USA.  You think that sucks?  Well, expect the tendrils of law
to extend past the nominal geographic borders more often.  If
individuals can become locationally ambiguous, there's no reason to
expect governments to remain locationally confined.
Now, is USA law a threat?  Now is the time to estimate the cost of
extradition, trial, incarceration, etc. relative to other law
enforcement priorities.  It's pretty unlikely, in the case of PGP-2.6.
No need to lose sleep.
So, is it illegal in Europe?  Well, not usually.  What law of any
European state has a 2.6-user broken?  The ITAR is a USA law, not,
say, a German one.  There may be other statutes, as in France, which
could restrict its use, but they're not the ITAR.  So if I were living
in England, using PGP 2.6, I'd have nothing to fear from local
authorities as such.  (Maybe from them acting as extradition officers,
but you can figure out that difference easily.)
And I haven't even addressed detection yet.

@_date: 1994-05-27 21:16:33
@_author: Eric Hughes 
@_subject: on detectability of PGP versions 
The issue has arisen of whether displaying some particular version
number of PGP on the inside of messages or signatures implies that one
is using that version number.
How could it?  The format that one bit of public software makes can be
duplicated by another.  If there are two bodies of code which produce
the same output, an external observer can make no decision as to which
one was used if the only evidence were one of format.  If, however,
there were only one piece of code (say PGP 2.6), there would be a
statistically valid judgement that a 2.6 version number indicated a
2.6 use.
Let's say we want to avoid that.  I'd suggest that a future derivation
of the 2.3a code base or the as-yet-mythical 3.0 code base use the
version number in the PGP formats (both binary and ascii) as format
version numbers, and let the version numbers of PGP proper diverge.
To make it really convenient, the config file might have a
version_output flag which indicated what kind of message to generate.
There's no good functionality reason why such a PGP shouldn't write
post-Sept. 2.6 messages, 2.3 messages, 2.4 messages, even non-PKCS 2.2
messages.  Ditto for reading and verifying all those kinds of
Could anybody really tell the difference?

@_date: 1994-05-27 22:10:11
@_author: Eric Hughes 
@_subject: "illegal": law and tort 
Not everything that lands you in court is illegal.
If there's a law passed and you violate it, that's an illegal act.  If
you cause someone harm, that's a tortious act.  Law is a criminal
matter; tort is a civil matter.  Both end up in court, but the
difference between civil and criminal is enormous.
I got some private mail that pointed out that I didn't address the
copyright issue on PGP 2.6.  I'll do so here.  The RSAREF-1 license
doesn't apply outside US and Canada, as I recall.  (And let me be
explicit--I'm feeling too lazy to look it up right now.)  So use of
RSAREF-1 products, including PGP 2.6, in Europe is not licensed, and
therefore infringes the copyright of RSADSI.
Copyright infringement is a tort (a harm), not a violation of law.
Saying that infringing software is "illegal" because it infringes is
incorrect.  Infringing software is tortious, certainly.  Let's put an
end to confusing tortious with illegal.
This distinction makes a big difference.  In the case of illegality,
the government takes you to court.  In the case of tort, the offended
party takes you to court.  Now while one could conceivably be
extradited for the ITAR (criminal), one couldn't be for copyright
infringement (civil).
Now, if someone in Europe were to use PGP 2.6, what could RSADSI do
about it?  They could sue in civil court for damages.  Which court?
If in the USA, then their remedy is limited to what the USA civil
court can order, and if the European user were to have no assets in
the USA, that's pretty much the end of the remedy.  If the court were
in Europe, RSADSI would have to sue in a European court.  Now _you_
guess what that costs.  For an individual user, there's almost nothing
to worry about.

@_date: 1994-05-28 08:16:05
@_author: Eric Hughes 
@_subject: removed from list.... 
The cypherpunks list was wiped because of a bug in majordomo, not
because of some attack.

@_date: 1994-05-28 08:30:39
@_author: Eric Hughes 
@_subject: v2.6 for the rest of us 
The issue is whether mere use of USA-illegally exported crypto is
itself illegal.
   AFAIK (anybody OCRed it?), it
   contains no clause that would cover the use of software or
   rocket launchers that have already been exported.
The text of the ITAR is available at one or both of eff.org or
I purposefully elided over this point in my first post in order to
more clearly talk about jurisdiction.  (This may not have been best.)
I don't know if such use is illegal; for the purpose of discussion
above, I assumed it was.  It may be otherwise, however.  Suppose it's
not explicitly illegal.  Does that mean you can't get prosecuted for
it, or convicted?  Whatever the answer is, it's not "clearly no".
Inside every prosecutor's office is a legal hacker try to push the
boundaries of criminal law, trying to make more things _illegal_.
(Not exactly what you want to hear, I'm sure.)  What creative
arguments might an agressive prosecutor use?  Conspiracy is a good
one.  The argument could be that there's so much publicity about PGP
that any user must know that 2.6 was USA-illegally exported, and,
therefore, was blindly conspiring with the original exporter.  This is
an apparently ludicrous argument, but could it fly?  Ever heard of the
twinkie defense?

@_date: 1994-05-28 08:33:15
@_author: Eric Hughes 
@_subject: "illegal": law and tort 
What if the European user obtains PGP 2.6 from a European site,
   then rips out the RSAREF code, and makes it use Phil's original
   code from 2.3a, and then distributes this copy. Is there still a
   copyright violation on RSADSI?  Is there one on MIT ?
re: RSADSI.  Is the 2.6 work in any way derived from RSADSI property?
It doesn't appear to be.  There's none of the original RSADSI code and
it wasn't used as template for replacement.
re: MIT.  There would still be copyright property of MIT in a code
base as outlined, since that part was not altered.

@_date: 1994-05-28 08:43:23
@_author: Eric Hughes 
@_subject: My 2.3a Key is listed as a 2.6 (Aaargh!) 
will come where it is prohibited to be european and we get arrested
   after coming to the States... ;-)
There's a serious issue lurking behind here, which is that a
sufficiently motivated USA government could keep a hot-list of known
crypto users on the computer at Customs, and arrest them upon entry.
This is unlikely to the point of ridiculousness right now, and, with
Cantwell's bill having passed committee and alternate PGP releases
already out, becoming moot.
   Do I violate american law when I transfer files from United Kingdom
   to Germany?  In some cases the internet packets are routed through
   american machines because the connection Germany/Britain is lousy
   slow.
Well, the USA might want to claim jurisdiction.  They've already done
this with money in transit.  There was a recent case where money was
being wired from Columbia to Europe somewhere.  New York was an
intermediary which provided connectivity for the money--a holding
account.  The money was seized while in the holding account.  The
Supremes upheld the seizure.
An agressive prosecutor might apply this precedent to data flows,
arguing that at the point the data entered a US computer, it came
inside USA territory and therefore was re-exported.  Ignorance might
be no defense.  As I recall, the bankers knew the money was flowing
through New York, but I don't think their client did.

@_date: 1994-05-29 20:46:01
@_author: Eric Hughes 
@_subject: digital clearinghouse idea 
Electronic checks are currently handled by the U.S. banking
      system as Automatic Clearinghouse transactions, and are used by
      organizations such as Checkfree(tm) and by insurance companies
      to automatically take money out of your account each month for
      premiums, etc
If you use the ACH system, you can't pre-authorize sporadic payments
for arbitrary amounts.  Since the receiving institution enters the
transaction into the ACH, and since the security environment of the
ACH is, er, primitive to what can be accomplished with public key
techniques, each transaction amount must be specifically authorized
with a piece of paper.  Individual transactions can be authorized, as
well as periodic payments such as loans and insurance premiums.
With Checkfree, the sender must separately authorize each payment, as
I understand it.  The receiving institution cannot ask for payment.
It's a hole in the payments system--an electronic way for individuals
to give authorization to take money from their accounts on a per
transaction basis.

@_date: 1994-05-30 09:29:35
@_author: Eric Hughes 
@_subject: "lifeguard(?)": bullet tracking system??? 
> What's the relevance to crypto or politics of lifeguard?
Almost all of you saw this quoted statement for the first time on this
list, because I sent the original in private email.
   What's the relevance of microphones in Dunkin Donuts?     What's the relevance of Digital Telephony II?     What's the relevance of 1984?     What's the relevance
   of yet another use of technology by Uncle Sam to strenghen law enforcement
   and the millitary?
Well, it's not privacy, whatever it is.  There's precious little
speech content in a shotgun blast.
Cypherpunks is about privacy through implementations of cryptography.
Some politics intrudes perforce, since use and distribution is part of
implementation, and because bad politics can interfere with both use
and distribution.  Cypherpunks is not _about_ other topics, althought
they can and do become relevant sometimes.
The tailors of seamless garmets should go elsewhere to advocate their
views.  Cypherpunks is not for the partisan.  I don't particularly
care if you're anti-fascist or pro-fascist, if you're pro-privacy,
you're welcome here.  You don't have to be against increased power for
police acting in public to be against wiretaps.
Privacy and encryption is not the sole province of one political view
or another.  As soon as an issue becomes a partisan issue, you've
lost, because at least half the people are against it.  Linking
support for privacy and encryption to the support for any particular
partisan position, be it libertarianism, anarchism, extropianism, or
whatever, is foolish in the extreme.  The implied message is "Warning:
if you don't believe X, privacy may be inconsistent with your current
Those who argue that a support for privacy implies a support for some
other unrelated political view deserve, to paraphrase Tim May, the
results for their own stupidity.  But _I_ don't deserve the results of
this stupidity, and I don't want cypherpunks turned into a medium for
its propagation.
Where is the abortion-clinic-blocking Christian right on cypherpunks?
I, for one, feel that the lack of their presence is a serious flaw in
the social makeup of cypherpunks.  There _are_ members of the list who
are sympathetic to this view, but they do not have a presence,
certainly, in the same way that the libertarians do.  This is a flaw.
We need the presence of more folks who are in-your-face for privacy.
There are some in the Christian right, I'm sure.  Why are they not
They and others are not here because they've been chased out by the
anti-government rhetoric.  Being against government in general
certainly leads, _a fortiori_, against government involvement in
crypto.  It is not, however, the only such reason to be against
government restrictions on crypto and government actions against
privacy.  I'm sure it feels very nice to be part of a mutual
self-congratulation anarchy, but to the extent that
self-congratulation causes the exclusion of others who share your
nominal political goals, that self-congratulation is stupidity.
There is a tendency to argue for privacy by a deduction from some
previously held political view.  That's fine for one person, but it
doesn't generalize past one's own partisans.  If you want victory, and
not just a few small gains, you have to generalize, and in order to
generalize, you have overcome your laziness to think in terms of your
own values and not in terms of those of another.  If you want to
convince someone else who doesn't agree with you in many things, you
have to dig deeper and think harder about the reasons and the desires
for privacy.
Therefore, off-topic posts like the one about gunfire location are
counterproductive.  They implicitly argue that "you, too, should be in
alignment with this in order to be pro-privacy."  Get it out of here.
A have only a little hope, but definitely some hope, in the power of
self-restraint to make a good discussion forum.  Think about what
you're saying on the list; if it's not about privacy through
cryptography and their tactics, don't say it here.

@_date: 1994-05-30 09:41:32
@_author: Eric Hughes 
@_subject: Does Estonian RSA chip violate patents? 
As far as I know, RSA/PKP patents are for _algorithms_, not
   respected outside the US, though patents for RSA/PKP _hardware_
   would be respected worldwide.
The patent on the RSA cryptosystem, whatever its content, only applies
within the USA.  There is no worldwide patent on the RSA cryptosystem.
Activities not in the USA are not relevant to a USA patent.
   I'm not sure how algorithm patents can be applied to hardware -- you may or    may not be able to sell this chip in the US _without_ violating patents. If the firmware on the chip does RSA, it's covered.  If it merely does
modular exponentiation, it's not.  If the chip has an on-board
programmable microcontroller and no RSA firmware, it's not covered by
the patent, even if software can be loaded into the chip which does
RSA.  The device which loads the code in and which uses the loaded
code, however, would be covered.
   You may even be able to apply for a European patent for the
   hardware, which would then be respected everywhere, except in the
   US where it may be superceded by the algorithm patents.
Supercession like this does not happen.  If there were a patent on the
hardware and a patent on RSA both active in the same jurisdiction,
one would have to obtain license from _both_ patent holders.

@_date: 1994-05-30 21:47:02
@_author: Eric Hughes 
@_subject: IMP (was Re: ecash-info (fwd)) 
1.) Chaum's e-cash coupled with WWW/Mosaic is a de facto internet
   mercantile protocol.
Hardly.  The announcement just says it's available, not that anybody's
using it.  Since the information came from a press release, we can
assume that lack of mention of an important customer, like a bank,
means that there are no such customers right now.  What that says to
me is that DigiCash has looked for customers, and not found any.
They've certainly had the time.
Furthermore, it's not clear that this software can be both legally and
usefully deployed in the USA.  The Foreign Bank Secrecy Act of 1974
requires the microfilming of all checks of value over $100, with
administrative provisions for extending the required recording
keeping.  Other check-like transaction accounts have since been added.
So can a bank avoid this?  First, they can limit transaction amounts
to less than $100.  That violates my criterion of usefulness; it would
have some utility, to be sure, but just as surely would be a severely
crippled utility.  Second, they might be able to record the
transaction as a "cash purchase".  The problem here is that this
accounting technique may be ruled non-compliant by the regulators,
which would make the transaction _illegal_ (since there's not way to
comply by recording both parties).  The regulators have been
authorized to move activities across the boundary of legality by
legislative action.  Now, one cost of deploying any such system would
be the expected (negative) value of the risk taken in losing the whole
development investment to an adverse regulatory decision, let alone
possible actual penalties.
Even beyond this, there's the IRS $10K cash reporting limit, and the
attendant restrictions on structuring.  Detection of structuring
becomes much more difficult, and banks are held responsible for at
least some of the enforcement.  Here's another set of risks, like
Just how big is the potential Internet market (in, say, two years),
compared to other banking segments?  Precious small right now, really.
Just plain profitability is also an issue.  Add to that costs of
licensure and costs of risk and you're left with some significant
barriers to USA deployment.
   2.) It seems to me that that e-cash, contrary to the status quo's thinking,
   is *critical* to internet commerce. No, it's not critical.  Some form of transaction mechanism is
critical.  Privacy is not critical to the bulk of the economy, though.
Face up to it.  If it were, it would be so obvious that we wouldn't be
discussing it on a mailing list.  In fact, _we_ wouldn't be discussing
it, but rather a whole bunch of bank vice presidents.
   An anonymous cash market is most
   unrestricted and efficient market there is, because privacy/security (more
   than trust, I think) is the capstone of any serious transaction mechanism.
Is anonymous cash really the most efficient?  No, not in all cases.
When no one is looking, the anonymity is irrelevant, and
identifier-based schemes work fine.  Is, for example, anonymity the
most efficient for the Federal funds transfer network?  No, because
the values of money are so large that default on a transaction would
case serious systemic problems.
Cash does have some advantages, in particular its immediate and final
clearing.  These can reduce transaction costs in certain markets.
Anonymity, however, is not a panacea.
Characterizations of where anonymity is _already_ practiced indicate
potential places for initial deployment.  Negotiation for trades in
the foreign exchange market are frequently anonymous, even though the
trades themselves are not.  There is a gold and silver exchange in
Shanghai, I think it is, where the exchange keeps no records and all
transactions are settled between traders.  Motivated list members may
wish to hit the libraries and look for more.
   3.) Since a big pile of the discussion on this group lately has been about
   our collective concerns about an RSA-approved version of PGP, I think there
   is a real parallel here in e-cash.  PGP only requires the cooperation of your email correspondent in order
to function.  The risk of a patent infringement suit is small, since
the parties involved are small.  Digital cash requires the
participation of many more parties, some of whom have, almost of
necessity, deep pockets.  The parallel does not extend very far.  Without the creation of an
entirely black market which can remain completely unexposed (and this
is more difficult that it appear even on second or third thought), it
is unlikely that digital cash technology will be usefully deployed

@_date: 1994-05-30 21:52:08
@_author: Eric Hughes 
@_subject: The Cypherpunks' Electronic Book 
I'm afraid, then, that this project is doomed, because I don't have
time to hack on majordomo.  Gary Jeffers, however, could manage the
whole thing with a cleverly written procmail filter, taking
inspiration from the cypherpunks remailer on how to offer mail servers
from user accounts.

@_date: 1994-05-30 22:01:51
@_author: Eric Hughes 
@_subject: Popular opposition doesn't mean privacy is lost 
While grudgingly accepting the larger message of your posting, I qualify
   this with the following observation:
Thank you.  I'll clarify what you responded to below.
re: partisan issue v. direct action
When you're engaged in politics, you try to be politic.  When you're
directly acting, you can tell 'em to fuck off.  And I find no
particular contradiction in participating in both contexts at the same
time.  The key is to realize that there are two different contexts
with different rules of rhetoric.
   Egregious among the ``large, faceless organizations'' is the tyranny
   erected by the majority, ``at least half the people'', called democratic
   political government.
Not everyone believes this.  Be politic when doing politics.
   My interpretation of the welcome message has always been that a
   cypherpunk works to create his own privacy _in spite of_ interference [...]
And do whatever you want when not doing politics.
It was not my intention to become involved with political issues as
such when cypherpunks started.  Clipper changed that.  Direct action
of writing and deploying code should continue, as well as the
political education and action necessary to allow deployment to exist.

@_date: 1994-05-30 22:08:01
@_author: Eric Hughes 
@_subject: IMP (was Re: ecash-info (fwd)) 
re: IMP-interest folks
   [...]  it seemed unlikely that a group of such hobbyists could
   build a real digicash system while avoiding Chaum's work!
Well, the IMP people weren't tring to build digicash, but rather do
internet commerce.  Cash and anonymity were discussed, but were not
considered central to the program.
   (2.) It seems to me that that e-cash, contrary to the status quo's thinking,
   > is *critical* to internet commerce.    Of course crypto and true digital cash is central....this is our whole
   message, nearly.
When I responded directly to the original message, I claimed that it
wasn't central to internet commerce.  I was speaking there about the
realpolitik of deployment.  Internet commerce can and might happen
without anonymity.
That doesn't make it any less central to my own and other's desire
that it be present and available.

@_date: 1994-05-30 22:23:43
@_author: Eric Hughes 
@_subject: IMP (was Re: ecash-info (fwd)) 
I figure that somebody acted. Somebody wrote code. Is it shipping? I have a
   product I'm dying to sell this way right now.
I'd like to hear something about this.  If you don't want to talk
about the product or it's means of delivery, fine.  We're talking
finance here now.  My questions are:
Total yearly expected revenue -- gives an idea about how much revenue
is available to create intermediation.
Distribution of buyers of the transactions -- is this more like a
vending machine or a subscription service?  A question of relative
efficiency between identifier systems and cash systems.
Total number of transactions -- gives an idea of the cost per
transaction and the amount of capability to provide that number of
Distribution of the amounts of the transactions -- are the amounts
fixed, clustered, flat, or what?  This also affects the relative
efficiency of various systems.
Distribution in time of the transactions -- another cost-to-
figure; peak load is important.
If you don't want to discuss this in public, I also understand.

@_date: 1994-10-03 21:30:42
@_author: Eric Hughes 
@_subject: Bomb information ban 
should seek to replace the traditional symbol of anarchy (you know, the
   bowling ball with the fuse) with something more moderne. What, like a zero with a one sticking out?
You do know, of course, that explosives increase the entropy of their
targets toward maximum.

@_date: 1994-10-03 21:43:01
@_author: Eric Hughes 
@_subject: US Should Forbid Export of Digital Wiretap Technology (fwd) 
comp.society.privacy yields the following from crawford at scipp.ucsc.edu
   (Mike Crawford).  I _think_ it's black humor, but the moderator of c.s.p
   seems to have accepted it at face value.
No, it's serious, and it's brilliant.
The gambit is this.  The law enforcement community argues that they
won't abuse their technical ability to wiretap.  Implicitly they
acknowledge that such ability is both possible and undesirable.  Now
Mike Crawford observes that legal safeguards, _which are the only
safeguards_, do not exist in other countries, and therefore
uncontrollable wiretapping, which is acknowledged undesirable, should
be restricted by law in this country which prevents such equipment
from being deployed in a country without safeguards.
Now, do you think that any switch manufacturer is going to want to see
their international market torn to shreds like this?

@_date: 1994-10-05 09:13:52
@_author: Eric Hughes 
@_subject: private assets in the world 
Some interesting figures recently wafted my way about the sizes of
private asset holdings in the world.  These are Goldman, Sachs
4 Trillion (10^12) dollars in total worldwide personal assets
2 Trillion of that is secretly held assets
1.5 Trillion of the secretly held assets are in Switzerland
Mighty interesting numbers indeed.

@_date: 1994-10-05 20:51:11
@_author: Eric Hughes 
@_subject: ANNOUNCE: SF Bay Area Physical Meeting 8 Oct 94 
What: SF Bay Area Physical Cypherpunks Meeting
When: Saturday, 8 Oct 94
      12:00 noon - 6:00 p.m.
Where: Silicon Graphics, Mt. View (directions below)
(Provisional) Theme: Intellectual "Property"
    Mark Hosler of Negativland will be our (provisional) guest.  He's
told me he's planning on showing, but I've not been able to confirm
with him in the last few days.  For those of you who don't know what
Negativland is, they're a music group who got into a fracas with
Island Records and their own label SST over a recording Negativland
did entitled "U2".
    Mark/Negativland have a new book coming out called _Fair Use_,
which is a complete history of the whole affair with both commentary
and a complete set of primary source documents.      Our theme, therefore, will be intellectual property, information
distribution, sampling, etc., with, of course, applications to
    We will also, as always, welcome and expect topics and
presentations from the attendees.  If you've got something you want to
present, you've got the time here.  If you've got something you want
to discuss, you can have the floor to lead a discussion of it.
    All are welcome, whether or not you've ever been to a cypherpunks
meeting before or not.

@_date: 1994-10-06 04:57:19
@_author: Eric Hughes 
@_subject: data havens and operator protection 
When the site is up, please don't store much as I do not
   have that much disk space, and ENCRYPT your files.  I fear
   that someone will send me some stuff that is very illegal,
   and leave it in the clear.  I'd suggest that you test for various entropies of distribution, and
reject anything that doesn't look random.  I'd also suggest testing
for various magic numbers such as for compressed files (various
formats) and executables.
Either you should concern yourself _and_ do something about it, or
not.  Worrying about it and not preventing what you are concerned
about is silly.

@_date: 1994-10-06 05:04:39
@_author: Eric Hughes 
@_subject: crypto game idea 
These constraints imply there is some bank-like agency that creates and     signs "official" game cards.  Cards are a conserved quantity, and digital money protocols apply to
any conserved quantity.  You would need one currency for each card type.
Another interesting thing about MTG is that since each player has a
separate deck, and not a single shared deck, all the problems of
dealing out of a shared deck are gone.  In fact, you can play the game
entirely with one-way functions, I'm pretty sure.

@_date: 1994-09-08 22:52:26
@_author: Eric Hughes 
@_subject: ANNOUNCE: September meeting is Third Annual Cypherpunks Conference 
What: The Grotesquely Overnamed Third Annual Cypherpunks Conference
When: Saturday, September 10, 1994
      12:00 noon - 6:00 p.m. PDT
Where: Silicon Graphics, Cafe Iris
    In the annual tradition of overblown announcements of the
September Meeting, this greeting invites you to the Third Annual
Cypherpunks Conference, Worldwide Media Event, Gala Schmooze Festival,
and Anarchic Capitalist Celebration Banquet, all to be held at the
usual date, the second Saturday of the month, at noon.
    Featured will be an overview of CRYPTO '94 with lots of good
results including an experimentally attained known plaintext attack on
DES, cryptanalysis of a chaos-linked telephone scrambler, and new and
unproven hash functions.
    Join us!

@_date: 1994-09-12 09:28:16
@_author: Eric Hughes 
@_subject: Introduction- Telephone 
When you have an untappable wire
   between the sender and recipient, then traffic analysis is impossible (and
   crypto unnecessary).
Yet you can create an untappable wire with cryptography!  The device
in question is called a link encryptor.  Take a stream cipher and run
it continuously across the channel in question.  Pad the asynchronous
traffic when it's not flowing and add some synchronization to both the
stream and the data insertion.
You can tap the physical line still, but the interceptions reveal zero
information (computationally--the stream cipher _is_ keyed, after
A good project would be virtual link encryptors for the Internet.

@_date: 1994-09-12 09:29:11
@_author: Eric Hughes 
@_subject: the usual suspects 
John Droge (?)
John Droge is the product manager for Mykotronx in charge of Clipper

@_date: 1994-09-15 07:34:16
@_author: Eric Hughes 
@_subject: RC4 Legal Issues 
Can RC4 still be construed as a trade secret or proprirtary to
   RSADS and Bizdos or are, as I understand from previous messages,
   we free to use RC4 now (ignoring the submarine patent issue)?
A trade secret is just that, a secret.  For parties unrelated to the
holder of the secret, once it's no longer a secret, it's not a secret,
and the former holder of the secret has no protection at all.  In
other words, if you're not, say, a BSAFE licensee, you are free to use
the alleged RC4 algorithm.
Let me repeat.  If you've never made an agreement with RSADSI about
not distributing their trade secrets, RSADSI has _no_ claim against
you about the trade secret.  (I don't know if the name "RC4" is
Note the use of the word 'unrelated' in the sentence above.  The
situation is hazier there.  Both licensees and agents (including
employees) of the holder of the secret are liable for damages if they
breach the trust of the secret holder by revealing the secret.  This
liability, however, does _not_ make the secret any less revealed.  The
former holder can sue for damages, assuming there's someone to sue and
the damages can be ascertained.
If you're the user of a product which includes RC4, like Lotus Notes,
for example, the agreement between Lotus and RSADSI about protection
of trade secrets doesn't apply to you, assuming you don't work for
Lotus or RSADSI.  You weren't a party to the agreement, and its terms
don't directly affect thrid parties.  You made a (shrink-wrap)
agreement with Lotus, not RSADSI.

@_date: 1994-09-15 07:47:04
@_author: Eric Hughes 
@_subject: RC4 Legal Issues 
Does the answer to this question depend on whether it really was reverse
   engineered, or is a direct lift from the original source code?
It does not matter to disinterested parties, like the average
cypherpunk.  If it was reverse engineered, there may be a claim by the seller of
the software against the licensee for breaching a "no reverse
engineering" clause.  In this case RSADSI is not a party to the action
because the reversing engineer did not make an agreement with RSADSI
concerning trade secrets.  Any disinterested party is also not subject
to this action, because they made no agreement with anybody involved.
It's possible that RSADSI and, say, Lotus have an indemnification
agreement in the case of reverse engineering, but that only affects
the distribution of resources between those two companies.
If it was lifted from source code, then RSADSI has a claim of
malfeasance against theft of trade secrets.  This doesn't reverse the
fact that it's no longer a secret, but rather allows RSADSI to sue for
the damages caused by the revelation of the secret.  RSADSI can only
sue the person who revealed the secret, not just anybody who posesses
it.  It's also possible that there might be a claim against the party
to whom the secret was directly divulged, were there some conspiracy
to steal trade secrets.  That situation does not seem to apply here.
In all of the above, be mindful that anybody can file a lawsuit and
claim anything at all, and if it sounds official the gullible might
believe that even the most farcical claims have merit.

@_date: 1994-09-15 07:57:54
@_author: Eric Hughes 
@_subject: RC4 Legal Issues 
Some general words on trade secrets.
Trade secret law is eminently sensible.  It grows out of common law
and the merits and facts of real situations regarding information.
Trade secret law does not attempt to reverse the disclosure of
information, which would be contrary to the properties of information.
It does not require that people forget something they have learned.
Nor does trade secret law force tribute upon those who use that
knowledge, as patent law does.  It does not restrict the transmission
of information, as copyright law does.
If, however, you tell someone you're going to keep a secret, and they
compensate you for that promise (i.e. consideration in a contract),
then the law expects you to uphold your promise or make good the harm
that you've caused.  Lacking an agreement, the holder of the agreement
has no recourse.
In a cryptographic world, the model of trade secret law is worth
considering.  It concerns only information and agreements between

@_date: 1994-09-17 16:15:28
@_author: Eric Hughes 
@_subject: On the crime bill and remailers 
Even the crime bill doesn't apply _ex post facto_, meaning anything
newly illegal under the crime bill wasn't illegal before it.  In
particular, any discussion about remailers, discussion which has
already happened and which might be construed as conspiracy for a
newly illegal action, cannot now be subject to the terms of a new
bill.  Even more in particular, any discussion of remailers that has
already happened is perfectly safe.
And as for me, I don't plan on shutting up now.

@_date: 1994-09-17 16:58:22
@_author: Eric Hughes 
@_subject: Data Havens 
I was exploring the concept of a "data haven" which, to my
   knowledge, a place whose location is unknown to its users, but via
   anonymous remailers, files can be stored and retrived from it.
This is certainly on-topic.  As stated, however, the outline suffers
badly froma confusion of purpose.  It is not necessary to solve every
problem that can be thought of, merely to solve the most important
problem in such a way that allows it to be combined with other known
Specifically, the proposal worries far too much about communications
security and routing issues, which best go elsewhere in the
abstraction.  The main service proposed is data storage, not anonymous
remailing.  Remailing can be done with other segments.
Secondly, such storage need not be tied to identity.  There's no need
for passwords or passphrases or even public keys.  The main idea here
is storage.  You want the property that arbitrary people can't scan
the storage facility for content, but identity, while it would work,
is _more_ than is necessary.  (Can anybody anticipate the solution?
See below.)
   2:  One must have to "hide" behind a VERY TRUSTABLE remailer, [...]
This is a concern about communications, and is not necessary to the
main idea of remote archiving.
   4:  A need for verifing that the mail got to the DH successfully since
       data errors do occur, and sometimes networks truncate mail packets.
Again, this communication issue should be dealt with in a separate
layer that is concerned about the reliability of communications.
   5:  A way of making verifing that the user is who (s)he claims to be.
Identity-based retrieval is possible, but it's not necessary.  Since
the service is single purpose (storage) and won't be dealt with
directly by humans, i.e. no command prompt, but rather will act as a
back end for some retrieval process, the persistence of identity isn't
required at the back end.  Some persistence will certainly be useful,
but it can occur at the user's end.
   6:  Multiple security levels, so files cannot be retrived even if
       one's PGP key is compromised (user settable)
This is really overkill.  Every bit of complication makes the code
harder to design, harder to write, harder to debug, and harder to
deploy.  A simple solution with the basic function can later be
elaborated upon.
   8:  There will need to be a way to tell if the DH is up or not.
If you make a request, and nothing comes back, it's not up.  I don't
see the value in extra functionality.
   9:  How will PGP keys be stored and indexed?
Again, this issue can be finessed.  At least part of the issue is a
communications one as well, which is best dealt with elsewhere.
   10: How would people be able to trust a DH?
If you store only encrypted data--and only the stupid would not--the
only bit of trust is in continued uptime.  Replication and redundancy
can be handled at the user's end.  At some point _every_ replication
bottoms out to the unreplicated storage of some bit of data.  This is
the primitive, and this deserves to get implemented first.
   11: How would a DH turn away files because the disk is full?
Silent failure should work just fine.  Disk space limitations are just
as difficult to deal with as communication failures.
   12: Would integrating DigiDollars with a DH be a good idea?
At some point when they exist, yes.  Right now, without such
mechanisms, requiring this will prevent any deployment.
   I apologize for the length of this post, but there are a lot of questions
   and problems in making a stable, usable data haven.
Looking to implement the final goal as a first project is doomed to
failure.  Implementing a simple primitive as an attainable project is
a much better idea.
Now for some specifics.  There is a package called Almanac which is a
file-by-mail server.  Leveraging off this code is a good place to
start.  Lots of the basic issues are already solved.
Now, about authentication.  The basic service is storage.  It's not
even providing name access to the storage.  The data itself is what is
desired, and a cryptographic one-way hash function suffices as a name.
Knowledge of the hashcode provides all the authentication that is
needed.  If you don't know the hashcode, you can't get the file.  If
you do know the hashcode, you can.  No one else can guess the
hashcode, and since no one else knows these hashcodes, the hashcodes
suffice as a replacement for the presistence of identity.
Furthermore, the many files stored by a particular individual are not
linked together in any way on the remote site.  The storage site need
not have this data; in fact even having this data introduces another
security risk.
The software on the user end can keep track of any mapping desired.  Some
sort of tracking software on the user end will be needed in any case
to keep track of what is stored where; it may as well keep track of a
remote name mapping.
So the primitives to implement are very simple; there are two: "store
text T" and "retrieve the text with hashcode N".  Perhaps a third is
also desired: "is text with hashcode N present?".
This kind of system is very simple.  For implementation of the back
end, the files can be stored with filenames which are hexadecimal
representations of their hashcodes.  This representation allows one to
leverage the existing index structure of the file system, avoiding the
need to code one inside the application.
For the front end, a log file will suffice for a trial version of name
mapping.  The retrieval method is "grep by hand".  Something more
advanced can be implemented later, perhaps something that looks like a
file system or an ftp site.

@_date: 1994-09-17 17:02:07
@_author: Eric Hughes 
@_subject: Data Havens 
P.S. Thanks to Bill Stewart for raising this issue last week at the
physical meeting.  He had a similar idea, with similar complications.
There's no shame in not having complete clarity on a first proposal.
The basic idea of hashcode-naming arose during Bill's presentation.

@_date: 1994-09-17 17:09:55
@_author: Eric Hughes 
@_subject: (fwd) "Will You Be a Terrorist?" 
[...] perhaps it's time to start seriously
   looking at hacking list software to create mailing lists that are fully
   anonymous and encrypted.  Has anybody started on such a project?
I'd suggest that a much more productive avenue of approach would be to
improve the aliasing facilities of a remailer provider to allow a
pseudonym to look like a fully normal name.
Ownership of root is not necessary for this.  I know that Matt Ghio's
mail delivery set up allows this.  At his site there's this
'name+extra' syntax which delivers mail to 'name', but because of a
special sendmail version 8 macro in the Received: field both the
'name' and the 'extra' can be recovered.  The 'extra' is then an input
into a remailer as a pseudonym.
The aliasing has to happen somewhere.  It can happen at the mailing
list exploder or at the remailer.  Since the mapping at the remailer
is of much more general use, and since it allows one to leverage _all_
forms of mail communication and not just mailing list, it seems like a
much better place for that mapping to exist.  Implementation inside a
remailer is a duplication of function--almost always a bad thing.

@_date: 1994-09-17 17:17:39
@_author: Eric Hughes 
@_subject: RC4 - A response from RSA Data Security, Inc. 
Weasel words if I ever saw it.
   From: jim at RSA.COM (Jim Bidzos)
   FYI... I'd appreciate if you posted this wherever you saw RC4...
       It has come to RSA Data Security's attention that certain RSA
   trade secrets, in the form of confidential and proprietary source
   code, have been misappropriated and disclosed.  [...]
Let it be officially observed that nowhere in this 'warning' is there
any claim that the alleged RC4 code posted is related in any way to
"certain RSA trade secrets".  The innuendo to Bruce is certainly that,
but there's no official statement to that effect.  All this statement
says is that certain things happened, but does not claim that the
specific code posted is what is being referred to.
And I suspect that's because a statement to that effect would be a
lie, or at the least counterfactual.  If the code posted were
copyrighted, it would be much stronger to make the claim that in fact,
the posted code was RSA code.  That's not actually claimed, and the
statement published stops just short of it, just short of making a
false public statement which would restrain trade.
In other words, it's _all_ hot air, not just most of it.

@_date: 1994-09-17 17:19:54
@_author: Eric Hughes 
@_subject: RC4 Legal Issues 
Ah, but that does make some sense. You see, Stac bought MS-DOS from
   Microsoft, and had to adhere to Microsoft's shrink wrap agreement.
Whether or not a shrink wrap agreement is valid is a further issue
here as well.  Taking something apart that lots of people have is, or
at least should be, a fair use.

@_date: 1994-09-17 17:21:11
@_author: Eric Hughes 
@_subject: The Importance of Filtering 
Still, if one of thse could be made
   accessible to anon ftp it might be worthwhile (if toad allows anon ftp).
Toad.com does not run an ftp daemon, and I can't install one myself.

@_date: 1994-09-17 18:36:07
@_author: Eric Hughes 
@_subject: terrorist FORTRESS SLEUTH remailers & FORTRESS lists 
We are in a time window now. In a few years at most, remailers &
   lists like Cypherpunks & newsgroups like Sci.crypt may be outlawed.
Outlawed where?  In every jurisdiction in the world?
I would prefer to deal with this situation when it appears likely to
happen and concentrate on achievable results now.  Focusing on the
harder problems of greater repression will prevent useful progress
from being made.

@_date: 1994-09-19 10:18:20
@_author: Eric Hughes 
@_subject: DC-Nets and IP addresses 
I've been arguing that DC-Nets are among the crypto protocols that
   we've not exploited much so far. I was working on an
   implementation, till I got stuck with the 'net' part of it.
Speaking of long-term integration on the internet, might it not be a
good idea to get some IP address range assigned for dc-net use?  To integrate with the rest of the Internet, there should be some IP
address that this message appears to originate from.  These are the
addresses that need reservation.  Class A,B,C addresses are the standard unicast addresses for network
interfaces.  Class D addresses are multicast addresses.  Class E
addresses are reserved; there are 27 bits of address space available.
If we could reserve some 11 bit prefix of this address space, that
would leave us with 16 bits of address for dc-net addresses.  This
will certainly suffice until the new IP is fully deployed.
As far as social mechanisms go, how does one go about reserving some
prefix of the Class E address space?  Could our resident IETF gurus
comment, please?
Very Simple Review: To send one message, (1) a group of people make a
bunch of bilateral communications.  (2) Each person publishes the sum
of all the messages the receive.  (3) The sum of all the broadcasts in
item (2) is the message.
There are a bunch of integration issues to deal with as well.
For communication internal to the dc-net, i.e. from one member to
another, a Class D multicast address will suffice.  All the dc-net
members would be members of the multicast group, and any of them could
reconstruct a message.
Communication from the dc-net to the rest of the internet is the
problem.  How does someone send a message into the dc-net?  How does
the dc-net send a message outside itself?  How do you properly do
name service?
For sending a message into the dc-net, a message directly posted from
the outside to the internal multicast address for the dc-net would
suffice.  But most systems can't route to a Class D address yet.
Sending a message from the dc-net should appear, in an ideal world, to
originate from the Class E address for the dc-net, but the same
routing problem is even worse here.
Unicast proxy addresses for the net solve both of these.  By using
multiple loopback interfaces, you can given a machine on the Internet
more IP addresses than it has physical interfaces.  That is, if a
single machine has only an ethernet connection, adding two loopback
interfaces could give that machine three IP addresses.  These extra IP
addresses can be used as proxy addresses.
These proxy sites would have to be trusted at least against denial of
service.  If one assumes higher level authentication and integrity
checking, alterations in the message stream by the proxy can be
detected.  Failure recovery could then include choice of a new proxy
or reconfiguration of the dc-net.
I can't really comment now on how might a proper long term solution
might work.  One would at least keep the proxy addresses for backward
compatibility, since it's unlikely for many years to have direct
support for dc-nets shipped as standard kernel features, although that
_is_ the eventual goal.  It's likely that the protocols for
discovering and joining multicast groups, as one example of an
aggregate addressed entity, will apply here.

@_date: 1994-09-19 11:20:47
@_author: Eric Hughes 
@_subject: (fwd) "Will You Be a Terrorist?" 
>I'd suggest that a much more productive avenue of approach would be to
   >improve the aliasing facilities of a remailer provider to allow a
   >pseudonym to look like a fully normal name.
   I'm not sure that's a good solution.  Todd, Todd, Todd.  You can run a remailer and the mailing list on the
_same_ machine and do the aliasing in the remailer.  You can even
restrict operation of the remailer to work only with the mailing list,
if that's what you want.
The issue here is clean separation of abstraction.
   >At his site [that's CMU--EH] there's this
   >'name+extra' syntax which delivers mail to 'name', but because of a
   >special sendmail version 8 macro in the Received: field both the
   >'name' and the 'extra' can be recovered.  The 'extra' is then an input
   >into a remailer as a pseudonym.
   Sure.  I'm familiar with AMS [...]
This doesn't require AMS.  I've done the same hack myself in ruleset 0
of sendmail.  Then you tweak the HReceived line to add the $u macro,
which under sendmail v8 includes the whole address which caused
   Another, better I think, possibility is
   to add headers and let the MUA sort it out: you don't have to depend upon
   non RFC-822 features in the MTA.
That's exactly how it works now.  The Received field is rfc822
compliant, and the remailer, which is a part of the MUA, is where it
gets parsed.

@_date: 1994-09-19 17:14:37
@_author: Eric Hughes 
@_subject: (fwd) "Will You Be a Terrorist?" 
[...] giving both limited-use remailers Limited use remailers are exactly what a subscription service does.
   Could you send me what you've done on this?  I think it's a desirable
   feature to have, though requiring that people hack their sendmail.cfs
   is not a big boost to the "popularity of package" indicator.
Admittedly, sendmail.cf hacking is not for the light of heart.  I've
appended a little tutorial I wrote a few months ago on how to do this.
The only correction I have on rereading is that version 8 sendmail
doesn't use frozen configuration files.

@_date: 1994-09-19 21:15:20
@_author: Eric Hughes 
@_subject: Sendmail hacking (was (fwd) "Will You Be a Terrorist?") 
While Eric's way of doing things works, I reccomend asking your
   systems manager to look at installing procmail as the Mlocal agent.
This is good advice, for different reasons.  I do realize that the
stated reasons in the little tutorial were for mail sorting, but I
really worked it out for remailer addressing.  Installing procmail for
local delivery does make filtering easier.
The idea is that I could, for example, take an address, for example
hughes+SOLONg at ah.com, which is really addressed to someone else, and
map it in my own mail filter, at the user level, to the real
recipient.  This address is a real first class address, not just a
comment in an address field, and is guaranteed to work wherever
email is supported.
Now as far as politics go, I wrote that tutorial in such a way that
you could give it to your sysadmin and have them do the work.  The
"explanation" at the beginning is a prepackaged excuse for why you
want it. ;->

@_date: 1994-09-20 09:34:28
@_author: Eric Hughes 
@_subject: On the crime bill and remailers 
>But they are so targeted to prevent GOVERNMENT    >observation and intercepts, that they just plain look bad.
   I strongly disagree with this.  Anonymous remailers as presently constructed
   will be almost completely ineffective against any significant government
   attempts to surveil email traffic.
Is this the national security part of government, or the law
enforcement part of government?  Certainly the national security
apparatus has the technical means to defeat the current remailers,
but does the FBI or (even more unlikely) the local cops?
True, the FBI could ask for a data tap on the connections to a
remailer, but they would have to know how to do it, first, and in any
case it would be very expensive.  Compatible remailers spanning the
globe could be argued evidence of an attempt to thwart law enforcement
access by internationalization.  Certainly remailers hinder law
enforcement, if not actually prevent it.
And in the end, it's a court that decides, not a military tribunal.
Uni's argument is worth examining and does not fall down on its face.

@_date: 1994-09-22 12:00:10
@_author: Eric Hughes 
@_subject: HIT MEN 
I'm sorry, but this is patently ludicrous.  This is not a MUD or
   MOO.  We're not talking about game theory and the "iterated
   prisoner's dilemma."  This is about the real world.  Game theory _does_ make a distinction between activities that make
victims and those that don't.
Gambling is victimless.  All parties consent to the transaction.  The
end result is a rearrangement of economic power.  There is a small
indirect loss to the extent that the two bettors make effort
conducting this transaction, but this effort is not freely usable
by other parties.
Murder has victims.  The dead did not consent to their death.  There
is a direct economic loss in the now unavailable abilities of the dead
and indirect economic loss in the process of disposing the dead's
It is not, however, the direct parties to the "transaction" where the
game theory applies, but rather in the relation of other parties.
If I know that two people are betting with each other, that doesn't
affect me, because their activity is completely consensual.  If I
don't want to gamble, I don't have to.  I can't deny my gambling debts
if I've never used an opportunity to get any.
On the other hand, everyone has enemies and everyone has different
enemies at different times.  Each person has some risk of being
murdered, be it large or small.  The relationship between a murderer,
their agent, and the victim is _not_ separable from my own interest,
because I stand some non-negligible possibility of being the victim in
the future.
Therefore it is in my own best interest to take action against a
structure of murder for hire if the cost of that action is less than
the marginal cost of my risk against murder.  In other words, the
cheaper murder for hire is, the more people there will be who will be
interested in making sure it doesn't exist.
Risk is a subjective entity.  The less able one feels able to identify
and analyze potentially harmful events, the higher the risk is.  A
major change in situation, for example, the existence of a truly
anonymous murder market, greatly increases risk, because nobody has
experience in how such might behave.  Do not be surprised if many,
many people take it upon themselves to quash the building blocks for a
murder market.
Ironically, if it seen that the limiting factor in deployment of these
markets is the creative thought of the designers, it will be in the
best interest of many people to use these incipient markets to prevent
their further growth.

@_date: 1994-09-28 20:37:29
@_author: Eric Hughes 
@_subject: groups 
Frequently when discussing a cypher the
   question of whether it is a group arises.  In the absence of further
   definition, is it safe to assume that the set of elements for this
   group is the cyphers with each possible key and that the operation for
   this group is composition?
Yes, this is exactly how what this "is X a group" mean when applied to
ciphers.  It's an attempt to get a handle on just how much extra
scrambling happens under composition, i.e. double, triple, multiple
The useful question is, however, not whether it's actually a group,
but just how close to a group is it?  If it were only lacking one
element, it wouldn't be a group, but double encryption would be
statistically speaking a waste of effort for such a hypothetical
cipher.  The work on DES showed that DES is very far away from being a
group.  There are interesting questions about the semigroup that DES
encryptions generates.  Does it contain the identity, i.e. does it
even generate a group?  Put yet another way, does some combination of
encryption (not decryption) operations eventually generate the
identity function?  If so, how long is the shortest such combination?
The goal is to estimate the size of the keyspace for a theoretical
exhaustive search attack.  The result is a greatest lower bound on the
keyspace entropy.
These techniques are not really well developed.  I expect that these
issues will lead to some extremely interesting developments in
mathematics.  In analogy I point out the stochastic stability theorem
for vector fields.  It turns out that strictly topological
classification of vector fields doesn't work for a variety of reasons.
But add a small amount of "diffusion" to the flows and you get a
really nice classification theorem in terms of Morse functions and
elementary catastrophes.  (See Chapter Two of Casti's _Reality Rules_.)
For groups the situations seems similar.  You've got a situation where
a small deletion removes huge amounts of structure, which,
nevertheless, the stochastic version has.  In fact these two areas may
be connected, by considering discrete and finite subgroups of these
flow and turning the diffusion into a discrete Markov process.
