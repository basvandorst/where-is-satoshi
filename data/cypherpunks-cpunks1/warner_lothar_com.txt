
@_date: 2009-09-17 01:23:11
@_author: Brian Warner 
@_subject: [tahoe-dev] Bringing Tahoe ideas to HTTP 
To be specific, the itch that I was looking to scratch was the
authentication of Firefox updates. In some slides from the last
BlackHat, I was dismayed to learn that the firefox update process
depends utterly upon SSL and the assorted Certificate Authorities to
validate https URLs that land on a mozilla.org server. The actual update
bundles that are fetched from those https URLs are not validated at all.
This causes two problems. The first is that any failure of the SSL or CA
path will allow an attacker to subvert the update process and take over
the browser. The slides I looked through showed one easy attack (the
ASN.1 pascal-vs-C-string bug) which has since been fixed. But we've seen
lots of failures at this level, and there are dozens of CAs in the TCB:
a compromise of any one of them would break everything (some are still
using MD5). Since firefox checks in daily to find out about new updates,
there are lots of opportunities to mount this attack.
The second is that it limits Mozilla's mirroring possibilities. I think
that they currently have to hand out private keys to their mirrors,
something like a cert that designates the server as mirror1.mozilla.org,
so they must be very cautious about who runs each mirror. Their mirrors
must all be running SSL, and a compromise of any of those mirrors could
jeopardize the whole update path. I think that they could have far more
mirrors (and be better able to accomodate the tens of millions of
firefox users) if they didn't have this limitation.
Having an end-to-end method to validate the update bundles would fix
both of these problems. Updates could even be acquired via other means
(sneakernet, local mirror, etc) and validated by the browser
individually before unpacking+installation. Plugins could conceivably
used something similar, but I think the basic browser update path is a
valuable one that's easier to reason about.
doing something like what I want for firefox: the Sparkle-enabled
application will only accept update bundles which are signed by a DSA
privkey that matches a pubkey embedded in the app. It'd be nice if
Firefox could do the same. And if Firefox were to establish a
quietly-backwards-compatible convention (i.e. the hash-mark trick) for
strong URL-based authentication of HTTP resources, then other
applications could start using it too, and a significant class of
current web security problems (like the mixed-content one where an HTTPS
page loads a javascript library via HTTP) could be fixed.
 -Brian

@_date: 2011-01-31 13:18:16
@_author: Brian Warner 
@_subject: [tahoe-announce] Tahoe-LAFS-1.8.2 Released! 
ANNOUNCING Tahoe, the Least-Authority File System, v1.8.2
The Tahoe-LAFS team is pleased to announce the immediate
availability of version 1.8.2 of Tahoe-LAFS, an extremely
reliable distributed storage system. Get it here:
Tahoe-LAFS is the first distributed storage system to offer
"provider-independent security" b meaning that not even the
operators of your storage servers can read or alter your data
without your consent. Here is the one-page explanation of its
unique security and fault-tolerance properties:
The previous stable release of Tahoe-LAFS was v1.8.1, which was
released October 28, 2010 [1].
v1.8.2 is a stable bugfix release, adding compatibility with
the recently-released Twisted-10.2, and correcting a number of
minor issues. See the NEWS file [2] for details.
WHAT IS IT GOOD FOR?
With Tahoe-LAFS, you distribute your filesystem across
multiple servers, and even if some of the servers fail or are
taken over by an attacker, the entire filesystem continues to
work correctly, and continues to preserve your privacy and
security. You can easily share specific files and directories
with other people.
In addition to the core storage system itself, volunteers
have built other projects on top of Tahoe-LAFS and have
integrated Tahoe-LAFS with existing systems, including
Windows, JavaScript, iPhone, Android, Hadoop, Flume, Django,
Puppet, bzr, mercurial, perforce, duplicity, TiddlyWiki, and
more. See the Related Projects page on the wiki [3].
We believe that strong cryptography, Free and Open Source
Software, erasure coding, and principled engineering practices
make Tahoe-LAFS safer than RAID, removable drive, tape,
on-line backup or cloud storage.
This software is developed under test-driven development, and
there are no known bugs or security flaws which would
compromise confidentiality or data integrity under recommended
use. (For all important issues that we are currently aware of
please see the known_issues.rst file [4].)
This release is compatible with the version 1 series of
Tahoe-LAFS. Clients from this release can write files and
directories in the format used by clients of all versions back
to v1.0 (which was released March 25, 2008). Clients from this
release can read files and directories produced by clients of
all versions since v1.0. Servers from this release can serve
clients of all versions back to v1.0 and clients from this
release can use servers of all versions back to v1.0.
This is the thirteenth release in the version 1 series. This
series of Tahoe-LAFS will be actively supported and maintained
for the forseeable future, and future versions of Tahoe-LAFS
will retain the ability to read and write files compatible
with this series.
You may use this package under the GNU General Public License,
version 2 or, at your option, any later version. See the file
"COPYING.GPL" [5] for the terms of the GNU General Public
License, version 2.
You may use this package under the Transitive Grace Period
Public Licence, version 1 or, at your option, any later
version. (The Transitive Grace Period Public Licence has
requirements similar to the GPL except that it allows you to
delay for up to twelve months after you redistribute a derived
work before releasing the source code of your derived work.)
See the file "COPYING.TGPPL.html" [6] for the terms of the
Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either
licence, at your option.)
Tahoe-LAFS works on Linux, Mac OS X, Windows, Cygwin, Solaris,
*BSD, and probably most other systems. Start with
"docs/quickstart.html" [7].
HACKING AND COMMUNITY
Please join us on the mailing list [8]. Patches are gratefully
accepted -- the RoadMap page [9] shows the next improvements
that we plan to make and CREDITS [10] lists the names of people
who've contributed to the project. The Dev page [11] contains
resources for hackers.
Tahoe-LAFS was originally developed by Allmydata, Inc., a
provider of commercial backup services. After discontinuing
funding of Tahoe-LAFS R&D in early 2009, they continued
to provide servers, bandwidth, small personal gifts as tokens
of appreciation, and bug reports.
Google, Inc. sponsored Tahoe-LAFS development as part of the
Google Summer of Code 2010. They awarded four sponsorships to
students from around the world to hack on Tahoe-LAFS that
Thank you to Allmydata and Google for their generous and
public-spirited support.
HACK TAHOE-LAFS!
If you can find a security flaw in Tahoe-LAFS which is serious
enough that we feel compelled to warn our users and issue a fix,
then we will award you with a customized t-shirts with your
exploit printed on it and add you to the "Hack Tahoe-LAFS Hall
Of Fame" [12].
This is the seventh release of Tahoe-LAFS to be created solely
as a labor of love by volunteers. Thank you very much to the
team of "hackers in the public interest" who make Tahoe-LAFS
Brian Warner
on behalf of the Tahoe-LAFS team
January 30, 2011
San Francisco, California, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] tahoe-announce mailing list
tahoe-announce at tahoe-lafs.org

@_date: 2011-10-30 22:59:58
@_author: Brian Warner 
@_subject: [p2p-hackers] ANN: Tahoe-LAFS 1.9 Released! 
ANNOUNCING Tahoe, the Least-Authority File System, v1.9.0
The Tahoe-LAFS team is pleased to announce the immediate
availability of version 1.9.0 of Tahoe-LAFS, an extremely
reliable distributed storage system. Get it here:
Tahoe-LAFS is the first distributed storage system to offer
"provider-independent security" b meaning that not even the
operators of your storage servers can read or alter your data
without your consent. Here is the one-page explanation of its
unique security and fault-tolerance properties:
The previous stable release of Tahoe-LAFS was v1.8.3, which was
released September 13, 2011.
v1.9.0 offers a new mutable-file format (more efficient for
large files), a file-blacklisting feature, and a new
"drop-upload" feature. See the NEWS file [3] and
known_issues.rst [4] file for details.
WHAT IS IT GOOD FOR?
With Tahoe-LAFS, you distribute your filesystem across
multiple servers, and even if some of the servers fail or are
taken over by an attacker, the entire filesystem continues to
work correctly, and continues to preserve your privacy and
security. You can easily share specific files and directories
with other people.
In addition to the core storage system itself, volunteers
have built other projects on top of Tahoe-LAFS and have
integrated Tahoe-LAFS with existing systems, including
Windows, JavaScript, iPhone, Android, Hadoop, Flume, Django,
Puppet, bzr, mercurial, perforce, duplicity, TiddlyWiki, and
more. See the Related Projects page on the wiki [5].
We believe that strong cryptography, Free and Open Source
Software, erasure coding, and principled engineering practices
make Tahoe-LAFS safer than RAID, removable drive, tape,
on-line backup or cloud storage.
This software is developed under test-driven development, and
there are no known bugs or security flaws which would
compromise confidentiality or data integrity under recommended
use. (For all important issues that we are currently aware of
please see the known_issues.rst file [2].)
This release is compatible with the version 1 series of
Tahoe-LAFS. Clients from this release can write files and
directories in the format used by clients of all versions back
to v1.0 (which was released March 25, 2008). Clients from this
release can read files and directories produced by clients of
all versions since v1.0. Servers from this release can serve
clients of all versions back to v1.0 and clients from this
release can use servers of all versions back to v1.0.
This is the fifteenth release in the version 1 series. This
series of Tahoe-LAFS will be actively supported and maintained
for the foreseeable future, and future versions of Tahoe-LAFS
will retain the ability to read and write files compatible
with this series.
You may use this package under the GNU General Public License,
version 2 or, at your option, any later version. See the file
"COPYING.GPL" [4] for the terms of the GNU General Public
License, version 2.
You may use this package under the Transitive Grace Period
Public Licence, version 1 or, at your option, any later
version. (The Transitive Grace Period Public Licence has
requirements similar to the GPL except that it allows you to
delay for up to twelve months after you redistribute a derived
work before releasing the source code of your derived work.)
See the file "COPYING.TGPPL.rst" [5] for the terms of the
Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either
licence, at your option.)
Tahoe-LAFS works on Linux, Mac OS X, Windows, Solaris, *BSD,
and probably most other systems. Start with
"docs/quickstart.rst" [6].
HACKING AND COMMUNITY
Please join us on the mailing list [7]. Patches are gratefully
accepted -- the RoadMap page [8] shows the next improvements
that we plan to make and CREDITS [9] lists the names of people
who've contributed to the project. The Dev page [10] contains
resources for hackers.
Atlas Networks has contributed several hosted servers for
performance testing. Thank you to Atlas Networks [11] for
their generous and public-spirited support.
And a special thanks to Least Authority Enterprises [12],
which employs several Tahoe-LAFS developers, for their
continued support.
HACK TAHOE-LAFS!
If you can find a security flaw in Tahoe-LAFS which is serious
enough that we feel compelled to warn our users and issue a fix,
then we will award you with a customized t-shirts with your
exploit printed on it and add you to the "Hack Tahoe-LAFS Hall
Of Fame" [13].
This is the ninth release of Tahoe-LAFS to be created solely
as a labor of love by volunteers. Thank you very much to the
team of "hackers in the public interest" who make Tahoe-LAFS
Brian Warner
on behalf of the Tahoe-LAFS team
October 31, 2011
San Francisco, California, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] p2p-hackers mailing list
p2p-hackers at lists.zooko.com

@_date: 2011-10-30 22:59:58
@_author: Brian Warner 
@_subject: [tahoe-announce] ANN: Tahoe-LAFS 1.9 Released! 
ANNOUNCING Tahoe, the Least-Authority File System, v1.9.0
The Tahoe-LAFS team is pleased to announce the immediate
availability of version 1.9.0 of Tahoe-LAFS, an extremely
reliable distributed storage system. Get it here:
Tahoe-LAFS is the first distributed storage system to offer
"provider-independent security" b meaning that not even the
operators of your storage servers can read or alter your data
without your consent. Here is the one-page explanation of its
unique security and fault-tolerance properties:
The previous stable release of Tahoe-LAFS was v1.8.3, which was
released September 13, 2011.
v1.9.0 offers a new mutable-file format (more efficient for
large files), a file-blacklisting feature, and a new
"drop-upload" feature. See the NEWS file [3] and
known_issues.rst [4] file for details.
WHAT IS IT GOOD FOR?
With Tahoe-LAFS, you distribute your filesystem across
multiple servers, and even if some of the servers fail or are
taken over by an attacker, the entire filesystem continues to
work correctly, and continues to preserve your privacy and
security. You can easily share specific files and directories
with other people.
In addition to the core storage system itself, volunteers
have built other projects on top of Tahoe-LAFS and have
integrated Tahoe-LAFS with existing systems, including
Windows, JavaScript, iPhone, Android, Hadoop, Flume, Django,
Puppet, bzr, mercurial, perforce, duplicity, TiddlyWiki, and
more. See the Related Projects page on the wiki [5].
We believe that strong cryptography, Free and Open Source
Software, erasure coding, and principled engineering practices
make Tahoe-LAFS safer than RAID, removable drive, tape,
on-line backup or cloud storage.
This software is developed under test-driven development, and
there are no known bugs or security flaws which would
compromise confidentiality or data integrity under recommended
use. (For all important issues that we are currently aware of
please see the known_issues.rst file [2].)
This release is compatible with the version 1 series of
Tahoe-LAFS. Clients from this release can write files and
directories in the format used by clients of all versions back
to v1.0 (which was released March 25, 2008). Clients from this
release can read files and directories produced by clients of
all versions since v1.0. Servers from this release can serve
clients of all versions back to v1.0 and clients from this
release can use servers of all versions back to v1.0.
This is the fifteenth release in the version 1 series. This
series of Tahoe-LAFS will be actively supported and maintained
for the foreseeable future, and future versions of Tahoe-LAFS
will retain the ability to read and write files compatible
with this series.
You may use this package under the GNU General Public License,
version 2 or, at your option, any later version. See the file
"COPYING.GPL" [4] for the terms of the GNU General Public
License, version 2.
You may use this package under the Transitive Grace Period
Public Licence, version 1 or, at your option, any later
version. (The Transitive Grace Period Public Licence has
requirements similar to the GPL except that it allows you to
delay for up to twelve months after you redistribute a derived
work before releasing the source code of your derived work.)
See the file "COPYING.TGPPL.rst" [5] for the terms of the
Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either
licence, at your option.)
Tahoe-LAFS works on Linux, Mac OS X, Windows, Solaris, *BSD,
and probably most other systems. Start with
"docs/quickstart.rst" [6].
HACKING AND COMMUNITY
Please join us on the mailing list [7]. Patches are gratefully
accepted -- the RoadMap page [8] shows the next improvements
that we plan to make and CREDITS [9] lists the names of people
who've contributed to the project. The Dev page [10] contains
resources for hackers.
Atlas Networks has contributed several hosted servers for
performance testing. Thank you to Atlas Networks [11] for
their generous and public-spirited support.
And a special thanks to Least Authority Enterprises [12],
which employs several Tahoe-LAFS developers, for their
continued support.
HACK TAHOE-LAFS!
If you can find a security flaw in Tahoe-LAFS which is serious
enough that we feel compelled to warn our users and issue a fix,
then we will award you with a customized t-shirts with your
exploit printed on it and add you to the "Hack Tahoe-LAFS Hall
Of Fame" [13].
This is the ninth release of Tahoe-LAFS to be created solely
as a labor of love by volunteers. Thank you very much to the
team of "hackers in the public interest" who make Tahoe-LAFS
Brian Warner
on behalf of the Tahoe-LAFS team
October 31, 2011
San Francisco, California, USA
[1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] tahoe-announce mailing list
tahoe-announce at tahoe-lafs.org

@_date: 2012-12-20 09:36:20
@_author: Brian 
@_subject: [tahoe-dev] Weekly Dev notes, 20-Dec-2012 
It's our last weekly chat of the year! Here are some notes:
in attendance: Zooko (scribe), Marlowe, freddyb, amiller, David-Sarah,
Warner (late)
* translation: Rana from the Tor project walked Marlowe through
    workflow; Their git repo is checked by transifex. Transifex git
    pulls their repo. The one thing we have to do manually is that
    transifex has no way to check for malicious coding added in
    translations, like XSS/injection-style attacks. Transifex maintains
    a glossary of "one-offs", words that appear. voulnet does
    translations for Guardian Project and Tor and would be interested in
    doing Tahoe-LAFS as well.
* Tenerife, Blake2
* ticket notes:
     land them!
   probably ready to land
   if tests can be made to pass, land it!
   trivial, let's land it. If DS doesn't land by this weekend,
         warner will.
   DS will poke at it, else warner will try to fix
   warner will try to write a test, test_client.NodeMaker
   DS will consider 166-3.diff, if no objections by this weekend,
        warner will land. The -d issue can be figured out for 1.11
   warner will try to write a patch this weekend
   warner will write the patch
   warner will review and land
   warner will land
  rest of 1.10 tickets: can be landed if simple, else kick out to 1.11
* 1.10: warner will make a push this weekend and over holidays. Goal is
        to get a 1.10-alpha1 out by xmas, then aim for 1.10-final by
        late January.
* leasedb
  * warner still needs to review davidsarah/1818-leasedb
  * we still need to implement starter-lease code before landing
    1818-leasedb, probably in january
  * DS will rebase 1819-cloud-merge on top of 1818-leasedb
  * DS decided to stick with separate SI,shnum columns instead of a
    single merged shareid column: sqlite accepts foreign keys and unique
    keys and handles primary keys well enough that quota-measuring
    queries (finding unique lists of shares owned by a given account)
    are simple, or at least they can't be simplified enough to justify
    the denormalization hit
  * DS will consider adding the additional leasedb state-transitions to
    the docs (COMING->GONE when the upload process is interrupted before
    the backend creates any part of the share object, STABLE->GONE when
    the shares are deleted out-of-band, GOING->GONE when the share
    deletion process is interrupted but completes anyways), even before
    those transitions are actually implemented.
There will be no dev call next week on 27-Dec-2012. We'll meet again
happy holidays!
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-01-12 15:33:10
@_author: Brian Warner 
@_subject: [tahoe-announce] ANN: Tahoe-LAFS 1.9.1 Released! 
ANNOUNCING Tahoe, the Least-Authority File System, v1.9.1
The Tahoe-LAFS team has announced the immediate availability of
version 1.9.1 of Tahoe-LAFS, an extremely reliable distributed
storage system. Get it here:
Tahoe-LAFS is the first distributed storage system to offer
"provider-independent security" b meaning that not even the
operators of your storage servers can read or alter your data
without your consent. Here is the one-page explanation of its
unique security and fault-tolerance properties:
The previous stable release of Tahoe-LAFS was v1.9.0, released
on October 31, 2011.
v1.9.1 is a critical bugfix release which fixes a significant
security issue [ See the NEWS file [1] and known_issues.rst
[2] file for details.
WHAT IS IT GOOD FOR?
With Tahoe-LAFS, you distribute your filesystem across
multiple servers, and even if some of the servers fail or are
taken over by an attacker, the entire filesystem continues to
work correctly, and continues to preserve your privacy and
security. You can easily share specific files and directories
with other people.
In addition to the core storage system itself, volunteers
have built other projects on top of Tahoe-LAFS and have
integrated Tahoe-LAFS with existing systems, including
Windows, JavaScript, iPhone, Android, Hadoop, Flume, Django,
Puppet, bzr, mercurial, perforce, duplicity, TiddlyWiki, and
more. See the Related Projects page on the wiki [3].
We believe that strong cryptography, Free and Open Source
Software, erasure coding, and principled engineering practices
make Tahoe-LAFS safer than RAID, removable drive, tape,
on-line backup or cloud storage.
This software is developed under test-driven development, and
there are no known bugs or security flaws which would
compromise confidentiality or data integrity under recommended
use. (For all important issues that we are currently aware of
please see the known_issues.rst file [2].)
This release is compatible with the version 1 series of
Tahoe-LAFS. Clients from this release can write files and
directories in the format used by clients of all versions back
to v1.0 (which was released March 25, 2008). Clients from this
release can read files and directories produced by clients of
all versions since v1.0. Servers from this release can serve
clients of all versions back to v1.0 and clients from this
release can use servers of all versions back to v1.0.
This is the sixteenth release in the version 1 series. This
series of Tahoe-LAFS will be actively supported and maintained
for the foreseeable future, and future versions of Tahoe-LAFS
will retain the ability to read and write files compatible
with this series.
You may use this package under the GNU General Public License,
version 2 or, at your option, any later version. See the file
"COPYING.GPL" [4] for the terms of the GNU General Public
License, version 2.
You may use this package under the Transitive Grace Period
Public Licence, version 1 or, at your option, any later
version. (The Transitive Grace Period Public Licence has
requirements similar to the GPL except that it allows you to
delay for up to twelve months after you redistribute a derived
work before releasing the source code of your derived work.)
See the file "COPYING.TGPPL.rst" [5] for the terms of the
Transitive Grace Period Public Licence, version 1.
(You may choose to use this package under the terms of either
licence, at your option.)
Tahoe-LAFS works on Linux, Mac OS X, Windows, Solaris, *BSD,
and probably most other systems. Start with
"docs/quickstart.rst" [6].
HACKING AND COMMUNITY
Please join us on the mailing list [7]. Patches are gratefully
accepted -- the RoadMap page [8] shows the next improvements
that we plan to make and CREDITS [9] lists the names of people
who've contributed to the project. The Dev page [10] contains
resources for hackers.
Atlas Networks has contributed several hosted servers for
performance testing. Thank you to Atlas Networks [11] for
their generous and public-spirited support.
And a special thanks to Least Authority Enterprises [12],
which employs several Tahoe-LAFS developers, for their
continued support.
HACK TAHOE-LAFS!
If you can find a security flaw in Tahoe-LAFS which is serious
enough that we feel compelled to warn our users and issue a fix,
then we will award you with a customized t-shirts with your
exploit printed on it and add you to the "Hack Tahoe-LAFS Hall
Of Fame" [13].
This is the tenth release of Tahoe-LAFS to be created solely
as a labor of love by volunteers. Thank you very much to the
team of "hackers in the public interest" who make Tahoe-LAFS
Brian Warner
on behalf of the Tahoe-LAFS team
January 12, 2011
San Francisco, California, USA
[ [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] tahoe-announce mailing list
tahoe-announce at tahoe-lafs.org

@_date: 2012-07-01 17:51:30
@_author: Brian 
@_subject: [tahoe-dev] switching from introducers to gossip? 
Yeah, the general idea is that all nodes provide the "grid-control"
service, in addition to the "storage" service they might be providing
right now. Nodes announce both "grid-control" and "storage" via the same
introducer Announcements as before. The old Introducer becomes a node
that only provides "grid-control", on a pre-published FURL.
"grid-control" lets you publish Announcements (either your own or ones
you're forwarding from others), and subscribe to the same.
Once that is in place, and we have some code to prevent infinite
flooding loops, there are several different approaches you could take:
* fully-connected mesh: every node makes a Foolscap connection to every
  grid-control provider they hear about, subscribe to hear about all
  announcements, and publish any announcements that the other side
  doesn't already know about.
* opportunistic: clients only connect to storage servers, and storage
  servers don't make outbound connections to anybody, but if you *do*
  happen to be connected to someone who also offers "grid-control", then
  connect to their grid-control object too and exchange Announcements
* cluster-of-Introducers: normal nodes don't offer grid-control, but
  multiple Introducers do, and all of them know about each other. All
  nodes connect to all grid-control providers (which means all
  Introducers).
* one Introducer: this is just a degenerate cluster-of-Introducers
I think we can probably accomodate that. I'm optimizing for our two main
use cases: friendnet and paid-service.
In the friendnet, nearly all nodes are both a client *and* a server.
Client-only nodes (like the one I occasionally connect to VG2 to
investigate bug reports), or server-only nodes (imagine a paid storage
server, the "rent-a-friend" idea I've talked about before) are rare. So
ruling out C->C or S->S connections doesn't change very much.
In the paid-service case (allmydata), we don't want clients talking to
each other (they're all behind NAT anyways). But we could allow S->S
connections without problems, and if all servers know about all other
servers, then we could add new servers to the grid by just connecting
them to at least one existing server, and knowledge of them would flood
quickly and reliably to everyone else.
Note that we don't need active+online connections to all other nodes all
the time. Connecting with less than 100% duty cycle would still get the
information distributed eventually. What I'm really expecting is that
we'll use Zooko's clever log-scaling flooding techniques (from Mnet) to
limit the amount of traffic and connections but still achieve
rapid+reliable diffusion of knowledge.
They aren't interdependent, for sure. Now that  is in trunk, we've
got a handle on Announcements (i.e. the node key that signs each one) so
recipients can make decisions about whether they'll accept the thing
being introduced or not, independently of the channel by which they
received the announcement. *That* is important to unlock alternate
introduction topologies: without signed announcements, the only form of
grid control you can get is to limit who gets access to the Introducer
(as the VG2 folks accomplish by changing the introducer.furl each time
it is accidentally leaked). But with signed announcements, you don't
need control over the channel to retain control over which servers your
client uses, or over which clients your server will serve. You could
even safely use a single massive universe-spanning broadcast channel, if
you could make it efficient enough.
And the first steps of Accounting don't require changes to introduction
at all. These steps will enable tracking of who-uses-what, and manual
control (probably by pasting nodeids into tahoe.cfg) over both
which-servers-should-I-use and which-clients-should-I-accept. This needs
signed announcements (to get a strong nodeid of a server) and signed
accounting-facet-of-storage-server FURLification messages (so clients
can demonstrate control of a key). The main question is whether nodes
which are both clients and servers should have a single key, or two
separate keys (I prefer a single key, because it makes reciprocal
storage-permission grants easier).
The second steps of Accounting, where we try to make things easy and
automatic for our common use cases, is where we start getting into my
Invitation scheme, and is where gossip becomes more interesting. What I
really want is to make it super-easy for a new user to get their node
running and connected to their friend's existing grid. And, more
importantly, for that *first* friend to set up that grid.
Imagine for a moment that we have a nicely-packaged OS-X or debian app,
already distributed via the mac App Store or through apt/etc. And also
imagine that we've got uPnP working (or something equivalent, maybe
involving a relay or some helper service that we run), so NAT isn't a
problem. Then this is my goal:
  The first friend (Alice) hears about Tahoe from her favorite blog, and
  installs it with her favorite package manager. She lauches it for the
  first time, and it asks "start your own grid, or join someone
  else's?", and she picks "start your own". Her node starts up,
  establishes an external IP address, sets itself up to restart at
  reboot, and announces that Alice is now the proud member of a 1-node
  grid, and that she should invite a few friends to join before she'll
  get more than educational value out of the system. She hits the
  "Invite A Friend" button, types Bob's (pet)name and email address into
  the box, and the node sends Bob a message with links to the
  application, instructions, and an invitation code.
  Bob gets Alice's email, downloads+installs the app, and pastes in the
  invitation code. The next thing he sees is a picture of the two-node
  grid, with the Alice and Bob nodes labeled, and he can upload files
  and either retrieve them locally or share them with Alice.
  Later, Alice and Bob invite other people to join in their grid. The
  only grid-specific coordinates that each new member needs is a
  single-use invitation code like "d77hbsmkgeufjpwacu3ywkbwem".
  Eventually, Alice leaves the grid, but her departure doesn't affect
  the remaining members: they can still connect and exchange shares as
  usual.
  All grid members get a control panel where they can see who else is
  using their storage, allow/deny access, and control where their own
  node places shares. By default, anyone who gets invited to join the
  grid gets full access to storage on all members' servers, but access
  can be revoked at any time.
The corresponding story with an AllMyData-like paid-service is:
  Alice visits allmydata.com, signs up for the service with a credit
  card, downloads the client app and gets an invitation code for her
  account. She pastes the invitation code into the "accept an
  invitation" box when her app starts up.
  Her app connects to all AllMyData storage servers and is allowed
  storage access. New servers can be added without Alice's involvement.
  Any subset of the servers can go away without affecting her ability to
  connect to (or learn about) the rest.
To support those stories, I don't want Alice (or AllMyData) to be
running a single Introducer, or even a cluster of Introducers. Alice,
Bob, and the other members of the friendnet should *all* be helping each
other connect to the rest of their grid.. otherwise they have to pay
attention to how many Introducers are present, and who's responsible for
them, and make sure there are enough left available to accomodate
Does that help explain my interest in gossip-based introduction?
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-07-01 19:45:00
@_author: Brian 
@_subject: [tahoe-dev] switching from introducers to gossip? 
That's doable (it's basically what the  Google Summer of Code project
produced), and it would be more robust than the current
one-lone-Introducer (and we need the "union of announcements" feature in
any case). But it wouldn't decrease the administrative burden.. in fact
it would be worse than a single introducer.
Imagine a grid that has two Introducers and everybody knows about both
of them (I1 and I2). Now the operator of one (I1) of them announces that
they're going to retire it, so somebody (I3) else volunteers to add a
replacement. We'll start with I1+I2, then have I1+I2+I3, then finish
with I2+I3.
With the  -style "introducer.furls", after the volunteer spins
up I3, everybody in the entire grid has to edit their configs to add
I3's new FURL.
With gossip, the volunteer adds I3 and then they're done. Everyone else
learns about I3 from I1/I2, then remembers I3, and connects to it even
though I1 is gone.
If you generalize this, then all nodes can function as introducers, and
there's no need for dedicated Introducer nodes. As long as at least one
node with a public IP is up at any given time, everybody else can learn
the current state of the world.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-07-03 09:36:28
@_author: Brian 
@_subject: [tahoe-dev] switching from introducers to gossip? 
Ah, that's an excellent data point. Thanks! Yeah, multi-introducers are
a bit like RAID: you have more time to respond to a failure before the
whole system starts having problems.
Yeah, I think the worst-case attack is a DoS, where somebody floods
useless information into the system. The key is the signed
announcements: you may hear about all sorts of garbage, but you'll only
pay attention to announcements that are signed by someone you've
Invited, or who Invited you, or to whom you're transitively connected by
Ideally we can use that same criteria to limit how Announcements are
flooded, so unrecognized garbage (i.e. "a stranger") doesn't travel
further than a single node.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-06-12 23:34:45
@_author: Brian Warner 
@_subject: [tahoe-dev] verification of subset of file == proof of 
Well, we've never implemented a POR because we've never really wanted
one. "Proof-of-retrievability" is achieved by just retrieving the data.
What the cryptography literature calls proof-of-retention (or
-retrievability, -data-posession, or -ownership) gives you is a way to
*cheaply* (i.e. using less storage and bandwidth than the whole file)
assert that some remote server still has the data they claimed to have,
and haven't found some clever (i.e. cheaper) way to just pass the test
without really holding the whole file.
There's a number of protocols already out there. In general the verifier
can assert that either the server is holding the full original file, or
a collection of calculated verification data that is at least as large
as the original file (so if they want to pass the test, they might as
well be honest).  is one
The simplest way to do this, however, is for the verifier to hold the
whole file too. When we've discussed this in the Tahoe "one grid to rule
them all" context, we've talked about "share buddies": two
non-collaborating servers, each purportedly holding a copy of the same
share. They check up on each other by asking for keyed hashes of random
sections of the share (or the whole thing, if they're willing to spend
the disk IO on it). The idea was part of a larger server-driven-repair
thing we were thinking of: servers check up on the files they're helping
to store, and if they notice problems, they can trigger repair all by
themselves. Distributed reputation measurements are involved too:
servers can boost their reputation by delivering POR proofs on a timely
basis, and share-buddies can vouch for each other.
Anyways, it's sort of a neat idea, but we probably need some more
extensive accounting / server-reputation frameworks in place before
it'll be super useful in the Tahoe context.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-06-13 13:00:02
@_author: Brian Warner 
@_subject: [tahoe-dev] Resurrecting Mojo Nation 
Great question!
So, I wasn't at Mojo Nation (I was fascinated by the concept in 97 or 99
or whenever it made a splash, but never worked there, and only joined
its descendant AllMyData in 2005, many years after MN ran aground). But
my understanding was that many of the following contributed to its
* overly ambitious scope, would have required an impossibly good
  engineering and management team to implement everything
* too much science needed inventing to make it work
* real markets require diverse motivated players. MN users didn't bother
  tweaking agent behaviors, so you didn't get diversity. Users were
  accidentally encouraged to hoard Mojo (the client displayed your
  balance like a game score, users sought to maximize that number more
  than actually using it), so motivations were broken.
* nodes were transient, so reliability was unpredictable
For Tahoe, we reduced the scope, threw out the economic games, and
narrowed the use-case to commercial grids and friendnets (where uptime
is more predictable). Bittorrent did the same, reducing the scope to
short-term transfers instead of long-term storage. Both have achieved
their own smaller goals.
I think Mojo Nation is still a promising idea, and I think it's got a
better chance of working today than 15 years ago. Many of the challenges
are still there, but yeah, some of them are easier to address:
* overambition is still a big problem. Personally I'm trying to build
  Tahoe up to the point where we can re-introduce MN ideas, but it'll be
  a long road. Strive to break it into smaller pieces, make sure you can
  tolerate missing parts (if you fail to make progress on component A,
  are components B and C still usable?), develop some plausible
  use-cases first, start with the simplest thing that could possibly
  work, let the UI and user feedback drive the design
* Bitcoin makes automated payment easier, for the tiny fraction of the
  world that is willing to use it, but it's probably the right way to
  go, and removes a big centralized engineering hassle (the MN bank). We
  need some better/safer wallet-control protocols (you want your storage
  node to have control over some small stash of BTC, and most of the
  bitcoin clients I've seen are aimed at human-scale transactions), like
  Purses in the Waterken/E/SES examples, but that's just engineering. I
  think MN's extend-pairwise-credit amortization is still important,
  since even with BTC's reduced friction (transaction fees) you don't
  want to be shuffling pennies every few minutes.
* measuring/predicting reliability of storage nodes is still an unsolved
  (and possibly unsolveable) problem. You need servers to stick around
  for a long period of time, otherwise repair costs will swamp your
  bandwidth and leave you no room for real traffic. Needing long-term
  servers interacts badly with adoption (you want to encourage
  experimentation, folks who want to install it just to play around with
  it should be able to do that quickly, but you can't afford to use them
  as servers, since many of them will get bored and delete it or let it
  break the next day, so they don't really get the full experience, so
  they may not really be motivated to stick around). As a client you
  need to distinguish between good servers and transient ones, so you
  really want everyone to monitor and publish uptime data on each other,
  but they could be lying, which gets you back into the reputation graph
  thing. There's been a lot of work on reputation graphs (starting with
  Raph Levien's Advogato, and motivated by EBay and Amazon), but I don't
  know how much of it is buried in proprietary/closed codebases (since
  it's easier to game a system when you have the source) vs being
  available as an off-the-shelf library.
* disk capacity and broadband speeds are faster. Unfortunately people
  are creating more data than ever, and disk speeds (seek times) are
  pretty flat. One metric is how long it takes to read out the full
  contents of a disk, or how long it takes to copy a disk over your
  internet connection: both numbers are kind of sobering (usually
  measured in days or months). Home internet connections remain very
  asymmetric, upload speeds are lousy. Disk prices are dropping, so
  distributed storage has to compete with cheaper local storage, which
  can be a hard sell.
* do people really want remote storage? Why? One reason is to get access
  from their data from elsewhere (sharing with friends, using it from
  someone else's computer, publishing to the world). Another reason is
  for backup. Both are handled pretty well by centralized solutions,
  especially when that solution (e.g. Facebook, Flickr) comes with some
  nice integrated display/edit/discovery/search tools for the data. A
  distributed storage solution has to compete with the incumbents, and
  many of the benefits of Tahoe/MojoNation-style storage aren't
  compelling ("no SPOF" isn't exciting when Facebook never goes down,
  "private" is not something a lot of those folks want or care about,
  "cheap" is competing with free-as-in-eyeballs).
* backup is a question of inspiring confidence. Random servers run by
  strangers does not inspire confidence.
Anyways, I think it's still a fun idea, but still big and difficult. I'd
love to see someone charge ahead on it, but as a business I'd still
consider it pretty risky.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-06-13 13:26:20
@_author: Brian Warner 
@_subject: [tahoe-dev] Resurrecting Mojo Nation 
Oh, one other thought: another challenge of Mojo Nation was that each
file involved hundreds or thousands of backend blocks, and the overhead
of finding/tracking/downloading all of them was pretty bad. If I
remember right, the blocks came in fixed sizes (powers of two, up to
maybe 1MB), and each included a little bit of data about all segments of
the file (to avoid the "chunking" reliability problem). The result was
high alacrity (you had to download the whole file before any part of it
became readable, so no streaming) and really bad disk IO patterns on
both upload and download.
The very first simplification we made in the Tahoe design process was to
use a small number (N=10) of variable-sized shares
(sharesize=filesize/k), and to locate those shares algorithmically (both
to decide where to put them, and to find them again during download).
That means fewer things to keep track of, and nobody trying to actually
keep track of them all the time.
In a more market-driven scheme, you need to be able to push shares to
cheap+reliable servers, find them again later, and also find the copies
that servers have bought from each other. Shares move around on you,
even when no clients are looking at them. That means more overhead:
instead of being able to determine offline (permuted ring) where shares
are likely to be, you have to actually ask everyone. To do this
efficiently requires log(N) DHT cleverness (where you don't actually ask
*everybody*), which allows some of them to lie (which they will, because
they don't want you to discover the competition's cheaper copies).
So the flexible share-placement required by a free storage market
probably comes at the cost of complexity and share-tracking overhead.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-03-06 19:23:39
@_author: Brian Warner 
@_subject: [tahoe-dev] Idea for a Publish/Subscribe Message System on 
Great idea! We've discussed this a bit in the past, in the context of
helping AllMyData users send files to each other, but never got around
to building most of it. (We did build a tinyurl-like service that
pointed at filecaps, with some Javascript in the frontend that acted
upon the link by inserting the filecap into your root directory, but it
was mostly out-of-band).
Our thought was to give each pair of users a pair of directories. Each
one would be an "inbox" for one of them and an "outbox" for the other.
You'd give your friend the writecap to your inbox, and they'd add things
to it. Then you'd read from it later. A user agent could notice when
something was added to the inbox and move it somewhere else (sort of
like maildir's new/ and cur/ directories), to keep the inbox tidy.
You could just use the file's filecap: those are unique. Or the
storage-index if you wanted to show someone else the directory listing
without revealing the filecaps.
The benefit of using a dircap to track them is that you could fetch your
messages from a different machine by just remembering the dircap,
instead of the whole list of URIs.
Twisted has a lot of SMTP functionality built-in, which would make it
easier to integrate into the Tahoe process, if that ended up being
You've read my  paper, right? It probably
won't surprise you that some of these ideas influenced Tahoe too.
As above, you can mostly avoid the need for append-caps by using
pairwise inbox/outbox directories.
* Giving Alice a one-inbox writecap allows her to cancel messages
  (deleting it before Bob has a chance to read it), but you could
  actually argue this is a feature
* For long-term storage, Bob might want to have a user agent (or a cron
  job) copy/move messages out of the inbox and into some archive
  directory where Alice can't delete them any longer
* it's clear where the message came from: Alice cannot write into the
  inbox that Bob has created for Carol
* append-only caps are, cryptographically speaking, really hard
Yeah, my problem with IM2k was always that storage of the message body
is not the important cost: as you pointed out, it's the recipient's
attention that really matters. In IM2k, or this scheme, you have to give
the recipient enough information about the message (typically the
subject line) to decide whether to download the rest. It'll take the
spammers at most an hour before every subject line is "Help I've been
mugged and lost my wallet", or "Hi sweetie", or "Important your account
has been suspended", and the recipient has to download every message (or
ignore them and suffer false-positives). Actually, I take it back, every
spam I get already has those subject lines :).
What you really need is to rate-limit attention-grabbing behavior that
comes from outside a "social contract". New connections (people who
learn about me out-of-band, from a conference or a blog post or on the
street) are only enabled by allowing strangers to consume your time, but
if you can require them to spend their time too, then you can keep
things to a comfortably civilized level. That rate-limiting could take
the form of CAPTCHA, or money (either a refundable bond or outright
payment), or proof of membership in some group, whatever fits your
You also want reciprocal access and easy third-party introductions to
reduce the barrier to natural human communication patterns, and you want
gradual revocation to discourage abuse by otherwise normal
correspondents (that uncle who keeps forwarding chain letters to you).
Append-only caps are possible but tricky: we've had them sketched out
for years. They need pubkey-encryption (which we don't currently have or
need in Tahoe), but that's not too hard. The biggest part is deciding
how much complexity we're willing to accept in exchange for reducing the
server-attacker's ability to selectively roll-back individual records.
There's a big fun multi-way tradeoff here. Zooko is keen on using
client-side storage to remember the most-recent state of the mutable
object (so they can reject attempts to roll it back). I keep fantasizing
about a per-share DAG of record dependencies to make it hard for N-1 of
the servers to convince you that a record has gone away. And there's a
funny lattice of caps (append+write+read, append-only, append-and-read,
write-only, read-only, verify) that need some thought. It gets even
weirder when you consider the failure modes: if each record is
erasure-coded, and you get 4 shares that show evidence of record A being
added, and 3 with record B added, but k=5 and neither is enough to
recover the new records.. what should a new record-appender do?
Adding revocation to append-only caps is more complicated, but not
horribly so. You'd keep a list of pubkeys (verifiying keys) in each
share, signed by a master key (which gets to add/revoke append-caps). It
adds an extra dimension of failure modes. The server needs to be more
aware of the share format (to enforce some of the writer restrictions,
to prevent simple availability-threatening graffiti), but that's the
case for irrevocable appendcaps too.
Bah (/me waves hands), that's what petnames are for :).
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-03-14 13:06:37
@_author: Brian Warner 
@_subject: [tahoe-dev] #466 (signed-introducer-announcements) landed! 
Thanks to Zooko's hard work in getting pycryptopp-0.6.0.(mumble)
released yesterday, I was finally able to land the signed-introducer code last night. What does this mean for users?
* tahoe now depends upon the new pycryptopp: next time you update,
  you'll need to do 'setup.py build' so it will pick up 0.6.0
* the first time your node wakes up with the new code, it will create a
  NODEDIR/private/server.privkey file, containing the new Ed25519
  private signing key. This is a binary file, not meant for copy/paste
  or human interaction.
* server IDs are changing. The old (foolscap-based) IDs look like
  "rkybwv7hpuwpnyqhwjz43v727orr7fqd". Once everything is upgraded, the
  Welcome page will show new server IDs that look like
  "v0-fcmgu663rdyshncihts4e45rtwjwvc7ebcrtlaiv345yyps667pq". (the old
  ones are a SHA1 hash of the tub's public SSL certificate, the new ones
  are an Ed25519 public verifying key)
Internally, this opens up the door for a bunch of stuff:
* Introducer announcements are now extensible dictionaries, instead of
  fixed-size tuples. This allows servers to cleanly advertise new
  services, and include additional metadata like how much space they
  have available. This will be used by the upcoming Accounting work to
  advertise an alternate storage-server object from which per-account
  connections can be obtained. * Announcements are signed, which means the Introducer doesn't get to
  modify the metadata, reducing its authority a little bit. This gets us
  one step closer to having a distributed introduction mechanism (the
  signed announcements can simply be flooded, without worrying about
  what the other nodes might do to them in transit). * Server nodes are known by their Ed25519 public verifying key, rather
  than by their Foolscap SSL TubID. This enables secure non-SSL
  messaging (sign a request instead of sending unsigned requests over a
  validated-SSL connection), so we can switch from Foolscap to e.g. HTTP
  for share transport, which should make the Tahoe protocol easier to
  port to other languages (Foolscap offers more features than we really
  need, and its need to check the SSL certificate is an implementation
  hassle). * Clients can securely reference a server by its pubkey, which will be
  the basis for explicit "which servers am I willing to use"
  configuration.  What about compatibility? All combinations of V1/V2 client/introducer
should work as expected:
* new (V2) clients can talk to old (V1) Introducers just fine: they'll
  detect the lack of V2 methods and talk down to the introducer (sending
  it unsigned V1-format tuples instead of signed V2-format
  dictionaries).
* old V1 clients can talk to new V2 introducers: they send announcements
  to the old method name, the Introducer will upgrade the tuples to
  dictionaries (unsigned, of course) for distribution to V2 clients, and
  distributes the original tuple to V1 clients
* new V2 Introducers can talk to old V1 clients just fine: the client
  will subscribe with the old V1 method, causing the Introducer to
  downgrade new-style announcements for the V1 client
* V1 clients always get tuples, V2 clients always get dictionaries.
  *Signed* announcements will only happen when all three participants
  (announcing client, Introducer, subscribing client) are V2.
What about serverid compatibility?
* over the last few months we've refactored the way clients use storage
  servers, to split their notion of "serverid" (aka "peerid") into
  several pieces. V2 announcements provide specific values for these
  different pieces, so that some can remain the same as before, while
  others are new. (this process is about 80% complete)
* "serverid" will be used to mean the Ed25519 pubkey (but some code
  still uses it to mean the tubid.. this will eventually be fixed). This
  is the servers's long-term secure identifier, suitable for   server designation. Old V1 nodes won't have serverids, so it won't be
  possible to securely reference a V1 node, so using  will depend
  upon upgraded servers and an upgraded Introducer.
* "name" is used to describe servers on the Welcome page, and is either
  the pubkey (if available) or the tubid. It is not secure, in the sense
  that it could be spoofed, and so shouldn't be used for   server designation.
* "permutation seed" is used by the server-selection algorithm. It is
  provided by the server (which can use anything it likes). Brand new V2
  servers use the ed25519 serverid. Old V1 servers use the foolscap
  tubid (i.e. when V1 tuples are upgraded by the Introducer to V2 dicts,
  it adds a "permutation-seed-base32" key derived from the tubid). V2
  servers which wake up with existing shares will use their tubid
  forevermore, since that probably means other clients have known them
  by the tubid, so they'll be expecting share placement based upon the
  old tubid. This allows backwards compatibility for old shares while
  allowing brand new empty servers to live in the future, not the past.
* "lease seed" is always the tubid, and continues to be used to generate
  the per-share per-server lease-renew/cancel secrets. To safely use a
  shared secret, you have to send that secret over a very specific
  channel, which means they're tied to a transport protocol and a
  verifiable endpoint. So they won't be usable in a post-Foolscap world
  anyways. The plan (as part of  is to replace shared-secrets with
  per-lease Ed25519 keypairs.
* "foolscap write enabler seed" is also the tubid, for exactly the same
  reasons. We'll need to replace both lease-management and mutable-file
  write-management before we can move from Foolscap to unencrypted HTTP.
Open questions:
* serverids currently include a short version marker: the "v0-" in
  "v0-fcmgu663rdyshncihts4e45rtwjwvc7ebcrtlaiv345yyps667pq". Does that
  get in the way of cut-and-paste? Would it be better to use something
  like "v0fcmgu663rdyshncihts4e45rtwjwvc7ebcrtlaiv345yyps667pq"? When we
  abbreviate these in places like the FileChecker results page (to
  identify specific servers), is there a way to get the v0- out of the
  abbreviated form? (maybe use a "-v0"/"v0" suffix? maybe define the
  abbreviated form to skip the prefix, so this example appears as just
  "fcmgu"?)
* are there places where I've missed the tubid-to-serverid transition? I
  spotted one just now, the "My nodeid" field on the welcome page.
* Next steps: push forward on the Accounting work, specifically looking
  for ways to display (to clients) which servers you're using, and then
  maybe to exert some control over that list. There are some UI
  questions to figure out: I can imagine managing this config with both
  tahoe.cfg (have a config key with a list of serverids) and via a web
  page (a  with enable/disable checkboxes), but the latter
  requires some web-security frameworking that we don't have in place
  yet (and might not want to rely upon anyways).
Let me know if you have an questions.. I imagine some of this is as
clear as mud.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-03-14 13:25:36
@_author: Brian Warner 
@_subject: [tahoe-dev] keeping private grids private 
Like Markus said, we're getting closer, but we aren't quite there yet.
The most important fix is to make the introducer.furl actually secret
(currently it's guessable by anyone who knows the tubid): ticket  is
related (but I can't find the actual ticket). Once fixed, then keeping
the introducer.furl from falling into those wrong hands will work. It
gives you a sort of secret-frat-party security system: anyone who's in
the club can invite anyone they like, and there's no way to kick someone
out (knowledge of the introducer.furl is irrevocable).
We don't want to add new security measures to the Introducer itself
(like giving it a list of "good" clients so it can ignore the rest),
because we want to get rid of the Introducer entirely. We want to
replace it with a distributed gossip-based system ( and you can't
rely on a bunch of gossiping nodes to enforce access-control policies.
So we're looking in different directions to provide the sort of control
you're looking for.
The next step is the explicit-server-selection work:  When that's
done, each client will be able to indicate which servers they want to
use, ignoring rogue servers. That will fix the availability problems
(servers connecting, accepting shares, then disappearing). The
configuration of this is still a matter of debate: one approach is to
list the pubkey of the servers you want to use, but that can be
labor-intensive for larger grids, and makes it hard to share files if
the uploader uses a different list than the downloader. Another approach
is to delegate membership to a "grid manager" of some sort: more moving
pieces but probably easier to use.
The step after that is part of Accounting ( in which servers
reject operations by unauthorized clients. This would include both
storage (leeching) and network bandwidth (downloading shares, running
deep-check, etc, but not basic DoS).
But for now, yeah, IP-address filtering is a good quick answer.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-03-17 12:54:21
@_author: Brian Warner 
@_subject: [tahoe-dev] several questions about tahoe backup 
Yeah, I'm really satrting to think that we need that RepairAgent that we
keep talking about: something inside the tahoe client node (or inside
the "Agent" that we discusses briefly at the last Summit) which can
manage a rate-limited asynchronous interruptable/restartable
check/repair/renew process. Doing it entirely from the command line is
too fragile: it basically implies that the whole process needs to
complete before 1: your CLI command gets killed, 2: the node gets
bounced, 3: the client's connections to the storage servers remain
The hard part about the RepairAgent has always been how to configure it.
But I'm starting to think that tahoe.cfg should just be able to list a
couple of aliases and a frequency (once/day, etc).
Backups use almost entirely immutable files and directories, and
immutable files are not vulnerable to collision problems. The only
mutable directory is the top-level one (which contains the timestamped
subdirectories and the "Latest" link). So the only potential danger is
that the "tahoe backup" is modifying that directory while the
"deep-check --repair" is repairing it.
It's hard to say what the chances are of bad things happening here. A
couple of thoughts:
 - "tahoe backup" modifies the top-level directory at the very end of
   the process, while "deep-check --repair" visits the top directory at
   the very beginning of the process. If you start both at the same
   time, they probably won't collide.
 - if the directory needed repairing, then the "tahoe backup"
   modify-directory operation will effectively repair it at the same
   time, perhaps reducing the chances that deepcheck--repair will try to
   repair it later
 - The chances of UCWE resulting in lost data depends upon the encoding
   parameters and how many simultaneous writers there are. With 3-of-10,
   assuming all shares are available, there'd have to be 5 simultaneous
   versions of the file before none of them are recoverable (two shares
   of version A, two of version B, two*C, two*D, two*E). Which
   theoretically means that one tahoe-backup writer, one repairer, and
   one previously-existing version should always result in at least one
   version being recoverable. But, this is highly dependent upon what
   sort of damage the repairer was trying to fix in the first place.
(incidentally deep-check without --repair is always safe: it doesn't
modify the shares at all)
Multiple deep-check --repair operations on the same directory runs the
same UCWE risk as multiple writers trying to modify a directory at the
same time: the danger is that each will successfully replace shares on
different servers at the same time, resulting in some old "A" shares,
some new "B" shares, and some new (different) "C" shares. Having a
variety of share versions reduces your recoverability margins.
We haven't ever tried to seriously model or test this. It would be
interesting to create a directory, set up multiple clients, have them
all repeatedly hammer away at it (making modifications) and measure how
many UCWEs they get, and when/if the file becomes unrecoverable. It'd
probably be a good idea to instrument the storage servers to send
details of how the shares are changing to a common logfile, so we could
reconstruct the process later.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-03-28 13:54:19
@_author: Brian Warner 
@_subject: [tahoe-dev] erasure coding makes files more fragile, not less 
That.. is a pretty broad and potentially disingenuous statement, and
feels unsupported. I think I know what you mean, but it's a bit like
saying "everybody dies" or "all programs crash eventually": maybe true,
but kinda useless, and kinda deceptive, or at least distracting.
[BTW folks: Zooko and I talk about this stuff all the time, and we know
each other's opinions pretty well, so please don't misinterpret my words
as indicating anger or annoyance. We're old pals, and this is a
well-worn comfortable argument.]
The metric that I'd find useful is what percentage of files *that people
actively tried to keep around* were lost. Tahoe is a system for
multiplying the durability of your servers, but it's not magic, and if
you start with lousy unmaintained servers, then you aren't likely to
have good results.
Ah, you do know how to provoke me :). That's like saying "seat belts,
airbags, and helmets kill people", invoking haunting images of demonic
safety gear stalking the last remaining humans through the forest,
seatbelts to snare, airbags to suffocate, and helmets to keep watch for
the desperate counterattack. Sometimes (I'm reminded of your alien
toaster example) you imply things like "we should outlaw seatbelts, and
mandate that car seats must be attached to the front bumper, so people
feel scared enough to drive slower", which, although it might reduce the
rate of car crashes, is not a workable solution.
And what I think you should mean instead is "seat belts certainly save
lives, but we should pay attention to whether people might be tempted to
drive faster because of the feeling-of-safety they provide, and think
about how to mitigate that".
That's the important part (if it's even true), and provocative
soundbites which omit it are delivering the wrong message.
You know, I'm not sure that's actually true. I have a feeling that any
folks who lose data in a Tahoe grid (and I'm not accepting that claim
yet: I haven't personally heard many examples of loss, although you talk
to more users than I do) would be just as likely to lose data in a RAID
array, or in a single-disk server. I.e. to study this properly, I'd want
to separate the user population into "careful sysadmins" and "casual
end-users", and examine failure rates (and experiences) in the two camps
Hrm, we've had this argument before and I'm never sure where to go it.
Yes, the math in our provisioning/reliability tool describes a somewhat
unrealistic model with the usual because-it-makes-the-math-easier
assumptions (Poisson processes, independent identically-distributed
failures). Should we get rid of it? No, I think it still has value.
Should we add some warning stickers that say "human error and
non-independent failure modes will probably limit how close you can get
to these numbers"? Sure. If people ignore those stickers and believe the
fairy-tale math and drive too fast and crash and burn, should we throw
out the math? No, I think the tools are still useful to people who
understand the limits of the model.
(ugh, just the way you phrase that claim makes it sound like Tahoe is a
fundamentally flawed technology and any file that comes into contact
with it catches the plague and falls deathly ill. How about "any
potential file loss in Tahoe must come about because of one of the
following:" instead?)
Wait wait, the details are somewhat correct but the conclusion is wrong
and the premise is off-base. Yes, k>1 on servers with <50% reliability
is worse than k=1 on those same servers: bad servers are bad, relying
upon more of them is worse. 3-of-10 on bad servers is worse than
1-of-10. But 1-of-10 is way better than 1-of-2 or 1-of-1. And 3-of-10 is
better than 3-of-3. 3-of-10 on good=25% servers has an 80.7% chance of
failure, nearly the same as 1-of-1's 75% chance of failure. 2-of-10 on
good=25% gets you a 24.4% chance of failure, way better than 75%, and
1-of-10 is down to 5.6% failure[1]. So it's not
erasure-coding/replication that's causing the problem, it's the
combination of k>1 and horrifically bad servers.
I'd rewrite your conclusion to be that the reliability must have been
below 50%, not below k/N. I think we've always assumed that servers will
have better than 50% reliability (you'd never pay a hosting provider for
anything worse than that). Tahoe is a tool for making a great grid out
of good servers, not for making a good grid out of lousy servers. If
you're stuck with that, use 1-of-N and hope for the best.
(If our goal had been to support lots-of-lousy-servers, we'd probably
have built something else: implement replication and automatic repair
first, then get around to things like mutable files and a web interface.
The result would be inefficient on good servers.)
But let's add some other possibilities, some of which we can improve
with code, some of which depend upon sysadmins doing their jobs and grid
members honoring commitments to their clients:
3: people got bored, wandered away, took their servers with them
4: hosts got rebooted and servers didn't automatically come back up
5: failed servers weren't replaced
6: files weren't repaired
When there's no incentive to keep your server running (which could be as
simple as knowing that other people will know when it's been offline),
servers tend to go away, and using replication or FEC to mitigate that
is expensive (the old problem of not knowing whether the server is
coming back or not, therefore needing to treat it as permanent,
triggering immediate repair, and eventually the repair bandwidth is so
high that you can't use the grid for actual work).
We need better OS-integration code to make it easy to get a server to
come up on each reboot. On OS-X that means a LaunchAgent or something.
On Debian/etc it means an init.d or upstart job. (we have this problem
all the time with buildslaves: it's pretty easy to get one running by
hand, but the energy barrier between that and having a real every-reboot
service is high enough that a lot of folks don't bother).
I've been saying forever that it's too hard/slow/inconvenient to get
periodic repair to run automatically (cron jobs are soo gross, and
suffer from the same energy-barrier problem). And I've been planning
(and failing to complete) to move this functionality into the Tahoe
client for nearly as long (  I really think that having
automatic repair of everything reachable from your rootcap(s) is
necessary to get close to the enticing durability promise that
erasure-coding provides.
My conclusion: we can't make serious claims about the benefits/etc of
erasure coding until we've eliminated the confounders, by fixing known
problems that hurt reliability and then collecting actual data[2]. I
think that claiming "erasure coding makes files more fragile" is wrong.
Getting good reliability out of a Tahoe grid requires just as much
attention and effort as any other storage technology: it can't conjure
reliability out of nothing. But I still believe that, for the same
effort, you'll get much more durability out of Tahoe than out of simple
replication/RAID (when Tahoe has the same level of automation as those
other tools, which it doesn't yet).
And I agree that building monitoring tools, and especially the automatic
repair agent, is just as important as Zooko says. Note that monitoring
by itself isn't enough: you need to take action when it's required,
either on the small scale (repair) or on the large (replacing servers).
But good tools to tell you when action is needed is the first step.
yay provocation! :-)
 -Brian
[1]: 3-of-10 on p=25%, chance of failure is the sum of three cases:
      Num(good servers)=0: 25%^10  = 5.6%
      Num(good servers)=1: 10*25%^1*75%^9  = 18.8%
      Num(good servers)=2: 10*9*25%^2*75%^8  = 56.3%
     2-of-10 on p=25%: sum of the first two terms (Num=0,Num=1)
[2]: this was in the plans for the "repair agent" at Allmydata before it
     shut down: that would have been a good place to collect long-term
     statistics on drive failure, share loss, repair bandwidth, and file
     decay curves. The idea was to collect that data for a year or two,
     including failures due to motherboards breaking and upgrades going
     wrong, and then use it to justify a more deliberate choice of k and
     N (minimizing cost while still meeting the reliability goals). This
     project lost a lot of momentum when we lost the centralized place
     to do that research, and the paycheck to build the supporting
     tools.
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org

@_date: 2012-09-11 13:57:03
@_author: Brian Warner 
@_subject: [tahoe-dev] notes from the Tahoe-LAFS Weekly Dev Call, 
Nope. Drewp's defense increases the total entropy of the input to the
convergence function, but that only helps if you're limited to guessing
that input all-at-once. The compression attack lets you guess the secret
input incrementally (just like a padding-oracle attack), so the
attacker's job is linear, not exponential. Adding 256 bits of
unguessable secret merely adds about 256 extra guesses to their
The defense is either to prevent the mixing of secret and adaptive
attacker-supplied data in the same compression context (i.e. the same
file), or to prevent the attacker from measuring the length of the
resulting compressed data.
I'm vaguely uncomfortable with it, but I'm more uncomfortable with some
of the alternatives. Exposing the exact byte-length of the plaintext is
easy to implement (the alternatives are harder to implement) and easy to
explain to users ("we expose the exact byte-length of your plaintext,
and if you append N bytes of attacker-supplied data, we'll expose
length+N"). Compressing the data first might have value (for large
fluffy data, but we think most large data is already mp3/jpg
compressed), but is harder to explain: "we'll leak the length of a
gzipped form of your data, which exposes some obscured combination of
the actual length of your file and the fluffiness of its contents, which
will vary in hard-to-predict way if you append attacker-supplied data to
Padding isn't too hard to explain ("we expose 8*ceil(len/8)"), but the
privacy value it provides is dubious: an active attacker can still
detect single-byte variations if they can get you to start close to an
edge of the block size, and 8 bytes may not be enough to thwart the
would-be file-correlator (who's just on the lookout for a file exactly
4834263 bytes long, but knows there aren't any other files close to that
length, so the rounded-up 4834264-byte file is probably the same). For
larger files, even 4096-byte chunks might not be enough. So the benefit
depends upon the block size you pick, versus the distribution of file
sizes, meaning we'd have to pick a block size out of a hat, and
unjustified ad-hoc constants always make me think we're doing something
wrong. (it might end up being a good idea, but it makes me nervous).
You could add random padding (in a convergent fashion, e.g. append
H(file)%8 bytes of zeros, record the original length in the encrypted
data somewhere). But as we've learned from anonymous remailers, random
padding merely lowers the signal-to-noise ratio, and only increases the
cost of statistical correlation by a linear factor. So you'd have to be
clear on what sort of protection you were earning before taking the
complexity hit of random padding.
 -Brian
tahoe-dev mailing list
tahoe-dev at tahoe-lafs.org
