
@_date: 2005-12-03 04:21:42
@_author: Lauren Weinstein 
@_subject: Google search and seizure, etc. vs. technologists 
1) Any practical attempt to "swamp" Google's database in such a
   manner is unlikely to succeed, given the sheer volume of legit
   queries that they receive.  I suspect they'd be smart enough to
   detect abuse patterns fairly easily.  That kind of analysis is
   their bread and butter.
2) Attempts to purposely "abuse" Google in such a manner (faked
   requests) may well violate their Terms of Service, and if they
   don't now you can be sure that they will in some future version
   of the ToS.  The likely result will at a minimum be bans and ISP
   actions, and at the max lawsuits.  Pull out your wallet.
3) Routing queries through anon proxies will provide some protection
   for the technological elite who understand such things.  They will
   not protect the average user, who most likely doesn't understand
   the risks and issues, and will never use such proxies, even
   assuming that they were trivial to use.
It is fashionable for some technologists to unwisely promote ad hoc,
short-term technological "fixes" in a sort of cold war escalation
mode, without dealing with the fundamental problems.  This is
especially unproductive when it comes to helping to protect average
users who take the default settings for almost everything, but are
just as much at risk of abuse, if not more so.
In this case, it seems reasonable to ask that Google (and other
search engines) show at least as much genuine interest in protecting
people's privacy and rights as does the local library.  And that
library isn't making billions from people's activities -- Google is.
Finally, the statement that:
is of course not really correct.  There are ways (not fullproof, but
some are damned good) to audit such activities, assuming that
appropriate laws are in place requiring such verification.  A simple
claim of compliance from the party in question is obviously not
sufficient, even in the case of Google, whom I have no reason to
believe is lying about what they are doing at this time.
Lauren Weinstein
lauren at pfir.org or lauren at vortex.com or lauren at eepi.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
  - People For Internet Responsibility - Co-Founder, EEPI
  - Electronic Entertainment Policy Initiative - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink:  - - -
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-12-03 08:53:22
@_author: Lauren Weinstein 
@_subject: [IP] Google search and seizure, etc. vs. technologists 
In fact, the reality of the current security and privacy mess with
the Internet helps to prove my point.  For example, talk to the folks
who drive around plotting all of the open wireless LANs that are
literally everywhere in virtually every neighborhood.  The vast
majority of them have *no* security at all -- not even cruddy old
WEP.  This includes businesses, medical offices, you name it, as
well as vast numbers of private homes.  Yet, for years every WLAN
product has included at the very least WEP capabilities, and
instructions on how to set it up.  Despite this, many people's open
WLANs are constantly being abused, sometimes with tragic results.
That situation is gradually starting to improve, but only because the
setting up of *some* level of security has become part of the
standard installation scripts for many products.  But until this
became the *default*, even when it was easy to use, most people
didn't bother.  Why?  Most of the time, simply because they didn't
believe that any associated risks applied to them -- and that view
is easy to understand.  The computer industry is great at promoting
the vast benefits of their products, but do their best to keep the
downsides to the fine print, buried in click-through license
mumbo-jumbo that even many lawyers would have trouble understanding,
along with lilliputian quick-start guides that are the only
instructions many people read.
The same thing goes for Internet services.  It is utterly reasonable
to expect that the *defaults* provided will respect people's privacy,
security, and other rights.  We are a society of laws and those laws
are there (at least in theory) to help protect those rights.  It is
unfair in the extreme to suggest that anyone who doesn't jump
through hoops to protect themselves from information abuse is
somehow negligent, while asserting that legislative efforts should
not be made to rein in the way that the services behave -- so that
those services meet a reasonable standard that society agrees is
Yes, imposing society's will on such firms can be tough to do,
especially when dealing with powerful and well-heeled interests.
But not to do so -- to not even try -- is just surrendering to what
most of us know in our hearts is just plain wrong.
Lauren Weinstein
lauren at pfir.org or lauren at vortex.com or lauren at eepi.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, EEPI
   - Electronic Entertainment Policy Initiative - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink:   - - -
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-12-20 10:01:41
@_author: Lauren Weinstein 
@_subject: "Double Secret" Wiretaps vs. the President's 2004 Statement 
In April 2004, President Bush made a seemingly direct and
unequivocal statement regarding U.S. wiretapping policies in the
fight against terrorism.  We now know that he spoke these words after
authorizing the NSA warrantless wiretapping program.
You can hear his comments for yourself in this very short video:
 (Windows Media)
The White House explanation for this seemingly gaping discrepancy is
that the President was supposedly (we're now told) only talking about
"ordinary" secret wiretaps under the PATRIOT Act, not about what
we might call "Double Secret" NSA wiretaps (legal or not).
Newspeak is alive and well.  Dean Wormer of "Animal House" fame
would be proud.
Lauren Weinstein
lauren at pfir.org or lauren at vortex.com or lauren at eepi.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
  - People For Internet Responsibility - Co-Founder, EEPI
  - Electronic Entertainment Policy Initiative - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2005-05-05 05:13:59
@_author: Lauren Weinstein 
@_subject: [IP] Google's Web Accelerator is a big privacy risk 
I guess it's going to take some kind of major Google-based privacy
breakdown for people to finally understand what we've been saying.
It doesn't matter how sweet, nice, trusted, or cool a service may
be, the collection and archiving of vast amounts of users' Web
search, e-mail, browsing, and other activities is a recipe for utter
disaster.  Google isn't the only culprit, but they're the big
enchilada so they represent a very major risk.  The only way to
avoid abuse of such data is not to keep it around in the first place.
Google's new Accelerator service ironically appears to wed the source
masking aspects of caches (along with all of the usual problems with
caches both for users and destination sites) to the worst aspects of
Google's highly problematic data archiving policies.
Google is smiling their way into becoming -- probably more through a
bizarre combination of hubris and naivete than purposeful intentions

@_date: 2005-09-12 01:41:43
@_author: lauren@vortex.com 
@_subject: Lauren Weinstein's Blog Update: Public Call for Skype to Release  
Lauren Weinstein's Blog Update: Public Call for Skype to Release
                            September 12, 2005

@_date: 2006-04-23 02:51:05
@_author: Lauren Weinstein 
@_subject: DoJ to Propose Major New Internet Controls 
In a speech a few days ago, Attorney General Gonzales announced DoJ
plans to send Congress new legislation to control "pornography" and
(apparently) ultimately to require activity log and other data
retention by Internet Services (in follow-up interviews, Google and
other search engines have been specifically discussed).
Gonzales is pitching this legislation using child abuse as the hook.
That is, he is arguing for tools to use against child abuse and
child pornography -- certainly a "third rail" issue these days where
virtually everyone will support enforcement efforts.
However, it's also clear that the DoJ seems to have no intention
of limiting such tools *only* to child-related areas.  The legislation
itself is currently titled:
  "Child Pornography and Obscenity Prevention Amendments of 2006"
A transcript of the Attorney General's speech is here:
   Note this key quote:
   "This legislation will help ensure that communications providers
    report the presence of child pornography on their systems by
    strengthening criminal penalties for failing to report it.
    It will also prevent people from inadvertently stumbling across
    pornographic images on the Internet."
Requiring the reporting of child pornography on systems (when it is
known to exist) is something that few people would argue against,
obviously.  But let's examine the second sentence again:
   "It will also prevent people from inadvertently stumbling across
    pornographic images on the Internet."
This seems to be addressing the entire broad category of non-child
"pornography" (which of course can be defined in any number of ways
in different locales and contexts), and suggests a requirement (here
we go again!) for proactive ratings/controls (presumably ID or credit
card based for "offensive" materials) for all (U.S.) Web sites.  So
this isn't just about children, it's likely about broader government
controls over many U.S.-based Internet entities (of course, Gonzales
doesn't effectively address the issue of Web sites outside the
Gonzales goes a lot further in another quote:
   "The investigation and prosecution of child predators depends
    critically on the availability of evidence that is often in the
    hands of Internet service providers. This evidence will be
    available for us to use only if the providers retain the records
    for a reasonable amount of time. Unfortunately, the failure of some
    Internet service providers to keep records has hampered our ability
    to conduct investigations in this area.
    As a result, I have asked the appropriate experts at the Department
    to examine this issue and provide me with proposed recommendations.
    And I am going to reach out personally to the CEOs of the leading
    service providers and to other industry leaders to solicit their
    input and assistance.
    Record retention by Internet service providers consistent with
    the legitimate privacy rights of Americans, is an issue that must
    be addressed."
Again, we see that protecting children -- the goal that we all
support -- is being used as the raison d'etre to likely later
propose broad data retention requirements on all manner of Internet
services.  Ironically, this is occurring shortly after calls for
mandated data *destruction* legislation that arose in the wake of
the DoJ vs. Google records battle (where I strongly supported
Google's stance).  I predicted that this sequence would occur --
though it is happening even faster than I expected.
Record retention is a particularly risky area.  DoJ might be expected
to argue (as Gonzales implies) that such records would only be
demanded in cases involving children.  That's today's line.  But in
a general records retention environment, you cannot a priori retain
only the records related to child abusers whom you don't already
know about -- you must retain *everyone's* records.
While the criteria for records access might be child abuse today,
does anyone seriously believe that calls for access to user log data
will not massively expand over time, to the extent that such data is
available?  Of course it will.  If the data exists, all manner of
ostensibly laudable reasons for government digging through users'
Internet activities will be forthcoming.  And that will create a
wholly different kind of Internet, where ultimately our every action
on the Net may be subject to retroactive inspection.  The term
"slippery slope" is definitely applicable.
We need to see the specifics of legislation before detailed comments
will be possible.  But the handwriting is on the wall, and it does
not bode well for either Internet users or Internet-related services.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-04-29 02:31:40
@_author: Lauren Weinstein 
@_subject: Sounding the alarm on government mandated data retention 
Recently here in IP, I commented on Attorny General Gonazales' comments
on data retention, and the alarming slippery slope that I feel this
Now, Declan has noted in an article:
that a Democratic Congresswoman is proposing to fast-track a bill or
ammendment to *require* essentially permanent retention of users'
Internet activity data (until at *least* one year after the user
*closes their account*).  For long-term users, this means effectively
permanent retention.
Again, I must note the supreme ironies.  It was only a few months
ago that people were screaming bloody murder about DoJ demanding
Search Engine records -- a demand that apparently only Google had
the backbone to appropriately resist, noting the sensitivity of the
data involved.  This controversy triggered calls (including in some
legislative quarters) for a law mandating the destruction of much
related data after some reasonable, relatively short interval, with
appropriate designated exceptions for R&D, business development, and
the like.
Now, by waving the red flag of fighting child pornography, seemingly
intelligent and usually well-meaning legislators appear ready to
create the mother of all big-brother database laws, a treasure trove
of personal data that will ultimately be available for every fishing
expedition under the sun.
For those persons who trust the government not to abuse such data, I
hasten to note that these kinds of infrastructures, once in place,
tend to be self-perpetuating, and will be available to *future*
governments as well, including administrations who might not be as
"benign" as the current one.
Declan's article correctly notes the comparison with the McMartin
Preschool child abuse witch-hunts of years ago.  Hysteria over the
abhorrent and real problem of child porn is being used to
potentially decimate broad and critical privacy rights -- with
the high probability of negative effects and consequences that
are almost impossible to overstate.
If we do not maintain a balance between law enforcement goals
(including but not limited to child abuse issues), and privacy rights,
we will be flushing those rights we've had as law-abiding citizens
down the toilet -- all in the name of seemingly laudable goals.
The Internet is rapidly becoming involved in most technology-based
human communications.  The sensitivity of Internet user activity
data can be enormous.  Broadly mandated data retention would move us
drastically toward the realm of previously unimaginable "nightmare"
scenarios (such as requiring the recording of all telephone calls, or
the installation of government cameras in bedrooms -- both actions
that could indeed be useful for law enforcement purposes).
Without wishing to sound melodramatic, I strongly assert that if we
don't take a stand now, we are likely to see the wonders of the Net
repurposed into shackles that have the potential to undermine the
very basis of our fundamental freedoms.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-07-08 11:44:16
@_author: Lauren Weinstein 
@_subject: [IP] FBI plans new Net-tapping push 
Data retention laws.  Purpose-built voice and data wiretapping
capabilities in communications gear.  A sharp salute to the masters
of the Black Chamber, with terrorism and child abuse the rhetorical
keys to creating the pervasive surveillance society.
But there's a piece missing.  Crypto controls of course!
Despite their fundamental impracticality, laws prohibiting,
controlling, or penalizing the use of "untappable" crypto will be
increasingly enticing to the powers-that-be.  For of what use is all
that extremely expensive wiretapping capability if you can't
interpret the damned bits?
Such control laws would of course trigger a vast escalation in the
crypto "arms race" -- with ever more emphasis on steganographic and
other message obscuring techniques.  Innocents will have their
personal and business privacy eviscerated, while the truly evil will
plunge deeper from view, with knee-jerk reactions pulling our basic
liberties down the rathole as well.
After all, even the road to "1984" was paved with good intentions.
Indeed, "He loved Big Brother."
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink:  - - -
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-07-28 02:40:02
@_author: Lauren Weinstein 
@_subject: [IP] Can you be compelled to give a password? [was: 
Police Blotter: Laptop border searches OK'd]
Dave, the trend is toward laws that penalize refusal to cooperate
with demands for decryption keys.  This concept can work in various
ways.  In the border case, for example, a person might be refused
entry -- or perhaps suffer confiscation of related property in some
cases -- if they declined to provide the keys.
In the case of criminal convictions, additional sentence and fine
penalties can be imposed for uncooperative attitudes in this regard.
Keep in mind that in the eyes of some in government, only people
with something to hide would bother using encryption in the first
place.  From that assumption flows a sea of potential abuses.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink:   - - -
You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-07-31 12:21:00
@_author: Lauren Weinstein 
@_subject: [IP] search experience on "border" 
And to what end -- other than going through the motions -- is such
a search?
Given a quick check, the border agent would be unlikely to find a
cache of porn photos that was compressed and archived in a single
encrypted file named C:\WINDOWS\$NtUninstallKB911567 or some other
obscure name -- not a single JPG porn file to be found in a file
Perhaps what's really going on in such border cases is some sort of
"amateur test" -- since any pro who wanted to bring porn (or any
other data) into the U.S. on a laptop would never leave the data in
an easily discovered form.  But then again, why bother using the
laptop?  How about putting an innocuous looking file on that cute
keychain memory dongle?  Or on an iPod?  Porn could be easily rigged
to look like an mp3 file, that could even play properly.  Or why not
use some spare cell phone memory area?  Or how about that 2 Gig
memory stick in the camera, or a miniSD memory card inserted
into an electric razor or the binding of a book?
To quote the wonderful episode "OBIT" from the original '60s
television series "The Outer Limits": "The machines are everywhere!"
Anyone with half a brain who wants to bring data into the U.S. can
do so without meaningful detection, short of a full body cavity
strip search and prolonged forensic analysis -- and even then the
true nature of any data might well be undiscovered.
All of the rest is for show, and perhaps to cull the low hanging fruit.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
    - People For Internet Responsibility - Co-Founder, IOIC
    - International Open Internet Coalition - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-05-09 06:44:28
@_author: Lauren Weinstein 
@_subject: An Open Letter to Google: Concepts for a Google Privacy 
An Open Letter to Google:
                Concepts for a Google Privacy Initiative
                           Lauren Weinstein
                              May 9, 2006
      Preface: The overall situation relating to U.S. and global
      privacy issues is deteriorating rapidly.  Recent Congressional
      moves toward legislating broad, government-mandated data
      retention laws (  )
      are particularly alarming.  The manners in which we
      collectively choose to address these sorts of issues are
      likely to have drastic impacts not only on our own lives, but
      also broadly on the shape of society, both today and in the
      future.
Greetings. When I was recently invited to speak at Google's Santa
Monica center ( Video at  ),
I was impressed by the quality of the facilities, but even more so
by the caliber of the Google employees I met during my visit.
Google's capabilities are extraordinary.  While I have been publicly
critical of some Google policies, my concerns have been focused not
on Google today, but rather mainly on how Google's immense data
processing, storage, and related infrastructures might be abused
in the future, particularly by outside entities in a position to
force Google's hand despite Google's own best intentions.
As discussed in my talk, I consider Google to be an incredibly
important and admirable resource with vast potential to do good.
But by the same token, it is largely this very power that increases
the risks of serious abuses of Google capabilities being forced upon
the organization, and Google will likely be unable to mitigate many
of these unless it takes major proactive steps on an immediate and
ongoing basis, particularly including privacy-related efforts.
Increasingly, Internet users are becoming highly sensitized to both
perceived and real risks to their privacy associated with their use
of the Net.  While the real risks we face in this arena are serious
enough, people's confidence (or lack thereof) in products and
services will in many cases be shaped primarily by perceptions, and
often significantly less by the underlying realities.  This
highlights the critical fact that to be truly successful, efforts to
reduce privacy risks must not only have genuine and ongoing positive
privacy effects, but also need to be clearly perceived by users and
the broader public to be in place and fully supported as primary
goals of the organizations involved.
Web-based search engines are an obvious current focus of many privacy
concerns, but as more traditional "desktop" applications migrate to
tightly coupled topologies with user data stored on remote servers
not under users' direct local control (e.g. for PC searches,
document preparation, e-mail, etc.), these issues and related
potential risks are rapidly spreading across the entire computer and
Internet spectrums.
Fears that users' private information may be increasingly subject to
intrusive perusal by law enforcement or other authorities (often with
minimal and/or questionable cause) are further damaging user
confidence in such services, with a range of issues related to data
retention being an important element at the heart of these
concerns.  To the extent that potentially sensitive data is stored
for extended periods, particularly in non-anonymous forms, it is
inevitable that outside demands for access to it -- on ever broader
scales -- will be accelerating.  While individual court cases will
of course vary in their results, the court system cannot be relied
upon to always render appropriate decisions regarding such matters,
particularly in today's political and legislative environments.
I believe that Google, by virtue of its Internet industry leadership,
technical and human resources, and corporate culture, is in a unique
position.  Google can demonstrate how world-class privacy protection
policies and technologies can be developed and deployed in ways that
enhance user confidence in current and future Google services -- by
proactively protecting users' private data without interfering with
service operations, innovation, R&D, or the legitimate concerns of
law enforcement.  Google could be the acknowledged global leader in
this area, becoming synonymous with the concept of integrating new
and advanced privacy capabilities into world-class Internet services
and products.
Obviously the confidence such efforts would engender in Google's
users would be healthy for Google's bottom line, but more
importantly it will provide genuine and continuing real benefits to
the Google user community itself (i.e. the entire world).  Where
non-proprietary information is involved, further benefits to society
could be achieved through making publicly available (via published
papers, conferences, etc.) those aspects of resulting
privacy-related R&D technologies that could be deployed by other
entities to the benefit of the global community.
I recommend that Google establish a team explicitly dedicated to the
development and deployment of privacy-related efforts as outlined
above.  Such a team would be tasked with establishing the framework
of these projects in a consistent manner, and ensuring to the
greatest extent practicable that all current and future Google
products and services would be integrated (from the outset when
possible) with these privacy technologies and policies.  The team
would need access to other individuals within both the development
and operational aspects of Google, and ideally would report directly
to high-level management.
To be effective, such a team would need to be significantly
interdisciplinary in its makeup and scope, including a variety of
skills.  Some of these would include a broad range of CS capabilities
(including specialized mathematical disciplines related to
encryption, among many others).  Experience in dealing with the
particular and complex interplay between technology and societal
issues will also be an important component of such a team.
Google's growing scale and influence suggest that the sorts of
privacy efforts suggested herein could be among the most important
non-governmental privacy-related endeavors for many years to come,
and could have vast positive impacts far into the future not only
for Google and its users, but throughout the commercial, nonprofit,
and government sectors.
This document represents a very brief conceptual outline, offered
with only the best interests of both Google and the world at large
in mind.  Google and the broader Internet are at a critical
crossroads in many respects, and I believe that Google has the
opportunity to do enormous good by initiating the types of efforts
that I've described.
I would welcome the opportunity to discuss these concepts with you in
more detail and to work with Google toward their realization, as you
may deem appropriate.
Thank you very much for your consideration.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2006-05-20 06:05:18
@_author: Lauren Weinstein 
@_subject: VeriChip chairman promotes RFID "chipping" of immigrants 
Many of us who are concerned about the potential abuse of RFID
systems have long suspected that some "low status" class of
individuals would be the first to find itself subjected to RFID chip
implants under government edict, after which the range of included
persons would gradually expand to cover more and more of the general
These chips in their present form cannot be controlled by the
implanted individual, and so are subject to interrogation at any
time with or without the knowledge of the "chipee."
I've speculated in the past that persons convicted of sex crimes
might be among the likely initial targets by the proponents of this
technology, possibly as a requirement for parole.
However, it appears that VeriChip (the main player in the human RFID
implant space) may have their sights on a significantly larger
demographic.  VeriChip's chairman was on Fox News last Tuesday
promoting the concept of "chipping" immigrants, "guest workers," and
the like.
Here's the transcript:
Hold out your arm -- this won't hurt a bit, eh?
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Moderator, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: You are subscribed as eugen at leitl.org
To manage your subscription, go to
 Archives at: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2007-12-20 07:32:18
@_author: Lauren Weinstein 
@_subject: Details of Unlisted Number Address "Exploit" Revealed 
Details of Unlisted Number Address "Exploit" Revealed
                Greetings.  After due consideration, some expert advice, and since
the firm involved obviously feels that they're not doing anything
wrong (will everyone else agree?), I've decided to release the
details of the unlisted number to address lookup "exploit" I
outlined in "Psst! Wanna Know the Street Address for an Unlisted
Number?" (  ) -- please
see that entry for the background on this situation.  This "exploit"
is still up and running as of a few minutes ago.
As noted previously, this technique is extremely successful at
revealing the street addresses for U.S. landline (non-mobile)
telephone numbers, including those aforementioned unlisted numbers.
The returned information isn't 100% accurate for all queries and
some numbers are missing -- I suspect stale data in certain
situations -- but it's very "good" overall.
Also, the full text of a response I received from the company's
(apparent) public relations firm is available for your perusal and
amusement (  ).
Calling this procedure an "exploit" is actually a misnomer as you'll
see, since it's simple and direct to access once you know where it
lives -- and even that is unfortunately relatively obvious, so it
seems very likely that it's already being used for "unintended"
purposes.  My hope is that broader knowledge of this matter may lead
to a more rapid resolution of the situation, since the firm chose
not to limit this data after I called their attention to the privacy
issues involved.
As you probably know, various large cable television and other
service firms (e.g. Time Warner, Comcast, etc.) offer an array of
Web-based offers via their Web sites.  The most typical means for a
new customer to query these sites about available offers at their
location is via their phone number.
And as it turns out, a major provider of back-end database and
related operations provides various functional aspects of many
related Web sites.  Enter a phone number at the Time Warner offers
site, for example, and it's likely to actually be processed by this
back-end service (sometimes in a quite obvious manner).
It is also apparently possible to make similar queries via voice
calls to a toll-free number at the back-end services firm's call
center, but I have not explored the non-Web aspects of this
operation in detail.
Rather than worry about the cable firms in this example (though we
could go through their sites as well when they link to this company)
we might as well go directly to the back-end operation that's
providing the information, since their own site apparently gives
access to exactly the same data.  Here we go ...
The company under discussion is Acceller, Inc., and you can visit
their services access page at:
 In the upper right-hand corner of the page, you'll find a "Search
For Offers" form where a phone number may be entered.  It's that
simple.  (Note: You may need to have cookies enabled for this to
work, and Internet Explorer may perform better than other browsers
in some cases for these queries.)
Enter a phone number, watch the bouncing ball for 10 seconds or so,
and then you stand an excellent chance of seeing a street address
revealed for U.S. non-mobile numbers (along with the various service
offerings available at that address, of course).
The "geniuses" who programmed that site probably won't be getting
any job offers from Google anytime soon.
The implementation error is serious and obvious.  The proper
procedure to avoid revealing private information about unlisted
numbers would be to have the user enter their address -- not reveal
it from the database based on phone number -- and then verify it yes
or no against the database (even this suggested technique has some
privacy issues, but they are relatively less serious and could be
minimized in various ways).  By taking the "helpful shortcut" of
revealing the address, the system is putting at risk -- for free and
unlimited access by anyone at any time -- the private address
information for unlisted numbers.
I'm afraid that's really all there is to it.  Simple, clean, and
neat, to be sure.  If you've been paying your local phone company
every month for an unlisted number and are upset by this situation,
I urge you to contact your telephone company, Acceller, and -- who
knows? -- perhaps even your legislative representatives might be
intrigued, among other persons and groups.
Unfortunately, this isn't the sort of Christmas present that most
people probably would wish for.  But it appears to be Acceller
that's doing all of the ho-ho-hoing.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
  - People For Internet Responsibility - Co-Founder, NNSquad
  - Network Neutrality Squad - Founder, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: Archives: RSS Feed: Powered by Listbox:

@_date: 2007-02-15 11:53:51
@_author: Lauren Weinstein 
@_subject: New Short Video: "Is Your Cell Phone Bugged?" 
I've been getting lots of continuing interest and queries in the
wake of my blog item from late last year:
"How To Tell If Your Cell Phone Is Bugged"
(  )
In an effort to explain this issue in a more demonstrative
and somewhat less technical manner, I'm pleased to announce a
short free video (under six minutes): "Is Your Cell Phone Bugged?"
While I'll admit that the production values are much closer to
those of Ed Wood than of Cecil B. DeMille, I hope you'll still
find this video to be interesting, or at least amusing.
"Is Your Cell Phone Bugged?" Video Access Pages:
   YouTube (Streaming):
      Google Video (Streaming & Download):
   Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Founder, CIFIP
   - California Initiative For Internet Privacy - Founder, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: Archives: Powered by Listbox: Eugen* Leitl leitl ICBM: 48.07100, 11.36820            8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
[demime 1.01d removed an attachment of type application/pgp-signature which had a name of signature.asc]

@_date: 2007-05-06 05:39:25
@_author: Lauren Weinstein 
@_subject: Strangling the Internet with ID 
This New York Times piece:
gives an excellent overview of efforts now in progress in various
states to require verified ID before allowing anyone to sign-up for
"social networking" sites like MySpace, and the impacts these could
potentially have on all manner of Web sites.
In particular, the article notes the view that such efforts would be
impractical and could even do more damage by pushing children (the
group these laws would ostensibly protect) toward other sites
completely under the radar.  The article also recognizes that
requiring ID (most likely a credit card) would then provide
networking sites (or their third-party subcontractors) with a direct
linkage to all users' true identities that could be subject to later
exploitation and abuse.
While we all want to protect children, these ID-based models will
not do so, and indeed will bring with them a whole host of other
major risks.
How long will it be before some bright boys inside the Beltway get
the idea of requiring that *all* Internet usage be tied to verified
IDs?  This would fit in just dandy with the mandated data retention
push, COPA, and the other efforts to turn the Internet into an ever
more purpose-built computerized arm of law enforcement.
Wanna use Google?  Verify your ID first, please, so retained records
can be retroactively tied to you at any point in the future by
various agencies.
Too dark a scenario?  Couldn't happen?  Do you really want to bet
against me on this one given current trends?
Of course, we can still turn the tide, working together as consumers
and Internet service providers alike.  We can tell the politicos
that enough is enough.  But will we?  Or will it be business
as usual?
Place your bets.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Founder, CIFIP
   - California Initiative For Internet Privacy - Founder, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: DayThink: Archives: RSS Feed: Powered by Listbox:

@_date: 2007-05-31 10:17:20
@_author: Lauren Weinstein 
@_subject: Thoughts on Google Maps Street Level Photos and Privacy 
Thoughts on Google Maps Street Level Photos and Privacy
              Greetings.  The New York Times noted today
(  ) that Google Maps is now displaying
street level photos for some locations in some areas -- the list of
which is sure to be expanding rapidly.
I've been asked what I thought about the privacy implications of
this -- some people seem to be pretty upset.
I started noticing this feature on various Google Map searches
around here in L.A. some time ago.  It's certainly handy for getting
a feel for what an unfamiliar place looks like before heading on
Given the static nature of the images, which currently are unlikely
to be updated very frequently, I do not see a big privacy risk at the
moment.  Real estate companies are constantly snapping photos of
houses in many areas for their databases -- though obviously these
are not public in the way Google Maps now is.  In my neck of L.A.,
I've seen film camera trucks bristling with lenses plowing up and
down the streets shooting movie backgrounds.
In general, such photography from a public point (street, sidewalk,
etc.) is legal -- though there are exceptions that can come into
play for purposeful harassment and in other special cases.
However, it is possible to imagine possible situations where this
feature of Google Maps could cause problems, and even potential
risks for Google, depending on how Google chooses to manage the
So long as the images being used by Google Maps are from
authenticated sources and are relatively infrequently updated, the
privacy risks stay low for most locales.  This isn't to say that
various government agencies won't go berserk over particular images
in any case -- given the ease with which you can get hassled by police
these days for taking a photo of the local freeway overpass -- but by
and large that won't happen for shots of most locations, to be sure.
However if Google decided to allow users to submit their own more
frequently updated photos of locations, either for the official
Google Maps database or through public "mashups" that link such
photos to the mapping database, the situation becomes more
problematic.  Not only could much more frequently updated photos
cross the line into real privacy violations, but the risk of
photoshopped photos being submitted or used that show faked imagery
would seem a real possibility.  You can use your own imagination
about the range of ways in which such fakes could be manipulated to
attract attention, harass, or mislead.
Now, I have absolutely no indication that Google has any intention
of permitting such "self-submitted" location photos scenarios.  In
fact, Google does have a link with which you can report
"inappropriate" photos for possible removal, though if photos were
faked, figuring out what was really inappropriate in different
situations could get rather complex.  In any case, all I'm saying here
is that so long as Google Maps is using authentic photos on a
infrequent update interval, the privacy risks remain relatively low
in the vast majority of cases.
A bigger risk to the service might loom in the future though.  I
can't count the number of times I've gotten queries from people that
amount to: "My neighbor has a camera pointed at my house -- who can
I report him to?  I feel like my children are at risk," etc.  In
almost all of these cases, my response is that so long as someone is
taking photos from public spaces or their own property, and isn't
making a special effort to see things they couldn't otherwise
normally see, such photography or video is usually permitted.  That
answer seems to infuriate many people.
This seems to suggest -- given the post-9/11 mentality -- that it is
not impossible to imagine laws that could be written specifically to
restrict the use of such street level photos, ostensibly on personal
security and privacy grounds.  If Google Maps were painted as a
major privacy problem -- which again is an opinion I don't subscribe
to, but that some others already do -- this could act as a catalyst
toward the enactment of such legislation.  This would be very
unfortunate in the absence of genuine, major privacy concerns of a
sort that do not currently exist in the Google Maps context, and
that might not ever exist there if Google and its competitors use
due care.
I only bring up this sort of possibility as did the "Ghost of
Christmas Yet to Come" -- not as something that Will Be, but as
something that Might Be -- a cautionary thought experiment, as it
So, bottom line -- for now the Google Maps street level photos
provide a useful service and should not raise significant privacy
concerns, except for a tiny percentage of photos that can be easily
expunged.  Whether this benign situation will remain the case
depends upon Google's decisions regarding the service moving forward.
Allen Funt would probably be amused, anyway.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
   - People For Internet Responsibility - Co-Founder, IOIC
   - International Open Internet Coalition - Founder, CIFIP
   - California Initiative For Internet Privacy - Founder, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: Archives: RSS Feed: Powered by Listbox:

@_date: 2007-11-23 12:17:07
@_author: Lauren Weinstein 
@_subject: Beware Software Gifts from the MPAA 
Beware Software Gifts from the MPAA
               Greetings.  I'm on record as supporting *reasonable* efforts by
the MPAA, RIAA, and their various cohorts to protect their
intellectual property assets.  However, a software tool being
distributed to universities by the MPAA, supposedly to help them
internally track student file sharing (and remember, there are
efforts to make such tracking a requirement of federal law) appears
to leak information like a sieve, not just to the MPAA but to the entire
Internet (  ).
Part of the MPAA toolkit's data leakage is obviously intentional --
like the "phone home" aspect that reveals a new installation to MPAA
servers.  Other aspects, like the open Web server that the toolkit
installs, which exposes collected data publicly, may simply be the
result of design incompetence.
Either way, I agree with those observers who suggest that installing
this free software mess would be a big mistake on the part of
university system administrators.
The MPAA now says that the current release that they've been pushing
to the educators is only the beta version.  I'm all in favor of
betas, even extended ones, but a cardinal rule of software
development says that you don't allow beta software to be used in
outside production environments unless it has at least been vetted
for major security and privacy problems.
In this case, the problems with the MPAA software are so obvious
that they call into question the veracity -- or at least the
competence -- of the entire project.
When our policymakers consider the desires of the entertainment
industry to turn university IT departments into intellectual
property cops, I hope that this particular fiasco will be duly noted.
Lauren Weinstein
lauren at vortex.com or lauren at pfir.org
Tel: +1 (818) 225-2800
Co-Founder, PFIR
  - People For Internet Responsibility - Co-Founder, NNSquad
  - Network Neutrality Squad - Founder, PRIVACY Forum - Member, ACM Committee on Computers and Public Policy
Lauren's Blog: Archives: RSS Feed: Powered by Listbox:

@_date: 2007-10-04 12:52:51
@_author: Lauren Weinstein 
@_subject: The Online Medical Records Trap 
The Online Medical Records Trap
                  Greetings.  Microsoft is rolling out their centralized medical
records project
(  ) --
with the somewhat misleading name "HealthVault" -- and it's time for
consumers to start paying attention to what's going on in this
sector -- Google is working along similar lines as well.  (Why do I
call the HealthVault moniker misleading?  Keep reading.)
There is a vast market assumed for centralized recording of every
aspect of your medical life, initially through free accounts where
you would input the data yourself, but as quickly as possible the
intention is to move toward having doctors, hospitals, pharmacies,
and everyone else involved in your medical treatment entering the
data directly.  The federal government is also a big booster of the
centralized medical data idea -- a fact that might be enough to give
one pause in and of itself.
The selling points for such projects seem obvious enough.  Instant
access to your medical data for emergencies or other purposes, ease
of seeing test results and (in theory) correcting errors, and so
on.  All good stuff.
But what's not obvious from the sales pitches are the downsides, and
they could be serious indeed.
The term HealthVault is misleading because we know by definition
that such services will be anything but a vault when it comes to
privacy.  You can almost hear the conversations at Microsoft where
they tried to come up with a name that gave the impression of
security, Fort Knox, and impenetrability.  And of course, Microsoft
is making all the usual claims about encryption, safety, and the
same promises we always hear about centralized data systems.
But the big risk in centralized medical data -- arguably the most
personal data about any of us -- isn't about whether the servers can
be hacked or the communications eavesdropped (though these are real
issues, to be sure).
The most serious problem is that once medical data is in a
centralized environment, there are essentially no limits to who can
come along with a court order (or in the case of the government, as
we know, secret orders or illegal demands that can't usually be
resisted) for access to that data.  Service providers typically have
no choice but to comply.  The only way to prevent this is for the
data to be encrypted in such a way that even the service provider
cannot access it without your permission, even with a court order
staring them in the face.  As far as I know, none of the systems
currently in development or deployment take that approach to
encryption -- but I'd love to have someone inform me that such
techniques would be used.  That would change the equation
Who might want access to your medical data?  Insurance companies
obviously, and one might expect them to lobby hard for such access,
in the name of "reducing fraud and insurance costs" of course.  Many
employers would also love to get access, to help weed out medically
expensive employees and applicants.
Perhaps more ominously, broad "fishing expeditions" by the
government -- both for research, investigative, and other purposes

@_date: 2011-12-02 10:16:02
@_author: Lauren Weinstein 
@_subject: AT&T, Sprint, T-Mobile admit to using Carrier IQ; Apple says it 
- - -
As I noted originally, it seems unwise to "pile on" in this situation, given
that the facts are not entirely clear.  In particular, it apparently has not
yet been demonstrated that CIQ is actually *transmitting* specific user data
that would be trigger wiretap laws, irrespective of ephemeral data
collection on the device to gather service and use statistics that are being
My gut feeling is that in this case there may be parties opportunistically
attacking ahead of the facts, and that it is quite possible that the
failures in this situation are mainly ones of transparency, disclosure, and
user control, rather than the much more serious issues of "wiretapping" per
We shall see.

@_date: 2011-11-17 12:45:04
@_author: Lauren Weinstein 
@_subject: "CarrierIQ" on various mobile handsets 
"Carrier IQ (CIQ) sells rootkit software included on many US handsets sold
  on Sprint, Verizon and more.  Devices supported include android phones,
  Blackberries, Nokias, Tablet devices and more ...  Carrier IQ is able to
  query any metric from a device.  A metric can be a dropped call because of
  lack of service.  The scope of the word metric is very broad though,
  including device type, such as manufacturer and model, available memory
  and battery life, the type of applications resident on the device, the
  geographical location of the device, the end user's pressing of keys on
  the device, usage history of the device, including those that characterize
  a user's interaction with a device."   (Android Security
  Test) [NNSquad]

@_date: 2011-11-30 23:39:58
@_author: Lauren Weinstein 
@_subject: Comedy of Errors Led to False "Water Pump Hack" Report (RISKS-26.65) 
"Even though Mimlitz's username was connected to the Russian IP address in
  the SCADA log, no one from the fusion center bothered to call him to ask
  if he had logged in to the system from Russia. Instead, the center
  released a report on Nov. 10 titled "Public Water District Cyber
  Intrusion" that connected the broken water pump to the Russian log-in five
  months earlier, inexplicably stating that the intruder from Russia had
  turned the SCADA system on and off, causing the pump to burn out.  "And at
  that point all hell broke loose," Craven said."  [Source: Kim Zetter,
  *WiReD*] "Oh Boy!  We get to announce a Foreign CYBER-ATTACK!  Maybe Terrorists
conducting a dry run on a small water system! -- That's what the "experts"
will say on TV!  Don't bother with the reality checks, that could spoil all
the fun!"

@_date: 2012-04-13 10:44:36
@_author: Lauren Weinstein 
@_subject: ICANN data breach exposes gTLD applicant data ... (ars technica) 
ICANN data breach exposes gTLD applicant data, leads to deadline extension
  (ars technica)
  "The group that oversees the Internet's address system has extended the
  application deadline for new generic top level domains (TLDs) and warned
  that a glitch in its processing system exposed potentially sensitive
  applicant information to competitors."
They can't even get the basic application security right.

@_date: 2012-04-13 23:53:55
@_author: Lauren Weinstein 
@_subject: Why one in five U.S. adults don't use the Internet (CNN) 
"Even though the Internet has become a key tool for accessing services,
  getting an education, finding jobs, getting the news, keeping up with
  people you know and much more, one in five U.S. adults still does not use
  the Internet at all, according to a new Pew report.  Why? Mostly they're
  just not interested -- not in the Web, e-mail, YouTube, Facebook or
  anything else that happens online."    (CNN)

@_date: 2012-04-14 12:01:42
@_author: lauren@vortex.com 
@_subject: CISPA, Cybersecurity, and the Devil in the Dark 
Lauren Weinstein's Blog Update, April 14, 2012
CISPA, Cybersecurity, and the Devil in the Dark
The threat of "cyberattacks" is real enough.  But associated risks have in
many cases been vastly overblown, and not by accident of chance.
The "cybersecurity" industry has become an increasingly bloated "money
machine" for firms wishing to cash in on cyber fears of every stripe, from
realistic to ridiculous. And even more alarmingly, it has become an excuse
for potential government intrusions into Internet operations on a scope
never before imagined.
There are warning signs galore.  While we can all agree that SCADA systems
that operate industrial control and other infrastructure environments are in
need of serious security upgrades -- most really never should have been
connected to the public Internet in the first place -- "war game" scenarios
now being promulgated to garner political support (and the really big
bucks!) for "cyber protection" have become de rigueur for agencies and
others hell bent for a ride on the cybersecurity gravy train.
Phony demos purporting to illustrate mass cyber attacks are more akin to
Fantasyland than reality, and the turf war between the Department of
Homeland Security (DHS) and intelligence agencies such as CIA and NSA in
this sphere should give all of us cause for significant concern.
The Cyber Intelligence Sharing and Protection Act (CISPA - H.R. 3523) has
become the embodiment of hopes for those entities who hope to turn overblown
fears of cyber attacks into a pipeline for potentially massive access by
government into the private data of Internet users.
Sponsors of the legislation tout its relative shortness and generality, but
those are precisely among the aspects that make this legislation so
CISPA effectively overrides virtually all existing laws related to Internet
privacy protections.  And since CISPA offers firms access to government
cybersecurity "threat data" in exchange for ostensibly voluntary feeding of
data back from those firms to the government, and provides for broad
protective immunity for companies that choose to do so, a pantheon of tech
heavyweights have lined up in support.
Just a few of the firms who have to various extents professed direct support
of CISPA include Facebook, Symantec, Verizon, IBM, Intel, Microsoft, and
Oracle. There are many others.
Notably absent from this list is Google, who has not taken a formal position
on the existing CISPA legislation and apparently is unlikely to do so.
Google's current approach to CISPA seems particularly prescient.
While it would be absolutely incorrect to attribute bad motives to the firms
supporting CISPA, the legislation itself is in my view so vague and general
that it represents largely an "empty vessel" capable of enormous potential
damage if deployed and then subjected to the inevitable stream of court
CISPA claims to ban using data collected under its authority for other than
cyber threat activities.  But we've seen such data compartmentalization bans
fall many times before in other data collection contexts.
Since the legislation creates such a broad override of existing privacy
protections, and such encompassing immunities for firms that provide
associated data to the government, the lack of specificity in so many
aspects of CISPA creates what could be the opportunity for a "perfect storm"
of abuses down the line.
There are indeed genuine risks of serious attacks on the Internet and
connected infrastructural systems.  But in the fog of the
military-industrial complex's rapid push into this area, it has become
obvious that realistic assessments are being shoved aside in favor of scare
tactics, agency power struggles, and "get rich quick" scheming.
This entire area has become a quintessential example of sowing F.U.D.  --
Fear, Uncertainly, Doubt -- while legitimate questions of privacy and
individual rights are purposefully being marginalized.
We saw much the same thing happen after 9/11, with the knee-jerk rush to
pass the PATRIOT Act and Homeland Security Act, with a range of profiteering
and abuses against individual liberties that then resulted -- even leading
the U.S. down the evil path of torture.
We must avoid a repeat of this madness.
Information sharing can be a crucial element of cybersecurity, but for
legislation addressing this area, the devil is very much in the details, and
the lack of details in CISPA is an invitation to possible privacy disasters.
To the extent that cybersecurity threats do exist, the desire to quell them
must not be permitted to run slipshod over our personal privacy, liberties,
and associated protections in existing laws.
We can work together to help protect ourselves from actual cyber threats,
without allowing ourselves to become cyber schnooks in the process.

@_date: 2012-04-15 09:51:37
@_author: Lauren Weinstein 
@_subject: Web freedom faces greatest threat ever, warns Google's Sergey Brin 
"The principles of openness and universal access that underpinned the
  creation of the Internet three decades ago are under greater threat than
  ever, according to Google co-founder Sergey Brin.  In an interview with
  the Guardian, Brin warned that there were "very powerful forces that have
  lined up against the open Internet on all sides and around the world. I am
  more worried than I have been in the past it's scary."  He said the threat
  to the freedom of the Internet came from a combination of governments
  increasingly trying to control access and communication by their citizens,
  the entertainment industry attempting to crack down on piracy, and the
  rise of "restrictive" so-called walled gardens such as Facebook and Apple,
  which tightly controlled what software could be released on their
  platforms."    (Guardian)
I agree 100% with Sergey.  And regardless of how you personally feel
about Google, to try deny the truth of his remarks is beyond foolish.

@_date: 2012-04-17 10:12:30
@_author: Lauren Weinstein 
@_subject: 60% of Wikipedia entries about companies contain errors - 
(Science News)
  When respondents attempted to engage editors through Wikipedia's "Talk"
  pages to request factual corrections to entries, 40 percent said it took
  "days" to receive a response, 12 percent indicated "weeks," while 24
  percent never received any type of response.  According to Wikipedia, the
  standard response time to requests for corrections is between two and five
  days.  Only 35 percent of respondents were able to engage with Wikipedia,
  either by using its "Talk" pages to converse with editors or through
  direct editing of a client's entry. Respondents indicated this figure is
  low partly because some fear media backlash over making edits to clients'
  entries. Respondents also expressed a certain level of uncertainty
  regarding how to properly edit Wikipedia entries.  Of those who were
  familiar with the process of editing Wikipedia entries, 23 percent said
  making changes was "near impossible." Twenty-nine percent said their
  interactions with Wikipedia editors were "never productive."

@_date: 2012-04-17 10:56:34
@_author: Lauren Weinstein 
@_subject: Walled gardens look rosy for Facebook,	Apple -- and would-be censors 
Battle for the Internet:
Walled gardens look rosy for Facebook, Apple - and would-be censors
  (Guardian)
  Zittrain's real worry is that "the personal computer is dead".  His
  conclusion is a call to arms: "We need some angry nerds" - people capable
  of breaking out of the walled gardens.  Indeed, the US government has
  found some: it has backed projects such as "the Internet in a suitcase",
  which could set up a telecommunications network inside a country separate
  from the existing infrastructure.  Zittrain acknowledges such projects,
  but for the wider world, he says, "convenience is great. I wouldn't call
  for a return to the green blinking cursor of [Microsoft's pre-Windows]
  MS-DOS or the [text-based] Apple II. But we should build architectures
  that permit innovation and experimentation if consumers wish to go
  'off-roading'."

@_date: 2012-09-04 09:35:18
@_author: Lauren Weinstein 
@_subject: 1 million iOS device IDs leaked after alleged FBI laptop hack 
"One million unique device identifiers (UDIDs) from iOS devices have been
  posted online by hacking group AntiSec, who claimed the UDIDs came from an
  FBI-owned laptop. The group published a file containing the UDIDs-as well
  as push notification tokens, device names, and more-on Monday evening,
  promising that there are plenty more entries where that came from. AntiSec
  claims the original file contained roughly 12 million UDID entries-some
  with very personal data attached, such as full names, cell numbers, and
  home addresses."    (ars technica via NNSquad)
[Key word right now is *alleged*.  LW]

@_date: 2012-09-04 09:41:40
@_author: Lauren Weinstein 
@_subject: Ustream continues to attempt explaining Hugo Awards stream blackout 
"This occurred because our 3rd party automated infringement system,
  Vobile, detected content in the stream that it deemed to be copyrighted.
  Vobile is a system that rights holders upload their content for review on
  many video sites around the web.  The video clips shown prior to Neil's
  speech automatically triggered the 3rd party system at the behest of the
  copyright holder."   (Ustream via NNSquad)
Most of the folks commenting on their posting are not very happy.
  [In another NNS posting on this subject, Lauren Weinstein added, ``A
  similar risk exists with Google's "Hangouts On Air" via Content ID.
  Solutions are not trivial.''  PGN]
    [Lee Rudolph noted Hugo and the Rampaging Robots.  PGN]

@_date: 2012-09-04 16:11:34
@_author: Lauren Weinstein 
@_subject: FBI Says Laptop Wasn't Hacked; never possessed Apple device ID file 
"The Federal Bureau of Investigation is refuting a statement made by
  members of AntiSec this weekend that they hacked the laptop of an FBI
  special agent and stole a file containing 12 million Apple device IDs and
  associated personal information."   (*Wired* via
  NNSquad)

@_date: 2012-09-04 21:24:26
@_author: Lauren Weinstein 
@_subject: Apple patent would disable phone based on location 
"Among a bevy of patents awarded to Apple this week was one that would
  enable or disable certain features of a phone depending on its
  location. It could be useful, but it also raises serious questions about
  who really owns your device."    (NBC via NNSquad)
A lot of ideas are patented but never used.  Anyway, without reading the
patent in detail, I'd note there are a variety of apps (that probably
postdate the patent application) that do this already.  One problem with any
attempt to enforce such a regime is that you need everyone to have phones
carrying the capability, and you have to be ready for the litigation
exposure if (for example) an important call or message is blocked by such a
system.  It doesn't take much imagination to think of a bunch of other
exposure examples as well.

@_date: 2012-09-05 15:04:11
@_author: Lauren Weinstein 
@_subject: Did YouTube Really Block Michelle Obama's DNC Speech for 
(This message on Google+)
  (Slate, via NNSquad)
  "Either way, this amounts to something less than a copyright apocalypse.
  Michelle Obama's speech is still available on plenty of other YouTube
  channels, including here, here, and here. But on the heels of the Hugo
  Awards debacle, it's another reminder of the need for human vigilance
  against overzealous digital-rights-management algorithms.  In a statement
  chalking up the glitch to "a technical error on YouTube," an Obama
  campaign official added, "We do not expect tonight's coverage will be
  affected." Copyright bots, the gauntlet has been thrown!"
Irrespective of this particular case, this whole area (not just YouTube) of
automated content flagging needs serious attention from a number of
standpoints.  Here's an example of what has happened to me (and many other
people).  I uploaded a video of mine that included a segment of old,
definitely public domain material.  Shortly thereafter, my entire vid was
flagged by YouTube's Content ID.  Why?  It took some digging to figure out,
but it turns out a Content ID partner had uploaded a video of their own that
happened to include a section of the same public domain material I had used.
This apparently made it look like my video was infringing, since Content ID
assumed the section of my vid that matched their vid was in violation.
Wrong!  But Content ID partners get the assumption of being correct, and
there's no way for an average user to assert that something is public domain
a priori.  I was able to get this reversed by careful explanation on the
appropriate forms, but I wonder how many people would just throw up their
arms and say, "To hell with it!" and not bother?  This is not an easy
situation to solve, but the explicit assumption that Content ID partners are
correct and that takedowns or other actions are immediate -- with a protest
required to get blocks, etc. removed after the fact, strikes me as
increasingly problematic.
Lauren Weinstein (lauren at vortex.com): Network Neutrality Squad:   +1 (818) 225-2800
