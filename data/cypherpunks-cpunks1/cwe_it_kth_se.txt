
@_date: 1995-08-18 09:54:56
@_author: Christian Wettergren 
@_subject: Where is the key cracking farming software? 
I think it is time this kind of software is outlawed! I mean, it is a criminal instrument, and the only good it does is to embarrase good
old well-meaning companies trying to make a profit. Besides, the customers should know better than to buy stuff over the net! And Netscape
said AS IS all the time, didn't they?
(Just joking! :-))
But seriously, I wonder how long it will take before bruteXXX programs will be classified as "criminal instruments"? As well as real good random generators, I guess? (I don't think they will outlaw the XOR
op, so to get rid of one-time-pads they have to go for the random gen...)

@_date: 1995-08-29 22:54:33
@_author: Christian Wettergren 
@_subject: The illegal markets of cyberspace 
I guess I'll get a bunch of cypherpunkers on me now,
even though I have the disclaimers/clarifications there.
I am not opposed to anonymous services at all, ok?
The inital idea behind this note, my main conclusion,
is that NSA and others wont be able to estimate the amount
of free computing power available "out there". The note
outlines what I consider a probable scenario that will
invalidate their estimates with a few orders of magnitude.
If that is not enough, one can always bring out the big jack hammer: An combiner Internet Worm/SSL Bruter kidnaping
the net for a number of hours.
This is a short note I wrote the other day. It points out
a potential future risk, and also show existing problems
with the FSP "proto-market". Also note that I am not opposed to anonymous services per se,
I am only pointing out possible misuses of the technology. There are just as big risks in not deploying encryption and
anonymous services, in going forward with a world without privacy and private spaces.
THE ILLEGAL MARKETS OF CYBERSPACE
by Christian Wettergren, cwe at it.kth.se
Given the recent Brute-SSL efforts, together with the BlackNets
and an eventual ecash exchange, there is a quite interesting situation emerging. The future markets of Cyberspace will
be trading computing power, storage capacity and communications bandwidth, in addition to the more usually mentioned goods. This
market for computing capabilities can be used for legitimate purposes
as well as for illegal ones. I will here concentrate on the illegal
uses, since they will prove to be a challenge to control.
Computing power can yield pay-off in actual money, as the bruteSSL
effort has quite convincingly shown. This can create a market for hiring computing power for illegal purposes. The actors on such a
market can be quite safe, given the anonymity of the BlackNet and the
tracelessness of ecash (DigiCash). There are other goods on the
market as well; storage capacity and communication bandwidth.
How would such a market be operated?
The supply of "goods" for the market could be created by  hackers
breaking in to other's systems and hiring out the stolen capacity.
The intruder could install a backdoor into a foreign system that would
accept issued cryptographic access codes that would expire after a
certain amount of time or usage. This makes it possible for the
intruder to operate the business without having to go near the "scene
of the crime". There is of course a certain risk that the intruder
might lose the system to the hiring party, but that isn't such a big
deal, since first of all its not his system, and second of all he may
have booby-trapped the system for this case.
The intruder would break into computers en masse, and install the
backdoors as indicated above. They would then offer the stolen
merchandise onto a BlackNet-like arrangement. Potential buyers would
express their interests, and the broker of the BlackNet would connect
the two together.
The buyer and seller would agree on a price. The buyer would deposit
the access codes, the seller the anonymous ecash by the broker, and
the broker would effect the deal, taking a share of the profit. The
buyer can then exchange his ecash for real money, or do whatever he
wants with it. The seller brutes away onto whatever he wants, why not
the SWIFT international banking system?
The usage of stolen CPU cycles must of course be done in a careful
way. The intruder would probably install some safeguards against
excessive use, in his own interest. These safeguards could feature; *
only using spare cycles, * monitoring superuser and sysadm activities,
* hiding the process from system utilities like ps, * backing off
during daytime hours etc. Other merchandise
Storage capacity can be traded in a similar way, by setting up
backdoor file server processes that listenes for the proper access
codes. This kind of capacity could be used as anonymous post boxes,
where you store secrets that you don't want to store at home, even if
they are encrypted. It could also be used for bulk storage if it is
cheaper than buying a new harddrive. Since this storage isn't offered
by the proper owner, he can easily be very competetive. :-)
There are of course a number of catches trading with stolen disk
capacity, but they can quite easily be circumvented. To counter the
privacy issue, all stored files will be encrypted by the submitter.
This also eliminates potential evidence, if the proper owner discovers
the illegal use of his resources. There is also a certain risk of losing the files if the area is
discovered. This can be countered by storing the files in several
locations. There is a third risk of traffic analysis of the file server. This
analysis can be complicated by having a system of file servers that
exchange files with each other, moving them around. In this scheme a
buyer can submit a file in one location, and it can be stored in a
totally different location. It will take a concerted action by several
system owners to track down all their unwanted guests, so it is more
likely they will only shut down the file server on their own system. Underground bases
Trading communication bandwidth is somewhat more involved than the two
previous ones, and cannot be traded without a portion of disk and cycles. It can however be worth a great deal to a potential buyer. Buyers of communication bandwidth is most likely setting up a service
that is sold for profit. This service can probably not tolerate
day-light and accountability, and hence needs to be anonymous. A good
example of such a service is the emerging FSP-server black market,
which has been souring during the last year and a half. (There have
been lists circulating with several hundreds of FSP servers.)
An FSP server is an anonymous file server where the users can freely
upload and download files. These "black markets" of file exchanges has
been used to trade porn, pirated music and pirated software. A site in
Sweden recently caught students that had started such a server. 3
Gb/day went out through the server, and an estimated worth of $2
million in pirated PC programs were exchanged over it during it's
three weeks of operation. The high volumes in the server was mainly due to the large amounts of
available bandwidth out from the site. The example is not entirely
good, since there is no money or ecash exchange in this case. The
thing traded currently in the FSP buisness is instead the mere
existance of a server, trading one piece of server access info for
another. This is mainly because of lack of features in the FSP code,
and not a fundamental feature of any such market.
Communication bandwidth/service space rental is traded in a similar
way as the other merchandise over the BlackNet system, with ecash
exchange. The service provider will probably keep on using the site
until the proper owner discovers it, since it is a hassle to move the
service while running.
What is the size of this potential market?
I consider the estimates below conservative. Any illegal  market would
probably be much bigger, and constantly try to expand. Internet now has well over 3 million reachable computers. Lets assume 1
percent of them could be broken into at any one time, i.e 30.000
Each computer is probably good for 5-10 MIPS, but assume we can use on
average 1 MIPS without risk for discoverage. (We can probably use more
during non-office hours, but maybe nothing during the day.) You can
certainly use 10 Mb of ddisk storage on each computer without
problems. This adds up to a constant 30 GIPS in computing power, and 300 Gb's of
storage. And I believe this is a very conservative estimate, as I
I think it is quite likely that markets similar to those described
above will emerge in a few years. There is already one primitive
example of such a market in the FSP buisness, and we will most likely
see more elaborate forms soon. The developement will accelerate once
there is targets which will yield interesting pay-offs.
Another conclusion is that all current estimates on available privately
available CPU power for bruteforcing is likely to be _wrong_ in the
face of such markets. The net has now shown several cases of doing the
supposedly impossible; RSA-129, SSL1, SSL2, RC40 etc.
The SSL2 effort, although impressive, I believe has only revealed a
miniscule piece of what is possible to do. Observe that the current
effort has all used volounteers, has not used any of the easily
accessible super computers on the net, nor has used any intrusion
techniques to round up CPU. The ultimate technique would be to have a well-writen worm raid the
Net for CPU power, maybe only being active for a few hours. The worm
could penetrate a substantial fraction of the Internet, if fed the
right database of possible attacks on different vendors.
The last, and most obvious conclusion perhaps, is that all sites
should be concerned about their security. There is more to steal in
your system than your supposedly worthless information, and I would
say that the laws are quite unclear on the issue of liability in any
of the above situations. At least if you haven't taken proper
By the way, the above mechanisms can be used to create perfectly legit
and proper markets as well. Don't confuse the phenomenas with the
techniques. [BlackNet is a creation of Tim May , and possibly
other cypherpunkers. A black market broker announces a public key widely
on Internet, stating the market's existance. Potential buyers and sellers
encrypt their requests and offers with the public key and posts the encrypted info in a newsgroup somewhere. The broker can then match up buyers and sellers. Ecash can be used to transfer funds, and the broker
will get his share of the deal. This scheme is close to impossible to traffic analyse.]

@_date: 1995-10-04 01:45:49
@_author: Christian Wettergren 
@_subject: The Evolution of Cooperation (Towards a mathematical theory of reputation?) 
I vaguely remember that Axelrod did a few interesting additional papers,
on things like geographical propagation of knowledge in iterated prisoner's dilemma, and of behaviour in which the 'bugs' had limited memory
as well.
Very interesting reading, I'd say. Do anyone know what he have done recently?

@_date: 1995-10-04 04:06:47
@_author: Christian Wettergren 
@_subject: Netscape hole without .Xauthority (fwd) 
This is all true, in a way.
But there is a growing number of applications that contains this kind
of remote execution capabilities, and whose security is dependant on
Xauth. I believe that X is soon becoming the weakest link in the
security chain.
I guess we don't have to discuss the quality of the 'magic cookie'
RNG's, do we? Not to mention the fact that the cookie is in effect
a password that is perfectly snoopable.
How common is DES-based Xauth-schemes? They are not used very
much, as far as I know. And if theyare, as in XDM, then again, what
about the RNG?
I guess this is just the distinction of breaking the glass window
in the back of the house, or to pick up the front door key from beneath the "Welcome" door mat, but anyway.

@_date: 1995-10-04 04:58:26
@_author: Christian Wettergren 
@_subject: Europe 
This may surface in the swedish media very soon now. There will be an article in Ny Teknik next week about these issues, and they
have done some digging at Brussels as well. I've tried to get 'Striptease' (discussion TV-program) interested as well, but I don't know about them.
So lets go off and think hard about good (culture-related) arguments
why this is a bad idea. We'll gonna have to look really nice, and
say some sensible things. :-)
I'm personally attacking the assumption that the police cannot get
to the encrypted traffic without key escrow. Well, why not bug the
keyboard on the originating machine? Etc etc...
I'm currently planning to start an email list dicussing this issue,
but I need some proper political clearance first. (They should at
least have a say, I guess.)
Another thing that is currently happening in Sweden is that a National Identity Card is being proposed by a mjor part of the
swedish industry and other players. This ID-card will be a smart card, and is meant to be used in most places.
What strikes me as so strange is that we have an official phonetapping
approval rate of 300/yr, in a population of 8 million people.
How can the phone tapping be so important then?
I think things are moving faster in this area than we might think.
There is certainly things happening at the EU level, according
to the Ny Teknik reporter I spoke with. There is a resolution at
the Council of Ministers, already taken during 1994, apparantely.
He was vague about the contents of that resolution, however.
I'm listening, I'm listening... :-)

@_date: 1995-10-16 03:27:58
@_author: Christian Wettergren 
@_subject: [NOISE] was Re: java security concerns 
I'm doing a PhD on runtime information flow analysis of programs,
tracking each datum and who has contributed to it. Each datum has an
associated set of subjects that has contributed, and each system call
checks whether all subjects in the set are granted the call or not.
This tracking is done by compiled-in 'shadowing' code, compiled in
into the binary, and the code is inserted based on something similar
to 'data flow' analysis.
Its messy, but I think it might work out in the end. This kind of
access control is much better suited for extensive communication
between different subjects than the current paradigm of having
an owner of the process. With the current concept, it is imperative for the process to
filter and controll each datum entering the process, since it might
be 'hostile'. (The current concept of identity is really based on
*partitioning* an expensive computing facility, without communication
between the different partitions.) I believe this task to be to burdening in the long run.
With "my approach", you can accept any input without fear, since
it will be stopped when your application does the syscall.
I just started, so I don't have anything concrete yet. I'll have it in five years! :-)
Why ever prove anything else but a trace of actual execution? This is
usually almost trivial, you don't have the problem of calculating the
proof for all possible branches, etc...
It might be fruitful to do it for an actual system, although I think
that this "paradigm"-shift will influence a lot of the design of the
Tell me if your planning to do something along these lines, it would
be most interesting.

@_date: 1995-09-17 22:26:37
@_author: Christian Wettergren 
@_subject: Netscape SSL implementation is broken! 
Neat, I'd say. Has everyone sold their Netscape Comm stock yet? :-)
I guess we should send them the draft-ietf-security-randomness-00.txt
I was also thinking about how many Credit Card numbers will pass
between now and the moment Netscape has done anything about it.
This piece of information does have quite a value, I'd say.
I have included a short program that tries to generate non-guessable
random numbers. It was written a bit back, and my coding style isn't
all that good. It might be interesting, or not.  (Btw, if you find any
problems with it, I'd appreciate to know about it.)
----- ZZ: README -----
asadi -
   "As strong as DES is" (hopefully)
Written by: Christian Wettergren
            cwe at nada.kth.se
            February 1993
This utility generates a "random" hexstring, which can be used as input
to xauth, for example. It uses a private secret and some other input
to generate the hexstring. In this way a long-term secret can be used
to generate a short-term secret. Since the short-term secret might be
compromised (different xauth cookies might be tried repeatedly, since o warning is emitted from the Xserver) it is not safe to use the
same secret on repeated occasions.
This utility does not even need a private long-term secret, since it
may use the ticket generated within the Kerberos authentication system.
In this way the long-term secret is as guarded as your private password
or the Kerberos master-password.
If you don't use the Kerberos system, you have to regenerate the long-term
secret sometimes (in the same way as you change your password). This
utility tries to help you with that step too. A decent pseudo-random
generator is included, and a routine that helps you generate the secret
might be run.
The short-term secret wont reveal anything about the long-term secret,
since the long-term secret is altered and then encrypted with DES. The
result is the short-term secret. Search space
The algorithm used to generate the long-term secret tries to enlarge the
search-space as much as possible. so that an exhaustive attack becomes
The factors involved are:
     1/ A good random generator
     2/ time-of-day
     3/ user entered text
     4/ user dependant elapsed time
     5/ pid of process
     6/ hostid of computer
     7/ not using consecutive values from
        random generator (initial throw-away &
        intermediate throw-away.)
The most important of all is of course the random generator. The included generator is a minimum standard.
    Probable usage:       echo add $DISPLAY MIT-MAGIC-COOKIE-1 `asadi` | xauth     DISCLAIMER: No guarantees are made about this
    program, explicit or implicit. It is distributed
    AS IS. etc... :-)
  opensafely() -
  open file, try not to reveal when it was
  written.
  Unfortunately, this is not possible!
  No matter how this is done, at least the
  ctime reveals when it was written.
  If I don't remember incorrectly, there are
  bugs in the filesystem under SunOS, so that
  the ctime-field is updated too often. Maybe   this might distort this field sometimes.
  Another approach might be to chmod the file
  whenever it is used. In this way it's ctime
  field is updated and hence overwritten.
  It does not reveal anything extra either,   since the approximate time when the cookie is
  generated is probably shown in ~/.Xauthority
  anyway.
   generate a good secret "random" file.
   This routine tries to enlarge the search-space
   for a potential cracker. The involved factors
   are:
     1/ A good random generator (see accompanying file.)
     2/ time-of-day
     3/ user entered text
     4/ user dependant elapsed time
     5/ pid of process
     6/ hostid of computer
     7/ not using consecutive values from
        random generator (initial throw-away &
        intermediate throw-away.)
   This approach hopefully deters an attack, or at least
   makes it considerably harder for the attacker.
   Does anyone see any weakness in the above approach? It
   is not based on any cryptological analysis, so no
   guarantees are made of it's appropriateness.
  fprintf(stderr, "asadi - generate a good random hexstring based on\n");
  fprintf(stderr, "        a private secret as a seed. (This secret can\n");
  fprintf(stderr, "        be the Kerberos ticket-file.) Could be used\n");
  fprintf(stderr, "        for getting a good xauth-cookie, for example.\n\n");
  fprintf(stderr, "Usage: asadi [-r] [-l n] [-v] [filename]\n");
  fprintf(stderr, "       -r   -- generate a secret file (default: ~/.secret\n");
  fprintf(stderr, "       -l n -- how many 8-byte blocks to output (default: 16)\n");
  fprintf(stderr, "       -v   -- verbose, not very interesting.\n");
  fprintf(stderr, "       filename -- name of secret file (default: Kerberos\n");
  fprintf(stderr, "                   ticket file, or ~/.secret)\n");
---- ZZ: asadi.c ----
    asadi v1.1 -
      "As strong as DES is" (hopefully)
    This utility generates a "random"     hexstring, which can be used as input
    to xauth, for example. Either a Kerberos
    ticketfile or a secret file is used as
    seed to the random generator. Other input
    is probably hostid, process id and time,
    depending on the implementation of the     DES-library.
    The random generator used is the DES-
    algorithm. This method is guaranteed     not to reveal anything about the used     seed. To crack the cookie you have to     crack DES. (There is also a normal good     pseudo-random generator included, to
    facilitate the generation of secrets.)
    Written by: Christian Wettergren
                cwe at nada.kth.se
                February 1993
    Usage:
      asadi [keyfilename] [-v] [-l num] [-r]
    The number of 8-byte blocks to     generate can be controlled with the     -l-switch. There is also a verbose-
    switch.
    If one does not use Kerberos, a secret file
    can be used as a key instead. The contents     of this file will not be revealed by this     program, but you should of course NOT USE     your password anyway!
    To help generate this secret file is a
    decent (according to it's author, not me) random-
    generator included in this program. Use
    the r-switch for this. It deposits the secret
    in the file ~/.secret (with the appropriate
    chmod). This file is also used if there is
    no Kerberos.
    Probable usage:       echo add $DISPLAY MIT-MAGIC-COOKIE-1 `asadi` | xauth     DISCLAIMER: No guarantees are made about this
    program, explicit or implicit. It is distributed
    AS IS. etc... :-)
 USEKRB /* switches the use of Kerberos on/off */
 DEFAULTKEYLEN  8 /* multiples of 16 nibbles */
 SECRETFILE ".secret"
         USEKRB
 extern char *getpass();
extern void goodsrand(unsigned long);
extern unsigned long goodrand(void);
extern char *getenv(char *);
extern void *malloc(int);
char *keyfile = NULL;
int vflag = 0;
int keylen = DEFAULTKEYLEN;
int major = 1; /* version of program */
int minor = 0;
   cblock, continue until eof.
   Hence there is no actual reason to use files
   larger than eight bytes, but the above approach is
   used since the ticket-files are larger. (In this    way I don't have to care about file's structure    too much, either.)
void calcsecretkey(char *file, des_cblock *key) {
  des_cblock tmp;
  int i;
  int fd;
  if (vflag)
    fprintf(stderr, "file: %s\n", keyfile);
  if ((fd = open(file, O_RDONLY)) == -1) {
    fprintf(stderr,     exit(1);
  }
  while (read(fd, &tmp, sizeof(des_cblock)) == sizeof(des_cblock)) {
    for(i = 0; i < sizeof(des_cblock); i++)
      *((unsigned char *)key + i)
    DES_ZERO_CBLOCK(tmp);  /* fixes eof-condition */
  }
  /* close the file */
  if (close(fd) == -1) {
    fprintf(stderr, "Could not close file! (errno=%d)\n", errno);
    exit(1);
  }
void printcblock(FILE *fd, des_cblock *blk) {
  int i;
  for(i=0; i < sizeof(des_cblock); i++) {
    fprintf(fd, "%02x",   }
  opensafely() -
  open file, try not to reveal when it was
  written.
  Unfortunately, this is not possible!
  No matter how this is done, at least the
  ctime reveals when it was written.
  If I don't remember incorrectly, there are
  bugs in the filesystem under SunOS, so that
  the ctime-field is updated too often. Maybe   this might distort this field sometimes.
  Another approach might be to chmod the file
  whenever it is used. In this way it's ctime
  field is updated and hence overwritten.
  It does not reveal anything extra either,   since the approximate time when the cookie is
  generated is probably shown in ~/.Xauthority
  anyway.
int opensafely(char *file) {
  int fd;
  /* delete old file, if any */
  if (unlink(file) == -1) {
    if (errno != ENOENT) {
      fprintf(stderr, "Error: could not unlink '%s'. (errno=%d)\n",       exit(1);
    }
  }
  /* open it again */
  if ((fd = open(file, O_WRONLY|O_CREAT, S_IRUSR)) == -1) {
    fprintf(stderr, "Error: could not create '%s'. (errno=%d)\n",     exit(1);
  }
  return(fd);
   generate a good secret "random" file.
   This routine tries to enlarge the search-space
   for a potential cracker. The involved factors
   are:
     1/ A good random generator (see accompanying file.)
     2/ time-of-day
     3/ user entered text
     4/ user dependant elapsed time
     5/ pid of process
     6/ hostid of computer
     7/ not using consecutive values from
        random generator (initial throw-away &
        intermediate throw-away.)
   This approach hopefully deters an attack, or at least
   makes it considerably harder for the attacker.
   Does anyone see any weakness in the above approach? It
   is not based on any cryptological analysis, so no
   guarantees are made of it's appropriateness.
void gensecret(char *file) {
  int i,j;
  struct timeval t, s;
  unsigned long d, u, v;
  int fd;
  unsigned long x;
  char *c;
  char n[100];
  int ta, b;
  struct utimbuf tm;
  /* Get time before enter */
  gettimeofday(&s, (struct timezone *)0);
  /* heading */
  printf("\nGenerating a Secret!\n");
  /* get user's response */
  printf("\nCAUTION! Don't use your password below!\n");
  printf("You don't have to remember this data, so\n");
  printf("just type something in.\n\n");
  c = getpass("Enter something:");
  /* get time after enter */
  gettimeofday(&t, (struct timezone *)0);
  d = t.tv_usec - s.tv_usec;
  /* make something of input */
  for(j=0; j < strlen(c) / sizeof(unsigned long); j++) {
    /* collect sizeof(long) bytes of input */
    for(v=0, i=0; i < sizeof(unsigned long); i++)       v = (v << 8) + c[i+j*sizeof(unsigned long)];
    /* xor them together */
    u ^= v;
  }
  /* get throw-away factors */
  printf("\nEnter a throw-away factor: ");
  gets(n);
  ta = atoi(n);
  printf("\nEnter a step factor: ");
  gets(n);
  b = atoi(n);
  /* verbose */
  if (vflag) {
    fprintf(stderr, "text: %s\n", c);
    fprintf(stderr, "garbled text: %ld\n", u);
    fprintf(stderr, "elapsed: %ld\n", d);
    fprintf(stderr, "time: %ld %ld\n", t.tv_sec, t.tv_usec);
    fprintf(stderr, "pid: %d\n", getpid());
    fprintf(stderr, "hostid: %d\n", gethostid());
    fprintf(stderr, "throw-away factor: %d\n", ta);
    fprintf(stderr, "step factor: %d\n", b);
    fprintf(stderr, "generated seed: %ld\n", t.tv_usec ^ t.tv_sec ^ d ^ getpid() ^ gethostid() ^ u);
  }
  /* init random generator */
  goodsrand(t.tv_usec ^ t.tv_sec ^ d ^ getpid() ^ gethostid() ^ u);
  /* open the file safely */
  fd = opensafely(keyfile);
  /* throw-away ta numbers */
  for(i=0; i < ta; i++)
    (void)goodrand();
  /*      this actually writes sizeof(long)      times too much data, but it does not
     matter.   */
  for (i=0; i 	m  (unsigned long)2147483647
	q  (unsigned long)127773
	a (unsigned int)16807
	r (unsigned int)2836
** F(z)	= (az)%m
**	= az-m(az/m)
** F(z)  = G(z)+mT(z)
** G(z)  = a(z%q)- r(z/q)
** T(z)  = (z/q) - (az/m)
** F(z)  = a(z%q)- rz/q+ m((z/q) - a(z/m))
** 	 = a(z%q)- rz/q+ m(z/q) - az
unsigned long seed;
void goodsrand( /* unsigned long*/ initial_seed)
unsigned long initial_seed;
    seed = initial_seed; unsigned long goodrand(/*void*/){
int 	lo, hi, test;
    hi   = seed/q;
    lo   = seed%q;
    test = a*lo - r*hi;
    if (test > 0)
    else
    return seed;
 TEST1
**   The result of running this program should be
**   1043618065.  If this program does not yeild this
**   value then your compiler has not implemented this
**   program correctly.
unsigned long	n_rand;
register int 	i;
int	success = 0;
    goodsrand(1);
    for( i = 1; i <= 10001; i++){
        n_rand = goodrand();
        if( i> 9998)      }
    if (success){
    }else{
    }

@_date: 1995-09-27 02:15:13
@_author: Christian Wettergren 
@_subject: Exchange random numbers (was: Re: netscape's response) 
Well, I'm not either, actually. But I think this might be better
than the current state of affairs, where every bit of your seed
is almost guessable. And it might also be an intermediate solution
until there is a good random seed hardware generator in every computer.
I think you mustn't allow the any external partner to "contribute" at a
known and/or chosen offset into the buffer. You mustn't either accept "too much" contribution.
Yes. But I wonder whether this isn't really about the battle between
"the pragmatists" vs "the purists" point of view wrt security? I see so
many very unsophisticated attacks out there that a related-key attack,
although possible and powerful, still is rather unlikely.
Could you quantify how powerful a related-key attack is, compared to
some other kind of attack? I don't know anything about this kind of attack, do you have any references?
Ok, noted. Maybe I should try to write down this "idea" for a proper review?

@_date: 1996-04-27 00:24:05
@_author: Christian Wettergren 
@_subject: trusting the processor chip 
Take a look at the IEEE Symp on Security and Privacy Proceedings from
1995, I believe it was. There was a paper there about security bugs in
the Intel processors, enumerating a number of them in 80386 for example.
There where at least one or two byte sequences that plainly stopped the processor.
[I'll find the reference, I have it back home.]
The authors concluded that the number of released bugs reports had
dimished over time for each processor model, and for the Pentium not a single one had been released. They speculated whether it was considered company confidential perhaps?
They "promised" to build their own "processor tester" to try to find
the most obvious ones at least. But it will be very hard to find all of
these bugs, judging from the released bugs. Some of them are only appearing sporadically under a pretty complicated set of circumstances,
like what is in the pipeline, the cache etc...
The processor is ever important, if it is illdefined or flakey, it is
almost impossible to build security on top of it.

@_date: 1996-04-29 22:21:58
@_author: Christian Wettergren 
@_subject: trusting the processor chip 
The promised reference:
"The Intel 80x86 Processor Architecture: Pitfalls for Secure Systems"
Olin Silbert, Oxford Systems Inc,
Phillip A Porras, The Aerospace Corp,
Robert Lindell, --- " ---
An in-depth analysis of the 80x86 processor families identifies
architectural properties that may have unexpected, and undesirable,
results in secure computer systems. In addition, reported
implementation errors in some processor versions render them undesirable for secure systems because of potential security and
reliability problems. In this paper, we discuss the imbalance in scrutiny for hardware protection mechanisms relative to software,
and why this imbalance is increasingly difficult to justify as
hardware complexity increases. We illustrate this difficulty with examples of architectural subtleties and reported implementation
My comments:
This is a high-security view paper, so they go on looking for
all possible covert channels etc. Not what we are discussing here, perhaps.
They note one problem with Page Access Control by the TCB through
the VERR and VERW instructions. In some cases it is possible
that these instructions leave "grant access" when they should have
said the opposite.
They note that the Timestamp Counter (TCS) in the pentium might
give out high-resolution timing information. This can be used attack sw RSA running in another task for example, I believe.
They have 102 flaw reports collected for 80386, 80486, Pentium.
There are 8 major security flaws reported. "7. The bits of the I/O Permission Bitmap (IOPB) correspond to individual byte addresses
in the I/O address space. The D0 step of the 386 permits
access to certain addresses prohibited by the I/O bitamap: if a 4-byte access is performed, only 3 of the 4 relevant bytes are There were 9 denial-of-service as well, here's one "LAL, LSL, VERR, VERW for a null (zero) selector (A1 step) [Turl88]"
Quite fun reading, although I also recognizes that this kind of
attack is a bit down on the list of best cost/effort ratios.

@_date: 1996-02-04 01:11:49
@_author: Christian Wettergren 
@_subject: FV Demonstrates Fatal Flaw in Software Encryption of Credit Cards 
The "keyboard sniffer" of FV is really troublesome, and the
extension of this threat will hamper the Internet Commerce
tremendously, I believe. The thing that might have made it
hard to accept the threat for cypherpunkers is that it was presented together with a plug for the FV scheme, (which may or may not be valid btw.)
But more generally, I see the following happening.
The factors that now are "harmonizing" are;
* the tremendous growth of Inet commerce; Digicash, encrypted
  CardNo's etc. Many of the now proposed schemes have no
  independant "evidence" mechanism, whereby you can settle
  a disputed transaction fairly. You will have to choose
  to believe one of the parts, and that is very often the
  service provider/bank/card company.
* The decline of the "ordinary" card fraud market,
  VISA/Europay/Mastercard is rapidly finishing their
  forthcoming smart card systems. I'd guess this "market"
  is gone within 2-3 years. Some "big organisations" might
  start to move into the new "fraud markets" soon.
* The fact that the PC are such an extremely used platform,
  and that the need for back compatibility will make it
  almost impossibe to add substantial security to it now.
* The fact that anti-virus tools haven't been able to
  eradicate the virii problem even before the "forthcoming
  surge" in virus writing that I believe will come. According
  to a survey by Information Week (Nov 27 -95) 67% of the   companies had been hit by a virus the last year, and 12%   of the companies had suffered financial loss caused of it.   (1293 companies surveyed).   Admittedly there are social problems behind the continued spread
  of virii too, but that alone doesn't make them go away. Take
  a look at the article "Virus Authors strike Back" by Alan
  Solomon in "Computers and Security" 11 (1992) 602-606. The
  state of anti-virus tools seemed to be in a rather sad state
  back then, and I really wonder whether they are any better
  now.
* The knowledge about how to write virii has been spread
  rather far - a college kid can get his hands on one of
  the polymorphic virus generators, and start to output
  new self-encrypting virii with the same action routine
  regularly. Also, note that this new kind of virii ("virii
  with a mission") would start to cost immediately, in   contrast with the "old kind" that only cost when you   have to clean them out, or if they wipe un-backuped data.
  (your fault - core dumped)
* All PC's will be net-connected... Embed a public key in the
  virus, let it encrypt the loot and post it to Usenet
  in the group junk.erotica. You can then harvest the group
  with the secret key anywhere in the world.
  (Be generous, let the virus go away automatically if it
  has "contributed" enough money.)
The pay-off of continously updating your virus to cope with
new protection mechanisms would be enormous. Lets assume that I
employ 10 programmers 2 years from now, that writes new action routines and develop new virus types... I bet I could get a decent living quite soon. Also assume I settle down in a suitable country with lax enough laws, do you believe that I
would be a criminal then? What is the legal status of virii,
and what is this concept of "electronic money" anyway? :-)
I promise, I wont do that. It's not a bet.

@_date: 1996-01-24 17:08:11
@_author: Christian Wettergren 
@_subject: Hack Java 
I think what we should worry about is the second-order effects of
Java; how will the world look like when Java is everywhere?
We should also not discount the "social" effects; what will people
do to try to circumvent the "stupid" safeguards that Java will be
distributed with.
I have earlier heard the opinion from the Java team (I believe) that
this is not "Java's fault", and I can understand that standpoint.
My opinion is still that the net result (pun intended!) is even weaker security, because of these two reasons above. (In my darker moments, I feel that the whole field of computer security
is in a major crisis. Ever heard of the Emperor's New Clothes? ;-))
Just some mumbling from,

@_date: 1996-07-03 04:35:48
@_author: Christian Wettergren 
@_subject: Paper: "A Socially based Identity Model" 
I've written a paper where I introduce a "name spectrum"
as a identity model. The name spectrum has increasing
levels of identification; anyone, anyone with alias,
established pseudonym, well-reputed pseudonym, escrowed
pseudonym, identity and True Name. I try to show how law enforcement still can find criminals,
even though they (we) have privacy. I argue that the power
balance between the individual and the law enforcement should be approximately the same as it is in ordinary life. I talk quite a lot about the analogy between real life and
cyberspace when it comes to power and trust.
I have a suggestion for how to deploy traffic mixers (DCnet)
without tilting the power balance too much to the advantage
of the user as well. I suggest reputation servers where an efficient reputation market can be maintained. I'd appreciate any comments on the paper. It is still
preliminary, though.
It is available at  in
a number of formats. -Christian Wettergren, cwe at it.kth.se

@_date: 1996-07-16 20:53:24
@_author: Christian Wettergren 
@_subject: Word lists for passphrases 
You should on the other hand be able to use the username as an indicator
of what kind of password it is;
user "warez" / pass "warez" (but better check the home directory for MS Word)
user "l0pht" / pass "'l33t"
user "feh" / pass "uk4n+r3dt13" (look for zines)
Actually, these kids believe the language they use are hiding them, but I
bet that the letter digrams they present is a immediate marker of "H4k3rz".
It's definitively better than searching for normal "elite, hacker, phracker,
exploit". I just used "l33t" (52), "d00d" (742), "h4qu3r" (5), "sux" (4053)
on AltaVista, to name a few.

@_date: 1996-06-05 18:51:17
@_author: Christian Wettergren 
@_subject: Class III InfoWar: TST Article 
I've met Winn Schartau and a number of the people mentioned in the
article at a conference in Brussels about Information Warfare two
weeks ago.
I've also seen the article that is referred in the message from
Winn, and here is the URL for it.
Alternatively, you can access it through
going through a brief registration process etc.
Also, I've meet the journalist, Peter Warren, at the conference as
well. We even went for a beer! :-)
So, I'd definitively say there is too much real-world details
to it for me to believe it is a NetMYTH.
-Christian Wettergren,
 KTH/Teleinformatics
 Sweden.
PS. I'm not a netMYTH either, and I do exist. :-)

@_date: 1996-06-19 19:35:40
@_author: Christian Wettergren 
@_subject: Fuseable Links - no guarantees?? 
According to the FAQ for satellite piracy, whatever that is called, it is
quite simple for some models of PICs. Many of the OTP PICs have a wipe mode for reusal. Apply a certain voltage,
the programming voltage, and the memory is wiped and a fuse is restored so
the memory is programmable again.
Approx a year ago some people on this scene discovered that one could restore
the fuse without erasing the memory content. They applied the programming
voltage minus 0.5V (or something similar). The idea is that there is a voltage
drop across the fuse, and this modified voltage level just barely "manages
it" across the fuse. The voltage level is however not enough to spark the
memory erasure mechanism off.
So I guess one can look at the circuitry and apply non-standard voltage and
current values, or even non-standard timing values -- and do bad things
to these circuits. So this begs the question: Is there anyone who has looked
at "computer security" issues at this level? Is this just bad implementations
of these circuits or are there a fundamentally hard problem in this?
(I'd guess you'll find the FAQ if you search for the words "satellite piracy
PIC OTP" on Alta Vista.)

@_date: 1996-06-20 18:47:14
@_author: Christian Wettergren 
@_subject: Fuseable Links - no guarantees?? 
Does anyone have any pointers to papers or literature on this?

@_date: 1996-05-10 21:06:53
@_author: Christian Wettergren 
@_subject: Runtime info flow in Java 
I'm presenting my licentiate research proposal
next week, and I thought that some of you might
find it interesting. I'd like to find others
that are working with similar projects, to have
some people to discuss with.
The actual proposal is available at      I've included an abstract below.
Comments are most welcome.
Licentiate Thesis Proposal Seminar Title: "Runtime Information Flow Analysis and Security" Candidate: Christian Wettergren
Time:      Wednesday, 15th May, 15:00--16:00
Place:     Room Telegrafen, Dept. of Teleinformatics, KTH,            Electrum Bldg., lift B, 5th floor, Kistagangen 16,            16440 Kista, Sweden
Committee: Gerald Maguire, KTH/Teleinformatics
           Sead Muftic, SU/DSV
           Enn Tuygu, KTH/Teleinformatics
Today's computer security systems are fragile and brittle. I
believe this statement to be consistent with practical experiences.
One can for example observe the regularity of alerts from CERT. Many of the problems are caused by data-driven bugs in application programs. It is important to find a security paradigm that is more
stable for the communicative and networked world of tomorrow.
I propose a new way of doing information flow analysis of programs.
This information flow analysis is done in runtime, and will provide
detailed information about influences of the process to the access control decision process. The information flow is based on
sets of subjects instead of preallocated security classes, thus decoupling the flow analysis from the access control.
The runtime analysis is performed by special code that is run along
with the original program. It shadows the computation and keeps track
of the information flows within the program. A special compiler
emits this shadow code. I will implement such a compiler for the
Java language. Issues about the compiler and the shadow code will be discussed in the thesis. The thesis will also investigate the behaviour of the shadow code for programs with different communication
For more information contact Christian Wettergren, +46 (0)8-751 14 91,
cwe at it.kth.se. You can also retrieve the licentiate thesis proposal from

@_date: 1996-05-14 20:04:50
@_author: Christian Wettergren 
@_subject: Notes from the SF Physical Cypherpunks meeting 
[I've cc:ed this note to one of the designers of KOM,
 Jacob Palme. Hi Jacob! -cwe]

@_date: 1996-05-28 21:57:00
@_author: Christian Wettergren 
@_subject: Runtime info flow in Java 
I've uploaded a letter-formatted version of the paper as well now.
(Or I hope so at least, can't try it here since we only have A4 paper.)
I have also put the original FrameMaker document there, as well as a small presentation in PowerPoint about the topic. Take a look at
 for more information.
I've read briefly previously about KeyKOS, I believe it was in IEEE
Symp on Sec & Priv, or something like that.
I'll take a closer look at KeyKOS. It is interesting to find others
doing similar things, since it is quite hard to find previous work
in the area. (I've digged through Comm of ACM all the way back to
1969 for material. Sigh! :-))
I have experiences from UNIX, and I would say that a large number of the
security problems in the daemons are due to the fact that the programmer
did not succeed in keeping data from different subjects separated. This is
today solved by ad hoc methods by the programmer, and the task is too
One of the things I want to examine is how fast a subject's influence
is spreading through the program during execution. I'm worried that the
influence in general is not contained, and that one either has to have
a very intelligent compiler or have to rewrite most programs to take
advantage of the scheme. I hope to be able to straighten out this question
mark during the coming months.

@_date: 1996-05-28 22:39:12
@_author: Christian Wettergren 
@_subject: Runtime info flow in Java 
First of all I'm concentrating on programs that deals with data input from many different subjects. There is a problem in trying to separate the influence of these different subjects from each other. What resources should the process be allowed to access? If it is too little, nothing useful can be done. If it is too much, you run a risk of compromise.
I try to achieve my goals in a somewhat different way than in a traditional
capabilities system. Much, if not most, of the security work make the assumption that the program can do anything, and that the OS doesn't know squat about what the program does from a security point of view. This clearly doesn't work anymore, at least in my view.
What I try to achieve is that one doesn't have to trust the program anymore.
The program is compiled with a special compiler that inserts an extra
"guarding" program in parallell with the original program. I call this the
"shadow code", since it shadows the original program's execution.
All data inputs to the process have a subject identity to them. The shadow
code keeps track of how these identities flow through the variables and the
execution path as the program is executed. Suppose we're calculating c := a + b, then the subject set of 'c' is the union of the subject sets of
'a' and 'b'; sset[c] := sset[a] U sset[b].  Subject sets appear, instead of
plain subjects, as you can see. This is a piece of shadow code that is
executed just before the original statement is executed. You have to
take care of the execution path as well for conditionals as well.
The subject sets are presented to the OS by the shadow code when the program
does a system call. These subject sets are now used to do *detailed* access
control for the *specific* system call. This (hopefully) solves the problem
of giving too much/too little access, since this decision now can be based
on the precise subject sets presented.
You can find a discussion on this in a power point presentation at
 Take a look at  for more info. Comments are most welcome!
