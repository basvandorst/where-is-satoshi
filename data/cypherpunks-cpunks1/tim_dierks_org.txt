
@_date: 1996-01-12 15:51:28
@_author: Tim Dierks 
@_subject: Domains, InterNIC, and PGP (and physical locations of hosts, to boot) 
For what it's worth, you can use the mapping software at
 to find your location fairly accurately; you may
need another map to locate yourself, since the streets are unlabeled. I
managed to figure out that I'm currently at latitude 37.3435 degrees,
longitude -121.8925 degrees. I think that's correct to within about 100
feet or so.
 - Tim
Anyone with a GPS device, feel free to stop by; I'm in unit A2, and I've
got homebrew in the fridge.
Tim Dierks - Software Haruspex - tim at dierks.org
If you can't lick 'em, stick 'em on with a big piece of tape. - Negativland

@_date: 1996-01-27 12:47:09
@_author: Tim Dierks 
@_subject: The French do some things right... 
Of course, aside from censoring photos and a book that happened to talk
about the fact that he had cancer. I think it's just a different set of
 - Tim
Tim Dierks - Software Haruspex - tim at dierks.org
If you can't lick 'em, stick 'em on with a big piece of tape. - Negativland

@_date: 1996-07-02 07:28:48
@_author: Tim Dierks 
@_subject: [Fwd: Doubleclick] 
The way doubleclick works is that the sites who contract with them to sell
advertising space insert a URL into their page which fetches the
doubleclick ad banner. For example, the guys at TroutHeads, Inc.
( would insert an HTML IMAGE tag with an HREF referring
to ad.doubleclick.net; that then results in _your_ browser doing an HTTP
transaction with ad.doubleclick.net; doubleclick can then hand you all the
cookies it wants.
Anytime you fetch an image, you're visiting a site, and because it's
automatic, you can easily visit a lot of sites you never knew you were
going to.
For any HTML document you wish to display an ad banner for, simply add the
     HTML tags:
Click on graphic to find out more!
     Where MY_URL is the URL for the HTML document displaying the ad banner. For
     example:
Click on graphic to find out more!
 - Tim
Tim Dierks - Software Haruspex - tim at dierks.org
"...when ketchup finally comes out of the bottle, it is going a good 25 miles a
year.... It rolls along at three-thousandths of a mile an hour. Heinz knows the
speed because it has a device called a Bostwickometer, a chutelike contraption
that calculates the speed at which ketchup travels."
 - The New York Times, June 12, 1996

@_date: 1996-03-22 19:08:17
@_author: Tim Dierks 
@_subject: ASN.1 Tools/Compilers 
I've recently been looking into this as well. I haven't looked at ISODE
yet. Snacc looks reasonable, but can't handle big integers (> 2^32), which
may make it hard to use for certificates, due to embedded RSA keys; I
haven't yet checked to see what could be done about this. It's free; the
compiler is under the GNU license, but the runtime is redistributable
without fee or onerous restriction.
I also spoke to a company in NJ, Open Systems Solutions (609.987.9073), but
their licensing terms were too expensive for my purposes. Their product
runs on a lot of platforms and sounds very complete, but requires a
licensed run-time environment. They currently support C and Pascal; C++ is
coming. Their development environment starts at $11,500.
I'm also searching for an ASN.1 product. We can afford to pay for a
compiler, but we need unrestrained distribution of the runtime in source
form. Any information would be greatly appreciated.
You may wish to examine the ASN.1 homepage           - Tim
Tim Dierks - Software Haruspex - tim at dierks.org
Hastening the heat-death of the universe since 1968.

@_date: 1996-05-19 18:57:43
@_author: Tim Dierks 
@_subject: Rumor: DSS Broken? 
DSS uses SHA, which isn't affected by the Dobbertin finding. I believe that
you would have to solve the discrete logarithm problem to break DSS; this
would imply being able to break Diffie-Hellman and a number of other crypto
algorithms. (However, I'm not certain that it's been shown that breaking
DSS is equivalent to breaking discrete logarithms.)
 - Tim
Tim Dierks - Software Haruspex - tim at dierks.org
"That's the trouble with technology. It attracts people who have nothing
to say." - Muffey Kibbey, mother [Wall Street Journal, May 10 1996]

@_date: 1996-05-21 15:10:35
@_author: Tim Dierks 
@_subject: Is Chaum's System Traceable or Untraceable? 
Not that full anonymity isn't a Good Thing, but couldn't this be solved by
having the merchant (who presumably is on-line) provide PDA <-> mint
connectivitiy for the purposes of getting change, exchanging coins, etc.?
My assumption is that all the ecash protocols are not subject to a MITM
attack, which I would just presume to be good practice.
Also, given the fully anonymous protocol as you've described it (both payor
and payee blind the coins), what's to prevent the merchant from depositing
your change before he gives it to you? Unless your PDA is online, you'll be
home before you find out the hot dog vendor shorted you. (It's my
understanding that the current digicash system does not support Chaum's
method of revealing the identity of double-spenders).
 - Tim
Tim Dierks  --  timd at consensus.com  --  Head of Thing-u-ma-jig Engineering, Consensus Development

@_date: 2002-08-12 15:28:15
@_author: Tim Dierks 
@_subject: Palladium: technical limits and implications 
The addition of an additional security ring with a secured, protected memory space does not, in my opinion, change the fact that such a ring cannot accurately determine that a particular request is consistant with any definable security policy. I do not think it is technologically feasible for ring -1 to determine, upon receiving a request, that the request was generated by trusted software operating in accordance with the intent of whomever signed it.
Specifically, let's presume that a Palladium-enabled application is being used for DRM; a secure & trusted application is asking its secure key manager to decrypt a content encryption key so it can access properly licensed code. The OS is valid & signed and the application is valid & signed. How can ring -1 distinguish a valid request from one which has been forged by rogue code which used a bug in the OS or any other trusted entity (the application, drivers, etc.)?
I think it's reasonable to presume that desktop operating systems which are under the control of end-users cannot be protected against privilege escalation attacks. All it takes is one sound card with a bug in a particular version of the driver to allow any attacker to go out and buy that card & install that driver and use the combination to execute code or access data beyond his privileges.
In the presence of successful privilege escalation attacks, an attacker can get access to any information which can be exposed to any privilige level he can escalate to. The attacker may not be able to access raw keys & other information directly managed by the TOR or the key manager, but those keys aren't really interesting anyway: all the interesting content & transactions will live in regular applications at lower security levels.
The only way I can see to prevent this is for the OS to never transfer control to any software which isn't signed, trusted and intact. The problem with this is that it's economically infeasible: it implies the death of small developers and open source, and that's a higher price than the market is willing to bear.
  - Tim
PS - I'm looking for a job in or near New York City. See my resume at

@_date: 2002-08-12 16:32:05
@_author: Tim Dierks 
@_subject: trade-offs of secure programming with Palladium (Re: 
I agree; I think the system as you describe it could work and would be secure, if correctly executed. However, I think it is infeasible to generally implement commercially viable software, especially in the consumer market, that will be secure under this model. Either the functionality will be too restricted to be accepted by the market, or there will be a set of software flaws that allow the system to be penetrated.
The challenge is to put all of the functionality which has access to content inside of a secure perimeter, while keeping the perimeter secure from any data leakage or privilege escalation. The perimeter must be very secure and well-understood from a security standpoint; for example, it seems implausible to me that any substantial portion of the Win32 API could be used from within the perimeter; thus, all user interface aspects of the application must be run through a complete security analysis with the presumption that everything outside of the perimeter is compromised and cannot be trusted. This includes all APIs & data.
I think we all know how difficult it is, even for security professionals, to produce correct systems that enforce any non-trivial set of security permissions. This is true even when the items to be protected and the software functionality are very simple and straightforward (such as key management systems). I think it entirely implausible that software developed by multimedia software engineers, managing large quantities of data in a multi-operation, multi-vendor environment, will be able to deliver a secure environment.
This is even more true when the attacker (the consumer) has control over the hardware & software environment. If a security bug is found & patched, the end user has no direct incentive to upgrade their installation; in fact, the most concerning end users (e.g., pirates) have every incentive to seek out and maintain installations with security faults. While a content or transaction server could refuse to conduct transactions with a user who has not upgraded their software, such a requirement can only increase the friction of commerce, a price that vendors & consumers might be quite unwilling to pay.
I'm sure that the whole system is secure in theory, but I believe that it cannot be securely implemented in practice and that the implied constraints on use & usability will be unpalatable to consumers and vendors.
  - Tim
PS - I'm looking for a job in or near New York City. See my resume at

@_date: 2003-06-03 11:14:46
@_author: Tim Dierks 
@_subject: Maybe It's Snake Oil All the Way Down 
I have my own opinion on what this assertion means. :-) I believe it intends to state that ssh is more successful because it is the only Internet crypto system which has captured a large share of its use base. This is probably true: I think the ratio of ssh to telnet is much higher than the ratio of https to http, pgp to unencrypted e-mail, or what have you.
However, I think SSL has been much more successful in general than SSH, if only because it's actually used as a transport layer building block rather than as a component of an application protocol. SSL is used for more Internet protocols than HTTP: it's the standardized way to secure POP, IMAP, SMTP, etc. It's also used by many databases and other application protocols. In addition, a large number of proprietary protocols and custom systems use SSL for security: I know that Certicom's SSL Plus product (which I originally wrote) is (or was) used to secure everything from submitting your taxes with TurboTax to slot machine jackpot notification protocols, to the tune of hundreds of customers. I'm sure that when you add in RSA's customers, those of other companies, and people using OpenSSL/SSLeay, you'll find that SSL is much more broadly used than ssh.
I'd guess that SSL is more broadly used, in a dollars-secured or data-secure metric, than any other Internet protocol. Most of these uses are not particularly visible to the consumer, or happen inside of enterprises. Of course, the big winners in the $-secured and data-secured categories are certainly systems inside of the financial industry and governmental systems.
  - Tim

@_date: 2003-06-06 15:04:49
@_author: Tim Dierks 
@_subject: Maybe It's Snake Oil All the Way Down 
I don't think this problem is easier to solve (or at least I sure don't know how to solve it). It seems to me that you could tell a user every time they go to a new site that it's a new site, and hope that users would recognize that e-g0ld.com shouldn't be "new", since they've been there before. However, people go to a large enough number of sites that they'd be seeing the "new" alert all the time, which leads me to believe that it wouldn't be taken seriously.
Fundamentally, making sure that people's perception of the identity of a web site matches the true identity of the web site has a technical component that is, at most, a small fraction of the problem and solution. Most of it is the social question of what it means for the identity to match and the UI problem of determining the user's intent (hard one, that), and/or allowing the user to easily and reliably match their intent against the "reality" of the true "identity".
Any problem that has as a component the fact that the glyphs for "lower-case L" and "one" look pretty similar isn't going to be easy to solve technologically.
  - Tim

@_date: 2003-06-08 18:03:29
@_author: Tim Dierks 
@_subject: An attack on paypal 
I don't think it's https that's broken, since https wasn't intended to solve the customer authentication / authorization problem (you could try to use SSL's client certificates for that, but no one ever intended client certificate authentication to be a generalized transaction problem).
When I responded to this before, I thought you were talking about the server auth problem, not the password problem. I continue to feel that the server authentication problem is a very hard problem to solve, since there's few hints to the browser as to what the user's intent is.
The password problem does need to be solved, but complaining that HTTPS or SSL doesn't solve it isn't any more relevant than complaining that it's not solved by HTML, HTTP, and/or browser or server implementations, since any and all of these are needed in producing a new solution which can function with real businesses and real users. Let's face it, passwords are so deeply ingrained into people's lives that nothing which is more complex in any way than passwords is going to have broad acceptance, and any consumer-driven company is going to consider "easy" to be more important that "secure".
Right now, my best idea for solving this problem is to:
  - Standardize an HTML input method for  which does an SPEKE (or similar) mutual authentication.
  - Get browser makers to design better ways to communicate to users that UI elements can be trusted. For example, a proposal I saw recently which would have the OS decorate the borders of "trusted" windows with facts or images that an attacker wouldn't be able to predict: the name of your dog, or whatever. (Sorry, can't locate a link right now, but I'd appreciate one.)
  - Combine the two to allow sites to provide a user-trustable UI to enter a password which cannot be sucked down.
  - Evangelize to users that this is better and that they should be suspicious of any situation where they used such interface once, but now it's gone.
I agree that the overall architecture is broken; the problem is that it's broken in more ways than can just be fixed with any change to TLS/SSL or HTTPS.
  - Tim

@_date: 2003-03-05 14:40:20
@_author: Tim Dierks 
@_subject: Wiretap Act Does Not Cover Message 'in Storage' For Short 
Furthermore, it's apparently not illegal for a non-governmental actor to retrieve stored information which they have access to, although it might be illegal for them to wiretap a communication even if they had access to the physical medium over which it travels.
I disagree with "Somebody"'s claim; I don't think that claim would go anywhere in court, since a transmission clearly falls under the category of "wire communication", and it's clear that transmission lines are the very entities the wiretap act has always been intended to protect, so Congress' intent is quite clear, regardless of any argument about "storage".
  - Tim

@_date: 2003-05-12 21:18:25
@_author: Tim Dierks 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?) 
Assuming that a CPU costs $500 and that its value can be amortized over 2 years, CPU costs .0016 cents/second.
Based on the numbers enough, the revenue/spam sent is .044 cents. Thus, the breakeven point is 27.6 seconds/message: assuming other costs are minimal, you have to require > 27.6 seconds of CPU calculation from an email submittant to ruin the spamming business model.
A few thoughts on this:
  - You have to adjust the size of the calculation frequently to keep up with Moore's law (although the time/$500 CPU is constant, assuming constant profitability for spam)
  - If spammers have new technology or economies of scale available to them, it's going to adversely affect everyone else. (That is, if you're using an 18-month-old CPU and CPU-seconds cost you twice what they cost in the volume it costs spammers, your $500 computer will have to spend 2 minutes of time to calculate a token it takes a spammer 30 seconds to   - This is going to dramatically increase the costs of sending bulk e-mail for non-spammers: for example, I get airline specials a few times a week; they must send millions of these.
  - The CPU time required here is several orders of magnitude larger than the cryptographic costs associated with SSL, and SSL is not broadly accepted at least in part due to the CPU cost associated with with it; this implies to me that there will be substantial resistance.
  - The CPU costs associated with SSL engendered a substantial market in cryptographic accelerators intended to reduce the cost to do an RSA private key operation. Presumably, a system like this will create such a market for e-mail token accelerators: unfortunately, this is exactly the kind of new tech / economy of scale envisioned above: we may end up with a situation where a calculation which costs a spammer .044 cents will take the average user's CPU 10 minutes or more to calculate.
  - Tim
