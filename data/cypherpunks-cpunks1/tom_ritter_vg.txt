
@_date: 2011-12-05 20:34:03
@_author: Tom Ritter 
@_subject: [cryptography] really sub-CAs for MitM deep packet 
Interesting for me is probably around 65%.  You can judge for
yourself:  I like it, but to be honest, it does get spouts of super-high volume
(like the last week while I was traveling).  I consume it via RSS from
gmane which keeps my inbox cleaner.

@_date: 2011-11-08 19:51:53
@_author: Tom Ritter 
@_subject: [p2p-hackers] Verifying Claims of Full-Disk Encryption in Hard 
Hash: SHA1
After reviewing the FIPs approval document for the drive[1], I've tried to put together a complete threat model outlining the major classes of attack on the hard drive in the interest of being rigorous.  I'd like your input to see if I missed any you can think of.  I've explicitly excluded DriveTrust (the proprietary stuff) from the threat model, and am only focusing on the ATA Standard.
[1] In approximate physical/logical order, this is every attack I can conceive of:
1. The BIOS may have been replaced to record passwords
2. The keyboard or keyboard connection may be tapped/keylogged
3. The physical computer may have been tampered with physically installing hardware in any of its components
4. The Operating System may have been tampered with
5. The application used to interact with the hard drive (hdparm) may have been subverted
6. The SATA connection to the HDD may have been tapped
7. On the Drive
8. AT Password Security Protocol
This groups those attacks together, and notes whether I consider them within the realm of testing for the drive.  I'm not sure what will be doable easily or cheaply, but if I can verify the firmware, I'll try.
Not Considered for evaluation
User Coercion or Cooperation / "Evil Maid" Attacks
Side Channel Attacks
Considered for Evaluation
1. Buggy firmware
2. Key Management
3. Encryption
4. System Area
Again, all comments welcome, but particularly interesting in talking to
  - Anyone familiar with these Seagate drives or DriveTrust.
  - Anyone familiar with BIOS support for the AT Security Spec, who can help me locate a new netbook to work with.
  - Anyone familiar with Data Recovery Services who could provide information on disk unlocking, AT password bypass, or moving platters between disks.
  - Anyone who has done this before.
- -tom
p2p-hackers mailing list
p2p-hackers at lists.zooko.com

@_date: 2011-11-15 08:19:18
@_author: Tom Ritter 
@_subject: [p2p-hackers] Verifying Claims of Full-Disk Encryption in 
Hash: SHA1
Misdirected a reply to Eugen instead of the list a week ago.  I don't think this
will correctly reply, because I wasn't subscribed to this list at the time.
I used whatever documents I could find to get as much information
about the drive as possible.  That was the marketing material (which
obviously didn't help much), and the FIPS-140 document (which did have
some technical information).  If I could use the Common Criteria or
Protection Profile document, I'd love to - but I'm not sure how to get
those or go about requesting them (besides just calling and asking.)
I may be naive, having never dealt with FIPS validation, but I kind of
hoped/assumed that things that were insecure wouldn't be approved.
I'm using insecure casually, basically meaning "If I steal your
laptop, can I recover your data for under a couple thousand dollars?'
If that is possible, and within the reach of a hobbyist (or organized
crime, minor government, etc) - I would expect it not to be approved.
And if it was approved, I'd expect the approval to be in error.
Maybe I'm wrong about the approval process - I've never been involved
with it.  I'm just approaching it from the perspective of 'Should I
trust this?' and using the FIPS-140 approval to gain a little intel
and make a good starting point for a hard drive to start with.
- -tom

@_date: 2012-08-07 09:30:52
@_author: Tom Ritter 
@_subject: [liberationtech] What I've learned from Cryptocat 
I agree with a lot of the points being raised, including all of
Moxie's (especially about Google v Riseup) but also Eleanor's
regarding niche products and irrelevancy.
In particular I want to expand on this bit:
I agree with that position wholeheartedly.
Still, possible does not equate to easy.  Cryptocat is the Jackie
Robinson of Web Crypto Services[0].  And not to fault Nadim, as this
is a volunteer effort, but there is more it can and should do to make
it harder for  - just as Google and Facebook have done.
 - Cryptocat should use DNSSEC - even if validating resolvers are not
deployed, it's another piece.  Maybe down the road when a binary
plugin is developed, it can validate the DNSSEC chain.[1]
 - It should Pin certificates in Chrome.  As soon as the header is
supported in any other browser it should use it.  Same with TACK.
 - It should assert the SSL certificate with both DANE and
DNSSEC-Stapled Certificates
 - It should (it does for the record, just saying) use Strict Transport Security
 - It should (it now does as of Sunday) deploy Content Security Policy
 - It should do all the other security techniques recommended:
x-frame-options, X-Content-Type-Options, etc
 - Where it is possible, plugins should assert the validity of the Code and Keys
 - Controversial: It should use per-request mutated javascript
obfuscation to make it more difficult to inline-middle the application
in realtime[2]
 - It could experiment with browser enhancements to provide signed
javascript files and so on
All of those are not too difficult for an individual to try, and it
makes SSL Interception harder.  It's not any less possible, but it
raises the bar.  If you think these techniques aren't effective - I
challenge you to do a live MITM of the gmail interface and have it
still function seemlessly.  It just flat-out won't work in Chrome of
course, but even in Firefox - it is not trivial.[4]  That's what I
mean by being Jackie Robinson - you just have to be 'better'.  Above
and beyond.
Trying to fix  is way, way harder because it's just impractical to
tell someone "Oh, compile everything from source, run a perfectly
secure Linux box with PaX and grsecurity, etc etc"  Ideally, that's
what we'd have.  I suppose the important part is to acknowledge the
risk of server compromise, and keep the bars approximately equal.  If
all the above measures were employed, but the server left the way it
was - then rooting the box is absolutely easier.  Google and Facebook
have a huge advantage here.
[0] If you don't get the reference, Jackie Robinson broke the
segegration barrier in US baseball - he was spit, cursed, threatened
with murder, had pitches thrown at his head - and through it all, he
just played the game steadfastly. There's an urban legend (I'm unsure
on it's truth) that his contract stated he couldn't complain, even
when fans spit on him.
[1] If your arguement is 'I don't trust DNSSEC' my response is 'Me
neither, but I believe in beaurcracy and turf wars and that it'd be
more difficult for a government to subvert two PKIs than one.'
[2] If your arguement against it is "but then I can't audit it" my
argument is "you don't audit it now." If your argument is still "I
can't trust the code delivered" my response is "well, since you
obviously are doing local SSL interception to read the server
responses, hash the mutated javascript serverside, and send a PGP
signature along with it so you can do the same and trust it that way".
[3] Heck, maybe that's a way to upgrade web services to thick client
services - have an optional thick client someone can run that sits as
a proxy running verification.  Same web interface works with or
without the tool, but the tool provides run-time verification.
[4] Javascript obfuscation makes it difficult to rewrite the code; if
you add code - CSP prevents you from exfiltrating easily; and if you
exfiltrate to another user in the chat the chatters *should see* this
other user in the chat they don't trust.
Yes, yes, yes.  There is a *tremendous* amount of implicit and
unmentioned TRUST in the person operating the service or relying on
the software.  That's why anyone would use RedPhone, TextSecure or
WhisperCore back when it was closed source.  Because people *trusted*
If the EFF hosted an e-mail solution I'd be throwing money at them to
let me sign up.  Because Google is huge and diverse - they are
obligated to respond to legal threats in most of the countries of the
world.  Because Google is huge and opaque - I have little faith in
their ability to notify me/etc in the event of a LE request.  But the
EFF has both juristiction on their side (arguably they'd have more if
they were based in, say, Scandenavia) and they have trust.  I trust
that the EFF will fight harder for me than Google.  And there's
intimidation factor - a LE agency ought to know if they come the the
EFF with a request they need to back it up with a supoena or warrant.
I absolutely think of riseup as a trust project.  I would like to see
many more of them.  Nick Merril's Calyx Institute I think of as a
Trust Project.  He's trying very hard to remove Trust, and make it a
cryptography project - but he literally has to build the
infrastructure for that because it doesn't exist.  (Which is one of
the reasons you can't actually buy any services from them yet.)   It
will be *very* interesting to see how Phil Z's and Jon Callas' Silent
Circle positions itself.  A trust project?  They're aiming to remove
trust also; but to what extent can they?
Trying to improve upon the trust factor is extraordinarily difficult.
I think, in the short term, it relies on linking up with a person or
organization people already trust - and therefore somehow convincing
them to trust you. And in the long term - devoting your life to being
a trustworthy individual.  Not something we can solve with
cryptography - even a thick client.
Anyway, I realize I haven't addressed the issue of 'Should cryptocat
move to this model or that, shut itself down, add warnings, push
forward with users, etc'.  But I wanted to raise the point that it can
do more, today, to make users safers - and if _any_ webapp in this
sphere wants to push the envelope, it should probably do those things
first.*  And since people are already using it, these are options to
improve security besides just shutting it down.
* None of this is meant to be a slight at Nadim, who has certainly
earned my respect for both his effort and his results so far.
liberationtech mailing list
liberationtech at lists.stanford.edu
Should you need to change your subscription options, please go to:
If you would like to receive a daily digest, click "yes" (once you click above) next to "would you like to receive list mail batched in a daily digest?"
You will need the user name and password you receive from the list moderator in monthly reminders. You may ask for a reminder here: Should you need immediate assistance, please contact the list moderator.
Please don't forget to follow us on

@_date: 2012-05-14 23:16:28
@_author: Tom Ritter 
@_subject: [p2p-hackers] Pirate Pay 
Hm.  I'm not sure how to bootstrap when you only want to interact with
people you trust - but it seems like this could be a model for a Web
of Trust that grows over time if you have a way to validate what
people are supposed to be sending.
I am Alice and I interact with 1000 other people, Bobs1-1000, who send
me pieces of a file. They're valid, so I sign their public keys saying
they were good for some number of bytes, send them the signature, but
also keep it locally. I send data to 50 other people, Carols1-50 who
in turn give me signatures.  Over time, I interact with Bob50 again,
and trust him based on my previous signature. I find a Dave, who I
trust a little because he has a signature from Bob600, and Bob600 was
good to me.
The key pieces (and why this couldn't work for distributed DNS) are
that I know that Bob[x] sent me is valid because I have the
information to build a merkle tree and validate his piece.  The more I
download, the more people I 'trust' because they were honest actors
last time. The more I upload, the more people 'trust' me because I
acted honestly in the past.
But I may have reinvented something simple or missed an obvious flaw,
because I'm not well-versed in how DHT works, or anything published in
this area.
p2p-hackers mailing list
p2p-hackers at lists.zooko.com

@_date: 2013-08-12 16:23:51
@_author: Tom Ritter 
@_subject: Information theoretically secure communication networks 
As Lance said, this is pretty close to what alt.anonymous.messages
evolved into in the 90s and early 00's.
I gave a talk two weeks ago looking at 10 years of messages there and
finding user errors, weak passwords, user-segmenting settings, and
traffic patterns.  Details are over here:

@_date: 2013-08-27 20:57:35
@_author: Tom Ritter 
@_subject: Metadata anonymization through time delayed email messaging. 
I don't know - if I'm performing physical or network surveillance of a
target, and I see a Mix message leave - that tells me something very
definite about the timing.  Obviously you wouldn't want to store the
message in plaintext, but if you encrypted it to the first hop, along
with the address, and a time to send (and tried your hardest to lie
about the timestamps on the filesystem); you can increase the
difficulty of learning something definite.  And I think that holds
even if the attacker does a physical intrusion and looks at the
filesystem. (It reminds me Rivest's FlipIp game - the attacker is
allowed to do a physical intrusion and read the filesystem, but
everyone learns that they have and thus distrusts that node.)  Of
course it only holds if there are multiple possible senders, delaying
an email from my home when I live alone doesn't help me.  But if there
are multiple possible senders, it feels like tacking on a
lesser-quality mix node at the beginning.
Another argument to it's utility is there is no easy way to disguise
the fact that you are sending a mix message.  Right now the only ways
I can think of hiding that fact would be to use mix bridges (some
entry remailer node that isn't published, akin to Tor's bridges) with
a protocol that looks as identical to SSL in a webbrowser as you can;
or to send them out over Tor.
I think the user-configurable time is the idea behind Alpha Mixing,
although I hope it's implemented better than in Type 1 Remailers.
Absolutely.  And on the sender end, I can't think of good ways to
obfuscate large messages.  The splitting technique of Mixmaster has
always felt like a bit of a hack (no offense), because someone doing
end to end correlation should be able to link those fairly easily.
For receiving large files, I think a client/server architecture where
you can choose to delete the message on the server, or download chunk
by laborious chunk over time would be advantageous[0].
[0] This might, might, even be an argument of added complexity by
splitting files, before compressing and encrypting them, so you can
download chunks 1-4 and (potentially) get a portion of the file in a
readable albeit incomplete format.

@_date: 2013-08-12 16:23:51
@_author: Tom Ritter 
@_subject: Information theoretically secure communication networks 
As Lance said, this is pretty close to what alt.anonymous.messages
evolved into in the 90s and early 00's.
I gave a talk two weeks ago looking at 10 years of messages there and
finding user errors, weak passwords, user-segmenting settings, and
traffic patterns.  Details are over here:

@_date: 2013-08-27 20:57:35
@_author: Tom Ritter 
@_subject: Metadata anonymization through time delayed email messaging. 
I don't know - if I'm performing physical or network surveillance of a
target, and I see a Mix message leave - that tells me something very
definite about the timing.  Obviously you wouldn't want to store the
message in plaintext, but if you encrypted it to the first hop, along
with the address, and a time to send (and tried your hardest to lie
about the timestamps on the filesystem); you can increase the
difficulty of learning something definite.  And I think that holds
even if the attacker does a physical intrusion and looks at the
filesystem. (It reminds me Rivest's FlipIp game - the attacker is
allowed to do a physical intrusion and read the filesystem, but
everyone learns that they have and thus distrusts that node.)  Of
course it only holds if there are multiple possible senders, delaying
an email from my home when I live alone doesn't help me.  But if there
are multiple possible senders, it feels like tacking on a
lesser-quality mix node at the beginning.
Another argument to it's utility is there is no easy way to disguise
the fact that you are sending a mix message.  Right now the only ways
I can think of hiding that fact would be to use mix bridges (some
entry remailer node that isn't published, akin to Tor's bridges) with
a protocol that looks as identical to SSL in a webbrowser as you can;
or to send them out over Tor.
I think the user-configurable time is the idea behind Alpha Mixing,
although I hope it's implemented better than in Type 1 Remailers.
Absolutely.  And on the sender end, I can't think of good ways to
obfuscate large messages.  The splitting technique of Mixmaster has
always felt like a bit of a hack (no offense), because someone doing
end to end correlation should be able to link those fairly easily.
For receiving large files, I think a client/server architecture where
you can choose to delete the message on the server, or download chunk
by laborious chunk over time would be advantageous[0].
[0] This might, might, even be an argument of added complexity by
splitting files, before compressing and encrypting them, so you can
download chunks 1-4 and (potentially) get a portion of the file in a
readable albeit incomplete format.

@_date: 2013-08-12 16:23:51
@_author: Tom Ritter 
@_subject: Information theoretically secure communication networks 
As Lance said, this is pretty close to what alt.anonymous.messages
evolved into in the 90s and early 00's.
I gave a talk two weeks ago looking at 10 years of messages there and
finding user errors, weak passwords, user-segmenting settings, and
traffic patterns.  Details are over here:

@_date: 2013-08-27 20:57:35
@_author: Tom Ritter 
@_subject: Metadata anonymization through time delayed email messaging. 
I don't know - if I'm performing physical or network surveillance of a
target, and I see a Mix message leave - that tells me something very
definite about the timing.  Obviously you wouldn't want to store the
message in plaintext, but if you encrypted it to the first hop, along
with the address, and a time to send (and tried your hardest to lie
about the timestamps on the filesystem); you can increase the
difficulty of learning something definite.  And I think that holds
even if the attacker does a physical intrusion and looks at the
filesystem. (It reminds me Rivest's FlipIp game - the attacker is
allowed to do a physical intrusion and read the filesystem, but
everyone learns that they have and thus distrusts that node.)  Of
course it only holds if there are multiple possible senders, delaying
an email from my home when I live alone doesn't help me.  But if there
are multiple possible senders, it feels like tacking on a
lesser-quality mix node at the beginning.
Another argument to it's utility is there is no easy way to disguise
the fact that you are sending a mix message.  Right now the only ways
I can think of hiding that fact would be to use mix bridges (some
entry remailer node that isn't published, akin to Tor's bridges) with
a protocol that looks as identical to SSL in a webbrowser as you can;
or to send them out over Tor.
I think the user-configurable time is the idea behind Alpha Mixing,
although I hope it's implemented better than in Type 1 Remailers.
Absolutely.  And on the sender end, I can't think of good ways to
obfuscate large messages.  The splitting technique of Mixmaster has
always felt like a bit of a hack (no offense), because someone doing
end to end correlation should be able to link those fairly easily.
For receiving large files, I think a client/server architecture where
you can choose to delete the message on the server, or download chunk
by laborious chunk over time would be advantageous[0].
[0] This might, might, even be an argument of added complexity by
splitting files, before compressing and encrypting them, so you can
download chunks 1-4 and (potentially) get a portion of the file in a
readable albeit incomplete format.

@_date: 2013-12-13 19:31:21
@_author: Tom Ritter 
@_subject: Joke 
I doubt it - abuse through Tor is a legitimate problem.  Wikipedia blocks
editing from Tor for the same reason.
There are ideas for solving this though, and it would be cool to see more
ideas, and more fleshing out of them.  Mike Hearn has talked about having
people make a bitcoin deposit for an account, and after so much time of
legitimate use, the deposit is refunded.  Before that, if it's used for
abuse, the deposit is kept by the service.

@_date: 2013-12-14 02:55:13
@_author: Tom Ritter 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
I can answer for Cryptopocalype. :)  I had a follow-up blog post after
Black Hat, but the crux is looking for the next crypto black swan. Joux's
work in optimizing the function field sieve for fields of a small
characteristic has been a significance improvement kind of out of left
field. If he or anyone else made improvements to the FFS for fields of a
large  characteristic or the GNFS - we would be in a bad way. The security
margin on the ECDLP is greater than DL or factoring and while we've got the
algorithms, the implementations are sometimes missing and the ability to
pivot, in software update mechanisms, in CAs, everywhere - is completely
missing. ECC has other attributes that make it attractive too, so let's get
the plumbing ready, so we can support a quick pivot away from RSA and over
to ECC if we have to.
I copied Justin rather than (poorly) summarize his work.
(Just landed, sent from the baggage claim, excuse brevity)

@_date: 2013-12-14 15:23:50
@_author: Tom Ritter 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
This is different from the normal 'repeated/non-random k leads to private
key', is it not?  Is there a paper/reference I can read more about this

@_date: 2013-12-15 14:23:09
@_author: Tom Ritter 
@_subject: Gmail's receiving mostly authenticated email 
I saw that article too, and thought it was interesting, but I noticed
something odd in their statistics:
91.4% of ***NON-SPAM*** emails sent to Gmail users come from
authenticated senders, which helps Gmail filter billions of
impersonating email messages a year from entering our users’ inboxes.
More specifically, the 91.4% of the authenticated ***NON-SPAM***
emails sent to Gmail users come from senders that have adopted one or
more of the following email authentication standards: DKIM (DomainKey
Identified Email) or SPF (Sender Policy Framework).
""" (emphasis mine)
So first Google runs their pretty-good-but-not-perfect spam filtering,
then they look at what they're categorized as non-spam to generate
those statistics.  The ham (not spam) emails that are miscategorized
are much more likely to be omitting SPF/DKIM, so there's a bit of
selection bias occurring.
Also, for what it's worth, SPF isn't related to crypto at all, and is
ridiculously easy to set up for 'normal' domain admins.  (That is,
domain admins with a couple well-known SMTP servers, and not some
crazy distributed architecture.)  There's a great calculator online
for it here: There's some tricky questions people may not know the answer to, but
omitting answers will only create a more _permissive_ policy, rather
than run the risk of borking your email.

@_date: 2013-12-22 13:14:36
@_author: Tom Ritter 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
I'm confused, but maybe missing something?  The article says:
The stakes rose when more technology companies adopted RSA's methods
and Internet use began to soar. The Clinton administration embraced
the Clipper Chip, envisioned as a mandatory component in phones and
computers to enable officials to overcome encryption with a warrant.
RSA led a fierce public campaign against the effort, distributing
posters with a foundering sailing ship and the words "Sink Clipper!"
A key argument against the chip was that overseas buyers would shun
U.S. technology products if they were ready-made for spying. Some
companies say that is just what has happened in the wake of the
Snowden disclosures.
The White House abandoned the Clipper Chip and instead relied on
export controls to prevent the best cryptography from crossing U.S.
borders. RSA once again rallied the industry, and it set up an
Australian division that could ship what it wanted.
"We became the tip of the spear, so to speak, in this fight against
government efforts," Bidzos recalled in an oral history.
RSA, meanwhile, was changing. Bidzos stepped down as CEO in 1999 to
concentrate on VeriSign, a security certificate company that had been
spun out of RSA. The elite lab Bidzos had founded in Silicon Valley
moved east to Massachusetts, and many top engineers left the company,
several former employees said.
It seems like Bidzous was out of RSA long before DUAL EC PRNG was even
proposed, and was in fact campaigning and strategizing against RSA
while he was there.  Where are references to other accusations or

@_date: 2013-12-13 19:31:21
@_author: Tom Ritter 
@_subject: Joke 
I doubt it - abuse through Tor is a legitimate problem.  Wikipedia blocks
editing from Tor for the same reason.
There are ideas for solving this though, and it would be cool to see more
ideas, and more fleshing out of them.  Mike Hearn has talked about having
people make a bitcoin deposit for an account, and after so much time of
legitimate use, the deposit is refunded.  Before that, if it's used for
abuse, the deposit is kept by the service.

@_date: 2013-12-14 02:55:13
@_author: Tom Ritter 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
I can answer for Cryptopocalype. :)  I had a follow-up blog post after
Black Hat, but the crux is looking for the next crypto black swan. Joux's
work in optimizing the function field sieve for fields of a small
characteristic has been a significance improvement kind of out of left
field. If he or anyone else made improvements to the FFS for fields of a
large  characteristic or the GNFS - we would be in a bad way. The security
margin on the ECDLP is greater than DL or factoring and while we've got the
algorithms, the implementations are sometimes missing and the ability to
pivot, in software update mechanisms, in CAs, everywhere - is completely
missing. ECC has other attributes that make it attractive too, so let's get
the plumbing ready, so we can support a quick pivot away from RSA and over
to ECC if we have to.
I copied Justin rather than (poorly) summarize his work.
(Just landed, sent from the baggage claim, excuse brevity)

@_date: 2013-12-14 15:23:50
@_author: Tom Ritter 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
This is different from the normal 'repeated/non-random k leads to private
key', is it not?  Is there a paper/reference I can read more about this

@_date: 2013-12-15 14:23:09
@_author: Tom Ritter 
@_subject: Gmail's receiving mostly authenticated email 
I saw that article too, and thought it was interesting, but I noticed
something odd in their statistics:
91.4% of ***NON-SPAM*** emails sent to Gmail users come from
authenticated senders, which helps Gmail filter billions of
impersonating email messages a year from entering our users’ inboxes.
More specifically, the 91.4% of the authenticated ***NON-SPAM***
emails sent to Gmail users come from senders that have adopted one or
more of the following email authentication standards: DKIM (DomainKey
Identified Email) or SPF (Sender Policy Framework).
""" (emphasis mine)
So first Google runs their pretty-good-but-not-perfect spam filtering,
then they look at what they're categorized as non-spam to generate
those statistics.  The ham (not spam) emails that are miscategorized
are much more likely to be omitting SPF/DKIM, so there's a bit of
selection bias occurring.
Also, for what it's worth, SPF isn't related to crypto at all, and is
ridiculously easy to set up for 'normal' domain admins.  (That is,
domain admins with a couple well-known SMTP servers, and not some
crazy distributed architecture.)  There's a great calculator online
for it here: There's some tricky questions people may not know the answer to, but
omitting answers will only create a more _permissive_ policy, rather
than run the risk of borking your email.

@_date: 2013-12-22 13:14:36
@_author: Tom Ritter 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
I'm confused, but maybe missing something?  The article says:
The stakes rose when more technology companies adopted RSA's methods
and Internet use began to soar. The Clinton administration embraced
the Clipper Chip, envisioned as a mandatory component in phones and
computers to enable officials to overcome encryption with a warrant.
RSA led a fierce public campaign against the effort, distributing
posters with a foundering sailing ship and the words "Sink Clipper!"
A key argument against the chip was that overseas buyers would shun
U.S. technology products if they were ready-made for spying. Some
companies say that is just what has happened in the wake of the
Snowden disclosures.
The White House abandoned the Clipper Chip and instead relied on
export controls to prevent the best cryptography from crossing U.S.
borders. RSA once again rallied the industry, and it set up an
Australian division that could ship what it wanted.
"We became the tip of the spear, so to speak, in this fight against
government efforts," Bidzos recalled in an oral history.
RSA, meanwhile, was changing. Bidzos stepped down as CEO in 1999 to
concentrate on VeriSign, a security certificate company that had been
spun out of RSA. The elite lab Bidzos had founded in Silicon Valley
moved east to Massachusetts, and many top engineers left the company,
several former employees said.
It seems like Bidzous was out of RSA long before DUAL EC PRNG was even
proposed, and was in fact campaigning and strategizing against RSA
while he was there.  Where are references to other accusations or

@_date: 2013-12-13 19:31:21
@_author: Tom Ritter 
@_subject: Joke 
I doubt it - abuse through Tor is a legitimate problem.  Wikipedia blocks
editing from Tor for the same reason.
There are ideas for solving this though, and it would be cool to see more
ideas, and more fleshing out of them.  Mike Hearn has talked about having
people make a bitcoin deposit for an account, and after so much time of
legitimate use, the deposit is refunded.  Before that, if it's used for
abuse, the deposit is kept by the service.

@_date: 2013-12-14 02:55:13
@_author: Tom Ritter 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
I can answer for Cryptopocalype. :)  I had a follow-up blog post after
Black Hat, but the crux is looking for the next crypto black swan. Joux's
work in optimizing the function field sieve for fields of a small
characteristic has been a significance improvement kind of out of left
field. If he or anyone else made improvements to the FFS for fields of a
large  characteristic or the GNFS - we would be in a bad way. The security
margin on the ECDLP is greater than DL or factoring and while we've got the
algorithms, the implementations are sometimes missing and the ability to
pivot, in software update mechanisms, in CAs, everywhere - is completely
missing. ECC has other attributes that make it attractive too, so let's get
the plumbing ready, so we can support a quick pivot away from RSA and over
to ECC if we have to.
I copied Justin rather than (poorly) summarize his work.
(Just landed, sent from the baggage claim, excuse brevity)

@_date: 2013-12-14 15:23:50
@_author: Tom Ritter 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
This is different from the normal 'repeated/non-random k leads to private
key', is it not?  Is there a paper/reference I can read more about this

@_date: 2013-12-15 14:23:09
@_author: Tom Ritter 
@_subject: Gmail's receiving mostly authenticated email 
I saw that article too, and thought it was interesting, but I noticed
something odd in their statistics:
91.4% of ***NON-SPAM*** emails sent to Gmail users come from
authenticated senders, which helps Gmail filter billions of
impersonating email messages a year from entering our users’ inboxes.
More specifically, the 91.4% of the authenticated ***NON-SPAM***
emails sent to Gmail users come from senders that have adopted one or
more of the following email authentication standards: DKIM (DomainKey
Identified Email) or SPF (Sender Policy Framework).
""" (emphasis mine)
So first Google runs their pretty-good-but-not-perfect spam filtering,
then they look at what they're categorized as non-spam to generate
those statistics.  The ham (not spam) emails that are miscategorized
are much more likely to be omitting SPF/DKIM, so there's a bit of
selection bias occurring.
Also, for what it's worth, SPF isn't related to crypto at all, and is
ridiculously easy to set up for 'normal' domain admins.  (That is,
domain admins with a couple well-known SMTP servers, and not some
crazy distributed architecture.)  There's a great calculator online
for it here: There's some tricky questions people may not know the answer to, but
omitting answers will only create a more _permissive_ policy, rather
than run the risk of borking your email.

@_date: 2013-12-22 13:14:36
@_author: Tom Ritter 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
I'm confused, but maybe missing something?  The article says:
The stakes rose when more technology companies adopted RSA's methods
and Internet use began to soar. The Clinton administration embraced
the Clipper Chip, envisioned as a mandatory component in phones and
computers to enable officials to overcome encryption with a warrant.
RSA led a fierce public campaign against the effort, distributing
posters with a foundering sailing ship and the words "Sink Clipper!"
A key argument against the chip was that overseas buyers would shun
U.S. technology products if they were ready-made for spying. Some
companies say that is just what has happened in the wake of the
Snowden disclosures.
The White House abandoned the Clipper Chip and instead relied on
export controls to prevent the best cryptography from crossing U.S.
borders. RSA once again rallied the industry, and it set up an
Australian division that could ship what it wanted.
"We became the tip of the spear, so to speak, in this fight against
government efforts," Bidzos recalled in an oral history.
RSA, meanwhile, was changing. Bidzos stepped down as CEO in 1999 to
concentrate on VeriSign, a security certificate company that had been
spun out of RSA. The elite lab Bidzos had founded in Silicon Valley
moved east to Massachusetts, and many top engineers left the company,
several former employees said.
It seems like Bidzous was out of RSA long before DUAL EC PRNG was even
proposed, and was in fact campaigning and strategizing against RSA
while he was there.  Where are references to other accusations or

@_date: 2013-02-08 16:35:08
@_author: Tom Ritter 
@_subject: [liberationtech] Bellovin, Blaze, Clark, Landau 
When law enforcement relies on vulnerabilities in the system (be it
protocols, operating systems, applications, or web sites), they are
incentivized to keep it insecure.  If it were secure, how would they
get in?
Would the FBI patch their own systems against the bugs they know
about?  How would they control that information across all their
systems?  (This is an old hackers' puzzle: if you had an OpenSSH 0day,
would you patch yourself against it?)
If I were a communications provider (e.g. Silent Circle), and I found
that the FBI was hacking me to learn customer data... what is my
recourse?  To borrow from the CFAA, the FBI is certainly performing
unauthorized access or exceeding authorized access to a computer
system.  Am I allowed to kick them out? Sue them? What if they
accidently crash a system because they're crappy exploit writers?
Just like when Matt Blaze wrote it in Wired, this feels like a
mistimed April Fools joke.
Unsubscribe, change to digest, or change password at:
