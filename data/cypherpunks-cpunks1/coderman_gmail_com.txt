
@_date: 2005-08-22 15:26:48
@_author: coderman 
@_subject: [declan@well.com: [Politech] Montana Supreme Court justice 
the state of oregon just passed a law (yet to be put into effect) that
requires a prescription from a doctor for all sudafed (pseudo
ephedrine) purchases.  the problem isn't drug addicts killing
themselves with corrosive fluids, as this would be a problem that
solves itself in short order, but rather that meth heads are idiotic
crime machines.  i've had numerous friends and acquaintances affected
by this (vehicles stolen or broken into, property damaged and/or
stolen, tweakers robbing at knife point, etc, etc) and it's getting
big brother isn't the answer, but when you get a lot of pissed off
citizens and overwhelmed police involved the solutions they settle for
are going to be ugly and invasive.
what a fucking mess...
* last week a tweaker out of jail for only a few weeks went around to
our hay growers neighbors and stole all sorts of random crap from
homes up and down the road he lived on.  everything from elk antlers
to hand made arrows for bow hunting, power tools loaded into a wheel
barrow, the most random crap.  the only reason he didn't hit our hay
grower was that last time he stole from them they went to his parents
house and told him "the next time your son steals from my home you'll
be attending a funeral".  now that's closer to an effective solution.

@_date: 2005-08-23 10:25:22
@_author: coderman 
@_subject: [declan@well.com: [Politech] Montana Supreme Court justice 
agreed; though i'd rather see them taking something less neurotoxic,
like dex or racemic amphetamine.
fortunately stimulants are some of the cheapest drugs to produce minus
all the regulatory overhead.
i'm saving this quote :)

@_date: 2005-12-02 11:25:30
@_author: coderman 
@_subject: [zooko@zooko.com: Re: [p2p-hackers] darknet ~= (blacknet, 
blacknets don't solve the hard problems related to large scale
anonymous digital cash, mainly identity management and strong
reputation metrics. (s/digital cash/non trivial resource exchange/g)
darknets, as the abused term appears to be currently employed, place
an emphasis on friendship as a trust/reputation metric and associate
that trusted channel with copyrighted content distribution. (even
though, as zooko pointed out, the original microsoft paper describing
darknets put more emphasis on the opaque nature of the overlay /
private traffic and gave little attention to the friend to friend
aspect of introduction / networking)
agreed. i'm even more convinced these terms are essentially worthless
as anything more descriptive than "a private network of some type".
embrace and extend the namespace!

@_date: 2005-12-02 13:54:10
@_author: coderman 
@_subject: a little bird told me 
makes sense to me. when your threat model includes $TLA with a DCS1000
observed to some degree.
fun to speculate about until the details are known.

@_date: 2005-12-20 13:38:54
@_author: coderman 
@_subject: Exactly what part... 
Glenn Henry at VIA gets my respect for putting crypto on the core of
commodity processors*.  Does hardware count? :)
*

@_date: 2005-12-22 10:47:07
@_author: coderman 
@_subject: [Clips] US CODE: Title 50,1811. Authorization during time 
faulty implementations meaning side channels leaking key material.  i
know that Glenn at Centaur/VIA is concerned about perceived pressures
to keep crypto out of processor cores.   consider this rumor but i'd
love to see someone follow up on this story.
with cache/memory timing, differential power analysis, even acoustic
side channels weakening software cipher implementations (and hardware
to a lesser degree) i can't help but wonder why Intel and AMD have not
deployed entropy, digests, block ciphers and Montgomery multipliers in
their cores - it takes very little die space and provides a huge
return.  makes my inner paranoid twitch...
with that said, i think it's clear that a properly designed crypto
system could be considered secure.  the government still uses AES256
for their top secret datum, and the NSA license of ECC could be
interpreted as a vote of confidence in that PK system.  (or is this
just another ruse? :)
with ciphers and protocols maturing is the next frontier for
cypherpunks decentralized reputation and trust metrics applied to
process, persons, and systems?
the world around these theoretically secure ciphers is full of holes
as you describe.

@_date: 2005-12-22 12:33:36
@_author: coderman 
@_subject: [Clips] US CODE: Title 50,1811. Authorization during time 
this question has bothered me: why choose a cipher whose
implementation in most circumstances is subject to side channels when
there are others resistant to such attacks?
are side channels in flawed implementations the new backdoor of choice
(since insufficient key space and overt flaws are now unavailable)?
i don't see how hardware tokens / crypto ignition keys prevent human
abuses.  passwords and passphrases are useless (unless coupled with
tokens and used only for liveness detection) and vascular biometrics
are excellent for "who you are" type authentication coupled with
physical key "what you have" based auth.
this doesn't preclude the use of a single cipher though; key
management has always been the bane of strong crypto.
indeed; passwords/passphrases as sole authenticators should die. they
should always be coupled with physical tokens IMHO...

@_date: 2005-12-25 21:12:58
@_author: coderman 
@_subject: [arma@mit.edu: Re: EFF no longer funding Tor (was Re: ATTN: 
here is my preference:
- locate a store that provides pre paid mastercard/visa/amex , often
as gift cards or for internet payments.
- have someone buy one for you, buy one yourself incognito, or locate
a kiosk that dispenses and charges them like an ATM in reverse
(coinstar used to do this, though sadly that program was shut down)
- register the card via an anonymous hotspot / through tor? *grin* /
untraceable line (most of the cards work like debit/credit when
swiped, but if you want to use it for online / catalogue purchases or
put more than $500 on them you need to register via phone or website)
- create a pseudonymous identity and remember it, as you will need the
name and address later.
- send donation via the afore mentioned hotspot / untraceable line and enjoy!
P.S.  the lifecycle of these pre-paid card systems has been an
interest of mine since the late 90's.  it's weird how many of them
sprout up, last a year or two, and then disappear just as quickly as
they came.  surely there is a story behind this somewhere.  fraud? lack of interest?  the man keeping us down? :P~
P.P.S. using a hotspot anonymously can be a little tricky.  i'll let
you ponder this for a while...
P.P.P.S.  these work well for paying for VoIP service too, which gives
you a hard(er) to trace line, when used in conjunction with
$random_hotspots for situations where a phone is required.  remember
that the transaction for the VoIP gear should be anonymous as well
since the devices are identified by MAC ID.
ok, not simple, but seems to work well enough if you are cautious.  if
you are really paranoid you can layer these services until an adequate
depth of deception is in place.

@_date: 2005-12-30 12:38:49
@_author: coderman 
@_subject: Detect Spying on YOU 
cmon, who seriously thinks they can honey token the NSA/$TLA?
i bet they are laughing themselves silly over such amusing suggestions...

@_date: 2005-12-31 17:44:32
@_author: coderman 
@_subject: Detect Spying on YOU 
i could see some county sheriff's office doing something stupid like
that with seized evidence perhaps. ("ooh! here's a bookmark labeled
'sekrit stuff', let's check it out!")
but the NSA and any other intelligence agency worth half a shit is
going to have clue.
early this year i was collecting information on telecommunications and
electrical power distribution infrastructure to see how detailed a map
publicly available sources could provide to such facilities and the
trends/assessments possible when combining data sets for pattern
i had a number of custom search tools, bots, and databases built up
internally that pulled large amounts of GIS data, LERG, industry
investments/research, maps, press releases, product catalogues, web
searches, cached documents, etc. (court documents pertaining to
telecom and power industries are full of informative details,
especially when the redaction performed in PDF for confidentiality is
only visibly obscuring text [white on white] while keeping content in
place :)
after about 6 weeks and many 100*GBytes of traffic i noticed a
peculiar echo on my line begin abruptly one day.  i'm off an old
analog switch ESS style in rural oregon and this echo/line noise was
associated with my number only (not others off same CO).
i suspected this was a one way conference / tap, which is completely
undetectable for digital systems but alters the line characteristics
of an analog switched circuit.
this was the only hint ever given that i might be under scrutiny. given the nature of my internet usage and the *.gov sites used (among
others) it would have been clear to anyone watching what i was up to. the data mining programs 'rumored' to be in use by the various
government agencies would be able to detect this type of activity
easily, so i suspect this was visible to somebody.
even still, the only clue, if it is one, was the analog conference on
my line, and this was noticeable only because i'm still hanging off
antiquated analog equipment that is rarely in use today.
while i think honey tokens are an interesting approach to independent
evaluation of intelligence / surveillance process and capability, it
would be incredibly difficult to get any information out of such a
project.  NSA and others are very skilled at the one way function of
information: a lot goes in, very very little ever comes back out, and
even then it is tightly constrained.  (i would guess no other agency
the world over has "least privilege" mastered so thoroughly)
an interesting subject for discussion perhaps, but not really useful
in the real world (tm)...

@_date: 2005-12-31 18:32:33
@_author: coderman 
@_subject: [dave@farber.net: [IP] more on AP Story Justice Dept. 
i would count on it, as it's a good bet the answer is yes rather than no.
i'm working on a one time pad based IPsec key daemon with a similar
purpose to what you describe.  i'll be posting here for feedback when
it's ready but the basic premise is that it provides strong ephemeral
IPsec keying using one time pads previously exchanged between peers. as long as the pads are generated and secured properly[1] you don't
need to care if $TLA has kept your IPsec traffic archives in their
acres of computing machinery.
likewise, if large qubit quantum computers suddenly become feasible or
multi ring GCF gets really fast, you don't need to worry about past
key exchanges (also archived) being compromised, as with pub key based
ISAKMP implementations.
last, such a mode needs no open ports[2], so the attack surface for
remote exploitation is limited to the IP level - only authenticated
traffic is passed up the stack, everything else is dropped.
as long as your OTP's are truly random and never compromised, the key
exchange will be secure and the only way to attack your traffic
remotely will be brute force of AES256.
[1]. securing pads is really the crux of the issue here.  i'm using
modified linux distributions for key generation (a host with no
networking capability - kernel omits all network functionality) and
IPsec termination (boot from CD/DVD, require USB fob / hardware token
+ passphrase for auth to access pads stored in encrypted volume).
[2]. this is true with an explanation: for the initial session ICMP
payloads are sent in the clear (not IPsec) to perform the encrypted
key exchange using OTP's.  once IPsec is initialized, ICMP is also
directed through IPsec via the SPD and future rekeying uses OTP's on
top of the existing IPsec SA.  i'll have more details later but in
short all traffic is authenticated or dropped, most of it
authenticated via IPsec, and the only exception being key exchange via
ICMP which is authenticated via OTP only until the first SA is
the advantage of using OTP's in addition to security is simplicity:
all buffers are fixed size, key material is small (per instance) and
the operations fast (no montgomery multiplication on very large
numbers).  even at a 1Hz rekey interval you could fit a years worth of
key exchange OTP in 100MBytes of storage.
the disadvantage is you probably need hardware entropy generation to
produce the pads in a reasonable time.  i'm using the VIA C5XL and C5P
processors for testing / runtime and these can produce more than
enough entropy for large pads without sucking /dev/random dry.
last but not least, the implicit out of band pad exchange with trusted
peers is reasonable for private group networking and other smaller
networks but would be very difficult to scale to a large organization.
 this is a feature in my eyes, as private group networks are what this
is intended for and meatspace pad exchange a desired requirement to
ensure trust is properly placed.

@_date: 2005-02-22 15:00:59
@_author: Martin Peck 
@_subject: Code name "Killer Rabbit": New Sub Can Tap Undersea Cables 
DWDM certainly makes it more complicated.  Of course, that same
technology allows them to send much more back. (Regarding the single
OC-3 mentioned previously.)
How they process and return the information is indeed the BIG SECRET. The old USSR taps used pods attached to the cables for recording and
were serviced periodically to pick up the collected data.
See also: If you look at the landing sites for various oceanic fiber cables you
will see that a great many of them are on "friendly" territory.  You
can be sure that these lines are tapped.  (Which brings up the issue
someone else mentioned a while ago.  We make a big deal about ECHELON
monitoring satellites, yet no one really cares about the tapping of
landing sites that carry many times more information?  Silly humans)
I presume the fiber tapping submarine is interested mainly in those
cables which don't land on friendly territory or the sections landed
between unfriendly sites. (E.g. not all data goes through all sites)
This would be a reasonable assumption.  But so would a number of other
possible techniques.  The great mystery continues...
Best regards,

@_date: 2005-11-14 02:41:44
@_author: coderman 
@_subject: [mnl@well.com: [Geowanking] cisco wi-fi geosurveillance 
high power works great to confuse these location tracking heuristics;
a 1W* shows up as 'right next to AP' on all radios in the vicinity.
a number of access point makers include this kind of location tracking
capability, for example Newbury Networks 'locale points':
 so
this applies to more than just the cisco/Airespace products.
there are tricks to work around high powered clients / rogue AP
signals but i haven't seen vendors implement them yet and exactly what
these workarounds are is left as an exercise for the reader. :)
best regards,
* this probably exceeds FCC EIRP limits but no one cares about the FCC
anymore right?

@_date: 2006-04-01 17:02:08
@_author: coderman 
@_subject: Bugged Humans 
Weapons that shoots microchips into the bodies of innocent civilians.
An artist smuggling blueprints for fake technology inside Chinas first
international weapons fair. Laughing arms traders drinking 30 year old
Chivas Regal among teenage models advertising new weapons. No, it4s
not a scary sci-fi movie. It4s a blast of an art show by Danish artist
Jakob S. Boeskov
sounds like a great time; the yes men infiltrate the military
industrial complex.
i'm dreaming sweet visions of honey tokens and trojan wares wrapped in
the latest pornographic steel-and-tech laden facades...
(and yeah, pass that shit this way John... :)
p.s, don't fret for hugo - bird flu pandemics and fiat currency fads
are our savior; hah!

@_date: 2006-04-07 13:55:01
@_author: coderman 
@_subject: [Clips] EFF: AT&T forwards all Internet traffic into NSA 
i'm interested to see the monetary incentives behind this
collaboration.  when your competitors (and every other tier-3) are
getting infrastructure investment and subsidy it is hard not to follow
suit despite ethical qualms (if any of these carriers actually had
ethical concerns before diverting traffic wholesale to the NSA).

@_date: 2006-04-07 16:44:09
@_author: coderman 
@_subject: Former AT&T technician Mark Klein Statement re: NSA Taps 
Wiretap Whistleblower's Statement
12:25 PM Apr, 07, 2006
Former AT&T technician Mark Klein has come forward to support the
EFF's lawsuit against AT&T for its alleged complicity in the NSA's
electronic surveillance. Here, Wired News publishes Klein's public
statement in its entirety.
Full story: Ex-AT&T Worker Tells Of NSA Op
[  ]
Statement: Mark Klein, April 6, 2006
My background:
For 22 and 1/2 years I worked as an AT&T technician, first in New York
and then in California.
What I observed first-hand:
In 2002, when I was working in an AT&T office in San Francisco, the
site manager told me to expect a visit from a National Security Agency
agent, who was to interview a management-level technician for a
special job. The agent came, and by chance I met him and directed him
to the appropriate people.
In January 2003, I, along with others, toured the AT&T central office
on Folsom Street in San Francisco -- actually three floors of an SBC
building. There I saw a new room being built adjacent to the 4ESS
switch room where the public's phone calls are routed. I learned that
the person whom the NSA interviewed for the secret job was the person
working to install equipment in this room. The regular technician work
force was not allowed in the room.
In October 2003, the company transferred me to the San Francisco
building to oversee the Worldnet Internet room, which included large
routers, racks of modems for customers' dial-in services, and other
equipment. I was responsible for troubleshooting problems on the fiber
optic circuits and installing new circuits.
While doing my job, I learned that fiber optic cables from the secret
room were tapping into the Worldnet circuits by splitting off a
portion of the light signal. I saw this in a design document available
to me, entitled "Study Group 3, LGX/Splitter Wiring, San Francisco"
dated Dec. 10, 2002. I also saw design documents dated Jan. 13, 2004
and Jan. 24, 2003, which instructed technicians on connecting some of
the already in-service circuits to the "splitter" cabinet, which
diverts some of the light signal to the secret room. The circuits
listed were the Peering Links, which connect Worldnet with other
networks and hence the whole country, as well as the rest of the
One of the documents listed the equipment installed in the secret
room, and this list included a Narus STA 6400, which is a "Semantic
Traffic Analyzer". The Narus STA technology is known to be used
particularly by government intelligence agencies because of its
ability to sift through large amounts of data looking for
preprogrammed targets. The company's advertising boasts that its
technology "captures comprehensive customer usage data ... and
transforms it into actionable information.... (It) provides complete
visibility for all internet applications."
My job required me to connect new circuits to the "splitter" cabinet
and get them up and running. While working on a particularly difficult
one with a technician back East, I learned that other such "splitter"
cabinets were being installed in other cities, including Seattle, San
Jose, Los Angeles and San Diego.
What is the significance and why is it important to bring these facts to light?
Based on my understanding of the connections and equipment at issue,
it appears the NSA is capable of conducting what amounts to
vacuum-cleaner surveillance of all the data crossing the internet --
whether that be peoples' e-mail, web surfing or any other data.
Given the public debate about the constitutionality of the Bush
administration's spying on U.S. citizens without obtaining a FISA
warrant, I think it is critical that this information be brought out
into the open, and that the American people be told the truth about
the extent of the administration's warrantless surveillance practices,
particularly as it relates to the internet.
Despite what we are hearing, and considering the public track record
of this administration, I simply do not believe their claims that the
NSA's spying program is really limited to foreign communications or is
otherwise consistent with the NSA's charter or with FISA. And unlike
the controversy over targeted wiretaps of individuals' phone calls,
this potential spying appears to be applied wholesale to all sorts of
internet communications of countless citizens.

@_date: 2006-04-10 12:37:56
@_author: coderman 
@_subject: [Clips] EFF: AT&T forwards all Internet traffic into NSA 
indeed; the laundering would be well implemented.  it's unlikely
highly visible raw cash infusions are the mechanism, more likely
ancillary benefits in equipment, "unrelated" contracts, facilities,
and other infrastructure.
i've seen too much infrastructure build out in these
post-telecom-crash years (esp. landing points and backbone/gigapop)
that just seems suspect.  perhaps this also falls under the various
"critical infrastructure protection" programs juiced with cash post
9/11 with passive taps as added bonus.

@_date: 2006-04-10 12:56:12
@_author: coderman 
@_subject: [Details on the AT&T/NSA wiretapping] 
not really, see below.
hardware monies buy things like FPGA driven filters, and these
hardware sniffers can in turn easily talk to banks of DDR.
there was a paper at USENIX or somewhere that showed Xilinx FPGA's
programmed with up to 700+ snort filter rules that could monitor a
10GigE stream in real time (yes, 10GigE) and scaled linear; just the
kind of mechanism well funded adversaries like to brute force. [i
can't find this paper anymore, does someone else have a link / copy?]
nallatech makes some nice FPGA hardware systems that would apply:
sure, this doesn't capture everything, but i suspect these filters are
tuned more for what they want to discard (p2p movie and warez traffic,
that'd eliminate quite a chunk, right?) than for what they want to
inspect.  (that is, what they want to inspect is everything they don't
consider useless and filter out)
on a side note, the recent interference in the Sourcefire and Check
Point merger makes you wonder, doesn't it?  what kind of
classification systems is the government using from Sourcefire that is
so sensitive it must be US owned?
they don't get to play on the equipment.  they only get to splice a fiber to it.
you can buy these kinds of high capacity hardware filtering /
classifying systems but they are insanely expensive.  like
 for example.

@_date: 2006-04-11 12:45:35
@_author: coderman 
@_subject: [Details on the AT&T/NSA wiretapping] 
this would be a fun exercise.  i wonder how much dark fiber is truly
"dark" these days...
a friend and i had a discussion on this very subject recently.  if you
don't mind the social network analysis but desire privacy of content,
does it matter if your encrypted comms stand out assuming they can't
break the cipher?
strong anonymity against an NSA threat model is very difficult;
sometimes privacy of content is sufficient.
in any case, i'd like to see encryption become the norm for even
trivial communications. like the Azureus enhancements Steve mentioned
this can be done in a simple and intuitive manner - it will just take
a lot of effort...

@_date: 2006-04-11 13:00:12
@_author: coderman 
@_subject: privacy threats 
if you had to rank each of the following in order from greatest to
least privacy invasion, how would you rank them?
- global eavesdroppers: NSA, etc.
- corporate aggregators: Acxiom, ChoicePoint, etc.
- social network sites and blogs: MySpace, LiveJournal, etc.
NSA is often a villain due to the shear breadth of data they monitor. But corporate privacy invaders can get a level of detail on your
person that even Big Brother envies.  and just how much personal
detail do people willingly broadcast to the world through social
networks and online journals (knowingly or unknowingly)?
how would you protect your privacy in each of these three contexts?

@_date: 2006-04-11 17:13:29
@_author: coderman 
@_subject: Privacy, Anonymity, and John Q. Public 
i've always liked Ian Goldberg's nymity slider as a description of
identity and how you disclose/leak/protect it.
if i were in your situation i think a high level overview of identity
and nymity (along the lines of the nymity slider) followed by specific
privacy enhancing technologies would work well.  perhaps covering:
- anonymous email (mixnets) and browsing/sessions (tor/onions)
- pseudonymous communication with aliases. (Off-the-Record?  blogs?)
- security and least privilege?
i'd be curious to know what you put together; this would be a helpful
resource for me and others i'm sure.

@_date: 2006-04-12 10:23:20
@_author: coderman 
@_subject: [Details on the AT&T/NSA wiretapping] 
this is an excellent idea.  i've played with the old WRT54G's a little
bit and it is certainly an amenable piece of equipment for this kind
of tweaking.  i've had problems trying to get too much on a single
unit as the flash space restrictions are tight but there is still
enough space to support a decent set of services (like openvpn and tor
as you mention).
this is the only other trouble i've had with them: the crypto bits
tend to get sluggish, esp. when negotiating EDH or generating keys.
(fortunately this isn't needed all too frequently)
i haven't looked at the GS but if they support WPA2 they should also
support AES; it would be nice if this AES engine could be used for
general offload in addition to WPA2 traffic :)
i'm going to have to get one to tinker with...

@_date: 2006-04-14 14:52:23
@_author: coderman 
@_subject: [Clips] Say Hello to Voiceprinting 
we used a system like this for a retail directory assistance service
called Infone.  the caller could authenticate by pin, by voice, or
both.  the voice enrollment required the caller to say "hello, infone"
three times or until a suitable voice print could be attained.
then when the caller accessed the system they would simply say "hello,
infone" and based on their incoming phone number the print was either
accepted or rejected.
the problem with these systems is that they can only select / identify
an individual from a small group of possibilities and line quality /
head colds can cause false negatives.
for example, if more than 10 people were associated with an account
the user had to enter a PIN to identify them, and then provide the
"hello, infone" voice print for further authentication.
it is also a non-trivial matter to tune the threshold for
success/failure appropriately for a given set of users.  this is all
based on probabilities so you need to set the threshold high enough
that the risk of false positives (impostors) is low enough to keep
security/losses at acceptable limits while also preventing excessive
numbers of false negatives that will annoy and aggravate your
still, the tech keeps getting (incrementally) better and it does
provide an additional layer of defence.  i'm not sure the currently
excessive costs associated with this technology are worth the benefit
though. (there are basically two companies who specialize in this
stuff (they've bought up all the rest) and they charge a premium for
these services and technologies :)

@_date: 2006-04-21 14:41:25
@_author: coderman 
@_subject: [jamuir@scs.carleton.ca: [Geowanking] IP geolocation] 
i believe you can do this with flash as well, and javascript should
probably be disabled for good measure along with any other active
browsers are a horrible interface from a security and privacy
perspective.  i've actually toyed with using lynx/links as requesting
agent saving to text with a caching proxy to constrain the various
info leakage holes that might be exploited in a browser used for
anonymous surfing. (got distracted by other tasks before getting it
into a usable state)
i'd be curious to know how various people / projects are attacking
this kind of leakage.

@_date: 2006-12-04 15:21:17
@_author: coderman 
@_subject: Post quantum reality 
looks like it will be Q1 2007 with 16 qubits:
  regarding the deafening silence (where outright dismissal is not used)
in crypto circles about AQC: at what point does skepticism turn into
denial?  *grin*
a nice overview: Aharonov, et al. [3] showed that a slightly more general formulation
of adiabatic algorithms, when used for quantum-state generation, is in
fact universal for QC. Designing quantum algorithms via quantum-state
generation is a novel and potentially important direction, because it
ties into classical algorithm design techniques using Markov chains
and techniques such as bounds on conductance and spectral gaps. As a
first step, it would be interesting to even give such an algorithm for
solved problems such as quadratic residuosity or discrete logarithms.
hardware entropy++

@_date: 2006-12-07 10:59:44
@_author: coderman 
@_subject: redgene might be gone 
ouch.  was it a middle or exit?  were tor keys on disk in plaintext?

@_date: 2006-12-16 00:27:50
@_author: coderman 
@_subject: Disguising a Tor node? 
see there are effective ways to manage this risk.  i'm not keen on posting
details here but perhaps off the record or at a later date.  you do
need to be willing to drop a suspect host, so mitigation is mainly
centered on secure initialization and subsequent vigilant monitoring
to decide when to cut out.  there are probably a thousand more
significant risks from host and application security angles, but
physical security is indeed tricky/severely limited in a remote
dedicate server scenario.
heheh, curious yellow raises its head again...  this has always been a
favorite for censorship resistance and plausible deniability.
it works ok; the processor struggles with the crypto (read: latency
and constant max load) but otherwise tolerable.  i've thought about
making a "Tor spot" configuration for access points, where transparent
http/tcp and dns proxy through Tor is provided for all associated
clients.  how useful would such a thing be?  (perhaps
personaltelco-free / personaltelco-anon dual service?)
the trade-off's and design constraints are more complicated and
context dependant.  read the draft blocking resistant Tor design
paper, it covers all these topics and provides a mostly reasonable
approach (the devil is in the details, as always...)

@_date: 2006-02-03 08:51:18
@_author: coderman 
@_subject: [smb@cs.columbia.edu: serious threat models] 
not too hard, actually.  softswitching makes this kind of hi jinx
relatively easy, and the Cirpack switching system Vodafone uses is
commonly available (to those steeped in EU telco at least).
[see  ]
i test systems like this from excel/lucent that use a unix host
controller communicating with one or more switch chassis full of
blades for spans of T1/E1, SS7, etc.  they send well defined packets
over ethernet to configure switch spans and perform call handling. it's an ugly binary protocol, like most are, but easily manipulated.
if you knew what you were doing it would be straightforward to insert
a promiscuous device on the LAN or add a process on the unix host used
by the softswitch that listened for incoming calls from a given set of
MIN's and one way conference these calls to a third party*.  if you
had access to a current version of the softswitch software itself for
modification it would be even easier (most companies license sources
and tailor or customize the software to run these switches so it's not
quite as simple as a generic drop in replacement).
it took "a professional" to do this, sure, but the number of people
skilled enough to pull this off is not a small number.
* the pre paid phones were probably vodafone as well, so that transit
for the conference'd calls was all on the same network and would thus
avoid using circuits from other carriers which would need to be
accounted for. (that is to say, it would be much easier to hide these
conferences as long as they stayed in network, rather than tying up
spans to external carriers which would probably trigger accounting

@_date: 2006-02-03 14:26:18
@_author: coderman 
@_subject: [smb@cs.columbia.edu: serious threat models] 
i stand corrected. media reports have indicated Ericsson Mobile
Softswitch was the software in question:
pretty much any softswitch technology is vulnerable to this type of attack.
see also:  , although some of
this description is a bit misleading or applies to a particular
architecture.  note that some carriers, like Sprint, build their own
softswitching systems in house.  presumably these would be more
resistant to tampering as the detailed information required to mount
such an attack is protected via trade secret and non disclosure.

@_date: 2006-02-07 10:06:24
@_author: coderman 
@_subject: [Stalking by Cellphone] 
remember those cell phone number history sales?  that same information
feed contains tower identifiers for every call placed.  those
identifiers in turn can be linked to GPS coordinates and
inter|extrapolated location of the caller, thus the 150 yard accuracy.
 (this is how some carriers are approaching E911 as well).
does anyone really expect strong privacy from any telecommunications
provider these days?  time to roll your own...

@_date: 2006-02-10 05:25:29
@_author: coderman 
@_subject: [declan@well.com: [Politech] Feingold, Kennedy ask AT&T and 
executive summary
telco's that let NSA tap freely:
- Adelphia Communications
- AOL Time Warner
- AT&T
- Cable & Wireless
- Charter Communications
- Cingular Wireless
- Citizens Communications
- Cogent Communications
- Global Crossing
- Google [picking their battles?]
- Level 3
- Microsoft
- NTT Communications
- Qwest Communications
- SAVVIS Communications
- Sprint Nextel
- T-Mobile USA
- United Online
- Verizon Communications
- XO Communications
- Yahoo
those tap'd against their will :)
- BellSouth Communications
- Cablevision Systems
- CenturyTel
- Comcast
- Cox Communications
- EarthLink
that should be a decent feed into the colorado processing center where
ADVISE will be running.[1]
1.  - "US plans
massive data sweep; Little-known data-collection system could troll
news, blogs, even e-mails."

@_date: 2006-02-16 15:22:03
@_author: coderman 
@_subject: [Clips] Skype Use May Make Eavesdropping Passe 
yeah, better than nothing, but how far do you trust a faceless corp
peddling closed source warez?  (same goes for Google, etc.  the recent
announcement to make zPhone open source is a big win IMHO)
i'd love to see a high order analysis of these 256bit nonces used for
keying skype.  use of entropy on windoze has traditionally been pretty
my favorite example to date:  -
"Strange Attractors and TCP/IP Sequence Number Analysis"
p.s.  speaking of google, can we all agree they are well on the path
of evil?  logging all chats?  multiple computer search?  glad i only
use gmail for public comms...

@_date: 2006-02-20 03:44:00
@_author: coderman 
@_subject: [funsec] "if you are not doing anything wrong, why should 
you worry about it?"
tell this to DHS.  bridge photography is an endagered past time...

@_date: 2006-02-21 03:59:00
@_author: coderman 
@_subject: [funsec] Court says cops can't yank video: 'Baby cam' 
catches arrest on tape
yes and no.  like the airline security measures which are "sensitive
security information" the photography of police might disclose
"sensitive law enforcement tactics" (whatever they call it in a given
and like the hassles/confiscation you get for photographing critical
infrastructure this too is now verboten.  the fact that this shields
authority from public oversight is simply a bonus, in their eyes.
(that would _never_ be the reason to ban such public disclosure, of
course; tis a mere side effect of keeping you safe :)
welcome to the police state.

@_date: 2006-02-22 07:35:41
@_author: coderman 
@_subject: [michael.holstein@csuohio.edu: Re: Anonymity questions] 
tor does not apply to an NSA threat model; your low latency mix/onion
== p0wn3d by NSA, sorry.
from the FAQ they say as much: [6.7
 ]
"As mentioned above, it is possible for an observer who can view large
portions of the Internet (called a 'global adversary') to be able to
correlate timings of all traffic entering and exiting the tor network,
and thus link arbitrary users. Tor does not defend against such a
threat model."
that said, i think IPsec is a great idea in as many places as possible
assuming your key distribution/exchange is well implemented.

@_date: 2006-02-24 11:09:14
@_author: coderman 
@_subject: TIA Lives On (so that's where it went...) 
TIA Lives On
By Shane Harris, National Journal
(c) National Journal Group Inc.
Thursday, Feb. 23, 2006
A controversial counter-terrorism program, which lawmakers halted more
than two years ago amid outcries from privacy advocates, was stopped
in name only and has quietly continued within the intelligence agency
now fending off charges that it has violated the privacy of U.S.
""It is no secret that some parts of TIA lived on behind the veil of
the classified intelligence budget.""
Research under the Defense Department's Total Information Awareness
program -- which developed technologies to predict terrorist attacks
by mining government databases and the personal records of people in
the United States -- was moved from the Pentagon's
research-and-development agency to another group, which builds
technologies primarily for the National Security Agency, according to
documents obtained by National Journal and to intelligence sources
familiar with the move. The names of key projects were changed,
apparently to conceal their identities, but their funding remained
intact, often under the same contracts.
It is no secret that some parts of TIA lived on behind the veil of the
classified intelligence budget. However, the projects that moved,
their new code names, and the agencies that took them over haven't
previously been disclosed. Sources aware of the transfers declined to
speak on the record for this story because, they said, the identities
of the specific programs are classified.
Two of the most important components of the TIA program were moved to
the Advanced Research and Development Activity, housed at NSA
headquarters in Fort Meade, Md., documents and sources confirm. One
piece was the Information Awareness Prototype System, the core
architecture that tied together numerous information extraction,
analysis, and dissemination tools developed under TIA. The prototype
system included privacy-protection technologies that may have been
discontinued or scaled back following the move to ARDA.
A $19 million contract to build the prototype system was awarded in
late 2002 to Hicks & Associates, a consulting firm in Arlington, Va.,
that is run by former Defense and military officials. Congress's
decision to pull TIA's funding in late 2003 "caused a significant
amount of uncertainty for all of us about the future of our work,"
Hicks executive Brian Sharkey wrote in an e-mail to subcontractors at
the time. "Fortunately," Sharkey continued, "a new sponsor has come
forward that will enable us to continue much of our previous work."
Sources confirm that this new sponsor was ARDA. Along with the new
sponsor came a new name. "We will be describing this new effort as
'Basketball,' " Sharkey wrote, apparently giving no explanation of the
name's significance. Another e-mail from a Hicks employee, Marc
Swedenburg, reminded the company's staff that "TIA has been terminated
and should be referenced in that fashion."
Sharkey played a key role in TIA's birth, when he and a close friend,
retired Navy Vice Adm. John Poindexter, President Reagan's national
security adviser, brought the idea to Defense officials shortly after
the 9/11 attacks. The men had teamed earlier on
intelligence-technology programs for the Defense Advanced Research
Projects Agency, which agreed to host TIA and hired Poindexter to run
it in 2002. In August 2003, Poindexter was forced to resign as TIA
chief amid howls that his central role in the Iran-Contra scandal of
the mid-1980s made him unfit to run a sensitive intelligence program.
It's unclear whether work on Basketball continues. Sharkey didn't
respond to an interview request, and Poindexter said he had no comment
about former TIA programs. But a publicly available Defense Department
document, detailing various "cooperative agreements and other
transactions" conducted in fiscal 2004, shows that Basketball was
fully funded at least until the end of that year (September 2004). The
document shows that the system was being tested at a research center
jointly run by ARDA and SAIC Corp., a major defense and intelligence
contractor that is the sole owner of Hicks & Associates. The document
describes Basketball as a "closed-loop, end-to-end prototype system
for early warning and decision-making," exactly the same language used
in contract documents for the TIA prototype system when it was awarded
to Hicks in 2002. An SAIC spokesman declined to comment for this
Another key TIA project that moved to ARDA was Genoa II, which focused
on building information technologies to help analysts and policy
makers anticipate and pre-empt terrorist attacks. Genoa II was renamed
Topsail when it moved to ARDA, intelligence sources confirmed. (The
name continues the program's nautical nomenclature; "genoa" is a
synonym for the headsail of a ship.)
As recently as October 2005, SAIC was awarded a $3.7 million contract
under Topsail. According to a government-issued press release
announcing the award, "The objective of Topsail is to develop
decision-support aids for teams of intelligence analysts and policy
personnel to assist in anticipating and pre-empting terrorist threats
to U.S. interests." That language repeats almost verbatim the
boilerplate descriptions of Genoa II contained in contract documents,
Pentagon budget sheets, and speeches by the Genoa II program's former
As early as February 2003, the Pentagon planned to use Genoa II
technologies at the Army's Information Awareness Center at Fort
Belvoir, Va., according to an unclassified Defense budget document.
The awareness center was an early tester of various TIA tools,
according to former employees. A 2003 Pentagon report to Congress
shows that the Army center was part of an expansive network of
intelligence agencies, including the NSA, that experimented with the
tools. The center was also home to the Army's Able Danger program,
which has come under scrutiny after some of its members said they used
data-analysis tools to discover the name and photograph of 9/11
ringleader Mohamed Atta more than a year before the attacks.
Devices developed under Genoa II's predecessor -- which Sharkey also
managed when he worked for the Defense Department -- were used during
the invasion of Afghanistan and as part of "the continuing war on
terrorism," according to an unclassified Defense budget document.
Today, however, the future of Topsail is in question. A spokesman for
the Air Force Research Laboratory in Rome, N.Y., which administers the
program's contracts, said it's "in the process of being canceled due
to lack of funds."
It is unclear when funding for Topsail was terminated. But earlier
this month, at a Senate Intelligence Committee hearing, one of TIA's
strongest critics questioned whether intelligence officials knew that
some of its programs had been moved to other agencies. Sen. Ron Wyden,
D-Ore., asked Director of National Intelligence John Negroponte and
FBI Director Robert Mueller whether it was "correct that when [TIA]
was closed, that several ... projects were moved to various
intelligence agencies.... I and others on this panel led the effort to
close [TIA]; we want to know if Mr. Poindexter's programs are going on
somewhere else."
Negroponte and Mueller said they didn't know. But Negroponte's deputy,
Gen. Michael V. Hayden, who until recently was director of the NSA,
said, "I'd like to answer in closed session." Asked for comment,
Wyden's spokeswoman referred to his hearing statements.
The NSA is now at the center of a political firestorm over President
Bush's program to eavesdrop on the phone calls and e-mails of people
in the United States who the agency believes are connected to
terrorists abroad. While the documents on the TIA programs don't show
that their tools are used in the domestic eavesdropping, and
knowledgeable sources wouldn't discuss the matter, the TIA programs
were designed specifically to develop the kind of "early-warning
system" that the president said the NSA is running.
Documents detailing TIA, Genoa II, Basketball, and Topsail use the
phrase "early-warning system" repeatedly to describe the programs'
ultimate aims. In speeches, Poindexter has described TIA as an
early-warning and decision-making system. He conceived of TIA in part
because of frustration over the lack of such tools when he was
national security chief for Reagan.
Tom Armour, the Genoa II program manager, declined to comment for this
story. But in a previous interview, he said that ARDA -- which
absorbed the TIA programs -- has pursued technologies that would be
useful for analyzing large amounts of phone and e-mail traffic.
"That's, in fact, what the interest is," Armour said. When TIA was
still funded, its program managers and researchers had "good
coordination" with their counterparts at ARDA and discussed their
projects on a regular basis, Armour said. The former No. 2 official in
Poindexter's office, Robert Popp, averred that the NSA didn't use TIA
tools in domestic eavesdropping as part of his research. But asked
whether the agency could have used the tools apart from TIA, Popp
replied, "I can't speak to that." Asked to comment on TIA projects
that moved to ARDA, Don Weber, an NSA spokesman said, "As I'm sure you
understand, we can neither confirm nor deny actual or alleged projects
or operational capabilities; therefore, we have no information to
ARDA now is undergoing some changes of its own. The outfit is being
taken out of the NSA, placed under the control of Negroponte's office,
and given a new name. It will be called the "Disruptive Technology
Office," a reference to a term of art describing any new invention
that suddenly, and often dramatically, replaces established
procedures. Officials with the intelligence director's office did not
respond to multiple requests for comment on this story.

@_date: 2006-02-25 08:52:24
@_author: coderman 
@_subject: AT&T's database of 1.92 trillion phone calls (Sprint does 
Sprint did this as well starting in the mid to late 90's but covering
a much deeper/wider data set.  for hypothetical example, mobile phones
add much more richness/detail at this scale when you consider the
location tracking aspects of monitoring radio signal levels, cell
tower associations (with associated GIS attributes) and hand off /
interpolation with multiple towers to get within a few hundred meters
or better.
they tapped their fiber at the backbone peering / termination points. company line was "monitoring packet headers/circuit|path ids only, for
routing optimization only, for a brief period of time only". (yes,
that means voice, data, leased optical circuits, all of it)
the under reported capabilities and extensive secrecy around this
project indicated other uses and other "collaborators" to assist with
processing and collection.
like anonymous hero in the story below calling out att i'm not going
into much detail (NDA's aren't the only stick they can beat you with,
keep digging all you guys/gals, this story just gets nastier the
deeper you look...
and keep blowing those whistles; we need some real accountability and
this "legalize it in retrospect" / "classify and compartmentalize it
into deep black" bullshit doesn't cut it.  (just be careful when you
do so, and that goes for reporters who receive the info - see the
previous post about holding reporters liable for merely possessing
classified materials)
i'm one of a small set of people who has been through a tour of the
Sprint world network headquarters / technical operations center and
salivated over the equipment present (not the new campus, not the old
HQ, it's below ground, and you either know what i'm talking about or
don't. i never got to see the geographic fail-over location but it had
to be just as impressive.  a nuke in this facility, the nerve core of
sprint enterprise, and you had recovery on the order of seconds via
this redundant remote "hot backup" data center. it still makes me go
'wow' this many years later.
the raw technology located here, and the processing it was capable of
doing, coupled with the fact that collection and subsequent analysis
was distributed and comprised centers like this one and others meant
public estimates of what was "possible to tap and process" at the
global level for even an NSA style adversary were almost always
grossly underestimated.  the closer you got to ballpark, the more
likely such scenarios were publicly declared "tin foil hat paranoia" NOTE: to the corporate legal departments, TLA spooks: all of the above
information is public in some form or another given enough digging;
please don't interpret this as proprietary or classified.  and please
don't send the white vans for remote technical surveillance like FBI
Infragard over the wireless security debacle; i'm no dummy.  (Hi Mary!
 i'm still waiting for that apology...)
P.S.  who is going to start an open public/community driven data
mining program to perform knowledge discovery against our tax payer
funded entities and public corporations and those who serve them? large scale decentralized / distributed computing is possible these
days with broadband and gaming boxes laying aplenty across this
nation.  perhaps if accountability will not be enforced by those in
power charged with doing so a more grass roots approach is
P.P.S is this funny / amusing (funsec) in a dark humor (haha, we got
so pwn'ed!) kinda way?  *grin*
ok, enough parens and commentary.  i've spoken my mind and said my peace.
---------- Forwarded message ----------
Taking Spying to Higher Level, Agencies Look for More Ways to Mine Data
He was alluding to databases maintained at an AT&T data center in Kansas,
which now contain electronic records of 1.92 trillion telephone calls, going
back decades. The Electronic Frontier Foundation, a digital-rights advocacy
group, has asserted in a lawsuit that the AT&T Daytona system, a giant
storehouse of calling records and Internet message routing information, was
the foundation of the N.S.A.'s effort to mine telephone records without a
An AT&T spokeswoman said the company would not comment on the claim, or
generally on matters of national security or customer privacy.
But the mining of the databases in other law enforcement investigations is
well established, with documented results. One application of the database
technology, called Security Call Analysis and Monitoring Platform, or Scamp,
offers access to about nine weeks of calling information. It currently
handles about 70,000 queries a month from fraud and law enforcement
investigators, according to AT&T documents.
A former AT&T official who had detailed knowledge of the call-record
database said the Daytona system takes great care to make certain that
anyone using the database - whether AT&T employee or law enforcement
official with a subpoena - sees only information he or she is authorized to
see, and that an audit trail keeps track of all users. Such information is
frequently used to build models of suspects' social networks.
The official, speaking on condition of anonymity because he was discussing
sensitive corporate matters, said every telephone call generated a record:
number called, time of call, duration of call, billing category and other
details. While the database does not contain such billing data as names,
addresses and credit card numbers, those records are in a linked database
that can be tapped by authorized users.
New calls are entered into the database immediately after they end, the
official said, adding, "I would characterize it as near real time."
According to a current AT&T employee, whose identity is being withheld to
avoid jeopardizing his job, the mining of the AT&T databases had a notable
success in helping investigators find the perpetrators of what was known as
the Moldovan porn scam.
In 1997 a shadowy group in Moldova, a former Soviet republic, was tricking
Internet users by enticing them to a pornography Web site that would
download a piece of software that disconnected the computer user from his
local telephone line and redialed a costly 900 number in Moldova.
While another long-distance carrier simply cut off the entire nation of
Moldova from its network, AT&T and the Moldovan authorities were able to
mine the database to track the culprits.
Fun and Misc security discussion for OT posts.
Note: funsec is a public and open mailing list.

@_date: 2006-02-26 17:52:06
@_author: coderman 
@_subject: Cell phone tracking services available in UK and elsewhere 
... and people wonder why i don't have a cell phone (this is one of
many reason, although the largest being annoyance rather than privacy
for me):
 Mobile tracking devices on trial
Click presenter
Your mobile phone is a beacon - a radio transmitter in a box.
Therefore it is possible to trace the signal and work out where it is.
There are now several web companies which will track your friends' and
family's phones for you, so you always know where they are.
But just how safe is it to make location details available online?
There are several reasons why you may want to track someone. You may
be a company wanting to keep tabs on employees during work hours, or a
parent wanting to check up on a child's whereabouts.
These sorts of tracking services, now available in the UK, get
information from the network about which cell your phone is currently
in, and, for a small fee, display the location on an online map.
As well as checking where a certain phone is right now, you can run
scheduled lookups, or snail trails, to record the phone's movements
throughout the day, and produce a report for you to peruse at your
Obviously you cannot just enter any mobile phone number and expect to
track someone.
First of all you need to prove your identity, via a credit card, and
then, crucially, the owner of the phone in question needs to consent
to being tracked.
The owner is sent a text message telling them about the tracking
request, to which they must reply.
The question is: is it possible to circumvent this security, and track
someone without their knowledge?
I attempted to find out, using regular contributor Guy Kewney, an
independent technology journalist and, for one day only, human guinea
I sent him on a tour of London. He could go anywhere he wanted, and I
planned to meet up with him later and tell him, hopefully, where he
had been.
Guy did not know that when I borrowed his phone for a few minutes
earlier in the day, I took the opportunity to register it on one of
the tracking services.
I received the incoming text message warning him about the tracking,
responded to it and then deleted it from his inbox.
When I gave him his phone back, Guy had no idea he was now in
possession of a consenting tracking device.
Hence, a little while later, I could watch him emerge from the tube at
the start of his tour.
But just borrowing someone's phone for a few minutes is too obvious a
loophole. It is one which has already been closed by an industry body
which oversees new technologies such as mobile tracking services.
Voluntary rules
The Mobile Broadband Group has drawn up a voluntary code of conduct
which the networks in the UK ask location providers to stick to.
One of the conditions of the code is that after a phone is registered
as a tracking device, reminder texts should be sent to the phone at
random intervals.
This way, it should be impossible for a malicious tracker to intercept
every reminder.
The problem is, those random reminders are not required to be sent
very frequently.
We tracked several phones over several days, and often had to wait for
a day or two before receiving a reminder message.
Hamish Macleod from the Mobile Broadband Group, who came up with the
code of conduct, argues this is enough.
He said: "We assessed this risk during the development of the code and
consulted obviously with all the experts that we did, and the schedule
of random alerts that we came up with we thought was adequate to
protect against the risks.
"This is a situation to be kept under review as the service is developed."
With more and more children owning mobile phones, special attention
needs to be given to who can track them.
If you are not a genuine parent or guardian, the code requires
location services to check that both the tracker and the person being
tracked can prove they are consenting adults.
Mr Macleod says: "The person that is to be located has to demonstrate
to the service provider they are at least 16 years old.
"They can do this through various channels, for example they can get a
credit card number which is used as a proxy for age verification, or
something like that."
At least, that is what is supposed to happen. But neither of the
services we tested asked the person being tracked to prove they were
an adult.
Although they did ask us for the age of the person we wanted to track,
they did not check we were telling the truth.
The companies were not following the letter of the code and, what is
more, no-one was holding them to account.
HAVE YOUR SAY
What do you make of the new mobile tracking services online? Is it
ever possible for regulation to keep up with technology?
Neither service would comment on this oversight.
Although the code of conduct was well intentioned, the Mobile
Broadband Group admits it will need refining as loopholes become
It also highlights the limits of such voluntary codes, and the
problems with policing them.
Jago Russell from the human rights group Liberty says: "We have
concerns in general about industry codes of practice. They aren't
legal regulation; they don't give the consumer an effective legal
remedy if the code of practice isn't complied with.
"So in many ways they're not really worth the paper they're written on."
As a result of our investigation, The Mobile Broadband Group is making
some changes to the code of conduct.
The frequency of the random reminders is going to be increased, and
the code will make clearer the appropriate way to check the age of the
Guy Kewney says: "It's a shame but then if you start regulating new
technology you usually fall down because people don't expect the
"The real problem is that you can't actually perceive the unintended
consequences of your technology change, so a hard and fast rule that
says 'don't do this' won't stop you doing that, in which case you've
wasted your time passing it."
Should we really be worried about being tracked by mobile phones?
Guy Kewney says: "You can worry about anything in this society. If I
wanted to track you, the easy way to do it is - well you've found one
way, but if they've closed that loophole or if it becomes tricky -
then I just hire a private detective.
---end cut---
does anyone have a list / site for good research on anonymous wireless
communications?  there seem to be few papers or projects dealing with
this particular transport method.
"We introduce anonymous wireless rings: a new computational model for
ring networks. In the well-known hardware ring each processor has two
buffers, one corresponding to each of its neighbors. In the wireless
ring each processor has a single buffer and cannot distinguish which
neighbor the arriving bit comes from. This feature substantially
increases anonymity of the ring. A priori it is not clear whether any
non-trivial computation can be performed on wireless rings. "
are wireless rings the most effective without excessive resources /

@_date: 2006-02-27 00:02:22
@_author: coderman 
@_subject: INTELLECT SURVEILLED: THORSTEIN VEBLEN AND THE ORGANS OF STATE 
INTELLECT SURVEILLED: THORSTEIN VEBLEN
AND THE ORGANS OF STATE SECURITY
Sylvia E. Bartley
selected quotes: ""
... Latent nativist fears in the United States surmounted class
divisions to forge a ground_swell of anticommunism. This fusion of
fear and myth, expressed as super-patriotism, would trample professed
democratic tenets and quickly led to blatant violations of
constitutional rights.
The United States Government first resorted to espionage against its
own citizens during the Civil War, while the Veblens were still
farming in Cato, Wisconsin. To perform this domestic surveillance, the
War Department hired the Pinkerton Detective Agency, which had
perfected such practices in previous anti-labor operations...
By the end of the first decade of the 20th century, political
detective units existed in most U.S. cities... In a climate of growing
war hysteria, the second decade of the century saw the rapid
development of collaboration between private and public police
networks nationwide...

@_date: 2006-02-27 09:05:09
@_author: coderman 
@_subject: [funsec] Re: AT&T's database of 1.92 trillion phone calls 
i'd have to agree, with regards to corporate or government entities
making strong individual privacy a priority _on their own accord_ with
this kind of applied information technology.[1]
so the only feasible solution is empowering users to take
responsibility for their own information security and privacy.  if
"johnny can't encrypt"[2] this is a very tall order indeed[3].
what would the ideal minimum amount of information exposed consist of
if you could apply usable security/encryption and privacy enhancing
technologies to the usual communications today (voice, text, video,
- no content of payloads, due to end to end encryption
- strong anonymous mix networks for non interactive messaging
- weakly anonymous low latency onion/relay networks for near real time messaging
- seamless wireless and sneaker net support to offload locally/out of
band whenever possible
you'd still be exposing:
- location of endpoints used (except in the strong and latent mix
scenario perhaps)
- distinct parties involved (social network analysis)
- volume of encrypted traffic exchanged
i suppose the real question is how long would it take to design and
implement (and the hardware to support it prevalent for all users).
5 years seems extremely optimistic given the difficulties involved.
[and i suppose this also means the paranoid will all become proficient
TSCM technicians.]
ah, we can dream :)
until then, the fraction of unusual end lusers making use of strong
privacy enhancing technologies will be a function of how annoying they
are to use vs. how annoying the government privacy invasion programs
become.  single digits for the near future...
[1.] "DoJ strikes back against Google (your privacy concerns are
unfounded (lol))"
  [2.] "NPR : E-Mail Encryption Rare in Everyday Use"
  at metzdowd.com/msg05769.html
[3.] " User Interaction Design for Secure Systems"
 MANDATORY REQUIREMENTS::
A. Path of Least Resistance. The most natural way to do any task should
also be the most secure way.
B. Appropriate Boundaries. The interface should expose, and the system
should enforce, distinctions between objects and between actions along
boundaries that matter to the user.
C. Explicit Authorization. A user's authorities must only be provided to
other actors as a result of an explicit user action that is understood
to imply granting.
D. Visibility. The interface should allow the user to easily review any
active actors and authority relationships that would affect
security-relevant decisions.
E. Revocability. The interface should allow the user to easily revoke
authorities that the user has granted, wherever revocation is
F. Trusted Path. The interface must provide an unspoofable and faithful
communication channel between the user and any entity trusted to
manipulate authorities on the user's behalf.
G. Identifiability. The interface should enforce that distinct objects
and distinct actions have unspoofably identifiable and distinguishable

@_date: 2006-02-27 09:48:21
@_author: coderman 
@_subject: A New Class of Unsafe Primes 
i'd be interested to know what you find out.
totally unrelated commentary:
i dreamed recently i was an old man with a failing liver
(E_TOO_MUCH_DEFCON)  performing one last bemused retrospective on life
before my session expired.  i chuckled over the use of public key
encryption in a world with common large qubit quantum computers: the
relative key strengths now in use were measured in killowatts of
computation sustained over a minimum time period for key pair
generation on dedicated hardware with open ended storage (meaning
whatever you could generate within a lifetime of key pair computation
could be stored reasonably on a common storage medium)
i recall a very strong key pair started at 64 kilowatts over 100 days
but was at least conjectured to require a coherent state (raw qubit
brute force) larger than anything possible to build in our solar
nonces, digests, symmetric secrets and one time pads for key exchange
were all still measured in bytes though... *grin*
something else of potential relevance:
Hi Bill --
I know there has been some discussion on whether _strong_ primes are
needed for _RSA_.  The definition of a strong prime is a little more
involved; c.f. the paper by Rivest and Silverman
[  and also available on Ron Rivest's
web page].  I was unaware, though, that there is a debate regarding the
use of safe primes for Diffie-Hellman.  My impression is that the use of
safe primes is generally accepted to be an important practice that
thwarts various attempts to compute a discrete log (e.g.
Pohlig-Hellman); also enough safe primes and generators are published --
one may utilize them in a protocol (assuming the people who published
the list are trusted not to have deliberately chosen prime groups for
which computing a discrete log is easier :)).
I'm also not sure how the choice of primes for Diffie-Hellman relates to
the complexity of factoring as you mentioned in your post.  As far as I
know, no one (in the open community at least) has discovered a
meaningful reduction in a standard model between the Diffie-Hellman
problem over a prime group and Factoring (nor has anyone proven that
such reductions cannot exist).  The closest thing I can think of is
trying to come up with the factorization of p-1 as you might want to do
in the Pohlig-Hellman algorithm -- but in that case, the complexity
would be prohibitive if p-1 had any large prime factors...
Are you referring to performing Diffie-Hellman over some other group?
Or is there a connection that you know of and can elaborate on?
Best Regards,
Zulfikar Ramzan
IP Dynamics, Inc.   Secure, Scalable Virtual Community Networks

@_date: 2006-02-27 10:14:49
@_author: coderman 
@_subject: Fwd: [funsec] Re: AT&T's database of 1.92 trillion phone calls 
Fwd: discussion on enabling and motivating end users to assume
responsbility for their own information security/privacy over the
communication and computing resources they use.
can we go ahead and state as fact that a capability model tied to a
pet name pattern / sticky note metaphor is required for strong least
privelege which in turn is mandatory for the secure user interface /
interaction requirements mentioned below?
[if you don't think caps and pet names should be mandatory, can you
provide a reasonable explanation of how key based capabilities and
pets names are less secure than the alternative you are describing?]
wow, that's a lot work to describe in detail (design) let alone even
attempt to implement.  (at least if you designed and implemented it
right once you should never need to implement again)
---------- Forwarded message ----------
i'd have to agree, with regards to corporate or government entities
making strong individual privacy a priority _on their own accord_ with
this kind of applied information technology.[1]
so the only feasible solution is empowering users to take
responsibility for their own information security and privacy.  if
"johnny can't encrypt"[2] this is a very tall order indeed[3].
what would the ideal minimum amount of information exposed consist of
if you could apply usable security/encryption and privacy enhancing
technologies to the usual communications today (voice, text, video,
- no content of payloads, due to end to end encryption
- strong anonymous mix networks for non interactive messaging
- weakly anonymous low latency onion/relay networks for near real time messaging
- seamless wireless and sneaker net support to offload locally/out of
band whenever possible
you'd still be exposing:
- location of endpoints used (except in the strong and latent mix
scenario perhaps)
- distinct parties involved (social network analysis)
- volume of encrypted traffic exchanged
i suppose the real question is how long would it take to design and
implement (and the hardware to support it prevalent for all users).
5 years seems extremely optimistic given the difficulties involved.
[and i suppose this also means the paranoid will all become proficient
TSCM technicians.]
ah, we can dream :)
until then, the fraction of unusual end lusers making use of strong
privacy enhancing technologies will be a function of how annoying they
are to use vs. how annoying the government privacy invasion programs
become.  single digits for the near future...
[1.] "DoJ strikes back against Google (your privacy concerns are
unfounded (lol))"
  [2.] "NPR : E-Mail Encryption Rare in Everyday Use"
  at metzdowd.com/msg05769.html
[3.] " User Interaction Design for Secure Systems"
 MANDATORY REQUIREMENTS::
A. Path of Least Resistance. The most natural way to do any task should
also be the most secure way.
B. Appropriate Boundaries. The interface should expose, and the system
should enforce, distinctions between objects and between actions along
boundaries that matter to the user.
C. Explicit Authorization. A user's authorities must only be provided to
other actors as a result of an explicit user action that is understood
to imply granting.
D. Visibility. The interface should allow the user to easily review any
active actors and authority relationships that would affect
security-relevant decisions.
E. Revocability. The interface should allow the user to easily revoke
authorities that the user has granted, wherever revocation is
F. Trusted Path. The interface must provide an unspoofable and faithful
communication channel between the user and any entity trusted to
manipulate authorities on the user's behalf.
G. Identifiability. The interface should enforce that distinct objects
and distinct actions have unspoofably identifiable and distinguishable

@_date: 2006-02-27 11:37:31
@_author: coderman 
@_subject: National Security, Secrecy, Diffusion of Responsibility, and 
speaking of least privilege,
what institution is more deserving of strong least privilege applied
to authorization and accountability than a the military-industrial
complex and it's government?
the current highly classified, highly compartmentalized, broad swath
privileges in place right now are akin to giving a company full of
employees a single shared account login and trying to apply any kind
of oversight and policy restriction.
what would a Key KOS government/industry look like?
full disclosure of all decisions and resource allocations (and
associated delegations involved if any) for all government activities
declared in advance and then denied until quorum based consensus as to
their reasonableness (?)
a fun exercise for thought, as anything you communicate (in any
medium/representation) is essentially a social (and thus political)
"A Fabric of Illegality"
Click here to return to the browser-optimized version of this page.
This article can be found on the web at
A Fabric of Illegality
[from the March 13, 2006 issue]
Now we know the truth: For months in 2002, when George W. Bush and his
top lieutenants were publicly insisting on their adherence to the
Geneva Conventions, they were privately torpedoing efforts by Alberto
Mora, the Navy's courageous general counsel, to prevent, and establish
accountability for, brutal treatment of detainees. Two years before
the publication of the Abu Ghraib photos, Mora confronted the
highest-level Pentagon officials over abuse of prisoners at Guantanamo
and warned the Administration that its interrogation policies invited
torture and cruelty. The New Yorker's Jane Mayer revealed Mora's
lonely campaign just as Kofi Annan and a team of United Nations
investigators declared Guantanamo a torture camp that should be closed
and its prisoners either tried or released.
If the Administration has so far been able to resist demands for
accountability, whether from the Pentagon's own lawyers or the UN, it
is because of the collusion of the courts and Congress in abuses both
international and within the United States. Exhibit A: the grotesque
February 16 ruling by US District Judge David Trager denying his
court's jurisdiction over the rendition to Syria and torture of
Canadian national Maher Arar, who spent nearly a year in secret
captivity (see David Cole on page 5). Exhibit B: the bipartisan effort
to avoid Congressional investigation of the NSA's warrantless
surveillance of American citizens.
Although key leaders remain angry at the White House for not seeking
Congressional approval for the NSA wiretap program, debate over
surveillance has been sidelined. Leaders from both parties are lining
up behind proposals to bleach the stain of illegality from warrantless
wiretaps--either by incorporating warrantless eavesdropping into the
Foreign Intelligence Surveillance Act or by simply declaring
warrantless taps legal. Lost is the simple fact that both plans
broaden domestic spying far beyond the Patriot Act and make hash of
the venerable constitutional demand for search warrants.
That Guantanamo and NSA spying on citizens--the Administration's
abuses abroad and at home--are part of the same fabric of illegality
was brought home by a February 14 House national security subcommittee
hearing. Led by Christopher Shays and Henry Waxman, the subcommittee
heard firsthand evidence of what becomes of truth-tellers in the Bush
military and intelligence services.
In this sense Mora was lucky: He was merely blocked at every turn. He
wasn't demoted like Specialist Samuel Provance, who was kicked
downstairs after confronting a general with horrifying details about
interrogations at Abu Ghraib. Mora wasn't declared by his bosses to be
mentally ill, like NSA whistleblower Russell Tice--who indicated to
the subcommittee that the agency's illegal "black ops" extend well
beyond the wiretap program. No one spread false rumors about Mora's
sex life, as the Defense Intelligence Agency did about Lieut. Col.
Anthony Shaffer after he revealed the extent of the government's
pre-9/11 knowledge about Mohamed Atta (gained through the "Able
Danger" data-mining program).
The dark arts of trashing whistleblowers, who are supposedly protected
by federal law, add yet another layer of illegality to the "war on
terror." Still, Congress and the courts dodge their responsibilities
while the White House maintains its right to stand above the law--and
torture, imprisonment without trial and warrantless spying on
Americans go on, and on.
---end cut---

@_date: 2006-02-27 11:56:48
@_author: coderman 
@_subject: hamachi p2p vpn nat-friendly protocol details 
authenticity and privacy
favorite quote:
">> Designing security protocols is hard...
Yes, it is. This is why I like it."
'Cypherpunks Write [Secure] Code!'
An open question for anyone reading this:
is the critically wounded, barely beating cypherpunks list languishing
in such a sad state due to apathy or impending irrelevance/death?  i
see embers of life awaiting some minimal votes of confidence (i'd go
so far as to offer sexual favors for a toad node back* :) but any kind
of renewed interest is meager at best.  [would a public list archive
help? an rss feed? a abridged list / digest? [ala kernel trap]]
such volatile times, so little interest...
 at metzdowd.com/msg05790.html
Alex Pankratov
Sun, 26 Feb 2006 07:18:15 -0800
The description on a page was not updated properly. Recent clients
use per-direction keys after they complete P2P KE.
Crypto suite is essentially just a protocol number. It requires
no authentication. If the server side responds with HELO.OK, it
means that it can comprehend specified protocol revision. Similar
to what happens during the SSH handshake.
It is not.
A protection against what kind of attack ?
Identity is used to specify which public key the client wants
to be authenticated with on the server side. Assuming it is
swapped in transition by a man in the middle, it would still
require an attacker to re-sign authentication hash in the
Assuming he has a private key to do that, he will effectively
succeed in authenticating under substituted ID. He then will
need to re-sign server's auth hash to complete the attack,
which is not going to happen.
There is an off chance that the attacker might swapped the
identity to one that has the same public key. The chances
of this happening are infinitely small unless an attacker
also has an access to victim's keypair, which becomes a
trivial attack case.
If you are referring to HMAC-SHA1 for authentication hashes, it
is a part of a crypto suite (protocol revision) spec.
This is the second revision of Hamachi system. First revision
was using SSL for cli-srv and IKE/ESP for p2p security. It was
a prototype and it soon become obvious that both SSL and IKE
were overkills for our purposes. We did not need certificate
authentication of SSL, we did not want to run our own auth
protocol over SSL/AnonDH, which would've increased the number
of packets per login sequence. We didn't need the flexibility
(ie complexity) of IKE either.
After stripping down IKE (ie removing SA negotiation, reworking
ID payloads and not doing quick mode), we essentially ended up
with a protocol that was also fit for securing cli-srv session.
It was further tweaked and replaced SSL.
I should probably add that I implemented IKE (v1) keying daemon
from scratch with all bells and wistles (NATT, extended MODP
groups, etc) at some point in the past. Some remnants of it
are still floating around, the library name was libike.
Yes, it is. This is why I like it.
 at metzdowd.com/msg05796.html
Travis H.
Sun, 26 Feb 2006 07:22:06 -0800
In SSL, the lack of authentication of the cryptosuite could be used to
convince a v3 client that it is communicating with a v2 server, and
the v3 server that it is communicating with a v2 client, causing them
to communicate using SSL v2, which is called the "version rollback
attack".  This is not relevant to the hamachi protocol because there
is no negotiation.  Nevertheless, authenticating the previous
plaintext fields once a secure channel is established is considered
good form.
In Schneier's "Practical Cryptography", he suggests computing the MAC
over the entire history of sent messages, which ensures that any
tampering is detected at the next MAC.  This is eventually what was
done in SSLv3, for reasons Tero alluded to and which are successfully
thwarted for the reasons you describe.
I sort of wonder at the utility of a TCP implementation of the p2p
VPN... tunnelling TCP over TCP is well known to be a Bad Thing with
regard to interaction of the TCP timeouts.
Aside:  Can anyone tell me why the constants used in ipad and opad for
HMAC were chosen?  If they're not arbitrary, I'd like to know the
rationale behind them.
 at metzdowd.com/msg05801.html
Alex Pankratov
Sun, 26 Feb 2006 07:24:20 -0800
Nonces and DH exponents are serialized using PER-style ASN.1 encoding.
So the whole concatenation is unambigious.
Just to be clear, Hamachi tunnels VPN/P2P traffic over UDP. TCP is
used for client-server session only.
VPN over TCP is bad for two reasons. One you listed, and another
is that it becomes trivial to DoS this kind of VPN. TCP packets
are not authenticated (unless MD5/BGP extension is used, which
is unlikely), so the state of VPN transport layer and consequently
the state of a tunnel can be altered by 3rd party.
That's why SSL VPNs make very little sense in non-proxied setups
and that's why (I'd guess) OpenVPN 'tweaked' SSL to run over UDP

@_date: 2006-02-27 13:03:21
@_author: coderman 
@_subject: FAQ: How to subscribe and or contribute to cypherpunks 
by popular demand (for some degree of popular that includes a few
emails to my inbox seeking additional information :)
::Question:: How do I observe/participate in cypherpunks list discussions?
subscription requests consist of a simple text body with the list name
and your email address sent to a special email list manager account.
a subscribe request typically looks like:
"subscribe cypherpunks coderman at gmail.com"
for example.
some popular/common list administration services/hosts are:
majordomo at jfet.org
majordomo at al-qaeda.net
[ maybe majordomo at toad.com ? :P ]
a full example just for clarification:
subscribe cypherpunks coderman at gmail.com
::Question:: what can i do to contribute?
anything that would be helpful / interesting to facilitate easier and
most useful conversations via this list:
- more nodes and more contributors, be that code, design or
philosophical tangents of tenuous relation to encryption or privacy.
- a public web based subscription interface for users
- a RSS/Atom/feed based distribution of list contents
- a sister best of / abridged / digest version of list traffic
distributed in daily and monthly digests.
- write secure code to protect your privacy and facilitate trusted
social interactions with your peers and associates.
- SEND ADDITIONAL COMMENTS / SUGGESTIONS TO THIS LIST :)

@_date: 2006-02-27 13:13:38
@_author: coderman 
@_subject: Fwd: [cap-talk] Re: [e-lang] Introducing Emily, 
forwarding an interesting discussion on the nature of a "secure
domain" where key based capabilities can be utilized securely.
When you get mired into threat models involving well fundend
adversaries using exotic interdiscplinary vulnerability assesment and
exploitation the definition of "secure domain" becomes extremely
verbose and difficult (some would argue effectively impossible for
anyone but large TLA's) given the amount of context required to state
security in the exotic threat model with sufficient trust and defense
in depth.
[exotic threat models == tempest, global active adversary, DoS/attacks
expending significant network and real world resources (very wide
spectrum attacks at high power), domain specific physical access side
channel attacks, etc, etc, etc in an ongoing cycle since we all know
these parameters change over time]
---------- Forwarded message ----------
, Capability Talk My main point is  below.  Please skip down to that if reading time
is limited.
  While I agree with the difficulties in preventing covert
communication, I don't more generally agree with "Don't forbid what
you can't prevent", at least in this instance.  If confinement is a
natural effect of tokenized permission transfers (e.g. via
capabilities) where capabilities to objects are bundled with the
permission to communicate to the server of whatever object the
capability grants access to, then it seems quite natural and
effective to include that permission to communicate along with the
permission to access the object.  It may well be that communication
is possible in any case (e.g. via a covert channel), but by bundling
it explicitly with a permission to access an object it makes other
communication outside that explicitly granted only possible by
extraordinary means such as covert channels - which are available in
any case.  In my opinion it's preferable to explicitly limit such
communication rather than simply give up in the face of covert
channels and open all communication.
I admit that I do find it amusing finding myself on this side of this
argument in that the network operating system that I designed and
implemented through much of the 1980s (NLTSS, e.g.:
) took the opposite position on this issue - arguing that the
'natural' condition of processes is to be able to freely communicate
on a general network and that only object access (not the
right/permission to communicate) should be limited by capability
transfers.  At some point I came to accept that I was wrong in taking
that approach, I think mostly as a result of dealing with so many
situations where limiting communication (e.g. with firewalls) can
indeed be useful, even accepting the potential presence of covert
channels.  I generally feel that covert channels are more of a
theoretical than a practical threat, except in cases of dealing with
quite sensitive information like classified information or sensitive
intellectual property or business information.
  I won't explicitly address the above means to prevent covert
channels except to say that given the history of analysis of covert
channels I'm somewhat skeptical of such efforts.
One thing I think it's important to keep clear is that the mechanisms
that have generally been discussed for covert channels require
cooperation on both ends of the channel.  No mechanisms that I'm
aware of have been demonstrated which 'force' communication from one
process into another unwilling recipient (e.g. to access an object
without explicit permission).
  My main reason for writing is to dispute this statement:
I hope in the above you are meaning that capabilities are useless too
 vs. being
useless in general.  Of course the primary use for capabilities is in
explicitly transferring permissions between processes (subjects,
active objects, domains, whatever you choose to call active computing
entities).  One such permission is the permission to communicate
which, in the strongest capability systems, always explicitly
accompanies any transferred capability.  That is, when a capability
is transmitted from one process to another the permissions of the
capability include the authority to communicate to whatever service
provides the explicit permissions granted by the capability.  For
example, a capability to a file includes permission to communicate to
the appropriate file server.  However, most permissions explicitly
transferred by capabilities are some form of object access beyond the
authority to communicate to the object server.
While it's true that in the face of covert channels the value of
transferring a permission to communicate via a capability (e.g. as
above the permission to communicate to a file server) may be somewhat
constrained (the process and the file server may be able to
communicate in any case via a covert channel), the primary value of
the capability in transferring permissions (in the example the
permission to access a file, which is not compromised by the presence
of covert channels) is still present.
Providing confinement in the face of covert channels is indeed a
difficult problem.  However, I think it's important not to suggest
that capability tokenized transfers of permissions have no value
simply because one permission, the permission to communicate, is
difficult to control (with or without capabilities).  Most
permissions are not so difficult to control and can be perfectly
adequately managed with capabilities.  I'm not alone in arguing that
tokenizing permissions via capabilities provides many advantages over
conveying permissions by other means such as access lists or ambient
authority mechanisms (e.g. users/groups and permission
bits/configurations for users/groups).  These values of capability
transfers are not rendered useless simply because covert channels
limit the ability of capabilities to also manage the permission to communicate.
You (Constantine Plotnikov) may be arguing that a capability
infrastructure can't prevent a process from communicating permissions
via covert channels (e.g. by proxy).  This is true just as one can't
prevent data from being communicated via covert channels.  However,
this is again only dealing with the potential confinement value in
capabilities as distinct from what I see as their primary value in
providing for transfer of permissions for object access.  Covert
channels can thwart efforts at confinement, but they cannot thwart
efforts to limit object access to those processes which have been
explicitly granted access - even if via a covert channel through a proxy means.
--Jed cap-talk mailing list
cap-talk at mail.eros-os.org

@_date: 2006-02-27 13:15:49
@_author: coderman 
@_subject: FAQ: How to subscribe and or contribute to cypherpunks 
i interpreted that as an invitation to ping you via email every week
or so until i see a draft or document posted / linked to here :)

@_date: 2006-02-28 10:55:20
@_author: coderman 
@_subject: Fwd: Abridged -> Financial Cryptography Update: Identity on the 
user centric identity management is coming.  big improvements here but
i'm going to dismiss it by saying the InfoCard system is still managed
by a huge proprietary code base mired in an ecosystem of
the rootkits of the future will simply be hooking into userspace to
steal data off the pages you use to communicate over InfoCard secured
sessions back to your bank. (see the Haxdoor rootkit as an example of
That aside, what is this InfoCard? Well, that's not spelt out in so
many words as yet:
In the client user interface, each of the user's digital identities
used within the metasystem is represented by a visual "Information
Card" (a.k.a. "InfoCard", the source of this technology's codename).
The user selects identities represented by InfoCards to authenticate
to participating services. The cards themselves represent references
to identity providers that are contacted to produce the needed claim
data for an identity when requested, rather than claims data stored on
the local machine. Only the claim values actually requested by the
relying party are released, rather than all claims that the identity
possesses (see Law 2).
... Now we come to the user-centric part of the InfoCard system:
2.7. Authenticating Users to Sites InfoCards have several key
advantages over username/password credentials:
    * Because no password is typed or sent, by definition, your
password can not be stolen or forgotten.
    * Because authentication is based on unique keys generated for
every InfoCard/site pair (unless using a card explicitly designed to
enable cross-site collaboration), the keys known by one site are
useless for authentication at another, even for the same InfoCard.
    * Because InfoCards will resupply claim values (for example, name,
address, and e-mail address) to relying parties that the user had
previously furnished them to, relying parties do not need to store
this data between sessions. Retaining less data means that sites have
fewer vulnerabilities. (See Law 2.)
What does that mean? Although it wasn't mentioned there, it turns out
that there are two possibilities: Client side key generation and
relationship tracking, as well as "provider generated InfoCards"
written up elsewhere:
    Under the company's plan, computer users would create some cards
for themselves, entering information for logging into Web sites. Other
cards would be distributed by identity providers -- such as banks or
governmental agencies or online services -- for secure online
authentication of a person's identity.
    To log in to a site, computer users would open the InfoCard
program directly, or using Microsoft's Internet Explorer browser, and
then click on the card that matches the level of information required
by the site. The InfoCard program would then retrieve the necessary
credentials from the identity provider, in the form of a secure
digital token. The InfoCard program would then transmit the digital
token to the site to authenticate the person's identity.
Obviously the remote provision of InfoCards will depend on buy-in,
which is a difficult pill to follow as that means trusting Microsoft
in oh so many ways - something they haven't really got to grips with.
But then there are also client-generated tokens. Are they useful?
If they have client-side key generation and relationship caching, then
these are two of the missing links in building a sustainable secure
system. See my emphasis further above for a hint on relationship
tracking and see Kim Cameron's blogfor this comment: "Cameron: A
self-issued one you create yourself." Nyms (as per SSH and SOX) and
relationship tracking (again SSH, and these days Trustbar,Petname and
recent other suggestions) are strong. These ideas have been around for
a decade or more, we call it opportunistic cryptography as a school.
Alternatively, notice how the credentials term is slipped in there.
That's not how Stefan Brands envisages it (from Identity on the move I
- Stefan Brands on user-centric identity management), but they are
using his term. What that means is unclear (and see Identity on the
move III - some ramblings on "we'll get it right this time, honest
injun!" for more).
Finally, one last snippet:
3.6. Claims != "Trust" A design decision was to factor out trust
decisions and not bundle them into the identity metasystem protocols
and payloads. Unlike the X.509 PKIX [IETF 05], for example, the
metasystem design verifies the cryptography but leaves trust analysis
for a higher layer that runs on top of the identity metasystem.
Hallelujah! Trust is something users do. Crypto systems do claims
about relationships.

@_date: 2006-01-01 18:53:13
@_author: coderman 
@_subject: [dave@farber.net: [IP] more on AP Story Justice Dept. 
yeah, follow tcp stream in ethereal is a good example of how trivial
it is to recreate a session of communication given an archive of its
component datagrams.
right.  hence my fetish for one time pads for key exchange and
previous comment about quantum computers / fast GNFS / etc.  they are
up to 8 qubits, only a few thousand more to go.  ;)
this is particular to the method TD mentioned i think...
i am assuming the following:
- the operating system is installed on a loop-aes volume so that
integrity of the kernel, libraries and utilities is protected via
- the one time pads are stored encrypted in a similar manner so that
access to them requires external keys (like the gpg encrypted keys
used for loop-aes volumes)
- the passphrase used to authenticate a user for access to the pads is
coupled with external storage (usb) of the keys used to access the
to recover the plaintext communication from the encrypted datagrams
the attacker would need to obtain the encrypted pad, the keys on
external storage (usb), and the passphrase to access the keys.
this doesn't provide time destruction so i assume this is in reference
to Tyler's description.  you could couple the user authentication with
a physically hardened token of some sort for access to the pads but
even this would require manual destruction.
do they make physically hardened authentication tokens with timed self
destruction built in?

@_date: 2006-01-01 18:57:44
@_author: coderman 
@_subject: Tor-stored Pads 
this reminded me of 'cryptoogle' which seems easily compromised but
operates using a time delayed expiration of key material as derived
from search results:

@_date: 2006-01-03 11:23:12
@_author: coderman 
@_subject: The NSA Program 
the nedonna beach landing point for the WCI cable (and others)
underwent significant physical security and facility upgrades in
recent years.  back when critical infrastructure details were
carefreely public the termination faclities a few hundred yards from
the shore even carried a promiscuous "FIBER OPTIC" sign on the door.
(the oregon fishermans undersea cable group used to provide the cable
plots with GPS coordinates a few score miles out as well.  now you
have to request these from them directly so they can limit
distribution to local area fishermen and others with a legitimate need
for the information)
initial reaction to security concerns included building a large razor
wire chain link fence around the facilities, although it appears this
was too much of an attention getter as they removed all such imposing
fencing before long and have continued to rely on extensive
cameras/alarms/highly visible boundary around the now rebuilt
facilities (aprox. 3-4 times the size of the original structure).
could more capturing equipment on site be the reason behind the
significant facilities upgrade?  they don't like to give tours of such
places unfortunately... :)
the main peering facilities located in hillsboro for the WCI cable
have not undergone any similar upgrades although the building was
already large and well secured from the start.
[it would be interesting to know what changes have been implemented at
other western landing sites; the nedonna beach point is the only one i
am directly familiar with]

@_date: 2006-01-05 10:54:26
@_author: coderman 
@_subject: [declan.mccullagh@gmail.com: [Politech] Feds begin 
i thought the idea of reinforcing cockpit doors was a good one.  i
think the issue is that most of the security added has been
agreed; this seems better than checking the shoes of the elderly or
forcing a nursing mother to drink some breast milk (just to be sure,
you know...)
but it's also easy to circumvent. do terrorists engage in social engineering?
also, it was my understanding that El Al uses armed personel on
flights; if this is the case perhaps more air marshalls are the
deterrent to use instead of passenger personality.
i don't think that is the issue; it is the secret laws hidden behind
"sensitive security information" which is to be fought.  if there is a
law that random search and identification are required to fly, it
needs to be public.
so glad i quit flying years ago...

@_date: 2006-01-05 13:22:31
@_author: coderman 
@_subject: [dave@farber.net: [IP] more on AP Story Justice Dept. 
it seems like this should be possible using a radioactive material
with a known short half-life and exposing it to a neutron source with
a mask (beryllium?) with the key space on it.
assume a grid of cells on a flat surface containing the radioactive
material; if a given cell emits over a threshold of radiation it is a
'1' bit, dead it is a 0 bit.  exposing the 0's to a neutron emitter
would fission the radioactive cells early leaving it's ionizing
radiation level below the threshold.
there would be some delay between when the key was usable with all
cells/bits readable (a few days, weeks, months?) and when it was still
holding a detectable / useful amount of key information that could be
used in a brute force attack against the unknown bits of key.
they let you put americium in smoke detectors but something tells me
it would be hard to get radioactive crypto keys commercially approved
for production. :)
(the neutron source would be another problem, although piezoelectric
fusion might work)

@_date: 2006-01-05 17:11:14
@_author: coderman 
@_subject: [dave@farber.net: [IP] The connection between NSA 
don't trust businesses nor governments with your private bits as much
as possible.  let your ISP freely share those encrypted payloads with
whoever they please.  end to end encryption has been advocated forever
but perhaps now people will be a little more willing to listen.  a
good time for crypto geeks to be a little more willing to look at
ease-of-use / HCI issues for secure decentralized networking.  lots of
failures to learn from...
open source++
community wireless++
decentralized networks++
do you have any infosec rent-a-fucks in mind?   choicepoint and the
other datamining privacy invasion businesses get my "fuck you buddy"
infosec sucked in 2005 but this is tangential to
NSA/$TLA/telecom/ISP/datareseller collusion.

@_date: 2006-01-06 14:50:18
@_author: coderman 
@_subject: phone records for sale 
Steven M. Bellovin Fri, 06 Jan 2006 14:02:12 -0800
18 USC 2702(c) says
        A provider described in subsection (a) may divulge a record or
        other information pertaining to a subscriber to or customer of
        such service (not including the contents of communications
        covered by subsection (a)(1) or (a)(2)) ...
        (6) to any person other than a governmental entity.
If the phone companies are not giving it out voluntarily, perhaps
they're being tricked or perhaps they have corrupt employees.
from the article:
""In some cases, telephone company insiders secretly sell customers'
phone-call lists to online brokers, despite strict telephone company
rules against such deals, according to Schumer.""
the call center employees and other data services API's (less common)
is exactly how they do it.  t-mobile, verizon, sprint, they all
contract out to call centers for various things which provide the call
center operators a restricted environment in which to use their
internal applications (usually IE, sometimes Remedy or Oracle Forms,
graphical Java apps, etc).
obviously part of the features of these applications is search by
name, MIN, account, etc.  often you can access a person's entire
account through such systems and very little if any oversight is
provided.  the carriers sole focus (as it seems) is to prevent
fraudulent equipment/phone deliveries to operators using customer
accounts.  they could care less about unauthorized access given their
lack of any attempt to halt such activity.
in addition to this, many of these internal networks are horribly
insecure, as was well demonstrated by the t-mobile hacks earlier this
year. [1]
the only reason they continue to get away with such poor practice is
that these networks are (in theory) all internal with dedicated lines
from the call center back to the carrier networks on which the
applications are run. and the fallout from their insecurity is not
directly attributable back to them (they can and do blame various
middle men, from devious operators to negligent call center policies,
[1] more fun quotes:
"To test the service, the FBI paid Locatecell.com $160 to buy the
records for an agent's cell phone and received the list within three
hours, the police bulletin said."
"I would say the most powerful investigative tool right now is cell
records," Rizzo said. "I use it a couple times a week. A few hundred
bucks a week is well worth the money."

@_date: 2006-01-12 23:08:11
@_author: coderman 
@_subject: Fwd: Researchers Develop Quantum Processor 
Researchers Develop Quantum Processor By Jay Wrolstad
January 12, 2006 11:57AM
A computer chip based on the esoteric science of quantum mechanics has
been created by researchers at the University of Michigan. The chip
might well pave the way for a new generation of supercomputers.
Employing the same semiconductor-fabrication techniques used to create
common computer chips, the Michigan team was able to trap a single
atom within an integrated chip and control it using electrical
Electrically charged atoms (ions) for such quantum computers are
stored in traps in order to isolate the qubits, a process that is
essential for the system to work.
The challenge is that current ion traps can hold only a few atoms, or
qubits, and are not easily scaled, making it difficult to create a
quantum chip that can store thousands or more atomic ions. A string of
such atoms, in theory, could store thousands of bits of information.
In the chip created at Michigan, which is the size of a postage stamp,
the ion is confined in a trap while electric fields are applied. Laser
light puts a spin on the ion's free electron, enabling it to flip it
between the one or zero quantum states.
The spin of the electron dictates the value of the qubit. For example,
an up-spin can represent a one, or a down-spin can represent a zero --
or the qubit can occupy both states simultaneously.
Applications for Cryptography
The quantum processor is made of gallium arsenide in a layered
structure and etched with electrodes using the same type of
lithography process as those used to create today's computer chips.
Each electrode is connected to a separate voltage supply, and these
various electrical voltages control the ion by moving as it hovers in
a space carved out of the chip.
The next step is to build a bigger chip with many more electrodes, so
that it can store more ions. There still is a lot of work to be done
to learn how to control lots of ions in one of these chips. It won't
be nearly as easy as it was with conventional computer chips, but at
least we know what to do in principle, Monroe said.
"This type of integrated chip structure is significant because it
demonstrates a way to scale the quantum computer to bigger systems,"
Monroe said. "It has applications for processing very large [data
sets] such as in cryptography, for example, and there is a lot of
interest in this by the government."
enjoy those pubkeys while you can suckers!
(i'm waiting for someone to suggest 32KBit key sizes.  how much RAM
does that eat?)

@_date: 2006-01-13 01:16:51
@_author: coderman 
@_subject: Fwd: Researchers Develop Quantum Processor 
indeed; they vastly understate the difficulty of the difficult part
they mention in the article.  i'm mostly poking fun - the stability of
lots of qubits together is independent of the manufacturability of
these individual qubit holders using existing tech.
i'll get imminently worried when the RSA challenges start dropping like mad...

@_date: 2006-01-19 11:01:40
@_author: coderman 
@_subject: Fwd: [Clips] Re: The Backhoe: A Real Cyberthreat? 
there are other easy ways to obtain outage information, especially
when the fiber affected handles significant amounts of traffic.  they
have stemmed the tide of outage information but more than enough gets
by to be useful for this type of analysis.  (although it was much
easier to just hit up the FCC for history when they kept track of it.
the telcos are just as glad to keep this data secret - they pushed as
hard as uncle sam to hide this data)
and as mentioned below, it doesn't take a backhoe either.  highly
capable portable power tools, post hole diggers, a myriad of other
construction equipment, could wreak havoc just as easily.  (Milwaukee
V28 portable saws are a good example - some disgruntled telco
employee(s?) in canada used a portable saw to cut two long distance
cables into the US causing over 280,000 circuits to go dead)
the tricky part is identifying redundant paths/rings as both must
usually be interrupted to create significant outage. (graph theory
applied to directed high degree node/link attacks)
there is a reason they are pursuing security through obscurity so
heavily.  sometimes it's all you've got... :)
--- begin forwarded text
---------- Forwarded message ----------
--- begin forwarded text
  Delivered-To: nanog-outgoing at trapdoor.merit.edu
  Delivered-To: nanog at trapdoor.merit.edu
  Delivered-To: nanog at segue.merit.edu
  Delivered-To: nanog at nanog.org
  Date: Thu, 19 Jan 2006 13:00:43 -0500
  From: sgorman1 at gmu.edu
  Subject: Re: The Backhoe: A Real Cyberthreat?
  Cc: nanog at nanog.org
  Sender: owner-nanog at merit.edu
  While it is always fun to call the government stupid, or anyone else for
that matter, there is a little more to the story.
  - For one you do not need a backhoe to cut fiber
  - Two, fiber carries a lot more than Internet traffic - cell phone, 911,
financial tranactions, etc. etc.
  - Three, while it is very unlikely terrorists would only attack telecom
infrastructure, a case can be made for a telecom attack that amplifies a
primary conventional attack.  The loss of communications would complicate
things quite a bit.
  I'll agree it is very far fethced you could hatch an attack plan from FCC
outage reports, but I would not call worrying about attacks on
telecommunications infrastructure stupid.  Enough sobriety though, please
return to the flaming.
  ----- Original Message -----
  From: jmaimon at ttec.com (Joe Maimon)
  Date: Thursday, January 19, 2006 12:01 pm
  Subject: Re: The Backhoe: A Real Cyberthreat?
  >
  >
  >
  >
  > > "In 2004, Department of Homeland Security officials became
  > fearful that
  > > terrorists might start using accidental dig-ups as a road map
  > for deliberate
  > > attacks, and convinced the FCC to begin locking up previously
  > public data on
  > > outages. In a commission filing, DHS argued successfully that
  > revealing the
  > > details..."
  > >
  > > --MORE--
  > >
  > >   > >
  > > -Dennis
  > >
  > >
  > >
  >
  > This is really stupid. Assuming the terrorist actually have the
  > dozens
  > of backhoes needed to completely erase meaningfull internet
  > connectivity
  > in north america, they would probably prefer to use them to smash
  > cars
  > and kill people on the interstate highways or something.
  >
  > Terrorist inflict terror by killing people, not by forcing
  > internet
  > explorer to display "page cannot be displayed".
  >
  > Let us not assume that murderous terrorist are as dumb as people
  > in DHS.
  >
--- end forwarded text
R. A. Hettinga The Internet Bearer Underwriting Corporation 44 Farquhar Street, Boston, MA 02131 USA
"... however it may deserve respect for its usefulness and antiquity,
[predicting the end of the world] has not been found agreeable to
experience." -- Edward Gibbon, 'Decline and Fall of the Roman Empire'
Clips mailing list
Clips at philodox.com

@_date: 2006-01-19 16:29:50
@_author: coderman 
@_subject: Fwd: [Clips] Re: The Backhoe: A Real Cyberthreat? 
the solution (at least, the only effective solution aside from
significant infrastructure redundancy - $$$) is rapid repair, and
att's disaster recovery program works well in this regard.  if you
recall after the trade center attacks (taking out massive CO capacity)
they used a fleet of mobile switching trailers to terminate and switch
all of the damaged fiber.
this type of disaster recovery is also expensive, but much less than
buried infrastructure and fixed COs.
in my experience severely congested packet networks are just as shitty
as outages in general; what good is that broadband line when your path
to the world is constrained at 14.4? :P
the real problem is the lack of diversity at the physical "X fibers
through same conduit / RoW" layer that forces a single point of
failure.  the telco idea of path diversity is one ring buried plant
and the other ring aerial plant along the same right of way... doesn't take much for a clustered outage in this environment to
disrupt packet/cell based networks as much as dedicated circuits.
in this respect the DHS paranoia over bridge photography begins to
make a little more sense (although still useless).

@_date: 2006-01-23 13:30:49
@_author: coderman 
@_subject: RentaCops in Public Spaces? 
remember blackwater at NOLA?  now that's creepy...

@_date: 2006-01-24 16:27:16
@_author: coderman 
@_subject: NSA: REDACTING WITH CONFIDENCE 
damn, i liked those leaky document formats. more than meets the eye indeed...
NSA: REDACTING WITH CONFIDENCE
The National Security Agency has issued new guidance to assist
officials in redacting (censoring) documents in Microsoft Word format
and producing unclassified Adobe Portable Document (PDF) files without
inadvertently disclosing sensitive information.
"MS Word is used throughout the DoD and the Intelligence Community
(IC) for preparing documents, reports, notes, and other formal and
informal materials. PDF is often used as the format for downgraded or
sanitized documents."
"There are a number of pitfalls for the person attempting to sanitize
a Word document for release."
For example, "As numerous people have learned to their chagrin, merely
converting an MS Word document to PDF does not remove all [sensitive]
metadata automatically."
"This paper describes the issue, and gives a step-by-step description
of how to do it with confidence that inappropriate material will not
be released."
See "Redacting with Confidence: How to Safely Publish Sanitized
Reports Converted From Word to PDF," National Security Agency,
December 13, 2005:

@_date: 2006-01-27 06:08:39
@_author: coderman 
@_subject: [bear@sonic.net: Re: thoughts on one time pads] 
agreed; it would be interesting to debate the bare minimum
requirements for a system where pads would provide a useful
improvement in security.  this means all those other holes bidding
malicious peers welcome need to be closed.
note that unless you have a hardware entropy source generating
anything more than a small amount of truly random pad is going to take
a lonnnnng time.
the yarrow based /dev/random in bsd is a fucking cop out; they should
remove it (that is what /dev/urandom is for).
fortunately VIA, AMD and Intel all provide hw rng sources of varying
capability on commodity systems.
this is why i like pads for key distribution.  with key material pre
distributed between the endpoints that will consume it you can
restrict network communication so that only authenticated traffic
(from peers whom you have exchanged pads with) is allowed into higher
levels of the OS stack / forwarded / applications.
this is really where i see a justifiable security improvement - block
all unauthenticated traffic up front, no open ports, no complex public
key formats / negotiation. (it would also be interesting to see all of
the potential remote exploit vulnerabilities in common IPsec key
in this scenario you can still transfer your huge data archives around
without consuming the entire pad with a quickness; frequent IPsec key
exchange to refresh SA's leverage the security and simplicity of pads
while retaining the flexibility of a chained block cipher for bulk
strong authentication and endpoint security are one of these critical
components required to use a pad effectively.  at a minimum i've
settled on the following for managing key material and endpoint
- bootstrap with read-only disc media prepared by a trusted peer. boot takes about 8-12 seconds for key management mode on a 1Ghz VIA
- passphrase protected full disk encryption with loop-AES
- loop-AES key schedule on USB memory stick [two factor auth]
- distinct domains / runtime instances for specific purposes.  as an
example, key management mode (import / export of keys, generation of
pads, creation/modification of digital identity) does not even support
any network capabilities in the statically linked kernel.  all
interaction in this domain is performed via file system with keys
manually copied to external domains which are network aware or hosting
this does mean that you're stuck using linux/bsd* for a secure domain,
with grsec/lsm/selinux/pax style defenses highly suggested.  ideally a
capability operating system would be used, but this is a challenging
yes! fixed buffer sizes, small attack surface, authentication from the
first packet onward (rather than entering into a negotiation to
ascertain identity).
best regards,
* both of these kernels need a good audit before they can be trusted
(at least pertaining to the code exposed to unauthenticated attackers
at a minimum), as do_brk() and bsd beacon overflows in ring0

@_date: 2006-01-30 09:11:26
@_author: coderman 
@_subject: [Clips] All Those NSA Wiretaps Are Just a Friendster in 
oh man, that's classic!
i wonder if i could get them to pay for FiOS...

@_date: 2006-06-01 08:12:28
@_author: coderman 
@_subject: Crashing the Wiretapper's Ball 
amusing :)
By Thomas Greene| Also by this reporter
02:00 AM Jun, 01, 2006
CRYSTAL CITY, Virginia -- The dingy hotel corridor was populated with
suits, milling about and radiating airs of defensive hostility. They
moved in close-knit groups, rounding a stranger or a rival group
conspicuously, the way cats do. They spoke in whispers. They glanced
nervously over their shoulders as they took calls on their cell
phones, then darted swiftly into alcoves.
They were government officials, telephone company honchos, military
officers, three-letter-agency spooks and cops, all brought together by
salesmen dealing in the modern equipment of surveillance. It was my
job to learn what they were up to.
They'd gathered for the ISS World Conference, a trade show featuring
the latest in mass communications intercept gear, held in the
Washington, D.C., suburb of Crystal City, Virginia. Situated
conveniently between Reagan National Airport and the Pentagon, Crystal
City is an artificial place dominated by conference centers and
hotels, set up to accommodate the endless, and often secret,
intercourse between the U.S. military and its myriad itinerant
contractors, lobbyists, consultants and trainers. They rotate in and
out, civilians using the airport, military personnel taking the subway
from the Pentagon, with Crystal City as the intersection in a
figure-eight circuit of constant activity.
Back in the narrow hotel corridor, vendors manned their booths,
exhibiting the latest gadgets for mass electronic surveillance:
machines capable of scouring the data streams of millions of
subscribers -- industrial-strength kits for packet interception and
analysis, RF interception, and voice and keyword recognition.

@_date: 2006-06-09 10:56:52
@_author: coderman 
@_subject: "A million bucks in stolen calls" 
it's hard to sheild income, hence the advice to inflate expenses when
fudging taxes rather than trying to hide incoming funds.
these guys were making too much money to stay covert for long, so i
don't think tor or encryption of comms or data would have helped.  it
might have delayed the inevitable a bit, but that's all.
"Authorities said that to hide profits from his scheme, which ran from
November 2004 to May 2006, Pena bought real estate, three luxury
vehicles and a 40-foot motorboat."
  -- that's not a good way to hide funds :)

@_date: 2006-06-13 10:50:10
@_author: coderman 
@_subject: [lists@user-land.org: [p2p-hackers] USA Preparing the 
let users shape at the endpoints (where it is most effective anyway)
and let the telco's carry blackened traffic.
end of problem. :)

@_date: 2006-06-17 05:21:29
@_author: coderman 
@_subject: user centric network endpoint based session 
trying to get some feedback for working documentation / design before
our next published iteration expected on july 4th.
please feel free to provide public comments or suggest related
projects/research/code to me directly or on list.
throwing down the gauntlet:
using various authentication and key management methods at the TCP
session level associated with a specific IP/port endpoint pair for
access to network services[1][2][3][4][5]* is a relic from decades
past and is not only inefficient and inflexible but actively
detrimental to good usable security due to the baggage and complexity
inherent in these methods.[6][7][8]
access to network services should be provided on top of a network
endpoint local to the two domains requesting and providing services
respectively, with user centric authentication for initialization of
the secure IPv4/IPv6 tunnel session to which services are bound and
revocation performed by terminating this session and the ability to
reestablish it.
revocable delegation is implemented by proxy of traffic between peers
to the delegated domain and irrevocable delegation implemented by
sharing authentication credentials for the desired endpoint service(s)
with the trusted peer for direct communication without proxy.
* i listed three distributed capability based protocols not as a
slight, but to point out that a capability / POLA / least privilege
approach to building and providing services at the OS and application
layers is the only way truly good security can be realized.  i would
like to see the implementation / protocol specific parts of
communication privacy pulled out of such projects so they can focus on
and implement what they are designed for and most effective at. this
is a long term vision as the effort to transition to wide scale
capability based security is significant.[9]
in a sense this is simply a way to exchange "the capability to
communicate with me privately" and then utilize the services made
available to your peers when this capability is exercised.
Q: why delegate authentication and privacy to a network IPv4/IPv6
endpoint layer?
- this allows a flexible and intuitive method for implementing privacy
and authentication of digital communication between peers.  the
existing tools and concepts associated with Virtual Private Networks
can be employed in a decentralized and user centric manner while
existing applications and services can use the strong authentication
and session management available by binding to the desired endpoint
"sharing the authentication and privacy bootstrap" makes sense for
everyone. more reasons?
- it allows you to limit any unauthenticated attacks against
application / private services to the VPN layer itself (OpenVPN port,
IPsec stack, etc), thus keeping applications more vulnerable to attack
(rich web services, new apps, etc) inside an authenticated boundary.
NOTE: this should not be interpreted as the usual "perimeter security"
model which is flawed.  when each peer communicates directly you have
effectively deperimeterized the hosts on the network.
- it meshes well with a virtual machine approach to isolating domains
where each VM instance can have it's own network endpoint tied to
distinct authenticated sessions.
- it allows pet names to be given to distinct addresses bound to peer
identity (using the SHA2-256 digest of peer public key to generate a
feed::/8 address for example, which can be given a petname[10] in
public.peertech.org or 172.16.27.53 devwiki)
- traffic shaping, bandwidth monitoring, IDS and other techniques can
be applied to distinct authenticated sessions using the desired IP
address in a straightforward manner.  this can be particularly
difficult to do when an application uses ephemeral / dynamic ports but
is simple with distinct endpoints.
Q: what about passwords?
- it is assumed that this style of security would utilize full disk
encryption or a key manager (like the browser site login remember
feature) to manage strong authentication material associated with a
user's identity.  passwords are too weak for good network
Q: what would the key distribution for this kind of identity
management look like?
- some examples:
A. Strongly authenticated propinquitous capability exchange:
  First two peers exchange public keys (self signed OpenVPN
certificates) and endpoint locators in person.
  Second they both connect over wireless / LAN directly using OpenVPN
to establish an authenticated and private network between them.
B. Strongly authenticated transitive introduction:
  Using a secure session pair created via strong auth, send the public
key of each peer to be introduced to each other.
  Each peer attempts directly connecting using the endpoint
identifiers for each other obtained from the mutually trusted peer.
C. Opportunistically authenticated capability exchange:
  Petition public / untrusted introducer with nickname or other
identifier for endpoint discovery (coderman.dyndns.org for example).
  Connect to peer and exchange and save keys (openssh style).
  Keys may be verified in the future or reset if problems are encountered.
Q: This sounds way too complicated; what can support this kind of connectivity:
- while difficult this is feasible and straightforward.  existing
tools like OpenVPN, OpenSSH 3.4+, IPsec, PPTP, and others can all be
integrated in a suitable fashion using everything from UDP, TCP to
ICMP and even covert DNS tunnels or 802.11 injection for transport.
the key will be making key management and user interaction simple
enough for the appropriate threat models.
1. "HTTPS protocol"
  - 2. "STARTTLS protocols"
  - 3. "Lessons from E-speak"
  -  4. "httpsy protocol"
  - 5. "CapTP protocol"
  - 6. "Security: Problem Solved?"
  - 7. "Why johnny can't encrypt"
  - 8. "Why Phishing Works"
  - 9. "Capability Myths Demolished"
  - 10. "Introduction to Petname Systems"
  -

@_date: 2006-06-17 06:53:54
@_author: coderman 
@_subject: [Clips] How Britain Beat Hooliganism 
well, no one said the Panopticon wasn't effective; just too invasive
and prone to unacceptable abuses (either potential or currently
realized for varying frequency and atrocity)
if you get past the initial "fuck big brother" reaction there are
actually some interesting insights to be gleaned here concerning
reputation between peers in public and private spaces, the nature of
gauging your personal risk in large groups, and so forth.
techniques certainly applicable to cypherpunk and privacy advocate goals.
the rest is left as an exercise for the reader...

@_date: 2006-06-17 12:18:11
@_author: coderman 
@_subject: zeroisation of storage 
not too accurate in parts (this was a priority long before the spy
plane drama but usually associated with key material); still
"Fail-Safe Techniques Erase Magnetic Storage Media"
"This is a very challenging problem," said Michael Knotts, a research
scientist in the GTRI's Signature Technology Laboratory. "We had to
verify that the data would be beyond all possible recovery even with
unlimited budget and unlimited time. Commercial devices on the market
for data erasure just couldn't fill the bill, because they were
magnetically too weak, they were physically too large and heavy, or
they didn't meet stringent air safety standards."
Producing a magnetic field sufficient to destroy data patterns
required the use of neodymium iron-boron magnets custom-designed for
the project and special pole pieces made of esoteric cobalt alloys.
The magnets, which weigh as much as 125 pounds, had to produce fields
sufficient to penetrate metallic housings that surround some drives.
"We developed models for magnetic circuits that we could run through
optimization codes to design the best shape to get the field that we
needed," Knotts said. "It takes quite a magnetic field to get through
the steel enclosures on some of the drives. We are producing magnetic
fields comparable to those used in magnetic resonance imaging
equipment, so these are not your ordinary refrigerator magnets."
"This was certainly an unusual project," he said. "It's not often that
we get paid to crush equipment in presses, blow things up and set off
fires in microwave ovens."
i occasionally use one of those noisy AC powered degauss'ers on hard
disks but have wondered if it would pass the "unlimited budget and
unlimited time" test.  i wonder what it would take to restrain a disk
through an MRI machine without it impaling itself into the coils...
(some of those horror stories are pretty wild)
initializing a disk with entropy afterwards is also annoyingly time
consuming for big disks.  i'm concerned about just how usable you can
make this process, perhaps turning it into a background batch process
requiring multiple disks so one can be used for the live system while
an empty disk is being wiped and randomized.
i wonder when Peter Gutmann's article on hard disk encryption is going
to be published (if not already?)

@_date: 2006-06-21 18:47:24
@_author: coderman 
@_subject: Fwd: Some legal trouble with TOR in France 
clearly you haven't seen the n3td3v threads in full-disclosure.  keep
those lip^H^H^Hkeyboards flapping over flippant falafel, a resource
consumption attack.  pwned! lolz...
on a more serious note i am sure there is tor tampering where
possible.  the reason i had to kill the original peertech node (was
this this first non-roger public node or is my dementia/schizophrenia
progressing?) is related to this subject, though i'll let dead dogs
decompose where they lay(lie?) and avoid another tangent into
"apparent paranoia".
physical security is a necessary element of trust, along with all the
other realms of cypherpunk voodoo (infosec, emsec, trannysecx, etc).
i know good security when i see it (hah); the truth shall set you free
[or make you crazy]. opportunistic may be popular but active eve waits
for the unprepared.
 (hey, why you hiding fucker?)
a better fed chick this year please,
love coderman - your clinically classified canary.

@_date: 2006-06-21 19:26:54
@_author: coderman 
@_subject: How The Telcos And The Government Are About To Boost The 
what say ye?  a stirring amidst the complacent masses?
here's lots of news today about the (not particularly surprising)
revelations that AT&T may have helped monitor internet traffic for the
NSA. It's interesting to note, with this news, the side story that
AT&T also just revamped their privacy policy, allowing them to more
freely share whatever data they collect with government officials.
However, rather than discuss those two issues (which are being
discussed widely), a more interesting question is whether or not this,
along with the ongoing debates around net neutrality, will actually
lead more people to simply encrypt their internet traffic. It
certainly could open up quite the business opportunity for firms
providing encrypted VPN systems that basically scramble all your data
so your ISP can't snoop and can't prioritize (or downgrade) the
poor chumps who buy the proprietary snake oil; true security requires
visibility, and alas there's not a big market for decentralized open
source security/privacy infrastructure (a paying market that is).
[sometimes virtue is its own reward.  and sometimes it at least gets
you beers and whiskey.]

@_date: 2006-06-22 14:52:48
@_author: coderman 
@_subject: coderman off his meds / physical security / sneak n peak 
[AnonymousHeckler] Silly punk, they don't send a van for a sneak and peak.
it's hard to sneak when you've got remote surveillance of the
perimeter.  unfortunately hiding in plain sight didn't work too well
either. (of course i'll never know the details, which is part of the
point. FOIPA has been neutered; though another try can't hurt...)
visible cams are cheap and easy (my recent favorite: "Cams from the
TPB bust"  ) and i like the
deterrent they provide.  wireless makes a good backup path (in
addition to primary broadband) for critical signalling and remote feed
archival; recording locally doesn't make much sense, right? :)
rcovert and wifitap style wireless transport is a great secondary path
with an amplified injector (unidirectional).  i'd love to try this at
1Mbps encoding on 700mW 900Mhz (SR9 radio) but the 2.4Ghz works well
enough at 30dBm.  don't forget those UPS's...
[i dream of a day the 802.11 MAC is dead. flawed assumptions at the
base of this stack leads to vulnerability up
transport/session/application layers too. cognitive software radios++]
regarding critical signalling: always fail safe to zeroisation upon
DoS or detection.  good key management means a false positive is easy
to recovery from.
concealed/covert cameras would be fun but difficult.  anyone have
suggestions / experience?
   coderman - with a significantly lower B.A.C. today...

@_date: 2006-06-22 15:18:08
@_author: coderman 
@_subject: How The Telcos And The Government Are About To Boost The 
is there a way to offload the critical (key secrecy) parts to a
trusted third party / external location so that retention would be
effectively pointless?
(that is to say, within the jurisdiction of data retention let them
archive all the blackened traffic they want until the heat death of
the universe...)

@_date: 2006-06-22 21:15:54
@_author: coderman 
@_subject: Bank Data Sifted in Secret by U.S. to Block Terror 
ho hum, who didn't see this coming?
"How long can this go on?" indeed...
Bank Data Sifted in Secret by U.S. to Block Terror
By ERIC LICHTBLAU and JAMES RISEN
WASHINGTON, June 22  Under a secret Bush administration program
initiated weeks after the Sept. 11 attacks, counterterrorism officials
have gained access to financial records from a vast international
database and examined banking transactions involving thousands of
Americans and others in the United States, according to government and
industry officials.
The program is limited, government officials say, to tracing
transactions of people suspected of having ties to Al Qaeda by
reviewing records from the nerve center of the global banking
industry, a Belgian cooperative that routes about $6 trillion daily
between banks, brokerages, stock exchanges and other institutions. The
records mostly involve wire transfers and other methods of moving
money overseas and into and out of the United States. Most routine
financial transactions confined to this country are not in the
"The capability here is awesome or, depending on where you're sitting,
troubling," said one former senior counterterrorism official who
considers the program valuable. While tight controls are in place, the
official added, "the potential for abuse is enormous."
Officials described the Swift program as the biggest and most
far-reaching of several secret efforts to trace terrorist financing.
Much more limited agreements with other companies have provided access
to A.T.M. transactions, credit card purchases and Western Union wire
payments, the officials said.
Treasury officials said Swift was exempt from American laws
restricting government access to private financial records because the
cooperative was considered a messaging service, not a bank or
financial institution. [ED: heheh]
Several people familiar with the Swift program said they believed that
they were exploiting a "gray area" in the law and that a case could be
made for restricting the government's access to the records on Fourth
Amendment and statutory grounds.
In terrorism prosecutions, intelligence officials have been careful to
"sanitize," or hide the origins of evidence collected through the
program to keep it secret, officials said.
Quietly, counterterrorism officials sought to expand the information
they were getting from financial institutions. Treasury officials, for
instance, spoke with credit card companies about devising an alert if
someone tried to buy fertilizer and timing devices that could be used
for a bomb, but they were told the idea was not logistically possible,
a lawyer in the discussions said.
Intelligence officials were so eager to use the Swift data that they
discussed having the C.I.A. covertly gain access to the system,
several officials involved in the talks said. But Treasury officials
resisted, the officials said, and favored going to Swift directly.
[ED: wow, that would have been fun. crash an international banking
network by accident? oops!]
Within weeks of 9/11, Swift began turning over records that allowed
American analysts to look for evidence of terrorist financing.
Initially, there appear to have been few formal limits on the
"At first, they got everything  the entire Swift database," one
person close to the operation said.
Officials realized the potential for abuse, and narrowed the program's
targets and put in more safeguards. Among them were the auditing firm,
an electronic record of every search and a requirement that analysts
involved in the operation document the intelligence that justified
each data search. Mr. Levey said the program was used only to examine
records of individuals or entities, not for broader data searches.
Despite the controls, Swift executives became increasingly worried
about their secret involvement with the American government, the
officials said. By 2003, the cooperative's officials were discussing
pulling out because of their concerns about legal and financial risks
if the program were revealed, one government official said.
"How long can this go on?" a Swift executive asked, according to the official.
Even some American officials began to question the open-ended
arrangement. "I thought there was a limited shelf life and that this
was going to go away," the former senior official said.

@_date: 2006-06-24 18:25:13
@_author: coderman 
@_subject: missing info on "special collections service" 
pages discussing the "special collections service" run by CIA/NSA
appear to be 404'ing (with exception of cryptome archives perhaps).
anyone have archives of the FAS docs, cetin.net.cn pages, etc?
additional relevant details?
"those who talk don't know, those who know don't talk"...

@_date: 2006-06-24 22:04:55
@_author: coderman 
@_subject: Scott Marcus Declaration on ATT/NSA Spying 
thanks JYA,
some interesting tidbits:
'Klein Exhibit C speaks of a private tap? backbone network, which
appears to be partitioned from AT&T's main Internet backbone, the
CBB.[15]  This suggests the presence of a private network.  The most
plausible inference is that this was a covert network that was used to
ship data of interest to one or more central locations for still more
intensive analysis.  I return to the capabilities of the Tap?
Configurations later in this Declaration, under "Capabilities of the
Tap? Configuration."'
words with a '?' are my guess as to the censored content.
funny tidbit, they forgot to blank out "Narus" in "the Narus system"
in one spot, can you find it? :)
[let's play a game of fill in the blanks!]
interesting that on-network links were not tapped, as seems to be
inferred.  also interesting that AT&T began selling "internet protect"
that uses similar methods (profile/anomaly based).

@_date: 2006-06-25 18:37:34
@_author: coderman 
@_subject: [dave@farber.net: [IP] Greek cellular wiretapping scandal] 
all circuits busy!  oops.  the problem with one way conferences like
this is that you tie up significant switch resources (a "conference
resource" or other such name, in addition to the outbound spans
required for covert relay to destination).  the problems with text
messages probably occurred during peak usage periods when contention
for finite switch resources (provisioned _without_ clandestine
circuits in use :) hits service affecting limits.
we are so familiar with license codes to activate functionality in
enterprise software i don't see why this is much of a point.  of
course there is CALEA like functionality.  the focus on CALEA is more
a bureaucratic aspect; the technical implementation of a one way
conference is trivial, the proper controls and administration for
CALEA implementation using such a technique is probably 10x to 100x
more effort to satisfy all the legal requirements and user friendly
feature richness.
bingo.  a very practical approach assuming you have the insider access
to implement.  maybe even hired a grey/black hat to code it (as SMB
mentioned the free reign hackers have enjoyed on telco neworks in the
it definitely appears to be the work of an Ericson telco coder working
in conjunction with the Vodafone tech to get the configuration and
deployment of the eavesdropping implemented.
the basic prerequisites:
- one telco coder who knows the API / state machine of the soft switch
to code to, either at an API level (sounds like it, as this was a
process working with the legitimate soft switch programs on a unix
host) but could be done at a network level (process monitoring and
injecting call process commands directly to switch hardware at a low
level - harder to do, but can be more stealthy)
- one technician who can supply the current switch configuration
(spans from towers / carriers, their signalling characteristics, etc)
- telco test configuration (a softswitch configuration as close to
target configuration as possible, a tsunami or other bulk call
generator / call test harness)
- time and money.
work out the proper configuration for identifying incoming calls of
interest, bridge to available one way conference, connect conference
outbound to pool of relay/destination cell phones.
that suicide looks really suspicious, doesn't it?
LOL, ROFFLE, etc.
the nature of this relay would be interesting to discover.  was this a
forwarded type relay (i.e. handset not active, forward to this
number?) or a store and forward, like voicemail, or what?
it was intentional, there's no way that was an accident.  perhaps it
was intentional so they could say of course we didn't do it because
we're not that stupid?  or perhaps it's all an elaborate ruse to make
us think in that direction, and clearly i shouldn't choose the cup in
front of me! ..  er,  back to the story:
mission accomplished, too many contradictions and potential deceits
and distractions.  need to talk to someone with knowledge of the
activity (oh wait, that problem is neatly resolved by convenient
oh well, speculation is more fun anyway...
not arcane, just highly specialized and complicated.  people do this
all the time all over the world for a living.  ho hum, soft switching
hasn't been rocket science since the 1990's :P
yup, agreed on all counts.  since the Vodafone insider is "expired"
perhaps the Ericsson / telco coder will surface with a additional
digging.  i'd bet on powerball before that outcome though...

@_date: 2006-06-26 14:04:22
@_author: coderman 
@_subject: Scott Marcus Declaration 
doh, mea culpa
(i realized this later yesterday when trying to correlate the titles
of redacted exhibits with the names of the exhibits that were relased
what kind of help would be useful (sending in one-off edits as
discovered, or is there a group collaborating elsewhere)?
is there a running archive of all the relevant docs / articles or at
least pointers to them? (to appease the copyright cartels)

@_date: 2006-03-01 20:35:48
@_author: coderman 
@_subject: mixminion nodes wanted 
stealth monger looking for mixminion node operators:
 [ref:  ]
(actually i'm not certain which debian mixnet package is hinted at here...)
 at metzdowd.com/msg05826.html
Re: NPR : E-Mail Encryption Rare in Everyday Use
Wed, 01 Mar 2006 06:14:43 -0800
But you don't have to reveal that you sent him email.  You can use
stealthy communication.
Stealthy communication is communication wherein not only is the
content concealed from eavesdroppers by encryption, but information
about who is communicating with whom, when, or if at all, is
concealed, as well.
The Internet can be used for stealthy communication.  The basic idea
is that each potential participant has ongoing traffic to and from a
message pool which is propagated world-wide.  When the participant has
no live traffic to send, dummy traffic is sent instead.  The dummy
traffic is indistinguishable from the live traffic except by using
decryption keys which are chosen by correspondents.  The outbound
traffic continues autonomously without interruption for months and
years and is not correlated to the live traffic, so an observer
without the keys cannot determine when or how much live communication
is happening.  Inbound cover traffic consists of taking a full feed of
the message pool at all times without interruption.
A Debian Linux package exists which enables stealthy email.  It has
been in everyday use for years, although not widely.  Details on
request.  I am looking for someone to host it.  Any volunteers?
 -- StealthMonger

@_date: 2006-03-02 11:11:21
@_author: coderman 
@_subject: 'Torture Boy' Signals More Spying 
i feel like throwing a FOIPA party,
'Torture Boy' Signals More Spying
By Robert Parry
March 2, 2006
Correcting misleading testimony to Congress, Attorney General Alberto
Gonzales has signaled that George W. Bush's warrantless surveillance
of Americans went beyond the known eavesdropping on communications to
suspected terrorists overseas.
In a letter to the Senate Judiciary Committee on Feb. 28, Gonzales
recanted testimony he gave on Feb. 6 when he declared that Bush had
only authorized a narrowly constructed warrantless wiretapping program
by the National Security Agency against Americans in touch with
foreign terror suspects.
Referring to a part of his testimony in which he said Bush had
approved the NSA program "and that is all that he has authorized,"
Gonzales withdrew that language, saying "I did not and could not
address  any other classified intelligence activities." [Washington
Post, March 1, 2006]
The strained wording of Gonzales's letter  and the fact that he
deemed it necessary to correct his testimony  suggest that other
warrantless surveillance programs exist outside the framework of the
NSA program, which began shortly after the Sept. 11, 2001, terror
attacks and was exposed by the New York Times in December 2005.
Sen. Arlen Specter of Pennsylvania, the committee's Republican
chairman, didn't put Gonzales under oath at the Feb. 6 hearing, but
false statements to Congress still constitute a potential criminal
Close Questioning
The dubious testimony came during close questioning by Sen. Patrick
Leahy of Vermont, the committee's ranking Democrat. Leahy pressed
Gonzales on the administration's claim that Congress gave Bush the
power to wiretap without a court warrant when it authorized use of
force against al-Qaeda after the Sept. 11 attacks.
In his testimony, Gonzales argued that the congressional use-of-force
authorization, combined with the President's Commander-in-Chief power
in the Constitution, permitted Bush to approve a wiretapping program
for communications between Americans and terror suspects operating
outside the United States.
But  in challenging Bush's right to ignore the 1978 Foreign
Intelligence Surveillance Act, which requires a special court to
approve wiretaps  Leahy demanded to know if the administration's
legal interpretation also let Bush conduct other warrantless spying on
Americans, including tapping purely domestic phone calls, mail
openings and "black bag" break-ins into people's homes and offices.
"Under that (administration) logic, is there anything that stops you
from wiretapping without a warrant somebody inside the United States
that you suspect of having al-Qaeda connections?" Leahy asked.
"Clearly, Senator, that is not what's going on here," Gonzales
responded. "The President had authorized a much more narrow program.
We are always, of course, subject to the Fourth Amendment. So the
activities of any kind of surveillance within the United States would,
of course, be subject to the Fourth Amendment," which requires
"probable cause" and a court warrant before the property of Americans
can be searched.
Leahy persisted. "Under your interpretation of this, can you go in and
do mail searches? Can you go into e-mails? Can you open mail? Can you
do black-bag jobs?  Can you go and do that (to) Americans?"
Gonzales responded, "Sir, I've tried to outline for you and the
committee what the President has authorized, and that is all that he
has authorized."
"Did it authorize the opening of first-class mail of U.S. citizens?"
Leahy continued. "That you can answer, yes or no."
Gonzales: "There is all kinds of wild speculation about..."
Leahy: "Did it authorize it?"
Gonzales: "There is all kinds of wild speculation out there about what
the President has authorized and what we're actually doing. And I'm
not going to get into a discussion, Senator."
Recanted Testimony
Three weeks later, by recanting the statement about "that is all that
he (Bush) has authorized" in the context of Leahy's line of
questioning, Gonzales appears to be acknowledging that some of Leahy's
concerns are valid, that there are other components to Bush's
warrantless surveillance operations beyond the NSA program.
Given the fact that the Bush administration and its media allies have
openly challenged the loyalty of Americans who have disagreed with
Bush's policies, it would not be a big jump to suspect that Bush has
authorized spying on citizens, journalists and/or politicians who
have, in his view, undermined his strategy in the War on Terror or the
Iraq War.
Some Republicans publicly have urged Bush to counter these Americans
whom they call "Fifth Columnists" for supposedly sympathizing with or
otherwise helping the enemy.
At the Feb. 6 hearing, Sen. Lindsey Graham, R-S.C., declared that "I
stand by this President's ability, inherent to being Commander in
Chief, to find out about Fifth Column movements, and I don't think you
need a warrant to do that."
When Graham offered to work with the administration to draft
guidelines for how best to neutralize this alleged threat, Gonzales
smilingly replied, "Senator, the President already said we'd be happy
to listen to your ideas." [See Consortiumnews.com's "Bush's Mysterious
'New Programs'."]
With Bush's elastic use of language and his aggressive interpretation
of his own powers, there would seem to be little that Bush feels he
cannot do.
Gonzales, who was Bush's White House counsel before becoming Attorney
General, is part of a cadre of far-right lawyers who have asserted
virtually unlimited powers for Bush during the indefinite War on
Gonzales earned the nickname "Torture Boy" for going along with
ideologues like John Yoo and David Addington in defending
interpretations of Bush's authority that opened the door to torture
and other abuses of U.S. detainees imprisoned in Guantanamo Bay, Iraq,
Afghanistan and secret CIA jails scattered around the world. [See
Consortiumnews.com's "U.S. Disconnect on Bush's Abuses."]
Legal Resistance
The right-wing lawyers encountered opposition from professional
attorneys at the Justice Department and the Defense Department. The
professionals  the likes of Assistant Attorney General Jack Goldsmith
and U.S. Navy general counsel Alberto Mora  forced the Bush lawyers
into some retreats on the most expansive assertions of executive
power, especially involving torture.
Referring to one of Yoo's opinions that asserted the President's power
to subject Guantanamo inmates to cruel, inhumane and degrading
treatment, Navy general counsel Mora wrote, "The memo espoused an
extreme and virtually unlimited theory of the extent of the
President's Commander-in-Chief authority." [See Mora's 22-page
chronology, as posted by The New Yorker.]
But, one by one, these internal critics were pushed out of the
government. Goldsmith resigned to take a teaching position at Harvard
Law School; Mora quit to take a job as general counsel for Wal-Mart's
international operations. [See Consortiumnews.com's "Another Bush Lie"
on Goldsmith, or The New Yorker's "The Memo" on Mora.]
In the context of Bush's top legal advisers rationalizing Bush's right
to torture prisoners or to jail American citizens without charges, the
likelihood seems high they also would claim for Bush the power to spy
on domestic opponents.
As Gonzales told the Senate Judiciary Committee on Feb. 6, "detention
is far more intrusive than electronic surveillance."
But it's unclear whether the American people will ever learn what
these additional eavesdropping programs were or whom they targeted.
The Bush administration has wrapped its domestic spying program in
layer after layer of secrecy and lies.
In a speech in Buffalo, N.Y., on April 20, 2004, Bush went out of his
way to mislead the American people into a false sense of security
about his respect for Fourth Amendment prohibitions on warrantless
"By the way, any time you hear the United States government talking
about wiretap, it requires  a wiretap requires a court order," Bush
said. "Nothing has changed, by the way. When we're talking about
chasing down terrorists, we're talking about getting a court order
before we do so."
At the time of his speech, Bush had been authorizing wiretaps without
getting approval from the FISA court for more than two years. [For
more on Bush's deceptions, see Consortiumnews.com's "Talkin' 'Texan'
Means Lying Big."
Secrecy Charade
The administration's claim about the need for extraordinary secrecy
surrounding the wiretap program is also largely a charade. Al-Qaeda
and other enemy groups have long been aware that the United States has
the capability of electronic eavesdropping and have structured their
operations accordingly.
In the Feb. 6 hearing, Gonzales acknowledged as much under questioning
from Sen. Joe Biden, D-Delaware.
Biden asked, "How has this revelation damaged the program" since the
administration's attack on the disclosure "seems to presuppose that
these very sophisticated al-Qaeda folks didn't think we were
intercepting their phone calls?"
Gonzales responded, "I think, based on my experience, it is true  you
would assume that the enemy is presuming that we are engaged in some
kind of surveillance. But if they're not reminded about it all the
time in the newspapers and in stories, they sometimes forget"  a
response that drew laughter from the citizens in the hearing room.
"You're amazed at some of the communications that exist," Gonzales
continued. "So when you keep sticking it in their face that we're
involved in some kind of surveillance, even if it's unclear in these
stories, it can't help but make a difference, I think."
In other words, Gonzales argued that the reason for the extraordinary
secrecy around the wiretap program is not that the disclosure of its
existence would alert al-Qaeda to a previously unknown U.S. spying
capability, but that newspaper stories might remind them to be a
little more cautious while chatting on the telephone.
Such a slim argument would suggest that the Bush administration has
another motive for trying to intimidate anyone  whether in the press
or in Congress  who wants to investigate the surveillance program.
On Feb. 28, reflecting on Gonzales's earlier testimony, Leahy said the
Attorney General's unresponsive answers led to the conclusion that
Gonzales "has a radically different understanding of the laws than do
many of us  the people's representatives in Congress who wrote the
As for Gonzales's responses to senators' questions about the program,
Leahy said, "whatever we asked, it was either too relevant or not
relevant enough, and either way, we were getting no answers from the
Attorney General."
A logical suspicion is that the administration is blocking a thorough
examination of the wiretapping program because it might show that Bush
followed the legal advice on his unlimited powers into pervasive
spying of his political enemies.
Robert Parry broke many of the Iran-Contra stories in the 1980s for
the Associated Press and Newsweek. His latest book, Secrecy &
Privilege: Rise of the Bush Dynasty from Watergate to Iraq, can be
ordered at secrecyandprivilege.com. It's also available at Amazon.com,
as is his 1999 book, Lost History: Contras, Cocaine, the Press &
'Project Truth.'

@_date: 2006-03-02 12:07:55
@_author: coderman 
@_subject: Usable encryption facilitates intuitive policy, rather than 
"I habitually send most of my email securely, but I don't think about
it. My robots take care of it for me. I tune policies, I don't encrypt
messages." - Jon
if you have to wrap the major key formats and uses into a single
bundle, so that a pre-generated user identity which contained keys in
formats applicable to any application the user might employ, what
would this bundle/list look like?
[let's avoid trust models and specifics of key utilization for a
higher level OS/application discussion.  for now i want to focus on
just what set of common types would serve the usual OS/application
needs in some form so that a single user/resource identity can be
created for use with lots of different "robots" further down the line
used depending on the trust model employed and the applications
currently i'm aware of the following covering most bases but i know
i'm missing some:
- nonce/guid -> 512 bits of entropy from /dev/random (NOTE: when is
BSD going to turn /dev/random back into a true entropy source rather
than the deceptive alias for /dev/urandom?)
- gpg key pair ->  DSA and Elgamal, gpg --gen-key ...
- gpg key -> RSA sign only, gpg --gen-key ...
- shared encryption secret -> 256 bits of entropy from /dev/random
- shared auth secret -> 256 bits of entropy from /dev/random
- openssl root CA key -> openssl req -x509 -new -keyout ca.key -out ca.crt ...
- openssl dh parameters -> openssl dhparam ...
- openssl entity key (signed by root CA) -> openssl req ... && openssl ca ...
- ssh rsa key: ssh-keygen -t rsa ...
- ssh dsa key: ssh-keygen -t dsa ...
- ssh moduli: ssh-keygen -G ... && ssh-keygen -T ...
- off the record user state: otrl_userstate_create();
what else would you add to this list?
 at metzdowd.com/msg05822.html
Re: NPR : E-Mail Encryption Rare in Everyday Use
Jon Callas
Tue, 28 Feb 2006 11:45:54 -0800
I have to chime in on a number of points. I'll try to keep commercial
plugs to a minimum.
* An awful lot of this discussion is some combination of outdated and
true but irrelevant. For example, it is true that usability of all
computers is not what it could be. But a lot of what has cruised by
here is similar to someone saying, "Yes, usability is atrocious --
here, look at this screenshot of Windows 3.1." Someone else pipes up,
"You think that's bad, let me show you this example from the Xerox
Alto. What*ever* were they thinking?" And then someone else says,
"Yeah, and if you think that's bad, look at what 'ls' did in Unix V6!"
Then when someone else says, "Y'know, I'm using the latest version of
Firefox, and it's actually pretty good" the next message says, "But
what about the Y2K issues, and what happens when in 2038?" I swear,
guys, this thread is the crypto version of the Monty Python "Luxury"
* Whitten and Tygar is a great paper, but it was written ages ago on
software that was released in 1997. Things aren't perfect now, but
let's talk about what's out there now. Even at the time, one of
Whitten's main points is how hard it is to apply usability to
security, because of how odd it is. As a very quick example, in most
forms of user design, you let exploration take a prominent place. But
it doesn't work in security because you can't click undo when you do
something you didn't intend.
* There are new generations of crypto software out there. I produce
the PGP products, and PGP Desktop and PGP Universal are automatic
systems that look up certs use them, automatically encrypt, and even
does both OpenPGP and S/MIME.
They're not perfect, and lead to other amusing issues. For example, an
hour ago, I was coordinating with someone that I'm meeting at a
conference. I got a reply saying, "I'm at the airport and can't
decrypt your message from my phone." I hadn't realized that I *had*
encrypted my message, because my system and my colleague's system had
been doing things for us.
I habitually send most of my email securely, but I don't think about
it. My robots take care of it for me. I tune policies, I don't encrypt
If you don't want to use my products, as Ben Laurie pointed out,
there's a very nice plugin for Thunderbird called Enigmail that makes
doing crypto painless.
* There are also new generations of keyservers out there that work on
the issues of the old servers to trim defunct keys, and manage other
issues. I have out there the PGP Global Directory. Think of it as a
mash-up of a keyserver along with Robot CA concepts and user
management goodness adapted from modern mailing list servers like
* A number of us are also re-thinking other concepts such as using
short-lived certificates based on the "freshness" model to constrain
lifecycle management issues.
* There are many challenges remaining. Heck, the fact that people here
apparently have not updated their knowledge any time this century is
part of the problem. But let me tell you that email encryption is
growing, and growing strongly. However, most of the successes are not
happening where you see them. They're happening in business, where
communities of partners decide they need to do secure email, and then
they do. This is another place where things have changed radically. A
decade ago, we thought that security would be a grass-roots phenomenon
where end-users and consumers would push security into those stodgy
businesses. What's happening now is the exact opposite -- savvy
businesses are putting together sophisticated security systems, and
that's slowly starting to get end-users to wake up.
I'd be happy to discuss at length where things are getting better,
where they aren't, and where some issues have been shuffled around.
But we do need to talk about what's going on now, not ten years ago.
        Jon

@_date: 2006-03-02 12:58:03
@_author: coderman 
@_subject: [dewayne@warpspeed.com: [Dewayne-Net] New paint blocks out 
hmm, faraday cage on demand sounds kind of useful.  they don't mention
the level of attenuation though, and i suspect it's not that great.
is anyone else aware of systems that can provide variable rf
attenuation on demand?

@_date: 2006-03-04 00:31:01
@_author: coderman 
@_subject: Fwd: [TSCM-L] Re: New paint blocks out cell phone signals 
you can: there are also a few companies selling faraday cloth, though i don't
recall the attenuation provided.  what i'd really like is something
toggle'able, although the product described in this thread sounds more
like snake oil than truly "nano reconfigurable faraday surface"
a friend also has an attic/loft well coated in many layers of lead
base; there are two small windows and the attenuation with lead based
appears to be pretty decent as well.  (a little hard to find these
day, though :)

@_date: 2006-03-04 00:54:29
@_author: coderman 
@_subject: [Clips] Ferrari Case Takes New Twist With Possible Tie to 
these small "police agencies" are a nice way to get equipment and toys
otherwise unaccessible to the general public.  a common loophole if
you can afford it.  of course, with all the deep black going around
(*cough cough*) who knows? :P
this entity looks a little odd, to put it mildly... (and who is Connie Wong?)
San Gabriel Valley Transit Authority
Listing Type:	Business
Listing Date:	02/09/2006 - 02/23/2006
Address:	4115 E Live Oak Ave
Arcadia, CA 91006-5865
Phone:	(626) 254-0471
San Gabriel Valley Transit Authority
Listing Type:	Business
Listing Date:	01/31/2006 - 02/23/2006
Address:	4115 E Live Oak Ave
Arcadia, CA 91006-5865
Phone:	(626) 446-1753
San Gabriel Valley Transit Authority
Listing Type:	Business
Listing Date:	12/22/2005 - Current
Address:	Address not listed
Phone:	(626) 303-3505
San Gabriel Valley Transit Authority
Listing Type:	Business
Listing Date:	05/19/2005 - 12/21/2005
Address:	148 E Lemon Ave
Monrovia, CA 91016-2808
Phone:	(626) 303-3505
Monrovia Transit Authority
Listing Type:	Business
Listing Date:	12/22/2005 - Current
Address:	Address not listed
Phone:	(626) 303-3505
Monrovia Transit Authority
Listing Type:	Business
Listing Date:	12/01/2004 - 04/05/2005
Address:	148 E Lemon Ave
Monrovia, CA 91016-2808
Phone:	(626) 303-3505
Monrovia Transit Authority
Listing Type:	Business
Listing Date:	04/25/2005 - 12/21/2005
Address:	148 E Lemon Ave
Monrovia, CA 91016-2808
Phone:	(626) 303-3505
S G V T P D
Listing Type:	Business
Listing Date:	02/22/2006 - Current
Address:	4115 E Live Oak Ave
Arcadia, CA 91006-5865
Phone:	(626) 446-1753
S G V T P D
Listing Type:	Business
Listing Date:	02/22/2006 - Current
Address:	4115 E Live Oak Ave
Arcadia, CA 91006-5865
Phone:	(626) 254-0471
San Gabriel Valley Transit Police
Listing Type:	Business
Listing Date:	12/22/2005 - Current
Address:	Address not listed
Phone:	(626) 303-3505
San Gabriel Valley Transit Police
Listing Type:	Business
Listing Date:	05/19/2005 - 12/21/2005
Address:	148 E Lemon Ave
Monrovia, CA 91016-2808
Phone:	(626) 303-3505
additional pointers welcome...

@_date: 2006-03-04 01:51:54
@_author: coderman 
@_subject: More public things you can't take pictures of in public, was: 
(also known as the thought crime prevention department)
Things you can't take pictures of in public and other psuedo crimes
enforced by hassle, annoyance and privacy invasion:
---begin various clips---
REVERSE THE PANOPTICON!  (man i love this one...)

@_date: 2006-03-04 01:54:13
@_author: coderman 
@_subject: Fwd: [TSCM-L] Re: New paint blocks out cell phone signals 
agreed, and thanks for the clarification.  it was effective enough
kill to wifi in 2.4Ghz, but this is a far cry from TEMPEST...

@_date: 2006-03-04 03:26:53
@_author: coderman 
@_subject: [Clips] Ferrari Case Takes New Twist With Possible Tie to 
yeah, they wanted the cool toys...
'''In interviews with board members, they say the rationale for
creating the transit authority police is twofold: they had the legal
right to do it, and "it sounds like a cool idea."'''
also explains why they have been hiding listings recently
(particularly the Police listings moved from Monrovia to Gabriel):
'''The bizarre revelations could also cost the agency its contract to
operate in Monrovia. City Manager Scott Ochoa said he warned Maiwandi
early on that the city did not want him wading into police
i bet they bought weapons and tactical body armor to equip their
police force too :)

@_date: 2006-03-04 08:35:55
@_author: coderman 
@_subject: Identity is Hard, Let's go Shopping 
(Posted by adam)
Kim Cameron... says: "In my view, the identity problem is one of the
hardest problems computer science has ever faced." I think this is
true, and I'd like to tackle why that is. I'm going to do that in a
couple of blog posts, because I think the subject is broad and
complex, and I'd like to offer some perspectives into that chaos.
I've been saying for a while that people like to pay for privacy, when
they understand what the threat to their privacy is, and how the
solution works. Thus, they buy curtains. Curtains work very well to
enhance privacy by stopping passers-by from looking through your
windows. Another part of that talk is that privacy means a lot of
different things to people, ranging from 'the right to be left alone'
to 'informational self-determination' to 'abortion.' I believe that
identity displays very similar properties in how widely the term is
Identity is a problem because it means so many different things about
who we are, and how we perceive ourselves, others, and our
relationships with them. Identity also entails a set of business
relationships, and the experiences and reliance that entities embed
into those relationships. Finally, identity entails a set of
government relationships, some of which are about citizenship, or
various sorts of temporary presence or exclusion, or moneys flowing to
or from the government. Sometimes, these relationships overlap in
various ways.
This relates to Zooko's "Decentralized, Secure, Human-Meaningful"
triangle. Zooko looks at the digital systems for dealing with
identifiers, and the properties those identifiers can have. I want to
start from the variety of relationships, and the way people think
about the relationships, then move to identifiers. Replacing the
actual relationship with a digital identifier often creates issues,
because the two differ.
As we encode various forms of identity onto computers, we make choices
about identifiers and representations. Some of these choices are now
such second nature that actually listing the details them seems
bizarre: "My mail client sends a message to alice at example.com"* vs "I
send mail to mom." We have internalized the idea that an email address
is a good identifier for a person. We tend to internalize these
representations fairly easily, even when its not a good idea.
"123-45-6789 applied for this credit card," that must be Alice
I'll talk more about the issues of assigning trust or reliance to
identifiers, rather than people, in another post.

@_date: 2006-03-04 08:51:01
@_author: coderman 
@_subject: telco network security con 
despite the marketing hype, att's nda team would actually be fun to
see.  something tells me they wont be allowing photographs...
"Communications Security in the Digital Age Featured Only at
TelecomNEXT; AT&T's National Disaster Recovery Team on Display on
TelecomNEXT Exhibit Floor"
 Thursday, 02 March 2006
Powered By BusinessWire WASHINGTON--(BUSINESS WIRE)--March 2, 2006--A
top priority for telecom service providers competing in today's
borderless economy, key security issues will play a central role on
the exhibit floor and in must-attend conference sessions at
TelecomNEXT in Las Vegas, March 19 - 23, 2006. TelecomNEXT, the only
place where the business and technology of communications and
entertainment meet, replaces SUPERCOMM(R) as USTelecom's annual
industry show.
"Network security and the ability to operate in the face of disaster
are some of the top concerns for integrated communications providers,"
said John Abel, USTelecom's Senior Vice President, Marketing,
Membership and Business Development. "In today's converged telecom
market, security solutions are more critical than ever before and
TelecomNEXT is the only place to see the latest advances in network
The TelecomNEXT exhibit floor was recently expanded and an additional
hall was added to accommodate a premier enterprise security exhibit
-AT&T's Network Disaster Recovery (NDR) team. The NDR team is part of
AT&T's comprehensive business continuity plan to ensure that voice and
data communications can be restored quickly for business and
government customers if a disaster damages or destroys parts of the
network. The fully mobile NDR team allows AT&T to monitor, manage and
proactively protect the networks of its enterprise customers.
In addition, several TelecomNEXT sessions will focus on critical
network security and reliability issues. These sessions bring together
experts on communications security issues and include a panel on cyber
security presented by representatives from the Department of Homeland
Security's National Cyber Security Division.
Some of the featured sessions include:
    --  Cyber Security and Energy Interdependency Summit
        This roundtable panel will discuss the reliability and
        security of the nation's electric grid, explore alternative
        back-up energy sources for central offices, and examine SCADA
        and cyber security issues.
            --  Steve Conrad, Sandia National Lab - Energy and
                Telecommunications Interdependencies
            --  Dave Robinson, Sandia National Lab - Risk assessment,
                business continuity, grid vulnerability
            --  John Boyes, Sandia National Lab - Energy Surety
                Program, Distributed Energy Resources and Energy
                Storage Systems
            --  Mike Hickey, VP, National Security, Verizon
            --  David Barron, Asst. VP, National Security, BellSouth
    --  Enterprise Security 101: Business Continuity, Disaster
        Recovery and Cyber Security
        Representatives from AT&T's NDR team will be on the
        TelecomNEXT show floor to discuss fundamentals of successful
        corporate business continuity planning. The session will
        explore new business opportunities from offering business
        continuity expertise and solutions to enterprise customers.
            --  Robin Bienfait, VP, Network Operations, AT&T
            --  Kenneth J. Smith, Director, Global Network Operations,
                Network Disaster Recovery, AT&T
    --  Prioritizing Cyber Security
        Produced by the Department of Homeland Security's National
        Cyber Security Division, this session looks at the operational
        and technical challenges to cyber security, including the
        unique challenges to small businesses.
            --  Liesyl Franz, Director, International Affairs, Deputy
                Director for Outreach and Awareness, National Cyber
                Security Division, Dept. Homeland Security
            --  Ron Layton, Deputy Director, Law Enforcement and
                Intelligence National Cyber Security Division, Dept.
                Homeland Security
            --  Ron Teixeira, Executive Director, National Cyber
                Security Alliance
            --  John E. Scott, II, Small Business Administration,
                Nevada District Director
            --  Robert G. Schoshinski, Division of Marketing
                Practices, Bureau of Consumer Protection, Federal
                Trade Commission
Several technical papers on network security will be presented by
Juniper Networks, Nortel, Lucent Worldwide Services, Broadwing
Communications, VeriSign Communications Services, and VoIPshield
Systems on Monday, March 20 from 11:40 am to 3:00 pm. The TelecomNEXT
Paper presentations will address wireless, VoIP and converged network
security; as well as several other topics. The papers offer technical
decision makers, designers, engineers, network developers, and other
stakeholders the information they need to make informed purchasing
The keynote speakers for TelecomNEXT are ...
TelecomNEXT will be held at the Mandalay Bay Convention Center in Las
Vegas, Nevada, March 19-23, 2006. The exhibit floor will be open
Tuesday, March 21 and Wednesday, March 22. For more information on
TelecomNEXT, go to

@_date: 2006-03-06 10:31:06
@_author: coderman 
@_subject: POLL: crypto hardware & Fwd: [Xen-devel] Announce of our Xen 
mmm, virtual machines...
Some time before Christmas, a project was started. The task was to
enhance an existing LiveCD solution with User-mode Linux. A number of
requirements was stated, where the greatest challenge was to fit 10
virtual routers within an old no-name PC with only 256MB Ram.
With this solution, students taking CCNA/CCNP level studies can have
their own router lab on a bootable CD... The student can set up a virtual
network of 10 routers or hosts, and exercise BGP, OSPF, ISIS and RIP
how many of you cypherpunks have a padlock enabled core at your
disposal (C5P, C5J or +)?
anyone who will have one within the next two months (if not now)?
Hello all,
Some time before Christmas, a project was started. The task was to
enhance an existing LiveCD solution with User-mode Linux. A number of
requirements was stated, where the greatest challenge was to fit 10
virtual routers within an old no-name PC with only 256MB Ram. And the
solution must still be run from a LiveCD.
Thanks to Xen, the task was possible to complete.
-But, what does it do?
With this solution, students taking CCNA/CCNP level studies can have
their own router lab on a bootable CD. No need for expensive equipment.
The student can set up a virtual network of 10 routers or hosts, and
exercise BGP, OSPF, ISIS and RIP routing. The routing software is
Quagga, whose interface is very similar to Ciscos native CLI.
Feel free to download our first Release Candidate at the project website;
Please note that the name "Qroutix" isn't ment for the final product.
We're currently phasing over to the new name, which will impact the URL
eventually. If the abobe link doesn't work, please try:
Don't hesitate to mail me or Anders feedback if you like (or dislike)
our project.
Best regards
Rickard Borgmdster
Xen-devel mailing list
Xen-devel at lists.xensource.com
To unsubscribe from this list: send the line "unsubscribe netdev" in
the body of a message to majordomo at vger.kernel.org
More majordomo info at

@_date: 2006-03-06 10:51:13
@_author: coderman 
@_subject: POLL: crypto hardware & Fwd: [Xen-devel] Announce of our 
thanks; i'd be curious about general availability of the C5XL / single
hw entropy source mainboards as well. (this board at least provides
enough entropy for robust keying, even if ciphers and digests in
software are a bit slow at ~1Ghz)
i'm not sure and i'm not too optimistic; some people do have
limited/dev C5J boards to play with though...
i reallly want to get my hands on an armful of nano-itx esther systems. :P

@_date: 2006-03-06 18:11:11
@_author: coderman 
@_subject: wars of attrition 
hey, at least the cypherpunks aren't mentioned! *grin*
[small blessings for a nearly defunct and moribund list perhaps...]
let's get this thought crime party started!
favorite quote:
I turned the letter over to my lawyer and told him to send the
following message to the feds:
Fuck you. Strong letter to follow.
(so how much of this is actually documented and blatantly intimidating
versus journalistic 'emphasis' with passion?)
 Bush declares war on freedom of the press
March 6, 2006 07:44 AM / The Rant .
By DOUG THOMPSON
Using many of the questionable surveillance and monitoring techniques
that brought both questions and criticism to his administration,
President George W. Bush has launched a war against reporters who
write stories unfavorable to his actions and is planning to prosecute
journalists to make examples of them in his "war on terrorism."
Bush recently directed Attorney General Alberto Gonzales to use
"whatever means at your disposal" to wiretap, follow, harass and
investigate journalists who have published stories about the
administration's illegal use of warrantless wiretaps, use of faulty
intelligence and anything else he deems "detrimental to the war on
Reporters for The New York Times, which along with Capitol Hill Blue
revealed use of the National Security Agency to monitor phone calls
and emails of Americans, say FBI agents have interviewed them and
criminal prosecutors at the Justice Department admit they are laying
"the groundwork for a grand jury that could lead to criminal charges,"
CIA Director Porter Goss told Congress recently that "it is my aim and
it is my hope that we will witness a grand jury investigation with
reporters present being asked to reveal who is leaking this
information. I believe the safety of this nation and the people of
this country deserve nothing less."
As part of the investigation, the Justice Department, Department of
Homeland Security and the National Security Agency are wiretapping
reporters' phones, following journalists on a daily basis, searching
their homes and offices under a USA Patriot Act provision that allows
"secret and undisclosed searches" and pouring over financial and
travel records of hundreds of Washington-based reporters.
Spokesmen for the Justice Department and Department of Homeland
Security admit there are "ongoing investigations" regarding
publication of stories "involving threats to national security" but
will not reveal what those investigations include.
In addition to using the USA Patriot Act to pry into the lives of
journalists, the Justice Department has also dusted off a pre-World
War I law to prosecute people who receive classified information,
although the law was aimed at military personnel not civilians.
"This is the first administration that I can remember, including
Nixon's, that said we need to think about a law that would put
journalists who print national security things up in front of grand
juries and put them in jail if they don't reveal their sources," says
David Gergen, who served as President Regan's director of
communication and also worked in the Nixon and Ford White Houses.
Political scientist George Harleigh, who worked in the Nixon
administration, says such use of federal law enforcement authority was
illegal when Nixon tried it and still so today.
"We're talking about a basic violation of the Constitutional guarantee
of a free press as well as a violation of the rights of privacy of
American citizens," Harleigh says. "I had hoped we would have learned
our lessons from the Nixon era. Sadly, it appears we have not."
In recent weeks, the FBI has issued hundreds of "National Security
Letters," directing employers, banks, credit card companies, libraries
and other entities to turn over records on reporters. Under the USA
Patriot Act, those who must turn over the records are also prohibited
from revealing they have done so to the subject of the federal probes.
"The significance of this cannot be overstated," says prominent New
York litigator Glenn Greenwald. "In essence, while the President sits
in the White House undisturbed after proudly announcing that he has
been breaking the law and will continue to do so, his slavish
political appointees at the Justice Department are using the mammoth
law enforcement powers of the federal government to find and
criminally prosecute those who brought this illegal conduct to light.
"This flamboyant use of the forces of criminal prosecution to threaten
whistle-blowers and intimidate journalists are nothing more than the
naked tactics of street thugs and authoritarian juntas."
Just how widespread, and uncontrolled, this latest government assault
has become hit close to home last week when one of the FBI's National
Security Letters arrived at the company that hosts the servers for
this web site, Capitol Hill Blue.
The letter demanded traffic data, payment records and other
information about the web site along with information on me, the
Now that's a problem. I own the company that hosts Capitol Hill Blue.
So, in effect, the feds want me to turn over information on myself and
not tell myself that I'm doing it. You'd think they'd know better.
I turned the letter over to my lawyer and told him to send the
following message to the feds:
Fuck you. Strong letter to follow.

@_date: 2006-03-06 18:33:13
@_author: coderman 
@_subject: wars of attrition (msnbc? that's a little unusual!) 
sorry, my humor is lacking; this list is a few hundred KSLOC from
being any kind of threat. KE KE KE...
looks like this hit msnbc??
favorite quotes:
... the Justice Department is aggressively trying to identify the
sources for two explosive news stories: the existence of secret
Central Intelligence Agency prisons in eastern Europe, and the
National Security Agency's domestic surveillance programme...
"When you have more and more information being classified, and more
and more secrets being kept, the only way reporters can get
information is when internal whistleblowers provide it. And that
drives this administration crazy," says Lucy Dalglish, executive
director of the Reporters Committee for Freedom of the Press.
In the first four years of the administration, the volume of
classified documents barred from public distribution nearly doubled to
close to 16m annually. Over the same time, declassification of
documents has slowed to a trickle.
White House steps up effort to halt flow of secrets
By Edward Alden in Washington
Financial Times
Updated: 9:12 p.m. ET March 6, 2006
The administration of President George W. Bush is mounting an
unprecedented effort to crack down on leaks of government secrets,
even as it is vastly expanding the range of information deemed too
sensitive to share with the public.
That twin effort has raised fears that the White House may succeed in
shutting off the flow of such information by threatening to jail those
who leak secrets and those who receive them.
The issue has come to a head in the government's efforts to prosecute
two pro-Israeli lobbyists for receiving classified information from a
Pentagon official. Larry Franklin, the official, was sentenced to 12
years in prison in January, and the lobbyists  Steven Rosen and Keith
Weissman of the American Israel Public Affairs Committee  are to go
on trial next month.
Many see the case, which relies on a novel interpretation of a
90-year-old espionage law, as a test of whether the administration can
exercise new powers to shut off leaks that have been severely
embarrassing to the White House. In particular, the Justice Department
is aggressively trying to identify the sources for two explosive news
stories: the existence of secret Central Intelligence Agency prisons
in eastern Europe, and the National Security Agency's domestic
surveillance programme.
The Washington Post reported at the weekend that dozens of officials
from both agencies had been questioned recently by the FBI in the leak
"When you have more and more information being classified, and more
and more secrets being kept, the only way reporters can get
information is when internal whistleblowers provide it. And that
drives this administration crazy," says Lucy Dalglish, executive
director of the Reporters Committee for Freedom of the Press.
Since the September 11 attacks, the administration has vastly expanded
the range of information deemed secret, ranging from the serious 
such as the NSA spying programme  to the seemingly trivial. It has
begun withholding, for instance, the names and telephone numbers of
many government officials, making it more difficult for reporters and
others to track down knowledgeable sources.
In the first four years of the administration, the volume of
classified documents barred from public distribution nearly doubled to
close to 16m annually. Over the same time, declassification of
documents has slowed to a trickle.
Porter Goss, director of the Central Intelligence Agency, warned in a
Senate hearing last month that leaks had caused "severe damage" to his
agency. "It is my aim and it is my hope that we will witness a grand
jury investigation, with reporters present, being asked to reveal who
is leaking this information," he said.
That threat is the main reason the prosecution of Mr Rosen and Mr
Weissman has caused such concern. The two are accused of discussing
with Mr Franklin a classified draft memorandum regarding US policy
towards Iran. In a court memorandum filed in support of the lobbyists,
a former Justice Department official, Viet Dinh  chief architect of
the Patriot Act  argued that the prosecution would have a chilling
effect on debate over national security issues.
"Until now, no administration has attempted to address what it may
perceive as annoying or premature 'leaks' by criminalising the receipt
and use of unsolicited oral information obtained as part of the
lobbying or reporting process," he wrote.
The government's effort, he said, would in effect "create some type of
official secrets act through the prosecution of a test case against
two individuals who were engaged in a practice that defines foreign
policy lobbying  the sharing of information  in which lobbyists and
members of the press engage every day."
The US has long resisted adopting a British-style Official Secrets
Act. But support for the idea is growing. In 2000, President Bill
Clinton vetoed legislation passed by the Republican Congress that
would have criminalised unauthorised leaks of classified information,
though even that bill would not have made the receipt of such
information a crime. The Republican chairmen of both the Senate and
House intelligence committees have said recently they might make
another effort to pass such legislation.
Critics say the obsession with leaks is absurd because top White House
officials have been at the forefront of leaking the most sensitive
classified information. For instance, Lewis "Scooter" Libby, the
former chief of staff to Vice-President Dick Cheney who faces perjury
charges in the Valerie Plame case, has said in his defence that Mr
Cheney authorised him to discuss with some reporters the CIA's
classified 2002 National Intelligence Estimate (NIE) on Iraq's weapons
programmes in the run-up to the Iraq war. Newspaper stories based on
the false claims in the NIE that Iraq possessed chemical and
biological weapons, and was developing nuclear arms, helped build US
public support for invading Iraq.
In a television interview last month, Mr Cheney said he had the power
to declassify such information, citing an executive order signed by
the president. This is precisely why the system for classifying
secrets is open to abuse, according to Thomas Blanton, director of the
National Security Archive, which presses for declassification of
information. "The fact is that most of the leaks that take place are
coming from very high-ranking officials, up to and including the
The crackdown on leaks, he said, was a result of White House anger
that mid-level officials were "in open revolt" against policies. "The
top officials can't tell the real secrets from the embarrassments, and
they are reacting to the embarrassments," he said. "It destroys the
credibility we need to maintain the real secrets."
Copyright The Financial Times Ltd. All rights reserved.

@_date: 2006-03-08 10:21:32
@_author: coderman 
@_subject: wars of attrition & reverse rubber hose & the 
i like to think you don't need any bats at all; waging direct lethal
violence against the largest and best equipped military in the world
(esp. adding up police, swat, n.guard, military, etc) fuels their
propaganda machine and gets you crushed like an ant under foot.
bomb throwers and assassins get no sympathy from the public no matter
justified your perceived grievances.
cutting at the heart of this nation-scale responsibility diffusion
machine requires taxing communication and commerce engines which make
its very existence possible.  this tax is applied in the form of
continued and targeted infrastructure disruption against those
entities which are refusing and deflecting oversight and
accountability for their actions, and all those who serve them
directly or indirectly.
punks with portable saws and thermic lances slicing fiber and junking
equipment is much more palatable to the public when used against
entities already perceived unpopular and abusive to fundamental
rights.  we've already talked about data mining and critical
infrastructure analysis to direct such attacks in the most effective
manner possible.
although somehow i think this will get you a more severe response than
killing random yes men (despite the fact this is limited to property
damage alone).
hmmm, the information required to organize such efforts would be a
good fit for the blacknet.

@_date: 2006-03-08 11:21:50
@_author: coderman 
@_subject: Bush's Mysterious 'New Programs' 
maybe the new detention centers are for journalists of insufficient loyalty...
[it's hard for me to be outraged or shocked by anything done by our
leaders at this point, but massive detention center build-out for 'new
programs' is raising the hair on the back of my neck.]
"In the war against terrorists of global reach, as the Nation learned
all too well on Sept. 11, 2001, the territory of the United States is
part of the battlefield," Bush's lawyers argued in briefs to the
federal courts. [Washington Post, July 19, 2005]
    Given Bush's now open assertions that he is using his "plenary" -
or unlimited - powers as Commander in Chief for the duration of the
indefinite War on Terror, Americans can no longer trust that their
constitutional rights protect them from government actions.
    As former Vice President Al Gore asked after recounting a litany
of sweeping powers that Bush has asserted to fight the War on Terror,
"Can it be true that any President really has such powers under our
Constitution? If the answer is 'yes,' then under the theory by which
these acts are committed, are there any acts that can on their face be
    In such extraordinary circumstances, the American people might
legitimately ask exactly what the Bush administration means by the
"rapid development of new programs," which might require the
construction of a new network of detention camps.
Bush's Mysterious 'New Programs'
by Nat Parry; Truthout ; March 08, 2006
    Not that George W. Bush needs much encouragement, but Sen. Lindsey
Graham suggested to Attorney General Alberto Gonzales a new target for
the administration's domestic operations - Fifth Columnists,
supposedly disloyal Americans who sympathize and collaborate with the
    "The administration has not only the right, but the duty, in my
opinion, to pursue Fifth Column movements," Graham, R-S.C., told
Gonzales during Senate Judiciary Committee hearings on Feb. 6.
    "I stand by this President's ability, inherent to being Commander
in Chief, to find out about Fifth Column movements, and I don't think
you need a warrant to do that," Graham added, volunteering to work
with the administration to draft guidelines for how best to neutralize
this alleged threat.
    "Senator," a smiling Gonzales responded, "the President already
said we'd be happy to listen to your ideas."
    In less paranoid times, Graham's comments might be viewed by many
Americans as a Republican trying to have it both ways - ingratiating
himself to an administration of his own party while seeking some
credit from Washington centrists for suggesting Congress should have
at least a tiny say in how Bush runs the War on Terror.
    But recent developments suggest that the Bush administration may
already be contemplating what to do with Americans who are deemed
insufficiently loyal or who disseminate information that may be
considered helpful to the enemy.
    Top US officials have cited the need to challenge news that
undercuts Bush's actions as a key front in defeating the terrorists,
who are aided by "news informers" in the words of Defense Secretary
Donald Rumsfeld.
    Detention Centers
    Plus, there was that curious development in January when the Army
Corps of Engineers awarded Halliburton subsidiary Kellogg Brown & Root
a $385 million contract to construct detention centers somewhere in
the United States, to deal with "an emergency influx of immigrants
into the US, or to support the rapid development of new programs," KBR
said. [Market Watch, Jan. 26, 2006]
    Later, the New York Times reported that "KBR would build the
centers for the Homeland Security Department for an unexpected influx
of immigrants, to house people in the event of a natural disaster or
for new programs that require additional detention space." [Feb. 4,
    Like most news stories on the KBR contract, the Times focused on
concerns about Halliburton's reputation for bilking US taxpayers by
overcharging for sub-par services.
    "It's hard to believe that the administration has decided to
entrust Halliburton with even more taxpayer dollars," remarked Rep.
Henry Waxman, D-California.
    Less attention centered on the phrase "rapid development of new
programs" and what kind of programs would require a major expansion of
detention centers, each capable of holding 5,000 people. Jamie
Zuieback, a spokeswoman for Immigration and Customs Enforcement,
declined to elaborate on what these "new programs" might be.
    Only a few independent journalists, such as Peter Dale Scott and
Maureen Farrell, have pursued what the Bush administration might
actually be thinking.
    Scott speculated that the "detention centers could be used to
detain American citizens if the Bush administration were to declare
martial law."
    He recalled that during the Reagan administration, National
Security Council aide Oliver North organized Rex-84 "readiness
exercise," which contemplated the Federal Emergency Management Agency
rounding up and detaining 400,000 "refugees," in the event of
"uncontrolled population movements" over the Mexican border into the
United States.
    Farrell pointed out that because "another terror attack is all but
certain, it seems far more likely that the centers would be used for
post-911-type detentions of immigrants rather than a sudden deluge" of
immigrants flooding across the border.
    Vietnam-era whistleblower Daniel Ellsberg said, "Almost certainly
this is preparation for a roundup after the next 9/11 for
Mid-Easterners, Muslims and possibly dissenters. They've already done
this on a smaller scale, with the 'special registration' detentions of
immigrant men from Muslim countries, and with Guantanamo."
    Labor Camps
    There also was another little-noticed item posted at the US Army
Web site, about the Pentagon's Civilian Inmate Labor Program. This
program "provides Army policy and guidance for establishing civilian
inmate labor programs and civilian prison camps on Army
    The Army document, first drafted in 1997, underwent a "rapid
action revision" on Jan. 14, 2005. The revision provides a "template
for developing agreements" between the Army and corrections facilities
for the use of civilian inmate labor on Army installations.
    On its face, the Army's labor program refers to inmates housed in
federal, state and local jails. The Army also cites various federal
laws that govern the use of civilian labor and provide for the
establishment of prison camps in the United States, including a
federal statute that authorizes the Attorney General to "establish,
equip, and maintain camps upon sites selected by him" and "make
available ... the services of United States prisoners" to various
government departments, including the Department of Defense.
    Though the timing of the document's posting - within the past few
weeks - may just be a coincidence, the reference to a "rapid action
revision" and the KBR contract's contemplation of "rapid development
of new programs" have raised eyebrows about why this sudden need for
    These developments also are drawing more attention now because of
earlier Bush administration policies to involve the Pentagon in
    operations inside the United States.
    Pentagon Surveillance
    Despite the Posse Comitatus Act's prohibitions against US military
personnel engaging in domestic law enforcement, the Pentagon has
expanded its operations beyond previous boundaries, such as its role
in domestic surveillance activities.
    The Washington Post has reported that since the Sept. 11, 2001,
terror attacks, the Defense Department has been creating new agencies
that gather and analyze intelligence within the United States.
[Washington Post, Nov.
    27, 2005]
    The White House also is moving to expand the power of the
Pentagon's Counterintelligence Field Activity (CIFA), created three
years ago to consolidate counterintelligence operations. The White
House proposal would transform CIFA into an office that has authority
to investigate crimes such as treason, terrorist sabotage or economic
    The Pentagon also has pushed legislation in Congress that would
create an intelligence exception to the Privacy Act, allowing the FBI
and others to share information about US citizens with the Pentagon,
CIA and other intelligence agencies. But some in the Pentagon don't
seem to think that new laws are even necessary.
    In a 2001 Defense Department memo that surfaced in January 2006,
the US Army's top intelligence officer wrote, "Contrary to popular
belief, there is no absolute ban on [military] intelligence components
collecting US person information."
    Drawing a distinction between "collecting" information and
"receiving" information on US citizens, the memo argued that "MI
[military intelligence] may receive information from anyone, anytime."
[See CQ.com, Jan. 31, 2005]
    This receipt of information presumably would include data from the
National Security Agency, which has been engaging in surveillance of
US citizens without court-approved warrants in apparent violation of
the Foreign Intelligence Security Act. Bush approved the program of
warrantless wiretaps shortly after 9/11.
    There also may be an even more extensive surveillance program.
Former NSA employee Russell D. Tice told a congressional committee on
Feb. 14 that such a top-secret surveillance program existed, but he
said he couldn't discuss the details without breaking classification
    Tice added that the "special access" surveillance program may be
violating the constitutional rights of millions of Americans. [UPI,
Feb. 14, 2006]
    With this expanded surveillance, the government's list of
terrorist suspects is rapidly swelling.
    The Washington Post reported on Feb. 15 that the National
Counterterrorism Center's central repository now holds the names of
325,000 terrorist suspects, a four-fold increase since the fall of
    Asked whether the names in the repository were collected through
the NSA's domestic surveillance program, an NCTC official told the
Post, "Our database includes names of known and suspected
international terrorists provided by all intelligence community
organizations, including NSA."
    Homeland Defense
    As the administration scoops up more and more names, members of
Congress also have questioned the elasticity of Bush's definitions for
words like terrorist "affiliates," used to justify wiretapping
Americans allegedly in contact with such people or entities.
    During the Senate Judiciary Committee's hearing on the wiretap
program, Sen. Dianne Feinstein, D-California, complained that the
House and Senate Intelligence Committees "have not been briefed on the
scope and nature of the program."
    Feinstein added that, therefore, the committees "have not been
able to explore what is a link or an affiliate to al-Qaeda or what
minimization procedures (for purging the names of innocent people) are
in place."
    The combination of the Bush administration's expansive reading of
its own power and its insistence on extraordinary secrecy has raised
the alarm of civil libertarians when contemplating how far the
Pentagon might go in involving itself in domestic matters.
    A Defense Department document, entitled the "Strategy for Homeland
Defense and Civil Support," has set out a military strategy against
terrorism that envisions an "active, layered defense" both inside and
outside US territory. In the document, the Pentagon pledges to
"transform US military forces to execute homeland defense missions in
the ... US homeland."
    The Pentagon strategy paper calls for increased military
reconnaissance and surveillance to "defeat potential challengers
before they threaten the United States." The plan "maximizes threat
awareness and seizes the initiative from those who would harm us."
    But there are concerns over how the Pentagon judges "threats" and
who falls under the category "those who would harm us." A Pentagon
official said the Counterintelligence Field Activity's TALON program
has amassed files on antiwar protesters.
    In December 2005, NBC News revealed the existence of a secret
400-page Pentagon document listing 1,500 "suspicious incidents" over a
10-month period, including dozens of small antiwar demonstrations that
were classified as a "threat."
    The Defense Department also might be moving toward legitimizing
the use of propaganda domestically, as part of its overall war
    A secret Pentagon "Information Operations Roadmap," approved by
Rumsfeld in October 2003, calls for "full spectrum" information
operations and notes that "information intended for foreign audiences,
including public diplomacy and PSYOP, increasingly is consumed by our
domestic audience and vice-versa."
    "PSYOPS messages will often be replayed by the news media for much
larger audiences, including the American public," the document states.
The Pentagon argues, however, that "the distinction between foreign
and domestic audiences becomes more a question of USG [US government]
intent rather than information dissemination practices."
    It calls for "boundaries" between information operations abroad
and the news media at home, but does not outline any corresponding
limits on PSYOP campaigns.
    Similar to the distinction the Pentagon draws between "collecting"
and "receiving" intelligence on US citizens, the Information
Operations Roadmap argues that as long as the American public is not
intentionally "targeted," any PSYOP propaganda consumed by the
American public is acceptable.
    The Pentagon plan also includes a strategy for taking over the
Internet and controlling the flow of information, viewing the Web as a
potential military adversary. The "roadmap" speaks of "fighting the
net," and implies that the Internet is the equivalent of "an enemy
weapons system."
    In a speech on Feb. 17 to the Council on Foreign Relations,
Rumsfeld elaborated on the administration's perception that the battle
over information would be a crucial front in the War on Terror, or as
Rumsfeld calls it, the Long War.
    "Let there be no doubt, the longer it takes to put a strategic
communication framework into place, the more we can be certain that
the vacuum will be filled by the enemy and by news informers that most
assuredly will not paint an accurate picture of what is actually
taking place," Rumsfeld said.
    The Department of Homeland Security also has demonstrated a
tendency to deploy military operatives to deal with domestic crises.
    In the wake of Hurricane Katrina, the department dispatched
"heavily armed paramilitary mercenaries from the Blackwater private
security firm, infamous for their work in Iraq, (and had them) openly
patrolling the streets of New Orleans," reported journalists Jeremy
Scahill and Daniela Crespo on Sept.
    10, 2005.
    Noting the reputation of the Blackwater mercenaries as "some of
the most feared professional killers in the world," Scahill and Crespo
said Blackwater's presence in New Orleans "raises alarming questions
about why the government would allow men trained to kill with impunity
in places like Iraq and Afghanistan to operate here."
    US Battlefield
    In the view of some civil libertarians, a form of martial law
already exists in the United States and has been in place since
shortly after the 9/11 attacks when Bush issued Military Order No. 1
which empowered him to detain any non-citizen as an international
terrorist or enemy combatant.
    "The President decided that he was no longer running the country
as a civilian President," wrote civil rights attorney Michael Ratner
in the book
    Guantanamo: What the World Should Know. "He issued a military
order giving himself the power to run the country as a general."
    For any American citizen suspected of collaborating with
terrorists, Bush also revealed what's in store. In May 2002, the FBI
arrested US citizen Jose Padilla in Chicago on suspicion that he might
be an al-Qaeda operative planning an attack.
    Rather than bring criminal charges, Bush designated Padilla an
"enemy combatant" and had him imprisoned indefinitely without benefit
of due process. After three years, the administration finally brought
charges against Padilla, in order to avoid a Supreme Court showdown
the White House might have lost.
    But since the Court was not able to rule on the Padilla case, the
administration's arguments have not been formally repudiated. Indeed,
despite filing charges against Padilla, the White House still asserts
the right to detain US citizens without charges as enemy combatants.
    This claimed authority is based on the assertion that the United
States is at war and the American homeland is part of the battlefield.
    "In the war against terrorists of global reach, as the Nation
learned all too well on Sept. 11, 2001, the territory of the United
States is part of the battlefield," Bush's lawyers argued in briefs to
the federal courts. [Washington Post, July 19, 2005]
    Given Bush's now open assertions that he is using his "plenary" -
or unlimited - powers as Commander in Chief for the duration of the
indefinite War on Terror, Americans can no longer trust that their
constitutional rights protect them from government actions.
    As former Vice President Al Gore asked after recounting a litany
of sweeping powers that Bush has asserted to fight the War on Terror,
"Can it be true that any President really has such powers under our
Constitution? If the answer is 'yes,' then under the theory by which
these acts are committed, are there any acts that can on their face be
    In such extraordinary circumstances, the American people might
legitimately ask exactly what the Bush administration means by the
"rapid development of new programs," which might require the
construction of a new network of detention camps.

@_date: 2006-03-08 13:15:12
@_author: coderman 
@_subject: A break-in to end all break-ins - In 1971, stolen FBI files 
heh, wonder who did it?  wonder if 'The Citizens' Commission to
Investigate the FBI' is an idea whose time has come (back again?)
A break-in to end all break-ins
In 1971, stolen FBI files exposed the government's domestic spying program.
By Allan M. Jalon
ALLAN M. JALON is a longtime contributor to The Times and other
publications on issues of culture and media.
March 8, 2006
THIRTY-FIVE YEARS ago today, a group of anonymous activists broke into
the small, two-man office of the Federal Bureau of Investigation in
Media, Pa., and stole more than 1,000 FBI documents that revealed
years of systematic wiretapping, infiltration and media manipulation
designed to suppress dissent.
The Citizens' Commission to Investigate the FBI, as the group called
itself, forced its way in at night with a crowbar while much of the
country was watching the Muhammad Ali-Joe Frazier fight. When agents
arrived for work the next morning, they found the file cabinets
virtually emptied.
Within a few weeks, the documents began to show up  mailed
anonymously in manila envelopes with no return address  in the
newsrooms of major American newspapers. When the Washington Post
received copies, Atty. Gen. John N. Mitchell asked Executive Editor
Ben Bradlee not to publish them because disclosure, he said, could
"endanger the lives" of people involved in investigations on behalf of
the United States.
Nevertheless, the Post broke the first story on March 24, 1971, after
receiving an envelope with 14 FBI documents detailing how the bureau
had enlisted a local police chief, letter carriers and a switchboard
operator at Swarthmore College to spy on campus and black activist
groups in the Philadelphia area.
More documents went to other reporters  Tom Wicker received copies at
his New York Times office; so did reporters at the Los Angeles Times 
and to politicians including Sen. George McGovern of South Dakota and
Rep. Parren J. Mitchell of Maryland.
To this day, no individual has claimed responsibility for the
break-in. The FBI, after building up a six-year, 33,000-page file on
the case, couldn't solve it. But it remains one of the most lastingly
consequential (although underemphasized) watersheds of political
awareness in recent American history, one that poses tough questions
even today for our national leaders who argue that fighting foreign
enemies requires the government to spy on its citizens. The break-in
is far less well known than Daniel Ellsberg's leak of the Pentagon
Papers three months later, but in my opinion it deserves equal
Found among the Media documents was a new word, "COINTELPRO," short
for the FBI's "secret counterintelligence program," created to
investigate and disrupt dissident political groups in the U.S. Under
these programs, beginning in 1956, the bureau worked to "enhance the
paranoia endemic in these circles," as one COINTELPRO memo put it, "to
get the point across there is an FBI agent behind every mailbox."
The Media documents  along with further revelations about COINTELPRO
in the months and years that followed  made it clear that the bureau
had gone beyond mere intelligence-gathering to discredit, destabilize
and demoralize groups  many of them peaceful, legal civil rights
organizations and antiwar groups  that the FBI and Director J. Edgar
Hoover found offensive or threatening.
For instance, agents sought to persuade Martin Luther King Jr. to kill
himself just before he received the Nobel Prize. They sent him a
composite tape made from bugs planted illegally in his hotel rooms
when he was entertaining women other than his wife  and threatened to
make it public. "King, there is one thing left for you to do. You know
what it is," FBI operatives wrote in their anonymous letter.
Under COINTELPRO, the bureau also targeted actress Jean Seberg for
having made a donation to the Black Panther Party. The fragile actress
ultimately committed suicide after a gossip nugget based on a FBI
wiretap was leaked to the L.A. Times and published. The item,
suggesting that the father of the baby she was carrying was a Black
Panther rather than her French writer-husband, turned out to be wrong.
The sheer reach of a completely politicized FBI was one of the most
frightening revelations of the Media documents. Underground newspapers
were targeted. Students (and their professors) were targeted.
Celebrities were targeted. The Communist Party of the U.S.A., the
Southern Christian Leadership Conference, the Student Non-Violent
Organizing Committee, the Black Panther Party, the Women's Strike for
Peace  all were targeted. "Neutralize them in the same manner they
are trying to destroy and neutralize the U.S.," one memo said.
Eventually, the COINTELPRO memos  some from Media and some unearthed
later  prompted hearings led by Rep. Don Edwards of California and by
Sen. Frank Church of Idaho on intelligence agency abuses. In the
mid-1970s, the wayward agency began finally to be reined in.
It is tragic when people lose faith in their government to the extent
that they feel they must break laws to expose corruption.
But a war that had been started and sustained by lies had gone on for
years. And a government had betrayed its citizens, manipulating their
fear to strengthen its grip on power.
Today, again, many people worry that their government may be on the
road to subverting its own ideals. I hope that the commemoration of
those unknown activists being held today in Media, Pa., will serve as
a reminder that fighting for democracy abroad must remain more than
merely an excuse to weaken civil liberties at home.

@_date: 2006-03-08 20:22:29
@_author: coderman 
@_subject: unknown_subject 
perhaps we should add "how to get the hell away from those crazy
cypherpunks" to the FAQ...

@_date: 2006-03-09 10:32:42
@_author: coderman 
@_subject: wars of attrition & reverse rubber hose & the 
(ah for the good old days; public discourse on proposed legislation
should provide the option of challenging your representative to a
duel.  *grin*
 )
regarding resource consumption attacks to stem the capricious
execution of NSL's:
can you give them their requested data on cases of punchcards?  and
bill them for it?
most annoying and obscure data storage format as a feature; that's a
disturbing thought...
[would it be punch cards or bernoulli disks?]

@_date: 2006-03-09 16:06:34
@_author: coderman 
@_subject: [smb@cs.columbia.edu: serious threat models] 
some additional details on this interesting tap,,,
looks like it was indeed an inside job (and of the vodafone tech's
mysteriously committed suicide after the tapping was exposed? hmmm)
basically they hooked their spyware into the CALEA like features which
come standard in any commercial softswitch implementation and used it
to capture and relay conversations to the pool of a dozen or so pre
paid wireless phones.  [note that CALEA isn't that complicated; it's
simply a one way conference resource attached to a specific
span/channel that is relayed to eve.]
funny how vodafone is trying to avoid any responsibility by
highlighting the fact an ericsson insider wrote the code, while
conveniently failing to mention it was a vodafone tech who put it in
place. :)
The CEO of Vodafone Greece George Koronias told a Parliamentary
investigation on Thursday that Vodafone had at no time purchased the
software used to carry out the illegal phone taps through its digital
systems, while stressing that the people responsible had to have
extremely high technical expertise and a deep knowledge of Ericsson's
programming environment.
During his testimony, Koronias stressed that Vodafone had "not
requested, not ordered and not received" the legal low-phone
interception programme developed by Ericsson, which the phone-tappers
had managed to activate in order to monitor the roughly 100 mobile
phones that were under surveillance.
He said that the low-phone interception programme was added to
Ericsson systems at the request of its customers after the September
11 attacks, but underlined the costly service had not been purchased
by Vodafone.
Koronias also emphasised that the Greek mobile-phone provider had
never been officially aware of the inactive low-phone interception
software's presence in its systems, but only the supplier Ericsson.
At the same time he pointed out that Vodafone, as a provider, would
not be given access to the source code for the software. Ericsson did
not provide this to its customers and the software was operated only
Ericsson's authorised staff, he said.
Asked who might have made the 'rogue' software, Koronias said that it
would have to be someone with intimate knowledge of Ericsson's
programming environment that could write directy in assembly language,
which operators were not able to do.
"The complexity of the programme points to someone with extremely high
expertise," Koronias said, while clarifying that Vodafone's staff did
not possess this level of skill.
Regarding the death of Vodafone staff member Costas Tsalikidis,
Koronias said that he had brought this to the attention of the
ministers and the Supreme Court prosecutor, placing himself and the
company at their disposal, because it had coincided with the discovery
of the 'ghost' software and informing the government.
In a re-opened investigation into Tsalikidis' death that is now
underway, meanwhile, first-instance court prosecutor Ioannis Diotis on
Thursday heard testimony from the coroner Giorgios Dilernia who
examined the body at the time and the head of the coroners' service
Philippos Koutsaftis.
Dilernia said the 39-year-old's death had clearly been caused by
hanging, while both coroners agreed on a verdict of suicide and said
that disinterment of the body would not bring about any result.
Tsalikidis was found hanged in March 2005, just days after the company
discovered the 'ghost' software in its systems and informed the
government. A police investigation at the time had attributed the
death to suicide but this has been questioned by the family,
especially in the light of later developments and the revelations
about the phone-tapping scandal.

@_date: 2006-03-09 22:08:10
@_author: coderman 
@_subject: Telling the 'approved' story 
i'd be laughing a lot harder were this not so disturbing; though still
the funniest thing i've read this month:
 Telling the 'approved' story
March 7, 2006 01:12 AM / The Rant .
By DOUG THOMPSON
On an unspecified day last week an employee of a federal agency that
cannot be revealed delivered a document that cannot be identified to a
company that cannot be named seeking information that cannot be
The aforementioned federal agent left the unidentified document with
an employee of the unnamed company. That employee then called the
owner, who must remain anonymous, to inform him that the document that
could not be identified sought information that could not be
discussed. The owner who must remain anonymous instructed the employee
to deliver the unidentified document to a lawyer whose name is
protected by attorney-client privilege.
The lawyer whose name is protected by attorney-client privilege
examined the unidentified document and then reviewed the information
that could not be discussed with the owner who must remain anonymous.
With the approval of the owner who must remain anonymous, the lawyer
whose name is protected by attorney-client privilege contacted a U.S.
attorney who demanded that his identity be concealed.
The U.S. attorney who demanded that his identity be concealed then
claimed the owner who must remain anonymous violated a law that could
not be disclosed and faced arrest for charges that could not be
specified because he had referred to the document that cannot be
identified in an article for a certain, but unnamed, web site.
The lawyer whose name is protected by attorney-client privilege argued
that his client could not be charged under the undisclosed law because
he had been acting as a journalist at the time of the alleged
publication and not as the owner of the company that cannot be named.
He had, in fact, learned of the existence of the document that cannot
be identified from a third-party, who was not named, and was not aware
of its exact contents because he had not seen or read the document
and, therefore, was not aware of the exact contents that cannot be
The U.S. attorney who demanded his identity be concealed consulted
with others who names are classified and concluded that the owner who
must remain anonymous walked a fine line between legal and illegal and
would not face arrest for violating a law that could not be disclosed
on charges that could not be specified.
So walking this fine line of justice allowed the owner who must remain
anonymous to avoid confinement at an institution at an unknown
location for an unspecified length of time.
In exchange for his freedom, the owner who must remain anonymous
agreed to write a "clarification" of what happened, following the
guidelines for publication laid down by the Bush administration.
Which is what you just read.
the piece which cannot be mentioned because it named the letter which
must remain secret is here:

@_date: 2006-03-10 09:16:46
@_author: coderman 
@_subject: POLL: crypto hardware & Fwd: [Xen-devel] Announce of our 
i'm curious how you use them.  care to share?
my two main uses for the C5P systems are loop-aes w/padlock and key
scrubbing for file storage and IPsec endpoints.
i'll use the entropy on the C5XL boards for key generation as well.
wow, i didn't think these were going to be ready till Q3.  did they
have any specs?  i'll look around today and see if i can find more
yeah, i've been lusting after a dual proc board since they were
revealed back in Q2 '04.  perhaps the market just isn't there?  other
products announced later have made it into production before these SMP
the last 6-9 months seem to be a holding pattern of "working out the kinks".
i'm wondering if the Balance systems will be updated with a C7 when
available.  not a great laptop, but would work nicely as a crypto
accelerated endpoint:

@_date: 2006-03-10 22:46:58
@_author: coderman 
@_subject: POLL: crypto hardware & Fwd: [Xen-devel] Announce of our 
VIA's naming conventions are annoying; some names refer to the whole
proc, some to just part of the core, and some to the whole
CPU/north/south bridge collection.
IIRC Luke is a smaller fab process (the eden-n) with the
faster/improved north bridge support.  it's still the C5P core (two
entropy sources and AES accel.)
 has some PCI quad port NIC's with the same VIA
rhine chips; unfortunately 2 NIC's is the most i've seen ship on the
(routerboard also has a PCI to 4 x miniPCI adapter that is great for
wireless gear)
i've used the PCI riser/adapter to mount two PCI cards horizontally
off the mini-itx for adding a quad port ethernet (4xtulip) and a quad
mPCI filled with atheros CM9 radios.  best little router you can ask
for, IMHO.
this would be easy (easier at least) with a nano-itx form factor.  i
know they make boards with LVDS video built on, but they seem to be
hard to get ahold of, mainly for OEM applications rather than direct
retail.  it will be interesting to see how this plays out...

@_date: 2006-03-10 23:05:37
@_author: coderman 
@_subject: POLL: crypto hardware & Fwd: [Xen-devel] Announce of our 
yeah, for this you'd need the on board cardbus for wireless card, then
use the two PCI slots for the RAID card and quad-NIC.  as a plus, the
boards with the cardbus slot usually have a compact flash port
underneath if you want a diskless system.
the C3 was a larger fab process and had no padlock engine (neither
entropy or AES).  it's difficult to differentiate between a mainboard
using a C3 and a mainboard using the C5.  this drives me nuts! you
have to look for the keyword "Nehemiah" or verify part/model   and
then Nehemiah may refer to either the C5XL or C5P core (C5XL == single
entropy source, C5P == two entropy sources and AES)

@_date: 2006-03-11 00:33:28
@_author: coderman 
@_subject: speaking of weak primes, weak exponents? 
Qi Cheng is not aware of any further work on "A New Class of Unsafe
Primes" -  , which was mentioned here
recently (thanks Peter).
not a big deal or something to be concerned about?  (the speed
improvement shown makes me think this should be a check performed for
all prime selection in any pubkey system, even if it is unlikely)
also curious if anyone has insight on the following as potential
pitfalls to avoid when implementing / generating RSA:
"RSA and a higher degree diophantine equation ... Let $N=pq$ be an RSA
modulus where $p$, $q$ are large primes of the same bitsize. We study
the class of the public exponents $e$ for which there exist an integer
$m$ with $1\leq m\leq {\log{N}\over \log{32}}$ and small integers $u$,
$X$, $Y$ and $Z$ satisfying $$(e+u)Y^m-\psi(N)X^m=Z,$$ where
$\psi(N)=(p+1)(q-1)$. First we show that these exponents are of
improper use in RSA cryptosystems."
"Cryptanalysis of RSA with constrained keys ... We show that choosing
a public key exponent $e$ for which there exist positive integers $X$,
$Y$ such that $\left\vert eY-XF(u)\right\vert$ and $Y$ are suitably
small, then the system is insecure."
one last related item, large qubit quantum computers:
 at metzdowd.com/msg05835.html
bulk quantum computation
Travis H.
Here's a 1997 paper on "quantum computing in the large" that I had
been asking about:
"Neil Gershenfeld and Isaac Chuang have developed an entirely new
approach to quantum computation that promises to solve many of these
problems. Instead of carefully isolating a small number of qubits, we
use a large thermal ensemble (such as a cup of coffee). Such a system
has ~10^23 degrees of freedom; by applying RF pulses that excite
nuclear magnetic resonances, we can create a tiny deviation from
equilibrium that acts just like a much smaller number of pure qubits."

@_date: 2006-03-11 02:13:04
@_author: coderman 
@_subject: journalistic insecurity and facilitating whistleblower privacy 
more fallout from the top sekrit "national security letters"
(30,000 issued per year, wonder how high this has increased with the
new focus on journalistic sources?)
On Tuesday, an email arrived from Dan Eggen, Justice Department
correspondent for The Washington Post. Dan wanted a copy of the letter
and more information on the story.
That's right I write a story about how the Bush administration is
monitoring the email of journalists and a journalist fires off an
email asking me to violate the USA Patriot Act and risk certain jail
time by providing him with a copy of a letter that I'm not even
supposed to admit I have.
Then I checked my voice mail to find a call from Robert O'Harrow Jr.,
another Post reporter, wanting information on my sources.  Hmmm. I
write a story about how the Bush administration is monitoring phone
calls of reporters and a reporter calls me on the phone to obtain
information on my confidential sources.  Anyone see a pattern here?
Next, I get both a phone call and an email from David Armstrong of the
National Security News Service saying he is working with 60 Minutes on
a story about domestic spying by the National Security Agency. He
wants info on my sources.
When Mark Felt, the number two man in the FBI, served as Post reporter
Bob Woodward's primary source on Watergate, he insisted that Woodward
avoid contact by telephone and devised a scheme of planted messages in
a newspaper left at Woodward's door and meetings in an underground
garage in Arlington....
My sources know better than to use phone lines and email to contact
me. We've worked out elaborate, and always changing, methods for
sharing information.
are the vast majority of journalists really this brain dead?  here is
what i'd like to know  from a reporter to whom i was about to divulge
sensitive information:
- do i _really_ trust you?  even if they turn the screws?
- do you know what physical security is (and implement it)?
  [ oops, is anyone left standing? ]
- do you use network security best practices when communicating
privately online?
  [ os up to date with security patches, unnecessary services
disabled, firewall, etc ]
- can i communicate via a secure channel?
  [ examples: whispered conversations in a noisy parking garage ;)
    off the record with mutually verified keys     other SSL mechanism with mutual authentication like     pgp/gpg encrypted email (though this seems not so popular?) ]
- do you protect your stored data appropriately?
  [ loop-aes encrypted volumes, FileVault, gpg encrypted files, etc ]
- do you use good passwords/phrases for authentication?
what other questions would you ask?
We don't burn our sources
March 9, 2006 05:25 AM / The Rant .
By DOUG THOMPSON
One of the questions frequently raised by critics of this web site is
"how can you guys have sources the mainstream media doesn't have?"
Good question. We often quote confidential sources in our stories. We
have a choice of depending on such sources or not publishing the
story. If I'm satisfied the sources are accurate I go with the story.
It's a question of trust and, during my 23 years in Washington as both
a journalist and a political operative, I built up a network of
sources I trust and who trust me to protect their identity and not put
them in harm's way. More than 40 years in journalism taught me to
protect such sources at all cost.
Many of those same sources don't trust the so-called "mainstream
media" outlets because they've been burned by journalists who put the
story ahead of protecting those who provide them with the information.
Even worse, the mainstreamers can be downright sloppy when it comes to
protecting those who have such information.
On Monday, I outlined how the Bush Administration has launched an
all-out war on the press, directing attorney general Alberto Gonzales
to go after reporters with subpoenas, wiretaps, monitoring of emails
and surveillance to try and stop leaks about the many questionable
activities of the White House.
I learned about the efforts because the FBI made the incredibly stupid
mistake of sending one of their "National Security Letters" to a
company I own demanding information on one of its clients - me.
Then I confirmed the story with my administration sources and ran with
it on Monday, knowing that even acknowledging receipt of a National
Security Letter could lead to trouble.  The letter was withdrawn after
my attorney negotiated a deal.
On Tuesday, an email arrived from Dan Eggen, Justice Department
correspondent for The Washington Post. Dan wanted a copy of the letter
and more information on the story.
That's right I write a story about how the Bush administration is
monitoring the email of journalists and a journalist fires off an
email asking me to violate the USA Patriot Act and risk certain jail
time by providing him with a copy of a letter that I'm not even
supposed to admit I have. In fact, I don't have it. I never did. The
FBI sent the letter to my web hosting company offices which are 300
miles away from my home and studio. At my instructions it went from
the employee who received it straight to my attorney and he dealt
directly with the feds. I never saw the letter, do not know what
happened to it and am not privy to details of what it said. I don't
want to know. That's why I'm still sitting here and not on my way to
Then I checked my voice mail to find a call from Robert O'Harrow Jr.,
another Post reporter, wanting information on my sources.  Hmmm. I
write a story about how the Bush administration is monitoring phone
calls of reporters and a reporter calls me on the phone to obtain
information on my confidential sources.  Anyone see a pattern here?
Next, I get both a phone call and an email from David Armstrong of the
National Security News Service saying he is working with 60 Minutes on
a story about domestic spying by the National Security Agency. He
wants info on my sources.
Let's see. A reporter uses both the telephone and email to request the
names of confidential sources on a story about how the National
Security Agency monitors telephone and email use of, you guessed it,
Sorry guys. I'm not about to burn my sources when you take so little
precaution in seeking information from me.  Besides, I wouldn't help
60 Minutes if they were the only news outlet left on the face of the
In 1981 I served on a panel discussion with Fred Graham, then legal
correspondent for CBS News.  During a break I told him about a paper I
once worked for, The Alton Telegraph in Illinois, which had lost a
landmark libel suit for something they never published. I thought it
might make a good story about injustice.
Instead, Graham turned the story over to Morley Safer and 60 Minutes
and they put together a hatchet job on the newspaper and told the
story from a trial lawyer's point of view. Instead of defending
freedom of the press, Safer and his crew sensationalized the story for
Some years later, we would learn again just how 60 Minutes and CBS
News hangs people out to dry. Jeffrey Wigand, a fired corporate vice
president for Brown & Williamson Tobacco Co., blew the whistle on the
company's campaign to hide the true dangers of nicotine. But 60
Minutes and Mike Wallace caved to corporate pressure and shelved the
story after revealing Wigand's identity. His reputation was ruined by
the network's incompetence.
Given such track records, why should any source trust the
mainstreamers?  The Washington Post sends an unsecure email openly
asking me to violate federal law by turning over a classified document
and I'm supposed to believe they will protect sources that I've
cultivated and protected for more than two decades?
When Mark Felt, the number two man in the FBI, served as Post reporter
Bob Woodward's primary source on Watergate, he insisted that Woodward
avoid contact by telephone and devised a scheme of planted messages in
a newspaper left at Woodward's door and meetings in an underground
garage in Arlington.  Felt knew using the telephone or other standard
communications means of the time would lead the secrecy-obsessed Nixon
White House to his door.  Felt's identity remained a secret for 31
My sources know better than to use phone lines and email to contact
me. We've worked out elaborate, and always changing, methods for
sharing information. I'm not about to risk their confidentiality with
reporters who are less careful.
I've been hauled in front of grand juries by overzealous prosecutors
who wanted names of sources. They didn't get them. As a journalist, I
was trained to develop my own network of sources, not call other
reporters and ask them to give up theirs.
Maybe I'm too old-fashioned for today's pop-culture journalism. Maybe
it's out of style for reporters to do their own legwork and research
instead of depending on Google and others to do it for them.
Or maybe I'm just too old to change and too damn suspicious to get
trapped by youngsters. My mama drowned the dumb ones.
more on the national security letters here:
and here:

@_date: 2006-03-11 03:06:25
@_author: coderman 
@_subject: NO-QUESTIONS WIRETAPPING - "liberty theater" 
let's call this particular form of freedom lip service: "liberty theater"
it's been quite a show and only promises to get even more entertaining... :)
NO-QUESTIONS WIRETAPPING
Friday, March 10, 2006
David Sarasohn
R emember that fundamental principle -- the one that got everybody so
upset when they first heard about the National Security Agency's
freelance wiretapping -- that says that if the U.S. government wants
to listen to your phone calls, it needs to get a court's permission?
George W. Bush used to talk about it when he was running for re-election.
Some people call it the Fourth Amendment. Remember it?
The U.S. Senate Select Committee on Intelligence has a message for you
about that principle: Forget it.
After months of huffing and puffing and declaring its determination to
stand up for the Constitution against the White House, the committee

@_date: 2006-03-13 15:16:08
@_author: coderman 
@_subject: On being a cypherpunk 
i suppose an abridged description would be:
i write code to facilitate personal privacy because i feel privacy is
important and worthwhile for many reasons.
i write code for those who want to take responsibility for their own
privacy because governments and businesses will not give them the
tools to do so.
i write code to assist private communication because the ability to
communicate freely is a fundamental and necessary aspect of any social
i write code because it gives me a great deal of satisfaction to build
something useful to myself and others.

@_date: 2006-03-13 15:18:33
@_author: coderman 
@_subject: Fwd: Tor wants to fund a few Ontario students 
Ontario cypherpunks students do what?
---------- Forwarded message ----------
Hi folks,
Thanks to Mike Gurski at Bell, the Tor project has some money to pay
one or two students to help develop Tor. The strings are that they need
to be students (of some sort) at a university in Ontario.
If you know any outstanding students who can code well and have an
interest in privacy/security, please pass this on to them. We want people
who can work independently and write good code.
We're ready to start whenever we find the right people. I'd like to find
some Windows developers to help fill the gaps in our current skills,
but if you know a brilliant developer I'm flexible.
I've written up more details here:

@_date: 2006-03-13 16:43:26
@_author: coderman 
@_subject: Via unveils high performance mini-ITX line - C7 cores in 
4096 bit montgomery multiplier in core as MONTMUL instruction.
SHA1 & SHA2-256 in core as XSHA instruction.
in addition to the usual dual entropy sources and AES in core...
see also Via unveils high performance mini-ITX line
Mar. 13, 2006
Via has announced a next-generation family of mini-ITX boards based on
its new C7 processor family. "Epia EN" boards will offer a large
performance boost over previous Epia boards, Via says. They target
thin clients, car PCs, robotics, medical equipment, kiosks, and server
(Click for larger view of Via Epia EN)
Initial Epia EN boards will feature C7 processors clocked at 1.5GHz,
or else an "Eden" version of the C7 clocked at 1.2GHz, for passively
cooled applications. Advanced features include support for 533/400MHz
DDR2 RAM, gigabit Ethernet, and an onboard SATA II RAID 0, 1, and O+1
A prototype Epia EN board based on a C7 processor
(Click to enlarge)
The EN-series will eventually offer models clocked to 2GHz, with
frontside-bus speeds up to 800MHz, Via says.
First C7-equipped mini-ITX boards from Via
The Epia EN boards will be the first mini-ITX boards to feature Via's
next-generation x86-compatible processors, the C7 desktop, C7-M
mobile, and C7-Eden embedded processors. All three are based on the
same "C5J Esther" core, with different testing requirements and
Touted features of the C5J Esther core include support for SSE2 and
SSE3 instructions, said to improve 3D performance; a full-speed FPU
(floating point unit), rather than the half-speed unit of earlier Via
chips; 16 pipeline stages; and 128KB each of L1 and L2 cache. The core
also integrates Via's cryptography hardware. It has a die size of 30
square millimeters, and is manufactured by IBM using 90-namometer SOI
(silicon-on-insulator) technology.
C7 die layout
(Click to enlarge)
The C7-series chips have a TDP (thermal design power, aka maximum
power draw) of 12 Watts when clocked at 1.5GHz, Via says -- or about
half that of a Celeron-M. Additionally, the chips dissipate 20 Watts
when clocked at 2GHz, Via says, and offer better performance-per-Watt
than Intel's venerable Pentium M, it claims.
C7 vs. Pentium M in performance-per-Watt
(Source: Via)
Via announced the C7 in May of last year -- see that announcement for
lots more details about the chip.
CN700 Northbridge
Along with new C7 and C7-M processors, the Epia EN-series boards will
use Via's relatively new CN700 chipset, which just began sampling in
December. The chipset includes a new "CN700" northbridge, along with a
VT8237-series southbridge connected through a V-link host controller.
The C7 processor, CN700 northbridge, and VT8237-R southbridge function diagram
(Click to enlarge)
Claimed performance leap
Benchmarking against older mini-ITX boards based on C3 processors
shows the C7-based Epia EN-series boards to offer 55 percent better
results on MPEG encoding, 40 better results on business productivity
performance, and about 10 percent better results on 3D graphics
performance tests, Via reports.
C3 v. C7 benchmark results
(Source: Via)
In addition to better performance, and performance-per-Watt, Via says
the EN-series boards are more reliable, thanks to low heat
dissipation. They are not as dependent as most boards on mechanical
cooling systems, and don't generate enough heat to damage board
components, Via says.
Other claimed features include:
    * ATX power
    * DDRII 400/533 memory socket
    * UDMA 66/100/133 connectors
    * CN700 Northbridge
    * VT8237R+ Southbridge
    * PCI connector
    * LVDS/DVI modules available
    * 6-channel audio
    * Switchable (jumpers) S/PDIF / S-Video port
    * PS-2 connectors
    * USB 2.0
    * Gigabit Ethernet
Via has not announced specific EN-series board availability, but says
that boards will be available at a variety of price points soon.

@_date: 2006-03-15 10:46:23
@_author: coderman 
@_subject: /. [PGP Creator's Zfone Encrypts VoIP] 
there is also TRIP: an inter-domain routing protocol for VoIP (like BGP for voice).  for
various political reasons this has never seemed to go anywhere.  i
posted a patch for gcc 3.x a while back if anyone wants to build the
vovida trip daemon on a modern system.

@_date: 2006-03-16 21:34:04
@_author: coderman 
@_subject: for the bored: test an iso (esp those with via padlock hw) 
if you'd like to help me test some crypto pieces the following ISO
includes a test mode which gathers stats and hardware info.  feel free
to trim whatever from this report and send me the remainder. additional modes support a network-less key management mode and a
network enabled instance and cd/dvd writing clone mode.
i'm curious about the following mainly:
- does it boot?
- is network hardware (no wireless) detected in 'net' target?
- does entropy mgmt on VIA hardware work? (c5test/c5keys/c5net)
- does the clonecd/clonedvd work with your hardware? (clone)
- are the key mgmt tools provided sufficient/working? (gpg, openssl, ssh)
feedback appreciated.  please note the test mode may take a loooong
time (30 mins not uncommon).  also note you may be left with a single
seeder on a slow DSL line, which might take a while as well.
src for mtrngd and modified hw_random in src/ on the iso.  these bits
need some work...
gpg --print-md sha256 test.iso
test.iso: C7096E4F 76F6AE52 F3E61058 0C269EC3 9C2A1478 B11DDDC5 0664F9F 864DDB44
you can run this without any disks for the security conscious.  the
full project is intended for release at defcon this year.  hope to see
you there.  (not as a presentation, we just like to geek out.  and
i'll try to be sober this year but no promises!)

@_date: 2006-03-17 00:43:25
@_author: coderman 
@_subject: [programs@necsi.org: Special program on _Homeland and 
heh, i'd love to see sante fe & necsi soundly trashing tsa no fly
lists and ssss labeling, nsa's tia reborn, and every other program the
vast majority of "security" bureaucracy/funding is porked in.
rapid repair is key, and att's ndr program a model with some success. perhaps cognitive wireless radios (software defined? fuck the fcc!)
will provide a good last mile in the near future...
as for other industries / organizations - some systems are just broken
against a skilled asymmetric attacker.  time to move on...

@_date: 2006-03-17 02:11:38
@_author: coderman 
@_subject: for the bored: test an iso (esp those with via padlock hw) 
identity management and decentralized and/or wireless networks.  we'll
see how much gets finished by summer...
thanks; there shouldn't be much traffic and anything is helpful.

@_date: 2006-03-20 15:16:44
@_author: coderman 
@_subject: The topology of covert conflict 
an interesting paper...
"Abstract. Often an attacker tries to disconnect a network by
destroying nodes or edges, while the defender counters using various
resilience mechanisms. Examples include a music industry body
attempting to close down a peer-to-peer file-sharing network; medics
attempting to halt the spread of an infectious disease by selective
vaccination; and a police agency trying to decapitate a terrorist
organisation. Albert, Jeong and Barabasi famously analysed the static
case, and showed that vertex-order attacks are effective against
scale-free networks. We extend this work to the dynamic case by
developing a framework based on evolutionary game theory to explore
the interaction of attack and defence strategies. We show, first, that
naive defences don't work against vertex-order attack; second, that
defences based on simple redundancy don't work much better, but that
defences based on cliques work well; third, that attacks based on
centrality work better against clique defences than vertex-order
attacks do; and fourth, that defences based on complex strategies such
as delegation plus clique resist centrality attacks better than simple
clique defences. Our models thus build a bridge between network
analysis and evolutionary game theory, and provide a framework for
analysing defence and attack in networks where topology matters. They
suggest definitions of efficiency of attack and defence, and may even
explain the evolution of insurgent organisations from networks of
cells to a more virtual leadership that facilitates operations rather
than directing them. Finally, we draw some conclusions and present
possible directions for future research..."

@_date: 2006-03-20 17:18:54
@_author: coderman 
@_subject: [Clips] Port knocking: A security idea whose time has come 
my comments below,
limit even attempted utilization of services to authenticated users -
that's a good idea.  port knocking is a poor implementation though.
you can do strong single packet authentication without the additive
latency of port knocking, and it is a cleaner design. (see
 for
i've talked about IPsec stacks keyed out of band which give you a
robust "authenticated peers only" configuration without esoteric port
knocking / SPA methods.  unfortunately right now the options available
are static pre shared key (setkey) which is insecure without some
scripting/munging around single use keys. (this should change soon,
for some lax definition of 'soon')
it'd be nice to expand the keying options for those who wish to avoid
exposing any services above the IP stack without proper
authentication. (that means no IKE ports either).  i'm a huge fan of
OpenVPN and IPsec private networking, though IPsec is better suited
for this "no services for the unauthenticated" mode of operation.
this is the only thing port knocking it has going for it; SPA or VPN's
are a much stronger solution.
this is a particularly significant concern over wireless networks, and
when you add sophisticated authentication you might as well jump ship
to SPA or VPN instead (since you're going to be spending additional
effort managing credentials anyway - do it right and be done with it!)

@_date: 2006-03-21 11:39:35
@_author: coderman 
@_subject: skype was made by clever people 
it's interesting to note that this clearly allows for a MITM as
required by legal authorities (Skype mentioned fully cooperating with
authorities as required - how often do they do this?).
the client authentication uses public keys signed by the Skype
Authority; presumably any key they sign as being "User Alice", even if
belonging to "User Eve", will be accepted by the client.  with no
visibility in client certs at the UI level i don't see how this can be
note that this is really just useful for inter-skype calls as
CALEA/traditional taps can take place once a skype call hits POTS.
one of the slides mentions: "You are the certification authority - You
can intercept and decrypt session keys".  if this means that client
private keys are also handed to the skype authority then eavesdropping
is trivial (and no longer requires active MITM).  however, this tidbit
is listed under "Skype Voice Interception - Feasibility of a man in
the middle attack" so i'm not sure if they are talking about a passive
eavesdrop or an active MITM with regards to the cert authority
other interesting bits:
they use a 2^32 strength key for RC4 obfuscation of data payloads. all this encryption is purely done to obfuscate protocol.  (the binary
obfuscation is impressive as well; i fucking hate that shit though :)
blocking skype with one rule:
iptables -I FORWARD -p udp -m length --length 39 -m u32 --u32
'27&0x8f=7' --u32 '31=0x527c4833' -j DROP
approximately 20,000 super nodes exist.
heap exploits for biggest botnet ever? :P~

@_date: 2006-03-21 13:51:02
@_author: coderman 
@_subject: Beware the clean-cut WASP cleaning crew member working in 
[from my neck of the woods, so probably more interesting to me than
most.  it'd also be interesting to hear other stories of suspected
clandestine surveillance.  this guy is friends with Brandon Mayfield,
another PDX attorney who had represented middle eastern clients, who
was jailed on bogus finger print matches to the spain bombings - even
when spanish authorities insisted he had nothing to do with it:
 ]
also interesting that ADT appears to comply fully with such black bag
jobs; another reason to roll your own :)
Lawyer thinks office was searched in secret
Surveillance - A Portland attorney, who represents a Saudi, cites
suspicious circumstances
Tuesday, March 21, 2006
BRYAN DENSON
A Portland lawyer suspects that federal authorities executed
warrantless searches of his Lloyd Center office to collect information
about a client who is the subject of an international terrorism
Tom Nelson, who represents Saudi national Soliman al-Buthi, previously
filed a complaint that alleged warrantless interception of phone and
e-mail communications between al-Buthi and his other lawyers.
"We allege in our complaint not only that they intercepted
communications without a warrant, but they used the interceptions to
the disadvantage of the client," Nelson said.
Nelson thinks government agents, with no judicial supervision, entered
his office on a number of occasions last year. He first raised the
suspicion in September in a letter to Karin Immergut, the U.S.
attorney for Oregon, who wrote back saying she was aware of no such
warrantless searches. Nelson recounted his fears about warrantless
searches by the National Security Agency in a story this week in U.S.
News & World Report.
Two years ago, the federal government charged al-Buthi, who headed an
Ashland nonprofit called al-Haramain Islamic Foundation, with taking
charitable donations totaling $130,000 in traveler's checks out of the
United States. Federal authorities have accused the al-Haramain parent
organization, based in Saudi Arabia, of ties to Osama bin Laden.
Nelson thinks that while he was representing al-Buthi on the criminal
charge and attempting to rid his client of a suspected "global
terrorist" designation that someone posing as a janitor repeatedly
tried to, and apparently did, enter his Lloyd Center office after
Attorney Jonathan Norling, who shares office space with Nelson, said
he was sleeping on a couch at their practice early one morning last
May when a man dressed as a custodian tried to enter Nelson's office.
Norling startled the man twice one night in July when he caught the
man trying to enter the locked office.
Norling also suspects federal authorities were trying to collect
information from Nelson's desk and computer. Whoever it was, he said,
had a badge for the building that appeared valid.
"This person clearly wasn't a cleaning crew," Norling said. "I know
the cleaning crew. They come in at different times. They have a cart,
and this guy didn't have a cart. . . . I've worked here seven years,
and I've worked a lot of late nights, and I never experienced anything
like that until Tom was working (on this case)."
Nelson was suspicious of the government, having briefly represented
Brandon Mayfield, the lawyer wrongly accused of the 2004 terrorist
attack in Spain. Mayfield was the subject of intense federal
Nelson's suspicions deepened when he found that his computer had
inexplicably been rebooted and that papers in his cluttered office had
been moved around. "I'm not the world's best housekeeper," he said,
"but I know where things are."
After a few suspicious experiences, Nelson took his al-Buthi files to
his home in Zigzag. There he experienced what he described as
unexplained lapses in his burglar alarm, failures that the company
that monitors the alarm couldn't adequately explain.
On Sept. 23, he fired off the first of two letters to Immergut, the
U.S. attorney for Oregon, complaining of "strong indications that my
office and my home have been the target of clandestine searches"
related to the al-Buthi case. Immergut responded Jan. 19 that she
stood by her earlier statements: She was aware of no such searches
under her watch. Immergut wrote that she assumed he was referring to
news reports about clandestine intercepts by the NSA.
Immergut pointed out in her response that the NSA and Department of
Justice were separate agencies. In an interview Monday, she added,
"The (NSA) is not required to come to the U.S. attorney for the
district of Oregon for authorization to conduct any kind of searches."
All of which keeps Nelson scratching his head.
"I have no proof the government's doing these things," he said. "I
just have a very healthy suspicion they are."

@_date: 2006-03-23 22:45:19
@_author: coderman 
@_subject: entropy status / benchmarks [was test an iso] 
for those with VIA/Intel/AMD hw entropy device support and a running
mtrngd you can get current status via '/etc/rc.d/rcS.mtrngd status'. logs are in /var/log/mtrngd/.
i'd be interesting in knowing run times for large amounts of entropy
gathered and mixed to /dev/random (gigabytes if it remains stable for
that long).  particularly for the Intel and AMD hw devices which i do
not currently have at my disposal for testing.
status output is similar to the following; sizes are in Bytes,
times/stats are in microseconds (not milli):
[Fri Mar 24 08:46:14-459926] Current MTRNGD Status:
  bad fips blocks ......: 13080
   monobit failures ___: 3359
   poker run failures _: 542707
   bit run failures  __: 1104377
   long run failures __: 9687
   cont run failures __: 35
  good fips blocks .....: 41614750
  hwrng read bytes .....: 104069575000
 entropy add bytes ....: 104036872320
  random writeable cnt .: 541858710
  hw entropy read stats ....:    min: 2479       avg:  3359      max:
22788      total: 139833561751
  rng fips check stats .....:    min: 904        avg:  919       max:
6464       total: 38267989605
  random recv starve stats .:    min: 3416       avg:  4305      max:
24018      total: 179159453561
you can stress /dev/random via 'bench-rng /dev/random 1024 1000000' or
simply 'cat /dev/random > /dev/null'.
uptime would be helpful.  note that i accidentally left "forgiving
fips check" set in the rcS.mtrngd script; this can be turned off for a
better real world test.  the forgiving option does not fail blocks
with poker or bit runs.  monobit, long, and continuous runs are always
critical and the block is discarded.
the FIPS check block size is 1500 bytes.  see
 for more info.
by default entropy density is at 80% so take that into consideration
when calculating available /dev/random throughput.  ex:
entropy add bytes ....: 104036872320  x  0.80 == 83,229,497,856 Bytes
of actual entropy added to /dev/random pool.

@_date: 2006-03-24 07:06:34
@_author: coderman 
@_subject: for the bored: test an iso (esp those with via padlock hw) 
apologies; the correct fingerprint (minus cut and paste error) should read:
test.iso: C7096E4F 76F6AE52 F3E61058 0C269EC3 9C2A1478 B11DDDC5 10664F9F
          864DDB44
or, without spaces:
 gpg --print-md sha256 test.iso 2>/dev/null | sed 's/[^0-9A-F]//g'
test.iso: 44947456 bytes (43M) 2006-03-16
also, for weakly private communication i can be reached using Off The
Record  (  ) on AOHell Instant Masochist
(AIM) with credentials:
username: coderman42
fingerprint: A59CDCB3 46468A16 27D21678 270AF0B5 0B0477CF
i consider email public / non-private unless we are exchanging it over
a private [virtual] network.  (but you should have known that already
given my use of a  address...)

@_date: 2006-03-26 08:37:33
@_author: coderman 
@_subject: RFA: hardware, wireless, defcon (request for assistance with 
:: public request for help with janus wireless / open source project
at defcon 14 ::
if you will be at defcon 14 this august and have one or more of the
following and would be willing to help with an open source project
launch / test during the con please get in touch with me using
Off-The-Record or coordinate a meat space rendezvous via email -
coderman at gmail.
coderman42 on AIM :: OTR print A59CDCB3 46468A16 27D21678 270AF0B5 0B0477CF
my appreciation to anyone and everyone for their help; we will need it
(we are a very small group based in portland with limited resources
and time).
i will try to express my appreciation and reward your generosity in
some fashion.  please forward this to anyone with crypto clue who
might be interested and likely to participate.
desired and/or required:
-  VIA Nehemiah hardware and >128M of memory.  C5XL, C5P or C5J / C7  required.
-  slimline IDE or USB CDROM/DVDROM drives.
-  any x586/Pentium system with > 128M of ram and 8G or more free on
unformatted disk partition.
-  portable USB storage devices that can be formatted to XFS/iso image.
-  any system capable of burning single or dual layer DVD-R discs.
-  any wireless equipment that can support WPA/WPA2 EAP TLS w RADIUS
(enterprise mode)
-  any prism2, hermes, atheros, cisco, intel or other linux supported
wireless hardware in pcmcia/cardbus or mini-PCI/PCI formfactor. 200mW+ especially useful.
-  802.11 or other HAM/FHSS/DSSS/OFDM amplifiers in the 900Mhz,
2.4Ghz, and 5.8Ghz bands (or other reasonable bands - HAM with
auth/no-privacy packet radio signalling?)
-  antennas / cables / filters / mounting systems / for any of the above bands.
-  audio/video recording and/or mastering equipment and knowledge.
-  home/work/edu internet bandwidth that can support and would be
available for the conference (or a subset) running a tor proxy and/or
bittorrent seeder.  traffic shaping and read-only boot/runtime is
supported if you use the live ISO cd for hosting a tor[rent] node. please consider the potential security risks of running a tor node
reachable from a private defcon wireless network before agreeing to
this.  middle/relay only nodes would still be helpful.
- well CPU and memory endowed systems that you would make available to
a private IPsec/OpenVPN network for distributed build and test
all hardware you want to keep is encouraged to stay in your possession
and a few hours or more would be helpful when contributing time/skills
at the conference.  you will need to meet me in person before or the
day of the conference.  the earlier the better.
thanks again,
  i look forwarded to meeting any of you in person and discussing this
project and code.
martin - janus wireless
coderman at gmail.com|peertech.org|charter.net|mindspring.com
 'bastardized Leonard Cohen; the only quote you'll ever see
me tarnish so,'
"It is not to tell you anything
But to live forever
That I write this.
This is the only code
I can write.
I am the only one
who has built it.
I didn't kill myself
When things went wrong
I didn't shirk difficult integrity,
  when the easy seduced me.
I learned to write
I learned to code
What might be named
On nights like this
By one like me.

@_date: 2006-03-26 09:46:17
@_author: coderman 
@_subject: guidelines for good password policy and maintenance / user 
time)
Creating a secure password:
    o Include punctuation marks and numbers.
    o Mix capital, lowercase and space characters.
    o Create a unique acronym.
    o Short passwords should be 8 chars at least.
Weaknesses to avoid:
    o Don't use a password that is listed as an example or public.
    o Don't use a password you have been using for years.
    o Don't use a password someone else has seen you type.
    o Don't use a password that contains personal information.
    o Don't use words or acronyms that can be found in a dictionary.
    o Don't use keyboard patterns (qwerty) or sequential numbers.
    o Don't use repeating characters (aa11).
Keep your password secure:
    o Never tell your password to anyone or use it where they can observe it.
    o Never send your password by email or speak it where others may hear.
    o Occasionally verify your current password and change it to a new one.
    o Avoid writing your password down.  (Keep it with you in a purse
or wallet if you have to write down the password until you remember
High assurance passwords / exotic threat model interactive auth: use
challenge response for single use Key Encryption Keys containing a
minimum of 128 bits of entropy in a full SHA-512 derived key.  exotic
threat model implies full process for physical, emission,
cryptographic and user interface security.  (i.e. expert level
security infrastructure and flawless identity management).
ideally this would be coupled with a personal vascular scan biometric
device (user centric with vascular auth challenge to open/sign
hardened internal secrets)
the odds of such a device being designed, produced and verified in an
open and full disclosure manner is not high. :P

@_date: 2006-03-26 10:50:17
@_author: coderman 
@_subject: [Full-disclosure] guidelines for good password policy and 
number at most over time)
excessive typing == unnecessary leaked information and longer auth
process (acoustic, profiling, easier pattern discovery, etc.)
i don't have a problem supporting a passphrase mode (>16 chars?  >32?)
but i'd rather not make it the default.
(and the default is and must be the most secure and usable path for
this to be trustworthy and widely usable)

@_date: 2006-03-27 09:10:16
@_author: coderman 
@_subject: [p2p-hackers] guidelines for good password policy and 
number at most over time)
very true.
it is my personal hunch that if users had just one password they
needed to remember they could remember a good one.  the janus stuff we
are working on uses loop-aes volumes specifically so you can store
passwords in a browser, store capability URL's, keep accounts and
logins in a text file, etc.
[i'd love to know of any studies to this end though.  i have tried
experiments to see just how much entropy i can commit to memory and it
is more than enough for a good interactive authentication.  i think
this is within the ability of most, if they had a desire to do so and
understood the benefit.]
so the goal is to provide a usable system with a single password, and
make it user centric, so that all the other credentials and secrets
associated with other digital identies can benefit from this bootstrap
(and presumably share this more secure bootstrap).

@_date: 2006-03-27 14:04:55
@_author: coderman 
@_subject: [p2p-hackers] guidelines for good password policy and 
number at most over time)
true; which is why i'd like to see them use a single good password to
mount an encrypted volume and secure OS where the rest of the
(different*) passwords and PIN's and whatever else are kept.
this is a handy utility!
i'd still be concerned about dictionary attacks on poor passwords
(that is, discovering '.848fe29s44j' is the hash for pwned.com and
'secret'.)  secure digests make this more expensive but not by much.
* are you aware of any utility for the browser that generates random
passwords?  i'd like something like this as well, with the idea that
the first time you visit the site (or need to change a password) a
random password is generated, placed in the input text field, and then
the browser password manager remembers it after that point.  (and the
password db is stored on an encrypted file system to prevent theft).
someone will ask about users who aren't on their machine and need to
access a site.  i don't like to support this ability because you
should never be using an untrusted computer to access a secure site. if the computer is trusted you should also be able to boot from CD and
insert your USB storage key (which lets you use your browser password
(actually, looking at the source for PwdHash it appears easy enough to
modify for random password generation)
thanks for the tip,

@_date: 2006-03-28 01:06:43
@_author: coderman 
@_subject: [p2p-hackers] guidelines for good password policy and 
smallnumber at most over time)
fine as long as trust and identity are properly implemented. physically hardened tokens are very good (ex: the rsa challenge / pin
based token authenticator via radius)
SPEKE and variants are also highly recommended in my book if you can
use them in a secure context (that is, no rootkits and equivalents to
capture passwords/phrases - a situation where single use passwords /
bingo auth are helpful if secure hardware tokens are not feasible)
this works very well, and if you have hardware accelerated encryption
it can be transparent.  you can also pre distribute keys (public and
secret) to the encrypted volumes you mount and run within (via a
secure bootstrap of course...)
[ see  ]
i think this is a rich field of discovery when considering the user
interface and authentication / session aspects of a secure system.
best regards,

@_date: 2006-03-28 01:49:17
@_author: coderman 
@_subject: [p2p-hackers] lockstep synchronization protocol problem 
look at using a quorum based key distribution and agreement protocol
(where quorum == a specific subset of group key management) with
regular attestation / rekeying via trusted and strongly authenticated
mechanisms.  session timeout (for failure / lack of consensus /
malicious attack) should be detected within an appropriate time frame
for the user to respond securely.  (i tend to think 60 seconds is an
acceptable window)
doing this in a user friendly manner is very difficult and probably
the reason prior work in this domain is scarce.

@_date: 2006-03-28 02:15:00
@_author: coderman 
@_subject: janus wireless faq / "secure"* public communication 
- why don't you have a public website with forums and other services?
    :: public networks allow unauthenticated communication and may
expose vulnerabilities.  we are building a secure* private group
networking system.  a strong least privilege system only communicates
over public networks in an ephemeral and read only manner via self
certifying identifiers.  (that is, we like to eat our own dogfood)
- then what is that site i saw that talked about a janus wireless member?
    :: individuals within the group may host their own public
services.  we expect them to confirm that any operating system
instance connected to public networks in this manner should be
considered less than secure even if they are well protected.
- how can i help you?
    :: get in touch with one of our members.  you might try email,
off-the-record, out-of-band, or other methods.
- do i have to buy VIA padlock hardware to use your software?
    :: no, but this is the default and the accelerated encryption
makes a secure runtime nearly transparent to you as a user.  (in other
words, we believe it is worth the cost to do so if you can)
- can i meet one of your members in person for a strong key exchange
and authentication?
    :: sure, see item * secure means strong least privilege vetted by someone you trust. this degree of virtuous interaction is very difficult, complicated and
currently believed to be the most secure way to design and maintain a
secure system.  this is elaborated on in detail in our technical
documentation archive.

@_date: 2006-03-28 02:24:58
@_author: coderman 
@_subject: Fwd: [p2p-hackers] lockstep synchronization protocol problem 
can you introduce some papers to read about what you have said?I can't get your
meaning,but thank you.how is it related to the synchronization problem?
i am about to go offline for the night; here are a few off the top of
my head that are relevant.  i can post more later this week and others
on this list will likely have input.
group key distribution:
Efficient Self-Healing Group Key Distribution with Revocation Capability (2003)
group reputation / trust metrics:
quorums and usability are more complicated and i don't have any links off hand.
best regards,
P.S.  please reply with any additional research / results if you
encounter them...
TZDz5D at 4PEVPTx>-La5=:
  "Peer-to-peer development."

@_date: 2006-03-28 02:39:43
@_author: coderman 
@_subject: off the record howto / best practices 
verify fingerprint:
"Buddy List"
   -> Tools Menu Options
      -> Preferences Menu Option
         -> Plugins Menu Option
            -> Select Username from Known Fingerprints
               -> Press "Verify fingerprint" action
                  -> VIEW FINGERPRINT AND APPROVE/REJECT IF EXPECTED
Fingerprint for you, coderman42 (AIM/ICQ):
A59CDCB3 46468A16 27D21678 270AF0B5 0B0477CF
Purported fingerprint for anonymous:
0B0477CF 270AF0B5 27D21678 46468A16 A59CDCB3
                     -> Select "i have" verified action only if expected is true
using verified otr credentials:
  -> Select "OTR: Not Private" image button at lower right corner if
secure channel is down
     -> Verify "OTR: Private" image button at lower right corner before chat
example of a failed key agreement:
the "OTR: Unverified" image was never shown at the lower right corner
of the window
indicating an initial OTR exchange had taken place.
(02:12:01) anonymous: hi code
(02:12:05) Attempting to start a private conversation with anonymous...
(02:12:11) coderman42: hello
(02:12:14) coderman42: do you have OTR?
(02:12:38) anonymous: hold on
(02:12:51) coderman42: k
(02:13:39) anonymous: *** Encrypted with the Gaim-Encryption plugin
            02:17
(02:18:16) coderman42: sorry, no worky for you.
(02:18:19) coderman42: try again
(02:18:29) coderman42: what client / OS are you using?
(02:18:38) coderman42: i recommend a unix like system with gaim
(02:19:46) anonymous: i am on gaim and i was useing gaim encrypt
(02:21:47) Attempting to start a private conversation with anonymous...
(02:22:00) coderman42: maybe you were; it is not working currently.
            02:22
(02:22:33) anonymous logged out.
(02:23:04) anonymous logged in.
(02:23:10) coderman42: wb
(02:23:12) Attempting to start a private conversation with anonymous...
(02:23:23) coderman42: (02:23:12) Attempting to start a private
conversation with anonymous...
(02:23:27) coderman42: waiting ...
(02:23:44) coderman42: brb
(02:26:58) anonymous: *** Encrypted with the Gaim-Encryption plugin
            02:27
(02:28:45) anonymous logged out.
remember to protect your keys.

@_date: 2006-03-29 22:30:45
@_author: coderman 
@_subject: how to get johnny to encrypt (his hard drive) 
thoughts on making this simpler?
0. insert new second disk of equal or greater size
1. boot from trusted cd/dvd ISO image
2. insert USB memory stick (or two if you want a backup)
3. enter new password / passphrase (see good password howto)
4. agree/confirm to copy over empty / target disk
5. wait as new disk is encrypted via loop-aes, keys are stored on
password protected USB image, all existing OS data* on source disk is
copied to encrypted volume on new disk.
6. reboot into new encrypted volume and copy back over original source
hard disk with loop-aes and store keys for this disk on USB image.
7. Johnny gets a data backup with his privacy.
* ubuntu, knoppix, slackware, linspire and centos supported.  a
windoze or other partition (vfat, ntfs, etc) can be copied and mounted
under a new installation of the previously mentioned linux OS'es on
the new encrypted disk. (if one of these linux flavors is not already

@_date: 2006-03-30 02:46:15
@_author: coderman 
@_subject: [Full-disclosure] Fwd: On sandboxes, and why I ... don't 
amen.  what's the cost if you are wrong?  (the likely case over a
sufficient period of time against motivated attackers)
that artificial security flavoring is only reassuring while the luck
in a shared processing environment you have bigger concerns, but i do
agree this is disturbing if your system was designed to operate in
probably coding like the other 97% of the planet.  (now that's
_really_ concerning)

@_date: 2006-03-30 02:53:57
@_author: coderman 
@_subject: [declan@well.com: [Politech] Surveillance in the sky: 
i wager $something_equivalent_to_the_cost_of_a_few_beers that the
safety concerns will scuttle this program within a year or two.
some radio punks with an fpga modem and homebrew front ends will deep
6 one of these units if occasional failure doesn't do it first.  with
so little value added it's hard to justify that kind of risk over the
public's heads and homes.
sats and manned planes are almost as effective at invading such aerial
privacy anyway...

@_date: 2006-03-30 04:08:16
@_author: coderman 
@_subject: [p2p-hackers] lockstep synchronization protocol problem 
hi jinz,
i don't have time for a detailed reply but i thought a little more
info would be useful
i mentioned quorum systems and group key distribution to achieve a
shared and authenticated state among a group of peers that can be kept
in sync / coherent via frequent attestation (group re keying with
quorum consensus to distribute new keys).
there are many ways to implement this so i'll stick to conceptual
features / attributes and how this relates to a private group network
system we are implementing.
quorum authorities are those who sign all the other authorities keys
as part of the group key distribution.  quorum  or group members are
those who receive keys from one or more quorum authorities.
the quorum authorities maintain an index of all known / trusted group
members and the trust metrics assigned to the roles / services they
can perform.
and peer may solicit, provide and consume the services of another once
they verify they are trusted to do so.  they can contact any of the
quorum authorities (who have a full index and trust metric state /
graph) to certify the remote peer before doing so.
a group authorities may issue a revocation signed by his current group
identity key to disband the quorum / group.
if consensus cannot be reached within the next group re-key interval
(due to failure, lack of consensus at the meatspace / user level, or
malicious attack / DoS) the group must be re-keyed from the face to
face ground up and all reputation rebuilt.
the identifiers signed by the quorum during each iteration consist of:
- the key digests for each authority for the next group key exchange
- the sha-256 digest of the current base share file state image
(includes base OS and private group files/keys)
- the sha-256 digests of all delta based overlay filesystem images. these are optional among group members but mandatory for all quorum
upon this base you can build / tie to various group synchronization
mechanisms that are strongly authenticated and yet still fully
i hope that helps.

@_date: 2006-03-30 06:16:02
@_author: coderman 
@_subject: [Full-disclosure] Fwd: On sandboxes, and why I ... don't 
amen.  what's the cost if you are wrong?  (the likely case over a
sufficient period of time against motivated attackers)
that artificial security flavoring is only reassuring while the luck
in a shared processing environment you have bigger concerns, but i do
agree this is disturbing if your system was designed to operate in
probably coding like the other 97% of the planet.  (now that's
_really_ concerning)
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2006-03-30 06:18:49
@_author: coderman 
@_subject: Fwd: driver for Atheros 5213 chipset - temporarily killed by 
The project has been moved to the other team. This means that this one
is put on hold
to avoid potential litigations. This has several implications with one
of them being that
this version of the driver is no longer developed in public. The other
is that the documentation
is being written for atheros hardware and the other teams is
developing the new version of
the driver so you have to be a bit patient right now.
kind regards,

@_date: 2006-03-30 06:28:05
@_author: coderman 
@_subject: Fwd: [TSCM-L] Feds bugged bedroom, phones of FIU pair 
hey, that sounds like a rotor machine.  they should have updated their
The prosecutor said the couple used their cover at FIU to infiltrate
the exile community, spying on the university's president, Mitch
Maidique, and other exile leaders. He said they secretly communicated
with the Cuban intelligence directorate, using five-digit code in
short-wave radio transmissions.
Once the messages were received, they would input them into their
home computer, equipped with decryption technology.
[... and a new enigma on ebay.  sounds a little fishy...  *grin*]
    ---------- Forwarded message ----------
CUBAN SPY CASE
Feds bugged bedroom, phones of FIU pair
New court evidence in the Cuba spy case reveals the United States
used wiretaps for years before agents arrested an FIU professor and
his counselor wife.
BY JAY WEAVER
jweaver at MiamiHerald.com
Federal agents planted a bug in the bedroom of a Florida
International University a couple of years ago, netting evidence to
charge them as unregistered agents for the Cuban government,
according to court records.
The FBI also wiretapped the home phones of Professor Carlos Alvarez
and his counselor wife, Elsa Alvarez, from at least late 2001 until
last summer, collecting electronic evidence on practically all of
their conversations.
The reams of intercepts included mundane exchanges and even the
private musings between husband and wife.
The FBI's eavesdropping of the couple's home goes far beyond what was
first known about evidence in the case, which included alleged
''confessions'' to federal agents last summer and the confiscation of
the Alvarezes' home and FIU computers. The surveillance evidence
surfaced as part of their lawyers' efforts to revoke the couple's
detention before their scheduled May 8 trial.
It's unclear from the court record how these thousands and thousands
of surveillance intercepts will help the U.S. attorney's office
prosecute the couple, who are suspected of reporting on the exile
community and its leaders to Cuban leader Fidel Castro's government.
According to sources familiar with the case, the FBI had hoped the
electronic intercepts would provide leads on alleged spying activity
on behalf of the Cuban government. The evidence led only to the
Alvarezes' arrests in January. It's unclear why prosecutors chose to
charge them at that time.
The couple's lawyers say prosecutors have produced ''about 200
supposedly pertinent conversations'' recorded by the FBI, court
records show. The evidence remains sealed from the public. But the
Alvarezes' lawyers say the ''majority deals only with mundane
activities of daily life'' -- such as conversations about the
Alvarezes' dinner plans, the tenting of their South Miami home for
termites and meetings at their Catholic church.
THE DEFENSE STANCE
The couple's lawyers, Steven Chaykin and Jane Moscowitz, argue their
clients would not leave for Cuba if released because they have strong
ties to the community, including five children and elderly parents.
They are challenging whether the FBI lawfully obtained warrants to
conduct the electronic surveillance. The FBI obtained the warrants
under the Foreign Intelligence Surveillance Act, which allows the
government to wiretap people in the United States suspected of being
agents for a foreign government or involved in terrorist activity overseas.
In the war on terror, the Bush administration has attracted sharp
criticism for authorizing warrantless domestic wiretaps without
approval from the secretive FISA court -- an issue that doesn't apply
to the Alvarez case.
It is not clear from court records how long the FBI conducted
electronic surveillance of the couple's home. But it appears the FISA
wiretaps of the Alvarezes may have begun years before the Sept. 11,
2001, terrorist attacks. Post-9/11, Congress approved the USA Patriot
Act that allows federal agencies to use foreign intelligence wiretap
evidence for criminal investigations, such as the Alvarezes' case.
'On March 6, 2006, the government produced summaries of allegedly
`pertinent' recorded conversations produced by that surveillance
starting in December 2001 and ending July 4, 2005, although the
government states that the eavesdropping began earlier and continued
until the defendants' arrest on Jan. 6, 2006,'' the Alvarezes' lawyers wrote.
The attorneys, in their motion, asked the government to disclose the
documents related to the wiretap warrants. They are trying to
challenge evidence that could affect their clients' case before a jury.
They cited constitutional protections for Carlos Alvarez, 61, a
psychology professor, and his wife, Elsa, 55, a psychology counselor,
both U.S. citizens.
Referring to the FISA law, the attorneys said: No U.S. citizen ``may
be considered an agent of a foreign power solely upon the basis of
activities that are protected by the First Amendment. . . .''
For example, they argued, more than 40 of the ''pertinent'' FISA
recordings are telephone conversations between Carlos Alvarez and an
unidentified colleague regarding legally licensed culture-exchange
programs between the United States and Cuba.
PROTECTIVE ORDER
This month, federal prosecutors refused to turn over documents for
the FISA warrants to the Alvarezes' attorneys.
So far, U.S. District Judge K. Michael Moore has issued a protective
order that allows only members of the legal teams and their staffs to
review the declassified FISA intercepts for the upcoming trial.
Prosecutors apparently disclosed evidence about the FISA wiretaps to
show the judge that the Alvarezes are a ``serious risk of flight.''
Assistant U.S. attorney Brian Frazier cited Magistrate Judge Andrea
Simonton's January ruling in which she said the couple would receive
''a hero's welcome'' in Cuba.
The prosecutor said the couple used their cover at FIU to infiltrate
the exile community, spying on the university's president, Mitch
Maidique, and other exile leaders. He said they secretly communicated
with the Cuban intelligence directorate, using five-digit code in
short-wave radio transmissions.
Once the messages were received, they would input them into their
home computer, equipped with decryption technology.
Prosecutors say the couple traveled to Cuba, Mexico and other
countries to exchange information with their handlers from the Cuban
Directorate of Intelligence.
According to court filings, the Alvarezes reported on ''community
attitudes'' after the FBI's 1998 arrests of 10 Cubans charged with
spying. That high-profile espionage case was linked to the Cuban
government's shoot-down of two Brothers to the Rescue exile planes
over the Florida Straits that killed four Miami men two years earlier.

@_date: 2006-03-30 10:35:00
@_author: coderman 
@_subject: Fwd: driver for Atheros 5213 chipset (fuck the fcc!) 
fuck the fcc!
---------- Forwarded message ----------
their identities cannot be exposed lest the FCC sniper team neutralize
their potential threat to authoritarian spectrum monopoly.
and translated across three languages... just to be sure.
the dcs1000 has been having problems.

@_date: 2006-03-30 11:05:56
@_author: coderman 
@_subject: cypherpunks write girl code? :) 
Do engineers and programmers care about concepts like beauty and
elegance? Should they? Designers have always known that looks
matter--that the outside (interface) matters. But deep in the heart of
those building the inside--the technology most users never see--lies
the sensibility of an artist. In a kind of "Design Eye for the Code
Guy" way.
While I'm stereotyping with abandon, I might as well be honest. I've
been going to tech conferences for the last 15 years, and I swear the
ratio of pocket protectors to Urban Outfitter clothes has shifted
dramatically. So maybe it's not accurate to say geeks today are better
looking--but they're certainly better dressed. With hipper haircuts.
Does this /mean/ anything? Maybe.
What prompted this post--and it's whimsical title--is a post by Jamis
Buck titled Beautiful code, test first, which includes the following:
"He was telling me how he feels like he has to sit and tweak his code
over and over until it not only acts right, but looks right. It cannot
be merely functional, it must be beautiful, as well."
But the best part was a comment by "Morten" that included the line:
"As for spending too much time on making the code look right down to
the last indentation - my code has been called "girl code" for the
same reason..."
And there you have it. I think "girl code" is quite a compliment.
Because caring about things like beauty makes us better programmers
and engineers. We make better things. Things that aren't just
functional, but easy to read, elegantly maintainable, easier--and more
joyful--to use, and sometimes flat-out sexy. And whether we like it or
not, most of the world associates an appreciation for beauty more with
women than men (especially geek men). Women may have a genetic
advantage here.
A passion for aesthetics can mean the difference between code that
others enjoy working on vs. code that's stressful to look at.
Yes, calling beautiful code "girl code" is both silly and some might
believe sexist. But that doesn't mean there isn't some truth to it. As
a female technologist in a heavily male-skewed industry, I don't need
you to compliment my hair. But if you tell me my code is pretty, I
might give you some tips.
And if it makes you feel better, I'll refer to YOUR gorgeous code as
metrosexual. But we'll both know the truth.

@_date: 2006-03-30 16:09:38
@_author: coderman 
@_subject: [p2p-hackers] group key agreement (was: lockstep 
a very detailed paper on group key agreement for ad-hoc networks:
Abstract. Over the last 30 years the study of group key agreement has
stimulated much work. And as a result of the increased popularity of
ad hoc networks, some approaches for the group key establishment in
such networks are proposed. However, they are either only for static
group or the memory, computation and communication costs are
unacceptable for ad-hoc networks. In this thesis some protocol suites
from the literature (2^d-cube, 2^d-octopus, Asokan-Ginzboorg, CLIQUES,
STR and TGDH) shall be discussed. We have optimized STR and TGDH by
reducing the memory, communication and computation costs. The
optimized version are denoted by 5STR and 5TGDH respectively. Based on
the protocol suites 5STR and 5TGDH we present a Tree-based group key
agreement Framework for Ad-hoc Networks (TFAN). TFAN is especially
suitable for ad-hoc networks with limited bandwidth and devices with
limited memory and computation capability. To simulate the protocols,
we have implemented TFAN, 5STR and 5TGDH with J2ME CDC. The TFAN API
will be described in this thesis.

@_date: 2006-03-31 13:19:14
@_author: coderman 
@_subject: Fwd: [TSCM-L] Re: Feds bugged bedroom, phones of FIU pair 
code pad shortwave from cuba:
---------- Forwarded message ----------
In regards to this piece - I found the following in the March 06
edition of Monitoring Times at page 8.
Spies Use Shortwave Broadcasts
In January, a Florida couple was accused of operating as covert agents
for Cuba's communist government for decades, using short-wave radios,
5-digit numerical-code language and computer-encrypted files to send
information about Miami's exile community to top Castro intelligence
Carlos Alverez and his wife Elsa, both staff members of Florida
International University, were denied bond before trial on a charge of
failing to register with the federal government as foreign agents.
The indictment, which included no mention of top-secret U.S.
government information being disclosed, came months after the couple
confessed to the FBI. Assistant U.S. Attorney Brian Frazier said
Carlos Alverez had spied for Cuba since 1977 and Elsa Alverez since
(See page 28 for more on Cuban 'numbers' stations.)"
Page 28
"UTILITY WORLD
HF COMMUNICATIONS
Cuban 'Numbers': A Pattern Emerges
By: Hugh Stegman, NV6H
hugh stegman at monitoring times.com
   Collection and analysis of several months' loggings confirms that,
just as others have observed, the Cuban voice 'numbers' station does
indeed have what may be its first daily broadcast schedule ever.
  This station is also known as 'V2,' 'Attention' (from its callup),
the 5-Figure Spanish Lady, and the 'SS/YL/5F' (same thing in
shortwavese'). Its the latest version of the famous Cuban spy
transmissions which have mystified listeners in much of the world,
while inspiring some good pop music, for several decades now.
  And indeed, these broadcasts are compelling in their sheer
strangeness. Mumbling voices, strange noises, Radio Havana, and even
the occasional parrot, can turn up on the open tuning carriers run
before the messages. Technical flubs, mostly of the 'oops, wrong
button' variety, are many and legendary. If everything works (always a
big "if" with this bunch), that ominous machine-spliced female finally
barks the distinctive 'Atencion' ('Attention').
   While the name 'V2' sounds appropriately like some kind of World
War II German rocket bomb, it is simply the sequential designator
given this particular broadcast on the list maintained by ENIGMA2000.
They're the online incarnation of the European Numbers Intelligence
Gathering and Monitoring Association. Over the years, this generic V2
has had a number of lettered variants. These differ in message
structure or detailed formatting.
   After the callup, our V2a variant sends a message designator with
three 5-number groups. These are the first groups in the three
following messages, which are of equal length. Each message is always
150 5-number groups, beginning (as we've noted) with the one in the
designator. The whole transmission usually ends with the Spanish
'final'  ('end'), around 45 minutes after the hour.
  While the Cubans have traditionally preferred monthly and weekly
schedules, the new local-daytime V2a is a daily one. It's a long
schedule by 'numbers' standards. It's more  like something you'd hear
from an international broadcaster, changing frequency more of less
hourly while maintaining a long program. This is pretty ambitious for
an operation which is so audibly straining to keep its aging,
hurricane-damaged equipment going.
  The daily schedule starts at 1600 Coordinated Universal Time (UTC),
and goes until the 2100 broadcasts ends, nearly six hours later. The
times in UTC and frequencies in kilohertz (kHz, AM mode) are:
       1600 on 7975.0
       1700 on 8010.0
       1800 on 8097.0
       1900 on 8097.0
       2000 on 7887.0
       2100 on 6855.0
   That's it. By the standards of 'numbers' stations, which often
confront listeners with a bewildering number of times and frequencies,
this is pretty simple stuff.
   But there is way more: All of the other V2 schedules are still on
the air. These are the more traditional ones, using what may or may
not be a weekly frequency rotation. Parallel transmissions frequently
occur, on two or three frequencies.
   At press time, the rest of V2a was on from as early as 0200 UTC
until as late as 1500. In other words, there's a Cuban voice 'spy
numbers' station  going somewhere at nearly any hour of the day. This
doesn't even count the hours of Morse code broadcasts in a similar
format. For whatever its worth, which may not be much, this represents
an awesome volume of traffic.
  V2a Message Continuity
  These transmissions have another most interesting feature. If one
logs all of the initial three-group message designators, it becomes
quickly evident that they are anyting but random. In fact, they ofter
increment their last figures by one with each day's broadcast.
   The best way to explain this is by example. On December 11, 2005,
one of several sets of message designators was 38641  45851  51761. On
the 12th, this one changed to 38642 45852 71762, but the messages
stayed the same. On the 13th, it became 38643  45853  51763. This
continued until the last digits reached 6 on the 16th.
   At the same time, another sequence started out as 55911  12911 31311 (they always seem to start out ending in 1). This one did the
same behavior, until reaching 5 on the 15th. Currently, in early
January, we have 51871  10971  04481, incrementing daily.
  It's been theorized that this last digit refers to the number of
times a message has been broadcast. In any event, it's a real good
idea to keep track of these numbers when logging the Cuban stations.
   As special word of thanks is due to Camilo Castillo, a dedicated
ham and numbers listener in Panama, for making most of the loggings
used in the data. A few others appeared on the usual Internet mailing
lists, and the showed the same patterns we describe."
 THE artilce also shows what they claim is a "Typical code pad used
with 'numbers' broadcasts." It is a small booklike pad about the same
size as the match box used for the small wood or kitchen type matches
( 2" x 1" x .5") with six  columns of numbers printed on both sides of
the page.
THE END
Reg Curtis VE9RWC

@_date: 2006-03-31 14:12:02
@_author: coderman 
@_subject: keys and cards and user interaction 
comments?  suggestions?
"keys" store password/passphrase protected volumes with cryptographic
keys, certs, and other credentials associated with digital identities.
"cards" are read only volumes with the public keys and public
identifiers associated with digital identities.
it is very important that they not be confused, and that "keys" are
only used on a trusted system.
"keys" are the only volume which will ever prompt for a
password/passphrase to open them.  if you are asked for a password it
should only be on a system you trust and as expected when using or
managing your keys.  keys are stored on an XFS filesystem on USB or
other media (USB by default) which contains the encrypted key store. this scales well (multi-gig USB volumes) and uses existing crypted
file system support to implement privacy.  Any number of other volumes
(for example hdd installed OS'es) can be tied to this "keys" volume by
storing the AES keys and disk identifiers associated with that volume
inside the "keys" protected volume.
the only boot targets which may use private "keys" are:
 - the "keys" secure key management mode.
  - the "install" mode to create new loop-aes keys and install OS on
this trusted system.
  - the "hdd" mode to boot an encrypted OS installation on a trusted system.
the other boot targets should only reference public "cards" and will
never prompt for authentication at boot or during operation.
"cards" are ISO9660 filesystems that can be stored on a public USB
memory stick or burned to mini-CDR / DVD-R, etc.  "cards" are public,
and can be copied freely and will never ask for authentication.
the "keys" authorized modes thus explicitly mount a USB volume as XFS
when a "keys" volume is expected.  the key mgmt mode will explicitly
mount as iso9660 when a "cards" volume is expected.  thus a confused
user could not accidentally write secret "keys" data to a public
"cards" volume, and vice versa.
this also allows the key management mode to determine what kind of
volume is present as indicated by the file system type. (the secure
key management mode is the only mode where public "cards" can be
imported to your secret "keys".  the hdd and install modes will never
prompt for a public card.  note that the "live" boot mode may use
"cards" to connect to remote services securely.)
"keys" storage:
[XFS volume ...
   (petname for this volume)
   (public GUID / nonce)
   (GPG or loop-aes encrypted file)
.../coderman/  (petname)
.../coderman/id.txt   (512 byte GUID / nonce in hex)
.../coderman/keys.dat   (encrypted key store, gpg or loop-aes)
coderman might be a social context while mpeck is a professional context.
"cards" storage:
[ ISO9660 volume ...
  (sha512 hash of identity public key)
  (identity public key)
  (nickname or alias for identified entity)
  (additional volumes or metadata)
  (signatures for nicknames and other metadata)
.../1496b640690342ed/  (hex digits of first 8 bytes of sha512 digest
of public.key)
.../1496b640690342ed/digest.txt  (full hex digits of sha512 digest of
.../1496b640690342ed/nickname.txt  ("coderman's public weblog")
.../1496b640690342ed/aaaaaa.dat   (arbitrary metadata - an image? etc)
.../1496b640690342ed/aaaaaa.sig   (signature for above)
.../1496b640690342ed/foo.dat   ""
.../1496b640690342ed/foo.dig   ""

@_date: 2006-03-31 19:06:34
@_author: coderman 
@_subject: keys and cards and user interaction 
some corrections / clarification:
note that within a graphical environment you may be prompted for
passwords or authentication unrelated to the root/core identities
which are stored in the "keys" volume(s).
within the janus wireless software all password/passphrase management
for root/core identities (the "keys" volume(s)) occurs at a text
console and usually during boot.
facilities are in place to prevent you from needing passwords in other
contexts although this cannot cover every possibility.
(that is to say, within janus we encourage the use of certificates and
signatures for authentication and captcha/PINs for liveness detection.
 the identity management provided by janus wireless software is
intended to make these keys/certificates easy to create, distribute,
manage and revoke in any external domains where they are used.)
this console mode only password use is done to prevent UI attacks
(phishing, spoofing, etc) and text console provides a good way to
avoid these.
the secure key management mode can import and export keys and cards
and supports a wide variety of filesystems to do so.  key backup (if
used, please do) occurs in this domain and may consist of saving the
password protected volume to multiple USB keys, compact flash drives,
hard disks, or burned to CD/DVD media.  you can use a different
password/passphrase for these backup volumes.  (for example, a random
256bit key written on a card stored in a safe)
the other "keys" authorized modes simply consume/use existing keys.
the "live" and internet connected modes are ephemeral, and thus only
use public "cards" when pubkeys/certificates are required to access
resources.  if replay / MITM is a concern the public keys used should
be one time only.
that should read: 512 _bit_ GUID or nonce in hex string.
a social and professional context are the two types provided by
default.  the number of contexts supported is limited only by storage
space on the "keys" volume and your ability to assign distinct pet
names to each.

@_date: 2006-03-31 19:23:34
@_author: coderman 
@_subject: janus wireless faq 
- why "wireless"?
we believe that wireless is the most robust form of communication when
implemented properly*.  we also believe that any communication between
secure domains should be considered public and open to active
attackers (like wireless is).
for this reason strong privacy and authentication must always be used
for secure network communication.
a proper wireless implementation can transmit datagrams in an
injection style manner and receive any datagrams in a monitor style
manner.  all packets received must be authenticated before passing up
to higher level (IP/etc) stacks. all unauthenticated packets must be
dropped silently.  the rate of transmit should be as low as possible
while still retaining sufficient communication bandwidth.  the rate of
transmit should also be considerate to the needs of others who can
hear your transmission and may defer theirs accordingly.  deference
should not open up denial of service vulnerabilities but is encouraged
when possible to provide a cooperative multi-network with sufficient
bandwidth for all.
[the technical complexity of this is high and we are being
intentionally vague at this point until further refinements are in
place and this can be described in detail via working implementation
on atheros / prism2 hardware that does not DoS other wireless
technologies.  802.11 is a good example of an improper implementation
that is trivial to DoS via spoofed packets at the MAC layer
(deauth/disassoc injection).]

@_date: 2006-05-08 03:28:24
@_author: coderman 
@_subject: [dave@farber.net: [IP] more on Hayden's Mistaken 
i needed a good laugh today; what fortune...
i passed by the much expanded nedonna beach[1] landing point and
facilities the other day. i am very curious to see the monetary
value[2] attached to this "reasonable searching" if it ever comes to
1.  |
2. every dollar they print chips away at the value of the bills in
your pocket/account.  as if taxation wasn't bad enough. where is the
TIA/echelon refund on 1040? *grin*
 Gold prices still expected to climb
Consumers and investors pushed demand for gold to a record level of
$53.6 billion last year, fuelling the precious metal's price ever
... many economists expect the US dollar to decline. "Historically,
all else equal, the dollar price of gold rises as the dollar itself
weakens," Murenbeeld says.

@_date: 2006-05-11 09:56:45
@_author: coderman 
@_subject: [dave@farber.net: [IP] NSA has massive database of 
actually, there was one detail which surprised me:
"""Among the big telecommunications companies, only Qwest has refused
to help the NSA, the sources said. According to multiple sources,
Qwest declined to participate because it was uneasy about the legal
implications of handing over customer information to the government
without warrants...
According to sources familiar with the events, Qwest's CEO at the
time, Joe Nacchio, was deeply troubled by the NSA's assertion that
Qwest didn't need a court order  or approval under FISA  to
Trying to put pressure on Qwest, NSA representatives pointedly told
Qwest that it was the lone holdout among the big telecommunications
companies. It also tried appealing to Qwest's patriotic side: In one
meeting, an NSA representative suggested that Qwest's refusal to
contribute to the database could compromise national security, one
person recalled.
In addition, the agency suggested that Qwest's foot-dragging might
affect its ability to get future classified work with the government.
Like other big telecommunications companies, Qwest already had
classified contracts and hoped to get more."""
of course. computers can't read ;)
i'm still lusting for financial full disclosure: "... The sources said
the NSA made clear that it was willing to pay for the cooperation." ,
maybe in a decade or two..

@_date: 2006-05-11 15:34:33
@_author: coderman 
@_subject: [dave@farber.net: [IP] NSA has massive database of 
hrmm, another question below...
let's look at 2002 operating revenue as a clue to telco size:
1. Verizon - $67,625,000,000
2. SBC - $43,138,000,000
3. AT&T - $37,827,000,000
4. Sprint+PCS - $27,256,000,000 (now add nextel?)
5. BellSouth - $22,440,000,000
6. Quest - $19,965,000,000
funny there is no mention of requests to Sprint; why their conspicuous absence?
here's a paranoid theory: they already provided pen register
equivalent data in real-time and could easily support the additional
raw fiber taps used for targeted capture before 9/11 made it a well
funded and well obfuscated priority across all carriers.
Daytona wasn't the only prototype / telco system adopted in this
domestic info war zone.
keep the whistles blowing...

@_date: 2006-05-11 15:45:59
@_author: coderman 
@_subject: [dave@farber.net: [IP] NSA has massive database of 
here's my guess:
- big name(s) in fancy transport make a show of arrival to convey
presence of authority
- discussions are held in confidence and off the record.  top sekrit, etc.
- verbal assurances given but no paper trail.  ask with a carrot ($$$)
and a stick (national security risk, etc)
as far as conveying the image of authority, maybe just a nice suit, an
ear piece, and a chevy blazer with white tags is sufficient...  ;)
(i'd love to know more detail on how these conversations were implemented)

@_date: 2006-05-15 08:12:17
@_author: coderman 
@_subject: Fwd: Some legal trouble with TOR in France 
ah, reputation and trust.  my favorite crux
---------- Forwarded message ----------
I am living in France and working for some French security agency.
Please understand that I may not identify myself. Working for a
security agency does not mean that I approve all their actions, even
those that I MUST do.
Since about 5 years, French services are trying to control the
"anonymous" French based services. It includes TOR, and some
About 4 years ago (I don't remember exactly, and I am at home now, I
haven't my documents with me), we visited the operator of the
remailers FROG and AZERTY. We suspected him to be also the webmaster
of the website CAMELEON, but it is another story.
We seized his computers, disks of course, etc, and arrested the man.
Then we told him "You have a choice between 2 options: You accept to
work for us, it means concretely to give us your remailers' keys and
to forward the remailer emails to us, or you will go to prison for
threat against the national security. Just a few months, the time we
check all your computers, make an audit on your disks, etc".
After 30 minutes, the guy gave us his remailers' keys, and accepted
our offer. He then re-installed his remailers, and all the traffic was
sent to us too. I remember that we asked him to NOT send us the
garbage that the remailers automatically send! Then our computers
processed the messages, using the remailers' keys. Of course we could
not decypher all, if Frog/Azerty was :"in the middle" we couldn't do
anything. But when these remailers where the first or the last one, it
was very very interesting...
I don't know now if these remailers are still operated, I am working
in another service.
About TOR now: I MAY not say all what I know, as the case is currently
investigated by our services and I don't want to get into trouble!
Just know that France's policy is to NOT allow ANY remailer or
anonymous service run from France, UNLESS the French special services
can control it. This is a NO exception rule.
The only recommendations that I can do to the TOR users, is to NOT use
any French-based TOR servers in entry ou exit.
People here and there are generally against the US gov and say that he
"violates their rights". I don't know a lot about the US gov. But what
I know about the French gov, and the instructions our services receive
a few times by week, make me sure that the French citizens' rights are
perpetually violated, about phone tapping and internet.

@_date: 2006-05-16 14:09:04
@_author: coderman 
@_subject: Fwd: Some legal trouble with TOR in France 
i suppose my point was that trusting tor as it stands is a leap of
faith.  there is little visibility as far as node selection criteria
for addition to the directory, the information and physical security
aspects of the servers within the directory, and the reputation of the
node operators with respect to "rubber hose / threatened
incarceration" attacks and the associated trust level to assign in
such a context.
much better than nothing, but i still consider tor useful mainly for
keeping your source IP out of webserver logs.  any other government /
malicious entity can compromise accordingly.  (i know this isn't the
situation overall, but i assume as much so i won't be surprised by a
worst case)
i used to run a peertech node on a dedicated server.  this host was
compromised by tech staff at the facility with physical access and
ever since i've refused to operate a node until i could be sure
physical security was assured.
i tend to consider any service that relies on host integrity also
reliant on a number of other prerequisites like:
- physical security to prevent unauthorized access
- hard disk encryption to prevent unauthenticated disclosure (esp.
seizure of hardware)
- infosec best practices to keep attack surface minimal (firewalls,
chroot, VM's, POLA, etc)
for the situation mentioned in parent thread, i'd like to know that if
the TLA comes knockin' my key scrubbing loop-aes turns all disks into
large entropy stores the moment power is killed upon any attempted
most services currently assume the disk is private.  if you want a
private disk, you need full disk encryption (key scrubbing in RAM++)
tied to strong authentication.

@_date: 2006-05-16 14:22:24
@_author: coderman 
@_subject: Russ Tice to testify tomorrow about "shocking" new programs run 
i'm anxiously awaiting some more technical detail on all these black
programs so heavily compartmentalized beyond accountability.
this is my favorite Russ Tice quote:
"there's no way the programs I want to talk to Congress about should
be public ever, unless maybe in 200 years they want to declassify
them. You should never learn about it; no one at the Times should ever
learn about these things. But that same mechanism that allows you to
have a program like this at an extremely high, sensitive
classification level could also be used to mask illegality, like
spying on Americans." [1]
Arkin says that all these activities revolve around two key questions:
are these just "ingestion and digestion" designed to catch more
terrorists, or are they the "the building blocks of a new seamless
surveillance culture?"
""We should be terrified that Congress has not been doing its job and
because all of the checks and balances put in place to prevent this
have been deliberately obviated. In order to get this done, the NSA
and White House went around all of the checks and balances. I'm
convinced that 20 years from now we, as historians, will be looking
back at this as one of the darkest eras in American history. And we're
just beginning to sort of peel back the first layers of the onion.
We're hoping against hope that it's not as bad as I suspect it will
be, but reality sets in every time a new article is published and the
first thing the Bush administration tries to do is quash the story.
It's like the lawsuit brought by [the Electronic Frontier Foundation]
against AT&T  the government's first reaction was to try to quash the
lawsuit. That ought to be a warning sign that they're on to
something."" - Matthew Aid
Meanwhile, National Journal's CongressDaily reported last week that
Russell Tice, a former NSA employee who was also one of the sources
who revealed the warrantless wiretapping story to The New York Times,
is going to give Senate Armed Services Committee staffers more
information Wednesday about the activities of the NSA during the
tenure of Gen. Michael Hayden. He says some of the things he will tell
the committee include the news that "not only do employees at the
agency believe the activities they are being asked to perform are
unlawful, but that what has been disclosed so far is only the tip of
the iceberg."
'    [Tice] said he plans to tell the committee staffers the NSA
conducted illegal and unconstitutional surveillance of US citizens
while he was there with the knowledge of Hayden. ... "I think the
people I talk to next week are going to be shocked when I tell them
what I have to tell them. It's pretty hard to believe," Tice said. "I
hope that they'll clean up the abuses and have some oversight into
these programs, which doesn't exist right now." ...
    Tice said his information is different from the Terrorist
Surveillance Program that Bush acknowledged in December and from news
accounts [last] week that the NSA has been secretly collecting phone
call records of millions of Americans. "It's an angle that you haven't
heard about yet," he said. ... He would not discuss with a reporter
the details of his allegations, saying doing so would compromise
classified information and put him at risk of going to jail. He said
he "will not confirm or deny" if his allegations involve the illegal
use of space systems and satellites.  '
1.

@_date: 2006-05-16 14:42:36
@_author: coderman 
@_subject: [anogeorgeo@yahoo.com: ATTN: MiTH attack against SkyPE, 
zero knowledge mixing.  even tor isn't enough.
ah, reputation and trust.  my favorite crux
human minds don't recall verbatim digital detail in bulk.  while i
agree there is more pork than effectiveness behind these systems, they
no doubt contribute significantly.
leveraging meatspace weakness for visibility into dark stores of data
seems especially useful.  keys are keys and digital data doesn't
"Catching sight of a pretty woman really is enough to throw a man's
decision-making skills into disarray."
oldest tricks are the best tricks i suppose.  they did send an
attractive fed chick to probe for info at DC13 while running the
blackbox challenge.  i'll take that over a rubber hose any day...

@_date: 2006-05-16 15:01:31
@_author: coderman 
@_subject: ISPs providing "warrant canaries" 
i've never heard of it before and google seems to think they coined it.
doesn't seem too useful.  if a warrant/NSL is served, was it for your
system?  do you now switch providers?  assume all secrets are
if you are concerned then a hosting facility is probably the wrong
place to keep your data / servers.

@_date: 2006-05-16 15:04:10
@_author: coderman 
@_subject: [dave@farber.net: [IP] Federal Source to ABC News: We Know 
i got a good chuckle out of that one.  such a simple solution!
makes me wonder who the source is...

@_date: 2006-05-16 15:52:29
@_author: coderman 
@_subject: ISPs providing "warrant canaries" 
this part i like!
i'm waiting for some judge to rule that these tricks effectively
disclose the reception of an NSL and are thus illegal.  judges don't
like technical hair splitting when the intent is clear: to disclose
what you are forbidden from disclosing.
(of course, Doug Thompson was able to skate by disclosure carefully so
perhaps this isn't much of a concern[1] :)
no keys are stored at the remote location?  or the traffic is
encrypted before the files are stored to disk plaintext?
keeping remote secrets secure is hard (usually requires hardware
tokens with tamper resistance)
1.

@_date: 2006-05-17 11:20:19
@_author: coderman 
@_subject: NS&AT&T 
this would be my assumption.  filter and backhaul the interesting
content on leased fiber. (and pay for rack room + leased fiber, $$$)
i'd love to have Sean Gorman's fiber map about now...
4 x OC3 = 622,080 kbp/s
8 x OC12 = 4,976,640 kbp/s
4 x OC48 = 9,953,280 kbp/s
== 15.552 Gbp/s  (is half of this mostly idle protect?)
given FPGA matching which can support at least a few hundred snort
style rules per chip at 10GigE line speed i don't think the Narus is
the bottleneck / limiting factor.  this type of deep inspection scales
linearly and is well within budget (though still expensive).
the Narus Insight can troll 10GigE/OC-192 links at L4 and OC-48 at L7.
 this might explain why the circuits top out at OC-48 into the tap
if you had a culling ratio of 25:1 you could backhaul all the
interesting traffic for this 15Gbps feed on an OC12.  assuming half
these links are idle protect that would drop the necessary culling in

@_date: 2006-05-17 13:50:58
@_author: coderman 
@_subject: Judge denies AT&T request for closed hearing 
wow, perhaps the attempted DoJ dismissal is going to get rejected as well...
A federal judge rejected a request from AT&T on Wednesday to kick the
public out of a hearing in a lawsuit alleging the telecommunications
company illegally cooperated with the National Security Agency.
AT&T had asked U.S. District Judge Vaughn Walker to bar everyone but
attorneys from the courtroom, arguing that trade secrets about the
inner workings of its network could be divulged.
"We have intellectual property rights in that information," said David
Anderson, an attorney at Pillsbury Winthrop who is representing AT&T.
"We submit that the hearing itself be held 'in camera,'" a legal term
meaning in private.
But Walker rejected the request, saying that carefully dealing with
questions about trade secrets in an open courtroom "is not
CNET Networks (publisher of CNET News.com), Wired News and the
California First Amendment Coalition sent an attorney to the hearing
on Wednesday to argue that the public should not be prevented from
attending the proceedings. A letter written by Roger Myers at Holme,
Roberts & Owen submitted early in the day said the hearing should
remain open because "the surveillance at the heart of the case
presents issues of enormous public interest and importance."
The Electronic Frontier Foundation, a digital rights group in San
Francisco, filed the class action lawsuit in January that claims AT&T
illegally cooperated with the Bush administration's secret
eavesdropping program. EFF has obtained documents from a former AT&T
employee that it believes buttresses its case, but which the
telecommunications company says contain trade secrets and proprietary
business information.
Both sides have been quarreling over what to do with the documents
provided by former AT&T technician Mark Klein and filed under seal
with the court, with EFF saying they should be made entirely public
and AT&T arguing they should be returned because they contain
confidential information.
Walker on Wednesday effectively split the difference, saying that he
would maintain the current state of affairs for now. He also ordered
EFF's attorneys not to "disclose these documents to any party," and
rejected AT&T's request that Klein be muzzled, saying the company
could sue him directly if it chose.
Based on the information that's been made public so far, the 100 pages
or so of information in Klein's documents appear to describe a secret
room established in AT&T's main switching centers through which a
tremendous amount of Internet and voice traffic flows. Those secret
rooms, according to Klein's attorney, give the NSA full access to the
company's networks and can be found in switching centers in San
Francisco, Los Angeles, Seattle and San Jose, Calif.

@_date: 2006-05-17 14:15:06
@_author: coderman 
@_subject: NS&AT&T 
i'd love to know how much manpower is assigned to defining and tuning
these filters.  this is a difficult process to be sure.
the SunFire V880 is the Narus controller according to the docs and i
bet the filter updates are pretty frequent.  they might even use an
IPsec VPN over the backhaul fiber via the cisco/juniper switches
indeed.  and the StorEdge T3 could cache quite a bit during peak
activity to fill up idle periods later at night.  (oh crap, i hope we
aren't giving them ideas!  ;)
yes.  it keeps that layer 7 inspection guessing past layer 4.  a
large, reputable zero knowledge mix is what would be ideal, though the
latency induced makes certain services impossible or unfriendly.
i love to promote out of band distribution any chance i get, including
sneaker net with DVD-R's and local wireless networks between peers.
but you really need a zero knowledge configuration to be sure.
i have faith in well designed hardware entropy sources and AES-256 in
hardware when frequently rekeyed.  pubkey crypto makes me nervous
(long term) but will always be useful.
i have much less faith in the systems around these crypto primitives,
be it operating systems or protocols down to physical security and
side channels.  i bet the black bag jobs are almost always 100%
100,000,000 peers running a zero knowledge mix off their broadband
connection.  i don't think stego would be effective; if there was an
unbreakable stego system the overhead would be significant.  (there
was a design a fellow at DC13 described using inodes on valid file
systems for storage, but this doesn't give you much space compared to
the physical storage capacity used overall)
but lots of crypto everywhere would certainly help make the presence
of encryption alone less interesting.  (as has been rumored on this
list and elsewhere that merely using encryption makes you interesting)

@_date: 2006-05-17 15:58:08
@_author: coderman 
@_subject: NS&AT&T 
hmm, i recall amusing conversations about honey tokens and baiting TLA's.
true, this is probably how it is done.
would IPsec or some NSA built auth & privacy at layer 2 be more likely?
consider this vicious rumor but a little birdie informed me that
physical security at these locations is well covered.  strategically
placed cages, reinforced and locked, armed guards. all this on top of
the usually very tight security at these facilities. (though it
sounded like the guards were a recent introduction.  someone getting
nervous about legitimate employees poking around?)
so in this case i think there is probably useful data on the disks
(the filters and controlling software for the narus / other
equipment), caching might be implemented (the T3's on fibre channel
have some nice throughput, although this configuration is years old at
this point), and i very much doubt any destructive countermeasures.
network file systems introduce reliability concerns.  intermittent
link outages would mean a bit of caching in the local case, but might
cause monitoring / capture failure in a network file system scenario.
maybe we'll find out in the near future. :)

@_date: 2006-05-17 21:35:10
@_author: coderman 
@_subject: NS&AT&T 
i was thinking three scenarios:
1. backhaul is a dedicated link (SONET?*) with encryption at this
layer and control/management out of band.
2. backhaul and control/mgmt on the dedicated link (SONET?*) with
encryption at this layer, no IPsec.
3. backhaul and control/mgmt on the dedicated link using IPsec for
both. (least likely perhaps)
the nature of SONET would make encryption at this layer tricky i think
(L2/L3?) although the NSA is fond of authentication and privacy at the
link layer.  if a desire to leverage commercial solutions (narus,
cisco, juniper, etc) won out would a strongly keyed IPsec be
sufficient?  no ISAKMP/IKE here, heh.
covert channels for backhaul?  nah, that would still be too visible.
especially if/when a customer puts link testing equipment on the line
and sees something funny. SONET doesn't give you a lot of play room.
not for this.  capturing SS7 would be useful and is surely performed though...
why not?  most of these SONET/[D]WDM links are long haul anyway.  it's
not a single repeated fiber, but hops along backbone peering points
like everything else.
also casts an interesting light on the new super NSA warehouse planned
for Denver, CO doesn't it.  nice place to position tap aggregation...
AT&T, Verizon and Sprint for sure.  probably lease fiber (through some
obfuscated shell company / other agency configuration?) from all of
them to some degree, including the transoceanic cable oligopolies.
one way to find out:
- perform your own non-interruptive tap on the fibers exiting $telco
via infiltration of outside plant conduit.  (so easy, lol)
- using test equipment see what SONET link(s) are full of blackened
traffic. you could use AS no's or BGP/SS7 characteristics to identify
legitimate circuits and highlight the blackened ones via elimination.
- ask Sean Gorman or GeoTEL MetroFiber which provider sold out that
particular circuit/fiber/route.
something tells me this is beyond the means of your average hacker.
FOIA requests it is then...  *grin*
for the record: i'm not advocating illegal intrusions; this is a
mental exercise. :)
[ i'm not too paranoid about visits from MIB's but mapping critical
information infrastructure is definitely one way to attract attention.
 maybe i'll talk more about that later... ]

@_date: 2006-05-17 21:41:09
@_author: coderman 
@_subject: Fwd: [Clips] Re: [CYBERIA] Pres. Orders and Securities Act 
thanks RAH, you save me much resource discovery time.
exposed shareholders indeed.
---------- Forwarded message ----------
--- begin forwarded text
  Delivered-To: rah at shipwright.com
  Thread-Topic: Pres. Orders and Securities Act liability (strongly verging OT)
  Thread-Index: AcZ6A/JBF/buiOcZTWGMnGJvY6GkYQAFYwFF
  Priority: normal
  Date:         Wed, 17 May 2006 21:22:13 -0400
  Reply-To: Law & Policy of Computer Communications
  Sender: Law & Policy of Computer Communications   From: chris.savage at CRBLAW.COM (Chris Savage)
  Subject: Re: [CYBERIA] Pres. Orders and Securities Act liability
(strongly verging OT)
  To: CYBERIA-L at LISTSERV.AOL.COM
  ________________________________
  From: Law & Policy of Computer Communications on behalf of Ethan Ackerman
  Sent: Wed 5/17/2006 6:29 PM
  To: CYBERIA-L at LISTSERV.AOL.COM
  Subject: Re: Pres. Orders and Securities Act liability (strongly verging OT)
  >>>>Second, I'm thinking that there's a problem here regarding
consistency.  If I have a material expenditure or liability (or, I suppose,
revenue or income or investment) that may appropriately be kept secret
under Section 78m(b)(3), then doesn't it follow logically that I will also
exclude it from the financials I file with my 10Ks and 8Ks, etc.?
Otherwise there will be a material mismatch between two publicly filed
financial statements by the same company for the same period.<<<<
  >>-The exemption covers those documents too.  Section 78m(b)(3) excuses
non-compliance only with Section 78m(b)(2) - BUT that is itself the
statutory authority for MOST of the SEC-required filings - including 10-Ks,
10-Qs, annual reports, Sarbanes-Oxley certification requirements, etc.  --
I should have made that more clear.  Most all of the '34 Act (which covers
publicly traded companies) rules are from 17 CFR Part 240 - and 78m(b)2 is
the authority for most of those rules.<<
  So: Bottom line: If AT&T (or Verizon) got paid $1 billion from the spooks
to do something, but got the right directive, they could simply not
disclose that revenue on any SEC filing.  Or, if they did something that
exposed them to liability -- like violating relevant customer privacy
requirements, and their normal obligation would be to disclose the
liability and make a reserve for it, they just don't have to.
  If that's right, at the moment it seems to me that the shareholders of
those companies are awfully exposed, aren't they....?
  Chris S.
  ************************************************************************
  This electronic mail transmission may contain confidential or privileged
  information. If you believe that you have received the message in error,
  please notify the sender by reply transmission and delete the message
  without copying or disclosing it.
  ************************************************************************
  **********************************************************************
  For Listserv Instructions, see   Off-Topic threads:   Need more help? Send mail to: Cyberia-L-Request at listserv.aol.com
  **********************************************************************
--- end forwarded text
R. A. Hettinga The Internet Bearer Underwriting Corporation 44 Farquhar Street, Boston, MA 02131 USA
"... however it may deserve respect for its usefulness and antiquity,
[predicting the end of the world] has not been found agreeable to
experience." -- Edward Gibbon, 'Decline and Fall of the Roman Empire'
Clips mailing list
Clips at philodox.com

@_date: 2006-05-17 21:47:01
@_author: coderman 
@_subject: Legal loophole emerges in NSA spy program 
this administration is particularly skilled at legal exploit.  pehaps
all that practice bending tax law over a barrel was merely warm up.
remember that Ashcroft was indeed signing approvals (in fact, they
pestered him at the hospital while he was still recovering from
surgery) and the deputy attorney general was also involved (i don't
remember if he provided authorization when Ashcroft was
incapacitated/reluctant or not...)
By Declan McCullagh
Story last modified Wed May 17 20:08:38 PDT 2006
SAN FRANCISCO--An AT&T attorney indicated in federal court on
Wednesday that the Bush administration may have provided legal
authorization for the telecommunications company to open its network
to the National Security Agency.
Federal law may "authorize and in some cases require
telecommunications companies to furnish information" to the executive
branch, said Bradford Berenson, who was associate White House counsel
when President Bush authorized the NSA surveillance program in late
2001 and is now a partner at the Sidley Austin law firm in Washington,
Bradford Berenson Bradford Berenson
Far from being complicit in an illegal spying scheme, Berenson said,
"AT&T is essentially an innocent bystander."
AT&T may be referring to an obscure section of federal law, 18 U.S.C.
2511, which permits a telecommunications company to provide
"information" and "facilities" to the federal government as long as
the attorney general authorizes it. The authorization must come in the
form of "certification in writing by...the Attorney General of the
United States that no warrant or court order is required by law."
Information that is not yet public "would be exculpatory and would
show AT&T's conduct in the best possible light," Berenson said. But he
did not acknowledge any details about the company's alleged
participation in the NSA's surveillance program, which has ignited an
ongoing debate on Capitol Hill and led to this class-action lawsuit
being filed in January by the Electronic Frontier Foundation.
Some legal experts say that AT&T may be off the hook if former
Attorney General John Ashcroft, who was in office at the time the NSA
program began, provided a letter of certification. (Other officials,
including the deputy attorney general and state attorneys general,
also are authorized to write these letters.)
"If the certification exists, AT&T is in pretty good shape," said Marc
Rotenberg, executive director of the Electronic Privacy Information
Center and co-author of a book on information privacy law.
EFF's lawsuit alleges that the telecommunications company let the NSA
engage in wholesale monitoring of Americans' communications in
violation of privacy laws. Confidential documents that EFF unearthed
during the course of the suit--kept under seal and still not
public--allege that AT&T gave the government full access to its
networks in a way that let millions of e-mail messages, Web browsing
sessions and phone calls be intercepted.
AT&T's ace in the hole?
If a letter of certification exists, AT&T could have an ace in the
hole. A second section of federal law says that a "good faith"
reliance on a letter of certification "is a complete defense to any
civil or criminal" lawsuit.
During the hearing Wednesday before U.S. District Judge Vaughn Walker,
Deputy Assistant Attorney General Carl Nichols also hinted that such a
letter exists. Nichols said that there are undisclosed "facts that
AT&T might want to present in its defense."
""" AT&T's legal defense?
An obscure section of federal law says that AT&T may have legally
participated in the NSA surveillance program -- if, that is, it
received a "certification" from the attorney general.
That section says: "Notwithstanding any other law, providers of wire
or electronic communication service... are authorized to provide
information, facilities, or technical assistance to persons authorized
by law to intercept wire, oral, or electronic communications... if
such provider... has been provided with... a certification in writing
by... the Attorney General of the United States that no warrant or
court order is required by law, that all statutory requirements have
been met, and that the specified assistance is required, setting forth
the period of time during which the provision... is authorized... No
provider of wire or electronic communication... shall disclose the
existence of any interception or surveillance or the device used to
accomplish the interception or surveillance..."
But, Nichols added, those facts relate to classified information that
are "state secrets" and would jeopardize national security if they
were disclosed. A hearing on the Bush administration's request to
dismiss the case on national security grounds has been scheduled for
June 23.
For its part, AT&T has remained silent about the extent of its alleged
participation in the NSA surveillance scheme, which initially was
thought to apply only to international calls but now may encompass
records of domestic phone calls and more. Verizon and BellSouth, for
instance, took steps to distance themselves from a USA Today report
that said their call databases were opened to the NSA. But AT&T
wouldn't comment.
Marc Bien, a spokesman for AT&T, told CNET News.com on Wednesday:
"Without commenting on or confirming the existence of the program, we
can say that when the government asks for our help in protecting
national security, and the request is within the law, we will provide
that assistance."
The next tussle in this lawsuit is likely to center on how far the
"state secrets" concept can extend. Is AT&T able to divulge the text
of any certification letter, without saying exactly what information
it turned over as a result? Must the mere existence of a certification
letter remain secret?
Injecting additional complexity is 18 U.S.C. 2511's prohibition on
disclosure. It says that telecommunication companies may not "disclose
the existence of any interception or surveillance or the device used
to accomplish the interception or surveillance"--except if required by
law. Unlawful disclosures are subject to fines.
EFF claims that the existence of a letter of certification should not
be classified. Cindy Cohn, an EFF attorney, told the judge on
Wednesday that it is "not a state secret because the statute has a
whole process" governing it.
"If you have a certification, let's see it," EFF attorney Lee Tien
said in an interview after the hearing.
For his part, Berenson, the former attorney for President Bush who's
now representing AT&T, complained about allegations that his client is
violating the law. It's unfortunate that EFF "chose to use words like
'criminal tendency' and 'crimes,'" Berenson said. AT&T "is one of the
great companies of the United States. To attach those kinds of labels
is reckless at best."
Berenson's biography says he worked for Bush on the "war on terrorism"
and the USA Patriot Act. Since leaving the White House, Berenson has
written letters to Congress (click here for PDF) calling for renewal
of the Patriot Act and has co-founded a group called Citizens for the
Common Defence that advocates a "robust" view of presidential
authority. It filed, for instance, an amicus brief (click here for
PDF) before the Supreme Court in the Hamdi case arguing that a U.S.
citizen could be detained indefinitely without trial because of the
war on terror.

@_date: 2006-05-19 13:42:43
@_author: coderman 
@_subject: Diffie-Hellman Re: UK Government to force handover of 
cipher TLSv1/SSLv3 DHE-RSA-AES256-SHA, 2048 bit RSA++
i like the speed of pre-shared keys assuming key mgmt is secure and
rekeying frequent (e.g. scheduled PSK's or one time pad based
ephemeral key exchange).
but anything using ephemeral keys needs to destroy them properly and
this is more robust  with DH (each end responsible for their
respective key destruction) than shared secrets (both ends must
destroy secrets) in addition to the fact that shared secrets are
usually much longer lived as well.
i do it all the time with openvpn, https, etc.  in theory anything
that supports SSLv3/TLSv1 should support a strong ephemeral DH cipher
suite.  as for particular sites and servers, i'd be interested to know
just what the usual distribution of utilized cipher suites is.  RSA
without DHE probably is the most common.
in most cases generating dh parameters and explicitly requiring a DHE
suite is the hardest part of any custom configuration needed.  the
session setup costs are a little higher but anyone doing SSL/TLS in
bulk probably has the necessary hardware acceleration in place
as a side note, i'd really like SHA2-256/512 to be added to SSL/TLS
and widely implemented.  AES256 with SHA1 digest is just a little
funny these days...

@_date: 2006-05-19 14:37:55
@_author: coderman 
@_subject: NS&AT&T 
hah, indeed.  they even took it a step further with the new "search
across computers" feature that sucks your hard drive into this
spiderweb of mining.
i trust individuals, not corporations or governments.  you can't
expect privacy from entities you don't trust.
from Information we collect and how we use it:
Information you provide ... [ED: anything in the GET/POST of your request]
Google cookies...
Log information...
User communications...
Links... [ED: what you click on]
Information sharing:
Google only shares personal information with other companies or
individuals outside of Google in the following limited circumstances:
- We have your consent...
- We provide such information to our subsidiaries, affiliated
companies or other trusted businesses or persons...
- We have a good faith belief that access, use, preservation or
disclosure of such information is reasonably necessary to (a) satisfy
any applicable law, regulation, legal process or enforceable
governmental request...
"limited" circumstances, LOL

@_date: 2006-05-19 16:43:33
@_author: coderman 
@_subject: NS&AT&T 
depending on the context i would need to trust not only the personal
integrity/morals of the person but also technical capability and
responsibility (so that careless mistakes would not be made).
the key is the direct individual relationship that can provide trust,
rather than an amorphous and distant relationship with a large opaque
quorums are an interesting group organization that can be trusted
perhaps, and allow more collaboration / social exchange than direct
individual interactions yet avoid the diffusion of responsibility and
lack of accountability present in larger organizational structures.
that's a longer discussion and i'm not sure i could do a good job
explaining my thoughts on it yet...
reputation and trust, my favorite crux  :)
[and i thought the technical aspects were difficult! heh]

@_date: 2006-05-19 22:33:05
@_author: coderman 
@_subject: congress giving us impressive "oversight theater" 
a favorite form of theatrical presentation, second only to "liberty theater". :P
SIGINT + HUMINT - OVERSIGHT == you assuming the position and paying
for the privilege.
they're solidifying public support for these previously illegal
activities and are doing a good job of it.  they won't be illegal or
this "narrowly targeted" for long...
On the Democratic side, Sen. Ron Wyden (Ore.) tried to get a bit
tougher. He asked about an "independent check that can be verified on
these programs that the newspapers are reporting on."
Roberts jumped in, defensively. "I am independent and I asked very
tough questions," he reported. He paused to check with his staff, then
added that oversight was "very independent."
Hayden's written statement said "UNCLASSIFIED" on each page, though it
could have been labeled "UNINTERESTING" because little more than a
collection of acronyms survived the declassification process.
"As director of NSA, I was the national SIGINT manager," he said. "I
would use this important new authority, the national HUMINT manager,
to enhance the standards of tradecraft."
Critics may say that the SSCI -- that's the Senate Select Committee on
Intelligence -- is AWOL these days when it comes to oversight. But,
FYI, no one would doubt these guys are A-OK with their ABCs.

@_date: 2006-05-20 10:57:32
@_author: coderman 
@_subject: Fwd: There's A Support Group Out There For Any Fetish - 
fucking hilarious; my side hurts...
---selective-cut--- (author using gmail so i assume no expectation of
privacy against forwarding)
  From: demonfighter at gmail.com (Steve Furlong)
  Subject: Re: [Clips] There's A Support Group Out There For Any Fetish
  > BE IT BEARSKIN RUGS OR PONYTAILS, THERE'S A SUPPORT GROUP OUT THERE FOR ANY
  > FETISH
  I have a compulsion to swap rips of Hollywood movies with my terrorist
  as we plot how to overthrow the government (any government), funding
  ourselves with money laundered from our off-shore gambling web site and
  internet drug sales. We also laugh at the efforts of the fedz to crack the
  encrypted files with our kiddie porn snuff videos, even as we launch a DDoS
  against the White House's web site from our zombie farm.* The Cypherpunks
  mailing list used to be my support group, but with Tim May's departure we're
  left with "support" from wankers like "Tyler Durden" and "Major Variola".
  Pitiful. Where's my (government-supported) support group?, I ask.
  * Did I miss any of the Horsemen? Something seems lacking there.
* i think the only relevant omission would be a black net trade in
ultra sensitive national security secrets trickled out to journalists
for jollies and sold over seas for fortunes in a callous erosion of
the security of this great nation and its freedom loving citizens...

@_date: 2006-05-20 17:55:00
@_author: coderman 
@_subject: ISPs providing "warrant canaries" 
You are further advised that Title 18, U.S C , Section
2709(c), prohibits any officer, employee or agent of yours from
disclosing to any person that the FBI has sought or obtained
access to information or records under these provisions.

@_date: 2006-05-22 06:05:02
@_author: coderman 
@_subject: words of wisdom from a happy yellow circle 
worth watching for the audio, amusing for the technical production:
'The Great Dictator - "read" by the Wal-Mart smiley face'
'...  Wal-Mart is embroiled in a legal dispute over the smiley face
image which it wants to trademark in the US. For the first time, the
smiley face speaks!'
text of the speech:
"I'm sorry, but I don't want to be an emperor. That's not my business.
I don't want to rule or conquer anyone. I should like to help everyone
- if possible - Jew, Gentile - black man - white. We all want to help
one another. Human beings are like that. We want to live by each
other's happiness - not by each other's misery. We don't want to hate
and despise one another. In this world there is room for everyone. And
the good earth is rich and can provide for everyone. The way of life
can be free and beautiful, but we have lost the way. Greed has
poisoned men's souls, has barricaded the world with hate, has
goose-stepped us into misery and bloodshed. We have developed speed,
but we have shut ourselves in. Machinery that gives abundance has left
us in want. Our knowledge has made us cynical. Our cleverness, hard
and unkind. We think too much and feel too little. More than machinery
we need humanity. More than cleverness we need kindness and
gentleness. Without these qualities, life will be violent and all will
be lost....
"The aeroplane and the radio have brought us closer together. The very
nature of these inventions cries out for the goodness in men - cries
out for universal brotherhood - for the unity of us all. Even now my
voice is reaching millions throughout the world - millions of
despairing men, women, and little children - victims of a system that
makes men torture and imprison innocent people. To those who can hear
me, I say - do not despair. The misery that is now upon us is but the
passing of greed - the bitterness of men who fear the way of human
progress. The hate of men will pass, and dictators die, and the power
they took from the people will return to the people. And so long as
men die, liberty will never perish. .....
"Soldiers! don't give yourselves to brutes - men who despise you -
enslave you - who regiment your lives - tell you what to do - what to
think and what to feel! Who drill you - diet you - treat you like
cattle, use you as cannon fodder. Don't give yourselves to these
unnatural men - machine men with machine minds and machine hearts! You
are not machines! You are not cattle! You are men! You have the love
of humanity in your hearts! You don't hate! Only the unloved hate -
the unloved and the unnatural! Soldiers! Don't fight for slavery!
Fight for liberty! In the 17th Chapter of St Luke it is written: "the
Kingdom of God is within man" - not one man nor a group of men, but in
all men! In you! You, the people have the power - the power to create
machines. The power to create happiness! You, the people, have the
power to make this life free and beautiful, to make this life a
wonderful adventure. Then - in the name of democracy - let us use that
power - let us all unite. Let us fight for a new world - a decent
world that will give men a chance to work - that will give youth a
future and old age a security. By the promise of these things, brutes
have risen to power. But they lie! They do not fulfil that promise.
They never will! Dictators free themselves but they enslave the
people! Now let us fight to fulfil that promise! Let us fight to free
the world - to do away with national barriers - to do away with greed,
with hate and intolerance. Let us fight for a world of reason, a world
where science and progress will lead to all men's happiness. Soldiers!
in the name of democracy, let us all unite!"

@_date: 2006-05-22 10:57:27
@_author: coderman 
@_subject: peertech quorum public offset 0000000 / janus wireless dc14 
peertech quorum public: janus wireless dc14 challenge: taking 5x longer than expected but making progress...
feedback on temporal key binding appreciated.  more to come in the
next week or so.
Peertech Quorum
18-may-2006 , offset 0000000
alias: public.peertech.org 	70.104.254.121
10.10.10.10 172.16.13.77 192.168.1.242
  About Us
"Experience should teach us to be most on our guard to protect liberty
when the Government's purposes are beneficent. Men born to freedom are
naturally alert to repel invasion of their liberty by evil minded
rulers. The greatest dangers to liberty lurk in insidious encroachment
by men of zeal, well meaning but without understanding." ~ Justice
Louis Brandeis
We believe in personal and social responsibility. We write code to
empower individuals and develop community.
Do not misuse this software to facilitate or conceal harm against
others; these efforts are given to you freely and in good faith.
Recent developments and other news can be found in the peertech status
log.   Quorum communication and development is explained in the
peertech quorum introduction.
  Current Quorum Key
Using digital keys and signatures for the inexperienced.
    * peertech.pubkey.txt
SHA2-512 digest of current peertech.pubkey.txt at offset 0000000:
B533C5F6 C306C60D 9723CC0D 6298692F F207160B 4DE29A09 30A752F2 8B03906D
41B0B080 C07B3FFF D53A6B8D 4FA1D33D E35483E7 DC7733BE 32F3D08F 815A5502
---peertech.pubkey.txt for offset 0000000---
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: GnuPG v1.4.3rc2 (GNU/Linux)
-----END PGP PUBLIC KEY BLOCK-----

@_date: 2006-05-22 15:56:29
@_author: coderman 
@_subject: it's like a cypherpunk christmas 
so is DoJ going to bite?
tap'd dat ass!
"A security consultant working with a major telecommunications carrier
told me that his client set up a top-secret high-speed circuit between
its main computer complex and Quantico, Virginia, the site of a
government-intelligence computer center. This link provided direct
access to the carrier's network corethe critical area of its system,
where all its data are stored. "What the companies are doing is worse
than turning over records," the consultant said. "They're providing
total access to all the data."
i'm on the wrong end of this gang bang...
  (bizweek has issues atm...)
"    The Departments of Justice, State, and Homeland Security spend
millions annually to buy commercial databases that track Americans'
finances, phone numbers, and biographical information, according to a
report last month by the U.S. Government Accountability Office, the
investigative arm of Congress. Often, the agencies and their
contractors don't ensure the data's accuracy, the GAO found.
    Buying commercially collected data allows the government to dodge
certain privacy rules. The Privacy Act of 1974 restricts how federal
agencies may use such information and requires disclosure of what the
government is doing with it. But the law applies only when the
government is doing the data collecting."
and sprint was sucking lucre from that SIGINT teat:  (i'm shocked, shocked! :)
'''Sprint Nextel Corp. is the latest phone company to be sued for
possibly giving call records to the government. ...
"Sprint Nextel continues to be dedicated in protecting the privacy of
our customers' communications," Gunasegaram said. "We comply fully
with lawful processes."
He declined to comment further when asked whether Sprint had been
approached by the National Security Agency or provided any customer
calling records to government officials.'''
still basking in the CHB afterglow of "fuck you. strong letter to follow":
"Attorney General Alberto Gonzales says the Bush administration may
prosecute New York Times reporters who wrote about the NSA's spying on
Americans, which means Bush can break the law by ordering the spying
but he wants to prosecute reporters who caught him breaking the law."
ahhh... i need a smoke.

@_date: 2006-05-23 15:23:57
@_author: coderman 
@_subject: [gnu@toad.com: May 24: National Day of Outrage at NSA/Telco 
i'd like to pass off previous legitimate criticisms on the lack of
pervasive and popular crypto by claiming usability flaws as the
culprit.  but encouraging the public is surely some part of this
how about handing out bootable CD's chock full of usable crypto
goodness[1] to all those sign waving agitators so they might exercise
a little personal responsibility for securing their privacy in
addition to the masturbatory mob unity displays seeking redress and
retraction from large, distant organizational structures who give two
shits about that catchy slogan wielded impotently on ceder stick as if
it were Excalibur itself expecting imminent victory over all of the
world's ills...
1. an updated image with zPhone integrated would be nice; perhaps
something i'll poke at in the near future unless someone else does it
first.  privacy knoppix needs a rebirth :)

@_date: 2006-05-23 15:27:33
@_author: coderman 
@_subject: [gnu@toad.com: May 24: National Day of Outrage at NSA/Telco 
On 5/23/06, a long string of amusing commentary on political theory
and the relative merits of working within a broken system to mitigate
abuses versus subverting that system entirely columinated in hilarious
epithets and criticism including:
you guys crack me the fuck up. :P

@_date: 2006-05-23 16:41:15
@_author: coderman 
@_subject: behavioral patterns, honey tokens, and baiting TLA's 
regarding previous discussion about baiting TLA's and resource
consumption attacks / honey tokens this article is relevant:
"It's not just about who calls who. The NSA phone-monitoring project
looks at how terrorists place their calls  and then applies that
model to everyone, to see who else might be a suspect. It's a form of
predictive data mining made famous by the notorious Total Information
Awareness project...
Today, we learn why everyone's calls had to be in the target set. The
NSA wasn't just conducting social network analysis. It was using a
more controversial data mining technique, dragged into the popular
imagination by Darpa's Total Information Awareness project, which
focuses on prediction, not connections.
Under this approach, sophisticated algorithms hunt for patterns of
terrorist behavior in information-trails, and then apply those
patterns to average citizens, seeing which ones fit. It doesn't matter
who you know. It's what you do that gets you in trouble. If you spend
money and buy plane tickets like Mohammed Atta did, then maybe you're
a terrorist, too. Same goes for the kind, and frequency, of phone
calls you make."
so, if you really felt like poking the bear, the task is simple: act
like a terrorist!
google news alerts will give you the necessary "terrorist behaviors"
that get the desired attention.  these activities range from paying
down significant credit card debt to researching critical information,
transportation, and power distribution infrastructure.
if anyone decides to try this i'd love to hear the tale of your
interrogation and/or temporary incarceration... *grin*

@_date: 2006-05-24 12:49:53
@_author: coderman 
@_subject: export bullshit and "thought crime" munitions... 
i categorically deny any government the authority to prevent me from
distributing strong encryption, in source or compiled, to anyone
it's time this bullshit was called out as obsolete and fully ineffective.
(if you don't feel the same you should avoid redistributing yourself.
i however refuse to play these stupid games or insist on foreign
development outside these restrictions.)
"""Although the US has ended most of their export controls for crypto
software, there are still some reasonable export controls in place,
namely, to prevent the software from being exported to a few embargoed
nations, such as North Korea, Iran, Libya, Syria, and Sudan. And for
commercial encryption software that you actually pay for (not this
free public beta), there are now requirements to check customers
against government watch lists as well, which is something that
companies such as PGP comply with these days. PGP Corp volunteered to
host the public beta software on their server, with all the
appropriate checks in place. That's why you have to register, to make
sure you are not in an embargoed country, to keep me in compliance
with U.S. export laws. Been there, done that. -Philip Zimmermann"""
Re:Misplaced paranoia ... on Monday May 22,  (
"""The purpose of the law of course, is not to prevent the export of
encryption to forgein countries. They already have these algorithims.
Nor is it to prevent access to the terrorist boegyman. They either
don't use it, or can easily get access to encryption.
No. The purpose of the law is to hang the sword of damocles over the
head of anyone who wants to bring safe and secure communication to the
masses. The government doesn't want the masses to encrypt their
traffic, and they use this law to impede the distrobution of your
software and others like it.
I think you need to give up the ghost here. If your government wants
to shut you down. they will, regardless of how much you try to comply
with export restrictions it will never be good enough. I think you
need to stop playing by rules where you can't possibly win and simply
go all out in an effort to get as many people using zfone as possible.
All out. Unrestricted downloads, ease of use, ad campaign, browser
plugins, whatever. Just do anything to get as many people using
encrypted VOIP as you possibly can, because until then, your software
will remain one the fringe where it's easier to shut down."""

@_date: 2006-05-27 18:07:38
@_author: coderman 
@_subject: SETEC ASTRONOMY 
"It's the most powerful privilege the government has. It's the nuclear
option. It never fails." - William Weaver, senior adviser to the
National Security Whistleblowers Coalition.
The State Secrets Privilege: Selected Case Files
            "Use of the state secrets privilege in courts has grown
significantly over the last twenty-five years. In the twenty-three
years between the decision in Reynolds [1953] and the election of
Jimmy Carter, in 1976, there were four reported cases in which the
government invoked the privilege. Between 1977 and 2001, there were a
total of fifty-one reported cases in which courts ruled on invocation
of the privilege. Because reported cases only represent a fraction of
the total cases in which the privilege is invoked or implicated, it is
unclear precisely how dramatically the use of the privilege has grown.
But the increase in reported cases is indicative of greater
willingness to assert the privilege than in the past." ...

@_date: 2006-05-28 21:51:43
@_author: coderman 
@_subject: [sandyinchina@gmail.com: Status of opportunistic 
opportunistic IPsec requires:
- additional latency during initial communication (sometimes excessive
waiting for timeouts)
- static public IP endpoint capable of IPsec
- keys published in DNS records
== totally unworkable for most users on the Internet.
SSH/SSL VPN's are much more suitable IMHO.  tied into a p2p style
NAT-punching configuration with simple key management (perhaps
opportunistic key exchange that can be upgraded to authenticated
exchange in person, etc) this _might_ be enough to blacken a majority
of Internet traffic.
OE via IPsec is certainly not though...
Wireless networks are a different story, and I am very much in favor
of IPsec for such networks.  The propinquity of participants can
facilitate other stronger / easier key management as well.

@_date: 2006-05-31 11:17:39
@_author: coderman 
@_subject: internet browsing privacy appliance 
we've got a proof of concept build of an internet privacy appliance
for windows users built at:
there are some known issues / deficiencies in this release:
- DNS leaks due to transparent proxy. transparent DNS proxy when in
anonymous mode is in progress (using tor-resolve and a python DNS
- http traffic is identified by outgoing port (80, 8080, etc) rather
than traffic type. L7 matching is also in the works.
- https (SSL/TLS) traffic is passed through and not proxied.
- this runtime has not been hardened against malicious peers on the
same internal network and chroot's and other techniques are not yet
we're trying to work out logistics for torrent seeding before
distributing the build tools to remaster your own vmware installers
and customize the privacy appliance.  we're working on fixing known
issues and anticipate a
how it works in a nutshell:
- start the vmware instance with 128M ram and 200M disk (image is 38M
- a public SMB share is provided with a Run.BAT install script
- script installs a MS PPTP VPN connection to forward all traffic
through the appliance
- privacy (privoxy) and anonymity (tor) is enabled by default.  you
can select privacy only for a faster browsing experience with ads and
popups filtered.
a note on auto updates:
remove the /etc/janus directory to prevent the automatic update check.
 we intend to use this to deploy security critical patches, filtering
updates to privoxy, and other maintenance.  you can apply these
changes by hand or disable them completely as desired.

@_date: 2006-11-26 22:37:06
@_author: coderman 
@_subject: Mixmaster? 
nah, that only means the masses won't be coding their own anonymity
and privacy systems, which is a good thing (the masses would fuck it
up with impressive ROT13  style).
this also means that the developers who can scratch this itch (a
usable, secure, and windows application) are going to be fewer and far
between.  don't fret, it only takes one to code it and then all your
seething masses can steep themselves in the hedonistic pleasures of
anonymity and privacy in their familiar environments.
and last but not least, regarding RAH's virtuous invitation to sling a
little logic yourself:
bitching on a mailing list about the platform specific deficiencies of
anonymity/privacy software is not likely to conjure up one of these
"usable, secure, windows capable" developers anxious to pleasure your
impatient expectations of convenience.  teaching yourself how to build
secure privacy systems [0][1] so you can meet these wants with your
own effort is more likely to result in the outcome you seek.
with that colorful retort out of the way, you are absolutely correct
about the usability and integration aspects of a given system
affecting penetration in target user base and the actual security
provided [2].
as was mentioned earlier, a virtual machine to host a well tested,
robust installation of unix'y network intensive applications on
windows is a compromise that often keeps both parties happy.  there
really is no good answer if you have to rely on the windows TCP stack
under load, especially for non server flavors of windows (that is,
even overlapped i/o will run into problems: about ~4,000 sockets last
time i tested on xp pro).
we used this virtual machine approach in janusvm [3], and tried to
focus on good usability via two methods:
a.) trimming the install process down as simple as possible (could be
better. vmware requested we cease distribution of the combined
janusvm+player+one-click-installer due to their licensing terms on the
player distribution)
b.) performing all of the anonymous Tor proxy of traffic transparently
at the network level using a default PPTP VPN route through the
virtual machine.
the user feedback has been positive, since this obviates the need for
error prone and tedious application specific configuration to use Tor,
and avoids leaking information when a plug-in or scripting facility
has the ability to bypass application proxy settings or is not
resolving addresses via SOCKSv4a / MapAddr.  (not to mention that some
applications which don't even support SOCKS or HTTP proxies can now
use Tor)
"encrypted communications as a matter of course" is not yet dead.
it's just taking a little longer than anyone expected back when the
battle was raging over cipher implementations and encrypted network
protocols with nary a thought to end user experience.
best regards,
0. "Secure Programming for Linux and Unix HOWTO -- Creating Secure Software"
  1. "Anonymity bibliography"
  2. "Why Johnny Can't Encrypt: A Usability Evaluation of PGP 5.0 (1999)"
  3. JanusVM
    [yes, this dc14 release is old, but it's held up well and we will
have a new version in january. (and yes, it made it through dc14 open
wireless use without a scratch. we should have clued in the sheeps on
the wall... ;) ]

@_date: 2006-11-28 14:57:29
@_author: coderman 
@_subject: [p2p-hackers] AES CTR vs. CBC, other [was: Re: security and 
i believe the "CTR chaining" weakness mentioned above is in regards to
the use of an explicit IV in IPsec for counter mode (CTR or CM) just
like CBC mode, for per packet synchronization, even though it is not
absolutely required. [0].
as a more general note, there are indeed some nice advantages to counter mode:
 - simplicity
  - parallelizable / pipeline-able
 - random access
  - lack of random IV's (generating entropy is hard and slow unless
you have a physical source).
and some drawbacks / constraints:
  - leaks plaintext size without padding (other modes just leak size
in terms of blocks)
 - vulnerable to time memory trade off attacks [1]
  - failure to prevent keystream reuse is catastrophic [2]
 - a strong message authentication code (MAC) must always be used [2]
as a side note, it is common to include entropy in the initial counter
value (64 bits of entropy + 64 bit counter) to avoid the time memory
trade off weaknesses.
using a random IV (like CTR in IPsec specifies) adds some overhead,
but avoids the time memory trade off as well as ensuring no keystream
reuse.  hardware entropy sources are great for this purpose since
entropy gathering daemons are notoriously slow.
best regards,
0. "a lengthy analysis of counter mode and ESP"
  1. M.E. Hellman, A cryptanalytic time-memory trade-off
  IEEE Transactions on Information Theory, July, 1980, pp. 401-406.
2. "Stream cipher attack"

@_date: 2006-11-29 11:43:03
@_author: coderman 
@_subject: Mixmaster? 
bootstrapping is hard, particularly when you must include a robust
reputation metric.  "anonymous digital gold tokens" is really too
narrow, as what you seek is exactly a robust reputation / trust metric
tied to the economy of peer interaction.  digital cash is attractive
because the reputation it embodies is fungible, but other forms of
reputation are useful and may prove more effective in certain
contexts, particularly when your adversary is well funded (think
"creeping death attacks"). [0]
oh, if it were so simple!  payment alone is not sufficient, this
[dark|anonymous|private]net requires robust reputation and usability
too.  payment is part of that equation, but other incentives to
participate and contribute must be addressed.  remember mojonation /
mnet? [1]
heheh, it's going to be a fun ride.  this also points to the
"incentive" for big government to crush with extreme prejudice any
such crypto-anarcho-capitalist digital economies.  a robust and
private economy of that sort would be popular, efficient, and a clear
threat to fiat money control.  decentralized, robust reputation
metrics capable of defending against such adversaries are difficult,
to put it mildly.
i wish i could have been there; sounds like an interesting talk.
there is a lot more i'd like to discuss regarding digital bearer
settlement, blinded digital cash, reputation metrics, and incentives
for privacy preserving networks and services, but i'll have to save
that for later, as the incentive of continued employment has overcome
the incentive for enjoyable and enlightening conversation... ;)
0. "Reliable MIX Cascade Networks through Reputation"
  1. "Mnet"

@_date: 2006-10-24 14:30:53
@_author: coderman 
@_subject: Mixmaster? 
shitty stacks are a common reason for networked applications,
particularly on non-server variants of windows that are intentionally
crippled for "revenue optimization" in redmond:
my suggestion is to use a virtual machine.  you could copy a
statically linked mixmaster to any number of existing virtual
appliances: customizing / managing virtual machines is a bit cumbersome right now
but these problems are being worked on and should address many
platform specific problems people encounter with network intensive
software like anonymous mixes / onion routers.

@_date: 2006-10-24 14:58:56
@_author: coderman 
@_subject: Post quantum reality 
the first commercial quantum computer company is launching a demo
online in mere weeks with an adiabatic qubit pool of 16 or 64 qubits,
to scale to many thousands by 2008.
this isn't gate model, but it doesn't matter. see
 for details.
so, who wants to map discrete log to max clique representation?  we
can split the processing cost as well as the profits on sale of the
verisign root...

@_date: 2006-10-25 09:40:21
@_author: coderman 
@_subject: At U.S. borders, laptops have no right to privacy. [but 
that's nice.  i'm glad i am aware of and utilize something called
"full disk encryption".  you may have heard of it, and wanted some,
but most of it sucks and is far to expensive or cumbersome to use. [1]
AES-256 behind two (n?) factor auth and they can take my disks and
probe until the (32bit) time_t overflow, enjoy.
my mitigation is now a broadband line and a few hours of distraction
to "re cache" my new laptop/hdd. [2]
that's the beauty of full disk crypto: no worries about physical
theft/loss, physical data recovery on platters, trojans compromising
your boot sequence or key mgmt tools and rootkit'ing / sniffing your
secrets. [3]
ah, much better...
"beg your pardon, you need my what for the laptop to clear inspection? ...
heheh, you're an amusing individual.  can i have my laptop back or
will you keep it out of spite?"
1. is 2007 the year of full disk encryption?  we should start an
anonymous betting pool backed by pre-paid visa / e-gold accounts tied
to fictitious identities... (at least, before they
legislate/strong-arm pre-paid phones, credit cards, and other privacy
preserving financial/communication services into the ether via the
convenient shock-fear-prod's of child pr0n and terrorism)
2. this assumes you also regularly perform full and incremental
backups, and verify / test archive / backup integrity prior to finding
out you actually don't have another copy of the data that just walked
out the door and became pure entropy in this lost context...
3. assuming it is designed, implemented, and usable enough to be
secure against these threats without leaving important information
perilously vulnerable to exploits or catastrophic failure.  this is a
hard problem (tm) :)

@_date: 2006-10-25 11:47:26
@_author: coderman 
@_subject: AZ State Atty General seizing wire transfers over $500 
of 11,000 cash grabs, only 100 of the intended undesirables were
impeded?  this kind of "success" makes the cognitive dissonator
fortunately your friendly pre-paid visa gift card merchant lets you
route that <$500 currency bundle for a $2 service charge (in many
locations, at least) with a friendly fungibility hard to match.
freedom isn't a $1.05, it's actually $2 even. [1]
1.

@_date: 2007-12-01 17:33:54
@_author: coderman 
@_subject: D-Wave Slides from SC07 progress in quantum computing panel 
click on Mr. T for the power point file.  (hah!)
i love the prominent featuring of Google partnership on this project.
surely Google / In-Q-Tel dollars will surge through the floodgates of
measured skepticism shortly...
some highlights:
D-Wave approach: Superconducting adiabatic quantum computer
- Extremely fast: Special purpose processor; superconducting
electronics are naturally fast (700+ GHz)
- Extremely low power: In principle reversible (zero heat generation);
in practice power consumption & heat generation drastically reduced
(factors of millions)
- At the limits of physics: Universal quantum computer can't do better
slides 14-21 are nice visualizations of the adiabatic QC implementation and use.
adiabatic quantum computation model:
- Computer initialized in "easy to reach" (convex) ground state
- Answer encoded in final state
- All currents adjusted slowly enough so that system remains in ground
state at all times
- AQC can be universal for QC  [ed: this is the crux, algorithms to
express some problems in AQC model difficult (right now)]
- AQC is exact by definition
quantum annealing computation model:
- Computer initialized in ground state
- Answer encoded in final state
- All currents adjusted over period of time fixed by user [ed: key
difference wrt AQC]
- QA is a heuristic algorithm [ed: key difference wrt AQC]
D-Wave processors can implement either AQC or QA models of computation.
Summary of preliminary result
- A set of progressively more powerful superconducting quantum
processors have been built  [ed: 28 qubits in demo]
- Next generation Q3/2008 targets competition with incumbent QUBO
solver methods (500+ qubits)
- Web services architecture operational at several levels of
abstraction from hardware; APIs documented and available

@_date: 2007-12-08 16:16:37
@_author: coderman 
@_subject: toad.com In World's First 100 .com Domains 
the sheer amount of losses racked up as part of calculated risk /
business strategy is amazing to me.  i remember sprint getting mad
about the price they were paying for their OC12/48 MPLS/SONET/ATM/IP
switches.  they hired hundreds to begin work on a switch in house, and
sunk $200+ million to make it look like a believable effort.
in october the vendor relented on price, and hundreds of consultants
got the ax before thanksgiving, within days of the newly negotiated
pricing.  all of that code, design, effort tossed into the rubbish
bin, having served its purpose as calculated ruse.
activities like this and other canceled projects are plentiful in the industry.
so much code and engineering locked away into IP asset vaults, never
to be seen or used again...  jeezus.

@_date: 2007-02-01 03:53:04
@_author: coderman 
@_subject: new janusvm for 31-january-2007 
26M (26653291) bytes
SHA1: dfa29620c8d14110d8507dfcb395a80326ee7b1b
SHA2-256: 0B062B02739E34020510CE41650B338AF695686DBA9DAD9FC667E4AF8EC6DA60
fixes and improvements over the previous dc14 version.  build sources
and documentation to be available this weekend.  (sorry, crazy

@_date: 2007-02-06 19:15:25
@_author: coderman 
@_subject: Partial List of IP Blocks Used by US "Terrorist Surveillance 
via The following partial list of IP blocks are routinely used by the US
government entities (supported by private contractors) to gain access
to, to monitor, and in some cases, to destroy IT networks. Such
activity is related to the US "Terrorist Surveillance Program." Most
of the registrants of the blocks listed below are not aware of these
activities. Concerned network admins should examine traffic logs
closely. A correlation of traffic from several of these IP blocks
likely indicates that a network is under surveillance or has had
access attempted by the US intelligence community and affiliated
83.27.0.0 - 83.27.255.255
170.86.0.0 - 170.86.255.255
62.212.234.128 - 62.212.234.255
81.57.102.0 - 81.57.103.255
201.5.0.0 - 201.5.255.255
213.151.160.0 - 213.151.191.255
70.83.15.0 - 70.83.15.255
166.128.0.0 - 166.255.255.255
60.64.0.0 - 60.159.255.255
142.191.0.0 - 142.191.255.255
83.65.121.32 - 83.65.121.39
12.108.2.0 - 12.108.3.255
65.128.0.0 - 65.159.255.255
24.158.208.0 - 24.158.223.255
86.97.64.0 - 86.97.95.255
201.239.128.0 - 201.239.255.255
68.36.0.0 - 68.36.255.255
70.44.0.0 - 70.44.255.255
64.231.200.0 - 64.231.203.255
189.128.0.0 - 189.255.255.255
216.155.192.0 - 216.155.207.255
121.6.0.0 - 121.7.255.255
71.96.0.0 - 71.127.255.255
190.213.196.0 - 190.213.196.255
80.72.230.0 - 80.72.230.255
58.29.0.0 - 58.29.255.255
121.128.0.0 - 121.191.255.255
88.191.3.0 - 88.191.248.255
58.72.0.0 - 58.79.255.255
70.16.0.0 - 70.23.255.255
200.57.192.0 - 200.57.255.255
201.5.0.0 - 201.5.255.255
124.168.0.0 - 124.168.255.255
211.200.0.0 - 211.205.255.255
78.252.0.0 - 78.252.255.255
59.0.0.0 - 59.31.255.255
72.64.0.0 - 72.95.255.255
211.200.0.0 - 211.205.255.255
145.53.0.0 - 145.53.255.255
71.200.0.0 - 71.200.127.255
60.206.0.0 - 60.207.255.255
194.178.125.48 - 194.178.125.55
98.226.0.0 - 98.226.255.255
201.88.0.0 - 201.88.255.255
205.209.128.0 - 205.209.191.255
51.0.0.0 - 51.255.255.255
70.64.0.0 - 70.79.255.255
70.112.0.0 - 70.127.255.255
202.84.96.0 - 202.84.127.255
70.32.0.0 - 70.32.31.255
207.218.192.0 - 207.218.255.255
69.31.88.0 - 69.31.89.255
198.74.0.0 - 198.74.255.255
221.0.0.0 - 221.3.127.255
72.144.0.0 - 72.159.255.255
220.96.0.0 - 220.99.255.255
82.88.0.0 - 82.91.255.255
216.128.73.0 - 216.128.73.255
and in cidr format for easy matching:

@_date: 2007-02-07 00:39:47
@_author: coderman 
@_subject: Partial List of IP Blocks Used by US "Terrorist 
presumably the utility of these endpoints will taper off quickly
toward almost nothing, so historical more than current utility... :)

@_date: 2007-02-15 09:49:26
@_author: coderman 
@_subject: [dave@farber.net: [IP] New Short Video: "Is Your Cell Phone 
good stuff.
predominantly the following are the best give away, and seem to apply
to some models and not others:
[via "A well designed bug program could try to minimize the obviousness of
this by quickly dropping the bug call if the phone owner tried to make
an outgoing call, or drop the bug connection if an incoming call tried
to ring through. But if the bug is up and running, that's the only
transmission path that is available on the phone at that time for the
vast majority of currently deployed cell phones."
this is undetectable on some models, and causes a few seconds of "one
way conference" style problems on others.  basically, you answer/call,
and get silence, neither party can hear each other for a few seconds.
"But if your battery seems to be running out of juice far too early
(despite what the phone's battery status display might claim), that
might be an indication that your phone is being used to transmit
behind your back (though a worn out battery or inaccurate battery
status display could also be the culprits).
Another clue that a phone may have been transmitting without your
permission is if it seems unexpectedly warm. You've probably noticed
how most cell phones heat up, especially on longer calls. This is
normal, but if you haven't been on any calls for a while and your cell
phone is warm as if long calls were in progress, you have another red
flag indication of something odd perhaps going on."
this is a good indicator, and particularly on some phones with
excellent battery life (some sanyo/motorola models) it becomes real
obvious when unusual battery drain is occurring.
"Finally, if you use a GSM phone (like the vast majority of phones
around the world, including Cingular and T-Mobile in the U.S.) you
have a virtually foolproof way to know if you phone is secretly
transmitting in voice mode. You've probably noticed the "buzzing"
interference that these phones tend to make in nearby speakers when
calls or data transmissions are in progress. A certain amount of
periodic routine communications between cell phones and the networks
will occur while the phones are powered on -- even when calls are not
in progress -- so short bursts of buzzing between calls (and when
turning the phones on or off) are normal.
But if you're not on a call, and you hear a continuing rapid
buzz-buzz-buzz in nearby speakers that lasts more than a few seconds
and gets louder as you approach with your phone, well, the odds are
that your phone is busily transmitting, and bugging is a definite
possibility. Note that this particular test is much less reliable with
non-GSM phones that use CDMA (e.g. Sprint/Verizon phones), since
CDMA's technology is less prone to producing easily audible local
interference. This strongly suggests that CDMA phones may be preferred
for such bugging operations."
this is a smoking gun on a GSM phone, and unfortunately it does not
work against CDMA, as mentioned.
take the battery out, it works great. :)

@_date: 2007-02-16 10:41:53
@_author: coderman 
@_subject: Reverse Rendition? Hey John Young... 
don't know about all 31 individuals, but a nice list and detail here:

@_date: 2007-02-19 10:27:59
@_author: coderman 
@_subject: Confirming Random numbers? 
remote or not doesn't add much to the difficulty of the question: "is
it _truly_ random?"
lots of statistical tests to confirm that a given distribution of bits
IS NOT, but nothing to prove IT IS.  and by IS NOT, i mean
sufficiently improbable to be random, thus considered not random.
even a true hw rng could throw all bits set given enough chances.
it's easy for a remote peer to fool such statistical tests: check the
output of AES-CBC keyed with all zeros.  there is almost no actual
entropy (in the keys) yet the output appears to be random, and you
would (in theory) not be able to distinguish without the key used.
if you look at the various hw rng daemons they often to some FIPS
sanity checks on the input but leave it at that.  the idea is that
failed hardware will start producing FIPS failures and can be

@_date: 2007-02-19 21:04:51
@_author: coderman 
@_subject: inverted virtue 
i never knew Eric O'Neill got a taste of the craft and wisely
departed; breach was an entertaining reminder of the "most criminal
worldwide institution".  perhaps, like the proverbial frog in a pot,
the lucre of lies and power is subtle and sweet, betraying the
bitterness beneath gradients of incremental compromise.
    Cryptome: There are no ex-spies or ex-spy agents: All remain
forever active and lie about being ex as they lie about what they did
and continue to do. There is no exit from spyworld only variations of
I read this in cryptome today and it makes me puzzled: did somebody
piss you off? Or is this the a nugget of distilled wisdom from
somebody else?
Cryptome: Spies and ex-spies are required by terms of employment and
training to lie, deceive, betray, commit crimes, and keep it secret.
If they cannot convincingly lie and break laws without getting caught
under all kinds of conditions as taught and tested in the US at the
Farm, they will not be hired. They lie to families and friends, to
everybody not in spyworld and often in spyworld too as a test and as a
duty. They are experts at appearing to be what they are not.
It is a common spy tradecraft to claim to be an ex-spy or ex-agent,
aggrieved, ready to spill secrets, their managers feigning offense,
blessing the spew by invoking national security threats, pretending
the miscreant is a rogue.
No spy or ex-spy ever tells the full story, only offers enticing tales
that mesmerize the gullible and attempts to outwit accomplished
doubters, whether other spies, agents, journalists, oversight
committees, investigative commissions or the public. None are ever
free to tell all they know, and face severe penalties if not death for
telling more selected secrets than allowed to lend credence to their
deceptions. So come the orchestrated dissenters, scholars, novelists,
confessors, professors, exposers of perfidy and anonymous leakers,
dispensing plausible disinformation purpose-made.
That's the deal spies and agents sign on to and cannot ever escape,
and are told so at the time of engagement, not that many want out of
the privileges such as that provided by the bountifully bloated US
Intelligence Community Management Fund which bribes sealed lips, most
assuredly for retirees and exes continuing to work their undercover
Anybody who claims to be a spy or ex-spy is a person unable to tell
the truth, and gets paid and pensioned for well-crafted accounts of
what is not, what to fear, what to doubt, who to distrust. Analyze the
Association For Intelligence Officers (AFIO),  and
numerous similar organizations around the planet for what they tell
and what they conceal in open deception.
The pervasive lies of spyworld -- officers, agents, contractors and
overseers -- undermine and corrupt culture, language, trust, law and
government. It is the most criminal worldwide institution of the time.

@_date: 2007-02-20 17:22:19
@_author: coderman 
@_subject: private credential/ecash thread on slashdot (Re: announce: 
there are some good replies, just need more moderation from the clue-full :)
indeed.  there was one insightful response to the unlinkability
aspect, and that is the inevitable venality of the credential
authorities.  perhaps i'm just overly cynical, but without a
trustworthy and secure CA the privacy assurances provided by such
credentials are fairly limited.  (and as detailed elsewhere, for most
uses the CA's won't issue to anonymous entities)
still, much better than what we've got now...
p.s. the lending protection aspect of credentials is dark comedy.
encode something into a credential that alice would never want to
share, credit card  bank access details, etc.  lol

@_date: 2007-02-21 14:54:25
@_author: coderman 
@_subject: New digital bearer cash site launched (was Re: money mixes) 
interesting indeed!
   How can I trust you that your currency is really worth anything and
not backed by hot air?
   Well, you can't. The only way to trust us is to give us a try. Use
our system with COW, get a very small amount of GG. Talk with us on
the channel. Over time you will see that we honour our promises and
that you can get your gold back. That way we will gain favour in your
eyes.  Sooner or later we will also add an auditing process for our
physical resources. Check on our site as information becomes
solving the reputation problem will be much harder.  it will be
interesting to see how this plays out...
a few things which make me cautious to trust their reputation:
"There are however a few external proxies that make our service
available to a bigger public. Those proxies are not sponsored by us
nor are they under our control."
 ^- bad idea.
it's Tor, not TOR.  (ok, a nit pick, but something anyone familiar
with Tor would know...)
lack of detail regarding authority and authorization to access funds
(physical and digital) by the three anonymous individuals.  is this a
quorum system, preventing a single rogue from wreaking havoc?  is an
escrow mechanism in place to recover from untimely death or
incarceration of an individual?  etc.
otherwise, i love it.  here's to hoping it goes somewhere!
 /me departs to code some COW wrangling logic...

@_date: 2007-02-21 16:00:57
@_author: coderman 
@_subject: eCache officer anonymity 
anyone want to wager on the ability of the eCache three to remain
anonymous?  leakage above the network layer has always been
one of the three is a little too distinct...

@_date: 2007-02-21 16:36:34
@_author: coderman 
@_subject: eCache officer anonymity 
digest of nonce+name
the trusted third parties to eCache acting as auditors and references
shouldn't cheat.  although i suppose reputation should always be a
factor in such trust metrics :P

@_date: 2007-02-26 13:56:21
@_author: coderman 
@_subject: new torpark 
torrify.com released a long awaited update to torpark:
they've also posted source, though i haven't looked at the content:
"runs fast and looks nice"

@_date: 2007-01-05 02:50:28
@_author: coderman 
@_subject: [*gasp*: Bush quietly gives himself power to open our 
i love the exclamation points in title.  makes for a wide grin on the
faces of those fatigued with constitutional destruction overload.
ah, outrage and disbelief...  seems like ages ago i could muster such
reaction to the abuse of powers that be.
In July 1987, then-Representative Dick Cheney, the top Republican on
the committee investigating the Iran-contra scandal, turned on his
hearing room microphone and delivered, in his characteristically
measured tone, a revolutionary claim...
"I personally do not believe the Boland Amendment applied to the
president, nor to his immediate staff," Cheney said.
Most of Cheney's colleagues did not share his vision of a presidency
empowered to bypass US laws governing foreign policy. The committee
issued a scathing, bipartisan report accusing White House officials of
"disdain for the law."
Cheney refused to sign it. Instead, he commissioned his own report
declaring that the real lawbreakers were his fellow lawmakers, because
the Constitution "does not permit Congress to pass a law usurping
Presidential power."
The Iran-contra scandal was not the first time the future vice
president articulated a philosophy of unfettered executive power --
nor would it be the last. The Constitution empowers Congress to pass
laws regulating the executive branch, but over the course of his
career, Cheney came to believe that the modern world is too dangerous
and complex for a president's hands to be tied. He embraced a belief
that presidents have vast "inherent" powers, not spelled out in the
Constitution, that allow them to defy Congress.
Cheney bypassed acts of Congress as defense secretary in the first
Bush administration. And his office has been the driving force behind
the current administration's hoarding of secrets, its efforts to
impose greater political control over career officials, and its
defiance of a law requiring the government to obtain warrants when
wiretapping Americans. Cheney's staff has also been behind President
Bush's record number of signing statements asserting his right to
disregard laws.
source:

@_date: 2007-01-11 03:33:26
@_author: coderman 
@_subject: wikileaks and what the fucks 
so i'm a little late to the drama party [0], but enjoying the
entertainment none the less.
a few things are particularly amusing, including the email header, no
doubt sailing across a multitude of narus taps in plaintext, forever
tying the WL alias to it's intended subject,
This is a restricted internal development mailinglist for
Please do not mention that word directly in these discussions; refer
instead to 'WL'.
as well as a dollar figure behind the psyphon scam, US $3,000,000
dollars, no doubt rationally allocated to posturing and vaporware
rather than extending existing best of class solutions. (Tor needs
help, in case people haven't noticed :)
so much talk of security, social network analysis, urgent privacy [1],
and not a single link to SNA avoiding Tor/i2p routing?  i'm not one to
harsh on the merits of a nice session layer, but when it clearly
addresses only half of the stated equation, the implications are not
positive. (to be fair, the wikileaks faq and links remedy this [2])
there is lots of talk of super architecture, "WikiLeaks integrates
technologies including modified versions of FreeNet, Tor, PGP and
software of our own design." [3] but very little details.  a freenet
and Tor combo would seem to accentuate the deficiencies of each, but
perhaps my ignorance is overly jaded.  i hope an infrastructure
entrusted with critical privacy will display the necessary
transparency required for reasonable trust when launched.
some interesting bits are also found within, with this judicial
position making me wonder when they'll come no-knocking for cable
plats and transit schedules:
"""Although existing authorities do not directly address the subject,
it appears that reasonable restrictions upon the possession and
dissemination of catastrophically dangerous information can be
constitutionally implemented," suggests Stewart Harris of the
Appalachian School of Law. See "Restrictions are justifiable,"
National Law Journal, December 11, 2006.
(one day you may need a license for intelligence and autonomy! now
take your pills and report to your cube...)
and nothing makes me chuckle like some fiat ethics:
"1. Ethics. We favour, and uphold, ethical behaviour in all circumstances."
(a good example, like Ellsberg/pentagon papers mentioned in detail
later, is a much better representation of the ethical reasoning
did they take up your suggestion, JYA?
"""If fleecing the CIA is the purpose, I urge setting a much higher
funding goal, in the $100M range and up."""
keep "losing it", John.  may your age related dementia continue for
many score... *grin*
0. WikiLeaks
      1. riseup security overview and measures
      2. WikiLeaks Links (heheh, sorry, i need sleep. but try and say it out
loud, i dare you!)
      [i2p, pgp, privoxy, freenet, gnupg, Tor]
3. WikiLeaks FAQ
   99. someone inevitably wonders why i'm geeking out on privacy from a
gmail account.  lest you question my sanity (it's eroded in different
dimensions), i have no expectation of privacy from plaintext nor
hosted service.  Tor is a minimum best effort, and in reality it takes
more skill and effort than most have at their disposal (for now).  so
i tentatively concur with this advice, unless you know enough and are
skilled enough to know your known unknowns and your unknown unknowns
(ah, such wisdom, rummy!):
"""The Internet is a spying machine and no use of it free of
surveillance is possible due to the system's design to allow
continuous monitoring by service providers, website operators,
security peddlers and government communications regulators across and
up and down the transmission stream. Hazards planted in users' boxes
are the least threat compared to the Internet's inherent capability of
siphoning and archiving data at multiples points without users'
knowledge or control. Any website privacy policy which promises
protection is a lie, same for any communications or government
-

@_date: 2007-01-19 16:56:34
@_author: coderman 
@_subject: 16 qubits, 42 couplers 
We have fixed the dates for the demo of our Orion quantum computing
system. We are going to hold two events, one at the Computer History
Museum in Mountain View, California on February 13th, and the second
at the Telus World of Science in Vancouver, Canada on February 15th...
Here is an optical picture of the processor we'll be using for the
demo. This particular circuit contains 16 qubits (the quasi-circular
loops arranged in a 4W4 array). Each of the qubits is coupled to its
nearest neighbors (N, S, E, W) and next-nearest neighbors (NW, NE, SW,
SE) via a tunable flux transformer, giving a total of 42 of these
 use ECC!  it's more efficient and more secure!  really!
some interesting presentations at:

@_date: 2007-01-22 02:09:14
@_author: coderman 
@_subject: cracking DES in 2007 ? Followup question RE: digital cable 
not quickly...
exhaustive search in 9 days for < $10,000 is pretty good.  you'll
solve twice as fast on average.  :)
see  for details.
maybe! *grin*
(in practice there are a dozen easier ways to get the same
signal/picture with much less effort)

@_date: 2007-01-24 13:30:16
@_author: coderman 
@_subject: Tor incentives 
[Ed: if we're taking bets, i'm guessing usability/simplicity for
operating an exit (3.1) are 80% of the battle.]
Tor Incentives Design Brainstorms
1. Goals: what do we want to achieve with an incentive scheme?
1.1. Encourage users to provide good relay service (throughput, latency).
1.2. Encourage users to allow traffic to exit the Tor network from
     their node.

@_date: 2007-06-13 10:45:17
@_author: coderman 
@_subject: [IP] EFF: Secret Surveillance Evidence Unsealed in AT&T 
right.  tap all the interesting fibers, feed to narus.
the narus is there specifically so they don't have to backhaul a
mirror of the traffic.  it does all the inspection to isolate
interesting information, then sends back that interesting information
to aggregation points, before that in turn is sent on to NSA.
the bridgeton center att noc is a good example.  there is a room
controlled by multi-factor biometric authentication (print, retinal)
with man trap doors.  this is probably the room used for distributing
configuration to the remote monitoring points (it's unlikely they
store much of interest at the remote sites, since the security is much
lower at these places) as well as aggregation of the feeds for
backhaul to NSA.
see also the new NSA facilities being built in denver, CO.  this is an
ideal place to aggregate traffic across the country...
from the sounds of it, the taps did introduce some problems which were
resolved quickly.  probably not from signal loss, but who knows.
in any case, i don't think powering an optical amplifier is difficult
in the facilities in question.  for transoceanic cables it becomes a
bigger problem  :)
best regards,

@_date: 2007-06-14 08:34:58
@_author: coderman 
@_subject: [IP] EFF: Secret Surveillance Evidence Unsealed in AT&T 
s/stupid/expensive/ :)
passive optical networking is used, so you get cost advantages of a
point to multi-point last mile distribution architecture.  you can
still easily achieve OC3 to each endpoint, so bandwidth per customer
is of little concern...
if an ATM switch isn't a real router, then sure!

@_date: 2007-06-14 10:51:11
@_author: coderman 
@_subject: [IP] EFF: Secret Surveillance Evidence Unsealed in AT&T 
you gotta love fast asic's for this kind of stuff.  cloudstream also
has success with the fpga approach.  (there's a grad paper somewhere
that describes a 10GigE inspection setup using fpga's and capable of
~100-600 snort style rules per chip.  more rules == linear scale.
would be fun to try L7, which does make things more difficult...)
what makes you say this?  i'd be surprised if the control channel is
pulled from the monitored flows.  you need bi directional transport,
for control and backhaul, among other reasons.
maybe we'll find out when congress/judiciary orders the devices
removed?  *cough*

@_date: 2007-06-22 14:07:00
@_author: coderman 
@_subject: AES broken? 
We describe a new simple but more power-
ful form of linear cryptanalysis. It appears to break AES
(and undoubtably other cryptosystems too, e.g. SKIP-
JACK). The break is "nonconstructive," i.e. we make it
plausible (e.g. prove it in certain approximate probabilis-
tic models) that a small algorithm for quickly determining
AES-256 keys from plaintext-ciphertext pairs exists b but
without constructing the algorithm. The attack's runtime
is comparable to performing 64w encryptions where w is
the (unknown) minimum Hamming weight in certain bi-
nary linear error-correcting codes (BLECCs) associated
with AES-256. If w < 43 then our attack is faster than ex-
haustive key search; probably w < 10. (Also there should
be ciphertext-only attacks if the plaintext is natural En-
AES's current status. In view of both (a) Bernstein's tim-
ing attack, (b) our nonconstructive argument for a cracking
algorithm, (c) the possibility of a "'trapdoor," we believe that
   1. AES should be abandoned
   2. cryptosystems provably immune to these attacks should
      be investigated, and
   3. our argument for crack-existence, since it is nonrigor-
      ous5 , should be investigated more carefully.
3.6    Now get paranoid
Suppose AES-256's designers had evilly arranged matters so
that some "code of the code" (known to them) unexpectedly,
contained a remarkably low-weight word (known to them),
with say, w 10. That would constitute a trapdoor enabling
cracking it with much smaller eo,ort 64w . If w = 10, they
could crack AES with 6410 = 260 pc-pairs. If w = 7 then
AES-256 would be as easy to crack as the cited attacks on
DES (only 242 pc-pairs needed)!
This could be the case even if the random codes approxima-
tion underlying our crude analysis in B'3.3 was invalid.
4 What now?
Obviously, B'2's strengthened form of linear cryptanalysis will
attack a wide variety of secret key cryptosystems, not just
AES-256, and will quite often raise the worry that there might
exist some intentionally or unintentionally inserted "trap-
door." I currently see no feasible way for AES's designers
to disprove the existence of this kind of trapdoor. And Bern-
stein's cache-timing attack [4] seems applicable against es-
sentially any system that employs Sboxes. That's a lot of
In short, almost every secret key cryptosystem yet proposed is
now busted or at least suspect. We need to design new kinds
of cryptosystems immune to both kinds of attack.

@_date: 2007-06-23 20:39:31
@_author: coderman 
@_subject: AES broken? 
was it chapter "3.6  Now get paranoid" ?
i'll point out that many interesting advances / attacks against
anonymity systems have come from information theory viewpoints.
ciphers and protocols tend to arise from the crypto side.
however, the practical applicability of the methods described may be
near impossible to achieve...
Perry E. Metzger: "The consensus from a few of my friends is that this paper (by
Warren Smith) is a bit eccentrically written but not obviously
flawed. Whether it is of any practical importance at all remains to be
seen -- there may be no way to apply the results."
 via  at metzdowd.com/msg07672.html

@_date: 2007-03-05 03:15:59
@_author: coderman 
@_subject: Consumer-Mass-Product Grade Laptop (with above average 
on the other end of the spectrum consider:
-> VIA C7 (w/Padlock RNGx2, AES, SHA, MontMult, NX) Everex StepNote
[0] 15.4" Widescreen Laptop
(for posterity, $398 refurb. / $468 retail)
add a Sony MicroVault USM-H [1] usb fob for your (physical & disk :)
key ring for loop-aes pass phrase protected storage with minimal
... of course, getting a nice bsd/linux full disk crypted os
provisioned is still annoying in nearly every distribution.  in this
sense, a rayservers service fee may be quite fiscally responsible
given your individual skills with software.  :)
0. 12W StepNote 1500 , 5.3lbs
      (note that poor battery specs are due to small 3 cell used, not
power consumption of the hardware)
1. USM-H 1.5g / 14.5x 2.7 x 30.0 mm in 256 MB, 512MB, 1GB , 2GB
   99. 'Software Ciphers Suck!'  :P

@_date: 2007-03-05 10:04:20
@_author: coderman 
@_subject: sometimes data spills in your favor... 
... Imagine a government agency, in a bureaucratic foul-up,
accidentally gives you a copy of a document marked "top secret." And
it contains a log of some of your private phone calls.
You read it and ponder it and wonder what it all means. Then, two
months later, the FBI shows up at your door, demands the document back
and orders you to forget you ever saw it.
... al-Buthi and Al-Haramain's American branch were added to the
government's public list of terrorists on Sept. 9, 2004, just weeks
after the government turned over the call log to the charity's
attorneys. It's not clear when officials realized they'd given a
highly classified document to an organization they considered
terrorist, but the FBI showed up at Belew's office in October and
demanded the call log back, advising the lawyer not to attempt to
remember the document's contents.
By then, Belew had given a copy of the document to Washington Post
reporter David Ottaway, who had been writing about how the government
investigated and listed individuals and groups suspected of funding
terrorism. Ottaway did not report on the classified call log, and when
the FBI called, the Post dutifully handed over its copy.
That might have been the end of it. But in December 2005 The New York
Times revealed that the government had been spying on Americans'
overseas communications without warrants, and Al-Haramain's lawyers
realized why the FBI had been so adamant about getting the document
"I got up in the morning and read the story, and I thought, 'My god,
we had a log of a wiretap and it may or may not have been the NSA and
on further reflection it was NSA," says Thomas Nelson, who represents
Al-Haramain and Belew. "So we decided to file a lawsuit."

@_date: 2007-03-07 02:59:24
@_author: coderman 
@_subject: Consumer-Mass-Product Grade Laptop (with above average 
agreed.  full disk crypto with a tamper resistant pre-boot auth/loader
is the only way to go... :)
absolutely.  i did a poor job pointing this out in my original post
when i mentioned how much almost every distro out there sucks in the
respect.  good key management and an easy pre-installed FDE setup
(with VMs!  and even dual boot, etc!) is hard and well worth the cost
of paying someone skilled at such things to do it for you...
most of the distro builds of openssl, openssh, entropy daemon (if
present), and other tools don't currently take advantage of padlock
acceleration.  this is one element that would be nice to see more
collaboration on implementation (in any camp, bsd, linux, etc)
my friend got his nc1500 today from a thurs morning order.  it runs
ubuntu edgy with a modified kernel and tools (see below) including
loop-aes and padlock accel for fde, ipsec, openssl, openssh, openvpn,
and entropy daemon for hw_random to /dev/random processing.
best regards,
the below part: if you'd like to help seed the c5/c7 dev tarball and
iso torrents (and same for janusvm dev torrents with some new features
to test) send me an email for early seeding of the torrents.  thanks!

@_date: 2007-05-28 03:36:05
@_author: coderman 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
hi Steven; an enjoyable read.  thank you!
i am curious about a few aspects.
you state "an assumption that the global passive adversary is
unrealistic".  is this really true in anonymity research circles?  it
seems the evidence to the contrary is well supported.  i do prefer the
"those who are the target of such adversaries have larger problems
than anonymous Internet access" statement instead.  :)
i am also curious if you had considered lower layer propinquity of
physical paths.  critical infrastructure research has shown how even
seemingly disparate and redundant paths are often inhabiting common
right of way and facilities.  is the assumption that inspection at
OC/WDM layers is too cumbersome/expensive for all but the previously
mentioned TLA/$gov adversaries?
given the surprises looking at network topology from an IX rather than
AS level, i'd expect a similar revelation when viewing from an optical
carrier vantage point.
sadly, the information useful for such study has become a subject of
heated and irrational censorship post 9/11.  i'll stop this tangent
early before i delve into a heated rant about critical infrastructure
and terrorism madness... *g*
best regards,

@_date: 2007-05-28 03:47:22
@_author: coderman 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
one more comment that ties into your mention PCIe bus limitations.
previous research on monitoring high speeds links has shown FPGA
devices well suited for header and deep packet inspect at line rates
up to 10GigE for hundreds of snort style  filter rules. this approach
scales in a linear fashion.
i'll try to find some of the papers on this subject; i don't have them
on hand.  coincidentally, many of those involved in such projects seem
to get sucked into the proprietary/classified commercial and
government sectors. *grin*
it's turtles, all the way down...

@_date: 2007-05-28 03:53:30
@_author: coderman 
@_subject: Fwd: Sampled Traffic Analysis by Internet-Exchange-Level 
Some of you might remember my email to this list in February, where I
asked for help from operators of Tor nodes in the UK [1]. This was for
an experiment to establish how diverse the topology of the Tor network
is -- an important component of how secure it is against traffic
analysis. Thanks to all those who responded to my request; I had a
great response and very interesting results.
I've now finished the draft version of the resulting paper, which is
to be presented at the PET Workshop (Ottawa, Canada, June 20--22 2007)
[2]. The latest version of the paper can be found at this URL:
 There is also an introduction to the area, and a summary of the paper
on my research group's blog "Light Blue Touchpaper":
 My paper, co-authored with Piotr Zielinksi, is a follow-up to Nick
Feamster and Roger Dingledine's paper, "Location Diversity in
Anonymity Networks" [3]. In it, they point out that bouncing anonymity
network traffic around lots of countries might not be as good as it
seems because there are a small number of ISPs which show up on many
of the links to, from and between Tor nodes.
What our paper explores is that even if you deal with this problem,
and choose paths with a diverse collection of ISPs, there are still
Internet exchanges on many of the paths. These do not appear in the
BGP data that Feamster and Dingledine use, which is why I had to
resort to a more limited-scale traceroute-based study.
So not only are Internet Exchanges good places to put traffic analysis
equipment, but some (including LINX [4] and AMS-IX [5]) collect the
necessary data anyway, for performance measurement purposes. They only
record the headers of one in every few thousand packets, but our paper
also shows that, even with such low-quality data, traffic analysis
still works.
There's certainly no reason to panic about these results, as there is
still much more work to be done in this area. For example, the picture
in the US, where Internet exchanges are less popular, will likely be
different. I do hope that the paper will encourage future work on both
establishing more accurate estimates of attack costs and developing
[1] [2] [3] [4] [5] w: [demime 1.01d removed an attachment of type application/pgp-signature]

@_date: 2007-05-30 10:44:59
@_author: coderman 
@_subject: Bandwith donation for some days ? 
if there is anyone with a VIA C7 system they could use there i would
love to assist with a padlock accelerated openssl/Tor node.  i do not
have a link where i can test myself, and this would be a useful
opportunity to see how much crypto offload improves throughput.
i've listed raw openssl stats in a previous message to this list,
along with a link to a patch that combines the MONTMULT acceleration
for RSA/DSA with the patches for AES/SHA offload via padlock dynamic
[my expectation is that zlib compression of traffic will become the
new bottle neck, as crypto overhead drops off.  i am very interested
to see a real world test though...]
best regards,

@_date: 2007-09-21 04:19:34
@_author: coderman 
@_subject: cpunks downtime 
the exit wall of sheep (embassy passwds) was lame but the control port
opener was nifty.
sequence for the control port payload injection:
- two vectors for form payload, a third for ip leakage across three
proxies on broadband
- javascript posts form automatically to localhost:9051 using:
 action=" method="post"
enctype="multipart/form-data" target="stylearea"  [that last to keep
the response from the tor control part spewing over the current page -
this puts it in a hidden iframe]
- all existing <FORM's in exit requests modified via proxies to inject
the TEXTAREA with payload into a hidden form element while leaving the
appearance of a legitimate form page (so any submit pwns, too late.
even lynx on openbsd if your control port is on 127.0.0.1:9051 (or any
accessible port if you've got a motivated attacker...))
- IP leakage for all IE on win32 users that aren't using a transparent
proxy (janusvm) via SMB/NetBIOS and WebDAV to external host with
tracking nonce directory name.  even if the control port is not open,
this will leak the origin of the request as webdav is below the
browser, interpreted in the file system / win32 api context. (SMB is
not nearly as useful as webdav since most ISPs filter NetBIOS and
SMB/CIFS traffic even if you explicitly allow at the router.)
- the purpose of the payload was an interesting 150-200k+ command set
for the control port to apply.  among various things this performed
the following:
- redirect the notice log to /dev/null on *nix like systems or to a
webdav path on one of the proxies. (this leaks ip immediately on win32
in addition to routing ongoing notices messages to the proxy directly.
- invalidate all known authentic nodes on the existing Tor network via
ExcludeNodes with digests, configure three new rogue nodes as
authoritative directories and exits, and finally starting a hidden
service and posting the .onion name to the proxy server.
- map local ports to the hidden service onion allowing an anonymous
user on the rogue Tor network to arbitrarily connect to the client
onion and interface with their Tor control port in real time.
- vulnerable Tor clients (not using transparent proxy like janusvm)
start falling by the thousands into the rogue Tor network for the
duration of a few hours while the attack was being tested...
of course, vmware just got their asses handed to them recently as well:
qemu/virtual box looks much more promising; perhaps supported soon...

@_date: 2007-09-23 05:28:07
@_author: coderman 
@_subject: cpunks downtime 
months?  i recall a day, two tops?  perhaps your endpoints is getting
differentiated services...  *cough*
the exit sniffing was lame, that's what you call it.  in addition to
no surprise for the clued.  sadly, all the big sites out there are in
the same pot of hot water with their wireless hotspot users...  they
aren't even trying to fix it.
best regards,

@_date: 2008-04-16 20:38:44
@_author: coderman 
@_subject: Codebreaker Makes $2.8B in a Year 
and next year (or maybe the one after that, or ... you get the idea)
 ... he blows up.  viva las vegas!
not nearly as much as the fed or congress.  NSA has big ears for spear
fishing the shiny little targets; when you have the power to shift the
foundation upon which the market(s) sit, you don't even need to aim
that blunt force trauma instrument.
reserve currency status can't buffer the sheer magnitude of fiat
spewing forth in debt and circulation...
nassim taleb has an informative explanation.  for every james simons
there are two bear stearns.
financial cryptography is only as useful as the monies it moves.
fickle fiat fads are fools gold in any shape or suit.
best regards,

@_date: 2008-08-16 11:18:49
@_author: coderman 
@_subject: A Quantum Adiabatic Algorithm for Factorization and Its 
"     We propose an adiabatic quantum algorithm capable of factorizing
numbers, using fewer qubits than Shor's algorithm. We implement the
algorithm in an NMR quantum information processor and experimentally
factorize the number 21. Numerical simulations indicate that the
running time grows only quadratically with the number of qubits. "
in related news, d-wave iteratively testing bigger and bigger chips:
too bad the canary in the coal mine has been deprecated (
 )

@_date: 2008-02-09 21:02:38
@_author: coderman 
@_subject: Toshiba tips random-number generator IC, is disingenuous 
i've been using the VIA padlock XSTORE instruction for entropy since
at least 2003, back when the C5XL hit the stage and you had a single
source (a combination of three free wheeling oscillators).
the next revision, the C5P, and all C5/C7 cores since than have
included two of these sources, individually selectable or capable of
working in tandem. (6 oscillators)
the throughput of these devices varies from 200k-2Mbps in a most
paranoid configuration, with whitener enabled and a conservative
sampling, up to more than 100Mbps in dual full throttle configuration
(which should only be used when the on die AES or SHA1 is applied to
obscure TRNG bias).
Toshiba Corp. has claimed a major breakthrough in the field of
security technology: It has devised the world's highest-performance
physical random-number generator (RNG) circuit.
The device generates random numbers at a data rate of 2.0 megabits a
second, according to Toshiba in a paper presented at the International
Solid-State Circuits Conference (ISSCC) here.
i must assume they are splitting hairs here, as VIA is not the only
one to outperform such benchmarks, but you do buy the whole chip, not
a stand-alone TRNG IC component.
in any case, it is amusing that they got such mileage from a
masturbatory press release, while things like padlock, integrating
crypto directly into CPU instructions, seems to garner less respect
and press.
last but not least, i recently purchased an Everex 15.4" StepNote
NC1610 Laptop PC w/ Via C7-M Processor [0].  spend the $30 to bring
this up to 2G of ram, and you've got an excellent little linux laptop
that can handle full disk crypto with ease (i've even benchmarked
loop-aes with 32 rounds in AES-256, just for fun, which the XCRYPT
instruction handles without breaking a sweat).
if you're concerned about all that border search stupidity, and tired
of software FDE or cryptainer compromises, this is a great
i've long been a fan of these cores, and i think any cypherpunk would
appreciate the capability these tiny, low power chips posses in terms
of crypto horsepower.
[i will, however, never forgive them for the abomination that is the
padlock hash engine.  why they required the SHA instruction to
finalize, limited the digest input size, and requiring an elaborate
fault to get an un-finalized state, is beyond me.  however, the rest
of the chip makes of up such a shortcoming, all things considered]
best regards,
0. $448.00 - Everex 15.4" StepNote NC1610 Laptop PC w/ Via C7-M Processor

@_date: 2008-02-25 03:06:23
@_author: coderman 
@_subject: How long can you go with an expired key? 
the usability is poor, compared to things like off the record [0] and
opportunistic keying, etc.  while i use encrypted mail daily in a
professional context, i never use it in a personal one.  sooner or
later the dinosaurs will drop it too.
it always tastes best when you cook it yourself.  (or at least, have
looked at the recipe and confirmed no cyanide or arsenic was
intentionally added *g*
[this, is my one complaint about OTR, building from source into a
useful client can be tedious compared to other methods...]
"you're being a bit brief, please go into detail"
0. oh the hoops i had to jump to import an old otr 2.x key in gaim to
otr3.0.x in pidgin.  the friends list is also an interesting study in
use and frequency of re-key; while i can no longer recall when
A59CDCB3 46468A16 27D21678 270AF0B5 0B0477CF was originally generated
others appear to cycle as frequently as weekly or so.  interesting how
the same tool can span the key management spectrum from anonymous
opportunistic to strong mutually authenticated.

@_date: 2008-02-25 05:06:37
@_author: coderman 
@_subject: How long can you go with an expired key? 
relying on an active reply / notification to you to determine "notice"
is flawed, "notice" can be passive :)
[besides, much more disconcerting than a long used key expiring, is a
fraudulent key or long deprecated key (rollback) being used, or other
such indicators more worthy of an active "heads up" response or just
extreme scrutiny...]
dead is such a relative term...  :P

@_date: 2008-02-29 15:42:56
@_author: coderman 
@_subject: How long can you go with an expired key? 
i see encrypted laptops and services fitting this bill, but i haven't
seen a ramp up of encrypted mail in this role.  perhaps i'm just not
looking in the right places.
[i didn't mean to dis encrypted mail quite as much as my previous
comments appear to in hindsight.  it certainly serves a purpose and is
used often in business.  but this is the only domain where i see it
used much at all, and even then, VPN's and SSL/TLS services are
overtaking many of the roles encrypted email used to fulfill.  just my
experience, and admittedly limited experience...]
enterprises are definitely encrypting. FDE and VPN's and SSL/TLS
services growing much more than encrypted email IMHO.  i'd be curious
to know how much of this is due to actual hacker threats, vs. data
spills and regulatory / industry standards compliance pressures.
pen registers for the intarwebs and social network analysis.  they get
most of what they want just watching those opaque bits move around...
i think encrypted torrents are the largest source of encrypted traffic
on the net.  this is purely speculation though; i'd love to see
numbers.  (encrypted torrents, easy.  encrypted mail, still too
best regards,

@_date: 2008-01-02 14:41:16
@_author: coderman 
@_subject: Your computer is too slow to handle this many creation requests! 
compression (zlib) is the Tor bottleneck on a 1.5Ghz C7.  crypto
throughput with patched openssl (dynamic padlock engine) is:
SHA-1 throughput 268,405.03kB/sec with 8k blocks
SHA2-256 throughput 263,643.08kB/sec with 8k blocks
AES-128-CBC throughput 1,029,006.84kB/sec with 8k blocks  -> yes, 8Gbs of AES!
AES-256-CBC throughput 779,103.35kB/sec with 8k blocks
[ montmult accel via openssl 0.9.9 bn_mont_mult via-mont.pl asm optimization ]
rsa 1024 394.1 sign/sec, 8710.6 verify/sec
rsa 2048 84.0 sign/sec, 2973.4 verify/sec
rsa 4096 14.2 sign/sec, 866.8 verify/sec
dsa 1024 1024.0 sign/sec, 852.5 verify/sec
dsa 2048 349.2 sign/sec, 294.6 verify/sec
hardware entropy throughput is 50kB/sec to 8+MB/sec depending on
XSTORE instruction and user space entropy daemon configuration.
best regards,

@_date: 2008-01-11 11:07:34
@_author: coderman 
@_subject: Storm, Nugache lead dangerous new botnet barrage 
authentication of replies to special searches used in the
decentralized command and control.  the botnet is basically being
partitioned up into distinct sets for resale or other purpose.
the previous design did not allow for such segmentation of C&C.

@_date: 2008-01-17 14:39:54
@_author: coderman 
@_subject: Storm, Nugache lead dangerous new botnet barrage 
it's actually not that difficult to tamper with (dht's are fragile
against coordinated malicious attackers, etc).  such a tampering is
pretty indiscriminate against the entire ring / overlay though, so no
one is anxious to try it :)

@_date: 2008-01-24 15:03:37
@_author: coderman 
@_subject: visions of drummers 
The team also added some DNA segments to the genome to serve as
"watermarks," allowing scientists to distinguish the synthetic genome
from the natural one.
That raises new possibilities of using microbes as a method of
communication. Dr. Venter said the watermarks contain coded messages.
Sleuths will have to determine the amino acid sequence coded for by
the watermarks, in order to decipher the message. "It's a fun thing
that has a practical application," he said.
i await the paper, "low latency signalling via coded influenza medium:
bandwidth estimates and congestion avoidance"

@_date: 2008-01-26 13:26:58
@_author: coderman 
@_subject: visions of drummers 
it was a proposal for encoding into a seed population coupled with
interbreeding a large group over 14 years to ensure propagation
indefinitely (of at least some of it). [0]
a bidirectional communication protocol via infectious vector is much more fun ;P
best regards,
0. DESIGNS FOR THE NEXT MILLENNIUM - Jaron Lanier

@_date: 2008-07-03 06:32:34
@_author: coderman 
@_subject: netsukuku 
getting closer ...
funny, one of my gmail ads for this thread is "Run SNORT up to 10 Gbps".
maybe one day opportunistic encryption won't suck.  that day is not today.
best regards,

@_date: 2008-07-20 22:42:01
@_author: coderman 
@_subject: Report: The End of the Internet Is Near.. 
there is no shortage of wild tales surrounding this debacle, it seems...
there was no telecom password(s) to steal, since the city was the
telceom.  they purchase "conditioned" fiber along existing right of
way and run everything from the fiber switches up to the IP routers.
(where "conditioned" means they get a cost break for non-commercial
use of fiber infrastructure).

@_date: 2008-11-25 10:59:57
@_author: coderman 
@_subject: 1.7 GBit/s RNG by laser feedback 
it is useful to whiten and/or mask any potential bias of the entropy
source with a run through a cipher or digest.  it's important to note
that you should be verifying entropy before this step (FIPS sanity
checks) otherwise your RNG could be highly biased and you'd not notice
from the whitened, masked output.
there are two schools of hardware entropy harvesting thought:
- use a von Neumann whitener to distill the raw entropy into a high
quality, low (single bit) bias source. this will also cut throughput
by an order of magnitude, perhaps.
- use a block cipher or digest to mask any bias that may be present in
an un-whitened, wide open source.
the latter seems to be gaining popularity, and of course it doesn't
hurt to do both.
this is indeed not a huge leap over VIA padlock's dual on core sources
(XSTORE) which also have AES on core for the masking above - these can
hit 100Mbps with whitening disabled and both sources enabled.  if
you're initializing FDE drives with good entropy this 1.7Gbps might be
useful.  otherwise i have a hard time consuming even a fraction of the
available entropy on a VIA system in normal use.
best regards,

@_date: 2008-11-25 14:09:05
@_author: coderman 
@_subject: 1.7 GBit/s RNG by laser feedback 
i was focused on the whitened vs. raw entropy in the previous post and
overlooked the point you were getting at.
it is good practice to use more than one hardware entropy source in a
system.  (on VIA's boards, only the first gen C5XL cores had a single
source, after that two are always present).
if one fails you have a backup and combined they can double
throughput.  if your requirements necessitate a high throughput
hardware (true) entropy source you can't fall back on software and
host entropy scavenging - it's just too slow. so you get two or more
sources and expect at least one to be functional for the lifetime of
the system.
there doesn't seem to be any additional technical detail about this
setup so perhaps we'll find out more later...
best regards,

@_date: 2008-10-11 01:49:47
@_author: coderman 
@_subject: Codebreaker Makes $2.8B in a Year 
well, it didn't even take that long:
" The current turmoil will likely lead to consolidation of the
industry, with experts predicting the death of more than 1,100 funds
this year. The ones that remain are likely to be mega funds with
stronger balance sheets and the best fund managers. But the scale of
the shake-up is reflected in the fact that even the largest players
with over US$30 billion each in assets are wobbling.
Examples include ... Renaissance Technologies, with a nearly 15 per
cent decline... "
(James H. Simons == Renaissance Technologies)

@_date: 2009-04-06 13:26:57
@_author: coderman 
@_subject: TOR encryption 
not sure what you mean. Tor uses encryption to provide anonymity for
TCP streams over a 3+ hop Tor circuit with authentication and privacy
between each relay (onion layer).
what you do with this TCP stream is your business. if the suggested
HTTPS/SSL/TLS over TCP is not available you may be forced to send
things in plaintext.
if it is in plain text the exit node can tamper with the data, just
like someone injecting on a wireless network, and many other
nope; there's nothing to get rid of.
best regards,

@_date: 2009-04-07 09:34:36
@_author: coderman 
@_subject: TOR encryption 
correct. Tor only encrypts from itself as client out to exit node. you
must encrypt from client application to destination (end-to-end).
best regards,

@_date: 2009-08-07 17:51:49
@_author: coderman 
@_subject: cleversafe says: 3 Reasons Why Encryption is Overrated 
well, arithmetic and algebra are math :)
and still exceptions to this rule. Shor's makes RSA/DH risky but
quantum search in GF(256) is probably too hard for any current lifespan.
improved McEliece is my favorite contender for a post-quantum reality.
hardware entropy sources are plentiful and bandwidth capable...
agreed. though perhaps this just argues for more conservative designs.
the padlock engine on the host i'm writing this with can do 32 rounds
just as easily as 10 or 14.

@_date: 2009-12-02 08:08:06
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_Feds_=91Pinged=92_Sprint_GPS_Data_8_Million_Time?= 
i am more interested in the redacted details of this little snippet:
    "Our pricing schedules reveal (for just two examples) that upon
the lawful request of law enforcement we are able to [XXX two examples
redacted by USMS XXX]. In cooperation with law enforcement, we do not
release that information to the general public out of concern that a
criminal may become aware of our capabilities, see a change in his
service, correctly assume that the change was made at the lawful
request of law enforcement and alter his behavior to thwart a law
enforcement investigation."
what two examples of lawful intercept on Verizon lines would introduce
a subtle "change in service" detectable by someone paying attention?

@_date: 2009-12-06 19:45:52
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_Feds_=91Pinged=92_Sprint_GPS_Data_8_Million_Time?= 
based on the recently released
 a couple ideas include:
"surveillance cameras on utility poles" (page 14) though on page 16
the discussion seems to imply that verizon will only provide network
access to the camera placed there by LE and using verizon right of way
and "Voicemail pass code reset" would definitely be visible to a
customer. (same for sprint)

@_date: 2009-12-07 08:34:20
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_Feds_=91Pinged=92_Sprint_GPS_Data_8_Million_Time?= 
the stated need is to access voice mail that may be stored in a
customer's account prior to a tap in place. in such instances access
to existing recordings require a passcode reset so LE can access, with
the side effect of this activity becoming known to subject. (if they
assume it is LE and not some random glitch, of course :)
perhaps this info is out of date and stored messages are now easily
accessible via other mechanisms; it seems an odd constraint...

@_date: 2009-01-18 18:01:40
@_author: coderman 
@_subject: The New Paranoia: Hedge-Funders Are Bullish on Gold, Guns, 
in a collapse the only thing worth shit is food and water; you can can
find shelter with the previous two.
to the extent that shiny stuff is fungible with food and water it is
useful.  if you're really bearish a market for sustenance will not
guns and brute gangs as catalyst for fungible trade is left as an
exercise for the reader.  note that death is a perfectly acceptable
payment for either party :)
... in any case, i always preferred the bifurcated breakdown in Battle
Angel Alita for my vision of futuristic deconstruction ... *grin*
maybe this is all theatrical suggestion to encourage a bottom sooner
rather than later.  compared to savage collapse and descent into
madness, we're not quite so bad off?  think i'll buy some stock!

@_date: 2009-07-11 18:16:25
@_author: coderman 
@_subject: Liechtenstein Agrees to End Bank Secrecy on Tax Data 
you wash it good and render as little unto Caesar that which is Caesars.
but make no mistake, Caesar will get his.

@_date: 2009-07-16 17:10:04
@_author: coderman 
@_subject: Protection against TEMPEST? 
display emanations are just a small subset of emsec interest,
particularly in a networked environment.
in any case, display obfuscation based on gaze / focal tracking can be
defeated with additional effort.
(will it cost more to attack? yes. is this cost reasonable, maybe -
depends on threat model, etc, etc.)
there are similar techniques based on altering the font rendering
behavior on LCD displays and various types of hardware / software
best regards,

@_date: 2009-05-07 20:39:46
@_author: coderman 
@_subject: GPS my door? 
why is the census particularly notable as a method to find your
castle, er, den of iniquity?
commercial imaging has plenty of resolution to pick out rooms of your
home and that cell phone at the side of your body is a wide area
augmentation analogue for overkill precision...
baside, RF warfare is like cutting cables.  no one wants to go there
if they can help it!

@_date: 2009-11-23 14:34:45
@_author: coderman 
@_subject: Incentives in Networking 
why is monetary compensation required for fairness? the bittorrent
protocol with tit for tat is far from perfect but it is also the
dominant protocol on the net and encourages fairness without monetary
settlement. there are other examples.
lucre is but one of many incentives, why do you assume it is the only solution?

@_date: 2009-11-23 16:25:49
@_author: coderman 
@_subject: Incentives in Networking 
my apologies for focusing solely on the price/money angle. there is a
good post about incentives on the Tor blog that covers similar ideas
and discusses the complexities and pit falls associated:
using loom for settlement is probably too much overhead for Tor but is
aiming closer to what is needed.
my issue with money payment in particular is described in this paragraph:
"On top of that are the social implications of adding money into the
system. Nick keeps reminding me of sociological studies saying that
rewarding volunteers with t-shirts makes them feel good about their
contribution, whereas rewarding them with a small amount of cash makes
them subconsciously start to value their contribution based on the
cash you give them. So they're more likely to stop volunteering, as
they don't feel their effort is properly appreciated. More details
here[0], here[1], and here[2]. It's hard to say how right this
research is, but it seems a rough set of variables to add in if we can
avoid it."
1. 2. 3. sorry for the rash response. i too am anxious for the day when robust
incentives in Tor provide a much larger, much more capable network!
best regards,

@_date: 2009-10-17 03:26:05
@_author: coderman 
@_subject: hardware acceleration available for Tor ? On FreeBSD ? 
speeding up OpenSSL derived CTR mode with hardware acceleration is
useful. (the HardwareAccel and EngineName options above)
speeding up Tor with native hardware acceleration and chained /
repetitive CTR offload is a much bigger win. as an example the VIA
Padlock engine can do a few score MBytes/sec aes 128 with small/single
block sizes like those used when HardwareAccel is on and EngineName
padlock set. if you could utilize the maximum 16KByte rep instruction
mode directly goes well over a gigabyte / second. this is also why the
native Solaris API CTR mode gives much better performance than the
OpenSSL engine acceleration.
speeding up OpenSSL pubkey ops also helps. as of OpenSSL 0.9.9 and
1.0.x you can build OpenSSL with padlock MONTMULT acceleration. still
no dynamic engine support for pubkey ops iirc...
there will be some benefit as Tor wraps a CTR mode around
(accelerated) OpenSSL ECB mode. the problem is that this method is
limited to single blocks per call, rather than long buffers optimized
for crypto offload.
you may also get SHA acceleration. the notices log should say, for example:
[info] crypto_global_init(): Initializing OpenSSL engine support.
[info] crypto_global_init(): Initializing dynamic OpenSSL engine
"padlock" acceleration support.
[info] crypto_global_init(): Loaded dynamic OpenSSL engine "padlock".
[info] crypto_global_init(): Loaded OpenSSL hardware acceleration
engine, setting default ciphers.
[info] Using default implementation for RSA
[info] Using default implementation for DH
[info] Using default implementation for RAND
[notice] Using OpenSSL engine VIA PadLock: RNG (not used) ACE2
PHE(8192) PMM  [padlock] for SHA1
[info] Using default implementation for 3DES
[notice] Using OpenSSL engine VIA PadLock: RNG (not used) ACE2
PHE(8192) PMM  [padlock] for AES
not necessarily, per above :)
it would also be nice to have these routines native for other engines,
like padlock. however this is not a small amount of effort and no one
with time and skill has shown an interest yet. (Tor buffer allocation
alignment to 16K, inline padlock instr. calls in REP mode, and other
changes required.)
there are kernel cryptographic facilities including asm optimized and
hardware accelerated crypto primitives. these are usually not utilized
from userspace directly. there are PKCS specs for communicating with
offload devices in a concise manner, and libs of various types to
speak this to myraid hardware. perhaps a longer discussion should be
taken off list...
the T2 is core acceleration and thus higher throughput for most
purposes. the 6000 is useful as a hardened private key store service
for your less trusted OS and software to cooperate with.
Tor would need to be updated to take advantage of the new CTR mode in
the OpenSSL API calls, but then the same HardwareAccel (and AccelName)
options would provide a significant improvement over the previous
acceleration mode.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-12-01 13:35:24
@_author: coderman 
@_subject: any moment now ... 
there are a lot who do take anonymous pre-paid cards. i've been using
this method for years for servers and other services.
purchase the cards with cash or barter.
you can load up to $500 without difficulty.  you pay a $5 or so fee
per card; avoid anything that charges percentages loaded. you have a
year to use it, usually, before fees start whittling down the balance.
you can register the cards on-line with privacy preserving billing
detail. be sure to consider country/state of billing address if this
matters for your purchase. (note that Tor is not the only anonymous
option for this :)
once registered with card holder name, address, use as you would any
other Visa/MC/Amex...
(there once was a company called CoinStar. they let you feed bills
into a kiosk to load cash onto Visa plastic which it spat out right
there. you could add currency to an existing card just the same. alas,
they had to change their model due to pressures. while it is hard to
find prepaid systems this convenient and privacy empowering, they do
come round now and then. still, point-of-sale purchase is not so bad
compared to the alternatives...)

@_date: 2010-12-02 13:22:21
@_author: coderman 
@_subject: any moment now ... 
there are a lot of them; it's a $24,000,000,000+ industry after all, ...
i have not seen a privacy oriented comprehensive index of prepaid
systems. that would be useful, if anyone has seen such a thing.

@_date: 2010-12-02 13:27:41
@_author: coderman 
@_subject: any moment now ... 
if this did happen, a more interesting question is what happens to the
US citizens who are or would be providing material support to
Wikileaks. (you may not remain a US citizen, for example :)

@_date: 2010-12-23 12:44:42
@_author: coderman 
@_subject: Cypherpunks Targeted 
railing against those using "power arrogantly and non-constructively." OK by me.
yet all weak claims against leaks or anon.
  ( see also  :)
97% of that article is meandering factoids centered around flawed
argument... can't make sense of most of it.  it's a time sink.
 "First they came for Anonymous, but I didn't care because I'm not a b-tard..."

@_date: 2010-12-23 12:57:56
@_author: coderman 
@_subject: the blast shack 
wow, something about leaks leads to copious text. can anyone write on
the subject without spanning volumes?
tortured media-freak condition is apt description for the majority
coverage on the subject.
the rest, well, might as well call ARPANET cypherpunkware...
"The future is already here  it's just not evenly distributed.";
 that is to say, like 0days and ethics, the future is a perspective.
and definitely not evenly distributed ;)

@_date: 2010-12-23 15:29:02
@_author: coderman 
@_subject: Tor VM stalled at 25% 
there are still a large number of risks to your anonymity when using
things like Java, Flash, arbitrary applications with Tor, even in a
fully transparently Tor'ified VM configuration.
local DNS resolver IP disclosures and side channels, chained exploits
(accelerated VM interfaces are very risky but oh so performant...),
many, many other considerations and risks.
you need to carefully consider your risks for using such things, hence
my recommendation for the stock bundle without those risky things
unless you really know what you're doing or the risks are
exceptionally low.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-23 12:48:12
@_author: coderman 
@_subject: Markets are efficient if and only if P = NP 
correlation != causation
also, the strong-form efficiency present in such an analysis fails in
the face of biased and flawed real-world market actors. cognitive and
informational biases render such approaches masturbatory at best.
leveraging economic research interest to fund algorithmic research is
a clever approach to funding perhaps.. :)
until they blow up*. the quant meltdown brought such computational
hubris back to earth...
(Renaissance Institutional Equities Fund was down 6% at the start of
this year. and 2009 should have been a good year for a hedge!)
* nassim talib == the man
he, by the way, recognized inherent market instability as an
opportunity. the Universa fund he advises made returns of 65% to 115%
in oct 2008 via his "black swan protection protocol.

@_date: 2010-07-06 12:09:05
@_author: coderman 
@_subject: [silk] Virtual prisons: how e-maps are curtailing our 
these devices and services are voluntary. it takes me <0.5 seconds to
disable radios and leave the Wireless-GIS-BigBrother-Grid.
they sell Faraday bags for the paranoid.
low cost, high fidelity spectrum analysis can be had by any for their
own due diligence.
perhaps of more concern is the widespread apathy regarding the degree
and depth of privacy erosion by these technologies... my technical
mitigations are doing just fine, thanks.

@_date: 2010-07-06 12:15:07
@_author: coderman 
@_subject: [silk] Virtual prisons: how e-maps are curtailing our 
this is a great aspect to manipulate to your own ends. like an appeal
to authority, manufactured sensor reality provides a plethora of
vulnerable vectors against the observers, whoever they may be. (and
far to trusting, surely)

@_date: 2010-07-13 20:51:16
@_author: coderman 
@_subject: Intel to also add RNG 
Since Intel
uh, what? you realize you're comparing a very noisy but very very
small entity against the remaining core of a modern many hundred
million gate processor right?
you can certainly disable / idle the sources when not needed, but
really, left wide open all the time they're a drop in the bucket.
it is the throughput and efficiency that makes it most useful. like
the AES XCRYPT instruction in VIA Padlock cores. you may avoid a
number of cache timing and other timing based side channel attacks on
software cipher implementations using hw as well, since they often
execute one or more rounds in a handful of cycles. there are probably
other advantages.
the crypto cluefull know the value of mixing a high throughput, easily
managed entropy source with host and application true random number
facilities (/dev/random, /dev/urandom, OpenSSL random engine support,
XSTORE instruction in userspace, etc.)
the key to using a hw source properly:
1. initialize, measure, and mix the raw source(s) with a userspace
entropy daemon.
2. continuously sanity check the read data over a large byte span and
remove a hardware entropy source that is not functioning within
comfortable tolerance. FIPS does have a nice suite of checks - again,
this can't prove your source is robust, only that it doesn't suck
horribly and obviously. :)
3. run the hw random data through a block cipher or hash digest to
mask generator bias before adding to host entropy facilities with a
conservative entropy density estimate. while the VIA and other good HW
sources can produce very high density output i prefer at most an 80%
estimation on input for robust distribution into the host pool as
4. periodically save state for use with mixing initialization in step
 on next restart.
5. monitor without writing if anomalies in the hw sources arise during
operation. with VIA XSTORE on C5P or greater (not C5XL with single
source) you have two independent sources which can be enabled or
disabled as needed. on such systems you can fall back to half-rate
throughput on the good source if the other goes bad.
if you mean "raw" as in omitting all of the steps above and just
reading /dev/hwrandom then i agree. otherwise, see above. :)
i can get > 80Mbps of entropy on VIA hw entropy sources. have you ever
tried to use /dev/random on a headless server? a recently booted
workstation? for more than a few keys at a time? etc?
keep secure state, properly mixed, and even a highly biased input
would be whitened and obscured beyond utility. i'd like to see
reasoning otherwise for XSTORE sources and XCRYPT AES mixing before
conservatively mixed into properly seeded /dev/random kernel pool. if
it is too biased (OpenSSL weak keys :) then the FIPS sanity checks
will kick it out and you're denied entropy rather than compromised
it's really a shame crypto isn't standard on every DIE. although if
they do a poor job of it the annoyance outweighs the utility. the SHA
instruction on Padlock borders on unusable without hacks like
interrupting the REP mode instruction with a fault/intr. so you can
grab the un-finalized work-in-progress digest state for large
best regards,

@_date: 2010-07-14 08:34:50
@_author: coderman 
@_subject: Intel to also add RNG 
i agree completely on all of the sad realities related to the
non-existence of pervasive hw crypto facilities.
the power consumption argument is a strawman though. the VIA docs
stated a power consumption difference when XSTORE is configured and
polled frequently vs. explicitly disabled and unused. the details are
fuzzy though, and i suspect it's the rest of the pipeline around
actual use of HWRNG state and moving across cache/bus lines...
i would be curious to know the power details on any of the hw entropy
sources, if any are out there.
best regards,

@_date: 2010-03-24 10:50:33
@_author: coderman 
@_subject: [vserver] Bought an entropykey - very happy 
be actively controlled as each junction is different) is a good source of
randomness (up to megabits / sec / junction), "encrypting" it just means
masking possible low entropy. I'd prefer to see raw conditoned stream than
"encrypted" one (even web content looks high-entropy to Diehard when
i have loved the padlock engines on via cores since they hit the
market in C5XL form with a single hw generator available via XSTORE.
unlike many designs this free wheeling resource can provide a torrent
of entropy sufficient to sate even the most gregarious consumption.
as mentioned above, you need a fast user space entropy daemon sanity
checking the raw, (probably) biased stream coming from hardware but it
is still good practice to digest this entropy to obscure any potential
generator state/bias heading into the host entropy pool.
that is to say, of the two common modes for utilizing hw entropy:
a. conservatively sample from a whitened, string filtered entropy
source for a low rate of high quality output (see xstore config words)
b. ramp un-whitened, un-filtered source(s) to maximum rate and AES/SHA
mix for high throughput, high quality output while irreversibly
masking generator bias/state present in the raw source stream.
the latter is more effective in practice and capable of generation
rates > 20Mbps with full FIPS sanity checks. the former tops out
around 1Mbps or less with more transient latency spikes on read (when
successive attempts to read fail to pass whiten+strfilter). note that
padlock engine supports SHA and AES on die as well making these easy
and fast to apply to generator output.
if you are still concerned a more conservative configuration would
estimate entropy density while feeding from raw input stream and add
encrypted/digested product to the host entropy pool with the specified
entropy density estimate adjusted downward to your requirements. (most
OS'es support this)

@_date: 2010-11-15 10:19:31
@_author: coderman 
@_subject: Bitcoin And The Electronic Frontier Foundation 
the cuda cards are killing bitcoin, why bother?
   (i suppose it is an interesting footnote...)

@_date: 2010-10-26 19:04:13
@_author: coderman 
@_subject: [SOT] Is the universe a big hologram? 
it's only noise(entropy) if you don't have the key.
they still won't have the key...

@_date: 2011-08-10 02:09:16
@_author: coderman 
@_subject: Fwd: DEF CON 19 - hackers get hacked! 
F-D seems to be down,...
wonder if this is the first US "cyber weapon" turned on US citizens on US
---------- Forwarded message ----------
while most were enjoying libations or talks a very interesting event
was taking place at the conference.
we're all familiar with the hostility of WiFi and GSM networks at DEF
CON, however, this year the most hostile network on earth was not
802.11; it was CDMA and 4G!
on Friday some parts of Anon and Lulz made appearance. by early
Saturday morning a weapon was deployed.
some characteristics:
- full active MitM against CDMA and 4G connections from Rio to carriers.
- MitM positioning for remote exploitation to ring0 on Android and PC.
- fall back to userspace only or non-persistent methods when
persistent rootkit unattainable.
- many attack trees and weaponized exploits. escalation from easy pwns
up to specialized techniques and tactics until success is achieved.
- simultaneous attack across CDMA and 4G connections using full power
in these LICENSED bands.
- operated continuously (except for outages :) from early Saturday
until 8am Monday.
- designed with intent: mass exploitation, reconnaissance,
exfiltration, eavesdropping.
how to tell if you met the beast at Rio:
- did you accept an upgrade for Android, Java, or other applications? (oops)
- did you notice 3G/4G signal anomalies, including full signal yet
poor bandwidth or no link?
- did you notice your Android at full charged plugged in, but dropping
to <50% charge once unplugged?
- did you notice 4G download speeds at quarter of usual, yet uploads
over twice as fast?
- did you notice Android services that immediately respawn when
killed? (Voice Search?)
- does your Android no longer connect to USB debugging yet adbd is alive?
- does your PC have an sshd that cannot be kill -9'd?
- did your Android crash - a hard freeze, and then take a long time to
...many other indicators, but for now that's sufficient to express the point.
if you met the beast, it seemed to have a nearly perfect success rate;
your odds not good.  in fact you probably didn't even notice as it
pilfered bytes off your devices and monitored your conversations.
i have waited over six DEF CONs to meet an adversary of this skill.
i was not disappointed.
did the talks suck this year because the good stuff is under NDA?
clearly a lot of you are selling out...
to those who got pwned, i would be interested in your experiences and
 ID 9B65F087 , FP = 1029 E3E0 F22A C73D B2D6  468F 2798 76BB 9B65 F087
 gpg --keyserver pool.sks-keyservers.net --recv-keys 9B65F087
 gpg --keyserver subkeys.pgp.net --recv-keys 9B65F087
 gpg --keyserver pgp.mit.edu --recv-keys 9B65F087
to the beast operators, i hope to see you next year!
 (and get your availability deficiencies and network anomalies worked
out. kind of a shame you spent so much time and money only to have
your kit fall over again and again.  and thanks for the 0days :)
until next year,...

@_date: 2011-08-10 02:26:17
@_author: coderman 
@_subject: DEF CON 19 - hackers get hacked! 
one last interesting note:
while HTTPS/SSL was attacked, Tor was not. it continued to work and
evade the attacks, while many other avenues for secure access were
blocked or used to exploit target...

@_date: 2011-08-11 15:24:06
@_author: coderman 
@_subject: 4g hack 
ding ding we have a winner.
apparently proper key management is hard, who needs security? we've
got an FCC license for this band...

@_date: 2011-12-22 12:28:15
@_author: coderman 
@_subject: Iran GPS Spoofing and the RSA Cipher 
Since 2008 I've been working on a method to fast-factor large
semiprimes with a friend of mine (maybe I've emailed you about this in
the past). We've made several advances that are previously unknown in
the mathematics literature. We found a unique prime number sieve that
uses digital-roots and the Chinese remainder theorem (it operates in
an almost "numerological" manner and it starts at the number 7); we
found symmetries that hint at a branch-and-bound contrapositive
solution to Riemann's Zeta; etc.
Lately we've been submitting a bunch of the integer sequences that
resulted from our research to AT&T's Online Encyclopedia of Integer
Sequences:

@_date: 2011-02-05 02:46:01
@_author: coderman 
@_subject: [FoRK] Chons 
ORCHID address space is perfect for this type of thing, and there are
particular extensions well suited to this. [0][1]
this came up on the p2p-hackers list, which i can't seem to get mail
through, [3]
regarding Android in particular, sounds similar to Serval. [2]
best regards,
0. An IPv6 Prefix for Overlay Routable Cryptographic Hash Identifiers
  [*this: just substitute the cryptographic with hashed coordinates or
searchable prefixes, or both given privacy considerations.]
  [*this: combine with geo-aware addressing.]
2. Serval Project
  3. [p2p-hackers] What we should build for the Egyptian (and other) protesters
  not to any noteworthy degree. the attempts have been numerous in both
commercial and research focus.
given the number of ad-hoc routing protocols, developers capable of
understanding the merits and detriments of general approaches and
specific implementations, and certainly not least of all the
difficulty in early-adoption of such a Metcalfe utility dependent
"collaborative transport" is quite difficult.
see as for my druthers i am keenly interested in combined topologies and
overlays leveraging the distinct advantages of particular transports
together for a best effort, immediately accessible ad-hoc
infrastructure. leased circuits and dedicated fiber continued to work
in Egypt; a BGP4 peering blackout is just a small slice of the overall
communication stacks and paths.
(you can run E-Line/E-LAN over free space optics as easily as MPLS /
WDM lambdas over fiber, multi-OFDMA wide band systems can be
aggregated over polarizations and center bands, etc, etc. the
possibilities are endless. and even packet over shortwave can carry
signalling channels around the globe...)
use madwifi-ng and a mobile IPv4/IPv6 transport. for example a custom
SOCKS/HTTP/Transparent proxy to multi-homed SCTP over VPNs on virtual
station madwifi-ng capable hardware. (i've used up to 6 clients per
radio with success, and maximum 8 radios per PCI host bus.)
lots of options in this space as well. just not cheap or easy yet...

@_date: 2011-02-06 20:59:34
@_author: coderman 
@_subject: [FoRK] Chons 
this is one of many potential addressing and routing optimizations for
ad-hoc networks. for example, a dead-drop or multi-homed rendezvous
point may not care about disclosing coarse geo coords, but clients
sending to same may want much more stringent pseudonymous / anonymous
without context, this does seem counter intuitive for guerrilla comms.
(locality constrained broadcast horizons are useful as well; anonymous
wireless communication is indeed difficult; lots of problems and parts
to play with :)

@_date: 2011-02-07 14:26:12
@_author: coderman 
@_subject: US Warships jamming Lebanon Internet 
unless it's ultra-wide band with orthogonal / turbo coding. USA Navy
is annoyed they can't jam those effectively ... yet.

@_date: 2011-02-08 12:35:49
@_author: coderman 
@_subject: US Warships jamming Lebanon Internet 
the latest is same as it ever was: cheaper, easier, more effective to
end-run 'round the crypto bits and attack implementation, human
never a shortage of serious vulns there...
(at least MITRE and NSA and FIWC and everyone else are finally
admitting we all get hacked no matter the protections - just a matter
of when, how much effort, how deep, and how persistent the
on the ITAR side, haven't heard any ramblings about digital crypto
munitions. who knows when/if they'll pick up that truncheon again...
(i know they reserved the right to regulate, but has anyone made any
noise about it?)

@_date: 2011-02-11 23:28:29
@_author: coderman 
@_subject: <nettime> Glenn Greenwald: The leaked campaign to attack  
great stuff; one comment:
only partly true. were it entirely true we'd have some cypherpunk
corpses laying about...
[ to my knowledge they've only annoyed and inconvenienced with disk
imaging and impromptu interrogations... ]

@_date: 2011-01-11 12:21:13
@_author: coderman 
@_subject: BHDC11 - De-anonymizing Live CDs through Physical Memory Analysis 
does anyone know more about the methods to be discussed by Andrew Case
next week?
the memory analysis of Tor seems interesting.
(do Tor Live CDs need a new kexec target for memtest sweeps / ram
zeroisation? :)
Traditional digital forensics encompasses the examination of data from
an offline or bdeadb source such as a disk image. Since the filesystem
is intact on these images, a number of forensics techniques are
available for analysis such as file and metadata examination,
timelining, deleted file recovery, indexing, and searching. Live CDs
present a large problem for this forensics model though as they run
solely in RAM and do not interact with the local disk. This removes
the ability to perform an orderly examination since the filesystem is
no longer readily available and putting random pages of data into
context can be very difficult for in-depth investigations. In order to
solve this problem, we present a number of techniques that allow for
complete recovery of a live CDbs in-memory filesystem and partial
recovery of its previously deleted contents. We also present memory
analysis of the popular Tor application as it is used by a number of
live CDs in an attempt to keep network communications encrypted and
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-01-20 09:10:23
@_author: coderman 
@_subject: Alleged Wikileaks Use of P2P to Siphon Documents 
in the past i've used p2p networks along with traditional search
engines to locate documents of interest. in particular, PDF and DOC
formats, especially related to "Confidential Information" and court
i won't go into details, but suffice to say this is very effective if
pursued as a consistent strategy over a modest time period. ("it only
takes one...").  and if they've used "redaction" to white-on-white the
sensitive bits it's even easier to pull out the high value details
within.  preaching to the choir here,
i was more interested in critical infrastructure at the time, rather
than political or other cruft. yet the principal is the same for WL or

@_date: 2011-01-20 13:29:25
@_author: coderman 
@_subject: Alleged Wikileaks Use of P2P to Siphon Documents 
what is implied, which i should have stated clearly:
the less popular extensions and mime types (PDF, DOC, XLS, ODT, etc.)
are easy to match and vastly less polluted than the primary media
focused content.

@_date: 2011-01-20 13:47:39
@_author: coderman 
@_subject: Alleged Wikileaks Use of P2P to Siphon Documents 
the vast majority are accidental. the nature of how these incidents
occur, and the user interface design failures which encourage them is
an interesting tale in and of itself... ;)

@_date: 2011-07-26 06:46:36
@_author: coderman 
@_subject: Cyber Weapons: The New Arms Race 
sounds about right.  we live in interesting times...

@_date: 2011-06-16 04:37:18
@_author: coderman 
@_subject: <nettime> Internet Digital Black Friday: First Bitcoin  
in reality the more mundane market manipulation and rampant pilfering
is at root. these exchanges are handling large sums with recklessly
insecure systems. it's a recipe for a wild ride!

@_date: 2011-06-17 23:46:48
@_author: coderman 
@_subject: [cryptography] Digital cash in the news... 
i checked this out when it dropped. it was delivered in haste, and not
something overly impression (like a pro kit re-tailored for bitcoin
the day before this dropped wallet encryption was released in the
official bitcoin client. the attackers had to rush deployment of this
malware before too many potential targets upgraded to encrypted
wallets (thus making them less accessible to attacker using this
the interesting aspect is how this following a significant crackdown
on the bitcoin.org forums and was sent as a mass phish via private
message to all the members.
i've pasted the content below. note that clicking on the image went to
a ....JPG/ directory which in turn sent the screensaver malware
payload that is not identified in most browsers as potentially
malicious (unlike .EXE or .COM, .BAT, .PDF, etc.)
once you click, it rather clumsily traversed the disk looking for the
first wallet.dat to deliver via an open relay to a drop box at
they'd clearly spent more time on the delivery aspects than on the
smarts within the wallet stealing code. as said, a rush job due to the
client update the day before.
waiting for the next trojan to target RPC port on running bitcoind's...
You have just been sent a personal message by MoonShadow- on Bitcoin Forum.
IMPORTANT: Remember, this is just a notification. Please do not reply
to this email.
The message they sent you was:
Statements which should not be generally offensive, be excessively
repeated or have bad formatting (spam), contain forbidden advertising
or political or religious views, not be non-English when English is
required, disclose personal data of others, or support any other rule
Proof can be seen at:
One more warning and your account might be banned.
Reply to this Personal Message here:
cryptography mailing list
cryptography at randombit.net

@_date: 2011-06-20 17:35:06
@_author: coderman 
@_subject: Privacy Tempest 
biological and natural systems seem to be quite effective against /
compared to the most advanced sensors.
i have horse pastures surrounding my abode; equines naturally attuned
to taking shifts watching over the herd. last week went out to
investigate a particular mare with focused attention beyond the
property, over the fence, in deep brush.
it was a stray cat, sitting silent in the 2am dark... i like to call
this "biological amplification" and it beats even the best of the Flir
a replenishing resource that costs me about $240 a month for the group.
(cameras, infrared, acoustics, none have come close to the
effectiveness of just watching the pones watch my perimeter. :)

@_date: 2011-06-26 19:26:55
@_author: coderman 
@_subject: True Crypt User Held in Contempt of Court 
what i would like to know regarding this case:
- was there evidence of custody over the data in question by this
person? (email from other party, etc.) evidence that could indicate
the cause for this action and contempt of court?
- is $person the primary interest or third party in action against a
different primary defendant/target?

@_date: 2011-03-24 00:13:05
@_author: coderman 
@_subject: Phoenix UAV can sense you breathing 
2011/3/23 lodewijk andri de la porte :
your body interacts with them:
"... a fine beam ultra-wideband (UWB), multi-Gigahertz radio frequency
(RF) sensor array ... mounted on the robots lightweight arm transmits
highly directional wideband signals that are able to penetrate
reinforced concrete walls at an extended range. Reflections from the
targets are captured by a signal detector circuit in the receiver and
amplitude and delay information is then processed in an integrated
signal processor to track the targets in real time."

@_date: 2011-03-26 23:11:35
@_author: coderman 
@_subject: Iranian state-sponsored cyberwarfare is indistinguishable 
pretty amusing, to be sure.
(years ago i quit being frustrated by lazy, inaccurate, attention porn
news programming and decided to be amused instead. i am often amused!
there are worse things...)
nothing in the "cyber domain", certainly. they're quite adept at old
skewl though...
considering the poorly deployed, poorly managed, poorly maintained
iranian networking and computing systems in question, Occam says
someone having fun through iranian pwn hops...
(not to mention, who better to place blame upon? what a great diversion! :)

@_date: 2011-03-27 21:10:55
@_author: coderman 
@_subject: Iranian state-sponsored cyberwarfare is indistinguishable 
now you can point them at:
  comodo ceo a fucking dunce and tool. send your csr anywhere else!
even if that someone is themselves persian...
 , a few choice quotes in the correspondence. c.f.:
 'I heard that some stupids tried to ask about it from Iran's
ambassador in UN, really? How smartass you are? Where were you when
Stuxnet created by Israel and USA with millions of dollar budget, with
access to SCADA systems and Nuclear softwares? Why no one asked a
question from Israel and USA ambassador to UN?'

@_date: 2011-05-18 21:03:23
@_author: coderman 
@_subject: Cryptic Seduction 
Yeah, what kind of encode/media do you want?
(anyone welcome to contact off list)

@_date: 2011-05-18 22:29:29
@_author: coderman 
@_subject: AES-NI 
anyone else playing with AES-NI?  i think i'm in love...
speeds are in Bytes/sec for 16, 64, 256, 1024, 8192 byte blocks.
evp            4727934.14k  6546323.52k  7251165.61k  7622717.78k  7666193.75k
evp            5950427.83k  8590923.33k  9879158.95k 10254692.35k 10293641.22k
evp            6492679.75k 13352846.68k 15996760.83k 16935757.82k 17116293.80k

@_date: 2011-05-28 03:51:24
@_author: coderman 
@_subject: There.s a Secret Patriot Act, Senator Says 
robust systems arise from the emergent behavior of decentralized
components. for example:
- design, implement, nurture tech for individual citizens to engage
their peers and communities.
- extend upon this base to facilitate effective and accountable
municipal administration.
- extend upon this base to achieve robust state governance.
- finally, leverage this outgrowth of competent administration and
policy at the state level to drive change in federal governance.
this is more likely to produce substantial "change" than a vote
between Giant Douche and Turd Sandwich. breaking the red/blue
dichotomy with independent Piss Bucket in the running won't change
this dynamic.
this is a Hard Problem with no simple answers...  let me know if you
solve it. ;)
 [ see  for details on why top down
is paralysis and bottom up is robust... ]

@_date: 2011-11-25 12:03:50
@_author: coderman 
@_subject: offensive security, techniques [was Suspicion in Iran that 
these experts are wrong. what is interesting is how this framework and
methodology are applied across different objectives/targets.
stuxnet, duqu, still blind men groping mere parts of the elephant.
on a related tangent, companies/products i'd really like to get details on:
- Remote Control System (HackingTeam)
- FinSpy (FINFISHER)
- Netronome SSL Inspector
- Hinton Interceptor (Telesoft Technologies)
- VUPEN
- Cambridge Consultants
- Packet Forensics
- Bivio
- Mantaro
- Medav
- ONPATH
- Qosmos

@_date: 2011-11-28 11:14:37
@_author: coderman 
@_subject: IT "Security" 
your honey tokens must be much better than this, sir...

@_date: 2012-04-03 12:22:50
@_author: coderman 
@_subject: [cryptography] "Combined" cipher modes 
don't use GCM wrong?  short tags are bad. changing tag lengths are
bad. use 128bit tags.
reminds me of CTR mode arguments...
cryptography mailing list
cryptography at randombit.net

@_date: 2012-08-18 19:36:56
@_author: coderman 
@_subject: [briar-devel] Foo security 
this is also known as hypothesis  [0]
anything more is a usability liability ;)
0. "Hypothesis  -- There is only one Mode, and it is Secure."

@_date: 2012-08-31 11:46:06
@_author: coderman 
@_subject: This List Is Terrorist 
th3j35t3r is a fount of comedy indeed!
lame XerXeS ahead...

@_date: 2012-12-10 11:26:41
@_author: coderman 
@_subject: Assange-WikiLeaks Crypto Arms Call Triple Cross 
if the screed rings not of truth and substance,
 your mind may be clouded by bias, or
 you're asleep at the wheel of life...

@_date: 2012-12-16 21:58:35
@_author: coderman 
@_subject: [cryptography] Gmail and SSL 
yes; this is what i want. for Google to arbitrarily enforce a decision
is dumb and not useful.

@_date: 2012-12-21 22:08:00
@_author: coderman 
@_subject: [liberationtech] Skype redux 
csipsimple is getting closer.  the ZRTP voice works great but video
leaves much to be desired.
twinkle does ZRTP but video still on the roadmap.
ekiga claims to intend to add ZRTP support at some point, not holding
my breath...
yup, you're right. FLOSS video calling with end-to-end crypto sorely lacking.

@_date: 2012-12-21 22:14:44
@_author: coderman 
@_subject: [liberationtech] Skype redux 
yeah yeah don't forget jitsi.  i just don't like it :)

@_date: 2012-07-16 03:07:52
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_That=92s_No_Phone=2E_That=92s_My_Tracker=2E?= 
as mentioned above, that's not much protection. you can be linked by
behavior and propinquity, if not by name.
strong un-link-ability is an odyssey...

@_date: 2012-07-16 03:37:45
@_author: coderman 
@_subject: [Full-disclosure] CRYPTO-GRAM, July 15, 2012 
many but not most.
also, goats are exceptional sources of inspiration on side channel
attacks and insider threats. more on this later.. ;)
[i'd like to see a survey of info-sec specialists[0] turned ag
entrepreneurs. or sechors[0] as jya calls them...]
this is true. they are better.
many criminals are also better!
 ... but not most. heh
as evidenced by novel MD5 collision attacks leveraged for windows
update MitM (aka, "holy grail") and expansive A/V countermeasures via,
again novel, code injection methods.
they also do extensive QA to ensure success against their targets,
spanning whatever platform and processes. QA is expensive, and
methodical QA on malware; this makes me chortle!
this is intended to preserve return on investment. maybe one
difference, but not the most significant.
they won't and they don't need to. conventional malware targets the
masses, and they're vulnerable without much effort.
military malware targets the specific, and they'll do whatever they
can (which is significant) to achieve success.
entirely different domains!
this is succinct and apropos. commercial A/V is not going to protect
against state sponsored attacks (of which world class malware is a
such protection requires ..., well, far more than kaspersky can ever give you :P
0.  "Reign of the Sechors"
  Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2012-06-19 02:30:22
@_author: coderman 
@_subject: [cryptography] Intel RNG 
these rates often are not useful. even busy secure web or VPN servers
use orders of magnitude less.
initialization of full disk crypto across an SSD RAID could consume
it, but that's the only "practical" use case i've encountered so far
that said, a typical host entropy gathering daemon is often
insufficient, and even off-die serial bus and other old skewl sources
were providing entropy in kbit/sec rates, not MByte/sec.
some (many?) HWRNG designs use bit accumulators that feed a register
that is read by a userspace instruction.
consider the following configuration:
- this register is collecting single bits from two high speed
oscillators that is sub-sampling single bits at a quarter clock.
- only whitened / non-run bits collected, as set in a configuration
write / initialization.
in short: providing slow, non-deterministic output rates to this
entropy instruction.
if the instruction is configured to not-block, you could starve the
available pool in one thread, in one process, by using it
if the instruction is configured to block, you could introduce
significantly processing delays (unexpectedly so?) to other consumers
in other threads of execution, or other processes.
Intel did an end run around this problem with the DRBG, which is
similar to urandom, in the sense that it does not provide a 1:1
correlation of entropy in the system to entropy bits returned out, as
you may get in /dev/random linux behavior, which blocks once the
kernel entropy pool is exhausted. (that's another rant/tangent. let's
not go there :)
it is also seeding from the physical noise sources, running sanity
checks of some type, and then handing over to DRBG. so there is
clearly more involved than just a call to AES-NI. 3x as expensive
doesn't sound unreasonable if the seeding and validation overhead is
that's a great idea, and my reading of it is that they have said as
much. perhaps they should more clearly state it so for the usual case.
my understanding is that you will never fail unless the hardware
itself "starts up"? with a broken physical source returning clearly
invalid bits.
E.g. "In the rare event that the DRNG fails during runtime, it would
cease to issue random numbers rather than issue poor quality random
as for stating that it should never "run dry", or fail to not return
bits as long as the instruction is working, no matter how frequently
it is invoked, see:
With respect to the RNG taxonomy discussed above, the DRNG follows the
cascade construction RNG model, using a processor resident entropy
source to repeatedly seed a hardware-implemented CSPRNG. Unlike
software approaches, it includes a high-quality entropy source
implementation that can be sampled quickly to repeatedly seed the
CSPRNG with high-quality entropy. Furthermore, it represents a
self-contained hardware module that is isolated from software attacks
on its internal state. The result is a solution that achieves RNG
objectives with considerable robustness: statistical quality
(independence, uniform distribution), highly unpredictable random
number sequences, high performance, and protection against attack.
Protecting online services against RNG attacks [read: high entropy
consumption servers]
Throughput ceiling is insensitive to the number of contending parallel threads
take with a gran of salt; this is all from their documentation:
  cryptography mailing list
cryptography at randombit.net

@_date: 2012-06-30 09:47:52
@_author: coderman 
@_subject: [ZS] Neat wallet 
unless a newly started VM has poor entropy, then keys generated there
are potentially weak.
there should be some fun new concerns along this angle soon... (and
plenty of bad precedent already)

@_date: 2012-03-02 22:06:20
@_author: coderman 
@_subject: 8107 odell rd 
speaking of fun topics, anyone know what the sign reads at:
8107 Odell Rd Laurel, MD 20708

@_date: 2012-03-13 19:31:34
@_author: coderman 
@_subject: [tor-talk] Tor and HTTPS graphic 
my last comment for this sad, confused tangent of a thread;
  it has been accosted via conjecture with too much frequency *grin*
SCTP for congestion control of transparent proxy TCP/UDP traffic.
local classification of traffic allocates by protocol / use fairness
instead of aggregate tcp fairness. like bittorrent or aria2 parallel
traffic treated as distinct low priority unit of traffic, deferring to
higher priority low latency web traffic and messaging.
multi-homing / multi-path endpoints in SCTP would maintain concurrent
connection with distinct endpoints, avoiding predecessor, timing,
denial of service attacks present in reliable, ordered, single stream
edges would be screwed as you mention, unless they were full fledged
participants consistently. using a UDP based transport with LEDBAT or
other technique to keep broadband upstream unsaturated and unclogged
(no deep queues), allowing all broadband endpoints the ability to
contribute to a large shared network.
ORCHID IPv6 addressing with IPsec tunnels is intended to re-use
existing work, including well tested auth+privacy with datagram
padding in IPsec. SCTP+TLS would fit over top of IPv6 ORCHID endpoints
(using IPsec SAs) to transport signalling/keying and encapsulated
client traffic. part of this would also include lowest priority (lossy
reliable) SRMP type delivery of useful, less immediate information to
nodes. to some extent the ORCHID addresses could be thought of as
hidden service names and also circuit endpoints for a given IPsec
this set of:
a. critical signalling and keying traffic
b. high priority, interactive web traffic and messaging
c. lower priority bulk traffic, downloads, streaming media
d. best effort, latent bulk caching and exchange
are the classful shaping groups ordered inside of opaque SFQ outbound
queues at various improved/concurrent stratified dependent link
padding paths of IPsec telescopes carrying intermediate
hop(signalling) and bearer traffic.
combining better prioritization of traffic and consistent consumption
of traffic (deferring low priority packets and using opportunistic
caching strategies for network information respectively) obtains the
best performance out of the SFQ DLP paths with the lowest latency for
priority traffic.
still, so many details left as exercise for the reader ;)
sort of, for only parts; if you want a portable user space
implementation (or port) it's all custom. the joys of wild conjecture
include absurd timelines and technical effort for free...
rump is about as close as i've seen: this is not the least of "how to deploy a thing like this" concerns.
there is also no backward compatibility or slow transition from an
existing Tor network to something using UDP encapsulated IPsec
telescopes (even if TCP can be transparently proxied over SCTP over
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2012-09-01 21:08:47
@_author: coderman 
@_subject: SCS whitewashed from wikipedia 
they finally managed to do it: United States Special Collections
Service is now gone, redirected to "Central Security Service"
some interesting vandalism in the history.
 i guess they're getting more sophisticated..

@_date: 2012-09-01 21:19:59
@_author: coderman 
@_subject: SCS whitewashed from wikipedia 
just to be clear, "Special Collections Service" is now merged/abridged
into CSC page; waiting to see if/when that part "disappears".
curious there is no mention of X-37(A|B|C) yet... anything new on this front?
  looking at you, jya

@_date: 2013-08-06 13:00:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
this is the most informative and useful post ever made in the
al-qaeda.net discussion...  which happens to be the most ridiculous
discussion full of fear and weakness.
cypherpunks afraid of a domain name...  wtf

@_date: 2013-08-06 13:00:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
this is the most informative and useful post ever made in the
al-qaeda.net discussion...  which happens to be the most ridiculous
discussion full of fear and weakness.
cypherpunks afraid of a domain name...  wtf

@_date: 2013-08-07 10:02:11
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
it is related to the list in the sense of embracing epithets and
culling the useless.
you've provided this reasoning in measured fashion and various tone
repeatedly; believe me when i say i understand exactly what you are
concerned about and why you consider this unreasonable.
let me be equally clear: cryptography, privacy, and anonymity
discussions under any name and forum are appropriate. to censor the
medium or message out of fear of misunderstanding is akin to never
exercising rights and liberties for fear they may cause scrutiny and
if this is you: so concerned about unwanted attention, that you'll
always consent to a search of your person without resistance, that
you'll always hand over keys to your system or provide access to your
devices and equipment upon mere request, perhaps when crossing
borders, just so you avoid "trouble".
if this is you: what the fuck are you doing on a cypherpunks list?
cypherpunks write code, especially privacy and anonymity code, which
is a much more contentious endeavor than what you are cowed by.  this
is an impasse, where we agree to disagree.
P.S. if you do operate from a truly backward and hostile domain where
such a keyword alone is grounds for harassment then you're likely
already sub'd via remailers and proxies and multi-hops oh my...

@_date: 2013-08-07 10:02:11
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
it is related to the list in the sense of embracing epithets and
culling the useless.
you've provided this reasoning in measured fashion and various tone
repeatedly; believe me when i say i understand exactly what you are
concerned about and why you consider this unreasonable.
let me be equally clear: cryptography, privacy, and anonymity
discussions under any name and forum are appropriate. to censor the
medium or message out of fear of misunderstanding is akin to never
exercising rights and liberties for fear they may cause scrutiny and
if this is you: so concerned about unwanted attention, that you'll
always consent to a search of your person without resistance, that
you'll always hand over keys to your system or provide access to your
devices and equipment upon mere request, perhaps when crossing
borders, just so you avoid "trouble".
if this is you: what the fuck are you doing on a cypherpunks list?
cypherpunks write code, especially privacy and anonymity code, which
is a much more contentious endeavor than what you are cowed by.  this
is an impasse, where we agree to disagree.
P.S. if you do operate from a truly backward and hostile domain where
such a keyword alone is grounds for harassment then you're likely
already sub'd via remailers and proxies and multi-hops oh my...

@_date: 2013-08-07 20:35:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
why the false dichotomy? do them both!
i also hear he was also a ginger lacking a soul...
are you stating that "So, say goodnight to Joshua ..." in the context
of a perceived threat against an individuals family is on the same
level of offense as a domain name? really?
all the more reason to resist self censorship and cowardice!
now _this_ is a discussion worthy of the list. and there are lots of ideas :P
"embracing epithets and culling the useless."
i am indefensible and unreasonable; let's keep me out of this!
  on that note a few resources and projects to make this tirade not
entirely useless:
"Selected Papers in Anonymity"
 [why does this not have an HTTPS URL?]
"Bibliography - GNU's Framework for Secure Peer-to-Peer Networking"
"Project Byzantium"
 [why does this not have an HTTPS URL?]
"Dust: A Censorship-Resistant Internet Transport Protocol"
"The Anykernel and Rump Kernels"

@_date: 2013-08-09 15:59:38
@_author: coderman 
@_subject: [cryptography] NSA Today on Missions, Authorities, Oversight, 
cryptography
some interesting stats, also interesting copy / paste behavior:
"Scope and Scale of NSA Collection
According to figures published by a major tech provider, the Internet
carries 1,826 Petabytes of
information per day. In its foreign intelligence mission, NSA touches
about 1.6% of that. However,
of the 1.6% of the data, only 0.025% is actually selected for review.
The net effect is that NSA
part in a million. Put another way, if a standard basketball court
represented the global
FRPPXQLFDWLRQVHQYLURQPHQW16$VWRWDO collection would be
represented by an area smaller than a
dime on that basketball court."
to read:
Scope and Scale of NSA Collection
According to figures published by a major tech provider, the Internet
carries 1,826 Petabytes of
information per day. In its foreign intelligence mission, NSA touches
about 1.6% of that. However,
of the 1.6% of the data, only 0.025% is actually selected for review.
The net effect is that NSA
analysts look at 0.00004% of the world's traffic in conducting their
mission - that's less than one
part in a million. Put another way, if a standard basketball court
represented the global
communications environment, NSA's total collection would be
represented by an area smaller than a
dime on that basketball court.
again we see the fallacy of "not a search/collection until reviewed by
an analyst."...

@_date: 2013-08-10 15:50:42
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
this is the kind of messaging i would use - leaving all the
complexities and drawbacks of traditional email behind.
and StealthMonger: while the theory and design of latest generation
anonymous remailers are suitable for secure mail, the practical
realities render them unusable.
effort on real-time protocols that can defend against traffic
analysis, or other non-email systems like pond would be better spent.

@_date: 2013-08-11 02:27:54
@_author: coderman 
@_subject: Lavabit and End-point Security 
i've been contemplating a write up about this, but the problem is once
you advertise your methods they become less effective.
there really is "security through obscurity" in this sense; when at a
resource disadvantage, every little bit counts...
if i were to summarize what i have found effective against dedicated
and resourceful attackers (again, i can't go into details :) this
would be the top 5:
1. use a common distro, but rebuild critical components - bootloader,
initramfs, openssl, openssh, the kernel, gnutls, libgmp, use 64bit,
2. use isolation and RBAC, Qubes, VirtualBox, VMWare, Parallels,
remember that VM escapes are available and expected. defense in depth
can never be too deep.
3. use constrained network access - identify anomalies, control
bandwidth, firewall ingress and egress aggressively. this implies
constant monitoring to detect such events. (another exercise left to
the reader)
4. rootkit and backdoor your own systems - use the dirty tricks to
observe and constrain your system before someone else uses dirty
tricks to compromise your system.
5. don't forget physical security - this is the universal oversight
and most effective end run around all other operational and technical
security measures. there is a reason physical access so often implies
"game over" and why black bag jobs are still and will continue to be
effective against all targets.
perhaps more later,

@_date: 2013-08-11 05:45:02
@_author: coderman 
@_subject: Lavabit and End-point Security 
some questions, some answers, ...
this means rebuild hardened versions of these libraries from source;
  excluding insecure cipher suites in an OpenSSL build for example,
  altering architecture optimizations, supported features, in others,
the goal being that an exploit targeted to a vanilla distribution will
more likely fail with observable error or crash, rather than succeed
many exploits are very brittle in this respect, with any change in
symbol offsets or capabilities rendering them completely ineffective.
virtualization implies chained exploits for full compromise. combined
with the above you've drastically increased the cost of a successful
attack with modest effort. the likelihood of detection (by appearing
vulnerable yet not being so) is also increased.
remember that VMMs and hypervisors are themselves potentially
vulnerable software systems suitable for hardening and customization.
data exfiltration can be very visible via network behavior if you're
paying attention.  cross referencing connection state in your upstream
router vs. local OS view of sockets can identify discrepancies where
compromise has concealed covert connections. malware communicating
directly on an ethernet or wireless adapter outside of the OS is also
visible at this junction.
this is mostly a variant of  at a kernel / system level.  like
notepad.exe connecting to the internet, there are some syscall, file
access, and network requests which are clearly anomalous and
indicators of compromise.
this is a storied tangent unto itself...
last but not least: you must develop a routine of continuous hardening
and improvement. these steps are not done once and finished; they are
elements within a larger strategy of operational rigor defending
against motivated and capable attackers. asking for my "hardened linux
build" is missing the point entirely!

@_date: 2013-08-11 13:28:53
@_author: coderman 
@_subject: Lavabit and End-point Security 
one last cautionary tale:
some time back i used the techniques discussed to harden some Android
phones brought with me into a hostile environment. i had kernel level
protections in place, hardened the system configuration and services,
pared down apps to the minimum and constrained their access to the
file system and network. this was months of effort.
the first adversarial encounter went very well in my favor - all of
the attempts to exploit my devices were thwarted at these various
layers and via these protections, with the sole exception of a Google
Voice Search hack that kept voice search active in an "open mic night"
eavesdropping capability.  this was quickly nullified via kill -STOP
(Android won't re-spawn an app that is already running, and a stopped
process proved quite effective at halting this repeated invocation of
search used to capture audio.)
fast forward to round two, and i doubled down on the kernel, system,
and application level protections. even more scrutiny is applied to
applications to avoid the misuse of legitimate functionality for
malicious purpose.  i am feeling confident!
... and then a baseband exploit easily walks under all of my
protections at every layer, completely and fully 0wning my devices,
with the only hint at anything amiss being the elevated thermal
dissipation and power consumption from the radios performing data
transmission, all while the Android OS believed the devices were
silent in airplane mode.
[informative interlude: software defined transceivers should be in
every hacker toolbox; radio level attacks are otherwise invisible to
you. they are also useful for many other purposes, perhaps one day
even providing a solution to the untrustworthy proprietary firmware
and baseband systems crammed into every mobile device these days.]
incidentally, this also demonstrates why IOMMU / VT-d guest isolation
of devices on the host bus is very useful, as a vulnerable NIC could
otherwise provide complete access to privileged memory and interfaces
just like the baseband exploit above...  assuming your CPU itself is
"trusting trust" continues to be a persistent and difficult problem,
leaving us all vulnerable to some degree or another - it's just a
function of cost and skill to compromise.  turtles all the way down!

@_date: 2013-08-12 14:50:26
@_author: coderman 
@_subject: Lavabit and End-point Security 
"I'm sorry. My responses are limited. You must ask the right questions."
weaponized baseband exploits are difficult, expensive, architecture
specific, and not used capriciously.
this, among other reasons, is why there is such a dearth of
information on them despite being proven exploitable with a wide
attack surface for many years.
Rupp said state-sponsored attackers are already using baseband
processor attacks in airports but declined to go into details beyond
saying that attacks could be carried out without the need to trick
smartphones owners into opening an email or visiting a malicious
website. Attacks might involve building a rogue GSM base-station from
commodity hardware or run from the infrastructure of a 'co-operative"
telco. It might also be possible to run attacks against baseband
processors of phones using Wi-Fi or Bluetooth interfaces, according to
GSMK Cryptophone.
"Once you have control over the app CPU, you can in principle use that
to load any code you want from the network," Rupp explained. "Since
you have already successfully escalated your privileges on the system,
no user interaction is necessary."
"Baseband Attacks: Remote Exploitation of Memory Corruptions in
Cellular Protocol Stacks"
"Anatomy of contemporary GSM cellphone hardware"
"Cellular baseband security"
"Run-time firmware integrity verification: what if you can't trust
your network card"

@_date: 2013-08-17 20:17:11
@_author: coderman 
@_subject: Is the Wikileaks Party a cypherpunk party? 
i read this as: "i would rather smash my thumb with a hammer than
stick my dick in a lamp socket"

@_date: 2013-08-23 21:46:12
@_author: coderman 
@_subject: [liberationtech] NSA Admits: Okay, Okay, There Have Been A Bunch 
cpunks oh god this alone makes it all worth it,,, thank you Snowden!
P.S. setup a bitcoin donation address.
best regards,

@_date: 2013-08-24 00:41:34
@_author: coderman 
@_subject: [liberationtech] NSA Admits: Okay, Okay, There Have Been A Bunch 
indeed; this codename gives the lie to all the congressional
testimony, to all the claims of controls and judiciary oversight, to
all the attestations of full compliance.
it's beautiful in laying bare the capriciousness to which the entire
intelligence juggernaut can be brought to bear against arbitrary
individuals; personal pettiness more than sufficient.

@_date: 2013-08-25 13:21:32
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_=5Bliberationtech=5D_Why_can=92t_email_be_secure=3F_=2D_?= 
cpunks it is a question of private vs. public communication.
email is and will continue to be useful for public communication. this
gmail account indexes 190+ lists, 10,000 news alerts from scores of
filters (everything from "TS//SI//NF" to "Flame OR Gauss OR Duqu OR
Stuxnet" to GoldreichGoldwasserHalevi), a total of 643,132 pieces of
communication. i can search through all of it in seconds and apply new
filters to existing content just as easily as new, and keep an offline
backup just in case.
but there is zero i would consider private; for that use a medium of
communication that is not a usability failure, that is not a metadata
leakage nightmare, that is not an operational security mine field.
let email _for private communication_ die already, please!

@_date: 2013-08-25 13:40:38
@_author: coderman 
@_subject: [liberationtech] Why_can't_email_be_secure 
and to StealthMonger's point about latest generation mix networks for
best privacy, why not instead focus on building low latency protocols
that are resistant to traffic analysis and confirmation?
make them datagram based; utilize user space stacks and latest
research.  solving the low latency datagram anonymity problem enables
existing usable private communication with the additional benefit of
endpoint and peer anonymity.
i believe this possible to make useful, even if never infallible.
certainly more possible than the odds of making truly scalable,
available, and _usable_ mix mailer networks and clients for the
most important: make this low latency infrastructure usable and cross
platform, so the implementations are easily adopted... like Napster
and BitTorrent back in the day. ;)

@_date: 2013-08-25 17:31:24
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_=5Bliberationtech=5D_Why_can=92t_email_be_secure=3F_=2D_?= 
the battle very weighted toward one's favor, however,
 it is fun to try!
    ;)

@_date: 2013-08-25 18:13:11
@_author: coderman 
@_subject: NSLs, gag-orders, code-changes, coerced backdoors - any tech 
replicate broadcast functionality (most suited to wireless
transmissions) in the unicast datagram model and you have p2p that
doesn't scale. remember first gen gnutella?

@_date: 2013-08-26 00:55:11
@_author: coderman 
@_subject: [liberationtech] Why_can't_email_be_secure 
the best kind of problems!
correct. i mention them as a prerequisite for both protection and usability.
protection for example, with end-to-end SCTP multi-homed endpoints via
userspace stacks would avoid predecessor attacks - if you block one
route there are others which transit traffic, maintaining an
uninterrupted session across otherwise individually volatile paths.
usability for example to support UDP traffic and applications which
are not currently served via TCP and connection oriented services.
sadly, even TCP re-invented in user space is insufficient. you want a
specific protocol implementation of multi-homed SCTP in userspace,
probably on top of other protocol supports like LEDBAT or AQM. perhaps
using ORCHID IPv6 identifiers for endpoint addressing. lot's of
options; and as you said: it's a hard problem!
this is a separate problem. for the core transport encapsulation in
UDP may be sufficient. for censorship avoidance you will likely need
to bounce over a DUST like path first to access such an anonymizing
network. topology is an interesting subject, as the design must be
decentralized but may not need to be homogenous.
you want variable latency at the datagram level (e.g. stochastic
reordering and shaping of traffic, with prioritization done at the
endpoint where flows are visible.) more than the utmost in
performance. as long as it is overall TCP fair of course :)
and this is just the start. we haven't touched on network discovery,
path awareness/selection/weighting, etc.  as you said, hard problems;
the best kind of problems!

@_date: 2013-08-29 04:07:51
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
i should clarify:
the mode of operation for this presumed design and implementation is
to have SOCKS, HTTP, HTTPS, transparent UDP, transparent TCP,
transparent DNS (this is indeed different than just UDP :), and some
subset of transparent ICMP proxy support on the client / node.  you
could configure proxy settings, direct traffic to the trans ports, or
perform queries directly against the DNS port of the running real time
datagram mixer instance.
at the exits for public traffic or at the private ORCHID based
"hidden/overlay" endpoints, you transit these same protocols, per
advertised support in exit policy or overlay service capability
on the wire, you would be sending UDP datagrams that encapsulate the
NAT busting IPsec telescope containing path data, multi-path SCTP in
userspace for reliable TCP stream transport over the datagram overlay.
for all intents and purposes these packets would look like AH/ESP or
CryptoBox wrapped opaque cipher texts in some standard UDP
as for ATM, SONET, satellite data terminals, metro wireless, and all
other unusual or exotic transports: these are likely not useful for
the core network unless directly public UDP IPv4 reachable.
censorship bypass, non-node capable devices like phones, or very poor
network connectivity situations, would require other transports and
protocols for this initial tunnel into the overall real-time datagram
mix-like network.  in this context, the varied physical layers and
logical paths in a given metro region operating beneath IP routing can
play a role in passing traffic from suppressed/blocked users out to
the broader mesh or internet at large.
devices and users communicating via obfuscated links into the dgm
network do not have traffic analysis protections like full
participants.  despite this lack of stronger anonymity, the actors
observing at the edge can only note that you are tunneling into the
public network, and utilizing some stochastic gradient of bandwidth in
aggregate for some period of time.
this is still not much information, especially compared to the current
state of affairs!
there are many complications and constraints around how this would
work - i make it sound so easy ;)
  however, you could provide such services, including wireless metro
area mesh or p-to-mp distribution networks, constrained by propinquity
and referral by reputation, in combination with broadband internet
uplink of a more traditional sort where available.
and in fact, using multiple paths / transports concurrently provides
advantage for data continuity and throughput despite volatile and
changing upstream link availability on an individual basis to
particular gateway or router or access point devices.
metro area mesh benefits nicely from some backhaul ad-hoc or fixed
plant high capacity point-to-point links over distance with short IP
routes; there is a good paper from early 2000's about using atheros
802.11a devices with a custom tertiary firmware and host driver to
bond eight devices into a single point-to-point link with an aggregate
throughput over three or four hundred megabit a second in transport
rate... or so i recall.  IPoATM on a OC12 or bigger to an internet
provider would absolutely be useful as an upstream sink within such a
i would love to see high degree mesh optimizer p-to-mp nodes applying
the latest high bit rate software defines radios for  backhaul and
security.  isolate each radio like a Pervices Noctar[0] or USRP B210
[1] into its own guest and isolate devices with VT-d enforced memory
access boundaries.  you may even put more than one device in a single
SDR Backhaul Guest VM if doing large-QAM or other complex MIMO
front-ends and signal processing.
i could go on, but alas, i've got code to write...  *grin*
0. "Noctar: 8Gbps, low latency, PCIe x4 bus, 250MHz bandwidth, full
duplex, RF frontend 100kHz  4GHz, Two, 12 bit, 125 MSPS ADCs, Dual
channel, 16 bit, 250 MSPS DAC, 20MHz, 0.28ppm, reference TCXO, Altera
Cyclone IV EP4CGX22C FPGA"
  1. "USRP B210 Kit: USB 3.0 (bus max 3.2Gb/s) for xfer ~60 MSym/sec, 56
MHz bandwidth 1x1 / 32 MHz 2x2 MIMO bandwidth, 70 MHz to 6 GHz
frequency range, flexible rate 12bit ADC/DAC, 2 TX and 2 RX full or
half duplex channels (4 total), Xilinx Spartan 6 XC6SLX150 FPGA"

@_date: 2013-08-29 04:22:19
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
i should have mentioned:
metro Ethernet or municipal run fiber networks with peering are the
best option for mesh traffic relaying like this. ATM is too expensive;
IDSN, despite a proud origin story of the first data mix networks, is
also expensive, and super slow.
get rooftop access for radios in a Fresnel friendly internet exchange
where you can simply forward traffic down a few floors over Ethernet
and you're in the best of positions.
consumer fiber to the home would be great, if ToS restrictions didn't
make such forwarding risky.  and the business upgrade for FTTP is
pretty outrageous in almost every case.
you could route through a VPN provider or dedi server of your own in
this case, but tunneling may not be sufficiently covert depending on
the amount of bandwidth used.

@_date: 2013-08-29 21:51:19
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
active attacks are often even more effective at rapid traffic
confirmation and analysis[0]; GPA is pretty tame perhaps!
in any case the challenge you mention: thwarting or preventing traffic
analysis without a full mix of constant traffic. if the datagram based
system above existed, combine with:
- stochastic fair queuing and re-ordering of egress traffic. by
"clamping" the outbound rate of randomized, re-ordered datagrams to a
broad "size/chunk" of capacity, you deter traffic confirmation,
anonymity set reduction, and other traffic analysis attacks of various
- client-side classification of application traffic into prioritized
classes[1] for ingress / dgm proxy level active shaping by classful
HTB queues before transiting the first hop and losing all visibility
into the content and priority of message payloads.
- integrate a lowest effort / unreliable background reliable multicast
like bulk transport channel for resource and key pre-caching, network
participant and performance information distribution, secure remote
archives, random performance measurement/tests across peer groups,
other low priority communications suited for this "filler" class of
traffic. (consuming more or less filler traffic helps smooth out the
effective throughput and efficiency when changing the broad
"stochastic traffic capacity range" appropriate for a given peer.)
- provide LEDBAT or AQM management of edge traffic to upstream(s) to
prevent unnecessary latency in upstream buffers. this ensures that
even at full utilization the responsiveness of the broadband link is
- and the multi-path SCTP, IPsec, UDP NAT traversal and encapsulation,
and other user space network stacks communicating across this overlay
network as discussed above for requisite application and control
communication support.
these techniques combined allow you to use still not insignificant
"stochastic traffic capacity ranges" instead of a constant fixed
amount of traffic to protect against these attacks.  these stochastic
ranges can be adjusted up or down as network performance and capacity
dictate. this protocol provides congestion control and TCP
friendliness while greatly reducing the amount of bandwidth consumed
relative to a traditional mix.
at best (in theory), an attacker with local active and global passive
methods on hand could discern anonymity sets for broad categories /
scales of possible communication usage.  E.g. anon set A exhibits
traffic utilization on the order of 1Mbps to 5Mbps, while anon set B
exhibits traffic utilization on the order of 5Mbps to 50Mbps, and anon
set C exhibits traffic utilization on the order of 50Mbps to 1Gbps,
given this drawback, code a kick ass client with participation enabled
by default if sufficient connectivity and resources are available.
you've now made these broad traffic volume sets nearly useless in a
practical / actionable sense.
congratulations! you've now got a traffic analysis resistant low
latency anonymity protocol, implementation, and network that nearly
anyone can participate in and contribute to. for my next magic hand
wave, a directory / route selection method that scales to billions of
peers while leveraging geographic propinquity and social peer groups
to constrain Sybil attacks and impact of bad actors.
next grow network capacity in a way that continually applies implicit
feedback from the network overall and peers directly and your
deterrence to these attacks begins to improve further over time,
perhaps even one day hitting a tipping point of prevalence and
persistence for de-facto victory in most threat models...
we can dream!
perhaps someone should toss up a Bitcoin donation address to support
work on detailed technical specifications, experimental prototypes,
maintaining clouds for continuous builds, regression checks, load
tests, and traffic analysis for quality measurement and security
could also use donations for bounties for identifying or exploiting
security or privacy vulnerabilities in the design and implementation
of this final generation anonymous network.  whoever sets this up
should probably use an onion to coordinate development and distribute
sources, other resources...
calling all "tup" s, ...  ;P
0. "From a Trickle to a Flood: Active Attacks on Several Mix Types"
  1. i have mentioned the following classes before, with each in
priority order for the HTB prioritization / shaping before traffic
enters the network and becomes opaque:
 a. control and signalling traffic - always takes precedence.
 b. real-time and interactive communications, but not video.
 c. real-time video communication, if applicable.
 d. low priority bulk communication.  torrents, archives, opportunistic caching
 e. filler / last-tier best effort unreliable traffic as mentioned
above for filling in the remaining capacity at the current stochastic
rx/tx rate center point.
2.  instead of trying to research and author formal proofs of entropy
bounds for various idealized models, cut straight to the chase and
build the most aggressive, best in class developmental learning / deep
learning systems for classification and identification of nodes,
flows, protocols, identities in a test bed setup that provides full
traffic visibility and active client edge MitM capability (E.g.
simulate attack via rogue AP or cell tower for tagging? selective DoS?
others,).  malicious attacks performed by the remote end or injected
by remote's upstream are not in scope for this traffic analysis and
privacy assessment. however, passive capture of all exit
communications and ORCHID hidden endpoint communications is in scope
for analysis.
then, see how effective this best scenario and tools attack is against
a running implementation.  did it fail catastrophically in flames or
break wide open with trivial effort?  keep improving...
respectably hardened against the most aggressive machine learning and
malicious active attacks you could conceive of and build?  great! have
a beer and then find the people who see the oversights and blind spots
you don't.  keep improving... rinse, repeat, ...

@_date: 2013-08-30 12:19:39
@_author: coderman 
@_subject: [Cryptography] The Case for Formal Verification 
this is the crux; where the human meets the machine is always a large,
evolving, complicated attack surface. e.g. usability and design level
requirements and behavior.
in the order of precedence of security risks, much bigger holes must
be addressed before formal verification provides return on time
if you're building verified compilers, or micro kernels, or core
libraries, this doesn't apply to you. ;)
i want seL4 in a Qubes isolation model, formally verified CryptoBox,
this makes no sense to me; patently absurd on the face of it.
why test code with clusters that are larger than your build systems?
why do we exist? ...
utility of quality measures can not be judged on superficial metrics
like "size in GB" or "processor hours".  anyone using this argument as
a disqualifier is not qualified to make such an assessment.
this is a great approach and fits in well with other security through
isolation defense in depth.  combining the strengths of formal
verification at critical core points within a system, and then
leveraging that robust core to isolate, constrain, mediate between
higher level applications seem most reasonable, tractable, with the
best return on time invested.
if i had a wishlist it would be:
- 64bit CompCert (not just 64bit int support :)
- verified virtualization isolation model (seL4 Qubes like system?)
- verified crypto_sign_edwards25519sha512batch and
crypto_sign_nistp256sha512ecdsa implementations
- verified compression, regexp, and other common libraries that are
useful at the security boundary between isolated domains or
some of the work done for quark might be partially applicable to some
of the above, but most of the verification is browser specific
(related to things like messaging and tab isolation, proper cookie
handling, socket communication, etc.)
where's the github for Coq kernels?
some other good resources:
ProofWeb:  particularly the courses available for the online interface to Coq.
frama-c:  i just came across this, it looks quite useful, but have not used it
in any depth yet...
Lemma stating_the_obvious:
 (* formal verification as a useful component of defense in depth is
self-evident *)
The future is here. It's just not widely distributed yet.

@_date: 2013-08-30 12:19:39
@_author: coderman 
@_subject: [Cryptography] The Case for Formal Verification 
this is the crux; where the human meets the machine is always a large,
evolving, complicated attack surface. e.g. usability and design level
requirements and behavior.
in the order of precedence of security risks, much bigger holes must
be addressed before formal verification provides return on time
if you're building verified compilers, or micro kernels, or core
libraries, this doesn't apply to you. ;)
i want seL4 in a Qubes isolation model, formally verified CryptoBox,
this makes no sense to me; patently absurd on the face of it.
why test code with clusters that are larger than your build systems?
why do we exist? ...
utility of quality measures can not be judged on superficial metrics
like "size in GB" or "processor hours".  anyone using this argument as
a disqualifier is not qualified to make such an assessment.
this is a great approach and fits in well with other security through
isolation defense in depth.  combining the strengths of formal
verification at critical core points within a system, and then
leveraging that robust core to isolate, constrain, mediate between
higher level applications seem most reasonable, tractable, with the
best return on time invested.
if i had a wishlist it would be:
- 64bit CompCert (not just 64bit int support :)
- verified virtualization isolation model (seL4 Qubes like system?)
- verified crypto_sign_edwards25519sha512batch and
crypto_sign_nistp256sha512ecdsa implementations
- verified compression, regexp, and other common libraries that are
useful at the security boundary between isolated domains or
some of the work done for quark might be partially applicable to some
of the above, but most of the verification is browser specific
(related to things like messaging and tab isolation, proper cookie
handling, socket communication, etc.)
where's the github for Coq kernels?
some other good resources:
ProofWeb:  particularly the courses available for the online interface to Coq.
frama-c:  i just came across this, it looks quite useful, but have not used it
in any depth yet...
Lemma stating_the_obvious:
 (* formal verification as a useful component of defense in depth is
self-evident *)
The future is here. It's just not widely distributed yet.

@_date: 2013-08-30 21:36:31
@_author: coderman 
@_subject: Lavabit and End-point Security 
a good presentation which suggests this technique, among other useful ideas:
"Attack Driven Defense"

@_date: 2013-08-31 18:23:11
@_author: coderman 
@_subject: So I discovered that my HP laptop leaks/transmits its built-in 
pretty interesting; xmits continuously when powered. during POST, no
effect if on/off/disabled in BIOS.

@_date: 2013-08-06 13:00:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
this is the most informative and useful post ever made in the
al-qaeda.net discussion...  which happens to be the most ridiculous
discussion full of fear and weakness.
cypherpunks afraid of a domain name...  wtf

@_date: 2013-08-06 13:00:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
this is the most informative and useful post ever made in the
al-qaeda.net discussion...  which happens to be the most ridiculous
discussion full of fear and weakness.
cypherpunks afraid of a domain name...  wtf

@_date: 2013-08-07 10:02:11
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
it is related to the list in the sense of embracing epithets and
culling the useless.
you've provided this reasoning in measured fashion and various tone
repeatedly; believe me when i say i understand exactly what you are
concerned about and why you consider this unreasonable.
let me be equally clear: cryptography, privacy, and anonymity
discussions under any name and forum are appropriate. to censor the
medium or message out of fear of misunderstanding is akin to never
exercising rights and liberties for fear they may cause scrutiny and
if this is you: so concerned about unwanted attention, that you'll
always consent to a search of your person without resistance, that
you'll always hand over keys to your system or provide access to your
devices and equipment upon mere request, perhaps when crossing
borders, just so you avoid "trouble".
if this is you: what the fuck are you doing on a cypherpunks list?
cypherpunks write code, especially privacy and anonymity code, which
is a much more contentious endeavor than what you are cowed by.  this
is an impasse, where we agree to disagree.
P.S. if you do operate from a truly backward and hostile domain where
such a keyword alone is grounds for harassment then you're likely
already sub'd via remailers and proxies and multi-hops oh my...

@_date: 2013-08-07 10:02:11
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
it is related to the list in the sense of embracing epithets and
culling the useless.
you've provided this reasoning in measured fashion and various tone
repeatedly; believe me when i say i understand exactly what you are
concerned about and why you consider this unreasonable.
let me be equally clear: cryptography, privacy, and anonymity
discussions under any name and forum are appropriate. to censor the
medium or message out of fear of misunderstanding is akin to never
exercising rights and liberties for fear they may cause scrutiny and
if this is you: so concerned about unwanted attention, that you'll
always consent to a search of your person without resistance, that
you'll always hand over keys to your system or provide access to your
devices and equipment upon mere request, perhaps when crossing
borders, just so you avoid "trouble".
if this is you: what the fuck are you doing on a cypherpunks list?
cypherpunks write code, especially privacy and anonymity code, which
is a much more contentious endeavor than what you are cowed by.  this
is an impasse, where we agree to disagree.
P.S. if you do operate from a truly backward and hostile domain where
such a keyword alone is grounds for harassment then you're likely
already sub'd via remailers and proxies and multi-hops oh my...

@_date: 2013-08-07 20:35:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
why the false dichotomy? do them both!
i also hear he was also a ginger lacking a soul...
are you stating that "So, say goodnight to Joshua ..." in the context
of a perceived threat against an individuals family is on the same
level of offense as a domain name? really?
all the more reason to resist self censorship and cowardice!
now _this_ is a discussion worthy of the list. and there are lots of ideas :P
"embracing epithets and culling the useless."
i am indefensible and unreasonable; let's keep me out of this!
  on that note a few resources and projects to make this tirade not
entirely useless:
"Selected Papers in Anonymity"
 [why does this not have an HTTPS URL?]
"Bibliography - GNU's Framework for Secure Peer-to-Peer Networking"
"Project Byzantium"
 [why does this not have an HTTPS URL?]
"Dust: A Censorship-Resistant Internet Transport Protocol"
"The Anykernel and Rump Kernels"

@_date: 2013-08-09 15:59:38
@_author: coderman 
@_subject: [cryptography] NSA Today on Missions, Authorities, Oversight, 
cryptography
some interesting stats, also interesting copy / paste behavior:
"Scope and Scale of NSA Collection
According to figures published by a major tech provider, the Internet
carries 1,826 Petabytes of
information per day. In its foreign intelligence mission, NSA touches
about 1.6% of that. However,
of the 1.6% of the data, only 0.025% is actually selected for review.
The net effect is that NSA
part in a million. Put another way, if a standard basketball court
represented the global
FRPPXQLFDWLRQVHQYLURQPHQW16$VWRWDO collection would be
represented by an area smaller than a
dime on that basketball court."
to read:
Scope and Scale of NSA Collection
According to figures published by a major tech provider, the Internet
carries 1,826 Petabytes of
information per day. In its foreign intelligence mission, NSA touches
about 1.6% of that. However,
of the 1.6% of the data, only 0.025% is actually selected for review.
The net effect is that NSA
analysts look at 0.00004% of the world's traffic in conducting their
mission - that's less than one
part in a million. Put another way, if a standard basketball court
represented the global
communications environment, NSA's total collection would be
represented by an area smaller than a
dime on that basketball court.
again we see the fallacy of "not a search/collection until reviewed by
an analyst."...

@_date: 2013-08-10 15:50:42
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
this is the kind of messaging i would use - leaving all the
complexities and drawbacks of traditional email behind.
and StealthMonger: while the theory and design of latest generation
anonymous remailers are suitable for secure mail, the practical
realities render them unusable.
effort on real-time protocols that can defend against traffic
analysis, or other non-email systems like pond would be better spent.

@_date: 2013-08-11 02:27:54
@_author: coderman 
@_subject: Lavabit and End-point Security 
i've been contemplating a write up about this, but the problem is once
you advertise your methods they become less effective.
there really is "security through obscurity" in this sense; when at a
resource disadvantage, every little bit counts...
if i were to summarize what i have found effective against dedicated
and resourceful attackers (again, i can't go into details :) this
would be the top 5:
1. use a common distro, but rebuild critical components - bootloader,
initramfs, openssl, openssh, the kernel, gnutls, libgmp, use 64bit,
2. use isolation and RBAC, Qubes, VirtualBox, VMWare, Parallels,
remember that VM escapes are available and expected. defense in depth
can never be too deep.
3. use constrained network access - identify anomalies, control
bandwidth, firewall ingress and egress aggressively. this implies
constant monitoring to detect such events. (another exercise left to
the reader)
4. rootkit and backdoor your own systems - use the dirty tricks to
observe and constrain your system before someone else uses dirty
tricks to compromise your system.
5. don't forget physical security - this is the universal oversight
and most effective end run around all other operational and technical
security measures. there is a reason physical access so often implies
"game over" and why black bag jobs are still and will continue to be
effective against all targets.
perhaps more later,

@_date: 2013-08-11 05:45:02
@_author: coderman 
@_subject: Lavabit and End-point Security 
some questions, some answers, ...
this means rebuild hardened versions of these libraries from source;
  excluding insecure cipher suites in an OpenSSL build for example,
  altering architecture optimizations, supported features, in others,
the goal being that an exploit targeted to a vanilla distribution will
more likely fail with observable error or crash, rather than succeed
many exploits are very brittle in this respect, with any change in
symbol offsets or capabilities rendering them completely ineffective.
virtualization implies chained exploits for full compromise. combined
with the above you've drastically increased the cost of a successful
attack with modest effort. the likelihood of detection (by appearing
vulnerable yet not being so) is also increased.
remember that VMMs and hypervisors are themselves potentially
vulnerable software systems suitable for hardening and customization.
data exfiltration can be very visible via network behavior if you're
paying attention.  cross referencing connection state in your upstream
router vs. local OS view of sockets can identify discrepancies where
compromise has concealed covert connections. malware communicating
directly on an ethernet or wireless adapter outside of the OS is also
visible at this junction.
this is mostly a variant of  at a kernel / system level.  like
notepad.exe connecting to the internet, there are some syscall, file
access, and network requests which are clearly anomalous and
indicators of compromise.
this is a storied tangent unto itself...
last but not least: you must develop a routine of continuous hardening
and improvement. these steps are not done once and finished; they are
elements within a larger strategy of operational rigor defending
against motivated and capable attackers. asking for my "hardened linux
build" is missing the point entirely!

@_date: 2013-08-11 13:28:53
@_author: coderman 
@_subject: Lavabit and End-point Security 
one last cautionary tale:
some time back i used the techniques discussed to harden some Android
phones brought with me into a hostile environment. i had kernel level
protections in place, hardened the system configuration and services,
pared down apps to the minimum and constrained their access to the
file system and network. this was months of effort.
the first adversarial encounter went very well in my favor - all of
the attempts to exploit my devices were thwarted at these various
layers and via these protections, with the sole exception of a Google
Voice Search hack that kept voice search active in an "open mic night"
eavesdropping capability.  this was quickly nullified via kill -STOP
(Android won't re-spawn an app that is already running, and a stopped
process proved quite effective at halting this repeated invocation of
search used to capture audio.)
fast forward to round two, and i doubled down on the kernel, system,
and application level protections. even more scrutiny is applied to
applications to avoid the misuse of legitimate functionality for
malicious purpose.  i am feeling confident!
... and then a baseband exploit easily walks under all of my
protections at every layer, completely and fully 0wning my devices,
with the only hint at anything amiss being the elevated thermal
dissipation and power consumption from the radios performing data
transmission, all while the Android OS believed the devices were
silent in airplane mode.
[informative interlude: software defined transceivers should be in
every hacker toolbox; radio level attacks are otherwise invisible to
you. they are also useful for many other purposes, perhaps one day
even providing a solution to the untrustworthy proprietary firmware
and baseband systems crammed into every mobile device these days.]
incidentally, this also demonstrates why IOMMU / VT-d guest isolation
of devices on the host bus is very useful, as a vulnerable NIC could
otherwise provide complete access to privileged memory and interfaces
just like the baseband exploit above...  assuming your CPU itself is
"trusting trust" continues to be a persistent and difficult problem,
leaving us all vulnerable to some degree or another - it's just a
function of cost and skill to compromise.  turtles all the way down!

@_date: 2013-08-12 14:50:26
@_author: coderman 
@_subject: Lavabit and End-point Security 
"I'm sorry. My responses are limited. You must ask the right questions."
weaponized baseband exploits are difficult, expensive, architecture
specific, and not used capriciously.
this, among other reasons, is why there is such a dearth of
information on them despite being proven exploitable with a wide
attack surface for many years.
Rupp said state-sponsored attackers are already using baseband
processor attacks in airports but declined to go into details beyond
saying that attacks could be carried out without the need to trick
smartphones owners into opening an email or visiting a malicious
website. Attacks might involve building a rogue GSM base-station from
commodity hardware or run from the infrastructure of a 'co-operative"
telco. It might also be possible to run attacks against baseband
processors of phones using Wi-Fi or Bluetooth interfaces, according to
GSMK Cryptophone.
"Once you have control over the app CPU, you can in principle use that
to load any code you want from the network," Rupp explained. "Since
you have already successfully escalated your privileges on the system,
no user interaction is necessary."
"Baseband Attacks: Remote Exploitation of Memory Corruptions in
Cellular Protocol Stacks"
"Anatomy of contemporary GSM cellphone hardware"
"Cellular baseband security"
"Run-time firmware integrity verification: what if you can't trust
your network card"

@_date: 2013-08-17 20:17:11
@_author: coderman 
@_subject: Is the Wikileaks Party a cypherpunk party? 
i read this as: "i would rather smash my thumb with a hammer than
stick my dick in a lamp socket"

@_date: 2013-08-23 21:46:12
@_author: coderman 
@_subject: [liberationtech] NSA Admits: Okay, Okay, There Have Been A Bunch 
cpunks oh god this alone makes it all worth it,,, thank you Snowden!
P.S. setup a bitcoin donation address.
best regards,

@_date: 2013-08-24 00:41:34
@_author: coderman 
@_subject: [liberationtech] NSA Admits: Okay, Okay, There Have Been A Bunch 
indeed; this codename gives the lie to all the congressional
testimony, to all the claims of controls and judiciary oversight, to
all the attestations of full compliance.
it's beautiful in laying bare the capriciousness to which the entire
intelligence juggernaut can be brought to bear against arbitrary
individuals; personal pettiness more than sufficient.

@_date: 2013-08-25 13:21:32
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_=5Bliberationtech=5D_Why_can=92t_email_be_secure=3F_=2D_?= 
cpunks it is a question of private vs. public communication.
email is and will continue to be useful for public communication. this
gmail account indexes 190+ lists, 10,000 news alerts from scores of
filters (everything from "TS//SI//NF" to "Flame OR Gauss OR Duqu OR
Stuxnet" to GoldreichGoldwasserHalevi), a total of 643,132 pieces of
communication. i can search through all of it in seconds and apply new
filters to existing content just as easily as new, and keep an offline
backup just in case.
but there is zero i would consider private; for that use a medium of
communication that is not a usability failure, that is not a metadata
leakage nightmare, that is not an operational security mine field.
let email _for private communication_ die already, please!

@_date: 2013-08-25 13:40:38
@_author: coderman 
@_subject: [liberationtech] Why_can't_email_be_secure 
and to StealthMonger's point about latest generation mix networks for
best privacy, why not instead focus on building low latency protocols
that are resistant to traffic analysis and confirmation?
make them datagram based; utilize user space stacks and latest
research.  solving the low latency datagram anonymity problem enables
existing usable private communication with the additional benefit of
endpoint and peer anonymity.
i believe this possible to make useful, even if never infallible.
certainly more possible than the odds of making truly scalable,
available, and _usable_ mix mailer networks and clients for the
most important: make this low latency infrastructure usable and cross
platform, so the implementations are easily adopted... like Napster
and BitTorrent back in the day. ;)

@_date: 2013-08-25 17:31:24
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_=5Bliberationtech=5D_Why_can=92t_email_be_secure=3F_=2D_?= 
the battle very weighted toward one's favor, however,
 it is fun to try!
    ;)

@_date: 2013-08-25 18:13:11
@_author: coderman 
@_subject: NSLs, gag-orders, code-changes, coerced backdoors - any tech 
replicate broadcast functionality (most suited to wireless
transmissions) in the unicast datagram model and you have p2p that
doesn't scale. remember first gen gnutella?

@_date: 2013-08-26 00:55:11
@_author: coderman 
@_subject: [liberationtech] Why_can't_email_be_secure 
the best kind of problems!
correct. i mention them as a prerequisite for both protection and usability.
protection for example, with end-to-end SCTP multi-homed endpoints via
userspace stacks would avoid predecessor attacks - if you block one
route there are others which transit traffic, maintaining an
uninterrupted session across otherwise individually volatile paths.
usability for example to support UDP traffic and applications which
are not currently served via TCP and connection oriented services.
sadly, even TCP re-invented in user space is insufficient. you want a
specific protocol implementation of multi-homed SCTP in userspace,
probably on top of other protocol supports like LEDBAT or AQM. perhaps
using ORCHID IPv6 identifiers for endpoint addressing. lot's of
options; and as you said: it's a hard problem!
this is a separate problem. for the core transport encapsulation in
UDP may be sufficient. for censorship avoidance you will likely need
to bounce over a DUST like path first to access such an anonymizing
network. topology is an interesting subject, as the design must be
decentralized but may not need to be homogenous.
you want variable latency at the datagram level (e.g. stochastic
reordering and shaping of traffic, with prioritization done at the
endpoint where flows are visible.) more than the utmost in
performance. as long as it is overall TCP fair of course :)
and this is just the start. we haven't touched on network discovery,
path awareness/selection/weighting, etc.  as you said, hard problems;
the best kind of problems!

@_date: 2013-08-29 04:07:51
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
i should clarify:
the mode of operation for this presumed design and implementation is
to have SOCKS, HTTP, HTTPS, transparent UDP, transparent TCP,
transparent DNS (this is indeed different than just UDP :), and some
subset of transparent ICMP proxy support on the client / node.  you
could configure proxy settings, direct traffic to the trans ports, or
perform queries directly against the DNS port of the running real time
datagram mixer instance.
at the exits for public traffic or at the private ORCHID based
"hidden/overlay" endpoints, you transit these same protocols, per
advertised support in exit policy or overlay service capability
on the wire, you would be sending UDP datagrams that encapsulate the
NAT busting IPsec telescope containing path data, multi-path SCTP in
userspace for reliable TCP stream transport over the datagram overlay.
for all intents and purposes these packets would look like AH/ESP or
CryptoBox wrapped opaque cipher texts in some standard UDP
as for ATM, SONET, satellite data terminals, metro wireless, and all
other unusual or exotic transports: these are likely not useful for
the core network unless directly public UDP IPv4 reachable.
censorship bypass, non-node capable devices like phones, or very poor
network connectivity situations, would require other transports and
protocols for this initial tunnel into the overall real-time datagram
mix-like network.  in this context, the varied physical layers and
logical paths in a given metro region operating beneath IP routing can
play a role in passing traffic from suppressed/blocked users out to
the broader mesh or internet at large.
devices and users communicating via obfuscated links into the dgm
network do not have traffic analysis protections like full
participants.  despite this lack of stronger anonymity, the actors
observing at the edge can only note that you are tunneling into the
public network, and utilizing some stochastic gradient of bandwidth in
aggregate for some period of time.
this is still not much information, especially compared to the current
state of affairs!
there are many complications and constraints around how this would
work - i make it sound so easy ;)
  however, you could provide such services, including wireless metro
area mesh or p-to-mp distribution networks, constrained by propinquity
and referral by reputation, in combination with broadband internet
uplink of a more traditional sort where available.
and in fact, using multiple paths / transports concurrently provides
advantage for data continuity and throughput despite volatile and
changing upstream link availability on an individual basis to
particular gateway or router or access point devices.
metro area mesh benefits nicely from some backhaul ad-hoc or fixed
plant high capacity point-to-point links over distance with short IP
routes; there is a good paper from early 2000's about using atheros
802.11a devices with a custom tertiary firmware and host driver to
bond eight devices into a single point-to-point link with an aggregate
throughput over three or four hundred megabit a second in transport
rate... or so i recall.  IPoATM on a OC12 or bigger to an internet
provider would absolutely be useful as an upstream sink within such a
i would love to see high degree mesh optimizer p-to-mp nodes applying
the latest high bit rate software defines radios for  backhaul and
security.  isolate each radio like a Pervices Noctar[0] or USRP B210
[1] into its own guest and isolate devices with VT-d enforced memory
access boundaries.  you may even put more than one device in a single
SDR Backhaul Guest VM if doing large-QAM or other complex MIMO
front-ends and signal processing.
i could go on, but alas, i've got code to write...  *grin*
0. "Noctar: 8Gbps, low latency, PCIe x4 bus, 250MHz bandwidth, full
duplex, RF frontend 100kHz  4GHz, Two, 12 bit, 125 MSPS ADCs, Dual
channel, 16 bit, 250 MSPS DAC, 20MHz, 0.28ppm, reference TCXO, Altera
Cyclone IV EP4CGX22C FPGA"
  1. "USRP B210 Kit: USB 3.0 (bus max 3.2Gb/s) for xfer ~60 MSym/sec, 56
MHz bandwidth 1x1 / 32 MHz 2x2 MIMO bandwidth, 70 MHz to 6 GHz
frequency range, flexible rate 12bit ADC/DAC, 2 TX and 2 RX full or
half duplex channels (4 total), Xilinx Spartan 6 XC6SLX150 FPGA"

@_date: 2013-08-29 04:22:19
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
i should have mentioned:
metro Ethernet or municipal run fiber networks with peering are the
best option for mesh traffic relaying like this. ATM is too expensive;
IDSN, despite a proud origin story of the first data mix networks, is
also expensive, and super slow.
get rooftop access for radios in a Fresnel friendly internet exchange
where you can simply forward traffic down a few floors over Ethernet
and you're in the best of positions.
consumer fiber to the home would be great, if ToS restrictions didn't
make such forwarding risky.  and the business upgrade for FTTP is
pretty outrageous in almost every case.
you could route through a VPN provider or dedi server of your own in
this case, but tunneling may not be sufficiently covert depending on
the amount of bandwidth used.

@_date: 2013-08-29 21:51:19
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
active attacks are often even more effective at rapid traffic
confirmation and analysis[0]; GPA is pretty tame perhaps!
in any case the challenge you mention: thwarting or preventing traffic
analysis without a full mix of constant traffic. if the datagram based
system above existed, combine with:
- stochastic fair queuing and re-ordering of egress traffic. by
"clamping" the outbound rate of randomized, re-ordered datagrams to a
broad "size/chunk" of capacity, you deter traffic confirmation,
anonymity set reduction, and other traffic analysis attacks of various
- client-side classification of application traffic into prioritized
classes[1] for ingress / dgm proxy level active shaping by classful
HTB queues before transiting the first hop and losing all visibility
into the content and priority of message payloads.
- integrate a lowest effort / unreliable background reliable multicast
like bulk transport channel for resource and key pre-caching, network
participant and performance information distribution, secure remote
archives, random performance measurement/tests across peer groups,
other low priority communications suited for this "filler" class of
traffic. (consuming more or less filler traffic helps smooth out the
effective throughput and efficiency when changing the broad
"stochastic traffic capacity range" appropriate for a given peer.)
- provide LEDBAT or AQM management of edge traffic to upstream(s) to
prevent unnecessary latency in upstream buffers. this ensures that
even at full utilization the responsiveness of the broadband link is
- and the multi-path SCTP, IPsec, UDP NAT traversal and encapsulation,
and other user space network stacks communicating across this overlay
network as discussed above for requisite application and control
communication support.
these techniques combined allow you to use still not insignificant
"stochastic traffic capacity ranges" instead of a constant fixed
amount of traffic to protect against these attacks.  these stochastic
ranges can be adjusted up or down as network performance and capacity
dictate. this protocol provides congestion control and TCP
friendliness while greatly reducing the amount of bandwidth consumed
relative to a traditional mix.
at best (in theory), an attacker with local active and global passive
methods on hand could discern anonymity sets for broad categories /
scales of possible communication usage.  E.g. anon set A exhibits
traffic utilization on the order of 1Mbps to 5Mbps, while anon set B
exhibits traffic utilization on the order of 5Mbps to 50Mbps, and anon
set C exhibits traffic utilization on the order of 50Mbps to 1Gbps,
given this drawback, code a kick ass client with participation enabled
by default if sufficient connectivity and resources are available.
you've now made these broad traffic volume sets nearly useless in a
practical / actionable sense.
congratulations! you've now got a traffic analysis resistant low
latency anonymity protocol, implementation, and network that nearly
anyone can participate in and contribute to. for my next magic hand
wave, a directory / route selection method that scales to billions of
peers while leveraging geographic propinquity and social peer groups
to constrain Sybil attacks and impact of bad actors.
next grow network capacity in a way that continually applies implicit
feedback from the network overall and peers directly and your
deterrence to these attacks begins to improve further over time,
perhaps even one day hitting a tipping point of prevalence and
persistence for de-facto victory in most threat models...
we can dream!
perhaps someone should toss up a Bitcoin donation address to support
work on detailed technical specifications, experimental prototypes,
maintaining clouds for continuous builds, regression checks, load
tests, and traffic analysis for quality measurement and security
could also use donations for bounties for identifying or exploiting
security or privacy vulnerabilities in the design and implementation
of this final generation anonymous network.  whoever sets this up
should probably use an onion to coordinate development and distribute
sources, other resources...
calling all "tup" s, ...  ;P
0. "From a Trickle to a Flood: Active Attacks on Several Mix Types"
  1. i have mentioned the following classes before, with each in
priority order for the HTB prioritization / shaping before traffic
enters the network and becomes opaque:
 a. control and signalling traffic - always takes precedence.
 b. real-time and interactive communications, but not video.
 c. real-time video communication, if applicable.
 d. low priority bulk communication.  torrents, archives, opportunistic caching
 e. filler / last-tier best effort unreliable traffic as mentioned
above for filling in the remaining capacity at the current stochastic
rx/tx rate center point.
2.  instead of trying to research and author formal proofs of entropy
bounds for various idealized models, cut straight to the chase and
build the most aggressive, best in class developmental learning / deep
learning systems for classification and identification of nodes,
flows, protocols, identities in a test bed setup that provides full
traffic visibility and active client edge MitM capability (E.g.
simulate attack via rogue AP or cell tower for tagging? selective DoS?
others,).  malicious attacks performed by the remote end or injected
by remote's upstream are not in scope for this traffic analysis and
privacy assessment. however, passive capture of all exit
communications and ORCHID hidden endpoint communications is in scope
for analysis.
then, see how effective this best scenario and tools attack is against
a running implementation.  did it fail catastrophically in flames or
break wide open with trivial effort?  keep improving...
respectably hardened against the most aggressive machine learning and
malicious active attacks you could conceive of and build?  great! have
a beer and then find the people who see the oversights and blind spots
you don't.  keep improving... rinse, repeat, ...

@_date: 2013-08-30 12:19:39
@_author: coderman 
@_subject: [Cryptography] The Case for Formal Verification 
this is the crux; where the human meets the machine is always a large,
evolving, complicated attack surface. e.g. usability and design level
requirements and behavior.
in the order of precedence of security risks, much bigger holes must
be addressed before formal verification provides return on time
if you're building verified compilers, or micro kernels, or core
libraries, this doesn't apply to you. ;)
i want seL4 in a Qubes isolation model, formally verified CryptoBox,
this makes no sense to me; patently absurd on the face of it.
why test code with clusters that are larger than your build systems?
why do we exist? ...
utility of quality measures can not be judged on superficial metrics
like "size in GB" or "processor hours".  anyone using this argument as
a disqualifier is not qualified to make such an assessment.
this is a great approach and fits in well with other security through
isolation defense in depth.  combining the strengths of formal
verification at critical core points within a system, and then
leveraging that robust core to isolate, constrain, mediate between
higher level applications seem most reasonable, tractable, with the
best return on time invested.
if i had a wishlist it would be:
- 64bit CompCert (not just 64bit int support :)
- verified virtualization isolation model (seL4 Qubes like system?)
- verified crypto_sign_edwards25519sha512batch and
crypto_sign_nistp256sha512ecdsa implementations
- verified compression, regexp, and other common libraries that are
useful at the security boundary between isolated domains or
some of the work done for quark might be partially applicable to some
of the above, but most of the verification is browser specific
(related to things like messaging and tab isolation, proper cookie
handling, socket communication, etc.)
where's the github for Coq kernels?
some other good resources:
ProofWeb:  particularly the courses available for the online interface to Coq.
frama-c:  i just came across this, it looks quite useful, but have not used it
in any depth yet...
Lemma stating_the_obvious:
 (* formal verification as a useful component of defense in depth is
self-evident *)
The future is here. It's just not widely distributed yet.

@_date: 2013-08-30 12:19:39
@_author: coderman 
@_subject: [Cryptography] The Case for Formal Verification 
this is the crux; where the human meets the machine is always a large,
evolving, complicated attack surface. e.g. usability and design level
requirements and behavior.
in the order of precedence of security risks, much bigger holes must
be addressed before formal verification provides return on time
if you're building verified compilers, or micro kernels, or core
libraries, this doesn't apply to you. ;)
i want seL4 in a Qubes isolation model, formally verified CryptoBox,
this makes no sense to me; patently absurd on the face of it.
why test code with clusters that are larger than your build systems?
why do we exist? ...
utility of quality measures can not be judged on superficial metrics
like "size in GB" or "processor hours".  anyone using this argument as
a disqualifier is not qualified to make such an assessment.
this is a great approach and fits in well with other security through
isolation defense in depth.  combining the strengths of formal
verification at critical core points within a system, and then
leveraging that robust core to isolate, constrain, mediate between
higher level applications seem most reasonable, tractable, with the
best return on time invested.
if i had a wishlist it would be:
- 64bit CompCert (not just 64bit int support :)
- verified virtualization isolation model (seL4 Qubes like system?)
- verified crypto_sign_edwards25519sha512batch and
crypto_sign_nistp256sha512ecdsa implementations
- verified compression, regexp, and other common libraries that are
useful at the security boundary between isolated domains or
some of the work done for quark might be partially applicable to some
of the above, but most of the verification is browser specific
(related to things like messaging and tab isolation, proper cookie
handling, socket communication, etc.)
where's the github for Coq kernels?
some other good resources:
ProofWeb:  particularly the courses available for the online interface to Coq.
frama-c:  i just came across this, it looks quite useful, but have not used it
in any depth yet...
Lemma stating_the_obvious:
 (* formal verification as a useful component of defense in depth is
self-evident *)
The future is here. It's just not widely distributed yet.

@_date: 2013-08-30 21:36:31
@_author: coderman 
@_subject: Lavabit and End-point Security 
a good presentation which suggests this technique, among other useful ideas:
"Attack Driven Defense"

@_date: 2013-08-31 18:23:11
@_author: coderman 
@_subject: So I discovered that my HP laptop leaks/transmits its built-in 
pretty interesting; xmits continuously when powered. during POST, no
effect if on/off/disabled in BIOS.

@_date: 2013-08-06 13:00:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
this is the most informative and useful post ever made in the
al-qaeda.net discussion...  which happens to be the most ridiculous
discussion full of fear and weakness.
cypherpunks afraid of a domain name...  wtf

@_date: 2013-08-06 13:00:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
this is the most informative and useful post ever made in the
al-qaeda.net discussion...  which happens to be the most ridiculous
discussion full of fear and weakness.
cypherpunks afraid of a domain name...  wtf

@_date: 2013-08-07 10:02:11
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
it is related to the list in the sense of embracing epithets and
culling the useless.
you've provided this reasoning in measured fashion and various tone
repeatedly; believe me when i say i understand exactly what you are
concerned about and why you consider this unreasonable.
let me be equally clear: cryptography, privacy, and anonymity
discussions under any name and forum are appropriate. to censor the
medium or message out of fear of misunderstanding is akin to never
exercising rights and liberties for fear they may cause scrutiny and
if this is you: so concerned about unwanted attention, that you'll
always consent to a search of your person without resistance, that
you'll always hand over keys to your system or provide access to your
devices and equipment upon mere request, perhaps when crossing
borders, just so you avoid "trouble".
if this is you: what the fuck are you doing on a cypherpunks list?
cypherpunks write code, especially privacy and anonymity code, which
is a much more contentious endeavor than what you are cowed by.  this
is an impasse, where we agree to disagree.
P.S. if you do operate from a truly backward and hostile domain where
such a keyword alone is grounds for harassment then you're likely
already sub'd via remailers and proxies and multi-hops oh my...

@_date: 2013-08-07 10:02:11
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
it is related to the list in the sense of embracing epithets and
culling the useless.
you've provided this reasoning in measured fashion and various tone
repeatedly; believe me when i say i understand exactly what you are
concerned about and why you consider this unreasonable.
let me be equally clear: cryptography, privacy, and anonymity
discussions under any name and forum are appropriate. to censor the
medium or message out of fear of misunderstanding is akin to never
exercising rights and liberties for fear they may cause scrutiny and
if this is you: so concerned about unwanted attention, that you'll
always consent to a search of your person without resistance, that
you'll always hand over keys to your system or provide access to your
devices and equipment upon mere request, perhaps when crossing
borders, just so you avoid "trouble".
if this is you: what the fuck are you doing on a cypherpunks list?
cypherpunks write code, especially privacy and anonymity code, which
is a much more contentious endeavor than what you are cowed by.  this
is an impasse, where we agree to disagree.
P.S. if you do operate from a truly backward and hostile domain where
such a keyword alone is grounds for harassment then you're likely
already sub'd via remailers and proxies and multi-hops oh my...

@_date: 2013-08-07 20:35:13
@_author: coderman 
@_subject: [cryptography] a Cypherpunks comeback 
why the false dichotomy? do them both!
i also hear he was also a ginger lacking a soul...
are you stating that "So, say goodnight to Joshua ..." in the context
of a perceived threat against an individuals family is on the same
level of offense as a domain name? really?
all the more reason to resist self censorship and cowardice!
now _this_ is a discussion worthy of the list. and there are lots of ideas :P
"embracing epithets and culling the useless."
i am indefensible and unreasonable; let's keep me out of this!
  on that note a few resources and projects to make this tirade not
entirely useless:
"Selected Papers in Anonymity"
 [why does this not have an HTTPS URL?]
"Bibliography - GNU's Framework for Secure Peer-to-Peer Networking"
"Project Byzantium"
 [why does this not have an HTTPS URL?]
"Dust: A Censorship-Resistant Internet Transport Protocol"
"The Anykernel and Rump Kernels"

@_date: 2013-08-09 15:59:38
@_author: coderman 
@_subject: [cryptography] NSA Today on Missions, Authorities, Oversight, 
some interesting stats, also interesting copy / paste behavior:
"Scope and Scale of NSA Collection
According to figures published by a major tech provider, the Internet
carries 1,826 Petabytes of
information per day. In its foreign intelligence mission, NSA touches
about 1.6% of that. However,
of the 1.6% of the data, only 0.025% is actually selected for review.
The net effect is that NSA
part in a million. Put another way, if a standard basketball court
represented the global
FRPPXQLFDWLRQVHQYLURQPHQW16$VWRWDO collection would be
represented by an area smaller than a
dime on that basketball court."
to read:
Scope and Scale of NSA Collection
According to figures published by a major tech provider, the Internet
carries 1,826 Petabytes of
information per day. In its foreign intelligence mission, NSA touches
about 1.6% of that. However,
of the 1.6% of the data, only 0.025% is actually selected for review.
The net effect is that NSA
analysts look at 0.00004% of the world's traffic in conducting their
mission - that's less than one
part in a million. Put another way, if a standard basketball court
represented the global
communications environment, NSA's total collection would be
represented by an area smaller than a
dime on that basketball court.
again we see the fallacy of "not a search/collection until reviewed by
an analyst."...

@_date: 2013-08-10 15:50:42
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
this is the kind of messaging i would use - leaving all the
complexities and drawbacks of traditional email behind.
and StealthMonger: while the theory and design of latest generation
anonymous remailers are suitable for secure mail, the practical
realities render them unusable.
effort on real-time protocols that can defend against traffic
analysis, or other non-email systems like pond would be better spent.

@_date: 2013-08-11 02:27:54
@_author: coderman 
@_subject: Lavabit and End-point Security 
i've been contemplating a write up about this, but the problem is once
you advertise your methods they become less effective.
there really is "security through obscurity" in this sense; when at a
resource disadvantage, every little bit counts...
if i were to summarize what i have found effective against dedicated
and resourceful attackers (again, i can't go into details :) this
would be the top 5:
1. use a common distro, but rebuild critical components - bootloader,
initramfs, openssl, openssh, the kernel, gnutls, libgmp, use 64bit,
2. use isolation and RBAC, Qubes, VirtualBox, VMWare, Parallels,
remember that VM escapes are available and expected. defense in depth
can never be too deep.
3. use constrained network access - identify anomalies, control
bandwidth, firewall ingress and egress aggressively. this implies
constant monitoring to detect such events. (another exercise left to
the reader)
4. rootkit and backdoor your own systems - use the dirty tricks to
observe and constrain your system before someone else uses dirty
tricks to compromise your system.
5. don't forget physical security - this is the universal oversight
and most effective end run around all other operational and technical
security measures. there is a reason physical access so often implies
"game over" and why black bag jobs are still and will continue to be
effective against all targets.
perhaps more later,

@_date: 2013-08-11 05:45:02
@_author: coderman 
@_subject: Lavabit and End-point Security 
some questions, some answers, ...
this means rebuild hardened versions of these libraries from source;
  excluding insecure cipher suites in an OpenSSL build for example,
  altering architecture optimizations, supported features, in others,
the goal being that an exploit targeted to a vanilla distribution will
more likely fail with observable error or crash, rather than succeed
many exploits are very brittle in this respect, with any change in
symbol offsets or capabilities rendering them completely ineffective.
virtualization implies chained exploits for full compromise. combined
with the above you've drastically increased the cost of a successful
attack with modest effort. the likelihood of detection (by appearing
vulnerable yet not being so) is also increased.
remember that VMMs and hypervisors are themselves potentially
vulnerable software systems suitable for hardening and customization.
data exfiltration can be very visible via network behavior if you're
paying attention.  cross referencing connection state in your upstream
router vs. local OS view of sockets can identify discrepancies where
compromise has concealed covert connections. malware communicating
directly on an ethernet or wireless adapter outside of the OS is also
visible at this junction.
this is mostly a variant of  at a kernel / system level.  like
notepad.exe connecting to the internet, there are some syscall, file
access, and network requests which are clearly anomalous and
indicators of compromise.
this is a storied tangent unto itself...
last but not least: you must develop a routine of continuous hardening
and improvement. these steps are not done once and finished; they are
elements within a larger strategy of operational rigor defending
against motivated and capable attackers. asking for my "hardened linux
build" is missing the point entirely!

@_date: 2013-08-11 13:28:53
@_author: coderman 
@_subject: Lavabit and End-point Security 
one last cautionary tale:
some time back i used the techniques discussed to harden some Android
phones brought with me into a hostile environment. i had kernel level
protections in place, hardened the system configuration and services,
pared down apps to the minimum and constrained their access to the
file system and network. this was months of effort.
the first adversarial encounter went very well in my favor - all of
the attempts to exploit my devices were thwarted at these various
layers and via these protections, with the sole exception of a Google
Voice Search hack that kept voice search active in an "open mic night"
eavesdropping capability.  this was quickly nullified via kill -STOP
(Android won't re-spawn an app that is already running, and a stopped
process proved quite effective at halting this repeated invocation of
search used to capture audio.)
fast forward to round two, and i doubled down on the kernel, system,
and application level protections. even more scrutiny is applied to
applications to avoid the misuse of legitimate functionality for
malicious purpose.  i am feeling confident!
... and then a baseband exploit easily walks under all of my
protections at every layer, completely and fully 0wning my devices,
with the only hint at anything amiss being the elevated thermal
dissipation and power consumption from the radios performing data
transmission, all while the Android OS believed the devices were
silent in airplane mode.
[informative interlude: software defined transceivers should be in
every hacker toolbox; radio level attacks are otherwise invisible to
you. they are also useful for many other purposes, perhaps one day
even providing a solution to the untrustworthy proprietary firmware
and baseband systems crammed into every mobile device these days.]
incidentally, this also demonstrates why IOMMU / VT-d guest isolation
of devices on the host bus is very useful, as a vulnerable NIC could
otherwise provide complete access to privileged memory and interfaces
just like the baseband exploit above...  assuming your CPU itself is
"trusting trust" continues to be a persistent and difficult problem,
leaving us all vulnerable to some degree or another - it's just a
function of cost and skill to compromise.  turtles all the way down!

@_date: 2013-08-12 14:50:26
@_author: coderman 
@_subject: Lavabit and End-point Security 
"I'm sorry. My responses are limited. You must ask the right questions."
weaponized baseband exploits are difficult, expensive, architecture
specific, and not used capriciously.
this, among other reasons, is why there is such a dearth of
information on them despite being proven exploitable with a wide
attack surface for many years.
Rupp said state-sponsored attackers are already using baseband
processor attacks in airports but declined to go into details beyond
saying that attacks could be carried out without the need to trick
smartphones owners into opening an email or visiting a malicious
website. Attacks might involve building a rogue GSM base-station from
commodity hardware or run from the infrastructure of a 'co-operative"
telco. It might also be possible to run attacks against baseband
processors of phones using Wi-Fi or Bluetooth interfaces, according to
GSMK Cryptophone.
"Once you have control over the app CPU, you can in principle use that
to load any code you want from the network," Rupp explained. "Since
you have already successfully escalated your privileges on the system,
no user interaction is necessary."
"Baseband Attacks: Remote Exploitation of Memory Corruptions in
Cellular Protocol Stacks"
"Anatomy of contemporary GSM cellphone hardware"
"Cellular baseband security"
"Run-time firmware integrity verification: what if you can't trust
your network card"

@_date: 2013-08-17 20:17:11
@_author: coderman 
@_subject: Is the Wikileaks Party a cypherpunk party? 
i read this as: "i would rather smash my thumb with a hammer than
stick my dick in a lamp socket"

@_date: 2013-08-23 21:46:12
@_author: coderman 
@_subject: [liberationtech] NSA Admits: Okay, Okay, There Have Been A Bunch 
oh god this alone makes it all worth it,,, thank you Snowden!
P.S. setup a bitcoin donation address.
best regards,

@_date: 2013-08-24 00:41:34
@_author: coderman 
@_subject: [liberationtech] NSA Admits: Okay, Okay, There Have Been A Bunch 
indeed; this codename gives the lie to all the congressional
testimony, to all the claims of controls and judiciary oversight, to
all the attestations of full compliance.
it's beautiful in laying bare the capriciousness to which the entire
intelligence juggernaut can be brought to bear against arbitrary
individuals; personal pettiness more than sufficient.

@_date: 2013-08-25 13:21:32
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_=5Bliberationtech=5D_Why_can=92t_email_be_secure=3F_=2D_?= 
it is a question of private vs. public communication.
email is and will continue to be useful for public communication. this
gmail account indexes 190+ lists, 10,000 news alerts from scores of
filters (everything from "TS//SI//NF" to "Flame OR Gauss OR Duqu OR
Stuxnet" to GoldreichGoldwasserHalevi), a total of 643,132 pieces of
communication. i can search through all of it in seconds and apply new
filters to existing content just as easily as new, and keep an offline
backup just in case.
but there is zero i would consider private; for that use a medium of
communication that is not a usability failure, that is not a metadata
leakage nightmare, that is not an operational security mine field.
let email _for private communication_ die already, please!

@_date: 2013-08-25 13:40:38
@_author: coderman 
@_subject: [liberationtech] Why_can't_email_be_secure 
and to StealthMonger's point about latest generation mix networks for
best privacy, why not instead focus on building low latency protocols
that are resistant to traffic analysis and confirmation?
make them datagram based; utilize user space stacks and latest
research.  solving the low latency datagram anonymity problem enables
existing usable private communication with the additional benefit of
endpoint and peer anonymity.
i believe this possible to make useful, even if never infallible.
certainly more possible than the odds of making truly scalable,
available, and _usable_ mix mailer networks and clients for the
most important: make this low latency infrastructure usable and cross
platform, so the implementations are easily adopted... like Napster
and BitTorrent back in the day. ;)

@_date: 2013-08-25 17:31:24
@_author: coderman 
@_subject: =?windows-1252?Q?Re=3A_=5Bliberationtech=5D_Why_can=92t_email_be_secure=3F_=2D_?= 
the battle very weighted toward one's favor, however,
 it is fun to try!
    ;)

@_date: 2013-08-25 18:13:11
@_author: coderman 
@_subject: NSLs, gag-orders, code-changes, coerced backdoors - any tech 
replicate broadcast functionality (most suited to wireless
transmissions) in the unicast datagram model and you have p2p that
doesn't scale. remember first gen gnutella?

@_date: 2013-08-26 00:55:11
@_author: coderman 
@_subject: [liberationtech] Why_can't_email_be_secure 
the best kind of problems!
correct. i mention them as a prerequisite for both protection and usability.
protection for example, with end-to-end SCTP multi-homed endpoints via
userspace stacks would avoid predecessor attacks - if you block one
route there are others which transit traffic, maintaining an
uninterrupted session across otherwise individually volatile paths.
usability for example to support UDP traffic and applications which
are not currently served via TCP and connection oriented services.
sadly, even TCP re-invented in user space is insufficient. you want a
specific protocol implementation of multi-homed SCTP in userspace,
probably on top of other protocol supports like LEDBAT or AQM. perhaps
using ORCHID IPv6 identifiers for endpoint addressing. lot's of
options; and as you said: it's a hard problem!
this is a separate problem. for the core transport encapsulation in
UDP may be sufficient. for censorship avoidance you will likely need
to bounce over a DUST like path first to access such an anonymizing
network. topology is an interesting subject, as the design must be
decentralized but may not need to be homogenous.
you want variable latency at the datagram level (e.g. stochastic
reordering and shaping of traffic, with prioritization done at the
endpoint where flows are visible.) more than the utmost in
performance. as long as it is overall TCP fair of course :)
and this is just the start. we haven't touched on network discovery,
path awareness/selection/weighting, etc.  as you said, hard problems;
the best kind of problems!

@_date: 2013-08-29 04:07:51
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
i should clarify:
the mode of operation for this presumed design and implementation is
to have SOCKS, HTTP, HTTPS, transparent UDP, transparent TCP,
transparent DNS (this is indeed different than just UDP :), and some
subset of transparent ICMP proxy support on the client / node.  you
could configure proxy settings, direct traffic to the trans ports, or
perform queries directly against the DNS port of the running real time
datagram mixer instance.
at the exits for public traffic or at the private ORCHID based
"hidden/overlay" endpoints, you transit these same protocols, per
advertised support in exit policy or overlay service capability
on the wire, you would be sending UDP datagrams that encapsulate the
NAT busting IPsec telescope containing path data, multi-path SCTP in
userspace for reliable TCP stream transport over the datagram overlay.
for all intents and purposes these packets would look like AH/ESP or
CryptoBox wrapped opaque cipher texts in some standard UDP
as for ATM, SONET, satellite data terminals, metro wireless, and all
other unusual or exotic transports: these are likely not useful for
the core network unless directly public UDP IPv4 reachable.
censorship bypass, non-node capable devices like phones, or very poor
network connectivity situations, would require other transports and
protocols for this initial tunnel into the overall real-time datagram
mix-like network.  in this context, the varied physical layers and
logical paths in a given metro region operating beneath IP routing can
play a role in passing traffic from suppressed/blocked users out to
the broader mesh or internet at large.
devices and users communicating via obfuscated links into the dgm
network do not have traffic analysis protections like full
participants.  despite this lack of stronger anonymity, the actors
observing at the edge can only note that you are tunneling into the
public network, and utilizing some stochastic gradient of bandwidth in
aggregate for some period of time.
this is still not much information, especially compared to the current
state of affairs!
there are many complications and constraints around how this would
work - i make it sound so easy ;)
  however, you could provide such services, including wireless metro
area mesh or p-to-mp distribution networks, constrained by propinquity
and referral by reputation, in combination with broadband internet
uplink of a more traditional sort where available.
and in fact, using multiple paths / transports concurrently provides
advantage for data continuity and throughput despite volatile and
changing upstream link availability on an individual basis to
particular gateway or router or access point devices.
metro area mesh benefits nicely from some backhaul ad-hoc or fixed
plant high capacity point-to-point links over distance with short IP
routes; there is a good paper from early 2000's about using atheros
802.11a devices with a custom tertiary firmware and host driver to
bond eight devices into a single point-to-point link with an aggregate
throughput over three or four hundred megabit a second in transport
rate... or so i recall.  IPoATM on a OC12 or bigger to an internet
provider would absolutely be useful as an upstream sink within such a
i would love to see high degree mesh optimizer p-to-mp nodes applying
the latest high bit rate software defines radios for  backhaul and
security.  isolate each radio like a Pervices Noctar[0] or USRP B210
[1] into its own guest and isolate devices with VT-d enforced memory
access boundaries.  you may even put more than one device in a single
SDR Backhaul Guest VM if doing large-QAM or other complex MIMO
front-ends and signal processing.
i could go on, but alas, i've got code to write...  *grin*
0. "Noctar: 8Gbps, low latency, PCIe x4 bus, 250MHz bandwidth, full
duplex, RF frontend 100kHz  4GHz, Two, 12 bit, 125 MSPS ADCs, Dual
channel, 16 bit, 250 MSPS DAC, 20MHz, 0.28ppm, reference TCXO, Altera
Cyclone IV EP4CGX22C FPGA"
  1. "USRP B210 Kit: USB 3.0 (bus max 3.2Gb/s) for xfer ~60 MSym/sec, 56
MHz bandwidth 1x1 / 32 MHz 2x2 MIMO bandwidth, 70 MHz to 6 GHz
frequency range, flexible rate 12bit ADC/DAC, 2 TX and 2 RX full or
half duplex channels (4 total), Xilinx Spartan 6 XC6SLX150 FPGA"

@_date: 2013-08-29 04:22:19
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
i should have mentioned:
metro Ethernet or municipal run fiber networks with peering are the
best option for mesh traffic relaying like this. ATM is too expensive;
IDSN, despite a proud origin story of the first data mix networks, is
also expensive, and super slow.
get rooftop access for radios in a Fresnel friendly internet exchange
where you can simply forward traffic down a few floors over Ethernet
and you're in the best of positions.
consumer fiber to the home would be great, if ToS restrictions didn't
make such forwarding risky.  and the business upgrade for FTTP is
pretty outrageous in almost every case.
you could route through a VPN provider or dedi server of your own in
this case, but tunneling may not be sufficiently covert depending on
the amount of bandwidth used.

@_date: 2013-08-29 21:51:19
@_author: coderman 
@_subject: UDP/datagram/cell based networks [was: Why_can't_email_be_secure] 
active attacks are often even more effective at rapid traffic
confirmation and analysis[0]; GPA is pretty tame perhaps!
in any case the challenge you mention: thwarting or preventing traffic
analysis without a full mix of constant traffic. if the datagram based
system above existed, combine with:
- stochastic fair queuing and re-ordering of egress traffic. by
"clamping" the outbound rate of randomized, re-ordered datagrams to a
broad "size/chunk" of capacity, you deter traffic confirmation,
anonymity set reduction, and other traffic analysis attacks of various
- client-side classification of application traffic into prioritized
classes[1] for ingress / dgm proxy level active shaping by classful
HTB queues before transiting the first hop and losing all visibility
into the content and priority of message payloads.
- integrate a lowest effort / unreliable background reliable multicast
like bulk transport channel for resource and key pre-caching, network
participant and performance information distribution, secure remote
archives, random performance measurement/tests across peer groups,
other low priority communications suited for this "filler" class of
traffic. (consuming more or less filler traffic helps smooth out the
effective throughput and efficiency when changing the broad
"stochastic traffic capacity range" appropriate for a given peer.)
- provide LEDBAT or AQM management of edge traffic to upstream(s) to
prevent unnecessary latency in upstream buffers. this ensures that
even at full utilization the responsiveness of the broadband link is
- and the multi-path SCTP, IPsec, UDP NAT traversal and encapsulation,
and other user space network stacks communicating across this overlay
network as discussed above for requisite application and control
communication support.
these techniques combined allow you to use still not insignificant
"stochastic traffic capacity ranges" instead of a constant fixed
amount of traffic to protect against these attacks.  these stochastic
ranges can be adjusted up or down as network performance and capacity
dictate. this protocol provides congestion control and TCP
friendliness while greatly reducing the amount of bandwidth consumed
relative to a traditional mix.
at best (in theory), an attacker with local active and global passive
methods on hand could discern anonymity sets for broad categories /
scales of possible communication usage.  E.g. anon set A exhibits
traffic utilization on the order of 1Mbps to 5Mbps, while anon set B
exhibits traffic utilization on the order of 5Mbps to 50Mbps, and anon
set C exhibits traffic utilization on the order of 50Mbps to 1Gbps,
given this drawback, code a kick ass client with participation enabled
by default if sufficient connectivity and resources are available.
you've now made these broad traffic volume sets nearly useless in a
practical / actionable sense.
congratulations! you've now got a traffic analysis resistant low
latency anonymity protocol, implementation, and network that nearly
anyone can participate in and contribute to. for my next magic hand
wave, a directory / route selection method that scales to billions of
peers while leveraging geographic propinquity and social peer groups
to constrain Sybil attacks and impact of bad actors.
next grow network capacity in a way that continually applies implicit
feedback from the network overall and peers directly and your
deterrence to these attacks begins to improve further over time,
perhaps even one day hitting a tipping point of prevalence and
persistence for de-facto victory in most threat models...
we can dream!
perhaps someone should toss up a Bitcoin donation address to support
work on detailed technical specifications, experimental prototypes,
maintaining clouds for continuous builds, regression checks, load
tests, and traffic analysis for quality measurement and security
could also use donations for bounties for identifying or exploiting
security or privacy vulnerabilities in the design and implementation
of this final generation anonymous network.  whoever sets this up
should probably use an onion to coordinate development and distribute
sources, other resources...
calling all "tup" s, ...  ;P
0. "From a Trickle to a Flood: Active Attacks on Several Mix Types"
  1. i have mentioned the following classes before, with each in
priority order for the HTB prioritization / shaping before traffic
enters the network and becomes opaque:
 a. control and signalling traffic - always takes precedence.
 b. real-time and interactive communications, but not video.
 c. real-time video communication, if applicable.
 d. low priority bulk communication.  torrents, archives, opportunistic caching
 e. filler / last-tier best effort unreliable traffic as mentioned
above for filling in the remaining capacity at the current stochastic
rx/tx rate center point.
2.  instead of trying to research and author formal proofs of entropy
bounds for various idealized models, cut straight to the chase and
build the most aggressive, best in class developmental learning / deep
learning systems for classification and identification of nodes,
flows, protocols, identities in a test bed setup that provides full
traffic visibility and active client edge MitM capability (E.g.
simulate attack via rogue AP or cell tower for tagging? selective DoS?
others,).  malicious attacks performed by the remote end or injected
by remote's upstream are not in scope for this traffic analysis and
privacy assessment. however, passive capture of all exit
communications and ORCHID hidden endpoint communications is in scope
for analysis.
then, see how effective this best scenario and tools attack is against
a running implementation.  did it fail catastrophically in flames or
break wide open with trivial effort?  keep improving...
respectably hardened against the most aggressive machine learning and
malicious active attacks you could conceive of and build?  great! have
a beer and then find the people who see the oversights and blind spots
you don't.  keep improving... rinse, repeat, ...

@_date: 2013-08-30 12:19:39
@_author: coderman 
@_subject: [Cryptography] The Case for Formal Verification 
this is the crux; where the human meets the machine is always a large,
evolving, complicated attack surface. e.g. usability and design level
requirements and behavior.
in the order of precedence of security risks, much bigger holes must
be addressed before formal verification provides return on time
if you're building verified compilers, or micro kernels, or core
libraries, this doesn't apply to you. ;)
i want seL4 in a Qubes isolation model, formally verified CryptoBox,
this makes no sense to me; patently absurd on the face of it.
why test code with clusters that are larger than your build systems?
why do we exist? ...
utility of quality measures can not be judged on superficial metrics
like "size in GB" or "processor hours".  anyone using this argument as
a disqualifier is not qualified to make such an assessment.
this is a great approach and fits in well with other security through
isolation defense in depth.  combining the strengths of formal
verification at critical core points within a system, and then
leveraging that robust core to isolate, constrain, mediate between
higher level applications seem most reasonable, tractable, with the
best return on time invested.
if i had a wishlist it would be:
- 64bit CompCert (not just 64bit int support :)
- verified virtualization isolation model (seL4 Qubes like system?)
- verified crypto_sign_edwards25519sha512batch and
crypto_sign_nistp256sha512ecdsa implementations
- verified compression, regexp, and other common libraries that are
useful at the security boundary between isolated domains or
some of the work done for quark might be partially applicable to some
of the above, but most of the verification is browser specific
(related to things like messaging and tab isolation, proper cookie
handling, socket communication, etc.)
where's the github for Coq kernels?
some other good resources:
ProofWeb:  particularly the courses available for the online interface to Coq.
frama-c:  i just came across this, it looks quite useful, but have not used it
in any depth yet...
Lemma stating_the_obvious:
 (* formal verification as a useful component of defense in depth is
self-evident *)
The future is here. It's just not widely distributed yet.

@_date: 2013-08-30 12:19:39
@_author: coderman 
@_subject: [Cryptography] The Case for Formal Verification 
this is the crux; where the human meets the machine is always a large,
evolving, complicated attack surface. e.g. usability and design level
requirements and behavior.
in the order of precedence of security risks, much bigger holes must
be addressed before formal verification provides return on time
if you're building verified compilers, or micro kernels, or core
libraries, this doesn't apply to you. ;)
i want seL4 in a Qubes isolation model, formally verified CryptoBox,
this makes no sense to me; patently absurd on the face of it.
why test code with clusters that are larger than your build systems?
why do we exist? ...
utility of quality measures can not be judged on superficial metrics
like "size in GB" or "processor hours".  anyone using this argument as
a disqualifier is not qualified to make such an assessment.
this is a great approach and fits in well with other security through
isolation defense in depth.  combining the strengths of formal
verification at critical core points within a system, and then
leveraging that robust core to isolate, constrain, mediate between
higher level applications seem most reasonable, tractable, with the
best return on time invested.
if i had a wishlist it would be:
- 64bit CompCert (not just 64bit int support :)
- verified virtualization isolation model (seL4 Qubes like system?)
- verified crypto_sign_edwards25519sha512batch and
crypto_sign_nistp256sha512ecdsa implementations
- verified compression, regexp, and other common libraries that are
useful at the security boundary between isolated domains or
some of the work done for quark might be partially applicable to some
of the above, but most of the verification is browser specific
(related to things like messaging and tab isolation, proper cookie
handling, socket communication, etc.)
where's the github for Coq kernels?
some other good resources:
ProofWeb:  particularly the courses available for the online interface to Coq.
frama-c:  i just came across this, it looks quite useful, but have not used it
in any depth yet...
Lemma stating_the_obvious:
 (* formal verification as a useful component of defense in depth is
self-evident *)
The future is here. It's just not widely distributed yet.

@_date: 2013-08-30 21:36:31
@_author: coderman 
@_subject: Lavabit and End-point Security 
a good presentation which suggests this technique, among other useful ideas:
"Attack Driven Defense"

@_date: 2013-08-31 18:23:11
@_author: coderman 
@_subject: So I discovered that my HP laptop leaks/transmits its built-in 
pretty interesting; xmits continuously when powered. during POST, no
effect if on/off/disabled in BIOS.

@_date: 2013-12-02 00:11:10
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
 Full Disclosure this, in the traditional sense, is what John calls a "COMSEC cover-up":
 meaning that the continual, most significant, and most likely to be
abused and widely are commercial services and collaborations and
  where the product is your private information of any sort, that you
usually unwittingly but sometimes capriciously yield to un trustworthy
third parties with little constraint on secondary distribution for
money to further removed stranger parties...
note that fully decentralized, end-to-end secured, with properly
managed keying and sessions capable technologies are resistant to
these third-party weaknesses and vulnerabilities.
crypto and comms and computing technology should not be abandoned en
whole like the russians for their manual type writers, but the minimum
required operational safety of any information processing system needs
huge innovation to get from current systems to something effective and
usable...  hey look, it's more of those fun problems to solve again ;)
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:10
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
 Full Disclosure ,
 cpunks regarding the inability for NSA employees to report ethical violations
in a manner that did not assure retribution:
this is actually a somewhat difficult anonymity / privacy question in
the context of highly compartmented information and operations, where
knowledge of a subset of specific details is sufficient to imply
strong suspicion and scrutiny to a very small number of individuals...
... assuming you don't circumvent the apparently mediocre constraints
to this information in the information systems that contain it. ;)
while academically interesting, in all practical terms we should
render this question moot and provide absolute communication
origin[0], destination[1], and content[2] privacy to all network users
in all locations under all circumstances guaranteed by constitutional
law, prosecutorial discretion, and practical realities (read:
implementations resistant to Tailored Access Operations like efforts
(NSA TAO / CNE related programs)
this latter guarantee will require a bit more design, coding and deployment,
 fun problems to solve![3]
1.  "peer communication endpoint privacy" - this is a hard problem.
the existing implementations are not usable and insufficiently large
in anonymity set (too few users): zero knowledge high latency mail
like messaging mixes, even if the twitter mixes are pretty cool.
a proper solution would be datagram based, NAT busting, low latency
(read: sufficiently real-time for video and voice), the majority
protocol across the Internet and local intranets and ad-hoc mesh nets
and other networks,
in an implementation that resists all known general purpose (wide
scale) and specialized (highly targeted and/or weaponized bleeding
edge and/or privileged positioned) attacks.
2. strong encryption like: alligator wrapped forward secrecy intended
streams, and equivalent techniques, solve this problem.
  clearly there is much work to do in the implementation and protocol
side of crypto integrity.  very, very much work...
3. "NSA TAO / CNE related programs" resistance is a very tall bar.
they rolled this out at DEF CON, of course. the soon departing .gov
Alexander rolled into town with some world class shit, no doubt...  is
it really going to be 33 years before we can talk about it?  for
better or for worse we won't have Snowden to disclose this
( as he's too classy
to drop dox on specific field operations and highly technical method
and tools information. hmmm...
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:11
@_author: coderman 
@_subject: [Full-disclosure] Intelligence agency subversions and clandestine, 
Full Disclosure ,
 Cypherpunks list On Wed, Oct 2, 2013 at 1:52 AM,
if you're not mad as hell about PRISM, UPSTREAM, BULLRUN, FLYING PIG,
XKEYSCORE, FOXACID, EgotisticalGiraffe, QUICKANT, QuantunInsert,
FRUGAL SHOT, MOTHMONSTER, MULLENIZE, ERRORONEOUSINGENUITY,
FINKDIFFERENT, GREATEXPECTATIONS, VALIDATOR, RAKE, PEDDLE,
PACKETCHEAP, BEACH HEAD, FERRET CANON, PINWALE, MARINA, TRAFFICTHIEF,
REMATION, LACONIC, ENDUE, MANASSAS, DANCINGOASIS, SPINNERET,
MOONLIGHTPATH, ...
 and all the other myriad "exceptionally controlled information",
 then you're beyond reason and redemption...
 ... let's not take a show of hands
 ;P
P.S. the new cypherpunks list has dropped the cypherpunks
for a more benign and powers that be submissive cypherpunks
 ... perhaps it does get past a few more filters? ...
--- fwd:
it doesn't get much more definitive than this retort.. :
[Snowden] felt confident that he had kept the documents secure from
Chinese spies, and that the N.S.A. knew he had done so. His last
target while working as an agency contractor was China...
adding that he had had "access to every target, every active
operation mounted by the N.S.A. against the Chinese. Full lists of
them," he said.
"If that was compromised," he went on, "N.S.A. would have set the
table on fire from slamming it so many times in denouncing the damage
it had caused. Yet N.S.A. has not offered a single example of damage
from the leaks. They haven't said boo about it except "we think,"
"maybe", "have to assume" from anonymous and former officials. Not
"China is going dark." Not "the Chinese military has shut us out."
there is a clear thoughtfulness, moral reasoning, and
conscientiousness repeatedly demonstrated by Snowden in these events.
it is now obvious that history will exonerate him fully.
... the distance between current reactionary retribution and that
future absolution appears to be a bit of a distance, however...
hopefully not too long.
October 17, 2013
Snowden Says He Took No Secret Files to Russia
By JAMES RISEN
WASHINGTON - Edward J. Snowden, the former National Security Agency
contractor, said in an extensive interview this month that he did not
take any secret N.S.A. documents with him to Russia when he fled there
in June, assuring that Russian intelligence officials could not get
access to them.
Mr. Snowden said he gave all of the classified documents he had
obtained to journalists he met in Hong Kong, before flying to Moscow,
and did not keep any copies for himself. He did not take the files to
Russia because it wouldn't serve the public interest," he said.
"What would be the unique value of personally carrying another copy of
the materials onward?" he added.
He also asserted that he was able to protect the documents from
China's spies because he was familiar with that nation's intelligence
abilities, saying that as an N.S.A. contractor he had targeted Chinese
operations and had taught a course on Chinese
"There's a zero percent chance the Russians or Chinese have received
any documents," he said.
American intelligence officials have expressed grave concern that the
files might have fallen into the hands of foreign intelligence
services, but Mr. Snowden said he believed that the N.S.A. knew he had
not cooperated with the Russians or the Chinese. He said he was
publicly revealing that he no longer had any agency documents to
explain why he was confident that Russia had not gained access to
them. He had been reluctant to disclose that information previously,
he said, for fear of exposing the journalists to greater scrutiny.
In a wide-ranging interview over several days in the last week, Mr.
Snowden offered detailed responses to accusations that have been
leveled against him by American officials and other critics, provided
new insights into why he became disillusioned with the N.S.A. and
decided to disclose the documents, and talked about the international
debate over surveillance that resulted from the revelations. The
interview took place through encrypted online communications.
Mr. Snowden, 30, has been praised by privacy advocates and assailed by
government officials as a traitor who has caused irreparable harm, and
he is facing charges under the Espionage Act for leaking the N.S.A.
documents to the news media. In the interview, he said he believed he
was a whistle-blower who was acting in the nation's best interests by
revealing information about the N.S.A.s surveillance dragnet and huge
collections of communications data, including that of Americans.
He argued that he had helped American national security by prompting a
badly needed public debate about the scope of the intelligence effort.
The secret continuance of these programs represents a far greater
danger than their disclosure," he said. He added that he had been more
concerned that Americans had not been told about the N.S.A.s reach
than he was about any specific surveillance operation.
So long as there's broad support amongst a people, it can be argued
there's a level of legitimacy even to the most invasive and morally
wrong program, as it was an informed and willing decision," he said.
However, programs that are implemented in secret, out of public
oversight, lack that legitimacy, and that's a problem. It also
represents a dangerous normalization of governing in the dark, where
decisions with enormous public impact occur without any public input.
Mr. Snowden said he had never considered defecting while in Hong Kong,
nor in Russia, where he has been permitted to stay for one year. He
said he felt confident that he had kept the documents secure from
Chinese spies, and that the N.S.A. knew he had done so. His last
target while working as an agency contractor was China, he said,
adding that he had had access to every target, every active
operation mounted by the N.S.A. against the Chinese. Full lists of
them, he said.
If that was compromised, he went on, N.S.A. would have set the
table on fire from slamming it so many times in denouncing the damage
it had caused. Yet N.S.A. has not offered a single example of damage
from the leaks. They havent said boo about it except we think,
maybe, have to assume from anonymous and former officials. Not
China is going dark. Not the Chinese military has shut us out.
An N.S.A. spokeswoman did not respond Thursday to a request for
comment on Mr. Snowden's assertions.
Mr. Snowden said his decision to leak N.S.A. documents developed
gradually, dating back at least to his time working as a technician in
the Geneva station of the C.I.A. His experiences there, Mr. Snowden
said, fed his doubts about the intelligence community, while also
convincing him that working through the chain of command would only
lead to retribution.
He disputed an account in The New York Times last week reporting that
a derogatory comment placed in his personnel evaluation while he was
in Geneva was a result of suspicions that he was trying to break in to
classified files to which he was not authorized to have access. (The
C.I.A. later took issue with the description of why he had been
reprimanded.) Mr. Snowden said the comment was placed in his file by a
senior manager seeking to punish him for trying to warn the C.I.A.
about a computer vulnerability.
Mr. Snowden said that in 2008 and 2009, he was working in Geneva as a
telecommunications information systems officer, handling everything
from information technology and computer networks to maintenance of
the heating and air-conditioning systems. He began pushing for a
promotion, but got into what he termed a petty e-mail spat in which
he questioned a senior manager's judgment.
Several months later, Mr. Snowden said, he was writing his annual
self-evaluation when he discovered flaws in the software of the
C.I.A.s personnel Web applications that would make them vulnerable to
hacking. He warned his supervisor, he said, but his boss advised him
to drop the matter and not rock the boat. After a technical team also
brushed him off, he said, his boss finally agreed to allow him to test
the system to prove that it was flawed.
He did so by adding some code and text in a nonmalicious manner=94 to
his evaluation document that showed that the vulnerability existed, he
said. His immediate supervisor signed off on it and sent it through
the system, but a more senior manager the man Mr. Snowden had
challenged earlier was furious and filed a critical comment in Mr.
Snowden's personnel file, he said.
He said he had considered filing a complaint with the C.I.A.=92s
inspector general about what he considered to be a reprisal, adding
that he could not recall whether he had done so or a supervisor had
talked him out of it. A C.I.A. spokesman declined to comment on Mr.
Snowden's account of the episode or whether he had filed a complaint.
But the incident, Mr. Snowden said, convinced him that trying to work
through the system would only lead to punishment. He said he knew of
others who suffered reprisals for what they had exposed, including
Thomas A. Drake, who was prosecuted for disclosing N.S.A. contracting
abuses to The Baltimore Sun. (He met with Mr. Snowden in Moscow last
week to present an award to him for his actions.) And he knew other
N.S.A. employees who had gotten into trouble for embarrassing a senior
official in an e-mail chain that included a line, referring to the
Chinese Army, that said, Is this the P.L.A. or the N.S.A.?
Mr. Snowden added that inside the spy agency theres a lot of dissent
 palpable with some, even. But he said that people were kept in line
through fear and a false image of patriotism, which he described as
obedience to authority.
He said he believed that if he tried to question the N.S.A.s
surveillance operations as an insider, his efforts would have been
buried forever, and he would have been discredited and ruined.=94 He
said that the system does not work, adding that you have to report
wrongdoing to those most responsible for it.
Mr. Snowden said he finally decided to act when he discovered a copy
of a classified 2009 inspector generals report on the N.S.A.s
warrantless wiretapping program during the Bush administration. He
said he found the document through a dirty word search, which he
described as an effort by a systems administrator to check a computer
system for things that should not be there in order to delete them and
sanitize the system.
"It was too highly classified to be where it was," he said of the
report. He opened the document to make certain that it did not belong
there, and after he saw what it revealed, curiosity prevailed, he
After reading about the program, which skirted the existing
surveillance laws, he concluded that it had been illegal, he said. =93If
the highest officials in government can break the law without fearing
punishment or even any repercussions at all, he said, secret powers
become tremendously dangerous.
He would not say exactly when he read the report, or discuss the
timing of his subsequent actions to collect N.S.A. documents in order
to leak them. But he said that reading the report helped crystallize
his decision. You cant read something like that and not realize what
it means for all of these systems we have," he said.
Mr. Snowden said that the impact of his decision to disclose
information about the N.S.A. had been bigger than he had anticipated.
He added that he did not control what the journalists who had the
documents wrote about. He said that he handed over the documents to
them because he wanted his own bias divorced from the decision-making
of publication, and that technical solutions were in place to ensure
the work of the journalists couldn't be interfered with."
Mr. Snowden declined to provide details about his living conditions in
Moscow, except to say that he was not under Russian government control
and was free to move around.
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:11
@_author: coderman 
@_subject: [Full-disclosure] Foreign Intelligence Resistant systems [was Re: 
Full Disclosure i must amend this prior advice.
in addition to legal protections, educational support, and competitive programs,
also provide:
- direct and unrestricted backbone access to various individuals or
groups who demonstrate competence in either the educational or
competitive realms, in order for them to mount additional attack
strategies against any reach-able target.  this access must consist of
both passive taps of backbone traffic as well as injection taps for
raw packet transmission at core rates. this should be available on the
Internet backbone at internet exchanges, private fiber through public
right of way, and core networks of operators of licensed wireless
a side benefit of implementing these reforms would be the de-facto
de-funding of offensive network operations by third parties or
governments. the cost to keep ahead of such a widespread, popular, and
distributed effort would be enormous, and provide continually
decreasing returns.
...  getting there is much more complicated of course.   *grin*
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:17
@_author: coderman 
@_subject: [Full-disclosure] ... endpoint security, strong encryption 
cpunks the practical uses are not just authenticity and privacy, but also
censorship avoidance and other availability improvements; c.f.:
"Lightweight Obfuscated Datagram Protocol (LODP)"
  "Elligator [...] introduces a new solution: an encoding for points on
a single curve as strings indistinguishable from uniform random
  encryption for privacy of data at rest can almost be considered a
subset of the problem of encryption for privacy of communication as
and all of the above hinge critically upon effective key management
and usability! which are the things you're most likely to screw up
inconspicuously and completely.
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:18
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
 Full Disclosure an interesting discussion :)
"This is perhaps our last fundamental tradeoff before the Singularity
occurs: Do we, as a society, want the comfort and convenience of
increasingly technologic, invisible digital integration enough to pay
for those benefits with the liberties that must be given up to be
protected from the downsides of that integration?" -- dan
i would argue that there is an alternative in design and architecture,
mainly those which decentralize and protect end-to-end. however, there
is a cost attached to these efforts as well, which so far most opt-out
of paying...
best regards,
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 10:29:05
@_author: coderman 
@_subject: DEF CON cell network attacks 
of course; the complete details will be slow to arrive, not least
because detailed description requires a demonstration in a
reproduction test setup, rather than reporting of actual traffic. :/
that said, useful aspects i'll certainly provide on whim or request.
the defining characteristics of the two types of attacks:
DC19 with DRT:
- "high power on-site", less descriminant attacks. target by and
limited to location.
- MitM for system, application, and protocol level attacks. Evilgrade,
MasterKey vulns, etc.  mostly known and a few 0day escalated attacks.
- favorite attack: "Google Voice Search" always-on eavesdropper
payload; Speex voice from all audible participants.
DC20 with Alexander's toys:
- "in the towers", highly targeted to specific devices, active over
wide metro area.
- baseband exploit vector for device key retrieval, memory and storage
forensics, exfiltration.
- PDoS attacks (bricked secondary devices used as fall back once
identified by call graph; ~20 hours)
- favorite attack: baseband pwn in airplane mode, with ex-filtration
over custom channel.
DC21: no appearance (observed).  speculation ongoing...
reversing attacker capabilities, toolkits, TTPs, humanpower/hours, a
much longer tangent.  but this assertion is based on correlation of
the observed power, capacity, and protocols in specific bands
implemented by the attacker with the capabilities of the DRT system.
multiple locations, terabytes of captured spectrum, patience and
as for who was operating it - unknown beyond the usual suspects, which
is a small set due to the restricted distribution of both the hardware
platform and the exploit kit atop it :)
i'll send more details once available.  the details and distribution
to be part of a separate FOIPA effort for US citizen security
enthusiasts that might be of interest to those following this thread.
best regards,

@_date: 2013-12-02 10:34:53
@_author: coderman 
@_subject: NSA: The Game 
classic!  :P
and fun for the whole family this holiday season,
The Internet users win if they kill all of the NSA agents.  The NSA agents win
if they render enough Internet users that the numbers of Internet users and
NSA agents are even.  In other words they win if the NSA agents constitute a
large enough voting bloc that they can't be lynched any more.  At that point
the NSA can unmask and openly subject the remaining Internet users to
extraordinary rendition.

@_date: 2013-12-02 10:40:28
@_author: coderman 
@_subject: Jim Bell needs Bitcoins! 
and it should go without saying; don't use a third-party wallet service!
the bitcoin network is one of the most hostile networks in the world;
the trail of pwn is long and continuous.  wallet services, changes,
pools, casinos, just about every BTC denominated service is operating
at an elevated risk level traditionally seen in banking while running
their operations like a self hosted blog...

@_date: 2013-12-02 17:56:47
@_author: coderman 
@_subject: peertech.org cert [was: DEF CON cell network attacks] 
Hash: SHA512
more details here soon...
only 443 should be considered valid - that is,
 try  first, plain-text must die.
and remember lkaglbgpvvcmc6xc.onion in case it becomes necessary
    Data:
        Version: 3 (0x2)
        Serial Number:
            2b:50:49:6a:55:85:55
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, ST=Arizona, L=Scottsdale,
O=GoDaddy.com, Inc.,
CN=Go Daddy Secure Certificate Authority - G2
        Validity
            Not Before: Dec  3 00:18:04 2013 GMT
            Not After : Dec  3 00:18:04 2014 GMT
        Subject: OU=Domain Control Validated, CN=peertech.org
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
            RSA Public Key: (4096 bit)
                Modulus (4096 bit):
                    00:b7:64:54:f1:2e:3a:ec:11:29:5a:93:1f:ad:f0:
                    16:8c:9c:eb:d9:0f:49:d2:9d:16:9a:53:a4:60:b6:
                    23:5b:4f:f3:17:90:77:0a:b3:25:27:f2:27:dd:65:
                    83:b6:e4:d5:13:b1:3b:97:5d:b5:b9:a9:62:32:4a:
                    7e:fb:67:73:20:5f:d7:44:52:c8:fc:ca:f8:fb:f1:
                    4f:d1:9d:94:39:72:12:2b:67:22:4c:0b:dc:7f:31:
                    34:cf:63:42:f1:c8:3d:ed:7c:de:2f:e2:63:e1:a2:
                    0a:c9:e6:86:dd:3f:39:73:af:01:58:d7:6d:59:7a:
                    51:d0:b7:bb:4c:8d:5f:1e:43:10:da:96:09:67:56:
                    2f:38:f6:a8:44:a7:96:9a:5c:bc:3e:6c:d6:d1:b6:
                    96:80:34:c8:88:84:4e:2e:06:14:0f:c5:f2:11:ff:
                    f6:15:06:f2:25:e7:d2:1a:8d:62:ef:5c:0e:fb:44:
                    8e:73:da:96:23:26:03:62:5c:2b:e6:70:5c:87:76:
                    d3:21:59:83:57:ac:56:15:bd:4f:25:fb:df:10:ec:
                    0e:56:fa:44:c8:8b:a4:97:ea:b1:98:71:3b:51:78:
                    79:ee:33:cf:b5:a5:68:15:86:9f:31:70:ee:8f:2f:
                    f4:53:32:b7:99:4f:67:21:db:1e:5d:4f:dc:5b:5d:
                    59:fd:30:3e:a2:04:22:13:76:05:4c:44:d6:08:fe:
                    b5:42:5f:b5:4a:38:4f:3d:eb:ea:59:63:ab:27:87:
                    7e:c4:46:3b:96:75:41:be:85:7e:e8:b5:8a:d4:11:
                    aa:cc:6a:28:b9:50:a3:f4:45:e2:50:d5:1f:6c:bf:
                    b8:ba:07:10:20:f8:7f:94:ec:15:d7:39:a6:fe:df:
                    65:78:1d:60:2c:b0:b1:76:40:82:b5:0f:d6:c8:e3:
                    8b:bb:f3:04:ff:80:e3:de:fc:2c:32:0e:21:13:d5:
                    bd:38:94:a1:c8:53:da:c7:3b:a9:a5:c1:70:ea:89:
                    ef:a7:f8:04:35:41:7e:38:05:73:ff:76:8a:c1:92:
                    7f:03:b8:76:48:b9:f6:61:b1:c5:22:be:b9:36:73:
                    de:0e:b8:36:4a:9c:c5:66:3b:63:2c:be:4f:20:75:
                    94:03:d8:05:d0:78:12:df:77:d8:17:51:7e:3c:24:
                    7f:cc:c6:8e:2a:f7:bc:f8:5c:29:64:bb:10:42:4d:
                    c0:83:64:6f:da:78:14:52:2e:97:49:e8:5d:7f:38:
                    36:3d:5a:5d:7c:44:71:28:21:04:6e:24:f5:f8:59:
                    93:1f:e9:d1:3e:6d:6d:db:93:57:8f:44:74:d6:64:
                    e9:2b:b6:33:fd:16:81:92:29:a5:80:6a:1f:2b:78:
                    66:d3:ed
                Exponent: 65537 (0x10001)
        X509v3 extensions:
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Extended Key Usage:
                TLS Web Server Authentication,
                 TLS Web Client Authentication
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 CRL Distribution Points:
                URI:
            X509v3 Certificate Policies:
                Policy: 2.16.840.1.114413.1.7.23.1
                  CPS:             Authority Information Access:
                OCSP - URI:
                CA Issuers -
                 URI:
            X509v3 Authority Key Identifier:
            X509v3 Subject Alternative Name:
                DNS:peertech.org, DNS:
            X509v3 Subject Key Identifier:
                C6:5E:C0:43:56:84:2E:11:A3:35:C8:AC:A9:70:96:7B:A5:2E:5B:77
    Signature Algorithm: sha256WithRSAEncryption
        b1:ea:a9:16:b6:9c:56:f4:59:99:df:36:69:92:a5:57:48:df:
        70:55:a6:1f:5b:51:74:b4:d1:d7:5a:f6:71:e6:92:f2:56:14:
        07:f4:2c:14:06:50:4a:e6:f8:32:8c:a1:ed:4b:25:50:fa:05:
        99:01:74:db:45:ae:c2:ca:dc:f3:e7:ad:50:1b:12:c2:1e:ea:
        c8:19:41:db:b0:eb:f1:0c:c7:ba:af:c2:08:9e:7d:3c:c9:de:
        5d:7f:ff:9e:c3:cc:54:bd:ac:1f:24:47:17:ae:ba:75:b7:0b:
        b7:ee:3b:3a:ba:2a:f7:19:19:1a:98:56:35:34:16:8a:ec:ac:
        50:f0:45:7c:06:5a:fe:b1:d8:8b:13:94:5b:2c:1c:3d:b6:df:
        f9:79:69:b0:75:68:b3:e5:01:8e:90:85:bc:bf:92:47:ba:d0:
        9c:8c:5d:28:d6:d3:17:58:96:76:ed:bf:65:75:7c:25:58:57:
        2f:52:ae:9f:a9:a1:35:92:ca:28:13:b6:ae:a8:89:cf:ce:a6:
        cd:31:28:42:f7:66:9d:de:38:0d:4c:d5:ae:49:6c:db:92:28:
        a2:7c:4a:18:8e:7b:b6:0a:c9:d4:8d:0a:82:d4:04:a6:d0:3d:
        8c:a6:37:ac:16:98:bd:79:49:83:60:7f:b5:dc:d7:80:aa:5d:
        ae:f7:11:eb

@_date: 2013-12-02 18:00:04
@_author: coderman 
@_subject: peertech.org cert [was: DEF CON cell network attacks] 
let's try attachment clients won't mangle... (previous will give bad sig)

@_date: 2013-12-02 21:31:52
@_author: coderman 
@_subject: trends in cybersecurity 
thought provoking read, as always. thanks Dan :)
this is worth posting whole, particularly this observation:
... polarization has come to cyber
security.  High end practice is accelerating away from the low end.
The best skills are now astonishingly good while the great mass of
those dependent on cyber security are ever less able to even estimate
what it is that they do not know, much less act on it.  This
polarization is driven by the fundamental strategic asymmetry of
cyber security, namely that while the workfactor for the offender
is the incremental price of finding a new method of attack, the
workfactor for the defender is the cumulative cost of forever
defending against all attack methods yet discovered.  Over time,
the curve for the cost of finding a new attack and the curve for
the cost of defending against all attacks to date must cross.  Once
those curves cross, the offender never has to worry about being out
of the money.  That crossing event occurred some time ago.
i do have one comment, per:
Everyone my age working in cyber security was trained for something
else, and because of that switch between one field and another
brings along the hybrid vigor of seeing the cyber security world
through a different lens.
instead of having a "cyber security" profession, all aspects of
"information security", "software security", or "cyber security" as a
specialization should not exist.  competence and experience with these
subjects should be considered part of routine software and systems
development practice. (right now this is mostly impractical, however,
it need not always be so...)
best regards,
--- cut-for-posterity ---
.Trends in Cyber Security
.Dan Geer, 6 November 13, NRO
Thank you for the invitation to speak with you today, which, let
me be clear, is me speaking as myself and not for anybody or anything
else.  As you know, I work the cyber security trade, that is to say
that my occupation is cyber security.  Note that I said "occupation"
rather than "profession."  On 18 September, the U.S. National Academy
of Sciences, on behalf of the Department of Homeland Security,
concluded that cyber security should be seen as an occupation and
not a profession because the rate of change is too great to consider
professionalization.[1]  You may well agree that that rate of change
is paramount and thus why cyber security is the most intellectually
demanding occupation on the planet.  In writing this essay, I will
keep my comments to trends rather than point estimates, just as you
asked in your invitation, but let me emphasize the wisdom of your
request by noting that the faster the rate of change, the more it
is trends that matter and not the value of any given variable at
any given time.  With luck, each of these trends will not be something
that you would argue with as a trend.  Argument, if any, will be
in their interpretation.
Note also that these trends do not constitute a set of mutually
exclusive, collectively exhaustive characterizations of the space
in which we live and work.  Some of them are correlated with others.
Some of them are newly emergent, some not.  Some of them are
reversible to a degree; some not reversible at all.  I am not, today
anyway, looking for causality.
Trend  Polarization
Much has been written about the increasing polarization of American
life.[2]  The middle is getting smaller whether we are noting that
only the middle class is shrinking, that it is the middle of the
country that is depopulating, that the political middle is lonelier
and lonelier, that both farms and banks are now only too small to
matter or too big to fail, that almost all journalism is now advocacy
journalism, that middle tier college education is a ticket to debt
and nothing else.
I submit that this trend towards polarization has come to cyber
security.  High end practice is accelerating away from the low end.
The best skills are now astonishingly good while the great mass of
those dependent on cyber security are ever less able to even estimate
what it is that they do not know, much less act on it.  This
polarization is driven by the fundamental strategic asymmetry of
cyber security, namely that while the workfactor for the offender
is the incremental price of finding a new method of attack, the
workfactor for the defender is the cumulative cost of forever
defending against all attack methods yet discovered.  Over time,
the curve for the cost of finding a new attack and the curve for
the cost of defending against all attacks to date must cross.  Once
those curves cross, the offender never has to worry about being out
of the money.  That crossing event occurred some time ago.
I'll come back to this first bullet at the end, but I mention it
first as polarization is becoming structural and of all the trends
the most telling.  You can confirm this by asking the best cyber
security people what they do on the Internet and what they won't
do on the Internet.  You will find it sharply different than what
the public at large does or will do.  The best people know the most,
and they are withdrawing, they are rejecting technologies.  To use
the words and style of the Intelligence Community, they are
Trend  Trends themselves
The idea that under the pressure of constant change about all you
can measure is the slope of the curve has gone from
don't-bother-me-with-math to everybody's-doing-it.  A Google search
for the phrase "information security trends" turns up 13,400 hits
and no two of the top ten are from the same source.  Consultancies
talk about what they are seeing in the back room, product vendors
talk about evolving needs, and reporters talk about what they are
seeing out on the street.
I am one of those folks.  A Wall Street colleague and I run the
Index of Cyber Security.[3]  The ICS is what is called a sentiment-based
index; if you are familiar with the US Consumer Confidence Index,[4]
then you already know what a sentiment-based index is.  Respondents
to the ICS are top drawer cyber security practitioners with direct
operational responsibility who share, each month, how their view
of security in several areas has changed since the month before.
Because there are no absolutes in cyber security, not even widely
agreed upon definitions of the core terms that make up cyber security
practice, a sentiment-based Index is, in fact, the best decision
support that can be done.
The Index asks the respondents monthly whether each of two dozen
different risks has gotten better, gotten worse, gotten a lot better,
gotten a lot worse, or stayed the same since the month before.  Out
of this, the Index of Cyber Security is calculated and released at
6pm on the last calendar day of the month, in further similarity
to the Consumer Confidence Index.  We write an analytic annual
report that I have given to the organizers for your further reading.
As an index of risk, a higher ICS number means higher risk.  That
risk number has risen, and seems likely to continue to rise.  It
is a composite trend line, but what is more interesting is that the
components of the risk are much more varied, i.e., what is the
dominating risk one month may not be the next.  We think that this
captures, in part, the dynamic nature of cyber security and does
so in a way not otherwise being done.  Respondents seem to agree
that the ICS does offer decision support to front-line people such
as themselves.
Trend  then, is that there is increasingly wide acceptance that
absolute measures are not worth seeking and a kind of confirmation
that cyber security is a practice, not a device.
Trend  Physics and its impact on data
As you well know, more and more data is collected and more and more
of that data is in play.  The general, round-numbers dynamic of
this trend are these: Moore's Law continues to give us two orders
of magnitude in compute power per dollar per decade while storage
grows at three orders of magnitude and bandwidth at four.  These
are top-down economic drivers and they relentlessly warp what is
the economically optimum computing model.  The trend is clear; the
future is increasingly dense with stored data but, paradoxically,
despite the massive growth of data volume, that data becomes more
mobile with time.
As is obvious, this bears on cyber security as data is what cyber
security is all about.  In 2007, Jim Gray gave a seminal talk[5]
about the transformation of science, coining the term "fourth
paradigm."  By that he meant that the history of science is that
science began as an endeavor organized around empirical observation.
After that came the age of theory -- theorizing as the paradigm of
what science did.  Then science became computational, again meaning
that the paradigm of what science did was to calculate.  His argument
for a fourth era was that of a paradigm shift from computational
science to data intensive science.  You here at NRO need no primer
on the power of that shift in paradigm, but I am here to tell you
that cyber security is embracing that fourth paradigm and it is
doing it now.
Ecology professor Philip Greear would challenge his graduate students
to catalog all the life in a cubic yard of forest floor.  Computer
science professor Donald Knuth would challenge his graduate students
to catalog everything their computers had done in the last ten
seconds.  It is hard to say which is more difficult, but everywhere
you look, cyber security practitioners are trying to get a handle
on "What is normal?" so that that which is abnormal can be identified
early in the game.  Behavioral approaches leading towards intrusion
detection are exactly the search for anomaly, and they are data
based.  The now-famous attack on RSA Data Security that led to RSA
buying Net Witness is an example of wanting to know everything so
as to recognize something.  I'm on the record at book length [6]
that the central organizing principle behind a competent security
program is to instrument your data sufficiently well that nothing
moves without it being noticed.  Physics has made it possible to
put computers everywhere.  Physics has made it possible to fill
them all with data.
Cyber security is barely keeping up, and not just because of two,
three, or four orders of magnitude in the physics upstream of the
Trend  Need for prediction
We all know that knowledge is power.  We all know that there is a
subtle yet important distinction between information and knowledge.
We all know that a negative declaration like "X did not happen" can
be only proven if you have the enumeration of *everything* that did
happen and can show that X is not in it.  We all know that a stitch
in time saves nine, but only if we know where to put the stitch.
We all know that without security metrics, the outcome is either
overspending or under protecting.
The more technologic the society becomes, the greater the dynamic
range of possible failures.  When you live in a cave, starvation,
predators, disease, and lightning are about the full range of
failures that end life as you know it and you are well familiar
with all of them.  When you live in a technologic society where
everybody and everything is optimized in some way akin to just-in-time
delivery, the dynamic range of failures is incomprehensibly larger
and largely incomprehensible.  The wider the dynamic range of
failure, the more prevention is the watchword.  As technologic
society grows more interdependent within itself, the more it must
rely on prediction based on data collected in broad ways, not
targeted ways.
Some define risk as the probability of a failure times the cost of
that failure.  To be clear, a trend in favor of making predictions
is a trend subsidiary to a trend in the cost of failure.  I've
written at length elsewhere about how an increasing downside cost
of failure requires that we find ways to be resilient, but not
resilient in the sense of rich redundancy, not resilient in the
sense of having quick recovery mechanisms, but resilient in the
sense of having alternate primary means that do not share common
mode risks.  As such, I strongly recommend that manual means be
preserved wherever possible because whatever those manual means
are, they are already fully capitalized and they do not share common
mode risk with digital means.
There is now more information security risk sloshing around the
economy than could actually be accepted were it exposed.  The
tournament now turns to who can minimize their risk the best, which,
in the civilian economy at large, means who can most completely
externalize their downside information security costs.  The weapons
here are perhaps as simple as the wisdom of Delphi, "Know thyself"
and "Nothing to excess" -- know thyself in the sense of quantitative
rigor and a perpetual propensity to design information systems with
failure in mind; nothing to excess in the sense of mimicking the
biologic world's proof by demonstration that species diversity is
the greatest bulwark against loss of an ecosystem.
Trend  Abandonment
If I abandon a car on the street, then eventually someone will be
able to claim title.  If I abandon a bank account, then the State
will eventually seize it.  If I abandon real estate by failing to
remedy a trespass, then in the fullness of time adverse possession
takes over.  If I don't use my trademark, then my rights go over
to those who use what was and could have remained mine.  If I abandon
my spouse and/or children, then everyone is taxed to remedy my
actions.  If I abandon a patent application, then after a date
certain the teaching that it proposes passes over to the rest of
you.  If I abandon my hold on the confidentiality of data such as
by publishing it, then that data passes over to the commonweal not
to return.  If I abandon my storage locker, then it will be lost
to me and may end up on reality TV.  The list goes on.
Apple computers running 10.5 or less get no updates (comprising
about half the installed base).  Any Microsoft computer running XP
gets no updates (comprising about half the installed base).  The
end of security updates follows abandonment.  It is certainly ironic
that freshly pirated copies of Windows get security updates when
older versions bought legitimately do not.
Stating the obvious, if Company X abandons a code base, then that
code base should be open sourced.  Irrespective of security issues,
many is the time that a bit of software I use has gone missing
because its maker went missing.  But with respect to security, some
constellation of {I,we,they,you} are willing and able to provide
security patches or workarounds as time and evil require.
Would the public interest not be served, then, by a conversion to
open source for abandoned code bases?  But wait, you say, isn't
purchased software on a general purpose computer a thing of the
past?  Isn't the future auto-updated smartphone clients transacting
over armored private (carrier) networks to auto-updated cloud
services?  Maybe; maybe not.  If the two major desktop suppliers
update only half of today's desktops, then what percentage will
they update tomorrow?
If you say "Make them try harder!," then the legalistic, regulatory
position is your position, and the ACLU is already trying that
route.  If smartphone auto-update becomes a condition of merchantability
and your smartphone holds the keying material that undeniably says
that its user is you, then how long before a FISA court orders a
special auto-update to *your* phone for evidence gathering?
If you say "But we already know what they're going to do, don't
we?," then the question is what about the abandoned code bases.
Open-sourcing abandoned code bases is the worst option, except for
all the others.  But if seizing an abandoned code base is too big
a stretch for you before breakfast, then start with a Public Key
Infrastructure Certifying Authority that goes bankrupt and ask "Who
gets the keys?"
Trend  Interdependence
The essential character of a free society is this: That which is
not forbidden is permitted.  The essential character of an unfree
society is the inverse, that which is not permitted is forbidden.
The U.S. began as a free society without question; the weight of
regulation, whether open or implicit, can only push it toward being
unfree.  Under the pressure to defend against offenders with a
permanent structural advantage, defenders who opt for forbidding
anything that is not expressly permitted are cultivating a computing
environment that does not embody the freedom with which we are
heretofore familiar.
Put concretely, the central expression of a free society is a free
market, and the cardinal measure of a free market is the breadth
of real choice -- choice that goes beyond color and trim and body
style to choices that optimize discordant, antithetical goal states.
The level of choice on the Internet is draining down.  You may revel
in the hundreds of thousands of supposedly new voices that have
found a way to chatter in full view.  You may note that new "apps"
for Android plus iPhone are appearing at over a thousand per day.
You may rightly remind us all that technology is democratizing in
the sense that powers once reserved for the few are now irretrievably
in the hands of the many.  What stands against that, and why I say
that it stands against that, is increasing interdependence.
We humans can design systems more complex than we can then operate.
The financial sector's "flash crashes" are an example of that;
perhaps the fifty interlocked insurance exchanges for Obamacare
will soon be another.  Above some threshold of system complexity,
it is no longer possible to test, it is only possible to react to
emergent behavior.  The lowliest Internet user is entirely in the
game of interdependence -- one web page can easily touch scores of
different domains.  While writing this, the top level page from
cnn.com had 400 out-references to 85 unique domains each of which
is likely to be similarly constructed and all of which move data
one way or another.  If you leave those pages up and they have an
auto-refresh, then moving to a new network signals to every one of
those ad networks that you have so moved.
The wellspring of risk is dependence, especially dependence on
shared expectations of shared system state, i.e., interdependence
on the ground.  If you would accept that you are most at risk from
the things you most depend upon, then damping dependence is the
cheapest, most straightforward, lowest latency way to damp risk,
just as the fastest and most reliable way to put more money on a
business's bottom line is through cost control.
Trend  Automation
Shoshana Zuboff of the Harvard Business School notably described
three laws of the digital age,
. Everything that can be automated will be automated.
. Everything that can be informated will be informated.
. Every digital application that can be used for surveillance and
.    control will be used for surveillance and control.
It is irrelevant, immaterial and incompetent to argue otherwise.
For security technology, Zuboff's Laws are almost the goal state,
that is to say that the attempt to automate information assurance
is in full swing everywhere, the ability to extract information
from the observable is in full swing everywhere, and every digital
application is being instrumented.
Before In-Q-Tel, I worked for a data protection company.  Our product
was, and I believe still is, the most thorough on the market.  By
"thorough" I mean the dictionary definition, "careful about doing
something in an accurate and exact way."  To this end, installing
our product instrumented every system call on the target machine.
Data did not and could not move in any sense of the word "move"
without detection.  Every data operation was caught and monitored.
It was total surveillance data protection.  What made this product
stick out was that very thoroughness, but here is the point: Unless
you fully instrument your data handling, it is not possible for you
to say what did not happen.  With total surveillance, and total
surveillance alone, it is possible to treat the absence of evidence
as the evidence of absence.  Only when you know everything that
*did* happen with your data can you say what did *not* happen with
your data.
But this trend of automating is now leaving the purely defensive
position behind.  In a press release two weeks ago today,[7] DARPA
signaled exactly that, and I quote
   [T]he Defense Advanced Research Projects Agency intends to hold
   the Cyber Grand Challenge -- the first-ever tournament for fully
   automatic network defense systems.  DARPA envisions teams creating
   automated systems that would compete against each other to
   evaluate software, test for vulnerabilities, generate security
   patches and apply them to protected computers on a network.  The
   growth trends ... in cyber attacks and malware point to a future
   where automation must be developed...
The automation trend is irreversible, but it begs a question that
I fear no one will answer in a way that doesn't merely reflect their
corporate or institutional interest, namely are people in the loop
a failsafe or a liability?[8]
Trend  Dual use
I've become convinced that all security technology is dual use.
While I am not sure whether dual use is a trend or a realization
of an unchanging fact of nature, the obviousness of dual use seems
greatest in the latest technologies, so I am calling it a trend in
the sense that the straightforward accessibility of dual use
characteristics of new technology is a growing trend.
There are a lot of examples, but in the physical world any weapon
usable for defense can be repurposed for offense.  Every security
researcher looking for exploitable flaws is deep in the dual use
debate because once discovered, those flaws can be patched or they
can be sold.  The cyber security products that promise total
surveillance over the enterprise are, to my mind, an offensive
strategy used for defensive purposes.
There was a time when flaws were predominantly found by adventurers
and braggarts.  Ten plus years of good work by the operating system
vendors elbowed the flaw finders out of the operating system and,
as a result, our principal opponents changed over from adventurers
and braggarts to being professionals.  Finding vulnerabilities and
exploiting them is now hard enough that it has moved out of the
realm of being a hobby and into the realm of being a job.  This
changed several things, notably that braggarts share their findings
because they are paid in bragging rights.  By contrast, professionals
do not share and are paid in something more substantial than fame.
The side effect has been a continued rise in the percentage of all
vulnerabilities that are previously unknown.  The trend, in other
words, is that by crushing hobbyists we've raised the market price
of working exploits to where now our opponents pay for research and
development out of revenue.
Simulating what the opponent can do thus remains the central task
of defensive research.  Much of that research is in crafting proofs
of concept that such and such a flaw can be taken advantage of.
Corman's neologism of "HD Moore's Law" says that the trend in the
power of the casual attacker grows as does the trend of the power
in Metasploit.[9] It is hard to think of a better description of
dual use.
Trend  The blurring of end-to-end
To my mind, the most important technical decision ever made was
that the security of the Internet was to be "end-to-end."[10]
"End-to-end" is a generic technical term yet simple to explain: the
Internet was built on the premise that two entities could connect
themselves to each other and decide what they wanted to do.  The
network was a delivery vehicle, but the form, content, and security
of the connection between the two ends was to be their own choice.
End-to-end is a model where the terminal entities are smart and the
network is dumb.  This is completely (completely) different than a
smart network with dumb terminal entities at the end of the wire.
No other design decision of the Internet comes close to the importance
of it's being an end-to-end design.  With end-to-end, security is
the choice of the terminal end-points, not something built into the
fabric of the Internet itself.  That is American values personified.
It is the idea that accountability, not permission seeking, is the
way a government curbs the misuse of freedoms, and, as accountability
scales but permission seeking does not, accountability wins.
End-to-end security is the digital manifestation of the right of
association and, in any case, is what enabled the Internet to become
relevant in the first place.  End-to-end does precisely what Peter
Drucker told us to do: "Don't solve problems, create opportunities."
The provision of content from anywhere to anywhere, which is the
very purpose of an internetwork, is a challenge to sovereignty.
America's Founders wanted no sovereign at all, and they devised a
government that made the center all but powerless and the periphery
fully able to thumb its nose at whatever it felt like.  Much ink
has been spilled on the frontier ethic versus the wishful policies
favored by the comfortable urbanity of the welfare state, but the
Internet's protocols have everything in common with the former and
nothing in common with the latter.
The free man requires the choice of with what degree of vigor to
defend himself.  That is a universal; America's Founders laid that
down in the Second Amendment, just as did George Orwell in the
English democratic socialist weekly "Tribune" when he said, "That
rifle on the wall of the laborer's cottage or working class flat
is the symbol of democracy.  It is our job to see that it stays
there."  Were George Washington or George Orwell still among us,
they would know that smart end-points and dumb networks are what
freedom requires, that smart networks protecting dumb end-points
breed compliant dependency.
But the trend is otherwise, and not just because of the fatuous
fashionability of entitlement, but rather because of a blurring of
what the term "end" means.  So very many people have adopted automatic
synchronization of multiple devices they own that one has to ask
whether their tablet is an end or their collection of mutually
synchronized devices is an end.  So many Internet-dependent functions
are spread silently across numerous entities and applications that
what is the end may well be more dynamic than can be described.  If
an end implies unitary control on the part of an owner, then set
theory says that mutually synchronized devices are a unitary end.
That blurring of "end" makes end-to-end provisioning problematic
as a set of devices cannot be assumed to be equally on and equally
participating in any given transaction.  Quoting Clark & Blumenthal[11]
   There is a risk that the range of new requirements now emerging
   could have the consequence of compromising the Internet's original
   design principles.  Were this to happen, the Internet might lose
   some of its key features, in particular its ability to support
   new and unanticipated applications.  We link this possible outcome
   to a number of trends: the rise of new stakeholders in the
   Internet,...  new government interests, the changing motivations
   of the growing user base, and the tension between the demand for
   trustworthy overall operation and the inability to trust the
   behavior of individual users.
This is nowhere so evident as in security, that is to say in the
application of the end-to-end principle to cyber security.  What
does end-to-end secure transport mean when travelocity.com is showing
you a page dynamically constructed from a dozen other entities?
Trend  Complexity in the supply chain
Even without resorting to classified information, it is now clear
that supply chain attacks have occurred.  Whether reading journalistic
accounts or Richard Clarke's novel _Breakpoint_, the finding is
that the supply chain creates opportunities for badness.  None of
the things I've yet read, however, blames the supply chain risk on
its complexity, per se, but that is the trend that matters.
Security is non-composable -- we can get insecure results even when
our systems are assembled from secure components.  The more components,
the less likely a secure result.  This applies to supply chains
that are growing ever more complex under the pressure of just-in-time,
spot market sourcing of, say, memory chips and so forth and so on.
Because the attacker has only to find one component of that chain
to be vulnerable while the defender has to assure that all components
are invulnerable, rising supply chain complexity guarantees increased
opportunity for effective attack.  It cannot do otherwise, and the
trend is clear.
Trend  Monoculture(s)
Beginning with Forrest in 1997,[12] regular attention has been paid
to the questions of monoculture in the network environment.  There
is no point belaboring the fundamental question, but let me state
it for the record: cascade failure is so very much easier to detonate
in a monoculture -- so very much easier when the attacker has only
to write one bit of malware, not ten million.  The idea is obvious;
believing in it is easy; acting on its implications is, evidently,
rather hard.
I am entirely sympathetic to the actual reason we continue to deploy
computing monocultures -- making everything almost entirely alike
is, and remains, our only hope for being able to centrally manage
it in a consistent manner.  Put differently, when you deploy a
computing monoculture you are making a fundamental risk management
decision: That the downside risk of a black swan event is more
tolerable than the downside risk of perpetual inconsistency.  This
is a hard question, as all risk management is about changing the
future, not explaining the past.  Which would you rather have, the
unlikely event of a severe impact, or the day-to-day burden of
perpetual inconsistency?
When we opt for monocultures we had better opt for tight central
control.  This supposes that we are willing to face the risks that
come with tight central control, of course, including the maximum
risk of all auto-update schemes, namely the hostile takeover of the
auto-update mechanism itself.  Computer desktops are not the point;
embedded systems are.  The trendline in the number of critical
monocultures seems to be rising and many of these are embedded
systems both without a remote management interface and long lived.
That combination -- long lived and not reachable -- is the trend
that must be reversed.  Whether to insist that embedded devices
self destruct at some age or that remote management of them be a
condition of deployment is the question.  In either case, the
Internet of Things and the appearance of microcontrollers in seemingly
every computing device should raise hackles on every neck.[13]
Trend  Attack surface growth versus skill growth
Everyone here knows the terminology "attack surface" and knows that
one of the defender's highest goals is to minimize the attack surface
wherever possible.  Every coder adhering to a security-cognizant
software lifecycle program does this.  Every company or research
group engaged in static analysis of binaries does this.  Every
agency enforcing a need-to-know regime for data access does this.
Every individual who reserves one low-limit credit card for their
Internet purchases does this.  I might otherwise say that any person
who encrypts their e-mail to their closest counterparties does this,
but because consistent e-mail encryption is so rare, encrypting
one's e-mail marks it for collection and indefinite retention by
those entities in a position to do so, regardless of what country
you live in.
In cyber security practice, the trend is that we practitioners as
a class are getting better and better.  We have better tools, we
have better understood practices, and we have more colleagues.
That's the plus side.  But I'm interested in the ratio of skill to
challenge, and as far as I can estimate, we are expanding the
society-wide attack surface faster than we are expanding our
collection of tools, practices, and colleagues.  If you are growing
more food, that's great.  If your population is growing faster than
your improvements in food production can keep up, that's bad.
In the days of radio, there was Sarnoff's Law, namely that the value
of a broadcast network was proportional to N, the number of listeners.
Then came packetized network communications and Metcalfe's Law,
that the value of a network was proportional to N squared, the
number of possible two-way conversations.  We are now in the era
of Reed's Law where the value of a network is proportional to the
number of groups that can form in it, that is to say 2 to the power
N.  Reed's Law is the new reality because it fits the age of social
networks.  In each of these three laws as publicly stated, the sign
bit is positive, but in parallel with the claim that everything is
dual use, the sign bit can also be negative because interconnections
are a contributor to the net attack surface.  If an Internet of
Things is indeed imminent, then the upward bend in the curve of the
global attack surface will grow steeper regardless of what level
of risk there is for any one thing so long as that level of risk
is always non-zero.
Trend  Specialization
Everyone my age working in cyber security was trained for something
else, and because of that switch between one field and another
brings along the hybrid vigor of seeing the cyber security world
through a different lens.  Statisticians, civil engineers, and
lawyers alike can contribute.  But the increasing quality of prepatory
education, the increasing breadth of affairs for which cyber security
is needful, and the increasing demand for skill of the highest sort
means the humans in the game are specializing.
While some people like to say "Specialization is for insects," tell
me that the security field itself is not specializing.  We have
people who are expert in forensics on specific operating system
localizations, expert in setting up intrusion response, expert in
analyzing large sets of firewall rules using non-trivial set theory,
expert in designing egress filters for universities that have no
ingress filters, expert in steganographically watermarking binaries,
and so forth.  Generalists are becoming rare, and they are being
replaced by specialists.  This is biologic speciation in action,
and the narrowing of ecologic niches.  In rough numbers, there are
somewhere close to 5,000 various technical certifications you can
get in the computer field, and the number of them is growing thus
proving the conjecture of specialization and speciation is not just
for insects and it will not stop.
[1] "Professionalizing the Nation's Cyber Workforce?"
 [2] _Hollowing out the Middle_, Carr & Kefalas; _Race Against the
Machine_, Brynjolfsson & McAfee; _Average Is Over_, Cowen
[3] "The Index of Cyber Security,"
 cybersecurityindex.org
[4] "The Consumer Confidence Index," Technical Note, 2011
 tinyurl.com/3sb633k
[5] Gray, "eScience," NRC-CSTB, Mountain View CA, 2007
 research.microsoft.com/en-us/um/people/gray/talks/NRC-CSTB_eScience.ppt
[6] Geer, _Economics and Strategies of Data Security_, 2008
[7] [8] Geer, "People in the Loop: Failsafe or a Liability?", 2012
 geer.tinho.net/geer.suitsandspooks.8ii12.txt
[9] Corman, "Intro to HDMoore's Law," 2011
 blog.cognitivedissidents.com/2011/11/01/intro-to-hdmoores-law
[10] Saltzer, Reed, & Clark, "End-to-End Arguments in System Design,"
 web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf
[11] Clark & Blumenthal, "Rethinking the design of the Internet,
The End-to-End Arguments vs. the Brave New World," 2001
 cyberlaw.stanford.edu/e2e/papers/TPRC-Clark-Blumenthal.pdf
[12] Forrest, Somayaji, & Ackley, "Building Diverse Computer Systems,"
HotOS-VI, 1997
 [13] Farmer, "IPMI: Freight Train to Hell v2.01," 2013
 fish2.com/ipmi/itrain.pdf
more material at geer.tinho.net/pubs

@_date: 2013-12-03 15:40:25
@_author: coderman 
@_subject: Fwd: [cryptography] A new approach to steganography 
I came up with a new approach to steganography. There's an
implementation and writeup of it here -

@_date: 2013-12-03 15:42:42
@_author: coderman 
@_subject: [cryptography] A new approach to steganography 
Q. Why did you use Python3 as a reference language?
A. Because not having distinct binary and unicode string types is barbaric.
oh the many ways i both love and hate python...

@_date: 2013-12-04 14:05:27
@_author: coderman 
@_subject: NSA tracking cellphone locations worldwide 
NSA tracking cellphone locations worldwide, Snowden documents show
By Barton Gellman and Ashkan Soltani, Wednesday, December 4, 12:18 PM
The National Security Agency is gathering nearly 5 billion records a
day on the whereabouts of cellphones around the world, according to
top-secret documents and interviews with U.S. intelligence officials,
enabling the agency to track the movements of individuals  and map
their relationships  in ways that would have been previously
The records feed a vast database that stores information about the
locations of at least hundreds of millions of devices, according to
the officials and the documents, which were provided by former NSA
contractorEdward Snowden. New projects created to analyze that data
have provided the intelligence community with what amounts to a mass
surveillance tool.
(Video: How the NSA uses cellphone tracking to find and develop targets)
The NSA does not target Americans location data by design, but the
agency acquires a substantial amount of information on the whereabouts
of domestic cellphones incidentally, a legal term that connotes a
foreseeable but not deliberate result.
One senior collection manager, speaking on condition of anonymity but
with permission from the NSA, said we are getting vast volumes of
location data from around the world by tapping into the cables that
connect mobile networks globally and that serve U.S. cellphones as
well as foreign ones. Additionally, data is often collected from the
tens of millions of Americans who travel abroad with their cellphones
every year.
In scale, scope and potential impact on privacy, the efforts to
collect and analyze location data may be unsurpassed among the NSA
surveillance programsthat have been disclosed since June. Analysts can
find cellphones anywhere in the world, retrace their movements and
expose hidden relationships among individuals using them.
(Graphic: How the NSA is tracking people right now)
U.S. officials said the programs that collect and analyze location
data are lawful and intended strictly to develop intelligence about
foreign targets.
Robert Litt, general counsel for the Office of the Director of
National Intelligence, which oversees the NSA, said there is no
element of the intelligence community that under any authority is
intentionally collecting bulk cellphone location information about
cellphones in the United States.
The NSA has no reason to suspect that the movements of the
overwhelming majority of cellphone users would be relevant to national
security. Rather, it collects locations in bulk because its most
powerful analytic tools  known collectively as CO-TRAVELER  allow it
to look for unknown associates of known intelligence targets by
tracking people whose movements intersect.
Still, location data, especially when aggregated over time, is widely
regarded among privacy advocates as uniquely sensitive. Sophisticated
mathematical techniques enable NSA analysts to map cellphone owners
relationships by correlating their patterns of movement over time with
thousands or millions of other phone users who cross their paths.
Cellphones broadcast their locations even when they are not being used
to place a call or send a text.
(Video: Reporter Ashkan Soltani explains NSA collection of cellphone data)
CO-TRAVELER and related tools require the methodical collection and
storage of location data on what amounts to a planetary scale. The
government is tracking people from afar into confidential business
meetings or personal visits to medical facilities, hotel rooms,
private homes and other traditionally protected spaces.
One of the key components of location data, and why its so
sensitive, is that the laws of physics dont let you keep it private,
said Chris Soghoian, principal technologist at the American Civil
Liberties Union. People who value their privacy can encrypt their
e-mails and disguise their online identities, but the only way to
hide your location is to disconnect from our modern communication
system and live in a cave.
The NSA cannot know in advance which tiny fraction of 1 percent of the
records it may need, so it collects and keeps as many as it can  27
terabytes, by one account, or more than double the text content of the
Library of Congresss print collection.
The location programs have brought in such volumes of information,
according to a May 2012 internal NSA briefing, that they are
outpacing our ability to ingest, process and store data. In the
ensuing year and a half, the NSA has been transitioning to a
processing system that provided it with greater capacity.
The possibility that the intelligence community has been collecting
location data, particularly of Americans, has long concerned privacy
advocates and some lawmakers. Three Democratic senators  Ron Wyden
(Ore.), Mark Udall (Colo.) and Barbara Mikulski (Md.)  have
introduced an amendment to the 2014 defense spending bill that would
require U.S. intelligence agencies to say whether they have ever
collected or made plans to collect location data for a large number
of United States persons with no known connection to suspicious
NSA Director Keith Alexander disclosed in Senate testimony in October
that the NSA had run a pilot project in 2010 and 2011 to collect
samples of U.S. cellphone location data. The data collected were
never available for intelligence analysis purposes, and the project
was discontinued because it had no operational value, he said.
Alexander allowed that a broader collection of such data may be
something that is a future requirement for the country, but it is not
right now.
The number of Americans whose locations are tracked as part of the
NSAs collection of data overseas is impossible to determine from the
Snowden documents alone, and senior intelligence officials declined to
offer an estimate.
Its awkward for us to try to provide any specific numbers, one
intelligence official said in a telephone interview. An NSA
spokeswoman who took part in the call cut in to say the agency has no
way to calculate such a figure.
An intelligence lawyer, speaking with his agencys permission, said
location data are obtained by methods tuned to be looking outside the
United States, a formulation he repeated three times. When U.S.
cellphone data are collected, he said, the data are not covered by the
Fourth Amendment, which protects Americans against unreasonable
searches and seizures.
According to top-secret briefing slides, the NSA pulls in location
data around the world from 10 major sigads, or signals intelligence
activity designators.
A sigad known as STORMBREW, for example, relies on two unnamed
corporate partners described only as ARTIFICE and WOLFPOINT. According
to an NSA site inventory, the companies administer the NSAs physical
systems, or interception equipment, and NSA asks nicely for
STORMBREW collects data from 27 telephone links known as OPC/DPC
pairs, which refer to originating and destination points and which
typically transfer traffic from one providers internal network to
anothers. That data include cell tower identifiers, which can be used
to locate a phones location.
The agencys access to carriers networks appears to be vast.
Many shared databases, such as those used for roaming, are available
in their complete form to any carrier who requires access to any part
of it, said Matt Blaze, an associate professor of computer and
information science at the University of Pennsylvania. This flat
trust model means that a surprisingly large number of entities have
access to data about customers that they never actually do business
with, and an intelligence agency  hostile or friendly  can get one
stop shopping to an expansive range of subscriber data just by
compromising a few carriers.
Some documents in the Snowden archive suggest that acquisition of U.S.
location data is routine enough to be cited as an example in training
materials. In an October 2012 white paper on analytic techniques, for
example, the NSAs counterterrorism analysis unit cites two U.S.-based
carriers to illustrate the challenge of correlating the travels of
phone users on different mobile networks. Asked about that, a U.S.
intelligence official said the example was poorly chosen and did not
represent the programs foreign focus.
The NSAs capabilities to track location are staggering, based on the
Snowden documents, and indicate that the agency is able to render most
efforts at communications security effectively futile.
Like encryption and anonymity tools online, which are used by
dissidents, journalists and terrorists alike, security-minded behavior
 using disposable cellphones and switching them on only long enough
to make brief calls  marks a user for special scrutiny. CO-TRAVELER
takes note, for example, when a new telephone connects to a cell tower
soon after another nearby device is used for the last time.
Side-by-side security efforts  when nearby devices power off and on
together over time  assist in determining whether co-travelers are
associated  through behaviorally relevant relationships, according
to the 24-page white paper, which was developed by the NSA in
partnership with the National Geospatial Agency, the Australian
Signals Directorate and private contractors.
A central feature of each of these tools is that they do not rely on
knowing a particular target in advance, or even suspecting one. They
operate on the full universe of data in the NSAs FASCIA repository,
which stores trillions of metadata records, of which a large but
unknown fraction include locations.
The most basic analytic tools map the date, time, and location of
cellphones to look for patterns or significant moments of overlap.
Other tools compute speed and trajectory for large numbers of mobile
devices, overlaying the electronic data on transportation maps to
compute the likely travel time and determine which devices might have
To solve the problem of undetectable surveillance against CIA officers
stationed overseas, one contractor designed an analytic model that
would carefully record the case officers path and look for other
mobile devices in steady proximity.
Results have not been validated by operational analysts, the report said.
Julie Tate contributed to this report. Soltani is an independent
security researcher and consultant.

@_date: 2013-12-07 17:27:48
@_author: coderman 
@_subject: infra-org (urls) 
actually, i have long held this view on an intuitive / elegance level
of understanding.  the continual expansion of our understanding of
quantum phenomena has only reinforced and clarified this model of
consciousness for me.
rather than sounding crazy, i am pleasantly surprised that others
grasp this concept of consciousness and are willing to embrace it!
this would be a fun tangent to discourse about, however, i'll save the
brain as quantum antenna linked to body via nerve cell transducers for
another day...  ;)
best regards,

@_date: 2013-12-07 21:06:40
@_author: coderman 
@_subject: infra-org (urls) 
that movie discussed a few interesting concepts, but was overall too
annoying/incorrect for me to enjoy :/
regarding the role of quantum effects on consciousness, i am mostly
dismissing the purely deterministic models of consciousness arising
out of chemical interactions or fields only.
consider instead the role of quantum effects within the brain as
influence on nerve behavior within a integrated information theory of

@_date: 2013-12-08 00:22:48
@_author: coderman 
@_subject: NSA morale down 
the portrayals from the brass and insiders is, "the administration is
not showing enough support!".
i have to wonder: how many rank and file are feeling betrayed by the
NSA administration instead?   they're now getting a look into all the
SCI bits they were compartmented from before; able to see a bigger
picture full of invasive technical excesses and legal abuses...
A second former official said NSA workers are polishing up their
rsums and asking that they be cleared  removing any material linked
to classified programs  so they can be sent out to potential
employers. He noted that one employee who processes the rsums said,
Ive never seen so many rsums that people want to have cleared in
my life.
it remains to be seen if they simply jump to private sector who are
just as bad, or pursue less offensive careers entirely.
NSA morale down after Edward Snowden revelations, former U.S. officials say
By Ellen Nakashima, Published: December 7
Morale has taken a hit at the National Security Agency in the wake of
controversy over the agencys surveillance activities, according to
former officials who say they are dismayed that President Obama has
not visited the agency to show his support.
A White House spokeswoman, Caitlin Hayden, noted that top White House
officials have been to the agency to express the presidents support
and appreciation for all that NSA does to keep us safe.
It is not clear whether or when Obama might travel the 23 miles up the
Baltimore-Washington Parkway to visit Fort Meade, the NSAs
headquarters in Maryland, but agency employees are privately voicing
frustration at what they perceive as White House ambivalence amid the
pounding the agency has taken from critics.
An NSA spokeswoman had no comment.
Obama in June defended the NSAs surveillance as lawful and said he
welcomed the public debate prompted by revelations from former
contractor Edward Snowden beginning that month.
Though Obama has asserted, for instance, that the NSAs collection of
virtually all Americans phone records is lawful and has saved lives,
the administration has not endorsed legislation that would codify it.
And his recent statements suggest he thinks some of the NSAs
activities should be constrained.
A senior administration official who was not authorized to speak on
the record said that the White House would normally not endorse
legislation so early in the process but that its been clear ...
that we prefer legislation that preserves the phone records program
while making some changes ... to potentially strengthen oversight
and transparency.
Said Hayden: The president has the highest respect for and pride in
the men and women of the intelligence community who work tirelessly to
protect our nation. Hes expressed that directly to NSAs leadership
and has praised their work in public. As he said: The men and women
of our intelligence community work every single day to keep us safe
because they love this country and believe in our values. Theyre
patriots.
She noted that in recent weeks, Lisa Monaco, assistant to the
president for homeland security and counterterrorism, and Denis
McDonough, the White House chief of staff, visited Fort Meade to
express the presidents support and appreciation for all that NSA does
to keep us safe.
Supporters of the NSA say staffers are not feeling the love.
The agency, from top to bottom, leadership to rank and file, feels
that it is had no support from the White House even though its been
carrying out publicly approved intelligence missions, said Joel
Brenner, NSA inspector general from 2002 to 2006. They feel theyve
been hung out to dry, and theyre right.
A former U.S. official  who like several other former officials
interviewed for this story requested anonymity because he still has
dealings with the agency  said: The president has multiple
constituencies  I get it. But he must agree that the signals
intelligence NSA is providing is one of the most important sources of
intelligence today.
So if thats the case, why isnt the president taking care of one of
the most important elements of the national security apparatus?
The White House, observers say, is caught between competing desires to
preserve what it has said are valuable national security programs and
to shield the president from criticism from allies abroad and
civil-liberties advocates at home.
Some observers said it is not surprising that Obama would not travel
to Fort Meade before internal and external reviews of surveillance
activities have been completed. The reviews are expected to be done
The NSAs director, Gen. Keith Alexander, who is retiring in the
spring after 81 / 2 years, has been the most vocal defender of the
agencys 35,000 employees. In speeches he has noted that more than
6,000 of them went to Iraq and Afghanistan to support the military. He
has spoken of how 22 cryptologists were killed. Theyre the heroes 
not the media leaker, he said in a September speech, in a reference
to Snowden.
NSA counterterrorism analysts have worked every weekend for eight
years since Ive been here. ... Twenty-four hours a day, seven days
a week, theyre there to defend us, he said then.
On Thursday, Obama said on MSNBC that he would be proposing some
self-restraint on the NSA and some reforms that can give people more
In an interview with NBC last month, he said: In some ways, the
technology and the budgets and the capacity [at NSA] have outstripped
the constraints. And weve got to rebuild those in the same way that
were having to do on a whole series of capacities ... [such as]
drone operations.
Civil-liberties advocates generally agree with that sentiment, but
they would go further and say that the NSAs bulk collection of
domestic phone records is unlawful and ought to be ended.
Former officials note how President George W. Bush paid a visit to the
NSA in January 2006, in the wake of revelations by the New York Times
that the agency engaged in a counterterrorism program of warrantless
surveillance on U.S. soil beginning after the Sept. 11, 2001,
terrorist attacks. Bush came out and spoke to the workforce, and the
effect on morale was tremendous, Brenner said. Theres been nothing
like that from this White House.
A second former official said NSA workers are polishing up their
rsums and asking that they be cleared  removing any material linked
to classified programs  so they can be sent out to potential
employers. He noted that one employee who processes the rsums said,
Ive never seen so many rsums that people want to have cleared in
my life.
Morale is bad overall, a third former official said. The news  the
Snowden disclosures  it questions the integrity of the NSA
workforce, he said. Its become very public and very personal.
Literally, neighbors are asking people, Why are you spying on
Grandma? And we arent. People are feeling bad, beaten down.

@_date: 2013-12-08 00:44:02
@_author: coderman 
@_subject: NSA morale down 
by private sector i'm thinking of companies like Statfor more than Amazon...
... Below are a series of articles this past week about
internationally acclaimed activist, Srdja Popovic, and his involvement
with the private intelligence firm Stratfor.
... If anyone has information about CANVAS or Srdja Popovic, please
feel free to contact me at zoealif[at]gmail.com. I am currently
writing a blog post on the story.

@_date: 2013-12-09 07:53:07
@_author: coderman 
@_subject: Android IMSI Catcher detection 
fun :)  i always liked osmocomBB, since openmoko days...
these days i prefer SDR and wider band, wider freq. transceivers, but
TI Calypso and MTK definitely more accessible!  will you provide a
developer mailing list in addition to github?
best regards,

@_date: 2013-12-09 08:07:18
@_author: coderman 
@_subject: EM-nature (was: infra-org) 
effective attenuation of emanations above 10Ghz would be interesting.
even at >5Ghz you run into trouble with the AC filer route as you
mention; best practice seems to be DC batteries inside the cage :/
attenuation at high frequencies for air flow mesh less problematic;
optical communication links will always be useful of course...
i would be curious to see high dBm with high dBi gain
emitters(antennas) worst-case testing against actual build outs at
beyond exceptional..
Teletronics makes some nice 1W 5.8Ghz amps for 802.11a which could be
so purposed inexpensively.
best regards,

@_date: 2013-12-09 09:49:49
@_author: coderman 
@_subject: Android IMSI Catcher detection 
it doesn't "function" yet, period.  *grin*
i leave it as an exercise for the reader to implement A0 detection on Android...

@_date: 2013-12-09 15:03:57
@_author: coderman 
@_subject: good clocks (not using GPS) and multi-channel hw [was: sidebands 
GPS disciplining to keep a OCXO in check periodically (GPSDO) would be
useful!  GPS just can't be the primary source.
has anyone used an OctoClock-G?
  best regards,

@_date: 2013-12-09 15:17:04
@_author: coderman 
@_subject: Android IMSI Catcher detection 
carrierIQ is good for something ;)
you're going to have to go ARM native (or ?) to observe use of A0 over
GSM, since android.telephony.gsm screwed us.
this came up on the cryptome list last week: camouflage, jamming,
obfuscation are all useful techniques to apply against unwelcome
observers. c.f. high power infra red LED camera dazzlers and LADAR
jammers, etc.
while equally effective on the cell bands, you'll want to be sure to
check your 20 before emitting with gusto!  ;P
best regards,

@_date: 2013-12-09 15:30:31
@_author: coderman 
@_subject: Android IMSI Catcher detection 
i feel your pain...
sort of; there are some interesting attacks using a force-pushed
silent PRL update (see DC19/DC20 cell attacks threads) which would be
observable by tower ID oddities, not to mention decremented or zero
PRL version.  however, you'd have to be paying attention (who checks
their PRL regularly? :).
if you simply check if a tower is in
 for example, you're open to
attacks spoofing a legitimate but remote (out of range) tower.
using direction finding techniques to cross reference the transmitter
location against the expected GPS coordinates in a tower database
relative to your position would also detect these tower impersonators,
but requires more hardware than a mobile baseband...
the expensive, limited distribution kit will be hard to distinguish
without a high performance software defined radio.  if you're able to
detect an identically spoofed tower using OsmocomBB with high
confidence i'd love to know how you did it!
truth.  also, an inversion of observed data link capacity (suddenly
seeing receive bandwidth drop in half or more while transmit rate
doubles) is no bueno.
best regards,

@_date: 2013-12-09 16:22:38
@_author: coderman 
@_subject: Open phones for privacy/anonymity applications, Guardian 
the FCC/NTIA don't like people using spectrum with unapproved devices.
sure, you can code it up. and sure, you can run an SDR in that range.
... but put them together in the wild at useful dBi and you're
stepping on toes.  try to sell/distribute such a setup? better have it
good analysis of the details:
  ...the FCCs ancillary jurisdiction cannot reasonably extend to the
development of software by parties uninvolved in the marketing or sale
of radio devices...
FCC Rules for SDR Device Certification Only Affect Radio Equipment

@_date: 2013-12-09 16:26:45
@_author: coderman 
@_subject: Open phones for privacy/anonymity applications, Guardian 
to be specific: it is this certification step that fully open source
SDR/baseband equipment manufacturers have difficultly with.  E.g. the
FCC plainly states systems  "wholly dependent on open source elements
would have a high burden to demonstrate their security during the
certification process.  where many have taken "high burden" to mean
"nearly impossible"...
best regards,

@_date: 2013-12-11 00:09:49
@_author: coderman 
@_subject: Fwd: [cryptography] Which encryption chips are compromised? 
you ask interesting questions Dan, and draw useful conclusions :)
some items to note:
- is this DUAL_EC_DRNG? don't think so. deadline is FY 2013.
- is this DUAL_EC_DRNG? the market for closed source, proprietary
crypto solutions is small (and growing smaller, :(
- is this XSTORE? it's been a while. but never should have been used
directly. see mtrngd with MSR bits set no whitening, max sample, max
freq. into mix + conservative estimate before /dev/random write.
some cryptographers and cypherpunks have become despondent or dejected
or demoralized by these events.
i see a larger picture: never before have so many been doing crypto less wrong!

@_date: 2013-12-11 00:10:24
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
I think there may be weaknesses in Intel's hardware RNG.  I took a
good look at Intel's hardware random number generator source. There's
a paper analyzing it here:
The basic idea is that back-to-back inverters, when powered on, flip
one way or the other randomly, sort of like DRAM memory when our
computer's power on.  By powering on a single pair of back-to-back
inverters over and over, they can generate a random bit per cycle, at
about 3 Giga-bits/second, which is amazing!  Here's my concerns about
the the paper:
- I saw no mathematical analysis of how much noise exists in the
system and how strongly it will influence the result each cycle. There
were generalities about how the noise could cause the output to be
random, but no numbers at all.
- There is an assumption that the capacitors are charged/discharged by
10% of the standard deviation of the noise.  I saw no justification
for this.  It seems they simply assumed best case.
- The paper is about as objective as a mother talking about her
children.  For example: "Overall, the Ivy Bridge RNG is a robust
design with a large margin of safety that ensures good random data is
generated even if the ES is not operating as well as predicted." Based
on what?
- I am not convinced they have the right model for the entropy source.
 They add noise to the bias on the capacitors, and compare that to 0
to determine the next output bit in their model.  I think the main
source of noise may be the randomness in number of electrons
added/subtracted each cycle, and that the back-to-back inverters in
the absence of other noise may be acting almost as an ideal
comparator.  However, if this were the case, even if there were 10%
noise in the number of electrons, there would be considerable
correlation between bits.
I also have questions about the design itself.  My main concern is
that noise on the VDD rail could easily determine the output.  For
example, if the transistors are mismatched, which of course they will
be, and the bias is set exactly right on the caps so there's a 50-50
chance of a 0 or 1, and suddenly VDD drops 10% due to a rising edge of
the the main system clock, then the inverter with higher gate
thresholds will become weak faster than the other one, thus
determining which one wins.  Since this circuit runs asynchronously
from the main system clock, I could easily see the 3MHz system clock
phase relative to the entropy generator clock determining most of the
results from the entropy source, while looking fairly random. Any
weakness in the raw random data stream is hidden from us by the AES
encryption done as a post-process.
I simulated back-to-back inverters in my .35u low power CMOS process
in SPICE to see if I could figure out how to make a practical circuit
using Intel's topology.  If it works, it would be fantastic.  I think
I can get rid of most of the supply noise issues.  I had a similar
problem in my "Infinite Noise Multiplier", so I switched to powering
the circuit with nothing but large W and L constant current sources,
and using the range from 0V to Vref, rather than 0V to VDD, because
Vref is stable relative to AVSS. However, I wasn't able to get enough
noise to make Intel's ciruit work, though that may be due to
limitations in the SPICE simulator.
Has anyone else had success using Intel's RNG topology?

@_date: 2013-12-11 00:10:52
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
I have to take back my criticism of Intel's RNG.  I got my sims
working for a version of their architecture in .35u CMOS, and it's
simply better than my "Infinite Noise Multiplier".  It's probably the
best true random noise generator ever.  I still don't like how their
schematic is seems highly sensitive to supply noise, but we don't know
what the actual circuit looks like.  Intel hasn't told us.
So, I'm going to modify it a bit to use the resistors available on my
chip and reduce the caps, fix the supply sensitivity, and I think I
can run 16 of these things in parallel at 100-200MHz on the tiny .35u
CMOS chip I'm designing.  I'll spit out the raw waveforms from the
inverters, buffered once, through 16 "analog" pins, so there wont be
any fear (hopefully) that I'm cooking the data on-chip, before you can
see it, and I'll open-source the schematics.  If there's a circuit
that can consume all 1.6Gbit/sec of this raw data, have fun with it!
On the digital side, I'll XOR bits together to get the bandwidth down
to something reasonable, which I can send over USB, and provide a
simple Linux driver.
This thing will definitely put out RF, but since I'm making the raw
data available at the pins, should I care?  By the way, this is just a
for-fun project at work.  I get to do a free chip design :-)

@_date: 2013-12-11 00:11:18
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
raw samples at 1.6Gb/s would be useful infrequently[0]; raw samples
from a trusted device extremely useful bitrate!
what is "my chip" and how can we find out more / support your efforts?
best regards,
0. to date i have only maxed out 400Mb/s raw VIA Padlock sources for
SSD FDE initialization and constructed experiments in temporal key
rolling.  it is however common to regularly consume on the order of
10Mb/s on a busy server, generating many keys, using crypto happy
software, etc.  (this is why every processor, every embedded device
should have a physical entropy source, with access to raw samples.
still waiting...)

@_date: 2013-12-11 07:17:09
@_author: coderman 
@_subject: Android IMSI Catcher detection 
the partnership with NGA to deploy them gives a hint: this is putting
USRPs up close and personal to target for exploitation.
(the USRP's are definitely more portable than my favorite SDR, the Noctar[0]!)
given the obtained bits mentioned (WLLids, DSL accounts, Cookies,
GooglePREFIDs) gathered and then handed off to TAO for further QUANTUM
INSERT fucking of target systems it is likely they are doing GSM/cell
MitM to observe identifiers, along with WiFi attacks, and other egress
rather than deploying baseband exploits or deep active attacks
directly against the devices or other networks they're communicating
thus CNE in this case is cell MitM/WiFi pwn with a USRP rogue tower to
get identifiers for TAO.  and TAO is where they get dirty with "remote
exploitation" of the device itself and other targets on networks it
we've seen how they have a smorgasbord of weaponized exploits to cover
the gamut of target hardware and technical acumen in the QUANTUM
INSERT / TURMOIL / TRAFFICTHIEF / MUTANT BROTH / etc, etc. style
efforts.  it appears they're using this same infrastructure where
possible for mobile; restricting CNE on the ground only to target.
best regards,
0. Pervices Noctar

@_date: 2013-12-11 07:22:12
@_author: coderman 
@_subject: Android IMSI Catcher detection 
see also this section on the OPEC hacks:
Heres how the NSA and GCHQ go after an organization like OPEC step by
step, based on an analysis of the NSA and GCHQ documents exposed by
Step 1: Identify. Using the NSA-built packet capture and inspection
system called TURMOIL, the agencies filter through Internet traffic at
a network choke point looking for specific "fingerprints" in traffic
that identify users with the organization being targeted. Data from
TURMOIL gets pulled into a number of traffic analysis tools, such as
XKeyscore and TRAFFICTHIEF, which do different sorts of packet
XKeyscore is the NSA's distributed search engine, catching a large
chunk of international Internet traffic for analysis. It helps find
things deep in the clutter of the Internet that analysts might miss by
allowing them to use search terms to find things in both live and
cached Internet traffic.
TRAFFICTHIEF, on the other hand, is much more focused. It filters for
very "strong" indicators, like known sets of IP addresses, addresses
within e-mail traffic, or user names in logins to social networks or
other services. It provides less depth of analysis than XKeyscore, but
it can handle much larger loads of data because it is more selective
about what it processes.
Together, the tools can be used to identify the systems used by an
individual or organization, including ranges of addresses that they
may use from work or home.
Step 2: Target. Using the profiles built using the surveillance tools,
the agencies can then identify potential points of attack. XKeyscore,
for example, can be used to search for patterns that identify known
security vulnerabilities within a range of addresses. Web visit
histories, e-mail traffic, and other data are analyzed looking for the
most likely (and least detectable) approach to gain access, and a
specific attack plan is crafted, including the identification of where
to launch the attack from.
At the NSA, this sort of thing is the work of Tailored Access
Operations. In the case of OPEC, the targeting process apparently went
on for several years as the NSA sought openings for an attack.
Step 3: Attack. Depending on who the target is, the NSA and GCHQ have
a variety of options. The least costly is to use access provided by
one of the intelligence agencies' telecommunications "partners" who
own network equipment at an exchange or other choke point that the
target's Internet traffic passes through. The agency running the
attack can use that access to introduce changes to Internet routing
tables that detour the targeted individual's traffic. But in some
cases, the NSA and GCHQ may have to perform "unilateral" taps on
network backbones to gain that level of accesstargeting a piece of
network hardware to take over or splicing directly into the target's
own connection to the Internet.
It's not clear which attack the NSA used to gain access to OPEC's
systems, though the GCHQ used a Quantum attack two years later to gain
its own very special access to the cartel's network. In the case of
the Belgacom hack, the GCHQ used a Quantum insert attackrouting the
Web requests for LinkedIn and Slashdot from the engineer being
targeted to a server posing as those sites. The NSA has used the same
approach to intercept traffic to sites such as Google.
The man-in-the-middle server can present content from the actual sites
the target intended to visit, but it can also add content to the
traffic, using what's called packet injectionmodifying the contents
of the data as it passes throughand intercept the user's credentials.
And by using a forged certificate, the NSA can intercept encrypted
traffic intended for the destination site.
Once the user has connected to the fake server, the intelligence
agencies can use the connection to launch attacks against the target's
Web browser to install monitoring software or other malware, using
similar techniques to those used by hackers. They can also use
credentials exposed via the man-in-the-middle attack to gain access to
other accounts owned by the target and to troll through connections in
those services that might be potential targets.
Step 4: Exploit. Once the target's computer has been successfully
attacked, the effort begins to look much like that of the Chinese
cyber warriors' attack of the New York Times or what cyber criminals
typically do when they score access to high-value targets. The
agencies' hackers work to stealthily expand their level of access,
using customized remote administration tools to grab user privileges
and gain access to other network resourcesmail servers, file servers,
and other network systems. They then start to "exfiltrate" data from
these systems and deliver them to analysts.

@_date: 2013-12-11 14:08:46
@_author: coderman 
@_subject: Android IMSI Catcher detection 
CNE+TAO as non destructive espionage (politics)
  but they also play
CNE+TAO as kinetic force multiplier (war)
so the answer is: both!  depending on the target...

@_date: 2013-12-11 18:04:39
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
Ivy Bridge is the codename for a line of processors based on the 22 nm
manufacturing process developed by Intel. The name is also applied
more broadly to the 22 nm die shrink of the Sandy Bridge
microarchitecture based on FinFET ("3D") tri-gate transistors, which
is also used in the Xeon andCore i7 Ivy Bridge-EX (Ivytown), Ivy
Bridge-EP and Ivy Bridge-E microprocessors released in 2013.

@_date: 2013-12-11 18:16:07
@_author: coderman 
@_subject: Android IMSI Catcher detection 
Regarding the CCP FY 2013 goals per
"Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4G/LTE)
networks via enabling. [CCP_00009]"
i wonder if they upgraded to N210 (pairs?) for good 4G/LTE performance?

@_date: 2013-12-11 19:01:31
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
"used in Virtual Private Network" == PPTP,IPsec,OpenVPN,etc.
"Web encryption devices" == in my interpretation, this is any targeted
hardware with the vulnerable chip.  it could be a tablet, a desktop,
and rack mount server...  any of these platforms could speak VPN or
Web crypto.  TAO/SCS do like to get into the switches though ;)
mostly "cloud infrastructure", "software defined data center", and the like:
back in the day, Sun got tired of the (relatively) slow performance
and latency of crypto offloading via bus and simply threw it into the
core.  you were still offloading crypto, but within the CPU.
also note that endpoint compromises sufficient to decrypt VPN or
secure web traffic is already present in TAO/CNE's tasking.  this
effort [CCP_00009] may focus on VPN concentrator / secure web proxy
deployments specifically to handle the RDRAND lookup per their private
starting counter.
previous back doors have also used entropy leakage sufficient to bring
a brute force attack into reasonable effort, while still denying third
parties a class break of the entropy / keys used.  this type of key
space search is not done on the ground with portable CNE but instead
back at SCS...
on a related tangent, the lack of additional disclosures is quite
frustrating.  this entire conversation would be resolved in a glance
if $the_snowden_gatekeepers were acting in the public interest.  :/
best regards,

@_date: 2013-12-11 23:41:41
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
i remember seeing software to do this, but for the life of me cannot
find it.  anyone?
my favorite redaction technique is still the Adobe white text on white
background in PDF trick; combine with a filter for CONFIDENTIAL /
PROPRIETARY and you've got a fire hose of informative flotsam...[0]
best regards,
0. "The Revenge of Distance: Vulnerability Analysis of Critical
Information Infrastructure"
  back when Sean Goreman's work and post 9/11 hysteria combined to drive
critical infrastructure information into access controlled obscurity
(not even FCC outage reports public!) i used this technique with
custom deep web crawlers for court documents and other technical
references.  code doesn't care about color ;)   thus fiber counts
along specific rights of way allocated to named customers provided the
specific capacity information needed to make useful models for
measuring "spatial implications of telecommunications infrastructure
susceptibility to targeted attack".  this was the first time i wrote
code that actually scared/disturbed me :o

@_date: 2013-12-12 06:08:35
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
i see your skepticism, and i raise you a retort! ;)
i even have a list of candidates you can experiment with to confirm
Intel Ivy Bridge as best fit. [0]
plus a few more things, e.g. your ~250-300million $USD/year budget goes toward:
"actively engag[ing] the US and foreign IT industries to covertly
influence and/or overtly leverage their commercial products' designs
[... to] make the systems in question exploitable through SIGINT
collection (e.g., Endpoint, MidPoint, etc.) with foreknowledge of the
modification. and, Insert vulnerabilities into commercial encryption
systems, IT systems, networks and endpoint communications devices used
by targets.
only with "foreknowledge of the modification" are you able to utilize
this backdoor. (NSA does not like to share)
also, this year by end of year, in 2013 you expect to:
- Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4GL/LTE)
networks by inserting vulnerabilities.
- Complete enabling for [well recognized name] encryption chips used
in Virtual Private Network and Web encryption devices.
and last but not least,
- Shape the worldwide commercial cryptography marketplace to make it
more tractable to advanced cryptanalytic capabilities being developed
by NSA/CSS.
Ok, given those requirements. Who fits the bill?
High end platform:
Intel targets what it believes is a significant growth opportunity to
bring the Intel Architecture into a rapidly evolving networking space.
Intel added to its portfolio with the introduction of the Highland
Forest platform, which combines the vendors Xeon E5-2600 v2 CPU with
its new Coleto Creek chipset. Price said Highland Forest  which can
pack up to 20 2.4GHz Ivy Bridge CPU cores  will offer two to six
times the performance of the previous Crystal Forest platform, which
was launched in October 2012.
Highland Forest, with Intels Data Plane Development Kit, can deliver
up to 255 million packets per second (p/s)  more than the 140 million
p/s from Crystal Forest  as well as security capabilities of 110
Gigabits per second of IPsec and 200 Gb/s SSL security for encrypted
IPsec (VPN) and SSL (Web crypto) and lots of it!  sounds interesting.
tell me more!
other market points of note:
- "Intel currently has over 15 SDN/NFV qualification trials underway
with carriers in all major regions.  Schooler emphasized that Intel
has no intention to sell directly to service providers and is fully
committed to launching an Intel Network Builders Ecosystem of industry
players supporting the Intel Architecture."
- "6WIND Announces Availability of Support for Intel Xeon Processor
Platform for Large-Scale Communications Infrastructure Systems,
Formerly Called Highland Forest 6WIND announces the availability of
support within the 6WINDGate software for the Intel Xeon Processor
Platform for Large-Scale Communications Infrastructure Systems,
formerly called Highland Forest. With its optimized support for the
Intel QuickAssist Technology that provides hardware acceleration for
encryption and compression, 6WINDGate delivers best-in-class
performance for networking applications such as WAN optimization, VPN
appliances, firewalls and Unified Threat Management (UTM) systems." -
funny they seem to distance themselves from "Highland Forest" and "Ivy
Bridge" in this press release and product launch...  [
 ]
they sound interesting, like they sell to many industries at large
scale.  are they a popular company/product?
 ""6WINDGate is already deployed in tens of commercial LTE networks
throughout Asia, Europe and North America, while also being used by
multiple tier-1 suppliers of enterprise and cloud networking
hey look, LTE! ...
ok, so that's a little suspect.  what's that, there's more you say?
"I am so glad I resisted pressure from Intel engineers to let
, "Oh, I should add that just today I had to fight back an attempt by
a Red Hat engineer to add a configuration option to blindly trust
RDRAND and bypass the entropy pool"
then the FreeBSD change of heart.
hey Wind River, how are you using RDRAND?
now what about Intel themselves, are they also pushing the chip?
Intel officials are making aggressive moves to expand the reach of its
silicon beyond servers and into other parts of the data centre.
Schooler said the company has been making products for networking gear
for about a decade, and has made significant strides in recent years.
Its also made several acquisitions  such as of Sensory Networks,
Ethernet chip maker Fulcrum Microsystems and networking software maker
Aepona, whose technology enables telecoms and cloud service providers
to offer more services on their networks.
Intel is looking to take advantage of the growth opportunity
networking represents, Schooler said. The market Intel is targeting is
about $16 billion (9.7bn), and the chip maker currently has about 5
percent of it. Along with its x86 architecture, Intel also is
developing accelerator chips for such jobs as packet inspection and
whew.  that's a lot of context and circumstance.  let's look back over
your goals for 2013:
Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4GL/LTE)
 - AFFIRMATIVE!
Complete enabling for [Intel Ivy Bridge] encryption chips used in
Virtual Private Network and Web encryption devices.
- AFFIRMATIVE!
Shape the worldwide commercial cryptography marketplace to make it
more tractable to advanced cryptanalytic capabilities being developed
by NSA/CSS.
- AFFIRMATIVE!
i will admit that i am continually impressed by NSA/SCS achievements.
they're extremely competent!
my reading between the lines: it is not a special chip, it is a
special collection of many of them (20+) handling tier-1 core traffic
encryption, which is an excellent point to aggregate a vulnerability
in keying ciphers. (ignore public key for now, since we can just focus
directly on session/temporal keys!)
0.  please to be experimenting with datas:
Interface Masters Technologies
Freescale Semiconductor
Alteon SSL Accelerator
Nortel SSL Accelerator
Strangeloop Networks
Riverbed Technology
Coyote point systems
Crescendo Networks
Microchip PIC32MZ
Barracuda Networks
Kemp Technologies
Check Point VPN-1
Sun Microsystems
Foundry Networks
Cavium Networks
Cavium NITROX
Juniper Networks
Nortel Networks
Array Networks
Intel Ivy Bridge <- only this is right length in justified context shown
Forum Systems
Cavium Nitrox
CAI Networks
A10 Networks
Cisco Systems
Citrix Systems
Sun SCA6000
MIFARE Plus
Network Box
Coleto Creek
F5 Networks
Cisco PIX
parting words:
On April 17 at the Open Networking Summit, Intel executives laid out
the companys strategy around data center networking and the
burgeoning trend of software-defined networking (SDN). They also
showed that their efforts will expand beyond simply supplying the
processors for networking hardware. The company unveiled reference
architectures designed to help enterprises, cloud service providers
and telecommunications companies more quickly create hardware and
software for SDN and network-function virtualization (NFV), moves that
could bring Intel into closer competition with the likes of networking
giant Cisco Systems and chip maker Broadcom.
 - don't let them get away with it!
open up raw access to entropy sources!!
don't discriminate against the unit, one is prime!!!

@_date: 2013-12-12 06:52:20
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
one last amusing note, Google has gone whole hog on SDN:
  how amusing would it be if they implemented inter-DC IPsec keyed with
RDRAND directly on compromised cores in one of these Highland Forest
like SDN deployments?
i can already see the updated napkin sketch now, and imagine the
streaming swears pouring forth from the googlies once uncovered...

@_date: 2013-12-12 08:20:44
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
let it be known:
in the event of my untimely demise under suspicious circumstances, i
will my coins to JYA so he may bless my passing with grand oration and
strong tale as he is so adept at providing.  *grin*
on a serious note, the useful steps are clear:
1. Intel releases raw access to noise samples
2. NIST defining and mandating a design that also supports raw sample
access, (we could change subject here to discuss something pleasant
like on-line checks and continuous checks,)
3. OS distributions include userspace entropy scavenging daemons
(haveged, dakarand, etc) to complement properly vetted hardware
entropy sources run in a conservative fashion.  default is set safe,
not fast.
is that so much to ask?

@_date: 2013-12-12 08:42:02
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
the bulk of 2012 was consume user hardware.  the endpoint is a totally
solved problem (read: trivial to exploit in many ways, all day, every
day, per the docs)
only server Ivy Bridge: Xeon E3 in mid-2012.
the cores pushed in the SDN initiatives above came out not so many months ago...
high capacity crypto aggregation points like this are an ideal target,
with backdoor keying of VPN/SSL the ideal (passive) attack with their
view of target's long haul fiber.
but not released, and "enabling" means tied into X-KEYSCORE,
TRAFFICTHIEF, whatever else gets draped off UPSTREAM...
the backdoors for all the other vendor hardware happened in years
prior.  HSMs and crypto accelerator gear is not exactly a vibrant or
competitive market.  in fact, these companies never seem to die, just
carry on with decent margins riding on incremental design upgrades
until they're bought out by a larger/growing competitor. ;)
of course, this could be because companies like Sun charge $9,999 for
an HSM/accelerator that is at best a reasonable cost at $1,499...

@_date: 2013-12-12 09:18:09
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
this does bring up an interesting point:
while it may be more efficient to use the same "key" for the DRBG
output across all processor lines, it would be more secure to use a
different key per line.  this implies that each iteration of Sandy
Bridge -> Ivy Bridge -> Haswell needs to be "enabled" by CCP, with
Xeon E5 debut in 2013 as discussed.
for Sandy Bridge, this would have shown in 2010? and unless in network
equipment described simply as "enabling decryption for Sandy Bridge
used by $operating systems and $applications."
sadly we'll have to wait a while to confirm this conjecture for
Haswell.  and we'll have to wait forever for more leaks apparently, as
the continuing decline of details demonstrates...
best regards,

@_date: 2013-12-12 09:23:50
@_author: coderman 
@_subject: Fwd: [liberationtech] PrivateSky Takedown 
Certivox Asked That We Share Their Side of the Story on the PrivateSky Takedown.
The real story on the PrivateSky takedown.
Posted by Brian Spector on Thu, Dec 12, 2013
With the story about our PrivateSky takedown now public, I want to
take the opportunity to clarify a few points in various articles that
have appeared since yesterday covering the story.
Some headlines strongly infer our friends at GCHQ "forced" us to take
PrivateSky down. That's not the case.
Secondly, a very important point wasn't printed. GCHQ couldn't, by
law, request a blanket back door on the system. There are a very rigid
set of controls that mean only specific individuals can come under
surveillance. The legal request for such surveillance has a due
process that must be stridently followed. At no time did I or anyone
at CertiVox talk about CertiVox in relation to any RIPA warrant, only
the generic process by which these warrants are served.
By saying "our friends at GCHQ", there is no facetiousness intended.
The team at CertiVox have the upmost respect for the folks we
interacted with at GCHQ. They took the due process I outlined in the
previous point very seriously. We found that as an organisation, and
every individual involved there, were as worried about a breach of
public trust as much as we are.
Finally, I believe very strongly the following should be a larger part
of the public discourse of these subjects. What everyone needs to
understand is that every developed democracy in the world, even where
privacy rights are enshrined to the maximum efficacy by statute, has
laws on the books that mandate that Internet Service Providers have
facilities to work with law enforcement for the purposes of legal
intercept, to enforce public safety and security.
Being L.I. capable is a very important set features and functions that
must be in place for any credible, commercial service on the Internet.
In endeavouring to make PrivateSky as secure as possible, we
overlooked this critical requirement when we built PrivateSky.
When CertiVox positioned PrivateSky as the easiest to use and most
secure encrypted messaging service, we really had two significant
points of differentiation. First, even though we held the root
encryption keys to the system, it was architected in such as way that
it would have been all but impossible for our internal staff to snoop
on our customer's communications, or for the service to leak any of
our customers data. Secondly, our possession of the root keys, and
our use of identity based encryption, made the system incredibly easy
to use. For the user, there were no private or public keys to manage,
every workflow was handled for the user in an easy to grasp pure HTML5
interface, no hardware or software required, just an HTML5 browser.
We boxed ourselves into a feature set and market position that when
called upon to comply with legal statues, we simply had no alternative
but to shut the service down. We built it, but we couldn't host it.
Why? Because as you can probably surmise, there is an inherent
impedance mismatch between being able to host a commercial
communications service that gives the upmost in privacy to its users,
against any breach, whilst at the same time being able to operate
safely within the confines of the law as it is on the books in most
countries on the planet.
In summary, it's the abuse of the communications interception in the
Snowden revelations that has everyone up in arms, as so it should. But
thats not what happened with PrivateSky.
What is our next move?
Watch this space.
Liberationtech is public & archives are searchable on Google.
Violations of list guidelines will get you moderated:
Unsubscribe, change to digest, or change password by emailing
moderator at companys

@_date: 2013-12-12 17:17:03
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
the worst kind of xpost of all?
every day without RDRAW is another day of my life with provably less
information theoretic meaning.  ;)
two chips or two families or two architectures or ...
is this a game of twenty questions? can we do a reddit AMA for the
leakers with their stash at the ready?
you know, if we had more documents providing context,
past experience tells us they like attacks universally effective,
unidirectional, silent/random-looking (without secret knowledge), and
don't mind expending custom hardware and algorithms to do it.
Dual_EC_DRBG doesn't count - that was a "jeezus, everyone asleep at
the wheel.  i bet we could get this approved!" moment.
triggering is active, observable (potentially), and usually
re-playable.  the only "delivered payloads", ala
EGOTISTICAL*/ERRONEOUS*, appear to be for confirmation pinging or
identification, and memory resident forensic/exfiltration run locally
on the host.  even the slides you link to note the OPSEC concerns of
"adversarial actors" (i think that's us on this list?)
sure.  note how this is also more complicated, with higher risk?  if
there was a better way i bet they'd choose it!
also, Intel and ARM, Apple and ARM, Apple and VIA, etc.
  you're not helping my pleading and cajoling for RDRAW sir.
on a related note, if Intel were to decide to include RDRAW in next
CPU line design, how long would it be to retail channels? >3yrs?

@_date: 2013-12-12 17:55:56
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
correction: persistence after reboot also has been stated to be
performed, though optional.  per Bruce's write up[0],
1. target identified (at endpoint or observable mid-point)
2. QUANTUM INSERT redirect to FoxAcid server
3. FoxAcid picks loader exploit according to: target value, exploit
value, target skill, other factors.
4. Loader exploit delivered to target
5. confirm success?  if no, abort.
6. With loader active, run two basic first pass payloads:
7. Collect configuration information (apps, registry, settings, etc.)
8. Collect location information
9. Escalate to persistent infection, run arbitrary other plugins, etc.
in any case, this is more consumer endpoint focused.  not applicable
to embedded VPN/HTTPS devices.
0. Bruce Schneier's attacking Tor article for the Guardian:

@_date: 2013-12-12 18:21:33
@_author: coderman 
@_subject: How long does it take to design and release a chip? 
using Sandy Bridge as a reference: 4 years design to demo, 1-2 years
demo to available.
design began 2005
demo'd in 2009
shipping in 2011

@_date: 2013-12-12 22:25:50
@_author: coderman 
@_subject: Multiple Plots by US, UK to Kidnap Edward Snowden 
ah FSB; you crack me up!
'''A senior officer of Russian counter-intelligence said: "Although
the Federal Security Bureau does not do anything about human rights
activist Snowden, the service has been active in counterintelligence.
I am pretty sure that kidnaping the former NSA employee will be
dramatically challenging." He also thanked "former NSA employees and
journalists for publishing such information...'''
Edward Snowden can be kidnapped from Russia?
10.12.2013 14:57
Edward Snowden, the whistleblower of NSA's total control systems can
be kidnapped from Russia. This is a priority for the British MI-6 and
the British Embassy, former NSA agent Wayne Madsen said, referring to
his colleagues.
Of course, nothing is known whether the CIA received the task, and
whether the U.S. Embassy is going to be involved in the activities to
try to kidnap Snowden. However, the British Embassy has already
tracked calls and letters of Snowden's "inner circle" and begun to
"dig up" their contacts in Moscow.
According to The Guardian, Snowden has the information, the disclosure
of which could become a nightmare for the U.S., even though the
fugitive NSA specialist decided not to disclose some of his data. In
addition, The Guardianadmitted that the media have so far published
"only 1%" of available information about NSA's total control over
billions of people in different countries.
Nevertheless, even this one percent has already made the UK
authorities introduce outright censorship against those who reveal
secrets of "global surveillance."
In particular, Wayne Madsen said that his girlfriend, who previously
worked for the National Security Agency as an expert on the Russian
language, tried to contact Snowden's acquaintances. Afterwards, she
was invited to come to the British Embassy and undergo special
training. She was also asked to report of FSB's interest in her
persons and communications.
The press quoted a former NSA expert, who said that the job to find
Snowden was of the highest priority for the embassy. Moreover, it was
said that the future operation to kidnap him involved number one MI-6
officer at the embassy, who worked under diplomatic cover as the
director for regional security.
The Center for the Study of Globalization has previously reported that
should the operation be successful, Snowden would be delivered to the
UK or the U.S. For the time being, the flywheel of total wiretapping
that Snowden launched was working against him to the utmost. "MI-6
intelligence agencies have begun to analyze the information they were
able to obtain through intelligence," the statement from the center
A senior officer of Russian counter-intelligence, whom Politonline.ru
confidentially managed to talk to, said: "Although the Federal
Security Bureau does not do anything about human rights activist
Snowden, the service has been active in counterintelligence. I am
pretty sure that kidnaping the former NSA employee will be
dramatically challenging." He also thanked "former NSA employees and
journalists for publishing such information, but added that
operational, technical and other measures to counter intelligence and
other illegal activities of foreign secret services on the territory
of Russia were  constantly maintained.
It only remains to add that the CIA has recently created a special
section in Russian on its official website, in which the department
offered Russian citizens (!) to join American intelligence. To choose
from, for example, the CIA offers engineering and technical
directions, a linguistic job, a secret agent with the knowledge of
Russian language and experts in business and analysts. The CIA
reportedly hopes to obtain classified information from newcomers in
the above areas to establish a new database of agents.

@_date: 2013-12-13 23:13:30
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
any details on "Mackerel: A Progressive School of Cryptographic
Thought" or "The Factoring Dead: Surviving the Cryptopocalypse" ?

@_date: 2013-12-14 04:33:31
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure as per the FreeBSD announcement[0] and others[1][2] direct use of
RDRAND as sole entropy source is not recommended.
from Westmere onward you could use AES-NI to make crypto fast in
OpenSSL.  a common theme is to initialize OpenSSL via
ENGINE_load_builtin_engines() which lets OpenSSL take advantage of
this acceleration.
with Sandy Bridge you also got RDRAND. now load_builtin_engines
results in the application using RDRAND directly for all entropy, in
addition to accelerating AES.
if you are using an application linked with openssl-1.0.1-beta1
through openssl-1.0.1e you should do one of the following:
a.) rebuild your OpenSSL with OPENSSL_NO_RDRAND defined.
b.) call RAND_set_rand_engine(NULL) after ENGINE_load_builtin_engines().
c.) git pull latest openssl with commit: "Don't use rdrand engine as
default unless explicitly requested." - Dr. Stephen Henson
the OPENSSL_NO_RDRAND option is recommended; an inadvertent call to
load engines elsewhere could re-enable this bad rng behavior.
best regards,
0. "FreeBSD Developer Summit: Security Working Group, /dev/random"
  1. "Surreptitiously Tampering with Computer Chips"
  2. "How does the NSA break SSL? ... Weak random number generators"

@_date: 2013-12-14 06:42:55
@_author: coderman 
@_subject: cognitive dissonance in threat modelling? 
i hope it was worth it for them!  'cause this is going to be expensive...
Matthew Green posted insights on how one might implement backdoors in chips:
  as well as the "Weak random number generators" attacks:
  regarding the unredaction automation: the typographic interpolation
trick discussed on the list, matching type face with justified spacing
with candidate word(s), is a really annoying idea and won't get out of
my head.
 (i tried to distract and forget with a Tor patch -
 - to no avail ;)
currently playing with scipy, skimage to:
- obtain from human initial document image
- obtain from human seed words / dictionary for matching
- misc. contrast / levels / etc conditioning for text optimized monochrome
- mask document image into text and non-text areas
- edge detect, align to horoz (for selections by x/y)
- broad region detect text rows into individual row images
- region detect individual chars per row image then assign char value via OCR
- insert human in loop to confirm / correct OCR row by row
- insert human to select redact line + redact area
- interpolate justified components: character spacing, word spacing, etc.
- iterate over known text with candidate fonts until best match.
- iterate over candidate words in best font until best match.
- success?  what confidence? (GOTO 10)
(the extra work for char by char and whole doc dis-assembly is in case
a "re-assemble scanned chars into candidate" rather than "match font
and re-produce text candidate" mode is needed.)
something better, Beuller?  ... Beuller?
... this won't be the last time i find this code useful!
current working set, including known wrong (please add suggestions :)
FeliCa and AMD
Nortel Networks
Apple and ARM
Array Networks
Cisco and Atmel
Philips and VIA
HiFn and Atmel
Cisco and ARM
Cisco and HiFn
Intel Ivy Bridge
Intel RDRAND
Atmel and IBM
Atmel and VIA
Apple and VIA
Intel and AMD
Intel and ARM
Forum Systems
VIA XSTORE
Cavium Nitrox
CAI Networks
A10 Networks
Cisco Systems
Citrix Systems
Sun SCA6000

@_date: 2013-12-14 08:40:34
@_author: coderman 
@_subject: [Full-disclosure] RDRAND used directly when default engines 
Full Disclosure On Sat, Dec 14, 2013 at 8:31 AM, Dennis E. Hamilton
i think the word you're looking for is "Feature".
... but you and me are not the customer.   ;)

@_date: 2013-12-14 09:25:49
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure this won't leave you vulnerable, but it will crash your app.  not
broken convention:
      /* If we are using a version of OpenSSL that supports native RDRAND
         make sure that we force disable its use as sole entropy source.
         See  */
      if (SSLeay() > OPENSSL_V_SERIES(1,0,0)) {
        t = ENGINE_get_default_RAND();
        if (t &&
            (strcmp(ENGINE_get_id(t), "rdrand") == 0)) {
          log_warn(LD_CRYPTO, "OpenSSL is using RDRAND by default."
                   " Attempting to force disable.");
          ENGINE_unregister_RAND(t);
          ENGINE_register_all_complete();
        }
      }
see best regards,

@_date: 2013-12-14 10:36:56
@_author: coderman 
@_subject: Fwd: Jacob impervious to "Rubber Hose Cryptanalysis" performed by 
this is pretty amusing :P
(and needs a "Knuth is my Homeboy" homage?)
Layers of the struggle privacy vs surveillance, in my picture of the year
This is the picture of the year for me, on so many different layers:
  [view the image directly via:
    ]
Stewart Baker, ex-NSA general counsel, and Jacob Appelbaum, internet
freedom activist/hacker/journalist (left, right).
They pretty much symbolise the two sides of the global scandal of the year.
They also symbolise the attitudes of both sides.

@_date: 2013-12-14 13:52:13
@_author: coderman 
@_subject: c4-r3kN.txt (urls) 
there are variations... i am afflicted with the contagious and acute
Entropus Major virus.  and now, any crypto system of which i am not
able to see the input randomness, by precision jitters or max rate
sampled freewheelers, or even that crazy faraday'ed up leadzone with
Geiger counter she told you about at BSides,
but hide that sweet sweet river of unrelated bits behind a bytecode
block??  that's just not cool!
until then, i've "borrowed" Peter G's d20's for a bit - hope he
doesn't need to roll them any time soon.
 ;P
i never considered prohibition as constraint on state of mind in public,
mainly thinking along monetary and covert economic activity angles.
but considering the public, and the multitudes of social scenes no
longer "lubricated" or under shadow of persecution, this would have a
direct and personal impact on many.
certainly a world removed from the producers and distribution
activity, which tends to monopolize the zeitgeist of the prohibition
crypto-compromise as frantic inferno is not quite right.,
the impact is almost invisible, until it is dire and potentially life-ruining.
global compromise for ever-present surveillance is crypto-HIV
 sure, you're fine now.  probably a while, no concerning symptoms.
then OMGWTFBBQ punctuated equilibrium, over-reaction,
suddenly crypto-AIDS just ate your life and shat out
 terminal-solitary-confinement and/or financial ruin.
plenty of company with all the other susceptible individuals, more than
you imaged...  equally destroyed by a silent corrupter too easy to ignore
they call it "Tailored Access" and "Computer Network Exploitation" for
... when they aren't having the FBI violating domestic providers in
their NSL hole.
it's legit.
on a more serious note, regarding the assumption:
 "if everything is backdoored already, essentially key escrow exists"
NSA has stated that many of their BULLRUN techniques are incredibly
fragile.  a number of them now burned in leaks, many yet to get
stuffed. if they "did it risky"[0], perhaps feeling emboldened by the
seeming success of Dual_EC_DRBG and friends, a common key / reduction
hidden behind AES-128 rounds could be discovered, independently
confirmed, and properly attributed.
so not only can the backdoors be broken up, replacements which are
resistant to compromise will take their stead.  "everything" becomes
"much" becomes "very little" until ideally such invasive tactics are
reserved for HUMINT tasked "good ol'e detective work" with legal
bonafides judged according to public laws and applicable to all
persons on earth, not just tribal deference pointed inward.
the jury is out; there are encouraging signs... but first, back to
those raw samples!!
best regards,
0. "Some thoughts on suborning encryption chips"
  A much easier approach is to simply eschew safety altogether and use a
fixed AES key that's common to all chips.
  [ED: or fixed modification to the AES-CBC-MAC compressor then masked
by the DRBG in front using "Stealthy Dopant-Level Hardware Trojans."]
But the NSA would never do something that risky. Right?

@_date: 2013-12-15 18:11:20
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
"Join us at Columbia Law School as renowned security expert Bruce
Schneier talks with Eben Moglen about what we can learn from the
Snowden documents, the NSA's efforts to weaken global cryptography,
and how we can keep our own free software tools from being subverted."

@_date: 2013-12-15 19:01:47
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
Peter's BlueHat talk on congitively flawed humans also excellent:
  so cypherpunks,  if you write code that you want to be useful:
don't write code with assumptions and admonishments inherently unheedable.
write code with awareness and compensation for silly human inclinations!

@_date: 2013-12-15 19:11:44
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
this also implies:
 "There is only one Mode, and it is Secure."

@_date: 2013-12-15 19:30:32
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
your understanding is flawed.  let me clarify:
the NSA does not currently break Tor on demand at the protocol level.
all indications are this is currently true.
the NSA and others have great success around Tor by opportunistically
watching users fuck up (see other usability thread), by pwning their
horribly insecure systems (0days as far as the eye can see..), and by
actively manipulating user paths to the Tor network or destination
"forget your global passive adversary threats, active denial and
manipulation of service attacks are _really_ scary!"
said another way, breaking Tor at protocol level is currently too
expensive a solution to the same ends provided by much cheaper means.

@_date: 2013-12-15 20:57:56
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
of course.  it's also expensive, relative to other options. i'm saying
NSA spends money carefully.
never said either thing.  i'm also long on the record advocating for
the next generation of low latency anonymous networking that _does_
provide strong defense against traffic analysis.  turns out the
details are, um..  complicated ;)
i'm glad that is not, in fact, my reasoning.
of course there are more sophisticated means available to them; that
will always be the case.  they've got BILLIONS and BILLIONS every
year, for their projects.
the point is not making something "NSA proof", which is an ill defined
and open ended venture.  the point is increasing the cost of their
efforts and narrowing their scope.
the more money they spend getting less and less in return, the better!

@_date: 2013-12-16 00:11:42
@_author: coderman 
@_subject: Aqua - a high bandwidth anonymity system that resists traffic analysis 
this seemed to get lost in the hubub over the summer,
Towards Efficient Traffic-analysis Resistant Anonymity Networks
Stevens LeBlond, David Choffnes, Wenxuan Zhou, Peter Druschel, Hitesh
Ballani, and Paul Francis
August 2013
Existing IP anonymity systems tend to sacrifice one of low latency,
high bandwidth, or resistance to traffic-analysis. High-latency
mix-nets like Mixminion batch messages to resist traffic-analysis at
the expense of low latency. Onion routing schemes like Tor deliver low
latency and high bandwidth, but are not designed to withstand traffic
analysis. Designs based on DC-nets or broadcast channels resist
traffic analysis and provide low latency, but are limited to low
bandwidth communication.
In this paper, we present the design, implementation, and evaluation
of Aqua, a high bandwidth anonymity system that resists traffic
analysis. We focus on providing strong anonymity for BitTorrent, and
evaluate the performance of Aqua using traces from hundreds of
thousands of actual Bit-Torrent users. We show that Aqua achieves
latency low enough for efficient bulk TCP flows, bandwidth sufficient
to carry BitTorrent traffic with reasonable efficiency, and resistance
to traffic analysis within anonymity sets of hundreds of clients. We
conclude that Aqua represents an interesting new point in the space of
anonymity network designs.

@_date: 2013-12-16 00:27:16
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
this is all coming to a few conclusions, where we simply disagree:
a) the black budget was leaked, along with other leaks about technical
capabilities and programs and priorities.  intelligence community is
not immune to government budget pressure.  you insist there is a
limitless expansion, and an unlimited technical ability.  i disagree.
b) you insist Tor's origins and funding sources are proof of
malfeasance; they've responded by diversifying funding. (not to
mention scrutiny of Tor by external, mututally un-trusting parties.
you can look at the code yourself, and interface with controller and
path construction yourself, etc.)
c) we both appear to agree that limiting solutions to technical realms
is missing the bigger picture.  yes to political reform that cuts
funding and restricts scope. yes to judicial reforms which demolish
secret orders and secret courts. yes to social measures which value
and reinforce privacy. yes to educational efforts which empower
individuals to make privacy positive decisions, etc.
last but not least, i second the call to fix it.  help write something better!

@_date: 2013-12-16 01:09:27
@_author: coderman 
@_subject: fallout of NSA induced difficulties (lots of drinking, 
this is what happens when large sums of money are secretly spent to
prevent the event of secure inter-net:
(NIST could simply be bought, but IETF had to be turned in on itself..)
"IETF PKIX meeting minutes from the 56th IETF"
We were somewhere in San Francisco on the edge of the 56th IETF when
the drugs began to take hold.  I remember saying something like "I
feel a bit
lightheaded; maybe you should take notes...."  And suddenly there was a
terrible roar all around us and the sky was full of what looked like huge
OIDs, all swooping and screeching and diving around the RFC, which was about a
hundred pages long.  And a voice was screaming: "Holy Jesus!  Where are these
goddamn business cases?"
Then it was quiet again.  My attorney had taken his shirt off and was pouring
beer into his mouth, to facilitate the PKI standards-creation process.  "What
the hell are you yelling about?" he muttered, staring up at the neon lights
with his eyes closed and covered with wraparound Spanish sunglasses.  "Never
mind," I said.  "It's your turn to figure out the interop requirements."  I hit
the brakes and dropped the Great Pile of Paperwork at the side of the room.
No point mentioning those OIDs, I thought.  The poor bastard will see them
soon enough.
We had two bags of X.509 standards, seventy-five pages of PKIX mailing list
printouts, five sheets of high-powered constraints, a saltshaker half-full of
vendor hype, and a whole galaxy of requirements, restrictions, promises,
threats...  Also, a quart of OSI, a quart of LDAP, a case of XML, a pint of
raw X.500, and two dozen PGPs.  Not that we needed all that for the trip, but
once you get into a serious PKI RFC binge, the tendency is to push it as far
as you can.  The only thing that really worried me was the X.500.  There is
nothing in the world more helpless and irresponsible and depraved than a man
in the depths of an X.500 binge, and I knew we'd get into that rotten stuff
pretty soon.

@_date: 2013-12-16 08:20:32
@_author: coderman 
@_subject: Wyden spends weeks preparing for questions to intelligence officials 
an interesting read on the state of things.
Wyden does Oregon proud,
[only excerpted, whole thing is huge. waiting for cryptome to mirror... ]
Wyden estimates that he gets about fifteen minutes a year to ask
questions of top intelligence officials at open hearings. With the
help of his intelligence staffer, John Dickas, a thirty-five-year-old
from Beaverton, Oregon, whom Wyden calls the hero of the
intelligence-reform movement, Wyden often spends weeks preparing his
questions. He and Dickas look for opportunities to interrogate
officials on the gaps between what they say in public and what they
say in classified briefings. At a technology conference in Nevada the
previous summer, General Keith Alexander, the director of the N.S.A.,
had said that the story that we have millions or hundreds of millions
of dossiers on people is absolutely false. Wyden told me recently,
It sure didnt sound like the world I heard about in private. For
months, he tried to get a clarification from the N.S.A. about exactly
what Alexander had meant. Now he had the opportunity to ask Clapper in
public. As a courtesy, he had sent him the question the day before.
Wyden leaned forward and read Alexanders comment. Then he asked,
What I wanted to see is if you could give me a yes or no answer to
the question Does the N.S.A. collect any type of data at all on
millions or hundreds of millions of Americans? 
Clapper slouched in his chair. He touched the fingertips of his right
hand to his forehead and made a fist with his left hand.
No, sir, he said. He gave a quick shake of his head and looked down
at the table.
It does not? Wyden asked, with exaggerated surprise.
Not wittingly, Clapper replied. He started scratching his forehead
and looked away from Wyden. There are cases where they could
inadvertently perhaps collect, but not wittingly.
Wyden told me, The answer was obviously misleading, false.

@_date: 2013-12-16 08:29:55
@_author: coderman 
@_subject: Bruce Schneier to leave BT 
retaliation for helping expose intelligence community excesses and illegalities?

@_date: 2013-12-16 19:27:34
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure updated list with env suggestion:
a.) rebuild your OpenSSL with OPENSSL_NO_RDRAND defined
b.) call ENGINE_unregister_RAND() on "rdrand" engine followed by
ENGINE_register_all_complete() to unregister rdrand as default
c.) set OPENSSL_ia32cap="~0x4000000000000000" in global environment
(this is poor fix)
d.) git pull latest openssl with commit: "Don't use rdrand engine as
default unless explicitly requested." - Dr. Stephen Henson
"what is affected??" - someone
sorry, i am not your distro maintainer.  but the list includes,
potentially (depending on configure opts / runtime / etc):
RHEL 6.5, 7.0
Centos 6.5
Fedora 18,19,rawhide
Ubuntu 12.04, 12.10, 13.04, 13.10, trusty
Debian 7.0, jessie, sid
Gentoo stable&unstable
Knoppix 7.0.5, 7.2.0
Kali 1.0.5
Slackware 14, 14.1, current
... if ssh built with --with-ssl-engine. these all use OpenSSL 1.0.1+.
 (remember both ssh client and server may use engines!)
and other libs, like:
... which appear to use OpenSSL default engines.
but really, you should go check your shit.
best regards,
P.S. if anyone is aware of RDRAND engine backports to OpenSSL 1.0.0*
or 0.9.8* in any distros i'd like to know about it!

@_date: 2013-12-16 19:30:50
@_author: coderman 
@_subject: Aqua - a high bandwidth anonymity system that resists traffic 
i had this same reaction when i found their Link Quality Source
Routing mesh protocol research[0].  crazy times! ;)
0. "Self Organizing Wireless Mesh Networks"

@_date: 2013-12-17 14:22:48
@_author: coderman 
@_subject: Tor funding [was: ranting at Juan's hatebait rapaciously [before 
discuss a post-Snowden Internet]]
even more today :)
Over the past year, we have received many requests for us to accept
bitcoin donations. After careful consideration and research, we are
thrilled to announce that effective today The Tor Project is accepting
bitcoin donations. In partnership with Bitpay, bitcoins can easily and
directly be donated to support Tors ongoing mission of being the
global resource for privacy technology advocacy, research and
education in the ongoing pursuit of freedom of speech, privacy rights
online, and censorship circumvention. Check out ourdonations page now.
Bitcoin donations received by The Tor Project will be converted
directly to US Dollars.
Our decision to accept bitcoins has been well thought out and
researched from a financial accounting perspective with an eye on
passing our required annual A-133 audit. We believe we are the first
US 501(c)3 non-profit organization to test acceptance of bitcoins and
attempt to pass the US Government A-133 Audit Standard. Our 2013 audit
results, along with our past financial documents, will be made
available on our website once complete in 2014.
The Tor Project is also proud to be in the company of other visible
non-profit organizations accepting bitcoins including EFF and
Why is this important? The Tor Project needs your donations to
continue our mission and to keep the Tor suite of technologies ahead
with the growing threats to privacy and anonymity around the world.
Your donation made TODAY, through bitcoin, Paypal, Amazon Payments,
Givv.org, checks, money orders or bank transfers, will provide greater
security and privacy for millions around the world who use Tor every
Help us continue our mission!

@_date: 2013-12-17 14:46:10
@_author: coderman 
@_subject: Tor funding [was: ranting at Juan's hatebait rapaciously [before 
Moglen discuss a post-Snowden Internet]]
sort of, but not really.  still waiting on  ...

@_date: 2013-12-18 08:29:14
@_author: coderman 
@_subject: acoustic side channel attacks against TEMPEST shielded equipment 
interesting work on using poor quality sound (like from a phone) for
chosen cipher text attacks with key recovery for GPG.
also note that they use frequencies >10kHz.  as discussed in the high
frequency audio covert channel, this range is fairly contention free
and easily accessible to microphones in consumer electronics of
various types.
Here, we describe a new acoustic cryptanalysis key extraction attack,
applicable to GnuPG's current implementation of RSA. The attack can
extract full 4096-bit RSA decryption keys from laptop computers (of
various models), within an hour, using the sound generated by the
computer during the decryption of some chosen ciphertexts. We
experimentally demonstrate that such attacks can be carried out, using
either a plain mobile phone placed next to the computer, or a more
sensitive microphone placed 4 meters away.
Beyond acoustics, we demonstrate that a similar low-bandwidth attack
can be performed by measuring the electric potential of a computer
chassis. A suitably-equipped attacker need merely touch the target
computer with his bare hand, or get the required leakage information
from the ground wires remote end of VGA, USB or Ethernet

@_date: 2013-12-20 04:32:33
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure fortunately impacts are less than anticipated!
nickm devised most concise fix: RAND_set_rand_method(RAND_SSLeay());
 always after ENGINE_load_builtin_engines().
full write up is here including a BADRAND engine patch for testing:
  last but not least, notable omissions on NSA role in reqs for random
number sources in Appendix E: US Government Role in Current Encryption
  can we get a do-over?

@_date: 2013-12-20 17:41:36
@_author: coderman 
@_subject: NSA holiday talking points humor 
this is pretty amusing reading:
  "NSA does not and will not demand changes by any vendor to any
product, nor does it have any authority to demand such changes." - NSA
"We pay above market rates[0] to our corporate partners for embedded
vulns goddamnit!" - NSA Truth
0.  $10,000,000 to backdoor all of RSA's BSafe customers and cheer
lead Dual_EC_DRBG through approval it seems.
 let's not get into the standards bodies[1] yet, they're a little raw
right now :o
1. "Critics: NSA agent co-chairing key crypto standards body [IETF
CFRG] should be removed"

@_date: 2013-12-20 18:43:16
@_author: coderman 
@_subject: [cryptography] Vegetation Comsec 
Discussion of cryptography and related most stylishly done as 'the drummers':
  where he is taken in by a strange society known as The Drummers.
These people operate in underwater compounds located off the coasts of
major centers, perform rhythmic, hypnotic dances and engage in
ritualized sex. This act, we learn later, is actually for the sake of
information exchange, which is done through the transmission of
nanomachines contained within their bodily fluids.
 - more recently via vodka emission:
scientists used a desk fan and mist of alcohol to transmit evaporated
molecules that were translated into binary signals and decoded by a
breathalyzer device.
- [this technique can be generalized to any gaseous emission (or aqueous
when at sea?) with appropriate detector.]
and of course, chemical signalling is not magically immune to flaws;
ant mills (death spirals) one of many examples of signalling amiss.
and there are some interesting research papers on targeted genomic
viral strains which only "unlock" to a very specific genetic profile.
i don't have them handy...

@_date: 2013-12-21 17:05:34
@_author: coderman 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
the leaks have sharpened my appetite for names and numbers.
collaborators in mass product perversion need to be named;
the extent of filthy lucre lures employed delineated; today!

@_date: 2013-12-21 17:19:09
@_author: coderman 
@_subject: public notice: TLA scrutiny an opportunity for catching capabilities 
if you're under scrutiny[0] no better time to test than today :)
- collect sequences, collect imagery, collect signals, collect
collaborators, collect everything! (you'll find data later you didn't
recognize as relevant)
- honey tokens to trigger channel targets, see which takes.
- selective channels of dis-information to quantify compromise.
- observe counter-reaction, counter counter-counter-measures,
- continually iterate process until truce or truncheon-ed...
caution: this can lead to escalation!
0. "Snowden ally Appelbaum claims his Berlin apartment was invaded"
  Berlin resident and US national Jacob Appelbaum told Saturday's
edition of the "Berliner Zeitung" daily that he believed he was under
surveillance in the German capital. Appelbaum told the paper that
somebody had broken into his apartment and used his computer in his
"When I flew away for an appointment, I installed four alarm systems
in my apartment," Appelbaum told the paper after discussing other
situations which he said made him feel uneasy. "When I returned, three
of them had been turned off. The fourth, however, had registered that
somebody was in my flat - although I'm the only one with a key. And
some of my effects, whose positions I carefully note, were indeed
askew. My computers had been turned on and off."

@_date: 2013-12-21 17:32:43
@_author: coderman 
@_subject: public notice: TLA scrutiny an opportunity for catching 
this assumes they're trying to be sneaky and surreptitious, of course.
sometimes an entry is about show of force rather than collection.  US
residence some years ago forcibly entered, surveillance system HERF'd,
dog placed in backyard, entire domicile imaged with all drawers,
cabinets, closets, cupboards, everything opened (and more :) in space
of 15 minute trip to store and back.
in any case, this is only effective if you're actually intimidated.
best to make it yet another egregious waste of public funding instead!

@_date: 2013-12-21 17:41:04
@_author: coderman 
@_subject: for those going to 30C3: Fwd: USB Sticks for TAILS [and OpenPGPv2 
The sticks [1] have arrived, you will be able to buy them for roughly
$15 at Chaos Communication Congress. Maybe I can drop off some of them
at the table of Wau Holland Foundation or elsewhere. Best you come find
me, for example at the Tor Relay meetup [2].
I ended up buying *200* sticks, 100 of each type and color. I will post
a detailed bill and pictures next year.
I will also bring OpenPGPv2 smartcards [3] and Gemalto USB tokens [4]
that you can buy from me, and some Yubikeys. [5]
[1] [2] [3] [4] [5] Moritz Bartl

@_date: 2013-12-21 19:43:06
@_author: coderman 
@_subject: FYI 
these people really hate Tor; they spelled it "the TOR Project"... on purpose.
  dicks!
on a related note, interpreting this document is an excellent exercise
in focusing on what is _not_ said, both in terms of qualifiers and
entire subjects/categories of omission.
oh that one might maintain a retrospective mapping from ongoing
Snowden leaks to misdirected / omitted / understated assertions and
recommendations in this Grade A Toothless Attention Distractor (aka,
"Report and Recommendations of The Presidents Review Group on
Intelligence and Communications Technologies")

@_date: 2013-12-21 20:00:38
@_author: coderman 
@_subject: FYI 
you say this like it's different from anything else you might request *grin*
indeed.  though this does bring up another question:
 i wonder if JYA will ever give in and support httpS?
... it would at least avoid trivial plaintext observation.
last but not least:
opsec tip you should assume everything remote and
retrieved is malicious.  grab in a throw away Qubes browser. convert
in a throw away parse and translate VM, then finally read and/or save
to a limited view VM using an open, trusted format.

@_date: 2013-12-22 13:38:57
@_author: coderman 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
another reason to love certificate transparency, convergence, pinning, etc...
  (yes John, httpS may be pwned, but it still flips pcap parser the bird! ;)

@_date: 2013-12-22 13:50:59
@_author: coderman 
@_subject: ECDHE-RSA-CHACHA20-POLY1305-SHA256 server side support in OpenSSL / 
Discussion of cryptography and related poked around some patches for chacha20 and poly1305 suites in
OpenSSL... there's more work to be done it seems.
is there a working setup for Linux server side chacha20 poly1305
suites with OpenSSL?  (i am probably not looking in the right place;
e.g. aead_support.patch, aead_ssl_support.patch,
best regards,

@_date: 2013-12-22 17:01:41
@_author: coderman 
@_subject: Exclusive: Secret contract tied NSA and security industry pioneer 
they've done the research. they're in good company!

@_date: 2013-12-22 17:11:29
@_author: coderman 
@_subject: private sector privacy enhancing technology transition for 
if DEA finds meaningful work in legal marijuana[0], will IC community
find meaningful work red teaming and supporting privacy enhancing
technologies and usable open source crypto?
knowing how to break things useful in building systems that are harder
to break...
0. "DEA agents finding greener jobs in lucrative legal marijuana industry"

@_date: 2013-12-28 07:00:08
@_author: coderman 
@_subject: P2P VPN 
i love the concept of L2 VPNs; so pure in theory.
(AppleTalk and IPX over WAN? no problem!)
in practice they need a lot of careful implementation and
configuration.  the attack surface for tap vs. tun is very different;
many services handling broadcast traffic assume a trusted local
network environment.
all of the security features listed on the wiki are related to
transport / authentication rather than endpoint service
considerations.  this should be remedied.
looks interesting! perhaps i can play around with it soon...
best regards,

@_date: 2013-12-28 07:14:47
@_author: coderman 
@_subject: Boycott the RSA Conference - List of Honor 
Josh Thomas also bowing out:
is anyone keeping track? i'm curious...

@_date: 2013-12-29 02:19:23
@_author: coderman 
@_subject: 30c3: The Year in Crypto default engines loaded in openssl-1.x 
cpunks in 30c3: The Year in Crypto
 with djb, Nadia Heninger, Tanja Lange
at ~28min discussion of RDRAND,
 Intel's pass the buck to NIST no-comment,
  (after initial "just trust us, we looked at a lab sample close"
didn't fly far enough...)
alt slides: hyperelliptic.org/tanja/vortraege/talk-30C3.pdf
also, Tor 0.2.4.20 (Mon Dec 23 07:21:35 UTC 2013)
 updates to avoid direct RDRAND use in specific circumstances:
   per previous discussion on OpenSSL use of RDRAND directly when engines on.[0]
  TL; DR - very rare case you may want to re-gen relay and hidden service keys
 now,,
you may wonder if IETF could apply resistance to NSA seducing of NIST,
 but you'd be stepping into a quagmire  :P
     [specifically, all of Dan Harkins "appeals for legitimacy" bear
striking resemblance to other demonstratively failed approaches to
failure by default designs. Dragonfly is not sufficiently justified.
insert pleas to appeal to decency and step away from CFRG and IETF
authority roles for propriety sake, regardless of any reasonable
claims or other implications best exemplified by RSA[1]]
 also,,
SIMON and SPECK is lulz; no really: fuck those guys!
 and remember that AES GCM is a choice between:
  - user-land side channels galore  /or/
  - hardware instruction back-door
2013 was indeed a year for crypto
  let's not do this again soon?
best regards,
0. "BADRAND and testing OpenSSL engines enabled behavior with direct
RDRAND engine"
 BADRAND lets you link a test version of your application or library
against OpenSSL 1.0.1e that uses a specific sequence of deterministic
"random numbers" in OpenSSL. e.g. standard C lib function rand()
seeded at zero replacing RDRAND. the debug logging to stderr can
identify bad fork() assumptions.
1. Dual-EC-DRBG is bad and RSA should feel bad. No excuses.
  IETF standards not a good reference for "formal proof" level thoroughness,
  and highly deployed does not mean highly used nor scrutinized (WEP,
LEAP, OpenSSL's Dual_EC_DRBG implementation, [the set is large])
X. "see that one top post ..."  [was: RDRAND used directly when...

@_date: 2013-12-29 10:43:46
@_author: coderman 
@_subject: automated crash reporting XKeyscore hooks 
seems automated processes are a great XKeyscore source:
"in practical terms, the NSA's agents... enjoy it because it allows
them [a "neat way" to gain "passive access" to a machine] ... In one
internal graphic, they replaced the text of Microsoft's original error
message with one of their own reading, "This information may be
intercepted by a foreign sigint system to gather detailed information
and better exploit your machine."
Inside TAO
Documents Reveal Top NSA Hacking Unit
By SPIEGEL Staff
The NSA's TAO hacking unit is considered to be the intelligence
agency's top secret weapon. It maintains its own covert network,
infiltrates computers around the world and even intercepts shipping
deliveries to plant back doors in electronics ordered by those it is
In January 2010, numerous homeowners in San Antonio, Texas, stood
baffled in front of their closed garage doors. They wanted to drive to
work or head off to do their grocery shopping, but their garage door
openers had gone dead, leaving them stranded. No matter how many times
they pressed the buttons, the doors didn't budge. The problem
primarily affected residents in the western part of the city, around
Military Drive and the interstate highway known as Loop 410.
In the United States, a country of cars and commuters, the mysterious
garage door problem quickly became an issue for local politicians.
Ultimately, the municipal government solved the riddle. Fault for the
error lay with the United States' foreign intelligence service, the
National Security Agency, which has offices in San Antonio. Officials
at the agency were forced to admit that one of the NSA's radio
antennas was broadcasting at the same frequency as the garage door
openers. Embarrassed officials at the intelligence agency promised to
resolve the issue as quickly as possible, and soon the doors began
opening again.
It was thanks to the garage door opener episode that Texans learned
just how far the NSA's work had encroached upon their daily lives. For
quite some time now, the intelligence agency has maintained a branch
with around 2,000 employees at Lackland Air Force Base, also in San
Antonio. In 2005, the agency took over a former Sony computer chip
plant in the western part of the city. A brisk pace of construction
commenced inside this enormous compound. The acquisition of the former
chip factory at Sony Place was part of a massive expansion the agency
began after the events of Sept. 11, 2001.
On-Call Digital Plumbers
One of the two main buildings at the former plant has since housed a
sophisticated NSA unit, one that has benefited the most from this
expansion and has grown the fastest in recent years -- the Office of
Tailored Access Operations, or TAO. This is the NSA's top operative
unit -- something like a squad of plumbers that can be called in when
normal access to a target is blocked.
According to internal NSA documents viewed by SPIEGEL, these on-call
digital plumbers are involved in many sensitive operations conducted
by American intelligence agencies. TAO's area of operations ranges
from counterterrorism to cyber attacks to traditional espionage. The
documents reveal just how diversified the tools at TAO's disposal have
become -- and also how it exploits the technical weaknesses of the IT
industry, from Microsoft to Cisco and Huawei, to carry out its
discreet and efficient attacks.
The unit is "akin to the wunderkind of the US intelligence community,"
says Matthew Aid, a historian who specializes in the history of the
NSA. "Getting the ungettable" is the NSA's own description of its
duties. "It is not about the quantity produced but the quality of
intelligence that is important," one former TAO chief wrote,
describing her work in a document. The paper seen by SPIEGEL quotes
the former unit head stating that TAO has contributed "some of the
most significant intelligence our country has ever seen." The unit, it
goes on, has "access to our very hardest targets."
A Unit Born of the Internet
Defining the future of her unit at the time, she wrote that TAO "needs
to continue to grow and must lay the foundation for integrated
Computer Network Operations," and that it must "support Computer
Network Attacks as an integrated part of military operations." To
succeed in this, she wrote, TAO would have to acquire "pervasive,
persistent access on the global network." An internal description of
TAO's responsibilities makes clear that aggressive attacks are an
explicit part of the unit's tasks. In other words, the NSA's hackers
have been given a government mandate for their work. During the middle
part of the last decade, the special unit succeeded in gaining access
to 258 targets in 89 countries -- nearly everywhere in the world. In
2010, it conducted 279 operations worldwide.
Indeed, TAO specialists have directly accessed the protected networks
of democratically elected leaders of countries. They infiltrated
networks of European telecommunications companies and gained access to
and read mails sent over Blackberry's BES email servers, which until
then were believed to be securely encrypted. Achieving this last goal
required a "sustained TAO operation," one document states.
This TAO unit is born of the Internet -- created in 1997, a time when
not even 2 percent of the world's population had Internet access and
no one had yet thought of Facebook, YouTube or Twitter. From the time
the first TAO employees moved into offices at NSA headquarters in Fort
Meade, Maryland, the unit was housed in a separate wing, set apart
from the rest of the agency. Their task was clear from the beginning

@_date: 2013-12-30 05:03:19
@_author: coderman 
@_subject: 30c3: To Protect And Infect, Part 2 
so much asking for names, details, conspirators.
so many months and months of nearly zero satisfaction.
... until:
kudos Jake for delivering; specifically. :)
"[QI vector] 30c3: To Protect And Infect, Part 2"
you can argue some subset of these attacks are exercised in a targeted
manner, however, this does nothing to prevent collateral damage to
domestic and global individuals, indiscriminately.
fuck these guys![0]
best regards,
0. fuck you, at least in so far as your offensive efforts to undermine
privacy and liberty in the name of route tasking without restraint.
 to those who go privacy tech repurpose, i will sing your praises and
support your efforts!

@_date: 2013-12-30 07:21:26
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
out of time, barest gist til next year: back when doing wifi security
research and other interests [trunc.] received an FBI black bag job;
presumably physical focus due to non standard OSes and FDE.  IBM
keyboard internal chip replaced with identical logging variant; note
that this is not as sophisticated as the more recent TAO toys with
covert RF channels and active, on-demand capabilities...
the keyboard tampering:
 which is for all intents and purposes otherwise visually undetectable
using this trojan chip technique, tailored for every common
while that was not bad, aside from leaking tamper event, the FDE was
so sad/funny. a screw amuck, replacement drive significantly different
(when compared to identical lot mate purchased with original that got
yanked for offline attack)
in a round about manner this was all instigated in part by wifi
research done at the time which put various powerful entities into a
tiff.  here's what the pacNW sample looked like back in early 2003:
"Cleartext Nodes: 8755 (62.59%)
  , WEP Nodes: 5232 (37.40%)"
 ... ah, memories :)
one last fun learning by example: consider that you thwart direct
physical access black bag type attempts, and are not running a
vulnerable router/CPE, and present a sufficiently compelling target,
you may encounter a clever "just outside the property line" isolation
and active attack on DOCSIS uplink. (a broadcast medium is hard to
mess with in a covert manner, unless you're able to isolate target
from the local broadcast loop itself.)
(circa 2007 - make note of image comments and also single "Comcast
tech" shielding self behind door...)

@_date: 2013-12-30 07:38:41
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
tamper evidence combined with secondary reference copies to compare
(buy two in cash on demand rather than shipped, use second as fallback
(vastly more frequent scenario) or as reference with sketch kit (what
did you did? ;)
this leads to the question i intended but omitted in prev:
to date most FBI/NSA/IC keyloggers have been visually obtuse dongle
type, varied software type, particularly for Windows, Mac, and Dos at
this point in the past.  the top class (effectively undetectable?)
hardware keyloggers appear to have avoided detailed disclosure.
is anyone aware of leaked hardware keylogger specs or ops in the veign
of magic lantern / CIPAV / Carnivore / DCS* category applied to covert
hardware based compromises?

@_date: 2013-12-30 07:43:21
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
COTTONMOUTH is informative; but generally USB based and visible via
spectrum when actively exfilling.
specifically hardware attacks on PS/2 / XT style keyboards.

@_date: 2013-12-30 22:06:25
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
hey Jim, (and Jake)
neither one of you appear to have a *coin tipjar yet...
why holding out? :)
best regards,

@_date: 2013-12-30 22:19:21
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
you're assuming this dump is exhaustive.  this is a very specifically
themed/focused release of top end tactics and exploits (essentially
weaponized platforms for targeted attacks). Jake says as much about
what they're dropping, which while impressive, has still gone through
the "best interest of public safety scrutinizing and censorship"
the indiscriminate, wholesale compromises are just getting started...
these disclosures will have more impact: financially to the impacted
vendors, effectively to IC as known vulnerable hardware and software
is replaced, and to the public at large now exposed to even more
essentially incomprehensible disclosures of vulnerability and
this is just an example of how, when the NSA pursues "all means and
methods in parallel, without restraint" seemingly innocuous oversights
are intentionally leveraged and discouraged from remediation for use
in tailored access (black bag / targeted) attacks.
it is worse.
best regards,
p.s. cryptome has lots of great docs on this and other 30C3 awesomeness:
   ,

@_date: 2013-12-30 23:21:14
@_author: coderman 
@_subject: Replacing corporate search engines with anonymous/decentralized 
decentralized search (not just not-corporate search) persists as one
of the great
practical challenges in peer to peer networking.
i have more to say later, but one effort from back in early 2000 is alpine:
   inside the 2004 snapshot there is also docs and implementation of
feedbackfs which is used to gather implicit feedback on recommendation
alpine is explicitly highly connected, flatter than not network
topology to improve robustness in the face of failure and active
attacks, and to avoid limitations inherent in many connection oriented
operating system facilities/sockets.
i am not quite an impartial party ;)
 but other approaches which are not a feasible replacement include:
 - the old skewl (mostly)flooding broadcasts like gnutella
 - fragile, hard to defend constructs like DHTs as keyword indexes
 - aggressive caching with local search (110% useful, but not sufficient alone)
 - distributed (but better somehow) search engines on darknets, etc.
these are more about search privacy or deep search more than
decentralized search.
the longer discussion is how to make decentralized search useful.
"Google style" search has a terrific performance advantage over
decentralized designs by brute force.
however, take advantage of massive endpoint / peer processing and
resources combined with implicit observational metrics for reputation
and recommendation, inside a well integrated framework for resource
discovery in usable software, and you have something more robust and
more effective than "Google style" could ever provide.
this is quite the trick, however!  despite an inter-operable component
model interface, and dynamic runtime module support to extend
discovery and wire protocol extensions, and other intentional efforts
at encouraging adoption and integration, alpine failed to bootstrap.
(i did many things wrong, but those things i did at least make
conscious effort to do right.  did i mention this is a hard problem?
this project has been excavated from archives, and will receive
maintenance upgrades[0] at minimum and significant improvement a
possible option, depending.
best regards,
[0] maintenance work for testable alpine builds
 - fix/improve g++ usage.
 - add IPv6 support. (specifically ORCHID addrs for darknet search)
 - update feedbackfs to latest fusefs bindings
 - update inotify bindings in feedbackfs
 - multiple-socket support, multi-addr discovery

@_date: 2013-12-30 23:27:53
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
its a way to convert digital shared hallucinations into fiat
denominated shared hallucinations.
for an example exchange in BTC network:
  you can generate your own wallet and use your own client directly in
network, or use a managed wallet service, or a conversion service that
immediately converts into $USD denominated deposits in a bank account,
or exchange for physical token representations of the coin/funds, etc.
 is probably the most accessible place to start,
 and github where the good forks are if you're in the ready to hack camp.
if you setup a wallet and tell me the address, i can donate coins for
you to experiment with.
best regards,

@_date: 2013-12-31 00:51:27
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
i'll let you cypherpunks in on a secret financial tip:
  the smart money banks in dogecoin:

@_date: 2013-12-31 02:47:45
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
sha256 579c3059e24b2d65f324053b0fed550a9d1d4fb2504a1a272940a26697ed8a33
(where else is the above mirrored? i had links, they're no longer good...)
best regards,

@_date: 2013-12-31 03:08:12
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
this makes sense, and leads to a question; see below.
so far we've seen 0.5%[0] of confirmations of general and nearly
insurmountable vulnerability against a state level actor, ... let's
see what 2014 has in store! :)
the question:
 do you believe the counter-surveillance was a factor in the extreme
measures used in your prosecution?
AP seemed the most controversial and outwardly demonised aspect of the
whole debacle, but perhaps i am giving too much weight to AP.
the judge sealing the entire court file raises questions, but i also
admit knowing little about the particulars of the facts and legal
motions of the case.
best regards,
0.  snowden leaks, ~1.6% to ~.40% released
     see also, tailored access megapwnage:

@_date: 2013-12-31 19:00:10
@_author: coderman 
@_subject: Replacing corporate search engines with anonymous/decentralized 
what you want more than traditional search is resource discovery,
which includes recommendation and per-peer-perspective reputation.
this is an area where centralized search is incapable or untrustworthy
enough compared to fully decentralized options.
done centrally, that central trusted party would be privy to all your
inter-peer interactions.  in decentralized fashion this exposes only
limited information to each peer.  (central services usually paying
the cost of the infrastructure to analyze all to all interactions by
selling your private information to third parties, or delegating to
those who do...)
public web is a small slice of all that is of interest.  just put a
internet archive.org copy on a hidden Tahoe-LAFS and everyone gets a
copy of the public web for local querying. (better yet, make a PIR
LAFS ;)
... this would need a little coding *grin*

@_date: 2013-12-31 19:08:10
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
agreed.  we've got some years to wait for a definitive full picture.
  - 932 pages (~1.6%) of
reported 58,000. NSA head claims 200,000 (~.40% of that released)
vendor responses are fairly self evident.
bad: RSA
less-bad: Cisco
good/proactive: SilentCircle
etc,...   we could get into details of what makes a good vendor
response vs. one that is clearly weasel worded accountability
deflection, don't think this list is the place however.
then you're not paying attention :)
corporate media sucks to more or less degree; i feel bad for anyone
who touches it.
glad it's not my problem!
best regards,

@_date: 2013-12-02 00:11:10
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
 Full Disclosure this, in the traditional sense, is what John calls a "COMSEC cover-up":
 meaning that the continual, most significant, and most likely to be
abused and widely are commercial services and collaborations and
  where the product is your private information of any sort, that you
usually unwittingly but sometimes capriciously yield to un trustworthy
third parties with little constraint on secondary distribution for
money to further removed stranger parties...
note that fully decentralized, end-to-end secured, with properly
managed keying and sessions capable technologies are resistant to
these third-party weaknesses and vulnerabilities.
crypto and comms and computing technology should not be abandoned en
whole like the russians for their manual type writers, but the minimum
required operational safety of any information processing system needs
huge innovation to get from current systems to something effective and
usable...  hey look, it's more of those fun problems to solve again ;)
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:10
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
 Full Disclosure ,
 cpunks regarding the inability for NSA employees to report ethical violations
in a manner that did not assure retribution:
this is actually a somewhat difficult anonymity / privacy question in
the context of highly compartmented information and operations, where
knowledge of a subset of specific details is sufficient to imply
strong suspicion and scrutiny to a very small number of individuals...
... assuming you don't circumvent the apparently mediocre constraints
to this information in the information systems that contain it. ;)
while academically interesting, in all practical terms we should
render this question moot and provide absolute communication
origin[0], destination[1], and content[2] privacy to all network users
in all locations under all circumstances guaranteed by constitutional
law, prosecutorial discretion, and practical realities (read:
implementations resistant to Tailored Access Operations like efforts
(NSA TAO / CNE related programs)
this latter guarantee will require a bit more design, coding and deployment,
 fun problems to solve![3]
1.  "peer communication endpoint privacy" - this is a hard problem.
the existing implementations are not usable and insufficiently large
in anonymity set (too few users): zero knowledge high latency mail
like messaging mixes, even if the twitter mixes are pretty cool.
a proper solution would be datagram based, NAT busting, low latency
(read: sufficiently real-time for video and voice), the majority
protocol across the Internet and local intranets and ad-hoc mesh nets
and other networks,
in an implementation that resists all known general purpose (wide
scale) and specialized (highly targeted and/or weaponized bleeding
edge and/or privileged positioned) attacks.
2. strong encryption like: alligator wrapped forward secrecy intended
streams, and equivalent techniques, solve this problem.
  clearly there is much work to do in the implementation and protocol
side of crypto integrity.  very, very much work...
3. "NSA TAO / CNE related programs" resistance is a very tall bar.
they rolled this out at DEF CON, of course. the soon departing .gov
Alexander rolled into town with some world class shit, no doubt...  is
it really going to be 33 years before we can talk about it?  for
better or for worse we won't have Snowden to disclose this
( as he's too classy
to drop dox on specific field operations and highly technical method
and tools information. hmmm...
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:11
@_author: coderman 
@_subject: [Full-disclosure] Intelligence agency subversions and clandestine, 
Full Disclosure ,
 Cypherpunks list On Wed, Oct 2, 2013 at 1:52 AM,
if you're not mad as hell about PRISM, UPSTREAM, BULLRUN, FLYING PIG,
XKEYSCORE, FOXACID, EgotisticalGiraffe, QUICKANT, QuantunInsert,
FRUGAL SHOT, MOTHMONSTER, MULLENIZE, ERRORONEOUSINGENUITY,
FINKDIFFERENT, GREATEXPECTATIONS, VALIDATOR, RAKE, PEDDLE,
PACKETCHEAP, BEACH HEAD, FERRET CANON, PINWALE, MARINA, TRAFFICTHIEF,
REMATION, LACONIC, ENDUE, MANASSAS, DANCINGOASIS, SPINNERET,
MOONLIGHTPATH, ...
 and all the other myriad "exceptionally controlled information",
 then you're beyond reason and redemption...
 ... let's not take a show of hands
 ;P
P.S. the new cypherpunks list has dropped the cypherpunks at al-qaeda.net
for a more benign and powers that be submissive cypherpunks at cpunks.org
 ... perhaps it does get past a few more filters? ...
--- fwd:
it doesn't get much more definitive than this retort.. :
[Snowden] felt confident that he had kept the documents secure from
Chinese spies, and that the N.S.A. knew he had done so. His last
target while working as an agency contractor was China...
adding that he had had "access to every target, every active
operation mounted by the N.S.A. against the Chinese. Full lists of
them," he said.
"If that was compromised," he went on, "N.S.A. would have set the
table on fire from slamming it so many times in denouncing the damage
it had caused. Yet N.S.A. has not offered a single example of damage
from the leaks. They haven't said boo about it except "we think,"
"maybe", "have to assume" from anonymous and former officials. Not
"China is going dark." Not "the Chinese military has shut us out."
there is a clear thoughtfulness, moral reasoning, and
conscientiousness repeatedly demonstrated by Snowden in these events.
it is now obvious that history will exonerate him fully.
... the distance between current reactionary retribution and that
future absolution appears to be a bit of a distance, however...
hopefully not too long.
October 17, 2013
Snowden Says He Took No Secret Files to Russia
By JAMES RISEN
WASHINGTON - Edward J. Snowden, the former National Security Agency
contractor, said in an extensive interview this month that he did not
take any secret N.S.A. documents with him to Russia when he fled there
in June, assuring that Russian intelligence officials could not get
access to them.
Mr. Snowden said he gave all of the classified documents he had
obtained to journalists he met in Hong Kong, before flying to Moscow,
and did not keep any copies for himself. He did not take the files to
Russia because it wouldn't serve the public interest," he said.
"What would be the unique value of personally carrying another copy of
the materials onward?" he added.
He also asserted that he was able to protect the documents from
China's spies because he was familiar with that nation's intelligence
abilities, saying that as an N.S.A. contractor he had targeted Chinese
operations and had taught a course on Chinese
"There's a zero percent chance the Russians or Chinese have received
any documents," he said.
American intelligence officials have expressed grave concern that the
files might have fallen into the hands of foreign intelligence
services, but Mr. Snowden said he believed that the N.S.A. knew he had
not cooperated with the Russians or the Chinese. He said he was
publicly revealing that he no longer had any agency documents to
explain why he was confident that Russia had not gained access to
them. He had been reluctant to disclose that information previously,
he said, for fear of exposing the journalists to greater scrutiny.
In a wide-ranging interview over several days in the last week, Mr.
Snowden offered detailed responses to accusations that have been
leveled against him by American officials and other critics, provided
new insights into why he became disillusioned with the N.S.A. and
decided to disclose the documents, and talked about the international
debate over surveillance that resulted from the revelations. The
interview took place through encrypted online communications.
Mr. Snowden, 30, has been praised by privacy advocates and assailed by
government officials as a traitor who has caused irreparable harm, and
he is facing charges under the Espionage Act for leaking the N.S.A.
documents to the news media. In the interview, he said he believed he
was a whistle-blower who was acting in the nation's best interests by
revealing information about the N.S.A.s surveillance dragnet and huge
collections of communications data, including that of Americans.
He argued that he had helped American national security by prompting a
badly needed public debate about the scope of the intelligence effort.
The secret continuance of these programs represents a far greater
danger than their disclosure," he said. He added that he had been more
concerned that Americans had not been told about the N.S.A.s reach
than he was about any specific surveillance operation.
So long as there's broad support amongst a people, it can be argued
there's a level of legitimacy even to the most invasive and morally
wrong program, as it was an informed and willing decision," he said.
However, programs that are implemented in secret, out of public
oversight, lack that legitimacy, and that's a problem. It also
represents a dangerous normalization of governing in the dark, where
decisions with enormous public impact occur without any public input.
Mr. Snowden said he had never considered defecting while in Hong Kong,
nor in Russia, where he has been permitted to stay for one year. He
said he felt confident that he had kept the documents secure from
Chinese spies, and that the N.S.A. knew he had done so. His last
target while working as an agency contractor was China, he said,
adding that he had had access to every target, every active
operation mounted by the N.S.A. against the Chinese. Full lists of
them, he said.
If that was compromised, he went on, N.S.A. would have set the
table on fire from slamming it so many times in denouncing the damage
it had caused. Yet N.S.A. has not offered a single example of damage
from the leaks. They havent said boo about it except we think,
maybe, have to assume from anonymous and former officials. Not
China is going dark. Not the Chinese military has shut us out.
An N.S.A. spokeswoman did not respond Thursday to a request for
comment on Mr. Snowden's assertions.
Mr. Snowden said his decision to leak N.S.A. documents developed
gradually, dating back at least to his time working as a technician in
the Geneva station of the C.I.A. His experiences there, Mr. Snowden
said, fed his doubts about the intelligence community, while also
convincing him that working through the chain of command would only
lead to retribution.
He disputed an account in The New York Times last week reporting that
a derogatory comment placed in his personnel evaluation while he was
in Geneva was a result of suspicions that he was trying to break in to
classified files to which he was not authorized to have access. (The
C.I.A. later took issue with the description of why he had been
reprimanded.) Mr. Snowden said the comment was placed in his file by a
senior manager seeking to punish him for trying to warn the C.I.A.
about a computer vulnerability.
Mr. Snowden said that in 2008 and 2009, he was working in Geneva as a
telecommunications information systems officer, handling everything
from information technology and computer networks to maintenance of
the heating and air-conditioning systems. He began pushing for a
promotion, but got into what he termed a petty e-mail spat in which
he questioned a senior manager's judgment.
Several months later, Mr. Snowden said, he was writing his annual
self-evaluation when he discovered flaws in the software of the
C.I.A.s personnel Web applications that would make them vulnerable to
hacking. He warned his supervisor, he said, but his boss advised him
to drop the matter and not rock the boat. After a technical team also
brushed him off, he said, his boss finally agreed to allow him to test
the system to prove that it was flawed.
He did so by adding some code and text in a nonmalicious manner=94 to
his evaluation document that showed that the vulnerability existed, he
said. His immediate supervisor signed off on it and sent it through
the system, but a more senior manager the man Mr. Snowden had
challenged earlier was furious and filed a critical comment in Mr.
Snowden's personnel file, he said.
He said he had considered filing a complaint with the C.I.A.=92s
inspector general about what he considered to be a reprisal, adding
that he could not recall whether he had done so or a supervisor had
talked him out of it. A C.I.A. spokesman declined to comment on Mr.
Snowden's account of the episode or whether he had filed a complaint.
But the incident, Mr. Snowden said, convinced him that trying to work
through the system would only lead to punishment. He said he knew of
others who suffered reprisals for what they had exposed, including
Thomas A. Drake, who was prosecuted for disclosing N.S.A. contracting
abuses to The Baltimore Sun. (He met with Mr. Snowden in Moscow last
week to present an award to him for his actions.) And he knew other
N.S.A. employees who had gotten into trouble for embarrassing a senior
official in an e-mail chain that included a line, referring to the
Chinese Army, that said, Is this the P.L.A. or the N.S.A.?
Mr. Snowden added that inside the spy agency theres a lot of dissent
 palpable with some, even. But he said that people were kept in line
through fear and a false image of patriotism, which he described as
obedience to authority.
He said he believed that if he tried to question the N.S.A.s
surveillance operations as an insider, his efforts would have been
buried forever, and he would have been discredited and ruined.=94 He
said that the system does not work, adding that you have to report
wrongdoing to those most responsible for it.
Mr. Snowden said he finally decided to act when he discovered a copy
of a classified 2009 inspector generals report on the N.S.A.s
warrantless wiretapping program during the Bush administration. He
said he found the document through a dirty word search, which he
described as an effort by a systems administrator to check a computer
system for things that should not be there in order to delete them and
sanitize the system.
"It was too highly classified to be where it was," he said of the
report. He opened the document to make certain that it did not belong
there, and after he saw what it revealed, curiosity prevailed, he
After reading about the program, which skirted the existing
surveillance laws, he concluded that it had been illegal, he said. =93If
the highest officials in government can break the law without fearing
punishment or even any repercussions at all, he said, secret powers
become tremendously dangerous.
He would not say exactly when he read the report, or discuss the
timing of his subsequent actions to collect N.S.A. documents in order
to leak them. But he said that reading the report helped crystallize
his decision. You cant read something like that and not realize what
it means for all of these systems we have," he said.
Mr. Snowden said that the impact of his decision to disclose
information about the N.S.A. had been bigger than he had anticipated.
He added that he did not control what the journalists who had the
documents wrote about. He said that he handed over the documents to
them because he wanted his own bias divorced from the decision-making
of publication, and that technical solutions were in place to ensure
the work of the journalists couldn't be interfered with."
Mr. Snowden declined to provide details about his living conditions in
Moscow, except to say that he was not under Russian government control
and was free to move around.
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:11
@_author: coderman 
@_subject: [Full-disclosure] Foreign Intelligence Resistant systems [was Re: 
Full Disclosure i must amend this prior advice.
in addition to legal protections, educational support, and competitive programs,
also provide:
- direct and unrestricted backbone access to various individuals or
groups who demonstrate competence in either the educational or
competitive realms, in order for them to mount additional attack
strategies against any reach-able target.  this access must consist of
both passive taps of backbone traffic as well as injection taps for
raw packet transmission at core rates. this should be available on the
Internet backbone at internet exchanges, private fiber through public
right of way, and core networks of operators of licensed wireless
a side benefit of implementing these reforms would be the de-facto
de-funding of offensive network operations by third parties or
governments. the cost to keep ahead of such a widespread, popular, and
distributed effort would be enormous, and provide continually
decreasing returns.
...  getting there is much more complicated of course.   *grin*
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:17
@_author: coderman 
@_subject: [Full-disclosure] ... endpoint security, strong encryption 
cpunks the practical uses are not just authenticity and privacy, but also
censorship avoidance and other availability improvements; c.f.:
"Lightweight Obfuscated Datagram Protocol (LODP)"
  "Elligator [...] introduces a new solution: an encoding for points on
a single curve as strings indistinguishable from uniform random
  encryption for privacy of data at rest can almost be considered a
subset of the problem of encryption for privacy of communication as
and all of the above hinge critically upon effective key management
and usability! which are the things you're most likely to screw up
inconspicuously and completely.
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:18
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
 Full Disclosure an interesting discussion :)
"This is perhaps our last fundamental tradeoff before the Singularity
occurs: Do we, as a society, want the comfort and convenience of
increasingly technologic, invisible digital integration enough to pay
for those benefits with the liberties that must be given up to be
protected from the downsides of that integration?" -- dan
i would argue that there is an alternative in design and architecture,
mainly those which decentralize and protect end-to-end. however, there
is a cost attached to these efforts as well, which so far most opt-out
of paying...
best regards,
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 10:29:05
@_author: coderman 
@_subject: DEF CON cell network attacks 
of course; the complete details will be slow to arrive, not least
because detailed description requires a demonstration in a
reproduction test setup, rather than reporting of actual traffic. :/
that said, useful aspects i'll certainly provide on whim or request.
the defining characteristics of the two types of attacks:
DC19 with DRT:
- "high power on-site", less descriminant attacks. target by and
limited to location.
- MitM for system, application, and protocol level attacks. Evilgrade,
MasterKey vulns, etc.  mostly known and a few 0day escalated attacks.
- favorite attack: "Google Voice Search" always-on eavesdropper
payload; Speex voice from all audible participants.
DC20 with Alexander's toys:
- "in the towers", highly targeted to specific devices, active over
wide metro area.
- baseband exploit vector for device key retrieval, memory and storage
forensics, exfiltration.
- PDoS attacks (bricked secondary devices used as fall back once
identified by call graph; ~20 hours)
- favorite attack: baseband pwn in airplane mode, with ex-filtration
over custom channel.
DC21: no appearance (observed).  speculation ongoing...
reversing attacker capabilities, toolkits, TTPs, humanpower/hours, a
much longer tangent.  but this assertion is based on correlation of
the observed power, capacity, and protocols in specific bands
implemented by the attacker with the capabilities of the DRT system.
multiple locations, terabytes of captured spectrum, patience and
as for who was operating it - unknown beyond the usual suspects, which
is a small set due to the restricted distribution of both the hardware
platform and the exploit kit atop it :)
i'll send more details once available.  the details and distribution
to be part of a separate FOIPA effort for US citizen security
enthusiasts that might be of interest to those following this thread.
best regards,

@_date: 2013-12-02 10:34:53
@_author: coderman 
@_subject: NSA: The Game 
classic!  :P
and fun for the whole family this holiday season,
The Internet users win if they kill all of the NSA agents.  The NSA agents win
if they render enough Internet users that the numbers of Internet users and
NSA agents are even.  In other words they win if the NSA agents constitute a
large enough voting bloc that they can't be lynched any more.  At that point
the NSA can unmask and openly subject the remaining Internet users to
extraordinary rendition.

@_date: 2013-12-02 10:40:28
@_author: coderman 
@_subject: Jim Bell needs Bitcoins! 
and it should go without saying; don't use a third-party wallet service!
the bitcoin network is one of the most hostile networks in the world;
the trail of pwn is long and continuous.  wallet services, changes,
pools, casinos, just about every BTC denominated service is operating
at an elevated risk level traditionally seen in banking while running
their operations like a self hosted blog...

@_date: 2013-12-02 17:56:47
@_author: coderman 
@_subject: peertech.org cert [was: DEF CON cell network attacks] 
Hash: SHA512
more details here soon...
only 443 should be considered valid - that is,
 try  first, plain-text must die.
and remember lkaglbgpvvcmc6xc.onion in case it becomes necessary
    Data:
        Version: 3 (0x2)
        Serial Number:
            2b:50:49:6a:55:85:55
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, ST=Arizona, L=Scottsdale,
O=GoDaddy.com, Inc.,
CN=Go Daddy Secure Certificate Authority - G2
        Validity
            Not Before: Dec  3 00:18:04 2013 GMT
            Not After : Dec  3 00:18:04 2014 GMT
        Subject: OU=Domain Control Validated, CN=peertech.org
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
            RSA Public Key: (4096 bit)
                Modulus (4096 bit):
                    00:b7:64:54:f1:2e:3a:ec:11:29:5a:93:1f:ad:f0:
                    16:8c:9c:eb:d9:0f:49:d2:9d:16:9a:53:a4:60:b6:
                    23:5b:4f:f3:17:90:77:0a:b3:25:27:f2:27:dd:65:
                    83:b6:e4:d5:13:b1:3b:97:5d:b5:b9:a9:62:32:4a:
                    7e:fb:67:73:20:5f:d7:44:52:c8:fc:ca:f8:fb:f1:
                    4f:d1:9d:94:39:72:12:2b:67:22:4c:0b:dc:7f:31:
                    34:cf:63:42:f1:c8:3d:ed:7c:de:2f:e2:63:e1:a2:
                    0a:c9:e6:86:dd:3f:39:73:af:01:58:d7:6d:59:7a:
                    51:d0:b7:bb:4c:8d:5f:1e:43:10:da:96:09:67:56:
                    2f:38:f6:a8:44:a7:96:9a:5c:bc:3e:6c:d6:d1:b6:
                    96:80:34:c8:88:84:4e:2e:06:14:0f:c5:f2:11:ff:
                    f6:15:06:f2:25:e7:d2:1a:8d:62:ef:5c:0e:fb:44:
                    8e:73:da:96:23:26:03:62:5c:2b:e6:70:5c:87:76:
                    d3:21:59:83:57:ac:56:15:bd:4f:25:fb:df:10:ec:
                    0e:56:fa:44:c8:8b:a4:97:ea:b1:98:71:3b:51:78:
                    79:ee:33:cf:b5:a5:68:15:86:9f:31:70:ee:8f:2f:
                    f4:53:32:b7:99:4f:67:21:db:1e:5d:4f:dc:5b:5d:
                    59:fd:30:3e:a2:04:22:13:76:05:4c:44:d6:08:fe:
                    b5:42:5f:b5:4a:38:4f:3d:eb:ea:59:63:ab:27:87:
                    7e:c4:46:3b:96:75:41:be:85:7e:e8:b5:8a:d4:11:
                    aa:cc:6a:28:b9:50:a3:f4:45:e2:50:d5:1f:6c:bf:
                    b8:ba:07:10:20:f8:7f:94:ec:15:d7:39:a6:fe:df:
                    65:78:1d:60:2c:b0:b1:76:40:82:b5:0f:d6:c8:e3:
                    8b:bb:f3:04:ff:80:e3:de:fc:2c:32:0e:21:13:d5:
                    bd:38:94:a1:c8:53:da:c7:3b:a9:a5:c1:70:ea:89:
                    ef:a7:f8:04:35:41:7e:38:05:73:ff:76:8a:c1:92:
                    7f:03:b8:76:48:b9:f6:61:b1:c5:22:be:b9:36:73:
                    de:0e:b8:36:4a:9c:c5:66:3b:63:2c:be:4f:20:75:
                    94:03:d8:05:d0:78:12:df:77:d8:17:51:7e:3c:24:
                    7f:cc:c6:8e:2a:f7:bc:f8:5c:29:64:bb:10:42:4d:
                    c0:83:64:6f:da:78:14:52:2e:97:49:e8:5d:7f:38:
                    36:3d:5a:5d:7c:44:71:28:21:04:6e:24:f5:f8:59:
                    93:1f:e9:d1:3e:6d:6d:db:93:57:8f:44:74:d6:64:
                    e9:2b:b6:33:fd:16:81:92:29:a5:80:6a:1f:2b:78:
                    66:d3:ed
                Exponent: 65537 (0x10001)
        X509v3 extensions:
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Extended Key Usage:
                TLS Web Server Authentication,
                 TLS Web Client Authentication
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 CRL Distribution Points:
                URI:
            X509v3 Certificate Policies:
                Policy: 2.16.840.1.114413.1.7.23.1
                  CPS:             Authority Information Access:
                OCSP - URI:
                CA Issuers -
                 URI:
            X509v3 Authority Key Identifier:
            X509v3 Subject Alternative Name:
                DNS:peertech.org, DNS:
            X509v3 Subject Key Identifier:
                C6:5E:C0:43:56:84:2E:11:A3:35:C8:AC:A9:70:96:7B:A5:2E:5B:77
    Signature Algorithm: sha256WithRSAEncryption
        b1:ea:a9:16:b6:9c:56:f4:59:99:df:36:69:92:a5:57:48:df:
        70:55:a6:1f:5b:51:74:b4:d1:d7:5a:f6:71:e6:92:f2:56:14:
        07:f4:2c:14:06:50:4a:e6:f8:32:8c:a1:ed:4b:25:50:fa:05:
        99:01:74:db:45:ae:c2:ca:dc:f3:e7:ad:50:1b:12:c2:1e:ea:
        c8:19:41:db:b0:eb:f1:0c:c7:ba:af:c2:08:9e:7d:3c:c9:de:
        5d:7f:ff:9e:c3:cc:54:bd:ac:1f:24:47:17:ae:ba:75:b7:0b:
        b7:ee:3b:3a:ba:2a:f7:19:19:1a:98:56:35:34:16:8a:ec:ac:
        50:f0:45:7c:06:5a:fe:b1:d8:8b:13:94:5b:2c:1c:3d:b6:df:
        f9:79:69:b0:75:68:b3:e5:01:8e:90:85:bc:bf:92:47:ba:d0:
        9c:8c:5d:28:d6:d3:17:58:96:76:ed:bf:65:75:7c:25:58:57:
        2f:52:ae:9f:a9:a1:35:92:ca:28:13:b6:ae:a8:89:cf:ce:a6:
        cd:31:28:42:f7:66:9d:de:38:0d:4c:d5:ae:49:6c:db:92:28:
        a2:7c:4a:18:8e:7b:b6:0a:c9:d4:8d:0a:82:d4:04:a6:d0:3d:
        8c:a6:37:ac:16:98:bd:79:49:83:60:7f:b5:dc:d7:80:aa:5d:
        ae:f7:11:eb

@_date: 2013-12-02 18:00:04
@_author: coderman 
@_subject: peertech.org cert [was: DEF CON cell network attacks] 
let's try attachment clients won't mangle... (previous will give bad sig)

@_date: 2013-12-02 21:31:52
@_author: coderman 
@_subject: trends in cybersecurity 
thought provoking read, as always. thanks Dan :)
this is worth posting whole, particularly this observation:
... polarization has come to cyber
security.  High end practice is accelerating away from the low end.
The best skills are now astonishingly good while the great mass of
those dependent on cyber security are ever less able to even estimate
what it is that they do not know, much less act on it.  This
polarization is driven by the fundamental strategic asymmetry of
cyber security, namely that while the workfactor for the offender
is the incremental price of finding a new method of attack, the
workfactor for the defender is the cumulative cost of forever
defending against all attack methods yet discovered.  Over time,
the curve for the cost of finding a new attack and the curve for
the cost of defending against all attacks to date must cross.  Once
those curves cross, the offender never has to worry about being out
of the money.  That crossing event occurred some time ago.
i do have one comment, per:
Everyone my age working in cyber security was trained for something
else, and because of that switch between one field and another
brings along the hybrid vigor of seeing the cyber security world
through a different lens.
instead of having a "cyber security" profession, all aspects of
"information security", "software security", or "cyber security" as a
specialization should not exist.  competence and experience with these
subjects should be considered part of routine software and systems
development practice. (right now this is mostly impractical, however,
it need not always be so...)
best regards,
--- cut-for-posterity ---
.Trends in Cyber Security
.Dan Geer, 6 November 13, NRO
Thank you for the invitation to speak with you today, which, let
me be clear, is me speaking as myself and not for anybody or anything
else.  As you know, I work the cyber security trade, that is to say
that my occupation is cyber security.  Note that I said "occupation"
rather than "profession."  On 18 September, the U.S. National Academy
of Sciences, on behalf of the Department of Homeland Security,
concluded that cyber security should be seen as an occupation and
not a profession because the rate of change is too great to consider
professionalization.[1]  You may well agree that that rate of change
is paramount and thus why cyber security is the most intellectually
demanding occupation on the planet.  In writing this essay, I will
keep my comments to trends rather than point estimates, just as you
asked in your invitation, but let me emphasize the wisdom of your
request by noting that the faster the rate of change, the more it
is trends that matter and not the value of any given variable at
any given time.  With luck, each of these trends will not be something
that you would argue with as a trend.  Argument, if any, will be
in their interpretation.
Note also that these trends do not constitute a set of mutually
exclusive, collectively exhaustive characterizations of the space
in which we live and work.  Some of them are correlated with others.
Some of them are newly emergent, some not.  Some of them are
reversible to a degree; some not reversible at all.  I am not, today
anyway, looking for causality.
Trend  Polarization
Much has been written about the increasing polarization of American
life.[2]  The middle is getting smaller whether we are noting that
only the middle class is shrinking, that it is the middle of the
country that is depopulating, that the political middle is lonelier
and lonelier, that both farms and banks are now only too small to
matter or too big to fail, that almost all journalism is now advocacy
journalism, that middle tier college education is a ticket to debt
and nothing else.
I submit that this trend towards polarization has come to cyber
security.  High end practice is accelerating away from the low end.
The best skills are now astonishingly good while the great mass of
those dependent on cyber security are ever less able to even estimate
what it is that they do not know, much less act on it.  This
polarization is driven by the fundamental strategic asymmetry of
cyber security, namely that while the workfactor for the offender
is the incremental price of finding a new method of attack, the
workfactor for the defender is the cumulative cost of forever
defending against all attack methods yet discovered.  Over time,
the curve for the cost of finding a new attack and the curve for
the cost of defending against all attacks to date must cross.  Once
those curves cross, the offender never has to worry about being out
of the money.  That crossing event occurred some time ago.
I'll come back to this first bullet at the end, but I mention it
first as polarization is becoming structural and of all the trends
the most telling.  You can confirm this by asking the best cyber
security people what they do on the Internet and what they won't
do on the Internet.  You will find it sharply different than what
the public at large does or will do.  The best people know the most,
and they are withdrawing, they are rejecting technologies.  To use
the words and style of the Intelligence Community, they are
Trend  Trends themselves
The idea that under the pressure of constant change about all you
can measure is the slope of the curve has gone from
don't-bother-me-with-math to everybody's-doing-it.  A Google search
for the phrase "information security trends" turns up 13,400 hits
and no two of the top ten are from the same source.  Consultancies
talk about what they are seeing in the back room, product vendors
talk about evolving needs, and reporters talk about what they are
seeing out on the street.
I am one of those folks.  A Wall Street colleague and I run the
Index of Cyber Security.[3]  The ICS is what is called a sentiment-based
index; if you are familiar with the US Consumer Confidence Index,[4]
then you already know what a sentiment-based index is.  Respondents
to the ICS are top drawer cyber security practitioners with direct
operational responsibility who share, each month, how their view
of security in several areas has changed since the month before.
Because there are no absolutes in cyber security, not even widely
agreed upon definitions of the core terms that make up cyber security
practice, a sentiment-based Index is, in fact, the best decision
support that can be done.
The Index asks the respondents monthly whether each of two dozen
different risks has gotten better, gotten worse, gotten a lot better,
gotten a lot worse, or stayed the same since the month before.  Out
of this, the Index of Cyber Security is calculated and released at
6pm on the last calendar day of the month, in further similarity
to the Consumer Confidence Index.  We write an analytic annual
report that I have given to the organizers for your further reading.
As an index of risk, a higher ICS number means higher risk.  That
risk number has risen, and seems likely to continue to rise.  It
is a composite trend line, but what is more interesting is that the
components of the risk are much more varied, i.e., what is the
dominating risk one month may not be the next.  We think that this
captures, in part, the dynamic nature of cyber security and does
so in a way not otherwise being done.  Respondents seem to agree
that the ICS does offer decision support to front-line people such
as themselves.
Trend  then, is that there is increasingly wide acceptance that
absolute measures are not worth seeking and a kind of confirmation
that cyber security is a practice, not a device.
Trend  Physics and its impact on data
As you well know, more and more data is collected and more and more
of that data is in play.  The general, round-numbers dynamic of
this trend are these: Moore's Law continues to give us two orders
of magnitude in compute power per dollar per decade while storage
grows at three orders of magnitude and bandwidth at four.  These
are top-down economic drivers and they relentlessly warp what is
the economically optimum computing model.  The trend is clear; the
future is increasingly dense with stored data but, paradoxically,
despite the massive growth of data volume, that data becomes more
mobile with time.
As is obvious, this bears on cyber security as data is what cyber
security is all about.  In 2007, Jim Gray gave a seminal talk[5]
about the transformation of science, coining the term "fourth
paradigm."  By that he meant that the history of science is that
science began as an endeavor organized around empirical observation.
After that came the age of theory -- theorizing as the paradigm of
what science did.  Then science became computational, again meaning
that the paradigm of what science did was to calculate.  His argument
for a fourth era was that of a paradigm shift from computational
science to data intensive science.  You here at NRO need no primer
on the power of that shift in paradigm, but I am here to tell you
that cyber security is embracing that fourth paradigm and it is
doing it now.
Ecology professor Philip Greear would challenge his graduate students
to catalog all the life in a cubic yard of forest floor.  Computer
science professor Donald Knuth would challenge his graduate students
to catalog everything their computers had done in the last ten
seconds.  It is hard to say which is more difficult, but everywhere
you look, cyber security practitioners are trying to get a handle
on "What is normal?" so that that which is abnormal can be identified
early in the game.  Behavioral approaches leading towards intrusion
detection are exactly the search for anomaly, and they are data
based.  The now-famous attack on RSA Data Security that led to RSA
buying Net Witness is an example of wanting to know everything so
as to recognize something.  I'm on the record at book length [6]
that the central organizing principle behind a competent security
program is to instrument your data sufficiently well that nothing
moves without it being noticed.  Physics has made it possible to
put computers everywhere.  Physics has made it possible to fill
them all with data.
Cyber security is barely keeping up, and not just because of two,
three, or four orders of magnitude in the physics upstream of the
Trend  Need for prediction
We all know that knowledge is power.  We all know that there is a
subtle yet important distinction between information and knowledge.
We all know that a negative declaration like "X did not happen" can
be only proven if you have the enumeration of *everything* that did
happen and can show that X is not in it.  We all know that a stitch
in time saves nine, but only if we know where to put the stitch.
We all know that without security metrics, the outcome is either
overspending or under protecting.
The more technologic the society becomes, the greater the dynamic
range of possible failures.  When you live in a cave, starvation,
predators, disease, and lightning are about the full range of
failures that end life as you know it and you are well familiar
with all of them.  When you live in a technologic society where
everybody and everything is optimized in some way akin to just-in-time
delivery, the dynamic range of failures is incomprehensibly larger
and largely incomprehensible.  The wider the dynamic range of
failure, the more prevention is the watchword.  As technologic
society grows more interdependent within itself, the more it must
rely on prediction based on data collected in broad ways, not
targeted ways.
Some define risk as the probability of a failure times the cost of
that failure.  To be clear, a trend in favor of making predictions
is a trend subsidiary to a trend in the cost of failure.  I've
written at length elsewhere about how an increasing downside cost
of failure requires that we find ways to be resilient, but not
resilient in the sense of rich redundancy, not resilient in the
sense of having quick recovery mechanisms, but resilient in the
sense of having alternate primary means that do not share common
mode risks.  As such, I strongly recommend that manual means be
preserved wherever possible because whatever those manual means
are, they are already fully capitalized and they do not share common
mode risk with digital means.
There is now more information security risk sloshing around the
economy than could actually be accepted were it exposed.  The
tournament now turns to who can minimize their risk the best, which,
in the civilian economy at large, means who can most completely
externalize their downside information security costs.  The weapons
here are perhaps as simple as the wisdom of Delphi, "Know thyself"
and "Nothing to excess" -- know thyself in the sense of quantitative
rigor and a perpetual propensity to design information systems with
failure in mind; nothing to excess in the sense of mimicking the
biologic world's proof by demonstration that species diversity is
the greatest bulwark against loss of an ecosystem.
Trend  Abandonment
If I abandon a car on the street, then eventually someone will be
able to claim title.  If I abandon a bank account, then the State
will eventually seize it.  If I abandon real estate by failing to
remedy a trespass, then in the fullness of time adverse possession
takes over.  If I don't use my trademark, then my rights go over
to those who use what was and could have remained mine.  If I abandon
my spouse and/or children, then everyone is taxed to remedy my
actions.  If I abandon a patent application, then after a date
certain the teaching that it proposes passes over to the rest of
you.  If I abandon my hold on the confidentiality of data such as
by publishing it, then that data passes over to the commonweal not
to return.  If I abandon my storage locker, then it will be lost
to me and may end up on reality TV.  The list goes on.
Apple computers running 10.5 or less get no updates (comprising
about half the installed base).  Any Microsoft computer running XP
gets no updates (comprising about half the installed base).  The
end of security updates follows abandonment.  It is certainly ironic
that freshly pirated copies of Windows get security updates when
older versions bought legitimately do not.
Stating the obvious, if Company X abandons a code base, then that
code base should be open sourced.  Irrespective of security issues,
many is the time that a bit of software I use has gone missing
because its maker went missing.  But with respect to security, some
constellation of {I,we,they,you} are willing and able to provide
security patches or workarounds as time and evil require.
Would the public interest not be served, then, by a conversion to
open source for abandoned code bases?  But wait, you say, isn't
purchased software on a general purpose computer a thing of the
past?  Isn't the future auto-updated smartphone clients transacting
over armored private (carrier) networks to auto-updated cloud
services?  Maybe; maybe not.  If the two major desktop suppliers
update only half of today's desktops, then what percentage will
they update tomorrow?
If you say "Make them try harder!," then the legalistic, regulatory
position is your position, and the ACLU is already trying that
route.  If smartphone auto-update becomes a condition of merchantability
and your smartphone holds the keying material that undeniably says
that its user is you, then how long before a FISA court orders a
special auto-update to *your* phone for evidence gathering?
If you say "But we already know what they're going to do, don't
we?," then the question is what about the abandoned code bases.
Open-sourcing abandoned code bases is the worst option, except for
all the others.  But if seizing an abandoned code base is too big
a stretch for you before breakfast, then start with a Public Key
Infrastructure Certifying Authority that goes bankrupt and ask "Who
gets the keys?"
Trend  Interdependence
The essential character of a free society is this: That which is
not forbidden is permitted.  The essential character of an unfree
society is the inverse, that which is not permitted is forbidden.
The U.S. began as a free society without question; the weight of
regulation, whether open or implicit, can only push it toward being
unfree.  Under the pressure to defend against offenders with a
permanent structural advantage, defenders who opt for forbidding
anything that is not expressly permitted are cultivating a computing
environment that does not embody the freedom with which we are
heretofore familiar.
Put concretely, the central expression of a free society is a free
market, and the cardinal measure of a free market is the breadth
of real choice -- choice that goes beyond color and trim and body
style to choices that optimize discordant, antithetical goal states.
The level of choice on the Internet is draining down.  You may revel
in the hundreds of thousands of supposedly new voices that have
found a way to chatter in full view.  You may note that new "apps"
for Android plus iPhone are appearing at over a thousand per day.
You may rightly remind us all that technology is democratizing in
the sense that powers once reserved for the few are now irretrievably
in the hands of the many.  What stands against that, and why I say
that it stands against that, is increasing interdependence.
We humans can design systems more complex than we can then operate.
The financial sector's "flash crashes" are an example of that;
perhaps the fifty interlocked insurance exchanges for Obamacare
will soon be another.  Above some threshold of system complexity,
it is no longer possible to test, it is only possible to react to
emergent behavior.  The lowliest Internet user is entirely in the
game of interdependence -- one web page can easily touch scores of
different domains.  While writing this, the top level page from
cnn.com had 400 out-references to 85 unique domains each of which
is likely to be similarly constructed and all of which move data
one way or another.  If you leave those pages up and they have an
auto-refresh, then moving to a new network signals to every one of
those ad networks that you have so moved.
The wellspring of risk is dependence, especially dependence on
shared expectations of shared system state, i.e., interdependence
on the ground.  If you would accept that you are most at risk from
the things you most depend upon, then damping dependence is the
cheapest, most straightforward, lowest latency way to damp risk,
just as the fastest and most reliable way to put more money on a
business's bottom line is through cost control.
Trend  Automation
Shoshana Zuboff of the Harvard Business School notably described
three laws of the digital age,
. Everything that can be automated will be automated.
. Everything that can be informated will be informated.
. Every digital application that can be used for surveillance and
.    control will be used for surveillance and control.
It is irrelevant, immaterial and incompetent to argue otherwise.
For security technology, Zuboff's Laws are almost the goal state,
that is to say that the attempt to automate information assurance
is in full swing everywhere, the ability to extract information
from the observable is in full swing everywhere, and every digital
application is being instrumented.
Before In-Q-Tel, I worked for a data protection company.  Our product
was, and I believe still is, the most thorough on the market.  By
"thorough" I mean the dictionary definition, "careful about doing
something in an accurate and exact way."  To this end, installing
our product instrumented every system call on the target machine.
Data did not and could not move in any sense of the word "move"
without detection.  Every data operation was caught and monitored.
It was total surveillance data protection.  What made this product
stick out was that very thoroughness, but here is the point: Unless
you fully instrument your data handling, it is not possible for you
to say what did not happen.  With total surveillance, and total
surveillance alone, it is possible to treat the absence of evidence
as the evidence of absence.  Only when you know everything that
*did* happen with your data can you say what did *not* happen with
your data.
But this trend of automating is now leaving the purely defensive
position behind.  In a press release two weeks ago today,[7] DARPA
signaled exactly that, and I quote
   [T]he Defense Advanced Research Projects Agency intends to hold
   the Cyber Grand Challenge -- the first-ever tournament for fully
   automatic network defense systems.  DARPA envisions teams creating
   automated systems that would compete against each other to
   evaluate software, test for vulnerabilities, generate security
   patches and apply them to protected computers on a network.  The
   growth trends ... in cyber attacks and malware point to a future
   where automation must be developed...
The automation trend is irreversible, but it begs a question that
I fear no one will answer in a way that doesn't merely reflect their
corporate or institutional interest, namely are people in the loop
a failsafe or a liability?[8]
Trend  Dual use
I've become convinced that all security technology is dual use.
While I am not sure whether dual use is a trend or a realization
of an unchanging fact of nature, the obviousness of dual use seems
greatest in the latest technologies, so I am calling it a trend in
the sense that the straightforward accessibility of dual use
characteristics of new technology is a growing trend.
There are a lot of examples, but in the physical world any weapon
usable for defense can be repurposed for offense.  Every security
researcher looking for exploitable flaws is deep in the dual use
debate because once discovered, those flaws can be patched or they
can be sold.  The cyber security products that promise total
surveillance over the enterprise are, to my mind, an offensive
strategy used for defensive purposes.
There was a time when flaws were predominantly found by adventurers
and braggarts.  Ten plus years of good work by the operating system
vendors elbowed the flaw finders out of the operating system and,
as a result, our principal opponents changed over from adventurers
and braggarts to being professionals.  Finding vulnerabilities and
exploiting them is now hard enough that it has moved out of the
realm of being a hobby and into the realm of being a job.  This
changed several things, notably that braggarts share their findings
because they are paid in bragging rights.  By contrast, professionals
do not share and are paid in something more substantial than fame.
The side effect has been a continued rise in the percentage of all
vulnerabilities that are previously unknown.  The trend, in other
words, is that by crushing hobbyists we've raised the market price
of working exploits to where now our opponents pay for research and
development out of revenue.
Simulating what the opponent can do thus remains the central task
of defensive research.  Much of that research is in crafting proofs
of concept that such and such a flaw can be taken advantage of.
Corman's neologism of "HD Moore's Law" says that the trend in the
power of the casual attacker grows as does the trend of the power
in Metasploit.[9] It is hard to think of a better description of
dual use.
Trend  The blurring of end-to-end
To my mind, the most important technical decision ever made was
that the security of the Internet was to be "end-to-end."[10]
"End-to-end" is a generic technical term yet simple to explain: the
Internet was built on the premise that two entities could connect
themselves to each other and decide what they wanted to do.  The
network was a delivery vehicle, but the form, content, and security
of the connection between the two ends was to be their own choice.
End-to-end is a model where the terminal entities are smart and the
network is dumb.  This is completely (completely) different than a
smart network with dumb terminal entities at the end of the wire.
No other design decision of the Internet comes close to the importance
of it's being an end-to-end design.  With end-to-end, security is
the choice of the terminal end-points, not something built into the
fabric of the Internet itself.  That is American values personified.
It is the idea that accountability, not permission seeking, is the
way a government curbs the misuse of freedoms, and, as accountability
scales but permission seeking does not, accountability wins.
End-to-end security is the digital manifestation of the right of
association and, in any case, is what enabled the Internet to become
relevant in the first place.  End-to-end does precisely what Peter
Drucker told us to do: "Don't solve problems, create opportunities."
The provision of content from anywhere to anywhere, which is the
very purpose of an internetwork, is a challenge to sovereignty.
America's Founders wanted no sovereign at all, and they devised a
government that made the center all but powerless and the periphery
fully able to thumb its nose at whatever it felt like.  Much ink
has been spilled on the frontier ethic versus the wishful policies
favored by the comfortable urbanity of the welfare state, but the
Internet's protocols have everything in common with the former and
nothing in common with the latter.
The free man requires the choice of with what degree of vigor to
defend himself.  That is a universal; America's Founders laid that
down in the Second Amendment, just as did George Orwell in the
English democratic socialist weekly "Tribune" when he said, "That
rifle on the wall of the laborer's cottage or working class flat
is the symbol of democracy.  It is our job to see that it stays
there."  Were George Washington or George Orwell still among us,
they would know that smart end-points and dumb networks are what
freedom requires, that smart networks protecting dumb end-points
breed compliant dependency.
But the trend is otherwise, and not just because of the fatuous
fashionability of entitlement, but rather because of a blurring of
what the term "end" means.  So very many people have adopted automatic
synchronization of multiple devices they own that one has to ask
whether their tablet is an end or their collection of mutually
synchronized devices is an end.  So many Internet-dependent functions
are spread silently across numerous entities and applications that
what is the end may well be more dynamic than can be described.  If
an end implies unitary control on the part of an owner, then set
theory says that mutually synchronized devices are a unitary end.
That blurring of "end" makes end-to-end provisioning problematic
as a set of devices cannot be assumed to be equally on and equally
participating in any given transaction.  Quoting Clark & Blumenthal[11]
   There is a risk that the range of new requirements now emerging
   could have the consequence of compromising the Internet's original
   design principles.  Were this to happen, the Internet might lose
   some of its key features, in particular its ability to support
   new and unanticipated applications.  We link this possible outcome
   to a number of trends: the rise of new stakeholders in the
   Internet,...  new government interests, the changing motivations
   of the growing user base, and the tension between the demand for
   trustworthy overall operation and the inability to trust the
   behavior of individual users.
This is nowhere so evident as in security, that is to say in the
application of the end-to-end principle to cyber security.  What
does end-to-end secure transport mean when travelocity.com is showing
you a page dynamically constructed from a dozen other entities?
Trend  Complexity in the supply chain
Even without resorting to classified information, it is now clear
that supply chain attacks have occurred.  Whether reading journalistic
accounts or Richard Clarke's novel _Breakpoint_, the finding is
that the supply chain creates opportunities for badness.  None of
the things I've yet read, however, blames the supply chain risk on
its complexity, per se, but that is the trend that matters.
Security is non-composable -- we can get insecure results even when
our systems are assembled from secure components.  The more components,
the less likely a secure result.  This applies to supply chains
that are growing ever more complex under the pressure of just-in-time,
spot market sourcing of, say, memory chips and so forth and so on.
Because the attacker has only to find one component of that chain
to be vulnerable while the defender has to assure that all components
are invulnerable, rising supply chain complexity guarantees increased
opportunity for effective attack.  It cannot do otherwise, and the
trend is clear.
Trend  Monoculture(s)
Beginning with Forrest in 1997,[12] regular attention has been paid
to the questions of monoculture in the network environment.  There
is no point belaboring the fundamental question, but let me state
it for the record: cascade failure is so very much easier to detonate
in a monoculture -- so very much easier when the attacker has only
to write one bit of malware, not ten million.  The idea is obvious;
believing in it is easy; acting on its implications is, evidently,
rather hard.
I am entirely sympathetic to the actual reason we continue to deploy
computing monocultures -- making everything almost entirely alike
is, and remains, our only hope for being able to centrally manage
it in a consistent manner.  Put differently, when you deploy a
computing monoculture you are making a fundamental risk management
decision: That the downside risk of a black swan event is more
tolerable than the downside risk of perpetual inconsistency.  This
is a hard question, as all risk management is about changing the
future, not explaining the past.  Which would you rather have, the
unlikely event of a severe impact, or the day-to-day burden of
perpetual inconsistency?
When we opt for monocultures we had better opt for tight central
control.  This supposes that we are willing to face the risks that
come with tight central control, of course, including the maximum
risk of all auto-update schemes, namely the hostile takeover of the
auto-update mechanism itself.  Computer desktops are not the point;
embedded systems are.  The trendline in the number of critical
monocultures seems to be rising and many of these are embedded
systems both without a remote management interface and long lived.
That combination -- long lived and not reachable -- is the trend
that must be reversed.  Whether to insist that embedded devices
self destruct at some age or that remote management of them be a
condition of deployment is the question.  In either case, the
Internet of Things and the appearance of microcontrollers in seemingly
every computing device should raise hackles on every neck.[13]
Trend  Attack surface growth versus skill growth
Everyone here knows the terminology "attack surface" and knows that
one of the defender's highest goals is to minimize the attack surface
wherever possible.  Every coder adhering to a security-cognizant
software lifecycle program does this.  Every company or research
group engaged in static analysis of binaries does this.  Every
agency enforcing a need-to-know regime for data access does this.
Every individual who reserves one low-limit credit card for their
Internet purchases does this.  I might otherwise say that any person
who encrypts their e-mail to their closest counterparties does this,
but because consistent e-mail encryption is so rare, encrypting
one's e-mail marks it for collection and indefinite retention by
those entities in a position to do so, regardless of what country
you live in.
In cyber security practice, the trend is that we practitioners as
a class are getting better and better.  We have better tools, we
have better understood practices, and we have more colleagues.
That's the plus side.  But I'm interested in the ratio of skill to
challenge, and as far as I can estimate, we are expanding the
society-wide attack surface faster than we are expanding our
collection of tools, practices, and colleagues.  If you are growing
more food, that's great.  If your population is growing faster than
your improvements in food production can keep up, that's bad.
In the days of radio, there was Sarnoff's Law, namely that the value
of a broadcast network was proportional to N, the number of listeners.
Then came packetized network communications and Metcalfe's Law,
that the value of a network was proportional to N squared, the
number of possible two-way conversations.  We are now in the era
of Reed's Law where the value of a network is proportional to the
number of groups that can form in it, that is to say 2 to the power
N.  Reed's Law is the new reality because it fits the age of social
networks.  In each of these three laws as publicly stated, the sign
bit is positive, but in parallel with the claim that everything is
dual use, the sign bit can also be negative because interconnections
are a contributor to the net attack surface.  If an Internet of
Things is indeed imminent, then the upward bend in the curve of the
global attack surface will grow steeper regardless of what level
of risk there is for any one thing so long as that level of risk
is always non-zero.
Trend  Specialization
Everyone my age working in cyber security was trained for something
else, and because of that switch between one field and another
brings along the hybrid vigor of seeing the cyber security world
through a different lens.  Statisticians, civil engineers, and
lawyers alike can contribute.  But the increasing quality of prepatory
education, the increasing breadth of affairs for which cyber security
is needful, and the increasing demand for skill of the highest sort
means the humans in the game are specializing.
While some people like to say "Specialization is for insects," tell
me that the security field itself is not specializing.  We have
people who are expert in forensics on specific operating system
localizations, expert in setting up intrusion response, expert in
analyzing large sets of firewall rules using non-trivial set theory,
expert in designing egress filters for universities that have no
ingress filters, expert in steganographically watermarking binaries,
and so forth.  Generalists are becoming rare, and they are being
replaced by specialists.  This is biologic speciation in action,
and the narrowing of ecologic niches.  In rough numbers, there are
somewhere close to 5,000 various technical certifications you can
get in the computer field, and the number of them is growing thus
proving the conjecture of specialization and speciation is not just
for insects and it will not stop.
[1] "Professionalizing the Nation's Cyber Workforce?"
 [2] _Hollowing out the Middle_, Carr & Kefalas; _Race Against the
Machine_, Brynjolfsson & McAfee; _Average Is Over_, Cowen
[3] "The Index of Cyber Security,"
 cybersecurityindex.org
[4] "The Consumer Confidence Index," Technical Note, 2011
 tinyurl.com/3sb633k
[5] Gray, "eScience," NRC-CSTB, Mountain View CA, 2007
 research.microsoft.com/en-us/um/people/gray/talks/NRC-CSTB_eScience.ppt
[6] Geer, _Economics and Strategies of Data Security_, 2008
[7] [8] Geer, "People in the Loop: Failsafe or a Liability?", 2012
 geer.tinho.net/geer.suitsandspooks.8ii12.txt
[9] Corman, "Intro to HDMoore's Law," 2011
 blog.cognitivedissidents.com/2011/11/01/intro-to-hdmoores-law
[10] Saltzer, Reed, & Clark, "End-to-End Arguments in System Design,"
 web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf
[11] Clark & Blumenthal, "Rethinking the design of the Internet,
The End-to-End Arguments vs. the Brave New World," 2001
 cyberlaw.stanford.edu/e2e/papers/TPRC-Clark-Blumenthal.pdf
[12] Forrest, Somayaji, & Ackley, "Building Diverse Computer Systems,"
HotOS-VI, 1997
 [13] Farmer, "IPMI: Freight Train to Hell v2.01," 2013
 fish2.com/ipmi/itrain.pdf
more material at geer.tinho.net/pubs

@_date: 2013-12-03 15:40:25
@_author: coderman 
@_subject: Fwd: [cryptography] A new approach to steganography 
I came up with a new approach to steganography. There's an
implementation and writeup of it here -

@_date: 2013-12-03 15:42:42
@_author: coderman 
@_subject: [cryptography] A new approach to steganography 
Q. Why did you use Python3 as a reference language?
A. Because not having distinct binary and unicode string types is barbaric.
oh the many ways i both love and hate python...

@_date: 2013-12-04 14:05:27
@_author: coderman 
@_subject: NSA tracking cellphone locations worldwide 
NSA tracking cellphone locations worldwide, Snowden documents show
By Barton Gellman and Ashkan Soltani, Wednesday, December 4, 12:18 PM
The National Security Agency is gathering nearly 5 billion records a
day on the whereabouts of cellphones around the world, according to
top-secret documents and interviews with U.S. intelligence officials,
enabling the agency to track the movements of individuals  and map
their relationships  in ways that would have been previously
The records feed a vast database that stores information about the
locations of at least hundreds of millions of devices, according to
the officials and the documents, which were provided by former NSA
contractorEdward Snowden. New projects created to analyze that data
have provided the intelligence community with what amounts to a mass
surveillance tool.
(Video: How the NSA uses cellphone tracking to find and develop targets)
The NSA does not target Americans location data by design, but the
agency acquires a substantial amount of information on the whereabouts
of domestic cellphones incidentally, a legal term that connotes a
foreseeable but not deliberate result.
One senior collection manager, speaking on condition of anonymity but
with permission from the NSA, said we are getting vast volumes of
location data from around the world by tapping into the cables that
connect mobile networks globally and that serve U.S. cellphones as
well as foreign ones. Additionally, data is often collected from the
tens of millions of Americans who travel abroad with their cellphones
every year.
In scale, scope and potential impact on privacy, the efforts to
collect and analyze location data may be unsurpassed among the NSA
surveillance programsthat have been disclosed since June. Analysts can
find cellphones anywhere in the world, retrace their movements and
expose hidden relationships among individuals using them.
(Graphic: How the NSA is tracking people right now)
U.S. officials said the programs that collect and analyze location
data are lawful and intended strictly to develop intelligence about
foreign targets.
Robert Litt, general counsel for the Office of the Director of
National Intelligence, which oversees the NSA, said there is no
element of the intelligence community that under any authority is
intentionally collecting bulk cellphone location information about
cellphones in the United States.
The NSA has no reason to suspect that the movements of the
overwhelming majority of cellphone users would be relevant to national
security. Rather, it collects locations in bulk because its most
powerful analytic tools  known collectively as CO-TRAVELER  allow it
to look for unknown associates of known intelligence targets by
tracking people whose movements intersect.
Still, location data, especially when aggregated over time, is widely
regarded among privacy advocates as uniquely sensitive. Sophisticated
mathematical techniques enable NSA analysts to map cellphone owners
relationships by correlating their patterns of movement over time with
thousands or millions of other phone users who cross their paths.
Cellphones broadcast their locations even when they are not being used
to place a call or send a text.
(Video: Reporter Ashkan Soltani explains NSA collection of cellphone data)
CO-TRAVELER and related tools require the methodical collection and
storage of location data on what amounts to a planetary scale. The
government is tracking people from afar into confidential business
meetings or personal visits to medical facilities, hotel rooms,
private homes and other traditionally protected spaces.
One of the key components of location data, and why its so
sensitive, is that the laws of physics dont let you keep it private,
said Chris Soghoian, principal technologist at the American Civil
Liberties Union. People who value their privacy can encrypt their
e-mails and disguise their online identities, but the only way to
hide your location is to disconnect from our modern communication
system and live in a cave.
The NSA cannot know in advance which tiny fraction of 1 percent of the
records it may need, so it collects and keeps as many as it can  27
terabytes, by one account, or more than double the text content of the
Library of Congresss print collection.
The location programs have brought in such volumes of information,
according to a May 2012 internal NSA briefing, that they are
outpacing our ability to ingest, process and store data. In the
ensuing year and a half, the NSA has been transitioning to a
processing system that provided it with greater capacity.
The possibility that the intelligence community has been collecting
location data, particularly of Americans, has long concerned privacy
advocates and some lawmakers. Three Democratic senators  Ron Wyden
(Ore.), Mark Udall (Colo.) and Barbara Mikulski (Md.)  have
introduced an amendment to the 2014 defense spending bill that would
require U.S. intelligence agencies to say whether they have ever
collected or made plans to collect location data for a large number
of United States persons with no known connection to suspicious
NSA Director Keith Alexander disclosed in Senate testimony in October
that the NSA had run a pilot project in 2010 and 2011 to collect
samples of U.S. cellphone location data. The data collected were
never available for intelligence analysis purposes, and the project
was discontinued because it had no operational value, he said.
Alexander allowed that a broader collection of such data may be
something that is a future requirement for the country, but it is not
right now.
The number of Americans whose locations are tracked as part of the
NSAs collection of data overseas is impossible to determine from the
Snowden documents alone, and senior intelligence officials declined to
offer an estimate.
Its awkward for us to try to provide any specific numbers, one
intelligence official said in a telephone interview. An NSA
spokeswoman who took part in the call cut in to say the agency has no
way to calculate such a figure.
An intelligence lawyer, speaking with his agencys permission, said
location data are obtained by methods tuned to be looking outside the
United States, a formulation he repeated three times. When U.S.
cellphone data are collected, he said, the data are not covered by the
Fourth Amendment, which protects Americans against unreasonable
searches and seizures.
According to top-secret briefing slides, the NSA pulls in location
data around the world from 10 major sigads, or signals intelligence
activity designators.
A sigad known as STORMBREW, for example, relies on two unnamed
corporate partners described only as ARTIFICE and WOLFPOINT. According
to an NSA site inventory, the companies administer the NSAs physical
systems, or interception equipment, and NSA asks nicely for
STORMBREW collects data from 27 telephone links known as OPC/DPC
pairs, which refer to originating and destination points and which
typically transfer traffic from one providers internal network to
anothers. That data include cell tower identifiers, which can be used
to locate a phones location.
The agencys access to carriers networks appears to be vast.
Many shared databases, such as those used for roaming, are available
in their complete form to any carrier who requires access to any part
of it, said Matt Blaze, an associate professor of computer and
information science at the University of Pennsylvania. This flat
trust model means that a surprisingly large number of entities have
access to data about customers that they never actually do business
with, and an intelligence agency  hostile or friendly  can get one
stop shopping to an expansive range of subscriber data just by
compromising a few carriers.
Some documents in the Snowden archive suggest that acquisition of U.S.
location data is routine enough to be cited as an example in training
materials. In an October 2012 white paper on analytic techniques, for
example, the NSAs counterterrorism analysis unit cites two U.S.-based
carriers to illustrate the challenge of correlating the travels of
phone users on different mobile networks. Asked about that, a U.S.
intelligence official said the example was poorly chosen and did not
represent the programs foreign focus.
The NSAs capabilities to track location are staggering, based on the
Snowden documents, and indicate that the agency is able to render most
efforts at communications security effectively futile.
Like encryption and anonymity tools online, which are used by
dissidents, journalists and terrorists alike, security-minded behavior
 using disposable cellphones and switching them on only long enough
to make brief calls  marks a user for special scrutiny. CO-TRAVELER
takes note, for example, when a new telephone connects to a cell tower
soon after another nearby device is used for the last time.
Side-by-side security efforts  when nearby devices power off and on
together over time  assist in determining whether co-travelers are
associated  through behaviorally relevant relationships, according
to the 24-page white paper, which was developed by the NSA in
partnership with the National Geospatial Agency, the Australian
Signals Directorate and private contractors.
A central feature of each of these tools is that they do not rely on
knowing a particular target in advance, or even suspecting one. They
operate on the full universe of data in the NSAs FASCIA repository,
which stores trillions of metadata records, of which a large but
unknown fraction include locations.
The most basic analytic tools map the date, time, and location of
cellphones to look for patterns or significant moments of overlap.
Other tools compute speed and trajectory for large numbers of mobile
devices, overlaying the electronic data on transportation maps to
compute the likely travel time and determine which devices might have
To solve the problem of undetectable surveillance against CIA officers
stationed overseas, one contractor designed an analytic model that
would carefully record the case officers path and look for other
mobile devices in steady proximity.
Results have not been validated by operational analysts, the report said.
Julie Tate contributed to this report. Soltani is an independent
security researcher and consultant.

@_date: 2013-12-07 17:27:48
@_author: coderman 
@_subject: infra-org (urls) 
actually, i have long held this view on an intuitive / elegance level
of understanding.  the continual expansion of our understanding of
quantum phenomena has only reinforced and clarified this model of
consciousness for me.
rather than sounding crazy, i am pleasantly surprised that others
grasp this concept of consciousness and are willing to embrace it!
this would be a fun tangent to discourse about, however, i'll save the
brain as quantum antenna linked to body via nerve cell transducers for
another day...  ;)
best regards,

@_date: 2013-12-07 21:06:40
@_author: coderman 
@_subject: infra-org (urls) 
that movie discussed a few interesting concepts, but was overall too
annoying/incorrect for me to enjoy :/
regarding the role of quantum effects on consciousness, i am mostly
dismissing the purely deterministic models of consciousness arising
out of chemical interactions or fields only.
consider instead the role of quantum effects within the brain as
influence on nerve behavior within a integrated information theory of

@_date: 2013-12-08 00:22:48
@_author: coderman 
@_subject: NSA morale down 
the portrayals from the brass and insiders is, "the administration is
not showing enough support!".
i have to wonder: how many rank and file are feeling betrayed by the
NSA administration instead?   they're now getting a look into all the
SCI bits they were compartmented from before; able to see a bigger
picture full of invasive technical excesses and legal abuses...
A second former official said NSA workers are polishing up their
rsums and asking that they be cleared  removing any material linked
to classified programs  so they can be sent out to potential
employers. He noted that one employee who processes the rsums said,
Ive never seen so many rsums that people want to have cleared in
my life.
it remains to be seen if they simply jump to private sector who are
just as bad, or pursue less offensive careers entirely.
NSA morale down after Edward Snowden revelations, former U.S. officials say
By Ellen Nakashima, Published: December 7
Morale has taken a hit at the National Security Agency in the wake of
controversy over the agencys surveillance activities, according to
former officials who say they are dismayed that President Obama has
not visited the agency to show his support.
A White House spokeswoman, Caitlin Hayden, noted that top White House
officials have been to the agency to express the presidents support
and appreciation for all that NSA does to keep us safe.
It is not clear whether or when Obama might travel the 23 miles up the
Baltimore-Washington Parkway to visit Fort Meade, the NSAs
headquarters in Maryland, but agency employees are privately voicing
frustration at what they perceive as White House ambivalence amid the
pounding the agency has taken from critics.
An NSA spokeswoman had no comment.
Obama in June defended the NSAs surveillance as lawful and said he
welcomed the public debate prompted by revelations from former
contractor Edward Snowden beginning that month.
Though Obama has asserted, for instance, that the NSAs collection of
virtually all Americans phone records is lawful and has saved lives,
the administration has not endorsed legislation that would codify it.
And his recent statements suggest he thinks some of the NSAs
activities should be constrained.
A senior administration official who was not authorized to speak on
the record said that the White House would normally not endorse
legislation so early in the process but that its been clear ...
that we prefer legislation that preserves the phone records program
while making some changes ... to potentially strengthen oversight
and transparency.
Said Hayden: The president has the highest respect for and pride in
the men and women of the intelligence community who work tirelessly to
protect our nation. Hes expressed that directly to NSAs leadership
and has praised their work in public. As he said: The men and women
of our intelligence community work every single day to keep us safe
because they love this country and believe in our values. Theyre
patriots.
She noted that in recent weeks, Lisa Monaco, assistant to the
president for homeland security and counterterrorism, and Denis
McDonough, the White House chief of staff, visited Fort Meade to
express the presidents support and appreciation for all that NSA does
to keep us safe.
Supporters of the NSA say staffers are not feeling the love.
The agency, from top to bottom, leadership to rank and file, feels
that it is had no support from the White House even though its been
carrying out publicly approved intelligence missions, said Joel
Brenner, NSA inspector general from 2002 to 2006. They feel theyve
been hung out to dry, and theyre right.
A former U.S. official  who like several other former officials
interviewed for this story requested anonymity because he still has
dealings with the agency  said: The president has multiple
constituencies  I get it. But he must agree that the signals
intelligence NSA is providing is one of the most important sources of
intelligence today.
So if thats the case, why isnt the president taking care of one of
the most important elements of the national security apparatus?
The White House, observers say, is caught between competing desires to
preserve what it has said are valuable national security programs and
to shield the president from criticism from allies abroad and
civil-liberties advocates at home.
Some observers said it is not surprising that Obama would not travel
to Fort Meade before internal and external reviews of surveillance
activities have been completed. The reviews are expected to be done
The NSAs director, Gen. Keith Alexander, who is retiring in the
spring after 81 / 2 years, has been the most vocal defender of the
agencys 35,000 employees. In speeches he has noted that more than
6,000 of them went to Iraq and Afghanistan to support the military. He
has spoken of how 22 cryptologists were killed. Theyre the heroes 
not the media leaker, he said in a September speech, in a reference
to Snowden.
NSA counterterrorism analysts have worked every weekend for eight
years since Ive been here. ... Twenty-four hours a day, seven days
a week, theyre there to defend us, he said then.
On Thursday, Obama said on MSNBC that he would be proposing some
self-restraint on the NSA and some reforms that can give people more
In an interview with NBC last month, he said: In some ways, the
technology and the budgets and the capacity [at NSA] have outstripped
the constraints. And weve got to rebuild those in the same way that
were having to do on a whole series of capacities ... [such as]
drone operations.
Civil-liberties advocates generally agree with that sentiment, but
they would go further and say that the NSAs bulk collection of
domestic phone records is unlawful and ought to be ended.
Former officials note how President George W. Bush paid a visit to the
NSA in January 2006, in the wake of revelations by the New York Times
that the agency engaged in a counterterrorism program of warrantless
surveillance on U.S. soil beginning after the Sept. 11, 2001,
terrorist attacks. Bush came out and spoke to the workforce, and the
effect on morale was tremendous, Brenner said. Theres been nothing
like that from this White House.
A second former official said NSA workers are polishing up their
rsums and asking that they be cleared  removing any material linked
to classified programs  so they can be sent out to potential
employers. He noted that one employee who processes the rsums said,
Ive never seen so many rsums that people want to have cleared in
my life.
Morale is bad overall, a third former official said. The news  the
Snowden disclosures  it questions the integrity of the NSA
workforce, he said. Its become very public and very personal.
Literally, neighbors are asking people, Why are you spying on
Grandma? And we arent. People are feeling bad, beaten down.

@_date: 2013-12-08 00:44:02
@_author: coderman 
@_subject: NSA morale down 
by private sector i'm thinking of companies like Statfor more than Amazon...
... Below are a series of articles this past week about
internationally acclaimed activist, Srdja Popovic, and his involvement
with the private intelligence firm Stratfor.
... If anyone has information about CANVAS or Srdja Popovic, please
feel free to contact me at zoealif[at]gmail.com. I am currently
writing a blog post on the story.

@_date: 2013-12-09 07:53:07
@_author: coderman 
@_subject: Android IMSI Catcher detection 
fun :)  i always liked osmocomBB, since openmoko days...
these days i prefer SDR and wider band, wider freq. transceivers, but
TI Calypso and MTK definitely more accessible!  will you provide a
developer mailing list in addition to github?
best regards,

@_date: 2013-12-09 08:07:18
@_author: coderman 
@_subject: EM-nature (was: infra-org) 
effective attenuation of emanations above 10Ghz would be interesting.
even at >5Ghz you run into trouble with the AC filer route as you
mention; best practice seems to be DC batteries inside the cage :/
attenuation at high frequencies for air flow mesh less problematic;
optical communication links will always be useful of course...
i would be curious to see high dBm with high dBi gain
emitters(antennas) worst-case testing against actual build outs at
beyond exceptional..
Teletronics makes some nice 1W 5.8Ghz amps for 802.11a which could be
so purposed inexpensively.
best regards,

@_date: 2013-12-09 09:49:49
@_author: coderman 
@_subject: Android IMSI Catcher detection 
it doesn't "function" yet, period.  *grin*
i leave it as an exercise for the reader to implement A0 detection on Android...

@_date: 2013-12-09 15:03:57
@_author: coderman 
@_subject: good clocks (not using GPS) and multi-channel hw [was: sidebands 
GPS disciplining to keep a OCXO in check periodically (GPSDO) would be
useful!  GPS just can't be the primary source.
has anyone used an OctoClock-G?
  best regards,

@_date: 2013-12-09 15:17:04
@_author: coderman 
@_subject: Android IMSI Catcher detection 
carrierIQ is good for something ;)
you're going to have to go ARM native (or ?) to observe use of A0 over
GSM, since android.telephony.gsm screwed us.
this came up on the cryptome list last week: camouflage, jamming,
obfuscation are all useful techniques to apply against unwelcome
observers. c.f. high power infra red LED camera dazzlers and LADAR
jammers, etc.
while equally effective on the cell bands, you'll want to be sure to
check your 20 before emitting with gusto!  ;P
best regards,

@_date: 2013-12-09 15:30:31
@_author: coderman 
@_subject: Android IMSI Catcher detection 
i feel your pain...
sort of; there are some interesting attacks using a force-pushed
silent PRL update (see DC19/DC20 cell attacks threads) which would be
observable by tower ID oddities, not to mention decremented or zero
PRL version.  however, you'd have to be paying attention (who checks
their PRL regularly? :).
if you simply check if a tower is in
 for example, you're open to
attacks spoofing a legitimate but remote (out of range) tower.
using direction finding techniques to cross reference the transmitter
location against the expected GPS coordinates in a tower database
relative to your position would also detect these tower impersonators,
but requires more hardware than a mobile baseband...
the expensive, limited distribution kit will be hard to distinguish
without a high performance software defined radio.  if you're able to
detect an identically spoofed tower using OsmocomBB with high
confidence i'd love to know how you did it!
truth.  also, an inversion of observed data link capacity (suddenly
seeing receive bandwidth drop in half or more while transmit rate
doubles) is no bueno.
best regards,

@_date: 2013-12-09 16:22:38
@_author: coderman 
@_subject: Open phones for privacy/anonymity applications, Guardian 
the FCC/NTIA don't like people using spectrum with unapproved devices.
sure, you can code it up. and sure, you can run an SDR in that range.
... but put them together in the wild at useful dBi and you're
stepping on toes.  try to sell/distribute such a setup? better have it
good analysis of the details:
  ...the FCCs ancillary jurisdiction cannot reasonably extend to the
development of software by parties uninvolved in the marketing or sale
of radio devices...
FCC Rules for SDR Device Certification Only Affect Radio Equipment

@_date: 2013-12-09 16:26:45
@_author: coderman 
@_subject: Open phones for privacy/anonymity applications, Guardian 
to be specific: it is this certification step that fully open source
SDR/baseband equipment manufacturers have difficultly with.  E.g. the
FCC plainly states systems  "wholly dependent on open source elements
would have a high burden to demonstrate their security during the
certification process.  where many have taken "high burden" to mean
"nearly impossible"...
best regards,

@_date: 2013-12-11 00:09:49
@_author: coderman 
@_subject: Fwd: [cryptography] Which encryption chips are compromised? 
you ask interesting questions Dan, and draw useful conclusions :)
some items to note:
- is this DUAL_EC_DRNG? don't think so. deadline is FY 2013.
- is this DUAL_EC_DRNG? the market for closed source, proprietary
crypto solutions is small (and growing smaller, :(
- is this XSTORE? it's been a while. but never should have been used
directly. see mtrngd with MSR bits set no whitening, max sample, max
freq. into mix + conservative estimate before /dev/random write.
some cryptographers and cypherpunks have become despondent or dejected
or demoralized by these events.
i see a larger picture: never before have so many been doing crypto less wrong!

@_date: 2013-12-11 00:10:24
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
I think there may be weaknesses in Intel's hardware RNG.  I took a
good look at Intel's hardware random number generator source. There's
a paper analyzing it here:
The basic idea is that back-to-back inverters, when powered on, flip
one way or the other randomly, sort of like DRAM memory when our
computer's power on.  By powering on a single pair of back-to-back
inverters over and over, they can generate a random bit per cycle, at
about 3 Giga-bits/second, which is amazing!  Here's my concerns about
the the paper:
- I saw no mathematical analysis of how much noise exists in the
system and how strongly it will influence the result each cycle. There
were generalities about how the noise could cause the output to be
random, but no numbers at all.
- There is an assumption that the capacitors are charged/discharged by
10% of the standard deviation of the noise.  I saw no justification
for this.  It seems they simply assumed best case.
- The paper is about as objective as a mother talking about her
children.  For example: "Overall, the Ivy Bridge RNG is a robust
design with a large margin of safety that ensures good random data is
generated even if the ES is not operating as well as predicted." Based
on what?
- I am not convinced they have the right model for the entropy source.
 They add noise to the bias on the capacitors, and compare that to 0
to determine the next output bit in their model.  I think the main
source of noise may be the randomness in number of electrons
added/subtracted each cycle, and that the back-to-back inverters in
the absence of other noise may be acting almost as an ideal
comparator.  However, if this were the case, even if there were 10%
noise in the number of electrons, there would be considerable
correlation between bits.
I also have questions about the design itself.  My main concern is
that noise on the VDD rail could easily determine the output.  For
example, if the transistors are mismatched, which of course they will
be, and the bias is set exactly right on the caps so there's a 50-50
chance of a 0 or 1, and suddenly VDD drops 10% due to a rising edge of
the the main system clock, then the inverter with higher gate
thresholds will become weak faster than the other one, thus
determining which one wins.  Since this circuit runs asynchronously
from the main system clock, I could easily see the 3MHz system clock
phase relative to the entropy generator clock determining most of the
results from the entropy source, while looking fairly random. Any
weakness in the raw random data stream is hidden from us by the AES
encryption done as a post-process.
I simulated back-to-back inverters in my .35u low power CMOS process
in SPICE to see if I could figure out how to make a practical circuit
using Intel's topology.  If it works, it would be fantastic.  I think
I can get rid of most of the supply noise issues.  I had a similar
problem in my "Infinite Noise Multiplier", so I switched to powering
the circuit with nothing but large W and L constant current sources,
and using the range from 0V to Vref, rather than 0V to VDD, because
Vref is stable relative to AVSS. However, I wasn't able to get enough
noise to make Intel's ciruit work, though that may be due to
limitations in the SPICE simulator.
Has anyone else had success using Intel's RNG topology?

@_date: 2013-12-11 00:10:52
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
I have to take back my criticism of Intel's RNG.  I got my sims
working for a version of their architecture in .35u CMOS, and it's
simply better than my "Infinite Noise Multiplier".  It's probably the
best true random noise generator ever.  I still don't like how their
schematic is seems highly sensitive to supply noise, but we don't know
what the actual circuit looks like.  Intel hasn't told us.
So, I'm going to modify it a bit to use the resistors available on my
chip and reduce the caps, fix the supply sensitivity, and I think I
can run 16 of these things in parallel at 100-200MHz on the tiny .35u
CMOS chip I'm designing.  I'll spit out the raw waveforms from the
inverters, buffered once, through 16 "analog" pins, so there wont be
any fear (hopefully) that I'm cooking the data on-chip, before you can
see it, and I'll open-source the schematics.  If there's a circuit
that can consume all 1.6Gbit/sec of this raw data, have fun with it!
On the digital side, I'll XOR bits together to get the bandwidth down
to something reasonable, which I can send over USB, and provide a
simple Linux driver.
This thing will definitely put out RF, but since I'm making the raw
data available at the pins, should I care?  By the way, this is just a
for-fun project at work.  I get to do a free chip design :-)

@_date: 2013-12-11 00:11:18
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
raw samples at 1.6Gb/s would be useful infrequently[0]; raw samples
from a trusted device extremely useful bitrate!
what is "my chip" and how can we find out more / support your efforts?
best regards,
0. to date i have only maxed out 400Mb/s raw VIA Padlock sources for
SSD FDE initialization and constructed experiments in temporal key
rolling.  it is however common to regularly consume on the order of
10Mb/s on a busy server, generating many keys, using crypto happy
software, etc.  (this is why every processor, every embedded device
should have a physical entropy source, with access to raw samples.
still waiting...)

@_date: 2013-12-11 07:17:09
@_author: coderman 
@_subject: Android IMSI Catcher detection 
the partnership with NGA to deploy them gives a hint: this is putting
USRPs up close and personal to target for exploitation.
(the USRP's are definitely more portable than my favorite SDR, the Noctar[0]!)
given the obtained bits mentioned (WLLids, DSL accounts, Cookies,
GooglePREFIDs) gathered and then handed off to TAO for further QUANTUM
INSERT fucking of target systems it is likely they are doing GSM/cell
MitM to observe identifiers, along with WiFi attacks, and other egress
rather than deploying baseband exploits or deep active attacks
directly against the devices or other networks they're communicating
thus CNE in this case is cell MitM/WiFi pwn with a USRP rogue tower to
get identifiers for TAO.  and TAO is where they get dirty with "remote
exploitation" of the device itself and other targets on networks it
we've seen how they have a smorgasbord of weaponized exploits to cover
the gamut of target hardware and technical acumen in the QUANTUM
INSERT / TURMOIL / TRAFFICTHIEF / MUTANT BROTH / etc, etc. style
efforts.  it appears they're using this same infrastructure where
possible for mobile; restricting CNE on the ground only to target.
best regards,
0. Pervices Noctar

@_date: 2013-12-11 07:22:12
@_author: coderman 
@_subject: Android IMSI Catcher detection 
see also this section on the OPEC hacks:
Heres how the NSA and GCHQ go after an organization like OPEC step by
step, based on an analysis of the NSA and GCHQ documents exposed by
Step 1: Identify. Using the NSA-built packet capture and inspection
system called TURMOIL, the agencies filter through Internet traffic at
a network choke point looking for specific "fingerprints" in traffic
that identify users with the organization being targeted. Data from
TURMOIL gets pulled into a number of traffic analysis tools, such as
XKeyscore and TRAFFICTHIEF, which do different sorts of packet
XKeyscore is the NSA's distributed search engine, catching a large
chunk of international Internet traffic for analysis. It helps find
things deep in the clutter of the Internet that analysts might miss by
allowing them to use search terms to find things in both live and
cached Internet traffic.
TRAFFICTHIEF, on the other hand, is much more focused. It filters for
very "strong" indicators, like known sets of IP addresses, addresses
within e-mail traffic, or user names in logins to social networks or
other services. It provides less depth of analysis than XKeyscore, but
it can handle much larger loads of data because it is more selective
about what it processes.
Together, the tools can be used to identify the systems used by an
individual or organization, including ranges of addresses that they
may use from work or home.
Step 2: Target. Using the profiles built using the surveillance tools,
the agencies can then identify potential points of attack. XKeyscore,
for example, can be used to search for patterns that identify known
security vulnerabilities within a range of addresses. Web visit
histories, e-mail traffic, and other data are analyzed looking for the
most likely (and least detectable) approach to gain access, and a
specific attack plan is crafted, including the identification of where
to launch the attack from.
At the NSA, this sort of thing is the work of Tailored Access
Operations. In the case of OPEC, the targeting process apparently went
on for several years as the NSA sought openings for an attack.
Step 3: Attack. Depending on who the target is, the NSA and GCHQ have
a variety of options. The least costly is to use access provided by
one of the intelligence agencies' telecommunications "partners" who
own network equipment at an exchange or other choke point that the
target's Internet traffic passes through. The agency running the
attack can use that access to introduce changes to Internet routing
tables that detour the targeted individual's traffic. But in some
cases, the NSA and GCHQ may have to perform "unilateral" taps on
network backbones to gain that level of accesstargeting a piece of
network hardware to take over or splicing directly into the target's
own connection to the Internet.
It's not clear which attack the NSA used to gain access to OPEC's
systems, though the GCHQ used a Quantum attack two years later to gain
its own very special access to the cartel's network. In the case of
the Belgacom hack, the GCHQ used a Quantum insert attackrouting the
Web requests for LinkedIn and Slashdot from the engineer being
targeted to a server posing as those sites. The NSA has used the same
approach to intercept traffic to sites such as Google.
The man-in-the-middle server can present content from the actual sites
the target intended to visit, but it can also add content to the
traffic, using what's called packet injectionmodifying the contents
of the data as it passes throughand intercept the user's credentials.
And by using a forged certificate, the NSA can intercept encrypted
traffic intended for the destination site.
Once the user has connected to the fake server, the intelligence
agencies can use the connection to launch attacks against the target's
Web browser to install monitoring software or other malware, using
similar techniques to those used by hackers. They can also use
credentials exposed via the man-in-the-middle attack to gain access to
other accounts owned by the target and to troll through connections in
those services that might be potential targets.
Step 4: Exploit. Once the target's computer has been successfully
attacked, the effort begins to look much like that of the Chinese
cyber warriors' attack of the New York Times or what cyber criminals
typically do when they score access to high-value targets. The
agencies' hackers work to stealthily expand their level of access,
using customized remote administration tools to grab user privileges
and gain access to other network resourcesmail servers, file servers,
and other network systems. They then start to "exfiltrate" data from
these systems and deliver them to analysts.

@_date: 2013-12-11 14:08:46
@_author: coderman 
@_subject: Android IMSI Catcher detection 
CNE+TAO as non destructive espionage (politics)
  but they also play
CNE+TAO as kinetic force multiplier (war)
so the answer is: both!  depending on the target...

@_date: 2013-12-11 18:04:39
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
Ivy Bridge is the codename for a line of processors based on the 22 nm
manufacturing process developed by Intel. The name is also applied
more broadly to the 22 nm die shrink of the Sandy Bridge
microarchitecture based on FinFET ("3D") tri-gate transistors, which
is also used in the Xeon andCore i7 Ivy Bridge-EX (Ivytown), Ivy
Bridge-EP and Ivy Bridge-E microprocessors released in 2013.

@_date: 2013-12-11 18:16:07
@_author: coderman 
@_subject: Android IMSI Catcher detection 
Regarding the CCP FY 2013 goals per
"Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4G/LTE)
networks via enabling. [CCP_00009]"
i wonder if they upgraded to N210 (pairs?) for good 4G/LTE performance?

@_date: 2013-12-11 19:01:31
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
"used in Virtual Private Network" == PPTP,IPsec,OpenVPN,etc.
"Web encryption devices" == in my interpretation, this is any targeted
hardware with the vulnerable chip.  it could be a tablet, a desktop,
and rack mount server...  any of these platforms could speak VPN or
Web crypto.  TAO/SCS do like to get into the switches though ;)
mostly "cloud infrastructure", "software defined data center", and the like:
back in the day, Sun got tired of the (relatively) slow performance
and latency of crypto offloading via bus and simply threw it into the
core.  you were still offloading crypto, but within the CPU.
also note that endpoint compromises sufficient to decrypt VPN or
secure web traffic is already present in TAO/CNE's tasking.  this
effort [CCP_00009] may focus on VPN concentrator / secure web proxy
deployments specifically to handle the RDRAND lookup per their private
starting counter.
previous back doors have also used entropy leakage sufficient to bring
a brute force attack into reasonable effort, while still denying third
parties a class break of the entropy / keys used.  this type of key
space search is not done on the ground with portable CNE but instead
back at SCS...
on a related tangent, the lack of additional disclosures is quite
frustrating.  this entire conversation would be resolved in a glance
if $the_snowden_gatekeepers were acting in the public interest.  :/
best regards,

@_date: 2013-12-11 23:41:41
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
i remember seeing software to do this, but for the life of me cannot
find it.  anyone?
my favorite redaction technique is still the Adobe white text on white
background in PDF trick; combine with a filter for CONFIDENTIAL /
PROPRIETARY and you've got a fire hose of informative flotsam...[0]
best regards,
0. "The Revenge of Distance: Vulnerability Analysis of Critical
Information Infrastructure"
  back when Sean Goreman's work and post 9/11 hysteria combined to drive
critical infrastructure information into access controlled obscurity
(not even FCC outage reports public!) i used this technique with
custom deep web crawlers for court documents and other technical
references.  code doesn't care about color ;)   thus fiber counts
along specific rights of way allocated to named customers provided the
specific capacity information needed to make useful models for
measuring "spatial implications of telecommunications infrastructure
susceptibility to targeted attack".  this was the first time i wrote
code that actually scared/disturbed me :o

@_date: 2013-12-12 06:08:35
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
i see your skepticism, and i raise you a retort! ;)
i even have a list of candidates you can experiment with to confirm
Intel Ivy Bridge as best fit. [0]
plus a few more things, e.g. your ~250-300million $USD/year budget goes toward:
"actively engag[ing] the US and foreign IT industries to covertly
influence and/or overtly leverage their commercial products' designs
[... to] make the systems in question exploitable through SIGINT
collection (e.g., Endpoint, MidPoint, etc.) with foreknowledge of the
modification. and, Insert vulnerabilities into commercial encryption
systems, IT systems, networks and endpoint communications devices used
by targets.
only with "foreknowledge of the modification" are you able to utilize
this backdoor. (NSA does not like to share)
also, this year by end of year, in 2013 you expect to:
- Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4GL/LTE)
networks by inserting vulnerabilities.
- Complete enabling for [well recognized name] encryption chips used
in Virtual Private Network and Web encryption devices.
and last but not least,
- Shape the worldwide commercial cryptography marketplace to make it
more tractable to advanced cryptanalytic capabilities being developed
by NSA/CSS.
Ok, given those requirements. Who fits the bill?
High end platform:
Intel targets what it believes is a significant growth opportunity to
bring the Intel Architecture into a rapidly evolving networking space.
Intel added to its portfolio with the introduction of the Highland
Forest platform, which combines the vendors Xeon E5-2600 v2 CPU with
its new Coleto Creek chipset. Price said Highland Forest  which can
pack up to 20 2.4GHz Ivy Bridge CPU cores  will offer two to six
times the performance of the previous Crystal Forest platform, which
was launched in October 2012.
Highland Forest, with Intels Data Plane Development Kit, can deliver
up to 255 million packets per second (p/s)  more than the 140 million
p/s from Crystal Forest  as well as security capabilities of 110
Gigabits per second of IPsec and 200 Gb/s SSL security for encrypted
IPsec (VPN) and SSL (Web crypto) and lots of it!  sounds interesting.
tell me more!
other market points of note:
- "Intel currently has over 15 SDN/NFV qualification trials underway
with carriers in all major regions.  Schooler emphasized that Intel
has no intention to sell directly to service providers and is fully
committed to launching an Intel Network Builders Ecosystem of industry
players supporting the Intel Architecture."
- "6WIND Announces Availability of Support for Intel Xeon Processor
Platform for Large-Scale Communications Infrastructure Systems,
Formerly Called Highland Forest 6WIND announces the availability of
support within the 6WINDGate software for the Intel Xeon Processor
Platform for Large-Scale Communications Infrastructure Systems,
formerly called Highland Forest. With its optimized support for the
Intel QuickAssist Technology that provides hardware acceleration for
encryption and compression, 6WINDGate delivers best-in-class
performance for networking applications such as WAN optimization, VPN
appliances, firewalls and Unified Threat Management (UTM) systems." -
funny they seem to distance themselves from "Highland Forest" and "Ivy
Bridge" in this press release and product launch...  [
 ]
they sound interesting, like they sell to many industries at large
scale.  are they a popular company/product?
 ""6WINDGate is already deployed in tens of commercial LTE networks
throughout Asia, Europe and North America, while also being used by
multiple tier-1 suppliers of enterprise and cloud networking
hey look, LTE! ...
ok, so that's a little suspect.  what's that, there's more you say?
"I am so glad I resisted pressure from Intel engineers to let
, "Oh, I should add that just today I had to fight back an attempt by
a Red Hat engineer to add a configuration option to blindly trust
RDRAND and bypass the entropy pool"
then the FreeBSD change of heart.
hey Wind River, how are you using RDRAND?
now what about Intel themselves, are they also pushing the chip?
Intel officials are making aggressive moves to expand the reach of its
silicon beyond servers and into other parts of the data centre.
Schooler said the company has been making products for networking gear
for about a decade, and has made significant strides in recent years.
Its also made several acquisitions  such as of Sensory Networks,
Ethernet chip maker Fulcrum Microsystems and networking software maker
Aepona, whose technology enables telecoms and cloud service providers
to offer more services on their networks.
Intel is looking to take advantage of the growth opportunity
networking represents, Schooler said. The market Intel is targeting is
about $16 billion (9.7bn), and the chip maker currently has about 5
percent of it. Along with its x86 architecture, Intel also is
developing accelerator chips for such jobs as packet inspection and
whew.  that's a lot of context and circumstance.  let's look back over
your goals for 2013:
Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4GL/LTE)
 - AFFIRMATIVE!
Complete enabling for [Intel Ivy Bridge] encryption chips used in
Virtual Private Network and Web encryption devices.
- AFFIRMATIVE!
Shape the worldwide commercial cryptography marketplace to make it
more tractable to advanced cryptanalytic capabilities being developed
by NSA/CSS.
- AFFIRMATIVE!
i will admit that i am continually impressed by NSA/SCS achievements.
they're extremely competent!
my reading between the lines: it is not a special chip, it is a
special collection of many of them (20+) handling tier-1 core traffic
encryption, which is an excellent point to aggregate a vulnerability
in keying ciphers. (ignore public key for now, since we can just focus
directly on session/temporal keys!)
0.  please to be experimenting with datas:
Interface Masters Technologies
Freescale Semiconductor
Alteon SSL Accelerator
Nortel SSL Accelerator
Strangeloop Networks
Riverbed Technology
Coyote point systems
Crescendo Networks
Microchip PIC32MZ
Barracuda Networks
Kemp Technologies
Check Point VPN-1
Sun Microsystems
Foundry Networks
Cavium Networks
Cavium NITROX
Juniper Networks
Nortel Networks
Array Networks
Intel Ivy Bridge <- only this is right length in justified context shown
Forum Systems
Cavium Nitrox
CAI Networks
A10 Networks
Cisco Systems
Citrix Systems
Sun SCA6000
MIFARE Plus
Network Box
Coleto Creek
F5 Networks
Cisco PIX
parting words:
On April 17 at the Open Networking Summit, Intel executives laid out
the companys strategy around data center networking and the
burgeoning trend of software-defined networking (SDN). They also
showed that their efforts will expand beyond simply supplying the
processors for networking hardware. The company unveiled reference
architectures designed to help enterprises, cloud service providers
and telecommunications companies more quickly create hardware and
software for SDN and network-function virtualization (NFV), moves that
could bring Intel into closer competition with the likes of networking
giant Cisco Systems and chip maker Broadcom.
 - don't let them get away with it!
open up raw access to entropy sources!!
don't discriminate against the unit, one is prime!!!

@_date: 2013-12-12 06:52:20
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
one last amusing note, Google has gone whole hog on SDN:
  how amusing would it be if they implemented inter-DC IPsec keyed with
RDRAND directly on compromised cores in one of these Highland Forest
like SDN deployments?
i can already see the updated napkin sketch now, and imagine the
streaming swears pouring forth from the googlies once uncovered...

@_date: 2013-12-12 08:20:44
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
let it be known:
in the event of my untimely demise under suspicious circumstances, i
will my coins to JYA so he may bless my passing with grand oration and
strong tale as he is so adept at providing.  *grin*
on a serious note, the useful steps are clear:
1. Intel releases raw access to noise samples
2. NIST defining and mandating a design that also supports raw sample
access, (we could change subject here to discuss something pleasant
like on-line checks and continuous checks,)
3. OS distributions include userspace entropy scavenging daemons
(haveged, dakarand, etc) to complement properly vetted hardware
entropy sources run in a conservative fashion.  default is set safe,
not fast.
is that so much to ask?

@_date: 2013-12-12 08:42:02
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
the bulk of 2012 was consume user hardware.  the endpoint is a totally
solved problem (read: trivial to exploit in many ways, all day, every
day, per the docs)
only server Ivy Bridge: Xeon E3 in mid-2012.
the cores pushed in the SDN initiatives above came out not so many months ago...
high capacity crypto aggregation points like this are an ideal target,
with backdoor keying of VPN/SSL the ideal (passive) attack with their
view of target's long haul fiber.
but not released, and "enabling" means tied into X-KEYSCORE,
TRAFFICTHIEF, whatever else gets draped off UPSTREAM...
the backdoors for all the other vendor hardware happened in years
prior.  HSMs and crypto accelerator gear is not exactly a vibrant or
competitive market.  in fact, these companies never seem to die, just
carry on with decent margins riding on incremental design upgrades
until they're bought out by a larger/growing competitor. ;)
of course, this could be because companies like Sun charge $9,999 for
an HSM/accelerator that is at best a reasonable cost at $1,499...

@_date: 2013-12-12 09:18:09
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
this does bring up an interesting point:
while it may be more efficient to use the same "key" for the DRBG
output across all processor lines, it would be more secure to use a
different key per line.  this implies that each iteration of Sandy
Bridge -> Ivy Bridge -> Haswell needs to be "enabled" by CCP, with
Xeon E5 debut in 2013 as discussed.
for Sandy Bridge, this would have shown in 2010? and unless in network
equipment described simply as "enabling decryption for Sandy Bridge
used by $operating systems and $applications."
sadly we'll have to wait a while to confirm this conjecture for
Haswell.  and we'll have to wait forever for more leaks apparently, as
the continuing decline of details demonstrates...
best regards,

@_date: 2013-12-12 09:23:50
@_author: coderman 
@_subject: Fwd: [liberationtech] PrivateSky Takedown 
Certivox Asked That We Share Their Side of the Story on the PrivateSky Takedown.
The real story on the PrivateSky takedown.
Posted by Brian Spector on Thu, Dec 12, 2013
With the story about our PrivateSky takedown now public, I want to
take the opportunity to clarify a few points in various articles that
have appeared since yesterday covering the story.
Some headlines strongly infer our friends at GCHQ "forced" us to take
PrivateSky down. That's not the case.
Secondly, a very important point wasn't printed. GCHQ couldn't, by
law, request a blanket back door on the system. There are a very rigid
set of controls that mean only specific individuals can come under
surveillance. The legal request for such surveillance has a due
process that must be stridently followed. At no time did I or anyone
at CertiVox talk about CertiVox in relation to any RIPA warrant, only
the generic process by which these warrants are served.
By saying "our friends at GCHQ", there is no facetiousness intended.
The team at CertiVox have the upmost respect for the folks we
interacted with at GCHQ. They took the due process I outlined in the
previous point very seriously. We found that as an organisation, and
every individual involved there, were as worried about a breach of
public trust as much as we are.
Finally, I believe very strongly the following should be a larger part
of the public discourse of these subjects. What everyone needs to
understand is that every developed democracy in the world, even where
privacy rights are enshrined to the maximum efficacy by statute, has
laws on the books that mandate that Internet Service Providers have
facilities to work with law enforcement for the purposes of legal
intercept, to enforce public safety and security.
Being L.I. capable is a very important set features and functions that
must be in place for any credible, commercial service on the Internet.
In endeavouring to make PrivateSky as secure as possible, we
overlooked this critical requirement when we built PrivateSky.
When CertiVox positioned PrivateSky as the easiest to use and most
secure encrypted messaging service, we really had two significant
points of differentiation. First, even though we held the root
encryption keys to the system, it was architected in such as way that
it would have been all but impossible for our internal staff to snoop
on our customer's communications, or for the service to leak any of
our customers data. Secondly, our possession of the root keys, and
our use of identity based encryption, made the system incredibly easy
to use. For the user, there were no private or public keys to manage,
every workflow was handled for the user in an easy to grasp pure HTML5
interface, no hardware or software required, just an HTML5 browser.
We boxed ourselves into a feature set and market position that when
called upon to comply with legal statues, we simply had no alternative
but to shut the service down. We built it, but we couldn't host it.
Why? Because as you can probably surmise, there is an inherent
impedance mismatch between being able to host a commercial
communications service that gives the upmost in privacy to its users,
against any breach, whilst at the same time being able to operate
safely within the confines of the law as it is on the books in most
countries on the planet.
In summary, it's the abuse of the communications interception in the
Snowden revelations that has everyone up in arms, as so it should. But
thats not what happened with PrivateSky.
What is our next move?
Watch this space.
Liberationtech is public & archives are searchable on Google.
Violations of list guidelines will get you moderated:
Unsubscribe, change to digest, or change password by emailing
moderator at companys at stanford.edu.

@_date: 2013-12-12 17:17:03
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
the worst kind of xpost of all?
every day without RDRAW is another day of my life with provably less
information theoretic meaning.  ;)
two chips or two families or two architectures or ...
is this a game of twenty questions? can we do a reddit AMA for the
leakers with their stash at the ready?
you know, if we had more documents providing context,
past experience tells us they like attacks universally effective,
unidirectional, silent/random-looking (without secret knowledge), and
don't mind expending custom hardware and algorithms to do it.
Dual_EC_DRBG doesn't count - that was a "jeezus, everyone asleep at
the wheel.  i bet we could get this approved!" moment.
triggering is active, observable (potentially), and usually
re-playable.  the only "delivered payloads", ala
EGOTISTICAL*/ERRONEOUS*, appear to be for confirmation pinging or
identification, and memory resident forensic/exfiltration run locally
on the host.  even the slides you link to note the OPSEC concerns of
"adversarial actors" (i think that's us on this list?)
sure.  note how this is also more complicated, with higher risk?  if
there was a better way i bet they'd choose it!
also, Intel and ARM, Apple and ARM, Apple and VIA, etc.
  you're not helping my pleading and cajoling for RDRAW sir.
on a related note, if Intel were to decide to include RDRAW in next
CPU line design, how long would it be to retail channels? >3yrs?

@_date: 2013-12-12 17:55:56
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
correction: persistence after reboot also has been stated to be
performed, though optional.  per Bruce's write up[0],
1. target identified (at endpoint or observable mid-point)
2. QUANTUM INSERT redirect to FoxAcid server
3. FoxAcid picks loader exploit according to: target value, exploit
value, target skill, other factors.
4. Loader exploit delivered to target
5. confirm success?  if no, abort.
6. With loader active, run two basic first pass payloads:
7. Collect configuration information (apps, registry, settings, etc.)
8. Collect location information
9. Escalate to persistent infection, run arbitrary other plugins, etc.
in any case, this is more consumer endpoint focused.  not applicable
to embedded VPN/HTTPS devices.
0. Bruce Schneier's attacking Tor article for the Guardian:

@_date: 2013-12-12 18:21:33
@_author: coderman 
@_subject: How long does it take to design and release a chip? 
using Sandy Bridge as a reference: 4 years design to demo, 1-2 years
demo to available.
design began 2005
demo'd in 2009
shipping in 2011

@_date: 2013-12-12 22:25:50
@_author: coderman 
@_subject: Multiple Plots by US, UK to Kidnap Edward Snowden 
ah FSB; you crack me up!
'''A senior officer of Russian counter-intelligence said: "Although
the Federal Security Bureau does not do anything about human rights
activist Snowden, the service has been active in counterintelligence.
I am pretty sure that kidnaping the former NSA employee will be
dramatically challenging." He also thanked "former NSA employees and
journalists for publishing such information...'''
Edward Snowden can be kidnapped from Russia?
10.12.2013 14:57
Edward Snowden, the whistleblower of NSA's total control systems can
be kidnapped from Russia. This is a priority for the British MI-6 and
the British Embassy, former NSA agent Wayne Madsen said, referring to
his colleagues.
Of course, nothing is known whether the CIA received the task, and
whether the U.S. Embassy is going to be involved in the activities to
try to kidnap Snowden. However, the British Embassy has already
tracked calls and letters of Snowden's "inner circle" and begun to
"dig up" their contacts in Moscow.
According to The Guardian, Snowden has the information, the disclosure
of which could become a nightmare for the U.S., even though the
fugitive NSA specialist decided not to disclose some of his data. In
addition, The Guardianadmitted that the media have so far published
"only 1%" of available information about NSA's total control over
billions of people in different countries.
Nevertheless, even this one percent has already made the UK
authorities introduce outright censorship against those who reveal
secrets of "global surveillance."
In particular, Wayne Madsen said that his girlfriend, who previously
worked for the National Security Agency as an expert on the Russian
language, tried to contact Snowden's acquaintances. Afterwards, she
was invited to come to the British Embassy and undergo special
training. She was also asked to report of FSB's interest in her
persons and communications.
The press quoted a former NSA expert, who said that the job to find
Snowden was of the highest priority for the embassy. Moreover, it was
said that the future operation to kidnap him involved number one MI-6
officer at the embassy, who worked under diplomatic cover as the
director for regional security.
The Center for the Study of Globalization has previously reported that
should the operation be successful, Snowden would be delivered to the
UK or the U.S. For the time being, the flywheel of total wiretapping
that Snowden launched was working against him to the utmost. "MI-6
intelligence agencies have begun to analyze the information they were
able to obtain through intelligence," the statement from the center
A senior officer of Russian counter-intelligence, whom Politonline.ru
confidentially managed to talk to, said: "Although the Federal
Security Bureau does not do anything about human rights activist
Snowden, the service has been active in counterintelligence. I am
pretty sure that kidnaping the former NSA employee will be
dramatically challenging." He also thanked "former NSA employees and
journalists for publishing such information, but added that
operational, technical and other measures to counter intelligence and
other illegal activities of foreign secret services on the territory
of Russia were  constantly maintained.
It only remains to add that the CIA has recently created a special
section in Russian on its official website, in which the department
offered Russian citizens (!) to join American intelligence. To choose
from, for example, the CIA offers engineering and technical
directions, a linguistic job, a secret agent with the knowledge of
Russian language and experts in business and analysts. The CIA
reportedly hopes to obtain classified information from newcomers in
the above areas to establish a new database of agents.

@_date: 2013-12-13 23:13:30
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
any details on "Mackerel: A Progressive School of Cryptographic
Thought" or "The Factoring Dead: Surviving the Cryptopocalypse" ?

@_date: 2013-12-14 04:33:31
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure as per the FreeBSD announcement[0] and others[1][2] direct use of
RDRAND as sole entropy source is not recommended.
from Westmere onward you could use AES-NI to make crypto fast in
OpenSSL.  a common theme is to initialize OpenSSL via
ENGINE_load_builtin_engines() which lets OpenSSL take advantage of
this acceleration.
with Sandy Bridge you also got RDRAND. now load_builtin_engines
results in the application using RDRAND directly for all entropy, in
addition to accelerating AES.
if you are using an application linked with openssl-1.0.1-beta1
through openssl-1.0.1e you should do one of the following:
a.) rebuild your OpenSSL with OPENSSL_NO_RDRAND defined.
b.) call RAND_set_rand_engine(NULL) after ENGINE_load_builtin_engines().
c.) git pull latest openssl with commit: "Don't use rdrand engine as
default unless explicitly requested." - Dr. Stephen Henson
the OPENSSL_NO_RDRAND option is recommended; an inadvertent call to
load engines elsewhere could re-enable this bad rng behavior.
best regards,
0. "FreeBSD Developer Summit: Security Working Group, /dev/random"
  1. "Surreptitiously Tampering with Computer Chips"
  2. "How does the NSA break SSL? ... Weak random number generators"

@_date: 2013-12-14 06:42:55
@_author: coderman 
@_subject: cognitive dissonance in threat modelling? 
i hope it was worth it for them!  'cause this is going to be expensive...
Matthew Green posted insights on how one might implement backdoors in chips:
  as well as the "Weak random number generators" attacks:
  regarding the unredaction automation: the typographic interpolation
trick discussed on the list, matching type face with justified spacing
with candidate word(s), is a really annoying idea and won't get out of
my head.
 (i tried to distract and forget with a Tor patch -
 - to no avail ;)
currently playing with scipy, skimage to:
- obtain from human initial document image
- obtain from human seed words / dictionary for matching
- misc. contrast / levels / etc conditioning for text optimized monochrome
- mask document image into text and non-text areas
- edge detect, align to horoz (for selections by x/y)
- broad region detect text rows into individual row images
- region detect individual chars per row image then assign char value via OCR
- insert human in loop to confirm / correct OCR row by row
- insert human to select redact line + redact area
- interpolate justified components: character spacing, word spacing, etc.
- iterate over known text with candidate fonts until best match.
- iterate over candidate words in best font until best match.
- success?  what confidence? (GOTO 10)
(the extra work for char by char and whole doc dis-assembly is in case
a "re-assemble scanned chars into candidate" rather than "match font
and re-produce text candidate" mode is needed.)
something better, Beuller?  ... Beuller?
... this won't be the last time i find this code useful!
current working set, including known wrong (please add suggestions :)
FeliCa and AMD
Nortel Networks
Apple and ARM
Array Networks
Cisco and Atmel
Philips and VIA
HiFn and Atmel
Cisco and ARM
Cisco and HiFn
Intel Ivy Bridge
Intel RDRAND
Atmel and IBM
Atmel and VIA
Apple and VIA
Intel and AMD
Intel and ARM
Forum Systems
VIA XSTORE
Cavium Nitrox
CAI Networks
A10 Networks
Cisco Systems
Citrix Systems
Sun SCA6000

@_date: 2013-12-14 08:40:34
@_author: coderman 
@_subject: [Full-disclosure] RDRAND used directly when default engines 
Full Disclosure On Sat, Dec 14, 2013 at 8:31 AM, Dennis E. Hamilton
i think the word you're looking for is "Feature".
... but you and me are not the customer.   ;)

@_date: 2013-12-14 09:25:49
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure this won't leave you vulnerable, but it will crash your app.  not
broken convention:
      /* If we are using a version of OpenSSL that supports native RDRAND
         make sure that we force disable its use as sole entropy source.
         See  */
      if (SSLeay() > OPENSSL_V_SERIES(1,0,0)) {
        t = ENGINE_get_default_RAND();
        if (t &&
            (strcmp(ENGINE_get_id(t), "rdrand") == 0)) {
          log_warn(LD_CRYPTO, "OpenSSL is using RDRAND by default."
                   " Attempting to force disable.");
          ENGINE_unregister_RAND(t);
          ENGINE_register_all_complete();
        }
      }
see best regards,

@_date: 2013-12-14 10:36:56
@_author: coderman 
@_subject: Fwd: Jacob impervious to "Rubber Hose Cryptanalysis" performed by 
this is pretty amusing :P
(and needs a "Knuth is my Homeboy" homage?)
Layers of the struggle privacy vs surveillance, in my picture of the year
This is the picture of the year for me, on so many different layers:
  [view the image directly via:
    ]
Stewart Baker, ex-NSA general counsel, and Jacob Appelbaum, internet
freedom activist/hacker/journalist (left, right).
They pretty much symbolise the two sides of the global scandal of the year.
They also symbolise the attitudes of both sides.

@_date: 2013-12-14 13:52:13
@_author: coderman 
@_subject: c4-r3kN.txt (urls) 
there are variations... i am afflicted with the contagious and acute
Entropus Major virus.  and now, any crypto system of which i am not
able to see the input randomness, by precision jitters or max rate
sampled freewheelers, or even that crazy faraday'ed up leadzone with
Geiger counter she told you about at BSides,
but hide that sweet sweet river of unrelated bits behind a bytecode
block??  that's just not cool!
until then, i've "borrowed" Peter G's d20's for a bit - hope he
doesn't need to roll them any time soon.
 ;P
i never considered prohibition as constraint on state of mind in public,
mainly thinking along monetary and covert economic activity angles.
but considering the public, and the multitudes of social scenes no
longer "lubricated" or under shadow of persecution, this would have a
direct and personal impact on many.
certainly a world removed from the producers and distribution
activity, which tends to monopolize the zeitgeist of the prohibition
crypto-compromise as frantic inferno is not quite right.,
the impact is almost invisible, until it is dire and potentially life-ruining.
global compromise for ever-present surveillance is crypto-HIV
 sure, you're fine now.  probably a while, no concerning symptoms.
then OMGWTFBBQ punctuated equilibrium, over-reaction,
suddenly crypto-AIDS just ate your life and shat out
 terminal-solitary-confinement and/or financial ruin.
plenty of company with all the other susceptible individuals, more than
you imaged...  equally destroyed by a silent corrupter too easy to ignore
they call it "Tailored Access" and "Computer Network Exploitation" for
... when they aren't having the FBI violating domestic providers in
their NSL hole.
it's legit.
on a more serious note, regarding the assumption:
 "if everything is backdoored already, essentially key escrow exists"
NSA has stated that many of their BULLRUN techniques are incredibly
fragile.  a number of them now burned in leaks, many yet to get
stuffed. if they "did it risky"[0], perhaps feeling emboldened by the
seeming success of Dual_EC_DRBG and friends, a common key / reduction
hidden behind AES-128 rounds could be discovered, independently
confirmed, and properly attributed.
so not only can the backdoors be broken up, replacements which are
resistant to compromise will take their stead.  "everything" becomes
"much" becomes "very little" until ideally such invasive tactics are
reserved for HUMINT tasked "good ol'e detective work" with legal
bonafides judged according to public laws and applicable to all
persons on earth, not just tribal deference pointed inward.
the jury is out; there are encouraging signs... but first, back to
those raw samples!!
best regards,
0. "Some thoughts on suborning encryption chips"
  A much easier approach is to simply eschew safety altogether and use a
fixed AES key that's common to all chips.
  [ED: or fixed modification to the AES-CBC-MAC compressor then masked
by the DRBG in front using "Stealthy Dopant-Level Hardware Trojans."]
But the NSA would never do something that risky. Right?

@_date: 2013-12-15 18:11:20
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
"Join us at Columbia Law School as renowned security expert Bruce
Schneier talks with Eben Moglen about what we can learn from the
Snowden documents, the NSA's efforts to weaken global cryptography,
and how we can keep our own free software tools from being subverted."

@_date: 2013-12-15 19:01:47
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
Peter's BlueHat talk on congitively flawed humans also excellent:
  so cypherpunks,  if you write code that you want to be useful:
don't write code with assumptions and admonishments inherently unheedable.
write code with awareness and compensation for silly human inclinations!

@_date: 2013-12-15 19:11:44
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
this also implies:
 "There is only one Mode, and it is Secure."

@_date: 2013-12-15 19:30:32
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
your understanding is flawed.  let me clarify:
the NSA does not currently break Tor on demand at the protocol level.
all indications are this is currently true.
the NSA and others have great success around Tor by opportunistically
watching users fuck up (see other usability thread), by pwning their
horribly insecure systems (0days as far as the eye can see..), and by
actively manipulating user paths to the Tor network or destination
"forget your global passive adversary threats, active denial and
manipulation of service attacks are _really_ scary!"
said another way, breaking Tor at protocol level is currently too
expensive a solution to the same ends provided by much cheaper means.

@_date: 2013-12-15 20:57:56
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
of course.  it's also expensive, relative to other options. i'm saying
NSA spends money carefully.
never said either thing.  i'm also long on the record advocating for
the next generation of low latency anonymous networking that _does_
provide strong defense against traffic analysis.  turns out the
details are, um..  complicated ;)
i'm glad that is not, in fact, my reasoning.
of course there are more sophisticated means available to them; that
will always be the case.  they've got BILLIONS and BILLIONS every
year, for their projects.
the point is not making something "NSA proof", which is an ill defined
and open ended venture.  the point is increasing the cost of their
efforts and narrowing their scope.
the more money they spend getting less and less in return, the better!

@_date: 2013-12-16 00:11:42
@_author: coderman 
@_subject: Aqua - a high bandwidth anonymity system that resists traffic analysis 
this seemed to get lost in the hubub over the summer,
Towards Efficient Traffic-analysis Resistant Anonymity Networks
Stevens LeBlond, David Choffnes, Wenxuan Zhou, Peter Druschel, Hitesh
Ballani, and Paul Francis
August 2013
Existing IP anonymity systems tend to sacrifice one of low latency,
high bandwidth, or resistance to traffic-analysis. High-latency
mix-nets like Mixminion batch messages to resist traffic-analysis at
the expense of low latency. Onion routing schemes like Tor deliver low
latency and high bandwidth, but are not designed to withstand traffic
analysis. Designs based on DC-nets or broadcast channels resist
traffic analysis and provide low latency, but are limited to low
bandwidth communication.
In this paper, we present the design, implementation, and evaluation
of Aqua, a high bandwidth anonymity system that resists traffic
analysis. We focus on providing strong anonymity for BitTorrent, and
evaluate the performance of Aqua using traces from hundreds of
thousands of actual Bit-Torrent users. We show that Aqua achieves
latency low enough for efficient bulk TCP flows, bandwidth sufficient
to carry BitTorrent traffic with reasonable efficiency, and resistance
to traffic analysis within anonymity sets of hundreds of clients. We
conclude that Aqua represents an interesting new point in the space of
anonymity network designs.

@_date: 2013-12-16 00:27:16
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
this is all coming to a few conclusions, where we simply disagree:
a) the black budget was leaked, along with other leaks about technical
capabilities and programs and priorities.  intelligence community is
not immune to government budget pressure.  you insist there is a
limitless expansion, and an unlimited technical ability.  i disagree.
b) you insist Tor's origins and funding sources are proof of
malfeasance; they've responded by diversifying funding. (not to
mention scrutiny of Tor by external, mututally un-trusting parties.
you can look at the code yourself, and interface with controller and
path construction yourself, etc.)
c) we both appear to agree that limiting solutions to technical realms
is missing the bigger picture.  yes to political reform that cuts
funding and restricts scope. yes to judicial reforms which demolish
secret orders and secret courts. yes to social measures which value
and reinforce privacy. yes to educational efforts which empower
individuals to make privacy positive decisions, etc.
last but not least, i second the call to fix it.  help write something better!

@_date: 2013-12-16 01:09:27
@_author: coderman 
@_subject: fallout of NSA induced difficulties (lots of drinking, 
this is what happens when large sums of money are secretly spent to
prevent the event of secure inter-net:
(NIST could simply be bought, but IETF had to be turned in on itself..)
"IETF PKIX meeting minutes from the 56th IETF"
We were somewhere in San Francisco on the edge of the 56th IETF when
the drugs began to take hold.  I remember saying something like "I
feel a bit
lightheaded; maybe you should take notes...."  And suddenly there was a
terrible roar all around us and the sky was full of what looked like huge
OIDs, all swooping and screeching and diving around the RFC, which was about a
hundred pages long.  And a voice was screaming: "Holy Jesus!  Where are these
goddamn business cases?"
Then it was quiet again.  My attorney had taken his shirt off and was pouring
beer into his mouth, to facilitate the PKI standards-creation process.  "What
the hell are you yelling about?" he muttered, staring up at the neon lights
with his eyes closed and covered with wraparound Spanish sunglasses.  "Never
mind," I said.  "It's your turn to figure out the interop requirements."  I hit
the brakes and dropped the Great Pile of Paperwork at the side of the room.
No point mentioning those OIDs, I thought.  The poor bastard will see them
soon enough.
We had two bags of X.509 standards, seventy-five pages of PKIX mailing list
printouts, five sheets of high-powered constraints, a saltshaker half-full of
vendor hype, and a whole galaxy of requirements, restrictions, promises,
threats...  Also, a quart of OSI, a quart of LDAP, a case of XML, a pint of
raw X.500, and two dozen PGPs.  Not that we needed all that for the trip, but
once you get into a serious PKI RFC binge, the tendency is to push it as far
as you can.  The only thing that really worried me was the X.500.  There is
nothing in the world more helpless and irresponsible and depraved than a man
in the depths of an X.500 binge, and I knew we'd get into that rotten stuff
pretty soon.

@_date: 2013-12-16 08:20:32
@_author: coderman 
@_subject: Wyden spends weeks preparing for questions to intelligence officials 
an interesting read on the state of things.
Wyden does Oregon proud,
[only excerpted, whole thing is huge. waiting for cryptome to mirror... ]
Wyden estimates that he gets about fifteen minutes a year to ask
questions of top intelligence officials at open hearings. With the
help of his intelligence staffer, John Dickas, a thirty-five-year-old
from Beaverton, Oregon, whom Wyden calls the hero of the
intelligence-reform movement, Wyden often spends weeks preparing his
questions. He and Dickas look for opportunities to interrogate
officials on the gaps between what they say in public and what they
say in classified briefings. At a technology conference in Nevada the
previous summer, General Keith Alexander, the director of the N.S.A.,
had said that the story that we have millions or hundreds of millions
of dossiers on people is absolutely false. Wyden told me recently,
It sure didnt sound like the world I heard about in private. For
months, he tried to get a clarification from the N.S.A. about exactly
what Alexander had meant. Now he had the opportunity to ask Clapper in
public. As a courtesy, he had sent him the question the day before.
Wyden leaned forward and read Alexanders comment. Then he asked,
What I wanted to see is if you could give me a yes or no answer to
the question Does the N.S.A. collect any type of data at all on
millions or hundreds of millions of Americans? 
Clapper slouched in his chair. He touched the fingertips of his right
hand to his forehead and made a fist with his left hand.
No, sir, he said. He gave a quick shake of his head and looked down
at the table.
It does not? Wyden asked, with exaggerated surprise.
Not wittingly, Clapper replied. He started scratching his forehead
and looked away from Wyden. There are cases where they could
inadvertently perhaps collect, but not wittingly.
Wyden told me, The answer was obviously misleading, false.

@_date: 2013-12-16 08:29:55
@_author: coderman 
@_subject: Bruce Schneier to leave BT 
retaliation for helping expose intelligence community excesses and illegalities?

@_date: 2013-12-16 19:27:34
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure updated list with env suggestion:
a.) rebuild your OpenSSL with OPENSSL_NO_RDRAND defined
b.) call ENGINE_unregister_RAND() on "rdrand" engine followed by
ENGINE_register_all_complete() to unregister rdrand as default
c.) set OPENSSL_ia32cap="~0x4000000000000000" in global environment
(this is poor fix)
d.) git pull latest openssl with commit: "Don't use rdrand engine as
default unless explicitly requested." - Dr. Stephen Henson
"what is affected??" - someone
sorry, i am not your distro maintainer.  but the list includes,
potentially (depending on configure opts / runtime / etc):
RHEL 6.5, 7.0
Centos 6.5
Fedora 18,19,rawhide
Ubuntu 12.04, 12.10, 13.04, 13.10, trusty
Debian 7.0, jessie, sid
Gentoo stable&unstable
Knoppix 7.0.5, 7.2.0
Kali 1.0.5
Slackware 14, 14.1, current
... if ssh built with --with-ssl-engine. these all use OpenSSL 1.0.1+.
 (remember both ssh client and server may use engines!)
and other libs, like:
... which appear to use OpenSSL default engines.
but really, you should go check your shit.
best regards,
P.S. if anyone is aware of RDRAND engine backports to OpenSSL 1.0.0*
or 0.9.8* in any distros i'd like to know about it!

@_date: 2013-12-16 19:30:50
@_author: coderman 
@_subject: Aqua - a high bandwidth anonymity system that resists traffic 
i had this same reaction when i found their Link Quality Source
Routing mesh protocol research[0].  crazy times! ;)
0. "Self Organizing Wireless Mesh Networks"

@_date: 2013-12-17 14:22:48
@_author: coderman 
@_subject: Tor funding [was: ranting at Juan's hatebait rapaciously [before 
discuss a post-Snowden Internet]]
even more today :)
Over the past year, we have received many requests for us to accept
bitcoin donations. After careful consideration and research, we are
thrilled to announce that effective today The Tor Project is accepting
bitcoin donations. In partnership with Bitpay, bitcoins can easily and
directly be donated to support Tors ongoing mission of being the
global resource for privacy technology advocacy, research and
education in the ongoing pursuit of freedom of speech, privacy rights
online, and censorship circumvention. Check out ourdonations page now.
Bitcoin donations received by The Tor Project will be converted
directly to US Dollars.
Our decision to accept bitcoins has been well thought out and
researched from a financial accounting perspective with an eye on
passing our required annual A-133 audit. We believe we are the first
US 501(c)3 non-profit organization to test acceptance of bitcoins and
attempt to pass the US Government A-133 Audit Standard. Our 2013 audit
results, along with our past financial documents, will be made
available on our website once complete in 2014.
The Tor Project is also proud to be in the company of other visible
non-profit organizations accepting bitcoins including EFF and
Why is this important? The Tor Project needs your donations to
continue our mission and to keep the Tor suite of technologies ahead
with the growing threats to privacy and anonymity around the world.
Your donation made TODAY, through bitcoin, Paypal, Amazon Payments,
Givv.org, checks, money orders or bank transfers, will provide greater
security and privacy for millions around the world who use Tor every
Help us continue our mission!

@_date: 2013-12-17 14:46:10
@_author: coderman 
@_subject: Tor funding [was: ranting at Juan's hatebait rapaciously [before 
Moglen discuss a post-Snowden Internet]]
sort of, but not really.  still waiting on  ...

@_date: 2013-12-18 08:29:14
@_author: coderman 
@_subject: acoustic side channel attacks against TEMPEST shielded equipment 
interesting work on using poor quality sound (like from a phone) for
chosen cipher text attacks with key recovery for GPG.
also note that they use frequencies >10kHz.  as discussed in the high
frequency audio covert channel, this range is fairly contention free
and easily accessible to microphones in consumer electronics of
various types.
Here, we describe a new acoustic cryptanalysis key extraction attack,
applicable to GnuPG's current implementation of RSA. The attack can
extract full 4096-bit RSA decryption keys from laptop computers (of
various models), within an hour, using the sound generated by the
computer during the decryption of some chosen ciphertexts. We
experimentally demonstrate that such attacks can be carried out, using
either a plain mobile phone placed next to the computer, or a more
sensitive microphone placed 4 meters away.
Beyond acoustics, we demonstrate that a similar low-bandwidth attack
can be performed by measuring the electric potential of a computer
chassis. A suitably-equipped attacker need merely touch the target
computer with his bare hand, or get the required leakage information
from the ground wires remote end of VGA, USB or Ethernet

@_date: 2013-12-20 04:32:33
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
Full Disclosure fortunately impacts are less than anticipated!
nickm devised most concise fix: RAND_set_rand_method(RAND_SSLeay());
 always after ENGINE_load_builtin_engines().
full write up is here including a BADRAND engine patch for testing:
  last but not least, notable omissions on NSA role in reqs for random
number sources in Appendix E: US Government Role in Current Encryption
  can we get a do-over?

@_date: 2013-12-20 17:41:36
@_author: coderman 
@_subject: NSA holiday talking points humor 
this is pretty amusing reading:
  "NSA does not and will not demand changes by any vendor to any
product, nor does it have any authority to demand such changes." - NSA
"We pay above market rates[0] to our corporate partners for embedded
vulns goddamnit!" - NSA Truth
0.  $10,000,000 to backdoor all of RSA's BSafe customers and cheer
lead Dual_EC_DRBG through approval it seems.
 let's not get into the standards bodies[1] yet, they're a little raw
right now :o
1. "Critics: NSA agent co-chairing key crypto standards body [IETF
CFRG] should be removed"

@_date: 2013-12-20 18:43:16
@_author: coderman 
@_subject: [cryptography] Vegetation Comsec 
Discussion of cryptography and related most stylishly done as 'the drummers':
  where he is taken in by a strange society known as The Drummers.
These people operate in underwater compounds located off the coasts of
major centers, perform rhythmic, hypnotic dances and engage in
ritualized sex. This act, we learn later, is actually for the sake of
information exchange, which is done through the transmission of
nanomachines contained within their bodily fluids.
 - more recently via vodka emission:
scientists used a desk fan and mist of alcohol to transmit evaporated
molecules that were translated into binary signals and decoded by a
breathalyzer device.
- [this technique can be generalized to any gaseous emission (or aqueous
when at sea?) with appropriate detector.]
and of course, chemical signalling is not magically immune to flaws;
ant mills (death spirals) one of many examples of signalling amiss.
and there are some interesting research papers on targeted genomic
viral strains which only "unlock" to a very specific genetic profile.
i don't have them handy...

@_date: 2013-12-21 17:05:34
@_author: coderman 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
the leaks have sharpened my appetite for names and numbers.
collaborators in mass product perversion need to be named;
the extent of filthy lucre lures employed delineated; today!

@_date: 2013-12-21 17:19:09
@_author: coderman 
@_subject: public notice: TLA scrutiny an opportunity for catching capabilities 
if you're under scrutiny[0] no better time to test than today :)
- collect sequences, collect imagery, collect signals, collect
collaborators, collect everything! (you'll find data later you didn't
recognize as relevant)
- honey tokens to trigger channel targets, see which takes.
- selective channels of dis-information to quantify compromise.
- observe counter-reaction, counter counter-counter-measures,
- continually iterate process until truce or truncheon-ed...
caution: this can lead to escalation!
0. "Snowden ally Appelbaum claims his Berlin apartment was invaded"
  Berlin resident and US national Jacob Appelbaum told Saturday's
edition of the "Berliner Zeitung" daily that he believed he was under
surveillance in the German capital. Appelbaum told the paper that
somebody had broken into his apartment and used his computer in his
"When I flew away for an appointment, I installed four alarm systems
in my apartment," Appelbaum told the paper after discussing other
situations which he said made him feel uneasy. "When I returned, three
of them had been turned off. The fourth, however, had registered that
somebody was in my flat - although I'm the only one with a key. And
some of my effects, whose positions I carefully note, were indeed
askew. My computers had been turned on and off."

@_date: 2013-12-21 17:32:43
@_author: coderman 
@_subject: public notice: TLA scrutiny an opportunity for catching 
this assumes they're trying to be sneaky and surreptitious, of course.
sometimes an entry is about show of force rather than collection.  US
residence some years ago forcibly entered, surveillance system HERF'd,
dog placed in backyard, entire domicile imaged with all drawers,
cabinets, closets, cupboards, everything opened (and more :) in space
of 15 minute trip to store and back.
in any case, this is only effective if you're actually intimidated.
best to make it yet another egregious waste of public funding instead!

@_date: 2013-12-21 17:41:04
@_author: coderman 
@_subject: for those going to 30C3: Fwd: USB Sticks for TAILS [and OpenPGPv2 
The sticks [1] have arrived, you will be able to buy them for roughly
$15 at Chaos Communication Congress. Maybe I can drop off some of them
at the table of Wau Holland Foundation or elsewhere. Best you come find
me, for example at the Tor Relay meetup [2].
I ended up buying *200* sticks, 100 of each type and color. I will post
a detailed bill and pictures next year.
I will also bring OpenPGPv2 smartcards [3] and Gemalto USB tokens [4]
that you can buy from me, and some Yubikeys. [5]
[1] [2] [3] [4] [5] Moritz Bartl

@_date: 2013-12-21 19:43:06
@_author: coderman 
@_subject: FYI 
these people really hate Tor; they spelled it "the TOR Project"... on purpose.
  dicks!
on a related note, interpreting this document is an excellent exercise
in focusing on what is _not_ said, both in terms of qualifiers and
entire subjects/categories of omission.
oh that one might maintain a retrospective mapping from ongoing
Snowden leaks to misdirected / omitted / understated assertions and
recommendations in this Grade A Toothless Attention Distractor (aka,
"Report and Recommendations of The Presidents Review Group on
Intelligence and Communications Technologies")

@_date: 2013-12-21 20:00:38
@_author: coderman 
@_subject: FYI 
you say this like it's different from anything else you might request *grin*
indeed.  though this does bring up another question:
 i wonder if JYA will ever give in and support httpS?
... it would at least avoid trivial plaintext observation.
last but not least:
opsec tip you should assume everything remote and
retrieved is malicious.  grab in a throw away Qubes browser. convert
in a throw away parse and translate VM, then finally read and/or save
to a limited view VM using an open, trusted format.

@_date: 2013-12-22 13:38:57
@_author: coderman 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
another reason to love certificate transparency, convergence, pinning, etc...
  (yes John, httpS may be pwned, but it still flips pcap parser the bird! ;)

@_date: 2013-12-22 13:50:59
@_author: coderman 
@_subject: ECDHE-RSA-CHACHA20-POLY1305-SHA256 server side support in OpenSSL / 
Discussion of cryptography and related poked around some patches for chacha20 and poly1305 suites in
OpenSSL... there's more work to be done it seems.
is there a working setup for Linux server side chacha20 poly1305
suites with OpenSSL?  (i am probably not looking in the right place;
e.g. aead_support.patch, aead_ssl_support.patch,
best regards,

@_date: 2013-12-22 17:01:41
@_author: coderman 
@_subject: Exclusive: Secret contract tied NSA and security industry pioneer 
they've done the research. they're in good company!

@_date: 2013-12-22 17:11:29
@_author: coderman 
@_subject: private sector privacy enhancing technology transition for 
if DEA finds meaningful work in legal marijuana[0], will IC community
find meaningful work red teaming and supporting privacy enhancing
technologies and usable open source crypto?
knowing how to break things useful in building systems that are harder
to break...
0. "DEA agents finding greener jobs in lucrative legal marijuana industry"

@_date: 2013-12-28 07:00:08
@_author: coderman 
@_subject: P2P VPN 
i love the concept of L2 VPNs; so pure in theory.
(AppleTalk and IPX over WAN? no problem!)
in practice they need a lot of careful implementation and
configuration.  the attack surface for tap vs. tun is very different;
many services handling broadcast traffic assume a trusted local
network environment.
all of the security features listed on the wiki are related to
transport / authentication rather than endpoint service
considerations.  this should be remedied.
looks interesting! perhaps i can play around with it soon...
best regards,

@_date: 2013-12-28 07:14:47
@_author: coderman 
@_subject: Boycott the RSA Conference - List of Honor 
Josh Thomas also bowing out:
is anyone keeping track? i'm curious...

@_date: 2013-12-29 02:19:23
@_author: coderman 
@_subject: 30c3: The Year in Crypto default engines loaded in openssl-1.x 
cpunks in 30c3: The Year in Crypto
 with djb, Nadia Heninger, Tanja Lange
at ~28min discussion of RDRAND,
 Intel's pass the buck to NIST no-comment,
  (after initial "just trust us, we looked at a lab sample close"
didn't fly far enough...)
alt slides: hyperelliptic.org/tanja/vortraege/talk-30C3.pdf
also, Tor 0.2.4.20 (Mon Dec 23 07:21:35 UTC 2013)
 updates to avoid direct RDRAND use in specific circumstances:
   per previous discussion on OpenSSL use of RDRAND directly when engines on.[0]
  TL; DR - very rare case you may want to re-gen relay and hidden service keys
 now,,
you may wonder if IETF could apply resistance to NSA seducing of NIST,
 but you'd be stepping into a quagmire  :P
     [specifically, all of Dan Harkins "appeals for legitimacy" bear
striking resemblance to other demonstratively failed approaches to
failure by default designs. Dragonfly is not sufficiently justified.
insert pleas to appeal to decency and step away from CFRG and IETF
authority roles for propriety sake, regardless of any reasonable
claims or other implications best exemplified by RSA[1]]
 also,,
SIMON and SPECK is lulz; no really: fuck those guys!
 and remember that AES GCM is a choice between:
  - user-land side channels galore  /or/
  - hardware instruction back-door
2013 was indeed a year for crypto
  let's not do this again soon?
best regards,
0. "BADRAND and testing OpenSSL engines enabled behavior with direct
RDRAND engine"
 BADRAND lets you link a test version of your application or library
against OpenSSL 1.0.1e that uses a specific sequence of deterministic
"random numbers" in OpenSSL. e.g. standard C lib function rand()
seeded at zero replacing RDRAND. the debug logging to stderr can
identify bad fork() assumptions.
1. Dual-EC-DRBG is bad and RSA should feel bad. No excuses.
  IETF standards not a good reference for "formal proof" level thoroughness,
  and highly deployed does not mean highly used nor scrutinized (WEP,
LEAP, OpenSSL's Dual_EC_DRBG implementation, [the set is large])
X. "see that one top post ..."  [was: RDRAND used directly when...

@_date: 2013-12-29 10:43:46
@_author: coderman 
@_subject: automated crash reporting XKeyscore hooks 
seems automated processes are a great XKeyscore source:
"in practical terms, the NSA's agents... enjoy it because it allows
them [a "neat way" to gain "passive access" to a machine] ... In one
internal graphic, they replaced the text of Microsoft's original error
message with one of their own reading, "This information may be
intercepted by a foreign sigint system to gather detailed information
and better exploit your machine."
Inside TAO
Documents Reveal Top NSA Hacking Unit
By SPIEGEL Staff
The NSA's TAO hacking unit is considered to be the intelligence
agency's top secret weapon. It maintains its own covert network,
infiltrates computers around the world and even intercepts shipping
deliveries to plant back doors in electronics ordered by those it is
In January 2010, numerous homeowners in San Antonio, Texas, stood
baffled in front of their closed garage doors. They wanted to drive to
work or head off to do their grocery shopping, but their garage door
openers had gone dead, leaving them stranded. No matter how many times
they pressed the buttons, the doors didn't budge. The problem
primarily affected residents in the western part of the city, around
Military Drive and the interstate highway known as Loop 410.
In the United States, a country of cars and commuters, the mysterious
garage door problem quickly became an issue for local politicians.
Ultimately, the municipal government solved the riddle. Fault for the
error lay with the United States' foreign intelligence service, the
National Security Agency, which has offices in San Antonio. Officials
at the agency were forced to admit that one of the NSA's radio
antennas was broadcasting at the same frequency as the garage door
openers. Embarrassed officials at the intelligence agency promised to
resolve the issue as quickly as possible, and soon the doors began
opening again.
It was thanks to the garage door opener episode that Texans learned
just how far the NSA's work had encroached upon their daily lives. For
quite some time now, the intelligence agency has maintained a branch
with around 2,000 employees at Lackland Air Force Base, also in San
Antonio. In 2005, the agency took over a former Sony computer chip
plant in the western part of the city. A brisk pace of construction
commenced inside this enormous compound. The acquisition of the former
chip factory at Sony Place was part of a massive expansion the agency
began after the events of Sept. 11, 2001.
On-Call Digital Plumbers
One of the two main buildings at the former plant has since housed a
sophisticated NSA unit, one that has benefited the most from this
expansion and has grown the fastest in recent years -- the Office of
Tailored Access Operations, or TAO. This is the NSA's top operative
unit -- something like a squad of plumbers that can be called in when
normal access to a target is blocked.
According to internal NSA documents viewed by SPIEGEL, these on-call
digital plumbers are involved in many sensitive operations conducted
by American intelligence agencies. TAO's area of operations ranges
from counterterrorism to cyber attacks to traditional espionage. The
documents reveal just how diversified the tools at TAO's disposal have
become -- and also how it exploits the technical weaknesses of the IT
industry, from Microsoft to Cisco and Huawei, to carry out its
discreet and efficient attacks.
The unit is "akin to the wunderkind of the US intelligence community,"
says Matthew Aid, a historian who specializes in the history of the
NSA. "Getting the ungettable" is the NSA's own description of its
duties. "It is not about the quantity produced but the quality of
intelligence that is important," one former TAO chief wrote,
describing her work in a document. The paper seen by SPIEGEL quotes
the former unit head stating that TAO has contributed "some of the
most significant intelligence our country has ever seen." The unit, it
goes on, has "access to our very hardest targets."
A Unit Born of the Internet
Defining the future of her unit at the time, she wrote that TAO "needs
to continue to grow and must lay the foundation for integrated
Computer Network Operations," and that it must "support Computer
Network Attacks as an integrated part of military operations." To
succeed in this, she wrote, TAO would have to acquire "pervasive,
persistent access on the global network." An internal description of
TAO's responsibilities makes clear that aggressive attacks are an
explicit part of the unit's tasks. In other words, the NSA's hackers
have been given a government mandate for their work. During the middle
part of the last decade, the special unit succeeded in gaining access
to 258 targets in 89 countries -- nearly everywhere in the world. In
2010, it conducted 279 operations worldwide.
Indeed, TAO specialists have directly accessed the protected networks
of democratically elected leaders of countries. They infiltrated
networks of European telecommunications companies and gained access to
and read mails sent over Blackberry's BES email servers, which until
then were believed to be securely encrypted. Achieving this last goal
required a "sustained TAO operation," one document states.
This TAO unit is born of the Internet -- created in 1997, a time when
not even 2 percent of the world's population had Internet access and
no one had yet thought of Facebook, YouTube or Twitter. From the time
the first TAO employees moved into offices at NSA headquarters in Fort
Meade, Maryland, the unit was housed in a separate wing, set apart
from the rest of the agency. Their task was clear from the beginning

@_date: 2013-12-30 05:03:19
@_author: coderman 
@_subject: 30c3: To Protect And Infect, Part 2 
so much asking for names, details, conspirators.
so many months and months of nearly zero satisfaction.
... until:
kudos Jake for delivering; specifically. :)
"[QI vector] 30c3: To Protect And Infect, Part 2"
you can argue some subset of these attacks are exercised in a targeted
manner, however, this does nothing to prevent collateral damage to
domestic and global individuals, indiscriminately.
fuck these guys![0]
best regards,
0. fuck you, at least in so far as your offensive efforts to undermine
privacy and liberty in the name of route tasking without restraint.
 to those who go privacy tech repurpose, i will sing your praises and
support your efforts!

@_date: 2013-12-30 07:21:26
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
out of time, barest gist til next year: back when doing wifi security
research and other interests [trunc.] received an FBI black bag job;
presumably physical focus due to non standard OSes and FDE.  IBM
keyboard internal chip replaced with identical logging variant; note
that this is not as sophisticated as the more recent TAO toys with
covert RF channels and active, on-demand capabilities...
the keyboard tampering:
 which is for all intents and purposes otherwise visually undetectable
using this trojan chip technique, tailored for every common
while that was not bad, aside from leaking tamper event, the FDE was
so sad/funny. a screw amuck, replacement drive significantly different
(when compared to identical lot mate purchased with original that got
yanked for offline attack)
in a round about manner this was all instigated in part by wifi
research done at the time which put various powerful entities into a
tiff.  here's what the pacNW sample looked like back in early 2003:
"Cleartext Nodes: 8755 (62.59%)
  , WEP Nodes: 5232 (37.40%)"
 ... ah, memories :)
one last fun learning by example: consider that you thwart direct
physical access black bag type attempts, and are not running a
vulnerable router/CPE, and present a sufficiently compelling target,
you may encounter a clever "just outside the property line" isolation
and active attack on DOCSIS uplink. (a broadcast medium is hard to
mess with in a covert manner, unless you're able to isolate target
from the local broadcast loop itself.)
(circa 2007 - make note of image comments and also single "Comcast
tech" shielding self behind door...)

@_date: 2013-12-30 07:38:41
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
tamper evidence combined with secondary reference copies to compare
(buy two in cash on demand rather than shipped, use second as fallback
(vastly more frequent scenario) or as reference with sketch kit (what
did you did? ;)
this leads to the question i intended but omitted in prev:
to date most FBI/NSA/IC keyloggers have been visually obtuse dongle
type, varied software type, particularly for Windows, Mac, and Dos at
this point in the past.  the top class (effectively undetectable?)
hardware keyloggers appear to have avoided detailed disclosure.
is anyone aware of leaked hardware keylogger specs or ops in the veign
of magic lantern / CIPAV / Carnivore / DCS* category applied to covert
hardware based compromises?

@_date: 2013-12-30 07:43:21
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
COTTONMOUTH is informative; but generally USB based and visible via
spectrum when actively exfilling.
specifically hardware attacks on PS/2 / XT style keyboards.

@_date: 2013-12-30 22:06:25
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
hey Jim, (and Jake)
neither one of you appear to have a *coin tipjar yet...
why holding out? :)
best regards,

@_date: 2013-12-30 22:19:21
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
you're assuming this dump is exhaustive.  this is a very specifically
themed/focused release of top end tactics and exploits (essentially
weaponized platforms for targeted attacks). Jake says as much about
what they're dropping, which while impressive, has still gone through
the "best interest of public safety scrutinizing and censorship"
the indiscriminate, wholesale compromises are just getting started...
these disclosures will have more impact: financially to the impacted
vendors, effectively to IC as known vulnerable hardware and software
is replaced, and to the public at large now exposed to even more
essentially incomprehensible disclosures of vulnerability and
this is just an example of how, when the NSA pursues "all means and
methods in parallel, without restraint" seemingly innocuous oversights
are intentionally leveraged and discouraged from remediation for use
in tailored access (black bag / targeted) attacks.
it is worse.
best regards,
p.s. cryptome has lots of great docs on this and other 30C3 awesomeness:
   ,

@_date: 2013-12-30 23:21:14
@_author: coderman 
@_subject: Replacing corporate search engines with anonymous/decentralized 
decentralized search (not just not-corporate search) persists as one
of the great
practical challenges in peer to peer networking.
i have more to say later, but one effort from back in early 2000 is alpine:
   inside the 2004 snapshot there is also docs and implementation of
feedbackfs which is used to gather implicit feedback on recommendation
alpine is explicitly highly connected, flatter than not network
topology to improve robustness in the face of failure and active
attacks, and to avoid limitations inherent in many connection oriented
operating system facilities/sockets.
i am not quite an impartial party ;)
 but other approaches which are not a feasible replacement include:
 - the old skewl (mostly)flooding broadcasts like gnutella
 - fragile, hard to defend constructs like DHTs as keyword indexes
 - aggressive caching with local search (110% useful, but not sufficient alone)
 - distributed (but better somehow) search engines on darknets, etc.
these are more about search privacy or deep search more than
decentralized search.
the longer discussion is how to make decentralized search useful.
"Google style" search has a terrific performance advantage over
decentralized designs by brute force.
however, take advantage of massive endpoint / peer processing and
resources combined with implicit observational metrics for reputation
and recommendation, inside a well integrated framework for resource
discovery in usable software, and you have something more robust and
more effective than "Google style" could ever provide.
this is quite the trick, however!  despite an inter-operable component
model interface, and dynamic runtime module support to extend
discovery and wire protocol extensions, and other intentional efforts
at encouraging adoption and integration, alpine failed to bootstrap.
(i did many things wrong, but those things i did at least make
conscious effort to do right.  did i mention this is a hard problem?
this project has been excavated from archives, and will receive
maintenance upgrades[0] at minimum and significant improvement a
possible option, depending.
best regards,
[0] maintenance work for testable alpine builds
 - fix/improve g++ usage.
 - add IPv6 support. (specifically ORCHID addrs for darknet search)
 - update feedbackfs to latest fusefs bindings
 - update inotify bindings in feedbackfs
 - multiple-socket support, multi-addr discovery

@_date: 2013-12-30 23:27:53
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
its a way to convert digital shared hallucinations into fiat
denominated shared hallucinations.
for an example exchange in BTC network:
  you can generate your own wallet and use your own client directly in
network, or use a managed wallet service, or a conversion service that
immediately converts into $USD denominated deposits in a bank account,
or exchange for physical token representations of the coin/funds, etc.
 is probably the most accessible place to start,
 and github where the good forks are if you're in the ready to hack camp.
if you setup a wallet and tell me the address, i can donate coins for
you to experiment with.
best regards,

@_date: 2013-12-31 00:51:27
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
i'll let you cypherpunks in on a secret financial tip:
  the smart money banks in dogecoin:

@_date: 2013-12-31 02:47:45
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
sha256 579c3059e24b2d65f324053b0fed550a9d1d4fb2504a1a272940a26697ed8a33
(where else is the above mirrored? i had links, they're no longer good...)
best regards,

@_date: 2013-12-31 03:08:12
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
this makes sense, and leads to a question; see below.
so far we've seen 0.5%[0] of confirmations of general and nearly
insurmountable vulnerability against a state level actor, ... let's
see what 2014 has in store! :)
the question:
 do you believe the counter-surveillance was a factor in the extreme
measures used in your prosecution?
AP seemed the most controversial and outwardly demonised aspect of the
whole debacle, but perhaps i am giving too much weight to AP.
the judge sealing the entire court file raises questions, but i also
admit knowing little about the particulars of the facts and legal
motions of the case.
best regards,
0.  snowden leaks, ~1.6% to ~.40% released
     see also, tailored access megapwnage:

@_date: 2013-12-31 19:00:10
@_author: coderman 
@_subject: Replacing corporate search engines with anonymous/decentralized 
what you want more than traditional search is resource discovery,
which includes recommendation and per-peer-perspective reputation.
this is an area where centralized search is incapable or untrustworthy
enough compared to fully decentralized options.
done centrally, that central trusted party would be privy to all your
inter-peer interactions.  in decentralized fashion this exposes only
limited information to each peer.  (central services usually paying
the cost of the infrastructure to analyze all to all interactions by
selling your private information to third parties, or delegating to
those who do...)
public web is a small slice of all that is of interest.  just put a
internet archive.org copy on a hidden Tahoe-LAFS and everyone gets a
copy of the public web for local querying. (better yet, make a PIR
LAFS ;)
... this would need a little coding *grin*

@_date: 2013-12-31 19:08:10
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
agreed.  we've got some years to wait for a definitive full picture.
  - 932 pages (~1.6%) of
reported 58,000. NSA head claims 200,000 (~.40% of that released)
vendor responses are fairly self evident.
bad: RSA
less-bad: Cisco
good/proactive: SilentCircle
etc,...   we could get into details of what makes a good vendor
response vs. one that is clearly weasel worded accountability
deflection, don't think this list is the place however.
then you're not paying attention :)
corporate media sucks to more or less degree; i feel bad for anyone
who touches it.
glad it's not my problem!
best regards,

@_date: 2013-12-31 23:04:19
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
are you only considering this 30C3/catalog set of docs?
venally complicit to conveniently compromised to blissfully ignorant
compromise of hardware vendors goes back to CryptoAG and as recently
as the BULLRUN leaks.  a bit too long and complicated a thread for
this list, i think...
sure, just another example of in scope target for a "compromise all
the things" approach.
my point was to highlight their response as particularly deceptive and
inexcusable when observing how the various parties not only respond,
but act, in response to these leaks. (e.g. Google deploying crypto
over their internal fibers is positive action.  sitting silent or
deflecting criticism not confidence inspiring...)
best regards,

@_date: 2013-12-02 00:11:10
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
this, in the traditional sense, is what John calls a "COMSEC cover-up":
 meaning that the continual, most significant, and most likely to be
abused and widely are commercial services and collaborations and
  where the product is your private information of any sort, that you
usually unwittingly but sometimes capriciously yield to un trustworthy
third parties with little constraint on secondary distribution for
money to further removed stranger parties...
note that fully decentralized, end-to-end secured, with properly
managed keying and sessions capable technologies are resistant to
these third-party weaknesses and vulnerabilities.
crypto and comms and computing technology should not be abandoned en
whole like the russians for their manual type writers, but the minimum
required operational safety of any information processing system needs
huge innovation to get from current systems to something effective and
usable...  hey look, it's more of those fun problems to solve again ;)
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:10
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
regarding the inability for NSA employees to report ethical violations
in a manner that did not assure retribution:
this is actually a somewhat difficult anonymity / privacy question in
the context of highly compartmented information and operations, where
knowledge of a subset of specific details is sufficient to imply
strong suspicion and scrutiny to a very small number of individuals...
... assuming you don't circumvent the apparently mediocre constraints
to this information in the information systems that contain it. ;)
while academically interesting, in all practical terms we should
render this question moot and provide absolute communication
origin[0], destination[1], and content[2] privacy to all network users
in all locations under all circumstances guaranteed by constitutional
law, prosecutorial discretion, and practical realities (read:
implementations resistant to Tailored Access Operations like efforts
(NSA TAO / CNE related programs)
this latter guarantee will require a bit more design, coding and deployment,
 fun problems to solve![3]
1.  "peer communication endpoint privacy" - this is a hard problem.
the existing implementations are not usable and insufficiently large
in anonymity set (too few users): zero knowledge high latency mail
like messaging mixes, even if the twitter mixes are pretty cool.
a proper solution would be datagram based, NAT busting, low latency
(read: sufficiently real-time for video and voice), the majority
protocol across the Internet and local intranets and ad-hoc mesh nets
and other networks,
in an implementation that resists all known general purpose (wide
scale) and specialized (highly targeted and/or weaponized bleeding
edge and/or privileged positioned) attacks.
2. strong encryption like: alligator wrapped forward secrecy intended
streams, and equivalent techniques, solve this problem.
  clearly there is much work to do in the implementation and protocol
side of crypto integrity.  very, very much work...
3. "NSA TAO / CNE related programs" resistance is a very tall bar.
they rolled this out at DEF CON, of course. the soon departing .gov
Alexander rolled into town with some world class shit, no doubt...  is
it really going to be 33 years before we can talk about it?  for
better or for worse we won't have Snowden to disclose this
( as he's too classy
to drop dox on specific field operations and highly technical method
and tools information. hmmm...
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:11
@_author: coderman 
@_subject: [Full-disclosure] Intelligence agency subversions and clandestine, 
if you're not mad as hell about PRISM, UPSTREAM, BULLRUN, FLYING PIG,
XKEYSCORE, FOXACID, EgotisticalGiraffe, QUICKANT, QuantunInsert,
FRUGAL SHOT, MOTHMONSTER, MULLENIZE, ERRORONEOUSINGENUITY,
FINKDIFFERENT, GREATEXPECTATIONS, VALIDATOR, RAKE, PEDDLE,
PACKETCHEAP, BEACH HEAD, FERRET CANON, PINWALE, MARINA, TRAFFICTHIEF,
REMATION, LACONIC, ENDUE, MANASSAS, DANCINGOASIS, SPINNERET,
MOONLIGHTPATH, ...
 and all the other myriad "exceptionally controlled information",
 then you're beyond reason and redemption...
 ... let's not take a show of hands
 ;P
P.S. the new cypherpunks list has dropped the cypherpunks at al-qaeda.net
for a more benign and powers that be submissive cypherpunks at cpunks.org
 ... perhaps it does get past a few more filters? ...
--- fwd:
it doesn't get much more definitive than this retort.. :
[Snowden] felt confident that he had kept the documents secure from
Chinese spies, and that the N.S.A. knew he had done so. His last
target while working as an agency contractor was China...
adding that he had had "access to every target, every active
operation mounted by the N.S.A. against the Chinese. Full lists of
them," he said.
"If that was compromised," he went on, "N.S.A. would have set the
table on fire from slamming it so many times in denouncing the damage
it had caused. Yet N.S.A. has not offered a single example of damage
from the leaks. They haven't said boo about it except "we think,"
"maybe", "have to assume" from anonymous and former officials. Not
"China is going dark." Not "the Chinese military has shut us out."
there is a clear thoughtfulness, moral reasoning, and
conscientiousness repeatedly demonstrated by Snowden in these events.
it is now obvious that history will exonerate him fully.
... the distance between current reactionary retribution and that
future absolution appears to be a bit of a distance, however...
hopefully not too long.
October 17, 2013
Snowden Says He Took No Secret Files to Russia
By JAMES RISEN
WASHINGTON - Edward J. Snowden, the former National Security Agency
contractor, said in an extensive interview this month that he did not
take any secret N.S.A. documents with him to Russia when he fled there
in June, assuring that Russian intelligence officials could not get
access to them.
Mr. Snowden said he gave all of the classified documents he had
obtained to journalists he met in Hong Kong, before flying to Moscow,
and did not keep any copies for himself. He did not take the files to
Russia because it wouldn't serve the public interest," he said.
"What would be the unique value of personally carrying another copy of
the materials onward?" he added.
He also asserted that he was able to protect the documents from
China's spies because he was familiar with that nation's intelligence
abilities, saying that as an N.S.A. contractor he had targeted Chinese
operations and had taught a course on Chinese
"There's a zero percent chance the Russians or Chinese have received
any documents," he said.
American intelligence officials have expressed grave concern that the
files might have fallen into the hands of foreign intelligence
services, but Mr. Snowden said he believed that the N.S.A. knew he had
not cooperated with the Russians or the Chinese. He said he was
publicly revealing that he no longer had any agency documents to
explain why he was confident that Russia had not gained access to
them. He had been reluctant to disclose that information previously,
he said, for fear of exposing the journalists to greater scrutiny.
In a wide-ranging interview over several days in the last week, Mr.
Snowden offered detailed responses to accusations that have been
leveled against him by American officials and other critics, provided
new insights into why he became disillusioned with the N.S.A. and
decided to disclose the documents, and talked about the international
debate over surveillance that resulted from the revelations. The
interview took place through encrypted online communications.
Mr. Snowden, 30, has been praised by privacy advocates and assailed by
government officials as a traitor who has caused irreparable harm, and
he is facing charges under the Espionage Act for leaking the N.S.A.
documents to the news media. In the interview, he said he believed he
was a whistle-blower who was acting in the nation's best interests by
revealing information about the N.S.A.s surveillance dragnet and huge
collections of communications data, including that of Americans.
He argued that he had helped American national security by prompting a
badly needed public debate about the scope of the intelligence effort.
The secret continuance of these programs represents a far greater
danger than their disclosure," he said. He added that he had been more
concerned that Americans had not been told about the N.S.A.s reach
than he was about any specific surveillance operation.
So long as there's broad support amongst a people, it can be argued
there's a level of legitimacy even to the most invasive and morally
wrong program, as it was an informed and willing decision," he said.
However, programs that are implemented in secret, out of public
oversight, lack that legitimacy, and that's a problem. It also
represents a dangerous normalization of governing in the dark, where
decisions with enormous public impact occur without any public input.
Mr. Snowden said he had never considered defecting while in Hong Kong,
nor in Russia, where he has been permitted to stay for one year. He
said he felt confident that he had kept the documents secure from
Chinese spies, and that the N.S.A. knew he had done so. His last
target while working as an agency contractor was China, he said,
adding that he had had access to every target, every active
operation mounted by the N.S.A. against the Chinese. Full lists of
them, he said.
If that was compromised, he went on, N.S.A. would have set the
table on fire from slamming it so many times in denouncing the damage
it had caused. Yet N.S.A. has not offered a single example of damage
from the leaks. They havent said boo about it except we think,
maybe, have to assume from anonymous and former officials. Not
China is going dark. Not the Chinese military has shut us out.
An N.S.A. spokeswoman did not respond Thursday to a request for
comment on Mr. Snowden's assertions.
Mr. Snowden said his decision to leak N.S.A. documents developed
gradually, dating back at least to his time working as a technician in
the Geneva station of the C.I.A. His experiences there, Mr. Snowden
said, fed his doubts about the intelligence community, while also
convincing him that working through the chain of command would only
lead to retribution.
He disputed an account in The New York Times last week reporting that
a derogatory comment placed in his personnel evaluation while he was
in Geneva was a result of suspicions that he was trying to break in to
classified files to which he was not authorized to have access. (The
C.I.A. later took issue with the description of why he had been
reprimanded.) Mr. Snowden said the comment was placed in his file by a
senior manager seeking to punish him for trying to warn the C.I.A.
about a computer vulnerability.
Mr. Snowden said that in 2008 and 2009, he was working in Geneva as a
telecommunications information systems officer, handling everything
from information technology and computer networks to maintenance of
the heating and air-conditioning systems. He began pushing for a
promotion, but got into what he termed a petty e-mail spat in which
he questioned a senior manager's judgment.
Several months later, Mr. Snowden said, he was writing his annual
self-evaluation when he discovered flaws in the software of the
C.I.A.s personnel Web applications that would make them vulnerable to
hacking. He warned his supervisor, he said, but his boss advised him
to drop the matter and not rock the boat. After a technical team also
brushed him off, he said, his boss finally agreed to allow him to test
the system to prove that it was flawed.
He did so by adding some code and text in a nonmalicious manner=94 to
his evaluation document that showed that the vulnerability existed, he
said. His immediate supervisor signed off on it and sent it through
the system, but a more senior manager the man Mr. Snowden had
challenged earlier was furious and filed a critical comment in Mr.
Snowden's personnel file, he said.
He said he had considered filing a complaint with the C.I.A.=92s
inspector general about what he considered to be a reprisal, adding
that he could not recall whether he had done so or a supervisor had
talked him out of it. A C.I.A. spokesman declined to comment on Mr.
Snowden's account of the episode or whether he had filed a complaint.
But the incident, Mr. Snowden said, convinced him that trying to work
through the system would only lead to punishment. He said he knew of
others who suffered reprisals for what they had exposed, including
Thomas A. Drake, who was prosecuted for disclosing N.S.A. contracting
abuses to The Baltimore Sun. (He met with Mr. Snowden in Moscow last
week to present an award to him for his actions.) And he knew other
N.S.A. employees who had gotten into trouble for embarrassing a senior
official in an e-mail chain that included a line, referring to the
Chinese Army, that said, Is this the P.L.A. or the N.S.A.?
Mr. Snowden added that inside the spy agency theres a lot of dissent
 palpable with some, even. But he said that people were kept in line
through fear and a false image of patriotism, which he described as
obedience to authority.
He said he believed that if he tried to question the N.S.A.s
surveillance operations as an insider, his efforts would have been
buried forever, and he would have been discredited and ruined.=94 He
said that the system does not work, adding that you have to report
wrongdoing to those most responsible for it.
Mr. Snowden said he finally decided to act when he discovered a copy
of a classified 2009 inspector generals report on the N.S.A.s
warrantless wiretapping program during the Bush administration. He
said he found the document through a dirty word search, which he
described as an effort by a systems administrator to check a computer
system for things that should not be there in order to delete them and
sanitize the system.
"It was too highly classified to be where it was," he said of the
report. He opened the document to make certain that it did not belong
there, and after he saw what it revealed, curiosity prevailed, he
After reading about the program, which skirted the existing
surveillance laws, he concluded that it had been illegal, he said. =93If
the highest officials in government can break the law without fearing
punishment or even any repercussions at all, he said, secret powers
become tremendously dangerous.
He would not say exactly when he read the report, or discuss the
timing of his subsequent actions to collect N.S.A. documents in order
to leak them. But he said that reading the report helped crystallize
his decision. You cant read something like that and not realize what
it means for all of these systems we have," he said.
Mr. Snowden said that the impact of his decision to disclose
information about the N.S.A. had been bigger than he had anticipated.
He added that he did not control what the journalists who had the
documents wrote about. He said that he handed over the documents to
them because he wanted his own bias divorced from the decision-making
of publication, and that technical solutions were in place to ensure
the work of the journalists couldn't be interfered with."
Mr. Snowden declined to provide details about his living conditions in
Moscow, except to say that he was not under Russian government control
and was free to move around.
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:11
@_author: coderman 
@_subject: [Full-disclosure] Foreign Intelligence Resistant systems [was Re: 
i must amend this prior advice.
in addition to legal protections, educational support, and competitive programs,
also provide:
- direct and unrestricted backbone access to various individuals or
groups who demonstrate competence in either the educational or
competitive realms, in order for them to mount additional attack
strategies against any reach-able target.  this access must consist of
both passive taps of backbone traffic as well as injection taps for
raw packet transmission at core rates. this should be available on the
Internet backbone at internet exchanges, private fiber through public
right of way, and core networks of operators of licensed wireless
a side benefit of implementing these reforms would be the de-facto
de-funding of offensive network operations by third parties or
governments. the cost to keep ahead of such a widespread, popular, and
distributed effort would be enormous, and provide continually
decreasing returns.
...  getting there is much more complicated of course.   *grin*
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:17
@_author: coderman 
@_subject: [Full-disclosure] ... endpoint security, strong encryption 
the practical uses are not just authenticity and privacy, but also
censorship avoidance and other availability improvements; c.f.:
"Lightweight Obfuscated Datagram Protocol (LODP)"
  "Elligator [...] introduces a new solution: an encoding for points on
a single curve as strings indistinguishable from uniform random
  encryption for privacy of data at rest can almost be considered a
subset of the problem of encryption for privacy of communication as
and all of the above hinge critically upon effective key management
and usability! which are the things you're most likely to screw up
inconspicuously and completely.
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 00:11:18
@_author: coderman 
@_subject: [Full-disclosure] Secure whistleblowing feedback / reporting 
endpoint security [was: [NSA bitching] [formerly Re: PRISM][]]
an interesting discussion :)
"This is perhaps our last fundamental tradeoff before the Singularity
occurs: Do we, as a society, want the comfort and convenience of
increasingly technologic, invisible digital integration enough to pay
for those benefits with the liberties that must be given up to be
protected from the downsides of that integration?" -- dan
i would argue that there is an alternative in design and architecture,
mainly those which decentralize and protect end-to-end. however, there
is a cost attached to these efforts as well, which so far most opt-out
of paying...
best regards,
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2013-12-02 10:29:05
@_author: coderman 
@_subject: DEF CON cell network attacks 
of course; the complete details will be slow to arrive, not least
because detailed description requires a demonstration in a
reproduction test setup, rather than reporting of actual traffic. :/
that said, useful aspects i'll certainly provide on whim or request.
the defining characteristics of the two types of attacks:
DC19 with DRT:
- "high power on-site", less descriminant attacks. target by and
limited to location.
- MitM for system, application, and protocol level attacks. Evilgrade,
MasterKey vulns, etc.  mostly known and a few 0day escalated attacks.
- favorite attack: "Google Voice Search" always-on eavesdropper
payload; Speex voice from all audible participants.
DC20 with Alexander's toys:
- "in the towers", highly targeted to specific devices, active over
wide metro area.
- baseband exploit vector for device key retrieval, memory and storage
forensics, exfiltration.
- PDoS attacks (bricked secondary devices used as fall back once
identified by call graph; ~20 hours)
- favorite attack: baseband pwn in airplane mode, with ex-filtration
over custom channel.
DC21: no appearance (observed).  speculation ongoing...
reversing attacker capabilities, toolkits, TTPs, humanpower/hours, a
much longer tangent.  but this assertion is based on correlation of
the observed power, capacity, and protocols in specific bands
implemented by the attacker with the capabilities of the DRT system.
multiple locations, terabytes of captured spectrum, patience and
as for who was operating it - unknown beyond the usual suspects, which
is a small set due to the restricted distribution of both the hardware
platform and the exploit kit atop it :)
i'll send more details once available.  the details and distribution
to be part of a separate FOIPA effort for US citizen security
enthusiasts that might be of interest to those following this thread.
best regards,

@_date: 2013-12-02 10:34:53
@_author: coderman 
@_subject: NSA: The Game 
classic!  :P
and fun for the whole family this holiday season,
The Internet users win if they kill all of the NSA agents.  The NSA agents win
if they render enough Internet users that the numbers of Internet users and
NSA agents are even.  In other words they win if the NSA agents constitute a
large enough voting bloc that they can't be lynched any more.  At that point
the NSA can unmask and openly subject the remaining Internet users to
extraordinary rendition.

@_date: 2013-12-02 10:40:28
@_author: coderman 
@_subject: Jim Bell needs Bitcoins! 
and it should go without saying; don't use a third-party wallet service!
the bitcoin network is one of the most hostile networks in the world;
the trail of pwn is long and continuous.  wallet services, changes,
pools, casinos, just about every BTC denominated service is operating
at an elevated risk level traditionally seen in banking while running
their operations like a self hosted blog...

@_date: 2013-12-02 17:56:47
@_author: coderman 
@_subject: peertech.org cert [was: DEF CON cell network attacks] 
Hash: SHA512
more details here soon...
only 443 should be considered valid - that is,
 try  first, plain-text must die.
and remember lkaglbgpvvcmc6xc.onion in case it becomes necessary
    Data:
        Version: 3 (0x2)
        Serial Number:
            2b:50:49:6a:55:85:55
        Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, ST=Arizona, L=Scottsdale,
O=GoDaddy.com, Inc.,
CN=Go Daddy Secure Certificate Authority - G2
        Validity
            Not Before: Dec  3 00:18:04 2013 GMT
            Not After : Dec  3 00:18:04 2014 GMT
        Subject: OU=Domain Control Validated, CN=peertech.org
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
            RSA Public Key: (4096 bit)
                Modulus (4096 bit):
                    00:b7:64:54:f1:2e:3a:ec:11:29:5a:93:1f:ad:f0:
                    16:8c:9c:eb:d9:0f:49:d2:9d:16:9a:53:a4:60:b6:
                    23:5b:4f:f3:17:90:77:0a:b3:25:27:f2:27:dd:65:
                    83:b6:e4:d5:13:b1:3b:97:5d:b5:b9:a9:62:32:4a:
                    7e:fb:67:73:20:5f:d7:44:52:c8:fc:ca:f8:fb:f1:
                    4f:d1:9d:94:39:72:12:2b:67:22:4c:0b:dc:7f:31:
                    34:cf:63:42:f1:c8:3d:ed:7c:de:2f:e2:63:e1:a2:
                    0a:c9:e6:86:dd:3f:39:73:af:01:58:d7:6d:59:7a:
                    51:d0:b7:bb:4c:8d:5f:1e:43:10:da:96:09:67:56:
                    2f:38:f6:a8:44:a7:96:9a:5c:bc:3e:6c:d6:d1:b6:
                    96:80:34:c8:88:84:4e:2e:06:14:0f:c5:f2:11:ff:
                    f6:15:06:f2:25:e7:d2:1a:8d:62:ef:5c:0e:fb:44:
                    8e:73:da:96:23:26:03:62:5c:2b:e6:70:5c:87:76:
                    d3:21:59:83:57:ac:56:15:bd:4f:25:fb:df:10:ec:
                    0e:56:fa:44:c8:8b:a4:97:ea:b1:98:71:3b:51:78:
                    79:ee:33:cf:b5:a5:68:15:86:9f:31:70:ee:8f:2f:
                    f4:53:32:b7:99:4f:67:21:db:1e:5d:4f:dc:5b:5d:
                    59:fd:30:3e:a2:04:22:13:76:05:4c:44:d6:08:fe:
                    b5:42:5f:b5:4a:38:4f:3d:eb:ea:59:63:ab:27:87:
                    7e:c4:46:3b:96:75:41:be:85:7e:e8:b5:8a:d4:11:
                    aa:cc:6a:28:b9:50:a3:f4:45:e2:50:d5:1f:6c:bf:
                    b8:ba:07:10:20:f8:7f:94:ec:15:d7:39:a6:fe:df:
                    65:78:1d:60:2c:b0:b1:76:40:82:b5:0f:d6:c8:e3:
                    8b:bb:f3:04:ff:80:e3:de:fc:2c:32:0e:21:13:d5:
                    bd:38:94:a1:c8:53:da:c7:3b:a9:a5:c1:70:ea:89:
                    ef:a7:f8:04:35:41:7e:38:05:73:ff:76:8a:c1:92:
                    7f:03:b8:76:48:b9:f6:61:b1:c5:22:be:b9:36:73:
                    de:0e:b8:36:4a:9c:c5:66:3b:63:2c:be:4f:20:75:
                    94:03:d8:05:d0:78:12:df:77:d8:17:51:7e:3c:24:
                    7f:cc:c6:8e:2a:f7:bc:f8:5c:29:64:bb:10:42:4d:
                    c0:83:64:6f:da:78:14:52:2e:97:49:e8:5d:7f:38:
                    36:3d:5a:5d:7c:44:71:28:21:04:6e:24:f5:f8:59:
                    93:1f:e9:d1:3e:6d:6d:db:93:57:8f:44:74:d6:64:
                    e9:2b:b6:33:fd:16:81:92:29:a5:80:6a:1f:2b:78:
                    66:d3:ed
                Exponent: 65537 (0x10001)
        X509v3 extensions:
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Extended Key Usage:
                TLS Web Server Authentication,
                 TLS Web Client Authentication
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 CRL Distribution Points:
                URI:
            X509v3 Certificate Policies:
                Policy: 2.16.840.1.114413.1.7.23.1
                  CPS:             Authority Information Access:
                OCSP - URI:
                CA Issuers -
                 URI:
            X509v3 Authority Key Identifier:
            X509v3 Subject Alternative Name:
                DNS:peertech.org, DNS:
            X509v3 Subject Key Identifier:
                C6:5E:C0:43:56:84:2E:11:A3:35:C8:AC:A9:70:96:7B:A5:2E:5B:77
    Signature Algorithm: sha256WithRSAEncryption
        b1:ea:a9:16:b6:9c:56:f4:59:99:df:36:69:92:a5:57:48:df:
        70:55:a6:1f:5b:51:74:b4:d1:d7:5a:f6:71:e6:92:f2:56:14:
        07:f4:2c:14:06:50:4a:e6:f8:32:8c:a1:ed:4b:25:50:fa:05:
        99:01:74:db:45:ae:c2:ca:dc:f3:e7:ad:50:1b:12:c2:1e:ea:
        c8:19:41:db:b0:eb:f1:0c:c7:ba:af:c2:08:9e:7d:3c:c9:de:
        5d:7f:ff:9e:c3:cc:54:bd:ac:1f:24:47:17:ae:ba:75:b7:0b:
        b7:ee:3b:3a:ba:2a:f7:19:19:1a:98:56:35:34:16:8a:ec:ac:
        50:f0:45:7c:06:5a:fe:b1:d8:8b:13:94:5b:2c:1c:3d:b6:df:
        f9:79:69:b0:75:68:b3:e5:01:8e:90:85:bc:bf:92:47:ba:d0:
        9c:8c:5d:28:d6:d3:17:58:96:76:ed:bf:65:75:7c:25:58:57:
        2f:52:ae:9f:a9:a1:35:92:ca:28:13:b6:ae:a8:89:cf:ce:a6:
        cd:31:28:42:f7:66:9d:de:38:0d:4c:d5:ae:49:6c:db:92:28:
        a2:7c:4a:18:8e:7b:b6:0a:c9:d4:8d:0a:82:d4:04:a6:d0:3d:
        8c:a6:37:ac:16:98:bd:79:49:83:60:7f:b5:dc:d7:80:aa:5d:
        ae:f7:11:eb

@_date: 2013-12-02 18:00:04
@_author: coderman 
@_subject: peertech.org cert [was: DEF CON cell network attacks] 
let's try attachment clients won't mangle... (previous will give bad sig)

@_date: 2013-12-02 21:31:52
@_author: coderman 
@_subject: trends in cybersecurity 
thought provoking read, as always. thanks Dan :)
this is worth posting whole, particularly this observation:
... polarization has come to cyber
security.  High end practice is accelerating away from the low end.
The best skills are now astonishingly good while the great mass of
those dependent on cyber security are ever less able to even estimate
what it is that they do not know, much less act on it.  This
polarization is driven by the fundamental strategic asymmetry of
cyber security, namely that while the workfactor for the offender
is the incremental price of finding a new method of attack, the
workfactor for the defender is the cumulative cost of forever
defending against all attack methods yet discovered.  Over time,
the curve for the cost of finding a new attack and the curve for
the cost of defending against all attacks to date must cross.  Once
those curves cross, the offender never has to worry about being out
of the money.  That crossing event occurred some time ago.
i do have one comment, per:
Everyone my age working in cyber security was trained for something
else, and because of that switch between one field and another
brings along the hybrid vigor of seeing the cyber security world
through a different lens.
instead of having a "cyber security" profession, all aspects of
"information security", "software security", or "cyber security" as a
specialization should not exist.  competence and experience with these
subjects should be considered part of routine software and systems
development practice. (right now this is mostly impractical, however,
it need not always be so...)
best regards,
--- cut-for-posterity ---
.Trends in Cyber Security
.Dan Geer, 6 November 13, NRO
Thank you for the invitation to speak with you today, which, let
me be clear, is me speaking as myself and not for anybody or anything
else.  As you know, I work the cyber security trade, that is to say
that my occupation is cyber security.  Note that I said "occupation"
rather than "profession."  On 18 September, the U.S. National Academy
of Sciences, on behalf of the Department of Homeland Security,
concluded that cyber security should be seen as an occupation and
not a profession because the rate of change is too great to consider
professionalization.[1]  You may well agree that that rate of change
is paramount and thus why cyber security is the most intellectually
demanding occupation on the planet.  In writing this essay, I will
keep my comments to trends rather than point estimates, just as you
asked in your invitation, but let me emphasize the wisdom of your
request by noting that the faster the rate of change, the more it
is trends that matter and not the value of any given variable at
any given time.  With luck, each of these trends will not be something
that you would argue with as a trend.  Argument, if any, will be
in their interpretation.
Note also that these trends do not constitute a set of mutually
exclusive, collectively exhaustive characterizations of the space
in which we live and work.  Some of them are correlated with others.
Some of them are newly emergent, some not.  Some of them are
reversible to a degree; some not reversible at all.  I am not, today
anyway, looking for causality.
Trend  Polarization
Much has been written about the increasing polarization of American
life.[2]  The middle is getting smaller whether we are noting that
only the middle class is shrinking, that it is the middle of the
country that is depopulating, that the political middle is lonelier
and lonelier, that both farms and banks are now only too small to
matter or too big to fail, that almost all journalism is now advocacy
journalism, that middle tier college education is a ticket to debt
and nothing else.
I submit that this trend towards polarization has come to cyber
security.  High end practice is accelerating away from the low end.
The best skills are now astonishingly good while the great mass of
those dependent on cyber security are ever less able to even estimate
what it is that they do not know, much less act on it.  This
polarization is driven by the fundamental strategic asymmetry of
cyber security, namely that while the workfactor for the offender
is the incremental price of finding a new method of attack, the
workfactor for the defender is the cumulative cost of forever
defending against all attack methods yet discovered.  Over time,
the curve for the cost of finding a new attack and the curve for
the cost of defending against all attacks to date must cross.  Once
those curves cross, the offender never has to worry about being out
of the money.  That crossing event occurred some time ago.
I'll come back to this first bullet at the end, but I mention it
first as polarization is becoming structural and of all the trends
the most telling.  You can confirm this by asking the best cyber
security people what they do on the Internet and what they won't
do on the Internet.  You will find it sharply different than what
the public at large does or will do.  The best people know the most,
and they are withdrawing, they are rejecting technologies.  To use
the words and style of the Intelligence Community, they are
Trend  Trends themselves
The idea that under the pressure of constant change about all you
can measure is the slope of the curve has gone from
don't-bother-me-with-math to everybody's-doing-it.  A Google search
for the phrase "information security trends" turns up 13,400 hits
and no two of the top ten are from the same source.  Consultancies
talk about what they are seeing in the back room, product vendors
talk about evolving needs, and reporters talk about what they are
seeing out on the street.
I am one of those folks.  A Wall Street colleague and I run the
Index of Cyber Security.[3]  The ICS is what is called a sentiment-based
index; if you are familiar with the US Consumer Confidence Index,[4]
then you already know what a sentiment-based index is.  Respondents
to the ICS are top drawer cyber security practitioners with direct
operational responsibility who share, each month, how their view
of security in several areas has changed since the month before.
Because there are no absolutes in cyber security, not even widely
agreed upon definitions of the core terms that make up cyber security
practice, a sentiment-based Index is, in fact, the best decision
support that can be done.
The Index asks the respondents monthly whether each of two dozen
different risks has gotten better, gotten worse, gotten a lot better,
gotten a lot worse, or stayed the same since the month before.  Out
of this, the Index of Cyber Security is calculated and released at
6pm on the last calendar day of the month, in further similarity
to the Consumer Confidence Index.  We write an analytic annual
report that I have given to the organizers for your further reading.
As an index of risk, a higher ICS number means higher risk.  That
risk number has risen, and seems likely to continue to rise.  It
is a composite trend line, but what is more interesting is that the
components of the risk are much more varied, i.e., what is the
dominating risk one month may not be the next.  We think that this
captures, in part, the dynamic nature of cyber security and does
so in a way not otherwise being done.  Respondents seem to agree
that the ICS does offer decision support to front-line people such
as themselves.
Trend  then, is that there is increasingly wide acceptance that
absolute measures are not worth seeking and a kind of confirmation
that cyber security is a practice, not a device.
Trend  Physics and its impact on data
As you well know, more and more data is collected and more and more
of that data is in play.  The general, round-numbers dynamic of
this trend are these: Moore's Law continues to give us two orders
of magnitude in compute power per dollar per decade while storage
grows at three orders of magnitude and bandwidth at four.  These
are top-down economic drivers and they relentlessly warp what is
the economically optimum computing model.  The trend is clear; the
future is increasingly dense with stored data but, paradoxically,
despite the massive growth of data volume, that data becomes more
mobile with time.
As is obvious, this bears on cyber security as data is what cyber
security is all about.  In 2007, Jim Gray gave a seminal talk[5]
about the transformation of science, coining the term "fourth
paradigm."  By that he meant that the history of science is that
science began as an endeavor organized around empirical observation.
After that came the age of theory -- theorizing as the paradigm of
what science did.  Then science became computational, again meaning
that the paradigm of what science did was to calculate.  His argument
for a fourth era was that of a paradigm shift from computational
science to data intensive science.  You here at NRO need no primer
on the power of that shift in paradigm, but I am here to tell you
that cyber security is embracing that fourth paradigm and it is
doing it now.
Ecology professor Philip Greear would challenge his graduate students
to catalog all the life in a cubic yard of forest floor.  Computer
science professor Donald Knuth would challenge his graduate students
to catalog everything their computers had done in the last ten
seconds.  It is hard to say which is more difficult, but everywhere
you look, cyber security practitioners are trying to get a handle
on "What is normal?" so that that which is abnormal can be identified
early in the game.  Behavioral approaches leading towards intrusion
detection are exactly the search for anomaly, and they are data
based.  The now-famous attack on RSA Data Security that led to RSA
buying Net Witness is an example of wanting to know everything so
as to recognize something.  I'm on the record at book length [6]
that the central organizing principle behind a competent security
program is to instrument your data sufficiently well that nothing
moves without it being noticed.  Physics has made it possible to
put computers everywhere.  Physics has made it possible to fill
them all with data.
Cyber security is barely keeping up, and not just because of two,
three, or four orders of magnitude in the physics upstream of the
Trend  Need for prediction
We all know that knowledge is power.  We all know that there is a
subtle yet important distinction between information and knowledge.
We all know that a negative declaration like "X did not happen" can
be only proven if you have the enumeration of *everything* that did
happen and can show that X is not in it.  We all know that a stitch
in time saves nine, but only if we know where to put the stitch.
We all know that without security metrics, the outcome is either
overspending or under protecting.
The more technologic the society becomes, the greater the dynamic
range of possible failures.  When you live in a cave, starvation,
predators, disease, and lightning are about the full range of
failures that end life as you know it and you are well familiar
with all of them.  When you live in a technologic society where
everybody and everything is optimized in some way akin to just-in-time
delivery, the dynamic range of failures is incomprehensibly larger
and largely incomprehensible.  The wider the dynamic range of
failure, the more prevention is the watchword.  As technologic
society grows more interdependent within itself, the more it must
rely on prediction based on data collected in broad ways, not
targeted ways.
Some define risk as the probability of a failure times the cost of
that failure.  To be clear, a trend in favor of making predictions
is a trend subsidiary to a trend in the cost of failure.  I've
written at length elsewhere about how an increasing downside cost
of failure requires that we find ways to be resilient, but not
resilient in the sense of rich redundancy, not resilient in the
sense of having quick recovery mechanisms, but resilient in the
sense of having alternate primary means that do not share common
mode risks.  As such, I strongly recommend that manual means be
preserved wherever possible because whatever those manual means
are, they are already fully capitalized and they do not share common
mode risk with digital means.
There is now more information security risk sloshing around the
economy than could actually be accepted were it exposed.  The
tournament now turns to who can minimize their risk the best, which,
in the civilian economy at large, means who can most completely
externalize their downside information security costs.  The weapons
here are perhaps as simple as the wisdom of Delphi, "Know thyself"
and "Nothing to excess" -- know thyself in the sense of quantitative
rigor and a perpetual propensity to design information systems with
failure in mind; nothing to excess in the sense of mimicking the
biologic world's proof by demonstration that species diversity is
the greatest bulwark against loss of an ecosystem.
Trend  Abandonment
If I abandon a car on the street, then eventually someone will be
able to claim title.  If I abandon a bank account, then the State
will eventually seize it.  If I abandon real estate by failing to
remedy a trespass, then in the fullness of time adverse possession
takes over.  If I don't use my trademark, then my rights go over
to those who use what was and could have remained mine.  If I abandon
my spouse and/or children, then everyone is taxed to remedy my
actions.  If I abandon a patent application, then after a date
certain the teaching that it proposes passes over to the rest of
you.  If I abandon my hold on the confidentiality of data such as
by publishing it, then that data passes over to the commonweal not
to return.  If I abandon my storage locker, then it will be lost
to me and may end up on reality TV.  The list goes on.
Apple computers running 10.5 or less get no updates (comprising
about half the installed base).  Any Microsoft computer running XP
gets no updates (comprising about half the installed base).  The
end of security updates follows abandonment.  It is certainly ironic
that freshly pirated copies of Windows get security updates when
older versions bought legitimately do not.
Stating the obvious, if Company X abandons a code base, then that
code base should be open sourced.  Irrespective of security issues,
many is the time that a bit of software I use has gone missing
because its maker went missing.  But with respect to security, some
constellation of {I,we,they,you} are willing and able to provide
security patches or workarounds as time and evil require.
Would the public interest not be served, then, by a conversion to
open source for abandoned code bases?  But wait, you say, isn't
purchased software on a general purpose computer a thing of the
past?  Isn't the future auto-updated smartphone clients transacting
over armored private (carrier) networks to auto-updated cloud
services?  Maybe; maybe not.  If the two major desktop suppliers
update only half of today's desktops, then what percentage will
they update tomorrow?
If you say "Make them try harder!," then the legalistic, regulatory
position is your position, and the ACLU is already trying that
route.  If smartphone auto-update becomes a condition of merchantability
and your smartphone holds the keying material that undeniably says
that its user is you, then how long before a FISA court orders a
special auto-update to *your* phone for evidence gathering?
If you say "But we already know what they're going to do, don't
we?," then the question is what about the abandoned code bases.
Open-sourcing abandoned code bases is the worst option, except for
all the others.  But if seizing an abandoned code base is too big
a stretch for you before breakfast, then start with a Public Key
Infrastructure Certifying Authority that goes bankrupt and ask "Who
gets the keys?"
Trend  Interdependence
The essential character of a free society is this: That which is
not forbidden is permitted.  The essential character of an unfree
society is the inverse, that which is not permitted is forbidden.
The U.S. began as a free society without question; the weight of
regulation, whether open or implicit, can only push it toward being
unfree.  Under the pressure to defend against offenders with a
permanent structural advantage, defenders who opt for forbidding
anything that is not expressly permitted are cultivating a computing
environment that does not embody the freedom with which we are
heretofore familiar.
Put concretely, the central expression of a free society is a free
market, and the cardinal measure of a free market is the breadth
of real choice -- choice that goes beyond color and trim and body
style to choices that optimize discordant, antithetical goal states.
The level of choice on the Internet is draining down.  You may revel
in the hundreds of thousands of supposedly new voices that have
found a way to chatter in full view.  You may note that new "apps"
for Android plus iPhone are appearing at over a thousand per day.
You may rightly remind us all that technology is democratizing in
the sense that powers once reserved for the few are now irretrievably
in the hands of the many.  What stands against that, and why I say
that it stands against that, is increasing interdependence.
We humans can design systems more complex than we can then operate.
The financial sector's "flash crashes" are an example of that;
perhaps the fifty interlocked insurance exchanges for Obamacare
will soon be another.  Above some threshold of system complexity,
it is no longer possible to test, it is only possible to react to
emergent behavior.  The lowliest Internet user is entirely in the
game of interdependence -- one web page can easily touch scores of
different domains.  While writing this, the top level page from
cnn.com had 400 out-references to 85 unique domains each of which
is likely to be similarly constructed and all of which move data
one way or another.  If you leave those pages up and they have an
auto-refresh, then moving to a new network signals to every one of
those ad networks that you have so moved.
The wellspring of risk is dependence, especially dependence on
shared expectations of shared system state, i.e., interdependence
on the ground.  If you would accept that you are most at risk from
the things you most depend upon, then damping dependence is the
cheapest, most straightforward, lowest latency way to damp risk,
just as the fastest and most reliable way to put more money on a
business's bottom line is through cost control.
Trend  Automation
Shoshana Zuboff of the Harvard Business School notably described
three laws of the digital age,
. Everything that can be automated will be automated.
. Everything that can be informated will be informated.
. Every digital application that can be used for surveillance and
.    control will be used for surveillance and control.
It is irrelevant, immaterial and incompetent to argue otherwise.
For security technology, Zuboff's Laws are almost the goal state,
that is to say that the attempt to automate information assurance
is in full swing everywhere, the ability to extract information
from the observable is in full swing everywhere, and every digital
application is being instrumented.
Before In-Q-Tel, I worked for a data protection company.  Our product
was, and I believe still is, the most thorough on the market.  By
"thorough" I mean the dictionary definition, "careful about doing
something in an accurate and exact way."  To this end, installing
our product instrumented every system call on the target machine.
Data did not and could not move in any sense of the word "move"
without detection.  Every data operation was caught and monitored.
It was total surveillance data protection.  What made this product
stick out was that very thoroughness, but here is the point: Unless
you fully instrument your data handling, it is not possible for you
to say what did not happen.  With total surveillance, and total
surveillance alone, it is possible to treat the absence of evidence
as the evidence of absence.  Only when you know everything that
*did* happen with your data can you say what did *not* happen with
your data.
But this trend of automating is now leaving the purely defensive
position behind.  In a press release two weeks ago today,[7] DARPA
signaled exactly that, and I quote
   [T]he Defense Advanced Research Projects Agency intends to hold
   the Cyber Grand Challenge -- the first-ever tournament for fully
   automatic network defense systems.  DARPA envisions teams creating
   automated systems that would compete against each other to
   evaluate software, test for vulnerabilities, generate security
   patches and apply them to protected computers on a network.  The
   growth trends ... in cyber attacks and malware point to a future
   where automation must be developed...
The automation trend is irreversible, but it begs a question that
I fear no one will answer in a way that doesn't merely reflect their
corporate or institutional interest, namely are people in the loop
a failsafe or a liability?[8]
Trend  Dual use
I've become convinced that all security technology is dual use.
While I am not sure whether dual use is a trend or a realization
of an unchanging fact of nature, the obviousness of dual use seems
greatest in the latest technologies, so I am calling it a trend in
the sense that the straightforward accessibility of dual use
characteristics of new technology is a growing trend.
There are a lot of examples, but in the physical world any weapon
usable for defense can be repurposed for offense.  Every security
researcher looking for exploitable flaws is deep in the dual use
debate because once discovered, those flaws can be patched or they
can be sold.  The cyber security products that promise total
surveillance over the enterprise are, to my mind, an offensive
strategy used for defensive purposes.
There was a time when flaws were predominantly found by adventurers
and braggarts.  Ten plus years of good work by the operating system
vendors elbowed the flaw finders out of the operating system and,
as a result, our principal opponents changed over from adventurers
and braggarts to being professionals.  Finding vulnerabilities and
exploiting them is now hard enough that it has moved out of the
realm of being a hobby and into the realm of being a job.  This
changed several things, notably that braggarts share their findings
because they are paid in bragging rights.  By contrast, professionals
do not share and are paid in something more substantial than fame.
The side effect has been a continued rise in the percentage of all
vulnerabilities that are previously unknown.  The trend, in other
words, is that by crushing hobbyists we've raised the market price
of working exploits to where now our opponents pay for research and
development out of revenue.
Simulating what the opponent can do thus remains the central task
of defensive research.  Much of that research is in crafting proofs
of concept that such and such a flaw can be taken advantage of.
Corman's neologism of "HD Moore's Law" says that the trend in the
power of the casual attacker grows as does the trend of the power
in Metasploit.[9] It is hard to think of a better description of
dual use.
Trend  The blurring of end-to-end
To my mind, the most important technical decision ever made was
that the security of the Internet was to be "end-to-end."[10]
"End-to-end" is a generic technical term yet simple to explain: the
Internet was built on the premise that two entities could connect
themselves to each other and decide what they wanted to do.  The
network was a delivery vehicle, but the form, content, and security
of the connection between the two ends was to be their own choice.
End-to-end is a model where the terminal entities are smart and the
network is dumb.  This is completely (completely) different than a
smart network with dumb terminal entities at the end of the wire.
No other design decision of the Internet comes close to the importance
of it's being an end-to-end design.  With end-to-end, security is
the choice of the terminal end-points, not something built into the
fabric of the Internet itself.  That is American values personified.
It is the idea that accountability, not permission seeking, is the
way a government curbs the misuse of freedoms, and, as accountability
scales but permission seeking does not, accountability wins.
End-to-end security is the digital manifestation of the right of
association and, in any case, is what enabled the Internet to become
relevant in the first place.  End-to-end does precisely what Peter
Drucker told us to do: "Don't solve problems, create opportunities."
The provision of content from anywhere to anywhere, which is the
very purpose of an internetwork, is a challenge to sovereignty.
America's Founders wanted no sovereign at all, and they devised a
government that made the center all but powerless and the periphery
fully able to thumb its nose at whatever it felt like.  Much ink
has been spilled on the frontier ethic versus the wishful policies
favored by the comfortable urbanity of the welfare state, but the
Internet's protocols have everything in common with the former and
nothing in common with the latter.
The free man requires the choice of with what degree of vigor to
defend himself.  That is a universal; America's Founders laid that
down in the Second Amendment, just as did George Orwell in the
English democratic socialist weekly "Tribune" when he said, "That
rifle on the wall of the laborer's cottage or working class flat
is the symbol of democracy.  It is our job to see that it stays
there."  Were George Washington or George Orwell still among us,
they would know that smart end-points and dumb networks are what
freedom requires, that smart networks protecting dumb end-points
breed compliant dependency.
But the trend is otherwise, and not just because of the fatuous
fashionability of entitlement, but rather because of a blurring of
what the term "end" means.  So very many people have adopted automatic
synchronization of multiple devices they own that one has to ask
whether their tablet is an end or their collection of mutually
synchronized devices is an end.  So many Internet-dependent functions
are spread silently across numerous entities and applications that
what is the end may well be more dynamic than can be described.  If
an end implies unitary control on the part of an owner, then set
theory says that mutually synchronized devices are a unitary end.
That blurring of "end" makes end-to-end provisioning problematic
as a set of devices cannot be assumed to be equally on and equally
participating in any given transaction.  Quoting Clark & Blumenthal[11]
   There is a risk that the range of new requirements now emerging
   could have the consequence of compromising the Internet's original
   design principles.  Were this to happen, the Internet might lose
   some of its key features, in particular its ability to support
   new and unanticipated applications.  We link this possible outcome
   to a number of trends: the rise of new stakeholders in the
   Internet,...  new government interests, the changing motivations
   of the growing user base, and the tension between the demand for
   trustworthy overall operation and the inability to trust the
   behavior of individual users.
This is nowhere so evident as in security, that is to say in the
application of the end-to-end principle to cyber security.  What
does end-to-end secure transport mean when travelocity.com is showing
you a page dynamically constructed from a dozen other entities?
Trend  Complexity in the supply chain
Even without resorting to classified information, it is now clear
that supply chain attacks have occurred.  Whether reading journalistic
accounts or Richard Clarke's novel _Breakpoint_, the finding is
that the supply chain creates opportunities for badness.  None of
the things I've yet read, however, blames the supply chain risk on
its complexity, per se, but that is the trend that matters.
Security is non-composable -- we can get insecure results even when
our systems are assembled from secure components.  The more components,
the less likely a secure result.  This applies to supply chains
that are growing ever more complex under the pressure of just-in-time,
spot market sourcing of, say, memory chips and so forth and so on.
Because the attacker has only to find one component of that chain
to be vulnerable while the defender has to assure that all components
are invulnerable, rising supply chain complexity guarantees increased
opportunity for effective attack.  It cannot do otherwise, and the
trend is clear.
Trend  Monoculture(s)
Beginning with Forrest in 1997,[12] regular attention has been paid
to the questions of monoculture in the network environment.  There
is no point belaboring the fundamental question, but let me state
it for the record: cascade failure is so very much easier to detonate
in a monoculture -- so very much easier when the attacker has only
to write one bit of malware, not ten million.  The idea is obvious;
believing in it is easy; acting on its implications is, evidently,
rather hard.
I am entirely sympathetic to the actual reason we continue to deploy
computing monocultures -- making everything almost entirely alike
is, and remains, our only hope for being able to centrally manage
it in a consistent manner.  Put differently, when you deploy a
computing monoculture you are making a fundamental risk management
decision: That the downside risk of a black swan event is more
tolerable than the downside risk of perpetual inconsistency.  This
is a hard question, as all risk management is about changing the
future, not explaining the past.  Which would you rather have, the
unlikely event of a severe impact, or the day-to-day burden of
perpetual inconsistency?
When we opt for monocultures we had better opt for tight central
control.  This supposes that we are willing to face the risks that
come with tight central control, of course, including the maximum
risk of all auto-update schemes, namely the hostile takeover of the
auto-update mechanism itself.  Computer desktops are not the point;
embedded systems are.  The trendline in the number of critical
monocultures seems to be rising and many of these are embedded
systems both without a remote management interface and long lived.
That combination -- long lived and not reachable -- is the trend
that must be reversed.  Whether to insist that embedded devices
self destruct at some age or that remote management of them be a
condition of deployment is the question.  In either case, the
Internet of Things and the appearance of microcontrollers in seemingly
every computing device should raise hackles on every neck.[13]
Trend  Attack surface growth versus skill growth
Everyone here knows the terminology "attack surface" and knows that
one of the defender's highest goals is to minimize the attack surface
wherever possible.  Every coder adhering to a security-cognizant
software lifecycle program does this.  Every company or research
group engaged in static analysis of binaries does this.  Every
agency enforcing a need-to-know regime for data access does this.
Every individual who reserves one low-limit credit card for their
Internet purchases does this.  I might otherwise say that any person
who encrypts their e-mail to their closest counterparties does this,
but because consistent e-mail encryption is so rare, encrypting
one's e-mail marks it for collection and indefinite retention by
those entities in a position to do so, regardless of what country
you live in.
In cyber security practice, the trend is that we practitioners as
a class are getting better and better.  We have better tools, we
have better understood practices, and we have more colleagues.
That's the plus side.  But I'm interested in the ratio of skill to
challenge, and as far as I can estimate, we are expanding the
society-wide attack surface faster than we are expanding our
collection of tools, practices, and colleagues.  If you are growing
more food, that's great.  If your population is growing faster than
your improvements in food production can keep up, that's bad.
In the days of radio, there was Sarnoff's Law, namely that the value
of a broadcast network was proportional to N, the number of listeners.
Then came packetized network communications and Metcalfe's Law,
that the value of a network was proportional to N squared, the
number of possible two-way conversations.  We are now in the era
of Reed's Law where the value of a network is proportional to the
number of groups that can form in it, that is to say 2 to the power
N.  Reed's Law is the new reality because it fits the age of social
networks.  In each of these three laws as publicly stated, the sign
bit is positive, but in parallel with the claim that everything is
dual use, the sign bit can also be negative because interconnections
are a contributor to the net attack surface.  If an Internet of
Things is indeed imminent, then the upward bend in the curve of the
global attack surface will grow steeper regardless of what level
of risk there is for any one thing so long as that level of risk
is always non-zero.
Trend  Specialization
Everyone my age working in cyber security was trained for something
else, and because of that switch between one field and another
brings along the hybrid vigor of seeing the cyber security world
through a different lens.  Statisticians, civil engineers, and
lawyers alike can contribute.  But the increasing quality of prepatory
education, the increasing breadth of affairs for which cyber security
is needful, and the increasing demand for skill of the highest sort
means the humans in the game are specializing.
While some people like to say "Specialization is for insects," tell
me that the security field itself is not specializing.  We have
people who are expert in forensics on specific operating system
localizations, expert in setting up intrusion response, expert in
analyzing large sets of firewall rules using non-trivial set theory,
expert in designing egress filters for universities that have no
ingress filters, expert in steganographically watermarking binaries,
and so forth.  Generalists are becoming rare, and they are being
replaced by specialists.  This is biologic speciation in action,
and the narrowing of ecologic niches.  In rough numbers, there are
somewhere close to 5,000 various technical certifications you can
get in the computer field, and the number of them is growing thus
proving the conjecture of specialization and speciation is not just
for insects and it will not stop.
[1] "Professionalizing the Nation's Cyber Workforce?"
 [2] _Hollowing out the Middle_, Carr & Kefalas; _Race Against the
Machine_, Brynjolfsson & McAfee; _Average Is Over_, Cowen
[3] "The Index of Cyber Security,"
 cybersecurityindex.org
[4] "The Consumer Confidence Index," Technical Note, 2011
 tinyurl.com/3sb633k
[5] Gray, "eScience," NRC-CSTB, Mountain View CA, 2007
 research.microsoft.com/en-us/um/people/gray/talks/NRC-CSTB_eScience.ppt
[6] Geer, _Economics and Strategies of Data Security_, 2008
[7] [8] Geer, "People in the Loop: Failsafe or a Liability?", 2012
 geer.tinho.net/geer.suitsandspooks.8ii12.txt
[9] Corman, "Intro to HDMoore's Law," 2011
 blog.cognitivedissidents.com/2011/11/01/intro-to-hdmoores-law
[10] Saltzer, Reed, & Clark, "End-to-End Arguments in System Design,"
 web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf
[11] Clark & Blumenthal, "Rethinking the design of the Internet,
The End-to-End Arguments vs. the Brave New World," 2001
 cyberlaw.stanford.edu/e2e/papers/TPRC-Clark-Blumenthal.pdf
[12] Forrest, Somayaji, & Ackley, "Building Diverse Computer Systems,"
HotOS-VI, 1997
 [13] Farmer, "IPMI: Freight Train to Hell v2.01," 2013
 fish2.com/ipmi/itrain.pdf
more material at geer.tinho.net/pubs

@_date: 2013-12-03 15:40:25
@_author: coderman 
@_subject: Fwd: [cryptography] A new approach to steganography 
I came up with a new approach to steganography. There's an
implementation and writeup of it here -

@_date: 2013-12-03 15:42:42
@_author: coderman 
@_subject: [cryptography] A new approach to steganography 
Q. Why did you use Python3 as a reference language?
A. Because not having distinct binary and unicode string types is barbaric.
oh the many ways i both love and hate python...

@_date: 2013-12-04 14:05:27
@_author: coderman 
@_subject: NSA tracking cellphone locations worldwide 
NSA tracking cellphone locations worldwide, Snowden documents show
By Barton Gellman and Ashkan Soltani, Wednesday, December 4, 12:18 PM
The National Security Agency is gathering nearly 5 billion records a
day on the whereabouts of cellphones around the world, according to
top-secret documents and interviews with U.S. intelligence officials,
enabling the agency to track the movements of individuals  and map
their relationships  in ways that would have been previously
The records feed a vast database that stores information about the
locations of at least hundreds of millions of devices, according to
the officials and the documents, which were provided by former NSA
contractorEdward Snowden. New projects created to analyze that data
have provided the intelligence community with what amounts to a mass
surveillance tool.
(Video: How the NSA uses cellphone tracking to find and develop targets)
The NSA does not target Americans location data by design, but the
agency acquires a substantial amount of information on the whereabouts
of domestic cellphones incidentally, a legal term that connotes a
foreseeable but not deliberate result.
One senior collection manager, speaking on condition of anonymity but
with permission from the NSA, said we are getting vast volumes of
location data from around the world by tapping into the cables that
connect mobile networks globally and that serve U.S. cellphones as
well as foreign ones. Additionally, data is often collected from the
tens of millions of Americans who travel abroad with their cellphones
every year.
In scale, scope and potential impact on privacy, the efforts to
collect and analyze location data may be unsurpassed among the NSA
surveillance programsthat have been disclosed since June. Analysts can
find cellphones anywhere in the world, retrace their movements and
expose hidden relationships among individuals using them.
(Graphic: How the NSA is tracking people right now)
U.S. officials said the programs that collect and analyze location
data are lawful and intended strictly to develop intelligence about
foreign targets.
Robert Litt, general counsel for the Office of the Director of
National Intelligence, which oversees the NSA, said there is no
element of the intelligence community that under any authority is
intentionally collecting bulk cellphone location information about
cellphones in the United States.
The NSA has no reason to suspect that the movements of the
overwhelming majority of cellphone users would be relevant to national
security. Rather, it collects locations in bulk because its most
powerful analytic tools  known collectively as CO-TRAVELER  allow it
to look for unknown associates of known intelligence targets by
tracking people whose movements intersect.
Still, location data, especially when aggregated over time, is widely
regarded among privacy advocates as uniquely sensitive. Sophisticated
mathematical techniques enable NSA analysts to map cellphone owners
relationships by correlating their patterns of movement over time with
thousands or millions of other phone users who cross their paths.
Cellphones broadcast their locations even when they are not being used
to place a call or send a text.
(Video: Reporter Ashkan Soltani explains NSA collection of cellphone data)
CO-TRAVELER and related tools require the methodical collection and
storage of location data on what amounts to a planetary scale. The
government is tracking people from afar into confidential business
meetings or personal visits to medical facilities, hotel rooms,
private homes and other traditionally protected spaces.
One of the key components of location data, and why its so
sensitive, is that the laws of physics dont let you keep it private,
said Chris Soghoian, principal technologist at the American Civil
Liberties Union. People who value their privacy can encrypt their
e-mails and disguise their online identities, but the only way to
hide your location is to disconnect from our modern communication
system and live in a cave.
The NSA cannot know in advance which tiny fraction of 1 percent of the
records it may need, so it collects and keeps as many as it can  27
terabytes, by one account, or more than double the text content of the
Library of Congresss print collection.
The location programs have brought in such volumes of information,
according to a May 2012 internal NSA briefing, that they are
outpacing our ability to ingest, process and store data. In the
ensuing year and a half, the NSA has been transitioning to a
processing system that provided it with greater capacity.
The possibility that the intelligence community has been collecting
location data, particularly of Americans, has long concerned privacy
advocates and some lawmakers. Three Democratic senators  Ron Wyden
(Ore.), Mark Udall (Colo.) and Barbara Mikulski (Md.)  have
introduced an amendment to the 2014 defense spending bill that would
require U.S. intelligence agencies to say whether they have ever
collected or made plans to collect location data for a large number
of United States persons with no known connection to suspicious
NSA Director Keith Alexander disclosed in Senate testimony in October
that the NSA had run a pilot project in 2010 and 2011 to collect
samples of U.S. cellphone location data. The data collected were
never available for intelligence analysis purposes, and the project
was discontinued because it had no operational value, he said.
Alexander allowed that a broader collection of such data may be
something that is a future requirement for the country, but it is not
right now.
The number of Americans whose locations are tracked as part of the
NSAs collection of data overseas is impossible to determine from the
Snowden documents alone, and senior intelligence officials declined to
offer an estimate.
Its awkward for us to try to provide any specific numbers, one
intelligence official said in a telephone interview. An NSA
spokeswoman who took part in the call cut in to say the agency has no
way to calculate such a figure.
An intelligence lawyer, speaking with his agencys permission, said
location data are obtained by methods tuned to be looking outside the
United States, a formulation he repeated three times. When U.S.
cellphone data are collected, he said, the data are not covered by the
Fourth Amendment, which protects Americans against unreasonable
searches and seizures.
According to top-secret briefing slides, the NSA pulls in location
data around the world from 10 major sigads, or signals intelligence
activity designators.
A sigad known as STORMBREW, for example, relies on two unnamed
corporate partners described only as ARTIFICE and WOLFPOINT. According
to an NSA site inventory, the companies administer the NSAs physical
systems, or interception equipment, and NSA asks nicely for
STORMBREW collects data from 27 telephone links known as OPC/DPC
pairs, which refer to originating and destination points and which
typically transfer traffic from one providers internal network to
anothers. That data include cell tower identifiers, which can be used
to locate a phones location.
The agencys access to carriers networks appears to be vast.
Many shared databases, such as those used for roaming, are available
in their complete form to any carrier who requires access to any part
of it, said Matt Blaze, an associate professor of computer and
information science at the University of Pennsylvania. This flat
trust model means that a surprisingly large number of entities have
access to data about customers that they never actually do business
with, and an intelligence agency  hostile or friendly  can get one
stop shopping to an expansive range of subscriber data just by
compromising a few carriers.
Some documents in the Snowden archive suggest that acquisition of U.S.
location data is routine enough to be cited as an example in training
materials. In an October 2012 white paper on analytic techniques, for
example, the NSAs counterterrorism analysis unit cites two U.S.-based
carriers to illustrate the challenge of correlating the travels of
phone users on different mobile networks. Asked about that, a U.S.
intelligence official said the example was poorly chosen and did not
represent the programs foreign focus.
The NSAs capabilities to track location are staggering, based on the
Snowden documents, and indicate that the agency is able to render most
efforts at communications security effectively futile.
Like encryption and anonymity tools online, which are used by
dissidents, journalists and terrorists alike, security-minded behavior
 using disposable cellphones and switching them on only long enough
to make brief calls  marks a user for special scrutiny. CO-TRAVELER
takes note, for example, when a new telephone connects to a cell tower
soon after another nearby device is used for the last time.
Side-by-side security efforts  when nearby devices power off and on
together over time  assist in determining whether co-travelers are
associated  through behaviorally relevant relationships, according
to the 24-page white paper, which was developed by the NSA in
partnership with the National Geospatial Agency, the Australian
Signals Directorate and private contractors.
A central feature of each of these tools is that they do not rely on
knowing a particular target in advance, or even suspecting one. They
operate on the full universe of data in the NSAs FASCIA repository,
which stores trillions of metadata records, of which a large but
unknown fraction include locations.
The most basic analytic tools map the date, time, and location of
cellphones to look for patterns or significant moments of overlap.
Other tools compute speed and trajectory for large numbers of mobile
devices, overlaying the electronic data on transportation maps to
compute the likely travel time and determine which devices might have
To solve the problem of undetectable surveillance against CIA officers
stationed overseas, one contractor designed an analytic model that
would carefully record the case officers path and look for other
mobile devices in steady proximity.
Results have not been validated by operational analysts, the report said.
Julie Tate contributed to this report. Soltani is an independent
security researcher and consultant.

@_date: 2013-12-07 17:27:48
@_author: coderman 
@_subject: infra-org (urls) 
actually, i have long held this view on an intuitive / elegance level
of understanding.  the continual expansion of our understanding of
quantum phenomena has only reinforced and clarified this model of
consciousness for me.
rather than sounding crazy, i am pleasantly surprised that others
grasp this concept of consciousness and are willing to embrace it!
this would be a fun tangent to discourse about, however, i'll save the
brain as quantum antenna linked to body via nerve cell transducers for
another day...  ;)
best regards,

@_date: 2013-12-07 21:06:40
@_author: coderman 
@_subject: infra-org (urls) 
that movie discussed a few interesting concepts, but was overall too
annoying/incorrect for me to enjoy :/
regarding the role of quantum effects on consciousness, i am mostly
dismissing the purely deterministic models of consciousness arising
out of chemical interactions or fields only.
consider instead the role of quantum effects within the brain as
influence on nerve behavior within a integrated information theory of

@_date: 2013-12-08 00:22:48
@_author: coderman 
@_subject: NSA morale down 
the portrayals from the brass and insiders is, "the administration is
not showing enough support!".
i have to wonder: how many rank and file are feeling betrayed by the
NSA administration instead?   they're now getting a look into all the
SCI bits they were compartmented from before; able to see a bigger
picture full of invasive technical excesses and legal abuses...
A second former official said NSA workers are polishing up their
rsums and asking that they be cleared  removing any material linked
to classified programs  so they can be sent out to potential
employers. He noted that one employee who processes the rsums said,
Ive never seen so many rsums that people want to have cleared in
my life.
it remains to be seen if they simply jump to private sector who are
just as bad, or pursue less offensive careers entirely.
NSA morale down after Edward Snowden revelations, former U.S. officials say
By Ellen Nakashima, Published: December 7
Morale has taken a hit at the National Security Agency in the wake of
controversy over the agencys surveillance activities, according to
former officials who say they are dismayed that President Obama has
not visited the agency to show his support.
A White House spokeswoman, Caitlin Hayden, noted that top White House
officials have been to the agency to express the presidents support
and appreciation for all that NSA does to keep us safe.
It is not clear whether or when Obama might travel the 23 miles up the
Baltimore-Washington Parkway to visit Fort Meade, the NSAs
headquarters in Maryland, but agency employees are privately voicing
frustration at what they perceive as White House ambivalence amid the
pounding the agency has taken from critics.
An NSA spokeswoman had no comment.
Obama in June defended the NSAs surveillance as lawful and said he
welcomed the public debate prompted by revelations from former
contractor Edward Snowden beginning that month.
Though Obama has asserted, for instance, that the NSAs collection of
virtually all Americans phone records is lawful and has saved lives,
the administration has not endorsed legislation that would codify it.
And his recent statements suggest he thinks some of the NSAs
activities should be constrained.
A senior administration official who was not authorized to speak on
the record said that the White House would normally not endorse
legislation so early in the process but that its been clear ...
that we prefer legislation that preserves the phone records program
while making some changes ... to potentially strengthen oversight
and transparency.
Said Hayden: The president has the highest respect for and pride in
the men and women of the intelligence community who work tirelessly to
protect our nation. Hes expressed that directly to NSAs leadership
and has praised their work in public. As he said: The men and women
of our intelligence community work every single day to keep us safe
because they love this country and believe in our values. Theyre
patriots.
She noted that in recent weeks, Lisa Monaco, assistant to the
president for homeland security and counterterrorism, and Denis
McDonough, the White House chief of staff, visited Fort Meade to
express the presidents support and appreciation for all that NSA does
to keep us safe.
Supporters of the NSA say staffers are not feeling the love.
The agency, from top to bottom, leadership to rank and file, feels
that it is had no support from the White House even though its been
carrying out publicly approved intelligence missions, said Joel
Brenner, NSA inspector general from 2002 to 2006. They feel theyve
been hung out to dry, and theyre right.
A former U.S. official  who like several other former officials
interviewed for this story requested anonymity because he still has
dealings with the agency  said: The president has multiple
constituencies  I get it. But he must agree that the signals
intelligence NSA is providing is one of the most important sources of
intelligence today.
So if thats the case, why isnt the president taking care of one of
the most important elements of the national security apparatus?
The White House, observers say, is caught between competing desires to
preserve what it has said are valuable national security programs and
to shield the president from criticism from allies abroad and
civil-liberties advocates at home.
Some observers said it is not surprising that Obama would not travel
to Fort Meade before internal and external reviews of surveillance
activities have been completed. The reviews are expected to be done
The NSAs director, Gen. Keith Alexander, who is retiring in the
spring after 81 / 2 years, has been the most vocal defender of the
agencys 35,000 employees. In speeches he has noted that more than
6,000 of them went to Iraq and Afghanistan to support the military. He
has spoken of how 22 cryptologists were killed. Theyre the heroes 
not the media leaker, he said in a September speech, in a reference
to Snowden.
NSA counterterrorism analysts have worked every weekend for eight
years since Ive been here. ... Twenty-four hours a day, seven days
a week, theyre there to defend us, he said then.
On Thursday, Obama said on MSNBC that he would be proposing some
self-restraint on the NSA and some reforms that can give people more
In an interview with NBC last month, he said: In some ways, the
technology and the budgets and the capacity [at NSA] have outstripped
the constraints. And weve got to rebuild those in the same way that
were having to do on a whole series of capacities ... [such as]
drone operations.
Civil-liberties advocates generally agree with that sentiment, but
they would go further and say that the NSAs bulk collection of
domestic phone records is unlawful and ought to be ended.
Former officials note how President George W. Bush paid a visit to the
NSA in January 2006, in the wake of revelations by the New York Times
that the agency engaged in a counterterrorism program of warrantless
surveillance on U.S. soil beginning after the Sept. 11, 2001,
terrorist attacks. Bush came out and spoke to the workforce, and the
effect on morale was tremendous, Brenner said. Theres been nothing
like that from this White House.
A second former official said NSA workers are polishing up their
rsums and asking that they be cleared  removing any material linked
to classified programs  so they can be sent out to potential
employers. He noted that one employee who processes the rsums said,
Ive never seen so many rsums that people want to have cleared in
my life.
Morale is bad overall, a third former official said. The news  the
Snowden disclosures  it questions the integrity of the NSA
workforce, he said. Its become very public and very personal.
Literally, neighbors are asking people, Why are you spying on
Grandma? And we arent. People are feeling bad, beaten down.

@_date: 2013-12-08 00:44:02
@_author: coderman 
@_subject: NSA morale down 
by private sector i'm thinking of companies like Statfor more than Amazon...
... Below are a series of articles this past week about
internationally acclaimed activist, Srdja Popovic, and his involvement
with the private intelligence firm Stratfor.
... If anyone has information about CANVAS or Srdja Popovic, please
feel free to contact me at zoealif[at]gmail.com. I am currently
writing a blog post on the story.

@_date: 2013-12-09 07:53:07
@_author: coderman 
@_subject: Android IMSI Catcher detection 
fun :)  i always liked osmocomBB, since openmoko days...
these days i prefer SDR and wider band, wider freq. transceivers, but
TI Calypso and MTK definitely more accessible!  will you provide a
developer mailing list in addition to github?
best regards,

@_date: 2013-12-09 08:07:18
@_author: coderman 
@_subject: EM-nature (was: infra-org) 
effective attenuation of emanations above 10Ghz would be interesting.
even at >5Ghz you run into trouble with the AC filer route as you
mention; best practice seems to be DC batteries inside the cage :/
attenuation at high frequencies for air flow mesh less problematic;
optical communication links will always be useful of course...
i would be curious to see high dBm with high dBi gain
emitters(antennas) worst-case testing against actual build outs at
beyond exceptional..
Teletronics makes some nice 1W 5.8Ghz amps for 802.11a which could be
so purposed inexpensively.
best regards,

@_date: 2013-12-09 09:49:49
@_author: coderman 
@_subject: Android IMSI Catcher detection 
it doesn't "function" yet, period.  *grin*
i leave it as an exercise for the reader to implement A0 detection on Android...

@_date: 2013-12-09 15:03:57
@_author: coderman 
@_subject: good clocks (not using GPS) and multi-channel hw [was: sidebands 
GPS disciplining to keep a OCXO in check periodically (GPSDO) would be
useful!  GPS just can't be the primary source.
has anyone used an OctoClock-G?
  best regards,

@_date: 2013-12-09 15:17:04
@_author: coderman 
@_subject: Android IMSI Catcher detection 
carrierIQ is good for something ;)
you're going to have to go ARM native (or ?) to observe use of A0 over
GSM, since android.telephony.gsm screwed us.
this came up on the cryptome list last week: camouflage, jamming,
obfuscation are all useful techniques to apply against unwelcome
observers. c.f. high power infra red LED camera dazzlers and LADAR
jammers, etc.
while equally effective on the cell bands, you'll want to be sure to
check your 20 before emitting with gusto!  ;P
best regards,

@_date: 2013-12-09 15:30:31
@_author: coderman 
@_subject: Android IMSI Catcher detection 
i feel your pain...
sort of; there are some interesting attacks using a force-pushed
silent PRL update (see DC19/DC20 cell attacks threads) which would be
observable by tower ID oddities, not to mention decremented or zero
PRL version.  however, you'd have to be paying attention (who checks
their PRL regularly? :).
if you simply check if a tower is in
 for example, you're open to
attacks spoofing a legitimate but remote (out of range) tower.
using direction finding techniques to cross reference the transmitter
location against the expected GPS coordinates in a tower database
relative to your position would also detect these tower impersonators,
but requires more hardware than a mobile baseband...
the expensive, limited distribution kit will be hard to distinguish
without a high performance software defined radio.  if you're able to
detect an identically spoofed tower using OsmocomBB with high
confidence i'd love to know how you did it!
truth.  also, an inversion of observed data link capacity (suddenly
seeing receive bandwidth drop in half or more while transmit rate
doubles) is no bueno.
best regards,

@_date: 2013-12-09 16:22:38
@_author: coderman 
@_subject: Open phones for privacy/anonymity applications, Guardian 
the FCC/NTIA don't like people using spectrum with unapproved devices.
sure, you can code it up. and sure, you can run an SDR in that range.
... but put them together in the wild at useful dBi and you're
stepping on toes.  try to sell/distribute such a setup? better have it
good analysis of the details:
  ...the FCCs ancillary jurisdiction cannot reasonably extend to the
development of software by parties uninvolved in the marketing or sale
of radio devices...
FCC Rules for SDR Device Certification Only Affect Radio Equipment

@_date: 2013-12-09 16:26:45
@_author: coderman 
@_subject: Open phones for privacy/anonymity applications, Guardian 
to be specific: it is this certification step that fully open source
SDR/baseband equipment manufacturers have difficultly with.  E.g. the
FCC plainly states systems  "wholly dependent on open source elements
would have a high burden to demonstrate their security during the
certification process.  where many have taken "high burden" to mean
"nearly impossible"...
best regards,

@_date: 2013-12-11 00:09:49
@_author: coderman 
@_subject: Fwd: [cryptography] Which encryption chips are compromised? 
you ask interesting questions Dan, and draw useful conclusions :)
some items to note:
- is this DUAL_EC_DRNG? don't think so. deadline is FY 2013.
- is this DUAL_EC_DRNG? the market for closed source, proprietary
crypto solutions is small (and growing smaller, :(
- is this XSTORE? it's been a while. but never should have been used
directly. see mtrngd with MSR bits set no whitening, max sample, max
freq. into mix + conservative estimate before /dev/random write.
some cryptographers and cypherpunks have become despondent or dejected
or demoralized by these events.
i see a larger picture: never before have so many been doing crypto less wrong!

@_date: 2013-12-11 00:10:24
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
I think there may be weaknesses in Intel's hardware RNG.  I took a
good look at Intel's hardware random number generator source. There's
a paper analyzing it here:
The basic idea is that back-to-back inverters, when powered on, flip
one way or the other randomly, sort of like DRAM memory when our
computer's power on.  By powering on a single pair of back-to-back
inverters over and over, they can generate a random bit per cycle, at
about 3 Giga-bits/second, which is amazing!  Here's my concerns about
the the paper:
- I saw no mathematical analysis of how much noise exists in the
system and how strongly it will influence the result each cycle. There
were generalities about how the noise could cause the output to be
random, but no numbers at all.
- There is an assumption that the capacitors are charged/discharged by
10% of the standard deviation of the noise.  I saw no justification
for this.  It seems they simply assumed best case.
- The paper is about as objective as a mother talking about her
children.  For example: "Overall, the Ivy Bridge RNG is a robust
design with a large margin of safety that ensures good random data is
generated even if the ES is not operating as well as predicted." Based
on what?
- I am not convinced they have the right model for the entropy source.
 They add noise to the bias on the capacitors, and compare that to 0
to determine the next output bit in their model.  I think the main
source of noise may be the randomness in number of electrons
added/subtracted each cycle, and that the back-to-back inverters in
the absence of other noise may be acting almost as an ideal
comparator.  However, if this were the case, even if there were 10%
noise in the number of electrons, there would be considerable
correlation between bits.
I also have questions about the design itself.  My main concern is
that noise on the VDD rail could easily determine the output.  For
example, if the transistors are mismatched, which of course they will
be, and the bias is set exactly right on the caps so there's a 50-50
chance of a 0 or 1, and suddenly VDD drops 10% due to a rising edge of
the the main system clock, then the inverter with higher gate
thresholds will become weak faster than the other one, thus
determining which one wins.  Since this circuit runs asynchronously
from the main system clock, I could easily see the 3MHz system clock
phase relative to the entropy generator clock determining most of the
results from the entropy source, while looking fairly random. Any
weakness in the raw random data stream is hidden from us by the AES
encryption done as a post-process.
I simulated back-to-back inverters in my .35u low power CMOS process
in SPICE to see if I could figure out how to make a practical circuit
using Intel's topology.  If it works, it would be fantastic.  I think
I can get rid of most of the supply noise issues.  I had a similar
problem in my "Infinite Noise Multiplier", so I switched to powering
the circuit with nothing but large W and L constant current sources,
and using the range from 0V to Vref, rather than 0V to VDD, because
Vref is stable relative to AVSS. However, I wasn't able to get enough
noise to make Intel's ciruit work, though that may be due to
limitations in the SPICE simulator.
Has anyone else had success using Intel's RNG topology?

@_date: 2013-12-11 00:10:52
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
I have to take back my criticism of Intel's RNG.  I got my sims
working for a version of their architecture in .35u CMOS, and it's
simply better than my "Infinite Noise Multiplier".  It's probably the
best true random noise generator ever.  I still don't like how their
schematic is seems highly sensitive to supply noise, but we don't know
what the actual circuit looks like.  Intel hasn't told us.
So, I'm going to modify it a bit to use the resistors available on my
chip and reduce the caps, fix the supply sensitivity, and I think I
can run 16 of these things in parallel at 100-200MHz on the tiny .35u
CMOS chip I'm designing.  I'll spit out the raw waveforms from the
inverters, buffered once, through 16 "analog" pins, so there wont be
any fear (hopefully) that I'm cooking the data on-chip, before you can
see it, and I'll open-source the schematics.  If there's a circuit
that can consume all 1.6Gbit/sec of this raw data, have fun with it!
On the digital side, I'll XOR bits together to get the bandwidth down
to something reasonable, which I can send over USB, and provide a
simple Linux driver.
This thing will definitely put out RF, but since I'm making the raw
data available at the pins, should I care?  By the way, this is just a
for-fun project at work.  I get to do a free chip design :-)

@_date: 2013-12-11 00:11:18
@_author: coderman 
@_subject: Fwd: [zs-p2p] [Cryptography] Fwd: [IP] 'We cannot trust' Intel and 
raw samples at 1.6Gb/s would be useful infrequently[0]; raw samples
from a trusted device extremely useful bitrate!
what is "my chip" and how can we find out more / support your efforts?
best regards,
0. to date i have only maxed out 400Mb/s raw VIA Padlock sources for
SSD FDE initialization and constructed experiments in temporal key
rolling.  it is however common to regularly consume on the order of
10Mb/s on a busy server, generating many keys, using crypto happy
software, etc.  (this is why every processor, every embedded device
should have a physical entropy source, with access to raw samples.
still waiting...)

@_date: 2013-12-11 07:17:09
@_author: coderman 
@_subject: Android IMSI Catcher detection 
the partnership with NGA to deploy them gives a hint: this is putting
USRPs up close and personal to target for exploitation.
(the USRP's are definitely more portable than my favorite SDR, the Noctar[0]!)
given the obtained bits mentioned (WLLids, DSL accounts, Cookies,
GooglePREFIDs) gathered and then handed off to TAO for further QUANTUM
INSERT fucking of target systems it is likely they are doing GSM/cell
MitM to observe identifiers, along with WiFi attacks, and other egress
rather than deploying baseband exploits or deep active attacks
directly against the devices or other networks they're communicating
thus CNE in this case is cell MitM/WiFi pwn with a USRP rogue tower to
get identifiers for TAO.  and TAO is where they get dirty with "remote
exploitation" of the device itself and other targets on networks it
we've seen how they have a smorgasbord of weaponized exploits to cover
the gamut of target hardware and technical acumen in the QUANTUM
INSERT / TURMOIL / TRAFFICTHIEF / MUTANT BROTH / etc, etc. style
efforts.  it appears they're using this same infrastructure where
possible for mobile; restricting CNE on the ground only to target.
best regards,
0. Pervices Noctar

@_date: 2013-12-11 07:22:12
@_author: coderman 
@_subject: Android IMSI Catcher detection 
see also this section on the OPEC hacks:
Heres how the NSA and GCHQ go after an organization like OPEC step by
step, based on an analysis of the NSA and GCHQ documents exposed by
Step 1: Identify. Using the NSA-built packet capture and inspection
system called TURMOIL, the agencies filter through Internet traffic at
a network choke point looking for specific "fingerprints" in traffic
that identify users with the organization being targeted. Data from
TURMOIL gets pulled into a number of traffic analysis tools, such as
XKeyscore and TRAFFICTHIEF, which do different sorts of packet
XKeyscore is the NSA's distributed search engine, catching a large
chunk of international Internet traffic for analysis. It helps find
things deep in the clutter of the Internet that analysts might miss by
allowing them to use search terms to find things in both live and
cached Internet traffic.
TRAFFICTHIEF, on the other hand, is much more focused. It filters for
very "strong" indicators, like known sets of IP addresses, addresses
within e-mail traffic, or user names in logins to social networks or
other services. It provides less depth of analysis than XKeyscore, but
it can handle much larger loads of data because it is more selective
about what it processes.
Together, the tools can be used to identify the systems used by an
individual or organization, including ranges of addresses that they
may use from work or home.
Step 2: Target. Using the profiles built using the surveillance tools,
the agencies can then identify potential points of attack. XKeyscore,
for example, can be used to search for patterns that identify known
security vulnerabilities within a range of addresses. Web visit
histories, e-mail traffic, and other data are analyzed looking for the
most likely (and least detectable) approach to gain access, and a
specific attack plan is crafted, including the identification of where
to launch the attack from.
At the NSA, this sort of thing is the work of Tailored Access
Operations. In the case of OPEC, the targeting process apparently went
on for several years as the NSA sought openings for an attack.
Step 3: Attack. Depending on who the target is, the NSA and GCHQ have
a variety of options. The least costly is to use access provided by
one of the intelligence agencies' telecommunications "partners" who
own network equipment at an exchange or other choke point that the
target's Internet traffic passes through. The agency running the
attack can use that access to introduce changes to Internet routing
tables that detour the targeted individual's traffic. But in some
cases, the NSA and GCHQ may have to perform "unilateral" taps on
network backbones to gain that level of accesstargeting a piece of
network hardware to take over or splicing directly into the target's
own connection to the Internet.
It's not clear which attack the NSA used to gain access to OPEC's
systems, though the GCHQ used a Quantum attack two years later to gain
its own very special access to the cartel's network. In the case of
the Belgacom hack, the GCHQ used a Quantum insert attackrouting the
Web requests for LinkedIn and Slashdot from the engineer being
targeted to a server posing as those sites. The NSA has used the same
approach to intercept traffic to sites such as Google.
The man-in-the-middle server can present content from the actual sites
the target intended to visit, but it can also add content to the
traffic, using what's called packet injectionmodifying the contents
of the data as it passes throughand intercept the user's credentials.
And by using a forged certificate, the NSA can intercept encrypted
traffic intended for the destination site.
Once the user has connected to the fake server, the intelligence
agencies can use the connection to launch attacks against the target's
Web browser to install monitoring software or other malware, using
similar techniques to those used by hackers. They can also use
credentials exposed via the man-in-the-middle attack to gain access to
other accounts owned by the target and to troll through connections in
those services that might be potential targets.
Step 4: Exploit. Once the target's computer has been successfully
attacked, the effort begins to look much like that of the Chinese
cyber warriors' attack of the New York Times or what cyber criminals
typically do when they score access to high-value targets. The
agencies' hackers work to stealthily expand their level of access,
using customized remote administration tools to grab user privileges
and gain access to other network resourcesmail servers, file servers,
and other network systems. They then start to "exfiltrate" data from
these systems and deliver them to analysts.

@_date: 2013-12-11 14:08:46
@_author: coderman 
@_subject: Android IMSI Catcher detection 
CNE+TAO as non destructive espionage (politics)
  but they also play
CNE+TAO as kinetic force multiplier (war)
so the answer is: both!  depending on the target...

@_date: 2013-12-11 18:04:39
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
Ivy Bridge is the codename for a line of processors based on the 22 nm
manufacturing process developed by Intel. The name is also applied
more broadly to the 22 nm die shrink of the Sandy Bridge
microarchitecture based on FinFET ("3D") tri-gate transistors, which
is also used in the Xeon andCore i7 Ivy Bridge-EX (Ivytown), Ivy
Bridge-EP and Ivy Bridge-E microprocessors released in 2013.

@_date: 2013-12-11 18:16:07
@_author: coderman 
@_subject: Android IMSI Catcher detection 
Regarding the CCP FY 2013 goals per
"Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4G/LTE)
networks via enabling. [CCP_00009]"
i wonder if they upgraded to N210 (pairs?) for good 4G/LTE performance?

@_date: 2013-12-11 19:01:31
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
"used in Virtual Private Network" == PPTP,IPsec,OpenVPN,etc.
"Web encryption devices" == in my interpretation, this is any targeted
hardware with the vulnerable chip.  it could be a tablet, a desktop,
and rack mount server...  any of these platforms could speak VPN or
Web crypto.  TAO/SCS do like to get into the switches though ;)
mostly "cloud infrastructure", "software defined data center", and the like:
back in the day, Sun got tired of the (relatively) slow performance
and latency of crypto offloading via bus and simply threw it into the
core.  you were still offloading crypto, but within the CPU.
also note that endpoint compromises sufficient to decrypt VPN or
secure web traffic is already present in TAO/CNE's tasking.  this
effort [CCP_00009] may focus on VPN concentrator / secure web proxy
deployments specifically to handle the RDRAND lookup per their private
starting counter.
previous back doors have also used entropy leakage sufficient to bring
a brute force attack into reasonable effort, while still denying third
parties a class break of the entropy / keys used.  this type of key
space search is not done on the ground with portable CNE but instead
back at SCS...
on a related tangent, the lack of additional disclosures is quite
frustrating.  this entire conversation would be resolved in a glance
if $the_snowden_gatekeepers were acting in the public interest.  :/
best regards,

@_date: 2013-12-11 23:41:41
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
i remember seeing software to do this, but for the life of me cannot
find it.  anyone?
my favorite redaction technique is still the Adobe white text on white
background in PDF trick; combine with a filter for CONFIDENTIAL /
PROPRIETARY and you've got a fire hose of informative flotsam...[0]
best regards,
0. "The Revenge of Distance: Vulnerability Analysis of Critical
Information Infrastructure"
  back when Sean Goreman's work and post 9/11 hysteria combined to drive
critical infrastructure information into access controlled obscurity
(not even FCC outage reports public!) i used this technique with
custom deep web crawlers for court documents and other technical
references.  code doesn't care about color ;)   thus fiber counts
along specific rights of way allocated to named customers provided the
specific capacity information needed to make useful models for
measuring "spatial implications of telecommunications infrastructure
susceptibility to targeted attack".  this was the first time i wrote
code that actually scared/disturbed me :o

@_date: 2013-12-12 06:08:35
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
i see your skepticism, and i raise you a retort! ;)
i even have a list of candidates you can experiment with to confirm
Intel Ivy Bridge as best fit. [0]
plus a few more things, e.g. your ~250-300million $USD/year budget goes toward:
"actively engag[ing] the US and foreign IT industries to covertly
influence and/or overtly leverage their commercial products' designs
[... to] make the systems in question exploitable through SIGINT
collection (e.g., Endpoint, MidPoint, etc.) with foreknowledge of the
modification. and, Insert vulnerabilities into commercial encryption
systems, IT systems, networks and endpoint communications devices used
by targets.
only with "foreknowledge of the modification" are you able to utilize
this backdoor. (NSA does not like to share)
also, this year by end of year, in 2013 you expect to:
- Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4GL/LTE)
networks by inserting vulnerabilities.
- Complete enabling for [well recognized name] encryption chips used
in Virtual Private Network and Web encryption devices.
and last but not least,
- Shape the worldwide commercial cryptography marketplace to make it
more tractable to advanced cryptanalytic capabilities being developed
by NSA/CSS.
Ok, given those requirements. Who fits the bill?
High end platform:
Intel targets what it believes is a significant growth opportunity to
bring the Intel Architecture into a rapidly evolving networking space.
Intel added to its portfolio with the introduction of the Highland
Forest platform, which combines the vendors Xeon E5-2600 v2 CPU with
its new Coleto Creek chipset. Price said Highland Forest  which can
pack up to 20 2.4GHz Ivy Bridge CPU cores  will offer two to six
times the performance of the previous Crystal Forest platform, which
was launched in October 2012.
Highland Forest, with Intels Data Plane Development Kit, can deliver
up to 255 million packets per second (p/s)  more than the 140 million
p/s from Crystal Forest  as well as security capabilities of 110
Gigabits per second of IPsec and 200 Gb/s SSL security for encrypted
IPsec (VPN) and SSL (Web crypto) and lots of it!  sounds interesting.
tell me more!
other market points of note:
- "Intel currently has over 15 SDN/NFV qualification trials underway
with carriers in all major regions.  Schooler emphasized that Intel
has no intention to sell directly to service providers and is fully
committed to launching an Intel Network Builders Ecosystem of industry
players supporting the Intel Architecture."
- "6WIND Announces Availability of Support for Intel Xeon Processor
Platform for Large-Scale Communications Infrastructure Systems,
Formerly Called Highland Forest 6WIND announces the availability of
support within the 6WINDGate software for the Intel Xeon Processor
Platform for Large-Scale Communications Infrastructure Systems,
formerly called Highland Forest. With its optimized support for the
Intel QuickAssist Technology that provides hardware acceleration for
encryption and compression, 6WINDGate delivers best-in-class
performance for networking applications such as WAN optimization, VPN
appliances, firewalls and Unified Threat Management (UTM) systems." -
funny they seem to distance themselves from "Highland Forest" and "Ivy
Bridge" in this press release and product launch...  [
 ]
they sound interesting, like they sell to many industries at large
scale.  are they a popular company/product?
 ""6WINDGate is already deployed in tens of commercial LTE networks
throughout Asia, Europe and North America, while also being used by
multiple tier-1 suppliers of enterprise and cloud networking
hey look, LTE! ...
ok, so that's a little suspect.  what's that, there's more you say?
"I am so glad I resisted pressure from Intel engineers to let
, "Oh, I should add that just today I had to fight back an attempt by
a Red Hat engineer to add a configuration option to blindly trust
RDRAND and bypass the entropy pool"
then the FreeBSD change of heart.
hey Wind River, how are you using RDRAND?
now what about Intel themselves, are they also pushing the chip?
Intel officials are making aggressive moves to expand the reach of its
silicon beyond servers and into other parts of the data centre.
Schooler said the company has been making products for networking gear
for about a decade, and has made significant strides in recent years.
Its also made several acquisitions  such as of Sensory Networks,
Ethernet chip maker Fulcrum Microsystems and networking software maker
Aepona, whose technology enables telecoms and cloud service providers
to offer more services on their networks.
Intel is looking to take advantage of the growth opportunity
networking represents, Schooler said. The market Intel is targeting is
about $16 billion (9.7bn), and the chip maker currently has about 5
percent of it. Along with its x86 architecture, Intel also is
developing accelerator chips for such jobs as packet inspection and
whew.  that's a lot of context and circumstance.  let's look back over
your goals for 2013:
Make gains in enabling decryption and Computer Network Exploitation
(CNE) access to fourth generation/Long Term Evolution (4GL/LTE)
 - AFFIRMATIVE!
Complete enabling for [Intel Ivy Bridge] encryption chips used in
Virtual Private Network and Web encryption devices.
- AFFIRMATIVE!
Shape the worldwide commercial cryptography marketplace to make it
more tractable to advanced cryptanalytic capabilities being developed
by NSA/CSS.
- AFFIRMATIVE!
i will admit that i am continually impressed by NSA/SCS achievements.
they're extremely competent!
my reading between the lines: it is not a special chip, it is a
special collection of many of them (20+) handling tier-1 core traffic
encryption, which is an excellent point to aggregate a vulnerability
in keying ciphers. (ignore public key for now, since we can just focus
directly on session/temporal keys!)
0.  please to be experimenting with datas:
Interface Masters Technologies
Freescale Semiconductor
Alteon SSL Accelerator
Nortel SSL Accelerator
Strangeloop Networks
Riverbed Technology
Coyote point systems
Crescendo Networks
Microchip PIC32MZ
Barracuda Networks
Kemp Technologies
Check Point VPN-1
Sun Microsystems
Foundry Networks
Cavium Networks
Cavium NITROX
Juniper Networks
Nortel Networks
Array Networks
Intel Ivy Bridge <- only this is right length in justified context shown
Forum Systems
Cavium Nitrox
CAI Networks
A10 Networks
Cisco Systems
Citrix Systems
Sun SCA6000
MIFARE Plus
Network Box
Coleto Creek
F5 Networks
Cisco PIX
parting words:
On April 17 at the Open Networking Summit, Intel executives laid out
the companys strategy around data center networking and the
burgeoning trend of software-defined networking (SDN). They also
showed that their efforts will expand beyond simply supplying the
processors for networking hardware. The company unveiled reference
architectures designed to help enterprises, cloud service providers
and telecommunications companies more quickly create hardware and
software for SDN and network-function virtualization (NFV), moves that
could bring Intel into closer competition with the likes of networking
giant Cisco Systems and chip maker Broadcom.
 - don't let them get away with it!
open up raw access to entropy sources!!
don't discriminate against the unit, one is prime!!!

@_date: 2013-12-12 06:52:20
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
one last amusing note, Google has gone whole hog on SDN:
  how amusing would it be if they implemented inter-DC IPsec keyed with
RDRAND directly on compromised cores in one of these Highland Forest
like SDN deployments?
i can already see the updated napkin sketch now, and imagine the
streaming swears pouring forth from the googlies once uncovered...

@_date: 2013-12-12 08:20:44
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
let it be known:
in the event of my untimely demise under suspicious circumstances, i
will my coins to JYA so he may bless my passing with grand oration and
strong tale as he is so adept at providing.  *grin*
on a serious note, the useful steps are clear:
1. Intel releases raw access to noise samples
2. NIST defining and mandating a design that also supports raw sample
access, (we could change subject here to discuss something pleasant
like on-line checks and continuous checks,)
3. OS distributions include userspace entropy scavenging daemons
(haveged, dakarand, etc) to complement properly vetted hardware
entropy sources run in a conservative fashion.  default is set safe,
not fast.
is that so much to ask?

@_date: 2013-12-12 08:42:02
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
the bulk of 2012 was consume user hardware.  the endpoint is a totally
solved problem (read: trivial to exploit in many ways, all day, every
day, per the docs)
only server Ivy Bridge: Xeon E3 in mid-2012.
the cores pushed in the SDN initiatives above came out not so many months ago...
high capacity crypto aggregation points like this are an ideal target,
with backdoor keying of VPN/SSL the ideal (passive) attack with their
view of target's long haul fiber.
but not released, and "enabling" means tied into X-KEYSCORE,
TRAFFICTHIEF, whatever else gets draped off UPSTREAM...
the backdoors for all the other vendor hardware happened in years
prior.  HSMs and crypto accelerator gear is not exactly a vibrant or
competitive market.  in fact, these companies never seem to die, just
carry on with decent margins riding on incremental design upgrades
until they're bought out by a larger/growing competitor. ;)
of course, this could be because companies like Sun charge $9,999 for
an HSM/accelerator that is at best a reasonable cost at $1,499...

@_date: 2013-12-12 09:18:09
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
this does bring up an interesting point:
while it may be more efficient to use the same "key" for the DRBG
output across all processor lines, it would be more secure to use a
different key per line.  this implies that each iteration of Sandy
Bridge -> Ivy Bridge -> Haswell needs to be "enabled" by CCP, with
Xeon E5 debut in 2013 as discussed.
for Sandy Bridge, this would have shown in 2010? and unless in network
equipment described simply as "enabling decryption for Sandy Bridge
used by $operating systems and $applications."
sadly we'll have to wait a while to confirm this conjecture for
Haswell.  and we'll have to wait forever for more leaks apparently, as
the continuing decline of details demonstrates...
best regards,

@_date: 2013-12-12 09:23:50
@_author: coderman 
@_subject: Fwd: [liberationtech] PrivateSky Takedown 
Certivox Asked That We Share Their Side of the Story on the PrivateSky Takedown.
The real story on the PrivateSky takedown.
Posted by Brian Spector on Thu, Dec 12, 2013
With the story about our PrivateSky takedown now public, I want to
take the opportunity to clarify a few points in various articles that
have appeared since yesterday covering the story.
Some headlines strongly infer our friends at GCHQ "forced" us to take
PrivateSky down. That's not the case.
Secondly, a very important point wasn't printed. GCHQ couldn't, by
law, request a blanket back door on the system. There are a very rigid
set of controls that mean only specific individuals can come under
surveillance. The legal request for such surveillance has a due
process that must be stridently followed. At no time did I or anyone
at CertiVox talk about CertiVox in relation to any RIPA warrant, only
the generic process by which these warrants are served.
By saying "our friends at GCHQ", there is no facetiousness intended.
The team at CertiVox have the upmost respect for the folks we
interacted with at GCHQ. They took the due process I outlined in the
previous point very seriously. We found that as an organisation, and
every individual involved there, were as worried about a breach of
public trust as much as we are.
Finally, I believe very strongly the following should be a larger part
of the public discourse of these subjects. What everyone needs to
understand is that every developed democracy in the world, even where
privacy rights are enshrined to the maximum efficacy by statute, has
laws on the books that mandate that Internet Service Providers have
facilities to work with law enforcement for the purposes of legal
intercept, to enforce public safety and security.
Being L.I. capable is a very important set features and functions that
must be in place for any credible, commercial service on the Internet.
In endeavouring to make PrivateSky as secure as possible, we
overlooked this critical requirement when we built PrivateSky.
When CertiVox positioned PrivateSky as the easiest to use and most
secure encrypted messaging service, we really had two significant
points of differentiation. First, even though we held the root
encryption keys to the system, it was architected in such as way that
it would have been all but impossible for our internal staff to snoop
on our customer's communications, or for the service to leak any of
our customers data. Secondly, our possession of the root keys, and
our use of identity based encryption, made the system incredibly easy
to use. For the user, there were no private or public keys to manage,
every workflow was handled for the user in an easy to grasp pure HTML5
interface, no hardware or software required, just an HTML5 browser.
We boxed ourselves into a feature set and market position that when
called upon to comply with legal statues, we simply had no alternative
but to shut the service down. We built it, but we couldn't host it.
Why? Because as you can probably surmise, there is an inherent
impedance mismatch between being able to host a commercial
communications service that gives the upmost in privacy to its users,
against any breach, whilst at the same time being able to operate
safely within the confines of the law as it is on the books in most
countries on the planet.
In summary, it's the abuse of the communications interception in the
Snowden revelations that has everyone up in arms, as so it should. But
thats not what happened with PrivateSky.
What is our next move?
Watch this space.
Liberationtech is public & archives are searchable on Google.
Violations of list guidelines will get you moderated:
Unsubscribe, change to digest, or change password by emailing
moderator at companys at stanford.edu.

@_date: 2013-12-12 17:17:03
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
the worst kind of xpost of all?
every day without RDRAW is another day of my life with provably less
information theoretic meaning.  ;)
two chips or two families or two architectures or ...
is this a game of twenty questions? can we do a reddit AMA for the
leakers with their stash at the ready?
you know, if we had more documents providing context,
past experience tells us they like attacks universally effective,
unidirectional, silent/random-looking (without secret knowledge), and
don't mind expending custom hardware and algorithms to do it.
Dual_EC_DRBG doesn't count - that was a "jeezus, everyone asleep at
the wheel.  i bet we could get this approved!" moment.
triggering is active, observable (potentially), and usually
re-playable.  the only "delivered payloads", ala
EGOTISTICAL*/ERRONEOUS*, appear to be for confirmation pinging or
identification, and memory resident forensic/exfiltration run locally
on the host.  even the slides you link to note the OPSEC concerns of
"adversarial actors" (i think that's us on this list?)
sure.  note how this is also more complicated, with higher risk?  if
there was a better way i bet they'd choose it!
also, Intel and ARM, Apple and ARM, Apple and VIA, etc.
  you're not helping my pleading and cajoling for RDRAW sir.
on a related note, if Intel were to decide to include RDRAW in next
CPU line design, how long would it be to retail channels? >3yrs?

@_date: 2013-12-12 17:55:56
@_author: coderman 
@_subject: [cryptography] Which encryption chips are compromised? 
correction: persistence after reboot also has been stated to be
performed, though optional.  per Bruce's write up[0],
1. target identified (at endpoint or observable mid-point)
2. QUANTUM INSERT redirect to FoxAcid server
3. FoxAcid picks loader exploit according to: target value, exploit
value, target skill, other factors.
4. Loader exploit delivered to target
5. confirm success?  if no, abort.
6. With loader active, run two basic first pass payloads:
7. Collect configuration information (apps, registry, settings, etc.)
8. Collect location information
9. Escalate to persistent infection, run arbitrary other plugins, etc.
in any case, this is more consumer endpoint focused.  not applicable
to embedded VPN/HTTPS devices.
0. Bruce Schneier's attacking Tor article for the Guardian:

@_date: 2013-12-12 18:21:33
@_author: coderman 
@_subject: How long does it take to design and release a chip? 
using Sandy Bridge as a reference: 4 years design to demo, 1-2 years
demo to available.
design began 2005
demo'd in 2009
shipping in 2011

@_date: 2013-12-12 22:25:50
@_author: coderman 
@_subject: Multiple Plots by US, UK to Kidnap Edward Snowden 
ah FSB; you crack me up!
'''A senior officer of Russian counter-intelligence said: "Although
the Federal Security Bureau does not do anything about human rights
activist Snowden, the service has been active in counterintelligence.
I am pretty sure that kidnaping the former NSA employee will be
dramatically challenging." He also thanked "former NSA employees and
journalists for publishing such information...'''
Edward Snowden can be kidnapped from Russia?
10.12.2013 14:57
Edward Snowden, the whistleblower of NSA's total control systems can
be kidnapped from Russia. This is a priority for the British MI-6 and
the British Embassy, former NSA agent Wayne Madsen said, referring to
his colleagues.
Of course, nothing is known whether the CIA received the task, and
whether the U.S. Embassy is going to be involved in the activities to
try to kidnap Snowden. However, the British Embassy has already
tracked calls and letters of Snowden's "inner circle" and begun to
"dig up" their contacts in Moscow.
According to The Guardian, Snowden has the information, the disclosure
of which could become a nightmare for the U.S., even though the
fugitive NSA specialist decided not to disclose some of his data. In
addition, The Guardianadmitted that the media have so far published
"only 1%" of available information about NSA's total control over
billions of people in different countries.
Nevertheless, even this one percent has already made the UK
authorities introduce outright censorship against those who reveal
secrets of "global surveillance."
In particular, Wayne Madsen said that his girlfriend, who previously
worked for the National Security Agency as an expert on the Russian
language, tried to contact Snowden's acquaintances. Afterwards, she
was invited to come to the British Embassy and undergo special
training. She was also asked to report of FSB's interest in her
persons and communications.
The press quoted a former NSA expert, who said that the job to find
Snowden was of the highest priority for the embassy. Moreover, it was
said that the future operation to kidnap him involved number one MI-6
officer at the embassy, who worked under diplomatic cover as the
director for regional security.
The Center for the Study of Globalization has previously reported that
should the operation be successful, Snowden would be delivered to the
UK or the U.S. For the time being, the flywheel of total wiretapping
that Snowden launched was working against him to the utmost. "MI-6
intelligence agencies have begun to analyze the information they were
able to obtain through intelligence," the statement from the center
A senior officer of Russian counter-intelligence, whom Politonline.ru
confidentially managed to talk to, said: "Although the Federal
Security Bureau does not do anything about human rights activist
Snowden, the service has been active in counterintelligence. I am
pretty sure that kidnaping the former NSA employee will be
dramatically challenging." He also thanked "former NSA employees and
journalists for publishing such information, but added that
operational, technical and other measures to counter intelligence and
other illegal activities of foreign secret services on the territory
of Russia were  constantly maintained.
It only remains to add that the CIA has recently created a special
section in Russian on its official website, in which the department
offered Russian citizens (!) to join American intelligence. To choose
from, for example, the CIA offers engineering and technical
directions, a linguistic job, a secret agent with the knowledge of
Russian language and experts in business and analysts. The CIA
reportedly hopes to obtain classified information from newcomers in
the above areas to establish a new database of agents.

@_date: 2013-12-13 23:13:30
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
any details on "Mackerel: A Progressive School of Cryptographic
Thought" or "The Factoring Dead: Surviving the Cryptopocalypse" ?

@_date: 2013-12-14 04:33:31
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
as per the FreeBSD announcement[0] and others[1][2] direct use of
RDRAND as sole entropy source is not recommended.
from Westmere onward you could use AES-NI to make crypto fast in
OpenSSL.  a common theme is to initialize OpenSSL via
ENGINE_load_builtin_engines() which lets OpenSSL take advantage of
this acceleration.
with Sandy Bridge you also got RDRAND. now load_builtin_engines
results in the application using RDRAND directly for all entropy, in
addition to accelerating AES.
if you are using an application linked with openssl-1.0.1-beta1
through openssl-1.0.1e you should do one of the following:
a.) rebuild your OpenSSL with OPENSSL_NO_RDRAND defined.
b.) call RAND_set_rand_engine(NULL) after ENGINE_load_builtin_engines().
c.) git pull latest openssl with commit: "Don't use rdrand engine as
default unless explicitly requested." - Dr. Stephen Henson
the OPENSSL_NO_RDRAND option is recommended; an inadvertent call to
load engines elsewhere could re-enable this bad rng behavior.
best regards,
0. "FreeBSD Developer Summit: Security Working Group, /dev/random"
  1. "Surreptitiously Tampering with Computer Chips"
  2. "How does the NSA break SSL? ... Weak random number generators"

@_date: 2013-12-14 06:42:55
@_author: coderman 
@_subject: cognitive dissonance in threat modelling? 
i hope it was worth it for them!  'cause this is going to be expensive...
Matthew Green posted insights on how one might implement backdoors in chips:
  as well as the "Weak random number generators" attacks:
  regarding the unredaction automation: the typographic interpolation
trick discussed on the list, matching type face with justified spacing
with candidate word(s), is a really annoying idea and won't get out of
my head.
 (i tried to distract and forget with a Tor patch -
 - to no avail ;)
currently playing with scipy, skimage to:
- obtain from human initial document image
- obtain from human seed words / dictionary for matching
- misc. contrast / levels / etc conditioning for text optimized monochrome
- mask document image into text and non-text areas
- edge detect, align to horoz (for selections by x/y)
- broad region detect text rows into individual row images
- region detect individual chars per row image then assign char value via OCR
- insert human in loop to confirm / correct OCR row by row
- insert human to select redact line + redact area
- interpolate justified components: character spacing, word spacing, etc.
- iterate over known text with candidate fonts until best match.
- iterate over candidate words in best font until best match.
- success?  what confidence? (GOTO 10)
(the extra work for char by char and whole doc dis-assembly is in case
a "re-assemble scanned chars into candidate" rather than "match font
and re-produce text candidate" mode is needed.)
something better, Beuller?  ... Beuller?
... this won't be the last time i find this code useful!
current working set, including known wrong (please add suggestions :)
FeliCa and AMD
Nortel Networks
Apple and ARM
Array Networks
Cisco and Atmel
Philips and VIA
HiFn and Atmel
Cisco and ARM
Cisco and HiFn
Intel Ivy Bridge
Intel RDRAND
Atmel and IBM
Atmel and VIA
Apple and VIA
Intel and AMD
Intel and ARM
Forum Systems
VIA XSTORE
Cavium Nitrox
CAI Networks
A10 Networks
Cisco Systems
Citrix Systems
Sun SCA6000

@_date: 2013-12-14 08:40:34
@_author: coderman 
@_subject: [Full-disclosure] RDRAND used directly when default engines 
i think the word you're looking for is "Feature".
... but you and me are not the customer.   ;)

@_date: 2013-12-14 09:25:49
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
this won't leave you vulnerable, but it will crash your app.  not
broken convention:
      /* If we are using a version of OpenSSL that supports native RDRAND
         make sure that we force disable its use as sole entropy source.
         See  */
      if (SSLeay() > OPENSSL_V_SERIES(1,0,0)) {
        t = ENGINE_get_default_RAND();
        if (t &&
            (strcmp(ENGINE_get_id(t), "rdrand") == 0)) {
          log_warn(LD_CRYPTO, "OpenSSL is using RDRAND by default."
                   " Attempting to force disable.");
          ENGINE_unregister_RAND(t);
          ENGINE_register_all_complete();
        }
      }
see best regards,

@_date: 2013-12-14 10:36:56
@_author: coderman 
@_subject: Fwd: Jacob impervious to "Rubber Hose Cryptanalysis" performed by 
this is pretty amusing :P
(and needs a "Knuth is my Homeboy" homage?)
Layers of the struggle privacy vs surveillance, in my picture of the year
This is the picture of the year for me, on so many different layers:
  [view the image directly via:
    ]
Stewart Baker, ex-NSA general counsel, and Jacob Appelbaum, internet
freedom activist/hacker/journalist (left, right).
They pretty much symbolise the two sides of the global scandal of the year.
They also symbolise the attitudes of both sides.

@_date: 2013-12-14 13:52:13
@_author: coderman 
@_subject: c4-r3kN.txt (urls) 
there are variations... i am afflicted with the contagious and acute
Entropus Major virus.  and now, any crypto system of which i am not
able to see the input randomness, by precision jitters or max rate
sampled freewheelers, or even that crazy faraday'ed up leadzone with
Geiger counter she told you about at BSides,
but hide that sweet sweet river of unrelated bits behind a bytecode
block??  that's just not cool!
until then, i've "borrowed" Peter G's d20's for a bit - hope he
doesn't need to roll them any time soon.
 ;P
i never considered prohibition as constraint on state of mind in public,
mainly thinking along monetary and covert economic activity angles.
but considering the public, and the multitudes of social scenes no
longer "lubricated" or under shadow of persecution, this would have a
direct and personal impact on many.
certainly a world removed from the producers and distribution
activity, which tends to monopolize the zeitgeist of the prohibition
crypto-compromise as frantic inferno is not quite right.,
the impact is almost invisible, until it is dire and potentially life-ruining.
global compromise for ever-present surveillance is crypto-HIV
 sure, you're fine now.  probably a while, no concerning symptoms.
then OMGWTFBBQ punctuated equilibrium, over-reaction,
suddenly crypto-AIDS just ate your life and shat out
 terminal-solitary-confinement and/or financial ruin.
plenty of company with all the other susceptible individuals, more than
you imaged...  equally destroyed by a silent corrupter too easy to ignore
they call it "Tailored Access" and "Computer Network Exploitation" for
... when they aren't having the FBI violating domestic providers in
their NSL hole.
it's legit.
on a more serious note, regarding the assumption:
 "if everything is backdoored already, essentially key escrow exists"
NSA has stated that many of their BULLRUN techniques are incredibly
fragile.  a number of them now burned in leaks, many yet to get
stuffed. if they "did it risky"[0], perhaps feeling emboldened by the
seeming success of Dual_EC_DRBG and friends, a common key / reduction
hidden behind AES-128 rounds could be discovered, independently
confirmed, and properly attributed.
so not only can the backdoors be broken up, replacements which are
resistant to compromise will take their stead.  "everything" becomes
"much" becomes "very little" until ideally such invasive tactics are
reserved for HUMINT tasked "good ol'e detective work" with legal
bonafides judged according to public laws and applicable to all
persons on earth, not just tribal deference pointed inward.
the jury is out; there are encouraging signs... but first, back to
those raw samples!!
best regards,
0. "Some thoughts on suborning encryption chips"
  A much easier approach is to simply eschew safety altogether and use a
fixed AES key that's common to all chips.
  [ED: or fixed modification to the AES-CBC-MAC compressor then masked
by the DRBG in front using "Stealthy Dopant-Level Hardware Trojans."]
But the NSA would never do something that risky. Right?

@_date: 2013-12-15 18:11:20
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
"Join us at Columbia Law School as renowned security expert Bruce
Schneier talks with Eben Moglen about what we can learn from the
Snowden documents, the NSA's efforts to weaken global cryptography,
and how we can keep our own free software tools from being subverted."

@_date: 2013-12-15 19:01:47
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
Peter's BlueHat talk on congitively flawed humans also excellent:
  so cypherpunks,  if you write code that you want to be useful:
don't write code with assumptions and admonishments inherently unheedable.
write code with awareness and compensation for silly human inclinations!

@_date: 2013-12-15 19:11:44
@_author: coderman 
@_subject: BlueHat v13 crypto talks - request for leaks ;) 
this also implies:
 "There is only one Mode, and it is Secure."

@_date: 2013-12-15 19:30:32
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
your understanding is flawed.  let me clarify:
the NSA does not currently break Tor on demand at the protocol level.
all indications are this is currently true.
the NSA and others have great success around Tor by opportunistically
watching users fuck up (see other usability thread), by pwning their
horribly insecure systems (0days as far as the eye can see..), and by
actively manipulating user paths to the Tor network or destination
"forget your global passive adversary threats, active denial and
manipulation of service attacks are _really_ scary!"
said another way, breaking Tor at protocol level is currently too
expensive a solution to the same ends provided by much cheaper means.

@_date: 2013-12-15 20:57:56
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
of course.  it's also expensive, relative to other options. i'm saying
NSA spends money carefully.
never said either thing.  i'm also long on the record advocating for
the next generation of low latency anonymous networking that _does_
provide strong defense against traffic analysis.  turns out the
details are, um..  complicated ;)
i'm glad that is not, in fact, my reasoning.
of course there are more sophisticated means available to them; that
will always be the case.  they've got BILLIONS and BILLIONS every
year, for their projects.
the point is not making something "NSA proof", which is an ill defined
and open ended venture.  the point is increasing the cost of their
efforts and narrowing their scope.
the more money they spend getting less and less in return, the better!

@_date: 2013-12-16 00:11:42
@_author: coderman 
@_subject: Aqua - a high bandwidth anonymity system that resists traffic analysis 
this seemed to get lost in the hubub over the summer,
Towards Efficient Traffic-analysis Resistant Anonymity Networks
Stevens LeBlond, David Choffnes, Wenxuan Zhou, Peter Druschel, Hitesh
Ballani, and Paul Francis
August 2013
Existing IP anonymity systems tend to sacrifice one of low latency,
high bandwidth, or resistance to traffic-analysis. High-latency
mix-nets like Mixminion batch messages to resist traffic-analysis at
the expense of low latency. Onion routing schemes like Tor deliver low
latency and high bandwidth, but are not designed to withstand traffic
analysis. Designs based on DC-nets or broadcast channels resist
traffic analysis and provide low latency, but are limited to low
bandwidth communication.
In this paper, we present the design, implementation, and evaluation
of Aqua, a high bandwidth anonymity system that resists traffic
analysis. We focus on providing strong anonymity for BitTorrent, and
evaluate the performance of Aqua using traces from hundreds of
thousands of actual Bit-Torrent users. We show that Aqua achieves
latency low enough for efficient bulk TCP flows, bandwidth sufficient
to carry BitTorrent traffic with reasonable efficiency, and resistance
to traffic analysis within anonymity sets of hundreds of clients. We
conclude that Aqua represents an interesting new point in the space of
anonymity network designs.

@_date: 2013-12-16 00:27:16
@_author: coderman 
@_subject: request for transcript: Bruce Schneier and Eben Moglen discuss a 
this is all coming to a few conclusions, where we simply disagree:
a) the black budget was leaked, along with other leaks about technical
capabilities and programs and priorities.  intelligence community is
not immune to government budget pressure.  you insist there is a
limitless expansion, and an unlimited technical ability.  i disagree.
b) you insist Tor's origins and funding sources are proof of
malfeasance; they've responded by diversifying funding. (not to
mention scrutiny of Tor by external, mututally un-trusting parties.
you can look at the code yourself, and interface with controller and
path construction yourself, etc.)
c) we both appear to agree that limiting solutions to technical realms
is missing the bigger picture.  yes to political reform that cuts
funding and restricts scope. yes to judicial reforms which demolish
secret orders and secret courts. yes to social measures which value
and reinforce privacy. yes to educational efforts which empower
individuals to make privacy positive decisions, etc.
last but not least, i second the call to fix it.  help write something better!

@_date: 2013-12-16 01:09:27
@_author: coderman 
@_subject: fallout of NSA induced difficulties (lots of drinking, 
this is what happens when large sums of money are secretly spent to
prevent the event of secure inter-net:
(NIST could simply be bought, but IETF had to be turned in on itself..)
"IETF PKIX meeting minutes from the 56th IETF"
We were somewhere in San Francisco on the edge of the 56th IETF when
the drugs began to take hold.  I remember saying something like "I
feel a bit
lightheaded; maybe you should take notes...."  And suddenly there was a
terrible roar all around us and the sky was full of what looked like huge
OIDs, all swooping and screeching and diving around the RFC, which was about a
hundred pages long.  And a voice was screaming: "Holy Jesus!  Where are these
goddamn business cases?"
Then it was quiet again.  My attorney had taken his shirt off and was pouring
beer into his mouth, to facilitate the PKI standards-creation process.  "What
the hell are you yelling about?" he muttered, staring up at the neon lights
with his eyes closed and covered with wraparound Spanish sunglasses.  "Never
mind," I said.  "It's your turn to figure out the interop requirements."  I hit
the brakes and dropped the Great Pile of Paperwork at the side of the room.
No point mentioning those OIDs, I thought.  The poor bastard will see them
soon enough.
We had two bags of X.509 standards, seventy-five pages of PKIX mailing list
printouts, five sheets of high-powered constraints, a saltshaker half-full of
vendor hype, and a whole galaxy of requirements, restrictions, promises,
threats...  Also, a quart of OSI, a quart of LDAP, a case of XML, a pint of
raw X.500, and two dozen PGPs.  Not that we needed all that for the trip, but
once you get into a serious PKI RFC binge, the tendency is to push it as far
as you can.  The only thing that really worried me was the X.500.  There is
nothing in the world more helpless and irresponsible and depraved than a man
in the depths of an X.500 binge, and I knew we'd get into that rotten stuff
pretty soon.

@_date: 2013-12-16 08:20:32
@_author: coderman 
@_subject: Wyden spends weeks preparing for questions to intelligence officials 
an interesting read on the state of things.
Wyden does Oregon proud,
[only excerpted, whole thing is huge. waiting for cryptome to mirror... ]
Wyden estimates that he gets about fifteen minutes a year to ask
questions of top intelligence officials at open hearings. With the
help of his intelligence staffer, John Dickas, a thirty-five-year-old
from Beaverton, Oregon, whom Wyden calls the hero of the
intelligence-reform movement, Wyden often spends weeks preparing his
questions. He and Dickas look for opportunities to interrogate
officials on the gaps between what they say in public and what they
say in classified briefings. At a technology conference in Nevada the
previous summer, General Keith Alexander, the director of the N.S.A.,
had said that the story that we have millions or hundreds of millions
of dossiers on people is absolutely false. Wyden told me recently,
It sure didnt sound like the world I heard about in private. For
months, he tried to get a clarification from the N.S.A. about exactly
what Alexander had meant. Now he had the opportunity to ask Clapper in
public. As a courtesy, he had sent him the question the day before.
Wyden leaned forward and read Alexanders comment. Then he asked,
What I wanted to see is if you could give me a yes or no answer to
the question Does the N.S.A. collect any type of data at all on
millions or hundreds of millions of Americans? 
Clapper slouched in his chair. He touched the fingertips of his right
hand to his forehead and made a fist with his left hand.
No, sir, he said. He gave a quick shake of his head and looked down
at the table.
It does not? Wyden asked, with exaggerated surprise.
Not wittingly, Clapper replied. He started scratching his forehead
and looked away from Wyden. There are cases where they could
inadvertently perhaps collect, but not wittingly.
Wyden told me, The answer was obviously misleading, false.

@_date: 2013-12-16 08:29:55
@_author: coderman 
@_subject: Bruce Schneier to leave BT 
retaliation for helping expose intelligence community excesses and illegalities?

@_date: 2013-12-16 19:27:34
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
updated list with env suggestion:
a.) rebuild your OpenSSL with OPENSSL_NO_RDRAND defined
b.) call ENGINE_unregister_RAND() on "rdrand" engine followed by
ENGINE_register_all_complete() to unregister rdrand as default
c.) set OPENSSL_ia32cap="~0x4000000000000000" in global environment
(this is poor fix)
d.) git pull latest openssl with commit: "Don't use rdrand engine as
default unless explicitly requested." - Dr. Stephen Henson
"what is affected??" - someone
sorry, i am not your distro maintainer.  but the list includes,
potentially (depending on configure opts / runtime / etc):
RHEL 6.5, 7.0
Centos 6.5
Fedora 18,19,rawhide
Ubuntu 12.04, 12.10, 13.04, 13.10, trusty
Debian 7.0, jessie, sid
Gentoo stable&unstable
Knoppix 7.0.5, 7.2.0
Kali 1.0.5
Slackware 14, 14.1, current
... if ssh built with --with-ssl-engine. these all use OpenSSL 1.0.1+.
 (remember both ssh client and server may use engines!)
and other libs, like:
... which appear to use OpenSSL default engines.
but really, you should go check your shit.
best regards,
P.S. if anyone is aware of RDRAND engine backports to OpenSSL 1.0.0*
or 0.9.8* in any distros i'd like to know about it!

@_date: 2013-12-16 19:30:50
@_author: coderman 
@_subject: Aqua - a high bandwidth anonymity system that resists traffic 
i had this same reaction when i found their Link Quality Source
Routing mesh protocol research[0].  crazy times! ;)
0. "Self Organizing Wireless Mesh Networks"

@_date: 2013-12-17 14:22:48
@_author: coderman 
@_subject: Tor funding [was: ranting at Juan's hatebait rapaciously [before 
discuss a post-Snowden Internet]]
even more today :)
Over the past year, we have received many requests for us to accept
bitcoin donations. After careful consideration and research, we are
thrilled to announce that effective today The Tor Project is accepting
bitcoin donations. In partnership with Bitpay, bitcoins can easily and
directly be donated to support Tors ongoing mission of being the
global resource for privacy technology advocacy, research and
education in the ongoing pursuit of freedom of speech, privacy rights
online, and censorship circumvention. Check out ourdonations page now.
Bitcoin donations received by The Tor Project will be converted
directly to US Dollars.
Our decision to accept bitcoins has been well thought out and
researched from a financial accounting perspective with an eye on
passing our required annual A-133 audit. We believe we are the first
US 501(c)3 non-profit organization to test acceptance of bitcoins and
attempt to pass the US Government A-133 Audit Standard. Our 2013 audit
results, along with our past financial documents, will be made
available on our website once complete in 2014.
The Tor Project is also proud to be in the company of other visible
non-profit organizations accepting bitcoins including EFF and
Why is this important? The Tor Project needs your donations to
continue our mission and to keep the Tor suite of technologies ahead
with the growing threats to privacy and anonymity around the world.
Your donation made TODAY, through bitcoin, Paypal, Amazon Payments,
Givv.org, checks, money orders or bank transfers, will provide greater
security and privacy for millions around the world who use Tor every
Help us continue our mission!

@_date: 2013-12-17 14:46:10
@_author: coderman 
@_subject: Tor funding [was: ranting at Juan's hatebait rapaciously [before 
Moglen discuss a post-Snowden Internet]]
sort of, but not really.  still waiting on  ...

@_date: 2013-12-18 08:29:14
@_author: coderman 
@_subject: acoustic side channel attacks against TEMPEST shielded equipment 
interesting work on using poor quality sound (like from a phone) for
chosen cipher text attacks with key recovery for GPG.
also note that they use frequencies >10kHz.  as discussed in the high
frequency audio covert channel, this range is fairly contention free
and easily accessible to microphones in consumer electronics of
various types.
Here, we describe a new acoustic cryptanalysis key extraction attack,
applicable to GnuPG's current implementation of RSA. The attack can
extract full 4096-bit RSA decryption keys from laptop computers (of
various models), within an hour, using the sound generated by the
computer during the decryption of some chosen ciphertexts. We
experimentally demonstrate that such attacks can be carried out, using
either a plain mobile phone placed next to the computer, or a more
sensitive microphone placed 4 meters away.
Beyond acoustics, we demonstrate that a similar low-bandwidth attack
can be performed by measuring the electric potential of a computer
chassis. A suitably-equipped attacker need merely touch the target
computer with his bare hand, or get the required leakage information
from the ground wires remote end of VGA, USB or Ethernet

@_date: 2013-12-20 04:32:33
@_author: coderman 
@_subject: RDRAND used directly when default engines loaded in 
fortunately impacts are less than anticipated!
nickm devised most concise fix: RAND_set_rand_method(RAND_SSLeay());
 always after ENGINE_load_builtin_engines().
full write up is here including a BADRAND engine patch for testing:
  last but not least, notable omissions on NSA role in reqs for random
number sources in Appendix E: US Government Role in Current Encryption
  can we get a do-over?

@_date: 2013-12-20 17:41:36
@_author: coderman 
@_subject: NSA holiday talking points humor 
this is pretty amusing reading:
  "NSA does not and will not demand changes by any vendor to any
product, nor does it have any authority to demand such changes." - NSA
"We pay above market rates[0] to our corporate partners for embedded
vulns goddamnit!" - NSA Truth
0.  $10,000,000 to backdoor all of RSA's BSafe customers and cheer
lead Dual_EC_DRBG through approval it seems.
 let's not get into the standards bodies[1] yet, they're a little raw
right now :o
1. "Critics: NSA agent co-chairing key crypto standards body [IETF
CFRG] should be removed"

@_date: 2013-12-20 18:43:16
@_author: coderman 
@_subject: [cryptography] Vegetation Comsec 
most stylishly done as 'the drummers':
  where he is taken in by a strange society known as The Drummers.
These people operate in underwater compounds located off the coasts of
major centers, perform rhythmic, hypnotic dances and engage in
ritualized sex. This act, we learn later, is actually for the sake of
information exchange, which is done through the transmission of
nanomachines contained within their bodily fluids.
 - more recently via vodka emission:
scientists used a desk fan and mist of alcohol to transmit evaporated
molecules that were translated into binary signals and decoded by a
breathalyzer device.
- [this technique can be generalized to any gaseous emission (or aqueous
when at sea?) with appropriate detector.]
and of course, chemical signalling is not magically immune to flaws;
ant mills (death spirals) one of many examples of signalling amiss.
and there are some interesting research papers on targeted genomic
viral strains which only "unlock" to a very specific genetic profile.
i don't have them handy...

@_date: 2013-12-21 17:05:34
@_author: coderman 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
the leaks have sharpened my appetite for names and numbers.
collaborators in mass product perversion need to be named;
the extent of filthy lucre lures employed delineated; today!

@_date: 2013-12-21 17:19:09
@_author: coderman 
@_subject: public notice: TLA scrutiny an opportunity for catching capabilities 
if you're under scrutiny[0] no better time to test than today :)
- collect sequences, collect imagery, collect signals, collect
collaborators, collect everything! (you'll find data later you didn't
recognize as relevant)
- honey tokens to trigger channel targets, see which takes.
- selective channels of dis-information to quantify compromise.
- observe counter-reaction, counter counter-counter-measures,
- continually iterate process until truce or truncheon-ed...
caution: this can lead to escalation!
0. "Snowden ally Appelbaum claims his Berlin apartment was invaded"
  Berlin resident and US national Jacob Appelbaum told Saturday's
edition of the "Berliner Zeitung" daily that he believed he was under
surveillance in the German capital. Appelbaum told the paper that
somebody had broken into his apartment and used his computer in his
"When I flew away for an appointment, I installed four alarm systems
in my apartment," Appelbaum told the paper after discussing other
situations which he said made him feel uneasy. "When I returned, three
of them had been turned off. The fourth, however, had registered that
somebody was in my flat - although I'm the only one with a key. And
some of my effects, whose positions I carefully note, were indeed
askew. My computers had been turned on and off."

@_date: 2013-12-21 17:32:43
@_author: coderman 
@_subject: public notice: TLA scrutiny an opportunity for catching 
this assumes they're trying to be sneaky and surreptitious, of course.
sometimes an entry is about show of force rather than collection.  US
residence some years ago forcibly entered, surveillance system HERF'd,
dog placed in backyard, entire domicile imaged with all drawers,
cabinets, closets, cupboards, everything opened (and more :) in space
of 15 minute trip to store and back.
in any case, this is only effective if you're actually intimidated.
best to make it yet another egregious waste of public funding instead!

@_date: 2013-12-21 17:41:04
@_author: coderman 
@_subject: for those going to 30C3: Fwd: USB Sticks for TAILS [and OpenPGPv2 
The sticks [1] have arrived, you will be able to buy them for roughly
$15 at Chaos Communication Congress. Maybe I can drop off some of them
at the table of Wau Holland Foundation or elsewhere. Best you come find
me, for example at the Tor Relay meetup [2].
I ended up buying *200* sticks, 100 of each type and color. I will post
a detailed bill and pictures next year.
I will also bring OpenPGPv2 smartcards [3] and Gemalto USB tokens [4]
that you can buy from me, and some Yubikeys. [5]
[1] [2] [3] [4] [5] Moritz Bartl

@_date: 2013-12-21 19:43:06
@_author: coderman 
@_subject: FYI 
these people really hate Tor; they spelled it "the TOR Project"... on purpose.
  dicks!
on a related note, interpreting this document is an excellent exercise
in focusing on what is _not_ said, both in terms of qualifiers and
entire subjects/categories of omission.
oh that one might maintain a retrospective mapping from ongoing
Snowden leaks to misdirected / omitted / understated assertions and
recommendations in this Grade A Toothless Attention Distractor (aka,
"Report and Recommendations of The Presidents Review Group on
Intelligence and Communications Technologies")

@_date: 2013-12-21 20:00:38
@_author: coderman 
@_subject: FYI 
you say this like it's different from anything else you might request *grin*
indeed.  though this does bring up another question:
 i wonder if JYA will ever give in and support httpS?
... it would at least avoid trivial plaintext observation.
last but not least:
opsec tip you should assume everything remote and
retrieved is malicious.  grab in a throw away Qubes browser. convert
in a throw away parse and translate VM, then finally read and/or save
to a limited view VM using an open, trusted format.

@_date: 2013-12-22 13:38:57
@_author: coderman 
@_subject: RSA complicity or not in the EC_DBRG backdoor (Re: Human scum: 
another reason to love certificate transparency, convergence, pinning, etc...
  (yes John, httpS may be pwned, but it still flips pcap parser the bird! ;)

@_date: 2013-12-22 13:50:59
@_author: coderman 
@_subject: ECDHE-RSA-CHACHA20-POLY1305-SHA256 server side support in OpenSSL / 
poked around some patches for chacha20 and poly1305 suites in
OpenSSL... there's more work to be done it seems.
is there a working setup for Linux server side chacha20 poly1305
suites with OpenSSL?  (i am probably not looking in the right place;
e.g. aead_support.patch, aead_ssl_support.patch,
best regards,

@_date: 2013-12-22 17:01:41
@_author: coderman 
@_subject: Exclusive: Secret contract tied NSA and security industry pioneer 
they've done the research. they're in good company!

@_date: 2013-12-22 17:11:29
@_author: coderman 
@_subject: private sector privacy enhancing technology transition for 
if DEA finds meaningful work in legal marijuana[0], will IC community
find meaningful work red teaming and supporting privacy enhancing
technologies and usable open source crypto?
knowing how to break things useful in building systems that are harder
to break...
0. "DEA agents finding greener jobs in lucrative legal marijuana industry"

@_date: 2013-12-28 07:00:08
@_author: coderman 
@_subject: P2P VPN 
i love the concept of L2 VPNs; so pure in theory.
(AppleTalk and IPX over WAN? no problem!)
in practice they need a lot of careful implementation and
configuration.  the attack surface for tap vs. tun is very different;
many services handling broadcast traffic assume a trusted local
network environment.
all of the security features listed on the wiki are related to
transport / authentication rather than endpoint service
considerations.  this should be remedied.
looks interesting! perhaps i can play around with it soon...
best regards,

@_date: 2013-12-28 07:14:47
@_author: coderman 
@_subject: Boycott the RSA Conference - List of Honor 
Josh Thomas also bowing out:
is anyone keeping track? i'm curious...

@_date: 2013-12-29 02:19:23
@_author: coderman 
@_subject: 30c3: The Year in Crypto default engines loaded in openssl-1.x 
in 30c3: The Year in Crypto
 with djb, Nadia Heninger, Tanja Lange
at ~28min discussion of RDRAND,
 Intel's pass the buck to NIST no-comment,
  (after initial "just trust us, we looked at a lab sample close"
didn't fly far enough...)
alt slides: hyperelliptic.org/tanja/vortraege/talk-30C3.pdf
also, Tor 0.2.4.20 (Mon Dec 23 07:21:35 UTC 2013)
 updates to avoid direct RDRAND use in specific circumstances:
   per previous discussion on OpenSSL use of RDRAND directly when engines on.[0]
  TL; DR - very rare case you may want to re-gen relay and hidden service keys
 now,,
you may wonder if IETF could apply resistance to NSA seducing of NIST,
 but you'd be stepping into a quagmire  :P
     [specifically, all of Dan Harkins "appeals for legitimacy" bear
striking resemblance to other demonstratively failed approaches to
failure by default designs. Dragonfly is not sufficiently justified.
insert pleas to appeal to decency and step away from CFRG and IETF
authority roles for propriety sake, regardless of any reasonable
claims or other implications best exemplified by RSA[1]]
 also,,
SIMON and SPECK is lulz; no really: fuck those guys!
 and remember that AES GCM is a choice between:
  - user-land side channels galore  /or/
  - hardware instruction back-door
2013 was indeed a year for crypto
  let's not do this again soon?
best regards,
0. "BADRAND and testing OpenSSL engines enabled behavior with direct
RDRAND engine"
 BADRAND lets you link a test version of your application or library
against OpenSSL 1.0.1e that uses a specific sequence of deterministic
"random numbers" in OpenSSL. e.g. standard C lib function rand()
seeded at zero replacing RDRAND. the debug logging to stderr can
identify bad fork() assumptions.
1. Dual-EC-DRBG is bad and RSA should feel bad. No excuses.
  IETF standards not a good reference for "formal proof" level thoroughness,
  and highly deployed does not mean highly used nor scrutinized (WEP,
LEAP, OpenSSL's Dual_EC_DRBG implementation, [the set is large])
X. "see that one top post ..."  [was: RDRAND used directly when...

@_date: 2013-12-29 10:43:46
@_author: coderman 
@_subject: automated crash reporting XKeyscore hooks 
seems automated processes are a great XKeyscore source:
"in practical terms, the NSA's agents... enjoy it because it allows
them [a "neat way" to gain "passive access" to a machine] ... In one
internal graphic, they replaced the text of Microsoft's original error
message with one of their own reading, "This information may be
intercepted by a foreign sigint system to gather detailed information
and better exploit your machine."
Inside TAO
Documents Reveal Top NSA Hacking Unit
By SPIEGEL Staff
The NSA's TAO hacking unit is considered to be the intelligence
agency's top secret weapon. It maintains its own covert network,
infiltrates computers around the world and even intercepts shipping
deliveries to plant back doors in electronics ordered by those it is
In January 2010, numerous homeowners in San Antonio, Texas, stood
baffled in front of their closed garage doors. They wanted to drive to
work or head off to do their grocery shopping, but their garage door
openers had gone dead, leaving them stranded. No matter how many times
they pressed the buttons, the doors didn't budge. The problem
primarily affected residents in the western part of the city, around
Military Drive and the interstate highway known as Loop 410.
In the United States, a country of cars and commuters, the mysterious
garage door problem quickly became an issue for local politicians.
Ultimately, the municipal government solved the riddle. Fault for the
error lay with the United States' foreign intelligence service, the
National Security Agency, which has offices in San Antonio. Officials
at the agency were forced to admit that one of the NSA's radio
antennas was broadcasting at the same frequency as the garage door
openers. Embarrassed officials at the intelligence agency promised to
resolve the issue as quickly as possible, and soon the doors began
opening again.
It was thanks to the garage door opener episode that Texans learned
just how far the NSA's work had encroached upon their daily lives. For
quite some time now, the intelligence agency has maintained a branch
with around 2,000 employees at Lackland Air Force Base, also in San
Antonio. In 2005, the agency took over a former Sony computer chip
plant in the western part of the city. A brisk pace of construction
commenced inside this enormous compound. The acquisition of the former
chip factory at Sony Place was part of a massive expansion the agency
began after the events of Sept. 11, 2001.
On-Call Digital Plumbers
One of the two main buildings at the former plant has since housed a
sophisticated NSA unit, one that has benefited the most from this
expansion and has grown the fastest in recent years -- the Office of
Tailored Access Operations, or TAO. This is the NSA's top operative
unit -- something like a squad of plumbers that can be called in when
normal access to a target is blocked.
According to internal NSA documents viewed by SPIEGEL, these on-call
digital plumbers are involved in many sensitive operations conducted
by American intelligence agencies. TAO's area of operations ranges
from counterterrorism to cyber attacks to traditional espionage. The
documents reveal just how diversified the tools at TAO's disposal have
become -- and also how it exploits the technical weaknesses of the IT
industry, from Microsoft to Cisco and Huawei, to carry out its
discreet and efficient attacks.
The unit is "akin to the wunderkind of the US intelligence community,"
says Matthew Aid, a historian who specializes in the history of the
NSA. "Getting the ungettable" is the NSA's own description of its
duties. "It is not about the quantity produced but the quality of
intelligence that is important," one former TAO chief wrote,
describing her work in a document. The paper seen by SPIEGEL quotes
the former unit head stating that TAO has contributed "some of the
most significant intelligence our country has ever seen." The unit, it
goes on, has "access to our very hardest targets."
A Unit Born of the Internet
Defining the future of her unit at the time, she wrote that TAO "needs
to continue to grow and must lay the foundation for integrated
Computer Network Operations," and that it must "support Computer
Network Attacks as an integrated part of military operations." To
succeed in this, she wrote, TAO would have to acquire "pervasive,
persistent access on the global network." An internal description of
TAO's responsibilities makes clear that aggressive attacks are an
explicit part of the unit's tasks. In other words, the NSA's hackers
have been given a government mandate for their work. During the middle
part of the last decade, the special unit succeeded in gaining access
to 258 targets in 89 countries -- nearly everywhere in the world. In
2010, it conducted 279 operations worldwide.
Indeed, TAO specialists have directly accessed the protected networks
of democratically elected leaders of countries. They infiltrated
networks of European telecommunications companies and gained access to
and read mails sent over Blackberry's BES email servers, which until
then were believed to be securely encrypted. Achieving this last goal
required a "sustained TAO operation," one document states.
This TAO unit is born of the Internet -- created in 1997, a time when
not even 2 percent of the world's population had Internet access and
no one had yet thought of Facebook, YouTube or Twitter. From the time
the first TAO employees moved into offices at NSA headquarters in Fort
Meade, Maryland, the unit was housed in a separate wing, set apart
from the rest of the agency. Their task was clear from the beginning

@_date: 2013-12-30 05:03:19
@_author: coderman 
@_subject: 30c3: To Protect And Infect, Part 2 
so much asking for names, details, conspirators.
so many months and months of nearly zero satisfaction.
... until:
kudos Jake for delivering; specifically. :)
"[QI vector] 30c3: To Protect And Infect, Part 2"
you can argue some subset of these attacks are exercised in a targeted
manner, however, this does nothing to prevent collateral damage to
domestic and global individuals, indiscriminately.
fuck these guys![0]
best regards,
0. fuck you, at least in so far as your offensive efforts to undermine
privacy and liberty in the name of route tasking without restraint.
 to those who go privacy tech repurpose, i will sing your praises and
support your efforts!

@_date: 2013-12-30 07:21:26
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
out of time, barest gist til next year: back when doing wifi security
research and other interests [trunc.] received an FBI black bag job;
presumably physical focus due to non standard OSes and FDE.  IBM
keyboard internal chip replaced with identical logging variant; note
that this is not as sophisticated as the more recent TAO toys with
covert RF channels and active, on-demand capabilities...
the keyboard tampering:
 which is for all intents and purposes otherwise visually undetectable
using this trojan chip technique, tailored for every common
while that was not bad, aside from leaking tamper event, the FDE was
so sad/funny. a screw amuck, replacement drive significantly different
(when compared to identical lot mate purchased with original that got
yanked for offline attack)
in a round about manner this was all instigated in part by wifi
research done at the time which put various powerful entities into a
tiff.  here's what the pacNW sample looked like back in early 2003:
"Cleartext Nodes: 8755 (62.59%)
  , WEP Nodes: 5232 (37.40%)"
 ... ah, memories :)
one last fun learning by example: consider that you thwart direct
physical access black bag type attempts, and are not running a
vulnerable router/CPE, and present a sufficiently compelling target,
you may encounter a clever "just outside the property line" isolation
and active attack on DOCSIS uplink. (a broadcast medium is hard to
mess with in a covert manner, unless you're able to isolate target
from the local broadcast loop itself.)
(circa 2007 - make note of image comments and also single "Comcast
tech" shielding self behind door...)

@_date: 2013-12-30 07:38:41
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
tamper evidence combined with secondary reference copies to compare
(buy two in cash on demand rather than shipped, use second as fallback
(vastly more frequent scenario) or as reference with sketch kit (what
did you did? ;)
this leads to the question i intended but omitted in prev:
to date most FBI/NSA/IC keyloggers have been visually obtuse dongle
type, varied software type, particularly for Windows, Mac, and Dos at
this point in the past.  the top class (effectively undetectable?)
hardware keyloggers appear to have avoided detailed disclosure.
is anyone aware of leaked hardware keylogger specs or ops in the veign
of magic lantern / CIPAV / Carnivore / DCS* category applied to covert
hardware based compromises?

@_date: 2013-12-30 07:43:21
@_author: coderman 
@_subject: trojan hardware (keyboard black bag implant) circa 2003 
COTTONMOUTH is informative; but generally USB based and visible via
spectrum when actively exfilling.
specifically hardware attacks on PS/2 / XT style keyboards.

@_date: 2013-12-30 22:06:25
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
hey Jim, (and Jake)
neither one of you appear to have a *coin tipjar yet...
why holding out? :)
best regards,

@_date: 2013-12-30 22:19:21
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
you're assuming this dump is exhaustive.  this is a very specifically
themed/focused release of top end tactics and exploits (essentially
weaponized platforms for targeted attacks). Jake says as much about
what they're dropping, which while impressive, has still gone through
the "best interest of public safety scrutinizing and censorship"
the indiscriminate, wholesale compromises are just getting started...
these disclosures will have more impact: financially to the impacted
vendors, effectively to IC as known vulnerable hardware and software
is replaced, and to the public at large now exposed to even more
essentially incomprehensible disclosures of vulnerability and
this is just an example of how, when the NSA pursues "all means and
methods in parallel, without restraint" seemingly innocuous oversights
are intentionally leveraged and discouraged from remediation for use
in tailored access (black bag / targeted) attacks.
it is worse.
best regards,
p.s. cryptome has lots of great docs on this and other 30C3 awesomeness:
   ,

@_date: 2013-12-30 23:21:14
@_author: coderman 
@_subject: Replacing corporate search engines with anonymous/decentralized 
decentralized search (not just not-corporate search) persists as one
of the great
practical challenges in peer to peer networking.
i have more to say later, but one effort from back in early 2000 is alpine:
   inside the 2004 snapshot there is also docs and implementation of
feedbackfs which is used to gather implicit feedback on recommendation
alpine is explicitly highly connected, flatter than not network
topology to improve robustness in the face of failure and active
attacks, and to avoid limitations inherent in many connection oriented
operating system facilities/sockets.
i am not quite an impartial party ;)
 but other approaches which are not a feasible replacement include:
 - the old skewl (mostly)flooding broadcasts like gnutella
 - fragile, hard to defend constructs like DHTs as keyword indexes
 - aggressive caching with local search (110% useful, but not sufficient alone)
 - distributed (but better somehow) search engines on darknets, etc.
these are more about search privacy or deep search more than
decentralized search.
the longer discussion is how to make decentralized search useful.
"Google style" search has a terrific performance advantage over
decentralized designs by brute force.
however, take advantage of massive endpoint / peer processing and
resources combined with implicit observational metrics for reputation
and recommendation, inside a well integrated framework for resource
discovery in usable software, and you have something more robust and
more effective than "Google style" could ever provide.
this is quite the trick, however!  despite an inter-operable component
model interface, and dynamic runtime module support to extend
discovery and wire protocol extensions, and other intentional efforts
at encouraging adoption and integration, alpine failed to bootstrap.
(i did many things wrong, but those things i did at least make
conscious effort to do right.  did i mention this is a hard problem?
this project has been excavated from archives, and will receive
maintenance upgrades[0] at minimum and significant improvement a
possible option, depending.
best regards,
[0] maintenance work for testable alpine builds
 - fix/improve g++ usage.
 - add IPv6 support. (specifically ORCHID addrs for darknet search)
 - update feedbackfs to latest fusefs bindings
 - update inotify bindings in feedbackfs
 - multiple-socket support, multi-addr discovery

@_date: 2013-12-30 23:27:53
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
its a way to convert digital shared hallucinations into fiat
denominated shared hallucinations.
for an example exchange in BTC network:
  you can generate your own wallet and use your own client directly in
network, or use a managed wallet service, or a conversion service that
immediately converts into $USD denominated deposits in a bank account,
or exchange for physical token representations of the coin/funds, etc.
 is probably the most accessible place to start,
 and github where the good forks are if you're in the ready to hack camp.
if you setup a wallet and tell me the address, i can donate coins for
you to experiment with.
best regards,

@_date: 2013-12-31 00:51:27
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
i'll let you cypherpunks in on a secret financial tip:
  the smart money banks in dogecoin:

@_date: 2013-12-31 02:47:45
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
sha256 579c3059e24b2d65f324053b0fed550a9d1d4fb2504a1a272940a26697ed8a33
(where else is the above mirrored? i had links, they're no longer good...)
best regards,

@_date: 2013-12-31 03:08:12
@_author: coderman 
@_subject: Jacob Appelbaum in Germany 
this makes sense, and leads to a question; see below.
so far we've seen 0.5%[0] of confirmations of general and nearly
insurmountable vulnerability against a state level actor, ... let's
see what 2014 has in store! :)
the question:
 do you believe the counter-surveillance was a factor in the extreme
measures used in your prosecution?
AP seemed the most controversial and outwardly demonised aspect of the
whole debacle, but perhaps i am giving too much weight to AP.
the judge sealing the entire court file raises questions, but i also
admit knowing little about the particulars of the facts and legal
motions of the case.
best regards,
0.  snowden leaks, ~1.6% to ~.40% released
     see also, tailored access megapwnage:

@_date: 2013-12-31 19:00:10
@_author: coderman 
@_subject: Replacing corporate search engines with anonymous/decentralized 
what you want more than traditional search is resource discovery,
which includes recommendation and per-peer-perspective reputation.
this is an area where centralized search is incapable or untrustworthy
enough compared to fully decentralized options.
done centrally, that central trusted party would be privy to all your
inter-peer interactions.  in decentralized fashion this exposes only
limited information to each peer.  (central services usually paying
the cost of the infrastructure to analyze all to all interactions by
selling your private information to third parties, or delegating to
those who do...)
public web is a small slice of all that is of interest.  just put a
internet archive.org copy on a hidden Tahoe-LAFS and everyone gets a
copy of the public web for local querying. (better yet, make a PIR
LAFS ;)
... this would need a little coding *grin*

@_date: 2013-12-31 19:08:10
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
agreed.  we've got some years to wait for a definitive full picture.
  - 932 pages (~1.6%) of
reported 58,000. NSA head claims 200,000 (~.40% of that released)
vendor responses are fairly self evident.
bad: RSA
less-bad: Cisco
good/proactive: SilentCircle
etc,...   we could get into details of what makes a good vendor
response vs. one that is clearly weasel worded accountability
deflection, don't think this list is the place however.
then you're not paying attention :)
corporate media sucks to more or less degree; i feel bad for anyone
who touches it.
glad it's not my problem!
best regards,

@_date: 2013-12-31 23:04:19
@_author: coderman 
@_subject: "To Protect and Infect" - the edges of privacy-invading technology 
============================== START ==============================
On Tue, Dec 31, 2013 at 8:02 PM, Hannes Frederic Sowa
are you only considering this 30C3/catalog set of docs?
venally complicit to conveniently compromised to blissfully ignorant
compromise of hardware vendors goes back to CryptoAG and as recently
as the BULLRUN leaks.  a bit too long and complicated a thread for
this list, i think...
sure, just another example of in scope target for a "compromise all
the things" approach.
my point was to highlight their response as particularly deceptive and
inexcusable when observing how the various parties not only respond,
but act, in response to these leaks. (e.g. Google deploying crypto
over their internal fibers is positive action.  sitting silent or
deflecting criticism not confidence inspiring...)
best regards,

@_date: 2013-02-24 14:06:05
@_author: coderman 
@_subject: [qubes-devel] please look at Comparison of Whonix, Tails, 
Qubes is built with security in mind and a clear intent to minimize
attacks surface. this is akin to the proactive defense grsecurity and
a hardened distro provides against a generic distribution.
compare the opposite approach of VMWare or VirtualBox which focus on
features and low level accelerations (kernel driver for network,
graphics, USB, acceleration, other extensions) without thought to the
added risk these less then hardened components expose the host
operating systems and other guests to.
for example, but not limited to, networking passive and active attacks
on physical and virtual endpoints, local and host privilege
escalations, driver level privilege escalations, and many other
serious vulnerabilities Qubes prevents outright by design and explicit
all of these protections require zeroization to be performed before
physical access; an interesting HCI design detail itself...
  (at DEF CON there are the usual hack the software attack challenges,
and non computing seal and lock based physical attack challenges, but
i have not yet seen a hack the running system cold boot attack
challenge - perhaps because a real attack would likely be destructive
to some or most of the hardware to be tested.  i'd still be game for
mobile and workstation challenges if anyone else is interested :)
