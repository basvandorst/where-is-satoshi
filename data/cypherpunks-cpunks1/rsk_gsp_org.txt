
@_date: 2011-11-30 11:51:17
@_author: Rich Kulawiec 
@_subject: Used your smartphone to log into your network? 
If so, this might be a good time to change passwords, and to review
what other information has transited your phone.
(Note: androidsecuritytest.com appears to be slashdotted at the moment.)
November 16: initial reports of Carrier IQ spyware surface:
all of which reference the research presented here:
November 22: Carrier IQ threatens security researcher Trevor Eckhart:
November 24:  Carrier IQ backs off its threats, says that it doesn't track Android users
November 29: Further research by Trevor Eckhart shows Carrier IQ spyware logs ALL keystrokes
all of which reference this research:

@_date: 2013-02-07 13:08:43
@_author: Rich Kulawiec 
@_subject: [liberationtech] Cryptography super-group creates unbreakable 
Alchemy is to chemistry, astrology is to astronomy, as closed-source
is to open source.
Closed-source is intellectual fraud.  It is the equivalent of an academic
paper which has a synopsis and conclusions -- but nothing else.  No honest
reviewer would ever approve such tripe for publication in a refereed
journal of mechanical engineering or physics or medicine...yet we, in
computer science, are expected to do the equivalent.  We're actually
expected to take someone's word that their code does what they say it
does -- even though we have a mountain of evidence stretching back to the
beginning of our field that says it's NEVER been true, even when the
code's written by people who are smart/experienced/honest/diligent/etc.
Not even Stephen Hawking gets his papers published without showing
his data/reasoning/work/etc.  As it should be.
So yes, my response to this is "source or GTFO".  Extraordinary claims
require extraordinary proof and in this case, there is none.
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-07 13:18:23
@_author: Rich Kulawiec 
@_subject: [liberationtech] Chromebooks for Risky Situations? 
Strongly agreed.
As the size of the organization grows, the probability that zero employees
are (a) taking payoffs/bribes (b) succumbing to extortion/blackmail
and/or (c) otherwise political/socially/economically/personal motivated
to do Bad Things decreases.
We could debate the shape of the curve, but I think it's darn near certain
that there is -- somewhere -- a Google employee doing (a) and a Google
employee doing (b) and a Google employee doing (c).  Of course there are.
There are simply too many of them for this not to be true.  The same
can be said of every large company and organization.
The question is thus not "do they exist?" because I think we already
know that they do.  The question, or questions rather, become things
like "What is their goal?", "What do they have access to?", "What
measures exist to prevent them from accessing things they shouldn't?",
"What measures exist to detect them trying to access things they
shouldn't?", "Will I find out if it happens to be my data?", and so on.
My own experience suggests that the answers to those last questions
are nearly always "nothing", "not much" and "no" even in places where we
would all hope otherwise.
So if you (rhetorical and plural you) are becoming an annoyance to whatever
government you're antagonizing because you're smart and effective,
then why wouldn't they consider dropping $100K in cash on a cloud engineer
in return for a USB drive full of everything you've all stored there?
Seems like a good investment.  Much less tedious than infiltrating
your group.  Probably cheaper and less risky.
Or why wouldn't they plan ahead and start getting their own people in the
pipeline for jobs there?  They could play the long game and gamble that
spending years training some of their own, putting them through school
at RIT or Michigan or GaTech and getting them into Rackspace and Google
and Twitter will one day pay off, when someone very very loyal to their
ideology and politics feeds them timely information.
Yes, you can encrypt everything -- if you're all diligent about that.
But the logs will still show when and where you were, and possibly who
is talking to who, how much information they're exchanging, and when.
(And there's the possibility that, in extremis, your communications can
be "accidentally" cut off just when you need them most.)
My point is that I don't think trusting *any* large organization is a
good move.  If you're going to store this kind of data anywhere but on
systems that you personally control, then pick the smallest, most obscure
ones you can find.  Better yet: don't build an architecture that relies
on centralized communications and thus is vulnerable to centralized
compromises; we've discussed Usenet here before and I think that sort
of decentralized architecture is a much better model for this application.
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-21 11:00:24
@_author: Rich Kulawiec 
@_subject: NYT covers China cyberthreat 
Would it hurt their business?  Really?
Well, if they're eBay, probably.  If they're Joe's Fill Dirt and
Croissants in Omaha, then probably not, because nobody, NOBODY in China
is ever actually going to purchase a truckload of dirt or a tasty
croissant from Joe.  So would it actually matter if they couldn't
get to Joe's web site or Joe's mail server or especially Joe's VPN server?
Probably not.
Nobody in Peru, Egypt, or Romania is likely to be buying from Joe
any time soon either.
This is why I've been using geoblocking at the network and host levels
for over a decade, and it works. But it does require that you make an
effort to study and understand your own traffic patterns as well as your
organizational requirements. [1]
I use it on a country-by-country basis (thank you ipdeny.com) and
on a service-by-service basis: a particular host might allow http
from anywhere, but ssh only from the country it's in.  I also
deny selected networks access to selected services, e.g., Amazon's
cloud doesn't get access to port 25 because of the non-stop spam
and Amazon's refusal to do anything about it.  Anything on the
Spamhaus DROP or EDROP lists (thank you Spamhaus) is not part
of my view of the Internet.  And so on.  Combined, all this
achieves lossless compression of abusive traffic.
This is not a security fix, per se; any services that are vulnerable
are still vulnerable.  But it does cut down on the attack surface as
measured along one axis, which in turn reduces the scope of some
problems and renders them more tractable to other approaches.
An even better approach, when appropriate, is to block everything
and then only enable access selectively.  This is a particularly
good idea when defending things like ssh.  Do you *really* need to
allow incoming ssh from the entire planet?  Or could "the US, Canada,
the UK and Germany" suffice?  If so, then why aren't you enforcing that?
Do you really think it's a good idea to give someone with a 15-million
member global botnet 3 or 5 or 10 brute-force attempts *per bot*
before fail2ban or similar kicks in?  I don't.  I think 0 attempts per
most bots is a much better idea.  Let 'em eat packet drops while they
try to figure out which subset of bots can even *reach* your ssh server.
Which brings me to the NYTimes, and the alleged hacking by the Chinese.
Why, given that the NYTimes apparently handed wads of cash over to
various consulting firms, did none of those firms get the NYTimes to
make a first-order attempt at solving this problem?  Why in the world
was anything in their corporate infrastructure accessible from the 2410
networks and 143,067,136 IP addresses in China?  Who signed off on THAT?
(Yes, yes, I *know* that the NYTimes has staff there, some permanently
and some transiently.  A one-off solution crafted for this use case
would suffice.  I've done it.  It's not hard.  And I doubt that
it would need to work for more than, what, a few dozen of the NYTimes'
7500 employees?  Clone and customize for Rio, Paris, Moscow, and
other locations.  This isn't hard either.  Oh, and lock it out of
everything that a field reporter/editor/photographer doesn't need,
e.g., there is absolutely no way someone coming in through one of
those should be able to reach the subscriber database.)
Two more notes: first, blocking inbound traffic is usually not enough.
Blocks should almost always be bidirectional. [2]  This is especially
important for things like the DROP/EDROP lists, because then spam
payloads, phishes, malware, etc. won't be able to phone home quite
so readily, and while your users will still be able to click on
links that lead to bad things...they won't get there.
Second, this may sound complex.  It's not.  I handle my needs with
make, rsync, a little shell, a little perl, and other similar tools,
but clearly you could do the same thing with any system configuration
management setup.  And with proper logging, it's not hard to discover
the mistakes and edge cases, to apply suitable fixes and temporary
point exceptions, and so on.
[1] 'Now, your typical IT executive, when I discuss this concept with
him or her, will stand up and say something like, "That sounds great,
but our enterprise network is really complicated. Knowing about all the
different apps that we rely on would be impossible! What you're saying
sounds reasonable until you think about it and realize how absurd it
is!" To which I respond, "How can you call yourself a 'Chief Technology
Officer' if you have no idea what your technology is doing?" A CTO isn't
going to know detail about every application on the network, but if you
haven't got a vague idea what's going on it's impossible to do capacity
planning, disaster planning, security planning, or virtually any of the
things in a CTO's charter.'  --- Marcus Ranum
[2] "We were so concerned with getting out that we never stopped to
consider what we might be letting in, until it was too late."
Let's see who recognizes that one. ;-)

@_date: 2013-02-22 05:29:40
@_author: Rich Kulawiec 
@_subject: [liberationtech] Fwd: [greg@pryzby.org: Ubuntu, Dash, 
I've thought about this for a couple of days and about 20 miles, and
although my initial reaction was "yes, they should", I'm now going to
reverse myself and say "well...maybe not".  Here's why.
I think the problem here is not susceptible to patching, because the
root cause isn't software: it's mindset.  The people who think that this
is actually a good idea -- and persist in thinking so despite cogent
(and in my opinion, highly persuasive) arguments to the contrary -- are
unlikely to shift course.  The course they've embarked on inevitably leads
to more of the same -- oh, with different technical details and levels of
impact, of course, but still: more of the same.  I am reminded of one
of my favorite quotes:
I don't think the situation is salvageable; I think the effort that could
be put into trying to do so is better spent elsewhere.
I think it's time to go.
Unsubscribe, change to digest, or change password at:

@_date: 2013-02-26 07:35:22
@_author: Rich Kulawiec 
@_subject: [liberationtech] Looking for collaborators for free-range 
It won't work.  Until the bot/zombie is solved, online voting is
a non-starter, since any election worthy of being stolen can be.
It doesn't matter what you do on the server side: you can construct as
elaborate and clever and secure an infrastructure as you wish...because
on the client side, there is no way to ensure that what the user sees
is what's actually happening.  (After all: it's not *their* computer
any more.  Its new owners can, if they wish, cause a vote for candidate
A to be sent as a vote for candidate B, and they can prevent the user
from knowing that's happened.)
And given that (a) we're now about a decade into the zombie problem
(b) no significant effort against them has ever been attempted,
let alone completed [1] and (c) the problem is already epidemic and
continues to get worse [2] [3], there is no reason whatsoever to think
it will be mitigated, let alone solved, in the forseeable future.
This doesn't just apply to your proposal: it applies to *all* of
them.  Unless you can propose and execute a viable plan for solving
the zombie problem, then whatever you design/build can be undercut
whenever someone chooses to make the effort.  (And provided they're
not foolishly heavy-handed about it, it's unlikely you would be able
to detect this. [4])
[1] Botnet "takedowns" are unimportant and irrelevant; their only
purpose is to provide a forum for the spokesliars at Microsoft et.al.
to trumpet their prowess while a gullible press and public overlook
that they *created* this problem.  Merely removing C&C networks does
nothing to remediate the individual members of the botnets, which are
still compromised, still vulnerable, and likely to be conscripted into
other botnets before the day is out.
[2] We're now seeing portable devices zombie'd: phones, tablets, etc.
[3] Estimates of zombie population vary, of course, but clearly, any
estimate under 100M should be laughed out of the room.  Vint Cerf gave
an estimate of 150M just about six years ago, and based on my own work
as well as that of others in the anti-spam/abuse area, I thought that
was on the high side at the time...but it's most certainly not now.
I think the number's probably in the 200-300M range at this point.
See:  for
Cerf's comments.
[4] See Schneier's insightful and chilling piece on this here:
That piece should be absolutely mandatory reading for anyone even
considering voting systems.  It not only provides a method for
estimating attacker budgets, but it correctly points out that attackers
quite often could tip the balance of an election by manipulating a
rather small number of votes -- with a corresponding reduction in the
probability that the manipulation will be detected.
Note that Schneier wrote that in 2004.  If you repeat his analysis
with numbers from the 2012 election cycle you'll end up with *much*
large attacker budgets.  For example, Schneier says that in 2002,
Congressional candidates raised over 500M.  But
says that in 2012, they spent about $1.82B.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at
