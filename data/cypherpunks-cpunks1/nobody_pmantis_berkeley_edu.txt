
@_date: 1992-12-07 19:56:34
@_author: nobody@pmantis.berkeley.edu 
@_subject: another remailer! 
I set up another remailer.  All in all it took me about 30 min to compile
perl and set up Hal's script.  It's too easy!
Just do the standard thing:  mail to hh at pmantis.berkeley.edu with the line
in the header Anon-To: or Request-Remailing-To:
Have fun!

@_date: 1992-12-11 14:58:27
@_author: nobody@pmantis.berkeley.edu 
@_subject: Chaum's "The Dining Cryptographers Problem" (VERY LONG) 
The following article is brought to you by the Information Liberation
Front (ILF), a group dedicated to the timely distribution of important
information. The ILF encourages you to use this article for educational purposes
only and to seek out the original article. Minor spelling errors and
slight alterations of formulas may have gotten past the OCR process.
We apologize for the length, but feel this is one of the key articles
in this area. J. Cryptology (1988) 1:65-75
The Dining Cryptographers Problem:
Unconditional Sender and Recipient Untraceability
David Chaum
Centre for Mathematics and Computer Science, Kruislan 413, 1098 SJ Amsterdam, The Netherlands
Abstract.  Keeping confidential who sends which messages, in a world where any physical transmission can be traced to its origin, seems impossible. The solution presented here is unconditionally or cryptographically secure, depending on whether it is based on one-time-use keys or on public keys, respectively. It can be adapted to address efficiently a wide variety of practical considerations.
Key words.  Untraceability, Unconditional Security, Pseudonymity.
Three cryptographers are sitting down to dinner at their favorite three-star restaurant. Their waiter informs them that arrangements have been made with the maitre d'hotel for the bill to be paid anonymously. One of the cryptographers might be paying for the dinner, or it might have been NSA (U.S. National Security Agency). The three cryptographers respect each other's right to make an anonymous payment, but they wonder if NSA is paying. They resolve their uncertainty fairly by carrying out the following protocol:
Each cryptographer flips an unbiased coin behind his menu, between him and the cryptographer on his right, so that only the two of them can see the outcome. Each cryptographer then states aloud whether the two coins he can see--the one he flipped and the one his left-hand neighbor flipped--fell on the same side or on different sides. If one of the cryptographers is the payer, he states the opposite of what he sees. An odd number of differences uttered at the table indicates that a cryptographer is paying; an even number indicates that NSA is paying (assuming that the dinner was paid for only once). Yet if a cryptographer is paying, neither of the other two learns anything from the utterances about which cryptographer it is.
To see why the protocol is unconditionally secure if carried out faithfully, consider the dilemma of a cryptographer who is not the payer and wishes to find out which cryptographer is. (If NSA pays, there is no anonymity problem.) There are two cases. In case (1) the two coins he sees are the same, one of the other cryptographers said "different," and the other one said "same." If the hidden outcome was the same as the two outcomes he sees, the cryptographer who said "different" is the payer; if the outcome was different, the one who said "same" is the payer. But since the hidden coin is fair, both possibilities are equally likely. In case (2) the coins he sees are different; if both other cryptographers said "different," then the payer is closest to the coin that is the same as the hidden coin; if both said "same," then the payer is closest to the coin that differs from the hidden coin. Thus, in each subcase, a nonpaying cryptographer learns nothing about which of the other two is paying.
The cryptographers become intrigued with the ability to make messages public untraceably. They devise a way to do this at the table for a statement of arbitrary length: the basic protocol is repeated over and over; when one cryptographer wishes to make a message public, he merely begins inverting his statements in those rounds corresponding to 1 's in a binary coded version of his message. If he notices that his message would collide with some other message, he may for example wait a number of rounds chosen at random from a suitable distribution before trying to transmit again.
1. Generalizing the Approach
During dinner, the cryptographers also consider how any number of participants greater than one can carry out a version of the protocol. (With two participants, only nonparticipant listeners are unable to distinguish between the two potential senders.) Each participant has a secret key bit in common with, say, every other participant. Each participant outputs the sum, modulo two, of all the key bits he shares, and if he wishes to transmit, he inverts his output. If no participant transmits, the modulo two sum of the outputs must be zero, since every key bit enters exactly twice; if one participant transmits, the sum must be one. (In fact, any even number of transmitting participants yields zero, and any odd number yields one.) For j rounds, each participant could have a j-bit key in common with every other participant, and the ith bit of each such key would be used only in the ith round. Detected collision of messages leads to attempted retransmission as described above; undetected collision results only from an odd number of synchronized identical message segments. (Generalization to fields other than GF(2) is possible, but seems to offer little practical advantage.)
Other generalizations are also considered during dinner. The underlying assumptions are first made explicit, including modeling key-sharing arrangements as graphs. Next, the model is illustrated with some simple examples. The potential for cooperations of participants to violate the security of others is then looked at. Finally, a proof of security based on systems of linear equations is given.
1.1. Model
Each participant is assumed to have two kinds of secret: (a) the keys shared with other participants for each round; and (b) the inversion used in each round (i.e., a 1 if the participant inverts in that round and a 0 if not). Some or all of a participant's secrets may be given to other participants in various forms of collusion, discussion of which is postponed until Section 1.3. (For simplicity in exposition, the possibility of secrets being stolen is ignored throughout.)
The remaining information about the system may be described as: (a)
who shares keys with whom; and (b) what each participant outputs
during each round (the modulo two sum of that participant's keys and
inversion). This information need not be secret to ensure
untraceability. If it is publicly known and agreed, it allows various
extensions discussed in Sections 2.5 and 2.6. The sum of all the
outputs will, of course, usually become known to all participants.
In the terminology of graphs, each participant corresponds to a vertex and each key corresponds to an edge. An edge is incident on the vertices corresponding to the pair of participants that shares the corresponding key. From here on, the graph and dinner-table terminologies will be used interchangeably. Also, without loss of generality, it will be assumed that the graph is connected (i.e., that a path exists between every pair of vertices), since each connected component (i.e., each maximal connected subgraph) could be considered a separate untraceable-sender system.
An anonymity set seen by a set of keys is the set of vertices in a connected component of the graph formed from the original graph by removing the edges concerned. Thus a set of keys sees one anonymity set for each connected partition induced by removing the keys. The main theorem of Section 1.4 is essentially that those having only the public information and a set of keys seeing some anonymity set can learn nothing about the members of that anonymity set except the overall parity of their inversions. Thus, for example, any two participants connected by at least one chain of keys unknown to an observer are both in the same anonymity set seen by the observer's keys, and the observer gains nothing that would help distinguish between their messages.
1.2. Some Examples
A few simple consequences of the above model may be illustrative. The anonymity set seen by the empty set (i.e., by a nonparticipant observer) is the set of all vertices, since the graph is assumed connected and remains so after zero edges are removed. Also, the anonymity sets seen by the full set of edges are all singleton sets, since each vertex's inversion is just the sum of its output and the corresponding key bits.
If all other participants cooperate fully against one, of course no protocol can keep that singleton's messages untraceable, since untraceability exists only among a set of possible actors, and if the set has only one member, its messages are traceable. For similar reasons, if a participant believes that some subset of other participants will fully cooperate against him, there is no need for him to have keys in common with them.
A biconnected graph (i.e., a graph with at least two vertex-disjoint paths between every pair of vertices) has no cut-vertices (i.e., a single vertex whose removal partitions the graph into disjoint subgraphs). In such a graph, the set of edges incident on a vertex v sees (apart from v) one anonymity set containing all other vertices, since there is a path not containing v between every pair of vertices, and thus they form a connected subgraph excluding v; each participant acting alone learns nothing about the contribution of other participants.
1.3. Collusion of Participants
Some participants may cooperate by pooling their keys in efforts to trace the messages of others; such cooperation will be called collusion. For simplicity, the possibilities for multiple collusions or for pooling of information other than full edges will be ignored. Colluders who lie to each other are only touched on briefly, in Section 2.6.
Consider collusion in a complete graph. A vertex is only seen as a singleton anonymity set by the collection of all edges incident on it; all other participants must supply the key they share with a participant in order to determine that participant's inversions. But since a collusion of all but one participant can always trace that participant merely by pooling its members' inversions as already mentioned, it gains nothing more by pooling its keys. The nonsingleton anonymity set seen by all edges incident on a colluding set of vertices in a complete graph is the set of all other vertices; again, a collusion yields nothing more from pooling all its keys than from pooling all its inversions.
Now consider noncomplete graphs. A full collusion is a subset of participants pooling all of their keys. The pooled keys see each colluder as a singleton anonymity set; the colluders completely sacrifice the untraceability of their own messages. If a full collusion includes a cut-
set of vertices (i.e., one whose removal partitions the graph), the collusion becomes nontrivial because it can learn something about the origin of messages originating outside the collusion; the noncolluding vertices are partitioned into disjoint subgraphs, which are the anonymity sets seen by the pooled keys.
Members of a partial collusion pool some but not all of their keys. Unlike the members of a full collusion, each member of a partial collusion in general has a different set of keys. For it to be nontrivial, a partial collusion's pooled keys must include the bridges or separating edges of a segregation or splitting of the graph (i.e., those edges whose removal would partition the graph). Settings are easily constructed in which the pooled keys see anonymity sets that partition the graph and yet leave each colluder in a nonsingleton partition seen by any other participant. Thus, colluders can join a collusion without having to make themselves completely traceable to the collusion's other members.
1.4. Proof of Security
Consider, without loss of generality, a single round in which say some full collusion knows some set of keys. Remove the edges known to the collusion from the key-sharing graph and consider any particular connected component C of the remaining graph. The vertices of C thus form an anonymity set seen by the pooled keys.
Informally, what remains to be shown is that the only thing the collusion learns about the members of C is the parity sum of their inversions. This is intuitively apparent, since the inversions of the members of C are each in effect hidden from the collusion by one or more unknown key bits, and only the parity of the sum of these key bits is known (to be zero). Thus the inversions are hidden by a one-time pad, and only their parity is revealed, because only the parity of the pad is The setting is formalized as follows: the connected component C is comprised of rn vertices and n edges. The incidence matrix M of C is defined as usual, with the vertices labeling the rows and the edges labeling the columns. Let K, I, and A be stochastic variables defined on GF(2)^n, GF(2)^m, and GF(2)^m, respectively, such that
K is uniformly distributed over GF(2)^n, K and I are mutually independent, and A = (MK) cross I. In terms of the protocol, K comprises the keys corresponding to the edges, I consists of the inversions corresponding to the vertices, and A is formed by the outputs of the vertices. Notice that the parity of A (i.e., the modulo two sum of its components) is always equal to the parity of I, since the columns of M each have zero parity. The desired result is essentially that A reveals no more information about I than the parity of 1. More formally:
Theorem.  Let a be in GF(2)^n. For each i in GF(2)^n, which is assumed by I with nonzero probability and which has the same parity as a, the conditional probability that A = a given that I = i is 2^(1 - m). Hence, the conditional probability that I = i given that A = a is the a priori probability that I = i.
Proof.  Let i be an element of GF(2)^n have the same parity as a. Consider the system of linear equations (MK) cross i = a, in k an element of GF(2)^n. Since the columns of M each have even parity, as mentioned above, its rows are linearly dependent over GF(2)^m. But as a consequence of the connectedness of the graph, every proper subset of rows of M is linearly independent. Thus, the rank of M is m - 1, and so each vector with zero parity can be written as a linear combination of the columns of M. This implies that the system is solvable because i cross a has even parity. Since the set of n column vectors of M has rank m - 1, the system has exactly 2^(n - m + 1) solutions.
Together with the fact that K and I are mutually independent and that K is uniformly distributed, the theorem follows easily.                           2. Some Practical Considerations
After dinner, while discussing how they can continue to make untraceable statements from this respective homes, the cryptographers take up a variety of other topics. In particular, they consider different ways to establish the needed keys; debate adapting the approach to various kinds of communication networks; examine the traditional problems of secrecy and authentication in the context of a system that can provide essentially optimal untraceability; address denial of service caused by malicious and devious participants; and propose means to discourage socially undesirable messages from being sent.
2.1. Establishing Keys
One way to provide the keys needed for longer messages is for one member of each pair to toss many coins in advance. Two identical copies of the resulting bits are made, say each on a separate optical disk. Supplying one such disk (which today can hold on the order of 10^10 bits) to a partner provides enough key bits to allow people to type messages at full speed for years. If participants are not transmitting all the time, the keys can be made to last even longer by using a substantially slower rate when no message is being sent; the full rate would be invoked automatically only when a 1 bit indicated the beginning of a message. (This can also reduce the bandwidth requirements discussed in Section 2.2.)
Another possibility is for a pair to establish a short key and use a cryptographic pseudorandom-sequence generator to expand it as needed. Of course this system might be broken if the generator were broken. Cryptanalysis may be made more difficult, however, by lack of access to the output of individual generators. Even when the cryptographers do not exchange keys at dinner, they can safely do so later using a public-
key distribution system (first proposed by [4] and [3]).
2.2 Underlying Communication Techniques
A variety of underlying communication networks can be used, and their topology need not be related to that of the key-sharing graph.
Communication systems based on simple cycles, called rings, are common in local area networks. In a typical ring, each node receives each bit and passes it round-robin to the next node. This technology is readily adapted to the present protocols. Consider a single-bit message like the "I paid" message originally sent at the dinner table. Each participant exclusive-or's the bit he receives with his own output before forwarding it to the next participant. When the bit has traveled full circle, it is the exclusive-or sum of all the participants' outputs, which is the desired result of the protocol. To provide these messages to all participants, each bit is sent around a second time by the participant at the end of the loop.
Such an adapted ring requires, on average, a fourfold increase in bandwidth over the obvious traceable protocols in which messages travel only halfway around on average before being taken off the ring by their recipients. Rings differ from the dinner table in that several bit-
transmission delays may be required before all the outputs of a particular round are known to all participants; collisions are detected only after such delays.
Efficient use of many other practical communication techniques requires participants to group output bits into blocks. For example, in high-capacity broadcast systems, such as those based on coaxial cable, surface radio, or satellites, more efficient use of channel capacity is obtained by grouping a participant's contribution into a block about the size of a single message (see, e.g., [5]). Use of such communication techniques could require an increase in bandwidth on the order of the number of participants.
In a network with one message per block, the well-known contention protocols can be used: time is divided evenly into frames; a participant transmits a block during one frame; if the block was garbled by collision (presumably with another transmitted block), the participant waits a number of frames chosen at random from some distribution before attempting to retransmit; the participants' waiting intervals may be adjusted on the basis of the collision rate and possibly of other heuristics [5].
In a network with many messages per block, a first block may be used by various anonymous senders to request a "slot reservation" in a second block. A simple scheme would be for each anonymous sender to invert one randomly selected bit in the first block for each slot they wish to reserve in the second block. After the result of the first block becomes known, the participant who caused the ith 1 bit in the first block sends in the ith slot of the second block.
2.3. Example Key-Sharing Graphs
In large systems it may be desirable to use fewer than the m(m - 1)/2 keys required by a complete graph. If the graph is merely a cycle, then individuals acting alone learn nothing, but any two colluders can partition the graph, perhaps fully compromising a participant immediately between them. Such a topology might nevertheless be adequate in an application in which nearby participants are not likely to collude against one another.
A different topology assumes the existence of a subset of participants who each participant believes are sufficiently unlikely to collude, such as participants with conflicting interests. This subset constitutes a fully connected subgraph, and the other participants each share a key with every member of it. Every participant is then untraceable among all the others, unless all members of the completely connected subset cooperate. (Such a situation is mentioned again in Section 3.)
If many people wish to participate in an untraceable communication system, hierarchical arrangements may offer further economy of keys. Consider an example in which a representative from each local fully connected subgraph is also a member of the fully connected central subgraph. The nonrepresentative members of a local subgraph provide the sum of their outputs to their representative. Representatives would then add their own contributions before providing the sum to the central subgraph. Only a local subgraph's representative, or a collusion of representatives from all other local subgraphs, can recognize messages as coming from the local subgraph. A collusion comprising the representative and all but one nonrepresentative member of a local subgraph is needed for messages to be recognized as coming from the remaining member.
2.4. Secrecy and Authentication
What about the usual cryptologic problems of secrecy and A cryptographer can ensure the secrecy of an anonymous message by encrypting the message with the intended recipient's public key. (The message should include a hundred or so random bits to foil attempts to confirm a guess at its content [1].) The sender can even keep the identity of the intended recipient secret by leaving it to each recipient to try to decrypt every message. Alternatively, a prearranged prefix could be attached to each message so that the recipient need only decrypt messages with recognized prefixes. To keep even the multiplicity of a prefix's use from being revealed, a different prefix might be used each time. New prefixes could be agreed in advance, generated cryptographically as needed, or supplied in earlier messages.
Authentication is also quite useful in systems without identification.
Even though the messages are untraceable, they might still bear
digital signatures corresponding to public-key "digital pseudonyms"
[1]; only the untraceable owner of such a pseudonym would be able to
sign subsequent messages with it. Secure payment protocols have
elsewhere been proposed in which the payer and/or the payee might be
untraceable [2]. Other protocols have been proposed that allow
individuals known only by pseudonyms to transfer securely information
about themselves between organizations [2]. All these systems require
solutions to the sender untraceability problem, such as the solution
presented here, if they are to protect the unlinkability of pseudonyms
used to conduct transactions from home.
2.5. Disruption
Another question is how to stop participants who, accidentally or even intentionally, disrupt the system by preventing others from sending messages. In a sense, this problem has no solution, since any participant can send messages continuously, thereby clogging the channel. But nondisupters can ultimately stop disruption in a system meeting the following requirements: (1) the key-sharing graph is publicly agreed on; (2) each participant's outputs are publicly agreed on in such a way that participants cannot change their output for a round on the basis of other participants' outputs for that round; and (3) some rounds contain inversions that would not compromise the untraceability of any nondisrupter.
The first requirement has already been mentioned in Section 1.1, where it was said that this information need not be secret; now it is required that this information actually be made known to all participants and that the participants agree on it.
The second requirement is in part that disrupters be unable (at least with some significant probability) to change their output after hearing other participants' outputs. Some actual channels would automatically ensure this, such as broadcast systems in which all broadcasts are made simultaneously on different frequencies. The remainder of the second requirement, that the outputs be publicly agreed on, might also be met by broadcasting. Having only channels that do not provide it automatically, an effective way to meet the full second requirement would be for participants to "commit" to their outputs before making them. One way to do this is for participants to make public and agree on some (possibly compressing and hierarchical, see Section 2.6) one-way function of their outputs, before the outputs are made public.
The third requirement is that at least some rounds can be contested (i.e., that all inversions can be made public) without compromising the untraceability of non-disrupting senders. The feasibility of this will be demonstrated here by a simple example protocol based on the slot reservation technique already described in Section 2.2.
Suppose that each participant is always to make a single reservation in each reserving block, whether or not he actually intends to send a message. (Notice that, because of the "birthday paradox," the number of bits per reserving block must be quadratic in the number of participants.) A disrupted reserving block would then with very high probability have Hamming weight unequal to the number of participants. All bits of such a disrupted reserving block could be contested without loss of untraceability for nondisrupters.
The reserved blocks can also be made to have such safely contestable
bits if participants send trap messages. To lay a trap, a participant
first chooses the index of a bit in some reserving block, a random
message, and a secret key. Then the trapper makes public an
encryption, using the secret key, of both the bit index and the random
message. Later, the trapper reserves by inverting in the round
corresponding to the bit index, and sends the random message in the
resulting reserved slot. If a disrupter is unlucky enough to have
damaged a trap message, then release of the secret key by the trapper
would cause at least one bit of the reserved slot to be contested.
With the three requirements satisfied, it remains to be shown how if enough disrupted rounds are contested, the disrupters will be excluded from the network.
Consider first the case of a single participant's mail computer disrupting the network. If it tells the truth about contested key bits it shares (or lies about an even number of bits), the disrupter implicates itself, because its contribution to the sum is unequal to the sum of these bits (apart from any allowed inversion). If, on the other hand, the single disrupter lies about some odd number of shared bits, the values it claims will differ from those claimed for the same shared bits by the other participants sharing them. The disrupter thereby casts suspicion on all participants, including itself, that share the disputed bits. (It may be difficult for a disrupter to cast substantial suspicion on a large set of participants, since all the disputed bits will be in common with the disrupter.) Notice, however, that participants who have been falsely accused will know that they have been--and by whom--and should at least refuse to share bits with the disrupter in the future.
Even with colluding multiple disrupters, at least one inversion must be revealed as illegitimate or at least one key bit disputed, since the parity of the outputs does not correspond to the number of legitimate inversions. The result of such a contested round will be the removal of at least one edge or at least one vertex from the agreed graph. Thus, if every disruptive action has a nonzero probability of being contested, only a bounded amount of disruption is possible before the disrupters share no keys with anyone in the network, or before they are revealed, and are in either case excluded from the network.
The extension presented next can demonstrate the true value of disputed bits, and hence allows direct incrimination of disrupters.
2.6. Tracing by Consent
Antisocial use of a network can be deterred if the cooperation of most participants makes it possible, albeit expensive, to trace any message. If, for example, a threatening message is sent, a court might order all participants to reveal their shared key bits for a round of the message. The sender of the offending message might try to spread the blame, however, by lying about some odd number of shared bits. Digital signatures can be used to stop such blame-spreading altogether. In principle, each party sharing a key could insist on a signature, made by the other party sharing, for the value. of each shared bit.
Such signatures would allow for contested rounds to be fully resolved,
for accused senders to exonerate themselves, and even for colluders to
convince each other that they are pooling true keys.  Unfortunately,
cooperating participants able to trace a message to its sender could
convince others of the message's origin by revealing the sender's own
signatures. A variation can prevent a participant's signatures from
being used against him in this way: instead of each member of a pair
of participants signing the same shared key bit, each signs a separate
bit, such that the sum of the signed bits is the actual shared key
bit. Signatures on such "split" key bits would still be useful in
resolving contested rounds, since if one contester of a bit shows a
signature made by the second contester, then the second would have to
reveal the corresponding signature made by the first or be thought to
be a disrupter.
In many applications it may be impractical to obtain a separate signature on every key bit or split key bit. The overhead involved could be greatly reduced, however, by digitally signing cryptographic compressions of large numbers of key bits. This might of course require that a whole block of key bits be exposed in showing a signature, but such blocks could be padded with cryptographically generated pseudorandom (or truly random) bits, to allow the exposure of fewer bits per signature. The number of bits and amount of time required to verify a signature for a single bit can be reduced further by using a rooted tree in which each node is the one-way compression function of all its direct descendants; only a digital signature of each participant's root need be agreed on before use of the keys comprising the leaves.
3. Relation to Previous Work
There is another multiparty-secure sender-untraceability protocol in the literature [1]. To facilitate comparison, it will be called a mix-net here, while the protocol of the present work is called a dc-net. The mix-net approach relies on the security of a true public-key system (and possibly also of a conventional cryptosystem), and is thus at best computationally secure; the dc-net approach can use unconditional secrecy channels to provide an unconditionally secure untraceable-
sender system, or can use public-key distribution to provide a computationally secure system (as described in Section 2.1).
Under some trust assumptions and channel limitations, however, mix-nets can operate where dc-nets cannot. Suppose that a subset of participants is trusted by every other participant not to collude and that the bandwidth of at least some participants' channels to the trusted subset is incapable of handling the total message traffic. Then mix-nets may operate quite satisfactorily, but dc-nets will be unable to protect fully each participant's untraceability. Mix-nets can also provide recipient untraceability in this communication environment, even though there is insufficient bandwidth for use of the broadcast approach (mentioned in Section 2.4).
If optimal protection against collusion is to be provided and the crypto-security of mix-nets is acceptable, a choice between mix-nets and dc-nets may depend on the nature of the traffic. With a mail-like system that requires only periodic deliveries, and where the average number of messages per interval is relatively large, mix-nets may be suitable. When messages must be delivered continually and there is no time for batching large numbers of them, dc-nets appear preferable.
4. Conclusion
This solution to the dining cryptographers problem demonstrates that
unconditional secrecy channels can be used to construct an
unconditional sender-untraceability channel. It also shows that a
public-key distribution system can be used to construct a
computationally secure sender-untraceability channel. The approach
appears able to satisfy a wide range of practical concerns.
I am pleased to thank Jurjen Bos, Gilles Brassard, Jan-Hendrik Evertse, and the untraceable referees for all their help in revising this article. It is also a pleasure to thank, as in the original version that was distributed at Crypto 84, Whitfield Diffie, Ron Rivest, and Gus Simmons for some stimulating dinner-table conversations.
[1]	Chaum, D., Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms, Communications of the  ACM, vol. 24, no. 2, February 1981, pp. 84-88.
[2]	Chaum, D., Security Without Identification: Transaction Systems to Make Big Brother Obsolete, Communications of the ACM, vol. 28, no. 10, October 1985, pp. 1030-1044.
[3]	Diffie, W., and Hellman, M.E., New Directions in Cryptography, IEEE Transactions on Information Theory, vol. 22, no. 6, November 1976, pp. 644-654.
[4]	Merkle, R.C., Secure Communication over Insecure Channels, Communications of the ACM, vol. 21, no. 4, 1978, pp. 294-299.
[5]	Tanenbaum, A.S., Computer Networks, Prentice Hall, Englewood Cliffs, New Jersey, 1981.
[End of Transmission]

@_date: 1993-04-16 20:09:56
@_author: nobody@pmantis.berkeley.edu 
@_subject: No Subject 
With regard to the White House's attempt to force the "Clipper" on you:
I guess the time has come for the Cypherpunks to break their 'political teeth'.
This issue is squarely on point with the purpose of the cpunks and needs to be
addressed.  The best thinkers on these topics are on this list (as are many
libertarian thinkers).  The Cypherpunks have gotten a fair amount of media play
as of late and I think those interested in privacy and security are frothing at
the mouth.  I know in general cpunks dont believe in the necessity for leaders,
but leader'ship' is a different matter.  I believe that there are people here
with the knowledge to fight against this proposal.  So, Cypherpunks, step to the
political plate.
Just some levity to start off with :-)
I read this differently than does Tim.  "shall" coupled with "request" actually
equals ambiguity and seems not to compel anyone.  Im sure that the language was
meant to confuse though.
Well, the door does still appear to be open for private circuit development and
a better escrow system (better?).  This does lend credence to the opinion that
this may just be a very forceful suggestion and not an order per se.
Gotta agree with Tim that this appears to be an incredibly obvious backdoor to
all telecommunications equipment.  This should be made clear in any public
statements about this document.
OK.  This might be the key to the downfall of this proposal.  The Govt appears
to be showing its weak hand here.  They have either not thouroughly addressed
the legal concerns or they are standing on shaky legal ground.  I believe there
could be a number of problems (legally speaking) with the proposal.  Seperation
of Powers, Commerce concerns, penumbra Right to Privacy, etc just to name a few.
Well, I guess Im off to the library to research another interesting, yet
inapplicable directly to my legal studies, topic.  (As if I dont spend enough
time in the library)  I guess if she's gonna review the legal sufficiency there
should be no problem with me 'parallel processing' that same information.
Surplus...what happened to the defecit?   :^)
  In general I believe that this event calls for a public expression of
intellectual disagreement.  An assertion of the power of the ideas expressed on
this list will put the Cypherpunks in the discourse of public policy.
Obviously, it should be well thought out and expressed in the most positive way.
Calm, cool, calculated response will gain the cpunks respect, a knee jerk,
emotional response will only get our ideas ignored.
  If politics doesn't work there also appears to be an economic out.  Creating
REAL encryptive circuits whose keys are not held by the government but rather by
the owner.  Private enterprise and a result to our concerns for liberty appear
amenable.  So any hardware cypherpunk hacks, get out your tools.
  Finally, a simple analogy.  The current state of the law does not require me
to register the key to my home with a government agency so that they can gain
access to my home in a more efficient way if they feel the need.  I keep the key
and the control (until they break down my door).  In that case, the value is
placed on my freedom, not the efficiency with which the police could access my
private communications.  There are reasons that search warrents were 'initially'
difficult to acquire and reasons why it should be difficult to access my home
(i.e. they must break down my door.)  Those reasons dealt with the severity of
encroachment upon my privacy and rights thereto.  In fact, that is the reason
given for the remaining formalistic requirements of the necessity of prior
judicial consent for warrents.  No, the judge does not ponder long and hard
about whether to give the warrent.  Rather, the purpose is to give the officers
pause.  The ritual is designed to make the parties involved at least ponder the
severity of their actions.  This proposal would only make invasions of our
privacy easier to achieve and eliminate obstacles in the way of officers, giving
them even less time to ponder the severity of their encroachment.
 VOLTAIRE                                      Studying the law,
                                                  Finding the flaws,
                                                      Creating a light,
                                                          Out of the night!
Tim- Aren't we closer than 10 mins. to midnight???????

@_date: 1993-08-03 15:11:41
@_author: nobody@pmantis.berkeley.edu 
@_subject: PKZIP Encryption is worthless 
To the best of my knowledge, PKZip uses a simple Vigenere algorithm for its
encryption. There is a program called "zipcrack", widely available on BBSes,
that does cryptanalysis of encrypted PKZip files. The rumor is that the "zipcrack" program originated in Russia, but really, cryptanalysis of the stuff
that PK is using is relatively trivial.
There are many good implementations of DES, including Symantec's in the Norton
Utilities. You could also use PGP. But don't rely on PKZip to protect your privacy. That's not what it's designed for.
Note the reply-to address above if you wish to reply.

@_date: 1993-08-10 18:06:53
@_author: nobody@pmantis.berkeley.edu 
@_subject: Using a 'telserv' program to redirect mail 
yada yada
Why not post it anoymously? Too late now. Cypherpunks not only write code,
they write code that people can use.

@_date: 1993-08-16 05:27:06
@_author: nobody@pmantis.berkeley.edu 
@_subject: Electronic Democracy 
Actually, elections are more like four sheep voting on which wolf they want
to be eaten by.
 .snail

@_date: 1993-08-27 14:27:55
@_author: nobody@pmantis.berkeley.edu 
@_subject: Digital Coin Claim 
Yes, but holds what?
I think you missed the point. You're thinking that people use their
identity-revealing keys to sign these public documents. I think Hnash
intended that people use anonymous or even one-time-only keys. The bearer
instrument is not the thing that gets publicized, it is the private key
corresponding to the public key in the public document. When you generate
that key, you put no identifying info in it. You use it only once, to
transfer ownership. Hence, your true identity is not tied in to the history
of ownership.
This leads back to the question about settling disputes - if the keys
associated with the owner of the coin do not identify him, he could attempt
to use the same coin more than once. This could perhaps be circumvented by
having a single registry. The merchant would wait until the registry showed
her (her key) to be the owner before handing over the goods.

@_date: 1993-02-19 09:51:53
@_author: nobody@pmantis.berkeley.edu 
@_subject: anonymous mail 
This message routed through 7 remailers, sent around 11:45 CST 2/19/93:
pmantis -> soda -> alumni -> rosebud -> mead -> shell -> buffalo
All welcome the new remailer Rusty has set up!
Also, congrats to Chael Hall for his efforts - I'm testing his remailer
as well for inclusion in various scripts.
(Eric, I'm not getting any responses back from your remailer for some reason, even if I just use it as a single hop)
Look for the 8 remailer routing confirmation coming soon - also
through rebma.
If there's some temporary problem with cicada and it's fixed, look for
the 9 remailer hopping message.
And if that shows, look for the 10 remailer routed message (now that's
security) utilizing extropia if I have to build the headers myself!!
Question: of the unix users, who does NOT have access to ksh (via your
login shell or  or somewhere else)?  Rewriting hop.mail in
ksh would allow me to support extropia, and reverse the chaining
direction (that is, route the mail as you specify and not actually in
DOS folks can expect hopmail.exe (source + executable) because I don't
think its possible in the native batch language.
Well, I guess you can figure out who this is, so

@_date: 1993-02-19 23:23:19
@_author: nobody@pmantis.berkeley.edu 
@_subject: anonymous mail 
This message routed through 8 remailers, sent around 11:50 CST 2/19/93:
pmantis -> soda -> alumni -> rebma -> rosebud -> mead -> shell -> buffalo
Actually, rewriting hop.mail and anon.mail in PERL might be a good idea...
Signed,  ?

@_date: 1993-01-20 00:13:14
@_author: nobody@pmantis.berkeley.edu 
@_subject: ILF Brings You Gilmore in Sci Am 
The Information Liberation Front brings you this article from the
February, 1993 "Scientific American."
Electronic Envelopes?
The uncertainty of keeping e-mail private
Recent legislative efforts to mandate remote wiretapping attachments
for every telephone system and computer network in the U.S. may have
been the best thing that ever happened for encryption software. "We
have mostly the FBI to thank," says John Gilmore of Cygnus Support in
Palo Alto, Calif. Gilmore is an entrepreneur, hacker and electronic
civil libertarian who helped to found the Electronic Frontier
Foundation (EFF). He is now watching closely the development of two
competing techniques for keeping electronic mail private.
As matters now stand, computers transmit messages from one user to
another in plain text. If a geneticist m Boston sends e-mail to a
molecular biologist in San Diego, any of the half a dozen or so
intermediary machines that forward the letter could siphon off a
copy- -and so could any of the dozens of workstations that might be
attached to the local-area network at the sender's or recipient's
university or company.
The Electronic Privacy Act of 1986 prohibits snooping by public e-
mail carriers or law-enforcement officials, except by court order.
Nevertheless, many people are becoming uncomfortable with the
electronic equivalent of mailing all their correspondence on
postcards and relying on people to refrain from reading it. They are
turning to public-key encryption, which allows anyone to encode a
message but only the recipient to decode it. Each user has a public
key, which is made widely available, and a closely guarded secret
key. Messages encrypted with one key can be decrypted only with the
other, thus also making it possible to "sign" messages by encrypting
them with the private key [see "Achieving Electronic Privacy," by
David Chaum; SCIENTIFIC AMERICAN, August 1992].
Two programs--and two almost diametrically opposed viewpoints
embodied in them--are competing for acceptance. Privacy Enhanced Mail
(PEM) is the long-awaited culmination of years of international
standard setting by computer scientists. Pretty Good Privacy (PGP) is
a possibly illegal work of "guerrilla freeware" originally written by
software consultant Philip Zimmermann.
The philosophies of PEM and PGP differ most visibly with respect to.
key management, the crucial task of ensuring that the public keys
that encode messages actually belong to the intended recipient rather
than a malevolent third party. PEM relies on a rigid hierarchy of
trusted companies, universities and other institutions to certify
public keys, which are then stored on a "key server" accessible over
the Internet. To send private mail, one asks the key server for the
public key of the addressee, which has been signed by the appropriate
certification authorities. PGP, in contrast, operates on what
Zimmermann calls "a web of trust": people who wish to correspond
privately can exchange keys directly or through trusted
intermediaries. The intermediaries sign the keys that they pass on,
thus certifying their authenticity.
PGP's decentralized approach has gained a wide following since its
initial release in June 1991, according to Hugh E. Miller of Loyola
University in Chicago, who maintains an electronic mailing list for
discussion among PGP users. His personal "keyring" file contains
public keys for about 100 correspondents, and others have keyrings
containing far more. As of the end of 1992, meanwhile, a final
version of PEM had not been officially released. Gilmore, who
subscribes to the electronic mailing list for PEM developers, says he
has seen "only five or 10" messages actually encrypted using the
Although PGP's purchase price is right--it is freely available over
the Internet and on electronic bulletin boards throughout the
world--it does carry two liabilities that could frighten away
potential users. First, U.S. law defines cryptographic hardware and
software as "munitions." So anyone who is caught making a copy of the
program could run afoul of export-control laws. Miller calls this
situation "absurd," citing the availability of high-quality
cryptographic software on the streets of Moscow.
Worse yet, RSA Data Security in Redwood City, Calif., holds rights to
a U.S. patent on the public-key encryption algorithm, and D. James
Bidzos, the company's president, asserts that anyone using or
distributing PGP could be sued for infringement. The company has
licensed public-key software to corporations and sells its own
encrypted-mail package (the algorithm was developed with federal
support, and so the government has a royalty-free license). When
Bidzos's attorneys warned Zimmermann that he faced a suit for
developing PGP, he gave up further work on the program.
Instead PGP's ongoing improvements are in the hands of an
international team of software developers who take advice from
Zimmermann by e-mail. The U.S. is the only nation that permits the
patenting of mathematical algorithms, and so programmers in the
Netherlands or New Zealand apparently have little to fear.
U.S. residents who import the program could still face legal action,
although repeated warnings broadcast in cryptography discussion
groups on computer networks have yet to be superseded by legal
filings. Meanwhile, Gilmore says, the only substantive effect of the
patent threat is that development and use of cryptographic tools have
been driven out of the U.S. into less restrictive countries.
--Paul Wallich

@_date: 1993-07-27 11:52:41
@_author: nobody@pmantis.berkeley.edu 
@_subject: Nose against the grindstone 
X-Really-From: Dave Mandl (dmandl at lehman.com)
I considered (for a couple of seconds) responding to P.M.'s request, but
then decided against it.  I'm sure he's a nice guy, but I generally don't
trust mainstream journalists too much and don't go out of my way to talk
to them.  People may have actually made a decision not to talk to him, so
I wouldn't assume it's "apathy" or anything like that.  (I'm sensitive about
this because people are always accusing anti-voting anarchists of "apathy,"
and that gets us hopping mad.)
On the subject of the T-shirts: I agree that they should not be too, er,
cryptic.  They shouldn't be just a way for us to pat ourselves on the
back and be in-group-ish, but a way to spread the word.  I also think we
should try to accommodate the different political views in the group (which
are not all that different anyway) by avoiding use of the American flag,
references to Jefferson, etc.  We should stick to issues we all agree
on, which there are plenty of: Anti-Big Brother, Anti-NSA/CIA/FBI,
pro-privacy, libertarianism (capital or small "L"), freedom of information,
   --Dave.

@_date: 1993-07-29 11:43:43
@_author: nobody@pmantis.berkeley.edu 
@_subject: Chaum's Dining Cryptographers [LONG] (was: Digital Money again) 
Someone suggested that Allan Bailey seek this paper on soda.berkeley.edu. It is
not there, but it was posted to the list last December. Here it is again.
Remailed-By: Tommy the Tourist The following article is brought to you by the Information Liberation
Front (ILF), a group dedicated to the timely distribution of important
information. The ILF encourages you to use this article for educational purposes
only and to seek out the original article. Minor spelling errors and
slight alterations of formulas may have gotten past the OCR process.
We apologize for the length, but feel this is one of the key articles
in this area. J. Cryptology (1988) 1:65-75
The Dining Cryptographers Problem:
Unconditional Sender and Recipient Untraceability
David Chaum
Centre for Mathematics and Computer Science, Kruislan 413, 1098 SJ Amsterdam, The Netherlands
Abstract.  Keeping confidential who sends which messages, in a world where any physical transmission can be traced to its origin, seems impossible. The solution presented here is unconditionally or cryptographically secure, depending on whether it is based on one-time-use keys or on public keys, respectively. It can be adapted to address efficiently a wide variety of practical considerations.
Key words.  Untraceability, Unconditional Security, Pseudonymity.
Three cryptographers are sitting down to dinner at their favorite three-star restaurant. Their waiter informs them that arrangements have been made with the maitre d'hotel for the bill to be paid anonymously. One of the cryptographers might be paying for the dinner, or it might have been NSA (U.S. National Security Agency). The three cryptographers respect each other's right to make an anonymous payment, but they wonder if NSA is paying. They resolve their uncertainty fairly by carrying out the following protocol:
Each cryptographer flips an unbiased coin behind his menu, between him and the cryptographer on his right, so that only the two of them can see the outcome. Each cryptographer then states aloud whether the two coins he can see--the one he flipped and the one his left-hand neighbor flipped--fell on the same side or on different sides. If one of the cryptographers is the payer, he states the opposite of what he sees. An odd number of differences uttered at the table indicates that a cryptographer is paying; an even number indicates that NSA is paying (assuming that the dinner was paid for only once). Yet if a cryptographer is paying, neither of the other two learns anything from the utterances about which cryptographer it is.
To see why the protocol is unconditionally secure if carried out faithfully, consider the dilemma of a cryptographer who is not the payer and wishes to find out which cryptographer is. (If NSA pays, there is no anonymity problem.) There are two cases. In case (1) the two coins he sees are the same, one of the other cryptographers said "different," and the other one said "same." If the hidden outcome was the same as the two outcomes he sees, the cryptographer who said "different" is the payer; if the outcome was different, the one who said "same" is the payer. But since the hidden coin is fair, both possibilities are equally likely. In case (2) the coins he sees are different; if both other cryptographers said "different," then the payer is closest to the coin that is the same as the hidden coin; if both said "same," then the payer is closest to the coin that differs from the hidden coin. Thus, in each subcase, a nonpaying cryptographer learns nothing about which of the other two is paying.
The cryptographers become intrigued with the ability to make messages public untraceably. They devise a way to do this at the table for a statement of arbitrary length: the basic protocol is repeated over and over; when one cryptographer wishes to make a message public, he merely begins inverting his statements in those rounds corresponding to 1 's in a binary coded version of his message. If he notices that his message would collide with some other message, he may for example wait a number of rounds chosen at random from a suitable distribution before trying to transmit again.
1. Generalizing the Approach
During dinner, the cryptographers also consider how any number of participants greater than one can carry out a version of the protocol. (With two participants, only nonparticipant listeners are unable to distinguish between the two potential senders.) Each participant has a secret key bit in common with, say, every other participant. Each participant outputs the sum, modulo two, of all the key bits he shares, and if he wishes to transmit, he inverts his output. If no participant transmits, the modulo two sum of the outputs must be zero, since every key bit enters exactly twice; if one participant transmits, the sum must be one. (In fact, any even number of transmitting participants yields zero, and any odd number yields one.) For j rounds, each participant could have a j-bit key in common with every other participant, and the ith bit of each such key would be used only in the ith round. Detected collision of messages leads to attempted retransmission as described above; undetected collision results only from an odd number of synchronized identical message segments. (Generalization to fields other than GF(2) is possible, but seems to offer little practical advantage.)
Other generalizations are also considered during dinner. The underlying assumptions are first made explicit, including modeling key-sharing arrangements as graphs. Next, the model is illustrated with some simple examples. The potential for cooperations of participants to violate the security of others is then looked at. Finally, a proof of security based on systems of linear equations is given.
1.1. Model
Each participant is assumed to have two kinds of secret: (a) the keys shared with other participants for each round; and (b) the inversion used in each round (i.e., a 1 if the participant inverts in that round and a 0 if not). Some or all of a participant's secrets may be given to other participants in various forms of collusion, discussion of which is postponed until Section 1.3. (For simplicity in exposition, the possibility of secrets being stolen is ignored throughout.)
The remaining information about the system may be described as: (a)
who shares keys with whom; and (b) what each participant outputs
during each round (the modulo two sum of that participant's keys and
inversion). This information need not be secret to ensure
untraceability. If it is publicly known and agreed, it allows various
extensions discussed in Sections 2.5 and 2.6. The sum of all the
outputs will, of course, usually become known to all participants.
In the terminology of graphs, each participant corresponds to a vertex and each key corresponds to an edge. An edge is incident on the vertices corresponding to the pair of participants that shares the corresponding key. From here on, the graph and dinner-table terminologies will be used interchangeably. Also, without loss of generality, it will be assumed that the graph is connected (i.e., that a path exists between every pair of vertices), since each connected component (i.e., each maximal connected subgraph) could be considered a separate untraceable-sender system.
An anonymity set seen by a set of keys is the set of vertices in a connected component of the graph formed from the original graph by removing the edges concerned. Thus a set of keys sees one anonymity set for each connected partition induced by removing the keys. The main theorem of Section 1.4 is essentially that those having only the public information and a set of keys seeing some anonymity set can learn nothing about the members of that anonymity set except the overall parity of their inversions. Thus, for example, any two participants connected by at least one chain of keys unknown to an observer are both in the same anonymity set seen by the observer's keys, and the observer gains nothing that would help distinguish between their messages.
1.2. Some Examples
A few simple consequences of the above model may be illustrative. The anonymity set seen by the empty set (i.e., by a nonparticipant observer) is the set of all vertices, since the graph is assumed connected and remains so after zero edges are removed. Also, the anonymity sets seen by the full set of edges are all singleton sets, since each vertex's inversion is just the sum of its output and the corresponding key bits.
If all other participants cooperate fully against one, of course no protocol can keep that singleton's messages untraceable, since untraceability exists only among a set of possible actors, and if the set has only one member, its messages are traceable. For similar reasons, if a participant believes that some subset of other participants will fully cooperate against him, there is no need for him to have keys in common with them.
A biconnected graph (i.e., a graph with at least two vertex-disjoint paths between every pair of vertices) has no cut-vertices (i.e., a single vertex whose removal partitions the graph into disjoint subgraphs). In such a graph, the set of edges incident on a vertex v sees (apart from v) one anonymity set containing all other vertices, since there is a path not containing v between every pair of vertices, and thus they form a connected subgraph excluding v; each participant acting alone learns nothing about the contribution of other participants.
1.3. Collusion of Participants
Some participants may cooperate by pooling their keys in efforts to trace the messages of others; such cooperation will be called collusion. For simplicity, the possibilities for multiple collusions or for pooling of information other than full edges will be ignored. Colluders who lie to each other are only touched on briefly, in Section 2.6.
Consider collusion in a complete graph. A vertex is only seen as a singleton anonymity set by the collection of all edges incident on it; all other participants must supply the key they share with a participant in order to determine that participant's inversions. But since a collusion of all but one participant can always trace that participant merely by pooling its members' inversions as already mentioned, it gains nothing more by pooling its keys. The nonsingleton anonymity set seen by all edges incident on a colluding set of vertices in a complete graph is the set of all other vertices; again, a collusion yields nothing more from pooling all its keys than from pooling all its inversions.
Now consider noncomplete graphs. A full collusion is a subset of participants pooling all of their keys. The pooled keys see each colluder as a singleton anonymity set; the colluders completely sacrifice the untraceability of their own messages. If a full collusion includes a cut-
set of vertices (i.e., one whose removal partitions the graph), the collusion becomes nontrivial because it can learn something about the origin of messages originating outside the collusion; the noncolluding vertices are partitioned into disjoint subgraphs, which are the anonymity sets seen by the pooled keys.
Members of a partial collusion pool some but not all of their keys. Unlike the members of a full collusion, each member of a partial collusion in general has a different set of keys. For it to be nontrivial, a partial collusion's pooled keys must include the bridges or separating edges of a segregation or splitting of the graph (i.e., those edges whose removal would partition the graph). Settings are easily constructed in which the pooled keys see anonymity sets that partition the graph and yet leave each colluder in a nonsingleton partition seen by any other participant. Thus, colluders can join a collusion without having to make themselves completely traceable to the collusion's other members.
1.4. Proof of Security
Consider, without loss of generality, a single round in which say some full collusion knows some set of keys. Remove the edges known to the collusion from the key-sharing graph and consider any particular connected component C of the remaining graph. The vertices of C thus form an anonymity set seen by the pooled keys.
Informally, what remains to be shown is that the only thing the collusion learns about the members of C is the parity sum of their inversions. This is intuitively apparent, since the inversions of the members of C are each in effect hidden from the collusion by one or more unknown key bits, and only the parity of the sum of these key bits is known (to be zero). Thus the inversions are hidden by a one-time pad, and only their parity is revealed, because only the parity of the pad is The setting is formalized as follows: the connected component C is comprised of rn vertices and n edges. The incidence matrix M of C is defined as usual, with the vertices labeling the rows and the edges labeling the columns. Let K, I, and A be stochastic variables defined on GF(2)^n, GF(2)^m, and GF(2)^m, respectively, such that
K is uniformly distributed over GF(2)^n, K and I are mutually independent, and A = (MK) cross I. In terms of the protocol, K comprises the keys corresponding to the edges, I consists of the inversions corresponding to the vertices, and A is formed by the outputs of the vertices. Notice that the parity of A (i.e., the modulo two sum of its components) is always equal to the parity of I, since the columns of M each have zero parity. The desired result is essentially that A reveals no more information about I than the parity of 1. More formally:
Theorem.  Let a be in GF(2)^n. For each i in GF(2)^n, which is assumed by I with nonzero probability and which has the same parity as a, the conditional probability that A = a given that I = i is 2^(1 - m). Hence, the conditional probability that I = i given that A = a is the a priori probability that I = i.
Proof.  Let i be an element of GF(2)^n have the same parity as a. Consider the system of linear equations (MK) cross i = a, in k an element of GF(2)^n. Since the columns of M each have even parity, as mentioned above, its rows are linearly dependent over GF(2)^m. But as a consequence of the connectedness of the graph, every proper subset of rows of M is linearly independent. Thus, the rank of M is m - 1, and so each vector with zero parity can be written as a linear combination of the columns of M. This implies that the system is solvable because i cross a has even parity. Since the set of n column vectors of M has rank m - 1, the system has exactly 2^(n - m + 1) solutions.
Together with the fact that K and I are mutually independent and that K is uniformly distributed, the theorem follows easily.                           2. Some Practical Considerations
After dinner, while discussing how they can continue to make untraceable statements from this respective homes, the cryptographers take up a variety of other topics. In particular, they consider different ways to establish the needed keys; debate adapting the approach to various kinds of communication networks; examine the traditional problems of secrecy and authentication in the context of a system that can provide essentially optimal untraceability; address denial of service caused by malicious and devious participants; and propose means to discourage socially undesirable messages from being sent.
2.1. Establishing Keys
One way to provide the keys needed for longer messages is for one member of each pair to toss many coins in advance. Two identical copies of the resulting bits are made, say each on a separate optical disk. Supplying one such disk (which today can hold on the order of 10^10 bits) to a partner provides enough key bits to allow people to type messages at full speed for years. If participants are not transmitting all the time, the keys can be made to last even longer by using a substantially slower rate when no message is being sent; the full rate would be invoked automatically only when a 1 bit indicated the beginning of a message. (This can also reduce the bandwidth requirements discussed in Section 2.2.)
Another possibility is for a pair to establish a short key and use a cryptographic pseudorandom-sequence generator to expand it as needed. Of course this system might be broken if the generator were broken. Cryptanalysis may be made more difficult, however, by lack of access to the output of individual generators. Even when the cryptographers do not exchange keys at dinner, they can safely do so later using a public-
key distribution system (first proposed by [4] and [3]).
2.2 Underlying Communication Techniques
A variety of underlying communication networks can be used, and their topology need not be related to that of the key-sharing graph.
Communication systems based on simple cycles, called rings, are common in local area networks. In a typical ring, each node receives each bit and passes it round-robin to the next node. This technology is readily adapted to the present protocols. Consider a single-bit message like the "I paid" message originally sent at the dinner table. Each participant exclusive-or's the bit he receives with his own output before forwarding it to the next participant. When the bit has traveled full circle, it is the exclusive-or sum of all the participants' outputs, which is the desired result of the protocol. To provide these messages to all participants, each bit is sent around a second time by the participant at the end of the loop.
Such an adapted ring requires, on average, a fourfold increase in bandwidth over the obvious traceable protocols in which messages travel only halfway around on average before being taken off the ring by their recipients. Rings differ from the dinner table in that several bit-
transmission delays may be required before all the outputs of a particular round are known to all participants; collisions are detected only after such delays.
Efficient use of many other practical communication techniques requires participants to group output bits into blocks. For example, in high-capacity broadcast systems, such as those based on coaxial cable, surface radio, or satellites, more efficient use of channel capacity is obtained by grouping a participant's contribution into a block about the size of a single message (see, e.g., [5]). Use of such communication techniques could require an increase in bandwidth on the order of the number of participants.
In a network with one message per block, the well-known contention protocols can be used: time is divided evenly into frames; a participant transmits a block during one frame; if the block was garbled by collision (presumably with another transmitted block), the participant waits a number of frames chosen at random from some distribution before attempting to retransmit; the participants' waiting intervals may be adjusted on the basis of the collision rate and possibly of other heuristics [5].
In a network with many messages per block, a first block may be used by various anonymous senders to request a "slot reservation" in a second block. A simple scheme would be for each anonymous sender to invert one randomly selected bit in the first block for each slot they wish to reserve in the second block. After the result of the first block becomes known, the participant who caused the ith 1 bit in the first block sends in the ith slot of the second block.
2.3. Example Key-Sharing Graphs
In large systems it may be desirable to use fewer than the m(m - 1)/2 keys required by a complete graph. If the graph is merely a cycle, then individuals acting alone learn nothing, but any two colluders can partition the graph, perhaps fully compromising a participant immediately between them. Such a topology might nevertheless be adequate in an application in which nearby participants are not likely to collude against one another.
A different topology assumes the existence of a subset of participants who each participant believes are sufficiently unlikely to collude, such as participants with conflicting interests. This subset constitutes a fully connected subgraph, and the other participants each share a key with every member of it. Every participant is then untraceable among all the others, unless all members of the completely connected subset cooperate. (Such a situation is mentioned again in Section 3.)
If many people wish to participate in an untraceable communication system, hierarchical arrangements may offer further economy of keys. Consider an example in which a representative from each local fully connected subgraph is also a member of the fully connected central subgraph. The nonrepresentative members of a local subgraph provide the sum of their outputs to their representative. Representatives would then add their own contributions before providing the sum to the central subgraph. Only a local subgraph's representative, or a collusion of representatives from all other local subgraphs, can recognize messages as coming from the local subgraph. A collusion comprising the representative and all but one nonrepresentative member of a local subgraph is needed for messages to be recognized as coming from the remaining member.
2.4. Secrecy and Authentication
What about the usual cryptologic problems of secrecy and A cryptographer can ensure the secrecy of an anonymous message by encrypting the message with the intended recipient's public key. (The message should include a hundred or so random bits to foil attempts to confirm a guess at its content [1].) The sender can even keep the identity of the intended recipient secret by leaving it to each recipient to try to decrypt every message. Alternatively, a prearranged prefix could be attached to each message so that the recipient need only decrypt messages with recognized prefixes. To keep even the multiplicity of a prefix's use from being revealed, a different prefix might be used each time. New prefixes could be agreed in advance, generated cryptographically as needed, or supplied in earlier messages.
Authentication is also quite useful in systems without identification.
Even though the messages are untraceable, they might still bear
digital signatures corresponding to public-key "digital pseudonyms"
[1]; only the untraceable owner of such a pseudonym would be able to
sign subsequent messages with it. Secure payment protocols have
elsewhere been proposed in which the payer and/or the payee might be
untraceable [2]. Other protocols have been proposed that allow
individuals known only by pseudonyms to transfer securely information
about themselves between organizations [2]. All these systems require
solutions to the sender untraceability problem, such as the solution
presented here, if they are to protect the unlinkability of pseudonyms
used to conduct transactions from home.
2.5. Disruption
Another question is how to stop participants who, accidentally or even intentionally, disrupt the system by preventing others from sending messages. In a sense, this problem has no solution, since any participant can send messages continuously, thereby clogging the channel. But nondisupters can ultimately stop disruption in a system meeting the following requirements: (1) the key-sharing graph is publicly agreed on; (2) each participant's outputs are publicly agreed on in such a way that participants cannot change their output for a round on the basis of other participants' outputs for that round; and (3) some rounds contain inversions that would not compromise the untraceability of any nondisrupter.
The first requirement has already been mentioned in Section 1.1, where it was said that this information need not be secret; now it is required that this information actually be made known to all participants and that the participants agree on it.
The second requirement is in part that disrupters be unable (at least with some significant probability) to change their output after hearing other participants' outputs. Some actual channels would automatically ensure this, such as broadcast systems in which all broadcasts are made simultaneously on different frequencies. The remainder of the second requirement, that the outputs be publicly agreed on, might also be met by broadcasting. Having only channels that do not provide it automatically, an effective way to meet the full second requirement would be for participants to "commit" to their outputs before making them. One way to do this is for participants to make public and agree on some (possibly compressing and hierarchical, see Section 2.6) one-way function of their outputs, before the outputs are made public.
The third requirement is that at least some rounds can be contested (i.e., that all inversions can be made public) without compromising the untraceability of non-disrupting senders. The feasibility of this will be demonstrated here by a simple example protocol based on the slot reservation technique already described in Section 2.2.
Suppose that each participant is always to make a single reservation in each reserving block, whether or not he actually intends to send a message. (Notice that, because of the "birthday paradox," the number of bits per reserving block must be quadratic in the number of participants.) A disrupted reserving block would then with very high probability have Hamming weight unequal to the number of participants. All bits of such a disrupted reserving block could be contested without loss of untraceability for nondisrupters.
The reserved blocks can also be made to have such safely contestable
bits if participants send trap messages. To lay a trap, a participant
first chooses the index of a bit in some reserving block, a random
message, and a secret key. Then the trapper makes public an
encryption, using the secret key, of both the bit index and the random
message. Later, the trapper reserves by inverting in the round
corresponding to the bit index, and sends the random message in the
resulting reserved slot. If a disrupter is unlucky enough to have
damaged a trap message, then release of the secret key by the trapper
would cause at least one bit of the reserved slot to be contested.
With the three requirements satisfied, it remains to be shown how if enough disrupted rounds are contested, the disrupters will be excluded from the network.
Consider first the case of a single participant's mail computer disrupting the network. If it tells the truth about contested key bits it shares (or lies about an even number of bits), the disrupter implicates itself, because its contribution to the sum is unequal to the sum of these bits (apart from any allowed inversion). If, on the other hand, the single disrupter lies about some odd number of shared bits, the values it claims will differ from those claimed for the same shared bits by the other participants sharing them. The disrupter thereby casts suspicion on all participants, including itself, that share the disputed bits. (It may be difficult for a disrupter to cast substantial suspicion on a large set of participants, since all the disputed bits will be in common with the disrupter.) Notice, however, that participants who have been falsely accused will know that they have been--and by whom--and should at least refuse to share bits with the disrupter in the future.
Even with colluding multiple disrupters, at least one inversion must be revealed as illegitimate or at least one key bit disputed, since the parity of the outputs does not correspond to the number of legitimate inversions. The result of such a contested round will be the removal of at least one edge or at least one vertex from the agreed graph. Thus, if every disruptive action has a nonzero probability of being contested, only a bounded amount of disruption is possible before the disrupters share no keys with anyone in the network, or before they are revealed, and are in either case excluded from the network.
The extension presented next can demonstrate the true value of disputed bits, and hence allows direct incrimination of disrupters.
2.6. Tracing by Consent
Antisocial use of a network can be deterred if the cooperation of most participants makes it possible, albeit expensive, to trace any message. If, for example, a threatening message is sent, a court might order all participants to reveal their shared key bits for a round of the message. The sender of the offending message might try to spread the blame, however, by lying about some odd number of shared bits. Digital signatures can be used to stop such blame-spreading altogether. In principle, each party sharing a key could insist on a signature, made by the other party sharing, for the value. of each shared bit.
Such signatures would allow for contested rounds to be fully resolved,
for accused senders to exonerate themselves, and even for colluders to
convince each other that they are pooling true keys.  Unfortunately,
cooperating participants able to trace a message to its sender could
convince others of the message's origin by revealing the sender's own
signatures. A variation can prevent a participant's signatures from
being used against him in this way: instead of each member of a pair
of participants signing the same shared key bit, each signs a separate
bit, such that the sum of the signed bits is the actual shared key
bit. Signatures on such "split" key bits would still be useful in
resolving contested rounds, since if one contester of a bit shows a
signature made by the second contester, then the second would have to
reveal the corresponding signature made by the first or be thought to
be a disrupter.
In many applications it may be impractical to obtain a separate signature on every key bit or split key bit. The overhead involved could be greatly reduced, however, by digitally signing cryptographic compressions of large numbers of key bits. This might of course require that a whole block of key bits be exposed in showing a signature, but such blocks could be padded with cryptographically generated pseudorandom (or truly random) bits, to allow the exposure of fewer bits per signature. The number of bits and amount of time required to verify a signature for a single bit can be reduced further by using a rooted tree in which each node is the one-way compression function of all its direct descendants; only a digital signature of each participant's root need be agreed on before use of the keys comprising the leaves.
3. Relation to Previous Work
There is another multiparty-secure sender-untraceability protocol in the literature [1]. To facilitate comparison, it will be called a mix-net here, while the protocol of the present work is called a dc-net. The mix-net approach relies on the security of a true public-key system (and possibly also of a conventional cryptosystem), and is thus at best computationally secure; the dc-net approach can use unconditional secrecy channels to provide an unconditionally secure untraceable-
sender system, or can use public-key distribution to provide a computationally secure system (as described in Section 2.1).
Under some trust assumptions and channel limitations, however, mix-nets can operate where dc-nets cannot. Suppose that a subset of participants is trusted by every other participant not to collude and that the bandwidth of at least some participants' channels to the trusted subset is incapable of handling the total message traffic. Then mix-nets may operate quite satisfactorily, but dc-nets will be unable to protect fully each participant's untraceability. Mix-nets can also provide recipient untraceability in this communication environment, even though there is insufficient bandwidth for use of the broadcast approach (mentioned in Section 2.4).
If optimal protection against collusion is to be provided and the crypto-security of mix-nets is acceptable, a choice between mix-nets and dc-nets may depend on the nature of the traffic. With a mail-like system that requires only periodic deliveries, and where the average number of messages per interval is relatively large, mix-nets may be suitable. When messages must be delivered continually and there is no time for batching large numbers of them, dc-nets appear preferable.
4. Conclusion
This solution to the dining cryptographers problem demonstrates that
unconditional secrecy channels can be used to construct an
unconditional sender-untraceability channel. It also shows that a
public-key distribution system can be used to construct a
computationally secure sender-untraceability channel. The approach
appears able to satisfy a wide range of practical concerns.
I am pleased to thank Jurjen Bos, Gilles Brassard, Jan-Hendrik Evertse, and the untraceable referees for all their help in revising this article. It is also a pleasure to thank, as in the original version that was distributed at Crypto 84, Whitfield Diffie, Ron Rivest, and Gus Simmons for some stimulating dinner-table conversations.
[1]	Chaum, D., Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms, Communications of the  ACM, vol. 24, no. 2, February 1981, pp. 84-88.
[2]	Chaum, D., Security Without Identification: Transaction Systems to Make Big Brother Obsolete, Communications of the ACM, vol. 28, no. 10, October 1985, pp. 1030-1044.
[3]	Diffie, W., and Hellman, M.E., New Directions in Cryptography, IEEE Transactions on Information Theory, vol. 22, no. 6, November 1976, pp. 644-654.
[4]	Merkle, R.C., Secure Communication over Insecure Channels, Communications of the ACM, vol. 21, no. 4, 1978, pp. 294-299.
[5]	Tanenbaum, A.S., Computer Networks, Prentice Hall, Englewood Cliffs, New Jersey, 1981.
[End of Transmission]

@_date: 1993-06-16 11:45:06
@_author: nobody@pmantis.berkeley.edu 
@_subject: YAA (yet another article) 
Really from: dmandl at lehman.com
But keep in mind that it's still used often enough, just not usually
against anyone with the power or credibility to speak out about it.
Don't you remember the Queens police precinct that got involved in
that stun-gun scandal a few years ago?
   --Dave (trying to give some extra business to the anonymous remailers).

@_date: 1993-06-28 05:30:19
@_author: nobody@pmantis.berkeley.edu 
@_subject: Remailer at rebma.mn.org 
It is indeed working OK now.  Encryption is not required.  Good to see this
remailer back up, especially because it introduces a long delay, making traffic
analysis more difficult.  FYI, sending a message to myself (in NYC) through
this remailer, it took about 15 hours for it to come back.  This is either very
good or very bad depending on your purposes.  Bad for urgent messages, good for
more...er...sensitive applications.
   --Dave.

@_date: 1993-03-11 01:16:28
@_author: nobody@pmantis.berkeley.edu 
@_subject: PGP Tutorial Gone. 
soda.berkeley.edu is supposed to have several files reguarding pgp.  The
problem is that this site is refusing connections.  Could we get an
alternative site?

@_date: 1993-05-31 09:20:21
@_author: nobody@pmantis.berkeley.edu 
@_subject: No Subject 
LOOKING FOR:  MS-DOS utilities for cryptanalysis.
WHY ON EARTH WOULD I WANT SUCH A THING? I'm analyzing a piece of encryption shareware advertised on
comp.archives.msdos.announce.  The author proudly claims that:
"The algorithm used was developped independently of any
literature on the subject of data encryption.  The author hasn't read any texts on this subject and any ressemblance that may or may not exist between this algorithm and any previous algorithms is purely coincidental."
He charges $15.00 for it too...  One of those "secret algorithm"
PARTICULAR TOOLS I'D USEFUL...
- A binary file editor/composer with hex and ascii displays
- A tool for generating and viewing letter frequencies, digram/
trigram frequencies
I've been able to get by with stuff I have lying around and
quick programs I written as needed.  But it sure would be nice
if there were some slick utilities made for the job!
I looked on soda in pub/cypherpunks/cryptanalysis and found nothing useful.
If anyone has anything like this, please, *please* upload it
to soda...
-the Cire

@_date: 1993-11-14 09:23:56
@_author: nobody@pmantis.berkeley.edu 
@_subject: CIA admits Timothy May Surveillance: PHOTOS! 
________________
      /                \
     / /          \ \   \
                  |
    /                  /
      ___\ \| | / /
      /           |
      |     __    |
  /       |       \   |
       |        \  |              "HEH HEH HEH !!!!!"
       |       __  |             L. Detweiler can eat my
      __\     (_o) |               shorts!  Am I Beavis
     |             |          /       or am I tcmay?
   \    ||             \        /      PSEUDOSPOOF THIS!
   |__             \
   |           (*___\
   |       _     |
   |    //_______|
  /       |_|_|_|___/\
     \|       \ -         |
       _----_______/
      /

@_date: 1993-11-16 21:34:15
@_author: nobody@pmantis.berkeley.edu 
@_subject: BAN Detweiler(WHAT A LOON) 
I THINK ITS TIME TO TAKE DETWEILER OFF THE MAILING LIST,
HE IS CLEARLY ABUSING THE PRIVELGE OF HAVING US AS AN AUDIENCE.
ANY OTHERS ON THIS SIDE OF THE ISSUE??
      ANON

@_date: 1993-11-22 20:35:08
@_author: nobody@pmantis.berkeley.edu 
@_subject: PGP-okay BBS? 
A few months ago we discussed Fidonet, securenet, and PGP. How can I find a
BBS that allows PGP traffic? Is there an equivalent of the nixpub list for

@_date: 1993-10-06 07:35:22
@_author: nobody@pmantis.berkeley.edu 
@_subject: Enough already! 
Has everyone on this list lost their minds?  Can't someone give
a well-intentioned piece of advice without getting bogged down
in a ten-day flame war?  I don't think anyone here questions
the integrity of the EFF.  They were trying to help by giving
the names of those outlaw GIFs.  What's the big deal?
If there's someone smoking a cigarette on the subway platform
and I see a cop coming, I'll tip the person off.  Common courtesy.
(I'm not saying this is the exact same thing that the EFF is doing,
just making an analogy.)  Why blow this all out of proportion?
Please do your part to save bandwidth and keep S/N as high as
possible.  If you're going to harangue people, do it via private
email.  Probably 40% of cypherpunk posts in the last few weeks
have been stupid bickering that never should have started and
probably persuaded quite a few people to unsubscribe besides.
There's no need to let everyone on the list know about every
tiny disagreement you have with someone's opinion.  Especially
when that person clearly has the best of intentions.
Maybe we SHOULD make people pay to post the list.
-Mr. Funn

@_date: 1993-09-09 16:27:27
@_author: nobody@pmantis.berkeley.edu 
@_subject: Crypto Visions 
Hey Nick, visionary stuff in general, but . . .
szabo>* Internet Casino: why travel to Las Vegas or Monte Carlo when szabo>you can play the finest games in the privacy of your own home?
Maybe it's time you stopped working on the CRT tan, and checked out
the showgirls :-).   There is *virtually* nothing like it.

@_date: 1994-02-02 13:05:34
@_author: nobody@pmantis.berkeley.edu 
@_subject: anonymous mail 
There's a jerk that's been mail-bombing me, and I can't do anything
because he's root at his site.  Would it be ethical to use a remailer to bomb him back?
Or maybe I shoudl simply fakemail a message to alt.fan.rush-limbaugh at anon.penet.fi with his name and have the contents say something like 'Limbaugh sucks', or post to alt.sex.wanted with the subject 'SWF virgin seeks man for first time'.
Any ideas on how to get someone back, or at least make life annoying?

@_date: 1994-02-02 23:31:05
@_author: nobody@pmantis.berkeley.edu 
@_subject: A serious question of ethics 
Ok, I'm in a bit of a quandry.  While surfing the net last week, I
happened across an address addached to a machine that belongs the the federal reserve.  No big deal.  I telnetted there on a lark, and entered 'guest' for the account.  It dropped me into a shell.  It didn't ask for a password.  Intrigued, I did a little looking around.  Nothing special, a CDRom and about 80 accounts.  But(!!), /etc/passwd was there and available and not using shadows.  No, I didn't snatch a copy.
1)  Should I alert someone there about the obvious (and, IMHO serious) seciruty hole?
2)  Should I ignore it?
3)  Should I take advantage of it (well, maybe not)
I don't like to see systems so open, no matter who they belong too, and the fact that the governments (whether you like them or not) has one this open REALLY bothers me. But, I also wonder what kind of trouble I could get into.  Technically, I violated something just by being there as I didn't have permission, and the fact I accessed the passwd file makes it even worse.  If I report it, I could be in deep shit.
I could mail to them via a remailer (like penet.fi, so that they could answer for more information if needed).  That is a little securer and Julf is out of jurisdiction of the FBI hunting me down.
Yes, I'm a little paranoid, but Uncle Sam likes to make examples out of white-collar hackers, and for me it was pure and dumb luck (like a jury would believe a 22 year-old computer geek isn't trying to gain illegal Any suggestions?  Please?  I consider this to be serious (most may not).

@_date: 1994-02-05 11:15:39
@_author: nobody@pmantis.berkeley.edu 
@_subject: Military & dependants 
Can American Military members or their family take copies of PGP
or other encryption programs with them when being stationed at
overseas bases?  Aren't the overseas installations considered to
be American soil while occupied, thus permitting such transfers?
There can be only one!

@_date: 1994-02-05 21:10:23
@_author: nobody@pmantis.berkeley.edu 
@_subject: Remailer Security 
Just a qucik question.
How safe am I from being traced if I use a remailer?  If I hop it through say three of them?

@_date: 1994-02-07 10:40:37
@_author: nobody@pmantis.berkeley.edu 
@_subject: A serious question of ethics 
Does that mean that I no longer should report the open system (I don't dare telnet there to find out if it is the same one)?
Also, and I'm purely curious, what actually became of my anonymous report, and do I need to be worried about SS agents in dark sunglasses coming to my home and dragging me away?  (Truely worried and scared)

@_date: 1994-02-25 15:11:32
@_author: nobody@pmantis.berkeley.edu 
@_subject: lists of U.S. cypherpunks and Tentacles. 
Yeah, right.  And let's get the names and addresses of all the gun
owners in the US too...

@_date: 1994-01-12 04:12:03
@_author: nobody@pmantis.berkeley.edu 
@_subject: szabo@netcom.com is NOT a tentacle!!! 
As for the `Szabo being a tentacle thread' in the newsgroups, pmetzger
just posted stating that he had indeed posted the name of the town Szabo lives in, as well as the names of his roommates.  He refrained from posting that information again.  I seem to vaguely recall seeing the original post, but can't find it in the buffers here -- everything before December 21st or so has expired.  the thing that ROYALLY PISSES ME OFF is that NOONE WHO HEARD PMETZGER CLAIM THIS has POSTED TO SAY THAT THEY HEARD HIM SAY THAT. reminds me of the infamous rape and murder of that NY woman, with dozens of witnesses hearing her screams, just going about their business. who will be raped next? and who will be silent? everyone who is watching my thread, and being silent about what they know, is a hypocrite and a dangerous accomplice to lies. I guess that's a bit overstated.  I suspect people in most major metropolitan areas don't want to get involved partially because they fear retribution, and partially because, with that many people packed together, you tend to care less about your neighbors than you would in a small town, where you know the people in your building or street.  I suspect people on the net don't bother because "it's just bits" -- they read the Net like they watch TV, without any connection to the characters or dramas unfolding before them.  In large part, what is said here doesn't really matter.  People get curious, but it's not worth getting into an uproar. if YOU GIVE A DAMN, POST! Ah, there's the rub.  Deep down, I really don't care about this particular issue.  To my knowledge, Nick Szabo, whether real or not, has never said anything that has made me even care whether or not he has real.  I've never found anything he's said particularly interesting.  He's a net.person.  Should he turn out to be a "tentacle," that's fine by me -- he won't be the first I've encountered.  If he turns out to be T.C.May in disguise, all that means is that there's one less person with T.C.May's ideas in the world than people thought. I think that uncaring attitude, which I regard as fairly dominant among people who've used cyberspace (and especially Usenet) a good amount of time, is the very reason that May's ideas about widespread crypto bringing down governments will never come to pass.  People have, and I believe will continue to have, a distrust about putting much faith into computers, and thus cyberspace will always have limitations.  I believe people put a great deal of stock in the feel of a crisp paper dollar bill, as well as a smile and a handshake. :-) Perhaps to add more fuel to the fire, a Nicholas Szabo does indeed live in Cupertino, according to a 1990-1991 White Pages from the area.  There is no G.Dale listed, however.  (I was hoping to correlate the two numbers)  I suspect that I need a more recent phone book to make a better test. ------ Legalize:          >----< | act I have programmed a computer.     . .
 \  / You are ~1,000,000,000,000,000 .1ms NAND gates have a nice day.  . . .
  \/ The true theory of everything will run on a finite turing machine. . . .

@_date: 1994-01-15 03:53:02
@_author: nobody@pmantis.berkeley.edu 
@_subject: Detweiler, you are WASTING YOUR TIME 
Detweiler is apparently the only one who cares enough to waste any time
on this. He's been provided with ample information to prove or disprove his accusations. He has refused to do so, and in such a refusal, he comes off like a ranting loony. Is there any evidence
_whatsoever_ that these accounts are indeed one person?
P.Metzger and T.C May have both posted evidence that they are seperate people. In absence of _any_ evidence to the contrary,
I accept their word for it. I don't see a motive, I don't see any evidence. No smoking gun - from my perspective, it's simply
your word against theirs. Detweiler's given me not one iota of proof for your claims, just a blanket assertion. There is no reason whatsoever for me (again, I don't know anybody involved
here) to doubt their words. Detweiler, on the other hand, has alleged
a huge conspiracy that's gone to a huge amount of theoretically
tracable work (phone lines for all the pseudos in 3 different
area codes). This seems like an extremely expensive way to accomplish what should be a fairly straightforward (and I note, harmless) procedure.
I will reconsider that opinion if he can post whatever it is
that convinced you that this is one person.
I pretty much assume everything on the net is crap, since its an insecure means of communication. Anyone not convinced of this is politely directed towards their nearest zumabot posting.
Dave Criswell
The true source of Oracle Corporation's wretched desperation, and low level stooge of the vast satanic cryptoanarchist conspiracy
dcriswel at us.oracle.com

@_date: 1994-01-15 20:03:41
@_author: nobody@pmantis.berkeley.edu 
@_subject: the bitter end 
oh, how the noise hurts my ears, oh how the fires burn my eyes, oh how
my body quakes and shivers. i, the glorious memetic warrior, lie bleeding
on the rocks, the enemy has vanquished us, we have been trampled 'neath
their onslaught. i hear my fellow men groaning with spasms around me,
they call each other's names and cry out, the noxious stench of death
oppresses my nostrils. the eve grows cool, it is twilight, and the bitter
cold infiltrates my body like fog through the grass.
we were ambushed, we thought we knew the enemy's numbers, we thought our
intelligence sound. but they had tricked us in the blackest of betrayals,
all our spies were double agents, and they had stabbed us in the back.
they laughed as they crushed us. the enemy was so numerous, his location
so ubiquitous, that we could not help but be massacred in the hot sun.
there was white fear and red terror everywhere as they came from every
direction to slay us.
all our operations were useless and ineffective, our carefully crafted
future plans aborted, the enemy had infected our own nervous system with his poison, and our grisly, grotesque failures haunt my mind like shrieking phantoms. oh, my trusted friends! my fellow warriors! my noble generals! all are dead and dying, bleeding and weeping, lying and crying. my consciousness flits between moments like a thief in the shadows, i am bewildered and dazed, as fragmentary
hallucinations of my youth flash before my eyes.
oh, the horror of their weaponry! they assailed us with their bombs,
their grenades, their tanks, their planes, the machine guns pumped bullets
into our fragile flesh, our limbs scatter the battlefield, our blood lies in pools in the trenches. we went deaf with the onslaught, our
ears bleeding, our eyes blinded by the horrid wrath of fire. their blitzkrieg trampled us like bewildered ants 'neath the stamp of soldier's feet. the earth is scarred with holes and pits, and hideous shapes of artillery and shrapnel surround me like monsters looming in my nightmares.
oh, that fearsome face of mine enemy, how it glowered and glared and
burned with fire in my eyes, i saw the venemous hatred cutting and
mowing me down. their hate surpassed ours, their deadliness crushed
us unmercifully, wretchedly, horribly beneath their iron wrath.
they were monsters from beyond our nightmares but from our own reality,
and they ripped our bodies apart to feed their chiseled jaws.
the moon shines down at me now, i see the reflection in the pools of
water around me, and i am the only one left alive. i hear my rasps,
i feel my chest heave, i feel my feeble heart pump, i can feel the gentle trickle of oozing blood at my sides, my life slowly, silently,
inevitably, inextricably leaking from my body. there is only utter cold and pitch blackness, as i hear the rats scurrying through my hair and gnawing at my flesh.
 /   /   /   /   /   /   /   /   /   /   /   /   /   /   /   /   /   /
 . :         _________       _________                      _________
  .         /   / \   \     /   / \   \                    /   / \   \
\~~~~~~~~/~~~/~~~~~~~~~~~/~~~~~~~~__/~~~~~ ~~~_/~~/~~~~~/~~~~~~~~~~/ ~~
\,\     /   /  ____     /   /~\   \      /~~~~_  /     /   /~~~~~~~     :'     \   \ /   /    /   /   \   \     \ ~~~ _ \    /   /
   ;     ~~~~~~~~~     ~~~~     ~~~~      ~~~~~ ~~    ~~~~
 \   \   \   \   \   \   \   \   \   \   \   \   \   \   \   \   \   \

@_date: 1994-01-16 18:13:15
@_author: nobody@pmantis.berkeley.edu 
@_subject: CYBERSPATIAL SNAKE *SQUISHING* CONTEST!! HUGE CASH PRIZE!! 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   Introducing the SECRETLY QUIZZICAL UNIFIED INTERNET SNAKE HUNT!
          * THOUSANDS OF CONTESTANTS * HUGE CASH PRIZES *
         * FASCINATING DISCOVERIES * HEDONISTIC DELIGHTS *        * FANTASTIC FUN FOR EVERYONE * ENDLESS ENTERTAINMENT *
- INTRODUCTION
- UPDATES
- DEADLINE
- THE CASH PRIZE
- MORE ABOUT `SQUISH' & `FACE'
- QUESTIONS
The recent WHITE HOT interest by multiple groups and individuals in the                  CYBERANARCHIST TENTACLE INFILTRATIONS
into the Internet have inspired an EXCITING NEW CONTEST and COMPETITION!
we, the Federation of Associations of Cyberspace Everywhere (FACE), announce the         SUPREMELY QUACKY UNIFIED INTERNET SNAKE HUNT! (SQUISH)
          * THOUSANDS OF CONTESTANTS * HUGE CASH PRIZES *
         * FASCINATING DISCOVERIES * HEDONISTIC DELIGHTS *        * FANTASTIC FUN FOR EVERYONE * FAMOUS PARTICIPANTS *
  updates on the SQUISH contest will be posted regularly. Send in
  notice of the more spectacular point accumulations with proof for
  verifications immediately and the Halls of Fame and Shame.
  Unverified points are not valid toward the cash prize.
  TIME IS RUNNING OUT! AVOID INQUIRING FURTHER OR WAITING FOR FURTHER
  INSTRUCTIONS. START IMMEDIATELY! MONTHS OF PARTICIPATION ARE
  REQUIRED TO ACCUMULATE COMPETITIVE STANDING. SOME PARTICIPANTS
  ALREADY HAVE A HEAD START.
  THE CASH PRIZE WILL BE AWARDED APRIL 1, 1994. FURTHER INCREMENTS
  WILL BE AWARDED AT YEARLY INTERVALS THEREAFTER.
MORE ABOUT `SQUISH' AND `FACE'
  The Federation of Associations of Cyberspace, Everywhere was founded
  in 1994 as a group that coordinates the activities among the many
  different online organizations. We have played a very low-profile
  role to date, and wanted to find some way of promoting our newfound
  alliance. We have groups combined from BBSes, local area networks,
  the Internet, and other global and local networks around the world
  (see below).
  We have built up some membership funds from the contributing
  organizations and private contributions to provide the prize money
  for SQUISH, and some private individuals have donated significant
  amounts. The contest was inspired by S.Boxx, who was the architect
  of point classifications and the current opponent lists. S.Boxx has
  also promised to provide any funds necessary for the successful
  completion of the contest. We hope that recent interest into snakes
  and tentacles by many on the Internet will make the contest
  spirited entertainment and a strong success.
  We encourage reporters and the media to use this announcement as our
  official press release. Feel free to redistribute or comment on
  this announcement in any forum.
  Address further questions to cypherpunks at toad.com, gnu at toad.com,
  tcmay at netcom.com, or hughes at ah.com. Some additional information is
  available in RISKS 15.25, 15.27, 15.28x: ftp CRVAX.SRI.COM, login
  anonymous, directory RISKS: (include the colon), file RISKS-i.j
    /////       ////       //  //      ////       /////      //  //
   ///         //  //      //  //       //       ///         //  //     ////       //  //      //  //       //        ////       //////
      ///      //  //      //  //       //          ///      //  //
   /////        ///\\       ////       ////      /////       //  //
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       Introducing the STELLARLY QUOTABLE INTERNET SNAKE HUNT!
Brought to you as a coordinated effort between the individuals
  * S.BOXX
  * MEDUSA
  * INFOCALYPSE
  * THE EXECUTIONER
  * PABLO ESCOBAR
  * DEADBEAT
and the Federation of Associations of Cyberspace Everywhere (FACE)
  * ILF (INFORMATION LIBERATION FRONT)
  * BLACKNET (INTERNET ESPIONAGE COORDINATION HEADQUARTERS)
  * BLOODNET (CYBERSPATIAL BLACK MARKETEERING AND LIQUIDATION SQUAD)
  * CRAM (CYBERSPATIAL REALITY ADVANCEMENT MOVEMENT)
  * CRaP (CYBERANARCHIST REPRESSION AND POISON)
  * CY{B,PH}ER{PU,WO}NKS
          * THOUSANDS OF CONTESTANTS * HUGE CASH PRIZES *
         * FASCINATING DISCOVERIES * HEDONISTIC DELIGHTS *        * FANTASTIC FUN FOR EVERYONE * CRIMINAL CONVICTIONS *
     * GRISLY DEATH TORTURE * JUDGEMENT DAY * APOCALYPSE NOW *

@_date: 1994-01-29 17:28:36
@_author: nobody@pmantis.berkeley.edu 
@_subject: NSA/FOIA foo bar 
For what its worth, I finally received my FOIA/Privacy Act information
earlier this week from the National Security Agency, from the FOIA
information request I submitted in May 1993.
Although I also received an additional piece of mail from the DIA (it
appears that NSA must really not have _all_ the keys) asking for
verification of my identity to fufill the request I iniated with NSA, it was filled a tad quicker than the Meade people originally forecasted
(two years!).
I received what I expected, but also included in the multi-sealed envelope
was an additional surprise: two sheets containing some rather sensitive information on an individual other than myself, the person I had asked for compiled information. I simply can't imagine the looks on their faces when I promptly return it informing them that it appears that they made a rather embarrassing mistake.

@_date: 1994-01-30 09:58:56
@_author: nobody@pmantis.berkeley.edu 
@_subject: NSA/FOIA foo bar 
Sorry for being vague.
Yes, my request was for my own dossier. Additionally, there were
two sheets intermingled concerning someone else completely, with
information concerning their drug use in the '70's.
Go figure.
