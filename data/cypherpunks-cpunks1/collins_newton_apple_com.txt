
@_date: 1993-08-09 22:26:56
@_author: Scott Collins 
@_subject: Wolf's got a thing or two to say 
The message in question was ascii armored with a missing checksum.  You can
trick PGP into ignoring the missing checksum by decrypting to the screen
(only).  It is an example of the fact that most messages are more work to
decrypt than they are worth upon reading (at least to me, since I do not
know or know of 'Wolf', 'Nancy', 'Rose', 'David' or 'Officer Cooper 171' or
any of their interactions).
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com
What follows is the de-armored text of the message "(fwd) Wolf's got a
thing or two to say":
----------cut here----------
Hello friends.
I hope you are all well.
I am doing better today than before.
I get a little more livelier every day.
I am not in the mood to talk about the situation right now, though.
I would like to first of all thank each an every one of you for
the SCADS of mail I have recieved in response to my post about what
happened last Monday night.
I am not very good at those name things...where everyone who writes someone
gets listed in a thank you note.
And I am not very good at promptly answering mail either.
And I am not very good at ever getting around to answering all of the mail
I recieve.  I wish that I were better about this, but I am simply too busy.
I have tried to send a thankyou note to as many of you as I can personally.
I know for a fact that there are many replies that I recieved that went
unanswered, and for that I hope no one takes it personally.
I am not in any way trying to say that every bit of individual support is not
as important as any other.  I read every piece of mail I get!  And I respond to it if I can.
I want for all of asar to know...I thank you for being here for me and I know
who is out there on my side!
now...I have something else that is on my mind...
I will admit that I have neglected to read every post in the thread that got
ignited by Nancy's RE: David post.  I know that I have not been able to locate
the post by Rose that keeps getting reffered to.  Oh well, too bad...I still
have some things to add on my behalf and simply because seom
something about this thread is very disturbing to me.
I am going to place a spoiler here b/c I am fearful that what I am about to
say my be flame bait.  I think it might offend some of you and I do not want
to get into a situation like that again.  I have carefully considered what I
would like to express, but I get t
 he feeling that there are some people who are looking for a debate no matter
what.  So if you want to square off and hash this thread to pieces, then of
course you are certainly free to do so, but I will be much more comfortable
with this if my $.02 are inserted right here and now...
this some of she and a that is most certainly enough lines...
I agree with whoever in response to this thread posted that this is emotionally
charged stuff.  I have been a little charged by it myself.
Since I have not read Rose's part in this I cannot relate to that area of the
discussion.  Obviously Rose is upset that someone said something negative to
her.  I will try not to be cynical about it, b/c I am feeling a little bit
upity and I do not want to be rude.
I am simply a bit disturbed by Nancy's original post about my having
"gotten David arrested".
On my behalf...call it symantic quibble if you will, but it is what I did to
protect myself and I am angered that it seems to have been questioned even
no especially when even David didn't question it once he had a period to calm
No I have read where everyone thinks that for one reason or another I did the
right thing to protect myself.  But let's face it, guys.
David got himself arrested.
As for police and police brutality and fairness and justice, well, look at
the perr
peers around you.
Many of us have very little faith in the justice system of this USA.
If we had more maybe more of us would have tried a long time ago to seek out
the justice we deserve for the violations we have suffered.
I am not quick to call the police either, let me tell you.
My first experience with trying to get police to help me with being harrassed
by Dez (where I was being forced to practice prostitution and being beaten and
ravaged regularly) led me to getting punished by Dez since he had so conveniently bought off parts of the police department in my home town.  I
got the shit beat out of me first by the cops then by Dez.
So I know how fucked up the police an be.
Luckily this is a different town and a different life (well almost).
As I sit here and think of the policeman, officer Cooper 171, beating David's
head against the roof of his squad car my stomach is turning.
David is badly bruised and one of his eyes got cut.
Now I am sorry that he has had to endure this.
I think it is wrong...and I am almost certain that the force used to restrain
him was a bit excessive.  I know David and he will not fight impossible odds.
Still, I am thankful that he got a little taste of hell that night with
respect to what he put me through.  He is a little bit sensitive to what he
did to me.
None of this is meant to excuse or justify his behavior, b/c I find it totally
unacceptable and abhoring at the very least.
I am sorry for the fucking injustices of the world.
There are in fact many.
Like the girl who tried to seek justice for being gang raped but had a bad
reputation so they told he to get out of their faces that they had no time
for her little case.
That was not just a case, that was her life.
Just like Nancy's friend who served 2 years for a crime he probably did not
It is an injustice.
I think we all agree that injustices do happen in every area of our society.
What are we here for?
ARe we here with hopes that we can pinpoint the exact place where society
went wrong and change it?
no I do not think that is it (stop me if I am wrong)
I think we are here to give care and support to one another b/c we have all
suffered some pretty haneous injustices and the care we get from one another
often helps to serve some purpose towards ending that cycle.
As for Rose...was she being manipulative?
well, I do not know.
I have felt that way at times, but I have also done that at times myself...
I firmly believe in the childhood come-back "takes one to know one"
and I know that when I see someone manipulating it is only because I have
done it myself that I am able to see it.
And yes it sometimes takes a bit of tough love to break behaviors like that.
I think we all love Rose...I know that we feel for her...she seems to be in
so much pain...
I do not think we are here to pass judgement on her...
and I do not think we are here to keep someone from being taken in by a situatio
n that we may percieve as harmful to them (within the infrastructure of the
group).  We have all heard at one time or another someone on here tell us about boundarie
s andd it is still up to us as individuals to set them.
I hope that from asar more than any other place there is more tolerance of
people learning that and feeling out just how to go about that.
And at the same time I think that this is the place where I first learned how
to enforce them as well, so I hope that all of asar understands that many of
us are still trying on some  of these new clothes....
as for the RE: David thread, well, I guess I have had my say.
I am looking at this from this perspective right now, and my perspectives are
always subject to change.
So if I haven't hurt anyone's feelings or run anyone off, then good.
I do not step out and speak my mind like this often and it always feels good
when I do...
flame me if you must
just put a spoiler in it so that we will have some warning
I am up and down right now
so I am tyring to be careful about some of the stufff I read.
that is enough ranting for tonight I think.
----------cut here----------

@_date: 1993-08-11 09:56:59
@_author: Scott Collins 
@_subject: How long would it take? 
When you encrypt a message M with PGP, you are really doing several things:
        1. Generating a random IDEA key K
        2. Encrypting M with K yielding IDEA(K,M)
        3. Encrypting K with the public key of the recipient, Rpub
           yielding RSA(Rpub,K)
           (note that if YOUR key is 1256 bits, but THEIR key is only 512 bits,
           you only get 512 bits of 'security' because you are encrypting to
           them, not to yourself)
        4. Sending (essentially) the message {RSA(Rpub,K)+IDEA(K,M)}
Someone who wants to read the message (e.g., the recipient or some
interceptor) must either know Rpri (Rpub's corresponding private key) to
extract K, or must be able to break RSA, or must know K a priori, or must
be able to break IDEA.
This is a lot of ways to get in.  Most of them prohibitive, except for the
recipient who can be expected to know Rpri.
  > Could the NSA reverse PGP encryption on a message that was encrypted with a
  > 1264 bit key?
Yes.  Although, I think it would be more likely through cryptanalysis of
the IDEA cypher than of the RSA encrypted IDEA key.
  > Do you think they could do this in a matter of hours?
I don't think so.
  > Why or why not
Cracking RSA is presumed to be as hard as factoring one of the components
of the key.  Although this has not been proven, I think it likely that no
better attack is currently known.  I have no figures yet on the complexity
of the IDEA cypher.  I do not know if it is susceptible to differential
cryptanalysis.  To my knowledge, exhaustive search is the only attack. With a random 128 bit key, search is prohibitive.
Sorry I didn't include more numbers,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-11 12:02:22
@_author: Scott Collins 
@_subject: How long would it take? 
>How does your "Yes" wash with the next paragraph of your note?
I'm sorry.  My answer was misleading (read 'wrong').  What I was trying to
say was:
  "Yes, but not in a reasonable amount of time."
My implication was that an attack against RSA with a 1264 bit key and an
attack against IDEA with a 128 bit key are both prohibitive, but that my
_guess_ is that cryptanalysis of the IDEA cypher would be the more fruitful
If the real question is:
  "Am I safe from the NSA when I use PGP and encrypt with a 1264 bit key?"
Then I must answer:
  "In my opinion, you are reasonably safe."
If the question is:
  > Could the NSA reverse PGP encryption on a message that was encrypted with a
  > 1264 bit key?
Then I must answer:
  "Yes, it is mathematically possible; although unlikely in the extreme."
I apologize.
  >Sorry I didn't include more numbers,
...really sorry.  They said what I meant.
  >And IDEA is not susceptible to diff.cryptan  -  that's the way
  >it was *designed* (actually the designer proved mathematically
  >the invinsibility of IDEA to this attack).
Thanks for this info.  I have been trying to get the IDEA papers:
  "Detailed Description and a Software Implementation of the IPES Cipher"
  "Markov Ciphers and Differential Cryptanalysis"
without success, as yet.  Perhaps you have them or know of an ftp site?
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-12 13:22:53
@_author: Scott Collins 
@_subject: Chaos harnessed for encryption / Fluctuations and Or 
>[...] that can synchronize without publishing their states.
  >If this could be done with strong PRNGs, you'd have something.
Here is a related article
  Article = "Secret Key Agreement by Public Discussion from Common Information"
  Author  = Ueli M. Maurer
  Publication = IEEE Transactions on Information Theory, Vol 39, No. 3
  Date    = May 1993
The problem of generating a shared secret key S by two parties knowing
dependent random variables X and Y, respectively, but not sharing a secret
key initially, is considered.  An enemy who knows the random variable Z,
jointly distributed with X and Y according to some probability distribution
Pxyz, can also receive all messages exchanged by the two parties over a
public channel.  The goal of a protocol is that the enemy obtains at most a
negligible amount of information about S.  Upper bounds on H(S) as a
function of Pxyz are presented.  Lower bounds on the rate H(S)/N (as
N-->infinity) are derived for the case where X = [X1, ..., Xn], Y = [Y1,
..., Yn], and Z = [Z1, ..., Zn] result from N independent executions of a
random experiment generating Xi, Yi and Zi for i=1, ..., N.  In particular,
it is shown that such secret key agreement is possible for a scenario where
all three parties receive the output of a binary symmetric source over
independent binary symmetric channels, even when the enemy's channel is
superior to the other two channels.  The results suggest how to build
cryptographic systems that are provably secure against enemies with
unlimited computing power under realistic assumptions about the partial
independence of the noise on the involved communications channels.
--end of Abstract--
Hope you like it,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-20 10:16:56
@_author: Scott Collins 
@_subject: cypher breaking and genetic algorithms 
--
  Well, since I'm here, I thought I'd satisfy a curiosity of mine.
  Has anyone done any research, formal or informal, on the use of
  genetic algorithms to break cyphers? If not, would anyone care to
  discuss how it might be done?
GA's (which I love, but you won't be able to tell from the following) are a
'robust' search mechanism better at finding _good_ answers than _the_
answer.  Because genetic search is driven by partial reward from a
partially correct solution, GA's are not adept at searching a space that is
very flat except for the single 'spike' of the correct answer.  Good
encryption systems are like this.  You are either right or wrong, no in
between.  Being one bit off in the key should give a totally fruitless
result.  GA's don't help much with such ciphers.
However, in simple substitution ciphers, frequencies and patterns in
partial decryptions can provide the reward GA's need to climb the hills.
In fact, Spillman, Janssen, Nelson and Kepner wrote an article in the
January 1993 Cryptologia titled "Use of a Genetic Algorithm in the
Cryptanalysis of Simple Substitution Ciphers" in which they found that, for
the particular class of problems they were solving, within (a short) 100
generations, the GAs could bring the cipher text to the point where a human
could 'just read it', whatever that means.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-20 12:56:57
@_author: Scott Collins 
@_subject: cypher breaking and genetic algorithms 
Oops, forgot to CC:cypherpunks.  Sorry.
 --
  What if the GA "knew" the plain-text, the cyphertext, and the
  encryption algorithm, and was searching for a decryption algorithm
  without the encryption key? Would that be for fruitful?
The attack I was describing assumed that the genetic strings _were_ keys
and the population was about finding the right key.
Peters response suggests that rather than a population comprising keys, a
population of 'programs' -- probably built from (constantly reordered)
modules that performed the same atomic operations used by the encryption
algorithm (and then some).  This is a very strong generalization, and one
that is getting more attention in the field.  'Genetic Programming'.  In
practice this can lead to more fluid populations.
In this instance, though, you can think of a key as a program to be
executed by an encryption or decryption machine and see that a population
of programs is similar in expressive power to a population of keys.
In the case of cryptanalysis of a _good_ cipher, it is the terrain (of the
problem space) itself that gives us the clues about the expected
performance of GA's.  For a population to improve, it has to be able to
measure the performance of an individual (how high has it climbed?) so that
it can give increased resources to the more successful (whose children are
likely to climb higher on a continuous surface).
In cryptanalysis, the goal (the mountain peak) is the correct plaintext. An individual, however it may be constructed, yields a trial decryption. Its performance must be measured against the only standard available in
this case, the known plaintext (or the expected statistics of plaintext if
known plaintext is not available).
If there were an accurate measure of how 'good' a trial decryption was then
your GA could climb.  However that would imply a continuous 'goodness'
function, whose surly bonds strong ciphers surely seek to slip.
It is this reliance on continuousness that make GAs great at climbing
hills, but rarely better than undirected random search at finding a needle
in a haystack.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-20 16:21:17
@_author: Scott Collins 
@_subject: genetic algorithms for crypto analysis 
>Sexual reproduction (aka string crossover)
Sexual reproduction is not string crossover.  Normal reproduction in a
typical GA picks two individuals from the population independently with
probability related to their fitness. In sexual reproduction, the pairs are
constrained such that selection is not independent e.g., 'males' mate with
Sexual reproduction is one factor that dampens premature dominance of the
population by a few 'great' individuals, so that search can continue on
other hills, i.e. encourages diversity and thus IS good, as was previously
stated, in choppier solution spaces.
Also consider the dominance mechanism supported by the diploid chromosome. One reason why double-strand species like ourselves can more rapidly adapt
than haploid species.  Dominance protects solutions that were good once
(and might be again) from being sampled to death, by holding them in
abeyance (a 'recessive' trait) in a temporarily unfavorable environment. Again, this encourages diversity by dampening premature destruction of hard
won solutions.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-27 12:06:00
@_author: Scott Collins 
@_subject: Who is David Sternlight? 
>[...] WHO IS DAVID STERNLIGHT? [...]
David Sternlight is a particulary active, if not universally admired,
poster to sci.crypt et al (including a special fan club news group).
The volume of his posts and their position (often antithetical to positions
taken by cypherpunks) has led some to speculate that he is not an
individual at all, but a group with an agenda.
Some people delight in reading his posts, either because they approve, or
for the same reason I like to read 'Ask Marilyn' in Parade: because they
like to get riled up.  Some people just add him to their 'kill' files. There has been debate over adding software moderation to sci.crypt that
automatically redirects David Sternlight posts to a side group.  In any
case, DS (as he is sometimes referred to) is a prominent political feature
of the privacy/cryptography related news groups.
If you really want to know who he is: join sci.crypt; read some of his
posts; and then ask him in e-mail.
If you do send him e-mail -- make sure that if you use an anonymous
remailer of the variety that allows him to respond to you, unlike the one
you used to post this request.
Hope this helps,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-28 21:18:49
@_author: Scott Collins 
@_subject: Total RSA in PGP 
>Am I mistaken in believing RSA is more secure than the present hybrid?
.....SHORT ANSWER.....
You are mistaken.
.....MEDIUM ANSWER.....
You are mistaken not because the statement 'RSA is more secure than the
present hybrid' is false, but because it is a mistake to put your belief in
this statement, which has not been proved true.  RSA alone would represent
a great increase in computational effort, without risk of a decrease in
security, after which you couldn't prove you were any better off (though,
in practice, against currently known attacks, and with a large key, you
might be).
.....LONG ANSWER.....
RSA alone is no _less_ secure than the PGP's combination of RSA and IDEA:
if you can break RSA, you can extract the IDEA key and decipher the
message; if you can break IDEA, you don't need the key.
I am guessing that you share a widely echoed predjudice that public-key
ciphers are better than secret-key ciphers (I apologize if I have
mis-labeled you :).  Public-key ciphers have gained a reputation for being
more secure, as a class, than secret-key ciphers.  Perhaps because
public-key ciphers afford 'better' key management, the world at large has
gotten the impression that they provide 'better' security.  Public-key
ciphers as a class are _not_ more secure than secret-key ciphers.  One
counter example, which periodically rears its ugly head here, is the (truly
random) one-time-pad.  This secret-key cipher offers perfect security in
the Shannon sense.  No public-key cipher can make that claim.
To prove RSA _more_ secure than the hybrid, RSA must be proved more secure
than IDEA.  Unfortunately, we don't really know how secure the RSA
algorithm is (or IDEA, for that matter).  It is known that RSA is no _more_
secure than factoring a component of the public key (readily available to
an attacker).  To my knowledge, it has not been proved that either a) RSA
is at least this secure; or b) factoring is hard.
Despite a paucity of formal proof, I know of know better attack on a
message enciphered with well chosen keys than factoring, which both man and
machine currently find taxing.  RSA with well chosen keys is 'empirically'
computationally secure.
While IDEA has been designed specifically to resist differential
cryptanalysis (thanks to those who pointed me to the IDEA papers explaining
this), more formal proof of its security awaits further understanding of
the information theory aspects of its foundation: mixing operations from
incompatible groups.  In the end, IDEA is also 'empirically'
computationally secure.
I know of no comparisons of the security offered by RSA and IDEA against
practical attacks.
.....FINAL ANSWER.....
In theory: theory is as good as practice; but in practice... it isn't.
Hope this helps,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-08-29 12:13:30
@_author: Scott Collins 
@_subject: no ftpd on soda.berkeley.edu ? 
>Has anyone else tried to ftp soda in the past 2 days or so? I've been
  >unable to establish a connection.

@_date: 1993-08-30 12:28:48
@_author: Scott Collins 
@_subject: Apple planning to use Clipper chip? 
I do not, in any capacity, speak for Apple.  But...
  >Apple even discussed the
  >pricing and said that if the Clipper/Skipjack chip could be sold to
  >them for less than $30, they could "design it into every Mac."
Based on long experience with Macs and Mac software (system and otherwise),
I think this is highly unlikely.
1. Apple has a history of following the 'software only' approach in general.
2. Apple loudly and often touts compatability across its entire line.
3. 3rd party Mac developers have little incentive to write software with mass
   appeal (e.g., communications software) but limited applicability (because of
   hardware requirements).
4. If the software isn't pre-installed in your system, then unless it comes from
   Microsoft, such a 'questionable' standard is probably avoidable.
5. Therefore, for a standard to emerge on the Mac... 1) Apple would have to
   begin producing machines that contained this chip; 2) Apple would have to
   produce special system software, explicitly for this class of machines,
   that used this chip; 3) Apple would have to produce compelling end-user
   communications software that used clipper services on this class of machines
   and either didn't run at all on earlier hardware, or didn't use clipper
   technology.
   It is unlikely that a 3rd party would do it, or have any impact if it did.
   But Apples history is scalable software that runs on every machine (ala
   QuickTime).  If Apple wanted to introduce privacy enhancement technology in
   its system, it seems economically and historically more probable that it
   would simply license RSA/DES/etc technology and roll in a software only
   service.
This is my opinion, based solely on my nine years of experience as
Macintosh developer.
To paraphrase Columbo: "It's my experience, sir, that people rarely do
things they don't *usually* do."  ...which may sound obvious, but then you
*saw* the killer do it in the first 10 minutes...
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-08-30 13:58:50
@_author: Scott Collins 
@_subject: Apple+Clipper 
Tim and Paul present accurate evidence mitigating some of my specific
points.  I agree that the AV Macs and AOCE are steps (or even leaps)
towards a platform favorable for clipper infestation.
.....BEGIN HAIR SPLITTING MESSAGE.....
I would like to fine tune one of Tim's comments:
  > and  are already satisfied with the new generation of av Macs, as
These machines most certainly do not contain the clipper chip (which I'm
sure Tim did not mean to imply), though they do show that Apple can make
machines with special purpose hardware and capabilities not present, or
emulatable, on earlier machines (this, I think, was Tim's point: a counter
example to my speculation).
It is illuminating to note, however, that the 880av is not based on the
same hardware as the 800.  It is an earlier generation that took longer to
come to market.  In this sense it recalls the late IIfx i.e., faster for a
while and then a dead end.  In many ways, the 800 is a superior machine,
and the 880 has some catching up to do (like adding interleaved RAM access,
for one).  By my count, the 880 has taken over three years to come to
Summary: the AV Macs may indicate a new trend, but they do not represent an
immediate foothold for clipper.
.....END HAIR SPLITTING MESSAGE.....
Other than that, and although they come to slightly different conclusions,
I agree with Tim and Paul, who examined the root motives rather than
'diagnosing for symptoms'.  My final take on this is:
Apples history and our guesses about its likely motives lead me to (still)
predict that Apple can't immediately jump on the Clipper bandwagon; though
the further out we speculate (beyond 2 years?), the less faith in this
prediction we can justify.
I like to be wrong almost as much as I like to be right.  More, if the pay
is better.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-08-31 06:46:31
@_author: Scott Collins 
@_subject: Apple, privacy, and AOCE 
>I found the idea that RSADSI will be generating folks' key pairs
  >particularly chilling.
What I gathered from actually using this software is that you personally
generate a key pair, on your own machine, and then transparently send your
public key to RSADSI.  Some time later, you receive a certificate (with an
expiration date) that allows your 'signer' to function.  RSADSI does not
make, or even see, your private key.
  >The article accompanying these sidebars suggests that folks' private keys
  >will be stored on the server;
My understanding is that address books on the [optional] servers may have
copies of certificates, for people who have certificates and want them
  >the article [...] must be the result of miscommunication
  >The NSA recently signed an agreement with the Software Publishers
  >Association that will provide expedited approval of RC-4 encryption based
  >on 40-bit keys.
Not surprising, since a pre-computation attack allowing a direct key lookup
against RC-4 with 40 bit keys is economically feasible for anyone who can
afford a CD-ROM jukebox (128 mips-years of computation + 8 terabytes of
  >NSA [...] will allow slightly more-powerful scrambling capabilities
  >[in AOCE] AOCE uses 64-bit keys, and larger keys mean better security.
This could mean anything.  They might actually be using 64 bit keys (which
would be good, although 80 bits is recommended), or they might be using 40
bit keys with 24 bits of salt (or worse: 32 and 32).  Salted keys (key+salt
of sufficient size), stop the precomputed attack, but if the actual key
size, without salt, is still only 40 bits, then exhaustive search of the
keyspace, after the salt has been seen, will only take 64 mips-years.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-08-31 08:16:30
@_author: Scott Collins 
@_subject: What's wrong with PEM? 
After reading the RFCs for PEM (1421-1424), I am curious what other people
think about PEM.  For cypherpunks agenda, in what ways is PEM lacking?  My
take is:
  1. PEM is a protocol, only applicable to mail (perhaps only to internet
mail) while PGP is program that provides similar services for mail, but is
also applicable to non-mail related encryption tasks.
  2. PEM and PGP don't aggree on the symmetric algorithms (DES, IDEA).
  3. PEM certificates are bulky, and transmission is encouraged.
  4. PEM certificates are issued by Certificate Authorities, which would
seem to preclude PGP's 'web of trust' model.
These all seem to have answers:
  1. PEM is protocal, PGP is a program that implements much of what PEM
is... why not make PGP PEM compliant.
  2. Propose IDEA as a symmetric algorithm for PEM.
  3. Ha! PGP already has key servers.
  4. Propose a revion to the certification scheme where USER certificates
would be created by the owner and signed by non-certificate-authority
acquaintances ala PGP.
Yes, this would take time and effort.  No, this should not be taken as an
affront to our current and previous efforts.  I think that we should persue
_every_ avenue.  If the only real problem with PEM is the trust model, and
we can change that, then this would be a strongly legitimizing action.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-12-02 12:12:32
@_author: Scott Collins 
@_subject: N-Gram 
>[algorithm to] store data the same way the human brain does.
  >[stored data would] take up only [0.5%] of the original space.
Whoever said the human brain stores data compressed to 0.5% of its original
size, and what is its original size anyway.
Paul Baclace says:
  >Sounds like Bugajsky creates a generative grammar and then stores list
  >of productions that specifies a walk on the tree to extract data.  This
  >is a form of Kolmogorov Complexity compression, which has been expanded
  >upon most notably by Chaitin.
I agree.  The description sounds more like this than anything else I'm
familiar with.
Paul Baclace goes on to say:
  >I wonder whether [he] includes the size of his grammar in [the claim]
0.5% is a questionable claim.  If it includes the grammar, then the grammar
must be very simple, and the data of very low entropy with respect to it --
in which case 0.5% would be an uninteresting experimental result.  If the
claim does _not_ include the size of the grammar, then the claim is useless
for evaluating this scheme.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-12-14 13:43:52
@_author: Scott Collins 
@_subject: Error-Qualifying Signatures 
(Oops, forgot to include 'punks, sorry Nick)
Nick Szabo asks:
  >Is a one-way hash function or digital signature possible with the
  >following property: signature verification doesn't just determine
  >the boolean altered vs. pristine, but also shows the picture
  >distance between the altered and original?
This is possible.  It is not a desirable quality for secure-hashes in most
other situations because it compromises the privacy of the original
message.  Hash functions are usually designed specifically to avoid this.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-12-15 14:10:43
@_author: Scott Collins 
@_subject: Improved DH system. 
>I have been told that there is a new improved version of
  >DH key exchange, which is authenticated. Could
  >someone give me the reference, and/or tell me what it is
  >all about?........ Diffie??
I'm back at the office and can (finally) provide the information, sorry for
the delay.
The paper is "Authentication and Authenticated Key Exchanges" by Whitfield
Diffie, Paul C. van Oorschot, and Michael J. Wiener, published in _Designs,
Codes and Cryptography, 2, 107-125 (1992), by Kluwer Academic Publishers.
Here is some notation, and a brief description of the basic protocol. Almost everything from this point forward is quoted directly from the
{.}     Braces indicate a hash function.  {x, y} is the result when a hash
function is applied to x concatenated with y.
S_A     Alice's secret key for a signature scheme.  S_A(x) is Alice's
signature on x.  S_A{x} is Alice's signature on the hashed version of x.
P_A     Alice's public key for a signature scheme.  If the signature scheme
is a public-key cryptosystem, then we define P_A{x} and P_A(x) to be
Alice's public key encryption function with and without hashing.
E_K(x)  Encryption using a symmetric cryptosystem with key K.
5.1. Basic [Station-to-Station] Protocol
The STS protocol consists of DH key establishment, followed by an exhcange
of authentication signatures.  In the basic version of the protocol, we
assume that the parameters used for the key establishement, (i.e., the
specification of a particular cyclic group and the corresponding primitive
element a) are fixed and known to all users.  While we refer to the DH
operation as exponentiation, implying that the underlying group is
multiplicative, the description applies equally well to additive groups
(e.g., the group of points of an elliptic curve over a finite field).  We
also assume in this section that Alice knows Bob's authentic public key,
and vice versa; this assumption is dropped in the following section [which
I did not type in].
Alice                                           Bob
-----                                           ---
a is known,
x is random
        ------------- a^x --------------->>
                                                a is known,
                                                y is random
                                                K = (a^x)^y = a^(xy)
        <<---- a^y, E_K(S_B{a^y, a^x}) ----
K = (a^y)^x = a^(xy)
        ------- E_K(S_A{a^x, a^y}) ------>>
The paper is a very good read.  It describes the motivations behind the
protocol; how to assure (or dis-abuse) yourself of the security of other
protocols; modifications; other uses; etc.  I highly recommend it.
Hope this helps,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-12-15 14:50:43
@_author: Scott Collins 
@_subject: Error-Qualifying Signatures 
Since this description is of a more general interest, I am cc'ing this
thread back to the list.
  >Yes, but inverting a hash function isn't necessarily a problem.   >Inverting an encryption function is. With hash functions, we
  >really want to know it is hard to take message A and append something
  >B so that f(AB)=f(C). Now, ideally people have always thought
  >that it was bad if given C, one could come up with a D such that
  >f(C)=f(D). But I haven't figured out how that can affect practical
  >problems. Did I miss something?
Let {x} be a hash on x.  Let S_A{x} be encryption of the hash of x with
Alice's secret key, i.e., Alice's signature over x.  Thus, a signed 'thing'
is (x, S_A{x}).
If {x} yields the function f(y) which tells how different y is from x
(ostensibly to measure what damage x sustained in transit, to become y),
then f(y) can be exploited to find y such that {y} = {x} (this is, after
all, the design criteria behind f(y)).  If {x} = {y} then S_A{y} = S_A{x},
and therefore I can publish a document signed by Alice (y, S_A{y}), without
her knowledge (both meanings) or cooperation.
Someone on the list showed a few months back that provably few errors (or
abitrary attacker introduced changes) are needed to get to a matching hash,
but finding the changes to introduce is expensive.  Building a hash
function such that a distance measure is easy to calculate and exploit,
makes finding the right errors easier, and thus allows falsified
signatures.  I take x, introduce my required changes yielding y, and then
exploit f(y) with say a genetic search, or simulated annealing, to find y'
such that {y'} = {x}, then I republish (y', S_A{x}): my altered
document/image/whatever, + some errors to make the hashes match, + Alice's
original signature.  The signature is verifiable.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-12-24 11:51:23
@_author: Scott Collins 
@_subject: Impuning my reputation by association 
I paraphrase, not quote, you in this message.  Please tell me if the
meanings I have extracted from your posts are not what you intended.  I
suspect, however, that whatever you might have intended, I attribute the
same meanings to your posts as the majority readers.
You say that there are no honest cypherpunks, only liars, slinking cowards,
and people too stupid to realize they are being 'taken'.  You attribute
many characteristics, particularly immoral ones, to cypherpunks, which
throughout the rest of this message I will summarize with the words: lying,
liar, etc.
If a cypherpunk is: 'anyone engaged in traffic on the cypherpunk list',
then both you and I are cypherpunks.  I believe myself to be honest,
forward, and intelligent.  I assume, of course, that you believe the same
of yourself.  Therefore, there must be at least two honest 'punks.  Since
you cannot easily verify that my beliefs about myself are true, it could be
that there is only one honest 'punk.  (From the old testement: "If, even
one righteous man dwells therein, I will stay My hand.")
If a cypherpunk is: 'anyone who uses cryptographic tools for the purposes
of fraud', then there can be no honest cypherpunks by definition.  I have
never, am not now, nor do I intend to in the future, use cryptographic
tools for the purposes of fraud, deception, character assassination, or
other wrongs.
Regardless of which definition of cypherpunks you, "L. Detweiler", believe,
people to whom you speak will assume the _first_ definition, which as a
set, contains you, me, and other potentially honest individuals.  If you
didn't mean that definition (they will not even bother to think to
themselves), you would have used the word 'criminals' or a derivative,
thereof.  You tell people "all cypherpunks are liars".  If they pass the
initial paradox (that you, a cypherpunk, are telling them you are liar), by
presuming your honesty, and therefore, necessarily, your exclusion from the
set, then they must now believe the false notion that I, Scott Collins,
_am_ a liar.
 -1- "L. Detweiler" tells people 'Scott Collins is a liar'.
 -2- I, Scott Collins, am not a liar.
My beliefs (including, like our Justice system, a general presumption of
innocense) about other cypherpunks does not even come into play here.  The
issue  is: you are impuning my character.
I leave the logical conclusion of statements -1- and -2- as an exersize for
the reader.
It seems that you have made yourself my judge, and worse, an executioner. How will you ensure Justice?  How will you find, with certainty, the Truth?
 Or, do you consider the persecution of innocents to be 'acceptable
losses'.  The precedents set in every written guideline of moral behavior
that I have read are exactly opposite this.  In our legal system: a)
defendents are presumed innocent until proven guilty, and b) are guaranteed
due legal process.  In the major religions with which I am familiar, it is
only the deity who may judge and punish, not man.
There are bad things in this world, and I hate those things.  You and I
even agree on what some of those things are.  But I ask you this:
            Who are _you_, to judge me?
            Who are _you_, to persecute me?
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-12-26 21:20:08
@_author: Scott Collins 
@_subject: Benford: Why and Why Not (non-Math-heads: SNOOZE ALERT) 
Here is an explanation of why more numbers start with '1' than with '9',
how to make a system where that isn't true, and why you don't need to.  If
you don't like math, you've already extracted everything from this message
that you could possibly need.
For any integral magnitude x in the range 0..N, there are infinitely many
polynomials of the form
        c_1 b_1^e_1 + c_2 b_2^e_2 + ... + c_L b_L^e_L = x
c_i, b_i, e_i integers.  This is trivially provable given the single term
(x b_1^0), in combination with all the possible terms where c_i = 0.
Let us distinguish polynomials of a form where, for terms i and j, i != j:
  1. b_i = j_i
  2. e_i = L-i
  3. b_i^e_i <= x
  4. 0 <= c_i < b_i
Condition 1 allows only polynomials where b is the same for every term. Condition 2 allows only polynomials whose terms are in strictly decreasing
order by the exponent, and contain every integral exponent from L-1 downto
0.  Condition 3 ensures that the c_1 != 0.
These four conditions, restrict the set of polynomials that can represent
x, for any B such that b_i=B, to 1.  These conditions are, in fact, the
'normalization' rules for representing numbers as strings of symbols, in
any base B.  Since B can be assumed, and e_i adduced, any x can be
represented by concatenating symbols drawn from an alphabet of size B,
representing the magnitudes 0..B-1 according to c_i.  When B=10, and the
alphabet is { '0'=0, '1'=1, '2'=2, ... '9'=9 }, we call this the decimal
Consider the journey of x as it goes from 0 to B^(i+1)-1.  It has to
progress from 0 to B^i-1 to 2B^i-1 to B^(i+1)-1.
Graph(?) A:
 B^(i-1)-1 (B^i)-1   (2B^i)-1                                  (B^(i+1))-1
  R    r     S     s    T                     t                  R'
Distance r = s = B^i.  Distance t = (B-2)B^i.  These three 'legs' of x's
journey represent, starting with s, a contiguous range of representations
beginning with '1', t, a contiguous range of representations _not_ starting
with '1', and r, a range 1/B the size we are disecting, which is itself
divided in the same proportions.  Thus, from S to T, the fraction of
strings beginning with '1' increases to (about) 1/2, and from T to R' it
decreases to 1/B.  And since r is a minor copy of rst, at R and S, the
fraction must be 1/B.  So, for any period, the fraction rises to 1/2 in
time s, and falls to 1/B in time (B-2)s.
Consider the normalized decimal representations of integers drawn from the
range [0,N].  When N=1, the set in question is {'0', '1'} of which 1/2
begin with '1'.  As N goes to 9, eight strings are added to the set, none
of which begin with '1', thus, at N=9, only 1/10 of the sets elements begin
with '1'.  As N goes to 19, the fraction swings quickly back up to 1/2.  As
N goes to 99, the fraction drops, again, more slowly (8 times more slowly),
to 1/10.  On a log graph, this behavior is a saw-tooth pattern:
Graph B:
        .         .         .
        .         .         .
0.5 ....*.........*.........*..........
        . *       . *       . *
    p   .   *    *.   *    *.   *
        .     *   .     *   .     *  0.1 ............*.........*.........*..
      * .         .         .
        .         .    N    .
      0 1        19        199      1999
Note that this graph describes properties of a representation for numbers. That is, this is the graph of a distribution of strings, not of integers. A different representation would yield a different behavior.
Consider the graph of log_B(N).  Here the x-axis is N, the y-axis log_B(N),
and it is graphed on log_B, paper as '*'s:
Graph C:
3 -                     +---------*
    *
2 -           +---------*
    *
1 - +---------*
    *
0 - *
         |         |         |
   B^0       B^1       B^2       B^3
Ceiling(log_B(N)), shown in the graph with lines, is the length of the base
B representation of N.  This shows that even if the 'unfair first digit'
problem were avoided by a different representation, any log based
distribution would still exhibit a similar problem in string _lengths_. i.e., only 1/B of all strings from 0..N are shorter than log_b(N): an
'unfair distribution of lengths'.
For a flat distribution of strings, you require a representation scheme
where, for any N, 1/B strings begin with a_i (a symbol from B's alphabet),
and for range of allowable lengths of strings in the scheme (1..L), for any
l, the number of strings for numbers in N is the same.
Here are two such schemes.
'Base-1' representation: the alphabet has one symbol, any magnitude x is
represented by x concatenated instances of the symbol.  The first property
is satisfied because the alphabet has 1 symbol, and 1/1 of the strings from
1..N begin with that symbol.  The second property is satisfied because the
allowable lengths vary from 1..N, and for each length, only one string
exists of that length, thus every possible length has the name number of
Fixed length representation:  All numbers from 0..N, N = B^L, are
represented by strings of length L comprising symbols from B's alphabet,
constructed according to the normalization rules but replacint condition 3
with the rule e_i=L-(i+1) (forcing all strings to be the same length).  The
second property is satisfied because there is only one allowable length. The first property is satisfied, because, since N=B^L, every distinct
string of length L of symbols from B's alphabet is a valid number in this
representation, and of those strings, for any position p in the string,
including p=0 (the first symbol), 1/B of the strings will symbol a_i in
that position.  An example of this scheme is a byte of computer memory used
to hold magnitudes from 0..255.
But, since the 'Base-1' scheme doesn't exhibit the predictability problem
of our normalized decimal system, and is a dramatically 'real'
representation of numbers (although inconvenient) one might guess that even
if one can predict features of representations, it does not necessarily
follow that such a prediction can be exploited into guessing the number
itself.  Something near half of all decimal representations begin with a
symbol from { '1', '2', '3' }, but that doesn't actually help me guess the
next number, just make some predictions about its representation.
This is, in fact the case.  Our normalized log-based representation schemes
are 'unfair' in the distribution of strings, essentially using all the
'good' ones first (for oft' used small numbers).  The further out we go,
the longer strings we need, and the log distrubition problem surfaces.  But
for any range, the actual (formless) magnitudes themselves are evenly
distributed, in spite of what you might guess from our biased strings. Thus, Benford distribution is the kernel of a great bar bet, but an
unlikely alley in predicting the underlying magnitudes.
Fractals?  Well, r is a 'little copy' of rst.  Chaos theory?  No.  How
about just some good basic algebra (OK, a little calculus if you want to
calculate the area under under the curve in Graph B, and from that, the
amount to bet at the bar).
Hope you enjoyed this,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-07-16 15:48:22
@_author: Scott Collins 
@_subject: Relation between number theory and cryptography 
>if we were to add some noise [then] we have added [...] information
Perhaps in 'Information Relativity'.  With respect to the original system
(and by definition), noise is not information.  It is only data.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746                  catalyst at netcom.com
QUOTING.    Full text of sources upon request.  You may quote if you do
the same *and* include this notice so your readers may quote similarly.

@_date: 1993-07-24 13:00:08
@_author: Scott Collins 
@_subject: FAQ, round 2 (posting because of bounce) 
I tried to mail these comments directly to Eric Raymond, who posted his in
progress FAQ.  My mail bounced, so I am posting it in hopes that he will
get it.  I missed a lot of the FAQ commentary, so I apologize if this is
all known.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com
..........bounced comments follow..........
Good work on the FAQ.  I'ts not a rewarding job, I'm sure; I just wanted to
personally express gratitude.
Sorry I took so long to get these comments to you.
  >   The best-known PKCs are [...] DES
DES is a symmetric cypher, i.e. *not* a public key crypto-system.
  >`digital signature' or `message digest code' or `message hash'
A message digest or hash is distinct from a digital signature.  In
particular, for a given input, everyone will derive the same digest or hash
but a different signature.
  >The three major DSS techniques are Snefru, MD5, and DSS.
Again, MD5 is not a signature algorigthm.  It is only a (supposedly)
cryptographically secure, i.e. one way, hash.  Everyone who runs MD5 on the
same input, will get the same output.  If you meant that MD5 is used as a
component of some signature algorithms (which is true), then I apologize,
it wasn't clear to me.
  >   DSS is [...] associated with the Clipper proposal.
They both come from the government.  They were both influenced by the NSA. They are not associated in any formal way.  More cousins than brothers.
  >c. DC-net or similar protocols to thwart spoofing.
DC-nets are anonymous voting mechanisms (at their heart).  I don't see the
direct relation to 'thwart spoofing'.
  >   If two or more people encode known text with their private keys applied in
  >succession, all their public keys will be required to decode it.  This is
  >an unforgeable contract.
Yes, although more often digital signatures are what people want and mean
when they discuss digital contracts.  With individual digital signatures,
i.e. a hash of the contract signed with your private key, each signature
can be individually verified.
  >   RSA stands for `Rivest-Shamir-Adelson',
Keep up the good work,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-07-31 17:47:55
@_author: Scott Collins 
@_subject: Programs that prove themselves. 
Intuitively, this is akin to Godels incompleteness theorem.
Or read "What is the name of this book?" by Raymond Smulliyan.  A multitude
of interesting problems are posed, around the interaction of Knights,
Knaves and Normals.  Knights always tell the truth.  Knaves always lie. Normals sometimes tell the truth and sometimes lie.
A Normal can 'pretend' to be a Knight, because he is not constrained in his
answers, therefore, he can always answer as a Knight would.
Your program might be a Knight (i.e., constrained to always tell the truth)
but a 'Normal' program could always simulate your program.  It would
perform all the functions of your program with stolen code, but inside it
wouln't prove itself to itself.
It is only in the presence of some unforgeable distinguishing
characteristic recognized by a trustworthy *outside* observer, that a
bystander can tell Normal from Knight.
Sign your software and have users check the signature with a trusted
outside signature verification mechanism (e.g. a 'good' copy of PGP, or a
secure operating system).
I know this is not the information you are looking for.  I also know this
is not a pipe.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024/669687   catalyst at netcom.com

@_date: 1993-06-18 10:57:41
@_author: Scott Collins 
@_subject: xor w/prbs 
While the pseudo-random bit sequence algorithm used in the Computer Shopper
article is weak, it is important to note that the article is on the right
track.  However, a one time pad based on PRBS is only as secure as the PRBS
itself.  If the author did not state this, he was remiss.
There *are* cryptographically strong pseudo-random bit generators.  A one
time pad based on a CSPRBS would be as secure as the underlying 'hard'
problem.  For example, Blum and Micali's paper "How to Generate
Cryptographically Strong Sequences of Pseudo-Random Bits" (Nov. 84 SIAM),
details a scheme based on the discrete log problem.
Essentially, this system is based on selecting bits from successive
exponentiations of a seed.  If you could guess the next bit to be selected,
without knowing the seed, you could reverse this into an algorithm to solve
the discrete log problem.
The Blum and Micali paper also references a paper by Shamir (which I have
not read) called "On the generation of cryptographically strong
pseudo-random sequences" 8th International Colloquium on Automata,
Languages and Programming, Lecture Notes in Coputer Science, 62,
Spring-Verlag, New York, 1981.  The difference being that the Shamir scheme
generates *numbers* while the Blum/Micali scheme generates *bits*.
I try never to label anyone a moron until I am sure their stupidity is not
just my failure to communicate.
Scott Collins              | "Few people realize what tremendous power
  there is in one of these things."
                            -- Willy Wonka
Apple Computer, Inc.       |     phone: 408 862-0540(v), 974-6094(f)
1 Infinite Loop, MS 301-2C | AppleLink: SCOTTCOLLINS
Cupertino, CA 95014        |  internet: collins at newton.apple.com

@_date: 1993-06-22 11:23:48
@_author: Scott Collins 
@_subject: gov. contracts for Clipper phones 
>[...] I find it
  >highly unlikely that the contracts in question are for clipper-based phones;
  >we already know the government doesn't plan to use clipper technology
  >itself, since it can be suborned by LEO types.
I think it *very* likely that the government would want to spy on itself
just as much as it wants to spy on everybody else.  Remember, the
government is not a single entity -- out to get us -- but a collection of
individuals, some fraction of whom are covering their butts and looking for
goats at any given moment (as has been revealed to us by the media).  All
of whom are interested in maintaining/improving their current status.  This
is true at the level of the individual, the committee, the agency, the
party... in fact at any identifiable organizational level, entities will
engage in behavior that profits them even (or especially) at the expense of
entities outside themselves.
Scott Collins              | "Few people realize what tremendous power
  there is in one of these things."
                            -- Willy Wonka
Apple Computer, Inc.       |     phone: 408 862-0540(v), 974-6094(f)
1 Infinite Loop, MS 301-2C | AppleLink: SCOTTCOLLINS
Cupertino, CA 95014        |  internet: collins at newton.apple.com

@_date: 1993-11-02 01:34:52
@_author: Scott Collins 
@_subject: Hole in MD5 
Kaliski's response (re: den Boer and Bosselaers' recent work) sounds
reasonable when applied to real life 'human readable' messages typically
comprising many blocks.  I wonder, though, if this technique admits a
reasonable attack on single-block, offline hashing schemes like Bellcore's
timestamping system.
I am a little unsure of the details of their system, but I think I
correctly present the gist of it in the following.
Bellcore's timestamping system is 'offline' in that all the information a
verifier gets is from the prover (except, perhaps, double-checking the root
hash with some public archive).  Most of the important information is
already gone: the maximum depth of that day's hash-tree; the hash-tree
itself; the actual depth of any given timestamp; et al.
Eve has a document, allegedly timestamped with the Bellcore system.  To
prove it to me, she gives me the document (doc), a date/time, and a list of
N hashes, h_1..h_N, where h_N is the root hash for that date (verifable
from some widely published event on that date).  I call Bellcore, or look
in some archives to get the published root hash (root) for that date/time.
        h <- MD5(doc)
        For i<-1..N-1
          h<-MD5(h concatenated with h_i)
When I'm done, if h = h_N, then the timestamp is valid.
Since I don't know the actual depth of Eve's timestamp, her hash sequence
can have any number of elements.  If Eve can produce a collision for
digests the size of the internal nodes in the daily timestamp hash-tree,
even if she can't do it with a single direct collision, she can spoof me. (Of course, if she gives me some number of hashes such that 2 to that power
 is greater than the number of
people in the U.S., I might smell a rat.)  I haven't yet seen the paper, so
this may be an unreasonable conclusion.
I gathered from Bellcore's presentation at the last RSA conference that
they don't sign the timestamps because "you could always bribe the
timestamper".  They rely completely on the security of the chosen hash
function, and the idea of a 'widely published event'.
If anybody has better/more specific info on Bellcore's system, or den Boer
and Bosselaers work, or Preneel's paper, I would be interested.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-11-05 11:27:47
@_author: Scott Collins 
@_subject: Hole in MD5 (Not) 
What follows is a private e-mail exchange with Burt Kaliski (posted with
his permission), where he clarifies the 'hole in MD5' and shows that it
does not afford the attack I described previously.
Mike Ingle:
  >Recently there was a message here about MD5 having a hole in it.
  >Maybe this is what the person was talking about...
Bruce Schneier:
  [ describes Bart Preneel's Ph.D. thesis, which cites the work of
  den Boer and Bosselaer ]
Burt Kaliski:
  [ a LaTeX document noting the implications, or lack thereof, of den Boer
  and Bosselaers' work ]
Scott Collins:
  [ describes an attack on (e.g.) Bellcore's timestamp system; wonders
  if den Boer and Bosselaers' work makes this attack possible ]
Burt Kaliski (private response):
  >When operating on single blocks, MD5 computes a function z = f(x,y0),   >where x is the 512-bit message block, y0 is a fixed 128-bit value, and   >z is the 128-bit message digest.
  >
  >den Boer and Bosselaers found a way to construct a triple (x,y1,y2)   >such that f(x,y1) = f(x,y2). The y1 and y2 values are not the same as   >the fixed y0, so clearly this is different than an MD5 collision,   >which would have different message blocks.
  >
  >I'm not sure how this relates to the attack you have in mind, although   >I'd be interested in more details. Also, the attack you describe is   >"after-the-fact" in the sense that the target value h_N is already   >published. To forge a time-stamp at that point, what I need is not a   >collision, but an inversion. (I have to find something that hashes to   >h_N.) Collisions play a greater role "before-the-fact," where I might   >give Eve something to sign, where I happen to know another message   >with the same digest.
  >
  >-- Burt Kaliski
  >RSA Laboratories
Scott Collins:
  > [ ... ]
  >
  >Ahh. This is not (even close to) a big enough foothold to support my   >attack.  :-)
  >
  > [ ... ]
  >
  >The attack does, in fact, require inversion.  Since the verifier can't   >compare the depth of the alleged hash tree to the actual one, the attack is   >still possible even when only _some_ inversions are possible, as long as   >the attacker can find one along the actual path to the root (the degenerate   >case being when the attacker can find an inversion for the root itself).
  >
  >The attack only came to mind because the the depth cannot be verified, and   >so the attacker is not limited in the number of steps (in case she can only   >find inversions of a special form); the intermediate hash values are all of   >minimal size; the intermediate hash values are expected to be 'random', and   >so there is no constraint requiring human-readable inversions.  Thus, it   >seemed that if an the hash could be usefully inverted, this would be the   >situation that allowed it.
  >
  >Thanks for the clarification.  May I repost your answer, or at least _this_   >message which quotes it, to the original distribution list of my question?
Permission was granted.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-11-16 15:05:56
@_author: Scott Collins 
@_subject: RSA/MP/FFT speedups? 
Cetin Koc, Professor at Oregon State working with RSA, gave a lecture at
the 93 RSA Data Security Conference on improving RSA performance, where, at
one point, he discounted the efficacy of FFTs for
multiplication/exponentiation of such small numbers (under 2000 bits),
compared to better use of addition chains, separating squaring from
multiplication, and cleaner MP multiplies, etc.
Recently, someone (I can't remember) mentioned in conversation that someone
else (I also can't remember) had very good results with FFTs.  In fact, the
break even point was actually just a few hundred bits.
I would really like to find out: a) who is doing this work; b) is there a
paper; c) some performance figures (test code would be good :-).
If anyone has any pointers, please send them to me in private e-mail.
If anyone else is interested in this topic, please tell me in private
e-mail; I will CC answers to all interested parties, or (if interest
exceeds my CC threshold) post to the list.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-11-30 18:07:54
@_author: Scott Collins 
@_subject: Entropy, Randomness, etc. 
Good questions.
  >My understanding of a random number is a number is generated from
  >two or more unrelated events.
No.  This may be one general category of ways to manufacture random
numbers, but specifically a random number is just an arbitrary number
typically drawn from a sequence of independent arbitrary numbers.  The
quality of 'randomness' is a measure of the independence of the elements in
the stream.  Therefor, there is no such thing as a random number except as
an element of a sequence or other context from which to establish
  >In order for this number to be most useful cryptographically, it needs
  >a even distribution.
No.  In order for this number to be cryptographically useful, it must cost
more to guess the number (perhaps knowing the numbers that came before)
than the reward for guessing it correctly.  It happens that non-flat
distribution of a sequence is a lever for cheaper guessing, thus flat
distribution is natural characteristic of high-quality random sequences.
  >Does this make this distribution a gaussian distribution?
No.  Gaussian (a.k.a. 'normal') distribution is the bell curve (and clearly
indicates a relation between samples).  Math texts describing this
distribution often use the phrase 'distribution of some random variable x',
by which they in fact mean 'distribution of samples from a varying source'.
  >Also how are these statistical measurements done?
See Knuth, "The Art of Computer Programming", Volume 2: Seminumerical
Algorithms, Chapter 3: Random Numbers.
  >Is it as simple as a histogram?
  >Are we talking frequency analysis with FFTs and
  >more advanced things?
  >How do we measure the entropy of a random number, or a series of
  >random numbers?
Ah.  Now we're talking.  Entropy is closely related but not equal to
'randomness'.  Entropy is a measure of information often expressed as the
fraction of information-size to data-size.  Randomness is a measure of
unpredictability.  A sufficiently random sequence will be of very high
entropy from the perspective of the 'guesser', though not necessarily from
the that of the generator (e.g. a PRNG).  The best way to measure entropy
(if that is what you want to measure), is to build a sufficiently powerful
Markov model, or the equivalent, to predict the sequence, and treat it like
a compressor.  The number of bits output is the entropy of the sequence
with respect to that model.  If you can't build a model as smart as your
presumed attackers (as smart as them, not as smart as any model they might
build), then you will have to use more tests to assure yourself of
indepence of elements in the sequence (see Knuth, et al).  In practice
however, most of these methods represent very low bars over which any RNG
_must_ jump, and which often poor ones can.  Most RNGs are broken by
understanding how they work, and exploiting weaknesses in their
construction and context (e.g. poor 'seed' selection).
  >Have people on the list done this, or is this still in the range of
  >people that do math and number theory for a living?
Yes, and Yes.
  >These topics are probably covered in some of the basic books in the field,
  >but all of the reference's I've been able to locate don't go into
  >specifics of how to measure the quality of random numbers.
See Knuth.
  >Unless some measurements are made, you can't really be sure that those
  >/dev/mem MD5 hashes don't come up the same 10%, 30%, or more of the time.
  >It seems that a lot of assumptions are being made about what is good and
  >what isn't.
You should be exactly as paranoid as it is cost effective to be.
Hope this helps.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-09-01 16:14:28
@_author: Scott Collins 
@_subject: Non-Cash Schemes -- precedent? 
This mornings (1 Sep 93) Wall Street Journal, page B2, Enterprise column:
"'Scrip' ATMs Appeal to Growing Number of Retailers".
The artical describes retailers who are installing ATM machines that hand
out 'scrip', deducted from a clients account, for use in the stores.  Less
attractive to thieves, cheaper to build and maintain.
A physical precedent for digital schemes ?
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-09-07 12:26:42
@_author: Scott Collins 
@_subject: Who generates AOCE keys? 
In the software I used (as recently as last Thursday) the keys are
_absolutely_, _positively_ generated locally.  Subsequently the public key
can be mailed automagically to RSADSI to be incorporated into a certificate
which is returned to you.  The latest version of RIPEM Mac uses the same
procedure for the same functionality.
  >>[...] users will get certified keys from RSA [...]
Yes!  _After_ sending RSADSI an uncertified key.
  >>[the user] can generate a key for use on their network
This is the uncertified key.
  >>Apple believes you'll want publically certified keys
Thus, they provide a mechanism to get RSADSI to certify your (self
generated) key.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-09-07 15:47:40
@_author: Scott Collins 
@_subject: Who generates AOCE keys? 
>what keeps people from [getting certified] keys with somebody else's name
The The relation between the preferred signature authority for the
installation, and that installation.  From the documentation:
  >Some companies authorized to issue approval files to their employees may
  >require that you sign a printed request form and have it notarized by a
  >notary public. (To create a printed request form, choose Print from the File
  >menu.)  Note:  If you are going to use your Signer as an individual or in a
  >small business, look for the insert that came with this package for
  >instructions on using an outside approval authority.   >Print your request and send it, with a copy of the Request file on disk if
  >necessary, to your approval authority.  See the insert that came with your
  >package for details.  Assuming that your request form has been completed
  >properly, the approval authority will send back your Signer Approval file.
...which would seem to put the lie to (the general application of) my
ealier statement:
  >[the key] can be mailed automagically to RSADSI
Which turns out to be true only for the 'low assurance' RSA Persona
Certificate Authority (currently handing out certificates for free) which
does no verification of the user<-->id link.  CAs with more stringent
policies have stronger prerequisites for the issuance of a certificate.
Hope this helps,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-09-09 13:52:26
@_author: Scott Collins 
@_subject: blank lines v. the remailer 
>        Upon repeated tests of my remailers, I noticed that if there's
  >more than one blank line between the header and the header-pasting, then
  >the pasting doesn't take place. Does this happen with other people's
  >remailers? How is your script different from mine? How can this be fixed?
What follows is some of the text of the recurse.pl script, a component of
the remailer system.  I imagine that there are different versions of this
script floating around, but this is the version I got from
soda.berkeley.com when I set up my remailer.  I have commented it (and
noted my comments with 'SC:') to explain the relevent behavior, and deleted
non-relevent sections:
----------cut here----------
  # SC:read the header, looking for relevent lines
while (<>) {                # SC:get the next line (from where ever) into $_
        s/[ \t\r]*$// ;     # SC:remove trailing white space from $_
        last if /^$/ ;      # SC:get out if this line ($_) is otherwise blank
       ...code deleted here...
# SC:at this point $_ contains the blank line that followed the header
#  unless there was no blank line or message following the header (bad message)
  # We have just read the last line in the header.
  # Now we check to see if there is a pasting operator.
if ( ( $_ = <> ) && /^::[ \t\r]*$/ ) {
  # SC:get the next line (from where ever) into $_ ('if' can't use 'while'
  #  magic form), and if that next line is the pasting token then...
           # SC:append all the folling lines (up to, but not including,
           #  the next blank one) to the header
        while (<>) {
           ...code deleted here...
        }
} ...code deleted here...
----------cut here----------
You can see (from the condition of the 'if') that this code only finds the
pasting token if it is separated from the header by exactly one blank line.
This is easy enough to fix, if it is not the desired behavior, by inserting
while (<>) {
  last unless /^[ \t\r]*$/ ;
before the 'if' and removing the '($_=<>) &&' from the if condition.
Hope this helps,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-09-18 06:06:53
@_author: Scott Collins 
@_subject: anon.penet.fi 
>What is your policy on chaining to anon.penet.fi?
Hmmm, it would be bad to post to anon.penet.fi through a remailer, as the
anon id assigned by penet would be associated with the remailer, _not_ with
you.  Therefore, people who responded to the message would actually be
sending mail to the operator of the remailer that was the hop into penet. Not to mention the fact if the remailer account were also a personal
account, and the operator was a client of penet, that his anon id could be
compromised in this way (if he was foolish enough not to have a password).
Therefore, it seems reasonable that remailers should refuse to mail into
penet, unless and until a non-anonymous reply to anonymous mail facility
becomes available there.
To the penet knowledgeable: is my understanding correct?
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1993-09-18 18:05:36
@_author: Scott Collins 
@_subject: anon.penet.fi 
>Solution: if you send to na12345 at anon.penet.fi, then your mail won't
  >be pseudonymized; if you send to an12345 at anon.penet.fi, then your mail
  >will be pseudonymized.
Good.  Therefore, remailers should translate 'Request-Remailing-To:'
addresses like this:
        if ( /an(\d+ at anon.penet.fi)/ )  { s//na$1/; }
That is unless there are fifty other ways to say   In which
case, I would need to know the fifty ways.
Is this reasonable?
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   1 Infinite Loop, MS 301-2C   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1994-04-01 13:44:00
@_author: Scott Collins 
@_subject: How Many Games of Chess? 
>This is tangentially related to crypto.  I've been reading A.K. Dewdney's
  >_The New Turning Omnibus_ recently to refresh my memory of all that stuff
  >I learned in undergrad that I'm going to see again on the Comp Sci GRE
  >shortly. :-)  Anyway, I was glancing through the chapters on complexity,
  >computabilty, and minimax trees, and I got to wondering something:  how
  >many possible games of chess are there?  I know that it has to be a finite
  >number, but I'm not sure how to go about finding this number.  Any
  >pointers would be appreciated.
First, I think there are a finite number of games only if all stale-mates
are are required to terminate.
Second, here's one way if `just walking the tree` is too boring for you:
  0 - Start your computer on this while you hop in a starship and circle in
local space at a significant fraction of C.
  1 - Generate every legitimate board position (don't forget, pawns may be
promoted to other pieces) without regard for playing games.  A board
position might be expressed as a 64 digit, base 13 number.  More efficient
representation is probable (and desirable).  Plainly the number of board
positions is something vastly smaller than 13^64 which is 1.96e71 or
  196053476430761073330659
  760423566015424403280004
  115787589590963842248961
At this time, use two extra bits per state to note the mate condition.
Additionally, the total number of games must be less than or equal to the
total number of permutations of every possible board position.  Thus the
total number of possible chess games is something (again vastly) less than
(13^64)! (i.e., factorial --- sorry, Mathematica found this a little too
daunting to give me an estimate).
  2 - Connect nodes with edges representing possible moves.  For each
position, there can be no more than 64 pieces that might move, and for
each, no more than 63 possible results (including pawn promotion), so the
maximum number of edges is (13^64)*64*63 or about 7.90e74.
At this time, or slightly later, use the mate bits to indicate stale-mates.
  3 - Remove all subgraphs unreachable from the distinguished node that
represents the starting position.
  4 - Count the number of distinct paths through the graph that end in a
mate or a stale-mate.
  5 - Land your spaceship, collect your answer and find out how much money
accumulated in your hedge-fund while you were gone.
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-04 13:49:57
@_author: Scott Collins 
@_subject: How Many Games of Chess: Exact answer given! 
Based on new information I have at last answered the question of `How many
games of Chess' with finality.  Here is the quote that woke me up to the
reality of this problem in combinatorics.
  >The fact is that the end game is what defines a game of chess and
  >not the infinitude of possible paths between the first and last move.
The natural conclusion is that the complexity of the problem depends on how
much of the game you consider to be the `endgame'.  Thus, the actual number
of different chess games: 5
 2) White mates
 1) Black resigns
 0) Stalemate
-1) White resigns
-2) Black mates
Happily, this agrees with observed behavior.  In fact, this is the way
posterity remembers them, e.g., "Oh, yes, Spasky won." ;-)
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-05 15:19:15
@_author: Scott Collins 
@_subject: I need a book: Applied Combinatorics 
It goes for 84 bucks new.  I'm looking for a used copy.  Moe's is looking
for it.  Is there anyone out there who can sell or loan me a copy?
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-11 12:21:30
@_author: Scott Collins 
@_subject: (n!+1)^(1/2) 
>For any number n, if the square root of (n!)+1 is an integer, it is also
  >prime.  (This is interesting, but rather useless in practice)
For any number a, 1<a<=n, n! mod a == 0; therefore, n!+1 mod a == 1.  n!+1
is prime.  Prime numbers don't have integral square roots.
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-11 14:59:54
@_author: Scott Collins 
@_subject: (n!+1)^(1/2) Oops! I'm wrong. 
>For any number a, 1is prime.  Prime numbers don't have integral square roots.
  >For example :
  >
  >(4!+1)^(1/2)=5
  >(5!+1)^(1/2)=11
  >(7!+1)^(1/2)=71
I am completely wrong.  I replied too hastily.  Please accept my apologies.
 In fact, n!+1 is relatively prime to any a, 13, (n!+1)>(n^2) and may have factors
(including an integral square root) larger than n.
Oops :-)
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-14 20:30:58
@_author: Scott Collins 
@_subject: Good PRNG (here's where) 
>i'm doing some stuff on this remailer which requires a good rng.
  >perl's rng just calls c's rng, which totally sucks.  does
  >anyone know of a cryptographically sound rng i can use?  i could
  >just call it from perl or something.
Mark Riordan's ftp site has the source for the Blum-Blum-Shub PRNG.  This
should meet your needs.  You will have to contact him for access if you
don't already have it.
Hope this helps,
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-18 16:02:59
@_author: Scott Collins 
@_subject: 15 out of 16 times... 
It has been known since before I was born (see the very readable "Lady
Luck, the theory of probability" by Warren Weaver, 1963, Doubleday/Anchor
LoC CC# 63-8759) that the value (i.e., here 'cost') of this game is
This is described by a correlary of the law of large numbers wherein
(quoting from Weaver, emphasis his):
  By making the number _N_ of trials large
  enough, you can make as near unity (certainty)
  as you desire the probability that the actual
  number _m_ of successes will _deviate from_ the ex-
  pected number _np_ _by as much as you please_.
Note that, effectively, this law applies _before_ the one that lets you win
an expected number of trials.  This is why the person with the greater
bankroll can win even in the face of sub-optimal 'odds'; why Las Vegas
still exists; why gamblers still go broke; and why they go broke quicker
with the doubling system.
If it is not a question of probability, i.e., both parties _know_ the
commodity will perform in a particular way... then this does not apply. However, to the extent that they are uncertain --- it does (in spades).
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-18 17:16:28
@_author: Scott Collins 
@_subject: my remailer taking some (mild) heat [LONG] 
For your edification:
I run a remailer.  Someone used it to post copyrighted material.  I was
contacted to help resolve the issue.  The person who contacted me, Brad
Templeton, was neither abusive nor unreasonable, but he did express some
interesting attitudes.  I am reposting the dialogue here.  My added
comments begin with '
I must emphasize that I sympathize with Mr. Templeton and bear him no ill
will.  I am interested in his views---and your reaction to his views---of
remailers, their legality, and future.
 Somebody posted an AP Wire story to comp.org.eff.talk using your
remailer.  We'll need to know who it was or have you contact them
so we can get them to make amends for the copyright violation.  Thanks.
 I responded::   # I included his initial message here
This is distressing to me.  I don't run a remailer to abet infringers of
copy (or other) rights.  I certainly do not condone this action. Unfortunately, there is little I can do after the fact.  My remailer is not
the sort that requires a priori relationships.  If a message has the right
sort of header, the remailer sends it on its way ... no questions asked.  I
never see any mail that passes through my remailer.  I keep no logs, the
efficacy of which would be compromised in any case by remailer chaining or
encryption.  I can block remailing to or from any particular address, but
my remailer is incapable of taking action based on content.  I am sorry
that I can neither tell you who it was, nor contact them ... not because I
don't wish to, but because I am unable to.
I will happily assist you in any way that I am able.  What follows is my
public policy with respect to the remailer.  It details my capabilities and
  # I included my remailer policy here, which most of you have seen.
  # E-mail me privately for copies.
I hope this is of some assistance to you.
: I understand your policy, and I suspect that down the road that while
anon remailers will continue to exist and serve a purpose, those that allow
people to break laws behind them (defamation and copyright, and possibly
kiddie-porn in particular) will have to shut down.
The law is clear on this.  If a newspaper publishes libel, the newspaper
is liable with the writer, and fully liable if they hide the writer's
name.   You'll be in that boat, and shutting down or logging after the
fact won't do you much good.
I think the right answer is a remailer that logs, allows replies (like
the finet one) and which opens up in the case of illegal postings, or
any other postings that don't follow its rules.  It might say that
it demands a warrant, for example.
What you're doing is of little value.  Anybody can post anon to USENET
anyway, if they don't care about replies.  I am surprised you would
take the risk to add no functionality.
 I responded: My immediate advice to you is to send mail to the same distribution that
the illegal material followed, requesting contact from the sender.  This
would have the same enforcability of reply as Julf's remailer.  People
rarely mail things to lists they don't themselves read, so it is likely to
be read by the intended.
As I said before, I will help you in any way that I can.
I understand that, lacking a perpetrator, I am the next visible target for
your ire ... so I am taking your comments as predictions about society (as
I'm sure you intended) rather than personal comments (as so many people are
wont to read into e-mail these days).
  # I included his first two paragraphs here.
My remailer is not a newspaper; rather it resembles the post-office, a
phone switch, or the hole in the tree trunk in "To Kill a Mockingbird". All of these allow communication with some amount of anonymity selected by
the sender (up to and including `no return address`).
Newspapers have editors.  There is a presumption of knowledge over their
content.  _Of course_ one sues such a publication for libel or error---they
have advertised their control over their publication so that readers may
trust in its verity and appropriateness.  One _must_ sue when such a
trusted publication causes damages.
Angry people can 'cement over the hole', but it won't be because my
remailer broke either faith or law.
  >I think the right answer is a remailer that logs,
Any phrase that starts with 'the right answer is' is questionable.  If
there were a 'right answer' for communication we would only need one of:
newspapers, phones, tv's, postcards, conversations in the hall, pounding a
broom handle on the ceiling, short-wave radio, ad infinitum.  The right
media depends on the situation and the people involved.
  >allows replies (like the finet one)
My remailer allows replies; the sender need only include a return address
(possibly encrypted) exactly like the US Post Office.  My service is
completely different from the finet one.  Julf's system requires its own
machine and huge space resources for mapping tables.  Such a system is
beyond my resources.
  >and which opens up in the case of illegal postings, or
  >any other postings that don't follow its rules.
My service conforms to this statement.  I was---and am now---happy to help
you resolve this issue to the best of my ability.  I won't support,
condone, or abet illegal activity; however, I can't and won't spy on law
abiding users on the slim chance that I could detect illegal activity a
priori.  I will enact restrictions that prevent illegal activity whenever I
can do so without impacting citizens (e.g., I can block addresses, etc.).
  >What you're doing is of little value.
It is unfortunate that your only contact with my remailer was of little (in
fact negative) value to you.  In in another situation you---as other people
certainly do---might value it highly.
  >Anybody can post anon to USENET anyway, if they don't care about replies.
My remailer makes no provisions for posting to usenet.  It is simply a
remailer; it can do nothing that sendmail cannot do.
  >I am surprised you would take the risk to add no functionality.
One if by land; two if by the information super-highway.
We're all together in this,
 I thought it was for netnews, that is what I saw.  Actually, anybody can
do anon E-mail as well, but fewer know how.
You are not a newspaper, but I truly believe you are taking on all the
liability for bad things in the material remailed.
 The End? Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-18 21:25:13
@_author: Scott Collins 
@_subject: 15 out of 16 times (math, not laundry) 
>Actually, the casinos win in Las Vegas because the odds of almost
  >every bet are in their favor.
In most cases the odds favor the house---I never claimed otherwise---and
that certainly speeds up the inevitable process of cash extraction.
  >Larger capital allows you to affect the distribution of winnings, but
  >not whether or not the underlying bet is a good one.
If the difference in bankrolls exceeds a tolerance related to the `odds',
the quality of the bet is immaterial.
The direct implication of the weak law of large numbers is: a) the longer
you play, the more certain you will experience a `run of bad luck'; b) the
party with less money goes broke waiting for their `run of bad luck' to
end.  When one part goes broke, the game is over, even if the distribution
of winnings does not match the theoretical expectations (and in the case of
going broke, it can't ... or you wouldn't have played).
  >Every casino, in effect, takes on the whole world.  As all the bets
  >are independent, it doesn't matter if they are played by one player or
  >by a new player every time.  The world has much more capital.  Yet the
  >casinos consistently win.
No.  The whole world doesn't go broke as a unit.  Individuals stop playing,
leaving their money in an unexpected distribution, when they _personally_
go broke.
In fact, most gambling decisions are related in some way to cash resources
of the participants.  For example, I propose a hypothetical game where you
(the player) flip a fair coin.  If it comes up heads on the first toss, I
pay you $2; game over.  If it comes up heads on the second, I pay you $4;
game over. $8, $16... How much would you pay me (the house) to play this
game?  The theoretical value is infinite; you could win any amount of money
at this game -- 1/2 the time $2 dollars, 1/4 of the time $4, 1/8 of the
time $8... expectations = Sum_{n \goesto \infty}{n \over n}.
Let's say I'm an actual casino, and could reasonably pay out winnings up to
but not beyond $4.3 billion.  You should pay no more $33 for a chance at
that money.  Derivation as an exercise for the reader.  Consider this from
the perspective of the house.  The house is using the Martingale system
against you, doubling its bet every time it loses until it gets that $33. That means that to launder $33, one party could conceivably lose
$4.3billion.  Obviously no mathematicians work at my casino.  They all left
to persue jobs that ensure a paycheck.
These are _not_ my personal conclusions.  This is sound, if disturbing,
probability theory---known for at least 250 years.  This particular effect
goes by many names including "Gambler's Ruin".  Given the odds, and the respective bankrolls, you can calculate the probability that any given
party will go broke in extended play.  The problem of "Duration of Play"
was solved by Bernoulli and published posthumously in 1713.
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-19 16:58:18
@_author: Scott Collins 
@_subject: 15 out of 16 times (math, not laundry) 
>Pretend the casino is run out of a church.  "Parishioners" arrive and
  >enter a confessional to place their bets.  The "priest" cannot see who
  >is placing each bet.  Each "parishioner" plays until he or she is
  >broke.  "Parishioners" arrive at a steady rate and will do so
  >indefinitely.
Let me just make sure I understand what you mean.  I believe you are saying:
Conjecture A:
  A.1   As parishoners play and leave, the division of wealth approaches the
        `odds' of the game.  Thus if the odds are .51 house (of God), .49
        parishoner, then eventually the house will end up with 51 cents
        out of every dollar `played'.  Just as it would if the church were
        playing against one very wealthy parishoner (i.e., the `world').
  A.2   Since there are a large number of parishoners, enough games can
        always be played to make the distribution match the odds.
If this is _not_ what you mean to say then I apologize for missing your
point; read no further---just send me explanations to clear up my
mis-understanding.  If Conjecture A is accurate statement of your belief,
then please step across this line.
Let me walk through your model, one parishoner at a time.  Please read this
with an open mind; it could be true.
  >Each "parishioner" plays until he or she is broke.
Lets say the odds of the game are .51 to .49.  Each parishoner has $100. Each parishoner plays until broke.
At some point in play, the distribution of wealth with respect to _that
player_ may be arbitrarily close to c=$51, p=$49.  What, though, is the
distribution at the _end_ of that game?  Since each game only ends when the
p=$0, the distribution is c=$100, p=$0.  On to the next parishoner.
After the 9th, but before the 10th parishoner, the distribution must be
c=$900, p[10]=$100.  It can't be worse than that for the church, or we
wouldn't have moved on to the 10th parishoner.  It can't be better for the
player because each has only $100 to wager.  After the n'th, c=$100n,
Conjecture A predicts that as n, the number of players, goes to infinity,
c, the fraction of money won by the church, approaches C, the probability
the church will win a single trial.  But in fact, the model shows that as n
approaches infinity, c goes to 1.
Where could one disagree with this interpretation of the model?
  a.    Maybe the church has 10 confessionals, or 1000, or 10,000.
        Serializing the players might be a `paper' advantage to the church
        that doesn't occur in reality.
  b.    Players can have any amount of money, not just $100 dollars.
  c.    What if the church goes broke?
(a) Imagine that the church has at most k confessionals, and thus can play
no more than k simultaneous games.  Fill all k.  All other players are
waiting in line for an open spot.  The next parishoner can't play until an
existing player goes broke.  The distribution of wealth during play by the
(k-1+10)th player is exactly as before, except now it is +/-$100(k-1).
(b) has no impact.  As above, at the end of each game the fraction of money
won by the church with respect to that player is 1 (assuming it's the
player and not the church that `went out').
(c) If the church goes broke, all bets are off, literally but not
figuratively.  The distribution of wealth is c=0, P=1 (P for all players as
opposed to p for a single player).  This also does not match the
expectation of .51.
  >The chance of the "church" to win or lose is the same on every
  >bet, regardless of who places it.
That is true.  But the only way the player can realize his mathematical
expectations is if he is allowed to continue playing even after he is out
of money (i.e., so he can climb back out of the hole).  Ok, the first
player goes out, but the infinity of players after him can make up for
that, right?  Wrong, because on his way to winning back the first players
money, if the second player goes broke, _his_ game is over.  Now its up the
third guy, ad infinitum (literally)..... just because the series is
infinite doesn't mean the sum is.
No set of players, all of whom go broke, break the church.  Therefore, for
the series to end it must be instigated by a set of players that includes
at least one who doesn't go broke (i.e., the church goes broke instead). In fact, a single player who doesn't go broke ends the series without any
help from other players.
Thus, to stem the tide of pious donations (i.e., the church's winnings), a
single player with enough money to `outlast' the church is required.
Hope you found this interesting but not insulting,
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-21 14:34:37
@_author: Scott Collins 
@_subject: Gambler's Ruin, 15 out of 16, and a Probability Parable 
Howdy Peter,
OK, though it's been enjoyable, I won't try any further to convince you.
I peppered this message with smileys to let you know that I think
mathematical debates are about differing observations, not differing
values.  In such conversations, its easy to lose sight of that and take
something the wrong way.  Please don't; it has been fun and just because
neither of us has convinced the other (yet) doesn't mean I think the less
of you (or, hopefully, the reverse... I know to you, I must seem pretty
I, myself, would like a little more explanation of _your_ point of view
(see my question below beginning with "Why?").  I will recapitulate the
high points of my problems with your previous arguments so that you can
clear them up for me in private e-mail.  I also quote some equations that
summarize the point I was trying to make, so that you can examine them and
offer up alternatives that represent your point.  I am cc'ing cypherpunks
on this final message so that they can see these equations.  Here we go :-)
I wrote a conjecture:
  SC>A.1   As parishoners play and leave, the division of wealth approaches the
  SC>      `odds' of the game.
Which you agreed with:
  PH>I agree with both conjectures.
I then repeated the conjecture in my argument:
  SC> [A.1] predicts that as ... the number of players goes to infinity,
  SC> ... the fraction of money won by the church approaches ... the probability
  SC> the church will win a single trial.
Which you do _not_ accept as the statement you agreed with:
  PH>There is a slight difference between [A.1] and
  PH>this statement.  [A.1] predicts that as ... the number of bets
  PH>goes to infinity the fraction of bets won will approach ... the
  PH>probability that the church will win a single trial.
On the probability of the player's ultimate ruin you say:
  PH>Each parishioner has a high probability of losing their savings and a
  PH>low probability of winning everything owned by the church.  It is
  PH>possible for any single parishioner to win everything, but it is
  PH>unlikely.
Why?  Why is the probability not almost `even', like the odds of the game,
.51 vs .49?  What other information influences this _new_ probability, the
probability of the player going broke, if it is not---as I say---the
difference in cash resources between the player and the house?
I didn't ask you this question in my earlier messages---I thought I was
supplying the answer---but you did provide an alternate explanation:
  PH>This player wins because he or she was fortunate enough to place the
  PH>first bet in the series [of sufficient consective bets lost by the house].
  PH>The player needs to be lucky.
To paraphrase my "Why?" question above: can you qualify `lucky'?  How
`lucky' does the player have to be?  I submit to you that given individual
trials where the players probability of winning a single unit in a single
trial is p, the total amount of money at stake in the series of trials is
C, the amount currently held by the player is d, the house C-d=D, that the
ultimate chance for the players ruin is given by the equation (from
[Weaver] cited in an earlier message):
                      1-p
            where r = ---                        p
                                             r^C - r^d
       R_d (prob. of ruin given d capital) = ---------
                                              r^C - 1
Though in the limit (a fair game) you would derive a friendlier form as:
                        d
              R_d = 1 - -
                        C
...and, of course, at the other extremes, where p=1, or p=0, the player
never or always goes broke respectively.
These equations are consistent the proposition that the probability of ruin
depends on both the odds of the game _and_ the initial distribution of
capital.  Note their behavior as C increases with respect to d.  Soon, this
difference dominates even in the face of good `odds'.  I invite you to
experimentally verify, at your leisure, the `fair game' version with two
players and different amounts of pennies where each bet is a single penny
and decided by a coin toss.
Finally, you offer me this comfort :-)
  PH>This can be very confusing.  I've seen two professional mathematicians
  PH>and a futures textbook make this mistake.
Thank you ;-)  If I, two professional mathematicians, a textbook, a book I
cited to you, and several other cypherpunks all erred similarly, then it
must be a treacherously easy mistake to make; I don't feel any shame.  But,
I would also relate this little probability parable (again, from
[Weaver])---of course drawing no comparisons:
  In the card room of the Quadrangle Club at
  the University of Chicago, years ago, a hand con-
  sisting of thirteen spades was dealt.  The celebrated
  mathematician Leonard Eugene Dickson was one of
  the players.  (Those who know his interest in bridge
  realize that the probability of his being one of the
  players was not far below unity.)  At the request of
  his companions, he calculated the probability of this
  deal  (It is roughly 10^-13.)  A young know-it-all gaily
  reported at lunch the next day that he had calculated the
  probability of dealing thirteen spades, and had found that
  Dickson had made a mistake.  Another famous
  mathematician, Gilbert Bliss, was present; he
  properly dressed down the youngster by saying,
  "Knowing that Dickson calculated a probability and
  got one result, and you had tried to calculate the
  same probability but got another result, I would
  conclude that the probability is practically unity that
  Dickson was right and you are wrong."
Be happy and keep wondering---that's what makes us great,
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-04-23 18:36:17
@_author: Scott Collins 
@_subject: Byzantine Agreement Problem 
The "Byzantine Agreement Problem" is _not_ solved in theory.  The last time
I surveyed the literature, it was still widely conjectured to be
theoretically intractable.  It has direct implications on networks and
networked systems; however, often some of the constraints of the original
problem can, with effort, be violated---which makes practical systems more
feasible.  These violations usually take the form of a second, more
reliable, band of communication.
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-02-08 17:42:12
@_author: Scott Collins 
@_subject: Some stuff about Diffie-Hellman (and more :-) 
DH exchange doesn't require a known modulus.  Most people implement it with
a common alpha and small set of generators so that they don't have to
invent a distribution or agreement protocol.  Authenticated DH exchanges
(e.g., station-to-station protocol) can include these parameters as part of
each parties signature; and provide an agreement policy (e.g., initiator's
parameters unless receiver thinks they are weak).
After each party has generated and exchanged an exponent, each verifies the
`certificate' of the other, and the signature of the other over the
exponent pair.
The shared knowledge that makes this possible in this case is, of course,
foreknowledge of the public key of the other party.  If you don't know it
before you start the protocol, you can't really know who you're talking to.
 Other protocols can be designed with other choices of shared knowledge.
STS is immently practical, any other practical and fair scheme is likely to
be similar, i.e., involve shared knowledge, independently generated random
input from both parties, a mechanism for securely (but expensively)
transmitting the random data (typically based on the shared knowledge),
combining the disjoint random data symmetrically so that each party shares
in a fresh secret session key, and finally authentication based in part on
the original shared knowledge.
Hope this helps,
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1994-02-16 13:00:27
@_author: Scott Collins 
@_subject: Politics, Religion, MUDs, MOOs, the Internet, the Past, and the Future 
Here is some cogent text from James Burke, a guy right at the top of my
`man-I-wish-I-was-that-smart' list.  He is noted for his television series
"Connections", "The Day the Universe Changed", "Tomorrow's World", and "The
Burke Special".
After the last physical cypherpunks meeting, thoughts of MOOs and whatnot
floating through my head, I chanced on a Discovery Channel broadcast of
"The Day the Universe Changed" and when it was over, rushed right out to
get the book.
His comments about computers (particularly considering he made them in
1984-5), and the kind of future they can allow mixed in my head with all
the things cypherpunks normally plan for and dream about and filled me with
a sense of "Wow! This guy is dead on (and even still ahead of us in his
    James Burke
    The Day the Universe Changed (companion to the public television series)
    1985, Little, Brown, and Co.
    ISBN 0-316-11706-4
  *** the first sentence from the Preface ***
You are what you know.
  *** the last five paragraphs in the book ***
The knowledge acquired through the use of any structure is selective. There are no standards or beliefs guiding the search for knowledge which
are not dependent on the structure.  Scientific knowledge, in sum, is not
necessarily the clearest representation of what reality is; it is the
artifact of each structure and its tool.  Discovery is invention. Knowledge is man-made.
If this is so, then all views at all times are equally valid.  There is no
metaphysical, super-ordinary, final, absolute reality.  There is no special
direction to events. The universe is what we say it is.  When theories
change the universe changes.  The truth is relative.
This relativist view is generally shunned.  Is is supposed by the Left to
dilute commitment and by the Right to leave society defenseless.  In fact
it renders everybody equally responsible for the structure adopted by the
group.  If there is no privileged source of truth, all structures are
equally worth assessment and equally worth toleration.  Relativism
neutralizes the views of extremists of all kinds.  It makes science
accountable to the society from which its structure springs.  It urges care
in judgement through awareness of the contextual nature of the judgemental
values themselves.
A relativist approach might well use the new electronic data systems to
provide a structure unlike any which has gone before.  If structural change
occurs most often through the juxtaposition of so-called `facts' in a novel
way, then the systems might offer the opportunity to evaluate not the facts
which are, at the present rate of change, obsolete by the time they come to
the public consciousness, but the relationships between facts: the
constants in the way they interact to produce change.  Knowledge would then
properly include the study of the structure itself.
Such a system would permit a type of `balanced anarchy' in which all
interests could be represented in a continuous reappraisal of the social
requirements for knowledge, and the value judgements to be applied in
directing the search for that knowledge.  The view that this would endanger
the position of the expert by imposing on his work the judgement of the
layman ignores the fact that science has always been the product of social
needs, counscioulsy expressed or not.  Science may well be a vital part of
human endeavour, but for it to retain the privilege which it has gained
over centuries of being in some measure unaccountable, would be to render
both science itself and society a disservice.  It is time that knowledge
became more accessible to those to whom it properly belongs.
  *** end of quoted material ***
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-02-23 13:28:12
@_author: Scott Collins 
@_subject: Why only public-key crypto? 
>I find this to be a strange statement.  Do we have no interest
  >in non-public key methods?  Seems the Cypherpunks should have
  >an interest in all forms of crypto.
It's not so strange.  Cypherpunks are trying to bring about social changes,
not primarily technological ones.  Crypto is here, and we want to change
our culture in a way where, through strong crypto, privacy becomes the norm
rather than the exception.
With this goal in mind, public-key systems are vastly more interesting
because they are the `social' solutions.
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-01-03 14:54:09
@_author: Scott Collins 
@_subject: Question for article 
>Say someone fucks you over (real or imagined) or flames you severely.  What
  >sort of nasty things can you do to them or their data?  You know, like
  >e-mail bombings etc.  I don't need particulars, since this is pointed at a
  >mainstream audience.  (It also might not get published if the technophobic
  >editor(s) think its too risque, if you know what I mean.)
You can:
  - 1 - If the damage done you was real, not just an annoyance, then you might
  - 2 - Otherwise, or if there is reason to believe that it was without
intent, then you could be a grown-up: live and learn.
Purile retaliation is the demesne of bullies and children.
  >I have some ideas already, but I'd like to hear from the pros. :->
This sounds like people who study martial arts so they can `really kick
some ass'.  Serious students of many disciplines consider it for defense
only.  This is the case with the technology of privacy.
You have seriously mistaken this list.  This is not a list of `expert
electronic vigalantes' who deal out home brew justice.  This is a group of
people with concerns about technological encroachment on personal privacy,
and ensuring that the information age doesn't swallow law abiding citizens
into a new world of glass houses.
I am sorry to say I can easily imagine what you must have been reading to
give you this impression.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1994-01-17 13:14:03
@_author: Scott Collins 
@_subject: Appropriate bit of poetry 
Alternatively... as Cat Stevens would say:
  "If you wanna be you, be you.  If you wanna be me, be me..."
I don't exactly share Stevens's sentiment.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1994-01-25 13:56:53
@_author: Scott Collins 
@_subject: Provability and Randomness 
Entropy is relative.
A string is `random' (with respect to an observer) when the probability of
correctly predicting the next symbol of the string is arbitrarily low
(e.g., size_of_the_alphabet^-1).  Entropy, and therefore `randomness' can
only be considered in the presence of symbol probabilities... and therefore
prejudicial knowledge i.e., a context (algorithms, models, history,
Different contexts --> different probabilities --> different quality of
 * Absent a context, there is no such thing as `randomness'.
Posit two identical contexts, sender and receiver.  Sender transmits a
`random' string to receiver.  (Beeeeeeeeeeep.  Sorry, that was the warning
that sounds whenever I fib).  The sender can only send a random string if
the reciever doesn't already `know' that string or doesn't know which
string the sender will transmit.  If the sender knows something that the
reciever doesn't then the contexts are not identical.
 * Absent differing contexts, there is no such thing as randomness.
A fair coin toss can be random because you_before_the_toss and
you_after_the_toss are different contexts (reciever and sender,
respectively; one of whom knows the outcome).
Posit two disjoint contexts, A and B.  A transmits a message to B, who has
no information in common with A.  B has no context with which to predict
the first symbol that will appear and thus it is always random.  As symbols
appear, B builds a model of A... and thus acquires knowledge of A (i.e., a
shared context).  By the end of the message, B might be predicting quite
well.  If B can't build any model of A's behavior at all, then B will share
no context with A; won't be able to predict characters; the string will
remain random.
 * Absent shared knowledge (overlapping context), all information is random.
Imagine that B's shared knowledge with A takes the form of a program to
output a prediction of the next symbol A will transmit.  This
program---however large it is and however it might work inside---is nothing
more than B's model of A.  When B has no knowledge of A, this program is
essentially `empty'.  It contains no information, and can make no
predictions better some arbitrary limit (e.g., size_of_the_alphabet^-1). The program learns from each symbol transmitted by A, thus a good (and
portable) measure of the `size' of the program is how many symbols it has
seen.  Let us say that this program sees every symbol A ever transmits to B
(numbered from 1..n), and thus during it's life it will actually be n+1
different programs (numbered B0..Bn of size 0..n, respectively).
Imagine that you can ask any one of these programs to predict any symbol
from A.  Thus you could ask B3 to predict symbol 4 (exemplary of the normal
case) or you could ask B5 to predict symbol 1 (which it could, of course,
do perfectly, having already seen symbol 1).
Now we have a new definition of randomness.  A string is random with
respect to B if no program of B shorter than the string can predict it with
success greater than our arbitrary threshhold (which is typically defined
by the performance of B0).
If A is sending a passage from a well known book, and B `discovers' this
after receiving symbol 20 and can access the text of that book, B20
suddenly becomes a very good predictor of many future symbols.  The string
is not random.  But it _was_ random to B0, and B1 and perhaps less for each
successive symbol.  B20 is a different context than B0.  It has different
knowledge, different probabilities and therefore perceives a different
quality of randomness in A's message.  B20 is still only a program of
`size' 20 (i.e., you don't count the size of the book in B).  This is
easily demonstrated if you imagine what happens when A sends a message that
is a deterministic algorithm for producing a an infinite stream of symbols,
followed by the stream it generates.  If this algorithm requires i symbols
to express, then Bi is a perfect predictor for all subsequent symbols.  Bi
is clearly of size i (there is no external book for us to add to the size
of Bi).
In fact, no matter what message A sends, B considers it an algorithm for
generating predictions of future symbols.  Thus A is actually sending B a
sequence of programs (each a prefix of the next, and thus not
re-transmitted) B1, B2, ... Bn (but remember, these programs execute in the
context of B's knowledge... thus their predictions are not `universal'). This just brings our notion of programs, program length and prediction
around to the other side and lets us summarize:
 * A string is random with respect to B if the string itself is the
shortest program with which B can generate that string.
... or qualitatively
 * The randomness of a string Bn with respect to B is an inverse of the
quality of the predictions B can make of Bn from the strings B0...Bn-1.
We rely on the `relativity' of entropy.  Codes and cyphers can't function
without it.  The difference between your context and that of an attacker
(you know the key or codebook) is what makes the message meaningful only to
you (hopefully it will still have _some_ information you couldn't guess
before reading it).
Randomness is relative, thus there is no universal randomness measure for a
string, thus there can be no proof that a string is universally random. You can easily measure the exact entropy of a string with respect to a very
formally defined context (one where you can produce exact predictions). This is useful, but reveals nothing about the quality of the predictions a
different, even similar, context might make (Just one symbol is the
difference between B19 and B20 above; the string was random to one but not
the other), It reveals nothing about models we can't describe so perfectly
(like human thought).
 * There is no algorithm for deciding if a string is universally random.
In a less obvious leap, it is only by comparing the predictions of Bi with
Bk that a string of length j (i < j <= k) can be shown to be random with
respect to Bi.  Thus:
 * There is no algorithm shorter than the string itself for determining if
a string is random with respect to a given context.
Not exactly Q.E.D. but close enough for rock `n roll.
Scott Collins         | "Few people realize what tremendous power there
  is in one of these things."     -- Willy Wonka
BUSINESS.   voice:408.862.0540  fax:974.6094   collins at newton.apple.com
Apple Computer, Inc.   5 Infinite Loop, MS 305-2B   Cupertino, CA 95014
PERSONAL.   voice/fax:408.257.1746    1024:669687   catalyst at netcom.com

@_date: 1994-07-11 01:57:19
@_author: Scott Collins 
@_subject: Tamper-Proof Software? No! 
Software only products cannot be made unconditionally tamper-proof, for the
following definition of `tamper-proof':
  "An attacker, on their own machine (over which they have complete
control), given a copy of the software that `runs' on that machine but
includes mechanisms so that it won't run under certain conditions (the
`tamper-proofing'), cannot produce a piece of software that lacks the
By this definition, I am not addressing, e.g., pirates attempting to unlock
a software distribution without the key, nor getting a bogus agent to run
in a protected environment like Telescript, nor programs where a
significant part of its functionality happens inside a physically
tamper-proof `dongle'.
Tamper-proofing is a fundamentally different problem from secret
communication.  The latter is `How can two parties exchange information
such that no third party can learn it?'  The former is `How can one party
tell a secret to a second party, and at a later time, take it back?'  You
can't `un-tell' a secret.  The functionality of your program is the secret.
If that secret is revealed (and when you run the program, it will be)
there's nothing left to protect; the secret is out.
Tamper-proofing mechanisms amount to questions, answers, and actions.  Each
can be supplied by either the software itself or some outside entity (e.g.,
the OS, a `dongle', a network key-server, etc.).  They come in many forms,
but they can be reduced to "Is this the original software?", "yes" or "no",
and `continue' or `quit'.  In the case where it is the software itself that
decides whether to run or quit (and since the attacker has complete control
over the environment, it must be), the attacker is not constrained to
defeating an arbitrarily hard authentication scheme.  It is sufficient to
avoid the test or refuse to quit.  Replace each call to a tamper-detection
routine with a call to a routine that has the same side-effects as the
original would when no tampering has occurred (which can be observed).
Thus, if the software checksums itself---remove the code that asks for the
checksum, or remove the code that quits if the checksum doesn't match.  If
the checksum is required to decrypt some part of the program---build a copy
of the software that is already decrypted, or use the saved checksum from
an original run.  If the program uses the value returned by a dongle to
decrypt part of itself---watch it happen once, then keep the decrypted
part.  If a network server won't give you an open socket until the software
answers an unpredictable question about itself that the modified program
cannot answer---relay the question to an unmodified instance of the
Sooner or later, in the course of execution, the `useful' part of your
software will be presented, unencrypted and ready to run (if not without
strings) to the CPU.  Even if this happens only a little bit at a time, the
attacker can record those hunks and assemble them into a new, unencumbered
package.  The attack might not be cheap!  But people will do it if the
reward exceeds the cost.  If there is functionality you want to protect
unconditionally, don't give it away!  Sell a service instead.
Hope this helps,
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-07-12 13:10:26
@_author: Scott Collins 
@_subject: tamper-proof p-code 
Ray->In your essay, you overlook the use of pseudo-code interpreters
  > and cryptographic code mangling.
No I don't.  In fact, I specifically mention the latter.
  Ray->It is not possible to make software
  > unconditionally tamper proof, but it is possible to make it hard [...]
  Ray->If crackers had to alter just 10% of an
  > application to get it to work unprotected, I think that would be a
  > sufficient deterrent to most of them.
I agree!  I even said this in the final paragraph:
  Scott->The attack might not be cheap!  But people will do it if the
  >reward exceeds the cost.
Some of the things you mention would make a program very expensive to
`crack'.  However, as we both said: just expensive, not impossible.  It
certainly might be expensive enough to stop the particular class of attacks
you have in mind.
Your notes about remote trusted systems (e.g., Telescript) are accurate.
The difference they introduce into the scenario is that execution is no
longer under control of the attacker, and in fact the attacker can have a
piece of software that `runs', but may only run after being unlocked on the
trusted system, with the private key of the trusted system.  I specifically
mentioned and excluded this class of problems from my argument.
However, you also say:
  Ray->Here, the problem is that the code is never "decrypted" in
  >the first place.
  Ray->Imagine the task of having to create a plaintext which will generate
  > a certain MD5 hash.
No.  The code is decrypted.  It does get to the CPU.  The CPU does execute
instructions belonging to the `actual functionality' of the software.
Comparing this to finding a text with a given hash is not accurate.  (Maybe
it is accurate if the attacker tries to get between the interpreter and the
byte-codes; but not if the attacker just stands behind the CPU.)
Either the CPU gets to see the final instructions or it doesn't.  If it
never sees them it is because the program doesn't or won't run in the first
place.  I exempted this situation from my argument.  The attacker must have
at least one working copy of the software.  If the CPU _does_ see the
instructions, then the secret is out, no matter how difficult it is to
capture it ... it's still only difficult, not impossible.  My argment is
about communication, not about programming.  Like the old joke:
  A: "Would you sleep with me for a million dollars?"
  B: "...uh, sure.  Yeah, I'll sleep with you for a million bucks."
  A: "Would you sleep with me for twenty dollars?"
  B: "What do you think I am?!"
  A: "I know what you are!  Now we're just haggling for a price."
The quality and effectiveness of `protection code' (under the conditions I
gave) can never amount to anything more than `haggling for a price'.  I
think you already understand and agree with this.  The price might actually
be as much as $1,000,000.00; which could be sufficient deterrent.  To that
end, the tamper-proofing will have succeeded.
Your p-code (maybe `protected-code') proposal could be a viable product.
Don't stop.  After all, none of DES, IDEA, and RSA, are unconditionally
secure, and they serve us well.
Scott Collins     | "Invention, my dear friends, is 93% perspiration,
  6% electricity, 4% evaporation, and 2% butter-
  collins at acm.org |  scotch ripple."                   -- Willy Wonka
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
408.862.0540   fax:974.6094   R254(IL5-2N)   collins at newton.apple.com
408.257.1746  1024:669687                         catalyst at netcom.com

@_date: 1994-07-19 16:17:07
@_author: Scott Collins 
@_subject: Non-determinism forever. (was -- Re: GUT and P=NP) 
>Non-determinism is only another way of rephrasing the existential
  >quantification.
I agree.
Entropy, like velocity, is relative.  `Non-deterministic' is the label we
apply to the unknown or possibly unknowable.  Non-deterministic algorithms
(or thought experiments) work by `knowing more than we do'.  They guess the
un-guessable: the correct answers to problems we can't solve readily any
other way.  From their point of view, for some reason, it's not
un-guessable.  This very attribute makes them un-guessable to us.
We simulate `guessing' correctly by exhaustive search (check out, e.g.,
NFA's and pattern matching).  "Is P==NP?" is roughly equivalent to "For
every problem that you could `guess' the answer if only you knew how---and
can prove the answer correct without guessing---is there a shortcut (that
meets some strong criterea)?"
If P==NP is ever proven it _will_ have an impact on a large class of
problems (and the effect will depend on the nature of the proof), but not
all problems.  Some problems are harder than NP, e.g. decrypting a message
encrypted with a truly random OTP.  Even if you guess the correct
decryption, you can't prove it's right without guessing.
Currently, lacking `THE shortcut', P != NP (in the practical sense; _not_
the theoretical).  Even if it becomes the case that, demonstrably, P == NP
in both the practical and theoritical sense, the world will still be an
interesting place (in both the practical and theoretical sense).
Scott Collins     | "Invention, my dear friends, is 93% perspiration,
  6% electricity, 4% evaporation, and 2% butter-
  collins at acm.org |  scotch ripple."                   -- Willy Wonka
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
408.862.0540   fax:974.6094   R254(IL5-2N)   collins at newton.apple.com
408.257.1746  1024:669687                         catalyst at netcom.com

@_date: 1994-07-22 11:47:20
@_author: Scott Collins 
@_subject: catalyst remailer closed 
For those of you who have not seen my public policy on the use of the
catalyst remailer, this excerpt:
  >  - 3 -  I do not own the machine my remailer is running on.  In fact it is
  >         a commercial system.  Be nice.  If they ask me to stop running my
  >         remailer on their system... I will.  Additionally, you implicitly
  >         accept all the risks associated with trusting somebody elses
  >         machine.
After a rash of abuses, I received a polite notification from NETCOM that
it is now their policy to prohibit the running of remailers out of user
accounts, and a request to close down my remailer.
  >Therefore, you are hereby directed to disable your anonymous
  >remailer immediately.
That particular sentence may sound harsh, but it was set in very civil
message.  I just think they wanted me to get the point.
The catalyst remailer has been shut down.  While NETCOMs policy prohibits
remailers, it will not open again on NETCOM hardware.
Scott Collins     | "Invention, my dear friends, is 93% perspiration,
  6% electricity, 4% evaporation, and 2% butter-
  collins at acm.org |  scotch ripple."                   -- Willy Wonka
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
408.862.0540   fax:974.6094   R254(IL5-2N)   collins at newton.apple.com
408.257.1746  1024:669687                         catalyst at netcom.com

@_date: 1994-07-26 12:44:50
@_author: Scott Collins 
@_subject: No, each tape position cannot... (was Re: GUT and P=NP) 
>Could I not let each position on the tape represent a real value in
  >[0...1]?
You could try!  But you would always omit values.  You can demonstrate this
with the `diagonal rule' or similar proofs.  Here's a simple one:
Take any two adjacent `positions' on the tape; Write out the decimal (or
binary) notation for the real values they represent (note, the
representations may be infinite).  Given two such strings that are not
identical, you can always find a string numerically `between' them (even if
both are infinite) as long as they are not identical.  E.g.,
      "0.12345"
  --->"0.123455"<----
      "0.12346"
Such a string is a real value you omitted.  Your tape, even if it is
infinite, is not the right order of infinity to model the Real numbers.
Scott Collins     | "Invention, my dear friends, is 93% perspiration,
  6% electricity, 4% evaporation, and 2% butter-
  collins at acm.org |  scotch ripple."                   -- Willy Wonka
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
408.862.0540   fax:974.6094   R254(IL5-2N)   collins at newton.apple.com
408.257.1746  1024:669687                         catalyst at netcom.com

@_date: 1994-06-09 14:44:31
@_author: Scott Collins 
@_subject: I will be in Detroit/Cleveland/Akron area this weekend 
...and cities between.  I could also stop in Ann Arbor.  Any cypherpunks in
these towns who want to sign keys, etc, email asap; I might not be able to
retrieve it after I depart.
Be seeing you,
Scott Collins   | "That's not fair!"                         -- Sarah
 "You say that so often.  I wonder what your basis
   408.862.0540 |  for comparison is."                 -- Goblin King
BUSINESS.    fax:974.6094    R254(IL5-2N)    collins at newton.apple.com
Apple Computer, Inc.  5 Infinite Loop, MS 305-2D  Cupertino, CA 95014
PERSONAL.    408.257.1746       1024:669687       catalyst at netcom.com

@_date: 1994-03-09 10:28:01
@_author: Scott Collins 
@_subject: Why the chip in my dog won't work in humans. 
I have such a chip in my dog.
Animal services can destroy a stray animal after as little as 48 hours.  My
dog doesn't speak English, and if she loses her tags and gets lost ---
she's a stray!
Animal services scan (and you have to be pretty close, like those
door-opening-id-cards) all the animals that are picked up.  If there's a
chip, the animal WON'T BE DESTROYED.  They'll call the Infopet service, who
will in turn call me, and I'll come pick her up.  Additionally, I have
pre-authorized emergency medical attention for her.  If she needs help,
she'll get it even if they don't know where I am.
And, as others mentioned, if she is stolen then the next time she is taken
in to the vet (my vet and many others in CA scan as a matter of course) or
picked up by animal services ... I will know about it.
I love my dog.  She's a good companion; and I take good care of her.  She
has never lost her tags or `gotten loose'.  But if she ever does...
...this chip will help me recover my property.  Whoa! what happened to
loving companion?  How did we go from friend to chattel?  The truth of the
matter is that the law considers and dog _owners_ act as though dogs are
property.  They have value.  They need to be protected like any other piece
of property.  I love my dog, but that doesn't change the fact that if she
fell in love with YOU and wanted YOU to be her master and decided she no
longer loved ME ... she would still stay with me, because she's mine.
 - --- -
Is this the edge of a slippery slope for putting chips in human beings?  I
don't think so.  The reasons for having such a device in a dog are
completely different from the reasons for having them in an human being. In one case it is essentially to identify property (like a brand on a cow

@_date: 1994-11-22 11:07:24
@_author: Scott Collins 
@_subject: Brad Templeton, ClariNet, and remailers 
>Brad and ClariNet have already caused one remailer to go down (the
  >operator of it has commented here before and of course can do so again
  >if he sees this), and his comments Saturday night cause me to think he
  >may be considering a test case of some sort. (He is fearful of losing
  >his Associate Press/etc. franchise if he fails to enforce his rights.)
I might be the (ex-)remailer operator in question.  I find Brad's lack of
knowledge about remailers quite surprising in light of almost 4 hours of
conversation devoted solely to this topic, by telephone, over the course of
a month.
My summary analysis of Brad is: he'll try to scare/bully you into getting
what he wants by citing (or imagining) laws upon which he will base
prosecution.  Prosecution never follows.  If you debate his law, he resorts
to "You are Netcom's customer; Netcom is my customer; if you want to remain
Netcom's customer then you had better toe my line."  Persection of more or
less potency always follows.
I try not to flame, but the greater my contact with Brad---the greater my
disdain for him.  He is an extremely small-minded man.
Brad can't yet even demonstrate a crime.  He constantly reports remailer
abuses in the form of AP Newswire articles distributed anonymously; and
thus (_obviously_) stolen from ClariNet.  The AP Newswire, however, is
already distributed electronically has a vast army of legitimate
direct-subscribers.  Brad never offers evidence that the posts actually
come from ClariNet, and in fact ***he immediately deletes the posts
whenever he sees them*** (and saves no copies!).
I have no idea how or why he is allowed to do this.  Though it certainly
cuts down on `competition'.
collins at acm.org                                Scott Collins
