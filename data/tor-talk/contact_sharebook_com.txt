
@_date: 2014-12-30 03:14:33
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
Hi all. we published documentations about our big plan here
Wanna make sure everything is alright before starting implementing the
thing. Tell us your comments :)

@_date: 2014-12-30 13:23:55
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
User only establish hundreds of Tor hidden services once, when launch
the app, which cost high computational power for awhile, but when all
hidden services are connected then it doesn't cost much CPU power to
keep connections alive and there is no reason to change hidden service's
circuit in order to send new "Notifications" to Bob, Alice can send
hundreds of "Notifications" to him through same hidden service circuit.
The real problem with current hidden service setup is that it doesn't
support sending keep-alive packets with high delays to keep circuits
open which cause battery problems on mobile devices because constantly
sending keep-alive packets doesn't let the device go to sleep mode but
Tor can solve this problem and many others in their next generations. If by "Multicast" you mean send the packet to one node to send it to all
others, then you need fully trust that node for anonymization which
motivates attackers to run malicious nodes because even with small
fraction of nodes compared to whole network, they can deanonymize users.
If your "Multicast" protocol sends packets to all receivers separately,
then it doesn't make any difference with sending a TCP packet to all Tor
hidden services... As mentioned in document, we assume anonymity works. If attacker can
break Tor, i guess no other protocol can resist them to anonymize
metadata. All metadata protection protocols have some degree of trust on
distributed nodes that handle anonymization, high latency onion routing
networks provide more protection against correlating timing attacks but
it doesn't worth the trade-offs because a global adversary that watch
entire planet still can compute correlations on enter-exit points of
communications. We learned even NSA
can't break Tor in mass scales and that give us enough confidence for
the rest of attackers, too. We don't trust "PseudonymousServer" at all. We assume it's already
p0wned by hackers or legal orders, you even don't need hack them, you
just stand outside the datacenter and simply eavesdrop their network
traffic because all traffic for "PseudonymousServer" is over http We only trust the anonymity network for anonymizing user's connection to
"PseudonymousServer". [1] [2]

@_date: 2015-01-03 10:04:52
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
I think you are criticizing using Tor because it can't handle load in
mass scales. Using any other approach for anonymization have same
problem, note that only multi-hop proxies like onion routing can foil
traffic analysis, simply distributing data across p2p nodes by assuming
that there is no a central service provider to look at data in its
control panel won't protect your network's metadata. The only solution
is encouraging more volunteers to run Tor relays for increasing its
capacity rather than saying that if millions of users try use Tor they
can't. By the way keeping circuits open theoretically won't computationally
cost much CPU power for relays, only opening circuits require
asymmetrical cryptography which is the expensive part and as i said when
Alice open a circuit to Bob she won't drop it as long as middle relays
are available. I'm not worry about Tor. It would be awesome if as you said millions of
more users try use it because when they learn about Tor, they also learn
how to run a relay. Tens of millions around the world are paying to
install Anti-virus softwares on their desktop computers which massively
harm their security and freedom, running a free Tor relay is much easier
than installing an Anti-virus environment, except that it greatly
increase their security and freedom. With more relays beside more
scalability, also chance of controlling both entry and exit nodes become
harder for powerful adversaries to deanonymize origin of Tor circuits. I
think with more relays Tor team itself finds opportunities to adopt even
more security mechanisms that make it harder for attackers to correlate
patterns which increase the load on Tor network, such as adding random
size padding to traffic at relays. It's a matter of enlightening and soft power. I'm not sure what is "round robin". You can't rely on friends as a
remailer to deliver things, how is communication between friend1 with
friend2 secured to ask friend2 deliver something to friend3? If you
directly send it then ISP/government/any-other-attack-in-between can
simply discover a relation for friend1-*-friend2, if you use a multi-hop
proxy to anonymize their connection then you have to trust Tor for
protecting metadata as we do. Also friends might be unavailable (which
make it difficult decide send data to whom as you don't know which
friend is going to remain unavailable for how long) and we must
instantly deliver everything to all recipients whenever user share
something. Furthermore your plan for handing over entire data so many
times among friends seems much more complicated+expensive than simply
directly sending a few byte long packet to both Bob and Bill
synchronously (hidden service) or asynchronously (public pool) in our
case... If you are thinking about creating something like a low latency TCP
stream using members of your network to deliver packets within
reasonable time then It's not a good idea to design an anonymizer on
your own that it's vulnerabilities are not clear to the community and
nobody care about it. Tor gets so many research papers, enormous code
audit, warm attention from hackers and intelligence agencies every year
but still isn't fully deployed. We just created everything under Tor. I described circumstances to generate a new Tor circuit for a new
identity. You can load many "Blocks" using same Tor circuit but for
saving a new "Block", circuit need to change. For instance when Alice
post a new comment or message she change her Tor circuit before
uploading the "Block" but all her friends to download that "Block" won't
change their Tor circuit to "PseudonymousServer". Actually it's not essential to change the circuit before saving a new
"Block", it doesn't compromise metadata to upload a new "Block" without
establishing a new circuit. "PseudonymousServer" might learn these new
"Blocks" are created by same persons who created those other "Blocks"
but it doesn't tell anything about who created them or who is going to
retrieve them. Even correlating new "Blocks" to each other is very hard
for "PseudonymousServer" because it only sees "Blocks" coming from Tor
exit nodes and many different users use exact same exit node to save new
"Blocks" on "PseudonymousServer" which make it impractical to correlate
"Blocks" that are coming from same exit node... So, No users won't change their Tor circuit for new comments or
messages. With more relays and adding more security layers (e.g padding etc) in
the future, if Tor team overcome software bugs then there is no need to
worry about deanonymization, at least for majority of users. One of the main protections against global adversaries with controlling
both ends of circuits, is exerting very high delay for TCP packets (yet
unknown how long) that makes loading web pages very slow which disturbs
users who are waiting to view entered URLs (which even make difficulties
for relays themselves as keeping data for applying delay requires large
storage buffers...), but in our case as users don't know when a new
post/comment might appear in their timelines, it won't disturb them if
app display posts with some delay. So if later on Tor team provide a
different relay software for volunteers to launch a new parallel onion
routing network beside their current low latency network, for
applications like us that are able to endure inconvenience of delays
then we surly will look into adopting it for more protection against
global adversaries. Now Tor is not our concern, we are looking for possible mistakes in our
own software, such as crypto parts, functional bugs, key management et
cetera. If you found any problems on those sections please let us know.

@_date: 2015-01-09 00:13:11
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
i think you got it all wrong, maybe it's because English is not my
native language. let me demonstrate it by technical details
-ESTIMATING TOTAL COST-- We assume our network gets 10 million active users with 167 friend per
each user. Hidden Service (hybrid scheme): beside classical hidden services, we do
have shared secrets between Alice and Bob which after minor changes (few
lines code) on relay operators empower them create hidden service
circuits for social networking in mass scales without heat. There will
be a directory server (managed by stable parties) that every 24 hours
generate snapshots from all available onion routers (OR) sorted by row
numbers to make sure everyone around the world see same view from list
of ORs with same order. Alice knows a SharedSecret and a CommonSecret
for Bob (Bob's shared secret is unique for Alice but his common secret
is same for all his friends). In an undirected graph number of edges=(vertices)*(degree)/2 so in our
network there are <835 million connections but there aren't 835 million
onion circuits between users. Each user for handling hidden services
only have two regular circuit that for 10 million users sum of them
would become 20 million. Thus Alice only have two 3hop circuit and Bob
have two 3hop circuit, there is no overheat here compared to what Tor
users generally do for browsing websites securely by Tor browser bundle
hence I'm not going to calculate cost of maintaining these regular
circuits. The sender circuit (SC) is used for sending Notifications to
friend hidden services, the receiver circuit (RC) is used as the hidden
service itself to receive Notifications from all friends. In RC, third
hop is called rendezvous point (RP). Alice in order to send a
Notification to Bob, need find out what is his RP plus some additional
information to send him packets through RP. In hybrid hidden services there is no need for asymmetric key agreements
to establish a secure channel between SC and RC, also I dismiss
calculating cost of symmetric cryptography on packets as it's trivial
using regular block ciphers so I won't estimate CPU work required by ORs
to handle hidden services (check djb's benchmarks for aes_128 at
cr.yp.to). All informations needed to exchange Notifications securely at
RPs, is delivered from CommonSecret and SharedSecret. Bob select his RPs from directory's snapshot in time intervals between
10minutes-12hours after beginning of each day at 00:00 UTC. Time
interval is delivered from V_1=H(CommonSecret||mm/dd/year||EpochCounter)
where EpochCounter is a natural number starting from 1 to n that reset
to 1 again at 00:00 UTC in next day and row number for RP in directory's
snapshot is delivered from
V_2=H(H(CommonSecret||mm/dd/year||EpochCounter)). Bob to generate Time
interval, spin a wheel by V_1 that has 42600 slots and encode where it
stops into waiting time between 10 minutes to 12 hours. To generate row
number for each epoch's RP, he spin a wheel by V_2 that has n slots
(n=number of available ORs in directory's snapshot) and use where it
stops as RP's row number. if row number for RP is for instance 3907, Bob
connect to OR    and keep these RPs open to make sure if
Alice failed send her Notification to  then she can try other RPs. Bob start opening RPs from 00:00 UTC, wait for generated time interval
and use a higher epoch counter to determine what is next RP and how much
he should stay there again by generated time interval. Hence total
numbers of epochs is different everyday for each person. When Alice know what is Bob's RP, she don't send anything to it until
she have a new Notification for him. She sends packets as
{CircuitID|Payload}over Http from her SC without establishing a TLS
channel with RP. CircuitID= first 4 byte of
H(CommonSecret||mm/dd/year||EpochCounter||GenerateCommonID), payload is
cipher-text of {cookie|Notification} encrypted by RP_KEY which is
cookie is (cookie1)?(cookie2). Bob when open an RP, tells all different
cookies for all his 167 friends to RP (for each friend there is a
different cookie1 and cookie2 value in each epoch), cookie1= first 4
byte of
and cookie2= first 4 byte of
When Alice gives {cookie|Notification} to RP, if
(cookie)=(cookie1)?(cookie2), RP send the packet to Bob, then RP OR in
its RAM replace (cookie2) with (H(cookie2). When Alice want to send
another Notification to Bob using same RP again, for (cookie) she have
to send (cookie1)?(H(cookie2)). Next Notification need
(cookie1)?(H(H(cookie2))) as cookie and so on. Let say each packet is approximately 60 byte and Alice sends 50
Notifications to all her friends each day. Thus Alice sends 50*60*167
byte to all her friends that sending them via her 3hop SC to each
friend's 3hop RC will increase the total amount 6x time more. Therefore
Alice everyday sends 3 MB through ORs in order to deliver Notifications
for different purposes to all her friends. If 10 million users send same
amount of data to their friends, it will cost 30 TB data exchange for
onion network. PseudonymousServer: public container for hosting blocks have 100%
efficiency. If each user everyday send/receive 10 MB data
(reading/posting) to/from PseudonymousServer, the total amount of
traffic for 10 million users would be 100 TB each day that based on our
threat model has to be routed through onion network but this is linear
traffic not an exponential effect, for instance if on Twitter.com each
user approximately download/upload 10MB data from/to Twitter.com servers
everyday, for 10 million users it would require exact same amount of
traffic (100*3 TB) to be routed through the onion network if they use
Tor browser bundle to access Twitter.com --SUMMARY-- Our paradigm with 10 million users for presumed social networking
scenarios, as an extra load compared to classical hidden services for
linear applications, requires 30 TB data exchange inside onion network
which constitute ~55% capacity of 5000 volunteer onion router with 1Mbps
available bandwidth each day that is slight compared to how much
bandwidth 10 millions users need for surfing their favorite websites
using Tor browser bundle because simply refreshing a graphical magazine
like buzzfeed.com will cost more than 3 MB ... In conclusion Tor network need more relays if millions of more users who
transfer megabytes of data per day try use it. Now I did a search on your website and i'm not exactly sure what is it.
what I found seems to be an experimental mesh network. You criticized
Tor because when a global adversary monitors both entry+exit nodes in a
circuit, metadata is compromised. In a mesh network (if friends are
using each other as mesh routers) even a local adversary by monitoring
any part of network can compromise metadata for that part. Breaking
onion routing need 2 point of failure but breaking mesh network only
need 1 point of failure. If you employ high delays, padding etc for more
security, then why not apply same defense on a parallel onion network
managed by a comprehensive organization like Tor inc? In mesh networks when a node route someone else's traffic to
destination, it makes traffic analysis for an observer harder as they
can't detect it's from node itself or someone else but exact same
property imply on onion routing networks either, if user run an onion
router then it become harder for an observer detect intercepted traffic
belongs to user itself or someone else behind it. Onion routing is
already implemented, widely adopted, heavily supported and foils various
types of more traffic analysis attacks that mesh networks can't. By the way it's cool to replace ISPs with mesh networks to reduce radius
of connection between identities and make dragnet SIGINT more difficult,
for instance when I send a TCP packet from my home IP address in Iran to
a Tor entryGuard located in iceland, GCHQ really collect metadata for my
connection by intercepting Iran's optic fibers at Oman sea and probably
deanonymize my Tor circuit if they are controlling my selected Tor exit
node in Japan too. But Internet backbones are beyond application
developers scope, it's up to societies. Our assumption is that anonymity works and when users retrieve something
from PseudonymousServer via Tor, server can't recognize requests coming
outside the exit node are from whom, for instance if Alice retrieve
block1 then retrieve block2 from same exit node, we assume server can't
recognize these retrievals are from same person as many others are using
same exit node to retrieve blocks and majority of exit nodes are not
concluding with attacker in same time. This threat model isn't perfect
nor broken. If we decide not to do that, there is no alternative
solution. High latency networks might cause deanonymization harder but
if they are practical enough, I'm sure Tor network can easily add delays
by writing few lines code for those who want it and if they do that in
the future we can easily adopt it. The only other solution that makes
deanonymizing connection between Alice and Bob really hard, is using a
PIR protocol by homomorphic encryption to ask Alice put something on a
database and then Bob later on query the database to pick up her packet
without telling server what is his query or what server should in
response give to him! But problem with such a PIR protocol is that for
10 million users, service provider have to pay billions of dollars to
cloud hostings every month for computing astronomical cryptographic
functions. Another PIR protocol that don't need cryptographically
massage all records in database to guess output, is asking Alice to put
something on database and Bob later download all records from database
to locally choose which record is for him and delete the rest of
unwanted outputs. But problem with such a PIR protocol is that database
everyday become larger and larger thus users have to download more and
more data from it next days which eventually paralyze the Internet. So we are on the right track...

@_date: 2015-01-11 23:39:55
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
I just proved that Notifications are affordable in mass scales. if you
think i missed something then show details
On website I didn't talk about details of hidden services themselves,
even Tor team admit that hidden services need more care. "Hybrid" hidden services doesn't exist yet and it's design isn't
suitable for serving something like an HTML website but follows same
concept, it let Bob introduce himself to Alice without revealing his
location and hides their connection from outsiders, which will work
great for social networking applications. In Tor hidden services today,
beside a lots of other things that Alice have to do before telling the
rendezvous point to Bob, the connection between Alice's circuit with
Bob's circuit at rendezvous point require establishing a TLS session,
but as I said in hybrid hidden services there is no need to establish a
TLS session between Alice's SC third hop and Bob's RP because they
already have keys for each other, and also there is no need to use a
different SC to send something to Bill's RP, whenever Alice have a
notification for Bob, she ping his RP and if Bob is there then send the
packet that is encrypted by RP_KEY directly to it as a TCP packet. Of
course Bob before that tells everything to RP and make it ready to
accept her packet. if someday Tor developers really implement hybrid
circuits, it would become a little bit more complicated than I
suggested, I just tried clarify it in a simplistic way to let you
understand that nothing go through a central could service to provide
hidden services ? just one regular circuit serve hundreds of hidden
services at same RP. My English is bad. But not that bad. No! Alice have a regular circuit that I called it SC, its third hope can
send TCP packets to hundreds of RPs in less than a few milliseconds.
When Alice knows what is Bob's RP, she don't do anything with it, it's a
local knowledge, she only touch RPs whenever she want send a
notification to them and when she wanna do that, first do a trivial TCP
handshake with each RP which almost add nothing to size of 60 byte
Notification itself that i estimated for you in previous email. So there
is not 167 circuits at Alice side, even when she send something still
she won't establish 167 circuits with friends. I explained it very
clearly I answer apples but you read them as cucumbers. I demonstrated that
Alice won't maintain 167 circuits by one Hybrid hidden service but you
say "nothing of this explain how you avoid maintaining 167 circuits just
for Alice". Alice efficiently deliver Notifications to her 167 friends (It doesn't
make any problem for anyone, neither friends nor Tor relays) and
Notification is not one message, each Notification for each friend is
completely different (i guess you are misthinking that 60 byte
Notification that Alice want send to 167 friend is same data so she
should multicast it? first: even if it was same data she still could
easily handle it without multicasting because 60 byte is very small.
second: to reach forward security, each Notification is encrypted by
each friend's forward secure symmetric key thus each of 167
Notifications that Alice want send to her 167 friends is completely
different from each others...)
There is no need to optimize Tor protocol, relay operators are using a
client software that is programmed by Tor, a little bit change on that
allow us talk with relays (send packets) as described. It doesn't
break/change anything on Tor specs or current Tor hidden services. And
we don't need distribution trees in here. RP is Bob's receiver (which listens to all friends not just Alice),
Alice have a circuit that i named it SC, its third hope (which don't
have an acronym yet) is in charge of distributing packets to all friends
RPs ...
i think there is no way to make it more sufficient if metadata secrecy
is requirement
don't forget that our priority is security not scalability
yap nothing to do with scalability but it wasn't a ratchet. As I said
Alice sends packets to RP without establishing a TLS session so an
observer in the way before RP can simply measure the "cookie" value and
use it to flood Bob with junk packets. What I explained was an one-time
cookie that can't be used twice to send something to RP.
If debate is about scalability then we are only talking about costs that
are categorized as 1-bandwidth 2-computation 3-storage. We can't talk
about latency or topology for scalability here because if they spend
something then it shows itself on our bandwidth costs. When data
transfer is the case we should ask how much bandwidth it cost for
routers? when data processing is the case we should ask how much CPU
work it cost for operators? when data storing is the case we should ask
how much space it cost for databases? I'm sure you agree that CPU cycles and storage disks are out of debate,
the question is cost of network communications. First of all even in a
complete different topology we still need send 167 different
Notification because of forward secrecy that force Alice encrypt her
Post/comment keys by each friend's forward secure key then encapsulate
them in a Notification (which means Notifications won't be semantically
same hence there is no way to multicast them). This means if we use a
Bittorrent like mechanism, we still have to deliver 10KB data for each
new post that is shared with all her 167 friends in our paradigm. I
don't see much advantage on delivering that 10 KB using Bittorrent, also
I don't see any serious drawback for sending that 10 KB data through Tor
either because doing it only increase the bandwidth cost 3x time more as
same data has to pass through 3 different onion proxy so the total cost
for uploading that data becomes 30 KB which is absolutely fine. For notifications as I said we can theoretically serve even millions of
users by a few thousands Tor relay so there is no need to change it and
changing it will become truly challenging to make it secure as it is
today by aid of hidden services. Yes for PseudonymousServer we can apply any cloud/broadcast technology
that we desire Sorry for that I didn't looked into your website carefully. in my opinion our own project is the most robust approach so far which
really aims at making a secure and practical social network. I remember
several other approach that catastrophically failed to do that. One of
them labeled as "Diaspora" (with distributed-ish mentality) got a lots
of attention but eventually its developers designed it fundamentally
insecure and impractical. there is no need for tree distribution
The only centralized part is PseudonymousServer that hosts cipher-texts
for photos etc and we love to decentralize it but problem is that in
reality it can't happen, for a large user base we need host new
gigabytes of data every day that is hard to supply it by volunteers,
also stability is another big problem when volunteers might just
disappear and users don't like to see their family photos are gone.
Solving stability problem require storing several copy from same data on
hundreds of volunteer peers who are unable to keep even 1 copy from same
data I believe if a secure high latency onion network in the future break the
news then we can easily migrate to it without breaking anything in
application or user base. So there is no need to think about anonymizers
today maybe but don't think about distribution trees for TVs. [1]

@_date: 2015-01-13 21:48:21
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
Yes. i'm glad to hear that you started getting the point.
It is possible to use pubsub between Alice's SC's third hop and Bob's RP
but it doesn't improve anything for our application because your pubsub
is a topological multicast mechanism over application layer but what
Alice want send to her 167 friends from SC's third hop is 167 completely
different packet. Multicast is for when she want send same packet to 167
recipient thus pubsub at Alice's SC's third hop doesn't make bandwidth
cost of sending Notifications cheaper. My estimation was accurate but if tens of millions users supposed to
really install our application then we need more Tor relays because
exchanging 10 MB data with PseudonymousServer by millions of users cost
a lot, Today Tor have thousands of relays but they are all busy to
handle other things, there is no much space left for us. Most of people out there think Tor is only for escaping from
totalitarians or buying drugs, they call websites behind hidden services
"Darkweb" that sounds very macabre. Tor team should expand its coverage
on legitimate applications for ordinary users who are not doing anything
wrong or escaping from someone. The only upgrade that really helps is
getting more Tor relays. I don't understand why they don't do PR like
most of other companies. Incentive systems like Torcoin can be a good
start. Sending cipher-text of "Blocks" via hidden services? I think it would
cost much more for Tor network because hidden service have 6 hop while
downloading cipher-text from PseudonymousServer is done through 3 hop
and also friends hidden service might be offline (when friends are
offline we send Notifications to public pool and whenever they become
online they grab the Notification from pool and download corresponding
Block from PseudonymousServer) but it is possible to optionally send the
cipher-text of post directly to each friend who is online through hidden
service but still user should upload the Block on PseudonymousServer in
order to be able retrieve it in future times because user at client side
have limited storage which means might delete things from local cache or
accidentally lose data on its storage which requires retrieving
cipher-text again from PseudonymousServer. I don't see any security
improvement on doing this because when we download something from server
we trust Tor (if attacker can't deanonymize Tor, server only can observe
numbers of retrievals that is useless when all users approximately have
between 100-250 friends thus each block shows averagely 100-250
retrieval, there is no correlation between blocks), for sending data
through hidden services we still need trust Tor so doing that just
increase the complexity for no reason. I don't see any bandwidth consuming problem when Paul says "i agree" as
a comment then encrypt it and upload cipher-text as a block on
PseudonymousServer then send a Notification to Alice then Alice forward
same Notification to all her 167 friends because it cost same amount of
bandwidth for transferring Notifications and same amount of bandwidth
for downloading the block 167 times from PseudonymousServer. Sending the
cipher-text block through hidden services will cost much more than
downloading it from PseudonymousServer because when users download a
block from it they are behind 3 hop but when Alice send something to
friends hidden services, there is 6 hop in between. I think it's better spell the question of choice of trade-off like this:
do we want forward secrecy for sending each Notification to each friend
when we only use Mceliece cryptosystem for asymmetrical encryption? or
do we want forget about group PQ forward secrecy by encrypting the
Notification using a common secret (or using Attribute-Based Encryption)
that is same for all friends to be able multicast the cipher-text value
which will be same for all friends? The answer is very clear when
security is priority and sending 167 Notification in size of 60 byte is
very affordable. If we decide switch to another strategy, it will be
easy by telling a common secret to all friends using a "Notification"
that a specific "Mark" at its beginning declare what is going on (if
desired "Mark" is not defined in application yet, we can ask users to
update application with a new version that understands the "Mark"), but
we won't change our strategy. I don't understand why you involved block storage cloud in the question?
it have 100% efficiency and have nothing to do with cryptography. To establish a PQ forward secure key between Alice and Bob, Bob sends a
Mceliece public key (that is 200 KB in size!) to Alice and she use it to
encrypts a random symmetric value then send cipher-text to Bob then he
removes his temporary Mceliece private key. That symmetric value is a
forward secure key. What Alice have for Bob as forward secure key, is
different with what she have for Bill. If you say there will be a
channel between Alice with her friends, the only thing we can do is to
ask Alice send one small Notification to all 167 friends that declares a
symmetric key for encrypting that channel (let say channel is a time
epoch like 6 hours period) so when Alice want send more notification to
her friends through same channel, she will encrypt them by channel's key
and generate same cipher-text for all friends that can be multicasted.
But the real problem is that multicasting is not metadata friendly. in pubsub, constant connections even between pseudonyms might reveal
some parts of social graph, what I proposed as Hybrid hidden service is
discontinuous and packets traveling from SC's third hope to RPs don't
look relevant to each other, there is no way to draw a social graph
between one sender and several RPs because when an OR sends 167 packet
to 167 RP, an observer in between can't separate these packets are from
same person who sent them to all those RPs, or 167 different person at
that OR sent those packets to RPs in a linear paradigm as each packet
looks random without any connection information. everything changes when
there is a constant identical connection between SC's third hope and 167
RP that makes entire relations between pseudonyms visible to an
observers between them without hacking ORs. it's not feasible to protect metadata secrecy on multicasting because
you fundamentally can't send a random packet to each recipient and when
you multicast same value then you enter one-to-many pseudonyms paradigm
which means some social graphs between pseudonymous vertices become
visible to observers in that zone (search social network
de-anonymization papers for more info). I think pubsub is a useful tool for a liberal network when everything is
centralized but it's not enough for a secure network when Goliaths are
snooping on everything. Blocks don't have trade-off on bandwidth. Bandwidth trade-off is for
Notifications. We can use twitter's distribution strategy on PseudonymousServer, you
can consider blocks as tweets, how twitter sends a plaintext tweet to
167 different person from different IP addresses who ask it? I guess we
can use same method to deliver blocks to 167 different person who
request it. And in our app we limit numbers of friends to ~250 friends, if someone
shares something to millions then probably it's not private. There might be a lots of volunteers who are willing to donate their
storage for incentives but they are finite not infinite, someday we
finally get ride of them as numbers of blocks rapidly grow without stop
and we should keep all blocks forever. Just search about how much data
people post on social media everyday. They are gone because the hard disk itself that kept a copy is gone
(pirated movies overflow, memory failures, volunteers running away,
cryptolockers etc)

@_date: 2015-01-15 22:04:02
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
oh I meant we won't use multicasting above hidden services so thats why
it become very expensive. If we do so then yes it become as efficient as
using PseudonymousServer what is TOR2WEB doing in your replay? that's something completely
different which have nothing to do with PseudonymousServer
Awesome slogan. Criticizing cloud storage in the case of a cryptanalysis breakthrough is
unrealistic. attackers wiretap communications and pickup cipher-texts in
transit not just from servers. They can easily detect cipher-texts (e.g
PGP encrypted emails) from plain-texts to store them forever so assuming
that we didn't stored cipher-text on a server won't help anyone if
attackers break ciphers themselves. it's not Utah-like. We can get donations if people really use the
application in mass scales (think of wikipedia)
i didn't say distribution optimization is impossible, i said we already
have distribution optimization on PseudonymousServer itself so what you
wanna optimize then?
i answered these above, i thought we don't have multicasting over hidden
why do you think our one-to-many pseudonyms graph would be different
from Flickr? pubsub attach some metadata to pseudonymous vertices that
can be used for analyzing them anonymity is a different topic. i'm talking about compromising social
graphs. for instance in netflix attack vertices are already anonymous
but attackers try match some data from IMDB that gave real identities
for patterns to deanonymize similar patterns on anonymized netflix
dataset and they really did!
i guess you searched "social network anonymity" in scholar and just sent
me the results. but those papers are not protections against link
prediction algorithms that attackers use for deanonymizing social
graphs. they talk about cucumbers not apples.
If "disadvantage" means a deanonymization attack that breaks our threat
model (attacker can't break Tor, majority of exit nodes aren't
concluding with attacker) then explain it, but if "disadvantage" is
depending on a feudal vendor rather than having fun with a liberal
distributed network, then we try overthrow any feudal part as soon as
possible but it's very hard to do that when we can't find a distributed
alternative. First; as I said in our threat model we assume majority of ORs aren't
concluding with attacker in same time and we assume anonymity works
(attacker can't deanonymize Tor). Second; an observer can see Alice's third hope sends packet to what RPs.
But attacker can't determine these 167 packet that third hop OR sends to
167 RP, is from Alice to her 167 friends or 167 different person at that
OR send one packet to one of their friends at each RP which in this
scenario it becomes connection between pseudonyms in a linear paradigm.
But what pubsub as far as I understand (maybe I got it wrong) do a
subscription between root sender and leaf receivers which reveals the
connection to an observer in between when root multicast a packet to
leaves subscribers. First question is how much bandwidth in numbers a high latency
packet-oriented multicast saves compared to asking Alice instantly
unicast the packets? Second question is if the multicaster sends same packets to recipients
then how is that possible to tell an observer that don't draw edges
between anonymous vertices? Even 1 hour delay doesn't change packets
semantically, while in unicasting random packets the observer can't draw
edges between root vertex and recipient vertices. I agree that in real world scenarios multicasting is not that bad but
it's better choose stronger theories when we have the opportunity,
despite the fact that nobody attacks those weak parts which we scared
from. I propose we use the pubsub multicast strategy as a backing plan
when we get ride of available bandwidth in Tor network, to switch
unicasting Notifications into multicasting one Notification that is
encrypted by an epoch forward secure key for all friends. How much excessive MB/GB/TB it would be in your estimation when we
download block from server?? it is not doomed if someone pay Amazon's bills but it will be flooded
with blocks and there is no alternative solution for keeping those
blocks on somewhere else as p2p networks are only good on distributing
data not keeping the data itself for long terms with 100% reliability. I love to get ride of PseudonymousServer because i'm the one who is
responsible for paying off Amazon bills but even if we do multicasting
above hidden services then we still need it for "future retrievals" when
requesters can't find a seeder for desired block on Bittorrent network
in the future and for "asynchronous retrievals" when Bob's hidden
service is offline and when he becomes online gets Notification from
public pool to retrieve the block but Alice is offline at that time.
Also we need PseudonymousServer for backuping PDB and many different
things. People are unpredictable and unreliable which lead save several copy
from same data somewhere to make sure if one copies disappeared then we
have it somewhere else. we need a lot more space for a distributed
reliable storage than we need on cloud with daily backups. If keeping
blocks on an efficient+reliable cloud is doomed, keeping them by unknown
volunteers is foredoomed. They systematically won't! you are a good man but most of others out
there aren't like you. just think of those zombies who sued apple
because of asking them free some space for installing an important
update. people really want when they replace their smartphone, simply by
entering a username and password recover everything back. This is not
subterfuge, it's substantial. Usability is a security parameter because
if majority of users don't use our secure software then attackers easily
compromise them. We are a mobile application (for various important reasons) and mobile
phones have a few GB free space which is very valuable, we only can
cache texture contents for a long time, cached media contents will be
removed after a short period of time. Without backing up blocks on a
server, for sure they will lose them during time.

@_date: 2015-01-17 20:42:44
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
If attackers break ciphers one decade later then Tor's forward secrecy
is compromised even for any collected forward secure operation today. Our goal is common so it doesn't matter I join you or you join us, the
outcome belongs to people like any other free software :) This incident is similar to that Flickr paper that you already saw.
Attackers poll out
real identities from another source (e.g IMDB) then try
correlate their patterns with side-channels of pseudonyms to deanonymize
I thought you said each vertex get same thing, if they get different
things then it's
I think you are talking about pressure not bandwidth because 167 friend
download same amount of data from server if they try download it from
Bittorent either, and we don't care about pressure on server.
So you say that at first glance each pubsub node keep all blocks for all
other friendly pubsub nodes then furthermore we save the block on an
Bittorrent network? In my opinion even friends are unreliable however
better than strangers.
not all but most of the expensive part is that

@_date: 2015-01-17 20:49:18
@_author: contact@sharebook.com 
@_subject: [tor-talk] Cryptographic social networking project 
No I don't have such a misleading thought because Diaspora is a
webscript and their strategy is asking users to run their own webservers
for distributing the webservice! That distribution have nothing to do
with secrecy nor scalability, they are just wrong. Those who designed
Diaspora didn't have any clue about security engineering or any other
type of engineering. Their prospects isn't even close to our current
design goals.
