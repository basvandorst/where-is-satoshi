
@_date: 2013-11-20 07:26:04
@_author: Paul Syverson 
@_subject: [tor-talk] Social scientific research on Tor and similar 
I'm all for more research in this space, but why create a separate
database, especially if there are currently few paper? Couldn't you
contribute these to anonbib? Probably you want to create a new topic
label for them.

@_date: 2013-11-25 22:02:37
@_author: Paul Syverson 
@_subject: [tor-talk] Regarding #8244; 
Topposting cause I'm tired and lazy. Sorry.
So I designed exactly this type of thing
c. fifteen years ago. Cf. "Weakly Secret Bit Commitment: Applications to Lotteries and Fair Exchange"
and a journal version of some of that in
"Temporarily Hidden Bit Commitment and Lottery Applications"
Also, Roger and I described an application of the basic idea to
mix routes in 2002  in which we introduced the idea of suicide defense
to protect the network that Tyler Moore would later invent independently
and get all the credit for
"Reliable MIX Cascade Networks through Reputation"
You can find all of these on my homepage

@_date: 2013-10-17 06:56:41
@_author: Paul Syverson 
@_subject: [tor-talk] New paper : Users Get Routed: Traffic Correlation	on 
Actually the work we did on this paper was as part of a larger program
that has been our primary focus for the last several years: how can
you secure communication over Tor against an adversary that can, e.g.,
own 30% of the nodes (or big chunk of guard and exit bandwidth) or
large parts of the AS or other underlying network infrastructure.  Our candidate is to leverage trust diversity in different parts of the
network (e.g. trust based on who is running nodes on what hardware and
what OS from what physical and network location, etc.) But this is
tricky. One can't just use the most trusted parts of the network
because this will probably indicate that this is statistically more
likely to be communication from/to people that trust this part of the
network. You need to get away from the idea of a single set of trust
values for all users for the whole network.  Different kinds of people
will have different adversaries, which is just one factor to the
diversity of trust. We've already got a few publications on this "More
Anonymous Onion Routing Through Trust" by myself and Aaron Johnson and
"Trust-based Anonymous Communication: Adversary Models and Routing
Algorithms" by the two of us, plus Roger Dingledine and Nick
Mathewson. You can find both on my homepage (syverson.org)
The current paper under discussion came from the realization that we
needed to have a much better handle on network models, tools and
appropriate adversary models for the existing Tor network and usage in
order to properly incorporate trust into routing for improved future
design.

@_date: 2013-09-13 14:42:41
@_author: Paul Syverson 
@_subject: [tor-talk] Tor and Financial Transparency 
I said nothing about being clueful in technical matters. I said that
if you make clueful constructive criticisms you are typically likely
to be in a position to make clueful constructive suggestions about the
design. Many contributors to Tor, paid or otherwise, do so outside of
the science and technology per se. If your focus is on political
aspects that is where you could contribute, but I have yet to see more
on that front from you than ad hominem attacks.
(Note also that you straightjacket and oversimplify Tor by limiting it
purely to a political dimension, but if that is your hammer, and you
are not simply trolling please use it as a tool of more than
destruction when hitting the Tor nail. I will not engage in political
debate, so I will have to leave that to others. Please also make sure
that political or otherwise, your comments remain constructive and
relevant to Tor.)
Something is not a flaw in a system if it is overtly stated to be
beyond the the scope of the system. We've said since before Tor that
onion routing by itself does not prevent an adversary able to watch
both ends of a connection from determining who is talking to whom. So
you cannot validly claim this is a flaw of Tor. You can note this as
a limitation on what it currently offers.  But that is already
frequently stated, so one must say more than that to make a
contribution.  Also, I have already pointed you at research by myself
and others on the hard problems of quantifying the extent of this
limitation and on designing to go beyond it.
I'm not going to address the moral/political claims you make since
that is outside my current bailiwick. I will simply take them as
premises of your argument without commenting on their soundness.  I
will however note that this criticism is not valid regardless of how
sound the premises may be. It commits a variant on a classic
fallacy. As I used to teach my introductory logic students, if you
reject an argument because it is given by someone evil (in your
opinion) without addressing the merits of the argument itself, you
commit an ad hominem fallacy. Nate Freitas and others have given you
lots of reasons that the work behind Tor (research, design, funding,
code) is _by design_ set up for (and thus receives) as much scrutiny
and verification as pretty much anything out there---and mostly
more so than anything else out there. And, on a meta level, there is
public discussion of the current limits and attempts to improve that,
e.g., open hardware and deterministic builds. And since you are so
focused on funding, there is also public discussion of how the Tor
Project Inc. attempts to diversify its funding. If you can offer more
than ad hominem reasons why this approach is flawed by design, I
believe the opportunity to see how to improve Tor would be welcome.

@_date: 2013-09-14 09:12:39
@_author: Paul Syverson 
@_subject: [tor-talk] Tor and Financial Transparency 
Last try, as I've already spent more cycles on this
than I generally have for such.
I describe it in the last message, and spell it out in more detail
Irrelevant to this exchange. I already noted to you before
that I didn't say any of those things. I don't understand why
you persist in bringing them up. Again. I never said those things.
I have yet to see other than an ad hominem argument in your
statements, Roughly, A. Entity x is evil. B. Entity x funded the building of y. C. If A and B are true, there can be no adequate answer
   to "Why should we trust y?"*
D. Therefore, we cannot trust y.
*No matter how much more open the funding, design, and coding are than
anything providing similar functionality and no matter how much more
public, independent, scientific, widespread, repeated analysis y is
subject to than anything else out there.
If you want to engage in discourse and use reasoning outside the
bounds of valid argument as recognized by the group you are talking
to, and when the distinction is pointed out to you and you are asked
to explain, you simply reiterate your position without making any
attempt to explain why those you are talking to should abandon there
criteria and adopt yours, then you will be (correctly) perceived as
trolling. I was trying to suggest a way for you to avold trolling,
unless that was your goal. Ermm. I pointed you at our paper, the first paper attempting to
quantify that in a meaningful way using the best available data.
And, as I recall you thanked me for it.
And yes, this is a hard problem. Science and technology are lousy with
hard problems, and this is one of them. The work in the paper I just
mentioned trying to address it builds on the work of lots of people
from many countires with many diverse sourecs of funding over a decade
or so, without which it couldn't give anything close to the start
of an answer it provides.
Setting aside the huge implicit composition and division assumptions
you are making, myself and others in this thread have already explained
that we feel our time is better spent designing a process and then working in a way that is fault tolerant against such concerns.
Those are merely hard problems rather than intractible ones, but feel
free to look at whatever you like. I hope I'm not being too presumptuous
in saying that you already have as much of an answer as those who
work on Tor can give you about that.
Well no not exactly. I was being a bit terse with "set up for", but
I've already been overlong in so many respects. As Roger has already
explained somewhere (I forget sorry) quite well: It's not enough to
have open design.  You need to have good documentation of the code and
of the design
(cf. ) so others can understand what you are doing, build there own, etc.
You need to make data available so that people can easily do strong
and repeatable analysis not just of the design but of the deployment
and usage (cf.  ) You need to spend a
lot of time doing your own research
(cf.  as well as
collaborating with others and also running around to research groups
around the world who might have lots strong expertise but not a grasp
of the hard problems and why they matter. If you don't they probably
won't try to solve nearly as many of your problems; they'll solve
other problems or misconstrue yours. Roger was probably the main
person doing that for a long time, but in an effort to not have him
explode it is now a separate job, handled this year by Nick Hopper on
sabbatical from the Univeristy of Minnesota. This is a partial list
(this message is already too long) of how Tor is designed and operates
to receive lots of scrutiny rather than just being available for

@_date: 2013-09-15 01:35:43
@_author: Paul Syverson 
@_subject: [tor-talk] Tor and Financial Transparency 
Back in the ancient pre-Tor days, at the height of the crypto wars, Ian
Goldberg asked me at Financial Crypto in 1998 why we created onion
routing. Not entirely facetiously I told him that the fascinating
technological problems and the pontential to better protect people and
their activities was nice, but the real attraction was to create a
context where people who were sure they should hate each other were
forced to collaborate.

@_date: 2013-09-17 11:31:04
@_author: Paul Syverson 
@_subject: [tor-talk] Tor and Financial Transparency 
People have not yet done that work for hidden services.  Not because
they are uninterested but because there is so much to do and only so
much time to do it in. Actually the existence of guard nodes, whose
configuration plays such a large role in those results, itself came
about because of research the Lasse Overlier and I did on finding
hidden services, (published 2006 I think). But the solution of using
guards is itself a version of something described in earlier work by
Wright et al. in c. 2002, when they introduced "helper nodes" as
something to address the more general issue for lots of different
anonymity designs, not just Tor, which did not even have a published
design yet. For recent advances in attacks on hidden services cf.
"Trawling for Tor Hidden Services: Detection, Measurement,
Deanonymization" by Biryukov et al. Many of the issues have since been
address or are the subject of design changes that are being discussed
for Tor now. See the relevant trac tickets and Tor proposals.
I hope the above paragraph shows you that these things take a lot
of time. If you wanted those things all done before Tor was deployed,
Tor would never have been deployed. Lots of the research depends on
analyzing deployment and usage patterns on the real network. I think
Tor and its analysis actually stands out as a huge success story
for how much has been accomplished by how many people with how much
funding. People involved with inventing, engineering and, deploying
other significant systems are often astonished that it is not a much
bigger operation with orders of magnitude more funding. The paper
we've been talking about could not have been done in 2002, not just
because there was no widely used and deployed Tor network to get
data about, but because techniques and data for network measurement
(general Internet not just Tor-network) were not as advanced or
available. What is technically possible and with what resources changes all the
time. And as I have said, there's lots of work that needs to be done
to say things that are meaningful, not just aphoristic about this.
That's why knowledgeable people will always reject except as deceptive
shorthand simple statements about whether _anything_ is safe, secure,
anonymous, unable to be monitored, etc.  They will attempt to turn these
into questions about a particular class of adversary (amount of
resources, dynamics of resource deployment, nature and target of
attack) attacking a particular class of users engaging in a particular
class of behavior, on a particular class and configuration of network.
With perhaps minor tweaking, this is as true of someone examining
the security of a class of crypto algorithms as of someone examining
intrusion resilience of an enterprise network.
This points at a different kind of hard problem. People working on Tor
have tried to be clear all along about what it does and what it does
not do, and be clear about how much is unknown subject to long
scientific analysis. Tor has long been a model of openness that others
point to for how to do it. But how and where to be clear is tricky.
For example, for many years, the software used to say when firing up
something like "This is experimental software. Do not rely on it for
strong anonymity." At the same time however, other systems purported
to offer similar protections would be marketed as offering rock solid
protection or some such. People who, e.g., have lives that don't allow
them to spend time reading and learning to understand research papers
about the all the different technologies that they need to use every
day, would understandably think that something called "rock solid" is
better than something that is labeled by its own producer "for
experimental use only", even if the latter is actually way more secure
for their needs than the former. So in this context, it is deceptive
and can put people at risk to call Tor experimental in the terse blurb
that is all many users will see. So what's the most honest thing to do
here? What you see is the current best attempt to cope with that. But like everything else, this is recognized as not settled once and
for all and needs revisiting as time, resources, and which thing is
most urgent permits.

@_date: 2014-12-14 23:28:02
@_author: Paul Syverson 
@_subject: [tor-talk] Tor and solidarity against online harassment 
No Tor is not a Chaum-style network. It is an onion routing network not a mix
network (See "Why I'm not an Entropist" And in particular, it is not as secure as the security provided it its strongest,
most honest node in a circuit. End-to-end correlation works just fine even if
everything betweent eh entry and exit relasys is honest and well performing.
(See "Users Get Routed: Traffic Correlation on Tor by Realistic Adversaries"
The last comment of the paragraph is correct however.

@_date: 2014-12-15 06:36:38
@_author: Paul Syverson 
@_subject: [tor-talk] Tor and solidarity against online harassment 
I was contrasting with Chaum mixes for which this can be approximatetly true
(ignoring trickle and flood attacks, ignoring the tiny anonymity set that
arises in practice, ignoring path length attacks for free-route mixnets such
as the mixmaster/mixminion networks were...)
I doubt it's "fixable" in the sense of being able to simply remove any
advantage to an adversary that can completely observe (and possibly
alter) both the guard and exit ends of the circuit. More optimistically
I think there are things to be done to reduce the probability for most users
that any realistic adversary is in both locations and to increase the
workload of an adversary who is in both locations. Always more interesting
work to do. ;>)
Sorry, no. May I never be that self-serving. "That is very clever."
was simply the last few words in the paragraph. Responding inline is a
trade-off of trying not to alter the meaning of the interlocutor while
saving the reader as much as possible. And I was overly terse: It is
true that having malicious relays that cannot be behaviorally
distinguished from honest relays is an advantage for many classes of
attack. It is also true that having an adversary at both ends (if it
is not the same adversary, and if the two do not collude) is much
better than having a single adversary able to watch/attack both ends.

@_date: 2014-02-07 06:20:05
@_author: Paul Syverson 
@_subject: [tor-talk] Pissed off about Blacklists, and what to do? 
Well even if this pushes us over the Godwin threshold, I still think
it's worth trying to control the spread of such fallacious reasoning.
1. Trolling is a red herring for the incident that prompted this
discussion since Josh was trying to watch video not post anything.
Even if sites _do_ want to allow anonymous access while minimizing
abuse (generally for writing rather than obtaining data) there are
blacklistable anonymous credential techniques and structured incentive
techniques that can be used.
2. Claims of significantly disproportionate abuse via Tor are not
infrequent. But what is infrequent to the point of nonexistence in my
experience is anything to back that up. Most often the claim is based
on the salience of abuse rather than any actually plausible
statistics. Connections exiting the Tor network are easily
recognizable as such via IP address. This makes perception of abuse
subject to at least two potential base-rate fallacies that must be
discharged if a claim is to be given any credence.
First one must be sure that the rate of recognized abuse from Tor is
actually higher than recognized abuse from other sources rather than
just disproportianately categorizable since it effectively wears a
category on its sleave.
Second, one must be sure that the rate at which abuse is recognized as
abuse in general is not significantly affected by whether it arrives
via Tor. (If you find way more coins on the ground where the light is
better, it doesn't mean that there are actually more coins on the
ground there rather than elsewhere.)
If you make claims without considering the above, you are just making
stuff up and fooling yourself that you have evidence for it.

@_date: 2014-02-24 13:40:06
@_author: Paul Syverson 
@_subject: [tor-talk] Why so many bugfixes? 
This was a major community/social event, the Winter Tor Developers Meeting,
_Not_ some major breach event or similar, just in case anyone was wondering.

@_date: 2014-01-08 12:23:24
@_author: Paul Syverson 
@_subject: [tor-talk] !!! Important please read. !!! 
Right. There's over a decade of research showing that nobody beats
longterm intersection given a targeted attack by a well-resourced
adversary. (And anything practical for Tor does not even need to be
longterm.) Cf. freehaven.net/anonbib/ and since it's not there also my
"Why I'm not an Entropist?" against any notion that one can "eliminate
the global view".  This is a lesson that has been re-taught at least
since I was asked in 1997 why we were creating onion routing instead
of building pipenet. There are interesting things one can do to
improve against some practical adversaries. As always devil's in the
I think you meant "And How!" ;>)
Tor may be the best thing available, but it still has lots of places
where work is needed.
Cf. I think the latest word on where things stand is probably our
"Users Get Routed: Traffic Correlation on Tor by Realistic Adversaries",
which is on anonbib. An overlapping group of people is now at work
on how to leverage trust to improve things given those results.
And changing Tor's guard parameters is in the works given the above and other research results (especially "Changing of the
Guards: A Framework for Understanding and Improving Entry Guard
Selection in Tor").
Personally, I'm concerned that some of those planned changes should be
put on hold because they will be positive in some respects but a net
negative overall. But we need to do the research to back up or
disprove my concerns, which I can't spend any cycles on for at least a
few months since we're now focused elsewhere---such as on how
specifically to improve things using trust in the face of the
User's-Get-Routed results.

@_date: 2014-07-01 14:36:08
@_author: Paul Syverson 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
As with most of this discussion, many of your statements have been
vague and provocative.  Not sure which of the three, or possibly for
things asserted above are the "it" that you don't see anyone
denying. I'll take yet another stab.
Yes Tor is vulnerable (for some but not all appropriate understandings
of "vulnerable") to global observers (for some but not all appropriate
understandings of "global"). This has been a documented and analyzed
aspect to onion routing since before we designed
Tor. Cf. e.g. "Towards an Analysis of Onion Routing Security" from
2000. As to the extent and nature of global observers that Tor is and
is not vulnerable to cf. e.g. "Users Get Routed: Traffic Correlation
on Tor by Realistic Adversaries" 2013. Nobody's denying it because
everyone has been stating over and over to you the quantified specific
ways in which it is true and ways in which it is not. There's plenty
more work to be done in this space, and I hope others will make
helpful contributions to it.
You have elsewhere in this thread noted that resistance to traffic
confirmation is not rocket science. I would agree that it's not merely
rocket science; it's much harder. (OK that's probably not fair to
rocket science, but there is no indication that it's any easier
despite your repeated unsubstantiated allegations to the contrary.)
People have already alluded to DISSENT, which is a great approach and
accomplishment that makes things stronger in some ways but weaker in
others.  Another attempt to improve resistance to traffic confirmation
including active attackers is described in "Preventing Active Timing
Attacks in Low-Latency Anonymous Communication" 2010.
People have denied over and over your allegations that Tor was somehow
designed to be intentionally vulnerable in some way. They have already
cited various aspects to the openness of the design, the extensive
scientific scrutiny to which it has been subject, etc. as evidence of
this. It's hard to imagine what would satisfy you at this point but
perhaps this will help: I designed Tor with Roger and Nick. At all
times we designed it to be as secure as we could given usability,
performance, and other practicality goals (which are themselves
security goals we considered, as has also been widely documented). At
no point did we intentionally do anything to make the design less
secure than we could think how to do while still making it as usable
and practical as possible. Nor did anyone ask any of us to do so, as
far as I know. My opinion (subject to reasoned _scientific_ debate)
about why the Tor design is more secure for practical attacks than
those designed to be putatively more secure against a widescale
attacker (such as those mentioned above) is sketched in "Why I'm not
an entropist" 2009. That paper could use some updating and expansion,
but the basic points hold up I believe.
People have day jobs trying to design, build, and analyze systems to
protect people. I often take way longer than that to respond to
substantive well-reasoned questions, as do many people with jobs
and/or lives. Such people also typically expect response times
proportional to the importance, urgency, and reasonableness of the
questions. To such people I say please do not infer too much to the
fact that I have responded to all this in a mere 6 days.

@_date: 2014-07-01 16:00:59
@_author: Paul Syverson 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
So you keep saying. Everybody who has worked on this who has responded
has said that they don't know how and that they find this a hard
problem. But your response is simply to keep repeating that it is
trivial to eliminate without telling us how.
Lots of smart people have thought about hidden service design. E.g.,
Karsten did his dissertation on it and earlier guard nodes were
introduced to Tor based on Lasse and my illustration of how easy
attacks were on hidden services without guards. Our original design of
hidden services in Tor harks back to notions of rendezvous services in
earlier NRL onion routing work and earlier work by Ian Goldberg, I
think in _his_ dissertation if memory serves.  That HS design
languished at times while other aspects of Tor were more urgently
worked on and that they could use more attention has been
acknowledged, and it is getting some. It could use still more and will
hopefully be getting it soon.
You may be way smarter than all of these people, but so smart that we
can't infer how your simple solution works from these two sentence
descriptions. As a kneejerk thought based on just even this brief
description: a malicious active client is a trivial adversary to
create. It can induce whatever signature it wants on its flow to the
HS and can actively affect flows from the HS. What keeps the Tor relay
adjacent to the HS or the ISP at the HS or between it and the adjacent
relay from recognizing timing signals from malicious clients?
For that matter, I don't understand why the system you mention would
not be vulnerable to the attack you mention to motivate it.
Please illustrate how. Please give a design sketch with at least
enough details and at a simple enough level of description that even
the world's top hidden service design and analysis researchers can
understand it since they keep telling you they don't understand these
trivial fixes you keep mentioning.

@_date: 2014-07-01 16:26:04
@_author: Paul Syverson 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
In keeping with the explicit goals and assumptions of Tor: No, I don't
think I should be taken at my word.  I think people should instead
rely on the extraordinary evidence of the most well-documented,
scrutinized, and open system in existence. I wouldn't have bothered to
claim anything except that Mark explicitly said, "I don't see anyone
denying it.  Do you?"  As I noted, I did see that others already had.
But since he didn't seem to, and as a designer of Tor, I explicitly
and directly answered him.  Believe me or not as you wish.

@_date: 2014-07-02 06:34:06
@_author: Paul Syverson 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
Well even a sketch (which you begin to provide below) would be more
helpful to be able to comment on whether you actually have practical
security improvements in mind than was simply claiming that others could
obviously do better and just chose not to do so.
I also wasn't specifically talking about hosting web pages. This
thread has meandered a bit, but I was responding to the repeated
claims that it was obvious how we could have designed our systems to
be more secure by asking how, because it was not at all obvious to me.
It sounds like you are describing a censorship resistant publishing
scheme for (relatively) static content like Freehaven or the Eternity
Service (minus the forgetting in 2. which is more like Vanish or the
Infernity Service---which I think I only ever wrote up partially in
some mailing list comment somewhere 15 years or so ago). It's hard to comment without more details about intended goals,
adversary model etc. But what you are describing is a very limited subset
of the way many hidden services are used now.  People use HS for private
chatrooms, for maintenance access to their firewalled systems, to
manage the damage caused to an operation when insiders are compromised
because they only over get access to the hidden service part, not
to mention things like Strongbox and similar systems. My point is simply that this could not serve as a drop-in replacement
for hidden services as they are currently used to protect people and
their activities (assuming I get the gist from this initial
description).  That might be OK. You might be starting to describe
something useful.  But useful how, and in what context, and with what
security would need spelling out in much more detail.
Looking forward to it. Please keep in mind that much of the time when
we get good ideas, someone has already not only had similar ones but
written them up, possibly implemented them, possibly deployed them,
possibly published them in peer-reviewed venues, etc. So please as
much as possible explain how what you offer is an improvement over
existing designs described e.g. in papers in the anonbib.

@_date: 2014-07-08 05:13:47
@_author: Paul Syverson 
@_subject: [tor-talk] Tor Exit Operator convicted in Austrian lower court 
Also when the discussions changed from being about Tor? Some broader
contextual discussion is to be expected occasionally, but this thread
seems to have completely left Tor behind many messages ago.
Could posters please connect what you are saying to Tor or take the
discussion elsewhere?

@_date: 2014-06-19 10:59:50
@_author: Paul Syverson 
@_subject: [tor-talk] Presentation material in LaTeX 
To see more than you probably care to know on the history of the
names 'onion routing' and 'Tor' cf. pages 129, 135 of Two things that I see were not mentioned there: Nick Mathewson pointed
out to me and I confirmed in email exchanges that we actually started
using 'Tor' to refer to the basic onion routing system design that
we were working on before the design now generally called "Tor".
'Tor' also means a fine-meshed net in Turkish.

@_date: 2014-03-07 07:39:06
@_author: Paul Syverson 
@_subject: [tor-talk] Current attack of TOR to break anonymity 
About efficient cell-based attacks (although written long before the
above one was published so not quite addressing all its particulars), see
the Tor blog

@_date: 2014-03-08 14:39:20
@_author: Paul Syverson 
@_subject: [tor-talk] Pissed off about Blacklists, and what to do? 
If you naively view Tor as Yet Another Pulbic Proxy, I agree. But this
is the same thinking that leads you to block all encrypted traffic you
aren't MITMing. There may be environments where it makes sense, but
most of the time you are hurting yourself more than you are helping,
And enough places have learned that preventing encrypted traffic hurts
them that many people reading this probably don't remember when it was
commonly argumed that the opposite was preferable.  If you have
customers or employees that could benefit from personal defense in
depth or if your corporate operations do, then you are unnecessarily
hurting yourself. As Andrew noted, if you just buy a box and use its
defaults, you probably aren't getting what you want.  Directing
incoming Tor traffic appropriately, possibly requiring extra
authentication steps for anything where you don't need to permit
anonymous-from-you access to your services, makes much more sense.
Or encouraging corporations to run the same, e.g., allowing exit only
to their servers/ports and only for appropriate classes of
traffic. This is something we suggested early on, I think in the JSAC
1998 paper, or possibly in 2000 "Onion Routing Access Configurations".

@_date: 2014-03-08 14:45:12
@_author: Paul Syverson 
@_subject: [tor-talk] Torproject frontpage content 
A caveat: the frontpage needs to concisely hit just the most salient
points. It is a well-known problem that many (most?) users first
encountering Tor think that it encrypts the whole internet. And my
experience is that mentioning encryption briefly is more likely to
reinforce that thinking than it is to elucidate. There is a link right
below "What is Tor?"  to "Learn more about Tor" that takes you to a
page that goes into more detail, including your points above.  I
actually think that is preferable to adding more clarification to the
frontpage. A _well designed_ user study might tell us more about how
different options are perceived. In the meantime we have competing

@_date: 2014-03-09 09:28:56
@_author: Paul Syverson 
@_subject: [tor-talk] Pissed off about Blacklists, and what to do? 
I understand that many organizations are dysfunctional and don't use
common sense, but that isn't something to recommend.  Solving such
dysfunction is hard, highly contextual, and I'm not pretending it is
something for which I have expertise. But there are still very simple
things security folks can to do if dysfunction has not gone off the
deep end. Selective, short-lived blocking based on incidents is
different from permanent blocks, as Andrew commented, speaking as
former head of IT of a global company.  Similarly having a perimeter
rule-set that includes requiring authentication, or solving a CAPTCHA,
or whatever is specifically appropriate based on IP address rather
than just permanent blocks as I commented.
It seems that your soft/hard distinction is between permanent blocking
of a class of IP addresses and anything else.  Anything that crude is
probably going to cost in some way even if you don't know exactly how
yet.  It isn't necessary conservative to make blocking decisions
without even asking the above questions or because the cost of finding
good answers to some of them is itself too high to justify. I
understand how, e.g., a company worried about spam could come to block
all email from Europe for half a year, as one of the largest US ISPs
did a decade ago.  But that's different than recommending them to do so.

@_date: 2014-03-18 00:59:26
@_author: Paul Syverson 
@_subject: [tor-talk] Fundamental differences between Onion Routing and 
First off Tor not "TOR" and The Onion Routing not "The Onion Router"
cf. I respond to some of your specific statements below, but I think the
most thorough discussion of the evolution of onion routing design
including Tor (but not including any changes in the most recent few
years or so) is in "A Peel of Onion"
If I recall correctly this was not part of any of the three main
generations on onion routing design that came from NRL (Tor being the
third). But the general idea of onion routing does not preclude
such a possibility.
Partly correct. Tor added many of these things, but configurable exit
policies (and entrance policies for that matter) were added a
generation before Tor. Also there were rendezvous servers and
location-hidden services even in the very first design, although the
Tor design changed many features of each.
Not sure I follow what you are saying, but onion routing, including Tor,
has always had the source (client in Tor) select the nodes in the route
in an unpredictable manner. (In the very first onion routing paper
we introduced a concept we called 'loose source routing' which allowed
intermediate relays to create their own onion routes to the next hop
in the route chosen by the source. This was primarily to handle
cases when one relay could not directly reach another, although it
had other features.)

@_date: 2014-05-14 12:03:24
@_author: Paul Syverson 
@_subject: [tor-talk] darkweb-everywhere - was: Using HTTPS Everywhere 
The point isn't about the "Dark Web" brand. It is about the .onion
brand.  I know what a .onion address and a .onion site is.  I honestly
have no idea what you mean by "Dark Web" here since I have seen it
used in so many incompatible and confused ways that it cannot be used
to communicate anything coherently unless the speaker takes additional
effort each time to spell out what they mean. In other words, this is
not a useful term for talking to people who understand the techonology
and is a dangerously misleading term for talking to people who don't.
There may be a better phrase. It might be, but probably isn't "Deep
Web", which has a more coherent origin, but is already transitioning
in an even muddier way than how "hacker" has evolved. I don't think
common usage, e.g., in the popular media, makes any distinction
between "Dark Web" and "Deep Web". This entire thread is indeed
something of an illustration of that and I assume was the original
point of the frustration expressed.
They have cookies.

@_date: 2014-11-13 08:52:38
@_author: Paul Syverson 
@_subject: [tor-talk] "Hidden Services" vs "Onion services" 
This is also nice because it further emphasizes the distinction
between the thing that the user is setting up and the network that
is providing secure/hidden/private/location-protected/whatever access to it.
'Onion service' to me doesn't as cleanly conceptually separate the
service that is protected behind the onion network and the service of
protection for it that the network provides.
There are things besides onion websites (e.g. onionshare or private access
for system administration) that it seems are more reasonably connoted
by 'service' than 'site', but no convenient-enough-to-be-useful term
is going to be the 100% best choice in all respects. 'Onion site'
sounds like a winner to me. (But who would have expected it, clearly a
dark horse, perhaps even a dark web horseman of the infocalypse...
Oh dear.)

@_date: 2014-11-16 12:05:07
@_author: Paul Syverson 
@_subject: [tor-talk] "Hidden Services" vs "Onion services" 
For reasons I stated (separating the service the network provides of
doing the hiding from the service available via hidden access), I
prefer "onion site" as a general term even for non-websites despite
other drawbacks thereof.  Beside pejorative connotations, another conceptual confusion
frequently made in the media and important to counter is that these
sites/services/whatever are part of the Tor network.  Yes I know they
also confuse "The Web" with "The Internet" but its even more useful
for us to keep those separate. Calling them "onion sites" rather than
"onion services" helps with that in my opinion.

@_date: 2014-10-06 23:00:47
@_author: Paul Syverson 
@_subject: [tor-talk] Stupid hidden services question 
The client and/or HS choose their guards as usual. All other relays in
both Intro Circuits and both Rendezvous Circuits in a HS access are
chosen with the bandwidth-weighted probability of being chosen as a
middle node.

@_date: 2014-10-14 14:37:25
@_author: Paul Syverson 
@_subject: [tor-talk] Reasoning behind 10 minute circuit switch? 
If I recall, we (Roger, Nick, and I) had a bunch of discussions
concerning the trade-offs between the overhead of the public-key
operations of circuit building and the pseudonymous profiling
occurring at an exit. (The intersection threats from repeated circuit
builds was not uppermost in our thoughts at that point. We were aware
of the potential. But this was before we did the research that so
strongly motivated the need for guard nodes.) The ten minute choice
was an informed one, and we had some numbers on public-key overhead.
But we had no hard usage data or similar on which to base our

@_date: 2014-10-15 22:57:05
@_author: Paul Syverson 
@_subject: [tor-talk] Social Research on TOR in Turkey during March2014 
Not sure why a web of trust approach should be considered incompatible
with grounding trust in a pseudonym or what you mean by "true name"
(some sort of Vinge reference?), but in any case that's the best
Freudian typo of the day.

@_date: 2014-10-15 23:52:41
@_author: Paul Syverson 
@_subject: [tor-talk] Social Research on TOR in Turkey during March2014 
Ah I was reading "DNA swaps" in the sense of the Vincent and Jerome
characters swapping identitities in Gattaca rather than the sense of
swapping credentials to authenticate each other. Hence my amusement.
Depends what you're trying to reliably identify, and let's completely
sidestep the criteria for "reliable" in the various popular
authenticators you cited are. (I disagree with Quine on much, but I do
accept his maxim, "No entity without identity"---although unlike Quine
I would understand both of these stochastically.) Sorry, need sleep
and am straying well into not-torritory.

@_date: 2015-04-03 20:50:17
@_author: Paul Syverson 
@_subject: [tor-talk] DNS hijacking 
If s/he is using Tor and hasn't done something odd to reconfigure, then
the DNS resolve is done at the exit relay.  His local DNS resolver is
never contacted. Also, original poster said that local resolution
worked correctly (presumably the correct IP address is known); only
over Tor was there a problem.

@_date: 2015-04-06 20:35:44
@_author: Paul Syverson 
@_subject: [tor-talk] Tor Summer of Privacy 
*sigh* If you're going to commit ad hominems and fallacies of division
at least try to be competent about it. You shouldn't be focused on
mere funding (and anyway you missed that we started DARPA funding in
1996); Those couple of blokes in 1995 were myself and other
U.S. govt. employees (Naval Research Laboratory). We didn't hire any
contractors till 1997 and not Roger and Nick (with whom I did the
initial Tor design) until 2001 or 2002.
More details on the history at
For the technical reasons behind the degree and nature of centralization
and decentralization, see the above paper and the Tor design paper. Also note that ironically the first few major design
versions made purely by govt. employees were actually more
decentralized. E.g. see the above paper, also
It was only when we moved to the Tor design, that we moved to being
a bit less P2P with directory authorities. For more technical arguments why this is in practice more secure than
other designs known at the time see
  and
 But by all means please continue justifying everything you say based
on what you tenaciously are sure some large organizations must intend
rather than the technical design reasons that have been published and
publically vetted by the best scientific and technical researchers on
the planet from the most respected advanced institutions in every
country. What could they possibly add to the truly dizzying intellect
manifest in your arguments to date?
Apologies to others for failing to resist feeding the troll. Guess I'm
tired.  Here's a little ad hominem of my own: Moritz started it.

@_date: 2015-08-03 10:56:55
@_author: Paul Syverson 
@_subject: [tor-talk] Historically speaking, 
There _were_ explicit problems, but nobody approached us with them or
with requirements that they said needed a new technology. We came up
with some specific problems we thought might be useful to solve and a
technology that addressed them. These co-evolved, and I can't say
which is the chicken and which is the egg. We also tried to design in
an open-ended and modular way in expectation of other applications
that we had not yet thought of or evolutions of existing applications.
And this was as much or more about anticipation than about the
communication environment that existed at the time, which is the
reason I mentioned the pizza channel (since I don't think anybody was
offering a way to order food over the Web in 1995).
Well not just managers. In papers, conference presentations, etc.
basically to anyone that we were trying to tell about onion routing
and what it had the potential to do.

@_date: 2015-08-03 12:02:31
@_author: Paul Syverson 
@_subject: [tor-talk] Historically speaking, 
Hi Cari,
I'm confused. I work at the U.S. Naval Research Laboratory. The Navy
is a standard place for me to apply to with any funding proposal. Perhaps this will help
And, for any proposal, we _don't_ know that we can get funding for it
till a funder agrees.

@_date: 2015-08-03 15:16:59
@_author: Paul Syverson 
@_subject: [tor-talk] Historically speaking, 
Ah OK. Now your question makes sense to me. I started at NRL in 1989. I
started working on onion routing in 1995.  I've worked on a couple of
areas, but prior to onion routing and anonymous comms, my largest
focus had been epistemic and temporal logics for analyzing
authentication and security protocols, which was closest to my
academic background---primarily logic and philosophy of logic.
Glad I could help.

@_date: 2015-08-27 08:57:44
@_author: Paul Syverson 
@_subject: [tor-talk] IBM says Block Tor 
This is an overly narrow view of "use Tor". In any corporate
environment, including customer support settings, it could be
important to protect searches of public information (including perhaps
especially competitor information) from competitors and possible
network observers. Maybe _you_ would have no reason to use Tor there,
but your company would have a reason for you to use Tor.
In an inadequately configured environment, perhaps.  But corporate
investigators and law enforcement officers use Tor all the time to
investigate crime online and could have to do so unofficially if no
adequate sanctioned solution were available.  Even in an inflexible
setting that tension is unnecessary, however. We specifically designed
for multiple usage scenarios including one where your use is subject
to local monitoring but still is protected once leaving the local
network.  The case here is described under Proxy-and-OR-at-Firewall
Access in "Onion Routing Access Configurations".

@_date: 2015-08-27 10:51:51
@_author: Paul Syverson 
@_subject: [tor-talk] IBM says Block Tor 
Hi Tom,
So I was responding to the claim that there is no reason for an
enterprise to be supporting the use of Tor by its employees (and I
certainly didn't list all of the reasons they could benefit from its
Other issues: I may be reading in to your comments but you seemed to
be at least partially concerned with exfiltration. This report is
focused on intrusions and does not even mention exfiltrations. Also
simply blocking Tor relays without actually preventing use of Tor
clients will readily be circumvented by even relatively nontechnical
users via bridges and obfuscated transport (easy radiobutton
configuration choices when starting Tor Browser). The other big issue
was alluded to by others. It can be a reasonable cost-effective and
shortterm expedient to temporarily block a known network for various
reasons. And if that is all you meant, I agree. But blocking the Tor
network is not a good means for, e.g., resisting SQL injections and
malware that are widespread on the Internet.  And botnet DDoS will be
virtually unaffected.

@_date: 2015-02-01 07:08:19
@_author: Paul Syverson 
@_subject: [tor-talk] Tor -> VPN  Clarification 
Whoa! That phrase blew my mind and is almost certainly the phrase of the
week if not month---and (for me) before dawn on the first day at that.

@_date: 2015-02-02 15:46:11
@_author: Paul Syverson 
@_subject: [tor-talk] ATOMIC BANJO and LEVITATION used by CSE 
You should rather say Tor is not _the_ onion routing, it's _an_ onion
routing: cf. p. 129 again---except this is not the 'the' of definite
description but the 'the' of "The original and still the best". (I got
this phrase from Roger Needham in 1993.  He was talking about BAN
logic, and said he got the phrase from a shoe polish tin.)

@_date: 2015-02-02 16:37:58
@_author: Paul Syverson 
@_subject: [tor-talk] ATOMIC BANJO and LEVITATION used by CSE 
Great. So we were on the same page already.
Hopefully the paper I just sent you helped. Basically what we called
'onion' in pre-Tor versions of onion routing from NRL doesn't exist in
Tor. An onion was just layers, no middle. It was used to build the
circuit. What came after the circuit was built had content in the
middle of the layers, so was not truly an onion.  (Also the onion's
layers were public-key crypto, what came later was symmetric-key.)  We
changed how circuits were built in the Tor design, but kept the name
from the earlier designs since the core concept was the same.  Most
importantly wrt the name: an onion router is just a Tor relay.  Tor's
not just an individual relay. It's the whole system: all the relays,
the directory system, the client software, etc.
The point was that there was a bunch of stuff we started doing at NRL
in 1995 we called "onion routing" including what we eventually called
Tor.  Some people not at NRL designed, and in some cases built, other
systems using the same onion routing principles (e.g. the Freedom
Network that Zero Knowledge Systems ran c. 2000-2001, Iron Key had its
own private onion routing network, plus lots of academic paper
designs, etc.)  The contrast in the name, why it was _the_ onion
routing, was comparing Tor to other non-NRL pre-Tor onion routing
systems. Tor was part of the original set of projects and design goals
at NRL (which had a bunch of iterations and revisions so that none
after early 1996 was the original original onion routing). None of the
other non-NRL systems from the pre-Tor days would have been implementing
Tor. Although Tor imported a key idea from at least Cebolla and
probably some other ideas from others as well (or learned things _not_
to do from some of them).

@_date: 2015-02-02 16:56:53
@_author: Paul Syverson 
@_subject: [tor-talk] ATOMIC BANJO and LEVITATION used by CSE 
Tinfoil hat brigade will probably not believe anything I say, but for
the rest of you: I was talking to them about licensing the onion
routing patent and other things right up until they shut the network
down. I feel confident this was simply a business decision. Ian and/or
Adam may care to say more (or not).

@_date: 2015-02-04 07:19:48
@_author: Paul Syverson 
@_subject: [tor-talk] "Confidant Mail" 
See also Let's Encrypt plans to offer free and automatic to set up certificates
from a recognized authority starting in mid-2015. (Not quite ready
yet.) It is backed by EFF, Mozilla, Akamai, Cisco, and Identrust.

@_date: 2015-01-29 15:04:32
@_author: Paul Syverson 
@_subject: [tor-talk] ATOMIC BANJO and LEVITATION used by CSE 
See p. 129 of (Note, the German meaning of 'Tor' mentioned in the FAQ is discussed in the
"A Peel of Onion" paper, the Turkish meaning is apparently a fine-meshed net.)

@_date: 2015-01-30 06:59:00
@_author: Paul Syverson 
@_subject: [tor-talk] Tor -> VPN  Clarification 
As with all security, it depends on your goals, what you want to protect,
and from whom. I have used Tor in both ways for various reasons.
Tor -> VPN
Some possible examples of what this is good for.  You might want to
use this if you want to hide your current network location but you
need to log into a VPN to access certain services available only via
the VPN, or if the VPN is associate with you (e.g. run by your
employer) and you don't want the local ISP to see you log into the
Since you log into the VPN, everything you do there can be tied to
your account. If you are concerned that your activity "leaving" the
VPN can be tied to you by someone who might compromise the VPN in some
way, then anything the VPN knows about you from that account will be
potentially vulnerable to this. If this is not something you are
worried about or a risk you consider unlikely or not bad enough should
it happen, then you might use this configuration.
VPN -> Tor
You might not have a choice: your computer is currently configured to
direct all connections via the VPN, and you want to use Tor to either
hide your destinations from the VPN or to hide that you are using that
VPN from your destinations or you may want to access something at a
.onion address or....
Or you may have a choice and some reason to use Tor, but you are in a
location that blocks the public Tor relays. You could also use
bridges, but you know the VPN is not blocked and this is more
convenient or it better fits your trust/threat concerns than a bridge
would. Or you may know the location of access to the VPN and you are
happy to have your access to the VPN visible to the local ISP, but you
don't want it to see you accessing the Tor network or possibly
unexpected destinations such as a bridge.
I have certainly not given all the reasons for using either
configuration, nor have I spelled out all the risks from every
possible adversary.  But I hope this helps.

@_date: 2015-01-30 22:42:12
@_author: Paul Syverson 
@_subject: [tor-talk] Tor -> VPN Clarification 
That's right. They are using mixes not onion routers. It's a different
architecture with a different threat model. Tor's security is largely
based on having a large and diverse enough set of entry and exit
points to the network that it is hard for a practical advesary to
watch (and possibly disrupt to create a timing signal) both ends of a
connection at once. An adversary that can do so however is assumed to
be able to correlate source and destination. JAP's security is based
on the mix concept, wherein the adversary is assumed able to see both
sides of a connection (which would break anonymity for Tor), but the
timing properties of connections are such that it is difficult to say
which of the concurrent connections on the client side of the mix
correlates with which connection on the destination side.  Creating a
fixed path of mixes (known as a mix cascade) run by different
operators means that there is not a single mix that knows that
correlation. JAP, unlike Tor, is meant to remain secure even if an
adversary can see connections on both sides. To be successful at this
a low-latency cascade like JAP must maintain a constant (or adequately
large) anonymity set of the same persistent clients concurrently and
must use padding and other techniques to prevent natural or induced
patterns from giving away the correlation.

@_date: 2015-07-29 09:50:51
@_author: Paul Syverson 
@_subject: [tor-talk] Historically speaking, 
Hi Virgil,
If I'm understanding you, it's a question with a presupposition
failure. Nobody came to us and said, "We have this problem we're
encountering in the field.  How would you solve it?" We (David,
Michael, and I) thought of an interesting research problem and
solution area that could also ultimately result in technology that
would be useful to the Navy. We then applied for funding to research it.
We came up ourselves with potential application suggestions such as
open source intelligence gathering or "phoning home" as you put it.
We also came up with other ideas (some good, some bad) and also talked
to people about how it might be useful.  As another example that I
remember from an early briefing slide: We knew about the 1991 pentagon
pizza channel
 and we speculated that maybe in the future people would even be doing
incredible stuff like ordering food online (The Web was only two years
old at that point.)  We had a picture where the ordering
information went over the Web from the Pentagon to Domino's and was
routed by an enemy (Iraq at the time of the putative pizza channel
concern). I remember a point I would make during presentations was
that the enemy could see the number of orders made by people at the
Pentagon to Domino's even if he couldn't break the encryption to know
if they were for pepperoni or extra cheese.  (And this was years
before ShmooCon 2005 when Nick Mathewson uttered the immortal line:
"Look. Dan Kaminsky has just fit an entire meat-lover's pizza inside a
DNS request.")
There is some more discussion of the history
of onion routing (including Tor) here
also, though the slides above are not in it (I'll have to look around)
for some other application ideas see
 (Note that in those slides we said onion routers were Chaum mixes
because when we told more experienced researchers about onion routing,
they told us these were a form of Chaum mixes (with which we were
initially unfamiliar).  We didn't really articulate the important
differences till much later.)

@_date: 2015-07-29 16:51:05
@_author: Paul Syverson 
@_subject: [tor-talk] Historically speaking, 
I can confirm that this is the first I've ever heard that. I can also
confirm that I talked long ago (maybe late nineties or early aughts,
in any case after the first public onion routing deployments) to
someone who knows way more than I do about how communication on and
off ships at sea happens (or at least did at the time). This wasn't a
Navy or government person, just an academic researcher I know who said
he knew about this environment. I had an idea roughly the same as
described in this scenario and asked if this could be another useful
application of onion routing.  He said that the very tight constraints
of this environment made it almost certain that the multiple hops
needed would be unacceptable. I didn't pursue any further.

@_date: 2015-06-21 08:55:32
@_author: Paul Syverson 
@_subject: [tor-talk] Matryoshka: Are TOR holes intentional? 
On a practical level no. In our 2006 results we ran experiments seeing if one could use
correlation to find Tor onion services (that we had set up, not other
people's) with a single compromised relay on the live network. Matches
were trivial to identify and we had zero false positives on many thousands
of runs. [0] In 2007, Bauer et al. extended our work to allow owning
of multiple relays, which would permit correlation on ordinary destinations
(not just onionsites). They generally could identify with a very tiny
false positive rate based just on circuit setup, before any application
traffic had even been sent. [1]
Uniform cell size does reduce the effectiveness of destination
fingerprinting.  And it's conceivable that with the growth of the
network and its use, correlation based on datasets of wholesale
network-wide collected timing information could be made nontrivially
more expensive. I have suggested to Roger and others for a while now
that it would be worth exploring synchronous building of circuits for
this reason to see if that is true, and discussed some of the factors
for exploration. But as far as I know neither ourselves nor anyone
else has found time to do this research. In any case, if one observes
entry and exit of a circuit and wants to know if they are correlated,
it takes almost no traffic on the connection to do so. This was first
described in the mentioned papers, but it has also been born out by
several later results as the network and its use have grown.
[0] Locating Hidden Servers. Overlier and Syverson available at [1] Low-Resource Routing Attacks Against Tor. Bauer et al.
available at

@_date: 2015-06-23 06:54:37
@_author: Paul Syverson 
@_subject: [tor-talk] Matryoshka: Are TOR holes intentional? 
Even if, for the sake of argument, the padding node to node would work
perfectly for the security you want there, it would be irrelevant to
protecting correlation of client to destination. It is infeasible on
the network links that matter: those between the client and the
traffic-security network and those between the destination and the
network. The system is intended to provide protection of communication
with destinations that do not participate in its protocols. So even
ignoring who would pay for this overhead, the vast majority of
intended destinations won't participate.  And the vast majority of
clients could not afford to have always-on, full-length padding to
connect to the network. Nor would they like the performance of the
limit to that rate (e.g. no bursts above it).

@_date: 2015-06-25 20:15:45
@_author: Paul Syverson 
@_subject: [tor-talk] Is this still valid? 
This is all correct, but Tor (and for that matter the instances of
onion routing we built before it) always provided censorship
circumvention even if we didn't always call it that. We were conscious
and intentional that these systems could permit access to data,
services, and network locations that might be locally blocked at the
client end or might be blocked at the destination end for access from
specific network locations. As Seth noted, what has been added (and
continues to be developed) since the early 2000s version of Tor are
various methods to obfuscate that someone is connecting to the Tor network.

@_date: 2015-03-11 06:31:21
@_author: Paul Syverson 
@_subject: [tor-talk] Protest Blocking Tor via CloudFlare 
This should have security advantages as well against end-to-end
correlation by an AS level adversary.

@_date: 2015-05-19 09:26:33
@_author: Paul Syverson 
@_subject: [tor-talk] Making a Site Available as both a Hidden Service and 
Hi Ben,
I'm presenting a short paper I wrote with Griffin Boyce "Genuine
onion: Simple, Fast, Flexible, and Cheap Website Authentication" on
almost exactly this topic at the IEEE Workshop on Web 2.0 Security &
Privacy on Thursday. You can get it at
or get both the paper and slides from
The basic idea is to use onion services for better authentication.
Partly perhaps because of our unfortunate original choice of
terminology (Hidden Service) we haven't as much emphasized the
self-authenticating property of these services as the hiding.  We
treat hiding in this work as basically an orthogonal issue, although we
do discuss some advantage in that respect as well. TLS Certs are
problematic for various reasons and for onion addresses are currently
only available for extended validation, which is a nonstarter for most
people. The binding for the two sites (which may or may not be two
paths to the same web server) we suggest is GPG signatures on both
addresses posted on both sites. This can be easily used right now w/
existing tools, which is great but obviously is highly manual. So
"easily" is in the eye of the beholder. We discuss use cases,
protections, efficiencies, and conveniences provided. Also
complementarity to TLS, automation, and the potential for integration
with existing tools such as Convergence and Monkeysphere. Also,
integration with the ahmia onion service search engine.

@_date: 2015-05-19 22:08:36
@_author: Paul Syverson 
@_subject: [tor-talk] Use of TOR for illegal activities 
Thanks for the ill-deserved compliment. There's also a more
historically detailed less wit-focused account of the name [1].
[1]  (page 129)

@_date: 2015-10-14 15:41:42
@_author: Paul Syverson 
@_subject: [tor-talk] Tor 
In a word, No. That was not an application we had in mind when we
proposed looking at the question of how to separate identification
from routing in web and other low-latency Internet communication.  The
scientific/technical ideas and the application ideas we had arose
together chicken-and-egg fashion, and I'd be hard pressed to say which
ideas we thought of first. But in any case this was not one of them.
For more details please read "A Peel of Onion", which you can find at

@_date: 2015-09-04 15:38:11
@_author: Paul Syverson 
@_subject: [tor-talk] 
=?utf-8?q?2015?=
Great TWN as usual. This is really cool, but I just wanted to note
that this is certainly not Tor's literary debut. It's been mentioned
in a bunch of novels and stories. The only one I can think of off the
top of my head is Cory Doctorow's Little Brother, but I know I've seen
it elsewhere.

@_date: 2015-09-19 10:41:50
@_author: Paul Syverson 
@_subject: [tor-talk] What good is using Facebook through 
You are also not vulnerable to any DNS hijack since address lookup
does not use the DNS system. Likewise BGP hijacks are diminished in
value. But perhaps more important than either of these, any CA hijack
or shenanigans are greatly diminished in usefulness. You might want to
look at a short position paper we have that discusses this:
"Genuine onion: Simple, Fast, Flexible, and Cheap Website Authentication"
pdf of paper and
slides available at We also have a revised and expanded paper reflecting subsequent
developments in the works.

@_date: 2015-09-22 09:45:41
@_author: Paul Syverson 
@_subject: [tor-talk] What good is using Facebook through 
Hi Virgil,
I think pinning might be sufficient. DNSSEC is so minimally deployed
as to not be a significant factor. See "Measuring the Practical Impact
of DNSSEC Deployment" from USENIX Sec 2013. Certificate transparency
will probably be providing records assurance sooner.
After sending I also thought I should have mentioned that the DNS
lookup is visible (often over separate paths than the connection to
Facebook) whether or not it is hijacked.  And maybe Facebook in
particular has employed adequate other things. I was taking Facebook
as not just the specific concern but as an exemplar of what using
onion addresses gets you when you are not trying to hide network
location. The self-authentication of onion addresses and the
communications entirely "within" Tor applies to other sites as
well. And for both Facebook and those sites these provide additional
assurance whether or not certificate pinning or other mechanisms have
been deployed.

@_date: 2016-07-31 22:44:14
@_author: Paul Syverson 
@_subject: [tor-talk] Tor Project Corporate Document FOI Request 
I don't know the extent to which this covers what you were looking for, but
you might want to look at/participate in the thread
that discusses various Tor documents.
The second message (from Alison) specifically includes several
documents that seem to cover at least some of what you were asking about.
The thread I reference in general discusses the need for having a good
place to put all such documents and the pros and cons of various
choices.  So, while I think it's true that the particular thread we're
currently in remains unanswered by anyone from TPI, there is clearly
ongoing expenditure of nontrivial time and effort on the general
topic.  No doubt plenty of room for improvement. HTH.

@_date: 2016-08-27 11:12:38
@_author: Paul Syverson 
@_subject: [tor-talk] Any risk by showing traffic statistic on the 
Thanks for both running an exit and for checking about posting of
statistics.  It is indeed tricky to do so safely. (And gathering of
statistics: it is generally advisable to only gather those statistics
you would be willing to make public.) These are fine questions to pose to the recently formed Tor Research
Safety Board.  The board is mainly to provide guidelines and feedback to those doing
research on Tor, but it clearly is relevant to people like you,
who want to make data available to others who might do research.
As you noted, realtime updates and or even later postings of
temporally fine-grained numbers could be too revealing for even
after-the-fact traffic correlation.
First of all look at the guidelines
Assuming you have done so, I suggest you put together a brief
description of what exactly you plan to collect and what your process
will be (e.g. how and for how long will any raw data be held for
incorporation into statistics before being deleted, especially if this
is much longer than circuit lifetime). Then submit this to the board.
Right now a board contact address has not been set up so it's just
listed as Roger, but you can also reply to me for this one since I
think if you send to him right now it may not go out to the board for
at least several weeks.

@_date: 2016-02-24 19:58:53
@_author: Paul Syverson 
@_subject: [tor-talk] Tor for everyone; 
The description below sounds a fair amount like Keybase (
Perhaps it would be helpful to contrast your goals with theirs?

@_date: 2016-02-28 23:29:58
@_author: Paul Syverson 
@_subject: [tor-talk] trusting .onion services 
But the whole point of GPG is that there is a web of trust. Yes anyone
can sign something and say that they're you. But only people who have
met you face-to-face and confirmed your key, e.g., using the
Zimmerman-Sassamanprotocol should be signing your key.  Someone can
then trust your key is bound to you to the extent that they trust the
keys of the people who vouch for you.
This is why we suggest this approach for an at-the-moment solution
(Note the final edited version, coming out soon in IEEE Security & Privacy
is a little different, but content is basically the same.)
Besides the PGP approach we present, we also give an X509 style
solution that requires some policy changes but will work with the
usual browser certificate semantics for TLS.
For another example of the PGP signature approach not mentioned in
the paper see

@_date: 2016-01-14 12:32:58
@_author: Paul Syverson 
@_subject: [tor-talk] Escape NSA just to enter commercial surveillance? 
Tor is about separating identification from routing, as we explicitly
stated in publication way back in 1996. And it is not just for access
to a site from which one wants to remain anonymous or pseudonymous.
One of the motivating examples we gave when starting this work
c. 1995-6 was someone traveling wanting to log into a workstation at
their usual work location not wanting network observers to know their
association with where they work. Another example would be to login
but not identify to their destination where they are logging in
from. In both of these cases, you want to be not just identified but
authenticated by the destination.  This was part of the motivation for
Tor from the beginning of onion routing.
But whatever our motivation was, it is a tool. We should not be
dictating based on our original motivations creative ways that other
people find to make use of that tool as long as that use isn't abusive
or destructive.
As Robert Hunter brilliantly observed wrt commentary on lyrics he
 I know where it's come from, but I don't know where it's been.

@_date: 2016-01-17 11:12:56
@_author: Paul Syverson 
@_subject: [tor-talk] trusting .onion services 
For a description of what one can do now via GPG, and a plan for
integration with Certificate Authorities (for the little guy, not
just, e.g., Facebook), see
Note: this is specifically focused on onionsites that have registered
domains with which to associate. The GPG approach could be used
without a registered domain associated. (And in a previously published
paper also on saint's github, we noted that this could work for
Wordpress blogs or Facebook pages, not just domains registerd by the
onionsite owner.) Or one could use keybase, etc. I just want people to
know the scope of what is being attempted in this work.

@_date: 2016-01-25 10:25:20
@_author: Paul Syverson 
@_subject: [tor-talk] Using VPN less safe? 
A little terse to know, but onion routing is designed around diversity
of trust. Just to be clear, this does not mean 'let the Tor Project
Inc. or the Tor Director Authorities (itself a diverse set)
or... select a route and hand it to you'. It does mean 'let the Tor
software use its randomized algorithms to select a route that makes
tradeoffs of performance and security that experts have thought about'.
There are of course configuration settings so you can do differently
if you want. If anyone wants to do that, they should try to make as
informed a choice as possible and understand what the issues are. We
have made a number of mathematical and experimental analyses, policy
languages, etc. available to understand trust in route selection for
Tor or other onion routing systems, taking into account a wide range
of adversary types. The most recent published work we have on this is
"20,000 In League Under the Sea: Anonymous Communication, Trust,
MLATs, and Undersea Cables" available at
This is ongoing evolving research. This is not ready for deployment
for everybody's Tor clients to do their own trust-aware route
selection.  And, one of the observations of this work is that you
should probably always use the default settings unless you have
specific other adversaries in mind and understand how diverging from
the pack will affect you.  What this work will do is help people who
want to use different route selection choices to understand those
choices, and it will eventually impact the default and alternative
route selections built into the Tor software.  It also focuses just on route selection.  Tor does other things to
diversify trust.  For example, Tor's binaries have for the last few
stable releases reflected reproducible (or determistic) builds, which
means that people can independently verify that the officially
distributed binaries are compiled from the officially distributed
source programs. If they did not match, anyone could test and expose
that.  See

@_date: 2016-01-26 14:04:54
@_author: Paul Syverson 
@_subject: [tor-talk] onion routing MITM 
This is false. First of all '.onion' is an officially recognized reserved top level
domain according to IETF RFC 7686.
Second, a CA _will_ validate a .onion address, but only to provide an
EV (extended validation) Cert. EV Certs are typically only
had by big companies etc. Typical browsers represent an EV cert by
showing the lock icon in green. Facebook and a couple of other entities
do have certs for their .onion addresses. Most .onion site operators are
likely to want DV (domain validation) certs, which are currently not
permitted under the guidelines of the CA/Browser Forum.
That is the current state of things, which is different from how things
were several months ago and will probably change again at some point.

@_date: 2016-01-26 14:14:49
@_author: Paul Syverson 
@_subject: [tor-talk] onion routing MITM 
Probably should also have noted wrt the original question
that for people who use PGP/GPG there are things that can be done
now and onionsites that do make use of that. Cf.
"Bake in .onion for Tear-free and Stronger Website Authentication"
for a description of both how people are using GPG now, and for
the situation and plans for certs in the future.
See also Juha Nurmi's related post to this list about booby trapped
onion sites.

@_date: 2016-01-28 07:56:12
@_author: Paul Syverson 
@_subject: [tor-talk] Different degree of identification -> 
I think it could be a good topic for face-to-face discussion.
I also think it dovetails with our trust-aware approach. I'm
not sure I think ID in the usual official sense will mean much
in this context (but we can discuss); however, if a useful notion
of identity can be introduced it could be one of the factors
in determining relay trust.

@_date: 2016-07-05 00:30:46
@_author: Paul Syverson 
@_subject: [tor-talk] Paper on traffic correlation 
A work of penetrating pathos and unwavering brilliance, one that surely
sets the standard for erudition by which all 21st century work will be
Less facetiously, do you have anything specific you were wondering about?

@_date: 2016-07-06 07:09:39
@_author: Paul Syverson 
@_subject: [tor-talk] Paper on traffic correlation 
You've glossed over the hard and dynamic part here: Tor (the network)
is a transnational entity in multiple senses. And its users' interests
and concerns are far more diverse than the geopolitical entities in
which its relays physically reside. If Tor is fulfilling its intent,
"real adversaries" should comprise a highly varied and internally
inconsistent collection of entitities---sometimes even when from the
perspective of a single user. Besides the above paper, we also devised a framework for people who
have some specific ideas about their adversaries to express their
degree of trust in relays, ASes, IXPs, etc. and have that inform a
probabilistic representation of trust that can be sampled by routing
algorithms to inform trust-aware routing.
 (Citing from
the same URL as OP. Paper has been published, vol. 1, no. 1, April
Of course, having this trust information one must figure out how to
use it to select paths.  An initial description of trust-aware routing
for Tor can be found at Since you raised the question of legal barriers, you might want to
note that the PoPETs paper above is titled "20,000 In League Under the
Sea: Anonymous Communication, Trust, MLATs, and Undersea Cables" and
includes a discussion of Mutual Legal Asssitance Treaties.  More
extensively treatment on the specific topic of MLATs and Tor have also
been published and are available online.

@_date: 2016-07-11 06:05:17
@_author: Paul Syverson 
@_subject: [tor-talk] using a VPN, 
Assuming that your client-guard connection is not observed _and_ your
adversary cannot learn through observation that those relays are
yours, then you would (mostly) avoid de-anon. The problem is that this
association is not easily hidden. If, e.g., your exit's ISP notices
repeated patterns from certain circuits, it can form a pseudonymous
profile of you. Now if there is ever a single link to your actual IP
or other sensitive identifier that whole profile is linked to
you---probably worse than a single connection de-anon.
This is a major basis for Tor in the first place. When we created
onion routing, we noted that a Navy only network would identify
traffic into/out of the network as for the Navy. So one had to carry
traffic for diverse parties to protect against this. And since
limiting traffic to those trusting an entirely Navy run network is
similarly problematic, you have to let diverse others run some of the
network. And since they won't just trust your code, it has to be open
source. That is how we have been doing it since the nineties.
One could, as you suggest, just use your own trusted relays within
that larger network. But that brings you a long way back towards the
original problem we were looking at in 1995. Leveraging trust safely
and efficiently turns out to be hard. We've been looking at this for a
while now. For our latest publication on incorporating trust in
relays, ISPs, etc. into routing decisions see "20,000 In League
Under the Sea: Anonymous Communication, Trust, MLATs, and Undersea
Cables" Jaggard et al. Proceedings on Privacy Enhancing Technologies 1(1).

@_date: 2016-06-05 18:43:42
@_author: Paul Syverson 
@_subject: [tor-talk] A possible solution to traffic correlation attacks, 
You guys might want to look at the stop-and-go mix paper (Kesdogan et al. 1998)
and the alpha mixing paper (Dingledine et al. 2006) at freehaven.net/anonbib/
Other topics touched on in this thread include defensive dropping
"Timing Attacks in Low-Latency Mix-Based Systems" Levine et al. 2004,
also at anonbib.
There are many research papers that have explored aspects of these ideas.
For this you might look at "Preventing Active Timing Attacks in Low-Latency Anonymous Communication"
Johnson et al. 2010, also on anonbib

@_date: 2016-06-20 21:25:53
@_author: Paul Syverson 
@_subject: [tor-talk] Question for those who say "Tor is pwned" 
I know I'm feeding the troll, but this is just crap. I invented onion
routing (with David and Michael) and designed Tor (with Roger and
Nick).  We did not design it so that an adversary can just watch the
edges. We designed it to separate identification from routing. Nobody
told or requested us to make anything weak or less secure. The three
of us came up with the motivations and idea for onion routing ourselves
and argued for the usefulness of pursuing it further. And we designed
it to be as secure as we could and still functional. And, as many have
argued, usability and performance are security properties for traffic
and routing security systems. Indeed perceived usability and
performance are important, as are network and operator
incentives. David, Michael and I designed the thing to be secure. We
also explained that it needed to carry traffic for others, let others
run part of the infrastructure, and be open source for it to provide
security to any distinct enterprise or general class wanting to use it
to protect their communications. This is part of the security design
regardless of who builds, deploys, or uses it. There were onion
routing networks, e.g., the Freedom network from Zero Knowledge
Systems Inc., that, to the best of my knowledge, had nobody from the
U.S. govt. involved in its deployment or design (other than that it
was an instance of onion routing). It was designed and built by other
people who are wicked smart (smarter than me) and free to create and
build whatever they wanted.  Somehow, this is what they chose to make.
Some people early on when we were first publicizing and announcing
onion routing (e.g. I remember getting such a question at FC'97) asked
us why we weren't building pipenet. Such a network is theoretically
way more secure for some properties in idealized environments, but
even a single user can shut down the network by simply not sending.
That's not secure.  In fact the first onion routing design in 95-96
was not subject to ready observation at the edges.  (although somebody
watching all the links from every onion router to every other could
still learn much).  The default configuration assumed onion routers
running on enclave firewalls with no separate clients. We explored
various padding and similar schemes to complicate observation of
traffic patterns, but I have yet to this day to see one that is adequately
practical to deploy and effective. These were things to try to add to
make the basic design more secure, but we could not find anything to
appreciably help here so did not incorporate it into the Tor design.
If you ever find such a design, describe it. No credible researcher in
any scientific venue has ever claimed to have a system to be more
secure that essentially covers the general use case and userbase of
Tor.  Mix systems, DC nets, buses, PIR, etc. are all very cool. And
subject to some strong environment and other assumptions can be more
secure than Tor against some classes of adversaries.  I have worked on
and designed some of these cool systems myself. But compared to Tor,
each one of these has limitations that, as explored and designed so
far, would restrict to a small (hence more easily targeted) anonymity
set, or has untenable usability or performance problems, or generally
all of the above.  It's funny that there's supposed to be this
intentional built in design weakness, and yet no scientist, engineer,
or mathematician in any country seems to have published a stronger
fundamental design. Hmm, perhaps you mean to imply that we who created
onion routing not only intentionally designed our systems to be weaker
than we could have but that we also have controlled all of the
scientific research and publication on secure system design by every
researcher in every country everywhere on the planet for the last
twenty years.
Onion routing design has evolved. Tor has forward secrecy, which the
two main onion routing designs we introduced before it did not. (Nor
did the Freedom network.) But we did not come up with including
forward secrecy, that was first introduced in Zack Brown's
Cebolla. And we adopted it when we designed Tor. Tor added a directory
system after its first design, then evolved and improved design,
robustness, and trust diffusion of the directory system over time. Tor
added deterministic builds to further reduce the trust in Tor-built
binaries, and work to improve continues through this day.
We have been completely forthcoming about our designs and any
limitations found by ourselves or others, including everything we can
empirically discern about end-to-end correlation risks from ASes,
IXPs, MLATs, etc.  And we have always designed to be as secure as we
practically could. I'm not going to engage further. I do invite those
who might so engage to find any valid technical, empirically justified
stronger design that does not make significant compromises to
performance, cut off large chunks of the existing userbase, etc. I'm
dubious you will find any. But if you do, I'd be happy to pursue its

@_date: 2016-06-21 00:19:39
@_author: Paul Syverson 
@_subject: [tor-talk] Question for those who say "Tor is pwned" 
The idea of layered encryption for anonymous communication was
introduced by David Chaum in the 1980s. AFAICT the term "onion" to
describe mixing was first used in a published work by Gulcu and Tsudik
in early 1996, just before our first onion routing publication a few
months later, but after we had submitted our work. Nihil sub sole
novum, but I believe we invented the design of a network that utilizes
layers of public-key crypto to lay a cryptographic circuit over which
data can be passed bidirectionally. We did get a patent on that, for
whatever that's worth.  In any case, Cecki and Gene used "onion" to
refer to layering around a message in a remailer mix network. We
called it "onion routing" not just because it was layered, but because
the data structure for circuit construction we used in the first few
generations (pre-Tor) was essentially comprised _only_ of layers, like
an onion: no message in the middle. These are two different things. I
describe it in some detail in "A Peel of Onion".  Here's an excerpt:
  Mix networks get their security from the mixing done by their
  component mixes, and may or may not use route unpredictability to
  enhance security. Onion routing networks primarily get their
  security from choosing unpredictable routes through a network, and
  onion routers typically employ no mixing at all. This gets at the
  essence of the two even if it is a bit too quick on both
  sides. Other typical and highly salient distinctions include that
  all existing onion routing network designs are for carrying
  bidirectional low-latency traffic over cryptographic circuits while
  public mixnets are designed for carrying unidirectional high-latency
  traffic in connectionless messages*. Mixes are also usually intended
  to resist an adversary that can observe all traffic everywhere and,
  in some threat models, to actively change traffic. Onion routing
  networks are generally completely broken against an adversary who
  observes both ends of a communication path. Thus, onion routing
  networks are designed to resist a local adversary, one that can only
  see a subset of the network and the traffic on it.
  * An exception is Web MIXes [6], which creates bidirectional
    circuits through mix cascades to carry public web traffic.
Right. I actually think calling the traffic and routing security Tor
primarily provides "anonymity" is a bit misleading and gets people to
confuse the primary security properties mix networks provide with the
primary security properties that onion routing networks
provide. Cf. more about this in my "Why I'm not an Entropist". But I
accept that this usage is now ingrained and not subject to correcting
even if the theory supports it.
D'accord. I'll agree with you that this design is limited and flawed
in that it is merely the best thing of its type available or that
anyone, anywhere has thought of. And I apologize and make no excuse
for my inability to come up with something better than the secure
system designs of the best minds in this area on the planet---minds
which I readily state totally kick my ass.
Nobody said it was. Anything for real use always involves many
compromises.  The best we can do is be as explicit as we can about our
choices, the reasons for making them, and the consequences we can
discern. People can then make an informed decision to use our systems
or not. I hope that people continue to analyze Tor to better
understand its properties and its advantages and disadvantages in
different environments and subject to different constraints. I also
hope people continue to explore other designs and would be happy if
someone supplants Tor with a system that provides comparable usability
and performance to Tor with better security.
Too briefly: these add huge overhead to the network, break underlying
protocols and/or hurt performance (which has been shown time-and-again
to drive real users of real systems to insecure alternatives, hence
hurting security overall), and none have been shown to provide strong
security against an active adversary for low-latency (i.e., practical)
systems. We published a design in 2010 that essentially turns a
solution against a passive adversary into a solution against an active
adversary. It had some nice theoretical properties, but I don't think
it was practical. These haven't been ruled out. There is ongoing
research, but so far none of it has looked adequately useful in practice.
I think there are some things we maybe could do with mixing and
synchronization to raise the bar at least a little against a _passive_
adversary. I have told many researchers my thoughts about this, but so
far nobody has taken it up that I know of. I would like to look into
it myself, but I already have a many-years backlog of more important
(more likely to make a real difference IMO) research questions to

@_date: 2016-06-21 01:45:19
@_author: Paul Syverson 
@_subject: [tor-talk] Tor... patented? 
To the best of my knowledge, Tor is not encumbered by any patents.
The onion routing patent has expired, and in any case was never
applicable to Tor because some of the design features of Tor took it
outside of the scope of the onion routing patent.

@_date: 2016-06-21 12:29:09
@_author: Paul Syverson 
@_subject: [tor-talk] Question for those who say "Tor is pwned" 
Thanks for the kind words and support Ted. I always feel funny getting
much credit here when there's so much collaboration and shoulders of
giants and all that.  Not to mention that I just work on making this
stuff. It's the people who use it because they are doing things that
really need it who are making the real contributions to humanity. And
please don't be pained on my account. Generally I don't find it a good
use of my time to respond to the almost ineffable cardinals of
confused/misinformation out there, but there are new people joining
the list all the time. So sometimes I think it's good to try to set the
record straight a bit for those with ears to hear. ( Plus when I'm
avoiding facing that I'll be up all night working on something at the
end of an already long day, it's easy to distract myself with
this. ;>)

@_date: 2016-06-21 12:48:38
@_author: Paul Syverson 
@_subject: [tor-talk] Question for those who say "Tor is pwned" 
Yes that paper. Not sure what the question is.
Well there's things like alpha-mixing (better tau-mixing) as that
could be used to blend and improve security for traffic of different
sensitivity levels _if_ it can adequately avoid leaking how
paranoid/sensitive different traffic is. Various proposals following on
those lines have been floated, but this needs a lot more analysis to
see how/if it would make sense.
Another thought I've raised to a bunch of people for at least 2-3
years is the idea of semi-synchronous building of Tor circuits. Since
most circuits are built pre-emptively it should be relatively easy to
implement and shouldn't cost much in overhead if all relays, e.g.,
batched and fulfilled all extension requests they received in the last
say 2 seconds, effectively timed mixing of circuit building
cells. This might make it hard for a widescale passive network
observer to trivially identify circuits simply from the building (as
Bauer et al. first explored at WPES 2007).  They would then have to go
into the relayed traffic.
Questions include, how much extra work does this really create for the
adversary? (It doesn't appear to have much overhead, but if it has
even less useful effect, it's not worth it.)  What to do when circuits
are not available (Do you just say screw the delay for those, or bite
that bullet which implies driving a nontrivial fraction of users to
less secure options)? How often _are_ circuits not available
pre-meptively? Does this somehow disproportionally affect a
particularly sensitive class of traffic?  I'm assuming you don't want
to actually synchronize relays here as I could imagine all kinds of
weird congestion effects.  Even if you don't one should do lots of
Shadow experiments or some such (after the prior questions make it
seem worth doing them) to make sure these effects aren't induced

@_date: 2016-06-22 07:16:21
@_author: Paul Syverson 
@_subject: [tor-talk] Question for those who say "Tor is pwned" 
Not sure if accurate is an applicable notion here. I remain hopeful
but dubious about anything that just assumes p2p automatically must be
better for safety and privacy vs. client/server in the long run.
One reason is discussed in section 2.4 of
"Bridging and Fingerprinting: Epistemic Attacks on Route Selection"
For me this remains an open hard area that I continue to focus on.
And people who know me will tell you that I always say, "Dare to be
stupid."  It's very hard to make any decent contributions if you are
too afraid of looking dumb.

@_date: 2016-06-22 08:38:55
@_author: Paul Syverson 
@_subject: [tor-talk] Design of next-generation Tor systems 
Everything's a technical term to somebody. Roughly yes I was
contrasting client/server with anything where every entity is both a
participant and part of the routing infrastructure (in that sense the
first published and deployed onion routing system in 1996 was p2p in
that there was no separation of clients and relays (that was changed
in 1997), although we assumed most end users would be connecting to
onion routers rather than running them locally). The reality is
of course more complex with a variety of centralization/decentralization
features to routing, to directory systems, etc. (The 1997-98 design
separated clients from relays, but planned for a flat distribution
of directory information---which was never fully completed.)
You want to be as decentralized as you can, but not more than that. ;>)
I'll try to watch it when I get a chance.
Sorry I couldn't make it to STRINT. As ever, I'm way behind (probably
shouldn't be taking time for this exchange), but I hope to look at
it more closely as soon as I get a chance.

@_date: 2016-06-23 11:56:37
@_author: Paul Syverson 
@_subject: [tor-talk] Tor is anti-censorship software 
Vitriol aside, the problem is that you don't get to just apply your
own intuitive decisions about the meaning of technical terms and then
complain based on that. To get out of my own technical area to one I'm
guessing is more familiar to those who seem to favor political points
regardless if they make any scientific sense: I could say that
democracy is when each person in a society has a say (vote) on any law
or official decision that society makes.  This is not entirely
unintuitive (and I really don't want to get into quibbles about what's
a person, etc.)  One problem is that, whether that definition is right
or wrong, there are almost no democracies anywhere, and everyone
recognizes that this couldn't scale to societal size in practice. The
closest to this definition in the U.S. might be New England town
meetings. But even small towns typically elect officials to decide
various things. Somebody who decides that is how the term must be used
and thus runs around saying "that's not democratic" about every action
of a town council or school board is not contributing anything
constructive by doing so.
The Tor Project remains the exemplar of being up front about what it
provides and doesn't, what needs improvement, what people have found
about weaknesses etc. (I know simply saying nobody is doing it better
is not an excuse for not trying harder, but it is a standard of
reasonableness). "Anonymity" has some intuitive meaning that has been
articulated to multiple meanings as lots of precise mathematical and
technical analysis teases intuitions out. If you have a better single
word than 'anonymity' that conveys to people who don't want to read
all that technical mumbo-jumbo what Tor provides, I think we would
all be happy to use it. (Well I would anyway.)
Thanks. I do think Tor people work hard not just making good things to
make the Internet a safer more secure place but also trying to figure
out how to articulate that usefully to the broader public. I can say
that many times when I have suggested some more precise description of
what is provided, people who understand public communications way
better than me, gently pat me on the head and explain that nobody's
going to understand what I just said and/or that people will grab some
technical nuance in it and draw the totally opposite conclusion of
what is intended.  Constructive contributions there, as in the
technology itself, would always be welcome.

@_date: 2016-06-27 23:32:20
@_author: Paul Syverson 
@_subject: [tor-talk] Tor is anti-censorship software 
'Anonymity', more specifically communications anonymity. (As I've
already said, I think "anonymity" is somewhat misleading as a term for
practical low-latency traffic security systems because it generally is
used to imply at least soem kind of uncertainty amongst a known given
set. But often for realistic systems the set is neither fixed nor
known.  I talked about this in "Why I'm not an Entropist". There are
multiple definitions used in the research literature, several even if
you limit yourself to ones that are just some type of entropy (shannon
entropy, min entropy, etc.)  Rather than argue about whether or not
something is _anonymous_ according to some imagined platonic form of
anonymity or some such, specify operating environment (network model,
etc.), usage model, adversary model, and security definition. Then
describe how secure a given system is in that context. That's often
hard to do fully for practical systems but the closer you come the
more reliable your statement is. What you want to call it doesn't
matter (except it kind of does because people will quite reasonably
apply their intuitions and prior knowledge to try to understand you ;>)

@_date: 2016-06-30 15:10:42
@_author: Paul Syverson 
@_subject: [tor-talk] Tor is anti-censorship software 
I agree completely, which is why I said in an earlier message in this
  If you have a better single word than 'anonymity' that conveys to
  people who don't want to read all that technical mumbo-jumbo what
  Tor provides, I think we would all be happy to use it. (Well I would
  anyway.)
Intuitions are fine, and necessary for any of us to function in the
world. But once you start to unpack them and talk about whether
something _really_ has property X, then you are moving beyond what
the "average user" is concerned with.
I think your definition is misleading, and I suspect most (all?) who
work in this area would agree with me.  Specifically, it is misleading
to assume 'traffic analysis' must imply a global adversary, whether
observing, active, or a combination of the two. The nutshell way I
have expressed this protection going way back before Tor was that
onion routing generally protects against traffic analysis not traffic
confirmation: it protects against an adversary doing traffic analysis
on a flow it sees. Such an adversary will not learn the
source/destination from that analysis. If the adversary does traffic
analysis in two places, it will most of the time be able to confirm
that it is looking at the same flow of traffic in both places.  This
is a nutshell, but I stand by it as basically correct. Details are
more subtle, e.g., sometimes website fingerprinting can reveal something
about the destination, subject to closed-world assumptions, etc.
Why do you imply the user is dumb? I certainly reject that
characterization of users. I assume that, like myself, most users
can't give an accurate description capturing every important property
of most of the tools they use, microchips, automobiles, airplanes,
etc.  That's not because they're dumb, but because nobody can, or
indeed should try to, know all the important things about everything
they rely on. What I think Tor does well (but could always do better)
is get the gist of things across, and then (more than most other
communities or organizations) provide the means for anyone who has the
time, tools, and inclination to fruitfully probe as far as they wish.

@_date: 2016-03-22 22:39:52
@_author: Paul Syverson 
@_subject: [tor-talk] Extend auto-IP-switching-time in TorBrowser (and 
I'm confused. What is the situation you are concerned about?  A new
stream would go over a new circuit whether the previous stream is kept
alive or not. Is that not so? And I'm not sure what keeping the idle
stream open has to do with this. I understand the UX issues of
switching circuits, and I get the threat if not allowing a stream to
close causes attaching indefinitely to new circuits.  But I don't
understand why it is bad to have a new stream open on a new circuit
after another stream closes that was artificially kept open for a
while vs. having the new stream open after an initial stream closed

@_date: 2016-05-31 08:19:32
@_author: Paul Syverson 
@_subject: [tor-talk] Could Tor be used for health informatics? 
It's not a mutually exclusive situation. Cf. "Bake in .onion for
Tear-Free and Stronger Website Authentication" IEEE Security & Privacy
14(2), March/April 2016.
Most relevantly, from the last section.
  First, currently deployed onion addresses and protocols rely on
  SHA-1 and RSA-1024, both of which have reached the end of their
  effective-security lifetimes. But Tor client and relay software has
  transitioned in stable releases to SHA-256 and Ed25519, which are
  adequate for the foreseeable future. And Tor is expected to
  transition onion services to these cryptographic primitives within
  the year.  Therefore, any valid objections based on this concern
  will be short-lived. More important, when combined, onion
  protections can only add to TLS and certifcate protections. Breaking
  the private RSA-1024 key associated with an onion address that has
  an appropriately stronger TLS key and certificate doesn?t, by
  itself, allow an attacker to subvert a certified TLS session with
  the onionsite. Conversely, MITM, cipher degradation, or other
  certificate or TLS instance attacks aren?t possible with onion
  addresses unless the attacker also breaks the self-authentication.
This was directed at sites that aren't concerned about location
hiding, just better authentication and confidentiality of content.  So
had slightly different context than as Nate is addressing for IoT, but
these points apply whether or not one wants the onion service to be
hidden or not.
Great slides. Thanks Nate.

@_date: 2017-08-03 20:05:09
@_author: Paul Syverson 
@_subject: [tor-talk] Comments? 
Ermm, brilliant. ;>)
More seriously. The point of this work is not to propose attacks per se but to observe that a Tor adversary intending to target individuals or
specific groups might be much more effective against those targets
than would the usual "hoovering" adversaries described in the literature,
even if it has roughly the same resources as the usually considered
adversaries. (Hoovering adversaries simply try to gather as much as
they can indiscriminantly.) And we observed that targeting adversaries
are in various ways more realistic. We suggested that Tor design changes
and security analyses should take targeting into account going
forward. That was our main point. We also proposed some
countermeasures for the specific example attacks we introduced to
illustrate that point, some of which I think are original (onionsite
templates) while others are part of territory already explored for
other reasons (guard layering and different guard-set sizes and

@_date: 2017-08-08 13:18:31
@_author: Paul Syverson 
@_subject: [tor-talk] Comments? 
Ermm probably? I just don't recall completely now weeks later, though
I remember we did fill up the remaining time. Let's see, I had an
exchange with ermm maybe Prateek Mittal, where in response to his
question I emphasized that we weren't suggesting ignoring the
prospects of a hoovering adversary. In fact hoovering might be the
source of some of the inputs an adversary might use to decide to
target an individual, group, or destination. But, it would then be
more likely for the reasons I presented, for an adversary to follow a
targeting strategy even if it had hoovering capabilities already set
Another point that was raised to me in a side comment after the Q&A
was that what I said about evidence for onionsite fingerprinting from
the Oakland poster by Juarez et al.could have been interpreted
differently than I intended.  They showed in that work that
identifying a circuit as an onionsite connection (vs. not an onionsite
connection) via fingerprinting from the middle relay on the client
side was 99.98% effective. They didn't address fingerprinting specific
sites therein. I stand by our claim that given the smallness of the
space and other factors that such fingerprinting is likely for current
Tor and onionspace to be very effective. (Once we make all my
grand-vision changes to onionspace that I'll talk about in my ESORICS
keynote paper, that could well change. But that's c. 5-10 years away
at this point.) Which leads us to...
No we haven't yet tried this in practice. As usual, it is hard to set
up an experiment like that in a way that adequately protects user
safety and privacy. There is work in progress that has gone through
review by the Tor Research Safety Board and will use PrivCount to
gather information about the amount of activity on a particular known
and public onionsite.  But it's still very much in the works.

@_date: 2017-08-23 07:35:26
@_author: Paul Syverson 
@_subject: [tor-talk] MTor (multicast tor), is it going to be released? 
Right. The primary author had graduated and moved on to other things c. a year and a half ago.
Main differences were (1) a multicast root is selected amongst
(adequate-weight) available middle relays that will mate all
connections to it for that multicast session, (2) that any relay that
is part of a multicast session has a session group identifier (GID),
(3) that if a circuit building request hits a guard or middle relay
already participating in the session, it connects that circuit to its
existing group circuit, and (4) optionally, the set of relays to
select a middle hop from is restricted for deduplication benefit.
Our analysis showed that for small to moderate sized groups on the
existing Tor network, absent a pretty restricted middle-hop set, there
was virtually no deduplication (hence a star, which still saved over
all pairs).  If curious, you can see our security analysis of MTor
against targeting adversaries (also analysis of a group chatting via a
private IRC channel and of people connecting to the same onion
service) here:

@_date: 2017-08-31 06:52:00
@_author: Paul Syverson 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
In "The Once and Future Onion" I contrast onionspace with "the
less-secure web" rather than the insecure web. I think it's a bit more
accurate term: as one example, there is a difference between an
HTTPS-protected (and HSTS enabled, etc.) site and a vanilla HTTP site.
(I also note that going through Tor Browser in general provides the
ordinary user with more route information than they otherwise
have---indeed authenticated route information. And I underscore this
with the phrase "the alliuminated web".)
This article is for a keynote talk I'll be giving at ESORICS in a few
weeks. The proceedings will be published by Springer and the talk hasn't
been given yet, but you can get the paper right now from I also mention this point, as well as integration with HTTPS Everywhere in
"The Once and Future Onion".

@_date: 2017-08-31 07:01:21
@_author: Paul Syverson 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
As the cryptographic design changes for next generation onion services
are now being rolled out, that
in-my-opinion-never-actually-well-grounded concern will go away. I
cover at a high level, a design for onion altnames in "The Once and
Future Onion" [1] that I think is consistent with the current CA/B
Forum issues about onion addresses. It doesn't cover all desired
cases, so I hope you are successful. But I think it covers a lot of
the ground.
[1]

@_date: 2017-02-20 11:33:50
@_author: Paul Syverson 
@_subject: [tor-talk] Finally a Cloudflare captchas workaround thanks to 
Griffin Boyce and I published a paper not quite a year ago with a
section addressing this topic.  It covers much of the same ground as
Alec's fine post (still included below), give or take a few points.
And it supports the statements of the OP about cryptographic strength
and onion addresses. As we note, I can't make sense of the objections
to DV certs even given the weaker cryptographic strengths prior to the
changes. They would still be an effective strengthening over the
status quo ante. In case it's useful, I'm including that short section
just below.
As to the main question asked about whether this could solve
issues/concerns with Cloudflare captchas, my guess is it's just a bit
early in these developments to do more than speculate.

@_date: 2017-01-19 07:14:09
@_author: Paul Syverson 
@_subject: [tor-talk] Tor transparent proxy -> strange behavior regarding 
This is an onion address. Ordinarily configured Firefox will not recognize
it as such and simply generate a DNS request. As per IETF RFC 7686,
"Applications that do not implement the Tor protocol SHOULD generate
an error upon the use of .onion and SHOULD NOT perform a DNS lookup."
So your Firefox is performing appropriately. To go to the onion address for FaceBook you should use Tor Browser.

@_date: 2017-06-20 08:23:56
@_author: Paul Syverson 
@_subject: [tor-talk] Is the recent growth in Ukrainian users confusing 
You are assuming a hidden (double) onion service.
Facebook uses a single onion service.

@_date: 2017-09-20 08:19:08
@_author: Paul Syverson 
@_subject: [tor-talk] Unusual Tor's spikes in Egypt and Turkey on 28th 
I'm pretty sure he means putting it on a single-onion service, so no
exit relays at all and actually more security than accessing the
server via a circuit that exits Tor protection. Cf.
or for a recent high-level overview of previous and potential
developments in onion services

@_date: 2018-08-08 20:51:04
@_author: Paul Syverson 
@_subject: [tor-talk] HSTS forbids "Add an exception" (also, 
You may be interested in our paper "HSTS Supports Targeted Surveillance"
that we will present at FOCI next week
Amongst other things, it discusses some of the issues raised in this thread.
They will post the paper on Tuesday, but if someone wants a copy now,
let me know.

@_date: 2018-09-29 23:35:28
@_author: Paul Syverson 
@_subject: [tor-talk] Tor browser and VPN or web proxy 
While that is all roughly on-average correct, it depends entirely on your
adversary and intended activity. (You might not be average.)  If, as
one example, you need to connect to a corporate VPN and you don't
want a local adversary (such as the ISP) to know your affiliation with
that corporation, then this is the order to do things.

@_date: 2019-05-02 16:15:03
@_author: Paul Syverson 
@_subject: [tor-talk] [tor-relays] Anti-Sybil (re: Explain... all the 
Note that we created a research system for gathering such data,
reasoning about the trust implications, and applying it to routing
decisions. we wrote a paper on it that we presented at PETS 2015.
"20,000 In League Under the Sea: Anonymous Communication, Trust,
MLATs,and Undersea Cables"
I don't know that anyone has done much with this since, but I hope
that's helpful information.
