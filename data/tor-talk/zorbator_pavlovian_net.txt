
@_date: 2007-04-09 13:07:07
@_author: Ben Wilhelm 
@_subject: Another Method to Block Java Hijinks 
I've been running Tor clients and servers under VMWare Server for a while now. I do my secure browsing inside a dedicated VM, and my firewall is set up to block all outgoing traffic from the VM. The VM connects directly to my Tor server (on another VM, though that's not as important) which itself connects to the outside world. It's not quite ideal because in theory that VM could snoop around my LAN and report on stuff, but I could disable that with some more work (putting that VM in a dead-end virtual network so it can't talk to anything except a Tor server), I'm just lazy and don't think that's really likely to be an issue.
VMWare Player ought to be possible to set up so that it runs behind a DHCP server on whatever is running VMWare. VMWare Server definitely is.

@_date: 2007-07-20 23:39:45
@_author: Ben Wilhelm 
@_subject: Tor takes too much RAM 
# free
              total       used       free     shared    buffers     cached
Mem:         98520      96772       1748          0       2220       5848
-/+ buffers/cache:      88704       9816
Swap:        65528      58480       7048
# killall tor
# free
              total       used       free     shared    buffers     cached
Mem:         98520      41464      57056          0        644      10356
-/+ buffers/cache:      30464      68056
Swap:        65528      22496      43032
I'd love to keep it running, but when it's singlehandedly chewing up more than half of my system's RAM, it just isn't going to happen. Any suggestions on this? Are there config options I can tweak to make it a little less RAM-hungry, or is it just intrinsically a memory gobbler?

@_date: 2007-07-21 00:33:28
@_author: Ben Wilhelm 
@_subject: Tor takes too much RAM 
Here's some docs for you to look over, since you clearly don't know the free command.
 (look at "interpreting free".)
Also, running it on a system and comparing the output to /proc/meminfo can be enlightening. I find it gives a good overview of what the system is doing - "top" might say "hey this program is using a lot of memory", but "free" can tell you "this entire system is struggling" on the commandline, which is occasionally much nicer than opening up top. I would have included top output except that I didn't think of posting to the list before doing this, and I suspect that starting tor cleanly would not have demonstrated the memory usage as well.
Essentially, it's telling me that before I killed tor, I had 7m of swapfile and 1.7m of RAM free. Deducting buffers and cache, I had a whopping 10mb of RAM free. After I killed tor, that changed to 43mb of swap and 57mb of main memory free, with 11m used by buffers and cache. Note that the former was after I'd killed apache and mysql in an attempt to have a usable command-line - I imagine it would have looked worse if I hadn't already done that.
So, essentially, tor was eating 90mb or so of RAM at that point. Considering Olaf's hilarious 1.5gb example, I guess I was getting off

@_date: 2007-07-21 01:30:46
@_author: Ben Wilhelm 
@_subject: Tor takes too much RAM 
It does have vmstat. I should point out, however, that vmstat shows pretty much the exact same stuff that free does, only with less math done for you, a few important missing numbers, and a few added numbers which aren't really important in this case.
(This is a different server, which is why it has more RAM)
$ vmstat && free
procs -----------memory---------- ---swap-- -----io---- -system--   r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
  0  0   2716  27472 143508  20876    1    1     1     3    3    3  3 12 77  7
              total       used       free     shared    buffers     cached
Mem:        385840     358368      27472          0     143508      20876
-/+ buffers/cache:     193984     191856
Swap:       369452       2716     366736
Tor is currently disabled on that first server because I run other things on it that I'd rather stayed functioning :) My relatively small 90mb usage is pretty meaningless compared to the 1.5gb usage of others, though, and on my other computer it's using 136m RES according to top.
   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
24579 zorba     15   0  148m 136m 4724 S  5.3 36.3 278:10.78 tor
It's not a local system, so I didn't have an easy way of seeing a hard drive indicator. I can tell you that I was having literally thirty-second-long delays just trying to use the command line, which went away when I killed tor. So I suspect it was swapping like a mofo.
Version 0.1.2.14 - I'm just updating with Debian (unstable, I suspect.)

@_date: 2007-07-21 06:42:04
@_author: Ben Wilhelm 
@_subject: Blocking child pornography exits 
>      Not AFAIK.  It blocks exits for whatever ports you tell it to block exits
 > for.  The sample torrc that comes with the package has several example lines
 > that you can uncomment or that you can simply use as examples for syntax when
 > writing your own ExitPolicy statements.  One of those may be an  > reject *:25", but it starts out, IIRC, having only an "ExitPolicy reject *:*"
 > statement uncommented for those who want to dabble in running a  > server.
For quite a few versions, Tor has come with a significant number of ports blocked, including standard ports for email, exploits, and p2p filesharing. I don't know if this is still the case, but if not, it's changed recently.
The relevant code, which seems to still be active, starts at line 542 in policies.c, and I'll copy the exit policy itself and relevant comment in:
 DEFAULT_EXIT_POLICY                                         \
   "reject *:25,reject *:119,reject *:135-139,reject *:445,"         \
   "reject *:465,reject *:563,reject *:587,"                         \
   "reject *:1214,reject *:4661-4666,"                               \
   "reject *:6346-6429,reject *:6699,reject *:6881-6999,accept *:*"
  * cfg doesn't end in an absolute accept or reject, add the default exit
  * policy afterwards. If rejectprivate is true, prepend
  * "reject private:*" to the policy. Return -1 if we can't parse cfg,
  * else return 0.
  */
So chances are that if you haven't explicitly added an absolute accept or reject to the end of your cfg, you're blocking a large number of ports that the tor developers have decided they don't want on their network.
Last I heard, the tor developers did this solely to keep the network usable, and not for moral reasons. But I may be wrong on that. Nevertheless, trying to block something as nebulous and illdefined as "child pornography" is obviously a far, far different thing than simply blocking a pile of ports frequently used for p2p traffic. Tor doesn't even try to recognize common p2p packets, so hey.

@_date: 2007-07-21 20:13:15
@_author: Ben Wilhelm 
@_subject: Blocking child pornography exits 
I believe you're misinterpreting the comment - that particular default exit policy is appended in all cases unless the torrc ends with reject *:* or accept *:* (note that the only likely reason for that is efficiency, since it would have no effect if it was appended in those I seem to remember that the vast majority of servers did have that default policy in their exit policy, but I can't find a link to a good ol'-fashioned Tor directory server list so I can't demonstrate that right now.

@_date: 2007-11-07 05:19:39
@_author: Ben Wilhelm 
@_subject: some civically irresponsible exits? 
Devil's advocate position: No, you can't. You can't connect directly to any user to send spam directly to their inbox. You *can* connect to arbitrary mail servers and request that they spam users, but that's their problem, not Tor's.
I think blocking port 25 is probably the right thing to do as a default, but I personally have all ports open on my server.

@_date: 2007-10-13 06:07:24
@_author: Ben Wilhelm 
@_subject: Browser dos/don'ts ( was Re: Incognito Live CD using Polipo) 
I disagree. Don't do anything that makes you stand out. That includes changing to a multitude of fake user-agents.
Pick the most common user-agent and use it. That's probably whatever the latest version of Firefox returns. (I'm assuming Tor traffic is firefox-heavy - I may be wrong on this. IE6 or IE7 may be a better choice. Remember, they can tell you're probably coming from Tor, so you want to blend in with average Tor traffic.) Then only change it if the "most popular browser" changes.
That way you blend in with the herd. It's easy to track the guy who's using Bob's Krazy Web Browzur one day, and xXxDeAtHxXx the next day, and "lol ive got a new useragent today" after that. It's not so easy to track one guy out of ten thousand using Firefox.

@_date: 2007-09-30 15:49:21
@_author: Ben Wilhelm 
@_subject: Google indexes onion links 
I don't really see a problem with it. It's still just as anonymous for the server, it's just not as anonymous for the viewer. Honestly, if anything, it's a good thing - it means you don't need to go install Tor if you want to read anonymous people's posts, as long as you don't feel the need to be anonymous yourself.

@_date: 2008-02-16 10:39:00
@_author: Ben Wilhelm 
@_subject: Compromised entry guards rejecting safe circuits (was Re: OSI 
You're suffering from several very serious misconceptions.
First off, the Mersenne primality testing network is designed to test prime numbers of a very specific type, namely 2^n-1. It turns out that you can test primality for those numbers in a much more efficient manner than for general primes. The Mersenne algorithm is useless for general primes, and virtually every prime used in modern cryptography is not going to be a Mersenne prime.
Second, merely testing to see if something is prime is not isn't particularly helpful in breaking modern cryptography. You already know that the public key isn't a prime (since it's the product of two private keys) and you also already know that the private keys are prime (since that's necessary for the algorithm to function.) What you'd need to do in order to derive the private keys from a public key is to *factor* an extremely large number with no convenient properties. This is an entirely different issue from mere primality testing.
Without major breakthroughs in number factoring, I seem to remember it's actually provable that modern public keys literally cannot be factored within the heat death of the universe. As in, "if you turned every atom of the universe into energy, and used it to power a universe-sized supercomputer which reaches the theoretical limits of efficiency, you would not be done factoring a single public key by the time you ran out of energy". Unless you want to claim that the US government is actually *more powerful* than this, any number of supercomputers and databases they might have is completely irrelevant.
Now, if you do want to keep on with the "the government is all-powerful and can corrupt Tor installations easily", there's a few easy tactics you can use.
First, you can claim that the US governmenet has come up with a factoring breakthrough that makes factoring - and thus far, far easier. There's certainly nothing we've discovered yet that proves this is impossible. Of course, there's no evidence for it being possible either.
Second, private keys are only as secure as they system they are stored on. Much more plausibly, you could claim that the US government has backdoors into most (if not all) modern OSes, including the ones used to generate Tor's directory server private keys. If the government got the private keys that way there would be, of course, no barrier to them intercepting Tor communications in exactly the way you claim.
But claiming that the government has huge datacenters that derive public keys from private keys is simply impossible. The math doesn't add up.
Now for a bit of hard math, just to demonstrate that you need to think about your numbers a bit further:
The density of prime numbers can be approximated as 1/log(N), as you've mentioned. This means, for 256-binary-digit primes, the density is approximately 1/log(2^256) or 0.012976. There are 2^255 (that's about 5.7896 * 10^76) 256-digit numbers, therefore we can assume that there are approximately 1/log(2^256) * 2^255 primes in that area.
This is approximately 7.5127 * 10^74 primes.
If we assume we can store each prime number on a single atom of hydrogen (this is obviously a hilarious overestimation of storage density, but bear with me) we can store 6.02214 * 10^23 prime numbers in one gram of hydrogen. Thus we will need 1.2475 * 10^51 grams in order to store our "prime database". The Sun masses approximately 1.98892 * 10^33 grams, so we'll need the hydrogen of approximately 627 thousand million million suns merely to store a list of all the 256-digit prime numbers.
If Tor uses 512-bit keys then we're approximately seventy orders of magnitude too small, however.
(That was actually kind of fun to work out.)

@_date: 2008-02-16 12:38:24
@_author: Ben Wilhelm 
@_subject: Compromised entry guards rejecting safe circuits (was Re: OSI 
You're continuing to drastically underestimate the numbers involved. Let's say that a computer is a cube, one half foot on each side. Now let's take the Earth, and *cover the Earth with solid computers* to a depth of one mile. This gives us approximately 232 billion billion computers. If you assume that each computer can generate a thousand private/public pairs per second (I believe this is an exaggeration for commodity hardware, though you could likely build a custom system to do so) then that means we get 2.32 * 10^23 keys every second.
I'm going to go handwavy here and assume that one key is approximately equal to one prime. This isn't true, but we'll end up within an order of magnitude of the right answer, and honestly more precision than that isn't needed.
With 7.5127 * 10^74 primes, attempting to cover 1% of the keyspace at 2.32 * 10^23 keys per second would take approximately one million million million million million million million *years*. Excuse me for not being particularly worried about this. And remember, this assumes the entire surface of the planet is covered, a mile thick, with computers. Last I checked this was not the case.
(Again, this also ignores the issue of where you store all this data.)
Seriously, sit down and think about the numbers some. The numbers are *gigantic* - so gigantic that "brute force" becomes implausible, even if you assume the adversary owns all the government and corporations of our world and has access to alien supercomputers.

@_date: 2008-02-01 22:59:18
@_author: Ben Wilhelm 
@_subject: The use of malicious botnets to disrupt The Onion Router 
A manually administered . . . centralized list? Because, call me crazy, but a centralized list of "authorized routers" has some very, very obvious flaws in it, both technical and security-related.

@_date: 2008-02-17 09:29:29
@_author: Ben Wilhelm 
@_subject: Compromised entry guards rejecting safe circuits (was Re: OSI 
Yes, this is correct - if you use a horrifically insecure random-number generator, you'll end up with a horrifically insecure public key. Any serious application of crypto will use a random-number generator with far more than 16 bits of entropy. I don't actually know what the current standard for pseudo-random crypto generators are, but I give as a simple example Boost's Mersenne Twister generator, which, as I understand it, can be given something on the order of 20,000 bits of entropy as a seed. (Obviously, this is far more than is strictly needed to generate all 256-bit primes.)
This is untrue in several ways. There's nothing in the structure of a psuedorandom generator which makes it impossible to analyse, and many pseudorandom generators are understood extremely well. Again, this isn't something I'm particularly expert in, but it's a solved problem to roughly the same extent that the entire public-key cryptography issue is a solved problem (i.e. "solved, barring spectacular and unexpected Note that you could simply use a source of truly secure entropy to bypass these issues entirely, and most non-embedded operating systems include such a thing built-in.
We've described logically why your original attack would not work (at least, why it would not allow any kind of security breaches - obviously you can bring the Tor network down using such an attack, but that's not exactly avoidable.) It is neither intact nor correct, and, assuming no security bugs in the Tor implementation, I believe it is provably so.

@_date: 2008-01-04 07:30:37
@_author: Ben Wilhelm 
@_subject: Tor server using Vista? 
Amen to that. Out of all the systems I've administered, I've had zero Windows boxes compromised and one Linux box. And that isn't because Linux is "less secure" - it's because I knew Windows a lot better by the time I started doing stuff online, and I didn't know enough Linux at the time to realize I was making a horrible security vulnerability with one bad decision.
The most secure operating system in the world will be insecure in the hands of someone who doesn't understand it. The least secure operating system - which is probably Windows at the moment - can still be run quite securely if you keep on top of it.
I use Windows as a desktop system, and keep it behind an OpenBSD firewall/router. If for some reason I felt like this was the system I had to run a Tor server on, I'd run it on this system with little worry of compromise.

@_date: 2008-01-24 04:49:33
@_author: Ben Wilhelm 
@_subject: Child pornography blocking again 
* Use of effort that could be spent other places
* Possible legal liability issues
* Cries of "you're blocking child porn, why not also block warez/hate speech/freenet/political propoganda that I don't like"
* Every single problem that comes along with trying to maintain a blacklist, including malicious submissions, manpower, filtering
And, the biggest problems to my mind:
* If the blacklist is stored on some central server, creating a very nice system where people must report what they're browsing to a central * If the blacklist is stored in a downloadable form of any kind, effectively making a *list of child pornography sites*
The second might be avoidable through some clever hashing, but that simultaneously eliminates any sort of accountability or auditability, and as much as I like the Tor guys I don't want them to be able to knock entire sites off the Tor network.
(I'm also kind of entertained at the idea of a privacy group saying, effectively, "okay now that our behavior is no longer trackable please send us all the kiddieporn sites you know of thanks in advance".)

@_date: 2008-01-24 05:51:52
@_author: Ben Wilhelm 
@_subject: Child pornography blocking again 
One could easily argue that the transmission of child porn doesn't hurt children at all, and it's the *production* that does. From there, you run into a supply and demand argument - the more supply there is, the lower the demand is. Economically speaking, legalizing the transmission of child porn might actually *reduce* the harm done to children.
Obviously, this doesn't count the people who may get interested in pedophilia thanks to child porn, the people who may decide to produce some now that it's easier to transmit, or - on the other side - the people who end up *not* committing any of the pedophilia-related crimes due to being able to *ahem* get their frustrations out with porn.
It's not a clear-cut case at all, in any direction, and I would personally rather Tor stuck to their original game plan ("anonymous internet access") than any kind of grafted-on possibly-counterproductive morals ("anonymous internet access for the things that we personally feel are morally justifiable with a day or two of thought").
(On the same vein one could actually argue that warez is worse, as economically, warez discourages production of software, using the same logic where freely distributed child porn discourages production of more child porn. The situation isn't really parallel though - child porn is illegal to produce and that changes the system quite a bit.)

@_date: 2008-01-25 01:23:09
@_author: Ben Wilhelm 
@_subject: Child pornography blocking again 
Actually, I disagree - the April Fool's joke was obviously a joke, while your suggestion - which is dangerous and badly designed on several fronts - could be taken seriously be people.
If you can solve all those problems, there might be something to it, but I personally do not believe that those problems are solvable.

@_date: 2008-03-21 12:32:19
@_author: Ben Wilhelm 
@_subject: More GSoC Ideas 
Various comments on these, regarding why some of these are dubious ideas:
You will never, ever, ever block all child porn websites. It's simply impossible. To make things worse, in the US there's at least some possibility that filtering things by content leaves you open for lawsuits based on what you didn't filter - meaning that blocking child porn websites might leave you liable for the ones you missed. From a purely PR perspective, people might also argue "well, he clearly knew child porn was being viewed through his server, and he kept his srever up! Burn him, he's a witch!"
I don't really have a problem with this one :) (Although if you can get a second IP from your ISP, this can be solved neatly - I have all Tor traffic going through its own special IP. Still, this is often impractical.)
The Pirate Bay itself uses extraordinarily little bandwidth, and to my knowledge nobody has ever been prosecuted for downloading .torrent files. The actual process of running the torrent doesn't necessarily even touch TPB (what with distributed hash tables and the like) and even the parts that do touch TPB use a minimal amount of bandwidth. Essentially, this doesn't do what you might think it does.
First off, it's nearly impossible to make Tor capable of filtering on this sort of a level - the Tor client simply doesn't know what kind of traffic may be sent through it until the connection is already made, and thus it can't possibly avoid servers that disallow certain protocols. The only thing you could do here is sever connections as soon as you determine that it's the "wrong type" and this obviously has severe usability implications.
Second, an increasing number of protocols are encrypted, thanks to the efforts of Verizon and co - I certainly turn on encryption on my bittorrent client whenever I use it, and I don't even use it to download illegal stuff. Obviously anything encrypted will pass straight through your clever protocol filter.
I think they may be even more irritated when you assure them that legal-preteen.com is blocked, and then the FBI shows up wanting to know why they're visiting hot-hot-hot-15-and-under.com :)

@_date: 2008-05-18 13:10:01
@_author: Ben Wilhelm 
@_subject: USAF wants to violate federal criminal law 
Yes, the great strength of Linux is that there are never massive pervasive security holes, and even if there were, they would certainly be fixed within days.
Oh wait,  - whoops! Linux has serious long-term security breaches also!
Well, at least there aren't any constantly-exploited packages with a history of insecurity that are still commonly used, oh wait ha ha  yes there are.
Is Linux *more secure*? Absolutely. Does Linux let you walk along in cheerful oblivion, knowing that the Grandmaster of Linux won't let any security holes onto your computer? Not in the least. If you don't watch where you go, you won't fall through as *many* security holes - but you'll still fall through a few.
Claiming that isn't the case, especially with such a horrible counterexample mere days ago, isn't really inclined to make people believe you.

@_date: 2008-05-18 13:16:18
@_author: Ben Wilhelm 
@_subject: USAF wants to violate federal criminal law 
You may want to read  for information on what "accept interference" means. Basically, it means that it must not explode or melt down - not that it must take orders from arbitrary other people and send them your credit card numbers.
 > This httpS message sends the wire negotiated encryption key over the
 > wire WITH the "encrypted" data. Do you frequently write the lock
 > combination on the safe or tape the key to the lock when it is left in
 > hostile environments?
I think you really, really need to go learn more about cryptography and the https protocol, as there's no point where what you described actually happens. The closest is when the client sends a chunk of random data to the server, which they both use to generate the encryption keys . . . and this only happens once it's already encrypted by the server's public key, meaning nobody besides the server can read it.
As a side note, HTTPS is basically HTTP wrapped in an SSL/TLS session . . . and guess what Tor uses? If it's as insecure as you claim, Tor is pretty hilariously broken.

@_date: 2008-05-18 13:31:51
@_author: Ben Wilhelm 
@_subject: Ports 443 & 80 
As I understand it, there's still a problem here - Tor thinks it's listening on port 9001, so it'll advertise to the directories that it's waiting on port 9001. Which obviously won't work all that well if they have to connect to port 80.
Here's what the relevant section of my torrc looks like:
 Required: what port to advertise for Tor connections.
ORPort 80
 If you want to listen on a port other than the one advertised
 in ORPort (e.g. to advertise 443 but bind to 9090), uncomment the
 line below too. You'll need to do ipchains or other port forwarding
 yourself to make this work.
ORListenAddress 0.0.0.0:8080
There's a chunk below it for directory ports also, although I have that disabled due to low bandwidth.

@_date: 2008-05-19 01:10:01
@_author: Ben Wilhelm 
@_subject: hidden service maps 
They're hidden in the sense that their physical location is a secret. They can be listed on other hidden Tor services (or even on normal webpages) and accessed like normal, but there's theoretically no way to track down who exactly is providing the service (with the same set of guarantees as tor normally provides, of course).

@_date: 2008-05-19 01:52:18
@_author: Ben Wilhelm 
@_subject: hidden service maps 
No prob. :)
Short answer: Yes.
Longer answer: Yes, but it's a little more difficult. The application can't try to connect via IP, because hidden services don't have IPs. It has to connect via a hostname. As I understand it, this means the application must be using SOCKS 4a or SOCKS 5, and also must be set up to do that - a lot of applications simply aren't, and expect to be able to resolve the host and then connect to the IP in two separate steps. Which, in fairness, works in virtually all cases.
If the application is properly coded, then, yes, any system which doesn't break the network layering hierarchy will work just fine, given an appropriate onion address.
It would presumably be possible to rig up some kind of wacky system that mapped private IPs to onion addresses on the fly, but Tor doesn't have that yet (and I don't know if they've even bothered considering implementing it, there are bigger issues.)
