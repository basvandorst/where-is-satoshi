
@_date: 2007-04-23 18:41:19
@_author: Mike Cardwell 
@_subject: Open DNS 
>
I think you misunderstand the meaning of the word "scam".
If you'd spent two minutes reading their website you would have noticed that by signing up for an account you can turn off the feature you mentioned above. It's called "typo correction" and is described:
"When OpenDNS receives a request to resolve a domain which does not exist (known to techies as NXDOMAIN or RCODE 3), OpenDNS first attempts to correct any known typos and resolve the domain again. If that fails, OpenDNS uses the request as a search query to give you a page of search results. If you turn this feature off, you will no longer have us correct typos for you. Note: mail servers running DNSBLs and URIBLs work fine with typo correction enabled."
You can hardly blame them for turning this on by default and using the advertising. But you can certainly applaud them for making it optional. It is a FREE service after all.
That could be them doing typo correction for you. As far as I can see they're bloody fast. Your lack of knowledge about how their system works, the fact that you never posted any benchmarks, and you're poor usage of the word "scam" makes me disregard your speed comments.
He never said he'd do that. But guess what, if he wanted to do it, he could turn off the advertising.
That's not what he said he'd do.
Read their documentation. Everyone else, ignore this guy and check out the service yourselves.
P.S. I have no relationship to this site in any way other than having a peak at it a year or two back, and just signing up for a new account.

@_date: 2007-04-23 19:41:13
@_author: Mike Cardwell 
@_subject: Example hidden service issue 
*snip option two*
Just a reminder as it's been a few weeks since this discussion. The "bad" hidden service instructions are still up in the online documentation. I left option one above as I think that should be the option used, at least in the short term until someone gets around to writing some more extensive documentation.

@_date: 2007-04-23 22:23:56
@_author: Mike Cardwell 
@_subject: Example hidden service issue 
Thanks. I was just checking it hadn't been forgotten :)
It fixes the issue I raised. It all makes sense to me and is clear to follow, but then I'm speaking as someone that already understood how to do it... Regardless, complicated yet safe documentation is preferable to simple yet unsafe documentation.

@_date: 2007-04-26 11:53:23
@_author: Mike Cardwell 
@_subject: bandwidth limit strangeness 
I'm running a tor server called 'Grepular'. At the moment it's a
"partial" exit node in that it only exits a few specific ports. It's
also a directory mirror. I'm running version 0.1.2.13, with this
SocksPort          9050
SocksListenAddress 0.0.0.0
RunAsDaemon 1
DataDirectory /var/lib/tor
ControlPort 9051
BandwidthRate          64KB
BandwidthBurst         64KB
MaxAdvertisedBandwidth 64KB
Nickname grepular
Address tor-node.grepular.com
ORPort 443
ORListenAddress 85.234.136.20:9001
DirPort 80
DirListenAddress 85.234.136.20:9030
ExitPolicy accept *:20-23,accept *:53,accept *:109-115,accept *:123,accept *:143,accept *:389,accept *:465,accept *:587,accept *:636,accept *:989-995,accept *:1080,accept *:6660-6667,reject *:*
I use the following iptables rules to redirect port 80 and 443
connections to the actual ports tor is listening on:
iptables -t nat -A PREROUTING -d 85.234.136.20 -p tcp --dport  80 -j DNAT --to-destination 85.234.136.20:9030
iptables -t nat -A PREROUTING -d 85.234.136.20 -p tcp --dport 443 -j DNAT --to-destination 85.234.136.20:9001
With the bandwidth limits set as they are, why is tor using up nearly
1 Megabit per second? I thought it might be the directory mirror not
being counted in the bandwidth usage, but from googling, I see this
shouldn't be the case?
I have much more spare capacity than 64KB/sec but I'm loathed to
increase the current limits in my config until I'm confident I
can accurately control the usage.

@_date: 2007-04-26 11:57:17
@_author: Mike Cardwell 
@_subject: Accept-encoding: gzip 
As a directory mirror, current requests for the mirror data cause about
2.7MB of data transfer. If the data could be delivered compressed with
gzip that could significantly reduce the transfered data...
The main benefit of this being more bandwidth available for routing
instead of directory transfers. This could be done in a backwards
compatible fashion simply by using the http "Accept-encoding: gzip"
option. This could even be an option that you enable/disable from
the torrc. Am I right? Or am I missing something?

@_date: 2007-04-26 12:02:41
@_author: Mike Cardwell 
@_subject: Behaviour of "Address" on a multi-ip server 
My server has many IP addresses. I was paranoid that even though I set
"Address" in my configuration, outgoing connections might originate from
one of the other IP 's on the server. So to combat this I use the
following iptables rule:
iptables -t nat -A POSTROUTING -s ! 85.234.136.20 -m owner --uid-owner debian-tor -j SNAT --to-source 85.234.136.20
Where 'debian-tor' is the user my tor process runs as, and
85.234.136.20 is the IP I want all tor outgoing connections to appear
My question is. Is this a waste of time? Does tor already originate
connections from the same IP it listens on? If not, it should... At
the very minimum, it should be a documented issue.

@_date: 2007-04-26 16:45:39
@_author: Mike Cardwell 
@_subject: ip-port.torhosts.nighteffect.us and exim 
I've been looking into how to use this with Exim4. I just thought I'd
share it here for the benefit of the archives.
warn dnslists    = $interface_port.${sg{$interface_address}{\N^(\d+)\.(\d+)\.(\d+)\.(\d+)$\N}{\$4\.\$3\.\$2\.\$1}}.ip-port.torhosts.nighteffect.us
     log_message = This connection is coming from a tor node that allows exiting to this ip/port combination
The ACL simply logs the connection, it doesn't perform a rejection, or
adding a header to the message or anything else. That part is left to
the reader or the exim users mailing list.
It was made slightly more difficult to use by the fact that I had to
reverse the 4 octets of the IP address of the host being connected to. I
understand why this was done though and agree with it.
Just out of interest, why do lookups that return positive results take
such a long time? This is what I typically get:
server:~# time host 20.136.234.85.109.123.123.123.123.ip-port.torhosts.nighteffect.us
20.136.234.85.109.123.123.123.123.ip-port.torhosts.nighteffect.us has address 127.0.0.2
Host 20.136.234.85.109.123.123.123.123.ip-port.torhosts.nighteffect.us not found: 2(SERVFAIL)
Host 20.136.234.85.109.123.123.123.123.ip-port.torhosts.nighteffect.us not found: 2(SERVFAIL)
real    0m23.451s
user    0m0.030s
sys     0m0.010s
The first line of response is pretty quick, then there are long delays
before each SERVFAIL...
If the lookup returns an NXDOMAIN, there are no SERVFAILS so the lookups
are much faster. I'm not a DNS expert so I'm not sure what is happening
that causes the SERVFAIL's...

@_date: 2007-04-27 11:38:25
@_author: Mike Cardwell 
@_subject: bandwidth limit strangeness 
You guessed correctly. Makes more sense now I've rtfm. I've upped my
available bandwidth a little and have been using this over night:
BandwidthRate  128KB
BandwidthBurst 256KB
Looking at my actual bandwidth usage, it does seem to work as
advertised. :)

@_date: 2007-04-27 11:41:18
@_author: Mike Cardwell 
@_subject: Accept-encoding: gzip 
Hmmm, my mistake. Thanks for the info. I tested this by simply doing a
wget on the ip:port combo where my directory is. And then manually
sending an Accept-Encoding header to see if it sent stuff compressed.
I think I'm finally starting to get my head around the way it works
now! :)

@_date: 2007-04-27 14:42:46
@_author: Mike Cardwell 
@_subject: Tor nodes blocked by e-gold 
Sorbs have *many* different lists. They do not just list sources of spam,
and nor do they claim to. See If someone ignorantly decides to start blocking mail or http requests
based on an IP being listed on the aggregate of all sorbs zones, ie
dnsbl.sorbs.net then it is they who are at fault, not Sorbs. Sorbs does
not tell you what to do with their lists.
http.dnsbl.sorbs.net  - List of Open HTTP Proxy Servers.
socks.dnsbl.sorbs.net - List of Open SOCKS Proxy Servers.
misc.dnsbl.sorbs.net  - List of open Proxy Servers not
                        listed in the SOCKS or HTTP lists.
So... If you're listed in http.dnsbl.sorbs.net, sorbs are saying,
"Last time we checked. There's an open HTTP proxy at IP x. Do
what you want with this free information". What they're *not*
saying is "Block IP x or you'll get hacked and spammed!!!"
So there are three main possibilities as far as E-Golds actions go as far
as I can see.
1.) They're ignorantly blocking Tor users without realising.
2.) They're blocking them on purpose because the collatoral damage is
    worth it to protect their other customers.
3.) They're ignorantly blocking Tor users without realising, but if they
    knew about Tor they'd do it on purpose anyway to protect their service
    and customers.
Sorbs are not doing anything evil, or scamming anyone. They are publicly
expressing their opinion and observations of behaviour from IP
addresses, and letting people do what they want to with that
The only solution to this problem is to contact E-Gold and try to get
them to whitelist TOR exit nodes, perhaps using
ip-port.torhosts.nighteffect.us. They might say yes, they might so no,
or they might ignore you. You're free to take your business elsewhere of

@_date: 2007-04-27 16:23:11
@_author: Mike Cardwell 
@_subject: Tor nodes blocked by e-gold 
Really? In which one of the following lists does Sorbs list Tor servers?
And in what way does the description mislead the user as to the purpose
of the listing?
 1.) http.dnsbl.sorbs.net
 2.) socks.dnsbl.sorbs.net
 3.) misc.dnsbl.sorbs.net
 4.) smtp.dnsbl.sorbs.net
 5.) web.dnsbl.sorbs.net
 6.) new.spam.dnsbl.sorbs.net
 7.) recent.spam.dnsbl.sorbs.net
 8.) old.spam.dnsbl.sorbs.net
 9.) spam.dnsbl.sorbs.net
10.) escalations.dnsbl.sorbs.net
11.) block.dnsbl.sorbs.net
12.) zombie.dnsbl.sorbs.net
13.) dul.dnsbl.sorbs.net
They each have very specific listing criteria, but none of them specify
"Tor exit node"...

@_date: 2007-04-30 21:53:27
@_author: Mike Cardwell 
@_subject: Exiting only port 80 
Am I right in thinking that most people use Tor for web browsing, over
ports 80 and 443? And am I right in thinking that most of tors bandwidth
is used up by a minority of users, using services that require much higher amounts of bandwidth, such as ptp traffic? These are just guesses,
but I couldn't find any data about how much traffic Tor is pushing over
various ports, and would appreciate being pointed in the direction of
it if it exists!
If I am right, wouldn't the majority of the tor user base be better
served if a collection of exit nodes only exited port 80 and 443
traffic? Does that have privacy implications? I initially thought
I should configure up my node to exit all traffic except for certain
ports, but after giving it more thought, it seemed the wider network
would be better off having more available http/https traffic.

@_date: 2007-08-11 11:13:54
@_author: Mike Cardwell 
@_subject: Warning to NoReply.org DEB Package Users 
I've been using the noreply 0.1.2.16 release since it came out 9 days
root at clayman:~# grep noreply /etc/apt/sources.list
deb      etch main
deb-src  etch main root at clayman:~# dpkg -l|grep ' tor '
ii  tor                             0.1.2.16-1~~etch.1
anonymizing overlay network for TCP
root at clayman:~# The amd64 Feisty version came out at the same time:

@_date: 2007-08-11 20:05:23
@_author: Mike Cardwell 
@_subject: ModSecurity v2 Apache rules for directory servers 
On one of the suggested methods to get your Directory service on port 80 if Apache is
in the way is to use mod_proxy.
Personally I think sticking tors directory service behind Apache so it's
not exposed to the wider Internet directly is a good thing anyway. The
shear scale of development, usage and history of Apache makes me
confident that it is less likely to contain security holes than tor,
(see recent exploit)
This is not a dig! I am writing this email to share some ModSecurity
( rules that I have been developing and using
to severely restrict the requests that get forwarded onto the tor daemon by
mod_proxy. Someone may find them useful. Here are the relevant parts of
my Apache vhost:
   SecRuleEngine             On
   SecRequestBodyAccess      On
   SecResponseBodyAccess     Off
   SecRuleInheritance        Off
   SecAuditLogRelevantStatus "^500$"
   SecDefaultAction          "log,auditlog,deny,phase:2,status:500,severity:'2'"
   SecRule HTTP_HOST        "!^\d{1,3}(?>\.\d{1,3}){3}$" "msg:'Host header must be IP address'"
   SecRule REQUEST_PROTOCOL "!^HTTP/1\.[01]$"            "msg:'HTTP/1.0 or HTTP/1.1 only'"
   SecRule REQUEST_METHOD   "!^GET$"                     "msg:'We only allow GETs here'"
   SecRule REQUEST_HEADERS:Content-Length "!^0?$"        "msg:'No request message bodies allowed'"
   SecRule REQUEST_URI "!^/tor/server/authority$"                                       "chain,msg:'Badly formed uri'"
   SecRule REQUEST_URI "!^/tor/status/all$"                                             "chain"
   SecRule REQUEST_URI "!^/tor/running-routers$"                                        "chain"
   SecRule REQUEST_URI "!^/tor/dir\.z$"                                                 "chain"
   SecRule REQUEST_URI "!^/tor/server/(?>d|fp)/(?>[A-F0-9]{40})(?>\+[A-F0-9]{40})*\.z$" "chain"
   SecRule REQUEST_URI "!^/tor/status/fp/[A-F0-9]{40}(?>\+[A-F0-9]{40})*\.z$"
   ProxyPass I put another http service behind Apache earlier this year unrelated to
tor (I wont mention the name of the product). After it had been running
for a couple of months, we found a DOS that could be performed
accidently by doing a GET request in a certain way. Whilst waiting
for a bug fix, because I had the flexibility of Apache in front of it,
it was a synch to just stick a rewrite rule in place to prevent the
request taking place and the DOS happening.
P.S. The "ProxyPassReverse" entry in the faq seems redundant as the tor
directory http service doesn't appear to ever return a redirect response.

@_date: 2007-08-13 12:51:52
@_author: Mike Cardwell 
@_subject: Directory issues 
I had the same issue after upgrading. Restarting tor didn't seem to
help. I did:
rm -rf /var/lib/tor/cached-* /var/lib/tor/bw_accounting
followed by restarting tor, and it started working again. I wasn't sure if
that was just a fluke at the time so never brought it up.

@_date: 2007-08-14 16:53:06
@_author: Mike Cardwell 
@_subject: ModSecurity v2 Apache rules for directory servers 
>>> "Please don't do stuff like this."
 >> Why not?  I don't see any problem in validating/checking the behavior
 >> or request/fingerprints of incoming connections to Tor, so long as it
 >> doesn't break Tor (hence QA testing after R&D).  Why would checking
 >> input be a bad thing?
 > because they make no sense.
 >
 > Why do you want such a thin? i believe to prevent "attacks"?
Yes. To reduce the likelyhood of my system being compromised due to flaws in Tor such as the recent currently undisclosed exploit that allows people to, basically, turn others machines into open relays.
 > - if the rules are correct, they allow "attacks" too
The point is to reduce the possible attacks, not stop them outright.
 > - the rules add complexity and make it hard to debug
Rubbish. ModSecurity has excellent logging. It doesn't make things more difficult to debug.
 > - Tor is an open source software which isn't broken by design, so if
 > there are any security problems, just upgrade
 >
 > mod_security can be used in some cases like:
 > - you have to run old buggy software because the vendor...
 > - you have to run unknown user installed software (like PHP..) and you are an
 >     ISP, ..
It's good for applying temporary protection against flaws before they're   patched. I *have* done this before. It also supplies certain protection against 0 day attacks.
 > but Tor is an "alive" project, and there is security support for
 > nearly all platforms, so any attempt to "fix" holes by adding a layer,
 > may create new holes, or even completely new attacks possible.
Sorry, I don't buy it. I'll stick with ModSec and tweak my rules as I think I was a little overly keen about my original rules and posted them before I'd had time to test them properly, and yes they have thrown up a few false positives so I've been tweaking them. I'll bed them in, and then go looking through the source code to try and spot stuff I've missed. I'm personally going to continue to use them, and people are free to contact me if they want to use them.

@_date: 2007-08-18 20:21:32
@_author: Mike Cardwell 
@_subject: Privoxy usage? 
Same here. I use OpenVPN with my laptop as the client. I chose to use TCP over port 443, rather than the default UDP so I'd have no NAT/firewall issues as I move around from network to network. Works like a charm. I don't deny it's probably inefficient, but it's not noticably so. Not to me anyhow.

@_date: 2007-12-20 13:11:15
@_author: Mike Cardwell 
@_subject: another seeming attack on my server's DirPort 
Alternatively, if you've got an Apache reverse proxy in front of your DirPort as described in the manual, you could perhaps implement per IP, connection and bandwidth rate limiting with mod_cband. Just a thought.

@_date: 2007-12-30 10:41:20
@_author: Mike Cardwell 
@_subject: Proper TOR DNS Configuration Testing Help 
I was considering doing something similar but haven't found the time recently. I got around to setting up a basic page which does the DNS check you're refering to, and also does a check to make sure gopher:// requests are being proxied:
The DNS check basically works by just turning on binds query logging, and then having a daemon which tails the log file looking for the appropriate requests and then making the data available to the cgi

@_date: 2007-12-30 10:43:06
@_author: Mike Cardwell 
@_subject: Proper TOR DNS Configuration Testing Help 
I was considering doing something similar but haven't found the time recently. I got around to setting up a basic page which does the DNS check you're refering to, and also does a check to make sure gopher:// requests are being proxied:
The DNS check basically works by just turning on binds query logging, and then having a daemon which tails the log file looking for the appropriate requests and then making the data available to the cgi

@_date: 2007-02-05 21:17:03
@_author: Mike Cardwell 
@_subject: Forwarding email ports 
I'm not sure what was suggested is actually correct. Port 25 is for SMTP
relaying, port 587 is for SMTP submission. Port 465 is for SMTP
submission with SSL negotiation immediately on connect.
Both ports 25 and 587 can do TLS, and generally if 25 does it, 587 will
do it to.
Other issues regarding SMTP inside TOR...
If you use either 25 or 587 with TLS, the exit node will still be able to view
the plain text value of the "HELO" or "EHLO" sent by the submitting
host. This *could* allow in certain circumstances, for the exit node to
make a good guess of the originating host, for what that's worth. This is
because many MUAs use the hostname or the IP address of your machine in the
HELO. If you're behind NAT, that value may just be the RFC1918 address though.
Port 465 doesn't have this problem though as the entire conversation is
encrypted. Assuming the client doesn't accept a bad certificate and
leave themselves open to a MITM attack.
For informational purposes, port 465 was hijacked by Microsoft for Outlook
when they decided to come up with their own way of doing SMTP SSL. It has
recently been assigned by IANA for a "real" service. Check out the port
on Many hosts now reject mail from dynamic IP addresses. You might want to
perform recipient callouts with rejections during the SMTP conversation,
rather than blindly accepting any mail from the TOR network and then
generating a bounce when it fails to deliver.
SMTP inside TOR has so many little issues it makes my brain hurt.

@_date: 2007-03-31 15:12:21
@_author: Mike Cardwell 
@_subject: Example hidden service issue 
In the documentation it tells you to set up an example hidden service
pointing at google.com, eg:
HiddenServicePort 80 I've just started looking at hidden services so I'm not exactly sure how
they work yet, but if I'm correct, by setting that up and testing it
surely you'll be connecting to  on port 80 from the server
with your hidden service and doing a:
GET / HTTP/1.1
Host: youronionaddress
Wont that give google a map of Real IP -> Hidden service name?

@_date: 2007-03-31 17:49:53
@_author: Mike Cardwell 
@_subject: Example hidden service issue 
That's exactly the way I should have described the issue in my original
post. I didn't think I'd need to spell it out in so much detail. :)
If you assume that everyone that has set up a hidden service has done
the google test as described in the documentation and hasn't then
changed the onion address afterwards. Also assume that google logs the
Host header, eg using apache common+host format and that they archive
the logs. This gives google the ability to grep for an onion address and
get the real ip of the hidden service if they're ever "asked" for it.

@_date: 2007-03-31 18:01:24
@_author: Mike Cardwell 
@_subject: Example hidden service issue 
Further to this, there is still a problem even if you *do* change the
onion address after doing the test. The fact that google can see that
someone was testing setting up a hidden tor service from a particular IP
on a particular date is often going to be enough info to expose the
*probable* real location of a hidden service.

@_date: 2007-03-31 18:44:02
@_author: Mike Cardwell 
@_subject: Example hidden service issue 
I think the whole google test should be removed from the documentation.
I also think that everyone should be aware that if they did the google
test and continued to use the same onion address that their real IP can
*probably* be found by the "authorities" if need be.
Also, if google can see a log entry of an onion address request coming
from a certain IP, then someone announces a hidden service a day later
with a *different* onion address, they can make a good guess that it's
running from the same IP and they've simply changed the onion address.
I'm assuming here there aren't thousands of new hidden services added
every day to the tor network

@_date: 2007-05-05 15:00:35
@_author: Mike Cardwell 
@_subject: Exiting only port 80 
I think you sort of missed my point. I'm aware there are lots of protocols and ports used on tor and that they all need bandwidth. http seems to be the killer application of tor though and it performs badly, so my suggestion was to be a little bias towards providing bandwidth for that particulary usage. Not "very" bias, a little bias.
For my particular node I've decided to only exit ports 80 and 443 once I've finished shifting services about and configuring things up.

@_date: 2007-05-01 13:31:11
@_author: Mike Cardwell 
@_subject: Exiting only port 80 
As far as I can see email and irc don't have a bandwidth problem. At
least not to the extent that web browsing does. My suggestion was for
some exit nodes to start only doing http, not "all" exit nodes, and not
even "most" exit nodes.
If there was easily accessible up to date information about what sort of
traffic is going over the Tor network, individual administrators of exit
nodes could make their own decisions about what is most needed.
Ideally, I'd like to be able to tell my tor exit node to aim to make 75% of
it's bandwidth available for http requests, and to only use this
reserved space for other protocols when it's not being taken advantage
of. That sounds complicated though.

@_date: 2007-10-01 16:35:29
@_author: Mike Cardwell 
@_subject: funneling a wireless net's outbound connections through tor 
1.) People that can perform these attacks if you just use a normal Internet connection: Governments, people working for ISPs
2.) People that can perform these attacks if you use Tor: Governments, people working for ISPs and anyone who know how to install Tor. Including some wannabe hacker 13 year old kid living on the other side of the World.
If you use Tor, you considerably increase the number and range of people that could potentially attack you. You also make yourself a tastier target.
This is not a bad thing if you know how to deal with it. It *is* a bad thing if you don't. For example, I have only ever had attempted MITM attacks against my ssh sessions when using them over Tor.
Your interpretation of what I said is quite hilarious.
Hopefully nobody will help you use Tor for something that is dangerous and that you clearly don't understand. For your users sake.

@_date: 2007-10-01 18:47:22
@_author: Mike Cardwell 
@_subject: funneling a wireless net's outbound connections through tor 
Ok. Add them to both lists then.
Cool. So we both agree that there are far more people that *can* attack you if you use Tor... Because option 1 is a subset of option 2, where 2 has the extra group of people which we'll refer to as "everyone in the You get attacked on Tor, simply for being a user of Tor. If you browse the Internet without taking appropriate precautions, when using Tor, you will be attacked eventually. You are creating this very environment for your users. You're not doing them a favour.
It is absolutely true though. I said:
You seemed to interpreted it as:
You then reacted by accusing me of being both a Troll, and of working for the NSA. The words, "conspiracy nut," come to mind.
Your view is crazy. You'd rather trust random anonymous people from all over the World to deliver "clean" traffic to you than your ISP/Government? Fair enough if you think your government or ISP has a reason to do it but it sounds to me like the only reason you're using tor for this particular project is:
1.) You want to give Internet access to people who don't want to pay for
     their own.
2.) You don't want to be connected with any dodgy traffic they might
     generate.
Why? They can be used in a perfectly safe way by people who know how to access the Tor network safely.
You seem to think people can just use Tor without understanding the issues. I guess maybe you think the "Warning: Want Tor to really work?" section should be removed from the Download page on tor.eff.org so it doesn't scare people out of using Tor? After all, it's better that people use Tor blindly and unsafely and perhaps without even realising, than not at all right? I didn't read that thread as far as I can remember. Go on then, who else thinks this is a good idea?
Read Your users *will* fall prey to these sorts of attacks unless they know the exact implications of using your service, and how to do it safely.

@_date: 2007-10-26 10:07:26
@_author: Mike Cardwell 
@_subject: Spam over Tor 
People can already block tor exit nodes connecting to their SMTP servers with ease. Blocking tor exit nodes that connected to yahoo to send email is only slightly more difficult, because of the received header that you mentioned. If spam ever became a problem on Tor, which I doubt, it would be easy for email admins to protect themselves from it. If yahoo ever see it as a problem, they can block it themselves.
imo, that's a bad idea. If you're not willing to allow people to access a service via Tor, reject it in your policy. Don't allow it in your policy and then cripple access to it.

@_date: 2007-10-26 10:09:27
@_author: Mike Cardwell 
@_subject: Spam over Tor 
If I write a web based application that sends out loads of spam if you click a button, then connect to the Tor network and click that button. Does that classify as spam over Tor?

@_date: 2007-10-26 18:21:00
@_author: Mike Cardwell 
@_subject: Leopard Vidalia 
In case anyone's interested, I just installed the Tiger version of
Vidalia under Leopard and it works fine

@_date: 2007-10-29 13:05:55
@_author: Mike Cardwell 
@_subject: Spam over Tor 
"Spam over Tor" is meaningless anyway. In the same way that, "Spam over
IP," or, "Spam over TCP," or, "Spam over keyboard," would be meaningless.
The issue is, which host is responsible for the last SMTP hop over the
Internet. The only time that you can say that Tor is responsible for a
spam message is if there is a direct connection from a host hidden by
the Tor network, to one of the MXs of the recipient. I've not heard of
this happening.
If you use a webmail system to send a spam, it is the webmail system
that is responsible for it. It is irrelevant how you connected to that
webmail system. If you connect to an SMTP relay to send your spam, then
it is the relay that is responsible for it.

@_date: 2007-10-01 10:06:50
@_author: Mike Cardwell 
@_subject: funneling a wireless net's outbound connections through tor 
If you set up something like that you're opening up all sorts of attacks against the people who use your service. If they don't know that all of their plain text traffic can be read and modified by, "dodgy," exit nodes, and almost certainly *will* be at some point...

@_date: 2007-10-01 15:19:26
@_author: Mike Cardwell 
@_subject: funneling a wireless net's outbound connections through tor 
If they use an Internet cafe, their traffic is subject to being monitored. If they use Tor it is *also* subject to being modified.
Example 1:
Your user goes to  and enters their login details. The Tor exit node controller has written something to modify the html on that page so the form posts to a http url instead of a https url. Their login details are now compromised.
Example 2:
Your user goes to  to download msn messenger. They click the "download it now" link. The tor exit node controller intercepts that request and returns a modified exe containing a trojan instead of the original.
Scary huh?
Of course, you could argue that the person running the Internet cafe or the ISP could do that, but I am inclined to believe it's much more likely to occur on the Tor network than in those cases.
The anonymity of the IP address is not at issue here. The issue is, by using Tor, you allow the possibility of exit nodes monitoring and modifying traffic, so you should only use Tor if you truly understand these issues and how to deal with them.
IMHO. There's no need to use Tor for general web browsing, and at the end of the day it probably makes your online experience more dangerous rather than less dangerous.

@_date: 2007-10-08 09:50:31
@_author: Mike Cardwell 
@_subject: headers in email 
Not really. Just send yourself an email and look at the Received headers when you get it. That will tell you exactly where the server is.
They wont see an open relay. To see an open relay suggests you have some way of performing a test to relay mail through it.
This is the problem with Tor. I guess you could use PGP.
I'd be tempted to use authenticated SMTP with a hidden service and make people sign up, so you can rate limit what they send.
You could set up a gmail account via tor. Then point a stunnel at smtp.gmail.com port 465 over Tor using tsocks or something. Making sure you have a copy of their public cert first and that the stunnel validates it. I set this up and pointed my MTA (Exim) at it just for a play at one point. I had to make sure Exim stripped the Received headers and sent a suitably anonymous EHLO when talking to their service but otherwise it worked.

@_date: 2007-10-08 10:21:28
@_author: Mike Cardwell 
@_subject: headers in email 
I initially set Exim to freeze the messages in the queue so I could inspect their headers and body, to check for just this. You can then flush an individual message using "exim -v -M message_id" allowing you to watch all communication going back and forth between the two servers.
I never considered that stunnel might send identifying information of some sort though. Hmmm. Does anyone have any experience of using stunnel   with tsocks over the Tor network?

@_date: 2007-09-16 15:37:04
@_author: Mike Cardwell 
@_subject: I break the silence: My arrest 
When you hit reply. Your cursor is at the top of the message. There's nothing stopping you moving the cursor down.
In fact, a quick google shows that if you're using Firefox, there's a Greasemonkey script which does this for you:

@_date: 2007-09-18 13:02:53
@_author: Mike Cardwell 
@_subject: Maximum num ExitPolicy 
Is there a maximum number of ExitPolicy entries you can have for a node?

@_date: 2007-09-18 13:30:47
@_author: Mike Cardwell 
@_subject: Maximum num ExitPolicy 
So what will happen if some prat creates a torrc with 100 million ExitPolicy entries?

@_date: 2008-01-07 23:06:32
@_author: Mike Cardwell 
@_subject: SORBS vs Tor and the world 
For reference, one might use this list in an ACL chunk in Exim4 as follows:
deny dnslists =       message  = $sender_host_address is running a Tor exit node that exits to $interface_address:$interface_port

@_date: 2008-01-01 12:52:09
@_author: Mike Cardwell 
@_subject: Proper TOR DNS Configuration Testing Help 
1.) You visit 2.) The cgi generates a unique code. In this case, a 32 character alphanumeric string. It then spits out some html containing several triggers to try and make the web browser do a dns lookup on "$code.tordnscheck.grepular.com" where $code is replaced by the unique id it just generated. The triggers are inside the  and are:
3.) A meta refresh then refreshes the page and adds ?code=$code to the uri arguments.
4.) When the page is reloaded it "asks" a separate process that I will describe in a moment, whether or not it knows the IP that did the lookup of $code.tordnscheck.grepular.com, and if so it displays it.
5.) There is a separate process written in perl, which uses File::Tail to monitor the bind query log. It's a threaded application. One thread tails the log looking for entries like $code.tordnscheck.grepular.com. When it comes across any, it stores the code and the ip together in a shared variable, for up to 10 minutes
6.) The second thread accepts incoming socket connections. Basically, the torcheck.cgi script makes a tcp connection to the app tailing the log file and writes $code to it, and the app then returns the IP address and closes the connection.
The gopher request works in a similar fashion. The trigger is:
Then I have another application listening on the gopher port looking for requests like "/torgophertest/$code" and then linking $code with the client IP. Then it makes the information available to the cgi via the same socket method.
I hope that all makes sense.

@_date: 2008-03-10 10:40:59
@_author: Mike Cardwell 
@_subject: Gmail/SSL 
These repeated discussions about gmail and ssl make me wary of ever using their webmail service, or for that matter any other webmail service with Tor. Just because a website is secure at the moment, doesn't mean they wont make changes in future which leak your sessions.
It is considerably safer to use gmails secure imap/smtp services rather than their webmail with Tor imo. More bandwidth friendly too.

@_date: 2008-05-21 11:02:11
@_author: Mike Cardwell 
@_subject: Tor server for port 443 
The standardised port for SMTP submission is 587. See  specifically "Although some servers support port 465 for legacy secure SMTP in violation of the specifications"
However. gmail do actually support both 587 with TLS *and* 465 with SSL on connect, on smtp.gmail.com.

@_date: 2008-05-21 12:04:30
@_author: Mike Cardwell 
@_subject: Tor server for port 443 
The port 465 issue became particularly important recently when IANA actually assigned it for a real use. Previously it was an unassigned port that was hijacked by Microsoft for Outlook.
While port 587 is the official standard port for email submission, it doesn't *require* the usage of SSL. GMail does however have this Also, I'd still personally prefer to use port 465 over port 587 for mail submission when both are available, purely because when using port 465 you negotitate SSL immediately, whilst with port 587 there is some plain text negotiation first which *could* accidently leak identifying information such as your hostname in the EHLO, to the Exit node.

@_date: 2008-05-22 09:25:09
@_author: Mike Cardwell 
@_subject: Tor server for port 443 
Port 25 is used for both mail relay and mail submission, whilst ports 587 and 465 are only used for mail submission. Mail submission over Tor isn't a problem, mail relay over Tor would allow it to be abused for spamming. There is nothing bad about opening up ports 465 and 587. I am also unfamiliar with SSM but I'd bet my left testicle that it's usage on the Internet is insignificant in comparison to smtps over port 465.

@_date: 2011-04-21 09:38:07
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Dropbox over Tor feedback 
I know this is only indirectly related, but I recently wrote about how
the Dropbox mobile clients send file meta data over an unencrypted
network connection, in direct contradiction of what their public
documentation stated:
Instead of fixing the problem, they removed the bit of documentation
that stated that the meta data was encrypted. They didn't modify it to
state that the mobile clients send meta data unencrypted, they just
removed the bit stating otherwise.
If you're going to use Dropbox over Tor, it's definitely worth auditing
the network comms properly as you blatantly can't rely on trusting them.
Certainly use something like TrueCrypt with it.

@_date: 2011-08-22 20:49:37
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] New HTTP authorization attack 
FWIW, there are many ways to track a browser cross-site and across
restarts, even if you have javascript and cookies and flash cookies
disabled. I recently blogged about a bunch of them which abuse the
browser cache here:

@_date: 2011-08-23 09:29:45
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] New HTTP authorization attack 
If you read the article, you'll see that clearing the cache on toggle
isn't enough. The cache should be completely disabled. If not, you could
visit sitea.com, then visit siteb.com, and they could easily figure out
that you're the same person. Even if you're coming from a different Tor
exit node, even if you clear cookies inbetween. That is unless you have
the patience to only visit one site at a time, and toggle off/on between
each different site visit.

@_date: 2011-08-23 16:35:35
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] New HTTP authorization attack 
Neat. I was unaware of the SafeCache addon.
Would be great if you achieved that.
That's a shame. I'm seeing more and more sites enabling https.

@_date: 2011-12-06 09:34:26
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] 2 ways to boost Tor by Tor2web additions 
It sounds like you just want to set up a reverse proxy. Apache can do
this with mod_proxy. You could also use mod_cache so that content which
doesn't change regularly can sit on the proxy without having to be
re-requested over Tor each time.
I don't see the point of this? tor2web.org already does that, but is
free and doesn't require a password...

@_date: 2011-12-20 12:01:39
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] "If you have access to certain tools, 
FWIW, I built a web app a while ago which sends out an HTML email to you
full of different types of web bugs to try and test if your email client
is loading remote content when it shouldn't be. It found bugs in
Thunderbird, Outlook, Androids standard mail client, K-9, Apple Mail,
the iOS email client, Roundcube and several other webmail
implementations. If you want to try it out, it can be accessed here:
And I originally wrote a about it here:

@_date: 2011-12-20 15:18:39
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] "If you have access to certain tools, 
If you're using a standalone client, you're pretty safe if you tell it
to not render the email as HTML.

@_date: 2011-12-21 12:07:38
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] janusvm still safe? 
In that case, maybe somebody should contact them and politely ask them
to stop distributing insecure software?

@_date: 2011-12-23 14:05:13
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] janusvm still safe? 
I use encrypted LVM on my laptop. I disabled swap altogether. I placed
the boot partition and boot loader on a separate USB stick which I keep
on my person at all times. The full disk encryption uses a key file
rather than a password. The key file lives on the USB stick, protected
using GnuPG's symmetric encryption option. I also patched my Linux
kernel with something called TRESOR to prevent the full disk encryption
key living in RAM, to help defend against cold boot attacks. I wrote it
all up here:

@_date: 2011-02-09 10:04:29
@_author: tor@lists.grepular.com 
@_subject: Sent e-mails going into spam folders. 
This is slightly going off on a tangent, but I wonder if any services
like the following exist...?
I'd like to set up an SMTP server as a hidden service to accept incoming
email. It would need a gateway from the Internet though. So if somebody
on the Internet emailed:
username at myhiddenservice.example.com
A machine on the Internet would accept that email and forward it on over
Tor to:
username at myhiddenservice.onion
It would be trivial to set up such a gateway. Just set up a wildcard MX
record on *.example.com, and configure up an MTA. Just wondering if it
has been done though?

@_date: 2011-02-16 09:28:25
@_author: tor@lists.grepular.com 
@_subject: Contacted by "oompaloompa" operator: BadExit removed 
Is this one of the guys who didn't have published contact info? I can
see he does at the moment... Did he explain why he didn't have it?

@_date: 2011-02-01 09:57:45
@_author: tor@lists.grepular.com 
@_subject: tor weather subscription problem 
As a web developer who has discovered and defended against CSRF in the
past, I feel I should express my opinion here. You should only use HTTP
referrers to prevent CSRF as a quick fix whilst a proper system is put
in place. A better way would be to embed a session ID in the form, pass
it in the POST data, and then compare it against the session id on the
server side.

@_date: 2011-02-07 09:41:06
@_author: tor@lists.grepular.com 
@_subject: What are email risks? 
The major part of my full time job is as an email administrator.
Scrubbing headers will affect deliverability to some systems. Probably
not as much as having a Tor exit node IP in your Received headers
though. Smarthosting through an anonymous GMail account is a good idea
because they don't put the connecting IP address into the Received
headers, and systems generally trust mail from GMail more anyway.

@_date: 2011-02-01 00:23:38
@_author: tor@lists.grepular.com 
@_subject: Is "gatereloaded" a Bad Exit? 
If valid contact info is important/necessary, the Tor project should
enforce it, and perform periodic email address validation in order to
allow routers to be Exits. If it's not important/necessary than I see no
valid reason to complain about it not existing.
The above may or may not be true. Would be nice to see some evidence. Or
at least some evidence of somebody trying to find the truth.
Do you find that being condescending is a good way to get people to
agree with you? I tend to find it fosters disrespect.
If exiting port 80 but not port 443 causes problems for Tor, then Tor
should be updated so you can't offer one without the other. This is a
problem with Tor, not with Tor exit operators.

@_date: 2011-01-31 12:50:01
@_author: tor@lists.grepular.com 
@_subject: Is "gatereloaded" a Bad Exit? 
They may or may not read this list. Has anyone taken pro-active steps to
try and contact the people running these exits? They may not publish
their contact details in the directory, but we have their IP
addresses... Which means we can probably figure out how to contact at
least some of them...
Assuming the worse, and disregarding volunteer exit bandwidth without
some proper investigation, doesn't sound like a good approach to me...

@_date: 2011-01-31 13:21:37
@_author: tor@lists.grepular.com 
@_subject: Is "gatereloaded" a Bad Exit? 
I don't think you can make that assumption. Maybe they just didn't want
their email address to be public for spam bots to harvest. Maybe they're
just used to not publishing their email address unless they really have
to. Safest course of action: Figure out how to contact them, and ask them.
It's the easiest, but the least efficient route. Somebody mentioned 6%
of Exit bandwidth. How much effort would be spent trying to increase the
capacity of the network by 6% via coding and/or publicity? Probably a
lot more effort than would be required to try and contact these Exit
owners and maybe retain the bandwidth.
You make it sound as though running an Exit node is a privilege and that
people who run them somehow owe the Tor project? They're volunteering
bandwidth, for the benefit of the network. If you don't treat volunteers
well, they will go elsewhere, and the people who lose out are the people
who use the Tor network, not the people who previously ran Exit nodes.
Exit bandwidth is a scarce and valuable resource, and should be treated
as such.

@_date: 2011-07-07 17:52:31
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Maintaining your privacy sending e-mails 
FYI, FireGPG is still alive (ish). I am running FireGPG on Firefox 5.
See:

@_date: 2011-07-07 20:53:31
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Maintaining your privacy sending e-mails 
It works on Windows, OSX and Linux using the method described at that
URL. Nobody is distributing an XPI, but you can build your own by
following the instructions in the git repository.

@_date: 2011-06-02 12:24:27
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] SMTP & POP3 Email over Tor.. Anonymity breaking? 
I have a pretty decent knowledge of the SMTP, POP3 and IMAP4 protocols,
and I'm not aware of any part of the protocol which transmits this
SMTP *might* leak your machine name or hostname or LAN IP address when
transmitting the EHLO. When you send an email, it's going to include
your local system time and local time zone in the Date header. It may
also include information about your email client and/or OS in some
header like X-Mailer or User-Agent.
I reckon IMAP4 and POP3 are relatively safe protocols. I don't think
they leak any useful information. It may be possible to fingerprint what
actual IMAP client you're using by analysing the protocol, such as how
many connections are open, command execution order, the format of tag
names, IMAP extension usage, how the client responds to certain types of
protocol errors, etc.
Not sure. If I wanted to access my email over Tor, but using a proper
client rather than webmail, I'd probably set up fetchmail to fetch the
email using SSL secured POP3 over Tor, and drop it in a local Maildir,
and point Thunderbird at that. For SMTP, I'd stick Exim inbetween
Thunderbird and Tor, and configure it to remove/sanitise headers and to
use a custom HELO.
An advantage of using fetchmail to retrieve the mail, is that mail
retrieval would be done on a regular interval, rather than just when
you're actually reading it. You might not want an attacker to be able to
determine the times that you're online checking your email.
One thing to note. For SMTP submission over Tor. If you can use port
465+SSL rather than TLS on ports 587 or 25, then do that. If you're
using TLS rather than SSL, even though the majority of your connection
is encrypted, the welcome banner and your initial EHLO are transmitted
in the clear. smtp.gmail.com has both options.

@_date: 2011-06-02 16:52:42
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] EFF Tor Challenge 
"If Tor has vulnerabilities, it might get exploited!"
Of course, you can replace "Tor" with any other application name. Tor is
not special in this regard.

@_date: 2011-06-02 19:46:47
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] SMTP & POP3 Email over Tor.. Anonymity breaking? 
Erm. I explained absolutely everything you've just said in my very
response to you:
"SMTP *might* leak your machine name or hostname or LAN IP address when
transmitting the EHLO. When you send an email, it's going to include
your local system time and local time zone in the Date header. It may
also include information about your email client and/or OS in some
header like X-Mailer or User-Agent."
My point was that neither IMAP, nor POP3 leak the times. SMTP doesn't
either, but the actual content of the emails that are sent over SMTP can
do, in the Date header.
No idea what you're talking about here.
To clarify, SMTP, POP3 and IMAP4 don't leak your timezone. Your email
client will stick your timezone in the Date header of an email before
sending it over SMTP. This is something done on your machine, by
Thunderbird, not something a mail server does, or the exit node does.

@_date: 2011-05-03 21:35:15
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] ORBot-like app for Mac/Windows 
The reason it is possible on Android is because each app runs under it's
own user id.
netfilter/iptables has an "owner" module. Assuming you're using the Tor
TransPort directive on port 9040, you could torify uid 1234 under Linux
with this command (untested):
iptables -t nat -A OUTPUT -m owner --uid-owner 1234 -j REDIRECT
--to-ports 9040
Then the outgoing connections of any app running under uid 1234 are
forwarded to local port 9040 and "torrified."
This doesn't really translate to OSX or Windows or even normal Linux
desktop usage.
At least, this is how I'm assuming Orbot does it. I know this is how
DroidWall handles applying firewall rules for different apps...

@_date: 2011-05-19 16:39:26
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Content-Security-Policy 
I don't know if this is something we should be concerned about, but I
thought I'd bring it to your attention anyway.
Firefox 4 implements Content-Security-Policy:
It allows website owners to send a HTTP response header containing a
policy about what the page is allowed to do. Ie, is it allowed to fetch
images from a different domain? Is it allowed to include inline
javascript? etc...
One of the features of Content-Security-Policy is that you can refer to
a URI in the response header which is used for reporting violations. If
the browser detects that the page is trying to violate one of its
conditions (eg by linking to a remote image), it will then POST data
about that violation to the report URI. The data that it POSTs is a blob
of JSON. One of the things included in that JSON is the full set of
request headers that the browser used when requesting the page that lead
to the violation.
It's my understanding that people use proxys like Privoxy to sanitise
and strip HTTP headers. Using this Content-Security-Policy reporting
method could allow a website owner to cause the users browser to package
up the headers in a nice blob of JSON, and then POST them back to the
server, bypassing any header sanitising.
You can put Content-Security-Policy in "report only" mode, so it would
be completely transparent to the end user.
Worth addressing?

@_date: 2011-05-22 13:28:29
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Using passwords with TOR 
I use a Firefox addon called Certificate Patrol. It keeps a record of
certificates that https websites serve. It then alerts you if they
change. It displays information about the old certificate next to the
new certificate so you can tell if the issuer has changed, and if the
old cert was due to expire anyway.
Should come in handy if you come across a Tor Exit node that is somehow
generating "valid" certificates for a domain and MITM'ing you.

@_date: 2011-05-22 21:48:24
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Using passwords with TOR 
Strange. I'm using 4.0.1 on OSX. I just turned on the functionality to
always popup info about new certificates and I don't think that is
working for me either. It definitely pops up stuff when the certificate
changes though. Maybe worth a bug report?

@_date: 2011-05-31 22:50:28
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] World IPv6 Day June 8th, 
============================== START ==============================
I thought the point of IPv6 Day was for sites to go dual stack for the
day to uncover any potential problems with the migration procedure to
IPv6, and to spread awareness? Going IPv6 only will just create
unnecessary problems for people imo, and is not what other sites are doing.

@_date: 2011-11-06 12:46:07
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Implement JSONP interface for check.torproject.org 
As a long time NoScript user, I completely disagree with this. Almost
every website today works completely fine without JavaScript. In fact,
most websites work *better* without JavaScript, as they pull in far
fewer unnecessary resources from third party domains.
JavaScript is useful, but browsing without it, and only turning it on
for a limited set of sites when absolutely necessary, is much much
safer, from both a security and privacy point of view. Hopefully
JavaScript will become safer to use over time with the addition and take
up of new tech like Content-Security-Policy. It certainly isn't safe at
the moment though.
As a web developer, I like the implementation. I wont use it on my site
though because I care about my visitors privacy and don't want to send
the IP addresses of *all* of my site users to some "untrusted" third
party. I also don't want to hand over the security of my website to said
third party, by allowing them to inject arbitrary javascript into my
pages and handing over complete control of the DOM. This isn't paranoid,
AD networks have been hacked in the past leading to the compromise of
lots of other websites because of this very problem.
Clearly a lot of people don't even consider these problems though. The
number of people using Google Analytics is proof enough of that.
Also, my website is 100% https, however there isn't a https version of
 Including non-ssl protected
javascript in my site would make it easy to MITM. An attacker could just
modify the javascript to read the contents of the DOM and then send it
I would go so far as to say that the javascript returned by torcheck.php
should actually check to see if it was loaded from a https website, but
over http, and alert a warning if that happened. This would prevent
silly mistakes.
Also, there is a "vulnerability" in
 The callback parameter should
be extremely limited in what characters it accepts. For example,
letters, underscores and numbers only. You shouldn't be able to do stuff
Ouch, it's being returned with a content-type of text/html as well, so
you can generate arbitrary html pages on server.globaleaks.org,
containing javascript to steal cookies and such. XSS-tastic.
The content-type should be application/json or at the very least text/plain.
I'm available for website pen-testing by the way ;)

@_date: 2011-11-06 13:31:15
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Implement JSONP interface for check.torproject.org 
I was clearly talking rubbish here; the content type should be a
javascript one. Still, I was completely correct about the danger of
using text/html and allowing arbitrary content for the callback parameter.

@_date: 2011-11-06 14:01:50
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Implement JSONP interface for check.torproject.org 
It would be safer to expose a JSON web service than a JSONP web service,
and use a wild "Access-Control-Allow-Origin" HTTP response header to
allow cross-site XMLHttpRequest. That way, people could pull the data
without suffering the risks of embeddeding third party JavaScript.
There's nothing stopping it from being provided as a secondary option.

@_date: 2011-11-07 10:08:57
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] New Browser Bundle 
I don't think any research is required to know that "third party"
cookies at least, are used to track users across sites. And that
tracking Tor users across sites is very likely to reduce their anonymity.
If you don't want to disable cookies altogether, I'd at least recommend
disabling third party ones. If you think that will affect the user
experience badly, it's worth noting that Apple disables third party
cookies by default in Safari, so it can't be all that bad... I've not
personally come across any sites where it has caused problems for me,
but I will admit that such sites must exist.
I use both. RequestPolicy is definitely much more difficult to maintain,
but makes your browsing experience so much safer. I don't think the
average user is going to be happy with RequestPolicy in its current
form. FYI, you'll find my name on

@_date: 2011-11-09 09:40:08
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tormail? 
I personally wouldn't feel comfortable using an email service run by
anonymous operators. It depends what you're using it for though I guess.
If I were using TorMail, I'd do it under the assumption that they're
archiving and reading every single email I send or receive through it.
I'd have more confidence that my email isn't being read, by using GMail.
Not that I would use either.

@_date: 2011-11-09 16:00:34
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tormail? 
This is also exactly what somebody would say if they were running the
service as a honeypot. If TorMail is run by anonymous operators, then we
don't even have their reputations to rely on.
Are the operators really anonymous though? If you send an email from
TorMail to a GMail account for example, then it will contain the real
Internet IP address of a server which TorMail routes out from... Given
the IP address, it should be possible to discover the operator(s).

@_date: 2011-11-10 09:56:24
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tormail? 
It's quite different for non-anonymous providers. They are restricted by
laws, and are held responsible for their actions, legally and
commercially. If we don't even know where TorMail is hosted, we don't
know what laws they're subject to, nor whether they're following them.
And if they're caught doing something illegal, we can't track them down
in order to hold them responsible.
If I were using GMail, I'd assume that they weren't reading my email,
but would bare in mind that they could if they wanted to, or were
compelled to by the US government.
If I were using TorMail, I'd assume that they were reading my email.
Your average TorMail account is probably much more likely to contain
information of interest to hackers and governments than your average
GMail account.

@_date: 2011-11-10 18:04:42
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tormail? 
So let me get that straight. Google is above the law, and nobody knows
how to get in contact with them. I disagree with both assertions.
GMail   : Has a policy that they don't read your email
TorMail : Has a policy that they don't read your email
If GMail does read your email, there may be legal or commercial
consequences. If TorMail reads your email, there is no recourse. None.
That's all very nice, but at no point did I advocate using a
non-anonymous email provider, without anonymising yourself.

@_date: 2011-11-24 20:12:33
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [Openvpn-users] Openvpn over tor, possible? 
That is perfectly possible. You will need to configure OpenVPN to use
TCP as Tor doesn't support UDP connections. It doesn't sound like you
need a high level of anonymity, and that you're just trying to bypass
network blocks, so you might get better performance/reliability by
dropping the default circuit length from 3 nodes to 2 nodes.
Instructions for doing this in Ubuntu can be found here:
Also, it might be a good idea to select a port for OpenVPN that is in
the default "LongLivedPorts" list. From the man page:
"LongLivedPorts PORTS - A list of ports for services that tend to have
long-running connections (e.g. chat and interactive shells). Circuits
for streams that use these ports will contain only high-uptime nodes, to
reduce the chance that a node will go down before the stream is
finished. (Default: 21, 22, 706, 1863, 5050, 5190, 5222, 5223, 6523,
6667, 6697, 8300)"

@_date: 2011-11-24 22:07:12
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [Openvpn-users] Openvpn over tor, possible? 
Should be. You just need to get the source code, make the small
modification described in the article, and then compile it. I don't have
instructions for doing that as I don't use Windows.

@_date: 2011-11-29 11:06:30
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tor resolver DNSSEC RRs 
Are there any plans to add support for the DNSSEC related RR types to
the DNS resolver built into Tor? Ie, DNSKEY, RRSIG, DS, NSEC and NSEC3?
If not, I think it would be a good thing to add, now the root zone and
major top level zones have been signed, browsers are starting to
experiment with using DNSSEC signed certificates.
If the SSHFP RR type is added too, people who use OpenSSH with the
VerifyHostKeyDNS option can benefit from public key verification when
SSH'ing into a box for the first time, over Tor.
Whilst I'm here, I may as well request MX and AAAA support too I guess.
MX for people who want to run mailservers from inside Tor. You could
argue against AAAA support because Tor doesn't support IPv6 yet, but I'm
just asking for it for completeness more than anything.

@_date: 2011-11-29 14:48:24
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tor resolver DNSSEC RRs 
Getting Tor to simply do the lookups would be a good start. Then people
will be able to stick a validating resolver between themselves and Tor.
At the moment, the only way to do this is to pick a server on the
Internet which supports recursive lookups, and point Unbound or similar
at that over Tor, forcing it to use TCP for all lookups.

@_date: 2011-10-11 14:20:29
@_author: Mike Cardwell 
@_subject: [tor-talk] Tor hidden services and SSL certificates 
Hidden services are already encrypted end to end. They don't have the
MITM problems that using Tor to access Internet services has; there are
no Exit Nodes are involved. So there's no real point in adding a layer
of SSL on top.

@_date: 2011-10-11 15:26:18
@_author: Mike Cardwell 
@_subject: [tor-talk] Tor hidden services and SSL certificates 
The Tor documentation can be found at
 is a good overview
of the way that hidden services work on top of Tor, and there is a link
at the bottom of that page to a more technical description.

@_date: 2011-10-11 19:24:47
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Securing servers 
Even if the sender doesn't encrypt before sending (as most don't), you
can always PGP encrypt incoming mail as it hits your mail server. That
way, if your server/network is compromised, at least your email from
before the compromise took place is protected. It also protects the mail
in the various caches of your IMAP clients, and if somebody hacks your
email account, they wont be able to read any email that they download.
I've been doing this myself for a while now. I wrote/released some
software to do it. It's described here:
And here:

@_date: 2011-10-11 20:04:08
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Securing servers 
That is true yes, my private PGP key doesn't go anywhere near the server
which hosts my email.
Regarding your comments on keys being stored in RAM on crypto
filesystems, I have a working solution for that too. My Ubuntu laptop
uses full disk encryption, but the key is shifted from RAM into the
debug registers of the CPU as soon as it starts booting, and all crypto
operations are performed directly on the CPU without the key being
transferred back into RAM, using the CPU's AES-NI instructions. This
prevents the key being exposed during cold boot attacks. To achieve
this, I patched my kernel using something called TRESOR. For more info
- If you compile a new kernel without LKM support then it's not even
possible for root to access the key.
I would do this on my mail server too, but it's a virtual machine which
this technique doesn't work on.
I do exactly that. After encryption, a second copy of every email is
forwarded to a different machine, over a VPN using SMTP, which also has
encrypted incremental backups using duplicity/gpg.
Another possibility would be to have a mail server as a hidden service,
and then just set up the Internet facing server to immediately forward
all incoming email to the hidden server via Tor.

@_date: 2011-10-14 10:28:11
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Ideas to securely implement PGP encryption/decryption 
I'm jumping into this thread late, and am not replying to a specific
email, I just wanted to add an idea I had a while ago.
1.) First of all, add some basic functions:
Select some encrypted/signed text, right click, select decrypt/verify.
See the results in a XUL window.
Right click a textarea, select "Enter encrypted text", a XUL window pops
up asking for the plain text. You enter that, and the encrypted text is
inserted into the textarea.
Select some text in a textarea, click sign, and see the text replaced by
the signed version.
2.) Make the following functions available to javascript:
window.gnupg.encrypt( callback )
window.gnupg.decrypt( data, callback )
window.gnupg.sign( data, callback )
window.gnupg.verify( data, callback )
window.gnupg.add_public_key( key, callback )
Whenever one of those operations could cause a privacy leak, such as the
site being able to automatically determine your key id, or determine
whether or not you have a particular public key in your ring, use a XUL
window to ask the user to authorise the request. Any decrypted data
should go into a separate XUL window.
Then, people who write applications like webmail clients can do stuff
like this:
if( "gnupg" in window ){
Which would mean that if somebody has the addon installed, and clicks
the textarea, window.gnupg.encrypt() would be called, which would spawn
the XUL window where they enter the plain text. Once the user has
entered the plain text, and hit "Save" or whatever, the callback
function would be called with the ciphertext as an argument.
The vast majority of sites, eg GMail wont implement something like this
(at least not at first), but we can do it ourselves by writing
greasemonkey (or similar) plugins.
If it is designed well enough, it could even become a standard one day
and be built directly into browsers.

@_date: 2011-10-14 10:39:47
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Ideas to securely implement PGP encryption/decryption 
Another example;
if( "gnupg" in window ){
  if( window.gnupg.has_signed_text(thetextarea.value) ){
    add_verify_button( thetextarea );
  }
function add_verify_button ( thetextarea ){
  var verify_button = document.createElement('input');
  verify_button.type='submit';
  ..blah blah styling, inserting into the DOM etc..
  verify_button.onclick = function(){
    window.gnupg.verify( thetextarea.value );
  };
window.gnupg.verify would return immediately, but would open a XUL
window specifying whether or not the text had been signed correctly. It
would also give you the option of pulling the key down from a keyserver.
It would need to display the actual signed text as well so we know that
the text being tested is the text we think is being tested and that the
javascript hasn't just called window.gnupg.verify with some other known
good signed text.

@_date: 2011-10-31 09:56:40
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Exit enclave without middle node 
I'd like to set up an exit enclave on a machine I have, but I don't want
it to relay any other traffic. Not even as a middle node. It only seems
to be possible to set up a server as an exit enclave if you also make it
a middle node relay. Is that correct?

@_date: 2011-09-08 15:40:29
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Hardware accel by default 
I was just reading through the tor man page, and I came across the
HardwareAccel and AccelName options. This peaked my interest because my
new laptop has the AES-NI CPU instruction set. I added this to my torrc:
HardwareAccel 1
AccelName     aesni
And now when I start Tor I get this:
[notice] Using OpenSSL engine Intel AES-NI engine [aesni] for AES
My question is... Why wasn't AES-NI taken advantage of by default? Why
did I have to come across it by accident? Even in the man page it says
that all you have to do is run "openssl engine" to find out what engines
you have available. Why couldn't Tor have done this it's self?

@_date: 2011-09-09 09:36:24
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Dutch police break into webservers over hidden 
Probably the safest way to run a hidden service is to do it from inside
a VM.
Install Tor on the host OS. Configure up the Hidden Service on the host
OS, but point it at the IP of the VM. Set up a firewall on the VM to
prevent all other network traffic going in or out of it. Or
alternatively use the TransPort functionality of Tor so all traffic
leaving the VM goes through Tor.
If the webserver on the VM is compromised, they get access to the VM,
but the VM shouldn't know its real IP address (just the NAT'd one), or
anything else about where it is or who it belongs to.
You're still relying on there being no vulnerabilities in the VM
software or the Tor software which allow an attacker to access the host
system, but that sort of attack is much more difficult to pull off than
compromising a web server, or any of the software being served by the
web server.
For all we know, this was a simple PHP exploit that allowed the attacker
to make a HTTP request from the target server to a host on the wider
Internet, to discover its IP.

@_date: 2011-09-09 09:42:19
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Dutch police break into webservers over hidden 
I meant to say set up a firewall on the *host* OS to prevent all other
traffic going in or out of the VM. I'd probably set up a firewall on the
VM it's self too though as an extra layer of protection. If they hack
the VM but don't get root, they wont be able to bypass the VMs firewall.

@_date: 2011-09-09 12:41:03
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Dutch police break into webservers over 
I don't know what you're asking from me... If your firewall is blocking
the connections, reconfigure your firewall to allow them.

@_date: 2011-09-23 15:20:15
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] How to verify the authenticity of the Torbutton xpi 
If you have the public key which corresponds to the private key which
was used to create the signature, then it doesn't matter if the SSL
certificate is faked. Even using non-SSL http would be fine.
If the file, or the signature file you download are tampered with, doing
this verification will alert you to that fact.

@_date: 2011-09-24 11:07:05
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] How to verify the authenticity of the Torbutton xpi 
That is correct. For example, I have signed this email with my private
pgp key. I am the only person with access to that private key. The
corresponding public key is available on the Internet for anyone to
download, in several places. Anyone who has my public key can verify
that this email was signed by me, and that it hasn't been tampered with.
This is the same process used to sign Tor.

@_date: 2012-04-30 22:28:09
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] ADDRMAP reversed IP bug 
============================== START ==============================
I've come across what appears to be a bug. In the following control port
debug log you'll see I look up the IP address of "grepular.com" three
times in a row. Look how the octets of the IP address in the ADDRMAP
responses are reversed in the second and third responses:
mike at alfa:~$ telnet localhost 9051
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
AUTHENTICATE XXXXX
250 OK
SETEVENTS addrmap
250 OK
RESOLVE grepular.com
250 OK
650 ADDRMAP grepular.com 178.79.145.246 "2012-05-01 01:21:07"
EXPIRES="2012-05-01 00:21:07"
RESOLVE grepular.com
650 ADDRMAP grepular.com 246.145.79.178 "2012-05-01 01:21:07"
EXPIRES="2012-05-01 00:21:07"
250 OK
RESOLVE grepular.com
650 ADDRMAP grepular.com 246.145.79.178 "2012-05-01 01:21:07"
EXPIRES="2012-05-01 00:21:07"
250 OK
If I disconnect and reconnect, they're reversed from the very first
response. If I restart Tor and try again, then the first response is
correct, but the subsequent responses are all reversed again. This
happens for any domain I test. The "tor-resolve" command doesn't display
this problem. I'm running version "0.2.3.14-alpha"

@_date: 2012-08-04 18:51:00
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tor powered wifi hotspot 
Hash: SHA512
I think this part is essential. Ask yourself this: Would you install
Tor on a friend or families laptop without explaining to them exactly
what it is and how to use it safely? I know I wouldn't.
The trouble is, most people will probably ignore the warnings, and
some of them will end up having their SSL sessions stripped and their
accounts hacked. Some will end up having access to their accounts
blocked for logging in from multiple countries in a short period of
time, and when they get phoned up by their banks to ask them why this
happened, they'll have no idea.
I wouldn't feel happy routing somebody elses Internet traffic over Tor
without *making sure* they understood the risks. For the general
public, I don't think anything short of a face to face discussion can
do that. Certainly not a landing page.

@_date: 2012-12-02 15:18:52
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Synchro of database server over Tor 
Hash: SHA512
Standard MySQL replication should work over Tor without issue.

@_date: 2012-12-16 21:13:45
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Make Wifi available through Tor? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
The problem is, there seems to be a much higher ratio of bad:good Tor
exit nodes than bad:good public wifi hotspots. I can't give you any
evidence for that, but that's just the impression I've got since I've
followed the project.
I wouldn't let my mother do her online banking over Tor without
explaining to her exactly how it works, and making sure she
understands what she is doing. Even if a bad exit node didn't SSL
strip her connection, she could still find her online banking access
frozen due to accessing it from IPs in unexpected countries.
If I were to offer a free Torified WiFi hotspot, I'd feel obliged to
put up a splash page explaining how it works, and force people to
check a box to state they understand, before they are given access to
browse anything else. I normally hate those sorts of splash pages, but
in this case, I would make an exception.
I would also set up a transparent http web proxy using the
HTTPS-Everywhere rulesets so that people without the HTTPS-Everywhere
browser addon still get some of its protection. Using:

@_date: 2012-02-21 09:13:58
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Scroogle is No More? 
Yes, it's been like that for a few days, and a few days prior to that it
was just throwing error messages about Google blocking them.
I've started using this instead: It provides Google search results, supports https, works without
javascript enabled, seems to be hosted in the Netherlands and they take
a good approach to privacy:

@_date: 2012-02-21 14:38:46
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Scroogle is No More? 
Strange. I don't get that error message when accessing startpage.com
over Tor. I'm not using a standard bundle like TorBrowser though. Would
be interesting to find out which particular aspect of your configuration
is leading to that error message.

@_date: 2012-02-21 20:48:17
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Scroogle is No More? 
I use startpage.com with javascript disabled, over Tor, without getting
any such warning. I have no reason to believe that you're actually
seeing that warning unless you provide some evidence.
If you're actually concerned that people shouldn't be using
startpage.com, then you will help us to reproduce the warning that
you're getting. Otherwise, I don't feel particularly compelled to change
my habits, or stop recommending startpage.com.

@_date: 2012-02-21 22:06:21
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Scroogle is No More? 
Someone who values evidence over ranting.
Because you wont be taken seriously by anyone otherwise.
I'm just trying to help you achieve something other than shouting into
the wind.
I just went to torproject.org and it told me to disable Tor so they
could log my IP address and send it to the feds. Nobody "sane" would use
torproject.org anymore. I'm going to provide no evidence for this.
When you see how seriously you take the above claim, you'll see how
seriously I take yours.

@_date: 2012-02-21 22:49:43
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Scroogle is No More? 
The only thing that my low-key friends and I have been trying to do is
discover the cause of a problem you reported. I am genuinely interested
in seeing what caused it, to see if it can be fixed. I myself have only
just started using that search engine because Scroogle has gone offline.
I notice you had difficulty identifying the point I was trying to make
in my analogy. I wont confuse you with any more of them.

@_date: 2012-02-29 16:24:15
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Magnet application in TOR Browser?? 
I believe that in order to use magnet URLs, you need to be able to
connect to the DHT (Distributed Hash Table) network. I think this uses
UDP, which Tor doesn't currently transport.

@_date: 2012-01-02 13:31:05
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Postfix + Tor (Was: remailers) 
I don't see why an email address needs to be memorable. That's what we
have address books for. I very rarely type an email address into my
email client. I usually just reply to an existing email, or use my
address book.

@_date: 2012-01-04 14:26:41
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Linux TransparentProxy setup and IPv6 
If you have a Linux machine with an IPv6 address, and you're using the
iptables technique described on that page, then you're going to leak.
"iptables" only applies to IPv4 traffic. You need to put in an explicit
rule using "ip6tables" to block all IPv6 traffic.
Alternatively, just disable IPv6 support on your machine.
Maybe the documentation should be updated with this information?

@_date: 2012-07-01 11:43:44
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [ZS] Re: Can one make money running anonymity 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
My research indicates it's exactly what I thought it was. No matter
how much you "mix" your coins with X other people, all you're doing is
making it so that if anyone wants to trace the origin of those coins,
instead of it leading directly back to you, it leads directly back to
a group of X people, including you. If X isn't sufficiently large, it
becomes a pointless exercise. There's no way X is large enough to
offer any sort of meaningful protection.

@_date: 2012-07-06 11:55:47
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Transparent e-mail encryption? 
Hash: SHA512
I wrote some free software which does *some* of what you described,
early last year. You can read about it and download it from my blog:
It encrypts all incoming email on the server, but I handle decrypting
inside my clients rather than using a proxy. It's pretty simple, and
will work with any MTA which can filter an email through an external
command. I use it with Exim. Other people use it with Procmail.

@_date: 2012-07-06 21:02:26
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] How to pin the SSL certificate for torproject.org? 
Hash: SHA512
The Tor project SSL certs are already pinned within Chrome. Search for
the string DOMAIN_TORPROJECT_ORG in:
I don't think Firefox has anything similar. Personally I use
HTTPS-Everywhere and Certificate Patrol, so I should be alerted to any
strangeness going on.
Chrome also has a default HSTS list embedded in it. My own domains
"grepular.com" and "emailprivacytester.com" are forced through HTTPS
even on the first visit, because they are hard coded into Chrome.
Although they're not pinned to a particular cert. You can add your own
domains to this list in Chrome as well. See
 for information on
how to do that. Also, the HTTPS-Everywhere project uses a script to
compile rulesets automatically from the Chrome list.

@_date: 2012-06-07 12:52:06
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] TOR Nodes 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
- From the Tor manual and "man torrc":
AllowSingleHopExits 0|1
This option controls whether clients can use this server as a single
hop proxy. If set to 1, clients can use this server as an
exit even if it is the only hop in the circuit. Note that most clients
will refuse to use servers that set this option, since most
clients have ExcludeSingleHopRelays set. (Default: 0)
So even if you configure your client to use single hop circuits, most
relays wont allow it.

@_date: 2012-06-20 23:21:14
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Orbot Data Overhead 
Hash: SHA512
I was concerned about the idle usage of Orbot myself when I originally
installed it and took some measurements. I decided that I couldn't
leave it turned on permanently because it was sucking up too much
bandwidth. I only get 500MB/month on my phone plan. Is it going to be
possible to significantly reduce the idle bandwidth usage?

@_date: 2012-06-30 14:06:00
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Can one make money running anonymity services? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Does anyone know a method of obtaining BitCoins anonymously, other
than mining them yourself?

@_date: 2012-06-30 17:32:45
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [ZS] Re: Can one make money running anonymity 
Hash: SHA512
I can't identify your logic.
I've no idea what "SR" is. "Tumbler" sounds like some sort of
mixing/laundering service. Which would require a *lot* of people to
use it in order for it to work in any meaningful way. If you know of
such a service that has maybe 50,000 people or more using it daily,
please let me know. My guess is that they all have several orders of
magnitude fewer users. I'm not a fan of pretend anonymity.

@_date: 2012-03-18 18:03:55
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Orbot and firewall? 
I used to use Droidwall, but I now use LBE Privacy Guard instead. LBE
Privacy Guard provides a per application network firewall, but it also
lets you block loads of other stuff on a per app basis too, like access
to location, the call history, contacts, IMEI and so on. When an app
tries to access one of these things, it pops up a confirmation dialogue
where you can specify allow/block and whether or not to remember that
choice. It is also free, but it also requires a rooted phone.
Although the above sounds a bit like an advert, I have no affiliation
with the author of the application other than as a very happy user.

@_date: 2012-03-20 09:42:44
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Orbot and firewall? 
Thanks for the info. I didn't realise that existed. It seems to work
quite well, but it's still not nearly as good as using LBE Privacy Guard.
Concerns about the app not being open source are legitimate. It's all
down to whether or not you're willing to trust them with root on your phone.
Here's the app on the google market:
Here's the authors website, in its original language, and using Google
translate to convert to English:

@_date: 2012-03-21 09:41:10
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Orbot and firewall? 
Funnily enough, I wouldn't have seen the above message had you not
replied to it. The troll found his way into my kill file after a
previous rant.
As I understand it, the LBE implementation supplies fake data, instead
of causing exceptions to be thrown. Eg, it will return a fake IMEI, or
an empty contact list etc. I've not had it crash any apps for me.
The reasons are mainly down to usability. When you install an app
through normal channels, LBE Privacy Guard sets sane defaults. Eg, it
will set access to location to be "Ask", so the first time the app
attempts to access my location a message will be popped up giving me the
option of allowing/blocking and remembering (or not) that decision.
It also lets you block access to the network per app, and it lets you
set permissions depending on wifi or 3g per app. This is important as it
is a lot easier for end services which are regularly polled to track
your location and behaviour if you're constantly popping on and off
different wifi networks (work/home/coffee shop etc). If you only connect
via 3g, then they're able to determine much less about you. Of course,
if you're using Orbot, that's even better.
The user interface is extremely well polished for an app like this too.
It is easy to see all of the apps that have permission to send SMS for
example at a quick glance, and whether or not LBE is blocking them. It
even displays how much bandwidth each individual app has used over wifi
and over 3g separately, with graphs. I can see how many times each app
has attempted to access some data, eg my call logs, and how many times
it has been blocked from doing so.
I completely understand why some people may not feel comfortable using
it though. Thoughts about the software being evil *have* crossed my
mind. I would be much happier if the source code was available. Even
happier if stock Android or Cyanogenmod had these capabilities built in.
I will stop, "shoving it down everyone's throat quite intensely," now.

@_date: 2012-03-23 09:09:30
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Azureus cannot work with Tor 
If your machine doesn't know its public IP address (because of NAT) and
all of its outgoing TCP traffic is forced over Tor (using TransPort),
and all of its non-TCP traffic is dropped, then it is safe from any such
protocol leaks.

@_date: 2012-05-01 21:29:23
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] ADDRMAP reversed IP bug 
No responses so I've taken this to trac.torproject.org -

@_date: 2012-05-06 13:24:40
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] can't enable SSL with IRSSI over TOR 
There's no point in adding a layer of SSL over hidden services; the
connection is already encrypted end to end.

@_date: 2012-05-06 18:18:31
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] can't enable SSL with IRSSI over TOR 
I guess so. There's a chance that the Tor daemon is running on a
different machine to the IRC server and somewhere between those two
machines the network is compromised.

@_date: 2012-05-08 12:02:23
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] orbot vs. tor 
On a "normal" Android device, you need to configure each app to use
Orbot via the proxy settings. However, on rooted devices, Orbot has
access to transparently intercept communications on a per app basis. I
believe it uses iptables, but I could be wrong.
You can do the same thing using the standard Tor client on desktops, if
you're using a decent operating system like Linux or BSD. You just need
to use the "TransPort" and "DNSPort" Tor options (see the docs), and
then use Linux's iptables or BSD's pf. The same isn't possible on
Windows. However, I believe it is possible to set up a virtual machine
on Windows running Linux/BSD and route your traffic through that for
transparent Tor access.

@_date: 2012-05-21 09:43:43
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] "*.onion" performance tru "onion.to" 
At a guess:
man torrc:
Tor2webMode 0|1
When this option is set, Tor connects to hidden services
non-anonymously. This option also disables client connections to
non-hidden-service hostnames through Tor. It must only be used when
running a tor2web Hidden Service web proxy. To enable this option the
compile time flag --enable-tor2webmode must be specified. (Default: 0)
My understanding that when enabling Tor2webMode, the number of hops
between you and the hidden service is reduced. This is because under
normal circumstances both the client and server get anonymity when using
hidden services. When somebody uses a tor2web style service though,
they're basically giving up their client anonymity to the web service,
so the number of hops for the client side of the connection is reduced
to improve performance.

@_date: 2012-05-31 16:42:12
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] How to Control middle Nodes? 
You may get better results by dropping the middle nodes altogether and
just using two hop circuits. Depends on your anonymity requirements.
Here's an old blog post I wrote to explain how to do it:

@_date: 2012-10-01 15:00:29
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] introducing ahmia search 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
It does work much better now, but I'm still seeing the browser freeze
occasionally when typing. Although web workers can't access the dom,
my suggestion wouldn't require that. It's just a case of catching
onkey events on the text field in the main gui thread, and then
passing the value of the field to a web worker to perform the
potentially long running process of running a search.
Looking much tidier now.

@_date: 2012-10-06 20:37:21
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [tor-dev] resistance to rubberhose and UDP questions 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
FYI, if you use TRESOR/Trevisor, you can protect your OS encryption
keys from cold boot attacks:
The basic idea being that your keys are shifted from RAM into the
debug registers of the CPU on boot, then all future crypto is done
directly on the CPU (AES-NI) without the keys re-entering RAM.
Of course, you will probably still have other sensitive data in RAM.
(I use this patch on my Ubuntu laptop)

@_date: 2012-10-06 20:54:55
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [tor-dev] resistance to rubberhose and UDP questions 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Not without some modifications. They currently provide patches for
vanilla 2.6.36, 3.0.9 and 3.0.43
Yes. So I don't always upgrade whenever my distro does. I keep an eye
on the commit log to see if there is anything specific that I
must/want to upgrade for.
I don't know, no. I wish they would. It would make my life much easier :)
FWIW, I wrote up a bunch of stuff I did to make my laptop more secure,
including using TRESOR, last year. There are some useful links in it:

@_date: 2012-10-06 22:44:36
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [tor-dev] resistance to rubberhose and UDP questions 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
"TRESOR is only compatible with real hardware. Run-
ning TRESOR as guest inside a virtual machine is gen-
erally insecure as the guest?s registers are stored in the
host?s main memory."
This is a serious project. They have considered many different styles
of attack, and have included attack code. The PDF is comprehensive.

@_date: 2012-10-06 22:49:15
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [tor-dev] resistance to rubberhose and UDP questions 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Also, the encryption/decryption is done using a key derived from the
password which you enter at the very beginning of boot up. Not with
the password or key you provide to cryptsetup/luks. This wasn't clear
to me when I wrote the blog post which I linked to. It's all in the PDF.

@_date: 2012-10-06 23:46:24
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] [tor-dev] resistance to rubberhose and UDP questions 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Yes. I replied too quickly to your email and realised my mistake
shortly afterwards. Hence the second email.
Yes. They do that. As is documented. I guess this is one of the
reasons why it's not in the mainline kernel.

@_date: 2012-10-17 11:18:02
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tor hidden service 'in cloud' 
Hash: SHA512
The problem with using VMs is that the physical host it is running on
can silently read the VMs entire memory, allowing it to easily read
the VMs disk encryption keys at any point after the VM has booted up.

@_date: 2012-09-18 14:37:41
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Hidden Services 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
If you do this, please honour peoples robots.txt files.

@_date: 2012-09-18 19:27:23
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Hidden Services 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
People use robots.txt to indicate that they don't want their site to
be added to indexes. If you want to ignore the site owners
wishes/intentions, you can of course pretend that robots.txt doesn't
apply to your particular indexing method because of some technicality.
That's not very polite though.

@_date: 2012-09-19 09:13:52
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Hidden Services 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
In almost all cases (99% or higher), robots.txt is used to indicate
that a site shouldn't be crawled, *because* they don't want it to be
indexed. The intention is painfully clear...

@_date: 2012-09-19 09:44:19
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Allow only tor connections to server 
Hash: SHA512
Can you change it to "Listen 127.0.0.1:1234" ?
Also, this isn't Tor specific, but it's something every Linux sysadmin
should do: Learn iptables. Block all traffic by default, and then
write rules to allow through only the traffic that you need.

@_date: 2012-09-26 11:42:35
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Tor and P2P (Hidden SMS) 
Hash: SHA512
I've had an idea for a while for a killer service for Orbot, but
haven't begun to start implementing it yet. I use an application
called TextSecure to send encrypted SMS. It hides the message that I'm
sending, but it doesn't hide who I'm talking to and when, which is
just as important.
If Orbot on my phone and my friends phone were both running hidden
services. Then they could both make a "direct" connection to each
other, and transmit SMS/BBM/Kik/WhatsApp style messages directly over
the Tor network between phones. The messages would automatically be
encrypted and the fact that either of us are even sending or receiving
messages, let alone who with, would be hidden.
This is not the same as using XMPP over Tor. XMPP requires a trusted
third party server to handle the relaying. This is P2P direct
communication using hidden services. It's not real-time IM chat. It's
SMS style chat (with acceptable delays), and the simplicity of the
user interface should reflect this. It would look very similar to the
native SMS app.
When one phone connects to another, it "knows" that the device it's
connecting to is running the hidden service that it is trying to send
a message to. However, the other phone, (the one running the hidden
service), has no idea who is connecting to it. So I think it would be
a good idea when sending a message that the phone connects to a hidden
service and says, "Hi. There's a message waiting for you at
xxxxx.onion. You can retrieve it using this long unique random code:
yyy". And then the recipient phone connects back to that onion address
to retrieve the message, supplying the unique code. That way, both
phones know the onion address of the person they're talking to.
Alternatively (this would be faster), in the original connection, it
could send the actual SMS content along with the "confirmation code",
and the message could appear to the recipient as "Unconfirmed Sender"
until the recipient phone successfully connects back to the sender
onion address to confirm that it sent it.
It could even allow multiple identities, with a different onion
address for each one.
Basically, it would provide encrypted, hidden, "SMS". In many
countries, the police can obtain information about who is SMS'ing who
without a warrant, they just need a warrant to view the content of
those messages. This would solve that problem.
Ideally, it would also use encryption to store the messages on the
phone side in case the phone is compromised. TextSecure uses EC public
key crypto for this. It takes incoming messages that aren't encrypted,
and encrypts them with the public key. You then use your private key
to decrypt them later. I believe the Guardian Project created a
library for encrypted sqlite databases which could come in handy there

@_date: 2012-09-28 14:34:46
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] introducing ahmia search 
Hash: SHA512
Am I right in thinking that the way this search engine works is that
the entire index is sent to the browser initially, and then the
browser locally searches that index? If so, that's a pretty neat way
of protecting peoples searches. Obviously, it wont scale, but you know
that already.
It feels like you're doing the search in the main thread as I type
into the search field, as it's blocking the user interface a lot. I
suggest you use javascript web workers for this purpose so you can
background the searching task onto a new thread. Or just get rid of
the whole "search as I type" thing. Gimmicks are fine, unless they
actually make the user experience worse.
Please provide https. At the moment, the search engine can be
trivially MITM'd and script inserted to log searches. Also, please
rethink your decision to let Google execute arbitrary code on your pages.

@_date: 2013-12-08 20:15:17
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Open phones for privacy/anonymity applications, 
Since the GSM f/w controls a radio, and thus the power, it may need a
FCC certification.  In which case you would need someone to finance
the certification every time a new version of the Gnu firmware is
released (FSF perhaps?).

@_date: 2013-12-11 02:01:34
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Why postfix cannot work on tor (was What are some free 
Postfix does not work with tor.
There are a few problems:
- Postfix does not have a SOCKS4a proxy option (in fact, no proxy
  option)
- TorDNS cannot handle MX lookups.  So running postfix on a
  transparent proxy fails because MX lookups fail.
- Torsocks has a documented feature to disable tordns, but it's
  broken.
Does Exim or Roundcube have a way around these problems?

@_date: 2013-12-11 09:19:33
@_author: Mike Cardwell 
@_subject: [tor-talk] Why postfix cannot work on tor (was What are some 
1.) Install Linux
2.) Set up Transparent Proxying as per
    3.) Install the "Unbound" caching DNS resolver on the same machine.
    Disable it's UDP support "do-udp: no", so it only does DNS lookups
    over TCP. Then it should be able to do MX lookups over Tor (without
    using Tors built in DNSPort service)
Now any MTA will work over Tor, Exim, Sendmail, Postfix, Qmail. For
bonus points, and completely anonymous email without having to use a
third parties remailer, configure Unbound to forward requests for
".onion" lookups to Tors DNSPort. An MX record of a .onion domain
will fail, but then the MTA will fall back to doing an A record
lookup, and will then connect to the relevant hidden smtp service. If
you want to test that, send an email to:
mike.cardwell at grepularmmmiatj7.onion
Obviously, that's not very anonymous as the .onion address contains
a substring of my normal domain, and my real name is included too,
and I've also not configured my SMTP server to obfuscate various
things about my machine that are leaked in the SMTP communication,
Received headers, Message-Id etc. But for testing, it's useful.

@_date: 2013-02-14 21:28:43
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] tor2web - How can I get my hidden service indexed? 
Hash: SHA512
This seems like a strange default to me. I can see why people would
want to create hidden services that can be discovered using ordinary
channels on the Internet such as search engines.
If a hidden service operator actually wanted to block search engines,
they'd know to create their own robots.txt file, or to add appropriate
meta tags to their HTML, or to simply block based on the User-Agent

@_date: 2013-07-01 10:27:11
@_author: Mike Cardwell 
@_subject: [tor-talk] Secure email with limited usable metadata 
If you're going to use somebody elses machine to access your webmail,
you probably want to make sure it has a unique password. Even to the
extent that your IMAP password for the same account is different. This
is because you should also be using two factor authentication for
webmail in case the untrusted machine is trojanned/keylogged. Then even
if it is keylogged they wont be able to do anything with the password
they gained.
The open source webmail application Roundcube has several plugins to handle two factor authentication using
different types of hardware tokens and protocols:
It's worth noting also that Roundcube has a PGP plugin now too based
on openpgp.js:
Your PGP key is never uploaded to the server. You paste it into a
textarea after logging in, and then it is stored in your browsers
"localStorage" (
Ordinarily I still wouldn't trust in-browser PGP, as every time you
log in, you have to hope that the server didn't send you some new
backdoored JS. However, if it's your own webmail installation on your
own server, you're using your own browser and all traffic goes over
https, you might feel that you can trust it.
Personally, I avoid using untrusted machines to access my email.

@_date: 2013-07-04 10:47:02
@_author: Mike Cardwell 
@_subject: [tor-talk] What would you put on a a Tor Wishlist? 
I would like the DNS resolver in Tor to support more RR types, e.g MX, TXT
and SRV. I would also like to be able to set up DNS records for hidden
services, so for example I could add MX+SRV records for a .onion address
so we can more easily do XMPP federation and SMTP between hidden services.
I would like to set up my own hidden SMTP service and have an address like:
  mike at 1234567890123456.onion
If I could add TXT records to the onion address then I could use PKA to
publish my public PGP key in the DNS by creating a TXT record like:
  mike at alfa:~$ dig +short txt mike._pka.1234567890123456.onion
  "v=pka1\;fpr=35BCAF1D3AA21F843DC3B0CF70A5F5120018461F\;uri=
  mike at alfa:~$ As described here:
  People might create Internet gateways for incoming email in a similar
manner to the way  works so that non-hidden SMTP
servers would be able to contact me using addresses like:
  mike at 1234567890123456.tor2web.org
Tor2web.org would then accept this incoming email and forward it on to the
MX records that I've published for 1234567890123456.onion.
Similar things could be done for XMPP.

@_date: 2013-03-06 21:34:29
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] How easy are Tor hidden services to locate? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
This is why ideally you'd run the hidden service from a machine that
doesn't know it's real IP, and has no way of figuring it out. Eg, use
a VM which has all of it's traffic transparently routed through Tor by
the host.
Of course, there may still be bugs in the virtualisation software that
allow an attacker to break out of the VM, but this is considerably
more secure than relying on the security of whatever PHP application
you're using on your website. Or you could just use two physical
machines instead of a VM, and hope there are no bugs in Tor its self.

@_date: 2013-05-24 12:57:57
@_author: Mike Cardwell 
@_subject: [tor-talk] You could use ModX to create .onion sites, 
A new CA could be generated by the Torproject and included with TBB. The
CA could be completely public, so anybody is able to download its private
key and generate a certificate using it. TBB could include this new CA,
and also be patched so that certificates signed using this new CA only
work for .onion domains. Then people could grab the CA and use it to
generate a certs for their .onion address.
Then we'd gain all the efficiencies provided by SPDY and none of the
drawbacks of SSL certificate warnings.
There should be no issue with people having access to this CA's keys
as long as it's only used for .onion domains.
Actually, I wonder if it's possible to just patch TBB to not do
certificate verification for .onion URLs?
The only drawback I can see for this is if people incorrectly import
this new CA into their non-TBB browser, meaning that people could
use the new CA to generate certificates for non-.onion addresses
and MITM *their* connections.
Maybe Mozilla would allow the Torproject to run a CA which only
works for .onion domains, and include code for that restriction
SPDY *must* be much more efficient than HTTP over Tor. It has
compression and multiplexing so multiple resources can be sent down
the same single connection at the same time, and it has push so that
the server can look at the resource that has been requested and send
along all of the other relevant resources at the same time, rather
than waiting for the browser to request them. Eg, browser asks for
html file, so server responds by sending the html file *and* it's css,
javascript and images all at the same time. Compare this to the browser
requesting a HTML page, receiving the HTML page, parsing it, seeing
that it needs a CSS file, requesting that, seeing that it needs a JS
file, requesting that. Especially seeing as a lot of resources are
fetched in the order they appear in the HTML and block other resources
from being requested until they have finished being fetched themselves,
eg javascript and css.
SPDY is currently supported by Firefox, Chromium and Opera. A few
examples of sites that already have SPDY enabled: Google.com+mail,
Facebook, Twitter, Wordpress.com. Apache has a module for it:
 and the latest versions of Nginx
have it built in.
Yeah, I'm a fan of SPDY and I think Tor especially will benefit
hugely from sites enabling it.

@_date: 2013-11-02 13:50:18
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] Basics of secure email platform 
Before becoming a secure e-mail provider, first you should understand
how users can best protect themselves.
Users should not relay outbound messages to someone elses SMTP server.
That's needless leaking.  They should run their own mail server.
Ideally, when a mail server sends a message, it takes the most secure
path first, and downgrades the security as needed until the message is
sent.  This means it should make attempts in this order:
  1) Create a list of tor exit nodes that do not block port 25
  2) Command the tor daemon to exit those nodes exclusively.
  3) Send the message SSL over Tor, direct to the recipients mail server.
  4) If that fails, SSL without Tor direct to the recipients mail server.
  5) If that fails, send in the clear direct to the recipients mail server.
  6) If that fails, send in the clear to the recipients mail server
     via non-blacklisted relay.
Postfix is too limiting to be able to handle the above job.  This is
the *real* problem for tor users.  If you want to work on a project to
improve users e-mail security, work on the tooling problems.
If you're really determined to simply be just another e-mail provider,
examine hushmail.com, countermail.com, and safe-mail.net first.  Those
providers are on the right track, because they give a means for
novice users to have end-to-end encryption.  Darkmail is also
something to keep an eye on.
Also make sure the owner is not a U.S. citizen.

@_date: 2013-11-22 17:34:10
@_author: Mike Cardwell 
@_subject: [tor-talk] "Safeplug" 
They probably wont be happy when their bank locks them out of their
account for accessing it from multiple different countries in a short
period of time too.
You shouldn't just route people through Tor without their knowledge.
They need to understand the risks and adapt their use accordingly.

@_date: 2013-11-23 20:03:10
@_author: Mike Cardwell 
@_subject: [tor-talk] "Safeplug" 
When your traffic comes out of a Tor exit node, there is a significantly
increased risk of passive and active MITM attacks against you, and also
increased risk of being locked out of your accounts.
I did not say, "don't route people through Tor". I said, "don't route
people through Tor without their knowledge."

@_date: 2013-11-24 02:04:55
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] tordns incapable of MX lookups (was Basics of secure 
You guys are getting hung up on the wrong thing.  Before talking ports
(which is a non-issue), realize that tordns cannot do an MX lookup.
This remains the biggest hurdle to sending mail.
Postfix must run with a transparent proxy (no SOCKS proxy capability),
so it relies wholly on tordns for MX lookups.  Torsocks has a (now broken) feature to disable TorDNS.  If tordns
could be disabled, then postfix could do an MX lookup.  It would be a
leak, but at least it would work.  At the moment, the tordns disabler
has been removed, so there is no hope of running a mail
server... Unless someone comes up with a SOCKS-capable mail server.

@_date: 2013-11-26 10:54:58
@_author: Mike Cardwell 
@_subject: [tor-talk] "Safeplug" 
I don't have any hard data, it's just what I've casually observed. Take
from that what you will. I will explain my reasoning end of this
Yes. Therefore my statement holds: "You shouldn't just route people
through Tor without their knowledge. They need to understand the risks
and adapt their use accordingly"
Yes, we need both ends of the connection to understand and account for the
problem of cycling IPs/countries.
This whole thing is an idealism vs pragmatism argument. Your argument
relies on Tor being just another network like any other. Whereas I'm
saying it is different and therefore should be treated differently. I
don't have any data to back this up, so you'll probably just label it
FUD, but IMO a lot of the Exit nodes are malicious and you're much more
likely to have your traffic compromised by a seriously malicious hacker
when using Tor than when not. This is why I would not route my mums
traffic through Tor without making sure she understood the difference to
her "normal" Internet connection.
To be completely clear: Tor is one my favourite OSS projects. I think
it's a great and worthwhile piece of software and is very important for
many people. Hopefully one day in the not too distant future my C foo
will be good enough to contribute, I would love to be employed by the
Tor Project at some point. I don't wish to dissuade people from using
it. I just want people to be safe when they do.
If I, as a random geek, wanted to mess around with MITM attacks to see
what information I could steal, I have a few options: I could do it
on my LAN at home, targetting friends and family. I could do it at
work and risk my job. I could go to somewhere with an open wifi hot
spot and target a couple of coffee drinkers reading the news. Or I
could spend a couple of minutes setting up a Tor exit node from the
comfort of my office, getting sustained access to the traffic of
thousands of strangers all over the World. This is why I think
malicious Tor Exit nodes are widespread: Because setting them up is
easy, attractive and safe.

@_date: 2013-10-06 11:19:35
@_author: Mike Cardwell 
@_subject: [tor-talk] Stop pushing stackexchange in every thread 
I've just personally decided to leave answers on every tor.stackexchange
question pointing people to the tor-talk mailing list. And you can just
ignore me. Well, I haven't, but you get the idea.
I think that pointing people to questions which already have answers
on StackExchange is a good idea as it helps to reduce duplicated effort.
I think that redirecting relevant discussion off-list is a very bad
idea. StackExchange should be used as a knowledge base, not as a
replacement for the mailing list.
That discussion belongs here, not on StackExchange.

@_date: 2013-09-03 09:02:27
@_author: Mike Cardwell 
@_subject: [tor-talk] Contents of PirateBrowser 0.6b 
Did anyone think to ask them? Maybe they are. Maybe they're not, but
will do if asked? There's not much point speculating.

@_date: 2014-04-18 12:50:02
@_author: tor@lists.grepular.com 
@_subject: [tor-talk] securely reading and posting to mailing lists (was 
You can see this thread securely using lynx with this URL:
  snews://news.gmane.org:563/CACYKwB0HZfvsa_k_A6dp4-PPOACJONn+HtNtLbvxYMmRponVKA at mail.gmail.com
Ironically, this list does not allow anonymous posting.  But FYI, you
would normally post anonymously by using mixmaster to send mail to
tor-talk at lists.torproject.org.  (BTW, this is how my message was sent,
but you will notice that it does not go through to the list).
Anyway, this is the technique you should use on mailing lists that are
mindful of the security of participants.

@_date: 2014-02-14 10:31:35
@_author: Mike Cardwell 
@_subject: [tor-talk] Ostel and WebRTC over Tor? 
Unless your VOIP app talks to the Tor Control Port, and sets up each circuit
and stream it's self, rather than letting Tor do it automatically.

@_date: 2014-01-21 09:49:09
@_author: Mike Cardwell 
@_subject: [tor-talk] Security issue 
The one that is core to the way that the web allows different origins to
interact with each other:
It's not a Firefox thing, it's a "Web" thing.
That's not correct. As that page explains, you can only access the
content of a cross-origin request if the "other" origin sends a HTTP
response header saying so (Access-Control-Allow-Origin). Cross origin is
prevented by default.
If you have a web server listening on 127.0.0.1 and that web server sends a Access-Control-Allow-Origin header with it's response, then
yes, you will be able to communicate with it from other websites.
By design.

@_date: 2014-01-21 09:58:45
@_author: Mike Cardwell 
@_subject: [tor-talk] Security issue. Firefox in Tor Browser Bundle allows 
There is some misunderstanding of cross-origin policy here. Cross-origin
policy does not prevent the cross-origin request from taking place. It
only prevents you from being able to read the response.
There would be no point in preventing the request from taking place
as people can initiate them already, without even using JavaScript.
For example, the above request could have been made by just sticking
this in some HTML:
There is no cross-origin policy violation by doing that.
You can not read the response of a cross-origin AJAX request *unless*
an Access-Control-Allow-Origin header is returned with the response,
and only if that Access-Control-Allow-Origin header allows your
particular origin (or all origins) to do so.

@_date: 2014-01-21 10:08:13
@_author: Mike Cardwell 
@_subject: [tor-talk] Security issue. Firefox in Tor Browser Bundle allows 
If you can use XMLHttpRequest to perform a request against a machine
on your LAN that isn't using CORS, and then read the response, then
there is a bug, and you will get a healthily sized cheque from Google
or Mozilla for reporting it to them. If you can't read the response
then there isn't a bug. What you're seeing is: how the web works.

@_date: 2014-01-21 14:24:17
@_author: Mike Cardwell 
@_subject: [tor-talk] Security issue. Firefox in Tor Browser Bundle allows 
I don't think the XHR method provides anything above what you can do
with timing load/error events on dynamically generated imgs.
It is not a good default for regular browsing, but it is what we have
and it is how the web was designed, and there is no way back now without
replacing the web with something new. The web is too interconnected
to be safe, but that interconnectedness is also what has made it as
big as it is today.
I personally use RequestPolicy in Firefox to prevent *all* cross-origin
requests from any site to any other site, be they XHR, images or any
other type of content. It has a whitelist system built in which is
very similar to the way NoScript works. If I had to choose between
giving up RequestPolicy or NoScript, I would give up NoScript without a
second thought. I don't use TBB myself, but it's my understanding that all TBB
traffic goes through Tor, and thus doesn't have access to localhost
or the LAN anyway, making this a non-issue... If connections are
being made from TBB without going via Tor, then there is a serious
leak in TBB. I'm not convinced this is happening though.

@_date: 2014-01-26 15:06:53
@_author: Mike Cardwell 
@_subject: [tor-talk] Thunderbird leak 
I just blogged about a general security issue in Thunderbird which may
also affect people who are using Tor:
Basically, an email can be crafted such that when you click a link in
that email it is opened within a Thunderbird tab instead of in your
usual (potentially torified) web browser. Bypassing any other defenses
you might also have, including NoScript etc.

@_date: 2014-01-26 18:34:59
@_author: Mike Cardwell 
@_subject: [tor-talk] Thunderbird leak 
Yes, I am sure. I am not on the Tails list. Perhaps somebody who is already there might
bring it up?

@_date: 2014-01-26 18:43:45
@_author: Mike Cardwell 
@_subject: [tor-talk] Thunderbird leak 
As mentioned in the blog post, when right clicking one of these links
in order to select "Copy Link Location" from the context menu, you will
find that the option is missing. I imagine that many people at this point
would skip their usual copy/paste routine and just click the link for
You're definitely not supposed to be able to do this. Mozilla
acknowledged that it was a security issue and classified it as moderate.
It has been over two years since I told them about it and it hasn't
been fixed, hence why I am now making it public.

@_date: 2014-01-27 14:40:29
@_author: Mike Cardwell 
@_subject: [tor-talk] Thunderbird leak 
Security related bugs are hidden by default and only made public when
a fix is rolled out. This is very common. They are aware that this issue
is now public information so I assume they'll be unlocking it at some
Unfortunately, in this instance, I think this private disclosure has
allowed the issue to go unfixed for a long time. I probably should have
made it public much sooner.

@_date: 2014-01-28 07:39:06
@_author: Mike Cardwell 
@_subject: [tor-talk] Thunderbird leak 
The above statement is all wrong. Thunderbird by default displays emails
as original HTML. Only when you install TorBirdy does that change.
No, I don't believe that played any part in the classification.
It requires the user to receive an email, and then click a link in that
email. This is not unusual behaviour.
It is a horrible bug for Tor users who are using Thunderbird without
TorBirdy. To clarify, at no point did I state that TorBirdy users were
affected. I brought up the issue here exactly so that those sorts of
issues could be investigated.
I suggest if you are going to make any further statements about the
way the bug works, you replicate it first.
The bug report is now public. Somebody has submitted a patch, but
they've also suggested that there may be similar bugs in the MathML
code waiting to be found.

@_date: 2014-01-28 09:11:35
@_author: Mike Cardwell 
@_subject: [tor-talk] Thunderbird leak 
If somebody put my name in quotes, I wouldn't immediately jump to the
conclusion that they're claiming that it isn't my name, nor would I
care. But then I wouldn't go around making incorrect claims about bugs
without testing them first either. I'm sorry if I hurt your feelings
by pointing out that you were wrong on your employers bugzilla board,
but it's your own fault for not backing up your claims. Unless you've
got something useful to add regarding the bug, please don't continue
adding noise, on this list, or on the bugzilla page. All you've done
so far is confuse matters.
I wont be taking part in this thread on tor-talk any further. If anyone
is interested in following the issue, see:

@_date: 2014-07-24 13:38:57
@_author: Mike Cardwell 
@_subject: [tor-talk] Android app: Torrific 
One suggestion: Test this on a network which dishes out IPv6 addresses.
None of these Firewall apps seem to take IPv6 into consideration. So if
you wander onto a WiFi network which dishes out v6 addresses and then
one of your Apps tries to connect to a host which supports v6, like for
example Google or Facebook, then it will bypass your iptables rules.
You need to set up rules using ip6tables for IPv6 too.
Also, make sure that the rules are applied prior to any network
connectivity coming up.

@_date: 2014-06-27 13:28:23
@_author: Mike Cardwell 
@_subject: [tor-talk] How does DNS work with .onion addresses? 
There is an exception to this rule. If you use DNSPort + TransPort +
VirtualAddrNetwork + AutomapHostsOnResolve, Tor provides a DNS resolver.
And if you perform an A/AAAA record lookup for a .onion domain against
that DNS resolver, then it will pick a unique IP address from a pool you
specified (10.0.0.0/8 or similar) and return that. It will then remember
the Onion->IP mapping. It is then your job to intercept connections to
those IPs on your router and forward them to the host/port specified in
TransPort. Tor will see those connections and figure out the hidden
service you're trying to connect to by reversing the Onion->IP mapping
that it provided earlier during the DNS lookup.
This is why any device on my LAN can talk to hidden services, without
having to install Tor on each of them, albeit less securely than if
they all had Tor installed locally of course.

@_date: 2014-03-06 09:44:56
@_author: Mike Cardwell 
@_subject: [tor-talk] Advice on XMPP as a hidden service 
Depends. When somebody adds "user at chat.cpunk.us" into their XMPP client
it will do a DNS SRV lookup of "_xmpp-server._tcp.chat.cpunk.us" and
currently will receive "chat.cpunk.us" as the response, and so connect
to the host "chat.cpunk.us". I think a lot of clients fall back to
connecting directly to the A/AAAA record if the SRV record lookup fails.
So you *could* just add an additional higher priority SRV record to
chat.cpunk.us containing your onion address. I assume in this situation
most clients would try to connect to the .onion address, fail immediately
because they're not using Tor, and then fall back to the 2nd SRV record
However, there are probably many badly written clients out there which
will fail in lots of exotic ways. Allowing people to sign up with
"user at example.onion", would help the service work with clients that don't
support SRV records. People using Tor wouldn't be able to do SRV lookups
anyway as they're not supported by the Tor resolver. It would also prevent
DNS spoofing. "user at example.onion" should also help avoid various leaks
that clients might have.
Hidden services offer several benefits. If you're not using a hidden
service, your client could accidentally connect to the server outside
of Tor. The client might do something "helpful" like fall back to making
a direct connection when it can't connect to the configured socks proxy.
It prevents DNS spoofing. It prevents malicious exit nodes attempting
to discover information about the traffic they're exiting, attempting
to perform SSL stripping attacks etc.
If any of this relies on UDP, then no. Even if it's entirely TCP, the
latency added by onion routing will probably be too much in most cases.
Test it.
I don't know.

@_date: 2014-05-14 09:23:30
@_author: Mike Cardwell 
@_subject: [tor-talk] darkweb-everywhere - was: Using HTTPS Everywhere to 
I would prefer it if the people who run websites with hidden service
alternatives would simply check if the client IP is a Tor exit node,
and then advertise the availability of the hidden service to such
users inside the actual website.
This wouldn't be that difficult either. We have the Tor DNSEL, and
there are also a few Apache modules which allow you to perform DNSBL
style lookups on the client IP and perform different actions based on
the result, such as setting environment variables/headers etc.

@_date: 2014-05-14 16:19:04
@_author: Mike Cardwell 
@_subject: [tor-talk] darkweb-everywhere - was: Using HTTPS Everywhere to 
On the other hand, I could implement my solution today on my website in
probably less than 20 minutes and it would work with all browsers.
Whilst the header solution would require one or more browser plugins to
be written, tested, maintained and distributed. It would be nice if it
would come pre-installed with TBB, but until it does, I'm not going to
hold my breath waiting.
However it is implemented, my main concern would be that users are
simply informed of the existance of the onion site, rather than being
force redirected to it.
To make it even simpler, maybe use a meta tag.
The ideal solution IMO would be a generic web standard which allows us to
advertise the existence of alternative domains which can be used to reach
the same content. That way, browsers might have native support without a
plugin being required. The biggest issue with that is probably how to
display the info in the browser UI. It seems Firefox and Chrome are trying
to display as little info as possible to the user these days.
Another use case for the generic web standard route would be general
censorship resistance and fault tolerance. If access to a website gets
blocked or fails for some reason, the browser may be able to pop up a
message informing the user how else they can access the content if they
have previously visited the site and received a list of
alternate domains.

@_date: 2014-05-30 08:11:55
@_author: Mike Cardwell 
@_subject: [tor-talk] [OT[ New web-cookie policies on internet 
Myself and a few other people have been slowly building an Adblock
filter list to remove these cookie warnings from sites for about 2
years now:
I'm not the lead developer, I just submit the occasional rule.
Anyone wishing to use the list or contribute more rules is more
than welcome.
They're especially annoying when they use a cookie to remember
your cookie preferences, because those of us who know what we're
doing don't allow cookies to persist for long, so end up seeing
the warning every time we visit a site (unless we're using the
above filter list in Adblock of course).

@_date: 2014-05-30 18:58:31
@_author: Mike Cardwell 
@_subject: [tor-talk] [OT[ New web-cookie policies on internet 
It doesn't help in that regard, and doesn't claim to.
That can be entirely automated:
Deletes the cookies and local storage that a site created when you
close the tab.

@_date: 2014-05-30 21:36:27
@_author: Mike Cardwell 
@_subject: [tor-talk] [OT[ New web-cookie policies on internet 
All it does is hide the notices yes. There is no reason to block first
party cookies from being set. It doesn't get you anything. What is
important is for the cookies not to leak cross-site, and for them to
be deleted when you leave the site.
Then allow cookies?
If your worry is that the adblock filter I mentioned will have hidden
this particular notice from you, then don't. Nobody has written that
rule, and the nature of the notice means that nobody would.

@_date: 2014-10-31 12:23:02
@_author: Mike Cardwell 
@_subject: [tor-talk] Facebook brute forcing hidden services 
So Facebook have managed to brute force a hidden service key for:
 If they have the resources to do that, what's to stop them brute
forcing a key for any other existing hidden service?

@_date: 2014-10-31 12:50:21
@_author: Mike Cardwell 
@_subject: [tor-talk] Facebook brute forcing hidden services 
You don't get to pick the ".onion" address. It is derived from the key
you randomly generated.
However, you can just keep generating keys over and over again until
you get one that matches what you want. People have been doing this
to choose their own prefixes for a while now, but this is the first
time I've seen somebody generate a full string of their own choosing.
If facebook can do that, then so can GCHQ and NSA. And if they can
do that, they can brute force a key which matches the .onion address
of any existing hidden service. So they can then MITM hidden services.
I don't think I'm being dramatic when I say this proves that Tor
hidden services are now completely broken. I'd like somebody to
show me that I'm wrong for some reason though...

@_date: 2014-10-31 13:02:34
@_author: Mike Cardwell 
@_subject: [tor-talk] Facebook brute forcing hidden services 
Getting one ending "corewwwi" seems incredibly lucky to me. Did they tell
you how many keys they generated starting with "facebook" and how long it
took them?

@_date: 2014-10-31 17:14:20
@_author: Mike Cardwell 
@_subject: [tor-talk] Facebook brute forcing hidden services 
Here is their blog post about the matter:
  They have successfully managed to get a certificate issued with
facebookcorewwwi.onion in the subjectAltName field. The cert file:
  The subjectAltName:
  DNS:certly.io, DNS:*.certly.io, DNS:owa.certly.io, DNS:mail.certly.io, DNS:autodiscover.certly.io, DNS:*.assetsrv.com, DNS:facebookcorewwwi.onion
