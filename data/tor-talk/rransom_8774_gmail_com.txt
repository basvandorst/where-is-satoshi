
@_date: 2010-08-20 18:45:55
@_author: Robert Ransom 
@_subject: polipo 
As I understand it, Polipo can't scrub the headers of an HTTPS request,
even if you use it as an HTTPS proxy.
Robert Ransom

@_date: 2010-08-25 20:28:18
@_author: Robert Ransom 
@_subject: Google and Tor. 
On Wed, 25 Aug 2010 20:04:01 -0700
If Tor exit nodes were allowed to bypass Google's CAPTCHA, someone
could put up a low-bandwidth Tor exit node and then send their own
automated queries directly to Google from their Tor exit's IP.
Robert Ransom

@_date: 2010-08-12 00:50:29
@_author: Robert Ransom 
@_subject: Restricted Exit Policy Port Suggestions? 
I just looked through the IANA-registration-based services file from
iana-etc 2.30 ( as installed
to /etc/services on Arch Linux).  Here are my recommendations:
* 70 (Gopher)
* 504 (Citadel (a BBS; see ))
* 553 (PIRP (see )
* 564 (9P (related to Plan 9; documented at multiple sites))
* 1649 (IANA-registered Kermit port)
* 2401 (CVS pserver)
* 2628 (DICT (see  and/or IETF RFC 2229))
* 3690 (Subversion)
* 4155 (bzr version control system)
* 4349 (fsportmap (related to Plan 9))
* 4691 (Monotone version control system)
* 5999 (CVSup)
* 6121 (SPDY)
* 9418 (Git)
* 11371 (HKP (?OpenPGP HTTP Keyserver?))
Gopher and Kermit are still in use; Citadel is in use, and the protocol
used on port 504 appears to support TLS.  PIRP may or may not be in
use, but I do not expect abuse complaints related to it.  9P is useful
over the Internet, and the Plan 9 ports are unlikely to be exposed to
the Internet (or accessed!) unintentionally or by technically clueless
users for the foreseeable future, so they should not result in abuse
complaints.  CVSup can be used to upgrade FreeBSD to a -CURRENT
system.  The rest of the ports listed above need no further explanation.
Other ports to consider:
* 194 (IANA-registered IRC port)
* 994 (IANA-registered IRC-SSL port)
* 1080 (IANA-registered SOCKS port)
* 1789 (in IANA services file, registered to DJB; described only as
  ?hello?; possibly useful for testing connectivity to a
  soon-to-be-public server)
* 5191..5193 (other AOL ports; 5190 is already listed)
* 5556 (FreeCiv (turn-based game))
* 5688 (GGZ Gaming Zone (probably low-data-rate, although the protocol
  is probably not useful over Tor and should be checked for unwanted
  information disclosure))
* 6665 (in IANA services file; described only as ?IRCU?)
* 6666..6673 (not listed in IANA services file, but used unofficially
  by the Inferno VM; overlaps with customary IRC ports; no ports in
  this range are listed as used by file-sharing programs)
* 8074 (Gadu-Gadu)
* 8990..8991 (in IANA services file; described as ?webmail HTTP(S)
  service?)
I don't expect these ports to cause much trouble for the Tor exit node
(except possibly the IRC ports).  Port 1080 can be used to reach
BitTorrent or other rude services, but that's a little trickier for the
client to set up than Tor alone, and it is less likely to result in
DMCA complaints sent to the Tor exit operator (although the SOCKS
server operator may complain).
Robert Ransom

@_date: 2010-08-12 07:01:10
@_author: Robert Ransom 
@_subject: Restricted Exit Policy Port Suggestions? 
What you need is a federal prosecutor willing to put the DMCA-abuse
spammers behind bars for a zillion counts of perjury.  The threat of
the EFF sponsoring an occasional lawsuit over a blatantly false
accusation won't deter them; the spammers operate as ?independent?
corporations with no real assets in their names, and if one shell
company gets zapped in civil court, they'll close it and start two new
ones running the same software the next day.  The threat of being sent
to prison for the next 2000 years might make those scum turn off their
spambots and go ooze back to wherever they came from.
Robert Ransom

@_date: 2010-08-14 08:37:00
@_author: Robert Ransom 
@_subject: DuckDuckGo now operates a Tor exit enclave 
On Sat, 14 Aug 2010 16:09:18 +0100
I don't remember where I read this, but at the moment, exit enclaving
only works if your Tor client has already downloaded and cached the
relay descriptor for the destination host.
Robert Ransom

@_date: 2010-08-01 22:54:47
@_author: Robert Ransom 
@_subject: Padding again Was: Practical web-site-specific traffic analyses 
Assuming the user can't just make his Tor node a relay and wait for
other random people to start stuffing their data through it, I would
suggest the following padding strategy:
* Limit the Tor client's download bandwidth to about 10 kB/s or less,
  to reduce the amount of padding needed.
* Limit the Tor client to one TLS connection, so that all incoming
  traffic is roughly indistinguishable to the attacker we're
  considering (a passive eavesdropper on the user's link to the Tor
  network).
* If possible, introduce delays into outgoing non-RELAY_SENDME cells to
  mask keystroke timing.
* To pad your connection, download a large, useful file through Tor in
  the background.
A higher-latency anonymity service within Tor would be a Good Thing,
but we doesn't seem to have one at the moment, and it's probably not
necessary to block this attack.
Robert Ransom

@_date: 2010-08-15 09:31:36
@_author: Robert Ransom 
@_subject: DuckDuckGo now operates a Tor exit enclave 
On Sun, 15 Aug 2010 17:40:16 +0200
I don't know whether Eugen Leitl is connected to DuckDuckGo, but he has
routinely posted/forwarded Tor-related news stories to the mailing
list.  Search for his name in the archives at
As for whether the blog post is an advertisement, Gabriel Weinberg
created, owns, and operates DuckDuckGo, and readers of his blog are
presumably interested in his business ventures and already aware of
From a comment posted by ?phobos? (Andrew Lewman) on
DuckDuckGo probably allows non-SSL access for the same reasons.
Also, they would need to have an HTTP service that redirects to their
HTTPS URL in order to support users typing ?duckduckgo.com? into a
browser without a URL scheme, such a redirect can't be sent before the
browser has sent the request (and URL) in the clear, and once the user
has sent a request in the clear, sending the response back in the clear
doesn't hurt their privacy any further.
But it wouldn't be needed *if* you could ensure that you are using the
exit enclave.
It looks like they mainly use JavaScript to load search results lazily
(when the user scrolls down so that the end of the page is visible).
Their FAQ () says that they are
actively working on a non-JavaScript version.  I hope they finish it
soon; their site wedged my browser the first time I tried it.
For now, Torbutton can block many of the scary JavaScript-based attacks
while still allowing JavaScript to run.
I don't know why Gabriel Weinberg didn't post a link to his blog post
to the list himself.  Advertisement or not, it is certainly an
appropriate news item for this list.
Robert Ransom

@_date: 2010-08-17 12:09:29
@_author: Robert Ransom 
@_subject: Tor Project 2008 Tax Return Now Online 
On Tue, 17 Aug 2010 09:05:27 -0700
What do you expect the Tor Project to do with zillions of dollars?
Using donated funds to operate more relays, bridges, and exit nodes
won't help much -- Tor nodes need to be dispersed among as many
different operators and ISPs as possible.  Using donated funds to
improve the Tor software is a good thing, but there is a limit to how
much money can be thrown at that -- Tor developers must be competent
programmers, and must understand the Tor software and protocol well.
Also, remember that Tor's opponents would put much more effort into
blocking Tor if it were heavily promoted in the Western media.  (China
and Iran are not Tor's only opponents -- here in the US, misguided
politicians want to criminalize operating a Tor relay (see S. 436
What are you studying?  Perhaps we can help you find a way to work on
Robert Ransom

@_date: 2010-08-17 12:28:02
@_author: Robert Ransom 
@_subject: Tor Project 2008 Tax Return Now Online 
On Tue, 17 Aug 2010 12:09:29 -0700
Oops -- I just re-read the bill, and it's somewhat less broad than I
thought when I first saw it.  It still seems to criminalize running a
Tor relay with a directory mirror, or running a Tor relay without full
logging, or running a Tor relay at all if you also run a web server or
provide an Internet mail-like service.
Robert Ransom

@_date: 2010-12-26 05:56:38
@_author: Robert Ransom 
@_subject: Any way to secure/anonymize ALL traffic? 
On Thu, 23 Dec 2010 09:21:08 -0500
The transparent proxying firewall rules on the Tor wiki are intended to:
* not affect any traffic to or from Tor,
* redirect all other outbound TCP connections into Tor's TransPort,
* redirect all other outbound DNS packets into Tor's DNSPort, and
* drop all other outbound packets.
But the only way I know of to test whether your computer is leaking DNS
packets without disturbing your firewall configuration is to use a
packet sniffer.
Robert Ransom

@_date: 2010-12-26 07:07:22
@_author: Robert Ransom 
@_subject: Any way to secure/anonymize ALL traffic? 
Maybe, but it would be better to set the time zone to US Eastern Time
(America/Detroit on at least glibc-based Linux distributions), so that
you'll blend in with English-speaking T(A)ILS users.
Robert Ransom

@_date: 2010-12-26 19:30:24
@_author: Robert Ransom 
@_subject: tor is blocked in china 
On Mon, 27 Dec 2010 10:41:26 +0800
The problem is that Vidalia forces Tor's 'UpdateBridgesFromAuthority'
option on.  When the UpdateBridgesFromAuthority option is on, and a
Bridge line contains a fingerprint, Tor contacts the bridge authority
to ask for the bridge's descriptor before contacting any bridges.
The safest thing to do is to use only Bridge lines containing
fingerprints, and turn off UpdateBridgesFromAuthority.  This way, Tor
will not contact the bridge authority, but will check the fingerprints
of the bridges it connects to so that it can detect man-in-the-middle
attacks.  Unfortunately, Vidalia will not allow you to configure Tor
that way.
Robert Ransom

@_date: 2010-12-29 16:35:40
@_author: Robert Ransom 
@_subject: How does a ftp-server log real ip-address of client machine? 
Your FTP client sent your IP address to the server.
To prevent your FTP client from sending your IP address to the server,
you need to use an FTP client that supports 'passive mode', at the very
least.  Setting 'passive mode' may or may not be enough; if you want to
make sure the FTP client you want to use won't leak information, audit
its source code.
Robert Ransom

@_date: 2010-11-19 01:19:49
@_author: Robert Ransom 
@_subject: Tor 0.2.1.26-1~~lenny+1: segfault with libcryto.so.0.9.8 
On Fri, 19 Nov 2010 09:44:47 +0100
No.  The core dumps contain all session keys and secret keys which Tor
was using at the time, and those must not be disclosed.
If you have installed the debug symbol package corresponding to the
version of Tor, yes, they are useful.  Use GDB or one of its frontends
to print a traceback from the core.  The traceback should be safe to
Robert Ransom

@_date: 2010-11-21 05:03:08
@_author: Robert Ransom 
@_subject: SOCKS 4a or SOCKS 5 when using Polipo? 
That was the original reason to use an HTTP proxy between Firefox and
Tor.  Firefox can now be configured to resolve hostnames using the
SOCKS proxy -- set the ?network.proxy.socks_remote_dns? option in
about:config to ?true?, or use Torbutton, which automatically sets that
The current reason to use an HTTP proxy between Firefox and Tor is that
Firefox has an inappropriately short, hard-coded timeout for
connections through SOCKS proxies.  See
Like the SOCKS 4A protocol, the SOCKS 5 protocol allows clients to
specify a hostname instead of an IP address, and Polipo does so.  Other
clients, including Firefox with the (well-hidden) socks_remote_dns
option turned off, may not specify a hostname to a SOCKS 5 server.
Robert Ransom

@_date: 2010-11-24 07:36:20
@_author: Robert Ransom 
@_subject: Onion url's 
See  for a description
of how Tor connects to hidden services.
Current versions of Tor retrieve only v2 hidden service descriptors.
Each v2 hidden service descriptor is stored on 6 relays chosen
pseudo-randomly from those assigned the HSDir flag in the current
consensus.  Robert Ransom

@_date: 2010-11-24 07:41:06
@_author: Robert Ransom 
@_subject: Do I need an updated .torrc file? 
You only need a new torrc if your current one causes Tor to stop
working or emit warning messages.
Robert Ransom

@_date: 2010-11-24 19:49:40
@_author: Robert Ransom 
@_subject: Active Attacks - Already in Progress? 
There have been previous posts to or-talk about a German organization
called perfect-privacy.com .
Robert Ransom

@_date: 2010-11-24 21:51:23
@_author: Robert Ransom 
@_subject: Active Attacks - Already in Progress? 
Several people and organizations run multiple Tor relays with obviously
similar names.  They generally do not try to hide their identities or
the connections between their relays.  See
 for an easily browsable list; click on
the name of a relay to see more detailed information about it,
including the ContactInfo value, if any, specified by the relay's
Entities which operate multiple Tor relays can, usually should, and
often do use the MyFamily torrc option to indicate that their relays
are run by a common operator.  If two relays list each other in their
MyFamily directives, your Tor client will not include them in the same
circuit. Unless you have turned off the EnforceDistinctSubnets torrc
option, your Tor client will also not include two relays in the same /16
network in a single circuit.
Tor weights its node selection according to node bandwidth, as
specified in the consensus.  The consensus, in turn, provides bandwidth
values measured by the ?bandwidth authorities?.  This weighting is
necessary to balance load fairly throughout the Tor network.
There should be multiple bandwidth authorities running, operated by
people whom the Tor Project and the directory authority operators
trust; as I understand it, there is currently only one running
bandwidth authority, but the Tor Project is working on getting others
back online.
The relay families which you have complained about are most likely not
controlled by a single organization, and the organizations that control
them are most likely not trying or planning to attack Tor or its users.
A passive attacker can use some combination of the following
capabilities to try to link you to the Internet server you access using
a Tor circuit:
* The ability to monitor the TLS connection from your computer to your
  guard node for the circuit.
* The ability to monitor the Tor circuit at your middle node (by
  controlling the middle node and monitoring/logging its internal
  state).
* The ability to monitor the TCP connection from your exit node for the
  circuit to the server you are accessing.
There are other capabilities which an attacker could have, but I think
the three I have listed are sufficient for this discussion.
An attacker who monitors the TLS connection from you to your guard node
and the TCP connection from your exit node to the server can link the
endpoints of your connection using timing alone.  There is no point in
considering the more precise attacks that can be performed by
controlling your guard node and/or exit node themselves; if an attacker
monitors both you and the server you are connecting to, you lose.
An attacker who monitors the Tor circuit at your middle node and the
TCP connection from your exit node to the server can link the
connection at the server to your guard node for the circuit.  This will
not provide your IP address to the attacker.  However:
* An attacker who knows one of your guard nodes may be able to begin
  monitoring the guard node's incoming connections.
* An attacker who knows all three of your current guard nodes, can
  monitor the middle node on another Tor circuit, and sees that it
  originates from a guard node you are not currently using, can
  determine that you did not open that Tor circuit.  This is a
  surprisingly damaging attack, especially if your Tor client has
  chosen one or more low-bandwidth (and therefore relatively unpopular)
  guard nodes.
An attacker who monitors the TLS connection from you to your guard node
and the Tor circuit at your middle node may later gain access to logs
kept by the server you are accessing, match the IP address and times of
connections to the server with the times at which you opened TCP
connections through the Tor circuit, and thereby determine what
requests you sent to the server.
There are several torrc options that you can set if you are afraid of
certain relays -- ExcludeNodes, ExcludeExitNodes, StrictNodes,
StrictExitNodes, NodeFamily, and perhaps others.  ExcludeExitNodes may
be useful if you find that an exit node is misbehaving and is not yet
flagged as a BadExit.  I strongly recommend that you DO NOT set any of
these directives, with the possible exception of ExcludeExitNodes, if
you are *very* certain that a particular exit node is actively
All of the above options will change the probability distribution from
which your Tor client chooses circuits.  If you blacklist a few
low-bandwidth relays, you probably won't change the distribution
noticeably, but you won't improve your security noticeably, either.  If
you blacklist one or more of the major families of high-bandwidth Tor
relays and/or exits, you will change the distribution quite noticeably,
and you will make yourself quite distinguishable from normal Tor users.
The most obvious way in which choosing circuits from an unusual
probability distribution can hurt you is through the distribution from
which you choose exit nodes.  An adversary can capture and examine a
particularly sensitive server's logs, notice that someone is accessing
it only through relatively low-probability Tor exits, and then go look
for logs from less sensitive servers to which you might have given
information that readily identifies you.  If the adversary knows that
someone is posting information they want to suppress to a blog or forum
through low-probability Tor exits, and then finds that Fred Foobar
routinely accesses a shopping site through the same low-probability Tor
exits, Fred Foobar is in trouble.
There is another, somewhat less obvious way in which choosing circuits
from an unusual distribution can hurt you -- if you routinely download
large files from an adversary-monitored server through high-bandwidth
exit nodes, but low-probability, low-bandwidth middle nodes, the
adversary may be able to detect this fact from the server alone, and
use it to link your connections together.
I assume that choosing circuits from an unusual distribution can allow
other attacks as well.  In general, the Tor developers try to avoid
making different clients' circuit distributions distinguishable, and
would prefer that you not make your Tor client's circuit distribution
distinguishable yourself, even if there is no obvious way that your
particular change will allow an attack on your anonymity.
The Adversary would like to thank you for providing those names.  They
will be *very* useful.
Robert Ransom

@_date: 2010-11-28 13:21:30
@_author: Robert Ransom 
@_subject: glibc Errors for TBB 1.0.17 
Yes, and it looks like a bug to me.  Added to Trac as See  for the build
scripts, but we would prefer to fix this bug.
Robert Ransom

@_date: 2010-11-07 10:58:52
@_author: Robert Ransom 
@_subject: Firefox,FireFTP,FTP etc. downloads anonymity. 
Supporting SOCKS4A is a good sign -- that means it might not leak DNS
requests -- but I don't think the Tor developers have reviewed it to
check for other anonymity and security issues.
Torbutton displays that warning when you start to download a file that
Firefox will not display itself.  Saving the file to disk with Firefox
itself (with no extensions) probably won't break your anonymity.  I
don't know whether using FireFTP to download the file will break your
However, if you run or open the downloaded file (whether after or
instead of saving the file to disk) on a computer that will ever again
be connected to the Internet, your anonymity can quite easily be
compromised (through unique identifiers hidden inside an executable
file, for example).
What is 3proxy?
Robert Ransom

@_date: 2010-11-10 11:23:58
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
Yes.  Current Tor relays send the IP address of the other node in a
NETINFO cell at the beginning of each TLS connection.
No.  This would break both bridges and relays operated behind a NAT,
even with the ORPort forwarded to the internal IP address on which the
bridge or relay is listening.
Robert Ransom

@_date: 2010-11-13 21:43:27
@_author: Robert Ransom 
@_subject: Two or several tor-nodes on one external ip 
When multiple relays appear with the same IP address, the directory
authorities drop all but two of them.
Robert Ransom

@_date: 2010-10-02 14:19:00
@_author: Robert Ransom 
@_subject: beneficia versus maleficia 
People who are already willing to commit crimes can already get
anonymity -- they can use unsecured wireless access points, they can
break into poorly secured computers on the Internet and relay their
traffic through those, they can steal phones to make anonymous phone
calls, they can send letters through the U.S. Postal Service
anonymously, etc..  Tor is for people who do not want to break the law
in order to keep advertisers
and evil governments
, etc.) from
tracking what they read on the Internet.
Read .
Robert Ransom

@_date: 2010-10-16 07:49:12
@_author: Robert Ransom 
@_subject: Where does Tor get its relay lists from? 
In the current Tor network, the directory servers sign a ?consensus?
listing and describing the currently known Tor relays, and most relays
serve copies of the consensus to their clients.
Robert Ransom

@_date: 2010-10-23 17:59:47
@_author: Robert Ransom 
@_subject: TCP stack attack? 
Roughly every attack that can be performed in a Tor node's TCP stack
can also be performed by anyone that can stick his own hardware between
the Tor node and the Internet.  There are some attacks that can be
performed there, but an attacker who can modify a Tor node's kernel
would be able to do more damage by reconfiguring or modifying Tor
Robert Ransom

@_date: 2010-10-28 01:23:20
@_author: Robert Ransom 
@_subject: Question about torbrowser for mac 
On Wed, 27 Oct 2010 21:35:08 -0400
Please check that Torbutton is installed by trying to add Torbutton to
your Firefox toolbar.  (The instructions are in the last paragraph of
 .)
Robert Ransom

@_date: 2010-10-28 02:22:17
@_author: Robert Ransom 
@_subject: TorFaq on https for hidden services ( was: Hints and Tips for 
I would recommend that hidden services not use HTTPS.  The Tor hidden
service protocol does an adequate job of authenticating servers and
encrypting traffic to them.  In addition, it is unlikely that any CA
that Firefox is configured to trust would issue a certificate for
a .onion hostname.
I don't see any risk to the server.
Yes, that is a bad sentence.
I think it's time to nuke that FAQ entry.  (Probably long past time to
nuke it.)
Robert Ransom

@_date: 2010-10-28 20:55:20
@_author: Robert Ransom 
@_subject: Firefox ctrl-shift-del vs. Torbutton 
Torbutton clears TLS session resumption information out of the browser,
which is not listed in the ?Clear Recent History...? dialog, when the
user toggles between Tor and non-Tor browsing:
On Wed, 27 Oct 2010 16:41:57 -0700
The cache can be used to store pieces of HTML, CSS, and JavaScript
containing unique identifiers, which can then be transmitted back to a
server in various ways (even without JavaScript).
Robert Ransom

@_date: 2010-10-28 21:13:34
@_author: Robert Ransom 
@_subject: Crypto for hidden services [was: TorFaq on https] 
Tor verifies that the hidden service's descriptor is signed by a private
key whose public key's truncated hash matches the hidden service
hostname.  For an HTTPS connection, your browser merely verifies that
some CA which the browser's developers have been paid to make users
?trust?, whether directly or indirectly, has signed a certificate
claiming that the server's public key can be ?trusted? to serve a
particular hostname.  Tor's authentication of hidden services is better
than anything HTTPS can do.
A clueless HS admin can publish all requests which reach his server
onto the Internet.  A malicious HS admin can forward all requests to
NSA, CIA, FBI, Mossad, GCHQ, and whatever other entities are out to get
I'm slightly worried about this, but I currently don't see any tunnel
software in use that uses cryptographic algorithms that I consider
stronger than Tor's.
HTTPS to behind a HS costs the user rather a lot of effort, for
minimal, if any, benefit.  Thus, I would recommend that hidden services
not use HTTPS.
I don't expect most users to verify SSL certificate fingerprints out of
band, whether ?out-of-band? means on the non-Tor Internet, over the
telephone network, or through the mythical DNSSEC.
I thought of this, but the hidden service private key would be enough
of a giveaway.  Having a second private key around is no easier or
harder to hide than having the first private key around.
There is no real reason not to use another layer of cryptography on top
of Tor hidden services.  Using HTTPS, and convincing users to use
HTTPS, is far harder than merely using another layer of cryptography,
and provides no real benefit.
We have a PKI for hidden services already, designed into the protocol.
I do not expect piling HTTPS on top of that PKI to add any security at
this time.
Robert Ransom

@_date: 2010-10-29 04:16:52
@_author: Robert Ransom 
@_subject: Crypto for hidden services [was: TorFaq on https] 
Oh, you meant remote fingerprinting of the server's TLS stack.  I
didn't think of that, but I doubt that it's any worse than the HTTP
server's fingerprint.
I thought you were talking about fingerprinting a captured server,
because Tor is not supposed to leak (much) information about itself to
the other end of a circuit.
Robert Ransom

@_date: 2010-10-01 14:48:56
@_author: Robert Ransom 
@_subject: BetterPrivacy - necessary? 
On Fri, 01 Oct 2010 22:29:48 +0100
Torbutton disables plugins (e.g. Java and Flash), and restricts the capabilities of
JavaScript code.
I think Polipo was a better cache, and since an HTTP proxy can't filter
evil content out of HTTPS responses, Privoxy's filtering was not very
Robert Ransom

@_date: 2010-10-07 17:45:41
@_author: Robert Ransom 
@_subject: Hidden service: Is it possible for an attacker to break out of 
Using a VM doesn't prevent most side-channel attacks.  It only blocks
access to a description of your hardware.
It depends on the VM software you are using.
Robert Ransom

@_date: 2010-10-07 21:26:43
@_author: Robert Ransom 
@_subject: Me <-> Tor <-> VPN <-> Internet? 
On Thu, 7 Oct 2010 23:58:28 -0400
No -- put them on the Hidden Wiki.
Finding *that* is left as an exercise for the reader.
Robert Ransom

@_date: 2010-09-24 15:10:53
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
Use the macchanger utility.  Make sure you write down your original MAC
first, in case you need to switch back to it later.
Robert Ransom

@_date: 2010-09-24 15:43:19
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
Yes.  I knew that, and forgot to mention it (at least in that list).
These defenses, and the attacks they are intended to block, need to be
written up in a (hidden?) wiki article, so people setting up sensitive
hidden services can read all of them in one place.
No.  An attacker *will* find your entry guards (see
); you want them to
have as many clients as possible, so that you still have some chance of
getting lost in the crowd.
Probably.  The first time I read the Murdoch-Zieli?ski paper
, I didn't
notice that someone was actually planning to use the sFlow data to
locate spammers.  Robert Ransom

@_date: 2010-09-25 17:21:14
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
On Sat, 25 Sep 2010 17:04:14 -0700
If you are running a hidden service, on a computer with no network
access except through Tor, no -- you might not be hosed just by an
attacker being able to run a shell command, but leaking an actual MAC
address from an actual NIC might get you tracked down.  (An attacker
with shell access can read your MAC address on Linux just by running
ifconfig, even as an ordinary user.)
I don't know whether browser plugins can be used to read a MAC address,
but if *they* can run a shell command like ifconfig, yes, you are in
real trouble.
Robert Ransom

@_date: 2010-09-12 01:42:06
@_author: Robert Ransom 
@_subject: Problems with `dig` and `host` under transparently torified 
Tor's DNSPort does not provide support for the full DNS standard.
You can try ?dig +tcp  YOUR-QUERY-HERE? to retrieve the other
records.  (I think the  option belongs before the query, but it
may belong at the end of the command line; run ?dig --help? for
Are you really running Tor as root?  It seems to me that those
instructions should be changed to have Tor run with DNSPort 9053 in a
Tor-only user account, and have iptables redirect DNS requests to port
Robert Ransom

@_date: 2010-09-12 18:40:03
@_author: Robert Ransom 
@_subject: When is the 'MyFamily' setting unnecessary? 
On Sun, 12 Sep 2010 20:28:33 -0400
That's the wrong approach.  The config file should contain a random
secret key shared among all relays in a family, and the relays should
publish in their descriptors a public key derived from that secret key
along with a signature of the relay's current signing key with that
secret key.  With DJB's Curve25519 elliptic-curve parameters, the
public key can take only 511 bits, and the signature can take only 506
bits.  A smaller curve could fit the public key into 319 bits and the
signature into about 320 bits (the precise size would be determined by
the group order).
This would not be backward-compatible with existing clients, but it
avoids the current quadratic blowup in both the config files and the
total descriptor size.
Robert Ransom

@_date: 2010-09-12 21:11:42
@_author: Robert Ransom 
@_subject: When is the 'MyFamily' setting unnecessary? 
On Sun, 12 Sep 2010 23:36:30 -0400
No, the client needs to see it in the relay/bridge descriptor.
I don't see how it could open up any *new* attacks -- the directory
authorities can already ignore relays, or mark them as Invalid, with
near impunity.
Don't forget that the keys and signatures would need to be represented
in ASCII in the descriptors.  If you're willing to break backward
compatibility anyway, there is some room for squeezing the existing
family specifications down, as well (i.e. represent node identity key
fingerprints in base64, or even base85 (only the clients should care
about it, and they can probably eat the performance cost)).
Also, don't forget that we can use an elliptic curve modulo a 159-bit
prime for this -- node family keys are relatively low-value
authentication keys, and since they would only be used to sign nodes'
ephemeral *signing* keys, they can be changed with rather little trouble.
Robert Ransom

@_date: 2010-09-12 22:19:07
@_author: Robert Ransom 
@_subject: When is the 'MyFamily' setting unnecessary? 
On Mon, 13 Sep 2010 00:26:02 -0400
s/bridges/authorities/, I assume.
It's better to not rely on any trusted third party any more than we
absolutely have to.  For this, we don't need a TTP at all, so we
shouldn't rely on one.
The signature system I had in mind was essentially the system in ?4 of
 (the system
proved at least as hard as DDH), with an added space optimization
(mainly, compute h as a hash of y1, and publish only y1 and y2).  On a
curve modulo a 159-bit prime, a signature and its public key fit in a
total of about 640 bits.  The only system I know of with a shorter
signature is the Boneh-Lynn-Shacham pairing-based scheme, with 160-bit
signatures and a 512-bit public key, and in this application that's not
a space improvement (total size: 672 bits per descriptor).
I think Dr. Bernstein is currently attacking a curve of about 130-bit
order.  Even using that curve for this purpose would discourage
mischief: it's still quite hard to find the secret key, and even if you
do find it, it's not very useful, or for very long.  As I said, family
secret keys would be low-value authentication keys, and it is easy to
make a compromised family key useless (just stop using it).
Unless the operator does something *really* dumb like use an easily
guessed character string as his secret (and we can make that difficult
by requiring that it be specified as exactly N base64 characters,
possibly with a checksum prepended by whatever tool we provide to
generate family keys), it's much faster to use an attack based on the
group structure.  There are elliptic-curve groups for which the only
known algorithms to solve the discrete-logarithm problem are
group-generic (i.e., they work on any cyclic group), and the
group-generic methods take time proportional to the square root of the
group order.  Brute-force guessing takes time proportional to the group
order itself.
Robert Ransom

@_date: 2010-09-13 12:45:24
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
He *would* be able to access the Ethernet card in the
Internet-connected gateway box, and I have seen reports of at least one
Ethernet card with an unauthenticated remote-update backdoor which
could be used to take over the entire computer through DMA.  At the
very least, virtual network adapters are unlikely to have intentional
backdoors hidden in them.
* First, operate the hidden service using software with no security
  holes, and on a (physical) computer that does not operate any
  Internet-visible services (especially not a Tor relay).  Putting your
  hidden service in a virtual machine won't protect you from the
  side-channel attack described in ?Hot or Not?.
* Second, if you must use software with security holes to operate your
  hidden service, keep that software in a virtual machine, and do not
  let it communicate with a real network adapter.  (The ?host-only
  network? option in VirtualBox should be safe enough, for example.)  I
  don't see a big reason to run Tor in a VM, unless you need to set up
  transparent proxying and don't want to mess up your main OS
  installation.
Robert Ransom

@_date: 2010-09-16 17:47:32
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
Yes.  I read a report years ago that at least one model of Ethernet
card had a remote ?firmware upgrade? ?feature? built in, with
absolutely no authentication of the new firmware blob.  The card
firmware had access to the host's DMA hardware, which can be used to
root the host.
Only if you trust the hardware firewall/router.  I wouldn't.
It did.
Robert Ransom

@_date: 2010-09-17 19:41:34
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
If your hidden service really needs to be annoying to find, run it:
* using only well-written, secure software,
* in a VM with no access to physical network hardware,
* on a (physical) computer with no non-hidden services of any kind
  running on it (so that an attacker can't use Dr. Murdoch's ?Hot or
  Not? clock-skew detection attack),
* and over a fast enough Internet connection that the adversary cannot
  easily determine your connection's speed.
The VM is optional *if* and *only if* an attacker cannot possibly get
root on your hidden service.  The physical computer with no non-hidden
services on it, and the fast Internet connection, are optional if you
do not need to keep your service hidden at all.
Using secure software to run your hidden service is absolutely
essential; if an attacker can get a list of files
in /bin, /usr/bin, /usr/local/bin, /sbin, /usr/sbin, /usr/local/sbin,
and /command, and a list of directories in /usr/local and /opt, he
probably knows enough to identify the service's owner, and more
importantly, he knows enough to recognize another service owned by the
same person.  Your preferred Unix distribution, your favorite editors,
your favorite command-line utilities, etc. are not especially easy to
hide.  (For example, if you find a hidden service running Plan 9 or
Inferno, or with 9base or plan9port installed on it, you're going to
look at me first -- I'm on both the Tor mailing lists and
Plan-9-related mailing lists, and I don't think anyone else is at the
The above precautions are probably enough, unless a three-letter agency
(or four-letter association) knows about your hidden service and wants
to find and ?neutralize? its operator.  In that case, you have to worry
about the near-global passive adversary and other threats that Tor
can't afford to defeat.
Another, safer, option is to keep your hidden service below the radar
entirely -- it's a lot harder for your adversaries to find something if
they don't know it exists.  I assume that's the approach that the US
Navy uses.
Robert Ransom

@_date: 2010-09-20 02:00:13
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
If your web server and all of the interpreters and programs it runs are
competently written, there is no way for an attacker to get root
access, or even run a shell command.  Web applications and the
special-purpose interpreters they run on are often incompetently
I select the message I want to reply to, and then I click the ?Reply?
button in my mail client's toolbar.
Robert Ransom

@_date: 2010-09-20 08:10:46
@_author: Robert Ransom 
@_subject: The best way to run a hidden service: one or two computers? 
============================== START ==============================
On Mon, 20 Sep 2010 09:58:14 -0400
Maybe.  Most Linux distributions do not put much effort into protecting
a system against a malicious user with shell access.  Even if you have
no local privilege-escalation holes, there are usually scary
side-channel attacks (e.g. cache-related leakage of AES keys), and you
may have already given the compromised UID permission to send arbitrary
network packets (if it can run VirtualBox, for example, the attacker
can set up a VM with a bridged network device, log in as root in the
VM, and send evil packets at will).
Also, if you haven't bothered to change your MAC address, an attacker
with any UID can read it using ifconfig; your hardware manufacturers
may have kept records of where the device(s) with that MAC address were
If you have a Linux system with persistent storage, try Claws Mail.  If
you have a Windows system, gpg4win includes Claws Mail for Windows.
(Unfortunately, it leaks its version number, your GTK version number,
and its build target (including processor architecture) in an X-Mailer
Robert Ransom

@_date: 2011-04-01 20:27:06
@_author: Robert Ransom 
@_subject: [tor-talk] GSOC Ideas. 
On Fri, 1 Apr 2011 17:12:20 -0700
No shit.  Your substantive contribution to TorExport consists of less
than 10 new lines near the end -- diff attached.  (I normalized the
leading whitespace in both files with ?expand -t 4? first.)
Robert Ransom

@_date: 2011-04-02 13:07:34
@_author: Robert Ransom 
@_subject: [tor-talk] Google disable web-access to gmail for Tor-users? 
Use the released version of Torbutton 1.3.2-alpha from
Robert Ransom

@_date: 2011-04-20 15:40:37
@_author: Robert Ransom 
@_subject: [tor-talk] Torbutton problem 
On Wed, 20 Apr 2011 17:41:12 -0400
Yes, he is.  Both versions of Firefox default to using the same profile.
Robert Ransom

@_date: 2011-04-28 07:45:44
@_author: Robert Ransom 
@_subject: [tor-talk] no country flags in Vidalia 2.10 
On Thu, 28 Apr 2011 02:00:32 -0300
Was the .tar.bz2 file a Tor Browser Bundle?
You can also check for a contact address in the relay descriptor.
TorStatus web sites show a relay's contact address in the relay
information page that appears when you click on a relay's name, and
they can show relays' contact information in a column on a relay list
as well.
Robert Ransom

@_date: 2011-08-09 09:55:05
@_author: Robert Ransom 
@_subject: [tor-talk] Reason Firefox version in TBB is so far behind? 
That is why we ship the latest version of Firefox on the 3.6 branch in
our stable TBBs.  Mozilla is still releasing security updates on the
Firefox 3.6 branch.
As you can see from
 , Firefox
3.6.19 and Firefox 5.0.1 were released on the same day.  That is
because Firefox 3.6.19 and Firefox 5.0.1 are security-fix releases
that fix the same security bug.  (Firefox 4.0, 4.0.1, and 5.0 are no
longer safe to use, even though their version numbers are greater than
There are some bugfixes in Firefox 5.0.1 that aren't in Firefox 3.6.19

@_date: 2011-08-09 10:01:35
@_author: Robert Ransom 
@_subject: [tor-talk] Problem with Linux Version 
Do not extract or run Tor Browser Bundle as root.
Robert Ransom

@_date: 2011-12-15 00:32:24
@_author: Robert Ransom 
@_subject: [tor-talk] variable speed limits on ports ... 
I expect that no one would ever notice that per-port rate-limiting
The ?bandwidth authority? currently measures exits' available
bandwidth by exiting to a test HTTPS server on port 443.  See
for more information.
Robert Ransom

@_date: 2011-12-21 23:42:09
@_author: Robert Ransom 
@_subject: [tor-talk] On verifying security of Tor Routers idea 
DO NOT mass-mail relay operators about this.  There may be valid
reasons to send mail to some or many relay operators, but this idiotic
port-scan idea is not one of them.
Robert Ransom

@_date: 2011-12-21 23:45:54
@_author: Robert Ransom 
@_subject: [tor-talk] Automatic vulnerability scanning of Tor Network? 
All of these ideas about removing allegedly ?insecure? or ?vulnerable?
relays from the network ignore the fact that someone who wants to
compromise Tor relays and use them to attack Tor users will just make
the relays appear to not be vulnerable, so that they can stay in the
network.  I'm amazed at how many people want us to remove relays which
have definitely not been compromised from the Tor network.
Robert Ransom

@_date: 2011-12-27 12:48:48
@_author: Robert Ransom 
@_subject: [tor-talk] No tor bridges 
Yes, it's fixed now.  Thanks for the report!
Robert Ransom

@_date: 2011-12-30 06:46:01
@_author: Robert Ransom 
@_subject: [tor-talk] What is going on with /var/run/tor? 
See /usr/share/doc/tor/README.Debian .  /var/run/tor needs to be owned
by the debian-tor user and group.
Robert Ransom

@_date: 2011-12-30 07:59:31
@_author: Robert Ransom 
@_subject: [tor-talk] Differences between real exit traffic and 
Someone watching all traffic to and from the exit node would be able
to distinguish that connection from Tor traffic because traffic on the
SSH connection would not be relayed over any OR connection (in either
direction).  Someone watching only that SSH connection (e.g. a sniffer
at host.com) would be able to distinguish that SSH connection from an
exiting Tor stream because your SSH client would respond to messages
from the server immediately after they reach the exit node, whereas an
SSH client connecting over Tor would not be able to respond until data
from the server reached the other end of a Tor circuit.
Robert Ransom

@_date: 2011-02-28 12:30:45
@_author: Robert Ransom 
@_subject: [tor-talk] Thoughts on proxy setup wrt insecure connections 
Connections to the plaintext POP3 and IMAP ports may be secured using
the STARTTLS command.
This enables attacks against users' anonymity -- for example, a web
page at  could include
 as an inline image to
distinguish users who have configured their Tor client to allow
connections to port 110 from those who have not.
Robert Ransom

@_date: 2011-02-11 11:35:35
@_author: Robert Ransom 
@_subject: Is "gatereloaded" a Bad Exit? 
On Fri, 11 Feb 2011 01:47:45 -0500
There are currently only about 700 published bridges.  See
According to ,
1/11 of bridges are assigned to the 'reserved' pool, and as I
understand it, those reserved bridges are distributed periodically to
groups who will make use of them.
Other than that, well said.
Robert Ransom

@_date: 2011-02-13 11:04:09
@_author: Robert Ransom 
@_subject: Yet another UDP / DNS quiestion... 
On Sun, 13 Feb 2011 18:50:19 +0000
That's a process ID, not a user ID.
Robert Ransom

@_date: 2011-02-14 20:42:14
@_author: Robert Ransom 
@_subject: Scroogle and Tor 
Polipo monkey-wrenches Torbutton's protection against long-term cache
Robert Ransom

@_date: 2011-02-03 19:23:10
@_author: Robert Ransom 
@_subject: IP address blocked on certain site 
On Thu, 03 Feb 2011 22:21:34 -0500
Turning off 'Use Polipo' in the Torbutton Preferences dialog would be
easier and much safer.
Robert Ransom

@_date: 2011-02-04 16:55:37
@_author: Robert Ransom 
@_subject: IP address blocked on certain site 
On Fri, 04 Feb 2011 14:52:25 +0000
Only if the configuration option network.proxy.socks_remote_dns (only
accessible in about:config) is set to true.
Torbutton will ensure that this option is set properly.
Robert Ransom

@_date: 2011-01-12 08:12:08
@_author: Robert Ransom 
@_subject: Gmail saying "cookies are turned off" but they are not 
On Wed, 12 Jan 2011 10:49:25 -0500
                                         ^RIGHT HERE^

@_date: 2011-01-16 19:34:32
@_author: Robert Ransom 
@_subject: How to use Google Gadgets with Tor? - Is this possible? 
If you are talking about the program called 'Google Gadgets', no, it
has not been audited, and it is unlikely to be safe to use over Tor.
This thread is about using Google gadgets embedded in a web page with
Firefox (and Torbutton).
Robert Ransom

@_date: 2011-01-30 01:31:18
@_author: Robert Ransom 
@_subject: Tor 0.2.2.22-alpha is out 
Tor 0.2.2.22-alpha contains 'a slight tweak ... that makes *relays and
bridges* that run this new version reachable from Iran again' (emphasis
added).  Running it as your client will not help you.
You need to find a bridge that is running 0.2.2.22-alpha, or find a
relay that is running 0.2.2.22-alpha and configure it as a bridge.
You should not have published your IP address.  It is quite easy for
your government to use your IP address to identify you and punish you,
and no one on this list can use your IP address to help you.
Robert Ransom

@_date: 2011-01-30 01:55:57
@_author: Robert Ransom 
@_subject: Is "gatereloaded" a Bad Exit? 
On Sun, 30 Jan 2011 10:33:31 +0100
They will be now.
The exit scanner detects such nodes, and Mike Perry has just made it
easier to mark nodes with suspicious policies with the BadExit flag in
the future:
Robert Ransom

@_date: 2011-01-30 15:05:59
@_author: Robert Ransom 
@_subject: Question and Confirmation. 
On Sun, 30 Jan 2011 22:33:21 +0000
Each relay removes one layer of encryption.
Tor does *not* encrypt and send packet headers.  Tor only relays the
data within a TCP connection.
Robert Ransom

@_date: 2011-01-30 16:20:06
@_author: Robert Ransom 
@_subject: Polipo bug reporting 
If that bundle contains a CHANGES file for Polipo, the last entry in it
is for the included version of Polipo.  We do not know of any new bug tracker for Polipo.  If you have a bug
report for Polipo itself, report it to the polipo-users mailing list
(see ).
Robert Ransom

@_date: 2011-01-06 01:11:56
@_author: Robert Ransom 
@_subject: Tor-BlackBelt Privacy 
On Thu, 06 Jan 2011 09:04:23 +0100
These two lines might make Tor slightly faster, but will put far more
load on the Tor network.  The NumEntryGuards line will also make the
client more vulnerable to certain anonymity-set-reducing attacks.
Either 'Cav' is seriously afraid of some node named "IL", or he is
trying to protect his users from those $DEROGATORY_ADJECTIVE Jews and
didn't put in the curly braces needed to exclude all nodes in a
country.  (And didn't realize that Mossad can rent servers in other
Robert Ransom

@_date: 2011-06-04 03:52:49
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
Hash: SHA1
On Sat, 04 Jun 2011 12:37:14 +0200
My understanding was that EFF would query DNS for a hostname, and if
the hostname does not exist, assume that it's private.  (This should
scare you even more.)
Robert Ransom

@_date: 2011-06-04 12:18:53
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
On Sat, 4 Jun 2011 12:09:52 -0700
If EFF needs to perform a DNS query on each hostname it receives a
certificate for, EFF will leak information to an attacker watching its
servers.  If EFF tries to not log hostnames which do not exist, EFF
will leak a user's request time *every time* that it receives a
certificate associated with a non-existent hostname.
Robert Ransom

@_date: 2011-06-04 14:25:19
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
On Sat, 4 Jun 2011 12:56:15 -0700
Firefox cannot resolve hostnames to IP addresses when it is using *any*
proxy.  Anyone who uses an SSH tunnel as a SOCKS to connect to an
intranet will risk this leakage, and SSH tunnels can be made fairly
easy to use.  I have no information on how widely used that
configuration is.
That would be a Good Thing, just to decrease the incentive for
attackers to monitor EFF's Internet connection.
Either way, the attacker wins -- if you resolve hostnames over Tor, the
attacker can use a homoglyph or near-homoglyph of a target hostname for
its attack, and simply not allow DNS servers accessible outside its
victim network to see the attack hostname.
Robert Ransom

@_date: 2011-06-06 13:40:17
@_author: Robert Ransom 
@_subject: [tor-talk] 4 hops in tor? 
This can happen when Tor ?cannibalizes? a normal three-hop circuit
(most often, it has circuits pre-built to exit nodes that allow exiting
to ports you have used recently, and you try to connect to an IP
address and port that none of the pre-built circuits' exit nodes allow
access to), or when Tor connects to an ?exit enclave? (a Tor relay
running on a server you are trying to connect to).  Tor also often
builds four-hop circuits while connecting to hidden services.
Robert Ransom

@_date: 2011-06-09 01:02:00
@_author: Robert Ransom 
@_subject: [tor-talk] unbound, ttdnsd and DNSPort config 
This looks like a bug.  Please open a Trac ticket for it.
Robert Ransom

@_date: 2011-06-21 04:31:22
@_author: Robert Ransom 
@_subject: [tor-talk] rend-spec.txt HS stuff 
This is correct.
That is not the permanent identifier used in the example in that
paragraph.  But I see no reason to specify a whole permanent identifier
for that example.
The calculations in that paragraph are correct.  ?/? is used to
indicate integer division.
tor26 is configured as a v0 hidden-service authority.
No.  That blank line was intentional.
Robert Ransom

@_date: 2011-06-21 05:38:04
@_author: Robert Ransom 
@_subject: [tor-talk] Access blocked by Baracuda Content filter 
Use Tor.
If it blocks Tor, use Tor bridges.
If it blocks Tor bridges, we would like to probe that filter.
Robert Ransom

@_date: 2011-06-21 12:19:23
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
This could occur with a SOCKS proxy, too (such as that run by ?ssh
-D?), since there is no standard way to ask a SOCKS proxy to resolve a
hostname to an IP address.  (Tor allows this using a non-standard
extension to SOCKS.)
Maybe.  I doubt that users with configuration 2 will opt in to SSL
certificate submission without reading all of the documentation they
can find, and configuration 1 seems more likely to occur during an
attack than in a deployed intranet.
There is no better option than a user-specified domain blacklist.  Any
attempt to automatically detect these private certificates and avoid
submitting them will defeat the most important purpose of the
distributed SSL observatory project: detecting SSL MITM attacks.
Robert Ransom

@_date: 2011-03-04 10:17:30
@_author: Robert Ransom 
@_subject: [tor-talk] Stricter NEWNYM? 
This can happen even on a new circuit.  Tor does not try to select a
different exit node after a NEWNYM has been issued, as that would make
users' streams before a NEWNYM more linkable to their streams after the
Torbutton would also need a 'new identity' button.  See
 for some
discussion of what that would involve.
If you want to close all web-browsing streams while switching to a 'new
identity', the best currently possible options are to toggle Torbutton
off, then back on, or to quit Firefox entirely and restart it.  (This
also requires that you restart Polipo or not be using it.)  Perhaps
that should be documented better.
Alternatively, a user could use Vidalia's 'Network Map' to close all
open web-browsing streams.
This approach would make it impractical for a user to use IRC or SSH on
a LiveCD while browsing without linking the IRC/SSH session to
his/her/its browsing activities.  Please separate the 'kill all
streams' command from the NEWNYM command.
A 'kill all streams' command would be more useful if it came with an
implementation of proposal 171 and ended all streams sent by one
application (as determined by the application-separation criteria in
that proposal).  Unfortunately, that won't become possible until
proposal 171 is implemented.
Robert Ransom

@_date: 2011-03-06 10:09:49
@_author: Robert Ransom 
@_subject: [tor-talk] can't get tor to work :( 
All of the directory authorities crashed between 2011-03-06T10:00 and
2011-03-06T11:00 UTC.  Newly started Tor clients will not work until
the directory authorities are running again.
The message Vidalia displays is "Authenticating to Tor", and it means
that Vidalia has not yet connected to the control port of your Tor
client.  Tor clients never authenticate themselves to the Tor network.
Robert Ransom

@_date: 2011-03-08 17:09:29
@_author: Robert Ransom 
@_subject: [tor-talk] Stricter NEWNYM? 
This will harm user anonymity.  Circuit path selection must be
independent of the circuits and exit nodes which a client has
previously used.
See proposal 171 (and its surrounding discussion).  Separating streams
by destination port will not help separate users' web-browsing
activities from their Internet mail connections.
Robert Ransom

@_date: 2011-03-09 14:20:32
@_author: Robert Ransom 
@_subject: [tor-talk] Making TOR exit-node IP address configurable 
Try running "man tor |grep -C5 OutboundBindAddress".
But I'm not surprised that someone who wants to perform content
censorship on a Tor exit node is too clueless to find that Tor
configuration option, or to find out that iptables can apply different
rules to the user ID under which Tor is running.
Robert Ransom

@_date: 2011-03-09 17:04:14
@_author: Robert Ransom 
@_subject: [tor-talk] Making TOR exit-node IP address configurable 
On Wed, 09 Mar 2011 23:29:16 +0100
Ah!  Now I get it.  You want to censor non-HTTP connections on port 80,
and probably Google searches for "Robert'); DROP TABLE Students;--" (a
quote from one popular web comic) as well.
I've opened a relevant enhancement ticket.  See
Robert Ransom

@_date: 2011-03-10 13:18:16
@_author: Robert Ransom 
@_subject: [tor-talk] Cannot upgrade tor-devel 
The new version will still work with libevent-1.4.14b_2 installed, but
the FreeBSD tor-devel port has been changed to link Tor against
libevent-2.0.10 now that it has been released, and if you build Tor
with both versions of libevent installed, Tor will be compiled with the
include files from libevent 2 and linked to libevent 1, which won't
To install the tor-devel port,
* uninstall libevent-1.4.14b_2 temporarily (the portupgrade tools
  should include something that will create a 'backup' package of a
  port while uninstalling it),
* install the tor-devel port,
* then reinstall libevent-1.4.14b_2 (preferably from your package).
Robert Ransom

@_date: 2011-03-10 19:37:20
@_author: Robert Ransom 
@_subject: [tor-talk] Cannot upgrade tor-devel 
On Fri, 11 Mar 2011 03:27:27 +0000
No.  Just reinstall the libevent-1.4.14b_2 package you created when you
uninstalled libevent-1.4.14b_2 .  Both versions of libevent can be
installed at the same time (and they must both be installed if you want
to use both Tor 0.2.2.x and tmux, for example).
Robert Ransom

@_date: 2011-03-21 09:56:44
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
This ?phone-home? behaviour is not safe for users who browse the web
over Tor until proposal 171 is implemented in Tor.  At best, it would
*only* fragment the anonymity set of Tor users.
Robert Ransom

@_date: 2011-03-21 10:00:53
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
On Mon, 21 Mar 2011 09:05:30 -0400
1. The extension cannot determine whether you have a ?rare? certificate
   without querying the database.
2. If users do not report self-signed certificates that they expect to
   see, the database cannot be used to detect man-in-the-middle attacks
   on sites that use self-signed certificates.
Robert Ransom

@_date: 2011-03-22 18:26:40
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
On Mon, 21 Mar 2011 17:09:38 -0700
Could you include a native-code SOCKS client library in the extension?
This won't work if an exit node lies about the IP address of
?observatory.eff.org? (and it won't work reliably in any case).  Using
an EFF-run hidden service would fix that problem if we can make hidden
services work reliably again.
Robert Ransom

@_date: 2011-03-23 02:40:31
@_author: Robert Ransom 
@_subject: [tor-talk] How evil is TLS cert collection? 
On Tue, 22 Mar 2011 21:19:46 -0700
Will you be able to get a certificate valid for that IP address (rather
than hostname)?
Robert Ransom

@_date: 2011-05-08 15:24:11
@_author: Robert Ransom 
@_subject: [tor-talk] Tor 0.2.3.1-alpha w/o traffic 
0.2.3.1-alpha will remove items from its extra-info descriptor or drop
its e-i descriptor entirely (and still publish a relay descriptor) if
the e-i descriptor would otherwise exceed the 50-kiB limit.  That's not
the problem this time.  (But we don't know what the problem is yet.)
Robert Ransom

@_date: 2011-05-11 01:22:14
@_author: Robert Ransom 
@_subject: [tor-talk] Source code modifying for testing 
If you can control both the entry and exit nodes, you don't even need
to perform an active attack -- a purely passive timing attack will
identify the client.  That's why each Tor client selects a few relays
to use as ?entry guards? -- see
 and
Robert Ransom

@_date: 2011-05-11 07:11:20
@_author: Robert Ransom 
@_subject: [tor-talk] Cannot upgrade tor-devel under FreeBSD 
You seem to have turned on the TCMALLOC configuration option in the
FreeBSD tor-devel port, and for some reason the ports system didn't
install the ?google-perftools? package which that option requires.
Turn off the TCMALLOC option and try again.  (The easiest way to change
the port's options is to move your
current /var/db/ports/tor-devel/options file to some other directory
and try installing the port again.)
Robert Ransom

@_date: 2011-05-17 16:18:11
@_author: Robert Ransom 
@_subject: [tor-talk] 504 Proxy loop detected by Polipo 
This looks to me like a problem caused by Polipo's configuration in the
Tor bundle you are using -- specifically, I suspect that Polipo dropped
the Referer header on at least one request, and possibly all of the
requests in this loop.
The proper place to report this bug would be as a Trac ticket on
 in the ?Tor bundles/installation?
component, but we plan to remove Polipo from as many of our bundles as
possible as soon as possible, so we might just ignore a Trac ticket for
this issue.
Robert Ransom

@_date: 2011-05-19 06:17:12
@_author: Robert Ransom 
@_subject: [tor-talk] Tor 0.2.2.26-beta and 0.2.2.27-beta are out 
This change has already been merged to the 0.2.3.x tree (the ?master?
branch in our Git repo).
I have no information on whether this change will reduce CPU load on
large relays and exits, but I would not expect it to reduce CPU load.
Robert Ransom

@_date: 2011-05-31 01:11:00
@_author: Robert Ransom 
@_subject: [tor-talk] password... 
On Tue, 31 May 2011 09:46:07 +0330
See tor-spec.txt in .
Robert Ransom

@_date: 2011-11-03 19:21:31
@_author: Robert Ransom 
@_subject: [tor-talk] Tor client pushing large amounts of data? 
This looks like a mostly-harmless integer overflow bug.
Robert Ransom

@_date: 2011-11-09 14:54:42
@_author: Robert Ransom 
@_subject: [tor-talk] New Browser Bundle 
No.  The ?New Identity? command in Torbutton's popup menu clears state
in the browser; Vidalia's ?New Identity? command does not.
Robert Ransom

@_date: 2011-10-04 21:38:06
@_author: Robert Ransom 
@_subject: [tor-talk] observation: Browser bundle & secure files deletion 
If you have evidence that TBB-Firefox stores sensitive information to
disk without a user asking it to, please file a bug report.  One of
the main design goals of Torbutton was to prevent Firefox from ever
writing sensitive information to disk (unless a user has specifically
asked it to, e.g. by changing Torbutton's configuration or adding a
bookmark to Firefox).  See section 1.2 of
 .
I can't tell because you didn't tell us what files you think
TBB-Firefox writes which contain sensitive information.
Neither Tor nor TBB attempts to securely erase files, because most
filesystems in use on most operating systems (and many modern storage
devices) make securely erasing files infeasible.
TBB should never write sensitive information to disk.  TBB must assume
that it is safe to create and delete temporary files which do not
contain sensitive information within the TBB directory.
Programs that wipe free space are rarely able to wipe enough
information to be worthwhile.  Flash drives cannot be erased reliably
at all.
We have.  That's why we try hard to not write sensitive information to disk.
We assume that erasing data written to disk is impossible, because it
is infeasible on most filesystems and operating systems and many
storage devices.
We assume that erasing data written to disk is impossible, because it
is infeasible on most filesystems and operating systems and many
storage devices.
Robert Ransom

@_date: 2011-10-10 07:44:19
@_author: Robert Ransom 
@_subject: [tor-talk] Tor Browser Bundle: PGP encryption built-in? 
No.  See  , but
beware -- I'm sure katmagic and I missed a few dozen attacks.
This sounds reasonable, except for the parts about the XUL interface
and the browser-based UI.  It also sounds rather like GPG4Win, except
for those parts.
Robert Ransom

@_date: 2011-10-10 21:54:09
@_author: Robert Ransom 
@_subject: [tor-talk] Fwd: Tor Browser Bundle: PGP encryption built-in? 
You seem to have missed the point of that page -- the problem with
FireGPG is what it allows, not how it was implemented.
A warning before JavaScript enumerates your keyring isn't sufficient.
Users must, at a minimum, be able to block all further attempts by a
page or website to use GPG features.
And even that won't help most users -- a request-for-permission dialog
can only protect users who read messages before clicking 'Allow', and
who understand that allowing a website to use a GPG plugin is
No we wouldn't.
I don't consider Firefox the 'best of Web Browsing' or GPG the 'best
of encryption'.  They are only the crap tools we're stuck with for
Robert Ransom

@_date: 2011-10-14 17:54:03
@_author: Robert Ransom 
@_subject: [tor-talk] Tor compromised? 
You can only create many circuits through a bridge if you already know
its TCP address.
We plan to make bridges direct their clients' circuits through their
entry guards.  See
for the few notes we have online from when we discussed bridge
concealment at the Tor developer meeting this summer.
Robert Ransom

@_date: 2011-10-14 18:11:54
@_author: Robert Ransom 
@_subject: [tor-talk] Tor compromised? 
We already use a fixed (all-zero) counter-mode nonce, since we never
use the same AES key for more than one counter-mode stream.
A change to an Tor relay's RNG or relay encryption can only affect the
connections (both circuits and TLS connections) between that relay and
the clients connecting to it.  If the later relays on a circuit are
behaving correctly, there is nothing an entry node can do to modify
the data sent on a circuit without causing that circuit to fail
completely (with high probability); if the exit node on a circuit *is*
compromised, the entry node doesn't need to muck with the circuit data

@_date: 2011-10-14 19:21:04
@_author: Robert Ransom 
@_subject: [tor-talk] still problems - update available 
Have you restarted TBB since you were told that message was fixed?  I
just restarted one of my TBBs, and it performed the update check again
and didn't show the ?your TBB is out of date? message.
(Yes, the update check is only done on startup.  Yes, this makes it
rather useless to many (most?) TBB users, who keep their TBBs running
for a long time.  No, we can't just repeat the update check
periodically; it's bad enough that the update check makes a TBB's
first circuit recognizable at the exit node, and that every time a
user opens a new window, the exit node can tell that the user is
opening a new window and can tell whether TBB is asking check.tpo to
send the out-of-date warning message.  (I don't think we realized that
was a problem before we deployed this update notifier and shouted
?Wolf! Wolf!? at our users.))
Robert Ransom

@_date: 2011-10-14 20:35:35
@_author: Robert Ransom 
@_subject: [tor-talk] Tor Browser Bundle: PGP encryption built-in? 
Adding GPG to a web browser does not move us any steps closer to
having a mail user agent audited and packaged for use with Tor.
There are two attacks on that page.  When I thought of the
keyring-enumeration attack listed there, I hadn't heard of the
plaintext-leak attack yet, so I thought that only FireGPG's API was
dangerous, and then only to Tor users who might be trying to remain
anonymous or pseudonymous.  (I have since realized that I really don't
want an attacker to be able to read my keyring, even if They know who
I am already.)
Then katmagic told us about the plaintext-leak attacks on FireGPG, and
I thought ?Oh crap, that's *scary*.?.  And *then* I discarded the idea
of GPG-in-a-browser.
These are not attacks on easily-avoided flaws in FireGPG's
implementation.  These are attacks on FireGPG's *purpose* -- *any*
browser extension that did what FireGPG was *designed* to do would be
vulnerable to these attacks.
The Mikes and katmagic are trying to come up with new designs that
could, in theory, be implemented safely.  In practice, if you try to
let users enter text to be encrypted into something that looks like a
web form, an attacker *will* find a way to fool users into entering
their plaintext into something that JavaScript can read from (or
intercept key-press events for...), because a web form can be made to
look like your GPG plaintext-entry area.  So the only option is to
have users enter plaintext into something that is clearly a separate
window, and clearly not under the control of any web page -- and that
defeats most of the purpose of putting GPG in a browser.
The gain is slim compared to the difficulty of designing a secure GPG
browser extension and implementing it securely.  Auditing a real MUA
for use with Tor would be less difficult and *far* more useful.
Also, we don't have room left in TBB for a GPG distribution at the
moment.  Firefox and Qt are too bloated.
It's a bad idea if an attacker is very likely to succeed at grabbing
users' plaintexts.
FireGPG was dangerous because it worked as designed.  You (GlobaLeaks)
started by proposing to implement the same design (including the API)
Now you've backpedaled to trying to find *some* set of features that
will let you bolt GPG onto the side of a browser, for no reason that I
can see other than that you are determined to not give up on putting
GPG in a browser *somehow*, even if you can't integrate it usefully
into ?Webmail and other web applications? as you said you wanted to.
If your goal is GPG-in-a-browser for its own sake, go ahead and
implement it.  I doubt that it will ever be useful, but it's your
But if your goal is to let users send or receive encrypted and/or
signed e-mail anonymously or pseudonymously, GPG-in-a-browser is the
wrong means to reach your goal.
Robert Ransom

@_date: 2011-10-15 20:42:04
@_author: Robert Ransom 
@_subject: [tor-talk] since today check.torproject.org states "you are not 
No.  We tried setting up an 'exit enclave' on check.torproject.org,
which causes Tor clients to open their TCP streams to a server over a
circuit built to a Tor relay on that same server.  This should make it
harder for a malicious exit node to notice that you are opening a new
Firefox window in your Tor Browser Bundle, among other things.
Unfortunately, a bug in one of the services behind
check.torproject.org caused it to not realize that connections made
through the exit enclave were in fact coming from Tor.  That issue
should be fixed soon.
Malicious bullshit like this is not helpful.
Robert Ransom

@_date: 2011-10-21 12:53:59
@_author: Robert Ransom 
@_subject: [tor-talk] Suggestion: make _hidden services_ choose random 
Bullshit.  See  for the main
reason Tor uses entry guards.
Robert Ransom

@_date: 2011-09-06 15:12:52
@_author: Robert Ransom 
@_subject: [tor-talk] I've yet to understand <clock skew> attacks on 
They can only use that to locate your server if they can either
connect to it directly (not through Tor) or accept a non-Torified
connection from it, and determine what your server thinks is the
current time based on information it receives on that connection.
The obvious ways that your server could leak its current time include
running a web server and sending e-mail messages.  The less obvious
ways include opening an outbound TLS connection and running a cron job
with externally observable effects (e.g. an automatic update
Robert Ransom

@_date: 2012-04-04 10:44:10
@_author: Robert Ransom 
@_subject: [tor-talk] Absence of digital signature of TBB sources 
The Git tag is signed.
The official TBBs are built from the sources in Git, not from the
tarballs.  There probably shouldn't be any release tarballs for TBB
source code.
Robert Ransom

@_date: 2012-04-04 20:41:00
@_author: Robert Ransom 
@_subject: [tor-talk] Tor build failed - can't find libevent.. 
Oh, you're using FreeBSD.  Their goofy libevent2 port screws
everything up.  Build Tor using the security/tor-devel port.
If you insist on not using the port, you need to run:
  export CFLAGS=-I/usr/local/include/event2
  export LDFLAGS=-L/usr/local/lib/event2
before compiling Tor.  But if you couldn't figure that out on your
own, you really *really* should be using the FreeBSD port for Tor.
Robert Ransom

@_date: 2012-04-06 08:39:27
@_author: Robert Ransom 
@_subject: [tor-talk] TBB installation script doesn't work 
Please open a Trac ticket for this.
(Also, this is a problem with the TBB build scripts; TBB doesn't have
an installation script.)
Robert Ransom

@_date: 2012-04-18 08:37:43
@_author: Robert Ransom 
@_subject: [tor-talk] wget - secure? 
Which version of wget did you audit?  What information leaks did you
check for during your audit?
Which SSL library did you configure wget to use?  Which version of
that SSL library did you audit?
Based on your knowledge of the protocols that wget supports, where did
you most expect to find information leaks in wget's source?  (Since
you claim that ?wget is 100% safe to use with Tor?, clearly you didn't
find any information leaks.)
Which configuration of wget makes it use Tor ?100% safe?ly?
Robert Ransom

@_date: 2012-04-20 14:15:54
@_author: Robert Ransom 
@_subject: [tor-talk] wget - secure? 
No, the underlying point is that I have personally seen wget send my
computer's IP address over Tor in an FTP PORT command.  wget is not
?100% safe?.
The code to send a PORT command is still present in wget 1.13.4.  wget
1.13.4 is not ?100% safe?; anyone who wants to recommend it needs to
specify a particular configuration of wget which is safe.  (Don't
count on a ?default configuration?; Linux distributors might have
messed with it, or failed to update it to the version shipped in
recent wget source distributions.)
And that's not even the potential information leak that folks who are
familiar with ?anonymous FTP? would check for first.
Robert Ransom

@_date: 2012-04-29 21:33:31
@_author: Robert Ransom 
@_subject: [tor-talk] Problem with ttdnsd-665a534 on Ubuntu 12.04 server 
Looks like it's saying ?stdio.h: File not found".  (It would be easier
for English-speakers to help you if you ran ?export LC_ALL=C? in your
terminal before compiling a program, to tell compilers to use the
POSIX standard ?locale?.)
?sudo apt-get install build-essential? might help.
Robert Ransom

@_date: 2012-08-06 20:24:00
@_author: Robert Ransom 
@_subject: [tor-talk] ControlPortWriteToFile line added to torrc by 
It is a bug (filed as  because it
writes information about a filesystem location from which that copy of
TBB was run.
Robert Ransom

@_date: 2012-08-16 04:50:02
@_author: Robert Ransom 
@_subject: [tor-talk] tbb/vidaila network map problem 
This bug was already reported ( and a
fix will be in the next release of Vidalia.
Robert Ransom

@_date: 2012-08-24 19:26:17
@_author: Robert Ransom 
@_subject: [tor-talk] Tor already running 
As far as I know, ?bao song? has never contributed to Tor Browser
Bundle.  (A search of  did
not find any occurrences of ?Bao Song? in the repository history.)
Users are not expected to compile Tor Browser Bundle for themselves.
Robert Ransom

@_date: 2012-08-24 20:03:04
@_author: Robert Ransom 
@_subject: [tor-talk] Tor already running 
This is rather hard to do reliably and safely from a shell script, but
other people have asked for this feature too.  See
 .
No, this is because TBB-Firefox has to be started with the -no-remote
option so that it won't conflict with a non-TBB Firefox.
Robert Ransom

@_date: 2012-08-24 21:29:21
@_author: Robert Ransom 
@_subject: [tor-talk] Tor already running 
It took me several minutes of reading the list of tickets in that
?component? to find that ticket.
Several things:
* pgrep isn't POSIX, and it isn't in GNU coreutils (as of version
8.13), so it probably won't exist on someone's Linux system.
* pgrep only indicates that there is some process named ?tor? (or
?vidalia?) running, not that the specific Tor or Vidalia shipped in
TBB is running.
* There is currently no way for any program not started by TBB-Vidalia
to determine which ports TBB-Tor is listening on, and there is no way
for any such program to determine what control-port password Torbutton
will need in order to send TBB-Tor a ?SIGNAL NEWNYM? command (required
for the ?New Identity? command to work).  (See also
 .)
Robert Ransom

@_date: 2012-08-24 21:44:21
@_author: Robert Ransom 
@_subject: [tor-talk] simple example in ruby 
I see no SOCKS client code here.
Also, this guy refuses to search for a SOCKS client library
himself/herself/itself, so why would you expect him/her/it to be able
to learn how to use a library by reading its website or source code?
Robert Ransom

@_date: 2012-08-24 23:00:26
@_author: Robert Ransom 
@_subject: [tor-talk] Tor already running 
POSIX is not esoteric.  But there is a pgrep in the ?procps? package,
which contains the POSIX-required ps command, and FreeBSD ships with a
pgrep, so pgrep should be available everywhere TBB for Linux can be
run anyway.
No.  If the Tor Browser is packaged properly for a Linux distribution,
it will be configured to use a system-wide Tor instance, and it won't
use any of the startup crap that TBB includes.
I assumed that if pgrep were ubiquitous on Linux systems, it would be
in coreutils (bad assumption), so I looked there.  I only stated the
version of coreutils that I checked because I didn't want to go hunt
for the most recent version of coreutils.
No.  TBB is intended to not interact with a system-wide Tor instance in any way.
TBB-Vidalia does write all of that information into environment
variables, which is why only programs which it starts have easy access
to it.  The control-port password will never be written to a file
because any attacker who can authenticate to a Tor instance's control
port can completely destroy its user's anonymity.
Robert Ransom

@_date: 2012-08-26 23:29:09
@_author: Robert Ransom 
@_subject: [tor-talk] Up-to-date Repositories 
The Debian and RPM repositories on
 are maintained.
All RPM repositories on deb.tpo (outside the OBSOLETE/ directory)
contain the current -rc release 0.2.3.20-rc .
Robert Ransom

@_date: 2012-08-29 00:07:50
@_author: Robert Ransom 
@_subject: [tor-talk] [Tails-dev] Please review Tails stream isolation 
Nick or Roger would say no.  But they are planning to specifically
leave those options disabled for the web browser.  (That's what
?enabled by default (but for the web browser)? meant.)
Robert Ransom

@_date: 2012-08-31 17:59:41
@_author: Robert Ransom 
@_subject: [tor-talk] HiddenServices: calculating .onion address with 
What do you mean by ?Tor's GitHub account??
Robert Ransom

@_date: 2012-02-09 13:14:46
@_author: Robert Ransom 
@_subject: [tor-talk] irc clients and Tor 
I suspect that the breakage in irssi+torsocks is that irssi uses
non-blocking sockets, and the version of torsocks shipped in Debian
Squeeze doesn't handle non-blocking sockets correctly.  I've heard
that a later version of torsocks does work correctly on programs which
use non-blocking sockets.
Robert Ransom

@_date: 2012-02-10 17:18:41
@_author: Robert Ransom 
@_subject: [tor-talk] Ars Technica on Iran's latest strategy 
seems to have been effective.  We
just need to hunt down and fix some obfsproxy (server-side) crash bugs
and get a good list of very-high-bandwidth obfsproxy bridges before we
tell everyone where to find a Tor+obfsproxy client bundle.

@_date: 2012-02-11 15:49:27
@_author: Robert Ransom 
@_subject: [tor-talk] Trying to help 
No, it doesn't.  This means that you (or a program on your computer)
tried to use that Tor instance as a client to connect to a server
which wasn't running at the time.
Robert Ransom

@_date: 2012-02-14 22:06:30
@_author: Robert Ransom 
@_subject: [tor-talk] glibc's DNS lookups fail 
Are you using the iptables rules shown on
 ?
Robert Ransom

@_date: 2012-02-18 03:43:44
@_author: Robert Ransom 
@_subject: [tor-talk] Installer for obfsproxy as a Windows service 
obfsproxy does not support UDP.
It's probably  , which is quite
reproducible.  (Fortunately, Roger reproduced it on Linux, where it
was able to give us some information which might let us debug it.)
I don't think obfsproxy supports that yet.  (Patches welcome!)
Robert Ransom

@_date: 2012-02-20 08:23:05
@_author: Robert Ransom 
@_subject: [tor-talk] irc clients and Tor 
torsocks 1.2-3 just hit wheezy/testing, and it works on irssi (at
least as shipped in wheezy).
Robert Ransom

@_date: 2012-02-20 18:09:45
@_author: Robert Ransom 
@_subject: [tor-talk] Obfsproxy Documentation/Help? 
Yes, there is.
Oh, you want to know *how* to do that?  Look at/edit/copy the line
beginning with ?TransportProxy? in the ?state? file in Tor's
DataDirectory.  That file is not user-friendly; edit it as little as
you can.  You may need to use a text editor which can handle
Unix-style line endings.
Robert Ransom

@_date: 2012-02-24 13:36:45
@_author: Robert Ransom 
@_subject: [tor-talk] Let's make Onion Addresses Meaningful To Humans 
Which languages do you want us to ship a dictionary for in every Tor
client?  (Please specify the exact dictionaries you want us to use as
How large are these dictionaries (in bytes)?
No.  Computers do not operate efficiently on numbers represented in base 10.
Have you tried this using the actual dictionaries that you want us to
use?  Are the resulting addresses really memorable?  How long are the
resulting addresses?  Can they be entered into a computer as
efficiently as addresses in the current format?  Can a human proofread
addresses in this form for errors as efficiently as addresses in the
current format?
Robert Ransom

@_date: 2012-02-24 16:10:48
@_author: Robert Ransom 
@_subject: [tor-talk] Let's make Onion Addresses Meaningful To Humans 
Tor clients themselves interpret hidden service hostnames, so every
Tor client would need to include every dictionary.  (Dictionaries
couldn't be kept in an optional extra package, because clients which
do not have a particular dictionary would be easily distinguishable
from those which do have it.)
Robert Ransom

@_date: 2012-02-26 11:49:07
@_author: Robert Ransom 
@_subject: [tor-talk] dizum 
This means that one of the directory authorities started using a new
?certificate? to sign a ?consensus?.  This message isn't something
that normal users and relay/bridge operators should care about; we'll
downgrade its severity in future releases of Tor so normal users won't
see it.
Robert Ransom

@_date: 2012-02-29 18:13:18
@_author: Robert Ransom 
@_subject: [tor-talk] Does obfsproxy make any sense for relays 
We don't know.  We were worried that would crash clients who use an obfsproxy with a relay behind it, but
I've had a Tor 0.2.3.12-alpha-dev client running for over a day
configured to use a relay as a bridge, and so far I haven't seen a
I'll be willing to declare that clients which use microdescriptors
aren't susceptible to  after a week or two (to ensure that moria1
has changed its onion key, and this issued a new microdescriptor).
That won't help clients that are configured to also use a bridge
running 0.2.2.x, but hopefully no one who uses obfsproxy will try to
also use a regular bridge.
I should start another Tor client with microdescriptors disabled, too.
 Maybe that will help us find (and fix)  if it's still around in
Robert Ransom

@_date: 2012-02-29 19:35:03
@_author: Robert Ransom 
@_subject: [tor-talk] Does obfsproxy make any sense for relays 
It was bad wording, but we both knew what you had to have meant.
Robert Ransom

@_date: 2012-01-19 15:53:25
@_author: Robert Ransom 
@_subject: [tor-talk] tor out of date 
See  .  (The easy download
page ( provides a
link to that: ?Looking For Something Else? View All Downloads?)
We do.  See  and
 for instructions for Debian,
Ubuntu and some RPM-based distributions; if we don't provide a package
for your distribution, you can still build from source.
Robert Ransom

@_date: 2012-01-22 23:09:26
@_author: Robert Ransom 
@_subject: [tor-talk] hidden files in tbb/linux directories, 
Those files are generated by one of the TBB-for-Linux build scripts
so that if that script ever misbehaves, I (or whoever else has to
debug it) can find out what it did and what it was trying to do
without having to rebuild all of TBB.
Robert Ransom

@_date: 2012-01-25 17:17:29
@_author: Robert Ransom 
@_subject: [tor-talk] Fwd: ANONdroid 
JonDonym (or whatever they called themselves at the time) backdoored
its service in order to deanonymize a user.  Their centralized design
makes it likely that their service will be backdoored again.
Robert Ransom

@_date: 2012-01-28 00:17:58
@_author: Robert Ransom 
@_subject: [tor-talk] Aurora only build 
README.dev has not been updated since it was split out of the README
file in April 2009.  That statement is no longer true.
Robert Ransom

@_date: 2012-07-23 04:17:05
@_author: Robert Ransom 
@_subject: [tor-talk] TBB lags behind as Firefox ESR 10.0.6 is released 
* Firefox 10.0.6 is a security-fix-only release.  Why is Erinn putting
it through a QA process?
* What classes of problems can the QA process detect?  Are these
problems more severe or less severe than arbitrary remote code
* How long will you wait for the QA process before making this
security-fix release available to users?
* How long will you wait before removing the current stable release
from the list of ?recommended versions? of TBB?
Robert Ransom

@_date: 2012-07-26 22:19:12
@_author: Robert Ransom 
@_subject: [tor-talk] Problem with new multiple-instance exit nodes never 
The dirauth operators all have this option unspecified (or set to 2).
To fix this, either (a) persuade the dirauth operators to increase
this value or (b) get more IP addresses and run at most two relays on
each of them.
Robert Ransom

@_date: 2012-07-27 01:48:51
@_author: Robert Ransom 
@_subject: [tor-talk] Problem with new multiple-instance exit nodes never 
It's not the easiest option, but it is possible.  If you can make a
convincing argument that whichever value you want them to set is still
low enough to not make serious attacks significantly easier, or that
raising the limit will let a significant amount of ?good? relay
capacity enter the network, the limit will probably be raised.
It might be even easier to persuade ?enough? dirauth operators to try
raising the limit and see whether the result is ?good? or ?bad? in
various ways; if nothing especially bad happens after a week or two,
they'll probably change the default limit.
I have no idea how to configure your OS to allow you to use a second
IP address.  That sounds like a common task, though, so there must be
instructions for it somewhere.
To configure Tor to listen on a specific IP address: Use Tor 0.2.3.x
on the relay, specify an IP address on your ORPort torrc line, and if
Tor refuses to start, read and act on its log messages.  (Bonus points
for reading the log messages yourself instead of pasting them into
e-mail or IRC and waiting for someone else to echo them back to you.)
You might need to specify an IP address explicitly for all of the
relays (even the ones you want to listen on your server's default IP
address); being explicit about that certainly won't hurt anything on a
server with static IP addresses.  I recommend continuing to use a
different ORPort for each Tor instance, since some/many/most censoring
firewalls censor connections with different server ports in different
Robert Ransom

@_date: 2012-03-02 05:19:25
@_author: Robert Ransom 
@_subject: [tor-talk] Operating system updates / software installation 
Every FreeBSD port's list of distfiles includes hashes and sizes of
each distfile to be downloaded.  If I remember correctly, the only
required hash is SHA-256.
portsnap and freebsd-update reportedly use good, competently designed
crypto to verify the files they download before parsing them in a
shell script with (necessarily) root privileges.
portaudit downloads, ungzips and untars an unsigned file as root, then
parses a text file extracted from what was hopefully a tarball in a
shell script run (unnecessarily) as root.  Sucks to be a FreeBSD user.
But apt uses GPG (run with (necessarily) root privileges) to verify
the files it downloads.  Sucks to be a Debian user when someone finds
another code-exec bug in GPG's parsing code.
This is a bigger risk to anonymity -- automatic update-related
operations run in the background on a transparent-proxied system can
link the traffic you intended to anonymize with properties of your
operating-system installation (e.g. on Debian, /etc/cron.daily/apt
leaks your system's time zone and the set of package repositories that
you install software from to your circuits' exit node(s)).  Windows
users are at much greater risk from this, because most people install
lots of crap software, thereby marking their systems (and thus their
Tor circuits) with a unique set of automatic updaters.
Of course, if you live in Iran, you're probably better off taking your
chances with exit-node roulette than downloading unsigned, unverified
updates directly through a known-malicious ISP.  Just don't expect
your transparently proxied traffic to stay anonymous.
Robert Ransom

@_date: 2012-03-02 06:16:19
@_author: Robert Ransom 
@_subject: [tor-talk] Operating system updates / software installation 
Jacob Appelbaum is the one that wanted a transparent-proxy client
feature in the ?Torouter? (and enabled by default for an unsecured
wireless network).  He gave at least three reasons for it:
* It would allow/encourage people who buy the ?Torouter? (or whatever
  name it would have ended up with) to provide a public wireless
  access point, even if their ISP would not permit them to do so or
  would punish them for their neighbors' misbehaviour.  (This reason
  was not met with enthusiasm.)
* It would allow people who own a Torouter and some other
  special-purpose device which cannot run a Tor client itself (he gave
  the Chromebook as an example) to route their traffic through Tor.
* It would protect people who own a Torouter and route their traffic
  through it against traffic logging by their ISP.
None of these uses are able or intended to anonymize user traffic, but
the latter two do justify the existence of a transparent-proxy client
BitTorrent clients ?seed? over Tor, too.  That eats rather more
bandwidth than just downloading a file over Tor.
But it's not just bandwidth load.  BitTorrent clients open many TCP
connections, and frequently close them to switch to another
destination; the open TCP connections chew up TCP port numbers on your
exit node, and switching to new TCP connections will spread the
traffic load over many Tor circuits, so you'll break what little
rate-limiting the Tor network can impose *and* hose more relays and
exits with traffic and TCP connections.
And the jerks who use Tor for copyright-infringing torrent traffic (or
even just to connect to the tracker for a copyright-infringing
torrent) get their exit nodes' hosting providers flooded by
fake-DMCA-notice spambots.  That can get exit nodes shut down, thereby
reducing the Tor network's capacity significantly.
GPG sucks, so apt sucks too.
apt-get has the decency to only download over a small number of
parallel connections, and not upload, so it shouldn't eat as much
bandwidth as BitTorrent.
I'm more worried about the risks to user anonymity.  It sucks to be
the user reading about some sensitive subject when your apt cron job
decides to poke every package source you install from.  ?Oh, that guy
who keeps reading about Foozer's Disease must be in the
Antarctica/McMurdo time zone!?
It's probably not anonymous.
Tor's goal is to provide unlinkability between the source of a
connection and its destination.  Tor Browser Bundle and Tails aim to
provide unlinkability at destinations between connections from a
single source.  Anonymity requires the latter property.
Of course, if you want to link your connections together, you
certainly can -- I log into GMail over Tor using a username and
password linked to my real name and to a location where I live.  I'm
not anonymous, nor even pseudonymous, but Tor still prevents GMail
from determining my current location.
An operating-system installation which was set up without Tor, then
stuck behind a Tor transparent proxy, receives location privacy from
Tor.  If the person who set up that system was careful to turn off all
the automatic network operations that could otherwise make a system's
traffic identifiable, the system could even be anonymous.  You aren't
likely to get there from a Debian or FreeBSD system without serious
effort.  I don't think it's possible at all with Windows.
?apt-get upgrade? should be fairly well-behaved for a bulk-download
client.  Sucks that ?apt-get upgrade? tells your exit node what Debian
mirror you installed from and what updates you want to install.  Sucks
that the apt cron job told the exit node that you were reading about
an embarassing medical condition through what Debian mirror you
installed from and what time zone your VM is set for.
Anonymity is hard!  Let's do crypto.
(That sounds like politician-speak.)
Use Tor 0.2.3.x-alpha, give the user 10 or more SocksPorts and 10 or
more DNSPorts to point things which really need to be anonymous at,
and no TransPort.
In the VM you're trying to ?anonymize?, run 10 or more
transparent-proxy-through-SOCKS stubs (one for each user ID in which
you run a non-SOCKS-friendly application that you want to
?anonymize?), and set up iptables rules.
Using a SocksPort safely is complicated.  If you couldn't bother to
SOCKSify an application's source code properly, did you audit it for
all the possible information leaks that could nuke what little
anonymity you had left after the cron jobs?
Let's not.  It's bad enough that the GlobaLeaks clowns are telling
people to point a Windows application SOCKSifier at their feet and
pull the trigger.
s/anonymous //
You can prevent a system from making non-Torified connections without
having to mash all of its traffic into the same Tor ?identity? with a
single transparent proxy.
Sounds like a good piece to split into a separate program, but
splitting Tor's link protocols into separate processes is more
immediately important.
(That sounds like politician-speak, too.)
I'm all for auditing more applications, and then SOCKSifying them
properly, so no one will need a transparent proxy.
No.  See above, and see my reply to Andrew's message.
That ticket was a user support question, and did not belong in Trac.
It was not a ticket about removing Tor's built-in transparent proxy
support (or splitting it into a separate process).  (I think it's too
early to file such a ticket.)
Most of the people who were ?up to it? considered other tasks more
important than developing an easy-to-misuse transparent proxy kit,
and/or did not consider themselves qualified to make a
transparent-proxied system (other than possibly Tails) ?anonymous?.
(I no longer think I'm capable of setting up an anonymous Debian
system using a transparent proxy.  Fortunately, I never got around to
that back when I did think I was capable of it.)
Robert Ransom

@_date: 2012-03-05 22:15:38
@_author: Robert Ransom 
@_subject: [tor-talk] Awareness for identity correlation through circuit 
Everyone who suggests using BitTorrent over Tor is pointed to
 ,
which mentions that issue.  It should be more visible.  Perhaps you
could send a patch to add it to the list of warnings on the download
page (see for the source files).
Using multiple SocksPorts from the same Tor client only helps if you
are using Tor 0.2.3.x-alpha, which introduced 'stream isolation'.  (I
don't think 0.2.2.x supports multiple SocksPorts at all.)  Read the
man page.
The Tails developers plan to start using Tor 0.2.3.x and 'stream
isolation' as soon as a 0.2.3.x stable release is available.  This
might or might not happen in time for Tails 0.11.  (But applications
running within Tails have much less information to leak about their
More importantly, many applications which you did not intend to torify
will use that DNS resolver.
The torsocks command supports a user-specified configuration file
(read the man page).  The usewithtor command does not.
I agree that someone should make configuring torsocks easier.  (Note
that usernames and/or passwords can be used to separate streams, too.)
This is the main reason that I'm not a fan of TorBOX.  It provides
pseudonymity, not anonymity, but most people will think that it
provides anonymity.
Robert Ransom

@_date: 2012-03-11 00:39:05
@_author: Robert Ransom 
@_subject: [tor-talk] Can't access Tor network 
Is your network cable plugged in?  (Yes, this problem actually happens.)
Have you tried using bridges?
(Something is dropping all packets between your computer and the
directory authorities.  This doesn't look like a DPI box; it's
dropping packets before it saw a single TLS handshake.)
Robert Ransom

@_date: 2012-03-18 16:17:54
@_author: Robert Ransom 
@_subject: [tor-talk] high memory usage 
Which version of Tor are you using, and what package did you obtain it from?
On a Unixoid operating system, recompiling Tor with the
--enable-openbsd-malloc configure option would probably help.  But
that code isn't currently Windows-compatible.
Robert Ransom

@_date: 2012-03-25 03:35:55
@_author: Robert Ransom 
@_subject: [tor-talk] TOR bridge mailing list 
By default, each Tor bridge publishes a descriptor to the ?bridge
authority?.  Every hour, the bridge authority sends the descriptors of
currently running bridges to bridges.torproject.org, which distributes
them to users who request bridges over HTTPS and by e-mail.
Distributing bridge addresses once a week is not useful.  Most bridges
move to a different IP address every 24 hours.
Robert Ransom

@_date: 2012-03-25 20:31:56
@_author: Robert Ransom 
@_subject: [tor-talk] How can the video play in TBB without plagins? 
Firefox 4 and later support the HTML 5 video tag.
Robert Ransom

@_date: 2012-03-30 03:06:54
@_author: Robert Ransom 
@_subject: [tor-talk] Choosing a name for a .onon 
Shallot computes a single public modulus p*q and searches for a public
exponent e which produces a SHA-1 hash with the desired properties.
That's much faster than doing a 512-bit-by-512-bit bignum multiply for
each hash, *and* the search for a suitable exponent could (in theory)
be performed in parallel across many (untrusted) computers.
Robert Ransom

@_date: 2012-03-30 03:28:39
@_author: Robert Ransom 
@_subject: [tor-talk] Choosing a name for a .onon 
In the old-style (PGP 2.x) key ID format, a portion of the public RSA
modulus was directly used as the key ID.  The most
difficult-to-implement algorithm that you could possibly want to use
to attack that involves a lattice computation, and succeeds far faster
than brute-force.
New-style (OpenPGP) key IDs are hashes of the public key; the only
attack that can produce a desired key ID is brute-force search.
(That's not hard though -- for RSA, generate a keypair in the usual
manner, then change the public exponent (as Shallot does); for DSA or
ElGamal, generate a keypair and then search for powers of the group
generator and of the public key which lead to the desired hash.  Both
attacks allow the brute-force search to be performed on computers
which cannot be trusted to know the private key.)
So yes, short PGP key IDs are very bad news.  Avoid them if you can
(but I doubt that you can).
Robert Ransom

@_date: 2012-03-30 04:19:35
@_author: Robert Ransom 
@_subject: [tor-talk] Choosing a name for a .onon 
Yes.  (Note that hidden service identity public keys are only used for
signature verification, which is not the same as encryption with any
modern padding scheme.)
But Tor didn't enforce that requirement for hidden service identity
keys soon enough, and I don't think OpenSSL's RSA implementation
benefits much from those particular choices of e (other than from the
fact that they're short).
Maybe a little.  No one will let Shallot run long enough to produce a
really big public exponent, though.  (Relays raise 1024-bit numbers to
320-bit powers all the time for forward secrecy.  Shallot won't
generate 320-bit public exponents.)
Maliciously generated hidden service identity keys could have much
larger public exponents, but hopefully no one will bother implementing
that DoS attack.
Maybe.  But note that the public exponent is stored at the end of the
public key blob, so updating the exponent (or a piece of it) also
makes generating each hash easier.
No -- the Euclidean algorithm would break that *very* quickly.
Robert Ransom

@_date: 2012-03-30 07:45:01
@_author: Robert Ransom 
@_subject: [tor-talk] Choosing a name for a .onon 
After reading that note four times, I still see no details about your
attack tool.
Your note does not contain the word ?timestamp?.
According to RFC 4880, the key generation timestamp is near the
beginning of the key blob.  Thus, every time you change the timestamp,
you need to re-hash a relatively long fixed string (the public modulus
in an RSA key, or the group parameters in a DLP-based key).  Changing
the timestamp may be useful for DSA or ElGamal keys (I'm not convinced
of that), but it's not helpful in generating an RSA key with chosen
key ID.
Robert Ransom

@_date: 2012-05-06 07:03:31
@_author: Robert Ransom 
@_subject: [tor-talk] can't enable SSL with IRSSI over TOR 
Does Freenode's hidden service support SSL?  Does it support SSL on port 6697?
Robert Ransom

@_date: 2012-10-14 15:57:30
@_author: Robert Ransom 
@_subject: [tor-talk] Tor download without browser 
Since you are only interested in censorship circumvention, not
anonymity, you can try to configure your software to use
127.0.0.1:9050 as a SOCKS proxy.  (You might need to set this as a
system-wide proxy.)  Depending on what kind of censorship your ISP is
performing and how your applications use, misuse, or don't even try to
use proxies, this might or might not help.
Please note that (a) this will provide NO ANONYMITY, and (b) any web
browsing that you perform through the same Tor client will also be
deanonymized by these other applications' traffic.
Robert Ransom

@_date: 2012-10-15 13:58:59
@_author: Robert Ransom 
@_subject: [tor-talk] Location-aware persistent guards 
The hardest part is load-balancing among the possible entry guards.
Robert Ransom

@_date: 2012-10-15 15:58:01
@_author: Robert Ransom 
@_subject: [tor-talk] Location-aware persistent guards 
Mike Perry took the TICKET_MODIFY permission away from ?normal? Trac
users because one moron misinterpreted a change to one ticket's
keywords (
 (I don't see how that change will prevent normal users from *reading*
changes to ticket keywords, but whatever.)
My suggestion would be quite inefficient if entry guards' weights vary
widely.  Sorting a long list is even more inefficient, and would need
to be done in data-independent time if (as you suggest) the sort keys
are secret.
Robert Ransom

@_date: 2012-09-08 08:46:42
@_author: Robert Ransom 
@_subject: [tor-talk] Hidden Services - reliably resolving/using onions, 
Patient: ?Doctor, it hurts when I do this.?
Doctor: ?Don't do that then.?
Tor's hidden service protocol requires that the client build many
auxiliary circuits in order to establish each rendezvous circuit (and
a client must open a separate rendezvous circuit with each hidden
service that it connects to).  A client connection attempt which does
not succeed quickly also causes the service to build many wasted
circuits.  Any system in which each user operates a Tor hidden service
and attempts to connect to many other users *will* put excessive load
on the network in several ways, in addition to wasting users' CPU time
and making the Tor instances involved generally flake out.
Robert Ransom

@_date: 2012-09-11 05:55:30
@_author: Robert Ransom 
@_subject: [tor-talk] Windows Screenreader Users? 
A blind user reported to tor-assistants that Vidalia does not work
with JAWS.  I later tested Vidalia with Windows Narrator, and it did
not speak the labels or contents of any 'controls' within Vidalia
Robert Ransom

@_date: 2012-09-11 06:00:25
@_author: Robert Ransom 
@_subject: [tor-talk] TorBrowser Tweaks 
This wiki page is crap.  Someone should 'blank' it (edit it to remove
its content).
Robert Ransom

@_date: 2012-09-11 06:40:03
@_author: Robert Ransom 
@_subject: [tor-talk] SocksPort: Circuit isolation is not Exit isolation 
This makes choosing each circuit's exit node independently even more important.
Jane Red is hosed regardless of her exit-node distribution:
The casual log observer will see that all three have, at some time,
connected from IP addresses whose reverse-DNS strings contain ?tor?,
and decide based on that that they are all the same person.  And if
you cause them any trouble, they may hand their logs over to a
statistical log observer.
This sentence seems about as relevant to the rest of your message as a
fruit bat.
Robert Ransom

@_date: 2012-09-15 03:26:20
@_author: Robert Ransom 
@_subject: [tor-talk] onion id calculation 
You're using the first quarter of the base16 encoding of the SHA-1
hash, instead of the first half of the SHA-1 hash itself.
Robert Ransom

@_date: 2012-09-26 02:08:06
@_author: Robert Ransom 
@_subject: [tor-talk] Tor and P2P 
DO NOT use implement peer-to-peer software that way.  You will make
your users more vulnerable to some attacks, and thrash the HS
directory system excessively, and probably overload the users' Tor
client processes to the point that they start pounding on the Tor
network in general (see  for one
failure mode).
Some parts of the Tor hidden service protocol can be used for
peer-to-peer communication, but that would require new client-side
protocols (for communication between the application and the Tor
client), as well as an overhaul of the hidden service code.  SOCKS and
Tor's current control-port protocol are not suitable for this.
Whether those protocols are ?standardized? in any way or not, they
need to be designed and/or reviewed by people who understand Tor well,
and implemented competently.
Robert Ransom
