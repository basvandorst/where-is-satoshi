
@_date: 2004-08-25 23:28:30
@_author: Nick Mathewson 
@_subject: A small how-to - request for comments 
Thanks, Thomas!  Cool HOWTO.  Have you thought about adding it to the
wiki?  (
I worry about sections 2 through 4, though.  One warning about using
tsocks in this way, however.
tsocks correctly replaces 'connect' calls with calls to your SOCKS
proxy (Tor).  But tsocks doesn't do anything about requests to your
DNS server.  This means that if you refer to any machines by hostname
when you're using tsocks, you'll be sending that hostname over the
network, perhaps leaking the fact that you are about to connect to the
corresponding server.
Tor 0.0.8 has a workaround for this problem, until we can hack tsocks
(or a work-alike) to support DNS.  Instead of using a hostname
directly, first use 'tor-resolve' to resolve the hostname into an IP
(via Tor) and then use that IP address with your tsocks-ified

@_date: 2004-08-26 18:40:12
@_author: Nick Mathewson 
@_subject: Basic questions 
I know there's at least one Windows solution that acts a little like
tsocks, but I haven't used any myself.  SocksCap looks as though it
might do what you want, but I'm not sure it's the very best.
You should probably run an onion router if you want to be a server;
I'll try to clarify this in the documentation.  If you just want to
run a client yourself, you don't need to set ORport at all.
Tor runs as a superset of socks4 and socks4a, and implements some (but
not all) of socks5.  To see what parts of socks tor supports, see
  Hope this helps,

@_date: 2004-08-26 19:07:25
@_author: Nick Mathewson 
@_subject: Test: TOR and the Mule --- HELP 
Right.  It looks as though your application is using socks4, not
socks4a as it claims.
This is as expected; privoxy only handles HTTP requests, not SOCKS
Here's a little diagram.  (You might need to use a fixed-width font to
view this properly.
When you use Privoxy and socks4a, your requests look like this:
     I  "GET      V
I Privoxy I
     I "Connect to servername"   (socks4a)
     V
  -------
  I Tor I
  -------
And when you use an application that uses socks4a correctly, it works
like this:
     I "Connect to servername"   (socks4a)
     V
  -------
  I Tor I
  -------
But what emule seems to be doing is:
-                I
 I  "Lookup servername"        I "Connect to IP address" (socks4)
 I                             I
 V                             V
---------     -------
So privoxy can't help you, if you aren't using HTTP.  If you want to
avoid leaking your destinations to your DNS server, you need to do one
of the following:
   - Make your application use socks4a correctly.
   - Resolve the server name to an IP though some safe means.  I don't
     know whether the tor-resolve script works cleanly on windows; if
     it does, you can try to manually resolve server names to IPs and
     see if you can point your application to them directly.  (You
     might need Python to make it run; the next version of Tor will
     include a standalone version that doesn't need python.)
It's possible that some future socks interface application might be
able to replace your application's calls to the windows DNS stack with
request to Tor instead, but this feature isn't implemented in any that
I'm aware of right now.
Hope this helps,

@_date: 2004-08-19 13:26:45
@_author: Nick Mathewson 
@_subject: (FWD) Compiling Tor on Windows? 
Okay, this turns out to be a piece of weirdness in cygwin's autoconf.
I don't know what caused it, but I've committed a workaround to CVS,
so the next release should build on cygwin just fine.
If you want to build on cygwin in the meantime, you can either get the
latest snapshot from CVS (instructions are on the main Tor page), or
make a one-line change to the file "util.h".  Change the 29th line
 HAVE_STRUCT_TIMEVAL_TV_SEC
 !defined(HAVE_GETTIMEOFDAY) && !defined(HAVE_STRUCT_TIMEVAL_TV_SEC)
There's a precompiled 0.0.8rc1 binary available from
   You'll need to install OpenSSL first; there are instructions on the
This one should work better, we hope. :) Please let us know if it
Many thanks for your patience,

@_date: 2004-08-24 20:02:10
@_author: Nick Mathewson 
@_subject: tor client over HTTP or SSH port forwarding ? 
There will be an easy solution with Tor 0.0.8, which should be out
today or tomorrow (assuming we find no more bugs in 0.0.8rx2).
Assuming your firewall allows port 443 (HTTPS) and port 80 (HTTP), you
can just add "FascistFirewall 1" to your torrc file, and Tor will only
use servers that are listening on ports 443 and 80.
Just one problem, though: Currently, I don't think there are any
servers configured like that.  With any luck (and, hopefully, a good
port forwarding FAQ), there should be a few such 'firewall-friendly'
servers ready in the next couple of weeks.

@_date: 2004-12-07 21:53:14
@_author: Nick Mathewson 
@_subject: Reproducible crash with tor0.0.9rc6-win32 and https 
Hi, Jesse!  My apologies for not answering earlier.
We traced this bug to a side-effect of an earlier fix for compilation
on Solaris.  Unfortunately, this fix was subtly broken on platforms
that used signed char by default, and was very broken on windows with
non-ASCII characters.
We will have an rc7 out within a day or so that should fix this
problem and a few others.
Thanks for your patience,

@_date: 2004-12-18 00:32:27
@_author: Nick Mathewson 
@_subject: Confusing (error?) messages for a none tech-saavy user. 
Thanks for the message!  You're right; this wasn't a very good log
message, and we think we've made it better in 0.0.9 and 0.0.9.1 (the
latest release).
You would see this message if a connection has to be closed, but we
still had some data to write on the connection.  This can happen when
an application closes a connection without reading all of its data,
and for many other reasons.  It's nothing to worry about, and it
doesn't produce a [warn] message in the latest releases.
Hope this helps,

@_date: 2004-12-21 15:39:06
@_author: Nick Mathewson 
@_subject: Tor a Virus? 
Okay, I've download the latest AVG 7.0 Free[*] edition, and tried it
out.  I tried it with Tor running, and not running.  It flagged
0.0.9pre4 as a trojan, as you say.  It didn't flag Tor-0.0.9.1 as a
Trojan, or any other windows version I could find, and I tried a lot.
Here's what I think the possibilities are.
Given that the complaint is that Tor is a "trojan horse proxy", my
guess is that one of the following is true:
    1. Maybe, by default, AVG detects some SOCKS proxies, thinks that
       all SOCKS proxies are evil, and needs to whitelist specific
       SOCKS proxies one by one.  For some reason, they detect
       0.0.9pre4, but not other versions.   (Not so likely.)
    2. Maybe AVG blacklists versions of Tor deliberately, thinking
       that Tor itself is a SOCKS proxy, and all SOCKS proxies are
       evil.  They blacklisted pre4, or something that looks very like
       it.  (Confusing, but possible.)
    3. Maybe I was infected with a virus of some kind between the
       release of pre3 and pre4, but it went away by itself before I
       released pre5.  (Just barely possible; not too likely.)
    4. Maybe I have in fact been infected by a virus that no virus
       scanner can detect on my computer, but which can only be
       detected in tor-0.0.9pre4.  (Not likely either.)
I'm going to insestigate more to find out what happened.  If anybody
is using the commercial version of AVG, I'd appreciate your asking
them for tech support: their web pages says they won't help people who
haven't paid.  I'll send a request anyway, but my hopes aren't too
[*] Free as in beer.

@_date: 2004-12-21 21:01:48
@_author: Nick Mathewson 
@_subject: Tor a Virus? 
Follow-up: I sent a message to their tech-support address, but got an
auto-reply saying that they don't read mail unless it contains a
registration number.  I'm not going to follow any further with these
people.  With luck, somebody else can who has the paid version of
their software can contact them to ask them what's up.
Here's the message I sent.

@_date: 2004-12-21 23:35:29
@_author: Nick Mathewson 
@_subject: Tor a Virus? 
[...]
No.  Before version 0.0.9pre6, there was no windows installer.

@_date: 2004-12-23 23:34:48
@_author: Nick Mathewson 
@_subject: Tor running on mipsel 
There was a problem with the authdirservers earlier; but as Roger has
mentioned elsewhere, we managed to fix it for the moment. :)
Thanks for these points; they were very helpful.  I'm adding them to
our TODO file.  We should get them done some time in the Tor 0.1.0
series, if not sooner.

@_date: 2004-11-30 11:10:38
@_author: Nick Mathewson 
@_subject: some tor questions 
No.  It will choose from the list randomly, and when it's time to
rotate circuits, it will choose from the list randomly again.

@_date: 2004-10-13 22:05:10
@_author: Nick Mathewson 
@_subject: get_default_conf_file under windows 
[...]
Applied.  This will be in 0.0.9pre3.
Can you confirm that with this patch, Tor now works on NT 4?

@_date: 2004-09-01 23:06:57
@_author: Nick Mathewson 
@_subject: Limiting possible last hops 
No need to annotate the data on the tor network; each user's client
software chooses exit points on its own, so you could just have the
user tell the client "for request to this location, use one of these
routers".  This could easily go into the client config file, for
Automatic location affinity would be even cooler, if we could do it;
see  .
Possibly; I'm not as sure that this is what you really want.  Why not
just do it at the configuration level?

@_date: 2004-09-01 23:12:19
@_author: Nick Mathewson 
@_subject: Open Proxy Monitors 
This is correct.  It is not a design goal for Tor to hide which
connections are coming from the Tor network.  Although I *personally*
believe that people should allow anonymous connections, I also believe
that people should have the right to ban anonymous connections to
their own servers if they don't want to get them.
Honestly, the solution for people who want to chat anonymously is to
use a service that doesn't do IP-based authentication and blocking.
Somebody mentioned silc; I haven't tried it myself, or investigated
its security, but it seems a step in the right direction.

@_date: 2004-09-01 23:14:12
@_author: Nick Mathewson 
@_subject: Overloading defaults 
Good suggestion.  Assuming Roger agrees, this will be fixed in 0.0.9.

@_date: 2004-09-30 11:35:25
@_author: Nick Mathewson 
@_subject: Funning log entry... 
Tor isn't looking for stuff in "documents and settings\nickm" on your
machine; it is complaining that it found a bug in a part of the
program that was in that directory on my machine when _I_ compiled it.
No need to worry about that.  As for the actual bug--- I'll try to figure out what's up with that.

@_date: 2004-09-01 14:26:06
@_author: Nick Mathewson 
@_subject: Limiting possible last hops 
You can request that Tor only use specific last hops by setting the
"ExitNodes" option in the configuration file.  By default, Tor treats
this option as a request: if none of your preferred exit nodes is
available, Tor tries other nodes to see if they can work.  You can
make the option mandatory by setting the "StrictExitNodes" option.
See the tor manual page for more information.

@_date: 2005-04-15 19:03:20
@_author: Nick Mathewson 
@_subject: TOR dying 
FYI, this looks like a libevent bug -- see the most recent comment on
the bug page linked above.

@_date: 2005-04-19 20:45:04
@_author: Nick Mathewson 
@_subject: Tunnel length (WAS: Re: Tor sketches) 
End-to-end correlation attacks work if the attacker can view both ends
of a circuit.  The attacker notices that the timing and volume of
the traffic entering Alice's end of the circuit is correlated to the
timing and volume of the traffic leaving at Bob's end of the circuit,
and so links Alice to Bob.

@_date: 2005-04-05 20:18:03
@_author: Nick Mathewson 
@_subject: 4/4 CVS Build - Huge Jump in Responsiveness - Just ME? 
Hi, Gene!  This is indeed looking to be a fun and exciting bug. :p
A bugtracker item would be a great idea.  Maybe, "Crashes in 0.1.0.x
with NetBSD" ?

@_date: 2005-04-05 20:47:21
@_author: Nick Mathewson 
@_subject: 4/4 CVS Build - Huge Jump in Responsiveness - Just ME? 
Okay, I think I fixed this.  See whether no-pthreads builds work for
you with latest CVS?
Also, which versions of NetBSD and libevent are you using?

@_date: 2005-04-05 23:06:03
@_author: Nick Mathewson 
@_subject: Problems making tor work 
[...]
I think you meant 9050, not 5090.
Also, you shouldn't be using Tor directly as a SOCKS proxy: doing so
can leak information via DNS requests.  (See
 .)
Instead, you should point your web browser at an HTTP proxy like
privoxy, and tell the proxy to use SOCKS4a to connect to Tor.  For
instructions on this, see Please don't hesitate to ask us any more questions that you may have.

@_date: 2005-04-05 23:18:58
@_author: Nick Mathewson 
@_subject: 4/4 CVS Build - Huge Jump in Responsiveness - Just ME? 
Oops. My fault. It should be fixed now.
And when you have the chance...

@_date: 2005-04-05 23:29:00
@_author: Nick Mathewson 
@_subject: 4/4 CVS Build - Huge Jump in Responsiveness - Just ME? 
I wasn't wondering about pthreads; I was curious about your version of

@_date: 2005-04-06 18:12:08
@_author: Nick Mathewson 
@_subject: even simpler solution [was: Re: script to magically restart tor [was: Re: disappearing nodes]] 
Watch out!  In the past, people doing things like this have wound up
hosing the Tor network pretty badly: Suppose that, for some reason,
your configuration becomes broken or your software becomes obsolete.
Suppose that this brokenness or obsolescence is only apparent after
your software has connected to another Tor server.  If this happens,
then the tight loop you give above will create a tool that hammers the
Tor network in a tight loop---and hopefully, that's not what you
(One case that comes to mind: somebody was doing the above with an
obsolete version of Tor.  But when Tor realized it was obsolete, it
downloaded a directory to make sure it was *really* obsolete before
shutting down.  Ouch!  The directory servers were overloaded.  To
solve it, we had to block the badly-behaved servers, and make newer
versions of the code download directories slightly less

@_date: 2005-04-12 13:10:49
@_author: Nick Mathewson 
@_subject: Tor Sketches 
Also please be aware: there is probably no security benefit to
changing your path length to anything higher than 3; and we don't know
whether 1 works because we haven't tried it in ages and ages. :)

@_date: 2005-08-18 00:12:08
@_author: Nick Mathewson 
@_subject: Tor does not support W95 
Ah, I think I might know what this is, and why it might seem that we
"dropped" w95 support.
We use the CryptGenRandom function to get entropy from windows.  This
function was introduced in win98; to get it in win95, I think you need
OSR2 or later, or a later version of IE.  I'm not sure if this is
what's up in your case, but it might help.

@_date: 2005-08-19 09:49:06
@_author: Nick Mathewson 
@_subject: bad security setting for win32 tor service 
Matt -- I'd like to accept a patch like this.  Can you explain to me
what it would do for Tor's storage, though?  J Random User shouldn't
be able to read Tor's private keys -- can this happen if Tor runs as
"NT AUTHORITY\LocalService" ?  If so, what is the real solution?

@_date: 2005-08-23 16:51:29
@_author: Nick Mathewson 
@_subject: [take 2] tor-0.1.1.5-alpha 'make check' failure on OSX 10.4.2 
This is nothing to be worried about; it's a bug in the tests, not in
Tor.  It should be fixed in the next alpha version.

@_date: 2005-08-23 17:10:10
@_author: Nick Mathewson 
@_subject: bad security setting for win32 tor service 
But other services are running as LocalService, right?  It would be a
shame if a buggy webserver or something could look at Tor's keys.  Is
it possible for the installer (or the service setup code) to create
a separate limited user for the tor service?
Sounds plausible to me.  If you're playing around with services,
you're not a windows newbie, and you ought to understand this stuff,
right?  Or will this create tons of support problems?

@_date: 2005-08-28 16:30:47
@_author: Nick Mathewson 
@_subject: exitpolicy question 
What version of Tor are you running?  We used to have a bug where Tor
would ignore its exit policy.  In any case, you should make sure
you're running either the most recent 0.1.0.x, or the most recent
0.1.1.x .

@_date: 2005-12-15 05:06:15
@_author: Nick Mathewson 
@_subject: [declan@well.com: [Politech] E.U. Parliament votes to force "data retention" on telecom, Net firms [priv]] 
Hi, Eugen.
I'm sorry you find the experience terrible.  We've been working more
than full time for several years now to try to make it otherwise
without sacrificing performance or security.
Roger is not proposing to introduce padding or delay willy-nilly.
Performance remains a priority.  After all, anonymity networks protect
users with other users.  If we added measures that made performance
suck, users would leave, and any increased protections would be small
comfort the remaining hard-core users.
The only way I can see us building any such system into Tor is if it
could be shown to significantly resist fingerprinting or end-to-end
correlation attacks without degrading performance significantly.
Our current focus for increased performance is to get more servers by
encouraging more users to run servers.  After all, more users without
more servers makes performance worse.  To do this, we must first work
on the network's architecture so that it can scale to tens of
thousands of relays without collapsing.  We're doing this now.
Second, we need to make it easier to run a server, and create
incentives to do so.  This is an active area of research.
(It's not easy to give contributors higher priority, and the reasons
why have been hashed over before. The issue is how to give good users
without making it easy for an attacker to isolate their by its higher
priority.  We're working on this, but it isn't easy.  If there were an
easy and secure way, we would have built it, I promise.)
If we can assume that the attacker is too idiotic to carry out the
attack, then of course any system you name is secure against any
attack you name.  But if one of these "knuckledraggers" knows enough
to ask somebody who reads the literature, or if they announce that
they care vocally enough to contract a commercial provider to
implement simple traffic correlation techniques, they will fare worse.
After all, most sub-TLA police agencies do not build their own
surveillance tools: they buy them off the shelf.
I agree with Roger that the best defenses we know now against this
kind of attack are to increase the total volume of traffic (by growing
the network to handle that traffic), and to split entry and exit
across locations that are unlikely to be compromised by the same
Once again, I'm very sorry that you are unhappy with Tor performance.
We are aware that it is not as fast as many people would like, and we
are aware that improving it would be good.  Please feel free to
contribute any patches you like, and to encourage your friends who
might know how to program to do so.

@_date: 2005-12-15 05:12:42
@_author: Nick Mathewson 
@_subject: Almost on-topic news article -- Wikipedia, Jimmy Wales, and anonymity! 
[...]
Yeah, this represents a split between how the technical world uses the
word "anonymous" and how the broad public uses it.  To us, "anonymous"
means, roughly, "untraceable" -- that an attacker with certain
capabilities can't link users to their speech.  To the public,
"anonymous" often means "unattributed" -- in other words, speech that
nobody wrote their name on.
By way of example: to them, bathroom graffiti is anonymous because it
typically isn't signed.  To us, there's no such thing as anonymous
bathroom graffiti, because it's way too easy to install cameras to
watch people walking into bathrooms, and because people's handwriting
can be identified.
(It's nice, by the way, to see pro-anonymity statements from Jimbo;
this bodes well for technical Tor/Wikipedia rapprochement mechanisms
getting support from their policy wing.)

@_date: 2005-12-22 15:03:24
@_author: Nick Mathewson 
@_subject: recent tor stream timeout errors... 
Um. Guys?  Speaking for myself as a Tor developer here:
AWe have nothing against P2P architectures[*], and no current plans to
"remove P2P traffic from the Tor network" beyond how we currently have
the code, by default, not allow exit to certain ports.  The only
reason that we're asking people not to use filesharing over Tor is
because we believe that the current network doesn't have the bandwidth
to handle bulk data transfer.
So our official stance is that we ask people (politely, please!) not
to shove massive traffic through the network until the network can
handle it.  This is to some extent self-regulating: people who try to
download gigabyte-sized files through Tor usually notice that Tor is
far slower for this than they would like, and stop.
The end solution here is not a model where we try to centrally or
collectively enforce traffic merits anonymity and what doesn't: I
think we can all see where that would lead.  Instead, I think we need
to scale better.
But hey, I'm a tech guy.  I look for technical solutions to
everything. :)
Well, I *develop* Tor because I believe that privacy is a fundamental
right and a prerequisite for security; and that it's inadequate to
rely solely on the threat of after-the-fact enforcement to keep others
from violating your rights or stealing your information.
But then again, you don't have to believe in all of that.  This is a
software development project, not an ideological organization.  We're
stronger when we encompass people with differing goals.

@_date: 2005-12-23 22:29:51
@_author: Nick Mathewson 
@_subject: P2P wanted? 
Those who don't search the or-talk archives are condemned to repeat
them.  :)
Check out the march 2005 archive at
   and the thread called "exit node only server."
In particular, I talk a bit about why you don't really mean
tit-for-tat, and why it's hard, and why you might want to do it anyway
in   and  Paul Syverson offers an important reference at
     And be sure to check out the rest of the thread too!
Hope this is interesting,

@_date: 2005-12-31 03:12:30
@_author: Nick Mathewson 
@_subject: OSX - Manual Restart? 
Hm! There may be a bug here.  I'll look into it. In the meantime, I'd
suggest you do a separate "start" and "stop" step.

@_date: 2005-12-11 20:16:59
@_author: Nick Mathewson 
@_subject: Odd log messages 
That's one likeliest explanation.  Tor uses HTTP to serve directory
information, but (we think) it never sends a HTTP request bigger than
49999 bytes long.  So when it sees a very long HTTP request, it
rejects it.
That's quite a long request, though! Possibly somebody is sending
malformed HTTP, or some compromised machine is trying out exploits.
Hard to say.

@_date: 2005-02-09 23:37:01
@_author: Nick Mathewson 
@_subject: xp help plz 
You should read Many of your readers will not understand what you mean by "too much

@_date: 2005-01-20 14:43:25
@_author: Nick Mathewson 
@_subject: Compile problems on CVS Current under NetBSD 
[...]
By "it didn't help" do you mean "I got the same messages about not
finding libevent"?  Or did something else happen?
This is a problem with your autoconf installation, not with Tor.

@_date: 2005-07-06 17:44:03
@_author: Nick Mathewson 
@_subject: I'm seeing someone else's localhost.localdomain 
Sad to say, that's not what tor-resolve does.  It isn't a replacement
for your resolver; it's a command-line tool that uses Tor to lookup a
single hostname, and returns a single IP address.
Example use:
  [2]% tor-resolve tor.eff.org
  Got answer 209.237.230.66
It would be pretty cool to have a replacement DNS proxy that used Tor;
somebody should write one. :)

@_date: 2005-06-15 14:17:44
@_author: Nick Mathewson 
@_subject: Tor 0.1.0.10 on OSX Tiger problems 
That's not quite right.  You need to run it with "start" or "stop" as
an argument.  Who told you to run it with no params?
Oh, interesting.  It looks like the installer is supposed to create a
_tor user for you, but isn't.  Maybe it's busted on Tiger.  Phobos:
this would be a good place to start checking this out.

@_date: 2005-06-15 14:17:44
@_author: Nick Mathewson 
@_subject: Tor 0.1.0.10 on OSX Tiger problems 
That's not quite right.  You need to run it with "start" or "stop" as
an argument.  Who told you to run it with no params?
Oh, interesting.  It looks like the installer is supposed to create a
_tor user for you, but isn't.  Maybe it's busted on Tiger.  Phobos:
this would be a good place to start checking this out.

@_date: 2005-06-17 22:46:10
@_author: Nick Mathewson 
@_subject: Please review new control-spec.txt 
Hi, all.  At the recommendations of a Very Experienced Internet
Person, I've taken a hard look at the control protocol, and come to
agree with the V.E.I.P that the protocol that shipped with 0.1.0.10 is
a pain in the neck.  It is just binary enough to be hard to use, with
no real benefit.  The solution is to go with a nice text-based
protocol line SMTP and HTTP and everybody else use.
I've done one, currently located at:
   Was this more in line with what you were thinking of?
It's based more on SMTP than on anything else, but it isn't pure
SMTP.  Most trivially, it's 8-bit clean by fiat, has no line length
limits, and so on.  More significantly, I generalized the format used
by the DATA command so that other commands and replies could use it as
well.  Commands that take extra data start with "+"; reply lines that
are followed by extra data use "+" instead of "-".
Also, "6yz" replies can appear out-of-sequence, as you suggested.
Here's an example session:
    C: AUTHENTICATE "secret"
    S: 250 OK
    C: SETEVENTS CIRC
    S: 250 OK
 (now we'll be getting a bunch of '650 CIRC ...' replies.  Note that
 the
 first one we get is not responsive to the GETCONFIG reply.)
    C: GETCONFIG orport controlport
    S: 650 CIRC 1000 LAUNCHED
    S: 250-orport=9001
    S: 250 controlport=9050
    S: 650 CIRC 1000 EXTENDED moria1
 (the next line starts with +, so the server knows to expect a data
 block.)
    C: +POSTDESCRIPTOR
    C: router foobar 1.2.3.4 9001 0 9030
    C: [... a server descriptor goes here ...]
    C: .
    S: 250 OK
    S: 650 CIRC 1000 EXTENDED moria1,moria1
    S: 650 CIRC 1000 BUILT moria1,moria2,moria3
  (the client asks for two "info" values, one of which fits on a
  single line, and one of which doesn't.)
    C: GETINFO version addr-mappings/cache
    S: 250-version=Tor 0.1.1.0-alpha-cvs
    S: 250+addr-mappinggs/cache
    S: tor.eff.org=209.237.230.66
    S: .
    S: 250 OK
If you have the time to see what I've gotten wrong in *this* version
of the specification, that would be much appreciated.  (Even telling
me what is in bad taste would be helpful.)  I've already gotten a
start implementing it.
The old protocol will continue to work in 0.1.1.x, and will only be
disabled in 0.1.2.x or later.  New functionality will not be
backported to the old protocol.  The example controller libraries will
be forward-ported.

@_date: 2005-06-19 20:18:44
@_author: Nick Mathewson 
@_subject: Bandwidth Limiting 
[...]
Not every option that Tor excepts is included in the default sample
torrc.  Just add the BandwidthRate and BandwidthBurst options yourself.

@_date: 2005-06-20 15:21:32
@_author: Nick Mathewson 
@_subject: (FWD) Re: Please review new control-spec.txt 
[...]
Right.  By default, you can send an AUTHENTICATE command before you
send any other command.  Unless you set a password somehow, you can
send any authentication string you want from localhost and it will be
accepted.  You do need to send *SOME* authentication before any
commands, though.
(This is a Sneaky Design Decision to trick to force developers to
admit to themselves that they are doing something ugly when they use a
Just Trust Localhost authentication model.)

@_date: 2005-06-20 20:58:39
@_author: Nick Mathewson 
@_subject: (FWD) Re: Please review new control-spec.txt 
In v0, send the following string if there is no password (octets in
   [00 00      00 07          ]
    ^^^^^      ^^^^^
    length=0   authenticate    That is, send "\x00\x00\x00\x07".
   See control-spec-v0.txt section 2, 3.8, and 4.1.
In v1, send the following string if there is no password:
   "AUTHENTICATE\r\n"
   (See control-spec.txt sections 3.4 and 5.1
hope this helps,

@_date: 2005-06-29 16:05:56
@_author: Nick Mathewson 
@_subject: Howto compile Tor on a windows system 
Did you put the rest of the libevent source anywhere?  Are you
building it too?  Libevent is more than a header file.
In general, when you're reporting errors on a mailing list, you should
tell people what errors you are getting.  Otherwise it's hard to tell
what is going wrong.
With VC7, and the project file in CVS.  Matt Edman sent us an nmake
makefile for 0.0.9 a while ago, but it never got ported to 0.1.0 or
later.  I can try to do this soon if you like.
The steps are:
 - Make sure that everything is up to date:
   - Get the most recent zlib source
   - Get the most recent openssl library.
   - Get the most recent libevent source.
 - Build.
It was a while ago; I haven't tried in a while.  If you have any
patches to make it work with vc6 or cygwin, please send them in.  I'd
love to have Tor build correctly under more compilers.
hoping this helps,

@_date: 2005-06-29 17:36:51
@_author: Nick Mathewson 
@_subject: Please review new control-spec.txt 
Thanks, Robert!  I know you're busy, so I really appreciate your
having taken a look at this.
 [...]
Hm.  I think I might be wandering into religious territory here.
I am pretty convinced that it's simpler to use.  As a completely
unscientific study, the interface code to deal with the new protocol
is about 30% shorter than the code to deal with the old protocol,
excluding comments and whitespace.  I'm seeing this trend across the
Java and Python interface libraries, so I'm pretty confident of it.
Also, the new protocol is far, far simpler to test and debug.  When I
wrote implemented the old one, I needed a pretty complicated test
harness to test each new feature.  I also needed to answer tons of
email and IRC questions from people who had misunderstood how to
connect to the system, how to parse its responses, and so on.  Most
people who approached me with difficulties were stuck at the earliest
message formatting stages: they were sending something slightly
misformatted and baffling themselves completely.
Being able to telnet to the control port makes stuff far, far easier.
Now writing tests is as easy as telnet, scripting tests is as easy as
netcat, and telling people how to use the controller interface is as
easy as typing human-readable strings.
I agree that there are too many different ways to escape things.
"We encode short one-ling strings like this, with \" double quotes"
We encode multiline text like  RFC822,
..where lines beginning with a dot get an extra dot prepended
and after the last line, we have a line containing only a dot
- We've encode binary stuff in hex.
None of these is hard to processor generate, but choosing a single
consistent format would probably help a lot.  The problem is that the
needs are kinda different: in the first case, we have arguments with
optional spaces; in the second, we have multiline arguments; in the
third, we have non-printable arguments.
Hm.  I took a lead from SMTP here, which uses 250 to give values and
OK responses.  A 259 response type would probably be better.
I'm not sure I believe this part.
Tor's configuration system assumes that there is a "null" or "default"
value for every option that is distinct from setting the option to a
particular value.
 [...]
Sadly, this wouldn't work.  This is signed data; you can't add
whitespace willy-nilly. You would have to say:
     C: POSTDESCRIPTOR \
     C: router foobar 1.2.3.4 9001 0 9030\
     C: more desciptor data\
     C: even more desciptor data\
     C: last line of descriptor
     S: 250 OK
Hm.  I wish I had a better idea of what I wanted to do here.  My
current inclination is to stay with the current system as "simple
enough", but I wouldn't mind sanding out some of the corner cases.

@_date: 2005-06-09 14:36:01
@_author: Nick Mathewson 
@_subject: Why TOR Operators SHOULD always sniff their exit traffic... 
[Please forgive me if I sound like an ass below.]
Guys, could we please be a bit more polite on the list?  This isn't
alt.privacy.anon-server.  Let's start applying the principle of
charity, okay?  Chris is not stupid.  If you are who I suspect you may
be, you aren't stupid either.
 [...]
I don't believe that this is what Chris was saying.  Your response
would be reasonable if he had said "don't worry about hostile exit
nodes because they would be breaking the law."  Sure, that would be
stupid advice, but that's not what he said.  Instead, he said
something like "don't be a hostile exit node; eavesdropping on exit
node traffic may be against the law and may expose you to additional
liability for what you transport."  IMO, that's good advice.  (Yes, I
know, in your opinion, that's bad advice.  But it is advice about what
server ops should do, not about how clients should get anonymity.)
An analogy.  Chris has said "Don't steal from people's cars; it would
be illegal."  You have replied with "You must lock your car and not
leave valuables in it; laws are not enough to protect you."  You are
both right, but your response does not invalidate his statement.
Chris works at EFF.  Chris spends all day talking with some of the
best lawyers I know.  Even if you are, say, the computer security
chief of a law office or another organization that needs to deal with
lawyers a lot, I would be quite surprised if you have received *more*
or *better* legal advice about your Tor node than he has about his, or
if the lawyers you spoke to understand Tor as well as those Chris
works with.
 [...]
There's a difference between these propositions:
   * All jerks will announce themselves as jerks.
   * There is no need to defend ourselves against unannounced jerks.
   * It is a good idea to limit the damage that known jerks can do.
   * When somebody announces, "I intend to be a jerk", it is a good idea
     to limit the damage he can do.
I don't think anyone here is naive enough to believe either of the
first two propositions.  Contrariwise, there is much to be said for
the second two.
Your anonymity set has just gotten very small.  :)
Um.  Is there any advice that you can give us about how to improve
Tor, or how to improve the advice we give people about how to use Tor,
on the basis of your research?  Even knowing more about which attacks
work (or don't work) would help us resist them better.
Feel free to email the developers privately, if you'd prefer.
Chris called your advice stupid, not you.  Even if he's right, you
would not be the first smart person to give people a bad impression of
the law on the Internet.  And despite what you say your lawyer has
told you, enough lawyers have told me otherwise that I do not think
that I would feel safe doing what you say you are doing.
 [...]
Your approach is kinda pointless here wrt the Tor developers.  We
*know* that hostile nodes are possible and probably existent.  We
don't deny this, even though we encourage people to be honest.  If we
haven't addressed a particular threat, it isn't because of laziness or
complacency -- it's because we don't know about the threat, or don't
know how to fix it.  If you can tell us about specific threats we
don't know about, or ways to overcome threats that we *do* know about,
Of course, if you think that the Tor developers have gotten lazy or
complacent, you could start by telling us so.
your friend,

@_date: 2005-03-22 13:01:20
@_author: Nick Mathewson 
@_subject: Accounting and Hibernation Features 
Also, the manual should be included in the windows tor package in a
file called "tor-reference.html"

@_date: 2005-03-25 16:00:53
@_author: Nick Mathewson 
@_subject: Question about torrc in Windows 
Also, the installer should have put a shortcut in the StartMenu that
will open the file in Notepad.

@_date: 2005-03-26 19:58:20
@_author: Nick Mathewson 
@_subject: (FWD) OS/X Installer 
Good idea!  You should write an entry for the Wiki faq at
   (It isn't Tor's job to filter HTTP headers; Privoxy does that.  The
privoxy file that ships with Tor on OS X is the default, modified
minimally to use Tor.  If you want to submit recipes to make Privoxy
do what you want, that would be great too.)

@_date: 2005-03-26 20:10:36
@_author: Nick Mathewson 
@_subject: (FWD) OS/X Installer 
[...]
Right now, the OS X installer sticks all of the Tor stuff in
symlinks from /usr/bin, /usr/man, and /var/log as appropriate.  This
is, I'm told, how OS X expects me to do stuff.  When I was installing
stuff into /usr, Mac people told me that was wrong, and that packages
shouldn't do that.
I've changed the default torrc.sample to mention where to find torrc
on Mac OS X.  If there's anything else specific that we should change,
please let us know, especially if you can point to specific places in
the documentation that should be different, or files that we are
putting in the wrong place.
Thanks for your help,

@_date: 2005-03-01 17:14:19
@_author: Nick Mathewson 
@_subject: "cracks" via tor 
[...]
I'm not a lawyer, but I think your questions may be answered in the
Legal FAQ written by lawyers at the EFF.  It lives at:

@_date: 2005-03-04 18:37:01
@_author: Nick Mathewson 
@_subject: exit node only server 
[...]
Hm. This is not a bad idea.  (Or at least, if it is a bad idea, it is
not obviously a bad idea.)  Roger and I have discussed this in the
past, but haven't yet gotten around to it.
One issue is that we would need to change the client code so that
they could recognize exit-only servers: as it stands, clients would
try to use them as middleman servers and get confused.  But if we're
changing client code anyway, we could just have *clients* do the right
thing, and preferentially avoid using exits at intermediate positions
on their circuits.  Clients would have an incentive to do this anyway,
since middleman nodes (as you say) are less likely to be overloaded,
as things now stand on the network.
Of course, there could be some anonymity issues here.  None leap right
to mind, but hey.
Anyway, in the long term, we need better solutions to incentive
problems. I'll drop another message about that in a second...

@_date: 2005-03-04 19:12:14
@_author: Nick Mathewson 
@_subject: exit node only server 
Everybody is confused.  If you *aren't* confused about how to create
incentive structures for volunteer-operated anonymity networks, you
should let us know what the answer is.  :)
As noted by Chris, we are indeed hoping to more Tor to a more
decentralized discovery model.  We have to, otherwise user demand will
outstrip network capacity.  Chris is correct that a Bittorent-style
centralized t-f-t tracker would be problematical; it would present a
single point of failure, and create fairly bad anonymity problems by
potentially providing an adversary with a centralized view of how many
people have delivered how many bytes.  A localized mechanism may
have more hope, at some loss of efficiency--though it could still have
anonymity problems.
Just because something isn't in the codebase today, you shouldn't
assume that we have examined it carefully and determined it to be
unnecessary or ineffective---more likely, we have been very busy with
other things to keep the network up, running, happy, and as efficient
and featureful as we can make it.  (Though there *is* some stuff that
isn't there because we don't want it, so don't assume in the other
direction either.)
 [...Skipping discussion of human nature, t-f-t, routing versus
   swarming downloads, etc...]
Well, you could look at section 5 of our "Challenges" paper at
 .  It's
not been published yet, and there's as much speculation as anything
else, but hey, it could be a start.
Of course, it suffers from the same weakness as all of the other
discussions on this mailing list in that it doesn't actually propose a
design.  It sketches out the details of the outline of the shadow of a
design, however, which is better than no design at all.
The great thing about designs is that it's way easier to talk sensibly
about "Will this proposal work, and can it be fixed?" than it is to
talk about "Will any proposal containing this feature work?".
But yeah--don't worry if you think we might be idiots who aren't
thinking about incentives at all.  We are indeed thinking about
incentives.  We know they're important.  Honest.

@_date: 2005-03-04 19:21:12
@_author: Nick Mathewson 
@_subject: exit node only server 
As has been mentioned, such a system assume a lower bound of service
that servers provide to everybody.  That way, low-bandwidth users, or
users who can't run Tor nodes, still get some service.  (More users
will help provide more anonymity against many adversaries, after all.
True, they'd get bad bandwidth --- but low-bandwidth users don't need
much bandwidth, and the choice may be between either creating
incentives for server operators by providing worse-but-existent
service to non-servers, or having too few servers, so nobody gets
Of course, this isn't tit-for-tat anymore (at least, not the tit-for-
tat that Rapoport came up with and Axelrod helped investigate).  In
straight tit-for-tat, you respond with exactly the behavior you saw in
the round immediately before the present round.  I think that most
people who are using the term here mean it in some more vague and
extended sense.  (i.e., 'Y'know, like what Bittorrent does, or
something, except localized, and with bandwidth relayed instead of
chunks uploaded, but quantized somehow, and not broadcast, and...')
For more info, you might want to see the "Challenged" paper linked to
in my last email.

@_date: 2005-03-02 16:32:19
@_author: Nick Mathewson 
@_subject: exit node only server 
Interesting question!  Right now, you can set up a Tor server that is
*never* used as an exit node (i.e., a middleman server), but there
isn't any supported way to make sure that your server is *only* used
as an exit node.
Why would you want to do this?

@_date: 2005-11-16 00:48:52
@_author: Nick Mathewson 
@_subject: For those using Tor with windows 
Hi, and thanks for writing this program.  A few questions and
  1. Do you plan on releasing the source code?  Nobody should trust a
     security application if it can't be built from source.
  2. Why so large?  The nodeblockv11.rar file is over 3 MB in size; by
     way of comparison, the windows Tor installer itself is only 968K.
  3. It looks like you're distributing wget in binary form without
     including the source or the offer you received to get the source;
     unless I'm missing something, this is in violation of clause 3 of
     the GPL.
thanks again,

@_date: 2005-11-16 22:30:08
@_author: Nick Mathewson 
@_subject: Error message? 
1. Can you say more about this restart?
2. Can you send me your torrc file?
3. Can you verify that you're actually running the torrc file that you
   think you are?  (Add a bogus line, say, and make sure you get an
   error message.)

@_date: 2005-11-16 22:54:41
@_author: Nick Mathewson 
@_subject: Marketing Tor (Was Re: For those using Tor with windows) 
Legally: I'm not a lawyer, but as far as I know nothing in the Tor license
would keep you from doing this.  (You mention the GPL below, but
that's irrelevant: Tor isn't licensed under the GPL.  When I mentioned
the GPL above, I was talking above about a program called wget.)
Ethically: I think it's a little bit dubious to re-sell bandwidth that
others are giving away for free and contribute nothing in return.
Strategically: It's self-defeating.  If the service remains small, it
probably won't be very profitable. If it becomes large, then it will
strain the network, performance will degrade, and their users will
leave.  Of course, there's a tragedy-of-the-commons scenario here,
where everybody has it in their interest to extract more than they
contribute, but our design has this problem anyway. (See summary in
3.3. of  .)
Well, I'd disagree.  It's indeed abhorrent to steal people's work
without permission, but it seems a bit silly to call people evil for
doing with Tor what the software developers have explicitly given them
permission to do.  The Tor license does not restrict our software from
being used as part of proprietary commercial products, so long as the
conditions are met.
This isn't to say that anything goes, of course.  The license is
pretty explicit: No taking our names off it, no taking the license off
it, no pretending we endorse you.  I'd also call it slimy to release
less-secure variants and pretend they're as good, or not to
acknowledge publicly where the software came from.  (Releasing a
proprietary version would also be bad PR IMO.  On the one hand, only
clueless people would trust it.  On the other hand, why bother
building off Tor if you're only trying to sell to clueless customers?
Give them a one-hop proxy with a trustworthy-looking model on the box.)

@_date: 2005-11-19 13:22:50
@_author: Nick Mathewson 
@_subject: Hey guys, here is another (great?) idea 
From a technical perspective, it would also fail.  Right now, our
directory-based server discovery system requires all clients to know
about all servers.  This works right now for hundreds of servers; for
hundreds of thousands, it would fail.  We need more architectural work
before we can support a P2P model.
(Yes, we know about existing p2p models, but the problem isn't
trivial.  It's easy to do bad things to anonymity by partitioning
client knowledge, or worse, isolating clients in adversary-targetable

@_date: 2005-11-19 13:56:15
@_author: Nick Mathewson 
@_subject: Hey guys, here is another (great?) idea 
[reformatted to fix top-post.]
 [...]
DNS maps names to values, and doesn't worry about vulenrabilities
resulting from adversary knowing which clients have learned which
values.  That's not our problem.  Our problem is finding a way for
clients to learn about servers and build paths through those servers
so that if you (an adversary) see a client, and you control a
directory cache, and you control some servers, and you see part of the
client's path, you can't deduce with a better-than-chance probability
whether the path was generated by the client.
Section 5.2 discusses this in more detail.  I cannot possibly recommend this paper
highly enough to people who want to help with design

@_date: 2005-11-19 14:49:37
@_author: Nick Mathewson 
@_subject: Hey guys, here is another (great?) idea 
[reformatted to fix top-post.]
  [...]
Ah. I was thrown off by the fact that you said "DNS", not "BGP" or
something.  DNS has nothing to do with how routers learn paths on the
Internet, so I didn't know you were talking about how routers learn
paths on the Internet.
Once again, BGP solves a very different problem: how to make sure that
each router knows the best way to send an IP packet closer to where it
is supposed to go.  It doesn't concern itself with the anonymity
questions I mention above in the slightest.
Trivial example: In Internet routing, you typically trust the first
router you use to route your packets.  But in Tor, if you trust the
first router to pick your path, or give you a list of routers, you are
completely vulnerable to a compromised first router.  There might be
ways around this problem (and the other problems) but they need design
and analysis.

@_date: 2005-11-25 20:30:11
@_author: Nick Mathewson 
@_subject: Has anybody seen the message, "BUG: conn->on_circuit==NULL, but ..." ? 
Hi, all.
Has anybody ever seen the log message, "BUG: conn->on_circuit==NULL,
but there was in fact a circuit there." ?
I suspect that, if it happens, it would happen on busy exit servers.
My guess is that it never happens at all, since if it did, we would be
seeing corruption under other circumstances; if this is so, then I can
eliminate a redundant check and make the code a bit faster.

@_date: 2005-11-08 17:24:52
@_author: Nick Mathewson 
@_subject: Hacker strikes through student's router 
[...]
For the record, Tor developers (and many at the EFF) are indeed of
many reasons people have claimed that developing anonymity is bad.  We
think about them a lot, and right now, we don't think that they're
correct. In fact, we discuss many of them in the abuse faq, the main
faq, and the "Challenges" paper.
In case anybody cares.
(This is not to blame Prof. Merkle; there's no telling what he was
saying in context, and what information he was going on.)

@_date: 2005-11-09 15:13:44
@_author: Nick Mathewson 
@_subject: Hacker strikes through student's router 
You could make one tomorrow, but it would be useless, since clients
wouldn't know how to handle its restrictions automatically.
Moreover, if you were doing this in order to try to keep people from
doing bad stuff over your server, you'd be sorely disappointed: the
world has GET-based exploits as well as POST-based exploits.
Finally, you'd set a pretty awful precedent if you did this without
careful planning: suppose you decide to handle only GET from HTTP, and
somebody else decides to also handle POST to a limited number of
sites, and somebody else decides to normalize requests, all without
giving clients an idea of what to expect, we'll be in a world of
(I hate to think what would happen to protocols more finicky than

@_date: 2005-11-09 15:21:52
@_author: Nick Mathewson 
@_subject: Hacker strikes through student's router 
[...]
Again, you might want to read the "challenges" paper.
   It cites other work.
Also, nearly all of the debate from the old "Crypto Wars" is
applicable to the present situation IMO.  Also, look for the term
"revocable anonymity" for favorable (!) views concerning building back
doors into anonymity systems, and debates about those views.
I think you can answer the question of what the paper says yourself by
reading the paper.
And the abuse faq.
And the main faq.
[sarcasm begins]
What do you think? As you probably know, before we started working on
Tor, there was almost no such thing as computer crime or abuse.
Everybody could be easily tracked down by their IP addresses, so
anybody who tried to get away with naughtiness had to deal with their
ISP and their local police almost immediately.
There was practically no fraud, no defacement, no flooding, no abuse,
no illicit access, no data theft, no harassment, no fraud, no nothing.
[sarcasm ends]
I don't think these are "impossible questions"; I think they're
answerable with a little thought, a little history, and a little
technical knowledge.

@_date: 2005-11-09 16:38:24
@_author: Nick Mathewson 
@_subject: Hacker strikes through student's router 
[...]
Sorry there; I should have stopped typing earlier.
The thing that bothered me was that I pointed you to a paper and two
FAQs, and rather than reading those FAQs and the relevant parts of
that paper, you instead answered based on what you thought the paper
probably said, and asked questions that were discussed in those FAQs.
Nevertheless, my response was not in tune with the level of discourse
we should promote on this list; I'll try to do better in the future.

@_date: 2005-10-06 14:51:09
@_author: Nick Mathewson 
@_subject: TOR in Java? 
I think your idea is a fine one for somebody's spare time; we always
need more implementations for the Tor protocol, and Java is a popular
choice these days.  You might want to start with the code from the
Java Anon Proxy people; I don't know their current status here, but
for a while, they had a working Tor *client* written in Java.  Of
course, a server is significantly more complicated, so there would be
a lot more work.
As for the performance issue: you are completely wrong about Tor
servers not needing CPU; at reasonable bandwidth, the requirements are
high.  Fortunately, most of the CPU is used for AES, DH, and RSA, all
of which any sane implementation will implement in native code, so one
might stand a chance of having a compatible implementation of the Tor
protocol written in a less performance critical language.
In other words:  if you want to clone Tor in Java, feel free!  We look
forward to your work.
Note, however, that I keep talking about "compatible implementations"
here.  Tor is 49 thousand lines right now[1], and we're trying to
strengthen incrementally it all the time.  Throwing out the
implementation that we've been working on for the last four years and
starting again from scratch is not likely to work for us.
As for the rest of this thread: language choice is a classical
bike-shed problem[2].  Please, tread lightly, and consider whether
what you're saying needs to be said.  If you're worried about Java:
there's no risk we'll switch the main Tor implementation to it in the
foreseeable future.  If you want Java: great, get some programmers
together and bang out an implementation.
[1] Tor has about 37.6 klines of code, and 11.4 klines of comments.
[2] On bikesheds:

@_date: 2005-09-26 13:37:47
@_author: Nick Mathewson 
@_subject: Tor and port 80 
For directory purposes, yes.  You need to make your web browser
redirect all requests that start with /tor to the Tor server's
directory port.
For OR purposes, it's not likely to be easy.  You'd need to write a
proxy that would check initial connections to see whether they look
like SSL or HTTP, redirecting them to Tor in the first case and your
browser in the second.
The method you describe is unlikely to achieve this purpose, assuming
that the "authorities" are smart.  If the server is a Tor server,
you can find this out by trying to use Tor with it, and seeing whether
it answers you.
Arrakis: when somebody sends a message to or-talk, hundreds of people
receive it.  If every one of them who *didn't* know the answer said "I
have no clue", it would be impossible to use the list.  I'm glad
you want to help out, but please realize that it's not helpful to tell
everybody when you don't know the answer to their question.

@_date: 2005-09-27 15:29:28
@_author: Nick Mathewson 
@_subject: Hello directly from Jimbo at Wikipedia 
[...]
Right on.
There are reasonable people working on both of these projects, but as
you know, there will always be unreasonable people on both sides.
Please realize that the contributing Tor developers, at least, don't
share the "Jimbo==Big Brother!!!1!" view: we know that you aren't
anti-privacy, any more than we're pro-abuse.
Hey folks -- the reason that Wikipedia (and other services) use IPs to
block users is not stupidity, laziness, or ignorance.  People use
IP-based blocking because it limits abuse better than no blocking at
all.  Blocking IPs is not saying, "I hate privacy, I think IPs do and
should map 1:1 to human beings, and abuse is an ISP problem; and Tor
doesn't exist."  It's saying, "I can't deal with the abuse I'd see if
I didn't block some IPs, and while IP blocking is imperfect, it's
about as good as any other scheme I have had the time so far to
People don't block IPs because they think IPs are people, or because
they've never heard of NAT.  They block IPs because IPv4 addresses are
(for most people, at the moment, to a first approximation) a somewhat
costly{1} resource.  When they block Bob's IP, the theory is that they
force him spend the effort to move to a new IP before he can abuse
their service again.{2}
So therefore, this isn't about identity; this is about economics.
Replacing IP addresses with a different kind of identifier won't work
unless that identifier takes enough human effort to renew.  Free
website accounts accounts don't usually have this property.  Valid
credit card numbers (as Geoff notes) do indeed have this property, but
not everybody has one.  Email addresses in some domains (
have this property; email addresses in other domains (
These resources don't need to be perfect, unstealable, or uncloneable!
The goal is to reduce abuse; making abuse impossible is not a
Similarly, these resources don't need to be privacy-preserving, or
unlinked from individuals.  Using blind-signature based credential{3}
systems, it's possible to use a sensitive, identifying resource (like
an  address or a credit card or a phone number) to
bootstrap a pseudonymous resource.  Now that the first blind signature
patents have started to expire, this approach is more workable than it
would have been before.  I think that approaches like this are pretty
promising, but need a lot of work to be practical.
Such a scheme wouldn't need to be built into Tor.  It could pretty
easily be a system-independent architecture that could work with
any number of privacy-enhancing layers.
Jimmy and others: do you think I'm on the right track above?  I'm
trying to design a system sorta based on the above principles, but as
you can see, there is a lot of fuzziness.
To everybody in this discussion: here are some things that might make
you feel better in the short run, but which will ultimately not help.
  - Trying to convince Jimbo that privacy is good, or that reducing
    false positives would serve wikipedia's goal of openness.  He
    knows.
  - Trying to convince Tor developers that abuse is bad, or that
    reducing abuse would server Tor's goal of widespread acceptance.
    We know.
  - Trying to convince Tor developers to subvert services attempts to
    block Tor exit connections{4} based on IPs.  We won't; it would be
    wrong.
  - Trying to convince Wikipedia operators that privacy is evil _per
    se_, and should be thwarted regardless of potential for abuse in
    particular instances.  I doubt they'd buy it; it doesn't look like
    Jimbo will.
  - Trying to convince the world that some wikipedians have an unnuanced
    view of Tor and anonymity and false-positives.  We know.
  - Trying to convince the world that some Tor operators and users have an
    unnuanced view of IP blocking and abuse.  We know.
Here are some things that would be harder, but which would probably be
  - Try to develop better understanding of why and whether abuse prevention
    mechanism, even the ones you think are crappy, work in practice.
  - If a hypothetical abuse prevention mechanism wouldn't work,
    explain why not.
  - When it looks like somebody is saying something utterly stupid or
    insane, try to figure out why, from their point of view, it might
    seem reasonable to say such a thing.{5}
  - Come up with workable ways to prevent abuse that don't damage
    privacy or preclude anonymizing layers like Tor.
  - Implement those models, and try them out.
There are probably other helpful things, too.
{1} Costly in effort or in cash.
{2} Yes, the theory breaks down.  Some IPs (like those of Tor servers
    and other, less privacy-focused, proxies) aren't costly enough to
    change, so services are tempted to restrict them out of hand, or
    give them some kind of probationary status.  Other IPs (like those
    use by large NATed apartment buildings and ISPs) are too costly to
    change, and are shared by many users, so services that care about
    availability have to play games with temporary blocks and the
    like.
{3}  has a decent
    introduction.
{4} We're okay with subverting entry-blocks.  This isn't hypocrisy;
    this is because entry blocks are fundamentally different.  When
    Alice connects to Tor to connect to Bob, an exit block means that
    Bob doesn't want anonymous connections, whereas an entry block
    means that somebody doesn't want Alice to have privacy.  Entry
    blocking subverts Alice's self-determination, whereas exit
    blocking on Bob's part *is* self-determination, even if we don't
    like it.
{5}

@_date: 2005-09-27 16:56:01
@_author: Nick Mathewson 
@_subject: Wikipedia & Tor 
[...]
Allow me to clarify this point, again.  My apologies if you read my
last post on this.
Requiring anonymous users to log on to wikipedia is not a privacy
problem per se; if Alice anonymously creates an account on Wikipedia
named "xyzzy00", then Alice is still untraceable to her new
(pseudonymous) account.  If she needs her activities to be unlinked to
each other, she can get unlinkability by creating multiple accounts
(perhaps because "xyzzy00" edits articles about Alice's field of
academic expertise, whereas "plover11" edits articles about the latest
research on Alice's embarrassing disease).
The problem, of course, is that requiring accounts is not in itself
helpful; if accounts are unlinkable to each other, then an abusive
user could keep creating new accounts ad infinitum.
CAPTCHAs and other reverse turing tests are probably enough to
prevent automated attacks, but a lot of abuse, I'm told, is users
manually vandalizing pages.  This isn't just for wikipedia, either:
you don't need a bot to be really annoying on an IRC network.

@_date: 2005-09-27 18:13:25
@_author: Nick Mathewson 
@_subject: Hello directly from Jimbo at Wikipedia 
[...]
What about logins for new users on Tor only?  That is, suppose you
allowed non-logged-in posts, and allowed posts with Tor, but not
non-logged-in posts with Tor.  Would that also be a nonstarter?
 [...]
Something kind of like your proposal might work, but it has problems.
For reference, the proposal is (verbatim):
    Here is a simple solution to the problem of Tor users being unable to
    edit Wikipedia
    trusted user -> tor cloud -> authentication server -> trusted tor
    cloud -> wikipedia
    untrusted user -> tor cloud -> authentication server -> untrusted tor
    cloud -> no wikipedia
    Simple.
I'm sure you realize that there's a lot of gray area in this design,
so let me try to fill some of it in, and I'll comment as I go.
Clearly, users are authenticating to the authentication service using
some kind of pseudonymous mechanism, right?  That is, if Alice tells
the auth server, "I'm Alice, here's a password!", there's no point in
having a Tor cloud between Alice and the authentication server.  So
I'm assuming that Alice tells the authserver "I'm user999, here's a
password!"  But if "user999" isn't linkable to Alice, how do you stop
an abusive user from creating thousands of accounts and abusing them
one by one?
Second, the authentication server needs to be pretty trusted, but it
also needs to be able to relay all "trusted" users' bandwidth.  That
introduces a bottleneck into the network where none is needed.
(There's a similar bottleneck in the "trusted cloud" concept.)
Third, how do users become trusted or untrusted?  Who handles abuse
Fourth, the design seems to envision only a single authentication
server, and ties the authentication server into the Tor network
I think you can solve most of the above problems with the architecture
I discussed earlier on this thread.  It would look something like:
Step 1:
  User <-> Authentication server
  (Establish a blinded credential, perhaps rate-limited by scarce IPs
  or email addrs or something.)
Step 2:
  User -> Tor network -> Authentication server
  (Prove to authentication server that user has a given credential.
  Get a short-lived token for use with wikipedia)
Step 3:
  User -> Tor network -> wikipedia
  (User proves to wikipedia, "hey, I've got a recent credential for
  pseudonym X from authentication server Y."  Wikipedia decides
  whether it's banned nym X.)
The weak point here is the transition between step 2 and step 3.
Unlike your design, this doesn't fit exactly into mediawiki's existing
"these IPs are good; these IPs are blocked" implementation, so more
code would be needed.  Other interfaces could be possible, of course.
It does have the advantages, though, that the authentication server's
bandwidth needs are comparatively modest, that it's hard for bots and
jerks to create boundless numbers of accounts, that wikipedia can make
its own decisions about which users to ban, and that the
authentication service remains independent of the Tor network, so that
people can run different servers with different policies.
How does this sound to you?

@_date: 2005-09-27 23:13:31
@_author: Nick Mathewson 
@_subject: Hello directly from Jimbo at Wikipedia 
Right.  There are plenty of holes in this approach.  Still, it's
better than the current "no Tor IPs at all for editing" approach, and
a pretty good temporary measure for certain problems.
For example, it would solve the problem of somebody who is running a
Tor server on their home IP, who wants to edit Wikipedia themself, and
doesn't care about their own anonymity on Wikipedia.  This is a source
of a large number of the complaints we receive about Wikipedia.
It would also solve the problem of somebody who's using Tor to get
past an overly restrictive firewall where they spend much but not all
of their time.
Actually, we're not in any better position than you are.  We don't
know who our userbase is either; we certainly don't have identities
for them, and we really don't want to track their identities or
trustworthiness, for a number of reasons:
 - If it were easy for us to tell what individual users were doing
   with Tor, it would be easy for *everybody* tell what individual
   users were doing.  I wish we could separate good users from bad
   without seeing what they were doing, but without linking them to
   the actual contents of their communication, it isn't really
   possible.
 - We don't want people to have to trust us with their secrets.  It
   would make us a great target for malicious hackers and legal
   attacks.
 - Our standard of trust is not likely to be anyone else's.
 - We are not a community service; our operators don't know our users,
   and our users don't know each other, except when they choose to
   communicate on forums like this one.  This is necessary for
   privacy: if the community knows who's who on the network, so does
   the Chinese government.
On the other hand, if there were an authentication service that gave
you pseudonyms for Tor users who wanted pseudonyms, you could tell
which pseudonyms contributed well, and which were jerks, and which
were nonentities.
We can't allocate servers to different places; operators need to
decide what kind of servers they want to run.  I worry that many would
decide that running a "trusted users only" server was not what they
wanted to do.
Yes, I agree.
I'm in complete agreement that perfection isn't needed.  We just need
to come up with a flawed system less flawed than what we have today.
Exactly!  Of course, this token wouldn't be from Tor per se; it would
be from a separate authentication service.
(I'd want this to be separate because, frankly, these systems have
historically been hard, and if we screw it up, I'd rather not have a
screwed-up system bolted to the insides of the Tor codebase.  Plus,
there are other anonymity projects out there, and there will probably
be more in the future.  If we get this right, there's no reason that
you and they should have to go through this dance again to reinvent
the wheel. Finally, there will probably be demand for more than one
policy, which would suggest more than one auth service.)
Sounds good to me.  What are the next steps on working on designs like
this?  I'd like to maximize the chance that a system like this gets
built in such a way that our users and Wikipedia are all happy with it
when it's done.
In the short term, what are the next steps in allowing
Wikipedia-trusted logged-in users to edit Wikipedia over Tor?
We all have limited time and resources here, but I'd like to devote
some of mine into getting this situation improved.
many thanks for your time,

@_date: 2005-09-28 05:03:30
@_author: Nick Mathewson 
@_subject: Hello directly from Jimbo at Wikipedia 
[...]
Hashcash is often considered, but commonly dismissed, because it
limits identities based on the wrong resource: computers.
If you haven't read the paper "'Proof-of-work' Proves Not To Work" by
Ben Laurie and Richard Clayton, I recommend it highly.  See
 .  It mostly
discusses why hashcash can't prevent spam, but the arguments would
seem to apply to wikipedia editing as well.
 [...]
Sorry, but you've stumbled a personal crusade of mine.
The word is pseudonymous, not pseudo-anonymous.  And the difference is
importatant.  "Pseudonymous" means "using false names," like calling
yourself Batman instead of Bruce Wayne.  "Anonymous" means "without a
name," like writing "The Joker will pay for his crimes" and not
signing it.  "Pseudo-anonymous" isn't a real word, but if it were, it
would mean "falsely anonymous", like the bank robber who disguised
himself by wearing a motorcycle helmet with his name written on the
As one of the designers, I'd like to weigh in.  Tor provides
anonymity, but we've never opposed people who wanted to use an
anonymous system to bootstrap per-service or cross-service
We will never, of course, alter Tor to make people have pseudonyms.
But letting using pseudonyms is not against our overarching goals.
The overarching goals are privacy and usability.{2}
I don't see any iterable (that is, awful) partitioning attacks here.
Assume a network where some users have pseudonyms and some don't.
Assume that pseudonyms are first obtained through a blinded{3}
process, so that an attacker can't tell which user has which
Assume that the attacker is watching all authentication services
(since this is probably the best point for these attacks).  The
attacker could tell when users create new pseudonyms, and when
pseudonymous users are active.  From this info, the attacker could
rule out some users as possible owners of some pseudonyms, but that's
about it.  Correlation and intersection attacks are unlikely to work
unless the attacker is watching the user as well as the auth server,
and that's outside our threat model.
Right.  I suspect that this is one of those social engineering
problems that we won't solve except by trying things out and seeing
whether they work.
{1} There are all other kinds of great terms in the field.  For
    example, "allonymous" is using a name belonging to someone else,
    like if the Joker writes a letter and signs it "Batman."  Oddly,
    there is no classical term for using one's given name.
{2} If you care about privacy and not usability, I recommend DC nets.
    If you care about usability and not privacy, I recommend turning
    Tor off.
{3} Again see

@_date: 2005-09-29 00:17:07
@_author: Nick Mathewson 
@_subject: [roy@rant-central.com: Re: [arma@mit.edu: Re: Wikipedia & Tor]] 
Jimmy, David, I suggest that you might want stop answering each other
directly.  It is clear that at least one of you is unable to explain
himself to the other in a way that he can understand.  There are more
productive matters to discuss than what anonymity means in common
 [...]
 [...]
 [...]
So if I establish authentication with you using one identity
("user91010") while keeping my actual name ("Nick Mathewson") a
secret, I could have both an established identification and an
unacknowledged name.{1}
Similarly, you could have an anonymous credential, which would allow
you to prove that you belong to a group of people ("allowed to post on
or-talk"), while keeping your actual identity ("David Benfell") a
I assume that you're not just ignoring everybody else and replying
only to what Jimmy says, right?  There have been other posts here
explaining why pseudonymity and Tor are not at odds, so long as
pseudonymity is user selected.
 [...] Wikipedia has user accounts and IP-based blocking.  That's a kind of
authentication.  Wikipedia does not require you to use a user account
to edit pages, and does not do much to ensure that user accounts
belong to real people.  That's a lack of authentication.
It's like how Tor blocks some highly-abusable services, like SMTP on
port 25, but doesn't do content filtering to try to hunt for abusive
behavior on exiting streams.  We filter out some abuse, but we can't
filter out all abuse without turning off the network.  An anti-Tor
rhetorician could say, "You filter abuse, but you don't filter abuse!"
But what would that prove?
Look, if don't want to spend the time to learn how Wikipedia works,
that's fine.  But there's no secret here to how it works, and if
there's any way to move this discussion forward, it will involve
people learning how it works.
These people do not need to be you, but they will be ones who are
helpful in the long run.
{1} This case is more commonly known, in the literature, as
    pseudonymous communication than anonymous communication.  Then
    again, if you're going to invoke dictionaries in a technical
    discussion, anonymity becomes a very broad term.
hope this helps,

@_date: 2005-09-29 00:38:01
@_author: Nick Mathewson 
@_subject: [roy@rant-central.com: Re: [arma@mit.edu: Re: Wikipedia & Tor]] 
Hi again, Jimmy!
 [...]
I think I've identified one of the reasons some people here are disturbed
about your suggestions.  When you talk about changing the Tor
architecture, they think you mean changes to Tor that would require
all users to have pseudonyms, or ostracize the users who didn't.  When
you say "Tor should do X," they think you mean "the Tor software
should do X".{1}
If that were what you meant, they would be right to be concerned.
Pseudonymity is wrong for many users.  Complicating the core Tor
implementation would be bad.
But these aren't your goals, if I understand correctly.  Wikipedia
doesn't ultimately care how Tor is implemented, or what it contains,
so long as it is significantly less effective as a tool for Wikipedia
abuse.  Yes?
This could be achieved, as some people fear, through modifying the
core of Tor.  But that isn't the only way to change matters.  As
discussed, introducing a separate pseudonymous authentication service
(perhaps even an anonymous credential service, if we can find a way to
do this without patent infringement) would serve just as well, and
require no modifications to the Tor code.  Users who didn't want to
use such a service would be no worse off than they are today.  Users
who wanted to use Tor and edit Wikipedia at the same time could decide
whether the implications of such a service were acceptable to them.
{1} To be clear, I think that it's more accurate to talk about changes
    to the User/Tor/Wikipedia interaction, and to suggest a need for
    action by the Tor project and its supporters, than to talk about a
    need for changes in Tor's architecture, and a need for action by
    Tor.

@_date: 2005-09-05 02:45:41
@_author: Nick Mathewson 
@_subject: selecting Node lists by  criteria? 
Not as Tor is currently implemented.  As you note above, implementing
this feature would require us to build a general-purpose expression
language into Tor.  That would be a neat trick, but kind of wasteful:
the world already has hundreds of decent programming languages, and
building a special purpose one wouldn't do much good.
Also, it wouldn't be enough.  If we implemented what you describe
above, people would want to specify rules for node selection that
depended on factors other than individual node position within the
circuit.  You'd get reference to other nodes ("Choose exit nodes in
the US if the entry node is not in the US"), references to desired
stream targets ("Choose exit node in same country as target website"),
references to other current circuits ("Choose exit node different from
any currently in use") and references to older circuits ("Choose the
same exit node we used to connect to this website last time").  And
What we've done instead is make it pretty easy to override Tor's
circuit building strategy with an external controller program.
Interested programmers should check out the documentation, interface
libraries, and demo code at
     (For another challenge, you'd have the problem that there isn't a
really reliable way to map IP to country.  Also, restricting nodes by
country can be insufficient.  Suppose that I wanted to restrict France
(for example) from interfering with my connection to my entry node.
It's not enough to choose an entry node outside of France!  I also
need to make sure that the connection to my entry node doesn't pass
though France.  If I'm worried about legal attacks, I need to be
concerned about nodes whose owners and operators are in France,
regardless of where they themselves are located.  It can get pretty hard.)

@_date: 2006-04-28 14:30:34
@_author: Nick Mathewson 
@_subject: Mid-Latency [Re: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit)] 
[...]
I'd like to register a small objection: while (absent countermeasures)
correlation attacks work, it remains to be proven whether or not you
can improve security significantly while adding only a small,
tolerable, amount of padding and delay.  Research on high-latency
mix-nets seems to show that you can delay intersection attacks by
increasing latency variability and decreasing sender-frequency
variability; but nobody has done the numbers (yet, AFAIK) to tell
whether these techniques are useful on the low end of the latency
There are smart researchers with strong intuitions in either direction
on this; my intuition tells me that when so many clever people
disagree, more experimental results are needed.
Of course, nothing like this will go into Tor in the forseeable
future.  We have a strong design policy: "No Voodoo."  In other words,
we try not to add "security" features unless someone can demonstrate
that they actually improve security.
(Anybody interested in doing something like this as a research
project: first, check out the papers about traffic analysis on
 .  Many of the most 'obvious' ideas don't
work as well as you'd think they would; many of the recent
traffic-analysis techniques work better.)

@_date: 2006-04-28 14:35:16
@_author: Nick Mathewson 
@_subject: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit) 
[...]
Please, please, read the FAQ that Roger cited.  You don't need
alternating hops to do a correlation attack; you just need first and
Congratulations; you just invented high-latency mix-nets. :)
The problem is that nobody can prove that these "jumbling" techniques
do any good in resisting an attacker until you increase the delay to
the point where messages take a very long time to arrive.  When this
happens, you wind up with a very low number of users, so you don't get
much anonymity anyway.
You can find out more about the last 25 years of anonymity research at
 .

@_date: 2006-04-28 18:19:57
@_author: Nick Mathewson 
@_subject: Mid-Latency [Re: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit)] 
[Fixed topposting so conversation can flow.]
I think you misread me; I didn't say, "cover traffic never helps." I
said, "nobody knows whether a little bit of cover traffic helps much."
This defense you describe (usually called "constant-rate padding")
works if the users in question are always sending at the same rate and
at the same pattern.  But this means that if they *ever* want, say, a
10kpbs download, they must *constantly* generate 10kpbs worth of
traffic, which is quite expensive for the network to deal with.
Also, if their computers sometimes crash, they're in trouble, since
they're not "always on" any more: see
 .
Now, it is *possible* that there is a system like this where you can
get good effects with just a little big of extra cover traffic.  It is
also possible, however, that there isn't one.  Nobody has done the
experimentation and analysis to prove either way.

@_date: 2006-04-06 01:15:53
@_author: Nick Mathewson 
@_subject: wishlist 
Check out the volunteer page at
   The developer TODO is at

@_date: 2006-04-18 13:49:18
@_author: Nick Mathewson 
@_subject: slow client startup 
What version of Tor? Some had bugs related to this.
Also, logs would help.

@_date: 2006-04-18 14:18:39
@_author: Nick Mathewson 
@_subject: slow client startup 
Yeah, we fixed that bug since then.  You should probably upgrade.

@_date: 2006-04-22 10:35:48
@_author: Nick Mathewson 
@_subject: IP resolving 
This looks like you are trying to run a server, but your server can't
lookup it's own hostname in DNS.
And *this* looks like the only address Tor could find is a private
address on the 192.168.0.x private network.
To be a server, Tor needs to have a public IP and know about it.  You
should set your public Aadress in options->Address, and make sure port
forwarding is working.  See

@_date: 2006-08-16 15:40:20
@_author: Nick Mathewson 
@_subject: Tor bug?: AllowInvalidNodes 
It works. It just doesn't mean what you thought.
Sure it was.  "Unverified" and "Invalid" are the same concept:
'attested to as likely to be okay by the directory server.'  The only
that has changed is the name.
Why did we change the name?
Because "Verified" was a stupid name.  It implied that we had a good
way to go out and tell whether a node's operator was honest, upright,
and competent, and whether the node was physically secure and
If you were under the impression that we had a way to do this, sorry.
If you know a way to do this, please let us know.  We're all ears.
Please keep in mind that we haven't got much cash to do this with, and
what cash we do have, we'd rather spend on rent and food and
developing Tor.
Right, you're confirming that we were right to change "Verified" to
"Valid".  Apparently, you *did* think that "verified" was a magicial
stamp of good intentions.
Dude, we're not going to impose a worldwide server auditing system.
We're not going to visit server operators' houses.   Even if it did,
what would it prove?  Any organization could set up servers in a bunch
of its members' houses.  Are we supposed to do background checks?
ExcludeNodes *is* supposed to work.  If it doesn't, submit a bug
report.  Warning! You will need to describe *exactly* what you did,
and *exactly* what Tor did in response.  Logs will help. This is too
hard for many people.
frustratedly yrs,

@_date: 2006-08-16 18:00:47
@_author: Nick Mathewson 
@_subject: Tor bug?:  AllowInvalidNodes 
[...]
See Roger's message, which you quote below:
   > The exit.pl script that Geoff wrote and runs on Serifos uses the
   > phrase "not a valid Tor server" to mean "not a Tor server as far
   > as I know".
This is the serifos script that Roger is talking about.  It lists IP
addresses as "invalid" if they are not the IP of a tor server it
knows.  Some "valid" (according to the directory authorities) Tor
servers exit on IPs that are not the same as the IP they listen on.
This means that the IP they exit on will not appear on serifos's list
of valid nodes.
 [...]
Hm?  No, they both meant "attested to as likely to be ok".  In the old
days, directory authorities attested to servers as ok when they admins
told them to, and the admins told them to as they got mail claiming to
be from server admins.  We thought that this was a bad idea and
created a false sense of security.  Now, directory authorities attest
to servers as ok when the servers seem to be running, and the admins
have not told them to consider the servers suspicious.
The version 2 directory specification came into use during the Tor
0.1.1.x series, says:
    "Valid" -- a router is 'Valid' if it seems to have been running
    well for a while, and is running a version of Tor not known to be
    broken, and the directory authority has not blacklisted it as
    suspicious.
 [...]
Though that's what it meant in practice, that's not the interpretation
of "verified" that I'd have made.  Moreover, it's not IMO a useful
property to have.  Knowing who the adversary claims to be is only
effective against an adversary who can't or won't lie about who they
 [...]
It's not a bad idea.  Time permitting, a web-of-trust kind of system
might be neat to do.  Of course, we'd need think about what effect
this will have on route-based partitioning, and on possibly
discouraging operators from running servers if they need to meet other
operators face-to-face to do so.  And how hard is it really to foil a
face-to-face meeting?  These are neat questions.
(Please forgive us if someday we eventually start doing this, and pick
trust seeds in the UK from among people we already know and trust.
I'm sure you would do the same.)
Sorry, I don't think it ever said it was a magical stamp of good
intentions.  If we said that, that was a stupid thing for us to say,
and I'm glad we changed it.
ITYM "chiquita", but I am not a little girl.
Wow.  In my opinion, this would be tons of effort, would not pay for
itself, would turn operators away, would create a risk of information
leakage leading to identity theft, and would still be easy for
governments and nefarious organizations to subvert.  (Your security
model above seems based on the idea that the attacker can do things,
but wouldn't think it was worth the resources.  I worry that the
resource cost on server operators would also discourage them from
running good nodes.)
I realize that I could be wrong here; I'm just pointing out that this
is not a trivial idea, and it's not an obviously unalloyed win.
No, I'm afraid I didn't know that; I genuinely would like this feature
to work.  If vidalia isn't working for you, you could possibly try
editing your torrc?  No pressure; I don't mean for this to be any kind
of accusation or anything.  Just... if you want us to fix something
that seems to work for us, we need information on how it's broken.
My apologies for my unprovoked rudeness.  I like to think of free
software as a darwinian meritocracy rather than a dictatorship, and
would certainly hope that if Roger and I do a bad job as developers,
the community will realize this, try to talk us info doing something
sensible, fork Tor if we don't, and stop us from harming the world any
But seriously, we're trying to do our best here.

@_date: 2006-08-16 18:52:42
@_author: Nick Mathewson 
@_subject: subversion server ill? 
Good catch!  We just moved the repository to use HTTPS instead of
HTTP.  If you go to  instead of
 it will work fine.
I'll ask Peter to look into getting a redirect that works with svn in
place, assuming that's possible.  (Who knows...)
It depends.  It can't hurt to tell us, if you're specific.  (That is,
what platform you're on, what log messages Tor logs, what *exactly*
happens when you try to connect, and so on.)  Usually the answer will
be "we know; we're working on it," but for cases where it isn't, it's
good to know asap.
Weird.  I had the same build failure, but since then, it's been
working for me.  What happens for you?

@_date: 2006-08-21 11:23:39
@_author: Nick Mathewson 
@_subject: Exit Node sniffing solution...an idea... 
Erk.  I hope I'm not *that* rude. :)
 [...]
This would pretty much restrict exit nodes to a few places in the US
and Europe, since that's where the exit node operators we know are.
It would limit the scalability of the network pretty badly, and that's
a problem, since we need to accommodate more users, not less.
Also, "A local machine the operators control" would be insufficient
and troublesome.  If we want to lower the likelihood of eavesdropping,
we'd need to make sure it wasn't on an easily eavesdropped network
(like, say, a university net).  "Local" would mean no collocated
hosts, and no hosts at your place of work.
So we'd basically be limited to people that Roger and I know
personally who have very fast network connections to their homes and
who want to run an exit node.  That is not a big list... and because
it's not a big list, it would make us more vulnerable to certain
   - End-to-end correlation attacks get easier, since fewer exits
     means fewer points that a roving adversary would need to
     eavesdrop on in order to see all traffic leaving the network.
   - Legal/social/online DOS attacks get easier, since fewer exits
     means fewer people you need to sue/intimidate/flood in order to
     take down the network.
Technically speaking, hidden exit nodes are a pretty cool idea -- but
I don't think they achieve what you want.  If nobody knows where the
exit nodes are, it's _harder_ to tell whether they're trustworthy,
rather than easier.
Now, perhaps you meant that only Roger and I should know where the
exits were.  But that would create problems:
 - It would turn Roger and me into a single failure point with respect
   to the network.  For obvious reasons, I'd like to *minimize* the
   number of viable attacks on the network that start with "Send thugs
   to threaten Nick"; this would create a new one. ;)
 - It would require us to operate in secret, without oversight.  This
   would reduce confidence in the network.
 - It wouldn't work so well, since an attacker could easily enumerate
   the exit nodes by just making a series of connections via Tor to a
   website they control, and looking at which IPs those connections
   come from.
Still, technically, it's a very cool notion.  I don't think it's
useful *here*, but I kinda hope we eventually come up with something
it's good for, so I have an excuse to implement it. ;)
 [...]
Again, if you want to know who's running [X].exit.onion, you could
just make a connection to your own website via [X].exit.onion, and see
whose IP it comes from.
Also, if it's not easy to prove that you're running a Tor exit node,
you will IMO have a _harder_ time defending yourself if somebody tries
to accuse you of originating traffic that your exit node delivers.
Being hard to block at the exit side is not a goal of Tor.  We want it
to be _easy_ for websites that don't want anonymous traffic to block
us.  Being blockable discourages administrators from taking an
adversarial stance to our software, and has in several cases actually
encouraged people to improve their authorization systems to not rely
on IP blocking for security.  See
   for more rationale.

@_date: 2006-08-21 11:36:53
@_author: Nick Mathewson 
@_subject: Unable to start Tor in Cygwin 
I'm afraid I don't have a cygwin setup handy, so I can only explain
what Tor is doing here.  Tor is calling Cygwin's setrlimit function to
change the maximum number of file descriptors (RLIMIT_NOFILE).  It
looks like this call is failing with EMFILES.  This shouldn't happen,
since we don't raise the value any higher than the hard limit.  I'd
suspect a Cygwin limitation.
Googling shows that this has been a problem with _at least some_
versions of Cygwin:
    Does this problem occur with the latest cygwin builds?

@_date: 2006-08-27 22:40:58
@_author: Nick Mathewson 
@_subject: Holy shit I caught 1 
Good catch, Mike!  As others have said, this is probably the effect of
China (or Chinese ISPs) running a MITM attack against their own
computers in order to make their Internet less secure.
I suspect we'll see this trend in a lot of exit nodes we catch as
broken: we'll detect more plausibly broken configurations than
obviously malicious ones.  After all, lots of people *do* have broken
configs.  (And if somebody is trying to do an attack, it probably
makes sense for them to keep some kind of deniability by pretending
to be broken rather than hostile.)
Another note: if people want to continue running these checks against
exits (and I hope you do!) I'd suggest you keep what, exactly, you're
checking for a secret until *after* you run each round of tests.  Then
announce the results, release the source, and think of more stuff to
test for.  Releasing the source will help other people check out
whether the network is behaving correctly, but keeping mum about what
you're checking for will keep dishonest/broken people from changing
their behavior before you can find them out.

@_date: 2006-08-28 13:04:31
@_author: Nick Mathewson 
@_subject: Holy shit I caught 1 
[...]
Errr.  I'm afraid I can't agree here.  The term "security through
obscurity" is generally reserved for attempts to keep a vulnerability
secret in hopes that attackers won't notice it.   You are correct that
such approaches aren't stable, but that's not what I was advocating.
Instead, I was suggesting that if you come up with a way to check for
a previously non-checked attack, it makes sense to run the scan before
you announce the scan.  Otherwise, you're giving people notice that an
attack that they were (possibly) previously getting away will soon be
detected.  Once you've got initial results, it makes more sense to
distribute the scanning code so others can improve it.
By analogy, sure, it's dumb to leave the bank vault combination set to
"12345" in hopes that robbers won't notice it.  But it's also
counterproductive to distribute photographs of one's plainclothes
police officers in advance of a drug sting.

@_date: 2006-08-04 15:46:38
@_author: Nick Mathewson 
@_subject: Abusing Root-CA attack on tor 
[...]
Not quite.  There are multiple directory authorities.  Clients have
the public keys for all of them.  No directory authority is trusted
completely: clients only believe a statement that is made by more than
half of the authorities.
If you want to know how Tor directories work, check out the
dir-spec.txt document.
We (the developers) don't have the secret keys to the directory
servers.  The only "root key" here is the one that signs the source
distribution.  But if somebody started putting out fake Tor releases
with modified lists of directory authority public keys, we'd probably
notice that.
Instead we need to assume that Mallory compromises more than half of
the directory authority keys here.  That's not something we try to
defend against, except by trying to make it harder to do: we assume
that if more than half of the authorites are compromised, we lose.

@_date: 2006-08-04 15:46:38
@_author: Nick Mathewson 
@_subject: Abusing Root-CA attack on tor 
[...]
Not quite.  There are multiple directory authorities.  Clients have
the public keys for all of them.  No directory authority is trusted
completely: clients only believe a statement that is made by more than
half of the authorities.
If you want to know how Tor directories work, check out the
dir-spec.txt document.
We (the developers) don't have the secret keys to the directory
servers.  The only "root key" here is the one that signs the source
distribution.  But if somebody started putting out fake Tor releases
with modified lists of directory authority public keys, we'd probably
notice that.
Instead we need to assume that Mallory compromises more than half of
the directory authority keys here.  That's not something we try to
defend against, except by trying to make it harder to do: we assume
that if more than half of the authorites are compromised, we lose.

@_date: 2006-08-08 17:59:09
@_author: Nick Mathewson 
@_subject: ACLs null on NT 
Hi, Lee!  This looks like good research.  There's one big problem,
though: our windows skills are weak.  We'll either need a patch for
this stuff, or more specific instructions about what exactly to do, or
this could take a very long time to fix.
 [...]
I'll pass this on to the libevent list.

@_date: 2006-08-12 17:20:31
@_author: Nick Mathewson 
@_subject: Can governments block tor? 
Currently, yes, if the government employs anybody who knows how to
download Tor and read C.   I would imagine that most governments do.
We're working on this.
rtfm'ly yrs,

@_date: 2006-12-15 00:13:32
@_author: Nick Mathewson 
@_subject: tor log file function 
Remember that spaces are handled by your command line interpreter
before they reach C.  So while you meant to have a command line
equivalent to a torrc file of:
   log notice file log.txt
Instead, Tor is breaking this command line into:
   log notice
   file log.txt
On Unix, you'd solve this by saying:
   tor log "notice file log.txt"
so that the quotes would force the "notice file log.txt" part to be
treated as one value.  I don't know whether this will work on Windows
or not, but the odds seem okay.  Every OS needs a way to tell where
arguments end on the command line, right?  ;)
Check out write_pidfile in util.c:
 void
 write_pidfile(char *filename)
 {
  MS_WINDOWS
   FILE *pidfile;
   if ((pidfile = fopen(filename, "w")) == NULL) {
 %s", filename,
              strerror(errno));
   } else {
     fprintf(pidfile, "%d\n", (int)getpid());
     fclose(pidfile);
   }
  }
Hmmm.  Looks like we couldn't find the equivalent of getpid() on
Windows, but looking at it now, I can't imagine why.  MSDN says that
there's one living in process.h.  I've checked in a fix as r9116,
which should get into the next alpha, assuming it doesn't turn out to
be way more complicated than it looks.  Thanks for the reminder!

@_date: 2006-12-01 17:18:51
@_author: Nick Mathewson 
@_subject: How can I trust all my Tor nodes in path 
Hi, Seth!
 [...]
Actually, Tor tunnels multiple circuits over each TLS connection, so
remembering ports won't do the job.  An attacker who can compromise an
entire circuit's worth of servers will also need to remember the
circuit IDs for each circuit.  Still, it wouldn't be hard for an
attacker to modify Tor to log this.

@_date: 2006-12-16 14:28:54
@_author: Nick Mathewson 
@_subject: Annoying "wikileaks" message 
Probably not a bug; probably, somebody has decided that they'd like
their "wikileaks" list to get mail from or-talk, but that they forgot
that doing so while configuring wikileaks to moderate would result in
annoying emails sent to everybody who mails or-talk.
Wikileaks people: you need to fix this asap, or to unsubscribe the
wikileaks mailing list from or-talk.

@_date: 2006-12-17 22:04:05
@_author: Nick Mathewson 
@_subject: There's errors compling latest svn version with mingw 
Okay, I think the patch I just pushed might help.  Windows doesn't
seem to define the very standard type socklen_t, so I've added in a
typedef.  If there are other platforms that break it, it'll be time
for an autoconf test.

@_date: 2006-12-30 09:06:13
@_author: Nick Mathewson 
@_subject: Wired article on Tor 
In particular, see
 and the
surrounding thread.  This is good research, but the story is old
news here. :)

@_date: 2006-12-03 23:27:01
@_author: Nick Mathewson 
@_subject: Bootstraping Tor manually to get past the Great Firewall 
There's a controller feature that lets you feed Tor descriptors.
Check out the section on the POSTDESCRIPTOR command in
control-spec.txt.  Also, as a stopgap, if you dump a big pile of
descriptors in the cached-routers file and the correct statuses in the
cached-statuses directory before you start Tor, it should deal
correctly.  There isn't a controller command to post a new network
status, but adding one would be an easy project for somebody to try.
We'll probably need to do a bit more hacking before it works as a
complete solution for the censorship problem, though.  For one,
descriptors expire regularly, whereas the information you need to
communicate with a particular server could be made as small as its IP
and ORPort values.  (Clients would need to know not to trust the
connection they opened until they had used it to download signed
network-status documents.)
The long-term problem is dealing with the fact that the censors can
access the directories too, and that IP-based blocks are the bread and
butter of firewalls.
 [...]
Actually, you can't spoof a network-status document without changing
the authority key fingerprints Tor is configured with.

@_date: 2006-12-03 23:33:04
@_author: Nick Mathewson 
@_subject: Tor DNS lookups failing 
[...]
The most helpful thing from my point of view would be to try to figure
out whether there's any pattern to the failures.  Are some versions of
Tor broken for DNS lookups?  If so, that's the problem we should try
to fix first.  If you can identify any servers that fail on lookups
particularly often, that would be a great place to start.

@_date: 2006-12-06 17:49:48
@_author: Nick Mathewson 
@_subject: user vulnerability in directory data? 
Here's what Tor stores in the data directory.  I've tried to annotate
the security implications of stuff, but I might have missed
A few general notes before I start:
- I'm assuming an adversary who discovers the contents of the data
  directory, but who can't change them without being detected.  If the
  attacker can alter files on the user's HD or USB drive, he's
  probably won.
- In addition to notes on sensitivity, every file will additionally
  leak the time at which it was last modified.
- If you're very concerned about this stuff, it isn't enough to delete
  the files; data recovery works.  Secure deletion isn't terribly
  reliable either without kernel support.
Here are the files:
  cached-status/*
    The most recently downloaded network status document for each
    authority.  Each file holds one such document; the filenames are
    the hexadecimal identity key fingerprints of the directory
    authorities.
    [Not sensitive AFAICT; everybody downloads the same network status
    documents from the same authorities unless they have configured a
    different set of authorities.]
  cached-routers
  cached-routers.new
    These files hold downloaded router statuses.  Some routers may
    appear more than once; if so, the most recently published
    descriptor is used.  The ".new" file is an append-only journal;
    when it gets too large, all entries are merged into a new
    cached-routers file.
    [Probably not sensitive.  As above, everybody downloads
    descriptors from the same routers, unless you have a nonstandard
    configuration (e.g., you've enabled FetchUselessDescriptors.)]
  state
    A set of persistent key-value mappings.  These are documented in
    the file.  These include:
       - The current entry guards and their status.
         [Somewhat sensitive; this could be used by a roving attacker
         with eavesdropping capability.  I'm working on a patch to tie
         this stuff to IP, but that has security implications of its
         own that need to be worked through.]
       - The current bandwidth accounting values (unused so far; see
         below).
       - When the file was last written
         [Slightly sensitive; reveals a time when the user was using
         Tor.  Still, so does the mtime on all of the files, so it's
         not terribly useful.]
       - What version of Tor generated the state file
         [Probably not harmful in practice: an adversary who can get a
         copy of your state file can probably also look at your Tor
         binary, assuming you're carrying them around in the same
         place.]
       - A short history of bandwidth usage, as produced in the router
         descriptors.
         [Probably not sensitive, but unnecessary for non-servers.
         I'll restrict this to servers in the next release unless
         somebody tells me a good reason why not.]
  bw_accounting
    Used to track bandwidth accounting values (when the current period
    starts and ends; how much has been read and written so far this
    period).  Soon to be obsoleted by state.  Only used when
    bandwidth accounting is enabled.
    [Probably not sensitive; all the traffic analysis attacks I know
    about require comparatively fine-grained information about timing
    and volume.  "How many bytes did Tor write this week" is probably
    not terribly secret for most people.]
  control_auth_cookie
    Used for cookie authentication with the controller. Regenerated on
    startup.  See control-spec.txt for details.  Only used when cookie
    authentication is enabled.
    [Sensitive while Tor is running, but an attacker who can read your
    private files while Tor is running can probably win anyway.]
  keys/*
    Only used by servers.  Holds identity keys and onion keys.
    [This is very sensitive: if an attacker gets a copy of this
    directory, he can impersonate the server.  I'd like to add support
    for encrypting this stuff or storing it remotely in the future,
    but that would require some redesign.  See dir-voting.txt if
    you're interested.]
  fingerprint
    Only used by servers.  Holds the fingerprint of the server's
    identity key.
    [Not sensitive.]
  router.desc
    Only used by servers. Holds the most recently generate router
    descriptor.
    [Not sensitive.]
  approved-routers
    Only used by directory authorities.  Holds a list of approved and
    invalidated routers.
    [Not sensitive.]
These are the files I found on a cursory glance through the code.
There may be more; please ask about any you may happen across.
Please forgive the delay; things have been very busy here in Boston
for the last few days.  We do not in fact subscribe to security
through obscurity; our C code is public, but we recognize that not
everybody can read C, and so we try to make our documentation as
complete as we can.  This stuff should definitely go in the
documentation. Perhaps somebody could write up the above email for the
"FILES" section of the Tor manpage?

@_date: 2006-12-06 20:57:18
@_author: Nick Mathewson 
@_subject: user vulnerability in directory data? 
Ah, good catch, but those don't go in the data directory.  They go in
the directory configured by HiddenServiceDir.  There is one such
directory per hidden service.  Its contents are as you describe:
   hostname -- the .onion domain name for
      this hidden service.
   private_key -- the private key for this hidden service.
Both are sensitive.  The former lets an attacker tell what hidden
services you've been running.  The latter lets an attacker impersonate
your hidden service.

@_date: 2006-12-07 08:48:51
@_author: Nick Mathewson 
@_subject: Nodes frequently changing keys... 
Actually, from the look of things, these are actually multiple nodes
with the same nickname.  This is completely kosher according to the
spec.  If you want to tell nodes apart, you're supposed to look at the
identity key, not just at the nickname.  Unless the "Named" flag is
set in the network status docs, the nickname is not a canonical
In some cases, this is probably intentional.  "Unnamed" is currently
the default nickname used when no nickname is set.
"ididedittheconfig" seems like an obvious riff on the line in the
default torrc.  "anonymous" seems like an obvious "I didn't want to
name this" name.  I'm not so sure abobut waldi, iddbadfpi2, and oinc.

@_date: 2006-12-07 09:20:49
@_author: Nick Mathewson 
@_subject: Windows-specific bug? cached-routers ignored on start-up 
Hm.  This might have something to do with the fact that we now use
mmap (or CreateFileMapping on Windows) to load cached-routers on
startup, in order to let the OS use less RAM.  It looks like the
Windows implementation could be broken, though.  If anybody with
Windows coding fu wants to take a look at tor_mmap_file in compat.c,
that would probably be where the error is.
BTW, to make sure we don't lose track of bugs, it's best to use the
bug tracker at

@_date: 2006-12-07 10:14:17
@_author: Nick Mathewson 
@_subject: Windows-specific bug? cached-routers ignored on start-up 
Yup. There was indeed a bug there.  I've got a likely fix checked in
to the repository, which should appear in 0.1.2.5-x.  Please let me
know if it works, either by email or on the bug tracker entry at

@_date: 2006-12-08 01:10:20
@_author: Nick Mathewson 
@_subject: Tor 0.1.2.2-alpha eventdns timeouts 
[...]
My apologies for the delay here.  Your diagnosis turned out to be
completely correct.  I was looking for far more tricky problems, when
the root cause turned out to be (I think) that eventdns.c never
actually reset the timeout count.  Oops! I've checked a patch in to
subversion as r9054; if you have a chance to see whether it fixes the
problem for you, I'd be most grateful.

@_date: 2006-12-10 21:27:21
@_author: Nick Mathewson 
@_subject: how to prevent Tor from auto-buiding circle? 
Right.  control-spec.txt is indeed an official document.  There are
indeed some configuration options listed there that aren't on the
manual page.  This is because these options are only useful to writers
of controllers, not to general Tor users.
Also, please realize that if there's something that isn't in the
documentation, that isn't because we're trying to make it a "HIDDEN
configuration" option.  We don't do that.  It's probably because we're
lame and forgot to document it.  Just ask, or use the source. :)

@_date: 2006-02-24 19:46:14
@_author: Nick Mathewson 
@_subject: Why doesn't Tor support 4a? 
I assume this isn't what you meant to ask.  Tor supports SOCKS4a and
SOCKS5-with-hostnames, but using SOCKS4 or SOCKS5-with-IP-addresses
means that you're probably leaking DNS.
 [...]
Yes, people have looked into solutions here.  "Torcap" intercepts
gethostbyname requests at the C library level, and the projects called
"TorDNS" act as local nameservers that relay requests to Tor.  Neither
is cross-platform, though, and neither supports hidden services
correctly.  (Supporting hidden services would be doable with the
'MAPADDRESS' command in the control interface, but I don't think
anybody's taking that approach yet.)
The problem here is not a lack of good ideas but a lack of spare
time.  Thanks for the ideas though!

@_date: 2006-02-02 14:43:00
@_author: Nick Mathewson 
@_subject: General anonimity/privacy question when using TOR 
Actually, I think that the JAP FAQ answer is incorrect.  I'll explain.
Low-latency anonymity networks are vulnerable to end-to-end
timing attacks: an attacker who sees both ends of the circuit can
notice similarities in packet timing and volume, and thus match up the
client to the exit.
This attack is more powerful than the kind of long-term intersection
attack that is described below.  In a long-term intersection attack,
you notice that Bob, on average, receives more when Alice is sending
than when she is not.  But if you can tell when Alice is sending and
when Bob is receiving, you are presumably watching Alice and Bob, and
so you can do a correlation attack instead.
Defenses against correlation attacks are generally incompatible with
affordable low-latency anonymity networks.  If anybody has a defense
which can be demonstrated to make these attacks appreciably harder
without making the network unusable, they haven't demonstrated it to
be so.
The only circumstances I can think of where an intersection attack is
possible but a correlation attack isn't are those where the attacker
hasn't been collecting fine-grained data, but wants to track users
after the fact; or where an attacker can't watch Alice and Bob
directly, but can tell through indirect means when they are active
(such as by pinging Alice's IP and noticing when her posts show up on
Bob's blog.)
So, to answer your question: I don't think it's particularly harmful
or helpful for a client to stay online all the time.  Tor will rotate
your outgoing IP regularly either way, and the increased defense
against intersection attacks probably isn't your biggest security

@_date: 2006-01-31 00:55:18
@_author: Nick Mathewson 
@_subject: Tor talk in Boston this Thursday (MIT, Room 4-237, 7:30 pm) 
Hi! I'm giving a tor-related talk this Thursday at MIT.  It's open to
the public.  You should come if you're in the neighborhood.
Anonymous Communications for Crypto Geeks, the U.S. Department of
Defense, and You
Nick Mathewson and Roger Dingledine
First half: Introduction to the theory and designs that make anonymity
networks work, and a discussion of the technical choices from the
earliest designs of the 1980s to today. Second half: Experiences
deploying anonymity, including backing, adoption, law enforcement
issues, abuse, anti-abuse measures, usability, co-existing with other
systems, censorious governments, and creating incentives for people to
help privacy. Thu Feb 2, 07:30-09:30pm, 4-237
Contact: Sherri Davidoff, W20-557, x3-7788, sipb-iap-lectures at mit.edu

@_date: 2006-01-16 14:36:44
@_author: Nick Mathewson 
@_subject: Tor reputation system 
Yes, this is a fine attack.  It's similar to some described in
    Right now, though, we don't do anything to automate testing for
complex failure modes.

@_date: 2006-07-07 16:46:34
@_author: Nick Mathewson 
@_subject: low bandwidth utilization 
Hm. I wonder whether conn is corrupted here.  Can you have gdb print
the value of *conn in purge_expired_resolves?

@_date: 2006-07-16 20:48:30
@_author: Nick Mathewson 
@_subject: Problems running TOR for an extended period 
[...]
Pretty much, except for the (I hope you'll forgive the term) less
popular BSDs.  OpenBSD claims to have a gethostbyname_r, but it is
lying: it just  gethostbyname_r to gethostbyname.  (This is
the moral equivalent of keeping your rat poison in a jar labeled
We _could_ go multithreaded and make it block, but performance on exit
nodes would suck.  When two users wanted to make exit connections at
the same time, one wouldn't start a DNS lookup until the other was
done.  Also, an attacker could shut down all DNS requests just by
making requests that would take a long time to complete.
Right now, we're trying a different approach.  In version 0.1.2.x,
we're trying an approach where we add a built-in async DNS resolver to
Tor and don't use the platform DNS resolver at all: this way, we don't
need to be multithreaded.  Right now, it seems to have a bug that
creates a periodic segfault, but watch this space: I hope we'll get it
straightened out soon.

@_date: 2006-07-17 10:47:11
@_author: Nick Mathewson 
@_subject: Problems running TOR for an extended period 
[...]
As noted, it's a wiki, so you can change it.  As an alternative to
"better," I'd suggest "more up-to-date" or "more thread-friendly" or
"more appropriate".
Can you confirm this with a link?  Better yet, can you alter the wiki
to say the right thing?
This is actually _worse_ in the OpenBSD case.  The
only reason to provide gethostbyname_r in addition to gethostbyname is
that _r is supposed to be reentrant.  All standards and documentation
say so.  There's no reason to provide a _r that isn't reentrant,
unless you want to confuse people who use autoconf to try to find a
reentrant gethostbyname().  This is just a bad decision on the
implementors' part, period.
Oh, it happens.  All you need is one domain with slow DNS for the
attack to work.
It's in CVS; feel free to check it out?  It's very much alpha, so it
probably won't be an official non-alpha release for the next couple of
months at least.

@_date: 2006-06-01 12:10:54
@_author: Nick Mathewson 
@_subject: Vidalia 
Please don't misunderstand: suspicions are good.  If you find any bugs
in the source, you ought to tell us about them.  If you worry about
'true intentions', though, did you know that the Vidalia authors and
the TorCP authors are the same people?
(Unstability isn't the point; TorCP is unsupported code using an
unsupported interface.  Nobody is improving it; nobody is porting it;
nobody is making it take advantages of improvements in Tor 0.1.1.x;
nobody is translating the interface.  Nostalgia and FUD can't save
unsupported code; only support can.)
We do stuff without notice all the time.  We're just a bunch of
overworked developers -- it's hard enough working on Tor full time; we
don't have a marketing department to tell everybody what the next
version will be about.
Anyway, this isn't the dev list, and this isn't where development
happens.  Vidalia has been slated to replace TorCP for a long time.
If you want to see what we're doing, lurk on the irc channel, or
follow CVS.
This *is* something I feel badly about.  However, signal-to-noise
ratio on this list is so incredibly low that a lot of the main
contributers have stopped reading it regularly, thus making it an
unsuitable venue for development chatter.
 .  It seems to be BSD licensed.  Is it
doing something sinister?
(Did you try clicking on the "Trac" link at the bottom of their pages?
It takes you to that site.)
QT is a cross-platform GUI toolkit. This is one of the big improvements of Vidalia over TorCP: because QT
is cross-platform, Vidalia can run on OSX and Unix as well as on
(Did you try googling for QT?  That's the first link.)
Cool!  If you notice any bugs while you're doing so, please report
them as well.  Since you are the single most prolific poster on the
or-talk mailing list, it will be good to see you helping us out with
the project.
(If you have the time to audit the Tor source too, that would be greatly
appreciated.  We don't get enough external review.)

@_date: 2006-06-01 12:17:14
@_author: Nick Mathewson 
@_subject: Message that enough directory infos are gathered occurs twice 
This is harmless.  Tor logs these messages as it tracks the state of how
many servers it knows about.  Sometimes, new information makes it
decide that it needs to learn about more servers before building
Hm. Probably, though, it would be nice not to log the "we now have enough
information" message before we clear out old stuff; I'll see if I can
make the messages cleaner.

@_date: 2006-06-15 18:22:49
@_author: Nick Mathewson 
@_subject: Torrc configurator 
This is a fairly good idea, though I wouldn't use these names.
Please, please, no.
"Man in the middle" is an attack where you impersonate server A to
server B, and server B to server A.
"Middleman" is a possible tor configuration that relays traffic.
These are technical terms with specific meanings; please don't make
users think that they are about to launch a hostile impersonation
attack when they're just going to run a server!
How about "client" "middleman server" and "exit server"?  These are
the terms that Tor uses, after all.

@_date: 2006-06-03 03:22:04
@_author: Nick Mathewson 
@_subject: FW: [Full-disclosure] Tool Release - Tor Blocker 
I'm not sure this is something we need to be terribly concerned about;
the original poster seems to be overreacting to something with a bad
blocking tool.  We already ship a better tool to find the exits that
allow connections to you, so I'm not sure what harm this bit of C
could do.
That's news to me.  We've got around 200,000 active users by our
estimate; if Mr. Areff is correct, that's over 100,000 malicious
hackers.  If that were the case, I think we'd see far more abuse
reports.  I'd be interested to see how he reached his conclusion about
our user demographics, and whether he thinks we ought to be soliciting
funds from organized crime rather than the DoD and the EFF (our past
funders).  (It's understandable why some sysadmins make this mistake,
of course.  When Tor is used as intended, sysadmins tend not to
notice: it's just another IP.  When jerks use Tor to irritate others,
Tor leaps to their attention.)
Malicious?  Okay.
Rhetoric aside, we fully support everybody's right to block our
software from using your service. In fact, we've even released a tool
to help people do this.  Our FAQ, our docs, and personal
correspondence with us would have each been sufficient to find the
"exitlist.py" script in the Tor source tree; it uses Tor to keep track
of exit nodes.  Unlike the Apache module Mr. Areff posted, it keeps an
up-to-date list of exit nodes, so that as new Tor exits arrive, you
learn about them automatically.  That way you don't need to hardwire a
list of inevitably-out-of-date IP addresses, as the posted module
This is a good interim solution for many people.  If your security
model is such that anybody with a non-blocked IP can deface your
website at will, you might want to block anonymizing networks
until/unless you decide to change your security model.

@_date: 2006-06-09 18:14:13
@_author: Nick Mathewson 
@_subject: IPv6 
Nope.  There are two things that you might mean by IPv6-ready, and Tor
is neither.  You might mean,
      "Can Tor connect to hosts that only have IPv6 addresses?"
or you might mean,
       "Can Tor support servers that only have IPv6 addresses?"
Both are desirable; the former (connecting to ipv6-only destinations)
is easier.  It's easier because supporting it only requires changing
our code, not changing our topology.  IPv6-address-only servers
present a topology problem: right now, we assume that (mostly) every
Tor server can connect to every other.  This has problems of its own,
and adding IPv6-address-only servers adds problems too: it means that
only servers with IPv6 abilities can connect to IPv6-address-only
servers.  This makes it possible for the attacker to make some
inferences about client paths that it wouldn't be able to make
Unlikely.  Right now, it uses TLS; IPsec is not "more secure" than TLS
for any meaningful fashion that matters to us.  Also, if I understand
correctly, adding IPsec to systems without it requires root-level
access to the IP stack, which is not compatible with our
no-root-required philosophy.  If we add a non-TCP solution,
DTLS-over-UDP seems likelier, since it doesn't need root.
I suppose we could do IPsec-where-available, DTLS otherwise, but it
doesn't make much sense: given the existence of non-IPsec hosts, we
need TLS or DTLS.
So far, nobody whatsoever has said "I need this"; it's firmly a
nice-to-have-someday feature.
It needs to be designed (explain what you think Tor should do), argued
to be secure (explain why it's better or at least as good as what Tor
does now), specified (explained at the byte level at approximately the
level of detail in tor-spec.txt), and implemented (done in software).
Odd; this should really be in the FAQ.  I must have missed it.

@_date: 2006-05-02 19:36:12
@_author: Nick Mathewson 
@_subject: HCR for key negotiation 
Looks promising; we should see if this is standing in 5 years or so.
For now, however, this doesn't look like a mature protocol to me.  HCR
signatures appear to be introduced in the same paper as HMQV, which
was published in last year's Crypto [1].  A cursory Google search
shows some results (of what importance, I can't say) against HMQV and
HCR, with patches to those protocols in a proposed 'HMQV-1' that isn't
any faster than HMQV [2].
Moreover, it seems likely that HMQV is covered by the same patents as
MQV [3], which I believe are still in force.
In any case, I'd want to see a lot more analysis and research on these
systems before we used them in the real world; just because something
was been published in last year's Crypto doesn't mean it's secure.
[1] [2] [3]

@_date: 2006-05-15 17:13:00
@_author: Nick Mathewson 
@_subject: Some simple changes to the tor architecture I believe may greatly improve it 
[All proposals trimmed; see original email for full details]
Hi, Glymr.  Some of your ideas are good, and almost none are flatly
impossible, but they nearly all are less simple than they initially
appear.  I'm not trying to shoot any of them down (except  but
they need more thought before they could be implemented as-is.
I'd also like to ask you to read the specs and papers, and search for
discussion surrounding these issues on the list archives.  Many of
these have come up before.
That'd be neat, but:
  1) we'd need to solve directory scaling first
  2) we'd need to re-do routing so that non-dialup users don't go
     through these connections.
Again see the "Challenges" paper.
It's true that we need more exit capacity, but many people aren't
willing to run exit nodes.  We can use 2 Mb/s of middleman capacity
for every 1 Mb/s of exit capacity -- why disallow people from
providing it?
This is a non-starter.  If you want to spy on users, please go away.
Wiretapping innocuous information and sending it to the police en
masse is not a good way to protect privacy.
Some problems are:
  1. Privacy-conscious users don't want their info given to anybody
     enforcement, especially to law enforcement without a warrant.
  2. In many decent jurisdictions, you can't simply give away people's
     personal information willy-nilly.
  3. Keeping logs makes a record that is itself a vulnerability.  It
     can get stolen from the server op, or from the people he's
     sending it to, or in transit.
  4. "Law enforcement" is a very broad term.  Does it include the
     Saudi morals police?  The Chinese censors?  The IRS?
  5. It is completely unethical.  Even the most privacy-ignorant ISPs
     (the ones who give away users' information without asking for a
     warrant) wait to be *asked* before doing so, after all.
Something like this will never get built into Tor so long as I'm
working on it.
But most of the good attacks on Tor are either passive timing attacks,
or attacks that introduce timing signatures.  A server that doesn't
transmit traffic is probably broken, not attacking the network.
BTW, directory authorities already check whether they can build
circuits through servers.
This allows a sybil attack to take down good nodes.  That's unacceptable.
 [...]
1. Locality *isn't* a criterion for node selection right now.
2. Directory information doesn't propagate much faster than 15-minute
   intervals at best.
3. If load info is too fine-grained, that's probably an attack
   vector.  But if load info is coarse-grained, we might as well use
   the current approach.
This would do nothing to address end-to-end correlation attacks.
This is about what happens now, except it happens at the client-side:
the client learns a summary view, and compares the summary to its last
network view in order to tell which servers it needs to know more about.
Then read dir-spec.txt.
Again see the "Challenges" paper.  This has anonymity implications.
It may be doable, but those anonymity implications need to be solved

@_date: 2006-05-15 18:58:52
@_author: Nick Mathewson 
@_subject: Some legal trouble with TOR in France + 
[...]
I typically argue this from the "can't" point of view, not the
"won't".  If it were possible detect block evil activities through
programmatic means, I *would* be in favor of blocking them.
Unfortunately, evil-detection isn't automatable (RFC3514
notwithstanding), and most schemes for blocking are both over-broad
_and_ easy to circumvent.
Non-automated schemes, as you say, fall for different reasons: you
can't make one without putting human judgment in the loop, and once
you've done that, you've appointed somebody as a censor, and you've
created a mechanism for someone else to take the reigns of censorship
in the future.
Also, there's the jurisdictional arbitrage problem: which local
standards does your hypothetical censor try to comply with?  China's?
Rather, if you're not willing to accept that people may use your
Internet connection to do stuff you don't like, don't run an exit
node.  You don't have to like everything that people do.  I don't
*want* people to use my software for any number of things, but I
believe that the benefits it provides do outweigh the problems.
Hm?  I don't think Tor was built to prove anything; I think it was
built to further usable online privacy for everyone. :)
As for wasting the coders' time, don't worry.  We have a long history
of ignoring bad ideas.

@_date: 2006-05-15 19:25:15
@_author: Nick Mathewson 
@_subject: Some legal trouble with TOR in France + 
[reformatted, snipped, and top-posting fixed.]
Murder, child abuse, top-posting, and posting one-line replies to long
messages without snipping irrelevant portions. ;)
No, seriously, I can't do any better than your dictionary or your
favorite ethicist.  That's the point I was trying to make.  Right and
wrong are not things that a single person or groups can decide for the
rest of the world, and they're certainly not something that software
can detect.  That doesn't mean that there's no such thing as right and
wrong; it means that you shouldn't enforce moral judgments at the
network layer.
Sorry if I wasn't clear, or if it seemed like I was advocating
And we have now drifted completely away from Tor.  For penance, I
resolve that my next posts will be technical or project-related.  If I
ignore future political stuff, that's why. :)

@_date: 2006-05-16 11:39:27
@_author: Nick Mathewson 
@_subject: keys? 
It's such a good idea that we already do it. :)  See the design paper,
or the spec.
I don't mean to be offensive when I say this, and it isn't just you
who's doing it:
     It's most unlikely that the next really useful idea for an
     improvement in Tor's architecture will come from somebody who
     hasn't taken the time to learn how Tor works today.
I'm really glad you want to help, but to do so usefully, you need to
understand what you're helping with.  If you want to improve Tor's
design, you really need to read up on how the current design works.

@_date: 2006-05-21 15:17:01
@_author: Nick Mathewson 
@_subject: Threats to anonymity set at and above the application layer; HTTP headers 
I'm not a lawyer, so I'm not going to comment on your legal theories.
But from a technical anonymity perspective, choosing an unusual user
agent probably isn't a good idea: if 100K Tor users appear to be using
user agent X, and you use a less popular user agent Y, it's easier for
websites and observers to build a pseudonymous profile for your actions.
This is why I'd really like this discussion to arrive at an improved
privoxy configuration to ship with Tor: even if you, personally, know
a better configuration than the default, you might still be better off
using the default configuration in order to blend in with a larger
See the "Anonymity loves company" paper for more discussion.

@_date: 2006-05-21 15:55:54
@_author: Nick Mathewson 
@_subject: Threats to anonymity set at and above the application layer; HTTP headers 
Hi, Seth.  This is a pretty good summary of higher-layer issues; thanks!
I think there are some things we can do at a Tor level, some things
that need higher-level app filtering, some things that need app
support, and some stuff we don't know how to solve at all.
I. I think these are in the "probably no automatic solution exists"
I could be wrong about the last two; many smart people think that
automated or semiautomated textual normalization is possible.
II. Needs app support:
  (I don't think there's much we can do about this at the Tor level;
   if people were going to use something like Mixminion in large
   numbers, they would've started by now.)
  (You'd need a client that aggregated keypresses, as ssh can do with
  passwords, as IRC does with lines of text, etc.)
III. App support and filtering are worthwhile targets:
Right, we need one of these.  Ideally, it would be for a Free Sotware
proxy that isn't completely unsupported and unmaintained: privoxy is
showing its age.  I have hopes for proxymodo if it ever becomes
(If anybody suggests proxomitron, I'll call them names for not reading
what I said about free software. ;) )

@_date: 2006-05-11 16:49:56
@_author: Nick Mathewson 
@_subject: Improvement of memory allocation possible? 
I don't think you would want that; the CPU usage would be *insanely*
high.  Every time you transmitted any information at all, you'd need
to shrink the buffer, and then immediately re-grow the buffer the
buffer when you had more data to transmit.
Right now, Tor shrinks buffers ever 60 seconds, down to the next
largest power of two above the largest amount of the buffer at any
time in the last 60 seconds.  A 60-second lag here probably does no
harm memory-wise, but the power-of-two thing will, on average, make
25% of your buffer space unused.
The only thing that would actually help trade cpu for RAM here won't
be a more frequent shrinking; instead, we'd have to switch off the
power-of-two buffers implementation.  But if we're going to do *that*,
we may as well move to an mbuf/skbuff-style implementation, and get
improved RAM usage and improved CPU usage at the same time.  (That
approach will make our SSL frame-size uniformity code a little
trickier, but I think we can handle that.)
Hm.  I should look at a breakdown of buffer size; I'll try to do that
later tonight, once I've had my server running for a bit.  It's
probably important to know whether our real problem is wedged
connections whose buffers get impossibly large, or buffers whose
capacities are larger than they have to be.

@_date: 2006-11-14 13:13:37
@_author: Nick Mathewson 
@_subject: Anonymous Blogging 
You can find full details about Tor's protocol at
   Tor uses 1024-bit RSA, 1024-bit Diffie-Hellman, 128-bit AES in counter
mode, and SHA1.  We also sometimes use 3DES if your version of OpenSSL
is very old.
Then again, if you are worried about an hypothetical attacker who can
break AES-128 but can't break AES-256, such an attacker probably has
resources to mount attacks against Tor that are far easier.

@_date: 2006-11-02 22:11:53
@_author: nickm@freehaven.net 
@_subject: _circuit_mark_for_close(): Reason 9 out of range at command 
Hi!  This is bug 351, and should be fixed in the next version of Tor, and is nothing to worry about.
See

@_date: 2006-11-13 11:50:35
@_author: Nick Mathewson 
@_subject: Tor compilation? 
Check out doc/tor-win32-mingw-creation.txt in the doc directory for the
latest alphas.

@_date: 2006-11-13 14:55:52
@_author: Nick Mathewson 
@_subject: Build from tor-0.1.1.25 SRPM for CentOS 4.4 x86_64 fails 
Hm.  Looks like the problem is down here...
It looks like the -march and -mtune parameters are getting set by
tor.spec at line 33:
  %define optflags -march=%{target_cpu} -mtune=%{target_cpu} -O2
I think you need to somehow override the target_cpu setting in the
spec file.  I am afraid, however, that my RPM fu is weak; I don't know
whether you need to edit the spec file or whether you can do this from
the command line.

@_date: 2006-11-13 16:26:45
@_author: Nick Mathewson 
@_subject: IDS signatures [was Re: Interestingly enough...] 
You can see the rules at    This one checks for the string "client ".
These two check for "GET /tor/server/" and "GET /tor/status/"
respectively.  I'm surprised they don't have a rule for "Hey, somebody
just _uploaded_ a descriptor; there's a Tor server running on your
These two check for the string "TOR" near the string "".
So it looks like they're detecting unencrypted directory connections,
as well as some fixed strings in our X.509 certificates.  Good; that's
about what we had thought made us most fingerprintable now.  We'll
probably take care of these some time as a part of our next protocol
(Note: we're not trying to resist IDS users here, or help people
violate network policy.  We're trying to do it as a part of a broader
effort to keep censorious governments from blocking Tor easily.)

@_date: 2006-10-23 18:47:36
@_author: Nick Mathewson 
@_subject: "Practical onion hacking: finding the real address of Tor clients" 
[...]
Sorry, Tor doesn't work that way.  The directory authorities' private
keys are stored only by the administrators of the authorities, and
certified by each other, and by their presence in the (signed) Tor
distribution.  Random third parties can't generate correctly signed
directories, even if they have the SSL root certificates your web
browser uses, since Tor doesn't use those certificates.
Please read dir-spec.txt if you'd like to know how Tor directories
actually work.

@_date: 2006-10-23 18:54:33
@_author: Nick Mathewson 
@_subject: Tor 0.1.2.2-alpha eventdns timeouts 
[...]
No, this seems to be a (relatively harmless) bug with our eventdns
code.  I'm hoping to have it fixed soon; please let us know if it
appears in later versions.
Also, you can check to see whether bugs are already reported by
checking our bugtracker at:
   This is bug 326:

@_date: 2006-10-04 14:36:02
@_author: Nick Mathewson 
@_subject: Optimal ratio of node types 
Assuming all traffic goes through three hops (and for the most part it
does; the four-hop cases are a bit weirder and a lot less frequent)
then, to a first approximation, we want at least 1/3 of capacity in
exit nodes.
(That's capacity, btw, not number.  2 exit nodes that do 10kbps are
not really much better from a capacity POV than 1 exit node that does
This is, of course, an approximation; the real figure will probably
be a bit different because of many issues, such as varying exit
policies, socket limitations, differences between the cost of handling
encrypted OR traffic and handling traffic to the network, and so on.
It doesn't go the other way around, btw: since all exits can be
relays, it doesn't hurt to have an all-exit network.
There's also directory caches.  More of those could never hurt,
especially on middleman nodes.
By the way, this kind of came up in a recent change we made that
should show up in 0.1.2.2-alpha: the new code avoids using exits as
relays nodes when there are lots more non-exits than exits.

@_date: 2006-10-05 01:23:14
@_author: Nick Mathewson 
@_subject: EXPERIMENTAL Windows binary for 0.1.1.24; please let us know if it works. 
Hi, Windows users!
Please try
    It's built by Matt Edman, the Vidalia guy, but it'll be the official
Windows binary for 0.1.1.24 if it works.  Thanks, Matt!
(The official windows releases from 0.1.2.2-alpha and on will be
probably be built with MinGW, but we don't want to change compilers in
the middle of a stable release series.)
Please let us know whether it works for you.  Especially, please let
us know if 0.1.1.23 works for you, but this 0.1.1.24 package fails.
Please *don't* spam the list with "it worked"/"it didn't work" mails,
or people will think you didn't read these instructions.  :)
many thanks,

@_date: 2006-09-05 13:22:57
@_author: Nick Mathewson 
@_subject: TOR Directory file 
You can rely on cached-routers working for now,  but we do not promise
never to change it.  Tor is under active development.
(Similarly, we do not promise permanent backward compatibility with
respect to any current protocol.  We try to keep stable series working
for at least a year (when we can), and we try not to change formats
and protocols gratuitously, but that's about it.)
I would suggest not if you require information to be 100% accurate and
up-to-date; this site tends not to track updates to the directory
format very quickly.
If you want to downlaod the info yourself, you should check out the
document I suggested you read.  It's here:

@_date: 2006-09-01 13:25:25
@_author: Nick Mathewson 
@_subject: Tor 0.1.2.1a for Win32 
"0.1.2.1-alpha-cvs" is not the same as "0.1.2.1-alpha."  The latter
is fine.
Please remember, in software, all the letters matter. :)

@_date: 2006-09-06 16:38:45
@_author: Nick Mathewson 
@_subject: Let us know if Tor compiles with warnings 
Hi, all.  This is just a reminder: when compiled from source, Tor is
supposed to build without warnings.  So if it compiles with warnings
on your favorite platform, please drop us a line so we can clean
things up.  Sometimes, compiler warnings indicate actual bugs that
need to be fixed.
Also, this should go without saying, but: if you need to patch the Tor
source in order to make it build for you, could please you send us
your patches so that we can fold them into the main distribution?
many thanks,

@_date: 2006-09-11 17:49:26
@_author: Nick Mathewson 
@_subject: hidden services spoof 
Checking the PGP signature on the release should be enough to detect
fake updates.
(You've been checking PGP signatures already, right?)

@_date: 2006-09-19 11:11:29
@_author: Nick Mathewson 
@_subject: [INFO] new anonymizing software 
Personally, my position on I2P is that I have no idea how secure its
design is, since I haven't seen a protocol specification.  So far as I
can tell, there isn't one.  This doesn't mean that the protocol is
broken; just that I have no way of telling what the protocol actually
*is* without reading the source and assuming everything the source
does is intentional.
You might also want to check out the FAQ entry at
  though we haven't edited it for a long while.

@_date: 2006-09-01 13:25:25
@_author: Nick Mathewson 
@_subject: Tor 0.1.2.1a for Win32 
"0.1.2.1-alpha-cvs" is not the same as "0.1.2.1-alpha."  The latter
is fine.
Please remember, in software, all the letters matter. :)

@_date: 2006-09-27 10:38:01
@_author: Nick Mathewson 
@_subject: Missing threads...been removed? 
Hm.  They might have been lost when moria had its filesystem go kaput
yesterday.  Once Roger is back around, I'll see how much we can

@_date: 2006-09-03 16:13:52
@_author: Nick Mathewson 
@_subject: New key negotiations 
We do plan on versioning the protocol soon, some time in the next
version or two.  The plan for doing this with circuit negotiation is
to add a note in router descriptors to indicate which circuit protocol
a given router speaks.
It isn't too likely that the protocol you describe will go in, though.
The problem with our current key setup and authentication protocol is
not _just_ that it's slow, but that it's fragile -- although there is
a security proof (by Ian Goldberg in PET 2006 [1]), the proof relies
on (previously) unintended implementation details, and the paper
argues that the protocol is easy to mis-implement.
Nevertheless, the current key negotiation protocol *does* have a
correctness proof.  If we replace the key negotiation protocol, we'll
do it with something _more_ proven and well-established, not less.
It does look like a cool idea, though.  You should probably see
whether something similar exists in the literature, and whether any of
the attacks from the literature work on your proposal.  Just because
it isn't ready for Tor, doesn't mean it's not worth pursuing.
[1]

@_date: 2006-09-04 17:49:32
@_author: Nick Mathewson 
@_subject: Earthlink's broken DNS affecting Tor nodes? 
Alas, there isn't a way to do this now: all nodes are assumed to have
working DNS.  The symptoms are minor, however, and I'd leave your
server running.
This *is* something we should fix, though.  I've added bug 330 on
flyspray to remind us to fix it.  I've suggested a few possible
solutions there; if anybody wants to submit a patch, I'd love to get
something in to handle this situation.
(bug link at
 )

@_date: 2006-09-04 17:55:13
@_author: Nick Mathewson 
@_subject: TOR Directory file 
The directory protocol is described at
    Indeed you did.  The old protocol is at
    The storage format is undocumented, and intentionally so: we may
change it without warning, so please don't rely on it.  But basically,
the old format was just to store a raw directory to disk.  The new
format is to store a network status document for each authority in a
file named cached-status/ (with the authority's
fingerprint given in hex); and to store the router descriptors
concatenated in cached-routers and cached-routers.new.  The latter is
append-only, and used as a journal; periodically, we prune out unused
router descriptors and regenerate cached-routers.
The source (in routerlist.c) should have full information.

@_date: 2007-04-23 13:33:35
@_author: Nick Mathewson 
@_subject: Open DNS 
[...]
Ha.  Actually, this is old news: If an exit node is running the Tor
0.1.2.x series, it can detect DNS hijacking of this kind, and
translate the IP addresses for the advertisement pages back into "no
such domain" responses.  From the ChangeLog for 0.1.2.2-alpha:
    - Workaround for name servers (like Earthlink's) that hijack
      failing DNS requests and replace the no-such-server answer with
      a "helpful" redirect to an advertising-driven search
      portal. Also work around DNS hijackers who "helpfully" decline
      to hijack known-invalid RFC2606 addresses. Config option
      "ServerDNSDetectHijacking 0" lets you turn it off.
From the svn logs:
  Instead of just checking known-invalid addresses for DNS hijacking,
  we now check randomly generated addresses, and if too many of them
  map to the same IP, we assume that IP is the destination of a DNS
  hijack attempt.
  A little bird tells me that some DNS hijackers think that declining
  to give an A record for RFC2606 addresses (like .invalid and
  .example) makes them more standards compliant.  Standardswise, this
  is like an illicit brothel making sure that nobody has pulled the
  tags off the mattresss, but that doesn't get us out of working
  around it.
The anonymity issues of having a large number of exit nodes send all
their DNS requests to the same 3rd party are somewhat troubling, but
no more so than having the same number of exit nodes using the same
ISP or backbone.
Of course, this is neither an endorsement of OpenDNS nor an
endorsement of their stupid and annoying DNS NEXIST hijacking.

@_date: 2007-08-17 19:04:48
@_author: Nick Mathewson 
@_subject: MinGW compile error with rev 10888 
That looks like a libevent error.  As far as I know, the best libevent
for mingw is still 1.1b.  Is that the one you're using, or do you have
a different one installed?

@_date: 2007-08-27 18:53:52
@_author: Nick Mathewson 
@_subject: Attn TorStatus folks! We are about to break your bandwidth measures! 
So, for a long time, Tor servers put information in server descriptors
that Tor clients didn't actually use.  The biggest offenders were the
read-history and write-history lines: they account for around 60% of
the size of a big set of compressed servers.  By removing these lines,
we can save an enormous proportion of directory bandwidth, and (I
hope) support more clients at a time.
But what about the tools that use this information?
Tor 0.2.0.x has a feature called "extra-info" documents.  This is an
adjunct descriptor that gets published along side the main server
descriptor.  Clients don't download it by default.  We now put
bandwidth history information there.  Soon, extra-info documents will
be the _only_ place to find bandwidth history information, once
routers start omitting it from their regular descriptors.]
[For the full details of the decisions involved above, see proposal
104 at
  I'd like to get torstatus updated to handle extra-info before it starts
getting bandwidth history.  To make this easier, I've added a GETINFO
    GETINFO desc/all-recent-extrainfo-hack
It gives the same result as desc/all-recent, except that it looks into
any appropriate locally available extrainfo documents and adds
bandwidth history lines that it found there.  (The signature is no
longer valid, of course, but parsing should still work.)
So, to keep torstatus's bandwidth history info from breaking, here's
the procedure to follow:
    1) Use Tor 0.2.0.6-alpha or later.
    2) Switch GETINFO desc/all-recent to
       GETINFO desc/all-recent-extrainfo-hack
    3) Set "DownloadExtraInfo 1" in the tor process's configuration.
(Later, it would be better to go back to GETINFO desc/all-recent, look
at the extra-info-digest line in the original descriptor, and then
GETINFO extra-info/ to get the bandwidth information.  But I
wanted to provide something fast so that updating the code would be
In all likelihood, servers will start dropping bandwidth history
information from their descriptors in about 2-4 weeks from now.  Is
that enough time?  We'd really like to get the directory bandwidth
savings on the 0.2.0.x timeframe, but we don't want to break existing
code in doing so if we can possibly help it.

@_date: 2007-08-27 19:25:04
@_author: Nick Mathewson 
@_subject: Attn TorStatus folks! We are about to break your bandwidth measures! 
Thanks, Kasimir!  Please let me know if you run into any issues, or if
you run into any delays moving servers over.

@_date: 2007-08-07 21:47:36
@_author: Nick Mathewson 
@_subject: orconfig.h for windows 
unistd.h is only included when HAVE_UNISTD_H is set; if your platform
doesn't have it, the configure script should not define HAVE_UNISTD_H.

@_date: 2007-08-08 16:55:16
@_author: Nick Mathewson 
@_subject: orconfig.h for windows 
Check out Roger's earlier message on this thread.  The build process
we use is documented at:

@_date: 2007-12-05 11:32:13
@_author: Nick Mathewson 
@_subject: Build Problems on Solaris 
[...]
Hi, Steve, and thanks for the report!  I think I have this fixed in
the subversion repository now (as of r12679).  Let me know if it comes

@_date: 2007-12-08 06:11:31
@_author: Nick Mathewson 
@_subject: Build Problems on Solaris 
Ah, I think I see what this is.  In 0.2.0.x, threads are now
mandatory.  But threads default to off on solaris for some old reason.
(I believe we fixed the bug in question.)  Try configuring with an explicit
--enable-threads?  I'll change the behavior assuming this works.
(Also, make sure you have libevent 1.3e or later; earlier ones had
Solaris bugs, I believe.)

@_date: 2007-02-13 02:03:00
@_author: Nick Mathewson 
@_subject: suggestion for 'is my installation of tor working?' page 
As others have noted, this is really excellent, but there's way too
much information there for it to be useful for unsophisticated users.
There's no way that my dad, for example could tell that his window
width and height identify him far more uniquely than do his User-Agent
or his "DMA code".
Maybe there should be some kind of "What I Learned" section at the
top, with parts like:
  Javascript said:   "Your IP is x.y.z.w".
     (Learn more about how to disable Javascript _here_.),
  Java said: "Your IP is x.y.z.w.":
     (Learn more about how to disable Java _here_.)
That is, sort information by order of significance of disclosure, and
for each piece of information, tell users what it means, how much it
isolates them, and how to stop disclosing it.
Also, is there some way to see, use, and distribute the source for
these pages?  As long as you operate them, yours will of course be
most popular, but my free software instincts make me ask "what do we
do if Wesley is unavailable for a while?"

@_date: 2007-02-13 11:37:13
@_author: Nick Mathewson 
@_subject: Mingw compile error with latest rev. 9577 
Thanks!  I've checked in a patch for this as revision 9578.

@_date: 2007-02-16 00:46:54
@_author: Nick Mathewson 
@_subject: suggestion for 'is my installation of tor working?' page 
[...]
Good idea!  Send in a patch, and I'll clean it up and check it in.  It
doesn't need to include IE instructions; somebody else can send them
in later if they know then answer.

@_date: 2007-02-19 21:18:35
@_author: Nick Mathewson 
@_subject: PHP coder needs Tor details 
Hi!  Amazingly, we have documentation.
   You can just run a Tor client though, and look in its cached-routers
and cached-routers.new files in its data directory.

@_date: 2007-02-20 18:08:10
@_author: Nick Mathewson 
@_subject: map of tor routers 
Neat; if you're going to check more often than that, I'd suggest that
you run a Tor client and look in its cache instead.
Neat stuff!  Keeping historical data might also be cool, so you could
see how the network's geography changed over time.
 [...]
Nice; good idea.

@_date: 2007-02-23 01:47:46
@_author: Nick Mathewson 
@_subject: purging old router information, revocation 
Hm.  You're right; this isn't documented well enough.  Let me dig
through the code a little.
Once your router is no longer publishing router descriptors, the clock
starts ticking: it will no longer be included in the network status
documents the authorities generate after it's older then
MAX_AGE_TO_PUBLISH seconds old (currently, 20 hours, though we're
going to crank this up to something higher so clients don't need to
publish so often), the authorities won't include it in the network
status documents they generate.
Some clients may ask caches for the descriptor anyway, since they may
have older network status documents.  Caches throw even old expired
descriptors away after  OLD_ROUTER_DESC_MAX_AGE (currently 5 days).
It would be cool to have a patch to dir-spec.txt to document this
stuff, if it's not documented there somewhere already. :)

@_date: 2007-02-26 10:28:38
@_author: Nick Mathewson 
@_subject: Please stay on topic. [was Re: ISP controlling entry/exti ("Low-Resource Routing Attacks Against Anonymous Systems")] 
[A lot of Jews-control-the-earth stuff.]
Please, take it elsewhere.  This is what I've asked the Bush-did-9/11
crowd and the NSA-has-put-transmitting-devices-in-my-teeth crowd, and
this is what I'm asking you.  This is or-talk, not conspiracy-theory-
Also, you may want to get an email reader that wraps lines properly.

@_date: 2007-02-26 15:06:23
@_author: Nick Mathewson 
@_subject: "Re: ISP controlling entry/exti" ("Low-Resource Routing Attacks Against Anonymous Systems") 
Dude, did the Jews put something in your water that makes you unable
to comprehend "stay on topic"?
Possibly so, since I managed to tell you to stay on topic _twice_
(once on 5 Jan, once today at 10:30 Eastern) to no good effect.
There are other people on this list with equally unpopular theories.
They manage to stay on-topic.  You apparently can't.  They respond to
"Please stay on topic" by saying "sorry" and staying on topic.  You
apparently don't.
With all respect and best wishes, I need to suggest that this is
probably not the mailing list for you.
Please, folks, remember not to respond to off-topic posters.  When you
do, there are now _two_ people talking discussing the Fiendish
Fluoridators on rec.pets.cats or whatever.
My apologies for the digression. Now, back to useful work.

@_date: 2007-02-27 00:51:24
@_author: Nick Mathewson 
@_subject: "Low-Resource Routing Attacks Against Anonymous Systems" 
[...]
It was written by Shava Nerad, the Tor Project's multi-talented PR
person, social engineer, and bureaucracy wrangler, with comments from
me and other developers.
See the about page at

@_date: 2007-02-28 10:51:41
@_author: Nick Mathewson 
@_subject: Feb 27 03:40:25.760 [err] circuitbuild.c:2156: entry_guards_prepend_from_config: Assertion options->EntryNodes failed,; aborting. 
Well, it's an assertion failure.  That's always a bug.  It means that
some part of the Tor code noticed that one of its assumptions was
violated, and rather than continuing on (and probably crashing,
possibly in bad and exploitable ways), it exited immediately with the
above message.
The message in question looks like it might happen if a controller
quickly set and then cleared the EntryNode option before Tor started
picking a path for its next circuit.  I've checked in a patch that
should fix this in the next development version (0.1.2.9-beta or -rc),
and that will appear in 0.1.1.27 too if there's ever one of those. ;)
Thanks again for the bug report!

@_date: 2007-02-28 13:35:14
@_author: Nick Mathewson 
@_subject: Censorship [was Re: Norwegian DNS compromized] 
[...]
There are many reasons why I do not think it is a good idea to add any
censorship code to Tor.  That's one of them.  Let me elaborate.
Let's assume for the sake of argument that some kinds of expression
are so totally pernicious and without merit that the world would be
better if nobody could engage in them.  (If you disagree, great, but
bear with me here.)  Even if this _were_ the case, would not follow
that it is a good thing to create censorship mechanisms for that data.
  - First, since censorship tech requires people to administer it,
    creating censorship tech places some people in control of what
    other people can say and see.  Even if the censors are enlightened
    minimalists who begin with the best of intentions, the risk is
    high that they will err, or be subverted, or be replaced.
    Centralizing authority like this creates a nasty point of failure,
    and a tempting target for attackers.
    (Before somebody proposes that a legal system be given the job of
    deciding what's okay, I'd point out that what's banned in France
    != what's banned in China != what's banned in the US[*] != what's
    banned in Russia != what's banned in Iran.  If you ban only the
    intersection of illegal things, you ban nothing.  If you ban the
    union of illegal things, you do the censors' job for them.)
  - Second, there's Paul's point above about legal ramifications under
    US law.
  - Third, censorship tech has unintended consequences.  Check out
    Richard Clayton's paper "Failures in a Hybrid Content Blocking
    System."  Clayton describes how BT, in an attempt to create a
    highly specific content blocking system, in effect wound up
    creating an index service for the very content they were trying to
    block.  This problem would only be _worse_ in a system like Tor
    where, if you wanted to block access to certain places, you would
    necessarily need to give exit nodes access to the blacklist.
Remember, it is possible to believe in right and wrong without
believing that moral judgments belong in the OSI stack.
Also, this should not need to be said, but debates about the merits of
Divine Command Theory[**] are not on-topic here.  Remember, just as
two wrongs don't make a right, an off-topic post is not sufficient to
make a reply on-topic.
[*] And don't get me started on obscenity law in the US: distributing
    "obscene" materials is generally illegal, but "obscenity" is
    defined in reference to prevailing community standards.  In
    general, there's no way to be quite sure whether something will be
    found obscene other than going to court over it, and there's no
    guarantee that what's found not to be obscene here will be found
    obscene 50 miles away.
[**]  .  I've got
     strong opinions about _this_ too, but I also have the good sense,
     I hope, to keep my mouth shut about it on the mailing list. ;)

@_date: 2007-02-06 11:45:51
@_author: Nick Mathewson 
@_subject: tor plus openssl hardware? 
From the manual:
       HardwareAccel 0|1
              If non-zero, try to use crypto hardware acceleration
              when available. This is untested and probably buggy.
              (Default: 0)
Hardware acceleration is off by default because some people have
reported that it makes their Tor server crash.  We'd like more data
here; please feel free to try it out and let us know if it works for

@_date: 2007-02-06 18:41:43
@_author: Nick Mathewson 
@_subject: tls and connection hacking 
Check out section 2 of tor-spec.txt, at
    tor.eff.org/svn/trunk/doc/spec/tor-spec.txt
The earlier sections may help with notation and terminology.

@_date: 2007-02-11 19:08:08
@_author: Nick Mathewson 
@_subject: your message 
Hi!  You just sent the word "unsubscribe" to several hundred people.
That isn't very nice, and it doesn't work either.  If you want to
remove yourself from the or-talk list, you can either follow the
instructions in the headers of every or-talk email you've ever
    X-To-Get-Off-This-List: mail majordomo at seul.org, body unsubscribe
    or-talk
Or you can go to list webpage at  and
   To join the or-talk mailing list, send an e-mail message to
   majordomo at seul.org with no subject and a body of "subscribe
   or-talk".
Again, so you know, the way to get off a mailing list is almost
NEVER to mail the list itself.

@_date: 2007-01-11 09:13:20
@_author: Nick Mathewson 
@_subject: EventDNS Crash: ISP-Hijacked Address 
[...]
Not trivially (assuming you can't fix your DNS provider).  But if you
can use gdb get us a backtrace from that core, the fix will come out a
lot faster.  (Do _NOT_ send the core itself; it has a copy of your
keys in it.)
(To get a stack trace, run "gdb {path-to-tor} {path-to-core-file},
then type "bt".)
But before you do that, I've checked in a possible fix to svn; if you
can let us know whether that works for you, that would also be
Thanks for reporting this, BTW!  Please let us know if you find
anything else.

@_date: 2007-01-11 14:20:35
@_author: Nick Mathewson 
@_subject: How to use svn [was Re: EventDNS Crash: ISP-Hijacked Address] 
Hi!  Since this is something more people might want to know about,
I'll post more detailed instructions.
"Svn" is "Subversion".  It is indeed a cvs-type system.  If you're
running a Unix-like system, just use your package manager to install
it or get the source at  .
Once you've done that, you can get the latest source by following the
instructions at  :
   svn checkout  tor
This will create a new directory called "tor".  Later, to fetch
updates, cd into the directory and type "svn update".  For more
information, see the subversion documentation.

@_date: 2007-01-11 15:25:43
@_author: Nick Mathewson 
@_subject: cbc news article: Website wants to take whistleblowing online 
Hey, Wikileaks people.  Your FAQ says that you're using "modified
versions of FreeNet, Tor, PGP and software of our own design."  This
is a perfect time to share your modifications to Tor with the rest of
us; if they're good, we'd like to include them in the main
distribution.  If they're bad, we'd like to be able to warn you before
some poor dissident gets thrown in jail.
Generally, keeping your design and source code secret before public is
not a good idea; at least two Tor-related projects I can think of that
have done this have had significant flaws exposed after their initial

@_date: 2007-01-16 10:20:16
@_author: Nick Mathewson 
@_subject: Question for DEVs -- Write/Read Limiting 
[...]
To elaborate: there are some sane combinations, and some insane ones.
For example, there's no good way to support having a read limit that's
significantly higher than your write limit (since if we do that,
servers will read traffic they can't relay), but it's easy to support a
write limit that's higher than your read limit (we did it before, and
it seemed to work fine).
So why not implement just higher write limits?  Two reasons.  First,
there's an interface issue: if there's a feature to set a high write
limit, people will expect that setting a low write limit will work
too.  Second, there's a lack of demand: most people with asymmetric
bandwidth (like ADSL and cable modem customers) have higher bandwidth
for reading than writing, not the other way around.
Agreed.  Also, a documentation patch or FAQ entry would also be keen.

@_date: 2007-01-04 13:36:53
@_author: Nick Mathewson 
@_subject: Transparent proxy won't work with mingw under win32 
Honestly, I don't know how to make it work on win32.  What I need is:
   - A way to redirect TCP streams to a local port.  This could use
     some pf variant, or not: any good TCP/IP stack should be able to
     do it.
   - A way for a local application to learn the original destination or
     port.  On BSD, this is /dev/pf and ioctl(DIOCNATLOOK); on Linux,
     this is getsockopt(SO_ORIGINAL_DST).
It doesn't matter whether the underlying implementation uses pf or
what; what matters is that the feature set above is available.  If
somebody tells us the right way to get this working, we'll try to
get it done in the 0.1.2.x series.

@_date: 2007-01-05 12:45:13
@_author: Nick Mathewson 
@_subject: A friendly reminder to stay on topic [Re: Good reasons to use Tor etc.] 
[...]
Jon Doe, Xiando, please remember: There are lots of venues to tell the
people who really rules the world, or who has been fluoridating the
water, or what really happened on the moon landing, or why JFK was
really assassinated.  This is or-talk, not conspiracy-free-for-all;
please try to keep things Tor-related.
[Note 1: I realize that some people have argued that anything one
 might conceivably say _using_ Tor is itself on-topic for a Tor list.
 This is not so.  Just because you can use IPv6 to talk about kittens,
 does not mean that pictures of kittens are on-topic for an IETF list
 about IPv6.]
[Note 2: Yes, I realize that this will make people decide that I'm a
 pawn of the Bavarian Illuminati, or the Scottish Rite Freemasons, or
 the Twelve Bankers Who Run Everything, or the Goldfish Fanciers of
 Massachusetts.  Fnord.]
Again, just a friendly reminder.

@_date: 2007-07-17 16:32:28
@_author: Nick Mathewson 
@_subject: Reminder: Tor 0.1.0.x and earlier will stop working in August. 
Hi, all.  This is a two-weeks reminder that the v1 directory system,
which was used by versions of Tor earlier than 0.1.1.x, will start to
shut down some time in August.  Right now, I'm planning on the
beginning of August, but I could be persuaded to wait for the end of
August if there's some pressing need.
The reasons for dropping support are:
  - 0.1.0.x is obsolete and very insecure.
  - The v1 directory protocol uses an obscenely large amount of
    bandwidth that could be put to better use.
If you're running a tool that uses v1 directories, you need to update
it too, or it will stop working.
This is a reminder; the original announcement was back on May 31.  I
received no objections then, so as far as I know, everybody is still
okay with this.  Please let me know if I'm wrong.
For reference, the original announcement was here:

@_date: 2007-07-22 16:52:36
@_author: Nick Mathewson 
@_subject: Blocking child pornography exits 
Hi, Ron.  This discussion comes up every few months or so, and
generates more heat than light.  See my posts to or-talk around 15
May 2006,  in particular
      Short version: If I knew how to build a version of Tor that could be
used only for Good and never for Evil, I surely would.  But I have no
idea how to do that well, and I don't think anybody else does either.
(There are proposed solutions to do that.  They are bad.)

@_date: 2007-07-05 23:50:17
@_author: Nick Mathewson 
@_subject: MinGW compile errors with svn version 10742 
Thanks!  I've checked in a fix as 10743 to try to fix this.  Please
let me know if there are more errors.

@_date: 2007-07-28 18:19:32
@_author: Nick Mathewson 
@_subject: What are Tor guards? 
Yes.  They are not more trusted than other nodes; the point is that
you stick to a small set of entries in order to avoid profiling
attacks.  Read through the math in the FAQ entry again, and check out
the papers that the FAQ entry lists.
What part of the documentation gave you the impression that guards
were hand-chosen?  We should fix that.

@_date: 2007-06-18 02:06:28
@_author: Nick Mathewson 
@_subject: unknown_subject 
James: You just mailed a list of hundreds of people, telling them
"unsiscribe".  This isn't how you get off mailing lists.  Try
following the instructions that have appeared in the headers of every
or-talk emails you've ever received:
  X-To-Get-Off-This-List: mail majordomo at seul.org, body unsubscribe or-talk
In other words, mail majordomo at seul.org , with the line "unsubscribe
or-talk" in the mail body.
Ringo (and others): If you really think that you need to say
inaccurate, unhelpful stuff (like "You are not allowed to"), please
don't CC the entire list with it.  Signal-to-noise issues *are* a
problem.  Please don't be part of the noise.
many thanks,

@_date: 2007-06-14 23:28:01
@_author: Nick Mathewson 
@_subject: What this data represents? 
If you want to know what the control port interface does, the best
place to look is in the documentation at:     The ns/* stuff is in the same format as v2 directories.  For that, see
the directory documentation at:     You want section 3; it explains the format in pretty intense detail.

@_date: 2007-03-07 11:04:57
@_author: Nick Mathewson 
@_subject: Building tracking system to nab Tor pedophiles 
Well, it sounds like a pretty thorough implementation of a well-known
attack.  If the goal was getting press coverage, it's successful.  If
the goal was "let's embed a scripting language in everything!" then
it's also a success there.  If the goal was getting talks at hacker
cons, then I bet it will work fine.  These are all laudable goals, and
I sympathize with them all as far as they go.
But if the goal were actually to send criminals to jail, then I rather
suspect that the fellow would've had a talk with law enforcement, or a
lawyer, beforehand.
Similarly, I hope that in his interview, the author of this attack
mentioned that the attack depends on bad configuration choices on the
part of the user, and that the interviewer just didn't that would be
interesting.  It would be a bit misleading to say "I have an attack on
this system" when you only have an attack against users using the
system wrong.
Right.  I don't see what keyword set you could possibly use to
reliably distinguish between real criminals, people reading Nabokov,
people reading reports _about_ the real criminals, and fangirls
reading harry/ron slashfic online.
 [...]
Right.  This _is_ a general-purpose attack tool; there's no reason it
can't be just as useful for identifying the IPs of misconfigured Tor
users looking for information on democracy in China, or for the
nearest VD clinic, or for information on how to run for office, or
whatever.  Snoops everywhere should be pleased.

@_date: 2007-03-07 12:33:28
@_author: Nick Mathewson 
@_subject: one less onion skin 
[...]
This was one of the major reasons for not doing it at the same time as
CREATE_FAST.  Assuming that TLS conns are mostly longer-lived than
circuits, then circuit PK should strongly dominate link PK.  The same
amount of data, however, goes over TLS as over circuits.
Given those (fuzzy, inaccurate) assumptions, it follows using
CREATE_FAST should have been sufficient to get rid of 33% of the
server-side PK.  Dumping the first circuit hop's AES, however, would
only get rid (at best) of 12.5% of server-side AES, so it wasn't as
immediately clear of a win.  (There are 8 server-side AES operations
on all the data now: the first two servers in the circuit need to a
TLS decrypt, a circuit decrypt, and a TLS encrypt; the third server
does a TLS decrypt and a circuit decrypt.)
AES was between 8 and 20% of server CPU time the last time I looked;
this change would save at most 2.5% of server CPU, which doesn't
really make it seem like low-hanging fruit to me.

@_date: 2007-03-07 14:01:40
@_author: Nick Mathewson 
@_subject: Compile error w/0.1.2.9-rc on Kubuntu 6.10 
That message also sometimes occurs when you have libevent installed,
but are missing the corresponding devel package.  Look for something
called libevent-dev or libevent-devel.
(I'll try to make the message more accurate in the upcoming
0.2.0.x-alpha series, but that's not for a while.)

@_date: 2007-03-07 23:25:32
@_author: Nick Mathewson 
@_subject: Building tracking system to nab Tor pedophiles 
Now that we all agree, could somebody draft the statement as a patch for
the download page source at
     ?
Who will be first to get their patch to tor-webmaster at freehaven.net?
Whose patch will be best?  Only you can decide! ;)

@_date: 2007-03-03 16:16:11
@_author: Nick Mathewson 
@_subject: Latest tor beta exits on start 
Hi, I think I've found the bug and fixed it.  Tor has an internal
function (nt_service_is_stopped()) that detects whether we're running
as an NT service, and if so whether the NT service wants to get shut
down.  Unfortunately, in order to detect whether it was running as an
NT service, it first tried to load the NT service functions, which
older versions of windows don't have.  D'oh! :/
I've checked in a fix that will appear in the next -rc release.  With
any luck, somebody will try building it and running it on some older
Windows version before then.
Thanks again,

@_date: 2007-03-03 16:22:09
@_author: Nick Mathewson 
@_subject: network connection 
Not necessarily anything; this log message happens when Tor gives up
on a closing connection before it can write all the data it has to
write on that connection.  This could mean that your network
connection is unable to write, or (more likely) your Tor was talking
to a computer that failed to .  Assuming you're using a recent version
(0.1.2.8-beta or 0.1.2.9-rc), you'll only see it if you're running a
server; usually, it's nothing to worry about on its own.
Then again, now that I look at it, this is a really _awful_ error
message.  It's not clear, and not helpful.  I'll try to change it
before the next -rc release comes out.  Thanks!

@_date: 2007-03-03 17:11:56
@_author: Nick Mathewson 
@_subject: TLS HMAC key bit-length 
Check out section 6.3 of RFC2246: the MAC secrets are derived from the
first 2*SecurityParmeters.hash_size bytes of the generated key block.
So this will be 20 bytes if the hash is SHA-1, etc.

@_date: 2007-03-12 09:16:31
@_author: Nick Mathewson 
@_subject: mingw compile trouble 
Try upgrading to the latest autotools, and/or running the autogen.sh
script that comes with Tor.  (The version of Tor in svn requires a
more recent version of automake and autoconf than you have necessarily
been using.)

@_date: 2007-03-04 12:57:18
@_author: Nick Mathewson 
@_subject: "router get by nickname" on request to dir server appears to be failing 
[Reformatted: lines wrapped. You might want to see if you can get
 your mailer to wrap lines to 72 characters.]
It is possible for the servers to appear in your directory without
having a listing _by name_.  Servers are listed as "Named" by
directory authorities if the nickname has been registered with the
directory authorities, and no other server is allowed to canonically
use it.  If the name isn't registered, then any server can claim to
have that name.  This is why Tor is suggesting that you identify
servers by key, not name.
I'll change this warning so it is more clear; thanks for the tip.
Identity keys don't change for a given server, unless the server admin
deletes the old identity key and generates a new one.
I don't think there is an easy way to turn off just this warning right
now; we're going to re-do how DNS happens in the next development
series (after 0.1.2.x), and stuff might improve then.
There _is_ a workaround that might help, but it's ugly.  Tor doesn't
warn about mapped addresses, so you could try this: if your
application's "localip/url cache" currently has a mappings like this:
   tor.eff.org   ->   209.237.230.67
   archives.seul.org -> 18.244.0.188
Then instead have your application's cache map to internal addresses
   tor.eff.org   ->   10.10.0.1
   archives.seul.org -> 10.10.0.2
And have Tor map those addresses to the ones you really want, by
adding to the torrc:
   MapAddress 10.10.0.1 tor.eff.org
   MapAddress 10.10.0.2 archives.seul.org
    Or use IPs directly:
    10.10.0.1 209.237.230.67
    10.10.0.2 18.244.0.188
This approach has two advantages besides suppressing warnings:
 - It only suppresses warnings for the addresses where you have a
   local mapping, so you still find out if you missed an address.
 - By giving your application 10.x addresses instead of actual
   addresses, you ensure that your application won't connect if it
   somehow forgets to use socks5.
hope this helps,

@_date: 2007-03-25 11:50:57
@_author: Nick Mathewson 
@_subject: Ultimate solution 
[...]
  [...]
When free software people ask "is a license free?" they usually are
asking whether it conforms to the Debian Free Software Guidelines or
the Open Source Definition.
I'm no lawyer, but the term in the license above seems like a clear
violation of the Debian Free Software Guidelines to me.  In
particular, it violates guideline 5 ("No Discrimination Against
Persons or Groups") and possibly guideline 6 ("No Discrimination
Against Fields of Endeavor").  The restriction on what you can modify
it to do seems to controvert guideline 2 ("Derived Works"), .  These
same requirements appear in the Open Source Definition.  Thus, the
license is neither a Free Software license nor an Open Source license,
unless you mean free-as-in-beer.
I won't touch on the other issues here.

@_date: 2007-03-04 21:19:25
@_author: Nick Mathewson 
@_subject: "router get by nickname" on request to dir server appears to be failing 
[...]
What you are probably seeing is two servers with different identity
keys and the same nickname.  When you specify by nickname, sometimes
you'll get one, and sometimes you'll get the other.
That doesn't do that; server identity keys are constant.

@_date: 2007-03-04 22:35:34
@_author: Nick Mathewson 
@_subject: Please try 0.1.2.9-rc (Also, 0.2.0.x is now branched.) 
ANNOUNCEMENT 1:
Hi, all.  If you haven't already, it would be really helpful to the
development process if you could try Tor 0.1.2.9-rc in the next few
days and let us know whether it works for you.  This is especially
important for people who have been happy with 0.1.1.x Tors up till
now: we really want to know whether there are any issues that will
stop anybody from upgrading to the 0.1.2.x series.
(There is a known bug where Tor 0.1.2.9-rc does not work with old
versions of Windows (95, 98, and Me).  If you're running one of those,
you'll want to wait until 0.1.2.10-rc.  Sorry about that, and thanks
again to norvid for reporting the bug.)
ANNOUNCEMENT 1.5:
This is just a regular reminder: if you build Tor from source, it
should compile without warnings.  Please send me mail if it doesn't.
(For extra excitement, if you're using GCC, you can run the configure
script with --enable-gcc-warnings and get GCC to add even more
warnings.  The list currently stands at:
    -Wall -W -Wfloat-equal -Wundef -Wpointer-arith Wstrict-prototypes
    -Wmissing-prototypes -Wwrite-strings -Wredundant-decls
    -Wchar-subscripts -Wcomment -Wformat=2 -Wwrite-strings
    -Waggregate-return -Wmissing-declarations -Wredundant-decls
    -Wnested-externs -Wbad-function-cast -Wswitch-enum -Werror
    -Winit-self -Wmissing-field-initializers
    -Wdeclaration-after-statement -Wold-style-definition
Again, if any of these warnings actually trigger anywhere in the code,
please let me know.  We try to write the cleanest C we possibly can,
and we hope it shows. ;)
ANNOUNCEMENT 2:
If you have been tracking Tor development code via subversion, we just
branched the 0.1.2.x series off from the main branch.  Development of
0.1.2.x will continue on the branch:
  and the new latest development series will continue to be at:
  many thanks,

@_date: 2007-03-06 16:54:32
@_author: Nick Mathewson 
@_subject: UDP over Tor [was Re: blog about tor and skype] 
There's another reason that UDP-over-Tor is nontrivial that isn't
mentioned there.
To get any decent kind of UDP performance, we can't just treat it like
TCP (with reliable in-order delivery).  If we want UDP-over-Tor to
work and not suck completely, UDP 'streams' probably need to get
relayed from router to router via a DTLS-over-UDP-based link protocol,
not the current TLS-based one. But if we're doing that, and we don't
want the UDP traffic to be trivially partitioned, we need to change
the way we handle delivery for regular cells.  (This would be good for
performance for other reasons: it would stop the property where once
dropped packet on a TLS link stalls all the circuits using that
Of course, there's no reason somebody couldn't design and implement
the sucky version in the meantime.  It would be a bit tricky, but
probably fun.  We'd need to add a new stream type, a new set of relay
commands to use it, a separate set of exit policies, and support for
socks5 udp commands.  To support UDP messages longer than 500 bytes or
so, we'll need a way to fragment UDP across Tor cells.  So, tricky,
but possible.  Check out
   if this is something you'd like to work on. ;)

@_date: 2007-05-16 02:06:07
@_author: Nick Mathewson 
@_subject: bw_accounting and mirroring dir 
Probably a bad idea; that file is deprecated in 0.1.2.x and later in
favor of the state file.
Hm.  I suppose we could tweak the check in
decide_to_advertise_dirport() to be a little more subtle.  Roger, any
thoughts on that?
Alternatively, if you're feeling hackish, you could just edit the code
in decide_to_advertise_dirport and make it do what you want.
I'm not sure what you're trying to measure here.  You can get
information about ongoing bandwidth usage by connecting to the control
port and asking for BW events, but that's a little trickier.

@_date: 2007-05-16 21:53:52
@_author: Nick Mathewson 
@_subject: svn 10201 not working 
Thanks for the note!  I messed up a loop in crypto.c while I was
trying to fix some new warnings from gcc 4.2.  I've fixed it in
r10202, I think.

@_date: 2007-05-28 23:47:52
@_author: Nick Mathewson 
@_subject: Compile Error report 
Try re-running configure on the latest svn?
Is HAVE_STRUCT_IN6_ADDR is defined in orconfig.h?
Where is struct in6_addr defined in your system headers?

@_date: 2007-05-29 09:57:47
@_author: Nick Mathewson 
@_subject: Compile Error report 
You didn't answer the above questions.  I need to know what's going on
there.  There seems to be some problem where the autoconf script is
not correctly detecting whether your headers have a 'struct in6_addr '

@_date: 2007-05-31 13:44:01
@_author: Nick Mathewson 
@_subject: Fetching only Exit nodes 
You might want to stop that; 0.1.2.x has a lot of security
Right. 0.1.1.x is old.... though getinfo network-status *does* work
for me there.  It doesn't use the same format, though, and it can't
tell you what is an exit node.
You _could_ arrange for a long-running script to be notified of all
new descriptors as they arrive by using SETEVENTS to listen for
NEWDESC  events, but I'm not sure that's what you want.
No.  The former rejects all addresses in private networks; accepts
port 80, and port 443; and rejects everything else.
The latter just rejects everything.

@_date: 2007-05-31 16:10:00
@_author: Nick Mathewson 
@_subject: Plan: dropping support for v1 directory protocol. 
[Hi, folks.  This message also went to or-dev, but I think there are
some tool maintainers who aren't on that list.]
Hi, all!
As you probably know, Tor has had a few different directory protocols
in its lifetime.  The oldest one (the "v1 protocol") was pretty bad:
it took up a lot of bandwidth, and it made every authority into a
single point of failure.  The more recent protocol (the "v2 protocol") has
been fully supported since 0.1.1.8-alpha.
Unfortunately, there are still some tools that use v1 directories, and
there are still some clients (and even a few servers!) running
0.1.0.x.  This is bad for a number of reasons: The 0.1.0.x series has
not been supported for a while.  Tor 0.1.1.x has been stable for more
than a year now, and it has a lot of important security features that
are not supported in 0.1.0.x.  (These are features, not bugfixes, and
they can't be backported without basically replacing 0.1.0.x with
IMO, we are _not_ doing people a favor by keeping support for 0.1.0.x:
it is insecure, buggy, and old.
Thus, in a few months (say, on 1 August or 1 September), I propose
that we drop support for v1 directories.  The authorities, instead of
generating full v1 directories, will serve empty directories instead,
so that caches will not propagate stale information.  This will make
0.1.0.x clients download empty directories, and fail to build circuits
until their users upgrade to 0.1.1.x.
At the same time, there's another transition to make in directory
information: Check out proposal 104.  We're going to move the fields
"read-history" and "write-history" (which currently are only used by
some tools, and are not used by Tor iteself) into a separate
"extra-info" document that not everybody downloads.  This will cut
down on directory bandwidth, _a lot_, since those fields are very
If you are maintaining a tool that uses v1 directories or the
*-history fields, you'll need to switch to use v2 directories and
extra-info documents.  I'll try to ease the transition as much as I
can, possibly by writing a script to cobble the contents of a Tor's
cache into some semblance of a v1 directory.
I'm not proposing this lightly; I really hate dropping support for old
versions.  Nevertheless, I think we need to do this soon: to limit the
bandwidth demands on directory servers; to continue to improve the
network's security; to avoid bloating our code with backward
compatibility hacks indefinitely; and to ensure that users running
ancient insecure software don't get hurt by it.
Please let me know if for some reason August 1 is too late for you; if
you've got compelling reasons, I'll push the date back to September 1.
Please also let me know if I'm being totally insane here.  :)

@_date: 2007-11-08 10:28:30
@_author: Nick Mathewson 
@_subject: suspicious log warning messages 
[...]
There's a new v3 directory authority, "ides", run by Mike Perry.
Apparently, adding it caused some weird bug to show up in the new
certificate download code.  See Flyspray bug 546.

@_date: 2007-10-31 23:30:05
@_author: Nick Mathewson 
@_subject: peculiar 0.2.0.9-alpha behavior this a.m. 
[...]
Hi, Scott!   I'd suspect a bug in 0.2.0.9 alpha; I'm not aware of any
authority bug.
Unfortunately, the log messages still leave me clueless as to what's
going on.  If this happens again, can you:
   A) Make a copy of cached-descriptors* and cached-consensus, so
      that the state can be reproduced to try to investigate what's up.
   B) If possible, log at info for a while: it says a lot more about
      what's happening with downloads.
I'm going to try to make those "Not enough info" messages more useful
in the next alpha; sorry I can't figure this out just now.

@_date: 2007-10-31 23:32:22
@_author: Nick Mathewson 
@_subject: peculiar 0.2.0.9-alpha behavior this a.m. 
============================== START ==============================
 [...]
Hey, it's not _our_ fault if we don't introduce enough bugs when we're
adding features to the alphas. ;)

@_date: 2007-10-11 18:18:59
@_author: Nick Mathewson 
@_subject: Bug: main.c:344: connection_stop_writing 
FWIW, I think I've just fixed this.  If the bug recurs in
0.2.0.8-alpha or later, please let us know.  For the gory details, see
the last two comments on bug 451 (link above).  The patch was r11882.
Wow, that's a lot!  We've fixed a few memory leaks recently; let us
know if 0.2.0.8-alpha is better.
That will probably have to wait for 0.2.1.x or later; right now, we
use extra CPUs for RSA, and not much else.  The logical next step is
to use them for AES too, but that will require a bit of refactoring in
how we do our circuit crypto.
(Anybody who feels like hacking on this, let me know.)

@_date: 2007-10-16 09:59:44
@_author: Nick Mathewson 
@_subject: 0.1.2.18 is getting close to ready; please test it 
Thanks!  I believe I've backported fixes for these; please let me know
if the problems are still there.

@_date: 2007-10-18 14:15:12
@_author: Nick Mathewson 
@_subject: tor-ctrl v1 - setting bandwidthrate from commandline via controlport and many, many other possibilites... 
Nobody's reported any bugs, and the script is working fine for me, so
I've added it to the contrib directory for the 0.2.0.x series.  I
edited the file a little to make it fit in 80-column terminals, but
otherwise, it's unchanged.  Thanks!

@_date: 2007-10-24 22:53:58
@_author: Nick Mathewson 
@_subject: Compile Error with svn rev. 12170 
Thanks!  I think I just fixed this; let me know if it's still broken?

@_date: 2007-10-26 18:29:43
@_author: Nick Mathewson 
@_subject: Random names for tor nodes? 
The fingerprints do this just fine: if don't mind using a unique and
hard-to-remember nickname, just refer to it by its hexadecimal

@_date: 2007-10-27 18:44:14
@_author: Nick Mathewson 
@_subject: Tor 0.2.0.9-alpha is out 
There's a deeper problem at work, too; I've added this as Bug 538:

@_date: 2007-10-29 15:21:42
@_author: Nick Mathewson 
@_subject: compile errors with MinGW at revision 12267 
This should work better now; thanks.
BTW, if anybody can figure out how to get buildbot running under
mingw, let me know: I'd really like to add a windows buildbot to catch
stuff like this.

@_date: 2007-10-01 21:24:09
@_author: Nick Mathewson 
@_subject: latest svn rev 11720 become cpu hungry 
Actually, I think this is an old bug; let me know if r11738 is any
better?  I found a nasty issue in router_parse_list_from_string that
gave O(n^2) performance in some cases.
Unlikely; the only 64-bit optimization was in digest-to-hash
calculation, and the 32-bit code there remained unchanged.

@_date: 2007-10-02 13:30:35
@_author: Nick Mathewson 
@_subject: latest svn rev 11720 become cpu hungry 
Short version: There was an optimization that worked around it, but
that optimization no longer applied.
Long version: The format of a "router list," as we parsed it used to
     (ExtraInfo | RouterDesc)*
In other words, it had any number of extrainfo and routerdesc
documents, possibly scrambled up.
The old code did:
   - If we start with the word extra-info, it's an extra-info and
     we're done.
   - If we start with the word router, it's a routerdesc and we're
     done.
   - Otherwise, scan for the first instance of the word router and
     scan for the first instance of the word extra-info.  Whichever
     comes first is the next document.
This was fine until we added annotations around r11680.  The format
    (Annotation* (ExtraInfo | RouterDesc))*
Now, the first two cases no longer applied when there were
annotations, since the point where we were looking never started with
the word router or the word extra-info, so we always did case 3.
But in a list like the cached-descriptors list that has no extra-info
documents, we wound up scanning the entire list looking for an
extra-info that never existed, and we did this scan for every router
in the cache.  That's O(n^2) in cache size, and that's no good.
For the fix, see the patch. :)

@_date: 2007-09-13 11:59:25
@_author: Nick Mathewson 
@_subject: end-to-end encryption question 
[Lines re-wrapped.]
Any MITM that can alter unencrypted data in order to make it unusable
can also alter encrypted data in order to make it unusable, surely?

@_date: 2007-09-13 12:07:08
@_author: Nick Mathewson 
@_subject: end-to-end encryption question 
[lines re-wrapped]
Nobody is supposed to translate the destination address to
127.0.0.1...  Oh!  I see what went wrong here.  "The local host" is
not the same as "localhost", but the instructions should be a lot more
clear about that point.
The paragraph quoted above is about publicly visible webservers:
Suppose for example that you have a webserver running at IP 1.2.3.4.
Suppose that there is also a Tor exit at 1.2.3.4.  If your webserver
is configured to reject requests from 127.0.0.1, that's fine.  If your
webserver is configured to reject requests from 1.2.3.4, that's no
No.  127.0.0.1 is a private address; your public IP is not private.
The default behavior is direct HTTP requests to directory servers.
AllDirActionsPrivate, I believe.

@_date: 2007-09-16 13:15:42
@_author: Nick Mathewson 
@_subject: Tor DIRs changed? 
There are 5 directory authorities.
The first and third you listed above moved in May:
    (Roger needed to relocate the computer.)
The reason that none of these are giving you a list of nodes by
requesting the url "Tor" is that you're using an obsolete format:,

@_date: 2007-09-04 19:27:12
@_author: Nick Mathewson 
@_subject: tor 0.1.2.17 server died after only a few hours 
Is anybody else seeing this?
Can you get a stack trace?

@_date: 2007-09-21 15:04:46
@_author: Nick Mathewson 
@_subject: Load Balancing 
Damn, that slide (on overview.html) is so wrong.  I can't believe
nobody's noticed this before. :(
For more accurate info, see path-spec.txt (section 1 and section 3)
and the design paper (subsection entitled "Circuits and streams" and
subsection entitled "Opening and closing streams").
Short answer: Tor tries to group many streams on a single circuit.  If
we didn't, that would be way too much PK.

@_date: 2007-09-05 11:35:37
@_author: Nick Mathewson 
@_subject: tor 0.1.2.17 server died after only a few hours 
The test you mention above doesn't exist in 0.1.2.17.  Is it possible
you have source for a later version (0.2.0.x) intead?

@_date: 2007-09-06 12:32:17
@_author: Nick Mathewson 
@_subject: tor 0.1.2.17 server died after only a few hours 
On further consideration, this looks exactly like Bug 406 on the bug
  (  )
This is a tricky one; something to do with the way we handle "linked"[*]
directory connections on 0.1.2.x servers seems to be broken; I'll try
to track it down.  (It seems like we're mis-managing the
blocked_on_or_conn field somehow; see bug report for more details.)
As a workaround, I believe that this bug doesn't appear in the
0.2.0.x-alpha series so far; if you want to try one of those, it may
work better for you.  On the other hand, it might do worse; it _is_ an
alpha after all. :/
[*] (We used to call these internal directory connections "bridged"
  instead of "linked", but we changed the word when we introduced
  "bridge servers" in 0.2.0.x, because we wanted to avoid confusing
  people.)

@_date: 2008-04-18 09:38:57
@_author: Nick Mathewson 
@_subject: [OT] mitigating or defeating syntax analysis 
The Wikipedia "Stylometry" article is also not totally useless here.
Also, this should be obvious, but it's important to test any approach
you consider adopting here against actual stylometry tools and
techniques.  Some of the suggestions on this thread are plausible,
whereas others are pretty unsuitable to resisting the more successful
approaches in this field.

@_date: 2008-08-16 11:30:24
@_author: Nick Mathewson 
@_subject: The "de-Tor-iorate Anonymity" talk by Nathan Evans at DEFCON 16 
[...]
What was his rationale for saying that this would help?

@_date: 2008-08-16 11:34:38
@_author: Nick Mathewson 
@_subject: MaxOnionsPending questions 
Neither.  It means incoming CREATE request payloads.
(Why "onionskin"?  In the original Onion Routing designs, "onions"
were structures made with multiple nested PK encryption and used to
create circuits.  In Tor, circuits are built interactively, one hop at
a time, in order to get forward secrecy and (trivially) prevent replay
attacks.  Instead of sending an entire onion, we send one layer of the
onion --or onionskin-- at a time.)
These are all good questions!  Pending onionskin requests are managed
in the cpuworker.c file, but I don't think high-water marks are
tracked.  A patch to handle this better would be welcome.

@_date: 2008-08-20 17:31:20
@_author: Nick Mathewson 
@_subject: DNS lookup types 
It can be.  Somebody would need to write a proposal (see the process in
  ) for it and implement it.  This would be a good project for somebody
who wanted to get familiar with the Tor internals.

@_date: 2008-08-21 12:19:27
@_author: Nick Mathewson 
@_subject: [OT] Off-topic posts 
(I haven't run this post by anybody else, so I'm speaking for myself
  at the moment.)
I second that.

@_date: 2008-08-07 15:03:34
@_author: Nick Mathewson 
@_subject: exit node "tortila" adds material to www.barnesandnoble.com home page 
Yep.  If the exit node doesn't create this failure mode for every
attempt to load the page, then this might conceivably be another
occurance of the mysterious bug 779:
   I've got a possible fix checked in to trunk, but nobody has replicated
the bug well enough to confirm that the fix makes the bug go away.
Nevertheless, since the fix does indeed fix a real problem in the code
that is consistent with what we know about bug 779, I think we should
backport it anyway.

@_date: 2008-08-07 18:13:42
@_author: Nick Mathewson 
@_subject: Tor 0.2.0.30 does not bootstrap when "FastFirstHopPK 0" in torrc file 
Looks like a bug.  I've added it to flyspray as bug 797:

@_date: 2008-08-08 14:29:22
@_author: Nick Mathewson 
@_subject: torrc file changes and features - reversal request & possible bug. 
[...]
Hi, Anon Mus.
Tor has never deleted comments on its own, unless a controller tells
it to save configuration changes.  However, Vidalia has never
preserved comments when saving configuration changes.  This isn't new
to the (rather old) 0.1.2.19.
I agree that it would be awesome to Preserving comments when altering a configuration file would be great,
but it turns out to be pretty hard.  We'd have to change the way that
Tor processes configuration files in order to detect comments before
options, and keep comments with their associated options, and keep
options in the same order, and detect where to insert new options in
order to minimize confusion.
It would be neat to do something like this, and I bet the Vidalia team
might be interested in patches to do it.
Does this still happen with any recent version of Vidalia?  If so, it
should go onto the vidalia bugtracker.

@_date: 2008-08-10 17:15:02
@_author: Nick Mathewson 
@_subject: Stop rotating circuits 
Does setting MaxCircuitDirtiness very high not do what you want?

@_date: 2008-12-12 11:11:51
@_author: Nick Mathewson 
@_subject: [Fwd: (Probably) a known problem?] - cant run a relay node 
[...]
These bugs are now fixed in svn trunk, I think.   The fixes should be
in 0.2.1.9-alpha, assuming that the fix was really a fix.

@_date: 2008-12-12 11:19:57
@_author: Nick Mathewson 
@_subject: [Fwd: (Probably) a known problem?] - cant run a relay node 
[...]
This was bug 691; it should be fixed in 0.2.1.9-alpha when it comes
  This is probably a good time for me to encourage people to use the
bugtracker at bugs.torproject.org to report and track bugs.  It lets
us do a better job of collecting and consolidating information about
each bug, and of making sure that nobody forgets about it until it
gets fixed.

@_date: 2008-12-28 21:30:37
@_author: Nick Mathewson 
@_subject: Tor on Android 
Nice stuff!  A few comments.
Hm.  Libevent should be made to detect this.  Ordinarily, fd_mask is
defined in sys/select.h or something it includes.  Can you grep around
a little in the Android headers to make sure it's not defined
anywhere?  If it isn't, we can probably define it to long without
hurting anything, so long as we define NFDBITS to match.
I've changed trunk to use RSA_generate_key_ex when we have it, and to
only use RSA_generate_key on OpenSSL 0.9.7, which doesn't have
This way, we won't need to copy code from OpenSSL and make our license
even more complicated. ;)
(A reminder to folks: when you paste code that you didn't write,
please mention the fact?  Thanks!)
 [...]
I noticed in trunk that the header files didn't use a consistent macro
naming scheme, so I've switched them all to use the "_TOR_FILENAME_H"
convention, which seemed least likely to collide with anything.
Hm.  Usually if system headers are getting searched before our
headers, that's a sign that the C compiler is acting weird.  Can you
investigate this one a little more?  As you can tell, I'd like 0.2.1.x
to build out-of-the-box for Android, especially given how little code
changing seems to be required.

@_date: 2008-12-28 23:02:39
@_author: Nick Mathewson 
@_subject: Tor on Android 
If so, bionic should be changed.  But sometimes writing portable
software means building on platforms that do silly things.  If the
broken bionics are widespread, libevent could cope pretty easily,
since it only uses fd_mask for sizeof(fd_mask) which it uses to
calculate how many bytes to allocate for an fd_set.  If the code
instead just always allocated a multiple of sizeof(long) bits per
fd_set, it would be more concise anyway, and not significantly less
Yeah.  If you want to do something like this, the usual trick is to
post-process the config.h so that all the macros now start with a
common prefix that won't conflict with the regular autoconf macros.
For an example, recent libevent versions should do it right; old ones
had the same problem as Android.
 [...]
It would be neat if you sent the agcc patch upstream. :)
 [...]
Interesting!  Both were clearly errors in the source.  Both patches
are now applied.  If you're feeling brave, try configuring Tor with
the --enable-gcc-warnings option: it will warn about other compilation
issues that we might want to care about.

@_date: 2008-12-31 15:04:24
@_author: Nick Mathewson 
@_subject: SSL certificate checker plugin for Firefox? 
I haven't evaluated it closely, but the "Petname tool" for firefox may
do some of what you want.

@_date: 2008-02-17 12:03:51
@_author: nickm@freehaven.net 
@_subject: .onion sites fail to load with: (waiting for rendezvous desc) 
FWIW, it looks like Karsten maybe just fixed this issue with a patch
that went into the Subversion repository as r13540.  If anybody who's
been seeing this problem is able to try running svn trunk, it would
be great to see whether this fixes the problem.  Thanks!

@_date: 2008-02-18 13:40:09
@_author: Nick Mathewson 
@_subject: max number of file descriptors hard coded 
Thanks, Olaf!  I've added it to the bugtracker as bug 611:
   I'll try to get a fix in for the next release.

@_date: 2008-01-07 16:40:15
@_author: Nick Mathewson 
@_subject: SORBS vs Tor and the world 
We've been through this before, and so far as I know, the problems
with the SORBS Tor DNSBL remain more or less as they were before.
(I don't want to single out SORBS here; other dnsbl services for Tor
nodes have taken the same approach.)
I support everybody's right to reject anonymous email; I support
everybody's right to reject email based on any criteria they like.
It's your server.  But the last time I looked, the SORBS Tor list
tried to include _all_ Tor servers, not just the ones that are
configured to relay SMTP.
In other words, the effect of these lists is not only to block
anonymous SMTP via Tor, but also to block email from people who run
middleman Tor servers that don't deliver anonymous email at all.  That
seems pointlessly coarse-grained to me.
Now, if somebody wants to block anonymous email, and they don't mind
blocking all non-anonymous email from people running Tor servers that
don't even support anonymous email, then these dnsbls meets their
needs just fine.
On the other hand, if your only goal is to block anonymous SMTP, and
you agree that blocking all Tor servers is very overreaching, you
might instead try looking at the more targetted DNSEL service
available at
   It lets you block _exactly_ those servers that relay traffic on given
ports to your address.  For a more thorough rationale, and a fairly
detailed spec of how to make a compatible implementation, see

@_date: 2008-01-22 01:13:24
@_author: Nick Mathewson 
@_subject: Tor meetup in San Francisco this Thursday 
Hi, all!
I'll be in San Francisco for most of this week, and I thought it would
be neat to have a Tor Folks meetup on Thursday, probably in the late
afternoon or early evening.  Let me know (off-list) if there's any
interest, and I'll figure out where -- probably a coffee shop or

@_date: 2008-01-23 23:50:07
@_author: Nick Mathewson 
@_subject: Tor meetup in San Francisco this Thursday, 7pm, Sugarlump Coffee Lounge 
Hi again!  Thanks to local recommendations, we'll be meeting up at the
Sugarlump Coffee Lounge at 7pm Thursday night.  I'm planning to stick
around for a couple hours.  According to my source, they're
an okay compromise between "tolerable coffee" and "likely to have
enough space in case a bunch of people show up."
   Where: Sugarlump Coffee Lounge, 2862 24th Street at Bryant.
   When: 7pm.
   What: No actual agenda; just hanging out, meeting local Tor
     users, operators, and enthusiasts.
Hope you can make it!

@_date: 2008-01-02 10:48:54
@_author: Nick Mathewson 
@_subject: tor26 missing certificate messages today 
I finally tracked these down; for the resolution, see comments on bug 569:
  Many thanks to everybody who helped!

@_date: 2008-01-02 16:24:34
@_author: Nick Mathewson 
@_subject: [OT] more from Cryptome on NSA, Windows firewals, mail services 
He's probably referring to the "NSAKey" key in NT 4.  For more
information, see
   It's a secondary code-signing key, allegedy to be used if their
primary code signing key needed to be revoked.
If you believe Microsoft, the key was called "_NSAKEY" because it was
introduced in order to meet NSA requirements for a secondary key.
Naming things after the software or organization that requires them,
rather than after their actual purpose, is not unusual for Microsoft:
Their office XML spec is littered with stuff like the notorious
Personally, I don't believe that contemporary operating systems are so
secure that the NSA would rather have security holes custom-built for
it instead of just using the ones that are already there.

@_date: 2008-01-02 16:41:32
@_author: Nick Mathewson 
@_subject: Tsocks and DNS 
I just read through the patch, but I haven't tried it out yet.  If I'm
understanding it right, it extends tsocks so that in addition to
replacing connect() as usual, it also replaces gethostbyname(),
getaddrinfo(), and so on with versions that use Tor's resolve
facilities.  It doesn't support reverse lookups.
There are some weird bits to the code: the authors seem to be unaware
of AutomapHostsOnResolve -- or maybe they didn't want to rely on
having it turned on.  In any case, they duplicate its functionality in
something they call a "deadpool."
They don't say what license their code is distributed under.
Honestly, I'd test it out and see whether it works with any given
application.  For some applications, this approach will work; for
some, it won't.
You might also want to try recent alpha Tors' DNSPort feature; if you
can get an application to use Tor as your resolver, you can be very
sure indeed that no data is being leaked.

@_date: 2008-01-02 16:52:41
@_author: Nick Mathewson 
@_subject: Tsocks and DNS 
[...] I spoke too soon.  tsocks is under GPLv2, and they distribute a
patched tsocks with the license in place.
Honestly, I don't want to make it sound like there's anything wrong
with this code; DNS APIs a royal pain in the neck to implement, and
DNS logic is a pit of nasty exception cases and things you were
assumed to know.

@_date: 2008-01-02 17:08:32
@_author: Nick Mathewson 
@_subject: Your computer is too slow to handle this many creation requests! 
Yeah, this _is_ a problem.  I'd like to get it so that AES is also
parallelized (since AES is where a well-behaved Tor spends most of its
time), but the changes involved are probably tricky enough that
they'll have to wait for the next development series.
If anybody would like to mess around with this ahead of time, there's
one easy place to mess around, and one hard place to mess around:
  - The easy place is when cells are encrypted on circuits.  For a
    middleman node, this represents one AES operation out of 3.  Right
    now, it happens in relay.c.
  - The hard place is getting all openssl crypto to get parallelized.

@_date: 2008-07-19 12:50:00
@_author: Nick Mathewson 
@_subject: Mixed pages - serious bug of tor 
Since this is getting discussed on IRC, and or-talk, and other email,
I think we should start collecting all the info we have in one place.
This bug is now on the bugtracker as bug 779, at
   I've got some speculations about possible causes written there, but no
hard conclusions yet.  This doesn't look like it will be an easy one
to track down, but here's some stuff that would help:
  - Debug-level logs of the error occurring.  Obviously, these need to
    be logs that start _before_ the data gets messed up.
  - The actual content of a page or file corrupted in this way.
    Screenshots are not as helpful, since it's not so easy to analyze
    what the corruption actually _is_ at the byte level once a browser is
    done rendering it.
Without more data, Roger thinks our best bet would be getting a good
test network working here so that we can reproduce the bug at an exit
node under our control and see what's happening there.  I think that
our best option (again, assuming that nobody comes through with more
data) is to look through the code until we find something that would
explain the bug.  I have a possible lead, but not a thorough enough
etiology to be sure that it's the _right_ lead.

@_date: 2008-07-30 13:53:01
@_author: Nick Mathewson 
@_subject: *Theoretical* question to the Tor project leader 
Dear Roy:
An mit.edu email address is not the same as working from MIT.  Roger
is not an employee of MIT.  Roger works for The Tor Project.  The Tor
Project is a not-for-profit corporation with no MIT affiliation.
I don't know who told you that Roger works at or for MIT, but you
should maybe stop trusting them as a reliable source.

@_date: 2008-07-31 09:22:03
@_author: Nick Mathewson 
@_subject: svn 16301 link error - undefined reference to `_tor_inet_ntoa' 
Re-run autogen.sh?  It looks like the project isn't linking against
the functions that got moved to the new address.c file, which suggests
to me that the generated makefiles might not know about it.

@_date: 2008-07-11 10:09:58
@_author: Nick Mathewson 
@_subject: question about cached-status 
Hi!  Since you replied to Roger's 0.2.0.29-rc email, I initially
assumed that you were referring to the directory protocol as used in
0.2.0.x.  For 0.1.2.x and earlier, the answers are different.  But
since your subject line says "cached-status", and that's a directory
used by 0.1.2.x and earlier, I don't know which version of the
protocol you mean.  I'll try to answer for both.
In the v3 protocol, as used by 0.2.0.x, it has an expiry time.  From
    "valid-until" SP YYYY-MM-DD SP HH:MM:SS NL
        [Exactly once.]
        The end of the Interval for this vote.  After this time, the
        consensus produced by this vote should not be used.  See 1.4 for
        voting timeline information.
In the v2 directory protocol, as used by 0.1.2.x, clients refresh
individual status documents on a rolling schedule as described in
section 5.1 of dir-spec-v2.txt.  (Caches follow the rules in section
In the v3 directory protocol, the network status document is a
multiply signed consensus that you can get from any cache.  If an
authority signing the consensus goes offline, a working consensus can
still be made as long as more than half of the authorities are
present.  If a cache goes offline, the client can get the consensus
from another cache.  (The client can tell that the cache is down when
it tries to connect there and fails.)
In the v2 directory protocol, each authority has its own view of the
network, ance clients download a view per authority from a cache.  If
a cache goes down, clients act as in v3 (they try another cache).  If
an authority is down for a long time, clients should eventually give
up trying to download that status document.  hope this helps,

@_date: 2008-07-11 11:37:04
@_author: Nick Mathewson 
@_subject: Circuit question 
First, you might be wrong about what nodes are exits.  The Exit flag
in the networkstatus document is not a perfect view of whether a node
can be used as an exit: to actually see whether
Second, not all circuits are built for delivering traffic to the
internet.  Some are built for testing tor servers, some are for
rendezvous points, and so on.  You can see circuits' purposes in
events if extended events are enabled.

@_date: 2008-07-11 15:05:48
@_author: Nick Mathewson 
@_subject: Circuit question 
[oops. Didn't end the paragraph.]
  a node can support a connection to a given service, you need to
check its exit policy.

@_date: 2008-06-18 01:20:59
@_author: Nick Mathewson 
@_subject: Tor 0.2.1.1-alpha is out 
[...]
Good point!  I think 0.2.1.1-alpha might take the wrong approach here;
If it does, I'll make 0.2.1.2-alpha smarter.  (Ah well.  That's why
it's an alpha.)

@_date: 2008-06-01 12:11:03
@_author: Nick Mathewson 
@_subject: controller GETINFO ns/id/fingerprint "s" record 
See  ,
section 4.3 and section 5.1.  See also the FetchDirInfoEarly option.
No.  GETINFO commands do not influence the download schedule.

@_date: 2008-03-20 11:04:09
@_author: Nick Mathewson 
@_subject: Tor Project accepted to Google Summer of Code 2008! 
Great news, folks!  Once again, with help from the amazing folks at
the EFF, the Tor Project has been accepted as a mentoring organization
in Google's Summer of Code[1].  This program funds students to work on
open source and free software projects over the summer, and provides
organizations like ours with a chance to work with great and
enthusiastic coders from around the world.
Many thanks first to Google for the opportunity, and to EFF for their
continuing help and support.  We'd also like to thanks everyone in the
Tor community who agreed to help mentor students with us this summer,
especially those who contributed to our project ideas list[2].
If you're a student interested in working with the Tor Project under
the Google Summer of Code program this year, please check out Google's
FAQ[3] for the program, and the Tor Project's GSoC 2008[4] page for
more information. If you have any questions that aren't answered
there, just stop by our IRC channel and ask. We look forward to seeing
you there!  (If you know students with a knack for software who'd like
a fun summer job, please let them know about this too.  The more
students who apply for Tor, the more we are likely to be assigned.)
The FAQ has more information about how to apply.  Google will start
accepting applications on March 24.  The deadline is March 31 at 5
pacific time.
Also, be sure to check out the other great organizations[1] who will be
mentoring students this year.
{A version of this mail first appeared at blog.torproject.org [5].}
[1] [2] [3] [4] [t]

@_date: 2008-03-22 10:43:50
@_author: Nick Mathewson 
@_subject: About the MapAddress option 
Sure.  Just do Mapaddress 1.2.3.4 1.2.3.4.servername.exit
This will effect all connections to 1.2.3.4, not just those to port 22.

@_date: 2008-03-22 11:04:17
@_author: Nick Mathewson 
@_subject: Another MapAddress option 
When Tor needs to build a new path for a stream, it checks whether it
already has a circuit open that will work for that stream.  If there
is already a clean open circuit that could be used, Tor uses that.
It might be neat to add some way to indicate that some addresses or
domains shouldn't share circuits with others.  If anybody wants to
work on this (maybe as part of a gsoc project), that would be pretty neat.

@_date: 2008-03-22 11:13:10
@_author: Nick Mathewson 
@_subject: Proposal: Incorporate Unreachable ORs into the Tor Network 
Hi, Robert!  I think this is definitely a step in the right direction,
with some tricky issues associated with it.  In particular, it
represents a big deviation from Tor's current clique topology.  We
should definitely drop the clique assumption (for scaling reasons if
nothing else) at some point, though, and there's no reason it can't be
Send it to or-dev and let's talk about it there?

@_date: 2008-05-22 09:00:18
@_author: Nick Mathewson 
@_subject: controller GETINFO ns/id/fingerprint "s" record 
In particular, it's used to try to predict which nodes will have most
of their bandwidth used in being an exit, in order to avoid using up
their bandwidth with relay traffic.  See path-spec.txt.

@_date: 2008-05-22 09:07:13
@_author: Nick Mathewson 
@_subject: a serious TOR adversary? 
See also Locating Hidden Servers by Lasse O/velier and Paul Syverson,
which motivated Tor's guard node design.

@_date: 2008-05-27 15:11:47
@_author: Nick Mathewson 
@_subject: Fwd: Logistics of International Policy Restrictions (project liberation) 
[...]
Wilfred might have erroneously thought that IBB is part of the state
department.  That's a pretty common misconception.

@_date: 2008-05-27 17:05:06
@_author: Nick Mathewson 
@_subject: Weird-looking circuits in Vidalia 
[...]
 [...]
Good idea; I think I should have this working in svn (and on the
0.2.0.x branch) now.  Controller developers: please try it out and see
if it does what you'd like?

@_date: 2008-05-14 10:10:28
@_author: Nick Mathewson 
@_subject: "unnamed" exit nodes 
I don't know offhand for Vidalia, but for Tor, just refer to nodes by
their key fingerprint, sticking a $ before the fingerprint,
as in:
EntryNodes $70A08C76BCB9ADE55907029B83DB6891957AC92C
If you want to force a given name binding, you can use the format
  $70A08C76BCB9ADE55907029B83DB6891957AC92C=peacetime
to only match a "Named" server with the given nickname and key, or
  $70A08C76BCB9ADE55907029B83DB6891957AC92C~peacetime
to match any server with the given nickname and key.
This feature could be better documented, though, and I'd love to get a
documentation patch to explain all of this better. :)

@_date: 2008-05-14 10:12:21
@_author: Nick Mathewson 
@_subject: [nickm: Re: Question] 
Oops; sent last reply from an unsubsribed address.

@_date: 2008-05-15 01:44:53
@_author: Nick Mathewson 
@_subject: Exit node's IP 
You can get current circuits by watching circuit events, or by looking
at the results of GETINFO circuit-status.  From there, you can get the
IP of the last node of a given circuit by looking up that node's
server descriptor with GETINFO desc/...  , or just looking it up in
the latest consensus.
If you want to know the exit node for a given stream, also check out
streams as they attach to circuits; see control-spec.txt for full
Remember, there's more than one "the current exit node IP".  Tor can
(and often does) have multiple circuits open at once, in use for
different purposes and for different time windows.
It's useful for some purposes; just not yours.  "GETINFO address" is
good for helping the user figure out what external address Tor has
guessed for the server.  If you're behind any interesting kind of
firewall, determining this is not completely obvious.

@_date: 2008-11-09 22:12:19
@_author: Nick Mathewson 
@_subject: SANS Paper: Detecting Tor 
Cosmetic issues:
   1) It's "Tor", not TOR.
   2) The paper cites the website rather than any of the actual
      published academic papers on Tor: lame.
   3) The paper doen't say when the research was done or what version
      of Tor was used, so it may not be _inaccurate_ so much as
      outdated.
Actual issues:
   The Tor-detection method described in this paper involves looking
   for a string in the outgoing connections.  You wouldn't know it
   from reading the paper, but the string in question is part of the
   CNAME field of a certificate sent from a client to a server.  We
   don't follow that protocol any more; in particular see proposal 124
   and proposal 130.
Where Tor stands today:
   We're a lot better at avoiding dumb regex-matching attacks in the
   Tor protocol than we were before.  When an 0.2.0.x client is
   talking to an 0.2.0.x server, there should not be any regular
   expressions that can be used to distinguish the data stream from a
   regular HTTPS session.
   (Some may remain; we may have missed some details.  Nonetheless,
   the approach described in this paper doesn't work on any recent
   version of the Tor protocol.)

@_date: 2008-11-09 22:19:06
@_author: Nick Mathewson 
@_subject: any middlemen seeing DoS currently? 
Judging by the timing, I'd think it might be related to a bug we only
uncovered on Friday.  Why Friday?  That was the first time that a
directory authority's certificate expired before it could be replaced.
The bug was that clients repeatedly asked directory caches for a new
certificate over and over, without noticing that they were getting
something expired and deciding to wait for a while.
That bug should be fixed in newer versions of Tor.  Also, all the
authority operators should (if we can make them) get way more careful
about checking certificate expiry times.

@_date: 2008-11-11 10:36:39
@_author: Nick Mathewson 
@_subject: Problems runing Tor on Vista x64 
There are two errors here:
  - The above error message is totally useless.  Future versions of
    libevent should give a better error for this case.
  - The error above usually happens when your firewall or "antivirus"
    software is blocking connections to 127.0.0.1 (that is, it's
    blocking connections from your computer to your computer).  This is
    pretty broken.  First, check if your firewall software is up to date.
    (This is windows, so you might need to randomly reboot.)  Second,
    check whether you can tell it to allow Tor to connect to localhost.

@_date: 2008-11-13 11:53:33
@_author: Nick Mathewson 
@_subject: Any plans to fix tor for OpenDNS? 
The problem isn't that Tor is unfriendly with OpenDNS.  The problem is
that OpenDNS is unfriendly to the Internet.  Tor is giving you those
warnings becaue OpenDNS is intentionally giving false answers to its
questions.  I've heard that OpenDNS has a "tell me about real DNS
records, not about your own fantasy version of DNS" option somewhere
in its configuration settings; if it does, you should probably set
it so that Tor is getting the real DNS hierarchy.

@_date: 2008-11-17 15:00:07
@_author: Nick Mathewson 
@_subject: Tor cleverness? 
Welcome to Unix. :)
A file on Unix exists independently of its location in the directory
hierarchy.  This is why you can have multiple "hard links" on the
filesystem all pointing to the same underlying file.  Programs that
have opened the file keep reading or writing to the same file even if
it is moved... or deleted.  For more information, look up "inodes".
If you want to rotate your logs, sent a HUP signal.  Tor will treat
this as a sign to close and reopen them, thereby creating new files if
you have moved the old ones away.
It should.  Looks like there was a bug; I've checked in a fix.

@_date: 2008-10-21 17:57:44
@_author: Nick Mathewson 
@_subject: php hex code for cookie authentication to controller? 
What's the actual length of $auth_value?  If it's not
AUTHENTICATION_COOKIE_LEN (32, I think), that's when I'd expect that
Also, I don't know PHP so well, but maybe you should specify 'rb'
instead of 'r'.

@_date: 2008-10-21 20:06:45
@_author: Nick Mathewson 
@_subject: php hex code for cookie authentication to controller? 
D'oh!  I didn't read the code closely enough: Try omitting the quotes.
They're only for sending a literal value.

@_date: 2008-09-24 11:46:29
@_author: Nick Mathewson 
@_subject: Does TOR use any non-ephemeral (non-DHE) ciphers? 
This isn't news.  If you have compromised a private key used for SSL
sessions, and a ciphersuite without PFS is used, you can decrypt those
sessions after the fact.  That's basically what "without PFS" means.
You mean ciphersuites, not ciphers.  The answer is "No; Tor always
uses ephemeral-key modes with TLS."

@_date: 2008-09-05 11:08:39
@_author: Nick Mathewson 
@_subject: Google's Chrome Web Browser and Tor 
I dig what I've heard of the Chrome architecture, but it seems clear
that, like every other consumer browser, it's not suitable for
anonymous browsing out-of-the-box.  The real question will be how easy
it is to adapt it to be safe.  Torbutton, for instance, has proven to
take some pretty extreme hackery to try to shut down all of Firefox's
interesting leaks.  If it turned out to be (say) an order of magnitude
easier to extend Chrome to be anonymity-friendly, that would be pretty
awesome.  We'll see, I guess.
Has anybody looked into Chrome's extension mechanisms?  It would be
neat to know how hard it would be to address the information leaks
addressed in, say,  .

@_date: 2008-09-11 23:14:06
@_author: Nick Mathewson 
@_subject: Tor 0.2.1.5-alpha is out 
Hm.  If it's treating warnings as errors, you'll need to stop passing
--enable-gcc-warnings to ./configure for the time being.
I think I fixed this warning in r16759; if you can fetch trunk from
the Subversion repository, it would be good to know whether the
warning is gone for you now.

@_date: 2009-04-24 09:07:09
@_author: Nick Mathewson 
@_subject: Be ready: We're switching version control systems 
Hello, everyone!  Sometime in the next week or two, I am planning to
move the repository for Tor software from Subversion to Git.  This will
only affect the Tor program itself -- other software in the Tor
Project's Subversion repository will stay where it is for now.
WHAT DOES THAT MEAN?
When we develop software, we use a tool called a version control system
to keep track of all of the changes we have made to it.  Right now, we
use Subversion, which is a pretty conservative centralized version
control design: it manages everything in a big repository on our
Subversion server.  We're switching to Git, which is a decentralized
version control system (DVCS): it allows for many repositories existing
in parallel on different computers.
For more info on Git and its advantages, see  .
We're mainly switching for:
- Better support for branch merging.
- Better support for distributed collaboration.
- Better support for offline development.
- Better support for security fix development.
- Cryptographic confirmation of repository integrity.
- Yes, we'll back up before we start.
- No, I don't know which day the switch will happen on yet.
- No, the website is not moving out of svn.
- Yes, this might be a good time to think about the story of the bike shed.
  [
HOW DOES THIS AFFECT YOU?
== If you download Tor as a package
  It doesn't affect you at all, except inasmuch as it helps us develop
  Tor more effectively and get you better work faster.
== If you have been tracking Tor from subversion, but not changing it
  Instead of checking out the repository using "svn checkout", you'll
  clone it out with "git clone".  Instead of saying "svn update" to
  see the latest version, you'll say "git pull".
== If you have been writing patches for Tor against subversion, and
   mailing them in.
  As above, you'll need to use git to get the latest development
  version, not subversion.  If you do your work on a local git branch,
  though, you have a better ability to make sure that your patches
  form a logical sequence, and that they apply cleanly against the
  latest Tor before you send them in.
  Of course, you can still just do your patches against a working copy,
  use "git diff" to generate a patch, and email it in.  Just because
  you have support for local branches and versioning doesn't mean you
  need to use it.
  We'll be glad to work with people on the mailing lists and the IRC
  channels to help folks transition along with us.  I'll be sending out
  links to more detailed instructions as the transition occurs.
For more reading on Git, see:
The Git Tutorial
    Git for Computer scientists
  The "Everyday Git" quick-reference:
  Git for SVN users:
  Two very opinionated Google Tech Talks talks about Git:
  Randal Schwartz:
       Linus Torvalds
     Our handy repository of (supposedly) useful Git tools.
  git://git.torproject.org/git/githax
See in particular the documentation on using Git with our Thandy
project; the instructions for Tor should be similar.
  And of course, the delightful Git Manual:

@_date: 2009-02-21 14:25:53
@_author: Nick Mathewson 
@_subject: Segfaults on tor-0.2.12-alpha and  tor-0.2.0.34 
[...]
Can you get a stack trace?  See
 if
you're not sure how.

@_date: 2009-02-10 01:49:55
@_author: Nick Mathewson 
@_subject: another BADEXIT found $8424E8653469B1EFF87E79E8599933A3BAF8FDB2 
[...]
Internally, this ability exists.  In the relevant configuration file,
authority operators can mark entire IP ranges as BadExit.  This
doesn't get propagated to the consensus; instead, they automatically
vote for any OR that shows up in a marked IP range as being BadExit.
The result's the same, but the client code and the consensus format
get to stay a little simpler.

@_date: 2009-02-10 15:41:37
@_author: Nick Mathewson 
@_subject: Grrr...SafeLogging doesn't work in 0.2.1.12-alpha :-{ 
[..]
No need; I've just done the fix in svn r18480.

@_date: 2009-02-10 22:26:12
@_author: Nick Mathewson 
@_subject: Some Bones to Pick with Tor Admins 
As Martin notes, privoxy won't modify your SSL connections for you.
Torbutton protects against many other attacks that regular Firefox
configuration can't protect you against, too.  See the Torbutton
design document at  for a
more full list.

@_date: 2009-02-10 23:05:59
@_author: Nick Mathewson 
@_subject: Tor on win98 [was Re: Some Bones to Pick with Tor Admins] 
Dear Mark,
I remember back in 2005 when Tor broke on windows 95 for you.  Back
then, you didn't call us names.  Instead, you told us what errors you
were getting, which versions worked for you and which didn't, and
helped debug the problem.  That worked out great, IMO.
Here's the thread:
    As Roger noted, we are perfectly glad to keep Tor working on older and
stranger platforms than yours.  Heck, we've taken patches to get Tor
working on IRIX and AIX.  And you don't need to be able to write code
to contribute!  If a win98 user with decent debugging skills (you?)
would like to help us figure out what exactly broke Tor on win98, I
would be glad to try to help figure out what's needed to fix it.
To be clear, you're saying that 0.2.0.32 worked, but 0.2.0.33 didn't?
And you're saying that there is no useful error message, just a crash
with a GPF message?  One very interesting part of your first message
was when you said, "not within vidalia."
(If anybody else has a copy of win98 they can fire up, and they want
to help track this down, then the more the merrier.  Alternatively, it
might be useful for somebody who knows windows history to look through
the code that changed between the affected versions, or to look at any
changes in the build methodology between the affected versions, or
BTW: Please knock it off with the insults.  They don't make me develop
any better or faster, and they don't make the list a better place.

@_date: 2009-01-14 12:37:00
@_author: Nick Mathewson 
@_subject: cannot compile 0.2.1.10-alpha 
It would also be helpful to have a copy of the config.log script that
configure generated, since something seems to have gone wrong there.
The file torint.h is only supposed to define ssize_t if the platform
has no ssize_t, but it seems that yours has one in sys/types.h that
autoconf did not detect.
(The config.log file will be very big.  Please do not email it to the
whole list.  Just compress it and send a copy to me and coderman, if
you could.)

@_date: 2009-01-19 17:13:45
@_author: Nick Mathewson 
@_subject: tor over ipv6 
No.  Right now, it doesn't work at all with IPv6.
There are two kinds of ways Tor might support IPv6: first,  ......
Hang on!  This is a FAQ!  The state of, and issues surrounding,
IPv6 in Tor are explained here:

@_date: 2009-01-20 23:03:40
@_author: Nick Mathewson 
@_subject: command line control software 
Check out contrib/tor-ctrl.sh in the Tor source distribution.  It may
need some hacking to do what you want, but it should be a good start.
If you come up with any improvements, feel free to send us patches.

@_date: 2009-01-21 01:29:58
@_author: Nick Mathewson 
@_subject: cannot compile 0.2.1.10-alpha 
If the failure ever happens again, please save the config.log so we
can get a better idea what's going on.
I'm afraid I don't know what's up with your other issue.  Could it be
some kind of resource exhaustion thing?  I didn't think that XP Server
had that kind of problem.  The diagnostic and workaround approaches
people discussed at bug 98 may be apropos.
(That reminds me: I must get back to libevent hacking!)

@_date: 2009-01-23 17:45:51
@_author: Nick Mathewson 
@_subject: Lame and unimportant 
Patched, thanks!
(Apparently I can't detect triple-letters.  I stared at your message
for about 60 seconds trying to figure out what the problem was.)

@_date: 2009-01-07 14:45:28
@_author: Nick Mathewson 
@_subject: tor controlport wants authentication even if authentication is switched off 
[...] Even if authentication is turned off, the first command on the control
connection needs to be "AUTHENTICATE" (or "PROTOCOLINFO").  This is a
fix for a neat cross-protocol attack where the attacker tricks your
web browser into talking to the control port and generating a string
where most of the lines are ignored, up until the lines the attacker
actually generated.

@_date: 2009-11-11 21:15:20
@_author: Nick Mathewson 
@_subject: TLS Man-In-The-Middle Vulnerability 
Indeed it will not.  We have a fix in svn to make the 0.2.1.x and
0.2.2.x-alpha series both work correctly with OpenSSL 0.9.8l.  With
any luck, we should get releases out before too long.

@_date: 2009-10-18 19:05:28
@_author: Nick Mathewson 
@_subject: 0.2.2.5-alpha doesn't know how to make libtor.a 
I can't reproduce this; can you say more about your toolchain?  What
OS are you getting this on?  Whose make are you using, and what
version?  If it isn't gmake, does trying gmake[*] cause the problem to
go away?
Does anything happen if you edit src/or/Makefile.in to replace every
reference to "./libtor.a" with one to "libtor.a" , then run configure
[*] It wasn't our intention to require gmake; but learning that we
    broke non-gmake builds would be a good step to diagnosing what's
    wrong.

@_date: 2010-08-13 10:46:53
@_author: Nick Mathewson 
@_subject: Vulnerability in OpenSSL 1.0.x & Firefox 4 Silent Updates 
Looking at the claims, it seems to only affect OpenSSL 1.0.0a and
maybe 1.0.0.  (I can reproduce it with 1.0.0.a, but not with 0.9.8x
and earlier.)   None of our binary packages ship with any version of
OpenSSL 1.0.x (unless I'm missing something), so people using our
binaries are probably safe.  I'll ask around harder later today to
make sure everything is in fact getting built in conformance with its
If you're using a version of openssl 1.0.0a that comes with your
operating system, with any luck your vendor will already have issued a
patch.  If not, there is an alleged patch posted in that thread at
 ; I haven't
evaluated it, and it doesn't seem to have gotten merged into openssl
proper yet, so you shouldn't apply it blindly.  It looks safe to me,
but what do I know?  Personally, I'd think re-linking your Tor against
a statically built 0.9.8o would probably be a better bet than
rebuilding your vendor openssl.
It's also possible (though not certain) that Tor could be unaffected.
If you look at the code in question, it only seems to gets invoked for
the elliptic-curve crypto case, which Tor doesn't use or enable.
OTOH, I haven't checked carefully enough to be sure there's no way to
force an openssl 1.0.0a server into that codepath if it doesn't have
any elliptic curve stuff configured, so caution is still warranted.

@_date: 2010-02-12 22:24:35
@_author: Nick Mathewson 
@_subject: ExcludeNodes setting bypassed 
I'll try to expand on the understand the bug report you are citing,
since the stuff there really _does_ explain what the problem is,
albeit in programmer-speak.
The root problem here is in the way that node selection was originally
written.  We needed to solve the question of, "what should we do when
the user requests that only certain nodes be used, and then makes a
request that those nodes cannot satisfy?"  Some examples where
excluding nodes can make it impossible to fulfill a request include:
   - Excluding a node, then choosing that node as the exit for a
particular circuit.
   - Excluding every introduction point for a hidden service, then
trying to connect to that hidden service.
   - Excluding every distributed directory point for a hidden service,
then trying to look up its descriptor.
   - Operating a hidden service, when the client picks a rendezvous
point you've excluded.
   - Trying to connect to an IP:Port when you have excluded every exit
node that would support it.
   - Trying to bootstrap when you have excluded every directory authority.
In *most* of these cases, we figured that recent requests should
override old requests, so if the user says "don't do X" and then says
"do X", they probably meant the latter rather than the former.
Similarly, we figured that people mostly wanted their requests not to
break, and would get irritated if excluding nodes meant that their
hidden service requests could break at random.  So (IIUC) we set up
the code so that some service requests that could only be granted with
excluded nodes would produce a warning rather than a complete failure.
It turns out this wasn't the choice a lot of people want: they want to
be able to say "Never ever ever use these nodes. If I ever make a
request that can only be satisfied with nodes I've excluded, reject
that request, even if it means I don't get the hidden services I want,
or I can't bootstrap, or whatever."  This isn't a crazy thing to ask
for at all.  As Andrew said, Roger's working on rewriting big chunks
of the node selection code to support this feature.  As Andrew said,
check out Bug 1090 for the details and progress.
(Another confusing aspect here is that "exclude X as an exit node" has
been taken by some people to mean that all circuits ending at X should
be verboten.  But circuits can end at a node for reasons other than
sending traffic out of the network, including accessing a hidden
service via a rendezvous point, performing a self-test, or accessing a
directory server.  Perhaps what people really want is an
ExcludeAsLastHop option, and we should build that instead.)
Another goal of the node-selection rewrite, BTW, is to simplify the
node selection process.  It's pretty complex, and there could well be
more bugs in it.  We should also work on specifying the whole thing
better, so it's easier to tell surprises from bugs; Sebastian said he
was interested in trying that out in whatever free time he has left.
So that's what's going on here.  It is not in fact, a sooper-sekrit
government backdoor.  There is not any exception for nodes in
Washington, Moscow, Area 51, or the Bermuda Triangle. It's a node
selection algorithm which was originally written with a false UI
assumption (that people would want working requests to trump
configuration settings), and which Roger's been trying to make more
like what people want.  Some of it's already rewritten in 0.2.2.x;
some will take more work.
And as for whoever thinks that Roger not getting the code rewritten
fast enough for their taste means that we're a bunch of contemptible
lying double-dealing sellouts who would sabotage our own life's-work
for whatever reason: They are mistaken.  For my part, I'd rather quit
software entirely than back-door Tor, and I believe that goes for
everybody on the project.
Sorry for the intemperate digression.
Hope this helps,

@_date: 2010-02-12 22:46:18
@_author: Nick Mathewson 
@_subject: Path-spec - fast circuits 
2010/2/12 ilter y?ksel :
First of all, "Fast" circuits are a bit misnamed as used in
path-spec.txt.  Basically, "fast" means "bandwidth-sensitive".  The
only ones that aren't don't need to be "fast" in this sense are ones
that are going to be used only for a tiny amount of traffic.
That said, I think the statement in path-spec.txt may be poor.  It
probably makes sense to weight all choices by bandwidth, now that
bandwidth is measured rather than just being self-advertised.
To see what the code is actually doing, the string to search for is
need_capacity or NEED_CAPACITY.  The most interesting layer to look
for this is at is where it's passed as a flag to
circuit_launch_by_router() or circuit_launch_by_extend_info().

@_date: 2010-02-12 22:49:26
@_author: Nick Mathewson 
@_subject: Nodes selection algorithm 
The best specification of this is in the path-spec.txt document
shipped with the Tor distribution.  It's not complete, but it's an
okay start.   There are also some relevant proposals in
doc/spec/proposals at
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-12 22:55:26
@_author: Nick Mathewson 
@_subject: What means that log record? 
It means that one part of the code said "close connection X when you
get around to it!" and another part of the code also said "close
connection X when you get around to it!"  We try not to allow this in
the code base, since a connection that's marked to be closed shouldn't
really be used in a way that would make us want to close it again.
This isn't a problem for you, since the code catches it and tries to
handle it gracefully.  It is a problem for the developers, though.
What version of Tor are you seeing these messages from?

@_date: 2010-02-12 23:07:55
@_author: Nick Mathewson 
@_subject: Bringing back Tor on the iPhone - take 2 
On Fri, Feb 5, 2010 at 6:08 PM, Marco Bonetti
Since nobody's objecting, I've removed it with 79bdfb63e9936619.  If
it turns out that we need a specific iPhone-only block at some point
in the future, we should turn it on by detecting the  iphone sdk at
compile time in the regular autoconf way.  Thanks to Marco for picking
up the ball here.

@_date: 2010-02-13 11:18:33
@_author: Nick Mathewson 
@_subject: Path-spec - fast circuits 
Right.  If I'm a Tor node, I have a better picture of my own actual
usage than any other process anywhere in the network.
But one big problem is that you have no guarantee whatsoever that I'm
telling you the truth about my measurements.  See for example Kevin
Bauer et al's "Low Resource Routing Attacks Against Tor."
As a hackish workaround, we had clipped the largest believable
self-reported bandwidth, so that a hosstile or broken server couldn't
trivially claim to have infinite capacity and attack or DOS the
network.  But this meant that genuinely high-capacity nodes got
Neither of the above points is imaginary; Bauer et al demonstrated
their attacks on planetlab, and the underutilized capacity really
(A smaller problem was that nodes were reporting their observed
bandwidth _usage_, whereas clients really care about the expected
performance of their circuits.)
Mike and others can probably talk more about the other issues here.

@_date: 2010-02-15 12:53:47
@_author: Nick Mathewson 
@_subject: getinfo circuit-status 
No;  it's the one that's considered "best" for the particular stream.
The general rule is that first, a circuit must be appropriate for the
stream (the exit policy must be compatible, the capacity must be
adequate, the nodes must be stable enough, etc).  Second, the circuit
must not be too dirty (a circuit becomes 'dirty' the first time it's
used; once it's been dirty for CircuitMaxDirtiness seconds, it
shouldn't be used for attaching new streams).  Third, a less dirty
circuit is treated as better than a more dirty circuit.
{This is based on re-reading circuit_get_best in circuituse.c.}
Yes; have your controller say "USEFEATURE VERBOSE_NAMES" early on.
(VERBOSE_NAMES is documented in section 3.19 of control-spec.txt; the
LongName format is uses is explained in section 2.4.)
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-15 14:19:24
@_author: Nick Mathewson 
@_subject: getinfo circuit-status 
[...]
If you watch for STREAM events, you'll learn which streams get
attached to which circuits.

@_date: 2010-02-03 16:00:09
@_author: Nick Mathewson 
@_subject: client bug in 0.2.2.7-alpha and a new bad exit: exoassist 
Thanks for tracking that down!  Should be fixed in 7d5d4f9f0385.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-04 20:18:57
@_author: Nick Mathewson 
@_subject: Bringing back Tor on the iPhone - take 2 
[...]
That matches with my impressions of it.  All it does is define
"__DARWIN_UNIX03" and "IPHONE".  The only place in Tor that looks at
"IPHONE" is set_max_file_descriptors, where instead of defaulting to
asking for 15000 connections, it only asks for 9999.  If the define
and the fd limit change aren't needed any more, let's kill them.

@_date: 2010-01-17 22:31:34
@_author: Nick Mathewson 
@_subject: Memory usage on relays 
It's in recent versions of OpenSSL (recent as in the 1.0.0 beta versions.)
If you would rather try patching an older version of OpenSSL yourself, try out
I have no idea whether it applies cleanly (or at all) to older versions.

@_date: 2010-01-19 11:54:13
@_author: Nick Mathewson 
@_subject: Memory usage on relays 
The failure mode is if you somehow wind up in a position where an
adversary is in control of your environment; they could  set
LD_PRELOAD or LD_PATH to whatever they wanted.
Personally, I'm not convinced that this is a reason not to dynamically
link.  Most attacks that would give somebody write access to your
environment would let them subvert your system in ways that don't
require dynamic linking. (That is, If the attacker can run arbitrary
shell commands, put stuff in your ~/.profile, or mess with your shell
process's memory, then they're in a great position whether your
binaries are static or not.)  I'm not alone in thinking this: there
are some pretty paranoid applications out there (gnupg and openssh for
example) that are happy to use the dynamic linker.

@_date: 2010-06-07 11:00:27
@_author: Nick Mathewson 
@_subject: Why not TOR come up with an encryption system? 
To be explicit about why: no encryption will actually work unless the
final party receiving your connection has the ability to decrypt it to
see what you said.   This would mean that, even if Tor had a built-in
end-to-end encryption tool, wouldn't do you any good on sites that
didn't install the tool as well.
And once we're requiring both sides of the communication to install
extra software, we might as well just have both sides just support SSL
and be done with it.  (Personally, I think that our chances are better
here if it _is_ SSL: it's easier to convince website operators to
support https than it would be to convince them to run a special Tor
decryptor, run as a hidden service, or whatever Tor-specific option we
might imagine.)

@_date: 2010-03-10 15:50:00
@_author: Nick Mathewson 
@_subject: tor 0.2.1.24 crashes on Sparc-Solaris10 
It would still help a lot if you could get a stack trace to find out
where the unaligned memory access happens.  We try to only do aligned
memory access in our code; if there's somewhere where we're doing
unaligned access, I want to find it and fix it.

@_date: 2010-03-20 01:39:08
@_author: Nick Mathewson 
@_subject: Advertising multiple ORPorts at once 
It helps with anti-censorship, not anonymity per se (afaict).  The
idea is that many hosts have more than one address, and nearly all can
listen on multiple ports.  Actually using this ability would allow a
bridge to actually accept connections at all its addresses (in the
first case) and help defeat naive port-blocking approaches (in the
It's not exactly cutting edge stuff, but every little bit can help here.

@_date: 2010-05-12 14:09:41
@_author: Nick Mathewson 
@_subject: messages indicate strange choice by tor 
Oops, just saw that nobody had answered this.  That info message is a
bit misleading; "too old" in the message should really be something
more like "unsuitable".  For the full ugly details, check out
connection_or_group_set_badness() and connection_or_is_better() in
connection_or.c.  Some reasons you might get that message is if the
older connection is canonical and the new one isn't, or if the older
one has circuits and the new one has gone 15 minutes but gotten no
circuits.  I'll fix that info message in 0.2.2.x.

@_date: 2010-11-20 22:38:23
@_author: Nick Mathewson 
@_subject: Possible fix needs testing [was Re: Problem with 'tor 
This does indeed (as stars noted) look like bug  the one that
makes Tor not work with 0.9.8p or 1.0.0b.  Sebastian and I think we
might have come up with a fix.  I've attached the (tiny) patch that
seems to work for us in testing, but which may or may not.  If you
know how to apply patches and build Tor from source, and you are
running into the problem associated with the openssl versions in
question, give it a go and see if it makes stuff better?    It should
work cleanly on 0.2.1, 0.2.2, and master.
If you prefer git, this is branch "fix2204" in my public repository.
It's against 0.2.1, but it should also merge cleanly into 0.2.2 or

@_date: 2010-11-22 10:02:40
@_author: Nick Mathewson 
@_subject: Node not listed 
This looks just like the bug I posted a patch for yesterday and asked
people to try out. The bug is  it makes routers not work when
you're on openssl 0.9.8p/1.0.0b (or another version, if your vendor
has backported the CVE-2010-3864 fix).  The patch I posted should fix
it.  You can also downgrade your openssl.  Alternatively, just wait a
little while: Roger is going to be releasing 0.2.2.19-alpha and
0.2.1.27 Very Soon Now.

@_date: 2010-11-17 11:45:32
@_author: Nick Mathewson 
@_subject: Tor 0.2.1.26-1~~lenny+1: segfault with libcryto.so.0.9.8 
Without more information, there's not much info to go on there to
diagnose the problem.  Generally, to debug a segfault, we need a stack
trace.  To get one of those, make sure you're running Tor with
coredumps enabled, and use gdb to get a trace if Tor crashes again.
There are some decent online docs on how to do this; a little
searching should turn them up.
(You can ignore the "Treason Uncloaked!" junk.  That's the Linux
kernel being overly dramatic about peers that don't do TCP windows
right or something.)

@_date: 2010-10-04 11:49:42
@_author: Nick Mathewson 
@_subject: AdvTor 
It looks like they forked some older version of Tor.  It purports to
be a forked 0.2.1.26, but lots of the comment string typos and
copyright notices from the source code don't match up to that version,
and I suspect that it's actually based on a mixture of files from more
than one Tor version.  There are indeed bugfixes from 0.2.1.26 that
seem never to have made it into the source of this thing.  Frankly,
when I run into a programmer whose first instinct is to fork rather
than to contribute, I kind of assume that they're not too familiar
with how things are done in free software, which makes me a little
Some of the stuff they added is possibly worth taking into mainstream
Tor, though we can't use their code to do it: their license says that
the changes they made in the Tor client are under the Creative Commons
Noncommercial Share-Alike license, so we wouldn't be able to use them
even if, on examination, we did like them.
The olla-podrida of different Tor source versions makes it hard to
actually tell what the changes *are*: when you run into a point where
there's a difference, you don't know whether it's just a fix from
0.2.1.26 that the author didn't feel like forward-porting, or whether
Some of the changes are downright gratuitous; It looks like they
changed the torrc comment character from # to ; because... well,
Windows, I guess.  It also looks like they ripped out a big pile of
code that wasn't built on windows because... well, it offended them or
Some of the changes are good ideas, like trying to learn time skew
(rather than just reporting it) and better handling of HTTP.  I am
pretty sure there's a security hole in the time skew learning thing if
it works how I think it does, though, and all the string handling in
buffers.c is done with the kind of character-at-a-time,
who-needs-functions thing that is error-prone even when done by good
programmers with other programmers reviewing their stuff.
So yeah.  I would not recommend this software.  If the author wants to
participate in the wider world of Tor, I would recommend that he work
on figuring out what changes he wants in Tor itself, cleaning up the
implementation, speccing out the design for security review, and
getting them upstreamed to us.

@_date: 2010-10-06 09:48:14
@_author: Nick Mathewson 
@_subject: Stop TOR from building circuits in the background? 
Keep reading control-spec.txt till you get to section 5.4.  Look at
the documentation for __LeaveStreamsUnattached and
__DisablePredictedCircuits.  You'll want both, and you'll need to use
ATTACHSTREAM to attach streams yourself.

@_date: 2010-10-07 11:11:10
@_author: Nick Mathewson 
@_subject: AdvTor 
On Thu, Oct 7, 2010 at 4:32 AM, Anon Mus
Not sure what your trouble is here, but Tor doesn't ban sites.  I just
tried connecting there, and it worked fine for me.

@_date: 2010-09-02 12:56:36
@_author: Nick Mathewson 
@_subject: tor and resolv.conf / ipv6 
Sadly, yeah.
As a workaround, if you build Tor with Libevent 2.0.x, Tor will use
Libevent's evdns code, rather than its own internal (and
lagged-behind) implementation.  Libevent 2.0's dns code knows how to
handle IPv6 addresses for DNS servers.  (You can't do this with older
versions of Libevent, since until about Libevent 2.0, Tor required
evdns features that Libevent didn't have.)
As another workaround, you can specify an alternative resolv.conf file
using the ServerDNSResolvConfFile command.
As a real fix, there are a few possibilities.
   * Port the ipv6-resolver code over from Libevent 2.  [Not going to
happen in Tor 0.2.2.]
   * Re-port the entirety of evdns.c over from Libevent 2. [Definitely
not going to happen in Tor 0.2.2]
   * Just wait until Libevent 2.0.x is ubiquitous.

@_date: 2011-04-04 22:32:13
@_author: Nick Mathewson 
@_subject: [tor-talk] Ticket #2594 (new enhancement) ["Excito needs a web 
(In reference to  .)
To the best of my knowledge, we haven't started work on it, and there
isn't a scheduled due date.  Of course, my knowledge might be out of
date. If anybody wants to get involved, that would be great.
(For what it's worth, a ticket on the bugtracker doesn't mean that
there is code, or a schedule to produce code, or even that we're sure
that we want to do with the ticket says. All a ticket means is that
somebody thought that an idea was important enough that we shouldn't
forget about it, so they made a ticket for it.
Not I, I'm afraid.  Others might know more.  I've added the title of
the ticket to the subject line, in case somebody is working on the
topic but has forgotten what 4-digit number it had.

@_date: 2011-04-29 15:14:48
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.2.2.25-alpha is out! 
============================== START ==============================
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
  Tor 0.2.2.25-alpha fixes many bugs: hidden service clients are more
  robust, routers no longer overreport their bandwidth, Win7 should crash
  a little less, and NEWNYM (as used by Vidalia's "new identity" button)
  now prevents hidden service-related activity from being linkable. It
  provides more information to Vidalia so you can see if your bridge is
  working. Also, 0.2.2.25-alpha revamps the Entry/Exit/ExcludeNodes and
  StrictNodes configuration options to make them more reliable, more
  understandable, and more regularly applied. If you use those options,
  please see the revised documentation for them in the manual page.
  For now, only the source has been uploaded.  Packages will appear
  over the next few days.
    o Major bugfixes:
    - Relays were publishing grossly inflated bandwidth values because
      they were writing their state files wrong--now they write the
      correct value. Also, resume reading bandwidth history from the
      state file correctly. Fixes bug 2704; bugfix on 0.2.2.23-alpha.
    - Improve hidden service robustness: When we find that we have
      extended a hidden service's introduction circuit to a relay not
      listed as an introduction point in the HS descriptor we currently
      have, retry with an introduction point from the current
      descriptor. Previously we would just give up. Fixes bugs 1024 and
      1930; bugfix on 0.2.0.10-alpha.
    - Clients now stop trying to use an exit node associated with a given
      destination by TrackHostExits if they fail to reach that exit node.
      Fixes bug 2999. Bugfix on 0.2.0.20-rc.
    - Fix crash bug on platforms where gmtime and localtime can return
      NULL. Windows 7 users were running into this one. Fixes part of bug
      2077. Bugfix on all versions of Tor. Found by boboper.
  o Security and stability fixes:
    - Don't double-free a parsable, but invalid, microdescriptor, even if
      it is followed in the blob we're parsing by an unparsable
      microdescriptor. Fixes an issue reported in a comment on bug 2954.
      Bugfix on 0.2.2.6-alpha; fix by "cypherpunks".
    - If the Nickname configuration option isn't given, Tor would pick a
      nickname based on the local hostname as the nickname for a relay.
      Because nicknames are not very important in today's Tor and the
      "Unnamed" nickname has been implemented, this is now problematic
      behavior: It leaks information about the hostname without being
      useful at all. Fixes bug 2979; bugfix on 0.1.2.2-alpha, which
      introduced the Unnamed nickname. Reported by tagnaq.
    - Fix an uncommon assertion failure when running with DNSPort under
      heavy load. Fixes bug 2933; bugfix on 0.2.0.1-alpha.
    - Avoid linkability based on cached hidden service descriptors: forget
      all hidden service descriptors cached as a client when processing a
      SIGNAL NEWNYM command. Fixes bug 3000; bugfix on 0.0.6.
  o Major features:
    - Export GeoIP information on bridge usage to controllers even if we
      have not yet been running for 24 hours. Now Vidalia bridge operators
      can get more accurate and immediate feedback about their
      contributions to the network.
  o Major features and bugfixes (node selection):
    - Revise and reconcile the meaning of the ExitNodes, EntryNodes,
      ExcludeEntryNodes, ExcludeExitNodes, ExcludeNodes, and StrictNodes
      options. Previously, we had been ambiguous in describing what
      counted as an "exit" node, and what operations exactly "StrictNodes
      0" would permit. This created confusion when people saw nodes built
      through unexpected circuits, and made it hard to tell real bugs from
      surprises. Now the intended behavior is:
        . "Exit", in the context of ExitNodes and ExcludeExitNodes, means
          a node that delivers user traffic outside the Tor network.
        . "Entry", in the context of EntryNodes, means a node used as the
          first hop of a multihop circuit. It doesn't include direct
          connections to directory servers.
        . "ExcludeNodes" applies to all nodes.
        . "StrictNodes" changes the behavior of ExcludeNodes only. When
          StrictNodes is set, Tor should avoid all nodes listed in
          ExcludeNodes, even when it will make user requests fail. When
          StrictNodes is *not* set, then Tor should follow ExcludeNodes
          whenever it can, except when it must use an excluded node to
          perform self-tests, connect to a hidden service, provide a
          hidden service, fulfill a .exit request, upload directory
          information, or fetch directory information.
      Collectively, the changes to implement the behavior fix bug 1090.
    - ExcludeNodes now takes precedence over EntryNodes and ExitNodes: if
      a node is listed in both, it's treated as excluded.
    - ExcludeNodes now applies to directory nodes -- as a preference if
      StrictNodes is 0, or an absolute requirement if StrictNodes is 1.
      Don't exclude all the directory authorities and set StrictNodes to 1
      unless you really want your Tor to break.
    - ExcludeNodes and ExcludeExitNodes now override exit enclaving.
    - ExcludeExitNodes now overrides .exit requests.
    - We don't use bridges listed in ExcludeNodes.
    - When StrictNodes is 1:
       . We now apply ExcludeNodes to hidden service introduction points
         and to rendezvous points selected by hidden service users. This
         can make your hidden service less reliable: use it with caution!
       . If we have used ExcludeNodes on ourself, do not try relay
         reachability self-tests.
       . If we have excluded all the directory authorities, we will not
         even try to upload our descriptor if we're a relay.
       . Do not honor .exit requests to an excluded node.
    - Remove a misfeature that caused us to ignore the Fast/Stable flags
      when ExitNodes is set. Bugfix on 0.2.2.7-alpha.
    - When the set of permitted nodes changes, we now remove any mappings
      introduced via TrackExitHosts to now-excluded nodes. Bugfix on
      0.1.0.1-rc.
    - We never cannibalize a circuit that had excluded nodes on it, even
      if StrictNodes is 0. Bugfix on 0.1.0.1-rc.
    - Revert a change where we would be laxer about attaching streams to
      circuits than when building the circuits. This was meant to prevent
      a set of bugs where streams were never attachable, but our improved
      code here should make this unnecessary. Bugfix on 0.2.2.7-alpha.
    - Keep track of how many times we launch a new circuit to handle a
      given stream. Too many launches could indicate an inconsistency
      between our "launch a circuit to handle this stream" logic and our
      "attach this stream to one of the available circuits" logic.
    - Improve log messages related to excluded nodes.
  o Minor bugfixes:
    - Fix a spurious warning when moving from a short month to a long
      month on relays with month-based BandwidthAccounting. Bugfix on
      0.2.2.17-alpha; fixes bug 3020.
    - When a client finds that an origin circuit has run out of 16-bit
      stream IDs, we now mark it as unusable for new streams. Previously,
      we would try to close the entire circuit. Bugfix on 0.0.6.
    - Add a forgotten cast that caused a compile warning on OS X 10.6.
      Bugfix on 0.2.2.24-alpha.
    - Be more careful about reporting the correct error from a failed
      connect() system call. Under some circumstances, it was possible to
      look at an incorrect value for errno when sending the end reason.
      Bugfix on 0.1.0.1-rc.
    - Correctly handle an "impossible" overflow cases in connection byte
      counting, where we write or read more than 4GB on an edge connection
      in a single second. Bugfix on 0.1.2.8-beta.
    - Correct the warning displayed when a rendezvous descriptor exceeds
      the maximum size. Fixes bug 2750; bugfix on 0.2.1.5-alpha. Found by
      John Brooks.
    - Clients and hidden services now use HSDir-flagged relays for hidden
      service descriptor downloads and uploads even if the relays have no
      DirPort set and the client has disabled TunnelDirConns. This will
      eventually allow us to give the HSDir flag to relays with no
      DirPort. Fixes bug 2722; bugfix on 0.2.1.6-alpha.
    - Downgrade "no current certificates known for authority" message from
      Notice to Info. Fixes bug 2899; bugfix on 0.2.0.10-alpha.
    - Make the SIGNAL DUMP control-port command work on FreeBSD. Fixes bug
      2917. Bugfix on 0.1.1.1-alpha.
    - Only limit the lengths of single HS descriptors, even when multiple
      HS descriptors are published to an HSDir relay in a single POST
      operation. Fixes bug 2948; bugfix on 0.2.1.5-alpha. Found by hsdir.
    - Write the current time into the LastWritten line in our state file,
      rather than the time from the previous write attempt. Also, stop
      trying to use a time of -1 in our log statements. Fixes bug 3039;
      bugfix on 0.2.2.14-alpha.
    - Be more consistent in our treatment of file system paths. "~" should
      get expanded to the user's home directory in the Log config option.
      Fixes bug 2971; bugfix on 0.2.0.1-alpha, which introduced the
      feature for the -f and --DataDirectory options.
  o Minor features:
    - Make sure every relay writes a state file at least every 12 hours.
      Previously, a relay could go for weeks without writing its state
      file, and on a crash could lose its bandwidth history, capacity
      estimates, client country statistics, and so on. Addresses bug 3012.
    - Send END_STREAM_REASON_NOROUTE in response to EHOSTUNREACH errors.
      Clients before 0.2.1.27 didn't handle NOROUTE correctly, but such
      clients are already deprecated because of security bugs.
    - Don't allow v0 hidden service authorities to act as clients.
      Required by fix for bug 3000.
    - Ignore SIGNAL NEWNYM commands on relay-only Tor instances. Required
      by fix for bug 3000.
    - Ensure that no empty [dirreq-](read|write)-history lines are added
      to an extrainfo document. Implements ticket 2497.
  o Code simplification and refactoring:
    - Remove workaround code to handle directory responses from servers
      that had bug 539 (they would send HTTP status 503 responses _and_
      send a body too). Since only server versions before
      0.2.0.16-alpha/0.1.2.19 were affected, there is no longer reason to
      keep the workaround in place.
    - Remove the old 'fuzzy time' logic. It was supposed to be used for
      handling calculations where we have a known amount of clock skew and
      an allowed amount of unknown skew. But we only used it in three
      places, and we never adjusted the known/unknown skew values. This is
      still something we might want to do someday, but if we do, we'll
      want to do it differently.
    - Avoid signed/unsigned comparisons by making SIZE_T_CEILING unsigned.
      None of the cases where we did this before were wrong, but by making
      this change we avoid warnings. Fixes bug 2475; bugfix on 0.2.1.28.
    - Use GetTempDir to find the proper temporary directory location on
      Windows when generating temporary files for the unit tests. Patch by
      Gisle Vanem.

@_date: 2011-12-20 14:10:59
@_author: Nick Mathewson 
@_subject: [tor-talk] Reminder: please use trac.torproject.org for bug reports 
Hi, all!
Please take this message as a friendly reminder that we would really
prefer that bugs be reported on the bugtracker at trac.torproject.org.
The main advantage of doing this is that once a bug is on the
bugtracker, it can't go away until somebody closes it; and if it gets
closed in error, it can get reopened.  Also, bugs on the bugtracker
can get assigned to milestones, so we can treat them as a checklist of
things that need to get dealt with before a certain release can come
Bugs reported on a mailing list, however, can get forgotten about.
There are folks -- me included -- who try to remember to paste things
onto the bugtracker when I see them reported elsewhere, but that's
just one more thing for developers to spend time on, and sometimes we
miss them.
I'm not writing this to disclaim responsibility for getting stuff
fixed when it gets posted here, mentioned on IRC, tweeted, written in
personal email, scribbled in a bathroom stall where you expect a
developer to eventually visit,  or whatever!  If that's the only way
that you can report a bug, then thanks for reporting it: I would
rather have the bug report than not, and I am grateful for all the
help I can get! But before you do, please consider making a
developer's job easier, and posting bugs to the bugtracker.
Many thanks for your indulgence, and thanks for using Tor!
seasons' greetings,

@_date: 2011-02-22 00:03:30
@_author: Nick Mathewson 
@_subject: [tor-talk] Using Mixminion trough the Tor network 
You'd probably want to hack up Mixminion's socket.connect stuff to use
a SOCKS-compatible version instead.  The functions to hack on the
client side would be in lib/mixminion/MMTPClient.py ; that's the part
that does the client-side network connections.
Unfortunately, Mixminion isn't maintained these days; if anybody is
interested in new versions coming out, they should subscribe to the
mixminion-dev list and coordinate with others.

@_date: 2011-02-28 16:02:09
@_author: Nick Mathewson 
@_subject: [tor-talk] security properties of tor 
I'd start with the design paper: It's still mostly right about threat
models.  Then try reading the overview and faqs on the website, and
the big list of caveats at
  .  Those
ought to suggest more places to follow up.

@_date: 2011-02-14 13:46:20
@_author: Nick Mathewson 
@_subject: dir-spec.txt and directory-signature entries 
It means everything beginning with the string "network-status-version"
and ending with the first string "directory-signature ".  This refers
to the _string_ "directory signature " (with included space), not to
the entire directory signature.  (It _can't_ refer to the entire
directory signature, since when the authority computes the signature,
it doesn't know what the signature is going to be.)

@_date: 2010-12-31 22:17:17
@_author: Nick Mathewson 
@_subject: Key length and PK algorithm of TOR 
Well, there are at least a number of respectable people who think that
some ECC can be used in a non-patent-infringing way.  Certicom seems
to be taking the position that their patents cover all ECC usage --
and why wouldn't they? -- but others seem to think that ECC using the
P groups can be done safely, and DJB of course is quite confident in
But to answer your questions, the main reason Tor doesn't use ECC now
(and that its RSA keys are 1024 bits except for authority keys) is
that back when we designed the relevant parts of the  current Tor
protocol in 2003-2004, RSA-1024 seemed like a reasonably good idea to
us. We figured we could change it pretty easily when it started
showing its age, but as [1] should show, it might take a fair bit of
engineering to get cipher migration right.
There's a related question that people sometimes ask: "Why didn't you
make it so Tor could support an arbitrarily large array of cipher
combinations?"  Three main reasons.  First, we were worried about the
ciphersuite fingerprinting attacks that plague the cpunk remailer
design.  If an anonymity design forces users to pick from multiple
ciphers, users will stand apart from one another based on their cipher
choice.  (There's actually an even more subtle argument here; we wrote
a paper about it. [2])  Second, we were worried about protocol
downgrade attacks and didn't want to have to consider a secure
protocol negotiation scheme on top of everything else we were doing.
Third, we really wanted to get a working Tor completed in a reasonable
amount of time.
Robert Ransom and I (and others) are trying to start off a discussion
on or-dev about migrating Tor to work with longer keys and faster
ciphers; see [1] and [3] for more info there.
[1] [2] [3] peace & happy new year,

@_date: 2011-01-23 17:07:00
@_author: Nick Mathewson 
@_subject: Country-code exit broken in 0.2.2.21-alpha? 
I just current maint-0.2.2 from the command line and it built circuits okay with
    ./src/or/tor -geoipfile ./src/config/geoip -exitnodes '{gb}' -strictnodes 1
Could there be a vidalia issue here?  Could some other option be
interfering?  Could you have a missing geoip file somehow?

@_date: 2011-01-06 11:05:30
@_author: Nick Mathewson 
@_subject: Double log entries? 
Really dumb question: is it possible that you the log configured twice
in your torrc?

@_date: 2011-03-07 18:55:07
@_author: Nick Mathewson 
@_subject: [tor-talk] How does Tor REALLY work? 
You mean, which parts of the code call what, and how they all fit
together?  I'm afraid we haven't written anything like that.  I'd love
for somebody to start writing one, but for now, learning how the code
all fits together will require you to read some C.
If you're still interested, here are some good points to start with:
   - The tor program does most of its work in the main thread.  The
main thread is written launches operations in response to events,
which include network IO, timers, and signals.  Tor uses libevent to
notice these events.  The starting point for handling network IO
events (in 0.2.2) is conn_read_callback and conn_write_callback.  The
starting point for handling signals is signal_callback.  The starting
point for invoking periodic timers is second_elapsed_callback.  These
are all in src/or/main.c.
   - There are also subthreads to handle CPU-intensive tasks.  Right
now, they only handle onionskins.
   - To see how the program starts up, start with the function
tor_main() in src/or/main.c.  When Tor is run, it invokes
do_main_loop(), which sets up more of the global state, and then
spends most of its time in a loop.  The loop's main job is to call
event_base_loop(): this is where Tor spends most of its time.
Again, this is just a sketch of interesting points to start reading a
top-down tour of the program, and isn't a "tor internals guide" by any
means.  If somebody has time to write one someday, that would rock.

@_date: 2011-03-08 13:52:20
@_author: Nick Mathewson 
@_subject: [tor-talk] How does Tor REALLY work? 
No guarantees, I'm afraid, but fortunately (?) the rate of change is
limited to how fast people can code.  Anybody who's interested in
trying to do something like this would either need to resign
themselves to an ongoing process of keeping their work up to date, or
resign themselves to having it become out-of-date as development moves

@_date: 2011-03-11 00:13:22
@_author: Nick Mathewson 
@_subject: [tor-talk] How does Tor REALLY work? 
The doxygen documentation _is_ up-to-date in the source code -- at
least, it's .  Download the source, make sure you have doxygen
installed, run "make doxygen," and there you go.  ;)
Oh, yeah.  Maybe you don't have doxygen or a build environment or
something.  You might want something auto-updated.  Let's see...
   If I set up the crontab right, that should rebuilt daily.   It seems
to give some warnings: if anybody wants to run doxygen a few times
themselves and see how many of those they can clear up, patches would
be dandy.
I turned on the source-browsing feature: if it works out well, we
should turn it on in the main doxygen.
Also, if this is actually useful to somebody, we should make one of
the websites do it, and not just have it in my personal account.

@_date: 2011-03-21 11:43:19
@_author: Nick Mathewson 
@_subject: [tor-talk] Iran cracks down on web dissident technology 
Please, let's not introduce sarcasm to discussions like this.  It only
confuses people.
(For the uninitiated: Mike Perry and Ioerror are not the same person,
even if a guy says so with lots of exclamation points.)

@_date: 2011-05-05 20:02:18
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.2.3.1-alpha is out! 
Hash: SHA1
Changes in version 0.2.3.1-alpha - 2011-05-05
  Tor 0.2.3.1-alpha adds some new experimental features, including support
  for an improved network IO backend, IOCP networking on Windows,
  microdescriptor caching, "fast-start" support for streams, and automatic
  home router configuration. There are also numerous internal improvements
  to try to make the code easier for developers to work with.
  This is the first alpha release in a new series, so expect there to be
  bugs. Users who would rather test out a more stable branch should
  stay with 0.2.2.x for now.
  For now, only the source has been uploaded.  Our website scripts don't
  like for there to be three active branches at one time, so while we're
  getting that straightened out, you can get the source and the
  signature at
      and
      respectively.
  Packages for Debian and expert packages for other platforms should
  follow.  If you don't build from source, and prefer the easier-to-use
  packages, please stick with 0.2.2.x or 0.2.1.x until we get more bugs
  shaken out of this one.
  o Major features
    - Tor can now optionally build with the "bufferevents" buffered IO
      backend provided by Libevent 2. To use this feature, make sure you
      have the latest possible version of Libevent, and pass the
      --enable-bufferevents flag to configure when building Tor from
      source. This feature will make our networking code more flexible,
      let us stack layers on each other, and let us use more efficient
      zero-copy transports where available.
    - As an experimental feature, Tor can use IOCP for networking on Windows.
      Once this code is tuned and optimized, it promises much better
      performance than the select-based backend we've used in the past. To
      try this feature, you must build Tor with Libevent 2, configure Tor
      with the "bufferevents" buffered IO backend, and add "DisableIOCP 0" to
      your torrc. There are known bugs here: only try this if you can help
      debug it as it breaks.
    - The EntryNodes option can now include country codes like {de} or IP
      addresses or network masks. Previously we had disallowed these options
      because we didn't have an efficient way to keep the list up to
      date. Fixes bug 1982, but see bug 2798 for an unresolved issue here.
    - Exit nodes now accept and queue data on not-yet-connected streams.
      Previously, the client wasn't allowed to send data until the stream was
      connected, which slowed down all connections. This change will enable
      clients to perform a "fast-start" on streams and send data without
      having to wait for a confirmation that the stream has opened. (Patch
      from Ian Goldberg; implements the server side of Proposal 174.)
    - Tor now has initial support for automatic port mapping on the many
      home routers that support NAT-PMP or UPnP. (Not yet supported on
      Windows). To build the support code, you'll need to have libnatpnp
      library and/or the libminiupnpc library, and you'll need to enable the
      feature specifically by passing "--enable-upnp" and/or
      "--enable-natpnp" to configure. To turn it on, use the new
      PortForwarding option.
    - Caches now download, cache, and serve multiple "flavors" of the
      consensus, including a flavor that describes microdescriptors.
    - Caches now download, cache, and serve microdescriptors -- small
      summaries of router descriptors that are authenticated by all of the
      directory authorities. Once enough caches are running this code,
      clients will be able to save significant amounts of directory bandwidth
      by downloading microdescriptors instead of router descriptors.
  o Minor features:
    - Make logging resolution configurable with a new LogGranularity
      option, and change the default from 1 millisecond to 1
      second. Implements enhancement 1668.
    - We log which torrc file we're using on startup. Implements ticket
      2444.
    - Ordinarily, Tor does not count traffic from private addresses (like
      127.0.0.1 or 10.0.0.1) when calculating rate limits or accounting.
      There is now a new option, CountPrivateBandwidth, to disable this
      behavior. Patch from Daniel Cagara.
    - New --enable-static-tor configure option for building Tor as
      statically as possible. Idea, general hackery and thoughts from
      Alexei Czeskis, John Gilmore, Jacob Appelbaum. Implements ticket
      2702.
    - If you set the NumCPUs option to 0, Tor will now try to detect how
      many CPUs you have. This is the new default behavior.
    - Turn on directory request statistics by default and include them in
      extra-info descriptors. Don't break if we have no GeoIP database.
    - Relays that set "ConnDirectionStatistics 1" write statistics on the
      bidirectional use of connections to disk every 24 hours.
    - Add a GeoIP file digest to the extra-info descriptor. Implements
      enhancement 1883.
    - Add a new 'Heartbeat' log message type to periodically log a message
      describing Tor's status at level Notice. This feature is meant for
      operators who log at notice, and want to make sure that their Tor
      server is still working. Implementation by George Kadianakis.
  o Minor bugfixes (on 0.2.2.25-alpha):
    - When loading the microdesc journal, remember its current size.
      In 0.2.2, this helps prevent the microdesc journal from growing
      without limit on authorities (who are the only ones to use it in
      0.2.2). Fixes a part of bug 2230; bugfix on 0.2.2.6-alpha.
      Fix posted by "cypherpunks."
    - The microdesc journal is supposed to get rebuilt only if it is
      at least _half_ the length of the store, not _twice_ the length
      of the store. Bugfix on 0.2.2.6-alpha; fixes part of bug 2230.
    - If as an authority we fail to compute the identity digest of a v3
      legacy keypair, warn, and don't use a buffer-full of junk instead.
      Bugfix on 0.2.1.1-alpha; fixes bug 3106.
    - Authorities now clean their microdesc cache periodically and when
      reading from disk initially, not only when adding new descriptors.
      This prevents a bug where we could lose microdescriptors. Bugfix
      on 0.2.2.6-alpha.
  o Minor features (controller)
    - Add a new SIGNAL event to the controller interface so that
      controllers can be notified when Tor handles a signal. Resolves
      issue 1955. Patch by John Brooks.
    - Add a new GETINFO option to get total bytes read and written. Patch
      from pipe, revised by atagar. Resolves ticket 2345.
    - Implement some GETINFO controller fields to provide information about
      the Tor process's pid, euid, username, and resource limits.
  o Build changes
    - Our build system requires automake 1.6 or later to create the
      Makefile.in files. Previously, you could have used 1.4.
      This only affects developers and people building Tor from git;
      people who build Tor from the source distribution without changing
      the Makefile.am files should be fine.
    - Our autogen.sh script uses autoreconf to launch autoconf, automake, and
      so on. This is more robust against some of the failure modes
      associated with running the autotools pieces on their own.
  o Minor packaging issues:
    - On OpenSUSE, create the /var/run/tor directory on startup if it is not
      already created. Patch from Andreas Stieger. Fixes bug 2573.
  o Code simplifications and refactoring:
    - A major revision to our internal node-selecting and listing logic.
      Tor already had at least two major ways to look at the question of
      "which Tor servers do we know about": a list of router descriptors,
      and a list of entries in the current consensus. With
      microdescriptors, we're adding a third. Having so many systems
      without an abstraction layer over them was hurting the codebase.
      Now, we have a new "node_t" abstraction that presents a consistent
      interface to a client's view of a Tor node, and holds (nearly) all
      of the mutable state formerly in routerinfo_t and routerstatus_t.
    - The helper programs tor-gencert, tor-resolve, and tor-checkkey
      no longer link against Libevent: they never used it, but
      our library structure used to force them to link it.
  o Removed features:
    - Remove some old code to work around even older versions of Tor that
      used forked processes to handle DNS requests. Such versions of Tor
      are no longer in use as servers.
  o Documentation fixes:
    - Correct a broken faq link in the INSTALL file. Fixes bug 2307.
    - Add missing documentation for the authority-related torrc options
      RephistTrackTime, BridgePassword, and V3AuthUseLegacyKey. Resolves
      issue 2379.

@_date: 2011-05-05 20:50:35
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.2.3.1-alpha is out! 
It's not on by default.  It's not currently even built by default.  Scroll down:
   - Tor now has initial support for automatic port mapping on the many
     home routers that support NAT-PMP or UPnP. (Not yet supported on
     Windows). To build the support code, you'll need to have libnatpnp
     library and/or the libminiupnpc library, and you'll need to enable the
     feature specifically by passing "--enable-upnp" and/or
     "--enable-natpnp" to configure. To turn it on, use the new
     PortForwarding option.

@_date: 2011-05-06 09:05:41
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.2.3.1-alpha is out! 
Thanks, Olaf!  Be sure to keep a closer-than-usual eye out for crashes. :)

@_date: 2011-11-20 20:23:24
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor and AES-NI acceleration , and Tor profiling 
Because, according to our benchmarks, on systems *without* aesni or
other hardware acceleration, using the AES_* functions is actually
faster than the EVP_* ones. (By about 5%.) ?Since the function is
critical path, we want to use the fastest variant we can.
I think the right solution here is going to wind up involving checking
whether an AES engine is in use, and if so using EVP_, otherwise using
Additionally, while our counter-mode implementation is much faster
than older openssl's, it seems like openssl got a faster counter-mode
implementation around 1.0.0; we should use that one instead where

@_date: 2011-10-30 14:55:08
@_author: Nick Mathewson 
@_subject: [tor-talk] Freedom Hosting admin revealed by Anonymous - Tor 
Ah, sounds like the "underpants gnomes" method of character assassination.
Step 1: There's a crime! Step 2: ???????? Step 3: Profit^WAccusations!
(If you don't know what I'm talking about, watch the south park episode
with the Underpants Gnomes and/or accept my apologies for making a
culturally specific reference.)

@_date: 2012-04-19 10:52:31
@_author: Nick Mathewson 
@_subject: [tor-talk] Another openssl advisory: Tor seems not to be affected 
Hi, all!
It looks like there is an openssl security advisory affecting some but
not all of the ASN.1 parsing code. The announcement is here:
And the full-disclosure posting is here:
It looks like there is an openssl security advisory affecting some but
not all of the ASN.1 parsing code.  In short, the d2i_*_bio functions
and the d2i_*_fp functions are vulnerable to hostile input, but the
regular in-memory d2i_* functions, and the PEM_* functions, are not.
Tor only calls the safe d2i_* functions and the safe PEM_* functions,
and (as near as I can tell) doesn't call any part of OpenSSL that
calls an unsafe function.
So it appears that Tor is not affected by this.  (I invite everybody
to check my work here, of course.)
So if you saw the original announcment and were wondering, "Do I need
to upgrade my Tor's OpenSSL right now?" then the answer is "probably
not."  If you've got other programs that use OpenSSL, though, an
upgrade could be in order: with any luck, your operating system (or
the programs themselves) will handle that for you, if they've got a
decent security update system.
Just to be sure, future versions of the Tor packages we build ought to
ship with OpenSSL 1.0.1a or later.

@_date: 2012-07-31 19:13:07
@_author: Nick Mathewson 
@_subject: [tor-talk] Private Tor network on IPv6 only 
Tor doesn't currently do a good job of supporting IPv6 at all for anything
beyond bridges.  We hope to fix that in the next several months in the
0.2.4.x release series.
I don't have a current plan for IPv6-only support.

@_date: 2012-05-10 18:37:41
@_author: Nick Mathewson 
@_subject: [tor-talk] If you build your own OpenSSL, and you're on 1.0.1, 
Hi, all!
If you are using any version of openssl 1.0.1, 1.0.1a, or 1.0.1b, you
should know that it's affected by a recent security advisory:
If I am reading the diffs for this bug right, it looks like it would
attacker to crash a server remotely.  To avoid that, I'd recommend
that all Tor nodes running any version of OpenSSL 1.0.1 should upgrade
to 1.0.1c.
Non-1.0.1 version of OpenSSL have this bug in their DTLS
implementations, but Tor doesn't use DTLS.
We'll try to get new packages out soon.

@_date: 2012-10-27 13:07:40
@_author: Nick Mathewson 
@_subject: [tor-talk] Why would authorities fall back to "1"? 
Whoops; my phone used the wrong from address.  Let me try that again.
I tried to say:
To be honest, the whole "falling back" design here is a bit pointless.  If
2/3 of the authorities support and will use method 14, then there is as far
as I can tell no reason for anybody to generate a method-1 consensus, or
indeed any consensus whose method is not 14.  That's because such a
consensus would get signed by at most 1/3 of the authorities, and therefore
wouldn't have enough signatures to get used by anybody.
Now, we could imagine weird exceptions here, involving perversely
fragmented sets of authority versions, and clients who believe that the
authority set is much smaller than it truly is.  But for the most part, I
think falling back at all has little point.
That said, it might be smart to fall back to something other than 1, if we
can find a good reason to fall back.  The reason 1 was specified when I
designed the system was because only version 1 was specified as

@_date: 2012-09-03 14:30:03
@_author: Nick Mathewson 
@_subject: [tor-talk] [Tails-dev] Please review Tails stream isolation 
But it can forward connections to a transparent proxy -- like, say, Tor's
TransPort feature.  The tricky part here would be coming up with a way to
forward only the correct connections.
Failing that, torsocks is indeed a way pretty good option.

@_date: 2012-09-20 02:23:31
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor meetup in San Francisco this Saturday 
Hi, friends!
I'm in San Francisco this weekend for the EFF Pioneer awards, and I'm going
to have an informal Tor meetup this Saturday at the Noisebridge hackerspace
from noon through 6pm.
The internet can tell you where Noisebridge is and how to get there.
Please come, if you'd like to hang out and get technical, or learn more, or

@_date: 2013-04-13 15:07:15
@_author: Nick Mathewson 
@_subject: [tor-talk] ExcludeEntryNodes 
We removed it long ago when we were simplifying our node-selection options
to make them actually work (and try to make them work as people expected).
The previous implementation was buggy in some places,  and it had usability
issues that made people expect it to act differently than it actually did.
It also interacted with guard nodes weirdly and confusingly IIRC. Check out
the changelog entries for bug 1090 for the whole ugly story.
I wouldn't mind taking a well-written, well-tested patch to add a feature
like this again, if somebody can write one that actually does it right this
Which numbers?

@_date: 2013-02-07 14:19:32
@_author: Nick Mathewson 
@_subject: [tor-talk] Watch out for openssl 1.0.1d if you're using AESNI 
Hi, all!
There's a bug in openssl 1.0.1d that breaks Tor (and lots of other
programs) if you have a CPU with aesni support.
If you have aesni support on your CPU, and you're using the openssl
1.0.1 series, and you decide that you simply _must_ upgrade OpenSSL
before 1.0.1e can be released (soon, I hope), then see the link below
for a patch that will make Tor work around the bug in question.
For more information on the openssl bug, see
 .
(Incidentally, because one or two people have asked: Tor itself isn't
affected by the new Lucky-13 attack against TLS CBC implementations.
In order to do plaintext recovery, the attack requires that the same
secret be sent in a large number of encrypted TLS sessions. This can
happen with HTTPS (where an attacker can force many connections to
happen with Javascript, each of which will contain a cookie that the
attacker is trying to steal).  Tor, on the other hand, will send the
same secret encrypted the same way more than once.
This doesn't mean that Tor users couldn't be affected, though.
TorBrowser is a web browser based on Firefox, after all, and therefore
is potentially affected by any attack affecting HTTP.  Once there's a
new version of Firefox out, I hope that we'll have an updated browser
released soon afterwards.
For more information on the attack and its impact, see
 .)
best wishes,

@_date: 2013-02-27 19:28:35
@_author: Nick Mathewson 
@_subject: [tor-talk] Is anybody or anything still using /etc/tor/tsocks.conf ? 
We have a ticket ( to remove the /etc/tor/tsocks.conf file,
especially now that Torsocks exists and is recommended over a stock
tsocks.  It seems like a decent idea to me, but before I go ahead, I
want to know whether any packages or large groups of users are relying
on it.
Please comment on the ticket (
 ) if this file's
absence will be missed.

@_date: 2013-06-16 17:32:36
@_author: Nick Mathewson 
@_subject: [tor-talk] Plans about Askbot? 
I think if we're going to have a reasonable discussion, we need to
distinguish between "use" and "endorse."
I wrote a long rant at this point, but deleted it as unlikely to help.
Suffice it to say, though it is admirable if you only use things you can
endorse wholeheartedly (RMS comes to mind), but it is IMO unfair to assume
that everybody's acts count as declarations of endorsement for everything
they use and touch.
(This doesn't have much bearing on the topic at hand, fwiw. Much of your
argument retains some force if you say "use" rather than "endorse." I hope
someone who knows more than I will respond soon.)
Best wishes,

@_date: 2013-09-20 21:00:35
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor mini-hackathon at GNU 30th Anniversary Celebration 
Hi, all!
Tor will be one of several fine software projects featured in the
featured in the GNU 30th Anniversary Celebration and Hackathon next
weekend at MIT. If you like to program, and you're interested in
helping with Tor, sign up on the webpage
( and come on by!
I'll be there myself, hoping to spend my time coding and getting
people excited about hacking on Tor. Other Tor people in the greater
Boston area may come by as well-I hope we can get at least two or
three.  I don't currently expect to have all of our sub-projects
represented, but we'll try to put you in contact with the right people
if you want to hack on something else.
I'll try to have a list of fun suggested projects for people to work
on ahead of the event, ideally on a wiki somewhere.

@_date: 2013-09-30 11:22:58
@_author: Nick Mathewson 
@_subject: [tor-talk] Gnu30 hackathon report 
Hi, all!
The Tor hackathon at the gnu30 event went fairly well, I think. Two
people sent me small built/test patches which I've merged into the Tor
mainline, and a few more have promised me test improvements and other
patches.  I also met a lot of cool hackers, and talked with people
from other free software projects.  About a half dozen people
approached me asking how to get Tor people to speak for conferences
and student groups; I told them about the appropriate mailing lists. I
pair-programmed a bunch of ed25519 code, and talked about cryptography
with a lot of people.  I hope we'll be seeing more of some of the
folks I talked to on our mailing lists and IRC channels soon.
One thing I really enjoyed was participating in other group's
hackathons. I reported a a few possible security holes in a couple of
projects, asked questions about how to get code merged into others,
and hassled people who weren't signing their packages.
I think for the next hackathon we organize ourselves, we should invite
some other non-Tor free software project; cross-pollinating ideas and
areas of expertise was pretty valuable.
If I remember correctly, somebody said that the FSF is new to hosting
hackathon-style events.  But I have a pretty hard time believing that,
given how smoothly everything went.
best wishes,

@_date: 2014-04-26 11:01:10
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.2.5.4-alpha is released 
Changes in version 0.2.5.4-alpha - 2014-04-25
  Tor 0.2.5.4-alpha includes several security and performance
  improvements for clients and relays, including blacklisting authority
  signing keys that were used while susceptible to the OpenSSL
  "heartbleed" bug, fixing two expensive functions on busy relays,
  improved TLS ciphersuite preference lists, support for run-time
  hardening on compilers that support AddressSanitizer, and more work on
  the Linux sandbox code.
  There are also several usability fixes for clients (especially clients
  that use bridges), two new TransPort protocols supported (one on
  OpenBSD, one on FreeBSD), and various other bugfixes.
  This release marks end-of-life for Tor 0.2.2.x; those Tor versions
  have accumulated many known flaws; everyone should upgrade.
  The source is ready today; packages should be ready in the next several days.
  (I'm trying to take some load off of Roger's shoulders by doing
releases myself.  This means that the signatures on the release are be
made with my PGP key, not Roger's.  Please don't freak out.)
    o Major features (security):
    - If you don't specify MaxMemInQueues yourself, Tor now tries to
      pick a good value based on your total system memory. Previously,
      the default was always 8 GB. You can still override the default by
      setting MaxMemInQueues yourself. Resolves ticket 11396.
    - Block authority signing keys that were used on authorities
      vulnerable to the "heartbleed" bug in OpenSSL (CVE-2014-0160). (We
      don't have any evidence that these keys _were_ compromised; we're
      doing this to be prudent.) Resolves ticket 11464.
  o Major features (relay performance):
    - Speed up server-side lookups of rendezvous and introduction point
      circuits by using hashtables instead of linear searches. These
      functions previously accounted between 3 and 7% of CPU usage on
      some busy relays. Resolves ticket 9841.
    - Avoid wasting CPU when extending a circuit over a channel that is
      nearly out of circuit IDs. Previously, we would do a linear scan
      over possible circuit IDs before finding one or deciding that we
      had exhausted our possibilities. Now, we try at most 64 random
      circuit IDs before deciding that we probably won't succeed. Fixes
      a possible root cause of ticket 11553.
  o Major features (seccomp2 sandbox, Linux only):
    - The seccomp2 sandbox can now run a test network for multiple hours
      without crashing. The sandbox is still experimental, and more bugs
      will probably turn up. To try it, enable "Sandbox 1" on a Linux
      host. Resolves ticket 11351.
    - Strengthen sandbox code: the sandbox can now test the arguments
      for rename(), and blocks _sysctl() entirely. Resolves another part
      of ticket 11351.
    - When the sandbox blocks a system call, it now tries to log a stack
      trace before exiting. Resolves ticket 11465.
  o Major bugfixes (TLS cipher selection):
    - The relay ciphersuite list is now generated automatically based on
      uniform criteria, and includes all OpenSSL ciphersuites with
      acceptable strength and forward secrecy. Previously, we had left
      some perfectly fine ciphersuites unsupported due to omission or
      typo. Resolves bugs 11513, 11492, 11498, 11499. Bugs reported by
      'cypherpunks'. Bugfix on 0.2.4.8-alpha.
    - Relays now trust themselves to have a better view than clients of
      which TLS ciphersuites are better than others. (Thanks to bug
      11513, the relay list is now well-considered, whereas the client
      list has been chosen mainly for anti-fingerprinting purposes.)
      Relays prefer: AES over 3DES; then ECDHE over DHE; then GCM over
      CBC; then SHA384 over SHA256 over SHA1; and last, AES256 over
      AES128. Resolves ticket 11528.
    - Clients now try to advertise the same list of ciphersuites as
      Firefox 28. This change enables selection of (fast) GCM
      ciphersuites, disables some strange old ciphers, and stops
      advertising the ECDH (not to be confused with ECDHE) ciphersuites.
      Resolves ticket 11438.
  o Major bugfixes (bridge client):
    - Avoid 60-second delays in the bootstrapping process when Tor is
      launching for a second time while using bridges. Fixes bug 9229;
      bugfix on 0.2.0.3-alpha.
  o Minor features (transparent proxy, *BSD):
    - Support FreeBSD's ipfw firewall interface for TransPort ports on
      FreeBSD. To enable it, set "TransProxyType ipfw". Resolves ticket
      10267; patch from "yurivict".
    - Support OpenBSD's divert-to rules with the pf firewall for
      transparent proxy ports. To enable it, set "TransProxyType
      pf-divert". This allows Tor to run a TransPort transparent proxy
      port on OpenBSD 4.4 or later without root privileges. See the
      pf.conf(5) manual page for information on configuring pf to use
      divert-to rules. Closes ticket 10896; patch from Dana Koch.
  o Minor features (security):
    - New --enable-expensive-hardening option to enable security
      hardening options that consume nontrivial amounts of CPU and
      memory. Right now, this includes AddressSanitizer and UbSan, which
      are supported in newer versions of GCC and Clang. Closes ticket
      11477.
  o Minor features (log verbosity):
    - Demote the message that we give when a flushing connection times
      out for too long from NOTICE to INFO. It was usually meaningless.
      Resolves ticket 5286.
    - Don't log so many notice-level bootstrapping messages at startup
      about downloading descriptors. Previously, we'd log a notice
      whenever we learned about more routers. Now, we only log a notice
      at every 5% of progress. Fixes bug 9963.
    - Warn less verbosely when receiving a malformed
      ESTABLISH_RENDEZVOUS cell. Fixes ticket 11279.
    - When we run out of usable circuit IDs on a channel, log only one
      warning for the whole channel, and describe how many circuits
      there were on the channel. Fixes part of ticket 11553.
  o Minor features (relay):
    - If a circuit timed out for at least 3 minutes, check if we have a
      new external IP address, and publish a new descriptor with the new
      IP address if it changed. Resolves ticket 2454.
  o Minor features (controller):
    - Make the entire exit policy available from the control port via
      GETINFO exit-policy/*. Implements enhancement 7952. Patch from
      "rl1987".
    - Because of the fix for ticket 11396, the real limit for memory
      usage may no longer match the configured MaxMemInQueues value. The
      real limit is now exposed via GETINFO limits/max-mem-in-queues.
  o Minor features (bridge client):
    - Report a more useful failure message when we can't connect to a
      bridge because we don't have the right pluggable transport
      configured. Resolves ticket 9665. Patch from F?bio J. Bertinatto.
  o Minor features (diagnostic):
    - Add more log messages to diagnose bug 7164, which causes
      intermittent "microdesc_free() called but md was still referenced"
      warnings. We now include more information, to figure out why we
      might be cleaning a microdescriptor for being too old if it's
      still referenced by a live node_t object.
  o Minor bugfixes (client, DNSPort):
    - When using DNSPort, try to respond to AAAA requests with AAAA
      answers. Previously, we hadn't looked at the request type when
      deciding which answer type to prefer. Fixes bug 10468; bugfix on
      0.2.4.7-alpha.
    - When receiving a DNS query for an unsupported record type, reply
      with no answer rather than with a NOTIMPL error. This behavior
      isn't correct either, but it will break fewer client programs, we
      hope. Fixes bug 10268; bugfix on 0.2.0.1-alpha. Original patch
      from "epoch".
  o Minor bugfixes (exit relay):
    - Stop leaking memory when we successfully resolve a PTR record.
      Fixes bug 11437; bugfix on 0.2.4.7-alpha.
  o Minor bugfixes (bridge client):
    - Stop accepting bridge lines containing hostnames. Doing so would
      cause clients to perform DNS requests on the hostnames, which was
      not sensible behavior. Fixes bug 10801; bugfix on 0.2.0.1-alpha.
    - Avoid a 60-second delay in the bootstrapping process when a Tor
      client with pluggable transports re-reads its configuration at
      just the wrong time. Re-fixes bug 11156; bugfix on 0.2.5.3-alpha.
  o Minor bugfixes (client, logging during bootstrap):
    - Warn only once if we start logging in an unsafe way. Previously,
      we complain as many times as we had problems. Fixes bug 9870;
      bugfix on 0.2.5.1-alpha.
    - Only report the first fatal bootstrap error on a given OR
      connection. This stops us from telling the controller bogus error
      messages like "DONE". Fixes bug 10431; bugfix on 0.2.1.1-alpha.
    - Be more helpful when trying to run sandboxed on Linux without
      libseccomp. Instead of saying "Sandbox is not implemented on this
      platform", we now explain that we need to be built with
      libseccomp. Fixes bug 11543; bugfix on 0.2.5.1-alpha.
    - Avoid generating spurious warnings when starting with
      DisableNetwork enabled. Fixes bug 11200 and bug 10405; bugfix on
      0.2.3.9-alpha.
  o Minor bugfixes (closing OR connections):
    - If write_to_buf() in connection_write_to_buf_impl_() ever fails,
      check if it's an or_connection_t and correctly call
      connection_or_close_for_error() rather than
      connection_mark_for_close() directly. Fixes bug 11304; bugfix on
      0.2.4.4-alpha.
    - When closing all connections on setting DisableNetwork to 1, use
      connection_or_close_normally() rather than closing OR connections
      out from under the channel layer. Fixes bug 11306; bugfix on
      0.2.4.4-alpha.
  o Minor bugfixes (controller):
    - Avoid sending a garbage value to the controller when a circuit is
      cannibalized. Fixes bug 11519; bugfix on 0.2.3.11-alpha.
  o Minor bugfixes (tor-fw-helper):
    - Allow tor-fw-helper to build again by adding src/ext to its
      CPPFLAGS. Fixes bug 11296; bugfix on 0.2.5.3-alpha.
  o Minor bugfixes (bridges):
    - Avoid potential crashes or bad behavior when launching a
      server-side managed proxy with ORPort or ExtORPort temporarily
      disabled. Fixes bug 9650; bugfix on 0.2.3.16-alpha.
  o Minor bugfixes (platform-specific):
    - Fix compilation on Solaris, which does not have . Fixes
      bug 11426; bugfix on 0.2.5.3-alpha.
    - When dumping a malformed directory object to disk, save it in
      binary mode on Windows, not text mode. Fixes bug 11342; bugfix on
      0.2.2.1-alpha.
    - Don't report failures from make_socket_reuseable() on incoming
      sockets on OSX: this can happen when incoming connections close
      early. Fixes bug 10081.
  o Minor bugfixes (trivial memory leaks):
    - Fix a small memory leak when signing a directory object. Fixes bug
      11275; bugfix on 0.2.4.13-alpha.
    - Free placeholder entries in our circuit table at exit; fixes a
      harmless memory leak. Fixes bug 11278; bugfix on 0.2.5.1-alpha.
    - Don't re-initialize a second set of OpenSSL mutexes when starting
      up. Previously, we'd make one set of mutexes, and then immediately
      replace them with another. Fixes bug 11726; bugfix on
      0.2.5.3-alpha.
    - Resolve some memory leaks found by coverity in the unit tests, on
      exit in tor-gencert, and on a failure to compute digests for our
      own keys when generating a v3 networkstatus vote. These leaks
      should never have affected anyone in practice.
  o Minor bugfixes (hidden service):
    - Only retry attempts to connect to a chosen rendezvous point 8
      times, not 30. Fixes bug 4241; bugfix on 0.1.0.1-rc.
  o Minor bugfixes (misc code correctness):
    - Fix various instances of undefined behavior in channeltls.c,
      tor_memmem(), and eventdns.c that would cause us to construct
      pointers to memory outside an allocated object. (These invalid
      pointers were not accessed, but C does not even allow them to
      exist.) Fixes bug 10363; bugfixes on 0.1.1.1-alpha, 0.1.2.1-alpha,
      0.2.0.10-alpha, and 0.2.3.6-alpha. Reported by "bobnomnom".
    - Use the AddressSanitizer and Ubsan sanitizers (in clang-3.4) to
      fix some miscellaneous errors in our tests and codebase. Fixes bug
      11232. Bugfixes on versions back as far as 0.2.1.11-alpha.
    - Always check return values for unlink, munmap, UnmapViewOfFile;
      check strftime return values more often. In some cases all we can
      do is report a warning, but this may help prevent deeper bugs from
      going unnoticed. Closes ticket 8787; bugfixes on many, many tor
      versions.
    - Fix numerous warnings from the clang "scan-build" static analyzer.
      Some of these are programming style issues; some of them are false
      positives that indicated awkward code; some are undefined behavior
      cases related to constructing (but not using) invalid pointers;
      some are assumptions about API behavior; some are (harmlessly)
      logging sizeof(ptr) bytes from a token when sizeof(*ptr) would be
      correct; and one or two are genuine bugs that weren't reachable
      from the rest of the program. Fixes bug 8793; bugfixes on many,
      many tor versions.
  o Documentation:
    - Build the torify.1 manpage again. Previously, we were only trying
      to build it when also building tor-fw-helper. That's why we didn't
      notice that we'd broken the ability to build it. Fixes bug 11321;
      bugfix on 0.2.5.1-alpha.
    - Fix the layout of the SOCKSPort flags in the manpage. Fixes bug
      11061; bugfix on 0.2.4.7-alpha.
    - Correctly document that we search for a system torrc file before
      looking in ~/.torrc. Fixes documentation side of 9213; bugfix on
      0.2.3.18-rc.
    - Resolve warnings from Doxygen.
  o Code simplifications and refactoring:
    - Remove is_internal_IP() function. Resolves ticket 4645.
    - Remove unused function circuit_dump_by_chan from circuitlist.c.
      Closes issue 9107; patch from "marek".
    - Change our use of the ENUM_BF macro to avoid declarations that
      confuse Doxygen.
  o Deprecated versions:
    - Tor 0.2.2.x has reached end-of-life; it has received no patches or
      attention for some while. Directory authorities no longer accept
      descriptors from relays running any version of Tor prior to Tor
      0.2.3.16-alpha. Resolves ticket 11149.
  o Testing:
    - New macros in test.h to simplify writing mock-functions for unit
      tests. Part of ticket 11507. Patch from Dana Koch.
    - Complete tests for the status.c module. Resolves ticket 11507.
      Patch from Dana Koch.
  o Removed code:
    - Remove all code for the long unused v1 directory protocol.
      Resolves ticket 11070.

@_date: 2014-06-05 12:34:18
@_author: Nick Mathewson 
@_subject: [tor-talk] Yet another OpenSSL vulnerability 
Hi, all!
There's another OpenSSL vulnerabilty.  This one is less terrible
than heartbleed, but it's still quite bad.  People have taken to
calling it the "EarlyCCS" attack: it will probably get less media
attention than heartbleed because its name is insufficiently scary.
The impact on Tor is that an adversary in the position to run a MITM
attack on a Tor client or relay could cause a TLS connection to be
negotiated without real encryption or authentication.
This attack is possible if the connection initiator (client or
relay) is running an unpatched OpenSSL, and if the relay is running
an unpatched OpenSSL 1.0.1.  If either party has upgraded, or if the
relay is running a version before 1.0.1, the attack fails.
The circuit-layer crypto (which happens under the TLS layer) should
still provide significant protection for user communications over
Tor.  But a MITM attack of this kind could still help traffic
analysis, and likely other unexpected badness as well.
Because of this, I'd strongly recommend that everybody should
upgrade. If you're using Tor packages from our website, please
update to the latest versions as soon as they're available; I hope
that will be very soon.  If your Tor is built against an OpenSSL
provided by your operating system distribution, please install the
vendor updates as soon as they're available.
Here's the official OpenSSL security advisory:
  Here's a good write-up by Adam Langley, explaining this bug in detail:
  Here's a post from the original discoverer of the bug.
  And here's the vulnerability's website (since all vulnerabilities
have a website), complete with scary logo:
  (As a side-note, you should also be concerned about OpenSSL-based
applications that you're using that _aren't_ Tor.  Tor is
comparatively resilient to having one layer of crypto removed; but
most protocols aren't.  Fortunately, Firefox/TorBrowser is using NSS
for its TLS crypto.)
(As a final side-note: today's OpenSSL releases fix some other bugs
too.  If you run other programs that use OpenSSL -- particularly
ones that do DTLS -- you should upgrade for that reason too.)

@_date: 2014-06-18 15:56:17
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.2.5.5-alpha is released 
Changes in version 0.2.5.5-alpha - 2014-06-18
  Tor 0.2.5.5-alpha fixes a wide variety of remaining issues in the Tor
  0.2.5.x release series, including a couple of DoS issues, some
  performance regressions, a large number of bugs affecting the Linux
  seccomp2 sandbox code, and various other bugfixes. It also adds
  diagnostic bugfixes for a few tricky issues that we're trying to
  track down.
  The source is ready today; packages should be ready in the next several days.
  (I'm taking some load off of Roger's shoulders by doing releases
myself.  This means that the signatures on the release are made with
my PGP key, not Roger's.  Please don't freak out.)
    o Major features (security, traffic analysis resistance):
    - Several major improvements to the algorithm used to decide when to
      close TLS connections. Previous versions of Tor closed connections
      at a fixed interval after the last time a non-padding cell was
      sent over the connection, regardless of the target of the
      connection. Now, we randomize the intervals by adding up to 50% of
      their base value, we measure the length of time since connection
      last had at least one circuit, and we allow connections to known
      ORs to remain open a little longer (15 minutes instead of 3
      minutes minimum). These changes should improve Tor's resistance
      against some kinds of traffic analysis, and lower some overhead
      from needlessly closed connections. Fixes ticket 6799.
      Incidentally fixes ticket 12023; bugfix on 0.2.5.1-alpha.
  o Major bugfixes (security, OOM, new since 0.2.5.4-alpha, also in 0.2.4.22):
    - Fix a memory leak that could occur if a microdescriptor parse
      fails during the tokenizing step. This bug could enable a memory
      exhaustion attack by directory servers. Fixes bug 11649; bugfix
      on 0.2.2.6-alpha.
  o Major bugfixes (security, directory authorities):
    - Directory authorities now include a digest of each relay's
      identity key as a part of its microdescriptor.
      This is a workaround for bug 11743 (reported by "cypherpunks"),
      where Tor clients do not support receiving multiple
      microdescriptors with the same SHA256 digest in the same
      consensus. When clients receive a consensus like this, they only
      use one of the relays. Without this fix, a hostile relay could
      selectively disable some client use of target relays by
      constructing a router descriptor with a different identity and the
      same microdescriptor parameters and getting the authorities to
      list it in a microdescriptor consensus. This fix prevents an
      attacker from causing a microdescriptor collision, because the
      router's identity is not forgeable.
  o Major bugfixes (relay):
    - Use a direct dirport connection when uploading non-anonymous
      descriptors to the directory authorities. Previously, relays would
      incorrectly use tunnel connections under a fairly wide variety of
      circumstances. Fixes bug 11469; bugfix on 0.2.4.3-alpha.
    - When a circuit accidentally has the same circuit ID for its
      forward and reverse direction, correctly detect the direction of
      cells using that circuit. Previously, this bug made roughly one
      circuit in a million non-functional. Fixes bug 12195; this is a
      bugfix on every version of Tor.
  o Major bugfixes (client, pluggable transports):
    - When managing pluggable transports, use OS notification facilities
      to learn if they have crashed, and don't attempt to kill any
      process that has already exited. Fixes bug 8746; bugfix
      on 0.2.3.6-alpha.
  o Minor features (diagnostic):
    - When logging a warning because of bug 7164, additionally check the
      hash table for consistency (as proposed on ticket 11737). This may
      help diagnose bug 7164.
    - When we log a heartbeat, log how many one-hop circuits we have
      that are at least 30 minutes old, and log status information about
      a few of them. This is an attempt to track down bug 8387.
    - When encountering an unexpected CR while writing text to a file on
      Windows, log the name of the file. Should help diagnosing
      bug 11233.
    - Give more specific warnings when a client notices that an onion
      handshake has failed. Fixes ticket 9635.
    - Add significant new logging code to attempt to diagnose bug 12184,
      where relays seem to run out of available circuit IDs.
    - Improve the diagnostic log message for bug 8387 even further to
      try to improve our odds of figuring out why one-hop directory
      circuits sometimes do not get closed.
  o Minor features (security, memory management):
    - Memory allocation tricks (mempools and buffer freelists) are now
      disabled by default. You can turn them back on with
      --enable-mempools and --enable-buf-freelists respectively. We're
      disabling these features because malloc performance is good enough
      on most platforms, and a similar feature in OpenSSL exacerbated
      exploitation of the Heartbleed attack. Resolves ticket 11476.
  o Minor features (security):
    - Apply the secure SipHash-2-4 function to the hash table mapping
      circuit IDs and channels to circuits. We missed this one when we
      were converting all the other hash functions to use SipHash back
      in 0.2.5.3-alpha. Resolves ticket 11750.
  o Minor features (build):
    - The configure script has a --disable-seccomp option to turn off
      support for libseccomp on systems that have it, in case it (or
      Tor's use of it) is broken. Resolves ticket 11628.
  o Minor features (other):
    - Update geoip and geoip6 to the June 4 2014 Maxmind GeoLite2
      Country database.
  o Minor bugfixes (security, new since 0.2.5.4-alpha, also in 0.2.4.22):
    - When running a hidden service, do not allow TunneledDirConns 0;
      this will keep the hidden service from running, and also
      make it publish its descriptors directly over HTTP. Fixes bug 10849;
      bugfix on 0.2.1.1-alpha.
  o Minor bugfixes (performance):
    - Avoid a bug where every successful connection made us recompute
      the flag telling us whether we have sufficient information to
      build circuits. Previously, we would forget our cached value
      whenever we successfully opened a channel (or marked a router as
      running or not running for any other reason), regardless of
      whether we had previously believed the router to be running. This
      forced us to run an expensive update operation far too often.
      Fixes bug 12170; bugfix on 0.1.2.1-alpha.
    - Avoid using tor_memeq() for checking relay cell integrity. This
      removes a possible performance bottleneck. Fixes part of bug
      12169; bugfix on 0.2.1.31.
  o Minor bugfixes (compilation):
    - Fix compilation of test_status.c when building with MVSC. Bugfix
      on 0.2.5.4-alpha. Patch from Gisle Vanem.
    - Resolve GCC complaints on OpenBSD about discarding constness in
      TO_{ORIGIN,OR}_CIRCUIT functions. Fixes part of bug 11633; bugfix
      on 0.1.1.23. Patch from Dana Koch.
    - Resolve clang complaints on OpenBSD with -Wshorten-64-to-32 due to
      treatment of long and time_t as comparable types. Fixes part of
      bug 11633. Patch from Dana Koch.
    - Make Tor compile correctly with --disable-buf-freelists. Fixes bug
      11623; bugfix on 0.2.5.3-alpha.
    - When deciding whether to build the 64-bit curve25519
      implementation, detect platforms where we can compile 128-bit
      arithmetic but cannot link it. Fixes bug 11729; bugfix on
      0.2.4.8-alpha. Patch from "conradev".
    - Fix compilation when DNS_CACHE_DEBUG is enabled. Fixes bug 11761;
      bugfix on 0.2.3.13-alpha. Found by "cypherpunks".
    - Fix compilation with dmalloc. Fixes bug 11605; bugfix
      on 0.2.4.10-alpha.
  o Minor bugfixes (Directory server):
    - When sending a compressed set of descriptors or microdescriptors,
      make sure to finalize the zlib stream. Previously, we would write
      all the compressed data, but if the last descriptor we wanted to
      send was missing or too old, we would not mark the stream as
      finished. This caused problems for decompression tools. Fixes bug
      11648; bugfix on 0.1.1.23.
  o Minor bugfixes (Linux seccomp sandbox):
    - Make the seccomp sandbox code compile under ARM Linux. Fixes bug
      11622; bugfix on 0.2.5.1-alpha.
    - Avoid crashing when re-opening listener ports with the seccomp
      sandbox active. Fixes bug 12115; bugfix on 0.2.5.1-alpha.
    - Avoid crashing with the seccomp sandbox enabled along with
      ConstrainedSockets. Fixes bug 12139; bugfix on 0.2.5.1-alpha.
    - When we receive a SIGHUP with the sandbox enabled, correctly
      support rotating our log files. Fixes bug 12032; bugfix
      on 0.2.5.1-alpha.
    - Avoid crash when running with sandboxing enabled and
      DirReqStatistics not disabled. Fixes bug 12035; bugfix
      on 0.2.5.1-alpha.
    - Fix a "BUG" warning when trying to write bridge-stats files with
      the Linux syscall sandbox filter enabled. Fixes bug 12041; bugfix
      on 0.2.5.1-alpha.
    - Prevent the sandbox from crashing on startup when run with the
      --enable-expensive-hardening configuration option. Fixes bug
      11477; bugfix on 0.2.5.4-alpha.
    - When running with DirPortFrontPage and sandboxing both enabled,
      reload the DirPortFrontPage correctly when restarting. Fixes bug
      12028; bugfix on 0.2.5.1-alpha.
    - Don't try to enable the sandbox when using the Tor binary to check
      its configuration, hash a passphrase, or so on. Doing so was
      crashing on startup for some users. Fixes bug 11609; bugfix
      on 0.2.5.1-alpha.
    - Avoid warnings when running with sandboxing and node statistics
      enabled at the same time. Fixes part of 12064; bugfix on
      0.2.5.1-alpha. Patch from Michael Wolf.
    - Avoid warnings when running with sandboxing enabled at the same
      time as cookie authentication, hidden services, or directory
      authority voting. Fixes part of 12064; bugfix on 0.2.5.1-alpha.
    - Do not allow options that require calls to exec to be enabled
      alongside the seccomp2 sandbox: they will inevitably crash. Fixes
      bug 12043; bugfix on 0.2.5.1-alpha.
    - Handle failures in getpwnam()/getpwuid() when running with the
      User option set and the Linux syscall sandbox enabled. Fixes bug
      11946; bugfix on 0.2.5.1-alpha.
    - Refactor the getaddrinfo workaround that the seccomp sandbox uses
      to avoid calling getaddrinfo() after installing the sandbox
      filters. Previously, it preloaded a cache with the IPv4 address
      for our hostname, and nothing else. Now, it loads the cache with
      every address that it used to initialize the Tor process. Fixes
      bug 11970; bugfix on 0.2.5.1-alpha.
  o Minor bugfixes (pluggable transports):
    - Enable the ExtORPortCookieAuthFile option, to allow changing the
      default location of the authentication token for the extended OR
      Port as used by sever-side pluggable transports. We had
      implemented this option before, but the code to make it settable
      had been omitted. Fixes bug 11635; bugfix on 0.2.5.1-alpha.
    - Avoid another 60-second delay when starting Tor in a pluggable-
      transport-using configuration when we already have cached
      descriptors for our bridges. Fixes bug 11965; bugfix
      on 0.2.3.6-alpha.
  o Minor bugfixes (client):
    - Avoid "Tried to open a socket with DisableNetwork set" warnings
      when starting a client with bridges configured and DisableNetwork
      set. (Tor launcher starts Tor with DisableNetwork set the first
      time it runs.) Fixes bug 10405; bugfix on 0.2.3.9-alpha.
  o Minor bugfixes (testing):
    - The Python parts of the test scripts now work on Python 3 as well
      as Python 2, so systems where '/usr/bin/python' is Python 3 will
      no longer have the tests break. Fixes bug 11608; bugfix
      on 0.2.5.2-alpha.
    - When looking for versions of python that we could run the tests
      with, check for "python2.7" and "python3.3"; previously we were
      only looking for "python", "python2", and "python3". Patch from
      Dana Koch. Fixes bug 11632; bugfix on 0.2.5.2-alpha.
    - Fix all valgrind warnings produced by the unit tests. There were
      over a thousand memory leak warnings previously, mostly produced
      by forgetting to free things in the unit test code. Fixes bug
      11618, bugfixes on many versions of Tor.
  o Minor bugfixes (tor-fw-helper):
    - Give a correct log message when tor-fw-helper fails to launch.
      (Previously, we would say something like "tor-fw-helper sent us a
      string we could not parse".) Fixes bug 9781; bugfix
      on 0.2.4.2-alpha.
  o Minor bugfixes (relay, threading):
    - Check return code on spawn_func() in cpuworker code, so that we
      don't think we've spawned a nonworking cpuworker and write junk to
      it forever. Fix related to bug 4345; bugfix on all released Tor
      versions. Found by "skruffy".
    - Use a pthread_attr to make sure that spawn_func() cannot return an
      error while at the same time launching a thread. Fix related to
      bug 4345; bugfix on all released Tor versions. Reported
      by "cypherpunks".
  o Minor bugfixes (relay, oom prevention):
    - Correctly detect the total available system memory. We tried to do
      this in 0.2.5.4-alpha, but the code was set up to always return an
      error value, even on success. Fixes bug 11805; bugfix
      on 0.2.5.4-alpha.
  o Minor bugfixes (relay, other):
    - We now drop CREATE cells for already-existent circuit IDs and for
      zero-valued circuit IDs, regardless of other factors that might
      otherwise have called for DESTROY cells. Fixes bug 12191; bugfix
      on 0.0.8pre1.
    - Avoid an illegal read from stack when initializing the TLS module
      using a version of OpenSSL without all of the ciphers used by the
      v2 link handshake. Fixes bug 12227; bugfix on 0.2.4.8-alpha. Found
      by "starlight".
    - When rejecting DATA cells for stream_id zero, still count them
      against the circuit's deliver window so that we don't fail to send
      a SENDME. Fixes bug 11246; bugfix on 0.2.4.10-alpha.
  o Minor bugfixes (logging):
    - Fix a misformatted log message about delayed directory fetches.
      Fixes bug 11654; bugfix on 0.2.5.3-alpha.
    - Squelch a spurious LD_BUG message "No origin circuit for
      successful SOCKS stream" in certain hidden service failure cases;
      fixes bug 10616.
  o Distribution:
    - Include a tor.service file in contrib/dist for use with systemd.
      Some distributions will be able to use this file unmodified;
      others will need to tweak it, or write their own. Patch from Jamie
      Nguyen; resolves ticket 8368.
  o Documentation:
    - Clean up several option names in the manpage to match their real
      names, add the missing documentation for a couple of testing and
      directory authority options, remove the documentation for a
      V2-directory fetching option that no longer exists. Resolves
      ticket 11634.
    - Correct the documenation so that it lists the correct directory
      for the stats files. (They are in a subdirectory called "stats",
      not "status".)
    - In the manpage, move more authority-only options into the
      directory authority section so that operators of regular directory
      caches don't get confused.
  o Package cleanup:
    - The contrib directory has been sorted and tidied. Before, it was
      an unsorted dumping ground for useful and not-so-useful things.
      Now, it is divided based on functionality, and the items which
      seemed to be nonfunctional or useless have been removed. Resolves
      ticket 8966; based on patches from "rl1987".
  o Removed code:
    - Remove /tor/dbg-stability.txt URL that was meant to help debug WFU
      and MTBF calculations, but that nobody was using. Fixes     - The TunnelDirConns and PreferTunnelledDirConns options no longer
      exist; tunneled directory connections have been available since
      0.1.2.5-alpha, and turning them off is not a good idea. This is a
      brute-force fix for 10849, where "TunnelDirConns 0" would break
      hidden services.

@_date: 2014-05-14 15:46:40
@_author: Nick Mathewson 
@_subject: [tor-talk] Upcoming stable release: 0.2.4.22. Please test? 
Hi, all!
We're going to be releasing Tor 0.2.4.22 soon.  I have a candidate
source bundle at
  This is not the final Tor 0.2.4.22 release.  It is a testing bundle
that I made today.  I'm not planning to add any more code to it,
though, unless we find new bugs.
It should have a signed SHA256 hash in the file:
  I might upload new versions over the next several days if I find bugs
to fix.
There's a copy of the current 0.2.4.x changelog here:
  Does it work for you?  (This is going to be a question for people who
build Tor from source.)  In particular, I'm most interested in any new
bugs in this version that were not in 0.2.4.21.
If you find a bug in this bundle that was not present in 0.2.4.21,
please let me know -- either by sending an email, or opening a ticket
on trac.
best wishes,

@_date: 2014-05-16 15:56:48
@_author: Nick Mathewson 
@_subject: [tor-talk] Upcoming stable release: 0.2.4.22. Please test? 
The source package is now tagged and uploaded and available from
 . This is the final actual 0.2.4.22
version.  I'll send a more formal announcement in a day or two once
some packages are built: this email is mainly for the benefit of
people who want to build packages.

@_date: 2015-01-10 15:18:25
@_author: Nick Mathewson 
@_subject: [tor-talk] new paper on Tor and cryptography 
I'd say that it's more like saying "Why should a include a proposal
for a Tor handshake also include a new elliptic curve? Or a new hash
I wouldn't say so, but I would say that the problem of "let's design a
new PQ primitive" is independent from "let's design a PQ handshake for
an anonymity network."  Ideally, the first one is something you'd get
done in a way so as to be generally useful, and you could specify the
second in terms of the first.

@_date: 2015-01-16 07:54:26
@_author: Nick Mathewson 
@_subject: [tor-talk] GSOC 15 
To begin: Google has not announced the list of organizations in GSoC
2015, so we don't know whether we're selected or not.  We hope we are,
of course, but we can't take their selection for granted.
But assuming we are selected, a student's best chances for being
selected are making sure that they have a good portfolio of
well-written, well-designed software that they wrote.  It also helps
if a student has written a few small, thoughtful, well-designed
patches for Tor in the past, so we have a feeling of what it's like to
work with them.

@_date: 2015-03-17 10:30:35
@_author: Nick Mathewson 
@_subject: [tor-talk] Pre-announcement: source for Tor 0.2.4.26 and 0.2.5.11 
Hi, all!
Usual practice when a _stable_ release comes out is to wait for
packages to be built and become available before I send it to to the
blog and the mailing lists.  But usually when I do that, I get a lot
of questions in the meantime about "hey why didn't you announce the
new release?"  So here's a pre-announcement!
You can get the source for these releases at
   Once again, I'll be sending more formal announcements to more places
once there's a
Here are the relevant changelogs -- all changes in these releases are
also in 0.2.6:
Changes in version 0.2.5.11 - 2015-03-17
  Tor 0.2.5.11 is the second stable release in the 0.2.5 series.
  It backports several bugfixes from the 0.2.6 branch, including a
  couple of medium-level security fixes for relays and exit nodes.
  It also updates the list of directory authorities.
  o Directory authority changes:
    - Remove turtles as a directory authority.
    - Add longclaw as a new (v3) directory authority. This implements
      ticket 13296. This keeps the directory authority count at 9.
    - The directory authority Faravahar has a new IP address. This
      closes ticket 14487.
  o Major bugfixes (crash, OSX, security):
    - Fix a remote denial-of-service opportunity caused by a bug in
      OSX's _strlcat_chk() function. Fixes bug 15205; bug first appeared
      in OSX 10.9.
  o Major bugfixes (relay, stability, possible security):
    - Fix a bug that could lead to a relay crashing with an assertion
      failure if a buffer of exactly the wrong layout was passed to
      buf_pullup() at exactly the wrong time. Fixes bug 15083; bugfix on
      0.2.0.10-alpha. Patch from 'cypherpunks'.
    - Do not assert if the 'data' pointer on a buffer is advanced to the
      very end of the buffer; log a BUG message instead. Only assert if
      it is past that point. Fixes bug 15083; bugfix on 0.2.0.10-alpha.
  o Major bugfixes (exit node stability):
    - Fix an assertion failure that could occur under high DNS load.
      Fixes bug 14129; bugfix on Tor 0.0.7rc1. Found by "jowr";
      diagnosed and fixed by "cypherpunks".
  o Major bugfixes (Linux seccomp2 sandbox):
    - Upon receiving sighup with the seccomp2 sandbox enabled, do not
      crash during attempts to call wait4. Fixes bug 15088; bugfix on
      0.2.5.1-alpha. Patch from "sanic".
  o Minor features (controller):
    - New "GETINFO bw-event-cache" to get information about recent
      bandwidth events. Closes ticket 14128. Useful for controllers to
      get recent bandwidth history after the fix for ticket 13988.
  o Minor features (geoip):
    - Update geoip to the March 3 2015 Maxmind GeoLite2 Country database.
    - Update geoip6 to the March 3 2015 Maxmind GeoLite2
      Country database.
  o Minor bugfixes (client, automapping):
    - Avoid crashing on torrc lines for VirtualAddrNetworkIPv[4|6] when
      no value follows the option. Fixes bug 14142; bugfix on
      0.2.4.7-alpha. Patch by "teor".
    - Fix a memory leak when using AutomapHostsOnResolve. Fixes bug
      14195; bugfix on 0.1.0.1-rc.
  o Minor bugfixes (compilation):
    - Build without warnings with the stock OpenSSL srtp.h header, which
      has a duplicate declaration of SSL_get_selected_srtp_profile().
      Fixes bug 14220; this is OpenSSL's bug, not ours.
  o Minor bugfixes (directory authority):
    - Allow directory authorities to fetch more data from one another if
      they find themselves missing lots of votes. Previously, they had
      been bumping against the 10 MB queued data limit. Fixes bug 14261;
      bugfix on 0.1.2.5-alpha.
    - Enlarge the buffer to read bwauth generated files to avoid an
      issue when parsing the file in dirserv_read_measured_bandwidths().
      Fixes bug 14125; bugfix on 0.2.2.1-alpha.
  o Minor bugfixes (statistics):
    - Increase period over which bandwidth observations are aggregated
      from 15 minutes to 4 hours. Fixes bug 13988; bugfix on 0.0.8pre1.
  o Minor bugfixes (preventative security, C safety):
    - When reading a hexadecimal, base-32, or base-64 encoded value from
      a string, always overwrite the whole output buffer. This prevents
      some bugs where we would look at (but fortunately, not reveal)
      uninitialized memory on the stack. Fixes bug 14013; bugfix on all
      versions of Tor.
Changes in version 0.2.4.26 - 2015-03-17
  Tor 0.2.4.26 includes an updated list of directory authorities.  It
  also backports a couple of stability and security bugfixes from 0.2.5
  and beyond.
  o Directory authority changes:
    - Remove turtles as a directory authority.
    - Add longclaw as a new (v3) directory authority. This implements
      ticket 13296. This keeps the directory authority count at 9.
    - The directory authority Faravahar has a new IP address. This
      closes ticket 14487.
  o Major bugfixes (exit node stability, also in 0.2.6.3-alpha):
    - Fix an assertion failure that could occur under high DNS load.
      Fixes bug 14129; bugfix on Tor 0.0.7rc1. Found by "jowr";
      diagnosed and fixed by "cypherpunks".
  o Major bugfixes (relay, stability, possible security, also in 0.2.6.4-rc):
    - Fix a bug that could lead to a relay crashing with an assertion
      failure if a buffer of exactly the wrong layout was passed to
      buf_pullup() at exactly the wrong time. Fixes bug 15083; bugfix on
      0.2.0.10-alpha. Patch from 'cypherpunks'.
    - Do not assert if the 'data' pointer on a buffer is advanced to the
      very end of the buffer; log a BUG message instead. Only assert if
      it is past that point. Fixes bug 15083; bugfix on 0.2.0.10-alpha.
  o Minor features (geoip):
    - Update geoip to the March 3 2015 Maxmind GeoLite2 Country database.
    - Update geoip6 to the March 3 2015 Maxmind GeoLite2
      Country database.

@_date: 2015-03-18 16:29:35
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.2.6.5-rc is released 
The second (and hopefully last?) release candidate for Tor 0.2.6 is
out as source.  If you build from source, you'll probably be pretty
happy!  If not, it should be in your favorite operating system's
testing repositories, or in a TB alpha release, some time pretty soon.
Until then, you can get the source in the usual places from the
Torproject.org website.
Here's the changelog for this release:
Changes in version 0.2.6.5-rc - 2015-03-18
  Tor 0.2.6.5-rc is the second and (hopefully) last release candidate in
  the 0.2.6. It fixes a small number of bugs found in 0.2.6.4-rc.
  o Major bugfixes (client):
    - Avoid crashing when making certain configuration option changes on
      clients. Fixes bug 15245; bugfix on 0.2.6.3-alpha. Reported
      by "anonym".
  o Major bugfixes (pluggable transports):
    - Initialize the extended OR Port authentication cookie before
      launching pluggable transports. This prevents a race condition
      that occured when server-side pluggable transports would cache the
      authentication cookie before it has been (re)generated. Fixes bug
      15240; bugfix on 0.2.5.1-alpha.
  o Major bugfixes (portability):
    - Do not crash on startup when running on Solaris. Fixes a bug
      related to our fix for 9495; bugfix on 0.2.6.1-alpha. Reported
      by "ruebezahl".
  o Minor features (heartbeat):
    - On relays, report how many connections we negotiated using each
      version of the Tor link protocols. This information will let us
      know if removing support for very old versions of the Tor
      protocols is harming the network. Closes ticket 15212.
  o Code simplification and refactoring:
    - Refactor main loop to extract the 'loop' part. This makes it
      easier to run Tor under Shadow. Closes ticket 15176.

@_date: 2016-02-16 10:30:18
@_author: Nick Mathewson 
@_subject: [tor-talk] The CVE-2015-7547 glibc getaddrinfo() vulnerability, 
summary: New glibc bug. If you use glibc, install your vendor's
patches as they become available. Tor is not an easy target for this
attack, but you should upgrade anyway.
Hello, all!
There's apparently a new buffer overflow vulnerability in glibc, with
a patch out today.  If you are running some GNU/linux distribution
that uses the GNU C library, then you should upgrade as soon as your
distribution has a patch.  (And if they don't get a patch for you
soon, maybe you should switch to a distribution that fixes security
holes promptly.)
More info abouve CVE-2015-7547 here:
  * If I'm reading Tor's code correctly, and if I'm reading the
vulnerability description correctly, Tor should not be an easy target
here.  Tor never uses glibc's resolver to make DNS requests for any
attacker-controlled addresses. So in order to mount an attack based on
the this vulnerability, I think you'd need to successfully take over
one of somebody's configured addresses, first by figuring out what
they're resolving, and then either by compromising an appropriate DNS
server or running an appropriate DNS cache poisoning attack.
Of course, glibc users should upgrade anyway, for a few reasons:
   * Tor is not the only program you are running; some other program
is probably affected.
   * My analysis could be wrong.
   * Who knows, your nameserver might be evil or MITM'd.
Stay safe out there!

@_date: 2017-02-03 14:22:07
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.3.0.3-alpha is released! 
Hi!  There's yet another new alpha release.  I think we're closing in
on stability for this series, which is a pretty nice feeling.
You can download the source code from the usual place on the website.
It's an alpha, so please expect bugs and be ready to report them.
Packages should be out over the next several weeks.
Changes in version 0.3.0.3-alpha - 2017-02-03
  Tor 0.3.0.3-alpha fixes a few significant bugs introduced over the
  0.3.0.x development series, including some that could cause
  authorities to behave badly. There is also a fix for a longstanding
  bug that could prevent IPv6 exits from working. Tor 0.3.0.3-alpha also
  includes some smaller features and bugfixes.
  The Tor 0.3.0.x release series is now in patch-freeze: no additional
  features will be considered for inclusion in 0.3.0.x. We suspect that
  some bugs will probably remain, however, and we encourage people to
  test this release.
  o Major bugfixes (directory authority):
    - During voting, when marking a relay as a probable sybil, do not
      clear its BadExit flag: sybils can still be bad in other ways
      too. (We still clear the other flags.) Fixes bug 21108; bugfix
      on 0.2.0.13-alpha.
    - When deciding whether we have just found a router to be reachable,
      do not penalize it for not having performed an Ed25519 link
      handshake if it does not claim to support an Ed25519 handshake.
      Previously, we would treat such relays as non-running. Fixes bug
      21107; bugfix on 0.3.0.1-alpha.
  o Major bugfixes (entry guards):
    - Stop trying to build circuits through entry guards for which we
      have no descriptor. Also, stop crashing in the case that we *do*
      accidentally try to build a circuit in such a state. Fixes bug
      21242; bugfix on 0.3.0.1-alpha.
  o Major bugfixes (IPv6 Exits):
    - Stop rejecting all IPv6 traffic on Exits whose exit policy rejects
      any IPv6 addresses. Instead, only reject a port over IPv6 if the
      exit policy rejects that port on more than an IPv6 /16 of
      addresses. This bug was made worse by 17027 in 0.2.8.1-alpha,
      which rejected a relay's own IPv6 address by default. Fixes bug
      21357; bugfix on commit 004f3f4e53 in 0.2.4.7-alpha.
  o Minor feature (client):
    - Enable IPv6 traffic on the SocksPort by default. To disable this,
      a user will have to specify "NoIPv6Traffic". Closes ticket 21269.
  o Minor feature (fallback scripts):
    - Add a check_existing mode to updateFallbackDirs.py, which checks
      if fallbacks in the hard-coded list are working. Closes ticket
      20174. Patch by haxxpop.
  o Minor features (ciphersuite selection):
    - Clients now advertise a list of ciphersuites closer to the ones
      preferred by Firefox. Closes part of ticket 15426.
    - Allow relays to accept a wider range of ciphersuites, including
      chacha20-poly1305 and AES-CCM. Closes the other part of 15426.
  o Minor features (controller, configuration):
    - Each of the *Port options, such as SocksPort, ORPort, ControlPort,
      and so on, now comes with a __*Port variant that will not be saved
      to the torrc file by the controller's SAVECONF command. This
      change allows TorBrowser to set up a single-use domain socket for
      each time it launches Tor. Closes ticket 20956.
    - The GETCONF command can now query options that may only be
      meaningful in context-sensitive lists. This allows the controller
      to query the mixed SocksPort/__SocksPort style options introduced
      in feature 20956. Implements ticket 21300.
  o Minor features (portability, compilation):
    - Autoconf now checks to determine if OpenSSL structures are opaque,
      instead of explicitly checking for OpenSSL version numbers. Part
      of ticket 21359.
    - Support building with recent LibreSSL code that uses opaque
      structures. Closes ticket 21359.
  o Minor features (relay):
    - We now allow separation of exit and relay traffic to different
      source IP addresses, using the OutboundBindAddressExit and
      OutboundBindAddressOR options respectively. Closes ticket 17975.
      Written by Michael Sonntag.
  o Minor bugfix (logging):
    - Don't recommend the use of Tor2web in non-anonymous mode.
      Recommending Tor2web is a bad idea because the client loses all
      anonymity. Tor2web should only be used in specific cases by users
      who *know* and understand the issues. Fixes bug 21294; bugfix
      on 0.2.9.3-alpha.
  o Minor bugfixes (client):
    - Always recover from failures in extend_info_from_node(), in an
      attempt to prevent any recurrence of bug 21242. Fixes bug 21372;
      bugfix on 0.2.3.1-alpha.
  o Minor bugfixes (client, entry guards):
    - Fix a bug warning (with backtrace) when we fail a channel that
      circuits to fallback directories on it. Fixes bug 21128; bugfix
      on 0.3.0.1-alpha.
    - Fix a spurious bug warning (with backtrace) when removing an
      expired entry guard. Fixes bug 21129; bugfix on 0.3.0.1-alpha.
    - Fix a bug of the new guard algorithm where tor could stall for up
      to 10 minutes before retrying a guard after a long period of no
      network. Fixes bug 21052; bugfix on 0.3.0.1-alpha.
    - Do not try to build circuits until we have descriptors for our
      primary entry guards. Related to fix for bug 21242.
  o Minor bugfixes (configure, autoconf):
    - Rename the configure option --enable-expensive-hardening to
      --enable-fragile-hardening. Expensive hardening makes the tor
      daemon abort when some kinds of issues are detected. Thus, it
      makes tor more at risk of remote crashes but safer against RCE or
      heartbleed bug category. We now try to explain this issue in a
      message from the configure script. Fixes bug 21290; bugfix
      on 0.2.5.4-alpha.
  o Minor bugfixes (controller):
    - Restore the (deprecated) DROPGUARDS controller command. Fixes bug
      20824; bugfix on 0.3.0.1-alpha.
  o Minor bugfixes (hidden service):
    - Clean up the code for expiring intro points with no associated
      circuits. It was causing, rarely, a service with some expiring
      introduction points to not open enough additional introduction
      points. Fixes part of bug 21302; bugfix on 0.2.7.2-alpha.
    - Stop setting the torrc option HiddenServiceStatistics to "0" just
      because we're not a bridge or relay. Instead, we preserve whatever
      value the user set (or didn't set). Fixes bug 21150; bugfix
      on 0.2.6.2-alpha.
    - Resolve two possible underflows which could lead to creating and
      closing a lot of introduction point circuits in a non-stop loop.
      Fixes bug 21302; bugfix on 0.2.7.2-alpha.
  o Minor bugfixes (portability):
    - Use "OpenBSD" compiler macro instead of "OPENBSD" or "__OpenBSD__".
      It is supported by OpenBSD itself, and also by most OpenBSD
      variants (such as Bitrig). Fixes bug 20980; bugfix
      on 0.1.2.1-alpha.
    - When mapping a file of length greater than SIZE_MAX, do not
      silently truncate its contents. This issue could occur on 32 bit
      systems with large file support and files which are larger than 4
      GB. Fixes bug 21134; bugfix on 0.3.0.1-alpha.
  o Minor bugfixes (tor-resolve):
    - The tor-resolve command line tool now rejects hostnames over 255
      characters in length. Previously, it would silently truncate them,
      which could lead to bugs. Fixes bug 21280; bugfix on 0.0.9pre5.
      Patch by "junglefowl".
  o Minor bugfixes (Windows services):
    - Be sure to initialize the monotonic time subsystem before using
      it, even when running as an NT service. Fixes bug 21356; bugfix
      on 0.2.9.1-alpha.

@_date: 2017-06-07 11:15:35
@_author: Nick Mathewson 
@_subject: [tor-talk] Upcoming Tor releases tomorrow, 
Hi, all!
Tomorrow we'll be putting out new releases in all supported series
(0.2.4 through 0.3.1) to fix two vulnerabilities that we have found in
the hidden service code. These vulnerabilities allow an attacker to
cause a hidden service to crash with an assertion failure.  We believe
that is the only impact.  We are tracking these vulnerabilities as
TROVE-2017-004 and TROVE-2017-005.
For more information about how we handle security issues in Tor, see
our draft policy at:
    best wishes,

@_date: 2017-06-08 11:24:17
@_author: Nick Mathewson 
@_subject: [tor-talk] Upcoming Tor releases tomorrow, 
These releases are now available from  .
They are: 0.2.4.29, 0.2.5.14, 0.2.6.12, 0.2.7.8, 0.2.8.14, 0.2.9.11,
0.3.0.8, and 0.3.1.3-alpha.
It will take a while for the website download page to upgrade, since
the system that updates the website tends to get bogged down when
there are lots of builders running at once.  I'll send out the regular
announcements once the download page is up-to-date, since it tends to
confuse people when I don't wait for that.
If you're running a hidden service, I recommend that you upgrade as
soon as a package is available for your system.
best wishes,

@_date: 2017-03-01 16:16:33
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.3.0.4-rc 
Hi!  We're making progress: Tor 0.3.0.4-rc is now "release candidate"
status, which means we think we might be just about stable, but we
hope you'll find some more bugs.
You can download the source code from the usual place on the website.
Packages should be out over the next several weeks, including Tor
Browser releases next week.
(Tor 0.2.9.10 just came out too, but stable releases go on the
tor-announcements list.)
Changes in version 0.3.0.4-rc - 2017-03-01
  Tor 0.3.0.4-rc fixes some remaining bugs, large and small, in the
  0.3.0 release series, and introduces a few reliability features to
  keep them from coming back.
  This is the first release candidate in the Tor 0.3.0 series. If we
  find no new bugs or regressions here, the first stable 0.3.0 release
  will be nearly identical to it.
  o Major bugfixes (bridges):
    - When the same bridge is configured multiple times with the same
      identity, but at different address:port combinations, treat those
      bridge instances as separate guards. This fix restores the ability
      of clients to configure the same bridge with multiple pluggable
      transports. Fixes bug 21027; bugfix on 0.3.0.1-alpha.
  o Major bugfixes (hidden service directory v3):
    - Stop crashing on a failed v3 hidden service descriptor lookup
      failure. Fixes bug 21471; bugfixes on tor-0.3.0.1-alpha.
  o Major bugfixes (parsing):
    - When parsing a malformed content-length field from an HTTP
      message, do not read off the end of the buffer. This bug was a
      potential remote denial-of-service attack against Tor clients and
      relays. A workaround was released in October 2016, to prevent this
      bug from crashing Tor. This is a fix for the underlying issue,
      which should no longer matter (if you applied the earlier patch).
      Fixes bug 20894; bugfix on 0.2.0.16-alpha. Bug found by fuzzing
      using AFL (
    - Fix an integer underflow bug when comparing malformed Tor
      versions. This bug could crash Tor when built with
      --enable-expensive-hardening, or on Tor 0.2.9.1-alpha through Tor
      0.2.9.8, which were built with -ftrapv by default. In other cases
      it was harmless. Part of TROVE-2017-001. Fixes bug 21278; bugfix
      on 0.0.8pre1. Found by OSS-Fuzz.
  o Minor feature (protocol versioning):
    - Add new protocol version for proposal 224. HSIntro now advertises
      version "3-4" and HSDir version "1-2". Fixes ticket 20656.
  o Minor features (directory authorities):
    - Directory authorities now reject descriptors that claim to be
      malformed versions of Tor. Helps prevent exploitation of
      bug 21278.
    - Reject version numbers with components that exceed INT32_MAX.
      Otherwise 32-bit and 64-bit platforms would behave inconsistently.
      Fixes bug 21450; bugfix on 0.0.8pre1.
  o Minor features (geoip):
    - Update geoip and geoip6 to the February 8 2017 Maxmind GeoLite2
      Country database.
  o Minor features (reliability, crash):
    - Try better to detect problems in buffers where they might grow (or
      think they have grown) over 2 GB in size. Diagnostic for
      bug 21369.
  o Minor features (testing):
    - During 'make test-network-all', if tor logs any warnings, ask
      chutney to output them. Requires a recent version of chutney with
      the 21572 patch. Implements 21570.
  o Minor bugfixes (certificate expiration time):
    - Avoid using link certificates that don't become valid till some
      time in the future. Fixes bug 21420; bugfix on 0.2.4.11-alpha
  o Minor bugfixes (code correctness):
    - Repair a couple of (unreachable or harmless) cases of the risky
      comparison-by-subtraction pattern that caused bug 21278.
    - Remove a redundant check for the UseEntryGuards option from the
      options_transition_affects_guards() function. Fixes bug 21492;
      bugfix on 0.3.0.1-alpha.
  o Minor bugfixes (directory mirrors):
    - Allow relays to use directory mirrors without a DirPort: these
      relays need to be contacted over their ORPorts using a begindir
      connection. Fixes one case of bug 20711; bugfix on 0.2.8.2-alpha.
    - Clarify the message logged when a remote relay is unexpectedly
      missing an ORPort or DirPort: users were confusing this with a
      local port. Fixes another case of bug 20711; bugfix
      on 0.2.8.2-alpha.
  o Minor bugfixes (guards):
    - Don't warn about a missing guard state on timeout-measurement
      circuits: they aren't supposed to be using guards. Fixes an
      instance of bug 21007; bugfix on 0.3.0.1-alpha.
    - Silence a BUG() warning when attempting to use a guard whose
      descriptor we don't know, and make this scenario less likely to
      happen. Fixes bug 21415; bugfix on 0.3.0.1-alpha.
  o Minor bugfixes (hidden service):
    - Pass correct buffer length when encoding legacy ESTABLISH_INTRO
      cells. Previously, we were using sizeof() on a pointer, instead of
      the real destination buffer. Fortunately, that value was only used
      to double-check that there was enough room--which was already
      enforced elsewhere. Fixes bug 21553; bugfix on 0.3.0.1-alpha.
  o Minor bugfixes (testing):
    - Fix Raspbian build issues related to missing socket errno in
      test_util.c. Fixes bug 21116; bugfix on tor-0.2.8.2. Patch
      by "hein".
    - Rename "make fuzz" to "make test-fuzz-corpora", since it doesn't
      actually fuzz anything. Fixes bug 21447; bugfix on 0.3.0.3-alpha.
    - Use bash in src/test/test-network.sh. This ensures we reliably
      call chutney's newer tools/test-network.sh when available. Fixes
      bug 21562; bugfix on 0.2.9.1-alpha.
  o Documentation:
    - Small fixes to the fuzzing documentation. Closes ticket 21472.

@_date: 2017-05-26 09:59:17
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.3.1.2-alpha is released! 
(Also, 0.3.0.7 was released last week.  If you didn't know, you should
subscribe to tor-announcements.)
Hi, all!
You can find the source code for Tor 0.3.1.2-alpha at
 at the usual place.  It's an alpha, so please
expect plenty of bugs, and be ready to report them.  Packages should
be out over the next weeks -- I'd expect this series to hit Tor
Browser alpha releases some time in the middle of June.
This alpha release is coming out a little ahead of schedule to fix bug
22368, which was affecting relay stability and preventing us from
getting good testing information about the 0.3.1.x series.
Changes in version 0.3.1.2-alpha - 2017-05-26
  Tor 0.3.1.2-alpha is the second release in the 0.3.1.x series. It
  fixes a few bugs found while testing 0.3.1.1-alpha, including a
  memory corruption bug that affected relay stability.
  Below are the changes since 0.3.1.1-alpha.
  o Major bugfixes (crash, relay):
    - Fix a memory-corruption bug in relays that set MyFamily.
      Previously, they would double-free MyFamily elements when making
      the next descriptor or when changing their configuration. Fixes
      bug 22368; bugfix on 0.3.1.1-alpha.
  o Minor bugfixes (logging):
    - Log a better message when a directory authority replies to an
      upload with an unexpected status code. Fixes bug 11121; bugfix
      on 0.1.0.1-rc.
  o Minor bugfixes (memory leak, directory authority):
    - When directory authorities reject a router descriptor due to
      keypinning, free the router descriptor rather than leaking the
      memory. Fixes bug 22370; bugfix on 0.2.7.2-alpha.

@_date: 2017-09-05 10:36:39
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.3.1.6-rc is released! 
Hi, all!
There's a new Tor release candidate available!  The source is available
from the "download" page on the website on the website, and packages
should be available before long. The Tor Browser team expects to get a
release out later this month.
This is a release candidate; please help find bugs in it! If we don't
find any new critical problems, we'll be calling this release series
"stable" soon.
Changes in version 0.3.1.6-rc - 2017-09-05
  Tor 0.3.1.6-rc fixes a few small bugs and annoyances in the 0.3.1
  release series, including a bug that produced weird behavior on
  Windows directory caches.
  This is the first release candidate in the Tor 0.3.1 series. If we
  find no new bugs or regressions here, the first stable 0.3.1 release
  will be nearly identical to it.
  o Major bugfixes (windows, directory cache):
    - On Windows, do not try to delete cached consensus documents and
      diffs before they are unmapped from memory--Windows won't allow
      that. Instead, allow the consensus cache directory to grow larger,
      to hold files that might need to stay around longer. Fixes bug
      22752; bugfix on 0.3.1.1-alpha.
  o Minor features (directory authority):
    - Improve the message that authorities report to relays that present
      RSA/Ed25519 keypairs that conflict with previously pinned keys.
      Closes ticket 22348.
  o Minor features (geoip):
    - Update geoip and geoip6 to the August 3 2017 Maxmind GeoLite2
      Country database.
  o Minor features (testing):
    - Add more tests for compression backend initialization. Closes
      ticket 22286.
  o Minor bugfixes (directory cache):
    - Fix a memory leak when recovering space in the consensus cache.
      Fixes bug 23139; bugfix on 0.3.1.1-alpha.
  o Minor bugfixes (hidden service):
    - Increase the number of circuits that a service is allowed to
      open over a specific period of time. The value was lower than it
      should be (8 vs 12) in the normal case of 3 introduction points.
      Fixes bug 22159; bugfix on 0.3.0.5-rc.
    - Fix a BUG warning during HSv3 descriptor decoding that could be
      cause by a specially crafted descriptor. Fixes bug 23233; bugfix
      on 0.3.0.1-alpha. Bug found by "haxxpop".
    - Rate-limit the log messages if we exceed the maximum number of
      allowed intro circuits. Fixes bug 22159; bugfix on 0.3.1.1-alpha.
  o Minor bugfixes (logging, relay):
    - Remove a forgotten debugging message when an introduction point
      successfully establishes a hidden service prop224 circuit with
      a client.
    - Change three other log_warn() for an introduction point to
      protocol warnings, because they can be failure from the network
      and are not relevant to the operator. Fixes bug 23078; bugfix on
      0.3.0.1-alpha and 0.3.0.2-alpha.
  o Minor bugfixes (relay):
    - When a relay is not running as a directory cache, it will no
      longer generate compressed consensuses and consensus diff
      information. Previously, this was a waste of disk and CPU. Fixes
      bug 23275; bugfix on 0.3.1.1-alpha.
  o Minor bugfixes (robustness, error handling):
    - Improve our handling of the cases where OpenSSL encounters a
      memory error while encoding keys and certificates. We haven't
      observed these errors in the wild, but if they do happen, we now
      detect and respond better. Fixes bug 19418; bugfix on all versions
      of Tor. Reported by Guido Vranken.
  o Minor bugfixes (stability):
    - Avoid crashing on a double-free when unable to load or process an
      included file. Fixes bug 23155; bugfix on 0.3.1.1-alpha. Found
      with the clang static analyzer.
  o Minor bugfixes (testing):
    - Fix an undersized buffer in test-memwipe.c. Fixes bug 23291;
      bugfix on 0.2.7.2-alpha. Found and patched by Ties Stuij.
    - Port the hs_ntor handshake test to work correctly with recent
      versions of the pysha3 module. Fixes bug 23071; bugfix
      on 0.3.1.1-alpha.
  o Minor bugfixes (Windows service):
    - When running as a Windows service, set the ID of the main thread
      correctly. Failure to do so made us fail to send log messages to
      the controller in 0.2.1.16-rc, slowed down controller event
      delivery in 0.2.7.3-rc and later, and crash with an assertion
      failure in 0.3.1.1-alpha. Fixes bug 23081; bugfix on 0.2.1.6-alpha.
      Patch and diagnosis from "Vort".

@_date: 2018-06-12 12:57:51
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.3.4.2-alpha is released! 
Hi, all!
There's a new alpha Tor release!  Because it's an alpha, you should
only run it if you're ready to find more bugs than usual, and report
them on trac.torproject.org.
The source code is available from the usual place on
 if you build Tor from source, why not give it a
try?  And if you don't build Tor from source, packages should be ready
over the coming days, with a Tor Browser alpha release likely some
time in the next few weeks.
There's also a new stable release coming out today; as usual, that one
gets announced on the tor-announce mailing list.
Changes in version 0.3.4.2-alpha - 2018-06-12
  Tor 0.3.4.2-alpha fixes several minor bugs in the previous alpha
  release, and forward-ports an authority-only security fix from 0.3.3.6.
  o Directory authority changes:
    - Add an IPv6 address for the "dannenberg" directory authority.
      Closes ticket 26343.
  o Major bugfixes (security, directory authority, denial-of-service,
also in 0.3.3.6):
    - Fix a bug that could have allowed an attacker to force a directory
      authority to use up all its RAM by passing it a maliciously
      crafted protocol versions string. Fixes bug 25517; bugfix on
      0.2.9.4-alpha. This issue is also tracked as TROVE-2018-005.
  o Minor features (continuous integration):
    - Add the necessary configuration files for continuous integration
      testing on Windows, via the Appveyor platform. Closes ticket
      25549. Patches from Marcin Cielak and Isis Lovecruft.
  o Minor features (geoip):
    - Update geoip and geoip6 to the June 7 2018 Maxmind GeoLite2
      Country database. Closes ticket 26351.
  o Minor bugfixes (compatibility, openssl):
    - Work around a change in OpenSSL 1.1.1 where return values that
      would previously indicate "no password" now indicate an empty
      password. Without this workaround, Tor instances running with
      OpenSSL 1.1.1 would accept descriptors that other Tor instances
      would reject. Fixes bug 26116; bugfix on 0.2.5.16.
  o Minor bugfixes (compilation):
    - Silence unused-const-variable warnings in zstd.h with some GCC
      versions. Fixes bug 26272; bugfix on 0.3.1.1-alpha.
    - Fix compilation when using OpenSSL 1.1.0 with the "no-deprecated"
      flag enabled. Fixes bug 26156; bugfix on 0.3.4.1-alpha.
    - Avoid a compiler warning when casting the return value of
      smartlist_len() to double with DEBUG_SMARTLIST enabled. Fixes bug
      26283; bugfix on 0.2.4.10-alpha.
  o Minor bugfixes (control port):
    - Do not count 0-length RELAY_COMMAND_DATA cells as valid data in
      CIRC_BW events. Previously, such cells were counted entirely in
      the OVERHEAD field. Now they are not. Fixes bug 26259; bugfix
      on 0.3.4.1-alpha.
  o Minor bugfixes (controller):
    - Improve accuracy of the BUILDTIMEOUT_SET control port event's
      TIMEOUT_RATE and CLOSE_RATE fields. (We were previously
      miscounting the total number of circuits for these field values.)
      Fixes bug 26121; bugfix on 0.3.3.1-alpha.
  o Minor bugfixes (hardening):
    - Prevent a possible out-of-bounds smartlist read in
      protover_compute_vote(). Fixes bug 26196; bugfix on 0.2.9.4-alpha.
  o Minor bugfixes (onion services):
    - Fix a bug that blocked the creation of ephemeral v3 onion
      services. Fixes bug 25939; bugfix on 0.3.4.1-alpha.
  o Minor bugfixes (test coverage tools):
    - Update our "cov-diff" script to handle output from the latest
      version of gcov, and to remove extraneous timestamp information
      from its output. Fixes bugs 26101 and 26102; bugfix
      on 0.2.5.1-alpha.

@_date: 2019-01-20 20:47:01
@_author: Nick Mathewson 
@_subject: [tor-talk] [tor-announce] Tor 0.3.5.7 is released 
Hi, Jim!
You probably need to refresh my key from the keyservers:
[1718]$ gpg --list-keys nickm at torproject.org
pub   4096R/FE43009C4607B1FB 2016-09-21 [expires: 2020-09-16]
uid                          Nick Mathewson uid                          Nick Mathewson uid                          Nick Mathewson uid                          Nick Mathewson sub   4096R/6AFEE6D49E92B601 2016-09-23 [expires: 2020-09-16]
sub   4096R/91DDED0286AC8BFF 2016-09-23 [expires: 2020-09-16]

@_date: 2019-03-22 16:02:30
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor 0.4.0.3-alpha is released! 
Hi, all!
There's a new alpha Tor release! Because it's an alpha, you should
only run it if you're ready to find more bugs than usual, and report
them on trac.torproject.org.
The source code is available from the usual place on
 if you build Tor from source, why not give it a
try? And if you don't build Tor from source, packages should be ready
over the coming days, with a Tor Browser alpha release likely by
Here's what's new:
Changes in version 0.4.0.3-alpha - 2019-03-22
  Tor 0.4.0.3-alpha is the third in its series; it fixes several small
  bugs from earlier versions.
  o Minor features (address selection):
    - Treat the subnet 100.64.0.0/10 as public for some purposes;
      private for others. This subnet is the RFC 6598 (Carrier Grade
      NAT) IP range, and is deployed by many ISPs as an alternative to
      RFC 1918 that does not break existing internal networks. Tor now
      blocks SOCKS and control ports on these addresses and warns users
      if client ports or ExtORPorts are listening on a RFC 6598 address.
      Closes ticket 28525. Patch by Neel Chauhan.
  o Minor features (geoip):
    - Update geoip and geoip6 to the March 4 2019 Maxmind GeoLite2
      Country database. Closes ticket 29666.
  o Minor bugfixes (circuitpadding):
    - Inspect the circuit-level cell queue before sending padding, to
      avoid sending padding when too much data is queued. Fixes bug
      29204; bugfix on 0.4.0.1-alpha.
  o Minor bugfixes (logging):
    - Correct a misleading error message when IPv4Only or IPv6Only is
      used but the resolved address can not be interpreted as an address
      of the specified IP version. Fixes bug 13221; bugfix on
      0.2.3.9-alpha. Patch from Kris Katterjohn.
    - Log the correct port number for listening sockets when "auto" is
      used to let Tor pick the port number. Previously, port 0 was
      logged instead of the actual port number. Fixes bug 29144; bugfix
      on 0.3.5.1-alpha. Patch from Kris Katterjohn.
    - Stop logging a BUG() warning when Tor is waiting for exit
      descriptors. Fixes bug 28656; bugfix on 0.3.5.1-alpha.
  o Minor bugfixes (memory management):
    - Refactor the shared random state's memory management so that it
      actually takes ownership of the shared random value pointers.
      Fixes bug 29706; bugfix on 0.2.9.1-alpha.
  o Minor bugfixes (memory management, testing):
    - Stop leaking parts of the shared random state in the shared-random
      unit tests. Fixes bug 29599; bugfix on 0.2.9.1-alpha.
  o Minor bugfixes (pluggable transports):
    - Fix an assertion failure crash bug when a pluggable transport is
      terminated during the bootstrap phase. Fixes bug 29562; bugfix
      on 0.4.0.1-alpha.
  o Minor bugfixes (Rust, protover):
    - Add a missing "Padding" value to the Rust implementation of
      protover. Fixes bug 29631; bugfix on 0.4.0.1-alpha.
  o Minor bugfixes (single onion services):
    - Allow connections to single onion services to remain idle without
      being disconnected. Previously, relays acting as rendezvous points
      for single onion services were mistakenly closing idle rendezvous
      circuits after 60 seconds, thinking that they were unused
      directory-fetching circuits that had served their purpose. Fixes
      bug 29665; bugfix on 0.2.1.26.
  o Minor bugfixes (stats):
    - When ExtraInfoStatistics is 0, stop including PaddingStatistics in
      relay and bridge extra-info documents. Fixes bug 29017; bugfix
      on 0.3.1.1-alpha.
  o Minor bugfixes (testing):
    - Downgrade some LOG_ERR messages in the address/* tests to
      warnings. The LOG_ERR messages were occurring when we had no
      configured network. We were failing the unit tests, because we
      backported 28668 to 0.3.5.8, but did not backport 29530. Fixes bug
      29530; bugfix on 0.3.5.8.
    - Fix our gcov wrapper script to look for object files at the
      correct locations. Fixes bug 29435; bugfix on 0.3.5.1-alpha.
    - Decrease the false positive rate of stochastic probability
      distribution tests. Fixes bug 29693; bugfix on 0.4.0.1-alpha.
  o Minor bugfixes (Windows, CI):
    - Skip the Appveyor 32-bit Windows Server 2016 job, and 64-bit
      Windows Server 2012 R2 job. The remaining 2 jobs still provide
      coverage of 64/32-bit, and Windows Server 2016/2012 R2. Also set
      fast_finish, so failed jobs terminate the build immediately. Fixes
      bug 29601; bugfix on 0.3.5.4-alpha.

@_date: 2020-05-07 10:45:08
@_author: Nick Mathewson 
@_subject: [tor-talk] Tor Post-Quantum Cryptography 
Hi!  There are several proposals for this:
We don't have a current implementation timeline for these.  Step one
in any one of them would be implementing:
or something similar such as:
