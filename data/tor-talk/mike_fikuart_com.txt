
@_date: 2014-08-10 18:20:19
@_author: Mike Fikuart 
@_subject: [tor-talk] Scaling Tor 
Hi Tor-Talk,
I am doing an MSc in Telecommunications and Network at City University, London.  For my dissertation I am looking at the limitations of scaling Tor up and how the limits could be overcome and should state that I am not a programmer, though would love to be involved in Tor?s progress.
I?m not sure if I am confusing Authority Server and Directory Authority and Directory Server or if they are all one and the same...
Firstly, in the original Tor documentation (Tor-Design 18/05/2004) initial ?theoretical? limits were stated that Tor could operate, then three, but as many as, up to nine DA?s (Directory Authorities); however I note from the documentation you have gone through various version releases; have introduced directory caches etc to mitigate the overloading of the DA?s and now have ten DA?s operating and overall improved network performance.  Later (section 8) "Early experiences: Tor in the Wild? states initial expectations "of the network to support a few hundred nodes and 10,000 users before we?re forced to become more distributed?.  This reference was made to the ?clique topology? and ?full-visibility directories?, yet you now operate almost 6,000 relays and around 2.25M users (directly connected).  Have you fundamentally changed the topology or have you found gains in the reporting of relays for form the consensus (or elsewhere) to allow this scale factor?
Two of the bottle necks identified in dir-spec (section 0.3 Some Remaining Questions) are that having every client know about every relay; and to have every Directory Cache to know about every router won?t scale ad infinitum. A question raised in Tor-Design (section 9) is, "if clients can no longer have a complete picture of the network, how can they perform discovery while preventing attackers from manipulating or exploiting gaps in their knowledge??.  If the network were to be considered to scale up to significant number of all Internet users, could it be that the Directory Authority(Ies) release (to Directory Caches and clients) a even random sample of relays/nodes from the FULL set of nodes, such that the randomness of the path selection is still maintained.  The random selection could be sampled on a per client basis with enough of a sample as is currently downloaded (6000 relays).  What this means is that each client (or possibly groupings of clients) is getting a different ?view? of the network, but there would need to be a scaling down from the full set to the sample set at some point before the client.  I have looked over the documentation for the path selection, directory protocol and the consensus, but have not documented the timing of the exchanges of communications.  I imagine that this is an area that could present a limit if scaled up.  What are the current areas that present limitations for large scaling up?
I have been able to access most of the relevant documentation through the  but would appreciate it if there are any other repositories of info.  As mentioned at the start, I am not a programmer so the code base is meaningless to me :(
A small note; it would be useful for the documentation to be dated (and reversioner with dates) to indicate the freshness and relevance of the data.  I am aware that this may be a resource issue.
I appreciate your support with the network and hope to be able to contribute more in the future.
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart

@_date: 2014-08-10 18:25:30
@_author: Mike Fikuart 
@_subject: [tor-talk] Scaling Tor 
Hi Tor-Talk,
I am doing an MSc in Telecommunications and Network at City University, London.  For my dissertation I am looking at the limitations of scaling Tor up and how the limits could be overcome and should state that I am not a programmer, though would love to be involved in Tor?s progress.
I?m not sure if I am confusing Authority Server and Directory Authority and Directory Server or if they are all one and the same...
Firstly, in the original Tor documentation (Tor-Design 18/05/2004) initial ?theoretical? limits were stated that Tor could operate, then three, but as many as, up to nine DA?s (Directory Authorities); however I note from the documentation you have gone through various version releases; have introduced directory caches etc to mitigate the overloading of the DA?s and now have ten DA?s operating and overall improved network performance.  Later (section 8) "Early experiences: Tor in the Wild? states initial expectations "of the network to support a few hundred nodes and 10,000 users before we?re forced to become more distributed?.  This reference was made to the ?clique topology? and ?full-visibility directories?, yet you now operate almost 6,000 relays and around 2.25M users (directly connected).  Have you fundamentally changed the topology or have you found gains in the reporting of relays for form the consensus (or elsewhere) to allow this scale factor?
Two of the bottle necks identified in dir-spec (section 0.3 Some Remaining Questions) are that having every client know about every relay; and to have every Directory Cache to know about every router won?t scale ad infinitum. A question raised in Tor-Design (section 9) is, "if clients can no longer have a complete picture of the network, how can they perform discovery while preventing attackers from manipulating or exploiting gaps in their knowledge??.  If the network were to be considered to scale up to significant number of all Internet users, could it be that the Directory Authority(Ies) release (to Directory Caches and clients) a even random sample of relays/nodes from the FULL set of nodes, such that the randomness of the path selection is still maintained.  The random selection could be sampled on a per client basis with enough of a sample as is currently downloaded (6000 relays).  What this means is that each client (or possibly groupings of clients) is getting a different ?view? of the network, but there would need to be a scaling down from the full set to the sample set at some point before the client.  I have looked over the documentation for the path selection, directory protocol and the consensus, but have not documented the timing of the exchanges of communications.  I imagine that this is an area that could present a limit if scaled up.  What are the current areas that present limitations for large scaling up?
I have been able to access most of the relevant documentation through the  but would appreciate it if there are any other repositories of info.  As mentioned at the start, I am not a programmer so the code base is meaningless to me :(
A small note; it would be useful for the documentation to be dated (and reversioner with dates) to indicate the freshness and relevance of the data.  I am aware that this may be a resource issue.
I appreciate your support with the network and hope to be able to contribute more in the future.
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart

@_date: 2014-08-10 18:25:31
@_author: Mike Fikuart 
@_subject: [tor-talk] Scaling Tor 
Hi Tor-Talk,
I am doing an MSc in Telecommunications and Network at City University, London.  For my dissertation I am looking at the limitations of scaling Tor up and how the limits could be overcome and should state that I am not a programmer, though would love to be involved in Tor?s progress.
I?m not sure if I am confusing Authority Server and Directory Authority and Directory Server or if they are all one and the same...
Firstly, in the original Tor documentation (Tor-Design 18/05/2004) initial ?theoretical? limits were stated that Tor could operate, then three, but as many as, up to nine DA?s (Directory Authorities); however I note from the documentation you have gone through various version releases; have introduced directory caches etc to mitigate the overloading of the DA?s and now have ten DA?s operating and overall improved network performance.  Later (section 8) "Early experiences: Tor in the Wild? states initial expectations "of the network to support a few hundred nodes and 10,000 users before we?re forced to become more distributed?.  This reference was made to the ?clique topology? and ?full-visibility directories?, yet you now operate almost 6,000 relays and around 2.25M users (directly connected).  Have you fundamentally changed the topology or have you found gains in the reporting of relays for form the consensus (or elsewhere) to allow this scale factor?
Two of the bottle necks identified in dir-spec (section 0.3 Some Remaining Questions) are that having every client know about every relay; and to have every Directory Cache to know about every router won?t scale ad infinitum. A question raised in Tor-Design (section 9) is, "if clients can no longer have a complete picture of the network, how can they perform discovery while preventing attackers from manipulating or exploiting gaps in their knowledge??.  If the network were to be considered to scale up to significant number of all Internet users, could it be that the Directory Authority(Ies) release (to Directory Caches and clients) a even random sample of relays/nodes from the FULL set of nodes, such that the randomness of the path selection is still maintained.  The random selection could be sampled on a per client basis with enough of a sample as is currently downloaded (6000 relays).  What this means is that each client (or possibly groupings of clients) is getting a different ?view? of the network, but there would need to be a scaling down from the full set to the sample set at some point before the client.  I have looked over the documentation for the path selection, directory protocol and the consensus, but have not documented the timing of the exchanges of communications.  I imagine that this is an area that could present a limit if scaled up.  What are the current areas that present limitations for large scaling up?
I have been able to access most of the relevant documentation through the  but would appreciate it if there are any other repositories of info.  As mentioned at the start, I am not a programmer so the code base is meaningless to me :(
A small note; it would be useful for the documentation to be dated (and reversioner with dates) to indicate the freshness and relevance of the data.  I am aware that this may be a resource issue.
I appreciate your support with the network and hope to be able to contribute more in the future.
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart

@_date: 2014-08-17 17:44:44
@_author: Mike Fikuart 
@_subject: [tor-talk] Scaling Tor 
Hi Tor-Talk,
I am interested in the scaling limits to Tor and what present the bottlenecks to Tor?s future expansion.  I have looked into the documentation available and see that Tor has far exceeded initial projections through structural changes to the relationships between clients, DA?s and relays.
Two of the bottle necks identified in dir-spec (section 0.3 Some Remaining Questions) are that having every client know about every relay; and to have every Directory Cache to know about every router won?t scale ad infinitum.
Is there a known threshold that on the horizon that you are aware of but don?t need to address at this stage?
What are the limiting factors to the unchallenged scaling up of Tor to the multiple million users and nodes?
I would like some guidance in where these pinch points are so as to research this in greater detail.
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart

@_date: 2014-08-18 10:57:32
@_author: Mike Fikuart 
@_subject: [tor-talk] Scaling Tor 
Thanks, George.
Interesting proposal and an area I hadn?t considered to be an issue.  I will look again at the HS process and review links in more detail.
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart
Hi Tor-Talk,
I am interested in the scaling limits to Tor and what present the
bottlenecks to Tor?s future expansion.  I have looked into the
documentation available and see that Tor has far exceeded initial
projections through structural changes to the relationships between
clients, DA?s and relays.
Hidden Services have trouble scaling.
We've been thinking how to build availability in them by allowing
multiple nodes behind a single HS. There are many threads about this
in [tor-dev].
A good starting point is:
along with the threads it references in the beginning.
tor-talk mailing list - tor-talk at lists.torproject.org
To unsubscribe or change other settings go to

@_date: 2014-08-18 21:40:53
@_author: Mike Fikuart 
@_subject: [tor-talk] Scaling Tor 
Thanks Virgil.  I wasn?t directly what I was after; however it was an informative read and as with this subject grows the background knowledge that will come to use in the future.  I did get an interesting link from Johan Pouweise on scalability that his students published this year  which gives a good overview of the dilemma of decentralisation (FYI).
A question raised in Tor-Design (section 9) is, "if clients can no longer have a complete picture of the network, how can they perform discovery while preventing attackers from manipulating or exploiting gaps in their knowledge??.  If the network were to be considered to scale up to significant number of all Internet users, could it be that the Directory Authority(Ies) release (to Directory Caches and clients) a uniform, random sample of relays/nodes from the FULL set of nodes, such that the randomness of the path selection is still maintained.  The random selection could be sampled on a per client basis with enough of a sample as is currently downloaded (6000 relays).  What this means is that each client (or possibly groupings of clients) is getting a different ?view? of the network, but there would need to be a scaling down from the full set to the sample set at some point before the client.  Any thoughts on the idea?
Yours sincerely
Mike Fikuart

@_date: 2014-08-18 23:20:30
@_author: Mike Fikuart 
@_subject: [tor-talk] Scaling Tor 
Isis, brilliant response!  Some good bedtime reading to do, but just the track I was needing. Thanks for the support!
Yours sincerely
Mike Fikuart

@_date: 2014-07-30 11:43:46
@_author: Mike Fikuart 
@_subject: [tor-talk] Tor DNS 
I am not sure if this the correct forum for this question and if not would you direct me there; however:
I am aware that there is a Project Idea (under  point q. Improved DNS support for Tor; however has there been any exploration or development of a fully fledged DNS system for Tor that could give human readable names to hidden services?
This could give full DNS control over the domain and expand on the project listed above.  This would give a step advance in usability of Hidden Services and therefore the user traffic and public awareness.
If further consideration is given to also pursuing the registration of the .onion domain as a TLD, this could also open further publicity and revenue for the Tor Project.   The domain auctions for .tv and .co raised significant revenue for the Tuvalu and Colombian countries not to mention the managing organisations.
Has any of this been looked at previously or are there reasons why this is not being pursued?
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart

@_date: 2014-07-31 12:22:02
@_author: Mike Fikuart 
@_subject: [tor-talk] Tor DNS 
Thanks for the response Ondrej.
I was thinking specifically for the .onion addresses as opposed to the conventional www addressing.  When the client first recognises the .onion domain, could a DNS be set up within Tor dealing only with .onion hostnames/domain space and conventional DNS requests for www be handled as currently (or developed as per proposal 129)?
My thought was that [hiddenservice].onion would be dealt with by the Tor NameServer to return the hostname (derived from public key).  From here the hidden services protocol would continue as per normal.  The only weakness would be the security of the information coming back from the D/NS pointing to the same hostname.onion; however with Tor circuit/s to the DNS this should negate such an attack.  Further to your comment about the request leaving the Tor network; these DNS requests would be handled internally, never leaving the network.  Is this feasible and reliably reproducible?
Just as there was the increasing need for the Tor search engine, this would (I believe) encourage more people to benefit from presenting their information/services in a usable format.
I note your further comments about the cost/resources of registering the TLD .onion, but there may be a time when there is a business model that can benefit from the investment and returns.
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart
I am the author of the proposal 219.
If you want DNS, you can make it work today via a tunnel with Unbound. One
sample howto:  - DNSSEC is optional
I have spent more than half a year trying to make it work. Most time spent was
due to DNSSEC and especially its latency - it is quite easy to have 20
roundtrips for one DNS request because of CNAME and DNAME. Which can take 5-20
seconds - incurring seemingly "random" errors (from the user's point of view).
On a good day with good circuit and "heated cache" you can get average ~3 secs
to resolve a request.
This is not a good idea for many reasons. I'm not up-to-date with the latest
rendezvous protocol, but AFAIK the DNS request would be sent from different
exit node than the nodes used for rendezvous - which would in turn make
correlation attacks easier.
TLD costs $150k USD as "down payment" and requires additional infrastructure
to support the gTLS which is not cheap. There are much better ways how to
spend the resources.
DNS being 30+ years old has incredibly many special cases. There are
quick-and-dirty implementations but that's probably not what one would want
with anonymity software.

@_date: 2014-09-05 17:00:03
@_author: Mike Fikuart 
@_subject: [tor-talk] GEOIP's 
Hi Group,
I am looking into the various files used by the OR?s and OP?s and would like to know more about the GEOIP file and use.  I have already seen in the dir-spec document that these GEOIP?s are created in the ?Extra-info? document and relate to country codes for bridges and in turn was referred to the blocking.pdf document, which went a bit further in the same vein.
The blocking.pdf (Design of a blocking-resistant anonymity system, Tor Project technical report, Nov 2006) suggests "the compressed GEOIP database is only a few hundred kilobytes?, but the geoip file on my relay is about 2MB.  Is this just because it is decompressed, now a much larger DB or is not the DB being referred to in the document?
The geoip file has 82,363 different Country Code entries listed.  What do they relate to, as this would far exceed the bridges and relays?
I seem to remember (but now cannot find the reference) that the geoip?s have been responsible for improving the routing of data or selection of relays for circuits.  Is this correct and how does this work?
I would appreciate an explanation or a point in the direction of the appropriate documentation, thanks.
Yours sincerely
Mike Fikuart IEng MIET
Mobile: 07801 070580
Office: 020 33840275
Blog: mikefikuart
Skype: mikefikuart
Twitter: mikefikuart
LinkedIn: mikefikuart

@_date: 2014-09-06 13:54:13
@_author: Mike Fikuart 
@_subject: [tor-talk] GEOIP's 
Yes, thanks this is useful.
The current database lists 94566 IP/CC listings.
Is this a cut down version of the full database just for Tor and only listing bridges and routers, or what do those geoips relate to?
More relevant for me for Tor and it?s improvement over the years, does the algorithm for routing or circuit creation use the geoip and is it attributable to the improved performance of Tor in recent years?
I seem to remember (but now cannot find the reference) that the geoip?s have been responsible for improving the routing of data or selection of relays for circuits.  Is this correct and how does this work?
The geoip file has 82,363 different Country Code entries listed.
What do they relate to, as this would far exceed the bridges and
I seem to remember (but now cannot find the reference) that the
geoip?s have been responsible for improving the routing of data or
selection of relays for circuits.  Is this correct and how does this
The first few lines tell you how this file is generated:
# Last updated based on August 7 2014 Maxmind GeoLite2 Country
# wget
# gunzip GeoLite2-Country.mmdb.gz
# python mmdb-convert.py GeoLite2-Country.mmdb
See also the MaxMind website for details what's contained in their database.
Regarding database size, here's what happens when I compress the geoip file:
-rw-r--r--  1 karsten  staff   2.2M Sep  5 21:18 geoip
-rw-r--r--  1 karsten  staff   678K Sep  5 21:18 geoip.bz2
-rw-r--r--  1 karsten  staff   688K Sep  5 21:18 geoip.gz
-rw-r--r--  1 karsten  staff   402K Sep  5 21:18 geoip.xz
Not sure if this answers all your questions, but maybe it's a start.
All the best,
tor-talk mailing list - tor-talk at lists.torproject.org
To unsubscribe or change other settings go to

@_date: 2014-09-06 17:41:58
@_author: Mike Fikuart 
@_subject: [tor-talk] GEOIP's 
Clear on that now.  Thanks for your guidance.
Great work support group!

@_date: 2014-09-14 15:20:19
@_author: Mike Fikuart 
@_subject: [tor-talk] Advertising a hidden service? 
I think you are asking for a simple pragmatic answer like TorSearch submit a page: ?but the answer below is correct.  Advertise and distribute as you would a regular website.
I just set up a new hidden service for Tor. I'd like to make it
available to everyone in the Tor community. What's the best was to go
about doing this? The Tor Hidden Wiki? The Torlinks page? How do I go
about getting my site included and publicized?
Just as you would publicize any other website. Many people (technology journalists among them) appear to think that "the hidden internet" or "the dark web" is something that must be "tunneled into" and accessed only through a special portal such as the ones you have mentioned, when really they should be thinking of hidden services as usable alongside - and linkable from - any other web service.
Restricting the advertisement of hidden services to other hidden services will not help defeat the "dark web" mental model.
Of course, it then depends on the nature of your service and the target users.
tor-talk mailing list - tor-talk at lists.torproject.org
To unsubscribe or change other settings go to

@_date: 2015-03-09 11:04:18
@_author: Mike Fikuart 
@_subject: [tor-talk] Tor scaling and the distributed consensus 
Hi Tor-Talk,
This is a long one, but the main point is in the first paragraphs...
I was in contact previously (Aug 2014) where [you] gave assistance with the above subject for research I was doing for my dissertation.  Dissertation now complete I wanted to pass back a proposal for the distribution of a limited size consensus document.  This is by no means tested and validated, but remains an idea and concept of how this could be addressed.  I would be interested in your view as Tor developer(s) whether this is a viable concept to develop.
For ease I take an extraction of the ?Suggestion for further work? which is the essence, "A proposed alternative to the current format of the consensus document and relay descriptors would be to limit the size of the set of available relays. The anonymity of users of the Tor network has been achieved since the set size of the participating users was in the tens of thousands. Beyond a point of provable anonymity, increasing the size of the set would not increase the amount of anonymity. Therefore, if a sample subset r were chosen from the entire set R of all the available members, r?R, to be of efficient size and provide provable anonymity, this could limit the file size of the consensus document that is distributed to Directory Caches and ultimately to OPs and ORs. (For the remainder of this description OPs will refer to OPs and ORs)
The proportion of the member characteristics of r should be such that the circuit construction algorithm objectives can be efficiently maintained, for example stable relays for long-lived circuits, high and low bandwidth relays, and a range of Exit Relays with a selection of exit policies.
The ?consensus vote? would be formed in the same manner as is currently done, to create the set R; however the Directory Authorities would then make the selection r from R. The selection of members of r should be continuously and evenly random (in the proportions mentioned above, as subsets) such that ri?R where i = ?. The different subsets ri of R should be chosen by the Directory Authorities, signed and disseminated to the Directory Caches in a continuous and periodic manner. The OPs would then download the ri consensus as is currently done. The relay descriptors could be updated as is currently done by selectively downloading only the descriptors not currently known. This can be qualified by only downloading the descriptors not known in the current consensus ri and further limiting the overall cached-descriptor file maintained by the OP to an upper limit by discarding the oldest or least valuable data."
Below I quote from my dissertation ?Conclusions" and ?Suggestion for further work? and include the link to the full dissertation FYI.  There is also a Prezi presentation related to the dissertation (in full) and for simplicity the graphical representation of the concept.
 "8. Conclusions
Tor?s strength of anonymity is in its large and diverse anonymity set spread around the world. The range of users covers those with a fundamental belief in the right to their own private communications, to users that are dependent on their communications not being intercepted or knowledge that they are communicating with certain other people or organisations. For that latter set of users, the safety and security and freedom from persecution are dependent on the certainty of anonymity offered by the Tor network. Trade- offs against this tenet are unacceptable and would render the network irrelevant and ultimately obsolete. Numerous other networks [19],[40],[41] have been spawned from the robustness of the Tor protocol, to offer users scalable P2P communications or file sharing or remailer services, but have not been able to maintain the level of trust required to ensure anonymity under attack.
One may be prepared to take a calculated risk of prosecution for copyright infringement for sharing or downloading a film for entertainment by using a P2P-based BitTorrent-like network, but if one?s life, security or freedom is at stake, one needs to have full trust in the technology one uses. The Tor network is growing at an exponential rate and is adapting to meet the demand, while at the same time not compromising on the security and anonymity of communications. Betraying the trust of the millions of daily users by improving scalability or performance at the expense of those tenets would immediately render it obsolete.
The conventional client/server model offers trust at the expense of scalability, and the current P2P implementations using DHT and similar unauthenticated peer lookup mechanism offer scalability at the expense of trust. Tor has grown and developed organically to overcome the scaling pinch points, as they manifested to become obstacles to performance and growth. Maintaining this ethos will ensure that research will continue to be conducted into alternative network structures whilst not jeopardising network trust.
Tor?s robustness can be attributed to its distributed trust model. The trust that is established and controlled at the Directory Authority level is manifested in the consensus and relay descriptor documents. These are signed and distributed to OPs and ORs that make their own decisions based on these trusted documents without needing to evaluate the trust of the individual members.
There are currently proposals that will streamline the consensus vote amongst the Directory Authorities; however, the larger question of whether all OPs need to know about all ORs in the system has yet to be addressed.
The organic growth of Tor and incremental improvement to the efficiency of the directory protocol and network performance, while adhering to tenets of security and anonymity, appear to offer a viable way forward. This conservative progress has continued to attract new users and keeps Tor current and relevant until a paradigm shift takes place in how the trust can be distributed between segregated subsets of the entire system.
9. Suggestions for further work
Bearing in mind the conclusions expressed above, the robustness of the Tor network should be maintained by preserving the trusted Directory Authorities, albeit that they present a centralised focus for attack. The primary issue for limitations to scaling is the need for all members to know all other members in the network, and consequently the size of the related directory documents.
A proposed alternative to the current format of the consensus document and relay descriptors would be to limit the size of the set of available relays. The anonymity of users of the Tor network has been achieved since the set size of the participating users was in the tens of thousands. Beyond a point of provable anonymity, increasing the size of the set would not increase the amount of anonymity. Therefore, if a sample subset r were chosen from the entire set R of all the available members, r?R, to be of efficient size and
provide provable anonymity, this could limit the file size of the consensus document that is distributed to Directory Caches and ultimately to OPs and ORs. (For the remainder of this description OPs will refer to OPs and ORs)
The proportion of the member characteristics of r should be such that the circuit construction algorithm objectives can be efficiently maintained, for example stable relays for long-lived circuits, high and low bandwidth relays, and a range of Exit Relays with a selection of exit policies.
The ?consensus vote? would be formed in the same manner as is currently done, to create the set R; however the Directory Authorities would then make the selection r from R. The selection of members of r should be continuously and evenly random (in the proportions mentioned above) such that ri?R
where i = ?. The different subsets ri of R should be chosen by the Directory Authorities, signed and disseminated to the Directory Caches in a continuous and periodic manner. The OPs would then download the ri consensus as is currently done. The relay descriptors could be updated as is currently done by selectively downloading only the descriptors not currently known. This can be qualified by only downloading the descriptors not known in the current consensus ri and further limiting the overall cached-descriptor file maintained by the OP to an upper limit by discarding the oldest or least valuable data.
The threat model that this creates is to segregate the set R such that the OP does not see R but only a continuously random sample subset ri; however this can be militated against by enabling the OP to validate ri against R at any time. Also, protection needs to be ensured that the selection process by the Directory Authorities cannot be corrupted to bias to malicious and colluding relays.
By keeping the selection process of ri within the control of the Directory Authority and the relay selection for circuit construction within the control of the OP, this maintains the current distributed trust model.?
   Slide 15/16
 Yours sincerely
Mike Fikuart  MSc IEng MIET
Twitter: mikefikuart LinkedIn: mikefikuart
