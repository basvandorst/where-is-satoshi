
@_date: 2019-04-07 22:01:29
@_author: Roger Dingledine 
@_subject: [tor-talk] What is the weirdest/creepiest thing you have found 
I'm increasingly realizing that when "threat intelligence" companies
talk about the dark web, they mean anything on the internet that they
think you should be scared of.
For example, I talk to a growing number of CTOs from these threat
intelligence companies, and the recurring pattern is that they explain
that their marketing people need to say "oooo dark web" to feel like
they're being competitive, but actually almost all of their useful
material comes from watching paste sites like pastebin.
So increasingly, when I hear somebody breathlessly asking me about all
the spooky stuff on the internet, I wonder what that has to do with Tor,
that is, why they are asking Tor.
Or taking a step back: when they say dark web, are they talking about
(A) websites on the internet that are reachable via Tor onion services,
(B) websites on the internet that have bad stuff on them, or
(C) websites on the internet that you need to log in to before you can
read the content?
There was a time a while ago where I think people meant 'A', but nowadays
it seems everybody means 'B' or 'C'. There are a wide variety of websites
in Russia (i.e. that end in .ru) or Malaysia (.my) with all of those
things you mentioned plus more. And of course there is some overlap
between the three categories, but I think the overlap is a lot smaller
than people think, and certainly a lot smaller than the "oooo dark web"
hollywood tv shows want to imply.
For my most recent discussions about the dark web, and trying to get
some actual facts around it, see minutes 36-44 of the FOSDEM 2019 video:
Hope this helps,

@_date: 2019-04-27 21:28:55
@_author: Roger Dingledine 
@_subject: [tor-talk] Mozilla Research Grants 2019H1 - "Super Private 
Great find, nusenu.
It looks like they want to fund university research groups with $25k of
gift money (i.e. no university overhead). This is great.
I'm going to mail Jofish and ask him how we can best help them end up
with the best proposals -- whether we should mostly help in terms of
helping research groups craft their proposals, or mostly help in terms
of advising Mozilla on which proposals will have the biggest impact, or
some combination of both (while avoiding conflict-of-interest problems).
With luck, we'll start shouting about this from the blog and the
twitters soon.

@_date: 2019-02-17 06:10:33
@_author: Roger Dingledine 
@_subject: [tor-talk] Getting Involved in the Tor Project 
Hi Jason!
Thanks for asking. The simple answer is to start working with some of
the existing core contributors. Tor (that is, the Tor Project) does a
lot of its work online in a distributed way, but we also try to meet in
person as often as we can.
You can learn about the various teams here:
and see some upcoming in-person meetings on the event calendar on
the blog here:
and learn about how to become a core contributor here:
I'd suggest, since you mentioned you don't want to get involved as a
developer, listening in on the irc team meetings for the community team
and the UX team.
Hope that provides a useful start!

@_date: 2019-06-09 15:40:21
@_author: Roger Dingledine 
@_subject: [tor-talk] Surge in Users 
No, this is not right. Bridges and relays collect two kinds of aggregated
statistics -- total IP addresses they've seen over the time period,
and total consensus fetches they've seen over the time period.
Clients fetch a new consensus networkstatus document every couple of
hours, so you can get a count of the number of Tor clients that are
running, no matter how many different IP addresses they have, or how
many entry guards they use.
It's still not perfect, (a) because you'll overcount users like Tails
who don't keep state, if they reboot many times per hour, and (b)
because you'll undercount users who don't stay online for the whole
day, which is potentially a huge undercounting for countries like Iran
where a good chunk of users are using dialup or internet cafes or other
transient connections.
See also
as linked from
and there's lots more at
And for that second category of undercounting, see this totally different
method for estimating the total number of Tor users, which at the time
estimated a much larger 8 million daily Tor users compared to the 2
million daily users that our older metrics approach estimated:

@_date: 2019-06-09 17:37:03
@_author: Roger Dingledine 
@_subject: [tor-talk] Surge in Users 
They could, but I don't think that would be a good idea, at least until
somebody has thought through how to do it in a safe way. As a start for
that thinking, I would point people to:
But I think this would be a hard one to make properly safe.
In my experience, spot-checking these things in the distant past, the
hostnames and IP addresses don't tell me as much as I'd like. Maybe if
I were an expert in the network topology for these countries, I could
understand things better.
As another approach, learning the autonomous system (AS) number of
connecting users would be another way to measure diversity within the
country. I expect in some situations it would give too much precision
(too much granularity) for us to be comfortable publishing it though.
No, the directory authorities are run by nine individuals who are part
of the Tor community but are not 'under the control of torproject'. They
make decisions on their own, and for most security choices a majority or
threshold of them need to decide on something before it becomes so.
No. We can ask, but they should push back unless the request comes with
a solid plan on how the measurements will be safe enough.
Yeah, I would also like the world to figure out a way to do safer
measurements like this.
The Privcount approach seems like a useful building block here, because
it does network-wide aggregation and because it uses differential privacy
techniques to avoid publishing any counts that are too precise:
and if we had more developer time (aka more funding), we'd be able to
get there faster.
Careful there -- the Tor design doesn't try to prevent every person in
the world from learning that you're using Tor. It tries to prevent every
person in the world from being able to learn _what you do_ using Tor.
If you want to prevent the directory authorities from knowing your
location, you'll need to take some further step. But most of these
possible steps (use a bridge, use a pluggable transport, use a VPN)
just shift the ability to count you to some other point in the network.
So there is no magic answer, and it comes down to "it depends what you're
worried about more".
Hope that helps,

@_date: 2019-06-30 17:19:28
@_author: Roger Dingledine 
@_subject: [tor-talk] How to hide using Tor browser? 
============================== START ==============================
Alas, there are no great answers here.
Here's a related FAQ answer:
You could conceivably find an open proxy or a vpn and chain that at
the end of your circuit, but (a) it is messy (hard) to do that from a
practical perspective, and (b) it probably harms your anonymity.
The better answer is to find the people who run those websites, and
help teach them about the value of users who care about privacy:
But that suggestion will work better on some sites than others.
For even more to read, check out

@_date: 2019-03-02 00:13:32
@_author: Roger Dingledine 
@_subject: [tor-talk] Data collection by Tor Browser 
I believe the answer is no, Tor Browser shouldn't tell anybody else
any of these things about you.
You can read the Tor Browser design goals here:
and anything where it reveals your browsing activity would count as a
bug -- and depending on the type of information leak, could qualify for
a bug bounty:  .
Three caveats to my answer though:
(1) This word 'collect' is confusing, because that word sure makes it
sound like it includes internal program data structures. The browser
needs to know something about your web activity while it's loading web
pages for you, and that by itself isn't harmful. The key question is
whether it shares that information with anybody else. For this sort of
user info, we aim to stick to the principle of "no secret databases",
that is, anything that we gather should be so sanitized, and so safe to
collect, that we share it with everybody else too. That way we're never
in the position where attackers might want to break into our systems to
learn more about our users.
For browser activity, the obvious simple approach to only publishing
safe things is to publish nothing at all, which is what we try to do.
(2) I might not be up on the latest Tor Browser moves, so it's possible
there are some open tickets for disabling telemetry or the like which
aren't yet fixed. Keeping up with the constant changes to Firefox is tough
to do perfectly. I'll let the browser team jump in here if they want.
(3) Other places on the Internet could still keep statistics, based
on your connections to them. I'm thinking in particular of:
(3a) the addons.mozilla.org server, which ought to see just anonymized
connections over Tor, but that still lets them gather general statistics
like how many Tor users there are, what extensions they have installed,
etc. Similarly, the periodic update pings, and update fetches, happen
over Tor but can still be counted in the aggregate:
(3b) the Tor relays, which see connections from the Tor client that is
part of Tor Browser. Because of the decentralized Tor design, no single
relay should be able to learn both who you are and also what you do on
the Tor network. But they can still collect what they observe about who
you are. Relays collect and publish aggregate statistics about the users
they see (but not what they do, because they can't learn that). For much
more info, see (3c) other researchers might perform experiments using their own
internet connections to try to answer questions about Tor performance,
usage, safety, etc. The ones who are doing it right will consider how
to minimize risks while doing their experiments:
Hope this helps!

@_date: 2019-03-30 20:48:03
@_author: Roger Dingledine 
@_subject: [tor-talk] How dangerous are malicious entry guards? 
It depends what you're worried about, and what you're trying to protect.
Huh. I don't think they should need supercomputers for such a thing.
It's all about what data you can get. The known math that you do with
the data, once you have it, doesn't (shouldn't) need a supercomputer.
For the traffic analysis question in general, see papers from the PETS
conference and other anonymity literature:
For entry guards in particular, here are some URLs to start:
In general, don't just think about relay-level adversaries, but also think
about network-level adversaries who can observe (encrypted) Tor traffic.
And lastly, don't fall into traps where you think "omg Tor has this
potential entry guard issue, so I'm going to use this simpler centralized
system instead" -- because then you'll end up with that issue plus more.

@_date: 2019-05-06 23:15:42
@_author: Roger Dingledine 
@_subject: [tor-talk] Tor Glitch? 
You want to upgrade your Tor Browser to the new version which fixes
this Firefox bug:
For the earlier discussion, see this blog post and the many comments:
Hope this helps,

@_date: 2019-11-16 17:26:55
@_author: Roger Dingledine 
@_subject: [tor-talk] Brave Review Mentions Tor 
I'm going to flag that one as "citation needed". That is, I don't think
Brave is the browser for OnionBrowser on iOS.
Because iOS is missing real Firefox. And that alas is why there's no
Tor Browser on iOS either.
For more details, check out
especially the first and second comment from the comments section.
For those reading this, check out the Tor Browser design doc for
its application-level privacy goals and fixes:
And yes, I believe Brave wants to do all of those things too, and it
isn't there yet. I hope it does get there, because the world needs
more safe browsers.
Agreed. Even trying to keep state isolated across time (i.e. sometimes
your whole browser is torified, sometimes it isn't) is hard. That's why
we got rid of the "toggle model" in Torbutton:

@_date: 2019-11-17 14:40:43
@_author: Roger Dingledine 
@_subject: [tor-talk] TBird & torbirdy 
It is alas worse than that: somebody needs to look at the new 68esr and
evaluate it for privacy flaws, and nobody has had time + expertise to
do it. So there is no Torbirdy for recent Thunderbird because nobody
has made one:

@_date: 2019-10-23 15:39:51
@_author: Roger Dingledine 
@_subject: [tor-talk] TorBrowser is only showing a black windows after 
My guess is that you are using torbrowser-launcher, not actual
tor browser (as obtained from torproject.org).
There appears to be a bug in torbrowser-launcher:
The fix would be either to install tor browser the normal way
by downloading it from torproject.org, or to hope that the
torbrowser-launcher package gets a fix (or help them fix it).

@_date: 2020-02-02 17:57:28
@_author: Roger Dingledine 
@_subject: [tor-talk] Are 'StrictNodes 1' actually strict? 
Yep. StrictNodes does nothing there, and ExitNodes by itself should do
what you ask it to do.
The same as above, but leaving out the StrictNodes line since it
doesn't do anything.

@_date: 2020-02-02 23:31:54
@_author: Roger Dingledine 
@_subject: [tor-talk] Are 'StrictNodes 1' actually strict? 
Your next step is to make a series of steps that are (a) as simple as
possible, and (b) as consistently repeatable as possible, and that
still show your bug.
That is, try to remove as many variables as possible -- visit a very
boring website that has only one IP address and doesn't pull in ads
and other dynamic stuff. Definitely avoid Cloudflare-hosted sites, or
CDN-hosted sites in general. Avoid onion services, because they don't
exit. If possible, view the Tor controller events yourself (not just
relying on Tor Launcher's visualization). If possible, reproduce the bug
outside of Tor Browser entirely, with just your Tor client and making
requests to it with curl or the like. Reproduce it on a variety of exit
relays. Basically, you want to rule out as many other factors as possible,
to get the simplest possible "if I do these steps, it breaks every time"
test case. Once you have that very simple scenario, please file a ticket
on trac.
Or if it breaks on the complex scenarios, and doesn't break on the simple
scenarios, then that gives you a direction to investigate.
The "hands" exit relay is indeed an exit relay, but it is heavily rate
limited, so I would expect that requests that use it will take a long
time, time out more frequently, etc. So maybe having it as a performance
bottleneck is helping to expose some bug.

@_date: 2020-02-03 03:04:20
@_author: Roger Dingledine 
@_subject: [tor-talk] Tor and sources.list 
I'm expecting it to work this way, yes. Or at least, I've been patiently
waiting for my 0.4.2.6 deb too. :)
I expect that the workflow involves the real Tor deb going through the
general Debian process, and then once it is available in the real Debian
repositories (even if it's just the unstable ones), then the packages
get mirrored onto deb.torproject.org.
So, give it a couple of days and hopefully it will appear.

@_date: 2020-02-03 05:38:10
@_author: Roger Dingledine 
@_subject: [tor-talk] Tor Browser without Tor 
You should really avoid making exceptions to the proxy rules for Tor
Browser. If you let your browser connect to local services, that opens
the door for remote websites, which you access over Tor, to give you
instructions (e.g. via javascript, but not only via javascript) to make
local connections and then send that info back to the website.
In the most benign case, you're setting yourself up with a tracking marker
("there's that weird person who allowed connections to 192.168.1.1
again"). In worse cases, you're opening yourself up to permissions
surprises and attacks that start with the word "cross-site" or
For an early example of a similar bug that bit Tor users, see
All of that said, if you still want to shoot your feet off: in
about:config, there's a network.proxy.no_proxies_on option that you
can set.
For even more details, new in ESR68, there is now a
network.proxy.allow_hijacking_localhost option, which we needed to fix
for Tor Browser:
Good luck!

@_date: 2020-02-05 03:51:18
@_author: Roger Dingledine 
@_subject: [tor-talk] Tor and sources.list 
Yep. The Tor 0.4.2.6 debs have now arrived in Debian as well as
I talked to the maintainer and he said they were held up due to a bug
in the arm64 builder (arm as in the cpu architecture, not arm as in the
deprecated tor controller). The packages should be all set now.
It should be fine.
We try to change /etc/tor/torrc as infrequently as possible, because
every time we make even a tiny change, every single person who upgrades
and has modified their torrc file gets presented with a "how do you want
to handle this diff" question, and it's easy to make the wrong choice
and end up confused.

@_date: 2020-02-21 05:41:42
@_author: Roger Dingledine 
@_subject: [tor-talk] How secure is a hidden service? 
It's complicated.
I should start out with saying I'd never heard of Flugsvamp until your
email, and I have no notion of whether they used Tor or what. That said:
Services on the internet are inherently harder to make safe than clients,
(a) because they stay at the same place for long periods of time, and
(b) because the attacker can induce them to generate or receive traffic,
in a way that's harder to reliably do to clients.
Most identification problems with Tor users, and with onion services,
have turned out to be opsec mistakes, or flaws in the application
software at one end or the other. That is, nothing to do with the Tor
protocol at all. But of course in the "layers of conspiracy" world we
live in nowadays, you can never be quite sure, because maybe "they"
used a complex attack on Tor and then covered it up by pointing to an
opsec flaw. One hopefully productive way forward is to point out that
even if we don't know how every successful attack really started, we
know that opsec flaws are sufficient to explain most of them.
When I'm doing talks about Tor these days, I list these four areas
of concern, ordered by how useful or usable they are to attackers in
practice: (1) Opsec mistakes, (2) Browser metadata fingerprints / proxy
bypass bugs, (3) Browser / webserver exploits, and (4) Traffic analysis.
See e.g. the original story about Farmer's Market:
where at first people worried about a vulnerability in Tor, but then it
turned out that the operators had been identified and located far before
they even switched to using Tor.
To make this thread more productive and more concrete: can you point us
to these "documents made public for the court case"? Even if they're in
Svenska, they would still be useful to look at. The ones talking about
probabilities of IP address I mean.

@_date: 2020-01-18 22:49:54
@_author: Roger Dingledine 
@_subject: [tor-talk] Tor vs Tor Browser 
The "security slider" in Tor Browser is about disabling pieces of browser
functionality, to reduce surface area. Another name for it that might
give a better intuition would be "functionality filter". It is entirely
about stuff inside the browser, like whether it renders certain image
formats, whether it runs scripts, etc.
There is no equivalent of that "disabling application level pieces" idea
for the program called Tor: Tor just moves bytes back and forth for you,
and aims to give you good security by default.
(You will find advice on random websites out there, to add fifty new
lines to your torrc or something. Those guides are usually bad ideas.
Tor's defaults aim to keep most people safe, and since anonymity loves
company, you are probably better off blending in with the crowds.)

@_date: 2020-01-26 23:52:07
@_author: Roger Dingledine 
@_subject: [tor-talk] Ports required for Tor and hidden services 
Here are two approaches that are worth exploring:
(A) Set the iptables rules so only the tor process can get through
the firewall. This is how Tails does it, I believe. This way you're
firewalling based on what user is trying to make the connection, rather
than what destination they're trying to reach. More info at
(B) Pick a bridge that you know you like, and configure your Tor to
use that, and configure your firewall to only allow connections to
that bridge. More info on this approach at
("The best design we've been able to come up with is one that forces
you to be using Tor on your side, and only allows your traffic through
if it's coming from Tor.")
I guess there is also (C) do both.

@_date: 2020-01-30 04:45:12
@_author: Roger Dingledine 
@_subject: [tor-talk] Are "StrictNodes 1" actually strict? 
Check out the man page, where it says "StrictNodes does not apply to
ExcludeExitNodes, ExitNodes, MiddleNodes, or MapAddress."
So you shouldn't be setting StrictNodes for this case. Maybe you are
using a super old guide found somewhere on the internet? :) More info
from when we made the change back in 2011:
That said, ExitNodes should work. My guess is that you're visiting a
Cloudflare site, which is giving your Tor Browser an alt-svc header,
which sends the browser to load the site via one of Cloudflare's onion
addresses. And since onion services don't have the concept of "exiting",
then your Tor feels no need to end that circuit with your specified
*That* said, there are some bugs with how Tor Browser visualizes your
circuit when alt-svc is in use:
and it looks like the browser might be inconsistent about whether it
actually uses the alt-svc destinations, which could explain your getting
your exit relay every so often:
Best plan would be to pick a really simple non-CDN'ed single-address
domain, like freehaven.net, and try to recreate your issue there.

@_date: 2020-07-01 00:34:56
@_author: Roger Dingledine 
@_subject: [tor-talk] I don't understand two things about the node "freja". 
whois, and geoip databases, are notoriously inaccurate. This is a fine
illustration that it's not good to rely on them for situations that
really matter.
In particular, there's a pattern where some European country "loans"
an address block to somewhere in Africa or Asia, and then takes it back
a few years later, but nobody bothers updating whois for a while.
This pattern is also illustrated by some of the periodic spikes we have
of hundreds of thousands of new Tor users in Uganda -- they're actually
Tor users in Germany, but the geoip is wrong.
(To make things more exciting, sometimes there *are* spikes of many Tor
users in Uganda. But it means every time you see a pattern on one of
the metrics graphs, you have to wonder what you're actually seeing.)
Tor Browser's "about:tor" screen is served locally -- it does not come
from any remote website.
This is one of the Tor Browser usability improvements from some years ago,
where "making users wait for their Tor to bootstrap, and then fetch a
remote page, before the browser window appears" is no fun so we fixed it.

@_date: 2020-07-05 19:30:46
@_author: Roger Dingledine 
@_subject: [tor-talk] I don't understand two things about the node 'freja'. 
Actually, its exit policy does allow some outgoing ports:
So, it is missing the Exit flag, because its exit policy doesn't include
both ports 80 and 443.
I guess the follow-up question would be: when you say "one of my
accounts", perhaps this is an account that is reachable on a port
other than 80 and 443? For example, an irc account?
(When a relay is missing the Exit flag, Tor clients (a) won't use it when
preemptively making circuits, before new connections come in, because
it's too likely that the new connection will be for a destination that
the relay can't handle, and (b) won't apply the load balancing weights
that make them avoid using exit relays in non-exit positions in the
circuit. But if a connection request comes in when there aren't any
preemptive circuits already built, then the client will pick among
any relays whose exit policies allow that destination. So yes, it is
possible to use relays for exiting even when they don't have the Exit
flag, but they will get used less often.)
destination port k
use when new connections come in
Exonerator is the right tool for asking historical questions like this:
and it looks like the Exonerator folks have opted to say "yes" on whether
it counted as an exit relay, probably because its exit policy allowed
some connections, even if it didn't allow enough that it qualified for
the Exit flag.
All of this said, there is another possible explanation for your
scenario, though I don't think it happened here: sometimes relays exit
from a different IP address than they advertise in their descriptor. And
sometimes if there are several relays run by one person or organization,
one of the exit addresses overlaps with another relay. So it is possible
to receive a connection from the Tor side from an address that is a
non-exit relay, if there is an exit relay running nearby to it. But I
don't think that happened here.
Hope this helps,

@_date: 2020-03-29 07:04:10
@_author: Roger Dingledine 
@_subject: [tor-talk] Full storage OS doesnt give warning signal to Tor 
Yep! This is a bug with the Firefox updater, and they don't seem to have
any momentum at fixing it. :(
For the Tor ticket, see
And for the Firefox bug, see
Gotta love those 15 year old bugs. :(
