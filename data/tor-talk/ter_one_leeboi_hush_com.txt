
@_date: 2014-12-01 04:39:02
@_author: l.m 
@_subject: [tor-talk] OpenCart eCommerce CMS by public key not working 
So a normal browser session works. When you try to access the server
by SSH key-based auth. you get a broken site-am I correct? How are you
redirecting/filtering traffic. It may be you need to adjust your
Hi, this is Umair.
I've posted my issue few days before but never got
reply, so listing it again, so please help me, it will be highly
Hi, I?ve downloaded tor and configured it according to instructions,
now I
got both public & secret keys and I can access server / site with
key, so far everything is working fine.
Next I?ve installed OpenCart eCommerce CMS and its working fine on
browser everything is loading perfect, but when I try to access it via
public key than only html markup loads up, it seems stylesheet & other
scripts aren?t loading. I also think it could be because of port,
but I
don?t know how to fix this issue.
So please let me know should I continue with OpenCart CMS or is there
better CMS for TOR. So please suggest me and guide me about the
issue. Thanks?

@_date: 2014-12-01 05:00:48
@_author: l.m 
@_subject: [tor-talk] (D)DOS over Tor network ? Help ! 
To clarify. You have black sheep(s). Look for more than one.

@_date: 2014-12-01 06:59:27
@_author: l.m 
@_subject: [tor-talk] OpenCart eCommerce CMS by public key not working 
A normal browser session (without tor) works? Then don't worry about
the rules. When you use the .onion address you have problems? What is your hidden
service configuration in torrc?

@_date: 2014-12-01 07:24:57
@_author: l.m 
@_subject: [tor-talk] (D)DOS over Tor network ? Help ! 
I think it's also worth mentioning this may be an attack on your
service  via your server's service provider. It's not  impossible to
have one HS work fine but many cause timeouts as you  begin to enable
all HS. As you begin to increase traffic to guards you give away that
your services are online. Depending on on your service provider's capability they may not  even notice without going to a senior level.
This would imply your  service is the target rather than any
particular HS--or perhaps, as you noted, because  of some offending
HS. I  suppose you could create a large number of test HS to simulate
a  load.
themselves. But when you allow them all your service goes down completely. Why would your guards timeout without actual traffic. You
already tried changing the guards and got the same result--timeouts.

@_date: 2014-12-02 11:30:10
@_author: l.m 
@_subject: [tor-talk] Once again: window size 
Hi, those are not good results. I recommend trying a couple more tests
on panopticlick.
1. After maximizing, then closing, then reopening Tor-Browser, it
resizes automatically--after a couple seconds. Test at this window
2. Use Tor-Button to change identities. The window should resize
automatically. Test at this window size.
3. Use the 'new window' option from the Tor-Browser menu. Test at this
window size.
Based on what you've detailed your Screen size and Color Depth should
be 1000x600x24. That's 1 in 643. A much better result. If you get any
other result I recommend you re-download the Tor-Browser bundle and
delete your current Tor-Browser folder (and any links). Then use the
fresh bundle download to see if you get better results.
Hallo, das sind schreckliche Ergebnisse. Ich empfehle, versuchen ein
paar mehr Tests an Panopticlick.
1. Nach maximieren, dann schlie?en, dann die Wiederer?ffnung
Tor-Browser, die Gr??e automatisch - nach ein paar Sekunden. Test
bei dieser Fenstergr??e.
2. Verwenden Sie TorButton Identit?ten ?ndern. Das Fenster sollte
automatisch angepasst. Test bei dieser Fenstergr??e.
3. Verwenden Sie die "neuen Fenster" aus dem Tor-Browser-Men?. Test
bei dieser Fenstergr??e.
Nach dem, was Sie Ihre Bildschirmgr??e beschrieben habe und
Farbtiefe sollte 1000x600x24 sein. Dies ist eine in 643. Ein deutlich
besseres Ergebnis. Wenn Sie ein anderes Ergebnis zu bekommen empfehle
ich Ihnen erneut herunterladen das Tor-Browser-Paket. L?schen Sie
dann Ihre aktuelle Tor-Browser-Ordner (und alle Links). Test mit dem
neuen Bundle herunterladen, um zu sehen, wenn Sie bessere Ergebnisse.

@_date: 2014-12-02 11:47:53
@_author: l.m 
@_subject: [tor-talk] OpenCart eCommerce CMS HS not working 
Fine I'll remove the replies. If a normal browser--without Tor works. Then don't worry about the
rules I mentioned.
If the only problem is you get a broken site using the onion address.
Then what is your HiddenServicePort in torrc.
Finally. In a normal browser--without Tor. Do you connect using the ip
address or a domain name?
How's that. If that's still too much then.

@_date: 2014-12-02 16:45:51
@_author: l.m 
@_subject: [tor-talk] (D)DOS over Tor network ? Help ! 
? I don't see anything in the improvements suggested for hidden services
that would help this situation. Though I would be grateful for being
First, I just want to say I only meant sheep(s) to emphasize that you
don't know how many black sheep you have participating. I mentioned
the part about this potentially being an attack external to Tor out of
concern for your participation in a de-anonymizing attack on your
hosted HS. I see your HS's are offline while you troubleshoot this so
that's good. Next, I'm confused by what you describe. Sorry I deleted
your previous email so I may repeat some things you already said.
- no evidence of any HS being flooded from logs. No evidence of a load
on any particular HS.
- next to no bandwidth consumption. Does this include no processor
use? I don't recall if that was mentioned before.
- no evidence is apparent from checking REND_QUERY=HS. So no request
to rendezvous. Might make sense given little/no traffic.
- your guards go offline. This is contradictory. If the attack is
within Tor via a HS it implies the HS traffic *reliably* makes it to
at least your guard before you experience the symptomatic overload and
timeout. Meaning there must be traffic you can detect. Otherwise the
attacker would likely lose their connection to the rendezvous point
(at least sometimes) by committing to the attack. What I mean is in
order for this to be an attack via malicious HS it would need to
succeed in not timing out until the traffic reaches your guard and
server. That's two circuits that must work before failing at your
guard. Not to mention you already tried changing the guards. It just
seems implausible to occur reliably enough to take your server down.
This assumes little/no traffic and no heavy cpu usage.

@_date: 2014-12-03 07:30:06
@_author: l.m 
@_subject: [tor-talk] Once again: window size 
Hi Hartmut, I tried to reproduce your problem on Windows. You may have stumbled
onto a bug. Here are my results. Upon loading Tor-Browser, and after
automatic resize, the window has an extra large 32 pixel border along
the bottom edge. The content area is 1000x600 (for my display).
Producing one in 642 distribution. The extra large border disappears
after minimizing Tor-Browser and reactivating from the task bar. This
has the effect of adding those pixels to the content area. Now the
Tor-Browser window size is bigger. In my testing this made the window
larger by 32 pixels which produces a one in 148,505 distribution. Your
results may vary.
I was only able to reproduce this on Windows.
Now--it's not the end of the world. At least your desktop resolution
is unavailable. It's still a more unique display size and something to
be aware of.
Ich habe versucht, das Problem unter Windows wiederzugeben. Sie
k?nnen auf einen Fehler gestolpert. Hier sind meine Ergebnisse. Beim
Laden Tor-Browser, und nach der automatischen Gr??en?nderung hat
das Fenster einen extra gro?en 32 Pixel-Grenze entlang der unteren
Kante. Der Inhaltsbereich ist 1000x600 (f?r meine Display). Dies ist
eine in 642 Verteilung. Die extra gro?e Grenze verschwindet nach dem
Minimieren Tor-Browser und Reaktivierung in der Taskleiste. Dies hat
den Effekt der Zugabe die Pixel in den Inhaltsbereich. Nun ist die
Tor-Browser-Fenstergr??e ist gr??er. In meinen Tests das machte
das Fenster gr??er 32 Pixel, die eine in einem 148.505 Verteilung
erzeugt. Ihre Ergebnisse k?nnen variieren.
Ich war nur in der Lage, dies unter Windows zu reproduzieren.
Nun - es ist nicht das Ende der Welt. Zumindest ist Ihre
Desktop-Aufl?sung nicht verf?gbar. Es ist immer noch eine
einzigartige Display-Gr??e und etwas bewusst zu sein.

@_date: 2014-11-03 14:06:27
@_author: l.m 
@_subject: [tor-talk] Cloak Tor Router 
I've only one thing to  say about this idea or any other similar
Kickstarter project. You've got  to be stupid to sacrifice the control
and flexibility offered by  running Tor on a computer for a
configuration that operates at the  router/switch. There's no such
thing as easy anonymity online. There's  no such thing as easy privacy
online. Anyone who's actually interested  in these projects should
just fork over their money at Kickstarter and  stop spamming tor-talk
with useless self-promotion. Yes, you, Cloak. If  you think it's such
a good idea just do it and take advantage of the  daft--get it over
with already. So I can laugh at you when your buyers  realize how
stupid they were for not reading the Tor manual.
Honestly--it's  not hard to learn to be anonymous online. If you
seriously consider  these projects to be of some value you should just
stop. Stop trying to  be anonymous and just fork over your data to
whomever wants to look at  it.
The only thing that comes close to anonymity/privacy online  is to
treat each device as if it *could* be compromised. If they aren't  yet
compromised that may well be in the future. Then you see having absolute control and flexibility is a strength of Tor. Who the hell wants anonymity and actually trusts their networking equipment?
That's all
leeroy bearr
On 11/3/2014 at 11:59 AM, michi1 at michaelblizek.twilightparadox.com
breaks the
Wi-Fi security they can access the Tor network (or the internet -
depending on which Wi-Fi network they break), but in order to sniff
traffic from other devices the Cloak device itself would have to be
accessed (ie. root password guessed) and the device reconfigured
(disable wifi isolation).
What prevents me from setting up a DHCP server or sending false ARP
to route all traffic to me?
from multiple
(On by default and strongly recommended; you can disable it with
circuits will not be shared.
Ok, this should do it.
may allow an
destination port.
I do not think this actually solves it. For example there are many
which use HTTP even tough they have nothing to do with web browsing.
there are programs (like P2P) which use random ports and may cause
lots of
circuits being established.
 -Michi

@_date: 2014-11-03 14:05:43
@_author: l.m 
@_subject: [tor-talk] [Suspected Junk Mail] Re:  Cloak Tor Router 
I've only one thing to say about this idea or any other similar
Kickstarter project. You've got to be stupid to sacrifice the control
and flexibility offered by running Tor on a computer for a
configuration that operates at the router/switch. There's no such
thing as easy anonymity online. There's no such thing as easy privacy
online. Anyone who's actually interested in these projects should just
fork over their money at Kickstarter and stop spamming tor-talk with
useless self-promotion. Yes, you, Cloak. If you think it's such a good
idea just do it and take advantage of the daft--get it over with
already. So I can laugh at you when your buyers realize how stupid
they were for not reading the Tor manual.
Honestly--it's not hard to learn to be anonymous online. If you
seriously consider these projects to be of some value you should just
stop. Stop trying to be anonymous and just fork over your data to
whomever wants to look at it.
The only thing that comes close to anonymity/privacy online is to
treat each device as if it *could* be compromised. If they aren't yet
compromised that may well be in the future. Then you see having
absolute control and flexibility is a strength of Tor. Who the hell
wants anonymity and actually trusts their networking equipment?
That's all
leeroy bearr
On 11/3/2014 at 11:59 AM, michi1 at michaelblizek.twilightparadox.com
breaks the
Wi-Fi security they can access the Tor network (or the internet -
depending on which Wi-Fi network they break), but in order to sniff
traffic from other devices the Cloak device itself would have to be
accessed (ie. root password guessed) and the device reconfigured
(disable wifi isolation).
What prevents me from setting up a DHCP server or sending false ARP
to route all traffic to me?
from multiple
(On by default and strongly recommended; you can disable it with
circuits will not be shared.
Ok, this should do it.
may allow an
destination port.
I do not think this actually solves it. For example there are many
which use HTTP even tough they have nothing to do with web browsing.
there are programs (like P2P) which use random ports and may cause
lots of
circuits being established.
 -Michi

@_date: 2014-11-08 10:44:14
@_author: l.m 
@_subject: [tor-talk] 
It's not broken. They explain clearly that the concurrent use of
ixquick/startpage by multiple Tor users at a given exit relay can
trigger automated abuse blocking. They're right. It could be abuse.
The same reason Google does it. Why is this a surprise? The problem
with Google is the connection sometimes 'spills' over to new circuits
which puts you into an infinite loop of entering captchas. This makes
Google just block some exit relays entirely for a time because of
repeated failed captchas. Google really wants to make money so if they
set a cookie for one of your circuits, and ask for a captcha, which
then 'spills' to a new circuit, and you just choose a new
identity--well it shouldn't be a surprise they decide to block a bunch
exits for lost revenue. Just try your search on startpage/ixquick with
a new identity.
--leeroy bearr
On Fri, Nov 7, 2014 at
Does anyone know anyone at startpage, maybe you should CC them this. I
tried the startpage search box in Iceweasel in Tails and I receive a
message directed at Tor users whenever I try to search. I will paste
message below. Unfortunately it does not appear just once, it appears
time and I can't get search results that way. I wouldn't mind
answering a
captcha once in a while but I don't know how much that's going to help
against bots since bots apparently use opencv and tricks to break
Here is the message, it's long:
Welcome Tor Users!
We are happy to welcome you to Startpage, the world's most private
engine. Startpage now serves well over 2 million searches per day,
us the biggest private search service on the Internet.
Like Tor, Startpage was private long before privacy was cool. We have
fourteen-year company track record, and we are the only search engine
can back up our privacy promises with third-party certification.
Here are just a few of our powerful, privacy-protecting features:
    We do not record anything about you ? not your IP address, not
search queries, and we never use tracking cookies.
    We provide 100% Google results ? We submit your search
anonymously to
Google and return their results to you in total privacy.
    We encrypt all traffic ? using HTTPS, so even your ISP can't
snoop on
your searches.
    We offer a powerful free proxy ? that lets you anonymously view
third-party websites with every search.
    We're third-party certified and independently audited ? by
and Certified Secure, so you can take our privacy promises to the
We love Tor!
We believe in the Tor project and its privacy mission and we applaud
efforts to pursue serious Internet privacy.
As you know, Tor recently included Startpage as the default search
in the new Tor Browser Bundles. Thank you! We're honored to be
with all of you like-minded, hard-core privacy fanatics.
Just One Small Catch...
However, the avalanche of new Tor users has created an issue with the
algorithm we use to detect and reject automated screen-scraping
When multiple Tor users are searching through the same end node,
may wrongly conclude that the searches are coming from a scraper.
The unfortunate result is that Startpage may occasionally not return
results with Tor. But don't panic, we're committed to fixing it.
Here's a Temporary Solution
We are reaching out to the Tor developers to find a permanent
solution. In
the meantime, here is a workaround for Tor users:
    If you use the Tor Browser Bundle:
        Switching to a new Tor identity is easy and fast. Click the
onion icon next to your address bar, then click "New Identity" and try
search again. In some cases, you may have to switch identities a few
for this to work.
We want Tor users to have a great private search experience with
and we appreciate your patience while we develop a long-term solution.
you use Startpage, we'd love to hear from you and get your
Meanwhile, thanks for supporting the vision of Tor and Startpage and a
completely private Internet!

@_date: 2014-11-08 11:14:06
@_author: l.m 
@_subject: [tor-talk] 
Notice, they have the 'alleged' owner/operator of SR2. Hidden services
don't need to have an exploit to fall to the GPA and 5-eyes. Now they
have the alleged owner/operator they need to procure his resources to
complete the final stages of indictment. We'll never hear about how
they did it because them implying there's some secret sauce is a fear
tactic to scare darknet operators away from Tor. The secret sauce is
really old-fashioned police work using the GPA and 5-eyes.
You didn't really think hidden services or Tor a perfect defense?
There is no defense against skillful application of the GPA. Good
thing too--keeps us from becoming complacent. Personally I'd say good
riddance. Darknets only contribute to fear mongering over the average
joe using Tor. It makes agencies waste time and effort investigating
innocent advocates of freedom and privacy. How's the presence of a
darknet running on Tor hidden services supposed to make me feel
anyway? That's your freedom being used to poison kids and evade
It's not correct to think of this as Darknets/science vs. GPA/LEA/Law,
more like darknets vs. science. Science won.
--leeroy bearr
Global Passive Adversary, Surveillers, Wiretappers, Data Miners.
To be taken in context of anonymity networks.

@_date: 2014-11-09 12:51:46
@_author: l.m 
@_subject: [tor-talk] 
I understand. No one wants to do that. But they do because that's the only solution. Changing identities shouldn't lessen anonymity for  I say shouldn't because depending on how you use
the  new identity feature it's possible to have existing connections
still  open on your old circuit. If these connections are for
ad-related  services and you open a new connection to a site which
uses those ad  related services then you've potentially just leaked
your identity  change. Old circuits aren't closed immediately. I
digress. As far as  startpage/ixquick is concerned though it really is
'just try a new  identity' for accessing the search page. The
access-by-proxy links  presented will expire eventually forcing you to
search again. If you're  really desperate because the new identity
feature isn't working maybe  there's something wrong with your
consensus. If you're using TBB close  it, delete the folder, unpack
from the download, try again.
Otherwise  how would you propose to fix it? Suppose startpage/Tor work
together  for a fix. How would you envision such a fix to work? A
major goal of  Tor is to make you look no different than any other.
Including making sure you're not the only one using nodes. If you're
no  different than any other how do you prove you're not the one
abusing startpage search? Maybe there's no abuse and it's just many
people trying to use startpage through that exit. If you were the only
one  using an exit that would less anonymity.
--leeroy bearr
On Sat, Nov 8, 2014 at
Thanks, I know I can do that but I don't want to do that. Their help
says  "Both Ixquick and StartPage are compatible with Tor, although
use of
VPNs and Proxy services (including Tor) may occasionally trigger our
anti-abuse mechanisms. If so, you will temporarily be presented with a
small warning message, or a request to complete a CAPTCHA before
with your search." [1]
I didn't get captchas and the warning didn't go away. So it seems
It's a block unless you change identities until you get one that
works. If
you have to repeatedly change identities doesn't that do something to
lessen anonymity?

@_date: 2014-11-09 14:02:28
@_author: l.m 
@_subject: [tor-talk] Darknets/science vs. GPA/LEA/Law, 
I didn't judge anyone. I specifically said they have the 'alleged'
owner. I said good riddance to SR2 and it's ilk. Tor isn't an
environment of your freedom. It only ever has the potential to be. You
live in a world where your freedom is an ideal that only exists in
your head. If it did exist, and Tor were truly net-neutral, then don't
ever design around preventing use of specific hosts (like was done for
rapidgator). While you're at it make it impossible for guard rotation
attacks and make it so exits can neither filter selectively or inspect
traffic. Let me setup my internet completely anonymously so no
intelligence agency could easily track down my servers. Net neutrality
and privacy have overlap but aren't the same thing. Tor project has
already made design choices to choose a side--not always for your
beloved claim of being an environment of freedom and net-neutrality. --leeroy bearr
On 08/11/2014 16:14, l.m
On the contrary, it makes me feel that my freedom is being used to
provide an environment where some of the damage done by people with
misguided viewpoint can be mitigated.

@_date: 2014-11-28 15:19:24
@_author: l.m 
@_subject: [tor-talk] Once again: window size 
What do you mean, not really? If you look at number (7) as mentioned
you see the Design Goal *and* Implementation Status. Implementation
status shows the methods used to reach the goal. Clicking on the links
provides all the details you could need to change the behavior. These
are modifications to TorButton and Tor Browser. Maybe you're
suggesting to let all Tor Browser users to just shoot themselves in
the foot by making this easily customizable on a per-user basis?
--leeroy bearr
Hi mroq qorm,
well, not really. But can you tell me where the default size is

@_date: 2014-11-29 06:52:23
@_author: l.m 
@_subject: [tor-talk] Making Apache server talk to the Tor network? 
"...access to Tor" is ambiguous even for a web server. Are you fishing
or looking for help with a forward-reverse proxy? I only ask because
you leave out what you're trying to achieve and it's a given you've
access to the docs. Is your web server a client or server w.r.t Tor?
Producer or consumer? You could be asking how to setup a hidden
service or asking how to proxy the server's outgoing connections like
any other client. If you're fishing this will, of course, turn into
yet another 'define best practices' or 'tell me about your config'
thread. I didn't know the tor-manual was that hard to navigate. Sorry,
I merely jest, we in tor-talk, are at your service. Your personal

@_date: 2014-11-30 15:50:49
@_author: l.m 
@_subject: [tor-talk] Once again: window size 
I will try to simplify the explanation. See [1] for more information
on browser fingerprinting. Test with Tor Browser resized to different
window sizes. See the result for 'Bildschirmgr??e und Farbtiefe'
(Screen Size and Color Depth) changes by the current window size. Now
try the same test without Tor Browser.
Yes. Imagine if you use a VM with a fixed desktop resolution smaller
than your host desktop.
That your window starts full screen then resizes is good. That you
then maximize is bad. Is that better?

@_date: 2014-11-30 16:17:00
@_author: l.m 
@_subject: [tor-talk] Once again: window size 
============================== START ==============================
Ich werde versuchen, die Erkl?rung zu vereinfachen. Siehe [1] f?r
weitere Informationen
?ber Browser-Fingerprinting. Test mit Tor-Browser mit
unterschiedlichen Fenstergr??en. Sehen Sie das Ergebnis f?r
"Bildschirmgr??e und Farbtiefe '
(Bildschirmgr??e und Farbtiefe) ?ndert sich mit der aktuellen
Fenstergr??e. jetzt
versuchen, den gleichen Test ohne Tor-Browser.
Ja. Stellen Sie sich vor, wenn Sie eine VM mit einer festen
Desktop-Aufl?sung von weniger verwenden
als der Host-Desktop.
Dass Ihre Fenster startet Vollbild ?ndern Sie dann Gr??e ist gut.
dass Sie
Maximieren Sie ist schlecht. Ist das besser?

@_date: 2015-04-05 17:49:29
@_author: l.m 
@_subject: [tor-talk] Secure DNS Addresses 
You  might consider security and DNS a bit of a joke in that security
wasn't  a major design goal. DNSSEC is an extension which is meant to
provide  assurance that the response is authoritative. It doesn't
encrypt the  request, it only signs the response. This means it would
act  as a side-channel, or information leak if used together with Tor.
Using Tor for DNSSEC resolves is expensive and slow, slower if the
exit were to tamper. Having said that you might look into dnscrypt as a method to secure
the client-DNS resolver traffic. It supports forcing DNS over TCP if
needed. Some dnscrypt-supporting resolvers also provide DNSSEC.
Consider however that *any* local dns resolution together with Tor can
act as an information leak. All an adversary needs is to know is which
resolver you use and then watch the traffic generated by the resolver.
At some point that traffic will be unencrypted.
Do keep in mind some resolvers (like OpenDNS dnscrypt) provide
features where the *apparent* client can monitor and filter requests.
This might be a concern for you where MITM-like adversaries might

@_date: 2015-04-10 17:50:18
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
I would like to ask if you're using the Tor Browser bundle with or
without modification. When the new identity is used in Tor Browser
(it's my understanding--please correct if wrong) that the circuits
related to open tabs are allowed to close. This is because the NEWNYM
signal is issued while also closing the connections for the currently
open tabs. The existing circuits close naturally because they are
already dirty. Then later tabs use new circuits and all is well in
A complication can arise when using other applications (like TorBirdy)
with the Tor Browser bundle. The problem is some mail server
connections fail to close and persist across new identities (NEWNYM)
issued by Tor Browser. This makes later mail server connections appear
to split with an existing connection through one exit and new
connections through some other exit. Closing tabs in Tor Browser won't
fix it. Closing circuits related to tabs won't fix it. What needs to
happen is to have the existing mail server connection (having not
closed on it's own) forcefully closed by closing the related circuit.
I'm unclear if this is (partially) a fault of the mail server. I've
seen the same behavior in other applications so it may also be a
failure at the exit. If you see this problem increasingly occurring
you might try setting up a Vidalia instance in parallel with the Tor
Browser bundle. (I wouldn't normally suggest it except for
troubleshooting). You would then be able to see the offending circuit
held open.

@_date: 2015-04-10 18:12:25
@_author: l.m 
@_subject: [tor-talk] 
You might also try exiting TorBirdy completely. Then use new identity
in Tor Browser. Then reopen TorBirdy and see if it's still reporting
the same exit.

@_date: 2015-04-13 12:21:29
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Sophie,
It would be highly unusual to be connected to the same exit if your
mail servers use standard ports. If I'm not mistaken the port you're
using for outgoing mail (25) is currently only allowed in the exit
policy of 3 exits. This hurts your anonymity, and makes the problem
more apparent. You should try to identify an alternative port for your
outgoing mail server as-soon-as-possible. Note that Tor will, by
design, reuse known good exits. So if the other two exits that handle
port 25 are overloaded this may also contribute to the problem.
You mentioned that restarting Tor Browser worked. A new Tor instance
would have a chance to try (and bias towards) one of the other 2 exits
allowing port 25.
Other things, included for completeness, to try include checking for
torrc modifications:
1a. open the Tor Browser install folder
2a. navigate through the folders Browser, TorBrowser, Data, Tor
3a. make sure torrc is empty (default)
4a. make sure torrc-defaults is original with a date of 12/31/1999
(19:00 or 7:00PM)
1b. close Thunderbird completely
2b. use new identity in Tor Browser
3b. reopen mail. If the problem is indeed a persistent connection holding a circuit
open this action should at least force TorBirdy to use a new circuit
(and exit). Note that a/b will be more effective if you *first* deal
with the problem of the port used by your mail server. If you would
prefer to troubleshoot this without adding any software you can also
connect to the Tor process using Telnet to gather information. Please
indicate which operating system do you use.

@_date: 2015-04-13 13:15:51
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Yuri,
The problem of closing the connections gracefully is generally left to
the application. In tor's spec it's explicitly stated that it's the
responsibility of the application to gracefully handle connection
failure. In Tor Browser, and every other browser for that matter,
there are exploits that can leave unclosed connections. Tor Browser
deals with this by explicitly closing the connections associated with
a tab, for all tabs. This works as expected--allowing dirty, but
unused circuits to expire (also gracefully).
The problem with the feature that you propose is that it breaks a
major functionality of Tor. By default all traffic directed at a
particular socks port shares circuits. This means that all
applications that use, say, socks port 9150 will have their
application streams mixed together. This can help in some (limited)
ways to obfuscate the traffic. For example, an exit has no way of
knowing how many clients are sharing a Tor instance. The exit only has
the unique circuit id to say the streams are related in some way.
Explicitly closing circuits completely would break third-party
applications in unpredictable ways. It would generate errors that
would lead to posts to tor support describing weird application
behaviour. On the other hand explicitly closing application related
streams requires tor to be aware of the processes using it. Which
means additional logic to handle not just source port per application
stream but also source address (for the shared tor instance). If
you've seen the backlog of tickets you would understand why a major
change like this is not ideal.
If there's a problem. Either of applications not closing the
connection, or a server not closing the connection. These are problems
that should be fixed--not hidden by tor. That isn't to say what you
propose isn't a good idea, just it might be better left to custom
controllers. I think tor-devs might prefer to avoid feature creep.

@_date: 2015-04-13 15:13:31
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Yuri,
The new identity feature is documented to make *new* connections
appear to be from a different user. It doesn't say anywhere that it
terminates existing application connections. That's an assumption on
the part of the user. The only application where there's an exception
is Tor Browser which is coded to break those connections. It needs to
do this to deal with web bugs. If some other application has open
connections using tor it stand to reason that application has a
purpose for keeping the connection open. Either that application will
close the connection gracefully or not.
It's a hack to force third-party applications to close their
connections explicitly and call it a feature of tor. In truth it's
something that can already be done. Connect to the tor process using
telnet and close the circuits as you see fit. Alternatively connect
using Vidalia and close the circuit. I'm sure there are other ways.
So, in fact, there's nothing to code to get the feature you want as
it's already there. There's no place for the feature in Tor Browser
since it already explicitly closes connections related to open
tabs--allowing the circuits to close gracefully. It remains the
responsibility of any other third-party application to gracefully
close their own connections. If they don't the circuit stays open.
How's that not a bug you would rather fix in the application itself?

@_date: 2015-04-13 15:55:24
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Yuri,
I, er, don't think what you're proposing is the answer to the OP's
If they're using a port which is only supported by 3 exits they'll
still have the problem. If one exit is blocked and they choose that
one the mail server will see further attempts as possibly malicious.
At least one factor is the need to avoid the blacklisted exits in the
first place. That's hard to do if they've been using the same handful
of exits. Someone may be attempting to break into their account and
the blacklist of the exit may be warranted.
Furthermore, it hasn't been identified that the problem is a
connection which is remaining open across new identities. That's just
a behavior observed for arbitrary traffic in the wild. It's should be
highly unlikely for email traffic alone to cause this behavior. It
would require their imap/smtp traffic to coincide with some webmail
traffic across exits where one is blocked. It was me who mentioned it.
That was before noticing the port number and it's rarity at exit
I've only ever seen the problem described as circuits held open (with
TorBirdy) under very specific circumstances. It cannot yet be the
cause of the OP's problem. Not enough troubleshooting done. It's
actually more likely to be the port.
Anyway, telnet isn't hard, you could just ask tor-talk. The hardest
part is getting the right format of cookie for (default)
authentication. It's harder to get Vidalia working.

@_date: 2015-04-13 16:13:47
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Sophie,
Glad to see the problem appears sorted. To find exit policies I used
the cat and grep commands on microdesc data. This data is available on
the CollectTor website as well as locally in your Tor Browser folder.
After loading Tor Browser, do a search for cached-microdescs in the
Tor Browser install folder. If you then open a terminal at the
location and use (for simplicity):
cat cached-microdescs | grep accept
That gives you an idea of accept policies. If you add to that:
cat cached-microdescs | grep accept | grep portnumber
That gives you an idea of how many exits (that you know about) which
accept portnumber. If you add to that:
cat cached-microdescs | grep accept | grep portnumber | wc -l
You'll have (very roughly) the number of exits. I'll leave it to you
to search the man pages for better expressions to use with grep ;) In
your case the number of exits accepting port 25 was quite small.

@_date: 2015-04-16 17:52:38
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi again,
To demonstrate further the importance of port choice I think a
clarification is in order. From tor's spec [0] an exit may specify an
accept or reject policy. So the number of exits that may allow your
exiting traffic (in this case mail) is those that "accept" and those
that don't "reject". Keep that in mind when parsing your data in
whichever method. The count is roughly 12 exits for port 25 versus 657
for port 587. The choice of exit is influenced by exit bandwidth and
successful use (in the short-term).
You mentioned trying to perform a similar look-up for exit policies
using Atlas. I didn't see an easy way to do so from the protocol [1]
used by Atlas. It's possible to perform the same inspection of exit
policy (as parsing/cat+grep local data) using the wget command with a
parametrization of the details method. There's no built in way to just
get the count of exits allowing some exit traffic. Or is there? Maybe
this would be a useful feature? It would allow a more informed choice
(12 versus 657 out of ~1000).
[0] [1]

@_date: 2015-04-23 20:06:09
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Sophie,
Hmm...Perhaps Atlas isn't the best choice here. At any given time the
exits you can choose from are those you know of locally. It might be
better to focus on TorBirdy instead. When using Tor Browser, the tor process is kind enough to take notice
when using certain ports (WarnPlaintextPorts). So maybe TorBirdy
should do the same. That is to say, make TorBirdy more verbose about
choices for mail server port. Had you been warned that port 25 is not
the port you're looking for you might have chosen differently. Even if
the port was chosen temporarily, a reminder could've helped. To make
things worse you have to switch between TorBirdy and Tor Browser to
change identities. Then you have to run something like
check.torproject.org to ensure your ip is different from a
(potentially blocked) previous ip.
So things TorBirdy could do better to avoid this problem in the future
a) Be more verbose about choosing the mail server port. Possibly
include a reminder which can be disabled. Warn when making a hazardous
choice such as 25. A known abuse port and one which is blocked in the
default exit policy and reduced exit policy.
b) Provide new identity functionality in TorBirdy. It would need to be
careful not to "step on the toes" of Tor Browser. To this end it could
emulate the NEWNYM signal by leveraging stream isolation. New
identities triggered by TorBirdy would create streams isolated from
previous streams. By tracking streams associated with mail servers
TorBirdy can ensure old connections are closed before new ones. It can
do this in a way such that no interference occurs with Tor Browser.
c) Enable TorBirdy to configure use of TrackHostExits/Expire. Purely a
preference to deal with Tor Browser triggering a new identity when you
might prefer to have TorBirdy continue to use the last exit for a
time. If you've triggered a new identity in TorBirdy to avoid a
blocked exit this could also mitigate the problem of a blocked exit
being reused. Is there a better way to achieve the same result here?
Comments, suggestions, criticisms?

@_date: 2015-04-25 13:16:09
@_author: l.m 
@_subject: [tor-talk] 
Hi teor,
You could run TorBirdy through its own instance of the tor client
software, with a separate socks port.
This  would avoid many of the issues you're trying to work around in
b) and  c), as TorBirdy could happily send NEWNYM to its own client
instance all  it liked. There is a slightly increased network load
involved in  running two instances, and there could be security
implications of  running separate tor clients - but mainly if their
connections are  distinguishable.
Good point. Then again you can do that with any application and tor.
The main motivator is the use case for shared tor process. Tor itself
encourages this use case by supporting multiple socks ports and
isolation flags. Is it reasonable to expect everyone to run multiple
tor processes to isolate the NEWNYM signal? It also raises the
question of *how* they would issue the NEWNYM signal. A patch would
involve adding a simple controller to TorBirdy. In some use cases it
probably isn't even a concern to share NEWNYM. That is sometimes just
a NEWNYM is fine, ignoring the problem of changing exit. So if a patch
were created it should support both use cases: issue a NEWNYM or
emulate it for shared use-cases?
I think it might be too much to ask a tor process to issue NEWNYM to a
specific isolation context. But given the shared-process use case is
encouraged--is this a preferable solution?

@_date: 2015-04-25 13:48:22
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Sophie,
There's a strong correlation between the perceived usefulness to
end-users and their support for a FOSS project :) A simple warning is
easy enough.
I was wondering if that was going to come up. The ip check hidden
behind a warning dialog hinders obtaining useful data. I'll keep that
in mind. Logging information on success and failure to use an exit
would be a useful for debugging (and finding problematic exits).
Thanks for the input.

@_date: 2015-04-25 14:20:47
@_author: l.m 
@_subject: [tor-talk] 
On second thought there is an advantage to discouraging the use of the
check. If something went wrong with the socks port setting using the
check would leak the intention to use tor by connecting to
check.torproject.org. Not a big deal, unless the socks port isn't set
or becomes unset, and a bridge is being used by tor.
So caution is probably a better idea and have a proxy check first like
about:tor in Tor Browser.

@_date: 2015-04-25 14:26:04
@_author: l.m 
@_subject: [tor-talk] Clarification of Tor's involvement with DARPA's Memex 
If you're trying to avoid suspicion you should use Tor for
*everything*. If you only use Tor when you have something to hide, or
to avoid censoring, or to avoid dragnetting, you'll definitely stand
out when you do use tor.

@_date: 2015-04-27 15:57:37
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Yuri,
switch check.torproject.org Good point. It's true, there's no such thing as enough security if the
consequence is high. To be fair though PT-design has come a long way
from the classical bridge. It's not uncommon to attempt to evade
detection by obfuscation of the protocol at the bridge itself. A
properly configured VM would provide a benefit here. What's to stop a
whistleblower from carrying around a custom TBB/TorBirdy instance that
uses unpublished bridges (hosted by some friendly nation)? No more
than carrying around a properly configured VM or live boot of Tails.
I'm just saying *if* a patch were to propose making the 'test proxy'
option more accessible it would (likely) be shot down. The only
reasonably sane way to do so would be to include an actual proxy test
that links to the optional ip check. For consistency, if nothing else.
As long as the proxy test succeeds I can't imagine why the ip check
would be needed except maybe for debugging.

@_date: 2015-04-27 16:24:24
@_author: l.m 
@_subject: [tor-talk] TorBirdy seems to connect to the same exit node 
Hi Sophie,
If you would like to submit the feature request what you would first
do is connect to Tor's bug tracker [0]. From there you can either
register for your own account or use the credentials listed in the
'Welcome' text on the first page. Select 'New Ticket' and fill in the
ticket. Choose 'enhancement' for type and 'TorBirdy' for the
component. If you wish to reference the discussion here on tor-talk
you can use the links available in the archives [1].
Tricky. A failure could be both. Tor tries to guess if an exit will
allow your exiting traffic but it's not a guarantee. In which case,
you're correct, a new exit is chosen. Perhaps from existing circuits
or by building a new circuit if needed. This would also occur if the
connection to the mail server is refused. A response 'blocked' is not
be a failure in the usual sense. The connection succeeds in a manner
of speaking but is closed before sending data. Thanks for pointing
that out.

@_date: 2015-02-01 16:51:50
@_author: l.m 
@_subject: [tor-talk] Tor -> VPN  Clarification 
This VPN & Tor (or Tor & VPN) subject - and its discussion here has become complex.
Maybe too complex for all but a handful of folks?
What's complex? Intelligence agencies are reportedly targeting all VPN
providers. Governments are targeting encryption of communications in
the name of national security. Sounds to me like it's a matter of
damned if you do, damned if do don't.
Case 1, Using Tor to connect to a VPN -- Forces the use of TCP for the
VPN and makes it (much) easier to perform statistical correlation.
Suppose you then start to apply modifications via pluggable
transports. Now you're network conditions are in flux measurably from
bridge to exit and back. So your VPN connection is adjusting while Tor
is itself still vulnerable to attacks at the ISP level. Tor learns
your use over time so you'll tend to have at most one clean circuit
available. Now what happens if the circuit is destroyed either OR
internal or at either end. Your exit ip changes to another of a
limited set of exits that support the port used by the VPN. The VPN
could still throw you under a bus for connecting from a Tor exit. If
they sell you out by your account/system fingerprint intelligence will
already be monitoring said VPN and so we're back to statistics derived
from watching both ends. Your adversary is already on the VPN, already
watching the exits, knowing which ones support said VPN service ports.
Now all that's left is to trace the traffic back to the guard--and
you. Unless you've already connected to a malicious guard by chance,
ISP level gaming of circuit build times, or guard rotation. i.e.
predictable to a fault.
Case 2, Using a VPN to connect to Tor -- Enables the use of resilient
UDP signalling. Allows you to throw padding traffic at the VPN while
using Tor. Tor is itself subject to the network conditions of the VPN.
The VPN is more capable to adapt to changing network conditions due to
the use of UDP and differences in the congestion control compared to
Tor+TCP. On the other hand the VPN provider may try to make money from
your non-torified usage. They might also (try to) throw you under a
bus at the knock of intelligence agencies. If they do they can provide
your Tor guard fingerprint. If you use many simultaneously you might
have cause for concern. If you only use one it might not be so bad.
Your torified traffic will presumably be spread across multiple exits
and be changeable at a click. Your adversary is already on the VPN,
already watching the exits, but (hopefully) don't know which ones you
use because of the dynamic nature. Now all that's left is to trace
your traffic from guards to exit. This might be harder if you use
pluggable transports and if they cannot predict your use.
I haven't even included the implications if, in addition, your middle
hop is adversary-controlled. Now I'm not saying either is better but I
prefer the one with more variables in my favor.

@_date: 2015-02-01 17:16:47
@_author: l.m 
@_subject: [tor-talk] ISP CenturyLink Blocking Tor? 
[...] I then enabled Pluggable Transports  (meet-google or something like that) and now I'm able to connect to  Tor without any issues. This really concerns me as I was able to  repeat the crash by launching Tor Browser Bundle and crash the router Did you try without using PT? Does this problem with connecting to Tor
directly also occur if you connect to a bridge directly. If they're
blocking Tor they should figure out the bridge is being used to access
Tor and you will shortly experience an offline/non-connectable bridge
or modem/router problem. It's also interesting you say you were
disconnected from the *router* -- what about everyone else. You might
be able to disable remote admin of router settings but that won't stop
them from resetting the device altogether (which might have the
symptom of appearing to be disconnected from the router).

@_date: 2015-02-01 18:00:16
@_author: l.m 
@_subject: [tor-talk] How to make TBB useable as "system Tor", as Tor, 
To rephrase this proposal in an alternative way... At the moment, when
you download the TBB package, your only chance to use
tor-launcher/Tor/pluggable transports is to also start Tor Browser. No
way to do that without starting Tor Browser. What is being suggested
here, is an option to just start tor-launcher/Tor/pluggable transports
without starting Tor Browser. Then tor-launcher/Tor/pluggable
could be used for the usual applications that can be torified. And
the user wants to start Tor Browser, it would just connect to the
already running tor-launcher/Tor/pluggable transports (if not already
Okay, that's clearer. So you're proposing to provide a launcher that
makes loading Tor Browser optional? That can already be done manually
as I'm sure you're aware. Download the TBB bundle then delete the
tor-launcher extension. Now you can start the tor process via symlink
or simple script. Then you can start/close/relaunch Tor Browser via a
simple script on a whim while keeping the Tor process completely
1. After extracting TBB, navigate to the folder
the tor-launcher xpi (:().
2. Create your script to launch the tor process with your chosen
options from Tor's documentation. Use this with your preferred
method/shell to launch tor's process automatically or manually.
3. Create another script to launch Tor Browser. Here you need to make
sure you export LD_LIBRARY_PATH to the location of libstdc++.so.6
included with TBB. After extraction this would be
script execute the firefox binary including the options --class and
-profile. The -profile option is relative to launch. An example would
be ./Browser/firefox --class "Tor Browser" -profile
your preferred method/shell to launch Tor Browser whenever needed.
Loading Tor Browser will be completely separate from the Tor process
and closing Tor Browser won't terminate the active Tor process.
Neither will it load the Tor process automatically (:().
4. Load Tor Browser for the first time. You'll get an error about not
being properly configured. Click on the Tor Button icon and select
Preferences. Change Proxy Setting to Use custom proxy settings. Make
sure SOCKS Host has the address of your Tor process (default
localhost) and that the value for Port matches whatever is specified
in your custom torrc or torrc-default. If you now type about:tor into
the address or reload Tor Browser you should get Congratulations.
These settings will persist on every launch of Tor Browser until you
replace the install.
5. Reuse scripts for any install of TBB having the same directory
That should be it. Should be a solution until further consideration of
your proposal yields a better result for you.

@_date: 2015-02-01 19:13:14
@_author: l.m 
@_subject: [tor-talk] How to make TBB useable as "system Tor", as Tor, 
Actually, my apologies. I forgot that if you use the method I
mentioned previously you'll need to issue NEWNYM to the control port
and you won't be able to use the improved new identity feature of Tor
Browser. A better solution.
1. Use a separate script to launch the tor process as previously
2. Load TBB the first time. Enter about:config into the address bar.
3. Edit the script that comes with TBB, start-tor-browser, and go to
line 248. Begin reading here for changes to extensions.
4. Make the changes to extensions and exit Tor Browser.
5. Optionally change the password in start-tor-browser at line 288 or
set TOR_CONTROL_PASSWD as described.
6. Now you can use the included script to launch Tor Browser without
creating another and can use the improved new identity via Tor Button.
Hope that's better.

@_date: 2015-02-01 20:51:32
@_author: l.m 
@_subject: [tor-talk] Tor -> VPN  Clarification 
I gather the one with "more variables in my favor" is Case 2 - Using
VPN to connect to Tor?
That is the one (some) have said is definitely not good - yes? Still others may have said that VPN  connecting to Tor, isn't as bad as some
have indicated?
Observation:  There are a LOT of assumptions about VPNs & adversaries.
And they may / could be true.  Just sayin'.
The scenarios you describe, would almost seem to say (equivalent of): "Either of these is *full* of pitfalls, but since I'm gonna die if I don't do something, I can pick one (then pray)."
Reason I ask (about using Tor & *anything* else), is I need to do some
legitimate, online research.
Not political / terrorist issues, etc., nor anything socially taboo.  But still something I don't want anyone looking over my shoulder.
And I'm not sure if using TBB by itself (in Windows) is "good enough."

@_date: 2015-02-02 10:07:46
@_author: l.m 
@_subject: [tor-talk] ISP CenturyLink Blocking Tor? 
If anyone can penetrate their personnel firewall, please disclose to this group.  In most on my dealings, CenturyLink was too under-employed to respond to my requests.
The problem hasn't even been confirmed as censorship of Tor and you
want to dox them publically using Tor-talk. Is that what you think
Tor-talk is for? Yes of course lets all get right on that for you--so
we can attack their privacy the way they may (or may not) be attacking
their client's? Wrong list. Wrong way of looking at this.

@_date: 2015-02-02 12:00:27
@_author: l.m 
@_subject: [tor-talk] Tor -> VPN  Clarification 
Sorry, I wasn't clear. I meant that nobody here has made an argument
that "VPN -> Tor" is "definitely not good". I agree that leeroy seems
favor Case 2 aka "Using a VPN to connect to Tor".
Well lets try to setup an experiment. I'll get you started. It doesn't
require you to be NSA :P It requires a guard you're in control of. It
also requires an exit you're in control of. It requires a completely
separate connection to the internet to perform testing. Let's setup a
test scenario. The common parameters are circuit length, three, use
case is VPN over Tor. You'll need to be familiar with R. Let's start
with the easiest test (ignoring path selection and middle relay
churn). Analysis of traffic at the guard+exit.
First, in general, it should be clear, from tor spec, that if the VPN
used doesn't use port 443 then you'll be limited to a subset of all
exit nodes. You can obtain current data for consensus at CollecTor
[0]. You can find a parser for said data in the relevant section. It
should also be clear, from tor spec, that Tor will learn your usage
over time and restrict your circuit build to one over time. Tor will
also tend to reuse (bias) exits which it knows can handle your
request. Your adversary knows where to look for you because you gave
them some conveniently static traffic signature to look for. Your VPN
connection is such an indicator.
What you'll be measuring is how attacks can be used to perform
statistical correlation across nodes. Analysis of traffic at the guard
simulates an adversary who is observing your guard traffic. This
adversary can see incoming (from you) and outgoing connections at the
guard. Analysis of traffic at the exit simulates an adversary who can
see incoming and outgoing traffic at the exit. So essentially you'll
have as much information as the GPA. This adversary has the
characteristic of being able to share information among national
intelligence agencies and can trivially place themselves along
vulnerable routes within the VPN and the ISP at both ends. Again, for
simplicity, we're ignoring the anonymity network-internal adversary at
middle hops and analysis of VPN internal traffic. Let's assume you're
using that VPN for something and you don't want them to see *your* ISP
address. Metadata alone can trivially filter all use of the VPN to
reveal outliers that use the VPN in unusual ways. Your use of a Tor
exit stands out as a particularly juicy target.
Now to find you using statistical correlation of signals. Some
H1 -- If the connection to the VPN gets dropped on it's way to the
guard or on it's way to the next hop you're in trouble. You can
simulate this by forcing a destroy. The DESTROY message propagates
through your Tor circuit and the VPN drops. If you do this reliably,
over time, you may even get an adversary controlled/observed middle
H2 -- If you interrupt the guard connection at your test machine (on
the test ISP) on it's way out to the guard you're in trouble. This can
force TCP congestion control on both the Tor circuit and VPN. Because
the VPN congestion control depends on end-to-end conditions you must
first wait for tor to stabilize before the VPN. A measurable change in
signalling has occurred.
H3 -- If the VPN connection is dropped at the exit you're in trouble
for similar reasons as H1. Doing this reliably over time allows the
reconnect to be observed at one of the exits recently used. This data
can be obtained using only the metadata of your VPN. Which exits might
be used in the future depends on the port used by the VPN. This data
can be obtained using CollecTor.
H4 -- If you interrupt the VPN at the exit you're in trouble for
similar reasons as H2 only now you're attacking the congestion control
of the VPN. This creates a measurable change in signalling.
H5 -- Combining data sets of observations at both ends completely
removes any anonymity. Recall this is intended to be a simulation of
an external adversary who can only see the signalling at both ends of
Tor and the VPN internal traffic. By putting all the browsing over the
VPN you've lost the one advantage Tor can provide. You've given an
adversary a mostly static point to attack and given them many options.
H6 -- Doing something convoluted like also using pluggable transports
(at the same time) or using Tor to connect to a VPN, then using that
VPN to connect to some anonymous network will not help. All you've
done is created stronger correlation.
I don't have the resources to do it myself but I'm sure it would make
a phenomenal study. On the other hand, leaders of most free democratic
countries have been quoted to the effect of saying "security and
freedom go hand-in-hand". Consider that some of these leaders forsake
humanitarian aid and join the propagandist ranks of those countries
which incite hatred by screwing up foreign countries. All the hate is
a direct consequence of bungled military operations. We, the lowly
voter, now have to accept that sacrificing freedom is necessary for
security. (oops--that's just an opinion not an advocacy for extremism)
So I stand by my choice for using a VPN to connect to Tor instead of
the other way around. From my limited understanding the threats posed
by the alternative far outweigh any possible advantage. Then again the
way I use Tor naturally follows from project goals so it's the choice
with more variables in my favor.
[0]

@_date: 2015-02-02 12:12:08
@_author: l.m 
@_subject: [tor-talk] ISP CenturyLink Blocking Tor? 
Leeroy - I think what he meant was that if anyone can actually get
to someone to talk to (and get a response) - as opposed to breaching a
firewall and leaking staff details, at least that's the way I read it.
Good point. My apologies if that's the case. I might have jumped from
suing them to the time for discussion having ended.

@_date: 2015-02-03 17:46:16
@_author: l.m 
@_subject: [tor-talk] How to make TBB useable as "system Tor", as Tor, 
You still can. Tor launcher is an extension for firefox. It's not the
same as Vidalia. You would still need to launch the tor process
separately for system use. You could use Tor Browser + tor-launcher to
configure torrc for you but that's it. You can continue to use
tor-launcher within Tor Browser. The tor-launcher extension cannot
launch a tor process then exit while keeping tor in memory for you.
Unloading the browser unloads the extension and the tor process.
On the other hand you could use Vidalia to control the system tor
process. Then make the extension changes previously mentioned to
continue using tor-launcher with TBB. You would need to be careful
with the control port password configuration. i.e. making sure it
matches between torrc and TBB launcher script. Yes, I know Vidalia
isn't supported by Tor Project anymore and it's full of bugs. You
could still use the improved new identity in TBB and be able to use
Vidalia. You wouldn't gain anything over configuration of torrc
manually and you could just as easily do with Vidalia and connect to
the control port for issuing NEWNYM.
If you're proposing tor-launcher replace Vidalia in controlling a
system tor process--it's not possible for an extension to fill that
role. Graphical control of a system tor process isn't TBB related. tbb-dev
would be concerned with how to get Vidalia like features into a
running TBB process. To my knowledge they're already working on that.
This isn't what you're asking for though. You're just as well off
posting here to tor-talk. You might convince someone to fix the bugs
in Vidalia or to write a new Vidalia inspired gui ;)

@_date: 2015-02-12 15:20:35
@_author: l.m 
@_subject: [tor-talk]  Funded search engine for onionspace? 
Thanks for hosting a Tor2web proxy. I think I'm using the search wrong
though. What exactly is it supposed to do? If I type in duckduckgo I
don't find a useable link to the hidden service. If I type in the
onion for duckduckgo I don't get any indication that the link is,
well, duckduckgo. To be fair a similar problem occurs with a regular
google query. On the other hand, with google itself, I can type
duckduckgo in combination with onion.cab and get a link. I'm sure I'm
using this wrong. When someone says to me, I have a search engine for
onion space, I think of typing in duckduckgo and getting results as:
- detect use of Tor and provide a link to the .onion topmost, or
redirect to the .onion if using .onion.city
- provide onion.city proxy links for everyone else that make it clear
it's the site queried
- provide alternatives to onion.city, such as the mirrors tor2web.org,
tor2web.fi, tor2web.blutmagie.de, onion.cab The last one seems especially important because, as was recently made
clear, an attack on an individual proxy can render it useless for
tor2web traffic. I've also read recently about how trivial it is to
get a list of google queries that correspond with client requests.
This makes me worry that a custom google query would also put this
data in the clear. Is this a custom google running in it's own rack
indexing sites? Clearnet search engines cannot access an onion so
wouldn't that make it hard for googlebot to crawl the site,
automatically, for sitemap or robots.txt? You would have to submit the
sitemap to google, and use a tor2web mirror in the address? Wouldn't
this create fragmentation in search results that only list tor2web
mirrors the crawler is aware of?
There should be more collaboration in these emerging search engines
otherwise you'll be outpaced by darpa. Note that darpa won't be
opposed to using questionable tactics in obtaining hidden service

@_date: 2015-02-13 18:30:54
@_author: l.m 
@_subject: [tor-talk] Funded search engine for onionspace? 
and the
If you instead use a google search appliance couldn't you use google
engine for indexing without having to use google itself? Wouldn't that
also avoid the problem of google queries being associated with the
client making the request?
What is unique to onion.city is that access to someonion.onion.city
occurs using http and doesn't redirect to the .onion if Tor is in use.
That the tor2web mirror might snoop is implicit--that the exit (if
using tor) might also snoop is more of a concern.
The ability of tor2web to provide mirrors should be optional. If you
only know one mirror and that mirror cannot service the request then
how are you going to get any of the other mirrors? Google engine can
return related addresses in an order based on the success of loading
the mirror itself. If onion.city always works it will tend to precede
tor2web.org. If onion.city goes down (having search front-end separate
from tor2web mirror) the search engine can reorder the result to
improve the success of the first click.
  >Right now I aggregate existing lists of onion sites and put them
into the
  >*   >*   >*   >* If google is itself handling the indexing won't that cause a problem
for sites in those lists, which are normally okay with being indexed,
just not by googlebot? I for one couldn't care less about being
indexed by ahmia.fi but it'll be a cold day in hell before I let
googlebot. Precisely because of how easy it is to link the search to
the requester.

@_date: 2015-02-13 20:03:12
@_author: l.m 
@_subject: [tor-talk] Funded search engine for onionspace? 
Yes I'm aware of the faq. It's just that in using google you'll always
be incomplete compared to ahmia.fi but thats ok by me.

@_date: 2015-02-15 08:52:26
@_author: l.m 
@_subject: [tor-talk] Who said it takes hours of latency to fix anonymity? 
Wouldn't it be more accurate to say it's takes non-deterministic
latency and non-deterministic signalling to fix anonymity? Since if
either are deterministic by analysis of the application then said
anonymity is provably breakable by signals intelligence. So TCP isn't
enough, neither is padding or latency tricks. Neither is it enough to
have one or the other. Sounds like a challenging question to me.

@_date: 2015-02-15 17:15:28
@_author: l.m 
@_subject: [tor-talk] Tor over SSH (torsocks) (?) 
I cannot comment on using torsocks but you can achieve the same result
using netcat and the proxycommand of ssh/ssh_config. I found a Tor
Wiki related article here [0]. More info can be located in the man
pages for ssh_config, and ssh.
[0]

@_date: 2015-02-18 16:04:44
@_author: l.m 
@_subject: [tor-talk] Tor over SSH (torsocks) (?) 
It sounds like you need to do a little introspection on why you want
to torify your ssh. You've already confessed to having a lack of faith
in your own technical ability. You need to ask yourself the
question--what is my threat model? You want to connect to a VPS--how
did you pay for this VPS? If you didn't pay for it using anonymous
currency then you might consider that torifying your ssh access will
provide limited anonymity if a (digital) paper trail exists. Without
using a hidden service you need to consider that the port you use on
your VPS will influence the choice of exit relay. Even if you use a
hidden service you need to trust the HS guard. If you use a hidden
service and your guards come under attack you may end up being unable
to connect to your VPS. In any case you may experience dropped
connections or the limited ability to connect. Which means you'll need
fallback connection methods or a server setup to detect-correct
faults. tl;dr Based on Roger's response you could use torsocks just fine. That
won't change needing to secure access (ie key-based auth). So you'll
need to read the man pages irregardless. Focusing on access via tor
before knowing how to secure your VPS will come back to haunt you.
That's why I recommend netcat via proxycommand. Why use torsocks if
you don't have to. It's not like you won't be editing the config files

@_date: 2015-02-23 15:06:11
@_author: l.m 
@_subject: [tor-talk] tor --verify-config requires root? 
It's the User option that requires tor to be launched as root.
Verify-config validates the options instead of just checking for
parseable form.

@_date: 2015-02-23 16:21:41
@_author: l.m 
@_subject: [tor-talk] Delete certificates 
The ones listed on the Servers tab of the Certificates Manager are
exceptions. You should see they're not trusted. View the certificate
and for good measure check the details tab. In the certificate fields
box you should see they are explicitly distrusted. When you delete
them you force the default behavior which has them checked for
validity--which should be untrusted per the security devices that come
with TBB. If they come back untrusted you're fine. Otherwise you
should just redownload TBB.

@_date: 2015-02-23 18:40:01
@_author: l.m 
@_subject: [tor-talk] tor --verify-config opens listeners? (for short 
Nice find Nusenu, when loading tor using --verify-config sockets
should be created to allow rebinding by later process invocations.
Sounds like SO_REUSEADDR needs to be used when invoking tor including
the verify-config option. Your kernel is seeing a socket in time_wait
state and the back to back calls are a racing against this state.

@_date: 2015-02-24 17:26:16
@_author: l.m 
@_subject: [tor-talk] TorBirdy prevents Thunderbird loading multi-OS bug: 
problem is determining what causes the problem. Tor project developers
have lives too and volunteers are encouraged to participate. I looked
at those tickets and it looks like the problem is cross-platform as
far as linux-like and windows are concerned. It shouldn't matter if
troubleshooting using linux, bsd, or windows then. I gather that
disabling Thunderbird addons doesn't help and it's unlikely that
addons are a factor from the windows bug report. Once the problem
occurs the only thing to do is delete the profile.
I'll setup a linux install with thunderbird+torbirdy using riseup for
testing. Not promising anything though.

@_date: 2015-02-25 11:37:19
@_author: l.m 
@_subject: [tor-talk] TorBirdy prevents Thunderbird loading multi-OS bug: 
Hi, It would be useful to know how the email account is setup in
general. Whether POP, IMAP, SMTP is used. SSL (TLS Wrapper) or
STARTTLS. Have any changes been made to default configuration of
Torbirdy preferences or non-default tor ports.

@_date: 2015-02-25 17:37:29
@_author: l.m 
@_subject: [tor-talk] Delete certificates 
Hi Tomas,
There are two sources for certificates. The personal db and the
hard-coded db. Hard-coded is what TBB uses by default and is located
in the libnssckbi module. Also known as Builtin Object Token. This db
is read-only which is why those entries come back. The personal db is
disabled by default in TBB. You can enable it as follows:
1. enter about:config into the address bar
2. type security.nocertdb into the search field
3. toggle the option to false
Now close and reopen your TBB and it will have generated a cert8.db
for your personal certificate db. In the future when you make changes
TBB (Firefox) will make a copy of the certificate from libnssckbi into
your personal db. It will then check the personal db first and use
what you've chosen for trust. If you need to copy the file you can
obtain it by selecting the menu button, then choosing the (?) icon and
Troubleshooting Information. There is a button next to Profile Folder
which will open you profile directory so you can copy the cert8.db.

@_date: 2015-01-10 08:48:01
@_author: l.m 
@_subject: [tor-talk] are there privacy benefits of running a bridge node? 
Virgil Griffith wrote
disguised I'm not sure I would call that use case more private. An observer
could categorize your traffic incoming from an intermediary relay and time
that traffic with outgoing traffic. The same observer could perform a
congestion attack on your exit and use that result to make differentiation more
isis wrote
additional Such as? The only two I can see are that you would know, assuming
that you can trust the zeroth, and first-hop. That and if you support
PT on the
bridge you might consider that to be more resistant to analysis.

@_date: 2015-01-10 09:28:30
@_author: l.m 
@_subject: [tor-talk] new paper on Tor and cryptography 
While you're asking  --
Isn't that like saying who needs SHA-3 because SHA-2 hasn't been
broken? Why not just use MD-contruct? It uses the same argument, yes,
Has the future of PQ computing become so well established?
Thanks taxakis

@_date: 2015-01-10 10:07:22
@_author: l.m 
@_subject: [tor-talk] are there privacy benefits of running a bridge node? 
Oh wait, unless, did you mean same ip? So you'll have clients using
your bridge while you make connections to a guard. Current Tor
implements guard rotation mitigation. Observe directory connection
during bootstrap and associate timing with your initially chosen
guards. If clients later connect to you as bridge it would be possible
to differentiate your traffic from incoming clients by timing and
looking at next-hop.
You might be able to take advantage of such a situation if were
willing to accept the consequence for more frequent guard rotation Which is to say not using guards at all or change them over short
intervals to mimic the choice of a middle node for a client. If you
have 1000 clients using your bridge I can see how it would be harder
to correlate their incoming connection vs. failed/successful
middle-hop with your outgoing connection to entry node.

@_date: 2015-01-11 11:15:48
@_author: l.m 
@_subject: [tor-talk] DNSSEC better protecting users? 
Where might this be a problem? tor2web protects the publisher not the
user. If you were worried about the user wouldn't you use Tor and
instead replace the .tor2web.org part of the address with .onion?

@_date: 2015-01-15 15:42:02
@_author: l.m 
@_subject: [tor-talk] Where's longclaw 
After missing signature it's now not listed in current consensus. Did
I miss some event?

@_date: 2015-01-15 15:52:48
@_author: l.m 
@_subject: [tor-talk] DNSSEC better protecting users? 
I know it's off topic but if you do use DNSCrypt by forcing DNS over
TCP make sure you don't use OpenDNS servers. If you're familiar with
OpenDNS you know they have a control panel where you can admin the
service wrt it's external ip relation. DNS based filtering and
monitoring of requests. If you do use OpenDNS servers it's possible
for an exit to both track the requests made *and* filter requests. Use
an alternative server.

@_date: 2015-01-15 16:42:47
@_author: l.m 
@_subject: [tor-talk] Fox News bans my Tor Browser 
You're probably the only one viewing that site using Tor. That would
explain why you didn't have any problem at first. Now they've noticed.
It might be the changing exit node from new identity. Some exits get
listed in well known blacklists. Then the site operators start to pay
attention and they block using session data even for the
non-blacklisted exits. This poses a problem for you because as soon as
your exit changes the site may block.
You might try adding TrackHostExits to your torrc-defaults. Then you
just need to find an exit that works. You might also try AllowDotExit.
torrc-defaults located in /Browser/TorBrowser/Data/Tor

@_date: 2015-01-15 17:31:13
@_author: l.m 
@_subject: [tor-talk] Open link from command line in running tor browser 
You can try running Tor Browser by issuing the command:
firefox --class "Awsum It Works" -profile
path-to-torbrowser-default-profile If you get an error 'Couldn't load XPCOM' you need to set your LD_LIBRARY_PATH to the location of the libstdc++.so.6 included with
your  Tor Browser download.
The default path to the profile is in
current working dir)
The default path to the included libstdc++.so.6 is in

@_date: 2015-01-16 17:48:14
@_author: l.m 
@_subject: [tor-talk] What relay does really help the TOR project? 
Long story short: What type of
relay helps the TOR project more?
Exit-Relay or Middle-relay? Is it really the "job" from TOR to provide
an exit to the normal internet resources or should the focus be on
hidden services?
First, thank you for operating a Tor node. Second, I would like to
suggest a simple solution to your question. Tor is already designed to
make the best use out of any node. The most important thing is to make
your node the most useful you can manage. Try to keep it stable and
running. If your service provider allows you to operate an exit make
your exit policy reflects this. I'm not trying to question your stance
on allowing porn. What I think is important is that some random user
of Tor may have stumbled onto your exit and, noticing it's usefulness,
may have targeted your node using dotexit notation. I'm sure lots of
users single out good exits in this opportunistic manner and for many
That aside, if you make your node as stable and useful as you can then
the algorithms take over. Your node will be used in the best way
possible by default. See the dir-spec and path-spec [1] for more
details. The benefit of this approach is that if network conditions
change your node may change it's primary role on an hourly basis.

@_date: 2015-01-16 18:28:21
@_author: l.m 
@_subject: [tor-talk] Fox News bans my Tor Browser 
TBB's new identity feature is considered more anonymity safe [1].
Vidalia's new identity doesn't consider how inter-tab traffic can
identify you. It also doesn't consider how changes to the browser
window make you unique (and trackable) across changed identities. TBB
will close open tabs and shutdown any traffic that may cross
identities. It also resets the browser window to some common size
within Tor's user-base.
TrackHostExits host -- try to reuse exits for the host [2]
AllowDotExit -- specify an exit to use with an address using dot
notation [2]

@_date: 2015-01-17 16:41:16
@_author: l.m 
@_subject: [tor-talk] Fox News bans my Tor Browser 
previous; Yes, Tor attempts to reuse known good exits from the past hour.
getting Not entirely handled badly. A failure (on a clean circuit) to connect
to a site because the exit is blocked should trigger closing the
circuit and reattempt connection on a new clean circuit. A potential
solution might be to explicitly attempt a country disjoint from (say)
the previous 2 failures for a site. That or explicitly exclude the
country associated with the past 2 failures for a site.
requires a This is tricky. A site which asks for a captcha hasn't failed to
connect. Detecting and evading arbitrary captcha would likely compound
the problem by making the site block more exits. You and the entire
Tor network might be better off just to answer the captcha. That's
what I try to do anyway. Just saying.
too IPa A possible cause is that Tor only considers building a new circuit if 30s have past since the last new identity. So if you click new
identity a  few times in a row nothing may happen. Another factor is
that if a  clean circuit exists Tor may ignore the request to build a
new one until  (up to) 10m have past or the existing circuits become
allow Germany, Detecting geolocation based blocks might be addressed by looking at
the location (suffix, registration, ip) of the site itself or the
if If a site wants to track you they'll figure out a way. Even if you use
different exits, new identities. Those options just provide a way to
access sites that might block your access if your exit changes during
use. You're right about risks though. The exit could be malicious. A
site could provide you an address including dot notation to select
your exit.

@_date: 2015-01-31 12:04:38
@_author: l.m 
@_subject: [tor-talk] High CPU-usage every hour 
I am using multiple Tor instances on the same machine and my CPU-usage
goes goes way up for a few seconds in exact one hour intervals. Is
regular behavior (generating new RSA keys?) or is it an anomaly of an
ongoing attack?
Every hour a new consensus is available to be parsed by your Tor
client. Though parsing the data usually takes longer than a few
seconds per Tor process. In the absence of further information about
your use I would suggest this is the reason for the load you're
describing. Sounds normal for a really fast cpu if each Tor process
has it's own cpu affinity.

@_date: 2015-01-31 13:32:09
@_author: l.m 
@_subject: [tor-talk] How to make TBB useable as "system Tor", as Tor, 
Your main concern, if I understand correctly, is that using available
"system" packages you lack the latest and greatest Tor packages.
Current versions of TBB, which include all the components you mention,
take an integrated approach to the included binaries. So what you're
requesting is less integration within TBB? The development process for
Tor, Tor Browser, and pluggable transports tends to be disjoint so
what you're suggesting sounds reasonable. From what you've suggested
thus far it appears that to achieve what you're requesting:
1. TBB takes a less integrated approach. Instead of having related
binaries included within the Browser folder the binaries for Tor, and
pluggable transports should be restored to their own folders to make
upgrading easier. This includes relevant data/configuration.
    -- Loading Tor enumerates available pluggable transports from a
(torrc) configuration specified location.
    -- Contains a PT configuration file that determines how the
transports are to be used by a Tor process.
    -- Loading Tor Browser depends on a loader from /Tor/ to determine
if a Tor  process already exists. Reuse the process/config or launch
the Tor  process if needed.
2. The expert bundle downloads/repositories for PT, and TB are added
such that it's possible to download and maintain each of Tor, PT, TB
There are a couple caveats to consider when deciding to use the system
Tor approach. The first being that some OS use backported updates.This
might be a problem if you were to try and supersede libstdc++.so.6
from your system with the one used by Tor Browser. Another problem
being that to use the same Tor configuration system-wide might not be
as easy to achieve on Windows as it is for non-Windows OS. Even
supposing that it were done -- not all OS processes are designed
by-default to be privacy preserving. Supposing that Tor were used in
this way, and (viola!) system-Tor were in use, might lead a false
sense of security/privacy/anonymity. A lot of OS processes would need
to be changed from default behavior and, at least in the case of
Windows, it might not even be possible to modify. That this night lead
to useable attacks on anonymity across the possible permutations of
system configurations is a concern.
This is from digesting what you've already posted. Please do correct
or add.

@_date: 2015-01-31 14:24:13
@_author: l.m 
@_subject: [tor-talk] ATOMIC BANJO and LEVITATION used by CSE 
In the view of such intelligence agencies using Tor might make you an
extremist. It's more than enough reason for them to pay attention and
arguably as much as directly accessing any monitored site. If they tap
the cables, and consult shared intelligence, what are the chances that
using Tor will stop them. It's must be an inside joke at NSA to say
Tor is one of the technologies that they've not broken. A clever
misdirection to maintain face globally. They (probably) won't be able
to deanonymize all Tor clients at a moment in time. Neither will they
admit how many they can at a moment in time. An anonymous network used
only by intelligence agencies is useless to them. We live in an era
where 2million to create a hash collision, and still be considered
relatively secure, is chump change for countries that can hide behind
economic powerhouses.
There's a wealth of information that can be derived from the data you
make public. Threats aren't classified by access to monitored
sites--they're derived from all the data that can be gathered about
you. Have you ever read "Finding Paul Revere"? [1] Chances are (100%)
if you use Tor and have a private online presence (or lack thereof)
you've got a great big bulls-eye on you.
All you can do is make their job as hard as possible with as little
gain. Wear them down. Make them beg for every scrap. Make sure they
know it too.

@_date: 2015-01-31 16:20:12
@_author: l.m 
@_subject: [tor-talk] Running TBB with a remote tor process 
wifi) to
... and access  to the control port and socks port occurs in the
clear. You'll want to  secure them or you'll need to trust anyone else
on the same subnet  doesn't snoop. You could introduce another layer
of encryption using SSH  to provide security. As far as using the
process for browsing--do you trust the other systems on the subnet not
to  snoop on encrypted traffic. This will influence the cipher
strength used--and did that extra layer of encryption gain you
anything besides  installation complexity? Regarding using the tor relay as a client you might find the following
to be interesting reads.

@_date: 2015-01-31 17:23:45
@_author: l.m 
@_subject: [tor-talk] WebRTC to uncover local IP 
============================== START ==============================
this It means:
1) The network configuration of linux is more secure than the network configuration of windows. Even when using a VPN. Unless the VPN drops (and leaks).
2) If you're using a browser without some control over  how javascript
is used you'll encounter web bugs. Some of which might  make your VPN
service useless from the perspective of hiding your ISP  address.
3) For some reason Chrome is only able to succeed in using  UDP for
STUN. Meaning, if I understand correctly, that if you point a  Chrome
install to Tor via socks the STUN fails and doesn't leak. If  that's
any consolation...
4) Even if you restrict javascript use you  still need to worry about
the adversary who poisons your DNS cache. Such  an adversary can pose
as a whitelisted domain and force your ISP  address to leak.
So, the take home message:
1) Windows isn't a privacy oriented OS, and should be avoided if
possible. If you're not using windows you're already set.
2)  Irregardless of the OS you should be using extensions/addons to
control  how javascript gets used. Noscript/ScriptSafe for example. Alternatively disable the web bug using WebRTC Block (Chrome), or media.peerconnection.enable (FF). If you're using Tor Browser you're already set.
3) Consider using secure DNS methods (dnscrypt for  example) for your
non-torified browsers where you've opted to leave  webrtc enabled and
instead restrict the use of javascript.

@_date: 2015-07-02 17:53:02
@_author: l.m 
@_subject: [tor-talk] Doctor's possible sybil attack report from 
Hi nusenu,
I'm glad you asked. Why don't they have the exit flag? It probably has
something to do with MinMeasuredBWsForAuthToIgnoreAdvertised being 500
by default. If you look at consensus-health [0] you see much more than
500. This means, and I'm only quoting the spec [1], that these relay
need measured bandwidth to have a weight assigned to them. In the
absence of a consensus weight (note they're all zero), these relay
have 0 probability of being chosen. So they need to respond to a
bandwidth scan, and they haven't.
[0] [1] Is it any consolation that the running relay are, by default, in two
family? 85.222.0.0/16, and 213.187.0.0/16 form a family by default in
tor (unless EnforceDistinctSubnets is 0).

@_date: 2015-07-15 10:49:19
@_author: l.m 
@_subject: [tor-talk] OFTC and Tor 
At least for OFTC you should be able to connect using tor if you
authenticate. Authenticate during connect [0] and use SSL. Seems to
work well.
Hope that helps,
[0]

@_date: 2015-07-25 14:32:02
@_author: l.m 
@_subject: [tor-talk] Amending copyright in license of derivation. 
Say I modify some software under Tor Project license. Can I
amend/update the copyright to include extra contributors without
removing existing content? Is this allowed or would this mean an EFF
lawyer is going to be unhappy?

@_date: 2015-07-28 14:00:42
@_author: l.m 
@_subject: [tor-talk] tor not running 
Maybe also check DEP settings.
1. Click Start, click Control Panel, and then double-click System. (or
right-click My Computer and choose Properties)
2. Click the Advanced tab. Then, under Performance, click Settings.
3. Click the Data Execution Prevention tab.
4a. Click, Turn on DEP for essential Windows programs and services
only, to select the OptIn policy.
4b.  Click, Turn on DEP for all programs and services except those I
select,  to select the OptOut policy. Click Add and add the
applications  exceptions that you do not want to use DEP with.
I would recommend (4a) for testing if DEP is the problem.

@_date: 2015-07-28 14:18:04
@_author: l.m 
@_subject: [tor-talk] problem 
Oh that. Figures. That's always the last thing to notice when Windows
doesn't even warn you if it blocks a file.

@_date: 2015-06-02 12:01:02
@_author: l.m 
@_subject: [tor-talk] ng-rend-spec and very public services 
So I was thinking, perhaps incorrectly, that ng-rend-spec doesn't do
enough to protect very public onion services. Sure, there are
advantages to the proposed changes. What if the adversary is also
someone who can derive the credentials? Encrypted descriptors don't do
much if you can throw SIGINT at HSDirs to determine when they're used.
Even less if you happen to be a HSDir who knows a list of public onion
services and you want to know if you're in possession of any of their
descriptors. If you happen to be using OnioNS you've got another
contributing factor in the form of the onion service lookup leaking
intent to resolve.
Tell me I'm just being paranoid.

@_date: 2015-06-18 07:54:26
@_author: l.m 
@_subject: [tor-talk] Matryoshka: Are TOR holes intentional? 
To add to what Roger said,
All that padding means nothing if an adversary can introduce latency
or gaps *at arbitrary* locations in a path. An adversary that can see
your guard, and who can also see the guards traffic can introduce the
gaps/latency in traffic at any point in your path. You may not even
see the attack without being able to visualize end-to-end bandwidth
statistics. It might be due to a routing problem at a particular node
in the path. Solving this adversary isn't easy because they can hide
behind the design of the internet. There isn't a single anonymity
network that is immune.

@_date: 2015-03-02 14:28:28
@_author: l.m 
@_subject: [tor-talk] Fixing the problem of sending email from Tor: Proof 
A good try at solving the problem but one which requires all mail
server  to get onboard in the presence of established alternatives.
The proof of work system you propose doesn't address the  problem of
tampered email contents or if the email was wanted. It *might* prevent
exits from being a  source of blacklisting at exchanges. The
suppression lists to which you refer aren't generated based on IP (at
least not primarily). They're generated based on proof of sender
authorization, proof of contents being untampered, and sender
reputation (complaint, reject). I'm not certain about where you're sending your email from.
Are you trying to send email from the GlobaLeaks domain?
At  the very least it means all mail servers on the internet would
need to  accept your proof-of-work as evidence of not being spam and
not being  tampered. Such emails could still be spam. The emails can
still be  tampered with by a misconfiguration of sending client (using
TLS Wrapper  instead of STARTTLS and being forced to fallback to
insecure  communications by traffic manipulation). In the end it takes
more than  proof-of-work for public mail servers online. They don't
care if the  email takes work to produce, they care about if the email
is wanted in  the first place and if the contents are as originally
sent. They're  motivated by $$$ and their reputation.
If you're trying to send  emails behind Tor from a domain you control
you should use DKIM. Email  servers online can then verify the email
was both authorized and  un-tampered during transit. Using DKIM won't
fix your sending domain  already being on a suppression list from
bounces before using DKIM (and  due to use of Tor). You'll still need
to apply for removal from  applicable suppression lists. Where it will
help is to prevent your  domain from being added to lists in the
future. From there if you get no  complaints (spam) or rejects (virus)
you'll be on the road to  establishing the good reputation of your
domain. (I didn't see a DKIM record for GlobaLeaks using default
EuroDNS selector)
That just  leaves one problem--mail servers who block incoming
connections from tor  exits the same way websites sometimes block
exits. This might happen if  the exchange is attacked from a Tor exit.
If you meant this in your  proposal I would be very concerned. The
strength of Tor is in diversity.  This would weaken path selection to
always hold a node static for  some-particular traffic. Irregardless
it creates a single point of  attack. Now an adversary can just watch
the node(s) that handle email  and correlate traffic with destination
exchange. This is effectively the  same question as "how to keep
web-sites from blocking tor exits?".
You  might then be better off using DKIM and choosing a non-blocked
exit  (which might need to be changed depending on destination
exchange). This  provides proof of legitimate use of tor exits and
creates incentives to  unblock exits. i.e an exchange might not like
the reputation of  censoring GlobaLeaks

@_date: 2015-03-02 20:15:04
@_author: l.m 
@_subject: [tor-talk] Fixing the problem of sending email from Tor: Proof 
Hi Malte,
It's certainly the case that you can enforce TLS. But which one? SMTPS
(TLS Wrapper) depends on the client enforcing and maintaining TLS on
port 465 using client-talks-first. It ensures (if properly implemented
and enforced) TLS gets used before any communication with the server.
It's also legacy and poorly supported, a footnote in the SMTP
migration to TLS. ESMTPS (STARTTLS) has the server enforce TLS on port
587 after an initial unencrypted EHLO command and is
server-talks-first. The client then has to validate the certificate
provided from some cert-store before completing initiating data
transfer. Both require TLS but SMTPS is non-standard.

@_date: 2015-03-07 09:54:23
@_author: l.m 
@_subject: [tor-talk] personal note 
tunneling in some  other traffic" instead of being sarcastic, maybe
you can focus on  wording your message better, I find it quite hard to
follow what you  write :)
I don't think it was sarcasm at all. It is a novel idea. It's exactly
what PT-servers need to do to avoid detection. Unfortunately there are
major flaws in your belief that bittorrent can be used to create cover
traffic. Mostly in that you've not made your implementation clear
enough. Do no harm. As it stands you rely on strength in number--the
peers in a bittorrent swarm. So if an adversary attacks the swarm
you've been spotted. If you try to go against the BT-spec you been
spotted. You don't have the luxury of hiding behind google or azure.
You've only got Bittorrent encryption to hide your data. Which means
you actually have no encryption because BT-spec encryption isn't
security oriented--it's obfuscation oriented for making traffic
shaping hard. (On a side note bittorrent failed miserably in this
regard) Which means, in the absence of swarm cover traffic, you've got
nothing to protect your data encoded inside bittorrent packets. An
adversary will then only have to compare your hash-failing pieces to
the known-good piece by looking at the hash.
I expected a response like "hey thanks for being so critical because
criticism will make this transport stronger", I expected "it might be
a good idea to consider this criticism seriously for the sake of those
I'm trying to help"
What I got was yet another assumption. Sarcasm requires an ego. A
focus on self. Yet I think I've made it clear that my focus is on the
ethical concerns behind what you're proposing for those who will be
using this transport. I should care you've got trouble following what
I write? After that kind of response I couldn't care less.

@_date: 2015-03-11 12:35:53
@_author: l.m 
@_subject: [tor-talk] Protest Blocking Tor via CloudFlare 
Which site blocks tor exit entirely? I haven't seen one recently. Most
of the time I just get the copy/paste if Javascript is off. If
Javascript is on I either don't get the copy/paste or I get the
browser fingerprinting page. If I'm not mistaken the browser
fingerprinting site is the only one a free CF user has access to. The
ability to block anonymous proxy entirely is a paid feature isn't it?
Which would mean it's not CloudFlare who needs a grilling.

@_date: 2015-03-12 10:55:36
@_author: l.m 
@_subject: [tor-talk] Protest Blocking Tor via CloudFlare 
That's a list of sites that use CF captchas. I meant CF-enabled sites
which block Tor access entirely with only a message box for the
site-admin. I just figured since the subject was "Protest Blocking..."
that there would be specific sites where this is possible.

@_date: 2015-03-12 11:29:41
@_author: l.m 
@_subject: [tor-talk] Protest Blocking Tor via CloudFlare 
I guess it's still possible to have an infinite captcha loop even with
the free CF account or regular CF-captcha request. All a site would
need to do is use free CF then have an ip-based (TorDNSEL) redirect
back to the start. If they were to redirect to, say port 80, it could
construct a request to force Tor to consider a new circuit. This would
use the new circuit for redirecting back to the CF-captcha page which
would elevate to https. That would be annoying.

@_date: 2015-03-17 15:51:26
@_author: l.m 
@_subject: [tor-talk] Are webmail providers biased against Tor? 
To  put it bluntly. I read what you typed and saw a justification for blocking tor. Whether you actually ascribe to the tactic is beside the
 point. You typed: if I have no reason to accept tor on my server then
 blocking it makes sense, yes? Using tor shouldn't be a matter of
acceptable traffic: yes/no, block justified. Based on being lumped in with the bad it makes sense to justify some
servers may block tor?
Your privacy and anonymity online may be a game but for others it's a
serious concern. It would stand to reason that any justification for
blocking tor would offend.
The context of the response appears accurate.

@_date: 2015-05-05 12:36:24
@_author: l.m 
@_subject: [tor-talk] German University signs up 24 tor relays 
I'm not trying to upset anyone but do we really have to stalk every researcher who adds relays? Honestly, does there need to be a report
on  x-number of relays were added, constituting a spike this month to
date? I  mean this purely out of respect for tor-related research
worldwide.  Engaging in tor related research means they have the
ability and mentor  to identify the reason they're not getting x-flag
is because of reasons  ___, ___, and most likely ___. They know
there's resources available to pose questions if their mentor cannot
provide one. Does every tor researcher have to  disclose their
research before it's time? It's a little bit rude to assume they don't
understand the spec.
What if their research involves studying the traffic at an exit. What
if their research involves studying exploits? Yes, I know it's
questionable. This is science and engineering though. As a graduate it
wouldn't be fair to assume there wouldn't be a disclosure of results.
Have they done something wrong that they need feedback. Did they ask
for it (yet)? They aren't responsible as a graduate with a mentor?
If they're a master's student in Germany they'd have to be hiding
under a rock to not know the state of wiretapping by state
A little patience would be more becoming of a not-for-profit
organization that promotes privacy and anonymity. I do research too,
ongoing even, should I disclose everything to date too. Honestly. Let
them be until they're ready.

@_date: 2015-05-05 13:07:47
@_author: l.m 
@_subject: [tor-talk] German University signs up 24 tor relays 
I didn't say wondering about an anomaly is disrespectful. Assuming you
have the right bring their relay's to everyone's attention is
disrespectful. This is a network around privacy and anonymity
after-all. Isn't there a better way to start a witch hunt? Like
discovering relay's that do something wrong first? Who cares if they
don't have ContactInfo. It's not mandatory. Do you know how long these
relay were intended to stay up? What about the state of their
configuration? Are they complete? Was the operator intending to add
that information at a later time after changing the configuration.
It's like saying we know they've not read the manual and they are
intending ill-will. It's rude. Plain and simple.
Not to mention I see lots of relay without valid ContactInfo or
questionable ContactInfo.
I mean no disrespect. Seriously though; do you think every researcher
wants their relay's to be identified or linked to their research.
Because tor network is only filled with well-meaning people right?

@_date: 2015-05-05 14:22:57
@_author: l.m 
@_subject: [tor-talk] the privacy of public tor descriptor data (was: 
How hypocritical. You like to change the subject, again. You and Roger
crossed the line when you didn't accept the operator's response and
leave them alone. They only responded because you *forced* them to. A
relay descriptor is not a person. It's a machine processing digital
blips on a wire. A public descriptor describes a machine. If that
machine prefers to withhold personally identifying information who are
you to even ask why.
A relay is not a person, a descriptor may describe a real-person
relationship iff the operator decides to. It's a good thing Tor
Project doesn't have a code of conduct posted on the website. If it
did I would ask you to take it down.
Of course you have the right to ask questions and make nice graphs
about relays. If those relay make personally linkable information
available it's a choice. A project that promotes privacy and anonymity
is in violation of it's own purpose the moment it tries to force the
operator to identify themselves. I think you did just that. At least
that was the effect.
You've given me much to think about. Thank you.

@_date: 2015-05-05 16:00:24
@_author: l.m 
@_subject: [tor-talk] the privacy of public tor descriptor data 
Wow. You just blew my mind. So anonymity and privacy for users, but
not contributors that make said privacy features possible? By that
reasoning ContactInfo would be mandatory, which it's not. It also
follows that MyFamily would become a high-priority (mandatory) feature
to implement rather than something which is considered for
elimination. I'm curious--how do you intend to prove two relay with
similar subnet and ASN are related? I would be very interested in that
So regarding users/clients, don't ask, don't tell, and, in fact,
heavily document how they can avoid identification.
Regarding infrastructure operators. If you withhold *non-mandatory*
information you *will* be suspect. Even if you happen to be a
university. I feel so much better now.
x-num of relays registered to a public institution, forced disclosure
follows, that or be seen as a threat
-> relays associated with department
---> relays associated with research -----> relays associated with graduate
if the research isn't approved by tor network as a whole -> researcher becomes a target
-which means-
tor research becomes discouraged -> bugs, flaws not identified ---> state intelligence win
I propose you change the documentation, and the code to reflect your
stance. Which to me sounds like bs. The truth is anonymity of tor is
for the good, and bad, no matter how subjective. It's also a matter of
practice that a relay is only be marked bad if you do something bad,
or are incapable of performing relay duties. Otherwise you loose
flags. At not point is it an acceptable to treat a relay group as
suspect for missing non-mandatory data. The spec and design doc says
you're wrong.
Every researcher falls into two categories: those who support the
government and see tor as a possible threat, and those who support
privacy-anonymity advocacy. Singling out relay operators means the
former consider the choice wise, and makes the latter second guess.
It was wrong to push the operator. Engaging in research isn't wrong.
There's a completely valid reason to not want to have this information
available and this specific event is an example. If you allow elicit
drug harbors because you can't prove where they are--how can you
assume a relay may be malicious without gathering evidence. Your
public descriptors give you no right over the operator identity. Deal
with it.
What if the operator of these relays had ignored you? They should
have. You would have gone bonkers wouldn't you.

@_date: 2015-05-06 06:54:27
@_author: l.m 
@_subject: [tor-talk] German University signs up 24 tor relays 
>... in other words, relays are inherently public.
What? did you actually contribute to the conversation? What the hell
does that even mean?
Fine. Relays are public. The people who operate them are public
figures too. To hell with privacy. HS descriptors are also public. Their operators are public figures. If
I want to create hsdirs to profile hs use and then attack hs
infrastructure that what I'll do. If that also means attacking the HS
itself to discover service weaknesses, I'll do that too. Don't like
it? Too bad. The descriptors are public.
Don't you have a glorified beagle-rasp-board to convert into a router?
Must be hard. Not like you can rely on off the shelf routers to
produce consistent lack-of-compromise.

@_date: 2015-05-06 07:19:07
@_author: l.m 
@_subject: [tor-talk] German University signs up 24 tor relays 
Relays are a machine, an ip, a server, with a public relay descriptor.
You ISP has a similar descriptor for your CPE connected to their
infrastructure. So the ip you use is public without precaution. Does
that automatically make the association of you with that ip an
enforced public policy. Maybe for your ISP or government. Not on tor
If you really want to single out operator, or researcher, for missing
some non-mandatory data, like some tor nanny, you better be prepared
for consequences. Here I thought the policy was to create advocates
not enemies. All I'm saying is if a researcher at a university
registers some relay without contact that doesn't make them suspect.
Get some proof then the discussion is a moot-point. Just because some
past event happened (US-CERT, Black Hat Conference) doesn't give you
the right to force disclosure. Don't play coy. Forcing disclosure is
exactly what happened. Don't post some blog entry about being against
harassment then stalk or harass a researcher for not being proactive
to your comfort level.
You should be grateful for their work, not self-righteous. What the
hell do you think? The university pays for the relays and doesn't have
a code of conduct for student activity using university resource? That
code of conduct somehow doesn't apply to this graduate or their
mentor? Exactly how much work have you done with a university because
it sounds like none.
That's my 2c.

@_date: 2015-05-06 07:24:04
@_author: l.m 
@_subject: [tor-talk] German University signs up 24 tor relays 
I'm pretty sure I defended the researcher's right not to disclose
anything. Had nothing been disclosed these relays would be nothing but
24 relay associated in some way with a university. Now they're
associated with a work in particular. I'd expect you to reply as such
based on a search of the archives.
Pretending an attempt didn't occur to force disclosure doesn't change
the fact that it didn't happen. Ignorance is bliss isn't it. Must make
you feel good.

@_date: 2015-05-08 15:26:02
@_author: l.m 
@_subject: [tor-talk] Friendly LAN bridge -- bad idea? 
Such as
1. All users that share a tor client also share a threat model. The
tor configuration is shared. This may not be an ideal property.
2. If one user of the shared tor client breaks the process--it's
broken for all others. Which is to say a bug, exploit, failure will
affect all users simultaneously.

@_date: 2015-05-09 18:10:54
@_author: l.m 
@_subject: [tor-talk] Codename: TorBirdy 
Hi Vincent,
If you don't have access to the email on the other end you wont be
able to verify the headers. One way you might achieve your goal would
be to access the TorBirdy preferences and using the Test Proxy
Settings feature. You can access the preferences from the addon page
in Thunderbird or by clicking on the green text at the lower-right and
choosing Open TorBirdy Preferences. After the warning you'll see the
test button at the lower right of the next dialog box. The test will
load the site, check.torproject.org, and verify that the external ip
you're using is a Tor exit. This would mean the mail you send will
also come from this exit.
However, it doesn't verify the localhost proxy is operational first.
Just so you're aware. A way to ensure this isn't a problem is to make
sure the "Use recommended proxy settings for TorBirdy (Tor)" option is
selected *before* trying the button.

@_date: 2015-05-10 18:59:08
@_author: l.m 
@_subject: [tor-talk] send email through the Tor network 
Hi Cam,
What kind of web email? Could you be more specific?

@_date: 2015-05-16 14:10:51
@_author: l.m 
@_subject: [tor-talk] help will not connect 
Hi Jon,
You're using obfs3-bridges and you're not able to connect to them. If
you're sure there's no firewall interference on your computer you
should try the following. When you start Tor Browser click Open
Settings, Configure, Yes, then try changing the Transport type to one
of the meek-bridges. If you're still not able to connect, do the same
thing to get to this dialog and click on the Help button. You'll see
there are options for obtaining bridges by email and web. You would
then add the custom bridges to this same dialog.

@_date: 2015-05-18 07:50:53
@_author: l.m 
@_subject: [tor-talk] the privacy of public tor descriptor data 
I'm looking at the archives. Where did they choose to reply on
tor-talk a second-time. I'm blind. Won't you please point me to the
right response. I see providing a contact, not details of research.
Enlighten me. When did they disclose that information after it was
Does you know? Didn't think so.

@_date: 2015-05-18 11:46:16
@_author: l.m 
@_subject: [tor-talk] Crasher in tor browser alpha when playing videos 
Hi Chris,
Besides filling out a ticket you might try running TBB in debug mode.
Open a terminal and navigate to the folder you extracted TBB. It has a
folder called Browser and start-tor-browser.desktop. Now run:
./Browser/start-tor-browser --verbose
Which you will see from the script starts TBB without detaching. You
can also run:
./Browser/start-tor-browser --log [file]
To create the output in a log file for attachment to your ticket.

@_date: 2015-05-18 16:29:39
@_author: l.m 
@_subject: [tor-talk] Making a Site Available as both a Hidden Service and 
I think you're putting too much thought into making your site
available as both hidden service and on www. It's not about if you
can, or should you do it. It can be reduced to one thing: do you want
to hide the origin server for the hidden service? If yes, you have to
consider the complexity of keeping both services partitioned from each
other. If not, then, well, you get the point.

@_date: 2015-05-19 06:31:06
@_author: l.m 
@_subject: [tor-talk] Making a Site Available as both a Hidden Service and 
your website than just that. :-)
Such as? A hidden service is by definition hidden. So if you're
willing to have both a HS-front and www-front, how is it that it's not
the only consideration. A tor exit hides the client-origin so besides
the usual e-peen statement that .onion is superior __because__. None
of it matters. As the operator you'll experience complexity, nothing
you wouldn't experience anyway. How did the choice to deploy both HS
and www become about reasons? There are no reasons, none against
anyway. Only consideration of the deployment complexity.
That's like saying a name service for onions is superior to a petname
system. When in truth the statement induces two completely different
objectives. Reasons is not equal to deployment complexity. The title
says "making a site available ass both a HS and WWW". I choose to
ignore the deployment complexity and roll-my-own solution, not ask for
reason for why I might want both.
tl;dr - I agree, it would be great for everyone who has both a www and
HS for a site to use the same methods of solving deployment issues.
Makes it easier to target. Oh, btw, when was the last time facebook
was in the news for privacy violations--yesterday? An onion bought FB
exactly what?

@_date: 2015-05-19 07:26:19
@_author: l.m 
@_subject: [tor-talk] Making a Site Available as both a Hidden Service and 
No, because, as I've said. Your deployment of www-front induces the
same design choices. A HS-front is nothing more than a gloriously
encrypted version of the www-front. Same challenges as www-front but
more resources, more computation, more headers, more proxying, more
concern for latency and keep alives. More of everything. It's not hard
bro. If you set up a www-front you'll need to reinvestigate every part
during the HS deployement. So all I'm saying is you're over thinking
this. *Any* webmaster would be able to look at in such terms. So
really the deciding factor for all of your 'challenges' is do you want
to hide the origin server for HS. Because that is what determines the
rest of the deployment complexity. All you've currently considered is
learning-by-example. You don't successfully deploy by-example.

@_date: 2015-05-19 07:39:14
@_author: l.m 
@_subject: [tor-talk] Making a Site Available as both a Hidden Service and 
Oh wondrous challenges-by-example
About the https. I would just like to point out that FB using https
amounts to nothing more than a glorious kludge to win back people
who've moved on due to privacy concerns. So they try to prove identity
using a CA-cert, then wrap encrypted onion traffic in another layer of
encryption. What does it gain them except to be able to say: despite
what you may have herd about us, we really do care about your privacy.
However, redirecting from onion on a different port to https (on the
same front and simultaneously available on www) isn't as easy as it
sounds. That will break your sites secure elements. Onions lack a CA
and they're as secure as https using DH with ephemeral keys. You might
find you experience fewer problems in secure parts of your site
without the https. I guess that's not really by-example though. Sorry
I don't have a by-example example.
Oh and another example. If you accept payments by certain methods
(non-anonymous) your liability skyrockets when those payments are
issued using the onion. Although I can't provide you with an example
because it's a secret.
How's that. More examples to add to your examples. Hope your
deployment goes well.

@_date: 2015-05-19 07:48:34
@_author: l.m 
@_subject: [tor-talk] 
Typo. Not enough coffee. Enclose https in onion encryption. Worse even
than using a tor exit.

@_date: 2015-05-19 08:01:56
@_author: l.m 
@_subject: [tor-talk] Making a Site Available as both a Hidden Service and 
Incorrect. It's a reason to not accept those payment methods from the
I didn't say you asked for examples. I said you only consider by
example. Which you just did. But that's besides the point. You plan to
deploy on a locally run user site yet you claim to be conscious of
breaking the production server. It does not follow.

@_date: 2015-05-19 08:24:10
@_author: l.m 
@_subject: [tor-talk] 
More typo. You stated somewhere you intend to deploy to a test site
run locally. Something to that effect. I hope I'm not quoting you out
of context. Which would mean you have both a production server and
development server on which to take measurements and instrument as you
please. Those measurements are what gets it done.
And while I'm here:
So you're running both via some sort of multi-homing. As you've said
you don't care about hiding the server. Great, that simplifies your
deployment. You just need to be concerned with ensuring trust of your
site by not doing anything silly. Such as selling their data,
embedding exploitable code, not caring that your client really doesn't
want to use javascript, etc. All the things you would do with a HS
anyway. Without the constraint of hiding like the worst of tor.
Congratulations on giving your clients a choice and for being a good
model of tor use.
A counter example where you might actually want to hide the HS origin:
I was thinking of setting up a Christianity oriented site accessible
by onion in [redacted]. Although I don't care about attacks on the
www-front, I definitely don't want to have traffic on the HS be
correlated by side channel attack on www-front. Because then the
people who use the HS might experience severe persecution not just
(potentially) for using obfuscated bridges but also because of the
content. I'm glad this doesn't apply to you though.

@_date: 2015-05-22 19:50:10
@_author: l.m 
@_subject: [tor-talk] 
If tor had a more modular path selection system like pluggable
transports then work like this would be easier. Instead of forking tor
(perfectly fine of course), researchers could propose alternative path
selection algorithms. The proposals could go through a review then
implementation stage. Then clients could choose path selection
according to different threat models (requiring handshake support). A
tunable path-selection makes for some very interesting possibilities.
I look forward to reviewing the AS-inference against an adversary who
really want's to avoid detection by this implementation.

@_date: 2015-05-24 09:54:09
@_author: l.m 
@_subject: [tor-talk] SOCKS proxy to sit between user and Tor? 
Is the Socks-to-Socks proxy absolutely necessary? This could be done
as a browser plugin couldn't it? You might find the work of the
FreeSpeechMe team interesting. They have the objective of integration
with tor which sounds a lot like what you describe. It's probably not
vetted to your standards (yet) but the source may be a start for
tinkering. Would I be correct in saying this offers an alternative over OnioNS in
that it:
- requires downloading the blockchain, so will not leak statistics
associated with lookups
- can be extended to a general petname system which maps personally
chosen identifiers to known onion properties
On that note: what are the advantages of namecoin (.bit to .onion)
over a petname system (id to .onion) or OnioNS?

@_date: 2015-05-24 09:58:30
@_author: l.m 
@_subject: [tor-talk] SOCKS proxy to sit between user and Tor? 
Oh, nevermind I see you're already associated with that team.
Cool extension. So why the shift from plugin to proxy?

@_date: 2015-05-24 15:32:37
@_author: l.m 
@_subject: [tor-talk] SOCKS proxy to sit between user and Tor? 
Hi Jeremy,
Thank you for the thoughtful and thorough reply! I  think the users of
your software will appreciate you wanting to minimize  attack surface.
One thing I've noticed about mitmproxy is that it  appears to only
support SOCKS upstream proxies *without* authentication.  It's also a
http proxy, so although it's certainly useful, it may not  meet your
current requirements (in transparent proxy mode you'll exclude support
on Windows). I may be mistaken of course.
If I understand correctly you  intend to use the intermediate SOCKS
proxy to perform the translation of  .bit address to destination
format. If the address doesn't require  translation you'll pass it
through along with any authentication used  for domain-isolation. The
downside of using an intermediate proxy is  that you'll have an extra
dependency. The intermediate proxy needs to be  modified to perform
lookups against a local resolver as needed. If  proposal 229 [1] is
implemented you'll need to be aware of the changes.  This may turn
into maintenance difficulty in the long run.
If this  were a regular browser you could always just setup the local
DNS  resolver to forward if not resolving .bit addresses. Since this
is tor  you need to make that resolver aware of tor being used, and to
use the  SOCKS proxy instead (or tor-resolve). So maybe that's one
option. Have a  local DNS resolver which forwards to tor after
checking the address  (and turn off browser Remote DNS). That is to
say it might be easier to  maintain your own resolver implementation
which can be kept as simple as  you need. This would keep (some)
cross-browser compatibility, from TBB,  to Firefox. The downside being
the whole system will rely on the  resolver so you'll have to worry
about: conflicts with other local  resolvers (dnsmasq, some vpn), or
need to set the DNS server manually.  It looks like you do this
currently. If the local resolver wrapped all  the related processes
you could make a UI available to indicate status.
As a browser-plugin based alternative, maybe you can do without the
extra SOCKS proxy by a change to the plugin design. Say you use
Observer Notifications in the plugin. Now intercept the address and if
it ends in .bit make a request against a (local) server holding the
blockchain. This provides some flexibility in that you're not
restricted to using a SOCKS proxy. It should work with TBB. Unless I'm
mistaken (and I frequently am) websockets are enabled (check with
tbb-devs on this). An alternative approach would be to create your own
address bar for resolving addresses using the same approach previously
mentioned. There's a downside to this approach, in that if someone
were to use the regular bar, the resolve will be relayed using tor,
which might actually work if the exit DNS is setup to resolve
namecoin. Besides that, I'm only familiar with the SSH SOCKS proxy, and Tor's
SOCKS proxy. I can only look at the list of SOCKS servers on
Wikipedia, or HAProxy, as was previously mentioned, for other options.
In any case, thank you for trying to make FreeSpeechMe compatible with

@_date: 2015-05-26 18:40:03
@_author: l.m 
@_subject: [tor-talk] SOCKS proxy to sit between user and Tor? 
I'd like to point out that if you decide to use another SOCKS proxy
you may encounter another problem. Suppose I bypass the port assigned
to your custom proxy and instead point to the usual tor proxy. This
might occur if a user manually configures the proxy and cannot tell
the difference between the two. Most likely it'll fail and they'll
notice. In a worst case, your blockchain resolves are bypassed and a
leak occurs. It also raises the question of whether you really want to have a SOCKS
proxy for both regular firefox and tbb/tor.

@_date: 2015-05-26 18:45:14
@_author: l.m 
@_subject: [tor-talk] SOCKS proxy to sit between user and Tor? 
Of course turning off remote resolves to use a local resolver (free of
conflicts) also has this downside. Settings persist between tbb launch
so if remote DNS is turned off and a local resolver is down a leak
occurs using the system DNS.
If anything, for the sake of your sanity try to keep everything in the
I'd like to point out that if
you decide to use another SOCKS proxy
you may encounter another problem. Suppose I bypass the port assigned
to your custom proxy and instead point to the usual tor proxy. This
might occur if a user manually configures the proxy and cannot tell
the difference between the two. Most likely it'll fail and they'll
notice. In a worst case, your blockchain resolves are bypassed and a
leak occurs. It also raises the question of whether you really want to have a SOCKS
proxy for both regular firefox and tbb/tor.

@_date: 2015-05-28 10:28:05
@_author: l.m 
@_subject: [tor-talk] [RELEASE] Torsocks 2.1.0 
As described on the contact page of torproject.org:
If you found a security issue in one of our projects or our
infrastructure, please email the respective maintainer. You can find
their GPG fingerprint/key on our developer ldap search page. Due to
the many different projects we have, we do not offer a single list for
security issues.
A search on db.torproject.org provides the fingerprint/key which you
can compare against key pools.

@_date: 2015-05-28 14:48:14
@_author: l.m 
@_subject: [tor-talk] TBB does not employ fontconfig settings 
To answer your question you might find the Tor Browser design document
[0] a useful read. Font support leads to browser/system
fingerprinting. Plugins and scripts can extract font support lists,
html5 canvas elements can be used together with font
support/rendering, and the way fonts are rendered can lead to OS and
video card driver fingerprints.
tl;dr -- Font-support based fingerprinting remains an open-issue in
the current version of TBB.
