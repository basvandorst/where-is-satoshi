
@_date: 2007-04-05 12:39:22
@_author: James Muir 
@_subject: Another Method to Block Java Hijinks 
I've heard that properly configuring a firewall can be tricky.  In any case, using a firewall still doesn't protect from Java applets reading identifying information locally and sending it back through the anonymous connection.
In my opinion, I think its best just to disable Java, and all the other plugins mentioned in the warning on the download page.
You may be interested to know that there is a Live CD which bundles Tor and some ipchains rules.  It is mentioned in the Tor FAQ -- see "Virtual Privacy Machine":

@_date: 2007-04-25 11:16:33
@_author: James Muir 
@_subject: 2-node circuits Vs 3-node circuits 
Entry guards help defend against the ?verlier-Syverson attack on hidden Create-fast eliminates some unnecessary public key operations when a client negotiates ephemeral keys with its entry guard (they are unnecessary because the client already has a confidential and authentic TLS connection with its entry guard).  Basically, Create-fast makes surfing the web through Tor faster for clients.
Remember that all of the Tor network links are TLS encrypted.  So the create-fast command shouldn't be visible to entities outside the network.  However, which nodes serve as entry guards is public knowledge (this information is posted in the Tor directory).  So, if an ISP monitors TLS connections to a known entry guard, then they can collect a list of IP addresses of Tor clients.  But remember 1) Tor isn't designed to hide the fact that you're using Tor, and 2) using Tor isn't a crime (well, in my country it isn't :-)
Let's say all Tor nodes are equal now (i.e. there are no such thing as Entry Guards anymore).  If I monitor one node (say I'm an ISP), then I can collect IP addresses of hosts using or participating in the Tor network.  Some of these IP address will be from other Tor nodes, and some will be from Tor clients.  For any IP address I collect which is not listed in the directory, I can be certain that this is the IP address of a Tor user (i.e. someone who runs a Tor client and not a Tor node).  So even without CREATE_FAST, an ISP can still collect IP addresses of Tor users.
Tor clients can use fewer or more than 3 hops if they wish (you might have to modify the source code), but as Roger mentioned, using fewer than 3 hops is not recommended.  If you use mostly 2-hop circuits, then most of the time your entry node will know exactly which other Tor node to coerce (e.g. using a subpoena) to determine who you are communicating

@_date: 2007-04-05 17:10:51
@_author: James Muir 
@_subject: Another Method to Block Java Hijinks 
In the tests that I have done previously, the Java VM inherits the proxy settings listed in the browser (at least this is what is supposed to happen; sometimes this does not happen).  So if the browser is configured to use Privoxy and these setting are communicated correctly to the Java VM, what is there to stop a Java applet from sending back data through Privoxy?

@_date: 2007-02-02 16:04:55
@_author: James Muir 
@_subject: Ssh MITM attack when using tor 
Just curious -- how does ssh inform you that a man-in-the-middle (i.e. the exit node) is trying to victimize you?
If you have access to the logs on the machine you were ssh'ing into, you should find the IP address of the exit node there.  Once you have identified the malicious exit node, I would inform one of the Tor designers. In the future, you can turn on Tor's logging and look in the log file there to see what your exit node is (you may have to turn off "SafeLogging" in order to see Tor node names).

@_date: 2007-02-14 11:06:36
@_author: James Muir 
@_subject: how did my OP discover this IP address? 
I've been reading my OP's log file sorting through the various outbound connections that it makes into the Tor network.  I came across the following directory fetch request:
connection_connect(): Connecting to "72.1.218.225":9030
What has me a little puzzled is that I can't find this IP address anyplace in my OP's cached directory information.  Also, looking at the torstats web page ( I don't find it listed there either.
I think maybe this was the IP address of the router hevad99, which is now listed with the IP 72.1.218.238.  If this host has a dhcp connection then that might explain things.
Is it the case that hevad99's IP address changed during my (1 hour) Tor

@_date: 2007-02-14 12:38:57
@_author: James Muir 
@_subject: how did my OP discover this IP address? 
> Perhaps that was an IP you typed directly in. For example, you clicked
 > on a web link and instead of  it was
 >  in which case tor would only show and IP. I'm
 > not sure if that's how it would appear in the log file, but it's a
 > guess.
 > Ringo Kamens
The connection is a directory request (port 9030) made by my Tor client (aka. my Onion Proxy).  It's not a result of my surfing the web.  I know this for certain because I didn't do any web surfing while the log file was generated; I just let the Tor client connect to the Tor network for an hour.
I'm just a little curious about why that IP address (72.1.218.225) doesn't show up in the Tor directory.  If there is a record someplace of   past IP addresses that ORs use then it might show up there.  Anyone know of such a record?

@_date: 2007-02-15 11:11:00
@_author: James Muir 
@_subject: PHP coder needs Tor details 
Tor needs to create a directory where it can store network data.  It tried to create one at //.tor, but it does not have the necessary permissions.  You need to tell Tor someplace where it has permission to create a directory.
Have you had a look at the sample torrc file that comes with the tor source?  It is quite helpful.  Here is an excerpt:
 The directory for keeping all the keys/etc. By default, we store
 things in $HOME/.tor on Unix, and in Application Data\tor on Windows.
 /usr/local/var/lib/tor
So add a line like this to your torrc file:
DataDirectory /path/to/where/nobody/can/write/tor
(that's "nobody" as in the username nobody).  You can also specify this as a command line parameter -- read the tor man page to see how to do that.

@_date: 2007-02-16 00:08:31
@_author: James Muir 
@_subject: suggestion for 'is my installation of tor working?' page 
Along with having a web page which attempts to educate Tor users about the dangers of executing Java, JavaScript, Flash, etc. in their browsers, I think there also needs to be a stronger warning about this on the main Tor web site (tor.eff.org).  There is a warning on the wiki but this is something that's important enough to promote to the main page (and have translated).
There are Java and Flash applets that, when run in a Tor user's browser, will open non-proxied connections back to their originating web sites and thus expose a user's real IP address.  This is, I think, the most serious threat to Tor users who don't disable these in their browsers -- never mind fingerprinting my machine by capturing my screen resolution, etc. with JavaScript.
The NoScript extension with FireFox works great -- it disables all scripts and plugins.  I hope people who really need anonymity are using these.  However, I expect that many are using IE.  I don't run Windows, but I would guess that there probably isn't an easy way to disable Flash in IE.  A clear warning with the Tor client installation instructions might help new Tor users better protect their anonymity.

@_date: 2007-02-02 16:29:33
@_author: James Muir 
@_subject: Ssh MITM attack when using tor 
Just because you upgrade your OS doesn't mean you should throw out all your server's public keys. I would think that the server's maintainer would migrate the public keys over to the new system (if they remember, and if their hard drive hasn't crashed).
In any case, ssh public keys are self-created and are not validated by TTPs.  So, the very first time you connect to the server I don't think you would be able to detect a mitm attack.

@_date: 2007-02-19 16:40:24
@_author: James Muir 
@_subject: Removing 1 modular exponentiation 
that's not really a problem.  all computations are done in the group ZZ_p. 1/k really means the inverse of k modulo the order of g in ZZ_p. So b/k does not have to be an integer.
putting the security of the scheme aside, one question that comes to mind is how Alice (the OP) is going to get an authentic copy of Ricky's DH public key, y.  One way to do this is to include it in the router descriptors.  But then we have to ask if it's worth adding a new public key for each OR to the Tor PKI to just save one exponentiation during session key agreement.

@_date: 2007-02-19 17:34:30
@_author: James Muir 
@_subject: Removing 1 modular exponentiation 
the way things are done now, each OR has two public keys in its router descriptor.  you are, I think, suggesting that another be added.  I was just wondering if you had considered the extra bandwidth load this puts on the directory servers.  If the extra load is substantial (maybe it isn't, i don't know), then maybe we shouldn't give the ORs another public key to manage just to save one 1024-bit exponentiation.

@_date: 2007-02-19 18:23:29
@_author: James Muir 
@_subject: Removing 1 modular exponentiation 
Since we are working modulo p and we know that g is a generator of ZZ_p its order is p-1.  So, to find X above you just need to solve:
This can be done efficiently using the extended Euclidean Algorithm (provided that gcd(k,p-1)=1).

@_date: 2007-02-19 21:55:51
@_author: James Muir 
@_subject: Removing 1 modular exponentiation 
>>>
ah.. that makes sense to me now.
You may already know that the current scheme has a security reduction (Goldberg, PET 2006), so I imagine there would have to be a comparable argument before the powers that be would consider a new scheme.
Out of curiosity, what is it about your scheme that makes you say it is

@_date: 2007-02-21 14:09:31
@_author: James Muir 
@_subject: purging old router information, revocation 
I'd like to know how directories are cleaned up after a router leaves the Tor network.  I've read through the specs distributed with 0.1.2.7-alpha but I haven't been able to find a discussion on this. Maybe some readers who run onion routers have had some practical experience on this that they can share.
If an OR leaves the network and no longer accepts incoming connections, then I understand that the directory authorities will no longer list it as "Running" in their network-status documents ("Running" means the DA was able to connect to it sometime in the last 30mins).  How long will the DAs keep trying to connect to an OR that doesn't respond?  At what point do the DAs purge their stored descriptors for that router and no longer list it in their network-status document (assuming that they do, in fact, purge information)?
Eventually, the onion key for a router that has left the network will expire (the default lifetime is 1 week).  If a descriptor contains an expired onion key, do the DAs detect this, or is it up to the Tor clients do to this?
I just noticed that src/or/or.h seems to give some clues to these questions:
  * from the router list? In seconds. */
 ROUTER_MAX_AGE (60*60*48)
  * consider it live? In seconds. */
 ROUTER_MAX_AGE_TO_PUBLISH (60*60*20)
 OLD_ROUTER_DESC_MAX_AGE (60*60*24*5)
 NETWORKSTATUS_MAX_AGE (60*60*24)

@_date: 2007-02-24 00:49:32
@_author: James Muir 
@_subject: purging old router information, revocation 
Thank-you for explaining this.  I agree that it would be very nice to have this documented in dir-spec.txt.  It is definitely not discussed there now.
One thing that I couldn't find any reference to in the comments in the source code is how long directory authorities will keep trying to connect to an onion router that is not responding.  Is this also 20 hours?  There is a discussion about what Tor clients do when one of their entry guards stops responding but I would guess that directory authorities probably behave differently.

@_date: 2007-02-25 18:24:24
@_author: James Muir 
@_subject: "Low-Resource Routing Attacks Against Anonymous Systems" 
No one seems to have posted this to the list yet, so I thought I should:
"Low-Resource Routing Attacks Against Anonymous Systems",
K. Bauer, D. McCoy, D. Grunwald, T. Kohno, D. Sicker
Technical Report, University of Colorado
It was posted on Slashdot:

@_date: 2007-02-25 19:13:51
@_author: James Muir 
@_subject: "Low-Resource Routing Attacks Against Anonymous Systems" 
I just skimmed the paper quickly (I'm going to give it a careful read tomorrow), but I didn't see too much math in there ;-)  The impressive part of the paper seemed to me to be their experimental results (albeit using a private 66-node Tor network installed on PlanetLab).
I agree that the principles underlying the attack do not seem to be "new".  It was already known that nodes can submit false statistics about their uptime and bandwidth to directory authorities.  And it was already known that if you control the entry and exit node on a circuit you can link initiators and responders using timing analysis.  But maybe the paper has some new things to say about the implication of those facts.
Concerning an ISP controlling both entry and exit nodes:  when Tor clients build paths, they avoid choosing two nodes on the same /16 subnet (see path-spec.txt).  So, it does not seem that this is likely to

@_date: 2007-02-26 21:47:25
@_author: James Muir 
@_subject: "Low-Resource Routing Attacks Against Anonymous Systems" 
For those interested, here is someone's official response about the Technical Report and its implications for the Tor network:
Does anyone know who authored that?  It seems a bit strange to have an anonymous official statement, but maybe this is appropriate for Tor ;-)
Here is an FAQ by one of the Tech Report's authors:

@_date: 2007-02-27 11:13:52
@_author: James Muir 
@_subject: building pages with tor in mind 
I have some examples here:
I have yet to see an example of pure JavaScript code that can read an end-user's IP address.  Any code I've seen returns either "localhost" or

@_date: 2007-02-27 13:25:34
@_author: James Muir 
@_subject: building pages with tor in mind 
The risk is that you become more trackable.  The more information you make available about your browser, plugins and OS, the easier it is for web servers to create a profile on you (i.e. a record of your previous actions).  If you have cookies enabled and never delete them, then it is really easy to profile you!  Perhaps during one visit to a web server you accidentally submit your name in a web form.  In that case, your identity can be linked to that profile (i.e. you can be held accountable for all your previous actions).
I wrote a blog last year which explained some of this (although, re-reading it now, I see that a few of the details I wrote about Tor were incorrect):

@_date: 2007-02-27 17:17:07
@_author: James Muir 
@_subject: building pages with tor in mind 
The particular exploit that I think Paul is alluding to here (which I haven't mentioned previously) is the following:  in the latest Java API, the constructor for the Socket class has been designed to allow connections which by-pass proxies.  So, if you have the Java 1.5 or later VM enabled, you should beware that applets can open non-proxied connections, regardless of both the proxy settings in your browser and the proxy setting you set in the Java Control Panel.

@_date: 2007-01-11 15:28:49
@_author: James Muir 
@_subject: cbc news article: Website wants to take whistleblowing online 
my apologies.  I only recently subscribed to the list.

@_date: 2007-07-20 12:06:28
@_author: James Muir 
@_subject: RIP Anonymizer Web service 
The senior system admin and the president/founder of Anonymizer.com have given some more details about the discontinuation of their product "Private Surfing" in the above Slashdot discussion.  They are still marketing their other products; however, the free version of Private Surfing is no longer available.

@_date: 2007-06-19 11:35:58
@_author: James Muir 
@_subject: FF plugins DNS leaks 
hi Marc,
the warning on the download page at tor.eff.org states the dangers of toolbars in firefox and other browsers (  You might consider following the advice there about using a stripped down browser to surf the web with Tor (e.g. install a new copy of firefox, separate from the firefox you use for non-anonymized browsing).  You could also try one of the live Tor distributions mentioned on the list.
If you could report your findings about which of your toolbars leak your IP address based on WireShark traffic captures, then I'm sure that would be helpful to some of the readers here.
To answer your initial question about why Tor isn't giving you a warning about the identifying traffic leaving your computer, the answer is that Tor can't warn you about traffic it doesn't handle.  The traffic generated by your toolbars isn't being proxied by Tor, so it won't warn you about it.  I don't use Vidalia, but I think I recall that Vidalia does a number of geoip queries which are not proxied.  This does not necessarily violate Tor's security model, however.  Remember, Tor is not designed to hide the fact that you're using Tor.  It's designed to provide unlinkable communications.

@_date: 2007-06-19 11:43:02
@_author: James Muir 
@_subject: FF plugins DNS leaks 
correction:  it seems that Vidalia now proxies its geoip queries, so
your IP address is not exposed that way.  Quoting from

@_date: 2007-03-07 13:46:45
@_author: James Muir 
@_subject: one less onion skin 
Is the 8 to 20% AES CPU time true even for Entry Guards?
When I checked a couple of weeks ago, the network-status documents listed only 279 Entry Guards (out of 1301 total nodes).  My thought was that it makes sense to make their burden lighter since they handle more circuits.  Can't we eliminate 33% of the Entry Guards AES operations by dropping the outer onion skin?

@_date: 2007-03-03 12:23:56
@_author: James Muir 
@_subject: TLS HMAC key bit-length 
Does anyone know the bit-length of the symmetric keys used in HMAC after two nodes establish a TLS session?  I've tried to discover this from the specs, source code and using various "openssl s_client" commands, but no

@_date: 2007-03-08 18:30:16
@_author: James Muir 
@_subject: Warnings on the download page 
Your Java applet could be improved.  (hmm... I see you are using a Datagram Socket...)
The latest Java API includes functionality for making non-proxied connections (i.e. you can specify directly whether the applet's connection out will be proxied or non-proxied; this setting overrides any browser settings and any settings in the Java Control panel).  What is particularly interesting about this is that this behaviour is I discovered this back in January 2006 and wrote about it in a tech report.  I can give you a pointer to the tech report if you are interested.  I also have a demo which I will eventually post a URL for here once I clean it up a bit.

@_date: 2007-03-08 20:02:33
@_author: James Muir 
@_subject: Warnings on the download page 
All versions since 1.5 (released Sept 2004) have it.  The current version is 1.6 (although now Sun is calling it Version 6).
The docs for the 1.5 API are here:
Anyone who thinks it is safe to use Java with Tor needs to read this:
 > Socket
 >
 > public Socket(Proxy proxy)
 >
 > Creates an unconnected socket, specifying the type of proxy, if any,
 > that should be used regardless of any other settings.
 >
 > If there is a security manager, its checkConnect method is called
 > with the proxy host address and port number as its arguments. This
 > could result in a SecurityException.
 >
 >     Examples:
 >
 > * Socket s = new Socket(Proxy.NO_PROXY); will create a plain socket
 > ignoring any other proxy configuration.
 >
 > * Socket s = new Socket(new Proxy(Proxy.Type.SOCKS, new
 > InetSocketAddress("socks.mydom.com", 1080))); will create a socket
 > connecting through the specified SOCKS proxy server.
In the 1.6 API, everything is the same.
You should read the Fort Consult White paper "Practical Onion Hacking" as some of things you mention (SMB, CIFS) are mentioned there, I think.   VB and ActiveX are probably worth exploring.

@_date: 2007-03-08 23:37:59
@_author: James Muir 
@_subject: Warnings on the download page 
Even if all Java connections are proxied through Tor, it is still possible to read the end user's IP address locally and submit it to the server that originated the applet.  Java, along with all other browser plugins, should be disabled.
By the way, I just had another look at Roger and Mike's warning on the download page (it's now repositioned above the download links).  I think   it's very well done.  Good work!

@_date: 2007-03-08 23:55:32
@_author: James Muir 
@_subject: Removing 1 modular exponentiation 
The following recent preprint deals with the subject of this thread:
A. Kate, G. Zaverucha and I. Goldberg
Pairing-Based Onion Routing   pdf
CACR 2007-08

@_date: 2007-03-09 00:30:56
@_author: James Muir 
@_subject: Security Focus story 
A number of comments made on the list are referred to in this story. One of Nick's posts has been quoted.

@_date: 2007-03-11 09:45:35
@_author: James Muir 
@_subject: Not enough networkstatus documents to launch requests 
Mar 11 15:04:50.686 [info] update_router_descriptor_client_downloads(): Not enough networkstatus documents to launch requests.
Sometimes it takes Tor a while to collect network status documents. In my experience, if you just let Tor keep trying for a few minutes, say 5-10mins, then this problem will work itself out.  Of course, if the directory servers are unreachable from your location, then the problem isn't going to go away.  You should try entering the IP address of a directory server in your browser to just to make sure.

@_date: 2007-03-14 09:45:19
@_author: James Muir 
@_subject: Not enough networkstatus documents to launch requests 
It looks like you are running tor as root;  I don't think this is recommended.  In any case, as root, try this:
wget If this command successfully pulls down a network status document, then tor should be able to do the same.
If you still aren't able to diagnose the problem, try downloading and building  the latest tor from source; however, this time make sure you do it as a normal user.

@_date: 2007-03-14 13:10:06
@_author: James Muir 
@_subject: Not enough networkstatus documents to launch requests 
Does tor have the necessary permissions to write to /root/.tor ?

@_date: 2007-03-20 12:37:22
@_author: James Muir 
@_subject: posting hidden service descriptors 
I am trying to sort out a few low-level details about hidden services.
I know that hidden servers must post their descriptors to the DAs anonymously to avoid exposing their IP addresses.  Is this done through a normal (i.e. three hop) circuit?  I suspect it is not because in src/or/circuitbuild.c there is a condition for creating one-hop tunnels and a log message "Launching a one-hop circuit for dir tunnel."
My concern here is that using a one-hop circuit exposes the origin of the hidden service to that onion router (i.e. the one-hop).  Even if the data the one-hop relays to the DA from the OP is encrypted, the one-hop still learns an IP address which originates some hidden service (although, it may not be certain which one exactly).

@_date: 2007-03-20 17:13:42
@_author: James Muir 
@_subject: posting hidden service descriptors 
Thanks for the clarification!  That makes sense to me now.

@_date: 2007-03-06 23:11:16
@_author: James Muir 
@_subject: one less onion skin 
A typical Tor circuit looks like
OP -- OR1 -- OR2 -- OR3
where the three "--" links are all TLS connections.  TLS protects the OP's communications from adversaries outside the network, but another layer of crypto (used inside TLS) is needed to protect them from the onion routers themselves (e.g. we don't want OR1 to learn the identity of OR3).  Thus, the onion proxy (OP) negotiates AES keys and MAC keys with each onion router; call the AES keys k_1, k_2, k_3 and MAC keys d_1, d_2, d_3.
My question is this:  why bother with k_1 and d_1?  the communications between OP and OR1 don't need to be protected from the other onion routers.  I understand the reason for using k_2,d_2 and k_3,d_3, but k_1,d_1 doesn't seem to be adding anything.

@_date: 2007-03-07 00:07:25
@_author: James Muir 
@_subject: one less onion skin 
I agree that not using k_1, d_1 would allow OR1 to determine that they are the first node in a circuit.  However, Tor clients already leak this information.  The key agreement with OR1 is done using a "CREATE_FAST" command rather than a normal "CREATE".  So, once an OR receives a "CREATE_FAST" it knows its position in the circuit. (it might be that Tor clients which are also onion routers themselves do not send "CREATE_FAST"... I am not sure)
So the question is, if we have already leaked this information, are we wasting CPU cycles doing AES with OR1?

@_date: 2007-03-07 00:13:48
@_author: James Muir 
@_subject: Noobie Configuration Questions 
NoScript will also disable Flash in addition to JavaScript, although you have to enable this in its config window.  In fact, NoScript will disallow all plugins, which is really what you want.
No JavaScript, no Java, no plugins at all.

@_date: 2007-03-07 00:56:22
@_author: James Muir 
@_subject: Building tracking system to nab Tor pedophiles 
The approaches suggested won't work if you use Firefox with NoScript set to disable JavaScript, Java, Flash and any other plugins.

@_date: 2007-03-07 01:07:06
@_author: James Muir 
@_subject: one less onion skin 
I suppose that could happen, since the OP controls what commands are sent down the circuit to OR_{n-1}.  However, I don't think it would be a good idea.  If OR_{n-1} sent a CREATE_FAST message to OR_n then OR_{n-1} would learn the value of the AES key that OR_n shares with the OP.
The only legitimate situation in which a CREATE_FAST should be used is to do key agreement with OR_1.

@_date: 2007-05-26 12:14:58
@_author: James Muir 
@_subject: traceroute through tor and http proxy? 
If you turn on Tor's log, then it will report which nodes it is routing through (you may have to disable SafeLogging to see actual router names).  Would this type of proof satisfy you?
