
@_date: 2006-12-04 21:52:28
@_author: George Shaffer 
@_subject: Off Topic: Getting PGP and GnuPG Public Keys 
I've noticed a fair number of list members use GnuPG or PGP and I got
tired of manually trying to find a keyserver that had the poster's
public key. I know they are supposed exchange keys, but this seems very
hit or miss. So I wrote the little script below. It includes several
keyservers I'd been using plus all the ones listed at
less those that did not respond within a few seconds. It seems to work
pretty well under bash (Linux, CentOS 3.4/Red Hat Enterprise 3.4). It
also works on OpenBSD 3.9 under csh and ksh, so it should work under
just about any bash, csh, or ksh environment with GnuPG installed. For
PGP you'd need to correct the command syntax for each keyserver.
I hope someone finds this useful.
George Shaffer
if gpg --keyserver tickets.rutgers.edu --recv-key $1
   echo tickets.rutgers.edu
   exit
if gpg --keyserver pgp.mit.edu --recv-key $1
   echo pgp.mit.edu
   exit
if gpg --keyserver keyserver.veridis.com  --recv-key $1
   echo keyserver.veridis.com
   exit
if gpg --keyserver pgp.keyserver.ch  --recv-key $1
   echo pgp.keyserver.ch
   exit
if gpg --keyserver pgp.surfnet.nl --recv-key $1
   echo pgp.surfnet.nl
   exit
if gpg --keyserver  --recv-key $1
   echo    exit
if gpg --keyserver pgp.es.net --recv-key $1
   echo pgp.es.net
   exit
if gpg --keyserver pgp.rediris.es --recv-key $1
   echo pgp.rediris.es
   exit
if gpg --keyserver pgp.nic.ad.jp --recv-key $1
   echo pgp.nic.ad.jp
   exit
if gpg --keyserver pgp.uk.demon.net --recv-key $1
   echo pgp.uk.demon.net
   exit
if gpg --keyserver pgp.zdv.uni-mainz.de --recv-key $1
   echo pgp.zdv.uni-mainz.de
   exit
if gpg --keyserver keyserver.linux.it --recv-key $1
   echo keyserver.linux.it
   exit
if gpg --keyserver keys.iif.hu --recv-key $1
   echo keys.iif.hu
   exit
if gpg --keyserver pgp.eteo.mondragon.edu --recv-key $1
   echo pgp.eteo.mondragon.edu
   exit
echo exiting failure

@_date: 2006-10-31 21:05:23
@_author: George Shaffer 
@_subject: reporter from The Economist in Thailand seeks help / new Tor 
Learn to read the whole thread before posting. I discussed links and
said it was better than lynx, in response to "what about links?" about 7
hours before your post.
George Shafferr

@_date: 2006-10-31 21:16:49
@_author: George Shaffer 
@_subject: Apology: was Re: reporter from The Economist in Thailand seeks 
Sorry, the following was meant to be private. I thought I'd replaced
or-talk at freehaven.ne with the author's email but realized too late that
I had not.

@_date: 2006-10-31 21:31:48
@_author: George Shaffer 
@_subject: Possible fishing attempt for eBay 
They are bogus. I got exactly the two same emails and reported the first
to spoof at ebay.com. I wonder if it is pure coincidence that two people on
this list got the same phishing emails. Did anyone else get these?
George Shaffer

@_date: 2006-10-05 17:28:07
@_author: George Shaffer 
@_subject: Confused about Tor settings 
It's true that anyone who can read your DNS traffic can figure out sites
that you will likely be connecting to by TCP/IP protocol. Determining an
IP destination from DNS doesn't mean they can tell what you do there
(more below). The DNS issue does not mean Tor has no point. Tor prevents
(or attempts to and probably mostly succeeds in preventing) the site you
are going to, from knowing who you are or what your access patterns are.
There is a lot of anonymity value in that.
I have a web site. It's hosted but I full access to the logs. I browsed
my site through Tor and then repeated the same pages with a browser not
configured to use Tor. When done I retrieved the logs. I was using Lynx,
a text only brwoser, that represents less than one tenth of a percent of
the browser market. By searching for the exact version of Lynx, I was
able to find all my page requests both through Tor and not. All that I
did without Tor had my real IP address, and a DNS lookup gives the
reverse address including my ISP's name. Apparently my Tor session lasted more than 20 minutes. The requests were
made from 4 different IP's that had no relation to each other or to me.
It's only because I used a very unusual browser, and surfed my own site,
that I could identify my Tor traffic. If this were anyone else's site
and a common browser, the web operator would not likely relate what in
the logs looked like four short sessions, from four different users. If
the user engaged in consistent activities that violated site policies,
he would have to exert legal pressure on the four separate exit nodes to
get what information they had, and attempt to backtrack through
potentially 12 Tor nodes before he'd have a reasonable chance of getting
to me. Without Tor, the web operator could do a dns lookup in a few seconds,
and after a couple minutes on my providers website, be making a phone
call or writing an email. There is a huge difference. Only if my actions
were entirely legal, and did not violate the website use agreement, or
my ISP Terms of Use, my ISP, depending on the its policies and
attitudes, might/probably would not cooperate with the website operator.
As for the DNS leaks, I think more is being made of this than it
warrants. I'd guess 99%+ Internet users use the DNS sites assigned by
their ISP. When you make such a request nothing about you goes further.
If the name your application is looking up is already in the DNS cache,
the IP is returned directly to you. If not, your ISP's caching server
will need to go to higher level servers, but nothing about you is
included in these requests. If you use only your ISP's DNS servers, only
your ISP can know what locations you are looking up.
BUT your ISP already has total control of all your traffic between your
computer and a Tor entry node. If it's not encrypted (and only a
minority of web pages accept SSL requests) your ISP can read everything
you send or receive, as well as knowing who it's to or where it's from.
Even if it's encrypted Tor traffic, they still know at a minimum the Tor
entry node it's for, and depending on how well the Tor headers are
constructed, may even be able to find the final destination. If they
were specifically watching you and monitoring all your traffic already,
the DNS information would probably do little more than speed the
determination of your final destination.
While most ISP don't do a very good privacy job for their clients, they
also don't want a reputation for abusing their clients privacy because
that will cost them at least some customers. Unless they are operating
under some legal pressure, or responding to an abuse complaint, few are
likely to monitor their customer's routine traffic, and if they do it's
likely to be fully automated and the records kept for only a short time.
They are not required to monitor, and they cannot be asked for records
they do not have. Monitoring exposes them to more legal and financial
risks than not doing so. Of course there is always the possibility of a
rouge employee.
Glymr, I understand why you are leaving, but maybe you will check out
Tor in a year or two when it should be easier to use and more robust. It
looks like a potentially better solution that any of the commercial
privacy services.
George Shaffer

@_date: 2006-10-05 20:33:46
@_author: George Shaffer 
@_subject: Setting up a Tor private network 
I haven't gone very far with this but, yesterday I did get a private Tor
network to work, and I think the documentation makes it confusing and
difficult when it was very easy. Getting the client setup to work was
much harder. Once I had Tor and Privoxy working as a simple client on the computer I
intended to be the Tor server, I only had to change one line in the
Privoxy config. All I did was change listen-address from 127.0.0.1 to
the real IP address of the computer (in this case a NATed private
address). I tried two listen-address lines but that did not work.
Of course to get the local client application to work, I had to switch
it from 127.0.0.1 (or localhost) to the real IP.
Client setup on the remote computer was the same as on a local computer,
except everywhere where you would have 127.0.0.1 (or localhost) you need
to enter the real IP of the computer running Tor and Privoxy. This works
for web browsing with http and https. If you set up a socks client the
port should be 9100 instead of 9050 for a local client.
According to the documentation, for remote access (networking) the Tor
SocksListenAddress should also be set to an external address. I realized
that when I set up tor, I'd included both the localhost and real IP in
two SocksListenAddress lines, as it was my plan from the beginning to
network them.
Anyhow, you need to set up a chain of communication. Starting with a
client application (web browser). The web browser has to send its http
and https requests to Privoxy's listen-address (including port), and if
any client will be on a remote computer then the Privoxy's listen
address must be the computers real IP address (whether it's a public or
NAT address). Privoxy needs to talk to Tor so Privoxy's forward-socks4a
address must match one of Tor's SocksListenAddress. Since Tor allows
multiple SocksListenAddress(es) no changes need to be made to the
default Privoxy forward-socks4a address (unless they are different
computers which does not make much sense).
I have no idea what make-private-tor-network.py does.
This is an info level message and may not be be important in itself,
even though it may be caused by whatever misconfiguration is preventing
your Tor network to not work.
There are some security things you may want to consider. If you are
behind a strong firewall with NAT, you may feel that further measures
are not necessary. If you want a bit of extra security you can control
access to Privoxy and Tor. If for example you are on a NAT network
198.162.111.0, netmask 255.255.255.0 (or approximately 255 potential
hosts), you could add a line in Privoxy config "permit-access
198.162.111.0/24", which would allow all computers on your network to
access Privoxy and no others. If Tor and Privoxy are not on your
(dedicated) firewall (which may be the best place for them) and your
firewall is 198.162.111.1 then deny-access 198.162.111.1/31 (I think 31
is right) would prevent the firewall from accessing Privoxy. This would
be somewhat pointless if your firewall could ssh to the machine Privoxy
was on. On the other hand if your firewall had a web browser (bad idea)
any intruder on your firewall could make anonymous web connections as
you (and retrieve all his tools from his private website). Tor has a
similar but somewhat different scheme for controlling socks access,
documented in the torrc sample file.  Never set any security like this
until you have a system working; then if it breaks when you enable
security, you know you have the security wrong.
Mine is OpenBSD and Linux. The principles should be the same regardless
of system type, though sometimes of course the mechanics can be
maddeningly different. When I'm done, this new OpenBSD machine will be
my firewall, NAT router, and Tor/Privoxy server.
George Shaffer

@_date: 2006-10-07 02:45:24
@_author: George Shaffer 
@_subject: Analyzing TOR-exitnodes for anomalies 
I've read or skimmed the entire thread which seems to have ended midday
Thu, 10-5. Friday morning I clicked on a Cnet newsletter link:
Tor was enabled in Firefox and I got a page almost identical to the one
Alexander posted above, except it it had Cnet.com at the top. At some
subsequent time I copied the URL into an open copy of Firefox, and got a
somewhat similar page, except it had a variety of graphic content that
made the page look much slicker.
I wondered what was going on. Is Cnet blocking anonymous traffic? I
tried a browser not using Tor, and got a normal Cnet page with the
expected content. I then tried three other anonymizing services, The
Cloak, Anonymouse, and HideMyAss with the same URL. All got the same
correct result as the non Tor browser.
While reading this thread, when I saw Alexander's screen capture, I
realized that was just about what I'd seen Friday morning and tried
Firefox with Tor again and saw the expected Cnet page. I've tried
multiple times since, over a couple hours and each time got the right
I am very skeptical of one of the hypotheses, that web hosting services
are blocking Tor access. If a provider did this without an explicit
policy and or informing their customers that this was part of their
practices, they could easily be liable for any lost value for every
hosted site that had any decrease in traffic as a result of such
blocking. Second why would any hosting service care who visited its
clients web sites? Who they want as visitors is and should be a matter
of concern only to the sites' owners. A hosting service might assist a
specific site in blocking some type of unwanted traffic, and charge the
customer for the additional service. In the case of Cnet, they are a rather major Internet content provider
and I expect they run their own servers. Regardless of who manages
Cnet's servers, they are big enough they would expect full control over
any policies that denied access to any visitor. A query from the right
party to the right people at Cnet should answer conclusively whether or
not Cnet has had any part in this. If so then it should be a Tor / EFF
education matter and if not, then some other theory needs to be
considered. After writing this, I think it makes no sense at all. If
Cnet wanted to block someone they would display some kind of error
message or page; they would never redirect someone to a link farm of
unrelated links. It makes zero business sense to send visitors elsewhere
with no explanation.
I have one more theory or more accurately, a guess. When I was testing
to see if tor was working, I visited grc.com to use the "Sheilds Up"
test. If they showed an IP that wasn't mine, then I could be pretty sure
Tor was working. The first time I visited them, I was surprised when
they determined I was behind a proxy and refused to go any further.
Later, I tried again and this time they just determined a different IP
address than mine. I decided to go ahead and do a "Common Port" scan. I
was appalled. The exit node seemed to have all kinds of open ports - a
lot more than I thought would be proxied by Tor. Unfortunately I did not
think to write down the reverse DNS address or the open ports. My thought is that some exit nodes may be compromised without the
operators knowledge. Maintaining good security while running an exit
node does not look like a simple task. I'm reluctant to do more of these
scans because they are an unauthorized port scan against the exit node.
If however I see another of the strange pages discussed in this thread I
will try to capture the page and then quickly do a scan.
George Shaffer

@_date: 2006-10-07 18:53:59
@_author: George Shaffer 
@_subject: tor and its speed 
Glymr suggested using the Fasterfox extentsion. On Wed, 2006-10-04 at 12:18, sigi replied:
Part of the description for Fasterfox states: "Dynamic speed increases
can be obtained with the unique prefetching mechanism, which recycles
idle bandwidth by silently loading and caching all of the links on the
page you are browsing."
Something like this is ideal for a dial-up connection which really does
have periods of idle bandwidth. There you don't slow anyone else down by
using this, though if enough people used such "accelerators," the wasted
bandwidth would have some effect on the net.
On a system that's already slow due to limited _shared_ bandwidth, there
is no idle bandwidth. Prefetching all the links on a page in the hope
that the next one you read will already be ready and waiting for you is
just plain selfish. Every fetched page that you don't look at is totally
wasted bandwidth. You are getting your pages faster, at someone else's
expense. If everyone did this, it would be self-defeating, and the Tor
network would likely become completely unusable. Depending on your
browsing habits, a product like this could increase your total consumed
bandwidth by 2 to 10 times.
Please reconsider using Fasterfox, or any prefetching product, on the
Tor network.
George Shaffer

@_date: 2006-10-10 05:30:37
@_author: George Shaffer 
@_subject: Confused about Tor settings 
I have no idea, but even if it was, it doesn't mean it's solved in Tor. If so, their solution may be directly applicable, but Torpark
does not seem to be making their full source available. I downloaded
their source package, and it had only one medium size source file
and several non text files. I could find no copyright or credits
for any Firefox or Tor developer.
My mistake. You are most likely right regarding the final destination and content. As long as the cryptography is sound, the ISP is unlikely to break it; since Tor requires OpenSSL this should be the case. I did not
understand that the full content of all Tor packets was encrypted, but if
you've been looking at them, I'll take your word.
Regarding the entry node, every TCP (and UDP) packet has to have some destination where it's expected in an IP header. If they don't, routers
would not know what to do with the packet. In the case of Tor packets
leaving the original client, this would be the entry node, not the real George Shaffer
PS Sorry about the lack of headers to thread this properly. My ISP, Comcast,
blocked about 30 messages from Friday afternoon to Sunday afternoon and I
had to get this off the web, and build a reply in a new message.

@_date: 2006-10-19 05:06:45
@_author: George Shaffer 
@_subject: "Practical onion hacking: finding the real address of Tor 
Which they said quite clearly in different words: "Clearly Tor's
designers have done a pretty good job: I couldn't find any weaknesses in
Tor itself . . . So instead, I attacked the data which Tor carries the most of: web
Obviously a number of users are having difficulty configuring or using
Tor correctly. I've been a computer professional, mostly business
software development, but including managing a small IT department for
several years, since 1983. I spent a number of hours reading about Tor
(a lot of the background stuff, not just install instructions) before
installing it. Also I wanted to set it up as a server on my new
firewall. I'm not sure if I have Tor and my browser configured
correctly. All I am sure of is that when Tor is enabled, my IP is
successfully masked at three sites that test this.
For a user new to Tor, the documentation is often confusing or
ambiguous, important information is missing, and sometimes minor details
over emphasized (especially in Tor FAQ). Tor is a young product and
hopefully these problems will be remedied as it grows. In the meantime
though, some users are depending on it for anonymity. You can be sure
that someone in Red China, searching for information his or her
government does not want them to see, is not likely to have mis
configured or misused Tor for want of trying to get it right.
If this is true, then the Tor network serves no useful purpose for the
large majority of users who don't run Tor servers, let alone exit nodes.
Even if in the future, some auditing process is set up for exit nodes,
anyone using Tor, implicitly trusts whoever does the auditing, and he or
she is likely to be self selected. Besides technical knowledge and
connection limitations, there is at least one other valid reason for not
running a Tor server. Comcast, the largest ISP in the U.S., has Terms of
Use that very clearly prohibit any and all servers, including p2p, on
any residential connection. I suspect some other ISPs have similar
Maybe I'm missing something, but except for a large company with many
valid public IP addresses, what anonymity can you hope to gain by using
your own exit node, except hiding from a network sniffer in the clutter
of the other traffic which leaves the node. Whoever you connect to will
still have the exit node's IP, which can presumably traced back to you.
George Shaffer

@_date: 2006-10-21 10:34:45
@_author: George Shaffer 
@_subject: "Practical onion hacking: finding the real address of Tor 
In case you did not notice, I used ellipses (". . ."), the standard
English language notation for omitted content. I considered the part
that I left out an unfounded personal opinion that needed no comment.
Since you seem to want me to address that, I will. For my first comment
the actual title does not matter. You use the word "intentionally" as an
adjective to "misleading." You start with "I also think" so you state
this is opinion, and not necessarily fact, but basically you are saying
that you think the authors are liars. I'm guessing that you have never
met or spoken to the authors, or communicated with them about this prior
to your post. Sometimes it's hard to know our own motives, and harder
still those we know well. In a context like this, we cannot know the
motives of strangers. So you have included an unnecessary pejorative
term with no basis in fact.
The second issue is a matter of fact to be determined. Is the title of
the paper misleading? For that we do need the title. The subtitle is
"Finding the real address of Tor clients." Unless the authors are liars,
and I think they present enough evidence that that is not likely, they
did find 86 addresses in one day. They did exactly what the subtitle
said, so I don't see how it could be misleading.
The main title is "Practical Onion Hacking:" and I expect your point is
that they did not successful hack, crack, or break the Tor software,
which everyone who read the article already knows. I think the first
word "Practical" is important. I have come to expect, that when I see
practical as part of the title of something in any way related to
computer security, not to expect something esoteric, theoretical, or
even necessarily very technical. What I do expect are topics loosely
comparable to social engineering attacks or dumpster diving. These
obviously have no relationship at all to the technical merits of any
software, but they are part of the black hat arsenal.
If the main title had simply been "Onion Hacking" or "Onion Cracking,"
you would have a point about it being misleading. I think the preface of
"Practical" is the right qualifier to indicate the authors are not
making a head on attack against Tor. I've already seen and considered
the title, which makes it impossible to be fresh or original, but having
seen it, I cannot think of a better title. Thus, I believe you are
mistaken to call the title misleading.
Paul Syverson posted an informative article to this thread, at least to
someone new to Tor like myself. Apparently the people at FortConsult,
who represent themselves as IT security experts, are repeating work that
has been done in the past, without knowledge and or acknowledgment of
this previous work. That is something it is reasonable to be unhappy
about, but nothing in Fabian Keil's post that I responded to said
anything like that. He did say it was "nothing new" but with no
elaboration or explanation that would help anyone not intimately
familiar with the project, understand what he was referring to.
I've reread it multiple times, and while it may be complex or even
awkward, I believe I said what I meant and meant what I said. To
rephrase it, those referred to are highly likely to make every effort
they can to get it right, and still some are failing.
But products also vary greatly in how easy or hard they are to install
and or use, as well as the quality of their documentation. The EEF warns
that Tor is an "advanced" topic, i.e., not one for the technically
unsophisticated. While Tor is easy to use once set up, it is definitely
nearer the hard than easy end of installs. After it was installed there
were at least a couple of places where I said to myself, oh now I see
what they mean. The documentation, though abundant, leaves much to be
desired. Unfortunately that is normally true of resource limited, young
projects. It's also unfortunate that there is not likely any correlation
between the need for anonymity and computer expertise.
Haven't the authors of the report that you seem to object to so much
made a dramatic demonstration of this. The products you mention are used
by many content providers, and many web surfers, even knowledgeable
ones, like the "rich" experience and are willing to sacrifice security
and privacy for it. As I was completely unaware of any of the work Paul
Syverson referred to, this report got my attention much more effectively
than the documentation I had seen. To me there is a big difference
between simply stating something can be a problem, and a demonstration
of actual compromises. If any of these older demonstrations are
available online, then perhaps at least some of the references to
applications or products that can compromise the use of Tor should link
to them. If however, this older work remains only in the institutional
memory of those closely associated with the Onion Routing project(s), or
in off-line hard copy, for all practical purposes, the FortConsult
report is new material.
We seem to have different ideas about trust. I generally avoid any
security or privacy product I don't trust. If you mean we have to assume
that some (hopefully small) percentage of exit nodes are compromised,
but that the likely (large) majority of good nodes, outweigh the risks,
then we may agree.
I found a number of dedicated hosting solutions where you rent a
dedicated server associated with "root server." These start at $99 per
month. If I had that kind of money to spare, I think it would be better
spent in direct contributions to EFF.org. Also, anonymity needs are not likely to correlate with disposable
income. If anything, an inverse correlation is likely. The poor are much
more likely to be engaged in unpopular or anti establishment political
activities than the well to do. I'm stunned anyone would make such a suggestion. Only someone already
highly committed  to Tor would ever consider the time and expense of
such an approach; there is a world of difference between changing a
configuration option, if you have the bandwidth and your ISP allows it,
and what you suggest. Tor needs a mass of users and servers to succeed.
According to the graphs, servers are doubling annually. Trying to make
Tor users without a server feel like second class citizens or simply
unwanted, is a sure route to failure.
There is another reason for not running a Tor server even if my ISP
allowed it. I have a dedicated "stealth" firewall (protecting a personal
desktop with little of intrinsic value). There is no chance I would poke
holes in its configuration. That leaves only adding an additional
machine, outside the firewall in a DMZ. Even if I had sufficient
hardware, and was willing to deal with the routing issues, I'm not sure
that I'd want a computer that announces the presence of a live computer
at my IP address. When I put my security and privacy concerns together,
I'd rather give up Tor than my current security configuration.
There are also the potential legal issues which EFF addresses. In effect
they say they may try to help you if you run into legal problems running
a Tor server, but are more likely to help you assess the situation and
find a lawyer. Engaging quality legal representation to defend against a
serious legal challenge could easily bankrupt a middle income household.
George Shaffer

@_date: 2006-10-24 12:34:15
@_author: George Shaffer 
@_subject: "Practical onion hacking: finding the real address of Tor 
Fabian, there is no point in any further response to most of what you
are saying. We seem to be going in circles.
If a member of your family is sick with a contagious disease, and you
tend to them, do you "deserve" to get the disease? It might be smarter
to stay away and call a doctor, but perhaps you get infected before you
knew a doctor was needed, or while waiting for the doctor, or can't
afford a doctor.
That would depend on how well you understood how Tor works, and more
generally your understanding of computers, which to most people are
pretty much a mystery.
Are you sure? By "stealth" I mean a firewall that drops packets on
blocked ports (and ICMP) and returns no packets, regardless of whether
probing packets are properly formed or deliberately misformed. A scanner
(at least theoretically) gets exactly the same response as from a
computer that is turned off. This only works if every single port and
ICMP are blocked (stealth). A single open, or closed port, will reveal
unequivocally to a port scan that there is a working computer at the
target IP address. No sane attacker will devote additional resources to
an IP that appears to be off or disconnected, unless they have
independent reason to believe a working computer is actually at the
probed IP.
One might conclude, if one assumed these couple smart alec remarks
represented your entire knowledge of firewalls, that you don't seem to
know that once you open a port in a firewall to a server, e.g., Tor and
port 80, that the firewall cannot protect that server.
It's not that I don't trust my firewall, I just don't want to invite
random attacks, because a broad probe of many port 80s, happens to find
an open one on my machine. I hope you're not suggesting Packet Filter on
OpenBSD does not work.
Now that I've already told you something about my system, if you think
you are smart or knowledgeable enough to get past my firewall, I'll be
glad to give you permission to try. Just contact me out of this list,
and I'll work out terms (e.g., no deliberate destruction, one month
limit). If you succeed, I'll admit it publicly in this list. I would not dream of making such a challenge if I were running a Tor
node, because that would mean at least one open port, to a piece of
software running in the background, of which I have no internal
understanding. A minimal Tor node configuration would require allowing
inbound traffic on port 80. I do know such a port shows as open on an
exit node (and likely all active nodes). (Recently when I again got unexpected content as was discussed in a
recent thread, I scanned the Tor exit node from grc.com, and both 80 and
443 showed as open, where the others showed as stealth. This means Tor
is responding, even though the incoming packet is not a Tor packet.
Other explanations? I did not write down the IP, and have no knowledge
of the OS or firewall in use on that exit node.) Either way though, packets are now sent from the Tor node system that
can be fingerprinted to determine the OS, version, and some other facts
about the OS running the Tor node and possibly firewall. A port scanner
will quickly show other ports as blocked. The attacker can't immediately
know if the open service is on the firewall machine or being passed to a
machine behind the firewall. A careful packet analysis may reveal this.
the probable firewall running on that system, and if so possibly launch
a focused attack. Alternatively, the attacker can focus directly on the
open port 80.
All this from someone doing random scans for an open port 80. Before the
scan they probably would have not known the IP was in use. Now they have
much of what they need to try to attack the system.
There is also the Tor directory which I had not thought about
previously. This also announces the presence of tor nodes when before
these nodes were private, and depending on their local security, more or
less, well hidden. Does Tor have any buffer overflows that can be exploited? I surely don't
know. And no, I am not running Tor as root, but that still does not mean
someone could not make a nuisance of themselves. Perhaps Tor can be
crashed remotely. If so, an attacker might arbitrarily crash Tor every
one to six hours. This could be automated. Every so often I'd have to
troubleshoot to figure out why I could not connect with Tor. Any circuit
passing through the node would be disrupted.
I could put Tor on an individual client rather than the firewall. Then I
have to set up Tor on each client I might want to use. With port 80 (and
maybe 443) open on the firewall, then malicious traffic can go right to
my client computer. Of course I have to also open these ports on the
local computer firewall as well, if it's to serve as a Tor node. All
this is avoided if I don't run a server, but only a client. Then both
firewalls can allow only outgoing packets with stateful inspection, and
block all incoming traffic not in response to an outgoing request.
The simple fact is that anyplace you have no public (accessible by the
outside) services, your security must be weakened, if you add a Tor node
anywhere in your local computing environment. This is especially true
since Tor is developmental software. It's not like core pieces of the
open source OSs, or big projects like Perl or Apache, where many pairs
of knowledgeable eyes are likely to have reviewed the code over years.
TOR as a server runs on hundreds, rather than tens of thousands to
millions of computers, so it is not likely to have (yet) attracted much
malicious scrutiny. Once a single malicious attacker decides to focus on
Tor, he can get the source code to help him, but the Tor community does
not have the resources to find a quick solution, the way the large open
source communities do.
I happen to know a little about computers, security, and firewalls. If
you doubt it see  This has not been actively
maintained recently, but the Hardening OpenBSD and Password areas still
get a good bit of traffic. The firewall section in Hardening OpenBSD
should answer if I understand firewalls, and how to configure them. When
I say "know a little" I mean that literally. There are thousands of
books in print (just in English) on computers, many highly technical.
Those who can honestly claim to know a lot about computers are rare.
Fabian, there is something unpleasant in your attitude: those who make
different choices than you, are not as smart or knowledgeable, or simply
write something you think you can ridicule ("get what they deserve",
"just thinking about it would make it clear", "if you can't trust your
firewall", "get a firewall that actually works") all suffer your scorn.
Just because you apparently know something about Tor, and maybe
networking and cryptography, is no excuse to put down those who may know
George Shaffer

@_date: 2006-10-27 07:27:42
@_author: George Shaffer 
@_subject: "Practical onion hacking: finding the real address of Tor 
It may have been a poor analogy (I was thinking of computer viruses
which suggested disease) but my objection is to the use of the word
"deserve."  Let's try a different one: people who leave their house
doors unlocked don't deserve to be robbed or raped and people who leave
their cars unlocked don't deserve to have their cars stolen. In each
case the poor security increases the risk of the undesired results, but
does not make these results likely.
Failure to take good browser and system security precautions does not
result in "constant" adverse results. I know two computer professionals,
both of whom use Windows and have had high speed Internet connections
for the past five years. The only precaution either takes is they are
behind a NAT router (and may run an antivirus program). They have
everything enabled in their IE browsers. Neither has ever experienced
any disruptive experience, thought they may well have some adware or
innocuous virus on their system.
What is so often forgotten about malicious web attacks is that nearly
all web operators have a large investment in their sites and malicious
software hurts them as much or more as victim client computers. To go to
a malicious site you need to encounter a site whose security has been
compromised, be tricked into going to a site, be the victim of poisoned
DNS, receive an email with a macro based Outlook virus that uses IE
functionality, or deliberately browse fringe web sites. All can and do
have adverse consequences, but are not a common part of most surfer's
experiences. People who deserve to have bad things happen to them are criminals who
are justly convicted.
By unused to you mean unassigned or will simply turned off result in
such a message? I don't have enough computers to test this and know of
no legal way to do so. I guess I have to take your word, though I've
never heard this before. Perhaps someone could provide a URL that
describes this.
While I'm generally familiar with most of your points, and the one about
a firewall only allowing valid packets is a good one, in the context of
this discussion, your final sentence grates. Perhaps this comes from the
way German translates to English, but it would be much easier to read
"If you are not familiar with, then you should look up systrace" rather
than saying "you will be aware of." If I ever knew it I've completely
forgotten it. Looking at man, it does appear that it would be useful for
controlling "developmental" software on a very secure OpenBSD system.
The last time I checked, my recollection is that there are more than 600
commands on a minimal OpenBSD install, i.e., without misc, games or any
of the X window components. Very few people will know all of them. The
man pages are mostly quite good if you know the name of a command (or
can find it with "-k") but there is no overview how-to documentation
with OpenBSD that ties things together into logical task groups. My
phrasing is a helpful suggestion whether or not I know systrace, where
yours becomes an insult if I do not, by implying that I ought to know
No but you did say "get a firewall that actually works anyway." I
thought perhaps if you thought my firewall didn't work, that you might
think I had an easy system to crack.
You are right about the OS. Opening port 80 when no web or other server
is running still shows the port as open. Still, I don't care about
"major" problems, I don't want any additional problems, even what you
might think are minor ones.
I'm not saying I expect any attack to succeed. The point I've tried to
make more than once, that you seem to disagree with to the point that
you basically ignore it, is that I do not want to do anything to attract
any random or anonymous attack. I think I have an unusually high degree
of security relative to what I have to protect, but I don't wish to find
out that I'm wrong. My OpenBSD firewall is not current, but I don't
believe there are any kernel or firewall bugs relevant to my
configuration. My Linux desktop is up-to-date with patches.
Not all bugs are found first by the good guys. Occasionally bugs are not
revealed until systems are successfully compromised; with proprietary
systems this is normally the case. Even when the good guys find the bugs
first, which is most often the case with open source systems, there is
some lag between discovery, which usually but not always means the bug
has become public knowledge, and the time it takes for the developers to
find, fix, and make available patches. Then depending on your update
practices you may introduce additional delays.
The best that you can possibly be is fully up-to-date with your system's
patch level. If you are, you will be much better off than most
computers, including many commercial servers. This does not mean your
system has no exploitable vulnerabilities, but hopefully any crackers
with the skill to find and exploit such vulnerabilities will focus on
systems where there will be some real reward and not on individual home
And as I said before, if I had the funds to run a dedicated server, I'd
contribute them directly to tor.eff.org, where I think they would do
more good. I'd never go the expense and time of running a dedicated Tor
server. Second, I doubt that less than 1% of the existing Tor servers
are dedicated Tor servers run by individuals. I expect that nearly all
Tor servers fall into one of two groups: 1) organizations that have
excess bandwidth and server capacity, or an older unused PC that could
be set up as a dedicated server, and believe that Tor is simply worth
supporting, or might provide value to the organization. One of the great
things about all the open source systems is that the life of a PC can be
extended by several years as a dedicated server, for modest demand
applications. 2) Individuals with good bandwidth connections, who feel a
desire or obligation to support Tor with a server, and can do so by
simply changing one or more configuration options. Here their interest
in Tor overrides any security concerns they may have, or they may not be
aware of any security issues, or consider them insignificant.
I've spent far more time with Tor than I ever expected to when I
started. If I considered only cost benefit, I'd conclude my best course
would be to remove or disable Tor and forget it. I've used it very
little after I got it to work, because it is simply too slow most of the
time (though sometimes it's quite reasonable). I've seen someone on this
list say this is a minor issue; I'd strongly disagree. I'd expect for
the average non technical user it is the single most important Tor
issue, after installation and setup issues.
I'm sticking with it because it is intellectually one of the most
interesting software projects I've encountered in a long time. In theory
at least it is a very elegant solution to an important network need. I
think with the direction governments and businesses are going, the need
for Tor or a comparable product will only grow. I don't think the single
server commercial services are an adequate answer. So I really hope Tor
succeeds, but I expect to stay mostly on the sidelines as a watcher and
occasionally a user.
Fabian, please make this the last time you suggest that I run a Tor
server whether locally or hosted. This is the third time you've
suggested that I run a server and the third time I said I'm not going
Coderman raised the last point two days before you did, and after I
reconsidered what I wrote, I agreed with him 10 hours before you posted
this. How about reading the current posts before responding?
I disagree with the previous point. The ONLY attacks the firewall does
NOT protect the client from are man in the middle attacks, where the
attacker is able to alter the Tor packets so that they remain valid IP
packets and the packet "state" is maintained, i.e., that the firewall
sees the altered packet as a response to a previously sent request. In
contrast, unless the firewall rules are regularly manually updated to
restrict incoming packets to all valid Tor nodes, the ONLY attacks the
firewall CAN protect a Tor server from are malformed TCP packets.
Firewalls generally don't, and none that I've used, assure valid packets
for specific applications or protocols. This may be true sometime in the
future, but to-date, to the best of my knowledge, only specialized
proxies provide application level packet integrity checking. In other words, only computers on the Tor packets path, or with access
to the cable over which the packets are being passed, can launch a very
specific type of attack on a Tor client behind one or more stateful
firewalls. Without a large amount of ongoing administrative work, any
computer on the Internet can exploit any vulnerability which may be
found in the Tor software when it runs in server mode and the
firewall(s) allow access to it.
George Shaffer

@_date: 2006-10-27 07:43:52
@_author: George Shaffer 
@_subject: Sending mail on OS X 
I understand the need for controlling spam. If you don't control it, the
recipients will often block you. Even if you're not blocked no
legitimate organization or tool wants to be identified as supporting or
enabling spam.
The Mixminion project seems to be stalled, as they have not released any
new software in almost 11 months, even though it is described as alpha
In the Overview of Tor,  the "Why we
need Tor" section states "It can even threaten your job and physical
safety by revealing who and where you are. For example, if you're
traveling abroad and you connect to your employer's computers to check
or send mail, you can inadvertently reveal your national origin and
professional affiliation to anyone observing the network, even if the
connection is encrypted." The same logic would apply to any military or
government employees, dependent on local communications.
The "Tor: The Second-Generation Onion Router" design document
 mentions
using SpamAssassin in section "6.2 Exit policies and abuse" on Tor exit
I'm curious if the current default on exit nodes to block port 25 is a
temporary expedient due to the very limited resources available to the
Tor project? Do the developers hope at some point to be in a position to
enable anonymous email through the Tor network, either by blocking
individual spam messages at the exit, or blocking spam sources by IP
address from the entry nodes? The latter should involve a much lower
overhead, but at the risk of blocking legitimate users. Perhaps blocking
only the better known, high volume spam sites would substantially reduce
the load on the Tor network while minimizing the impact on legitimate
George Shaffer

@_date: 2006-10-31 06:19:50
@_author: George Shaffer 
@_subject: reporter from The Economist in Thailand seeks help / new Tor 
Continuing now OT thread:
Lynx has its uses, but anyone used to modern browsers is likely to find
it frustrating. Lynx is not just text only in that it does not display
graphics but is text based and runs in a text window (terminal). It does
not recognize tables, and most modern web pages are built in tables,
allowing the standard page and navigation elements, to be arranged above
or to the left of the main page content. This means as you read the
source, these come before the main text content. That is how Lynx
displays the page (as it is sequentially arranged in the source file) ;
the main page content is usually between a screenful or more of standard
items and links and more of this at the bottom. A page as simple as
Google's home page takes 13 tabs or down arrows to reach the search
field. Yahoo, on the other hand recognizes it has received a request
from a text browser, and sends a different page where the search field
is the first item on the page after "Yahoo". Lynx takes some getting
used to.
Lynx is not simple. It's default configuration file is 140K, but mostly
explanatory comments. It has about 135 options. I don't know that you
can assume it's 100% safe. If you eliminate all active content from your
current browser, or install an alternate browser (e.g., Netscape, Opera)
and disable all active content, and severely control cookies, wouldn't
that do what Lynx is intended to do while still seeing most web pages,
more or less as intended?
George Shaffer

@_date: 2006-10-31 07:42:53
@_author: George Shaffer 
@_subject: Lynx and links: was Re: reporter from The Economist in Thailand 
More OT: I was simply commenting on the text browser being discussed,
lynx. links, aka elinks, is clearly better than lynx and eliminates most
of the problems I mentioned. I'm still not sure why a GUI browser, with
all active content disabled and a good cookie policy isn't generally
better though. I am not anti text browsers. In fact I developed my
website,  to work with lynx (before links was
available) and every browser I could test with. lynx and not links comes
with OpenBSD. If links comes with your system, then it would be faster
than configuring a second GUI browser (or setting up an alternate
Firefox profile). Be sure to disable cookie saving because links default
is to accept and save all cookies. All cookies will then act as session
cookies. ('o' for options, highlight "Cookies", press spacebar,
highlight "Saving", Edit, change 1 to 0, OK, Save)
George Shaffer.

@_date: 2007-01-03 12:21:54
@_author: George Shaffer 
@_subject: Opening 2 Firefox profiles 
It may be easy on your system but not mine. I've read this works on
Windows. My experience is that it does not on Linux.
I've used -ProfileManager with firefox on the path, with the entire
explicit path to firefox, and switching to the firefox directory and
using ./firefox. I've tried this on Linux, CentOS 3.3 and 4.4, which
should be functionally identical to Red Hat Enterprise Linux 3.3 and
4.4. I've even cut and pasted -ProfileManager from the Firefox Help: How
To Manage Profiles page to assure I was spelling and capitalizing it
correctly. The 3.3 system is much older but fully patched. The
-Profilemanager switch has never worked once any Firefox window is open.
On the 3.3 system, I have three quite different profiles, including one
specific to Tor, that I can switch between, but I've never succeeded in
opening two Firefox windows using different profiles at the same time.
If there is anyone who has solved this problem on a similar **Linux**
system, I'd like to know how.
Thank you,
George Shaffer

@_date: 2007-01-03 15:32:47
@_author: George Shaffer 
@_subject: Opening 2 Firefox profiles 
Interesting. As a variety of sources have said "Linux is not an
operating system," it's kernel, and there are many incompatibilities
between various distributions.
The "Don't ask at startup" box in the profile manager dialog is NOT
checked, so it comes up each time I open a window, provided no other
window is already open. When I made the second profile I experimented
and checked the box. With it checked Firefox would always start with the
selected profile and not show the profile manager dialog. The
-ProfileManager switch, would force the profile manager dialog to
display, provided no other Firefox windows were already open. I'm not
aware any other related boxes, not on the dialog itself, but if there is
one that could be the problem.
George Shaffer

@_date: 2007-01-03 16:10:53
@_author: George Shaffer 
@_subject: Question for Job and others 
That was my suspicion.
I didn't think spam was an issue.
This suggests to me some form of counseling or surveying as
possibilities. Whether it's along these lines or something else, what
you say suggests that you probably want privacy even more than
anonymity, though you may not have thought of these as separate.
Specifically I'm thinking of encryption via GnuPG or PGP. If a family
member or boss has access to your client's computer and can read your
communications, that might be more damaging to your clients than being
able to find out who you are.
Tor will encrypt your emails up to the exit node, but if you send your
emails as plain text, i.e., unencrypted, the exit node operator and any
administrator between the exit node and your client's computer could
theoretically read your emails. There is software designed to grab email
(and other content) off any transmission media, and make it readable in
real time. If your client sent any reply or information to you without
Tor and or encryption it could be readable anywhere on the return path,
and from the Tor exit node on if sent by Tor but not encrypted.
If you and your clients both used encrypted email, they would not need
to delete your emails immediately after reading them. If they did not
have their email client remember their password for the "current
session" or were careful always to close the email client anytime they
left their computer, no one who did not know their GnuPG password or
pass phrase could ever read your email. A technically inclined person
with access to your client's computer might be able to read the email
headers outside of the email program, but not any of the message
"Clients" typically implies some form of payment. Pay Pal may provide
for anonymous payments; I have no idea. If not, virtually any other form
of payment would require your clients to know something about you that
would be traceable. Even with an arbitrary company name at a P.O. Box,
at least in the U.S. there are public records that allow business owners
to be traced.
Also, before I dealt with someone who claimed to be any form of
psychologist, I'd want proof and identification. Encryptions allows
identification documents to be digitally photographed, scanned, or video
taped, and sent securely.
Encryption very much furthers the goals you indicate, but cannot be used
without the active cooperation of the recipient, so it cannot be used to
harass someone else. At any point the recipient did not wish to see
further emails from you, he or she would merely need to delete your
public key from their key ring and they would not be able to read your
messages. They could delete them or save them unread until a suitable
time. Though setting up encryption requires a moderate effort on your
clients part, if the information is as sensitive as you suggest, I'd
think your clients would want to take advantage of this.
This suggests to me that you want the clients to make the initial
contact. Perhaps you have, or will have, a website that describes you
and your services. I know I certainly would not trust, or reveal any
sensitive information, to someone who contacted me anonymously, and who
I cold not track down to verify who they were. If you and your clients
did not use encryption (with good passwords or phrases) and a client
made the mistake of saving the emails to and from you, this could cause
a problem. If the client went on a business trip without the PC, a
spouse or boss could read these and then impersonate the client. If the
spouse of boss were clever it's unlikely you would detect the deception.
It is. Since I've been reading this list I've learned a lot about
anonymity and privacy that go beyond pure Tor issues.
George Shaffer

@_date: 2007-01-03 16:16:37
@_author: George Shaffer 
@_subject: Question for Job and others / was: Re: Tor and Thunderbird: 
I understand the implications of revealing your IP address. That was not
what my question was really about. I said "Job, can you explain, in an
abstract manner, why it is important to you to send emails where the
recipient has no way to identify you, but you do not care about your ISP
or independent email provider being aware of your other activities,
except when you are contacting these special recipients, when you will
be using Tor?" What I found odd and was asking about was why Job was concerned that the
recipient of his email be unable to see his IP, when he said "I understand my ISP and mail.com will be able to trace me but not
receivers of emails as I am not sending any at that moment." which tends
to reverse the normal privacy concerns. Without the originating IP it's
essentially impossible to identify the ISP of an email sender, and the
ISP of the sender is likely to take meaningful action if the sender sent
really harassing or offensive emails or emails which violated the ISP's
terms of service. To me this looked like someone looking for a way to
send email, most privacy advocates would be uncomfortable defending.
Generally I think of email exchanges as mostly friendly or at least
informative. If the sender does not want the recipient (as opposed to
prying governments, ISPs, or other businesses that collect personal
information) to know who he or she is, that suggests some form of
unpleasantness may be involved.
Pretty much right. Since I thought Job might be looking for a way to
send harassing or similar emails I thought this was worth mentioning. An
annoying or mildly harassing email that otherwise might be perfectly
legal, may now, in the US, become illegal simply because the sender
attempts to hide his or her identity. I did not say I agreed with the
law or that it would be enforced in most circumstances. The FBI has and
will get involved when an email makes physical threats and appears to
have crossed state lines. Using Tor almost guarantees the latter.
Traditional investigative techniques are much more likely to be
productive in such a case, than trying to trace Tor's routing.
George Shaffer

@_date: 2007-01-04 17:21:37
@_author: George Shaffer 
@_subject: Good reasons to use Tor etc. 
This response, like nearly every other one, conveniently ignored that I
mentioned "repressive governments (and other non-benign powerful
organizations)" and other reasons I cited for using Tor. Like most mail
lists, Usenet, and open Internet forums, people see something they don't
like or understand, ignore the context of the whole message and
preceding messages, and find a convenient excuse to launch a broad
attack against some other poster who supposedly lacks the "ability to
think critically."
To no avail, I tried to give good reasons for using Tor before I asked
my specific question, which was why Job did not want the recipient of
his Tor emails to have his IP, when he did not care about his ISP or
independent email provider having this, provided they could not link his
IP to the anonymous Tor messages.
The biggest irony in this thread, is the person whose motives I
questioned, was the only one who actually read and responded to what I
said. On reading his answer, I suggested that he consider GnuPG or PGP,
in lieu of or together with Tor, as a possibly better means of
accomplishing his specific purposes.
George Shaffer
