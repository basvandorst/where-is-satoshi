
@_date: 2008-03-31 22:49:05
@_author: Lucky Greeen 
@_subject: clock jump in 0.2.0.23-rc, too 
If  you are using a dual-core or multiprocessor system, it is likely
that you too are experiencing issues with the TSC being out of syc
between the cores. The TSC counters on physical CPUs can get out of sync
just as CPUs on virtual CPUs can. Physical CPUs just experience this
issue so rarely that the most users will never encounter it. The
likelihood that the TSCs between two cores on the same system get out of
sync appears to be system/motherboard/CPU dependent.
See  on the rationale for adding the
"notsc" option to the Linux kernel. Also see
 for a detailed explanation by an AMD
engieer of why and under which conditions the TSCs might go out of sync.
At least in the past FreeBSD was also impacted by TSCs getting out of
sync, causing the time to jump as the the process migrates between CPUs.
There is a very simple way for you to test if the time jumps you have
been seeing are caused by the TSCs between two CPU cores being out of
sync: simply temporarily disable SMP in your kernel. If the problem goes
away, the TSCs likely are out of sync. If so, you may want to find out
of there is a way to disable FreeBSD's use of the TSC similar to the
"notsc" option in Linux and see if that addresses the problem.
--Lucky Green

@_date: 2008-03-31 20:44:25
@_author: Lucky Greeen 
@_subject: "Your system clock just jumped" on Debian+VMware ESX 
============================== START ==============================
How to fix this issue
After extensive testing, I have been able to confirm that the following
fix will put an end to the clock jump errors when using Debian Etch on
VMware ESX: simply add "notsc" to your kernel line in /boot/grub/menu.lst
Example Before
"kernel /vmlinuz--2.6.22-4-amd64 root=/dev/hda1 ro notsc"
I have not seen any adverse effects from this change.
Likely Root Cause
Current Linux kernels use the CPU's "Time Stamp Counter" (TSC) to
determine the time as returned by gettimeofday(). Tor uses
gettimeofday() to determine the age of a circuit. If multiple virtual
CPUs are allocated to the guest OS, the TSC of the virtual CPUs can get
wildly out of sync. As the OS switches the Tor process from one virtual
CPU to the other, the time returned by gettimeofday() will diverge
Note that this is not an issue for processes that do not use the TSC to
determine time. You will not see the jumps running "date" in a loop.
For the error to occur the process has to migrate between CPUs. You will
therefore not encounter this error on uniprocessor systems.
How to not fix this issue
Most articles online that are covering issues with the clock in VMware
guest operating systems will tell you to sync the time in the guest OS
with the host, recommend you install ntp in the guest, implore you not
to install ntp in the guest, or advise you to add "clock=pit nosmp
noapci nolapci" to your grub kernel line. Of all those recommendations,
all but the latter concern themselves with clock drift, having no effect
on the clock jumps discussed here. Adding "clock=pit nosmp noapci
nolapci" will in fact prevent the clock jumps for the simple reason that
it turns your multiprocessor VM into a uniprocessor VM. Probably not
what you had in mind.
In addition to Tor, the popular IMAP server dovecot experiences the
exact same issues when installed on a multi-processor guest OS on top of
a VMware ESX host.
Adding "notsc" to the kernel line in menu.lst resolves this issue for
both Tor and dovecot.
In several weeks of operation, I have not seen any adverse effects from
disabling the use of the TSC on either my Tor or IMAP servers.
Hope this helps,
--Lucky Green

@_date: 2008-02-27 21:14:51
@_author: Lucky Green 
@_subject: "Your system clock just jumped" on Debian+VMware ESX 
I am seeing the following errors in the Tor log:
Feb 28 04:54:43.008 [notice] Your system clock just jumped 4398 seconds
backward; assuming established circuits no longer work.
Feb 28 04:54:46.020 [notice] Your system clock just jumped 4399 seconds
forward; assuming established circuits no longer work.
Tor version:
Tor v0.2.0.20-rc (r13715)
Standard Debian package
Guest OS:
Debian etch
Kernel 2.6.22-4-amd64
Host OS:
VMware ESX 3.5
VMware Tools installed
ntp is installed on the guest. ntpq -p shows a solid lock.
I recognize that there have been long-standing issues with system time
on VMware Workstation. Though I don't believe this is the case on ESX,
certainly not with VMware Tools installed.
I ran another Tor test server on this very same ESX host (though
different VM) for a couple of weeks earlier this year without issues.
Does anybody here have a suggestion how to determine root cause?
--Lucky Green

@_date: 2008-02-28 20:23:47
@_author: Lucky Green 
@_subject: "Your system clock just jumped" on Debian+VMware ESX 
Thank you all for your good advice!
I tried several potential fixes. Unfortunately none of them worked.
What I tried so far:
1) removed ntp from the guest
2) Enabled time sync from the guest to the host using "vmware-guest
--cmd "vmx.set_options synctime 0 1" (which, unlike editing the .vmx
file by hand is permanent)
3) verified that the ESX host has the correct time with ntp enabled and
is shown as being in the correct time zone.
4) verified that the hardware clock on both host and guest are set correctly
5) Scoured the VMware forums for advice. I see evidence of drifts, but
not of jumps.
I continue to see Tor report errors of jumps in the system time from
4397-4399 seconds. Strangely, this jump in time does not appear to be
reflected in the time stamp that Tor assigns to the error message.
What I have not yet tried:
I have not tried setting clocksource=pitt and similar grub modifications
suggested in the VMware forums. I don't see how such changes could help
in this case. We are not talking about a slow drift. We are talking
about (supposed) system clocks jumps of over an hour only minutes apart.
Suggestions for next steps would be much appreciated.

@_date: 2008-11-10 22:22:35
@_author: Lucky Green 
@_subject: Problems runing Tor on Vista x64 
The venerable Dr. Watson chose to enter well-deserved retirement with
the release of Vista. The good doctor's successor is WinDbg.  Both
64-bit and 32-bit versions can be found at:
Users of Windows XP, 2000, and even NT4 are equally encouraged to let
the good doctor rest by installing the tools found at the above URL.

@_date: 2008-09-09 17:02:52
@_author: Lucky Green 
@_subject: Reduced Tor Traffic [was: Re: peculiar server...] 
I am very much looking forward to more diagnostic instrumentation in the
Tor network. I am seeing a 30% difference in the traffic through
basically identical servers that are neither bandwidth nor CPU limited
with identical uptimes. Something about the path selection appears to
lead to favor one server over another.
Also interesting to me is the overall reduced amount of traffic over the
last few months that I have been seeing with my middleman nodes. The
most likely explanation is that the overall Tor network capacity is exit
node bound and that middleman nodes have grown disproportionately over
time. Still, it sure would be nice to be able to perform rigorous
analysis on the network.

@_date: 2008-09-11 23:11:53
@_author: Lucky Green 
@_subject: invitation to directory server operators 
I too didn't even know the option existed. I must have missed the announcement in the release notes that we should enable this feature back when it was added. Anyway, added now.
Wonder what other features have been added to Tor that I should enable.

@_date: 2009-11-22 21:29:58
@_author: Lucky Green 
@_subject: The Case for Banning Reduced Hop Count Implementations 
I have followed various discussions lately about the creation of reduced
hop Tor clients that implement fewer than the three hops considered by
Tor's design. Such clients represent an attack on Tor as a whole.
Indeed, defenses against reduced hop clients leveraging the Tor network
should be built into Tor's design to defend against this attack.
Today and for the foreseeable future, Tor's network latency relates to
the maximum latency that Tor users are willing to accept. As Tor gets
faster, it attracts more users and more traffic, which in turn increases
latency. As the Tor network increases in latency, it loses users for
whom the latency becomes unacceptably high.
Latency in turn relates to the number of hops. The more hops, the higher
the latency. Which not coincidentally is why some with lower anonymity
requirements may prefer fewer hops. Here is the catch: as traffic from
those with lower anonymity and hop requirements increases, it drives the
latency of three hop connections above the latency acceptable for those
seeking higher anonymity. The end state, if lower than three hop
implementations are permitted to use the Tor network, is that Tor's
network performance will acceptable only to users of lower hop clients.
This fact alone drives a need to block reduced hop clients from the
network. But it gets worse.
Many of those that would be satisfied with fewer hops engage in
comparatively low risk behavior (which is why they are satisfied with
lower anonymity), such as downloading large files of questionable
origin. The protocols commonly used for such downloads can accept higher
latency than the interactive protocols needed by the part of the user
population seeking higher anonymity levels. Pushing the latency of three
hop clients farther out of the usability envelope.
Though the above is more than sufficient cause to block reduced hop
clients from corrupting the Tor network, it deserves mention that single
hop clients in particular remove the protection that Tor's design until
now afforded to exit node operators. If only three hop clients can use
the Tor network, the Tor exit node operator can be confident that
capture of an exit hop's connection log will fail to provide the
attacker with useful tracking information. This discourages both legal
and illegal attacks on Tor exit hops and thus increases the overall
number and capacity of Tor exits.
Removing this protection will lead to an increase in attacks on exit
hops, which in turn will lead to decreased exit capacity. Further
negatively impacting Tor network latency.
In summary, reduced hop clients are deleterious to Tor a whole and users
with the level of anonymity that Tor was design to provide in
particular. Users with lower anonymity needs should be guided towards
the many other systems available today that provide lower anonymity than
Most importantly, Tor should implement a (potentially blinded) hop
verification that ensures that lower hop count clients cannot abuse the
Tor network.
--Lucky Green
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2009-10-06 04:02:15
@_author: Lucky Green 
@_subject: Your system clock just jumped 130 seconds forward; assuming 
See my post for a possible fix:
Note that the TCS timer issues in the above post can happen on any multicore system, not just under VMware.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-12-06 11:43:24
@_author: Lucky Green 
@_subject: Relay flooding, confirmation, HS's, default relay, web of trust 
The Web of Trust (WoT) concept provides for marginal security benefits
and then only in a very narrow set of circumstances that are unlikely to
hold true for the larger community of Tor node operators.
Starting with the second point, the WoT concept presumes that trust
between its members precedes the codification of that trust into
attestations attached to digital certificates.
In other words, the WoT might provide (but likely will not) security
benefits to a group of users that have pre-existing social relations and
trust. For example, members of a human rights group that have personally
known each other, or at least the bulk of each other, for years.
The WoT cannot provide security benefits to a group of users with no
pre-existing social trust relationship, such as the set of "Tor node
operators". The thousands of Tor node operators, a tiny percentage of
which have an existing social relationship, have no inherent trust
amongst each other. And how could they?
Absent an existing real-life WoT, there is no digital WoT to codify.
Even within a group that has a strong existing trust and social graph in
real life, the digital codification of a WoT offers security benefits
only at the extreme margins.
This fact is easiest explained by example:
o Fire up your preferred OpenPGP software. (If you don't have OpenPGP
software, then your understanding of how a WoT works is likely different
from what a WoT actually does).
o Eliminate all public keys for users with whom you do not intend to
communicate. (No communication security system can provide security
benefits to communications that will never take place).
o List the public keys that show as valid. (Meaning they are signed by
one or more keys that you trust to some degree).
o Eliminate all the public keys that are signed by your key. (Those keys
are not authenticated by the WoT, they were authenticated by you directly).
o Eliminate all the public keys that are signed by keys that you chose
to trust because they are the equivalent of CA root keys. This includes
Debian distribution signing keys, the keys of any commercial CA, and the
signing keys of auto-responder key servers such as the PGP Global
Directory. (Signatures performed by such keys do not employ the WoT).
o Look at the small number of public keys remaining. The keys are likely
from deep inside your social circle. Now eliminate all the public keys
that you could trivially authenticate directly, such as by asking a key
holders, who are well known to you, to provide you with their key's
fingerprint at work, at the next security conference, or the next time
you meet at the pub. (The WoT may have authenticated those keys, but the
WoT was not necessary to do so since you could have trivially
authenticated those few keys yourself).
o Lastly, count the remaining public keys. The number will likely be
zero (no real life benefit to the WoT) or close to zero (benefit only in
the extreme margins).
In summary, the WoT is not a suitable solution to increasing the
security of the Tor network.
--Lucky Green
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-12-08 13:55:26
@_author: Lucky Green 
@_subject: leaker-optimized versions of Tor 
There are no low-latency anonymizing system designs known to science
today that can protect a user's privacy against a determined, global,
TLA-level adversary. Considerable and by no means unreasonable doubt
exist in the community if such a design is even theoretically possible,
a question for which I refrain from forming an opinion solely due to the
impressive progress science has made over the millennia.
The picture is less clear when it comes to high-latency systems, such as
anonymous remailers. No rational doubt exists in the community that the
systems so far fielded fail to protect against this treat model. But the
question if we know how to design a high-latency system that defends
against the proposed threat model largely remains unanswered. This is in
part due to the fact that the bulk of recent research has focused
primarily on low-latency systems.
That said, it is my belief that if a low-latency system protecting
privacy in the face of TLA-level actors were to be identified, I suspect
the design will be based on PIR, not MIX. It is for this reason that I
encourage high-latency anonymity researchers to focus on PIR designs.
--Lucky Green
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-28 16:35:09
@_author: Lucky Green 
@_subject: [tor-talk] Thoughts on proxy setup wrt insecure connections 
This article is good intro to how the STARTTLS command would be used:
In short, the client sends the STARTTLS command to the server to
indicate a desire to use TLS encryption for the connection.
STARTTLS is most widely used with SMTP, POP, and IMAP.
The genesis of the STARTTLS command was a realization that the earlier
approaches to adding TLS security to existing TCP protocol-based
services suffered from a systemic flaw: "wrapping" the connection in TLS
and offering the "wrapped" service on a different port in effect
required doubling the number of assigned ports. One port for the
cleartext version, one port for the TLS version.
(This turned out to be less of a problem in practice than anticipated at
the time of the creation of the STARTTLS command, as the growth of
encryption was paralleled by a reduction in ports on which many hosts
connected to the Internet may transmit packets due to ISP level
filtering and the rise of NAT. But that's a discussion for a different
mailing list).

@_date: 2011-03-21 16:33:14
@_author: Lucky Green 
@_subject: [tor-talk] Iran cracks down on web dissident technology 
This thread has crossed into the unreasonable realm of conspiracy
theories akin to fears that jet aircraft dispense mind-controlling drugs
via their con trails. Let's call and end to this thread and move on to
more productive discussion about how to improve Tor for its users.
