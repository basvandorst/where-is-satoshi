
@_date: 2012-08-06 11:39:37
@_author: Edward Z. Yang 
@_subject: [tor-talk] Strong anonymization in a fixed group of participants 
Hello all,
I've been experimenting with protocols for solving the following
    A small (N = 10 to 100), fixed group of participants would each like to publish
    a random, fixed length string to the other participants, without revealing
    who the string came from (except that it came from one of the participants
    in the group).
The attack model is as follows: we make no attempt to stop denial of
service attacks, and we allow leakage of who the random fixed length
string originated from *as long as* the participant whose identity
was leaked finds out immediately.
I have a nifty solution that involves secure multi-party computation,
but there is a much simpler solution that involves Tor:
    1. Once the fixed group of participants is determined, have one
       leader listen for N random strings on a Tor address
    2. Each participant acquires a new Tor circuit, waits a random
       interval of time, and then submits their string to the leader.
    3. Once all the random strings have been received by the leader,
       he broadcasts the result on a public channel.
    4. Each client verifies that their random string is in the
       list; if it is not, they abort the protocol.
I was chatting with some of my friends about this protocol, and one
of their big skepticisms was whether or not the Tor protocol was
designed for this case (a few bits of deanonymization is not a big
deal in the context of all of Tor, but it is a big deal when the
group of participants is small).  So I was wondering if the denizens
on this list had any relevant information or advice about this.

@_date: 2012-08-06 21:54:51
@_author: Edward Z. Yang 
@_subject: [tor-talk] Strong anonymization in a fixed group of participants 
Hello Nick,
Thanks for the reply.
Right.  But it is possible Tor is insecure against attacks that don't matter
in practice for its ordinary use case, but matter here.
I am not sure a mix network is the right primitive here: in the usual
formulation (ala Chaum), anonymity requires at least one mix server be honest.
In the case of a one-hop mix, this is no good, because you're entirely
depending on the mix server being honest.  So we want a protocol which is
robust against malicious mixers (or we should use more hops--but this
particular use-case wants to minimize hops because every hop costs
transaction fees.)
My particular formulation nominates a leader, but really the one-hop
mix should be thought of as a multiparty computation.
Sorry!  Here is the threat model for the mix:
    - We expect the protocol to function correctly when all participants
      are honest but curious.
    - In the case of a minority of actively attacking participants,
      it would be good if the protocol resisted this attack, but we
      are also OK with a protocol abort (so DOS by participants is OK).
      Corrupt output is not acceptable, but if the protocol aborts
      loss of anonymity of the random string is not a problem, since
      it can be revoked and we can try again with a new random string.
    - In the case of a majority of actively attacking participants (Sybil
      attack), the protocol is permitted to fail to provide anonymity silently.
      We screwed in this case anyway, because if the adversary controls all of
      the nodes involved in the mix, even if the protocol is carried out by a
      trusted mixer he can still deanonymize.
    - The mix protocol should be completely resistant to outside attackers, including
      attackers with full access to network traffic.
The anonymity set is the participants of the mix.
We want to layer this on top of the traditional Tor threat model,
in the case where a user would like to act on behalf of a pseudoanonymous
entity anonymously (the pseudoanonymous entity is the participant in
the protocol).  In this case we don't care if we're weak against
a traffic analysis attack on the Tor network itself.
Wouldn't this be protected by adding the timing delay, and stipulating
all of the messages be constant size? (I guess I also don't see why
a random timing delay is not optimal.)  I think I do want this protocol
to be robust against this attack, because in general the participants
of the protocol may *not* be anonymous (since it is one-hop).
That is a very nice list of papers.  I will do some reading into DC-nets;
what is your favorite paper describing their implementation?

@_date: 2012-08-07 05:01:34
@_author: Edward Z. Yang 
@_subject: [tor-talk] Strong anonymization in a fixed group of participants 
Great, that looks like it solves exactly the right problem!
Excerpts from Roger Dingledine's message of Tue Aug 07 04:29:57 -0400 2012:
