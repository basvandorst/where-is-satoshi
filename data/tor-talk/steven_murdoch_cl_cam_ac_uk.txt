
@_date: 2005-07-24 23:48:09
@_author: Steven J. Murdoch 
@_subject: spawn_enough_dnsworkers 
You can use the command "screen" to avoid being logged in all the
time. This allows you to have a shell open, run Tor, "detach" the
shell (using Ctrl-a d) and logout.  Later when you log back in you can
reattach the shell by running the command "screen -d -r". There is
more information about screen at these URLs:
  Hope this helps,
Steven Murdoch.

@_date: 2005-07-30 11:21:39
@_author: Steven J. Murdoch 
@_subject: Policy question 
If you mean by entry point, the first hop (OR) in the Tor network, after
the Tor Proxy (OP) running on the client's machine, then "reject *:*"
will not prevent them from doing so. Letting other people use your machine as an OP is risky because the
Socks traffic is unencrypted so anyone watching this link could see
what is being requested. If you still want to do this, you could open
your SocksPort and then use firewall rules to resrict which IP
addresses can use it. A better option is to keep SocksPort listening
on localhost and let people SSH in and set up an encrypted tunnel.
This lets you do password authentication as well as IP address, and
provides a bit more security through encryption.
Letting some people use your node as an exit node is tricky because
Tor is designed to prevent the exit node from knowing which IP address
made the request. What you could do is set up a password-protected
proxy (e.g. Socks or HTTP) on the node and set your exit policy to
allow access to it. A similar option would be to allow SSH access to
localhost, and let people set up tunnels (provided they know the
Hope this helps,
Steven Murdoch.

@_date: 2005-07-30 17:12:33
@_author: Steven J. Murdoch 
@_subject: Policy question 
Using a your own node as an entry node seems OK. There is some debate
as to whether this helps or hinders security but it shouldn't be too
bad. Using your own node as an exit node sounds risky. This means that
anyone who sees (non Tor) traffic coming from this node knows that it
is from you. He can't know which of your computers did it, but I don't
see what advantage using Tor gives you over a normal Socks proxy.
A middleman node can be the first OR on the route through Tor, so
setting this as your entry node should work at the moment. From the
perspective of the OR, it cannot (easily) tell whether a connection
coming in is from an OP or from another OR. Setting "reject *.*"
prevents an OR from being the last hop, but it can be in any other
Hope this helps,

@_date: 2005-03-15 00:10:58
@_author: Steven J. Murdoch 
@_subject: Low-Cost Traffic Analysis of Tor 
One of the advantages of Tor is that it is sufficiently open and
widely deployed enough to run "real-world" anonymity experiments. Last
year, myself and George Danezis performed traffic analysis on Tor to
test the attack potential of weaker adversaries. This paper has now
been accepted for a conference, the 2005 IEEE Symposium on Security
and Privacy (Oakland). It isn't a full and general attack on Tor as
the basic attack only gives path information, not the address of the
originator, but we think it does provide some interesting results.
The paper can be found here (PDF 364K):
  Tor is the second generation Onion Router, supporting the anonymous
 transport of TCP streams over the Internet. Its low latency makes it
 very suitable for common tasks, such as web browsing, but insecure
 against traffic analysis attacks by a global passive adversary. We
 present new traffic analysis techniques that allow adversaries with
 only a partial view of the network to infer which nodes are being
 used to relay the anonymous streams and therefore greatly reduce the
 anonymity provided by Tor. Furthermore, we show that otherwise
 unrelated streams can be linked back to the same initiator. Our
 attack is feasible for the adversary anticipated by the Tor
 designers. Our theoretical attacks are backed up by experiments
 performed on the deployed, albeit experimental, Tor network. Our
 techniques should also be applicable to any low latency anonymous
 network. These attacks highlight the relationship between the field
 of traffic analysis and more traditional computer security issues,
 such as covert channel analysis. Our research also highlights that
 the inability to directly observe network links does not prevent an
 attacker from performing traffic analysis: the adversary can use the
 anonymising network as an oracle to infer the traffic load on remote
 nodes in order to perform traffic analysis.
Hope this is of interest,
Steven J. Murdoch.

@_date: 2005-03-17 10:01:31
@_author: Steven J. Murdoch 
@_subject: Low-Cost Traffic Analysis of Tor 
We are not quite sure what causes some nodes to be more affected by
our attack than others, which is why we didn't say much about this in
the paper. One hypothesis is that nodes near their capacity will be
mode badly affected, and our results do support this (the nodes you
mention are believed to be either on DSL connections or were being
DDoSed).  However we didn't survey enough nodes and collect enough
samples for this to be particularly convincing evidence.
This is difficult to say. Typically these attacks never give an
absolute yes or no as to whether a particular address is the
originator, but instead give a probability. This will initially be
close to random, but gradually converge on the correct answer, so the
time a user is safe depends on how accurate the attacker needs to be.
I don't think our results can give an answer to that, firstly because
we don't have enough samples and secondly because there may be better
correlation functions which give more accurate results. Actually I am
pretty sure this can be improved - see Figure 3b in the paper. Another
problem with measuring anonymity is that even if one test only shows a
slightly better than random chance that Alice is the person making the
connection, when Alice looks at the website the next day, the attack
can be repeated and the probability of a false positive is reduced.
A possibility I was thinking of is, say A is the victim, and B the
corrupt server, and their stream is going through Tor nodes M1, M2,
M3. Each of M1, M2, M3 will be detected as they carry the primary
signal. Then say there is also C and D, communicating though M1, M4,
M5. Now when B is sending the pulse, M1, M2, M3 will slow down other
connections going through it, (this is exactly
what we detect). But now the C-D connection will be slowed down, due
to M1 being common, and so M4 and M5 will be less loaded. A third
stream, E-F, going through M4, M6, M7 can now go faster (due to M4
being common), causing M6 and M7 to become more heavily loaded. M6 and
M7 may thus be detected by our algorithm, and this is the nature of
the echos we thought about. George says on this:
"One would expect to see echos if the traffic was indeed mixed
together, ie. if different streams were interacting together so that
they each pick up each other's characteristics. If there is perfect
propagation and mixing of the different streams that is good news
since we would not be able to tell them apart. On the other hand we
found that there is enough to be able to remotely monitor nodes, but
not enough to produce false positives."
I'm glad you found it useful.

@_date: 2005-10-11 23:26:10
@_author: Steven J. Murdoch 
@_subject: Software from "Low-Cost Traffic Analysis of Tor" 
Some of you might have read the paper "Low-Cost Traffic analysis of
Tor"[1], by myself and George Danezis. I have now released the code I used
to run these experiments, in case it will help any future research.
For more information, and to download the code, see:
 If you have any comments, suggestions or questions, please let me
Steven Murdoch.
[1]

@_date: 2005-09-29 00:27:51
@_author: Steven J. Murdoch 
@_subject: Hello directly from Jimbo at Wikipedia 
This would be very difficult to do using the existing Tor design as it
doesn't know anything about users or sessions. It lives at the TCP
layer and all it does is shift packets from one IP address to another,
giving some privacy to both ends. Adding higher layer functionality to
Tor increases the chance that it will do neither job well, so here is
a proposal which I think does what you want, but avoids this problem.
The goal is to increase the cost for a Tor user to commit abuse on
Wikipedia. It doesn't need to be full-proof, but just enough to make
them go elsewhere. Wikipedia could require Tor users to log in before
making edits, and ban accounts if they do something bad. However the
cost of creating new accounts is not very high. The goal of this
proposal is to impose a cost on creating accounts which can be used
though Tor. Non-Tor access works as normal and the cost can be small,
just enough to reduce the incentive of abuse.
Suppose Wikipedia allowed Tor users to only read articles and create
accounts, but not able to change anything. The Tor user then goes to a
different website, call it the "puzzle server". Here the Tor user does
some work, perhaps does a hashcash computation[1] or solves a
CAPTCHA[2], then enters the solution along with their new Wikipedia
username. The puzzle server (which may be run by Wikipedia or Tor
volunteers), records the fact that someone has solved a puzzle along
with the username entered. The puzzle server doesn't need the
Wikipedia password as there is no reason for someone to do work for
another person's account.
Now when that Tor user logs into their Wikipedia account to edit
something, the Wikipedia server asks the puzzle server whether this
account has ever solved a puzzle. If it has, the user can make the
edit, if not then the user is told to go to the puzzle server first.
This check can be very simple - just an HTTP request to the
puzzle server specifying the Wikipedia username, which returns "yes"
vs "no", or "200" vs "403". For performance reasons this can be
cached locally. There is no cryptography here, and I don't think it is
needed, but it can be added without much difficulty.
If the Tor user starts committing abuse, his account is cancelled. The
puzzle server doesn't need to be told about this, as Wikipedia will
not let that user make any edits. The reason this approach avoids the
usual problems with proof-of-work schemes[3] is that good Tor users
only have to solve the puzzle once, just after they create the
account. Bad Tor users will need to solve another puzzle every time
they are caught and had their account cancelled.
So my question to Jimbo is: what type of puzzle do you think would be
enough to reduce abuse through Tor to a manageable level? The
difficulty of the puzzle can be tuned over time but what would be
necessary for Wikipedia to try this out?
Hope this helps,
Steven Murdoch.
[1] [2] [3] "Proof-of-Work" Proves Not to Work by Ben Laurie and Richard
     Clayton:

@_date: 2005-09-29 11:40:06
@_author: Steven J. Murdoch 
@_subject: Hello directly from Jimbo at Wikipedia 
Yes, that is probably correct, but I still think it is a useful
result. The problem for Wikipedia and Tor is that Wikipedia cannot
differentiate abusers from people who need legitimately need privacy,
since Wikipedia blocks on IP address and Tor is an easy way to get
another IP address.
What needs to be done is to give Wikipedia a way to tell the
difference between legitimate Tor users and abusers. The basis for my
proposal is that abusers can currently get IP addresses quite easily,
through open proxies, zombie machines or simply rebooting their ADSL
modem, as well as through Tor.
To mitigate abuse from Tor, the cost of committing abuse through Tor
needs to be just higher than the cost of an abuser getting another IP
address.  This is not very high. Legitimate Tor users cannot just get
a new IP address since some ways are illegal and they get less privacy
through these than Tor provides.
If Wikipedia abusers find it is easier to get another IP address than
to solve a puzzle and use Tor, then Wikipedia will be able to tell
that Tor users who have solved a puzzle are probably not abusers, and
so can safely unban Tor IP addresses. Wikipedia can block the abusers
through their current mechanisms.
Whether this will work depends on the type of abuse that Wikipedia
receives, and Jimbo is much more qualified to comment on this then me.
Steven Murdoch.

@_date: 2006-08-10 14:15:07
@_author: Steven Murdoch 
@_subject: Mechanism for resisting targetted backdoors in Tor 
At the PET workshop ( I gave a brief talk
on a simple idea relating to Tor. One known weakness of open source
software is that, even if the source is well auditied, an attacker
could still implant a backdoor in the version downloaded by one
person, and have a very low chance of detection.
I suggested a mechanism for allowing users to detect if they were the
victim of such a targetted attack. The threat is very specialised and
the solution is not foolproof but I hope it will be of interest.
I describe the basics of the idea in this blog post:
 Also, there are more details in the comments.
I would be happy to receive any questions or comments.

@_date: 2006-12-02 01:14:13
@_author: Steven Murdoch 
@_subject: setup tor in private intranet 
There are instructions here:
 In particular Adam Langley has put together a neat little script which
does most of the hard work for you:
 This will work whether or not you are connected to the Internet. Tor
does not care. All that matters is the Tor nodes are able to access
the directory authority you specify.

@_date: 2006-11-27 01:07:00
@_author: Steven Murdoch 
@_subject: Traces left by Torpark, and other security discussion (was Re: TorPark) 
I was also interested in the answer to these questions, so I tried out
Torpark under Virtual PC[1] and with Process Monitor[2] running to see
what really happened. In some cases it doesn't quite match your
documentation. This was a fairly cursory examination, and it certainly
isn't complete so please correct me if any of my points are incorrect.
This isn't quite how modern operating systems work. As the hard disk
is so slow compared to main memory, operating systems will
aggressively page unused data to swap, and use main memory for disk
To test this I ran Torpark with a fairly generous amount of RAM
(512MB). Although RAM never ran out, there was significant swap file
usage (even idle, it used 149MB swap). On reboot, the pagefile.sys
file contained 2367 mentions of "Torpark". These were mainly
filenames, but also contained user data. For example:
 "E:\Torpark 1.5.0.7\App\tor\data\cached-status\7EA6EAD6FD83083C538F44038BBFA077587DD755"
 "ushCircuit 1.1 - Flush the tor circuit on port 9051 (Torpark): Installing"
This is indeed a tricky problem to deal with, but in the mean time,
perhaps you should clarify the  on the Torpark
homepage.   "[Torpark] leaves no track, is small, portable, and costs nothing."
Leaving traces behind may be unavoidable, but making users think that
it does not could lead to them facing problems. Some more examples are
continued later.
In prefs.js, I noticed the following line:
user_pref("capability.policy.maonoscript.sites", "... mozillazine.org
noscript.net torpark.nfshost.com ...");
If I understand it correctly, this exempts your site from the
Javascript blocking. Is there any particular reason for this? I'm
certainly not suggesting any malicious intent, but DNS does get
spoofed, domain names do get hijacked, court orders do get passed and
XSS vulnerabilities do get found.
If there is no convincing reason for exempting certain sites from
Javascript blocking, prudent defence in depth principles would dictate
that they not be exempted. This also applies to the noscript and
Mozilla sites.
It creates at least 3 ones which are persistent after reboot, but
there might be more that I missed.
Process monitor shows Torpark, Flushcircuit and Firefox trying to
create a large number of entries in the registry, but many already
exist, created presumably by Internet Explorer or Windows itself. For
 RegSetValue
 RegSetValue
 RegSetValue
Flushcircuit also creates several keys like this one, but they do not
survive a reboot:
 RegSetValue	HKLM\SYSTEM\ControlSet001\Control\Session
One registry key that Firefox creates that is new, and survives a reboot is:
 RegSetValue
There are similar ones for Firefox itself and Torpark.
machine it is running on
It creates a number of files, on the hard disk, which remain after
Some temporary files from Nullsoft installer are left:
 Documents and Settings//Local Settings/Temp/nst4.tmp
 Documents and Settings//Local Settings/Temp/nszB.tmp
Also there are these files used by the Windows task scheduler to
optimise future application loading times[4]:
 WINDOWS/Prefetch: FIREFOX.EXE-07686B34.pf
 WINDOWS/Prefetch: FLUSHCIRCUIT.EXE-129F88FF.pf
 WINDOWS/Prefetch: TORCIRCUITSTATUS.EXE-2E679AC0.pf
 WINDOWS/Prefetch: TOR.EXE-29FB7B10.pf
 WINDOWS/Prefetch: TORPARK.EXE-18DD2E51.pf
 WINDOWS/Prefetch: TOR_RESOLVE.EXE-2BA063E1.pf
The Nullsoft installer also creates this file in the system directory:
 WINDOWS/system32: gdiplus.dll
Although Torpark includes its own profile, Firefox still creates one
 Documents and Settings\\Application Data\Mozilla\Firefox
This only contains pluginreg.dat.
A large number of files are also modified, but I haven't gone through
these to find out which are by Torpark and not parts of Windows.
This is only a start, but I hope this information will be of some help
towards producing a comprehensive and accurate analysis of Torpark and
its components.
[1] [2] [3] [4]

@_date: 2006-09-05 22:52:42
@_author: Steven Murdoch 
@_subject: Revealing tor hidden services by their clock skew 
I was going to post this to the or-talk list, but I see someone beat
me to it :-)
To avoid any misunderstanding, I should add that there is no reason to
panic. Primarily the paper is designed to feed into the future design
of Tor rather than suggest any short term fixes. There are already
known attacks on Tor which will probably work better than this, but
the proposed defences to these will not fix the problem I discuss in
the paper.
Also, in the paper, I say that for clarity the results in the paper
are mainly from a private Tor network and running it in reality will
be more messy. However, as the performace of the Tor network improves,
the attack will be more effective, so is worth bearing in mind for the
future.

@_date: 2007-12-11 19:34:36
@_author: Steven J. Murdoch 
@_subject: New attack-vector via covert and side channel 
This results discussed aren't actually that new. Chapters 4 and 5,
which are on Tor, are based on papers published in May 2005 and
October 2006 respectively.
  I've now published the thesis version of these papers, which have more
diagrams and other improvements, but the underlying data and
conclusions are the same.
To quote from my previous message:
 "To avoid any misunderstanding, I should add that there is no reason
 to panic. Primarily the paper is designed to feed into the future
 design of Tor rather than suggest any short term fixes. There are
 already known attacks on Tor which will probably work better than
 this, but the proposed defences to these will not fix the problem I
 discuss in the paper.
 Also, in the paper, I say that for clarity the results in the paper
 are mainly from a private Tor network and running it in reality will
 be more messy. However, as the performace of the Tor network improves,
 the attack will be more effective, so is worth bearing in mind for the
 future."
 --

@_date: 2007-02-17 18:00:35
@_author: Steven Murdoch 
@_subject: Tor experiment: request for assistance from operators of UK nodes 
I'm a researcher at the University of Cambridge, and I'm studying
anonymous communication systems (e.g. Tor). I also operate a Tor node
(ephemer) myself.
Currently, I'm working on a study to discover how diverse the location
of Tor nodes is on the Internet, to see how secure it is against
someone who controls a few ISPs. As a case study, I'm using the UK as
an example.
To do this I need assistance from the operators of Tor nodes in the
UK. It doesn't matter where you are located, I care about the Tor
server itself. I'd like to find out the path between UK Tor nodes and
a sample of others and a few websites too. I've written a script for doing this, which is simple enough for
anyone to check that it does what it says. Would you be able run this
on the same computer as your Tor node, or another which shares the
same Internet connection?
There are two scripts, one for Linux/BSD systems and one for Windows.
You only need to run one, and if possible please use the Linux one
(it's faster and produces more useful data).
The Linux script can be found here (use this if possible):
 After downloading, at a command prompt, type "chmod 755
traceroute.sh" to make it executable and "./traceroute.sh" to run it.
The Windows one is here:
 To run it, just double click on it
There are PGP signatures here:
  The Linux one takes about 2-3 to run and the Windows one will take
about 3-4 hours. It doesn't need any attention once started, so you
can just leave it in the background. When it is finished, it will say "Completed". It will produce a file
called traceroute.log -- this contains the data I need, please send it
via email.
If you have any questions, please feel free to ask, either on or
off-list. I am also sjmurdoch on the Tor IRC channel.
Thanks in advance,

@_date: 2007-01-01 13:12:10
@_author: Steven Murdoch 
@_subject: Wired article on Tor 
Have a look at the graphs in the paper:
 They were collected from tests on real hardware where I put in a
temperature probe. Some are from local connections and some
transatlantic, and in both cases the quality of the results were good.
Without that much analysis, differences of 1--2 C were detectable.
The source code is online, so you can also try it yourself. To get
accurate results, it does take quite a while. My tests where typically
8--12 hours:

@_date: 2007-01-01 13:27:29
@_author: Steven Murdoch 
@_subject: Wired article on Tor 
There has been some discussion over the pros and cons of running a Tor
router on the same machine as the hidden service. An advantage is that
it gives a certain amount of plausible deniability -- connections from
you might be your's or someone else's. A downside is that then the
server accepts TCP connections and is on a public list of Tor routers,
so making the clock skew attack (and others) easier.
Under Linux there are also TCP initial sequence numbers, but much more
problematic is that externally visible events occur on low-level timer
interrupts. For example, the original clock skew paper[1] showed that
just by watching when TCP packets were sent out, the clock skew could
be found. Hiding this is very hard, since timer interrupts are a
hardware event.
[1]

@_date: 2007-01-01 18:22:52
@_author: Steven Murdoch 
@_subject: flooding attacks to discover hidden services 
This is a special case of the attack described in 5.2 of [1].
If we assume that the hidden service is on a Tor server then the nodes
which will show positive correlation will the the hidden service and
the guard node. If the guard nodes are stable then this gives the
hidden service some protection.
If the hidden service is not on a Tor server, and there is no other
way for the attacker to build a list of candidates to ping, then the
attack becomes a lot harder. Furthermore, there is no reason the hidden server needs to respond to
pings, or even have a public IP address. Tor only requires that the
hidden service be able to make outgoing TCP connections.
Hosting the hidden service on a Tor node gives some plausible
deniability, but opens up attacks like the one you describe.
[1]

@_date: 2007-07-18 15:58:17
@_author: Steven Murdoch 
@_subject: On the performance scalability of Tor 
A frequently stated problem with Tor is the poor performance and
improving this is the goal of several sub-projects. One of these is to
simply encourage the deployment of more Tor servers. This will
increase the capacity of the network, but the consequent improvement
to users is more difficult to estimate.
The intuitive hypothesis -- that a n% increase in network capacity
will result in an n% increase in performance for users -- is almost
certainly wrong. In fact, the defining factor is how the number of
users scales with the available bandwidth -- a currently unknown
I discuss this way of looking at Tor as well as the consequences and
limitations of the approach in a blog post published today:
 As always, comments and suggestions, either here on the list or on the
blog, are appreciated.

@_date: 2007-03-09 10:39:42
@_author: Steven Murdoch 
@_subject: Warnings on the download page 
The particular feature is "plugin scanning", for which more details
can be found here, including how to disable it:
 I have a half-finished blog post discussing this and the problems it
caused for Torpark, so now would probably a good time to complete it.

@_date: 2007-03-11 10:08:00
@_author: Steven Murdoch 
@_subject: How to run Tor from USB with Linux (Kubuntu 6.10) 
This link explains, but I've never tried it myself:
 This link may give you some hints, at least for Tor itself:
 Essentially, you can work out most of the required libraries using
"ldd", but I found a few extra ones were needed too.
Hope this helps,

@_date: 2007-05-28 11:00:48
@_author: Steven Murdoch 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
Some of you might remember my email to this list in February, where I
asked for help from operators of Tor nodes in the UK [1]. This was for
an experiment to establish how diverse the topology of the Tor network
is -- an important component of how secure it is against traffic
analysis. Thanks to all those who responded to my request; I had a
great response and very interesting results.
I've now finished the draft version of the resulting paper, which is
to be presented at the PET Workshop (Ottawa, Canada, June 20--22 2007)
[2]. The latest version of the paper can be found at this URL:
 There is also an introduction to the area, and a summary of the paper
on my research group's blog "Light Blue Touchpaper":
 My paper, co-authored with Piotr Zielinksi, is a follow-up to Nick
Feamster and Roger Dingledine's paper, "Location Diversity in
Anonymity Networks" [3]. In it, they point out that bouncing anonymity
network traffic around lots of countries might not be as good as it
seems because there are a small number of ISPs which show up on many
of the links to, from and between Tor nodes.
What our paper explores is that even if you deal with this problem,
and choose paths with a diverse collection of ISPs, there are still
Internet exchanges on many of the paths. These do not appear in the
BGP data that Feamster and Dingledine use, which is why I had to
resort to a more limited-scale traceroute-based study.
So not only are Internet Exchanges good places to put traffic analysis
equipment, but some (including LINX [4] and AMS-IX [5]) collect the
necessary data anyway, for performance measurement purposes. They only
record the headers of one in every few thousand packets, but our paper
also shows that, even with such low-quality data, traffic analysis
still works.
There's certainly no reason to panic about these results, as there is
still much more work to be done in this area. For example, the picture
in the US, where Internet exchanges are less popular, will likely be
different. I do hope that the paper will encourage future work on both
establishing more accurate estimates of attack costs and developing
[1] [2] [3] [4] [5]

@_date: 2007-05-28 12:03:10
@_author: Steven Murdoch 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
The convention in anonymity research is to assume a global passive
adversary, since then any system shown to be secure under that model
is probably secure in the real world. The problem with this approach
is it eliminates all practical low-latency designs, hence the weaker
threat model adopted by Tor.
I do think that a global passive adversary is stronger than the real
world situation. For example, such an adversary could read traffic
between two computers in my office, which I suspect is outside of the
NSA's capabilities, unless I were targeted for special attention.
The actual capabilities will probably lie somewhere between the two
extremes. Sometimes your connections through Tor will go via enough
monitored nodes to be tracked, sometimes they won't. The interesting
question is the relative proportion between the two quantities, and
how to change it for the better.
I had thought about that aspect, but given the shortage of space
didn't include it. Perhaps I should for the final version. Traceroute
gives a more accurate picture of topology the BGP data (in that it
shows up IXes), but it is still not "true". For example, it only discovers devices which reduce the IP TTL, and so
will not find MPLS links or long-haul layer-2 VLANs. Then, as you
point out, it could be that seemingly disparate traffic is going
through the same cable-tunnel, if not the same fibre.
The point behind that section was to dispel the myth that traffic
analysis is easy, because you can just run tcpdump on off-the-shelf
hardware. Actually, on high-speed links it requires serious
engineering effort to even capture the data, let alone store it. That
said, there is demand for such capabilities and given enough hardware
it is possible.

@_date: 2008-02-15 15:56:14
@_author: Steven J. Murdoch 
@_subject: Updated version of Tor Browser Bundle; now internationalized 
A new version of the Tor Browser Bundle (version 0.0.8) is available
from the usual URL:
 Notable changes include a new version of Torbutton to fix a security
problem, and a new build system which makes it easier to build
internationalized bundles. It is currently available in:
 - English (en-US)
 - Arabic (ar)
 - German (de)
 - Spanish (es-ES)
 - Farsi/Persian (fa-IR)
 - French (fr)
 - Dutch (nl)
 - Portugese (pt-PT)
 - Russian (ru)
 - Simplified Chinese (zh-CN)

@_date: 2008-02-03 18:31:21
@_author: Steven J. Murdoch 
@_subject: New Tor distribution for testing: Tor Browser Bundle 
Yes, I did look at how Portable Tor worked when I started, and it was
very helpful to see that it could be done, though I've taken a bit of
a different approach, based on my guess at user requirements. The main architectural change, is that Vidalia controls most of the
process. The major advantage is that Vidalia receives and understands
status messages from Tor and can act accordingly. It's also easy to
extend without needed extra build components.
I added new configuration options to handle starting Polipo and Firefox:
 - BrowserExecutable: location of the web browser to be started when
    Tor successfully builds a circuit. When the browser exits, Vidalia
    will shut down too
 - ProxyExecutable: location of the proxy server, started when Vidalia
    does and will be killed as Vidalia exits.
These changes are now in the mainline Vidalia source tree, so might be
useful for other bundles of Tor too. The Tor Browser Bundle is still
in development so assuming we stick to this architecture there might
be some more.

@_date: 2008-02-04 02:34:49
@_author: Steven J. Murdoch 
@_subject: New Tor distribution for testing: Tor Browser Bundle 
I don't think this is likely in the near future. One of the important
target classes of users is people who are at risk of persecution by
their government and want to keep a low profile. Many of these users
are also not fully computer literate and there may not be fully
translated Tor documentation in their language.
The goals of the bundle include being easy to set up and to leave
limited traces (both are still being worked on). In this scenario, to
broadcast the fact that someone is using Tor is in my opinion an
unacceptable risk. There would need to be some way to protect these
users before mandatory server operation is the standard.

@_date: 2008-01-30 00:52:18
@_author: Steven J. Murdoch 
@_subject: New Tor distribution for testing: Tor Browser Bundle 
Recently I have been working on creating a distribution of Tor which
includes a pre-configured browser -- the Tor Browser Bundle. It is
intended for being run off an USB flash drive, but will probably also
be helpful to users who want an easy-to-setup packaging of Tor.
More information and download links can be found here:
 The bundle contains Firefox, Tor, Vidalia, Polipo and Torbutton. No
installation is needed (just unpack the contents). All the components
are automatically started by one double-click.
The bundle is new, and contains development versions of Tor, Vidalia
and Torbutton, so should be considered a testing release. I do hope it
will be useful, and I'd appreciate comments, suggestions, and bug

@_date: 2008-11-22 13:14:19
@_author: Steven J. Murdoch 
@_subject: How I Learned to Stop Ph34ring NSA and Love the Base Rate Fallacy 
George Danezis has discussed this post on his blog:

@_date: 2009-01-23 00:57:40
@_author: Steven J. Murdoch 
@_subject: tor-browser bundle on XP 
Tor Browser Bundle 1.1.8 now includes Firefox 3 (3.0.5 to be precise).
It can be downloaded from the usual place:

@_date: 2009-03-26 15:27:09
@_author: Steven J. Murdoch 
@_subject: Gsoc Idea: Lunux Tor/Firefox Bundle 
One constraint of the Linux bundle is that it shouldn't require root
access. This might cause a problem for running a virtual machine.

@_date: 2010-08-02 02:07:07
@_author: Steven J. Murdoch 
@_subject: Practical web-site-specific traffic analyses 
Yes, this has been a known risk with all currently deployed
low-latency anonymity systems. One recent paper which looked at the
problem was discussed here:
 and the full paper is here:
 What they found is that single-hop proxies were easily broken (>95%
accuracy), but multi-hop systems were more of a challenge. The attack
against JonDo was about 20% accurate and against Tor it was only 3%
This doesn't mean that multi-hop systems are safe though, because the
attack assumed that the anonymity system didn't add any extra traffic.
In fact, Tor and JonDo do add quite a bit of extra traffic, and it was
probably this which confused the attack. Much of this traffic can be
identified and if it were removed before the traffic analysis was
performed, the accuracy would likely go up by quite a bit.
To fix this attack, systems can add dummy traffic (padding), delay
packets, and/or drop packets. Tor adds a bit of padding, but unlikely
enough to make a difference. Tor doesn't (intentionally) drop or delay
More research is needed before we will know how to best to use and
combine these traffic analysis resistance techniques. I co-authored a
paper on some aspects of this problem, but while the combination of
delaying and padding is promising, more needs to be done before this
can be deployed in a production system:

@_date: 2011-12-21 12:59:02
@_author: Steven J. Murdoch 
@_subject: [tor-talk] Automatic vulnerability scanning of Tor Network? 
The scan which happened yesterday was enough to get the attention of both the
university network security team, and the sys-admins of the department which
hosts my Tor server. The last time this happened was 2009.
It's already difficult enough to host a Tor server, but triggering institutional
IDS is only going to make justifying the benefit of running a node harder.

@_date: 2011-12-21 23:32:35
@_author: Steven J. Murdoch 
@_subject: [tor-talk] Automatic vulnerability scanning of Tor Network? 
I'm still highly unconvinced. If an institution has a policy that port scans are
suspicious and to be avoided, making the scans more stealthy could be
counterproductive. It might well make them harder to detect, but when they are
detected it will look even more suspicious. I'm also not convinced a slow port
scan will help much given that this is a common black-hat technique and thus the
sort of signature which will make it into an IDS.
Even if we could avoid detection, I don't see much of an advantage to a port
scan. Nowadays open ports are a very poor guide to actual system security. I'd
expect that practical security vulnerabilities will be the result of bad
passwords, old versions of daemons, insecure web applications, and so on; not
because someone has installed an inherently insecure daemon.

@_date: 2011-09-21 13:50:48
@_author: Steven Murdoch 
@_subject: [tor-talk] PhD studentship at Cambridge for study of 
I have funding available for a PhD student to work at the University of Cambridge Computer Laboratory, on the topic of privacy enhancing technologies and anonymous communications, starting in April 2012. The topic is broadly defined so as to allow scope for the PhD candidate to find his or her own research direction, but proposals relating to Tor would certainly be on-topic. The sponsorship is jointly provided by Microsoft Research Cambridge and under the Dorothy Hodgkin Postgraduate Awards scheme. As such, applicants must be nationals from India, China, Hong Kong, South Africa, Brazil, Russia or countries in the developing world as defined by the Development Assistance Committee of the OECD: The application deadline is soon (28 October 2011), so please circulate this advertisement to anyone who you think might find it of interest.
Further details can be found on the University website:
 Enquiries should be sent to me (Steven.Murdoch at cl.cam.ac.uk).

@_date: 2014-02-21 16:20:02
@_author: Steven Murdoch 
@_subject: [tor-talk] Anonymity degree of TOR 
Hi MR,
Degree of anonymity and entropy are not very useful metrics for Tor. There's a discussion of this and other possibilities for measuring security in these papers:
    Best wishes,

@_date: 2014-06-27 12:48:27
@_author: Steven Murdoch 
@_subject: [tor-talk] How does DNS work with .onion addresses? 
For .onion addresses, DNS is not used. Your Tor client receives a SOCKS connect request for a .onion address and recognises it as a hidden service request. Your Tor client then performs the hidden-service rendezvous procedure, including looking up the current introduction point in the hidden service distributed hash table (as your traffic never leaves the Tor network, there's no exit node involved).
Yes. If your browser is misconfigured then the DNS request will go out to your OS's configured DNS server, then likely out to your ISP, then likely out to one of the root name servers. Assuming nobody is being malicious, you'll get an error message that the domain name doesn't exist but someone eavesdropping you will know that you wanted to go to that hidden service. If someone is being malicious they could return the wrong IP address and your browser will connect to it.
There are people who survey DNS, and they report that there are quite a lot of requests for .onion. Some of these are people clicking on .onion links without Tor, but some could be the result of DNS leaks.
Best wishes,
