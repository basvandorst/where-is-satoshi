
@_date: 2012-08-15 19:50:51
@_author: Matthew Finkel 
@_subject: [tor-talk] http://torbrowser.sourceforge.net/ 
I mostly ignored this thread because I didn't think it was a big deal.
I figured the name of your new web browser would most likely confuse
people, but that could easily be changed once enough people convinced
you of that. But then I actually decided to visit the website, and I
was shocked. That must have taken you some time to get it so similar
to torproject.org. Just flipping back and forth between two tabs, I
was amazed at how close they are. But this amazement comes at a
potentially very steep price. Many others have already said it but are
you trying to confuse people? And you said, in not so many words, that
you know that your browser leaks DNS queries. How many people have
downloaded your browser thinking it is affiliated with Tor and that it
will provide them with anonymity? How many people are now at risk? [1]
[1]

@_date: 2012-08-16 17:01:15
@_author: Matthew Finkel 
@_subject: [tor-talk] http://torbrowser.sourceforge.net 
Though imitation is the highest form of flattery, you should really
just redesign your site. Create your own CSS and maybe try using a
3-column design instead of just 2...provides much more flexibility. =)
If you open both sites in different web browser tabs and flip back and
forth between them and notice any similarity/overlap then it's
probably too similar.
Also, the blue background looks bad...really bad, and I think your
project deserves better than that!

@_date: 2012-12-02 00:01:14
@_author: Matthew Finkel 
@_subject: [tor-talk] torsocks is broken and unmaintained 
The real issue is that once they start providing torified-forks of
certain projects where do they draw the line? torFirefox for TBB, sure
(which may be coming down the pipe anyway)! torssh, why not? Tor Project
is already stretched thin which means third party devs would have to
implement most of the work and who would be able to audit all of them?
"Torification" integrated into these projects would be a usability
god-send for most people. But that would ultimately be its undoing. At
this point many users don't understand that anonymity is not as simple
as flipping a switch, it's so much more complex than that. One possible
advantage of Tor being a little complex is that it makes people realize
that ensuring ones safety/privacy online is *not* easy and it's possible
that increasing the usability too much could put more people at risk.
In addition to this, if different projects have tor integrated then that
would mean each one would have to keep state separately and each would
most likely have different guard nodes and such. The result, again,
would be putting the users more at risk.
I understand the appeal of such packages, but if you think about this
then you'll see that running a single daemon and channeling connections
through it probably is the best and most resource efficient way. Just
think, if "x number of" programs you wanted to run were torified than
you would essentially being running x instances of tor, not ideal.
For now, using built-in proxy support for an application, or torsocks if
it doesn't have it, is the best option we have and we still need to be
careful when we use any built-in proxy option.

@_date: 2012-12-29 16:46:42
@_author: Matthew Finkel 
@_subject: [tor-talk] Please help w@lksne.go-plus.net 
Hi Wolfram,
The Tor Browser Bundle isn't actually installed. If you want to
"uninstall" it you only need to delete its directory/folder.
If you'd like some help getting it working, please feel free to join us
in the irc channel  on irc://irc.oftc.net:6667 (or with SSL on port 6697)
or send an email to help at rt.torproject.orgi providing as many details as
possible (version of TBB, operating system (such as Windows XP, Mac OS X 10.7,
Ubuntu Linux 10.4, etc), any error messages you received, etc).
I hope this helps.
All the best,

@_date: 2012-07-09 23:55:24
@_author: Matthew Finkel 
@_subject: [tor-talk] HTTPS to hidden service unecessary? 
It still needs work, but they do exist.
In general it's just better practice and safer to provide end-to-end
encryption. There are very few reasons not to use TLS.

@_date: 2012-11-02 23:10:53
@_author: Matthew Finkel 
@_subject: [tor-talk] torsocks is broken and unmaintained 
I saw this thread earlier but didn't have a chance to reply. I was
thinking about volunteering to patch it up and maintain it if no one
else wanted to take it on, also, but if you want to take the lead on it
then I'm more than happy to help you where ever possible...assuming this
is the direction that's decided upon.

@_date: 2012-11-03 23:23:37
@_author: Matthew Finkel 
@_subject: [tor-talk] torsocks is broken and unmaintained 
Thanks for adding one more thing to your plate! I know Jake can handle
this but the more eyes we have looking at these initial changes the
better it'll be.
Agreed. To be honest, I haven't really looked at the code too much, so
I'll start diving into that in a bit. (If there isn't one already...I
haven't checked) Can we get a trac component added so we can track
progress and such?
Yes...let's! :)
Was there supposed to be more to that sentence?
Certainly sounds like a good idea. I'm going to have to familiarize
myself with some of the other *nix platforms it does/should support.
Just looking through the current issues on google code, for example, I
don't know the internals of OSX well enough *yet* to know if [1] is even
possible. But once we've compiled a list of all the current critical
patches, Debian and others (assuming such a list doesn't exist already),
then we start applying, testing, revising, etc. :)
[1] - Matt

@_date: 2012-10-06 02:06:23
@_author: Matthew Finkel 
@_subject: [tor-talk] Tor SOCKS? 
Depending on the version of TBB you have, Tor will randomly select the
SOCKS5 port it listens on. I don't know of official documentation off
hand, but I know there are a couple ways to find it. It is specified in
Data/Tor/port.conf within the extracted directory (on my computer it is
tor-browser_en-US). Or you can also retrieve it within the Tor Browser
by checking the proxy settings: Edit->Preferences, in the Advanced menu,
select the Network tab, click Settings in the Connection section, and
the port is stated for the SOCKS port.
I hope this helps.
This looks like it should explain it:
tldr; There were still leaks for various reasons (some "unavoidable")
but the Tor proxy option is a separate implementation.

@_date: 2012-09-25 15:18:00
@_author: Matthew Finkel 
@_subject: [tor-talk] VPS provider 
Yes! Sadly there aren't too many KVM hosts, but providers are slowly
offering more options. Xen has been stable for a longer amount of time,
so there are more options available for that, Linode, et al.
I personally have KVM boxes from  and
 at times they leave something to be desired
with regard to performance, but overall I have no complaints related to
service or uptime. I don't currently use them for Tor related purposes,
but if they're not going to serve as exit nodes, anything else shouldn't
cause a  problem (except bandwidth, as was noted). I'm planning to
contact them in the future to determine their stance on Tor and see if I
can move forward with some ideas I have, but that remains to be seen.

@_date: 2012-09-25 18:04:22
@_author: Matthew Finkel 
@_subject: [tor-talk] VPS provider 
The above is true, for as much as I know, for the most part, but it
really depends on the situation and the purpose of the VPS. Using a
container-like VM provides very little guarantee as to who may have
access to data contained within. As you said, this is not limited to the
immediate VPS provider's staff, either.
Similarly, for the emulation implementations the data is nearly never
100% secure. However, the information that is stored on this type of
system is a key factor into whether or not it is safe enough to use a
third-party provider. It's not the case that the data is secure when
using KVM/Xen vs OpenVZ/Linux-VServer, only that is is more secure. ;)

@_date: 2013-04-12 18:58:03
@_author: Matthew Finkel 
@_subject: [tor-talk] [Tails-dev] secure and simple network time (hack) 
I don't really understand your reservation about this project. It's reasonable
to want authenticated time to a non-webserver of ones choice. Depending on
your environment, tlsdate is complementary to the various other
programs. You can (and will) use whatever you decide fits your needs,
but please don't disparage a valid project because it segfaults "after a
while". It's a work-in-progress, better to contribute useful information
than complain.

@_date: 2013-04-18 20:01:28
@_author: Matthew Finkel 
@_subject: [tor-talk] CloudFlare 
Wikimedia is actually willing to discuss an alternative setup if a
usable one is found. Their current implementation is not really
acceptable, but there also isn't really a working/implemented alternative
solution, at this point (and it's not exactly at the top of their list
to implement their own).
- Matt

@_date: 2013-04-19 02:53:17
@_author: Matthew Finkel 
@_subject: [tor-talk] CloudFlare 
Interesting, I assume this was before Onionoo was around. I understand
why it was/is necessary.
Yes, and it's a good solution, assuming one already has an account. The
real issue is creating an account anonymously and then gaining the
privilege to edit with that account...and...
Yes, I completely agree.
Again, I agree.
The fear associated with taking this path is that there will be an
overwhelming amount of "jerk behavior" such that it overwhelms the
wikipedia community and therefore discourages volunteers from actually
reviewing edits. The correct course of action is a difficult problem
(which is why this is likely still unsolved). It may be good to also
have a trial period where the user must submit x number of edits that
are not-deemed-to-be-jerk-behavior before they will be able to edit the
live page, just a thought though.
I think people (in general) lose sight of this, often, and it's important
that we remember why we do what we do, whether supporting a free and
uncensored internet (and world) or supporting a site that provides a
wealth of content not (freely) accessable anywhere else.
With respect to the WikiMedia and Tor communities, it seems as if both
are, understandably, more concerning with furthering their cause than
figuring out a way to work together (not necessarily the devs of the
projects, but the communities as a whole). However, as far as I can tell,
if we're both going to be successful in our goals, we're going to need
to be able to cooperate and determine a solution that fulfills the needs
of both groups - at this point it feels as if Tor users prefer to single
out WikiMedia as not being Tor friendly and the WikiMedia community
doesn't see the benefit of allowing Tor users to contribute (yes, these
are harsh generalizations, sorry).
I really think a solution would be a considerable benefit to everyone.
- Matt

@_date: 2013-04-19 03:12:06
@_author: Matthew Finkel 
@_subject: [tor-talk] CloudFlare 
Yeah, the various ideas for nym systems was what I was implying and the
"limited resource" aspect of them is definitely hard to specify.
And I think given the current situation this is an understandable
action, however it should not be necessary and sadly this is most detrimental
to the users who rely on Tor to reach the uncensored internet.
- Matt

@_date: 2013-08-10 19:29:39
@_author: Matthew Finkel 
@_subject: [tor-talk] So what about Pirate Browser? 
I think I'm confused about what they're actually trying to accomplish.
It sounds like they took TBB, replaced TorBrowser with the latest
version of Firefox portable (with the addition of foxyproxy), updated
the configs, and added some bookmarks. They also added some magic that
"allows you to circumvent censorship that certain countries such as
Iran, North Korea, United Kingdom, The Netherlands, Belgium, Finland,
Denmark, Italy and Ireland impose onto their citizens."
The one thing I always think about when I hear about the comparison of
censorship circumvention vs. anonymity[0] is something I once heard (maybe
from Jake or Roger, I apologies for not having a citation), but it went
something like "When you ask someone in China why they choose to use
Tor, they do not say it is to circumvent the strict censorship in their
country. They say that they use it for the anonymity aspect, because if
the government can censor what they are doing, then that means the
government *knows* what they are doing. As a result, if they can prevent
the government from tracking them, then they are also able to access
sites that the government does not want them to access".
Assuming I recall the basis of the quote correctly, this is an extremely
important idea that must be understood when dealing with censorship.
Going back to the PirateBrowser, if they are stripping out all of the
fantastic work Mike has done to preserve a users Anonymity (and the
packaging Erinn has done) and they replace it with Portable Firefox, I
don't think it can reach the full potential of "No more censorship!"
that they proclaim. However, I do think it is worth it to look at what
magic they use in Iran and North Korea. Is it more than using Tor and a
hidden service?
Just some thoughts,
- Matt
[0]

@_date: 2013-08-11 06:46:59
@_author: Matthew Finkel 
@_subject: [tor-talk] So what about Pirate Browser? 
I thought that was where I originally heard it, too. Alas, it was not
mentioned during that talk, nor was it mentioned during 23c3 or Internet
Days. I wonder if anyone else knows what I'm talking about.
Number 10 is quite relevant for this (The 23c3 talk also describes the
content of this paper, for those who do not want to read).
That would be sad if that is the case. I saw Tom just posted some info
on Libtech. Some interesting choices [0]:
- Matt

@_date: 2013-08-14 04:56:50
@_author: Matthew Finkel 
@_subject: [tor-talk] obfsproxy failure: obfs3 
Hi Lee!
Thanks for running a bridge! How did you install obfsproxy? If you
installed it using your distribution's package manager, which distribution
do you use?

@_date: 2013-03-28 02:31:12
@_author: Matthew Finkel 
@_subject: [tor-talk] Can't connect to 
You'll have to contact Tor Mail directly. It looks like the connection to
the database failed...from my reading of the error.

@_date: 2013-10-08 02:34:15
@_author: Matthew Finkel 
@_subject: [tor-talk] still unable to reach StartPage or Ixquick 
So these are actually two versions number for two different
programs. 0.2.4.x referred to the tor version which is packaged in TBB.
3.0a referred to the TBB version. Your current version of TBB just
happens to have a very similar version number to tor's. TBB will be
jumping to 3.x soon, though, as Roger said, tor will remain on the
0.2.x.y path.
I actually experienced this yesterday. I was too busy to troubleshoot
the connection issue, but it appeared that the request timed out. This
happened for both startpage and DDG, but not the other websites I
loaded. T'was strange, but probably just circuit dependent. In short,
if this is what you saw then it isn't only you, but I don't know why
it's happening.

@_date: 2014-04-12 13:52:42
@_author: Matthew Finkel 
@_subject: [tor-talk] IMPORTANT: Heartbleed vulnerability impact on Hidden 
Where do you propose the "more serious and visible banner" be placed?
With all of the attention that heartbleed attracted in the mainstream
media, I would think (but would probably be wrong) that relay and
hidden service operators are aware of the vulnerability and the fact
that their keys were potentially compromised.
I'm not sure this will accomplish exactly what you think it will
accomplish. Hidden services are merely one-last-proxy, so as far as we
know, the way to retrieve a hidden service's private key is the same way
as retrieving a relay's private key, by connecting to it's OR Port and
establising (most of) a TLS connection. If you connect to a hidden
service and attempt to establish a TLS connection then you're
connecting to that-thing-behind-the-hidden-service (whether that's
apache, nginx, sshd, etc). Due to the way hidden services are designed,
a non-local user/attacker should not be able to interact with the
instance of Tor that runs the hidden service (where "local" in this
situation includes anyone who can directly connect to the server).
But to answer your question more directly, your proposal won't be
extremely easy to do. In order to establish a connection only through
relays using vulnerable versions of OpenSSL it will require some
modifications to Tor on th hidden service-side to guarantee that it
builds such a circuit. On the client side you can use a controller
(Stem, txtorcon(?)) to choose your hops. Is there a reason you
specifically want this, though? Is there added benefit when every hop is
Great! If I'm wrong then an attacker only needs the hidden service
address and port number to be able to retrieve the private key. If I'm
not then the attacker really needs your IP address and OR Port (if
you're a relay).

@_date: 2014-04-12 13:59:33
@_author: Matthew Finkel 
@_subject: [tor-talk] Does Tor need to be recompiled *after* the openssl 
"Maybe". If you are upgrading OpenSSL from a much older version then you
may need to recompile Tor (so it knows about the newer version and uses
the correct headers and such) but if you're simply upgrading from, say,
1.0.1e to 1.0.1g then you should not need to recompile Tor. If you
restart Tor it should use the newer version of openssl without issue.

@_date: 2014-04-12 16:18:48
@_author: Matthew Finkel 
@_subject: [tor-talk] Viewing current Dir Auth votes 
It sounds like you're looking for consensus-health[0] :)
[1]

@_date: 2014-04-12 16:20:29
@_author: Matthew Finkel 
@_subject: [tor-talk] Does Tor need to be recompiled *after* the openssl 
Yes, this is a great point that I forgot to mention. Thanks!

@_date: 2014-08-05 16:57:57
@_author: Matthew Finkel 
@_subject: [tor-talk] Why adding Guard-Exit (EE) node in Tor yeild more 
Hi Saurav,
Can you clarify what you mean by Guard-Exit nodes? If I understand
correctly, you ran a simulation where you had x nodes which had the
Guard flag and y exit nodes, then you ran another simulation where
you had (x+y) exit nodes which also had the Guard flag? Is this

@_date: 2014-12-12 05:06:48
@_author: Matthew Finkel 
@_subject: [tor-talk] Tor and solidarity against online harassment 
Hi Jonathan,
Thanks for your support, would you like your name signed on the statement?

@_date: 2014-02-07 18:42:43
@_author: Matthew Finkel 
@_subject: [tor-talk] Pissed off about Blacklists, and what to do? 
Contacting Project Honey Pot has been on my TODO list for a while now
with the hope that some progress can be made, such as they handle exit
nodes specially. The anti-spam list ecosystem is much larger than
Project Honey Pot, but it would be a start.
Paul's mail was very much on point with this. However, Tor has a
perception/PR problem for this. ipset[0] is a prime example of this.
Regarding its listing of numerous blacklists and explicitly the list of
Tor exit nodes it says "...it certainly reduces comment spam on a
WordPress blog and there have been claims from websites owners that
their servers had been attacked through Tor."
Basically what Lunar said.
A more active and vocal community may help. Passively accepting the
current situation doesn't seem to be working. If the services don't
know that legitimate Tor users exist in a significant quantity and
that they are worthwhile to support, then there's no incentive to try.
- Matt

@_date: 2014-01-27 07:24:35
@_author: Matthew Finkel 
@_subject: [tor-talk] question about bridge relays 
To add to this, be aware that if you go to
 then you will likely receive two types
of bridges. There are "vanilla" bridges and there are bridges which that
Tor Project call Pluggable Transports. If you copy the bridges from the
website into the Tor Browser Bundle, as Roger described, you may only be
able to use some of them, which is fine, you only need one bridge to
work. If you would like all of the bridges on the website to work then
you will want to download the Pluggable Transport-capable Tor Browser
Bundle. It's a little larger in size but it provides additional
functionality that is important if you are somewhere that censors Tor
The pluggable transport bundle is available from [0]. If you are using a
Mac then you will want to choose one from the first 13 links, the links
that contain osx32 in the file name, and you'll want to choose the link
that provides your preferred language, if it's available (de = German,
en-US = US English, es-ES = Spanish (Spain), fa = Farsi, etc).
There is also a FAQ page which will hopefully answer some of your
questions. One of the sections[1], "How do I use pluggable transports?"
provides instructions and some bridges to help you get started. If
possible, follow Roger's instructions above to add the 'obfsproxy'
bridge lines in that section, if that doesn't work then try to follow
the instructions on that webpage.
The announcement that was made for this pluggable transport-capable TBB
can be found on [2]. It provides some more links and additional
information (including the two links I mentioned above).
Sorry if these instructions are difficult to follow or understand.
Whether or not you need to use the pluggable transport-capable bundle
really depends on where you are. If you don't know if you need to use
pluggable transports then try following Roger's directions first. If you
are still unable to connect to the Tor network then try to follow the
instruction for the pluggable transport-capable bundle.
[0] [1] [2] That really would be swell. The easier we can make this, with
step-by-step visual instructions, the bettwe.
I hope this helps,
- Matt

@_date: 2014-07-05 03:59:28
@_author: Matthew Finkel 
@_subject: [tor-talk] messing with XKeyScore 
In reality it's a bit silly to try to mess with these rules if they are
n-years old. Based on the pics, simply requesting that all users use
bridges at bridges.torproject.org instead of bridges at torproject.org is the
easiest change that by-passes this specific set of rules. But, I
think it is more realistic that these minor points are moot and the
regexes were fixed long ago and that the ruleset more fully covers
Tor's distributors now.
This problem makes me sad on many levels, and I'm not opposed to
implementing mitigation techniques (within reason) based on the
rulesets, however we shouldn't do anything that will hurt our users nor
should be do anything that makes tor more difficult to use
(unfortunately this includes sending users bogus bridge addresses).
For the use-case of bridges, where a user tries to circumvent local
network interference and implicitly expects they're not fingerprinted
by NSA, we are mostly failing right now.

@_date: 2014-07-25 02:38:41
@_author: Matthew Finkel 
@_subject: [tor-talk] Why does requesting for bridges by email require a 
This actually has very little to do with trust, and (as Roger said)
these providers were chosen because of the difficulty of creating new
accounts. Out of curiousity, what are you actually worried about?
Personally, it is sad that you need a phone number when you create
these accounts over Tor, but if retrieving bridges is important (and
it usually is), then there are usually ways to do this safely.
Another distribution method is currently being written and we will
write others in the future, but please help us provide another way
(yes, you, please help us if the current situation is unsatisfactory!).
The more people we can safely help, the better.
- Matt

@_date: 2014-07-25 02:46:24
@_author: Matthew Finkel 
@_subject: [tor-talk] Why does requesting for bridges by email require a 
See I haven't looked much at other providers recently. We want to keep the
whitelist as small as possible. We can only make the situation worse by
increasing the attack surface. The email distributor is already
significantly weaker than the website. We'd rather provide more
safe/secure distribution methods.
This is already done informally. Eventually we will try to make this
safer (to some extent)[0].
[0]

@_date: 2014-07-26 07:47:24
@_author: Matthew Finkel 
@_subject: [tor-talk] Why does requesting for bridges by email require a 
Yes, they do rely on captchas and phone numbers. But luckily, in the
case for gmail, the capture-difficulty is variable. This in no way
solves the problem, but it's certainly better than most alternatives.
Excluding the NSA/US Gov, I think gmail is the best
corporate-controlled service available, right now. This
opinion may change if contradictory information is released, but at
this time, for our purposes, I am happy requiring gmail.
Services like riseup are excellent, but we are abusing their systems
(a little), as well as potentially putting more work/stress/pressure on
the staff. I wish there was a way to necessitate the requirements and
rigor of riseup with the scalability of gmail. Alas, this isn't
available, as far as I know. Riseup is also special due to existing
person relationships, it's possible we can expand the whitelist to other
provides such as autistici, but it will be a more involved process.
Suggestions and help always appreciated

@_date: 2014-07-27 16:00:49
@_author: Matthew Finkel 
@_subject: [tor-talk] Why does requesting for bridges by email require a 
An important point, that I don't think was mentioned previously, is that
Riseup cannot be a substitute for gmail and yahoo mail. The latter
are two service providers which place very few restrictions on the
users. Riseup, on the other hand, only accepts people who either
honestly have similar political and social ideals or they lie. Granted,
if an adversary is trying to surveil or track users then they probably
won't have any problem with deception and lying during the application
process. However, this does raise the bar for entry into retrieving
the specific bridges which are only distributed to riseup users.
I hadn't heard of them. The account creation process seems simple,
sadly the captchas are not very difficult, either. I'm not saying
they're not usable, only that this seems like an easy target for
powerful adversaries. They also have offices in the US and China,
which could cause other problems.
Before we start whitelisting many new email providers, we should
define exactly which criterion we are looking for and what
percentage of the bridges we should allocate to the provider based
on which criteria they meet. We need a system that is usable by the
masses but also one that doesn't render the majority of the system
useless because someone/something was able to enumerate most of the

@_date: 2014-06-03 23:44:15
@_author: Matthew Finkel 
@_subject: [tor-talk] Can someone please help me understand section 1.10 
Hi Yaron,
The short answer is yes. This is how Alice and Bob establish a shared
secret key.
The longer answer is yes, section 1.10 describes how Alice (the client)
and Bob (the hidden service) establish shared secrets. After both Alice
and Bob possess the two respective halves of the Diffie-Hellman keys,
they use the shared secret and a key derivation function to expand the
key material into a byte sequence from which a 5-tuple is extracted (KH,
Df, Db, Kf, Kb). The first element (KH) is used to prove knowledge of
the shared secret, the second (Df) is used when computing the digest of
every cell from Alice to Bob, Db is the same but for cells from Bob to
Alice, Kf is the shared secret key used to {en,de}cipher cells from
Alice to Bob, and Kb is used to {en,de}cipher cells from Bob to Alice.
It sounds like these latter two keys, Kf and Kb, are what you are most
interested in.  Assuming the rendezvous point is unable to break the
security assumptions of the Diffie-Hellman handshake and the KDF is
secure, all messages sent between Alice and Bob are end-to-end
Does this make sense?

@_date: 2014-06-06 04:49:40
@_author: Matthew Finkel 
@_subject: [tor-talk] Security concerns with running an exit relay 
tl;dr Thank you for wanting to run a relay. If you think the
documentation is lacking specific information, or if it is confusing,
please say so. It usually doesn't change unless someone says something.
Hi Robert,
There are two unfortunate situations for which we need to account. 1)
It's actually very difficult for the current developers to know what
qualifies as a "full and exemplary answer". The documentation can be
written, and maybe this should be, but the reality is that Tor doesn't
have the resources to explain in detail how someone should configure
their server. At this point tor runs on many different systems, but the
only truely supported, plug-n-play OS is Debian GNU/Linux. Roger already
mentioned it, but [0] does describe some basic configuration changes and
does have some good post-installation suggestions. Admittedly, it's
not perfect and is probably lacking some vital information, so if you
can provide some suggestions then that will help everyone.
The OperationalSecurity wiki page that Roger mentioned and that is
linked from [0] is more of an ideal situation. Some of it is absolutely
a good idea to follow (please!), but the most important parts are
generally basic tasks, such as keep your OS up-to-date. If you are using
a VPS, or a similar shared hosting environment, then some of the
information will not be applicable, i.e. "Physical Security" and
"Reliability". But that page will probably be confusing to those users
with little experience, it isn't written in a way that helps someone
learn how to secure their system, which is sad. (Luckily it's on a Wiki,
so anyone can correct this ;) )
With regard to insufficient documentation about setting DirPortFrontPage
and maintaining a synchronized system clock, it may be a good idea to
add these to the "Step Four: Once it is working" section on [0].
Overall, a mix of [1] and [2] is a good combination, unfortunately it
may not be obvious which parts you want to follow from [1] and which you
want to follow on [2] (such as if you are using Debian rather than
Ubuntu). This is a great discussion to have on tor-relays. I'm sorry
that you had bad experiences in the past.
2) Expanding the Tor network is vitally important, but the network
itself and many Tor users have powerful adversaries. There must be a
way to balance adding an amazing number of insufficiently secure nodes
and growing the network at a slower rate. Maybe having a pre-configured,
installable, OS would make this easier, but the network also needs
diversity which this would hurt and creating and maintaining something
like this is not currently feasible. If someone within the community
has the time and ability to write detailed, step-by-step
documentation on the Wiki, then it sounds like this will be a great
step in the right direction, but until this happens, sites like [3] are
good places to start. Also note that if you aren't comfortable
administering a server then there are other ways you can help Tor and
the Tor network [4] (and the other "Help another way" options).
But, most importantly, if you think the documentation is lacking
specific information, or if it is confusing, please say so. It usually
doesn't change unless someone says something.
Really, though, despite everything else, thank you for wanting to run
a relay.
[0] [1] [2] [4]

@_date: 2014-03-22 20:17:19
@_author: Matthew Finkel 
@_subject: [tor-talk] Tor-ramdisk 2014 20140309 released 
Is there a good way to send you suggestions for the build script? There
isn't a trac component for tor-ramdisk, should one be created for this?

@_date: 2014-11-09 19:50:21
@_author: Matthew Finkel 
@_subject: [tor-talk] Tor Blog: "Thoughts and Concerns about Operation 
Thanks for sending this!
For those who read this earlier, two new paragraphs were added:
Under "Attacks on the Tor network":
*Similarly, there exists the attack where the hidden service selects
the attacker's relay as its guard node. This may happen randomly or
this could occur if the hidden service selects another relay as its
guard and the attacker renders that node unusable, by a denial of
service attack[0] or similar. The hidden service will then be forced to
select a new guard. Eventually, the hidden service will select the
And under "Advice to concerned hidden service operators"
*Another possible suggestion we can provide is manually selecting the
guard node of a hidden service. By configuring the EntryNodes option
in Tor's configuration file you can select a relay in the Tor network
you trust. Keep in mind, however, that a determined attacker will
still be able to determine this relay is your guard and all other
attacks still apply.
* Added information about guard node DoS and EntryNodes option - 2014/11/09 18:16 UTC
Yes please!

@_date: 2014-11-17 16:46:52
@_author: Matthew Finkel 
@_subject: [tor-talk] misleading advice in Ars Technica article about 
Thanks wyory. A new week, a new Tor headline. Happy Monday.
Probably a good idea. VPNs are useful, sometimes, but not very often and
definitely not for most use-cases.
- Matt

@_date: 2014-10-10 20:22:30
@_author: Matthew Finkel 
@_subject: [tor-talk] orWall 1.0.0 released! 
Hey CJ,
This looks great, very nice! I'm playing around with it now, so I may
send some PRs in the future. :)
I was also wondering if you keep the content for orwall.org in version
control. Overall it's very good, but I'd like to help improve some
wording, if possible. I can always send you an email, if that is
better for you.
Thanks for working on this.
- Matt

@_date: 2014-10-15 07:21:00
@_author: Matthew Finkel 
@_subject: [tor-talk] New SSLv3 attack: Turn off SSLv3 in your TorBrowser 
Thanks Nick. Interestingly, but mostly uselessly for us, Mozilla
published an extension[0] that does this. Unfortunately they say it
only works on >= FF26 (without tweaking it) and Tor Browser 3.6 is
based on FF24.
For what it's worth, the extension[0] should work with the new Tor
Browser 4.0, but this is untested.
If you do make this config change, when you visit a site that only
supports SSLv3 or downgrades to it, you should receive a message that
    Cannot communicate securely with peer: no common encryption algorithm(s).
    (Error code: ssl_error_no_cypher_overlap)
For those wondering, this works exactly the same on Tails (1.1.2), too.
(and yes, they spelled it "cypher").
I'm also curious what Mike, Georg, and the other TB Devs think. It
looks we need to wait until November when SSL will be disabled in
mainline Firefox[1].
[0] [1]

@_date: 2014-10-31 21:34:37
@_author: Matthew Finkel 
@_subject: [tor-talk] Facebook brute forcing hidden services 
Censorship and network interference is exactly what we're trying to
prevent in this situation. Why would you want to prevent someone from
reaching their destination? We're interested in freedom (and providing
unrestricted access), not controling where users can and can not go.

@_date: 2015-02-01 21:50:35
@_author: Matthew Finkel 
@_subject: [tor-talk] ISP CenturyLink Blocking Tor? 
Wow. That is quite coincidence. Can you ask your friend to contact
CenturyLink and ask them why this happened. It appears no one has
experienced this or, at least, no one updated the Good/Bad ISP wiki
page with this[0].
You probably chose the meek-google pluggable transport[1]. Basically,
it takes advantage of the fact that someone can run a webserver on
Google's infrastructure (using AppEngine) such that when you establish
a HTTPS session with the webserver, your ISP only see the connection
to Google's servers and not the specific server you're connecting to;
the specific webserver (meek) is defined within the encrypted portion.
When Google receives the connection, it correctly passes the
connection to the meek webserver. From there, the webserver then sends
your connection to a Tor Bridge, which is your first hop into the Tor
network. It's a very cool idea and it seems to work very well. The
current Tor Browser also supports connecting to a meek instance running
on Amazon's EC2 infrastructure and on Microsoft's Azure infrastructure.
[0] [1] Sounds like it. It would be great if someone directly asks CenturyLink
about this.
It's interesting that resetting the modem allowed you to access the
internet again. I wonder if the internet connection block you
experienced was based on the modem's IP address, and when you reset
the modem it was given a new dynamic IP address - hence bypassing the
block. This reminds me a little of the way China handles connections[2],
but it's still a little early to make a serious comparison.
The more information we can get about this, the better.
[2] Also, as a general aside, please remember that trying to run a
bittorrent client over Tor is a bad idea[3] (the first half is the
relevant portion). I'm not sure if this was the intention, but just a
a friendly reminder :)
[3]

@_date: 2015-10-16 16:04:51
@_author: Matthew Finkel 
@_subject: [tor-talk] Get Tor bridge via python code 
Hi Farod,
Sadly no, you can not retrieve bridges easily using a python script. The
website ( and email
(bridges at bridges.torproject.org) are the only two available methods. The
reason for this is because if an API were available for this then it would
need to support CAPTCHA-like (proof-of-humanity) functionality, and there
was not an easy way to implement this - nor was there any need because no
one had previously requested it. Without some sort of CAPTCHA it would
be extremely easy for anyone to retrieve all available bridges and then
block their IP addresses - thus making the bridges useless.
- Matt

@_date: 2016-08-07 02:08:54
@_author: Matthew Finkel 
@_subject: [tor-talk] How stealth onions actually function? 
The only documentation I know that exists is the spec[3].
The spec has a more detail, but briefly both authentication methods rely on
a pre-shared secret between client and service. The distinction is made where
that shared-secret is used.
When a service uses basic authentication instead of publishes its introduction
points in plaintext, it encrypts the list of intro points with a key chosen at
random and then encrypts that symmetric key multiple times using the shared
secret for each client it has configured. With this, all clients can retrieve
the hidden service descriptor from the HSDir but if a client doesn't have a
valid shared secret then they can't find the intro points from the descriptor.
   When generating a hidden service descriptor, the service encrypts the
   introduction-point part with a single randomly generated symmetric
   128-bit session key using AES-CTR as described for v2 hidden service
   descriptors in rend-spec. Afterwards, the service encrypts the session
   key to all descriptor cookies using AES. Authorized client should be able
   to efficiently find the session key that is encrypted for him/her, so
   that 4 octet long client ID are generated consisting of descriptor cookie
   and initialization vector.
Stealth authentication is similar, except it publishes a hidden service
descriptor for each configured client.
   With all else being equal to the preceding authorization protocol, the
   second protocol publishes hidden service descriptors for each user
   separately and gets along with encrypting the introduction-point part of
   descriptors to a single client.    [...]
   A hidden service generates an asymmetric "client key" and a symmetric
   "descriptor cookie" for each client. The client key is used as
   replacement for the service's permanent key, so that the service uses a
   different identity for each of his clients. The descriptor cookie is used
   to store descriptors at changing directory nodes that are unpredictable
   for anyone but service and client, to encrypt the introduction-point
   part, and to be included in INTRODUCE2 cells
This is exactly one reason why stealth hidden services are great.
[3]

@_date: 2017-08-16 04:17:16
@_author: Matthew Finkel 
@_subject: [tor-talk] help 
Hi Petey,
It looks like Tor thinks your system clock is roughly 7 hours behind the
correct time. Is the timezone correctly configured on your system or did
you recently change your timezone or change your clock?
If I take a guess, I'd say your system is configured with UTC as the timezone,
but the clock itself is set for your local time. Do you know how to confirm
this and can you confirm this? - Matt

@_date: 2017-12-11 02:51:22
@_author: Matthew Finkel 
@_subject: [tor-talk] company devised process to disable Intel Management 
This is a bit off-topic, but you might find these interesting:

@_date: 2017-10-25 13:35:21
@_author: Matthew Finkel 
@_subject: [tor-talk] Need a stable .onion address hosted by the Tor 
Something to keep in mind is Facebook intentionally makes their onion
service faster than normal. They are not concerned with location-privacy
so they disable most protections. If you need a stable and fast onion
service for testing, Facebook's may be the best choice (for the near
future, at least).
I'm curious, do you know what is failing? Are the connection requests
timing out? If you attach a controller to the tor client and watch for
circuit events, do you see the connection failing at the same point
(I haven't run any tests, if I have some time I will)

@_date: 2018-04-13 14:20:31
@_author: Matthew Finkel 
@_subject: [tor-talk] Structured Information on Tor 
Hi! It's great you're interested this! Just so you know for next time,
as a matter of respect for everyone on this list, we use "y'all" or
"everyone" (or something similar).
Unfortunately, no. There isn't an all-inclusive book about Tor. This is
partly due to no one having any spare time for working on it, and partly
due to Tor evolving so quickly the book would be outdated before it
reached the publishing presses (along with some other reasons). The
current Tor documentation page [0] has nearly all the details you need,
but it's spread across multiple locations.
There are high-level overviews and lower-level specifications, but we are
missing a middle-level description.
The specifications are the core documentation for the different
components. If you want something high-level you can look at [0]
section (a) and the EFF's "Tor and HTTPS" website [1]. If you need more
details about how this all works, [0] section (k) has links for the
various parts of Tor. In particular, the Tor Design paper (The Second
Generation Onion Router) is still relevant, although many parts of Tor
today are different. There is a series of blog posts from a few years
ago describing updates since that paper was published [2][3][4]
(although some of that information is now old, too).
Section (i) at [0] has links for some interesting videos, too.
[0] [1] [2] [3] [4] I hope this helps,

@_date: 2018-04-29 18:36:10
@_author: Matthew Finkel 
@_subject: [tor-talk] How do the OBFS4 "built-in" Bridges work? 
Currently this is how it works, yes. It is not ideal, and there is
on-going development work for rolling out a more scalable method.
Indeed "Bad actors" could block the bridges hard-coded in Tor Browser.
It is also true many of those default bridges are overloaded.

@_date: 2018-04-30 13:57:15
@_author: Matthew Finkel 
@_subject: [tor-talk] How do the OBFS4 "built-in" Bridges work? 
Yes, it is possible. There's nothing magical about how Tor sends the
traffic and none of the currently-deployed pluggable transports
significantly modify a users traffic pattern. A network operator could
observe strange traffic from a client, where the destination is a rarely
used IP address and the port number is non-standard. This could be a Tor
connection or it could be a brand-new up-and-coming app which could
revolutionalize the world. What does the network operator do? Do they
block the traffic because it *could* be a connection into the Tor
Of course, there is the next step the network operator could take -
active probing. If they suspect a connection is into a Tor bridge, then
they can try connecting to it, and if it responds like a Tor relay then
they can classify it as "Tor". The obfs4 pluggable transport includes
active probing protection where the client must have the bridge's
non-public second identity key as requirement for establishing a
connection with the bridge. If the client does not have this identity
key, then the initial obfs4 connection will fail and the server will
not leak the fact there is a Tor bridge underneath it.
Not necessarily. That option only tells Tor "don't choose a relay as my
first-hop (guard/entry relay) if I know it will be blocked". This simply
avoids choosing a relay listening on port 9999 when we already know the
network firewall only allows ports 443 and 80.

@_date: 2018-04-30 14:05:55
@_author: Matthew Finkel 
@_subject: [tor-talk] How do the OBFS4 "built-in" Bridges work? 
Yes, and/but no. Moat is a good step in the correct direction, but it by
no means solves all the problems. Moat simply retrieves bridges from
bridges.torproject.org "automatically", rather than requring you do it.

@_date: 2018-04-30 21:57:45
@_author: Matthew Finkel 
@_subject: [tor-talk] Fingerprinting issue in Tor Browser for macOS 
============================== START ==============================
Yes, sadly this is the current state. The three supported platforms for
Tor Browser are distinguishable by looking at a user's available fonts.
This is current a compromise between fingerprintability and usability.
Please see the Tor Browser Design document for additional details [0].
However, note this isn't the only method for identifying the underlying
Section 4.6, Subsection "Specific Fingerprinting Defenses in the Tor
Browser", Item 6. Fonts

@_date: 2018-08-08 13:57:51
@_author: Matthew Finkel 
@_subject: [tor-talk] HSTS forbids "Add an exception" (also, 
Right. This is the recommendation in the RFC [0]. It would be
counter-productive if the webserver informed the browser that the
website should only be loaded over a secure connection, and then the
user was given the option of ignore that. That would completely defeat
the purpose of HSTS.
[0]  Section 12.1
Why? There are three(?) options here:
1) The domain is preloaded in the browser's STS list, so it knows ahead
of time if that site should only use TLS or not. If it is in the
preloaded list, then the browser establishes a TLS connection as the
first step. If this fails, then none of the HTTP Request was leaked. If
the TLS connection fails, then the user is shown an error page and
cannot add an exception.
2) The domain is not in the preloaded list, so the browser learns about
the website setting HSTS on its first successful TLS connection and HTTP
request. This would potentially leak the user's entire request to a MITM
but this (HSTS) would not detect a MITM either. The MITM (or malicious
endpoint) would only be detected if they served an invalid certificate
chain for the domain name. The HSTS header would only prevent the user
from loading the website over an insecure HTTP connection in the future.
3) The user previously loaded the site and the browser cached a STS
value for that domain. If the user tries visiting the website again,
except this time they request an insecure connection, then the browser
will rewrite the URI so it uses TLS port 443 (by default), and then it
will initiate the TLS connection. There isn't any information leaked
before the TLS handshake. Furthermore, if the server and browser cannot
negotiate a valid TLS connection (because the certificate-chain is
invalid, or the ciphersuites don't intersect), then the user is
presented with an error message which they cannot override and add an
exception (as you experienced).
No? This was one of the main goals of HSTS. It should prevent SSL
stripping (for some definitions of prevent).
I'm also not sure if you're referring to public key pinning, as well.
Where the website can specify the exact hash of its public key in the
HTTP headers. That is another topic, and that relies on
Trust-On-First-Use, as well.

@_date: 2018-08-08 18:22:48
@_author: Matthew Finkel 
@_subject: [tor-talk] HSTS forbids "Add an exception" (also, 
Please consider opening a bug with Mozilla for this.
Full list (for latest stable Tor Browser):
I don't have a good explanation for why you experienced this.
Correct. HSTS is a TOFU protocol, and it only takes effect on the
second connection. From what I see in the Firefox code, the HSTS value
is only cached after the HTTP response header is parsed. The next time
the website is requested, Firefox checks the cache for a STS entry and
forces TLS if an entry exists.
Unless the browser includes the domain in the STS preload list, you
shouldn't experience a problem loading a broken-TLS-configured website
until the second request. But, maybe I missed something.

@_date: 2018-08-09 18:47:05
@_author: Matthew Finkel 
@_subject: [tor-talk] Exit nodes can redirect requests? 
Without seeing the actual website, we can only guess what caused this.
Did you have javascript enabled in Tor Browser? Maybe there was a
javascript file that tries alternative tor2web gateways?
It depends. In theory, yes, it could in this case. This would qualify
the exit node as a bad relay, but in practice it could detect onion.casa
is a dead website and it sent a HTTP redirect for tor2web.xyz.
It seems more likely this was a feature provided by the forum, but if
the exit relay injected a redirect from onion.casa to tor2web.xyz then
it is a good idea to find which relay this is and investigate it.

@_date: 2018-12-21 17:31:11
@_author: Matthew Finkel 
@_subject: [tor-talk] Moving stuff between Tor Browsers 
There isn't a specific way of doing this built into the browser. You can
backup and restore the entire profile (which is what Mozilla suggest)
[0]. In this case, you'll want the profile at
Bookmarks can be exported using the built-in backup/restore process[1].
Tor Browser doesn't provide any additional feature for this. It's simply
a more private and secure version of Firefox.

@_date: 2018-02-17 20:17:33
@_author: Matthew Finkel 
@_subject: [tor-talk] Launching new tabs in existing TBB from the shell 
That's surprising. I just tested it with a fresh Tor Browser
installation on 64-bit Linux and it worked without an error. A couple
  - What version of Tor Browser are you using?
    - Press the Alt key, then select the Help menu at the top, then click About Tor Browser
  - Did you already try restarting your computer and trying again?
- Matt

@_date: 2018-07-23 21:52:47
@_author: Matthew Finkel 
@_subject: [tor-talk] torjail - run programs in tor network namespace 
Nice! Very interesting.
A few comments (take or leave them):
1) Tor 0.2.3 was deprecated many years ago, no need for checking the tor
version number or support for torrc options [0].
2) I enjoy the print output when it's configuring the namespaces, but
there's no need for so much yelling :) (s/TOR/Tor/) [1]
3) Keep in mind, using torsocks is not the same as using Tor's
4) Please be aware of the problem with using "tor" in the project's
name [2].
[1] [2] Have you looked at bubblewrap? It's a nice and simple namespacing
utility, too.

@_date: 2018-07-24 23:18:39
@_author: Matthew Finkel 
@_subject: [tor-talk] torjail - run programs in tor network namespace 
This is a list for empowering each other and building a community and
technology for helping those who are in need around the world. Please
refer to our social contract [0], if there's any confusion. Please do
not confuse spelling Tor, as requested, with someone who is very excited
and yelling "TOR!" or maybe a heading on a slideshow saying "TOR
This isn't about punishment, we're simply asking people follow the
request of the community and people who build this community/technology
and put their time, energy, and life into it.

@_date: 2018-03-06 12:57:39
@_author: Matthew Finkel 
@_subject: [tor-talk] Tor4 
This isn't related to your below question, and it's not related to Tor,
so this topic should be dropped.
There is much need and want for more applications using onion services.
Yes, TorChat gained popularity (mostly due to its name) but it was never
a program the community was comfortable promoting or using. Recently,
Richocet has become a popular application for communicating. OnionShare
is also widely used. There are email providers using onion services, as
Indeed, IPFS is an interesting project. It gained support for using
onion services, too. The last comment is very important:
"We want to get all of IPFS and libp2p audited before we start
encouraging people to use it with TOR. Unfortunately, this will take a
Although it would've been nice if they correctly spelled Tor.

@_date: 2018-03-25 16:00:25
@_author: Matthew Finkel 
@_subject: [tor-talk] Intercept: NSA MONKEYROCKET: Cryptocurrency / 
Nope, this was included in the original Bitcoin paper, there's nothing
new about that. The fact that the United States government agencies
targetted the system and private comanpies is new, but not surprising
given what we know of their (dubious/unethical/illegal) historical
But this is now off-topic from onion routing, so this thread shouldn't
For reference:
The traditional banking model achieves a level of privacy by limiting
access to information to the parties involved and the trusted third
party. The necessity to announce all transactions publicly precludes
this method, but privacy can still be maintained by breaking the flow
of information in another place: by keeping public keys anonymous. The
public can see that someone is sending an amount to someone else, but
without information linking the transaction to anyone.

@_date: 2018-05-01 18:05:36
@_author: Matthew Finkel 
@_subject: [tor-talk] Tor Browser "Sandbox" Development Status? 
Please see both warnings at the top of the page (in particular the
Where did you find the download link?
Creating a Sandboxed Tor Browser on all platforms is something we really
want, but it is non-trivial and requires more research and time.

@_date: 2018-05-18 18:26:41
@_author: Matthew Finkel 
@_subject: [tor-talk] GNOME Is Removing the Ability to Launch Apps from 
Do you have any links about this? This is an interesting development.

@_date: 2018-11-25 16:07:21
@_author: Matthew Finkel 
@_subject: [tor-talk] Get relay information from the "Network Status 
You'll probably be interested in reading the official consensus document
specification [0].
The short answer is: if you have the relay's fingerprint encoded in
base16 (hex), then you'll need to convert it to base64. The result is on
the r-line in the field next to the relay's name. The section from
the specification says:
   "Identity" is a hash of its identity key, encoded in base64, with
   trailing equals sign(s) removed."
I usually use python for this, because it's relatively easy, but there
may be an even easier methods.
If I want to look at maatuska [1] and I know it's fingerprint encoded in hex
is BD6A829255CB08E66FBE7D3748363586E46B3810, then I convert the encoding
into base64 with:
$ python
Python 2.7.15 (default, May  9 2018, 11:32:33) [GCC 7.3.1 20180130 (Red Hat 7.3.1-2)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
This takes the hex string and converts it into binary, and then takes
the binary and converts it into base64. You'll want the result not
including any '=' and new line at the end - vWqCklXLCOZvvn03SDY1huRrOBA.
So, looking at the current consensus:
$ torsocks wget We can see Maatuska has this r-line:
   r maatuska vWqCklXLCOZvvn03SDY1huRrOBA 8Ws9cPzBQWrlqtTZJWKFEixvz1Y 2018-11-25 09:42:37 171.25.193.9 80 443
Hope this helps,
[0]

@_date: 2019-04-16 18:08:16
@_author: Matthew Finkel 
@_subject: [tor-talk] tor in arm 
Thanks for your interest! "this shit" isn't appropriate for this
mailing list, please be respectful to everyone here.
For Tor Browser on ARM we have an open ticket for it [0], we may begin
supporting it within the next few months, but we've had too many other
higher priority tickets. If you're comfortable with compiling it
yourself, there is a git branch available for review/testing you can
try (without any guarantees) - but let us know if you're successful :)
Unfortunately, I don't have any other alternatives, sorry.
- Matt
[0]

@_date: 2019-04-27 02:41:48
@_author: Matthew Finkel 
@_subject: [tor-talk] How Tor Browser changing circuits for tabs? 
You may find this section of the Tor Browser design document
of interest:
You'll want to look at torbutton. The code for providing first-party
isolation (FPI) is part of the domain isolator (in particular
The circuit display is controlled by this:
NEWNYM controls the state of the entire tor process, there isn't a way to
apply NEWNYM on a single circuit or stream. The way Tor Browser controls
the connection is via SOCKS5 username and password authentication. Tor
doesn't care what values you send, but it will isolate connections that use
different usernames and passwords.
I hope this helps.

@_date: 2019-07-02 14:06:17
@_author: Matthew Finkel 
@_subject: [tor-talk] stay clear from exit "BSDNow2016" 
Hi nusenu,
Thanks for this info!
What was the decision by the bad-relays@ list members? Unfortunately,
"Please avoid this
exit node" is not a very good solution because recommending every user
exclude one node does
not scale to millions of users (unless Tor Browser ships this
configuration, but that would be a sad
path for Tor Browser). :/
- Matt

@_date: 2019-06-10 12:27:38
@_author: Matthew Finkel 
@_subject: [tor-talk] Tor Browser Android 8.5.1 obfs4 Bridges Problem 
There was a chat about this on IRC. The current thought is this relates to
one of the recent bridge bugs, like
I'm most confused because the notice-level logs and CIRC events show
the client successfully established a connection with the bridges, but tor
does not mark them as usable. I haven't looked at the referenced ticket,
so maybe there's a reasonable explanation how they're all related.

@_date: 2019-03-27 16:46:06
@_author: Matthew Finkel 
@_subject: [tor-talk] tor project website change 
Hi Udo,
The website design started at least 6 years ago, if not longer. Multiple
people worked on it and made it possible. The new website provides a
more welcoming interface, in particular for new users. Now the page is
concise and provides links for exactly the version a user likely needs.
If the user needs/wants another version (in another language or if they
want the Alpha version), then they are contained on a subsequent page.
People don't want too many options, they simply want the correct/best
option. This new design provides this for them.
If you have specific suggestions for improving this new design, then
please let us know. It seems you would like easier access to the tor
download page, I also don't see this. This is be a good improvement,
thanks for letting us know.
- Matt

@_date: 2019-03-29 12:12:21
@_author: Matthew Finkel 
@_subject: [tor-talk] tor project website change 
Not explicitly, the link at the top of the new site for "Documenation"
goes to that domain.
- Matt

@_date: 2019-05-03 13:50:35
@_author: Matthew Finkel 
@_subject: [tor-talk] [tor-relays] ALL GREYPONY SERVERS ARE OPEN FOR DDOS 
Just so we all have the same understanding here, no one should send or
respond to emails like this. Just like harassment, threats (even idle
threats) are not acceptable here.
Thanks, in advance, for your decorum.

@_date: 2019-11-19 20:53:00
@_author: Matthew Finkel 
@_subject: [tor-talk] loading some content changes Tor Browser 9.0 to full 
Sorry for the delay, thanks for your questions.
It never changed. That comment is a suggestion, it was never
implemented (as far as I know).
Fullscreen is only available if it is initiated by a user clicking on something.
 says:
  // Only grant fullscreen requests if this is called from inside a trusted
  // event handler (i.e. inside an event handler for a user initiated event).
  // This stops the fullscreen from being abused similar to the popups of old,
  // and it also makes it harder for bad guys' script to go fullscreen and
  // spoof the browser chrome/window and phish logins etc.
  // Note that requests for fullscreen inside a web app's origin are exempt
  // from this restriction.
This also prevents leaking screen dimensions on a webpage unless you
explicitly click on an element that invokes full screen.
Yes, this still leaks real screen dimensions, as Mike discussed in
Disabling fullscreen is not a good solution. We have another ticket,
where the user is prompted before fullscreen is allowed, for that:
The maximize button is not the same as requesting fullscreen, in
general. With letterboxing, maximizing the browser does not (should
not) leak real screen dimensions.

@_date: 2019-10-02 17:33:28
@_author: Matthew Finkel 
@_subject: [tor-talk] TBB and Importing Cookies. 
Interesting question.
Nope. Without more information it's difficult guessing why this happened, too.
In addition to installing the new add-on, did you modify Tor Browser in other
ways? Which add-on did you use for exporting/importing the cookies? It sounds
like "importing" the cookies for mail.google.com failed for some
reason. Did you try
clearing the cookies in Firefox and import them there? And was that successful?

@_date: 2019-10-23 19:39:28
@_author: Matthew Finkel 
@_subject: [tor-talk] TorBrowser is only showing a black windows after 
Hi, thanks for reporting this!
When you describe seeing a black window, does it look like the
screenshot on this bug?

@_date: 2020-02-23 02:53:42
@_author: Matthew Finkel 
@_subject: [tor-talk] TBB "Security Level" Question. 
To be clear, the "Security Levels" are a simple wrapper around NoScript. It
provides three options (Standard, Safer, Safest), therefore Tor Browser users
should only be divided into three groups based on the respective properties.
The situation is more complex than this because Tor Browser reveals more
distinguishing information than the "security level" you selected. Some users
also customize their Tor Browser by installing additional extensions - they are
likely particularly unique.
In newer installations the NoScript button doesn't appear next to the
address bar. You can only access the NoScript configuration through
about:addons now.
Yes, there may be some "security" ramifications. The "security levels" were
created, in part, because in the past some features in the browser had bugs
(vulnerabilities) that we potentially exploitable. By increasing the "security
level" in the browser, there is a trade-off with increasing breakage on the
web - sometimes that breakage is decreasing usability (click-to-play) or no
javascript on unencrypted connections, etc. If a vulnerability in Tor Browser
is exploited such that a connection can be made that bypasses the tor proxy,
then this will reveal your real IP address (under normal circumstances).
Correct. Tor Browser's default configuration is significantly more privacy
preserving than all other browsers available today. In addition, Mozilla has
made significant progress in hardening Firefox, and consequently this has
improved Tor Browser's hardening. If you are really concerned about your IP
address being revealed, then you should either use the Safer or Safest level,
or don't use the Internet (or use Tails or Qubes).
Yes, this is another trade-off between usability and letting everyone create
custom rules for every website they visit.
- Matt

@_date: 2020-02-24 00:01:20
@_author: Matthew Finkel 
@_subject: [tor-talk] Validating the DA authority document 
"Tor" [0]
Good, I assume you already read the dir-spec? [1]
With respect to keys, it's important to understand which keys exist
and how they are used.
In the "how version 3 should be better than version 2" section (0.2):
      * The most sensitive data in the entire network (the identity keys
        of the directory authorities) needed to be stored unencrypted so
        that the authorities can sign network-status documents on the fly.
        Now, the authorities' identity keys are stored offline, and used
        to certify medium-term signing keys that can be rotated.
Therefore, we know authorities has (at least) two keys, their identity key and
their signing key.
Looking at section (appendix?) B "General-use HTTP URLs",
   The key certificate for this server (if it is an authority) should be
   available at:
      This document provides all public keys associated with this authority, so you
are following the correct path.
The document (currently) contains four public keys, along with some metadata
(see 3.1. Creating key certificates for more details):
  1) version number of this certificate
  2) the authority's identity key fingerprint
  3) the period for which this certification is valid
  4) the directory's long-term (RSA) identity key
  5) the directory's medium-term (RSA) signing key
  6) a signature item 4 using the medium-term signing key
  7) a signature over items 1-6 (plus the header of 7) using the long-term
     identity key
In particular, see section 1.3 for how a signature is computed over a document.
You can take the public keys and process them with openssl, if you want to
sanity-check your implementation (either paste the key directly on the command
line as input to this command, or provide it in a file and add the |-in
  $ openssl rsa -RSAPublicKey_in -noout -text
  [snip]
  RSA Public-Key: (3072 bit)
  Modulus:
      00:ed:c6:57:bc:34:71:7e:30:d8:b6:bf:7f:f5:4b:
      10:f3:9d:be:e9:c9:87:32:bf:15:56:1f:06:90:bc:
      1b:ab:74:73:aa:39:14:2f:04:36:47:d9:85:bc:6e:
      05:9e:a3:1c:30:a5:e2:eb:6a:d8:60:0d:df:64:bd:
      5a:7e:14:fc:d3:87:29:bf:2a:7f:0f:77:4f:33:c4:
  [snip]
The important piece of this part  that you should notice is that this key is
using the RSA Public Key PEM format.
Following from the above, next, if you want to validate the signature on
this certificate using openssl apps, then it is a two-step process (as far
I can figure out):
  1) Obtain the digest of the document to-be-signed
  2) Get the digest from the signature
  3) Verify the two digests are identical
For (1), you can obtain this with:
  $ openssl dgst -sha1 -binary tor26-certificated_text | openssl base64
For (2), you can obtain this with:
  $ openssl rsautl -verify -inkey tor26_id_key -pubin -keyform PEM -in
tor26-certificated_text.bin.sig | openssl base64
(As a side note, I tried very hard getting openssl dgst to validate this
directly, but it expects the signature as a DigestInfo without padding and I
don't know how to transform the sig into that format.)
In the above example, |tor26-certificated_text| is the certificate excluding
the final signature (as defined in section 1.3). |tor26_id_key| is the identity
public key converted from PKCS RSAPEM format to X.509 SubjectPublicKeyInfo
PEM.  |tor26-certificated_text.bin.sig| is the the signature at the bottom of
the file, with the SIGNATURE header and trailer stripped, and base64 decoded.
For the PEMRSA to PEM conversion, I used:
  $ openssl rsa -in tor26_rsa_id_key -RSAPublicKey_in -pubout -out tor26_id_key
When you obtain the two digests, then you can byte-for-byte compare them
however you'd like.
In the above example, I chose to encode them in base64 so that I could easily
compare them on the command line. You can leave them as binary data and compare
them however you'd like.
If the two digests are identical, then the signature is valid.
I'll skip the cross-certification signature and leave that as an exercise :)
Verifying the signature on a network-status document follows the above pattern,
except in this case the directory authority's signing key is used instead of the
identity key.
The dir-spec explains that the signature is over the data beginning with
"network-status-version" and ending with "directory-signature ".
Similar to the above commands:
  $ openssl rsautl -pubin -inkey tor26_signing_key -in
tor26-consensus-consensus_signed.bin.sig | openssl base64
All signatures appended on the consensus (should) be over the same digest, so
it doesn't matter which signature you use.
The digest of the consensus follows similarly:
  $ openssl dgst -sha1 -binary consensus_signed | openssl base64
I assume whichever crypto library you're using provide an API for directly
verifying a signature over the document, so as long as you are using the
correct public key and the correct header of the document, then
verification should be "easy". I hope this helps point you in the
right direction.
- Matt
[0] [1]
