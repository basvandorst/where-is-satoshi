
@_date: 2013-04-29 20:51:32
@_author: Guido Witmond 
@_subject: [tor-talk] Tor's reputation problem with pedo, 
Hi Chris,
Here, in the Netherlands we have the hotline[1] to report sites
containing child porn. They will evaluate and report to the proper
authorities. Other countries may have similar hotlines.
It should be safe to report there, although I guess they already know about onion sites. I'll inquire with them but guess it will take a few days to get an answer, due to queen/king issues these days.
However, given the nature of onion sites, I don't know how the police
investigators could track and take down the source without defeating the
anonymity of Tor.
Perhaps the authorities already do and leave *us* in the dark. :-)
1:

@_date: 2013-04-29 22:15:08
@_author: Guido Witmond 
@_subject: [tor-talk] Tor's reputation problem with pedo, 
No you can't stamp out the problem, it's a human/brain thing. And taking
down the images doesn't solve the abuse, that has already happened. It
does prevent the victim (child) of running into it later in life.
Especially with more and better image tagging software, who knows what a
google glass image recognition system might display when it matches a
person on the street against an old image of child abuse?
Eradicating the supply is - in my opinion - the best we can do to help
the victims. And so is removing the links on the directories.
I believe, reporting the onion sites to the hotline is a good thing, but
I'm awaiting their answer(s).
PS. anonymity is good. Even for pedophiles who would like to get help
with that. There is also a anonymous hotline for them.

@_date: 2013-04-29 22:47:01
@_author: Guido Witmond 
@_subject: [tor-talk] Tor's reputation problem with pedo, 
To answer two questions at once:
There is no single right solution! And there is no easy solution. Never.
With censoring child porn. I believe it's a good thing. To help the
Abusing that censorship to censor political speech: absolutely not.
And there are many shades of grey. Blocking known criminals that peddle
malware: yes please. Even though I believe we should strive for better
operating systems that are immune to these attacks. Having a censor
blocking these sites makes my life easier so I don't have to *second
guess* every website out there. That only makes me paranoid.
Like most things, it's a matter of balance. And eternal vigilance. And
oversight over the censors. Guarding the guards. I certainly want to
hold my censors accountable.
Even better, let me select my censors to my liking. Filter child porn
and criminals and politicians that I don't like all you want. I decide
whether to use your filter or not.
Let's make sure there is always Tor to overcome too restrictive censors.
Regards, Guido.

@_date: 2013-08-08 10:41:33
@_author: Guido Witmond 
@_subject: [tor-talk] TOR bundle on hostile platforms: why? 
Quoting from the article:
just accept that you have to trust Microsoft and Symantec and, for
That's what I'm trying to address with my protocol. [0]
I've come up with a way that lets each web site run its *own*
certificate signer. It signs the server certficate and puts that into
DNSSEC with DANE. This removes the need for trusted third parties.
That same certificate signer also signs client certificates. The client
certificate is the *account* at the site.
As the web browser can validate the server certificate at connect time,
it can check that the server certificate root matches with the client
certificate root. Only if they match, the browser will log in.
No need to trust anyone. Verification is at the heart of the protocol.
In fact, users won't see the crypto at all.[1]
The proof of concept is in a web proxy and you test it at [2]
[2]

@_date: 2013-03-29 00:10:33
@_author: Guido Witmond 
@_subject: [tor-talk] Mozilla Persona and Tor 
I guess, you perhaps should read on...
Agreed. It would be cool if it was limited to these.
In my not so humble opinion: Persona requires an email address!
Email addresses are Personal Identifying Data!
Email addresses are a scarce resource for most of the worlds' people. Even for the enlightened few that have their own domains. Or the people that can use xxx+ like addresses if the site and their provider allows it.
IMHO: The only way to use Persona privately is to use a throwaway email address for each different site.
Regards, Guido.

@_date: 2013-05-23 14:38:57
@_author: Guido Witmond 
@_subject: [tor-talk] [OT] Generating a web site 
Self signed client certificates already work with Firefox. It's more private and secure with less hassle. But again only firefox.

@_date: 2013-09-11 13:49:00
@_author: Guido Witmond 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
You might consider either of these options to make people aware:
1. Log in to gmail and set an autoreply that you've changed your address
and that you won't be using gmail anymore and that people have to resend
to your new address;
or more user friendly to the people who want to reach you
2. Log into gmail to set a forward to your bitmessage account. Set
auto-delete at gmail on. Configure your local mailer to set an Reply-to
header to your new address, so people will respond to the correct
address. (also notify in your signature message)
Use what you prefer.
This way you reach everyone who might have missed your address change
announcement. Otherwise, these people might get annoyed when you don't
respond to your gmail address anymore.
Both methods tell Google that their current ways are not accepted. I'm
sure they monitor how many people stop using gmail and start forwarding.
Together with the reduction in traffic.
Best not to close the gmail account entirely to prevent reuse of your
accountname by someone else. Let it die a slow death.
Cheers, Guido.

@_date: 2014-01-22 15:52:24
@_author: Guido Witmond 
@_subject: [tor-talk] Spoiled Onions 
End-to-End encryption where both the server and the client certificate
are signed with the same CA (that of the site) protects against this
attack. Each site runs its own certificate signer for their own
visitors. Clients are known only by a unique (or autogenerated)
nickname. Not by their real identities.
When a client connects to a site, it validates the server certificate
and uses only client certificates signed by the same Certificate Signer
to authenticate. If there is a MitM, it cannot create a valid server
certificate that matches that of the site.
Without DNSSEC, this is a TOFU (Trust on first use) validation. There is
a chance that a user gets a rogue end point at the first connection.
With DNSSEC, the site owner publishes their own Certificate Signer Root
I call it Eccentric Authentication. It is not meant for activists and
criminals but for the normal internet user.
I believe that before we can protect activists, we need to protect
ourselves first. (It's the first rule of First Aid: protect yourself or
you are the next victim).
Regards, Guido Witmond.

@_date: 2014-03-10 13:11:13
@_author: Guido Witmond 
@_subject: [tor-talk] Another fake key for my email address 
Hi Errin,
The problem you mention here is that there is no way to verify who a
certain public key belongs to.
I could not even verify yours. I've downloaded both keys above from the
keyservers into gpg. One key has no signatures at all, the other key has
more than 30 signatures, none of those signers are known in my (small)
keyring. I'm none the wiser. And my mail reader doesn't even try to
match email-address to public key fingerprint. It won't raise an alarm
when there is a mismatch. Thunderbird/Icedove lets me do the hard work.
To play Devils' Advocate: It could be that I'm replying to an impostor
claiming to be Erinn Clark. I have no way to check. Only by
investigating the use of both keys throughout the history at the
internet archive, I might be able to discern which key belongs to Erinn
and which is the impostor.
Heck, I had an email conversation with some people of the CCC where they
used one of my gpg-keys to encrypt their message and I used a different
key to sign my reply. Their mail program didn't alert, neither did they
spot it.
I don't blame them. The PGP/GPG web of trust is not designed to
introduce strangers to each other. It's designed to let people who've
met in person to encrypt their email communication. And extend that to
their circle. And when the web of trust would succeed in spanning the
globe, it would form a social graph that makes Faceboogle look like
The cause of this dual-key problem is that that an email-address is seen
as the identity, while in fact, the public key is the identity, as there
is only one private key that fits the public key.
Humans can't deal with key fingerprints. They use the email address as
What's needed is a way to let computers verify that the human readable
label (email address) is unique and maps to the same public key. This
makes the human readable name a true substitute identifier for the
public key.
I've come up with a scheme that does that. I call it
Eccentric-Authentication. It could solve the MitM problem for web-sites,
it could solve the spoiled onion exit nodes problem. And it offers
people to create new encrypted communication channels where none existed
And best, a user agent takes all the hard crypto-problems out of the
hands of the end user.
Check out: With regards, Guido Witmond.

@_date: 2014-03-11 13:30:46
@_author: Guido Witmond 
@_subject: [tor-talk] X509 S/MIME certificate. Was: Another fake key for 
Replying to my own post:
I would like to offer my suggestion for a solution to this problem.
GPG has shown it only protects if someone can trace a path through the
web-of-trust that they can trust.
The Tor project has a different requirement. It needs to have a world
wide global identity that states who is the package builder. Verifiable
to anyone. Without them to enter the web-of-trust. That would defeat
their anonymity requirements.
The protocol for that is:  *X509 S/Mime*.
I don't consider that to be a 'dirty word'.
An X509 certificate is effectively like a digital passport, verifiable
to anyone who trusts the CA that signed it.
The global cabal of Certificate Authorities are not the ones to provide
that trust. For the sole reason that there was never a way to tie a
domain name to a certificate authority. Any CA could sign any domain
name. And every browser would accept every CA, shifting Erinn's problem
to the torproject.org level.
With DNSSEC and DANE, we have that missing link. DANE allows site
operators to specify what CA they use for their site. It could be
allows to set up your own CA and specify that.
Here's why I think it can be used to solve the impersonated key problem:
1. The torproject admins create a private key and a self signed Root
Certificate, say 4k RSA.
2. The admins create a server certificate for  and
sign it using their own Root Certificate.
3. They publish the Root Certifificate fingerprint (or the whole public
key) in a TLSA (DANE) record and sign their DNS-records with DNSSEC.
These steps let every browser validate (via DNSSEC delegations) which is
the Root Certificate for Torproject. The Firefox extension "Extended
DNSSEC Validator" does that.
4. Then the project members create a private key and request a
certificate at the admins. The admins sign it with the correct flags.
Erinn would get a S/MIME certificate with message signing and object
signing capabilities. Jacob could get a message signing certificate but
no object signing.
I, not involved in torproject except as relay operator, would not get a
certificate bearing the torproject name at all.
This is how the admins can delegate trust. I can trust the
torproject-admins not to signs two different certificates bearing the
name Erinn. And I can trust the tor using community to oversee the admins.
Each of the Tor project members would keep their GPG-keys for private
communication. S/MIME signed messages are for project use.
With regards, Guido Witmond.

@_date: 2014-03-11 21:52:49
@_author: Guido Witmond 
@_subject: [tor-talk] X509 S/MIME certificate. Was: Another fake key for 
Public response to a private message
Hi, (xxx)
DNSSEC and DANE change the landscape.
1. With DNSSEC and DANE you don't need one of the global CA certificates
anymore; You can run your own CA. If that proves too difficult , you
might outsource it to one. This puts the global CA in a position where
they have to provide value for service, instead of just rent-collecting
for a green url-bar.
If these global CA's are smart they would offer services where they will
guard your own Root CA key. But I can dream...
2. DNSSEC itself is quite a hassle to set up and run correctly too. It's
best to outsource that to a DNS-registrar. Although this is still a
niche market for DANE records in DNSSEC, the same market forces apply.
If not satisfied with one registrar, take your domain name and shop for
another registrar.
3. The registrars in the DNS-hierarchy can still be persuaded to delete
your certain domain name. (censorship.) Or point it towards a different
server (hijacking). I'll show later how to protect against that.
When everyone can run their own Root CA, all sorts of new avenues open up.
With their own Root CA, companies can provide certificates for their
spokespeople. Or they can sign certificates for clients (at a slightly
different domain name). This way, banks can send out encrypted
statements directly to customers. No more emails asking you to log in
with a username and password. This reduces MitM attacks drastically.
It increases privacy, I would have a certificate for each of my banks,
one for my pension fund. Another at this mailing list and yet another at
another mailing list. My browser would keep them apart.
With a small addition to the browser, it can make sure that it only
offers me client certificates to log in at the server whose server
certificate has been signed by the same Root CA. This makes logging in
even easier for the end user. And it really eliminates MitM-attacks.
While crooks can create a pixel-perfect copy of a banks' site, the
crooks cannot impersonate the Root certificate of the bank, so the
browser will correctly identify the crooks' site as a different site and
not offer my banks' client certificate to log in. My browser protects me
against phishing.
We can go one step further. It is the Root CA of a site that is used to
select the client certificates that the browser offers the user to log
with. The domain name is not used in the selection. It means that the
site owners (who own their own Root CA) can create a new domain name,
sign a server certificate using their root CA and point these new
DNS-records to their server. The site has changed domain name but the
client certificates stay valid. How's that for censorship resistance?
But that is the realm of what I call Eccentric Authentication.
With regards, Guido Witmond.

@_date: 2016-02-22 22:03:17
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; introducing Eccentric Authentication 
Dear Tor community,
I came across this message[1] about Shari Steele wanting to bring Tor to
the mainstream. I humbly believe I have something that might assist her
in this quest. I call it Eccentric Authentication.
The Eccentric Authentication protocol is designed for situations where
people - who haven't met each other - exchange public keys in a
verifiable way. This happens in public. It's the opposite of a darknet
protocol where people can only communicate after being introduced.
In short:
1. Eccentric Authentication is a protocol between a site and its users.
2. The site acts as platform where people get introduced to each other.
3. As part of the introduction process, the user agents of each of the
participants verify that there is no Man-in-the-Middle active.
4. Once verified, the users can each create a Tor hidden service, send
the address and port number in an encrypted message to the other. If the
other person is interested they can connect to the hidden service and
reach the first person.
The first three steps happen in the open. It's where the introductions
get done. The last step is where people set up encrypted tunnels through
Tor to connect in private. What they send over the tunnel is up to them.
For example:
A blog site lets people post blog messages. After signing up, bloggers
sign these messages using their private key. Each user has their own
private key(s), at least one for each site.
Readers who come across the site can read anonymously and verify the
message signatures.
If an anonymous reader would like to respond in public, they sign up for
an account and they too sign their messages before publication.
If either the blogger or responder wishes to send a private message,
they can use the others' persons public key after validating there is no
MitM. Message transport goes through the site. After a few round trips
of messages, there is certainty there is no MitM. They can now create
their Tor tunnels and send the details to the other.
Participants can stay as anonymous as they wish. It's only the site that
needs a public identity. The users participate without providing any
personal information, not even a name or an email address or other long
lived contact mechanism. A client certificate is all that's needed. The
site runs their own CA and signs the client certificates for the users.
The users' client certificates are devoid of personal information. All
that's needed to sign up is a fresh key pair and a chosen nickname.
There is no need to sign up with a email address or other identity.
There is no way to contact that user if they destroy the private key to
that certificate. The user stays in control.
If people create a fresh Hidden Service for each introduction, they have
complete control over when the other can contact them. This might be
very useful at a dating site where one be able to break off all
communication from an individual by destroying that hidden service endpoint.
About Meta data:
Anything that people do on blogs is signed with their certificates. This
is public data. However, each user creates a fresh public key and a new
nickname for each site. There is no easy linking of identities between
disjunct sites.
As the initial message exchange between two strangers goes via the site,
it can log this. As such, there is a correlation between sending private
messages through the site and the creation Tor Tunnels. This means it's
very unlikely that people who haven't sent a private message through the
site to communicate with each other. This might be mitigated a bit by
probabilistic sending of chaff messages that look like real traffic.
However, the bulk of the interesting traffic flows via hidden services,
out of sight of anyone, including the site. But again, this protocol is
designed for people to participate in public yet communicate in private.
There are a lot of technical details. For those and other use cases of
eccentric authentication, please visit my site:
  Eccentric-Authentication.org.
With regards,
Guido Witmond.
1:

@_date: 2016-02-23 19:31:44
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
The answer is to let strangers - who never met before - exchange public
keys in a verifiable way.
After the exchange is verified to be free of MitM's, they can
communicate in private via Tor.
All while staying anonymous.
Guido Witmond.

@_date: 2016-02-23 22:04:20
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Indeed, verifying strangers doesn't make sense.
But the moment that two strangers wish to communicate, things get
When people meet in person, they immediately know whom the are talking
names. Most people would recognize the other when they meet again. We
use face, voice, posture, way of expression, hairstyle, clothing,
eyewear, etc to recognize each other.
This is very nice property to have in digital communication: *Being able
to recognize someone with whom you have communicated before.*
It would be easy create such a system if privacy was no concern: sign
every message using your government provided digital identity card.
Tyrannical governments love this.
The challenge is to have that recognition property *while remaining
So, I envision that people who have never met online don't need to know
of one other.
But as they meet at a website, a mailing list, a dating site, a web
shop, a blog, a forum etc, they want to be able to recognize each other
and be able to send private messages that no one else, including the
site/forum operators can read.
Being private is something we take for granted in real life. We usually
know when other people can hear our conversations and when not. With
digital communications we need to encrypt the communications to protect
it against eavesdropping. That's the third property: *Protect against
There is one more: In real life, it's very hard for someone to
impersonate someone who you have met before. Most people would treat the
impersonator as a different person from the one they remember.
That leads to a fourth property: *Identities must be hard to spoof.*
This combinations of properties is the goal:
- being able to recognise others;
- while remaining anonymous;
- be able to send private messages;
- and being able to detect MitM's.
And with Tor in the mix, we can prevent most meta data of whom is
communicating to whom, when and how long.
And that's what I want to achieve.
With regards, Guido Witmond.

@_date: 2016-02-23 23:49:37
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Hi Allen,
Good questions.
Each message is associated with an identity. There may be multiple
messages bearing that same identity. That makes is a pseudonym.
But the protocol suggests (strongly) to create a new private key for
each site. That makes my 'facebook' posts independent from my 'twitter'
As there is no need to provide more than a nickname and a public key (no
email address) at signup, there is no way for both to collude and link
my identities. I could even employ multiple 'facebook' or 'twitter'
identities, separating work and private accounts, etc.
If I want to respond anonymously to a message, I could create a new
identity just for that purpose and destroy the private key afterwards.
In those respects it's more anonymous.
I expect a combination of both. Some identities I treasure and I want to
build a reputation on them, other identities are throwaways at a web
shop, or to troll at a forum.
Axiom: The more one uses an identity, the less anonymous it gets.
You are correct that every key represents an identity. The computer has
no problem keeping them apart. But humans do. The amount of entropy in
each key is too large for humans to handle.
That's why I let people chose a nickname at signup time. I'd chose a
nickname of guido at tor-talk (if available) to build my reputation here.
I'd chose a more random anon-15245325486 at facebook to respond to
someone's timeline.
Secondly, with the requirement that nickname at sitename.tld to be unique,
I could write that nickname on a business card and hand it out. People
could verify at a verification service that there is only one
certificate (and public key) for that name and be sure to have gotten
*my* public key. From that point, they can send encrypted messages to me.
If that sitename.tld is my own domain (and as such my own CA), I can be
sure that no one else has the ability to sign certificates to
impersonate me. Hence I can exchange a certificate by just writing a
nickname at sitename on a business card. How more human friendly can you get?
With regards,
Guido Witmond.

@_date: 2016-02-24 23:04:39
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Granted, it's secure to print a fingerprint on a business card but it's
not so user friendly. And as studies[1] have shown, most 'normal' people
won't be as judiciously with fingerprint validation as the security
minded. And I believe both groups deserve the same strength in security.
Would you use this service if all you'd have to do is type in the users'
nickname at site and your computer would validate if there is only one
certificate attached to that name. If so, you can be sure that only the
intended recipient can decrypt it. If the computer would find multiple
certificates - or none at all - it would give an error and doesn't allow
communication because it couldn't determine the correct public key to use.
Or what about being able to scribble a nickname at site address at the back
of a beer coaster in a bar.
My drive is to make key exchange happen as a natural part of normal
interactions between people. Not as a separate step that could be
neglected, forgotten or done wrong.
Regards, Guido Witmond.
1a: Why Johnny can't encrypt.
1b: Engineering Security, by Peter Gutmann.

@_date: 2016-02-25 00:26:02
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Teaching is not a solution. See Peter Gutmann's book Security
Engineering. 800+ Pages of disasters with security. Depressing and
enlightening ;-)
I don't want *people* to exchange keys. I envision people to exchange
names and let computers do the key lookup.
For example, I get the id at site name from a nice lady I met at a bar.
It's just like an email address but slightly different.
At home, I type in that address and my computer searches the validation
service for the key. If all is well, there is *one* public key. That
must be the key of the lady. If there is none, she may have given me a
wrong address, or I may have made a typo. In these cases, it's like she
gave a wrong telephone number.
If there is one public key, it must be hers as her computer checks for
duplicates to protect her privacy. Or it's the name of some stranger,
and after an embarrassing moment, I understand I can't reach her until
we meet again in person.
If there are duplicates, she must find another site as it violated the
protocol. She would do so as she won't get any responses from the people
whom she gave her correct address. Those people would reject the
duplicates and move on. (That's the protocol requirement.)
If she gave the correct id at site and there is only one public key, I can
send her encrypted messages that only she can decrypt. Now we can talk
in private. And when we use Tor, we hardly leave any meta data.
So the exchange of a human readable name - the id at site - implies that I
can deduce the correct public key. The one-to-one relationship between
names and keys makes it easy for humans to excahnge a name and for the
computer to figure out the correct public key.
So, to answer your question: people communicate id at site names, the
computer verifies the uniqness properties to determine the corresponding
public keys. The requirement to make the relation between names and
public keys is key. Pun intended.
I hope this answers your question.
Regards, Guido Witmond.

@_date: 2016-02-25 23:05:51
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Hi krishna e bera,
Good question.
Regrettable, I don't have an answer. I can solve the MitM problem in
certain cases but not in general.
Thank you for challenging me with the question. Below is the writeup to
the partial solution and the description of the general problem with
MitMing. And I have a new challenge.
First there is a difference between the issuer of client certificates
and the validation service. These are different entities. And these must
be run by different groups to prevent collusion between them.
The site runs its own CA. It signs both the server and client certificates.
Users choose their nickname @ sitename.tld as CN and supply a fresh
public key to be signed by the site's CA. This nickname is the user's
human readable identity. The CA must sign each CN only once. That is,
there may not be two certificates bearing the same CN. If there is one
occurrence of a duplicate, the site loses its trustworthiness and the
user agents should report that to the user and not connect there any more.
The sites existence depends on it not to get caught signing duplicate
CNs. The rest of this post is about detecting a duplicate.
Users are encouraged to post their certificate containing the CN and the
public key to the verification service after acquiring the certificate.
The verification service registers each certificate, that is: {CN,
public key} tuple that it gets offered. If it detects two or more of the
same CN with different public keys, it raises an alarm.
When users post public messages to sites, they sign it using their
private key. The signature gets posted along the message (hidden using CSS).
A user who posts a message should verify that it gets posted correctly
by the site, ie, with the user's signature, not a duplicate or a whole
new identity.
When readers are browsing around a site, the user agent verifies some of
the certificates at random at the verification service. The user agent
sends the certificate to the validation service and receives all
certificates on file bearing the CN. There should always be one. If
there are multiple, it's proof of misconduct.
But suppose a site does create a duplicate certificate of user A and
shows it to user B. Assume that certificate 'a' and 'b' have been
submitted to the verification service.
User A posts a message at the site. A -> m,Sa(m) -> site
The site creates a duplicate certificate c, with a public key that
matches a site controlled private key but it bears the users' A CN.
So B expects: m, Sa(m), but instead gets: site -> m, Sc(m)
If B would check the verification service it would learn of the two
certificates bearing the same CN. Busted.
But B doesn't check the verification service and wants to send a private
message to A and hands it of at the site for delivery.
B ->  Ec(m, Sb(m)), Sb( Ec(m, Sb(m)) ) -> site
That is: sign(encrypt(sign(message)))
The site decrypts the message and re-encrypts using A's public key a. It
could encrypt the inner signed message, but it can't recreate the outer
signature, as the site lacks the private key of b.
If the site would create a duplicate for b, that would be detected by A
who does check at the verification service.
So the site/CA cannot create duplicate certificates bearing the same CN
as these will be detected quickly. That was the amount of badness I
imagined at first.
The site has to create a new identity D with a fresh CN to be able to
sign(encrypt(sign(message))) for A.
Site -> Ea(m, Sd(m), Sd( Ea(m, Sd(m)) ) -> A
A believes he got a message from D while B believes he's talking to A
because he didn't check it.
The site could have forgone the dangerous step of creating a duplicate
certificate for A and create a fresh identity in the first place. That
won't trigger duplicate detection. Then A believes he's talking to D and
B believes he's talking to C.
And that is one weakness for which I haven't gotten a solution yet: a
hostile site scraping content from other sites - or even it's own - and
luring others to initiate private messages that are relayed to the
original writer by the hostile site, completely MitM'ed.
They can only detect this attack by mismatches in the content. For
example, B mentions to A "I saw your message at site Y" while A has
published it at site X.
So my challenge is: how to detect or prevent this attack.
Regards, Guido Witmond.

@_date: 2016-02-25 23:46:45
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Luckily, any sufficiently advanced technology is indistinguishable from
magic, so to my audience - the normal user - it looks like that :-)
There is good news, anyone can run this protocol on any domain. It's not
limited to companies. In fact, running it on your own domain gives you
the security that no one can be messing with it.
Everything has a price. Only sunlight is free, after paying the
rent/hotel/wood for the fire under the bridge to survive the night. :-)
Seriously, the requirement is that each sitename is unique and can't be
abused by others than the owner. That way, each user at sitename is unique.
And that's to make the one-to-one relationship between names and keys.
There might be stronger systems than the current DNS registrars. A
sitename in a Namecoin system springs to mind. The issue is that it's
used by a very small group.
But take it from me, I'm in favour of stronger naming systems than DNS.
It's quite brittle in respect to coercion.
Public key fingerprints are a solution to both problems.
Except that people won't check these things. You do, but I want a system
that works for people who don't/can't verify those.
Cheers, Guido.

@_date: 2016-02-26 21:31:46
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Hi Paul,
All from cursory reading:
Both Keybase.io and Eccentric Authentication share the same goal: Crypto
for everyone!
But there are differences:
1. Technology
- Keybase uses PGP, Eccentric uses X509;
- Keybase uses the Bitcoin blockchain as trust anchor, Eccentric uses
DNSSEC and a separate verification service like Certificate Transparency.
2. Model
- Keybase has a person centric key model:
Even though people can have multiple private keys, these are connected.
Each user has 1 identity. That means, every message sent is attributed
to the person.
In this model, each of the actions strengthens the faith in the relation
between the key and the identity.
- Eccentric uses a key model where each user has many keys:
Each of those keys is an identity, tied to the site that signed it. Keys
cannot be shared between sites. This prevents linking of identities
unless the person reveals it. Or if cookies betray him.
In Eccentric, people are advised to use a throwaway identity whenever a
site requires an identity. In Keybase, it's much harder to remain
anonymous as I expect sites to encourage linking your account to your
3. Central / Dispersed
Keybase uses a central repository for all key/identity announcements.
This makes them a single high value target.
Eccentric uses a single CA per site. There is no central repository. The
risks of compromise are spread out. With some proper use of subkeys, the
scary part of key management can be outsourced to a service provider.
4. User Security
Keybase provides confidentiality of the message contents but as it uses
existing email transport, neglects meta data protection, in fact it
gives up meta data protection to gain stronger ties between usernames,
keys and identity.
Eccentric offers much stronger protection of meta data and equals
protection of message confidentiality. With Eccentric it's harder to
assure a certain key belongs to an author of a publication.
There's probably a ton more. If I made any mischaracterisations of
Keybase, please enlighten and forgive me.
With regards,
Guido Witmond.

@_date: 2016-02-27 13:18:08
@_author: Guido Witmond 
@_subject: [tor-talk] Tor for everyone; 
Hi Zenaan,
Thank you for all these questions, I'll answer them to the best of my
But first, please accept the premise that I don't want to cast Keybase
in a bad light. On the contrary, they are trying to solve the most
difficult problem on the internet:
*How to find the correct public key of a person.*
I respect Keybase for their work and I think that their model has a good
chance of getting adoption in their target area: linking identities
between several social sites to strengthen the link between names and
public keys.
I've tried to create an objective comparison between them and me, not a
value judgement. Apologies for my bias that have crept in.
On to your questions
A hash table does a lookup from HASH(data) -> data.
When I retrieve the data, I can calculate the hash and determine if I
got the correct data.
What I want is a lookup of name -> public key.
I could set up a DHT that does HASH(name) -> public key but there in no
user name in the public key, so there is no way to calculate that I got
the correct data.
Would I create a DHT based on HASH(name) -> certificate, where
certificate is {name, public key, CA-signature}, I still have to
validate if I got a result from the correct CA. The question that
remains: who is the CA chosen by .
I'm not sure which fundamentally broken model you are referring to.
I've tried to give an objective comparison, not a value judgment. The
blockchain is suitable as a trust anchor. I haven't found a need for it
yet in Eccentric.
On the contrary, it's their fundamental design decision. Tying several
identities together strengthens the relationship between identity and
public key. It's how Keybase solves the most important question.
Indeed, I find it scary to link all aspects of my life into a single key.
I'm a strong believer in keeping separate contexts of my life separate.
Humor is a good example. Thing I say to friends in jest are not funny to
people who weren't there at that time. That same words could mean
something entirly different in a different context.
Or take the example of a boss who doesn't hire a candidate based upon
drunk pictures on facebook. That candidate could have a good social
life, going out with friends, getting drunk once in a while but not
getting in trouble.
Or take the person who drinks at home. Why does he drink? Is it because
he's out of a job, then hiring him may find you with a very motivated
Keybase doesn't offer me that separation.
I try to solve the same key lookup question (which is the correct key
for a given name), but I want to keep contexts separate. And that's a
different goal.
If keybase gets big, I probably use them to link some of my identities
into one but I keep that network small.
- have you discussed this "limitation" with the keybase
Keybase and I solve for different goals. We might learn from each other,
no doubt, but I don't see a need to integrate.
People should consider each proposal on their merits.
I'm not even sure yet that I've solved all the avenues where MitM could
sneak in. I'm not sure that there is a general solution, it's probably
impossible to be anonymous and have complete protection against MitMs.
In that regard, I'm a NIH dope, going down avenues that no one else took
to see where it gets me. Even if it doesn't get me anywhere, the journey
is fun.
But the things that I find, I publish on my site, for others to poke
holes in it.
And last Thursday, someone just did. [1]
I've got my information from reading their site: keybase.io.
Again, different design decisions.
They are aware of it and moved to the bitcoin blockchain for that reason.
This is a valid concern. Keeping the private key secret is the ultimate
burden of every use of cryptography.
But we already have that burden. Every https-secured site needs to keep
the private key secret. Every DNSSEC signed domain name has two private
keys. Every bitcoin address is a public key that belongs to a private key.
Please see the nitrokey.com HSM as one offering to help keys secret.
I expect that in the eccentric model, most CA keys will be managed by
hosting providers. It will be one more service in their offering,
hosting, DNS, Eccentric CA. Just keep your root key on your HSM.
The CA provides the one-to-one mapping between usernames and keys. It's
my answer to the question at the top.
The eccentric protocol demands that the CA signs each  @ part
only once. This is easy to do in software and easy to verify with an
verification service. If a site ever signs two different public keys for
the same , the protocol requires all user agents to warn their
users about this broken promise and consider that site untrustworthy.
The benefit of this requirement is that I can write my on the back of a beer coaster and give it to someone. That person
verifies at the verification service that there is just one certificate
that bears my . If so, that person has got my public key and
can encrypt messages to me.
It's a method to tie keys to usernames so people can do the lookup of
name -> public key. See the question on top of this message.
If answering the big question isn't enough value, the eccentric protocol
also offers phishing protection where anonymity isn't required, such as
electronic banking.
Their value (to users) is to make it easy to find the correct key for a
username so users can send encrypted messages without worries about a MitM.
Indeed, people could create a different keybase identity (in a Tails VM)
to separate their contexts.
I'm investigating how such an infrastructure can be build. Please see
the eccentric-authentication.org site and read through the archives.
This is current research on how to make it easier.
I offer mechanisms to make it easy to use cryptography correctly. So
people can be safe against eavesdropping, MitM, remain anonymous when
they desire.
I hope you find it interesting.
With regards, Guido Witmond.
1:

@_date: 2016-02-28 20:26:48
@_author: Guido Witmond 
@_subject: [tor-talk] Time for p2p, content addressed, 
Mass Surveillance, Sabotaging Traffic
Hi Zenaan,
Take a look at  , a censorship
resistant publishing project.
Now how can we get hosts behind Cloudflare to publish in Freenet.
Regards, Guido Witmond.

@_date: 2016-02-28 22:53:13
@_author: Guido Witmond 
@_subject: [tor-talk] trusting .onion services 
Hi Rejo,
I think that in general, .onion addresses are unauthenticated. That is,
there is no way of determining who an address belongs to.
All we know of an .onion address is that its tied to whomever holds the
private key. And given the risk of disclosure of the private key, all
bets are off. This is also true of GPG, where an adversary can create a
clone key bearing my name but their key. Erinn Clark of the Tor Project
has been a victim of such an attack.
In my pet project I'm using Hidden Services as a means for people to
connect to each other. One person opens a HS, send the onion address to
another in an encrypted message. The other connects to the service. Then
BOTH people authenticate to the other with their already exchanged keys
before their software lets the data flow commence. Knowledge of the
onion address or even having a copy of the private key won't get the
connection started.
In short, I built an authentication layer on top of hidden services.
That authentication layer uses PKI certificates and stuff to distribute
public keys to each other. And ultimately, the same issue reappears:
Whom am I talking to? And with risk of disclosure of the private key,
all bets are off.
I believe this to be a fundamental property of cryptography. The eternal
uncertainty of the identity of the other party. The more anonymous the
key exchange the higher the uncertainty. In other words: the higher the
need for secrecy and anonymity, the greater the uncertainty.
The answer you are looking for is to determine how much of a risk there
is with plain onion asdresses, or what extra authentication and
repudiation you need to build on top. And how much deanonymisation you
are willing to accept.
I believe it's ultimately a design trade off.
With regards, Guido Witmond.
