
@_date: 2014-04-09 19:21:53
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] strange behavior of Tor Browser on Windows 8.1 
Hash: SHA256
I have upgraded to latest Tor Browser Bundle version: 3.5.4 - Windows
32 bit.
My operating system is Windows 8.1 Pro Enterprise, 64 bit.
The odd things i have noticed (which didn't happen in previous
versions) are:
1. Some kind of cookie / session handling issue, i cannot login to
mail.aol.com , after entering credentials I get this error:
Authentication Problem
Uh-oh! Your sign-in got derailed. We?re on it?sorry for the delay.
Click here to try again.
If you use a bookmark to get to AOL Mail, update it to
 .
Browser security settings sometimes disrupt sign-in. In Internet
Explorer, try selecting ?Enable Protected Mode? in both the Internet
zone and Trusted sites zone . On Firefox, try using Safe Mode .
You also might try deleting your browser history. Find this in the
?Tools? menu ? and make sure to clear (delete) cookies!
For complete instructions, click here.
If you?re unable to access your account for more than two hours,
please tell us.
2. Portable application issue: Windows doesn't see the portable
firefox within the Tor Browser Bundle as a portable app, I have
firefox normal installed for normal browsing and Tor Browser Bundle
and run them simultaneously.
I use CCleaner from Piriform to clear the cookies, history and cache
stuff. In the previous versions of tor browser bundle, i could close
my regular installed firefox and leave Tor Browser Open, and CCleaner
could clean everything with no error.
now with the latest version of Tor Browser, i close my regular firefox
but CCleaner when I run CLEAN states that firefox is opened and needs
to close in order for it to clean the cookies and cache stuff.
 Why so?

@_date: 2014-04-12 12:16:18
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] IMPORTANT: Heartbleed vulnerability impact on Hidden 
Hash: SHA256
After seeing the challenge done by CloudFlare, to setup a server open
to the internet with that vulnerable OpenSSL version so everyone could
try and get its private keys (to see if it's actually possible), after
speaking earlier with people in  IRC channel, we think it's a good
way to find out for sure if the Hidden Services could have been
compromised or not. And if yes, make a more serious and visible banner
to notify them. Because so far nobody has changed the Hidden Service
address, from all the Hidden Services I am using.
I don't want them to be exposed to risks and when something happens,
yet another thing which will be blamed on Tor.
So, to developers and special reference to arma, proposition:

@_date: 2014-04-19 15:39:03
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] bleeding relays rejected, 
Hash: SHA256
Reading the dev list yesterday I saw that a scan was performed on all
the relays in the Tor network and the ones vulnerable to OpenSSL
heartbleed had their fingerprints listed with a !reject argument by
the directory authorities.
So far so good, but what about the bleeding bridges and obfs bridges?
Was that database scanned for bleeding bridges too? Since these act as
entry guards this is important.
It wasn't clear from what I've read yesterday if the scan was only
over the normal relays (not bridges which are not advertised in the
Tor network) or on everything, including the bridges. If we are
talking about second scenario, I apologize in advance for asking again
but just wanted to make sure and get a confirmation.

@_date: 2014-04-23 18:48:02
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] US ip address 
Hash: SHA256
You can set a static exit node in your torrc but that is not
recommended at all as it will have impact on your anonymity.
Always remember that Tor works for you best when you use it as it
comes "out of the  box" with no customization whatsoever - this will
camouflage you with the other many users, making something customized
puts a highlight on you and individualizes you from the users.
So, you can set an US relay as your default exit relay to use only
that US IP address, but you are doing the wrong thing.

@_date: 2014-08-05 14:49:59
@_author: s7r 
@_subject: [tor-talk] Tor weather is broken 
Hash: SHA1
Tor Weather is broken for many weeks now.
It still sends reports when node is down (I can confirm this) but you
cannot subscribe with a new fingerprint - it gives you Error Internal server error.
maybe someone can fix? I know Weather is old and not working anymore,
but the uptime reports can be quite useful some times when you simply
don't have time to attend at your computer for 2-3 days.

@_date: 2014-08-13 19:40:49
@_author: s7r 
@_subject: [tor-talk] The Tor network doesn't support Named relays anymore 
Hash: SHA1
That is a good thing as the Named/Unnamed flags were pretty useless
anyway. I have opened a ticket on trac notifying that I've tried to
list MyFamily via nicknames instead of fingerprints, and for the
relays which had the "Named" flag Tor mapped nickname to fingerprint
just fine and proper fingerprints where showing in atlas/globe, but
for relays with Unnamed flag, Tor wouldn't map nickname to fingerprint
and output error.
Looks like Named/Unnamed flags disappeared from the consensus, checked
all relays all working just fine, the same like before.

@_date: 2014-08-20 04:02:20
@_author: s7r 
@_subject: [tor-talk] Who do I ask about purchasing additional Tor 
Hash: SHA1
So if the Torproject can't help you out, we would be happy to send you
It's a T shirt for crying out loud. you buy it to support an
organization you like and to wear a message you agree with / support.
I don't think it will last as a Louis Vuitton one.
Are you buying it to wear it at a wedding or a super important meeting?

@_date: 2014-08-20 04:30:49
@_author: s7r 
@_subject: [tor-talk] Who do I ask about purchasing additional Tor 
Hash: SHA1
I am sorry, I ment no disrespect, no sarcasm. Just saying that when
you pay ~25 eur for a T shirt and you know the material is good
(cotton, no synthetic stuff which smells funny) don't know what else
you might expect from such a T shirt. Probably their lifetime depends
on more factors like usage, washing times, bla bla :) clothing theory.
When I buy such a T-shirt I only look for the material, if it's cotton
then I buy it thinking I indirectly support a project or organization
I care about. The longer it lasts, the better but this is last on the
Hope it sounds better now.
Thanks for this.

@_date: 2014-08-29 18:47:57
@_author: s7r 
@_subject: [tor-talk] warns in logfile about onionskin length and non-OR 
Hash: SHA1
Anyone can explain what this warnings are and if they are reason for
[warn] Unexpected onionskin length after decryption: 58
[warn] Tried to establish rendezvous on non-OR or non-edge circuit.
First time I  get them on a relay running continuously for over 5 months.
Thank you!

@_date: 2014-12-14 18:10:34
@_author: s7r 
@_subject: [tor-talk] Tor and solidarity against online harassment 
Hash: SHA1
I can see a lot of FUD spread around here regarding Roger and the NSA.
First of all, Tor is free, open-source and its usage is not enforced.
Feel free to use it if you trust it, if not that's ok with the rest of us.
Second, I can't understand how some people think that, if Roger was
colluding with the NSA or other LEA to undermine Tor's values or
implement some kind of a backdoor, this would not be somehow be ket
secret. The reason why it is public is exactly because there is
nothing to hide in a polite collaboration for various topics.
Who can think that a LEA will make information available to the public
which could directly or indirectly disclose their involvement in
something they want to keep secret? Like hey, how stupid the NSA and
Roger were to make this information public, and how smart that person
who read this in Roger's CV was and said: Caught ya! You are working
for the NSA to backdoor Tor. 100 points answer.
I might add the fact that Tor is not at war with LEA. Of course its
goals are to ensure perfect anonymity for everyone, but if a LEA wants
to have a discussion and ask more about Tor and how it works, why
couldn't anyone with knowledge (including but not limited to the Tor
developers) talk to them? It's always better for everyone to be
properly informed. LEA is not something evil, as some people suggest
directly or indirectly here, to the contrary, they are doing their
jobs and Tor devs are doing theirs, but there _has_ to be diplomacy
otherwise the thousands of years of human evolution are wasted.
I am not saying under any circumstances that the NSA or other LEA are
not trying to spy/crack Tor, just that it's done via other means
outside of the control of the Tor devs.
Last thing, receiving donations from the govt. has nothing to do with
a backdoor either. Those money come as a donation and are tax
deductible from fiscal law, and some agencies are _required_ to spread
a certain % of their money to non profit foundations working on
different things depending on their domain of activity. Once you make
a donation, it's a donation by definition so you are not entitled to
put any conditions, like ask for a certain feature or something,
except the entire organization wants it too.
If the money were given to control the development of Tor, they would
be smarter than this and not fund Tor directly as it happens now. You
think it's that complicated for the US govt. to find a big corporation
with interests in the same field and proxy the money through them?
Please think more before you accuse somebody who you don't even know
or ever met.

@_date: 2014-12-16 02:43:33
@_author: s7r 
@_subject: [tor-talk] concurrent HS connections limit and guard traffic 
Hash: SHA1
Was wondering if there are any theoretical limits for the maximum
possible concurrent connections to a Hidden Service via a single Tor
instance  - asking from the Hidden Service server point of view.
Excluded are CPU and bandwidth factors - are there any other factors
which can act as a bottleneck here?
One would be, the way I see it, the guard server. Since a Guard is
selected randomly and kept for longer period of time, let's say a
Hidden Service selects a Guard with low bandwidth resources (lowest
allowed by directory authorities in order to make it eligible for
receiving the guard flag). Now, this Guard also handles traffic for
other clients too, simultaneously.
Since the Guard's bandwidth resources are low, the Hidden Service
server can be a ten-gigabit one, it won't matter, since all the Hidden
Service traffic will go through the Guard, and that will be the
A Guard by default, does it make any rate-limiting for Tor traffic per
client? Let's pretend my guard server gets selected to be the Guard
for a high profile Hidden Service which handles a lot of traffic. This
single client will consume all my bandwidth - will the default Tor
settings do anything to rate-limit it in any way? Will I still handle
other clients too, simultaneously?
Apologies in advance if I said something terrible stupid.

@_date: 2014-12-20 00:18:12
@_author: s7r 
@_subject: [tor-talk] My relay isn't being listed in Atlas or Globe? 
Hash: SHA1
Your relay indeed does not appear in atlas or globe, yet it has the
following flags in the consensus:
So, it _is_ running.
Looked it up on onionoo mirror on  and
doesn't appear either.
Maybe onionoo it's just a cache problem and we should wait little more
In the mean time, keep an open eye on the Tor log file and watch out
for errors as well as the periodic heartbeat where Tor will tell you
how many circuits it has and how much data has sent/received.
Other way to look for your relay is:
(warning: big page)
and ctrl + f in browser for Find, type the name of your relay and you
will see what Directory Authorities have to say about your relay.
Hope this helps! Thanks for running a relay.

@_date: 2014-12-22 19:47:35
@_author: s7r 
@_subject: [tor-talk] Anonbib November papers without papers 
Hash: SHA1
hey Sebastian,
Many thanks for taking care of this! anonbib is an important resource.
Could you please also add one more entry and include this research
paper with date September 2014? I am trying for over 1 week to find
time to do it but need to learn how to use bibtex/git.
It was announced here:
And the research paper is here:
We already have a fix for it suggested by Paul which seams fairly easy
to implement and shouldn't affect more than the load in the network
and on each relay:

@_date: 2014-12-23 18:26:32
@_author: s7r 
@_subject: [tor-talk] Anonbib November papers without papers 
Hash: SHA1
Ok, sent the additional bibtex entry to anonbib at freehaven.net. Does
this address automatically adds the entries to the page source code or
someone manually reviews everything?

@_date: 2014-12-25 16:26:42
@_author: s7r 
@_subject: [tor-talk] (Slur.io) running over Tor 
Hash: SHA1
To me it looks like a fund raising website as they ask for donation
and have a fixed amount they want to reach in a month, however there
is no explanation about how exactly will the system work, something
like a whitepaper or protocol description from 1000 feet. It just says
very few things about arbitrage and public key cryptography as well
that it'll run over Tor.
This _could_ be a scam, so caution. Maybe the only interest here is
fund raising, and since you donate the money anonymously via bitcoin
only, and you don't know who you are giving to (nothing like a legal
entity or legal registered non-profit, company, individual or group of
individuals) you have no control, guarantee or transparency in
regarding what happens to the cash.

@_date: 2014-12-27 04:49:20
@_author: s7r 
@_subject: [tor-talk] Is there a representative of the LizardSquad on this 
Hash: SHA1
If Thomas White, who runs exit relays for long time and actually keeps
them online by continuing to pay for the invoices out of his own money
looks dumb, maybe you can explain to this community what is the use of
your approx. 3500 relays who never even got the chance to touch a big
fraction of the traffic in the network since they were blacklisted
before they were properly measured by the Directory Authorities.
If it's not a sybil attack or an attempt to grow the directory data
with annoying and irrelevant data, what is it then?
Are you willing to sustain 3500 exit relays for long term?
There were others who tried to find vulnerabilities in Tor, but the
approach was more open and transparent with the development team,
since a good 'test' is always welcomed by everyone. Nobody tries to
hide or run away from such a test in this community.

@_date: 2014-02-25 02:39:16
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] how relays upgrade to latest version of Tor 
Hash: SHA1
When a new version of Tor is released, one which makes significant
changes to routing rules, covers security vulnerabilities, etc. - how
do all the ~6000 relays upgrade to the latest version automatically
and simultaneously so the peers in the network can talk to each other?
On a normal client which uses the Tor Browser Bundle, the update does
not take place at all unless the user does it manually. Is it the same
case to relays? It has to be, since some normal clients act as relays
also in order to help the network (this is my case also).
So, when something with important changes takes place - how are all
the peers in the network convinced to upgrade simultaneously and

@_date: 2014-02-27 22:24:05
@_author: s7r 
@_subject: [tor-talk] about circuit management 
Hash: SHA1
I have remained with Vidalia and installed it as standalone in order
to be able to use it with newer Tor Browser Bundles releases and I am
watching circuits to have an understanding about how they work. I have
some basic questions, please and thank you in advance:
1) What is the lifetime of a circuit? For example if I connect via Tor
to my email server, Tor will select 3 routers randomly and make the
connection. For how long will the circuit stay up? When will it
change? Of course, taking in consideration none of the relays get
disconnected from the Tor network. Is it a lifetime set for circuit?
Or a bandwidth traffic consumption limit?
2) For example when I access the website aol.com it has multiple
resources which are hosted on other servers, other IP addresses and I
can see a bunch of circuits on ports 80 and 443 just to be able to
load the entire content of the website. Does Tor know that all these
resources are for the same page, and should choose the same circuit
for all the same like the parent circuit, or it chooses randomly?
This is important because if a website is let's say trying to track
user behavior and they see an IP address as REMOTE_ADDR and if they
track another image hosted on other server, paired with a session ID
to know it's the same session and that image gets requested from
another IP address than site can be sure the user is using an anonymizer.
3) NTor circuit extension - don't ALL relays support this?
4) A connection to a hidden service - does it have a lifetime? I can
see when I access a hidden service that more circuits are opened. Is
there a lifetime for these or can I stay connected to the hidden
service forever as long as all relays in my circuit stay online?

@_date: 2014-07-02 18:56:29
@_author: s7r 
@_subject: [tor-talk] Tor Exit Operator convicted in Austrian lower court 
Hash: SHA1
The subject of this attracted my attention. Are we talking here about
a clear law, written black on white which states that it is illegal to
run Tor relays (or any kind of telecommunications proxy servers) and
that you are responsible for your user's actions, even if you provide
those services free of charge, therefor not required to collect any
data about your users? Is it actually a specific law which was
enforced here clearly stating that you cannot run Tor or open proxy
Or are we talking about just one decision from a judge who probably
didn't do a proper reading and analysis before applying this decision?
Or maybe the person charged with this was actually doing something
illegal? Anyone has more details?
If so, shouldn't the EU legislation protect you against such an abuse?
In some countries, quite a lot of them actually, there is even no
definition in the law whatsoever for open proxy servers or
telecommunications internet traffic. Internet is (from legal point of
view, no technical - new invention. Tor is newer and science fiction
for the vast majority of people). Does this mean in those countries
you can run anything you want? Or not run anything because you to to
jail for ANOTHER penal code, which makes vague reference about this too.
That is nonsense. Why not arrest the owners of a stainless steel blade
factory, because some people stab other people with those blades.

@_date: 2014-07-02 19:48:41
@_author: s7r 
@_subject: [tor-talk] Tor Exit Operator convicted in Austrian lower court 
Hash: SHA1
That's a fine argument. You recommend me shutting down all my exit
relays? Or what should I understand out of that argument?
Totally agree on this, but that is not what we were discussing.
If I use my direct internet connection to commit something illegal,
why not charge my ISP as well for offering me the infrastructure to do
what I did?

@_date: 2014-07-03 03:54:32
@_author: s7r 
@_subject: [tor-talk] Tor Exit Operator convicted in Austrian lower court 
Hash: SHA1
In the blockchain I saw a pretty good fed of BTC to his donation
address - folks in the community didn't turn back on this. With that
sum donated there he could arrange for a top lawyer, minimum. I don't
know what was the exact rate when he cashed those into FIAT anyway but
still it was something.
Probably all was needed to be done was to explain to that (those)
judge(s) exactly how Tor works, what it is and how is it not different
than running an ISP or simply NOT securing your wi-fi at home with a
password. As it was said in previous messages, this case has gone
terribly wrong for many reasons - but could have been easily won
without spending huge amount of money and without any fancy lawyers. A
basic newbie lawyer could have won this.
Be sure there is. I feel the same way, it has to be.
If there was NOTHING on those servers except Tor, those would have
been returned to him long time ago, from my point of view. I am just
saying and asking myself out of curiosity, I am not making
suppositions nor accusations and is none of my business - this should
be irrelevant, period.
If you are doing illegalities and use Tor to keep you anonymous, and
you want to give back and run a relay, when you are convicted or
prosecuted you are not so because of that relay. But if you are law
abiding citizen going to work or doing some business within the legal
and social limits, and running a relay to support free speech,
innovation and freedom of information it's hard to ever be charged
with anything (hopefully) - I sincerely hope this is a legal error
because of lack of communication and it will not create a precedent.
They should think how to add more relays to the network and make it
bigger, faster, safer. With each new relay operator all existing relay
operators are stronger.

@_date: 2014-07-03 17:42:48
@_author: s7r 
@_subject: [tor-talk] Tor Exit Operator convicted in Austrian lower court 
Hash: SHA1
You will be amazed of the quality of some important people inside Tor
community and torservers.net organization, and the kind of help they
are willing to offer, regardless if it's financial, legal, technical
or you name it.

@_date: 2014-07-13 21:16:33
@_author: s7r 
@_subject: [tor-talk] Hidden service 1024-bit 
Hash: SHA1
What is the status of this proposal? Is it close?
Maybe we can borrow some functions and ideas from i2p eepsites, which
load faster and etc. and implement them in our next generation's
hidden service.

@_date: 2014-07-23 17:42:00
@_author: s7r 
@_subject: [tor-talk] Almost everyone involved in developing Tor was (or 
Hash: SHA1
This is some nice piece of troll fuel, I got to say.
The fact that Tor receives donations from US govt. is not a secret,
never intended to be one, and everything is done in a transparent
manner. If the US govt. would want to sabotage people by launching a
"honey-pot" anonymity network, I think they would have been much wiser
than doing it like Tor model. The sponsorship from the US govt. only
shows us that there is still "some good" in the govt. and not
everything is compromised into violating rights of freedom and free
If you think that it's bad 'just because it was invented by the
military / at their request' please note that a very big percentage of
inventions which changed the world and life of people were invented
either by the military either for the military. Please stop using a
razor blade immediately if using one, because it was invented for the
army if you read its history.
Apparently these days the best way to launch your shitty company and
make it known is not to pay for advertising, better and free to issue
a press release that "We found a bug in Tor, Tor is broken, Tails is
broken, EC cryptography is broken and used as a honey-pot, etc.". This
will generate a lot of noise on the internet. I can't count how many
times the Tor Project site states: 100% anonymity is not guaranteed,
Tor doesn't come with any warranty, this is EXPERIMENTAL software, a
lot of your anonymity depend on your actions, etc. What could be more
clear than this? Nobody is forced into using Tor, but there isn't any
alternative and it really works IF YOU KNOW HOW TO USE IT.
P.S.: I sent to a Tor user a customized .doc file which loaded some
external images from a server under my control. That user was not
using a sandbox or isolated environment and opened the document so I
logged the user's REAL IP ADDRESS when it fetched the resources!!!! I
BROKE TOR, HAVEN'T I?

@_date: 2014-07-24 20:51:50
@_author: s7r 
@_subject: [tor-talk] ISP surveillance. 
Hash: SHA1
it is irrelevant if your IP is static or dynamic - the ISP has that
data tied to a broadband internet access account so they know it's you
either way, regardless your IP type.
Using Tor will encrypt your data totally with multiple layers, this
means that your ISP can see that you are using Tor, and nothing more.
They can't see what sites you visit, what data you download,
intercept, modify or alter the data you download, can't see if you are
accessing hidden services and what hidden services, etc. Bottom of the
line, your ISP can see you are using Tor and that's all, nothing more.
Using Tor is not a felony under any circumstances.
If you don't want your ISP to learn you are using Tor, you can choose
to connect to the Tor network via an obfuscating bridge (make sure you
choose obfs3 pluggable transport) and in this case your ISP won't even
see that you are using Tor, it will see obfuscated random traffic,
inconclusive traffic.
Go to  fetch your obfs3 bridges and put
them in your torrc for Tor Browser or at startup when booting Tails do
not select "This computer's connection is free of obstacles", choose
to enter a bridge, and enter your bridge previously fetched from

@_date: 2014-06-06 03:30:45
@_author: s7r 
@_subject: [tor-talk] Security concerns with running an exit relay 
Hash: SHA1
Well there is nothing magic about it. Just run it as you would any
server, keep it maintained and up to date and of course don't easily
allow remote access to it so somebody can fish it at first mass scan.
Install the latest stable version including its dependencies and make
sure you run up to date versions for all you have installed on the server.
Make sure you use NTP to sync the time and have accurate time on your
server - Tor needs the right time, especially if you are a relay. A
good practice is to run ORPort on 443 and DirPort 80 for easy
connectivity, and include a DirPortFrontPage argument to point to a
html file which explains what Tor is and that the said IP is a Tor
exit router. You can find an example for this page if you google "this
is a tor exit router" and modify the content slightly according to
your needs.
If you are an exit relay it is recommended you run your own recursive
DNS resolver on localhost too (BIND). Use a DirPortFrontPage argument
in torrc
I suggest you don't run the relay on your computer. Find a reasonable
ISP and rent a server / virtual server, run it from there. If you
google "how to install tor " you
will find plenty tutorials. Just edit the torrc file to act as a
relay. Provide a good contact email address, so people can contact you
and enter your exit policy. I would recommend you to block just port
25 SMTP, to prevent spam. But if you host you relay in a
torrent-unfriendly place, block higher ports also for p2p. But, p2p by
definition cannot be really permanently blocked (via destination:port)
no matter what.
If you find trouble in doing it or if you have any other questions
mail me.

@_date: 2014-06-11 03:14:36
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] Norse Darklist, for blocking Tor 
Hash: SHA1
How is this any more helpful than making your own scripts which
regularly fetches the Tor nodes list from torproject.org?
Usually blacklist means one more problem, not one fixed problem. Tor
blocking should be history by now, I can't even imagine people still
blocking Tor thinking all troubles are over when anyone could run a
proxy over Tor (a compromised computer with IP not blacklisted
anywhere) and still remain anonymous. Thinking to block Tor is ...
"amazing" :-)

@_date: 2014-06-18 00:48:28
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] draft letter for financial institutions or other third 
Hash: SHA1
I've spoken today with someone who had to back off in running a relay
from home because his IP address was blocked from accessing a
financial institution website. Quite uncomfortable.
I have made a simple non-technical draft letter to educate these
parties about Tor. It can be found here:
Spread it around and/or edit it, share it via any ways if you find it

@_date: 2014-03-10 01:31:29
@_author: s7r@sky-ip.org 
@_subject: [tor-talk] MaxMemInCellQueues questions 
Hash: SHA1
Hi Onions,
Reading the blog post with the DDoS possible attack to terminate
relays by making RAM memory scarce, I would like to ask the following:
In Tor versions > 2.4 a defense against these types of attacks was
deployed (MaxMemInCellQueues). MaxMemInCellQueues shall kill circuits
when RAM memory gets low based on cell lifetime (?oldest circuit(s)?).
The post says:
"There is likely not one single value
that makes sense here: if it is too high, then relays with lower memory
will not be protected; if it is too low, then there may be more false
positives resulting in honest circuits being killed."

@_date: 2014-11-13 18:03:27
@_author: s7r 
@_subject: [tor-talk] Clearnet/Onion access  for website 
Hash: SHA1
You couldn't possibly have provided less details than this. I assume I
don't have to go back to the genesis and also provide details of how
to install Tor for your operating system - this is pretty easy to
If you don't care about hiding the actual location of your server and
want to run your hidden service on the same server with the clearnet
site (makes sense if it's the same thing and non-hidden) you should
just instruct your webserver (apache or whatever you use your
hostname.onion as a ServerName or ServerAlias for the virtual host of
your website and add to your torrc:
HiddenServiceDir /path/to/your/tor-hs-dir  this is the location
where you have the private_key for your onion hidden service.
HiddenServicePort 80 127.0.0.1:80
P.S. By default a webserver will listen in most cases on all available
interfaces (including local loopback - 127.0.0.1) if you have this
setting customized, you need either to change the IP from
HiddenServicePort with the one where the web server is listening
either set the web server to listen on localhost too.

@_date: 2014-10-28 00:30:32
@_author: s7r 
@_subject: [tor-talk] 
=?windows-1252?q?=28Alex_Biryukov_/_Ivan_Pustogarov_story=29?=
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Here are some Bitcoin reliable nodes sponsored by Thomas (TheCthulhu)
accessible via Tor hidden services:
All use Bitcoin default port 8333. These servers are up all the time
and very fast.
Hidden services are end-to-end encrypted so the risk of MITM between
nodes does not exist. Also, if you run bitcoin in such a way with
onlynet=tor enabled in config, nobody listening your wire can have a
slight clue that you use bitcoin.
We think tor-hidden-services only Bitcoin nodes are a very important
part of the Bitcoin ecosystem.
Getting them running is quite simple. You just need disk space, at
least 50GB free for now. Here are some guides:

@_date: 2014-10-28 01:32:04
@_author: s7r 
@_subject: [tor-talk] 
=?windows-1252?q?=28Alex_Biryukov_/_Ivan_Pustogarov_story=29?=
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Totally agree about undermining decentralization by having to trust a
single provider. Nobody recommended that, the addresses were for
informative purpose only, to be used in parallel with other nodes run
by other operators / organizations. No user is forced to use
exclusively peers run by the same operator. An user is free to add as
many hidden nodes for bootstrapping as desired.  Once connected to a
node that node will exchange information about other nodes and so on.
I agree the hidden services are old. There is a nice proposal,
hopefully it will be analyzed more and implemented as soon as possible.

@_date: 2014-10-28 23:30:25
@_author: s7r 
@_subject: [tor-talk] 
=?windows-1252?q?=28Alex_Biryukov_/_Ivan_Pustogarov_story=29?=
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
One question: how did you configure your Bitcoin node to be functional
on v4,v6 and .onion at the same time?
For example, the Tor hidden service node needs to have the following
setting in bitcoin.conf:
This will teach the daemon the .onion IP address it needs to advertise
to other peers. It has no other way to learn this address except if
you manually copy/paste it in bitcoin.conf
I don't know how this affects the v4 and v6 interfaces, do you have
multiple externalip= arguments in bitcoin.conf (in order to advertise
the public v4 and v6 addresses too)? Is it possible this way?
Can you please remove the sensitive data and copy/paste your
bitcoin.conf? I am interested only in Listen=, Bind=, proxy= and
externalip= as well as other connectivity entries.
I don't run Tor hidden bitcoin nodes and clearnet nodes at the same
time on the same instance (or even on the same server). I run bridge
Bitcoin nodes in parallel. The bridge Bitcoin nodes help broadcast the
information received from other Tor hidden peers to clearnet peers
(since we do not want an island or a separate network - the clearnet
and Tor hidden services network need to be glued together as a whole
A bridge Bitcoin node is configured as a regular clearnet Bitcoin
node. Additionally, you install Tor, and simply add in bitcoin.conf:
Where 127.0.0.1:9050 is the Tor socks5 listener. Substitute the port
if different. This setting tells the bitcoin daemon about the channel
to reach .onion peers. For the rest of the clearnet peers it will use
as default, its own public IP. Now this node exchanges information
with .onion peers and clearnet peers simultaneous just fine,
broadcasting the information from Tor hidden peers to clearnet peers.

@_date: 2014-10-30 19:02:36
@_author: s7r 
@_subject: [tor-talk] 
=?windows-1252?q?=28Alex_Biryukov_/_Ivan_Pustogarov_story=29?=
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
I still think that doing MITM over a Tor hidden service requires more
than just computing power to break 80-bit crypto security, as opposite
to if you were trying to MITM something with 80-bit security in the
clearnet. There are additional layers of encryption in Tor with better
To be able to perform MITM over a Tor hidden service both the  HS
client and the HS server have to choose a total of 6 compromised
relays controlled by the same attacker. Someone has to be very very
unlucky, the odds in this context are insanely low.
Or maybe I am not understanding MITM as I should in this context - I
think MITM in the traditional way, not impersonating the HS,
performing DoS attacks on it or DoS attacks over the Hidden Service
Directory relays responsible for feeding HS descriptors to the clients.
Having a hunch that someone might have started a bitcoin node and
downloaded the entire blockchain (if that someone didn't download it
via other means previously) is not equal to an observer being able to
see when you actually USE bitcoin (how often and other metadata, like
when you send a payment for example).

@_date: 2014-10-30 20:18:36
@_author: s7r 
@_subject: [tor-talk] 
=?windows-1252?q?=28Alex_Biryukov_/_Ivan_Pustogarov_story=29?=
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
How will bitcoind know when it is used with Tor in order to use max. 4
non-HS peers? You mean when onion= is set? Or if the socks5 address is
127.0.0.1:9050 bitcoind assumes it is Tor and adopts the corresponding
By default, a non-HS (normal) node will have in peers.dat file both
clearnet nodes and HS nodes?

@_date: 2014-10-31 14:50:39
@_author: s7r 
@_subject: [tor-talk] Facebook brute forcing hidden services 
Hash: SHA1
It is not that simple. What makes you think they generated exactly the
URL facebookcorewwwi.onion completely? They need to show some more
information about how they did it... There is also a chance that they
took a very long time to generate facebook*.
As I said, only they can tell us exactly.

@_date: 2014-09-16 11:36:58
@_author: s7r 
@_subject: [tor-talk] Tor relay on home computer 
Hash: SHA1
Well running a relay from home might not be such a bright idea,
because of multiple reasons:
1. your ISP could (depending on your terms of usage) terminate your
account if you run any kind of servers or open services from a
residential line (if you don't have a business line)
2. you will be subject to abuse complaints (if you host a Tor exit relay).
3. your IP will be blacklisted and you will have to solve captchas
when accessing some services and be banned from accessing online
financial services (if you host an exit relay).
4. very low chances, the server might be in the interest of law
enforcement agency at some time and in this case it's always better
for it to be in a datacenter or workplace. (the same this applies if
you host an exit relay).
5. you have to keep your computer up most of the time since a Tor
relay is used and grows in the consensus based on its uptime and
speed. It should be up most of the time and connected to the internet
working at good sped, it's sometimes hard to accomplish this from home
on a residential line.
I have written some few facts about pros and cons of running a relay
from home, you can read more about it on Torproject.org also says that running a relay from home, especially an
exit relay, could be headache. Under no circumstances it is forbidden
to run a relay from home, just that it could be more complicated.

@_date: 2015-04-16 20:25:08
@_author: s7r 
@_subject: [tor-talk] Why obfs4 bridges aren't work in Tails? 
Hash: SHA256
I have sent you a private email with some tested obfs4 bridges
operated by me. The bridges are public (in Bridge-db) but I'm not
sending them here for the entire mail list to know your entries in the
Tor network. After you test, if working, feel free to use them as much
as you want, or fetch other obfs4 bridges from Bridge-db.
If the bridges won't work, we should investigate further and let Tails
team know about it, if it's a bug, but I don't think so.
On Debian Wheezy 64bit with Tor 0.2.5.10 and obfs4proxy installed from
deb.torproject.org/torproject.org obfs4proxy main (via apt-get) 3
obfs4 bridges out of a total of 31 crashed with no error or warn in
Tor log.
heartbeat notices, with info about total circuits, relayed traffic, [...
Simply started the Tor daemon again on these 3 servers and they are up
and running, no problem. Will keep an eye on this.
Yawning (CC'ed) made some updates and improvements to obfs4proxy for
better detection of process crash. Is the latest version of obfs4proxy
in the repository deb.torproject.org/torproject.org obfs4proxy main so
we can update in Debian simply with apt-get?

@_date: 2015-08-11 17:06:00
@_author: s7r 
@_subject: [tor-talk] Problem with where hidden_services able to be 
Hash: SHA256
If you installed from deb.torproject.org I assume you are using Tor
0.2.6.10, correct? (run # tor --version to check this).
Please explain once again what you did, I don't exactly understand.
Have you restored a hidden service for which you had backups of
private_key and hostname files? Or did you leave Tor to create a new
hidden service? What do you mean by 'set-up a directory in user's
Documents folder'?
If you have installed via apt, your datadirectory should be
see there files like cached-microdesc-consensus, lock, state, etc.?
Also, the username who should run Tor on your system is debian-tor.
Please provide more details and torrc entries.

@_date: 2015-08-11 17:27:10
@_author: s7r 
@_subject: [tor-talk] SSH connection attempts through hidden service 
Hash: SHA256
When you have a SSH port open to the clearnet (especially if listening
on default port, 22) you get quite an amount of such failed automated
requests. Nothing to worry about here, really, if you don't use a dumb
root password which could be included in most of dictionaries. I
strongly recommend you to disable password authentication and only
allow ssh-key based authentication in sshd_config.
This is not a defect in Tor or in SSH. It's just how things work in
the wild - secure your server!
It doesn't matter you didn't share your onion hostname; it is
available and known to the HSDirs.
You can use this feature in torrc at server side (add it under
HiddenServicePort entry):
HiddenServiceAuthorizeClient basic Tor will generate a passphrase, you can find it out from the
client_keys file created in the directory where you have your
private_key and hostname (HiddenServiceDir).
This will encrypt the descriptors published by your hidden service, so
only clients who provide the correct passphrase will be able to connect.
An additional line in torrc at client's side is needed to provide the
HidServAuth   If there are multiple users who need to connect to this hidden
service, you can add more HiddenServiceAuthorizeClient lines, for as
many users as you have - this way if you want to remove access just to
one user, you can delete the HiddenServiceAuthorizeClient line related
to his username and that passphrase won't work any more. The same
passphrase will work from multiple places (multiple clients) at the
same time.

@_date: 2015-08-13 03:03:17
@_author: s7r 
@_subject: [tor-talk] Problem with where hidden_services able to be 
Hash: SHA256
I understand.
In Debian, if installed via apt-get, Tor will run under user debian-tor.
If you create the hidden service directory in /home/user/Documents,
this doesn't give the permissions to the user running Tor, which is as
I said 'debian-tor' and not 'user'.
Please follow up below and see comments inline:
OK, this is normal.
Tor cannot generate new hidden service files in
and Tor is run by 'debian-tor'.
Do this: leave in torrc:
HiddenServiceDir /home/user/Documents/hidden_service
And run these commands:
chown -R debian-tor:debian-tor /home/user/Documents/hidden_service
chown -R debian-tor:debian-tor /home/user/Documents/hidden_service/*
This won't work unless Tor is also started/reloaded (so it'll generate
the hidden service files), and you need to add each time entries in
torrc for each user for this to happen:
HiddenServiceDir /home/user1/Documents/hidden_service/
HiddenServicePort 80 127.0.0.1:80 # or whatever you use
HiddenServiceDir /home/user2/Documents/hidden_service/
HiddenServicePort 80 127.0.0.1:80 # or whatever you use
You also need to change the owner of all hidden_service folders for
each user to debian-tor using the commands above.

@_date: 2015-08-14 02:03:47
@_author: s7r 
@_subject: [tor-talk] ConnLimit issues with tor-0.2.7.2-alpha 
Hash: SHA256
Do you have ControlPort enabled and does this log line appear when you
open an external app which uses ControlPort?
In my case, on 0.2.7.2-alpha, I see this every time I open arm. Please
confirm if this is the case, so I may open a ticket for it.

@_date: 2015-02-06 19:00:11
@_author: s7r 
@_subject: [tor-talk] Gmail is blocking sending email from smtp.gmail.com 
Hash: SHA256
Negative, Gmail does not block Tor.
A Google Apps business account allows sending emails via Tor both from
webmail ( and for SMTP username over TLS
(Thunderbird tested). Just did a test now, and received the email in
another email box:
Received: from [0.0.0.0] (hosted-by.snel.com. [77.95.229.20])
        by mx.google.com with ESMTPSA id         for         (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 06 Feb 2015 08:49:52 -0800 (PST)

@_date: 2015-01-03 01:55:38
@_author: s7r 
@_subject: [tor-talk] Giving Hidden Services some love 
Hash: SHA1
Now why would we use https on top of a Tor Hidden Service?
 is not the same as The regular internet (clearnet) domains, when used with http, do not
provide any kind of encryption or authentication and are vulnerable to
man in the middle attacks and wiretapping.
.onion Tor Hidden Services _already provide end to end encryption and
authentication_ when used with the default http. They are not
vulnerable to man in the middle attacks or hijacks. On top of this
primary layer of encryption, there are more crypto layers in the Tor
circuits connecting a client to a hidden service.
Maybe the crypto currently used in hidden services is not considered
_very_ strong with nowadays available computing power, but adding an
additional layer of encryption using the commercial CA model seams
like the wrong way to do it. Why? Because facebook did it (they were
the first ones as far as I Know), it means now this is somehow a
I encourage the work on new generation hidden services, which will
have better security and better end to end crypto. We do not need
commercial CA's in a Tor hidden services for various reasons,
including but not being limited to the fact that when you purchase a
SSL certificate you leave another money trail and provide details to
make a payment / place an order, hurting the anonymity of a hidden
service. Why would you pay for something which Tor already does, and
even does it better?
P.S. I personally have _way more trust_ in the RSA1024 and SHA1
implementation used in current Tor Hidden Services design than in a
publicly available CA.
Rather than spending time to convince commercial CAs to sign .onion
domains, better spend that time to find sponsors in order to enable
coders and skilled persons to work on next generation hidden services.

@_date: 2015-01-06 19:17:06
@_author: s7r 
@_subject: [tor-talk] New Software: P2P filesharing designed to use Tor 
Hash: SHA1
Thank you for spending time on this - I was thinking of such a piece
of software which could implement the bittorrent p2p filesharing
protocol but with .onion peers, in order to get rid of DMCA  and
copyright infringement complaints.
Can you provide more technical details? How does it work, how are
peers discovered, how are files shared, how do you initially discover
the files? is there a central repository for it and so on.

@_date: 2015-07-01 21:45:08
@_author: s7r 
@_subject: [tor-talk] help needed to stress-test an onionbalanced HS - 
Hash: SHA256
Following the alpha release of OnionBlanace, I played with it today.
It is easy to install and use, no advanced skills required. I will try
to write tutorials and publish them, but it's pretty easy, basically
it's just editing few config files. The existing documentation is neat
and easy to understand.
Using OnionBalance 0.1.1 Alpha and Tor 0.2.7.1-alpha-dev, I have
configured a hidden service (web site) running OnionBalance with 5
failback servers (different Tor processes, different servers, etc.).
What I want is to stress test it, and see how does OnionBalance spread
the load between the failback servers (will count the hits on each
server and make an average, see how they are rotated).
For anyone who wants to help, please request/load the hidden service
as much as possible and spread it around. For users who can, it might
be helpful to add a cronjob under an unprivileged user to fetch the
page via torified wget and send it to > dev/null or automate the
process by other means. Simply stress test this hidden service like
you hate it ;)
The page is just some random generated text, plain static html (no
javascript, no flash, other naughty stuff) and it's about 140KB.
The OnionBalance hidden service will stay up for 15 days. During this
time I will analyze the logs and count the hits on each server. I
don't see what else I can count besides page hits - any other
application optimizations behind a hidden service are not related to
Tor. Results will be made public on the mail list. Hope this will help
us understand better hidden service scalability and implement prop 224
in the best possible way, considering all aspects.
Counting starts July 1st 2015 18:00 UTC.

@_date: 2015-07-02 02:49:05
@_author: s7r 
@_subject: [tor-talk] help needed to stress-test an onionbalanced HS - 
Hash: SHA256
It is up. Tested from multiple different places. It could be that you
got an older outdated but yet non-expired descriptor. I had the HS
running for testing before enabling OnionBalance (and OnionBalance
modifies descriptors, but for a while the previous non-expired ones
are still 'alive' in the network).
Should be fixed now. Please re-check and let me know.

@_date: 2015-07-02 23:57:30
@_author: s7r 
@_subject: [tor-talk] help needed to stress-test an onionbalanced HS - 
Hash: SHA256
Here are some results after 24 hours:
- - there was no complaint (warn/error) on any of the Tor instances
(either on the master server running OnionBalance which is publishing
descriptors or on the failback server instances). This is good!
- - there was no warn/error in OnionBalance. The same instance is still
running smooth, no crashes. CPU/RAM usage in normal parameters all the
time. This is good!
Counts for successful connections in the last 24 hours:
Failback server  19221
Failback server  12286
Failback server  42982
Failback server  27691
Failback server  34695
            TOTAL: 136875
Server  for example handled more than 3 times vs. server  I guess
this is the result of the random introduction points per descriptor
selection made by OnionBalance. This should rotate, so as more time
passes we will see smaller differences between the servers.
I have to say I am happy with the results. 136875 successful hits in
24 hours for a 140KB page is something. I feel this is far from the
maximum and it can handle a lot more - continue to stress test as much
as you can:

@_date: 2015-07-03 14:05:18
@_author: s7r 
@_subject: [tor-talk] help needed to stress-test an onionbalanced HS - 
Hash: SHA256
OnionBalance doesn't modify the rendezvous spec. Basically it just
uses the HSDir system to publish descriptors signed with the master
key containing introduction points to the failback servers. When you
connect to  you are in fact connecting
to another hidden service, one of the failback servers. OnionBalance
doesn't modify how Tor builds and handles circuits.
I think there is a controlport command to drop all existing circuits
(similar to New Identity in Torbutton).

@_date: 2015-07-05 01:57:13
@_author: s7r 
@_subject: [tor-talk] OnionBalance Hidden Service has over 1 million 
Hash: SHA256
After little over 3 days of uptime, the OnionBalance hidden service
 was successfully accessed over 1
Million times. There was no complaint in any of the running Tor instance
Here are the counts of successful hits per each failback server (as
previously stated, I am using 5 separate virtual machines running
their own Tor instance):
Failback server  199892
Failback server  130329
Failback server  278323
Failback server  184836
Failback server  291119
    *TOTAL: 1084499*
Zip archives of the Apache log files of each instance are available
here: This does not mean that there were over 1 million unique clients (or
circuits). Some clients connected hundreds or thousands of times
through the same rendezvous circuit (Tor will keep a rendezvous
circuit to a hidden service alive and use that for as many connections
to that particular hidden service, unless the descriptor is manually
flushed and circuit killed).
I would be interested to know if there is any Tor control port option
which would allow me to query via telnet and ask regularly with a
cronjob how many rendezvous circuits it has (will run it on each
failback instance). This way, I can combine this info with the
webserver logs in order to have an idea about the number of circuits
handled per instance and average number of requests per circuit. If
anyone has an idea how to do this, please let me know.
I want to thank everyone who contributed in stress testing this hidden
service, and please continue to do it, even harder if possible. I
still see no complaint or sign that anything is overloaded.
I know there are people who built scripts to make automated requests
to this hidden service (thanks!): please share them on the mail list,
with as much details as you can. The more we know about how the
requests were made, the better we can make out of these numbers.
Have fun stress testing even more!

@_date: 2015-07-08 05:00:19
@_author: s7r 
@_subject: [tor-talk] OnionBalance Hidden Service has over 1 million 
Hash: SHA256
*Numbers look good: Over 4 million hits in 7 days.*
I want again to use this opportunity to say THANK YOU to everyone who
is contributing and stress testing. 4 million requests tell me people
are putting quite some effort into it. Please continue to stress test
as much as you can in the next days. After I collect some rendezvous
circuit stats also, we will stop the test - don't want to overkill the
network, prefer to leave more bandwidth capacity for users.
I was waiting to have some rendezvous circuit statistics as well, to
compare them with the hits on the webserver and have an overview on
the circuits stats and average number of requests per circuit.
Hopefully this will happen in the next days. Since you asked, here are
the exact numbers now.
The service was started 1st July 2015. Here are the counts today, 8th
July (little over 7 days of uptime):
Failback instance  956281
Failback instance  732187
Failback instance  837818
Failback instance  768636
Failback instance  911546
TOTAL: 4206468
There are no significant warnings or errors - the same instances are
running since service first started, no reboot or application restart.
I am happy with how it works. As you can see we have *over 4 million
hits*. The number of requests per failback instance confirms the load
is fairly spread.
Hidden service  up and strong!

@_date: 2015-07-11 16:13:07
@_author: s7r 
@_subject: [tor-talk] TorBrowser 4.5.3 circuit path display in TorButton breaks 
Hash: SHA256
On TorBrowser 4.5.3 I've detected that after some time of usage ( > 18
hours or so in my case) it doesn't show the circuit path any more when
clicking on TorButton, not for clearnet destinations and also not for
hidden services as well.
Circuit data display doesn't work all the time - for example, circuit
path isn't displayed for websites which redirect:
If I enter in address bar  but the Exit node selected
for this circuit is in Poland, I'm being redirected to  -
TorButton won't show circuit path in this case.
The funny thing is that sometimes it works, sometimes it does not. Is
it possible that if circuits are isolated per url domain bar, when I
try to connect to google.com Tor builds a circuit, with the exit node
in Poland, and after google server redirects me to google.pl it
selects a different circuit with the exit somewhere else?
Anyone else experienced this?

@_date: 2015-07-14 01:54:17
@_author: s7r 
@_subject: [tor-talk] OnionBalance Hidden Service has over 1 million 
Hash: SHA256
Here are the latest counts for the OnionBalace hidden service
 :
Failback instance  2329348
Failback instance  1822384
Failback instance  2025677
Failback instance  2109677
Failback instance  2202052
*TOTAL: 10489138*
Uptime is ~2 weeks. We have passed the 10 million threshold, not bad,
especially for a ~2 week period of time. Logs are here:
Each failback instance had 2 introduction points in the master
Thanks to everyone who contributed in this! Please stop the automated
scripts which connect to this hidden service now. I am temporarily
shutting it down for 1 or 2 days, in order to install a script which
will collect rendezvous circuit statistics on each failback instance.
We need this info since we can't say how many clients or circuits made
the 10 million successful hits from above.
In the next part of the test we will make sure we use a separate
rendezvous circuit for each request, using a modified third party
script with -tor-auto-isolate. This is extremely high load on the
network and it's VERY RUDE to do it in the wild with Guards (also
responsible for other users traffic). For this reason, I have asked
TheCthulhu for a high end server where I've setup a non-public bridge
to be used for this. This way, at least we won't be hammering on
Guards. I want to run it for shorter period of time (max. 72 hours),
but at 'full speed'.
Who is interested and able to help, please email me directly and I'll
provide the necessary tools and info.
Results and logs will be made public immediately after. I want to see
how many different rendezvous circuits can be created with a hidden
service (failback instance) if it has only 2 introduction points in
the master descriptor and how many such circuits will each server
take. It might be helpful for deciding related to prop 224 (next
generation hidden services) - merging HSDirs and IPs - how many of
them should a hidden service have by default.

@_date: 2015-07-21 04:44:18
@_author: s7r 
@_subject: [tor-talk] Hidden Service and exit circuit questions? 
Hash: SHA256
I don't exactly understand your concern here so excuse me if my reply
is off topic.
Doesn't matter if a Tor instance only handles a hidden service. Tor
has built in client functionality end establishes some circuits,
keeping them in case they will be needed. Even if you don't have a
SocksPort enabled, built in client functionality will not be disabled.
Also, a Tor instance running a hidden service will also open other
types of circuits besides rendezvous, such as introduction points
circuits and circuits needed to publish descriptors to the HSDirs
responsible for the hosted hidden service. So, it's normal for you to
see in your Tor client -> guard -> relay -> exit circuits and it is
not a threat to the anonymity of your hidden service, and no, it's
impossible for an exit (or a client, or any other relay/bridge) to
connect to your hidden service without using a rendezvous circuits.
There are other aspects to consider in your hidden service if you fear
such leaks, such as: can an attacker game the application hosted on
the hidden service in order to make arbitrary requests to a clearnet
address? can an attacker game the application hosted on the hidden
service in order to find out relevant info about its internet
connectivity, public IP address or other connection related
information? This won't be related to Tor anyway, it requires
hardening and much reading of opsec documentation. torproject.org and
tails.boum.org as well as whonix.org have some great articles about
this topic - do read.

@_date: 2015-07-25 16:58:07
@_author: s7r 
@_subject: [tor-talk] OnionBalance Hidden Service has over 1 million 
Hash: SHA256
If anyone still has scripts to automate requests to
 (OnionBalance hidden service) it is
time to shut them down. I am sending this notification because I have
turned off the hidden service, and if someone keeps such scripts
running they will just request descriptors which don't exist any more
at the HSDirs.
I was able to test the hidden service better by building many separate
rendezvous circuits for each request regularly. Need some time to
analyze the logs and will send a detailed report.

@_date: 2015-03-01 23:50:03
@_author: s7r 
@_subject: [tor-talk] Obfsproxy: Multiple ServerTransportListenAddr lines 
Hash: SHA256
Thanks for running a bridge.
If you want to bind the same pluggable transport protocol to ipv4 and
ipv6 (2 IP:port) I recommend one line for each pluggable transport, as
ServerTransportPlugin obfs2,obfs3 exec /usr/bin/obfsproxy managed
ServerTransportListenAddr obfs2 [::]:42862
ServerTransportListenAddr obfs3 [::]:49991
This [::] will open ports on both ipv4 and ipv6 (all interfaces if you
have multiple - like more IP addresses), if you have a dual stack server.
I recommend you not to use obfs2, since it's too old. Better make an
obfs3 and obfs4 bridge. For this, you can install the obfs4proxy
package from torproject.org deb:
echo "deb  obfs4proxy main" >>
apt-get update && apt-get -y install obfs4proxy
Substitute in your torrc /usr/bin/obfsproxy with /usr/bin/obfs4proxy
Note this obfs4proxy is able to do both obfs3 and obfs4 pluggable
transport, so you don't need the old python based obfsproxy package.
This one is written in Golang. It cannot do obfs3.
Tip: obfs4proxy package makes it easier for you to run pluggable
transports on low (usually reserved) ports, like 80, 443 for our good
fellows behind firewalls which allow only few ports. For this you can
install libcap2-bin package form apt-get and use that.

@_date: 2015-03-05 15:06:13
@_author: s7r 
@_subject: [tor-talk] Why corrupt government officials are strongly 
Hash: SHA256
Glad so see there are more and more people who see the world from a
more technical and practical eye :)

@_date: 2015-03-07 16:05:40
@_author: s7r 
@_subject: [tor-talk] The "StrictNodes 0" will disappeared from my torrc 
Hash: SHA256
And even better you can start using the latest Tor stable which is
Your Tor version 0.2.4.24 is listed as 'recommended version' in the
consensus, so it's not like you are shooting yourself in the foot, but
unless you have a very good reason (I can't think of one) to have that
specific Tor version, I STRONGLY recommend you to upgrade to the
latest Tor stable.
Vidalia is also unmaintained. Why do you need it exactly? Why won't
you run Tor Browser (with Tor launcher) which has a GUI for you to add
proxy, bridges, and whatever network connectivity requirements you
might have. You just have to leave the Tor Browser (portable Firefox)
open in your bar while using the Tor localhost socks5.
If this is annoying, then install Tor as a service on your OS and
start it from services when you want to use it.

@_date: 2015-03-09 02:27:06
@_author: s7r 
@_subject: [tor-talk] possible solutions for increasing the capacity of a 
Hash: SHA256
When operating a high-usage Hidden Services 2 things are needed to
'tweak' the performance and enable it to handle more concurrent clients:
Increase NumEntryGuards to 3 or 5
Increase MaxClientCircuitsPending 300
*These values can be increased if the traffic to the Hidden Service in
question is even higher.
I came to look at this values when I saw in Tor logfile the message
that it wanted to launch more circuits but already had n circuits
pending already, so thought this can be a bottleneck. When I increased
these values, that message disappeared from logs.
Obviously the Guard(s) is/are a bottleneck for a Hidden Service, since
all the traffic to or from it has to go through the Guard(s). The
performance (CPU/RAM) and bandwidth of the server actually hosting the
Hidden Service won't make much of a difference in this scenario, when
Tor (used with default settings) will randomly select 1 (one) Guard
and keep it for a longer period.
I know the Guard requirements are different now, this flag being
currently allocated to a certain percent of the fastest Stable and
most-of-the-time up relays in the consensus - but still, this can be
the bottleneck if we are talking about a big Hidden Service.
In order to mitigate this, which one of the methods below do you think
would hurt anonymity the least:
1. Run your own high speed Guard relays and manually teach the server
hosting the Hidden Service to use them. Could this work? It doesn't
sound very random or diverse for anonymity, and obviously these Guards
will also be Guards for other clients, which have selected them
randomly, therefor they won't have all the bandwidth available.
2. Run your own high speed Bridge Relays. When using Bridges, we have
these possibilities:
a) Create regular high speed Bridge Relays and use them by adding them
all to the server hosting the Hidden Service and add NumEntryGuards n
where n = number of bridges. Leave other users to use these bridges
also by publishing them with Tonga.
b) Create private Bridge Relays (PublishServerDescriptor 0) and use
them by adding them all to the server hosting the Hidden Service and
add NumEntryGuards n where n = number of bridges.
c) Create private Bridge Relays (PublishServerDescruptor 0) and use
them by adding them all to the server hosting the Hidden Service and
add NumEntryGuards n where n = number of bridges and configure Tor to
build 4 Hop circuits when used with Bridge Relays:
Hidden Service -> bridge -> middle1 -> middle2 -> middle3 -> rendezvous
Will such a behavior (method 2-c) be easily detected? Will any of the
other relays or an attacker watching the Tor network (or part of the
Tor network) notify this? In case we use 4 hop circuits with a Bridge
with PublishServerDescriptor 0 (IP address will not be in the
consensus and not even in Tonga's database), and we configure Tor in a
way that the first hop (middle1) also has the Guard flag, won't all
the bridges connecting this way look like normal Tor clients?
What other parameters could improve the performance and capacity of a
Hidden Service?
!!! !!! !!!
THESE METHODS ARE EXPERIMENTAL, NOT YET TESTED AND JUST FOR RESEARCH!
DO NOT USE THEM FOR REAL HIDDEN SERVICES, IT CAN AND PROBABLY WILL
COMPROMISE THEIR CURRENT LEVEL OF ANONYMITY WHICH IS ENSURED MORE OR
LESS BY Tor's DEFAULT SETTINGS.

@_date: 2015-03-12 18:56:27
@_author: s7r 
@_subject: [tor-talk] Load Balancing/High Availability Hidden Services 
Hash: SHA256
Hi Donncha,
Your idea is indeed very interesting. I am eager to see it in
practice. If you have the time, me and TheCthulhu (cc'ed) could
provide the infrastructure and necessary system administration hours
to test this.
While your current solution is a way to use load balancing and
redundancy, which means spreading the resource usage over multiple
machines, checkout my questions about maximizing a single HS server as
close as possible to its total capacity:
Please email directly if you want to start this, we will document each
step and share the results with everyone here. Maybe this will give
some hints for writing a proposal for load balancing and high capacity
hidden services which could be merged with the proposal of second
generation hidden services.

@_date: 2015-05-20 18:48:52
@_author: s7r 
@_subject: [tor-talk] reverse enumeration attacks on bridges (re: 100-foot 
Hash: SHA256
Speaking of, it's a long time I have been asking myself this, why does
a bridge with PT need a publicly open ORPort?
I understand it for a regular bridge, no PT, but when I use PTs why
should I also open the ORPort publicly? I understand the PT needs to
talk to Tor via its ORPort, but can't we make this happen on
127.0.0.1? Right now if a 'watcher' sees obfs4proxy traffic and can't
tell what it is, just does a full port scan on the destination and
sees an ORPort open.

@_date: 2015-05-24 14:42:54
@_author: s7r 
@_subject: [tor-talk] SOCKS proxy to sit between user and Tor? 
Hash: SHA256
Hi Jeremy
Why do you want this and why do you think this is a good idea? What
are you trying to solve? The socks5 which Tor open is not a simple
socks5 protocol implementation, it has some customizations and
enhancements used by Tor Browser to isolate streams, etc.
As TvdW suggests, you if you use a TCP proxy that will just redirect
the requests, there should be no penalty of performance or features
for the Tor socks5. But I am not sure why you want to do this.

@_date: 2015-11-01 15:26:23
@_author: s7r 
@_subject: [tor-talk] Question Regarding Routing of Network-Traffic using 
Hash: SHA256
Just to make sure you realize this puts you at higher risk in running
into a malicious guard. If you stick to the same entry guard for
longer time as Tor does by default, you have less chances to run into
an evil guard because you don't choose so often. If you run into an
evil guard your anonymity will be hurt badly. I can't say that a
malicious guard means 100% deanonymization, but for sure it's _very_
bad, so if you can choose less often it is better. That's why I always
recommend to stick with the default Tor settings, unless you have a
very good reason for what you are doing.
The type of attack you describe sounds like a path bias attack. It's a
known one (hard for an attacker to accomplish) and there is ongoing
work to make Tor only try a certain number of relays as Guards. If
none of them are reachable or fail too much, it will disconnect
entirely and shut down to protect the user.
There is nothing an attacker can do in order to make you choose his
evil guards. If he succeeds to keep a certain number of evil guards
running in the network, it's all about (bad)luck if you pick them or
not - that is why it's very important not to choose too often.

@_date: 2015-10-12 01:52:12
@_author: s7r 
@_subject: [tor-talk] Question 
Hash: SHA256
Maybe the assistance you require might feel a lot more comfortable in
an instant message environment as opposite to email / mail lists.
I recommend you jump on IRC, in  channel on irc.oftc.net network -
there are nice people there who could answer some questions if you are

@_date: 2015-09-07 01:12:53
@_author: s7r 
@_subject: [tor-talk] New mailing list: tor-teachers 
Hash: SHA256
Exactly, +1 nickm! And while we are at it something useful would also
be automatically creating bibtex entries for the newly created
important research papers, so we can add them on faster on anonbib. We
are missing some papers there, and I also want to create a mirror for
it which will cache all the papers (currently some of them are served
from external sources, which means if those sources go away so does
the paper) - but it's low priority at this moment.
See you on the list!

@_date: 2016-04-03 13:27:40
@_author: s7r 
@_subject: [tor-talk] Fwd: Fwd: This account is currently being used in 1 
Hello Alin,
Both IP addresses indicated by you are Tor exit nodes, so I think this
is normal.
It is normal for Tor browser to use different exit IP addresses
(different circuits) for all Tabs open (all destinations / domains) - it
is called circuit isolation per url domain bar. So, if you are connected
to gmail.com using exit IP A and you open another tab to connect to
other domain, for example whatsmyipaddress.com it is totally normal to
get a different exit IP address with the second domain - there is
nothing wrong here.
If you are using 2 factor authentication with gmail and you are totally
sure your computer is not compromised, i think it's safe. There are many
technical possibilities which could happen, for example you were
connected to gmail using a circuit and a certain exit node, and that
circuit failed for a reason (a relay in the chain got disconnected,
etc.) and Tor immediately rebuilt a new circuit to the same destination
gmail.com obviously with a new exit node / new exit IP address. Until
gmail notified that session was killed, it shown you that message.

@_date: 2016-01-03 15:45:15
@_author: s7r 
@_subject: [tor-talk] On further minimizing harassment for Tor Exit Nodes 
Hash: SHA256
Altering Tor's path selection is something we shouldn't play with
until we have concrete papers that suggest it is wrong. As Moritz
said, having a GeoIP database to make path selection changes is
probably a terrible idea, due that such databases are by design not
100% accurate and subject to constant change. Such a behavior will
also alter anonymity in an unknown (I think bad) way.
Anyway, your suggestion might actually happen automatically along with
a more important fix, which is AS aware path selection. This is non
trivial work and will probably take some time, but it's not unknown
and people are looking into it.
does not cover specifically this kind of risk.

@_date: 2016-01-10 20:25:11
@_author: s7r 
@_subject: [tor-talk] Help me secure my setup 
Hash: SHA256
Periodic consensus downloads, as well as keeping always some fresh
circuits on the list in order to attach streams to when requested via
the SocksPort. In other words, not much traffic but not 0 traffic as well.
Related to your other questions, you might be using too much
complexity which is in most of cases not desired. To be frank I didn't
understand your goals and threat model...
If I were you I would just configure a good vpn on the server in the
datacenter (say openvpn for example with my own certs and everything)
and connect to the vpn first, then normally (no bridges) to Tor. This
will probably obfuscate some adversaries in learning that you are
using Tor from home.
Connecting to the VPN after you connect to Tor will provide you an
unique static exit point from the Tor network which will make you very
very distinguishable so I would not do that if I were you.

@_date: 2016-06-16 19:51:30
@_author: s7r 
@_subject: [tor-talk] Only nine of the 29 Windows VPN clients that I 
Hello grarpamp, mirmir
Speaking of, there is this website:
If you go to Proxy/VPN in the left menu it will show you some info
related to vpn usage detected.
In my latest firefox it says:
First seen 	2016/06/16 16:47:04
Last update 	2016/06/16 16:47:04
Total flows 	1
Detected OS 	Windows 7 or 8
HTTP software	Firefox 10.x or newer (ID seems legit)
MTU 	        1406
Network link 	OpenVPN TCP bs64 SHA1 lzo
Language 	English
Distance 	11
Where I use exactly OpenVPN in TCP mode. In Tor Browser this is not
I am not sure how reliable is this tool, but what's the trick in normal
firefox to disable this so that networking info is not revealed any
more? How is this information gather by this website?

@_date: 2016-06-17 00:16:03
@_author: s7r 
@_subject: [tor-talk] Only nine of the 29 Windows VPN clients that I 
As far as I was able to find one defense against TCP/IP stack
fingerprinting is blocking outgoing ICMP entirely and disabling replying
to ICMP requests on the defensive host, but this could be somehow wrong
since it's stated that just inspecting the initial TTL and window size
fields could be enough.
Wonder what is a good way to disguise VPN usage (any VPN implementation)
at OS level.

@_date: 2018-12-03 23:35:20
@_author: s7r 
@_subject: [tor-talk] Tor official list of new .onion addresses? 
Relying on the fact that nobody can ever learn the onion addresses you
have is a terrible security policy. This can be never guaranteed, as
relays are public and anyone can run one, thus become hidden service
directory as soon it meets the necessary flags.
You should be prepared and assume the onion address is known, thus
defend with ssh keys instead of weak passwords, possibly even change the
default port (this does not add security but bypasses some automated
brute force tools, it's no help for targeted manual attack so don't rely
There are other techniques lower at little-t-tor protocol level that
suite your concerns, like HiddenServiceAuthorizeClient - you should
better look into those if you are concerned about someone trying to
connect to your onion address. These are neat for some services that
need privacy and need to not advertise to the unauthorized access users
that they are online up and running or only allow limited access to some
users that provide additional credentials or auth material other than
just knowing the onion address.
Onion addresses have the purpose to conceal the physical (IP) location
of the service, but the addresses themselves have to be prepared to be
known to the world, for a strong security policy. Tor documentation
clearly states this.
If you open ssh on an onion address and you allow root login with
password "1234" IT IS NOT Tor's FAULT YOU WERE PWNED. It is just a
terrible security policy. Do not do this.
*Hope for the best, prepare for the worst!*

@_date: 2018-12-05 02:28:14
@_author: s7r 
@_subject: [tor-talk] What keys does Tor use in client mode 
According to
Lines 4700 - 4710:
     * keys.  First, reset the state. */
    log_notice(LD_NET, "Our IP address has changed.  Rotating keys...");
    tor_addr_copy(*last_interface_ip_ptr, &iface_addr);
    SMARTLIST_FOREACH(outgoing_addrs, tor_addr_t*, a_ptr, tor_free(a_ptr));
    smartlist_clear(outgoing_addrs);
    smartlist_add(outgoing_addrs, tor_memdup(&out_addr,
    /* We'll need to resolve ourselves again. */
    reset_last_resolved_addr();
    /* Okay, now change our keys. */
What kind of keys does Tor use in client mode, and why are they rotating
when an interface changes, or the IP address of an interface? How are
they related to the interface or IP address?
Asking if there is something more I should know here, wrt this. I was
unaware of any keys used in client mode.

@_date: 2018-12-07 02:12:16
@_author: s7r 
@_subject: [tor-talk] comparison of Tor and Kovri in regards to 
I am a Tor supporter, but this is not the reason why I disapprove this
It depends from what perspective you look at it as "safer than Tor". It
does not have directory authorities, and there are no relevant points
that need to make a consensus in order to make the I2P network work, so
yes some attacker cannot take down 9 servers and disable the network,
but this does not necessarily mean is safer. I mean, Tor could any time
drop the system where known directory authorities vote for other relays
and make a consensus, in favor for a decentralized system that is
controlled only by code and cannot be shut down by seizing N servers,
but this does not happen because the directory authority system is
studied, well known, it works and we are sure it solves way more attacks
than it opens. Think about that. It's a piece of cake for Tor developers
to write code that somehow drop the directory authority consensus style
and adopt something else, but this opens huge attack surface that is not
yet well studied and well understood, so better no. I think this is a +,
not a -.
- I2P can be attacked with far less resources than Tor;
- Tor is deeply researched and various attack types and problems have
already been solved;
- Tor is larger as a network with more capacity, and more diversity;
They also have different purposes so they cannot be directly compared on
absolutely every feature, because:
- Tor is designed to allow people to access the internet (clearnet, or
better said destinations outside the Tor network) anonymously, by
routing the traffic via a chain of multiple servers, making the
trace-back to a certain  user as close to impossible as possible.
- I2P is more oriented for traffic inside the I2P network (e.g. you
cannot browse cnn.com anonymously via I2P).
It's like comparing apples with bananas. Both are good, but quite
That is not the reason. Tor has more network resources in terms of
servers available for users to use, it uses bandwidth weights to ensure
a server gets as much traffic as it can at least theoretically handle,
based on bandwidth authority measurements.
Tor also uses flags, in order to know what servers to pick for each
point in a given circuit.
These are the primary reasons why Tor is much faster and continues to be
reliable even when it was attacked by million of 'zombie' botnet
computers that were hidden behind Tor.
I don't think that was a good thing that happened, but I think it is a
good thing that we got through it with no problems for average users.
Even the worst critic should applause this.
It is easy to click and run with Tor, but it also makes the privacy
oriented necessary settings so users cannot be tracked by websites. This
is important, there is much work done to remove from Firefox stuff or
configure stuff in a way that is oriented for user privacy. Tor Browser
it does not just start Tor automatically and a portable Firefox for

@_date: 2018-12-08 18:32:15
@_author: s7r 
@_subject: [tor-talk] comparison of Tor and Kovri in regards to 
newbie user? In I2P?
Not even that, I am not an user at all of I2P.
But I know about it and read about it, and the information was extracted
from the official i2p website.
If the website is not properly formatted and updated in description in
order to match reality, than this clearly states how much we can count
on it for anonymity or important stuff.
Nobody said Tor is done. In fact it's far from done.
It's just decades ahead I2P, as stated on the I2P official website. You
keep implying non-sense and twist words in your reply, as I correct you
below. Nobody is implying Tor is done, just that is much more researched
than I2P.
Nobody said I2P _sucks_ because it does not have feature X.
The idea is that having different and different purposes they cannot be
compared plain and simple, in a table, they each have various downsides
and upsides. It's kind of like comparing oranges with apples.
apples aren't so juicy.
oranges are.
This does not mean we said apples suck.
As stated on the i2p website that could be risky, anonymity is not
"outproxy functionality does have a few substantial weaknesses against
certain attackers - once the communication leaves the mixnet, global
passive adversaries can more easily mount traffic analysis. In addition,
the outproxies have access to the cleartext of the data transferred in
both directions, and outproxies are prone to abuse, along with all of
the other security issues we've come to know and love with normal
Internet traffic."
This is the first thing all critics say. So what if it's government
money as long as the code is open source and anyone can audit it? Anyone
can run a relay and be a part of the network.
I have absolutely nothing against government funding as long as they are
given to Tor Project Foundation as they are, and allow the foundation to
decide for itself how and when to use those financial resources, and for
what they think it's best.
Great things take money.
And currently I don't think government funding still represents the
majority % of the total funding.
You are not forced to use Tor - stop using it if you think government
money cursed it and made it evil.
Okay, could be. But what does this have to do with anything? We are not
discussing "What could be done if the pig could fly" or all the
theoretical stuff. We were discussing current real situation, what is
I2P now, and what it does now, not what it could be if and if.
What does this have to do with it anything? Of course there are
solutions, who said there aren't? We was discussing the current existing
features not what could be done theoretically.

@_date: 2018-05-28 18:47:57
@_author: s7r 
@_subject: [tor-talk] Post Quantum Tor 
You claim this based upon what evidence? Do you have any technical
document or citation in order to sustain your claim? I am not talking
about something you read on an anonymous blog here. Also, which RSA?
There is limited evidence that RSA 1024 might not be sufficient with
current existing computing power (not even evidence, more like an
assumption), but RSA 2048 / 4096 should be sufficient. Even  for RSA
1024 you might need to be a real threat in order to be worth the
resources to be spent on you.
There is no evidence of ECDSA and ECDH being screwed (regardless of the
curve used, NIST ones, cv25519, secp256k1, etc.).
I understand that some might be inclined to think that everything is
screwed, and that the NSA/CIA have the power to do anything, but there
is no evidence to sustain such a claim. To be frank, I am very happy to
have people like this in the community because problems might get fixed
even before they become real problems.
Everyone who correctly used encryption tools with up to date recommended
standards were safe, the cases where it failed relied purely on human
error, social engineering or other kind of side channel attacks. If I am
able to spy on the passphrase of your private key (or if you have a weak
dictionary passphrase that I can break with brute force in like 1 year)
this does not mean I have the power to break the algorithm of your
encryption key (RSA, ECC). Unfortunately way too many people use small,
easy to remember passphrases (even related to their names, dates of
birth, spouse names, pet names, etc.). A good brute force tool will take
for example 2 years to break a relatively simple passphrase, but if fed
with hints (names, dobs, friends, pets, places) that can be narrowed
down exponentially to 2 months.
Let's keep this discussion productive. Tor _needs_ post quantum
resistant crypto as a _feature_, so that current traffic if captured and
stored cannot be decrypted within reasonable time in the future. The
time frame is variable an dependent on each case and threat model, but
let's say like one or two decades. So, this is just an extra security
measure Tor takes as the number one privacy tool, one that can be relied on.
There is no evidence that quantum computers will be strong enough in 5
or 10 years to break the current NON QUANTUM RESISTANT crypto used. At
current moment quantum computers barely can do a square root of a two
digit number. Also, I think it's safe to assume this type of threat is
irrelevant if the current crypto in Tor might be broken in 100 years
from now, because even if the subject is still alive moment, it
might not matter at all.
Taking the discussion just a little further, quantum computers face a
physics problems related to time and space. A proven physics assumption
tells us that something can only be in one place/position at a time.
Like bits in normal computers nowadays, that can be either 0 either 1.
Qbits have to be both at the same time. So, being a true lover of
technology and believer, I am not stating it's impossible and it will
never happen, but it is surely not knocking on our doors, from my opinion.
Before experts struggle to answer this one, let us be productive and
work on the proposals Nick quoted in a previous email to this thread, so
we eliminate risk and don't have to worry if / when this becomes reality.

@_date: 2018-05-28 21:15:58
@_author: s7r 
@_subject: [tor-talk] Post Quantum Tor 
Well, with all due respect, Andreas Antonopoulos point of view and
personal opinion cannot be counted as evidence. cointelegraph.com uses
to quote twitter people and technology activists and stuff like this,
but when I say evidence I am thinking of technical or academical papers
describing and proving it exactly. This website is nothing like that.
In this article:
...Do they use that to break Bitcoin? The simple answer is no.
Hmm. Okay. Sounds like a real oracle. So we should just take that quote
and nail it to our bedroom wall and stare at it every day. But this is
worth 0 honestly.
The problem is that if the NSA could break it, so could others that have
enough incentive. Bitcoin price could be an incentive to many less
transparent governments that have funds for research and do not need to
publicly state what they are doing. So I am guessing that if it could be
done, we would see its effect.
Where did they state this exactly publicly and officially? I am just
asking, they could have stated it but I am just not aware of it and
would like to see if possible. I mean they stating it, not someone
saying hey it's me, and I know for sure the NSA can break current crypto.
Right. Agreed. Encryption should always be upgraded to a point that is
considered sufficient for the forseeable future. Requiring at least rsa
4096 for top secret information means that people are taking extra
security measures and raising standards, which is very very good.

@_date: 2018-10-25 17:47:22
@_author: s7r 
@_subject: [tor-talk] derive onion v3 key from mnemonic seed phrase? 
Indeed, it should be possible. I have discussed on a chat with one of
the authors of BIP39 about this just before v3 HS code was here and
there's nothing that prevents it.
This is under my attention, as well as, offline master keys for onion
services. These two items go together very well, and I think there
should be part of Tor code and documented in the manuals, so less
experienced users avoid to use third party scripts that they do not
This way one can hold on to an onion service for so long time, being
able to restore from a human memorable (or at list write-able on paper)
phrase and also make it seized-proof.

@_date: 2019-12-26 01:35:43
@_author: s7r 
@_subject: [tor-talk] Russia successfully disconnected from the internet | 
============================== START ==============================
I don't get what is the big news about it? I mean, the news is that they
are doing a terrible thing that provides them a false sense of security,
ideas of censorship and isolation which I am totally against and
strongly discourage, but this article says that "the Russian government
did not disclose any technical details" -- sounds like they invented
some super ultra cyber security solution that they want to keep top secret.
In reality, it is only BGP rules about traffic manipulation. Of course
such rules can be more or less complex, since there might be ISPs in
Russia with AS numbers that are not only in Russia territory, but then
again it can be done much more simply than described in the article and
it's not such a master piece of engineering as pictured in that article.
The only problem is that, while it was meant to counter cyber attacks,
it provides a false sense of security. This is the only reason why other
countries are not doing it, not because they don't have the "magic
technical solution" or they don't know how to code BGP rules :)
It does not worth the downside of someone simulating cyber attacks to
their protected institutions and triggering constant disconnects from
the global internet, destroying business there and causing terrible
financial losses.
Having an authority within the country responsible for such decisions is
also not good, as it gives power to the people there to game the system
in their own benefits. This is not why the internet was invented, to the
contrary it was invented to abolish such things and evil practices.

@_date: 2019-01-06 23:20:23
@_author: s7r 
@_subject: [tor-talk] Issue accessing Onion v3 Services# 
We would investigate, but this provides no information that can help.
1. Why do you think the fault lied with that bridge you were using? Did
you try any other v3 onion service using that bridge besides  the ones
hosted by you? Like one you know for sure it's up, like the one that was
provided in an earlier reply to this thread? Was that not working also?
2. Do you have any log files from the Tor daemon when you were trying to
access v3 onion services and you couldn't?
3. Give us the fingerprint of that bridge and obfs4 auth data so we can
try to reproduce.
Without any of these, this looks like just a simple mistake or something
going wrong with your hosted v3 onion service at that particular moment.
The Tor version that the bridge is using is irrelevant, v3 onion
services need to be supported client <-> server side, so if your Tor
version is recent enough as well as the server side (otherwise it cannot
generate a v3 onion address at all, so the problem shouldn't even exist
in this case) all the relays in the path do not matter as long as they
are running a *supported* Tor version.

@_date: 2019-09-16 09:09:40
@_author: s7r 
@_subject: [tor-talk] Onioncat and Tor Hidden Services V3 
What do you mean here? I guess you mean P2P type of applications s tart
to break down when the host / user count grows beyond 10 or so _only
when OnionCat is used with HSv3_, right? Why is that exactly?

@_date: 2020-01-07 15:38:46
@_author: s7r 
@_subject: [tor-talk] Help setting up tor dos defense 
Sure - the best move to prevent onion services partitioning using this
HS defense. However, there is something unclear I'd like to understand.
From the manual:
**HiddenServiceEnableIntroDoSDefense** **0**|**1**::
Enable DoS defense at the intropoint level. When this is enabled, the
rate and burst parameter (see below) will be sent to the intro point
which will then use them to apply rate limiting for introduction request
to this service.
The introduction point honors the consensus parameters except if this is
specifically set by the service operator using this option. The service
never looks at the consensus parameters in order to enable or disable
this defense. (Default: 0)
So the service hosting the HS does not look at this consensus param.
Right now e do not have a consensus  param for this at all, but what
will happen if the directory authorities will vote this consensus param
as HiddenServiceEnableIntroDoSDefense 1? In this case, the introduction
points will see that, and use the default values of 25 introductions per
second with a burst of 200 / sec. In this case, if a HS operator wants
to _disable_ this protection totally, he should set
HiddenServiceEnableIntroDoSRatePerSec 0 which according to the manual:
"If this option is 0, it is considered infinite and thus if
**HiddenServiceEnableIntroDoSDefense** is set, it then effectively
disables the defenses."?
Or should he just set HiddenServiceEnableIntroDoSDefense 0, which is
already 0 by default for _services_?  (this is the confusing part).
