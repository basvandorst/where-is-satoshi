
@_date: 2015-04-24 13:24:49
@_author: Allen 
@_subject: [tor-talk] Clarification of Tor's involvement with DARPA's Memex 
More wanking = fewer wars, so that is a need, IMO, along with food, water,
shelter and medical care.
Beyond that, define "need".  Privacy and freedom from government and
corporate surveillance are fundamental rights, IMO.  Keeping your internet
activity private from your ISP and the world-at-large is a perfectly valid
use of Tor.  You can't expect someone else to keep private what you are not
willing to keep private yourself.
-----Original Message-----
Sent: Friday, April 24, 2015 1:08 PM
[TRIGGER WARNING]
Outgoing traffic stats from Tor exit nodes. Almost all traffic of Chinese
speaking Tor users is average adult porn, which is banned in China. You can
tell it's from China because the sites are aimed to Hong Kong residents. The
"Chinese people use Tor because they are supressed in their free speech and
really want to post on the internet how bad China is" is a lie, almost all
of them just want to wank.
Tell me one hidden service which needs anonymity, has more than 100 users
and is not a drug market place or furry porn community for computer science
Don't get me wrong, Tor is a beautiful and necessary tool for people to
ignore their goverments regulation on what to put in their bodies and what
to watch, but it really isn't what the liberal hivemind wants to believe.
The idea of Tor is in no way compatible with govermental regulation, every
cooperation with LE will be a nail in Tor's coffin.

@_date: 2015-04-30 11:57:29
@_author: Allen 
@_subject: [tor-talk] Full integration with bitcoin (suggestion / feature 
currency like Taler  Surely you jest...
" Taler is an electronic payment system that was built with the goal of
supporting taxation. With Taler, the receiver of any form of payment is
known, and the payment information comes attached with details about what
the payment was made for. Thus, governments can use this data to tax
buisnesses and individuals based on their income, making tax evasion and
black markets less viable."

@_date: 2015-04-30 17:49:24
@_author: Allen 
@_subject: [tor-talk] What is being detected to alert upon? 
Question: I recompiled OpenSSL to remove a bunch of features that look
unnecessary and might present a security risk, such as SSL2, SSL3 and DTLS.
(In case it matters, it is OpenSSL v1.0.2a and the specific configure
options are no-ssl2 no-ssl3 no-idea no-dtls no-psk no-srp no-dso no-npn
no-hw no-engines -DOPENSSL_NO_HEARTBEATS -DOPENSSL_USE_IPV6=0).
I'm using this rebuilt DLL with Tor.  Does this compromise Tor's TLS
handshake so that it no longer looks like Firefox?  If so, what so I need to
do to allow Tor to mimic Firefox's TLS handshake?

@_date: 2015-12-02 22:54:26
@_author: Allen 
@_subject: [tor-talk] regression in torproxy 2.7.4? 
I have a webservice that runs as a tor hidden service.  The client connects
to torproxy using a random socks4 username (which results in fresh circuit)
and sends a short string to the server.  The server sends a response from a
few bytes to a few kilobytes in size, then gracefully closes the
connection.  This is roughly equivalent to accessing a website with
"keep-alive" turned off.
This ran like a champ under torproxy 2.6.10.  It could run it for days with
no unexpected behavior.
With torproxy 2.7.4 however, the client is seeing a partial response
roughly every 1000 requests.  Sometimes it looks to the client like the
server closed the connection without sending any data, and sometimes it
looks like only half the data gets there (which might be roughly 500 bytes
or one cell worth, although I haven't measured it exactly).
I'm not sure what to make of this.  Any network protocol has the potential
for transmission errors and the client and server should be able to handle
them, but I'm still wondering if 2.7.4 might have a regression that
sometimes leads it to not forward all pending data before a connection is
gracefully closed.
If I back off to 2.6.10, I still see these partial responses although less
frequently.  That could be because routers in the circuit are running
2.7.4.  Or maybe I just got lucky before with 2.6.10 and it had the
potential for the same behavior but I just never saw it.
Is anyone else seeing partial page loads or similar behavior with 2.7.4?
Any other thoughts on what I'm seeing?

@_date: 2015-12-16 09:23:35
@_author: Allen 
@_subject: [tor-talk] torpoxy support for forced https 
I suggest torproxy could generate a random CA certificate when its
installed and transparently convert all http to https, generating the
required SSL certificates on-the-fly and signing them with the random CA
certificate.  The user would then have to add the random CA certificate to
their browser, or better yet, this could somehow be automated for the Tor
Browser.  One open question with this scheme is whether torproxy would also
need to rewrite html content to change http urls to https.
Alternately, the Tor Project could ask Mozilla and other browsers
developers to add a switch for "treat .onion as secure".  Or maybe it could
be "treat .onion as secure but only if certain conditions hold, such as the
proxy is running on the localhost and a to-be-determined status query of
the proxy succeeds".

@_date: 2015-07-16 01:50:00
@_author: Allen 
@_subject: [tor-talk] Recommended private key management and recovery 
of private keys.  IMO, this discussion would be more suitable for a cryptocurrency mailing
list.  I think you will find though that the only way to recover from the
theft of private cryptocurrency spending keys is to spend the cryptocurrency
(i.e., transfer it to an uncompromised wallet) before the thieves do.
I predict that impression will change very shortly...

@_date: 2015-07-16 09:52:36
@_author: Allen 
@_subject: [tor-talk] OnionBalance 0.1.1 Alpha released - Hidden Service 
Looks promising (although I have not yet tested it).
With regard to the planned "Complex mode", the most important feature IMO is
to provide maximum protection for the "onion service permanent key" which
currently resides on the Management Server, because it that is compromised,
no amount of load balancing is going to help you keep the service up...

@_date: 2015-07-16 18:21:00
@_author: Allen 
@_subject: [tor-talk] Hidden Service and exit circuit questions? 
eliminating all exit circuits.
You could also try "-SOCKSPort 0" if you don't plan to make outgoing
See

@_date: 2015-07-20 14:38:51
@_author: Allen 
@_subject: [tor-talk] Hidden Service and exit circuit questions? 
rendezvous No, there is a handshake process needed to establish a Tor connection
between the two machines, and that handshake only works through the
rendezvous point.  See

@_date: 2015-07-20 20:48:51
@_author: Allen 
@_subject: [tor-talk] Hidden Service and exit circuit questions? 
the Tor service and an exit node, I'm thinking that the exit node may be
able to use the existing circuit to access the HS port over the 3-hop
circuit without ever going through the normal 6-hop rendezvous?
You could check the source code, but I would guess that if a circuit is not
built using the rendezvous protocol, then packets coming in on that circuit
are not forwarded back to the hidden service port on the localhost.  More
generally, packets coming in on any circuit are forward only to the local
port for which the circuit was setup to proxy, i.e., there is no "crosstalk"
between circuits.

@_date: 2015-06-08 06:58:34
@_author: Allen 
@_subject: [tor-talk] Blocking of Tor relay IP address 
up in blocklists maintained by various services.
You could try running Tor with ExitRelay = 0.  Then your server will only
relay traffic inside the Tor network and not from the Tor network to
external sites (like Akamai).  You could also use ExitPolicy to prevent
traffic from exiting to specific websites (like Apple and Akamai), while
still allowing it to go to other websites you don't have a problem with. See

@_date: 2015-06-15 18:28:42
@_author: Allen 
@_subject: [tor-talk] Hidden Service Scaling Summer of Privacy Project 
Hi Donncha,
One thing I think I'm seeing is that if I restart the tor process on a hidden server, it chooses new introduction points and any clients that have a cached service descriptor cannot access the hidden service until the cached descriptor expires.  This leads to an apparent service outage for those clients.
Does that correspond to what other people see when operating hidden services?
If that is the problem, the solution might be either that the tor proxy client immediately expires a cached hidden service descriptor after failing to reach the service, or that the tor process on the hidden server remembers its introduction points so it can pick them back up when it restarts.

@_date: 2015-06-15 19:14:35
@_author: Allen 
@_subject: [tor-talk] Hidden Service Scaling Summer of Privacy Project 
Thanks.  The ticket mentions a client-side expiration test that is not
working correctly.  That corresponds to the messages I'm seeing in the log
file (and that tipped off to the problem):
"We already have a new enough service descriptor for service ID %s with the
same desc ID and version."

@_date: 2015-03-28 18:39:07
@_author: Allen 
@_subject: [tor-talk] hidden service with only one authorized client 
As far as I can tell from testing and from deconstructing the spec at
 , if I have a
hidden service with only one authorized client, there is no functional
difference between using basic auth (rend-spec section 2.1) and stealth auth
(rend-spec section 2.2).  By that I mean, the security and privacy would
effectively be the same in both cases.  Is my reading correct?  If not, what
is the functional difference?  Thanks.

@_date: 2015-05-01 10:41:03
@_author: Allen 
@_subject: [tor-talk] What is being detected to alert upon? 
I didn't see an answer to this question, but I did compare the TLS Hello's
from Firefox and the Tor binary distributed by torproject.org and there are
lots of differences (see the two files attached), so I'm not sure this is
worth worrying about...
-----Original Message-----
Sent: Thursday, April 30, 2015 5:49 PM
Question: I recompiled OpenSSL to remove a bunch of features that look
unnecessary and might present a security risk, such as SSL2, SSL3 and DTLS.
(In case it matters, it is OpenSSL v1.0.2a and the specific configure
options are no-ssl2 no-ssl3 no-idea no-dtls no-psk no-srp no-dso no-npn
no-hw no-engines -DOPENSSL_NO_HEARTBEATS -DOPENSSL_USE_IPV6=0).
I'm using this rebuilt DLL with Tor.  Does this compromise Tor's TLS
handshake so that it no longer looks like Firefox?  If so, what so I need to
do to allow Tor to mimic Firefox's TLS handshake?

@_date: 2015-05-27 08:49:51
@_author: Allen 
@_subject: [tor-talk] isolating multiple server requests 
I have a client application that Tor to communicate with several servers.
For privacy reasons, it is important that after each request, the client
starts with a "fresh slate" so the server is not able to tell that the next
request is coming from the same client.  (Note that after the client
restarts it's session with a particular server, it will never use the
previous session again.)
It is my vague understanding there might be three ways to accomplish this:
1. The client can make a new connection to the Tor proxy with a new unique
username, see
  My
concern here is that over time, the Tor proxy will build up a long list of
prior usernames that are never going to be used again.
2. The client can send Tor proxy a NEWNYM signal on its control port.  My
concerns here are that:
a. The spec implies Tor proxy might ignore that signal, see
b. It is not clear to me how to be certain when the request has completed
and it is safe to attempt a new connection.
c. That would reset circuits to all servers, including some circuits that
might be in use.  While I don't think that would result in an error, it
would slow down those requests and make Tor do unnecessary work to
reestablish circuits.
3. The client can somehow talk directly to the Tor controller to establish
new circuits.  My concern here is the complexity and potential to make a
programming mistake that leads to information disclosure.
What is the best approach in this situation?
Thanks much.

@_date: 2015-05-27 14:53:49
@_author: Allen 
@_subject: [tor-talk] isolating multiple server requests 
Thanks.  I take it IsolateClientAddr refers only to the source IP address,
not the port binding?  IsolateDestAddr looks useful, but I'm not sure in
what circumstances IsolateClientAddr would be useful.

@_date: 2015-11-18 16:29:26
@_author: Allen 
@_subject: [tor-talk] Islamic State 
Refuse to be terrorized.  If we all do that, then we have won the war.

@_date: 2015-11-20 18:14:13
@_author: Allen 
@_subject: [tor-talk] MITM attack on TLS 
If your IT department allows outgoing SSH, then spin up a micro Linux EC2
instance on Amazon Web Services (which costs only 1.3 cents per hour), then
SSH into the EC2 instance and setup an SSH tunnel.
Assuming your local machine is running Windows, you can use Putty as the
SSH client.  If you just want to use the EC2 instance as a proxy (without
Tor), then in the  Putty configuration, look under Connection -> SSH ->
Tunnels, for Source port pick any high number like 9000, pick Dynamic,
click Add, then Open the session, finally, configure your browser to
connect to a SOCKS4 proxy on 127.0.0.1 at the port you chose (like 9000).
If you want to use Tor, too, then download and start torproxy on the EC2
instance.  Assuming the torpoxy port on the EC2 instance is 9050, then in
the Putty configuration under Connection -> SSH -> Tunnels, for Souce port
pick any high number like 9000, pick Local and in the Destination field
enter 127.0.0.1:9050, click Add, then Open the session and again configure
your browser to connect to a SOCKS4 proxy on localhost at the port you
chose (like 9000).
If you've never used EC2 before, it will probably take you 1-2 hours to do
this the first time (maybe you can find a tutorial on the www or
something), but once you get it set up it works quite nicely, and the price
is right.

@_date: 2015-11-20 18:16:30
@_author: Allen 
@_subject: [tor-talk] MITM attack on TLS 
Or they might fire you.  IMO, you want to stay under the radar of your IT
department.  Much better if you can to let them have their MiTM certs and
go around them using SSH or some other protocol.

@_date: 2015-11-21 16:56:12
@_author: Allen 
@_subject: [tor-talk] MITM attack on TLS 
Personally, I would think SSH is much safer.  It is used by IT people all
the time for server management, so they will understand it.  The
destination address will be a cloud server, which you can simply say you
are using for a personal project.  OBFS4 on the other hand is not normally
used by IT people--it is used to get around IT people.  They will
immediately be very suspicious if they are able to figure out the
protocol.  And the destination IP address is who-knows-what, which could by
itself raise questions and might even lead them to think a computer on
their network could be infected with a virus that needs immediate
investigation.  In the end, a protocol they know and understand and use in
their own work will be much less threatening to them than something they

@_date: 2015-11-25 10:39:09
@_author: Allen 
@_subject: [tor-talk] ru news 
In all fairness, AFAIK if someone controls one entry guard and one exit
node, they can correlate all traffic that uses those two nodes for entry
and exit.  If there are roughly 2000 entry guards and 1000 exit nodes on
the network and if Tor clients select entry and exit nodes at random, for
every server you control, you can correlate roughly 0.00005% of the traffic
on the network.  Divide that number by roughly seven for hidden "onion"
services, since that traffic can use any relay as an "exit" node, and
perhaps more than seven if the hidden service disguises itself as a Tor
relay so the traffic destination becomes more difficult to determine.
"A traffic confirmation attack is possible when the attacker controls or
observes the relays on both ends of a Tor circuit and then compares traffic
timing, volume, or other characteristics to conclude that the two relays
are indeed on the same circuit. If the first relay in the circuit (called
the "entry guard") knows the IP address of the user, and the last relay in
the circuit knows the resource or destination she is accessing, then
together they can deanonymize her."
email has been sent from a virus-free computer protected by Avast.

@_date: 2015-11-25 10:47:55
@_author: Allen 
@_subject: [tor-talk] ru news 
Somehow they sneeked that in the last upgrade.  I'm not amused either.
Hopefully it is now disabled.

@_date: 2015-11-25 10:50:30
@_author: Allen 
@_subject: [tor-talk] ru news 
You don't know that it all.  Either country could have taps inside the
backbone infrastructure of the other, or control parts of the Tor network
used by people in the other country.  You shouldn't mislead people with
claims that neither be proven nor reasonably argued.

@_date: 2016-04-28 22:00:08
@_author: Allen 
@_subject: [tor-talk] Supreme Court Gives FBI More Hacking Power 
I read the order you cited, and I see no rule that says what you claim.
What I do see is a rather modest addition to the Federal Rules of Criminal
Procedure, Rule 41, which gives any magistrate jurisdiction to issue a
warrant in cases where law enforcement is unable to determine where a crime
is being committed due to the use of technological measures such as Tor.
In other words, under prior practice, if a crime was being committed but it
was not clear where it was being committed due to the use of technology
such as Tor, it was not clear which court district would have jurisdiction
to issue a search warrant.  Under the new rules, this situation no longer
falls "through the cracks" because a magistrate in any district can issue a
warrant without regard to jurisdictional limits of the districts.  Simply
using Tor does not subject someone to a warrant; there still has to be
probable cause that a crime is being committed.

@_date: 2016-08-08 15:15:52
@_author: Allen 
@_subject: [tor-talk] Tor protocol classification 
It might just be blocking specific destination IP addresses, or it might be
recognizing unique properties of the TLS handshake implementation between
the user's Tor client and network's Tor relays.

@_date: 2016-08-09 04:38:02
@_author: Allen 
@_subject: [tor-talk] Tor Project Corporate Document FOI Request 
I don't think you've actually looked at any of the information the Tor
Project provides to the public on its website.  Because if you had looked
at it, you would know exactly what the legal name of the corporation was.
Given that you are too lazy to actually find and read the publicly
available information, why should the Tor Project honor your request to
provide additional information?  I think they are well justified to simply
ignore it.

@_date: 2016-08-24 15:14:09
@_author: Allen 
@_subject: [tor-talk] Tor 0.2.9.2-alpha is released 
It would be really helpful for both users and the Tor project if there were
Windows binaries built so the alpha, beta and rc versions could be better

@_date: 2016-08-24 16:19:58
@_author: Allen 
@_subject: [tor-talk] Tor 0.2.9.2-alpha is released 
IMO, having folks compile Tor themselves under Windows will cause the
project more problems, not fewer.
On Wed, Aug 24, 2016 at 4:17 PM, Juan Miguel Navarro Martínez <

@_date: 2016-12-19 09:04:46
@_author: Allen 
@_subject: [tor-talk] Massive Bandwidth Onion Services 
AFAIK, HiddenServiceNumIntroductionPoints >= 3 is also for the benefit
of the client, so if intro point  doesn't work for the client, it
can try to connect at intro point  and then finally at intro point
 before giving up.  So let's say my Tor client looks up your Tor
hidden service descriptor and attempts to connect at intro point and that fails.  What would/should it do at that point?  Give up?

@_date: 2016-12-19 11:19:52
@_author: Allen 
@_subject: [tor-talk] Massive Bandwidth Onion Services 
I got that point, that your service will have 60+ intro points.  You
also said "people accessing the service onion address at lunchtime
will receive/cache different descriptors from those who access it some
hours later", which lead me to believe that a single client will not
"see" all of those 60+ intro points.  So that question is, if you
change HiddenServiceNumIntroductionPoints = 1 to implement your
proposal, if a single Tor client does one and only one lookup on your
Tor hidden service, how many intro points will it see and be able to
connect to?

@_date: 2016-12-21 09:01:37
@_author: Allen 
@_subject: [tor-talk] Not comfortable with the new single-hop system 
Alex, that is inappropriate language and behavior for a public
discussion list.  You have demeaned yourself greatly with that
outburst, and only succeeding in damaging the Tor project.  Please
Second, as someone who firmly believes in Murphy's Law, I share the
concerns that have been expressed.  The only solution to address these
concerns if to discuss the steps that have or will be taken to ensure
the situation cannot happen, not to attack the concerns themselves or
the intelligence of the people who hold them.

@_date: 2016-12-21 12:59:59
@_author: Allen 
@_subject: [tor-talk] privacy of hidden services 
I have a question about the privacy of hidden services.  Let's say I
create a tor hidden service and privately send the onion address to
only two other people.  Would anyone outside of myself and those two
people be able to determine the onion address or monitor activity
related to the hidden service such as HS descriptor uploads and
downloads from directory servers, or connection attempts via
introduction or rendezvous points?  Would it make a difference if the
hidden service used basic or stealth authorization?  I wasn't able to
figure out the answers to these questions from reading the rend-spec.
Thanks much!

@_date: 2016-12-21 14:57:47
@_author: Allen 
@_subject: [tor-talk] privacy of hidden services 
ok, I'm not sure I completely understand.  If my HS uses stealth auth,
what data remains in the clear?  Is the HS descriptor on the HS dirs
stored using a persistent identifier, or does the identifier change
every 24 hours?  Are there any persistent identifiers that can be
observed on the network to track usage of the HS?  Thanks much.

@_date: 2016-12-21 15:19:52
@_author: Allen 
@_subject: [tor-talk] privacy of hidden services 
Hi Flipchan, I'm not concerned with limiting access--I'm concerned
with who if anyone is able to detect the existence and activity of the
HS, and more specifically at this point, who is able to detect the
existence and activity of a HS that uses stealth auth when the onion
address is only distributed to authorized users.

@_date: 2016-12-21 19:03:17
@_author: Allen 
@_subject: [tor-talk] privacy of hidden services 
The HS directory servers receive the HS public key aka onion address.
The information leakages are: (1) through various HSdir  enumeration
techniques, the world at large can discover the HS public key and
onion address; (2) the HS directory server is able to monitor service
descriptor uploads and retrievals.  Rend-spec v3 will change this by
instead sending the HS directory servers a pseudorandom subkey that
changes every 24 hours and can only be predicted by someone who knows
the onion address, which will prevent leakage of the onion address and
prevent long-term monitoring of descriptor uploads and retrievals for
an onion address that is not publicly published.
The HS directory servers also receive the list of intro points and
ephemeral service keys.  If basic or stealth auth is used, this is
encrypted so there is no info leakage--only authorized users can
obtain this info.
The only difference between basic and stealth auth is that stealth
auth is equivalent to creating a different onion address for each
authorized user.
The intro points receive only an ephemeral service key.  When basic or
stealth auth is used, the relationship between permanent keys and
ephemeral keys is only available to authorized users.  The intro point
can track the establishment of service connections for the ephemeral
key, but can't tie that back to the onion address.
The rendezvous point receives only a randomly generated single-use
cookie.  It knows it is establishing a rendezvous connection, but does
not know for what service.  The single-use cookie is sent to the HS
encrypted with the HS key, so only the HS can read that transmission.
To summarize, the info leakages for HS that do not use authorization are:
- World at large can discover onion address using various directory
enumeration techniques.
- HS directory can track HS descriptor uploads and downloads and tie
those to the onion address.
- Intro point can track HS connection attempts and relate them to onion address.
For HS's that use basic authorization:
- World at large can discover onion address.
- HS directory can track HS descriptor uploads and downloads and tie
those to the onion address.
- Intro point can track HS connection attempts but only relate them to
the ephemeral service key for the duration of the key.
- Authorized users who operated an intro point could track HS
connection attempts through that intro point.
For HS's that use stealth authorization:
- Each authorized user uses a different effective onion address.
World at large can discover each of those onion addresses, but can't
relate them to each other.
- HS directory can track HS descriptor uploads and downloads for each
individual onion address, but can't relate them to each other.
- Intro point can track HS connection attempts but only relate them to
ephemeral service key for the duration of the key.
Is all that correct?

@_date: 2016-12-30 11:28:52
@_author: Allen 
@_subject: [tor-talk] help - some site DE-anonymize me 
zalmos is webproxy.  According to GeoIP, its servers are located in
France.  So when you visit another website such as google.com thru
zalmos, the other website (google.com) is probably giving you content
and ads that are appropriate for the country in which the zalmos proxy
server is located (French). That doesn't mean google or zalmos has
traced you back thru Tor.

@_date: 2016-12-30 17:06:08
@_author: Allen 
@_subject: [tor-talk] help - some site DE-anonymize me 
============================== START ==============================
That makes sense, too.  I see my browser says
Accept-language: en-US,en;q=0.5
See

@_date: 2016-02-23 16:26:48
@_author: Allen 
@_subject: [tor-talk] Tor for everyone; 
I don't understand.  If a message is associated with an identity, then it
is not anonymous, it is at best pseudo-anonymous.  Which are you proposing,
truly anonymous messages that have no identity associated with them, or
pseudo-anonymous messages that have a pseudo-anonymous identity associated
with them?
Second, it is easy to prevent spoofing of pseudo-anonymous identities using
digital signing.  The identity is represented by a public signing key, and
if a message is signed using the corresponding private key, it must have
been sent by a person who knows the private key.  What else is required
beyond that?

@_date: 2016-02-23 18:22:38
@_author: Allen 
@_subject: [tor-talk] Tor for everyone; 
That's not a service that I would use myself.  If I wanted people to be
able to get my public key from a business card, I would print the key
itself on my card using a QR code.  The other stuff you listed also don't
have much interest to me personally, but I can't speak for anyone else.

@_date: 2016-01-17 09:38:09
@_author: Allen 
@_subject: [tor-talk] Tor ain't working or pulling up.... 
come why won't it boot up I have no
sam's hill is wrong with Tor it's been this way
Try rebooting your machine, delete the contents of the tor state directory,
reboot your machine again and make sure the tor state directory is still
gone, then start tor.  Under Windows, the tor state directory is

@_date: 2016-07-13 06:01:06
@_author: Allen 
@_subject: [tor-talk] How to include Tor in my application 
Step 1 Option A
Download and install torbrowser, and copy from the installation the two
folders named "Tor".  Those should contain everything you need.
Step 1 Option B
Go to  , look in the directory for a
recent version and hope that it includes a zip file called something like
"tor-win32-X.X.X.X-XXXX.zip".  That contains everything you need.
Step 2
Get your app to launch tor.exe with the necessary command line options for
your application.  The command line options are documented at
 .  At minimum you
probably want to use the -SOCKSPort and -DataDirectory options to ensure
your app's version of Tor doesn't collide with the user's own version of
Tor (if they have one installed).

@_date: 2016-07-21 07:30:15
@_author: Allen 
@_subject: [tor-talk] Tor Project Corporate Document FOI Request 
See  at FYI, FOI stands for "Freedom of Information".  It refers to a specific set
of laws that apply to government agencies only, not corporations.  You
can't make an FOI request to a corporation.  The Torproject is a 501(c)(3)
organization and has certain disclosure obligations under law.  AFAICS, the
required information is all available on its website.

@_date: 2016-07-21 08:03:49
@_author: Allen 
@_subject: [tor-talk] Tor Project Corporate Document FOI Request 
For starters, you can't legally request that someone assassinate the
President, send you child pornography, provide you with weapons of mass
destruction, etc.  So definitely not anything.  And while you can make some
requests, you can only make an FOI request of a government agency.

@_date: 2016-07-22 12:06:19
@_author: Allen 
@_subject: [tor-talk] Why so may exit node IP addresses in the TBB? 
It started on the alpha development of 4.5[1]:
That doesn't answer the question though why the different circuits use
different exit nodes.  They could all use the same exit node.  I recall
seeing fair bit of debate over how many exit nodes a Tor client should use
and how often it should switch exit nodes...

@_date: 2016-06-02 11:39:32
@_author: Allen 
@_subject: [tor-talk] Tor (and other nets) probably screwed by Traffic 
Another alternative would be to re-architect the services of interest to
use a message or packet store-and-forward protocol with a random delay to
thwart traffic analysis.

@_date: 2016-06-02 17:45:45
@_author: Allen 
@_subject: [tor-talk] Tor (and other nets) probably screwed by Traffic 
another alternative would be random packet sizes, ie, the packet size
transmitted to the next hop would not be the same as the size received

@_date: 2016-06-05 17:20:24
@_author: Allen 
@_subject: [tor-talk] A possible solution to traffic correlation attacks, 
IMO, the packets would probably need to be randomly delayed at each node,
not just entering and exiting the network.  A mathematical model would be
needed to determine the necessary amount of delay (I doubt 30 ms would be
enough).  The delay could be chosen by the originating node, so it could
chose the privacy vs latency tradeoff.
It might also be beneficial to have two channels to each exit node, with
each channel used in only one direction, i.e., outbound packets travel one
route, while inbound packets travel a different route.

@_date: 2016-06-10 16:43:58
@_author: Allen 
@_subject: [tor-talk] Firefox add-on tells when website on clearnet has 
Why not ask the websites to add an "X-onionurl" header to their https
responses?  Then you wouldn't have to maintain an untrusted database.

@_date: 2016-06-10 22:13:37
@_author: Allen 
@_subject: [tor-talk] Tor-Friendly Two-Factor Authentication? 
How about developing a simple 2FA app for a smartphone?  Maybe a smartphone
could emulate a FIDO U2F?  Alternately, I remember some of the first 2FA
devices were fobs that displayed a 6 digit code that changed every 15
seconds or so, based a pseudorandom generator that had a secret seed value
that was known by the server.  A simple smartphone app design might be to
give the user a pseudorandom seed when they create their account, the user
inputs the seed into the app on their phone, and then when they want to
login they have to enter a 6-8 digit code displayed by their smartphone
app.  Maybe some apps like that already exist...

@_date: 2016-06-24 08:10:20
@_author: Allen 
@_subject: [tor-talk] Reminder to stay on-topic 
Let's move on from this finally.  It's starting to get annoying.

@_date: 2016-06-24 09:39:41
@_author: Allen 
@_subject: [tor-talk] US Federal Court: The Fourth Amendment Does Not 
The judge's logic is pretty amusing and shocking at the same time:
basically, because of all the malware and software vulnerabilities in the
world, as soon as you connect your computer to the internet, you have no
reasonable expectation of privacy because your computer is probably going
to be hacked by someone, and if it just happens to be the FBI who hacks
your computer, you should have expected that.

@_date: 2016-06-29 05:49:10
@_author: Allen 
@_subject: [tor-talk] Recent news stories regarding Tor 
Can we please stop with this topic?  Done.  Fini.  Banned.  Banished.
Barred.  Excluded.  No more.  Thank you.

@_date: 2016-06-29 13:34:32
@_author: Allen 
@_subject: [tor-talk] Recent news stories regarding Tor 
If it were up to me, I would vote at this point to ban grarpamp from this
list for at least a month for keeping this topic alive.  While being a
frequent contributor may have its privileges, the line has been crossed.

@_date: 2016-06-29 15:14:41
@_author: Allen 
@_subject: [tor-talk] Recent news stories regarding Tor 
It would be even easier for me to unsubscribe from the tor-talk list, which
I'm close to doing, and I'm sure a lot of people have already done

@_date: 2016-05-04 08:45:12
@_author: Allen 
@_subject: [tor-talk] MITM attack: How to see Tor Messenger's exit node? 
A software bug.  But given that your desired opsec is to be resistant to
MitM attacks, you should always perform the required authentication steps
regardless.  Note that in any reasonable software, you shouldn't have to
compare fingerprints every conversation--instead you should only have to do
this once and the software should then store some kind of credentials so it
can perform automated authentication.  If "Tor Messager" makes you check
fingerprints every time you start a fresh conversation, you might want to
look for another solution.

@_date: 2016-09-17 07:26:33
@_author: Allen 
@_subject: [tor-talk] Connect Tor to socks4a proxy 
You can open a TCP connection to the tor proxy port (by default 9050
or 9150 on the localhost), send a command string, then read the reply.
If the reply indicates a successful connection, you then send and
receive bytes from the proxy port just like it was connected to the
final end point.  The command string and reply formats are documented
at

@_date: 2017-11-29 13:30:44
@_author: Allen 
@_subject: [tor-talk] Is there a limit to how many .onion addresses I can 
I've created 200 hidden services before and it worked, but I didn't
have much load (incoming connections). If you did this, you would
probably want to run more than one tor process anyway for load
balancing--AFAIK, each tor process is essentially single-threaded, so
if you have 10 cores on your computer, you might want to run 10 tor
processes, each with a different DataDirectory and SOCKSPort, and with
50 hidden services.

@_date: 2017-10-25 08:50:47
@_author: Allen 
@_subject: [tor-talk] Need a stable .onion address hosted by the Tor 
As long as you keep the tor processing running on your web server, the
response should be relatively quick. If you shutdown the tor process
on your web server and then restart it, it might take a few minutes
for machines on the tor network to find your server again. You can
restart the http server, but don't restart the tor process.  The onion
address has nothing to do with the response time.
On Wed, Oct 25, 2017 at 8:36 AM, Rob van der Hoeven

@_date: 2017-10-25 09:19:40
@_author: Allen 
@_subject: [tor-talk] Need a stable .onion address hosted by the Tor 
sounds like a useful program. I have no idea what you're looking for
though. A fast onion server to ping? As you correctly pointed out, the
facebook onion address would work for that.
On Wed, Oct 25, 2017 at 9:07 AM, Rob van der Hoeven

@_date: 2017-10-25 16:50:51
@_author: Allen 
@_subject: [tor-talk] Does the Tor DNS transparent proxy code use clients 
and what happens if you use dig alone to talk directly to tor?
something like "dig -p torport hostname +tcp" (see man dig)
On Wed, Oct 25, 2017 at 4:42 PM, Rob van der Hoeven

@_date: 2017-10-25 17:20:31
@_author: Allen 
@_subject: [tor-talk] Does the Tor DNS transparent proxy code use clients 
I don't know what this thing is that you're referring to as a
"torport" and what kind of behavior you expect from it.  But maybe you
could try what the tor documentation refers to as the DNSPort
from DNSPort [address:]port|auto [isolation flags]
If non-zero, open this port to listen for UDP DNS requests, and
resolve them anonymously. This port only handles A, AAAA, and PTR
requests---it doesn’t handle arbitrary DNS request types. Set the port
to "auto" to have Tor pick a port for you. This directive can be
specified multiple times to bind to multiple addresses/ports. See
SocksPort for an explanation of isolation flags. (Default: 0)
On Wed, Oct 25, 2017 at 5:01 PM, Rob van der Hoeven

@_date: 2017-10-25 17:51:37
@_author: Allen 
@_subject: [tor-talk] Does the Tor DNS transparent proxy code use clients 
the DNS query should be tunneled over a tor connection, so if it's
working right, you would see no DNS query leaving your system

@_date: 2018-02-21 10:21:53
@_author: Allen 
@_subject: [tor-talk] Upcoming security releases for Tor 0.2.9 and up. 
can we get a windows build, i.e., a tor-win32-0.2.9.xx.zip
