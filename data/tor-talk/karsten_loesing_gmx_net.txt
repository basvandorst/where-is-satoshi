
@_date: 2007-04-13 12:15:29
@_author: Karsten Loesing 
@_subject: GSoC project: Distributed Tor Directory 
Hash: SHA1
Hi everyone,
Google has announced which applications have been accepted for Google
Summer of Code. I am happy to say that my application has been accepted!
:) It's about distributing the Tor directory for hidden service
descriptors (not router descriptors) to all onion routers or at least a
subset of it.
If you like to read more on my project and its progress, stop by at
What about the other three students who have been accepted for a Tor
project in GSoC? Who are you? Show yourself!  :)

@_date: 2007-04-01 10:56:17
@_author: Karsten Loesing 
@_subject: Example hidden service issue 
Hash: SHA1
Don't know if it's a good option, but why not start with installing the
web server, test it locally, and then configure the hidden service? You
could simply switch the sections one and two and replace directly by localhost.

@_date: 2007-04-18 11:45:15
@_author: Karsten Loesing 
@_subject: [Fwd: High-traffic Colluding Tor Routers in Washington, D.C. 
Hash: SHA1
this question is not directly related to the described case.
I would like to contribute some more Tor servers running at different
providers across Germany (probably not in the same /16 network). My
current server is a virtual server at 1blu that has a bandwidth of 931
KB/s which makes it the 71st fastest Tor server in the network. Maybe
other providers are even faster than 1blu. Just as a comparison: the
fastest Tor server at the moment has 4533 KB/s.
Do you think it's a privacy problem to run 3 to 5 servers? All servers
would be non-exit servers because of the current habit of the German
police to collect all exit servers. Of course, I will set the family entry.
Just want to ask in advance.

@_date: 2007-04-18 12:18:20
@_author: Karsten Loesing 
@_subject: [Fwd: High-traffic Colluding Tor Routers in Washington, D.C. 
Hash: SHA1
They offer "1blu-vServer Unlimited" with unlimited traffic volume for 17
euros per month. I don't know if it's the best offering, so I decided to
give them a try. Are there other good offerings for (virtual) Linux
servers with unlimited traffic?
OK. Does someone else have scruples about it?

@_date: 2007-04-18 21:29:55
@_author: Karsten Loesing 
@_subject: [Fwd: High-traffic Colluding Tor Routers in Washington, D.C. 
Hash: SHA1
Hi Karsten, (strange to write that *g*)
At the moment I count 630 TCP connections using netstat. And I don't
know about /proc/user_beancounters, but that file is empty.
I don't have any long-term experience with 1blu so far. Maybe they shut
down my node as soon as they find out why it produces so much traffic.
And maybe they change their contracts as soon as everybody is running
Tor servers at them from now on. Let's wait and see.
Personally, I don't know so much about e-mail anonymizers, yet. So, if
you have information that I cannot find in a two-minutes Google session,
yes, please send it to me.

@_date: 2007-08-08 21:41:28
@_author: Karsten Loesing 
@_subject: Proposal of a new hidden wiki 
Hash: SHA1
Yes, that's really a nice idea. And it might even work.
Correct. A hidden service uploads a current descriptor (containing
contact information) if a) there is some significant change in contact
information or b) an hour passes.
That's a bad idea, because it does not really improve availability if a
hidden service is restarted every two hours.
The two services should rather be run in parallel all the time. Then,
after some maths, one would (probably -- am no mathematician) find that
both services have their own descriptors published half the time, and
thus receive half of the client accesses. (Note that the one-hour
intervals break as soon as the list of introduction points changes --
that means that starting the nodes with a certain timing does not
significantly improve this solution.)
However, I am quite sure that the developers did not have this variant
of content replication in mind when they designed the hidden services.
That means that it might break. But why not try it? :)

@_date: 2007-12-19 15:35:02
@_author: Karsten Loesing 
@_subject: Suspicious Circuits 
Hash: SHA1
No, I don't think it's a bug.
- From the log file that you, Kyle, gave me yesterday I can see that you
started Tor at 16:04:51 which established introduction points at
"Slowpoke", "dpujtk", and "server" and published a descriptor for your
service at 16:05:27. The delay of 36 seconds comes from the fact that
Tor waits at least 30 seconds for a descriptor to be stable before
publishing it. Then you made a connection attempt at 16:06:26 which
succeeded at 16:06:53 and another attempt at 16:07:00 succeeding at
16:07:02. Everything fine so far.
Subsequently, at 16:07:12 you restarted Tor and made it establish new
introduction points at "otherator2", "crelm", "bytebutlerfive" and
publish a new descriptor containing these introduction points at
16:07:53. Again, the delay of 41 seconds is intentional. But---and this
is the problem---when accessing your service at 16:07:25, Tor downloaded
the first descriptor without being able to know that it's obsolete. So,
Tor tried to connect to "Slowpoke" and the other introduction points
which were not acting as introduction points for your service any more.
That's why you get those NAKs which lead to re-extending the failed
introduction circuits which is also normal behavior.
Hence, there is not a problem in the Tor code.
In general, when performing tests, you should give Tor a little bit more
time to stabilize, especially for hidden services. You should also
consider not to run both server and client on the same Tor instance.
If the problem persists even when waiting for some more time, please report!
Timing is everything! :)

@_date: 2007-12-20 12:08:51
@_author: Karsten Loesing 
@_subject: Suspicious Circuits 
Hash: SHA1
Uhhhm, right. The problem is that introduction points are not removed on
failure, which they should be. It's quite unusual that introduction
points fail (and most people won't notice that), but okay, we should
better fix it. My first guess is that this problem was introduced in
0.2.0.7-alpha (ChangeLog entry: "- Hidden services were choosing
introduction points uniquely by hexdigest, but when constructing the
hidden service descriptor they merely wrote the (potentially ambiguous)
nickname.") and that hex-encoded identities are compared with nicknames
when removing introduction points. But it's quite hard to tell without
running it. On the other hand, this change was also backported to
0.1.2.18 which did not have this problem. Hmm.
Let's find it out. :) As discussed on  yesterday, I attached a patch
to this message containing some more logging statements. Could you,
Kyle, apply it and run the same configuration as you did last time? You
should also enforce the same timing problem, because without it's
unlikely that intro points fail and respond with a NAK message.
Thanks for that! :)
Good question. 30 seconds are not really much compared to the overall
performance of hidden services. How important is it that hidden services
are more immediately available after setting them up? This is only done
once in a while. Does this affect user experience so much? I think that
the behavior in Kyle's case is a really rare event, compared to the
normal use cases for hidden services. So, I would not change it in favor
of fewer and more accurate descriptor publications.

@_date: 2007-06-01 10:24:06
@_author: Karsten Loesing 
@_subject: question about A/B communication with dir servers for hidden 
Hash: SHA1
Yes, they are.
No, never.
Correct, the directory server never learns about the IP addresses of the
service provider and its clients.

@_date: 2007-06-01 12:47:08
@_author: Karsten Loesing 
@_subject: Length of new onion addresses 
Hash: SHA1
(posting to or-talk and or-dev, because it concerns both, usability and
at the moment I am designing the new ASCII-based format for hidden
service descriptors, including new security features like encryption of
introduction points and the ability to be distributed among onion
routers unpredictably for non-clients. This incorporates a secret cookie
that needs to be passed between the hidden service provider and his
clients in addition to the service id which is the current onion
address. You can read about all the details in proposal  in the svn
As the new descriptor might replace the current descriptor some day and
the format of onion addresses would affect all hidden service users, I
would like to discuss this decision of the onion address format in
public, rather than make a decision on my own and being confronted with
incomprehension when it might be introduced.
The current onion addresses consist of 80 bits and (as you all know)
look like this (address of the hidden wiki):
The new onion addresses would consist of two parts: (1) the service id
and (2) the secret cookie.
(1) In contrast to the current format, the service id is not used to
identify the service (bad name then, I know), but to generate an
unpredictable descriptor id where to find the service descriptor. If an
adversary can create an own key pair with a fingerprint equal to the
service id, she can prevent the actual hidden service from announcing
his service. Though, the effect of this is limited, because descriptor
ids are automatically changed every day. My idea was to use 32 bits for
the service id.
(2) The secret cookie is the key for encrypting and decrypting the
introduction points and to calculate the current descriptor id. Whoever
finds out the secret cookie could observe hidden service activity and
attack introduction points which both would otherwise not be possible.
My plan was to use a 128 bit key as secret cookie.
In total, new onion addresses would be 160 bits long. The question is
now, if an onion address of that size is still manageable for human
beings? (Is the current size manageable after all?) For illustration
purposes, the new addresses would look like this:
Or are my assumptions concerning the length of the service id still too
incautious, and would 200 bits (72 bits for service id and 128 bits for
the secret cookie), resulting in the following onion address, be better?
For downward compatibility reasons, those 200 bits could also be
distributed by using 80 bits for the service id and 120 bits for the
secret key. Then, people could start using the new descriptor by simply
adding a dot and a secret cookie to their current (unchanged) onion
address. This would look like this:
To the (probably upcoming) question, why one needs a secret cookie at
all, or if it could also be used optionally in the long run: The plan is
to distribute the storage of descriptors, primarily for scalability
reasons. But this raises new security issues, because anyone running a
stable onion router could become responsible for storing a descriptor,
so that we simply need new security mechanisms. Otherwise, security
would be worse by the distribution, but with the secret cookie, security
even gets better than before.
But perhaps we should rather aim for usability than for security and use
only 120 bit long onion addresses, e.g. by using 32 bits for the service
id and 88 bits for the cookie, resulting in the following onion address?
Maybe we shouldn't even extend the onion addresses at all, but allocate
the 80 bits in another way, e.g. 24 bits for the service id and 56 bits
for the secret cookie? Then we should use another virtual top level
domain to distinguish current and new descriptors, resulting in
something like the following:
What do you guys prefer? How do you exchange onion addresses? Publishing
them on non-hidden web pages, pasting them to IRC chats, writing them on
business cards, memorizing and telling them, ...? I think it's important
to find a balance between security and usability here.
The question is: Does size matter? :)
Any comments are welcome! Thanks!

@_date: 2007-06-01 19:33:42
@_author: Karsten Loesing 
@_subject: Length of new onion addresses 
Hash: SHA1
Hi Michael,
My bad. No worry, this is just a misunderstanding. What I should have
written is that a service's onion address (what clients bookmark or type
into their browsers) stays the same all the time.
What changes are the descriptor identifiers which are created from the
service id and the secret cookie. This allows for storing descriptors on
changing nodes all the time, which is a novel security feature that
becomes possible from incorporating the secret cookie. It prevents
persons from tracking a service's activity or usage pattern. I only
mentioned it to stress that the attack of generating a key pair with the
same id as an honest service would be limited to one day. Such an attack
would become more likely the fewer bits the service id has. But the
changing descriptor ids have no impact on the usage by hidden service
providers or clients.

@_date: 2007-03-20 17:55:10
@_author: Karsten Loesing 
@_subject: posting hidden service descriptors 
Hash: SHA1
Hi James,
Just a guess: Maybe Tor is "cannibalizing" an already existing circuit
and adding another hop before connecting to the directory? A one-hop
solution would case headaches for me, too. :)

@_date: 2007-03-23 10:15:18
@_author: Karsten Loesing 
@_subject: Hidden services 
Hash: SHA1
Hi JT,
Maybe I can help you with this.
All connections to introduction and rendezvous points are
sender-anonymous. This is depicted by the big onions on the slides.
These connections consist of more than one hop just as with circuits to
public servers. The standard hop count for each sender-anonymous
connection is 3.
Well, if _all_ Tor servers in the path from a client to a hidden server
were compromised, they could find out that the two are communicating.
Communication between the two is still end-to-end encrypted from the
client's to the server's Tor node. But the adversaries could make an own
attempt to connect to the hidden server and find out what it is offering.
Anyway, we are talking about at least 6 routers of which 3 are picked by
the client and 3 by the hidden service. So, it's not so likely that they
are all compromised. In fact, this is what Tor relies on. I think, you
should not be too nervous about that kind of attack.
The last node in the circuit, which is closest to the hidden server,
does not know that it is talking to the hidden service. The hidden
server opened a circuit to that router as done with every other circuit.
So, this router cannot conclude what the hidden server is doing. It
could also be - which is more likely - a usual client. If you are more
interested in attacks on this, you might want to read the paper by
?verlier and Syverson on locating hidden servers.
Hope this helps.

@_date: 2007-03-23 11:32:46
@_author: Karsten Loesing 
@_subject: Preconfigured hidden service 
Hash: SHA1
Hi JT,
Just a personal comment on your idea: Yes, it would be nice to enable
the other 80% to run their own hidden web server, just by moving files
into folders and clicking Next-Next-Finish. And I think this would
improve Tor.
The question is, whether this is a task for the core Tor. What I
personally like about hidden services is that they are free from any
specific protocol. You can run a web server, an ftp server, a chat
server, or whatever.
Maybe it's just a question of bundling Tor with other applications. I
could rather imagine a package with Tor, Vidalia, Privoxy, and a
pre-configured small web server that listens only to local requests.
Plus a one-page installation instruction with screenshot how to enable
the hidden server using Vidalia. Then we could address at least 60 out
of the 80% other users, without having to change Tor at all.

@_date: 2007-03-31 15:58:17
@_author: Karsten Loesing 
@_subject: Is this for real? 
Hash: SHA1
But wouldn't they have even more fun, if they called their server
"WeLovePrivacy"? At least, I would have, if I were them... ;)
Don't worry, the probability that it's an NSA server is the same as for
every other server in the Tor network.

@_date: 2007-03-31 16:27:49
@_author: Karsten Loesing 
@_subject: Is this for real? 
Hash: SHA1
That's an interesting issue. Who is scared by a suspicious server name
and would thereupon stop using Tor? Not the absolute beginner who does
not care about log files and not the expert who knows that an attacker
needs all 3 out of 900+ routers a user chooses to subvert her privacy.
However, I assume that the NSA would rather run 10, 20, or 50 nodes with
inconspicuous names, sit back, and see what they can observe. But who
knows? Perhaps they have multiple strategies? :)

@_date: 2007-03-31 17:01:56
@_author: Karsten Loesing 
@_subject: Example hidden service issue 
Hash: SHA1
Hi Mike,
In fact, that is not the information you want to hide. The server that
is to be hidden may know which Tor node is actually hiding it. Hidden
services are meant to hide the locations of the servers (here: Google)
from others.
Perhaps it's better if you think of another server than Google which you
would like to hide. I mean, for me, "Google" means the opposite of
"anonymity"---apart from Google summer of code supporting Tor which is a
step into the right direction. ;)
If you set up a hidden service, you provide access to a service in the
non-Tor network to a client connecting to you over the Tor network
(simplified picture):
client -- Tor proxy -- some Tor routers -- Tor proxy (YOU) -- Google
You advertise the server to the Tor network using an onion address. As
soon as you receive a request to the hidden service from a client, you
connect to Google with your own IP, perform the request, and respond to
the client over Tor.
I hope that this makes it a little clearer to you.

@_date: 2007-03-31 17:21:45
@_author: Karsten Loesing 
@_subject: Is this for real? 
Hash: SHA1
Hi Thomas,
Do people who use Tor without knowing how it works care about the server
list in Tork (which I don't know)? If so, and if it bothers them that
some server names are suspicious (and there will be more of them after
this discussion), then it might be a good idea to explain it in the Tork
FAQ. Short answer as from Alexander is enough: "Names mean nothing".

@_date: 2007-03-31 17:45:17
@_author: Karsten Loesing 
@_subject: Example hidden service issue 
Hash: SHA1
May sound like a bad idea, but does no harm at all.
Google does not learn from your tests that you are providing a hidden
service for it. The connections made during your tests are
indistinguishable from other direct connections you make to Google
everyday. There is no remark in them that they belong to a hidden
service request.
The only thing you should NOT do when setting up a hidden service after
the above mentioned howto is to give the onion address to Google BEFORE
changing to your own server. They could perform an altered request over
Tor (e.g. for a non-existing resource) and find out which IP address
requested that resource.
In case you want to be absolutely sure, you can simply switch to a new
onion address by deleting the hidden service key stored in your local
hidden service directory. That forces Tor to create a new key, and you
have a new onion address.

@_date: 2007-03-31 19:30:26
@_author: Karsten Loesing 
@_subject: Example hidden service issue 
Hash: SHA1
Was that me confusing everyone?! :( Sorry for that, my fault! The
descriptions above seem right to me.
These could indeed be new threats to hidden services; the first being
more threatening than the second. I could imagine that nobody has ever
thought about an untrustworthy (to be hidden) server, but only about all
the other untrustworthy nodes in the network. I assume I also need more
thinking on that... and more coffee...
Maybe it could help to switch steps one and two in the howto? First set
up the web server and try if it's available over and then make it available over Tor. Or is there a special reason for
this order that I overlooked?

@_date: 2007-05-15 22:42:17
@_author: Karsten Loesing 
@_subject: Setup Directory Server 
Hash: SHA1
Hi Eric
There are no special sources or binaries for directory servers. You can
use the same sources/binaries as for an onion proxy or onion router. The
only thing you need to change is the configuration in torrc.
Additionaly, you need to change the configurations of all clients to
contact your directory instead of the public directories using
DirServer. I think to remember that you need at least two directories to
run a Tor network. If you are unsure which configuration options that
are, look into the man page or let PuppeTor create an example
configuration that you can change afterwards.

@_date: 2007-05-15 23:08:47
@_author: Karsten Loesing 
@_subject: Setup Directory Server 
Hash: SHA1
Either I missed the irony in your post, or you have got something
seriously wrong. Of course, you cannot simply start a sixth
authoritative directory service by yourself that will be trusted by all
clients. And if you could, I wouldn't call that decentralization of
trust, but a serious security leak.
But it's a joke, right? (In this case I would like to promote the use of
smileys, so that the silly non-native speakers can understand the real
meaning, too.) :)

@_date: 2007-05-15 23:38:23
@_author: Karsten Loesing 
@_subject: Setup Directory Server 
Hash: SHA1
Nope, no way! You can run a directory *mirror* by storing and forwarding
the directory information of authoritative directories to clients. But
you cannot simply run your own authoritative directory server and write
an email to the Tor ops so that they trust you and add you to the list
of authoritative directories. The anonymity of Tor relies to a certain
extent on the trustworthiness of the directories. If you (and your
friends) could control a majority of the directories and convince
clients to use your own, potentially modified directory information, you
could pass different router lists to different clients and defeat their
anonymity by observing which routers they pick.

@_date: 2007-06-01 00:47:32
@_author: Karsten Loesing 
@_subject: All authorities have failed. Not trying any. 
Hash: SHA1
Though I have no idea about the __AllDir... stuff, I can give you a
first hint to solve it:
1970-01-01 00:00 + 37+ years = today
Now the rest is up to you. ;)

@_date: 2007-05-15 20:57:23
@_author: Karsten Loesing 
@_subject: Setup Directory Server 
Hash: SHA1
There is an own config option (DirServer) that you can use to override
the hardcoded dir servers.
If you want to play around with your own directory, you may want to use
PuppeTor which was designed to run your own Tor network on a local
machine. It manages all the necessary configurations for you. You can
download it from the SVN repository.

@_date: 2007-10-24 18:15:29
@_author: Karsten Loesing 
@_subject: Setting up a private tor network 
Hash: SHA1
Hi Csaba,
Quoting from your private mail (with your permission):
In PuppeTor I did not get 0.2.0.8-alpha to work in a private network
setting, but only versions up to 0.2.0.7-alpha. Further, the current
trunk (or what will become 0.2.0.9-alpha these days) introduces the new
v3 directories that make things a little bit more complicated:
The solution for building a private network with all versions up to
0.2.0.7-alpha is to periodically send HUP signals to the nodes until
they start building circuits. In principal you don't have to, but it
accelerates things a lot; as an example, I tried to create a private
network with 2 directories and 4 routers _without_ sending HUP commands:
3 out of 10 attempts built circuits after 15 minutes and a few seconds,
and the other 7 attempts took 60 minutes and a few seconds for it. The
multiples of 15 minutes should come from the interval in which directory
mirrors fetch networkstatuses from the directory authorities. When
sending HUP signals, the whole process takes about half a minute. The
reason is that directory mirrors refetch the networkstatus immediately
when reloading their configuration. As a side note: proxies behave
differently for this. If you want to read more, have a look at the
Javadocs of PuppeTor's ProxyNode class:
In 0.2.0.8-alpha-dev (and newer versions) you need to configure v3
directory authorities to get things working. There is a description how
to do this here:
 .
In order to speed up the process you can configure Tor to build
consensuses in shorter intervals. The following configuration worked for
me: V3AuthVotingInterval 10 minutes, V3AuthVoteDelay 1 minute,
V3AuthDistDelay 1 minute. Unfortunately, the process still takes about
half an hour, so this is only a first solution to get it working. If you
find a better solution, please let us know!
First of all, it's good to have multiple approaches to this problem. We
could both learn from the other approach and improve our tools.
My decision to not use a virtual machine for each node was that I did
not see why it should be necessary. In PuppeTor every Tor node has it's
own working directory and set of ports and should not interfere with the
other local Tor processes. The only output that I care about is what Tor
writes to its log files. My primary motivation for writing PuppeTor was
to test my developments on Tor hidden services which are rather
high-level in Tor.
However, when it comes to lower levels, like sniffing or altering
packets, my approach might be too limited. I'm not sure about that,
because I rarely used that. Thus, there is room for other approaches! :)

@_date: 2007-10-07 20:08:10
@_author: Karsten Loesing 
@_subject: Setting up a private tor network 
Hash: SHA1
Hi Shreyas,
Which Tor version do you use? I had a potentially related problem with
the current trunk version that had to do with private IP addresses and
the directories. You could try to set the new config option
"ClientDNSRejectInternalAddresses" to 0. That option is not described in
the wiki, yet. But I'm not sure if that will solve your problem, too.
Apart from that you might consider using PuppeTor for creating private
Tor network configurations and running whatever you want to test in it.
We developed it for testing and measuring hidden-service related things,
but it could also be useful for you. It also contains all our wisdom
measured in necessary configuration options and sending HUP signals to
create private Tor networks. You can find it here:

@_date: 2007-10-08 00:38:06
@_author: Karsten Loesing 
@_subject: Setting up a private tor network 
Hash: SHA1
Then you might encounter problems with 0.1.2.17, because PuppeTor is
configured to be used with the development versions. This is kind of a
dilemma: Newer Tor version require certain configuration options to be
used in a private setting which are not understood by older Tor
versions. So, you will need to remove some configuration strings before
being able to use PuppeTor with 0.1.2.17. Or use the trunk version. Or I
could include a version check and select configurations appropriately --
 sometime.
You could also use PuppeTor only to establish and initialize private
network configurations, without performing actual test. Afterwards, you
can re-use the working directories with their configuration files and
state files and start the Tor processes on your own. Up to you.
Hard to say without your log files. From PuppeTor I know that newly
configurated private Tor networks require multiple reloads before being
stable. And this process also fails quite often.
In general you should not have to change the Tor code to create a
private Tor network. Maybe your changes are what prevents Tor from
working properly?!
Could you try whether PuppeTor is able to create a private network
configuration for you -- with your changed and the unchanged Tor? If you
have specific questions on PuppeTor, e.g. how to configure it for
0.1.2.17, you could also mail me off the list. And if this all fails,
you could post a link to your info-level log files here.

@_date: 2007-09-26 16:27:09
@_author: Karsten Loesing 
@_subject: "Rejecting truncated ESTABLISH_INTRO cell" warns 
Hash: SHA1
Hi everyone,
Hmm, it looks like it was us (our university working group), trying to
include authentication to Tor hidden services.
For the moment, consider this as a rather agressive marketing strategy
to promote our new proposal on hidden service authentication, which we
by the way just sent to or-dev:
And the plan worked, didn't it? ;)
However, if this explanation did not convince you: It simply was a
modified Tor client going wild. The test was intended to be performed in
a private Tor network, but for some reason our Tor nodes connected to
public Tor nodes. Sorry for the confusion! In the future, we will try to
keep our packets at home. If we should fail at this, please mail me, as
it is unlikely that it was someone else.

@_date: 2007-09-07 16:12:11
@_author: Karsten Loesing 
@_subject: [german] Suche Strafrechtler (Vorwurf: Verbreitung KiPo) 
Hash: SHA1
Hallo Theodor,
(Answering this mail in German, as it looks like a German problem...)
Bin kein Rechtsanwalt, kenne aber ein paar Details eines ?hnlichen Falls
vom Fr?hjahr 2007.
Wenn nicht das BKA dahinter steckt, kannst du dir ziemlich sicher sein,
dass die Kenntnis ?ber Tor bei der Polizei/Staatsanwaltschaft relativ
begrenzt ist, und dass du ?ber eine Argumentation mit Tor wenig
erreichen wirst.
Versuchen kannst du es trotzdem. Du k?nntest ihnen beispielsweise einen
Nachweis liefern, dass dein Rechner zum Strafzeitpunkt im Tor-Netzwerk
als Exit-Node registriert war. Die Logs der Directory Authorities
findest du mit "rsync asteria.noreply.org::tordir". Wenn du dabei Hilfe
brauchst kannst mir auch gerne noch einmal mailen bzw. bin ich nachher
auch im Allerdings ist das nat?rlich kein Beweis daf?r, dass du nicht trotzdem
den Zugriff selbst gemacht hast. Im Zweifel bleibt dir nur die
Untersuchungen abzuwarten.
Versuche es einmal mit einer Mail an den CCC (anonymizer at ccc.de). Die
k?nnen dir vielleicht weiterhelfen.
W?nsche dir viel Erfolg bzw. eher viel Geduld! Lass dich nicht
unterkriegen! :)

@_date: 2008-08-04 10:35:00
@_author: Karsten Loesing 
@_subject: SIGHUP without effect 
Hash: SHA1
Hi Scott, Hans,
this might indeed be a bug, or at least a behavior that should be
changed. However, some more information about it would be helpful in
finding out what exactly is wrong.
The first thing is a description of what needs to be done in order to
reproduce the problem. Is it just setting up a relay and, well, waiting?
If so, how long does one have to wait? Can you provide your torrc files?
Could you reproduce the behavior yourself after you experienced it the
first time? What was the first Tor version that had this problem, and
can you confirm that previous versions didn't have it?
At some time, preferably when we have more information about what's
going on, someone should open a flyspray task for this bug. or-talk is
not the best place to discuss bugs. :)
How did you figure that out? Could you paste the log statements?
The explanation might be that the authorities don't store router
descriptors when changes are considered cosmetic. However, after 12
hours time difference between storing two descriptors, changes should
never be considered cosmetic, regardless of how subtle they are.
Okay, so what is SIGHUP supposed to do here? From the manpage:
"SIGHUP The signal instructs Tor to reload its configuration (including
closing and reopening logs), fetch a new directory, and kill and restart
its helper processes if applicable."
I might be wrong, but as far as I understand this, sending a HUP signal
does not necessarily include uploading a new descriptor that is then
accepted by the authorities. Why should this happen if the currently
stored descriptor is fine?
Well, this behavior is not intended. It would be quite interesting to
figure out when this situation occurs. Please provide more information
(as stated at the top of this mail).

@_date: 2008-08-05 15:01:06
@_author: Karsten Loesing 
@_subject: questions about MinUptimeHidServDirectoryV2 in 0.2.1.2-alpha 
Hash: SHA1
hours?  And
or goes
why not
The default of 24 hours ensures that hidden service directories are
available for the next few hours with a certain probability. The idea is
that there are hundreds of hidden service directories at some point
which are not authoritative any more, but provide a more scalable and
robust storage than the three authoritative ones can. Hidden services
and clients need to have a view as consistent as possible of which
hidden service directories are out there, so that clients can find
previously stored hidden service descriptors. The 24 hours have turned
out to be a characteristic that allows distinguishing highly available
relays from others. The rationale behind it is that a certain number of
relay operators turn their relays off over night. The following diagram
shows the variation of relays with different minimum uptimes over an
interval of 2+ months. You can see the difference between minimum
uptimes of 16 hours and lower and those of 20 hours and higher. That is
the reason for the default of 24 hours.
The option MinUptimeHidServDirectoryV2 is mainly there to perform tests
with the distributed hidden service directory without having to wait for
24 hours. It is not required to set it in the public Tor network. (It
only has an effect on directory authorities anyway.)
I should probably make the design paper of the distributed hidden
service directory available rather soon. It answers questions like yours.
Hope that helps!

@_date: 2008-08-06 17:27:13
@_author: Karsten Loesing 
@_subject: SIGHUP without effect 
Hash: SHA1
Hi Hans, Scott,
Correct. dir-spec.txt says that relays generate and upload a new router
descriptor when: "- Bandwidth has changed by a factor of 2 from the last
time a descriptor was generated, and at least a given interval of time
(20 mins by default) has passed since then." (They further do in other
situations, but this is the only one that is bandwidth-related.) The
directory authorities perform the same check when deciding whether or
not to store a router descriptor.
But you are right, this doesn't explain why Tor should stop publishing
descriptors afterwards.
something like
Ah, that's reasonable. Well, log statements are my primary source to see
that something is going wrong. So in this case I wondered which log
statement might have lead you to your conclusions. I didn't find one
that was directly related, so I asked if there was another one I might
have overlooked. After all, it could be something like "There is
something wrong with the descriptor I just wanted to upload, so I'll try
again later" (or something similar). So, it makes sense to turn on
logging in this case (probably even on debug level) to track down this bug.
Just to get this right: You changed your configuration once or multiple
times to force Tor to upload new descriptors, and at some time later
(about 18 hours) you realize that it has stopped publishing new
descriptors, correct? At that point even changes to your exit policy
don't make Tor publish a new descriptor any more, but you have to
restart it. (All of this should be fine to do, I'm just trying to
understand what is happening.)
Okay, I'll try to reproduce the bug myself and have a second look at the
code. However, if either of you finds out information that might help in
finding this bug, please share.

@_date: 2008-08-06 18:06:35
@_author: Karsten Loesing 
@_subject: questions about MinUptimeHidServDirectoryV2 in 0.2.1.2-alpha 
Hash: SHA1
Hi Scott,
The big difference is that every hidden service directory is responsible
for a certain set of hidden service descriptors and not all of them.
If you run a hidden service you determine six responsible hidden service
directories depending on a) the onion address of your service and b) the
node identities of the hidden service directories. Then you store your
descriptor on exactly those directories.
Your clients need the same or at least very similar information about
hidden service directories as you have. If their list of directories
contains further directories or misses some of those that you know, your
clients will end up requesting your descriptor from the wrong
directories. A further difficulty comes from the fact that your clients
and you might use consensuses with up to two hours time difference. A
certain number of differences is tolerable by performing replication,
but these shouldn't get too big.
These flags have different purposes, and their definitions might change
in the future (as might the definition of "HSDir"). Apart from that
there needs to be an "HSDir" flag anyway to denote which relays want to
participate in the hidden service directory.
Admittedly, a further evaluation could compare the approach taken here
with your approach to derive usefulness of a hidden service directory
from "Guard" and/or "Stable" flags instead. Honestly, I don't know what
the result would be. Seems that there's always work left to do. ;)
"Directory Size" refers to the size of the distributed hidden service
directory, assuming that *all* relays that have their directory port
open work as hidden service directory. Of course, this number differs
significantly from the current number of hidden service directories.
That's why one proposed change of proposal 143 (which is planned to be
implemented in 0.2.1.x) is to make all relays with open dir port act as
hidden service directories by default, with the possibility to opt-out.
"Time Index" is admittedly a bad axis description, which however comes
from the fact that I didn't know how to write month names
appropriate places of the x axis in R. :) The x values denote the hours
of evaluated consensuses between mid-January and end of March. The peaks
that you see for minimum uptimes, e.g., of 4 to 16 hours are the days in
that interval. Now compare the peaks of using no minimum uptime at all
with those of requiring an uptime of 24 hours. If there would be no
requirement for minimum uptime, replication would have to be increased
I think I have already answered these questions above. If I should have
left out something, please ask.
Hope this helps a bit more now. :)

@_date: 2008-12-12 12:18:39
@_author: Karsten Loesing 
@_subject: How many hidden service circuits built? 
Hash: SHA1
I'm not sure what you are up to, so I'm guessing. Are you asking for a)
parallelizing connection establishment in order to reduce delay, b)
having a separate circuit to the hidden server for every
application-level stream, or something else?
As for a), we are already working on improvements to reduce the delay in
connection establishment. Did you have a look at this page?:
Part of the solution is to parallelize some of the substeps. One example
are circuits to introduction points which are built in parallel after a
delay of 15 seconds. Future ideas are to request hidden service
descriptors from the directories in parallel. But making two (or even
more) full connection establishments with all steps being performed
twice (or more times) is a bit too brute-force, isn't it? The goal is to
make hidden services faster, but in a way that doesn't put too much new
load on the network.
As for b), I don't know if this makes sense, either. Why separate the
circuits when you can multiplex an arbitrary number of streams over
them? Fault tolerance? Unlinkability of streams?
But instead of guessing what you had in mind, I'll just ask: Why do you
want to do this?

@_date: 2008-12-13 15:35:48
@_author: Karsten Loesing 
@_subject: How many hidden service circuits built? 
Hash: SHA1
Hi Bernhard,
You might also want to read the documents that are linked from the NLnet
project page, for example:
Okay, we didn't change anything about path selection so far. One reason
is that this might have serious consequences on anonymity. While it
would be great to make Tor and hidden services faster by using only the
best nodes available, this largely destroys anonymity. All changes here
should be made with extra caution!
See the measurements in the analysis linked above. This document
contains some data about message transfer times after connections are
established. Basically, we excluded message transfer times from the
project, because they didn't seem to be a problem of hidden services,
but rather of Tor in general.
Even though this would constitute a local optimization, the effects on
overall network load would be seriously bad. There must be ways to
improve RTTs which waste less resources than this approach.
One solution might be to change path selection for rendezvous circuits,
both on client- and server-side. If we knew what relays to pick for
these circuits which are likely to deliver good RTTs, we could improve
RTTs for the 6-hop circuit from client to server. Again, changing path
selection requires caution as stated above.
Another solution is to start performing QoS for hidden services. In
combination with client authorization (see proposal 121), hidden servers
could decide whether to pick an extra-fast circuit to connect to the
client's rendezvous point, or not.
Having said that, did you look at proposal 121 for OnionCat. I could
imagine that OnionCat would make good use of the additional security
that client authorization offers for hidden services. See also a
Technical Report on that topic:

@_date: 2008-02-15 10:31:13
@_author: Karsten Loesing 
@_subject: puppetor setup 
Hash: SHA1
Hi skaoth,
de.uniba.wiai.lspi.puppetor.impl.ProxyNodeImpl startNode
Please go check the config options in
Did you try to run Tor with the mentioned config file like "tor -f
that-torrc-file"? There is probably a config option in that file that is
unrecognized by Tor...
... which brings us to the question which Tor version you use.
Unfortunately PuppeTor only works with versions around 0.2.0.7-alpha
which was the last version that I used it for. Later versions require v3
directory settings and earlier versions don't provide some of the config
options (for example ClientDNSRejectInternalAddresses is such a
troublemaker). So, you could either try to run PuppeTor with other Tor
versions, or remove those unknown config options before writing node
configurations (see comments below for how to do that).
Sorry for the inconvenience! I planned to make PuppeTor compatible with
current 0.2.0.x versions for a long time, but always deferred it for
other things. Well, at least you helped prioritizing this task in my
todo list. :) Ah, damnit, this is open source: "Feel free to send a
patch." :D
You can change the configurations of all nodes created by PuppeTor,
either by changing their template (for directory nodes, routers or
proxies) or single configurations, e.g. with the methods
ProxyNode.addConfiguration() or Network.addTemplateConfiguration().
Please also have a look at the Javadocs for that.
If you have questions about PuppeTor, you can either mail me directly or
bother the or-talk list.

@_date: 2008-02-16 21:46:54
@_author: Karsten Loesing 
@_subject: .onion sites fail to load with: (waiting for rendezvous desc) 
Hash: SHA1
Some days ago there was a guy on  with a similar problem. You? :)
After trying out some things which did not appear to have any direct
effect, it suddenly worked again for him.
I just tried to access two hidden services. Worked fine. But obviously,
there is a bug that we should track down. Maybe you can help us with that?
What does "almost never" mean? How often does it work? What happens when
you restart Tor and try again? What if you wait for some minutes after
starting Tor before trying?
With "latest Tor alpha" you mean 0.2.0.19-alpha? Did you try to compile
and run current trunk? Unfortunately one bug fix for 0.2.0.19-alpha
turned out to be erroneous and was reverted in current trunk. But I
doubt that it's the one causing the problem you describe.
What versions are the people running who say that it's working for them?
Can you tell the .onion address in public or in private mail to me? Or
another service that you can tell? If not, do you know by any chance who
is running such a service and whether they are running version
0.2.0.10-alpha or higher?
Can you reach the example hidden service or my v2 test service  ?
Thanks for your help!

@_date: 2008-01-13 14:19:26
@_author: Karsten Loesing 
@_subject: tornode lefkada 
Hash: SHA1
signing key 0000000000000000000000000000000000000000: launching request.
this node from the list of nodes?
There have been several reports of this problem and several answers.
Here is one:

@_date: 2008-01-26 13:50:58
@_author: Karsten Loesing 
@_subject: HidServDirectoryV2 option 
Hash: SHA1
Hi Olaf and all,
Known drawbacks? No. Bugs? Maybe, but none that we know about.
We did not publicly announce this new config option yet, because there
was still some code about v2 hidden service descriptors that needed to
be included in trunk. But since last night (!) everything is in.
So, what happens when you set "HidServDirectoryV2 1"? Your relay will
become part of a DHT-like directory for hidden service descriptors.
Hidden servers with version 0.2.0.10-alpha or higher publish their
descriptors to a subset of these relays in addition to (some day:
instead of) the directory authorities. And clients with version
0.2.0.10-alpha or higher fetch descriptors from those relays in parallel
to (some day: instead of) fetching descriptors from the directory
authorities. The idea is to have a large number of relays having that
config option set, e.g. some hundreds.
So, if your relay has a current alpha version (0.2.0.16-alpha or
higher), please consider adding that config option. The more the better.
Note: Your relay needs to run for at least 24 hours before being listed
as hidden service directory in the Tor status.
If you want to learn more about v2 hidden service descriptors, have a
look at proposal 114:
Again, no guarantees that there are no bugs anymore. But without testing
we won't find them.
So, I would suggest: Let the testing begin! :)

@_date: 2008-01-28 22:37:26
@_author: Karsten Loesing 
@_subject: HidServDirectoryV2 option 
Hash: SHA1
Yes, there are multiple documents on different technical levels.
The first is my GSoC 2007 application which contains the general idea,
some pre-studies, and a brief security discussion; however, the design
as described there has slightly changed while writing the specification
and implementing it, so it is only about 90 % accurate:
Then, proposal 114 contains a more accurate description of the design as
it is implemented now, but with fewer explanations:
The relevant parts of the proposal are also included in rend-spec.txt:
Just in case you need something more citable: I'm currently writing a
paper about it (and some other stuff). If you like, I could send you the
submitted version (as soon as it is submitted) via private e-mail.
If you have comments on any of these documents, please feel free!
Hope this helps!

@_date: 2008-05-18 23:41:02
@_author: Karsten Loesing 
@_subject: ContactInfo? 
Hash: SHA1
Hey Nathaniel,
That doesn't matter so much. The intention of the contact line is not to
parse it automatically (previous attempts were not very successful), but
are read by humans. In fact, it might be better to obfuscate that line a
bit in order to prevent the bots from collecting your address -- or make
their "lives" a bit harder. Further, in most cases your GPG key won't be
used to encrypt notice message to you or verify your mails to us anyway.
By the way, thank you for running a relay!

@_date: 2008-05-07 18:53:31
@_author: Karsten Loesing 
@_subject: Tor On Private Network 
Hash: SHA1
ServerDNSAllowBrokenResolvConf sounds like a useful option here.
Have a look at the last section of proposal 135 that contains a bunch of
useful config options for private Tor networks:

@_date: 2008-11-11 10:38:22
@_author: Karsten Loesing 
@_subject: Version deprecated? 
Hash: SHA1
Whoops. They were missing in the config after moving gabelmoo to new
hardware and recreating its config from an older backup. Fixed.

@_date: 2008-11-11 17:50:08
@_author: Karsten Loesing 
@_subject: Hidden service route 
Hash: SHA1
No, that's not how it works. There are 6 nodes between you and the
hidden service, three chosen by the hidden service, three chosen by you.
See  for a description of the
hidden service protocol.
Changing the route length should have minimal impact on performance. The
step that takes time is to extend an existing circuit by another hop. I
guess it has only minimal impact on performance whether you extend a
3-hop circuit to a fourth node, or a 2-hop circuit to a third node.
You might want to try the latest alpha (0.2.1.7-alpha). It contains some
improvements to speed up hidden services.

@_date: 2008-11-13 10:23:36
@_author: Karsten Loesing 
@_subject: Error "Making tunnel to dirserver failed" 
Hash: SHA1
Looks like bug 767:
It's fixed in 0.2.1.6-alpha and will be fixed in 0.2.0.32, too.

@_date: 2008-11-03 01:33:17
@_author: Karsten Loesing 
@_subject: Future Development on Hidden Services 
Hash: SHA1
Hi list,
as some of you may know, there have been several improvements to hidden
services lately. First, hidden services publish their descriptors to a
distributed directory [1] consisting of currently 71 nodes. Second,
hidden services may require client authorization already during
connection establishment to block unauthorized requests as early as
possible [2]. Third, hidden service performance has been improved with
respect to advertising and accessing hidden services [3,4].
Certainly, there are still things that can (and should) be improved.
This is an attempt to compile a good list of future development tasks on
hidden services. Comments are most welcome. If there are other things
with hidden services that need improvement, please let us know.

@_date: 2008-11-07 16:44:09
@_author: Karsten Loesing 
@_subject: any middlemen seeing DoS currently? 
Hash: SHA1
This might be the problem, yes. The reason is that ides' authority
certificate has expired. But clients do not differentiate between a
(temporary) download problem and the situation that a certificate has
expired and a new one needs to be created (which is rather unlikely to
happen within the next few minutes). So, clients send another request
for a certificate every minute. All clients running 0.2.0.x or higher do
this, which is why there is so much additional traffic in the network.
The problem of clients downloading certificates that often will be
solved with the next alpha. But the main solution is to upgrade the
authority certificate which should happen some time today.

@_date: 2008-11-07 20:24:16
@_author: Karsten Loesing 
@_subject: any middlemen seeing DoS currently? 
Hash: SHA1
A new certificate is now in place. This should clear things up really
soon. The authorities should exchange the new certificate during the
next voting process (in roughly 30 minutes). Then clients will be
satisfied with the new certificate and stop requesting a new one repeatedly.
That means there is not enough time for an official announcement. Or
rather, the effect would not be as significant as compared to the
resulting confusion.
Sorry for the trouble! This will be fixed in future Tor versions. And we
will pay more attention to expiring certificates.
The next certificate expires on January 17, 2009. Mark the date. ;)

@_date: 2008-09-13 13:36:27
@_author: Karsten Loesing 
@_subject: invitation to directory server operators 
Hash: SHA1
Hi all,
the quoting approach doesn't work here any more, so that I try to
address the main questions directly; if I should have overlooked
something important, please let me know:
One question was why we didn't announce the feature of configuring a
node as v2 hidden service directories (HSDir in the folling) earlier:
This feature was introduced in one of the alphas of the 0.2.0.x series.
Back then I asked some people I knew to configure their node as HSDir to
have a number of 3--6 HSDirs as a basis to get it running.
Unfortunately, there was a major bug in one of the alphas (I don't
recall if it was in the HSDir code or not, but anyway, it's fixed long
ago, so no worries). The result was that the one of the more
high-bandwidth nodes crashed and the node administrator downgraded to
0.1.2.x. At that time I refrained from asking more people to be beta
testers before being more sure that it works more stable. Now that the
HSDir code runs for quite some time without making trouble, I would say
it is stable; which doesn't rule out the possibility of bugs completely,
though. It was also on my TODO list to make an announcement, but not on
top position, so that Scott got ahead of me with his announcement. It
wasn't urgent, though, because the v0 directory is still running in
Scott asked whether enough people turned on this option now: Not if we
want the distributed directory be as stable and reliable as it was
planned in its design. It is really awesome that so many people followed
the announcement here, but we need as many HSDirs as possible. The
concept depends on distributing descriptors among hundreds of nodes in
the long term. This is required for higher reliability in face of single
failing and corrupt nodes. Plus, it even gains more importance for
hidden services with client authorization (see proposal 121) where you
have separate hidden service descriptors for different clients that
should not be linked together. With only a few HSDirs we need to rely on
delaying descriptor publication for different descriptors from the same
hidden service going to the same HSDir. With hundreds of HSDirs we can
make this significantly faster. But this whole thing is not even
completely implemented in trunk, so give us some time before announcing
it here. (See proposal 121 for more details if you are interested in that.)
Andrew found out that it is not required to open the DirPort in addition
to setting the HSDir configuration. While this could on the one hand be
considered a bug, it shows on the other hand that this requirement is
really redundant and can be dropped. Originally, this requirement stems
from a time when it was not clear that we can tunnel directory requests
over the OR port. This works by extending a circuit to the OR port of a
relay and sending a so-called BEGIN_DIR cell that contains a directory
request and can be answered directly instead of a command to open a
connection to another server or something like that.
Then there was a question why nodes need to have an uptime of 24 hours
or more: As was discussed earlier on this list, this is a means to
ensure high availability of HSDirs. If one looks at the number of nodes
over time and removes nodes with lower uptime than 24 hours, one gets a
very smooth graph with low variations. Unfortunately this excludes
people on daily disconnected DSL lines. Sorry for that, but if we want a
reliable distributed hidden service directory, we really need reliable
nodes that don't change their IP address. Hidden service clients shall
be able to find a hidden service descriptor even when it was published a
few hours ago.
Finally, there were some questions about legal issues when configuring a
relay as hidden service directory. I can't answer those, sorry. Please
consult your lawyer, or turn off this option. We will add a remark in
the sample torrc (and maybe other places) that this option can be turned
off when 0.2.1.x goes stable (at the latest).

@_date: 2008-09-17 13:10:56
@_author: Karsten Loesing 
@_subject: PET Convention 2008.2 on Sep 30, 2008 in Darmstadt, Germany 
Hash: SHA1
Hi everybody,
even though this is not perfectly on-topic (sorry for that!), I figured
that some people on this list might be interested in the next
Privacy-Enhancing Technologies Convention that will take place on
September 30, 2008 in Darmstadt, Germany. From the homepage:
"PET-CON is a convention to help junior researchers, master and diploma
students, to come together and exchange ideas. For this purpose, we're
holding this event every six months at an easily reachable location
somewhere in Germany or nearby.
The convention is organized according to the grass roots approach: from
young researchers for young researchers. Therefore, there is no formal
dress code, no filtering of contributions, and no participation fee. If
possible, we plan the convention in a way which allows people to travel
there and back home on the same day -- so that busy people can
participate as well."
Please find more information on the convention on Sep 30 here:

@_date: 2008-09-03 10:17:52
@_author: Karsten Loesing 
@_subject: Tor On Private Network 
Hash: SHA1
A fine question. Your config looks sane, but I'm running into the same
problem. I'm sure we could figure that out, but you should rather
consider running the v3 directory protocol instead of v2. At least I can
tell that it's working with a v3 directory authority.
You'll find more information about running a private network with a v3
directory authority here:
And at some point there will also be an update to the FAQ entry...
As an example, this is a torrc for a private Tor network with three v3
directory authorities (you can leave out some of the options):
DataDirectory .
SafeLogging 0
UseEntryGuards 0
Log info stdout
Log info file log
ControlPort 4324
SocksPort 4325
ContactInfo wont at reply.org
HidServDirectoryV2 1
ORPort 4326
Nickname dir1
DirPort 4327
Address 127.0.0.1
ORListenAddress 127.0.0.1
DirListenAddress 127.0.0.1
AuthoritativeDirectory 1
V2AuthoritativeDirectory 1
V3AuthoritativeDirectory 1
DirAllowPrivateAddresses 1
MinUptimeHidServDirectoryV2 0 minutes
TestingTorNetwork 1
DirServer dir3 v3ident=09C9ADB5E47D2536C17FB91AE7A43B1B215A624E
orport=4334 127.0.0.1:4335 49A7 4E44 B7EC A22C 72CC B5E2 EAEB 6CDB 529A 2B2A
DirServer dir1 v3ident=588CC7268BEC4224E913F5E723059B694494C42C
orport=4326 127.0.0.1:4327 62C0 0C87 1C55 6726 AB9E BAA7 9316 519C 4A3F 7B7D
DirServer dir2 v3ident=B66E944D985D9D3F6AC77D2B4CC44E2CF249A6E4
orport=4330 127.0.0.1:4331 ABAD 3F46 5EAA 7A97 AD29 D42B 53E7 EE77 1939 F943
It should be sufficient to run a single directory server pointing to
itself (all the other nodes in the network need to point to it, too).
Hope that helps,

@_date: 2008-09-11 22:20:01
@_author: Karsten Loesing 
@_subject: invitation to directory server operators 
Hash: SHA1
Good that you bring this up, Scott! Most of the proposal you refer to is
implemented, but it takes a while for the code to make it into trunk.
This one was now assigned a higher priority. :)
The new default value for storing and serving v2 hidden service
descriptors is now implemented in trunk and will be part of 0.2.1.6-alpha.
This does not, however, mean that it will be backported to 0.2.0.x
anytime soon (or at all). People who run a 0.2.0.x relay still need to
set the option manually as described by Scott:

@_date: 2009-04-21 13:51:43
@_author: Karsten Loesing 
@_subject: Google Summer of Code 2009 
Hash: SHA1
Glad to have you with us! :)
And thank you for starting the introductions on this list. It would be
neat if the other GSoC students did the same. A paragraph or two about
you and your projects would be nice. Just go ahead, it's the community
bonding period [0]. Community meet $student, $student meet community!

@_date: 2009-12-03 08:29:29
@_author: Karsten Loesing 
@_subject: Exit archives 
You might want to look at this Python script that parses the descriptor archives to tell you exactly what you are looking for. It also comes with a HOWTO explaining which files you need:
I'm afraid there isn't, sorry.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2009-12-03 19:22:43
@_author: Karsten Loesing 
@_subject: Exit archives 
If it doesn't compile, you might want to try the Java version of the
script (requires Java 6; maybe 5 works, too) that has identical results.
Or you need to upgrade to Python 2.6.2 or higher.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2009-01-14 23:10:10
@_author: Karsten Loesing 
@_subject: Questions about gathering information and statistics about the 
Hash: SHA1
Hi Sebastian,
That sounds like a fun project! :)
I'm a bit in a hurry and cannot answer your posting in detail, sorry for
that. But let me give you some pointers now.
Well, first of all, I should say that your concerns about possibly
endangering anonymity of Tor users are very important. The data you
collect should not be usable to deanonymize Tor users.
For example, you mention collection of data on entry nodes (and that you
don't want to collect them, okay). What you should _not_ do is collect
precise data about who connected to your entry node at what time.
Someone else could collect similar data on their exit nodes what targets
are requested at what time. Both data sets don't pose a risk on their
own, but put together... *ouch*   A better way to collect such data
would be to aggregate them over, say, 24 or 48 hours, aggregate them by
country instead of memorizing single IP addresses, and round them up to
multiples of 8 or 16. That's about how geolocations of directory users
can be collected right now.
If you wanted to experience a few dozen enraged privacy researchers, you
should have been at last PETS when a study on the Tor network, 'Shining
Light in Dark Places: Understanding the Tor Network', was presented.
Apart from the authors' consideration to make their data available to
the research community in an 'anonymized way' (I don't recall their full
plan for anonymizing them), that paper is a good read! ;)
So, the right way to collect data about an anonymity network is for sure
a hot topic. Prepare for a lively discussion here. ;)
Anyway, I wanted to give you some pointers. Did you know that gathering
good statistics of the Tor network is on the 3-year roadmap (Section 5.7)?
This should really not stop you from doing your own statistics! We have
just started with that and there's definitely enough fun work left to
do. :) But maybe some thoughts in that document are interesting for you.
Also, you might be interested in an analysis of bridge usage in Tor. The
bridge authority Tonga collects data about all bridges in the network in
order to give them out to bridge clients. These data are also archived
for later statistical analysis. The approach of evaluating these data
might be interesting for you. The data model is more or less the same as
for non-bridge data. Ah, and please keep in mind that this is only an
early draft of the analysis *cough*. If you want, you can find the
evaluation scripts in the parent directory of the same SVN repository:
There will be some more statistics on the Tor network within the next
weeks. My plan is to evaluate archived network statuses, router
descriptors, and extra-info documents of the past 12 months to get a
better idea on the network growth and related facts. Further, I'd like
to evaluate geolocations of client requests to the directory authorities
and directory mirrors. And I want to finish that bridge data analysis.
So, to answer one of your questions: Yes, people are interested in such
statistics. :)
If you have ideas on what data should be collected (and how that can be
done in an anonymity-preserving way) or what statistics should be
performed with existing data, your input is most welcome!
And sorry again for ignoring most of your posting. I'll try to get to it
the next days.

@_date: 2009-01-18 13:17:17
@_author: Karsten Loesing 
@_subject: Questions about gathering information and statistics about the 
Hash: SHA1
Hi Sebastian,
It's not that these data are non-public, but there is currently no way
to request them from the directory servers. And unfortunately, I don't
have a good sample at hand, as I don't collect these data right now.
But I think you should be able to generate them on a directory mirror,
too. Have a look at the DirRecordUsage* config options (grep for them in
the code). You may also need to configure --enable-geoip-stats.
Correct. Often, bridge admins are disappointed that they don't help Tor
'enough', because they see so little bandwidth. But people who don't
have much bandwidth to share do help the network by setting up a bridge.
As Roger has stated several times, bridges might become even more useful
in the future. So it's good to already have a solid number of bridges
when they are needed.
One explanation that comes to mind is that some corporate filtering
systems make it necessary to use bridges.
I would have to look this up in the spec, but I think there is no
anonymity gain by using bridges in terms of an 'extra hop'. Bridges
replace the first node in a circuit, so that circuit are 3 hops long, too.
Starting with the descriptors is a good idea. You can collect them with
Peter Palfrader's directory archive scripts in the contrib/ directory.
Right, making data available might turn out to be difficult. I haven't
looked at specific frameworks, yet. One option would be to integrate
more graphics into TorStatus (
Kasimir Gabert did a great job displaying bandwidth histories for the
past day, week, month, and so on. Maybe these graphics can be extended,
given that we have good data to present.
Ah, the exam phase? :) If so, good luck with that!

@_date: 2009-01-24 16:35:18
@_author: Karsten Loesing 
@_subject: Questions about gathering information and statistics about the 
Hash: SHA1
Hi Sebastian,
Yes, the existing TorStatus pages already contain enough information, so
this would mean adding more pages. I rather meant using and extending
the infrastructure of TorStatus to collect, store, and present data
about the Tor network. This extension could allow users to select what
data they are interested in and generate graphs for them. But to be
honest, I haven't looked into any technical realizations so far. It's
just an idea.
That looks great so far!
You shouldn't wait for the perfect time to make your code available --
there is no such time. Nobody expects your code to be perfect from the
beginning. You might consider putting it into the Tor SVN repository or
make it available at some other place. And of course: Commit early,
commit often!
Also, when your exams are done, you might want to hang out at  (if
you aren't there already). It's probably easier to discuss designs there
than filling the mailboxes of the people here. :)

@_date: 2009-07-10 19:50:30
@_author: Karsten Loesing 
@_subject: Bad Exit Node 
Hash: SHA1
Why do you think it's flagged as Bad Exit?
This is what the current network status says about your node:
r Romulus /30/iO64x+ENBABbRdf9JOVyk+k wcVamAnXtevgQeBzsOZ5TuX0YAc
2009-07-10 15:48:21 92.241.164.157 9001 9030
s Exit Fast Running V2Dir Valid
v Tor 0.2.0.35
w Bandwidth=50
p reject 25,119,135-139,445,465,587,1214,4661-4666,6346-6429,6699,6881-6999
Where did you see that your node has the BadExit flag?

@_date: 2009-07-10 20:12:10
@_author: Karsten Loesing 
@_subject: Bad Exit Node 
Hash: SHA1
That page says that your node does not have the BadExit flag. All flags
are listed, but your node only has those with a green check mark. Your
node didn't have the BadExit flag the whole day.

@_date: 2009-07-26 12:37:06
@_author: Karsten Loesing 
@_subject: warning message question 
Hash: SHA1
FYI, gabelmoo is passing directory requests through Apache for two
reasons: First, I have been using Apache as a first attempt to measure
how long clients take to download network statuses in order to derive
how fast clients are; this functionality is now in 0.2.2.0-alpha-dev, so
that Apache is not required anymore for this:
Second, I'm using port 80 both for serving the Tor directory and for
serving files for performance measurements:
It's back online now.

@_date: 2009-07-04 13:32:46
@_author: Karsten Loesing 
@_subject: many new relays 
Hash: SHA1
It's not that simple. Every descriptor is stored in a separate file.
Archiving the cached-* files would add a lot of redundancy.
Good idea. Removing the crypto parts did the trick. The compressed June
descriptors are now 20 MB rather than about 100 MB before. I think we
can afford the bandwidth (even if 50 or-talkers download the thing):
You'll probably want to use the published timestamps or write your own
little parsing application to match descriptors with network status
lines in the consensuses:
(I'll remove both links in 1 month from now.)
Let us know what you find!

@_date: 2009-06-14 13:09:02
@_author: Karsten Loesing 
@_subject: Hackers exploiting tor clients on .onion sites? 
Hash: SHA1
So, did I get this right? You are concerned about certain log messages,
you even searched them on the Net, but you deleted them afterwards
(including the searches in your browser history) and are telling us now
that something strange is going on when visiting .onion sites?
I'm not saying there cannot be bugs in this part of the Tor code. But
what you describe is rather unlikely. I'm not aware how someone could
write anything to your log file---nor why he/she should want to do that.
Should you encounter these messages again, please retain them and file a
bug report: For the fun of it you might also want to verify that you are running an
official Tor version:

@_date: 2009-06-30 15:27:55
@_author: Karsten Loesing 
@_subject: many new relays 
Hash: SHA1
I have uploaded a tarball of the 00:00 UTC consensuses from June 1 to
30, 2009 here (3.3 M):
If someone needs the consensuses in between (709 M including votes) or
the server descriptors (760 M uncompressed), please let me know via
private email. (We're still in the process of finding a better way to
make these files public, but then there are always tasks with higher

@_date: 2009-06-30 21:22:31
@_author: Karsten Loesing 
@_subject: Obfuscated URLs? 
Hash: SHA1
Two thoughts:
- - What you describe as obfuscated URLs sounds a lot like precursor
designs of hidden services. For example, encoding a path into the
locator works only as long all nodes in that path are functional. Hidden
services (and other designs) have directory services to overcome that
problem. Why make a step backwards?
- - Tor is made for interactive communication, not for exchanging single
files. Even if you don't intend to exchange bulk files, others will do
so. Unfortunately, the Tor network does not have the necessary capacity.

@_date: 2009-03-01 15:22:48
@_author: Karsten Loesing 
@_subject: Questions about gathering information and statistics about the 
Hash: SHA1
Hi Martin,
who maintains TorStatus these days? Is it you, Kasimir, both, even more
people...? :) Is there a mailing list, IRC channel, or some other way to
contact you rather than or-talk?
Looks like a great start to me!
Right now, I'm investigating options to display more statistics about
the Tor network:  . TorStatus
seems to be a promising tool for that.
What would you say, how hard would it be to add router descriptors from
the past years to the database and make nice graphs from them? I have
written a Java application to feed descriptor archives into a PostgreSQL
database that could be adapted to MySQL and the TorStatus schema.
Also, how hard would it be to add more graphs displaying other
information than the numbers of servers with certain flags? For an
example what output I'm interested in, see the evaluation of the 2008
data: And finally, how extensible is TorStatus regarding other data than
descriptor archives? Given that there are other interesting data about
the Tor network than what relays advertise, would it be feasible to
extend the TorStatus database and add more graphs?

@_date: 2009-05-09 11:33:25
@_author: Karsten Loesing 
@_subject: ExitNodes for encrypted connects only are not possible. Why? 
Hash: SHA1
Feel free to configure your node to exit to those 5 ports only. That
makes your node an exit node for connections to those ports.
Your node won't get the Exit flag, though, but that's not required for
being an exit node. The Exit flag is used by clients for path selection.
Relays with the Exit flag are selected less often for non-exit
positions, so that their bandwidth is saved for exiting connections.
That means that your node will be selected more often as middle node and
less often as exit node compared to relays that have the Exit flag.
It's unlikely that the criteria you pasted above will be changed. There
need to be some criteria, and if almost every node matches them, the
flag would be useless.
Hope that helps!

@_date: 2009-05-09 19:36:56
@_author: Karsten Loesing 
@_subject: ExitNodes for encrypted connects only are not possible. Why? 
Hash: SHA1
I'm not sure what you are trying to achieve with that. The idea is not
to flag as many nodes that permit exiting as Exit nodes. The idea is to
relieve the exit nodes carrying most of the exit traffic from acting as
middle nodes, so that they can push more exit traffic. The same is done
for guard nodes, by the way. It's unlikely that your node would carry as
much exit traffic with the five ports you mentioned as compared to other
nodes that already meet the requirements for the Exit flag.
Of course the requirements could be lowered to assign the Exit flag to
more relays. But it defeats the purpose if too many nodes have that
flag. In the end, all nodes would see the same load as before, without
the Exit flag.
I'm not saying that the current definition for the Exit flag is perfect.
But right now we lack good data to come up with a better definition.

@_date: 2009-05-10 23:41:59
@_author: Karsten Loesing 
@_subject: My tor exit node is gone from the node list? 
Hash: SHA1
We discussed this problem on IRC today and found out that your node is
not reachable from multiple locations. To be more precise, your node
does not present an SSL certificate when accessed from these locations.
You can test this from different machines using the following command:
% openssl s_client -connect 89.248.169.108:8010
You should see a certificate then. If the output consists only of the
following line, something's wrong:
This problem seems to be related to your port 8010. From some locations
your node presents an SSL certificate on port 443 but not on 8010. You
might want to ask your ISP why that is the case. (A workaround might be
to switch your OR port from 8010 to 443, but let's try to figure out the
reason for the original problem first.)
While looking at your problem we found that many relays have similar
reachability problems. This is a list of relays that are missing the
Running flag by at least one authority:
If someone else on this list finds her/his node in this list and can
help us figure out what's going on, that would be grand. Single events
of missing Running flags are nothing to worry about, but if there is a
pattern we should have a look at it.

@_date: 2009-05-20 20:16:38
@_author: Karsten Loesing 
@_subject: Hidden services on Tor versions 0.1.2.x should be upgraded soon! 
Hash: SHA1
Hi folks,
if you run a hidden service on Tor version 0.1.2.x or lower, you should
upgrade to 0.2.0.x or 0.2.1.x soon. Otherwise, people running Tor
versions 0.2.2.x or higher won't be able to reach your hidden service.
Why is this the case? We added a new format for hidden service
descriptors in 0.2.0.x and made hidden services and clients speak both
the old and the new format. 0.2.1.x didn't change that. But in 0.2.2.x
we have just dropped support for the old format. Speaking both formats
at the same time means an unnecessary message overhead that we have to
stop at some point. That means that a hidden service running 0.1.2.x and
a client running 0.2.2.x won't be able to connect; the same applies to
hidden services on 0.2.2.x and clients on 0.1.2.x.
This is also a reminder that 0.1.2.x is obsolete. End-of-life for
0.1.2.x was announced in February 2009 [0]. There are known security
holes in 0.1.2.x that are fixed in later versions. Please upgrade!

@_date: 2009-10-06 13:12:06
@_author: Karsten Loesing 
@_subject: Directory History 
Hash: SHA1
You can find the descriptor archive here:
You may find this script useful that parses these archives and tells you
whether an IP address was a relay at a given time:
The script is available in Java and in Python.
Good luck with your court case!

@_date: 2009-10-15 21:22:54
@_author: Karsten Loesing 
@_subject: Directory History 
Sorry, there's no web interface, yet. I talked to Martin Mulazzani about integrating that functionality in TorStatus, but that might not happen very soon. Also, it would be great to have some feedback on the Java/Python script first that can be included in the web version.
(Sent from Android, so please excuse typos and mailing list rudeness of all kinds.)

@_date: 2009-10-19 20:59:10
@_author: Karsten Loesing 
@_subject: any rough stats on bridges ? 
Hash: SHA1
The latest information that I can give you is from June 22:
in particular
Let me know if there's something else you are interested in that could
be extracted from the bridge descriptors, and I can include it in the
next report.

@_date: 2009-09-21 12:20:08
@_author: Karsten Loesing 
@_subject: Hidden service usage 
Hash: SHA1
No, these config options won't help you in finding out what usage _your_
hidden service sees. The option
is only used by around ten relays that act as directory authorities; and
are only useful on three of these directory authorities that store (the
old version of) hidden service descriptors.
So, these options won't help you. You shouldn't enable them, or your Tor
will behave funny.
Can you instead learn the number of connections to your hidden service
from your webserver (or whatever kind of server that is)? Your local Tor
opens a new connection for every incoming request to your hidden
service. Maybe you can count those connections?

@_date: 2009-09-29 23:18:18
@_author: Karsten Loesing 
@_subject: Tor server "nami" taken by the German Police 
Hash: SHA1
Hi Tristan,
Sorry to hear! :(
You might want to have a confirmation for the police or your lawyer that
your IP address was a Tor relay at the incident time. That doesn't
automatically prove that you couldn't have performed what you're accused
of. But it could as well have been an anonymous Tor user.
We have the descriptor archives from the past few years available here:
Also, I wrote a small Java application that parses these archives and
tells you whether a given IP address was a relay and permitted exiting
to a given target at a given time. See the script and the HOWTO here:
If you like, feel free to download the script and relevant descriptor
archives to show that your IP address was a relay back then. If you are
running into technical problems or need another confirmation, please let
me know.
If others have feedback to the script, please let me know, too! The plan
is to make this script as user-friendly as possible and make a web-based
version of it afterwards.

@_date: 2010-08-25 12:35:45
@_author: Karsten Loesing 
@_subject: blutmagie TNS / v0.2.2.15 nodes 
Hi Olaf,
This might be related to:
Changes in version 0.2.2.15-alpha - 2010-08-18
    - Relays report the number of bytes spent on answering directory
      requests in extra-info descriptors similar to {read,write}-history.
      Implements enhancement 1790.
There are now two new lines "dirreq-read-history ..." and
"dirreq-write-history ..." containing the bytes spent on the dir
protocol. Maybe TNS greps for "read-history" and not "^read-history"
when parsing descriptors?
I'll have more time to investigate this tomorrow. Please let me know if
you find something interesting in the meantime.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-16 22:36:23
@_author: Karsten Loesing 
@_subject: bridge relay: GeoIPFile config option 
No. Tor can only handle the text-based ip-to-country database, but none
of Maxmind's databases. You can the database that Tor understands in
src/config/geoip in the sources:
Or do you want to use Maxmind's database for some reason? If so, you can
probably convert the text-based one (not .dat) easily.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-17 00:16:35
@_author: Karsten Loesing 
@_subject: bridge relay: GeoIPFile config option 
My impression is also that free and commercial Maxmind don't differ by
that much. I started working on a GeoIP database comparison in October
2009 that might be of interest here:
  As you can see in Figure 3, the two Maxmind databases have significant
overlap. I didn't investigate any further what the differences are and
in how far they affect the countries we're interested in with respect to
bridge usage. I'm going to publish the scripts for drawing these graphs
in the next few days on  If someone wants
to pick this up, I'm happy to help out with support.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-19 19:13:36
@_author: Karsten Loesing 
@_subject: Tor in China 
That's a fine question. It's already on my list. I'll let you know as
soon as I have a better answer than "probably something wrong with the
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-03-10 17:30:44
@_author: Karsten Loesing 
@_subject: Drop Tor users via bridges by over 2/3 in the beginning of March 
No obvious problems with the measurements or presentation, so these
numbers are probably real.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-03-10 13:27:42
@_author: Karsten Loesing 
@_subject: Tor in China 
============================== START ==============================
I figured out the problem. The metrics portal had the bridge user
numbers from 2009-11-30 to 2010-01-05 imported twice. This affected all
countries, but was simply most visible for Chinese bridge users. I
removed those days from the stats and imported the descriptors again.
The corrected graphs can be found on the graphs page:
  For reference, here is one of the old graphs:
Thanks for letting us know!
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-05-13 11:50:38
@_author: Karsten Loesing 
@_subject: GeoIP database comparison 
In theory, this sounds like a great idea. But I'm not sure if this works
for smaller countries with only a few IP address ranges.
Is the database you had in mind contained in the table that I attached
to my first message in this thread?
  If not, can you look up the ranges for Tunisia and post them here?
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-09-22 22:01:56
@_author: Karsten Loesing 
@_subject: VisiTor - or: a script to tell you how many of your users are probably 
Hi everyone!
We have heard from web server operators who are wondering how many of
their visitors are using Tor to do so.
We can now answer this question. We have an exit list archive back to
February 2010 and a tool to compare an Apache HTTP server log to these
lists. We can further guess how many of the requests come from Torbutton
users by looking at the user-agent string.
There's a lot of sensitive data involved here, which is why we give out
the archived exit lists and our tool so that web server operators can
run the comparison themselves.
You'll find the exit list archive and the VisiTor tool here:
    If you are running a web server and want to help us make the tool
better, please download the sources, review the 300+ lines of finest
Java*, run the tool on your machine, and let us know how that works!
*There will be a Python version once we're happy with the Java version.
Want to help writing (and maintaining) a Python version?
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-04-04 09:31:45
@_author: Karsten Loesing 
@_subject: [tor-talk] GSOC Ideas. 
It would be useful, but improving the metrics website to be a better
TorStatus website would be much more useful. :)
Maybe I should accept the fact that the world has roughly as many
JSP/servlet developers as it has TorStatus maintainers and just do it
I'm afraid I wouldn't be a good mentor for a PHP GSoC project.  I'm both
incapable and unwilling to read PHP code.
But this shouldn't stop you from working on TorStatus unrelated to GSoC.
I'd be glad to help you understand the metrics data if you're interested!
Fair enough.

@_date: 2011-04-29 16:18:34
@_author: Karsten Loesing 
@_subject: [tor-talk] fetching all server descriptors 
It's correct that metrics-db does not fetch non-referenced descriptors.
But it does parse the cached-descriptors[.new] files from gabelmoo, one of
the directory authorities.  So, the archives at least contain the
descriptors published to gabelmoo.  But there may be descriptors that are
only published to one or more of the other directory authorities which
would then not be contained in the metrics archive.  I can't say how many
descriptors we're talking about.
See  and  for more discussion about this issue.  The current
status of these tasks is that we need to extend Tor to make the rejected
descriptors and those not contained in the consensus available via the
directory protocol.  Once that's done, I can extend metrics-db to archive
these descriptors, too.  I'd like to turn off rsyncing the
cached-descriptors* files from gabelmoo sooner rather than later.
The directory-archive script only downloads referenced descriptors, too.

@_date: 2011-03-30 07:50:06
@_author: Karsten Loesing 
@_subject: [tor-talk] GSOC Ideas. 
The odds of Tor picking a GSoC student to improve TorStatus are non-zero,
but low.  (To be precise, I wouldn't mentor that project, but I don't know
if somebody else would.)
The better approach for providing Tor network status information is to
extend the metrics website, mostly because the metrics website is
maintained whereas the TorStatus website isn't.  Kevin Berry, one of our
last year's GSoC students who I mentored, started working on a basic
network status page here:
  The code for the metrics website is here, and yes, it's JSP/servlets:
  Please let me know if you have further questions.

@_date: 2011-11-16 09:23:30
@_author: Karsten Loesing 
@_subject: [tor-talk] Amazon Cloud server 
Hi Rhona,
The short answer is that it's crazy expensive to run a useful relay in
the cloud.  Basically, a relay is the more useful the more bandwidth it
pushes.  And bandwidth is what's expensive here.  More details are here:

@_date: 2011-09-12 08:20:50
@_author: Karsten Loesing 
@_subject: [tor-talk] Check wether IP has been a Tor node 
I just added a robots.txt disallowing all URLs that query descriptors
from the database, plus a few more that aren't useful for search
engines.  Maybe that'll make the search engines focus on the important

@_date: 2012-02-08 08:45:05
@_author: Karsten Loesing 
@_subject: [tor-talk] New TorStatus protocol, website, and Android app 
Hash: SHA1
Hi everyone,
you probably all know the TorStatus website [0] that lets you search
the current list of Tor relays.  And maybe some of you noticed last
year's HFOSS project to rewrite TorStatus in Python/Django [1].
Unfortunately, both projects suffer from lack of maintenance.  It's
just hard to find someone who both understands the Tor directory
protocol and who is good at writing websites.
In the past few months, we have been working on a new TorStatus
protocol, website, and Android app.  The idea is that all the Tor
descriptor parsing can happen on a server that provides status
information to clients.  The clients don't have to worry about Tor
directory protocol details.  That also makes it much easier to write
and maintain new TorStatus-like applications and websites.
Here's where you can learn more about...
- - the new TorStatus website: - - the Android app: - - the server and protocol: This code is all in beta state and only lightly tested.  Any feedback
or help are much appreciated.  And if you have ideas for developing
your own client, please let us know.
All the best,
Jens, Arturo, Karsten
[0] [1]

@_date: 2012-01-27 15:34:58
@_author: Karsten Loesing 
@_subject: [tor-talk] Ernie tordir.sql for MySQL ? 
Hi Martin,
I think porting the metrics database to MySQL will be difficult, because
we're using at least two PostgreSQL-specific features: arrays and table
partitioning via table inheritance.  Not sure what the MySQL equivalents
are there.
Also, the database is rather specific to what's needed to run the
metrics website, including aggregating data so that we can make graphs.
 If you're trying to do something else, maybe the database works for
you, or maybe it doesn't.
What are you trying to do?
