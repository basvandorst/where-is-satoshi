
@_date: 2013-08-06 13:37:32
@_author: Jon Tullett 
@_subject: [tor-talk] Javascript vs privacy? 
Hi all
I have a couple of questions related to the Freedom Hosting saga.
Disclosure: I'm a journalist and I'm writing about this, but I won't
quote anyone without prior permission.
My understanding is that NoScript shipped disabled in the TBB because
that would reduce the likelihood of the browser being fingerprinted -
a conscious decision intended to strengthen privacy. However, it seems
that doing so exposed users to a Javascript exploit (and probably
predictably so: Javascript's attack surface is famous).
So I have two questions:
1) Will this incident, with Tor users being specifically targeted via
JS attacks, lead to the NoScript policy being reconsidered ie: is the
privacy consideration still considered to outweigh the security
issues? Or maybe more awareness for users, eg on the TBB landing page?
"You have Javascript on. You are likely to be pwned by a grue."
2) Is there a concern that other agencies will use similar techniques
to attack Tor users, and does (or should) that affect the answer to
the first question? For example, I could well imagine a repressive
regime setting up a fake .onion bulletin board to encourage dissident
discussion. Since TBB ships with a specific, known, point release of a
browser, that would seem to make it easier for targeted attacks. Maybe
I'm paranoid, but I'd have thought it likely that a state intelligence
agency with a cyberwar budget would be sitting on working 0-days for
pretty much any browser, so the actual version may not matter much.
I'd also be very interested to know whether there are any available
stats regarding the % of Tor users who use TBB versus Whonix versus
Tails etc, and whether that changes now, but I understand that even
high-level stats like that could carry privacy concerns.
Any input welcome!

@_date: 2013-08-07 09:28:17
@_author: Jon Tullett 
@_subject: [tor-talk] Javascript vs privacy? 
Thanks Lunar, appreciate the input. You raise good points.
Yes - I was summarising and you caught me. That's how I understood it
too: NS was installed by default with some features enabled but the
Javascript filtering specifically was disabled by default. I should
have been clearer.
Re the JS filter, granted, users can turn it on, but it's probably
reasonable to assume (as the attacker here correctly did) that most
users will not.
Today. I use NoScript by default when I browse with Firefox, because
some tasks demand it.
Sometimes it's a pain, as you say, but that's a compromise I make
knowingly and willingly. I also use Lynx daily, so I'm kinda used to
the web not looking like it does for most people :)
Here's the thing though: when I use Tor (which I do), I do so knowing
I'm making certain compromises: my usual ecosystem of browser plugins
will not be available, scripting will be disabled, network performance
will be slow, etc. I'm not sure I'm convinced by the "it's a
compromise" argument, because I'm making several already.
But some people wouldn't want to, you're right. And that's why I asked
about awareness - is there scope for better communicating to a user
(such as in the Tor browser homepage) that JS is enabled to improve
their browsing experience and enhance privacy, but it may open them to
(another) attack and here's how it can be disabled? If not, I'd be
very interested to know the thinking behind that decision - it feels,
to me, to be a decision not to inform a userbase of a clear and
present danger.
Well, none, but that's because I know what to expect. But your point
is valid - most users would find the web badly broken with JS
I do - I have a security background. But _regular_ users, no - no
chance. Lab workers, yes. However, I wouldn't classify Tor users as
regular users - they are people who are taking extraordinary steps to
protect themselves. One more extraordinary step doesn't seem that
implausible, but then I probably do have a biased perspective.
Definitely! The attack surface of the modern browser is a wonderful
thing to behold. But surely you aren't suggesting that because another
attack vector exists, we shouldn't defend others? That's kinda the
whole reason for Tor to exist, no? "There are some ways your privacy
can be violated that we can't help with, but we will do what we can to
mitigate as many as possible..."
This is an interesting discussion anyway, so thank you. I think the
questions, in context, boil down to this:
Knowing that TBB users can be attacked a certain way, and knowing that
at least one attack has taken place, should/will the configuration
and/or messaging be re-evaluated?
You're right in the points you raise - they aren't new points, and I'm
sure they were taken into account when the existing decisions were
taken. Those points would have been on one side of the balance, with
possible security considerations on the other. So what I'm asking is,
in the light of this incident, does that balance shift?
Should stress that I'm ok with the answer being "no" :) I'm here to
report, not to criticise.

@_date: 2013-08-07 10:43:55
@_author: Jon Tullett 
@_subject: [tor-talk] Javascript vs privacy? 
Excellent, thanks! I'll keep an eye on the comments there.

@_date: 2013-08-13 06:10:34
@_author: Jon Tullett 
@_subject: [tor-talk] Updated "Why JavaScript is enabled" FAQ entry 
I think it reads very well. Only change I would suggest would be to change
'cookie' to 'fingerprint'. We're talking about a unique identifier, but not
an actual browser -thing-, but that's probably just a question of style.
Personally I'd still like to see a message front and centre on the browser
homepage too...longtime users (and probably lots of new ones) likely skip
the faq entirely. Licence agreements and instructions are for wimps, right?

@_date: 2014-12-11 08:54:05
@_author: Jon Tullett 
@_subject: [tor-talk] Off topic- Android is suspect spyware? 
Anything that any corporation touches is suspicious by the same
measures, if you want to be sufficiently paranoid about it. You think
there's no Chinese spyware in Huawei phones, or that Apple is on your
Yes. Get a forked device, like an Amazon Kindle Fire - such vendors
replace much of the Google software, often including the default app
store, with their own. But if you trust the third party more than
Google, your paranoia is broken.
This I don't understand at all. Of all the mobile ecosystems,
Android's has the least of an appstore monopoly. If you don't want to
use the Google Play Store, use another - there are numerous
third-party app stores. Or download apks directly and sideload them
(careful...this is where the malware lurks). All these are options
which don't exist in Apple or Microsoft devices. That's not a
criticism or endorsement, just a fact.
BlackBerry, curiously, is even more open - there's the default
BlackBerry World appstore, and BB10 ships with access to the Amazon
store for Android apps, and it supports easy sideloading AND provides
extra layers of app scanning beyond what Google does. But if you don't
trust Google, you shouldn't trust BlackBerry, for the same reasons.
Only if that is the limit of your paranoia. You can root an Android
phone and rip out a bunch of stuff (the "Samsung decrapifier" is a
pretty good example of a bloatware removal tool), but there's still a
bunch of stuff that's off-limits, notably the code in, eg, the
baseband processor on the phone. Even if you could completely wipe a
phone, you couldn't be certain it was incapable of tracking or
eavesdropping. So the question is, how paranoid do you personally need
to be?
I think you need to do some homework.
You should probably start with a personal risk assessment, then
research whatever measures are required to mitigate that risk. If you
are in a position where you need to be extremely paranoid about this
stuff, don't use a smartphone at all. Get a featurephone with no GPS
and a removable battery, and use it as a modem if you need to get
online, and take the battery out when you're in a sensitive situation.
If you just want to be tracked a bit less, root your Android
smartphone and use Orweb and orWall and suchlike. Avoid apps which are
ad-supported. Learn which services are what, and disable as many as
you comfortably can.
Or any of a number of options in between. It all comes down to what
level of risk you personally need to address.

@_date: 2014-12-11 09:33:08
@_author: Jon Tullett 
@_subject: [tor-talk] Off topic- Android is suspect spyware? 
Yes. This is why I specifically mentioned baseband processors as an
example of hardware which may operate code outside your control.

@_date: 2014-06-30 09:35:25
@_author: Jon Tullett 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
Probably fairly good odds, I guess - it can't be that unusual a name.
But just so we're clear: are you definitely not the same Mark McCarron
who designed the GIEIS system to defeat spam? I ask because that Mark
laid claim to a fairly lengthy security pedigree, and it doesn't seem
unreasonable to make the connection between him (aiming to fix
shortcomings in email) and you (aiming to fix shortcomings in Tor).
So...definitely a different Mark McCarron?

@_date: 2014-06-30 09:53:35
@_author: Jon Tullett 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
Conspiracy theory aside, I'm curious about these. I mean, p12: "How
does TOR handle DNS requests?...still investigating".
That seems remarkably clueless for spooks capable of interdicting
networking hardware and implanting invisible malware, doesn't it?
Especially since Tor had military backing - it's not like they should
have struggled to find someone who could explain the basics. Couldn't
they just pick up the phone? Or, you know, visit torproject.org and
find the answer there?
So I do wonder. About its age, about its source, about its
reliability...about lots of things. But in particular, I wonder
whether (since that part is so clueless) we should rely too heavily on
its claims about agencies' limitations in attacking Tor.

@_date: 2014-11-07 13:04:38
@_author: Jon Tullett 
@_subject: [tor-talk] Operation Onymous against hidden services, 
Well, I wouldn't want to rule anything out :) But in this case, we're
talking about hidden services which proxied for drug dealers. Whatever
your personal feelings about it, the war on drugs is a given. So the
reality is that there are enormous intelligence and law enforcement
operations targeting people in the drug trade. If one of them starts
to operate (or do business with) a hidden service, is it so unlikely
that that service could get caught up in the investigation?
If anything, I'd have thought that the coordinated takedowns lend
credibility to that argument - it's not like dealers would only do
business through a single marketplace at a time. Compromise or turn a
big dealer or two, and you'd probably be able to target a whole lot of
marketplaces at once.
I'm not saying that's what happened, just that it offers a plausible
option that doesn't require additional tinfoil hattery beyond the
PS: I also think that it's a bit aggressive to describe anyone who
offers discussion or argument as a "pentagon lackey". But then I'm
probably one of them myself, right? :p

@_date: 2014-11-10 09:42:27
@_author: Jon Tullett 
@_subject: [tor-talk] Operation Onymous against hidden services, 
That's an assumption, and it may be incorrect. It is alleged that some
HS operations were infiltrated early on - that sort of foolish trust
is just the sort of basic mistake law enforcement thrives on. And
infiltrating target organisations is something the LEO agencies do for
a living, after all.
Or some agent gets lucky and is appointed a moderator on a darknet
marketplace forum, proceeds to socially engineer his way from there.
Hey trusted moderator friend, can you recommend software to do X? Why,
sure I can, download Y from Z.
It's not just about dealers. It's about the entire ecosystem. The drug
economy is just that: an economy. Dealers are just retailers - there's
an entire supply chain and supporting players extending back from that
point (though online commerce certainly flattens the structure a lot!)
Every part of that ecosystem is fair game for investigators, and any
compromise can be leveraged along the chain. For a retail analogy,
think Target, which was compromised via an HVAC contractor who
probably thought they weren't a target (heh) at all.
Again, I'm not suggesting this theory is correct, just that it's an
option. At this stage, there's a ton of speculation and I'm cautioning
against jumping to conclusions.
That said, if you're running a hidden service, you absolutely should
assume the worst and tighten your security practices, not just after
an incident like this but on a regular basis. Risk management is a

@_date: 2015-08-03 09:26:31
@_author: Jon Tullett 
@_subject: [tor-talk] Circuit Fingerprinting Attacks: Passive 
Ahah! Thanks - should have checked your blog first, I guess :)

@_date: 2015-06-26 11:57:45
@_author: Jon Tullett 
@_subject: [tor-talk] A month with BADONIONS 
Hi all
This was interesting - not sure if I've missed discussion of it here,
but I didn't find anything with a quick search.
Tl:dr; the author set up a very basic honeypot to detect potentially
abusive guard and exit nodes, and found some. (Quelle surprise!)
The claim that they reported the naughty guard nodes to Tor but have
not seen any remediation is something which might merit a response, if
nothing else.

@_date: 2015-03-26 09:06:01
@_author: Jon Tullett 
@_subject: [tor-talk] Games Without Frontiers: Investigating Video Games 
Interesting, thanks!
I do question one of the early assumptions, though: "Many games also
include the notion of private games between a limited number of
players which may only be accessed using a password. This means that,
even a highly motivated adversary (e.g., one who is willing to run a
game client themselves) still cannot observe the game state."
That seems to be making risky assumptions. Chiefly that the only
possible attack is via an external game client - this may be mistaken:
an adversary could attack many places: by attacking or subverting the
game client software itself, by attacking the game network, by
attacking the operator of the game (eg: Blizzard, in the case of WoW,
etc), and so on.
We shouldn't be surprised to find the likes of the NSA attacking
gaming communities, because they are large communities, often overly
trusting of their environment (notably the client software), and
frequently with central control built in.
For example: You could mitigate some of that, sure. You could choose a less popular
game (ie: less targeted), with open source client and server software
(though you'd have to review it too, which is probably beyond the
skill of most users), which operates in encrypted peer to peer
fashion. And you can use behavioural steganography as your paper
describes. Keep raising the bar, I guess. But a lot of that sounds
like security by obscurity, and a skilled adversary should be able to
attack that. Any opsec leak, and that castle would fall down fairly
fast, I suspect.
Still, fun research. Literally :)

@_date: 2015-03-27 09:13:57
@_author: Jon Tullett 
@_subject: [tor-talk] Games Without Frontiers: Investigating Video Games 
Hi Rishab
No, you're entirely correct about that :)
That right there is a fundamental mistake. There are numerous ways for
that collusion to happen, but I'll offer just three:
- A developer can be legally compelled to comply with surveillance.
The Lavabit saga, versus the many other vendors who _didn't_ say no,
is instructive in this regard.
- A developer can be infiltrated or hacked. See also: Gemalto.
- A developer can be incompetent. Leak keys (hello, pastebin!), leave
admin backdoors, incorrectly configure crypto, etc etc ad nauseam.
...if and only if it is implemented correctly.  That, again, is a
dangerous assumption. It builds on the first assumption, so now we
have assumption^2.
Also, remember that compromised client software trumps perfect crypto.
And remember that it's not just your game client that could be
attacked, it's the entire operating stack: hardware, firmware, OS, and
It feels to me like anyone who's already under surveillance would
probably gain nothing at all from this exercise beyond a false sense
of security. Its benefit to anyone else, over and above using the
alternative existing tools, is a question I'd be interested to
...if and only if they are implemented correctly. Another assumption,
so now we're at assumption^3. And vulnerable to the same attack
vectors as your second assumption. Assume Tor is as resistant a comms
channel as we can manufacture today - it didn't save Ross Ulbricht.
Why? Because he made opsec mistakes _separate_ to the secure comms
I think the mistakes you're making here are broadly twofold:
1) You're assuming technology is implemented in a hypothetically
perfect manner. That's great in an academic thought-experiment, but
not in the real world.
2) You're underestimating both the vulnerable surface area of this
sort of project, and the capabilities of the potential adversaries.
And again, I don't think the paper is useless or uninteresting - I'm
not completely down on it :) I just don't think it's as effective as
you're pitching it to be. If nothing else. the obfuscation may raise
the bar a bit for an attacker. At worst, though, it may lull a user
into a false sense of security. We do, after all, know that the NSA is
attacking game networks, presumably because they have a sense that
their targets are using them to communicate. You're relying on
security through obscurity, but the obscurity is already under attack.

@_date: 2015-03-27 09:42:01
@_author: Jon Tullett 
@_subject: [tor-talk] Games Without Frontiers: Investigating Video Games 
"Monitoring". I did wonder at the time if that particular slide didn't
reflect an ingenious scheme by some NSA staffer to basically skive off
playing WoW all day :)

@_date: 2015-03-28 22:29:18
@_author: Jon Tullett 
@_subject: [tor-talk] Games Without Frontiers: Investigating Video Games 
I agree. And that, I think, is the point I'm trying to make - the fact that
these points are debatable suggests they shouldn't be taken as assumptions
in research.
Of course you have to draw a line in the sand somewhere, because the worst
possible cases preclude privacy entirely, but be aware, and transparent,
about the nature of your assumptions. And be prepared to be disappointed -
a lot of what we know to be fact today was dismissed by the mainstream as
dystopian pessimism just a few years ago.
My job is not to be a pessimist, though. Just to challenge assumptions :-)

@_date: 2016-08-13 20:22:16
@_author: Jon Tullett 
@_subject: [tor-talk] Tor and Spamhaus. 
Knowing Spamhaus, I'd guess that they don't target exit nodes per se,
but rather that Tor has been used by spammers which has resulted in
the block listings. Getting them delisted will be exceptionally
difficult (since there's no guarantee the spammers won't immediately
resume business as usual).

@_date: 2016-08-15 12:43:47
@_author: Jon Tullett 
@_subject: [tor-talk] using same usernames on same websites under tor and 
Interesting discussion, I'll look forward to hearing peoples' views.
Allowing correlation between multiple sites based on the same identity
likely will reduce privacy, I assume, though the extent of that impact
might be debatable. It'd make the risk assessment and the opsec more
complicated and more error-prone respectively, but assuming you can
overcome that, the impact might be negligible. I'm curious to know how
you'd assess the risk, under those circumstances.
Personally I don't see much overlap between communities, so I tend to
use different pseudonyms on different sites and forums, but there's
also very little risk to me if they were to be associated.  But I can
well imagine the opposite - if I had an established identity and
reputation like the Grugq or Moxie or something, then I'd want to
achieve, if not conformity, then at least known association between
identities on multiple forums within the same community. And I'd
definitely want to avoid impacting my privacy and anonymity. I would
guess that achieving that might just be a question of abstracting the
comms a bit. Use the same identity, but give it a separate email
address and Tor connection, for example - that's a lot easier to
manage now that we have separate circuits per browser tab, I imagine.
Interesting topic, thanks!

@_date: 2016-08-19 20:55:04
@_author: Jon Tullett 
@_subject: [tor-talk] Tor and Spamhaus. 
But they don't, and there isn't. There have been many many suggested
"fixes" to SMTP, but most would fail because unless widely
implemented, they'd break email, and it's pretty damned fragile to
start with. Whitelisting, for example doesn't work for several
reasons. Greylisting works better, at the server or client level, but
didn't catch on and is often considered too much of a compromise on
Even SPF and DKIM had slow tentative starts, because operators were
very nervous about impacting reliability and usability. Now, of
course, it's the opposite; if you don't comply, you're effectively
shut out. And that's _mostly_ ok except for fringe cases, but if
you're one of those fringe cases then it unfortunately is a real pain.
That's a shame, but they're in such a tiny minority that no one who
matters, cares.
You won't change that approach now. For the vast majority of users,
right now, spam is a mostly solved problem. That's borne out by data:
spam levels have been decreasing for years now. So the operators won't
backtrack on what's working. Even so, there's no cartel or hidden
agenda. Just a broadly accepted community response to widespread abuse
- it's functionally the same as if they upgraded SMTP to a new version
that blocked out some servers who unfortunately aren't able to upgrade
and so can no longer exchange mail with them.
You can still run your own server, using the older version. It just
won't be able to talk to most other mail servers, especially not the
big public operators like Gmail, Yahoo, and Hotmail. But there's
nothing stopping a community of mail server operators setting up a
network of email hosts using older standards. Well, apart from the
inevitable spam and other abuse they'll have to deal with...

@_date: 2016-08-26 16:13:39
@_author: Jon Tullett 
@_subject: [tor-talk] New relays and bridges. 
Would you be able to run a small headless Linux VM, with a Tor relay?
That should be very low in resource overhead, and it wouldn't conflict
with your desktop Tor browser.

@_date: 2016-12-01 11:14:04
@_author: Jon Tullett 
@_subject: [tor-talk] Hacker and Tor. 
OK: yes.
Step back a little. Rephrase it as "if a target browses to a monitored
page via Tor, can a provider find their real IP?" We know this is
possible; the FBI used such techniques against, eg, Freedom Hosting.
It requires control over the affected page, available browser
exploits, and sloppy opsec by the victim.
Given that such a technique works in general, it would work equally in
specific instances like a cPanel interface.
Logically, therefore, the answer to your question is "yes".

@_date: 2016-07-14 08:23:05
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
I think what you'll find in such cases is that the FBI generally crack
the servers hosting the illicit material, not Tor itself.
In other words, the feds locate onion sites hosting illegal material,
using standard intelligence gathering techniques. They establish
(encrypted, secure, private, and presumably uncracked) Tor connections
to those servers, and then attack them over those connections. There
are frequently vulnerabilities in hosting services - content
platforms, web forums, third-party Javascript libraries, file uploads,
management interfaces...many sites, darkweb or not, have much broader
attack surfaces than their owners understand.
Having pwned the server, a malware component is then injected to
visiting computers. Ie: when the criminal visits the infected site,
his PC is infected (over that encrypted, secure, etc) connection. Now
infected, his PC will be under the control of the FBI, and the
investigation will proceed from there. As soon as it's connected to
the regular internet, that connection will be traced, but that
connection is not necessary - data on the PC can be exfiltrated by the
feds over Tor and used to identify the user.

@_date: 2016-07-14 09:38:01
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
I agree - a warning of the dangers of visiting infected onion sites
could be useful (even though the problem is not specifically a Tor
one). There's the risk of feature creep - security is a big space and
it isn't really Tor's job to educate people on every risk online.
Perhaps a clarification that just as TBB is not all you need to
maintain privacy, it's also not all you need to stay secure, with a
pointer to some external tips?
For onion site operators, there's this:
Which does include this: 'Hidden services operators need to practice
proper operational security and system administration to maintain
security. For some security suggestions please make sure you read over
Riseup's "Tor hidden services best practices" document.'
Which in turn links here:
That's more specifically about Tor config though - it could usefully
include pointers on basic webserver opsec too, though again it may be
out of scope to say much more than "bad people may attack your web
server, onion or not. Educate yourself on keeping it secure".

@_date: 2016-07-14 13:45:50
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
These are separate issues with separate ramifications. Breaking
Firefox is comparatively trivial. Breaking Tor would be extremely
untrivial, both in effort and implication.
Take one scenario; the FBI deploys malware on a server to identify its
users. That doesn't require (or even benefit from) attacking the Tor
network directly. It's about exploiting vulnerabilities in the hosting
software for delivery, then about vulnerabilities in the users'
browsers for infection. That may be browser vulnerabilities or Flash
vulns or whatever, but again, nothing to do with Tor.
Also worth separating Tor and TBB. Vulnerabilities in TBB would likely
be flaws in Firefox or a bundled addon. Exploiting that is certainly
plausible, but doesn't count as "cracking Tor" in the context of
compromising the network or encryption.
In the case of Freedom Hosting, it was reportedly a combination of
both; the FBI cracked the server, then planted malware which exploited
a vuln in Firefox (and therefore TBB) users. They didn't, it is
believed, compromise Tor crypto in the process.
Should add that users with NoScript enabled would not have been
vulnerable - I get the "noscript decreases privacy" argument, but I'd
still kinda like it to be on by default to protect users. Maybe with a
big red "Turn on Javascript because I'm happy to get pwned by
malicious ads, FBI malware, and miscellaneous trackers" button :)
Lastly, I should acknowledge that none of this is proof that Tor has
NOT been compromised. Just that in the incident in question, it was
probably not.
Unfortunately, security is rarely a top priority for either developers
or users.

@_date: 2016-07-14 21:34:16
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
Yes indeed. I linked to such an article in another email in this thread.
Depends on the context, I guess. To the user, maybe, but in the
context of this (Tor) community, the distinction matters. Browser
vulns and server exploits are common. Tor's crypto is not, AFAIK,
known to be compromised. If a law enforcement agency cracked Tor, it
would be a very significant development indeed. The same agency using
browser exploits doesn't move the security needle at all; we already
know they do that.
The issue of who should be responsible for alerting a user to possible
risks is debatable. Tor's job, after all, is not to keep users secure;
it's to keep them anonymous. I don't speak for the Tor project, but I
expect the assumption is that users should take responsibility for
their own security, just as they should take responsibility for
antivirus, patching, and brushing their teeth :)

@_date: 2016-07-15 07:23:20
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
Well, it doesn't really matter what I think :) There have been
discussions, and as I understand it in most cases there are two
issues: privacy tradeoffs in blocking third party content (doing so
makes your browser more identifiable), and breaking the web enough
that users will just downgrade their settings thereby making
themselves insecure and again degrading their privacy in the same
Me, I block scripts in TBB because I weigh security a bit higher than
privacy, and it's nice that it's relatively easy to do so, but I would
like it to be signposted or explained a bit more clearly.
Very good choice, though possibly  too complicated for average users
(but then, so is maintaining a NoScript whitelist).

@_date: 2016-07-15 07:34:00
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
Again, remember that this conversation was in the context of Freedom Hosting.
Absolutely agree that the same style of investigation could (and
probably does) happen in a more brutal political regime. Users there,
being at greater risk, have a greater need to take further steps to
protect themselves.
Well, no. Tor does make it clear you need to do more than just
downloading TBB to be anonymous and secure. If you think TBB is a
single-solution prepackaged silver bullet, you are at risk.
I don't think there's any debate whether Tor should try to be such a
silver bullet - clearly it can't and shouldn't - the question seems to
be around whether Tor should give more clear guidance/warnings. I'm
always in favour of that.
Yeah, I kinda am. Users in such hostile environments absolutely need
to take more care to keep themselves secure, and not just online. If
you are relying on any product to keep you alive, you definitely
should be constantly reading about it.
It's saying that the Tor network will help you stay anonymous, and the
browser bundle will help facilitate that, but you also need to take
further steps to stay anonymous and secure. I think that's realistic
and reasonable.
Also, remember there is no such thing as 100% security, and the
incremental usability/security tradeoffs become more severe the
further you go. Everyone has to decide for themselves where to draw
the line - how secure they want to be and how much compromise they can
accept. All a third party like Tor (or you and I) can do is educate.

@_date: 2016-07-15 07:39:45
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
That's right. It was a very small piece of malware - all it did was
phone home on the clearweb. Very clearly targeted at Tor users, and a
clever demonstration of reality: you don't need to crack crypto to
attack an encrypted network.
No, I wouldn't think so. I'd quite like to see a very plain-language
use-case breakdown either in the TBB homepage or linked off it - if
you are using TBB for , then you should do . If you are
using it in  environment, then you should read . For a
more complicated list of how agencies may attack you despite your use
of Tor, read . I'd volunteer to write such guides, if there was
demand for it.

@_date: 2016-07-16 14:00:20
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
I think we differ there. I don't think it's irresponsible, and I don't
think the configuration is designed to be vulnerable. I do agree
there's room for better awareness, but there's no perfect solution. At
some point people have to take responsibility for their own safety,
and the fact that they're downloading Tor in the first place suggests
they are able to do so.

@_date: 2016-07-16 14:07:25
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
Sure. Nor are they physical security experts, but some have to learn
pretty quickly how to evade pursuit, right? It's not Tor's job to
cover that, either.
Tor is a very specific tool, remember. You can use it for lots of
things, but I'm not sure it's appropriate for the organisers to take
responsibility for education people about every possible use-case,
risk, and adversary. You know your situation best - you need to take
responsibility for understanding your risk profile and taking
appropriate countermeasures, only one of which will be using Tor.
That said, I do think that where attacks are commonplace, or
frequently misunderstood, it makes sense to draw users' attention to
that, not least because there's a very good central facility to
achieve that - the Tor browser's start page and update mechanism. But
there's a balance, and while we may disagree on where the balance
lies, ultimately it's up to the project team to decide.

@_date: 2016-07-18 14:11:34
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
It is, you know. More complex, and probably not suitable.
Haroon Meer, who I greatly respect in the security space, describes UX
complexity in terms of his mum. As in, "could my mum do this?" and if
the answer is no, it's too complex for the average user. I like that.
Fact is, security is a spectrum. "No security consideration at all" is
at one end of that spectrum. Tor, the TBB and the associated
documentation, is someway further along the spectrum, Whonix is
somewhat further still, but there's a lot more room beyond that. Even
that's a gross oversimplification - "no browser security except
NoScript" is more secure but less private than TBB in its default
Because of that, I don't think it's possible, much less desirable, to
describe the entire spectrum of use-cases. And even less possible to
actually document the toolset appropriate for every point. It's
probably far more meaningful to help users understand that spectrum,
self-assess where they fall on it and what their risk profile may look
like as a result, and pointers to resources which would align with
"Just use VirtualBox and Whonix" is not meaningful advice. It's a
great fit for a very specific subset of users, but many (I would guess
"most") users are not in that subset, and for everyone else it'd just
be some combination of confusing, overwhelming, unnecessary, or
The key question to you, as someone advocating that specific toolset,
would be: for what type of user is VirtualBox+Whonix the optimum
solution, and how would Joe Random identify if he is that sort of

@_date: 2016-07-18 15:33:10
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
Why not? Are you able to say with certainty that they are not at risk
and shouldn't be using Tor? Sounds like a risky assumption. Not that
it's applicable here, but activists' families are not uncommonly at
high risk. I'd caution against assuming you know someone's risk
profile better than they do. And that, in a nutshell, is why I don't
think Tor should be making such an assumption in its recommendations
to users in general.
Why should there be mention of Whonix? It's an independent project.
Proxy bypass, maybe, but that's in there with all the other potential
risks, and again, Tor can't document all of them.
I think we agree that we'd like to see more documentation, we just
aren't agreeing on how much more. Me, I'd like to see them document
threats a bit more with links to discussion and solutions. You'd like
them to be a great more specific in one particular direction.
Ultimately, as I've said before, that balance is one the  Tor
maintainers decide, and presumably they don't do so arbitrarily.
Why Whonix and not Tails? Why not any other tools?
That's a rhetorical question - I'm sure there are pros and cons either
way and it could be argued at length without conclusion. I'm not
convinced Tor should be promoting either; same way I'm not convinced
Tor should be promoting any specific tools. There will always be
others, and they may be better suited to users depending on their
Why is money relevant? Where do you live, that freedom and torture is
measured in $/hr? :)
Again, why is cost the metric? It's relevant for a narrow subset of
users in a Tor context, and a broader subset in a general security
context, but I don't see the relevance here.
Even if it were relevant, you've just asked a potentially
technically-incompetent user to conduct a very complex risk analysis.
A lot of CIOs can't do an accurate risk assessment, but you want
Haroon's mum to do it?
3.1. Is that a meaningful number to anyone? What does it mean? What is
the ratio above which Whonix is the remedy for all my ills? What do I
do if I'm below it? Does it know about exchange rates and cost of
living? What about...you get the idea. Meaningless calculations give
meaningless conclusions.
There must be lots of better ways. For eg, I would guess that a risk
flowchart would be pretty effective. A short series of "Are you
concerned about X?" questions would easily infer a risk profile, which
would map to suggested tools and behaviours. For example: "Law
enforcement authorities are known to attack [link to explanation] Tor
users by compromising servers on the Tor network. Are you concerned
about this type of attack?"

@_date: 2016-07-19 03:08:18
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
Now you're back to "sheep". Don't assume that "technically
inexperienced" equates to "clueless".
Security theatre is generally not positive, but again, security is
never absolute and you will always be able to find an argument for
doing more, and someone who will argue that failing to do so is, yes,
arguably bad. Everyone has to draw the line somewhere. Tor has done
We're going in circles on this now, so this will be my last repetition
of that particular argument. As I've said, I think we agree there's
room for better education, but just differ on details.
That's a list of projects Tor is involved with. It's interesting but
there's no context - someone who knows they need the tool is already
most of the way there. Helping people identify that the need the tool
at all is the part I'm interesting in.
At a guess, it's because Tor is more actively involved in Tails than
in Whonix. But that is just a guess. Have you asked the maintainers?
Very different issues, I think. I'm sure you disagree; I'm not going
to debate it.
Yes, I do. Systems get attacked, and are updated to thwart attacks.
Tor does this - that is not a fail, that's the normal security dev
process. Don't assume that nothing is happening - it's not like Tor is
not actively researched and developed.
Have you updated it to account for subverted VPN providers? Advising
people to use VPNs which may have been subject to national security
letters is arguably bad.

@_date: 2016-07-19 03:14:38
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
Context matters. Mirimir was asking for what amounts to a very complex
assessment measuring risk in monetary terms. Anyone who can do that
reliably can get a very high paid job doing so. It's really not
Absolutely individuals should conduct their own risk assessments. But
not in those terms. For most consumers, security is not about money.
Going to jail is about freedom and personal safety, not cash. Even
losing data is a balance between losing work (money) and personal
items (sentimental value, not money). Understanding your risk profile,
for most people, actually has relatively little to do with money
(though "losing all my money to phishing" is absolutely a risk to be

@_date: 2016-07-19 11:50:05
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
I take it that's a no, then?
Point being, not only do we now know which operators have received
letters, we _can't_ know. The first rule of NSL club is you don't talk
about NSL club. I have yet to see much evidence that warrant canaries
help. And that's not the only risk; operators can be coerced, hacked,
suborned, or otherwise compromised. Belgacom, for example.
We mitigate that by layering services, but that's back to the question
of how complex an environment suits your risk profile. Not everyone
has the same nut; not everyone needs the same size hammer.

@_date: 2016-07-19 12:18:36
@_author: Jon Tullett 
@_subject: [tor-talk] FBI cracked Tor security 
But your guide does not. It doesn't even mention them. Why are you
concealing the truth from users?!?11
The point I'm trying to make is that you can't cover every base. Too
often, attempts to do so just end up with unusable rambling essays on
security which no one will read and which still fail to cover a lot of
ground. You're accusing Tor of something that you yourself can't
avoid. That's not a criticism - just a reflection of reality.
Which part of "we can't know" wasn't clear? We don't know - can't know
- which relays are compromised, but we have to assume that at least
some are (MIT et al). Ditto for exit nodes. Again, don't fixate on
NSLs. That's one form of compromise but there are many more. The only
safe assumption is that the environment is hostile - just how hostile
and what is a reasonable response will vary from one user to the next.
The threat of the NSA is not evenly spread, and does not warrant
identical countermeasures. Some people aren't concerned at all. Some
are concerned about privacy in a theoretical way and use Tor because
they have a vague sense that it's messing with The Man. Some are
active targets and know they need to substantially strengthen their
opsec, and will use Tor as part of a much broader toolset. Different
strokes for different folks, and the advice I'd give them would be
very different in each case.

@_date: 2016-10-07 13:50:39
@_author: Jon Tullett 
@_subject: [tor-talk] Tor and Google error / CAPTCHAs. 
It really varies. Some subreddits are VERY heavily moderated, some are
completely open, most are somewhere in between. Your experience of
reddit is probably quite personal and likely to be different from any
other user. It's a big space. That's kinda off-topic, but it's
relevant in the bigger picture, I think.
It's been very interesting, over the last couple of decades, to
observe the changing attitudes to censorship and control in online
communities. For me it started in the days of BBS and Usenet, and
thereafter different communities evolved in very different ways.
Community norms in areas like community policing, netiquette, topic
enforcement, language, personal privacy...all became very different,
and vastly more varied. And, of course, we have rather different
attitudes from law enforcement/intelligence to those communities and
their platforms, and very different commercial ideas too.
I find tracking that historical change to be useful because it reminds
me that our expectations in the future will be different too. Our
notions of privacy and security, for example, are far from static; we
can't take a snapshot of the market today and assume it's either
inherently "correct" (for some definition), nor unchanging. In
context, I'm interested in how that affects the evolution of
communities/services like Tor.

@_date: 2016-10-07 21:15:43
@_author: Jon Tullett 
@_subject: [tor-talk] Tor and Google error / CAPTCHAs. 
I completely agree. Maybe it would have been better to say that
expectations of privacy differ between communities, and independently
evolve over time. As such, whatever one community may consider to be a
baseline for privacy is likely to be different tomorrow, and not to
work when applied to another community. A lot of disconnect in this
space starts with the assumption that what's right for me must by
definition be right for you.
Just so. It's a spectrum of understanding, and that's why I tend to
answer privacy questions with "what's your risk profile?" It's always
different, and most people really don't know (and don't know they
don't know). Most of my conversations, whether with corporate types or
media (about Yahoo's mail interception, for a current eg) tend to be
about 80% clearing up misconceptions, 20% real issues.
Incidentally, I kinda enjoyed the conspiracy theory spam on this list
- it can be annoying for sure but at the same time it's good to
remember where the spectrum starts :)

@_date: 2016-10-19 13:06:13
@_author: Jon Tullett 
@_subject: [tor-talk] Hardened Tor Browser for Windows 
For the record, I'm not personally opposed to the telemetry in
Windows, in context. But I am curious whether the data gathered by
Microsoft could deanonymize a Tor user by, eg, pinpointing Tor usage
within a specific time frame, given a number of assumptions about an
observer's ability to correlate multiple visits to a surveilled site
and so on. I imagine Microsoft would not willingly divulge such info
("tell us everything about everyone using Tor at these moments" isn't
much of a warrant) but the possibility is what interests me.
My guess is that the answer is probably no, at least not practically,
but I wouldn't want to stake my life on it.

@_date: 2016-10-22 10:35:52
@_author: Jon Tullett 
@_subject: [tor-talk] tor and BlackBerry 
Have you tried running the Tor Android apps on BlackBerry? Doesn't BB
support many Android apps via emulation? Also, BB is moving away from
its own OS and towards Android anyway, so it may be a moot point in
the near future.

@_date: 2016-09-26 10:09:16
@_author: Jon Tullett 
@_subject: [tor-talk] Tor and Google error / CAPTCHAs. 
That's a very interesting perspective, thanks. Is there any
cooperation among such major players to share such information?
Correlation to form reasonably high-confidence scraping/abuse RBLs,
for example?

@_date: 2017-04-24 10:03:58
@_author: Jon Tullett 
@_subject: [tor-talk] Shodan & Hidden Services 
Interesting. What can you do with that? Can you tie them to specific
hidden services?

@_date: 2017-04-24 12:54:32
@_author: Jon Tullett 
@_subject: [tor-talk] Shodan & Hidden Services 
Oops! At least it looks like a fairly small population of people
making that particular mistake.

@_date: 2017-08-07 09:32:20
@_author: Jon Tullett 
@_subject: [tor-talk] Comments? 
Enjoyed the video - thanks Paul. It cut off before Q&A...were there
any particularly good questions from the audience?
Curious to know - at a practical level, have you actually tried any of
it in practice, or had any contact with anyone who has? I mean, do the
results in practice mirror the predictions in terms of distribution
and probability ito deanonymising potential targets?

@_date: 2017-08-12 23:14:57
@_author: Jon Tullett 
@_subject: [tor-talk] Tor, DNS leaks, and BrowserLeaks.com 
Do you mean the OpenDNS search page? That used to serve ads when you
tried to resolve a non-existent domain, but it was expired some time
ago. Or are you referring to something else?

@_date: 2017-08-30 11:51:00
@_author: Jon Tullett 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, and Tor's reputation 
Blog post refers:
Leaving aside the accusations of bias in the first part, what is the
view of the proposal to force hidden services to rotate addresses?
It appears to be philosophically anathema to Tor, and probably
unworkable since it makes no attempt to account for jurisdictional
differences. Still, I'd be interested to hear whether it provoked any
real debate within Tor, or whether similar proposals have been
considered in the past.
Separately, I'm personally curious about Tor's reputation. Sure, some
people paint it as a wretched hive of scum and villainy, but how
widespread is that view, and is it a concern to anyone involved with
the project? Has it been studied/researched at all?

@_date: 2017-08-30 12:47:10
@_author: Jon Tullett 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
But but that's where the scum and villainy hang out :) More seriously,
agreed - names matter. On a similar note, "hidden services" was a
terrible name from the outset - kinda invited negative connotations.
Yay for onion sites, I guess.

@_date: 2017-08-30 14:41:52
@_author: Jon Tullett 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
Hi Alec!
Thanks for the thoughtful reply.
With a devil's advocate hat on for a moment, two things strike me.
First is that the technical advantages of Tor are not in question, and
raising technical arguments in what quickly becomes an ethical debate
tends to polarize positions further. And that doesn't help the
reputation issue, though I'm still not sure that's as big a deal as
some may think.
And yet Facebook itself actively engages in censorship, and cooperates
with law enforcement when legally required to do so. I know Facebook
corporate is acutely aware of the complexity of juggling
differently-defined (if not outright conflicting) legal expectations
of privacy across jurisdictions - providing access through Tor is
clearly not diminishing those obligations. That seems to suggest that
there is scope for middle ground, whatever that may be.

@_date: 2017-08-30 15:45:07
@_author: Jon Tullett 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
I meant it more generally - pro-Tor arguments tend to become technical
fairly quickly. Possibly because they're easy - easy to raise, easy to
defend. Ethical stuff gets murky awful fast, and is so full of
strawmen. You're opposed to censorship? You must be pro-terrorism.
Burn the witch!
I can't, because it is. However, that's the ethical argument - is
there a censorship line, and if so where? That's what Krawetz is
bringing up by pointing out what he sees as Tor's denunciation of one
type of content where it has scrupulously avoided that in the past.
It's worth noting that this is  already out of context; the comments
on the blog post clarify that the group feels bad about any "vile" use
of the network. Clearly (and probably the key point here) is that
feeling bad about it is not held to justify censoring it.
He'd probably counter that he's not suggesting _censorship_, just a
mechanism that would make life harder for illegitimate sites while not
outright knocking them offline. Which does sound an awful lot like a
first step towards a slippery slope, even before you get into the
conflicting definitions of what is legitimate and what is not.
Murky. Hence my curiosity to know Tor's official thoughts on it.
Well, that's an interesting discussion. I'm actually not sure how I'd
answer it - issues like responsible disclosure spring to mind. Will
think on it.

@_date: 2017-08-30 15:55:36
@_author: Jon Tullett 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
Ah, a motoring analogy. Now we're back in my comfort zone! I have a
kinda Godwinesque theory that the probability that an IT discussion
will resort to a motoring analogy tends to 1 as the discussion goes
on. Only without killing the thread, cos we don't hate cars, or
something. OK, even my analogy analogy doesn't work. Sue me.
Ah, but...groups of houses - communities - can and do. Homeowners
associations, rules on noise, speed limits, controlled access to
suburbs, crosswalks, vehicle regulations - brakes, seatbelts,
indicators. In fact, you've managed to pick an astoundingly regulated
example to illustrate how deregulation is good :)
And to pick out contemporaneous news, the spate of car-related
terrorism attacks in Europe are likely to lead to more road-related
controls, like bollards and roadblocks. That's kinda road-censorship
in this context, no?
Weeeell. Sure. Except that the proposal here claims to be making life
difficult for operators of illegal services without sacrificing any of
the anonymity and security goals of the project. Presumably it's not
the only possible suggestion, and they may well all be complete crap,
but that's what I'm interested in. So, it's not a request to
compromise on the goals (though it might do so anyway - Alec seems to
think it would, and he would surely know better than me), and as such,
what does the project think of it, is kinda where I was coming from.

@_date: 2017-08-30 18:55:13
@_author: Jon Tullett 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
Speak for yourself, dude. I have a garage attached to my house. So there :p
For the pedestrians among us, however, there are laws controlling
behaviour, like jaywalking laws. Even as a non-motoring analogy my
objection would probably still be the same.

@_date: 2017-08-30 19:56:25
@_author: Jon Tullett 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
That's a very good way of putting it. Thanks Roger.
Doesn't that risk adding insecurity? If I trust a less secure channel
to authenticate the hidden service, then impersonating the hidden
service may become easier by providing a weaker point of attack, no?
It's not like there's a shortage of demos of people getting
LetsEncrypt (and other CA) certs they shouldn't.

@_date: 2017-03-03 19:47:00
@_author: Jon Tullett 
@_subject: [tor-talk] blocking sinkholes and honeypots 
Wouldn't that risk giving away the fact that it's a honeypot?

@_date: 2017-03-29 15:35:32
@_author: Jon Tullett 
@_subject: [tor-talk] blocking sinkholes and honeypots 
What I mean is, if blocking Tor can be correlated as a positive
indicator that a service is a honeypot, it risks making it easier to
spot. Ideally, a honeypot should mimic a real world service as closely
as possible, so I'd be cautious about blocking Tor on honeypots. Might
handle exit node traffic differently, but even that risks giving
something away. I'm just inherently opposed to identifiably different
behaviour in this sort of context. YMMV.

@_date: 2017-05-07 11:13:36
@_author: Jon Tullett 
@_subject: [tor-talk] Analysis of Tor bot behaviour 
Very interesting, not just from the Tor connection issues. I get the
impression the Tor devs are already in the loop on the specific issues

@_date: 2017-11-03 09:38:58
@_author: Jon Tullett 
@_subject: [tor-talk] donation via tbb 
Why ever not? Tor should be funded by lots of diverse contributors,
and many use it for entirely public purposes. Military funding,
journalists, ordinary citizens who want to support those in oppressive
regimes...plenty of possibilities. If you need to donate anonymously,
sure, that should be an option too. But not everyone shares the same

@_date: 2017-09-04 17:04:10
@_author: Jon Tullett 
@_subject: [tor-talk] Is there any societal use in Bitcoin? 
As it happens, I just recently transferred funds internationally. It
took 36 hours to clear, at a guaranteed rate. My local bank charged
about $8 in fees (mostly for the overhead of liaising with the local
receiver of revenue - there's a bunch of paperwork, so I can't really
object to the fee). My point is that if you're paying absurd taxes and
taking a week, you might be able to find a better option.
By contrast BTC, in the same timeframe, dropped more than 10%. If I'd
been using it to transfer the same funds, I'd have been massively out
of pocket.
There are strong arguments for disintermediating financial systems,
but we don't need to overhype the problem space, and let's not kid
ourselves that Bitcoin is a silver bullet either.

@_date: 2017-09-05 08:50:20
@_author: Jon Tullett 
@_subject: [tor-talk] Is there any societal use in Bitcoin? 
On 5 September 2017 at 08:25, carlo von lynX
You did indeed. Couple of issues with Taler. First, it doesn't show up
on Google. You have to know that it's "GNU Taler". Sure, RMS would
probably argue that's a feature not a bug, but it's something of a
barrier to awareness.
Second, release notes from this June [1] paraphrase thusly:
That has NOPE NOPE NOPE written all over it for me, I'm afraid. I'm
sure it's very clever, but until one of the release notes says "You
can now safely transfer funds from one bank to another", I'll stick
with established options (which include BTC, just not for spot forex
[1]

@_date: 2017-09-07 12:11:07
@_author: Jon Tullett 
@_subject: [tor-talk] Is there any societal use in Bitcoin? 
On 7 September 2017 at 11:43, carlo von lynX
Very much so. It was a toy back then, and Linus was upfront about
that. Remember "it won't be big and professional like GNU"?
on Linux was about a decade. I'm sure the Taler guys are hoping to be
out of alpha somewhat faster than that :)

@_date: 2018-02-06 11:49:06
@_author: Jon Tullett 
@_subject: [tor-talk] Finding "Good" neigbors 
Alec Muffett's a good person to ask about this. He was instrumental in
Facebook's onion site, and more recently Wikipedia (which appears to
be defunct now). Not sure if he's still on this list, but he's active
on Twitter:
