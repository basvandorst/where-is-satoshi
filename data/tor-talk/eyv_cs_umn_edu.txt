
@_date: 2005-08-17 17:39:00
@_author: Eugene Y. Vasserman 
@_subject: Connection limit 
Hash: RIPEMD160
I know it's possible to limit the throughput for a Tor node, but is it
possible to limit the NUMBER of connections (incoming and outgoing) a
Tor node makes? This would be excellent for preventing router crashes
(like I get...).

@_date: 2005-08-17 20:55:43
@_author: Eugene Y. Vasserman 
@_subject: Connection limit 
Hash: RIPEMD160
Thank you very much. I'm trying opther things to get my router to stop
crashing - will notify of progress.
Thus spake phobos at rootme.org:

@_date: 2005-08-30 15:04:45
@_author: Eugene Y. Vasserman 
@_subject: set or-talk digest on 
Hash: RIPEMD160
crap. sorry about that.
Thus spake Eugene Y. Vasserman:

@_date: 2005-07-27 10:30:43
@_author: Eugene Y. Vasserman 
@_subject: minimise to system tray 
Hash: RIPEMD160
It's on the TODO list, I think.
Thus spake Konstantine:

@_date: 2007-04-16 19:24:03
@_author: Eugene Y. Vasserman 
@_subject: My ISP block Tor Servers 
Hash: RIPEMD160
Why exactly would blocking Tor be illegal (and in which country)?
Thus spake Ringo Kamens:

@_date: 2007-04-16 19:34:06
@_author: Eugene Y. Vasserman 
@_subject: My ISP block Tor Servers 
Hash: RIPEMD160
(This is way off-topic)
Net neutrality is a legal gray area. While it would piss me off too to
have my ISP block services, I don't think there's a law preventing it.
Unless the contract specified they would NOT block sites, they are not
violating contract. This, of course, depends on the exact contract
wording, but this is my intuition.
What the FCC established (for AT&T) was terms for a merger, not law. It
is my understanding that the FCC could establish such a rule for all
ISPs if it chose, but it is currently choosing not to. This may itself
be a legal gray area.
So, while blocking Tor is annoying, I don't think there's anything
illegal about it. Tor is a service, not a website, so it does not even
count as censorship.
Either way, I should shut up, since this is off-topic.
Thus spake Ringo Kamens:

@_date: 2007-12-02 20:21:44
@_author: Eugene Y. Vasserman 
@_subject: storage privacy 
Hash: SHA256
While I don't think much of physical destruction either, the "encrypted
storage" method might be problematic for legal reasons, at least in the
UK. If the police were to ask you to provide encryption keys (which they
are now allowed to do), and you have "lost" the keys, they can put you
away, even if the data on the drive would not have incriminated you.
Thoughts? Anyone from the UK?

@_date: 2007-02-27 10:06:04
@_author: Eugene Y. Vasserman 
@_subject: Newbie's questions 
Hash: RIPEMD160
I have set up a rough HOWTO on having anonymous and non-anonymous
Firefox sessions co-exist (even though this itself is NOT recommended).
It is written for Windows, but mostly applies to any other operating
system. The HOWTO is here: Any and all comments from the community are appreciated.
Thus spake Michael Holstein:

@_date: 2007-01-22 14:01:20
@_author: Eugene Y. Vasserman 
@_subject: Block directory authorities, is it possible? 
It seems to me that the most difficult things are 1) to ensure that a user
in a blocked country always has access to a bridge, and 2) proving that
bridges are useful.
1) It seems a user needs to know at least two working bridges in order
to not have their connection permanently disrupted (and require
re-bootstrapping). If only one bridge is known, if that bridge moves or
goes offline, bootstrapping is required. However, if two bridges are
known, the first bridge can be used for an active connection, and the
status of the second bridge can be maintained (and confirmed with the
bridge authority periodically), so if the active bridge moves, the
backup bridge can be used to connect to Tor and use the bridge authority
to check the status of the now-inactive or moved bridge. Clearly this
only protects against bridge moves, since if the first bridge has gone
offline, the user is now left with only one.
2) Determining whether a bridge is "useful" may be impossible without
allowing an adversary to enumerate a bridge. Any adversary that blocks a
bridge from their jurisdiction can set up a connection through that
bridge to make it seem like the bridge is actively being used. There is no easy way for the bridge authority or users to learn that a bridge has been blocked. While users in a given country may know they can't connect
to a bridge, they have no easy way to notify the bridge authority.
First, the user is not authoritative: we can't trust what a given user says, since that user may be working for the "government" (for arbitrary values of
"government") and may be attempting to disable bridges by bad-mouthing
(saying they are already blocked). Second, the user needs to have access
to the Tor network in the first place to notify the bridge authority
that a bridge is blocked. This is perhaps a lesser problem than the
first one.
I'm not sure this item CAN have a workable solution...

@_date: 2007-03-09 17:20:10
@_author: Eugene Y. Vasserman 
@_subject: Boulder Tech report on low-resource routing attacks on Tor 
Hi all,
I've been thinking about how exit and entry nodes controlled by the same adversary can easily determine if they are in the same circuit due to the predictable nature of circuit set-up (timing). Well, what about altering that? Perhaps Tor nodes should form long-lived "exploratory" circuits (a la I2P). Tor should slowly extend these, with unpredictable timing intervals, perhaps over the period of dozens of minutes, or even hours. Most of these circuits are not completely formed, and thus should not be used to route data. Since there are many of these, if one dies (they are long-lived so chances of early death are not negligible), so be it. This will allow circuit formation timing to be less predictable. As an added benefit, a Tor node may have a number of 1-hop or 2-hop circuits that it can use at any time, and by extending those, instead of forming new, full-length circuits from scratch, we can make recovery from circuit failure faster.
Thus spake Paul Syverson on Wed, 07 Mar 2007:

@_date: 2007-05-20 20:59:50
@_author: Eugene Y. Vasserman 
@_subject: Tor/privoxy and gmail/ajax? 
If you're logging only HTTP, could it be you're not seeing HTTPS
sessions with gmail?
Thus spake Michael_google gmail_Gersten:

@_date: 2007-11-18 21:09:01
@_author: Eugene Y. Vasserman 
@_subject: Chroot TOR as explained on Wiki error 
Hash: SHA256
Thus spake SPKills, on 11/18/07 4:44 PM:
People should be aware that there are problems in using chroot as a
security tool. It was never intended for this purpose.
Details here:

@_date: 2008-01-28 12:57:25
@_author: Eugene Y. Vasserman 
@_subject: HidServDirectoryV2 option 
(much snippage)
(yet even more further snippage)
Hi Karsten,
Is there a design document on this DHT-like thing?

@_date: 2008-01-02 14:47:11
@_author: Eugene Y. Vasserman 
@_subject: [OT] more from Cryptome on NSA, Windows firewals, mail services 
Thus spake Ringo Kamens on Sun, 23 Dec 2007:
I've heard of the Vista bit, but what are you referring to, as far as
having a decryption key for Windows stuff? I know they had one in...
What was it? Lotus Notes?

@_date: 2008-01-02 20:42:48
@_author: Eugene Y. Vasserman 
@_subject: [OT] more from Cryptome on NSA, Windows firewals, mail services 
Hash: SHA256
Thus spake Ringo Kamens, on 1/2/2008 4:17 PM:
Personally (and god help me), I believe Microsoft when they say the key
is not a key back door key. If it was, I wonder if they would name it
"NSA". Or is that what they want us to think? :)
The Schneier essay about the random number generator is more
interesting, and worth reading.

@_date: 2008-01-02 20:58:24
@_author: Eugene Y. Vasserman 
@_subject: [OT] more from Cryptome on NSA, Windows firewals, mail services 
Hash: SHA256
Thus spake Ringo Kamens, on 1/2/2008 8:51 PM:
I'm not defending Microsoft, I'm just trying to see things from both
sides. They're not NECESSARILY adding a back door. The algorithm is
included in a standards document - Microsoft added it because some
customers will ask for it. SP1 also adds AES-GMAC.

@_date: 2008-05-21 17:47:41
@_author: Eugene Y. Vasserman 
@_subject: a serious TOR adversary? 
Hash: SHA256
Thus spake Bernardo Bacic, on 5/21/08 6:45 AM:
"Although timing-based attacks have been demonstrated against
non-timing-preserving anonymity networks, they have depended either on a
global passive adversary or on the compromise of a substantial number of
Tor nodes."
Incorrect: Steven J. Murdoch. "Hot or Not: Revealing Hidden Services by
their Clock Skew"; Nicholas Hopper, Eugene Y. Vasserman, and Eric
Chan-Tin. "How much anonymity does network latency leak?".
(Full disclosure: I'm one of the authors of the second paper).
"Furthermore, we show that a well-provisioned adversary, using a
topological map of the network, can trace-back the path of an anonymous
user in under 20 minutes."
Most Tor circuits only live a maximum of 10 minutes, no? I never figured
out just how much of hard limit this is. Can an application ask to keep
the circuit longer? Can someone in the know clue me in?
